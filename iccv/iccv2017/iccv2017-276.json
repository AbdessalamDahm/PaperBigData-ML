"{\"abstract\":\"Bilinear models provide an appealing framework for mixing and merging information in Visual Question Answering (VQA) tasks. They help to learn high level associations between question meaning and visual concepts in the image, but they suffer from huge dimensionality issues.,,We introduce MUTAN, a multimodal tensor-based Tucker decomposition to efficiently parametrize bilinear interactions between visual and textual representations. Additionally to the Tucker framework, we design a low-rank matrix-based decomposition to explicitly constrain the interaction rank. With MUTAN, we control the complexity of the merging scheme while keeping nice interpretable fusion relations. We show how the Tucker decomposition framework generalizes some of the latest VQA architectures, providing state-of-the-art results.\",\"arxivId\":\"1705.06676\",\"authors\":[{\"authorId\":\"1405301761\",\"name\":\"Hedi Ben-younes\",\"url\":\"https://www.semanticscholar.org/author/1405301761\"},{\"authorId\":\"7535126\",\"name\":\"R\\u00e9mi Cad\\u00e8ne\",\"url\":\"https://www.semanticscholar.org/author/7535126\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\",\"url\":\"https://www.semanticscholar.org/author/51021910\"},{\"authorId\":\"1728523\",\"name\":\"N. Thome\",\"url\":\"https://www.semanticscholar.org/author/1728523\"}],\"citationVelocity\":82,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"2643877\",\"name\":\"Y. Bai\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"145382463\",\"name\":\"T. Zhao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1007/978-3-030-01258-8_2\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"380d50f3ccc07fa4f41282395a78c51e33985c39\",\"title\":\"Deep Attention Neural Tensor Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/380d50f3ccc07fa4f41282395a78c51e33985c39\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72445881\",\"name\":\"Xinhong Ma\"},{\"authorId\":\"1907582\",\"name\":\"T. Zhang\"},{\"authorId\":\"48258806\",\"name\":\"C. Xu\"}],\"doi\":\"10.1109/TMM.2019.2902100\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"857210ef01825dd18fa050b36d51c0b28da7744c\",\"title\":\"Deep Multi-Modality Adversarial Networks for Unsupervised Domain Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/857210ef01825dd18fa050b36d51c0b28da7744c\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":\"2010.08708\",\"authors\":[{\"authorId\":\"2728646\",\"name\":\"Hantao Huang\"},{\"authorId\":\"145421604\",\"name\":\"T. Han\"},{\"authorId\":\"72549949\",\"name\":\"Wei Han\"},{\"authorId\":\"48986588\",\"name\":\"D. Yap\"},{\"authorId\":\"32312400\",\"name\":\"C. Chiang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"91550d1490caa39f723d3efb5d1b78b6f8b7c6cf\",\"title\":\"Answer-checking in Context: A Multi-modal FullyAttention Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/91550d1490caa39f723d3efb5d1b78b6f8b7c6cf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7808048\",\"name\":\"M. Bucher\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d423f37185a2210d5e47f24d4792e68d0088cd52\",\"title\":\"Apprentissage et exploitation de repr\\u00e9sentations s\\u00e9mantiques pour la classification et la recherche d'images. (Learning and exploiting semantic representations for image classification and retrieval)\",\"url\":\"https://www.semanticscholar.org/paper/d423f37185a2210d5e47f24d4792e68d0088cd52\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1812.05252\",\"authors\":[{\"authorId\":\"144579865\",\"name\":\"P. Gao\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"30156979\",\"name\":\"Haoxuan You\"},{\"authorId\":\"50676465\",\"name\":\"Zhengkai Jiang\"},{\"authorId\":\"2887562\",\"name\":\"Pan Lu\"},{\"authorId\":\"49212307\",\"name\":\"Steven C. H. Hoi\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"}],\"doi\":\"10.1109/CVPR.2019.00680\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e9b13731027418ed38103d1dfc8a70f6881bc684\",\"title\":\"Dynamic Fusion With Intra- and Inter-Modality Attention Flow for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e9b13731027418ed38103d1dfc8a70f6881bc684\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2004.00849\",\"authors\":[{\"authorId\":\"47272083\",\"name\":\"Zhicheng Huang\"},{\"authorId\":\"46490565\",\"name\":\"Zhaoyang Zeng\"},{\"authorId\":\"1453953482\",\"name\":\"Bei Liu\"},{\"authorId\":\"143890169\",\"name\":\"Dongmei Fu\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5c188874316557d501369e611a96cafc8058dffa\",\"title\":\"Pixel-BERT: Aligning Image Pixels with Text by Deep Multi-Modal Transformers\",\"url\":\"https://www.semanticscholar.org/paper/5c188874316557d501369e611a96cafc8058dffa\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10405058\",\"name\":\"Chenfei Wu\"},{\"authorId\":\"46700331\",\"name\":\"J. Liu\"},{\"authorId\":\"38542466\",\"name\":\"X. Wang\"},{\"authorId\":\"143672034\",\"name\":\"X. Dong\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"184002001b3b514f432e538f872aebce3c7db060\",\"title\":\"Chain of Reasoning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/184002001b3b514f432e538f872aebce3c7db060\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"2006.11405\",\"authors\":[{\"authorId\":\"9148956\",\"name\":\"Chongyang Bai\"},{\"authorId\":\"2028262\",\"name\":\"H. Chen\"},{\"authorId\":\"39703734\",\"name\":\"Srijan Kumar\"},{\"authorId\":\"1702139\",\"name\":\"J. Leskovec\"},{\"authorId\":\"1728462\",\"name\":\"V. Subrahmanian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"51819e6b428676c373d97f267d18b8d4a25020fd\",\"title\":\"M2P2: Multimodal Persuasion Prediction using Adaptive Fusion\",\"url\":\"https://www.semanticscholar.org/paper/51819e6b428676c373d97f267d18b8d4a25020fd\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.12870\",\"authors\":[{\"authorId\":\"1960607091\",\"name\":\"Yi Zhou\"},{\"authorId\":\"8157338\",\"name\":\"Zhenhao Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"14e5d984af4ac965579644bd0ea4ae42587b6a00\",\"title\":\"Multimodal Learning for Hateful Memes Detection\",\"url\":\"https://www.semanticscholar.org/paper/14e5d984af4ac965579644bd0ea4ae42587b6a00\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50974488\",\"name\":\"Mingrui Lao\"},{\"authorId\":\"49813983\",\"name\":\"Yanming Guo\"},{\"authorId\":\"49528152\",\"name\":\"H. Wang\"},{\"authorId\":\"49468999\",\"name\":\"Xin Zhang\"}],\"doi\":\"10.1109/ACCESS.2018.2873570\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"161876ad06d5a349ccde4b4db3d3759ef43268a8\",\"title\":\"Multimodal Local Perception Bilinear Pooling for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/161876ad06d5a349ccde4b4db3d3759ef43268a8\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":\"1806.00857\",\"authors\":[{\"authorId\":\"35748708\",\"name\":\"Gabriel Grand\"},{\"authorId\":\"31408089\",\"name\":\"Aron Szanto\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2a9135976912d4169a4490c641561ed0867a306c\",\"title\":\"On the Flip Side: Identifying Counterexamples in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2a9135976912d4169a4490c641561ed0867a306c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10405058\",\"name\":\"Chenfei Wu\"},{\"authorId\":\"46700331\",\"name\":\"J. Liu\"},{\"authorId\":\"1680068\",\"name\":\"X. Wang\"},{\"authorId\":\"143672034\",\"name\":\"X. Dong\"}],\"doi\":\"10.1145/3240508.3240513\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"34c9753893fe4713568542e7d96dc9a9e6545ec8\",\"title\":\"Object-Difference Attention: A Simple Relational Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/34c9753893fe4713568542e7d96dc9a9e6545ec8\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1810.12440\",\"authors\":[{\"authorId\":\"47309247\",\"name\":\"Manoj Acharya\"},{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1609/aaai.v33i01.33018076\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"634161e4759616dbe06f0b1465999d3df122f366\",\"title\":\"TallyQA: Answering Complex Counting Questions\",\"url\":\"https://www.semanticscholar.org/paper/634161e4759616dbe06f0b1465999d3df122f366\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39105519\",\"name\":\"Matthew Ricci\"},{\"authorId\":\"7535126\",\"name\":\"R\\u00e9mi Cad\\u00e8ne\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"}],\"doi\":\"10.1016/j.cobeha.2020.08.008\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"519af509d69d15fede74f64bef8a7833d47fdd28\",\"title\":\"Same-different conceptualization: a machine vision perspective\",\"url\":\"https://www.semanticscholar.org/paper/519af509d69d15fede74f64bef8a7833d47fdd28\",\"venue\":\"Current Opinion in Behavioral Sciences\",\"year\":2021},{\"arxivId\":\"2004.12081\",\"authors\":[{\"authorId\":\"49576759\",\"name\":\"Zhe Sun\"},{\"authorId\":\"153857960\",\"name\":\"Z. Huang\"},{\"authorId\":\"144632157\",\"name\":\"Feng Duan\"},{\"authorId\":\"30752055\",\"name\":\"Y. Liu\"}],\"doi\":\"10.1109/ACCESS.2020.2994226\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d8ae71ed6bab317e2d04af77b14c4a8e6cc806df\",\"title\":\"A Novel Multimodal Approach for Hybrid Brain\\u2013Computer Interface\",\"url\":\"https://www.semanticscholar.org/paper/d8ae71ed6bab317e2d04af77b14c4a8e6cc806df\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1904.05876\",\"authors\":[{\"authorId\":\"38211837\",\"name\":\"Idan Schwartz\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"1918412\",\"name\":\"T. Hazan\"}],\"doi\":\"10.1109/CVPR.2019.01283\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf072e469d82e71f0515f32b686fb084f4f31714\",\"title\":\"A Simple Baseline for Audio-Visual Scene-Aware Dialog\",\"url\":\"https://www.semanticscholar.org/paper/cf072e469d82e71f0515f32b686fb084f4f31714\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1810.10656\",\"authors\":[{\"authorId\":\"2909186\",\"name\":\"Ben Zion Vatashsky\"},{\"authorId\":\"1743045\",\"name\":\"S. Ullman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"86553974fabf38bbe022dc44794f345339b45c0b\",\"title\":\"Understand, Compose and Respond - Answering Visual Questions by a Composition of Abstract Procedures\",\"url\":\"https://www.semanticscholar.org/paper/86553974fabf38bbe022dc44794f345339b45c0b\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1811.07789\",\"authors\":[{\"authorId\":\"1977256\",\"name\":\"V. Manjunatha\"},{\"authorId\":\"19173161\",\"name\":\"Nirat Saini\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/CVPR.2019.00979\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c5d15ab9b3d541e53d0b7743bce99a074698394b\",\"title\":\"Explicit Bias Discovery in Visual Question Answering Models\",\"url\":\"https://www.semanticscholar.org/paper/c5d15ab9b3d541e53d0b7743bce99a074698394b\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1906.10770\",\"authors\":[{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"},{\"authorId\":\"9919436\",\"name\":\"J. Yu\"},{\"authorId\":\"30513139\",\"name\":\"Yuhao Cui\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/CVPR.2019.00644\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8a1744da011375d711ed75fc2d160c6fdca2cf89\",\"title\":\"Deep Modular Co-Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8a1744da011375d711ed75fc2d160c6fdca2cf89\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47909637\",\"name\":\"Yun Liu\"},{\"authorId\":\"1679013\",\"name\":\"X. Zhang\"},{\"authorId\":\"1939569\",\"name\":\"Feiran Huang\"},{\"authorId\":\"1707275\",\"name\":\"Zhoujun Li\"}],\"doi\":\"10.1145/3269206.3271765\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c67d62592ff24a25764e489a8a68672d40f50da7\",\"title\":\"Adversarial Learning of Answer-Related Representation for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/c67d62592ff24a25764e489a8a68672d40f50da7\",\"venue\":\"CIKM\",\"year\":2018},{\"arxivId\":\"1902.09487\",\"authors\":[{\"authorId\":\"7535126\",\"name\":\"R\\u00e9mi Cad\\u00e8ne\"},{\"authorId\":\"1405301761\",\"name\":\"Hedi Ben-younes\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"},{\"authorId\":\"1728523\",\"name\":\"N. Thome\"}],\"doi\":\"10.1109/CVPR.2019.00209\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"0a9f1a1321958df7dfb2efce3e9d1e99b9f5ccb3\",\"title\":\"MUREL: Multimodal Relational Reasoning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0a9f1a1321958df7dfb2efce3e9d1e99b9f5ccb3\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51294257\",\"name\":\"T. Goto\"},{\"authorId\":\"1757878\",\"name\":\"C. Wang\"},{\"authorId\":\"1724928\",\"name\":\"Y. Li\"},{\"authorId\":\"3184895\",\"name\":\"Y. Tsuboshita\"}],\"doi\":\"10.1117/12.2549483\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"69b0b783929ec53e4bae15daffaddd3a2752b952\",\"title\":\"Multi-modal deep learning for predicting progression of Alzheimer's disease using bi-linear shake fusion\",\"url\":\"https://www.semanticscholar.org/paper/69b0b783929ec53e4bae15daffaddd3a2752b952\",\"venue\":\"Medical Imaging\",\"year\":2020},{\"arxivId\":\"2011.02164\",\"authors\":[{\"authorId\":\"49172303\",\"name\":\"T. Rahman\"},{\"authorId\":\"6937593\",\"name\":\"Shih-Han Chou\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"1387254703\",\"name\":\"Giuseppe Carenini\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e1cf7e279abc4301729c24cb7f888b2df42f7644\",\"title\":\"An Improved Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e1cf7e279abc4301729c24cb7f888b2df42f7644\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.08760\",\"authors\":[{\"authorId\":\"145097076\",\"name\":\"Minh H. Vu\"},{\"authorId\":\"40136362\",\"name\":\"T. L\\u00f6fstedt\"},{\"authorId\":\"1401897458\",\"name\":\"Tufve Nyholm\"},{\"authorId\":\"1824404\",\"name\":\"Raphael Sznitman\"}],\"doi\":\"10.1109/TMI.2020.2978284\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6adb61121ca4560915ade532910acde56440b88f\",\"title\":\"A Question-Centric Model for Visual Question Answering in Medical Imaging\",\"url\":\"https://www.semanticscholar.org/paper/6adb61121ca4560915ade532910acde56440b88f\",\"venue\":\"IEEE Transactions on Medical Imaging\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47016316\",\"name\":\"Revanth Reddy Gangi Reddy\"},{\"authorId\":\"10081629\",\"name\":\"R. Ramesh\"},{\"authorId\":\"33341943\",\"name\":\"Ameet Deshpande\"},{\"authorId\":\"2361078\",\"name\":\"Mitesh M. Khapra\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f9e109dc039be6869c58d56d878cc4990f0f4c86\",\"title\":\"A Question-Answering framework for plots using Deep learning\",\"url\":\"https://www.semanticscholar.org/paper/f9e109dc039be6869c58d56d878cc4990f0f4c86\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1912.03063\",\"authors\":[{\"authorId\":\"51149482\",\"name\":\"Corentin Kervadec\"},{\"authorId\":\"145664204\",\"name\":\"G. Antipov\"},{\"authorId\":\"2341854\",\"name\":\"M. Baccouche\"},{\"authorId\":\"144899680\",\"name\":\"C. Wolf\"}],\"doi\":\"10.3233/FAIA200412\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3e9336a1be4fc269a987656aab16d2791515917f\",\"title\":\"Weak Supervision helps Emergence of Word-Object Alignment and improves Vision-Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/3e9336a1be4fc269a987656aab16d2791515917f\",\"venue\":\"ECAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41022273\",\"name\":\"Duy-Kien Nguyen\"},{\"authorId\":\"1718872\",\"name\":\"Takayuki Okatani\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d83f208c54a837b1e8361bba49e90bc75927ca80\",\"title\":\"Supplementary Material for \\u201c Improved Fusion of Visual and Language Representations by Dense Symmetric Co-Attention for Visual Question Answering \\u201d\",\"url\":\"https://www.semanticscholar.org/paper/d83f208c54a837b1e8361bba49e90bc75927ca80\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2010.12025\",\"authors\":[{\"authorId\":\"47333939\",\"name\":\"Guangzhi Sun\"},{\"authorId\":\"145657505\",\"name\":\"C. Zhang\"},{\"authorId\":\"2001144927\",\"name\":\"Phil Woodland\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"79ff7b92d608301ac4ed43d13ff018c55ceba4f1\",\"title\":\"Combination of Deep Speaker Embeddings for Diarisation\",\"url\":\"https://www.semanticscholar.org/paper/79ff7b92d608301ac4ed43d13ff018c55ceba4f1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"16149902\",\"name\":\"Janani Ramaswamy\"},{\"authorId\":\"144009889\",\"name\":\"Sukhendu Das\"}],\"doi\":\"10.1109/WACV45572.2020.9093616\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c911d81bddb48490a02258e79379b6428246ddc2\",\"title\":\"See the Sound, Hear the Pixels\",\"url\":\"https://www.semanticscholar.org/paper/c911d81bddb48490a02258e79379b6428246ddc2\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1911.04058\",\"authors\":[{\"authorId\":\"48615049\",\"name\":\"Y. Xu\"},{\"authorId\":\"46308159\",\"name\":\"L. Chen\"},{\"authorId\":\"120235436\",\"name\":\"Zhongwei Cheng\"},{\"authorId\":\"71138167\",\"name\":\"Lixin Duan\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.34\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2fdcc61d9a02412f5eb5d596ee41c8504a83c20a\",\"title\":\"Open-Ended Visual Question Answering by Multi-Modal Domain Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/2fdcc61d9a02412f5eb5d596ee41c8504a83c20a\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"20525031\",\"name\":\"Taylor Mordan\"},{\"authorId\":\"1728523\",\"name\":\"N. Thome\"},{\"authorId\":\"2386962\",\"name\":\"Gilles H\\u00e9naff\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2b7f7a336ca33cfc59d870cbeca7cc4a1af6b168\",\"title\":\"Revisiting Multi-Task Learning with ROCK: a Deep Residual Auxiliary Block for Visual Detection\",\"url\":\"https://www.semanticscholar.org/paper/2b7f7a336ca33cfc59d870cbeca7cc4a1af6b168\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"2010.00515\",\"authors\":[{\"authorId\":\"151475424\",\"name\":\"Tianrui Hui\"},{\"authorId\":\"101219260\",\"name\":\"Si Liu\"},{\"authorId\":\"15633953\",\"name\":\"Shaofei Huang\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"1977587202\",\"name\":\"Sansi Yu\"},{\"authorId\":\"1977074324\",\"name\":\"Faxi Zhang\"},{\"authorId\":\"150147352\",\"name\":\"Jizhong Han\"}],\"doi\":\"10.1007/978-3-030-58607-2_4\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b907a8d6c6fc5a0c3a8857a9db4225dc922397ad\",\"title\":\"Linguistic Structure Guided Context Modeling for Referring Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/b907a8d6c6fc5a0c3a8857a9db4225dc922397ad\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3236503\",\"name\":\"Li-Chi Huang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5438445786db9f6181d9fabfc758663518ba28fd\",\"title\":\"Compressive Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/5438445786db9f6181d9fabfc758663518ba28fd\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1801.03002\",\"authors\":[{\"authorId\":\"22188614\",\"name\":\"Ivona Tautkute\"},{\"authorId\":\"144432036\",\"name\":\"T. Trzci\\u0144ski\"},{\"authorId\":\"150033476\",\"name\":\"Aleksander P. Skorupa\"},{\"authorId\":\"52401952\",\"name\":\"\\u0141ukasz Brocki\"},{\"authorId\":\"150175209\",\"name\":\"Krzysztof Marasek\"}],\"doi\":\"10.1109/ACCESS.2019.2923552\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"46fe7b0ea33d278629404edb27bf84b7dac7a0e8\",\"title\":\"DeepStyle: Multimodal Search Engine for Fashion and Interior Design\",\"url\":\"https://www.semanticscholar.org/paper/46fe7b0ea33d278629404edb27bf84b7dac7a0e8\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1908.02962\",\"authors\":[{\"authorId\":\"2420608\",\"name\":\"Difei Gao\"},{\"authorId\":\"3373117\",\"name\":\"R. Wang\"},{\"authorId\":\"145455919\",\"name\":\"S. Shan\"},{\"authorId\":\"1710220\",\"name\":\"X. Chen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"06b3ecff93bc79a1242b06702f160ffc43c487b9\",\"title\":\"From Two Graphs to N Questions: A VQA Dataset for Compositional Reasoning on Vision and Commonsense\",\"url\":\"https://www.semanticscholar.org/paper/06b3ecff93bc79a1242b06702f160ffc43c487b9\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1811.12772\",\"authors\":[{\"authorId\":\"6328564\",\"name\":\"M. Farazi\"},{\"authorId\":\"1931655\",\"name\":\"S. Khan\"},{\"authorId\":\"1712576\",\"name\":\"N. Barnes\"}],\"doi\":\"10.1016/j.imavis.2020.103985\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a678b68abd4047d5342f64725f57a04647a47711\",\"title\":\"From Known to the Unknown: Transferring Knowledge to Answer Questions about Novel Visual and Semantic Concepts\",\"url\":\"https://www.semanticscholar.org/paper/a678b68abd4047d5342f64725f57a04647a47711\",\"venue\":\"Image Vis. Comput.\",\"year\":2020},{\"arxivId\":\"1905.13540\",\"authors\":[{\"authorId\":\"2447631\",\"name\":\"Junyeong Kim\"},{\"authorId\":\"103278467\",\"name\":\"Minuk Ma\"},{\"authorId\":\"3549056\",\"name\":\"K. Kim\"},{\"authorId\":\"72108920\",\"name\":\"S. Kim\"},{\"authorId\":\"145954697\",\"name\":\"C. Yoo\"}],\"doi\":\"10.1109/IJCNN.2019.8852087\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1165b090e5ec6a9311ecba5be4f6aac0a1a4586b\",\"title\":\"Gaining Extra Supervision via Multi-task learning for Multi-Modal Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1165b090e5ec6a9311ecba5be4f6aac0a1a4586b\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":\"1804.00775\",\"authors\":[{\"authorId\":\"41022273\",\"name\":\"Duy-Kien Nguyen\"},{\"authorId\":\"1718872\",\"name\":\"Takayuki Okatani\"}],\"doi\":\"10.1109/CVPR.2018.00637\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f7cc85bed2a3d0b0ef1c0e0258f5b60ee4bb4622\",\"title\":\"Improved Fusion of Visual and Language Representations by Dense Symmetric Co-attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f7cc85bed2a3d0b0ef1c0e0258f5b60ee4bb4622\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2005.08271\",\"authors\":[{\"authorId\":\"47698311\",\"name\":\"Vladimir Iashin\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d87489d2facf197caafd24d0796523d55d47fb62\",\"title\":\"A Better Use of Audio-Visual Cues: Dense Video Captioning with Bi-modal Transformer\",\"url\":\"https://www.semanticscholar.org/paper/d87489d2facf197caafd24d0796523d55d47fb62\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2065332\",\"name\":\"H. Lee\"},{\"authorId\":\"1731707\",\"name\":\"K. Jung\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4012d85408a97d6c0878da0932e81b6022d96c08\",\"title\":\"Insensibility of Question Word Order in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/4012d85408a97d6c0878da0932e81b6022d96c08\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145268319\",\"name\":\"Qiang Sun\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"}],\"doi\":\"10.1145/3323873.3325044\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"33c6f05eac12622146fec4868735daa78f79f80a\",\"title\":\"Stacked Self-Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/33c6f05eac12622146fec4868735daa78f79f80a\",\"venue\":\"ICMR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1997924\",\"name\":\"Samira Pouyanfar\"},{\"authorId\":\"46958587\",\"name\":\"T. Wang\"},{\"authorId\":\"1705664\",\"name\":\"Shu-Ching Chen\"}],\"doi\":\"10.1109/CVPRW.2019.00064\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"45293b8428be256faf29c14be524c2c68110dadd\",\"title\":\"Residual Attention-Based Fusion for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/45293b8428be256faf29c14be524c2c68110dadd\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":\"2007.09592\",\"authors\":[{\"authorId\":\"47043894\",\"name\":\"Ruixue Tang\"},{\"authorId\":\"144905344\",\"name\":\"Chifeng Ma\"},{\"authorId\":\"32794831\",\"name\":\"W. Zhang\"},{\"authorId\":\"1509240145\",\"name\":\"Qi Wu\"},{\"authorId\":\"15469693\",\"name\":\"Xiaokang Yang\"}],\"doi\":\"10.1007/978-3-030-58529-7_26\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ff560bbf5c11894379d7e808683d553e3d1f08c2\",\"title\":\"Semantic Equivalent Adversarial Data Augmentation for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ff560bbf5c11894379d7e808683d553e3d1f08c2\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2012.00451\",\"authors\":[{\"authorId\":\"153276988\",\"name\":\"Antoine Yang\"},{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"153433844\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b1b6ff0df21818ac8c4f61d86141da48188f36b3\",\"title\":\"Just Ask: Learning to Answer Questions from Millions of Narrated Videos\",\"url\":\"https://www.semanticscholar.org/paper/b1b6ff0df21818ac8c4f61d86141da48188f36b3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1906.01004\",\"authors\":[{\"authorId\":null,\"name\":\"Yan Zhang\"},{\"authorId\":\"2276351\",\"name\":\"Krikamol Muandet\"},{\"authorId\":\"152284539\",\"name\":\"Qianli Ma\"},{\"authorId\":\"143627576\",\"name\":\"Heiko Neumann\"},{\"authorId\":\"39578749\",\"name\":\"Siyu Tang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8d8bf28727f1b2bc1a47425f3b6ec59bb8381f5b\",\"title\":\"Frontal Low-rank Random Tensors for Fine-grained Action Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/8d8bf28727f1b2bc1a47425f3b6ec59bb8381f5b\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33626762\",\"name\":\"J. Ordonez\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"96094b030013ca2d9b6d5a14b6f1fbbc57eb8a89\",\"title\":\"What is in that picture ? Visual Question Answering System\",\"url\":\"https://www.semanticscholar.org/paper/96094b030013ca2d9b6d5a14b6f1fbbc57eb8a89\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144318278\",\"name\":\"Abhishek Sinha\"},{\"authorId\":\"2566197\",\"name\":\"K. Ayush\"}],\"doi\":\"10.1109/ICIP.2018.8451353\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f1f6f1f2f3c732eb986f604f6056c23bd9e25c7c\",\"title\":\"Towards Mathematical Reasoning: A Multimodal Deep Learning Approach\",\"url\":\"https://www.semanticscholar.org/paper/f1f6f1f2f3c732eb986f604f6056c23bd9e25c7c\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47739808\",\"name\":\"Junkun Chen\"},{\"authorId\":\"1767521\",\"name\":\"Xipeng Qiu\"},{\"authorId\":\"144118452\",\"name\":\"Pengfei Liu\"},{\"authorId\":\"144052385\",\"name\":\"X. Huang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3468740e4a9fc72a269f4f0ca8470ccd60925f92\",\"title\":\"2019 Formatting Instructions for Authors Using LaTeX\",\"url\":\"https://www.semanticscholar.org/paper/3468740e4a9fc72a269f4f0ca8470ccd60925f92\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1812.01880\",\"authors\":[{\"authorId\":\"10817432\",\"name\":\"Kaihua Tang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"143905981\",\"name\":\"Baoyuan Wu\"},{\"authorId\":\"145909988\",\"name\":\"Wenhan Luo\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"}],\"doi\":\"10.1109/CVPR.2019.00678\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"88ec56eee6a787ccda0cf7fbfbec48c6b4ad68fe\",\"title\":\"Learning to Compose Dynamic Tree Structures for Visual Contexts\",\"url\":\"https://www.semanticscholar.org/paper/88ec56eee6a787ccda0cf7fbfbec48c6b4ad68fe\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145764583\",\"name\":\"F. Liu\"},{\"authorId\":\"40628473\",\"name\":\"Jing Liu\"},{\"authorId\":\"49597404\",\"name\":\"Z. Fang\"},{\"authorId\":\"48043335\",\"name\":\"R. Hong\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.24963/ijcai.2019/122\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"99dc8f4c6be75b32a584608cea2c0da0de47db8d\",\"title\":\"Densely Connected Attention Flow for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/99dc8f4c6be75b32a584608cea2c0da0de47db8d\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"1805.07932\",\"authors\":[{\"authorId\":\"2684967\",\"name\":\"J. Kim\"},{\"authorId\":\"29818400\",\"name\":\"Jaehyun Jun\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a5d10341717c0519cf63151b496a6d2ed67aa05f\",\"title\":\"Bilinear Attention Networks\",\"url\":\"https://www.semanticscholar.org/paper/a5d10341717c0519cf63151b496a6d2ed67aa05f\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2681569\",\"name\":\"Haoqi Fan\"},{\"authorId\":\"27329137\",\"name\":\"Jiatong Zhou\"}],\"doi\":\"10.1109/CVPR.2018.00118\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"135c71101af5d030f8cf470c454e7b655d699920\",\"title\":\"Stacked Latent Attention for Multimodal Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/135c71101af5d030f8cf470c454e7b655d699920\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"133678193\",\"name\":\"A. van den Hengel\"}],\"doi\":\"10.1109/MSP.2017.2739826\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"141c9f6817331a6f3cccf82ebda5c8fd66c88b98\",\"title\":\"Visual Question Answering: A Tutorial\",\"url\":\"https://www.semanticscholar.org/paper/141c9f6817331a6f3cccf82ebda5c8fd66c88b98\",\"venue\":\"IEEE Signal Processing Magazine\",\"year\":2017},{\"arxivId\":\"2003.07333\",\"authors\":[{\"authorId\":\"7754251\",\"name\":\"Sylvain Lobry\"},{\"authorId\":\"144173388\",\"name\":\"D. Marcos\"},{\"authorId\":\"1409495574\",\"name\":\"J. Murray\"},{\"authorId\":\"1404577763\",\"name\":\"D. Tuia\"}],\"doi\":\"10.1109/TGRS.2020.2988782\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0b3ddddefee26c686da2e1088d21e69c594f1c3d\",\"title\":\"RSVQA: Visual Question Answering for Remote Sensing Data\",\"url\":\"https://www.semanticscholar.org/paper/0b3ddddefee26c686da2e1088d21e69c594f1c3d\",\"venue\":\"IEEE Transactions on Geoscience and Remote Sensing\",\"year\":2020},{\"arxivId\":\"2010.08189\",\"authors\":[{\"authorId\":\"2283009\",\"name\":\"W. Chen\"},{\"authorId\":\"46315247\",\"name\":\"W. Wang\"},{\"authorId\":\"87109212\",\"name\":\"Li Liu\"},{\"authorId\":\"1731570\",\"name\":\"M. Lew\"}],\"doi\":\"10.1016/j.neucom.2020.10.042\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"61ba6969078b7358c61f7eb93b4150ab0e4f329b\",\"title\":\"New Ideas and Trends in Deep Multimodal Content Understanding: A Review\",\"url\":\"https://www.semanticscholar.org/paper/61ba6969078b7358c61f7eb93b4150ab0e4f329b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46700331\",\"name\":\"J. Liu\"},{\"authorId\":\"10405058\",\"name\":\"Chenfei Wu\"},{\"authorId\":\"39527132\",\"name\":\"Xiaojie Wang\"},{\"authorId\":\"143672034\",\"name\":\"X. Dong\"}],\"doi\":\"10.1109/CCIS.2018.8691361\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"e074ccab7b7c46b48d643c1026e71e563878885f\",\"title\":\"Sequential Visual Reasoning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e074ccab7b7c46b48d643c1026e71e563878885f\",\"venue\":\"2018 5th IEEE International Conference on Cloud Computing and Intelligence Systems (CCIS)\",\"year\":2018},{\"arxivId\":\"1902.00313\",\"authors\":[{\"authorId\":\"32701193\",\"name\":\"Yuanzhi Liang\"},{\"authorId\":\"2643877\",\"name\":\"Y. Bai\"},{\"authorId\":null,\"name\":\"Wei Zhang\"},{\"authorId\":\"6468417\",\"name\":\"Xueming Qian\"},{\"authorId\":\"4096586\",\"name\":\"L. Zhu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ab88c48e7829029c47ac6deea5c0ccbff3614c5c\",\"title\":\"Rethinking Visual Relationships for High-level Image Understanding\",\"url\":\"https://www.semanticscholar.org/paper/ab88c48e7829029c47ac6deea5c0ccbff3614c5c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1909.10128\",\"authors\":[{\"authorId\":\"2826839\",\"name\":\"Qingxing Cao\"},{\"authorId\":\"51473867\",\"name\":\"Bailin Li\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"49478124\",\"name\":\"L. Lin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4cede1c63336de84344922876e6ee23617e2afb3\",\"title\":\"Explainable High-order Visual Question Reasoning: A New Benchmark and Knowledge-routed Network\",\"url\":\"https://www.semanticscholar.org/paper/4cede1c63336de84344922876e6ee23617e2afb3\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1909.09944\",\"authors\":[{\"authorId\":\"49172303\",\"name\":\"T. Rahman\"},{\"authorId\":\"3443241\",\"name\":\"Bicheng Xu\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":\"10.1109/ICCV.2019.00900\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7a2de516a4e628a30036193d71faac7240d553ef\",\"title\":\"Watch, Listen and Tell: Multi-Modal Weakly Supervised Dense Event Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7a2de516a4e628a30036193d71faac7240d553ef\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1912.01119\",\"authors\":[{\"authorId\":\"97634546\",\"name\":\"Khaled Jedoui\"},{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e23a129f49fcd52258c14da28311cce3190d271f\",\"title\":\"Deep Bayesian Active Learning for Multiple Correct Outputs\",\"url\":\"https://www.semanticscholar.org/paper/e23a129f49fcd52258c14da28311cce3190d271f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1809.01124\",\"authors\":[{\"authorId\":\"153137839\",\"name\":\"M. Narasimhan\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1007/978-3-030-01237-3_28\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d88eb94d7054d2668b1a8dfa311721f37ae1f059\",\"title\":\"Straight to the Facts: Learning Knowledge Base Retrieval for Factual Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d88eb94d7054d2668b1a8dfa311721f37ae1f059\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"120828339\",\"name\":\"Binghua Li\"},{\"authorId\":\"1971112\",\"name\":\"Chaofeng Li\"},{\"authorId\":\"144632157\",\"name\":\"Feng Duan\"},{\"authorId\":\"47359248\",\"name\":\"N. Zheng\"},{\"authorId\":\"50543718\",\"name\":\"Qibin Zhao\"}],\"doi\":\"10.1007/978-3-030-58586-0_26\",\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"21cf6ebac135770d97b71702c7eec2d3121cf11c\",\"title\":\"TPFN: Applying Outer Product Along Time to Multimodal Sentiment Analysis Fusion on Incomplete Data\",\"url\":\"https://www.semanticscholar.org/paper/21cf6ebac135770d97b71702c7eec2d3121cf11c\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2001.03339\",\"authors\":[{\"authorId\":\"6937593\",\"name\":\"Shih-Han Chou\"},{\"authorId\":\"150336480\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"2268189\",\"name\":\"Wei-Sheng Lai\"},{\"authorId\":\"30885811\",\"name\":\"Min Sun\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8d27640ce75557156de13fb827b64446ef9cc0e4\",\"title\":\"Visual Question Answering on 360{\\\\deg} Images.\",\"url\":\"https://www.semanticscholar.org/paper/8d27640ce75557156de13fb827b64446ef9cc0e4\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1906.00067\",\"authors\":[{\"authorId\":\"35789996\",\"name\":\"Kenneth Marino\"},{\"authorId\":\"143887493\",\"name\":\"M. Rastegari\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"3012475\",\"name\":\"R. Mottaghi\"}],\"doi\":\"10.1109/CVPR.2019.00331\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"28ad018c39d1578bea84e7cedf94459e3dbe1e70\",\"title\":\"OK-VQA: A Visual Question Answering Benchmark Requiring External Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/28ad018c39d1578bea84e7cedf94459e3dbe1e70\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40295709\",\"name\":\"F. Liu\"},{\"authorId\":null,\"name\":\"Jing Liu\"},{\"authorId\":\"48386951\",\"name\":\"Xinxin Zhu\"},{\"authorId\":\"120313754\",\"name\":\"Richang Hong\"},{\"authorId\":\"1699900\",\"name\":\"H. Lu\"}],\"doi\":\"10.1145/3394171.3413649\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"063235546b312ee4cb5cc67578b6e879461c6d83\",\"title\":\"Dual Hierarchical Temporal Convolutional Network with QA-Aware Dynamic Normalization for Video Story Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/063235546b312ee4cb5cc67578b6e879461c6d83\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"},{\"authorId\":\"143655174\",\"name\":\"P. Turaga\"},{\"authorId\":\"40222634\",\"name\":\"K. Kulkarni\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"22a47c94c49e721e0afbf70ab10200403a1d2cf7\",\"title\":\"Compressive Visual Question Answering by Li-chi Huang A Thesis Presented in Partial Fulfillment of the Requirements for the Degree Master of Science Approved August 2017 by the Graduate Supervisory Committee: Pavan Turaga, Chair\",\"url\":\"https://www.semanticscholar.org/paper/22a47c94c49e721e0afbf70ab10200403a1d2cf7\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1905.10622\",\"authors\":[{\"authorId\":\"47327595\",\"name\":\"A. Dey\"},{\"authorId\":\"39937691\",\"name\":\"S. Ghosh\"},{\"authorId\":\"2864362\",\"name\":\"Ernest Valveny\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"03d364f55fe34ba02e767db6a7f54962562b44d1\",\"title\":\"Beyond Visual Semantics: Exploring the Role of Scene Text in Image Understanding\",\"url\":\"https://www.semanticscholar.org/paper/03d364f55fe34ba02e767db6a7f54962562b44d1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1808.10192\",\"authors\":[{\"authorId\":\"9192775\",\"name\":\"Preksha Nema\"},{\"authorId\":\"2361078\",\"name\":\"Mitesh M. Khapra\"}],\"doi\":\"10.18653/v1/D18-1429\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"fb0f20a356ba6160f4728c1f18594300ac4d1d00\",\"title\":\"Towards a Better Metric for Evaluating Question Generation Systems\",\"url\":\"https://www.semanticscholar.org/paper/fb0f20a356ba6160f4728c1f18594300ac4d1d00\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"2002.11835\",\"authors\":[{\"authorId\":\"3224102\",\"name\":\"D. Bacciu\"},{\"authorId\":\"9368519\",\"name\":\"D. Mandic\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"93222cb204c1e362fcad869e967e0354df522d3e\",\"title\":\"Tensor Decompositions in Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/93222cb204c1e362fcad869e967e0354df522d3e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8392193\",\"name\":\"Y. Takashima\"},{\"authorId\":\"1720751\",\"name\":\"Toru Nakashika\"},{\"authorId\":\"1744026\",\"name\":\"T. Takiguchi\"},{\"authorId\":\"1678564\",\"name\":\"Y. Ariki\"}],\"doi\":\"10.1186/s13636-019-0160-1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"28390d4c3ae86079f599822f83ad205805dd7440\",\"title\":\"Non-parallel dictionary learning for voice conversion using non-negative Tucker decomposition\",\"url\":\"https://www.semanticscholar.org/paper/28390d4c3ae86079f599822f83ad205805dd7440\",\"venue\":\"EURASIP J. Audio Speech Music. Process.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26339425\",\"name\":\"Valentin Vielzeuf\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"0501b8a99270a20c7536ed2f6df6569413810f6d\",\"title\":\"Apprentissage neuronal profond pour l'analyse de contenus multimodaux et temporels. (Deep learning for multimodal and temporal contents analysis)\",\"url\":\"https://www.semanticscholar.org/paper/0501b8a99270a20c7536ed2f6df6569413810f6d\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145986708\",\"name\":\"Bo Sun\"},{\"authorId\":\"14701865\",\"name\":\"Z. Yao\"},{\"authorId\":\"48380350\",\"name\":\"Yinghui Zhang\"},{\"authorId\":\"8834504\",\"name\":\"Lejun Yu\"}],\"doi\":\"10.1016/j.jvcir.2020.102762\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"86475be7965eebb5edba838788d26c9272f14a3b\",\"title\":\"Local relation network with multilevel attention for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/86475be7965eebb5edba838788d26c9272f14a3b\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2020},{\"arxivId\":\"2007.13262\",\"authors\":[{\"authorId\":\"39209233\",\"name\":\"Siwen Luo\"},{\"authorId\":\"2046142\",\"name\":\"S. Han\"},{\"authorId\":\"33053279\",\"name\":\"Kaiyuan Sun\"},{\"authorId\":\"48422087\",\"name\":\"Josiah Poon\"}],\"doi\":\"10.1007/978-3-030-63830-6_44\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5225c9ca12387634ad93d6ccc547f5b2347d88a3\",\"title\":\"REXUP: I REason, I EXtract, I UPdate with Structured Compositional Reasoning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/5225c9ca12387634ad93d6ccc547f5b2347d88a3\",\"venue\":\"ICONIP\",\"year\":2020},{\"arxivId\":\"1907.00661\",\"authors\":[{\"authorId\":\"32185652\",\"name\":\"Yusuke Yamaura\"},{\"authorId\":\"150246288\",\"name\":\"Nobuya Kanemaki\"},{\"authorId\":\"3184895\",\"name\":\"Yukihiro Tsuboshita\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"75952cb7d5945d001d0758a994eb8017ddca3733\",\"title\":\"The Resale Price Prediction of Secondhand Jewelry Items Using a Multi-modal Deep Model with Iterative Co-Attention\",\"url\":\"https://www.semanticscholar.org/paper/75952cb7d5945d001d0758a994eb8017ddca3733\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2003.12299\",\"authors\":[{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"47090142\",\"name\":\"Seunghwan Lee\"},{\"authorId\":\"90802314\",\"name\":\"Yun-cheol Choi\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"26ecc6b8911d5ae683873adb311ce4362416bd5f\",\"title\":\"CurlingNet: Compositional Learning between Images and Text for Fashion IQ Data\",\"url\":\"https://www.semanticscholar.org/paper/26ecc6b8911d5ae683873adb311ce4362416bd5f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1906.10169\",\"authors\":[{\"authorId\":\"7535126\",\"name\":\"R\\u00e9mi Cad\\u00e8ne\"},{\"authorId\":\"41020827\",\"name\":\"Corentin Dancette\"},{\"authorId\":\"1405301761\",\"name\":\"Hedi Ben-younes\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ab9cc2c6a8d35d7a145cf608ff9dd7af87213253\",\"title\":\"RUBi: Reducing Unimodal Biases in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ab9cc2c6a8d35d7a145cf608ff9dd7af87213253\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7535126\",\"name\":\"R\\u00e9mi Cad\\u00e8ne\"},{\"authorId\":\"1405301761\",\"name\":\"Hedi Ben-younes\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"},{\"authorId\":\"1728523\",\"name\":\"N. Thome\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"cfc9ef5c7ef8056cff7bf1f1cfdd75e120f28231\",\"title\":\"Multimodal Relational Reasoning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/cfc9ef5c7ef8056cff7bf1f1cfdd75e120f28231\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"2008.09884\",\"authors\":[{\"authorId\":\"46245587\",\"name\":\"Geeticka Chauhan\"},{\"authorId\":\"1742480112\",\"name\":\"Ruizhi Liao\"},{\"authorId\":\"153671052\",\"name\":\"W. Wells\"},{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":null,\"name\":\"Xin Wang\"},{\"authorId\":\"35140763\",\"name\":\"S. Berkowitz\"},{\"authorId\":\"2986398\",\"name\":\"S. Horng\"},{\"authorId\":\"1679873\",\"name\":\"Peter Szolovits\"},{\"authorId\":\"1729630\",\"name\":\"P. Golland\"}],\"doi\":\"10.1007/978-3-030-59713-9_51\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aac5ce0dfd22f8d713e74b607ce849f632260023\",\"title\":\"Joint Modeling of Chest Radiographs and Radiology Reports for Pulmonary Edema Assessment\",\"url\":\"https://www.semanticscholar.org/paper/aac5ce0dfd22f8d713e74b607ce849f632260023\",\"venue\":\"MICCAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150074679\",\"name\":\"Denis Dushi\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d19ab1db4d8c60643bc2ce8334505acaadee84ff\",\"title\":\"Using Deep Learning to Answer Visual Questions from Blind People\",\"url\":\"https://www.semanticscholar.org/paper/d19ab1db4d8c60643bc2ce8334505acaadee84ff\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71222785\",\"name\":\"Yun Liu\"},{\"authorId\":\"46447759\",\"name\":\"X. Zhang\"},{\"authorId\":\"1939569\",\"name\":\"Feiran Huang\"},{\"authorId\":\"2548662\",\"name\":\"X. Tang\"},{\"authorId\":\"1707275\",\"name\":\"Zhoujun Li\"}],\"doi\":\"10.1016/J.ASOC.2019.105584\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a78477728a184a80cdfcfb97d5023f37961c3b6a\",\"title\":\"Visual question answering via Attention-based syntactic structure tree-LSTM\",\"url\":\"https://www.semanticscholar.org/paper/a78477728a184a80cdfcfb97d5023f37961c3b6a\",\"venue\":\"Appl. Soft Comput.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32701193\",\"name\":\"Yuanzhi Liang\"},{\"authorId\":\"2643877\",\"name\":\"Y. Bai\"},{\"authorId\":\"48902313\",\"name\":\"Wei Zhang\"},{\"authorId\":\"6468417\",\"name\":\"Xueming Qian\"},{\"authorId\":\"4096586\",\"name\":\"L. Zhu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/ICCV.2019.01050\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"db717d20dc699f4b402db0ddf923135108a9e686\",\"title\":\"VrR-VG: Refocusing Visually-Relevant Relationships\",\"url\":\"https://www.semanticscholar.org/paper/db717d20dc699f4b402db0ddf923135108a9e686\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2008.10858\",\"authors\":[{\"authorId\":\"28958635\",\"name\":\"Saadullah Amin\"},{\"authorId\":\"3383477\",\"name\":\"Stalin Varanasi\"},{\"authorId\":\"151072380\",\"name\":\"K. Dunfield\"},{\"authorId\":\"71531491\",\"name\":\"G. Neumann\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0126fce30b412d583f8e33714908dd09b86293d1\",\"title\":\"LowFER: Low-rank Bilinear Pooling for Link Prediction\",\"url\":\"https://www.semanticscholar.org/paper/0126fce30b412d583f8e33714908dd09b86293d1\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":\"2001.10853\",\"authors\":[{\"authorId\":\"153857960\",\"name\":\"Z. Huang\"},{\"authorId\":\"1414569274\",\"name\":\"Chao Li\"},{\"authorId\":\"144632157\",\"name\":\"Feng Duan\"},{\"authorId\":\"1410448986\",\"name\":\"Qibin Zhao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b106718fbddc804773b6135b1915039945096be2\",\"title\":\"H-OWAN: Multi-distorted Image Restoration with Tensor 1x1 Convolution\",\"url\":\"https://www.semanticscholar.org/paper/b106718fbddc804773b6135b1915039945096be2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1741390809\",\"name\":\"Weidong Tian\"},{\"authorId\":\"1657469716\",\"name\":\"Rencai Zhou\"},{\"authorId\":\"151481257\",\"name\":\"Zhong-Qiu Zhao\"}],\"doi\":\"10.1109/IJCNN48605.2020.9207390\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0ff3ccd867a94b77f519e73cf2de9772aa8ae905\",\"title\":\"Cascading Top-Down Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0ff3ccd867a94b77f519e73cf2de9772aa8ae905\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":\"2004.03661\",\"authors\":[{\"authorId\":\"50535497\",\"name\":\"Jiahong Huang\"},{\"authorId\":\"1717056\",\"name\":\"M. Worring\"}],\"doi\":\"10.1145/3372278.3390695\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9e7b49b1b50b57fdb5f68c9185edee1978569474\",\"title\":\"Query-controllable Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/9e7b49b1b50b57fdb5f68c9185edee1978569474\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"82849187\",\"name\":\"R. Beard\"},{\"authorId\":\"27408524\",\"name\":\"R. Das\"},{\"authorId\":\"2394130\",\"name\":\"Raymond W. M. Ng\"},{\"authorId\":\"144775910\",\"name\":\"P. Gopalakrishnan\"},{\"authorId\":\"51504808\",\"name\":\"Luka Eerens\"},{\"authorId\":\"3127347\",\"name\":\"P. Swietojanski\"},{\"authorId\":\"3336488\",\"name\":\"O. Miksik\"}],\"doi\":\"10.18653/v1/K18-1025\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6240321ad0632b39ba07d3e65ccdbee8c25c8b0a\",\"title\":\"Multi-Modal Sequence Fusion via Recursive Attention for Emotion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6240321ad0632b39ba07d3e65ccdbee8c25c8b0a\",\"venue\":\"CoNLL\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1711219\",\"name\":\"Juzheng Li\"},{\"authorId\":\"144904238\",\"name\":\"H. Su\"},{\"authorId\":\"145254043\",\"name\":\"J. Zhu\"},{\"authorId\":\"49846744\",\"name\":\"Bo Zhang\"}],\"doi\":\"10.1109/ICME.2018.8486468\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c1655b32a30165f7863ece52c54270662a28be0e\",\"title\":\"Essay-Anchor Attentive Multi-Modal Bilinear Pooling for Textbook Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/c1655b32a30165f7863ece52c54270662a28be0e\",\"venue\":\"2018 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2018},{\"arxivId\":\"1802.00209\",\"authors\":[{\"authorId\":\"143757036\",\"name\":\"Ahmed Osman\"},{\"authorId\":\"1699054\",\"name\":\"W. Samek\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"7b66dababebd800e95d23a1fde299d44a52e98ed\",\"title\":\"Dual Recurrent Attention Units for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7b66dababebd800e95d23a1fde299d44a52e98ed\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1806.08279\",\"authors\":[{\"authorId\":\"47327595\",\"name\":\"A. Dey\"},{\"authorId\":\"39937691\",\"name\":\"S. Ghosh\"},{\"authorId\":\"2864362\",\"name\":\"Ernest Valveny\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8688e71710e9682d1e6594db6ca99717ae743074\",\"title\":\"Don't only Feel Read: Using Scene text to understand advertisements\",\"url\":\"https://www.semanticscholar.org/paper/8688e71710e9682d1e6594db6ca99717ae743074\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2010.01725\",\"authors\":[{\"authorId\":\"6328564\",\"name\":\"M. Farazi\"},{\"authorId\":\"1859082176\",\"name\":\"Salman Khan\"},{\"authorId\":\"1712576\",\"name\":\"N. Barnes\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4e5ffb9d473b195a9f0f159dca8bdbebce531ff6\",\"title\":\"Attention Guided Semantic Relationship Parsing for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/4e5ffb9d473b195a9f0f159dca8bdbebce531ff6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.00145\",\"authors\":[{\"authorId\":\"119883573\",\"name\":\"J. Yu\"},{\"authorId\":\"49659134\",\"name\":\"Zihao Zhu\"},{\"authorId\":null,\"name\":\"Yujing Wang\"},{\"authorId\":\"1735739\",\"name\":\"Weifeng Zhang\"},{\"authorId\":\"1581498565\",\"name\":\"Yue Hu\"},{\"authorId\":\"2573626\",\"name\":\"Jianlong Tan\"}],\"doi\":\"10.1016/j.patcog.2020.107563\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e526624783b3b5687da54b8cd4a7190a26a0b5e8\",\"title\":\"Cross-modal Knowledge Reasoning for Knowledge-based Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e526624783b3b5687da54b8cd4a7190a26a0b5e8\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":\"2012.07192\",\"authors\":[{\"authorId\":\"2826839\",\"name\":\"Qingxing Cao\"},{\"authorId\":\"51473867\",\"name\":\"Bailin Li\"},{\"authorId\":\"13246332\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"3170394\",\"name\":\"Keze Wang\"},{\"authorId\":\"1737218\",\"name\":\"L. Lin\"}],\"doi\":\"10.1109/TNNLS.2020.3045034\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e452c1aa68173d6a1d3aefd9f08f70e43b0c59f4\",\"title\":\"Knowledge-Routed Visual Question Reasoning: Challenges for Deep Representation Embedding\",\"url\":\"https://www.semanticscholar.org/paper/e452c1aa68173d6a1d3aefd9f08f70e43b0c59f4\",\"venue\":\"IEEE transactions on neural networks and learning systems\",\"year\":2021},{\"arxivId\":\"1908.06954\",\"authors\":[{\"authorId\":\"48544896\",\"name\":\"Lun Huang\"},{\"authorId\":\"46315174\",\"name\":\"Wenmin Wang\"},{\"authorId\":\"40445654\",\"name\":\"J. Chen\"},{\"authorId\":\"144539992\",\"name\":\"Xiao-Yong Wei\"}],\"doi\":\"10.1109/ICCV.2019.00473\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4c163d4942117179d3e97182e1b280027d7d60a9\",\"title\":\"Attention on Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/4c163d4942117179d3e97182e1b280027d7d60a9\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145097076\",\"name\":\"Minh H. Vu\"},{\"authorId\":\"1824404\",\"name\":\"Raphael Sznitman\"},{\"authorId\":\"3853327\",\"name\":\"T. Nyholm\"},{\"authorId\":\"40136362\",\"name\":\"T. L\\u00f6fstedt\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"e21d085735aef50dd784706aca173b7b0bd84eed\",\"title\":\"Ensemble of Streamlined Bilinear Visual Question Answering Models for the ImageCLEF 2019 Challenge in the Medical Domain\",\"url\":\"https://www.semanticscholar.org/paper/e21d085735aef50dd784706aca173b7b0bd84eed\",\"venue\":\"CLEF\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1514929766\",\"name\":\"Chongqing Chen\"},{\"authorId\":\"1840771\",\"name\":\"D. Han\"},{\"authorId\":\"71563119\",\"name\":\"Jun Wang\"}],\"doi\":\"10.1109/ACCESS.2020.2975093\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e75fa8852f5a4779cfdf2f22bd87e213f57b2d20\",\"title\":\"Multimodal Encoder-Decoder Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e75fa8852f5a4779cfdf2f22bd87e213f57b2d20\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1910.14671\",\"authors\":[{\"authorId\":\"9852531\",\"name\":\"J. Lin\"},{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1743587c272c36dbda0adc50496bf7f34b8148f1\",\"title\":\"TAB-VCR: Tags and Attributes based Visual Commonsense Reasoning Baselines\",\"url\":\"https://www.semanticscholar.org/paper/1743587c272c36dbda0adc50496bf7f34b8148f1\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1921879239\",\"name\":\"Shirong He\"},{\"authorId\":\"9100598\",\"name\":\"Dezhi Han\"}],\"doi\":\"10.3390/s20174897\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e52cae3e1df7ef76854645abf250db9282d01f27\",\"title\":\"An Effective Dense Co-Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e52cae3e1df7ef76854645abf250db9282d01f27\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"1803.09374\",\"authors\":[{\"authorId\":\"40807486\",\"name\":\"Brendan Duke\"},{\"authorId\":\"144639556\",\"name\":\"Graham W. Taylor\"}],\"doi\":\"10.1109/CRV.2018.00016\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"3d83aa3f1ed743d80b472a660102cb0ce21622ab\",\"title\":\"Generalized Hadamard-Product Fusion Operators for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/3d83aa3f1ed743d80b472a660102cb0ce21622ab\",\"venue\":\"2018 15th Conference on Computer and Robot Vision (CRV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144544920\",\"name\":\"Fei Liu\"},{\"authorId\":\"1749850\",\"name\":\"J. Liu\"},{\"authorId\":\"49597404\",\"name\":\"Z. Fang\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1109/ICIP.2019.8803670\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cd71651126f11162d262ff0dcb9ae094f51dcffd\",\"title\":\"Language and Visual Relations Encoding for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/cd71651126f11162d262ff0dcb9ae094f51dcffd\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"1908.04107\",\"authors\":[{\"authorId\":\"23165772\",\"name\":\"Z. Yu\"},{\"authorId\":\"30513139\",\"name\":\"Yuhao Cui\"},{\"authorId\":\"97583812\",\"name\":\"J. Yu\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a3d3df29fc98e0d674bf02bab69726795f4c7b78\",\"title\":\"Multimodal Unified Attention Networks for Vision-and-Language Interactions\",\"url\":\"https://www.semanticscholar.org/paper/a3d3df29fc98e0d674bf02bab69726795f4c7b78\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1709.04625\",\"authors\":[{\"authorId\":\"2973866\",\"name\":\"J. Huang\"},{\"authorId\":\"9951160\",\"name\":\"Modar Alfadly\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"28853de59af8560dca5ff83f68f5af1cec0493d9\",\"title\":\"Robustness Analysis of Visual QA Models by Basic Questions\",\"url\":\"https://www.semanticscholar.org/paper/28853de59af8560dca5ff83f68f5af1cec0493d9\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"2010.12917\",\"authors\":[{\"authorId\":\"3442255\",\"name\":\"Zan-Xia Jin\"},{\"authorId\":\"2003456770\",\"name\":\"Heran Wu\"},{\"authorId\":\"46962194\",\"name\":\"C. Yang\"},{\"authorId\":\"31679477\",\"name\":\"Fang Zhou\"},{\"authorId\":\"2005306\",\"name\":\"Jingyan Qin\"},{\"authorId\":\"145628818\",\"name\":\"Lei Xiao\"},{\"authorId\":\"120644708\",\"name\":\"XuCheng Yin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d209f0d94492447713541b28373d9b6cad5edeb9\",\"title\":\"RUArt: A Novel Text-Centered Solution for Text-Based Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d209f0d94492447713541b28373d9b6cad5edeb9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49597404\",\"name\":\"Z. Fang\"},{\"authorId\":null,\"name\":\"Jing Liu\"},{\"authorId\":\"80526284\",\"name\":\"Yanyuan Qiao\"},{\"authorId\":null,\"name\":\"Qu Tang\"},{\"authorId\":\"47002702\",\"name\":\"Y. Li\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1145/3240508.3240662\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a1f1a06b840558c4433f0e06a4e9172539469e21\",\"title\":\"Enhancing Visual Question Answering Using Dropout\",\"url\":\"https://www.semanticscholar.org/paper/a1f1a06b840558c4433f0e06a4e9172539469e21\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1904.06455\",\"authors\":[{\"authorId\":\"3427387\",\"name\":\"Dimitris G. Chachlakis\"},{\"authorId\":\"1410514417\",\"name\":\"Ashley Prater-Bennette\"},{\"authorId\":\"3037770\",\"name\":\"P. Markopoulos\"}],\"doi\":\"10.1109/ACCESS.2019.2955134\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d1ebd42f7f78ea0aa571641e0c308874add1ec46\",\"title\":\"L1-Norm Tucker Tensor Decomposition\",\"url\":\"https://www.semanticscholar.org/paper/d1ebd42f7f78ea0aa571641e0c308874add1ec46\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152673712\",\"name\":\"Youming Gao\"},{\"authorId\":\"144602988\",\"name\":\"Yi Ji\"},{\"authorId\":\"47362529\",\"name\":\"T. Xu\"},{\"authorId\":\"1965723\",\"name\":\"Y. Xu\"},{\"authorId\":\"6681872\",\"name\":\"Chunping Liu\"}],\"doi\":\"10.1007/978-3-030-30508-6_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"accdbb3b851357e4bc412442ddaf43945a60eb4b\",\"title\":\"Referring Expression Comprehension via Co-attention and Visual Context\",\"url\":\"https://www.semanticscholar.org/paper/accdbb3b851357e4bc412442ddaf43945a60eb4b\",\"venue\":\"ICANN\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8599825\",\"name\":\"Jonatas Wehrmann\"},{\"authorId\":\"143914916\",\"name\":\"Rodrigo C. Barros\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e1371af87f6d5e22ef6d8c5f9977f5e924f176f6\",\"title\":\"Bidirectional Retrieval Made Simple J\\u00f4natas Wehrmann\",\"url\":\"https://www.semanticscholar.org/paper/e1371af87f6d5e22ef6d8c5f9977f5e924f176f6\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1904.08324\",\"authors\":[{\"authorId\":\"66599917\",\"name\":\"Yanze Wu\"},{\"authorId\":\"145268319\",\"name\":\"Q. Sun\"},{\"authorId\":\"3493380\",\"name\":\"Jianqi Ma\"},{\"authorId\":\"49729707\",\"name\":\"B. Li\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"145589539\",\"name\":\"Y. Peng\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"914c3045b4e140a93eace23eded09317072d3f42\",\"title\":\"Question Guided Modular Routing Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/914c3045b4e140a93eace23eded09317072d3f42\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1708.02711\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2018.00444\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b14a60a1c3e6bb45baddd754a1cfe83ffc1bbb81\",\"title\":\"Tips and Tricks for Visual Question Answering: Learnings from the 2017 Challenge\",\"url\":\"https://www.semanticscholar.org/paper/b14a60a1c3e6bb45baddd754a1cfe83ffc1bbb81\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1811.11422\",\"authors\":[{\"authorId\":\"27743961\",\"name\":\"Dimitris Gkoumas\"},{\"authorId\":\"48437245\",\"name\":\"D. Song\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8841e2d08b1154cf7e1a187166ed57a1adc80724\",\"title\":\"Exploiting \\\"Quantum-like Interference\\\" in Decision Fusion for Ranking Multimodal Documents\",\"url\":\"https://www.semanticscholar.org/paper/8841e2d08b1154cf7e1a187166ed57a1adc80724\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2010.00514\",\"authors\":[{\"authorId\":\"15633953\",\"name\":\"Shaofei Huang\"},{\"authorId\":\"151475424\",\"name\":\"Tianrui Hui\"},{\"authorId\":\"101219260\",\"name\":\"Si Liu\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"49020088\",\"name\":\"Yunchao Wei\"},{\"authorId\":\"150147352\",\"name\":\"Jizhong Han\"},{\"authorId\":\"1776665\",\"name\":\"Luoqi Liu\"},{\"authorId\":\"143771567\",\"name\":\"Bo Li\"}],\"doi\":\"10.1109/CVPR42600.2020.01050\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"66566337664bee69915d3a46e0c5b66b15a8f5b5\",\"title\":\"Referring Image Segmentation via Cross-Modal Progressive Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/66566337664bee69915d3a46e0c5b66b15a8f5b5\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8599825\",\"name\":\"Jonatas Wehrmann\"},{\"authorId\":\"143914916\",\"name\":\"Rodrigo C. Barros\"}],\"doi\":\"10.1109/CVPR.2018.00805\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"083551c35be43aa3f0cc45408c09ec46b7a239ea\",\"title\":\"Bidirectional Retrieval Made Simple\",\"url\":\"https://www.semanticscholar.org/paper/083551c35be43aa3f0cc45408c09ec46b7a239ea\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1908.04011\",\"authors\":[{\"authorId\":\"134814700\",\"name\":\"T. Wang\"},{\"authorId\":\"1390532590\",\"name\":\"Xing Xu\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":\"1718099\",\"name\":\"A. Hanjalic\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"}],\"doi\":\"10.1145/3343031.3350875\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b4e1be8dd4d303e8e8ffe4343b2200d7952d16c4\",\"title\":\"Matching Images and Text with Multi-modal Tensor Fusion and Re-ranking\",\"url\":\"https://www.semanticscholar.org/paper/b4e1be8dd4d303e8e8ffe4343b2200d7952d16c4\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48352212\",\"name\":\"Aming Wu\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"},{\"authorId\":\"20332986\",\"name\":\"Q. Hu\"},{\"authorId\":\"144894837\",\"name\":\"F. Wu\"}],\"doi\":\"10.1109/TCSVT.2019.2956593\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"230a8581672b3147238eaab2cf686c70fe4f672b\",\"title\":\"Convolutional Reconstruction-to-Sequence for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/230a8581672b3147238eaab2cf686c70fe4f672b\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"1909.04800\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"1380338049\",\"name\":\"Anupriy\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":\"10.1016/j.patcog.2020.107586\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e281d8af3ec87fd893743afd6fb9d5ec3eaca924\",\"title\":\"Probabilistic framework for solving Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/e281d8af3ec87fd893743afd6fb9d5ec3eaca924\",\"venue\":\"Pattern Recognit.\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143757036\",\"name\":\"Ahmed Osman\"},{\"authorId\":\"1699054\",\"name\":\"W. Samek\"}],\"doi\":\"10.1016/j.cviu.2019.05.001\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"cb32b338023f9deb1eb2fb89d33784e12bdb5653\",\"title\":\"DRAU: Dual Recurrent Attention Units for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/cb32b338023f9deb1eb2fb89d33784e12bdb5653\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2019},{\"arxivId\":\"1911.03977\",\"authors\":[{\"authorId\":\"145282222\",\"name\":\"C. Zhang\"},{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"144718783\",\"name\":\"Li Deng\"}],\"doi\":\"10.1109/JSTSP.2020.2987728\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"415efb7b4d9d1e5b64dbaf3fe4229ad462acce71\",\"title\":\"Multimodal Intelligence: Representation Learning, Information Fusion, and Applications\",\"url\":\"https://www.semanticscholar.org/paper/415efb7b4d9d1e5b64dbaf3fe4229ad462acce71\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020},{\"arxivId\":\"1707.00683\",\"authors\":[{\"authorId\":\"153559313\",\"name\":\"H. D. Vries\"},{\"authorId\":\"3367628\",\"name\":\"Florian Strub\"},{\"authorId\":\"143716734\",\"name\":\"J. Mary\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1721354\",\"name\":\"Olivier Pietquin\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"feeb3a2aa35a02e06546d05d94bac9a2123fc0c8\",\"title\":\"Modulating early visual processing by language\",\"url\":\"https://www.semanticscholar.org/paper/feeb3a2aa35a02e06546d05d94bac9a2123fc0c8\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1709.07192\",\"authors\":[{\"authorId\":\"2180892\",\"name\":\"Yikang Li\"},{\"authorId\":\"46429989\",\"name\":\"N. Duan\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"47353404\",\"name\":\"X. Chu\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"}],\"doi\":\"10.1109/CVPR.2018.00640\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"47aff6477f05ec32fc163e1943fe9464a8379552\",\"title\":\"Visual Question Generation as Dual Task of Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/47aff6477f05ec32fc163e1943fe9464a8379552\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9852531\",\"name\":\"J. Lin\"},{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eefddfa610243968135726f9fddf4f69696863ed\",\"title\":\"TAB-VCR: Tags and Attributes based VCR Baselines\",\"url\":\"https://www.semanticscholar.org/paper/eefddfa610243968135726f9fddf4f69696863ed\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1476764875\",\"name\":\"Yatong Sun\"},{\"authorId\":\"38896551\",\"name\":\"G. Guo\"},{\"authorId\":\"7791865\",\"name\":\"X. He\"},{\"authorId\":\"49543292\",\"name\":\"X. Liu\"}],\"doi\":\"10.1109/ACCESS.2019.2961182\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c0e3c1f5bd2a70c0f2d4ca7ce9acdde0799426a2\",\"title\":\"Multi-Level Coupling Network for Non-IID Sequential Recommendation\",\"url\":\"https://www.semanticscholar.org/paper/c0e3c1f5bd2a70c0f2d4ca7ce9acdde0799426a2\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"14320047\",\"name\":\"C. Patil\"},{\"authorId\":\"34326205\",\"name\":\"Manasi S. Patwardhan\"}],\"doi\":\"10.1145/3383465\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"9e081431cfbab4d5c8823efa2620ca0accfa124e\",\"title\":\"Visual Question Generation\",\"url\":\"https://www.semanticscholar.org/paper/9e081431cfbab4d5c8823efa2620ca0accfa124e\",\"venue\":\"ACM Comput. Surv.\",\"year\":2020},{\"arxivId\":\"2002.05104\",\"authors\":[{\"authorId\":\"1396871443\",\"name\":\"Camila Kolling\"},{\"authorId\":\"8599825\",\"name\":\"Jonatas Wehrmann\"},{\"authorId\":\"1380051745\",\"name\":\"Rodrigo C. Barros\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206679\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e4bd198ec47697ed1442af0babd35b88451fd205\",\"title\":\"Component Analysis for Visual Question Answering Architectures\",\"url\":\"https://www.semanticscholar.org/paper/e4bd198ec47697ed1442af0babd35b88451fd205\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1915796\",\"name\":\"Junwei Liang\"},{\"authorId\":\"39978626\",\"name\":\"Lu Jiang\"},{\"authorId\":\"48749954\",\"name\":\"L. Cao\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1109/CVPR.2018.00642\",\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"72c16ae6969eda304f76af139e000e4cec34d564\",\"title\":\"Focal Visual-Text Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/72c16ae6969eda304f76af139e000e4cec34d564\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1912.01452\",\"authors\":[{\"authorId\":\"50535497\",\"name\":\"Jiahong Huang\"},{\"authorId\":\"9951160\",\"name\":\"Modar Alfadly\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"1717056\",\"name\":\"M. Worring\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"01aa5668a618fbb376b6ab6608defc074ed355ac\",\"title\":\"Assessing the Robustness of Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/01aa5668a618fbb376b6ab6608defc074ed355ac\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1809.01810\",\"authors\":[{\"authorId\":\"2826839\",\"name\":\"Qingxing Cao\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"46708631\",\"name\":\"Bailin Li\"},{\"authorId\":\"1737218\",\"name\":\"L. Lin\"}],\"doi\":\"10.1109/tpami.2019.2943456\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"97b93509f6c3c33dd3665d05b1878e36d58a1efb\",\"title\":\"Interpretable Visual Question Answering by Reasoning on Dependency Trees\",\"url\":\"https://www.semanticscholar.org/paper/97b93509f6c3c33dd3665d05b1878e36d58a1efb\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2019},{\"arxivId\":\"2004.04963\",\"authors\":[{\"authorId\":\"1576818877\",\"name\":\"Kento Terao\"},{\"authorId\":\"47668008\",\"name\":\"T. Tamaki\"},{\"authorId\":\"1688940\",\"name\":\"B. Raytchev\"},{\"authorId\":\"1686272\",\"name\":\"K. Kaneda\"},{\"authorId\":\"49969107\",\"name\":\"S. Satoh\"}],\"doi\":\"10.1587/transinf.2020EDP7089\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d44be3e1158eb1b04e311479b17c0ff6f3fc06ab\",\"title\":\"Rephrasing visual questions by specifying the entropy of the answer distribution\",\"url\":\"https://www.semanticscholar.org/paper/d44be3e1158eb1b04e311479b17c0ff6f3fc06ab\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.09073\",\"authors\":[{\"authorId\":\"49659134\",\"name\":\"Zihao Zhu\"},{\"authorId\":\"119883573\",\"name\":\"J. Yu\"},{\"authorId\":\"46394401\",\"name\":\"Yujing Wang\"},{\"authorId\":\"15087270\",\"name\":\"Yajing Sun\"},{\"authorId\":\"1581498565\",\"name\":\"Yue Hu\"},{\"authorId\":\"1509240145\",\"name\":\"Qi Wu\"}],\"doi\":\"10.24963/ijcai.2020/153\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6b13065b4050800e30bb74e010b8aaba3355525d\",\"title\":\"Mucko: Multi-Layer Cross-Modal Knowledge Reasoning for Fact-based Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/6b13065b4050800e30bb74e010b8aaba3355525d\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":\"1909.07583\",\"authors\":[{\"authorId\":\"1388780256\",\"name\":\"Yaser Alwatter\"},{\"authorId\":\"1798719\",\"name\":\"Yuhong Guo\"}],\"doi\":\"10.22215/etd/2019-13929\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"48795928eb87d1e8a038063b3aebee180e424d04\",\"title\":\"Inverse Visual Question Answering with Multi-Level Attentions\",\"url\":\"https://www.semanticscholar.org/paper/48795928eb87d1e8a038063b3aebee180e424d04\",\"venue\":\"ACML\",\"year\":2020},{\"arxivId\":\"1804.00105\",\"authors\":[{\"authorId\":\"2826839\",\"name\":\"Qingxing Cao\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"46708223\",\"name\":\"B. Li\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"1737218\",\"name\":\"L. Lin\"}],\"doi\":\"10.1109/CVPR.2018.00757\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eff328e0ecfb9a7a2d6664ee38aa32a61c7b9f42\",\"title\":\"Visual Question Reasoning on General Dependency Tree\",\"url\":\"https://www.semanticscholar.org/paper/eff328e0ecfb9a7a2d6664ee38aa32a61c7b9f42\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143957784\",\"name\":\"M. Iqbal\"},{\"authorId\":\"119339025\",\"name\":\"H. Chowdhury\"},{\"authorId\":\"145025159\",\"name\":\"K. Nguyen\"},{\"authorId\":\"3140440\",\"name\":\"C. Fookes\"},{\"authorId\":\"1729760\",\"name\":\"S. Sridharan\"}],\"doi\":\"10.36227/techrxiv.12731948\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"182cff43865499c081c2ea9c441605ae6670ad5e\",\"title\":\"VISUAL QUESTION ANSWERING THROUGH ADVERSARIAL LEARNING OF MULTI-MODAL REPRESENTATION\",\"url\":\"https://www.semanticscholar.org/paper/182cff43865499c081c2ea9c441605ae6670ad5e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1902.00038\",\"authors\":[{\"authorId\":\"1405301761\",\"name\":\"Hedi Ben-younes\"},{\"authorId\":\"7535126\",\"name\":\"R\\u00e9mi Cad\\u00e8ne\"},{\"authorId\":\"1728523\",\"name\":\"N. Thome\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"}],\"doi\":\"10.1609/aaai.v33i01.33018102\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a154867c7b45456abb14708a7bbc9c849aeecf4f\",\"title\":\"BLOCK: Bilinear Superdiagonal Fusion for Visual Question Answering and Visual Relationship Detection\",\"url\":\"https://www.semanticscholar.org/paper/a154867c7b45456abb14708a7bbc9c849aeecf4f\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1908.07129\",\"authors\":[{\"authorId\":\"152229386\",\"name\":\"Arka Sadhu\"},{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"66449153\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/ICCV.2019.00479\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"666d9a766de11c22d9fd7d8e3c36a80ecd6f0bd0\",\"title\":\"Zero-Shot Grounding of Objects From Natural Language Queries\",\"url\":\"https://www.semanticscholar.org/paper/666d9a766de11c22d9fd7d8e3c36a80ecd6f0bd0\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2932516\",\"name\":\"J. Zhang\"}],\"doi\":\"10.7282/T3-KA2Q-B984\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7b198f5cb09446433a8d3a181107f408d26d5a34\",\"title\":\"Scene graph parsing and its application in cross-modal reasoning tasks\",\"url\":\"https://www.semanticscholar.org/paper/7b198f5cb09446433a8d3a181107f408d26d5a34\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2007.06198\",\"authors\":[{\"authorId\":\"9748140\",\"name\":\"K. Gouthaman\"},{\"authorId\":\"50853059\",\"name\":\"Anurag Mittal\"}],\"doi\":\"10.1007/978-3-030-58601-0_2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"06b869a92a22db711e4fbe8b141c83523c7c4604\",\"title\":\"Reducing Language Biases in Visual Question Answering with Visually-Grounded Question Encoder\",\"url\":\"https://www.semanticscholar.org/paper/06b869a92a22db711e4fbe8b141c83523c7c4604\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1865719481\",\"name\":\"Deepak Gupta\"},{\"authorId\":\"27563697\",\"name\":\"Pabitra Lenka\"},{\"authorId\":\"1734904\",\"name\":\"Asif Ekbal\"},{\"authorId\":\"145532184\",\"name\":\"P. Bhattacharyya\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6ba2a128dd8dadc2925b3b9c01fb6db01bd75066\",\"title\":\"A Unified Framework for Multilingual and Code-Mixed Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/6ba2a128dd8dadc2925b3b9c01fb6db01bd75066\",\"venue\":\"AACL/IJCNLP\",\"year\":2020},{\"arxivId\":\"1806.01873\",\"authors\":[{\"authorId\":\"1915796\",\"name\":\"Junwei Liang\"},{\"authorId\":\"39978626\",\"name\":\"Lu Jiang\"},{\"authorId\":\"48749954\",\"name\":\"L. Cao\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1109/TPAMI.2018.2890628\",\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"aee265f6a19f9774c65d296cf9ec0e169365dda5\",\"title\":\"Focal Visual-Text Attention for Memex Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/aee265f6a19f9774c65d296cf9ec0e169365dda5\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2712862\",\"name\":\"D. Zhang\"},{\"authorId\":\"145690873\",\"name\":\"R. Cao\"},{\"authorId\":\"1765710\",\"name\":\"Sai Wu\"}],\"doi\":\"10.1016/J.INFFUS.2019.03.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"91118408f8192c2addade2a0401a32c3bbd47818\",\"title\":\"Information fusion in visual question answering: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/91118408f8192c2addade2a0401a32c3bbd47818\",\"venue\":\"Inf. Fusion\",\"year\":2019},{\"arxivId\":\"1805.05492\",\"authors\":[{\"authorId\":\"2235894\",\"name\":\"Pramod Kaushik Mudrakarta\"},{\"authorId\":\"40511120\",\"name\":\"Ankur Taly\"},{\"authorId\":\"30740726\",\"name\":\"M. Sundararajan\"},{\"authorId\":\"1696833\",\"name\":\"K. Dhamdhere\"}],\"doi\":\"10.18653/v1/P18-1176\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4a9831e5fec549edee454709048a51997ef60fb7\",\"title\":\"Did the Model Understand the Question?\",\"url\":\"https://www.semanticscholar.org/paper/4a9831e5fec549edee454709048a51997ef60fb7\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":\"2001.07059\",\"authors\":[{\"authorId\":\"6328564\",\"name\":\"M. Farazi\"},{\"authorId\":\"1931655\",\"name\":\"S. Khan\"},{\"authorId\":\"1712576\",\"name\":\"N. Barnes\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8527a2f65eaaf0c96b2ac9430185b0e12d8973a9\",\"title\":\"Accuracy vs. Complexity: A Trade-off in Visual Question Answering Models\",\"url\":\"https://www.semanticscholar.org/paper/8527a2f65eaaf0c96b2ac9430185b0e12d8973a9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1824096\",\"name\":\"M. Ziaeefard\"},{\"authorId\":\"1863173\",\"name\":\"F. L\\u00e9cu\\u00e9\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"019227992f2e3d0a93332e4107765d8efd2976be\",\"title\":\"Towards Knowledge-Augmented Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/019227992f2e3d0a93332e4107765d8efd2976be\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"113254351\",\"name\":\"Jin Ye\"},{\"authorId\":\"51003139\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"36234262\",\"name\":\"H. Xing\"},{\"authorId\":\"47786409\",\"name\":\"Junli Li\"},{\"authorId\":\"145592288\",\"name\":\"Rongrong Ji\"}],\"doi\":\"10.1109/ICIP.2019.8802992\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b66829b0356e7f1669b05435e4fb886eb1080537\",\"title\":\"Visual-Textual Sentiment Analysis in Product Reviews\",\"url\":\"https://www.semanticscholar.org/paper/b66829b0356e7f1669b05435e4fb886eb1080537\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"1809.04344\",\"authors\":[{\"authorId\":\"51228129\",\"name\":\"Shailza Jolly\"},{\"authorId\":\"3422247\",\"name\":\"Sandro Pezzelle\"},{\"authorId\":\"35660331\",\"name\":\"T. Klein\"},{\"authorId\":\"145279674\",\"name\":\"A. Dengel\"},{\"authorId\":\"1848946\",\"name\":\"Moin Nabi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"610e0bee525a6573932e077f091505f54a5c4ede\",\"title\":\"The Wisdom of MaSSeS: Majority, Subjectivity, and Semantic Similarity in the Evaluation of VQA\",\"url\":\"https://www.semanticscholar.org/paper/610e0bee525a6573932e077f091505f54a5c4ede\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2006.10021\",\"authors\":[{\"authorId\":\"46201245\",\"name\":\"Daniele Castellana\"},{\"authorId\":\"3224102\",\"name\":\"D. Bacciu\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206597\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"92411d2e88ef29f4995896e95febc807a3dfc0f3\",\"title\":\"Generalising Recursive Neural Models by Tensor Decomposition\",\"url\":\"https://www.semanticscholar.org/paper/92411d2e88ef29f4995896e95febc807a3dfc0f3\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"20525031\",\"name\":\"Taylor Mordan\"},{\"authorId\":\"1728523\",\"name\":\"N. Thome\"},{\"authorId\":\"2386962\",\"name\":\"Gilles H\\u00e9naff\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"}],\"doi\":\"10.1007/s11263-018-1109-z\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fdfcf08eb7e0c46faf4c239d30d0c408a9aeb6cb\",\"title\":\"End-to-End Learning of Latent Deformable Part-Based Representations for Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/fdfcf08eb7e0c46faf4c239d30d0c408a9aeb6cb\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47158869\",\"name\":\"Xing Xu\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"143663452\",\"name\":\"Huimin Lu\"},{\"authorId\":\"144780837\",\"name\":\"Li He\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":\"144618699\",\"name\":\"F. Shen\"}],\"doi\":\"10.1109/ICME.2018.8486475\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d353b30b9ca3124fad08e3bdc8167dfe994efb34\",\"title\":\"Dual Learning for Visual Question Generation\",\"url\":\"https://www.semanticscholar.org/paper/d353b30b9ca3124fad08e3bdc8167dfe994efb34\",\"venue\":\"2018 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8889792\",\"name\":\"Jihun Choi\"},{\"authorId\":\"5041757\",\"name\":\"Taeuk Kim\"},{\"authorId\":\"1734101\",\"name\":\"S. Lee\"}],\"doi\":\"10.18653/v1/S18-2012\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cb94ea16f12bde2de91d3cf3fac03a20b02611b1\",\"title\":\"Element-wise Bilinear Interaction for Sentence Matching\",\"url\":\"https://www.semanticscholar.org/paper/cb94ea16f12bde2de91d3cf3fac03a20b02611b1\",\"venue\":\"*SEM@NAACL-HLT\",\"year\":2018},{\"arxivId\":\"1905.05279\",\"authors\":[{\"authorId\":\"51346567\",\"name\":\"A. Pokle\"},{\"authorId\":\"1382655067\",\"name\":\"Roberto Mart\\u00edn-Mart\\u00edn\"},{\"authorId\":\"144368914\",\"name\":\"P. Goebel\"},{\"authorId\":\"144267910\",\"name\":\"V. Chow\"},{\"authorId\":\"40603515\",\"name\":\"H. Ewald\"},{\"authorId\":\"49499463\",\"name\":\"Junwei Yang\"},{\"authorId\":\"50218446\",\"name\":\"Zhenkai Wang\"},{\"authorId\":\"145759966\",\"name\":\"Amir Sadeghian\"},{\"authorId\":\"1779671\",\"name\":\"D. Sadigh\"},{\"authorId\":\"1702137\",\"name\":\"S. Savarese\"},{\"authorId\":\"144168587\",\"name\":\"M. V\\u00e1zquez\"}],\"doi\":\"10.1109/ICRA.2019.8794062\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6350a4ab11ee904389f7fc3ffcfb48a2b0613bff\",\"title\":\"Deep Local Trajectory Replanning and Control for Robot Navigation\",\"url\":\"https://www.semanticscholar.org/paper/6350a4ab11ee904389f7fc3ffcfb48a2b0613bff\",\"venue\":\"2019 International Conference on Robotics and Automation (ICRA)\",\"year\":2019},{\"arxivId\":\"1711.06370\",\"authors\":[{\"authorId\":\"3194022\",\"name\":\"Bohan Zhuang\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2018.00447\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7299465d70181e423480fdb252aa2e28c18aa012\",\"title\":\"Parallel Attention: A Unified Framework for Visual Object Discovery Through Dialogs and Queries\",\"url\":\"https://www.semanticscholar.org/paper/7299465d70181e423480fdb252aa2e28c18aa012\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48079662\",\"name\":\"Sungho Park\"},{\"authorId\":\"145864562\",\"name\":\"Sunhee Hwang\"},{\"authorId\":\"9024867\",\"name\":\"Jongkwang Hong\"},{\"authorId\":\"1703310\",\"name\":\"Hyeran Byun\"}],\"doi\":\"10.1109/ACCESS.2020.3041503\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"958284df0d0eca1b9cb234411aa15940c99e7ce6\",\"title\":\"Fair-VQA: Fairness-Aware Visual Question Answering Through Sensitive Attribute Prediction\",\"url\":\"https://www.semanticscholar.org/paper/958284df0d0eca1b9cb234411aa15940c99e7ce6\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152899351\",\"name\":\"X. Zhang\"},{\"authorId\":\"40485842\",\"name\":\"X. Sun\"},{\"authorId\":\"20637018\",\"name\":\"Chunjie Xie\"},{\"authorId\":\"1381365135\",\"name\":\"Bing Lun\"}],\"doi\":\"10.1109/ACCESS.2019.2933370\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"003ff75e4dbca1f2f87432399251c9d1d2a316c2\",\"title\":\"From Vision to Content: Construction of Domain-Specific Multi-Modal Knowledge Graph\",\"url\":\"https://www.semanticscholar.org/paper/003ff75e4dbca1f2f87432399251c9d1d2a316c2\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"2001.06354\",\"authors\":[{\"authorId\":\"51270689\",\"name\":\"Hyounghun Kim\"},{\"authorId\":\"47300698\",\"name\":\"Hao Tan\"},{\"authorId\":\"143977266\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.1609/AAAI.V34I05.6320\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0cad92e34323aa135d13d692c759246a8da54d05\",\"title\":\"Modality-Balanced Models for Visual Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/0cad92e34323aa135d13d692c759246a8da54d05\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2003.13962\",\"authors\":[{\"authorId\":\"2420608\",\"name\":\"Difei Gao\"},{\"authorId\":\"104106360\",\"name\":\"Ke Li\"},{\"authorId\":\"3373117\",\"name\":\"R. Wang\"},{\"authorId\":\"144481158\",\"name\":\"S. Shan\"},{\"authorId\":\"1710220\",\"name\":\"X. Chen\"}],\"doi\":\"10.1109/cvpr42600.2020.01276\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c9918cdf3c578fe18ea121b60b4b1961586e904f\",\"title\":\"Multi-Modal Graph Neural Network for Joint Reasoning on Vision and Scene Text\",\"url\":\"https://www.semanticscholar.org/paper/c9918cdf3c578fe18ea121b60b4b1961586e904f\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3427387\",\"name\":\"Dimitris G. Chachlakis\"},{\"authorId\":\"52212164\",\"name\":\"Mayur Dhanaraj\"},{\"authorId\":\"1410514417\",\"name\":\"Ashley Prater-Bennette\"},{\"authorId\":\"3037770\",\"name\":\"P. Markopoulos\"}],\"doi\":\"10.36227/techrxiv.12762392\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"281caa51f02e8db7c025b7627206e1a59ec45210\",\"title\":\"Dynamic L1-norm Tucker Tensor Decomposition\",\"url\":\"https://www.semanticscholar.org/paper/281caa51f02e8db7c025b7627206e1a59ec45210\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1905.06139\",\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"7896029\",\"name\":\"Yuanxin Liu\"},{\"authorId\":\"19169659\",\"name\":\"Xuancheng Ren\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"2511091\",\"name\":\"X. Sun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cc663416cbbd577ea02e8b4ef0ea201f5a12d608\",\"title\":\"Aligning Visual Regions and Textual Concepts for Semantic-Grounded Image Representations\",\"url\":\"https://www.semanticscholar.org/paper/cc663416cbbd577ea02e8b4ef0ea201f5a12d608\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48352212\",\"name\":\"Aming Wu\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a7501eb6d58b1f347140402171df7b3291496ab2\",\"title\":\"Connective Cognition Network for Directional Visual Commonsense Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/a7501eb6d58b1f347140402171df7b3291496ab2\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1811.10830\",\"authors\":[{\"authorId\":\"2545335\",\"name\":\"Rowan Zellers\"},{\"authorId\":\"3312309\",\"name\":\"Yonatan Bisk\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":\"10.1109/CVPR.2019.00688\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6dfc2ff03534a4325d06c6f88c3144831996629b\",\"title\":\"From Recognition to Cognition: Visual Commonsense Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/6dfc2ff03534a4325d06c6f88c3144831996629b\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1907.12133\",\"authors\":[{\"authorId\":\"50445724\",\"name\":\"C. Zhang\"},{\"authorId\":\"150336480\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"113737386\",\"name\":\"D. Xuan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"55a881988f757ff6fdac74429e39cb5b46aa3f47\",\"title\":\"An Empirical Study on Leveraging Scene Graphs for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/55a881988f757ff6fdac74429e39cb5b46aa3f47\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"1803.11186\",\"authors\":[{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1109/CVPR.2018.00603\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"36bb1983dceb84f33d9adcf4ef032c9b0aeed1e4\",\"title\":\"Two Can Play This Game: Visual Dialog with Discriminative Question Generation and Answering\",\"url\":\"https://www.semanticscholar.org/paper/36bb1983dceb84f33d9adcf4ef032c9b0aeed1e4\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2001.04732\",\"authors\":[{\"authorId\":\"51238351\",\"name\":\"Andr\\u00e9s Mafla\"},{\"authorId\":\"2166891\",\"name\":\"S. Dey\"},{\"authorId\":\"35570245\",\"name\":\"Ali Furkan Biten\"},{\"authorId\":\"51231577\",\"name\":\"Llu\\u00eds G\\u00f3mez\"},{\"authorId\":\"1694974\",\"name\":\"Dimosthenis Karatzas\"}],\"doi\":\"10.1109/WACV45572.2020.9093373\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"871f316cb02dcc4327adbbb363e8925d6f05e1d0\",\"title\":\"Fine-grained Image Classification and Retrieval by Combining Visual and Locally Pooled Textual Features\",\"url\":\"https://www.semanticscholar.org/paper/871f316cb02dcc4327adbbb363e8925d6f05e1d0\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1806.03726\",\"authors\":[{\"authorId\":\"38784892\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"}],\"doi\":\"10.1109/CVPR.2018.00599\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"1bfc74bad04b407d1792a70d73a3f5dc0be0506d\",\"title\":\"Cross-Dataset Adaptation for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1bfc74bad04b407d1792a70d73a3f5dc0be0506d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1935044135\",\"name\":\"Wenbo Zheng\"},{\"authorId\":\"1935044135\",\"name\":\"Wenbo Zheng\"},{\"authorId\":\"151486225\",\"name\":\"L. Yan\"},{\"authorId\":\"1491637173\",\"name\":\"Chao Gou\"},{\"authorId\":\"143754347\",\"name\":\"F. Wang\"}],\"doi\":\"10.1016/j.inffus.2020.10.007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"03a8f5098e8ffeed7a38f1ae8705f71b18d24e0e\",\"title\":\"KM4: Visual reasoning via Knowledge Embedding Memory Model with Mutual Modulation\",\"url\":\"https://www.semanticscholar.org/paper/03a8f5098e8ffeed7a38f1ae8705f71b18d24e0e\",\"venue\":\"\",\"year\":2021},{\"arxivId\":\"1811.08481\",\"authors\":[{\"authorId\":\"2909186\",\"name\":\"Ben Zion Vatashsky\"},{\"authorId\":\"1743045\",\"name\":\"S. Ullman\"}],\"doi\":\"10.1109/CVPR42600.2020.01039\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"66ccd32be901da217799c78af229676418c7a882\",\"title\":\"VQA With No Questions-Answers Training\",\"url\":\"https://www.semanticscholar.org/paper/66ccd32be901da217799c78af229676418c7a882\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144990548\",\"name\":\"Go Irie\"},{\"authorId\":\"9211474\",\"name\":\"M. O\\u0161trek\"},{\"authorId\":\"48017277\",\"name\":\"Haochen Wang\"},{\"authorId\":\"1787190\",\"name\":\"H. Kameoka\"},{\"authorId\":\"34454585\",\"name\":\"A. Kimura\"},{\"authorId\":\"1858824\",\"name\":\"Takahito Kawanishi\"},{\"authorId\":\"1718803\",\"name\":\"Kunio Kashino\"}],\"doi\":\"10.1109/ICASSP.2019.8683142\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"36170dadea3e9cdb5b3b422eb0264633e6fd1742\",\"title\":\"Seeing through Sounds: Predicting Visual Semantic Segmentation Results from Multichannel Audio Signals\",\"url\":\"https://www.semanticscholar.org/paper/36170dadea3e9cdb5b3b422eb0264633e6fd1742\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ffaa0cb4e257d4d6886bd65af5a46e3a7755f067\",\"title\":\"Supplementary Material Cycle-Consistency for Robust Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ffaa0cb4e257d4d6886bd65af5a46e3a7755f067\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9852531\",\"name\":\"J. Lin\"},{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1d660fdc8e7b23b5fa877a735744d1323a196cdb\",\"title\":\"A Simple Baseline for Visual Commonsense Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/1d660fdc8e7b23b5fa877a735744d1323a196cdb\",\"venue\":\"ViGIL@NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Pan Lu\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"2236084\",\"name\":\"Weitong Zhang\"},{\"authorId\":\"2447408\",\"name\":\"Jianyong Wang\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"7835f6e76e810445a38f76892c5dc58ee17efddb\",\"title\":\"Question : What is on the plate ? S of tm ax Linear Tanh ResNet Faster-RCNN GRU Linear Tanh\",\"url\":\"https://www.semanticscholar.org/paper/7835f6e76e810445a38f76892c5dc58ee17efddb\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c1693e1defad1cc8ec36b061add2afcd564013ff\",\"title\":\"Advancing Multi-Modal Deep Learning: Towards Language-Grounded Visual Understanding\",\"url\":\"https://www.semanticscholar.org/paper/c1693e1defad1cc8ec36b061add2afcd564013ff\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"73698428\",\"name\":\"Manan Shah\"},{\"authorId\":\"144494232\",\"name\":\"K. Viswanathan\"},{\"authorId\":\"2828701\",\"name\":\"Chun-Ta Lu\"},{\"authorId\":\"2326719\",\"name\":\"A. Fuxman\"},{\"authorId\":\"49969893\",\"name\":\"Z. Li\"},{\"authorId\":\"50408671\",\"name\":\"A. Timofeev\"},{\"authorId\":\"144711699\",\"name\":\"C. Jia\"},{\"authorId\":\"94567368\",\"name\":\"C. Sun\"}],\"doi\":\"10.1145/3357384.3357987\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eccff2a2fd7b99a4597ec4cb12895a99f1b036db\",\"title\":\"Inferring Context from Pixels for Multimodal Image Classification\",\"url\":\"https://www.semanticscholar.org/paper/eccff2a2fd7b99a4597ec4cb12895a99f1b036db\",\"venue\":\"CIKM\",\"year\":2019},{\"arxivId\":\"1806.03724\",\"authors\":[{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"38784892\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"}],\"doi\":\"10.1109/CVPR.2018.00569\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"04427d8371cb9e66e2cdcd2035756203398a8bf1\",\"title\":\"Learning Answer Embeddings for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/04427d8371cb9e66e2cdcd2035756203398a8bf1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49597404\",\"name\":\"Z. Fang\"},{\"authorId\":\"46700426\",\"name\":\"J. Liu\"},{\"authorId\":\"47003032\",\"name\":\"Y. Li\"},{\"authorId\":\"80526284\",\"name\":\"Yanyuan Qiao\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1016/J.PATCOG.2019.01.038\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aa31126aa9dc7665bf236a51c6de31c4bf6c59ad\",\"title\":\"Improving visual question answering using dropout and enhanced question encoder\",\"url\":\"https://www.semanticscholar.org/paper/aa31126aa9dc7665bf236a51c6de31c4bf6c59ad\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":\"1808.02632\",\"authors\":[{\"authorId\":\"144579867\",\"name\":\"P. Gao\"},{\"authorId\":\"2887562\",\"name\":\"Pan Lu\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"88479495\",\"name\":\"S. Li\"},{\"authorId\":\"2180892\",\"name\":\"Yikang Li\"},{\"authorId\":\"1741126\",\"name\":\"S. Hoi\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1007/978-3-030-01246-5_29\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"391af839051826ec317a6ea61010734baf536551\",\"title\":\"Question-Guided Hybrid Convolution for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/391af839051826ec317a6ea61010734baf536551\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50974488\",\"name\":\"Mingrui Lao\"},{\"authorId\":\"49813983\",\"name\":\"Yanming Guo\"},{\"authorId\":\"49528566\",\"name\":\"Hui Wang\"},{\"authorId\":\"145863022\",\"name\":\"X. Zhang\"}],\"doi\":\"10.20944/PREPRINTS201804.0313.V1\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2329335263b2911a05c36c8c3747d9ee96eb6fee\",\"title\":\"Cross-Modal Multistep Fusion Network With Co-Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2329335263b2911a05c36c8c3747d9ee96eb6fee\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144963976\",\"name\":\"Weidong Tian\"},{\"authorId\":\"145380213\",\"name\":\"B. He\"},{\"authorId\":\"1977865899\",\"name\":\"Nan-Xun Wang\"},{\"authorId\":\"33698309\",\"name\":\"Zhong-Qiu Zhao\"}],\"doi\":\"10.1109/IJCNN48605.2020.9207058\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"99a01a687f7959de4c86102342d4bcfec6382aa8\",\"title\":\"Multi-Channel Co-Attention Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/99a01a687f7959de4c86102342d4bcfec6382aa8\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47058196\",\"name\":\"X. Li\"},{\"authorId\":\"145776313\",\"name\":\"L. Lei\"},{\"authorId\":\"1500378392\",\"name\":\"Yuli Sun\"},{\"authorId\":\"50651883\",\"name\":\"M. Li\"},{\"authorId\":\"66930346\",\"name\":\"Gangyao Kuang\"}],\"doi\":\"10.1109/JSTARS.2020.2975252\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"ec712742b813a98e38bdc72cb572a27e91abf6ab\",\"title\":\"Multimodal Bilinear Fusion Network With Second-Order Attention-Based Channel Selection for Land Cover Classification\",\"url\":\"https://www.semanticscholar.org/paper/ec712742b813a98e38bdc72cb572a27e91abf6ab\",\"venue\":\"IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9024867\",\"name\":\"Jongkwang Hong\"},{\"authorId\":\"48079221\",\"name\":\"Sungho Park\"},{\"authorId\":\"1703310\",\"name\":\"Hyeran Byun\"}],\"doi\":\"10.1016/j.neucom.2020.03.098\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"72e48298519b5ff583e585a65eeea3ac10556adf\",\"title\":\"Selective residual learning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/72e48298519b5ff583e585a65eeea3ac10556adf\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35212676\",\"name\":\"J. Peyre\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"caffa07ead18aae78bf654bc57023eef58e74faf\",\"title\":\"Learning to detect visual relations\",\"url\":\"https://www.semanticscholar.org/paper/caffa07ead18aae78bf654bc57023eef58e74faf\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35137594\",\"name\":\"Jinpeng Mi\"},{\"authorId\":\"51436910\",\"name\":\"Hongzhuo Liang\"},{\"authorId\":\"1693350606\",\"name\":\"Nikolaos Katsakis\"},{\"authorId\":\"145194289\",\"name\":\"Song Tang\"},{\"authorId\":\"153082688\",\"name\":\"Qingdu Li\"},{\"authorId\":\"14966740\",\"name\":\"Changshui Zhang\"},{\"authorId\":\"50561627\",\"name\":\"J. Zhang\"}],\"doi\":\"10.3389/fnbot.2020.00026\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2e08cc165e4ea5706c3dea16118bb845bea47645\",\"title\":\"Intention-Related Natural Language Grounding via Object Affordance Detection and Intention Semantic Extraction\",\"url\":\"https://www.semanticscholar.org/paper/2e08cc165e4ea5706c3dea16118bb845bea47645\",\"venue\":\"Frontiers in Neurorobotics\",\"year\":2020},{\"arxivId\":\"1711.06794\",\"authors\":[{\"authorId\":\"2887562\",\"name\":\"Pan Lu\"},{\"authorId\":\"49404547\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"40538912\",\"name\":\"Wei Zhang\"},{\"authorId\":\"2447408\",\"name\":\"Jianyong Wang\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9a6268d2bc1221ea154097feadea0c58f234d02f\",\"title\":\"Co-attending Free-form Regions and Detections with Multi-modal Multiplicative Feature Embedding for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/9a6268d2bc1221ea154097feadea0c58f234d02f\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3449429\",\"name\":\"Alexander Kuhnle\"}],\"doi\":\"10.17863/CAM.49177\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c04262cb3f76ff769af32afad05263bd47ebef18\",\"title\":\"Evaluating visually grounded language capabilities using microworlds\",\"url\":\"https://www.semanticscholar.org/paper/c04262cb3f76ff769af32afad05263bd47ebef18\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2011.12662\",\"authors\":[{\"authorId\":\"47792675\",\"name\":\"Jie Ma\"},{\"authorId\":\"120809631\",\"name\":\"Jiwang Liu\"},{\"authorId\":\"49297808\",\"name\":\"Junjun Li\"},{\"authorId\":\"50320297\",\"name\":\"Qinghua Zheng\"},{\"authorId\":\"3393799\",\"name\":\"Qingyu Yin\"},{\"authorId\":\"1708169071\",\"name\":\"Jianlong Zhou\"},{\"authorId\":\"121240779\",\"name\":\"Y. Huang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ec666fc061c3e5276dfc1afd9b7a1ae39da69ba6\",\"title\":\"XTQA: Span-Level Explanations of the Textbook Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ec666fc061c3e5276dfc1afd9b7a1ae39da69ba6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3429472\",\"name\":\"Philipp Blandfort\"},{\"authorId\":\"2675822\",\"name\":\"Tushar Karayil\"},{\"authorId\":\"1473240224\",\"name\":\"J\\u00f6rn Hees\"},{\"authorId\":\"145279674\",\"name\":\"A. Dengel\"}],\"doi\":\"10.1007/s13735-019-00188-5\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"497e0ffd32cb4baa12195a686f778b2211b1f008\",\"title\":\"The Focus\\u2013Aspect\\u2013Value model for predicting subjective visual attributes\",\"url\":\"https://www.semanticscholar.org/paper/497e0ffd32cb4baa12195a686f778b2211b1f008\",\"venue\":\"International Journal of Multimedia Information Retrieval\",\"year\":2020},{\"arxivId\":\"1905.09998\",\"authors\":[{\"authorId\":\"46365808\",\"name\":\"Jialin Wu\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7336b10298798985eaa842da38609a3fd0700be3\",\"title\":\"Self-Critical Reasoning for Robust Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7336b10298798985eaa842da38609a3fd0700be3\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1902.05660\",\"authors\":[{\"authorId\":\"144826412\",\"name\":\"Meet Shah\"},{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2019.00681\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"735a63b58349e07b84c2e31927ce1b1cfaf09980\",\"title\":\"Cycle-Consistency for Robust Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/735a63b58349e07b84c2e31927ce1b1cfaf09980\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1805.04247\",\"authors\":[{\"authorId\":\"6328564\",\"name\":\"M. Farazi\"},{\"authorId\":\"144812766\",\"name\":\"Salman Khan\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7605857f551d128e7c3babfc019950250f81bca9\",\"title\":\"Reciprocal Attention Fusion for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7605857f551d128e7c3babfc019950250f81bca9\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9254311\",\"name\":\"Yuansheng Song\"},{\"authorId\":\"2110377\",\"name\":\"Ping Jian\"}],\"doi\":\"10.1007/978-3-030-60450-9_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5a81751ea4350cd67f9bd1d81b9410c64c22527e\",\"title\":\"Deep Hierarchical Attention Flow for Visual Commonsense Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/5a81751ea4350cd67f9bd1d81b9410c64c22527e\",\"venue\":\"NLPCC\",\"year\":2020},{\"arxivId\":\"1910.04964\",\"authors\":[{\"authorId\":\"145583986\",\"name\":\"Wenwu Zhu\"},{\"authorId\":\"72541452\",\"name\":\"X. Wang\"},{\"authorId\":\"1786871\",\"name\":\"Hongzhi Li\"}],\"doi\":\"10.1109/TCSVT.2019.2940647\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d92574b3eb8a90736afb0d6a56f581eee79bdea\",\"title\":\"Multi-Modal Deep Analysis for Multimedia\",\"url\":\"https://www.semanticscholar.org/paper/3d92574b3eb8a90736afb0d6a56f581eee79bdea\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"1908.04289\",\"authors\":[{\"authorId\":\"144740494\",\"name\":\"Peng Gao\"},{\"authorId\":\"30156979\",\"name\":\"Haoxuan You\"},{\"authorId\":\"3152448\",\"name\":\"Zhanpeng Zhang\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"}],\"doi\":\"10.1109/ICCV.2019.00592\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cf5a0d3b67cf03c2441f7aa20f0ea499bd02acf6\",\"title\":\"Multi-Modality Latent Interaction Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/cf5a0d3b67cf03c2441f7aa20f0ea499bd02acf6\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2675822\",\"name\":\"Tushar Karayil\"},{\"authorId\":\"3429472\",\"name\":\"Philipp Blandfort\"},{\"authorId\":\"33884920\",\"name\":\"J. Hees\"},{\"authorId\":\"145279674\",\"name\":\"A. Dengel\"}],\"doi\":\"10.1145/3323873.3325026\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"404997e98d37eec41f6fc4b131c7dc8b0b437414\",\"title\":\"The Focus-Aspect-Value Model for Explainable Prediction of Subjective Visual Interpretation\",\"url\":\"https://www.semanticscholar.org/paper/404997e98d37eec41f6fc4b131c7dc8b0b437414\",\"venue\":\"ICMR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993611266\",\"name\":\"Guohao Li\"},{\"authorId\":\"48632022\",\"name\":\"Xin Wang\"},{\"authorId\":\"40281988\",\"name\":\"Wenwu Zhu\"}],\"doi\":\"10.1145/3394171.3413943\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0030605bfa0a11e7474a8c5ff5b00f3ccdb22b22\",\"title\":\"Boosting Visual Question Answering with Context-aware Knowledge Aggregation\",\"url\":\"https://www.semanticscholar.org/paper/0030605bfa0a11e7474a8c5ff5b00f3ccdb22b22\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1809.00898\",\"authors\":[{\"authorId\":\"51138718\",\"name\":\"Marie-Morgane Paumard\"},{\"authorId\":\"145897899\",\"name\":\"D. Picard\"},{\"authorId\":\"2397984\",\"name\":\"H. Tabia\"}],\"doi\":\"10.1007/978-3-030-01231-1_10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5badd64093577999a81865c88aedf8c293c9fab7\",\"title\":\"Image Reassembly Combining Deep Learning and Shortest Path Problem\",\"url\":\"https://www.semanticscholar.org/paper/5badd64093577999a81865c88aedf8c293c9fab7\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1901.02322\",\"authors\":[{\"authorId\":\"3429472\",\"name\":\"Philipp Blandfort\"},{\"authorId\":\"2675822\",\"name\":\"Tushar Karayil\"},{\"authorId\":\"48258541\",\"name\":\"Federico Raue\"},{\"authorId\":\"33884920\",\"name\":\"J. Hees\"},{\"authorId\":\"145279674\",\"name\":\"A. Dengel\"}],\"doi\":\"10.1109/IJCNN.2019.8852259\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a743f4df329b76b4caeddc67e6babaede5563fb0\",\"title\":\"Fusion Strategies for Learning User Embeddings with Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/a743f4df329b76b4caeddc67e6babaede5563fb0\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3315036\",\"name\":\"S. Kang\"},{\"authorId\":\"2447631\",\"name\":\"Junyeong Kim\"},{\"authorId\":\"3031838\",\"name\":\"Hyunsoo Choi\"},{\"authorId\":\"2561991\",\"name\":\"S. Kim\"},{\"authorId\":\"145954697\",\"name\":\"C. Yoo\"}],\"doi\":\"10.1007/978-3-030-01264-9_24\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1cdf8790a675037579bbe2ee4f39f731f7672fae\",\"title\":\"Pivot Correlational Neural Network for Multimodal Video Categorization\",\"url\":\"https://www.semanticscholar.org/paper/1cdf8790a675037579bbe2ee4f39f731f7672fae\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1805.09701\",\"authors\":[{\"authorId\":\"2887562\",\"name\":\"Pan Lu\"},{\"authorId\":\"50688017\",\"name\":\"L. Ji\"},{\"authorId\":null,\"name\":\"Wei Zhang\"},{\"authorId\":\"29943965\",\"name\":\"Nan Duan\"},{\"authorId\":\"143849609\",\"name\":\"M. Zhou\"},{\"authorId\":\"2447408\",\"name\":\"Jianyong Wang\"}],\"doi\":\"10.1145/3219819.3220036\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d2de5d94461d66e6b97e6825ae0fea3d6d925382\",\"title\":\"R-VQA: Learning Visual Relation Facts with Semantic Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d2de5d94461d66e6b97e6825ae0fea3d6d925382\",\"venue\":\"KDD\",\"year\":2018},{\"arxivId\":\"1910.02509\",\"authors\":[{\"authorId\":\"31449728\",\"name\":\"T. Hayes\"},{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"153677280\",\"name\":\"Robik Shrestha\"},{\"authorId\":\"47309247\",\"name\":\"Manoj Acharya\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1007/978-3-030-58598-3_28\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f6c3e8b8e6d647ebb61833e9105d2147e472f534\",\"title\":\"REMIND Your Neural Network to Prevent Catastrophic Forgetting\",\"url\":\"https://www.semanticscholar.org/paper/f6c3e8b8e6d647ebb61833e9105d2147e472f534\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1806.04655\",\"authors\":[{\"authorId\":\"47016316\",\"name\":\"Revanth Reddy Gangi Reddy\"},{\"authorId\":\"10081629\",\"name\":\"R. Ramesh\"},{\"authorId\":\"33341943\",\"name\":\"Ameet Deshpande\"},{\"authorId\":\"2361078\",\"name\":\"Mitesh M. Khapra\"}],\"doi\":\"10.1109/IJCNN.2019.8851830\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"220bb685271613781f8e5d8a8194b0e7488791d3\",\"title\":\"FigureNet : A Deep Learning model for Question-Answering on Scientific Plots\",\"url\":\"https://www.semanticscholar.org/paper/220bb685271613781f8e5d8a8194b0e7488791d3\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1443432976\",\"name\":\"Zhenxiong Tan\"},{\"authorId\":\"151475424\",\"name\":\"Tianrui Hui\"},{\"authorId\":\"1584278646\",\"name\":\"Jinyu Chen\"},{\"authorId\":\"47179923\",\"name\":\"S. Liu\"}],\"doi\":\"10.1007/978-3-030-60633-6_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"99a02592befa3741ebeefd8d02fbe2960817b6fa\",\"title\":\"Multi-granularity Multimodal Feature Interaction for Referring Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/99a02592befa3741ebeefd8d02fbe2960817b6fa\",\"venue\":\"PRCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3429472\",\"name\":\"Philipp Blandfort\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8d207010d9147485901057a9d380ad589a294005\",\"title\":\"Computational Approaches to Subjective Interpretation of Multimedia Messages\",\"url\":\"https://www.semanticscholar.org/paper/8d207010d9147485901057a9d380ad589a294005\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2012.11014\",\"authors\":[{\"authorId\":\"35789996\",\"name\":\"Kenneth Marino\"},{\"authorId\":\"1606041624\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1726095131\",\"name\":\"Abhinav Gupta\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1a9015e511ec3da873f6114eeb542905a92d7d62\",\"title\":\"KRISP: Integrating Implicit and Symbolic Knowledge for Open-Domain Knowledge-Based VQA\",\"url\":\"https://www.semanticscholar.org/paper/1a9015e511ec3da873f6114eeb542905a92d7d62\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1620218253\",\"name\":\"Sruthy Manmadhan\"},{\"authorId\":\"30588803\",\"name\":\"Binsu C. Kovoor\"}],\"doi\":\"10.1007/s10462-020-09832-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"667b88984df0c5c11ac07899ffb5509185abdf57\",\"title\":\"Visual question answering: a state-of-the-art review\",\"url\":\"https://www.semanticscholar.org/paper/667b88984df0c5c11ac07899ffb5509185abdf57\",\"venue\":\"Artificial Intelligence Review\",\"year\":2020},{\"arxivId\":\"1903.12314\",\"authors\":[{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"145215470\",\"name\":\"Yu Cheng\"},{\"authorId\":\"38079056\",\"name\":\"Jingjing Liu\"}],\"doi\":\"10.1109/ICCV.2019.01041\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d379ba96b8f400b23b2cd72c428af67e578959ea\",\"title\":\"Relation-Aware Graph Attention Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d379ba96b8f400b23b2cd72c428af67e578959ea\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1903.00366\",\"authors\":[{\"authorId\":\"153677280\",\"name\":\"Robik Shrestha\"},{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1109/CVPR.2019.01072\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d9344534ab39544a3a3c173b27628e0d9c5d4dc5\",\"title\":\"Answer Them All! Toward Universal Visual Question Answering Models\",\"url\":\"https://www.semanticscholar.org/paper/d9344534ab39544a3a3c173b27628e0d9c5d4dc5\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1904.03100\",\"authors\":[{\"authorId\":\"71003878\",\"name\":\"Jian Li\"},{\"authorId\":\"21299583\",\"name\":\"Baosong Yang\"},{\"authorId\":\"14199369\",\"name\":\"Zi-Yi Dou\"},{\"authorId\":\"48631170\",\"name\":\"Xing Wang\"},{\"authorId\":\"1785083\",\"name\":\"Michael R. Lyu\"},{\"authorId\":\"2909321\",\"name\":\"Zhaopeng Tu\"}],\"doi\":\"10.18653/v1/N19-1359\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c9bfe765f076422256fef909bdca186b5880c52\",\"title\":\"Information Aggregation for Multi-Head Attention with Routing-by-Agreement\",\"url\":\"https://www.semanticscholar.org/paper/6c9bfe765f076422256fef909bdca186b5880c52\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":\"1711.06232\",\"authors\":[{\"authorId\":\"2973866\",\"name\":\"J. Huang\"},{\"authorId\":\"3409955\",\"name\":\"C. D. Dao\"},{\"authorId\":\"9951160\",\"name\":\"Modar Alfadly\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1609/aaai.v33i01.33018449\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a26d01dc2b9a4e435c015914690354f67a9b6a08\",\"title\":\"A Novel Framework for Robustness Analysis of Visual QA Models\",\"url\":\"https://www.semanticscholar.org/paper/a26d01dc2b9a4e435c015914690354f67a9b6a08\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8511875\",\"name\":\"Jonghwan Mun\"},{\"authorId\":\"3436470\",\"name\":\"Kimin Lee\"},{\"authorId\":\"143720148\",\"name\":\"Jinwoo Shin\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"7adef3d0200207baec75e39bbb852cacfaf8268b\",\"title\":\"Learning to Specialize with Knowledge Distillation for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7adef3d0200207baec75e39bbb852cacfaf8268b\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"2003.10065\",\"authors\":[{\"authorId\":\"2826839\",\"name\":\"Qingxing Cao\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"3170394\",\"name\":\"Keze Wang\"},{\"authorId\":\"49478124\",\"name\":\"L. Lin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e4e90d80721fc24ac40f4711f8692aba08dc14e0\",\"title\":\"Linguistically Driven Graph Capsule Network for Visual Question Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/e4e90d80721fc24ac40f4711f8692aba08dc14e0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.10833\",\"authors\":[{\"authorId\":\"145382022\",\"name\":\"Shanshan Zhao\"},{\"authorId\":\"50175298\",\"name\":\"M. Gong\"},{\"authorId\":\"145150876\",\"name\":\"Huan Fu\"},{\"authorId\":\"1490934465\",\"name\":\"Dacheng Tao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d28bc1c082789ea14316bf5f733efa4300da17a7\",\"title\":\"Adaptive Context-Aware Multi-Modal Network for Depth Completion\",\"url\":\"https://www.semanticscholar.org/paper/d28bc1c082789ea14316bf5f733efa4300da17a7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Valeo. ai\"},{\"authorId\":null,\"name\":\"Valeo\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9c8707ffb59b37029942baf4606b415b462de8eb\",\"title\":\"Driving Behavior Explanation with Multi-level Fusion\",\"url\":\"https://www.semanticscholar.org/paper/9c8707ffb59b37029942baf4606b415b462de8eb\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2548483\",\"name\":\"Shengfeng He\"},{\"authorId\":\"14898006\",\"name\":\"Chu Han\"},{\"authorId\":\"2513505\",\"name\":\"Guoqiang Han\"},{\"authorId\":\"145947071\",\"name\":\"Jing Qin\"}],\"doi\":\"10.1109/TNNLS.2019.2933439\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"3d3c31f077c002d476d7eb85e94d43830243e4bf\",\"title\":\"Exploring Duality in Visual Question-Driven Top-Down Saliency\",\"url\":\"https://www.semanticscholar.org/paper/3d3c31f077c002d476d7eb85e94d43830243e4bf\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2020},{\"arxivId\":\"1910.11475\",\"authors\":[{\"authorId\":\"48729196\",\"name\":\"Weijiang Yu\"},{\"authorId\":\"150167685\",\"name\":\"Jingwen Zhou\"},{\"authorId\":\"23476952\",\"name\":\"Weihao Yu\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"1730284\",\"name\":\"N. Xiao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ef318e7ff0883e72d853c75736d20cc123b556d5\",\"title\":\"Heterogeneous Graph Learning for Visual Commonsense Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/ef318e7ff0883e72d853c75736d20cc123b556d5\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1508389232\",\"name\":\"Junyi Feng\"},{\"authorId\":\"145197100\",\"name\":\"P. Gong\"},{\"authorId\":\"1508486471\",\"name\":\"Guanghui Qiu\"}],\"doi\":\"10.1145/3376067.3376082\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"732af43dac39f3ed15a43ab916eabb80dd67e72a\",\"title\":\"MDAnet: Multiple Fusion Network with Double Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/732af43dac39f3ed15a43ab916eabb80dd67e72a\",\"venue\":\"ICVIP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2846025\",\"name\":\"D. Yu\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"40434674\",\"name\":\"X. Tian\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1145/3316767\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b0ce44270916fd6e254fd9e75dd77ee1cf9f212a\",\"title\":\"Multi-source Multi-level Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b0ce44270916fd6e254fd9e75dd77ee1cf9f212a\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6937593\",\"name\":\"Shih-Han Chou\"},{\"authorId\":\"150336480\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"38784892\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"30885811\",\"name\":\"Min Sun\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/WACV45572.2020.9093452\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0e0c5d868d84908bb7a26c27c1aedea43fdc493d\",\"title\":\"Visual Question Answering on 360\\u00b0 Images\",\"url\":\"https://www.semanticscholar.org/paper/0e0c5d868d84908bb7a26c27c1aedea43fdc493d\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38882705\",\"name\":\"A. Singh\"},{\"authorId\":\"145887760\",\"name\":\"A. Mishra\"},{\"authorId\":\"153475826\",\"name\":\"Shashank Shekhar\"},{\"authorId\":\"46264522\",\"name\":\"A. Chakraborty\"}],\"doi\":\"10.1109/ICCV.2019.00470\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"ee356bc5c03bf822bbdd019fe1236c42595b4d6f\",\"title\":\"From Strings to Things: Knowledge-Enabled VQA Model That Can Read and Reason\",\"url\":\"https://www.semanticscholar.org/paper/ee356bc5c03bf822bbdd019fe1236c42595b4d6f\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50974488\",\"name\":\"Mingrui Lao\"},{\"authorId\":\"49813983\",\"name\":\"Yanming Guo\"},{\"authorId\":\"49528566\",\"name\":\"Hui Wang\"},{\"authorId\":\"35742440\",\"name\":\"X. Zhang\"}],\"doi\":\"10.1109/ACCESS.2018.2844789\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2609626519d8fa0ccc53bce49a3a21b928deeca6\",\"title\":\"Cross-Modal Multistep Fusion Network With Co-Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2609626519d8fa0ccc53bce49a3a21b928deeca6\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46314360\",\"name\":\"Weixuan Wang\"},{\"authorId\":\"49865085\",\"name\":\"Zhihong Chen\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1007/978-3-030-20876-9_37\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bf3f2f2c1b88eb7b031d593c9d83641baea364e2\",\"title\":\"Multivariate Attention Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/bf3f2f2c1b88eb7b031d593c9d83641baea364e2\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"2007.14419\",\"authors\":[{\"authorId\":\"94011352\",\"name\":\"S. Chen\"},{\"authorId\":\"1405907659\",\"name\":\"Ming Jiang\"},{\"authorId\":\"7788087\",\"name\":\"J. Yang\"},{\"authorId\":\"153386875\",\"name\":\"Q. Zhao\"}],\"doi\":\"10.1007/978-3-030-58452-8_6\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"96150d2fdbb72e11882ad06b346d6e0d2e819d51\",\"title\":\"AiR: Attention with Reasoning Capability\",\"url\":\"https://www.semanticscholar.org/paper/96150d2fdbb72e11882ad06b346d6e0d2e819d51\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2012.02951\",\"authors\":[{\"authorId\":\"1935410\",\"name\":\"M. Rahnemoonfar\"},{\"authorId\":\"39734189\",\"name\":\"Tashnim J. S. Chowdhury\"},{\"authorId\":\"1381535116\",\"name\":\"Argho Sarkar\"},{\"authorId\":\"1411385478\",\"name\":\"D. Varshney\"},{\"authorId\":\"1505798397\",\"name\":\"Masoud Yari\"},{\"authorId\":\"1789429\",\"name\":\"R. Murphy\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"af2550268c34fb0376a3f18f150bf4f9ce3023b9\",\"title\":\"FloodNet: A High Resolution Aerial Imagery Dataset for Post Flood Scene Understanding\",\"url\":\"https://www.semanticscholar.org/paper/af2550268c34fb0376a3f18f150bf4f9ce3023b9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.10079\",\"authors\":[{\"authorId\":\"41020827\",\"name\":\"Corentin Dancette\"},{\"authorId\":\"7535126\",\"name\":\"R\\u00e9mi Cad\\u00e8ne\"},{\"authorId\":\"1606041624\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b5cb23c3c09bcd9f0e12a864b9f4ac3fa0f2dfbd\",\"title\":\"Overcoming Statistical Shortcuts for Open-ended Visual Counting\",\"url\":\"https://www.semanticscholar.org/paper/b5cb23c3c09bcd9f0e12a864b9f4ac3fa0f2dfbd\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.08670\",\"authors\":[{\"authorId\":\"3227254\",\"name\":\"Hamid Reza Vaezi Joze\"},{\"authorId\":\"2966051\",\"name\":\"Amirreza Shaban\"},{\"authorId\":\"67294118\",\"name\":\"Michael L. Iuzzolino\"},{\"authorId\":\"145733034\",\"name\":\"K. Koishida\"}],\"doi\":\"10.1109/cvpr42600.2020.01330\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb8304061be88b2452872e12a53b23bc9f6b4925\",\"title\":\"MMTM: Multimodal Transfer Module for CNN Fusion\",\"url\":\"https://www.semanticscholar.org/paper/eb8304061be88b2452872e12a53b23bc9f6b4925\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1901.09590\",\"authors\":[{\"authorId\":\"3451828\",\"name\":\"Ivana Balazevic\"},{\"authorId\":\"4054662\",\"name\":\"Carl Allen\"},{\"authorId\":\"1697755\",\"name\":\"Timothy M. Hospedales\"}],\"doi\":\"10.18653/v1/D19-1522\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"05dc5fb3a3bdefdf181aafcc42cd80ff6b7704e7\",\"title\":\"TuckER: Tensor Factorization for Knowledge Graph Completion\",\"url\":\"https://www.semanticscholar.org/paper/05dc5fb3a3bdefdf181aafcc42cd80ff6b7704e7\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"2012.10285\",\"authors\":[{\"authorId\":\"14358891\",\"name\":\"T. Winterbottom\"},{\"authorId\":\"7750732\",\"name\":\"S. Xiao\"},{\"authorId\":\"145147517\",\"name\":\"A. McLean\"},{\"authorId\":\"1875235\",\"name\":\"N. A. Moubayed\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f06224d597451ce1d440ca0c8542dee4a5767afe\",\"title\":\"Trying Bilinear Pooling in Video-QA\",\"url\":\"https://www.semanticscholar.org/paper/f06224d597451ce1d440ca0c8542dee4a5767afe\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2006.04315\",\"authors\":[{\"authorId\":\"2520427\",\"name\":\"Yulei Niu\"},{\"authorId\":\"10817432\",\"name\":\"Kaihua Tang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1776220\",\"name\":\"Zhiwu Lu\"},{\"authorId\":\"143863244\",\"name\":\"Xian-Sheng Hua\"},{\"authorId\":\"112957699\",\"name\":\"Ji-Rong Wen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3e3f55cb25b919c4e8158195fd3ce2f23cfa7723\",\"title\":\"Counterfactual VQA: A Cause-Effect Look at Language Bias\",\"url\":\"https://www.semanticscholar.org/paper/3e3f55cb25b919c4e8158195fd3ce2f23cfa7723\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.11883\",\"authors\":[{\"authorId\":\"41022273\",\"name\":\"Duy-Kien Nguyen\"},{\"authorId\":\"28554843\",\"name\":\"Vedanuj Goswami\"},{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6c7faa44bde54f017e164ad8e687bd1963005988\",\"title\":\"Revisiting Modulated Convolutions for Visual Counting and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/6c7faa44bde54f017e164ad8e687bd1963005988\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.12962\",\"authors\":[{\"authorId\":\"145122731\",\"name\":\"Xin Lin\"},{\"authorId\":\"144116132\",\"name\":\"Changxing Ding\"},{\"authorId\":\"1882003\",\"name\":\"Jinquan Zeng\"},{\"authorId\":\"145047838\",\"name\":\"Dacheng Tao\"}],\"doi\":\"10.1109/cvpr42600.2020.00380\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"56092013ab20394725719910fc7d4fe2274f3d54\",\"title\":\"GPS-Net: Graph Property Sensing Network for Scene Graph Generation\",\"url\":\"https://www.semanticscholar.org/paper/56092013ab20394725719910fc7d4fe2274f3d54\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"94011352\",\"name\":\"S. Chen\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"456108dc68bc5d2a2e39cbeb69f51c65d0acf53e\",\"title\":\"AiR: Attention with Reasoning Capability (Supplementary Materials)\",\"url\":\"https://www.semanticscholar.org/paper/456108dc68bc5d2a2e39cbeb69f51c65d0acf53e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2008.08012\",\"authors\":[{\"authorId\":\"9748140\",\"name\":\"K. Gouthaman\"},{\"authorId\":\"3265714\",\"name\":\"A. Nambiar\"},{\"authorId\":\"1882516497\",\"name\":\"Kancheti Sai Srinivas\"},{\"authorId\":\"50853059\",\"name\":\"Anurag Mittal\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b46ce08535c728cc690852a7c63a9bb211ff25ab\",\"title\":\"Linguistically-aware Attention for Reducing the Semantic-Gap in Vision-Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/b46ce08535c728cc690852a7c63a9bb211ff25ab\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1903.06496\",\"authors\":[{\"authorId\":\"1414405933\",\"name\":\"Juan-Manuel P\\u00e9rez-R\\u00faa\"},{\"authorId\":\"26339425\",\"name\":\"Valentin Vielzeuf\"},{\"authorId\":\"2642628\",\"name\":\"S. Pateux\"},{\"authorId\":\"2341854\",\"name\":\"M. Baccouche\"},{\"authorId\":\"82117876\",\"name\":\"F. Jurie\"}],\"doi\":\"10.1109/CVPR.2019.00713\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e5cd45ee1e91ba7a68d2a18d0735a75ed021766a\",\"title\":\"MFAS: Multimodal Fusion Architecture Search\",\"url\":\"https://www.semanticscholar.org/paper/e5cd45ee1e91ba7a68d2a18d0735a75ed021766a\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1909.11874\",\"authors\":[{\"authorId\":\"52220768\",\"name\":\"T. Do\"},{\"authorId\":\"3354627\",\"name\":\"Thanh-Toan Do\"},{\"authorId\":\"134083550\",\"name\":\"Huy Tran\"},{\"authorId\":\"1387964524\",\"name\":\"Erman Tjiputra\"},{\"authorId\":\"20135953\",\"name\":\"Q. D. Tran\"}],\"doi\":\"10.1109/ICCV.2019.00048\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"27cb0b42e0573c4891ae2ca444776dee57bfe2ac\",\"title\":\"Compact Trilinear Interaction for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/27cb0b42e0573c4891ae2ca444776dee57bfe2ac\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1809.05848\",\"authors\":[{\"authorId\":\"46700331\",\"name\":\"J. Liu\"},{\"authorId\":\"51305314\",\"name\":\"Zehuan Yuan\"},{\"authorId\":\"1697065\",\"name\":\"C. Wang\"}],\"doi\":\"10.1007/978-3-030-11018-5_26\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1dc373458adf54678b6b981ce458ccdbe3f9d112\",\"title\":\"Towards Good Practices for Multi-modal Fusion in Large-scale Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/1dc373458adf54678b6b981ce458ccdbe3f9d112\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49597404\",\"name\":\"Z. Fang\"},{\"authorId\":\"7187373\",\"name\":\"J. Liu\"},{\"authorId\":null,\"name\":\"Qu Tang\"},{\"authorId\":\"49112842\",\"name\":\"Y. Li\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1007/978-3-030-20887-5_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8463ff93a6725017bd1875eeb7ae4d0f0e7df568\",\"title\":\"Answer Distillation for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8463ff93a6725017bd1875eeb7ae4d0f0e7df568\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50498297\",\"name\":\"Liang Peng\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":\"2105743\",\"name\":\"Y. Bin\"},{\"authorId\":\"145833207\",\"name\":\"Ning Xie\"},{\"authorId\":\"144618699\",\"name\":\"F. Shen\"},{\"authorId\":\"50006507\",\"name\":\"Yanli Ji\"},{\"authorId\":\"47158869\",\"name\":\"Xing Xu\"}],\"doi\":\"10.1007/s11042-018-6389-3\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"713dd629c183056202f31c2a98e5e37e0d83efa4\",\"title\":\"Word-to-region attention network for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/713dd629c183056202f31c2a98e5e37e0d83efa4\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":\"1811.00538\",\"authors\":[{\"authorId\":\"153137839\",\"name\":\"M. Narasimhan\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ad08da5951437c117551a63c2f8b943bee2029ce\",\"title\":\"Out of the Box: Reasoning with Graph Convolution Nets for Factual Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ad08da5951437c117551a63c2f8b943bee2029ce\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1904.08607\",\"authors\":[{\"authorId\":\"2447631\",\"name\":\"Junyeong Kim\"},{\"authorId\":\"103278467\",\"name\":\"Minuk Ma\"},{\"authorId\":\"4604969\",\"name\":\"Kyungsu Kim\"},{\"authorId\":\"2561991\",\"name\":\"S. Kim\"},{\"authorId\":\"145954697\",\"name\":\"C. Yoo\"}],\"doi\":\"10.1109/CVPR.2019.00853\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b621afeef5888f8f71fd6ca97a62daa0d0cb6d69\",\"title\":\"Progressive Attention Memory Network for Movie Story Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b621afeef5888f8f71fd6ca97a62daa0d0cb6d69\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49303626\",\"name\":\"K. Su\"},{\"authorId\":\"144904233\",\"name\":\"Hang Su\"},{\"authorId\":\"104545113\",\"name\":\"J. Li\"},{\"authorId\":\"1557387379\",\"name\":\"Jun Zhu\"}],\"doi\":\"10.3389/frobt.2020.00109\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"22e2a19bef88c30a37402da5b54fac34655d77ea\",\"title\":\"Toward Accurate Visual Reasoning With Dual-Path Neural Module Networks\",\"url\":\"https://www.semanticscholar.org/paper/22e2a19bef88c30a37402da5b54fac34655d77ea\",\"venue\":\"Frontiers in Robotics and AI\",\"year\":2020},{\"arxivId\":\"1910.10706\",\"authors\":[{\"authorId\":\"26385137\",\"name\":\"Noa Garcia\"},{\"authorId\":\"3186326\",\"name\":\"Mayu Otani\"},{\"authorId\":\"2427516\",\"name\":\"Chenhui Chu\"},{\"authorId\":\"1789677\",\"name\":\"Yuta Nakashima\"}],\"doi\":\"10.1609/AAAI.V34I07.6713\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"12f11d56a83516bfdd1f32f60e3695ab92a0f819\",\"title\":\"KnowIT VQA: Answering Knowledge-Based Questions about Videos\",\"url\":\"https://www.semanticscholar.org/paper/12f11d56a83516bfdd1f32f60e3695ab92a0f819\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49597404\",\"name\":\"Z. Fang\"},{\"authorId\":null,\"name\":\"Jing Liu\"},{\"authorId\":\"49544292\",\"name\":\"Xueliang Liu\"},{\"authorId\":null,\"name\":\"Qu Tang\"},{\"authorId\":\"50025104\",\"name\":\"Yonghong Li\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1145/3282469\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2c74311cc5e18a120bebf331b0dd85c72426380d\",\"title\":\"BTDP: Toward Sparse Fusion with Block Term Decomposition Pooling for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2c74311cc5e18a120bebf331b0dd85c72426380d\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144544920\",\"name\":\"Fei Liu\"},{\"authorId\":\"1749850\",\"name\":\"J. Liu\"},{\"authorId\":\"48043335\",\"name\":\"R. Hong\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1145/3343031.3350993\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6834deeabfbc3ca5989ca7a3bd76dc5a84c5a346\",\"title\":\"Erasing-based Attention Learning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/6834deeabfbc3ca5989ca7a3bd76dc5a84c5a346\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1904.05880\",\"authors\":[{\"authorId\":\"38211837\",\"name\":\"Idan Schwartz\"},{\"authorId\":\"1885974\",\"name\":\"Seunghak Yu\"},{\"authorId\":\"1918412\",\"name\":\"T. Hazan\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1109/CVPR.2019.00214\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ecce0a7b0f9b2bfbc6ca2c99805bddd53178ac35\",\"title\":\"Factor Graph Attention\",\"url\":\"https://www.semanticscholar.org/paper/ecce0a7b0f9b2bfbc6ca2c99805bddd53178ac35\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48044229\",\"name\":\"F. Qi\"},{\"authorId\":\"2059713\",\"name\":\"Xiaoshan Yang\"},{\"authorId\":\"145194969\",\"name\":\"C. Xu\"}],\"doi\":\"10.1145/3240508.3240633\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dae315b084b9164ac68da26aaa73de877f73f75c\",\"title\":\"A Unified Framework for Multimodal Domain Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/dae315b084b9164ac68da26aaa73de877f73f75c\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"2006.15631\",\"authors\":[{\"authorId\":\"46365808\",\"name\":\"Jialin Wu\"},{\"authorId\":\"46307991\",\"name\":\"Liyan Chen\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"f336b80e3f78615fbb414d4c4aed7545024dc4bf\",\"title\":\"Improving VQA and its Explanations by Comparing Competing Explanations\",\"url\":\"https://www.semanticscholar.org/paper/f336b80e3f78615fbb414d4c4aed7545024dc4bf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.12070\",\"authors\":[{\"authorId\":\"1564034697\",\"name\":\"Zhou Yu\"},{\"authorId\":\"30513139\",\"name\":\"Yuhao Cui\"},{\"authorId\":null,\"name\":\"Jun Yu\"},{\"authorId\":\"152808542\",\"name\":\"Meng Wang\"},{\"authorId\":\"1490934465\",\"name\":\"Dacheng Tao\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1145/3394171.3413977\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f40ed567148f724028952e5fe20a34a0b671dd2e\",\"title\":\"Deep Multimodal Neural Architecture Search\",\"url\":\"https://www.semanticscholar.org/paper/f40ed567148f724028952e5fe20a34a0b671dd2e\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2012.04983\",\"authors\":[{\"authorId\":\"1405301761\",\"name\":\"Hedi Ben-younes\"},{\"authorId\":null,\"name\":\"Eloi Zablocki\"},{\"authorId\":\"1398301486\",\"name\":\"P. P\\u00e9rez\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"44194713255b6ee890ce1a2d2b727d30e0b71cdb\",\"title\":\"Driving Behavior Explanation with Multi-level Fusion\",\"url\":\"https://www.semanticscholar.org/paper/44194713255b6ee890ce1a2d2b727d30e0b71cdb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yan Zhang\"},{\"authorId\":\"2276351\",\"name\":\"Krikamol Muandet\"},{\"authorId\":null,\"name\":\"Qianli Ma\"},{\"authorId\":\"144718494\",\"name\":\"H. Neumann\"},{\"authorId\":\"39578749\",\"name\":\"Siyu Tang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3588725a4fb22db3a1506eaed75eb97fba09ecc3\",\"title\":\"Low-rank Random Tensor for Bilinear Pooling\",\"url\":\"https://www.semanticscholar.org/paper/3588725a4fb22db3a1506eaed75eb97fba09ecc3\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1910.11124\",\"authors\":[{\"authorId\":\"1381855534\",\"name\":\"Hammad A. Ayyubi\"},{\"authorId\":\"35631602\",\"name\":\"Md. Mehrab Tanjim\"},{\"authorId\":\"1765887\",\"name\":\"D. Kriegman\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c9e5b9536ab2d87eb45d0185d89a1164e0b7f75d\",\"title\":\"Enforcing Reasoning in Visual Commonsense Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/c9e5b9536ab2d87eb45d0185d89a1164e0b7f75d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144612044\",\"name\":\"H. Chauhan\"},{\"authorId\":\"40195882\",\"name\":\"M. Firdaus\"},{\"authorId\":\"1734904\",\"name\":\"Asif Ekbal\"},{\"authorId\":\"145532184\",\"name\":\"P. Bhattacharyya\"}],\"doi\":\"10.18653/v1/P19-1540\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"314b6a975373f69f7628f2bc8647084181c84ac9\",\"title\":\"Ordinal and Attribute Aware Response Generation in a Multimodal Dialogue System\",\"url\":\"https://www.semanticscholar.org/paper/314b6a975373f69f7628f2bc8647084181c84ac9\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1796706\",\"name\":\"Daojian Zeng\"},{\"authorId\":\"1400347434\",\"name\":\"Guanhong Zhou\"},{\"authorId\":\"9491882\",\"name\":\"J. Wang\"}],\"doi\":\"10.1109/ICECIE47765.2019.8974765\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"01163764edf888ded242e992845badaaf6c6ec6e\",\"title\":\"Residual Self-Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/01163764edf888ded242e992845badaaf6c6ec6e\",\"venue\":\"2019 1st International Conference on Electrical, Control and Instrumentation Engineering (ICECIE)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32543309\",\"name\":\"Tianling Jiang\"},{\"authorId\":\"144602988\",\"name\":\"Yi Ji\"},{\"authorId\":\"49046633\",\"name\":\"Chunping Liu\"},{\"authorId\":\"21633777\",\"name\":\"Hailin Shao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"78c2f7520becde5e3bcd9b952791d67c33a48612\",\"title\":\"Visual-Textual Alignment for Graph Inference in Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/78c2f7520becde5e3bcd9b952791d67c33a48612\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144638992\",\"name\":\"Xinzhe Han\"},{\"authorId\":\"47672591\",\"name\":\"Shuhui Wang\"},{\"authorId\":\"145422145\",\"name\":\"Chi Su\"},{\"authorId\":\"153645460\",\"name\":\"W. Zhang\"},{\"authorId\":\"153159021\",\"name\":\"Qingming Huang\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1007/978-3-030-58545-7_32\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2a315d4e5db42ae5d45f7c1702998b41ac26babe\",\"title\":\"Interpretable Visual Reasoning via Probabilistic Formulation Under Natural Supervision\",\"url\":\"https://www.semanticscholar.org/paper/2a315d4e5db42ae5d45f7c1702998b41ac26babe\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2002.05556\",\"authors\":[{\"authorId\":\"144869806\",\"name\":\"Pedro Henrique Martins\"},{\"authorId\":\"2114966\",\"name\":\"Vlad Niculae\"},{\"authorId\":\"2566656\",\"name\":\"Zita Marinho\"},{\"authorId\":\"145644643\",\"name\":\"Andr\\u00e9 F. T. Martins\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4e627eb9f17369770f2cef5d71360c93c8494785\",\"title\":\"Sparse and Structured Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4e627eb9f17369770f2cef5d71360c93c8494785\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1807.11407\",\"authors\":[{\"authorId\":\"143914216\",\"name\":\"T. Robert\"},{\"authorId\":\"1728523\",\"name\":\"N. Thome\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"}],\"doi\":\"10.1007/978-3-030-01234-2_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"096544bcee4cea890d6d7eaffb667501d0816a9a\",\"title\":\"HybridNet: Classification and Reconstruction Cooperation for Semi-Supervised Learning\",\"url\":\"https://www.semanticscholar.org/paper/096544bcee4cea890d6d7eaffb667501d0816a9a\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1911.08618\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"1380338049\",\"name\":\"Anupriy\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":\"10.1609/AAAI.V34I07.6858\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dabe557eaad9e326a5b44c04fa619b2118f4bda5\",\"title\":\"Explanation vs Attention: A Two-Player Game to Obtain Attention for VQA\",\"url\":\"https://www.semanticscholar.org/paper/dabe557eaad9e326a5b44c04fa619b2118f4bda5\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2375749\",\"name\":\"T. Durand\"}],\"doi\":\"10.1109/cvpr42600.2020.00979\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b202588b7a62d19512770a6c06549deb808217ba\",\"title\":\"Learning User Representations for Open Vocabulary Image Hashtag Prediction\",\"url\":\"https://www.semanticscholar.org/paper/b202588b7a62d19512770a6c06549deb808217ba\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1908.03289\",\"authors\":[{\"authorId\":\"6328564\",\"name\":\"M. Farazi\"},{\"authorId\":\"1931655\",\"name\":\"S. Khan\"},{\"authorId\":\"1712576\",\"name\":\"N. Barnes\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e2a185828cad6b8ea5133a9e41d1ab4b75c9f718\",\"title\":\"Question-Agnostic Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e2a185828cad6b8ea5133a9e41d1ab4b75c9f718\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1577606322\",\"name\":\"Shrey Nahar\"},{\"authorId\":\"1576127863\",\"name\":\"S. Naik\"},{\"authorId\":\"15488883\",\"name\":\"Niti H Shah\"},{\"authorId\":\"49485385\",\"name\":\"Saumya Shah\"},{\"authorId\":\"9079986\",\"name\":\"Lakshmi Kurup\"}],\"doi\":\"10.1007/978-3-030-38445-6_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1bac534a3a2672297db2a76a4491b275e464bdbd\",\"title\":\"Automated Question Generation and Answer Verification Using Visual Data\",\"url\":\"https://www.semanticscholar.org/paper/1bac534a3a2672297db2a76a4491b275e464bdbd\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1911.06258\",\"authors\":[{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"50286460\",\"name\":\"Amanpreet Singh\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.1109/cvpr42600.2020.01001\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4fc2eb1b494a29c7cb39da3b180a302521e459a0\",\"title\":\"Iterative Answer Prediction With Pointer-Augmented Multimodal Transformers for TextVQA\",\"url\":\"https://www.semanticscholar.org/paper/4fc2eb1b494a29c7cb39da3b180a302521e459a0\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2007.13135\",\"authors\":[{\"authorId\":\"144861502\",\"name\":\"Lei Shi\"},{\"authorId\":\"2198730\",\"name\":\"K. Shuang\"},{\"authorId\":\"1947101\",\"name\":\"Shijie Geng\"},{\"authorId\":\"47527626\",\"name\":\"Peng Su\"},{\"authorId\":\"50676465\",\"name\":\"Zhengkai Jiang\"},{\"authorId\":\"144740494\",\"name\":\"Peng Gao\"},{\"authorId\":\"2011378\",\"name\":\"Z. Fu\"},{\"authorId\":\"144608002\",\"name\":\"Gerard de Melo\"},{\"authorId\":\"47374777\",\"name\":\"S. Su\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"71ff8e0194d1cc4f810f825a569263fea4056ecd\",\"title\":\"Contrastive Visual-Linguistic Pretraining\",\"url\":\"https://www.semanticscholar.org/paper/71ff8e0194d1cc4f810f825a569263fea4056ecd\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144493079\",\"name\":\"Z. Hu\"},{\"authorId\":\"1754240987\",\"name\":\"Jielong Wei\"},{\"authorId\":\"2639734\",\"name\":\"Qingbao Huang\"},{\"authorId\":\"1904290800\",\"name\":\"Hanyu Liang\"},{\"authorId\":\"1908173213\",\"name\":\"Xingmao Zhang\"},{\"authorId\":\"1901543027\",\"name\":\"Qingguang Liu\"}],\"doi\":\"10.1109/DSC50466.2020.00040\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2ad3b719a1a0868c29dbf72e81c8c3d226196c28\",\"title\":\"Graph Convolutional Network for Visual Question Answering Based on Fine-grained Question Representation\",\"url\":\"https://www.semanticscholar.org/paper/2ad3b719a1a0868c29dbf72e81c8c3d226196c28\",\"venue\":\"2020 IEEE Fifth International Conference on Data Science in Cyberspace (DSC)\",\"year\":2020},{\"arxivId\":\"2002.06800\",\"authors\":[{\"authorId\":\"9208016\",\"name\":\"Aakansha Mishra\"},{\"authorId\":\"47583423\",\"name\":\"A. Anand\"},{\"authorId\":\"46401518\",\"name\":\"Prithwijit Guha\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206913\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"212c2d71f9f404bcbb3cfe8bc35e5e1ea25076c5\",\"title\":\"CQ-VQA: Visual Question Answering on Categorized Questions\",\"url\":\"https://www.semanticscholar.org/paper/212c2d71f9f404bcbb3cfe8bc35e5e1ea25076c5\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020}],\"corpusId\":12913776,\"doi\":\"10.1109/ICCV.2017.285\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":50,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"fe466e84fa2e838adc3c37ee327cd68004ae08fe\",\"references\":[{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1709589\",\"name\":\"Graham Cormode\"},{\"authorId\":\"1836901\",\"name\":\"Marios Hadjieleftheriou\"}],\"doi\":\"10.14778/1454159.1454225\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c044e893d7055327e2971a9a9b65a8c764ca174\",\"title\":\"Finding frequent items in data streams\",\"url\":\"https://www.semanticscholar.org/paper/1c044e893d7055327e2971a9a9b65a8c764ca174\",\"venue\":\"Proc. VLDB Endow.\",\"year\":2008},{\"arxivId\":\"1511.03416\",\"authors\":[{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"50499889\",\"name\":\"O. Groth\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2016.540\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"def584565d05d6a8ba94de6621adab9e301d375d\",\"title\":\"Visual7W: Grounded Question Answering in Images\",\"url\":\"https://www.semanticscholar.org/paper/def584565d05d6a8ba94de6621adab9e301d375d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"},{\"authorId\":\"34699434\",\"name\":\"A. Ng\"}],\"doi\":\"10.1162/tacl_a_00177\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0ca7d208ff8d81377e0eaa9723820aeae7a7322d\",\"title\":\"Grounded Compositional Semantics for Finding and Describing Images with Sentences\",\"url\":\"https://www.semanticscholar.org/paper/0ca7d208ff8d81377e0eaa9723820aeae7a7322d\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2014},{\"arxivId\":\"1505.00468\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-016-0966-6\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"title\":\"VQA: Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fad611e35b3731740b4d8b754241e77add5a70b9\",\"title\":\"Multimodal Neural Language Models\",\"url\":\"https://www.semanticscholar.org/paper/fad611e35b3731740b4d8b754241e77add5a70b9\",\"venue\":\"ICML\",\"year\":2014},{\"arxivId\":\"1409.1259\",\"authors\":[{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"3158246\",\"name\":\"B. V. Merrienboer\"},{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":\"10.3115/v1/W14-4012\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1eb09fecd75eb27825dce4f964b97f4f5cc399d7\",\"title\":\"On the Properties of Neural Machine Translation: Encoder-Decoder Approaches\",\"url\":\"https://www.semanticscholar.org/paper/1eb09fecd75eb27825dce4f964b97f4f5cc399d7\",\"venue\":\"SSST@EMNLP\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J.-H. Kim\"},{\"authorId\":null,\"name\":\"K.-W. On\"},{\"authorId\":null,\"name\":\"J. Kim\"},{\"authorId\":null,\"name\":\"J.-W. Ha\"},{\"authorId\":null,\"name\":\"B.-T. Zhang\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Hadamard Product for Low-rank Bilinear Pooling\",\"url\":\"\",\"venue\":\"5th International Conference on Learning Representations,\",\"year\":2017},{\"arxivId\":\"1511.05234\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1007/978-3-319-46478-7_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1cf6bc0866226c1f8e282463adc8b75d92fba9bb\",\"title\":\"Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1cf6bc0866226c1f8e282463adc8b75d92fba9bb\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48881927\",\"name\":\"R. Li\"},{\"authorId\":\"1729056\",\"name\":\"J. Jia\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"269546925f0fd457b31c13c2870343b0aed761dc\",\"title\":\"Visual Question Answering with Question Representation Update (QRU)\",\"url\":\"https://www.semanticscholar.org/paper/269546925f0fd457b31c13c2870343b0aed761dc\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1511.07394\",\"authors\":[{\"authorId\":\"143953573\",\"name\":\"K. Shih\"},{\"authorId\":\"37415643\",\"name\":\"S. Singh\"},{\"authorId\":\"2433269\",\"name\":\"Derek Hoiem\"}],\"doi\":\"10.1109/CVPR.2016.499\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"175e9bb50cc062c6c1742a5d90c8dfe31d2e4e22\",\"title\":\"Where to Look: Focus Regions for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/175e9bb50cc062c6c1742a5d90c8dfe31d2e4e22\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1601.01705\",\"authors\":[{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"38666915\",\"name\":\"D. Klein\"}],\"doi\":\"10.18653/v1/N16-1181\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"75ddc7ee15be14013a3462c01b38b0548486fbcb\",\"title\":\"Learning to Compose Neural Networks for Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/75ddc7ee15be14013a3462c01b38b0548486fbcb\",\"venue\":\"HLT-NAACL\",\"year\":2016},{\"arxivId\":\"1606.01455\",\"authors\":[{\"authorId\":\"2684967\",\"name\":\"J. Kim\"},{\"authorId\":\"3226948\",\"name\":\"Sang-Woo Lee\"},{\"authorId\":\"3422869\",\"name\":\"Dong-Hyun Kwak\"},{\"authorId\":\"2939188\",\"name\":\"Min-Oh Heo\"},{\"authorId\":\"2947441\",\"name\":\"J. Kim\"},{\"authorId\":\"2577039\",\"name\":\"Jung-Woo Ha\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1afb710a5b35a2352a6495e4bf6eef66808daf1b\",\"title\":\"Multimodal Residual Learning for Visual QA\",\"url\":\"https://www.semanticscholar.org/paper/1afb710a5b35a2352a6495e4bf6eef66808daf1b\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Q. Wu\"},{\"authorId\":null,\"name\":\"P. Wang\"},{\"authorId\":null,\"name\":\"C. Shen\"},{\"authorId\":null,\"name\":\"A. Dick\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and A\",\"url\":\"\",\"venue\":\"van den Hengel. Ask me anything: free-form visual question answering based on knowledge from external sources. In CVPR\",\"year\":2016},{\"arxivId\":\"1504.06063\",\"authors\":[{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"11955007\",\"name\":\"Z. Lu\"},{\"authorId\":\"50812138\",\"name\":\"L. Shang\"},{\"authorId\":\"49404233\",\"name\":\"Hang Li\"}],\"doi\":\"10.1109/ICCV.2015.301\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"153d6feb7149e063b33e8ee437b74e4a2def8057\",\"title\":\"Multimodal Convolutional Neural Networks for Matching Image and Sentence\",\"url\":\"https://www.semanticscholar.org/paper/153d6feb7149e063b33e8ee437b74e4a2def8057\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1648075979\",\"name\":\"B. A. R. Kernfach\"},{\"authorId\":\"1648268257\",\"name\":\"Nur IM Sommersemester\"},{\"authorId\":\"1648268256\",\"name\":\"\\u00dcbersicht Franz\\u00f6sisch\"},{\"authorId\":\"1648134774\",\"name\":\"\\u00dcbersicht Italienisch\"}],\"doi\":\"10.1515/9783111697888-004\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fff1b293b45d06c8462021aa6c90c81e743e131b\",\"title\":\"B\",\"url\":\"https://www.semanticscholar.org/paper/fff1b293b45d06c8462021aa6c90c81e743e131b\",\"venue\":\"Edinburgh Medical and Surgical Journal\",\"year\":1824},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50477565\",\"name\":\"L. Tucker\"}],\"doi\":\"10.1007/BF02289464\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"6661789de63b3cebe2eafdd7e9e7a316ad1f0b8f\",\"title\":\"Some mathematical notes on three-mode factor analysis\",\"url\":\"https://www.semanticscholar.org/paper/6661789de63b3cebe2eafdd7e9e7a316ad1f0b8f\",\"venue\":\"Psychometrika\",\"year\":1966},{\"arxivId\":\"1602.07332\",\"authors\":[{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"50499889\",\"name\":\"O. Groth\"},{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"1382195702\",\"name\":\"Kenji Hata\"},{\"authorId\":\"40591424\",\"name\":\"J. Kravitz\"},{\"authorId\":\"6000646\",\"name\":\"Stephanie Chen\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"1388344504\",\"name\":\"David A. Shamma\"},{\"authorId\":\"1379506718\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-016-0981-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"title\":\"Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations\",\"url\":\"https://www.semanticscholar.org/paper/afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1505.02074\",\"authors\":[{\"authorId\":\"2540599\",\"name\":\"Mengye Ren\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"62a956d7600b10ca455076cd56e604dfd106072a\",\"title\":\"Exploring Models and Data for Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/62a956d7600b10ca455076cd56e604dfd106072a\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1745732\",\"name\":\"M. Charikar\"},{\"authorId\":\"50053975\",\"name\":\"Kevin C. Chen\"},{\"authorId\":\"1398716192\",\"name\":\"Martin Farach-Colton\"}],\"doi\":\"10.1007/3-540-45465-9_59\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"24763030fb1e9813dad51d28bea9c5d1414f9cda\",\"title\":\"Finding Frequent Items in Data Streams\",\"url\":\"https://www.semanticscholar.org/paper/24763030fb1e9813dad51d28bea9c5d1414f9cda\",\"venue\":\"ICALP\",\"year\":2002},{\"arxivId\":\"1511.02274\",\"authors\":[{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"46234526\",\"name\":\"Alex Smola\"}],\"doi\":\"10.1109/CVPR.2016.10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c1890864c1c2b750f48316dc8b650ba4772adc5\",\"title\":\"Stacked Attention Networks for Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2c1890864c1c2b750f48316dc8b650ba4772adc5\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1504.07889\",\"authors\":[{\"authorId\":\"2144284\",\"name\":\"Tsung-Yu Lin\"},{\"authorId\":\"2895705\",\"name\":\"Aruni RoyChowdhury\"},{\"authorId\":\"35208858\",\"name\":\"Subhransu Maji\"}],\"doi\":\"10.1109/ICCV.2015.170\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d3f789a56dca288b2c8e23ef047a2b342184950\",\"title\":\"Bilinear CNN Models for Fine-Grained Visual Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3d3f789a56dca288b2c8e23ef047a2b342184950\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1511.06973\",\"authors\":[{\"authorId\":\"34902783\",\"name\":\"Qi Wu\"},{\"authorId\":\"48319305\",\"name\":\"P. Wang\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2016.500\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"20dbdf02497aa84510970d0f5e8b599073bca1bc\",\"title\":\"Ask Me Anything: Free-Form Visual Question Answering Based on Knowledge from External Sources\",\"url\":\"https://www.semanticscholar.org/paper/20dbdf02497aa84510970d0f5e8b599073bca1bc\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1744364\",\"name\":\"T. Kolda\"},{\"authorId\":\"31431661\",\"name\":\"B. Bader\"}],\"doi\":\"10.1137/07070111X\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"87e43e9eba01a4eb03436c9946bf6aa031a5d5af\",\"title\":\"Tensor Decompositions and Applications\",\"url\":\"https://www.semanticscholar.org/paper/87e43e9eba01a4eb03436c9946bf6aa031a5d5af\",\"venue\":\"SIAM Rev.\",\"year\":2009},{\"arxivId\":\"1606.01847\",\"authors\":[{\"authorId\":\"50599725\",\"name\":\"A. Fukui\"},{\"authorId\":\"3422202\",\"name\":\"Dong Huk Park\"},{\"authorId\":\"3422876\",\"name\":\"Daylen Yang\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.18653/v1/D16-1044\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"fddc15480d086629b960be5bff96232f967f2252\",\"title\":\"Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/fddc15480d086629b960be5bff96232f967f2252\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":\"1606.00061\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"145743311\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b\",\"title\":\"Hierarchical Question-Image Co-Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"H. Xu\"},{\"authorId\":null,\"name\":\"K. Saenko\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Ask\",\"url\":\"\",\"venue\":\"attend and answer: Exploring question-guided spatial attention for visual question answering. In ECCV, pages 451\\u2013466\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144535340\",\"name\":\"Fei Yan\"},{\"authorId\":\"1712041\",\"name\":\"K. Mikolajczyk\"}],\"doi\":\"10.1109/CVPR.2015.7298966\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"efb0e69bc640171d1f115bb286d865bec6f21a7f\",\"title\":\"Deep correlation for matching images and text\",\"url\":\"https://www.semanticscholar.org/paper/efb0e69bc640171d1f115bb286d865bec6f21a7f\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1605.02697\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":\"10.1007/s11263-017-1038-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f7ddf708442dad7ed2978658b101c797c7c10220\",\"title\":\"Ask Your Neurons: A Deep Learning Approach to Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f7ddf708442dad7ed2978658b101c797c7c10220\",\"venue\":\"International Journal of Computer Vision\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3285716\",\"name\":\"Xinye Lin\"},{\"authorId\":\"9527255\",\"name\":\"Yixin Chen\"},{\"authorId\":\"1871246\",\"name\":\"X. Chang\"},{\"authorId\":\"1723807\",\"name\":\"X. Liu\"},{\"authorId\":\"47119262\",\"name\":\"X. Wang\"}],\"doi\":\"10.1145/3161412\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"299b07ec255398c7f9d147cb39d113e4926cc51b\",\"title\":\"SHOW\",\"url\":\"https://www.semanticscholar.org/paper/299b07ec255398c7f9d147cb39d113e4926cc51b\",\"venue\":\"IMWUT\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Y. Zhu\"},{\"authorId\":null,\"name\":\"R. Salakhutdinov\"},{\"authorId\":null,\"name\":\"R. S. Zemel\"},{\"authorId\":null,\"name\":\"A. Torralba\"},{\"authorId\":null,\"name\":\"R. Urtasun\"},{\"authorId\":null,\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Skip - thought vectors Tensor decompositions and applications\",\"url\":\"\",\"venue\":\"SIAM Rev .\",\"year\":null},{\"arxivId\":\"1506.06726\",\"authors\":[{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"2214033\",\"name\":\"Y. Zhu\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6e795c6e9916174ae12349f5dc3f516570c17ce8\",\"title\":\"Skip-Thought Vectors\",\"url\":\"https://www.semanticscholar.org/paper/6e795c6e9916174ae12349f5dc3f516570c17ce8\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1410.8027\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d29e1c4f1c2b079cf6b5dd458fa6cee246955f9\",\"title\":\"Towards a Visual Turing Challenge\",\"url\":\"https://www.semanticscholar.org/paper/3d29e1c4f1c2b079cf6b5dd458fa6cee246955f9\",\"venue\":\"ArXiv\",\"year\":2014}],\"title\":\"MUTAN: Multimodal Tucker Fusion for Visual Question Answering\",\"topics\":[{\"topic\":\"Tucker decomposition\",\"topicId\":\"289865\",\"url\":\"https://www.semanticscholar.org/topic/289865\"},{\"topic\":\"Question answering\",\"topicId\":\"18817\",\"url\":\"https://www.semanticscholar.org/topic/18817\"},{\"topic\":\"Multimodal interaction\",\"topicId\":\"42592\",\"url\":\"https://www.semanticscholar.org/topic/42592\"},{\"topic\":\"Bilinear filtering\",\"topicId\":\"1123309\",\"url\":\"https://www.semanticscholar.org/topic/1123309\"},{\"topic\":\"High-level programming language\",\"topicId\":\"212045\",\"url\":\"https://www.semanticscholar.org/topic/212045\"},{\"topic\":\"Bilinear transform\",\"topicId\":\"397622\",\"url\":\"https://www.semanticscholar.org/topic/397622\"},{\"topic\":\"Oracle Fusion Architecture\",\"topicId\":\"4475853\",\"url\":\"https://www.semanticscholar.org/topic/4475853\"}],\"url\":\"https://www.semanticscholar.org/paper/fe466e84fa2e838adc3c37ee327cd68004ae08fe\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017}\n"