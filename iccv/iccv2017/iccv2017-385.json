"{\"abstract\":\"Existing video event classification approaches suffer from limited human-labeled semantic annotations. Weak semantic annotations can be harvested from Web-knowledge without involving any human interaction. However such weak annotations are noisy, thus can not be effectively utilized without distinguishing its reliability. In this paper, we propose a novel approach to automatically maximize the utility of weak semantic annotations (formalized as the semantic relevance of video shots to the target event) to facilitate video event classification. A novel attention model is designed to determine the attention scores of video shots, where the weak semantic relevance is considered as atten-tional guidance. Specifically, our model jointly optimizes two objectives at different levels. The first one is the classification loss corresponding to video-level groundtruth labels, and the second is the shot-level relevance loss corresponding to weak semantic relevance. We use a long short-term memory (LSTM) layer to capture the temporal information carried by the shots of a video. In each timestep, the LSTM employs the attention model to weight the current shot under the guidance of its weak semantic relevance to the event of interest. Thus, we can automatically exploit weak semantic relevance to assist video event classification. Extensive experiments have been conducted on three complex large-scale video event datasets i.e., MEDTest14, ActivityNet and FCVID. Our approach achieves the state-of-the-art classification performance on all three datasets. The significant performance improvement upon the conventional attention model also demonstrates the effectiveness of our model.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"1724393\",\"name\":\"H. Shen\",\"url\":\"https://www.semanticscholar.org/author/1724393\"},{\"authorId\":null,\"name\":\"Chao Li\",\"url\":null},{\"authorId\":\"39767248\",\"name\":\"Jiewei Cao\",\"url\":\"https://www.semanticscholar.org/author/39767248\"},{\"authorId\":\"145622169\",\"name\":\"Zi Huang\",\"url\":\"https://www.semanticscholar.org/author/145622169\"},{\"authorId\":null,\"name\":\"Lei Zhu\",\"url\":null}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Chao Li\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":\"39767248\",\"name\":\"Jiewei Cao\"},{\"authorId\":\"145622169\",\"name\":\"Zi Huang\"}],\"doi\":\"10.1145/3132847.3133030\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"77e545ee564b0d68dbaa50160996adf63aaf6d99\",\"title\":\"Jointly Modeling Static Visual Appearance and Temporal Pattern for Unsupervised Video Hashing\",\"url\":\"https://www.semanticscholar.org/paper/77e545ee564b0d68dbaa50160996adf63aaf6d99\",\"venue\":\"CIKM\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48116016\",\"name\":\"J. Ren\"},{\"authorId\":\"50550351\",\"name\":\"W. Zhang\"}],\"doi\":\"10.1007/S11760-019-01449-W\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1581301ddb2b9b76c10b31eef101733ffebc46f8\",\"title\":\"CLOSE: Coupled content\\u2013semantic embedding\",\"url\":\"https://www.semanticscholar.org/paper/1581301ddb2b9b76c10b31eef101733ffebc46f8\",\"venue\":\"Signal Image Video Process.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1527097122\",\"name\":\"Y. Li\"},{\"authorId\":\"6681872\",\"name\":\"Chunping Liu\"},{\"authorId\":\"144602988\",\"name\":\"Yi Ji\"},{\"authorId\":\"9359893\",\"name\":\"Shengrong Gong\"}],\"doi\":\"10.1145/3378026\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"083e075864cdf19117f6b5f78db877347e2bca4f\",\"title\":\"Spatio-temporal Deep Residual Network with Hierarchical Attentions for Video Event Recognition\",\"url\":\"https://www.semanticscholar.org/paper/083e075864cdf19117f6b5f78db877347e2bca4f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1905.04757\",\"authors\":[{\"authorId\":\"40940512\",\"name\":\"Jun Liu\"},{\"authorId\":\"3000984\",\"name\":\"Amir Shahroudy\"},{\"authorId\":\"121247048\",\"name\":\"Mauricio Perez\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"},{\"authorId\":\"7667912\",\"name\":\"L. Duan\"},{\"authorId\":\"1711097\",\"name\":\"A. Kot\"}],\"doi\":\"10.1109/TPAMI.2019.2916873\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1b632712cd0d1f14784ba938f135960f71a52e5c\",\"title\":\"NTU RGB+D 120: A Large-Scale Benchmark for 3D Human Activity Understanding\",\"url\":\"https://www.semanticscholar.org/paper/1b632712cd0d1f14784ba938f135960f71a52e5c\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40892875\",\"name\":\"Pascal Mettes\"},{\"authorId\":\"1769315\",\"name\":\"D. Koelma\"},{\"authorId\":\"1647395777\",\"name\":\"Cees Snoek\"}],\"doi\":\"10.1145/3377875\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"83288d73e85700698168f07d7c2290864fa32198\",\"title\":\"Shuffled ImageNet Banks for Video Event Detection and Search\",\"url\":\"https://www.semanticscholar.org/paper/83288d73e85700698168f07d7c2290864fa32198\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2648498\",\"name\":\"Wenlong Xie\"},{\"authorId\":\"1720100\",\"name\":\"H. Yao\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"9162163\",\"name\":\"T. Han\"},{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1109/TMM.2018.2879749\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2c1d06998c57d06a792df88a48f4e52b59f730ff\",\"title\":\"Discovering Latent Discriminative Patterns for Multi-Mode Event Representation\",\"url\":\"https://www.semanticscholar.org/paper/2c1d06998c57d06a792df88a48f4e52b59f730ff\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40506635\",\"name\":\"Hao Song\"},{\"authorId\":\"41172535\",\"name\":\"Che Sun\"},{\"authorId\":\"47149737\",\"name\":\"X. Wu\"},{\"authorId\":\"144292444\",\"name\":\"Mei Chen\"},{\"authorId\":\"2489791\",\"name\":\"Yun-De Jia\"}],\"doi\":\"10.1109/TMM.2019.2950530\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d9f880418a19067a6bcd04a1d81af098f8a3b8a\",\"title\":\"Learning Normal Patterns via Adversarial Attention-Based Autoencoder for Abnormal Event Detection in Videos\",\"url\":\"https://www.semanticscholar.org/paper/3d9f880418a19067a6bcd04a1d81af098f8a3b8a\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46930271\",\"name\":\"Junyu Gao\"},{\"authorId\":\"1907582\",\"name\":\"T. Zhang\"},{\"authorId\":\"145194969\",\"name\":\"C. Xu\"}],\"doi\":\"10.1145/3240508.3240566\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb904609f211216a98bdab0a6d12c2f82ef89b0f\",\"title\":\"Watch, Think and Attend: End-to-End Video Classification via Dynamic Knowledge Evolution Modeling\",\"url\":\"https://www.semanticscholar.org/paper/eb904609f211216a98bdab0a6d12c2f82ef89b0f\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39974958\",\"name\":\"T. Yu\"},{\"authorId\":\"46660013\",\"name\":\"L. Wang\"},{\"authorId\":\"46181112\",\"name\":\"Chaoxu Guo\"},{\"authorId\":\"1909131\",\"name\":\"Huxiang Gu\"},{\"authorId\":\"1683738\",\"name\":\"S. Xiang\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.1016/j.patcog.2018.07.033\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0bbee095fc18a34e6bce72c51cea8f06cb5f4da0\",\"title\":\"Pseudo low rank video representation\",\"url\":\"https://www.semanticscholar.org/paper/0bbee095fc18a34e6bce72c51cea8f06cb5f4da0\",\"venue\":\"Pattern Recognit.\",\"year\":2019}],\"corpusId\":2015745,\"doi\":\"10.1109/ICCV.2017.394\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"6ae53b5837f6e6ca975dcb7af53ef51ac820e3a7\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"2992579\",\"name\":\"Hamid Izadinia\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1007/978-3-642-33765-9_31\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"40493e58880b5bc51e38d2831f0a4e6c1b01bde8\",\"title\":\"Recognizing Complex Events Using Large Margin Joint Low-Level Event Model\",\"url\":\"https://www.semanticscholar.org/paper/40493e58880b5bc51e38d2831f0a4e6c1b01bde8\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":\"1606.05032\",\"authors\":[{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":\"48993722\",\"name\":\"Wei-Lun Chen\"},{\"authorId\":\"150350159\",\"name\":\"Yadan Luo\"},{\"authorId\":\"38083193\",\"name\":\"F. Shen\"},{\"authorId\":\"15316116\",\"name\":\"J. Shao\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1145/2964284.2964319\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7573ff84d71de19fe7d387bb4a6de73cb28402f4\",\"title\":\"Zero-Shot Hashing via Transferring Supervised Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/7573ff84d71de19fe7d387bb4a6de73cb28402f4\",\"venue\":\"ACM Multimedia\",\"year\":2016},{\"arxivId\":\"1505.00315\",\"authors\":[{\"authorId\":\"34066479\",\"name\":\"Vignesh Ramanathan\"},{\"authorId\":\"3355264\",\"name\":\"Kevin D. Tang\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/ICCV.2015.508\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"16fdd6d842475e6fbe58fc809beabbed95f0642e\",\"title\":\"Learning Temporal Embeddings for Complex Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/16fdd6d842475e6fbe58fc809beabbed95f0642e\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1405.3531\",\"authors\":[{\"authorId\":\"1764761\",\"name\":\"K. Chatfield\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.5244/C.28.6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"14d9be7962a4ec5a6e55755f4c7588ea00793652\",\"title\":\"Return of the Devil in the Details: Delving Deep into Convolutional Nets\",\"url\":\"https://www.semanticscholar.org/paper/14d9be7962a4ec5a6e55755f4c7588ea00793652\",\"venue\":\"BMVC\",\"year\":2014},{\"arxivId\":\"1512.07155\",\"authors\":[{\"authorId\":\"2863531\",\"name\":\"Shugao Ma\"},{\"authorId\":\"3298267\",\"name\":\"Sarah Adel Bargal\"},{\"authorId\":\"1701293\",\"name\":\"J. Zhang\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"}],\"doi\":\"10.1016/j.patcog.2017.01.027\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ba29ba8ec180690fca702ad5d516c3e43a7f0bb8\",\"title\":\"Do less and achieve more: Training CNNs for action recognition utilizing action images from the Web\",\"url\":\"https://www.semanticscholar.org/paper/ba29ba8ec180690fca702ad5d516c3e43a7f0bb8\",\"venue\":\"Pattern Recognit.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"}],\"doi\":\"10.1007/s11263-005-1838-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d2fb2fa53021b2776da0fb8b53c54820ed3982cc\",\"title\":\"On Space-Time Interest Points\",\"url\":\"https://www.semanticscholar.org/paper/d2fb2fa53021b2776da0fb8b53c54820ed3982cc\",\"venue\":\"International Journal of Computer Vision\",\"year\":2005},{\"arxivId\":\"1608.00859\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-319-46484-8_2\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"title\":\"Temporal Segment Networks: Towards Good Practices for Deep Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46651287\",\"name\":\"C. Li\"},{\"authorId\":\"144794678\",\"name\":\"Zi Huang\"},{\"authorId\":\"144757965\",\"name\":\"Y. Yang\"},{\"authorId\":\"39767248\",\"name\":\"Jiewei Cao\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1109/TIP.2017.2670782\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"390593c6befa918e72fe72efaa367a9f5d36539f\",\"title\":\"Hierarchical Latent Concept Discovery for Video Event Detection\",\"url\":\"https://www.semanticscholar.org/paper/390593c6befa918e72fe72efaa367a9f5d36539f\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/CVPR.2015.7298698\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"0a28efacb92d16e6e0dd4d87b5aca91b28be8853\",\"title\":\"ActivityNet: A large-scale video benchmark for human activity understanding\",\"url\":\"https://www.semanticscholar.org/paper/0a28efacb92d16e6e0dd4d87b5aca91b28be8853\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/ICCV.2013.453\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6d934149644f048e176630c9ee3daed7fbe16c72\",\"title\":\"ACTIVE: Activity Concept Transitions in Video Event Classification\",\"url\":\"https://www.semanticscholar.org/paper/6d934149644f048e176630c9ee3daed7fbe16c72\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144474750\",\"name\":\"Subhabrata Bhattacharya\"},{\"authorId\":\"3222250\",\"name\":\"M. Kalayeh\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/CVPR.2014.287\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3affcfdda53cc090af03cee5896f764a253b093c\",\"title\":\"Recognition of Complex Events: Exploiting Temporal Dynamics between Underlying Concepts\",\"url\":\"https://www.semanticscholar.org/paper/3affcfdda53cc090af03cee5896f764a253b093c\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1601.03679\",\"authors\":[{\"authorId\":\"144950946\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"},{\"authorId\":\"2062835\",\"name\":\"Guodong Long\"},{\"authorId\":\"32076894\",\"name\":\"C. Zhang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"20767ca3b932cbc7b8112db21980d7b9b3ea43a3\",\"title\":\"Dynamic Concept Composition for Zero-Example Event Detection\",\"url\":\"https://www.semanticscholar.org/paper/20767ca3b932cbc7b8112db21980d7b9b3ea43a3\",\"venue\":\"AAAI\",\"year\":2016},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144927151\",\"name\":\"Mike Schuster\"},{\"authorId\":\"48099761\",\"name\":\"K. Paliwal\"}],\"doi\":\"10.1109/78.650093\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e23c34414e66118ecd9b08cf0cd4d016f59b0b85\",\"title\":\"Bidirectional recurrent neural networks\",\"url\":\"https://www.semanticscholar.org/paper/e23c34414e66118ecd9b08cf0cd4d016f59b0b85\",\"venue\":\"IEEE Trans. Signal Process.\",\"year\":1997},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8678448\",\"name\":\"M. Dorst\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bcae70dce393c1796d4f15c7b8bbf0ed6f468be1\",\"title\":\"Distinctive Image Features from Scale-Invariant Keypoints\",\"url\":\"https://www.semanticscholar.org/paper/bcae70dce393c1796d4f15c7b8bbf0ed6f468be1\",\"venue\":\"\",\"year\":2011},{\"arxivId\":\"1310.4546\",\"authors\":[{\"authorId\":null,\"name\":\"Tomas Mikolov\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"38644044\",\"name\":\"Kai Chen\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"87f40e6f3022adbc1f1905e3e506abad05a9964f\",\"title\":\"Distributed Representations of Words and Phrases and their Compositionality\",\"url\":\"https://www.semanticscholar.org/paper/87f40e6f3022adbc1f1905e3e506abad05a9964f\",\"venue\":\"NIPS\",\"year\":2013},{\"arxivId\":\"1510.06939\",\"authors\":[{\"authorId\":\"143798882\",\"name\":\"Mihir Jain\"},{\"authorId\":\"1738975\",\"name\":\"J. C. V. Gemert\"},{\"authorId\":\"1722052\",\"name\":\"Thomas Mensink\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1109/ICCV.2015.521\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"23eed412efdfdd5d798892a8d6ec5f9273a3952d\",\"title\":\"Objects2action: Classifying and Localizing Actions without Any Video Example\",\"url\":\"https://www.semanticscholar.org/paper/23eed412efdfdd5d798892a8d6ec5f9273a3952d\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1409.0575\",\"authors\":[{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"71309570\",\"name\":\"H. Su\"},{\"authorId\":\"2285165\",\"name\":\"J. Krause\"},{\"authorId\":\"145031342\",\"name\":\"S. Satheesh\"},{\"authorId\":\"145423516\",\"name\":\"S. Ma\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-015-0816-y\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"title\":\"ImageNet Large Scale Visual Recognition Challenge\",\"url\":\"https://www.semanticscholar.org/paper/e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":\"1406.6247\",\"authors\":[{\"authorId\":\"3255983\",\"name\":\"V. Mnih\"},{\"authorId\":\"2801204\",\"name\":\"N. Heess\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8a756d4d25511d92a45d0f4545fa819de993851d\",\"title\":\"Recurrent Models of Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/8a756d4d25511d92a45d0f4545fa819de993851d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. G. Hauptmann L. Jiang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Snoek . Objects 2 action : Classifying and localizing actions without any video example\",\"url\":\"\",\"venue\":\"ICCV , pages 4588\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3280656\",\"name\":\"Litao Yu\"},{\"authorId\":\"49308062\",\"name\":\"Y. Yang\"},{\"authorId\":\"145622169\",\"name\":\"Zi Huang\"},{\"authorId\":\"49830854\",\"name\":\"P. Wang\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1109/TIP.2016.2614136\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0b909a96db381eacadaa41103c68bb136652a515\",\"title\":\"Web Video Event Recognition by Semantic Analysis from Ubiquitous Documents.\",\"url\":\"https://www.semanticscholar.org/paper/0b909a96db381eacadaa41103c68bb136652a515\",\"venue\":\"IEEE transactions on image processing : a publication of the IEEE Signal Processing Society\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1162/neco.1997.9.8.1735\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"title\":\"Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"venue\":\"Neural Computation\",\"year\":1997},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"35350470\",\"name\":\"Yue Gao\"},{\"authorId\":\"48386678\",\"name\":\"X. Zhu\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1109/TMM.2014.2323014\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d4ab29decccb72ef944f9b2150106e595bf03345\",\"title\":\"Exploiting Web Images for Semantic Video Indexing Via Robust Sample-Specific Loss\",\"url\":\"https://www.semanticscholar.org/paper/d4ab29decccb72ef944f9b2150106e595bf03345\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2014},{\"arxivId\":\"1603.03925\",\"authors\":[{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2016.503\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bf55591e09b58ea9ce8d66110d6d3000ee804bdd\",\"title\":\"Image Captioning with Semantic Attention\",\"url\":\"https://www.semanticscholar.org/paper/bf55591e09b58ea9ce8d66110d6d3000ee804bdd\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1301.3781\",\"authors\":[{\"authorId\":null,\"name\":\"Tomas Mikolov\"},{\"authorId\":\"38644044\",\"name\":\"Kai Chen\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"330da625c15427c6e42ccfa3b747fb29e5835bf0\",\"title\":\"Efficient Estimation of Word Representations in Vector Space\",\"url\":\"https://www.semanticscholar.org/paper/330da625c15427c6e42ccfa3b747fb29e5835bf0\",\"venue\":\"ICLR\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144950946\",\"name\":\"Xiaojun Chang\"},{\"authorId\":null,\"name\":\"Yi Yang\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"},{\"authorId\":\"40508553\",\"name\":\"Y. Yu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"45815fb24d9d699f3ac2ba8b2481ee3f80bd477b\",\"title\":\"Complex Event Detection using Semantic Saliency and Nearly-Isotonic SVM\",\"url\":\"https://www.semanticscholar.org/paper/45815fb24d9d699f3ac2ba8b2481ee3f80bd477b\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"2976163\",\"name\":\"Kuiyuan Yang\"},{\"authorId\":null,\"name\":\"Yi Yang\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2016.106\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"26201e1b76f276187e31c7db84eab0bfcda01102\",\"title\":\"You Lead, We Exceed: Labor-Free Video Concept Learning by Jointly Exploiting Web Videos and Images\",\"url\":\"https://www.semanticscholar.org/paper/26201e1b76f276187e31c7db84eab0bfcda01102\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"I. Sutskever A. Krizhevsky\"},{\"authorId\":null,\"name\":\"G. E. Hinton\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Exploit - ing feature and class relationships in video categorization with regularized deep neural networks\",\"url\":\"\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence , to appear\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143845796\",\"name\":\"Jeffrey Pennington\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.3115/v1/D14-1162\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"title\":\"Glove: Global Vectors for Word Representation\",\"url\":\"https://www.semanticscholar.org/paper/f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Krizhevsky\"},{\"authorId\":null,\"name\":\"I. Sutskever\"},{\"authorId\":null,\"name\":\"G. E. Hinton\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Exploit - ing feature and class relationships in video categorization with regularized deep neural networks\",\"url\":\"\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence , to appear\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2909350\",\"name\":\"Alexander Kl\\u00e4ser\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"1689269\",\"name\":\"C. Liu\"}],\"doi\":\"10.1109/CVPR.2011.5995407\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3afbb0e64fcb70496b44b30b76fac9456cc51e34\",\"title\":\"Action recognition by dense trajectories\",\"url\":\"https://www.semanticscholar.org/paper/3afbb0e64fcb70496b44b30b76fac9456cc51e34\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39978626\",\"name\":\"Lu Jiang\"},{\"authorId\":\"143642520\",\"name\":\"Shoou-I Yu\"},{\"authorId\":\"1803714\",\"name\":\"D. Meng\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"},{\"authorId\":\"1706595\",\"name\":\"T. Mitamura\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1145/2733373.2806237\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"98d95d10f293cad7e8e0dd45b4d04617d18be6c6\",\"title\":\"Fast and Accurate Content-based Semantic Search in 100M Internet Videos\",\"url\":\"https://www.semanticscholar.org/paper/98d95d10f293cad7e8e0dd45b4d04617d18be6c6\",\"venue\":\"ACM Multimedia\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"144474750\",\"name\":\"Subhabrata Bhattacharya\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1007/s13735-012-0024-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9f9c54f724ac7d6f910bac2da76b9e53e89fb6e8\",\"title\":\"High-level event recognition in unconstrained videos\",\"url\":\"https://www.semanticscholar.org/paper/9f9c54f724ac7d6f910bac2da76b9e53e89fb6e8\",\"venue\":\"International Journal of Multimedia Information Retrieval\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"3111912\",\"name\":\"Navdeep Jaitly\"},{\"authorId\":\"40360972\",\"name\":\"Abdel-rahman Mohamed\"}],\"doi\":\"10.1109/ASRU.2013.6707742\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1149888d75af4ed5dffc25731b875651c3ccdeb2\",\"title\":\"Hybrid speech recognition with Deep Bidirectional LSTM\",\"url\":\"https://www.semanticscholar.org/paper/1149888d75af4ed5dffc25731b875651c3ccdeb2\",\"venue\":\"2013 IEEE Workshop on Automatic Speech Recognition and Understanding\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"1778989\",\"name\":\"Martin Szummer\"},{\"authorId\":\"47139824\",\"name\":\"A. Fitzgibbon\"}],\"doi\":\"10.1007/978-3-642-15549-9_56\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f6908334853988faf987be40024ba88480170441\",\"title\":\"Efficient Object Category Recognition Using Classemes\",\"url\":\"https://www.semanticscholar.org/paper/f6908334853988faf987be40024ba88480170441\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":\"10.1109/CVPR.2016.339\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d9671ec394ec374021702642713aa634b8556312\",\"title\":\"Harnessing Object and Scene Semantics for Large-Scale Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/d9671ec394ec374021702642713aa634b8556312\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39978626\",\"name\":\"Lu Jiang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"},{\"authorId\":\"145353524\",\"name\":\"Guang Xiang\"}],\"doi\":\"10.1145/2393347.2393412\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8ebbd8db37893b7b232858d7903aa051184a21de\",\"title\":\"Leveraging high-level and low-level features for multimedia event detection\",\"url\":\"https://www.semanticscholar.org/paper/8ebbd8db37893b7b232858d7903aa051184a21de\",\"venue\":\"ACM Multimedia\",\"year\":2012},{\"arxivId\":\"1409.3215\",\"authors\":[{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"cea967b59209c6be22829699f05b8b1ac4dc092d\",\"title\":\"Sequence to Sequence Learning with Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/cea967b59209c6be22829699f05b8b1ac4dc092d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1509.07845\",\"authors\":[{\"authorId\":\"50702063\",\"name\":\"B. Singh\"},{\"authorId\":\"2257769\",\"name\":\"Xintong Han\"},{\"authorId\":\"144494743\",\"name\":\"Zhe Wu\"},{\"authorId\":\"2852035\",\"name\":\"V. Morariu\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/ICCV.2015.518\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f9419434b8000278a9e559853bd35c6ff46f18b8\",\"title\":\"Selecting Relevant Web Trained Concepts for Automated Event Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/f9419434b8000278a9e559853bd35c6ff46f18b8\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3280656\",\"name\":\"Litao Yu\"},{\"authorId\":\"145622169\",\"name\":\"Zi Huang\"},{\"authorId\":\"39767248\",\"name\":\"Jiewei Cao\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1109/TMM.2016.2557059\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c294a5532729a9c0205886f97d8673bc54d97a53\",\"title\":\"Scalable Video Event Retrieval by Visual State Binary Embedding\",\"url\":\"https://www.semanticscholar.org/paper/c294a5532729a9c0205886f97d8673bc54d97a53\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2016},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1502.08029\",\"authors\":[{\"authorId\":\"145095579\",\"name\":\"L. Yao\"},{\"authorId\":\"1730844\",\"name\":\"Atousa Torabi\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"2482072\",\"name\":\"Nicolas Ballas\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":\"10.1109/ICCV.2015.512\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"5f425b7abf2ed3172ed060df85bb1885860a297e\",\"title\":\"Describing Videos by Exploiting Temporal Structure\",\"url\":\"https://www.semanticscholar.org/paper/5f425b7abf2ed3172ed060df85bb1885860a297e\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"48246959\",\"name\":\"Naiyan Wang\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"},{\"authorId\":\"1739816\",\"name\":\"D. Yeung\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1109/CVPR.2015.7298872\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3de050d1707524512eeab99780df3cbdee09670c\",\"title\":\"DevNet: A Deep Event Network for multimedia event detection and evidence recounting\",\"url\":\"https://www.semanticscholar.org/paper/3de050d1707524512eeab99780df3cbdee09670c\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012}],\"title\":\"Leveraging Weak Semantic Relevance for Complex Video Event Classification\",\"topics\":[{\"topic\":\"Relevance\",\"topicId\":\"503\",\"url\":\"https://www.semanticscholar.org/topic/503\"},{\"topic\":\"Long short-term memory\",\"topicId\":\"117199\",\"url\":\"https://www.semanticscholar.org/topic/117199\"},{\"topic\":\"Performance\",\"topicId\":\"3097\",\"url\":\"https://www.semanticscholar.org/topic/3097\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Smoothing\",\"topicId\":\"16185\",\"url\":\"https://www.semanticscholar.org/topic/16185\"},{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"}],\"url\":\"https://www.semanticscholar.org/paper/6ae53b5837f6e6ca975dcb7af53ef51ac820e3a7\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017}\n"