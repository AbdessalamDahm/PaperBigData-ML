"{\"abstract\":\"Current state-of-the-art approaches for spatio-temporal action localization rely on detections at the frame level that are then linked or tracked across time. In this paper, we leverage the temporal continuity of videos instead of operating at the frame level. We propose the ACtion Tubelet detector (ACT-detector) that takes as input a sequence of frames and outputs tubelets, i.e., sequences of bounding boxes with associated scores. The same way state-of-the-art object detectors rely on anchor boxes, our ACT-detector is based on anchor cuboids. We build upon the SSD framework [19]. Convolutional features are extracted for each frame, while scores and regressions are based on the temporal stacking of these features, thus exploiting information from a sequence. Our experimental results show that leveraging sequences offrantes significantly improves detection performance over using individual frames. The gain of our tubelet detector can be explained by both more accurate scores and more precise localization. Our ACT-detector outperforms the state-of-the-art methods for frame-mAP and video-mAP on the J-HMDB [12] and UCF-101 [31] datasets, in particular at high overlap thresholds.\",\"arxivId\":\"1705.01861\",\"authors\":[{\"authorId\":\"1881509\",\"name\":\"Vicky Kalogeiton\",\"url\":\"https://www.semanticscholar.org/author/1881509\"},{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\",\"url\":\"https://www.semanticscholar.org/author/2492127\"},{\"authorId\":\"143865718\",\"name\":\"V. Ferrari\",\"url\":\"https://www.semanticscholar.org/author/143865718\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\",\"url\":\"https://www.semanticscholar.org/author/2462253\"}],\"citationVelocity\":53,\"citations\":[{\"arxivId\":\"1903.00304\",\"authors\":[{\"authorId\":\"145949475\",\"name\":\"B. Hu\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"144530541\",\"name\":\"T. Cham\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f982a23ba54201fa650e2d943fe14b271d353ada\",\"title\":\"Progress Regression RNN for Online Spatial-Temporal Action Localization in Unconstrained Videos\",\"url\":\"https://www.semanticscholar.org/paper/f982a23ba54201fa650e2d943fe14b271d353ada\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1808.00297\",\"authors\":[{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":null,\"name\":\"Suman Saha\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":\"10.1007/978-3-030-20876-9_27\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"563fcc87934a4e6c8843c81b58273cb366918bfb\",\"title\":\"TraMNet - Transition Matrix Network for Efficient Action Tube Proposals\",\"url\":\"https://www.semanticscholar.org/paper/563fcc87934a4e6c8843c81b58273cb366918bfb\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"89507637\",\"name\":\"X. Chen\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"}],\"doi\":\"10.1109/VCIP.2018.8698697\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"ff7282988a5173d02203abc5d3a2ae898768ce60\",\"title\":\"Multi-task CNN Model for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/ff7282988a5173d02203abc5d3a2ae898768ce60\",\"venue\":\"2018 IEEE Visual Communications and Image Processing (VCIP)\",\"year\":2018},{\"arxivId\":\"1808.07712\",\"authors\":[{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":null,\"name\":\"Suman Saha\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":\"10.1007/978-3-030-11015-4_11\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7ffcf3435b1e7a984836bac25800481fb5140d97\",\"title\":\"Predicting Action Tubes\",\"url\":\"https://www.semanticscholar.org/paper/7ffcf3435b1e7a984836bac25800481fb5140d97\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1564031469\",\"name\":\"Aayush Jung Rana\"},{\"authorId\":\"82021814\",\"name\":\"Praveen Tirupattur\"},{\"authorId\":\"9247631\",\"name\":\"M. N. Rizve\"},{\"authorId\":\"7839191\",\"name\":\"K. Duarte\"},{\"authorId\":\"2935412\",\"name\":\"U. Demir\"},{\"authorId\":\"2116440\",\"name\":\"Y. Rawat\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d4b8626336566f34c7e1d17ddf7b144636812c18\",\"title\":\"An Online System for Real-Time Activity Detection in Untrimmed Surveillance Videos\",\"url\":\"https://www.semanticscholar.org/paper/d4b8626336566f34c7e1d17ddf7b144636812c18\",\"venue\":\"TRECVID\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121357290\",\"name\":\"Ruolin Wang\"},{\"authorId\":\"152641281\",\"name\":\"Y. Zhou\"}],\"doi\":\"10.1109/ICIP40778.2020.9190869\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4a343ca82464f8e11aa5626afc7474ab2286ed14\",\"title\":\"A Feature Pair Fusion And Hierarchical Learning Framework For Video Re-Localization\",\"url\":\"https://www.semanticscholar.org/paper/4a343ca82464f8e11aa5626afc7474ab2286ed14\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"2005.04255\",\"authors\":[{\"authorId\":\"2852303\",\"name\":\"Zhishuai Zhang\"},{\"authorId\":\"1474350644\",\"name\":\"Jiyang Gao\"},{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"1604966583\",\"name\":\"Yukai Liu\"},{\"authorId\":\"1838674\",\"name\":\"Dragomir Anguelov\"},{\"authorId\":\"46652068\",\"name\":\"Congcong Li\"}],\"doi\":\"10.1109/cvpr42600.2020.01136\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"230c8e0c7b89310078f9eeaaaa0bae326d7f6e6f\",\"title\":\"STINet: Spatio-Temporal-Interactive Network for Pedestrian Detection and Trajectory Prediction\",\"url\":\"https://www.semanticscholar.org/paper/230c8e0c7b89310078f9eeaaaa0bae326d7f6e6f\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1808.01575\",\"authors\":[{\"authorId\":\"144599697\",\"name\":\"Y. Feng\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"38144094\",\"name\":\"T. Zhang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1007/978-3-030-01264-9_4\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8619ce85b69e6164cb5bb32f225e510a0570bb37\",\"title\":\"Video Re-localization\",\"url\":\"https://www.semanticscholar.org/paper/8619ce85b69e6164cb5bb32f225e510a0570bb37\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"47067803\",\"name\":\"Hao Jiang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"53ff10d5c64f8b753e7ba04c8ab554901eb0e1b0\",\"title\":\"Action 4 D : Online Action Recognition in the Crowd and Clutter Quanzeng\",\"url\":\"https://www.semanticscholar.org/paper/53ff10d5c64f8b753e7ba04c8ab554901eb0e1b0\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145338246\",\"name\":\"F. Yang\"},{\"authorId\":\"1783949\",\"name\":\"Sakriani Sakti\"},{\"authorId\":\"1390531397\",\"name\":\"Wu Yang\"},{\"authorId\":\"1755144\",\"name\":\"Satoshi\"},{\"authorId\":\"122237784\",\"name\":\"Nakamura\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"45f19db1beacdf5753544603e80dfb3ebc7a4a9e\",\"title\":\"Detection Tracking Action Recognition Generate Patches Downscale Multi-label Actions Ultra-high-resolution Aerial Image 2160 x 3840 Patches 608 x 608 Cropping\",\"url\":\"https://www.semanticscholar.org/paper/45f19db1beacdf5753544603e80dfb3ebc7a4a9e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Minah Lee\"},{\"authorId\":null,\"name\":\"Burhan Ahmad Mudassar\"},{\"authorId\":\"40191008\",\"name\":\"Taesik Na\"},{\"authorId\":null,\"name\":\"Saibal Mukhopadhyay\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"bb8321f527569684f0066843ae8231c94a96deb2\",\"title\":\"A Spatiotemporal Pre-processing Network for Activity Recognition under Rain\",\"url\":\"https://www.semanticscholar.org/paper/bb8321f527569684f0066843ae8231c94a96deb2\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"1807.02800\",\"authors\":[{\"authorId\":\"40892875\",\"name\":\"Pascal Mettes\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c7e10cee568b9251c894e002c5304fb1205eb4ea\",\"title\":\"Spatio-Temporal Instance Learning: Action Tubes from Class Supervision\",\"url\":\"https://www.semanticscholar.org/paper/c7e10cee568b9251c894e002c5304fb1205eb4ea\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2010.06647\",\"authors\":[{\"authorId\":\"153634296\",\"name\":\"Matthew Hutchinson\"},{\"authorId\":\"74882299\",\"name\":\"Vijay Gadepally\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"65955a106905afb90a2a2fa74e48c6d6d597892f\",\"title\":\"Video Action Understanding: A Tutorial\",\"url\":\"https://www.semanticscholar.org/paper/65955a106905afb90a2a2fa74e48c6d6d597892f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.00427\",\"authors\":[{\"authorId\":\"2874605\",\"name\":\"X. Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d6d96b6405c1636bb7080ee809c8ec7fa1ada98f\",\"title\":\"Efficient Pipelines for Vision-Based Context Sensing\",\"url\":\"https://www.semanticscholar.org/paper/d6d96b6405c1636bb7080ee809c8ec7fa1ada98f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31965574\",\"name\":\"Minah Lee\"},{\"authorId\":\"2167197\",\"name\":\"B. Mudassar\"},{\"authorId\":\"40191008\",\"name\":\"Taesik Na\"},{\"authorId\":\"144192724\",\"name\":\"S. Mukhopadhyay\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bb8321f527569684f0066843ae8231c94a96deb2\",\"title\":\"N 1 . Backbone 2 . Activity RPN 4 . Activity Classification 3 . ROI Pooling Class Scores Regression C 3 D ROI Pooling GRU Linear CNN res\",\"url\":\"https://www.semanticscholar.org/paper/bb8321f527569684f0066843ae8231c94a96deb2\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21265854\",\"name\":\"N. Chesneau\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d9de669c07c6a8563a135e5c26b6f6432b354a27\",\"title\":\"Learning to Recognize Actions with Weak Supervision. (Reconnaissance d'actions de mani\\u00e8re faiblement supervis\\u00e9e)\",\"url\":\"https://www.semanticscholar.org/paper/d9de669c07c6a8563a135e5c26b6f6432b354a27\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1652110241\",\"name\":\"M. Lee\"},{\"authorId\":\"2167197\",\"name\":\"B. Mudassar\"},{\"authorId\":\"40191008\",\"name\":\"Taesik Na\"},{\"authorId\":\"144192724\",\"name\":\"S. Mukhopadhyay\"}],\"doi\":\"10.1109/DAC18072.2020.9218502\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"541ecd9eef7c7bf0b69f47584678a031d5b5c500\",\"title\":\"WarningNet: A Deep Learning Platform for Early Warning of Task Failures under Input Perturbation for Reliable Autonomous Platforms\",\"url\":\"https://www.semanticscholar.org/paper/541ecd9eef7c7bf0b69f47584678a031d5b5c500\",\"venue\":\"2020 57th ACM/IEEE Design Automation Conference (DAC)\",\"year\":2020},{\"arxivId\":\"1704.01358\",\"authors\":[{\"authorId\":\"145560551\",\"name\":\"Harkirat Singh Behl\"},{\"authorId\":\"145466505\",\"name\":\"M. Sapienza\"},{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":null,\"name\":\"Suman Saha\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"961fd8da3102e9c8696f70375507eee89d37ef61\",\"title\":\"Incremental Tube Construction for Human Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/961fd8da3102e9c8696f70375507eee89d37ef61\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3420479\",\"name\":\"D. Moltisanti\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e1363237a3ddc9a1c9ab9180f09c5bb58df62887\",\"title\":\"y 1 ? ? ? ? ? open jar scoop sugar ? ? ? ? ? ? ?\",\"url\":\"https://www.semanticscholar.org/paper/e1363237a3ddc9a1c9ab9180f09c5bb58df62887\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1811.12248\",\"authors\":[{\"authorId\":\"3105254\",\"name\":\"Yuancheng Ye\"},{\"authorId\":\"38101706\",\"name\":\"Xiaodong Yang\"},{\"authorId\":\"35484757\",\"name\":\"Yingli Tian\"}],\"doi\":\"10.1016/j.jvcir.2018.12.019\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ac360c948a81738b892869fafe950e05cf477618\",\"title\":\"Discovering Spatio-Temporal Action Tubes\",\"url\":\"https://www.semanticscholar.org/paper/ac360c948a81738b892869fafe950e05cf477618\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":\"1905.13417\",\"authors\":[{\"authorId\":\"143629372\",\"name\":\"L. Song\"},{\"authorId\":\"50202110\",\"name\":\"Shiwei Zhang\"},{\"authorId\":\"145015817\",\"name\":\"Gang Yu\"},{\"authorId\":\"144254616\",\"name\":\"Hongbin Sun\"}],\"doi\":\"10.1109/CVPR.2019.01226\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"518512621412fd76d47ef9225a45fcc99d0247d2\",\"title\":\"TACNet: Transition-Aware Context Network for Spatio-Temporal Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/518512621412fd76d47ef9225a45fcc99d0247d2\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1817030\",\"name\":\"Saining Xie\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"1808244\",\"name\":\"J. Huang\"},{\"authorId\":\"144035504\",\"name\":\"Zhuowen Tu\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4fa0d73b8ba114578744c2ebaf610d2ca9694f45\",\"title\":\"Rethinking Spatiotemporal Feature Learning For Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/4fa0d73b8ba114578744c2ebaf610d2ca9694f45\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153057610\",\"name\":\"N. Kumar\"},{\"authorId\":\"1442238004\",\"name\":\"N. Sukavanam\"}],\"doi\":\"10.1007/s00371-019-01777-5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d51842ce814ef9d21c516706c524c27d1707d525\",\"title\":\"Weakly supervised deep network for spatiotemporal localization and detection of human actions in wild conditions\",\"url\":\"https://www.semanticscholar.org/paper/d51842ce814ef9d21c516706c524c27d1707d525\",\"venue\":\"The Visual Computer\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"145905328\",\"name\":\"Kun He\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a50d2245d46ce0595ddbf25ae9acb8513aa70067\",\"title\":\"Text-to-Clip Video Retrieval with Early Fusion and Re-Captioning\",\"url\":\"https://www.semanticscholar.org/paper/a50d2245d46ce0595ddbf25ae9acb8513aa70067\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1712247436\",\"name\":\"Felix Hertlein\"},{\"authorId\":\"153443035\",\"name\":\"D. M\\u00fcnch\"},{\"authorId\":\"144006867\",\"name\":\"M. Arens\"}],\"doi\":\"10.1109/WACVW50321.2020.9096934\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f2da22aa90be9036b60ac7dbe0683c09e7f30a03\",\"title\":\"Context Sensitivity of Spatio-Temporal Activity Detection using Hierarchical Deep Neural Networks in Extended Videos\",\"url\":\"https://www.semanticscholar.org/paper/f2da22aa90be9036b60ac7dbe0683c09e7f30a03\",\"venue\":\"2020 IEEE Winter Applications of Computer Vision Workshops (WACVW)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145731841\",\"name\":\"P. Lei\"},{\"authorId\":\"143856428\",\"name\":\"S. Todorovic\"}],\"doi\":\"10.1109/CVPR.2018.00705\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4bfcedc30c05b68ba109b9ae71db42f1f1985770\",\"title\":\"Temporal Deformable Residual Networks for Action Segmentation in Videos\",\"url\":\"https://www.semanticscholar.org/paper/4bfcedc30c05b68ba109b9ae71db42f1f1985770\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49024484\",\"name\":\"J. Huang\"},{\"authorId\":\"47577022\",\"name\":\"Nannan Li\"},{\"authorId\":\"50289966\",\"name\":\"Thomas H. Li\"},{\"authorId\":\"1390631689\",\"name\":\"Shan Liu\"},{\"authorId\":\"46439321\",\"name\":\"Ge Li\"}],\"doi\":\"10.1109/TCSVT.2019.2923712\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"71780727bad491d006a97ee365c08ea616b707c3\",\"title\":\"Spatial\\u2013Temporal Context-Aware Online Action Detection and Prediction\",\"url\":\"https://www.semanticscholar.org/paper/71780727bad491d006a97ee365c08ea616b707c3\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47930257\",\"name\":\"R. S. C. Oliveira\"}],\"doi\":\"10.25911/5dfc956bbd86c\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"388212b4fbc19e6a685eb929f35a7e1c3c06f814\",\"title\":\"Visual Recognition From Structured Supervision\",\"url\":\"https://www.semanticscholar.org/paper/388212b4fbc19e6a685eb929f35a7e1c3c06f814\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35199438\",\"name\":\"Joshua Gleason\"},{\"authorId\":\"47454520\",\"name\":\"S. Schwarcz\"},{\"authorId\":\"1492122369\",\"name\":\"R. Ranjan\"},{\"authorId\":\"145586343\",\"name\":\"Carlos D. Castillo\"},{\"authorId\":\"1391201966\",\"name\":\"Jun-Cheng Chen\"},{\"authorId\":\"69416958\",\"name\":\"Ramalingam Chellappa\"}],\"doi\":\"10.1109/WACVW50321.2020.9096912\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"789cf1e1e4018b629973f7b4ba8864b71f501518\",\"title\":\"Activity Detection in Untrimmed Videos Using Chunk-based Classifiers\",\"url\":\"https://www.semanticscholar.org/paper/789cf1e1e4018b629973f7b4ba8864b71f501518\",\"venue\":\"2020 IEEE Winter Applications of Computer Vision Workshops (WACVW)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46809347\",\"name\":\"Xuhuan Duan\"},{\"authorId\":\"9173291\",\"name\":\"L. Wang\"},{\"authorId\":\"51262903\",\"name\":\"Changbo Zhai\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"1786361\",\"name\":\"Zhenxing Niu\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\"}],\"doi\":\"10.1109/ICIP.2018.8451692\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"12f7b8de96727f21a0c6733291241388f0fd12a7\",\"title\":\"Joint Spatio-Temporal Action Localization in Untrimmed Videos with Per-Frame Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/12f7b8de96727f21a0c6733291241388f0fd12a7\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"28933059\",\"name\":\"Jiangchuan Wei\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"50130622\",\"name\":\"Yun Yi\"},{\"authorId\":\"8194130\",\"name\":\"Qinyu Li\"},{\"authorId\":\"8312366\",\"name\":\"De-Shuang Huang\"}],\"doi\":\"10.1109/ICIP.2019.8802979\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6c4e7471cd845223b852efe09e5985544332b22a\",\"title\":\"P3D-CTN: Pseudo-3D Convolutional Tube Network for Spatio-Temporal Action Detection in Videos\",\"url\":\"https://www.semanticscholar.org/paper/6c4e7471cd845223b852efe09e5985544332b22a\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1416650467\",\"name\":\"Vida Adeli\"},{\"authorId\":\"1707752\",\"name\":\"E. F. Ersi\"},{\"authorId\":\"1734678\",\"name\":\"A. Harati\"}],\"doi\":\"10.1016/j.imavis.2019.08.009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"da6e00eeee9c068e081e24836b230024eaa2eeae\",\"title\":\"A component-based video content representation for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/da6e00eeee9c068e081e24836b230024eaa2eeae\",\"venue\":\"Image Vis. Comput.\",\"year\":2019},{\"arxivId\":\"1804.07667\",\"authors\":[{\"authorId\":\"2820136\",\"name\":\"Yu-Wei Chao\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"2535887\",\"name\":\"Bryan Seybold\"},{\"authorId\":\"144711958\",\"name\":\"D. Ross\"},{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"}],\"doi\":\"10.1109/CVPR.2018.00124\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e85c01ff4979357b428538c9f224fa4259541c1a\",\"title\":\"Rethinking the Faster R-CNN Architecture for Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/e85c01ff4979357b428538c9f224fa4259541c1a\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21265854\",\"name\":\"N. Chesneau\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"baa7f5ce8fd59da4e70944a0e77b3cf18534b2e8\",\"title\":\"Learning to Recognize Actions with Weak Supervision\",\"url\":\"https://www.semanticscholar.org/paper/baa7f5ce8fd59da4e70944a0e77b3cf18534b2e8\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"117454237\",\"name\":\"Zirui Qiu\"},{\"authorId\":\"144359415\",\"name\":\"J. Sun\"},{\"authorId\":\"51163848\",\"name\":\"Mingyue Guo\"},{\"authorId\":\"21836351\",\"name\":\"Mantao Wang\"},{\"authorId\":\"46334637\",\"name\":\"D. Zhang\"}],\"doi\":\"10.1007/978-981-15-0121-0_1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"71e47cea739e472da47756040e78fdae8bd21752\",\"title\":\"Survey on Deep Learning for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/71e47cea739e472da47756040e78fdae8bd21752\",\"venue\":\"ICPCSEE\",\"year\":2019},{\"arxivId\":\"1901.10364\",\"authors\":[{\"authorId\":\"67344892\",\"name\":\"Federico Landi\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"533aa3d1d990b0916294143d448f895116d825bc\",\"title\":\"Anomaly Locality in Video Surveillance\",\"url\":\"https://www.semanticscholar.org/paper/533aa3d1d990b0916294143d448f895116d825bc\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2003.14065\",\"authors\":[{\"authorId\":\"153216912\",\"name\":\"Dong Li\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1145/3343031.3350978\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8370ba2cd080bbc82925106b9fa6c914928cb90b\",\"title\":\"Long Short-Term Relation Networks for Video Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/8370ba2cd080bbc82925106b9fa6c914928cb90b\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29448130\",\"name\":\"Rico Thomanek\"},{\"authorId\":\"71502945\",\"name\":\"Tony Rolletschke\"},{\"authorId\":\"72743860\",\"name\":\"Benny Platte\"},{\"authorId\":\"120976709\",\"name\":\"Claudia H\\u00f6sel\"},{\"authorId\":\"29334132\",\"name\":\"Christian Roschke\"},{\"authorId\":\"3243773\",\"name\":\"R. Manthey\"},{\"authorId\":\"3282581\",\"name\":\"Manuel Heinzig\"},{\"authorId\":\"36000053\",\"name\":\"R. Vogel\"},{\"authorId\":\"144084779\",\"name\":\"F. Zimmer\"},{\"authorId\":\"1861810\",\"name\":\"M. Vodel\"},{\"authorId\":\"34738835\",\"name\":\"M. Eibl\"},{\"authorId\":\"152432592\",\"name\":\"M. Ritter\"}],\"doi\":\"10.1109/WACVW50321.2020.9096936\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"437466ec6eb15c157d17251b8c118255258ed8f6\",\"title\":\"Real-Time Activity Detection of Human Movement in Videos via Smartphone Based on Synthetic Training Data\",\"url\":\"https://www.semanticscholar.org/paper/437466ec6eb15c157d17251b8c118255258ed8f6\",\"venue\":\"2020 IEEE Winter Applications of Computer Vision Workshops (WACVW)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1756043\",\"name\":\"D. Khosla\"},{\"authorId\":\"16627788\",\"name\":\"Ryan Uhlenbrock\"},{\"authorId\":\"38032135\",\"name\":\"Y. Chen\"}],\"doi\":\"10.1007/978-3-030-03801-4_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0a72ee3970e4299cf912691055a12c5336fb1b68\",\"title\":\"A Low-Power Neuromorphic System for Real-Time Visual Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/0a72ee3970e4299cf912691055a12c5336fb1b68\",\"venue\":\"ISVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403735284\",\"name\":\"P. Medrano\"},{\"authorId\":\"1381227168\",\"name\":\"J. Villadangos\"},{\"authorId\":\"9104575\",\"name\":\"J. J. Astrain\"}],\"doi\":\"10.1109/SENSORS47125.2020.9278883\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"87a633fc8c0ad10f9458fe8d34518c7697f98066\",\"title\":\"UAS: IoT on-line sensors for power line inspection\",\"url\":\"https://www.semanticscholar.org/paper/87a633fc8c0ad10f9458fe8d34518c7697f98066\",\"venue\":\"2020 IEEE Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34041171\",\"name\":\"Akshaya Ramaswamy\"},{\"authorId\":\"3339923\",\"name\":\"K. Seemakurthy\"},{\"authorId\":\"49294154\",\"name\":\"J. Gubbi\"},{\"authorId\":\"21432550\",\"name\":\"B. Purushothaman\"}],\"doi\":\"10.1109/CVPRW50498.2020.00390\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"001ab97faa6b224b52aac252a003e223325e70a2\",\"title\":\"Spatio-temporal action detection and localization using a hierarchical LSTM\",\"url\":\"https://www.semanticscholar.org/paper/001ab97faa6b224b52aac252a003e223325e70a2\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1398447065\",\"name\":\"Sadjad Asghari-Esfeden\"},{\"authorId\":\"1687866\",\"name\":\"M. Sznaier\"},{\"authorId\":\"143867334\",\"name\":\"O. Camps\"}],\"doi\":\"10.1109/WACV45572.2020.9093500\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"51bcb7de98bedf65215910fcfd08555d5eed682a\",\"title\":\"Dynamic Motion Representation for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/51bcb7de98bedf65215910fcfd08555d5eed682a\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3386593\",\"name\":\"X. Dai\"}],\"doi\":\"10.13016/IFOP-IT5W\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0b77a9dd4cd19af8f7822993ed463debccf894ed\",\"title\":\"Modeling Deep Context in Spatial and Temporal Domain\",\"url\":\"https://www.semanticscholar.org/paper/0b77a9dd4cd19af8f7822993ed463debccf894ed\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1881509\",\"name\":\"Vicky Kalogeiton\"},{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"143865718\",\"name\":\"V. Ferrari\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"09926ed62511c340f4540b5bc53cf2480e8063f8\",\"title\":\"Tubelet Detector for Spatio-Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/09926ed62511c340f4540b5bc53cf2480e8063f8\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40812342\",\"name\":\"Yeongtaek Song\"},{\"authorId\":\"1784897\",\"name\":\"Incheol Kim\"}],\"doi\":\"10.3390/s19051085\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"be95dc7acb8e31d118f4693af3cc7c62b8f7d5e7\",\"title\":\"Spatio-Temporal Action Detection in Untrimmed Videos by Using Multimodal Features and Region Proposals\",\"url\":\"https://www.semanticscholar.org/paper/be95dc7acb8e31d118f4693af3cc7c62b8f7d5e7\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1380231577\",\"name\":\"Ching-Kai Tseng\"},{\"authorId\":\"38603660\",\"name\":\"Chien-Chih Liao\"},{\"authorId\":\"2651451\",\"name\":\"Po-Chun Shen\"},{\"authorId\":\"36027402\",\"name\":\"Jiun-In Guo\"}],\"doi\":\"10.1109/ICIP.2019.8802963\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"663dc035804a45460972a9d7fe372dbb6e2ed415\",\"title\":\"Using C3D to Detect Rear Overtaking Behavior\",\"url\":\"https://www.semanticscholar.org/paper/663dc035804a45460972a9d7fe372dbb6e2ed415\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2820136\",\"name\":\"Yu-Wei Chao\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"2535887\",\"name\":\"Bryan Seybold\"},{\"authorId\":\"144711958\",\"name\":\"David A. Ross\"},{\"authorId\":\"145820819\",\"name\":\"Jun Deng\"},{\"authorId\":\"1694199\",\"name\":\"Rahul Sukthankar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e85c01ff4979357b428538c9f224fa4259541c1a\",\"title\":\"RoI Pooling DNN Classifier Person Bike Background 2 D Feature Map Input ImageMulti-scale Anchor Boxes Region Proposal Network Region Proposals 2 D ConvNet c DNN Classifier Dunk Background SoI Pooling\",\"url\":\"https://www.semanticscholar.org/paper/e85c01ff4979357b428538c9f224fa4259541c1a\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46401013\",\"name\":\"Jian-wen Jiang\"},{\"authorId\":\"153843000\",\"name\":\"Y. Cao\"},{\"authorId\":\"80834369\",\"name\":\"L. Song\"},{\"authorId\":\"50202110\",\"name\":\"Shiwei Zhang\"},{\"authorId\":\"51487081\",\"name\":\"Yunkai Li\"},{\"authorId\":\"70397730\",\"name\":\"Ziyao Xu\"},{\"authorId\":\"47506758\",\"name\":\"Q. Wu\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":null,\"name\":\"Chi Zhang\"},{\"authorId\":\"145844907\",\"name\":\"Gang Yu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4f968688dcdd8980399265de1996a00a62034913\",\"title\":\"Human Centric Spatio-Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/4f968688dcdd8980399265de1996a00a62034913\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"1388834506\",\"name\":\"Hao Jiang\"}],\"doi\":\"10.1109/CVPR.2019.01213\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5b5c59d5ee264227a370ea68929bfcac0209b4e0\",\"title\":\"Action4D: Online Action Recognition in the Crowd and Clutter\",\"url\":\"https://www.semanticscholar.org/paper/5b5c59d5ee264227a370ea68929bfcac0209b4e0\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1712.00097\",\"authors\":[{\"authorId\":\"3112334\",\"name\":\"Behrooz Mahasseni\"},{\"authorId\":\"144434220\",\"name\":\"X. Yang\"},{\"authorId\":\"2824500\",\"name\":\"P. Molchanov\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"11769e150d4473d6983f4f6abb0ec7aa58d555ea\",\"title\":\"Budget-Aware Activity Detection with A Recurrent Policy Network\",\"url\":\"https://www.semanticscholar.org/paper/11769e150d4473d6983f4f6abb0ec7aa58d555ea\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"83172278\",\"name\":\"Y. Li\"},{\"authorId\":\"2303180\",\"name\":\"S. Xu\"},{\"authorId\":\"66678312\",\"name\":\"Xiangqian Cheng\"},{\"authorId\":\"1471662289\",\"name\":\"L. Zhou\"},{\"authorId\":\"49339105\",\"name\":\"Yanyun Zhao\"},{\"authorId\":\"153023158\",\"name\":\"Z. Zhao\"},{\"authorId\":\"152343380\",\"name\":\"Fei Su\"},{\"authorId\":\"48430112\",\"name\":\"BoJin Zhuang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"de47d9734fcb028339e95d5052281050ff237351\",\"title\":\"An Effective Detection Framework for Activities in Surveillance Videos\",\"url\":\"https://www.semanticscholar.org/paper/de47d9734fcb028339e95d5052281050ff237351\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1806.02424\",\"authors\":[{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"143891655\",\"name\":\"H. Jiang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"21e1d7a8b0e472e478eef1585e7823210e7ab92d\",\"title\":\"Action4D: Real-time Action Recognition in the Crowd and Clutter\",\"url\":\"https://www.semanticscholar.org/paper/21e1d7a8b0e472e478eef1585e7823210e7ab92d\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2008.13196\",\"authors\":[{\"authorId\":null,\"name\":\"Yuxi Li\"},{\"authorId\":\"8131625\",\"name\":\"W. Lin\"},{\"authorId\":\"145527065\",\"name\":\"Tao Wang\"},{\"authorId\":\"143937986\",\"name\":\"John See\"},{\"authorId\":\"47519958\",\"name\":\"Rui Qian\"},{\"authorId\":null,\"name\":\"Ning Xu\"},{\"authorId\":\"48170161\",\"name\":\"L. Wang\"},{\"authorId\":\"1802931\",\"name\":\"Shugong Xu\"}],\"doi\":\"10.1609/AAAI.V34I07.6811\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7b66ea4e404cc119f2f7970486cee19bc300a198\",\"title\":\"Finding Action Tubes with a Sparse-to-Dense Framework\",\"url\":\"https://www.semanticscholar.org/paper/7b66ea4e404cc119f2f7970486cee19bc300a198\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1807.11332\",\"authors\":[{\"authorId\":\"143716515\",\"name\":\"V. Fontana\"},{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":\"51152717\",\"name\":\"Stephen Akrigg\"},{\"authorId\":\"51149466\",\"name\":\"Manuele Di Maio\"},{\"authorId\":null,\"name\":\"Suman Saha\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":null,\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"fd71ae9599e8a51d8a61e31e6faaaf4a23a17d81\",\"title\":\"Action Detection from a Robot-Car Perspective\",\"url\":\"https://www.semanticscholar.org/paper/fd71ae9599e8a51d8a61e31e6faaaf4a23a17d81\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2004.00180\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"2683916\",\"name\":\"Lizhi Yang\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"fe9d2d14143e13e20cc318d4483a2a750a5ec55b\",\"title\":\"Spatio-Temporal Action Detection with Multi-Object Interaction\",\"url\":\"https://www.semanticscholar.org/paper/fe9d2d14143e13e20cc318d4483a2a750a5ec55b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9173291\",\"name\":\"L. Wang\"},{\"authorId\":\"46809347\",\"name\":\"Xuhuan Duan\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"1786361\",\"name\":\"Zhenxing Niu\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"}],\"doi\":\"10.3390/s18051657\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f02a6bccdaee14ab55ad94263539f4f33f1b15bb\",\"title\":\"Segment-Tube: Spatio-Temporal Action Localization in Untrimmed Videos with Per-Frame Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/f02a6bccdaee14ab55ad94263539f4f33f1b15bb\",\"venue\":\"Sensors\",\"year\":2018},{\"arxivId\":\"1803.07201\",\"authors\":[{\"authorId\":\"40366599\",\"name\":\"W. Liu\"},{\"authorId\":null,\"name\":\"Abhishek Sharma\"},{\"authorId\":\"1694992\",\"name\":\"O. Camps\"},{\"authorId\":\"1687866\",\"name\":\"M. Sznaier\"}],\"doi\":\"10.1007/978-3-030-01258-8_11\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b53259a81dcfa9913495bb47f62627c51e20f086\",\"title\":\"DYAN: A Dynamical Atoms-Based Network for Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/b53259a81dcfa9913495bb47f62627c51e20f086\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1705.01781\",\"authors\":[{\"authorId\":\"41172759\",\"name\":\"Federico Becattini\"},{\"authorId\":\"1789269\",\"name\":\"Tiberio Uricchio\"},{\"authorId\":\"1795847\",\"name\":\"Lamberto Ballan\"},{\"authorId\":\"2831602\",\"name\":\"Lorenzo Seidenari\"},{\"authorId\":\"8196487\",\"name\":\"A. D. Bimbo\"}],\"doi\":\"10.1145/3402447\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"dc974c31201b6da32f48ef81ae5a9042512705fe\",\"title\":\"Am I Done? Predicting Action Progress in Videos\",\"url\":\"https://www.semanticscholar.org/paper/dc974c31201b6da32f48ef81ae5a9042512705fe\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1806.11328\",\"authors\":[{\"authorId\":\"1902524\",\"name\":\"Guilhem Ch\\u00e9ron\"},{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a230350dc8a135fc390f9bb634249d08a07cea4e\",\"title\":\"A flexible model for training action localization with varying levels of supervision\",\"url\":\"https://www.semanticscholar.org/paper/a230350dc8a135fc390f9bb634249d08a07cea4e\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1806.11008\",\"authors\":[{\"authorId\":\"1902524\",\"name\":\"Guilhem Ch\\u00e9ron\"},{\"authorId\":\"145319877\",\"name\":\"Anton Osokin\"},{\"authorId\":\"143991676\",\"name\":\"Ivan Laptev\"},{\"authorId\":\"2462253\",\"name\":\"Cordelia Schmid\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"14fee990a372bcc4cb6dc024ab7fc4ecf09dba2b\",\"title\":\"Modeling Spatio-Temporal Human Track Structure for Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/14fee990a372bcc4cb6dc024ab7fc4ecf09dba2b\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1902.01466\",\"authors\":[{\"authorId\":\"4870207\",\"name\":\"Chenge Li\"},{\"authorId\":\"40102286\",\"name\":\"G. Dobler\"},{\"authorId\":\"145976729\",\"name\":\"X. Feng\"},{\"authorId\":\"49418346\",\"name\":\"Y. Wang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0c2cb193274217855000c98a02488885571b55bc\",\"title\":\"TrackNet: Simultaneous Object Detection and Tracking and Its Application in Traffic Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/0c2cb193274217855000c98a02488885571b55bc\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150282005\",\"name\":\"Rizard Renanda Adhi Pramono\"},{\"authorId\":\"73365425\",\"name\":\"Y. Chen\"},{\"authorId\":\"122315920\",\"name\":\"Wen-Hsien Fang\"}],\"doi\":\"10.1109/ICCV.2019.00015\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3b76da17a060f1edb80b26f489f4b6256d785c57\",\"title\":\"Hierarchical Self-Attention Network for Action Localization in Videos\",\"url\":\"https://www.semanticscholar.org/paper/3b76da17a060f1edb80b26f489f4b6256d785c57\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1912.05534\",\"authors\":[{\"authorId\":\"150140884\",\"name\":\"Jin-Woo Choi\"},{\"authorId\":\"49281242\",\"name\":\"C. Gao\"},{\"authorId\":\"79959317\",\"name\":\"Joseph C.E. Messou\"},{\"authorId\":\"3068086\",\"name\":\"Jia-Bin Huang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"439fd498e7b682dea5aa7e910267c10bf2ccb722\",\"title\":\"Why Can't I Dance in the Mall? Learning to Mitigate Scene Bias in Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/439fd498e7b682dea5aa7e910267c10bf2ccb722\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1811.08496\",\"authors\":[{\"authorId\":\"35199438\",\"name\":\"Joshua Gleason\"},{\"authorId\":\"48467498\",\"name\":\"Rajeev Ranjan\"},{\"authorId\":\"52023459\",\"name\":\"Steven Schwarcz\"},{\"authorId\":\"145668757\",\"name\":\"Carlos Castillo\"},{\"authorId\":\"1391201966\",\"name\":\"Jun-Cheng Chen\"},{\"authorId\":\"9215658\",\"name\":\"R. Chellappa\"}],\"doi\":\"10.1109/WACV.2019.00021\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1a2e40b8ef509ed099bb7e77862ed5ddca52c3a2\",\"title\":\"A Proposal-Based Solution to Spatio-Temporal Action Detection in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/1a2e40b8ef509ed099bb7e77862ed5ddca52c3a2\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":\"2008.08332\",\"authors\":[{\"authorId\":null,\"name\":\"Yuxi Li\"},{\"authorId\":\"8131625\",\"name\":\"W. Lin\"},{\"authorId\":\"143937986\",\"name\":\"John See\"},{\"authorId\":null,\"name\":\"Ning Xu\"},{\"authorId\":\"1802931\",\"name\":\"Shugong Xu\"},{\"authorId\":\"1671290360\",\"name\":\"Ke Yan\"},{\"authorId\":\"46961961\",\"name\":\"Cong Yang\"}],\"doi\":\"10.1007/978-3-030-58517-4_30\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f5140c7251be78ff4fec48efea3b1c6ba581fba9\",\"title\":\"CFAD: Coarse-to-Fine Action Detector for Spatiotemporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/f5140c7251be78ff4fec48efea3b1c6ba581fba9\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3005105\",\"name\":\"Youngkyoon Jang\"},{\"authorId\":\"49300666\",\"name\":\"Brian T. Sullivan\"},{\"authorId\":\"40626572\",\"name\":\"Casimir J H Ludwig\"},{\"authorId\":\"2283822\",\"name\":\"I. Gilchrist\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"},{\"authorId\":\"1398236231\",\"name\":\"W. Mayol-Cuevas\"}],\"doi\":\"10.1109/ICCVW.2019.00547\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e5d1234f99d3c6b9c0dc7545e030cac5a56ffc3f\",\"title\":\"EPIC-Tent: An Egocentric Video Dataset for Camping Tent Assembly\",\"url\":\"https://www.semanticscholar.org/paper/e5d1234f99d3c6b9c0dc7545e030cac5a56ffc3f\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1804.04527\",\"authors\":[{\"authorId\":\"22314218\",\"name\":\"Silvio Giancola\"},{\"authorId\":\"41022271\",\"name\":\"Mohieddine Amine\"},{\"authorId\":\"41015552\",\"name\":\"Tarek Dghaily\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1109/CVPRW.2018.00223\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"982f2025925062aeafac07ae015c9ed273e4d3d6\",\"title\":\"SoccerNet: A Scalable Dataset for Action Spotting in Soccer Videos\",\"url\":\"https://www.semanticscholar.org/paper/982f2025925062aeafac07ae015c9ed273e4d3d6\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2018},{\"arxivId\":\"1712.01111\",\"authors\":[{\"authorId\":\"145749579\",\"name\":\"R. Hou\"},{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cb8806e90aaa882ffc212864ae6d6e28c9092aa4\",\"title\":\"An End-to-end 3D Convolutional Neural Network for Action Detection and Segmentation in Videos\",\"url\":\"https://www.semanticscholar.org/paper/cb8806e90aaa882ffc212864ae6d6e28c9092aa4\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1881509\",\"name\":\"Vicky Kalogeiton\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"40dd2b9aace337467c6e1e269d0cb813442313d7\",\"title\":\"Localizing spatially and temporally objects and actions in videos. (Localiser spatio-temporallement des objets et des actions dans des vid\\u00e9os)\",\"url\":\"https://www.semanticscholar.org/paper/40dd2b9aace337467c6e1e269d0cb813442313d7\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2167197\",\"name\":\"B. Mudassar\"},{\"authorId\":\"40862506\",\"name\":\"P. Saha\"},{\"authorId\":\"50363755\",\"name\":\"Y. Long\"},{\"authorId\":\"37879315\",\"name\":\"M. Amir\"},{\"authorId\":\"73128469\",\"name\":\"Evan Gebhardt\"},{\"authorId\":\"40191008\",\"name\":\"Taesik Na\"},{\"authorId\":\"2813905\",\"name\":\"J. H. Ko\"},{\"authorId\":\"3517655\",\"name\":\"M. Wolf\"},{\"authorId\":\"144192724\",\"name\":\"S. Mukhopadhyay\"}],\"doi\":\"10.1109/JETCAS.2019.2935207\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6d8e64e941b6dbf62e7a8040a9532265796edb46\",\"title\":\"CAMEL: An Adaptive Camera With Embedded Machine Learning-Based Sensor Parameter Control\",\"url\":\"https://www.semanticscholar.org/paper/6d8e64e941b6dbf62e7a8040a9532265796edb46\",\"venue\":\"IEEE Journal on Emerging and Selected Topics in Circuits and Systems\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49024484\",\"name\":\"J. Huang\"},{\"authorId\":null,\"name\":\"Nannan Li\"},{\"authorId\":\"28891563\",\"name\":\"Jia-Xing Zhong\"},{\"authorId\":\"50289966\",\"name\":\"Thomas H. Li\"},{\"authorId\":\"47949235\",\"name\":\"G. Li\"}],\"doi\":\"10.1145/3240508.3240659\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ecb4bab5296224bdedd389cf18748c2ff0050100\",\"title\":\"Online Action Tube Detection via Resolving the Spatio-temporal Context Pattern\",\"url\":\"https://www.semanticscholar.org/paper/ecb4bab5296224bdedd389cf18748c2ff0050100\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1912.07249\",\"authors\":[{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"3321919\",\"name\":\"Gr\\u00e9gory Rogez\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8dce5b1cc382f4a341f7ea43c6329c9e8acd202d\",\"title\":\"Mimetics: Towards Understanding Human Actions Out of Context\",\"url\":\"https://www.semanticscholar.org/paper/8dce5b1cc382f4a341f7ea43c6329c9e8acd202d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2489020\",\"name\":\"Brian Geuther\"},{\"authorId\":\"1995462965\",\"name\":\"Asaf Pe'er\"},{\"authorId\":\"145818206\",\"name\":\"Hao He\"},{\"authorId\":\"71586239\",\"name\":\"G. Sabnis\"},{\"authorId\":\"2264830\",\"name\":\"V. Philip\"},{\"authorId\":\"49533156\",\"name\":\"V. Kumar\"}],\"doi\":\"10.1101/2020.10.08.331017\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b63e43d368935fb8657fa0bd800d03b1229485eb\",\"title\":\"Action detection using a neural network elucidates the genetics of mouse grooming behavior\",\"url\":\"https://www.semanticscholar.org/paper/b63e43d368935fb8657fa0bd800d03b1229485eb\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1908622\",\"name\":\"Qichao Xu\"},{\"authorId\":\"143937986\",\"name\":\"John See\"},{\"authorId\":\"8131625\",\"name\":\"W. Lin\"}],\"doi\":\"10.1109/ICME.2019.00104\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"624044ee08d89b35aa1b564505379da4b8b0700c\",\"title\":\"Localization Guided Fight Action Detection in Surveillance Videos\",\"url\":\"https://www.semanticscholar.org/paper/624044ee08d89b35aa1b564505379da4b8b0700c\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1778986\",\"name\":\"Wanru Xu\"},{\"authorId\":\"49402429\",\"name\":\"J. Yu\"},{\"authorId\":\"46533851\",\"name\":\"Zhenjiang Miao\"},{\"authorId\":\"40322073\",\"name\":\"L. Wan\"},{\"authorId\":\"50426357\",\"name\":\"Q. Ji\"}],\"doi\":\"10.1109/TCSVT.2019.2919064\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"10129da014606c70b6fab077319491c772b01c04\",\"title\":\"Spatio-Temporal Deep Q-Networks for Human Activity Localization\",\"url\":\"https://www.semanticscholar.org/paper/10129da014606c70b6fab077319491c772b01c04\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"1812.00303\",\"authors\":[{\"authorId\":\"144282337\",\"name\":\"B. McIntosh\"},{\"authorId\":\"7839191\",\"name\":\"K. Duarte\"},{\"authorId\":\"2116440\",\"name\":\"Y. Rawat\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b181ae8ed315ceb8f03332ba02ef0849adbe5b4c\",\"title\":\"Multi-modal Capsule Routing for Actor and Action Video Segmentation Conditioned on Natural Language Queries\",\"url\":\"https://www.semanticscholar.org/paper/b181ae8ed315ceb8f03332ba02ef0849adbe5b4c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145749579\",\"name\":\"R. Hou\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a3e9a317ec14b6673beead812b2134c7b5c623b\",\"title\":\"An Efficient 3 D CNN for Action / Object Segmentation in Video\",\"url\":\"https://www.semanticscholar.org/paper/8a3e9a317ec14b6673beead812b2134c7b5c623b\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2303172\",\"name\":\"Peng Lei\"},{\"authorId\":\"143856428\",\"name\":\"S. Todorovic\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b9306e90facafc2001e6f01f209ddbb0694d61fb\",\"title\":\"AN ABSTRACT OF THE DISSERTATION OF\",\"url\":\"https://www.semanticscholar.org/paper/b9306e90facafc2001e6f01f209ddbb0694d61fb\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2007.09861\",\"authors\":[{\"authorId\":\"9096071\",\"name\":\"Jianchao Wu\"},{\"authorId\":\"1874900\",\"name\":\"Zhanghui Kuang\"},{\"authorId\":\"48170161\",\"name\":\"L. Wang\"},{\"authorId\":\"1726357\",\"name\":\"Wayne Zhang\"},{\"authorId\":\"39914710\",\"name\":\"Gangshan Wu\"}],\"doi\":\"10.1007/978-3-030-58595-2_27\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf0bc1e97049ece897db97ba605594a89df50c34\",\"title\":\"Context-Aware RCNN: A Baseline for Action Detection in Videos\",\"url\":\"https://www.semanticscholar.org/paper/cf0bc1e97049ece897db97ba605594a89df50c34\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2004.00451\",\"authors\":[{\"authorId\":\"1573843594\",\"name\":\"Daniel Cores\"},{\"authorId\":\"1725529\",\"name\":\"V. Brea\"},{\"authorId\":\"1734140\",\"name\":\"M. Mucientes\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"eb0b0056ccecb9b484acd9eaac55f68bf9559174\",\"title\":\"Spatio-temporal Tubelet Feature Aggregation and Object Linking in Videos\",\"url\":\"https://www.semanticscholar.org/paper/eb0b0056ccecb9b484acd9eaac55f68bf9559174\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2001.04608\",\"authors\":[{\"authorId\":\"1527103472\",\"name\":\"Yixuan Li\"},{\"authorId\":\"50218816\",\"name\":\"Zixu Wang\"},{\"authorId\":\"48170350\",\"name\":\"Limin Wang\"},{\"authorId\":\"39914710\",\"name\":\"Gangshan Wu\"}],\"doi\":\"10.1007/978-3-030-58517-4_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e6e3034cd8855616533d091dc1d70e969c20a42b\",\"title\":\"Actions as Moving Points\",\"url\":\"https://www.semanticscholar.org/paper/e6e3034cd8855616533d091dc1d70e969c20a42b\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134668928\",\"name\":\"Raimon H. R. Pruim\"},{\"authorId\":\"133678273\",\"name\":\"Annegreet van Opbroek\"},{\"authorId\":\"3138549\",\"name\":\"M. Kruithof\"},{\"authorId\":\"134632765\",\"name\":\"R. D. den Hollander\"},{\"authorId\":\"145445122\",\"name\":\"J. Baan\"},{\"authorId\":\"134767384\",\"name\":\"Sebastiaan P. van den Broek\"},{\"authorId\":\"134536174\",\"name\":\"Nanda van der Stap\"},{\"authorId\":\"144229488\",\"name\":\"J. Dijk\"}],\"doi\":\"10.1117/12.2532323\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e093abab071b058d6822afde819709a8677bcb9f\",\"title\":\"Spatiotemporal detection of maritime targets using neural networks\",\"url\":\"https://www.semanticscholar.org/paper/e093abab071b058d6822afde819709a8677bcb9f\",\"venue\":\"Security + Defence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152831141\",\"name\":\"Pauline Luc\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e98a7f4e73f49248c912b141c43031a241d4ac33\",\"title\":\"Self-supervised learning of predictive segmentation models from video. (Apprentissage autosupervis\\u00e9 de mod\\u00e8les pr\\u00e9dictifs de segmentation \\u00e0 partir de vid\\u00e9os)\",\"url\":\"https://www.semanticscholar.org/paper/e98a7f4e73f49248c912b141c43031a241d4ac33\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1907.08895\",\"authors\":[{\"authorId\":\"145749579\",\"name\":\"R. Hou\"},{\"authorId\":\"1828568\",\"name\":\"Chen Chen\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"65961eb0380182c32ab3d018c83010aa80969d8a\",\"title\":\"An Efficient 3D CNN for Action/Object Segmentation in Video\",\"url\":\"https://www.semanticscholar.org/paper/65961eb0380182c32ab3d018c83010aa80969d8a\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"1904.09288\",\"authors\":[{\"authorId\":\"3042242\",\"name\":\"X. Yang\"},{\"authorId\":\"144434220\",\"name\":\"X. Yang\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":\"2299381\",\"name\":\"Fanyi Xiao\"},{\"authorId\":\"145879186\",\"name\":\"L. Davis\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":\"10.1109/CVPR.2019.00035\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c2cc82c2948c0513628a61d4ff829110750fdf9a\",\"title\":\"STEP: Spatio-Temporal Progressive Learning for Video Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/c2cc82c2948c0513628a61d4ff829110750fdf9a\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1906.05571\",\"authors\":[{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"143977389\",\"name\":\"C. Ngo\"},{\"authorId\":\"40434674\",\"name\":\"X. Tian\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2019.01233\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e65e8c434895601b27cda0bef9b1bd9ff1475bf3\",\"title\":\"Learning Spatio-Temporal Representation With Local and Global Diffusion\",\"url\":\"https://www.semanticscholar.org/paper/e65e8c434895601b27cda0bef9b1bd9ff1475bf3\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46867157\",\"name\":\"Y. Zhang\"},{\"authorId\":\"47364599\",\"name\":\"Mingli Ding\"},{\"authorId\":\"2860057\",\"name\":\"Yancheng Bai\"},{\"authorId\":\"48928816\",\"name\":\"Dandan Liu\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1016/j.patrec.2019.10.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d277ff82da3cb6bdfe9987f1be12998cccbf3c37\",\"title\":\"Learning a strong detector for action localization in videos\",\"url\":\"https://www.semanticscholar.org/paper/d277ff82da3cb6bdfe9987f1be12998cccbf3c37\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390076423\",\"name\":\"Guang Ting Foo\"},{\"authorId\":\"46917486\",\"name\":\"Kam Meng Goh\"}],\"doi\":\"10.3233/IDT-190360\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"914f36710026d0796f133469c0839915af711490\",\"title\":\"Violence action recognition using region proposal in region convolution neural network\",\"url\":\"https://www.semanticscholar.org/paper/914f36710026d0796f133469c0839915af711490\",\"venue\":\"Intell. Decis. Technol.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49357069\",\"name\":\"Dejun Zhang\"},{\"authorId\":\"118098028\",\"name\":\"Linchao He\"},{\"authorId\":\"143611428\",\"name\":\"Z. Tu\"},{\"authorId\":\"47180213\",\"name\":\"Shifu Zhang\"},{\"authorId\":\"1393588876\",\"name\":\"Fei Han\"},{\"authorId\":\"153671183\",\"name\":\"Boxiong Yang\"}],\"doi\":\"10.1016/j.patcog.2020.107312\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"79921dc4596e36efb431077208a73a46995d8a2c\",\"title\":\"Learning motion representation for real-time spatio-temporal action localization\",\"url\":\"https://www.semanticscholar.org/paper/79921dc4596e36efb431077208a73a46995d8a2c\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2542995\",\"name\":\"T. Kim\"},{\"authorId\":\"145954571\",\"name\":\"Y. Zhang\"},{\"authorId\":\"9381483\",\"name\":\"Zihao Xiao\"},{\"authorId\":\"51207689\",\"name\":\"Michael Peven\"},{\"authorId\":\"3256056\",\"name\":\"Weichao Qiu\"},{\"authorId\":\"1384716902\",\"name\":\"Jin Bai\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"},{\"authorId\":\"1678633\",\"name\":\"Gregory Hager\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"265010019d3d95568d237973b5d957c6aa80d7dd\",\"title\":\"SAFER : Fine-grained Activity Detection by Compositional Hypothesis Testing\",\"url\":\"https://www.semanticscholar.org/paper/265010019d3d95568d237973b5d957c6aa80d7dd\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Suman Saha\"}],\"doi\":\"10.24384/KQTR-E820\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dc64caa4143f88ca1f41a91036d897008f956610\",\"title\":\"Spatio-temporal human action detection and instance segmentation in videos\",\"url\":\"https://www.semanticscholar.org/paper/dc64caa4143f88ca1f41a91036d897008f956610\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"118098028\",\"name\":\"Linchao He\"},{\"authorId\":\"3172494\",\"name\":\"Jiong Mu\"},{\"authorId\":\"151501329\",\"name\":\"Mengting Luo\"},{\"authorId\":\"152999492\",\"name\":\"Yunlu Lu\"},{\"authorId\":\"1500399614\",\"name\":\"Xuefeng Tan\"},{\"authorId\":\"49357069\",\"name\":\"Dejun Zhang\"}],\"doi\":\"10.1007/978-981-15-3250-4_171\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dd65beb7fe8dd4d1b32f788a2718d71a8a509164\",\"title\":\"Spatio-Temporal Action Localization for Pedestrian Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/dd65beb7fe8dd4d1b32f788a2718d71a8a509164\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1904.04689\",\"authors\":[{\"authorId\":\"3420479\",\"name\":\"D. Moltisanti\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.1109/CVPR.2019.01015\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c7ee1000ff197985553c9fb8d9cdc838d2858cff\",\"title\":\"Action Recognition From Single Timestamp Supervision in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/c7ee1000ff197985553c9fb8d9cdc838d2858cff\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"}],\"doi\":\"10.25781/KAUST-VR909\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"b5c549fd9172f2d1be80cc77b0de9e90d3416463\",\"title\":\"Efficient Localization of Human Actions and Moments in Videos\",\"url\":\"https://www.semanticscholar.org/paper/b5c549fd9172f2d1be80cc77b0de9e90d3416463\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1718406\",\"name\":\"N. Inoue\"},{\"authorId\":\"34747136\",\"name\":\"C. Shiraishi\"},{\"authorId\":\"2817839\",\"name\":\"Aleksandr Drozd\"},{\"authorId\":\"9280008\",\"name\":\"K. Shinoda\"},{\"authorId\":\"2109666\",\"name\":\"Shi-wook Lee\"},{\"authorId\":\"1711097\",\"name\":\"A. Kot\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7f21d052a4efc2d299548e3ec16415cdcc49be8a\",\"title\":\"VANT at TRECVID 2018\",\"url\":\"https://www.semanticscholar.org/paper/7f21d052a4efc2d299548e3ec16415cdcc49be8a\",\"venue\":\"TRECVID\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405030052\",\"name\":\"Gibran Benitez-Garcia\"},{\"authorId\":\"145879931\",\"name\":\"M. Haris\"},{\"authorId\":\"1787546\",\"name\":\"Y. Tsuda\"},{\"authorId\":\"3081689\",\"name\":\"N. Ukita\"}],\"doi\":\"10.23919/MVA.2019.8757973\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"62a2339985d54cd679a6aa05f9d04f1708067309\",\"title\":\"Similar Finger Gesture Recognition using Triplet-loss Networks\",\"url\":\"https://www.semanticscholar.org/paper/62a2339985d54cd679a6aa05f9d04f1708067309\",\"venue\":\"2019 16th International Conference on Machine Vision Applications (MVA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47487418\",\"name\":\"P. Jana\"},{\"authorId\":\"1434558472\",\"name\":\"Swarnabja Bhaumik\"},{\"authorId\":\"2579872\",\"name\":\"P. P. Mohanta\"}],\"doi\":\"10.1109/TENSYMP46218.2019.8971058\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1fc3877894f09f48cddebdeaf11c00e35f322157\",\"title\":\"Key-Frame based Event Recognition in Unconstrained Videos using Temporal Features\",\"url\":\"https://www.semanticscholar.org/paper/1fc3877894f09f48cddebdeaf11c00e35f322157\",\"venue\":\"2019 IEEE Region 10 Symposium (TENSYMP)\",\"year\":2019},{\"arxivId\":\"1711.08362\",\"authors\":[{\"authorId\":\"8120382\",\"name\":\"P. Wang\"},{\"authorId\":\"1685696\",\"name\":\"W. Li\"},{\"authorId\":\"1719314\",\"name\":\"P. Ogunbona\"},{\"authorId\":\"145121530\",\"name\":\"Jun Wan\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"}],\"doi\":\"10.1016/j.cviu.2018.04.007\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"224b34acba3597912f8adc288fa8adbb1fca92b4\",\"title\":\"RGB-D-based Human Motion Recognition with Deep Learning: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/224b34acba3597912f8adc288fa8adbb1fca92b4\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2018},{\"arxivId\":\"1812.02707\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"2786693\",\"name\":\"C. Doersch\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2019.00033\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"94bbc4ea271c918705876b60d98d227a0ab55a43\",\"title\":\"Video Action Transformer Network\",\"url\":\"https://www.semanticscholar.org/paper/94bbc4ea271c918705876b60d98d227a0ab55a43\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144963395\",\"name\":\"P. Tang\"},{\"authorId\":\"48586124\",\"name\":\"Chun-Yu Wang\"},{\"authorId\":\"2443233\",\"name\":\"Xinggang Wang\"},{\"authorId\":\"1743698\",\"name\":\"Wenyu Liu\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"},{\"authorId\":\"1688516\",\"name\":\"Jingdong Wang\"}],\"doi\":\"10.1109/TPAMI.2019.2910529\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a69c19846bdf04a179308c824c076f1a62a46e1d\",\"title\":\"Object Detection in Videos by High Quality Object Linking\",\"url\":\"https://www.semanticscholar.org/paper/a69c19846bdf04a179308c824c076f1a62a46e1d\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1652110241\",\"name\":\"M. Lee\"},{\"authorId\":\"153631826\",\"name\":\"M. Mukherjee\"},{\"authorId\":\"15760080\",\"name\":\"Edward L. Lee\"},{\"authorId\":\"40862506\",\"name\":\"P. Saha\"},{\"authorId\":\"37879315\",\"name\":\"M. Amir\"},{\"authorId\":\"40191008\",\"name\":\"Taesik Na\"},{\"authorId\":\"144192724\",\"name\":\"S. Mukhopadhyay\"}],\"doi\":\"10.1109/JETCAS.2020.3031869\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"882af503cb200c14bfd8ab7279f3240f91d399b6\",\"title\":\"Cross-Layer Noise Analysis in Smart Digital Pixel Sensors With Integrated Deep Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/882af503cb200c14bfd8ab7279f3240f91d399b6\",\"venue\":\"IEEE Journal on Emerging and Selected Topics in Circuits and Systems\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390937493\",\"name\":\"Alaaeldin Ali\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"54bede87f33f39d0242e3e9fed20e662563b0ebb\",\"title\":\"Spatiotemporal Representation Learning For Human Action Recognition And Localization\",\"url\":\"https://www.semanticscholar.org/paper/54bede87f33f39d0242e3e9fed20e662563b0ebb\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31092565\",\"name\":\"Talha Ali Khan\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9df23768db7b6f68adb4441a3d50070649cc6a03\",\"title\":\"Masters Thesis: Multi-frame deep learning models for action detection in surveillance videos\",\"url\":\"https://www.semanticscholar.org/paper/9df23768db7b6f68adb4441a3d50070649cc6a03\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1911.06644\",\"authors\":[{\"authorId\":\"41022447\",\"name\":\"Okan K\\u00f6p\\u00fckl\\u00fc\"},{\"authorId\":\"50652944\",\"name\":\"Xiangyu Wei\"},{\"authorId\":\"46343645\",\"name\":\"G. Rigoll\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"143059e7d17fd17c961a538ea98fadcf2667d5ca\",\"title\":\"You Only Watch Once: A Unified CNN Architecture for Real-Time Spatiotemporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/143059e7d17fd17c961a538ea98fadcf2667d5ca\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1881509\",\"name\":\"Vicky Kalogeiton\"},{\"authorId\":\"69413223\",\"name\":\"Vicky\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"26269eb971756005a9ee87c6d8c816aea95acb07\",\"title\":\"Constrained Video Face Clustering using 1NN Relations\",\"url\":\"https://www.semanticscholar.org/paper/26269eb971756005a9ee87c6d8c816aea95acb07\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2424352\",\"name\":\"M. Beigi\"},{\"authorId\":\"49860655\",\"name\":\"L. Brown\"},{\"authorId\":\"33421444\",\"name\":\"Quanfu Fan\"},{\"authorId\":\"8988359\",\"name\":\"J. Henning\"},{\"authorId\":\"1955556\",\"name\":\"C. Lin\"},{\"authorId\":\"48667025\",\"name\":\"Humphrey Shi\"},{\"authorId\":\"144808138\",\"name\":\"C. Shu\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"600fc04b83e2269c280cfbdf719294f8cdb4d01a\",\"title\":\"Object-Centric Spatio-Temporal Activity Detection and Recognition\",\"url\":\"https://www.semanticscholar.org/paper/600fc04b83e2269c280cfbdf719294f8cdb4d01a\",\"venue\":\"TRECVID\",\"year\":2018},{\"arxivId\":\"2009.14639\",\"authors\":[{\"authorId\":\"1976000468\",\"name\":\"Okan Kopuklu\"},{\"authorId\":\"114991183\",\"name\":\"Stefan Hormann\"},{\"authorId\":\"32240536\",\"name\":\"Fabian Herzog\"},{\"authorId\":\"2277308\",\"name\":\"Hakan Cevikalp\"},{\"authorId\":\"46343645\",\"name\":\"G. Rigoll\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d197d0ab852c20122ffb1833fb29199ca77ce9bb\",\"title\":\"Dissected 3D CNNs: Temporal Skip Connections for Efficient Online Video Processing\",\"url\":\"https://www.semanticscholar.org/paper/d197d0ab852c20122ffb1833fb29199ca77ce9bb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.07485\",\"authors\":[{\"authorId\":\"152949394\",\"name\":\"J. Tang\"},{\"authorId\":\"49597328\",\"name\":\"J. Xia\"},{\"authorId\":\"13812767\",\"name\":\"Xinzhi Mu\"},{\"authorId\":\"1560385163\",\"name\":\"Bo Pang\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"}],\"doi\":\"10.1007/978-3-030-58555-6_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e820578147cac31a6748c3f6ef2eeaccac066b41\",\"title\":\"Asynchronous Interaction Aggregation for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/e820578147cac31a6748c3f6ef2eeaccac066b41\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1904.12993\",\"authors\":[{\"authorId\":\"49890205\",\"name\":\"Yubo Zhang\"},{\"authorId\":\"2931554\",\"name\":\"P. Tokmakov\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"55f70b16f087ec9b11168c67f3f3ff4e61baa0e5\",\"title\":\"A Study on Action Detection in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/55f70b16f087ec9b11168c67f3f3ff4e61baa0e5\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1802.08362\",\"authors\":[{\"authorId\":\"1388811741\",\"name\":\"Alaaeldin El-Nouby\"},{\"authorId\":\"144639556\",\"name\":\"Graham W. Taylor\"}],\"doi\":\"10.1109/CRV.2018.00015\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b6e9099320eca16c6959194d6d9113649ba88a2a\",\"title\":\"Real-Time End-to-End Action Detection with Two-Stream Networks\",\"url\":\"https://www.semanticscholar.org/paper/b6e9099320eca16c6959194d6d9113649ba88a2a\",\"venue\":\"2018 15th Conference on Computer and Robot Vision (CRV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50202110\",\"name\":\"Shiwei Zhang\"},{\"authorId\":\"143629371\",\"name\":\"L. Song\"},{\"authorId\":\"40115662\",\"name\":\"Changxin Gao\"},{\"authorId\":\"1707161\",\"name\":\"N. Sang\"}],\"doi\":\"10.1109/TMM.2019.2959425\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b8006397de84196e07ee4b520100940f2fd46483\",\"title\":\"GLNet: Global Local Network for Weakly Supervised Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/b8006397de84196e07ee4b520100940f2fd46483\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"1907.01847\",\"authors\":[{\"authorId\":\"73383712\",\"name\":\"W. Li\"},{\"authorId\":\"51305314\",\"name\":\"Zehuan Yuan\"},{\"authorId\":\"20412557\",\"name\":\"Dashan Guo\"},{\"authorId\":\"144585903\",\"name\":\"L. Huang\"},{\"authorId\":\"1706164\",\"name\":\"X. Fang\"},{\"authorId\":\"1697065\",\"name\":\"C. Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c33e9aaec527dfeb733fc10c1d2bda417f546b37\",\"title\":\"Deformable Tube Network for Action Detection in Videos\",\"url\":\"https://www.semanticscholar.org/paper/c33e9aaec527dfeb733fc10c1d2bda417f546b37\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152831141\",\"name\":\"Pauline Luc\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ae02e601eae125ce137324c678ab68e9ab272ea0\",\"title\":\"Self-supervised learning of predictive segmentation models from video\",\"url\":\"https://www.semanticscholar.org/paper/ae02e601eae125ce137324c678ab68e9ab272ea0\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22015276\",\"name\":\"Y. Wu\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"8194130\",\"name\":\"Qinyu Li\"}],\"doi\":\"10.1007/978-3-030-00767-6_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"069ab36fee71b15e9e6e8652e066f59d768ea071\",\"title\":\"Three-Stream Action Tubelet Detector for Spatiotemporal Action Detection in Videos\",\"url\":\"https://www.semanticscholar.org/paper/069ab36fee71b15e9e6e8652e066f59d768ea071\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":\"1909.08171\",\"authors\":[{\"authorId\":\"144957857\",\"name\":\"H. Nishimura\"},{\"authorId\":\"2764854\",\"name\":\"K. Tasaka\"},{\"authorId\":\"1770200\",\"name\":\"Y. Kawanishi\"},{\"authorId\":\"82910116\",\"name\":\"H. Murase\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"84caa8a506e47b322cf9dc116806b06bca0c0981\",\"title\":\"Multiple Human Tracking using Multi-Cues including Primitive Action Features\",\"url\":\"https://www.semanticscholar.org/paper/84caa8a506e47b322cf9dc116806b06bca0c0981\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2008.13759\",\"authors\":[{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"67968b5b59b08ea1dd8a1266b422ee38e3ca8ad5\",\"title\":\"Online Spatiotemporal Action Detection and Prediction via Causal Representations\",\"url\":\"https://www.semanticscholar.org/paper/67968b5b59b08ea1dd8a1266b422ee38e3ca8ad5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1912.04316\",\"authors\":[{\"authorId\":\"34656387\",\"name\":\"Matteo Tomei\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2175529\",\"name\":\"Simone Calderara\"},{\"authorId\":\"102613292\",\"name\":\"Simone Bronzin\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ad16dbe1a5c3b192de961a1f1c3fedeba8bf2783\",\"title\":\"STAGE: Spatio-Temporal Attention on Graph Entities for Video Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/ad16dbe1a5c3b192de961a1f1c3fedeba8bf2783\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2012.09434\",\"authors\":[{\"authorId\":\"48031771\",\"name\":\"X. Liu\"},{\"authorId\":\"72285615\",\"name\":\"Yao Hu\"},{\"authorId\":\"98807701\",\"name\":\"Song Bai\"},{\"authorId\":\"1430778662\",\"name\":\"Fei Ding\"},{\"authorId\":\"145905113\",\"name\":\"X. Bai\"},{\"authorId\":null,\"name\":\"Philip H. S. Torr\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"db1b0d0e70f29b0018d1a9462d98dd39559f3e4a\",\"title\":\"Multi-shot Temporal Event Localization: a Benchmark\",\"url\":\"https://www.semanticscholar.org/paper/db1b0d0e70f29b0018d1a9462d98dd39559f3e4a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145182602\",\"name\":\"Dong Li\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"144954807\",\"name\":\"Q. Dai\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1007/978-3-030-01231-1_19\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b6d977251b551471f5dddfb0a2e8f9c542e684d2\",\"title\":\"Recurrent Tubelet Proposal and Recognition Networks for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/b6d977251b551471f5dddfb0a2e8f9c542e684d2\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145749579\",\"name\":\"Rui Hou\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b4f422ef7f1297860bb4f011fbe30e01b233951c\",\"title\":\"An Efficient 3 D CNN for Action / Object Segmentation in Video\",\"url\":\"https://www.semanticscholar.org/paper/b4f422ef7f1297860bb4f011fbe30e01b233951c\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3076130\",\"name\":\"Keyang Cheng\"},{\"authorId\":\"1453694581\",\"name\":\"Lubamba Kasangu Eric\"},{\"authorId\":\"49503455\",\"name\":\"Rabia Tahir\"},{\"authorId\":\"47605260\",\"name\":\"M. Li\"}],\"doi\":\"10.1007/978-3-030-32456-8_33\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e4f8bccea93b03ceb7fbe38080a826a8f87a6dc8\",\"title\":\"Capsule Recurrent Neural Network with Weight Update Using Dynamic Routing by Agreement: A Unified Model for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/e4f8bccea93b03ceb7fbe38080a826a8f87a6dc8\",\"venue\":\"ICNC-FSKD\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38243491\",\"name\":\"A. Mahmood\"},{\"authorId\":\"31330222\",\"name\":\"S. Al-M\\u00e1adeed\"}],\"doi\":\"10.1007/s00138-019-01039-3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c0d3024822152d4dd948dd8222eef22c1e5c342e\",\"title\":\"Action recognition in poor-quality spectator crowd videos using head distribution-based person segmentation\",\"url\":\"https://www.semanticscholar.org/paper/c0d3024822152d4dd948dd8222eef22c1e5c342e\",\"venue\":\"Machine Vision and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21570451\",\"name\":\"A. Barbu\"},{\"authorId\":\"150963621\",\"name\":\"Dalitso Banda\"},{\"authorId\":\"6104312\",\"name\":\"Boris Katz\"}],\"doi\":\"10.1016/J.PATREC.2019.01.019\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4efdf79751faf6475222fdfd1906a4ab07852f5d\",\"title\":\"Deep video-to-video transformations for accessibility with an application to photosensitivity\",\"url\":\"https://www.semanticscholar.org/paper/4efdf79751faf6475222fdfd1906a4ab07852f5d\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2020},{\"arxivId\":\"2006.07976\",\"authors\":[{\"authorId\":\"1720856277\",\"name\":\"Junting Pan\"},{\"authorId\":\"30733670\",\"name\":\"S. Chen\"},{\"authorId\":\"73423138\",\"name\":\"Zheng Shou\"},{\"authorId\":\"1388486428\",\"name\":\"Jing Shao\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f46458babf6ec837ff829e54c110d1c71f0945eb\",\"title\":\"Actor-Context-Actor Relation Network for Spatio-Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/f46458babf6ec837ff829e54c110d1c71f0945eb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48625207\",\"name\":\"W. Li\"},{\"authorId\":\"46584793\",\"name\":\"J. Wang\"},{\"authorId\":\"2690741\",\"name\":\"Shengbei Wang\"},{\"authorId\":\"1809607\",\"name\":\"G. Jin\"}],\"doi\":\"10.1007/978-3-319-97289-3_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"473c74782b0120aa0a8b0e94f49fea6542a6d7da\",\"title\":\"Get the Whole Action Event by Action Stage Classification\",\"url\":\"https://www.semanticscholar.org/paper/473c74782b0120aa0a8b0e94f49fea6542a6d7da\",\"venue\":\"PKAW\",\"year\":2018},{\"arxivId\":\"1705.08421\",\"authors\":[{\"authorId\":\"39599498\",\"name\":\"C. Gu\"},{\"authorId\":\"94567368\",\"name\":\"C. Sun\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"2997956\",\"name\":\"C. Pantofaru\"},{\"authorId\":\"144711958\",\"name\":\"D. Ross\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"1758054\",\"name\":\"Y. Li\"},{\"authorId\":\"2262946\",\"name\":\"S. Ricco\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"153652146\",\"name\":\"J. Malik\"}],\"doi\":\"10.1109/CVPR.2018.00633\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"54c7c3909c7e1e827befdbe8d2595a3b196ba1b8\",\"title\":\"AVA: A Video Dataset of Spatio-Temporally Localized Atomic Visual Actions\",\"url\":\"https://www.semanticscholar.org/paper/54c7c3909c7e1e827befdbe8d2595a3b196ba1b8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153057610\",\"name\":\"N. Kumar\"},{\"authorId\":\"1442238004\",\"name\":\"N. Sukavanam\"}],\"doi\":\"10.1007/s11760-019-01633-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7cc117a589aa7c3f8a2bb152d02267d908dab68e\",\"title\":\"A weakly supervised CNN model for spatial localization of human activities in unconstraint environment\",\"url\":\"https://www.semanticscholar.org/paper/7cc117a589aa7c3f8a2bb152d02267d908dab68e\",\"venue\":\"Signal Image Video Process.\",\"year\":2020},{\"arxivId\":\"1712.04851\",\"authors\":[{\"authorId\":\"1817030\",\"name\":\"Saining Xie\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"1808244\",\"name\":\"J. Huang\"},{\"authorId\":\"144035504\",\"name\":\"Zhuowen Tu\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":\"10.1007/978-3-030-01267-0_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"815aa52cfc02961d82415f080384594639a21984\",\"title\":\"Rethinking Spatiotemporal Feature Learning: Speed-Accuracy Trade-offs in Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/815aa52cfc02961d82415f080384594639a21984\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52022007\",\"name\":\"Vasileios Choutas\"},{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"3428663\",\"name\":\"J\\u00e9r\\u00f4me Revaud\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/CVPR.2018.00734\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6009bba115904bc3bf876224db90b232c4f0a48f\",\"title\":\"PoTion: Pose MoTion Representation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6009bba115904bc3bf876224db90b232c4f0a48f\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40366599\",\"name\":\"W. Liu\"},{\"authorId\":null,\"name\":\"Abhishek Sharma\"},{\"authorId\":\"1694992\",\"name\":\"O. Camps\"},{\"authorId\":\"1687866\",\"name\":\"M. Sznaier\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ded41c9b027c8a7f4800e61b7cfb793edaeb2817\",\"title\":\"DYAN: A Dynamical Atoms Network for Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/ded41c9b027c8a7f4800e61b7cfb793edaeb2817\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"97596665\",\"name\":\"Y. Liu\"},{\"authorId\":\"145338223\",\"name\":\"F. Yang\"},{\"authorId\":\"1873153\",\"name\":\"D. Ginhac\"}],\"doi\":\"10.1145/3349801.3349821\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"8dd1565509362d0aef7db0a93bed20c422e3e818\",\"title\":\"Accurate Single-Stream Action Detection in Real-Time\",\"url\":\"https://www.semanticscholar.org/paper/8dd1565509362d0aef7db0a93bed20c422e3e818\",\"venue\":\"ICDSC\",\"year\":2019},{\"arxivId\":\"2004.01494\",\"authors\":[{\"authorId\":null,\"name\":\"Suman Saha\"},{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b6186cb2b81c4d39f7ba1b5ec649a3171b0caefd\",\"title\":\"Two-Stream AMTnet for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/b6186cb2b81c4d39f7ba1b5ec649a3171b0caefd\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2001.01033\",\"authors\":[{\"authorId\":\"2874605\",\"name\":\"X. Liu\"},{\"authorId\":\"2703630\",\"name\":\"Yurong Jiang\"},{\"authorId\":\"1390745613\",\"name\":\"Kyu-Han Kim\"},{\"authorId\":\"1747970\",\"name\":\"R. Govindan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"69aafaffc98351c7b7ffc6b54278005cdd9a1210\",\"title\":\"Grab: Fast and Accurate Sensor Processing for Cashier-Free Shopping\",\"url\":\"https://www.semanticscholar.org/paper/69aafaffc98351c7b7ffc6b54278005cdd9a1210\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.05049\",\"authors\":[{\"authorId\":\"2008154246\",\"name\":\"Zongheng Tang\"},{\"authorId\":\"47303356\",\"name\":\"Yue Liao\"},{\"authorId\":\"101219260\",\"name\":\"Si Liu\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"2103483\",\"name\":\"X. Jin\"},{\"authorId\":\"2292508\",\"name\":\"Hongxu Jiang\"},{\"authorId\":\"1410184682\",\"name\":\"Qian Yu\"},{\"authorId\":\"1510477221\",\"name\":\"Dong Xu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"74c30c601d5de21af098389abf7be0f8261e6c13\",\"title\":\"Human-centric Spatio-Temporal Video Grounding With Visual Transformers\",\"url\":\"https://www.semanticscholar.org/paper/74c30c601d5de21af098389abf7be0f8261e6c13\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.09211\",\"authors\":[{\"authorId\":\"40930518\",\"name\":\"Nakul Agarwal\"},{\"authorId\":\"73365400\",\"name\":\"Y. Chen\"},{\"authorId\":\"1387979739\",\"name\":\"Behzad Dariush\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"017484d832e0b217897adc889f9becbf1f8f3bcb\",\"title\":\"Unsupervised Domain Adaptation for Spatio-Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/017484d832e0b217897adc889f9becbf1f8f3bcb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1904.00696\",\"authors\":[{\"authorId\":\"4712803\",\"name\":\"Jiaojiao Zhao\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1109/CVPR.2019.01017\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"213a37f44d28799ebff6b20aa53867d4d7a08cc4\",\"title\":\"Dance With Flow: Two-In-One Stream Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/213a37f44d28799ebff6b20aa53867d4d7a08cc4\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1807.10982\",\"authors\":[{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"1781242\",\"name\":\"Abhinav Shrivastava\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1007/978-3-030-01252-6_20\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"6b325af08a63bc8f94c39ae1c12509dce23d755c\",\"title\":\"Actor-Centric Relation Network\",\"url\":\"https://www.semanticscholar.org/paper/6b325af08a63bc8f94c39ae1c12509dce23d755c\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1907.10837\",\"authors\":[{\"authorId\":\"2447769\",\"name\":\"Chunfei Ma\"},{\"authorId\":\"32407457\",\"name\":\"Joonhyang Choi\"},{\"authorId\":\"150936578\",\"name\":\"Byeongwon Lee\"},{\"authorId\":\"3246975\",\"name\":\"Seungji Yang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a3cb1fff165f191cf2a7d3be2b9efb7cb26e3ea8\",\"title\":\"Submission to ActivityNet Challenge 2019: Task B Spatio-temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/a3cb1fff165f191cf2a7d3be2b9efb7cb26e3ea8\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1905.11575\",\"authors\":[{\"authorId\":\"144045444\",\"name\":\"R. Su\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"6578587\",\"name\":\"L. Zhou\"},{\"authorId\":\"145481070\",\"name\":\"D. Xu\"}],\"doi\":\"10.1109/CVPR.2019.01229\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c3d445c883a396501acf3b5f2cd7680b2b953903\",\"title\":\"Improving Action Localization by Progressive Cross-Stream Cooperation\",\"url\":\"https://www.semanticscholar.org/paper/c3d445c883a396501acf3b5f2cd7680b2b953903\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2845745\",\"name\":\"Sovan Biswas\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1f2bd6effe8666d2843f66bcaae9724f7c453290\",\"title\":\"Discovering Multi-Label Actor-Action Association in a Weakly Supervised Setting\",\"url\":\"https://www.semanticscholar.org/paper/1f2bd6effe8666d2843f66bcaae9724f7c453290\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121961634\",\"name\":\"Yutang Wu\"},{\"authorId\":\"23604671\",\"name\":\"H. Wang\"},{\"authorId\":\"47672901\",\"name\":\"Shuheng Wang\"},{\"authorId\":\"8194130\",\"name\":\"Qinyu Li\"}],\"doi\":\"10.1109/ICASSP40776.2020.9054394\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"886653a4a10986596d39c45711f6f1f49b9d4e70\",\"title\":\"Enhanced Action Tubelet Detector for Spatio-Temporal Video Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/886653a4a10986596d39c45711f6f1f49b9d4e70\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1490866837\",\"name\":\"Chan Zheng\"},{\"authorId\":\"50030933\",\"name\":\"X. Yang\"},{\"authorId\":\"46875450\",\"name\":\"Xunmu Zhu\"},{\"authorId\":\"2023742062\",\"name\":\"Chen Changxin\"},{\"authorId\":\"49681427\",\"name\":\"L. Wang\"},{\"authorId\":\"41157630\",\"name\":\"Shuqin Tu\"},{\"authorId\":\"46889237\",\"name\":\"Aqing Yang\"},{\"authorId\":\"3104125\",\"name\":\"Yueju Xue\"}],\"doi\":\"10.1016/j.biosystemseng.2020.04.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c731fbe2dbe03aca753ef6f428bf2909054a8b92\",\"title\":\"Automatic posture change analysis of lactating sows by action localisation and tube optimisation from untrimmed depth videos\",\"url\":\"https://www.semanticscholar.org/paper/c731fbe2dbe03aca753ef6f428bf2909054a8b92\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2004.11475\",\"authors\":[{\"authorId\":\"9247631\",\"name\":\"M. N. Rizve\"},{\"authorId\":\"2935412\",\"name\":\"U. Demir\"},{\"authorId\":\"82021814\",\"name\":\"Praveen Tirupattur\"},{\"authorId\":\"1564031469\",\"name\":\"A. J. Rana\"},{\"authorId\":\"7839191\",\"name\":\"K. Duarte\"},{\"authorId\":\"27058669\",\"name\":\"I. Dave\"},{\"authorId\":\"2116440\",\"name\":\"Y. Rawat\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"beb5336d3babd2307887fd7ac7db5d946160f8a1\",\"title\":\"Gabriella: An Online System for Real-Time Activity Detection in Untrimmed Security Videos\",\"url\":\"https://www.semanticscholar.org/paper/beb5336d3babd2307887fd7ac7db5d946160f8a1\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1844969\",\"name\":\"Faming Gong\"},{\"authorId\":\"2024256982\",\"name\":\"Ma Yuhui\"},{\"authorId\":\"147858481\",\"name\":\"P. Zheng\"},{\"authorId\":\"145147427\",\"name\":\"T. Song\"},{\"authorId\":\"145147427\",\"name\":\"T. Song\"}],\"doi\":\"10.1016/j.jlp.2020.104043\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d5c9156cd61f03e84a03133e038c943206eef8f4\",\"title\":\"A deep model method for recognizing activities of workers on offshore drilling platform by multistage convolutional pose machine\",\"url\":\"https://www.semanticscholar.org/paper/d5c9156cd61f03e84a03133e038c943206eef8f4\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1803.00197\",\"authors\":[{\"authorId\":\"144847542\",\"name\":\"X. Chen\"},{\"authorId\":\"2376242\",\"name\":\"J. Yu\"},{\"authorId\":\"2290608\",\"name\":\"Zhengxing Wu\"}],\"doi\":\"10.1109/TCYB.2019.2894261\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f204290bd20817cc037dc87ba1d3664e9849434d\",\"title\":\"Temporally Identity-Aware SSD With Attentional LSTM\",\"url\":\"https://www.semanticscholar.org/paper/f204290bd20817cc037dc87ba1d3664e9849434d\",\"venue\":\"IEEE Transactions on Cybernetics\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152460549\",\"name\":\"Antonia Breuer\"},{\"authorId\":\"153269740\",\"name\":\"Jana Kirschner\"},{\"authorId\":\"1694892\",\"name\":\"S. Homoceanu\"},{\"authorId\":\"1679795\",\"name\":\"T. Fingscheidt\"}],\"doi\":\"10.1109/IVS.2019.8813816\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d16fab6cfc5f5a324e00e026d2b68c970f1b3702\",\"title\":\"Towards Tactical Maneuver Detection for Autonomous Driving Based on Vision Only\",\"url\":\"https://www.semanticscholar.org/paper/d16fab6cfc5f5a324e00e026d2b68c970f1b3702\",\"venue\":\"2019 IEEE Intelligent Vehicles Symposium (IV)\",\"year\":2019},{\"arxivId\":\"1812.03544\",\"authors\":[{\"authorId\":\"49890205\",\"name\":\"Yubo Zhang\"},{\"authorId\":\"2931554\",\"name\":\"P. Tokmakov\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1109/CVPR.2019.01021\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0181eb5f6f94df18586fea79d6ad37e583ff6f0c\",\"title\":\"A Structured Model for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/0181eb5f6f94df18586fea79d6ad37e583ff6f0c\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1812.05038\",\"authors\":[{\"authorId\":\"2978413\",\"name\":\"Chao-Yuan Wu\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"2681569\",\"name\":\"Haoqi Fan\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2562966\",\"name\":\"Philipp Kr\\u00e4henb\\u00fchl\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/CVPR.2019.00037\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"45cb2cbae5c0b4cc52e524cc191a2f8db674ed42\",\"title\":\"Long-Term Feature Banks for Detailed Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/45cb2cbae5c0b4cc52e524cc191a2f8db674ed42\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1905.00582\",\"authors\":[{\"authorId\":\"22255475\",\"name\":\"Ekraam Sabir\"},{\"authorId\":\"33896010\",\"name\":\"Jiaxin Cheng\"},{\"authorId\":\"26393556\",\"name\":\"Ayush Jaiswal\"},{\"authorId\":\"17806729\",\"name\":\"Wael AbdAlmageed\"},{\"authorId\":\"11269472\",\"name\":\"Iacopo Masi\"},{\"authorId\":\"145603129\",\"name\":\"P. Natarajan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4e910df41181637518563cf729d3bdaa166882c6\",\"title\":\"Recurrent Convolutional Strategies for Face Manipulation Detection in Videos\",\"url\":\"https://www.semanticscholar.org/paper/4e910df41181637518563cf729d3bdaa166882c6\",\"venue\":\"CVPR Workshops\",\"year\":2019},{\"arxivId\":\"1812.11631\",\"authors\":[{\"authorId\":\"32859304\",\"name\":\"Oytun Ulutan\"},{\"authorId\":\"34889835\",\"name\":\"S. Rallapalli\"},{\"authorId\":\"1718467\",\"name\":\"M. Srivatsa\"},{\"authorId\":\"50591689\",\"name\":\"B. S. Manjunath\"}],\"doi\":\"10.1109/WACV45572.2020.9093617\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"057d5e304f1f2f2bd6c35d5c861961ce102fcc48\",\"title\":\"Actor Conditioned Attention Maps for Video Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/057d5e304f1f2f2bd6c35d5c861961ce102fcc48\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40465774\",\"name\":\"Z. Gao\"},{\"authorId\":\"2028829514\",\"name\":\"Leming Guo\"},{\"authorId\":\"15880069\",\"name\":\"W. Guan\"},{\"authorId\":\"143602033\",\"name\":\"Anan Liu\"},{\"authorId\":\"1744930\",\"name\":\"T. Ren\"},{\"authorId\":\"1788427\",\"name\":\"Shengyong Chen\"}],\"doi\":\"10.1109/TIP.2020.3038372\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6648479157216bee1f31ef9718fcb64eeafa6843\",\"title\":\"A Pairwise Attentive Adversarial Spatiotemporal Network for Cross-Domain Few-Shot Action Recognition-R2\",\"url\":\"https://www.semanticscholar.org/paper/6648479157216bee1f31ef9718fcb64eeafa6843\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2021},{\"arxivId\":\"1804.01824\",\"authors\":[{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"3409955\",\"name\":\"C. D. Dao\"},{\"authorId\":\"143798882\",\"name\":\"Mihir Jain\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1016/j.cviu.2019.102886\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a427fc1fde8206136075785eda3d757278adfb44\",\"title\":\"Guess Where? Actor-Supervision for Spatiotemporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/a427fc1fde8206136075785eda3d757278adfb44\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2020},{\"arxivId\":\"1905.03922\",\"authors\":[{\"authorId\":\"144599697\",\"name\":\"Y. Feng\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"144416719\",\"name\":\"W. Liu\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2019.00138\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c19659297ac67a29d7524fba60062558f2235f8a\",\"title\":\"Spatio-Temporal Video Re-Localization by Warp LSTM\",\"url\":\"https://www.semanticscholar.org/paper/c19659297ac67a29d7524fba60062558f2235f8a\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1805.08162\",\"authors\":[{\"authorId\":\"7839191\",\"name\":\"K. Duarte\"},{\"authorId\":\"2116440\",\"name\":\"Y. Rawat\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d9a576f03fc5f6cabbd6291fb65db0ee0a607103\",\"title\":\"VideoCapsuleNet: A Simplified Network for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/d9a576f03fc5f6cabbd6291fb65db0ee0a607103\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"28145552\",\"name\":\"Hong-Chuan Chi\"},{\"authorId\":\"34701404\",\"name\":\"M. A. Sarwar\"},{\"authorId\":\"1423711882\",\"name\":\"Yousef-Awwad Daraghmi\"},{\"authorId\":\"150174890\",\"name\":\"Kuan-Wen Liu\"},{\"authorId\":\"72781398\",\"name\":\"T. Ik\"},{\"authorId\":\"1717444\",\"name\":\"Yih-Lang Li\"}],\"doi\":\"10.23919/APNOMS50412.2020.9237053\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8faa00496432c8a89f3326b4ad16882a84d35c5e\",\"title\":\"Smart Self-Checkout Carts Based on Deep Learning for Shopping Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8faa00496432c8a89f3326b4ad16882a84d35c5e\",\"venue\":\"2020 21st Asia-Pacific Network Operations and Management Symposium (APNOMS)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121033030\",\"name\":\"D. Papadopoulos\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"cc710563c48317bbd1b107c62dadf61bfb41a76f\",\"title\":\"Efficient human annotation schemes for training object class detectors\",\"url\":\"https://www.semanticscholar.org/paper/cc710563c48317bbd1b107c62dadf61bfb41a76f\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2006.11747\",\"authors\":[{\"authorId\":\"1500408667\",\"name\":\"Zhiyuan Fang\"},{\"authorId\":\"34362536\",\"name\":\"S. Kong\"},{\"authorId\":\"1521319166\",\"name\":\"Zhe Wang\"},{\"authorId\":\"143800213\",\"name\":\"Charless C. Fowlkes\"},{\"authorId\":\"1784500\",\"name\":\"Yezhou Yang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a792ff56eeed530fab1935168510cbb16b0f1b68\",\"title\":\"Weak Supervision and Referring Attention for Temporal-Textual Association Learning\",\"url\":\"https://www.semanticscholar.org/paper/a792ff56eeed530fab1935168510cbb16b0f1b68\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1801.09823\",\"authors\":[{\"authorId\":\"144963395\",\"name\":\"P. Tang\"},{\"authorId\":\"121900578\",\"name\":\"Chunyu Wang\"},{\"authorId\":\"2443233\",\"name\":\"Xinggang Wang\"},{\"authorId\":\"46641540\",\"name\":\"W. Liu\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"},{\"authorId\":\"1688516\",\"name\":\"Jingdong Wang\"}],\"doi\":null,\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"816184ba9e9dddbe0e62ae2db423124ef87241d6\",\"title\":\"Object Detection in Videos by Short and Long Range Object Linking\",\"url\":\"https://www.semanticscholar.org/paper/816184ba9e9dddbe0e62ae2db423124ef87241d6\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145560551\",\"name\":\"Harkirat Singh Behl\"},{\"authorId\":null,\"name\":\"Suman Saha\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c8207eab3fef93c6f88db4c8ba98a23bd1f57657\",\"title\":\"Supplementary Material : Incremental Tube Construction for Human Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/c8207eab3fef93c6f88db4c8ba98a23bd1f57657\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1908.08178\",\"authors\":[{\"authorId\":\"48754312\",\"name\":\"Pengfei Zhang\"},{\"authorId\":\"48696416\",\"name\":\"Y. Cao\"},{\"authorId\":\"1761508\",\"name\":\"B. Liu\"}],\"doi\":\"10.1109/ICIP.2019.8803564\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f0ba9505b5f625fae2a0b50c89224744f5b11207\",\"title\":\"Multi-Stream Single Shot Spatial-Temporal Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/f0ba9505b5f625fae2a0b50c89224744f5b11207\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2845745\",\"name\":\"Sovan Biswas\"},{\"authorId\":\"1889486\",\"name\":\"Yaser Souri\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1109/ICIP.2019.8803650\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0b28c19bc1dd8d6db7fa65c1aa5aa6714463c0e5\",\"title\":\"Hierarchical Graph-Rnns for Action Detection of Multiple Activities\",\"url\":\"https://www.semanticscholar.org/paper/0b28c19bc1dd8d6db7fa65c1aa5aa6714463c0e5\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1669712931\",\"name\":\"Arpan Gupta\"},{\"authorId\":\"3247309\",\"name\":\"Sakthi Balan Muthiah\"}],\"doi\":\"10.1145/3293353.3293415\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8889beea3ae4e529f888525e33bd2160559f9153\",\"title\":\"Temporal Cricket Stroke Localization from Untrimmed Highlight Videos\",\"url\":\"https://www.semanticscholar.org/paper/8889beea3ae4e529f888525e33bd2160559f9153\",\"venue\":\"ICVGIP\",\"year\":2018},{\"arxivId\":\"2006.07164\",\"authors\":[{\"authorId\":\"35466947\",\"name\":\"Vivek Singh Bawa\"},{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":\"1748978266\",\"name\":\"F. Kaping\\u2019a\"},{\"authorId\":\"1748969584\",\"name\":\"InnaSkarga-Bandurova\"},{\"authorId\":\"144438143\",\"name\":\"A. Leporini\"},{\"authorId\":\"1712241178\",\"name\":\"Carmela Landolfo\"},{\"authorId\":\"40628457\",\"name\":\"A. Stabile\"},{\"authorId\":\"51150498\",\"name\":\"F. Setti\"},{\"authorId\":\"2869400\",\"name\":\"R. Muradore\"},{\"authorId\":\"2375276\",\"name\":\"E. Oleari\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7594f3ee9b0bee6d26c0467bfe4bbc72a34e092f\",\"title\":\"ESAD: Endoscopic Surgeon Action Detection Dataset\",\"url\":\"https://www.semanticscholar.org/paper/7594f3ee9b0bee6d26c0467bfe4bbc72a34e092f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144957857\",\"name\":\"H. Nishimura\"},{\"authorId\":\"2764854\",\"name\":\"K. Tasaka\"},{\"authorId\":\"1770200\",\"name\":\"Y. Kawanishi\"},{\"authorId\":\"82910116\",\"name\":\"H. Murase\"}],\"doi\":\"10.3169/mta.8.269\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3a1ba4af7caa08a2dd5a69dd99499d544dd2178d\",\"title\":\"[Paper] Multiple Human Tracking with Alternately Updating Trajectories and Multi-Frame Action Features\",\"url\":\"https://www.semanticscholar.org/paper/3a1ba4af7caa08a2dd5a69dd99499d544dd2178d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1805.11333\",\"authors\":[{\"authorId\":\"40892875\",\"name\":\"Pascal Mettes\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1007/s11263-018-1120-4\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"90f457c30a678ea879827b6d576ec4b97e404c28\",\"title\":\"Pointly-Supervised Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/90f457c30a678ea879827b6d576ec4b97e404c28\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018}],\"corpusId\":1191338,\"doi\":\"10.1109/ICCV.2017.472\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":23,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"8dea2081609d838dc5b5a929f2ac19ce0c41c9a0\",\"references\":[{\"arxivId\":\"1506.02640\",\"authors\":[{\"authorId\":\"40497777\",\"name\":\"Joseph Redmon\"},{\"authorId\":\"2038685\",\"name\":\"S. Divvala\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"47465174\",\"name\":\"Ali Farhadi\"}],\"doi\":\"10.1109/CVPR.2016.91\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f8e79ac0ea341056ef20f2616628b3e964764cfd\",\"title\":\"You Only Look Once: Unified, Real-Time Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/f8e79ac0ea341056ef20f2616628b3e964764cfd\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1007/978-3-319-46493-0_45\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"ddbd24a73ba3d74028596f393bb07a6b87a469c0\",\"title\":\"Multi-region Two-Stream R-CNN for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/ddbd24a73ba3d74028596f393bb07a6b87a469c0\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"144565371\",\"name\":\"P. P\\u00e9rez\"}],\"doi\":\"10.1109/ICCV.2007.4409105\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c6cd1a1c1e6bde8e06120c431d4e816e4d67f249\",\"title\":\"Retrieving actions in movies\",\"url\":\"https://www.semanticscholar.org/paper/c6cd1a1c1e6bde8e06120c431d4e816e4d67f249\",\"venue\":\"2007 IEEE 11th International Conference on Computer Vision\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2753268\",\"name\":\"Mihai Marian Puscas\"},{\"authorId\":\"1716310\",\"name\":\"E. Sangineto\"},{\"authorId\":\"2876527\",\"name\":\"D. Culibrk\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":\"10.1109/ICCV.2015.193\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"beaab7075f1961b72884a7da8b9e942df787a39f\",\"title\":\"Unsupervised Tube Extraction Using Transductive Learning and Dense Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/beaab7075f1961b72884a7da8b9e942df787a39f\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50504401\",\"name\":\"Wei Chen\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1109/ICCV.2015.377\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8336e17542aacd02e644bc029389800bf248d470\",\"title\":\"Action Detection by Implicit Intentional Motion Clustering\",\"url\":\"https://www.semanticscholar.org/paper/8336e17542aacd02e644bc029389800bf248d470\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738975\",\"name\":\"J. C. V. Gemert\"},{\"authorId\":\"143798882\",\"name\":\"Mihir Jain\"},{\"authorId\":\"33379011\",\"name\":\"E. Gati\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.5244/C.29.177\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"21ef7e01de0e1feb4b21c89ccb0423e4213bb9e0\",\"title\":\"APT: Action localization proposals from dense trajectories\",\"url\":\"https://www.semanticscholar.org/paper/21ef7e01de0e1feb4b21c89ccb0423e4213bb9e0\",\"venue\":\"BMVC\",\"year\":2015},{\"arxivId\":\"1611.08563\",\"authors\":[{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":null,\"name\":\"Suman Saha\"},{\"authorId\":\"145466505\",\"name\":\"M. Sapienza\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":\"10.1109/ICCV.2017.393\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"df990d13fbe2e0a982061fc449e9c7e0aa9f357f\",\"title\":\"Online Real-Time Multiple Spatiotemporal Action Localisation and Prediction\",\"url\":\"https://www.semanticscholar.org/paper/df990d13fbe2e0a982061fc449e9c7e0aa9f357f\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1823362\",\"name\":\"J. Uijlings\"},{\"authorId\":\"1756979\",\"name\":\"K. V. D. Sande\"},{\"authorId\":\"1620219267\",\"name\":\"Theo Gevers\"},{\"authorId\":\"144638781\",\"name\":\"A. Smeulders\"}],\"doi\":\"10.1007/s11263-013-0620-5\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"38b6540ddd5beebffd05047c78183f7575559fb2\",\"title\":\"Selective Search for Object Recognition\",\"url\":\"https://www.semanticscholar.org/paper/38b6540ddd5beebffd05047c78183f7575559fb2\",\"venue\":\"International Journal of Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49049934\",\"name\":\"J. Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0ec48ac86456cea3d6d6172ca81ef68e98b21a61\",\"title\":\"The PASCAL Visual Object Classes Challenge\",\"url\":\"https://www.semanticscholar.org/paper/0ec48ac86456cea3d6d6172ca81ef68e98b21a61\",\"venue\":\"\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145015817\",\"name\":\"Gang Yu\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1109/CVPR.2015.7298735\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"22df6b6c87d26f51c0ccf3d4dddad07ce839deb0\",\"title\":\"Fast action proposals for human action detection and search\",\"url\":\"https://www.semanticscholar.org/paper/22df6b6c87d26f51c0ccf3d4dddad07ce839deb0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Perera\"},{\"authorId\":null,\"name\":\"N. Cuntoor\"},{\"authorId\":null,\"name\":\"C.-C. Chen\"},{\"authorId\":null,\"name\":\"J. T. Lee\"},{\"authorId\":null,\"name\":\"S. Mukherjee\"},{\"authorId\":null,\"name\":\"J. Aggarwal\"},{\"authorId\":null,\"name\":\"H. Lee\"},{\"authorId\":null,\"name\":\"L. Davis\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"A large - scale benchmark dataset for event recognition in surveillance video\",\"url\":\"\",\"venue\":\"\",\"year\":2011},{\"arxivId\":\"1608.01529\",\"authors\":[{\"authorId\":null,\"name\":\"Suman Saha\"},{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":\"145466505\",\"name\":\"M. Sapienza\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":\"10.5244/C.30.58\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6b0983e11312938381bb9d11ef42612aaf78f5f4\",\"title\":\"Deep Learning for Detecting Multiple Space-Time Action Tubes in Videos\",\"url\":\"https://www.semanticscholar.org/paper/6b0983e11312938381bb9d11ef42612aaf78f5f4\",\"venue\":\"BMVC\",\"year\":2016},{\"arxivId\":\"1212.0402\",\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"title\":\"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\",\"url\":\"https://www.semanticscholar.org/paper/da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J. Redmon\"},{\"authorId\":null,\"name\":\"S. Divvala\"},{\"authorId\":null,\"name\":\"R. Girshick\"},{\"authorId\":null,\"name\":\"A. Farhadi\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"You only look once: Unified\",\"url\":\"\",\"venue\":\"real-time object detection. In CVPR\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"M. D. Rodriguez\"},{\"authorId\":null,\"name\":\"J. Ahmed\"},{\"authorId\":null,\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"To - wards real - time object detection with region proposal networks\",\"url\":\"\",\"venue\":\"In NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1678553621\",\"name\":\"Martin P. Catherwood\"}],\"doi\":\"10.1515/9783111576855-016\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"725cd02f9ab4e5e4f7db6ef0d2ff5b13819a6fc1\",\"title\":\"K\",\"url\":\"https://www.semanticscholar.org/paper/725cd02f9ab4e5e4f7db6ef0d2ff5b13819a6fc1\",\"venue\":\"Edinburgh Medical and Surgical Journal\",\"year\":1824},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50504401\",\"name\":\"Wei Chen\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"144418348\",\"name\":\"R. Xu\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1109/CVPR.2014.101\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6226f4040fce4e636c75b9fd3abd42c4f32639dd\",\"title\":\"Actionness Ranking with Lattice Conditional Ordinal Random Fields\",\"url\":\"https://www.semanticscholar.org/paper/6226f4040fce4e636c75b9fd3abd42c4f32639dd\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143928529\",\"name\":\"Tian Lan\"},{\"authorId\":\"46396571\",\"name\":\"Y. Wang\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"}],\"doi\":\"10.1109/ICCV.2011.6126472\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"40da1560afbf65bb1d66e75a33dfe617e0dc4a2e\",\"title\":\"Discriminative figure-centric models for joint action localization and recognition\",\"url\":\"https://www.semanticscholar.org/paper/40da1560afbf65bb1d66e75a33dfe617e0dc4a2e\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":\"1607.01794\",\"authors\":[{\"authorId\":\"3245057\",\"name\":\"Zhenyang Li\"},{\"authorId\":\"32781361\",\"name\":\"Kirill Gavrilyuk\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"143798882\",\"name\":\"Mihir Jain\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1016/j.cviu.2017.10.011\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"86031f555c128b82a1ac0db89ff4faeae16a1802\",\"title\":\"VideoLSTM convolves, attends and flows for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/86031f555c128b82a1ac0db89ff4faeae16a1802\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2018},{\"arxivId\":\"1406.2199\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"title\":\"Two-Stream Convolutional Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1603.03590\",\"authors\":[{\"authorId\":\"2515835\",\"name\":\"Till Kroeger\"},{\"authorId\":\"1732855\",\"name\":\"R. Timofte\"},{\"authorId\":\"1778526\",\"name\":\"Dengxin Dai\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-319-46493-0_29\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9ceb5b92cad5cb135aaab43d4f25a6e34afe6e9f\",\"title\":\"Fast Optical Flow Using Dense Inverse Search\",\"url\":\"https://www.semanticscholar.org/paper/9ceb5b92cad5cb135aaab43d4f25a6e34afe6e9f\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Z. Li\"},{\"authorId\":null,\"name\":\"E. Gavves\"},{\"authorId\":null,\"name\":\"M. Jain\"},{\"authorId\":null,\"name\":\"C. G. Snoek\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"VideoLSTM convolves\",\"url\":\"\",\"venue\":\"attends and flows for action recognition. In arXiv\",\"year\":2016},{\"arxivId\":\"1502.08029\",\"authors\":[{\"authorId\":\"145095579\",\"name\":\"L. Yao\"},{\"authorId\":\"1730844\",\"name\":\"Atousa Torabi\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"2482072\",\"name\":\"Nicolas Ballas\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":\"10.1109/ICCV.2015.512\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5f425b7abf2ed3172ed060df85bb1885860a297e\",\"title\":\"Describing Videos by Exploiting Temporal Structure\",\"url\":\"https://www.semanticscholar.org/paper/5f425b7abf2ed3172ed060df85bb1885860a297e\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1608.00859\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-319-46484-8_2\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"title\":\"Temporal Segment Networks: Towards Good Practices for Deep Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"M. Everingham\"},{\"authorId\":null,\"name\":\"L. Van Gool\"},{\"authorId\":null,\"name\":\"C. Williams\"},{\"authorId\":null,\"name\":\"J. Winn\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and A\",\"url\":\"\",\"venue\":\"Zisserman. The PASCAL Visual Object Classes Challenge 2007 \",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143798882\",\"name\":\"Mihir Jain\"},{\"authorId\":\"1738975\",\"name\":\"J. C. V. Gemert\"},{\"authorId\":\"1681054\",\"name\":\"H. J\\u00e9gou\"},{\"authorId\":\"1716733\",\"name\":\"P. Bouthemy\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1109/CVPR.2014.100\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"377ad65969b98823dc5f28815d8a01b74fc1b79a\",\"title\":\"Action Localization with Tubelets from Motion\",\"url\":\"https://www.semanticscholar.org/paper/377ad65969b98823dc5f28815d8a01b74fc1b79a\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1505.00487\",\"authors\":[{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/ICCV.2015.515\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e58a110fa1e4ddf247d5c614d117d64bfbe135c4\",\"title\":\"Sequence to Sequence -- Video to Text\",\"url\":\"https://www.semanticscholar.org/paper/e58a110fa1e4ddf247d5c614d117d64bfbe135c4\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40506509\",\"name\":\"W. Hu\"},{\"authorId\":\"143874948\",\"name\":\"T. Tan\"},{\"authorId\":null,\"name\":\"Liang Wang\"},{\"authorId\":\"144555237\",\"name\":\"S. Maybank\"}],\"doi\":\"10.1109/TSMCC.2004.829274\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"461efc87636ff4e48323ffcb9f8fdf79cf736fb0\",\"title\":\"A survey on visual surveillance of object motion and behaviors\",\"url\":\"https://www.semanticscholar.org/paper/461efc87636ff4e48323ffcb9f8fdf79cf736fb0\",\"venue\":\"IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)\",\"year\":2004},{\"arxivId\":\"1506.01497\",\"authors\":[{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"144716314\",\"name\":\"J. Sun\"}],\"doi\":\"10.1109/TPAMI.2016.2577031\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"title\":\"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\",\"url\":\"https://www.semanticscholar.org/paper/424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2015},{\"arxivId\":\"1311.2524\",\"authors\":[{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"153652146\",\"name\":\"J. Malik\"}],\"doi\":\"10.1109/CVPR.2014.81\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2f4df08d9072fc2ac181b7fced6a245315ce05c8\",\"title\":\"Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/2f4df08d9072fc2ac181b7fced6a245315ce05c8\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48749954\",\"name\":\"L. Cao\"},{\"authorId\":\"1691128\",\"name\":\"Zicheng Liu\"},{\"authorId\":\"1739208\",\"name\":\"T. Huang\"}],\"doi\":\"10.1109/CVPR.2010.5539875\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"071c86ee1e28008f06a43da962174bd702d9f408\",\"title\":\"Cross-dataset action detection\",\"url\":\"https://www.semanticscholar.org/paper/071c86ee1e28008f06a43da962174bd702d9f408\",\"venue\":\"2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2676982\",\"name\":\"Hueihan Jhuang\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"},{\"authorId\":\"2133988\",\"name\":\"S. Zuffi\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"}],\"doi\":\"10.1109/ICCV.2013.396\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2cee43afc7aad6a8f7c4a6d566b60ebc79d57e7a\",\"title\":\"Towards Understanding Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2cee43afc7aad6a8f7c4a6d566b60ebc79d57e7a\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50364379\",\"name\":\"S. Oh\"},{\"authorId\":\"1397590190\",\"name\":\"A. Hoogs\"},{\"authorId\":\"145895163\",\"name\":\"A. Perera\"},{\"authorId\":\"1803047\",\"name\":\"Naresh P. Cuntoor\"},{\"authorId\":\"1786891\",\"name\":\"Chia-Chih Chen\"},{\"authorId\":\"37095078\",\"name\":\"J. T. Lee\"},{\"authorId\":\"2972072\",\"name\":\"S. Mukherjee\"},{\"authorId\":\"1705627\",\"name\":\"J. Aggarwal\"},{\"authorId\":\"2445131\",\"name\":\"Hyungtae Lee\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"},{\"authorId\":\"2754027\",\"name\":\"E. Swears\"},{\"authorId\":\"48631781\",\"name\":\"Xiaoyang Wang\"},{\"authorId\":\"144116884\",\"name\":\"Qiang Ji\"},{\"authorId\":\"1382043304\",\"name\":\"K. K. Reddy\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"2367683\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"145104025\",\"name\":\"Jenny Yuen\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"},{\"authorId\":\"145178895\",\"name\":\"Bi Song\"},{\"authorId\":\"1409113695\",\"name\":\"Anesco Fong\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"},{\"authorId\":\"46988196\",\"name\":\"Mita Desai\"}],\"doi\":\"10.1109/CVPR.2011.5995586\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2c305fa65fed336e6be1d15a6567075c6ea6e51b\",\"title\":\"A large-scale benchmark dataset for event recognition in surveillance video\",\"url\":\"https://www.semanticscholar.org/paper/2c305fa65fed336e6be1d15a6567075c6ea6e51b\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Z. Li\"},{\"authorId\":null,\"name\":\"E. Gavves\"},{\"authorId\":null,\"name\":\"M. Jain\"},{\"authorId\":null,\"name\":\"C. G. Snoek\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"VideoLSTM convolves\",\"url\":\"\",\"venue\":\"attends and flows for action recognition. In arXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3095774\",\"name\":\"Dan Oneata\"},{\"authorId\":\"3428663\",\"name\":\"J\\u00e9r\\u00f4me Revaud\"},{\"authorId\":\"1721683\",\"name\":\"J. Verbeek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1007/978-3-319-10578-9_48\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5d35db6d5bee363fcaf3ca9397cc063f023e0252\",\"title\":\"Spatio-temporal Object Detection Proposals\",\"url\":\"https://www.semanticscholar.org/paper/5d35db6d5bee363fcaf3ca9397cc063f023e0252\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123135459\",\"name\":\"Mikel D. Rodriguez\"},{\"authorId\":\"144643948\",\"name\":\"Javed Ahmed\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/CVPR.2008.4587727\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1c2629d53fd73ee42fb9a67b4d656688ef6a005f\",\"title\":\"Action MACH a spatio-temporal Maximum Average Correlation Height filter for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/1c2629d53fd73ee42fb9a67b4d656688ef6a005f\",\"venue\":\"2008 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2008},{\"arxivId\":\"1604.07279\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2016.296\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1e667851f67aaa4d3f75d662760a783f45ea4b05\",\"title\":\"Actionness Estimation Using Hybrid Fully Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/1e667851f67aaa4d3f75d662760a783f45ea4b05\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1604.06573\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2016.213\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d9aced120e530484609164c836da64548693484\",\"title\":\"Convolutional Two-Stream Network Fusion for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9d9aced120e530484609164c836da64548693484\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1411.6031\",\"authors\":[{\"authorId\":\"2082991\",\"name\":\"Georgia Gkioxari\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/CVPR.2015.7298676\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"295a1c000c5e3fd5959bb250e8376a06efa405b1\",\"title\":\"Finding action tubes\",\"url\":\"https://www.semanticscholar.org/paper/295a1c000c5e3fd5959bb250e8376a06efa405b1\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1512.02325\",\"authors\":[{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"1838674\",\"name\":\"Dragomir Anguelov\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"144828948\",\"name\":\"S. Reed\"},{\"authorId\":\"2667317\",\"name\":\"Cheng-Yang Fu\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"}],\"doi\":\"10.1007/978-3-319-46448-0_2\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4d7a9197433acbfb24ef0e9d0f33ed1699e4a5b0\",\"title\":\"SSD: Single Shot MultiBox Detector\",\"url\":\"https://www.semanticscholar.org/paper/4d7a9197433acbfb24ef0e9d0f33ed1699e4a5b0\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1506.01929\",\"authors\":[{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"1753355\",\"name\":\"Z. Harchaoui\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2015.362\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"2f488a8139630e3b2499ea2d3ff192e33387f7de\",\"title\":\"Learning to Track for Spatio-Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/2f488a8139630e3b2499ea2d3ff192e33387f7de\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5886094\",\"name\":\"P. Cochat\"},{\"authorId\":\"13267685\",\"name\":\"L. Vaucoret\"},{\"authorId\":\"31455512\",\"name\":\"J. Sarles\"}],\"doi\":\"10.1016/j.arcped.2012.01.013\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"10d85561e4aafc516d10064f30dff05b41f70afe\",\"title\":\"[Et al].\",\"url\":\"https://www.semanticscholar.org/paper/10d85561e4aafc516d10064f30dff05b41f70afe\",\"venue\":\"Archives de pediatrie : organe officiel de la Societe francaise de pediatrie\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1710872\",\"name\":\"T. Brox\"},{\"authorId\":\"144031005\",\"name\":\"A. Bruhn\"},{\"authorId\":\"2188270\",\"name\":\"N. Papenberg\"},{\"authorId\":\"7789445\",\"name\":\"J. Weickert\"}],\"doi\":\"10.1007/978-3-540-24673-2_3\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"91228e00fe33ed6072cfe849ab9e98160461549d\",\"title\":\"High Accuracy Optical Flow Estimation Based on a Theory for Warping\",\"url\":\"https://www.semanticscholar.org/paper/91228e00fe33ed6072cfe849ab9e98160461549d\",\"venue\":\"ECCV\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1881509\",\"name\":\"Vicky Kalogeiton\"},{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"143865718\",\"name\":\"V. Ferrari\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"09926ed62511c340f4540b5bc53cf2480e8063f8\",\"title\":\"Tubelet Detector for Spatio-Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/09926ed62511c340f4540b5bc53cf2480e8063f8\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3056091\",\"name\":\"M. Everingham\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"},{\"authorId\":\"145715698\",\"name\":\"C. K. Williams\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6a2ed19ac684022aa3186887cd4893484ab8f80c\",\"title\":\"The PASCAL visual object classes challenge 2006 (VOC2006) results\",\"url\":\"https://www.semanticscholar.org/paper/6a2ed19ac684022aa3186887cd4893484ab8f80c\",\"venue\":\"\",\"year\":2006}],\"title\":\"Action Tubelet Detector for Spatio-Temporal Action Localization\",\"topics\":[{\"topic\":\"Solid-state drive\",\"topicId\":\"30552\",\"url\":\"https://www.semanticscholar.org/topic/30552\"},{\"topic\":\"Scott continuity\",\"topicId\":\"79000\",\"url\":\"https://www.semanticscholar.org/topic/79000\"},{\"topic\":\"Sensor\",\"topicId\":\"1117\",\"url\":\"https://www.semanticscholar.org/topic/1117\"},{\"topic\":\"Cuboid\",\"topicId\":\"321750\",\"url\":\"https://www.semanticscholar.org/topic/321750\"},{\"topic\":\"Action potential\",\"topicId\":\"343\",\"url\":\"https://www.semanticscholar.org/topic/343\"},{\"topic\":\"Human Metabolome Database\",\"topicId\":\"214982\",\"url\":\"https://www.semanticscholar.org/topic/214982\"},{\"topic\":\"Stacking\",\"topicId\":\"100839\",\"url\":\"https://www.semanticscholar.org/topic/100839\"}],\"url\":\"https://www.semanticscholar.org/paper/8dea2081609d838dc5b5a929f2ac19ce0c41c9a0\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017}\n"