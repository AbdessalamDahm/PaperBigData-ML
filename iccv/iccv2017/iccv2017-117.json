"{\"abstract\":\"Training a feed-forward network for the fast neural style transfer of images has proven successful, but the naive extension of processing videos frame by frame is prone to producing flickering results. We propose the first end-toend network for online video style transfer, which generates temporally coherent stylized video sequences in near realtime. Two key ideas include an efficient network by incorporating short-term coherence, and propagating short-term coherence to long-term, which ensures consistency over a longer period of time. Our network can incorporate different image stylization networks and clearly outperforms the per-frame baseline both qualitatively and quantitatively. Moreover, it can achieve visually comparable coherence to optimization-based video style transfer, but is three orders of magnitude faster.\",\"arxivId\":\"1703.09211\",\"authors\":[{\"authorId\":\"49025576\",\"name\":\"Dongdong Chen\",\"url\":\"https://www.semanticscholar.org/author/49025576\"},{\"authorId\":null,\"name\":\"Jing Liao\",\"url\":null},{\"authorId\":\"145347148\",\"name\":\"L. Yuan\",\"url\":\"https://www.semanticscholar.org/author/145347148\"},{\"authorId\":\"1708598\",\"name\":\"N. Yu\",\"url\":\"https://www.semanticscholar.org/author/1708598\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\",\"url\":\"https://www.semanticscholar.org/author/144988571\"}],\"citationVelocity\":40,\"citations\":[{\"arxivId\":\"1807.01197\",\"authors\":[{\"authorId\":\"144525219\",\"name\":\"Chang Gao\"},{\"authorId\":\"51115672\",\"name\":\"Derun Gu\"},{\"authorId\":\"6767755\",\"name\":\"Fangjun Zhang\"},{\"authorId\":\"1841911\",\"name\":\"Y. Yu\"}],\"doi\":\"10.1007/978-3-030-20876-9_40\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"767eeaa478b835b7276523a6b1d018b21f0f83c1\",\"title\":\"ReCoNet: Real-time Coherent Video Style Transfer Network\",\"url\":\"https://www.semanticscholar.org/paper/767eeaa478b835b7276523a6b1d018b21f0f83c1\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"2003.13045\",\"authors\":[{\"authorId\":\"1391190989\",\"name\":\"L. Liu\"},{\"authorId\":\"73329364\",\"name\":\"Jiangning Zhang\"},{\"authorId\":\"1452345139\",\"name\":\"Ruifei He\"},{\"authorId\":\"93006732\",\"name\":\"Y. Liu\"},{\"authorId\":null,\"name\":\"Yabiao Wang\"},{\"authorId\":\"144970872\",\"name\":\"Ying Tai\"},{\"authorId\":\"9393671\",\"name\":\"Donghao Luo\"},{\"authorId\":\"1978245\",\"name\":\"Chengjie Wang\"},{\"authorId\":\"49298244\",\"name\":\"Jilin Li\"},{\"authorId\":\"1835006\",\"name\":\"Feiyue Huang\"}],\"doi\":\"10.1109/cvpr42600.2020.00652\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0555d625f3cc6992c503489933784e06c96abc68\",\"title\":\"Learning by Analogy: Reliable Supervision From Transformations for Unsupervised Optical Flow Estimation\",\"url\":\"https://www.semanticscholar.org/paper/0555d625f3cc6992c503489933784e06c96abc68\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1909.07074\",\"authors\":[{\"authorId\":\"9366027\",\"name\":\"Chanho Eom\"},{\"authorId\":\"31237220\",\"name\":\"Hyunjong Park\"},{\"authorId\":\"38723538\",\"name\":\"Bumsub Ham\"}],\"doi\":\"10.1109/TITS.2019.2942096\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d8cc9de85ec4799fd739c2d0ffd7fe06fa0e19e4\",\"title\":\"Temporally Consistent Depth Prediction With Flow-Guided Memory Units\",\"url\":\"https://www.semanticscholar.org/paper/d8cc9de85ec4799fd739c2d0ffd7fe06fa0e19e4\",\"venue\":\"IEEE Transactions on Intelligent Transportation Systems\",\"year\":2020},{\"arxivId\":\"1811.09393\",\"authors\":[{\"authorId\":\"32464128\",\"name\":\"Mengyu Chu\"},{\"authorId\":\"9071227\",\"name\":\"You Xie\"},{\"authorId\":\"2208679\",\"name\":\"Jonas Mayer\"},{\"authorId\":\"1388407684\",\"name\":\"L. Leal-Taix\\u00e9\"},{\"authorId\":\"1786445\",\"name\":\"N. Th\\u00fcrey\"}],\"doi\":\"10.1145/3386569.3392457\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9e52488ea7e83bf44aaa94c86b337a66f326c5e6\",\"title\":\"Learning temporal coherence via self-supervision for GAN-based video generation\",\"url\":\"https://www.semanticscholar.org/paper/9e52488ea7e83bf44aaa94c86b337a66f326c5e6\",\"venue\":\"ACM Trans. Graph.\",\"year\":2020},{\"arxivId\":\"1908.09514\",\"authors\":[{\"authorId\":\"145906066\",\"name\":\"Yang Chen\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"40434674\",\"name\":\"X. Tian\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1145/3343031.3350937\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"61a8b0469f6eec9b6b78433c40a2a3e197f8787e\",\"title\":\"Mocycle-GAN: Unpaired Video-to-Video Translation\",\"url\":\"https://www.semanticscholar.org/paper/61a8b0469f6eec9b6b78433c40a2a3e197f8787e\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1807.06587\",\"authors\":[{\"authorId\":\"4938340\",\"name\":\"Mingming He\"},{\"authorId\":\"49025576\",\"name\":\"Dongdong Chen\"},{\"authorId\":null,\"name\":\"Jing Liao\"},{\"authorId\":\"145891472\",\"name\":\"Pedro V. Sander\"},{\"authorId\":\"145347148\",\"name\":\"L. Yuan\"}],\"doi\":\"10.1145/3197517.3201365\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3149e4ec173374bae629188aa23b2020f4c6c8eb\",\"title\":\"Deep exemplar-based colorization\",\"url\":\"https://www.semanticscholar.org/paper/3149e4ec173374bae629188aa23b2020f4c6c8eb\",\"venue\":\"ACM Trans. Graph.\",\"year\":2018},{\"arxivId\":\"2010.11838\",\"authors\":[{\"authorId\":\"2121274\",\"name\":\"Chenyang Lei\"},{\"authorId\":\"152136086\",\"name\":\"Yazhou Xing\"},{\"authorId\":\"1559427865\",\"name\":\"Qifeng Chen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6716353f880fd7cb2be30d82c3f1dcd3abaebd98\",\"title\":\"Blind Video Temporal Consistency via Deep Video Prior\",\"url\":\"https://www.semanticscholar.org/paper/6716353f880fd7cb2be30d82c3f1dcd3abaebd98\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2011.07815\",\"authors\":[{\"authorId\":\"1423723631\",\"name\":\"Hao Su\"},{\"authorId\":\"143929163\",\"name\":\"J. Niu\"},{\"authorId\":\"37305311\",\"name\":\"X. Liu\"},{\"authorId\":\"47422334\",\"name\":\"Q. Li\"},{\"authorId\":\"144768030\",\"name\":\"Ji Wan\"},{\"authorId\":\"2285442\",\"name\":\"M. Xu\"},{\"authorId\":\"48419180\",\"name\":\"Tao Ren\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"912c9b3c3f3913b4ace558512d1c1925b89c4023\",\"title\":\"An End-to-end Method for Producing Scanning-robust Stylized QR Codes\",\"url\":\"https://www.semanticscholar.org/paper/912c9b3c3f3913b4ace558512d1c1925b89c4023\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1808.06847\",\"authors\":[{\"authorId\":\"3451442\",\"name\":\"Kfir Aberman\"},{\"authorId\":\"5807605\",\"name\":\"M. Shi\"},{\"authorId\":\"1400217664\",\"name\":\"Jing Liao\"},{\"authorId\":\"1684384\",\"name\":\"Dani Lischinski\"},{\"authorId\":\"1748939\",\"name\":\"B. Chen\"},{\"authorId\":\"1388323541\",\"name\":\"D. Cohen-Or\"}],\"doi\":\"10.1111/cgf.13632\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c14e77fc10f133358903019f45132d694682ab88\",\"title\":\"Deep Video\\u2010Based Performance Cloning\",\"url\":\"https://www.semanticscholar.org/paper/c14e77fc10f133358903019f45132d694682ab88\",\"venue\":\"Comput. Graph. Forum\",\"year\":2019},{\"arxivId\":\"1809.01726\",\"authors\":[{\"authorId\":\"51442114\",\"name\":\"Maciej Pesko\"},{\"authorId\":\"144432036\",\"name\":\"T. Trzci\\u0144ski\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"26fa3d9b589ca1d8c5dc5a10a5766bb172b096ab\",\"title\":\"Neural Comic Style Transfer: Case Study\",\"url\":\"https://www.semanticscholar.org/paper/26fa3d9b589ca1d8c5dc5a10a5766bb172b096ab\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2004.03142\",\"authors\":[{\"authorId\":\"48116039\",\"name\":\"Jian Ren\"},{\"authorId\":\"1752091\",\"name\":\"M. Chai\"},{\"authorId\":\"145582202\",\"name\":\"S. Tulyakov\"},{\"authorId\":\"49479171\",\"name\":\"Chen Fang\"},{\"authorId\":\"50457502\",\"name\":\"Xiaohui Shen\"},{\"authorId\":\"47988297\",\"name\":\"Jianchao Yang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dce3f80b0e1f43aa6fa94288710da0a5bdae2a9d\",\"title\":\"Human Motion Transfer from Poses in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/dce3f80b0e1f43aa6fa94288710da0a5bdae2a9d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1808.00449\",\"authors\":[{\"authorId\":\"2268189\",\"name\":\"Wei-Sheng Lai\"},{\"authorId\":\"3068086\",\"name\":\"Jia-Bin Huang\"},{\"authorId\":\"39231399\",\"name\":\"O. Wang\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"8020964\",\"name\":\"Ersin Yumer\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1007/978-3-030-01267-0_11\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"098b68fe34dba7fc4e206035ae2d149944bbca8f\",\"title\":\"Learning Blind Video Temporal Consistency\",\"url\":\"https://www.semanticscholar.org/paper/098b68fe34dba7fc4e206035ae2d149944bbca8f\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"70435288\",\"name\":\"Xinxiao Wu\"},{\"authorId\":\"1994473526\",\"name\":\"Jialu Chen\"}],\"doi\":\"10.1145/3394171.3413872\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f01bf32bcc38bf5e4d81f820494a7f8d7dbb2a3c\",\"title\":\"Preserving Global and Local Temporal Consistency for Arbitrary Video Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/f01bf32bcc38bf5e4d81f820494a7f8d7dbb2a3c\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1909.00475\",\"authors\":[{\"authorId\":\"47231927\",\"name\":\"G. Balakrishnan\"},{\"authorId\":\"3046516\",\"name\":\"Adrian V. Dalca\"},{\"authorId\":\"46917346\",\"name\":\"Amy Zhao\"},{\"authorId\":\"1724429\",\"name\":\"J. Guttag\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"}],\"doi\":\"10.1109/ICCV.2019.00026\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"374162524b3fffc1f926c05c5539f01a5d542014\",\"title\":\"Visual Deprojection: Probabilistic Recovery of Collapsed Dimensions\",\"url\":\"https://www.semanticscholar.org/paper/374162524b3fffc1f926c05c5539f01a5d542014\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405687143\",\"name\":\"Hu Xing-hong\"},{\"authorId\":\"9332673\",\"name\":\"L. Xue-ting\"},{\"authorId\":\"9080467\",\"name\":\"Zhang Zhu-ming\"},{\"authorId\":\"148376409\",\"name\":\"Xia Menghan\"},{\"authorId\":\"1389675806\",\"name\":\"Li Chengze\"},{\"authorId\":\"1405687156\",\"name\":\"Wong Tien-Tsin\"}],\"doi\":\"10.1145/3355089.3356534\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d880a761ce2f85c5b0460747a66bea5c839cd71c\",\"title\":\"Colorblind-shareable videos by synthesizing temporal-coherent polynomial coefficients\",\"url\":\"https://www.semanticscholar.org/paper/d880a761ce2f85c5b0460747a66bea5c839cd71c\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1905.01639\",\"authors\":[{\"authorId\":\"24028009\",\"name\":\"Dahun Kim\"},{\"authorId\":\"2262209\",\"name\":\"S. Woo\"},{\"authorId\":\"1926578\",\"name\":\"Joon-Young Lee\"},{\"authorId\":\"98758720\",\"name\":\"I. Kweon\"}],\"doi\":\"10.1109/CVPR.2019.00594\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5f0c8b5be40518b0ce7876ab152c2b9696ef713e\",\"title\":\"Deep Video Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/5f0c8b5be40518b0ce7876ab152c2b9696ef713e\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47824743\",\"name\":\"W. Wang\"},{\"authorId\":\"1474586426\",\"name\":\"Shuai Yang\"},{\"authorId\":\"1697982\",\"name\":\"Jizheng Xu\"},{\"authorId\":\"41127426\",\"name\":\"Jiaying Liu\"}],\"doi\":\"10.1109/TIP.2020.3024018\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"afdbaa80e2dc9b98017dd990615ed5982768caaa\",\"title\":\"Consistent Video Style Transfer via Relaxation and Regularization\",\"url\":\"https://www.semanticscholar.org/paper/afdbaa80e2dc9b98017dd990615ed5982768caaa\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3407321\",\"name\":\"Falong Shen\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"},{\"authorId\":\"39159696\",\"name\":\"Gang Zeng\"}],\"doi\":\"10.1109/CVPR.2018.00841\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bd68e6f668670f7651345670961a5f8eddeddd97\",\"title\":\"Neural Style Transfer via Meta Networks\",\"url\":\"https://www.semanticscholar.org/paper/bd68e6f668670f7651345670961a5f8eddeddd97\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1810.05399\",\"authors\":[{\"authorId\":\"50589814\",\"name\":\"Xiaodong Kuang\"},{\"authorId\":\"2283134\",\"name\":\"Xiubao Sui\"},{\"authorId\":\"49046598\",\"name\":\"Chengwei Liu\"},{\"authorId\":\"49420316\",\"name\":\"Yuan Liu\"},{\"authorId\":\"47261124\",\"name\":\"Qian Chen\"},{\"authorId\":\"144169960\",\"name\":\"Guohua Gu\"}],\"doi\":\"10.1016/j.infrared.2020.103338\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1fd0e10575e76d224451d63002a6ec0d92e47ed4\",\"title\":\"Thermal Infrared Colorization via Conditional Generative Adversarial Network\",\"url\":\"https://www.semanticscholar.org/paper/1fd0e10575e76d224451d63002a6ec0d92e47ed4\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1906.06520\",\"authors\":[{\"authorId\":\"144125030\",\"name\":\"S. Weiss\"},{\"authorId\":\"32464128\",\"name\":\"Mengyu Chu\"},{\"authorId\":\"1786445\",\"name\":\"N. Th\\u00fcrey\"},{\"authorId\":\"145491004\",\"name\":\"R. Westermann\"}],\"doi\":\"10.1109/tvcg.2019.2956697\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2a53ec1db4acd2bc84c6adb308bc72062aa9514a\",\"title\":\"Volumetric Isosurface Rendering with Deep Learning-Based Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/2a53ec1db4acd2bc84c6adb308bc72062aa9514a\",\"venue\":\"IEEE transactions on visualization and computer graphics\",\"year\":2019},{\"arxivId\":\"2004.08058\",\"authors\":[{\"authorId\":\"50762719\",\"name\":\"J. Chen\"},{\"authorId\":\"1758100\",\"name\":\"Yuexiang Li\"},{\"authorId\":\"70665656\",\"name\":\"Kai Ma\"},{\"authorId\":\"35086032\",\"name\":\"Y. Zheng\"}],\"doi\":\"10.1609/AAAI.V34I04.5750\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f4fbc95da08efd662dcb8c393b95b87a6735a33c\",\"title\":\"Generative Adversarial Networks for Video-to-Video Domain Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/f4fbc95da08efd662dcb8c393b95b87a6735a33c\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2769710\",\"name\":\"Xingxing Wei\"},{\"authorId\":\"145254044\",\"name\":\"Jun Zhu\"},{\"authorId\":\"3078190\",\"name\":\"Sitong Feng\"},{\"authorId\":\"144904238\",\"name\":\"H. Su\"}],\"doi\":\"10.1145/3240508.3240708\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"7183b44d2085f940c7521b21a670f61ef2c11625\",\"title\":\"Video-to-Video Translation with Global Temporal Consistency\",\"url\":\"https://www.semanticscholar.org/paper/7183b44d2085f940c7521b21a670f61ef2c11625\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1708.04538\",\"authors\":[{\"authorId\":\"37003547\",\"name\":\"M. Ruder\"},{\"authorId\":\"2841331\",\"name\":\"A. Dosovitskiy\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1007/s11263-018-1089-z\",\"intent\":[\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"8270cfa97e74ee341938685a66a9b75cb65abc17\",\"title\":\"Artistic Style Transfer for Videos and Spherical Images\",\"url\":\"https://www.semanticscholar.org/paper/8270cfa97e74ee341938685a66a9b75cb65abc17\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018},{\"arxivId\":\"1805.03857\",\"authors\":[{\"authorId\":\"37145669\",\"name\":\"Lu Sheng\"},{\"authorId\":\"1967781\",\"name\":\"Ziyi Lin\"},{\"authorId\":\"144478188\",\"name\":\"J. Shao\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1109/CVPR.2018.00860\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e0df8fe29381154c06b6b488cf32b6f6627b394f\",\"title\":\"Avatar-Net: Multi-scale Zero-Shot Style Transfer by Feature Decoration\",\"url\":\"https://www.semanticscholar.org/paper/e0df8fe29381154c06b6b488cf32b6f6627b394f\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1812.03473\",\"authors\":[{\"authorId\":\"51442114\",\"name\":\"Maciej Pesko\"},{\"authorId\":\"112872693\",\"name\":\"Adam Svystun\"},{\"authorId\":\"3269231\",\"name\":\"P. Andruszkiewicz\"},{\"authorId\":\"145561674\",\"name\":\"P. Rokita\"},{\"authorId\":\"144432036\",\"name\":\"T. Trzci\\u0144ski\"}],\"doi\":\"10.3233/fi-2019-1834\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4c81212a1ecca6b160631fea7f2a6cbff6f74012\",\"title\":\"Comixify: Transform video into a comics\",\"url\":\"https://www.semanticscholar.org/paper/4c81212a1ecca6b160631fea7f2a6cbff6f74012\",\"venue\":\"Fundam. Informaticae\",\"year\":2019},{\"arxivId\":\"1801.09710\",\"authors\":[{\"authorId\":\"47779150\",\"name\":\"Y. Xie\"},{\"authorId\":\"35358480\",\"name\":\"Erik Franz\"},{\"authorId\":\"32464128\",\"name\":\"Mengyu Chu\"},{\"authorId\":\"1786445\",\"name\":\"N. Th\\u00fcrey\"}],\"doi\":\"10.1145/3072959.3073643\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"07b924a1677e0c44aeedd18dbba349d5bc9ca10b\",\"title\":\"tempoGAN: A Temporally Coherent, Volumetric GAN for Super-resolution Fluid Flow\",\"url\":\"https://www.semanticscholar.org/paper/07b924a1677e0c44aeedd18dbba349d5bc9ca10b\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11954691\",\"name\":\"Hideki Todo\"},{\"authorId\":\"2509691\",\"name\":\"Tatsuya Yatagawa\"},{\"authorId\":\"1840764\",\"name\":\"Masataka Sawayama\"},{\"authorId\":\"1791538\",\"name\":\"Y. Dobashi\"},{\"authorId\":\"2228383\",\"name\":\"M. Kakimoto\"}],\"doi\":\"10.1007/s00371-019-01676-9\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"7590a209b4d26e4c74bd71ddde43b6571c16610a\",\"title\":\"Image-based translucency transfer through correlation analysis over multi-scale spatial color distribution\",\"url\":\"https://www.semanticscholar.org/paper/7590a209b4d26e4c74bd71ddde43b6571c16610a\",\"venue\":\"The Visual Computer\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145515771\",\"name\":\"Yang Tang\"},{\"authorId\":\"1454206187\",\"name\":\"Chaoqiang Zhao\"},{\"authorId\":\"2882683\",\"name\":\"Jianrui Wang\"},{\"authorId\":\"21247293\",\"name\":\"Chongzhen Zhang\"},{\"authorId\":\"103276442\",\"name\":\"Qiyu Sun\"},{\"authorId\":\"145757334\",\"name\":\"F. Qian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ab14f34d81b637fd54a846c3b4235a988caeeade\",\"title\":\"Perception and Decision-Making of Autonomous Systems in the Era of Learning: An Overview\",\"url\":\"https://www.semanticscholar.org/paper/ab14f34d81b637fd54a846c3b4235a988caeeade\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1906.09909\",\"authors\":[{\"authorId\":\"34997537\",\"name\":\"B. Zhang\"},{\"authorId\":\"4938340\",\"name\":\"Mingming He\"},{\"authorId\":\"104974421\",\"name\":\"J. Liao\"},{\"authorId\":\"145891472\",\"name\":\"Pedro V. Sander\"},{\"authorId\":\"145347147\",\"name\":\"Lu Yuan\"},{\"authorId\":\"1766992\",\"name\":\"A. Bermak\"},{\"authorId\":\"153642240\",\"name\":\"Dong Chen\"}],\"doi\":\"10.1109/CVPR.2019.00824\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"de595af4b6dee1fbe57c311f6ba45e6ac22e57ea\",\"title\":\"Deep Exemplar-Based Video Colorization\",\"url\":\"https://www.semanticscholar.org/paper/de595af4b6dee1fbe57c311f6ba45e6ac22e57ea\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1807.08186\",\"authors\":[{\"authorId\":\"2115998\",\"name\":\"Qingnan Fan\"},{\"authorId\":\"49025576\",\"name\":\"Dongdong Chen\"},{\"authorId\":\"145347148\",\"name\":\"L. Yuan\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\"},{\"authorId\":\"1708598\",\"name\":\"N. Yu\"},{\"authorId\":\"1748939\",\"name\":\"B. Chen\"}],\"doi\":\"10.1007/978-3-030-01261-8_27\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"51ca880503de463b465f9dfd61b9d3edc55709db\",\"title\":\"Decouple Learning for Parameterized Image Operators\",\"url\":\"https://www.semanticscholar.org/paper/51ca880503de463b465f9dfd61b9d3edc55709db\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5458428\",\"name\":\"M. Chen\"},{\"authorId\":\"121900636\",\"name\":\"Changbo Wang\"},{\"authorId\":\"47968194\",\"name\":\"Ligang Liu\"}],\"doi\":\"10.1016/j.cag.2020.05.018\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"861c306dd54b35706e1a9cdc1977617445392e84\",\"title\":\"Cross-domain retrieving sketch and shape using cycle CNNs\",\"url\":\"https://www.semanticscholar.org/paper/861c306dd54b35706e1a9cdc1977617445392e84\",\"venue\":\"Comput. Graph.\",\"year\":2020},{\"arxivId\":\"1811.02928\",\"authors\":[{\"authorId\":\"145505864\",\"name\":\"Dongdong Hou\"},{\"authorId\":\"47528018\",\"name\":\"Weiming Zhang\"},{\"authorId\":\"120809856\",\"name\":\"Jiayang Liu\"},{\"authorId\":\"47707237\",\"name\":\"Siyan Zhou\"},{\"authorId\":\"49025576\",\"name\":\"Dongdong Chen\"},{\"authorId\":\"1708598\",\"name\":\"N. Yu\"}],\"doi\":\"10.1145/3313950.3313952\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"14c7b356d600af8c091d6fb7cd929333e9c7a2b1\",\"title\":\"Emerging applications of reversible data hiding\",\"url\":\"https://www.semanticscholar.org/paper/14c7b356d600af8c091d6fb7cd929333e9c7a2b1\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3193874\",\"name\":\"Ondrej Jamriska\"},{\"authorId\":\"151221841\",\"name\":\"S\\u00e1rka Sochorov\\u00e1\"},{\"authorId\":\"150255187\",\"name\":\"O. Texler\"},{\"authorId\":\"38589587\",\"name\":\"M. Luk\\u00e1c\"},{\"authorId\":\"2798088\",\"name\":\"J. Fiser\"},{\"authorId\":\"2054975\",\"name\":\"Jingwan Lu\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"7997286\",\"name\":\"D. S\\u00fdkora\"}],\"doi\":\"10.1145/3306346.3323006\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b810da03b420d3105b35e166e99f24d9379d8aa6\",\"title\":\"Stylizing video by example\",\"url\":\"https://www.semanticscholar.org/paper/b810da03b420d3105b35e166e99f24d9379d8aa6\",\"venue\":\"ACM Trans. Graph.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2115998\",\"name\":\"Qingnan Fan\"},{\"authorId\":\"2477617\",\"name\":\"J. Yang\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\"},{\"authorId\":\"1748939\",\"name\":\"B. Chen\"},{\"authorId\":\"2242717\",\"name\":\"D. Wipf\"}],\"doi\":\"10.1109/CVPR.2018.00932\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9700d39d92d57c49753ba3b15f12093e01480f8e\",\"title\":\"Revisiting Deep Intrinsic Image Decompositions\",\"url\":\"https://www.semanticscholar.org/paper/9700d39d92d57c49753ba3b15f12093e01480f8e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2011.10974\",\"authors\":[{\"authorId\":\"39431125\",\"name\":\"Shuyang Gu\"},{\"authorId\":\"9324504\",\"name\":\"Jian-min Bao\"},{\"authorId\":\"2013406166\",\"name\":\"Dong Chen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"906c0c47fea0842a6dc5d1301c916eae025a2d90\",\"title\":\"Learnable Sampling 3D Convolution for Video Enhancement and Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/906c0c47fea0842a6dc5d1301c916eae025a2d90\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4938340\",\"name\":\"Mingming He\"},{\"authorId\":null,\"name\":\"Jing Liao\"},{\"authorId\":\"49025576\",\"name\":\"Dongdong Chen\"},{\"authorId\":\"145347148\",\"name\":\"L. Yuan\"},{\"authorId\":\"145891472\",\"name\":\"Pedro V. Sander\"}],\"doi\":\"10.1145/3292482\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"95069a2d3bbfb885580c2ee08b5dd00c8bfa3539\",\"title\":\"Progressive Color Transfer With Dense Semantic Correspondences\",\"url\":\"https://www.semanticscholar.org/paper/95069a2d3bbfb885580c2ee08b5dd00c8bfa3539\",\"venue\":\"ACM Trans. Graph.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"122921311\",\"name\":\"Chia-Hui Feng\"},{\"authorId\":\"113310986\",\"name\":\"Yu-Chun Lin\"},{\"authorId\":\"38787603\",\"name\":\"Y. Hung\"},{\"authorId\":\"1809082873\",\"name\":\"Chao-Kuang Yang\"},{\"authorId\":\"2419282\",\"name\":\"L. Chen\"},{\"authorId\":\"47216447\",\"name\":\"Shih-Wei Yeh\"},{\"authorId\":\"2273342\",\"name\":\"Shih-Hao Lin\"}],\"doi\":\"10.1007/978-3-030-50726-8_83\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7075e4b340f81b5b830c65b91d4926549e0551b9\",\"title\":\"Research on Aesthetic Perception of Artificial Intelligence Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/7075e4b340f81b5b830c65b91d4926549e0551b9\",\"venue\":\"HCI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"102874134\",\"name\":\"Yue-ran Zu\"},{\"authorId\":\"90371241\",\"name\":\"W. Tang\"},{\"authorId\":\"48570808\",\"name\":\"Xiuguo Bao\"},{\"authorId\":null,\"name\":\"Yanyang Wang\"},{\"authorId\":\"14769105\",\"name\":\"S. Wang\"}],\"doi\":\"10.1109/AEECA49918.2020.9213629\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"13f282a4b0cf1211e28ef87d331d178518f6da4d\",\"title\":\"Asymmetric convolution kernel for deep optical flow estimation\",\"url\":\"https://www.semanticscholar.org/paper/13f282a4b0cf1211e28ef87d331d178518f6da4d\",\"venue\":\"2020 IEEE International Conference on Advances in Electrical Engineering and Computer Applications( AEECA)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46874123\",\"name\":\"W. Gao\"},{\"authorId\":\"50024008\",\"name\":\"Y. Li\"},{\"authorId\":\"2926974\",\"name\":\"Yihang Yin\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/WACV45572.2020.9093420\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0da4bd286cac8a8aa8577867ff87cab279ca964f\",\"title\":\"Fast Video Multi-Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/0da4bd286cac8a8aa8577867ff87cab279ca964f\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"2007.05471\",\"authors\":[{\"authorId\":\"49543209\",\"name\":\"Xiaochang Liu\"},{\"authorId\":\"3601471\",\"name\":\"Xuan-yi Li\"},{\"authorId\":\"37535930\",\"name\":\"Ming-Ming Cheng\"},{\"authorId\":\"103234888\",\"name\":\"P. Hall\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"391d560a30884a77cf8d0edc1e17bfc20dc9d706\",\"title\":\"Geometric Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/391d560a30884a77cf8d0edc1e17bfc20dc9d706\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145037972\",\"name\":\"Gilles Puy\"},{\"authorId\":\"144565371\",\"name\":\"P. P\\u00e9rez\"}],\"doi\":\"10.1109/CVPR.2019.00917\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f02ea20eb2597ce4ffd6026713a1f804e9436f4d\",\"title\":\"A Flexible Convolutional Solver for Fast Style Transfers\",\"url\":\"https://www.semanticscholar.org/paper/f02ea20eb2597ce4ffd6026713a1f804e9436f4d\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"103664864\",\"name\":\"Chia-chi Cheng\"},{\"authorId\":\"40846050\",\"name\":\"Hungyu Chen\"},{\"authorId\":\"37811787\",\"name\":\"Wei-Chen Chiu\"}],\"doi\":\"10.1109/cvpr42600.2020.00568\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4daed2840a1fd1cada30cdee782c1d0c1f72f577\",\"title\":\"Time Flies: Animating a Still Image With Time-Lapse Video As Reference\",\"url\":\"https://www.semanticscholar.org/paper/4daed2840a1fd1cada30cdee782c1d0c1f72f577\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32464128\",\"name\":\"Mengyu Chu\"},{\"authorId\":\"9071227\",\"name\":\"You Xie\"},{\"authorId\":\"1388407684\",\"name\":\"L. Leal-Taix\\u00e9\"},{\"authorId\":\"1786445\",\"name\":\"N. Th\\u00fcrey\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"1ad368a4f1e6585b4abe355ed4c7f68601ab162a\",\"title\":\"Temporally Coherent GANs for Video Super-Resolution (TecoGAN)\",\"url\":\"https://www.semanticscholar.org/paper/1ad368a4f1e6585b4abe355ed4c7f68601ab162a\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24028009\",\"name\":\"Dahun Kim\"},{\"authorId\":\"2262209\",\"name\":\"S. Woo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"147874c425fe8dd318d6678a36a8fd4a509afc80\",\"title\":\"Deep Video\",\"url\":\"https://www.semanticscholar.org/paper/147874c425fe8dd318d6678a36a8fd4a509afc80\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24364745\",\"name\":\"Xiyu Yan\"},{\"authorId\":\"51261286\",\"name\":\"Yeli Xing\"},{\"authorId\":\"152237381\",\"name\":\"Zihao He\"},{\"authorId\":\"151470385\",\"name\":\"Tao Dai\"},{\"authorId\":\"101321464\",\"name\":\"Yong Jiang\"},{\"authorId\":\"3085483\",\"name\":\"S. Xia\"}],\"doi\":\"10.1109/ICMEW.2019.00021\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"91339c765d128ae3c14efba723d9928f198ff544\",\"title\":\"Neural Style Transfer with Content Discrimination\",\"url\":\"https://www.semanticscholar.org/paper/91339c765d128ae3c14efba723d9928f198ff544\",\"venue\":\"2019 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145202695\",\"name\":\"M. A. Ponti\"},{\"authorId\":\"1502030036\",\"name\":\"Leo Sampaio Ferraz Ribeiro\"},{\"authorId\":\"39289270\",\"name\":\"Tiago Santana Nazar\\u00e9\"},{\"authorId\":\"144655022\",\"name\":\"Tu Bui\"},{\"authorId\":\"144587010\",\"name\":\"J. Collomosse\"}],\"doi\":\"10.1109/SIBGRAPI-T.2017.12\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bb489e4de6f9b835d70ab46217f11e32887931a2\",\"title\":\"Everything You Wanted to Know about Deep Learning for Computer Vision but Were Afraid to Ask\",\"url\":\"https://www.semanticscholar.org/paper/bb489e4de6f9b835d70ab46217f11e32887931a2\",\"venue\":\"2017 30th SIBGRAPI Conference on Graphics, Patterns and Images Tutorials (SIBGRAPI-T)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38416504\",\"name\":\"S. Aksoy\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bb74c2c5e030d6e1b6e2d553b43fc853f12f12ad\",\"title\":\"STYLE SYNTHESIZING CONDITIONAL GENERATIVE ADVERSARIAL NETWORKS\",\"url\":\"https://www.semanticscholar.org/paper/bb74c2c5e030d6e1b6e2d553b43fc853f12f12ad\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1705.04058\",\"authors\":[{\"authorId\":\"9633703\",\"name\":\"Yongcheng Jing\"},{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"7357719\",\"name\":\"Zunlei Feng\"},{\"authorId\":\"3764313\",\"name\":\"Jingwen Ye\"},{\"authorId\":\"144646841\",\"name\":\"M. Song\"}],\"doi\":\"10.1109/TVCG.2019.2921336\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b0760764dc573b519f76d5a79531d49af333c67a\",\"title\":\"Neural Style Transfer: A Review\",\"url\":\"https://www.semanticscholar.org/paper/b0760764dc573b519f76d5a79531d49af333c67a\",\"venue\":\"IEEE Transactions on Visualization and Computer Graphics\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"146713167\",\"name\":\"F. Hauptfleisch\"},{\"authorId\":\"150255187\",\"name\":\"O. Texler\"},{\"authorId\":\"2028209631\",\"name\":\"A. Texler\"},{\"authorId\":\"40015757\",\"name\":\"J. Krivanek\"},{\"authorId\":\"101677388\",\"name\":\"D. S\\u00fdkora\"}],\"doi\":\"10.1111/cgf.14169\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5090c8c0f29f5328b28b08a8a188d899adc87ec1\",\"title\":\"StyleProp: Real\\u2010time Example\\u2010based Stylization of 3D Models\",\"url\":\"https://www.semanticscholar.org/paper/5090c8c0f29f5328b28b08a8a188d899adc87ec1\",\"venue\":\"Comput. Graph. Forum\",\"year\":2020},{\"arxivId\":\"1803.11182\",\"authors\":[{\"authorId\":\"3093568\",\"name\":\"Jianmin Bao\"},{\"authorId\":\"47514557\",\"name\":\"D. Chen\"},{\"authorId\":\"1716835\",\"name\":\"Fang Wen\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\"}],\"doi\":\"10.1109/CVPR.2018.00702\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c5b324f7f9abdffc1be83f640674beda81b74315\",\"title\":\"Towards Open-Set Identity Preserving Face Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/c5b324f7f9abdffc1be83f640674beda81b74315\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2011.00566\",\"authors\":[{\"authorId\":\"1390965785\",\"name\":\"Hang Zhou\"},{\"authorId\":\"47514207\",\"name\":\"Dongdong Chen\"},{\"authorId\":\"1510772128\",\"name\":\"Jing Liao\"},{\"authorId\":\"8780109\",\"name\":\"Kejiang Chen\"},{\"authorId\":\"5620602\",\"name\":\"Xiaoyi Dong\"},{\"authorId\":\"71552279\",\"name\":\"Kunlin Liu\"},{\"authorId\":\"47528018\",\"name\":\"Weiming Zhang\"},{\"authorId\":\"144988570\",\"name\":\"Gang Hua\"},{\"authorId\":\"49191981\",\"name\":\"N. Yu\"}],\"doi\":\"10.1109/cvpr42600.2020.01037\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"454814bad09c40c0d9c298973f0979f039fcd0f2\",\"title\":\"LG-GAN: Label Guided Adversarial Network for Flexible Targeted Attack of Point Cloud Based Deep Networks\",\"url\":\"https://www.semanticscholar.org/paper/454814bad09c40c0d9c298973f0979f039fcd0f2\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1654097472\",\"name\":\"Pratibha Rathi\"},{\"authorId\":\"1654094793\",\"name\":\"Pranav Adarsh\"},{\"authorId\":\"153792496\",\"name\":\"M. Kumar\"}],\"doi\":\"10.1109/ICOEI48184.2020.9143024\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"25970721632cd7fa44c841f9b0d47efd4fa54017\",\"title\":\"Deep Learning Approach for Arbitrary Image Style Fusion and Transformation using SANET model\",\"url\":\"https://www.semanticscholar.org/paper/25970721632cd7fa44c841f9b0d47efd4fa54017\",\"venue\":\"2020 4th International Conference on Trends in Electronics and Informatics (ICOEI)(48184)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1710978\",\"name\":\"D. Schnieders\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"70b70f07c400ea0d845b95e5e4d0c70881cf8ee1\",\"title\":\"Real-time Coherent Video Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/70b70f07c400ea0d845b95e5e4d0c70881cf8ee1\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2002.11220\",\"authors\":[{\"authorId\":\"144856828\",\"name\":\"D. Hart\"},{\"authorId\":\"1507591373\",\"name\":\"Jessica Greenland\"},{\"authorId\":\"2877830\",\"name\":\"B. Morse\"}],\"doi\":\"10.1109/WACV45572.2020.9093478\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"815e8f65aa086544c53fceba5b8e1cb00e78a439\",\"title\":\"Style Transfer for Light Field Photography\",\"url\":\"https://www.semanticscholar.org/paper/815e8f65aa086544c53fceba5b8e1cb00e78a439\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1811.00222\",\"authors\":[{\"authorId\":\"48865984\",\"name\":\"Kaidi Cao\"},{\"authorId\":null,\"name\":\"Jing Liao\"},{\"authorId\":\"145347148\",\"name\":\"L. Yuan\"}],\"doi\":\"10.1145/3272127.3275046\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3712c0706269c6f177e9c2b24b2d47b7ef186128\",\"title\":\"CariGANs: Unpaired Photo-to-Caricature Translation\",\"url\":\"https://www.semanticscholar.org/paper/3712c0706269c6f177e9c2b24b2d47b7ef186128\",\"venue\":\"ACM Trans. Graph.\",\"year\":2018},{\"arxivId\":\"1905.05916\",\"authors\":[{\"authorId\":\"2465080\",\"name\":\"Y. Shin\"},{\"authorId\":\"31878456\",\"name\":\"Sungsoo Park\"},{\"authorId\":\"40987989\",\"name\":\"Yoon-Jae Yeo\"},{\"authorId\":\"46504984\",\"name\":\"Minjae Yoo\"},{\"authorId\":\"7021627\",\"name\":\"Sung-Jea Ko\"}],\"doi\":\"10.1109/TIP.2019.2953352\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7f60a6794b653823864df9fab4827745e9414522\",\"title\":\"Unsupervised Deep Contrast Enhancement With Power Constraint for OLED Displays\",\"url\":\"https://www.semanticscholar.org/paper/7f60a6794b653823864df9fab4827745e9414522\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1801.04590\",\"authors\":[{\"authorId\":\"2283034\",\"name\":\"Mehdi S. M. Sajjadi\"},{\"authorId\":\"39963722\",\"name\":\"Raviteja Vemulapalli\"},{\"authorId\":\"144735789\",\"name\":\"M. Brown\"}],\"doi\":\"10.1109/CVPR.2018.00693\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"aa3f7330f9b27e57745c4d14753893964ad91d5a\",\"title\":\"Frame-Recurrent Video Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/aa3f7330f9b27e57745c4d14753893964ad91d5a\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1396302758\",\"name\":\"David Futschik\"},{\"authorId\":\"1752091\",\"name\":\"M. Chai\"},{\"authorId\":\"143773131\",\"name\":\"C. Cao\"},{\"authorId\":\"151487472\",\"name\":\"Chongyang Ma\"},{\"authorId\":\"1396302793\",\"name\":\"Aleksei Stoliar\"},{\"authorId\":\"143899943\",\"name\":\"S. Korolev\"},{\"authorId\":\"145582202\",\"name\":\"S. Tulyakov\"},{\"authorId\":\"153346619\",\"name\":\"M. Ku\\u010dera\"},{\"authorId\":\"7997286\",\"name\":\"D. S\\u00fdkora\"}],\"doi\":\"10.2312/EXP.20191074\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f245d89f59e6e962af5352eb40b85cb01a87a9f0\",\"title\":\"Real-Time Patch-Based Stylization of Portraits Using Generative Adversarial Network\",\"url\":\"https://www.semanticscholar.org/paper/f245d89f59e6e962af5352eb40b85cb01a87a9f0\",\"venue\":\"Expressive\",\"year\":2019},{\"arxivId\":\"1811.02476\",\"authors\":[{\"authorId\":\"50135260\",\"name\":\"Wenbo Li\"},{\"authorId\":\"39774417\",\"name\":\"Longyin Wen\"},{\"authorId\":\"144208134\",\"name\":\"Xiao Bian\"},{\"authorId\":\"1794837\",\"name\":\"Siwei Lyu\"}],\"doi\":\"10.1007/978-3-030-20887-5_15\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b570e441357e49f5518743d4e82df25ac5a394f5\",\"title\":\"Evolvement Constrained Adversarial Learning for Video Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/b570e441357e49f5518743d4e82df25ac5a394f5\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1954884\",\"name\":\"A. Gilbert\"},{\"authorId\":\"66174079\",\"name\":\"Matthew Trumble\"},{\"authorId\":\"144046599\",\"name\":\"A. Hilton\"},{\"authorId\":\"1680236\",\"name\":\"J. Collomosse\"}],\"doi\":\"10.1109/TVCG.2018.2889297\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1c3458f11e9e9598cc5cd763858e1c851e8ff7dc\",\"title\":\"Inpainting of Wide-Baseline Multiple Viewpoint Video\",\"url\":\"https://www.semanticscholar.org/paper/1c3458f11e9e9598cc5cd763858e1c851e8ff7dc\",\"venue\":\"IEEE Transactions on Visualization and Computer Graphics\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"81499194\",\"name\":\"He Wanyu\"},{\"authorId\":\"46628785\",\"name\":\"N. Yang\"},{\"authorId\":\"1394601672\",\"name\":\"Wang Chu-yu\"},{\"authorId\":\"2022821237\",\"name\":\"Jackie Yong Leong Shong\"}],\"doi\":\"10.1007/978-981-15-6568-7_12\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"69a41d98c0c441c90f89a25a2c21b1637f6e6aab\",\"title\":\"Day\\u2013Night Scene Transfer for Architectural Renderings Based on Color Transfer Approaches\",\"url\":\"https://www.semanticscholar.org/paper/69a41d98c0c441c90f89a25a2c21b1637f6e6aab\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1812.03264\",\"authors\":[{\"authorId\":\"2485552\",\"name\":\"B. Li\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"47353858\",\"name\":\"Tianfu Wu\"},{\"authorId\":\"1696179\",\"name\":\"Y. Zhou\"},{\"authorId\":\"47059263\",\"name\":\"L. Zhang\"},{\"authorId\":\"1724841\",\"name\":\"R. Chu\"}],\"doi\":\"10.1007/978-3-030-20890-5_14\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e7b446c0f2bc5012951248564f1a6db472fbf801\",\"title\":\"Neural Abstract Style Transfer for Chinese Traditional Painting\",\"url\":\"https://www.semanticscholar.org/paper/e7b446c0f2bc5012951248564f1a6db472fbf801\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"1905.12043\",\"authors\":[{\"authorId\":\"50383147\",\"name\":\"M. Doukas\"},{\"authorId\":\"1790503\",\"name\":\"V. Sharmanska\"},{\"authorId\":\"1776444\",\"name\":\"S. Zafeiriou\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a2f7e7adbbd2326c7ac7cbb67fa43214108bb372\",\"title\":\"Video-to-Video Translation for Visual Speech Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/a2f7e7adbbd2326c7ac7cbb67fa43214108bb372\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9400214\",\"name\":\"Guangxing Han\"},{\"authorId\":\"37735027\",\"name\":\"Xuan Zhang\"},{\"authorId\":\"3244057\",\"name\":\"Chongrong Li\"}],\"doi\":\"10.1145/3240508.3240693\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c5bacb5489537012805e88ad7f4f70c96a438f88\",\"title\":\"Semi-Supervised DFF: Decoupling Detection and Feature Flow for Video Object Detectors\",\"url\":\"https://www.semanticscholar.org/paper/c5bacb5489537012805e88ad7f4f70c96a438f88\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1805.04103\",\"authors\":[{\"authorId\":\"39431125\",\"name\":\"Shuyang Gu\"},{\"authorId\":\"24668624\",\"name\":\"C. Chen\"},{\"authorId\":null,\"name\":\"Jing Liao\"},{\"authorId\":\"145347148\",\"name\":\"L. Yuan\"}],\"doi\":\"10.1109/CVPR.2018.00858\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"42ce7ca66b0471c93fdb5863973abc494df540bb\",\"title\":\"Arbitrary Style Transfer with Deep Feature Reshuffle\",\"url\":\"https://www.semanticscholar.org/paper/42ce7ca66b0471c93fdb5863973abc494df540bb\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49543200\",\"name\":\"Xingyu Liu\"},{\"authorId\":\"2795697\",\"name\":\"Jingfan Guo\"},{\"authorId\":\"1744930\",\"name\":\"T. Ren\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"47033372\",\"name\":\"L. Huang\"},{\"authorId\":\"39914710\",\"name\":\"Gangshan Wu\"}],\"doi\":\"10.1145/3240508.3241402\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a1e2d97d26aaaa35995a36a8cf5ff143f9609940\",\"title\":\"HeterStyle: A Heterogeneous Video Style Transfer Application\",\"url\":\"https://www.semanticscholar.org/paper/a1e2d97d26aaaa35995a36a8cf5ff143f9609940\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2206122\",\"name\":\"Wenyuan Tao\"},{\"authorId\":\"50089974\",\"name\":\"H. Jiang\"},{\"authorId\":\"143844301\",\"name\":\"Q. Sun\"},{\"authorId\":\"50496117\",\"name\":\"Mu Zhang\"},{\"authorId\":\"98205005\",\"name\":\"K. Chen\"},{\"authorId\":\"1381741200\",\"name\":\"Marius Erdt\"}],\"doi\":\"10.1109/CW49994.2020.00013\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bd50d18ccba0a4123c15efdf41ee65f6ef558176\",\"title\":\"ArchGANs: stylized colorization prototyping for architectural line drawing\",\"url\":\"https://www.semanticscholar.org/paper/bd50d18ccba0a4123c15efdf41ee65f6ef558176\",\"venue\":\"2020 International Conference on Cyberworlds (CW)\",\"year\":2020},{\"arxivId\":\"2012.05901\",\"authors\":[{\"authorId\":\"2891193\",\"name\":\"Johannes Kopf\"},{\"authorId\":\"2621738\",\"name\":\"Xuejian Rong\"},{\"authorId\":\"50535349\",\"name\":\"J. Huang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"34ceed8aef36c717b3bfad8f6ccdfb4247013b4e\",\"title\":\"Robust Consistent Video Depth Estimation\",\"url\":\"https://www.semanticscholar.org/paper/34ceed8aef36c717b3bfad8f6ccdfb4247013b4e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3317083\",\"name\":\"Gao Chang\"},{\"authorId\":null,\"name\":\"Gu Derun\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"cd4f5257f1087cfe1f996c0d1bf3dfd104d70642\",\"title\":\"COMP 4801 Final Year Project Interim Report Project title : Real-time Coherent Video Style Transfer Group member :\",\"url\":\"https://www.semanticscholar.org/paper/cd4f5257f1087cfe1f996c0d1bf3dfd104d70642\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1474573850\",\"name\":\"Valentin Vasiliu\"},{\"authorId\":\"2660931\",\"name\":\"G\\u00e1bor S\\u00f6r\\u00f6s\"}],\"doi\":\"10.1109/ISMAR.2019.00-25\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b8c4612d3cd8744d8518cac45fc7dfacf3b72e8b\",\"title\":\"Coherent Rendering of Virtual Smile Previews with Fast Neural Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/b8c4612d3cd8744d8518cac45fc7dfacf3b72e8b\",\"venue\":\"2019 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50152173\",\"name\":\"Shiguang Liu\"},{\"authorId\":\"31735819\",\"name\":\"Y. Li\"},{\"authorId\":\"75097894\",\"name\":\"Guoguang Hua\"}],\"doi\":\"10.1109/TCSVT.2018.2858828\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a8bd0860e86966ea25ae435c7655c635b88305f4\",\"title\":\"Human Pose Estimation in Video via Structured Space Learning and Halfway Temporal Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/a8bd0860e86966ea25ae435c7655c635b88305f4\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3245182\",\"name\":\"Yanpeng Cao\"},{\"authorId\":\"153737613\",\"name\":\"Yongming Tang\"}],\"doi\":\"10.1109/CIRSYSSIM.2019.8935613\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7cc3f3304063f4c0f9e1ac9049a98e36e6bad8d8\",\"title\":\"Development of Real-Time Style Transfer for Video System\",\"url\":\"https://www.semanticscholar.org/paper/7cc3f3304063f4c0f9e1ac9049a98e36e6bad8d8\",\"venue\":\"2019 3rd International Conference on Circuits, System and Simulation (ICCSS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24028009\",\"name\":\"Dahun Kim\"},{\"authorId\":\"2262209\",\"name\":\"S. Woo\"},{\"authorId\":\"1576788264\",\"name\":\"Joon-Young Lee\"},{\"authorId\":\"145017149\",\"name\":\"In So Kweon\"}],\"doi\":\"10.1109/TPAMI.2019.2958083\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ab6d2e28f51012b1968b8b460624178d1cf47a5f\",\"title\":\"Recurrent Temporal Aggregation Framework for Deep Video Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/ab6d2e28f51012b1968b8b460624178d1cf47a5f\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152786529\",\"name\":\"F. Fang\"},{\"authorId\":\"145975100\",\"name\":\"T. Wang\"},{\"authorId\":\"40227204\",\"name\":\"Tieyong Zeng\"},{\"authorId\":\"1730192\",\"name\":\"Guixu Zhang\"}],\"doi\":\"10.1109/TVCG.2019.2908363\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f31c2f6659d0c9b653a71905096c741d8a91cc97\",\"title\":\"A Superpixel-Based Variational Model for Image Colorization\",\"url\":\"https://www.semanticscholar.org/paper/f31c2f6659d0c9b653a71905096c741d8a91cc97\",\"venue\":\"IEEE Transactions on Visualization and Computer Graphics\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1453600148\",\"name\":\"Dingkun Yan\"},{\"authorId\":\"50198403\",\"name\":\"Y. Sheng\"},{\"authorId\":\"46701588\",\"name\":\"Xiaoyang Mao\"}],\"doi\":\"10.1111/cgf.13819\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5f733bf19d66e880d5684884441adda085cf088e\",\"title\":\"Pencil Drawing Video Rendering Using Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/5f733bf19d66e880d5684884441adda085cf088e\",\"venue\":\"Comput. Graph. Forum\",\"year\":2019},{\"arxivId\":\"1709.03919\",\"authors\":[{\"authorId\":\"7480219\",\"name\":\"Boyi Li\"},{\"authorId\":\"3050945\",\"name\":\"X. Peng\"},{\"authorId\":\"2969311\",\"name\":\"Zhangyang Wang\"},{\"authorId\":\"1697982\",\"name\":\"Jizheng Xu\"},{\"authorId\":\"49732222\",\"name\":\"Dan Feng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2054d011a64b2d4bb2e99529c7a717966f096797\",\"title\":\"End-to-End United Video Dehazing and Detection\",\"url\":\"https://www.semanticscholar.org/paper/2054d011a64b2d4bb2e99529c7a717966f096797\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1708.03474\",\"authors\":[{\"authorId\":\"2115998\",\"name\":\"Qingnan Fan\"},{\"authorId\":\"2477617\",\"name\":\"J. Yang\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\"},{\"authorId\":\"1748939\",\"name\":\"B. Chen\"},{\"authorId\":\"2242717\",\"name\":\"D. Wipf\"}],\"doi\":\"10.1109/ICCV.2017.351\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c99718241901530bd60d419ed2539aaf8295692b\",\"title\":\"A Generic Deep Architecture for Single Image Reflection Removal and Image Smoothing\",\"url\":\"https://www.semanticscholar.org/paper/c99718241901530bd60d419ed2539aaf8295692b\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1737466611\",\"name\":\"Songhua Liu\"},{\"authorId\":\"46477223\",\"name\":\"H. Wu\"},{\"authorId\":\"1993702394\",\"name\":\"Shoutong Luo\"},{\"authorId\":\"30370666\",\"name\":\"Z. Sun\"}],\"doi\":\"10.1145/3394171.3413526\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a2a0f99ded70f351306522c387fca0065d0a92f2\",\"title\":\"Stable Video Style Transfer Based on Partial Convolution with Depth-Aware Supervision\",\"url\":\"https://www.semanticscholar.org/paper/a2a0f99ded70f351306522c387fca0065d0a92f2\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2010.10056\",\"authors\":[{\"authorId\":\"3302135\",\"name\":\"Xide Xia\"},{\"authorId\":\"3222730\",\"name\":\"Tianfan Xue\"},{\"authorId\":\"2268189\",\"name\":\"Wei-Sheng Lai\"},{\"authorId\":\"1399908730\",\"name\":\"Zheng Sun\"},{\"authorId\":\"1999258759\",\"name\":\"Abby Chang\"},{\"authorId\":\"1692670\",\"name\":\"B. Kulis\"},{\"authorId\":\"50763062\",\"name\":\"Jiawen Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1dcaad6826c65beea06801ab9973c49d0cb1830b\",\"title\":\"Real-time Localized Photorealistic Video Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/1dcaad6826c65beea06801ab9973c49d0cb1830b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1906.00668\",\"authors\":[{\"authorId\":\"145871213\",\"name\":\"M. Lu\"},{\"authorId\":\"46430948\",\"name\":\"Hao Zhao\"},{\"authorId\":\"2021251\",\"name\":\"A. Yao\"},{\"authorId\":\"6060281\",\"name\":\"Y. Chen\"},{\"authorId\":\"143979431\",\"name\":\"Feng Xu\"},{\"authorId\":\"28354921\",\"name\":\"L. Zhang\"}],\"doi\":\"10.1109/ICCV.2019.00605\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"652113e09c8430aade40b6969f01a18f0e781e00\",\"title\":\"A Closed-Form Solution to Universal Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/652113e09c8430aade40b6969f01a18f0e781e00\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1902.10424\",\"authors\":[{\"authorId\":\"3179679\",\"name\":\"G. Eilertsen\"},{\"authorId\":\"145394421\",\"name\":\"Rafa\\u0142 K. Mantiuk\"},{\"authorId\":\"145446691\",\"name\":\"J. Unger\"}],\"doi\":\"10.1109/CVPR.2019.01143\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"badaab2798fbe4f5621280ea5f0705ea8ad56683\",\"title\":\"Single-Frame Regularization for Temporally Stable CNNs\",\"url\":\"https://www.semanticscholar.org/paper/badaab2798fbe4f5621280ea5f0705ea8ad56683\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1807.08069\",\"authors\":[{\"authorId\":\"145979995\",\"name\":\"D. Zhang\"},{\"authorId\":\"3386593\",\"name\":\"X. Dai\"},{\"authorId\":null,\"name\":\"Xin Wang\"},{\"authorId\":\"1706938\",\"name\":\"Y. Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"207a1766a942be3f22534980f47916f6dc683095\",\"title\":\"S3D: Single Shot multi-Span Detector via Fully 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/207a1766a942be3f22534980f47916f6dc683095\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"14947926\",\"name\":\"Lingchen Yang\"},{\"authorId\":\"120077579\",\"name\":\"Zefeng Shi\"},{\"authorId\":\"3049304\",\"name\":\"Youyi Zheng\"},{\"authorId\":\"48918534\",\"name\":\"K. Zhou\"}],\"doi\":\"10.1145/3355089.3356511\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8d0095f69e1d18f10f3abe628ebdcab18a350c80\",\"title\":\"Dynamic hair modeling from monocular videos using deep neural networks\",\"url\":\"https://www.semanticscholar.org/paper/8d0095f69e1d18f10f3abe628ebdcab18a350c80\",\"venue\":\"ACM Trans. Graph.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144783081\",\"name\":\"You Xie\"},{\"authorId\":\"35358480\",\"name\":\"Erik Franz\"},{\"authorId\":\"32464128\",\"name\":\"Mengyu Chu\"},{\"authorId\":\"1786445\",\"name\":\"N. Th\\u00fcrey\"}],\"doi\":\"10.1145/3197517.3201304\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2e0605ba5cfe30864a514c8a69460dbb59d68df3\",\"title\":\"tempoGAN: A Temporally Coherent, Volumetric GAN for Super-resolution Fluid Flow\",\"url\":\"https://www.semanticscholar.org/paper/2e0605ba5cfe30864a514c8a69460dbb59d68df3\",\"venue\":\"ACM Trans. Graph.\",\"year\":2018},{\"arxivId\":\"2010.16417\",\"authors\":[{\"authorId\":\"31783675\",\"name\":\"Zhentao Tan\"},{\"authorId\":\"1752091\",\"name\":\"M. Chai\"},{\"authorId\":\"49025576\",\"name\":\"Dongdong Chen\"},{\"authorId\":\"1851024702\",\"name\":\"Jing Liao\"},{\"authorId\":\"3127351\",\"name\":\"Q. Chu\"},{\"authorId\":\"145347147\",\"name\":\"Lu Yuan\"},{\"authorId\":\"145582202\",\"name\":\"S. Tulyakov\"},{\"authorId\":\"49191981\",\"name\":\"N. Yu\"}],\"doi\":\"10.1145/3386569.3392488\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5c5de919abaddf1322ef4127cc1ad5f9a6a8f623\",\"title\":\"MichiGAN: multi-input-conditioned hair image generation for portrait editing\",\"url\":\"https://www.semanticscholar.org/paper/5c5de919abaddf1322ef4127cc1ad5f9a6a8f623\",\"venue\":\"ACM Trans. Graph.\",\"year\":2020},{\"arxivId\":\"1908.07683\",\"authors\":[{\"authorId\":\"150176607\",\"name\":\"KwanYong Park\"},{\"authorId\":\"2262209\",\"name\":\"S. Woo\"},{\"authorId\":\"24028009\",\"name\":\"Dahun Kim\"},{\"authorId\":\"3160154\",\"name\":\"Donghyeon Cho\"},{\"authorId\":\"98758720\",\"name\":\"I. Kweon\"}],\"doi\":\"10.1145/3343031.3350864\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e12184b519c14d6964d1ab45ff13fd87f24891c5\",\"title\":\"Preserving Semantic and Temporal Consistency for Unpaired Video-to-Video Translation\",\"url\":\"https://www.semanticscholar.org/paper/e12184b519c14d6964d1ab45ff13fd87f24891c5\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1904.05290\",\"authors\":[{\"authorId\":\"2470340\",\"name\":\"Junhwa Hur\"},{\"authorId\":\"145920814\",\"name\":\"S. Roth\"}],\"doi\":\"10.1109/CVPR.2019.00590\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"281c84088a4294bc0c74b4bb21d1800f2f925a5e\",\"title\":\"Iterative Residual Refinement for Joint Optical Flow and Occlusion Estimation\",\"url\":\"https://www.semanticscholar.org/paper/281c84088a4294bc0c74b4bb21d1800f2f925a5e\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2004.14489\",\"authors\":[{\"authorId\":\"150255187\",\"name\":\"O. Texler\"},{\"authorId\":\"1396302758\",\"name\":\"David Futschik\"},{\"authorId\":\"31256052\",\"name\":\"Michal Kucera\"},{\"authorId\":\"3193874\",\"name\":\"Ondrej Jamriska\"},{\"authorId\":\"151221841\",\"name\":\"S\\u00e1rka Sochorov\\u00e1\"},{\"authorId\":\"1752091\",\"name\":\"M. Chai\"},{\"authorId\":\"145582202\",\"name\":\"S. Tulyakov\"},{\"authorId\":\"7997286\",\"name\":\"D. S\\u00fdkora\"}],\"doi\":\"10.1145/3386569.3392453\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c69220ee364b93a0f574df2ee678ae7fd1621e70\",\"title\":\"Interactive video stylization using few-shot patch-based training\",\"url\":\"https://www.semanticscholar.org/paper/c69220ee364b93a0f574df2ee678ae7fd1621e70\",\"venue\":\"ACM Trans. Graph.\",\"year\":2020},{\"arxivId\":\"1810.03767\",\"authors\":[{\"authorId\":\"50591349\",\"name\":\"S. Yang\"},{\"authorId\":\"41127426\",\"name\":\"Jiaying Liu\"},{\"authorId\":\"1898172\",\"name\":\"W. Yang\"},{\"authorId\":\"35310979\",\"name\":\"Zongming Guo\"}],\"doi\":\"10.1109/TIP.2018.2873064\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cee7ba1de61426af9af7be9da499185dc3f74772\",\"title\":\"Context-Aware Text-Based Binary Image Stylization and Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/cee7ba1de61426af9af7be9da499185dc3f74772\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144372490\",\"name\":\"Santiago E. Montesdeoca\"},{\"authorId\":\"3060199\",\"name\":\"S. H. Soon\"},{\"authorId\":\"1710670\",\"name\":\"P. B\\u00e9nard\"},{\"authorId\":\"1745266\",\"name\":\"R. Vergne\"},{\"authorId\":\"2800344\",\"name\":\"J. Thollot\"},{\"authorId\":\"49777855\",\"name\":\"H. Rall\"},{\"authorId\":\"34865100\",\"name\":\"Davide Benvenuti\"}],\"doi\":\"10.1145/3092919.3092928\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7515ecfc81ece754410be6b1c1e02449511cb7c6\",\"title\":\"Edge- and substrate-based effects for watercolor stylization\",\"url\":\"https://www.semanticscholar.org/paper/7515ecfc81ece754410be6b1c1e02449511cb7c6\",\"venue\":\"NPAR '17\",\"year\":2017},{\"arxivId\":\"2001.02319\",\"authors\":[{\"authorId\":\"145515771\",\"name\":\"Yang Tang\"},{\"authorId\":\"1454206187\",\"name\":\"Chaoqiang Zhao\"},{\"authorId\":\"2882683\",\"name\":\"Jianrui Wang\"},{\"authorId\":\"21247293\",\"name\":\"Chongzhen Zhang\"},{\"authorId\":\"103276442\",\"name\":\"Qiyu Sun\"},{\"authorId\":\"153811925\",\"name\":\"Wei-Xing Zheng\"},{\"authorId\":\"7816352\",\"name\":\"W. Du\"},{\"authorId\":\"145757334\",\"name\":\"F. Qian\"},{\"authorId\":\"152638325\",\"name\":\"J. Kurths\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5bd815eac4ab1481d0c26208182bbea01ddbf8b9\",\"title\":\"An Overview of Perception and Decision-Making in Autonomous Systems in the Era of Learning\",\"url\":\"https://www.semanticscholar.org/paper/5bd815eac4ab1481d0c26208182bbea01ddbf8b9\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2009.08003\",\"authors\":[{\"authorId\":\"49873367\",\"name\":\"Yingying Deng\"},{\"authorId\":\"1443761295\",\"name\":\"Fan Tang\"},{\"authorId\":\"38690089\",\"name\":\"Weiming Dong\"},{\"authorId\":\"3119608\",\"name\":\"Haibin Huang\"},{\"authorId\":\"151487472\",\"name\":\"Chongyang Ma\"},{\"authorId\":\"48258806\",\"name\":\"C. Xu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c6aa5974edccd33117bdd1f6d2a8b6b3d0b44da\",\"title\":\"Arbitrary Video Style Transfer via Multi-Channel Correlation\",\"url\":\"https://www.semanticscholar.org/paper/6c6aa5974edccd33117bdd1f6d2a8b6b3d0b44da\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50536340\",\"name\":\"D. Chen\"},{\"authorId\":\"2115998\",\"name\":\"Qingnan Fan\"},{\"authorId\":\"1851024702\",\"name\":\"Jing Liao\"},{\"authorId\":\"1388720262\",\"name\":\"Angelica I. Avil\\u00e9s-Rivero\"},{\"authorId\":\"145347147\",\"name\":\"Lu Yuan\"},{\"authorId\":\"1708598\",\"name\":\"N. Yu\"},{\"authorId\":\"144988570\",\"name\":\"Gang Hua\"}],\"doi\":\"10.1109/TIP.2020.3009844\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"bc2c5fa98bedb68e1723efa46b97e44c5f101587\",\"title\":\"Controllable Image Processing via Adaptive FilterBank Pyramid\",\"url\":\"https://www.semanticscholar.org/paper/bc2c5fa98bedb68e1723efa46b97e44c5f101587\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10378049\",\"name\":\"Yifang Men\"},{\"authorId\":\"2620336\",\"name\":\"Zhouhui Lian\"},{\"authorId\":\"2858380\",\"name\":\"Y. Tang\"},{\"authorId\":\"2888671\",\"name\":\"J. Xiao\"}],\"doi\":\"10.1109/CVPR.2019.00602\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9412a443ff29a472b4783d8dcd60416e102ec8ef\",\"title\":\"DynTypo: Example-Based Dynamic Text Effects Transfer\",\"url\":\"https://www.semanticscholar.org/paper/9412a443ff29a472b4783d8dcd60416e102ec8ef\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47943365\",\"name\":\"Y. Zhou\"},{\"authorId\":\"12186775\",\"name\":\"Xing Xu\"},{\"authorId\":\"38083193\",\"name\":\"F. Shen\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"143663465\",\"name\":\"Huimin Lu\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1145/3394171.3413788\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"92ff7b00d7782c483ddc239e107acb034cda5536\",\"title\":\"Temporal Denoising Mask Synthesis Network for Learning Blind Video Temporal Consistency\",\"url\":\"https://www.semanticscholar.org/paper/92ff7b00d7782c483ddc239e107acb034cda5536\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1906.01689\",\"authors\":[{\"authorId\":\"134493188\",\"name\":\"Maximilian Werhahn\"},{\"authorId\":\"47779150\",\"name\":\"Y. Xie\"},{\"authorId\":\"32464128\",\"name\":\"Mengyu Chu\"},{\"authorId\":\"1786445\",\"name\":\"N. Th\\u00fcrey\"}],\"doi\":\"10.1145/3340251\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"03129ebc427191e55f710877bd91de99dc85ffc3\",\"title\":\"A Multi-Pass GAN for Fluid Flow Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/03129ebc427191e55f710877bd91de99dc85ffc3\",\"venue\":\"PACMCGIT\",\"year\":2019},{\"arxivId\":\"2004.15021\",\"authors\":[{\"authorId\":\"46612306\",\"name\":\"Xuan Luo\"},{\"authorId\":\"50535349\",\"name\":\"J. Huang\"},{\"authorId\":\"1717841\",\"name\":\"R. Szeliski\"},{\"authorId\":\"40353974\",\"name\":\"K. Matzen\"},{\"authorId\":\"2891193\",\"name\":\"Johannes Kopf\"}],\"doi\":\"10.1145/3386569.3392377\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"43550e50110d6a500ac827e30f54f391aae5f8c7\",\"title\":\"Consistent video depth estimation\",\"url\":\"https://www.semanticscholar.org/paper/43550e50110d6a500ac827e30f54f391aae5f8c7\",\"venue\":\"ACM Trans. Graph.\",\"year\":2020},{\"arxivId\":\"1805.02085\",\"authors\":[{\"authorId\":\"46179701\",\"name\":\"Yicun Liu\"},{\"authorId\":\"46606038\",\"name\":\"Jimmy Ren\"},{\"authorId\":\"120809851\",\"name\":\"Jianbo Liu\"},{\"authorId\":\"41021816\",\"name\":\"J. Zhang\"},{\"authorId\":\"10775732\",\"name\":\"Xiaohao Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e46069c69b5a71f9cda748036b95438803c29a21\",\"title\":\"Learning Selfie-Friendly Abstraction from Artistic Style Images\",\"url\":\"https://www.semanticscholar.org/paper/e46069c69b5a71f9cda748036b95438803c29a21\",\"venue\":\"ACML\",\"year\":2018},{\"arxivId\":\"1808.06601\",\"authors\":[{\"authorId\":\"2195314\",\"name\":\"T. Wang\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"47062069\",\"name\":\"Guilin Liu\"},{\"authorId\":\"29955511\",\"name\":\"A. Tao\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"},{\"authorId\":\"2301680\",\"name\":\"Bryan Catanzaro\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c5b55f410365bb889c25a9f0354f2b86ec61c4f0\",\"title\":\"Video-to-Video Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/c5b55f410365bb889c25a9f0354f2b86ec61c4f0\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1811.08747\",\"authors\":[{\"authorId\":\"49025576\",\"name\":\"Dongdong Chen\"},{\"authorId\":\"4938340\",\"name\":\"Mingming He\"},{\"authorId\":\"2115998\",\"name\":\"Qingnan Fan\"},{\"authorId\":null,\"name\":\"Jing Liao\"},{\"authorId\":\"48571017\",\"name\":\"L. Zhang\"},{\"authorId\":\"145505864\",\"name\":\"Dongdong Hou\"},{\"authorId\":\"145347148\",\"name\":\"L. Yuan\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\"}],\"doi\":\"10.1109/WACV.2019.00151\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"04ad242b95b2d3127680e790b82030ba9b9d2cce\",\"title\":\"Gated Context Aggregation Network for Image Dehazing and Deraining\",\"url\":\"https://www.semanticscholar.org/paper/04ad242b95b2d3127680e790b82030ba9b9d2cce\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":\"2004.10634\",\"authors\":[{\"authorId\":\"1423723631\",\"name\":\"Hao Su\"},{\"authorId\":\"143929163\",\"name\":\"J. Niu\"},{\"authorId\":\"37305311\",\"name\":\"X. Liu\"},{\"authorId\":\"47422334\",\"name\":\"Q. Li\"},{\"authorId\":\"9424770\",\"name\":\"Jiahe Cui\"},{\"authorId\":\"144768030\",\"name\":\"Ji Wan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c8c42e3f550f0b52227d0c482e9a2023fac8522c\",\"title\":\"Unpaired Photo-to-manga Translation Based on The Methodology of Manga Drawing\",\"url\":\"https://www.semanticscholar.org/paper/c8c42e3f550f0b52227d0c482e9a2023fac8522c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1802.07101\",\"authors\":[{\"authorId\":\"9633703\",\"name\":\"Yongcheng Jing\"},{\"authorId\":\"144378549\",\"name\":\"Yang Liu\"},{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"7357719\",\"name\":\"Zunlei Feng\"},{\"authorId\":\"66616425\",\"name\":\"Yizhou Yu\"},{\"authorId\":\"1727111\",\"name\":\"Mingli Song\"}],\"doi\":\"10.1007/978-3-030-01261-8_15\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"357613f3d6c3db33e91654ecef2dff701251a2de\",\"title\":\"Stroke Controllable Fast Style Transfer with Adaptive Receptive Fields\",\"url\":\"https://www.semanticscholar.org/paper/357613f3d6c3db33e91654ecef2dff701251a2de\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2007.05146\",\"authors\":[{\"authorId\":\"1736061\",\"name\":\"Xinghao Chen\"},{\"authorId\":\"46868350\",\"name\":\"Yiman Zhang\"},{\"authorId\":null,\"name\":\"Yunhe Wang\"},{\"authorId\":\"144305248\",\"name\":\"H. Shu\"},{\"authorId\":\"1691522\",\"name\":\"Chunjing Xu\"},{\"authorId\":\"145371957\",\"name\":\"Chang Xu\"}],\"doi\":\"10.1007/978-3-030-58539-6_37\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3b1b2e2fc090ad383dc2923aaa16445f4c847ca9\",\"title\":\"Optical Flow Distillation: Towards Efficient and Stable Video Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/3b1b2e2fc090ad383dc2923aaa16445f4c847ca9\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1812.11139\",\"authors\":[{\"authorId\":\"67100504\",\"name\":\"C. Thomas\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":\"10.1007/978-3-030-20893-6_29\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c748531e6277098d3135a4c552a74def520c9c9a\",\"title\":\"Artistic Object Recognition by Unsupervised Style Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/c748531e6277098d3135a4c552a74def520c9c9a\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47514203\",\"name\":\"Dongdong Chen\"},{\"authorId\":null,\"name\":\"Yuan Lu\"},{\"authorId\":\"50706273\",\"name\":\"Gang Hua\"}],\"doi\":\"10.1007/978-3-030-03243-2_863-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"32ce4b71433dee49769b599e8f3e059f8de2afcf\",\"title\":\"Deep Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/32ce4b71433dee49769b599e8f3e059f8de2afcf\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3323584\",\"name\":\"A. Malhotra\"},{\"authorId\":\"153571209\",\"name\":\"Viswanathan Swaminathan\"},{\"authorId\":\"145394457\",\"name\":\"G. Wu\"},{\"authorId\":\"2741560\",\"name\":\"I. Schizas\"}],\"doi\":\"10.1109/MMSP.2019.8901706\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d010349436a65f91f03d574597d44689cf83ae7\",\"title\":\"Generative Networks for Synthesizing Human Videos in Text-Defined Outfits\",\"url\":\"https://www.semanticscholar.org/paper/6d010349436a65f91f03d574597d44689cf83ae7\",\"venue\":\"2019 IEEE 21st International Workshop on Multimedia Signal Processing (MMSP)\",\"year\":2019},{\"arxivId\":\"1910.06632\",\"authors\":[{\"authorId\":\"36982950\",\"name\":\"Eunah Jung\"},{\"authorId\":\"144610879\",\"name\":\"Nan Yang\"},{\"authorId\":\"1695302\",\"name\":\"D. Cremers\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"ad61fbd32db8f62ebb3c715f0db1e23d85b9d103\",\"title\":\"Multi-Frame GAN: Image Enhancement for Stereo Visual Odometry in Low Light\",\"url\":\"https://www.semanticscholar.org/paper/ad61fbd32db8f62ebb3c715f0db1e23d85b9d103\",\"venue\":\"CoRL\",\"year\":2019},{\"arxivId\":\"2012.01642\",\"authors\":[{\"authorId\":\"84267967\",\"name\":\"C. Thomas\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0e6fd339e247604e00f4ca40de44438a96835471\",\"title\":\"Learning to Transfer Visual Effects from Videos to Images\",\"url\":\"https://www.semanticscholar.org/paper/0e6fd339e247604e00f4ca40de44438a96835471\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3b109686dae36cefec1867ce18c52ab10ec602a7\",\"title\":\"Real-time Coherent Video Style Transfer Final Report\",\"url\":\"https://www.semanticscholar.org/paper/3b109686dae36cefec1867ce18c52ab10ec602a7\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1904.06726\",\"authors\":[{\"authorId\":\"48133807\",\"name\":\"Y. Chang\"},{\"authorId\":\"143822897\",\"name\":\"Zhe Yu Liu\"},{\"authorId\":\"1716836\",\"name\":\"W. Hsu\"}],\"doi\":\"10.1109/CVPRW.2019.00229\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"62c6c2efdc2de134a94e78e9a350db74b80ccd00\",\"title\":\"VORNet: Spatio-Temporally Consistent Video Inpainting for Object Removal\",\"url\":\"https://www.semanticscholar.org/paper/62c6c2efdc2de134a94e78e9a350db74b80ccd00\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143667096\",\"name\":\"Shuai Yang\"},{\"authorId\":\"41127426\",\"name\":\"Jiaying Liu\"},{\"authorId\":\"1898172\",\"name\":\"W. Yang\"},{\"authorId\":\"35310979\",\"name\":\"Zongming Guo\"}],\"doi\":\"10.1145/3240508.3240580\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a72b476e05e126798c8c205f9554ae0ffaf1a097\",\"title\":\"Context-Aware Unsupervised Text Stylization\",\"url\":\"https://www.semanticscholar.org/paper/a72b476e05e126798c8c205f9554ae0ffaf1a097\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48985313\",\"name\":\"M. Zhang\"},{\"authorId\":\"123441315\",\"name\":\"Qiqi Gao\"},{\"authorId\":\"49605749\",\"name\":\"J. Wang\"},{\"authorId\":\"1993683220\",\"name\":\"Henrik Turbell\"},{\"authorId\":\"144652878\",\"name\":\"D. Zhao\"},{\"authorId\":\"34331831\",\"name\":\"J. Yu\"},{\"authorId\":\"104804167\",\"name\":\"Y. Lu\"}],\"doi\":\"10.1145/3394171.3413951\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"091275a8d1f78d69bc2cd4469a3e99e39ab0ec66\",\"title\":\"RT-VENet: A Convolutional Network for Real-time Video Enhancement\",\"url\":\"https://www.semanticscholar.org/paper/091275a8d1f78d69bc2cd4469a3e99e39ab0ec66\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72169165\",\"name\":\"P. Yuan\"},{\"authorId\":\"27102267\",\"name\":\"M. Xie\"},{\"authorId\":\"48154971\",\"name\":\"N. Leach\"},{\"authorId\":\"2538642\",\"name\":\"J. Yao\"},{\"authorId\":\"50142645\",\"name\":\"Xuelong Wang\"}],\"doi\":\"10.1007/978-981-15-6568-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"443d0075e76d8e22561054ce5a1901b880443742\",\"title\":\"Architectural Intelligence: Selected Papers from the 1st International Conference on Computational Design and Robotic Fabrication (CDRF 2019)\",\"url\":\"https://www.semanticscholar.org/paper/443d0075e76d8e22561054ce5a1901b880443742\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2005.10954\",\"authors\":[{\"authorId\":\"46193344\",\"name\":\"Mohammad Rami Koujan\"},{\"authorId\":\"50383147\",\"name\":\"M. Doukas\"},{\"authorId\":\"2931390\",\"name\":\"A. Roussos\"},{\"authorId\":\"1379747201\",\"name\":\"S. Zafeiriou\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e4a787b7177fec50da643a662a57db64ccc91ffc\",\"title\":\"Head2Head: Video-based Neural Head Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/e4a787b7177fec50da643a662a57db64ccc91ffc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.06134\",\"authors\":[{\"authorId\":\"49576412\",\"name\":\"L. Yang\"},{\"authorId\":\"2687716\",\"name\":\"Zhanning Gao\"},{\"authorId\":\"3246404\",\"name\":\"P. Ren\"},{\"authorId\":\"14104497\",\"name\":\"Siwei Ma\"},{\"authorId\":\"48385803\",\"name\":\"W. Gao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"38efe9308a95b354007cf2e7194c3b029e3eec5a\",\"title\":\"Intrinsic Temporal Regularization for High-resolution Human Video Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/38efe9308a95b354007cf2e7194c3b029e3eec5a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.00706\",\"authors\":[{\"authorId\":\"6603147\",\"name\":\"P. Kohli\"},{\"authorId\":\"84260591\",\"name\":\"S. Gunaseelan\"},{\"authorId\":\"144412329\",\"name\":\"J. Orozco\"},{\"authorId\":\"50051908\",\"name\":\"Y. Hua\"},{\"authorId\":\"34494617\",\"name\":\"Edward Li\"},{\"authorId\":\"1515554561\",\"name\":\"Nicolas Dahlquist\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"003af88548f11f4f3f0e29924a41ea2f1ca6574c\",\"title\":\"GPU-Accelerated Mobile Multi-view Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/003af88548f11f4f3f0e29924a41ea2f1ca6574c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.08083\",\"authors\":[{\"authorId\":\"50520638\",\"name\":\"Cheng-Che Lee\"},{\"authorId\":\"49661170\",\"name\":\"Wan-Yi Lin\"},{\"authorId\":\"1946996739\",\"name\":\"Yen-Ting Shih\"},{\"authorId\":\"3262164\",\"name\":\"Pei-Yi Kuo\"},{\"authorId\":\"2448188\",\"name\":\"Li Su\"}],\"doi\":\"10.1145/3394171.3413624\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"839da7325f0608195649299692121c25cca2f346\",\"title\":\"Crossing You in Style: Cross-modal Style Transfer from Music to Visual Arts\",\"url\":\"https://www.semanticscholar.org/paper/839da7325f0608195649299692121c25cca2f346\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41022618\",\"name\":\"Ond\\u0159ej C\\u00edfka\"},{\"authorId\":\"1808437\",\"name\":\"Umut Simsekli\"},{\"authorId\":\"145793390\",\"name\":\"G. Richard\"}],\"doi\":\"10.1109/TASLP.2020.3019642\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c0537c56eadf74252b27aef3b424d2b21d2526fe\",\"title\":\"Groove2Groove: One-Shot Music Style Transfer With Supervision From Synthetic Data\",\"url\":\"https://www.semanticscholar.org/paper/c0537c56eadf74252b27aef3b424d2b21d2526fe\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2020},{\"arxivId\":\"1802.10591\",\"authors\":[{\"authorId\":\"49025576\",\"name\":\"Dongdong Chen\"},{\"authorId\":\"145347148\",\"name\":\"L. Yuan\"},{\"authorId\":null,\"name\":\"Jing Liao\"},{\"authorId\":\"1708598\",\"name\":\"N. Yu\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\"}],\"doi\":\"10.1109/CVPR.2018.00696\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"fa4568b0c02d63eea0ddc7faea9ce069f6d6285a\",\"title\":\"Stereoscopic Neural Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/fa4568b0c02d63eea0ddc7faea9ce069f6d6285a\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"96599627\",\"name\":\"S. Chen\"},{\"authorId\":\"108575462\",\"name\":\"W. Ma\"},{\"authorId\":\"153116278\",\"name\":\"Yue Qin\"}],\"doi\":\"10.1007/978-3-030-34113-8_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"02a8e79085baa7a52cae65ee3bd7ed1045f05ed2\",\"title\":\"CNN-Based Stereoscopic Image Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/02a8e79085baa7a52cae65ee3bd7ed1045f05ed2\",\"venue\":\"ICIG\",\"year\":2019},{\"arxivId\":\"1802.09985\",\"authors\":[{\"authorId\":\"1382034111\",\"name\":\"Xinyu Gong\"},{\"authorId\":\"7192666\",\"name\":\"H. Huang\"},{\"authorId\":\"152309767\",\"name\":\"L. Ma\"},{\"authorId\":\"38083193\",\"name\":\"F. Shen\"},{\"authorId\":\"1743698\",\"name\":\"Wenyu Liu\"},{\"authorId\":\"36066491\",\"name\":\"Tong Zhang\"}],\"doi\":\"10.1007/978-3-030-01228-1_4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"13a3df27e8a1bfef2d858cdeede3674784f15f2d\",\"title\":\"Neural Stereoscopic Image Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/13a3df27e8a1bfef2d858cdeede3674784f15f2d\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2005.11630\",\"authors\":[{\"authorId\":\"100895685\",\"name\":\"Ang Li\"},{\"authorId\":\"3207491\",\"name\":\"Chunpeng Wu\"},{\"authorId\":\"50579965\",\"name\":\"Yiran Chen\"},{\"authorId\":\"144877709\",\"name\":\"Bin Ni\"}],\"doi\":\"10.1145/3397166.3409140\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c493a367d34f862a11d65a5e6d859535b3cfbb02\",\"title\":\"MVStylizer: an efficient edge-assisted video photorealistic style transfer system for mobile phones\",\"url\":\"https://www.semanticscholar.org/paper/c493a367d34f862a11d65a5e6d859535b3cfbb02\",\"venue\":\"MobiHoc\",\"year\":2020},{\"arxivId\":\"1811.02804\",\"authors\":[{\"authorId\":\"2115998\",\"name\":\"Qingnan Fan\"},{\"authorId\":\"2477617\",\"name\":\"J. Yang\"},{\"authorId\":\"2242717\",\"name\":\"D. Wipf\"},{\"authorId\":\"1748939\",\"name\":\"B. Chen\"},{\"authorId\":\"49144235\",\"name\":\"X. Tong\"}],\"doi\":\"10.1145/3272127.3275081\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a6c8742e53c9c72b5e2f3d3df0db3502755c9982\",\"title\":\"Image smoothing via unsupervised learning\",\"url\":\"https://www.semanticscholar.org/paper/a6c8742e53c9c72b5e2f3d3df0db3502755c9982\",\"venue\":\"ACM Trans. Graph.\",\"year\":2018}],\"corpusId\":1497291,\"doi\":\"10.1109/ICCV.2017.126\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":13,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"2d5b4144124f47a6357e6390dc6c0f8806ac54f5\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"40397554\",\"name\":\"Chung-Ming Wang\"},{\"authorId\":\"2150187\",\"name\":\"Yao-Hsien Huang\"},{\"authorId\":\"3299823\",\"name\":\"Ming-Long Huang\"}],\"doi\":\"10.1016/j.mcm.2006.01.029\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10fb269f1121e958631e402a99d006d9e20b35ca\",\"title\":\"An effective algorithm for image sequence color transfer\",\"url\":\"https://www.semanticscholar.org/paper/10fb269f1121e958631e402a99d006d9e20b35ca\",\"venue\":\"Math. Comput. Model.\",\"year\":2006},{\"arxivId\":\"1501.02565\",\"authors\":[{\"authorId\":\"3428663\",\"name\":\"J\\u00e9r\\u00f4me Revaud\"},{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"1753355\",\"name\":\"Z. Harchaoui\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/CVPR.2015.7298720\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f08e462b77347dc3cf483ca24dcd484c0ba5b432\",\"title\":\"EpicFlow: Edge-preserving interpolation of correspondences for optical flow\",\"url\":\"https://www.semanticscholar.org/paper/f08e462b77347dc3cf483ca24dcd484c0ba5b432\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1927808\",\"name\":\"J. E. Kyprianidis\"},{\"authorId\":\"1680236\",\"name\":\"J. Collomosse\"},{\"authorId\":\"46958572\",\"name\":\"T. Wang\"},{\"authorId\":\"145322699\",\"name\":\"Tobias Isenberg\"}],\"doi\":\"10.1109/TVCG.2012.160\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d24343feff22ab6839de2f7c659734489b9bb11b\",\"title\":\"State of the \\\"Art&#x201D;: A Taxonomy of Artistic Stylization Techniques for Images and Video\",\"url\":\"https://www.semanticscholar.org/paper/d24343feff22ab6839de2f7c659734489b9bb11b\",\"venue\":\"IEEE Transactions on Visualization and Computer Graphics\",\"year\":2013},{\"arxivId\":\"1504.06852\",\"authors\":[{\"authorId\":\"1382344214\",\"name\":\"A. Dosovitskiy\"},{\"authorId\":\"152702479\",\"name\":\"P. Fischer\"},{\"authorId\":\"48105320\",\"name\":\"Eddy Ilg\"},{\"authorId\":\"2880264\",\"name\":\"Philip H\\u00e4usser\"},{\"authorId\":\"3322806\",\"name\":\"Caner Hazirbas\"},{\"authorId\":\"2943639\",\"name\":\"V. Golkov\"},{\"authorId\":\"1715782\",\"name\":\"P. V. D. Smagt\"},{\"authorId\":\"153685345\",\"name\":\"D. Cremers\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1109/ICCV.2015.316\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c2fb5b39428818d7ec8cc78e152e19c21b7db568\",\"title\":\"FlowNet: Learning Optical Flow with Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/c2fb5b39428818d7ec8cc78e152e19c21b7db568\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1611.07865\",\"authors\":[{\"authorId\":\"1891828\",\"name\":\"Leon A. Gatys\"},{\"authorId\":\"1746183\",\"name\":\"Alexander S. Ecker\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"},{\"authorId\":\"1747779\",\"name\":\"Aaron Hertzmann\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"}],\"doi\":\"10.1109/CVPR.2017.397\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"acc529f6f65fbdbae1aff14682168b5132143f28\",\"title\":\"Controlling Perceptual Factors in Neural Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/acc529f6f65fbdbae1aff14682168b5132143f28\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1747779\",\"name\":\"Aaron Hertzmann\"}],\"doi\":\"10.1145/280814.280951\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f835978a33a86219a5e93852b2fe03c8aabba13e\",\"title\":\"Painterly rendering with curved brush strokes of multiple sizes\",\"url\":\"https://www.semanticscholar.org/paper/f835978a33a86219a5e93852b2fe03c8aabba13e\",\"venue\":\"SIGGRAPH '98\",\"year\":1998},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2884373\",\"name\":\"J. Elman\"}],\"doi\":\"10.1207/s15516709cog1402_1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"668087f0ae7ce1de6e0bd0965dbb480c08103260\",\"title\":\"Finding Structure in Time\",\"url\":\"https://www.semanticscholar.org/paper/668087f0ae7ce1de6e0bd0965dbb480c08103260\",\"venue\":\"Cogn. Sci.\",\"year\":1990},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1710872\",\"name\":\"T. Brox\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/TPAMI.2010.143\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ffd97ed7408fa75b86d4c8e4280f8d730ffa2cf0\",\"title\":\"Large Displacement Optical Flow: Descriptor Matching in Variational Motion Estimation\",\"url\":\"https://www.semanticscholar.org/paper/ffd97ed7408fa75b86d4c8e4280f8d730ffa2cf0\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2011},{\"arxivId\":\"1508.06576\",\"authors\":[{\"authorId\":\"1891828\",\"name\":\"Leon A. Gatys\"},{\"authorId\":\"1746183\",\"name\":\"Alexander S. Ecker\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":\"10.1167/16.12.326\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f37e90c0bd5c4a9619ccfb763c45cb2d84abd3e6\",\"title\":\"A Neural Algorithm of Artistic Style\",\"url\":\"https://www.semanticscholar.org/paper/f37e90c0bd5c4a9619ccfb763c45cb2d84abd3e6\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. A. Efros\"},{\"authorId\":null,\"name\":\"T. K. Leung\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Texture synthesis by nonparametric sampling\",\"url\":\"\",\"venue\":\"In Proc. ICCV,\",\"year\":1999},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"2343941\",\"name\":\"Hannes Fassold\"},{\"authorId\":\"1803123\",\"name\":\"P. Schallauer\"}],\"doi\":\"10.1109/LSP.2013.2248711\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f228db9422eb7ec744a3ae55f020dcfbbf6e0158\",\"title\":\"A Perceptual Image Sharpness Metric Based on Local Edge Gradient Analysis\",\"url\":\"https://www.semanticscholar.org/paper/f228db9422eb7ec744a3ae55f020dcfbbf6e0158\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2013},{\"arxivId\":\"1612.01925\",\"authors\":[{\"authorId\":\"48105320\",\"name\":\"Eddy Ilg\"},{\"authorId\":\"153200643\",\"name\":\"N. Mayer\"},{\"authorId\":\"2872102\",\"name\":\"Tonmoy Saikia\"},{\"authorId\":\"3316866\",\"name\":\"Margret Keuper\"},{\"authorId\":\"2841331\",\"name\":\"A. Dosovitskiy\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1109/CVPR.2017.179\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"edd846e76cacfba5be37da99c006e3ccc9b861b0\",\"title\":\"FlowNet 2.0: Evolution of Optical Flow Estimation with Deep Networks\",\"url\":\"https://www.semanticscholar.org/paper/edd846e76cacfba5be37da99c006e3ccc9b861b0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1703.09210\",\"authors\":[{\"authorId\":\"49025576\",\"name\":\"Dongdong Chen\"},{\"authorId\":\"145347148\",\"name\":\"L. Yuan\"},{\"authorId\":null,\"name\":\"Jing Liao\"},{\"authorId\":\"1708598\",\"name\":\"N. Yu\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\"}],\"doi\":\"10.1109/CVPR.2017.296\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e803dbe3c2a3b7f7a5017c48c7531ed3532ee4f5\",\"title\":\"StyleBank: An Explicit Representation for Neural Image Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/e803dbe3c2a3b7f7a5017c48c7531ed3532ee4f5\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1722900\",\"name\":\"Nicolas Bonneel\"},{\"authorId\":\"1854493\",\"name\":\"J. Tompkin\"},{\"authorId\":\"2454127\",\"name\":\"Kalyan Sunkavalli\"},{\"authorId\":\"3232265\",\"name\":\"Deqing Sun\"},{\"authorId\":\"145799132\",\"name\":\"Sylvain Paris\"},{\"authorId\":\"143758231\",\"name\":\"H. Pfister\"}],\"doi\":\"10.1145/2816795.2818107\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5cf676a6227d3b1388802991ef4f44ffaf98bec1\",\"title\":\"Blind video temporal consistency\",\"url\":\"https://www.semanticscholar.org/paper/5cf676a6227d3b1388802991ef4f44ffaf98bec1\",\"venue\":\"ACM Trans. Graph.\",\"year\":2015},{\"arxivId\":\"1603.01768\",\"authors\":[{\"authorId\":\"2681610\",\"name\":\"A. Champandard\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"3e837ba2bfcb028e2331cd3b0e5fefddc5b1c2a4\",\"title\":\"Semantic Style Transfer and Turning Two-Bit Doodles into Fine Artworks\",\"url\":\"https://www.semanticscholar.org/paper/3e837ba2bfcb028e2331cd3b0e5fefddc5b1c2a4\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2054975\",\"name\":\"Jingwan Lu\"},{\"authorId\":\"145891472\",\"name\":\"Pedro V. Sander\"},{\"authorId\":\"37737599\",\"name\":\"Adam Finkelstein\"}],\"doi\":\"10.1145/1730804.1730825\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"2da593f91bd50a4d7a49a3997a0704f4785124de\",\"title\":\"Interactive painterly stylization of images, videos and 3D animations\",\"url\":\"https://www.semanticscholar.org/paper/2da593f91bd50a4d7a49a3997a0704f4785124de\",\"venue\":\"I3D '10\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1747779\",\"name\":\"Aaron Hertzmann\"},{\"authorId\":\"10251113\",\"name\":\"C. Jacobs\"},{\"authorId\":\"145709776\",\"name\":\"N. Oliver\"},{\"authorId\":\"143800609\",\"name\":\"Brian Curless\"},{\"authorId\":\"1745260\",\"name\":\"D. Salesin\"}],\"doi\":\"10.1145/383259.383295\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"923562d216386a88947d40da310d94bbb1376a41\",\"title\":\"Image analogies\",\"url\":\"https://www.semanticscholar.org/paper/923562d216386a88947d40da310d94bbb1376a41\",\"venue\":\"SIGGRAPH '01\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2615673\",\"name\":\"Peter Litwinowicz\"}],\"doi\":\"10.1145/258734.258893\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"40064ed4de01e9c66a5d827463850816d1f681cc\",\"title\":\"Processing images and video for an impressionist effect\",\"url\":\"https://www.semanticscholar.org/paper/40064ed4de01e9c66a5d827463850816d1f681cc\",\"venue\":\"SIGGRAPH '97\",\"year\":1997},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48477439\",\"name\":\"Xuan Dong\"},{\"authorId\":\"2226288\",\"name\":\"B. Bonev\"},{\"authorId\":\"145350978\",\"name\":\"Y. Zhu\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.1109/CVPR.2015.7298671\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"036bfdf3613177919ea93f4acf7a340a4953f217\",\"title\":\"Region-based temporally consistent video post-processing\",\"url\":\"https://www.semanticscholar.org/paper/036bfdf3613177919ea93f4acf7a340a4953f217\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1604.04382\",\"authors\":[{\"authorId\":\"153228286\",\"name\":\"Chuan Li\"},{\"authorId\":\"1723149\",\"name\":\"M. Wand\"}],\"doi\":\"10.1007/978-3-319-46487-9_43\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"102a2096ba2e2947dc252445f764e7583b557680\",\"title\":\"Precomputed Real-Time Texture Synthesis with Markovian Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/102a2096ba2e2947dc252445f764e7583b557680\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1710872\",\"name\":\"T. Brox\"},{\"authorId\":\"144031005\",\"name\":\"A. Bruhn\"},{\"authorId\":\"2188270\",\"name\":\"N. Papenberg\"},{\"authorId\":\"7789445\",\"name\":\"J. Weickert\"}],\"doi\":\"10.1007/978-3-540-24673-2_3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"91228e00fe33ed6072cfe849ab9e98160461549d\",\"title\":\"High Accuracy Optical Flow Estimation Based on a Theory for Warping\",\"url\":\"https://www.semanticscholar.org/paper/91228e00fe33ed6072cfe849ab9e98160461549d\",\"venue\":\"ECCV\",\"year\":2004},{\"arxivId\":\"1603.08155\",\"authors\":[{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"3304525\",\"name\":\"Alexandre Alahi\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/978-3-319-46475-6_43\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9fa3720371e78d04973ce9752781bc337480b68f\",\"title\":\"Perceptual Losses for Real-Time Style Transfer and Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/9fa3720371e78d04973ce9752781bc337480b68f\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1849598\",\"name\":\"D. Butler\"},{\"authorId\":\"49820715\",\"name\":\"J. Wulff\"},{\"authorId\":\"2715753\",\"name\":\"G. Stanley\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"}],\"doi\":\"10.1007/978-3-642-33783-3_44\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"7d53f0c87c8ab0de6f3e74515e3ffaf3fab40c62\",\"title\":\"A Naturalistic Open Source Movie for Optical Flow Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/7d53f0c87c8ab0de6f3e74515e3ffaf3fab40c62\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":\"1604.08610\",\"authors\":[{\"authorId\":\"37003547\",\"name\":\"M. Ruder\"},{\"authorId\":\"2841331\",\"name\":\"A. Dosovitskiy\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1007/978-3-319-45886-1_3\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5181a9c3c9a36672a3890321dcc0faf4f8ea658e\",\"title\":\"Artistic Style Transfer for Videos\",\"url\":\"https://www.semanticscholar.org/paper/5181a9c3c9a36672a3890321dcc0faf4f8ea658e\",\"venue\":\"GCPR\",\"year\":2016},{\"arxivId\":\"1603.03417\",\"authors\":[{\"authorId\":\"145276680\",\"name\":\"D. Ulyanov\"},{\"authorId\":\"47606739\",\"name\":\"V. Lebedev\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"1740145\",\"name\":\"V. Lempitsky\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"ed16b5a85e06fc0e6c81b3843a5bb2bb50a35ac1\",\"title\":\"Texture Networks: Feed-forward Synthesis of Textures and Stylized Images\",\"url\":\"https://www.semanticscholar.org/paper/ed16b5a85e06fc0e6c81b3843a5bb2bb50a35ac1\",\"venue\":\"ICML\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"3428663\",\"name\":\"J\\u00e9r\\u00f4me Revaud\"},{\"authorId\":\"113130084\",\"name\":\"Zaid Harchaoui\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2013.175\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"56493a503eecb659bbef2fe4dd1fb915d251cac0\",\"title\":\"DeepFlow: Large Displacement Optical Flow with Deep Matching\",\"url\":\"https://www.semanticscholar.org/paper/56493a503eecb659bbef2fe4dd1fb915d251cac0\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":\"1703.01664\",\"authors\":[{\"authorId\":\"1754382\",\"name\":\"Yijun Li\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"1768964\",\"name\":\"Jimei Yang\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"145574672\",\"name\":\"Xin Lu\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/CVPR.2017.36\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c3453ef6e19bf44ec35becd6d37c6910efd7a6d7\",\"title\":\"Diversified Texture Synthesis with Feed-Forward Networks\",\"url\":\"https://www.semanticscholar.org/paper/c3453ef6e19bf44ec35becd6d37c6910efd7a6d7\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1610.07629\",\"authors\":[{\"authorId\":\"3074927\",\"name\":\"Vincent Dumoulin\"},{\"authorId\":\"1789737\",\"name\":\"Jonathon Shlens\"},{\"authorId\":\"1942300\",\"name\":\"M. Kudlur\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"99542f614d7e4146cad17196e76c997e57a69e4d\",\"title\":\"A Learned Representation For Artistic Style\",\"url\":\"https://www.semanticscholar.org/paper/99542f614d7e4146cad17196e76c997e57a69e4d\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143814637\",\"name\":\"B. Horn\"},{\"authorId\":\"1717435\",\"name\":\"B. Schunck\"}],\"doi\":\"10.1016/0004-3702(81)90024-2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cbe9176abf0c98c7abdfd136f53d58620f8acfec\",\"title\":\"Determining Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/cbe9176abf0c98c7abdfd136f53d58620f8acfec\",\"venue\":\"Artif. Intell.\",\"year\":1981},{\"arxivId\":\"1601.04589\",\"authors\":[{\"authorId\":\"153228286\",\"name\":\"Chuan Li\"},{\"authorId\":\"1723149\",\"name\":\"M. Wand\"}],\"doi\":\"10.1109/CVPR.2016.272\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"80d9a586c49ac6ec6a0b304ec1bb10d3f09fb526\",\"title\":\"Combining Markov Random Fields and Convolutional Neural Networks for Image Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/80d9a586c49ac6ec6a0b304ec1bb10d3f09fb526\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"}],\"doi\":\"10.1145/383259.383296\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dd7bf950093fc65f3ae6ad79666ce1077f9dfb2e\",\"title\":\"Image quilting for texture synthesis and transfer\",\"url\":\"https://www.semanticscholar.org/paper/dd7bf950093fc65f3ae6ad79666ce1077f9dfb2e\",\"venue\":\"SIGGRAPH '01\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7789445\",\"name\":\"J. Weickert\"},{\"authorId\":\"144031005\",\"name\":\"A. Bruhn\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"},{\"authorId\":\"2188270\",\"name\":\"N. Papenberg\"}],\"doi\":\"10.1007/978-3-540-34767-5_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0a0511b331a3a565e80bab22eb93978c4349d89e\",\"title\":\"A survey on variational optic flow methods for small displacements\",\"url\":\"https://www.semanticscholar.org/paper/0a0511b331a3a565e80bab22eb93978c4349d89e\",\"venue\":\"\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1789372\",\"name\":\"N. Sundaram\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"},{\"authorId\":\"1732330\",\"name\":\"K. Keutzer\"}],\"doi\":\"10.1007/978-3-642-15549-9_32\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d3ef059816bcf2d2b519ac36935c61a5a5e81e9b\",\"title\":\"Dense Point Trajectories by GPU-Accelerated Large Displacement Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/d3ef059816bcf2d2b519ac36935c61a5a5e81e9b\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"21472040\",\"name\":\"Irfan Essa\"}],\"doi\":\"10.1145/987657.987676\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"98710be7919d015878f7b29d99c588d1358d48a4\",\"title\":\"Image and video based painterly animation\",\"url\":\"https://www.semanticscholar.org/paper/98710be7919d015878f7b29d99c588d1358d48a4\",\"venue\":\"NPAR '04\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145799132\",\"name\":\"Sylvain Paris\"},{\"authorId\":\"1979640\",\"name\":\"S. W. Hasinoff\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":\"10.1145/1964921.1964963\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"280901728fe5b0f92addf6cbfef111b40800fbd0\",\"title\":\"Local Laplacian filters: edge-aware image processing with a Laplacian pyramid\",\"url\":\"https://www.semanticscholar.org/paper/280901728fe5b0f92addf6cbfef111b40800fbd0\",\"venue\":\"ACM Trans. Graph.\",\"year\":2011},{\"arxivId\":\"1605.08153\",\"authors\":[{\"authorId\":\"145025287\",\"name\":\"Alexander G. Anderson\"},{\"authorId\":\"25661702\",\"name\":\"C. P. Berg\"},{\"authorId\":\"3407880\",\"name\":\"Daniel P. Mossing\"},{\"authorId\":\"1708655\",\"name\":\"B. Olshausen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d9cbdff63dd970c846fa19cf4169685815629f6d\",\"title\":\"DeepMovie: Using Optical Flow and Deep Neural Networks to Stylize Movies\",\"url\":\"https://www.semanticscholar.org/paper/d9cbdff63dd970c846fa19cf4169685815629f6d\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1611.00850\",\"authors\":[{\"authorId\":\"1952002\",\"name\":\"A. Ranjan\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"}],\"doi\":\"10.1109/CVPR.2017.291\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a93d81c7f033f1e2b54d3288b60d214f55ccc010\",\"title\":\"Optical Flow Estimation Using a Spatial Pyramid Network\",\"url\":\"https://www.semanticscholar.org/paper/a93d81c7f033f1e2b54d3288b60d214f55ccc010\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7671691\",\"name\":\"Song-Hai Zhang\"},{\"authorId\":\"7824015\",\"name\":\"Xian-Ying Li\"},{\"authorId\":\"145140922\",\"name\":\"S. Hu\"},{\"authorId\":\"2404014\",\"name\":\"R. Martin\"}],\"doi\":\"10.1109/TMM.2011.2165052\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"059a45d34f7183af033dab8443f4fe21af914656\",\"title\":\"Online Video Stream Abstraction and Stylization\",\"url\":\"https://www.semanticscholar.org/paper/059a45d34f7183af033dab8443f4fe21af914656\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1722900\",\"name\":\"Nicolas Bonneel\"},{\"authorId\":\"2454127\",\"name\":\"Kalyan Sunkavalli\"},{\"authorId\":\"145799132\",\"name\":\"Sylvain Paris\"},{\"authorId\":\"143758231\",\"name\":\"H. Pfister\"}],\"doi\":\"10.1145/2461912.2461939\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"88dd14d67acfd542a707f3515bab25268585c8b0\",\"title\":\"Example-based video color grading\",\"url\":\"https://www.semanticscholar.org/paper/88dd14d67acfd542a707f3515bab25268585c8b0\",\"venue\":\"ACM Trans. Graph.\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3104633\",\"name\":\"A. Seleim\"},{\"authorId\":\"1854465\",\"name\":\"M. Elgharib\"},{\"authorId\":\"144032792\",\"name\":\"L. Doyle\"}],\"doi\":\"10.1145/2897824.2925968\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"6e06b480be8dead8c463c860ef961ba5306c2f79\",\"title\":\"Painting style transfer for head portraits using convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/6e06b480be8dead8c463c860ef961ba5306c2f79\",\"venue\":\"ACM Trans. Graph.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"2812486\",\"name\":\"P. Simard\"},{\"authorId\":\"1688235\",\"name\":\"P. Frasconi\"}],\"doi\":\"10.1109/72.279181\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d0be39ee052d246ae99c082a565aba25b811be2d\",\"title\":\"Learning long-term dependencies with gradient descent is difficult\",\"url\":\"https://www.semanticscholar.org/paper/d0be39ee052d246ae99c082a565aba25b811be2d\",\"venue\":\"IEEE Trans. Neural Networks\",\"year\":1994},{\"arxivId\":\"1611.07715\",\"authors\":[{\"authorId\":\"2578924\",\"name\":\"X. Zhu\"},{\"authorId\":\"3372084\",\"name\":\"Y. Xiong\"},{\"authorId\":\"3304536\",\"name\":\"Jifeng Dai\"},{\"authorId\":\"145347148\",\"name\":\"L. Yuan\"},{\"authorId\":\"1732264\",\"name\":\"Y. Wei\"}],\"doi\":\"10.1109/CVPR.2017.441\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5c544788faa5b6031db5020bbdaeb25e68c24e19\",\"title\":\"Deep Feature Flow for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5c544788faa5b6031db5020bbdaeb25e68c24e19\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2149814\",\"name\":\"A. Bousseau\"},{\"authorId\":\"1708868\",\"name\":\"Fabrice Neyret\"},{\"authorId\":\"2800344\",\"name\":\"J. Thollot\"},{\"authorId\":\"1745260\",\"name\":\"D. Salesin\"}],\"doi\":\"10.1145/1276377.1276507\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"3debd0d6d3e8096b063092da9aceb2078c541542\",\"title\":\"Video watercolorization using bidirectional texture advection\",\"url\":\"https://www.semanticscholar.org/paper/3debd0d6d3e8096b063092da9aceb2078c541542\",\"venue\":\"SIGGRAPH 2007\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J. E. Kyprianidis\"},{\"authorId\":null,\"name\":\"J. Collomosse\"},{\"authorId\":null,\"name\":\"T. Wang\"},{\"authorId\":null,\"name\":\"T. Isenberg\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"State of the\\u201d art: A taxonomy of artistic stylization techniques for images and video\",\"url\":\"\",\"venue\":\"IEEE Trans. on Visualization and Computer Graphics,\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48033193\",\"name\":\"Manuel Lang\"},{\"authorId\":\"47520207\",\"name\":\"O. Wang\"},{\"authorId\":\"2769987\",\"name\":\"T. Aydin\"},{\"authorId\":\"50663593\",\"name\":\"A. Smolic\"},{\"authorId\":\"144877481\",\"name\":\"M. Gross\"}],\"doi\":\"10.1145/2185520.2185530\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"923a2a63ee027c5ab6dbc0af6848022dc867be03\",\"title\":\"Practical temporal consistency for image-based graphics applications\",\"url\":\"https://www.semanticscholar.org/paper/923a2a63ee027c5ab6dbc0af6848022dc867be03\",\"venue\":\"TOGS\",\"year\":2012}],\"title\":\"Coherent Online Video Style Transfer\",\"topics\":[{\"topic\":\"Coherent\",\"topicId\":\"30938\",\"url\":\"https://www.semanticscholar.org/topic/30938\"},{\"topic\":\"Video clip\",\"topicId\":\"30493\",\"url\":\"https://www.semanticscholar.org/topic/30493\"},{\"topic\":\"Graphics processing unit\",\"topicId\":\"8807\",\"url\":\"https://www.semanticscholar.org/topic/8807\"},{\"topic\":\"Optical flow\",\"topicId\":\"26430\",\"url\":\"https://www.semanticscholar.org/topic/26430\"},{\"topic\":\"Mathematical optimization\",\"topicId\":\"89\",\"url\":\"https://www.semanticscholar.org/topic/89\"},{\"topic\":\"Feedforward neural network\",\"topicId\":\"153499\",\"url\":\"https://www.semanticscholar.org/topic/153499\"},{\"topic\":\"Real-time computing\",\"topicId\":\"172684\",\"url\":\"https://www.semanticscholar.org/topic/172684\"},{\"topic\":\"Software propagation\",\"topicId\":\"2021211\",\"url\":\"https://www.semanticscholar.org/topic/2021211\"},{\"topic\":\"Baseline (configuration management)\",\"topicId\":\"3403\",\"url\":\"https://www.semanticscholar.org/topic/3403\"},{\"topic\":\"Long short-term memory\",\"topicId\":\"117199\",\"url\":\"https://www.semanticscholar.org/topic/117199\"},{\"topic\":\"Real-time transcription\",\"topicId\":\"763488\",\"url\":\"https://www.semanticscholar.org/topic/763488\"},{\"topic\":\"Ground truth\",\"topicId\":\"33313\",\"url\":\"https://www.semanticscholar.org/topic/33313\"}],\"url\":\"https://www.semanticscholar.org/paper/2d5b4144124f47a6357e6390dc6c0f8806ac54f5\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017}\n"