"{\"abstract\":\"We consider retrieving a specific temporal segment, or moment, from a video given a natural language text description. Methods designed to retrieve whole video clips with natural language determine what occurs in a video but not when. To address this issue, we propose the Moment Context Network (MCN) which effectively localizes natural language queries in videos by integrating local and global video features over time. A key obstacle to training our MCN model is that current video datasets do not include pairs of localized video segments and referring expressions, or text descriptions which uniquely identify a corresponding moment. Therefore, we collect the Distinct Describable Moments (DiDeMo) dataset which consists of over 10,000 unedited, personal videos in diverse visual settings with pairs of localized video segments and referring expressions. We demonstrate that MCN outperforms several baseline methods and believe that our initial results together with the release of DiDeMo will inspire further research on localizing video moments with natural language.\",\"arxivId\":\"1708.01641\",\"authors\":[{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\",\"url\":\"https://www.semanticscholar.org/author/2234342\"},{\"authorId\":\"39231399\",\"name\":\"O. Wang\",\"url\":\"https://www.semanticscholar.org/author/39231399\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\",\"url\":\"https://www.semanticscholar.org/author/2177801\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\",\"url\":\"https://www.semanticscholar.org/author/1782755\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\",\"url\":\"https://www.semanticscholar.org/author/1753210\"},{\"authorId\":\"145160921\",\"name\":\"Bryan C. Russell\",\"url\":\"https://www.semanticscholar.org/author/145160921\"}],\"citationVelocity\":57,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"8775916\",\"name\":\"Da Cao\"},{\"authorId\":\"48205054\",\"name\":\"N. Han\"},{\"authorId\":\"48444479\",\"name\":\"Hao Chen\"},{\"authorId\":\"7621447\",\"name\":\"X. Wei\"},{\"authorId\":\"1897130\",\"name\":\"X. He\"}],\"doi\":\"10.1016/J.INS.2019.11.033\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d71aa931874ff05203091567d89c148b68ea292d\",\"title\":\"Video-based recipe retrieval\",\"url\":\"https://www.semanticscholar.org/paper/d71aa931874ff05203091567d89c148b68ea292d\",\"venue\":\"Inf. Sci.\",\"year\":2020},{\"arxivId\":\"2011.00597\",\"authors\":[{\"authorId\":\"2007582232\",\"name\":\"Simon Ging\"},{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"1835025\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"80089ad641bae28b0e57771afef181b60011069e\",\"title\":\"COOT: Cooperative Hierarchical Transformer for Video-Text Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/80089ad641bae28b0e57771afef181b60011069e\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2004.13931\",\"authors\":[{\"authorId\":\"153504695\",\"name\":\"Hao Zhang\"},{\"authorId\":\"1735962\",\"name\":\"Aixin Sun\"},{\"authorId\":\"1492128584\",\"name\":\"Wei Jing\"},{\"authorId\":\"10638646\",\"name\":\"Joey Tianyi Zhou\"}],\"doi\":\"10.18653/v1/2020.acl-main.585\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5a975dcd3dba2a11830e5595d4c4659441cb6836\",\"title\":\"Span-based Localizing Network for Natural Language Video Localization\",\"url\":\"https://www.semanticscholar.org/paper/5a975dcd3dba2a11830e5595d4c4659441cb6836\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"1909.05010\",\"authors\":[{\"authorId\":\"46584062\",\"name\":\"Junling Wang\"},{\"authorId\":\"152309767\",\"name\":\"L. Ma\"},{\"authorId\":\"119897463\",\"name\":\"Wenhao Jiang\"}],\"doi\":\"10.1609/AAAI.V34I07.6897\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"aa6c925c5f2fe61cdf8e09dd4ecbf1e7d220eac0\",\"title\":\"Temporally Grounding Language Queries in Videos by Contextual Boundary-aware Prediction\",\"url\":\"https://www.semanticscholar.org/paper/aa6c925c5f2fe61cdf8e09dd4ecbf1e7d220eac0\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2008.06880\",\"authors\":[{\"authorId\":\"1739188006\",\"name\":\"Sheng-Yu Zhang\"},{\"authorId\":\"3856602\",\"name\":\"Ziqi Tan\"},{\"authorId\":\"144644708\",\"name\":\"Jin Yu\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"33870528\",\"name\":\"Kun Kuang\"},{\"authorId\":null,\"name\":\"Jie Liu\"},{\"authorId\":\"1726030259\",\"name\":\"Jingren Zhou\"},{\"authorId\":\"1712223662\",\"name\":\"Hongxia Yang\"},{\"authorId\":\"144894837\",\"name\":\"F. Wu\"}],\"doi\":\"10.1145/3394171.3413880\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"72ca5f49b67f0e57e1f213323ff5d884e91ee824\",\"title\":\"Poet: Product-oriented Video Captioner for E-commerce\",\"url\":\"https://www.semanticscholar.org/paper/72ca5f49b67f0e57e1f213323ff5d884e91ee824\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145488619\",\"name\":\"M. Liu\"},{\"authorId\":null,\"name\":\"Xiang Wang\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":\"7792071\",\"name\":\"X. He\"},{\"authorId\":\"1748939\",\"name\":\"B. Chen\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1145/3209978.3210003\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"519da94369c1d87e09c592f239b55cc9486b5b7c\",\"title\":\"Attentive Moment Retrieval in Videos\",\"url\":\"https://www.semanticscholar.org/paper/519da94369c1d87e09c592f239b55cc9486b5b7c\",\"venue\":\"SIGIR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29367810\",\"name\":\"Wentian Zhao\"},{\"authorId\":\"70435288\",\"name\":\"Xinxiao Wu\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/TIP.2020.3042086\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bf2f223b2f4c425275f6b31f9e0111af32b41882\",\"title\":\"Cross-Domain Image Captioning via Cross-Modal Retrieval and Model Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/bf2f223b2f4c425275f6b31f9e0111af32b41882\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2021},{\"arxivId\":\"2009.03793\",\"authors\":[{\"authorId\":\"30793303\",\"name\":\"Amirhoshang Hoseinpour Dehkordi\"},{\"authorId\":\"153235768\",\"name\":\"M. Alizadeh\"},{\"authorId\":\"1397911258\",\"name\":\"Ali Movaghar-Rahimabadi\"}],\"doi\":\"10.36227/techrxiv.12928544\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"46f097e32ea304a14c8e26648b05f944d530b016\",\"title\":\"Linear Temporal Public Announcement Logic: a new perspective for reasoning the knowledge of multi-classifiers\",\"url\":\"https://www.semanticscholar.org/paper/46f097e32ea304a14c8e26648b05f944d530b016\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1808.08803\",\"authors\":[{\"authorId\":\"1819984\",\"name\":\"K. Ning\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"47118295\",\"name\":\"Ming Cai\"},{\"authorId\":null,\"name\":\"Yi Yang\"},{\"authorId\":\"145982709\",\"name\":\"Di Xie\"},{\"authorId\":\"39918420\",\"name\":\"F. Wu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"20da5315cfe5eab69d99bbda270e73ab488a49ba\",\"title\":\"Attentive Sequence to Sequence Translation for Localizing Clips of Interest by Natural Language Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/20da5315cfe5eab69d99bbda270e73ab488a49ba\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27720832\",\"name\":\"T. Long\"},{\"authorId\":\"40892875\",\"name\":\"Pascal Mettes\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"},{\"authorId\":\"1647395777\",\"name\":\"Cees Snoek\"}],\"doi\":\"10.1109/cvpr42600.2020.00122\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2f614f15b8ce225e7385a5427dd6cc2949b3d92f\",\"title\":\"Searching for Actions on the Hyperbole\",\"url\":\"https://www.semanticscholar.org/paper/2f614f15b8ce225e7385a5427dd6cc2949b3d92f\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98579574\",\"name\":\"Daizong Liu\"},{\"authorId\":\"51912474\",\"name\":\"Xiaoye Qu\"},{\"authorId\":\"1912074118\",\"name\":\"Jianfeng Dong\"},{\"authorId\":\"145232778\",\"name\":\"Pan Zhou\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"83d2f3b57aa07c499c3a19d22fe4f4ef655e9030\",\"title\":\"Reasoning Step-by-Step: Temporal Sentence Localization in Videos via Deep Rectification-Modulation Network\",\"url\":\"https://www.semanticscholar.org/paper/83d2f3b57aa07c499c3a19d22fe4f4ef655e9030\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":\"1905.02442\",\"authors\":[{\"authorId\":\"115044425\",\"name\":\"Sho Maeoki\"},{\"authorId\":\"51215319\",\"name\":\"Kohei Uehara\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.1109/CVPRW50498.2020.00484\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1cb7549a77b7040b7e2ea63ce79065ab2064df59\",\"title\":\"Interactive Video Retrieval with Dialog\",\"url\":\"https://www.semanticscholar.org/paper/1cb7549a77b7040b7e2ea63ce79065ab2064df59\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"1812.00303\",\"authors\":[{\"authorId\":\"144282337\",\"name\":\"B. McIntosh\"},{\"authorId\":\"7839191\",\"name\":\"K. Duarte\"},{\"authorId\":\"2116440\",\"name\":\"Y. Rawat\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b181ae8ed315ceb8f03332ba02ef0849adbe5b4c\",\"title\":\"Multi-modal Capsule Routing for Actor and Action Video Segmentation Conditioned on Natural Language Queries\",\"url\":\"https://www.semanticscholar.org/paper/b181ae8ed315ceb8f03332ba02ef0849adbe5b4c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1908.07236\",\"authors\":[{\"authorId\":\"145112187\",\"name\":\"Cristian Rodriguez-Opazo\"},{\"authorId\":\"1389646918\",\"name\":\"Edison Marrese-Taylor\"},{\"authorId\":\"9120887\",\"name\":\"F. Saleh\"},{\"authorId\":\"40124570\",\"name\":\"Hongdong Li\"},{\"authorId\":\"47873182\",\"name\":\"S. Gould\"}],\"doi\":\"10.1109/WACV45572.2020.9093328\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"03df26255781ebb71d9430e1b2aaabf8e1af9990\",\"title\":\"Proposal-free Temporal Moment Localization of a Natural-Language Query in Video using Guided Attention\",\"url\":\"https://www.semanticscholar.org/paper/03df26255781ebb71d9430e1b2aaabf8e1af9990\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1806.08251\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8f27df2d4fb7dd7ed5587640dcbe4dc1eb37acfb\",\"title\":\"Unseen Action Recognition with Multimodal Learning\",\"url\":\"https://www.semanticscholar.org/paper/8f27df2d4fb7dd7ed5587640dcbe4dc1eb37acfb\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2001.06891\",\"authors\":[{\"authorId\":\"1742291\",\"name\":\"Zixing Zhang\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"90148415\",\"name\":\"Yang Zhao\"},{\"authorId\":\"50621207\",\"name\":\"Q. Wang\"},{\"authorId\":\"46936306\",\"name\":\"H. Liu\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"}],\"doi\":\"10.1109/cvpr42600.2020.01068\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0a709bb1b4bce51de5aa67a362ea69e51a43d1e5\",\"title\":\"Where Does It Exist: Spatio-Temporal Video Grounding for Multi-Form Sentences\",\"url\":\"https://www.semanticscholar.org/paper/0a709bb1b4bce51de5aa67a362ea69e51a43d1e5\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1904.03589\",\"authors\":[{\"authorId\":\"6818270\",\"name\":\"Zhiyuan Fang\"},{\"authorId\":\"34362536\",\"name\":\"S. Kong\"},{\"authorId\":\"143800213\",\"name\":\"Charless C. Fowlkes\"},{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"}],\"doi\":\"10.1109/CVPR.2019.00654\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"92366e3c446c30e4c783c61dcf420edd17695c73\",\"title\":\"Modularized Textual Grounding for Counterfactual Resilience\",\"url\":\"https://www.semanticscholar.org/paper/92366e3c446c30e4c783c61dcf420edd17695c73\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"506ea19145838a035e7dba535519fb40a3a0018c\",\"title\":\"Learning Shared Multimodal Embeddings with Unpaired Data\",\"url\":\"https://www.semanticscholar.org/paper/506ea19145838a035e7dba535519fb40a3a0018c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2002.00842\",\"authors\":[{\"authorId\":\"3178508\",\"name\":\"Songyang Zhang\"},{\"authorId\":\"2941457\",\"name\":\"Tolga Aktas\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"42884b710491ee66fa4ccea6ffbe40f924a55432\",\"title\":\"Mi YouTube es Su YouTube? Analyzing the Cultures using YouTube Thumbnails of Popular Videos\",\"url\":\"https://www.semanticscholar.org/paper/42884b710491ee66fa4ccea6ffbe40f924a55432\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.07967\",\"authors\":[{\"authorId\":\"144810262\",\"name\":\"H. M. Nguyen\"},{\"authorId\":\"3388392\",\"name\":\"T. Miyazaki\"},{\"authorId\":\"2137463\",\"name\":\"Y. Sugaya\"},{\"authorId\":\"1740235\",\"name\":\"S. Omachi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"20b15ddf9efe511961321355bcb4a62c3a29a9ef\",\"title\":\"Multiple Visual-Semantic Embedding for Video Retrieval from Query Sentence\",\"url\":\"https://www.semanticscholar.org/paper/20b15ddf9efe511961321355bcb4a62c3a29a9ef\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1802.10250\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"1728712\",\"name\":\"Boyang Li\"},{\"authorId\":\"2018561\",\"name\":\"Vasili Ramanishka\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/WACV.2019.00048\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"99cdb10443a0543be3466c9231ff922bcc996843\",\"title\":\"Joint Event Detection and Description in Continuous Video Streams\",\"url\":\"https://www.semanticscholar.org/paper/99cdb10443a0543be3466c9231ff922bcc996843\",\"venue\":\"2019 IEEE Winter Applications of Computer Vision Workshops (WACVW)\",\"year\":2019},{\"arxivId\":\"2005.06409\",\"authors\":[{\"authorId\":\"51270689\",\"name\":\"Hyounghun Kim\"},{\"authorId\":\"151270642\",\"name\":\"Zineng Tang\"},{\"authorId\":\"143977266\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/2020.acl-main.435\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9a87c1f04bae4ab507ed0e03bfd10d870d733367\",\"title\":\"Dense-Caption Matching and Frame-Selection Gating for Temporal Localization in VideoQA\",\"url\":\"https://www.semanticscholar.org/paper/9a87c1f04bae4ab507ed0e03bfd10d870d733367\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"1910.11306\",\"authors\":[{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"2299479\",\"name\":\"R. Arandjelovi\\u0107\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/ICCV.2019.00583\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c4892a8ac3e3e3575b17fff393e57b8fd20a08a8\",\"title\":\"Controllable Attention for Structured Layered Video Decomposition\",\"url\":\"https://www.semanticscholar.org/paper/c4892a8ac3e3e3575b17fff393e57b8fd20a08a8\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2007.14682\",\"authors\":[{\"authorId\":\"1840585237\",\"name\":\"Philipp Rimle\"},{\"authorId\":\"12984122\",\"name\":\"Pelin Dogan\"},{\"authorId\":\"143720818\",\"name\":\"M. Gro\\u00df\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f8cf7fdf3f9595f7841ea2e128f569e23f99468f\",\"title\":\"Enriching Video Captions With Contextual Text\",\"url\":\"https://www.semanticscholar.org/paper/f8cf7fdf3f9595f7841ea2e128f569e23f99468f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.08614\",\"authors\":[{\"authorId\":\"2017491\",\"name\":\"J. Wu\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"50016941\",\"name\":\"Xiao-Guang Han\"},{\"authorId\":\"49478124\",\"name\":\"L. Lin\"}],\"doi\":\"10.1145/3394171.3413862\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"949b698f4aaaeea923d451db8175c5b464520f27\",\"title\":\"Reinforcement Learning for Weakly Supervised Temporal Grounding of Natural Language in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/949b698f4aaaeea923d451db8175c5b464520f27\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144286627\",\"name\":\"Fiona Fui-Hoon Nah\"},{\"authorId\":\"1746885\",\"name\":\"K. Siau\"},{\"authorId\":\"1743774\",\"name\":\"E. Bertino\"}],\"doi\":\"10.1007/978-3-030-50341-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"873abca5d878eef5fa34c3d1ede0dfa4a9a18926\",\"title\":\"HCI in Business, Government and Organizations: 7th International Conference, HCIBGO 2020, Held as Part of the 22nd HCI International Conference, HCII 2020, Copenhagen, Denmark, July 19\\u201324, 2020, Proceedings\",\"url\":\"https://www.semanticscholar.org/paper/873abca5d878eef5fa34c3d1ede0dfa4a9a18926\",\"venue\":\"HCI\",\"year\":2020},{\"arxivId\":\"2006.10457\",\"authors\":[{\"authorId\":\"46578437\",\"name\":\"K. Liu\"},{\"authorId\":\"1390538450\",\"name\":\"Xun Yang\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"},{\"authorId\":\"144258295\",\"name\":\"Huadong Ma\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"60e3cc7a1ba3e8617269b801b41692ed5f613b3d\",\"title\":\"Language Guided Networks for Cross-modal Moment Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/60e3cc7a1ba3e8617269b801b41692ed5f613b3d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1811.08925\",\"authors\":[{\"authorId\":\"40899706\",\"name\":\"Runzhou Ge\"},{\"authorId\":\"3029956\",\"name\":\"J. Gao\"},{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/WACV.2019.00032\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1d4dcd7ed33666e05e28b18f86a693264783749c\",\"title\":\"MAC: Mining Activity Concepts for Language-Based Temporal Localization\",\"url\":\"https://www.semanticscholar.org/paper/1d4dcd7ed33666e05e28b18f86a693264783749c\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145583985\",\"name\":\"Wenwu Zhu\"},{\"authorId\":null,\"name\":\"Xin Wang\"},{\"authorId\":\"48385803\",\"name\":\"W. Gao\"}],\"doi\":\"10.1109/TMM.2020.2969791\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a94ac484b3cc19cbf03bdbac0c727579a09fc3b9\",\"title\":\"Multimedia Intelligence: When Multimedia Meets Artificial Intelligence\",\"url\":\"https://www.semanticscholar.org/paper/a94ac484b3cc19cbf03bdbac0c727579a09fc3b9\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"49730189\",\"name\":\"Boyang Li\"},{\"authorId\":\"2018561\",\"name\":\"Vasili Ramanishka\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/WACVW.2019.00011\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"32b3e8f7a673801d6bcfb482a72c52c78e96b006\",\"title\":\"Joint Event Detection and Description in Continuous Video Streams\",\"url\":\"https://www.semanticscholar.org/paper/32b3e8f7a673801d6bcfb482a72c52c78e96b006\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49838322\",\"name\":\"Ken Fukuda\"},{\"authorId\":\"2719546\",\"name\":\"Julio Vizcarra\"},{\"authorId\":\"48643837\",\"name\":\"S. Nishimura\"}],\"doi\":\"10.1007/978-3-030-50341-3_4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b08a50fd42744ca4e8a5aeae9b6bcae2b5bed98a\",\"title\":\"Massive Semantic Video Annotation in High-End Customer Service - Example in Airline Service Value Assessment\",\"url\":\"https://www.semanticscholar.org/paper/b08a50fd42744ca4e8a5aeae9b6bcae2b5bed98a\",\"venue\":\"HCI\",\"year\":2020},{\"arxivId\":\"1910.01442\",\"authors\":[{\"authorId\":\"40879119\",\"name\":\"Kexin Yi\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"3422021\",\"name\":\"Yunzhu Li\"},{\"authorId\":\"143967473\",\"name\":\"P. Kohli\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7f3ecbe546efed8ba42812f977354c16590bad77\",\"title\":\"CLEVRER: CoLlision Events for Video REpresentation and Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/7f3ecbe546efed8ba42812f977354c16590bad77\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"1907.09358\",\"authors\":[{\"authorId\":\"3219864\",\"name\":\"Aditya Mogadala\"},{\"authorId\":\"151119369\",\"name\":\"M. Kalimuthu\"},{\"authorId\":\"2561225\",\"name\":\"D. Klakow\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f8a48678094adbe421d61d0045361bfc635a2900\",\"title\":\"Trends in Integration of Vision and Language Research: A Survey of Tasks, Datasets, and Methods\",\"url\":\"https://www.semanticscholar.org/paper/f8a48678094adbe421d61d0045361bfc635a2900\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1803.07485\",\"authors\":[{\"authorId\":\"32781361\",\"name\":\"Kirill Gavrilyuk\"},{\"authorId\":\"3060081\",\"name\":\"A. Ghodrati\"},{\"authorId\":\"3245057\",\"name\":\"Zhenyang Li\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1109/CVPR.2018.00624\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1e55e9c647832c969e449da28a391205a9704c60\",\"title\":\"Actor and Action Video Segmentation from a Sentence\",\"url\":\"https://www.semanticscholar.org/paper/1e55e9c647832c969e449da28a391205a9704c60\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2008.13362\",\"authors\":[{\"authorId\":\"2532612\",\"name\":\"Mrigank Rochan\"},{\"authorId\":\"1491322959\",\"name\":\"Mahesh Kumar Krishna Reddy\"},{\"authorId\":null,\"name\":\"Yang Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8aa1bf7c6b1505538903c57472e5fa0ed45b303d\",\"title\":\"Sentence Guided Temporal Modulation for Dynamic Video Thumbnail Generation\",\"url\":\"https://www.semanticscholar.org/paper/8aa1bf7c6b1505538903c57472e5fa0ed45b303d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1906.04402\",\"authors\":[{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"152714397\",\"name\":\"M. Soleymani\"}],\"doi\":\"10.1109/CVPR.2019.00208\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a39d5919531a56de0e36f6b76142041b5d508213\",\"title\":\"Polysemous Visual-Semantic Embedding for Cross-Modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/a39d5919531a56de0e36f6b76142041b5d508213\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1910.02930\",\"authors\":[{\"authorId\":\"2689239\",\"name\":\"Jack Hessel\"},{\"authorId\":\"48157646\",\"name\":\"Bo Pang\"},{\"authorId\":\"39815369\",\"name\":\"Z. Zhu\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"}],\"doi\":\"10.18653/v1/K19-1039\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"659e2f1d54b88252bcf08c4f3d54c0832a181c3e\",\"title\":\"A Case Study on Combining ASR and Visual Features for Generating Instructional Video Captions\",\"url\":\"https://www.semanticscholar.org/paper/659e2f1d54b88252bcf08c4f3d54c0832a181c3e\",\"venue\":\"CoNLL\",\"year\":2019},{\"arxivId\":\"2011.09046\",\"authors\":[{\"authorId\":\"1490732820\",\"name\":\"Bowen Zhang\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"2119006\",\"name\":\"Joonseok Lee\"},{\"authorId\":\"145327825\",\"name\":\"Mingde Zhao\"},{\"authorId\":\"40600020\",\"name\":\"Sheide Chammas\"},{\"authorId\":\"20048351\",\"name\":\"Vihan Jain\"},{\"authorId\":\"2042413\",\"name\":\"E. Ie\"},{\"authorId\":\"39543696\",\"name\":\"Fei Sha\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fe21d30afa60f8ab72da309ca0a80eee1ac07a66\",\"title\":\"A Hierarchical Multi-Modal Encoder for Moment Localization in Video Corpus\",\"url\":\"https://www.semanticscholar.org/paper/fe21d30afa60f8ab72da309ca0a80eee1ac07a66\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153772546\",\"name\":\"K. Ning\"},{\"authorId\":\"3041937\",\"name\":\"Lingxi Xie\"},{\"authorId\":\"1521935491\",\"name\":\"Fei Wu\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.24963/ijcai.2020/132\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"d358f8939992a8c2c649338810aa5e66ed665568\",\"title\":\"Polar Relative Positional Encoding for Video-Language Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/d358f8939992a8c2c649338810aa5e66ed665568\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":\"2005.03684\",\"authors\":[{\"authorId\":\"153825694\",\"name\":\"D. Fried\"},{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"1685771\",\"name\":\"P. Blunsom\"},{\"authorId\":\"1745899\",\"name\":\"Chris Dyer\"},{\"authorId\":\"152361825\",\"name\":\"S. Clark\"},{\"authorId\":\"3208081\",\"name\":\"A. Nematzadeh\"}],\"doi\":\"10.18653/v1/2020.acl-main.231\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"23edba4188492f39a7aefebbd7267a6a8d9ddb74\",\"title\":\"Learning to Segment Actions from Observation and Narration\",\"url\":\"https://www.semanticscholar.org/paper/23edba4188492f39a7aefebbd7267a6a8d9ddb74\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"1907.13487\",\"authors\":[{\"authorId\":\"40457423\",\"name\":\"Y. Liu\"},{\"authorId\":\"7641268\",\"name\":\"Samuel Albanie\"},{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b16eeb1e975e8e6ea9450c78fd12da05cfd1375f\",\"title\":\"Use What You Have: Video retrieval using representations from collaborative experts\",\"url\":\"https://www.semanticscholar.org/paper/b16eeb1e975e8e6ea9450c78fd12da05cfd1375f\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"2173143\",\"name\":\"C. Zhang\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"48707717\",\"name\":\"Z. Wang\"},{\"authorId\":\"145262461\",\"name\":\"Trung Bui\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1007/978-3-030-11024-6_43\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d4e7a7588b5d1474a4cd884e81730342e18186e9\",\"title\":\"Visually Indicated Sound Generation by Perceptually Optimized Classification\",\"url\":\"https://www.semanticscholar.org/paper/d4e7a7588b5d1474a4cd884e81730342e18186e9\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"1910.11009\",\"authors\":[{\"authorId\":\"47424372\",\"name\":\"Yu Xiong\"},{\"authorId\":\"39360892\",\"name\":\"Q. Huang\"},{\"authorId\":\"10357054\",\"name\":\"L. Guo\"},{\"authorId\":\"145798292\",\"name\":\"Hang Zhou\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/ICCV.2019.00469\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"87699cff38982712ddb0b2349313077779a5d0ff\",\"title\":\"A Graph-Based Framework to Bridge Movies and Synopses\",\"url\":\"https://www.semanticscholar.org/paper/87699cff38982712ddb0b2349313077779a5d0ff\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1910.02993\",\"authors\":[{\"authorId\":\"49577833\",\"name\":\"Daniel Y. Fu\"},{\"authorId\":\"41156945\",\"name\":\"W. Crichton\"},{\"authorId\":\"2651173\",\"name\":\"J. Hong\"},{\"authorId\":\"153742294\",\"name\":\"Xinwei Yao\"},{\"authorId\":\"9184695\",\"name\":\"Haotian Zhang\"},{\"authorId\":\"48289103\",\"name\":\"Anh Truong\"},{\"authorId\":\"1381444249\",\"name\":\"Avanika Narayan\"},{\"authorId\":\"1820412\",\"name\":\"M. Agrawala\"},{\"authorId\":\"1803218\",\"name\":\"Christopher R\\u00e9\"},{\"authorId\":\"2789576\",\"name\":\"K. Fatahalian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9eb31de07bd0cd684a46785020f08633e4331e05\",\"title\":\"Rekall: Specifying Video Events using Compositions of Spatiotemporal Labels\",\"url\":\"https://www.semanticscholar.org/paper/9eb31de07bd0cd684a46785020f08633e4331e05\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1804.07014\",\"authors\":[{\"authorId\":\"48009996\",\"name\":\"Yitian Yuan\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"145583986\",\"name\":\"Wenwu Zhu\"}],\"doi\":\"10.1609/aaai.v33i01.33019159\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"31bb920739f22b4865161f75692785decfea470c\",\"title\":\"To Find Where You Talk: Temporal Sentence Localization in Video with Attention Based Location Regression\",\"url\":\"https://www.semanticscholar.org/paper/31bb920739f22b4865161f75692785decfea470c\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121357290\",\"name\":\"Ruolin Wang\"},{\"authorId\":\"152641281\",\"name\":\"Y. Zhou\"}],\"doi\":\"10.1109/ICIP40778.2020.9190869\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4a343ca82464f8e11aa5626afc7474ab2286ed14\",\"title\":\"A Feature Pair Fusion And Hierarchical Learning Framework For Video Re-Localization\",\"url\":\"https://www.semanticscholar.org/paper/4a343ca82464f8e11aa5626afc7474ab2286ed14\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"1810.07212\",\"authors\":[{\"authorId\":\"3047890\",\"name\":\"Bowen Zhang\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"}],\"doi\":\"10.1007/978-3-030-01261-8_23\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ea133d0067740902bc26a082c842d9e7ba48ecf6\",\"title\":\"Cross-Modal and Hierarchical Modeling of Video and Text\",\"url\":\"https://www.semanticscholar.org/paper/ea133d0067740902bc26a082c842d9e7ba48ecf6\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"}],\"doi\":\"10.25781/KAUST-VR909\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b5c549fd9172f2d1be80cc77b0de9e90d3416463\",\"title\":\"Efficient Localization of Human Actions and Moments in Videos\",\"url\":\"https://www.semanticscholar.org/paper/b5c549fd9172f2d1be80cc77b0de9e90d3416463\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1803.10699\",\"authors\":[{\"authorId\":\"144529493\",\"name\":\"Li Ding\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":\"10.1109/CVPR.2018.00681\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c6ce420976f958e7582a2f452c3a541faa82074\",\"title\":\"Weakly-Supervised Action Segmentation with Iterative Soft Boundary Assignment\",\"url\":\"https://www.semanticscholar.org/paper/6c6ce420976f958e7582a2f452c3a541faa82074\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144677557\",\"name\":\"C. Li\"},{\"authorId\":\"47827559\",\"name\":\"Yuming Zhao\"},{\"authorId\":\"151474865\",\"name\":\"S. Peng\"},{\"authorId\":\"73708274\",\"name\":\"J. Chen\"}],\"doi\":\"10.1109/ICIP.2019.8802929\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c943d780edef5c07526e745ac678bfcea79b7bfb\",\"title\":\"Bidirectional Single-Stream Temporal Sentence Query Localization in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/c943d780edef5c07526e745ac678bfcea79b7bfb\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"1908.04052\",\"authors\":[{\"authorId\":\"152338671\",\"name\":\"Yiitan Yuan\"},{\"authorId\":\"152309767\",\"name\":\"L. Ma\"},{\"authorId\":\"145583986\",\"name\":\"Wenwu Zhu\"}],\"doi\":\"10.1145/3343031.3350985\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"745242c746b6f379048f6dbdfc009181d9027a60\",\"title\":\"Sentence Specified Dynamic Video Thumbnail Generation\",\"url\":\"https://www.semanticscholar.org/paper/745242c746b6f379048f6dbdfc009181d9027a60\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2359832\",\"name\":\"Hongya Wang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"46772808\",\"name\":\"X. Chen\"},{\"authorId\":\"2352456\",\"name\":\"Z. Xiong\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1145/3394171.3413975\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7b8d5e6f888c4e165fea9bab809239f7fe5fef65\",\"title\":\"Dual Path Interaction Network for Video Moment Localization\",\"url\":\"https://www.semanticscholar.org/paper/7b8d5e6f888c4e165fea9bab809239f7fe5fef65\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Zhu Zhang\"},{\"authorId\":\"144197770\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"49290494\",\"name\":\"Zhijie Lin\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"49710696\",\"name\":\"Dexia Cai\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5d145292fd11ca274693ec9ea6941a9147ae5868\",\"title\":\"4 Self-Attention Interaction Localizer 4 . 1 Problem Formulation\",\"url\":\"https://www.semanticscholar.org/paper/5d145292fd11ca274693ec9ea6941a9147ae5868\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41052836\",\"name\":\"Anya Belz\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"}],\"doi\":\"10.1017/S1351324918000086\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d740802aa22dbc187fe5df39108ba493b34d2839\",\"title\":\"From image to language and back again\",\"url\":\"https://www.semanticscholar.org/paper/d740802aa22dbc187fe5df39108ba493b34d2839\",\"venue\":\"Nat. Lang. Eng.\",\"year\":2018},{\"arxivId\":\"1912.06430\",\"authors\":[{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"1466466597\",\"name\":\"Lucas Smaira\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/cvpr42600.2020.00990\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fb40df31aa7177c9d009478479db61c39caebd54\",\"title\":\"End-to-End Learning of Visual Representations From Uncurated Instructional Videos\",\"url\":\"https://www.semanticscholar.org/paper/fb40df31aa7177c9d009478479db61c39caebd54\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47795983\",\"name\":\"Yu-Lan Yang\"},{\"authorId\":\"51484605\",\"name\":\"Z. Li\"},{\"authorId\":\"1519001806\",\"name\":\"Gangyan Zeng\"}],\"doi\":\"10.1109/ICCST50977.2020.00123\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"895fdebe3a2584fa87ee7da9eea47f131c09375f\",\"title\":\"A Survey of Temporal Activity Localization via Language in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/895fdebe3a2584fa87ee7da9eea47f131c09375f\",\"venue\":\"2020 International Conference on Culture-oriented Science & Technology (ICCST)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51033208\",\"name\":\"B. Liu\"},{\"authorId\":\"34149749\",\"name\":\"Serena Yeung\"},{\"authorId\":\"34613203\",\"name\":\"Edward Chou\"},{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1007/978-3-030-01219-9_34\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"73d1b35cd28befe845fcb60a3fed67c9fb7793ad\",\"title\":\"Temporal Modular Networks for Retrieving Complex Compositional Activities in Videos\",\"url\":\"https://www.semanticscholar.org/paper/73d1b35cd28befe845fcb60a3fed67c9fb7793ad\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2009.11232\",\"authors\":[{\"authorId\":\"1432778730\",\"name\":\"Binjie Zhang\"},{\"authorId\":\"1940342\",\"name\":\"Y. Li\"},{\"authorId\":\"144204924\",\"name\":\"C. Yuan\"},{\"authorId\":\"50854337\",\"name\":\"D. Xu\"},{\"authorId\":\"2091174\",\"name\":\"Pin Jiang\"},{\"authorId\":\"1387190008\",\"name\":\"Ying Shan\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"1e645df446ccdc985b85864ac0b91b053090c14d\",\"title\":\"A Simple Yet Effective Method for Video Temporal Grounding with Cross-Modality Attention\",\"url\":\"https://www.semanticscholar.org/paper/1e645df446ccdc985b85864ac0b91b053090c14d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1904.02755\",\"authors\":[{\"authorId\":\"3288111\",\"name\":\"S. Ghosh\"},{\"authorId\":\"50714560\",\"name\":\"A. Agarwal\"},{\"authorId\":\"27456119\",\"name\":\"Zarana Parekh\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.18653/v1/N19-1198\",\"intent\":[\"methodology\",\"result\"],\"isInfluential\":false,\"paperId\":\"ddf69a6ef015a1b0668ca48a486c4cc7e22a7d9c\",\"title\":\"ExCL: Extractive Clip Localization Using Natural Language Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/ddf69a6ef015a1b0668ca48a486c4cc7e22a7d9c\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":\"1909.00239\",\"authors\":[{\"authorId\":\"1759094\",\"name\":\"Mingfei Gao\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"}],\"doi\":\"10.18653/v1/D19-1157\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a758828d2865592fb7ee0c95fe4d2517cf405196\",\"title\":\"WSLLN: Weakly Supervised Natural Language Localization Networks\",\"url\":\"https://www.semanticscholar.org/paper/a758828d2865592fb7ee0c95fe4d2517cf405196\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1423743315\",\"name\":\"Theodoros Georgiou\"},{\"authorId\":\"3546791\",\"name\":\"Y. Liu\"},{\"authorId\":\"47482437\",\"name\":\"W. Chen\"},{\"authorId\":\"1731570\",\"name\":\"M. Lew\"}],\"doi\":\"10.1007/s13735-019-00183-w\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"763495e4ce53c989bf7c2910ae8cb51e4469e195\",\"title\":\"A survey of traditional and deep learning-based feature descriptors for high dimensional data in computer vision\",\"url\":\"https://www.semanticscholar.org/paper/763495e4ce53c989bf7c2910ae8cb51e4469e195\",\"venue\":\"International Journal of Multimedia Information Retrieval\",\"year\":2019},{\"arxivId\":\"2005.04208\",\"authors\":[{\"authorId\":\"153000035\",\"name\":\"M. Bain\"},{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"152853748\",\"name\":\"A. Brown\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"239c34ab213229725c6428e63b1315f2e8cdcbc8\",\"title\":\"Condensed Movies: Story Based Retrieval with Contextual Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/239c34ab213229725c6428e63b1315f2e8cdcbc8\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.00786\",\"authors\":[{\"authorId\":\"152905588\",\"name\":\"Jianhua Yang\"},{\"authorId\":\"144368930\",\"name\":\"Yan Huang\"},{\"authorId\":\"2004516791\",\"name\":\"Kai Niu\"},{\"authorId\":\"46953683\",\"name\":\"Zhanyu Ma\"},{\"authorId\":\"123865558\",\"name\":\"Liang Wang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"57177ff1c7cac4bd05597fc19e683c92ed751e9b\",\"title\":\"Actor and Action Modular Network for Text-based Video Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/57177ff1c7cac4bd05597fc19e683c92ed751e9b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1906.02497\",\"authors\":[{\"authorId\":\"1764508\",\"name\":\"Z. Zhang\"},{\"authorId\":\"34064720\",\"name\":\"Zhijie Lin\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"123034558\",\"name\":\"Z. Xiao\"}],\"doi\":\"10.1145/3331184.3331235\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"fb53803897d3df3e1f43a43a753ee88a64517c47\",\"title\":\"Cross-Modal Interaction Networks for Query-Based Moment Retrieval in Videos\",\"url\":\"https://www.semanticscholar.org/paper/fb53803897d3df3e1f43a43a753ee88a64517c47\",\"venue\":\"SIGIR\",\"year\":2019},{\"arxivId\":\"1906.12165\",\"authors\":[{\"authorId\":\"1764508\",\"name\":\"Z. Zhang\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"34064720\",\"name\":\"Zhijie Lin\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"}],\"doi\":\"10.24963/ijcai.2019/610\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5d145292fd11ca274693ec9ea6941a9147ae5868\",\"title\":\"Localizing Unseen Activities in Video via Image Query\",\"url\":\"https://www.semanticscholar.org/paper/5d145292fd11ca274693ec9ea6941a9147ae5868\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"1912.02256\",\"authors\":[{\"authorId\":\"143935879\",\"name\":\"Jonathan C. Stroud\"},{\"authorId\":\"32349340\",\"name\":\"Ryan McCaffrey\"},{\"authorId\":\"145557251\",\"name\":\"R. Mihalcea\"},{\"authorId\":\"145820819\",\"name\":\"Jun Deng\"},{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4979560dcff028a66ee44ce285c5bb1e22e1dc24\",\"title\":\"Compositional Temporal Visual Grounding of Natural Language Event Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/4979560dcff028a66ee44ce285c5bb1e22e1dc24\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"93353108\",\"name\":\"Cheng Chen\"},{\"authorId\":\"1649999106\",\"name\":\"Xiaodong Gu\"}],\"doi\":\"10.1007/978-3-030-64221-1_11\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c6b6e4860665d9185dfd80af63d93334582c56be\",\"title\":\"Semantic Modulation Based Residual Network for Temporal Language Queries Grounding in Video\",\"url\":\"https://www.semanticscholar.org/paper/c6b6e4860665d9185dfd80af63d93334582c56be\",\"venue\":\"ISNN\",\"year\":2020},{\"arxivId\":\"2012.02646\",\"authors\":[{\"authorId\":\"1992634637\",\"name\":\"Songyang Zhang\"},{\"authorId\":\"2484788\",\"name\":\"Houwen Peng\"},{\"authorId\":\"2027130177\",\"name\":\"J. Fu\"},{\"authorId\":\"38534822\",\"name\":\"Y. Lu\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"261582574b9e039be1518bc7c8e405a4af75a41a\",\"title\":\"Multi-Scale 2D Temporal Adjacent Networks for Moment Localization with Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/261582574b9e039be1518bc7c8e405a4af75a41a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145488619\",\"name\":\"M. Liu\"},{\"authorId\":null,\"name\":\"Xiang Wang\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"},{\"authorId\":\"1748939\",\"name\":\"B. Chen\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1145/3240508.3240549\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"175864710def9b3e8b42e4613856d0b840c37615\",\"title\":\"Cross-modal Moment Localization in Videos\",\"url\":\"https://www.semanticscholar.org/paper/175864710def9b3e8b42e4613856d0b840c37615\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144069314\",\"name\":\"Bin Jiang\"},{\"authorId\":\"49444962\",\"name\":\"X. Huang\"},{\"authorId\":\"143702931\",\"name\":\"C. Yang\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1145/3323873.3325019\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4e1ad4e3eeded53acf7514029ec556ee0ea42c45\",\"title\":\"Cross-Modal Video Moment Retrieval with Spatial and Language-Temporal Attention\",\"url\":\"https://www.semanticscholar.org/paper/4e1ad4e3eeded53acf7514029ec556ee0ea42c45\",\"venue\":\"ICMR\",\"year\":2019},{\"arxivId\":\"1809.01816\",\"authors\":[{\"authorId\":\"2150275\",\"name\":\"S. Kottur\"},{\"authorId\":\"144915495\",\"name\":\"Jos\\u00e9 M. F. Moura\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.1007/978-3-030-01267-0_10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"782bc02684de81f98c92475957501801bf91e023\",\"title\":\"Visual Coreference Resolution in Visual Dialog using Neural Module Networks\",\"url\":\"https://www.semanticscholar.org/paper/782bc02684de81f98c92475957501801bf91e023\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2007.02036\",\"authors\":[{\"authorId\":\"2447631\",\"name\":\"Junyeong Kim\"},{\"authorId\":\"103278467\",\"name\":\"Minuk Ma\"},{\"authorId\":\"48920375\",\"name\":\"T. Pham\"},{\"authorId\":\"97531942\",\"name\":\"Kyungsu Kim\"},{\"authorId\":\"145954697\",\"name\":\"C. Yoo\"}],\"doi\":\"10.1109/cvpr42600.2020.01012\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7fa5fdaacc87165a0281babd96949e8ec74d3a41\",\"title\":\"Modality Shifting Attention Network for Multi-Modal Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7fa5fdaacc87165a0281babd96949e8ec74d3a41\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"BiGRU BiGRU\"},{\"authorId\":null,\"name\":\"BiGRU\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"dd8a531ddff2ba788d02555af04632c46f31ecf0\",\"title\":\"Multi-Stage Cross-modal Interaction Module d ) Moment Retrieval Module q \\\" q # q $ q ) Query\",\"url\":\"https://www.semanticscholar.org/paper/dd8a531ddff2ba788d02555af04632c46f31ecf0\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1910.04744\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"479c6913b92335d77e81af95f559508f0e2753e5\",\"title\":\"CATER: A diagnostic dataset for Compositional Actions and TEmporal Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/479c6913b92335d77e81af95f559508f0e2753e5\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1900432330\",\"name\":\"Ke Ning\"},{\"authorId\":\"1811534\",\"name\":\"M. Cai\"},{\"authorId\":\"145982709\",\"name\":\"Di Xie\"},{\"authorId\":\"144894837\",\"name\":\"F. Wu\"}],\"doi\":\"10.1109/TMM.2019.2957854\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f9f2837b150eab8a1aa2e74a1a528700e1e6d8b8\",\"title\":\"An Attentive Sequence to Sequence Translator for Localizing Video Clips by Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/f9f2837b150eab8a1aa2e74a1a528700e1e6d8b8\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"1804.02516\",\"authors\":[{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"3448af861bf5d44ce7ab6b25002504815212252e\",\"title\":\"Learning a Text-Video Embedding from Incomplete and Heterogeneous Data\",\"url\":\"https://www.semanticscholar.org/paper/3448af861bf5d44ce7ab6b25002504815212252e\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2326243\",\"name\":\"Arun Balajee Vasudevan\"},{\"authorId\":\"1778526\",\"name\":\"Dengxin Dai\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"392d258c7c49a8d22bd6b323b2fb67bbca780a5b\",\"title\":\"Talk2Nav: Long-Range Vision-and-Language Navigation in Cities\",\"url\":\"https://www.semanticscholar.org/paper/392d258c7c49a8d22bd6b323b2fb67bbca780a5b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1908.06327\",\"authors\":[{\"authorId\":\"38727845\",\"name\":\"A. Burns\"},{\"authorId\":\"73441526\",\"name\":\"R. Tan\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"},{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"}],\"doi\":\"10.1109/ICCV.2019.00757\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"71634edd80ce000b3d1e462137fcfa8c2b377943\",\"title\":\"Language Features Matter: Effective Language Representations for Vision-Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/71634edd80ce000b3d1e462137fcfa8c2b377943\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144069314\",\"name\":\"Bin Jiang\"},{\"authorId\":\"47932618\",\"name\":\"X. Huang\"},{\"authorId\":\"143702931\",\"name\":\"C. Yang\"},{\"authorId\":\"48837492\",\"name\":\"J. Yuan\"}],\"doi\":\"10.1016/j.ipm.2019.102104\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bbc7306c513c42dff502dd0ce3850aab54096216\",\"title\":\"SLTFNet: A spatial and language-temporal tensor fusion network for video moment retrieval\",\"url\":\"https://www.semanticscholar.org/paper/bbc7306c513c42dff502dd0ce3850aab54096216\",\"venue\":\"Inf. Process. Manag.\",\"year\":2019},{\"arxivId\":\"1804.00100\",\"authors\":[{\"authorId\":null,\"name\":\"Jingwen Wang\"},{\"authorId\":\"2093119\",\"name\":\"W. Jiang\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"144391096\",\"name\":\"Yong Xu\"}],\"doi\":\"10.1109/CVPR.2018.00751\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bb4e2d6a6e3e1067f21a4cad087fc91c671e495d\",\"title\":\"Bidirectional Attentive Fusion with Context Gating for Dense Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/bb4e2d6a6e3e1067f21a4cad087fc91c671e495d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2008.01403\",\"authors\":[{\"authorId\":\"98579574\",\"name\":\"Daizong Liu\"},{\"authorId\":\"51912474\",\"name\":\"Xiaoye Qu\"},{\"authorId\":\"4029028\",\"name\":\"Xiao-Yang Liu\"},{\"authorId\":\"40240283\",\"name\":\"J. Dong\"},{\"authorId\":\"145232778\",\"name\":\"Pan Zhou\"},{\"authorId\":\"2956815\",\"name\":\"Zichuan Xu\"}],\"doi\":\"10.1145/3394171.3414026\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"2b632209923bfe3452ac19f23b46c70455fae465\",\"title\":\"Jointly Cross- and Self-Modal Graph Attention Network for Query-Based Moment Localization\",\"url\":\"https://www.semanticscholar.org/paper/2b632209923bfe3452ac19f23b46c70455fae465\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2101.00151\",\"authors\":[{\"authorId\":\"143725625\",\"name\":\"Hung Le\"},{\"authorId\":null,\"name\":\"Chinnadhurai Sankar\"},{\"authorId\":\"29072828\",\"name\":\"Seungwhan Moon\"},{\"authorId\":null,\"name\":\"Ahmad Beirami\"},{\"authorId\":null,\"name\":\"Alborz Geramifard\"},{\"authorId\":null,\"name\":\"Satwik Kottur\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3aa6afd427d08bf6000b4e4045cc0b0a66134fed\",\"title\":\"DVD: A Diagnostic Dataset for Multi-step Reasoning in Video Grounded Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/3aa6afd427d08bf6000b4e4045cc0b0a66134fed\",\"venue\":\"\",\"year\":2021},{\"arxivId\":\"1911.08199\",\"authors\":[{\"authorId\":\"49290494\",\"name\":\"Zhijie Lin\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"51305348\",\"name\":\"Zhu Zhang\"},{\"authorId\":\"50621207\",\"name\":\"Q. Wang\"},{\"authorId\":\"46936306\",\"name\":\"H. Liu\"}],\"doi\":\"10.1609/AAAI.V34I07.6820\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9388ec8a0de86969afce29947b8b80b5698e4a21\",\"title\":\"Weakly-Supervised Video Moment Retrieval via Semantic Completion Network\",\"url\":\"https://www.semanticscholar.org/paper/9388ec8a0de86969afce29947b8b80b5698e4a21\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1812.00087\",\"authors\":[{\"authorId\":\"145979995\",\"name\":\"D. Zhang\"},{\"authorId\":\"3386593\",\"name\":\"X. Dai\"},{\"authorId\":\"48631993\",\"name\":\"Xin Eric Wang\"},{\"authorId\":\"1706938\",\"name\":\"Y. Wang\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/CVPR.2019.00134\",\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"613f59279586bd53aed57bc133246a4eb3c38977\",\"title\":\"MAN: Moment Alignment Network for Natural Language Moment Retrieval via Iterative Graph Adjustment\",\"url\":\"https://www.semanticscholar.org/paper/613f59279586bd53aed57bc133246a4eb3c38977\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1904.09936\",\"authors\":[{\"authorId\":\"29132542\",\"name\":\"Meera Hahn\"},{\"authorId\":\"2293919\",\"name\":\"Asim Kadav\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"},{\"authorId\":\"1775043\",\"name\":\"H. Graf\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"1378f07a9229f09c7bf6c3be6ade4765403c0ca6\",\"title\":\"Tripping through time: Efficient Localization of Activities in Videos\",\"url\":\"https://www.semanticscholar.org/paper/1378f07a9229f09c7bf6c3be6ade4765403c0ca6\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2011.05049\",\"authors\":[{\"authorId\":\"2008154246\",\"name\":\"Zongheng Tang\"},{\"authorId\":\"47303356\",\"name\":\"Yue Liao\"},{\"authorId\":\"101219260\",\"name\":\"Si Liu\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"2103483\",\"name\":\"X. Jin\"},{\"authorId\":\"2292508\",\"name\":\"Hongxu Jiang\"},{\"authorId\":\"1410184682\",\"name\":\"Qian Yu\"},{\"authorId\":\"1510477221\",\"name\":\"Dong Xu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"74c30c601d5de21af098389abf7be0f8261e6c13\",\"title\":\"Human-centric Spatio-Temporal Video Grounding With Visual Transformers\",\"url\":\"https://www.semanticscholar.org/paper/74c30c601d5de21af098389abf7be0f8261e6c13\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.11071\",\"authors\":[{\"authorId\":\"2028596941\",\"name\":\"Andreea-Maria Oncescu\"},{\"authorId\":\"143848064\",\"name\":\"Jo\\u00e3o F. Henriques\"},{\"authorId\":\"1614034792\",\"name\":\"Yang Liu\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"},{\"authorId\":\"7641268\",\"name\":\"Samuel Albanie\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"6ee5d4a6ead378df9949daad5cf245c01563a3fa\",\"title\":\"QuerYD: A video dataset with high-quality textual and audio narrations\",\"url\":\"https://www.semanticscholar.org/paper/6ee5d4a6ead378df9949daad5cf245c01563a3fa\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.08845\",\"authors\":[{\"authorId\":\"145542498\",\"name\":\"Matthew Patrick\"}],\"doi\":\"10.1016/j.jss.2020.110652\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"27118e80abd9bcf9707d5dfd172abb3821ae1d6c\",\"title\":\"Exploring Software Reusability Metrics with Q&A Forum Data\",\"url\":\"https://www.semanticscholar.org/paper/27118e80abd9bcf9707d5dfd172abb3821ae1d6c\",\"venue\":\"J. Syst. Softw.\",\"year\":2020},{\"arxivId\":\"2003.05078\",\"authors\":[{\"authorId\":\"34280810\",\"name\":\"Gunnar A. Sigurdsson\"},{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"3208081\",\"name\":\"A. Nematzadeh\"},{\"authorId\":\"1466466597\",\"name\":\"Lucas Smaira\"},{\"authorId\":\"1471708751\",\"name\":\"M. Malinowski\"},{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"1685771\",\"name\":\"P. Blunsom\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/cvpr42600.2020.01086\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a1f1d17a350d30d55de52b15c9fe7fea4ba6ff13\",\"title\":\"Visual Grounding in Video for Unsupervised Word Translation\",\"url\":\"https://www.semanticscholar.org/paper/a1f1d17a350d30d55de52b15c9fe7fea4ba6ff13\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1907.12763\",\"authors\":[{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"150234800\",\"name\":\"Mattia Soldan\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"145160922\",\"name\":\"Bryan Russell\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e12a3e3f3f383f222b5d2007802d7b7944364301\",\"title\":\"Temporal Localization of Moments in Video Collections with Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/e12a3e3f3f383f222b5d2007802d7b7944364301\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145479818\",\"name\":\"D. Cao\"},{\"authorId\":\"1993664989\",\"name\":\"Yawen Zeng\"},{\"authorId\":\"7621447\",\"name\":\"X. Wei\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":\"48043335\",\"name\":\"R. Hong\"},{\"authorId\":\"145458349\",\"name\":\"Z. Qin\"}],\"doi\":\"10.1145/3394171.3413841\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7928ff4b66e866e7052915cd34861f1db2288cc4\",\"title\":\"Adversarial Video Moment Retrieval by Jointly Modeling Ranking and Localization\",\"url\":\"https://www.semanticscholar.org/paper/7928ff4b66e866e7052915cd34861f1db2288cc4\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1909.13784\",\"authors\":[{\"authorId\":\"73441526\",\"name\":\"R. Tan\"},{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"}],\"doi\":null,\"intent\":[\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"3c0d69d243c08eaa1d9030c95541a2ae23e8eb85\",\"title\":\"LoGAN: Latent Graph Co-Attention Network for Weakly-Supervised Video Moment Retrieval.\",\"url\":\"https://www.semanticscholar.org/paper/3c0d69d243c08eaa1d9030c95541a2ae23e8eb85\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1801.01582\",\"authors\":[{\"authorId\":\"2326243\",\"name\":\"Arun Balajee Vasudevan\"},{\"authorId\":\"1778526\",\"name\":\"Dengxin Dai\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2018.00434\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7a82d83f818cdc4ac714e468446bc2499ff9caa7\",\"title\":\"Object Referring in Videos with Language and Human Gaze\",\"url\":\"https://www.semanticscholar.org/paper/7a82d83f818cdc4ac714e468446bc2499ff9caa7\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1904.11574\",\"authors\":[{\"authorId\":\"46665218\",\"name\":\"Jie Lei\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/2020.acl-main.730\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb1b368ca847846774ee41af6da906ab77013313\",\"title\":\"TVQA+: Spatio-Temporal Grounding for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/eb1b368ca847846774ee41af6da906ab77013313\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"2007.14164\",\"authors\":[{\"authorId\":\"39650418\",\"name\":\"S. Chen\"},{\"authorId\":\"119897463\",\"name\":\"Wenhao Jiang\"},{\"authorId\":\"1654091065\",\"name\":\"Wei Liu\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1007/978-3-030-58548-8_20\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5fb52197928290d3020b2256ccab22d5bf93c366\",\"title\":\"Learning Modality Interaction for Temporal Sentence Localization and Event Captioning in Videos\",\"url\":\"https://www.semanticscholar.org/paper/5fb52197928290d3020b2256ccab22d5bf93c366\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2006.11747\",\"authors\":[{\"authorId\":\"1500408667\",\"name\":\"Zhiyuan Fang\"},{\"authorId\":\"34362536\",\"name\":\"S. Kong\"},{\"authorId\":\"1521319166\",\"name\":\"Zhe Wang\"},{\"authorId\":\"143800213\",\"name\":\"Charless C. Fowlkes\"},{\"authorId\":\"1784500\",\"name\":\"Yezhou Yang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a792ff56eeed530fab1935168510cbb16b0f1b68\",\"title\":\"Weak Supervision and Referring Attention for Temporal-Textual Association Learning\",\"url\":\"https://www.semanticscholar.org/paper/a792ff56eeed530fab1935168510cbb16b0f1b68\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1905.13540\",\"authors\":[{\"authorId\":\"2447631\",\"name\":\"Junyeong Kim\"},{\"authorId\":\"103278467\",\"name\":\"Minuk Ma\"},{\"authorId\":\"3549056\",\"name\":\"K. Kim\"},{\"authorId\":\"72108920\",\"name\":\"S. Kim\"},{\"authorId\":\"145954697\",\"name\":\"C. Yoo\"}],\"doi\":\"10.1109/IJCNN.2019.8852087\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1165b090e5ec6a9311ecba5be4f6aac0a1a4586b\",\"title\":\"Gaining Extra Supervision via Multi-task learning for Multi-Modal Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1165b090e5ec6a9311ecba5be4f6aac0a1a4586b\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50117915\",\"name\":\"Y. Wu\"},{\"authorId\":\"37108050\",\"name\":\"S. Drucker\"},{\"authorId\":\"3041721\",\"name\":\"M. Philipose\"},{\"authorId\":\"40125198\",\"name\":\"L. Ravindranath\"}],\"doi\":\"10.1145/3209900.3209909\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8494ea1faf92982a2c6bf07674eeb6201a13b70d\",\"title\":\"Querying Videos Using DNN Generated Labels\",\"url\":\"https://www.semanticscholar.org/paper/8494ea1faf92982a2c6bf07674eeb6201a13b70d\",\"venue\":\"HILDA@SIGMOD\",\"year\":2018},{\"arxivId\":\"1908.08527\",\"authors\":[{\"authorId\":\"1911972\",\"name\":\"Tanmay Gupta\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"2433269\",\"name\":\"Derek Hoiem\"}],\"doi\":\"10.1109/ICCV.2019.00752\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ae1764ffaa2fe68dafe33664624be38273c4ccef\",\"title\":\"ViCo: Word Embeddings From Visual Co-Occurrences\",\"url\":\"https://www.semanticscholar.org/paper/ae1764ffaa2fe68dafe33664624be38273c4ccef\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145479818\",\"name\":\"D. Cao\"},{\"authorId\":\"1993664989\",\"name\":\"Yawen Zeng\"},{\"authorId\":\"38813990\",\"name\":\"M. Liu\"},{\"authorId\":\"7792071\",\"name\":\"X. He\"},{\"authorId\":\"5332711\",\"name\":\"Meng Wang\"},{\"authorId\":\"145458349\",\"name\":\"Z. Qin\"}],\"doi\":\"10.1145/3394171.3413840\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3e7c91fb6f79dce1ab3e4be0efc97b8592ce7d96\",\"title\":\"STRONG: Spatio-Temporal Reinforcement Learning for Cross-Modal Video Moment Localization\",\"url\":\"https://www.semanticscholar.org/paper/3e7c91fb6f79dce1ab3e4be0efc97b8592ce7d96\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1803.08006\",\"authors\":[{\"authorId\":\"145327993\",\"name\":\"A. Khoreva\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1007/978-3-030-20870-7_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"da30d00c9490768e7726725482e3ecbd102f18cd\",\"title\":\"Video Object Segmentation with Language Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/da30d00c9490768e7726725482e3ecbd102f18cd\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"1809.01337\",\"authors\":[{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"39231399\",\"name\":\"O. Wang\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"145160921\",\"name\":\"Bryan C. Russell\"}],\"doi\":\"10.18653/v1/D18-1168\",\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"0b1ff82db09672656157874718860bee942483cf\",\"title\":\"Localizing Moments in Video with Temporal Language\",\"url\":\"https://www.semanticscholar.org/paper/0b1ff82db09672656157874718860bee942483cf\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"2008.08257\",\"authors\":[{\"authorId\":\"51305348\",\"name\":\"Zhu Zhang\"},{\"authorId\":\"49290494\",\"name\":\"Zhijie Lin\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"1877867\",\"name\":\"J. Zhu\"},{\"authorId\":\"1996703\",\"name\":\"X. He\"}],\"doi\":\"10.1145/3394171.3413967\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"02e5188e19523140b82d05f00bee10933ccc3b50\",\"title\":\"Regularized Two-Branch Proposal Networks for Weakly-Supervised Moment Retrieval in Videos\",\"url\":\"https://www.semanticscholar.org/paper/02e5188e19523140b82d05f00bee10933ccc3b50\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Charades-STA\"},{\"authorId\":null,\"name\":\"ActivityNet\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a2ad7a90e589ae7dd33185edba10498c78da9f3c\",\"title\":\"Uncovering Hidden Challenges in Query-Based Video Moment Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/a2ad7a90e589ae7dd33185edba10498c78da9f3c\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"73441526\",\"name\":\"R. Tan\"},{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"23fb5231bb8629bec8b7bfc15cccefca2cbd1754\",\"title\":\"wMAN: Weakly-supervised Moment Alignment Network for Text-based Video Segment Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/23fb5231bb8629bec8b7bfc15cccefca2cbd1754\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1906.03327\",\"authors\":[{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"35838466\",\"name\":\"D. Zhukov\"},{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"}],\"doi\":\"10.1109/ICCV.2019.00272\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"9311779489e597315488749ee6c386bfa3f3512e\",\"title\":\"HowTo100M: Learning a Text-Video Embedding by Watching Hundred Million Narrated Video Clips\",\"url\":\"https://www.semanticscholar.org/paper/9311779489e597315488749ee6c386bfa3f3512e\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2008.09837\",\"authors\":[{\"authorId\":\"46554630\",\"name\":\"L. Yang\"},{\"authorId\":\"2484788\",\"name\":\"Houwen Peng\"},{\"authorId\":\"39901030\",\"name\":\"Dingwen Zhang\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"122200133\",\"name\":\"J. Han\"}],\"doi\":\"10.1109/TIP.2020.3016486\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"086057656b94de8bfd0d50ebe935e3d433f593d3\",\"title\":\"Revisiting Anchor Mechanisms for Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/086057656b94de8bfd0d50ebe935e3d433f593d3\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"2001.06680\",\"authors\":[{\"authorId\":\"71170299\",\"name\":\"J. Wu\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"101219260\",\"name\":\"Si Liu\"},{\"authorId\":\"49478124\",\"name\":\"L. Lin\"}],\"doi\":\"10.1609/AAAI.V34I07.6924\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b8e744b1f33b1f3f53fcffb1dafd592e992694ff\",\"title\":\"Tree-Structured Policy based Progressive Reinforcement Learning for Temporally Language Grounding in Video\",\"url\":\"https://www.semanticscholar.org/paper/b8e744b1f33b1f3f53fcffb1dafd592e992694ff\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30793303\",\"name\":\"Amirhoshang Hoseinpour Dehkordi\"},{\"authorId\":\"153235768\",\"name\":\"M. Alizadeh\"},{\"authorId\":\"2005221955\",\"name\":\"Ali Movaghar\"}],\"doi\":\"10.36227/techrxiv.12928544.v1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b678835c5de86ebe2031da902957aead8de931aa\",\"title\":\"Linear Temporal Public Announcement Logic: a new perspective for reasoning the knowledge of multi-classifiers\",\"url\":\"https://www.semanticscholar.org/paper/b678835c5de86ebe2031da902957aead8de931aa\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2008.00744\",\"authors\":[{\"authorId\":\"7641268\",\"name\":\"Samuel Albanie\"},{\"authorId\":\"1614038854\",\"name\":\"Yang Liu\"},{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"47107270\",\"name\":\"E. Coto\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"},{\"authorId\":\"151352107\",\"name\":\"Valentin Gabeur\"},{\"authorId\":\"1612977414\",\"name\":\"Chen Sun\"},{\"authorId\":\"72492981\",\"name\":\"Alahari Karteek\"},{\"authorId\":\"153433844\",\"name\":\"C. Schmid\"},{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"50976845\",\"name\":\"Yida Zhao\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"},{\"authorId\":\"1389284356\",\"name\":\"Kaixu Cui\"},{\"authorId\":\"87652983\",\"name\":\"H. Liu\"},{\"authorId\":\"1808091339\",\"name\":\"Chen Wang\"},{\"authorId\":\"3040310\",\"name\":\"Y. Jiang\"},{\"authorId\":\"145912650\",\"name\":\"X. Hao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2921b34b99c6150a7625acdbdd99504c2789f7a2\",\"title\":\"The End-of-End-to-End: A Video Understanding Pentathlon Challenge (2020)\",\"url\":\"https://www.semanticscholar.org/paper/2921b34b99c6150a7625acdbdd99504c2789f7a2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47740660\",\"name\":\"Jingyuan Chen\"},{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"3179887\",\"name\":\"Xinpeng Chen\"},{\"authorId\":\"2750647\",\"name\":\"Zequn Jie\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"631d21ee2e0de4227be1dfe000006acf1e0fe783\",\"title\":\"Sentence Encoder Video Encoder Frame-Specific Sentence Representation Cross Gating Matching Aggregation Self Interactor Segment Localizer Cross Modal\",\"url\":\"https://www.semanticscholar.org/paper/631d21ee2e0de4227be1dfe000006acf1e0fe783\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"50976845\",\"name\":\"Yida Zhao\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cc57062ad3e622f5ab074a283afcfea745a2d6cc\",\"title\":\"Team RUC AI\\u00b7M: Technical Report in Video Pentathlon Challenge 2020\",\"url\":\"https://www.semanticscholar.org/paper/cc57062ad3e622f5ab074a283afcfea745a2d6cc\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1910.14303\",\"authors\":[{\"authorId\":\"48009996\",\"name\":\"Yitian Yuan\"},{\"authorId\":\"152309770\",\"name\":\"Lin Ma\"},{\"authorId\":\"46584062\",\"name\":\"Junling Wang\"},{\"authorId\":\"1743698\",\"name\":\"Wenyu Liu\"},{\"authorId\":\"145583985\",\"name\":\"Wenwu Zhu\"}],\"doi\":\"10.1109/tpami.2020.3038993\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"613634071acd170fe5c20600f8d49662a8c3b23f\",\"title\":\"Semantic Conditioned Dynamic Modulation for Temporal Sentence Grounding in Videos\",\"url\":\"https://www.semanticscholar.org/paper/613634071acd170fe5c20600f8d49662a8c3b23f\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1808.05326\",\"authors\":[{\"authorId\":\"2545335\",\"name\":\"Rowan Zellers\"},{\"authorId\":\"3312309\",\"name\":\"Yonatan Bisk\"},{\"authorId\":\"4671928\",\"name\":\"Roy Schwartz\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":\"10.18653/v1/D18-1009\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"af5c4b80fbf847f69a202ba5a780a3dd18c1a027\",\"title\":\"SWAG: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference\",\"url\":\"https://www.semanticscholar.org/paper/af5c4b80fbf847f69a202ba5a780a3dd18c1a027\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153228843\",\"name\":\"Chujie Lu\"},{\"authorId\":\"143891667\",\"name\":\"Long Chen\"},{\"authorId\":\"71208047\",\"name\":\"C. Tan\"},{\"authorId\":\"47056890\",\"name\":\"Xiao-Lin Li\"},{\"authorId\":\"1384523745\",\"name\":\"Jun Xiao\"}],\"doi\":\"10.18653/v1/D19-1518\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"872091517b0bfad0e9bc1826d4668022d1d57953\",\"title\":\"DEBUG: A Dense Bottom-Up Grounding Approach for Natural Language Video Localization\",\"url\":\"https://www.semanticscholar.org/paper/872091517b0bfad0e9bc1826d4668022d1d57953\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"2008.06941\",\"authors\":[{\"authorId\":\"47294375\",\"name\":\"Zhu Zhang\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"49290494\",\"name\":\"Zhijie Lin\"},{\"authorId\":\"2422046\",\"name\":\"Baoxing Huai\"},{\"authorId\":\"145078771\",\"name\":\"J. Yuan\"}],\"doi\":\"10.24963/ijcai.2020/149\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2086bd08d3921bc1e83fdad306ec0c5ac3b43428\",\"title\":\"Object-Aware Multi-Branch Relation Networks for Spatio-Temporal Video Grounding\",\"url\":\"https://www.semanticscholar.org/paper/2086bd08d3921bc1e83fdad306ec0c5ac3b43428\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":\"1904.03282\",\"authors\":[{\"authorId\":\"47733442\",\"name\":\"Niluthpol Chowdhury Mithun\"},{\"authorId\":\"49616225\",\"name\":\"Sujoy Paul\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":\"10.1109/CVPR.2019.01186\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ca4d965ab8fd07fd236a2ec5b5c7a520077a3085\",\"title\":\"Weakly Supervised Video Moment Retrieval From Text Queries\",\"url\":\"https://www.semanticscholar.org/paper/ca4d965ab8fd07fd236a2ec5b5c7a520077a3085\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1912.03590\",\"authors\":[{\"authorId\":\"3178508\",\"name\":\"Songyang Zhang\"},{\"authorId\":\"2484788\",\"name\":\"Houwen Peng\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1609/AAAI.V34I07.6984\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cef4a58c08816c3d3bd56826a418508720d4b20d\",\"title\":\"Learning 2D Temporal Adjacent Networks for Moment Localization with Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/cef4a58c08816c3d3bd56826a418508720d4b20d\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33685943\",\"name\":\"Mayoore S. Jaiswal\"},{\"authorId\":\"144222336\",\"name\":\"H. P. Hofstee\"},{\"authorId\":\"15110752\",\"name\":\"V. Chen\"},{\"authorId\":\"21080039\",\"name\":\"Suvadip Paul\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"153035546\",\"name\":\"F. Liu\"},{\"authorId\":\"2055404\",\"name\":\"A. Jagannathan\"},{\"authorId\":\"32272278\",\"name\":\"A. Gattiker\"},{\"authorId\":\"152565412\",\"name\":\"Inseok Hwang\"},{\"authorId\":\"48052648\",\"name\":\"J. Lee\"},{\"authorId\":\"11398739\",\"name\":\"M. Tong\"},{\"authorId\":\"1382198044\",\"name\":\"Sahil Dureja\"},{\"authorId\":\"4353428\",\"name\":\"Soham Shah\"}],\"doi\":\"10.1109/ICCVW.2019.00188\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8873d1369590249113e1f0491ce49d1502395b9c\",\"title\":\"Video-Text Compliance: Activity Verification Based on Natural Language Instructions\",\"url\":\"https://www.semanticscholar.org/paper/8873d1369590249113e1f0491ce49d1502395b9c\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3178508\",\"name\":\"Songyang Zhang\"},{\"authorId\":\"34739384\",\"name\":\"Jinsong Su\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"2f84c74b0c1b66420d06ad07f8a6b58fbf215ff6\",\"title\":\"Video Tree Attention Network Phrase Embedding ds Query Phrase Embedding dc Phrase Embedding dm Sentence Embedding hroot Temporal Localization Module Temporal Relationship Module + Matching\",\"url\":\"https://www.semanticscholar.org/paper/2f84c74b0c1b66420d06ad07f8a6b58fbf215ff6\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1903.02930\",\"authors\":[{\"authorId\":\"49513989\",\"name\":\"Antonios Anastasopoulos\"},{\"authorId\":\"9567965\",\"name\":\"Shankar Kumar\"},{\"authorId\":\"39977619\",\"name\":\"H. Liao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4791dc0c4519988536e4846cbb24ae6382b8fdfd\",\"title\":\"Neural Language Modeling with Visual Features\",\"url\":\"https://www.semanticscholar.org/paper/4791dc0c4519988536e4846cbb24ae6382b8fdfd\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1809.01696\",\"authors\":[{\"authorId\":\"46665218\",\"name\":\"Jie Lei\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.18653/v1/D18-1167\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e7e1313061b0d56364bd2c41f017deb954bb05db\",\"title\":\"TVQA: Localized, Compositional Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e7e1313061b0d56364bd2c41f017deb954bb05db\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"1901.06829\",\"authors\":[{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"1749527\",\"name\":\"Xiang Zhao\"},{\"authorId\":\"2864855\",\"name\":\"Jizhou Huang\"},{\"authorId\":\"50984378\",\"name\":\"F. Li\"},{\"authorId\":\"48033101\",\"name\":\"Xiao Liu\"},{\"authorId\":\"35247507\",\"name\":\"Shilei Wen\"}],\"doi\":\"10.1609/aaai.v33i01.33018393\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"6fd7e8aa1a031923e3580752e4ab9163e45fe41c\",\"title\":\"Read, Watch, and Move: Reinforcement Learning for Temporally Grounding Natural Language Descriptions in Videos\",\"url\":\"https://www.semanticscholar.org/paper/6fd7e8aa1a031923e3580752e4ab9163e45fe41c\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"2003.07048\",\"authors\":[{\"authorId\":\"2250163\",\"name\":\"Yijun Song\"},{\"authorId\":\"46584062\",\"name\":\"Junling Wang\"},{\"authorId\":\"152309770\",\"name\":\"Lin Ma\"},{\"authorId\":\"1564034697\",\"name\":\"Zhou Yu\"},{\"authorId\":null,\"name\":\"Jun Yu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e655c524630b0fb37f11b01468dab5477c58db0f\",\"title\":\"Weakly-Supervised Multi-Level Attentional Reconstruction Network for Grounding Textual Queries in Videos\",\"url\":\"https://www.semanticscholar.org/paper/e655c524630b0fb37f11b01468dab5477c58db0f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.10434\",\"authors\":[{\"authorId\":\"49687714\",\"name\":\"Haoyu Tang\"},{\"authorId\":\"2237811\",\"name\":\"Jihua Zhu\"},{\"authorId\":\"38813990\",\"name\":\"M. Liu\"},{\"authorId\":\"40465774\",\"name\":\"Z. Gao\"},{\"authorId\":\"46504200\",\"name\":\"Zhiyong Cheng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d1d28e778c391d07a6c3e7a2e96312fdc53c0ae2\",\"title\":\"Frame-wise Cross-modal Match for Video Moment Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/d1d28e778c391d07a6c3e7a2e96312fdc53c0ae2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153154393\",\"name\":\"J. Li\"},{\"authorId\":\"3085483\",\"name\":\"S. Xia\"},{\"authorId\":\"153641684\",\"name\":\"Q. Ding\"}],\"doi\":\"10.1145/3372278.3390702\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"98b1c9c1dfe23cf5478f7ff45c641a5576b66107\",\"title\":\"Multi-level Recognition on Falls from Activities of Daily Living\",\"url\":\"https://www.semanticscholar.org/paper/98b1c9c1dfe23cf5478f7ff45c641a5576b66107\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"dd7062e6f84750688fa96143209efc801e91f9bd\",\"title\":\"Visual Understanding through Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/dd7062e6f84750688fa96143209efc801e91f9bd\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2007.09877\",\"authors\":[{\"authorId\":\"152641281\",\"name\":\"Y. Zhou\"},{\"authorId\":\"7271879\",\"name\":\"M. Wang\"},{\"authorId\":\"121357290\",\"name\":\"Ruolin Wang\"},{\"authorId\":\"19216752\",\"name\":\"Shuwei Huo\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5d5710aa2ec37b641754c1268a35028f6fe1341a\",\"title\":\"Graph Neural Network for Video-Query based Video Moment Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/5d5710aa2ec37b641754c1268a35028f6fe1341a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390538450\",\"name\":\"Xun Yang\"},{\"authorId\":\"49544292\",\"name\":\"Xueliang Liu\"},{\"authorId\":\"2980051\",\"name\":\"Meng Jian\"},{\"authorId\":\"1993659018\",\"name\":\"Xinjian Gao\"},{\"authorId\":\"152808542\",\"name\":\"Meng Wang\"}],\"doi\":\"10.1145/3394171.3413610\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b839e6b1f65672d154feb6f6668d64a2333c71ee\",\"title\":\"Weakly-Supervised Video Object Grounding by Exploring Spatio-Temporal Contexts\",\"url\":\"https://www.semanticscholar.org/paper/b839e6b1f65672d154feb6f6668d64a2333c71ee\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"90191889\",\"name\":\"A. Ghodrati\"},{\"authorId\":\"3245057\",\"name\":\"Zhenyang Li\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"27280d900be88e6b613bc1da4be386bb8b2b1490\",\"title\":\"UvA-DARE ( Digital Academic Repository ) Actor and Action Video Segmentation From a\",\"url\":\"https://www.semanticscholar.org/paper/27280d900be88e6b613bc1da4be386bb8b2b1490\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144230956\",\"name\":\"Bo Huang\"},{\"authorId\":\"144645740\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1736727\",\"name\":\"Kai Yu\"}],\"doi\":\"10.1145/3301506.3301538\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"befc8b8ee539df950bbbab06d09c89d5b83eaa34\",\"title\":\"MLN: Moment localization Network and Samples Selection for Moment Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/befc8b8ee539df950bbbab06d09c89d5b83eaa34\",\"venue\":\"ICVIP\",\"year\":2018},{\"arxivId\":\"2011.10830\",\"authors\":[{\"authorId\":\"97375393\",\"name\":\"Mengmeng Xu\"},{\"authorId\":\"1397974082\",\"name\":\"Juan-Manuel Perez-Rua\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"145944235\",\"name\":\"B. Mart\\u00ednez\"},{\"authorId\":\"2171228\",\"name\":\"Xiatian Zhu\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"145406420\",\"name\":\"Tao Xiang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"cdc28eb98cd4e5fa28811f4ea6dbe7c64d5fcffe\",\"title\":\"Boundary-sensitive Pre-training for Temporal Localization in Videos\",\"url\":\"https://www.semanticscholar.org/paper/cdc28eb98cd4e5fa28811f4ea6dbe7c64d5fcffe\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1904.03493\",\"authors\":[{\"authorId\":\"48631993\",\"name\":\"Xin Eric Wang\"},{\"authorId\":\"46365930\",\"name\":\"Jiawei Wu\"},{\"authorId\":\"47739808\",\"name\":\"Junkun Chen\"},{\"authorId\":\"46255707\",\"name\":\"Lei Li\"},{\"authorId\":\"1706938\",\"name\":\"Y. Wang\"},{\"authorId\":\"1682479\",\"name\":\"William Yang Wang\"}],\"doi\":\"10.1109/ICCV.2019.00468\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"28b74bb7c8b08cceb2430ec2d54dfa0f3225d796\",\"title\":\"VaTeX: A Large-Scale, High-Quality Multilingual Dataset for Video-and-Language Research\",\"url\":\"https://www.semanticscholar.org/paper/28b74bb7c8b08cceb2430ec2d54dfa0f3225d796\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1808.01575\",\"authors\":[{\"authorId\":\"144599697\",\"name\":\"Y. Feng\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"38144094\",\"name\":\"T. Zhang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1007/978-3-030-01264-9_4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8619ce85b69e6164cb5bb32f225e510a0570bb37\",\"title\":\"Video Re-localization\",\"url\":\"https://www.semanticscholar.org/paper/8619ce85b69e6164cb5bb32f225e510a0570bb37\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2005.00200\",\"authors\":[{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"2378902\",\"name\":\"Yen-Chun Chen\"},{\"authorId\":\"1664725279\",\"name\":\"Yu Cheng\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1520007550\",\"name\":\"Jingjing Liu\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.161\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6961065a16f6c3db4879cfad5875d11ce75e6b2f\",\"title\":\"HERO: Hierarchical Encoder for Video+Language Omni-representation Pre-training\",\"url\":\"https://www.semanticscholar.org/paper/6961065a16f6c3db4879cfad5875d11ce75e6b2f\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"1804.05113\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"145905328\",\"name\":\"Kun He\"},{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1609/AAAI.V33I01.33019062\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"83b2a55aecd5f917dbedbc0c5ef3ff3b61013958\",\"title\":\"Multilevel Language and Vision Integration for Text-to-Clip Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/83b2a55aecd5f917dbedbc0c5ef3ff3b61013958\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1906.05226\",\"authors\":[{\"authorId\":\"10721120\",\"name\":\"Ramakanth Pasunuru\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/P19-1185\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2ef851a47fc32d596883e08a5f655179b8c5b02d\",\"title\":\"Continual and Multi-Task Architecture Search\",\"url\":\"https://www.semanticscholar.org/paper/2ef851a47fc32d596883e08a5f655179b8c5b02d\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48677815\",\"name\":\"Xinyan Yu\"},{\"authorId\":\"49890039\",\"name\":\"Y. Zhang\"},{\"authorId\":\"143758471\",\"name\":\"Rui Zhang\"}],\"doi\":\"10.1007/978-3-030-30671-7_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"62afe2605541f485bbd2bfe89b41161ce08a5977\",\"title\":\"Cross-Modality Video Segment Retrieval with Ensemble Learning\",\"url\":\"https://www.semanticscholar.org/paper/62afe2605541f485bbd2bfe89b41161ce08a5977\",\"venue\":\"Domain Adaptation for Visual Understanding\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48016309\",\"name\":\"H. Wang\"},{\"authorId\":\"145102437\",\"name\":\"Cheng Deng\"},{\"authorId\":\"3063894\",\"name\":\"Junchi Yan\"},{\"authorId\":\"145047838\",\"name\":\"Dacheng Tao\"}],\"doi\":\"10.1109/ICCV.2019.00404\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"05fc2ab1eb39f8f4d0f30dda1a2838c8125bff1b\",\"title\":\"Asymmetric Cross-Guided Attention Network for Actor and Action Video Segmentation From Natural Language Query\",\"url\":\"https://www.semanticscholar.org/paper/05fc2ab1eb39f8f4d0f30dda1a2838c8125bff1b\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"}],\"doi\":\"10.1109/CVPRW.2019.00351\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"702111d5821ac1962ca7f4c4e3c4ed6a0887b093\",\"title\":\"Leveraging the Present to Anticipate the Future in Videos\",\"url\":\"https://www.semanticscholar.org/paper/702111d5821ac1962ca7f4c4e3c4ed6a0887b093\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":\"1904.03885\",\"authors\":[{\"authorId\":\"2862582\",\"name\":\"Peratham Wiriyathammabhum\"},{\"authorId\":null,\"name\":\"Abhinav Shrivastava\"},{\"authorId\":\"2852035\",\"name\":\"V. Morariu\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.18653/v1/W19-1802\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e164e75632e23a7fba6a46d2ee2dc328720601af\",\"title\":\"Referring to Objects in Videos using Spatio-Temporal Identifying Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/e164e75632e23a7fba6a46d2ee2dc328720601af\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1811.10830\",\"authors\":[{\"authorId\":\"2545335\",\"name\":\"Rowan Zellers\"},{\"authorId\":\"3312309\",\"name\":\"Yonatan Bisk\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":\"10.1109/CVPR.2019.00688\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6dfc2ff03534a4325d06c6f88c3144831996629b\",\"title\":\"From Recognition to Cognition: Visual Commonsense Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/6dfc2ff03534a4325d06c6f88c3144831996629b\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2001.09099\",\"authors\":[{\"authorId\":\"46665218\",\"name\":\"Jie Lei\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"143977266\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.1007/978-3-030-58589-1_27\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"37dd9c725cb800fd5f336a5227f02c160b8723cb\",\"title\":\"TVR: A Large-Scale Dataset for Video-Subtitle Moment Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/37dd9c725cb800fd5f336a5227f02c160b8723cb\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39650418\",\"name\":\"S. Chen\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1007/978-3-030-58565-5_36\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"853069fa3f976fe368858ce4650b6348a17a3764\",\"title\":\"Hierarchical Visual-Textual Graph for Temporal Activity Localization via Language\",\"url\":\"https://www.semanticscholar.org/paper/853069fa3f976fe368858ce4650b6348a17a3764\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1905.03922\",\"authors\":[{\"authorId\":\"144599697\",\"name\":\"Y. Feng\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"144416719\",\"name\":\"W. Liu\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2019.00138\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c19659297ac67a29d7524fba60062558f2235f8a\",\"title\":\"Spatio-Temporal Video Re-Localization by Warp LSTM\",\"url\":\"https://www.semanticscholar.org/paper/c19659297ac67a29d7524fba60062558f2235f8a\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2010.06260\",\"authors\":[{\"authorId\":\"145112187\",\"name\":\"Cristian Rodriguez-Opazo\"},{\"authorId\":\"1389646918\",\"name\":\"Edison Marrese-Taylor\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"71200893\",\"name\":\"H. Li\"},{\"authorId\":\"143685465\",\"name\":\"S. Gould\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a7177ae93ed91f3bf34875205396ec97f0873bb7\",\"title\":\"DORi: Discovering Object Relationship for Moment Localization of a Natural-Language Query in Video\",\"url\":\"https://www.semanticscholar.org/paper/a7177ae93ed91f3bf34875205396ec97f0873bb7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47740660\",\"name\":\"Jingyuan Chen\"},{\"authorId\":\"3179887\",\"name\":\"Xinpeng Chen\"},{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"2750647\",\"name\":\"Zequn Jie\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.18653/v1/D18-1015\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"452aca244ef62a533d8b46a54c6212fe9fa3ce9a\",\"title\":\"Temporally Grounding Natural Sentence in Video\",\"url\":\"https://www.semanticscholar.org/paper/452aca244ef62a533d8b46a54c6212fe9fa3ce9a\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"2008.08716\",\"authors\":[{\"authorId\":\"152666334\",\"name\":\"Sudipta Paul\"},{\"authorId\":\"47733442\",\"name\":\"Niluthpol Chowdhury Mithun\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2efdeaa68e94eeef2831536cdd53f3e3868bbdca\",\"title\":\"Text-based Localization of Moments in a Video Corpus\",\"url\":\"https://www.semanticscholar.org/paper/2efdeaa68e94eeef2831536cdd53f3e3868bbdca\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"145905328\",\"name\":\"Kun He\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a50d2245d46ce0595ddbf25ae9acb8513aa70067\",\"title\":\"Text-to-Clip Video Retrieval with Early Fusion and Re-Captioning\",\"url\":\"https://www.semanticscholar.org/paper/a50d2245d46ce0595ddbf25ae9acb8513aa70067\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49336560\",\"name\":\"Weining Wang\"},{\"authorId\":\"144368926\",\"name\":\"Yan Huang\"},{\"authorId\":\"123865558\",\"name\":\"Liang Wang\"}],\"doi\":\"10.1109/CVPR.2019.00042\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0fa68cde4db12779adacb70a24961cf09b1adf73\",\"title\":\"Language-Driven Temporal Activity Localization: A Semantic Matching Reinforcement Learning Model\",\"url\":\"https://www.semanticscholar.org/paper/0fa68cde4db12779adacb70a24961cf09b1adf73\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1803.10906\",\"authors\":[{\"authorId\":\"3029956\",\"name\":\"J. Gao\"},{\"authorId\":\"40899706\",\"name\":\"Runzhou Ge\"},{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/CVPR.2018.00688\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f45c3a83e5c6276c6655c5df5833ab6b75e17bdf\",\"title\":\"Motion-Appearance Co-memory Networks for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f45c3a83e5c6276c6655c5df5833ab6b75e17bdf\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39650418\",\"name\":\"S. Chen\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1609/AAAI.V33I01.33018199\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8548d5a93869a5a4c808f5e81742f59f848c718c\",\"title\":\"Semantic Proposal for Activity Localization in Videos via Sentence Query\",\"url\":\"https://www.semanticscholar.org/paper/8548d5a93869a5a4c808f5e81742f59f848c718c\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"2010.07999\",\"authors\":[{\"authorId\":\"46665218\",\"name\":\"Jie Lei\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"143977266\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.706\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"9f2a7a912624d850cf9e0587263b4fcd88d44f18\",\"title\":\"What is More Likely to Happen Next? Video-and-Language Future Event Prediction\",\"url\":\"https://www.semanticscholar.org/paper/9f2a7a912624d850cf9e0587263b4fcd88d44f18\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2004.02707\",\"authors\":[{\"authorId\":\"1612421029\",\"name\":\"Yicong Hong\"},{\"authorId\":\"145112187\",\"name\":\"Cristian Rodriguez-Opazo\"},{\"authorId\":\"1509240145\",\"name\":\"Qi Wu\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.271\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c71cf890f1e6169c28407a985dcfd2b0b156d9e2\",\"title\":\"Sub-Instruction Aware Vision-and-Language Navigation\",\"url\":\"https://www.semanticscholar.org/paper/c71cf890f1e6169c28407a985dcfd2b0b156d9e2\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2326243\",\"name\":\"Arun Balajee Vasudevan\"},{\"authorId\":\"1778526\",\"name\":\"Dengxin Dai\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.3929/ETHZ-B-000438408\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"53e77b526587b3c3bf7bb359590692a081b53260\",\"title\":\"Talk2Nav: Long-Range Vision-and-Language Navigation with Dual Attention and Spatial Memory\",\"url\":\"https://www.semanticscholar.org/paper/53e77b526587b3c3bf7bb359590692a081b53260\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2004.13217\",\"authors\":[{\"authorId\":\"34871664\",\"name\":\"R. Cruz\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"145185576\",\"name\":\"Dylan Campbell\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1109/CVPRW50498.2020.00192\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"537b0899452b3ed09a2945cdd5f3d42383611fac\",\"title\":\"Inferring Temporal Compositions of Actions Using Probabilistic Automata\",\"url\":\"https://www.semanticscholar.org/paper/537b0899452b3ed09a2945cdd5f3d42383611fac\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"2008.10238\",\"authors\":[{\"authorId\":\"103278467\",\"name\":\"Minuk Ma\"},{\"authorId\":\"30559382\",\"name\":\"S. Yoon\"},{\"authorId\":\"2447631\",\"name\":\"Junyeong Kim\"},{\"authorId\":\"1753686270\",\"name\":\"Young-Joon Lee\"},{\"authorId\":\"3315036\",\"name\":\"S. Kang\"},{\"authorId\":\"145954697\",\"name\":\"C. Yoo\"}],\"doi\":\"10.1007/978-3-030-58604-1_10\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"425278984b2be6b5412e264c7a200b797018ae8f\",\"title\":\"VLANet: Video-Language Alignment Network for Weakly-Supervised Video Moment Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/425278984b2be6b5412e264c7a200b797018ae8f\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2862582\",\"name\":\"Peratham Wiriyathammabhum\"},{\"authorId\":null,\"name\":\"Abhinav Shrivastava\"},{\"authorId\":\"2852035\",\"name\":\"V. Morariu\"},{\"authorId\":\"145855898\",\"name\":\"L. Davis\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ef6dbe27031265a4663721883008f4c3e6a89c4e\",\"title\":\"Supplementary Material : Referring to Object in Video using Spatio-Temporal Identifying Description\",\"url\":\"https://www.semanticscholar.org/paper/ef6dbe27031265a4663721883008f4c3e6a89c4e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2001.09308\",\"authors\":[{\"authorId\":\"26907392\",\"name\":\"Zhenfang Chen\"},{\"authorId\":\"152309767\",\"name\":\"L. Ma\"},{\"authorId\":\"145909988\",\"name\":\"Wenhan Luo\"},{\"authorId\":\"144963373\",\"name\":\"Peng Tang\"},{\"authorId\":\"1698116\",\"name\":\"K. Wong\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"02c9abd1c4567ba82289b1a989a51243087c6521\",\"title\":\"Look Closer to Ground Better: Weakly-Supervised Temporal Grounding of Sentence in Video\",\"url\":\"https://www.semanticscholar.org/paper/02c9abd1c4567ba82289b1a989a51243087c6521\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49290494\",\"name\":\"Zhijie Lin\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"1742291\",\"name\":\"Zixing Zhang\"},{\"authorId\":\"48805561\",\"name\":\"Zijian Zhang\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"}],\"doi\":\"10.1109/TIP.2020.2965987\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5a68ef4d0c1a814dd0920f6824aaad8e15339f66\",\"title\":\"Moment Retrieval via Cross-Modal Interaction Networks With Query Reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/5a68ef4d0c1a814dd0920f6824aaad8e15339f66\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1908.03846\",\"authors\":[{\"authorId\":\"3178508\",\"name\":\"Songyang Zhang\"},{\"authorId\":\"34739384\",\"name\":\"Jinsong Su\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1145/3343031.3350879\",\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"21ad966d7cc9812e2e96f37a577456947e5b694e\",\"title\":\"Exploiting Temporal Relationships in Video Moment Localization with Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/21ad966d7cc9812e2e96f37a577456947e5b694e\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Zhiyuan Fang\"},{\"authorId\":\"34362536\",\"name\":\"S. Kong\"},{\"authorId\":\"143800213\",\"name\":\"Charless C. Fowlkes\"},{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"50e9aabc46ea2d1ee80aacfcade14746776a6761\",\"title\":\"Woman BrownPerson BluePerson Boy Counterfactual Phrase Grounding : woman in brown Result N / A\",\"url\":\"https://www.semanticscholar.org/paper/50e9aabc46ea2d1ee80aacfcade14746776a6761\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1910.02029\",\"authors\":[{\"authorId\":\"2326243\",\"name\":\"Arun Balajee Vasudevan\"},{\"authorId\":\"1778526\",\"name\":\"Dengxin Dai\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/s11263-020-01374-3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"28766f2ecfb5dc19addf272bf25301030e8b1af9\",\"title\":\"Talk2Nav: Long-Range Vision-and-Language Navigation with Dual Attention and Spatial Memory\",\"url\":\"https://www.semanticscholar.org/paper/28766f2ecfb5dc19addf272bf25301030e8b1af9\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3705643\",\"name\":\"H. Wang\"},{\"authorId\":\"145102437\",\"name\":\"Cheng Deng\"},{\"authorId\":\"1410309633\",\"name\":\"Fan Ma\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1609/AAAI.V34I07.6895\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"491bfcc0dbcca04b4983d2716e9125b76a45ede2\",\"title\":\"Context Modulated Dynamic Networks for Actor and Action Video Segmentation with Language Queries\",\"url\":\"https://www.semanticscholar.org/paper/491bfcc0dbcca04b4983d2716e9125b76a45ede2\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2011.10132\",\"authors\":[{\"authorId\":\"51218991\",\"name\":\"Sisi Qu\"},{\"authorId\":\"150234800\",\"name\":\"Mattia Soldan\"},{\"authorId\":\"97375393\",\"name\":\"Mengmeng Xu\"},{\"authorId\":\"1402915033\",\"name\":\"Jesper Tegn\\u00e9r\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"075ce64105cc54cec2b54c24f8f890f2c62d090b\",\"title\":\"VLG-Net: Video-Language Graph Matching Network for Video Grounding\",\"url\":\"https://www.semanticscholar.org/paper/075ce64105cc54cec2b54c24f8f890f2c62d090b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.08977\",\"authors\":[{\"authorId\":\"152641281\",\"name\":\"Y. Zhou\"},{\"authorId\":\"7271879\",\"name\":\"M. Wang\"},{\"authorId\":\"121357290\",\"name\":\"Ruolin Wang\"},{\"authorId\":\"19216752\",\"name\":\"Shuwei Huo\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"22dfa9f5552f3cf57688e41e118965e11c30b28b\",\"title\":\"Generating Adjacency Matrix for Video-Query based Video Moment Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/22dfa9f5552f3cf57688e41e118965e11c30b28b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.07514\",\"authors\":[{\"authorId\":\"8511875\",\"name\":\"Jonghwan Mun\"},{\"authorId\":\"72643925\",\"name\":\"Minsu Cho\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":\"10.1109/CVPR42600.2020.01082\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"7e3d5b20e5df692deb80d9e100e4f34c1a8f8031\",\"title\":\"Local-Global Video-Text Interactions for Temporal Grounding\",\"url\":\"https://www.semanticscholar.org/paper/7e3d5b20e5df692deb80d9e100e4f34c1a8f8031\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2008.02448\",\"authors\":[{\"authorId\":\"51912474\",\"name\":\"Xiaoye Qu\"},{\"authorId\":\"1855095179\",\"name\":\"Pengwei Tang\"},{\"authorId\":\"3008849\",\"name\":\"Zhikang Zhou\"},{\"authorId\":\"5524736\",\"name\":\"Y. Cheng\"},{\"authorId\":\"40240283\",\"name\":\"J. Dong\"},{\"authorId\":\"145232778\",\"name\":\"Pan Zhou\"}],\"doi\":\"10.1145/3394171.3414053\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a4d78df0b175e3cbf811e652184f6b1e9d11caca\",\"title\":\"Fine-grained Iterative Attention Network for Temporal Language Localization in Videos\",\"url\":\"https://www.semanticscholar.org/paper/a4d78df0b175e3cbf811e652184f6b1e9d11caca\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2007.02375\",\"authors\":[{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"5891694\",\"name\":\"J. Luo\"},{\"authorId\":\"37184350\",\"name\":\"J. Xu\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"1490772804\",\"name\":\"Tao Mei\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ad9d41b29f7b7b35278f466dc2eafedaf7f57db1\",\"title\":\"Auto-captions on GIF: A Large-scale Video-sentence Dataset for Vision-language Pre-training\",\"url\":\"https://www.semanticscholar.org/paper/ad9d41b29f7b7b35278f466dc2eafedaf7f57db1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1806.08251\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1109/WACV45572.2020.9093612\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dbbcf8af70db7533f76e8e55f108fcc6af6e0c0e\",\"title\":\"Learning Multimodal Representations for Unseen Activities\",\"url\":\"https://www.semanticscholar.org/paper/dbbcf8af70db7533f76e8e55f108fcc6af6e0c0e\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1912.06617\",\"authors\":[{\"authorId\":\"28798386\",\"name\":\"H. Doughty\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1398236231\",\"name\":\"W. Mayol-Cuevas\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.1109/CVPR42600.2020.00095\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1bc01f26b29282855e7cc997a737aa72697a4cac\",\"title\":\"Action Modifiers: Learning From Adverbs in Instructional Videos\",\"url\":\"https://www.semanticscholar.org/paper/1bc01f26b29282855e7cc997a737aa72697a4cac\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2011.14598\",\"authors\":[{\"authorId\":\"1753647133\",\"name\":\"Chen Zhao\"},{\"authorId\":\"1872964\",\"name\":\"Ali K. Thabet\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b19e442f6d313c211b522a791252de2c2468063b\",\"title\":\"Video Self-Stitching Graph Network for Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/b19e442f6d313c211b522a791252de2c2468063b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.00325\",\"authors\":[{\"authorId\":\"3186326\",\"name\":\"Mayu Otani\"},{\"authorId\":\"1789677\",\"name\":\"Yuta Nakashima\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"},{\"authorId\":\"48679036\",\"name\":\"J. Heikkila\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a9e1c2820f86b80d4b0b93829ceb982d9890a252\",\"title\":\"Uncovering Hidden Challenges in Query-Based Video Moment Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/a9e1c2820f86b80d4b0b93829ceb982d9890a252\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.11618\",\"authors\":[{\"authorId\":\"48211835\",\"name\":\"J. Liu\"},{\"authorId\":\"2928777\",\"name\":\"Wenhu Chen\"},{\"authorId\":\"5524736\",\"name\":\"Y. Cheng\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"35729970\",\"name\":\"Yiming Yang\"},{\"authorId\":\"46700348\",\"name\":\"Jing-jing Liu\"}],\"doi\":\"10.1109/cvpr42600.2020.01091\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"704ec27b8399df574a96da338c428a923509385e\",\"title\":\"Violin: A Large-Scale Dataset for Video-and-Language Inference\",\"url\":\"https://www.semanticscholar.org/paper/704ec27b8399df574a96da338c428a923509385e\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020}],\"corpusId\":1061352,\"doi\":\"10.1109/ICCV.2017.618\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":46,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"ee909ad489244016cf301bb7d7d8eeea423dbf35\",\"references\":[{\"arxivId\":\"1607.05177\",\"authors\":[{\"authorId\":\"3377097\",\"name\":\"A. Sharghi\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1007/978-3-319-46484-8_1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"083986588bdef41ce5f154f9decdd7dc6d39292e\",\"title\":\"Query-Focused Extractive Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/083986588bdef41ce5f154f9decdd7dc6d39292e\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2275622\",\"name\":\"Xiaoshi Zhong\"},{\"authorId\":\"1735962\",\"name\":\"Aixin Sun\"},{\"authorId\":\"49943757\",\"name\":\"E. Cambria\"}],\"doi\":\"10.18653/v1/P17-1039\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b5c038772fe777f721b5c26574dea208f9c1e464\",\"title\":\"Time Expression Analysis and Recognition Using Syntactic Token Types and General Heuristic Rules\",\"url\":\"https://www.semanticscholar.org/paper/b5c038772fe777f721b5c26574dea208f9c1e464\",\"venue\":\"ACL\",\"year\":2017},{\"arxivId\":\"1612.01669\",\"authors\":[{\"authorId\":\"8511875\",\"name\":\"Jonghwan Mun\"},{\"authorId\":\"14454974\",\"name\":\"P. H. Seo\"},{\"authorId\":\"3386346\",\"name\":\"Ilchae Jung\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":\"10.1109/ICCV.2017.312\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"00672bec9dd0e755f9c375f912c0f1c3918a6b74\",\"title\":\"MarioQA: Answering Questions by Watching Gameplay Videos\",\"url\":\"https://www.semanticscholar.org/paper/00672bec9dd0e755f9c375f912c0f1c3918a6b74\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1504.00325\",\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"title\":\"Microsoft COCO Captions: Data Collection and Evaluation Server\",\"url\":\"https://www.semanticscholar.org/paper/696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145969200\",\"name\":\"B. Klein\"},{\"authorId\":\"3004979\",\"name\":\"G. Lev\"},{\"authorId\":\"2251827\",\"name\":\"Gil Sadeh\"},{\"authorId\":\"145128145\",\"name\":\"Lior Wolf\"}],\"doi\":\"10.1109/CVPR.2015.7299073\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"51239b320c73f3f2219286bf62f24d6763379328\",\"title\":\"Associating neural word embeddings with deep image representations using Fisher Vectors\",\"url\":\"https://www.semanticscholar.org/paper/51239b320c73f3f2219286bf62f24d6763379328\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"L. A. Hendricks\"},{\"authorId\":null,\"name\":\"O. Wang\"},{\"authorId\":null,\"name\":\"E. Shechtman\"},{\"authorId\":null,\"name\":\"J. Sivic\"},{\"authorId\":null,\"name\":\"T. Darrell\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Localizing moments in video with natural language Long short - term memory\",\"url\":\"\",\"venue\":\"Neural computation\",\"year\":2016},{\"arxivId\":\"1503.01558\",\"authors\":[{\"authorId\":\"3274291\",\"name\":\"Jonathan Malmaud\"},{\"authorId\":\"1808244\",\"name\":\"J. Huang\"},{\"authorId\":\"145239860\",\"name\":\"Vivek Rathod\"},{\"authorId\":\"40939880\",\"name\":\"Nicholas Johnston\"},{\"authorId\":\"39863668\",\"name\":\"Andrew Rabinovich\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":\"10.3115/v1/N15-1015\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"59ba3b1b31e2f8adb18fb886ad3fc087081c0e38\",\"title\":\"What's Cookin'? Interpreting Cooking Videos using Text, Speech and Vision\",\"url\":\"https://www.semanticscholar.org/paper/59ba3b1b31e2f8adb18fb886ad3fc087081c0e38\",\"venue\":\"HLT-NAACL\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144551484\",\"name\":\"J. M\\u00e1s\"},{\"authorId\":\"144869456\",\"name\":\"G. Fernandez\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"da353c6a441fe788b93f93b9d362f0b89b5f48cb\",\"title\":\"Video Shot Boundary Detection Based on Color Histogram\",\"url\":\"https://www.semanticscholar.org/paper/da353c6a441fe788b93f93b9d362f0b89b5f48cb\",\"venue\":\"TRECVID\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2279670\",\"name\":\"Andrea Frome\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"1789737\",\"name\":\"Jonathon Shlens\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"},{\"authorId\":\"1706809\",\"name\":\"Marc'Aurelio Ranzato\"},{\"authorId\":null,\"name\":\"Tomas Mikolov\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4aa4069693bee00d1b0759ca3df35e59284e9845\",\"title\":\"DeViSE: A Deep Visual-Semantic Embedding Model\",\"url\":\"https://www.semanticscholar.org/paper/4aa4069693bee00d1b0759ca3df35e59284e9845\",\"venue\":\"NIPS\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2485529\",\"name\":\"Michaela Regneri\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"24138684\",\"name\":\"Dominikus Wetzel\"},{\"authorId\":\"1727272\",\"name\":\"Stefan Thater\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"1717560\",\"name\":\"Manfred Pinkal\"}],\"doi\":\"10.1162/tacl_a_00207\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"21b3007f967d39e1346bc91e0fc8b3f16121300c\",\"title\":\"Grounding Action Descriptions in Videos\",\"url\":\"https://www.semanticscholar.org/paper/21b3007f967d39e1346bc91e0fc8b3f16121300c\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2013},{\"arxivId\":\"1612.06890\",\"authors\":[{\"authorId\":\"153365679\",\"name\":\"J. Johnson\"},{\"authorId\":\"73710317\",\"name\":\"B. Hariharan\"},{\"authorId\":\"35341401\",\"name\":\"Laurens van der Maaten\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/CVPR.2017.215\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"03eb382e04cca8cca743f7799070869954f1402a\",\"title\":\"CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/03eb382e04cca8cca743f7799070869954f1402a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1604.02748\",\"authors\":[{\"authorId\":\"66508219\",\"name\":\"Y. Li\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"48749954\",\"name\":\"L. Cao\"},{\"authorId\":\"1739099\",\"name\":\"J. Tetreault\"},{\"authorId\":\"39420932\",\"name\":\"L. Goldberg\"},{\"authorId\":\"144633617\",\"name\":\"A. Jaimes\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2016.502\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"05f3f8f6f97db00bafa2efd2ac9aac570603c0c6\",\"title\":\"TGIF: A New Dataset and Benchmark on Animated GIF Description\",\"url\":\"https://www.semanticscholar.org/paper/05f3f8f6f97db00bafa2efd2ac9aac570603c0c6\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"144369161\",\"name\":\"Wei Qiu\"},{\"authorId\":\"144889265\",\"name\":\"Ivan Titov\"},{\"authorId\":\"1727272\",\"name\":\"Stefan Thater\"},{\"authorId\":\"1717560\",\"name\":\"Manfred Pinkal\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1109/ICCV.2013.61\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e8cd37fbd8bd5e690eef5861cf92af8e002d4533\",\"title\":\"Translating Video Content to Natural Language Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/e8cd37fbd8bd5e690eef5861cf92af8e002d4533\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"144332826\",\"name\":\"Chen Kong\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"}],\"doi\":\"10.1109/CVPR.2014.340\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"7afd833f484c8032e7fdc5f53188d2ebb0fb9934\",\"title\":\"Visual Semantic Search: Retrieving Videos via Complex Textual Queries\",\"url\":\"https://www.semanticscholar.org/paper/7afd833f484c8032e7fdc5f53188d2ebb0fb9934\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144418348\",\"name\":\"R. Xu\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"50504401\",\"name\":\"Wei Chen\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1654e19de0187085e9d1da2d9e8718f49cd2f731\",\"title\":\"Jointly Modeling Deep Video and Compositional Text to Bridge Vision and Language in a Unified Framework\",\"url\":\"https://www.semanticscholar.org/paper/1654e19de0187085e9d1da2d9e8718f49cd2f731\",\"venue\":\"AAAI\",\"year\":2015},{\"arxivId\":\"1511.02283\",\"authors\":[{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"1808244\",\"name\":\"J. Huang\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"3317152\",\"name\":\"Oana-Maria Camburu\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":\"10.1109/CVPR.2016.9\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e65142010431ffc089b272a1174214e00693e503\",\"title\":\"Generation and Comprehension of Unambiguous Object Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/e65142010431ffc089b272a1174214e00693e503\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1505.01861\",\"authors\":[{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/CVPR.2016.497\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"68478207cf3e4fc44bf1602abe82c7ac7f288872\",\"title\":\"Jointly Modeling Embedding and Translation to Bridge Video and Language\",\"url\":\"https://www.semanticscholar.org/paper/68478207cf3e4fc44bf1602abe82c7ac7f288872\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21308992\",\"name\":\"Steven Bird\"},{\"authorId\":\"145606490\",\"name\":\"E. Klein\"},{\"authorId\":\"3213150\",\"name\":\"E. Loper\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7a65f23d990231d461418067c808b09d84c19b2c\",\"title\":\"Natural Language Processing with Python\",\"url\":\"https://www.semanticscholar.org/paper/7a65f23d990231d461418067c808b09d84c19b2c\",\"venue\":\"\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2463875\",\"name\":\"B. Thomee\"},{\"authorId\":\"1760364\",\"name\":\"D. Shamma\"},{\"authorId\":\"1797144\",\"name\":\"G. Friedland\"},{\"authorId\":\"2532460\",\"name\":\"B. Elizalde\"},{\"authorId\":\"36845351\",\"name\":\"Karl Ni\"},{\"authorId\":\"143669214\",\"name\":\"D. Poland\"},{\"authorId\":\"1772549\",\"name\":\"D. Borth\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6e695ddd07aad719001c0fc1129328452385949\",\"title\":\"The New Data and New Challenges in Multimedia Research\",\"url\":\"https://www.semanticscholar.org/paper/a6e695ddd07aad719001c0fc1129328452385949\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1703.02521\",\"authors\":[{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"35198686\",\"name\":\"Joseph J. Lim\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/CVPR.2017.116\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"35f1bcff4552632419742bbb6e1927ef5e998eb4\",\"title\":\"Unsupervised Visual-Linguistic Reference Resolution in Instructional Videos\",\"url\":\"https://www.semanticscholar.org/paper/35f1bcff4552632419742bbb6e1927ef5e998eb4\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145971173\",\"name\":\"J. Xu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/CVPR.2016.571\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b8e2e9f3ba008e28257195ec69a00e07f260131d\",\"title\":\"MSR-VTT: A Large Video Description Dataset for Bridging Video and Language\",\"url\":\"https://www.semanticscholar.org/paper/b8e2e9f3ba008e28257195ec69a00e07f260131d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1503.01817\",\"authors\":[{\"authorId\":\"2463875\",\"name\":\"B. Thomee\"},{\"authorId\":\"1760364\",\"name\":\"D. Shamma\"},{\"authorId\":\"1797144\",\"name\":\"G. Friedland\"},{\"authorId\":\"2532460\",\"name\":\"B. Elizalde\"},{\"authorId\":\"36845351\",\"name\":\"Karl Ni\"},{\"authorId\":\"143669214\",\"name\":\"D. Poland\"},{\"authorId\":\"1772549\",\"name\":\"D. Borth\"},{\"authorId\":\"118220290\",\"name\":\"L. Li\"}],\"doi\":\"10.1145/2812802\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"354c029c88be2bbc27dfd2e2e729c0ae622511e6\",\"title\":\"YFCC100M: the new data in multimedia research\",\"url\":\"https://www.semanticscholar.org/paper/354c029c88be2bbc27dfd2e2e729c0ae622511e6\",\"venue\":\"Commun. ACM\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2913681\",\"name\":\"Stefanie Tellex\"},{\"authorId\":\"145364504\",\"name\":\"D. Roy\"}],\"doi\":\"10.1145/1646396.1646442\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3a44dd9f24da7c41ac01e1412690d4c33ff8e4a5\",\"title\":\"Towards surveillance video search by natural language query\",\"url\":\"https://www.semanticscholar.org/paper/3a44dd9f24da7c41ac01e1412690d4c33ff8e4a5\",\"venue\":\"CIVR '09\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2910174\",\"name\":\"Haonan Yu\"},{\"authorId\":\"145809603\",\"name\":\"N. Siddharth\"},{\"authorId\":\"21570451\",\"name\":\"A. Barbu\"},{\"authorId\":\"1737754\",\"name\":\"J. Siskind\"}],\"doi\":\"10.1613/jair.4556\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"083d1055f81dd7c9b41233a92b9768a857d1db58\",\"title\":\"A Compositional Framework for Grounding Language Inference, Generation, and Acquisition in Video\",\"url\":\"https://www.semanticscholar.org/paper/083d1055f81dd7c9b41233a92b9768a857d1db58\",\"venue\":\"J. Artif. Intell. Res.\",\"year\":2015},{\"arxivId\":\"1406.5824\",\"authors\":[{\"authorId\":\"34149749\",\"name\":\"Serena Yeung\"},{\"authorId\":\"50706340\",\"name\":\"Alireza Fathi\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3a31da018246f4d67c5702574b7c16e14d261541\",\"title\":\"VideoSET: Video Summary Evaluation through Text\",\"url\":\"https://www.semanticscholar.org/paper/3a31da018246f4d67c5702574b7c16e14d261541\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":\"1511.03745\",\"authors\":[{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1007/978-3-319-46448-0_49\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"14c2321851fb5ae580a19726dd2753a525d6ad76\",\"title\":\"Grounding of Textual Phrases in Images by Reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/14c2321851fb5ae580a19726dd2753a525d6ad76\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1605.04850\",\"authors\":[{\"authorId\":\"3037160\",\"name\":\"Michael Gygli\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"48749954\",\"name\":\"L. Cao\"}],\"doi\":\"10.1109/CVPR.2016.114\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"28f0e0d3783659bc9adb2cec56f19b1f90cdd2be\",\"title\":\"Video2GIF: Automatic Generation of Animated GIFs from Video\",\"url\":\"https://www.semanticscholar.org/paper/28f0e0d3783659bc9adb2cec56f19b1f90cdd2be\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"},{\"authorId\":\"34699434\",\"name\":\"A. Ng\"}],\"doi\":\"10.1162/tacl_a_00177\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"0ca7d208ff8d81377e0eaa9723820aeae7a7322d\",\"title\":\"Grounded Compositional Semantics for Finding and Describing Images with Sentences\",\"url\":\"https://www.semanticscholar.org/paper/0ca7d208ff8d81377e0eaa9723820aeae7a7322d\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2014},{\"arxivId\":\"1408.5093\",\"authors\":[{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"1782282\",\"name\":\"Evan Shelhamer\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"3049736\",\"name\":\"S. Karayev\"},{\"authorId\":\"144361581\",\"name\":\"J. Long\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1145/2647868.2654889\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6bdb186ec4726e00a8051119636d4df3b94043b5\",\"title\":\"Caffe: Convolutional Architecture for Fast Feature Embedding\",\"url\":\"https://www.semanticscholar.org/paper/6bdb186ec4726e00a8051119636d4df3b94043b5\",\"venue\":\"ACM Multimedia\",\"year\":2014},{\"arxivId\":\"1608.00859\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-319-46484-8_2\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"title\":\"Temporal Segment Networks: Towards Good Practices for Deep Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1510.01442\",\"authors\":[{\"authorId\":\"46402216\",\"name\":\"Huan Yang\"},{\"authorId\":\"2450889\",\"name\":\"B. Wang\"},{\"authorId\":\"145676588\",\"name\":\"Stephen Lin\"},{\"authorId\":\"2242717\",\"name\":\"D. Wipf\"},{\"authorId\":\"1697293\",\"name\":\"M. Guo\"},{\"authorId\":\"143632999\",\"name\":\"B. Guo\"}],\"doi\":\"10.1109/ICCV.2015.526\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"faafe2a76dbb9a5a1468b1a02b1f0f09ced8587e\",\"title\":\"Unsupervised Extraction of Video Highlights via Robust Recurrent Auto-Encoders\",\"url\":\"https://www.semanticscholar.org/paper/faafe2a76dbb9a5a1468b1a02b1f0f09ced8587e\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1106.0256\",\"authors\":[{\"authorId\":\"1737754\",\"name\":\"J. Siskind\"}],\"doi\":\"10.1613/jair.790\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d607a7f816436b6a55a11badd260a0cc58b8f8c4\",\"title\":\"Grounding the Lexical Semantics of Verbs in Visual Perception using Force Dynamics and Event Logic\",\"url\":\"https://www.semanticscholar.org/paper/d607a7f816436b6a55a11badd260a0cc58b8f8c4\",\"venue\":\"J. Artif. Intell. Res.\",\"year\":2001},{\"arxivId\":\"1506.08438\",\"authors\":[{\"authorId\":\"3114252\",\"name\":\"O. Sener\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"1702137\",\"name\":\"S. Savarese\"},{\"authorId\":\"1681995\",\"name\":\"A. Saxena\"}],\"doi\":\"10.1109/ICCV.2015.509\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"71d114b58379b99cb96f01fbb9d1667d970ed53c\",\"title\":\"Unsupervised Semantic Parsing of Video Collections\",\"url\":\"https://www.semanticscholar.org/paper/71d114b58379b99cb96f01fbb9d1667d970ed53c\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5886094\",\"name\":\"P. Cochat\"},{\"authorId\":\"13267685\",\"name\":\"L. Vaucoret\"},{\"authorId\":\"31455512\",\"name\":\"J. Sarles\"}],\"doi\":\"10.1016/j.arcped.2012.01.013\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"10d85561e4aafc516d10064f30dff05b41f70afe\",\"title\":\"[Et al].\",\"url\":\"https://www.semanticscholar.org/paper/10d85561e4aafc516d10064f30dff05b41f70afe\",\"venue\":\"Archives de pediatrie : organe officiel de la Societe francaise de pediatrie\",\"year\":2012},{\"arxivId\":\"1611.09978\",\"authors\":[{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/CVPR.2017.470\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ce264a4e1490e959d84ddd60edbb0edcbfb3af38\",\"title\":\"Modeling Relationships in Referential Expressions with Compositional Modular Networks\",\"url\":\"https://www.semanticscholar.org/paper/ce264a4e1490e959d84ddd60edbb0edcbfb3af38\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1705.02101\",\"authors\":[{\"authorId\":\"3029956\",\"name\":\"J. Gao\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"3469030\",\"name\":\"Zhenheng Yang\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/ICCV.2017.563\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e9bd6f0b04a0ddf9fcdf3a5fd1cfe87f8ae9cfff\",\"title\":\"TALL: Temporal Activity Localization via Language Query\",\"url\":\"https://www.semanticscholar.org/paper/e9bd6f0b04a0ddf9fcdf3a5fd1cfe87f8ae9cfff\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/CVPR.2015.7298878\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5838af587938e74b5758414c384dcf16dd6e1d1e\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/5838af587938e74b5758414c384dcf16dd6e1d1e\",\"venue\":\"CVPR\",\"year\":2015},{\"arxivId\":\"1704.04497\",\"authors\":[{\"authorId\":\"2338742\",\"name\":\"Y. Jang\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"49170458\",\"name\":\"Youngjin Kim\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1109/CVPR.2017.149\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b2f521c02c6ed3080c5fe123e938cdf4555e6fd2\",\"title\":\"TGIF-QA: Toward Spatio-Temporal Reasoning in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b2f521c02c6ed3080c5fe123e938cdf4555e6fd2\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71596621\",\"name\":\"J. Malmaud\"},{\"authorId\":\"3003604\",\"name\":\"Earl J. Wagner\"},{\"authorId\":\"145375772\",\"name\":\"N. Chang\"},{\"authorId\":\"145079099\",\"name\":\"K. Murphy\"}],\"doi\":\"10.3115/v1/W14-2407\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3f7a9b392edca880cdc8ed3bac6708a7d4fa348d\",\"title\":\"Cooking with Semantics\",\"url\":\"https://www.semanticscholar.org/paper/3f7a9b392edca880cdc8ed3bac6708a7d4fa348d\",\"venue\":\"ACL 2014\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3104292\",\"name\":\"Chlo\\u00e9 Kiddon\"},{\"authorId\":\"2064115\",\"name\":\"Ganesa Thandavam Ponnuraj\"},{\"authorId\":\"1982950\",\"name\":\"Luke Zettlemoyer\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":\"10.18653/v1/D15-1114\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e0dd4e915ea58c6e9cc0f03482894047226e4a03\",\"title\":\"Mise en Place: Unsupervised Interpretation of Instructional Recipes\",\"url\":\"https://www.semanticscholar.org/paper/e0dd4e915ea58c6e9cc0f03482894047226e4a03\",\"venue\":\"EMNLP\",\"year\":2015},{\"arxivId\":\"1604.01753\",\"authors\":[{\"authorId\":\"34280810\",\"name\":\"Gunnar A. Sigurdsson\"},{\"authorId\":\"2668759\",\"name\":\"G. Varol\"},{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1007/978-3-319-46448-0_31\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"21334d1aac5422da88780f8e24e181bfa15ef0e1\",\"title\":\"Hollywood in Homes: Crowdsourcing Data Collection for Activity Understanding\",\"url\":\"https://www.semanticscholar.org/paper/21334d1aac5422da88780f8e24e181bfa15ef0e1\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1605.03705\",\"authors\":[{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1730844\",\"name\":\"Atousa Torabi\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1721168\",\"name\":\"Niket Tandon\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1007/s11263-016-0987-1\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"154c22ca5eef149aedc8a986fa684ca1fd14e7dc\",\"title\":\"Movie Description\",\"url\":\"https://www.semanticscholar.org/paper/154c22ca5eef149aedc8a986fa684ca1fd14e7dc\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":\"1409.0575\",\"authors\":[{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"71309570\",\"name\":\"H. Su\"},{\"authorId\":\"2285165\",\"name\":\"J. Krause\"},{\"authorId\":\"145031342\",\"name\":\"S. Satheesh\"},{\"authorId\":\"145423516\",\"name\":\"S. Ma\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-015-0816-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"title\":\"ImageNet Large Scale Visual Recognition Challenge\",\"url\":\"https://www.semanticscholar.org/paper/e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":\"1506.01698\",\"authors\":[{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1007/978-3-319-24947-6_17\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"49512d11c468dc2fe3fe832d8c4dc8e0a01b0a4b\",\"title\":\"The Long-Short Story of Movie Description\",\"url\":\"https://www.semanticscholar.org/paper/49512d11c468dc2fe3fe832d8c4dc8e0a01b0a4b\",\"venue\":\"GCPR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1686917\",\"name\":\"Wu Liu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"},{\"authorId\":\"3038150\",\"name\":\"Cherry Che\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2015.7298994\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"562fbe1f8b8a77fbeb2adea42476752246b610e7\",\"title\":\"Multi-task deep visual-semantic embedding for video thumbnail selection\",\"url\":\"https://www.semanticscholar.org/paper/562fbe1f8b8a77fbeb2adea42476752246b610e7\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3037160\",\"name\":\"Michael Gygli\"},{\"authorId\":\"145551629\",\"name\":\"H. Grabner\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2015.7298928\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cfcb9bcc1e8b4d3451578398aeb37f0fa5614632\",\"title\":\"Video summarization by learning submodular mixtures of objectives\",\"url\":\"https://www.semanticscholar.org/paper/cfcb9bcc1e8b4d3451578398aeb37f0fa5614632\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"2757535\",\"name\":\"Jordi Vallmitjana\"},{\"authorId\":\"1690152\",\"name\":\"Amanda Stent\"},{\"authorId\":\"144633617\",\"name\":\"A. Jaimes\"}],\"doi\":\"10.1109/CVPR.2015.7299154\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cbf89cb4e107fb59e119ae619bcfe48e1964e033\",\"title\":\"TVSum: Summarizing web videos using titles\",\"url\":\"https://www.semanticscholar.org/paper/cbf89cb4e107fb59e119ae619bcfe48e1964e033\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153642390\",\"name\":\"David L. Chen\"},{\"authorId\":\"83415753\",\"name\":\"W. Dolan\"}],\"doi\":null,\"intent\":[\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"554a31ce91189cf6022ac677413ef2f8b9b40ca7\",\"title\":\"Collecting Highly Parallel Data for Paraphrase Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/554a31ce91189cf6022ac677413ef2f8b9b40ca7\",\"venue\":\"ACL 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/ICCV.2015.510\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"title\":\"Learning Spatiotemporal Features with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1510.07712\",\"authors\":[{\"authorId\":\"2910174\",\"name\":\"Haonan Yu\"},{\"authorId\":\"40579682\",\"name\":\"J. Wang\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"}],\"doi\":\"10.1109/CVPR.2016.496\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f678a0041f2c6f931168010e7418c500c3f14cdb\",\"title\":\"Video Paragraph Captioning Using Hierarchical Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/f678a0041f2c6f931168010e7418c500c3f14cdb\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1777498\",\"name\":\"Savas Konur\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0101f332492fe2f230b48691f586cf33b7eb9200\",\"title\":\"An interval logic for natural language semantics\",\"url\":\"https://www.semanticscholar.org/paper/0101f332492fe2f230b48691f586cf33b7eb9200\",\"venue\":\"Advances in Modal Logic\",\"year\":2008},{\"arxivId\":\"1609.08124\",\"authors\":[{\"authorId\":\"1730844\",\"name\":\"Atousa Torabi\"},{\"authorId\":\"1721168\",\"name\":\"Niket Tandon\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2068f66a10254d457cdb5fab74b0128b24bfdb65\",\"title\":\"Learning Language-Visual Embedding for Movie Understanding with Natural-Language\",\"url\":\"https://www.semanticscholar.org/paper/2068f66a10254d457cdb5fab74b0128b24bfdb65\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32301760\",\"name\":\"Gabor Angeli\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"},{\"authorId\":\"1746807\",\"name\":\"Dan Jurafsky\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"e95353d65cdad3ca73e6e70634f1964bb14e31de\",\"title\":\"Parsing Time: Learning to Interpret Time Expressions\",\"url\":\"https://www.semanticscholar.org/paper/e95353d65cdad3ca73e6e70634f1964bb14e31de\",\"venue\":\"HLT-NAACL\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143845796\",\"name\":\"Jeffrey Pennington\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.3115/v1/D14-1162\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"title\":\"Glove: Global Vectors for Word Representation\",\"url\":\"https://www.semanticscholar.org/paper/f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":\"1608.02367\",\"authors\":[{\"authorId\":\"3186326\",\"name\":\"Mayu Otani\"},{\"authorId\":\"1789677\",\"name\":\"Yuta Nakashima\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"},{\"authorId\":\"3111194\",\"name\":\"J. Heikkil\\u00e4\"},{\"authorId\":\"1771769\",\"name\":\"N. Yokoya\"}],\"doi\":\"10.1007/978-3-319-46604-0_46\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aa76f655c2ad655080593a191c4b479ab9f18117\",\"title\":\"Learning Joint Representations of Videos and Sentences with Web Image Search\",\"url\":\"https://www.semanticscholar.org/paper/aa76f655c2ad655080593a191c4b479ab9f18117\",\"venue\":\"ECCV Workshops\",\"year\":2016},{\"arxivId\":\"1503.01070\",\"authors\":[{\"authorId\":\"1730844\",\"name\":\"Atousa Torabi\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b1ddb2994e49a6a4f45e878c1cda7562b03177e6\",\"title\":\"Using Descriptive Video Services to Create a Large Data Source for Video Annotation Research\",\"url\":\"https://www.semanticscholar.org/paper/b1ddb2994e49a6a4f45e878c1cda7562b03177e6\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1512.02902\",\"authors\":[{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"2214033\",\"name\":\"Y. Zhu\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":\"10.1109/CVPR.2016.501\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1bdd75a37f7c601f01e9d31c2551fa9f2067ffd7\",\"title\":\"MovieQA: Understanding Stories in Movies through Question-Answering\",\"url\":\"https://www.semanticscholar.org/paper/1bdd75a37f7c601f01e9d31c2551fa9f2067ffd7\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"O. Wang\"},{\"authorId\":null,\"name\":\"E. Shechtman\"},{\"authorId\":null,\"name\":\"J. Sivic\"},{\"authorId\":null,\"name\":\"T. Darrell\"},{\"authorId\":null,\"name\":\"B. Russell\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Localizing moments in video with natural language Long short - term memory\",\"url\":\"\",\"venue\":\"Neural computation\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2910174\",\"name\":\"Haonan Yu\"},{\"authorId\":\"1737754\",\"name\":\"J. Siskind\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"96a0320ef14877038906947b684011cf7378c440\",\"title\":\"Grounded Language Learning from Video Described with Sentences\",\"url\":\"https://www.semanticscholar.org/paper/96a0320ef14877038906947b684011cf7378c440\",\"venue\":\"ACL\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52014393\",\"name\":\"Ut Austin\"},{\"authorId\":\"123312980\",\"name\":\"Austin\"},{\"authorId\":\"102704114\",\"name\":\"UMass Lowell\"},{\"authorId\":\"102898595\",\"name\":\"Lowell\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"43795b7bac3d921c4e579964b54187bdbf6c6330\",\"title\":\"Translating Videos to Natural Language Using Deep Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/43795b7bac3d921c4e579964b54187bdbf6c6330\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1611.06641\",\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"36508529\",\"name\":\"Arun Mallya\"},{\"authorId\":\"6648406\",\"name\":\"Christopher M. Cervantes\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1109/ICCV.2017.213\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d061fbed640a4a06dfea2c2fbe9ec05061d775ce\",\"title\":\"Phrase Localization and Visual Relationship Detection with Comprehensive Image-Language Cues\",\"url\":\"https://www.semanticscholar.org/paper/d061fbed640a4a06dfea2c2fbe9ec05061d775ce\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1505.06027\",\"authors\":[{\"authorId\":\"2329288\",\"name\":\"P. Bojanowski\"},{\"authorId\":\"3215950\",\"name\":\"R\\u00e9mi Lajugie\"},{\"authorId\":\"3024698\",\"name\":\"E. Grave\"},{\"authorId\":\"144570279\",\"name\":\"Francis R. Bach\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"144189388\",\"name\":\"J. Ponce\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2015.507\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"59ac98f3910dad473e7771ac61f796a038f1708f\",\"title\":\"Weakly-Supervised Alignment of Video with Text\",\"url\":\"https://www.semanticscholar.org/paper/59ac98f3910dad473e7771ac61f796a038f1708f\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1506.09215\",\"authors\":[{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"2329288\",\"name\":\"P. Bojanowski\"},{\"authorId\":\"143688116\",\"name\":\"Nishant Agrawal\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1388317459\",\"name\":\"S. Lacoste-Julien\"}],\"doi\":\"10.1109/CVPR.2016.495\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e17ba2b5d0769e7f2602d859ea77a153846cf27d\",\"title\":\"Unsupervised Learning from Narrated Instruction Videos\",\"url\":\"https://www.semanticscholar.org/paper/e17ba2b5d0769e7f2602d859ea77a153846cf27d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1501.02530\",\"authors\":[{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1721168\",\"name\":\"Niket Tandon\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1109/CVPR.2015.7298940\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a5ea0da7b93452bec54b5034706f2255bfb5a8f3\",\"title\":\"A dataset for Movie Description\",\"url\":\"https://www.semanticscholar.org/paper/a5ea0da7b93452bec54b5034706f2255bfb5a8f3\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2363529\",\"name\":\"Pradipto Das\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"},{\"authorId\":\"38972663\",\"name\":\"Richard F. Doell\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1109/CVPR.2013.340\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a23ab0fb7d9e9961e92d704ed71e3dbc15c0d908\",\"title\":\"A Thousand Frames in Just a Few Words: Lingual Description of Videos through Latent Topics and Sparse Object Stitching\",\"url\":\"https://www.semanticscholar.org/paper/a23ab0fb7d9e9961e92d704ed71e3dbc15c0d908\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":\"1707.09472\",\"authors\":[{\"authorId\":\"35212676\",\"name\":\"J. Peyre\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"153433844\",\"name\":\"C. Schmid\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"}],\"doi\":\"10.1109/ICCV.2017.554\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5ab64c8da40e5279c243cf18f06498cb2bfe0f7e\",\"title\":\"Weakly-Supervised Learning of Visual Relations\",\"url\":\"https://www.semanticscholar.org/paper/5ab64c8da40e5279c243cf18f06498cb2bfe0f7e\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1403.6173\",\"authors\":[{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"113090874\",\"name\":\"W. Qiu\"},{\"authorId\":\"33985877\",\"name\":\"Annemarie Friedrich\"},{\"authorId\":\"1717560\",\"name\":\"Manfred Pinkal\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1007/978-3-319-11752-2_15\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"889e723cd6d581e120ee6776b231fdf69707ab50\",\"title\":\"Coherent Multi-sentence Video Description with Variable Level of Detail\",\"url\":\"https://www.semanticscholar.org/paper/889e723cd6d581e120ee6776b231fdf69707ab50\",\"venue\":\"GCPR\",\"year\":2014},{\"arxivId\":\"1505.00487\",\"authors\":[{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/ICCV.2015.515\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e58a110fa1e4ddf247d5c614d117d64bfbe135c4\",\"title\":\"Sequence to Sequence -- Video to Text\",\"url\":\"https://www.semanticscholar.org/paper/e58a110fa1e4ddf247d5c614d117d64bfbe135c4\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1406.5679\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2319608\",\"name\":\"Armand Joulin\"},{\"authorId\":\"153196308\",\"name\":\"F. Li\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7f1b111f0bb703b0bd97aba505728a9b0d9b2a54\",\"title\":\"Deep Fragment Embeddings for Bidirectional Image Sentence Mapping\",\"url\":\"https://www.semanticscholar.org/paper/7f1b111f0bb703b0bd97aba505728a9b0d9b2a54\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Torabi\"},{\"authorId\":null,\"name\":\"N. Tandon\"},{\"authorId\":null,\"name\":\"L. Sigal\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Learning languagevisual embedding for movie understanding with naturallanguage\",\"url\":\"\",\"venue\":\"arXiv preprint arXiv:1609.08124\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1910299\",\"name\":\"Oren Boiman\"},{\"authorId\":\"144611617\",\"name\":\"M. Irani\"}],\"doi\":\"10.1007/s11263-006-0009-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"86078efdd0d1bbfaf4b7f821e973f607429751fc\",\"title\":\"Detecting Irregularities in Images and in Video\",\"url\":\"https://www.semanticscholar.org/paper/86078efdd0d1bbfaf4b7f821e973f607429751fc\",\"venue\":\"Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3006072\",\"name\":\"Sahar Kazemzadeh\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"32215032\",\"name\":\"Mark Matten\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.3115/v1/D14-1086\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"92c141447f51b6732242376164ff961e464731c8\",\"title\":\"ReferItGame: Referring to Objects in Photographs of Natural Scenes\",\"url\":\"https://www.semanticscholar.org/paper/92c141447f51b6732242376164ff961e464731c8\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1162/neco.1997.9.8.1735\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"title\":\"Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"venue\":\"Neural Computation\",\"year\":1997},{\"arxivId\":\"1511.04164\",\"authors\":[{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"3286703\",\"name\":\"Huazhe Xu\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/CVPR.2016.493\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d696a1923288e6c15422660de9553f6fdb6a4fae\",\"title\":\"Natural Language Object Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/d696a1923288e6c15422660de9553f6fdb6a4fae\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1505.04870\",\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2133220\",\"name\":\"C. Cervantes\"},{\"authorId\":\"145507543\",\"name\":\"Juan C. Caicedo\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1007/s11263-016-0965-7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0612745dbd292fc0a548a16d39cd73e127faedde\",\"title\":\"Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models\",\"url\":\"https://www.semanticscholar.org/paper/0612745dbd292fc0a548a16d39cd73e127faedde\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"L. A. Hendricks\"},{\"authorId\":null,\"name\":\"O. Wang\"},{\"authorId\":null,\"name\":\"E. Shechtman\"},{\"authorId\":null,\"name\":\"J. Sivic\"},{\"authorId\":null,\"name\":\"T. Darrell\"},{\"authorId\":null,\"name\":\"B. Russell\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Localizing moments in video with natural language\",\"url\":\"\",\"venue\":\"arXiv preprint\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1400949657\",\"name\":\"I. Pratt-Hartmann\"}],\"doi\":\"10.1016/j.artint.2005.04.003\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"97d1603fd783cdada8cd1ea0a57a79e9c0c98edc\",\"title\":\"Temporal prepositions and their logic\",\"url\":\"https://www.semanticscholar.org/paper/97d1603fd783cdada8cd1ea0a57a79e9c0c98edc\",\"venue\":\"Artif. Intell.\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/CVPR.2016.112\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"97398356607115f78d677663a682363eec3302d7\",\"title\":\"Highlight Detection with Pairwise Deep Ranking for First-Person Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/97398356607115f78d677663a682363eec3302d7\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1704.03114\",\"authors\":[{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"46867115\",\"name\":\"Yuqi Zhang\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/CVPR.2017.352\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5fcd93997b7dde90594dc1caa27ba9d560bbe63d\",\"title\":\"Detecting Visual Relationships with Deep Relational Networks\",\"url\":\"https://www.semanticscholar.org/paper/5fcd93997b7dde90594dc1caa27ba9d560bbe63d\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017}],\"title\":\"Localizing Moments in Video with Natural Language\",\"topics\":[{\"topic\":\"Natural language\",\"topicId\":\"1911\",\"url\":\"https://www.semanticscholar.org/topic/1911\"},{\"topic\":\"Video clip\",\"topicId\":\"30493\",\"url\":\"https://www.semanticscholar.org/topic/30493\"},{\"topic\":\"Baseline (configuration management)\",\"topicId\":\"3403\",\"url\":\"https://www.semanticscholar.org/topic/3403\"}],\"url\":\"https://www.semanticscholar.org/paper/ee909ad489244016cf301bb7d7d8eeea423dbf35\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017}\n"