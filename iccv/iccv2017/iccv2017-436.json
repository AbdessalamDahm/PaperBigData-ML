"{\"abstract\":\"While strong progress has been made in image captioning recently, machine and human captions are still quite distinct. This is primarily due to the deficiencies in the generated word distribution, vocabulary size, and strong bias in the generators towards frequent captions. Furthermore, humans \\u2013 rightfully so \\u2013 generate multiple, diverse captions, due to the inherent ambiguity in the captioning task which is not explicitly considered in today's systems. To address these challenges, we change the training objective of the caption generator from reproducing ground-truth captions to generating a set of captions that is indistinguishable from human written captions. Instead of handcrafting such a learning target, we employ adversarial training in combination with an approximate Gumbel sampler to implicitly match the generated distribution to the human one. While our method achieves comparable performance to the state-of-the-art in terms of the correctness of the captions, we generate a set of diverse captions that are significantly less biased and better match the global uni-, bi- and tri-gram distributions of the human captions.\",\"arxivId\":\"1703.10476\",\"authors\":[{\"authorId\":\"38314306\",\"name\":\"Rakshith Shetty\",\"url\":\"https://www.semanticscholar.org/author/38314306\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\",\"url\":\"https://www.semanticscholar.org/author/34849128\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\",\"url\":\"https://www.semanticscholar.org/author/2234342\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\",\"url\":\"https://www.semanticscholar.org/author/1739548\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\",\"url\":\"https://www.semanticscholar.org/author/48920094\"}],\"citationVelocity\":22,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"47286885\",\"name\":\"Jingyi Hou\"},{\"authorId\":\"2125709\",\"name\":\"Xinxiao Wu\"},{\"authorId\":\"1390826784\",\"name\":\"Rui-Qi Wang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"},{\"authorId\":\"7415267\",\"name\":\"Y. Jia\"}],\"doi\":\"10.1109/TIP.2020.2987425\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"174168393288dbb61a6ec4c674a0298e489b9e4d\",\"title\":\"Confidence-Guided Self Refinement for Action Prediction in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/174168393288dbb61a6ec4c674a0298e489b9e4d\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7437104\",\"name\":\"Chih-Yao Ma\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"9202076\",\"name\":\"G. Al-Regib\"},{\"authorId\":\"48682997\",\"name\":\"P. Vajda\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"145276578\",\"name\":\"Z. Kira\"}],\"doi\":\"10.1007/978-3-030-58523-5_21\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f692df9ca116884860d580902fa642370bd1be5d\",\"title\":\"Learning to Generate Grounded Visual Captions Without Localization Supervision\",\"url\":\"https://www.semanticscholar.org/paper/f692df9ca116884860d580902fa642370bd1be5d\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6aee8323be7ad5e568d62ba368bc7123f750515f\",\"title\":\"Paying More Attention to Saliency: Image Captioning with Saliency and Context Attention\",\"url\":\"https://www.semanticscholar.org/paper/6aee8323be7ad5e568d62ba368bc7123f750515f\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1812.05634\",\"authors\":[{\"authorId\":\"46979645\",\"name\":\"J. Park\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"}],\"doi\":\"10.1109/CVPR.2019.00676\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"6aa6932c22b9bd407e615ec2bfffc20cd88a9069\",\"title\":\"Adversarial Inference for Multi-Sentence Video Description\",\"url\":\"https://www.semanticscholar.org/paper/6aa6932c22b9bd407e615ec2bfffc20cd88a9069\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1810.00671\",\"authors\":[{\"authorId\":\"2562211\",\"name\":\"Xiaoyu Shen\"},{\"authorId\":\"65915850\",\"name\":\"Hui Su\"},{\"authorId\":\"50135831\",\"name\":\"W. Li\"},{\"authorId\":\"2561225\",\"name\":\"D. Klakow\"}],\"doi\":\"10.18653/v1/D18-1463\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6d69b19ab452f3673732bb1c151cf800fc25ee69\",\"title\":\"Nexus Network: Connecting the Preceding and the Following in Dialogue Generation\",\"url\":\"https://www.semanticscholar.org/paper/6d69b19ab452f3673732bb1c151cf800fc25ee69\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9947219\",\"name\":\"Simion-Vlad Bogolin\"},{\"authorId\":\"50272388\",\"name\":\"Ioana Croitoru\"},{\"authorId\":\"1749627\",\"name\":\"M. Leordeanu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9348890ecbbfd7bb75667fa2014ebe6f4a5558b1\",\"title\":\"A hierarchical approach to vision-based language generation: from simple sentences to complex natural language\",\"url\":\"https://www.semanticscholar.org/paper/9348890ecbbfd7bb75667fa2014ebe6f4a5558b1\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"},{\"authorId\":\"1796216614\",\"name\":\"Siyu Huang\"},{\"authorId\":\"40518823\",\"name\":\"Haoyi Xiong\"},{\"authorId\":\"7824051\",\"name\":\"Xingjian Li\"},{\"authorId\":\"1721158\",\"name\":\"D. Dou\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"652885a326e1b5b978f4abeeb88e5fe518733f7e\",\"title\":\"Neighbours Matter: Image Captioning with Similar Images\",\"url\":\"https://www.semanticscholar.org/paper/652885a326e1b5b978f4abeeb88e5fe518733f7e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144081629\",\"name\":\"Mario G\\u00f3mez Mart\\u00ednez\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"faa8314259e9de1af8e841c265b0251531b32e04\",\"title\":\"Deep learning for image captioning: an encoder-decoder architecture with soft attention\",\"url\":\"https://www.semanticscholar.org/paper/faa8314259e9de1af8e841c265b0251531b32e04\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2003.10925\",\"authors\":[{\"authorId\":\"47577022\",\"name\":\"Nannan Li\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"16025ed0f452e62514d4705b7da1e9f78067d9e7\",\"title\":\"Learning Compact Reward for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/16025ed0f452e62514d4705b7da1e9f78067d9e7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145816931\",\"name\":\"Gaurav Verma\"},{\"authorId\":\"1519982037\",\"name\":\"Suryateja Bv\"},{\"authorId\":\"1519989202\",\"name\":\"Samagra Sharma\"},{\"authorId\":\"2881425\",\"name\":\"Balaji Vasan Srinivasan\"}],\"doi\":\"10.1145/3377325.3377487\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"893154dbcd6c6c6d1c4913002de37d6e739cf5f2\",\"title\":\"Generating need-adapted multimodal fragments\",\"url\":\"https://www.semanticscholar.org/paper/893154dbcd6c6c6d1c4913002de37d6e739cf5f2\",\"venue\":\"IUI\",\"year\":2020},{\"arxivId\":\"1903.03414\",\"authors\":[{\"authorId\":\"19171514\",\"name\":\"J. Yang\"},{\"authorId\":\"49846744\",\"name\":\"Bo Zhang\"}],\"doi\":\"10.3390/APP9102078\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bfc870926e1583f79be747ea1d8c6436b84d7396\",\"title\":\"Artificial Intelligence in Intelligent Tutoring Robots: A Systematic Review and Design Guidelines\",\"url\":\"https://www.semanticscholar.org/paper/bfc870926e1583f79be747ea1d8c6436b84d7396\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1805.07112\",\"authors\":[{\"authorId\":\"1828568\",\"name\":\"Chen Chen\"},{\"authorId\":\"39108991\",\"name\":\"Shuai Mu\"},{\"authorId\":\"1410650653\",\"name\":\"Wanpeng Xiao\"},{\"authorId\":\"1410066883\",\"name\":\"Zexiong Ye\"},{\"authorId\":\"1410052649\",\"name\":\"Liesi Wu\"},{\"authorId\":\"102396462\",\"name\":\"Fuming Ma\"},{\"authorId\":\"34974680\",\"name\":\"Q. Ju\"}],\"doi\":\"10.1609/aaai.v33i01.33018142\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0daa3a4118e00b9f63b2d014a16ff1bc3ca9ff7e\",\"title\":\"Improving Image Captioning with Conditional Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/0daa3a4118e00b9f63b2d014a16ff1bc3ca9ff7e\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8088602\",\"name\":\"Ehsan Abbasnejad\"},{\"authorId\":\"1885250234\",\"name\":\"Javen Shi\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"}],\"doi\":\"10.1007/s11263-020-01360-9\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7391db7c99c5b43428b093188a66a9e274d7ac08\",\"title\":\"GADE: A Generative Adversarial Approach to Density Estimation and its Applications\",\"url\":\"https://www.semanticscholar.org/paper/7391db7c99c5b43428b093188a66a9e274d7ac08\",\"venue\":\"International Journal of Computer Vision\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40913232\",\"name\":\"P. Chen\"},{\"authorId\":\"1381434830\",\"name\":\"Alfredo Cuzzocrea\"},{\"authorId\":\"46993406\",\"name\":\"Xiaoyong Du\"},{\"authorId\":\"144408238\",\"name\":\"Orhun Kara\"},{\"authorId\":\"152244126\",\"name\":\"Ting Liu\"},{\"authorId\":\"1731022\",\"name\":\"K. Sivalingam\"},{\"authorId\":\"145514738\",\"name\":\"D. Slezak\"},{\"authorId\":\"1704749\",\"name\":\"T. Washio\"},{\"authorId\":\"50031361\",\"name\":\"X. Yang\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"},{\"authorId\":\"145337089\",\"name\":\"S. Barbosa\"},{\"authorId\":\"144841444\",\"name\":\"Michelangelo Ceci\"},{\"authorId\":\"1725650\",\"name\":\"S. Ferilli\"},{\"authorId\":\"40291891\",\"name\":\"A. Poggi\"}],\"doi\":\"10.1007/978-3-030-39905-4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"267f2d6635177ff0b0983c560c5d513b10a30626\",\"title\":\"Digital Libraries: The Era of Big Data and Data Science: 16th Italian Research Conference on Digital Libraries, IRCDL 2020, Bari, Italy, January 30\\u201331, 2020, Proceedings\",\"url\":\"https://www.semanticscholar.org/paper/267f2d6635177ff0b0983c560c5d513b10a30626\",\"venue\":\"IRCDL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51933789\",\"name\":\"N. Ilinykh\"},{\"authorId\":\"2995275\",\"name\":\"Simon Dobnik\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4a8a490f8d3a7414444289b8802052eae3ebbe0c\",\"title\":\"When an Image Tells a Story: The Role of Visual and Semantic Information for Generating Paragraph Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/4a8a490f8d3a7414444289b8802052eae3ebbe0c\",\"venue\":\"INLG\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"2751871\",\"name\":\"J. Wan\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":\"10.1109/tpami.2020.3013834\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ba341f992ceb10d9a7f032ac6027f18ef5e5f895\",\"title\":\"On Diversity in Image Captioning: Metrics and Methods.\",\"url\":\"https://www.semanticscholar.org/paper/ba341f992ceb10d9a7f032ac6027f18ef5e5f895\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"2012.11696\",\"authors\":[{\"authorId\":\"1839363\",\"name\":\"Pierre L. Dognin\"},{\"authorId\":\"2576373\",\"name\":\"I. Melnyk\"},{\"authorId\":\"2211263\",\"name\":\"Youssef Mroueh\"},{\"authorId\":\"8350409\",\"name\":\"I. Padhi\"},{\"authorId\":\"2535094\",\"name\":\"Mattia Rigotti\"},{\"authorId\":\"153598395\",\"name\":\"J. Ross\"},{\"authorId\":\"1999174380\",\"name\":\"Yair Schiff\"},{\"authorId\":\"49832828\",\"name\":\"R. A. Young\"},{\"authorId\":\"2679155\",\"name\":\"Brian M. Belgodere\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5d4b265d7f80b185c618fb230ea14dcf909beed7\",\"title\":\"Image Captioning as an Assistive Technology: Lessons Learned from VizWiz 2020 Challenge\",\"url\":\"https://www.semanticscholar.org/paper/5d4b265d7f80b185c618fb230ea14dcf909beed7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2012.11635\",\"authors\":[{\"authorId\":\"47749889\",\"name\":\"M. Khalifa\"},{\"authorId\":\"2218938\",\"name\":\"Hady ElSahar\"},{\"authorId\":\"2954698\",\"name\":\"Marc Dymetman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b3aaf4770ff5ab02a468f9909f994cf7bb6c4898\",\"title\":\"A Distributional Approach to Controlled Text Generation\",\"url\":\"https://www.semanticscholar.org/paper/b3aaf4770ff5ab02a468f9909f994cf7bb6c4898\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2003.03749\",\"authors\":[{\"authorId\":\"92827207\",\"name\":\"J. Chen\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"}],\"doi\":\"10.1109/CVPR42600.2020.01090\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"96485bda4f4118da249cc8a898230281ac8040a7\",\"title\":\"Better Captioning With Sequence-Level Exploration\",\"url\":\"https://www.semanticscholar.org/paper/96485bda4f4118da249cc8a898230281ac8040a7\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152281902\",\"name\":\"S. Wu\"},{\"authorId\":\"2087470\",\"name\":\"S. Fan\"},{\"authorId\":\"1700911\",\"name\":\"Zhiqi Shen\"},{\"authorId\":\"145977143\",\"name\":\"Mohan S. Kankanhalli\"},{\"authorId\":\"1699730\",\"name\":\"Anthony K. H. Tung\"}],\"doi\":\"10.1145/3394171.3413589\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"35ba6ed07ef68db187674498e684de7f3e160716\",\"title\":\"Who You Are Decides How You Tell\",\"url\":\"https://www.semanticscholar.org/paper/35ba6ed07ef68db187674498e684de7f3e160716\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1711.07068\",\"authors\":[{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"82247c9e74ddebb4dce65560ee69620579358f2d\",\"title\":\"Diverse and Accurate Image Description Using a Variational Auto-Encoder with an Additive Gaussian Encoding Space\",\"url\":\"https://www.semanticscholar.org/paper/82247c9e74ddebb4dce65560ee69620579358f2d\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"14320047\",\"name\":\"C. Patil\"},{\"authorId\":\"34326205\",\"name\":\"Manasi S. Patwardhan\"}],\"doi\":\"10.1145/3383465\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9e081431cfbab4d5c8823efa2620ca0accfa124e\",\"title\":\"Visual Question Generation\",\"url\":\"https://www.semanticscholar.org/paper/9e081431cfbab4d5c8823efa2620ca0accfa124e\",\"venue\":\"ACM Comput. Surv.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144751998\",\"name\":\"C. He\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1145/3292058\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1b0ef7ccad215c682a784d1aec4988b675d779b9\",\"title\":\"Image Captioning With Visual-Semantic Double Attention\",\"url\":\"https://www.semanticscholar.org/paper/1b0ef7ccad215c682a784d1aec4988b675d779b9\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3158899\",\"name\":\"Mariam Bouchakwa\"},{\"authorId\":\"2135034\",\"name\":\"Yassine Ayadi\"},{\"authorId\":\"1784204\",\"name\":\"I. Amous\"}],\"doi\":\"10.1007/s11042-020-08862-1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"445df9ebc8c43c39faeaa58518383f980fdd0da9\",\"title\":\"A review on visual content-based and users\\u2019 tags-based image annotation: methods and techniques\",\"url\":\"https://www.semanticscholar.org/paper/445df9ebc8c43c39faeaa58518383f980fdd0da9\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"2007.06877\",\"authors\":[{\"authorId\":\"51175635\",\"name\":\"Jiuniu Wang\"},{\"authorId\":\"50232214\",\"name\":\"Wenjia Xu\"},{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":\"10.1007/978-3-030-58452-8_22\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e38274d1d544af5fad2cb814d62a028e2ff7437b\",\"title\":\"Compare and Reweight: Distinctive Image Captioning Using Similar Images Sets\",\"url\":\"https://www.semanticscholar.org/paper/e38274d1d544af5fad2cb814d62a028e2ff7437b\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8088602\",\"name\":\"Ehsan Abbasnejad\"},{\"authorId\":\"3177281\",\"name\":\"Qinfeng Shi\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"}],\"doi\":\"10.1109/CVPR.2019.01104\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2587270fb2c80e6e827eb10221528c4f45dfb760\",\"title\":\"A Generative Adversarial Density Estimator\",\"url\":\"https://www.semanticscholar.org/paper/2587270fb2c80e6e827eb10221528c4f45dfb760\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33698309\",\"name\":\"Zhong-Qiu Zhao\"},{\"authorId\":\"49697077\",\"name\":\"Yue-Lin Sun\"},{\"authorId\":\"1977865899\",\"name\":\"Nan-Xun Wang\"},{\"authorId\":\"144963976\",\"name\":\"Weidong Tian\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206632\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"03a53b48a2c869658f969856acd2830711dc9ba9\",\"title\":\"Extricating from GroundTruth: An Unpaired Learning Based Evaluation Metric for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/03a53b48a2c869658f969856acd2830711dc9ba9\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26982950\",\"name\":\"Longteng Guo\"},{\"authorId\":\"1749850\",\"name\":\"J. Liu\"},{\"authorId\":\"145523338\",\"name\":\"Peng Yao\"},{\"authorId\":\"49298906\",\"name\":\"Jiangwei Li\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1109/CVPR.2019.00433\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4fef1313fd4948fed09dee318e2e231216c4fb3b\",\"title\":\"MSCap: Multi-Style Image Captioning With Unpaired Stylized Text\",\"url\":\"https://www.semanticscholar.org/paper/4fef1313fd4948fed09dee318e2e231216c4fb3b\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1839363\",\"name\":\"Pierre L. Dognin\"},{\"authorId\":\"2576373\",\"name\":\"I. Melnyk\"},{\"authorId\":\"2211263\",\"name\":\"Youssef Mroueh\"},{\"authorId\":\"153598395\",\"name\":\"J. Ross\"},{\"authorId\":\"2500466\",\"name\":\"Tom Sercu\"}],\"doi\":\"10.1109/CVPR.2019.01071\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"24fdb40c354599ee33a25530c3fa7b9ebc75e840\",\"title\":\"Adversarial Semantic Alignment for Improved Image Captions\",\"url\":\"https://www.semanticscholar.org/paper/24fdb40c354599ee33a25530c3fa7b9ebc75e840\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2007.11731\",\"authors\":[{\"authorId\":\"1828787912\",\"name\":\"Yiwu Zhong\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"101777533\",\"name\":\"J. Chen\"},{\"authorId\":null,\"name\":\"Dong Yu\"},{\"authorId\":\"47002659\",\"name\":\"Yanchao Li\"}],\"doi\":\"10.1007/978-3-030-58568-6_13\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"66ed8795eb6de5d2a6b204baac9378d6d28136cc\",\"title\":\"Comprehensive Image Captioning via Scene Graph Decomposition\",\"url\":\"https://www.semanticscholar.org/paper/66ed8795eb6de5d2a6b204baac9378d6d28136cc\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1805.00063\",\"authors\":[{\"authorId\":\"1839363\",\"name\":\"Pierre L. Dognin\"},{\"authorId\":\"2576373\",\"name\":\"I. Melnyk\"},{\"authorId\":\"2211263\",\"name\":\"Youssef Mroueh\"},{\"authorId\":\"39320489\",\"name\":\"J. Ross\"},{\"authorId\":\"2500466\",\"name\":\"Tom Sercu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"240ed539e96b9a304de54c904b375a9870496bf7\",\"title\":\"Improved Image Captioning with Adversarial Semantic Alignment\",\"url\":\"https://www.semanticscholar.org/paper/240ed539e96b9a304de54c904b375a9870496bf7\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3075017\",\"name\":\"Hongye Tan\"},{\"authorId\":\"49357071\",\"name\":\"Z. Yan\"},{\"authorId\":\"47370157\",\"name\":\"R. Li\"},{\"authorId\":\"81275118\",\"name\":\"Yimin Jing\"}],\"doi\":\"10.1360/N112018-00158\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8c6e184f5d76e94bc50647f087fbdabfdec81358\",\"title\":\"Towards creative language generation: exploring Chinese humor generation\",\"url\":\"https://www.semanticscholar.org/paper/8c6e184f5d76e94bc50647f087fbdabfdec81358\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2010.03855\",\"authors\":[{\"authorId\":\"40622539\",\"name\":\"Dong-Jin Kim\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"49331178\",\"name\":\"Jinsoo Choi\"},{\"authorId\":\"145017149\",\"name\":\"In So Kweon\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0bda89ebb8cbec54afb013349c97a8264b36fee0\",\"title\":\"Dense Relational Image Captioning via Multi-task Triple-Stream Networks\",\"url\":\"https://www.semanticscholar.org/paper/0bda89ebb8cbec54afb013349c97a8264b36fee0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.09580\",\"authors\":[{\"authorId\":\"41036094\",\"name\":\"C. Deng\"},{\"authorId\":\"46649124\",\"name\":\"Ning Ding\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"},{\"authorId\":\"1509240145\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1007/978-3-030-58601-0_42\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2320f853059c29ce7e70409fa559074d727da5a2\",\"title\":\"Length-Controllable Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/2320f853059c29ce7e70409fa559074d727da5a2\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1806.06422\",\"authors\":[{\"authorId\":\"50355189\",\"name\":\"Yin Cui\"},{\"authorId\":\"29983981\",\"name\":\"Guandao Yang\"},{\"authorId\":\"2799898\",\"name\":\"Andreas Veit\"},{\"authorId\":\"144247007\",\"name\":\"X. Huang\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"}],\"doi\":\"10.1109/CVPR.2018.00608\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6d3d61ef9b5ff6d41badbc3d40ea23acbbc9c3fe\",\"title\":\"Learning to Evaluate Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6d3d61ef9b5ff6d41badbc3d40ea23acbbc9c3fe\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"eccfd6174709c285d62b11fb3da9b68d485ca883\",\"title\":\"Integrating Rule-based Entity Masking into Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/eccfd6174709c285d62b11fb3da9b68d485ca883\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2004.03708\",\"authors\":[{\"authorId\":\"80389349\",\"name\":\"Zhuowan Li\"},{\"authorId\":\"2536742\",\"name\":\"Quan Hung Tran\"},{\"authorId\":\"2712573\",\"name\":\"Long Mai\"},{\"authorId\":\"145527698\",\"name\":\"Zhe Lin\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.1109/CVPR42600.2020.00350\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"477b70ed4753745e2700dd2791c3a5fb966f8b64\",\"title\":\"Context-Aware Group Captioning via Self-Attention and Contrastive Features\",\"url\":\"https://www.semanticscholar.org/paper/477b70ed4753745e2700dd2791c3a5fb966f8b64\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1805.12589\",\"authors\":[{\"authorId\":\"31121723\",\"name\":\"A. Deshpande\"},{\"authorId\":\"29956361\",\"name\":\"Jyoti Aneja\"},{\"authorId\":\"39709900\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"144016256\",\"name\":\"D. Forsyth\"}],\"doi\":\"10.1109/CVPR.2019.01095\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e7fe886600399448f3282c8da8fd98ab7e50eae3\",\"title\":\"Fast, Diverse and Accurate Image Captioning Guided by Part-Of-Speech\",\"url\":\"https://www.semanticscholar.org/paper/e7fe886600399448f3282c8da8fd98ab7e50eae3\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1392406002\",\"name\":\"Arturs Polis\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4bfeae734bced5b2613af9f7d8271354b614e08e\",\"title\":\"Paragraph-length image captioning using hierarchical recurrent neural networks\",\"url\":\"https://www.semanticscholar.org/paper/4bfeae734bced5b2613af9f7d8271354b614e08e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1809.02156\",\"authors\":[{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"40895688\",\"name\":\"Kaylee Burns\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.18653/v1/D18-1437\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"4921243268c81d0d6db99053a9d004852225a622\",\"title\":\"Object Hallucination in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/4921243268c81d0d6db99053a9d004852225a622\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"2009.03015\",\"authors\":[{\"authorId\":\"1383113350\",\"name\":\"Sahar Abdelnabi\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f7fb02529951ed7bcb150f8ed4488b0653758109\",\"title\":\"Adversarial Watermarking Transformer: Towards Tracing Text Provenance with Data Hiding\",\"url\":\"https://www.semanticscholar.org/paper/f7fb02529951ed7bcb150f8ed4488b0653758109\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3192572\",\"name\":\"Emiel van Miltenburg\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"1791713\",\"name\":\"Piek T. J. M. Vossen\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"fe400b814cfea5538887c92040f1ab0d6fb45bfe\",\"title\":\"Measuring the Diversity of Automatic Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/fe400b814cfea5538887c92040f1ab0d6fb45bfe\",\"venue\":\"COLING\",\"year\":2018},{\"arxivId\":\"1903.12020\",\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":\"10.1109/CVPR.2019.00432\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"90579a68e46b772a8e9aaca8ecbd06942d0b9b35\",\"title\":\"Describing Like Humans: On Diversity in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/90579a68e46b772a8e9aaca8ecbd06942d0b9b35\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2004.10796\",\"authors\":[{\"authorId\":\"4868335\",\"name\":\"J. Park\"},{\"authorId\":\"1857797\",\"name\":\"Chandra Bhagavatula\"},{\"authorId\":\"3012475\",\"name\":\"R. Mottaghi\"},{\"authorId\":\"47465174\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6966b0018daffa49eb2c38e68eb8964d56440233\",\"title\":\"Visual Commonsense Graphs: Reasoning about the Dynamic Context of a Still Image\",\"url\":\"https://www.semanticscholar.org/paper/6966b0018daffa49eb2c38e68eb8964d56440233\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.00387\",\"authors\":[{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"},{\"authorId\":\"1490938689\",\"name\":\"Peng Wang\"},{\"authorId\":\"49018095\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1109/cvpr42600.2020.00998\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b4916e339caef2d2a98e633e1f0b2144e2b0c9e2\",\"title\":\"Say As You Wish: Fine-Grained Control of Image Caption Generation With Abstract Scene Graphs\",\"url\":\"https://www.semanticscholar.org/paper/b4916e339caef2d2a98e633e1f0b2144e2b0c9e2\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1906.00283\",\"authors\":[{\"authorId\":\"7437104\",\"name\":\"Chih-Yao Ma\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"9202076\",\"name\":\"G. Al-Regib\"},{\"authorId\":\"122175026\",\"name\":\"P\\u00e9ter Vajda\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"145276578\",\"name\":\"Z. Kira\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"93c7166af45c86caec363e0b84dfd85ed3b51acc\",\"title\":\"Learning to Generate Grounded Image Captions without Localization Supervision\",\"url\":\"https://www.semanticscholar.org/paper/93c7166af45c86caec363e0b84dfd85ed3b51acc\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1809.06227\",\"authors\":[{\"authorId\":\"3441420\",\"name\":\"Tszhang Guo\"},{\"authorId\":\"3307026\",\"name\":\"S. Chang\"},{\"authorId\":\"2482533\",\"name\":\"Mo Yu\"},{\"authorId\":\"144654778\",\"name\":\"K. Bai\"}],\"doi\":\"10.18653/v1/D18-1083\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"a78199a2cc678818489087454fe1150db4870196\",\"title\":\"Improving Reinforcement Learning Based Image Captioning with Natural Language Prior\",\"url\":\"https://www.semanticscholar.org/paper/a78199a2cc678818489087454fe1150db4870196\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"2009.03949\",\"authors\":[{\"authorId\":\"1699605396\",\"name\":\"Zeyu Wang\"},{\"authorId\":\"114200472\",\"name\":\"Berthy Feng\"},{\"authorId\":\"144958935\",\"name\":\"Karthik Narasimhan\"},{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"}],\"doi\":\"10.1007/978-3-030-58571-6_37\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"81be56a5783552d5b32463b392ff0499dd86a5ab\",\"title\":\"Towards Unique and Informative Captioning of Images\",\"url\":\"https://www.semanticscholar.org/paper/81be56a5783552d5b32463b392ff0499dd86a5ab\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.10662\",\"authors\":[{\"authorId\":\"69544685\",\"name\":\"Jie Wu\"},{\"authorId\":\"1765674\",\"name\":\"Tianshui Chen\"},{\"authorId\":\"1721715\",\"name\":\"Hefeng Wu\"},{\"authorId\":\"10665619\",\"name\":\"Z. Yang\"},{\"authorId\":\"1773818\",\"name\":\"Guangchun Luo\"},{\"authorId\":\"49478124\",\"name\":\"L. Lin\"}],\"doi\":\"10.1109/tmm.2020.3011317\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f0edc8eb2d2b53482faf34906dacf996bc4127f6\",\"title\":\"Fine-Grained Image Captioning with Global-Local Discriminative Objective\",\"url\":\"https://www.semanticscholar.org/paper/f0edc8eb2d2b53482faf34906dacf996bc4127f6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1903.05942\",\"authors\":[{\"authorId\":\"40622539\",\"name\":\"Dong-Jin Kim\"},{\"authorId\":\"49331178\",\"name\":\"Jinsoo Choi\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"2398271\",\"name\":\"In-So Kweon\"}],\"doi\":\"10.1109/CVPR.2019.00643\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"79de42d6ca8d1bf2952c46eb74e6e0561f979257\",\"title\":\"Dense Relational Captioning: Triple-Stream Networks for Relationship-Based Captioning\",\"url\":\"https://www.semanticscholar.org/paper/79de42d6ca8d1bf2952c46eb74e6e0561f979257\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1711.01921\",\"authors\":[{\"authorId\":\"38314306\",\"name\":\"Rakshith Shetty\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5a63a7fcef8d7c6c65653b62e9a4ffb1da0feb81\",\"title\":\"$A^{4}NT$: Author Attribute Anonymity by Adversarial Training of Neural Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/5a63a7fcef8d7c6c65653b62e9a4ffb1da0feb81\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151017519\",\"name\":\"Gilad Vered\"},{\"authorId\":\"151504666\",\"name\":\"Gal Oren\"},{\"authorId\":\"34815079\",\"name\":\"Y. Atzmon\"},{\"authorId\":\"1732280\",\"name\":\"Gal Chechik\"}],\"doi\":\"10.1109/ICCV.2019.00899\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6fb03dcb0d57eb74d3395e598ae1712e3e926ec2\",\"title\":\"Joint Optimization for Cooperative Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6fb03dcb0d57eb74d3395e598ae1712e3e926ec2\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1711.06666\",\"authors\":[{\"authorId\":\"9085797\",\"name\":\"Keren Ye\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":\"10.1007/978-3-030-01267-0_51\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e1be2c16060974f66e5366872ebbee21325075e8\",\"title\":\"ADVISE: Symbolism and External Knowledge for Decoding Advertisements\",\"url\":\"https://www.semanticscholar.org/paper/e1be2c16060974f66e5366872ebbee21325075e8\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2011.00966\",\"authors\":[{\"authorId\":\"32370882\",\"name\":\"Shweta Mahajan\"},{\"authorId\":\"49863405\",\"name\":\"S. Roth\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7d805e35f17dab7382748130a2ca1bda629cdceb\",\"title\":\"Diverse Image Captioning with Context-Object Split Latent Spaces\",\"url\":\"https://www.semanticscholar.org/paper/7d805e35f17dab7382748130a2ca1bda629cdceb\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2007.11690\",\"authors\":[{\"authorId\":\"3219864\",\"name\":\"Aditya Mogadala\"},{\"authorId\":\"2562211\",\"name\":\"Xiaoyu Shen\"},{\"authorId\":\"2561225\",\"name\":\"D. Klakow\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"54a42098b34c2602305b03fe07b7db82b789f5db\",\"title\":\"Integrating Image Captioning with Rule-based Entity Masking\",\"url\":\"https://www.semanticscholar.org/paper/54a42098b34c2602305b03fe07b7db82b789f5db\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.03338\",\"authors\":[{\"authorId\":\"40651988\",\"name\":\"Marzieh Heidari\"},{\"authorId\":\"2862462\",\"name\":\"Mehdi Ghatee\"},{\"authorId\":\"1780566\",\"name\":\"A. Nickabadi\"},{\"authorId\":\"1796299590\",\"name\":\"Arash Pourhasan Nezhad\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"20b332af8399233b5fc33a7e7f98538bd4a82ab0\",\"title\":\"Diverse and Styled Image Captioning Using SVD-Based Mixture of Recurrent Experts\",\"url\":\"https://www.semanticscholar.org/paper/20b332af8399233b5fc33a7e7f98538bd4a82ab0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.08189\",\"authors\":[{\"authorId\":\"2283009\",\"name\":\"W. Chen\"},{\"authorId\":\"46315247\",\"name\":\"W. Wang\"},{\"authorId\":\"87109212\",\"name\":\"Li Liu\"},{\"authorId\":\"1731570\",\"name\":\"M. Lew\"}],\"doi\":\"10.1016/j.neucom.2020.10.042\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"61ba6969078b7358c61f7eb93b4150ab0e4f329b\",\"title\":\"New Ideas and Trends in Deep Multimodal Content Understanding: A Review\",\"url\":\"https://www.semanticscholar.org/paper/61ba6969078b7358c61f7eb93b4150ab0e4f329b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1806.02934\",\"authors\":[{\"authorId\":\"51043791\",\"name\":\"A. Kalyan\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"145721096\",\"name\":\"A. Kannan\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d2237f995d280edb8a47e27886261709ea3f654a\",\"title\":\"Learn from Your Neighbor: Learning Multi-modal Mappings from Sparse Annotations\",\"url\":\"https://www.semanticscholar.org/paper/d2237f995d280edb8a47e27886261709ea3f654a\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145359993\",\"name\":\"Fabian Karl\"},{\"authorId\":\"2388081\",\"name\":\"Mikko Lauri\"},{\"authorId\":\"31565315\",\"name\":\"Chris Biemann\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dfd1533d49d0213278d3d3301491cbe40f4d100b\",\"title\":\"Creating Information-maximizing Natural Language Messages Through Image Captioning-Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/dfd1533d49d0213278d3d3301491cbe40f4d100b\",\"venue\":\"KONVENS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11611009\",\"name\":\"Chun-ye Li\"},{\"authorId\":\"78507285\",\"name\":\"Zhiping Zhou\"},{\"authorId\":\"41052788\",\"name\":\"W. Zhang\"}],\"doi\":\"10.1007/s11042-019-08165-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0a59a5ed672dda9f45187bdb7727922e21f24fd9\",\"title\":\"An image retrieval method based on semantic matching with multiple positional representations\",\"url\":\"https://www.semanticscholar.org/paper/0a59a5ed672dda9f45187bdb7727922e21f24fd9\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":\"1810.07391\",\"authors\":[{\"authorId\":\"3422056\",\"name\":\"Xuanli He\"},{\"authorId\":\"2561045\",\"name\":\"Gholamreza Haffari\"},{\"authorId\":\"144739074\",\"name\":\"Mohammad Norouzi\"}],\"doi\":\"10.18653/v1/K18-1056\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"01ea10284faa0a173e553588a857a44e101d920b\",\"title\":\"Sequence to Sequence Mixture Model for Diverse Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/01ea10284faa0a173e553588a857a44e101d920b\",\"venue\":\"CoNLL\",\"year\":2018},{\"arxivId\":\"1803.08314\",\"authors\":[{\"authorId\":\"46522599\",\"name\":\"Xihui Liu\"},{\"authorId\":\"49404547\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"144478188\",\"name\":\"J. Shao\"},{\"authorId\":\"143982372\",\"name\":\"Dapeng Chen\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1007/978-3-030-01267-0_21\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"caab1c1d53718315f54bc4df42eb9a727fa18483\",\"title\":\"Show, Tell and Discriminate: Image Captioning by Self-retrieval with Partially Labeled Data\",\"url\":\"https://www.semanticscholar.org/paper/caab1c1d53718315f54bc4df42eb9a727fa18483\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2002.06661\",\"authors\":[{\"authorId\":\"32370882\",\"name\":\"Shweta Mahajan\"},{\"authorId\":\"1730400\",\"name\":\"Iryna Gurevych\"},{\"authorId\":\"49863405\",\"name\":\"S. Roth\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"87415957ec3aa3ae6756e3e7d22873cd9fc74c51\",\"title\":\"Latent Normalizing Flows for Many-to-Many Cross-Domain Mappings\",\"url\":\"https://www.semanticscholar.org/paper/87415957ec3aa3ae6756e3e7d22873cd9fc74c51\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145704540\",\"name\":\"Li Ren\"},{\"authorId\":\"2272096\",\"name\":\"Guo-Jun Qi\"},{\"authorId\":\"66719728\",\"name\":\"Kien A. Hua\"}],\"doi\":\"10.1109/WACV.2019.00034\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"449b9189e3058d33f871dfd3b07cc75a717038f7\",\"title\":\"Improving Diversity of Image Captioning Through Variational Autoencoders and Adversarial Learning\",\"url\":\"https://www.semanticscholar.org/paper/449b9189e3058d33f871dfd3b07cc75a717038f7\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":\"1808.05599\",\"authors\":[{\"authorId\":\"41017887\",\"name\":\"Yi-Lin Tuan\"},{\"authorId\":\"1706104\",\"name\":\"Hung-yi Lee\"}],\"doi\":\"10.1109/TASLP.2019.2896437\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"484ffd765876bc7f82a9eacff68ca20dbd4fcc34\",\"title\":\"Improving Conditional Sequence Generative Adversarial Networks by Stepwise Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/484ffd765876bc7f82a9eacff68ca20dbd4fcc34\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2019},{\"arxivId\":\"2002.11848\",\"authors\":[{\"authorId\":\"3212867\",\"name\":\"R. Luo\"},{\"authorId\":\"2490189\",\"name\":\"Gregory Shakhnarovich\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9ed8c8ee62b0afc403e44c29f6deedf6632885d5\",\"title\":\"Analysis of diversity-accuracy tradeoff in image captioning\",\"url\":\"https://www.semanticscholar.org/paper/9ed8c8ee62b0afc403e44c29f6deedf6632885d5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.05132\",\"authors\":[{\"authorId\":\"145196525\",\"name\":\"A. Jabbar\"},{\"authorId\":\"121856937\",\"name\":\"X. Li\"},{\"authorId\":\"1739254961\",\"name\":\"Bourahla Omar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d54d8c402785006faaf5de19e81f04eb484a3aa2\",\"title\":\"A Survey on Generative Adversarial Networks: Variants, Applications, and Training\",\"url\":\"https://www.semanticscholar.org/paper/d54d8c402785006faaf5de19e81f04eb484a3aa2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1706.01399\",\"authors\":[{\"authorId\":\"40170001\",\"name\":\"Ofir Press\"},{\"authorId\":\"48319922\",\"name\":\"A. Bar\"},{\"authorId\":\"50757607\",\"name\":\"Ben Bogin\"},{\"authorId\":\"1750652\",\"name\":\"Jonathan Berant\"},{\"authorId\":\"145128145\",\"name\":\"Lior Wolf\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a8176a160777bfe82b1c67506835c60073e6fbe8\",\"title\":\"Language Generation with Recurrent Generative Adversarial Networks without Pre-training\",\"url\":\"https://www.semanticscholar.org/paper/a8176a160777bfe82b1c67506835c60073e6fbe8\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738647655\",\"name\":\"Emiel van Miltenburg\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"adf57a2bdcffc38238e64d4ae797c12405281173\",\"title\":\"How Do Image Description Systems Describe People? A Targeted Assessment of System Competence in the PEOPLE-domain\",\"url\":\"https://www.semanticscholar.org/paper/adf57a2bdcffc38238e64d4ae797c12405281173\",\"venue\":\"LANTERN\",\"year\":2020},{\"arxivId\":\"1909.04402\",\"authors\":[{\"authorId\":\"1387994359\",\"name\":\"Mitja Nikolaus\"},{\"authorId\":\"30671790\",\"name\":\"M. Abdou\"},{\"authorId\":\"48024953\",\"name\":\"Matthew Lamm\"},{\"authorId\":\"19509693\",\"name\":\"Rahul Aralikatte\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"}],\"doi\":\"10.18653/v1/K19-1009\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"11557ee241f6b5dc0a8c62bb8014c0111bbe45ba\",\"title\":\"Compositional Generalization in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/11557ee241f6b5dc0a8c62bb8014c0111bbe45ba\",\"venue\":\"CoNLL\",\"year\":2019},{\"arxivId\":\"1706.01554\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"145721096\",\"name\":\"A. Kannan\"},{\"authorId\":\"145743311\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8cdd241b474bf7b0632162403ac2a3c4799252ad\",\"title\":\"Best of Both Worlds: Transferring Knowledge from Discriminative Learning to a Generative Visual Dialog Model\",\"url\":\"https://www.semanticscholar.org/paper/8cdd241b474bf7b0632162403ac2a3c4799252ad\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2042707165\",\"name\":\"Anfal Attai\"},{\"authorId\":\"145973534\",\"name\":\"Ashraf Elnagar\"}],\"doi\":\"10.1109/IIT50501.2020.9299027\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"002544729825daf6843a471ccb22d446969511b7\",\"title\":\"A survey on Arabic Image Captioning Systems Using Deep Learning Models\",\"url\":\"https://www.semanticscholar.org/paper/002544729825daf6843a471ccb22d446969511b7\",\"venue\":\"2020 14th International Conference on Innovations in Information Technology (IIT)\",\"year\":2020}],\"corpusId\":6093112,\"doi\":\"10.1109/ICCV.2017.445\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":13,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"1c0a6854b793ca8ad281513c184318b73d4868c4\",\"references\":[{\"arxivId\":\"1701.06547\",\"authors\":[{\"authorId\":\"5183779\",\"name\":\"J. Li\"},{\"authorId\":\"145768639\",\"name\":\"Will Monroe\"},{\"authorId\":\"10238549\",\"name\":\"Tianlin Shi\"},{\"authorId\":\"152857609\",\"name\":\"S\\u00e9bastien Jean\"},{\"authorId\":\"1863425\",\"name\":\"Alan Ritter\"},{\"authorId\":\"1746807\",\"name\":\"Dan Jurafsky\"}],\"doi\":\"10.18653/v1/D17-1230\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"176f1d608b918eec8dc4b75e7b6e0acaba84a447\",\"title\":\"Adversarial Learning for Neural Dialogue Generation\",\"url\":\"https://www.semanticscholar.org/paper/176f1d608b918eec8dc4b75e7b6e0acaba84a447\",\"venue\":\"EMNLP\",\"year\":2017},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"144369161\",\"name\":\"Wei Qiu\"},{\"authorId\":\"144889265\",\"name\":\"Ivan Titov\"},{\"authorId\":\"1727272\",\"name\":\"Stefan Thater\"},{\"authorId\":\"1717560\",\"name\":\"Manfred Pinkal\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1109/ICCV.2013.61\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e8cd37fbd8bd5e690eef5861cf92af8e002d4533\",\"title\":\"Translating Video Content to Natural Language Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/e8cd37fbd8bd5e690eef5861cf92af8e002d4533\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3090304\",\"name\":\"Zhuhao Wang\"},{\"authorId\":\"144894849\",\"name\":\"Fei Wu\"},{\"authorId\":\"1776903\",\"name\":\"Weiming Lu\"},{\"authorId\":\"145974111\",\"name\":\"Jun Xiao\"},{\"authorId\":\"38979129\",\"name\":\"Xi Li\"},{\"authorId\":\"3431212\",\"name\":\"Zitong Zhang\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"39e55283e6eb3f0f9db07cf1b20e0de8d5aac10e\",\"title\":\"Diverse Image Captioning via GroupTalk\",\"url\":\"https://www.semanticscholar.org/paper/39e55283e6eb3f0f9db07cf1b20e0de8d5aac10e\",\"venue\":\"IJCAI\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47130333\",\"name\":\"Siqi Liu\"},{\"authorId\":\"39815369\",\"name\":\"Z. Zhu\"},{\"authorId\":\"145361612\",\"name\":\"N. Ye\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":\"10.1109/ICCV.2017.100\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"163a474747fd63ab62ae586711fa5e5a2ac91bd8\",\"title\":\"Improved Image Captioning via Policy Gradient optimization of SPIDEr\",\"url\":\"https://www.semanticscholar.org/paper/163a474747fd63ab62ae586711fa5e5a2ac91bd8\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38314306\",\"name\":\"Rakshith Shetty\"},{\"authorId\":\"143852685\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"1708642\",\"name\":\"Jorma T. Laaksonen\"}],\"doi\":\"10.1145/2983563.2983571\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d6d6edce271935feec96484d0e1f16dcc24973fd\",\"title\":\"Exploiting Scene Context for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/d6d6edce271935feec96484d0e1f16dcc24973fd\",\"venue\":\"iV&L-MM@MM\",\"year\":2016},{\"arxivId\":\"1603.08507\",\"authors\":[{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"2893664\",\"name\":\"Zeynep Akata\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1007/978-3-319-46493-0_1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ecf551d532d0e9cfb252a1bea04d14db620bc488\",\"title\":\"Generating Visual Explanations\",\"url\":\"https://www.semanticscholar.org/paper/ecf551d532d0e9cfb252a1bea04d14db620bc488\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1511.06434\",\"authors\":[{\"authorId\":\"38909097\",\"name\":\"A. Radford\"},{\"authorId\":\"2096458\",\"name\":\"Luke Metz\"},{\"authorId\":\"2127604\",\"name\":\"Soumith Chintala\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8388f1be26329fa45e5807e968a641ce170ea078\",\"title\":\"Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/8388f1be26329fa45e5807e968a641ce170ea078\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":\"1411.5726\",\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2015.7299087\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"258986132bf17755fe8263e42429fe73218c1534\",\"title\":\"CIDEr: Consensus-based image description evaluation\",\"url\":\"https://www.semanticscholar.org/paper/258986132bf17755fe8263e42429fe73218c1534\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40410858\",\"name\":\"R. J. Williams\"}],\"doi\":\"10.1007/BF00992696\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4c915c1eecb217c123a36dc6d3ce52d12c742614\",\"title\":\"Simple statistical gradient-following algorithms for connectionist reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/4c915c1eecb217c123a36dc6d3ce52d12c742614\",\"venue\":\"Machine Learning\",\"year\":2004},{\"arxivId\":\"1611.01646\",\"authors\":[{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/ICCV.2017.524\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5785466bc14529e94e54baa4ed051f7037f3b1d3\",\"title\":\"Boosting Image Captioning with Attributes\",\"url\":\"https://www.semanticscholar.org/paper/5785466bc14529e94e54baa4ed051f7037f3b1d3\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1611.07004\",\"authors\":[{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"1822702\",\"name\":\"Tinghui Zhou\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1109/CVPR.2017.632\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"8acbe90d5b852dadea7810345451a99608ee54c7\",\"title\":\"Image-to-Image Translation with Conditional Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/8acbe90d5b852dadea7810345451a99608ee54c7\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1511.05101\",\"authors\":[{\"authorId\":\"3108066\",\"name\":\"Ferenc Husz\\u00e1r\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0e4a97a0ccbf699272e3d6dc25b6fe16eb35382d\",\"title\":\"How (not) to Train your Generative Model: Scheduled Sampling, Likelihood, Adversary?\",\"url\":\"https://www.semanticscholar.org/paper/0e4a97a0ccbf699272e3d6dc25b6fe16eb35382d\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1506.05751\",\"authors\":[{\"authorId\":\"40081727\",\"name\":\"Emily L. Denton\"},{\"authorId\":\"2127604\",\"name\":\"Soumith Chintala\"},{\"authorId\":\"3149531\",\"name\":\"Arthur Szlam\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"47900aca2f0b50da3010ad59b394c870f0e6c02e\",\"title\":\"Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/47900aca2f0b50da3010ad59b394c870f0e6c02e\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1511.06732\",\"authors\":[{\"authorId\":\"1706809\",\"name\":\"Marc'Aurelio Ranzato\"},{\"authorId\":\"3295092\",\"name\":\"S. Chopra\"},{\"authorId\":\"2325985\",\"name\":\"M. Auli\"},{\"authorId\":\"2563432\",\"name\":\"W. Zaremba\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"35c1668dc64d24a28c6041978e5fcca754eb2f4b\",\"title\":\"Sequence Level Training with Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/35c1668dc64d24a28c6041978e5fcca754eb2f4b\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":\"1607.08822\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1007/978-3-319-46454-1_24\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1c54acd7d9ed8017acdc5674c9b7faac738fd651\",\"title\":\"SPICE: Semantic Propositional Image Caption Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/1c54acd7d9ed8017acdc5674c9b7faac738fd651\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1612.00370\",\"authors\":[{\"authorId\":\"47130333\",\"name\":\"Siqi Liu\"},{\"authorId\":\"39815369\",\"name\":\"Z. Zhu\"},{\"authorId\":\"145361612\",\"name\":\"N. Ye\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":\"10.1109/ICCV.2017.100\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"665a311c538fc021c27acd3953f171924cc5905c\",\"title\":\"Optimization of image description metrics using policy gradient methods\",\"url\":\"https://www.semanticscholar.org/paper/665a311c538fc021c27acd3953f171924cc5905c\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1704.03493\",\"authors\":[{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"3095572\",\"name\":\"Ziyu Zhang\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1109/CVPR.2017.575\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"390cac0a7e2f90c8efb12a1a9ff850ef386e5db6\",\"title\":\"Creativity: Generating Diverse Questions Using Variational Autoencoders\",\"url\":\"https://www.semanticscholar.org/paper/390cac0a7e2f90c8efb12a1a9ff850ef386e5db6\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1606.03498\",\"authors\":[{\"authorId\":\"2887364\",\"name\":\"Tim Salimans\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"2563432\",\"name\":\"W. Zaremba\"},{\"authorId\":\"34415167\",\"name\":\"Vicki Cheung\"},{\"authorId\":\"38909097\",\"name\":\"A. Radford\"},{\"authorId\":\"41192764\",\"name\":\"Xi Chen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"571b0750085ae3d939525e62af510ee2cee9d5ea\",\"title\":\"Improved Techniques for Training GANs\",\"url\":\"https://www.semanticscholar.org/paper/571b0750085ae3d939525e62af510ee2cee9d5ea\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1511.05440\",\"authors\":[{\"authorId\":\"143949035\",\"name\":\"Micha\\u00ebl Mathieu\"},{\"authorId\":\"2341378\",\"name\":\"C. Couprie\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"17fa1c2a24ba8f731c8b21f1244463bc4b465681\",\"title\":\"Deep multi-scale video prediction beyond mean square error\",\"url\":\"https://www.semanticscholar.org/paper/17fa1c2a24ba8f731c8b21f1244463bc4b465681\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":\"1506.03099\",\"authors\":[{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"3111912\",\"name\":\"Navdeep Jaitly\"},{\"authorId\":\"1846258\",\"name\":\"Noam Shazeer\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"df137487e20ba7c6e1e2b9a1e749f2a578b5ad99\",\"title\":\"Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/df137487e20ba7c6e1e2b9a1e749f2a578b5ad99\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1703.06029\",\"authors\":[{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/ICCV.2017.323\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"24dc571a49d3431e8cb1f1008f86d5dd5b7a1613\",\"title\":\"Towards Diverse and Natural Image Descriptions via a Conditional GAN\",\"url\":\"https://www.semanticscholar.org/paper/24dc571a49d3431e8cb1f1008f86d5dd5b7a1613\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1612.00563\",\"authors\":[{\"authorId\":\"2071376\",\"name\":\"Steven J. Rennie\"},{\"authorId\":\"2293163\",\"name\":\"E. Marcheret\"},{\"authorId\":\"2211263\",\"name\":\"Youssef Mroueh\"},{\"authorId\":\"39320489\",\"name\":\"J. Ross\"},{\"authorId\":\"1782589\",\"name\":\"V. Goel\"}],\"doi\":\"10.1109/CVPR.2017.131\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6c8353697cdbb98dfba4f493875778c4286d3e3a\",\"title\":\"Self-Critical Sequence Training for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6c8353697cdbb98dfba4f493875778c4286d3e3a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145564333\",\"name\":\"G. Kulkarni\"},{\"authorId\":\"3128210\",\"name\":\"Visruth Premraj\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"2985883\",\"name\":\"Sagnik Dhar\"},{\"authorId\":\"50341924\",\"name\":\"Siming Li\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/TPAMI.2012.162\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5cb6700d94c6118ee13f4f4fecac99f111189812\",\"title\":\"BabyTalk: Understanding and Generating Simple Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/5cb6700d94c6118ee13f4f4fecac99f111189812\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"R. Girshick\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"To - wards real - time object detection with region proposal networks\",\"url\":\"\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1612.01887\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":\"10.1109/CVPR.2017.345\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9f4d7d622d1f7319cc511bfef661cd973e881a4c\",\"title\":\"Knowing When to Look: Adaptive Attention via a Visual Sentinel for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9f4d7d622d1f7319cc511bfef661cd973e881a4c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699645\",\"name\":\"R. Sutton\"},{\"authorId\":\"1730590\",\"name\":\"A. Barto\"}],\"doi\":\"10.1109/TNN.1998.712192\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"97efafdb4a3942ab3efba53ded7413199f79c054\",\"title\":\"Reinforcement Learning: An Introduction\",\"url\":\"https://www.semanticscholar.org/paper/97efafdb4a3942ab3efba53ded7413199f79c054\",\"venue\":\"IEEE Transactions on Neural Networks\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1403025868\",\"name\":\"Jean Pouget-Abadie\"},{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"144738865\",\"name\":\"Bing Xu\"},{\"authorId\":\"1393680089\",\"name\":\"David Warde-Farley\"},{\"authorId\":\"1955694\",\"name\":\"Sherjil Ozair\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"title\":\"Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1611.01144\",\"authors\":[{\"authorId\":\"145116380\",\"name\":\"Eric Jang\"},{\"authorId\":\"2046135\",\"name\":\"Shixiang Gu\"},{\"authorId\":\"16443937\",\"name\":\"Ben Poole\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"29e944711a354c396fad71936f536e83025b6ce0\",\"title\":\"Categorical Reparameterization with Gumbel-Softmax\",\"url\":\"https://www.semanticscholar.org/paper/29e944711a354c396fad71936f536e83025b6ce0\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1610.02424\",\"authors\":[{\"authorId\":\"3358971\",\"name\":\"Ashwin K. Vijayakumar\"},{\"authorId\":\"144354133\",\"name\":\"Michael Cogswell\"},{\"authorId\":\"35100058\",\"name\":\"R. R. Selvaraju\"},{\"authorId\":\"144207643\",\"name\":\"Q. Sun\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e4dd95c4341ec7d14317a3d97022773a0822906c\",\"title\":\"Diverse Beam Search: Decoding Diverse Solutions from Neural Sequence Models\",\"url\":\"https://www.semanticscholar.org/paper/e4dd95c4341ec7d14317a3d97022773a0822906c\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1604.00562\",\"authors\":[{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"38666915\",\"name\":\"D. Klein\"}],\"doi\":\"10.18653/v1/D16-1125\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"92dbc1509b5641946cc8b524610cb6803d6ee5f6\",\"title\":\"Reasoning about Pragmatics with Neural Listeners and Speakers\",\"url\":\"https://www.semanticscholar.org/paper/92dbc1509b5641946cc8b524610cb6803d6ee5f6\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":\"1510.03055\",\"authors\":[{\"authorId\":\"5183779\",\"name\":\"J. Li\"},{\"authorId\":\"1947267\",\"name\":\"Michel Galley\"},{\"authorId\":\"3125776\",\"name\":\"Chris Brockett\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"83415753\",\"name\":\"W. Dolan\"}],\"doi\":\"10.18653/v1/N16-1014\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"651e5bcc14f14605a879303e97572a27ea8c7956\",\"title\":\"A Diversity-Promoting Objective Function for Neural Conversation Models\",\"url\":\"https://www.semanticscholar.org/paper/651e5bcc14f14605a879303e97572a27ea8c7956\",\"venue\":\"HLT-NAACL\",\"year\":2016},{\"arxivId\":\"1412.6632\",\"authors\":[{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"40579682\",\"name\":\"J. Wang\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745\",\"title\":\"Deep Captioning with Multimodal Recurrent Neural Networks (m-RNN)\",\"url\":\"https://www.semanticscholar.org/paper/54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1611.00712\",\"authors\":[{\"authorId\":\"2772217\",\"name\":\"Chris J. Maddison\"},{\"authorId\":\"1714004\",\"name\":\"A. Mnih\"},{\"authorId\":\"1725303\",\"name\":\"Y. Teh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"515a21e90117941150923e559729c59f5fdade1c\",\"title\":\"The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables\",\"url\":\"https://www.semanticscholar.org/paper/515a21e90117941150923e559729c59f5fdade1c\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2157958\",\"name\":\"Michael J. Denkowski\"},{\"authorId\":\"1784914\",\"name\":\"A. Lavie\"}],\"doi\":\"10.3115/v1/W14-3348\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"26adb749fc5d80502a6d889966e50b31391560d3\",\"title\":\"Meteor Universal: Language Specific Translation Evaluation for Any Target Language\",\"url\":\"https://www.semanticscholar.org/paper/26adb749fc5d80502a6d889966e50b31391560d3\",\"venue\":\"WMT@ACL\",\"year\":2014},{\"arxivId\":\"1609.05473\",\"authors\":[{\"authorId\":\"3469209\",\"name\":\"Lantao Yu\"},{\"authorId\":\"8031058\",\"name\":\"W. Zhang\"},{\"authorId\":\"39055225\",\"name\":\"J. Wang\"},{\"authorId\":\"1811427\",\"name\":\"Y. Yu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2966ecd82505ecd55ead0e6a327a304c8f9868e3\",\"title\":\"SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient\",\"url\":\"https://www.semanticscholar.org/paper/2966ecd82505ecd55ead0e6a327a304c8f9868e3\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":\"1505.01809\",\"authors\":[{\"authorId\":\"39172707\",\"name\":\"J. Devlin\"},{\"authorId\":\"47413820\",\"name\":\"Hao Cheng\"},{\"authorId\":\"145204655\",\"name\":\"Hao Fang\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"}],\"doi\":\"10.3115/v1/P15-2017\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f142c849ffef66f7520aff4e0b40ac964ccb8cc1\",\"title\":\"Language Models for Image Captioning: The Quirks and What Works\",\"url\":\"https://www.semanticscholar.org/paper/f142c849ffef66f7520aff4e0b40ac964ccb8cc1\",\"venue\":\"ACL\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5886094\",\"name\":\"P. Cochat\"},{\"authorId\":\"13267685\",\"name\":\"L. Vaucoret\"},{\"authorId\":\"31455512\",\"name\":\"J. Sarles\"}],\"doi\":\"10.1016/j.arcped.2012.01.013\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"10d85561e4aafc516d10064f30dff05b41f70afe\",\"title\":\"[Et al].\",\"url\":\"https://www.semanticscholar.org/paper/10d85561e4aafc516d10064f30dff05b41f70afe\",\"venue\":\"Archives de pediatrie : organe officiel de la Societe francaise de pediatrie\",\"year\":2012},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1701.04862\",\"authors\":[{\"authorId\":\"2877311\",\"name\":\"Mart\\u00edn Arjovsky\"},{\"authorId\":\"52184096\",\"name\":\"L. Bottou\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9a700c7a7e7468e436f00c34551fbe3e0f70e42f\",\"title\":\"Towards Principled Methods for Training Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/9a700c7a7e7468e436f00c34551fbe3e0f70e42f\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1504.00325\",\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"title\":\"Microsoft COCO Captions: Data Collection and Evaluation Server\",\"url\":\"https://www.semanticscholar.org/paper/696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1506.01497\",\"authors\":[{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"144716314\",\"name\":\"J. Sun\"}],\"doi\":\"10.1109/TPAMI.2016.2577031\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"title\":\"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\",\"url\":\"https://www.semanticscholar.org/paper/424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1888731\",\"name\":\"M. Hejrati\"},{\"authorId\":\"21160985\",\"name\":\"M. Sadeghi\"},{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"3125805\",\"name\":\"Cyrus Rashtchian\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"144016256\",\"name\":\"D. Forsyth\"}],\"doi\":\"10.1007/978-3-642-15561-1_2\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eaaed23a2d94feb2f1c3ff22a25777c7a78f3141\",\"title\":\"Every Picture Tells a Story: Generating Sentences from Images\",\"url\":\"https://www.semanticscholar.org/paper/eaaed23a2d94feb2f1c3ff22a25777c7a78f3141\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":\"1611.08408\",\"authors\":[{\"authorId\":\"152831141\",\"name\":\"Pauline Luc\"},{\"authorId\":\"2341378\",\"name\":\"C. Couprie\"},{\"authorId\":\"2127604\",\"name\":\"Soumith Chintala\"},{\"authorId\":\"34602236\",\"name\":\"Jakob Verbeek\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"fcabf1c0f4a26431d4df95ddeec2b1dff9b3e928\",\"title\":\"Semantic Segmentation using Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/fcabf1c0f4a26431d4df95ddeec2b1dff9b3e928\",\"venue\":\"NIPS 2016\",\"year\":2016},{\"arxivId\":\"1603.03925\",\"authors\":[{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2016.503\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bf55591e09b58ea9ce8d66110d6d3000ee804bdd\",\"title\":\"Image Captioning with Semantic Attention\",\"url\":\"https://www.semanticscholar.org/paper/bf55591e09b58ea9ce8d66110d6d3000ee804bdd\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1412.2306\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/TPAMI.2016.2598339\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"title\":\"Deep Visual-Semantic Alignments for Generating Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017}],\"title\":\"Speaking the Same Language: Matching Machine to Human Captions by Adversarial Training\",\"topics\":[{\"topic\":\"Gibbs sampling\",\"topicId\":\"43651\",\"url\":\"https://www.semanticscholar.org/topic/43651\"},{\"topic\":\"Vocabulary\",\"topicId\":\"14901\",\"url\":\"https://www.semanticscholar.org/topic/14901\"},{\"topic\":\"Correctness (computer science)\",\"topicId\":\"12411\",\"url\":\"https://www.semanticscholar.org/topic/12411\"},{\"topic\":\"Approximation algorithm\",\"topicId\":\"87\",\"url\":\"https://www.semanticscholar.org/topic/87\"},{\"topic\":\"Sampling (signal processing)\",\"topicId\":\"7839\",\"url\":\"https://www.semanticscholar.org/topic/7839\"},{\"topic\":\"Triangular function\",\"topicId\":\"586135\",\"url\":\"https://www.semanticscholar.org/topic/586135\"},{\"topic\":\"Ground truth\",\"topicId\":\"33313\",\"url\":\"https://www.semanticscholar.org/topic/33313\"}],\"url\":\"https://www.semanticscholar.org/paper/1c0a6854b793ca8ad281513c184318b73d4868c4\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017}\n"