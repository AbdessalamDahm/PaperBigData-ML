"{\"abstract\":\"We consider the question: what can be learnt by looking at and listening to a large number of unlabelled videos? There is a valuable, but so far untapped, source of information contained in the video itself \\u2013 the correspondence between the visual and the audio streams, and we introduce a novel \\u201cAudio-Visual Correspondence\\u201d learning task that makes use of this. Training visual and audio networks from scratch, without any additional supervision other than the raw unconstrained videos themselves, is shown to successfully solve this task, and, more interestingly, result in good visual and audio representations. These features set the new state-of-the-art on two sound classification benchmarks, and perform on par with the state-of-the-art selfsupervised approaches on ImageNet classification. We also demonstrate that the network is able to localize objects in both modalities, as well as perform fine-grained recognition tasks.\",\"arxivId\":\"1705.08168\",\"authors\":[{\"authorId\":\"2299479\",\"name\":\"R. Arandjelovi\\u0107\",\"url\":\"https://www.semanticscholar.org/author/2299479\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\",\"url\":\"https://www.semanticscholar.org/author/1688869\"}],\"citationVelocity\":90,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"7885575\",\"name\":\"E. Amrani\"},{\"authorId\":\"1397958297\",\"name\":\"R. Ben-Ari\"},{\"authorId\":\"120159179\",\"name\":\"Tal Hakim\"},{\"authorId\":\"49791556\",\"name\":\"A. Bronstein\"}],\"doi\":\"10.1109/ICCVW.2019.00567\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7b68bddfe1da633dc5cad6015de2bf09c1171b3e\",\"title\":\"Learning to Detect and Retrieve Objects From Unlabeled Videos\",\"url\":\"https://www.semanticscholar.org/paper/7b68bddfe1da633dc5cad6015de2bf09c1171b3e\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"2003.04358\",\"authors\":[{\"authorId\":\"39598262\",\"name\":\"Rahul Sharma\"},{\"authorId\":\"6079502\",\"name\":\"Krishna Somandepalli\"},{\"authorId\":\"145254843\",\"name\":\"Shrikanth S. Narayanan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fe591ed44d1cb10aee5a99cb4dcdca20aabcb3a5\",\"title\":\"Crossmodal learning for audio-visual speech event localization\",\"url\":\"https://www.semanticscholar.org/paper/fe591ed44d1cb10aee5a99cb4dcdca20aabcb3a5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3065605\",\"name\":\"F. Saki\"},{\"authorId\":\"3264207\",\"name\":\"Yinyi Guo\"},{\"authorId\":\"2226292\",\"name\":\"Cheng-Yu Hung\"},{\"authorId\":\"38043420\",\"name\":\"Lae-Hoon Kim\"},{\"authorId\":\"1410323338\",\"name\":\"Manyu Deshpande\"},{\"authorId\":\"2578892\",\"name\":\"Sunkuk Moon\"},{\"authorId\":\"121986915\",\"name\":\"Eunjeong Koh\"},{\"authorId\":\"144387137\",\"name\":\"E. Visser\"}],\"doi\":\"10.33682/en2t-9m14\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"13085e5e59773253125bb7c96f9c7f5767759f49\",\"title\":\"Open-set Evolving Acoustic Scene Classification System\",\"url\":\"https://www.semanticscholar.org/paper/13085e5e59773253125bb7c96f9c7f5767759f49\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1909.09070\",\"authors\":[{\"authorId\":\"1403082631\",\"name\":\"J. G\\u00f3mez-P\\u00e9rez\"},{\"authorId\":\"143848947\",\"name\":\"R. Ortega\"}],\"doi\":\"10.1145/3360901.3364420\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e822040837cdb5831e6dfcc25aeb5bd5bd23c9a9\",\"title\":\"Look, Read and Enrich - Learning from Scientific Figures and their Captions\",\"url\":\"https://www.semanticscholar.org/paper/e822040837cdb5831e6dfcc25aeb5bd5bd23c9a9\",\"venue\":\"K-CAP\",\"year\":2019},{\"arxivId\":\"1802.01880\",\"authors\":[{\"authorId\":\"24028009\",\"name\":\"Dahun Kim\"},{\"authorId\":\"3160154\",\"name\":\"Donghyeon Cho\"},{\"authorId\":\"2283756\",\"name\":\"Donggeun Yoo\"},{\"authorId\":\"2398271\",\"name\":\"In-So Kweon\"}],\"doi\":\"10.1109/WACV.2018.00092\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e22979cdf147a63be74f3816ef59ef11f3508919\",\"title\":\"Learning Image Representations by Completing Damaged Jigsaw Puzzles\",\"url\":\"https://www.semanticscholar.org/paper/e22979cdf147a63be74f3816ef59ef11f3508919\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":\"2001.05691\",\"authors\":[{\"authorId\":\"122460701\",\"name\":\"Tianhao Li\"},{\"authorId\":\"119770705\",\"name\":\"L. Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2783c13471060300e62a1eed458d9d2888b5b5be\",\"title\":\"Learning Spatiotemporal Features via Video and Text Pair Discrimination\",\"url\":\"https://www.semanticscholar.org/paper/2783c13471060300e62a1eed458d9d2888b5b5be\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49108458\",\"name\":\"Min-Hyun Kim\"},{\"authorId\":\"1490899838\",\"name\":\"Jongchan Park\"},{\"authorId\":\"2854596\",\"name\":\"Dong-Geol Choi\"},{\"authorId\":\"145302395\",\"name\":\"S. Choi\"}],\"doi\":\"10.7467/ksae.2020.28.1.027\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"93e19f09706b5f8321fc082512dd29af914fa168\",\"title\":\"Estimation of Frontal Road Type Using Machine Learning and Ultrasonic Waves\",\"url\":\"https://www.semanticscholar.org/paper/93e19f09706b5f8321fc082512dd29af914fa168\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1959025244\",\"name\":\"Xuan-Bac Nguyen\"},{\"authorId\":\"98196896\",\"name\":\"Guee Sang Lee\"},{\"authorId\":\"153274504\",\"name\":\"Soo Hyung Kim\"},{\"authorId\":\"1736218\",\"name\":\"H. J. Yang\"}],\"doi\":\"10.1109/ACCESS.2020.3021469\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"edaa65d8bd38b7f5e99442f9a120489a1a16370c\",\"title\":\"Self-Supervised Learning Based on Spatial Awareness for Medical Image Analysis\",\"url\":\"https://www.semanticscholar.org/paper/edaa65d8bd38b7f5e99442f9a120489a1a16370c\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32486555\",\"name\":\"D. Epstein\"},{\"authorId\":\"3450230\",\"name\":\"Yiliang Shi\"},{\"authorId\":\"48144872\",\"name\":\"E. Wu\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cc8a78b43b5e14643dbf8991b585314cdee6a341\",\"title\":\"What\\u2019s Missing From Self-Supervised Representation Learning?\",\"url\":\"https://www.semanticscholar.org/paper/cc8a78b43b5e14643dbf8991b585314cdee6a341\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2004.14368\",\"authors\":[{\"authorId\":\"1390823178\",\"name\":\"Honglie Chen\"},{\"authorId\":\"10096695\",\"name\":\"Weidi Xie\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053174\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"66831f683141c11ed7e20b0f2e8b40700740c164\",\"title\":\"Vggsound: A Large-Scale Audio-Visual Dataset\",\"url\":\"https://www.semanticscholar.org/paper/66831f683141c11ed7e20b0f2e8b40700740c164\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72337067\",\"name\":\"Y. Li\"},{\"authorId\":\"39467036\",\"name\":\"Z. Liu\"},{\"authorId\":\"12028454\",\"name\":\"Yueyue Na\"},{\"authorId\":\"2326425\",\"name\":\"Ziteng Wang\"},{\"authorId\":\"1500394908\",\"name\":\"Biao Tian\"},{\"authorId\":\"1389198454\",\"name\":\"Qiang Fu\"}],\"doi\":\"10.1109/ICASSP40776.2020.9054263\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"79eb865937300b853fc0a79d5770f427f8e36866\",\"title\":\"A Visual-Pilot Deep Fusion for Target Speech Separation in Multitalker Noisy Environment\",\"url\":\"https://www.semanticscholar.org/paper/79eb865937300b853fc0a79d5770f427f8e36866\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"2002.11561\",\"authors\":[{\"authorId\":\"1419458795\",\"name\":\"Javier Naranjo-Alcazar\"},{\"authorId\":\"1417133896\",\"name\":\"Sergi Perez-Castanos\"},{\"authorId\":\"2450434\",\"name\":\"P. Zuccarello\"},{\"authorId\":\"2432536\",\"name\":\"M. Cobos\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8f35e463b17b181e7c1842b6b4843ad3596ff2d5\",\"title\":\"An Open-set Recognition and Few-Shot Learning Dataset for Audio Event Classification in Domestic Environments\",\"url\":\"https://www.semanticscholar.org/paper/8f35e463b17b181e7c1842b6b4843ad3596ff2d5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1910.10997\",\"authors\":[{\"authorId\":\"145798292\",\"name\":\"Hang Zhou\"},{\"authorId\":\"3243969\",\"name\":\"Z. Liu\"},{\"authorId\":\"50487517\",\"name\":\"Xudong Xu\"},{\"authorId\":\"47571885\",\"name\":\"Ping Luo\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"}],\"doi\":\"10.1109/ICCV.2019.00037\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"82feef7ae3b3d5ea16ce8bfdf9a01d9aadb4b7be\",\"title\":\"Vision-Infused Deep Audio Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/82feef7ae3b3d5ea16ce8bfdf9a01d9aadb4b7be\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47473876\",\"name\":\"Mingxin Zhang\"},{\"authorId\":\"49125925\",\"name\":\"T. Tanaka\"},{\"authorId\":\"32216189\",\"name\":\"Wenxin Hou\"},{\"authorId\":\"1657484873\",\"name\":\"Shengzhou Gao\"},{\"authorId\":\"49018339\",\"name\":\"T. Shinozaki\"}],\"doi\":\"10.21437/interspeech.2020-2027\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ed02595d039056765af09f13fc117a8d0656d173\",\"title\":\"Sound-Image Grounding Based Focusing Mechanism for Efficient Automatic Spoken Language Acquisition\",\"url\":\"https://www.semanticscholar.org/paper/ed02595d039056765af09f13fc117a8d0656d173\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":\"1908.08498\",\"authors\":[{\"authorId\":\"48842721\",\"name\":\"Evangelos Kazakos\"},{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.1109/ICCV.2019.00559\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7c9de67cc76aeecddcd07e8898acea3ef4eba738\",\"title\":\"EPIC-Fusion: Audio-Visual Temporal Binding for Egocentric Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7c9de67cc76aeecddcd07e8898acea3ef4eba738\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1902.07473\",\"authors\":[{\"authorId\":\"2564871\",\"name\":\"Yan-Bo Lin\"},{\"authorId\":\"3312576\",\"name\":\"Yu-Jhe Li\"},{\"authorId\":\"2733735\",\"name\":\"Y. Wang\"}],\"doi\":\"10.1109/ICASSP.2019.8683226\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6dad33f2e317cc23abeba8596a4c8a4a13117d54\",\"title\":\"Dual-modality Seq2Seq Network for Audio-visual Event Localization\",\"url\":\"https://www.semanticscholar.org/paper/6dad33f2e317cc23abeba8596a4c8a4a13117d54\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72500859\",\"name\":\"Y. Wu\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":null,\"name\":\"Yan Yan\"},{\"authorId\":\"143907244\",\"name\":\"Yi Yang\"}],\"doi\":\"10.1109/ICCV.2019.00639\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"6c2b97b0e02d0b7e02fe4303a6c1894e13b27335\",\"title\":\"Dual Attention Matching for Audio-Visual Event Localization\",\"url\":\"https://www.semanticscholar.org/paper/6c2b97b0e02d0b7e02fe4303a6c1894e13b27335\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1904.07846\",\"authors\":[{\"authorId\":\"2420123\",\"name\":\"D. Dwibedi\"},{\"authorId\":\"3152281\",\"name\":\"Y. Aytar\"},{\"authorId\":\"2704494\",\"name\":\"J. Tompson\"},{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2019.00190\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"75662c7ab05db37c52a2d750af2a8b712bbf3d53\",\"title\":\"Temporal Cycle-Consistency Learning\",\"url\":\"https://www.semanticscholar.org/paper/75662c7ab05db37c52a2d750af2a8b712bbf3d53\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1907.13487\",\"authors\":[{\"authorId\":\"40457423\",\"name\":\"Y. Liu\"},{\"authorId\":\"7641268\",\"name\":\"Samuel Albanie\"},{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b16eeb1e975e8e6ea9450c78fd12da05cfd1375f\",\"title\":\"Use What You Have: Video retrieval using representations from collaborative experts\",\"url\":\"https://www.semanticscholar.org/paper/b16eeb1e975e8e6ea9450c78fd12da05cfd1375f\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"1804.10070\",\"authors\":[{\"authorId\":\"3215419\",\"name\":\"B. McFee\"},{\"authorId\":\"1786276\",\"name\":\"Justin Salamon\"},{\"authorId\":\"34894065\",\"name\":\"J. Bello\"}],\"doi\":\"10.1109/TASLP.2018.2858559\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3b2f7f5363b3a2199a73752035361311f8ba85a4\",\"title\":\"Adaptive Pooling Operators for Weakly Labeled Sound Event Detection\",\"url\":\"https://www.semanticscholar.org/paper/3b2f7f5363b3a2199a73752035361311f8ba85a4\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3028258\",\"name\":\"Panagiotis Kasnesis\"},{\"authorId\":\"2630784\",\"name\":\"Nicolas-Alexander Tatlas\"},{\"authorId\":\"1877582\",\"name\":\"S. Mitilineos\"},{\"authorId\":\"3096444\",\"name\":\"Charalampos Z. Patrikakis\"},{\"authorId\":\"2706053\",\"name\":\"S. Potirakis\"}],\"doi\":\"10.3390/s19071629\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0b62a0b5b344847c7b8854702492da2199261af3\",\"title\":\"Acoustic Sensor Data Flow for Cultural Heritage Monitoring and Safeguarding\",\"url\":\"https://www.semanticscholar.org/paper/0b62a0b5b344847c7b8854702492da2199261af3\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46185180\",\"name\":\"A. Masullo\"},{\"authorId\":\"1717278\",\"name\":\"T. Burghardt\"},{\"authorId\":\"1677780022\",\"name\":\"Dima Damen\"},{\"authorId\":\"2682004\",\"name\":\"T. Perrett\"},{\"authorId\":\"1728108\",\"name\":\"M. Mirmehdi\"}],\"doi\":\"10.3390/s20092576\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bc9ff57de4b5630ceaad73f1d359350032753d00\",\"title\":\"Person Re-ID by Fusion of Video Silhouettes and Wearable Signals for Home Monitoring Applications \\u2020\",\"url\":\"https://www.semanticscholar.org/paper/bc9ff57de4b5630ceaad73f1d359350032753d00\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"2008.00820\",\"authors\":[{\"authorId\":\"4965440\",\"name\":\"Peihao Chen\"},{\"authorId\":\"29969244\",\"name\":\"Y. Zhang\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"},{\"authorId\":\"4506893\",\"name\":\"Hongdong Xiao\"},{\"authorId\":\"145592817\",\"name\":\"D. Huang\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"}],\"doi\":\"10.1109/TIP.2020.3009820\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d0ed8a26aa689992bd0e870df9e428987ea2a4e2\",\"title\":\"Generating Visually Aligned Sound From Videos\",\"url\":\"https://www.semanticscholar.org/paper/d0ed8a26aa689992bd0e870df9e428987ea2a4e2\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"2004.12943\",\"authors\":[{\"authorId\":\"31692099\",\"name\":\"Pedro Morgado\"},{\"authorId\":\"1699559\",\"name\":\"N. Vasconcelos\"},{\"authorId\":\"1806773\",\"name\":\"I. Misra\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"afc91295df19ffc7ab95530dc879ac11126afeee\",\"title\":\"Audio-Visual Instance Discrimination with Cross-Modal Agreement\",\"url\":\"https://www.semanticscholar.org/paper/afc91295df19ffc7ab95530dc879ac11126afeee\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145236670\",\"name\":\"R. Lu\"},{\"authorId\":\"3270912\",\"name\":\"Z. Duan\"},{\"authorId\":\"1700883\",\"name\":\"C. Zhang\"}],\"doi\":\"10.1109/LSP.2018.2853566\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2176fe5d53f69c26ae88c4ffe6607f7466ef33bc\",\"title\":\"Listen and Look: Audio\\u2013Visual Matching Assisted Speech Source Separation\",\"url\":\"https://www.semanticscholar.org/paper/2176fe5d53f69c26ae88c4ffe6607f7466ef33bc\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145491338\",\"name\":\"S. Palacio\"},{\"authorId\":\"1824088\",\"name\":\"V. Campos\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7ffd9e745e58f9dc876af7f68e9ef5b9d56d6461\",\"title\":\"VIDEO UNDERSTANDING THROUGH THE DISENTANGLEMENT OF APPEARANCE AND MOTION\",\"url\":\"https://www.semanticscholar.org/paper/7ffd9e745e58f9dc876af7f68e9ef5b9d56d6461\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1805.00833\",\"authors\":[{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"7641268\",\"name\":\"Samuel Albanie\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/978-3-030-01261-8_5\",\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"a2344004f0e1409c0c9473d071a5cfd74bff0a5d\",\"title\":\"Learnable PINs: Cross-Modal Embeddings for Person Identity\",\"url\":\"https://www.semanticscholar.org/paper/a2344004f0e1409c0c9473d071a5cfd74bff0a5d\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1711.08200\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"31493847\",\"name\":\"A. H. Karami\"},{\"authorId\":\"2713759\",\"name\":\"M. M. Arzani\"},{\"authorId\":\"9456273\",\"name\":\"Rahman Yousefzadeh\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f5ce640bbb9d6417fd0853ed88a9e7b93d72910d\",\"title\":\"Temporal 3D ConvNets: New Architecture and Transfer Learning for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/f5ce640bbb9d6417fd0853ed88a9e7b93d72910d\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"2010.05113\",\"authors\":[{\"authorId\":\"1994194269\",\"name\":\"Phuc H. Le-Khac\"},{\"authorId\":\"30978009\",\"name\":\"Graham Healy\"},{\"authorId\":\"1680223\",\"name\":\"A. Smeaton\"}],\"doi\":\"10.1109/ACCESS.2020.3031549\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4f0a8cad6d6a8d0397ad1bd35acce6458aa7164c\",\"title\":\"Contrastive Representation Learning: A Framework and Review\",\"url\":\"https://www.semanticscholar.org/paper/4f0a8cad6d6a8d0397ad1bd35acce6458aa7164c\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1905.04418\",\"authors\":[{\"authorId\":\"48293266\",\"name\":\"Michael J. Bianco\"},{\"authorId\":\"117106206\",\"name\":\"P. Gerstoft\"},{\"authorId\":\"50690309\",\"name\":\"James Traer\"},{\"authorId\":\"15018343\",\"name\":\"Emma Ozanich\"},{\"authorId\":\"35154087\",\"name\":\"M. A. Roch\"},{\"authorId\":\"1774548\",\"name\":\"S. Gannot\"},{\"authorId\":\"2262533\",\"name\":\"Charles-Alban Deledalle\"}],\"doi\":\"10.1121/1.5133944\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2e6c570d277b0b4edd48e2054d5cede4c6bbb50f\",\"title\":\"Machine learning in acoustics: Theory and applications.\",\"url\":\"https://www.semanticscholar.org/paper/2e6c570d277b0b4edd48e2054d5cede4c6bbb50f\",\"venue\":\"The Journal of the Acoustical Society of America\",\"year\":2019},{\"arxivId\":\"1812.04204\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2019.00041\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b809837560cf11937ee857338eb1a7ccd2abc7b2\",\"title\":\"2.5D Visual Sound\",\"url\":\"https://www.semanticscholar.org/paper/b809837560cf11937ee857338eb1a7ccd2abc7b2\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2006.14348\",\"authors\":[{\"authorId\":\"1491240396\",\"name\":\"Kun Su\"},{\"authorId\":\"10598535\",\"name\":\"X. Liu\"},{\"authorId\":\"2003419\",\"name\":\"Eli Shlizerman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c6127cceb5847551cc09814a0d00cf63ba21b546\",\"title\":\"Audeo: Audio Generation for a Silent Performance Video\",\"url\":\"https://www.semanticscholar.org/paper/c6127cceb5847551cc09814a0d00cf63ba21b546\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2006.09199\",\"authors\":[{\"authorId\":\"41020711\",\"name\":\"Andrew Rouditchenko\"},{\"authorId\":\"1394839535\",\"name\":\"Angie Boggust\"},{\"authorId\":\"30507748\",\"name\":\"David Harwath\"},{\"authorId\":\"47669634\",\"name\":\"Dhiraj Joshi\"},{\"authorId\":\"70913918\",\"name\":\"S. Thomas\"},{\"authorId\":\"3104038\",\"name\":\"Kartik Audhkhasi\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"144707379\",\"name\":\"Brian Kingsbury\"},{\"authorId\":\"1774515\",\"name\":\"M. Picheny\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"},{\"authorId\":\"152450847\",\"name\":\"J. Glass\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1141ac4a1443ae7b44266a84a7f042f38759ac47\",\"title\":\"AVLnet: Learning Audio-Visual Language Representations from Instructional Videos\",\"url\":\"https://www.semanticscholar.org/paper/1141ac4a1443ae7b44266a84a7f042f38759ac47\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993602785\",\"name\":\"Ruijian Jia\"},{\"authorId\":\"50142011\",\"name\":\"Xinsheng Wang\"},{\"authorId\":\"2852872\",\"name\":\"S. Pang\"},{\"authorId\":\"2237811\",\"name\":\"Jihua Zhu\"},{\"authorId\":\"40689776\",\"name\":\"J. Xue\"}],\"doi\":\"10.1145/3394171.3414023\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4955fda9e96f97e0dcd45c846ec52cb118d89060\",\"title\":\"Look, Listen and Infer\",\"url\":\"https://www.semanticscholar.org/paper/4955fda9e96f97e0dcd45c846ec52cb118d89060\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2727313\",\"name\":\"A. Jamaludin\"},{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/s11263-019-01150-y\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0e8cd058ae29c6f60a8750c1df3caa5dc0e99543\",\"title\":\"You Said That?: Synthesising Talking Faces from Audio\",\"url\":\"https://www.semanticscholar.org/paper/0e8cd058ae29c6f60a8750c1df3caa5dc0e99543\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"1904.00150\",\"authors\":[{\"authorId\":\"145816931\",\"name\":\"Gaurav Verma\"},{\"authorId\":\"76954832\",\"name\":\"E. Dhekane\"},{\"authorId\":\"1720741\",\"name\":\"T. Guha\"}],\"doi\":\"10.1109/ICASSP.2019.8683133\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ed9941b21b26f9396eed2c6b0d9c5b0cf6e5f118\",\"title\":\"Learning Affective Correspondence between Music and Image\",\"url\":\"https://www.semanticscholar.org/paper/ed9941b21b26f9396eed2c6b0d9c5b0cf6e5f118\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":\"1903.03591\",\"authors\":[{\"authorId\":\"48208484\",\"name\":\"Justin Lin\"},{\"authorId\":\"35159852\",\"name\":\"R. Calandra\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":\"10.1109/ICRA.2019.8793885\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5b474d390d434b4a156a38ad1062f8a7ccd25ef5\",\"title\":\"Learning to Identify Object Instances by Touch: Tactile Recognition via Multimodal Matching\",\"url\":\"https://www.semanticscholar.org/paper/5b474d390d434b4a156a38ad1062f8a7ccd25ef5\",\"venue\":\"2019 International Conference on Robotics and Automation (ICRA)\",\"year\":2019},{\"arxivId\":\"1810.06748\",\"authors\":[{\"authorId\":\"40360280\",\"name\":\"Di Fu\"},{\"authorId\":\"144039832\",\"name\":\"P. Barros\"},{\"authorId\":\"2988592\",\"name\":\"G. Parisi\"},{\"authorId\":\"1748494\",\"name\":\"H. Wu\"},{\"authorId\":\"2632932\",\"name\":\"Sven Magg\"},{\"authorId\":\"2201018\",\"name\":\"X. Liu\"},{\"authorId\":\"1736513\",\"name\":\"S. Wermter\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2e110a46e3ebf03c90a2b4007b502e6caa744e04\",\"title\":\"Assessing the Contribution of Semantic Congruency to Multisensory Integration and Conflict Resolution\",\"url\":\"https://www.semanticscholar.org/paper/2e110a46e3ebf03c90a2b4007b502e6caa744e04\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71866266\",\"name\":\"N. Bharadwaj\"},{\"authorId\":\"1820900342\",\"name\":\"Garrett M. Shipley\"}],\"doi\":\"10.1016/j.indmarman.2020.07.002\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6717ea41ab53b041aa30e39eabe456f19bfd6dc6\",\"title\":\"Salesperson communication effectiveness in a digital sales interaction1\\u2606\",\"url\":\"https://www.semanticscholar.org/paper/6717ea41ab53b041aa30e39eabe456f19bfd6dc6\",\"venue\":\"Industrial Marketing Management\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144017722\",\"name\":\"Olle G. Holmberg\"},{\"authorId\":\"48614214\",\"name\":\"Niklas D. Koehler\"},{\"authorId\":\"2259305\",\"name\":\"Thiago de C. Martins\"},{\"authorId\":\"1405643583\",\"name\":\"J. Siedlecki\"},{\"authorId\":\"39399712\",\"name\":\"T. Herold\"},{\"authorId\":\"51067892\",\"name\":\"Leonie Keidel\"},{\"authorId\":\"41022860\",\"name\":\"Ben Asani\"},{\"authorId\":\"41180363\",\"name\":\"Johannes Schiefelbein\"},{\"authorId\":\"153293139\",\"name\":\"S. Priglinger\"},{\"authorId\":\"144430238\",\"name\":\"K. Kortuem\"},{\"authorId\":\"2958299\",\"name\":\"F. Theis\"}],\"doi\":\"10.1038/s42256-020-00247-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"95604984d1e64cb480a3892c0c1a64b11dd18b7e\",\"title\":\"Self-supervised retinal thickness prediction enables deep learning from unlabelled data to boost classification of diabetic retinopathy\",\"url\":\"https://www.semanticscholar.org/paper/95604984d1e64cb480a3892c0c1a64b11dd18b7e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2005.13402\",\"authors\":[{\"authorId\":\"31222412\",\"name\":\"Pratik Mazumder\"},{\"authorId\":\"144377059\",\"name\":\"Pravendra Singh\"},{\"authorId\":\"50811450\",\"name\":\"Kranti K. Parida\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"91aea8435a9aa2409f9b279edacbfbb3fd19587b\",\"title\":\"AVGZSLNet: Audio-Visual Generalized Zero-Shot Learning by Reconstructing Label Features from Multi-Modal Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/91aea8435a9aa2409f9b279edacbfbb3fd19587b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.15489\",\"authors\":[{\"authorId\":\"49984891\",\"name\":\"Ceyuan Yang\"},{\"authorId\":\"121983635\",\"name\":\"Yinghao Xu\"},{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3cb65b26e407e7464223e9568010965fe73ae61f\",\"title\":\"Video Representation Learning with Visual Tempo Consistency\",\"url\":\"https://www.semanticscholar.org/paper/3cb65b26e407e7464223e9568010965fe73ae61f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.02001\",\"authors\":[{\"authorId\":\"49923155\",\"name\":\"Hsin-Ying Lee\"},{\"authorId\":\"47008546\",\"name\":\"Xiaodong Yang\"},{\"authorId\":\"153699069\",\"name\":\"Mingyu Liu\"},{\"authorId\":\"2195314\",\"name\":\"T. Wang\"},{\"authorId\":\"8646392\",\"name\":\"Yu-Ding Lu\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"12b38ff98d8cb847d735f8fb2b331cdcc30cae91\",\"title\":\"Dancing to Music\",\"url\":\"https://www.semanticscholar.org/paper/12b38ff98d8cb847d735f8fb2b331cdcc30cae91\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1804.07345\",\"authors\":[{\"authorId\":\"40217426\",\"name\":\"S. Parekh\"},{\"authorId\":\"1807587\",\"name\":\"S. Essid\"},{\"authorId\":\"2889451\",\"name\":\"A. Ozerov\"},{\"authorId\":\"1756744\",\"name\":\"Ngoc Q. K. Duong\"},{\"authorId\":\"144565371\",\"name\":\"P. P\\u00e9rez\"},{\"authorId\":\"145793390\",\"name\":\"G. Richard\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ae2114763744cc403df2e3b9da2cae9c9768ae78\",\"title\":\"Weakly Supervised Representation Learning for Unsynchronized Audio-Visual Events\",\"url\":\"https://www.semanticscholar.org/paper/ae2114763744cc403df2e3b9da2cae9c9768ae78\",\"venue\":\"CVPR Workshops\",\"year\":2018},{\"arxivId\":\"1804.01665\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1007/978-3-030-01219-9_3\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5c9ca16cb2337fd5948c7af28c29c156981250e8\",\"title\":\"Learning to Separate Object Sounds by Watching Unlabeled Video\",\"url\":\"https://www.semanticscholar.org/paper/5c9ca16cb2337fd5948c7af28c29c156981250e8\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1804.00326\",\"authors\":[{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"7641268\",\"name\":\"Samuel Albanie\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2018.00879\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c75658b080a9baaac20db39af86016ffa36f6f0\",\"title\":\"Seeing Voices and Hearing Faces: Cross-Modal Biometric Matching\",\"url\":\"https://www.semanticscholar.org/paper/2c75658b080a9baaac20db39af86016ffa36f6f0\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2007.06355\",\"authors\":[{\"authorId\":\"47519958\",\"name\":\"Rui Qian\"},{\"authorId\":\"1500378795\",\"name\":\"Di Hu\"},{\"authorId\":\"2451839\",\"name\":\"H. Dinkel\"},{\"authorId\":\"3000684\",\"name\":\"Mengyue Wu\"},{\"authorId\":null,\"name\":\"Ning Xu\"},{\"authorId\":\"8131625\",\"name\":\"W. Lin\"}],\"doi\":\"10.1007/978-3-030-58565-5_18\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"53eb4c778e7c2aec2f4c5d2681321b18c06decca\",\"title\":\"Multiple Sound Sources Localization from Coarse to Fine\",\"url\":\"https://www.semanticscholar.org/paper/53eb4c778e7c2aec2f4c5d2681321b18c06decca\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145878079\",\"name\":\"Vivek Sharma\"}],\"doi\":\"10.5445/IR/1000119819\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3605e0e6ea610576fa85fcf8737b9f20ddd87180\",\"title\":\"Self-supervised Face Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/3605e0e6ea610576fa85fcf8737b9f20ddd87180\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2007.10558\",\"authors\":[{\"authorId\":\"34777509\",\"name\":\"Yapeng Tian\"},{\"authorId\":\"40580714\",\"name\":\"Dingzeyu Li\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":\"10.1007/978-3-030-58580-8_26\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3867340091c920dc5f8ba462197fa5bc924a98c4\",\"title\":\"Unified Multisensory Perception: Weakly-Supervised Audio-Visual Video Parsing\",\"url\":\"https://www.semanticscholar.org/paper/3867340091c920dc5f8ba462197fa5bc924a98c4\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1912.02783\",\"authors\":[{\"authorId\":\"143902495\",\"name\":\"Michael Tschannen\"},{\"authorId\":\"2941141\",\"name\":\"Josip Djolonga\"},{\"authorId\":\"39687627\",\"name\":\"M. Ritter\"},{\"authorId\":\"32694028\",\"name\":\"Aravindh Mahendran\"},{\"authorId\":\"2815290\",\"name\":\"N. Houlsby\"},{\"authorId\":\"1802148\",\"name\":\"S. Gelly\"},{\"authorId\":\"34302129\",\"name\":\"M. Lucic\"}],\"doi\":\"10.1109/cvpr42600.2020.01382\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"797d52dd7819b15a5d171fd5bedad9cc911cf756\",\"title\":\"Self-Supervised Learning of Video-Induced Visual Invariances\",\"url\":\"https://www.semanticscholar.org/paper/797d52dd7819b15a5d171fd5bedad9cc911cf756\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1904.05979\",\"authors\":[{\"authorId\":\"144077750\",\"name\":\"Hang Zhao\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"2650832\",\"name\":\"W. Ma\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/ICCV.2019.00182\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c880de441a41c351955ad0bf8f712eeee500ac67\",\"title\":\"The Sound of Motions\",\"url\":\"https://www.semanticscholar.org/paper/c880de441a41c351955ad0bf8f712eeee500ac67\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1912.06430\",\"authors\":[{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"1466466597\",\"name\":\"Lucas Smaira\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/cvpr42600.2020.00990\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fb40df31aa7177c9d009478479db61c39caebd54\",\"title\":\"End-to-End Learning of Visual Representations From Uncurated Instructional Videos\",\"url\":\"https://www.semanticscholar.org/paper/fb40df31aa7177c9d009478479db61c39caebd54\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1906.00634\",\"authors\":[{\"authorId\":\"1901010\",\"name\":\"A. Cartas\"},{\"authorId\":\"145114663\",\"name\":\"J. Luque\"},{\"authorId\":\"143601910\",\"name\":\"P. Radeva\"},{\"authorId\":\"144036236\",\"name\":\"Carlos Segura\"},{\"authorId\":\"2837527\",\"name\":\"Mariella Dimiccoli\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2599ba93b13c7b08fc0309d0678cc2d74fe8c52a\",\"title\":\"How Much Does Audio Matter to Recognize Egocentric Object Interactions?\",\"url\":\"https://www.semanticscholar.org/paper/2599ba93b13c7b08fc0309d0678cc2d74fe8c52a\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7885575\",\"name\":\"E. Amrani\"},{\"authorId\":\"1397958297\",\"name\":\"R. Ben-Ari\"},{\"authorId\":\"14871837\",\"name\":\"I. Shapira\"},{\"authorId\":\"120159179\",\"name\":\"Tal Hakim\"},{\"authorId\":\"49791471\",\"name\":\"A. Bronstein\"}],\"doi\":\"10.1109/CVPRW50498.2020.00485\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"da031a350f80eb23b8cdbce32ec3b0b792cd7557\",\"title\":\"Self-Supervised Object Detection and Retrieval Using Unlabeled Videos\",\"url\":\"https://www.semanticscholar.org/paper/da031a350f80eb23b8cdbce32ec3b0b792cd7557\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"1911.12667\",\"authors\":[{\"authorId\":\"19198894\",\"name\":\"Humam Alwassel\"},{\"authorId\":\"144542135\",\"name\":\"D. Mahajan\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1ee9df4e96f5021509c438751b48d3de07ae8b75\",\"title\":\"Self-Supervised Learning by Cross-Modal Audio-Video Clustering\",\"url\":\"https://www.semanticscholar.org/paper/1ee9df4e96f5021509c438751b48d3de07ae8b75\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2008.00305\",\"authors\":[{\"authorId\":\"1973062\",\"name\":\"Omid Poursaeed\"},{\"authorId\":\"31531866\",\"name\":\"Tianxing Jiang\"},{\"authorId\":\"1850349772\",\"name\":\"Quintessa Qiao\"},{\"authorId\":\"35718053\",\"name\":\"N. Xu\"},{\"authorId\":\"3082383\",\"name\":\"Vladimir G. Kim\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"97da14337c54a6d055e2947b500af94bc5537a12\",\"title\":\"Self-supervised Learning of Point Clouds via Orientation Estimation\",\"url\":\"https://www.semanticscholar.org/paper/97da14337c54a6d055e2947b500af94bc5537a12\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30507748\",\"name\":\"David Harwath\"},{\"authorId\":\"39257069\",\"name\":\"A. Recasens\"},{\"authorId\":\"35399640\",\"name\":\"D\\u00eddac Sur\\u00eds\"},{\"authorId\":\"2213197\",\"name\":\"Galen Chuang\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145898103\",\"name\":\"J. Glass\"}],\"doi\":\"10.1007/s11263-019-01205-0\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"45070dd423a47f237d2c0bc7930579ecc4e4ad0a\",\"title\":\"Jointly Discovering Visual Objects and Spoken Words from Raw Sensory Input\",\"url\":\"https://www.semanticscholar.org/paper/45070dd423a47f237d2c0bc7930579ecc4e4ad0a\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"2001.04758\",\"authors\":[{\"authorId\":\"145153296\",\"name\":\"Hao Zhu\"},{\"authorId\":\"100602595\",\"name\":\"Mandi Luo\"},{\"authorId\":\"77886607\",\"name\":\"Rui Wang\"},{\"authorId\":\"4520695\",\"name\":\"A. Zheng\"},{\"authorId\":\"144282794\",\"name\":\"R. He\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7cabfa7362ebb57c77380caa57aa17fd7195605c\",\"title\":\"Deep Audio-Visual Learning: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/7cabfa7362ebb57c77380caa57aa17fd7195605c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9193663\",\"name\":\"Pasi Pertila\\u0308\"},{\"authorId\":\"2038526339\",\"name\":\"Mikko Parviainen\"},{\"authorId\":\"34857305\",\"name\":\"V. Myllyl\\u00e4\"},{\"authorId\":\"2038528155\",\"name\":\"Anu Huttunen\"},{\"authorId\":\"2038528172\",\"name\":\"Petri Jarske\"}],\"doi\":\"10.1109/MMSP48831.2020.9287131\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c2415c58a8aee24aadbe23aa93cb66cf81051c97\",\"title\":\"Time Difference of Arrival Estimation with Deep Learning \\u2013 From Acoustic Simulations to Recorded Data\",\"url\":\"https://www.semanticscholar.org/paper/c2415c58a8aee24aadbe23aa93cb66cf81051c97\",\"venue\":\"2020 IEEE 22nd International Workshop on Multimedia Signal Processing (MMSP)\",\"year\":2020},{\"arxivId\":\"1712.06651\",\"authors\":[{\"authorId\":\"2299479\",\"name\":\"R. Arandjelovi\\u0107\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/978-3-030-01246-5_27\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"dfc504536e8434eb008680343abb77010965169e\",\"title\":\"Objects that Sound\",\"url\":\"https://www.semanticscholar.org/paper/dfc504536e8434eb008680343abb77010965169e\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1804.03641\",\"authors\":[{\"authorId\":\"144956994\",\"name\":\"Andrew Owens\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1007/978-3-030-01231-1_39\",\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"171f8f1090ef0533ff470ed5a4d31ecfefcc74be\",\"title\":\"Audio-Visual Scene Analysis with Self-Supervised Multisensory Features\",\"url\":\"https://www.semanticscholar.org/paper/171f8f1090ef0533ff470ed5a4d31ecfefcc74be\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2010.05466\",\"authors\":[{\"authorId\":\"153211990\",\"name\":\"Di Hu\"},{\"authorId\":\"47519958\",\"name\":\"Rui Qian\"},{\"authorId\":\"46332801\",\"name\":\"Minyue Jiang\"},{\"authorId\":\"5424083\",\"name\":\"X. Tan\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"},{\"authorId\":\"12081764\",\"name\":\"E. Ding\"},{\"authorId\":\"8131625\",\"name\":\"W. Lin\"},{\"authorId\":\"1721158\",\"name\":\"D. Dou\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e96b7de5f6366aa1a8b4377d97c3f2464ab198ca\",\"title\":\"Discriminative Sounding Objects Localization via Self-supervised Audiovisual Matching\",\"url\":\"https://www.semanticscholar.org/paper/e96b7de5f6366aa1a8b4377d97c3f2464ab198ca\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2006.16228\",\"authors\":[{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"39257069\",\"name\":\"A. Recasens\"},{\"authorId\":\"145721402\",\"name\":\"Ros\\u00e1lia G. Schneider\"},{\"authorId\":\"2299479\",\"name\":\"R. Arandjelovi\\u0107\"},{\"authorId\":\"16092809\",\"name\":\"Jason Ramapuram\"},{\"authorId\":\"3364908\",\"name\":\"J. Fauw\"},{\"authorId\":\"1466466597\",\"name\":\"Lucas Smaira\"},{\"authorId\":\"48373216\",\"name\":\"S. Dieleman\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4174f03c7d8d9add62ae4ecd0ec90efba680b7ae\",\"title\":\"Self-Supervised MultiModal Versatile Networks\",\"url\":\"https://www.semanticscholar.org/paper/4174f03c7d8d9add62ae4ecd0ec90efba680b7ae\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"1807.03094\",\"authors\":[{\"authorId\":\"48080348\",\"name\":\"D. Hu\"},{\"authorId\":\"144962210\",\"name\":\"F. Nie\"},{\"authorId\":\"1720243\",\"name\":\"X. Li\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"16d4d7ec673b5697776d1c4f229f5a824b891972\",\"title\":\"Deep Co-Clustering for Unsupervised Audiovisual Learning\",\"url\":\"https://www.semanticscholar.org/paper/16d4d7ec673b5697776d1c4f229f5a824b891972\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143783559\",\"name\":\"M. Cartwright\"},{\"authorId\":\"47171633\",\"name\":\"J. Cramer\"},{\"authorId\":\"1786276\",\"name\":\"Justin Salamon\"},{\"authorId\":\"34894065\",\"name\":\"J. Bello\"}],\"doi\":\"10.1109/WASPAA.2019.8937265\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7cae2602ef4e806db2bead51008972410a94717a\",\"title\":\"Tricycle: Audio Representation Learning from Sensor Network Data Using Self-Supervision\",\"url\":\"https://www.semanticscholar.org/paper/7cae2602ef4e806db2bead51008972410a94717a\",\"venue\":\"2019 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)\",\"year\":2019},{\"arxivId\":\"2012.02639\",\"authors\":[{\"authorId\":\"2031911039\",\"name\":\"Edward Fish\"},{\"authorId\":\"2014512338\",\"name\":\"Andrew Gilbert\"},{\"authorId\":\"47371758\",\"name\":\"Jon Weinbren\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ffe1f5c2d579cc63a785023f4df11207504fbc1c\",\"title\":\"Rethinking movie genre classification with fine-grained semantic clustering\",\"url\":\"https://www.semanticscholar.org/paper/ffe1f5c2d579cc63a785023f4df11207504fbc1c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2641547\",\"name\":\"H. Liu\"},{\"authorId\":\"1799463962\",\"name\":\"Feng Wang\"},{\"authorId\":\"1846273678\",\"name\":\"Di Guo\"},{\"authorId\":\"153201597\",\"name\":\"Xinzhu Liu\"},{\"authorId\":\"50812963\",\"name\":\"Xinyu Zhang\"},{\"authorId\":\"2323566\",\"name\":\"Fu-Chun Sun\"}],\"doi\":\"10.1109/TII.2020.3000240\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a2e481fdf58e542dbd12d55915379a30c5a02c1b\",\"title\":\"Active Object Discovery and Localization Using Sound-Induced Attention\",\"url\":\"https://www.semanticscholar.org/paper/a2e481fdf58e542dbd12d55915379a30c5a02c1b\",\"venue\":\"IEEE Transactions on Industrial Informatics\",\"year\":2021},{\"arxivId\":\"2006.14613\",\"authors\":[{\"authorId\":\"14258597\",\"name\":\"A. Jabri\"},{\"authorId\":\"144956994\",\"name\":\"Andrew Owens\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c78b00f2abbf7523a860e717f767b0bb8f860143\",\"title\":\"Space-Time Correspondence as a Contrastive Random Walk\",\"url\":\"https://www.semanticscholar.org/paper/c78b00f2abbf7523a860e717f767b0bb8f860143\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48080348\",\"name\":\"D. Hu\"},{\"authorId\":\"144962210\",\"name\":\"F. Nie\"},{\"authorId\":\"1720243\",\"name\":\"X. Li\"}],\"doi\":\"10.1109/CVPR.2019.00947\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8abc9fc312fc6916725ec94816ab26c582cf1a90\",\"title\":\"Deep Multimodal Clustering for Unsupervised Audiovisual Learning\",\"url\":\"https://www.semanticscholar.org/paper/8abc9fc312fc6916725ec94816ab26c582cf1a90\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2007.10175\",\"authors\":[{\"authorId\":\"89293047\",\"name\":\"Jordan J. Bird\"},{\"authorId\":\"144708349\",\"name\":\"Diego R. Faria\"},{\"authorId\":\"2097466\",\"name\":\"C. Premebida\"},{\"authorId\":\"151473812\",\"name\":\"Anik\\u00f3 Ek\\u00e1rt\"},{\"authorId\":\"1737941\",\"name\":\"George Vogiatzis\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6732715a937fb514372ec1805937fc2b7e048561\",\"title\":\"Look and Listen: A Multi-modality Late Fusion Approach to Scene Classification for Autonomous Machines\",\"url\":\"https://www.semanticscholar.org/paper/6732715a937fb514372ec1805937fc2b7e048561\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3839467\",\"name\":\"Toshiki Kikuchi\"},{\"authorId\":\"3057653\",\"name\":\"Yuko Ozasa\"}],\"doi\":\"10.1109/ICASSP.2018.8461853\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"e9f113435abe50f2b2fee3f240a3f310491485cc\",\"title\":\"Watch, Listen Once, and Sync: Audio-Visual Synchronization With Multi-Modal Regression Cnn\",\"url\":\"https://www.semanticscholar.org/paper/e9f113435abe50f2b2fee3f240a3f310491485cc\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40217426\",\"name\":\"S. Parekh\"},{\"authorId\":\"1807587\",\"name\":\"S. Essid\"},{\"authorId\":\"2889451\",\"name\":\"A. Ozerov\"},{\"authorId\":\"1756744\",\"name\":\"Ngoc Q. K. Duong\"},{\"authorId\":\"144565372\",\"name\":\"P. P\\u00e9rez\"},{\"authorId\":\"145793390\",\"name\":\"G. Richard\"}],\"doi\":\"10.1109/TASLP.2019.2957889\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"300b6751b7ba68908afdd695f6ca5dfb2ff19d07\",\"title\":\"Weakly Supervised Representation Learning for Audio-Visual Scene Analysis\",\"url\":\"https://www.semanticscholar.org/paper/300b6751b7ba68908afdd695f6ca5dfb2ff19d07\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1600703039\",\"name\":\"Janani Ramaswamy\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053895\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"380e7cc65c7be734f2179953bd921630afdee6ec\",\"title\":\"What Makes the Sound?: A Dual-Modality Interacting Network for Audio-Visual Event Localization\",\"url\":\"https://www.semanticscholar.org/paper/380e7cc65c7be734f2179953bd921630afdee6ec\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3443095\",\"name\":\"Bruno Korbar\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"c97774191be232678a45d343a25fcc0c96c065e7\",\"title\":\"Co-Training of Audio and Video Representations from Self-Supervised Temporal Synchronization\",\"url\":\"https://www.semanticscholar.org/paper/c97774191be232678a45d343a25fcc0c96c065e7\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2007.01851\",\"authors\":[{\"authorId\":\"3393217\",\"name\":\"Dhiraj Gandhi\"},{\"authorId\":\"50179097\",\"name\":\"Abhinav Gupta\"},{\"authorId\":\"34026610\",\"name\":\"Lerrel Pinto\"}],\"doi\":\"10.15607/RSS.2020.XVI.002\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c9f9ee3659c2a855b33ae256e98b05c51b2e30b7\",\"title\":\"Swoosh! Rattle! Thump! - Actions that Sound\",\"url\":\"https://www.semanticscholar.org/paper/c9f9ee3659c2a855b33ae256e98b05c51b2e30b7\",\"venue\":\"RSS 2020\",\"year\":2020},{\"arxivId\":\"2002.12247\",\"authors\":[{\"authorId\":\"2475428\",\"name\":\"Spyros Gidaris\"},{\"authorId\":\"72165961\",\"name\":\"Andrei Bursuc\"},{\"authorId\":\"2505902\",\"name\":\"Nikos Komodakis\"},{\"authorId\":\"1398301486\",\"name\":\"P. P\\u00e9rez\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"}],\"doi\":\"10.1109/CVPR42600.2020.00696\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a96d5d6da7d0dfb5c06a8d1c6b5d9036d7a9215\",\"title\":\"Learning Representations by Predicting Bags of Visual Words\",\"url\":\"https://www.semanticscholar.org/paper/8a96d5d6da7d0dfb5c06a8d1c6b5d9036d7a9215\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1801.03150\",\"authors\":[{\"authorId\":\"95743023\",\"name\":\"Mathew Monfort\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"3298267\",\"name\":\"Sarah Adel Bargal\"},{\"authorId\":\"50112310\",\"name\":\"Alex Andonian\"},{\"authorId\":\"12082007\",\"name\":\"Tom Yan\"},{\"authorId\":\"40544169\",\"name\":\"K. Ramakrishnan\"},{\"authorId\":\"49860655\",\"name\":\"L. Brown\"},{\"authorId\":\"33421444\",\"name\":\"Quanfu Fan\"},{\"authorId\":\"1891570\",\"name\":\"Dan Gutfreund\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"}],\"doi\":\"10.1109/TPAMI.2019.2901464\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"07174c2f209f15cacf9ad3422b48652df286be69\",\"title\":\"Moments in Time Dataset: One Million Videos for Event Understanding\",\"url\":\"https://www.semanticscholar.org/paper/07174c2f209f15cacf9ad3422b48652df286be69\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":\"2007.12130\",\"authors\":[{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"2479187\",\"name\":\"Moitreya Chatterjee\"},{\"authorId\":\"145237406\",\"name\":\"N. Ahuja\"}],\"doi\":\"10.1007/978-3-030-58583-9_42\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"02f3ced09497c5db59985b2a5db9d3d0aebe5074\",\"title\":\"Sound2Sight: Generating Visual Dynamics from Sound and Context\",\"url\":\"https://www.semanticscholar.org/paper/02f3ced09497c5db59985b2a5db9d3d0aebe5074\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2001.05312\",\"authors\":[{\"authorId\":\"3263198\",\"name\":\"B. Mathisen\"},{\"authorId\":\"1732268\",\"name\":\"A. Aamodt\"},{\"authorId\":\"1694563\",\"name\":\"Kerstin Bach\"},{\"authorId\":\"3310967\",\"name\":\"Helge Langseth\"}],\"doi\":\"10.1007/s13748-019-00201-2\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b9d2510c39e68bcaa0b1cc20e4c9392cc3641092\",\"title\":\"Learning similarity measures from data\",\"url\":\"https://www.semanticscholar.org/paper/b9d2510c39e68bcaa0b1cc20e4c9392cc3641092\",\"venue\":\"Progress in Artificial Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47792365\",\"name\":\"Y. Asano\"},{\"authorId\":\"49359942\",\"name\":\"C. Rupprecht\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"245a50c0f6f6b0c1ea3ab77b2df116b83ba667d8\",\"title\":\"Surprising Effectiveness of Few-Image Unsupervised Feature Learning\",\"url\":\"https://www.semanticscholar.org/paper/245a50c0f6f6b0c1ea3ab77b2df116b83ba667d8\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48775435\",\"name\":\"Arshdeep Singh\"},{\"authorId\":\"2596382\",\"name\":\"P. Rajan\"},{\"authorId\":\"2175431\",\"name\":\"A. Bhavsar\"}],\"doi\":\"10.1016/j.patrec.2020.02.004\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ad620f8a6dda69cdf755aadde747bb75d75ad015\",\"title\":\"SVD-based redundancy removal in 1-D CNNs for acoustic scene classification\",\"url\":\"https://www.semanticscholar.org/paper/ad620f8a6dda69cdf755aadde747bb75d75ad015\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2020},{\"arxivId\":\"1911.05894\",\"authors\":[{\"authorId\":\"35996413\",\"name\":\"A. Jansen\"},{\"authorId\":\"1745455\",\"name\":\"D. Ellis\"},{\"authorId\":\"50781940\",\"name\":\"Shawn Hershey\"},{\"authorId\":\"37107826\",\"name\":\"R. C. Moore\"},{\"authorId\":\"2114994\",\"name\":\"M. Plakal\"},{\"authorId\":\"2054252\",\"name\":\"A. Popat\"},{\"authorId\":\"2278009\",\"name\":\"R. A. Saurous\"}],\"doi\":\"10.1109/ICASSP40776.2020.9054137\",\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"d8db0c9bdc2acf3c3fb25d5474f24472e8372bf8\",\"title\":\"Coincidence, Categorization, and Consolidation: Learning to Recognize Sounds with Minimal Supervision\",\"url\":\"https://www.semanticscholar.org/paper/d8db0c9bdc2acf3c3fb25d5474f24472e8372bf8\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"2008.06607\",\"authors\":[{\"authorId\":\"2840852\",\"name\":\"Jianbo Jiao\"},{\"authorId\":\"2212080\",\"name\":\"Yifan Cai\"},{\"authorId\":\"1397053973\",\"name\":\"Mohammad Alsharid\"},{\"authorId\":\"7599395\",\"name\":\"L. Drukker\"},{\"authorId\":\"1499292198\",\"name\":\"Aris Papageorghiou\"},{\"authorId\":\"144870105\",\"name\":\"J. Noble\"}],\"doi\":\"10.1007/978-3-030-59716-0_51\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d4512f2c17f26618cfdc3c7f349ebe5bb7b6ee0e\",\"title\":\"Self-supervised Contrastive Video-Speech Representation Learning for Ultrasound\",\"url\":\"https://www.semanticscholar.org/paper/d4512f2c17f26618cfdc3c7f349ebe5bb7b6ee0e\",\"venue\":\"MICCAI\",\"year\":2020},{\"arxivId\":\"2012.11552\",\"authors\":[{\"authorId\":\"2475428\",\"name\":\"Spyros Gidaris\"},{\"authorId\":\"3056236\",\"name\":\"Andrei Bursuc\"},{\"authorId\":\"145037972\",\"name\":\"Gilles Puy\"},{\"authorId\":\"2505902\",\"name\":\"Nikos Komodakis\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"},{\"authorId\":\"144565371\",\"name\":\"P. P\\u00e9rez\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0026d112cf8f3b98e45455d967de9ca3c33d22f6\",\"title\":\"Online Bag-of-Visual-Words Generation for Unsupervised Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/0026d112cf8f3b98e45455d967de9ca3c33d22f6\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1576489018\",\"name\":\"Bang Hu Yin\"},{\"authorId\":\"98228895\",\"name\":\"Xiu Li\"}],\"doi\":\"10.1088/1757-899x/715/1/012082\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ecfc3c33bbd319e7bf18f60ea2c66911d87044ca\",\"title\":\"Cross-modal retrieval by an end to end way\",\"url\":\"https://www.semanticscholar.org/paper/ecfc3c33bbd319e7bf18f60ea2c66911d87044ca\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47820818\",\"name\":\"J. Pu\"},{\"authorId\":\"1780393\",\"name\":\"Yannis Panagakis\"},{\"authorId\":\"145387780\",\"name\":\"M. Pantic\"}],\"doi\":\"10.1109/LSP.2020.2996412\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"922ed60c21df0bfff640bec0a3cf48d83f58eb54\",\"title\":\"Active Speaker Detection and Localization in Videos Using Low-Rank and Kernelized Sparsity\",\"url\":\"https://www.semanticscholar.org/paper/922ed60c21df0bfff640bec0a3cf48d83f58eb54\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2020},{\"arxivId\":\"1906.00910\",\"authors\":[{\"authorId\":\"143902541\",\"name\":\"Philip Bachman\"},{\"authorId\":\"40482726\",\"name\":\"R. Devon Hjelm\"},{\"authorId\":\"134859150\",\"name\":\"William Buchwalter\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9b09d296059909490096e34e9df2d95314787ad5\",\"title\":\"Learning Representations by Maximizing Mutual Information Across Views\",\"url\":\"https://www.semanticscholar.org/paper/9b09d296059909490096e34e9df2d95314787ad5\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1807.00230\",\"authors\":[{\"authorId\":\"3443095\",\"name\":\"Bruno Korbar\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2e057a9b195f0ea2d1c5a1e88ff9606f9b67ef8b\",\"title\":\"Cooperative Learning of Audio and Video Models from Self-Supervised Synchronization\",\"url\":\"https://www.semanticscholar.org/paper/2e057a9b195f0ea2d1c5a1e88ff9606f9b67ef8b\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"2009.09805\",\"authors\":[{\"authorId\":\"1491401265\",\"name\":\"Shuang Ma\"},{\"authorId\":\"46490565\",\"name\":\"Zhaoyang Zeng\"},{\"authorId\":\"1381192475\",\"name\":\"Daniel McDuff\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7df5dd31f2ce600a4be589dff4d6a758be262324\",\"title\":\"Learning Audio-Visual Representations with Active Contrastive Coding\",\"url\":\"https://www.semanticscholar.org/paper/7df5dd31f2ce600a4be589dff4d6a758be262324\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2928718\",\"name\":\"S. Grollmisch\"},{\"authorId\":\"144922828\",\"name\":\"E. Cano\"},{\"authorId\":\"2054846\",\"name\":\"Christian Kehling\"},{\"authorId\":\"1941069\",\"name\":\"Michael Taenzer\"}],\"doi\":\"10.23919/Eusipco47968.2020.9287743\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"91cd0134bf1b3fe6b103f39c52db36722cce34df\",\"title\":\"Analyzing the Potential of Pre-Trained Embeddings for Audio Classification Tasks\",\"url\":\"https://www.semanticscholar.org/paper/91cd0134bf1b3fe6b103f39c52db36722cce34df\",\"venue\":\"2020 28th European Signal Processing Conference (EUSIPCO)\",\"year\":2021},{\"arxivId\":\"2011.01819\",\"authors\":[{\"authorId\":\"143698653\",\"name\":\"P. Morgado\"},{\"authorId\":\"3184077\",\"name\":\"Y. Li\"},{\"authorId\":\"1699559\",\"name\":\"N. Vasconcelos\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"eeb33ad2ede9944918724978bcbfb08b4c8c50a8\",\"title\":\"Learning Representations from Audio-Visual Spatial Alignment\",\"url\":\"https://www.semanticscholar.org/paper/eeb33ad2ede9944918724978bcbfb08b4c8c50a8\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47519958\",\"name\":\"Rui Qian\"},{\"authorId\":\"153211990\",\"name\":\"Di Hu\"},{\"authorId\":\"2451839\",\"name\":\"H. Dinkel\"},{\"authorId\":\"3000684\",\"name\":\"Mengyue Wu\"},{\"authorId\":\"145857587\",\"name\":\"Ning Xu\"},{\"authorId\":\"8131625\",\"name\":\"W. Lin\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8f430dbeb164ef96dedfd83bf2583684fab2faa5\",\"title\":\"A Two-Stage Framework for Multiple Sound-Source Localization\",\"url\":\"https://www.semanticscholar.org/paper/8f430dbeb164ef96dedfd83bf2583684fab2faa5\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123910025\",\"name\":\"Sangeeta Kumari\"},{\"authorId\":\"3167328\",\"name\":\"D. Roy\"},{\"authorId\":\"143783559\",\"name\":\"M. Cartwright\"},{\"authorId\":\"34894065\",\"name\":\"J. Bello\"},{\"authorId\":\"144248962\",\"name\":\"A. Arora\"}],\"doi\":\"10.1109/IPDPSW.2019.00145\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ffabec70afdbc8fc10f3e5a19dbb1dacc8ff00db\",\"title\":\"EdgeL^3: Compressing L^3-Net for Mote Scale Urban Noise Monitoring\",\"url\":\"https://www.semanticscholar.org/paper/ffabec70afdbc8fc10f3e5a19dbb1dacc8ff00db\",\"venue\":\"2019 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)\",\"year\":2019},{\"arxivId\":\"2008.05789\",\"authors\":[{\"authorId\":\"1443743722\",\"name\":\"Ying Cheng\"},{\"authorId\":\"29068663\",\"name\":\"Ruize Wang\"},{\"authorId\":\"48699340\",\"name\":\"Zhihao Pan\"},{\"authorId\":\"51304315\",\"name\":\"Rui Feng\"},{\"authorId\":\"3067458\",\"name\":\"Yuejie Zhang\"}],\"doi\":\"10.1145/3394171.3413869\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"17b28643a5aaed62fbccd98781d4ebc0f0477afa\",\"title\":\"Look, Listen, and Attend: Co-Attention Network for Self-Supervised Audio-Visual Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/17b28643a5aaed62fbccd98781d4ebc0f0477afa\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7299839\",\"name\":\"Huadong Tan\"},{\"authorId\":\"89136398\",\"name\":\"Guang Wu\"},{\"authorId\":\"152226296\",\"name\":\"Pengcheng Zhao\"},{\"authorId\":\"47558599\",\"name\":\"Yan-Xiang Chen\"}],\"doi\":\"10.1109/ICASSP40776.2020.9052918\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8fd8e6b8ebe89bd7500d2639fcf42f52e3e771fa\",\"title\":\"Spectrogram Analysis Via Self-Attention for Realizing Cross-Model Visual-Audio Generation\",\"url\":\"https://www.semanticscholar.org/paper/8fd8e6b8ebe89bd7500d2639fcf42f52e3e771fa\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"2002.02650\",\"authors\":[{\"authorId\":\"1491590026\",\"name\":\"Patrick Keller\"},{\"authorId\":\"94158679\",\"name\":\"L. Plein\"},{\"authorId\":\"11128727\",\"name\":\"Tegawend\\u00e9 F. Bissyand\\u00e9\"},{\"authorId\":\"2445617\",\"name\":\"J. Klein\"},{\"authorId\":\"47681863\",\"name\":\"Y. L. Traon\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"027c95b0f028fa2fdb1c5c8bc8ea7e89e17a67fa\",\"title\":\"What You See is What it Means! Semantic Representation Learning of Code based on Visualization and Transfer Learning\",\"url\":\"https://www.semanticscholar.org/paper/027c95b0f028fa2fdb1c5c8bc8ea7e89e17a67fa\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1910.02930\",\"authors\":[{\"authorId\":\"2689239\",\"name\":\"Jack Hessel\"},{\"authorId\":\"48157646\",\"name\":\"Bo Pang\"},{\"authorId\":\"39815369\",\"name\":\"Z. Zhu\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"}],\"doi\":\"10.18653/v1/K19-1039\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"659e2f1d54b88252bcf08c4f3d54c0832a181c3e\",\"title\":\"A Case Study on Combining ASR and Visual Features for Generating Instructional Video Captions\",\"url\":\"https://www.semanticscholar.org/paper/659e2f1d54b88252bcf08c4f3d54c0832a181c3e\",\"venue\":\"CoNLL\",\"year\":2019},{\"arxivId\":\"1801.02690\",\"authors\":[{\"authorId\":\"33098317\",\"name\":\"A. Jimenez\"},{\"authorId\":\"2532460\",\"name\":\"B. Elizalde\"},{\"authorId\":\"1681921\",\"name\":\"B. Raj\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8c79bc04aff6d293610d112f8a760faef98f4b86\",\"title\":\"DCASE 2017 Task 1: Acoustic Scene Classification Using Shift-Invariant Kernels and Random Features\",\"url\":\"https://www.semanticscholar.org/paper/8c79bc04aff6d293610d112f8a760faef98f4b86\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1905.09773\",\"authors\":[{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"2112779\",\"name\":\"Tali Dekel\"},{\"authorId\":\"9340074\",\"name\":\"Changil Kim\"},{\"authorId\":\"2138834\",\"name\":\"Inbar Mosseri\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"},{\"authorId\":\"144544291\",\"name\":\"Michael Rubinstein\"},{\"authorId\":\"1752521\",\"name\":\"W. Matusik\"}],\"doi\":\"10.1109/CVPR.2019.00772\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e4b54f2e0ebbe450e2c527cf5a00d4816980a913\",\"title\":\"Speech2Face: Learning the Face Behind a Voice\",\"url\":\"https://www.semanticscholar.org/paper/e4b54f2e0ebbe450e2c527cf5a00d4816980a913\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1810.10974\",\"authors\":[{\"authorId\":\"37759796\",\"name\":\"S. Palazzo\"},{\"authorId\":\"2441118\",\"name\":\"C. Spampinato\"},{\"authorId\":\"2912641\",\"name\":\"I. Kavasidis\"},{\"authorId\":\"144027622\",\"name\":\"D. Giordano\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/tpami.2020.2995909\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0232f39cf09a47982c24e311a7424f466f964b22\",\"title\":\"Decoding Brain Representations by Multimodal Learning of Neural Activity and Visual Features\",\"url\":\"https://www.semanticscholar.org/paper/0232f39cf09a47982c24e311a7424f466f964b22\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41019567\",\"name\":\"Lukas Tuggener\"},{\"authorId\":\"1985672\",\"name\":\"M. Amirian\"},{\"authorId\":\"2043513\",\"name\":\"F. Benites\"},{\"authorId\":\"25095856\",\"name\":\"Pius von D\\u00e4niken\"},{\"authorId\":\"1491232062\",\"name\":\"Prakhar Gupta\"},{\"authorId\":\"73681262\",\"name\":\"F. Schilling\"},{\"authorId\":\"1831096656\",\"name\":\"Thilo Stadelmann\"}],\"doi\":\"10.3390/ai1040031\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"71446ab82087505d7849b1b6f1fce4dcda751c1d\",\"title\":\"Design Patterns for Resource-Constrained Automated Deep-Learning Methods\",\"url\":\"https://www.semanticscholar.org/paper/71446ab82087505d7849b1b6f1fce4dcda751c1d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1808.05561\",\"authors\":[{\"authorId\":\"7641268\",\"name\":\"Samuel Albanie\"},{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1145/3240508.3240578\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"540831094fd9b80469c8dacb9320b7e342b50e03\",\"title\":\"Emotion Recognition in Speech using Cross-Modal Transfer in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/540831094fd9b80469c8dacb9320b7e342b50e03\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"2006.05553\",\"authors\":[{\"authorId\":\"145639633\",\"name\":\"Yao-Hung Hubert Tsai\"},{\"authorId\":\"1390716752\",\"name\":\"Han Zhao\"},{\"authorId\":\"143979662\",\"name\":\"M. Yamada\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"cb02090828e24fff5df2d4a0d677d46e32ad0928\",\"title\":\"Neural Methods for Point-wise Dependency Estimation\",\"url\":\"https://www.semanticscholar.org/paper/cb02090828e24fff5df2d4a0d677d46e32ad0928\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34777509\",\"name\":\"Yapeng Tian\"},{\"authorId\":\"40580714\",\"name\":\"Dingzeyu Li\"},{\"authorId\":\"100887531\",\"name\":\"Chenliang Xu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3b0697bf5bded55d59c58e5d955d49354afbcd95\",\"title\":\"Weakly-Supervised Audio-Visual Video Parsing Toward Unified Multisensory Perception\",\"url\":\"https://www.semanticscholar.org/paper/3b0697bf5bded55d59c58e5d955d49354afbcd95\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1786276\",\"name\":\"Justin Salamon\"},{\"authorId\":\"3215419\",\"name\":\"B. McFee\"},{\"authorId\":\"48982127\",\"name\":\"P. Li\"},{\"authorId\":\"34894065\",\"name\":\"J. Bello\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b0d83370e1843d0e071f53920d192da182ef2355\",\"title\":\"DCASE 2017 SUBMISSION : MULTIPLE INSTANCE LEARNING FOR SOUND EVENT DETECTION\",\"url\":\"https://www.semanticscholar.org/paper/b0d83370e1843d0e071f53920d192da182ef2355\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9936815\",\"name\":\"Olga Slizovskaia\"},{\"authorId\":\"145217215\",\"name\":\"E. G\\u00f3mez\"},{\"authorId\":\"1916387\",\"name\":\"G. Haro\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"83b471ce32e3d218d7b4b55b6b0a3fa5559b0342\",\"title\":\"Correspondence between audio and visual deep models for musical instrument detection in video recordings\",\"url\":\"https://www.semanticscholar.org/paper/83b471ce32e3d218d7b4b55b6b0a3fa5559b0342\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1807.07364\",\"authors\":[{\"authorId\":\"144669071\",\"name\":\"Shah Nawaz\"},{\"authorId\":\"51093708\",\"name\":\"Muhammad Kamran Janjua\"},{\"authorId\":\"3457883\",\"name\":\"Alessandro Calefati\"},{\"authorId\":\"145116184\",\"name\":\"I. Gallo\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7fe117f5bbf91f85a97720eca8be36da87a5f8a8\",\"title\":\"Revisiting Cross Modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/7fe117f5bbf91f85a97720eca8be36da87a5f8a8\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2351434\",\"name\":\"Zhongwen Xu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6bd7ff039ff38f4bb41f7a4b9a1f370ef02eed80\",\"title\":\"Large-scale video analysis and understanding\",\"url\":\"https://www.semanticscholar.org/paper/6bd7ff039ff38f4bb41f7a4b9a1f370ef02eed80\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"2007.13976\",\"authors\":[{\"authorId\":\"51298994\",\"name\":\"Yoshiki Masuyama\"},{\"authorId\":\"2730311\",\"name\":\"Yoshiaki Bando\"},{\"authorId\":\"1968008\",\"name\":\"K. Yatabe\"},{\"authorId\":\"1936377\",\"name\":\"Yoko Sasaki\"},{\"authorId\":\"120942871\",\"name\":\"M. Onishi\"},{\"authorId\":\"47735058\",\"name\":\"Y. Oikawa\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0a10b7c9c881924d843445b258eba7209e9d0d8d\",\"title\":\"Self-supervised Neural Audio-Visual Sound Source Localization via Probabilistic Spatial Modeling\",\"url\":\"https://www.semanticscholar.org/paper/0a10b7c9c881924d843445b258eba7209e9d0d8d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.03028\",\"authors\":[{\"authorId\":\"8301799\",\"name\":\"Lingyu Zhu\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4024fb95ebf35d0edd25123b604d26e832b61a6b\",\"title\":\"Visually Guided Sound Source Separation using Cascaded Opponent Filter Network\",\"url\":\"https://www.semanticscholar.org/paper/4024fb95ebf35d0edd25123b604d26e832b61a6b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2001.03063\",\"authors\":[{\"authorId\":\"3200442\",\"name\":\"A. Tsiami\"},{\"authorId\":\"2539459\",\"name\":\"Petros Koutras\"},{\"authorId\":\"1750686\",\"name\":\"P. Maragos\"}],\"doi\":\"10.1109/cvpr42600.2020.00482\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e296a1f529d9caa125e8c6a56cac61423e04b41b\",\"title\":\"STAViS: Spatio-Temporal AudioVisual Saliency Network\",\"url\":\"https://www.semanticscholar.org/paper/e296a1f529d9caa125e8c6a56cac61423e04b41b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1902.06162\",\"authors\":[{\"authorId\":\"29724362\",\"name\":\"Longlong Jing\"},{\"authorId\":\"35484757\",\"name\":\"Yingli Tian\"}],\"doi\":\"10.1109/tpami.2020.2992393\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4c94ee7df6bc2bfcac76703be4f059a79010f7e5\",\"title\":\"Self-supervised Visual Feature Learning with Deep Neural Networks: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/4c94ee7df6bc2bfcac76703be4f059a79010f7e5\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"1803.08842\",\"authors\":[{\"authorId\":\"34777509\",\"name\":\"Yapeng Tian\"},{\"authorId\":\"145458657\",\"name\":\"Jing Shi\"},{\"authorId\":\"2868721\",\"name\":\"Bochen Li\"},{\"authorId\":\"3270912\",\"name\":\"Z. Duan\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":\"10.1007/978-3-030-01216-8_16\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a5e58ef7c11515847967019fbe01fa033d9bdd88\",\"title\":\"Audio-Visual Event Localization in Unconstrained Videos\",\"url\":\"https://www.semanticscholar.org/paper/a5e58ef7c11515847967019fbe01fa033d9bdd88\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1910.08732\",\"authors\":[{\"authorId\":\"50811450\",\"name\":\"Kranti K. Parida\"},{\"authorId\":\"31352334\",\"name\":\"Neeraj Matiyali\"},{\"authorId\":\"1720741\",\"name\":\"T. Guha\"},{\"authorId\":\"144054466\",\"name\":\"G. Sharma\"}],\"doi\":\"10.1109/WACV45572.2020.9093438\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a243ee80146ca37fc296bc67043ea2a67222de68\",\"title\":\"Coordinated Joint Multimodal Embeddings for Generalized Audio-Visual Zero-shot Classification and Retrieval of Videos\",\"url\":\"https://www.semanticscholar.org/paper/a243ee80146ca37fc296bc67043ea2a67222de68\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1911.05371\",\"authors\":[{\"authorId\":\"47792365\",\"name\":\"Y. Asano\"},{\"authorId\":\"49359942\",\"name\":\"C. Rupprecht\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"55c451f6cf2e96f45678d2dce6075a93129004c8\",\"title\":\"Self-labelling via simultaneous clustering and representation learning\",\"url\":\"https://www.semanticscholar.org/paper/55c451f6cf2e96f45678d2dce6075a93129004c8\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"2005.12433\",\"authors\":[{\"authorId\":\"2470573\",\"name\":\"S. Yuan\"},{\"authorId\":\"7916525\",\"name\":\"Xintao Wu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2f40c7906a7d612d1bdcba5dfd22520fd17a8cd1\",\"title\":\"Deep Learning for Insider Threat Detection: Review, Challenges and Opportunities\",\"url\":\"https://www.semanticscholar.org/paper/2f40c7906a7d612d1bdcba5dfd22520fd17a8cd1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.06170\",\"authors\":[{\"authorId\":\"151444035\",\"name\":\"Samyak Jain\"},{\"authorId\":\"34935738\",\"name\":\"Pradeep Yarlagadda\"},{\"authorId\":\"48236457\",\"name\":\"R. Subramanian\"},{\"authorId\":\"145091336\",\"name\":\"V. Gandhi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"40a7f20cf6a05a481146bd7f18ba747d17700ebd\",\"title\":\"AViNet: Diving Deep into Audio-Visual Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/40a7f20cf6a05a481146bd7f18ba747d17700ebd\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2001.00294\",\"authors\":[{\"authorId\":\"152504322\",\"name\":\"Dezhao Luo\"},{\"authorId\":\"73100429\",\"name\":\"Chang Liu\"},{\"authorId\":\"2187183\",\"name\":\"Y. Zhou\"},{\"authorId\":\"8697322\",\"name\":\"Dongbao Yang\"},{\"authorId\":\"2006302\",\"name\":\"Can Ma\"},{\"authorId\":\"12605536\",\"name\":\"Qixiang Ye\"},{\"authorId\":\"47824616\",\"name\":\"Weiping Wang\"}],\"doi\":\"10.1609/AAAI.V34I07.6840\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"63a8ad8721ae8f15f3ad27b2974aff2f90d10022\",\"title\":\"Video Cloze Procedure for Self-Supervised Spatio-Temporal Learning\",\"url\":\"https://www.semanticscholar.org/paper/63a8ad8721ae8f15f3ad27b2974aff2f90d10022\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1804703\",\"name\":\"Mark D. Plumbley\"},{\"authorId\":\"1789431\",\"name\":\"C. Kroos\"},{\"authorId\":\"34894065\",\"name\":\"J. Bello\"},{\"authorId\":\"145793390\",\"name\":\"G. Richard\"},{\"authorId\":\"1745455\",\"name\":\"D. Ellis\"},{\"authorId\":\"145022667\",\"name\":\"A. Mesaros\"}],\"doi\":\"10.33682/1syg-dy60\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2af6d3e089ccc63757dd00c4a16fc4ffecbd242e\",\"title\":\"Proceedings of the Detection and Classification of Acoustic Scenes and Events 2018 Workshop (DCASE2018)\",\"url\":\"https://www.semanticscholar.org/paper/2af6d3e089ccc63757dd00c4a16fc4ffecbd242e\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144036213\",\"name\":\"Thomas Langlois\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"07f5a895aacabd9bd918360012c1a671079d334e\",\"title\":\"MuVi Score Dataset : Modeling Human Music-Video Pairing Preferences\",\"url\":\"https://www.semanticscholar.org/paper/07f5a895aacabd9bd918360012c1a671079d334e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2004.03873\",\"authors\":[{\"authorId\":\"9936815\",\"name\":\"Olga Slizovskaia\"},{\"authorId\":\"1916387\",\"name\":\"G. Haro\"},{\"authorId\":\"145217215\",\"name\":\"E. G\\u00f3mez\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fc6767792c34f509b053523b5327b2b88f1d6521\",\"title\":\"Conditioned Source Separation for Music Instrument Performances\",\"url\":\"https://www.semanticscholar.org/paper/fc6767792c34f509b053523b5327b2b88f1d6521\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1809.06367\",\"authors\":[{\"authorId\":\"3306593\",\"name\":\"Edouard Oyallon\"},{\"authorId\":\"2134433\",\"name\":\"Sergey Zagoruyko\"},{\"authorId\":\"24040986\",\"name\":\"Gabriel Huang\"},{\"authorId\":\"2505902\",\"name\":\"Nikos Komodakis\"},{\"authorId\":\"1388317459\",\"name\":\"S. Lacoste-Julien\"},{\"authorId\":\"1758219\",\"name\":\"Matthew B. Blaschko\"},{\"authorId\":\"1829344\",\"name\":\"Eugene Belilovsky\"}],\"doi\":\"10.1109/TPAMI.2018.2855738\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"099c704bdbd6344bba4c1aefa4dea17f1d00c61c\",\"title\":\"Scattering Networks for Hybrid Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/099c704bdbd6344bba4c1aefa4dea17f1d00c61c\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":\"2002.04076\",\"authors\":[{\"authorId\":\"50469466\",\"name\":\"P. Verma\"},{\"authorId\":\"1772984\",\"name\":\"J. Salisbury\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9ef729fc8bd7c99255ca05af9d9af4a2dc64be75\",\"title\":\"Unsupervised Learning of Audio Perception for Robotics Applications: Learning to Project Data to T-SNE/UMAP space\",\"url\":\"https://www.semanticscholar.org/paper/9ef729fc8bd7c99255ca05af9d9af4a2dc64be75\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2507441\",\"name\":\"Vincent Lostanlen\"},{\"authorId\":\"2677556\",\"name\":\"G. Lafay\"},{\"authorId\":\"2708847\",\"name\":\"J. And\\u00e9n\"},{\"authorId\":\"2853956\",\"name\":\"M. Lagrange\"}],\"doi\":\"10.1186/S13636-018-0138-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4eb2fa464a145fe437dd51eb1c10d958a9384ed2\",\"title\":\"Relevance-based quantization of scattering features for unsupervised mining of environmental audio\",\"url\":\"https://www.semanticscholar.org/paper/4eb2fa464a145fe437dd51eb1c10d958a9384ed2\",\"venue\":\"EURASIP J. Audio Speech Music. Process.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47077615\",\"name\":\"J. Munro\"},{\"authorId\":\"1677780022\",\"name\":\"Dima Damen\"}],\"doi\":\"10.1109/cvpr42600.2020.00020\",\"intent\":[\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"646a256e30cd244b668660c32b529ff31a874a78\",\"title\":\"Multi-Modal Domain Adaptation for Fine-Grained Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/646a256e30cd244b668660c32b529ff31a874a78\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2007.10703\",\"authors\":[{\"authorId\":\"31638576\",\"name\":\"A. Arnab\"},{\"authorId\":\"1491624845\",\"name\":\"Chen Sun\"},{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"153433844\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1007/978-3-030-58607-2_44\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7d9660f127a880ec9757aedc90509524d744c15a\",\"title\":\"Uncertainty-Aware Weakly Supervised Action Detection from Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/7d9660f127a880ec9757aedc90509524d744c15a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145639633\",\"name\":\"Yao-Hung Hubert Tsai\"},{\"authorId\":\"46220633\",\"name\":\"Yue Wu\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"683448543f44fb46a0ddf5420c254a7329df873a\",\"title\":\"Demystifying Self-Supervised Learning: An Information-Theoretical Framework\",\"url\":\"https://www.semanticscholar.org/paper/683448543f44fb46a0ddf5420c254a7329df873a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.11866\",\"authors\":[{\"authorId\":\"2595189\",\"name\":\"Zehua Sun\"},{\"authorId\":\"120809631\",\"name\":\"Jiwang Liu\"},{\"authorId\":\"143969578\",\"name\":\"Qiuhong Ke\"},{\"authorId\":\"1877377\",\"name\":\"H. Rahmani\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"816236bf3219363bfe4b847363e137b1fe6712e7\",\"title\":\"Human Action Recognition from Various Data Modalities: A Review\",\"url\":\"https://www.semanticscholar.org/paper/816236bf3219363bfe4b847363e137b1fe6712e7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1910.11760\",\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"51333271\",\"name\":\"H. Zhao\"},{\"authorId\":\"4965440\",\"name\":\"Peihao Chen\"},{\"authorId\":\"66305116\",\"name\":\"D. Cox\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/ICCV.2019.00715\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"05c846b122dc64b6900c09b9210912615a3febb6\",\"title\":\"Self-Supervised Moving Vehicle Tracking With Stereo Sound\",\"url\":\"https://www.semanticscholar.org/paper/05c846b122dc64b6900c09b9210912615a3febb6\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7634810\",\"name\":\"Weiyao Wang\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"}],\"doi\":\"10.1109/CVPR42600.2020.01271\",\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"f6caf91f731fab861ef420f680cf691f12f70134\",\"title\":\"What Makes Training Multi-Modal Classification Networks Hard?\",\"url\":\"https://www.semanticscholar.org/paper/f6caf91f731fab861ef420f680cf691f12f70134\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1905.11137\",\"authors\":[{\"authorId\":\"7885575\",\"name\":\"E. Amrani\"},{\"authorId\":\"1397958297\",\"name\":\"R. Ben-Ari\"},{\"authorId\":\"120159179\",\"name\":\"Tal Hakim\"},{\"authorId\":\"144858358\",\"name\":\"Alex Bronstein\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ad52b2e7b7d66395ee65d282d422d27488dc140e\",\"title\":\"Toward Self-Supervised Object Detection in Unlabeled Videos\",\"url\":\"https://www.semanticscholar.org/paper/ad52b2e7b7d66395ee65d282d422d27488dc140e\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1711.02209\",\"authors\":[{\"authorId\":\"35996413\",\"name\":\"A. Jansen\"},{\"authorId\":\"2114994\",\"name\":\"M. Plakal\"},{\"authorId\":\"39420271\",\"name\":\"Ratheet Pandya\"},{\"authorId\":\"1745455\",\"name\":\"D. Ellis\"},{\"authorId\":\"50781940\",\"name\":\"Shawn Hershey\"},{\"authorId\":\"145183118\",\"name\":\"Jiayang Liu\"},{\"authorId\":\"1974225\",\"name\":\"R. C. Moore\"},{\"authorId\":\"2278009\",\"name\":\"R. A. Saurous\"}],\"doi\":\"10.1109/ICASSP.2018.8461684\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5d5fc66dd0fe38737dded9507396b45c2dae84e0\",\"title\":\"Unsupervised Learning of Semantic Audio Representations\",\"url\":\"https://www.semanticscholar.org/paper/5d5fc66dd0fe38737dded9507396b45c2dae84e0\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":\"2002.08742\",\"authors\":[{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"},{\"authorId\":\"7641268\",\"name\":\"Samuel Albanie\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/ICASSP40776.2020.9054057\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6edcd367fd429a013a1a777ebfa42528e37aa821\",\"title\":\"Disentangled Speech Embeddings Using Cross-Modal Self-Supervision\",\"url\":\"https://www.semanticscholar.org/paper/6edcd367fd429a013a1a777ebfa42528e37aa821\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48851910\",\"name\":\"Qing An\"},{\"authorId\":\"50827682\",\"name\":\"Yanhua Chen\"},{\"authorId\":\"25602326\",\"name\":\"Shu-sen Wu\"}],\"doi\":\"10.1117/12.2579682\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"412107a6389aadceb6493a126d82e1200854951d\",\"title\":\"Research on perceptual fusion of audio and video based on deep learning\",\"url\":\"https://www.semanticscholar.org/paper/412107a6389aadceb6493a126d82e1200854951d\",\"venue\":\"Other Conferences\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2481662\",\"name\":\"Y. Zhou\"},{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":\"10.1109/CVPR.2018.00775\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ebb1a828444cf3009cb4c4918d9350ceb5f3d547\",\"title\":\"Now You Shake Me: Towards Automatic 4D Cinema\",\"url\":\"https://www.semanticscholar.org/paper/ebb1a828444cf3009cb4c4918d9350ceb5f3d547\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33317650\",\"name\":\"M. Jaritz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"11adea48c41cb84721abef2890690d7b08710068\",\"title\":\"2D-3D scene understanding for autonomous driving\",\"url\":\"https://www.semanticscholar.org/paper/11adea48c41cb84721abef2890690d7b08710068\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2001.09414\",\"authors\":[{\"authorId\":\"153211990\",\"name\":\"Di Hu\"},{\"authorId\":\"98358780\",\"name\":\"Z. Wang\"},{\"authorId\":\"40518823\",\"name\":\"Haoyi Xiong\"},{\"authorId\":\"113144757\",\"name\":\"D. Wang\"},{\"authorId\":\"144962210\",\"name\":\"F. Nie\"},{\"authorId\":\"1721158\",\"name\":\"D. Dou\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"04b6568cb7f30c399157e94c30b44c59c00e251d\",\"title\":\"Curriculum Audiovisual Learning\",\"url\":\"https://www.semanticscholar.org/paper/04b6568cb7f30c399157e94c30b44c59c00e251d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.01616\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"153246625\",\"name\":\"Chang\\u2019an Chen\"},{\"authorId\":\"9187007\",\"name\":\"Z. Al-Halah\"},{\"authorId\":\"2368282\",\"name\":\"Carl Schissler\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1007/978-3-030-58545-7_38\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"33006edd74d92453903df5a53fa25539047c1850\",\"title\":\"VisualEchoes: Spatial Image Representation Learning through Echolocation\",\"url\":\"https://www.semanticscholar.org/paper/33006edd74d92453903df5a53fa25539047c1850\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1712.09680\",\"authors\":[{\"authorId\":\"3428237\",\"name\":\"Juncheng Billy Li\"},{\"authorId\":\"46393778\",\"name\":\"Y. Wang\"},{\"authorId\":\"2452082\",\"name\":\"Joseph Szurley\"},{\"authorId\":\"1740721\",\"name\":\"F. Metze\"},{\"authorId\":\"46634400\",\"name\":\"S. Das\"}],\"doi\":\"10.1109/ICASSP.2018.8462479\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1f684cad739a33ff25c817c102d62532c003f21e\",\"title\":\"A Light-Weight Multimodal Framework for Improved Environmental Audio Tagging\",\"url\":\"https://www.semanticscholar.org/paper/1f684cad739a33ff25c817c102d62532c003f21e\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1411176113\",\"name\":\"Irene Mart\\u00edn-Morat\\u00f3\"},{\"authorId\":\"2432536\",\"name\":\"M. Cobos\"},{\"authorId\":\"1682325\",\"name\":\"F. Ferri\"}],\"doi\":\"10.1109/TASLP.2020.3001683\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f9ded777936f5bd453986dff0364815109906da1\",\"title\":\"Adaptive Distance-Based Pooling in Convolutional Neural Networks for Audio Event Classification\",\"url\":\"https://www.semanticscholar.org/paper/f9ded777936f5bd453986dff0364815109906da1\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47171633\",\"name\":\"J. Cramer\"},{\"authorId\":\"2299056\",\"name\":\"Ho-Hsiang Wu\"},{\"authorId\":\"1786276\",\"name\":\"Justin Salamon\"},{\"authorId\":\"34894065\",\"name\":\"J. Bello\"}],\"doi\":\"10.1109/ICASSP.2019.8682475\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"586afdbc1ada3a9e3e0bbc36cc334faca4d26f4a\",\"title\":\"Look, Listen, and Learn More: Design Choices for Deep Audio Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/586afdbc1ada3a9e3e0bbc36cc334faca4d26f4a\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"16149902\",\"name\":\"Janani Ramaswamy\"},{\"authorId\":\"144009889\",\"name\":\"Sukhendu Das\"}],\"doi\":\"10.1109/WACV45572.2020.9093616\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c911d81bddb48490a02258e79379b6428246ddc2\",\"title\":\"See the Sound, Hear the Pixels\",\"url\":\"https://www.semanticscholar.org/paper/c911d81bddb48490a02258e79379b6428246ddc2\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"2002.10981\",\"authors\":[{\"authorId\":\"48359318\",\"name\":\"Sanchita Ghose\"},{\"authorId\":\"2845029\",\"name\":\"John J. Prevost\"}],\"doi\":\"10.1109/TMM.2020.3005033\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1337db4d3283e77e959a683ef5cb15949f1d5400\",\"title\":\"AutoFoley: Artificial Synthesis of Synchronized Sound Tracks for Silent Videos with Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/1337db4d3283e77e959a683ef5cb15949f1d5400\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35399640\",\"name\":\"D\\u00eddac Sur\\u00eds\"},{\"authorId\":\"39257069\",\"name\":\"A. Recasens\"},{\"authorId\":\"144159726\",\"name\":\"David Bau\"},{\"authorId\":\"30507748\",\"name\":\"David Harwath\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/CVPR.2019.00213\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bbc9cb65aeb814de917fecab31843b95070c3cc1\",\"title\":\"Learning Words by Drawing Images\",\"url\":\"https://www.semanticscholar.org/paper/bbc9cb65aeb814de917fecab31843b95070c3cc1\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48169460\",\"name\":\"Luyu Wang\"},{\"authorId\":\"2189948\",\"name\":\"K. Kawakami\"},{\"authorId\":\"3422336\",\"name\":\"A. Oord\"}],\"doi\":\"10.21437/interspeech.2020-1891\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"22aa9614306f0500b34c74c803f07ac0b5322f1e\",\"title\":\"Contrastive Predictive Coding of Audio with an Adversary\",\"url\":\"https://www.semanticscholar.org/paper/22aa9614306f0500b34c74c803f07ac0b5322f1e\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":\"1905.01235\",\"authors\":[{\"authorId\":\"47316088\",\"name\":\"Priya Goyal\"},{\"authorId\":\"144542135\",\"name\":\"D. Mahajan\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"1806773\",\"name\":\"I. Misra\"}],\"doi\":\"10.1109/ICCV.2019.00649\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"19975936b7ae315e3ca04330f22a7cb0e127a309\",\"title\":\"Scaling and Benchmarking Self-Supervised Visual Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/19975936b7ae315e3ca04330f22a7cb0e127a309\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1711.09082\",\"authors\":[{\"authorId\":\"10805888\",\"name\":\"Zhongzheng Ren\"},{\"authorId\":\"144756076\",\"name\":\"Y. Lee\"}],\"doi\":\"10.1109/CVPR.2018.00086\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"91e89cedd4093bfe176532530ddb960f2767aca5\",\"title\":\"Cross-Domain Self-Supervised Multi-task Feature Learning Using Synthetic Imagery\",\"url\":\"https://www.semanticscholar.org/paper/91e89cedd4093bfe176532530ddb960f2767aca5\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2011.00030\",\"authors\":[{\"authorId\":\"73580712\",\"name\":\"S. Wang\"},{\"authorId\":\"145022667\",\"name\":\"A. Mesaros\"},{\"authorId\":\"2373836\",\"name\":\"Toni Heittola\"},{\"authorId\":\"50195877\",\"name\":\"T. Virtanen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a9ebd69ccbf6e493abdac6f047b4bc8d3be88412\",\"title\":\"A Curated Dataset of Urban Scenes for Audio-Visual Scene Analysis\",\"url\":\"https://www.semanticscholar.org/paper/a9ebd69ccbf6e493abdac6f047b4bc8d3be88412\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2003.00877\",\"authors\":[{\"authorId\":\"51021226\",\"name\":\"Chuanxing Geng\"},{\"authorId\":\"1515128894\",\"name\":\"Zhenghao Tan\"},{\"authorId\":\"40633792\",\"name\":\"Song-Can Chen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb7f9199be024dc7eb51231a4374e90890c4935e\",\"title\":\"A Multi-view Perspective of Self-supervised Learning\",\"url\":\"https://www.semanticscholar.org/paper/eb7f9199be024dc7eb51231a4374e90890c4935e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1806.04620\",\"authors\":[{\"authorId\":\"21140516\",\"name\":\"Vinicius Signori Furlan\"},{\"authorId\":\"1784213\",\"name\":\"R. Bajcsy\"},{\"authorId\":\"2310152\",\"name\":\"Erickson R. Nascimento\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"93de8ce11488740e4cc8eeef4d8bec31ef2433e7\",\"title\":\"Fast forwarding Egocentric Videos by Listening and Watching\",\"url\":\"https://www.semanticscholar.org/paper/93de8ce11488740e4cc8eeef4d8bec31ef2433e7\",\"venue\":\"CVPR Workshops\",\"year\":2018},{\"arxivId\":\"1805.11592\",\"authors\":[{\"authorId\":\"3152281\",\"name\":\"Y. Aytar\"},{\"authorId\":\"2054956\",\"name\":\"T. Pfaff\"},{\"authorId\":\"2508525\",\"name\":\"D. Budden\"},{\"authorId\":\"145757542\",\"name\":\"T. Paine\"},{\"authorId\":\"47197117\",\"name\":\"Ziyu Wang\"},{\"authorId\":\"1737568\",\"name\":\"N. D. Freitas\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"705bbc4dcd475f9230863771da6596e1f677a92d\",\"title\":\"Playing hard exploration games by watching YouTube\",\"url\":\"https://www.semanticscholar.org/paper/705bbc4dcd475f9230863771da6596e1f677a92d\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71013766\",\"name\":\"Mathilde Brousmiche\"},{\"authorId\":\"47322308\",\"name\":\"S. Dupont\"},{\"authorId\":\"1993689197\",\"name\":\"Jean Rout\"}],\"doi\":\"10.1145/3422852.3423486\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"204190d66b85145bacc42001b760ff91b84d5443\",\"title\":\"Intra and Inter-modality Interactions for Audio-visual Event Detection\",\"url\":\"https://www.semanticscholar.org/paper/204190d66b85145bacc42001b760ff91b84d5443\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2009.12494\",\"authors\":[{\"authorId\":\"2966240\",\"name\":\"Jianren Wang\"},{\"authorId\":\"1972362408\",\"name\":\"Ziwen Zhuang\"},{\"authorId\":\"1720744705\",\"name\":\"Hang Zhao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a86941b60e5826b094fe5c4bc7ca283287d36245\",\"title\":\"SEMI: Self-supervised Exploration via Multisensory Incongruity\",\"url\":\"https://www.semanticscholar.org/paper/a86941b60e5826b094fe5c4bc7ca283287d36245\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1801.01237\",\"authors\":[{\"authorId\":\"145824699\",\"name\":\"Zheng Lian\"},{\"authorId\":\"48513993\",\"name\":\"Ya Feng Li\"},{\"authorId\":\"37670752\",\"name\":\"Jianhua Tao\"},{\"authorId\":\"50535672\",\"name\":\"Jian Huang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0037b3689a23d14965dbc339c921287a4652c746\",\"title\":\"A pairwise discriminative task for speech emotion recognition\",\"url\":\"https://www.semanticscholar.org/paper/0037b3689a23d14965dbc339c921287a4652c746\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"2173143\",\"name\":\"C. Zhang\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"48707717\",\"name\":\"Z. Wang\"},{\"authorId\":\"145262461\",\"name\":\"Trung Bui\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1007/978-3-030-11024-6_43\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d4e7a7588b5d1474a4cd884e81730342e18186e9\",\"title\":\"Visually Indicated Sound Generation by Perceptually Optimized Classification\",\"url\":\"https://www.semanticscholar.org/paper/d4e7a7588b5d1474a4cd884e81730342e18186e9\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"1904.07933\",\"authors\":[{\"authorId\":\"145343013\",\"name\":\"Andr\\u00e9s F. P\\u00e9rez\"},{\"authorId\":\"50113109\",\"name\":\"Valentina Sanguineti\"},{\"authorId\":\"2322579\",\"name\":\"Pietro Morerio\"},{\"authorId\":\"1727204\",\"name\":\"Vittorio Murino\"}],\"doi\":\"10.1109/WACV45572.2020.9093307\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f7c6ab8303a03dc9e8454c070030c3e6b0233d40\",\"title\":\"Audio-Visual Model Distillation Using Acoustic Images\",\"url\":\"https://www.semanticscholar.org/paper/f7c6ab8303a03dc9e8454c070030c3e6b0233d40\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144990548\",\"name\":\"Go Irie\"},{\"authorId\":\"9211474\",\"name\":\"M. O\\u0161trek\"},{\"authorId\":\"48017277\",\"name\":\"Haochen Wang\"},{\"authorId\":\"1787190\",\"name\":\"H. Kameoka\"},{\"authorId\":\"34454585\",\"name\":\"A. Kimura\"},{\"authorId\":\"1858824\",\"name\":\"Takahito Kawanishi\"},{\"authorId\":\"1718803\",\"name\":\"Kunio Kashino\"}],\"doi\":\"10.1109/ICASSP.2019.8683142\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"36170dadea3e9cdb5b3b422eb0264633e6fd1742\",\"title\":\"Seeing through Sounds: Predicting Visual Semantic Segmentation Results from Multichannel Audio Signals\",\"url\":\"https://www.semanticscholar.org/paper/36170dadea3e9cdb5b3b422eb0264633e6fd1742\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":\"1909.08685\",\"authors\":[{\"authorId\":\"144669071\",\"name\":\"Shah Nawaz\"},{\"authorId\":\"51093708\",\"name\":\"Muhammad Kamran Janjua\"},{\"authorId\":\"145116184\",\"name\":\"I. Gallo\"},{\"authorId\":\"38243491\",\"name\":\"A. Mahmood\"},{\"authorId\":\"3457883\",\"name\":\"Alessandro Calefati\"}],\"doi\":\"10.1109/DICTA47822.2019.8945863\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d0e10059e473f57a0a89b61a0d15a09bb2624641\",\"title\":\"Deep Latent Space Learning for Cross-Modal Mapping of Audio and Visual Signals\",\"url\":\"https://www.semanticscholar.org/paper/d0e10059e473f57a0a89b61a0d15a09bb2624641\",\"venue\":\"2019 Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2019},{\"arxivId\":\"1712.01393\",\"authors\":[{\"authorId\":\"49455017\",\"name\":\"Yipin Zhou\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"145262461\",\"name\":\"Trung Bui\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/CVPR.2018.00374\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f2d126e02401ec9f3c131eac423620529996df2f\",\"title\":\"Visual to Sound: Generating Natural Sound for Videos in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/f2d126e02401ec9f3c131eac423620529996df2f\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9407523\",\"name\":\"Yaxiong Chen\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"},{\"authorId\":\"3493789\",\"name\":\"Y. Feng\"}],\"doi\":\"10.1007/978-3-030-31726-3_39\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6fd9462b383033ac1e32964d9219a8636d98be18\",\"title\":\"Deep Voice-Visual Cross-Modal Retrieval with Deep Feature Similarity Learning\",\"url\":\"https://www.semanticscholar.org/paper/6fd9462b383033ac1e32964d9219a8636d98be18\",\"venue\":\"PRCV\",\"year\":2019},{\"arxivId\":\"2011.00168\",\"authors\":[{\"authorId\":\"1411301219\",\"name\":\"Aniruddha Tamhane\"},{\"authorId\":\"46365867\",\"name\":\"J. Wu\"},{\"authorId\":\"3197182\",\"name\":\"M. Unberath\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8789ac5d7084b9bc12367dc3178f7dd2b64d4a0a\",\"title\":\"Multimodal and self-supervised representation learning for automatic gesture recognition in surgical robotics\",\"url\":\"https://www.semanticscholar.org/paper/8789ac5d7084b9bc12367dc3178f7dd2b64d4a0a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1905.09272\",\"authors\":[{\"authorId\":\"2856712\",\"name\":\"Olivier J. H\\u00e9naff\"},{\"authorId\":\"41207614\",\"name\":\"A. Srinivas\"},{\"authorId\":\"3364908\",\"name\":\"J. Fauw\"},{\"authorId\":\"143653164\",\"name\":\"Ali Razavi\"},{\"authorId\":\"2786693\",\"name\":\"C. Doersch\"},{\"authorId\":\"143648071\",\"name\":\"S. Eslami\"},{\"authorId\":\"3422336\",\"name\":\"A. Oord\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1cae417456711c4da184f5efcd1b7464a7a0661a\",\"title\":\"Data-Efficient Image Recognition with Contrastive Predictive Coding\",\"url\":\"https://www.semanticscholar.org/paper/1cae417456711c4da184f5efcd1b7464a7a0661a\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"28035020\",\"name\":\"Kevin Wilkinghoff\"},{\"authorId\":\"34979912\",\"name\":\"F. Kurth\"}],\"doi\":\"10.33682/340j-wd27\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c2487e6fff9fd4500ec9cac09abecfd82a826285\",\"title\":\"Open-Set Acoustic Scene Classification with Deep Convolutional Autoencoders\",\"url\":\"https://www.semanticscholar.org/paper/c2487e6fff9fd4500ec9cac09abecfd82a826285\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2009.05103\",\"authors\":[{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"48514379\",\"name\":\"Yaxian Li\"},{\"authorId\":\"51116041\",\"name\":\"Xingxu Yao\"},{\"authorId\":\"153576780\",\"name\":\"Weizhi Nie\"},{\"authorId\":\"50591162\",\"name\":\"P. Xu\"},{\"authorId\":\"1755872\",\"name\":\"Jufeng Yang\"},{\"authorId\":\"1732330\",\"name\":\"K. Keutzer\"}],\"doi\":\"10.1145/3394171.3413776\",\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"055690edb313b4696ea3bc8cf8827430d2f8f6d4\",\"title\":\"Emotion-Based End-to-End Matching Between Image and Music in Valence-Arousal Space\",\"url\":\"https://www.semanticscholar.org/paper/055690edb313b4696ea3bc8cf8827430d2f8f6d4\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2006.11476\",\"authors\":[{\"authorId\":\"1390925224\",\"name\":\"Y. Yao\"},{\"authorId\":\"49046944\",\"name\":\"C. Liu\"},{\"authorId\":\"152504322\",\"name\":\"Dezhao Luo\"},{\"authorId\":\"9113781\",\"name\":\"Yin-qing Zhou\"},{\"authorId\":\"12605536\",\"name\":\"Qixiang Ye\"}],\"doi\":\"10.1109/cvpr42600.2020.00658\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"15e8b0a6366e29c7093ecf844eb40d03d8004abb\",\"title\":\"Video Playback Rate Perception for Self-Supervised Spatio-Temporal Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/15e8b0a6366e29c7093ecf844eb40d03d8004abb\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50419005\",\"name\":\"C. Huang\"},{\"authorId\":\"145733034\",\"name\":\"K. Koishida\"}],\"doi\":\"10.1109/CVPRW50498.2020.00483\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a2014a3a0658d85edbd78686401d7abfa00b2a08\",\"title\":\"Improved Active Speaker Detection based on Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/a2014a3a0658d85edbd78686401d7abfa00b2a08\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"1804.01452\",\"authors\":[{\"authorId\":\"30507748\",\"name\":\"David Harwath\"},{\"authorId\":\"39257069\",\"name\":\"A. Recasens\"},{\"authorId\":\"35399640\",\"name\":\"D\\u00eddac Sur\\u00eds\"},{\"authorId\":\"2213197\",\"name\":\"Galen Chuang\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"}],\"doi\":\"10.1007/978-3-030-01231-1_40\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7dcaf1ef07a593a987f3b529c2ad1e977c0c7196\",\"title\":\"Jointly Discovering Visual Objects and Spoken Words from Raw Sensory Input\",\"url\":\"https://www.semanticscholar.org/paper/7dcaf1ef07a593a987f3b529c2ad1e977c0c7196\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2007585481\",\"name\":\"Dhanunjaya Varma Devalraju\"},{\"authorId\":\"3352733\",\"name\":\"H. Muralikrishna\"},{\"authorId\":\"2596382\",\"name\":\"P. Rajan\"},{\"authorId\":\"35362808\",\"name\":\"Dileep Aroor Dinesh\"}],\"doi\":\"10.21437/interspeech.2020-2476\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fac938afdacb332ef85aaf2631757b61cfa1a673\",\"title\":\"Attention-Driven Projections for Soundscape Classification\",\"url\":\"https://www.semanticscholar.org/paper/fac938afdacb332ef85aaf2631757b61cfa1a673\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":\"2005.07097\",\"authors\":[{\"authorId\":\"153211990\",\"name\":\"Di Hu\"},{\"authorId\":\"35041003\",\"name\":\"Lichao Mou\"},{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"46930271\",\"name\":\"Junyu Gao\"},{\"authorId\":\"51151222\",\"name\":\"Yuansheng Hua\"},{\"authorId\":\"1721158\",\"name\":\"D. Dou\"},{\"authorId\":\"40049070\",\"name\":\"X. Zhu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bd0438b43d63605356bf5bcfedb8bd1e99803cdc\",\"title\":\"Ambient Sound Helps: Audiovisual Crowd Counting in Extreme Conditions\",\"url\":\"https://www.semanticscholar.org/paper/bd0438b43d63605356bf5bcfedb8bd1e99803cdc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47820818\",\"name\":\"J. Pu\"},{\"authorId\":\"1780393\",\"name\":\"Yannis Panagakis\"},{\"authorId\":\"2403354\",\"name\":\"S. Petridis\"},{\"authorId\":\"145218430\",\"name\":\"J. Shen\"},{\"authorId\":\"145387780\",\"name\":\"M. Pantic\"}],\"doi\":\"10.1109/TCYB.2018.2883607\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"50227a013c4c06d064b9eebaa67318adadf54a07\",\"title\":\"Blind Audio\\u2013Visual Localization and Separation via Low-Rank and Sparsity\",\"url\":\"https://www.semanticscholar.org/paper/50227a013c4c06d064b9eebaa67318adadf54a07\",\"venue\":\"IEEE Transactions on Cybernetics\",\"year\":2020},{\"arxivId\":\"1912.05396\",\"authors\":[{\"authorId\":\"1454226662\",\"name\":\"Aiham Taleb\"},{\"authorId\":\"38206541\",\"name\":\"C. Lippert\"},{\"authorId\":\"35660331\",\"name\":\"T. Klein\"},{\"authorId\":\"1848946\",\"name\":\"Moin Nabi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b94a3bfe8ca48855e4b4c6bcab5b051197052d9e\",\"title\":\"Multimodal Self-Supervised Learning for Medical Image Analysis\",\"url\":\"https://www.semanticscholar.org/paper/b94a3bfe8ca48855e4b4c6bcab5b051197052d9e\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6485607\",\"name\":\"Jongchan Park\"},{\"authorId\":\"49108458\",\"name\":\"Min-Hyun Kim\"},{\"authorId\":\"38563282\",\"name\":\"S. Choi\"},{\"authorId\":\"98758720\",\"name\":\"I. Kweon\"},{\"authorId\":\"2854596\",\"name\":\"Dong-Geol Choi\"}],\"doi\":\"10.23919/ELINFOCOM.2019.8706354\",\"intent\":[\"methodology\",\"result\"],\"isInfluential\":false,\"paperId\":\"1180af5d6e64c1ba6bcebaff84b8ac346eb7512e\",\"title\":\"Fraud Detection with Multi-Modal Attention and Correspondence Learning\",\"url\":\"https://www.semanticscholar.org/paper/1180af5d6e64c1ba6bcebaff84b8ac346eb7512e\",\"venue\":\"2019 International Conference on Electronics, Information, and Communication (ICEIC)\",\"year\":2019},{\"arxivId\":\"2005.11437\",\"authors\":[{\"authorId\":null,\"name\":\"Yizhe Zhu\"},{\"authorId\":\"2984407\",\"name\":\"Martin Renqiang Min\"},{\"authorId\":\"2293919\",\"name\":\"Asim Kadav\"},{\"authorId\":\"1775043\",\"name\":\"H. Graf\"}],\"doi\":\"10.1109/cvpr42600.2020.00657\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"68d6b024891a981f349016def772b90e116ea1af\",\"title\":\"S3VAE: Self-Supervised Sequential VAE for Representation Disentanglement and Data Generation\",\"url\":\"https://www.semanticscholar.org/paper/68d6b024891a981f349016def772b90e116ea1af\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2003.04298\",\"authors\":[{\"authorId\":\"1379929116\",\"name\":\"Mandela Patrick\"},{\"authorId\":\"47792365\",\"name\":\"Y. Asano\"},{\"authorId\":\"145891577\",\"name\":\"Ruth Fong\"},{\"authorId\":\"143848064\",\"name\":\"Jo\\u00e3o F. Henriques\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8ddbaa34c574124a91fa3bc217e232e17668e84c\",\"title\":\"Multi-modal Self-Supervision from Generalized Data Transformations\",\"url\":\"https://www.semanticscholar.org/paper/8ddbaa34c574124a91fa3bc217e232e17668e84c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2001.09691\",\"authors\":[{\"authorId\":\"47077615\",\"name\":\"J. Munro\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.1109/ICCVW.2019.00461\",\"intent\":[\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"10cf610ca725cdf459f6a4fa68999066b586b93a\",\"title\":\"Multi-Modal Domain Adaptation for Fine-Grained Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/10cf610ca725cdf459f6a4fa68999066b586b93a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3939138\",\"name\":\"Laura K Cirelli\"},{\"authorId\":\"1836458\",\"name\":\"S. J. Wan\"},{\"authorId\":\"117414796\",\"name\":\"Trenton C. Johanis\"},{\"authorId\":\"2226072\",\"name\":\"L. Trainor\"}],\"doi\":\"10.1177/2059204317745855\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b0fc637b5c7b222abfba38e2af638f87c31ec4a7\",\"title\":\"Infants\\u2019 use of interpersonal asynchrony as a signal for third-party affiliation\",\"url\":\"https://www.semanticscholar.org/paper/b0fc637b5c7b222abfba38e2af638f87c31ec4a7\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2012.03478\",\"authors\":[{\"authorId\":\"1491240396\",\"name\":\"Kun Su\"},{\"authorId\":\"10598535\",\"name\":\"X. Liu\"},{\"authorId\":\"2003419\",\"name\":\"Eli Shlizerman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"866ba646300961747ddc29ce57153858e2be588a\",\"title\":\"Multi-Instrumentalist Net: Unsupervised Generation of Music from Body Movements\",\"url\":\"https://www.semanticscholar.org/paper/866ba646300961747ddc29ce57153858e2be588a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2708847\",\"name\":\"J. And\\u00e9n\"},{\"authorId\":\"2507441\",\"name\":\"Vincent Lostanlen\"},{\"authorId\":\"69031840\",\"name\":\"S. Mallat\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b62e9d543082821cadb8a913f523c9ecbb1695a1\",\"title\":\"Classification with Joint Time-Frequency Scattering.\",\"url\":\"https://www.semanticscholar.org/paper/b62e9d543082821cadb8a913f523c9ecbb1695a1\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1804.02516\",\"authors\":[{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3448af861bf5d44ce7ab6b25002504815212252e\",\"title\":\"Learning a Text-Video Embedding from Incomplete and Heterogeneous Data\",\"url\":\"https://www.semanticscholar.org/paper/3448af861bf5d44ce7ab6b25002504815212252e\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2010.09709\",\"authors\":[{\"authorId\":\"22237490\",\"name\":\"Tengda Han\"},{\"authorId\":\"10096695\",\"name\":\"Weidi Xie\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"88f440120730e21b07bbd188b2a04787a3208861\",\"title\":\"Self-supervised Co-training for Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/88f440120730e21b07bbd188b2a04787a3208861\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144017722\",\"name\":\"Olle G. Holmberg\"},{\"authorId\":\"48614214\",\"name\":\"Niklas D. K\\u00f6hler\"},{\"authorId\":\"88862762\",\"name\":\"T. Martins\"},{\"authorId\":\"1405643583\",\"name\":\"Jakob Siedlecki\"},{\"authorId\":\"39399712\",\"name\":\"T. Herold\"},{\"authorId\":\"51067892\",\"name\":\"Leonie Keidel\"},{\"authorId\":\"41022860\",\"name\":\"Ben Asani\"},{\"authorId\":\"41180363\",\"name\":\"Johannes Schiefelbein\"},{\"authorId\":\"51952480\",\"name\":\"S. Priglinger\"},{\"authorId\":\"1379958091\",\"name\":\"K. Kortuem\"},{\"authorId\":\"2958299\",\"name\":\"F. Theis\"}],\"doi\":\"10.1101/861757\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"db880969a9b937558ec329ebcc8ede8ef47e2df2\",\"title\":\"Self-supervised retinal thickness prediction enables deep learning from unlabeled data to boost classification of diabetic retinopathy\",\"url\":\"https://www.semanticscholar.org/paper/db880969a9b937558ec329ebcc8ede8ef47e2df2\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2008.03555\",\"authors\":[{\"authorId\":\"1866277225\",\"name\":\"Sandeep Inuganti\"},{\"authorId\":\"1699429\",\"name\":\"V. Balasubramanian\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7513b5d0ab916491aef4df9baf18aa76ce3c021a\",\"title\":\"Assisting Scene Graph Generation with Self-Supervision.\",\"url\":\"https://www.semanticscholar.org/paper/7513b5d0ab916491aef4df9baf18aa76ce3c021a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2002.12764\",\"authors\":[{\"authorId\":\"30418264\",\"name\":\"Joel Shor\"},{\"authorId\":\"35996413\",\"name\":\"A. Jansen\"},{\"authorId\":\"2118042\",\"name\":\"Ronnie Maor\"},{\"authorId\":\"49618488\",\"name\":\"Oran Lang\"},{\"authorId\":\"3308255\",\"name\":\"Omry Tuval\"},{\"authorId\":\"2358434\",\"name\":\"Felix de Chaumont Quitry\"},{\"authorId\":\"1749128\",\"name\":\"M. Tagliasacchi\"},{\"authorId\":\"46256509\",\"name\":\"Ira Shavitt\"},{\"authorId\":\"49021734\",\"name\":\"D. Emanuel\"},{\"authorId\":\"2137554\",\"name\":\"Yinnon A. Haviv\"}],\"doi\":\"10.21437/interspeech.2020-1242\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1042714c5be82d980066fd038105112e601a848e\",\"title\":\"Towards Learning a Universal Non-Semantic Representation of Speech\",\"url\":\"https://www.semanticscholar.org/paper/1042714c5be82d980066fd038105112e601a848e\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3083497\",\"name\":\"R. Yadav\"},{\"authorId\":\"50847752\",\"name\":\"Ashish Sardana\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"},{\"authorId\":\"1893306\",\"name\":\"Rajesh M. Hegde\"}],\"doi\":\"10.1109/WACV45572.2020.9093565\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0bc1f4e7e59c4268166db5f16353a56d333616e6\",\"title\":\"Bridged Variational Autoencoders for Joint Modeling of Images and Attributes\",\"url\":\"https://www.semanticscholar.org/paper/0bc1f4e7e59c4268166db5f16353a56d333616e6\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"2003.03186\",\"authors\":[{\"authorId\":\"7885575\",\"name\":\"E. Amrani\"},{\"authorId\":\"1397958297\",\"name\":\"R. Ben-Ari\"},{\"authorId\":\"143679933\",\"name\":\"Daniel Rotman\"},{\"authorId\":\"144858358\",\"name\":\"Alex Bronstein\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"777873ef6d23c2cdd7dfd6c4834eb56769a25bb1\",\"title\":\"Noise Estimation Using Density Estimation for Self-Supervised Multimodal Learning\",\"url\":\"https://www.semanticscholar.org/paper/777873ef6d23c2cdd7dfd6c4834eb56769a25bb1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50469466\",\"name\":\"Prateek Verma\"},{\"authorId\":\"2000083\",\"name\":\"Kenneth J. Salisbury\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2bec95c1c879c2ada2f7a399dd3d331bb391ebdb\",\"title\":\"Unsupervised Learning of Audio Perception: Learning to Project Data to UMAP space\",\"url\":\"https://www.semanticscholar.org/paper/2bec95c1c879c2ada2f7a399dd3d331bb391ebdb\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11542215\",\"name\":\"Kazuki Miyazawa\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"083e98e41abaa88062773b4249feeeb0587b458f\",\"title\":\"Integrated Model for Learning of Actions, Language and Planning\",\"url\":\"https://www.semanticscholar.org/paper/083e98e41abaa88062773b4249feeeb0587b458f\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1394839535\",\"name\":\"Angie Boggust\"},{\"authorId\":\"3104038\",\"name\":\"Kartik Audhkhasi\"},{\"authorId\":\"5113463\",\"name\":\"D. Joshi\"},{\"authorId\":\"30507748\",\"name\":\"David Harwath\"},{\"authorId\":\"70913918\",\"name\":\"S. Thomas\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"1891570\",\"name\":\"Dan Gutfreund\"},{\"authorId\":\"48380309\",\"name\":\"Y. Zhang\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"1774515\",\"name\":\"M. Picheny\"},{\"authorId\":\"36217631\",\"name\":\"J. Glass\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"67e733b987eb508fdaa60746bf0f5ed4ad192dbe\",\"title\":\"Grounding Spoken Words in Unlabeled Video\",\"url\":\"https://www.semanticscholar.org/paper/67e733b987eb508fdaa60746bf0f5ed4ad192dbe\",\"venue\":\"CVPR Workshops\",\"year\":2019},{\"arxivId\":\"2003.01037\",\"authors\":[{\"authorId\":\"2507441\",\"name\":\"Vincent Lostanlen\"},{\"authorId\":\"1409622512\",\"name\":\"Alice Cohen-Hadria\"},{\"authorId\":\"34894065\",\"name\":\"J. Bello\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0f9363ff40e2be81110a5f9789f8eb46f6528cab\",\"title\":\"One or Two Components? The Scattering Transform Answers\",\"url\":\"https://www.semanticscholar.org/paper/0f9363ff40e2be81110a5f9789f8eb46f6528cab\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48359318\",\"name\":\"Sanchita Ghose\"},{\"authorId\":\"39409158\",\"name\":\"John J. Prevost\"}],\"doi\":\"10.1109/SoSE50414.2020.9130483\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"06525364255afaa0a159edd4204e6a561174579f\",\"title\":\"Enabling an IoT System of Systems through Auto Sound Synthesis in Silent Video with DNN\",\"url\":\"https://www.semanticscholar.org/paper/06525364255afaa0a159edd4204e6a561174579f\",\"venue\":\"2020 IEEE 15th International Conference of System of Systems Engineering (SoSE)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11542215\",\"name\":\"Kazuki Miyazawa\"},{\"authorId\":\"3130434\",\"name\":\"Takato Horii\"},{\"authorId\":\"46949537\",\"name\":\"T. Aoki\"},{\"authorId\":\"50757347\",\"name\":\"T. Nagai\"}],\"doi\":\"10.3389/frobt.2019.00131\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b7545e0cb890f184f4a4fcaa2fcce1b367e2051e\",\"title\":\"Integrated Cognitive Architecture for Robot Learning of Action and Language\",\"url\":\"https://www.semanticscholar.org/paper/b7545e0cb890f184f4a4fcaa2fcce1b367e2051e\",\"venue\":\"Front. Robot. AI\",\"year\":2019},{\"arxivId\":\"1807.08869\",\"authors\":[{\"authorId\":\"2708847\",\"name\":\"J. And\\u00e9n\"},{\"authorId\":\"2507441\",\"name\":\"Vincent Lostanlen\"},{\"authorId\":\"1746242\",\"name\":\"S. Mallat\"}],\"doi\":\"10.1109/TSP.2019.2918992\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0c392bf9bec0f1db35b68655be85c2b52a29d8cd\",\"title\":\"Joint Time\\u2013Frequency Scattering\",\"url\":\"https://www.semanticscholar.org/paper/0c392bf9bec0f1db35b68655be85c2b52a29d8cd\",\"venue\":\"IEEE Transactions on Signal Processing\",\"year\":2019},{\"arxivId\":\"1905.12681\",\"authors\":[{\"authorId\":\"7634810\",\"name\":\"Weiyao Wang\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"}],\"doi\":null,\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"4b434904230cd2c09f349cc69b72baa670b5d815\",\"title\":\"What Makes Training Multi-Modal Networks Hard?\",\"url\":\"https://www.semanticscholar.org/paper/4b434904230cd2c09f349cc69b72baa670b5d815\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2003.04210\",\"authors\":[{\"authorId\":\"2326243\",\"name\":\"Arun Balajee Vasudevan\"},{\"authorId\":\"1778526\",\"name\":\"Dengxin Dai\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-030-58548-8_37\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4d981cc84ee972104eb6d95a2421a42db8a0cf57\",\"title\":\"Semantic Object Prediction and Spatial Sound Super-Resolution with Binaural Sounds\",\"url\":\"https://www.semanticscholar.org/paper/4d981cc84ee972104eb6d95a2421a42db8a0cf57\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2009.06573\",\"authors\":[{\"authorId\":\"1943369921\",\"name\":\"Runze Su\"},{\"authorId\":\"152412578\",\"name\":\"Fei Tao\"},{\"authorId\":\"1390611083\",\"name\":\"Xudong Liu\"},{\"authorId\":\"46546481\",\"name\":\"H. Wei\"},{\"authorId\":\"9191331\",\"name\":\"Xiaorong Mei\"},{\"authorId\":\"72028302\",\"name\":\"Zhiyao Duan\"},{\"authorId\":\"49785011\",\"name\":\"L. Yuan\"},{\"authorId\":\"102551205\",\"name\":\"J. Liu\"},{\"authorId\":\"1914648773\",\"name\":\"Yuying Xie\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f2c1089ac93a2fdbe3430db44cdc2ce79bea23dd\",\"title\":\"Themes Inferred Audio-visual Correspondence Learning\",\"url\":\"https://www.semanticscholar.org/paper/f2c1089ac93a2fdbe3430db44cdc2ce79bea23dd\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1397173488\",\"name\":\"\\u0421\\u0435\\u0440\\u0433\\u0435\\u0439 \\u0428\\u0443\\u043c\\u0441\\u043a\\u0438\\u0439\"},{\"authorId\":\"114056342\",\"name\":\"S. Shumskiy\"}],\"doi\":\"10.29039/02011-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"53f4bcd30f616c94b842a150e2f01721752974a9\",\"title\":\"MACHINE INTELLIGENCE. ESSAYS ON THE THEORY OF MACHINE LEARNING AND ARTIFICIAL INTELLIGENCE\",\"url\":\"https://www.semanticscholar.org/paper/53f4bcd30f616c94b842a150e2f01721752974a9\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2007.10730\",\"authors\":[{\"authorId\":\"5641221\",\"name\":\"S. Jenni\"},{\"authorId\":\"41016678\",\"name\":\"Givi Meishvili\"},{\"authorId\":\"144707901\",\"name\":\"P. Favaro\"}],\"doi\":\"10.1007/978-3-030-58604-1_26\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7657ceea5001eb500b4aa2f5e0a440828cde4764\",\"title\":\"Video Representation Learning by Recognizing Temporal Transformations\",\"url\":\"https://www.semanticscholar.org/paper/7657ceea5001eb500b4aa2f5e0a440828cde4764\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2006.13662\",\"authors\":[{\"authorId\":\"47792365\",\"name\":\"Y. Asano\"},{\"authorId\":null,\"name\":\"Mandela Patrick\"},{\"authorId\":\"49359942\",\"name\":\"C. Rupprecht\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"008ba3c574f8e5085dfb1eef0342e8b408565e45\",\"title\":\"Labelling unlabelled videos from scratch with multi-modal self-supervision\",\"url\":\"https://www.semanticscholar.org/paper/008ba3c574f8e5085dfb1eef0342e8b408565e45\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2101.01169\",\"authors\":[{\"authorId\":null,\"name\":\"Salman Khan\"},{\"authorId\":null,\"name\":\"Muzammal Naseer\"},{\"authorId\":null,\"name\":\"Munawar Hayat\"},{\"authorId\":null,\"name\":\"Syed Waqas Zamir\"},{\"authorId\":null,\"name\":\"Fahad Shahbaz Khan\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"88dee8121cd06205a88ccfd71a0b3daa67c05cfd\",\"title\":\"Transformers in Vision: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/88dee8121cd06205a88ccfd71a0b3daa67c05cfd\",\"venue\":\"\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1500661238\",\"name\":\"Kiran Praveen\"},{\"authorId\":\"1483568345\",\"name\":\"A. Gupta\"},{\"authorId\":\"114317909\",\"name\":\"Akshara Soman\"},{\"authorId\":\"1726355\",\"name\":\"S. Ganapathy\"}],\"doi\":\"10.1109/ASRU46091.2019.9004011\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"27eb276475dcc11def609c5d7c28fe5e747d323e\",\"title\":\"Second Language Transfer Learning in Humans and Machines Using Image Supervision\",\"url\":\"https://www.semanticscholar.org/paper/27eb276475dcc11def609c5d7c28fe5e747d323e\",\"venue\":\"2019 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2326243\",\"name\":\"Arun Balajee Vasudevan\"},{\"authorId\":\"1778526\",\"name\":\"Dengxin Dai\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.3929/ETHZ-B-000431943\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4867095c19f6c5827943cc74335b370d4bfcab29\",\"title\":\"Semantic Object Prediction and Spatial Sound Super-Resolution with Binaural Sounds\",\"url\":\"https://www.semanticscholar.org/paper/4867095c19f6c5827943cc74335b370d4bfcab29\",\"venue\":\"ECCV 2020\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35996413\",\"name\":\"A. Jansen\"},{\"authorId\":\"2114994\",\"name\":\"M. Plakal\"},{\"authorId\":\"39420271\",\"name\":\"Ratheet Pandya\"},{\"authorId\":\"1745455\",\"name\":\"D. Ellis\"},{\"authorId\":\"50781940\",\"name\":\"Shawn Hershey\"},{\"authorId\":\"120809856\",\"name\":\"Jiayang Liu\"},{\"authorId\":\"48837012\",\"name\":\"C. Moore\"},{\"authorId\":\"2278009\",\"name\":\"R. A. Saurous\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a64dde284f657eb303cb73e8b7638df846ec9d04\",\"title\":\"Towards Learning Semantic Audio Representations from Unlabeled Data\",\"url\":\"https://www.semanticscholar.org/paper/a64dde284f657eb303cb73e8b7638df846ec9d04\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1911.09649\",\"authors\":[{\"authorId\":\"40895287\",\"name\":\"Arda Senocak\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"3053231\",\"name\":\"J. Kim\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"98758720\",\"name\":\"I. Kweon\"}],\"doi\":\"10.1109/tpami.2019.2952095\",\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"edd75cbdad797febb765e2bcaa8653b77138e3a5\",\"title\":\"Learning to Localize Sound Sources in Visual Scenes: Analysis and Applications\",\"url\":\"https://www.semanticscholar.org/paper/edd75cbdad797febb765e2bcaa8653b77138e3a5\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"88999446\",\"name\":\"Lovish Chum\"},{\"authorId\":\"37390198\",\"name\":\"A. Subramanian\"},{\"authorId\":\"1699429\",\"name\":\"V. Balasubramanian\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"}],\"doi\":\"10.1007/s41745-019-0099-3\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d6de0d33e48d6dc73afbd81a57130e0e826cbeb9\",\"title\":\"Beyond Supervised Learning: A Computer Vision Perspective\",\"url\":\"https://www.semanticscholar.org/paper/d6de0d33e48d6dc73afbd81a57130e0e826cbeb9\",\"venue\":\"Journal of the Indian Institute of Science\",\"year\":2019},{\"arxivId\":\"2011.01143\",\"authors\":[{\"authorId\":\"18139933\",\"name\":\"Efthymios Tzinis\"},{\"authorId\":\"34654283\",\"name\":\"Scott T. Wisdom\"},{\"authorId\":\"35996413\",\"name\":\"A. Jansen\"},{\"authorId\":\"50781940\",\"name\":\"Shawn Hershey\"},{\"authorId\":\"2211633\",\"name\":\"Tal Remez\"},{\"authorId\":\"1745455\",\"name\":\"D. Ellis\"},{\"authorId\":\"2387467\",\"name\":\"J. Hershey\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8cc141d242387dc9b64124e97896097ddfd6bcf2\",\"title\":\"Into the Wild with AudioScope: Unsupervised Audio-Visual Separation of On-Screen Sounds\",\"url\":\"https://www.semanticscholar.org/paper/8cc141d242387dc9b64124e97896097ddfd6bcf2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1908.02265\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"65a9c7b0800c86a196bc14e7621ff895cc6ab287\",\"title\":\"ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/65a9c7b0800c86a196bc14e7621ff895cc6ab287\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1807.07860\",\"authors\":[{\"authorId\":\"145798292\",\"name\":\"Hang Zhou\"},{\"authorId\":\"40457380\",\"name\":\"Y. Liu\"},{\"authorId\":\"3243969\",\"name\":\"Z. Liu\"},{\"authorId\":\"47571885\",\"name\":\"Ping Luo\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1609/aaai.v33i01.33019299\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1816f98e2a4dd54690c2689cf529699d8843e847\",\"title\":\"Talking Face Generation by Adversarially Disentangled Audio-Visual Representation\",\"url\":\"https://www.semanticscholar.org/paper/1816f98e2a4dd54690c2689cf529699d8843e847\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2507441\",\"name\":\"Vincent Lostanlen\"},{\"authorId\":\"1409622512\",\"name\":\"Alice Cohen-Hadria\"},{\"authorId\":\"2040713602\",\"name\":\"Juan Pablo Bello\"}],\"doi\":\"10.23919/Eusipco47968.2020.9287216\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0fc2f0cfe4aa38ece7f3776219e3d9bd35534bb8\",\"title\":\"One or Two Frequencies? The Scattering Transform Answers\",\"url\":\"https://www.semanticscholar.org/paper/0fc2f0cfe4aa38ece7f3776219e3d9bd35534bb8\",\"venue\":\"2020 28th European Signal Processing Conference (EUSIPCO)\",\"year\":2021},{\"arxivId\":\"2007.10984\",\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"145592817\",\"name\":\"D. Huang\"},{\"authorId\":\"4965440\",\"name\":\"Peihao Chen\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1007/978-3-030-58621-8_44\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"43971a0a2593f660427e016032b983b52f8dd8eb\",\"title\":\"Foley Music: Learning to Generate Music from Videos\",\"url\":\"https://www.semanticscholar.org/paper/43971a0a2593f660427e016032b983b52f8dd8eb\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.00800\",\"authors\":[{\"authorId\":\"35356152\",\"name\":\"H. H. Mao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"43bfcc4333920138613d6f9d76798f0c99452b92\",\"title\":\"A Survey on Self-supervised Pre-training for Sequential Transfer Learning in Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/43bfcc4333920138613d6f9d76798f0c99452b92\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1712.04382\",\"authors\":[{\"authorId\":\"145177721\",\"name\":\"M. Freitag\"},{\"authorId\":\"2512283\",\"name\":\"Shahin Amiriparian\"},{\"authorId\":\"8779597\",\"name\":\"Sergey Pugachevskiy\"},{\"authorId\":\"1709997\",\"name\":\"Nicholas Cummins\"},{\"authorId\":\"145411696\",\"name\":\"B. Schuller\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"589b9bdabddfa3a8d03fcbcf9b45514b128cde1e\",\"title\":\"auDeep: Unsupervised Learning of Representations from Audio with Deep Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/589b9bdabddfa3a8d03fcbcf9b45514b128cde1e\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2017},{\"arxivId\":\"1910.06693\",\"authors\":[{\"authorId\":\"1901010\",\"name\":\"A. Cartas\"},{\"authorId\":\"145114663\",\"name\":\"J. Luque\"},{\"authorId\":\"143601910\",\"name\":\"P. Radeva\"},{\"authorId\":\"1380262503\",\"name\":\"C. Segura\"},{\"authorId\":\"2837527\",\"name\":\"Mariella Dimiccoli\"}],\"doi\":\"10.1109/ICCVW.2019.00548\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d1cf1ce95af190223519c1c9705251c15557afe4\",\"title\":\"Seeing and Hearing Egocentric Actions: How Much Can We Learn?\",\"url\":\"https://www.semanticscholar.org/paper/d1cf1ce95af190223519c1c9705251c15557afe4\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1904.13132\",\"authors\":[{\"authorId\":\"47792365\",\"name\":\"Y. Asano\"},{\"authorId\":\"49359942\",\"name\":\"C. Rupprecht\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7bf4168f696923ea5566d3a1ced37772897e24bd\",\"title\":\"A critical analysis of self-supervision, or what we can learn from a single image\",\"url\":\"https://www.semanticscholar.org/paper/7bf4168f696923ea5566d3a1ced37772897e24bd\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9407523\",\"name\":\"Yaxiong Chen\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"},{\"authorId\":\"145720713\",\"name\":\"Shuai Wang\"}],\"doi\":\"10.1109/TGRS.2020.2979273\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e27873bd45b8b3206127fce377c62576068963b2\",\"title\":\"Deep Cross-Modal Image\\u2013Voice Retrieval in Remote Sensing\",\"url\":\"https://www.semanticscholar.org/paper/e27873bd45b8b3206127fce377c62576068963b2\",\"venue\":\"IEEE Transactions on Geoscience and Remote Sensing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50670669\",\"name\":\"T. Konno\"},{\"authorId\":\"1491179155\",\"name\":\"K. Nishida\"},{\"authorId\":\"1491176055\",\"name\":\"K. Itoyama\"},{\"authorId\":\"1764429\",\"name\":\"K. Nakadai\"}],\"doi\":\"10.1109/SII46433.2020.9025812\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ee9ed2ac476de9097165db6c7118b7daf9b648cf\",\"title\":\"Audio-Visual 3D Reconstruction Framework for Dynamic Scenes\",\"url\":\"https://www.semanticscholar.org/paper/ee9ed2ac476de9097165db6c7118b7daf9b648cf\",\"venue\":\"2020 IEEE/SICE International Symposium on System Integration (SII)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33098317\",\"name\":\"A. Jimenez\"},{\"authorId\":\"2532460\",\"name\":\"B. Elizalde\"},{\"authorId\":\"1681921\",\"name\":\"B. Raj\"}],\"doi\":\"10.1109/ICASSP.2018.8461631\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9b373cf5d7339e576ca25d65fb1fa4ea72094d44\",\"title\":\"Acoustic Scene Classification Using Discrete Random Hashing for Laplacian Kernel Machines\",\"url\":\"https://www.semanticscholar.org/paper/9b373cf5d7339e576ca25d65fb1fa4ea72094d44\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":\"1906.01012\",\"authors\":[{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"3434584\",\"name\":\"Ahsan Iqbal\"},{\"authorId\":\"32774629\",\"name\":\"A. Richard\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b0e31596fe23b8b6c99c1e51fd3d08dcd856d5ac\",\"title\":\"Mining YouTube - A dataset for learning fine-grained action concepts from webly supervised video data\",\"url\":\"https://www.semanticscholar.org/paper/b0e31596fe23b8b6c99c1e51fd3d08dcd856d5ac\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46885959\",\"name\":\"R. Wang\"},{\"authorId\":\"32885778\",\"name\":\"Huaibo Huang\"},{\"authorId\":\"1391221164\",\"name\":\"Xufeng Zhang\"},{\"authorId\":\"35043641\",\"name\":\"Jixin Ma\"},{\"authorId\":\"4520695\",\"name\":\"A. Zheng\"}],\"doi\":\"10.1109/ICMEW.2019.00-70\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a2a8ca7fbb86dc0b8f4d9c4c44e7bffb186c585a\",\"title\":\"A Novel Distance Learning for Elastic Cross-Modal Audio-Visual Matching\",\"url\":\"https://www.semanticscholar.org/paper/a2a8ca7fbb86dc0b8f4d9c4c44e7bffb186c585a\",\"venue\":\"2019 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2019},{\"arxivId\":\"1712.07271\",\"authors\":[{\"authorId\":\"144956994\",\"name\":\"Andrew Owens\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"2324658\",\"name\":\"J. McDermott\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1007/s11263-018-1083-5\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"046111bd2dfc057182e0b995110a5705b572c819\",\"title\":\"Learning Sight from Sound: Ambient Sound Provides Supervision for Visual Learning\",\"url\":\"https://www.semanticscholar.org/paper/046111bd2dfc057182e0b995110a5705b572c819\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018},{\"arxivId\":\"1804.03160\",\"authors\":[{\"authorId\":\"144077750\",\"name\":\"Hang Zhao\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"41020711\",\"name\":\"Andrew Rouditchenko\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"2324658\",\"name\":\"J. McDermott\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1007/978-3-030-01246-5_35\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"fe018f22600d07cbd0452a070e03708886470015\",\"title\":\"The Sound of Pixels\",\"url\":\"https://www.semanticscholar.org/paper/fe018f22600d07cbd0452a070e03708886470015\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50394552\",\"name\":\"Rui Lu\"},{\"authorId\":\"72028302\",\"name\":\"Zhiyao Duan\"},{\"authorId\":\"14966740\",\"name\":\"Changshui Zhang\"}],\"doi\":\"10.1109/TASLP.2019.2928140\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"90f8b5d87c41230c691e6a243aef9d62063522b0\",\"title\":\"Audio\\u2013Visual Deep Clustering for Speech Separation\",\"url\":\"https://www.semanticscholar.org/paper/90f8b5d87c41230c691e6a243aef9d62063522b0\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144039832\",\"name\":\"P. Barros\"},{\"authorId\":\"2236890\",\"name\":\"Manfred Eppe\"},{\"authorId\":\"2988592\",\"name\":\"G. Parisi\"},{\"authorId\":\"144227938\",\"name\":\"X. Liu\"},{\"authorId\":\"1736513\",\"name\":\"S. Wermter\"}],\"doi\":\"10.3389/frobt.2019.00137\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"afbc0881addf58dd82afb2580d0fecd42f65acd6\",\"title\":\"Expectation Learning for Stimulus Prediction Across Modalities Improves Unisensory Classification\",\"url\":\"https://www.semanticscholar.org/paper/afbc0881addf58dd82afb2580d0fecd42f65acd6\",\"venue\":\"Front. Robot. AI\",\"year\":2019},{\"arxivId\":\"2011.09192\",\"authors\":[{\"authorId\":\"103368444\",\"name\":\"K. Tuyls\"},{\"authorId\":\"2008186335\",\"name\":\"Shayegan Omidshafiei\"},{\"authorId\":\"2008186474\",\"name\":\"Paul Muller\"},{\"authorId\":\"47197505\",\"name\":\"Zhe Wang\"},{\"authorId\":\"2007915382\",\"name\":\"Jerome Connor\"},{\"authorId\":\"2008182142\",\"name\":\"Daniel Hennes\"},{\"authorId\":\"145253240\",\"name\":\"I. Graham\"},{\"authorId\":\"52462738\",\"name\":\"W. Spearman\"},{\"authorId\":\"2026325301\",\"name\":\"Tim Waskett\"},{\"authorId\":\"2026283770\",\"name\":\"Dafydd Steele\"},{\"authorId\":\"152831141\",\"name\":\"Pauline Luc\"},{\"authorId\":\"39257069\",\"name\":\"A. Recasens\"},{\"authorId\":\"51980959\",\"name\":\"Alexandre Galashov\"},{\"authorId\":\"2005813\",\"name\":\"G. Thornton\"},{\"authorId\":\"47431108\",\"name\":\"R. Elie\"},{\"authorId\":\"2905900\",\"name\":\"P. Sprechmann\"},{\"authorId\":\"50713166\",\"name\":\"P. Moreno\"},{\"authorId\":\"3421987\",\"name\":\"Kris Cao\"},{\"authorId\":\"3468254\",\"name\":\"Marta Garnelo\"},{\"authorId\":\"9076891\",\"name\":\"P. Dutta\"},{\"authorId\":\"1806291\",\"name\":\"Michal Valko\"},{\"authorId\":\"1599360864\",\"name\":\"Nicolas Heess\"},{\"authorId\":\"1392692054\",\"name\":\"Alex Bridgland\"},{\"authorId\":\"3422031\",\"name\":\"Julien P\\u00e9rolat\"},{\"authorId\":\"1419267454\",\"name\":\"Bart De Vylder\"},{\"authorId\":\"49961426\",\"name\":\"A. Eslami\"},{\"authorId\":\"144845452\",\"name\":\"M. Rowland\"},{\"authorId\":\"2689633\",\"name\":\"Andrew Jaegle\"},{\"authorId\":\"49274028\",\"name\":\"R. Munos\"},{\"authorId\":\"2830305\",\"name\":\"T. Back\"},{\"authorId\":\"2026327929\",\"name\":\"Razia Ahamed\"},{\"authorId\":\"1404756328\",\"name\":\"Simon Bouton\"},{\"authorId\":\"2026355587\",\"name\":\"Nathalie Beauguerlange\"},{\"authorId\":\"2026325402\",\"name\":\"Jackson Broshear\"},{\"authorId\":\"1686971\",\"name\":\"T. Graepel\"},{\"authorId\":\"1838779\",\"name\":\"D. Hassabis\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"66240545b56959cec31b4187d93e71884365d1f7\",\"title\":\"Game Plan: What AI can do for Football, and What Football can do for AI\",\"url\":\"https://www.semanticscholar.org/paper/66240545b56959cec31b4187d93e71884365d1f7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.04237\",\"authors\":[{\"authorId\":\"2285516\",\"name\":\"Triantafyllos Afouras\"},{\"authorId\":\"144956994\",\"name\":\"Andrew Owens\"},{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/978-3-030-58523-5_13\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0eb79a085e014f129b063199a38fe9945355c137\",\"title\":\"Self-Supervised Learning of Audio-Visual Objects from Video\",\"url\":\"https://www.semanticscholar.org/paper/0eb79a085e014f129b063199a38fe9945355c137\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1703.09179\",\"authors\":[{\"authorId\":\"2483078\",\"name\":\"Keunwoo Choi\"},{\"authorId\":\"34011672\",\"name\":\"G. Fazekas\"},{\"authorId\":\"40764812\",\"name\":\"M. Sandler\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d09ad42cb4f991a6ddb282cd0cf3e4f0d408b275\",\"title\":\"Transfer Learning for Music Classification and Regression Tasks\",\"url\":\"https://www.semanticscholar.org/paper/d09ad42cb4f991a6ddb282cd0cf3e4f0d408b275\",\"venue\":\"ISMIR\",\"year\":2017},{\"arxivId\":\"1912.01991\",\"authors\":[{\"authorId\":\"1806773\",\"name\":\"I. Misra\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"}],\"doi\":\"10.1109/CVPR42600.2020.00674\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0170bb0b524df2c81b5adc3062c6001a2eb34c96\",\"title\":\"Self-Supervised Learning of Pretext-Invariant Representations\",\"url\":\"https://www.semanticscholar.org/paper/0170bb0b524df2c81b5adc3062c6001a2eb34c96\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1805.00237\",\"authors\":[{\"authorId\":\"143683184\",\"name\":\"J. Pons\"},{\"authorId\":\"144611740\",\"name\":\"X. Serra\"}],\"doi\":\"10.1109/ICASSP.2019.8682912\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4a3df21d289bba93a40d27bb7dab970e0e3eca04\",\"title\":\"Randomly Weighted CNNs for (Music) Audio Classification\",\"url\":\"https://www.semanticscholar.org/paper/4a3df21d289bba93a40d27bb7dab970e0e3eca04\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":\"1904.04289\",\"authors\":[{\"authorId\":\"3443095\",\"name\":\"Bruno Korbar\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":\"10.1109/ICCV.2019.00633\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2aed352cdd78010f72eaf618d52a4793fab32cea\",\"title\":\"SCSampler: Sampling Salient Clips From Video for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2aed352cdd78010f72eaf618d52a4793fab32cea\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1803.11560\",\"authors\":[{\"authorId\":\"7641268\",\"name\":\"Samuel Albanie\"},{\"authorId\":null,\"name\":\"James Thewlis\"},{\"authorId\":\"143848064\",\"name\":\"Jo\\u00e3o F. Henriques\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"baf5628f131c8c380321513775724e337eeabb34\",\"title\":\"Substitute Teacher Networks: Learning with Almost No Supervision\",\"url\":\"https://www.semanticscholar.org/paper/baf5628f131c8c380321513775724e337eeabb34\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1803.03849\",\"authors\":[{\"authorId\":\"40895287\",\"name\":\"Arda Senocak\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"3053231\",\"name\":\"J. Kim\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"2398271\",\"name\":\"In-So Kweon\"}],\"doi\":\"10.1109/CVPR.2018.00458\",\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"b91d738cd1f5d550c5b27f328e55308a0a73b2d2\",\"title\":\"Learning to Localize Sound Source in Visual Scenes\",\"url\":\"https://www.semanticscholar.org/paper/b91d738cd1f5d550c5b27f328e55308a0a73b2d2\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2007.14937\",\"authors\":[{\"authorId\":\"143935879\",\"name\":\"Jonathan C. Stroud\"},{\"authorId\":\"144711958\",\"name\":\"D. Ross\"},{\"authorId\":\"1491624845\",\"name\":\"Chen Sun\"},{\"authorId\":\"145820819\",\"name\":\"Jun Deng\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"153433844\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a1e68a2ec3a813576e2a2ba7845214862d94815e\",\"title\":\"Learning Video Representations from Textual Web Supervision\",\"url\":\"https://www.semanticscholar.org/paper/a1e68a2ec3a813576e2a2ba7845214862d94815e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98492542\",\"name\":\"Jaesung Huh\"},{\"authorId\":\"1594024908\",\"name\":\"Hee Soo Heo\"},{\"authorId\":\"50240029\",\"name\":\"Jin-Gu Kang\"},{\"authorId\":\"1746678\",\"name\":\"Shinji Watanabe\"},{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a1f1a2907c519ee7db051e68493c0fcfcfaaf331\",\"title\":\"Augmentation adversarial training for unsupervised speaker recognition\",\"url\":\"https://www.semanticscholar.org/paper/a1f1a2907c519ee7db051e68493c0fcfcfaaf331\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2040711546\",\"name\":\"Kevin Wilkinghoff\"}],\"doi\":\"10.23919/Eusipco47968.2020.9287705\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a85d9551fb1a6b9d62be5085c30fc3cd02ac26aa\",\"title\":\"On Open-Set Classification with L3-Net Embeddings for Machine Listening Applications\",\"url\":\"https://www.semanticscholar.org/paper/a85d9551fb1a6b9d62be5085c30fc3cd02ac26aa\",\"venue\":\"2020 28th European Signal Processing Conference (EUSIPCO)\",\"year\":2021},{\"arxivId\":\"2006.05576\",\"authors\":[{\"authorId\":\"145639633\",\"name\":\"Yao-Hung Hubert Tsai\"},{\"authorId\":\"89971337\",\"name\":\"Yue Wu\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7bd050967c18ec5161aa5ed244f3348cbd464642\",\"title\":\"Self-supervised Learning from a Multi-view Perspective\",\"url\":\"https://www.semanticscholar.org/paper/7bd050967c18ec5161aa5ed244f3348cbd464642\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30691613\",\"name\":\"X. Wang\"},{\"authorId\":\"1686917\",\"name\":\"Wu Liu\"},{\"authorId\":\"153426241\",\"name\":\"J. Chen\"},{\"authorId\":\"1519969356\",\"name\":\"Xiaobo Wang\"},{\"authorId\":\"7590116\",\"name\":\"C. Yan\"},{\"authorId\":\"153040576\",\"name\":\"T. Mei\"}],\"doi\":\"10.1145/3380549\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"410d362eaa55c93b6772d1158b1522e6d6846e22\",\"title\":\"Listen, Look, and Find the One\",\"url\":\"https://www.semanticscholar.org/paper/410d362eaa55c93b6772d1158b1522e6d6846e22\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2020},{\"arxivId\":\"2001.08740\",\"authors\":[{\"authorId\":\"2299381\",\"name\":\"Fanyi Xiao\"},{\"authorId\":\"144756076\",\"name\":\"Y. Lee\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"153652147\",\"name\":\"J. Malik\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"80685dc522d30b18f3feb97d6c977f71fa746325\",\"title\":\"Audiovisual SlowFast Networks for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/80685dc522d30b18f3feb97d6c977f71fa746325\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71013766\",\"name\":\"Mathilde Brousmiche\"},{\"authorId\":\"1640427539\",\"name\":\"Jean Rouat\"},{\"authorId\":\"153352427\",\"name\":\"S. Dupont\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a34e898552deb20d8053cbd548e0fb2466096d2d\",\"title\":\"Multi-level Attention Fusion Network for Audio-visual Event Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a34e898552deb20d8053cbd548e0fb2466096d2d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1807.05636\",\"authors\":[{\"authorId\":\"32694028\",\"name\":\"Aravindh Mahendran\"},{\"authorId\":\"3469001\",\"name\":\"James Thewlis\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":\"10.1007/978-3-030-20873-8_7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d983231cc90305e0802e797f74de2b816b90750c\",\"title\":\"Cross Pixel Optical Flow Similarity for Self-Supervised Learning\",\"url\":\"https://www.semanticscholar.org/paper/d983231cc90305e0802e797f74de2b816b90750c\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"1806.07754\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"2713759\",\"name\":\"M. M. Arzani\"},{\"authorId\":\"9456273\",\"name\":\"Rahman Yousefzadeh\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-030-01225-0_18\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"85fb0d6cc991cf49ebc4f506b5edd44214979f65\",\"title\":\"Spatio-Temporal Channel Correlation Networks for Action Classification\",\"url\":\"https://www.semanticscholar.org/paper/85fb0d6cc991cf49ebc4f506b5edd44214979f65\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"1733113\",\"name\":\"T. Kanade\"},{\"authorId\":\"1774867\",\"name\":\"Yaser Sheikh\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8dac02f61e12560607f857cee3c1d5abaf40ecd0\",\"title\":\"Cooperative Learning of Audio and Video Models from Self-Supervised Synchronization\",\"url\":\"https://www.semanticscholar.org/paper/8dac02f61e12560607f857cee3c1d5abaf40ecd0\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2008.09960\",\"authors\":[{\"authorId\":\"50469466\",\"name\":\"P. Verma\"},{\"authorId\":\"103464392\",\"name\":\"Constantin Basica\"},{\"authorId\":\"1901978632\",\"name\":\"Pamela Davis Kivelson\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e3b5eac30cd2e6cbec149f5b3cf8a529567d6420\",\"title\":\"Translating Paintings Into Music Using Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/e3b5eac30cd2e6cbec149f5b3cf8a529567d6420\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1906.10996\",\"authors\":[{\"authorId\":\"2844639\",\"name\":\"S. Balke\"},{\"authorId\":\"2874052\",\"name\":\"M. Dorfer\"},{\"authorId\":\"121526892\",\"name\":\"L. Carvalho\"},{\"authorId\":\"3202583\",\"name\":\"A. Arzt\"},{\"authorId\":\"145964711\",\"name\":\"G. Widmer\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f96d156eb2ad9431f72c74abf99ca17a730c2b5e\",\"title\":\"Learning Soft-Attention Models for Tempo-invariant Audio-Sheet Music Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/f96d156eb2ad9431f72c74abf99ca17a730c2b5e\",\"venue\":\"ISMIR\",\"year\":2019},{\"arxivId\":\"1908.11602\",\"authors\":[{\"authorId\":\"50487517\",\"name\":\"Xudong Xu\"},{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/ICCV.2019.00097\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b7a5f074e06cf8d71e26fb5d25b86b4164a5bb54\",\"title\":\"Recursive Visual Sound Separation Using Minus-Plus Net\",\"url\":\"https://www.semanticscholar.org/paper/b7a5f074e06cf8d71e26fb5d25b86b4164a5bb54\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46499312\",\"name\":\"K. Miyazaki\"},{\"authorId\":\"1726559\",\"name\":\"T. Toda\"},{\"authorId\":\"3326124\",\"name\":\"T. Hayashi\"},{\"authorId\":\"1709999\",\"name\":\"K. Takeda\"}],\"doi\":\"10.1002/TEE.22868\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4f3e620a1853da4a907d2a6ff3b4827e947904a4\",\"title\":\"Environmental sound processing and its applications\",\"url\":\"https://www.semanticscholar.org/paper/4f3e620a1853da4a907d2a6ff3b4827e947904a4\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2008.01065\",\"authors\":[{\"authorId\":\"22237490\",\"name\":\"Tengda Han\"},{\"authorId\":\"10096695\",\"name\":\"Weidi Xie\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/978-3-030-58580-8_19\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"202c79bbb45ab6524141feacc81caacc4ba00401\",\"title\":\"Memory-augmented Dense Predictive Coding for Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/202c79bbb45ab6524141feacc81caacc4ba00401\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2004.05937\",\"authors\":[{\"authorId\":null,\"name\":\"Lin Wang\"},{\"authorId\":\"51182421\",\"name\":\"Kuk-Jin Yoon\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2528a82dd2266600d4ee2b54165556a984de94d4\",\"title\":\"Knowledge Distillation and Student-Teacher Learning for Visual Intelligence: A Review and New Outlooks\",\"url\":\"https://www.semanticscholar.org/paper/2528a82dd2266600d4ee2b54165556a984de94d4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.06976\",\"authors\":[{\"authorId\":\"2870877\",\"name\":\"Xu-Yao Zhang\"},{\"authorId\":\"117992479\",\"name\":\"Cheng-Lin Liu\"},{\"authorId\":\"21266300\",\"name\":\"C. Y. Suen\"}],\"doi\":\"10.1109/JPROC.2020.2989782\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6a53aaf97203d3f8a89d9d8e0d39ca568c0896d4\",\"title\":\"Towards Robust Pattern Recognition: A Review\",\"url\":\"https://www.semanticscholar.org/paper/6a53aaf97203d3f8a89d9d8e0d39ca568c0896d4\",\"venue\":\"Proceedings of the IEEE\",\"year\":2020},{\"arxivId\":\"2006.08386\",\"authors\":[{\"authorId\":\"2094379\",\"name\":\"Xavier Favory\"},{\"authorId\":\"3193584\",\"name\":\"Konstantinos Drossos\"},{\"authorId\":\"50195877\",\"name\":\"T. Virtanen\"},{\"authorId\":\"144611740\",\"name\":\"X. Serra\"}],\"doi\":\"10.5281/ZENODO.3887261\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"20a3a6689948082a836d87a1b527c6d5403cba2a\",\"title\":\"COALA: Co-Aligned Autoencoders for Learning Semantically Enriched Audio Representations\",\"url\":\"https://www.semanticscholar.org/paper/20a3a6689948082a836d87a1b527c6d5403cba2a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.09833\",\"authors\":[{\"authorId\":\"94281814\",\"name\":\"Fa-Ting Hong\"},{\"authorId\":\"1823519002\",\"name\":\"Xuanteng Huang\"},{\"authorId\":\"50135134\",\"name\":\"Weihong Li\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"}],\"doi\":\"10.1007/978-3-030-58601-0_21\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4079558004efd97ddb20ea160909f7fa97d689c2\",\"title\":\"MINI-Net: Multiple Instance Ranking Network for Video Highlight Detection\",\"url\":\"https://www.semanticscholar.org/paper/4079558004efd97ddb20ea160909f7fa97d689c2\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Xinyi Wu\"},{\"authorId\":\"30676447\",\"name\":\"Zhenyao Wu\"},{\"authorId\":null,\"name\":\"Lili Ju\"},{\"authorId\":\"40696794\",\"name\":\"Song Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"21f36fa303fd70278ff038dc5bbcf2a96c5f018a\",\"title\":\"Binaural Audio-Visual Localization\",\"url\":\"https://www.semanticscholar.org/paper/21f36fa303fd70278ff038dc5bbcf2a96c5f018a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2002.12177\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"2148510\",\"name\":\"A. Angelova\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1109/cvpr42600.2020.00021\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3cb1b739f32641938485b714a186fb705d0b0215\",\"title\":\"Evolving Losses for Unsupervised Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/3cb1b739f32641938485b714a186fb705d0b0215\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26339425\",\"name\":\"Valentin Vielzeuf\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0501b8a99270a20c7536ed2f6df6569413810f6d\",\"title\":\"Apprentissage neuronal profond pour l'analyse de contenus multimodaux et temporels. (Deep learning for multimodal and temporal contents analysis)\",\"url\":\"https://www.semanticscholar.org/paper/0501b8a99270a20c7536ed2f6df6569413810f6d\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403082631\",\"name\":\"J. G\\u00f3mez-P\\u00e9rez\"},{\"authorId\":\"2213589\",\"name\":\"R. Denaux\"},{\"authorId\":\"1401950156\",\"name\":\"A. Garc\\u00eda-Silva\"}],\"doi\":\"10.1007/978-3-030-44830-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1dd19753c01476612db6f668967ded7b859deb83\",\"title\":\"A Practical Guide to Hybrid Natural Language Processing: Combining Neural Models and Knowledge Graphs for NLP\",\"url\":\"https://www.semanticscholar.org/paper/1dd19753c01476612db6f668967ded7b859deb83\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66227056\",\"name\":\"M. Guo\"},{\"authorId\":\"2035796\",\"name\":\"C. Zhou\"},{\"authorId\":\"49721726\",\"name\":\"Jiahang Liu\"}],\"doi\":\"10.1109/JSTARS.2019.2949220\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"db38673271d01e83d915053f64eb058b94141c9f\",\"title\":\"Jointly Learning of Visual and Auditory: A New Approach for RS Image and Audio Cross-Modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/db38673271d01e83d915053f64eb058b94141c9f\",\"venue\":\"IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing\",\"year\":2019},{\"arxivId\":\"2007.05722\",\"authors\":[{\"authorId\":\"31836044\",\"name\":\"Takashi Oya\"},{\"authorId\":\"34279376\",\"name\":\"Shohei Iwase\"},{\"authorId\":\"41015901\",\"name\":\"R. Natsume\"},{\"authorId\":\"21583404\",\"name\":\"Takahiro Itazuri\"},{\"authorId\":\"3117231\",\"name\":\"Shugo Yamaguchi\"},{\"authorId\":\"1490867805\",\"name\":\"Shigeo Morishima\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"476d71a4cfd1529c4705636041add568853d74b1\",\"title\":\"Do We Need Sound for Sound Source Localization?\",\"url\":\"https://www.semanticscholar.org/paper/476d71a4cfd1529c4705636041add568853d74b1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32457254\",\"name\":\"Tatsuya Ishibashi\"},{\"authorId\":\"82143319\",\"name\":\"Yuri Nakao\"},{\"authorId\":\"1751242\",\"name\":\"Yusuke Sugano\"}],\"doi\":\"10.1145/3377325.3377483\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0717b5c3eeb8418a39bb90760c706a119b537269\",\"title\":\"Investigating audio data visualization for interactive sound recognition\",\"url\":\"https://www.semanticscholar.org/paper/0717b5c3eeb8418a39bb90760c706a119b537269\",\"venue\":\"IUI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10437962\",\"name\":\"Soo-Whan Chung\"},{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"},{\"authorId\":\"153579825\",\"name\":\"Hong-Goo Kang\"}],\"doi\":\"10.1109/JSTSP.2020.2987720\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7431525dd5b821532191c7c078972bc457565d86\",\"title\":\"Perfect Match: Self-Supervised Embeddings for Cross-Modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/7431525dd5b821532191c7c078972bc457565d86\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020},{\"arxivId\":\"1805.05553\",\"authors\":[{\"authorId\":\"9340074\",\"name\":\"Changil Kim\"},{\"authorId\":\"2596714\",\"name\":\"H. Shin\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"2694281\",\"name\":\"Alexandre Kaspar\"},{\"authorId\":\"1854465\",\"name\":\"M. Elgharib\"},{\"authorId\":\"1752521\",\"name\":\"W. Matusik\"}],\"doi\":\"10.1007/978-3-030-20873-8_18\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1bdd7ed61a38b61399340c04cd478a96b67a51e5\",\"title\":\"On Learning Associations of Faces and Voices\",\"url\":\"https://www.semanticscholar.org/paper/1bdd7ed61a38b61399340c04cd478a96b67a51e5\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9340074\",\"name\":\"Changil Kim\"},{\"authorId\":\"2596714\",\"name\":\"H. Shin\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"2694281\",\"name\":\"Alexandre Kaspar\"},{\"authorId\":\"48857539\",\"name\":\"M. Elgharib\"},{\"authorId\":\"1752521\",\"name\":\"W. Matusik\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"912fd5d2d83d149707559db832606b91ed912821\",\"title\":\"On Learning Associations of Faces and Voices Supplementary Material\",\"url\":\"https://www.semanticscholar.org/paper/912fd5d2d83d149707559db832606b91ed912821\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1906.03248\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"145426908\",\"name\":\"A. Angelova\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d3870249fbed967f6aa19e3bfa627b489c342d35\",\"title\":\"Evolving Losses for Unlabeled Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/d3870249fbed967f6aa19e3bfa627b489c342d35\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1909.01976\",\"authors\":[{\"authorId\":\"144669071\",\"name\":\"Shah Nawaz\"},{\"authorId\":\"51093708\",\"name\":\"Muhammad Kamran Janjua\"},{\"authorId\":\"145116184\",\"name\":\"I. Gallo\"},{\"authorId\":\"38243491\",\"name\":\"A. Mahmood\"},{\"authorId\":\"3457883\",\"name\":\"Alessandro Calefati\"},{\"authorId\":\"1688013\",\"name\":\"F. Shafait\"}],\"doi\":\"10.1109/ICCVW.2019.00551\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5d965a354bd3a96c7b3117fd332bd3ebf736fe0e\",\"title\":\"Do Cross Modal Systems Leverage Semantic Relationships?\",\"url\":\"https://www.semanticscholar.org/paper/5d965a354bd3a96c7b3117fd332bd3ebf736fe0e\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"2006.07203\",\"authors\":[{\"authorId\":\"3443095\",\"name\":\"Bruno Korbar\"},{\"authorId\":\"40052301\",\"name\":\"F. Petroni\"},{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a2bf96de7889360dce11b9fc80f578a56e63dcfc\",\"title\":\"Video Understanding as Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/a2bf96de7889360dce11b9fc80f578a56e63dcfc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1805.08651\",\"authors\":[{\"authorId\":\"1791548\",\"name\":\"A. Hyv\\u00e4rinen\"},{\"authorId\":\"49371787\",\"name\":\"H. Sasaki\"},{\"authorId\":\"145369890\",\"name\":\"R. Turner\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"212af8d82353dc58851cc484600a64b42c790f1a\",\"title\":\"Nonlinear ICA Using Auxiliary Variables and Generalized Contrastive Learning\",\"url\":\"https://www.semanticscholar.org/paper/212af8d82353dc58851cc484600a64b42c790f1a\",\"venue\":\"AISTATS\",\"year\":2019},{\"arxivId\":\"2009.03162\",\"authors\":[{\"authorId\":\"10666774\",\"name\":\"Mayank Golhar\"},{\"authorId\":\"35650165\",\"name\":\"Taylor L. Bobrow\"},{\"authorId\":\"147506686\",\"name\":\"Mirmilad Pourmousavi Khoshknab\"},{\"authorId\":\"6519146\",\"name\":\"S. Jit\"},{\"authorId\":\"1411734437\",\"name\":\"S. Ngamruengphong\"},{\"authorId\":\"2237579\",\"name\":\"N. Durr\"}],\"doi\":\"10.1109/access.2020.3047544\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"77442599e9d3a9a579d1170f25de6b3004e76892\",\"title\":\"Improving colonoscopy lesion classification using semi-supervised deep learning\",\"url\":\"https://www.semanticscholar.org/paper/77442599e9d3a9a579d1170f25de6b3004e76892\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1912.03330\",\"authors\":[{\"authorId\":\"11529694\",\"name\":\"Xueting Yan\"},{\"authorId\":\"1806773\",\"name\":\"I. Misra\"},{\"authorId\":null,\"name\":\"Abhinav Gupta\"},{\"authorId\":\"2028234\",\"name\":\"Deepti Ghadiyaram\"},{\"authorId\":\"144542135\",\"name\":\"D. Mahajan\"}],\"doi\":\"10.1109/cvpr42600.2020.00654\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4906a09839dcb6ac96a52e06bc7bd613f0482967\",\"title\":\"ClusterFit: Improving Generalization of Visual Representations\",\"url\":\"https://www.semanticscholar.org/paper/4906a09839dcb6ac96a52e06bc7bd613f0482967\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2007.06809\",\"authors\":[{\"authorId\":\"9435157\",\"name\":\"Ehsan Asali\"},{\"authorId\":\"1646641382\",\"name\":\"Farzan Shenavarmasouleh\"},{\"authorId\":\"3261667\",\"name\":\"F. Mohammadi\"},{\"authorId\":\"153046351\",\"name\":\"P. Suresh\"},{\"authorId\":\"1712033\",\"name\":\"H. Arabnia\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8eda77ac0d52cd89a49e03081832765fccd8a228\",\"title\":\"DeepMSRF: A novel Deep Multimodal Speaker Recognition framework with Feature selection\",\"url\":\"https://www.semanticscholar.org/paper/8eda77ac0d52cd89a49e03081832765fccd8a228\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.09476\",\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"145592817\",\"name\":\"D. Huang\"},{\"authorId\":\"47940821\",\"name\":\"Hang Zhao\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/CVPR42600.2020.01049\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b643a7186c08db9f13d7204f6e5e739f97902e71\",\"title\":\"Music Gesture for Visual Sound Separation\",\"url\":\"https://www.semanticscholar.org/paper/b643a7186c08db9f13d7204f6e5e739f97902e71\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2008.02069\",\"authors\":[{\"authorId\":\"1405559880\",\"name\":\"Gabriel Meseguer-Brocal\"},{\"authorId\":\"13709609\",\"name\":\"Rachel M. Bittner\"},{\"authorId\":\"34698326\",\"name\":\"S. Durand\"},{\"authorId\":\"3429674\",\"name\":\"B. Brost\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"601a2d5233d4f282a47e3bc930fdc218267e7aea\",\"title\":\"Data Cleansing with Contrastive Learning for Vocal Note Event Annotations\",\"url\":\"https://www.semanticscholar.org/paper/601a2d5233d4f282a47e3bc930fdc218267e7aea\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.07984\",\"authors\":[{\"authorId\":\"8301799\",\"name\":\"Lingyu Zhu\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7b2cf1d0538f3ad0d5fae1af4d97571b9291eabc\",\"title\":\"Separating Sounds from a Single Image\",\"url\":\"https://www.semanticscholar.org/paper/7b2cf1d0538f3ad0d5fae1af4d97571b9291eabc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.04124\",\"authors\":[{\"authorId\":\"40176903\",\"name\":\"Sangho Lee\"},{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"},{\"authorId\":\"6555176\",\"name\":\"Thomas Breuel\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3655a6344ffb57838fd7f7acce651f36d3a9d526\",\"title\":\"Parameter Efficient Multimodal Transformers for Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/3655a6344ffb57838fd7f7acce651f36d3a9d526\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1659094312\",\"name\":\"Venkat Krishnamohan\"},{\"authorId\":\"114317909\",\"name\":\"Akshara Soman\"},{\"authorId\":\"1483568345\",\"name\":\"A. Gupta\"},{\"authorId\":\"144113422\",\"name\":\"Sriram Ganapathy\"}],\"doi\":\"10.21437/interspeech.2020-2674\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4b2a2036de2f179dd9342c321865c6bbdcefbc13\",\"title\":\"Audiovisual Correspondence Learning in Humans and Machines\",\"url\":\"https://www.semanticscholar.org/paper/4b2a2036de2f179dd9342c321865c6bbdcefbc13\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3028279\",\"name\":\"Akihiro Eguchi\"},{\"authorId\":\"3130434\",\"name\":\"Takato Horii\"},{\"authorId\":\"47734618\",\"name\":\"T. Nagai\"},{\"authorId\":\"1800112\",\"name\":\"R. Kanai\"},{\"authorId\":\"1768153\",\"name\":\"Masafumi Oizumi\"}],\"doi\":\"10.3389/fncom.2020.00001\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b54fb2f3fe3dfc8c1939a29827f256a36b5e6b2f\",\"title\":\"An Information Theoretic Approach to Reveal the Formation of Shared Representations\",\"url\":\"https://www.semanticscholar.org/paper/b54fb2f3fe3dfc8c1939a29827f256a36b5e6b2f\",\"venue\":\"Frontiers in Computational Neuroscience\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49507095\",\"name\":\"Haoming Xu\"},{\"authorId\":\"147992804\",\"name\":\"Runhao Zeng\"},{\"authorId\":\"1443732549\",\"name\":\"Qingyao Wu\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"}],\"doi\":\"10.1145/3394171.3413581\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1d0ffb0a8c69ec211f91bda8f5e9f2ed5d5b42bf\",\"title\":\"Cross-Modal Relation-Aware Networks for Audio-Visual Event Localization\",\"url\":\"https://www.semanticscholar.org/paper/1d0ffb0a8c69ec211f91bda8f5e9f2ed5d5b42bf\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"120023554\",\"name\":\"Ke Huang\"},{\"authorId\":\"145453305\",\"name\":\"Xin Ma\"},{\"authorId\":\"145401371\",\"name\":\"R. Song\"},{\"authorId\":\"2924438\",\"name\":\"Xuewen Rong\"},{\"authorId\":\"32004054\",\"name\":\"X. Tian\"},{\"authorId\":\"48513221\",\"name\":\"Yibin Li\"}],\"doi\":\"10.1109/ACCESS.2018.2890330\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3860beb3ceda7cdecd4638489b42c2a9195a5c45\",\"title\":\"An Autonomous Developmental Cognitive Architecture Based on Incremental Associative Neural Network With Dynamic Audiovisual Fusion\",\"url\":\"https://www.semanticscholar.org/paper/3860beb3ceda7cdecd4638489b42c2a9195a5c45\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1805.02031\",\"authors\":[{\"authorId\":\"1840108\",\"name\":\"J. Liu\"},{\"authorId\":\"1689230\",\"name\":\"Y. Yang\"},{\"authorId\":\"1798258\",\"name\":\"S. Jeng\"}],\"doi\":\"10.1109/TMM.2018.2871418\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4e48c060d490a8bb2109a6b6f8340610d797b2b5\",\"title\":\"Weakly-Supervised Visual Instrument-Playing Action Detection in Videos\",\"url\":\"https://www.semanticscholar.org/paper/4e48c060d490a8bb2109a6b6f8340610d797b2b5\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":\"1904.09013\",\"authors\":[{\"authorId\":\"41020711\",\"name\":\"Andrew Rouditchenko\"},{\"authorId\":\"144077750\",\"name\":\"Hang Zhao\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"2324658\",\"name\":\"J. McDermott\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/ICASSP.2019.8682467\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c4a44cd4c6bdd7fe85a1227c5041827ba828e0de\",\"title\":\"Self-supervised Audio-visual Co-segmentation\",\"url\":\"https://www.semanticscholar.org/paper/c4a44cd4c6bdd7fe85a1227c5041827ba828e0de\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":\"1802.04051\",\"authors\":[{\"authorId\":\"2744489\",\"name\":\"Jaehun Kim\"},{\"authorId\":\"144554719\",\"name\":\"J. Urbano\"},{\"authorId\":\"1968667\",\"name\":\"Cynthia C. S. Liem\"},{\"authorId\":\"1718099\",\"name\":\"A. Hanjalic\"}],\"doi\":\"10.1007/s00521-019-04076-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"855fc9ba27b6b838f9de22b85721ecdfced3e8fc\",\"title\":\"One deep music representation to rule them all? A comparative analysis of different representation learning strategies\",\"url\":\"https://www.semanticscholar.org/paper/855fc9ba27b6b838f9de22b85721ecdfced3e8fc\",\"venue\":\"Neural Computing and Applications\",\"year\":2019},{\"arxivId\":\"2007.09902\",\"authors\":[{\"authorId\":\"145798292\",\"name\":\"Hang Zhou\"},{\"authorId\":\"48670507\",\"name\":\"Xudong Xu\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"},{\"authorId\":\"3243969\",\"name\":\"Z. Liu\"}],\"doi\":\"10.1007/978-3-030-58610-2_4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"73aa926dad010a3f1bb89faa31241f97a89cc461\",\"title\":\"Sep-Stereo: Visually Guided Stereophonic Audio Generation by Associating Source Separation\",\"url\":\"https://www.semanticscholar.org/paper/73aa926dad010a3f1bb89faa31241f97a89cc461\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2512283\",\"name\":\"Shahin Amiriparian\"},{\"authorId\":\"31766982\",\"name\":\"Maurice Gerczuk\"},{\"authorId\":\"31696419\",\"name\":\"Sandra Ottl\"},{\"authorId\":\"113705775\",\"name\":\"Lukas Stappen\"},{\"authorId\":\"50124126\",\"name\":\"A. Baird\"},{\"authorId\":\"2030916385\",\"name\":\"Lukas Koebe\"},{\"authorId\":\"2028530929\",\"name\":\"Bj\\u00f6rn Schuller\"}],\"doi\":\"10.1186/s13636-020-00186-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"de0fee27920d42443ceb274036eb7da5d8aba430\",\"title\":\"Towards cross-modal pre-training and learning tempo-spatial characteristics for audio recognition with convolutional and recurrent neural networks\",\"url\":\"https://www.semanticscholar.org/paper/de0fee27920d42443ceb274036eb7da5d8aba430\",\"venue\":\"EURASIP J. Audio Speech Music. Process.\",\"year\":2020},{\"arxivId\":\"2007.13729\",\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144220896\",\"name\":\"Xiaoyu Chen\"},{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5f978b3829acad6ac8b3372d2fa8d38a45b96d3d\",\"title\":\"Noisy Agents: Self-supervised Exploration by Predicting Auditory Events\",\"url\":\"https://www.semanticscholar.org/paper/5f978b3829acad6ac8b3372d2fa8d38a45b96d3d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.06175\",\"authors\":[{\"authorId\":\"2806097\",\"name\":\"Karren D. Yang\"},{\"authorId\":\"145160921\",\"name\":\"Bryan C. Russell\"},{\"authorId\":\"1786276\",\"name\":\"Justin Salamon\"}],\"doi\":\"10.1109/cvpr42600.2020.00995\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7555e7a02b23886f1c17049999e4fc66b30c8bf3\",\"title\":\"Telling Left From Right: Learning Spatial Correspondence of Sight and Sound\",\"url\":\"https://www.semanticscholar.org/paper/7555e7a02b23886f1c17049999e4fc66b30c8bf3\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2003.13594\",\"authors\":[{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"1491624845\",\"name\":\"Chen Sun\"},{\"authorId\":\"152567560\",\"name\":\"D. Ross\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/cvpr42600.2020.01033\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ee3ba7ebf3a0116d17857c53fe10d98ae3a586d9\",\"title\":\"Speech2Action: Cross-Modal Supervision for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ee3ba7ebf3a0116d17857c53fe10d98ae3a586d9\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1912.04487\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":\"10.1109/cvpr42600.2020.01047\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c4128ba8deeb67e731cf52fb98addcfddd487e55\",\"title\":\"Listen to Look: Action Recognition by Previewing Audio\",\"url\":\"https://www.semanticscholar.org/paper/c4128ba8deeb67e731cf52fb98addcfddd487e55\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50113109\",\"name\":\"Valentina Sanguineti\"},{\"authorId\":\"2322579\",\"name\":\"Pietro Morerio\"},{\"authorId\":\"2026650249\",\"name\":\"Niccol\\u00f2 Pozzetti\"},{\"authorId\":\"103150889\",\"name\":\"D. Greco\"},{\"authorId\":\"1723008\",\"name\":\"Marco Cristani\"},{\"authorId\":\"1727204\",\"name\":\"Vittorio Murino\"}],\"doi\":\"10.1007/978-3-030-58542-6_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8728049700f949a4731ca9d6de73dee8940592bc\",\"title\":\"Leveraging Acoustic Images for Effective Self-supervised Audio Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/8728049700f949a4731ca9d6de73dee8940592bc\",\"venue\":\"ECCV\",\"year\":2020}],\"corpusId\":10769575,\"doi\":\"10.1109/ICCV.2017.73\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":39,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"9b5f696f73c1264ccb8e97d3b738a2342ecd6bee\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Torralba Harwath\"},{\"authorId\":null,\"name\":\"J. R. Glass\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"dio Set : An ontology and human - labeled dataset for audio events\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1c46943103bd7b7a2c7be86859995a4144d1938b\",\"title\":\"Visualizing Data using t-SNE\",\"url\":\"https://www.semanticscholar.org/paper/1c46943103bd7b7a2c7be86859995a4144d1938b\",\"venue\":\"\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":\"1409.0575\",\"authors\":[{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"71309570\",\"name\":\"H. Su\"},{\"authorId\":\"2285165\",\"name\":\"J. Krause\"},{\"authorId\":\"145031342\",\"name\":\"S. Satheesh\"},{\"authorId\":\"145423516\",\"name\":\"S. Ma\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-015-0816-y\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"title\":\"ImageNet Large Scale Visual Recognition Challenge\",\"url\":\"https://www.semanticscholar.org/paper/e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":\"1301.3666\",\"authors\":[{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"2012435\",\"name\":\"M. Ganjoo\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"},{\"authorId\":\"34699434\",\"name\":\"A. Ng\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"755e9f43ce398ae8737366720c5f82685b0c253e\",\"title\":\"Zero-Shot Learning Through Cross-Modal Transfer\",\"url\":\"https://www.semanticscholar.org/paper/755e9f43ce398ae8737366720c5f82685b0c253e\",\"venue\":\"NIPS\",\"year\":2013},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3116662\",\"name\":\"J. Gemmeke\"},{\"authorId\":\"1745455\",\"name\":\"D. Ellis\"},{\"authorId\":\"36794621\",\"name\":\"Dylan Freedman\"},{\"authorId\":\"35996413\",\"name\":\"A. Jansen\"},{\"authorId\":\"39965499\",\"name\":\"W. Lawrence\"},{\"authorId\":\"1974225\",\"name\":\"R. C. Moore\"},{\"authorId\":\"2114994\",\"name\":\"M. Plakal\"},{\"authorId\":\"39687627\",\"name\":\"M. Ritter\"}],\"doi\":\"10.1109/ICASSP.2017.7952261\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5ba2218b708ca64ab556e39d5997202e012717d5\",\"title\":\"Audio Set: An ontology and human-labeled dataset for audio events\",\"url\":\"https://www.semanticscholar.org/paper/5ba2218b708ca64ab556e39d5997202e012717d5\",\"venue\":\"2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"P. Kr\\u00e4henb\\u00fchl\"},{\"authorId\":null,\"name\":\"C. Doersch\"},{\"authorId\":null,\"name\":\"J. Donahue\"},{\"authorId\":null,\"name\":\"T. Darrell\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\": A method for stochastic optimization\",\"url\":\"\",\"venue\":\"Proc . ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"80637010\",\"name\":\"CM Bennett\"},{\"authorId\":\"46907039\",\"name\":\"M. Miller\"},{\"authorId\":\"1857681861\",\"name\":\"GL Wolford\"}],\"doi\":\"10.1016/S1053-8119(09)71202-9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9b0305530d5b1d85c210f518615480ecf6e4ab19\",\"title\":\"Neural correlates of interspecies perspective taking in the post-mortem Atlantic Salmon: an argument for multiple comparisons correction\",\"url\":\"https://www.semanticscholar.org/paper/9b0305530d5b1d85c210f518615480ecf6e4ab19\",\"venue\":\"NeuroImage\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. A.\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Efros . Colorful image colorization\",\"url\":\"\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1603.09246\",\"authors\":[{\"authorId\":\"2199924\",\"name\":\"M. Noroozi\"},{\"authorId\":\"145646305\",\"name\":\"P. Favaro\"}],\"doi\":\"10.1007/978-3-319-46466-4_5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2ec8f7e0257a07d3914322b36072d1bbcd58a1e0\",\"title\":\"Unsupervised Learning of Visual Representations by Solving Jigsaw Puzzles\",\"url\":\"https://www.semanticscholar.org/paper/2ec8f7e0257a07d3914322b36072d1bbcd58a1e0\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"P. Kr\\u00e4henb\\u00fchl\"},{\"authorId\":null,\"name\":\"C. Doersch\"},{\"authorId\":null,\"name\":\"J. Donahue\"},{\"authorId\":null,\"name\":\"T. Darrell\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Datadependent initializations of convolutional neural networks\",\"url\":\"\",\"venue\":\"In Proc. ICLR,\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"D. Li\"},{\"authorId\":null,\"name\":\"J. Tam\"},{\"authorId\":null,\"name\":\"D. Toub\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Auditory scene classification using machine learning techniques\",\"url\":\"\",\"venue\":\"IEEE AASP Challenge on Detection and Classification of Acoustic Scenes and Events,\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1784851\",\"name\":\"T. Sainath\"},{\"authorId\":\"39571582\",\"name\":\"Ron J. Weiss\"},{\"authorId\":\"33666044\",\"name\":\"A. Senior\"},{\"authorId\":\"12812321\",\"name\":\"K. Wilson\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fd5474f21495989777cbff507ecf1b37b7091475\",\"title\":\"Learning the speech front-end with raw waveform CLDNNs\",\"url\":\"https://www.semanticscholar.org/paper/fd5474f21495989777cbff507ecf1b37b7091475\",\"venue\":\"INTERSPEECH\",\"year\":2015},{\"arxivId\":\"1605.09782\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2562966\",\"name\":\"Philipp Kr\\u00e4henb\\u00fchl\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1db6e3078597386ac4222ba6c3f4f61b61f53539\",\"title\":\"Adversarial Feature Learning\",\"url\":\"https://www.semanticscholar.org/paper/1db6e3078597386ac4222ba6c3f4f61b61f53539\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1512.08512\",\"authors\":[{\"authorId\":\"144956994\",\"name\":\"Andrew Owens\"},{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"2324658\",\"name\":\"J. McDermott\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145358192\",\"name\":\"E. Adelson\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"}],\"doi\":\"10.1109/CVPR.2016.264\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ac640c2d0f33fb3ab49f37b26982948fc31e3191\",\"title\":\"Visually Indicated Sounds\",\"url\":\"https://www.semanticscholar.org/paper/ac640c2d0f33fb3ab49f37b26982948fc31e3191\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2211891\",\"name\":\"Einat Kidron\"},{\"authorId\":\"2159538\",\"name\":\"Y. Schechner\"},{\"authorId\":\"1753908\",\"name\":\"Michael Elad\"}],\"doi\":\"10.1109/CVPR.2005.274\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"91bfc3de8bfa6b9e7ccd685f53db8304a0c114ad\",\"title\":\"Pixels that sound\",\"url\":\"https://www.semanticscholar.org/paper/91bfc3de8bfa6b9e7ccd685f53db8304a0c114ad\",\"venue\":\"2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"R. Arandjelovi\\u0107\"},{\"authorId\":null,\"name\":\"A. Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Look\",\"url\":\"\",\"venue\":\"listen and learn. CoRR, abs/1705.08168\",\"year\":2017},{\"arxivId\":\"1406.6909\",\"authors\":[{\"authorId\":\"2841331\",\"name\":\"A. Dosovitskiy\"},{\"authorId\":\"2060551\",\"name\":\"Jost Tobias Springenberg\"},{\"authorId\":\"3137672\",\"name\":\"Martin A. Riedmiller\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a6fd96a900d4130940b488863b71fd09ad41ccb9\",\"title\":\"Discriminative Unsupervised Feature Learning with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/a6fd96a900d4130940b488863b71fd09ad41ccb9\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35581798\",\"name\":\"G. Roma\"},{\"authorId\":\"2410807\",\"name\":\"W. Nogueira\"},{\"authorId\":\"144906288\",\"name\":\"P. Herrera\"}],\"doi\":\"10.1109/WASPAA.2013.6701890\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"43836a5c083c5f8d0cc176692c23d895369a4692\",\"title\":\"Recurrence quantification analysis features for environmental sound recognition\",\"url\":\"https://www.semanticscholar.org/paper/43836a5c083c5f8d0cc176692c23d895369a4692\",\"venue\":\"2013 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1643899707\",\"name\":\"MesarosAnnamaria\"},{\"authorId\":\"1643900391\",\"name\":\"HeittolaToni\"},{\"authorId\":\"1643889859\",\"name\":\"BenetosEmmanouil\"},{\"authorId\":\"1643878926\",\"name\":\"FosterPeter\"},{\"authorId\":\"1643899911\",\"name\":\"LagrangeMathieu\"},{\"authorId\":\"1643899769\",\"name\":\"VirtanenTuomas\"},{\"authorId\":\"1643898226\",\"name\":\"D. PlumbleyMark\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"993d02b935ee2a8c969d3a22b950b99a7fffe4c9\",\"title\":\"Detection and Classification of Acoustic Scenes and Events\",\"url\":\"https://www.semanticscholar.org/paper/993d02b935ee2a8c969d3a22b950b99a7fffe4c9\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1609.03499\",\"authors\":[{\"authorId\":\"3422336\",\"name\":\"A. Oord\"},{\"authorId\":\"48373216\",\"name\":\"S. Dieleman\"},{\"authorId\":\"1691713\",\"name\":\"H. Zen\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"2583391\",\"name\":\"Nal Kalchbrenner\"},{\"authorId\":\"33666044\",\"name\":\"A. Senior\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"df0402517a7338ae28bc54acaac400de6b456a46\",\"title\":\"WaveNet: A Generative Model for Raw Audio\",\"url\":\"https://www.semanticscholar.org/paper/df0402517a7338ae28bc54acaac400de6b456a46\",\"venue\":\"SSW\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3264357\",\"name\":\"Karol J. Piczak\"}],\"doi\":\"10.1109/MLSP.2015.7324337\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0e39e519471cc41b232381bd529542e2c02f21fa\",\"title\":\"Environmental sound classification with convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/0e39e519471cc41b232381bd529542e2c02f21fa\",\"venue\":\"2015 IEEE 25th International Workshop on Machine Learning for Signal Processing (MLSP)\",\"year\":2015},{\"arxivId\":\"1512.00567\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"144147316\",\"name\":\"S. Ioffe\"},{\"authorId\":\"103590098\",\"name\":\"Jon Shlens\"},{\"authorId\":\"3282833\",\"name\":\"Z. Wojna\"}],\"doi\":\"10.1109/CVPR.2016.308\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"23ffaa0fe06eae05817f527a47ac3291077f9e58\",\"title\":\"Rethinking the Inception Architecture for Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/23ffaa0fe06eae05817f527a47ac3291077f9e58\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c11626ae08706e6185fceff0a6d05e4bfd6bd06\",\"title\":\"Unsupervised Learning of Visual Representations using Videos\",\"url\":\"https://www.semanticscholar.org/paper/6c11626ae08706e6185fceff0a6d05e4bfd6bd06\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1705.06950\",\"authors\":[{\"authorId\":\"21028601\",\"name\":\"W. Kay\"},{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"11809518\",\"name\":\"Brian Zhang\"},{\"authorId\":\"38961760\",\"name\":\"Chloe Hillier\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"143740871\",\"name\":\"F. Viola\"},{\"authorId\":\"143897708\",\"name\":\"T. Green\"},{\"authorId\":\"2830305\",\"name\":\"T. Back\"},{\"authorId\":\"1820908\",\"name\":\"A. Natsev\"},{\"authorId\":\"2573615\",\"name\":\"Mustafa Suleyman\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6\",\"title\":\"The Kinetics Human Action Video Dataset\",\"url\":\"https://www.semanticscholar.org/paper/86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1604.07379\",\"authors\":[{\"authorId\":\"38236002\",\"name\":\"Deepak Pathak\"},{\"authorId\":\"2562966\",\"name\":\"Philipp Kr\\u00e4henb\\u00fchl\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1109/CVPR.2016.278\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"7d0effebfa4bed19b6ba41f3af5b7e5b6890de87\",\"title\":\"Context Encoders: Feature Learning by Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/7d0effebfa4bed19b6ba41f3af5b7e5b6890de87\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"W. Kay\"},{\"authorId\":null,\"name\":\"J. Carreira\"},{\"authorId\":null,\"name\":\"K. Simonyan\"},{\"authorId\":null,\"name\":\"B. Zhang\"},{\"authorId\":null,\"name\":\"C. Hillier\"},{\"authorId\":null,\"name\":\"S. Vijayanarasimhan\"},{\"authorId\":null,\"name\":\"F. Viola\"},{\"authorId\":null,\"name\":\"T. Green\"},{\"authorId\":null,\"name\":\"T. Back\"},{\"authorId\":null,\"name\":\"P. Natsev\"},{\"authorId\":null,\"name\":\"M. Suleyman\"},{\"authorId\":null,\"name\":\"A. Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"The Kinetics human action video\",\"url\":\"\",\"venue\":\"dataset. CoRR,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1806773\",\"name\":\"I. Misra\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1007/978-3-319-46448-0_32\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d4e3616d0b27957c4107ae877dc0dd4504b69ab\",\"title\":\"Shuffle and Learn: Unsupervised Learning Using Temporal Order Verification\",\"url\":\"https://www.semanticscholar.org/paper/6d4e3616d0b27957c4107ae877dc0dd4504b69ab\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1603.08511\",\"authors\":[{\"authorId\":\"2844849\",\"name\":\"Richard Zhang\"},{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1007/978-3-319-46487-9_40\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8201e6e687f2de477258e9be53ba7b73ee30d7de\",\"title\":\"Colorful Image Colorization\",\"url\":\"https://www.semanticscholar.org/paper/8201e6e687f2de477258e9be53ba7b73ee30d7de\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1505.05192\",\"authors\":[{\"authorId\":\"2786693\",\"name\":\"C. Doersch\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1109/ICCV.2015.167\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fc1b1c9364c58ec406f494dd944b609a6a038ba6\",\"title\":\"Unsupervised Visual Representation Learning by Context Prediction\",\"url\":\"https://www.semanticscholar.org/paper/fc1b1c9364c58ec406f494dd944b609a6a038ba6\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2279670\",\"name\":\"Andrea Frome\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"1789737\",\"name\":\"Jonathon Shlens\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"},{\"authorId\":\"1706809\",\"name\":\"Marc'Aurelio Ranzato\"},{\"authorId\":null,\"name\":\"Tomas Mikolov\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"4aa4069693bee00d1b0759ca3df35e59284e9845\",\"title\":\"DeViSE: A Deep Visual-Semantic Embedding Model\",\"url\":\"https://www.semanticscholar.org/paper/4aa4069693bee00d1b0759ca3df35e59284e9845\",\"venue\":\"NIPS\",\"year\":2013},{\"arxivId\":\"1610.09001\",\"authors\":[{\"authorId\":\"3152281\",\"name\":\"Y. Aytar\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"7ab8d3af6f78f9c9f64a2f2d38471401ad0988a9\",\"title\":\"SoundNet: Learning Sound Representations from Unlabeled Video\",\"url\":\"https://www.semanticscholar.org/paper/7ab8d3af6f78f9c9f64a2f2d38471401ad0988a9\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38158333\",\"name\":\"A. Blum\"},{\"authorId\":\"152708276\",\"name\":\"T. Mitchell\"}],\"doi\":\"10.1145/279943.279962\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"278841ab0cb24c1abcb75e363aeed1fa741c8cc4\",\"title\":\"Combining labeled and unlabeled data with co-training\",\"url\":\"https://www.semanticscholar.org/paper/278841ab0cb24c1abcb75e363aeed1fa741c8cc4\",\"venue\":\"COLT' 98\",\"year\":1998},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3264357\",\"name\":\"Karol J. Piczak\"}],\"doi\":\"10.1145/2733373.2806390\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"99e6f700d374e34c8376f1f43af994b278924f28\",\"title\":\"ESC: Dataset for Environmental Sound Classification\",\"url\":\"https://www.semanticscholar.org/paper/99e6f700d374e34c8376f1f43af994b278924f28\",\"venue\":\"ACM Multimedia\",\"year\":2015},{\"arxivId\":\"1506.00511\",\"authors\":[{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"1754860\",\"name\":\"Kevin Swersky\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":\"10.1109/ICCV.2015.483\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"6540cb7971d1a9d72562d465172e010fbb729bc3\",\"title\":\"Predicting Deep Zero-Shot Convolutional Neural Networks Using Textual Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/6540cb7971d1a9d72562d465172e010fbb729bc3\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1608.07017\",\"authors\":[{\"authorId\":\"144956994\",\"name\":\"Andrew Owens\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"2324658\",\"name\":\"J. McDermott\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1007/978-3-319-46448-0_48\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"93a87dfa72f22fba14ef243a62c7d0a6906dfed7\",\"title\":\"Ambient Sound Provides Supervision for Visual Learning\",\"url\":\"https://www.semanticscholar.org/paper/93a87dfa72f22fba14ef243a62c7d0a6906dfed7\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1502.03167\",\"authors\":[{\"authorId\":\"144147316\",\"name\":\"S. Ioffe\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d376d6978dad0374edfa6709c9556b42d3594d3\",\"title\":\"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\",\"url\":\"https://www.semanticscholar.org/paper/4d376d6978dad0374edfa6709c9556b42d3594d3\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1511.06856\",\"authors\":[{\"authorId\":\"2562966\",\"name\":\"Philipp Kr\\u00e4henb\\u00fchl\"},{\"authorId\":\"2786693\",\"name\":\"C. Doersch\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c3af47db3186691270192d5399bb5259e05c87a7\",\"title\":\"Data-dependent Initializations of Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/c3af47db3186691270192d5399bb5259e05c87a7\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":\"1508.04909\",\"authors\":[{\"authorId\":\"1792962\",\"name\":\"A. Rakotomamonjy\"},{\"authorId\":\"2378576\",\"name\":\"G. Gasso\"}],\"doi\":\"10.1109/TASLP.2014.2375575\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d2d9b4ae910c6e1dcf9cd98cdbf04e93e82ddd3d\",\"title\":\"Histogram of Gradients of Time\\u2013Frequency Representations for Audio Scene Classification\",\"url\":\"https://www.semanticscholar.org/paper/d2d9b4ae910c6e1dcf9cd98cdbf04e93e82ddd3d\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/978-3-319-54427-4_19\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"87defac1045bfa9af0162cd248d193e9be6eb25b\",\"title\":\"Out of Time: Automated Lip Sync in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/87defac1045bfa9af0162cd248d193e9be6eb25b\",\"venue\":\"ACCV Workshops\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1895488\",\"name\":\"David F. Harwath\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"87697847062e7eefec99a8c3aec888e3eef5e5b9\",\"title\":\"Unsupervised Learning of Spoken Language with Visual Context\",\"url\":\"https://www.semanticscholar.org/paper/87697847062e7eefec99a8c3aec888e3eef5e5b9\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1505.01596\",\"authors\":[{\"authorId\":\"33932184\",\"name\":\"Pulkit Agrawal\"},{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/ICCV.2015.13\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dfbfaaec46d38392f61d683c340ee92a0a66e5d9\",\"title\":\"Learning to See by Moving\",\"url\":\"https://www.semanticscholar.org/paper/dfbfaaec46d38392f61d683c340ee92a0a66e5d9\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J. Ba. Adam\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\": A method for stochastic optimization\",\"url\":\"\",\"venue\":\"Proc . ICLR\",\"year\":2005}],\"title\":\"Look, Listen and Learn\",\"topics\":[{\"topic\":\"ImageNet\",\"topicId\":\"256302\",\"url\":\"https://www.semanticscholar.org/topic/256302\"},{\"topic\":\"Information source\",\"topicId\":\"56773\",\"url\":\"https://www.semanticscholar.org/topic/56773\"}],\"url\":\"https://www.semanticscholar.org/paper/9b5f696f73c1264ccb8e97d3b738a2342ecd6bee\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017}\n"