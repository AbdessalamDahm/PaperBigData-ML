"{\"abstract\":\"In visual question answering (VQA), an algorithm must answer text-based questions about images. While multiple datasets for VQA have been created since late 2014, they all have flaws in both their content and the way algorithms are evaluated on them. As a result, evaluation scores are inflated and predominantly determined by answering easier questions, making it difficult to compare different methods. In this paper, we analyze existing VQA algorithms using a new dataset called the Task Driven Image Understanding Challenge (TDIUC), which has over 1.6 million questions organized into 12 different categories. We also introduce questions that are meaningless for a given image to force a VQA system to reason about image content. We propose new evaluation schemes that compensate for over-represented question-types and make it easier to study the strengths and weaknesses of algorithms. We analyze the performance of both baseline and state-of-the-art VQA models, including multi-modal compact bilinear pooling (MCB), neural module networks, and recurrent answering units. Our experiments establish how attention helps certain categories more than others, determine which models work better than others, and explain how simple models (e.g. MLP) can surpass more complex models (MCB) by simply learning to answer large, easy question categories.\",\"arxivId\":\"1703.09684\",\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\",\"url\":\"https://www.semanticscholar.org/author/33315685\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\",\"url\":\"https://www.semanticscholar.org/author/3290098\"}],\"citationVelocity\":33,\"citations\":[{\"arxivId\":\"1704.07121\",\"authors\":[{\"authorId\":\"38784892\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"}],\"doi\":\"10.18653/v1/N18-1040\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3374dfe0419cf452d2a60cdd750bdeb6e7433e59\",\"title\":\"Being Negative but Constructively: Lessons Learnt from Creating Better Visual Question Answering Datasets\",\"url\":\"https://www.semanticscholar.org/paper/3374dfe0419cf452d2a60cdd750bdeb6e7433e59\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":\"1712.01034\",\"authors\":[{\"authorId\":\"40426020\",\"name\":\"P. Li\"},{\"authorId\":\"144418234\",\"name\":\"J. Xie\"},{\"authorId\":\"49110790\",\"name\":\"Qilong Wang\"},{\"authorId\":\"30122644\",\"name\":\"Zilin Gao\"}],\"doi\":\"10.1109/CVPR.2018.00105\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2451db113552afb6d9ad15ef4009ec4133d28f74\",\"title\":\"Towards Faster Training of Global Covariance Pooling Networks by Iterative Matrix Square Root Normalization\",\"url\":\"https://www.semanticscholar.org/paper/2451db113552afb6d9ad15ef4009ec4133d28f74\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1811.07789\",\"authors\":[{\"authorId\":\"1977256\",\"name\":\"V. Manjunatha\"},{\"authorId\":\"19173161\",\"name\":\"Nirat Saini\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/CVPR.2019.00979\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c5d15ab9b3d541e53d0b7743bce99a074698394b\",\"title\":\"Explicit Bias Discovery in Visual Question Answering Models\",\"url\":\"https://www.semanticscholar.org/paper/c5d15ab9b3d541e53d0b7743bce99a074698394b\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52215792\",\"name\":\"H. F. Langroudi\"},{\"authorId\":\"2373177\",\"name\":\"Cory E. Merkel\"},{\"authorId\":\"51208860\",\"name\":\"Humza Syed\"},{\"authorId\":\"3327477\",\"name\":\"D. Kudithipudi\"}],\"doi\":\"10.1109/IJCNN.2019.8852192\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"501cb0a6d393b3ac12831eeb17c53f1f63f85108\",\"title\":\"Exploiting Randomness in Deep Learning Algorithms\",\"url\":\"https://www.semanticscholar.org/paper/501cb0a6d393b3ac12831eeb17c53f1f63f85108\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"25309225\",\"name\":\"Avikalp Srivastava\"},{\"authorId\":\"153803927\",\"name\":\"H. Liu\"},{\"authorId\":\"33208854\",\"name\":\"S. Fujita\"}],\"doi\":\"10.1145/3357384.3358000\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6fb13d374dc32a55ab454fe9b8dd05527b553af9\",\"title\":\"Adapting Visual Question Answering Models for Enhancing Multimodal Community Q&A Platforms\",\"url\":\"https://www.semanticscholar.org/paper/6fb13d374dc32a55ab454fe9b8dd05527b553af9\",\"venue\":\"CIKM\",\"year\":2019},{\"arxivId\":\"1711.06232\",\"authors\":[{\"authorId\":\"2973866\",\"name\":\"J. Huang\"},{\"authorId\":\"3409955\",\"name\":\"C. D. Dao\"},{\"authorId\":\"9951160\",\"name\":\"Modar Alfadly\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1609/aaai.v33i01.33018449\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a26d01dc2b9a4e435c015914690354f67a9b6a08\",\"title\":\"A Novel Framework for Robustness Analysis of Visual QA Models\",\"url\":\"https://www.semanticscholar.org/paper/a26d01dc2b9a4e435c015914690354f67a9b6a08\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1908.04289\",\"authors\":[{\"authorId\":\"144740494\",\"name\":\"Peng Gao\"},{\"authorId\":\"30156979\",\"name\":\"Haoxuan You\"},{\"authorId\":\"3152448\",\"name\":\"Zhanpeng Zhang\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"}],\"doi\":\"10.1109/ICCV.2019.00592\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf5a0d3b67cf03c2441f7aa20f0ea499bd02acf6\",\"title\":\"Multi-Modality Latent Interaction Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/cf5a0d3b67cf03c2441f7aa20f0ea499bd02acf6\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1908.02660\",\"authors\":[{\"authorId\":\"150180131\",\"name\":\"Kaiyu Yang\"},{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"145124903\",\"name\":\"J. Deng\"}],\"doi\":\"10.1109/ICCV.2019.00214\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"1d738fa77de08592d9b77754e48cc63e276e5c0d\",\"title\":\"SpatialSense: An Adversarially Crowdsourced Benchmark for Spatial Relation Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1d738fa77de08592d9b77754e48cc63e276e5c0d\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1904.04957\",\"authors\":[{\"authorId\":\"73659073\",\"name\":\"T. Hascoet\"},{\"authorId\":\"1678564\",\"name\":\"Y. Ariki\"},{\"authorId\":\"1744026\",\"name\":\"T. Takiguchi\"}],\"doi\":\"10.1109/CVPR.2019.00978\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9e7cdb434747c16c78a2dde86e2c43a8a75c8a14\",\"title\":\"On Zero-Shot Recognition of Generic Objects\",\"url\":\"https://www.semanticscholar.org/paper/9e7cdb434747c16c78a2dde86e2c43a8a75c8a14\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40062064\",\"name\":\"Claudio Greco\"},{\"authorId\":\"50829868\",\"name\":\"A. Testoni\"},{\"authorId\":\"145040726\",\"name\":\"R. Bernardi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fea5b24f57703f596fa01c188c3e445fa14994df\",\"title\":\"Which Turn do Neural Models Exploit the Most to Solve GuessWhat? Diving into the Dialogue History Encoding in Transformers and LSTMs\",\"url\":\"https://www.semanticscholar.org/paper/fea5b24f57703f596fa01c188c3e445fa14994df\",\"venue\":\"NL4AI@AI*IA\",\"year\":2020},{\"arxivId\":\"2001.07059\",\"authors\":[{\"authorId\":\"6328564\",\"name\":\"M. Farazi\"},{\"authorId\":\"1931655\",\"name\":\"S. Khan\"},{\"authorId\":\"1712576\",\"name\":\"N. Barnes\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8527a2f65eaaf0c96b2ac9430185b0e12d8973a9\",\"title\":\"Accuracy vs. Complexity: A Trade-off in Visual Question Answering Models\",\"url\":\"https://www.semanticscholar.org/paper/8527a2f65eaaf0c96b2ac9430185b0e12d8973a9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2028946\",\"name\":\"D. Gurari\"},{\"authorId\":\"50444302\",\"name\":\"Q. Li\"},{\"authorId\":\"47532530\",\"name\":\"Chi Lin\"},{\"authorId\":\"46317592\",\"name\":\"Y. Zhao\"},{\"authorId\":\"2582404\",\"name\":\"Anhong Guo\"},{\"authorId\":\"46500210\",\"name\":\"Abigale Stangl\"},{\"authorId\":\"1744846\",\"name\":\"Jeffrey P. Bigham\"}],\"doi\":\"10.1109/CVPR.2019.00103\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8dba803240e2cf00d143d4b0a82b95933b5883eb\",\"title\":\"VizWiz-Priv: A Dataset for Recognizing the Presence and Purpose of Private Visual Information in Images Taken by Blind People\",\"url\":\"https://www.semanticscholar.org/paper/8dba803240e2cf00d143d4b0a82b95933b5883eb\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c1693e1defad1cc8ec36b061add2afcd564013ff\",\"title\":\"Advancing Multi-Modal Deep Learning: Towards Language-Grounded Visual Understanding\",\"url\":\"https://www.semanticscholar.org/paper/c1693e1defad1cc8ec36b061add2afcd564013ff\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145764583\",\"name\":\"F. Liu\"},{\"authorId\":\"40628473\",\"name\":\"Jing Liu\"},{\"authorId\":\"49597404\",\"name\":\"Z. Fang\"},{\"authorId\":\"48043335\",\"name\":\"R. Hong\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.24963/ijcai.2019/122\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"99dc8f4c6be75b32a584608cea2c0da0de47db8d\",\"title\":\"Densely Connected Attention Flow for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/99dc8f4c6be75b32a584608cea2c0da0de47db8d\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48669970\",\"name\":\"X. Xu\"},{\"authorId\":\"2727656\",\"name\":\"X. Chen\"},{\"authorId\":null,\"name\":\"Chang Liu\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"143711382\",\"name\":\"D. Song\"}],\"doi\":\"10.1109/CVPR.2018.00520\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2fa9b32ebc329d57fa2e3fabb9e12382f019f47a\",\"title\":\"Fooling Vision and Language Models Despite Localization and Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/2fa9b32ebc329d57fa2e3fabb9e12382f019f47a\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1904.09317\",\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"153677280\",\"name\":\"Robik Shrestha\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.3389/frai.2019.00028\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"78f36f2acb0c88cfe74572933cb52c9cc75a1d50\",\"title\":\"Challenges and Prospects in Vision and Language Research\",\"url\":\"https://www.semanticscholar.org/paper/78f36f2acb0c88cfe74572933cb52c9cc75a1d50\",\"venue\":\"Front. Artif. Intell.\",\"year\":2019},{\"arxivId\":\"1809.04344\",\"authors\":[{\"authorId\":\"51228129\",\"name\":\"Shailza Jolly\"},{\"authorId\":\"3422247\",\"name\":\"Sandro Pezzelle\"},{\"authorId\":\"35660331\",\"name\":\"T. Klein\"},{\"authorId\":\"145279674\",\"name\":\"A. Dengel\"},{\"authorId\":\"1848946\",\"name\":\"Moin Nabi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"610e0bee525a6573932e077f091505f54a5c4ede\",\"title\":\"The Wisdom of MaSSeS: Majority, Subjectivity, and Semantic Similarity in the Evaluation of VQA\",\"url\":\"https://www.semanticscholar.org/paper/610e0bee525a6573932e077f091505f54a5c4ede\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49303626\",\"name\":\"K. Su\"},{\"authorId\":\"144904233\",\"name\":\"Hang Su\"},{\"authorId\":\"104545113\",\"name\":\"J. Li\"},{\"authorId\":\"1557387379\",\"name\":\"Jun Zhu\"}],\"doi\":\"10.3389/frobt.2020.00109\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"22e2a19bef88c30a37402da5b54fac34655d77ea\",\"title\":\"Toward Accurate Visual Reasoning With Dual-Path Neural Module Networks\",\"url\":\"https://www.semanticscholar.org/paper/22e2a19bef88c30a37402da5b54fac34655d77ea\",\"venue\":\"Frontiers in Robotics and AI\",\"year\":2020},{\"arxivId\":\"1908.02962\",\"authors\":[{\"authorId\":\"2420608\",\"name\":\"Difei Gao\"},{\"authorId\":\"3373117\",\"name\":\"R. Wang\"},{\"authorId\":\"145455919\",\"name\":\"S. Shan\"},{\"authorId\":\"1710220\",\"name\":\"X. Chen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"06b3ecff93bc79a1242b06702f160ffc43c487b9\",\"title\":\"From Two Graphs to N Questions: A VQA Dataset for Compositional Reasoning on Vision and Commonsense\",\"url\":\"https://www.semanticscholar.org/paper/06b3ecff93bc79a1242b06702f160ffc43c487b9\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49597404\",\"name\":\"Z. Fang\"},{\"authorId\":\"46700426\",\"name\":\"J. Liu\"},{\"authorId\":\"47003032\",\"name\":\"Y. Li\"},{\"authorId\":\"80526284\",\"name\":\"Yanyuan Qiao\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1016/J.PATCOG.2019.01.038\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aa31126aa9dc7665bf236a51c6de31c4bf6c59ad\",\"title\":\"Improving visual question answering using dropout and enhanced question encoder\",\"url\":\"https://www.semanticscholar.org/paper/aa31126aa9dc7665bf236a51c6de31c4bf6c59ad\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":\"1810.03649\",\"authors\":[{\"authorId\":\"31448527\",\"name\":\"S. Ramakrishnan\"},{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"45ec1446f42c0a7c7fe74319118335c76e0f7b19\",\"title\":\"Overcoming Language Priors in Visual Question Answering with Adversarial Regularization\",\"url\":\"https://www.semanticscholar.org/paper/45ec1446f42c0a7c7fe74319118335c76e0f7b19\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1801.08163\",\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"152452655\",\"name\":\"S. Cohen\"},{\"authorId\":\"31844147\",\"name\":\"Brian L. Price\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1109/CVPR.2018.00592\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7289a240c9425bc7cad87b3b835e5f0cac22f488\",\"title\":\"DVQA: Understanding Data Visualizations via Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7289a240c9425bc7cad87b3b835e5f0cac22f488\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144544920\",\"name\":\"Fei Liu\"},{\"authorId\":\"1749850\",\"name\":\"J. Liu\"},{\"authorId\":\"48043335\",\"name\":\"R. Hong\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1145/3343031.3350993\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6834deeabfbc3ca5989ca7a3bd76dc5a84c5a346\",\"title\":\"Erasing-based Attention Learning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/6834deeabfbc3ca5989ca7a3bd76dc5a84c5a346\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1907.11770\",\"authors\":[{\"authorId\":\"31686229\",\"name\":\"Noriyuki Kojima\"},{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"bcb6375b4286bf2718c4e5f2515e40601f706d18\",\"title\":\"To Learn or Not to Learn: Analyzing the Role of Learning for Navigation in Virtual Environments\",\"url\":\"https://www.semanticscholar.org/paper/bcb6375b4286bf2718c4e5f2515e40601f706d18\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35232494\",\"name\":\"Tongshuang (Sherry) Wu\"},{\"authorId\":\"78846919\",\"name\":\"Marco Tulio Ribeiro\"},{\"authorId\":\"1803140\",\"name\":\"J. Heer\"},{\"authorId\":\"1780531\",\"name\":\"Daniel S. Weld\"}],\"doi\":\"10.18653/v1/P19-1073\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"61c3c1d251c8d00a76c7513e06b24692d0b74284\",\"title\":\"Errudite: Scalable, Reproducible, and Testable Error Analysis\",\"url\":\"https://www.semanticscholar.org/paper/61c3c1d251c8d00a76c7513e06b24692d0b74284\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8799308\",\"name\":\"U. Nadeem\"},{\"authorId\":\"2210661\",\"name\":\"S. Shah\"},{\"authorId\":\"2470423\",\"name\":\"Ferdous Sohel\"},{\"authorId\":\"2444665\",\"name\":\"R. Togneri\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"}],\"doi\":\"10.1007/978-3-030-11479-4_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e549a9049bbbcb1a9e854de2f05fdfae4fb0da7d\",\"title\":\"Deep Learning for Scene Understanding\",\"url\":\"https://www.semanticscholar.org/paper/e549a9049bbbcb1a9e854de2f05fdfae4fb0da7d\",\"venue\":\"Handbook of Deep Learning Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6937593\",\"name\":\"Shih-Han Chou\"},{\"authorId\":\"150336480\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"38784892\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"30885811\",\"name\":\"Min Sun\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/WACV45572.2020.9093452\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0e0c5d868d84908bb7a26c27c1aedea43fdc493d\",\"title\":\"Visual Question Answering on 360\\u00b0 Images\",\"url\":\"https://www.semanticscholar.org/paper/0e0c5d868d84908bb7a26c27c1aedea43fdc493d\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40295709\",\"name\":\"F. Liu\"},{\"authorId\":null,\"name\":\"Jing Liu\"},{\"authorId\":\"48386951\",\"name\":\"Xinxin Zhu\"},{\"authorId\":\"120313754\",\"name\":\"Richang Hong\"},{\"authorId\":\"1699900\",\"name\":\"H. Lu\"}],\"doi\":\"10.1145/3394171.3413649\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"063235546b312ee4cb5cc67578b6e879461c6d83\",\"title\":\"Dual Hierarchical Temporal Convolutional Network with QA-Aware Dynamic Normalization for Video Story Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/063235546b312ee4cb5cc67578b6e879461c6d83\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2003.11844\",\"authors\":[{\"authorId\":\"51228129\",\"name\":\"Shailza Jolly\"},{\"authorId\":\"145491338\",\"name\":\"S. Palacio\"},{\"authorId\":\"144553243\",\"name\":\"J. Folz\"},{\"authorId\":\"48258541\",\"name\":\"Federico Raue\"},{\"authorId\":\"120996558\",\"name\":\"J. Hees\"},{\"authorId\":\"1384499125\",\"name\":\"Andreas Dengel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"625ec4698251cd181818bfd12f1cd5e63c7bcef0\",\"title\":\"P $\\\\approx$ NP, at least in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/625ec4698251cd181818bfd12f1cd5e63c7bcef0\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1810.12440\",\"authors\":[{\"authorId\":\"47309247\",\"name\":\"Manoj Acharya\"},{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1609/aaai.v33i01.33018076\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"634161e4759616dbe06f0b1465999d3df122f366\",\"title\":\"TallyQA: Answering Complex Counting Questions\",\"url\":\"https://www.semanticscholar.org/paper/634161e4759616dbe06f0b1465999d3df122f366\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1902.09487\",\"authors\":[{\"authorId\":\"7535126\",\"name\":\"R\\u00e9mi Cad\\u00e8ne\"},{\"authorId\":\"1405301761\",\"name\":\"Hedi Ben-younes\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"},{\"authorId\":\"1728523\",\"name\":\"N. Thome\"}],\"doi\":\"10.1109/CVPR.2019.00209\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0a9f1a1321958df7dfb2efce3e9d1e99b9f5ccb3\",\"title\":\"MUREL: Multimodal Relational Reasoning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0a9f1a1321958df7dfb2efce3e9d1e99b9f5ccb3\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1712.00377\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"}],\"doi\":\"10.1109/CVPR.2018.00522\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"90873a97aa9a43775e5aeea01b03aea54b28bfbd\",\"title\":\"Don't Just Assume; Look and Answer: Overcoming Priors for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/90873a97aa9a43775e5aeea01b03aea54b28bfbd\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"89813962\",\"name\":\"Shivangi Modi\"},{\"authorId\":\"153279050\",\"name\":\"Dhatri Pandya\"}],\"doi\":\"10.1109/ICCMC.2019.8819803\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c99654c738cf9a426fac40251e277282a8ee86a7\",\"title\":\"VQAR: Review on Information Retrieval Techniques based on Computer Vision and Natural Language Processing\",\"url\":\"https://www.semanticscholar.org/paper/c99654c738cf9a426fac40251e277282a8ee86a7\",\"venue\":\"2019 3rd International Conference on Computing Methodologies and Communication (ICCMC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46584793\",\"name\":\"J. Wang\"},{\"authorId\":\"145720027\",\"name\":\"W. Deng\"},{\"authorId\":\"9177519\",\"name\":\"Yukuan Sun\"},{\"authorId\":\"48515090\",\"name\":\"Y. Li\"},{\"authorId\":\"48884722\",\"name\":\"K. Wang\"},{\"authorId\":\"151470674\",\"name\":\"Guanghao Jin\"}],\"doi\":\"10.1109/ICME.2019.00132\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c9f0f52e068199acbbe2d528e379db04b96771a3\",\"title\":\"Twice Opportunity Knocks Syntactic Ambiguity: A Visual Question Answering Model with yes/no Feedback\",\"url\":\"https://www.semanticscholar.org/paper/c9f0f52e068199acbbe2d528e379db04b96771a3\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1389646918\",\"name\":\"Edison Marrese-Taylor\"},{\"authorId\":\"144760828\",\"name\":\"C. Rodriguez\"},{\"authorId\":\"2267140\",\"name\":\"Jorge A. Balazs\"},{\"authorId\":\"49384810\",\"name\":\"S. Gould\"},{\"authorId\":\"49484314\",\"name\":\"Y. Matsuo\"}],\"doi\":\"10.18653/v1/2020.challengehml-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7a406da5e069e37fe780d679a7140ecf46454bc3\",\"title\":\"ACL 2020 The 58th Annual Meeting of the Association for Computational Linguistics Proceedings of the Second Grand Challenge and Workshop on Multimodal Language (Challenge-HML)\",\"url\":\"https://www.semanticscholar.org/paper/7a406da5e069e37fe780d679a7140ecf46454bc3\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2006.06637\",\"authors\":[{\"authorId\":\"1742328079\",\"name\":\"Shaunak Halbe\"}],\"doi\":\"10.18653/v1/2020.challengehml-1.9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"274fffd96aa6c20931ccdf5e1ce6677dcc9fbe75\",\"title\":\"Exploring Weaknesses of VQA Models through Attribution Driven Insights\",\"url\":\"https://www.semanticscholar.org/paper/274fffd96aa6c20931ccdf5e1ce6677dcc9fbe75\",\"venue\":\"CHALLENGEHML\",\"year\":2020},{\"arxivId\":\"2009.11118\",\"authors\":[{\"authorId\":\"52220768\",\"name\":\"T. Do\"},{\"authorId\":\"47787551\",\"name\":\"Binh X. Nguyen\"},{\"authorId\":\"1981175\",\"name\":\"Huy Tran\"},{\"authorId\":\"1387964524\",\"name\":\"Erman Tjiputra\"},{\"authorId\":\"31534280\",\"name\":\"Q. D. Tran\"},{\"authorId\":\"3354627\",\"name\":\"Thanh-Toan Do\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"30173e8b551c0655e2036aba7fedf354f1ef5658\",\"title\":\"Multiple interaction learning with question-type prior knowledge for constraining answer search space in visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/30173e8b551c0655e2036aba7fedf354f1ef5658\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1912.01452\",\"authors\":[{\"authorId\":\"50535497\",\"name\":\"Jiahong Huang\"},{\"authorId\":\"9951160\",\"name\":\"Modar Alfadly\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"1717056\",\"name\":\"M. Worring\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"01aa5668a618fbb376b6ab6608defc074ed355ac\",\"title\":\"Assessing the Robustness of Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/01aa5668a618fbb376b6ab6608defc074ed355ac\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1908.03289\",\"authors\":[{\"authorId\":\"6328564\",\"name\":\"M. Farazi\"},{\"authorId\":\"1931655\",\"name\":\"S. Khan\"},{\"authorId\":\"1712576\",\"name\":\"N. Barnes\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e2a185828cad6b8ea5133a9e41d1ab4b75c9f718\",\"title\":\"Question-Agnostic Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e2a185828cad6b8ea5133a9e41d1ab4b75c9f718\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22225752\",\"name\":\"F. Brad\"}],\"doi\":\"10.1109/ICCVW.2019.00560\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f3ede2a4244f7485270d5e155de8cb14d1f88bc2\",\"title\":\"Scene Graph Contextualization in Visual Commonsense Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/f3ede2a4244f7485270d5e155de8cb14d1f88bc2\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1620218253\",\"name\":\"Sruthy Manmadhan\"},{\"authorId\":\"30588803\",\"name\":\"Binsu C. Kovoor\"}],\"doi\":\"10.1007/s10462-020-09832-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"667b88984df0c5c11ac07899ffb5509185abdf57\",\"title\":\"Visual question answering: a state-of-the-art review\",\"url\":\"https://www.semanticscholar.org/paper/667b88984df0c5c11ac07899ffb5509185abdf57\",\"venue\":\"Artificial Intelligence Review\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2034270322\",\"name\":\"Liyana Sahir Kallooriyakath\"},{\"authorId\":\"2034269084\",\"name\":\"Jithin M V\"},{\"authorId\":\"81431088\",\"name\":\"B. V\"},{\"authorId\":\"2034269088\",\"name\":\"Adith P P\"}],\"doi\":\"10.1109/ICSTCEE49637.2020.9277374\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ea0ab46474037363b0a52b758538e61ccb90ecec\",\"title\":\"Visual Question Answering: Methodologies and Challenges\",\"url\":\"https://www.semanticscholar.org/paper/ea0ab46474037363b0a52b758538e61ccb90ecec\",\"venue\":\"2020 International Conference on Smart Technologies in Computing, Electrical and Electronics (ICSTCEE)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1576818877\",\"name\":\"Kento Terao\"},{\"authorId\":\"134811419\",\"name\":\"Toru Tamaki\"},{\"authorId\":\"1688940\",\"name\":\"B. Raytchev\"},{\"authorId\":\"1686272\",\"name\":\"K. Kaneda\"},{\"authorId\":\"144404414\",\"name\":\"S. Satoh\"}],\"doi\":\"10.1109/ACCESS.2020.3022063\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c7583d58aec662313bd5b0082b656d9f44956dc3\",\"title\":\"An Entropy Clustering Approach for Assessing Visual Question Difficulty\",\"url\":\"https://www.semanticscholar.org/paper/c7583d58aec662313bd5b0082b656d9f44956dc3\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2007669688\",\"name\":\"Zujie Liang\"},{\"authorId\":\"49408562\",\"name\":\"Weitao Jiang\"},{\"authorId\":\"145442620\",\"name\":\"Haifeng Hu\"},{\"authorId\":\"47054782\",\"name\":\"Jiaying Zhu\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.265\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5f5dffcc47a08ef74e93077583b0e8a11662bf02\",\"title\":\"Learning to Contrast the Counterfactual Samples for Robust Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/5f5dffcc47a08ef74e93077583b0e8a11662bf02\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"1612.00837\",\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"7595427\",\"name\":\"Tejas Khot\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2017.670\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"title\":\"Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"42afa9a0166eeb45cb2e9b37e0a8eec482f78fe0\",\"title\":\"Visual Question Answering and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/42afa9a0166eeb45cb2e9b37e0a8eec482f78fe0\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1902.09506\",\"authors\":[{\"authorId\":\"152951058\",\"name\":\"Drew A. Hudson\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"c122fa378a774ba202d418cf71c5c356cf2f902f\",\"title\":\"GQA: a new dataset for compositional question answering over real-world images\",\"url\":\"https://www.semanticscholar.org/paper/c122fa378a774ba202d418cf71c5c356cf2f902f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144689860\",\"name\":\"Wei Deng\"},{\"authorId\":\"46584793\",\"name\":\"J. Wang\"},{\"authorId\":\"2690741\",\"name\":\"Shengbei Wang\"},{\"authorId\":\"1809607\",\"name\":\"G. Jin\"}],\"doi\":\"10.1145/3278198.3278207\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"09f1980e370fd5f4e1974baf7b943d26971ea219\",\"title\":\"Flexible Sentence Analysis Model for Visual Question Answering Network\",\"url\":\"https://www.semanticscholar.org/paper/09f1980e370fd5f4e1974baf7b943d26971ea219\",\"venue\":\"ICBEB 2018\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3449429\",\"name\":\"Alexander Kuhnle\"}],\"doi\":\"10.17863/CAM.49177\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c04262cb3f76ff769af32afad05263bd47ebef18\",\"title\":\"Evaluating visually grounded language capabilities using microworlds\",\"url\":\"https://www.semanticscholar.org/paper/c04262cb3f76ff769af32afad05263bd47ebef18\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35232494\",\"name\":\"Tongshuang (Sherry) Wu\"},{\"authorId\":\"8334069\",\"name\":\"Kanit Wongsuphasawat\"},{\"authorId\":\"40633287\",\"name\":\"Donghao Ren\"}],\"doi\":\"10.1145/3313831.3376451\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6596fc562cabd7b49571082ae5994545e7320cc2\",\"title\":\"Tempura: Query Analysis with Structural Templates\",\"url\":\"https://www.semanticscholar.org/paper/6596fc562cabd7b49571082ae5994545e7320cc2\",\"venue\":\"CHI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32791167\",\"name\":\"Chenchen Jing\"},{\"authorId\":\"150352923\",\"name\":\"Yuwei Wu\"},{\"authorId\":\"2674678\",\"name\":\"Xiaoxun Zhang\"},{\"authorId\":\"7415267\",\"name\":\"Y. Jia\"},{\"authorId\":\"49018095\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1609/AAAI.V34I07.6776\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5ac43583eedebd895fcfd45e9670a542c4c4070f\",\"title\":\"Overcoming Language Priors in VQA via Decomposed Linguistic Representations\",\"url\":\"https://www.semanticscholar.org/paper/5ac43583eedebd895fcfd45e9670a542c4c4070f\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1808.09648\",\"authors\":[{\"authorId\":\"25309225\",\"name\":\"Avikalp Srivastava\"},{\"authorId\":\"153803927\",\"name\":\"H. Liu\"},{\"authorId\":\"33208854\",\"name\":\"S. Fujita\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"216c6d29a6f57c37ef8f26f88b6ec9be5b855a66\",\"title\":\"From VQA to Multimodal CQA: Adapting Visual QA Models for Community QA Tasks\",\"url\":\"https://www.semanticscholar.org/paper/216c6d29a6f57c37ef8f26f88b6ec9be5b855a66\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1805.05492\",\"authors\":[{\"authorId\":\"2235894\",\"name\":\"Pramod Kaushik Mudrakarta\"},{\"authorId\":\"40511120\",\"name\":\"Ankur Taly\"},{\"authorId\":\"30740726\",\"name\":\"M. Sundararajan\"},{\"authorId\":\"1696833\",\"name\":\"K. Dhamdhere\"}],\"doi\":\"10.18653/v1/P18-1176\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4a9831e5fec549edee454709048a51997ef60fb7\",\"title\":\"Did the Model Understand the Question?\",\"url\":\"https://www.semanticscholar.org/paper/4a9831e5fec549edee454709048a51997ef60fb7\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":\"1802.08218\",\"authors\":[{\"authorId\":\"2028946\",\"name\":\"D. Gurari\"},{\"authorId\":\"48933900\",\"name\":\"Q. Li\"},{\"authorId\":\"32027456\",\"name\":\"A. J. Stangl\"},{\"authorId\":\"2582404\",\"name\":\"Anhong Guo\"},{\"authorId\":\"47532530\",\"name\":\"Chi Lin\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"},{\"authorId\":\"1744846\",\"name\":\"Jeffrey P. Bigham\"}],\"doi\":\"10.1109/CVPR.2018.00380\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a9e19e8ab24071a085d1273b9f9d49aa0e4ba48c\",\"title\":\"VizWiz Grand Challenge: Answering Visual Questions from Blind People\",\"url\":\"https://www.semanticscholar.org/paper/a9e19e8ab24071a085d1273b9f9d49aa0e4ba48c\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1804.02088\",\"authors\":[{\"authorId\":\"145659406\",\"name\":\"Y. Shi\"},{\"authorId\":\"2426872\",\"name\":\"T. Furlanello\"},{\"authorId\":\"40881843\",\"name\":\"Sheng Zha\"},{\"authorId\":\"2047844\",\"name\":\"Anima Anandkumar\"}],\"doi\":\"10.1007/978-3-030-01225-0_10\",\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"80fc9efde5bb28550d17363d882fd5bc6d805c26\",\"title\":\"Question Type Guided Attention in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/80fc9efde5bb28550d17363d882fd5bc6d805c26\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1902.00038\",\"authors\":[{\"authorId\":\"1405301761\",\"name\":\"Hedi Ben-younes\"},{\"authorId\":\"7535126\",\"name\":\"R\\u00e9mi Cad\\u00e8ne\"},{\"authorId\":\"1728523\",\"name\":\"N. Thome\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"}],\"doi\":\"10.1609/aaai.v33i01.33018102\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a154867c7b45456abb14708a7bbc9c849aeecf4f\",\"title\":\"BLOCK: Bilinear Superdiagonal Fusion for Visual Question Answering and Visual Relationship Detection\",\"url\":\"https://www.semanticscholar.org/paper/a154867c7b45456abb14708a7bbc9c849aeecf4f\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7535126\",\"name\":\"R\\u00e9mi Cad\\u00e8ne\"},{\"authorId\":\"1405301761\",\"name\":\"Hedi Ben-younes\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"},{\"authorId\":\"1728523\",\"name\":\"N. Thome\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"cfc9ef5c7ef8056cff7bf1f1cfdd75e120f28231\",\"title\":\"Multimodal Relational Reasoning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/cfc9ef5c7ef8056cff7bf1f1cfdd75e120f28231\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Guohao Li\"},{\"authorId\":\"72541452\",\"name\":\"X. Wang\"},{\"authorId\":\"145583986\",\"name\":\"Wenwu Zhu\"}],\"doi\":\"10.1145/3343031.3350922\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"35074d64a1d70172cab24a1343ae08ea3c078ce2\",\"title\":\"Perceptual Visual Reasoning with Knowledge Propagation\",\"url\":\"https://www.semanticscholar.org/paper/35074d64a1d70172cab24a1343ae08ea3c078ce2\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1711.06370\",\"authors\":[{\"authorId\":\"3194022\",\"name\":\"Bohan Zhuang\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2018.00447\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7299465d70181e423480fdb252aa2e28c18aa012\",\"title\":\"Parallel Attention: A Unified Framework for Visual Object Discovery Through Dialogs and Queries\",\"url\":\"https://www.semanticscholar.org/paper/7299465d70181e423480fdb252aa2e28c18aa012\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1909.01860\",\"authors\":[{\"authorId\":\"66275275\",\"name\":\"Yash Srivastava\"},{\"authorId\":\"152967610\",\"name\":\"Vaishnav Murali\"},{\"authorId\":\"34992579\",\"name\":\"S. Dubey\"},{\"authorId\":\"34356161\",\"name\":\"Snehasis Mukherjee\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b0ddbc14499fbc4b03ad92eb7f9a9b26b1eeb39e\",\"title\":\"Visual Question Answering using Deep Learning: A Survey and Performance Analysis\",\"url\":\"https://www.semanticscholar.org/paper/b0ddbc14499fbc4b03ad92eb7f9a9b26b1eeb39e\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1706.01427\",\"authors\":[{\"authorId\":\"35030998\",\"name\":\"A. Santoro\"},{\"authorId\":\"143724694\",\"name\":\"D. Raposo\"},{\"authorId\":\"50181861\",\"name\":\"David G. T. Barrett\"},{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"1996134\",\"name\":\"Razvan Pascanu\"},{\"authorId\":\"2019153\",\"name\":\"P. Battaglia\"},{\"authorId\":\"2542999\",\"name\":\"T. Lillicrap\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"007112213ece771be72cbecfd59f048209facabd\",\"title\":\"A simple neural network module for relational reasoning\",\"url\":\"https://www.semanticscholar.org/paper/007112213ece771be72cbecfd59f048209facabd\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Kushal Kafle\"},{\"authorId\":\"153677280\",\"name\":\"Robik Shrestha\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e3bb5773205477ae4711524a9d4ae739bee40349\",\"title\":\"Visual semantic role labeling requires recognizing activities and semantic context in images\",\"url\":\"https://www.semanticscholar.org/paper/e3bb5773205477ae4711524a9d4ae739bee40349\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23364558\",\"name\":\"Nilavra Bhattacharya\"},{\"authorId\":\"101489041\",\"name\":\"Q. Li\"},{\"authorId\":\"2028946\",\"name\":\"D. Gurari\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6a9293145a9a3a7ca42b18a437e0bce67a359127\",\"title\":\"Reason Label Description Issues with the Question-Image ( QI ) pair Low Quality\",\"url\":\"https://www.semanticscholar.org/paper/6a9293145a9a3a7ca42b18a437e0bce67a359127\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1908.04342\",\"authors\":[{\"authorId\":\"23364558\",\"name\":\"Nilavra Bhattacharya\"},{\"authorId\":\"48933740\",\"name\":\"Q. Li\"},{\"authorId\":\"2028946\",\"name\":\"D. Gurari\"}],\"doi\":\"10.1109/ICCV.2019.00437\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4cae43b28757e0c37a05156ed063dcc3bb652809\",\"title\":\"Why Does a Visual Question Have Different Answers?\",\"url\":\"https://www.semanticscholar.org/paper/4cae43b28757e0c37a05156ed063dcc3bb652809\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66935500\",\"name\":\"P. Deshmukh\"},{\"authorId\":\"51502239\",\"name\":\"Rani S. Lande\"}],\"doi\":\"10.1109/ICICT48043.2020.9112454\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8ce3c61b083ce5e66e34df3e1113cb603a6a6632\",\"title\":\"Convolutional Neural Network based Review System for Automatic Past Event Search using Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8ce3c61b083ce5e66e34df3e1113cb603a6a6632\",\"venue\":\"2020 International Conference on Inventive Computation Technologies (ICICT)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2712862\",\"name\":\"D. Zhang\"},{\"authorId\":\"145690873\",\"name\":\"R. Cao\"},{\"authorId\":\"1765710\",\"name\":\"Sai Wu\"}],\"doi\":\"10.1016/J.INFFUS.2019.03.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"91118408f8192c2addade2a0401a32c3bbd47818\",\"title\":\"Information fusion in visual question answering: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/91118408f8192c2addade2a0401a32c3bbd47818\",\"venue\":\"Inf. Fusion\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"120722271\",\"name\":\"Pratyay Banerjee\"},{\"authorId\":\"120838645\",\"name\":\"Tejas Gokhale\"},{\"authorId\":\"1784500\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"1760291\",\"name\":\"Chitta Baral\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"292d6cbab27ba35c825d75130311a4b27f291af2\",\"title\":\"Visual Question Answering with Annotation-Efficient Zero Shot Learning under Linguistic Domain Shift\",\"url\":\"https://www.semanticscholar.org/paper/292d6cbab27ba35c825d75130311a4b27f291af2\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150074679\",\"name\":\"Denis Dushi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d19ab1db4d8c60643bc2ce8334505acaadee84ff\",\"title\":\"Using Deep Learning to Answer Visual Questions from Blind People\",\"url\":\"https://www.semanticscholar.org/paper/d19ab1db4d8c60643bc2ce8334505acaadee84ff\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1906.10169\",\"authors\":[{\"authorId\":\"7535126\",\"name\":\"R\\u00e9mi Cad\\u00e8ne\"},{\"authorId\":\"41020827\",\"name\":\"Corentin Dancette\"},{\"authorId\":\"1405301761\",\"name\":\"Hedi Ben-younes\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ab9cc2c6a8d35d7a145cf608ff9dd7af87213253\",\"title\":\"RUBi: Reducing Unimodal Biases in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ab9cc2c6a8d35d7a145cf608ff9dd7af87213253\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2223252\",\"name\":\"Y. Zhou\"},{\"authorId\":\"1572139630\",\"name\":\"Rongrong Ji\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"1993645531\",\"name\":\"Gen Luo\"},{\"authorId\":\"46761465\",\"name\":\"Xiaopeng Hong\"},{\"authorId\":\"34739384\",\"name\":\"Jinsong Su\"},{\"authorId\":\"2713947\",\"name\":\"Xinghao Ding\"},{\"authorId\":\"40799321\",\"name\":\"Ling Shao\"}],\"doi\":\"10.1145/3394171.3413998\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"72687e467b4ab4d4799cca976013c5936ccb74b1\",\"title\":\"K-armed Bandit based Multi-Modal Network Architecture Search for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/72687e467b4ab4d4799cca976013c5936ccb74b1\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1806.01873\",\"authors\":[{\"authorId\":\"1915796\",\"name\":\"Junwei Liang\"},{\"authorId\":\"39978626\",\"name\":\"Lu Jiang\"},{\"authorId\":\"48749954\",\"name\":\"L. Cao\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1109/TPAMI.2018.2890628\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"aee265f6a19f9774c65d296cf9ec0e169365dda5\",\"title\":\"Focal Visual-Text Attention for Memex Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/aee265f6a19f9774c65d296cf9ec0e169365dda5\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":\"1903.00366\",\"authors\":[{\"authorId\":\"153677280\",\"name\":\"Robik Shrestha\"},{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1109/CVPR.2019.01072\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d9344534ab39544a3a3c173b27628e0d9c5d4dc5\",\"title\":\"Answer Them All! Toward Universal Visual Question Answering Models\",\"url\":\"https://www.semanticscholar.org/paper/d9344534ab39544a3a3c173b27628e0d9c5d4dc5\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1911.06258\",\"authors\":[{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"50286460\",\"name\":\"Amanpreet Singh\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.1109/cvpr42600.2020.01001\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4fc2eb1b494a29c7cb39da3b180a302521e459a0\",\"title\":\"Iterative Answer Prediction With Pointer-Augmented Multimodal Transformers for TextVQA\",\"url\":\"https://www.semanticscholar.org/paper/4fc2eb1b494a29c7cb39da3b180a302521e459a0\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1910.02509\",\"authors\":[{\"authorId\":\"31449728\",\"name\":\"T. Hayes\"},{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"153677280\",\"name\":\"Robik Shrestha\"},{\"authorId\":\"47309247\",\"name\":\"Manoj Acharya\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1007/978-3-030-58598-3_28\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f6c3e8b8e6d647ebb61833e9105d2147e472f534\",\"title\":\"REMIND Your Neural Network to Prevent Catastrophic Forgetting\",\"url\":\"https://www.semanticscholar.org/paper/f6c3e8b8e6d647ebb61833e9105d2147e472f534\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1907.12133\",\"authors\":[{\"authorId\":\"50445724\",\"name\":\"C. Zhang\"},{\"authorId\":\"150336480\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"113737386\",\"name\":\"D. Xuan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"55a881988f757ff6fdac74429e39cb5b46aa3f47\",\"title\":\"An Empirical Study on Leveraging Scene Graphs for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/55a881988f757ff6fdac74429e39cb5b46aa3f47\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"2012.02951\",\"authors\":[{\"authorId\":\"1935410\",\"name\":\"M. Rahnemoonfar\"},{\"authorId\":\"39734189\",\"name\":\"Tashnim J. S. Chowdhury\"},{\"authorId\":\"1381535116\",\"name\":\"Argho Sarkar\"},{\"authorId\":\"1411385478\",\"name\":\"D. Varshney\"},{\"authorId\":\"1505798397\",\"name\":\"Masoud Yari\"},{\"authorId\":\"1789429\",\"name\":\"R. Murphy\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"af2550268c34fb0376a3f18f150bf4f9ce3023b9\",\"title\":\"FloodNet: A High Resolution Aerial Imagery Dataset for Post Flood Scene Understanding\",\"url\":\"https://www.semanticscholar.org/paper/af2550268c34fb0376a3f18f150bf4f9ce3023b9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.06800\",\"authors\":[{\"authorId\":\"9208016\",\"name\":\"Aakansha Mishra\"},{\"authorId\":\"47583423\",\"name\":\"A. Anand\"},{\"authorId\":\"46401518\",\"name\":\"Prithwijit Guha\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206913\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"212c2d71f9f404bcbb3cfe8bc35e5e1ea25076c5\",\"title\":\"CQ-VQA: Visual Question Answering on Categorized Questions\",\"url\":\"https://www.semanticscholar.org/paper/212c2d71f9f404bcbb3cfe8bc35e5e1ea25076c5\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2846025\",\"name\":\"D. Yu\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"40434674\",\"name\":\"X. Tian\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1145/3316767\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b0ce44270916fd6e254fd9e75dd77ee1cf9f212a\",\"title\":\"Multi-source Multi-level Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b0ce44270916fd6e254fd9e75dd77ee1cf9f212a\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":\"1811.00491\",\"authors\":[{\"authorId\":\"32849969\",\"name\":\"Alane Suhr\"},{\"authorId\":\"49219517\",\"name\":\"Stephanie Zhou\"},{\"authorId\":\"78244694\",\"name\":\"Iris D. Zhang\"},{\"authorId\":\"14271134\",\"name\":\"Huajun Bai\"},{\"authorId\":\"3167681\",\"name\":\"Yoav Artzi\"}],\"doi\":\"10.18653/v1/P19-1644\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cf336d272a30d6ad6141db67faa64deb8791cd61\",\"title\":\"A Corpus for Reasoning About Natural Language Grounded in Photographs\",\"url\":\"https://www.semanticscholar.org/paper/cf336d272a30d6ad6141db67faa64deb8791cd61\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49597404\",\"name\":\"Z. Fang\"},{\"authorId\":null,\"name\":\"Jing Liu\"},{\"authorId\":\"80526284\",\"name\":\"Yanyuan Qiao\"},{\"authorId\":null,\"name\":\"Qu Tang\"},{\"authorId\":\"47002702\",\"name\":\"Y. Li\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1145/3240508.3240662\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a1f1a06b840558c4433f0e06a4e9172539469e21\",\"title\":\"Enhancing Visual Question Answering Using Dropout\",\"url\":\"https://www.semanticscholar.org/paper/a1f1a06b840558c4433f0e06a4e9172539469e21\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1455114388\",\"name\":\"Hrituraj Singh\"},{\"authorId\":\"35223379\",\"name\":\"Sumit Shekhar\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.264\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"baff151a5f1cb378d3627b88ff7d1b3afd29db45\",\"title\":\"STL-CQA: Structure-based Transformers with Localization and Encoding for Chart Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/baff151a5f1cb378d3627b88ff7d1b3afd29db45\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47860328\",\"name\":\"Shagun Uppal\"},{\"authorId\":\"73368394\",\"name\":\"Sarthak Bhagat\"},{\"authorId\":\"8223433\",\"name\":\"Devamanyu Hazarika\"},{\"authorId\":\"1999177921\",\"name\":\"Navonil Majumdar\"},{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"153015119\",\"name\":\"R. Zimmermann\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f23b548ff7b3517f028164a30c8bf186f11a1a6\",\"title\":\"Emerging Trends of Multimodal Research in Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/0f23b548ff7b3517f028164a30c8bf186f11a1a6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2001.03339\",\"authors\":[{\"authorId\":\"6937593\",\"name\":\"Shih-Han Chou\"},{\"authorId\":\"150336480\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"2268189\",\"name\":\"Wei-Sheng Lai\"},{\"authorId\":\"30885811\",\"name\":\"Min Sun\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8d27640ce75557156de13fb827b64446ef9cc0e4\",\"title\":\"Visual Question Answering on 360{\\\\deg} Images.\",\"url\":\"https://www.semanticscholar.org/paper/8d27640ce75557156de13fb827b64446ef9cc0e4\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1907.12271\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"145498821\",\"name\":\"P. Wang\"},{\"authorId\":\"39767248\",\"name\":\"Jiewei Cao\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1609/AAAI.V34I07.6885\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ed1dcc516162297bbab37aa64d920c87fcc77ca8\",\"title\":\"V-PROM: A Benchmark for Visual Reasoning Using Visual Progressive Matrices\",\"url\":\"https://www.semanticscholar.org/paper/ed1dcc516162297bbab37aa64d920c87fcc77ca8\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2004.05704\",\"authors\":[{\"authorId\":\"153677280\",\"name\":\"Robik Shrestha\"},{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.18653/v1/2020.acl-main.727\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2f4a012aa325cdee5a5c779fe2133e146616a5d5\",\"title\":\"A negative case analysis of visual grounding methods for VQA\",\"url\":\"https://www.semanticscholar.org/paper/2f4a012aa325cdee5a5c779fe2133e146616a5d5\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40474403\",\"name\":\"J. J. Lau\"},{\"authorId\":\"29948554\",\"name\":\"Soumya Gayen\"},{\"authorId\":\"2205800\",\"name\":\"Asma Ben Abacha\"},{\"authorId\":\"1398175407\",\"name\":\"Dina Demner-Fushman\"}],\"doi\":\"10.1038/sdata.2018.251\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"18f9a6045ba01cb079c4fa49a630d71bbd27cd92\",\"title\":\"A dataset of clinically generated visual questions and answers about radiology images\",\"url\":\"https://www.semanticscholar.org/paper/18f9a6045ba01cb079c4fa49a630d71bbd27cd92\",\"venue\":\"Scientific Data\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2420608\",\"name\":\"Difei Gao\"},{\"authorId\":\"3373117\",\"name\":\"R. Wang\"},{\"authorId\":\"144481158\",\"name\":\"S. Shan\"},{\"authorId\":\"51069511\",\"name\":\"X. Chen\"}],\"doi\":\"10.1109/JSTSP.2020.2989701\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5b3478e680e957672c4fbc8e1da559588997b325\",\"title\":\"Learning to Recognize Visual Concepts for Visual Question Answering With Structural Label Space\",\"url\":\"https://www.semanticscholar.org/paper/5b3478e680e957672c4fbc8e1da559588997b325\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152951058\",\"name\":\"Drew A. Hudson\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.1109/CVPR.2019.00686\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1ab7f7c1d328589f25c79515b9a5d824d7ffbbd1\",\"title\":\"GQA: A New Dataset for Real-World Visual Reasoning and Compositional Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1ab7f7c1d328589f25c79515b9a5d824d7ffbbd1\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1908.01801\",\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"153677280\",\"name\":\"Robik Shrestha\"},{\"authorId\":\"46328947\",\"name\":\"B. Price\"},{\"authorId\":\"145823372\",\"name\":\"S. Cohen\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1109/WACV45572.2020.9093494\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f59ae732612ce8c42035adfb47bd5739c6288ad6\",\"title\":\"Answering Questions about Data Visualizations using Efficient Bimodal Fusion\",\"url\":\"https://www.semanticscholar.org/paper/f59ae732612ce8c42035adfb47bd5739c6288ad6\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"2004.05595\",\"authors\":[{\"authorId\":\"1576818877\",\"name\":\"Kento Terao\"},{\"authorId\":\"47668008\",\"name\":\"T. Tamaki\"},{\"authorId\":\"1688940\",\"name\":\"B. Raytchev\"},{\"authorId\":\"1686272\",\"name\":\"K. Kaneda\"},{\"authorId\":\"49969107\",\"name\":\"S. Satoh\"}],\"doi\":\"10.1109/ACCESS.2020.3022063\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"217d80b1425c24996dafbe539a1e976a1e790ac0\",\"title\":\"Which visual questions are difficult to answer? Analysis with Entropy of Answer Distributions\",\"url\":\"https://www.semanticscholar.org/paper/217d80b1425c24996dafbe539a1e976a1e790ac0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50829868\",\"name\":\"A. Testoni\"},{\"authorId\":\"152741757\",\"name\":\"C. Greco\"},{\"authorId\":\"2008204693\",\"name\":\"Tobias Bianchi\"},{\"authorId\":\"1805994601\",\"name\":\"Mauricio Mazuecos\"},{\"authorId\":\"2008198429\",\"name\":\"Agata Marcante\"},{\"authorId\":\"3131683\",\"name\":\"Luciana Benotti\"},{\"authorId\":\"145040726\",\"name\":\"R. Bernardi\"}],\"doi\":\"10.18653/v1/2020.splu-1.4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a864a6c1046523aed2b8565ccc2c55f7279a4c61\",\"title\":\"They are not all alike: answering different spatial questions requires different grounding strategies\",\"url\":\"https://www.semanticscholar.org/paper/a864a6c1046523aed2b8565ccc2c55f7279a4c61\",\"venue\":\"SPLU\",\"year\":2020},{\"arxivId\":\"2006.10079\",\"authors\":[{\"authorId\":\"41020827\",\"name\":\"Corentin Dancette\"},{\"authorId\":\"7535126\",\"name\":\"R\\u00e9mi Cad\\u00e8ne\"},{\"authorId\":\"1606041624\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b5cb23c3c09bcd9f0e12a864b9f4ac3fa0f2dfbd\",\"title\":\"Overcoming Statistical Shortcuts for Open-ended Visual Counting\",\"url\":\"https://www.semanticscholar.org/paper/b5cb23c3c09bcd9f0e12a864b9f4ac3fa0f2dfbd\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.13406\",\"authors\":[{\"authorId\":\"153188991\",\"name\":\"Spencer Whitehead\"},{\"authorId\":\"97671685\",\"name\":\"H. Wu\"},{\"authorId\":\"51135899\",\"name\":\"Yi Ren Fung\"},{\"authorId\":\"153172090\",\"name\":\"Huai-zhong Ji\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1904c5389a70a905019d5429f09bc7f669bdc898\",\"title\":\"Learning from Lexical Perturbations for Consistent Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1904c5389a70a905019d5429f09bc7f669bdc898\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.02356\",\"authors\":[{\"authorId\":\"120722271\",\"name\":\"Pratyay Banerjee\"},{\"authorId\":\"120838645\",\"name\":\"Tejas Gokhale\"},{\"authorId\":\"1784500\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"1760291\",\"name\":\"Chitta Baral\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"72be4e0750cf5591d527d7792aa861353526e311\",\"title\":\"Self-Supervised VQA: Answering Visual Questions using Images and Captions\",\"url\":\"https://www.semanticscholar.org/paper/72be4e0750cf5591d527d7792aa861353526e311\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1904.02794\",\"authors\":[{\"authorId\":\"47309247\",\"name\":\"Manoj Acharya\"},{\"authorId\":\"93155387\",\"name\":\"Karan Jariwala\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.18653/v1/N19-1194\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f17f7590a6b4488921f046112bc8fdb82d513914\",\"title\":\"VQD: Visual Query Detection in Natural Scenes\",\"url\":\"https://www.semanticscholar.org/paper/f17f7590a6b4488921f046112bc8fdb82d513914\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46700331\",\"name\":\"J. Liu\"},{\"authorId\":\"10405058\",\"name\":\"Chenfei Wu\"},{\"authorId\":\"39527132\",\"name\":\"Xiaojie Wang\"},{\"authorId\":\"143672034\",\"name\":\"X. Dong\"}],\"doi\":\"10.1109/CCIS.2018.8691361\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e074ccab7b7c46b48d643c1026e71e563878885f\",\"title\":\"Sequential Visual Reasoning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e074ccab7b7c46b48d643c1026e71e563878885f\",\"venue\":\"2018 5th IEEE International Conference on Cloud Computing and Intelligence Systems (CCIS)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40055538\",\"name\":\"C. Yang\"},{\"authorId\":\"144889898\",\"name\":\"Mengqi Jiang\"},{\"authorId\":\"144069314\",\"name\":\"Bin Jiang\"},{\"authorId\":\"46351963\",\"name\":\"Weixin Zhou\"},{\"authorId\":\"2181606\",\"name\":\"K. Li\"}],\"doi\":\"10.1109/ACCESS.2019.2908035\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f0734fd670605a578b9e4b908e58b63e4142625e\",\"title\":\"Co-Attention Network With Question Type for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f0734fd670605a578b9e4b908e58b63e4142625e\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1909.11874\",\"authors\":[{\"authorId\":\"52220768\",\"name\":\"T. Do\"},{\"authorId\":\"3354627\",\"name\":\"Thanh-Toan Do\"},{\"authorId\":\"134083550\",\"name\":\"Huy Tran\"},{\"authorId\":\"1387964524\",\"name\":\"Erman Tjiputra\"},{\"authorId\":\"20135953\",\"name\":\"Q. D. Tran\"}],\"doi\":\"10.1109/ICCV.2019.00048\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"27cb0b42e0573c4891ae2ca444776dee57bfe2ac\",\"title\":\"Compact Trilinear Interaction for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/27cb0b42e0573c4891ae2ca444776dee57bfe2ac\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2944294\",\"name\":\"A. Gupta\"},{\"authorId\":\"36045956\",\"name\":\"P. J. Harrison\"},{\"authorId\":\"35604800\",\"name\":\"H\\u00e5kan Wieslander\"},{\"authorId\":\"52325058\",\"name\":\"Nicolas Pielawski\"},{\"authorId\":\"2824435\",\"name\":\"Kimmo Kartasalo\"},{\"authorId\":\"10994793\",\"name\":\"Gabriele Partel\"},{\"authorId\":\"40519546\",\"name\":\"Leslie Solorzano\"},{\"authorId\":\"2010965\",\"name\":\"Amit Suveer\"},{\"authorId\":\"5126805\",\"name\":\"Anna H Klemm\"},{\"authorId\":\"1776762\",\"name\":\"Ola Spjuth\"},{\"authorId\":\"2489478\",\"name\":\"Ida-Maria Sintorn\"},{\"authorId\":\"1705606\",\"name\":\"Carolina W\\u00e4hlby\"}],\"doi\":\"10.1002/cyto.a.23701\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9da1613dc792a36939cdb606c6846c5da99e8f59\",\"title\":\"Deep Learning in Image Cytometry: A Review\",\"url\":\"https://www.semanticscholar.org/paper/9da1613dc792a36939cdb606c6846c5da99e8f59\",\"venue\":\"Cytometry. Part A : the journal of the International Society for Analytical Cytology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"7595427\",\"name\":\"Tejas Khot\"},{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1007/s11263-018-1116-0\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7e232313a59d735ef7c8a9f4cc7bc980a29deb5e\",\"title\":\"Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7e232313a59d735ef7c8a9f4cc7bc980a29deb5e\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018},{\"arxivId\":\"1806.03726\",\"authors\":[{\"authorId\":\"38784892\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"}],\"doi\":\"10.1109/CVPR.2018.00599\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1bfc74bad04b407d1792a70d73a3f5dc0be0506d\",\"title\":\"Cross-Dataset Adaptation for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1bfc74bad04b407d1792a70d73a3f5dc0be0506d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10405058\",\"name\":\"Chenfei Wu\"},{\"authorId\":\"46700331\",\"name\":\"J. Liu\"},{\"authorId\":\"38542466\",\"name\":\"X. Wang\"},{\"authorId\":\"143672034\",\"name\":\"X. Dong\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"184002001b3b514f432e538f872aebce3c7db060\",\"title\":\"Chain of Reasoning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/184002001b3b514f432e538f872aebce3c7db060\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"2007.06198\",\"authors\":[{\"authorId\":\"9748140\",\"name\":\"K. Gouthaman\"},{\"authorId\":\"50853059\",\"name\":\"Anurag Mittal\"}],\"doi\":\"10.1007/978-3-030-58601-0_2\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"06b869a92a22db711e4fbe8b141c83523c7c4604\",\"title\":\"Reducing Language Biases in Visual Question Answering with Visually-Grounded Question Encoder\",\"url\":\"https://www.semanticscholar.org/paper/06b869a92a22db711e4fbe8b141c83523c7c4604\",\"venue\":\"ECCV\",\"year\":2020}],\"corpusId\":18050299,\"doi\":\"10.1109/ICCV.2017.217\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":13,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"915b5b12f9bdebc321e970ecd713458c3479d70e\",\"references\":[{\"arxivId\":\"1512.02167\",\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"39402399\",\"name\":\"Yuandong Tian\"},{\"authorId\":\"2265067\",\"name\":\"Sainbayar Sukhbaatar\"},{\"authorId\":\"3149531\",\"name\":\"Arthur Szlam\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"267fb4ac632449dbe84f7acf17c8c7527cb25b0d\",\"title\":\"Simple Baseline for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/267fb4ac632449dbe84f7acf17c8c7527cb25b0d\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1606.06108\",\"authors\":[{\"authorId\":\"2652444\",\"name\":\"K. Saito\"},{\"authorId\":\"145568592\",\"name\":\"Andrew Shin\"},{\"authorId\":\"3250559\",\"name\":\"Y. Ushiku\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.1109/ICME.2017.8019436\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"121a9a160f1f2819a01edbe522024b58dbfee798\",\"title\":\"DualNet: Domain-invariant network for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/121a9a160f1f2819a01edbe522024b58dbfee798\",\"venue\":\"2017 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2017},{\"arxivId\":\"1610.01465\",\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1016/j.cviu.2017.06.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6d92ce1c4f7f0ccfe068e663903e4dd614a15ede\",\"title\":\"Visual question answering: Datasets, algorithms, and future challenges\",\"url\":\"https://www.semanticscholar.org/paper/6d92ce1c4f7f0ccfe068e663903e4dd614a15ede\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":\"1511.07394\",\"authors\":[{\"authorId\":\"143953573\",\"name\":\"K. Shih\"},{\"authorId\":\"37415643\",\"name\":\"S. Singh\"},{\"authorId\":\"2433269\",\"name\":\"Derek Hoiem\"}],\"doi\":\"10.1109/CVPR.2016.499\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"175e9bb50cc062c6c1742a5d90c8dfe31d2e4e22\",\"title\":\"Where to Look: Focus Regions for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/175e9bb50cc062c6c1742a5d90c8dfe31d2e4e22\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1505.00468\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-016-0966-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"title\":\"VQA: Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1606.01455\",\"authors\":[{\"authorId\":\"2684967\",\"name\":\"J. Kim\"},{\"authorId\":\"3226948\",\"name\":\"Sang-Woo Lee\"},{\"authorId\":\"3422869\",\"name\":\"Dong-Hyun Kwak\"},{\"authorId\":\"2939188\",\"name\":\"Min-Oh Heo\"},{\"authorId\":\"2947441\",\"name\":\"J. Kim\"},{\"authorId\":\"2577039\",\"name\":\"Jung-Woo Ha\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1afb710a5b35a2352a6495e4bf6eef66808daf1b\",\"title\":\"Multimodal Residual Learning for Visual QA\",\"url\":\"https://www.semanticscholar.org/paper/1afb710a5b35a2352a6495e4bf6eef66808daf1b\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1511.05234\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1007/978-3-319-46478-7_28\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1cf6bc0866226c1f8e282463adc8b75d92fba9bb\",\"title\":\"Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1cf6bc0866226c1f8e282463adc8b75d92fba9bb\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1606.01847\",\"authors\":[{\"authorId\":\"50599725\",\"name\":\"A. Fukui\"},{\"authorId\":\"3422202\",\"name\":\"Dong Huk Park\"},{\"authorId\":\"3422876\",\"name\":\"Daylen Yang\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.18653/v1/D16-1044\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fddc15480d086629b960be5bff96232f967f2252\",\"title\":\"Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/fddc15480d086629b960be5bff96232f967f2252\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":\"1612.06890\",\"authors\":[{\"authorId\":\"153365679\",\"name\":\"J. Johnson\"},{\"authorId\":\"73710317\",\"name\":\"B. Hariharan\"},{\"authorId\":\"35341401\",\"name\":\"Laurens van der Maaten\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/CVPR.2017.215\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"03eb382e04cca8cca743f7799070869954f1402a\",\"title\":\"CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/03eb382e04cca8cca743f7799070869954f1402a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"38666915\",\"name\":\"D. Klein\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0ac8f1a3c679b90d22c1f840cdc8d61ffef750ac\",\"title\":\"Deep Compositional Question Answering with Neural Module Networks\",\"url\":\"https://www.semanticscholar.org/paper/0ac8f1a3c679b90d22c1f840cdc8d61ffef750ac\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1603.01417\",\"authors\":[{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"3375440\",\"name\":\"Stephen Merity\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f96898d15a1bf1fa8925b1280d0e07a7a8e72194\",\"title\":\"Dynamic Memory Networks for Visual and Textual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f96898d15a1bf1fa8925b1280d0e07a7a8e72194\",\"venue\":\"ICML\",\"year\":2016},{\"arxivId\":\"1511.03416\",\"authors\":[{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"50499889\",\"name\":\"O. Groth\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2016.540\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"def584565d05d6a8ba94de6621adab9e301d375d\",\"title\":\"Visual7W: Grounded Question Answering in Images\",\"url\":\"https://www.semanticscholar.org/paper/def584565d05d6a8ba94de6621adab9e301d375d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1606.03647\",\"authors\":[{\"authorId\":\"2018393\",\"name\":\"Hyeonwoo Noh\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b58e08741fb9803fa2a870eee139137d3bade332\",\"title\":\"Training Recurrent Answering Units with Joint Loss Minimization for VQA\",\"url\":\"https://www.semanticscholar.org/paper/b58e08741fb9803fa2a870eee139137d3bade332\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1606.08390\",\"authors\":[{\"authorId\":\"14258597\",\"name\":\"A. Jabri\"},{\"authorId\":\"2319608\",\"name\":\"Armand Joulin\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"}],\"doi\":\"10.1007/978-3-319-46484-8_44\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3c1bbd2672c11a796f1e6e6aa787257498ec8bec\",\"title\":\"Revisiting Visual Question Answering Baselines\",\"url\":\"https://www.semanticscholar.org/paper/3c1bbd2672c11a796f1e6e6aa787257498ec8bec\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1511.05099\",\"authors\":[{\"authorId\":\"40409467\",\"name\":\"P. Zhang\"},{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2016.542\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5fa973b8d284145bf0ced9acf2913a74674260f6\",\"title\":\"Yin and Yang: Balancing and Answering Binary Visual Questions\",\"url\":\"https://www.semanticscholar.org/paper/5fa973b8d284145bf0ced9acf2913a74674260f6\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1505.02074\",\"authors\":[{\"authorId\":\"2540599\",\"name\":\"Mengye Ren\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"62a956d7600b10ca455076cd56e604dfd106072a\",\"title\":\"Exploring Models and Data for Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/62a956d7600b10ca455076cd56e604dfd106072a\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1606.00061\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"145743311\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b\",\"title\":\"Hierarchical Question-Image Co-Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1410.0210\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ac64fb7e6d2ddf236332ec9f371fe85d308c114d\",\"title\":\"A Multi-World Approach to Question Answering about Real-World Scenes based on Uncertain Input\",\"url\":\"https://www.semanticscholar.org/paper/ac64fb7e6d2ddf236332ec9f371fe85d308c114d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1607.05910\",\"authors\":[{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1016/j.cviu.2017.05.001\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"88c307c51594c6d802080a0780d0d654e2e2891f\",\"title\":\"Visual question answering: A survey of methods and datasets\",\"url\":\"https://www.semanticscholar.org/paper/88c307c51594c6d802080a0780d0d654e2e2891f\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":\"1505.05612\",\"authors\":[{\"authorId\":\"2345388\",\"name\":\"Haoyuan Gao\"},{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":null,\"name\":\"Jie Zhou\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":null,\"name\":\"Lei Wang\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2fcd5cff2b4743ea640c4af68bf4143f4a2cccb1\",\"title\":\"Are You Talking to a Machine? Dataset and Methods for Multilingual Image Question\",\"url\":\"https://www.semanticscholar.org/paper/2fcd5cff2b4743ea640c4af68bf4143f4a2cccb1\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1511.05676\",\"authors\":[{\"authorId\":\"3335651\",\"name\":\"Aiwen Jiang\"},{\"authorId\":\"7572514\",\"name\":\"Fang Wang\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"},{\"authorId\":\"47001807\",\"name\":\"Y. Li\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3d1382fa43c31e594ed2d84dda9984b1db047b0e\",\"title\":\"Compositional Memory for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/3d1382fa43c31e594ed2d84dda9984b1db047b0e\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1604.01485\",\"authors\":[{\"authorId\":\"3393294\",\"name\":\"Ilija Ilievski\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7214daf035ab005b3d1e739750dd597b4f4513fa\",\"title\":\"A Focused Dynamic Attention Model for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7214daf035ab005b3d1e739750dd597b4f4513fa\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1601.01705\",\"authors\":[{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"38666915\",\"name\":\"D. Klein\"}],\"doi\":\"10.18653/v1/N16-1181\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"75ddc7ee15be14013a3462c01b38b0548486fbcb\",\"title\":\"Learning to Compose Neural Networks for Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/75ddc7ee15be14013a3462c01b38b0548486fbcb\",\"venue\":\"HLT-NAACL\",\"year\":2016},{\"arxivId\":\"1602.07332\",\"authors\":[{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"50499889\",\"name\":\"O. Groth\"},{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"1382195702\",\"name\":\"Kenji Hata\"},{\"authorId\":\"40591424\",\"name\":\"J. Kravitz\"},{\"authorId\":\"6000646\",\"name\":\"Stephanie Chen\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"1388344504\",\"name\":\"David A. Shamma\"},{\"authorId\":\"1379506718\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-016-0981-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"title\":\"Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations\",\"url\":\"https://www.semanticscholar.org/paper/afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"}],\"doi\":\"10.1109/TPAMI.2006.79\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"812355cec91fa30bb50e9e992a3549af39e4f6eb\",\"title\":\"One-shot learning of object categories\",\"url\":\"https://www.semanticscholar.org/paper/812355cec91fa30bb50e9e992a3549af39e4f6eb\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2006},{\"arxivId\":\"1511.05756\",\"authors\":[{\"authorId\":\"2018393\",\"name\":\"Hyeonwoo Noh\"},{\"authorId\":\"14454974\",\"name\":\"P. H. Seo\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":\"10.1109/CVPR.2016.11\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"385c18cc4024a3b3206c508c512e037b9c00b8f3\",\"title\":\"Image Question Answering Using Convolutional Neural Network with Dynamic Parameter Prediction\",\"url\":\"https://www.semanticscholar.org/paper/385c18cc4024a3b3206c508c512e037b9c00b8f3\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1109/CVPR.2016.538\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ebe5081b8a24b4740db929b6eae75f28f8edbc58\",\"title\":\"Answer-Type Prediction for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ebe5081b8a24b4740db929b6eae75f28f8edbc58\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1612.00837\",\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"7595427\",\"name\":\"Tejas Khot\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2017.670\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"title\":\"Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1506.06726\",\"authors\":[{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"2214033\",\"name\":\"Y. Zhu\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6e795c6e9916174ae12349f5dc3f516570c17ce8\",\"title\":\"Skip-Thought Vectors\",\"url\":\"https://www.semanticscholar.org/paper/6e795c6e9916174ae12349f5dc3f516570c17ce8\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"3407352\",\"name\":\"Mohammed A. Yousefhussien\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.18653/v1/W17-3529\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7e4b638e028498e900747b600f46cd723f1f231e\",\"title\":\"Data Augmentation for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7e4b638e028498e900747b600f46cd723f1f231e\",\"venue\":\"INLG\",\"year\":2017},{\"arxivId\":\"1505.01121\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":\"10.1109/ICCV.2015.9\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bd7bd1d2945a58cdcc1797ba9698b8810fe68f60\",\"title\":\"Ask Your Neurons: A Neural-Based Approach to Answering Questions about Images\",\"url\":\"https://www.semanticscholar.org/paper/bd7bd1d2945a58cdcc1797ba9698b8810fe68f60\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1511.06973\",\"authors\":[{\"authorId\":\"34902783\",\"name\":\"Qi Wu\"},{\"authorId\":\"48319305\",\"name\":\"P. Wang\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2016.500\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"20dbdf02497aa84510970d0f5e8b599073bca1bc\",\"title\":\"Ask Me Anything: Free-Form Visual Question Answering Based on Knowledge from External Sources\",\"url\":\"https://www.semanticscholar.org/paper/20dbdf02497aa84510970d0f5e8b599073bca1bc\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1511.02274\",\"authors\":[{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"46234526\",\"name\":\"Alex Smola\"}],\"doi\":\"10.1109/CVPR.2016.10\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c1890864c1c2b750f48316dc8b650ba4772adc5\",\"title\":\"Stacked Attention Networks for Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2c1890864c1c2b750f48316dc8b650ba4772adc5\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016}],\"title\":\"An Analysis of Visual Question Answering Algorithms\",\"topics\":[{\"topic\":\"Question answering\",\"topicId\":\"18817\",\"url\":\"https://www.semanticscholar.org/topic/18817\"},{\"topic\":\"Algorithm\",\"topicId\":\"305\",\"url\":\"https://www.semanticscholar.org/topic/305\"},{\"topic\":\"Text-based (computing)\",\"topicId\":\"75487\",\"url\":\"https://www.semanticscholar.org/topic/75487\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Baseline (configuration management)\",\"topicId\":\"3403\",\"url\":\"https://www.semanticscholar.org/topic/3403\"},{\"topic\":\"Modal logic\",\"topicId\":\"61528\",\"url\":\"https://www.semanticscholar.org/topic/61528\"},{\"topic\":\"Bilinear filtering\",\"topicId\":\"1123309\",\"url\":\"https://www.semanticscholar.org/topic/1123309\"},{\"topic\":\"Memory-level parallelism\",\"topicId\":\"249591\",\"url\":\"https://www.semanticscholar.org/topic/249591\"}],\"url\":\"https://www.semanticscholar.org/paper/915b5b12f9bdebc321e970ecd713458c3479d70e\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017}\n"