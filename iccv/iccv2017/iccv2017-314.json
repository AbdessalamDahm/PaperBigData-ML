"{\"abstract\":\"Despite the substantial progress in recent years, the image captioning techniques are still far from being perfect. Sentences produced by existing methods, e.g. those based on RNNs, are often overly rigid and lacking in variability. This issue is related to a learning principle widely used in practice, that is, to maximize the likelihood of training samples. This principle encourages high resemblance to the \\u201cground-truth\\u201d captions, while suppressing other reasonable descriptions. Conventional evaluation metrics, e.g. BLEU and METEOR, also favor such restrictive methods. In this paper, we explore an alternative approach, with the aim to improve the naturalness and diversity \\u2013 two essential properties of human expression. Specifically, we propose a new framework based on Conditional Generative Adversarial Networks (CGAN), which jointly learns a generator to produce descriptions conditioned on images and an evaluator to assess how well a description fits the visual content. It is noteworthy that training a sequence generator is nontrivial. We overcome the difficulty by Policy Gradient, a strategy stemming from Reinforcement Learning, which allows the generator to receive early feedback along the way. We tested our method on two large datasets, where it performed competitively against real people in our user study and outperformed other methods on various tasks.\",\"arxivId\":\"1703.06029\",\"authors\":[{\"authorId\":\"144445937\",\"name\":\"Bo Dai\",\"url\":\"https://www.semanticscholar.org/author/144445937\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\",\"url\":\"https://www.semanticscholar.org/author/37895334\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\",\"url\":\"https://www.semanticscholar.org/author/2422559\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\",\"url\":\"https://www.semanticscholar.org/author/1807606\"}],\"citationVelocity\":80,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"48569838\",\"name\":\"Xiangyang Li\"},{\"authorId\":\"1696610\",\"name\":\"S. Jiang\"}],\"doi\":\"10.1109/TMM.2019.2896516\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bc73f0f7d895a089416bc8f6090f3f8707c6a12f\",\"title\":\"Know More Say Less: Image Captioning Based on Scene Graphs\",\"url\":\"https://www.semanticscholar.org/paper/bc73f0f7d895a089416bc8f6090f3f8707c6a12f\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1380953427\",\"name\":\"Sharan Pai\"},{\"authorId\":\"6405002\",\"name\":\"Nikhil Sachdeva\"},{\"authorId\":\"153842846\",\"name\":\"R. Shah\"},{\"authorId\":\"153015119\",\"name\":\"R. Zimmermann\"}],\"doi\":\"10.1109/BigMM.2019.00-41\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c471ce066b218416446babb039bcff22f0e2dfb0\",\"title\":\"User Input Based Style Transfer While Retaining Facial Attributes\",\"url\":\"https://www.semanticscholar.org/paper/c471ce066b218416446babb039bcff22f0e2dfb0\",\"venue\":\"2019 IEEE Fifth International Conference on Multimedia Big Data (BigMM)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1564574213\",\"name\":\"Hasitha Hiran Walpola\"},{\"authorId\":\"51938252\",\"name\":\"Guhanathan Poravi\"}],\"doi\":\"10.1109/I2CT45611.2019.9033956\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9a4d3a6fefdfb542883d0138f0a9a4c34079dfbf\",\"title\":\"Front End Development Automation Tool: Missing Features?\",\"url\":\"https://www.semanticscholar.org/paper/9a4d3a6fefdfb542883d0138f0a9a4c34079dfbf\",\"venue\":\"2019 IEEE 5th International Conference for Convergence in Technology (I2CT)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134680082\",\"name\":\"Raimonda Stani\\u016bt\\u0117\"},{\"authorId\":\"1990294\",\"name\":\"D. Sesok\"}],\"doi\":\"10.3390/APP9102024\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"92ccf5a39c63cb5e1639be518e6db2e357acd58e\",\"title\":\"A Systematic Literature Review on Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/92ccf5a39c63cb5e1639be518e6db2e357acd58e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1812.05634\",\"authors\":[{\"authorId\":\"46979645\",\"name\":\"J. Park\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"}],\"doi\":\"10.1109/CVPR.2019.00676\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6aa6932c22b9bd407e615ec2bfffc20cd88a9069\",\"title\":\"Adversarial Inference for Multi-Sentence Video Description\",\"url\":\"https://www.semanticscholar.org/paper/6aa6932c22b9bd407e615ec2bfffc20cd88a9069\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3192572\",\"name\":\"Emiel van Miltenburg\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"1791713\",\"name\":\"Piek T. J. M. Vossen\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fe400b814cfea5538887c92040f1ab0d6fb45bfe\",\"title\":\"Measuring the Diversity of Automatic Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/fe400b814cfea5538887c92040f1ab0d6fb45bfe\",\"venue\":\"COLING\",\"year\":2018},{\"arxivId\":\"2002.01775\",\"authors\":[{\"authorId\":\"145939018\",\"name\":\"Inseop Chung\"},{\"authorId\":\"35869519\",\"name\":\"Seonguk Park\"},{\"authorId\":\"49476045\",\"name\":\"J. Kim\"},{\"authorId\":\"71494716\",\"name\":\"Nojun Kwak\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0e488f4f83303868b9fa9f807c4ad5c703fd7d61\",\"title\":\"Feature-map-level Online Adversarial Knowledge Distillation\",\"url\":\"https://www.semanticscholar.org/paper/0e488f4f83303868b9fa9f807c4ad5c703fd7d61\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":\"2003.10925\",\"authors\":[{\"authorId\":\"47577022\",\"name\":\"Nannan Li\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"16025ed0f452e62514d4705b7da1e9f78067d9e7\",\"title\":\"Learning Compact Reward for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/16025ed0f452e62514d4705b7da1e9f78067d9e7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1392406002\",\"name\":\"Arturs Polis\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4bfeae734bced5b2613af9f7d8271354b614e08e\",\"title\":\"Paragraph-length image captioning using hierarchical recurrent neural networks\",\"url\":\"https://www.semanticscholar.org/paper/4bfeae734bced5b2613af9f7d8271354b614e08e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1908.07810\",\"authors\":[{\"authorId\":\"50118263\",\"name\":\"Yike Wu\"},{\"authorId\":\"2516425\",\"name\":\"Shiwan Zhao\"},{\"authorId\":\"49252656\",\"name\":\"Jia Chen\"},{\"authorId\":\"48379958\",\"name\":\"Ying Zhang\"},{\"authorId\":\"1721029\",\"name\":\"Xiaojie Yuan\"},{\"authorId\":\"1703625\",\"name\":\"Zhong Su\"}],\"doi\":\"10.1109/ICME.2019.00070\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d4b29b999bc2d907d6d01ad30829058721d29394\",\"title\":\"Improving Captioning for Low-Resource Languages by Cycle Consistency\",\"url\":\"https://www.semanticscholar.org/paper/d4b29b999bc2d907d6d01ad30829058721d29394\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":\"1912.02470\",\"authors\":[{\"authorId\":\"39024334\",\"name\":\"Hao Chen\"},{\"authorId\":\"3393888\",\"name\":\"M. Giuffrida\"},{\"authorId\":\"4553782\",\"name\":\"P. Doerner\"},{\"authorId\":\"1919157\",\"name\":\"S. Tsaftaris\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1973c8f6d0fbc145f8301d6a230d19bd2303dcb7\",\"title\":\"Blind Inpainting of Large-scale Masks of Thin Structures with Adversarial and Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/1973c8f6d0fbc145f8301d6a230d19bd2303dcb7\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1809.06214\",\"authors\":[{\"authorId\":null,\"name\":\"Cheng Kuan Chen\"},{\"authorId\":\"1383271298\",\"name\":\"Zhufeng Pan\"},{\"authorId\":\"30885811\",\"name\":\"Min Sun\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"}],\"doi\":\"10.1609/AAAI.V33I01.33018151\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5e79138fd656ebea59eb008fcb97c97be7be8007\",\"title\":\"Unsupervised Stylish Image Description Generation via Domain Layer Norm\",\"url\":\"https://www.semanticscholar.org/paper/5e79138fd656ebea59eb008fcb97c97be7be8007\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47260649\",\"name\":\"Imran Sheikh\"},{\"authorId\":\"1791335\",\"name\":\"Rupayan Chakraborty\"},{\"authorId\":\"1809276\",\"name\":\"Sunil Kumar Kopparapu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c7f8ccccda67a44503b4c4e0611f38451a334cc2\",\"title\":\"Audio-Visual Fusion for Sentiment Classification using Cross-Modal Autoencoder\",\"url\":\"https://www.semanticscholar.org/paper/c7f8ccccda67a44503b4c4e0611f38451a334cc2\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2008.07291\",\"authors\":[{\"authorId\":\"8804828\",\"name\":\"M. Schlichtkrull\"},{\"authorId\":\"145832570\",\"name\":\"Weiwei Cheng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fe32763982114412b6ad22dcadaac896904e982a\",\"title\":\"Evaluating for Diversity in Question Generation over Text\",\"url\":\"https://www.semanticscholar.org/paper/fe32763982114412b6ad22dcadaac896904e982a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1801.05551\",\"authors\":[{\"authorId\":\"9541177\",\"name\":\"Navaneeth Bodla\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\"},{\"authorId\":\"9215658\",\"name\":\"R. Chellappa\"}],\"doi\":\"10.1007/978-3-030-01228-1_41\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2727927c7493cef9785b3a06a38f5c1ce126fc23\",\"title\":\"Semi-supervised FusedGAN for Conditional Image Generation\",\"url\":\"https://www.semanticscholar.org/paper/2727927c7493cef9785b3a06a38f5c1ce126fc23\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151017519\",\"name\":\"Gilad Vered\"},{\"authorId\":\"151504666\",\"name\":\"Gal Oren\"},{\"authorId\":\"34815079\",\"name\":\"Y. Atzmon\"},{\"authorId\":\"1732280\",\"name\":\"Gal Chechik\"}],\"doi\":\"10.1109/ICCV.2019.00899\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6fb03dcb0d57eb74d3395e598ae1712e3e926ec2\",\"title\":\"Joint Optimization for Cooperative Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6fb03dcb0d57eb74d3395e598ae1712e3e926ec2\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"15281603\",\"name\":\"Zerui Chen\"},{\"authorId\":\"144368930\",\"name\":\"Yan Huang\"},{\"authorId\":\"144143336\",\"name\":\"Liang Wang\"}],\"doi\":\"10.1109/ICIP.2019.8802975\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"66ec6ec4ced51e24e4a3b26246237dfe3ee689a5\",\"title\":\"Augmented Visual-Semantic Embeddings for Image and Sentence Matching\",\"url\":\"https://www.semanticscholar.org/paper/66ec6ec4ced51e24e4a3b26246237dfe3ee689a5\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"1911.00147\",\"authors\":[{\"authorId\":\"153650159\",\"name\":\"C. Thomas\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c8922345e2aaf4e4a88cf2c2e91b8545ef54c6d2\",\"title\":\"Predicting the Politics of an Image Using Webly Supervised Data\",\"url\":\"https://www.semanticscholar.org/paper/c8922345e2aaf4e4a88cf2c2e91b8545ef54c6d2\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38314306\",\"name\":\"Rakshith Shetty\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1109/ICCV.2017.398\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7fac20f3908c69bd336ea252e28c79f5abaa6dbe\",\"title\":\"Speaking the Same Language: Matching Machine to Human Captions by Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/7fac20f3908c69bd336ea252e28c79f5abaa6dbe\",\"venue\":\"ICCV 2017\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"42afa9a0166eeb45cb2e9b37e0a8eec482f78fe0\",\"title\":\"Visual Question Answering and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/42afa9a0166eeb45cb2e9b37e0a8eec482f78fe0\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1810.05795\",\"authors\":[{\"authorId\":\"2088535\",\"name\":\"C. Li\"},{\"authorId\":\"1771307\",\"name\":\"M. Zaheer\"},{\"authorId\":\"49890108\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1719347\",\"name\":\"B. P\\u00f3czos\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"170e2f4778f975768aaa5e888349fc0cb23d576f\",\"title\":\"Point Cloud GAN\",\"url\":\"https://www.semanticscholar.org/paper/170e2f4778f975768aaa5e888349fc0cb23d576f\",\"venue\":\"DGS@ICLR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2319973\",\"name\":\"Po-Yao Huang\"},{\"authorId\":\"144950946\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"},{\"authorId\":\"144547315\",\"name\":\"E. Hovy\"}],\"doi\":\"10.1145/3372278.3390674\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4d5018c8bdf61129ca06a333ddbbe32dd84e50c2\",\"title\":\"Forward and Backward Multimodal NMT for Improved Monolingual and Multilingual Cross-Modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/4d5018c8bdf61129ca06a333ddbbe32dd84e50c2\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":\"1809.05972\",\"authors\":[{\"authorId\":\"3272356\",\"name\":\"Yizhe Zhang\"},{\"authorId\":\"1947267\",\"name\":\"Michel Galley\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"40286474\",\"name\":\"Xiujun Li\"},{\"authorId\":\"3125776\",\"name\":\"Chris Brockett\"},{\"authorId\":\"83415753\",\"name\":\"W. Dolan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e79fbc3974827f3ea43a690221cd95fddefb7019\",\"title\":\"Generating Informative and Diverse Conversational Responses via Adversarial Information Maximization\",\"url\":\"https://www.semanticscholar.org/paper/e79fbc3974827f3ea43a690221cd95fddefb7019\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2038515405\",\"name\":\"Yazid Bounab\"},{\"authorId\":\"1471224685\",\"name\":\"Mourad Oussalah\"},{\"authorId\":\"2038543683\",\"name\":\"Ahlam Ferdenache\"}],\"doi\":\"10.1109/IPTA50016.2020.9286602\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"12246cc5d29c1d8d7177d7a6e820fe3038ccd1d5\",\"title\":\"Reconciling Image Captioning and User\\u2019s Comments for Urban Tourism\",\"url\":\"https://www.semanticscholar.org/paper/12246cc5d29c1d8d7177d7a6e820fe3038ccd1d5\",\"venue\":\"2020 Tenth International Conference on Image Processing Theory, Tools and Applications (IPTA)\",\"year\":2020},{\"arxivId\":\"2007.07407\",\"authors\":[{\"authorId\":\"1816754142\",\"name\":\"Juan Rebanal\"},{\"authorId\":\"1485909046\",\"name\":\"Yuqi Tang\"},{\"authorId\":\"1816758033\",\"name\":\"Jordan Combitsis\"},{\"authorId\":\"101751639\",\"name\":\"Kai-Wei Chang\"},{\"authorId\":\"2028468\",\"name\":\"Xiang 'Anthony' Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ba9a61a538cf6c669ffc7e043d642f8d3d3595ce\",\"title\":\"XAlgo: Explaining the Internal States of Algorithms via Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ba9a61a538cf6c669ffc7e043d642f8d3d3595ce\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49168719\",\"name\":\"C. Yin\"},{\"authorId\":\"39835284\",\"name\":\"B. Qian\"},{\"authorId\":\"39791510\",\"name\":\"Jishang Wei\"},{\"authorId\":\"4185657\",\"name\":\"X. Li\"},{\"authorId\":\"1491248835\",\"name\":\"X. Zhang\"},{\"authorId\":\"48514123\",\"name\":\"Y. Li\"},{\"authorId\":\"50320297\",\"name\":\"Qinghua Zheng\"}],\"doi\":\"10.1109/ICDM.2019.00083\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b19f5a65e327868bf31a85fc03752b58e09d0d03\",\"title\":\"Automatic Generation of Medical Imaging Diagnostic Report with Hierarchical Recurrent Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/b19f5a65e327868bf31a85fc03752b58e09d0d03\",\"venue\":\"2019 IEEE International Conference on Data Mining (ICDM)\",\"year\":2019},{\"arxivId\":\"1902.08261\",\"authors\":[{\"authorId\":\"48391641\",\"name\":\"Y. Tian\"},{\"authorId\":\"9695761\",\"name\":\"J. Engel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d1f7a4bf4b8691bbb67b8dd10da61c1a1b68ccce\",\"title\":\"Latent Translation: Crossing Modalities by Bridging Generative Models\",\"url\":\"https://www.semanticscholar.org/paper/d1f7a4bf4b8691bbb67b8dd10da61c1a1b68ccce\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1908.02632\",\"authors\":[{\"authorId\":\"151482698\",\"name\":\"Chen Shen\"},{\"authorId\":\"145592288\",\"name\":\"Rongrong Ji\"},{\"authorId\":\"2642638\",\"name\":\"Fuhai Chen\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"48569526\",\"name\":\"Xiangming Li\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c7f60b69ccafc9fb1aabc0aaac9942d68d9166cf\",\"title\":\"Scene-based Factored Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/c7f60b69ccafc9fb1aabc0aaac9942d68d9166cf\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9728275\",\"name\":\"Huanhou Xiao\"},{\"authorId\":\"34875762\",\"name\":\"Jinglun Shi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a17542ca3c7a39470bdbe70a2209c195be6d63df\",\"title\":\"Describing Video with Multiple Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/a17542ca3c7a39470bdbe70a2209c195be6d63df\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1812.06164\",\"authors\":[{\"authorId\":\"31571033\",\"name\":\"A. Salvador\"},{\"authorId\":\"3325894\",\"name\":\"M. Drozdzal\"},{\"authorId\":\"1398090762\",\"name\":\"Xavier Gir\\u00f3-i-Nieto\"},{\"authorId\":\"144290131\",\"name\":\"A. Romero\"}],\"doi\":\"10.1109/CVPR.2019.01070\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7ab155f8f532a238bc29e054b498a6945c157ace\",\"title\":\"Inverse Cooking: Recipe Generation From Food Images\",\"url\":\"https://www.semanticscholar.org/paper/7ab155f8f532a238bc29e054b498a6945c157ace\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1807.09418\",\"authors\":[{\"authorId\":\"47786844\",\"name\":\"J. Li\"},{\"authorId\":\"3026404\",\"name\":\"Yongkang Wong\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":\"10.1109/TMM.2019.2930041\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"92e02bd58b99ac17b475081611f091f4b0776482\",\"title\":\"Video Storytelling: Textual Summaries for Events\",\"url\":\"https://www.semanticscholar.org/paper/92e02bd58b99ac17b475081611f091f4b0776482\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151270642\",\"name\":\"Zineng Tang\"}],\"doi\":\"10.1145/3332305.3332323\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"9b2b30451f2a14ff55adafac65be2aacaed62125\",\"title\":\"Adaptive Aesthetic Photo Filter by Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/9b2b30451f2a14ff55adafac65be2aacaed62125\",\"venue\":\"ICVARS 2019\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3415549\",\"name\":\"Khalid Lamhaddab\"},{\"authorId\":\"3080553\",\"name\":\"Mohamed Lachgar\"},{\"authorId\":\"2788880\",\"name\":\"K. Elbaamrani\"}],\"doi\":\"10.1155/2019/4324871\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f463b8b77b612156b0c92794d2e8923a94a4d3bd\",\"title\":\"Porting Mobile Apps from iOS to Android: A Practical Experience\",\"url\":\"https://www.semanticscholar.org/paper/f463b8b77b612156b0c92794d2e8923a94a4d3bd\",\"venue\":\"Mob. Inf. Syst.\",\"year\":2019},{\"arxivId\":\"1909.04402\",\"authors\":[{\"authorId\":\"1387994359\",\"name\":\"Mitja Nikolaus\"},{\"authorId\":\"30671790\",\"name\":\"M. Abdou\"},{\"authorId\":\"48024953\",\"name\":\"Matthew Lamm\"},{\"authorId\":\"19509693\",\"name\":\"Rahul Aralikatte\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"}],\"doi\":\"10.18653/v1/K19-1009\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"11557ee241f6b5dc0a8c62bb8014c0111bbe45ba\",\"title\":\"Compositional Generalization in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/11557ee241f6b5dc0a8c62bb8014c0111bbe45ba\",\"venue\":\"CoNLL\",\"year\":2019},{\"arxivId\":\"2007.09580\",\"authors\":[{\"authorId\":\"41036094\",\"name\":\"C. Deng\"},{\"authorId\":\"46649124\",\"name\":\"Ning Ding\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"},{\"authorId\":\"1509240145\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1007/978-3-030-58601-0_42\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2320f853059c29ce7e70409fa559074d727da5a2\",\"title\":\"Length-Controllable Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/2320f853059c29ce7e70409fa559074d727da5a2\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1810.09630\",\"authors\":[{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"345a222fef6f5c1415056319ae7e87a369940d3f\",\"title\":\"A Neural Compositional Paradigm for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/345a222fef6f5c1415056319ae7e87a369940d3f\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1810.03649\",\"authors\":[{\"authorId\":\"31448527\",\"name\":\"S. Ramakrishnan\"},{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"45ec1446f42c0a7c7fe74319118335c76e0f7b19\",\"title\":\"Overcoming Language Priors in Visual Question Answering with Adversarial Regularization\",\"url\":\"https://www.semanticscholar.org/paper/45ec1446f42c0a7c7fe74319118335c76e0f7b19\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1908.09317\",\"authors\":[{\"authorId\":\"3422200\",\"name\":\"I. Laina\"},{\"authorId\":\"49359942\",\"name\":\"C. Rupprecht\"},{\"authorId\":\"145587209\",\"name\":\"N. Navab\"}],\"doi\":\"10.1109/ICCV.2019.00751\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a4ff2a0b65b7dfdecee8d2e4bc0c5f7e1fee03be\",\"title\":\"Towards Unsupervised Image Captioning With Shared Multimodal Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/a4ff2a0b65b7dfdecee8d2e4bc0c5f7e1fee03be\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144081629\",\"name\":\"Mario G\\u00f3mez Mart\\u00ednez\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"faa8314259e9de1af8e841c265b0251531b32e04\",\"title\":\"Deep learning for image captioning: an encoder-decoder architecture with soft attention\",\"url\":\"https://www.semanticscholar.org/paper/faa8314259e9de1af8e841c265b0251531b32e04\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2005.03119\",\"authors\":[{\"authorId\":\"2319973\",\"name\":\"Po-Yao Huang\"},{\"authorId\":\"145919382\",\"name\":\"J. Hu\"},{\"authorId\":\"144950946\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.18653/v1/2020.acl-main.731\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4318f99804c5fd57fd7c0a1087b22bbe6268e276\",\"title\":\"Unsupervised Multimodal Neural Machine Translation with Pseudo Visual Pivoting\",\"url\":\"https://www.semanticscholar.org/paper/4318f99804c5fd57fd7c0a1087b22bbe6268e276\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"1811.07662\",\"authors\":[{\"authorId\":\"47833739\",\"name\":\"Y. Zheng\"},{\"authorId\":\"2112160\",\"name\":\"Y. Li\"},{\"authorId\":\"1678689\",\"name\":\"S. Wang\"}],\"doi\":\"10.1109/CVPR.2019.00859\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"23e943809c131c50dc90c1d308373febc60b9029\",\"title\":\"Intention Oriented Image Captions With Guiding Objects\",\"url\":\"https://www.semanticscholar.org/paper/23e943809c131c50dc90c1d308373febc60b9029\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2002.11848\",\"authors\":[{\"authorId\":\"3212867\",\"name\":\"R. Luo\"},{\"authorId\":\"2490189\",\"name\":\"Gregory Shakhnarovich\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9ed8c8ee62b0afc403e44c29f6deedf6632885d5\",\"title\":\"Analysis of diversity-accuracy tradeoff in image captioning\",\"url\":\"https://www.semanticscholar.org/paper/9ed8c8ee62b0afc403e44c29f6deedf6632885d5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3212867\",\"name\":\"R. Luo\"},{\"authorId\":\"144811756\",\"name\":\"B. Price\"},{\"authorId\":\"145823372\",\"name\":\"S. Cohen\"},{\"authorId\":\"2490189\",\"name\":\"Gregory Shakhnarovich\"}],\"doi\":null,\"intent\":[\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"e5c4e5b4478f551c8cdd0685f41e34ffe3e15618\",\"title\":\"Result on standard split and MSCOCO test server\",\"url\":\"https://www.semanticscholar.org/paper/e5c4e5b4478f551c8cdd0685f41e34ffe3e15618\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46979645\",\"name\":\"J. Park\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"505a777fbf3760c16a80a3e893017d91d2c35b08\",\"title\":\"Supplementary Material to : Adversarial Inference for Multi-Sentence Video Description\",\"url\":\"https://www.semanticscholar.org/paper/505a777fbf3760c16a80a3e893017d91d2c35b08\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1906.06619\",\"authors\":[{\"authorId\":\"2251827\",\"name\":\"Gil Sadeh\"},{\"authorId\":\"46397904\",\"name\":\"L. Fritz\"},{\"authorId\":\"36004650\",\"name\":\"Gabi Shalev\"},{\"authorId\":\"40135367\",\"name\":\"E. Oks\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7b4708bce76d496e0a1083d057cad6e1562a302d\",\"title\":\"Generating Diverse and Informative Natural Language Fashion Feedback\",\"url\":\"https://www.semanticscholar.org/paper/7b4708bce76d496e0a1083d057cad6e1562a302d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2012.03110\",\"authors\":[{\"authorId\":\"48676958\",\"name\":\"Steffen Jung\"},{\"authorId\":\"3316866\",\"name\":\"Margret Keuper\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c618d0ef02ebaa197b71b8da77897e1e97b7aac\",\"title\":\"Spectral Distribution aware Image Generation\",\"url\":\"https://www.semanticscholar.org/paper/6c618d0ef02ebaa197b71b8da77897e1e97b7aac\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3491491\",\"name\":\"Shiyang Yan\"},{\"authorId\":\"1410066063\",\"name\":\"Yuan Xie\"},{\"authorId\":\"152345893\",\"name\":\"F. Wu\"},{\"authorId\":\"33830793\",\"name\":\"J. Smith\"},{\"authorId\":\"40178769\",\"name\":\"Wenjin Lu\"},{\"authorId\":\"46824190\",\"name\":\"B. Zhang\"}],\"doi\":\"10.1016/j.sigpro.2019.107329\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ea53299a067694a24e5e9cf8e852e122d5918847\",\"title\":\"Image captioning via hierarchical attention mechanism and policy gradient optimization\",\"url\":\"https://www.semanticscholar.org/paper/ea53299a067694a24e5e9cf8e852e122d5918847\",\"venue\":\"Signal Process.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1839363\",\"name\":\"Pierre L. Dognin\"},{\"authorId\":\"2576373\",\"name\":\"I. Melnyk\"},{\"authorId\":\"2211263\",\"name\":\"Youssef Mroueh\"},{\"authorId\":\"153598395\",\"name\":\"J. Ross\"},{\"authorId\":\"2500466\",\"name\":\"Tom Sercu\"}],\"doi\":\"10.1109/CVPR.2019.01071\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"24fdb40c354599ee33a25530c3fa7b9ebc75e840\",\"title\":\"Adversarial Semantic Alignment for Improved Image Captions\",\"url\":\"https://www.semanticscholar.org/paper/24fdb40c354599ee33a25530c3fa7b9ebc75e840\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1908.04919\",\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"58a77455b1c38afe1eab4bec664bd866eba1573d\",\"title\":\"Towards Diverse and Accurate Image Captions via Reinforcing Determinantal Point Process\",\"url\":\"https://www.semanticscholar.org/paper/58a77455b1c38afe1eab4bec664bd866eba1573d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1805.07112\",\"authors\":[{\"authorId\":\"1828568\",\"name\":\"Chen Chen\"},{\"authorId\":\"39108991\",\"name\":\"Shuai Mu\"},{\"authorId\":\"1410650653\",\"name\":\"Wanpeng Xiao\"},{\"authorId\":\"1410066883\",\"name\":\"Zexiong Ye\"},{\"authorId\":\"1410052649\",\"name\":\"Liesi Wu\"},{\"authorId\":\"102396462\",\"name\":\"Fuming Ma\"},{\"authorId\":\"34974680\",\"name\":\"Q. Ju\"}],\"doi\":\"10.1609/aaai.v33i01.33018142\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0daa3a4118e00b9f63b2d014a16ff1bc3ca9ff7e\",\"title\":\"Improving Image Captioning with Conditional Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/0daa3a4118e00b9f63b2d014a16ff1bc3ca9ff7e\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1811.02234\",\"authors\":[{\"authorId\":\"7808048\",\"name\":\"M. Bucher\"},{\"authorId\":\"1924996\",\"name\":\"S. Herbin\"},{\"authorId\":\"82117876\",\"name\":\"F. Jurie\"}],\"doi\":\"10.1007/978-3-030-20890-5_44\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ca4eb45862a7153e6264bc96a400508d94c9d7ef\",\"title\":\"Semantic bottleneck for computer vision tasks\",\"url\":\"https://www.semanticscholar.org/paper/ca4eb45862a7153e6264bc96a400508d94c9d7ef\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1488653711\",\"name\":\"Yanzhi Yi\"},{\"authorId\":\"1486063321\",\"name\":\"Hangyu Deng\"},{\"authorId\":\"153147804\",\"name\":\"Jinglu Hu\"}],\"doi\":\"10.18653/v1/2020.acl-main.93\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0b4d5b7cef06b66182db80803f783d077e3637b6\",\"title\":\"Improving Image Captioning Evaluation by Considering Inter References Variance\",\"url\":\"https://www.semanticscholar.org/paper/0b4d5b7cef06b66182db80803f783d077e3637b6\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2966240\",\"name\":\"Jianren Wang\"},{\"authorId\":\"9253634\",\"name\":\"Yihui He\"}],\"doi\":\"10.1109/3DV.2019.00062\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"28e46cfc43f992dab4c1c138aff85dd548c36764\",\"title\":\"Physics-Aware 3D Mesh Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/28e46cfc43f992dab4c1c138aff85dd548c36764\",\"venue\":\"2019 International Conference on 3D Vision (3DV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1669575427\",\"name\":\"Nafiz Sadman\"},{\"authorId\":\"2007036321\",\"name\":\"Kishor Datta Gupta\"},{\"authorId\":\"79489670\",\"name\":\"Md. Reazul Haque\"},{\"authorId\":\"2006718808\",\"name\":\"Sajib Sen\"},{\"authorId\":\"4439766\",\"name\":\"Subash Poudyal\"}],\"doi\":\"10.1109/ecti-con49241.2020.9158216\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"60f6888a66d41f43ca0a59640465c62b1d2f2f6a\",\"title\":\"Stylometry as a Reliable Method for Fallback Authentication\",\"url\":\"https://www.semanticscholar.org/paper/60f6888a66d41f43ca0a59640465c62b1d2f2f6a\",\"venue\":\"2020 17th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology (ECTI-CON)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3490541\",\"name\":\"Aaron Chan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b775774edc1c2edcc9782f37eb2682cd01cfd94a\",\"title\":\"A Survey of Image Captioning Methods\",\"url\":\"https://www.semanticscholar.org/paper/b775774edc1c2edcc9782f37eb2682cd01cfd94a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40362315\",\"name\":\"J. Wang\"},{\"authorId\":\"1866977\",\"name\":\"Yiping Duan\"},{\"authorId\":\"144978572\",\"name\":\"X. Tao\"},{\"authorId\":\"47789939\",\"name\":\"J. Lu\"}],\"doi\":\"10.1109/ICC40277.2020.9149264\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3a5a6c759925570ab178c45340d34174fc8760f3\",\"title\":\"Local-to-Global Semantic Supervised Learning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/3a5a6c759925570ab178c45340d34174fc8760f3\",\"venue\":\"ICC 2020 - 2020 IEEE International Conference on Communications (ICC)\",\"year\":2020},{\"arxivId\":\"1805.12589\",\"authors\":[{\"authorId\":\"31121723\",\"name\":\"A. Deshpande\"},{\"authorId\":\"29956361\",\"name\":\"Jyoti Aneja\"},{\"authorId\":\"39709900\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"144016256\",\"name\":\"D. Forsyth\"}],\"doi\":\"10.1109/CVPR.2019.01095\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e7fe886600399448f3282c8da8fd98ab7e50eae3\",\"title\":\"Fast, Diverse and Accurate Image Captioning Guided by Part-Of-Speech\",\"url\":\"https://www.semanticscholar.org/paper/e7fe886600399448f3282c8da8fd98ab7e50eae3\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1910.14609\",\"authors\":[{\"authorId\":\"35935570\",\"name\":\"Jean-Benoit Delbrouck\"},{\"authorId\":\"1397311046\",\"name\":\"Bastien Vanderplaetse\"},{\"authorId\":\"153352427\",\"name\":\"S. Dupont\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"49555853d7e9b6a2573117aa01d4c6c18b86c864\",\"title\":\"Can adversarial training learn image captioning ?\",\"url\":\"https://www.semanticscholar.org/paper/49555853d7e9b6a2573117aa01d4c6c18b86c864\",\"venue\":\"ViGIL@NeurIPS\",\"year\":2019},{\"arxivId\":\"1812.00235\",\"authors\":[{\"authorId\":\"1516206362\",\"name\":\"Tingke Shen\"},{\"authorId\":\"24899770\",\"name\":\"Amlan Kar\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":\"10.1109/ICCV.2019.01049\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b4cb0a7617212eb40c537f4053d571faa4b8227c\",\"title\":\"Learning to Caption Images Through a Lifetime by Asking Questions\",\"url\":\"https://www.semanticscholar.org/paper/b4cb0a7617212eb40c537f4053d571faa4b8227c\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144323115\",\"name\":\"W. Yu\"},{\"authorId\":\"48861681\",\"name\":\"T. Chang\"},{\"authorId\":\"1596824859\",\"name\":\"Xiaoting Guo\"},{\"authorId\":\"35661244\",\"name\":\"Xiaodong Wang\"},{\"authorId\":\"144532278\",\"name\":\"Bo Liu\"},{\"authorId\":\"49990843\",\"name\":\"Y. He\"}],\"doi\":\"10.1109/ACCESS.2020.2980898\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"71d97906de0d6fc9a702e716c4e2f08bb9e75a67\",\"title\":\"UGAN: Unified Generative Adversarial Networks for Multidirectional Text Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/71d97906de0d6fc9a702e716c4e2f08bb9e75a67\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67159407\",\"name\":\"S. Amirian\"},{\"authorId\":\"1438623667\",\"name\":\"Khaled Rasheed\"},{\"authorId\":\"1784399\",\"name\":\"T. Taha\"},{\"authorId\":\"1712033\",\"name\":\"H. Arabnia\"}],\"doi\":\"10.1109/CSCI49370.2019.00055\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1d4a2308f7ce78cf0a28dcf5873348baccc036ce\",\"title\":\"Image Captioning with Generative Adversarial Network\",\"url\":\"https://www.semanticscholar.org/paper/1d4a2308f7ce78cf0a28dcf5873348baccc036ce\",\"venue\":\"2019 International Conference on Computational Science and Computational Intelligence (CSCI)\",\"year\":2019},{\"arxivId\":\"2004.14487\",\"authors\":[{\"authorId\":\"94314731\",\"name\":\"Matthew Purri\"},{\"authorId\":\"1710772\",\"name\":\"K. Dana\"}],\"doi\":\"10.1007/978-3-030-58583-9_1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dd5f4a7a3f619cb64428dc1a8a128019c8d4f512\",\"title\":\"Teaching Cameras to Feel: Estimating Tactile Physical Properties of Surfaces From Images\",\"url\":\"https://www.semanticscholar.org/paper/dd5f4a7a3f619cb64428dc1a8a128019c8d4f512\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2001.06937\",\"authors\":[{\"authorId\":\"48603577\",\"name\":\"Jie Gui\"},{\"authorId\":\"1757186\",\"name\":\"Z. Sun\"},{\"authorId\":\"145868453\",\"name\":\"Yonggang Wen\"},{\"authorId\":\"145047838\",\"name\":\"Dacheng Tao\"},{\"authorId\":\"2778556\",\"name\":\"Jie-ping Ye\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fbc5486a1ffb9039dbb5046b84f0eb32e4ce8eea\",\"title\":\"A Review on Generative Adversarial Networks: Algorithms, Theory, and Applications\",\"url\":\"https://www.semanticscholar.org/paper/fbc5486a1ffb9039dbb5046b84f0eb32e4ce8eea\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.14124\",\"authors\":[{\"authorId\":\"47475299\",\"name\":\"K. Shirai\"},{\"authorId\":\"2036498481\",\"name\":\"Kazuma Hashimoto\"},{\"authorId\":\"50123248\",\"name\":\"A. Eriguchi\"},{\"authorId\":\"49584970\",\"name\":\"T. Ninomiya\"},{\"authorId\":\"48608426\",\"name\":\"S. Mori\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f6c65402de67aef611852baa6c89d0b97b3e4f06\",\"title\":\"Neural Text Generation with Artificial Negative Examples\",\"url\":\"https://www.semanticscholar.org/paper/f6c65402de67aef611852baa6c89d0b97b3e4f06\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2319973\",\"name\":\"Po-Yao Huang\"},{\"authorId\":\"3374337\",\"name\":\"Guoliang Kang\"},{\"authorId\":\"3446043\",\"name\":\"Wenhe Liu\"},{\"authorId\":\"144950946\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1145/3343031.3350894\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b8fd269ab69a974eaf057c0e4bcaf0be2b8ee55f\",\"title\":\"Annotation Efficient Cross-Modal Retrieval with Adversarial Attentive Alignment\",\"url\":\"https://www.semanticscholar.org/paper/b8fd269ab69a974eaf057c0e4bcaf0be2b8ee55f\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144435468\",\"name\":\"Yan Gan\"},{\"authorId\":\"145081501\",\"name\":\"Kedi Liu\"},{\"authorId\":\"145792498\",\"name\":\"M. Ye\"},{\"authorId\":\"38741485\",\"name\":\"Yuxiao Zhang\"},{\"authorId\":\"48549316\",\"name\":\"Yang Qian\"}],\"doi\":\"10.1007/s00521-019-04526-w\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a7d85886de887672b02e8f7c0fa3256c5b22d145\",\"title\":\"Generative adversarial networks with denoising penalty and sample augmentation\",\"url\":\"https://www.semanticscholar.org/paper/a7d85886de887672b02e8f7c0fa3256c5b22d145\",\"venue\":\"Neural Computing and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"2751871\",\"name\":\"J. Wan\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":\"10.1109/tpami.2020.3013834\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ba341f992ceb10d9a7f032ac6027f18ef5e5f895\",\"title\":\"On Diversity in Image Captioning: Metrics and Methods.\",\"url\":\"https://www.semanticscholar.org/paper/ba341f992ceb10d9a7f032ac6027f18ef5e5f895\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"1908.08529\",\"authors\":[{\"authorId\":\"29956361\",\"name\":\"Jyoti Aneja\"},{\"authorId\":\"37825612\",\"name\":\"Harsh Agrawal\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1109/ICCV.2019.00436\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"49d46b0245475067bb7192d9bb1538701ae1c014\",\"title\":\"Sequential Latent Spaces for Modeling the Intention During Diverse Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/49d46b0245475067bb7192d9bb1538701ae1c014\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"116860563\",\"name\":\"Jaume Zaragoza Bernabeu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"266f8869473a87dda9f7032100270057e963dc44\",\"title\":\"Neural Paraphrasing Generation System\",\"url\":\"https://www.semanticscholar.org/paper/266f8869473a87dda9f7032100270057e963dc44\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8353931\",\"name\":\"Jiahe Shi\"},{\"authorId\":\"5550675\",\"name\":\"Y. Li\"},{\"authorId\":\"103307901\",\"name\":\"Shengjin Wang\"}],\"doi\":\"10.1109/ICIP.2019.8803149\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8c054cda5375018e902daab0b0875773a854d035\",\"title\":\"Cascade Attention: Multiple Feature Based Learning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/8c054cda5375018e902daab0b0875773a854d035\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"1803.07950\",\"authors\":[{\"authorId\":\"4322411\",\"name\":\"L. Li\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"}],\"doi\":\"10.1109/WACV.2019.00042\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"abcf7dd1e35575eaac12332aa4bc7575ccdd6965\",\"title\":\"End-to-End Video Captioning With Multitask Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/abcf7dd1e35575eaac12332aa4bc7575ccdd6965\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3194553\",\"name\":\"Heng Gong\"},{\"authorId\":\"1844673750\",\"name\":\"Wei Bi\"},{\"authorId\":\"2674998\",\"name\":\"X. Feng\"},{\"authorId\":\"152277111\",\"name\":\"B. Qin\"},{\"authorId\":\"3028405\",\"name\":\"Xiaojiang Liu\"},{\"authorId\":\"152244126\",\"name\":\"T. Liu\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.262\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"74d21025fafefd00e132b4c37de092ea8424c253\",\"title\":\"Enhancing Content Planning for Table-to-Text Generation with Data Understanding and Verification\",\"url\":\"https://www.semanticscholar.org/paper/74d21025fafefd00e132b4c37de092ea8424c253\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46354187\",\"name\":\"H. Hu\"},{\"authorId\":\"71201688\",\"name\":\"Bo. Gao\"},{\"authorId\":\"49020094\",\"name\":\"Zhiyuan Shen\"},{\"authorId\":\"48378687\",\"name\":\"Y. Zhang\"}],\"doi\":\"10.1109/ACCESS.2020.2992772\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5058f9de8ceddd27bb17aa52d512f15fbaebe264\",\"title\":\"Image Smear Removal via Improved Conditional GAN and Semantic Network\",\"url\":\"https://www.semanticscholar.org/paper/5058f9de8ceddd27bb17aa52d512f15fbaebe264\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3221962\",\"name\":\"L. Qian\"},{\"authorId\":\"144059552\",\"name\":\"L. Qiu\"},{\"authorId\":\"8031058\",\"name\":\"W. Zhang\"},{\"authorId\":\"145820291\",\"name\":\"Xin Jiang\"},{\"authorId\":\"153020689\",\"name\":\"Yong Yu\"}],\"doi\":\"10.18653/v1/D19-1313\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"c7fade7c837872810123f5e7f762848dbfa937d8\",\"title\":\"Exploring Diverse Expressions for Paraphrase Generation\",\"url\":\"https://www.semanticscholar.org/paper/c7fade7c837872810123f5e7f762848dbfa937d8\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"1710.02534\",\"authors\":[{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"83d66c1f808962536a68418587b691f30221c5a1\",\"title\":\"Contrastive Learning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/83d66c1f808962536a68418587b691f30221c5a1\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1901.01641\",\"authors\":[{\"authorId\":\"145001851\",\"name\":\"Quan Yuan\"},{\"authorId\":\"46277016\",\"name\":\"J. Li\"},{\"authorId\":\"7559641\",\"name\":\"Lingwei Zhang\"},{\"authorId\":\"9272660\",\"name\":\"Zhefu Wu\"},{\"authorId\":\"47061593\",\"name\":\"G. Liu\"}],\"doi\":\"10.1007/s00371-019-01762-y\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"7b2cdc01b82be80db2b8c97dc6e3a759749b7d33\",\"title\":\"Blind motion deblurring with cycle generative adversarial networks\",\"url\":\"https://www.semanticscholar.org/paper/7b2cdc01b82be80db2b8c97dc6e3a759749b7d33\",\"venue\":\"The Visual Computer\",\"year\":2019},{\"arxivId\":\"2004.06247\",\"authors\":[{\"authorId\":\"47151783\",\"name\":\"E. Wang\"},{\"authorId\":\"1874200\",\"name\":\"Henggang Cui\"},{\"authorId\":\"70632991\",\"name\":\"S. Yalamanchi\"},{\"authorId\":\"1631201188\",\"name\":\"M. Moorthy\"},{\"authorId\":\"49181382\",\"name\":\"Fang-Chieh Chou\"},{\"authorId\":\"1829158\",\"name\":\"Nemanja Djuric\"}],\"doi\":\"10.1145/3394486.3403283\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1da9e5a88e171b64c4a668a56bc962e7ace6a6f5\",\"title\":\"Improving Movement Predictions of Traffic Actors in Bird's-Eye View Models using GANs and Differentiable Trajectory Rasterization\",\"url\":\"https://www.semanticscholar.org/paper/1da9e5a88e171b64c4a668a56bc962e7ace6a6f5\",\"venue\":\"KDD\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19261873\",\"name\":\"Yiwei Wei\"},{\"authorId\":\"2250564\",\"name\":\"Leiquan Wang\"},{\"authorId\":\"51172982\",\"name\":\"Haiwen Cao\"},{\"authorId\":\"134473682\",\"name\":\"Mingwen Shao\"},{\"authorId\":\"46740305\",\"name\":\"Chunlei Wu\"}],\"doi\":\"10.1016/j.neucom.2019.12.073\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"50260b547a481a95a2346759da8dba9366e89348\",\"title\":\"Multi-Attention Generative Adversarial Network for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/50260b547a481a95a2346759da8dba9366e89348\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"2002.06661\",\"authors\":[{\"authorId\":\"32370882\",\"name\":\"Shweta Mahajan\"},{\"authorId\":\"1730400\",\"name\":\"Iryna Gurevych\"},{\"authorId\":\"49863405\",\"name\":\"S. Roth\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"87415957ec3aa3ae6756e3e7d22873cd9fc74c51\",\"title\":\"Latent Normalizing Flows for Many-to-Many Cross-Domain Mappings\",\"url\":\"https://www.semanticscholar.org/paper/87415957ec3aa3ae6756e3e7d22873cd9fc74c51\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"1911.12018\",\"authors\":[{\"authorId\":\"98831710\",\"name\":\"B. Yang\"},{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"145586191\",\"name\":\"Can Zhang\"},{\"authorId\":\"35325151\",\"name\":\"Yuexian Zou\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9191773630826b15a86148453365aae7703aec6b\",\"title\":\"Non-Autoregressive Coarse-to-Fine Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9191773630826b15a86148453365aae7703aec6b\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143696833\",\"name\":\"Wenjie Cai\"},{\"authorId\":\"47362438\",\"name\":\"Q. Liu\"}],\"doi\":\"10.1016/j.neucom.2020.06.112\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c218331cf31c32c46eb660c1b2ce3e506c99b3b0\",\"title\":\"Image captioning with semantic-enhanced features and extremely hard negative examples\",\"url\":\"https://www.semanticscholar.org/paper/c218331cf31c32c46eb660c1b2ce3e506c99b3b0\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67159407\",\"name\":\"S. Amirian\"},{\"authorId\":\"1799121\",\"name\":\"K. Rasheed\"},{\"authorId\":\"1784399\",\"name\":\"T. Taha\"},{\"authorId\":\"1712033\",\"name\":\"H. Arabnia\"}],\"doi\":\"10.1109/ACCESS.2020.3042484\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"832aafb4989c24211a8377f82228c31f7a90ef81\",\"title\":\"Automatic Image and Video Caption Generation With Deep Learning: A Concise Review and Algorithmic Overlap\",\"url\":\"https://www.semanticscholar.org/paper/832aafb4989c24211a8377f82228c31f7a90ef81\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1702.08431\",\"authors\":[{\"authorId\":\"40482726\",\"name\":\"R. Devon Hjelm\"},{\"authorId\":\"12782441\",\"name\":\"Athul Paul Jacob\"},{\"authorId\":\"47828117\",\"name\":\"Tong Che\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"042116e805aa3b5171efaf0c822dc142310ceefe\",\"title\":\"Boundary-Seeking Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/042116e805aa3b5171efaf0c822dc142310ceefe\",\"venue\":\"ICLR 2017\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33698309\",\"name\":\"Zhong-Qiu Zhao\"},{\"authorId\":\"49697077\",\"name\":\"Yue-Lin Sun\"},{\"authorId\":\"1977865899\",\"name\":\"Nan-Xun Wang\"},{\"authorId\":\"144963976\",\"name\":\"Weidong Tian\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206632\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"03a53b48a2c869658f969856acd2830711dc9ba9\",\"title\":\"Extricating from GroundTruth: An Unpaired Learning Based Evaluation Metric for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/03a53b48a2c869658f969856acd2830711dc9ba9\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":\"1807.10018\",\"authors\":[{\"authorId\":\"51152390\",\"name\":\"Yilei Xiong\"},{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1007/978-3-030-01252-6_29\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b74a094b6e35fab07e1a4694afd12cad9696f1c1\",\"title\":\"Move Forward and Tell: A Progressive Generator of Video Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/b74a094b6e35fab07e1a4694afd12cad9696f1c1\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1834105\",\"name\":\"Nancy Fulda\"},{\"authorId\":\"40154683\",\"name\":\"Ben Murdoch\"},{\"authorId\":\"34778050\",\"name\":\"Daniel Ricks\"},{\"authorId\":\"30585164\",\"name\":\"D. Wingate\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cc99d6ad1e67520a5a765be7da7ff6ec3b1e5666\",\"title\":\"Informing Action Primitives Through Free-Form Text\",\"url\":\"https://www.semanticscholar.org/paper/cc99d6ad1e67520a5a765be7da7ff6ec3b1e5666\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1380224383\",\"name\":\"Xuri Ge\"},{\"authorId\":\"2642638\",\"name\":\"F. Chen\"},{\"authorId\":\"143648909\",\"name\":\"C. Shen\"},{\"authorId\":\"145592288\",\"name\":\"Rongrong Ji\"}],\"doi\":\"10.1109/ICME.2019.00069\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6550b0f3c3c2e848827a0392126b55b1dbb5799b\",\"title\":\"Colloquial Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6550b0f3c3c2e848827a0392126b55b1dbb5799b\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":\"1907.09358\",\"authors\":[{\"authorId\":\"3219864\",\"name\":\"Aditya Mogadala\"},{\"authorId\":\"151119369\",\"name\":\"M. Kalimuthu\"},{\"authorId\":\"2561225\",\"name\":\"D. Klakow\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f8a48678094adbe421d61d0045361bfc635a2900\",\"title\":\"Trends in Integration of Vision and Language Research: A Survey of Tasks, Datasets, and Methods\",\"url\":\"https://www.semanticscholar.org/paper/f8a48678094adbe421d61d0045361bfc635a2900\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2003.03473\",\"authors\":[{\"authorId\":\"152546466\",\"name\":\"Shashank Tripathi\"},{\"authorId\":\"82997838\",\"name\":\"Siddhant Ranade\"},{\"authorId\":\"36183106\",\"name\":\"Ambrish Tyagi\"},{\"authorId\":\"145972492\",\"name\":\"Amit Agrawal\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9ff9397d5b89978f90499f16a3ee255e265f58cd\",\"title\":\"PoseNet3D: Learning Temporally Consistent 3D Human Pose via Knowledge Distillation\",\"url\":\"https://www.semanticscholar.org/paper/9ff9397d5b89978f90499f16a3ee255e265f58cd\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1911.04192\",\"authors\":[{\"authorId\":\"29068663\",\"name\":\"Ruize Wang\"},{\"authorId\":\"2712533\",\"name\":\"Zhongyu Wei\"},{\"authorId\":\"2193560\",\"name\":\"Piji Li\"},{\"authorId\":\"5006870\",\"name\":\"Haijun Shan\"},{\"authorId\":\"24263694\",\"name\":\"J. Zhang\"},{\"authorId\":\"1409702669\",\"name\":\"Qi Zhang\"},{\"authorId\":\"144052385\",\"name\":\"X. Huang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"6c87e0cc7234d9a5fb2a33b8203d7d68c3d85d1d\",\"title\":\"Keep it Consistent: Topic-Aware Storytelling from an Image Stream via Iterative Multi-agent Communication\",\"url\":\"https://www.semanticscholar.org/paper/6c87e0cc7234d9a5fb2a33b8203d7d68c3d85d1d\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":\"2007.10662\",\"authors\":[{\"authorId\":\"69544685\",\"name\":\"Jie Wu\"},{\"authorId\":\"1765674\",\"name\":\"Tianshui Chen\"},{\"authorId\":\"1721715\",\"name\":\"Hefeng Wu\"},{\"authorId\":\"10665619\",\"name\":\"Z. Yang\"},{\"authorId\":\"1773818\",\"name\":\"Guangchun Luo\"},{\"authorId\":\"49478124\",\"name\":\"L. Lin\"}],\"doi\":\"10.1109/tmm.2020.3011317\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f0edc8eb2d2b53482faf34906dacf996bc4127f6\",\"title\":\"Fine-Grained Image Captioning with Global-Local Discriminative Objective\",\"url\":\"https://www.semanticscholar.org/paper/f0edc8eb2d2b53482faf34906dacf996bc4127f6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51188208\",\"name\":\"Sunghyun Park\"},{\"authorId\":\"1716415\",\"name\":\"S. Hwang\"},{\"authorId\":\"7243120\",\"name\":\"Fuxiang Chen\"},{\"authorId\":\"1795455\",\"name\":\"J. Choo\"},{\"authorId\":\"2577039\",\"name\":\"Jung-Woo Ha\"},{\"authorId\":\"6098375\",\"name\":\"S. Kim\"},{\"authorId\":\"49841374\",\"name\":\"Jinyeong Yim\"}],\"doi\":\"10.1609/aaai.v33i01.33016883\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f5c25a0f61005bf18953249cd3e08094b69a5d98\",\"title\":\"Paraphrase Diversification Using Counterfactual Debiasing\",\"url\":\"https://www.semanticscholar.org/paper/f5c25a0f61005bf18953249cd3e08094b69a5d98\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1907.10949\",\"authors\":[{\"authorId\":\"3366919\",\"name\":\"Massimiliano Patacchiola\"},{\"authorId\":\"1401704946\",\"name\":\"P. Fox-Roberts\"},{\"authorId\":\"1721991\",\"name\":\"E. Rosten\"}],\"doi\":\"10.1016/J.PATREC.2020.09.025\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e5c870b9908c561380db64b893b0c88bac3a5b83\",\"title\":\"Y-Autoencoders: disentangling latent representations via sequential-encoding\",\"url\":\"https://www.semanticscholar.org/paper/e5c870b9908c561380db64b893b0c88bac3a5b83\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2020},{\"arxivId\":\"1707.05251\",\"authors\":[{\"authorId\":\"48362742\",\"name\":\"Yubin Deng\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1145/3240508.3240531\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1a416647dc3397498f5175ff4c0b9c4fc9a33b59\",\"title\":\"Aesthetic-Driven Image Enhancement by Adversarial Learning\",\"url\":\"https://www.semanticscholar.org/paper/1a416647dc3397498f5175ff4c0b9c4fc9a33b59\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1706.00130\",\"authors\":[{\"authorId\":\"18900686\",\"name\":\"Huan Ling\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7a9fe5781220cca6ca600833015f200a9c03d50e\",\"title\":\"Teaching Machines to Describe Images with Natural Language Feedback\",\"url\":\"https://www.semanticscholar.org/paper/7a9fe5781220cca6ca600833015f200a9c03d50e\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1711.07068\",\"authors\":[{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"82247c9e74ddebb4dce65560ee69620579358f2d\",\"title\":\"Diverse and Accurate Image Description Using a Variational Auto-Encoder with an Additive Gaussian Encoding Space\",\"url\":\"https://www.semanticscholar.org/paper/82247c9e74ddebb4dce65560ee69620579358f2d\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32763968\",\"name\":\"A. Fisch\"},{\"authorId\":\"2544107\",\"name\":\"Kenton Lee\"},{\"authorId\":\"1744179\",\"name\":\"Ming-Wei Chang\"},{\"authorId\":\"144797264\",\"name\":\"J. Clark\"},{\"authorId\":\"1741283\",\"name\":\"R. Barzilay\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.705\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b01bc15919f72929d36fc0443395e97b632c81b8\",\"title\":\"CapWAP: Image Captioning with a Purpose\",\"url\":\"https://www.semanticscholar.org/paper/b01bc15919f72929d36fc0443395e97b632c81b8\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"1909.05316\",\"authors\":[{\"authorId\":\"145919382\",\"name\":\"J. Hu\"},{\"authorId\":\"145215470\",\"name\":\"Yu Cheng\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"32556571\",\"name\":\"J. Liu\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"1700325\",\"name\":\"Graham Neubig\"}],\"doi\":\"10.1609/AAAI.V34I05.6305\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f416f27ba8ae0be32bb4c9a3a50995965a09c449\",\"title\":\"What Makes A Good Story? Designing Composite Rewards for Visual Storytelling\",\"url\":\"https://www.semanticscholar.org/paper/f416f27ba8ae0be32bb4c9a3a50995965a09c449\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2007.00873\",\"authors\":[{\"authorId\":\"97531942\",\"name\":\"Kyungsu Kim\"},{\"authorId\":\"46663619\",\"name\":\"J. Lee\"},{\"authorId\":\"1720494\",\"name\":\"E. Yang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8c11d7cfa093f8133b37b77a59d097c3b014b352\",\"title\":\"Compressed Sensing via Measurement-Conditional Generative Models\",\"url\":\"https://www.semanticscholar.org/paper/8c11d7cfa093f8133b37b77a59d097c3b014b352\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"dd7062e6f84750688fa96143209efc801e91f9bd\",\"title\":\"Visual Understanding through Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/dd7062e6f84750688fa96143209efc801e91f9bd\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1904.06699\",\"authors\":[{\"authorId\":\"145861592\",\"name\":\"Y. Wei\"},{\"authorId\":\"50152458\",\"name\":\"S. Liu\"},{\"authorId\":\"145782209\",\"name\":\"Wang Zhao\"},{\"authorId\":\"1697700\",\"name\":\"Jiwen Lu\"},{\"authorId\":\"49640256\",\"name\":\"J. Zhou\"}],\"doi\":\"10.1109/CVPR.2019.00988\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bddad24bb44902680e03b586985c0966878946e1\",\"title\":\"Conditional Single-View Shape Generation for Multi-View Stereo Reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/bddad24bb44902680e03b586985c0966878946e1\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1810.05786\",\"authors\":[{\"authorId\":\"30572523\",\"name\":\"H. Wang\"},{\"authorId\":\"47271859\",\"name\":\"J. Williams\"},{\"authorId\":\"80158488\",\"name\":\"SingBing Kang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"56bb6fbf51905151f3147d674fea45219e6a6f35\",\"title\":\"Learning to Globally Edit Images with Textual Description\",\"url\":\"https://www.semanticscholar.org/paper/56bb6fbf51905151f3147d674fea45219e6a6f35\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"145497716\",\"name\":\"A. Das\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"}],\"doi\":\"10.18653/v1/P18-5004\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"532837c431617d37c03361ba5a7d5fdb082c55f4\",\"title\":\"Connecting Language and Vision to Actions\",\"url\":\"https://www.semanticscholar.org/paper/532837c431617d37c03361ba5a7d5fdb082c55f4\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":\"1812.08126\",\"authors\":[{\"authorId\":\"32236286\",\"name\":\"Annika Lindh\"},{\"authorId\":\"144394786\",\"name\":\"R. Ross\"},{\"authorId\":\"31179447\",\"name\":\"Abhijit Mahalunkar\"},{\"authorId\":\"31071031\",\"name\":\"Giancarlo Salton\"},{\"authorId\":\"34967075\",\"name\":\"John D. Kelleher\"}],\"doi\":\"10.1007/978-3-030-01418-6_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"93a10137a41f9e1c8f939517bfc75379b47cb1a1\",\"title\":\"Generating Diverse and Meaningful Captions - Unsupervised Specificity Optimization for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/93a10137a41f9e1c8f939517bfc75379b47cb1a1\",\"venue\":\"ICANN\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8768514\",\"name\":\"G. M\\u00e1ttyus\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"}],\"doi\":\"10.1109/CVPR.2018.00837\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"95549a8692f734b978f1177c76242e074d52e67a\",\"title\":\"Matching Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/95549a8692f734b978f1177c76242e074d52e67a\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2017491\",\"name\":\"J. Wu\"},{\"authorId\":\"1765674\",\"name\":\"Tianshui Chen\"},{\"authorId\":\"1721715\",\"name\":\"Hefeng Wu\"},{\"authorId\":\"20570336\",\"name\":\"Z. Yang\"},{\"authorId\":\"104002286\",\"name\":\"Qing Wang\"},{\"authorId\":\"1737218\",\"name\":\"L. Lin\"}],\"doi\":\"10.1109/ICME.2019.00227\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4e3b2d5e0dfffc088e75da297a77f63820cd3a31\",\"title\":\"Concrete Image Captioning by Integrating Content Sensitive and Global Discriminative Objective\",\"url\":\"https://www.semanticscholar.org/paper/4e3b2d5e0dfffc088e75da297a77f63820cd3a31\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2455036\",\"name\":\"Kevin Shen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e86bf3a31ff3f55b8dae4741ee3642a82f8e6680\",\"title\":\"Learning to Caption Images by Asking Natural Language Questions\",\"url\":\"https://www.semanticscholar.org/paper/e86bf3a31ff3f55b8dae4741ee3642a82f8e6680\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50117915\",\"name\":\"Y. Wu\"},{\"authorId\":\"1510709841\",\"name\":\"Zhengtao Li\"},{\"authorId\":\"34711885\",\"name\":\"X. Qu\"},{\"authorId\":\"38144106\",\"name\":\"Tianxu Zhang\"}],\"doi\":\"10.1117/12.2538212\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"859a5095bff3b85d2c1eb173cfad32e400a135e1\",\"title\":\"Combined infrared simulation and pix2pix model for underground target detection\",\"url\":\"https://www.semanticscholar.org/paper/859a5095bff3b85d2c1eb173cfad32e400a135e1\",\"venue\":\"International Symposium on Multispectral Image Processing and Pattern Recognition\",\"year\":2020},{\"arxivId\":\"1905.07061\",\"authors\":[{\"authorId\":\"26248419\",\"name\":\"Rajhans Singh\"},{\"authorId\":\"143655174\",\"name\":\"P. Turaga\"},{\"authorId\":\"39131476\",\"name\":\"S. Jayasuriya\"},{\"authorId\":\"144751013\",\"name\":\"R. Garg\"},{\"authorId\":\"32731737\",\"name\":\"M. Braun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"035560b83bf113bf73d33da6a518eed5be20297b\",\"title\":\"Non-Parametric Priors For Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/035560b83bf113bf73d33da6a518eed5be20297b\",\"venue\":\"ICML\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50708553\",\"name\":\"K. Sruthi\"},{\"authorId\":\"1729242481\",\"name\":\"S. MeharbanM\"}],\"doi\":\"10.1109/ICACCS48705.2020.9074468\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7a94ffc5c398bcee43a9aca2fe2edf8aad50cf2d\",\"title\":\"Review on Image Captioning and Speech Synthesis Techniques\",\"url\":\"https://www.semanticscholar.org/paper/7a94ffc5c398bcee43a9aca2fe2edf8aad50cf2d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"15106903\",\"name\":\"Xiaotong Shi\"},{\"authorId\":\"50234122\",\"name\":\"T. Du\"},{\"authorId\":\"9350303\",\"name\":\"Shuwen Chen\"},{\"authorId\":\"32830430\",\"name\":\"H. Zhang\"},{\"authorId\":\"15012848\",\"name\":\"C. Guan\"},{\"authorId\":\"143778540\",\"name\":\"B. Xu\"}],\"doi\":\"10.1109/EMBC44109.2020.9175334\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"908e2b69d619d942bf4f50bedf731ccdf29ec804\",\"title\":\"UENet: A Novel Generative Adversarial Network for Angiography Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/908e2b69d619d942bf4f50bedf731ccdf29ec804\",\"venue\":\"2020 42nd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49969887\",\"name\":\"Zhe Li\"}],\"doi\":\"10.1145/3240323.3240326\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1a30fd889b808dac8ebc489521bffbea9bfecda0\",\"title\":\"Towards the next generation of multi-criteria recommender systems\",\"url\":\"https://www.semanticscholar.org/paper/1a30fd889b808dac8ebc489521bffbea9bfecda0\",\"venue\":\"RecSys\",\"year\":2018},{\"arxivId\":\"1711.07613\",\"authors\":[{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2018.00639\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9dde6ed569684356c46217fa53224272b668bae8\",\"title\":\"Are You Talking to Me? Reasoned Visual Dialog Generation Through Adversarial Learning\",\"url\":\"https://www.semanticscholar.org/paper/9dde6ed569684356c46217fa53224272b668bae8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1909.04800\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"1380338049\",\"name\":\"Anupriy\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":\"10.1016/j.patcog.2020.107586\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e281d8af3ec87fd893743afd6fb9d5ec3eaca924\",\"title\":\"Probabilistic framework for solving Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/e281d8af3ec87fd893743afd6fb9d5ec3eaca924\",\"venue\":\"Pattern Recognit.\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3491491\",\"name\":\"Shiyang Yan\"},{\"authorId\":\"151472634\",\"name\":\"Y. Hua\"},{\"authorId\":\"46406827\",\"name\":\"N. Robertson\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9f964bc4f8405491bc69c9e03e6f466ec609b9dd\",\"title\":\"SC-RANK: Improving Convolutional Image Captioning with Self-Critical Learning and Ranking Metric-based Reward\",\"url\":\"https://www.semanticscholar.org/paper/9f964bc4f8405491bc69c9e03e6f466ec609b9dd\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"1902.03570\",\"authors\":[{\"authorId\":\"24508084\",\"name\":\"Deshraj Yadav\"},{\"authorId\":\"145461380\",\"name\":\"Rishabh Jain\"},{\"authorId\":\"37825612\",\"name\":\"Harsh Agrawal\"},{\"authorId\":\"40424000\",\"name\":\"Prithvijit Chattopadhyay\"},{\"authorId\":\"2781522\",\"name\":\"T. Singh\"},{\"authorId\":\"49148034\",\"name\":\"Akash Jain\"},{\"authorId\":\"8518719\",\"name\":\"S. Singh\"},{\"authorId\":\"121944615\",\"name\":\"Stefan Lee\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0d96ac48e92b6b42737276a319f48d9d27080fce\",\"title\":\"EvalAI: Towards Better Evaluation Systems for AI Agents\",\"url\":\"https://www.semanticscholar.org/paper/0d96ac48e92b6b42737276a319f48d9d27080fce\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39541577\",\"name\":\"Sheng Li\"},{\"authorId\":\"6018169\",\"name\":\"Zhiqiang Tao\"},{\"authorId\":\"104510214\",\"name\":\"K. Li\"},{\"authorId\":\"145692782\",\"name\":\"Yun Fu\"}],\"doi\":\"10.1109/TETCI.2019.2892755\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"125b0bde4ac0b4cb9453b205bc0c5c184af3dec2\",\"title\":\"Visual to Text: Survey of Image and Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/125b0bde4ac0b4cb9453b205bc0c5c184af3dec2\",\"venue\":\"IEEE Transactions on Emerging Topics in Computational Intelligence\",\"year\":2019},{\"arxivId\":\"2004.14592\",\"authors\":[{\"authorId\":\"1694651\",\"name\":\"Jiayi Zhang\"},{\"authorId\":\"8801869\",\"name\":\"Chongyang Tao\"},{\"authorId\":\"10784901\",\"name\":\"Zhenjing Xu\"},{\"authorId\":\"51179933\",\"name\":\"Qiaojing Xie\"},{\"authorId\":\"50504401\",\"name\":\"Wei Chen\"},{\"authorId\":\"144539156\",\"name\":\"R. Yan\"}],\"doi\":\"10.1145/3331184.3331193\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"24b5bdd7e8832a2a6fac3837627314d50366be13\",\"title\":\"EnsembleGAN: Adversarial Learning for Retrieval-Generation Ensemble Model on Short-Text Conversation\",\"url\":\"https://www.semanticscholar.org/paper/24b5bdd7e8832a2a6fac3837627314d50366be13\",\"venue\":\"SIGIR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38889850\",\"name\":\"Pengfei Xia\"},{\"authorId\":\"50774917\",\"name\":\"Jingsong He\"},{\"authorId\":\"153781930\",\"name\":\"Jin Yin\"}],\"doi\":\"10.1007/s11042-020-09110-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"17cefd99f2d04fc01663ba261d6afee54e8408d5\",\"title\":\"Boosting image caption generation with feature fusion module\",\"url\":\"https://www.semanticscholar.org/paper/17cefd99f2d04fc01663ba261d6afee54e8408d5\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"2006.03985\",\"authors\":[{\"authorId\":\"34291068\",\"name\":\"Markos Georgopoulos\"},{\"authorId\":\"145451981\",\"name\":\"J. Oldfield\"},{\"authorId\":\"1752913\",\"name\":\"Mihalis A. Nicolaou\"},{\"authorId\":\"1780393\",\"name\":\"Yannis Panagakis\"},{\"authorId\":\"145387780\",\"name\":\"M. Pantic\"}],\"doi\":\"10.1109/CVPRW50498.2020.00015\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"69c7551511b6982cb1e90bb6775e6534620940bd\",\"title\":\"Enhancing Facial Data Diversity with Style-based Face Aging\",\"url\":\"https://www.semanticscholar.org/paper/69c7551511b6982cb1e90bb6775e6534620940bd\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"2004.14589\",\"authors\":[{\"authorId\":\"48493356\",\"name\":\"Daniel Kang\"},{\"authorId\":\"10253256\",\"name\":\"T. Hashimoto\"}],\"doi\":\"10.18653/v1/2020.acl-main.66\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4b52fd45a52aa84b2b1bb1c8cf36cc2884d7df7a\",\"title\":\"Improved Natural Language Generation via Loss Truncation\",\"url\":\"https://www.semanticscholar.org/paper/4b52fd45a52aa84b2b1bb1c8cf36cc2884d7df7a\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"1806.06422\",\"authors\":[{\"authorId\":\"50355189\",\"name\":\"Yin Cui\"},{\"authorId\":\"29983981\",\"name\":\"Guandao Yang\"},{\"authorId\":\"2799898\",\"name\":\"Andreas Veit\"},{\"authorId\":\"144247007\",\"name\":\"X. Huang\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"}],\"doi\":\"10.1109/CVPR.2018.00608\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6d3d61ef9b5ff6d41badbc3d40ea23acbbc9c3fe\",\"title\":\"Learning to Evaluate Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6d3d61ef9b5ff6d41badbc3d40ea23acbbc9c3fe\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3491491\",\"name\":\"Shiyang Yan\"},{\"authorId\":\"5145427\",\"name\":\"F. Wu\"},{\"authorId\":\"33830793\",\"name\":\"J. Smith\"},{\"authorId\":\"40178769\",\"name\":\"Wenjin Lu\"},{\"authorId\":\"46824190\",\"name\":\"B. Zhang\"}],\"doi\":\"10.1109/ICPR.2018.8545049\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3c6272a095d6601acf683d9f94c8683009cd1e5c\",\"title\":\"Image Captioning using Adversarial Networks and Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/3c6272a095d6601acf683d9f94c8683009cd1e5c\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":\"2010.03855\",\"authors\":[{\"authorId\":\"40622539\",\"name\":\"Dong-Jin Kim\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"49331178\",\"name\":\"Jinsoo Choi\"},{\"authorId\":\"145017149\",\"name\":\"In So Kweon\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0bda89ebb8cbec54afb013349c97a8264b36fee0\",\"title\":\"Dense Relational Image Captioning via Multi-task Triple-Stream Networks\",\"url\":\"https://www.semanticscholar.org/paper/0bda89ebb8cbec54afb013349c97a8264b36fee0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2642638\",\"name\":\"F. Chen\"},{\"authorId\":\"145592288\",\"name\":\"Rongrong Ji\"},{\"authorId\":\"9665187\",\"name\":\"Jiayi Ji\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"1740430\",\"name\":\"B. Zhang\"},{\"authorId\":\"1380224383\",\"name\":\"Xuri Ge\"},{\"authorId\":\"153017460\",\"name\":\"Yongjian Wu\"},{\"authorId\":\"1835006\",\"name\":\"Feiyue Huang\"},{\"authorId\":null,\"name\":\"Yan Wang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2eca0afa23ee2b9b0999c445b8dba44ad3039bd1\",\"title\":\"Variational Structured Semantic Inference for Diverse Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/2eca0afa23ee2b9b0999c445b8dba44ad3039bd1\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1885314583\",\"name\":\"Made Raharja Surya Mahadi\"},{\"authorId\":\"9347718\",\"name\":\"Anditya Arifianto\"},{\"authorId\":\"9308183\",\"name\":\"K. N. Ramadhani\"}],\"doi\":\"10.1109/ICoICT49345.2020.9166244\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"538b261dbdffc4745cb217128c001ef1e63dc6b6\",\"title\":\"Adaptive Attention Generation for Indonesian Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/538b261dbdffc4745cb217128c001ef1e63dc6b6\",\"venue\":\"2020 8th International Conference on Information and Communication Technology (ICoICT)\",\"year\":2020},{\"arxivId\":\"2007.06877\",\"authors\":[{\"authorId\":\"51175635\",\"name\":\"Jiuniu Wang\"},{\"authorId\":\"50232214\",\"name\":\"Wenjia Xu\"},{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":\"10.1007/978-3-030-58452-8_22\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e38274d1d544af5fad2cb814d62a028e2ff7437b\",\"title\":\"Compare and Reweight: Distinctive Image Captioning Using Similar Images Sets\",\"url\":\"https://www.semanticscholar.org/paper/e38274d1d544af5fad2cb814d62a028e2ff7437b\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1907.11565\",\"authors\":[{\"authorId\":\"151017519\",\"name\":\"Gilad Vered\"},{\"authorId\":\"3431267\",\"name\":\"Gal Oren\"},{\"authorId\":\"34815079\",\"name\":\"Yuval Atzmon\"},{\"authorId\":\"1732280\",\"name\":\"Gal Chechik\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2d69f6cc66cad1ba771b5873de04eeac5dc32eca\",\"title\":\"Cooperative image captioning\",\"url\":\"https://www.semanticscholar.org/paper/2d69f6cc66cad1ba771b5873de04eeac5dc32eca\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34270609\",\"name\":\"H. Zhang\"},{\"authorId\":\"37603348\",\"name\":\"C. Luo\"},{\"authorId\":\"31487928\",\"name\":\"Xingrui Yu\"},{\"authorId\":\"143823409\",\"name\":\"Peng Ren\"}],\"doi\":\"10.1007/978-981-10-6571-2_327\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"181e2f10fd63a4e5cf7d3c5be3df4da922c3cf9c\",\"title\":\"MCMC Based Generative Adversarial Networks for Handwritten Numeral Augmentation\",\"url\":\"https://www.semanticscholar.org/paper/181e2f10fd63a4e5cf7d3c5be3df4da922c3cf9c\",\"venue\":\"CSPS\",\"year\":2017},{\"arxivId\":\"2012.11696\",\"authors\":[{\"authorId\":\"1839363\",\"name\":\"Pierre L. Dognin\"},{\"authorId\":\"2576373\",\"name\":\"I. Melnyk\"},{\"authorId\":\"2211263\",\"name\":\"Youssef Mroueh\"},{\"authorId\":\"8350409\",\"name\":\"I. Padhi\"},{\"authorId\":\"2535094\",\"name\":\"Mattia Rigotti\"},{\"authorId\":\"153598395\",\"name\":\"J. Ross\"},{\"authorId\":\"1999174380\",\"name\":\"Yair Schiff\"},{\"authorId\":\"49832828\",\"name\":\"R. A. Young\"},{\"authorId\":\"2679155\",\"name\":\"Brian M. Belgodere\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5d4b265d7f80b185c618fb230ea14dcf909beed7\",\"title\":\"Image Captioning as an Assistive Technology: Lessons Learned from VizWiz 2020 Challenge\",\"url\":\"https://www.semanticscholar.org/paper/5d4b265d7f80b185c618fb230ea14dcf909beed7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"18111246\",\"name\":\"Bogdan Mazoure\"},{\"authorId\":\"33554869\",\"name\":\"Thang Doan\"},{\"authorId\":\"2238154\",\"name\":\"S. Ray\"}],\"doi\":\"10.18653/v1/W18-6240\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2b852a4e5026ab962050a0ef23a6892e06abb152\",\"title\":\"EmojiGAN: learning emojis distributions with a generative model\",\"url\":\"https://www.semanticscholar.org/paper/2b852a4e5026ab962050a0ef23a6892e06abb152\",\"venue\":\"WASSA@EMNLP\",\"year\":2018},{\"arxivId\":\"1705.11001\",\"authors\":[{\"authorId\":\"143786724\",\"name\":\"Kevin Lin\"},{\"authorId\":\"7379232\",\"name\":\"Dianqi Li\"},{\"authorId\":\"50045602\",\"name\":\"Xiaodong He\"},{\"authorId\":\"144463556\",\"name\":\"M. Sun\"},{\"authorId\":\"51064498\",\"name\":\"Zhengyou Zhang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a88f86093e6f2d14761d4b8cbdcadfeff496c948\",\"title\":\"Adversarial Ranking for Language Generation\",\"url\":\"https://www.semanticscholar.org/paper/a88f86093e6f2d14761d4b8cbdcadfeff496c948\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1806.02934\",\"authors\":[{\"authorId\":\"51043791\",\"name\":\"A. Kalyan\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"145721096\",\"name\":\"A. Kannan\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d2237f995d280edb8a47e27886261709ea3f654a\",\"title\":\"Learn from Your Neighbor: Learning Multi-modal Mappings from Sparse Annotations\",\"url\":\"https://www.semanticscholar.org/paper/d2237f995d280edb8a47e27886261709ea3f654a\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38593127\",\"name\":\"Wei Wang\"},{\"authorId\":\"16215052\",\"name\":\"Hai-Tao Zheng\"},{\"authorId\":\"38314901\",\"name\":\"H. Liu\"}],\"doi\":\"10.1007/978-3-030-16142-2_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"542805bb3421578e390de5ee249e675f103050ba\",\"title\":\"User Preference-Aware Review Generation\",\"url\":\"https://www.semanticscholar.org/paper/542805bb3421578e390de5ee249e675f103050ba\",\"venue\":\"PAKDD\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2715920\",\"name\":\"Malihe Alikhani\"},{\"authorId\":\"144884556\",\"name\":\"Matthew Stone\"}],\"doi\":\"10.18653/v1/W19-1806\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5834b21b80c8ec68d508684d25a613a604f06479\",\"title\":\"\\u201cCaption\\u201d as a Coherence Relation: Evidence and Implications\",\"url\":\"https://www.semanticscholar.org/paper/5834b21b80c8ec68d508684d25a613a604f06479\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1803.04376\",\"authors\":[{\"authorId\":\"3212867\",\"name\":\"R. Luo\"},{\"authorId\":\"31844147\",\"name\":\"Brian L. Price\"},{\"authorId\":\"145823372\",\"name\":\"S. Cohen\"},{\"authorId\":\"2490189\",\"name\":\"Gregory Shakhnarovich\"}],\"doi\":\"10.1109/CVPR.2018.00728\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7c1802d8d43dfe783650a03f03d41609fa5ae91e\",\"title\":\"Discriminability Objective for Training Descriptive Captions\",\"url\":\"https://www.semanticscholar.org/paper/7c1802d8d43dfe783650a03f03d41609fa5ae91e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1808.04538\",\"authors\":[{\"authorId\":\"46227885\",\"name\":\"Satya Krishna Gorti\"},{\"authorId\":\"20713590\",\"name\":\"Jeremy Ma\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c98643d08747205ecca5a1380d2ab22cdf622259\",\"title\":\"Text-to-Image-to-Text Translation using Cycle Consistent Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/c98643d08747205ecca5a1380d2ab22cdf622259\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1812.01525\",\"authors\":[{\"authorId\":\"2372537\",\"name\":\"Hang Chu\"},{\"authorId\":\"51344879\",\"name\":\"D. Li\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":\"10.1109/CVPR.2018.00743\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b09a35b0ee3f1b51fa809ca6a1f70528d910b366\",\"title\":\"A Face-to-Face Neural Conversation Model\",\"url\":\"https://www.semanticscholar.org/paper/b09a35b0ee3f1b51fa809ca6a1f70528d910b366\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46576324\",\"name\":\"Kevin P. Lin\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"cbbbd89435dbd21458dda069d00717125f757204\",\"title\":\"C L ] 1 6 A pr 2 01 8 Adversarial Ranking for Language Generation\",\"url\":\"https://www.semanticscholar.org/paper/cbbbd89435dbd21458dda069d00717125f757204\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72471322\",\"name\":\"H. Roman\"},{\"authorId\":\"145951921\",\"name\":\"B. Yang\"},{\"authorId\":\"48985596\",\"name\":\"Michelle Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7651ce29205e634699ac9776a00a2287b944411f\",\"title\":\"Photoshop 2 . 0 : Generative Adversarial Networks for Photo Editing\",\"url\":\"https://www.semanticscholar.org/paper/7651ce29205e634699ac9776a00a2287b944411f\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145359993\",\"name\":\"Fabian Karl\"},{\"authorId\":\"2388081\",\"name\":\"Mikko Lauri\"},{\"authorId\":\"31565315\",\"name\":\"Chris Biemann\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dfd1533d49d0213278d3d3301491cbe40f4d100b\",\"title\":\"Creating Information-maximizing Natural Language Messages Through Image Captioning-Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/dfd1533d49d0213278d3d3301491cbe40f4d100b\",\"venue\":\"KONVENS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47458613\",\"name\":\"A. Tripathi\"},{\"authorId\":\"145305735\",\"name\":\"Siddharth Srivastava\"},{\"authorId\":\"144174561\",\"name\":\"R. Kothari\"}],\"doi\":\"10.1007/978-3-030-04780-1_23\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a819e54b2d980dcff85ac8ab13801178aac5b59a\",\"title\":\"Deep Neural Network Based Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/a819e54b2d980dcff85ac8ab13801178aac5b59a\",\"venue\":\"BDA\",\"year\":2018},{\"arxivId\":\"2012.07333\",\"authors\":[{\"authorId\":\"1733071048\",\"name\":\"Chao Zeng\"},{\"authorId\":\"1687386\",\"name\":\"S. Kwong\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d7212df671c50beb567e3d3d608b0c14405c40e3\",\"title\":\"Intrinsic Image Captioning Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/d7212df671c50beb567e3d3d608b0c14405c40e3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.13659\",\"authors\":[{\"authorId\":\"14214933\",\"name\":\"Xingang Pan\"},{\"authorId\":\"31818765\",\"name\":\"Xiaohang Zhan\"},{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"},{\"authorId\":\"144389940\",\"name\":\"Ping Luo\"}],\"doi\":\"10.1007/978-3-030-58536-5_16\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7101bc1c316740d99cd87185586829291a983a1d\",\"title\":\"Exploiting Deep Generative Prior for Versatile Image Restoration and Manipulation\",\"url\":\"https://www.semanticscholar.org/paper/7101bc1c316740d99cd87185586829291a983a1d\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2011.05552\",\"authors\":[{\"authorId\":\"1914643328\",\"name\":\"A. Xue\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d6dc8e74f443a16d233163bcc72bb3a254bfe15\",\"title\":\"End-to-End Chinese Landscape Painting Creation Using Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/3d6dc8e74f443a16d233163bcc72bb3a254bfe15\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1705.07962\",\"authors\":[{\"authorId\":\"2796188\",\"name\":\"Tony Beltramelli\"}],\"doi\":\"10.1145/3220134.3220135\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9858b40d23d329151f202b76aac7ca515dee5913\",\"title\":\"pix2code: Generating Code from a Graphical User Interface Screenshot\",\"url\":\"https://www.semanticscholar.org/paper/9858b40d23d329151f202b76aac7ca515dee5913\",\"venue\":\"EICS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405686623\",\"name\":\"Nils Murrugarra-Llerena\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":\"10.1109/CVPR.2019.00659\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f23a5c29f227c2653014450284b7aa15ad9f88eb\",\"title\":\"Cross-Modality Personalization for Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/f23a5c29f227c2653014450284b7aa15ad9f88eb\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1801.09597\",\"authors\":[{\"authorId\":\"33999307\",\"name\":\"P. Andersen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"23a46bd009311dee8ea8b7c149b4f15d91a0c079\",\"title\":\"Deep Reinforcement Learning using Capsules in Advanced Game Environments\",\"url\":\"https://www.semanticscholar.org/paper/23a46bd009311dee8ea8b7c149b4f15d91a0c079\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151034836\",\"name\":\"I. Hrga\"},{\"authorId\":\"1382503013\",\"name\":\"Marina Ivasic-Kos\"}],\"doi\":\"10.23919/MIPRO.2019.8756821\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2c602c5ac9c6de0108b8bd7d4075f5f2da2e790c\",\"title\":\"Deep Image Captioning: An Overview\",\"url\":\"https://www.semanticscholar.org/paper/2c602c5ac9c6de0108b8bd7d4075f5f2da2e790c\",\"venue\":\"2019 42nd International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49776272\",\"name\":\"Pengfei Cao\"},{\"authorId\":\"47087612\",\"name\":\"Z. Yang\"},{\"authorId\":\"144526347\",\"name\":\"L. Sun\"},{\"authorId\":\"145629787\",\"name\":\"Y. Liang\"},{\"authorId\":\"1717198\",\"name\":\"M. Yang\"},{\"authorId\":\"144479376\",\"name\":\"Renchu Guan\"}],\"doi\":\"10.1007/s11063-018-09973-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"16efc1a4c7cdf8bc6d49cc326542e1fe1c88456b\",\"title\":\"Image Captioning with Bidirectional Semantic Attention-Based Guiding of Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/16efc1a4c7cdf8bc6d49cc326542e1fe1c88456b\",\"venue\":\"Neural Processing Letters\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145066124\",\"name\":\"Bin Guo\"},{\"authorId\":\"46506266\",\"name\":\"Haiying Wang\"},{\"authorId\":\"151260226\",\"name\":\"Yasan Ding\"},{\"authorId\":\"117889029\",\"name\":\"Shaoyang Hao\"},{\"authorId\":\"79953570\",\"name\":\"Yueqi Sun\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"891082eb8ec9796d9e6041a93c2dfcf1654daf76\",\"title\":\"1 c-TextGen : Conditional Text Generation for Harmonious Human-Machine Interaction\",\"url\":\"https://www.semanticscholar.org/paper/891082eb8ec9796d9e6041a93c2dfcf1654daf76\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eccfd6174709c285d62b11fb3da9b68d485ca883\",\"title\":\"Integrating Rule-based Entity Masking into Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/eccfd6174709c285d62b11fb3da9b68d485ca883\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1808.04364\",\"authors\":[{\"authorId\":\"3101288\",\"name\":\"Qiongkai Xu\"},{\"authorId\":\"14352700\",\"name\":\"Juyan Zhang\"},{\"authorId\":\"14564042\",\"name\":\"Lizhen Qu\"},{\"authorId\":\"33650938\",\"name\":\"Lexing Xie\"},{\"authorId\":\"1718786\",\"name\":\"R. Nock\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d407ad82df08aed159c86606161dff6a32386968\",\"title\":\"D-PAGE: Diverse Paraphrase Generation\",\"url\":\"https://www.semanticscholar.org/paper/d407ad82df08aed159c86606161dff6a32386968\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6131290\",\"name\":\"X. Yang\"},{\"authorId\":\"152261446\",\"name\":\"W. Xu\"},{\"authorId\":\"48383658\",\"name\":\"Q. Jia\"},{\"authorId\":\"8998684\",\"name\":\"L. Li\"},{\"authorId\":\"123309862\",\"name\":\"Zhu Wannian\"},{\"authorId\":\"72451089\",\"name\":\"J. Tian\"},{\"authorId\":\"46485351\",\"name\":\"H. Xu\"}],\"doi\":\"10.1016/J.DT.2019.06.021\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f24491b364ca8f7006a091256c511f972d785c1d\",\"title\":\"Research on extraction and reproduction of deformation camouflage spot based on generative adversarial network model\",\"url\":\"https://www.semanticscholar.org/paper/f24491b364ca8f7006a091256c511f972d785c1d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2007.15780\",\"authors\":[{\"authorId\":\"3360992\",\"name\":\"Cristina Garbacea\"},{\"authorId\":\"1743469\",\"name\":\"Q. Mei\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"64da659c0687762359226b4cf455520c78acd165\",\"title\":\"Neural Language Generation: Formulation, Methods, and Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/64da659c0687762359226b4cf455520c78acd165\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41052836\",\"name\":\"Anya Belz\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"}],\"doi\":\"10.1017/S1351324918000086\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d740802aa22dbc187fe5df39108ba493b34d2839\",\"title\":\"From image to language and back again\",\"url\":\"https://www.semanticscholar.org/paper/d740802aa22dbc187fe5df39108ba493b34d2839\",\"venue\":\"Nat. Lang. Eng.\",\"year\":2018},{\"arxivId\":\"1909.10430\",\"authors\":[{\"authorId\":\"3096279\",\"name\":\"Gregor Wiedemann\"},{\"authorId\":\"2194679\",\"name\":\"Steffen Remus\"},{\"authorId\":\"102421494\",\"name\":\"Avi Chawla\"},{\"authorId\":\"31565315\",\"name\":\"Chris Biemann\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ba8b3d0d2b09bc2b56c6d3f153919786d9fc3075\",\"title\":\"Does BERT Make Any Sense? Interpretable Word Sense Disambiguation with Contextualized Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/ba8b3d0d2b09bc2b56c6d3f153919786d9fc3075\",\"venue\":\"KONVENS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1716221829\",\"name\":\"Xueting Cao\"},{\"authorId\":\"66301964\",\"name\":\"Shenghui Rong\"},{\"authorId\":\"49421522\",\"name\":\"Yongbin Liu\"},{\"authorId\":\"8772032\",\"name\":\"Tengyue Li\"},{\"authorId\":\"123451851\",\"name\":\"Q. Wang\"},{\"authorId\":\"40145946\",\"name\":\"Bo He\"}],\"doi\":\"10.1109/ACCESS.2020.3002593\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"e5534bdd8204bdd21438fb65108f4b604c07b1bc\",\"title\":\"NUICNet: Non-Uniform Illumination Correction for Underwater Image Using Fully Convolutional Network\",\"url\":\"https://www.semanticscholar.org/paper/e5534bdd8204bdd21438fb65108f4b604c07b1bc\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1810.11735\",\"authors\":[{\"authorId\":\"32251567\",\"name\":\"Shikib Mehri\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a82034bd78ee09117baa35ab23b9d600a7509167\",\"title\":\"Middle-Out Decoding\",\"url\":\"https://www.semanticscholar.org/paper/a82034bd78ee09117baa35ab23b9d600a7509167\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1909.13403\",\"authors\":[{\"authorId\":\"3354281\",\"name\":\"Z. Lin\"},{\"authorId\":\"31751558\",\"name\":\"Alankar Jain\"},{\"authorId\":\"1838891\",\"name\":\"C. Wang\"},{\"authorId\":\"47706877\",\"name\":\"G. Fanti\"},{\"authorId\":\"145145415\",\"name\":\"V. Sekar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"15135d1dfa1c2e765bf3d946d797697715a55037\",\"title\":\"Generating High-fidelity, Synthetic Time Series Datasets with DoppelGANger\",\"url\":\"https://www.semanticscholar.org/paper/15135d1dfa1c2e765bf3d946d797697715a55037\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2003.01826\",\"authors\":[{\"authorId\":\"123898484\",\"name\":\"Ricard Durall\"},{\"authorId\":\"3316866\",\"name\":\"Margret Keuper\"},{\"authorId\":\"3299100\",\"name\":\"J. Keuper\"}],\"doi\":\"10.1109/CVPR42600.2020.00791\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4df3b534beeba05ba930814162ea6e19948c5fcd\",\"title\":\"Watch Your Up-Convolution: CNN Based Generative Deep Neural Networks Are Failing to Reproduce Spectral Distributions\",\"url\":\"https://www.semanticscholar.org/paper/4df3b534beeba05ba930814162ea6e19948c5fcd\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[],\"doi\":\"10.35940/ijrte.b1472.0982s1119\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d23256c631bde5d1c88a5f6ed139a458c45c6b54\",\"title\":\"Prediction of Caption and Emoji of an Image using Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/d23256c631bde5d1c88a5f6ed139a458c45c6b54\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1803.11544\",\"authors\":[{\"authorId\":\"49359942\",\"name\":\"C. Rupprecht\"},{\"authorId\":\"3422200\",\"name\":\"I. Laina\"},{\"authorId\":\"145587210\",\"name\":\"Nassir Navab\"},{\"authorId\":\"1678633\",\"name\":\"Gregory Hager\"},{\"authorId\":\"2266326\",\"name\":\"Federico Tombari\"}],\"doi\":\"10.1109/CVPR.2018.00892\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a334442b493501bb60a53dc3e689fc569965ad81\",\"title\":\"Guide Me: Interacting with Deep Networks\",\"url\":\"https://www.semanticscholar.org/paper/a334442b493501bb60a53dc3e689fc569965ad81\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1809.07294\",\"authors\":[{\"authorId\":\"144131805\",\"name\":\"Xin Yi\"},{\"authorId\":\"2457425\",\"name\":\"E. Walia\"},{\"authorId\":\"14655510\",\"name\":\"P. Babyn\"}],\"doi\":\"10.1016/j.media.2019.101552\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"acbeebdfd9dd3456628604eefcd53f50f974b132\",\"title\":\"Generative Adversarial Network in Medical Imaging: A Review\",\"url\":\"https://www.semanticscholar.org/paper/acbeebdfd9dd3456628604eefcd53f50f974b132\",\"venue\":\"Medical Image Anal.\",\"year\":2019},{\"arxivId\":\"2010.08189\",\"authors\":[{\"authorId\":\"2283009\",\"name\":\"W. Chen\"},{\"authorId\":\"46315247\",\"name\":\"W. Wang\"},{\"authorId\":\"87109212\",\"name\":\"Li Liu\"},{\"authorId\":\"1731570\",\"name\":\"M. Lew\"}],\"doi\":\"10.1016/j.neucom.2020.10.042\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"61ba6969078b7358c61f7eb93b4150ab0e4f329b\",\"title\":\"New Ideas and Trends in Deep Multimodal Content Understanding: A Review\",\"url\":\"https://www.semanticscholar.org/paper/61ba6969078b7358c61f7eb93b4150ab0e4f329b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"104150443\",\"name\":\"Zeqin Huang\"},{\"authorId\":\"9118491\",\"name\":\"Zhongzhi Shi\"}],\"doi\":\"10.1007/978-3-030-46931-3_29\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f08ac1aa8bfc804414b1e5a2bb98203337368807\",\"title\":\"Image Caption Combined with GAN Training Method\",\"url\":\"https://www.semanticscholar.org/paper/f08ac1aa8bfc804414b1e5a2bb98203337368807\",\"venue\":\"Intelligent Information Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390626344\",\"name\":\"Zhiyuan Liu\"},{\"authorId\":\"2427350\",\"name\":\"Yankai Lin\"},{\"authorId\":\"1753344\",\"name\":\"M. Sun\"}],\"doi\":\"10.1007/978-981-15-5573-2_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7cd0c93b77bd2cf085c02c7a98118b6b43592110\",\"title\":\"Cross-Modal Representation\",\"url\":\"https://www.semanticscholar.org/paper/7cd0c93b77bd2cf085c02c7a98118b6b43592110\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1810.04020\",\"authors\":[{\"authorId\":\"47412302\",\"name\":\"M. Z. Hossain\"},{\"authorId\":\"2470423\",\"name\":\"Ferdous Sohel\"},{\"authorId\":\"2222847\",\"name\":\"M. F. Shiratuddin\"},{\"authorId\":\"47028380\",\"name\":\"Hamid Laga\"}],\"doi\":\"10.1145/3295748\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7e27d44e3fac723ccb703e0a83b22711bd42efe8\",\"title\":\"A Comprehensive Survey of Deep Learning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7e27d44e3fac723ccb703e0a83b22711bd42efe8\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1808.07258\",\"authors\":[{\"authorId\":\"48695200\",\"name\":\"Chia-Che Chang\"},{\"authorId\":\"49044307\",\"name\":\"Chieh Hubert Lin\"},{\"authorId\":\"2720110\",\"name\":\"Che-Rung Lee\"},{\"authorId\":\"144854012\",\"name\":\"Da-Cheng Juan\"},{\"authorId\":\"1725923\",\"name\":\"W. Wei\"},{\"authorId\":\"1803730\",\"name\":\"Hwann-Tzong Chen\"}],\"doi\":\"10.1007/978-3-030-01234-2_13\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"59e91bd46492391beadce041806297e856af6ee6\",\"title\":\"Escaping from Collapsing Modes in a Constrained Space\",\"url\":\"https://www.semanticscholar.org/paper/59e91bd46492391beadce041806297e856af6ee6\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40796401\",\"name\":\"A. I. K\\u00e1roly\"},{\"authorId\":\"9095824\",\"name\":\"M\\u00e1rta Tak\\u00e1cs\"},{\"authorId\":\"15762156\",\"name\":\"P\\u00e9ter Galambos\"}],\"doi\":\"10.1109/IJCNN.2019.8852095\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d23ac37b9e255b8d2a86f0681c2a565119ba3ae0\",\"title\":\"OCSVM-based Evaluation Method for Generative Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/d23ac37b9e255b8d2a86f0681c2a565119ba3ae0\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":\"1901.00398\",\"authors\":[{\"authorId\":\"3360992\",\"name\":\"Cristina Garbacea\"},{\"authorId\":\"40502796\",\"name\":\"Samuel Carton\"},{\"authorId\":\"2601405\",\"name\":\"S. Yan\"},{\"authorId\":\"1743469\",\"name\":\"Q. Mei\"}],\"doi\":\"10.18653/v1/D19-1409\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"4260a9214dc23ce8149cf966ecf047d54597d798\",\"title\":\"Judge the Judges: A Large-Scale Evaluation Study of Neural Language Models for Online Review Generation\",\"url\":\"https://www.semanticscholar.org/paper/4260a9214dc23ce8149cf966ecf047d54597d798\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7808048\",\"name\":\"M. Bucher\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d423f37185a2210d5e47f24d4792e68d0088cd52\",\"title\":\"Apprentissage et exploitation de repr\\u00e9sentations s\\u00e9mantiques pour la classification et la recherche d'images. (Learning and exploiting semantic representations for image classification and retrieval)\",\"url\":\"https://www.semanticscholar.org/paper/d423f37185a2210d5e47f24d4792e68d0088cd52\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1809.06227\",\"authors\":[{\"authorId\":\"3441420\",\"name\":\"Tszhang Guo\"},{\"authorId\":\"3307026\",\"name\":\"S. Chang\"},{\"authorId\":\"2482533\",\"name\":\"Mo Yu\"},{\"authorId\":\"144654778\",\"name\":\"K. Bai\"}],\"doi\":\"10.18653/v1/D18-1083\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a78199a2cc678818489087454fe1150db4870196\",\"title\":\"Improving Reinforcement Learning Based Image Captioning with Natural Language Prior\",\"url\":\"https://www.semanticscholar.org/paper/a78199a2cc678818489087454fe1150db4870196\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49299019\",\"name\":\"Junnan Li\"},{\"authorId\":\"3026404\",\"name\":\"Yongkang Wong\"},{\"authorId\":\"47521917\",\"name\":\"Q. Zhao\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e93c977025e2829f852fc8c1e8f9547c3588dbf0\",\"title\":\"vv 1 camping tent food fire Residual BRNN Input Video Visual Encoder ( CNN ) Video Encoder Sentence Encoder Word 2 Vecs Sentence Semantic Embedding vv 2 vv 3 vvNN \\u2212 1 vvNN vv Video Semantic Embedding xx\",\"url\":\"https://www.semanticscholar.org/paper/e93c977025e2829f852fc8c1e8f9547c3588dbf0\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66353591\",\"name\":\"Amaia Salvador Aguilera\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4cb1819c27e207a2afeccfe450b931cc317de1e1\",\"title\":\"Computer vision beyond the visible : image understanding through language\",\"url\":\"https://www.semanticscholar.org/paper/4cb1819c27e207a2afeccfe450b931cc317de1e1\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144249776\",\"name\":\"H. Chen\"},{\"authorId\":\"3393888\",\"name\":\"M. Giuffrida\"},{\"authorId\":\"4553782\",\"name\":\"P. Doerner\"},{\"authorId\":\"1919157\",\"name\":\"S. Tsaftaris\"}],\"doi\":\"10.1109/CVPRW.2019.00318\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9f41b3500e556203de6659ed57a3d8fdd5496a4c\",\"title\":\"Adversarial Large-Scale Root Gap Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/9f41b3500e556203de6659ed57a3d8fdd5496a4c\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Huan Zhao\"},{\"authorId\":\"1477990460\",\"name\":\"Tingting Li\"},{\"authorId\":\"35759866\",\"name\":\"Yufeng Xiao\"},{\"authorId\":null,\"name\":\"Yu Wang\"}],\"doi\":\"10.3390/e22091055\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"40c2c3fbc2f42710e814c94b1f0d8567fb940272\",\"title\":\"Improving Multi-Agent Generative Adversarial Nets with Variational Latent Representation\",\"url\":\"https://www.semanticscholar.org/paper/40c2c3fbc2f42710e814c94b1f0d8567fb940272\",\"venue\":\"Entropy\",\"year\":2020},{\"arxivId\":\"2011.04264\",\"authors\":[{\"authorId\":\"32763968\",\"name\":\"A. Fisch\"},{\"authorId\":\"2544107\",\"name\":\"Kenton Lee\"},{\"authorId\":\"1744179\",\"name\":\"Ming-Wei Chang\"},{\"authorId\":\"144797264\",\"name\":\"J. Clark\"},{\"authorId\":\"1741283\",\"name\":\"R. Barzilay\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8ca71f61139c69131ab200368a30a3dc72fa6785\",\"title\":\"CapWAP: Captioning with a Purpose\",\"url\":\"https://www.semanticscholar.org/paper/8ca71f61139c69131ab200368a30a3dc72fa6785\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2012.07000\",\"authors\":[{\"authorId\":\"145144396\",\"name\":\"Dandan Song\"},{\"authorId\":\"4274864\",\"name\":\"Siyi Ma\"},{\"authorId\":\"2037300711\",\"name\":\"Zhanchen Sun\"},{\"authorId\":\"3389167\",\"name\":\"S. Yang\"},{\"authorId\":\"31364087\",\"name\":\"Lejian Liao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7912b8bb86a6d32ed355651d05ff0cbf37e9504e\",\"title\":\"KVL-BERT: Knowledge Enhanced Visual-and-Linguistic BERT for Visual Commonsense Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/7912b8bb86a6d32ed355651d05ff0cbf37e9504e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48394426\",\"name\":\"Naeha Sharif\"},{\"authorId\":\"8799308\",\"name\":\"U. Nadeem\"},{\"authorId\":\"14752125\",\"name\":\"Syed Afaq Ali Shah\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"1980026040\",\"name\":\"Wei Liu\"}],\"doi\":\"10.1007/978-3-030-49724-8_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8885ae1cbdac1d27443167689ed872dfe46c9e3f\",\"title\":\"Vision to Language: Methods, Metrics and Datasets\",\"url\":\"https://www.semanticscholar.org/paper/8885ae1cbdac1d27443167689ed872dfe46c9e3f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1712.04301\",\"authors\":[{\"authorId\":\"153859824\",\"name\":\"M. Mohammadi\"},{\"authorId\":\"1404786833\",\"name\":\"Ala Al-Fuqaha\"},{\"authorId\":\"1683936\",\"name\":\"Sameh Sorour\"},{\"authorId\":\"145837051\",\"name\":\"M. Guizani\"}],\"doi\":\"10.1109/COMST.2018.2844341\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d63b884d5ebc739f6e1bdf861fa9276260781404\",\"title\":\"Deep Learning for IoT Big Data and Streaming Analytics: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/d63b884d5ebc739f6e1bdf861fa9276260781404\",\"venue\":\"IEEE Communications Surveys & Tutorials\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46399735\",\"name\":\"Y. Liu\"},{\"authorId\":\"34639416\",\"name\":\"Meng-xi Guo\"},{\"authorId\":\"49051549\",\"name\":\"Jiayuan Zhang\"},{\"authorId\":\"46758870\",\"name\":\"Y. Zhu\"},{\"authorId\":\"46397160\",\"name\":\"Xiaodong Xie\"}],\"doi\":\"10.1145/3343031.3351025\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8127ea5f6dfcbf19d97daa64a44ecbb76181fd2b\",\"title\":\"A Novel Two-stage Separable Deep Learning Framework for Practical Blind Watermarking\",\"url\":\"https://www.semanticscholar.org/paper/8127ea5f6dfcbf19d97daa64a44ecbb76181fd2b\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"2007.03338\",\"authors\":[{\"authorId\":\"40651988\",\"name\":\"Marzieh Heidari\"},{\"authorId\":\"2862462\",\"name\":\"Mehdi Ghatee\"},{\"authorId\":\"1780566\",\"name\":\"A. Nickabadi\"},{\"authorId\":\"1796299590\",\"name\":\"Arash Pourhasan Nezhad\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"20b332af8399233b5fc33a7e7f98538bd4a82ab0\",\"title\":\"Diverse and Styled Image Captioning Using SVD-Based Mixture of Recurrent Experts\",\"url\":\"https://www.semanticscholar.org/paper/20b332af8399233b5fc33a7e7f98538bd4a82ab0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49359942\",\"name\":\"C. Rupprecht\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d9f931f3c70487e86c475fe18cfe16caf4f65d4e\",\"title\":\"Learning under Ambiguity through Multiple Predictions\",\"url\":\"https://www.semanticscholar.org/paper/d9f931f3c70487e86c475fe18cfe16caf4f65d4e\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9610143\",\"name\":\"Zhihao Fan\"},{\"authorId\":\"2712533\",\"name\":\"Zhongyu Wei\"},{\"authorId\":\"50695111\",\"name\":\"Siyuan Wang\"},{\"authorId\":\"1790227\",\"name\":\"X. Huang\"}],\"doi\":\"10.18653/v1/P19-1652\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aaf5e3afd61d0df6c483ca32faf8e7a9198b1557\",\"title\":\"Bridging by Word: Image Grounded Vocabulary Construction for Visual Captioning\",\"url\":\"https://www.semanticscholar.org/paper/aaf5e3afd61d0df6c483ca32faf8e7a9198b1557\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"2007.05597\",\"authors\":[{\"authorId\":\"3233864\",\"name\":\"S. Biswal\"},{\"authorId\":\"72612482\",\"name\":\"Peiye Zhuang\"},{\"authorId\":\"48188321\",\"name\":\"A. Pyrros\"},{\"authorId\":\"145643745\",\"name\":\"N. Siddiqui\"},{\"authorId\":\"143812875\",\"name\":\"O. Koyejo\"},{\"authorId\":\"1738536\",\"name\":\"Jimeng Sun\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0c3612f08814b86a5e44dfd1fe549acb7a1c1801\",\"title\":\"EMIXER: End-to-end Multimodal X-ray Generation via Self-supervision\",\"url\":\"https://www.semanticscholar.org/paper/0c3612f08814b86a5e44dfd1fe549acb7a1c1801\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1707.09700\",\"authors\":[{\"authorId\":\"2180892\",\"name\":\"Yikang Li\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"48884894\",\"name\":\"K. Wang\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1109/ICCV.2017.142\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf2de559e5a6235783e0762862f6e42192f142a8\",\"title\":\"Scene Graph Generation from Objects, Phrases and Region Captions\",\"url\":\"https://www.semanticscholar.org/paper/cf2de559e5a6235783e0762862f6e42192f142a8\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1811.05253\",\"authors\":[{\"authorId\":\"3491491\",\"name\":\"Shiyang Yan\"},{\"authorId\":\"5145427\",\"name\":\"Fangyu Wu\"},{\"authorId\":\"33830793\",\"name\":\"Jeremy S. Smith\"},{\"authorId\":\"40178769\",\"name\":\"Wenjin Lu\"},{\"authorId\":\"1782912\",\"name\":\"Bailing Zhang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b7294dd0ec8ff8d3353286bce6b4ace60f957a08\",\"title\":\"Image Captioning Based on a Hierarchical Attention Mechanism and Policy Gradient Optimization\",\"url\":\"https://www.semanticscholar.org/paper/b7294dd0ec8ff8d3353286bce6b4ace60f957a08\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1903.12020\",\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":\"10.1109/CVPR.2019.00432\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"90579a68e46b772a8e9aaca8ecbd06942d0b9b35\",\"title\":\"Describing Like Humans: On Diversity in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/90579a68e46b772a8e9aaca8ecbd06942d0b9b35\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1839363\",\"name\":\"Pierre L. Dognin\"},{\"authorId\":\"2576373\",\"name\":\"I. Melnyk\"},{\"authorId\":\"2211263\",\"name\":\"Youssef Mroueh\"},{\"authorId\":\"39320489\",\"name\":\"J. Ross\"},{\"authorId\":\"2500466\",\"name\":\"Tom Sercu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d7b10801e1ef598ac50ee5317d2a3a482f000826\",\"title\":\"Improved Adversarial Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/d7b10801e1ef598ac50ee5317d2a3a482f000826\",\"venue\":\"DGS@ICLR\",\"year\":2019},{\"arxivId\":\"1908.00169\",\"authors\":[{\"authorId\":\"150350159\",\"name\":\"Yadan Luo\"},{\"authorId\":\"145622169\",\"name\":\"Zi Huang\"},{\"authorId\":\"145527564\",\"name\":\"Z. Zhang\"},{\"authorId\":\"31115284\",\"name\":\"Jingjing Li\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"}],\"doi\":\"10.1145/3343031.3350961\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d4c8f6c4a2b744fcfd82a7d7c8041d87d2b5c250\",\"title\":\"Curiosity-driven Reinforcement Learning for Diverse Visual Paragraph Generation\",\"url\":\"https://www.semanticscholar.org/paper/d4c8f6c4a2b744fcfd82a7d7c8041d87d2b5c250\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1908.11602\",\"authors\":[{\"authorId\":\"50487517\",\"name\":\"Xudong Xu\"},{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/ICCV.2019.00097\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b7a5f074e06cf8d71e26fb5d25b86b4164a5bb54\",\"title\":\"Recursive Visual Sound Separation Using Minus-Plus Net\",\"url\":\"https://www.semanticscholar.org/paper/b7a5f074e06cf8d71e26fb5d25b86b4164a5bb54\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3257551\",\"name\":\"Xintong Yu\"},{\"authorId\":\"3441420\",\"name\":\"Tszhang Guo\"},{\"authorId\":\"145414746\",\"name\":\"Kun Fu\"},{\"authorId\":\"143900006\",\"name\":\"Lei Li\"},{\"authorId\":\"14966740\",\"name\":\"Changshui Zhang\"},{\"authorId\":\"1739414\",\"name\":\"Jianwei Zhang\"}],\"doi\":\"10.1109/IJCNN.2019.8851721\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f33c9e9e76e1d41d64d21c09ae434b05d83bc7f6\",\"title\":\"Image Captioning with Partially Rewarded Imitation Learning\",\"url\":\"https://www.semanticscholar.org/paper/f33c9e9e76e1d41d64d21c09ae434b05d83bc7f6\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47968201\",\"name\":\"Lixin Liu\"},{\"authorId\":\"46741143\",\"name\":\"Jiajun Tang\"},{\"authorId\":\"145078589\",\"name\":\"Xiaojun Wan\"},{\"authorId\":\"35310979\",\"name\":\"Zongming Guo\"}],\"doi\":\"10.1109/ICCV.2019.00434\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b774d6cd89cb27e62f03f183b89b7cacc412e131\",\"title\":\"Generating Diverse and Descriptive Image Captions Using Visual Paraphrases\",\"url\":\"https://www.semanticscholar.org/paper/b774d6cd89cb27e62f03f183b89b7cacc412e131\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1910.12019\",\"authors\":[{\"authorId\":\"9728275\",\"name\":\"Huanhou Xiao\"},{\"authorId\":\"34875762\",\"name\":\"J. Shi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a17542ca3c7a39470bdbe70a2209c195be6d63df\",\"title\":\"Diverse Video Captioning Through Latent Variable Expansion with Conditional GAN\",\"url\":\"https://www.semanticscholar.org/paper/a17542ca3c7a39470bdbe70a2209c195be6d63df\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144566098\",\"name\":\"Yang Fan\"},{\"authorId\":\"2073589\",\"name\":\"Jungang Xu\"},{\"authorId\":\"2643170\",\"name\":\"Yingfei Sun\"},{\"authorId\":null,\"name\":\"Yiyu Wang\"}],\"doi\":\"10.1007/978-3-030-30490-4_23\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"74e4ab92bea5086239d4c0bae100897bb7f833b7\",\"title\":\"A Novel Image Captioning Method Based on Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/74e4ab92bea5086239d4c0bae100897bb7f833b7\",\"venue\":\"ICANN\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"117548227\",\"name\":\"Saloni Kalra\"},{\"authorId\":\"88872765\",\"name\":\"Alka Leekha\"}],\"doi\":\"10.1080/02522667.2020.1715602\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"117333afd2ce2d80dd195dc5c5087f1b2b6bebdc\",\"title\":\"Survey of convolutional neural networks for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/117333afd2ce2d80dd195dc5c5087f1b2b6bebdc\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"113001756\",\"name\":\"A. Deshpande\"},{\"authorId\":\"29956361\",\"name\":\"Jyoti Aneja\"},{\"authorId\":\"24952249\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"144016256\",\"name\":\"D. Forsyth\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"b2c60061ad32e28eb1e20aff42e062c9160786be\",\"title\":\"Diverse and Controllable Image Captioning with Part-of-Speech Guidance\",\"url\":\"https://www.semanticscholar.org/paper/b2c60061ad32e28eb1e20aff42e062c9160786be\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1712.07576\",\"authors\":[{\"authorId\":\"8551209\",\"name\":\"Ching-Yao Chuang\"},{\"authorId\":\"22133106\",\"name\":\"Jiaman Li\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":\"10.1109/CVPR.2018.00108\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cfa58662750d752ed96184c9fde90150ec89d234\",\"title\":\"Learning to Act Properly: Predicting and Explaining Affordances from Images\",\"url\":\"https://www.semanticscholar.org/paper/cfa58662750d752ed96184c9fde90150ec89d234\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1804.00861\",\"authors\":[{\"authorId\":\"7379232\",\"name\":\"Dianqi Li\"},{\"authorId\":\"1788124\",\"name\":\"Qiuyuan Huang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"},{\"authorId\":\"144463557\",\"name\":\"M. Sun\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"39144e468bde0424d38a3f20a6b62ddec4b459ae\",\"title\":\"Generating Diverse and Accurate Visual Captions by Comparative Adversarial Learning\",\"url\":\"https://www.semanticscholar.org/paper/39144e468bde0424d38a3f20a6b62ddec4b459ae\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1809.00681\",\"authors\":[{\"authorId\":\"2479187\",\"name\":\"Moitreya Chatterjee\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1007/978-3-030-01216-8_45\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a27973d90c1427369cb10aa0202d671f0422e21e\",\"title\":\"Diverse and Coherent Paragraph Generation from Images\",\"url\":\"https://www.semanticscholar.org/paper/a27973d90c1427369cb10aa0202d671f0422e21e\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143602033\",\"name\":\"Anan Liu\"},{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"144536249\",\"name\":\"W. Nie\"},{\"authorId\":\"2788104\",\"name\":\"Yuting Su\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.24963/ijcai.2018/114\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2b5a95ec7882bf329c4203513e606aa91d4174c5\",\"title\":\"Multi-Level Policy and Reward Reinforcement Learning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/2b5a95ec7882bf329c4203513e606aa91d4174c5\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145704540\",\"name\":\"Li Ren\"},{\"authorId\":\"2272096\",\"name\":\"Guo-Jun Qi\"},{\"authorId\":\"66719728\",\"name\":\"Kien A. Hua\"}],\"doi\":\"10.1109/WACV.2019.00034\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"449b9189e3058d33f871dfd3b07cc75a717038f7\",\"title\":\"Improving Diversity of Image Captioning Through Variational Autoencoders and Adversarial Learning\",\"url\":\"https://www.semanticscholar.org/paper/449b9189e3058d33f871dfd3b07cc75a717038f7\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48391641\",\"name\":\"Y. Tian\"},{\"authorId\":\"9695761\",\"name\":\"J. Engel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"88c96a1cb8a0d4a071495ca5f0d6f0a64dd887c3\",\"title\":\"Latent Domain Transfer: Crossing modalities with Bridging Autoencoders\",\"url\":\"https://www.semanticscholar.org/paper/88c96a1cb8a0d4a071495ca5f0d6f0a64dd887c3\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1834105\",\"name\":\"Nancy Fulda\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4cb056e8353787fdbae5dbeb05aa7e8facb6939b\",\"title\":\"Semantically Aligned Sentence-Level Embeddings for Agent Autonomy and Natural Language Understanding\",\"url\":\"https://www.semanticscholar.org/paper/4cb056e8353787fdbae5dbeb05aa7e8facb6939b\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3409740\",\"name\":\"Ziyu Xue\"},{\"authorId\":\"39494411\",\"name\":\"Lei Wang\"},{\"authorId\":\"2834810\",\"name\":\"Peiyu Guo\"}],\"doi\":\"10.1109/icis46139.2019.8940218\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7344b254af85b53c5e989579b1d18fbf946c03de\",\"title\":\"Slot based Image Captioning with WGAN\",\"url\":\"https://www.semanticscholar.org/paper/7344b254af85b53c5e989579b1d18fbf946c03de\",\"venue\":\"2019 IEEE/ACIS 18th International Conference on Computer and Information Science (ICIS)\",\"year\":2019},{\"arxivId\":\"2009.09758\",\"authors\":[{\"authorId\":\"114952298\",\"name\":\"Marie-Anne Lachaux\"},{\"authorId\":\"2319608\",\"name\":\"Armand Joulin\"},{\"authorId\":\"1830914\",\"name\":\"Guillaume Lample\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.256\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5b947087d7d392b5bd5eaeb7ae6987564c2e8d35\",\"title\":\"Target Conditioning for One-to-Many Generation\",\"url\":\"https://www.semanticscholar.org/paper/5b947087d7d392b5bd5eaeb7ae6987564c2e8d35\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"1804.09160\",\"authors\":[{\"authorId\":\"48631993\",\"name\":\"Xin Eric Wang\"},{\"authorId\":\"2928777\",\"name\":\"Wenhu Chen\"},{\"authorId\":\"1706938\",\"name\":\"Y. Wang\"},{\"authorId\":\"1682479\",\"name\":\"William Yang Wang\"}],\"doi\":\"10.18653/v1/P18-1083\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0af4274ddc948bb175be7662a699a8270878ced2\",\"title\":\"No Metrics Are Perfect: Adversarial Reward Learning for Visual Storytelling\",\"url\":\"https://www.semanticscholar.org/paper/0af4274ddc948bb175be7662a699a8270878ced2\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":\"1703.10476\",\"authors\":[{\"authorId\":\"38314306\",\"name\":\"Rakshith Shetty\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1109/ICCV.2017.445\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1c0a6854b793ca8ad281513c184318b73d4868c4\",\"title\":\"Speaking the Same Language: Matching Machine to Human Captions by Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/1c0a6854b793ca8ad281513c184318b73d4868c4\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1643682004\",\"name\":\"He Zhao\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":\"10.1007/978-3-030-58526-6_46\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bd941a3cb2664715269cbbd30a4df6828799ac01\",\"title\":\"On Diverse Asynchronous Activity Anticipation\",\"url\":\"https://www.semanticscholar.org/paper/bd941a3cb2664715269cbbd30a4df6828799ac01\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2006.09267\",\"authors\":[{\"authorId\":\"1751231782\",\"name\":\"Amani Jaafer\"},{\"authorId\":\"37253181\",\"name\":\"G. Nilsson\"},{\"authorId\":\"51492663\",\"name\":\"G. Como\"}],\"doi\":\"10.1109/ITSC45102.2020.9294496\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"033a536dffb2cdb5141ea564456f68687d809b5f\",\"title\":\"Data Augmentation of IMU Signals and Evaluation via a Semi-Supervised Classification of Driving Behavior\",\"url\":\"https://www.semanticscholar.org/paper/033a536dffb2cdb5141ea564456f68687d809b5f\",\"venue\":\"2020 IEEE 23rd International Conference on Intelligent Transportation Systems (ITSC)\",\"year\":2020},{\"arxivId\":\"1905.11369\",\"authors\":[{\"authorId\":\"2299479\",\"name\":\"R. Arandjelovi\\u0107\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"461470832f30d7dcca7d58dc399190f70462ee55\",\"title\":\"Object Discovery with a Copy-Pasting GAN\",\"url\":\"https://www.semanticscholar.org/paper/461470832f30d7dcca7d58dc399190f70462ee55\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"112858943\",\"name\":\"Z. Liu\"},{\"authorId\":\"2427350\",\"name\":\"Yankai Lin\"},{\"authorId\":\"1753344\",\"name\":\"M. Sun\"}],\"doi\":\"10.1007/978-981-15-5573-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2f1107ea6b9b4147a808e9ae27757e214685e90a\",\"title\":\"Representation Learning for Natural Language Processing\",\"url\":\"https://www.semanticscholar.org/paper/2f1107ea6b9b4147a808e9ae27757e214685e90a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30185240\",\"name\":\"Yuning Qiu\"},{\"authorId\":\"32639375\",\"name\":\"Teruhisa Misu\"},{\"authorId\":\"2106794\",\"name\":\"C. Busso\"}],\"doi\":\"10.1145/3340555.3353749\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"c10d8d6838f82ffe3e11060f47ce3bee2e87f318\",\"title\":\"Driving Anomaly Detection with Conditional Generative Adversarial Network using Physiological and CAN-Bus Data\",\"url\":\"https://www.semanticscholar.org/paper/c10d8d6838f82ffe3e11060f47ce3bee2e87f318\",\"venue\":\"ICMI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"},{\"authorId\":\"1796216614\",\"name\":\"Siyu Huang\"},{\"authorId\":\"40518823\",\"name\":\"Haoyi Xiong\"},{\"authorId\":\"7824051\",\"name\":\"Xingjian Li\"},{\"authorId\":\"1721158\",\"name\":\"D. Dou\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"652885a326e1b5b978f4abeeb88e5fe518733f7e\",\"title\":\"Neighbours Matter: Image Captioning with Similar Images\",\"url\":\"https://www.semanticscholar.org/paper/652885a326e1b5b978f4abeeb88e5fe518733f7e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"754d61a4c298b55c15baef517298f17ad8bb576b\",\"title\":\"Generating Syntactically Diverse Translations with Syntactic Codes\",\"url\":\"https://www.semanticscholar.org/paper/754d61a4c298b55c15baef517298f17ad8bb576b\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1807.09958\",\"authors\":[{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"50816334\",\"name\":\"D. Ye\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1007/978-3-030-01228-1_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"94e3b75a6732b5918c4c2b87d127a9216ff07efc\",\"title\":\"Rethinking the Form of Latent States in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/94e3b75a6732b5918c4c2b87d127a9216ff07efc\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145179162\",\"name\":\"Mingxing Zhang\"},{\"authorId\":\"144757965\",\"name\":\"Y. Yang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"50006507\",\"name\":\"Yanli Ji\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1109/TIP.2018.2855415\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"16a2a1bf612f9f9719a7945485f7e73324d18783\",\"title\":\"More is Better: Precise and Detailed Image Captioning Using Online Positive Recall and Missing Concepts Mining\",\"url\":\"https://www.semanticscholar.org/paper/16a2a1bf612f9f9719a7945485f7e73324d18783\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66014582\",\"name\":\"I.U. Kothalawala\"},{\"authorId\":\"29829191\",\"name\":\"T. Silva\"}],\"doi\":\"10.1109/ICTER.2018.8615538\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"507b1ae19a54c03f3eaf1e6332ea267622684f0b\",\"title\":\"Colour-based Image Generation using CGAN\",\"url\":\"https://www.semanticscholar.org/paper/507b1ae19a54c03f3eaf1e6332ea267622684f0b\",\"venue\":\"2018 18th International Conference on Advances in ICT for Emerging Regions (ICTer)\",\"year\":2018},{\"arxivId\":\"1904.01735\",\"authors\":[{\"authorId\":\"47539816\",\"name\":\"Jian-Guo Zhang\"},{\"authorId\":\"49402095\",\"name\":\"Pengcheng Zou\"},{\"authorId\":\"144695970\",\"name\":\"Z. Li\"},{\"authorId\":\"2389866\",\"name\":\"Yao Wan\"},{\"authorId\":\"5632521\",\"name\":\"Xiuming Pan\"},{\"authorId\":\"144815077\",\"name\":\"Y. Gong\"},{\"authorId\":\"144019071\",\"name\":\"Philip S. Yu\"}],\"doi\":\"10.18653/v1/N19-2009\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ee87912392e161a2f434350ecaff846162291ed5\",\"title\":\"Multi-Modal Generative Adversarial Network for Short Product Title Generation in Mobile E-Commerce\",\"url\":\"https://www.semanticscholar.org/paper/ee87912392e161a2f434350ecaff846162291ed5\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51043791\",\"name\":\"A. Kalyan\"},{\"authorId\":\"153149395\",\"name\":\"P. Anderson\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"883cb62237c50de7615c837a0830d6a88721112a\",\"title\":\"Trainable Decoding of Sets of Sequences for Neural Sequence Models\",\"url\":\"https://www.semanticscholar.org/paper/883cb62237c50de7615c837a0830d6a88721112a\",\"venue\":\"ICML\",\"year\":2019},{\"arxivId\":\"1910.14428\",\"authors\":[{\"authorId\":\"2406046\",\"name\":\"A. Mehrjou\"},{\"authorId\":\"2141405\",\"name\":\"Wittawat Jitkrittum\"},{\"authorId\":\"2276351\",\"name\":\"Krikamol Muandet\"},{\"authorId\":\"4080509\",\"name\":\"B. Scholkopf\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7695ad05116bfdf9a6d106b3ea356a37d41a7c0a\",\"title\":\"Kernel-Guided Training of Implicit Generative Models with Stability Guarantees\",\"url\":\"https://www.semanticscholar.org/paper/7695ad05116bfdf9a6d106b3ea356a37d41a7c0a\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1654128868\",\"name\":\"Sruthi K V\"},{\"authorId\":\"1654099368\",\"name\":\"Meharban M S\"}],\"doi\":\"10.1109/ICACCS48705.2020.9074468\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ef4c30847b135ee89138126350d8a0c401470559\",\"title\":\"Review on Image Captioning and Speech Synthesis Techniques\",\"url\":\"https://www.semanticscholar.org/paper/ef4c30847b135ee89138126350d8a0c401470559\",\"venue\":\"2020 6th International Conference on Advanced Computing and Communication Systems (ICACCS)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2675822\",\"name\":\"Tushar Karayil\"},{\"authorId\":\"67063678\",\"name\":\"A. Irfan\"},{\"authorId\":\"48258541\",\"name\":\"Federico Raue\"},{\"authorId\":\"33884920\",\"name\":\"J. Hees\"},{\"authorId\":\"145279674\",\"name\":\"A. Dengel\"}],\"doi\":\"10.1007/978-3-030-30490-4_25\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"52941a210e543707b530aa6daf32c18561d8ecc3\",\"title\":\"Conditional GANs for Image Captioning with Sentiments\",\"url\":\"https://www.semanticscholar.org/paper/52941a210e543707b530aa6daf32c18561d8ecc3\",\"venue\":\"ICANN\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144613170\",\"name\":\"S. Cao\"},{\"authorId\":\"2896701\",\"name\":\"G. An\"},{\"authorId\":\"4464686\",\"name\":\"ZhenXing Zheng\"},{\"authorId\":\"2383779\",\"name\":\"Qiu-Qi Ruan\"}],\"doi\":\"10.1016/j.neucom.2020.08.019\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f235982f603a740dcee9cff7c5de234878f80a3f\",\"title\":\"Interactions Guided Generative Adversarial Network for unsupervised image captioning\",\"url\":\"https://www.semanticscholar.org/paper/f235982f603a740dcee9cff7c5de234878f80a3f\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152546466\",\"name\":\"Shashank Tripathi\"},{\"authorId\":\"82997838\",\"name\":\"Siddhant Ranade\"},{\"authorId\":\"36183106\",\"name\":\"Ambrish Tyagi\"},{\"authorId\":\"145972492\",\"name\":\"Amit Agrawal\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"507e65cf5994f012d7732b78006398433a945df5\",\"title\":\"PoseNet3D: Unsupervised 3D Human Shape and Pose Estimation\",\"url\":\"https://www.semanticscholar.org/paper/507e65cf5994f012d7732b78006398433a945df5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738647655\",\"name\":\"Emiel van Miltenburg\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"adf57a2bdcffc38238e64d4ae797c12405281173\",\"title\":\"How Do Image Description Systems Describe People? A Targeted Assessment of System Competence in the PEOPLE-domain\",\"url\":\"https://www.semanticscholar.org/paper/adf57a2bdcffc38238e64d4ae797c12405281173\",\"venue\":\"LANTERN\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72211602\",\"name\":\"Kai Rannenberg\"}],\"doi\":\"10.1007/978-3-030-46931-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d37509fc390147f2ab8e3746c3abb208b3cfc36f\",\"title\":\"Intelligent Information Processing X: 11th IFIP TC 12 International Conference, IIP 2020, Hangzhou, China, July 3\\u20136, 2020, Proceedings\",\"url\":\"https://www.semanticscholar.org/paper/d37509fc390147f2ab8e3746c3abb208b3cfc36f\",\"venue\":\"Intelligent Information Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26554826\",\"name\":\"Yuzhao Mao\"},{\"authorId\":\"144161025\",\"name\":\"C. Zhou\"},{\"authorId\":\"1680068\",\"name\":\"X. Wang\"},{\"authorId\":\"2462591\",\"name\":\"Ruifan Li\"}],\"doi\":\"10.24963/ijcai.2018/592\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"555e65623326de1b9c32bd22d482071920a6e4f1\",\"title\":\"Show and Tell More: Topic-Oriented Multi-Sentence Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/555e65623326de1b9c32bd22d482071920a6e4f1\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50439440\",\"name\":\"Hao Chen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6b82411656bc628bdbc72c5f4f9f8289b6073e0e\",\"title\":\"Adversarial Large-scale Root Gap\",\"url\":\"https://www.semanticscholar.org/paper/6b82411656bc628bdbc72c5f4f9f8289b6073e0e\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1909.02050\",\"authors\":[{\"authorId\":\"144889895\",\"name\":\"Ming Jiang\"},{\"authorId\":\"1788124\",\"name\":\"Qiuyuan Huang\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"},{\"authorId\":\"50141029\",\"name\":\"Xin Wang\"},{\"authorId\":\"9325940\",\"name\":\"Pengchuan Zhang\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"3207378\",\"name\":\"J. Diesner\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":\"10.18653/v1/D19-1220\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ce01073130ff984eb43cbf43f6bdcbe4d5a09df9\",\"title\":\"TIGEr: Text-to-Image Grounding for Image Caption Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/ce01073130ff984eb43cbf43f6bdcbe4d5a09df9\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"1903.10118\",\"authors\":[{\"authorId\":\"144362275\",\"name\":\"K. Hagiwara\"},{\"authorId\":\"2374364\",\"name\":\"Yusuke Mukuta\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"604ce3df514d0fddcc944c1741a1217d94aeb19f\",\"title\":\"End-to-End Learning Using Cycle Consistency for Image-to-Caption Transformations\",\"url\":\"https://www.semanticscholar.org/paper/604ce3df514d0fddcc944c1741a1217d94aeb19f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1805.00063\",\"authors\":[{\"authorId\":\"1839363\",\"name\":\"Pierre L. Dognin\"},{\"authorId\":\"2576373\",\"name\":\"I. Melnyk\"},{\"authorId\":\"2211263\",\"name\":\"Youssef Mroueh\"},{\"authorId\":\"39320489\",\"name\":\"J. Ross\"},{\"authorId\":\"2500466\",\"name\":\"Tom Sercu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"240ed539e96b9a304de54c904b375a9870496bf7\",\"title\":\"Improved Image Captioning with Adversarial Semantic Alignment\",\"url\":\"https://www.semanticscholar.org/paper/240ed539e96b9a304de54c904b375a9870496bf7\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1902.07816\",\"authors\":[{\"authorId\":\"3456570\",\"name\":\"Tianxiao Shen\"},{\"authorId\":\"40511414\",\"name\":\"Myle Ott\"},{\"authorId\":\"2325985\",\"name\":\"M. Auli\"},{\"authorId\":\"1706809\",\"name\":\"Marc'Aurelio Ranzato\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3360768fcb265a8b7c1ee5ba7cfe03de0e2fad62\",\"title\":\"Mixture Models for Diverse Machine Translation: Tricks of the Trade\",\"url\":\"https://www.semanticscholar.org/paper/3360768fcb265a8b7c1ee5ba7cfe03de0e2fad62\",\"venue\":\"ICML\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144757965\",\"name\":\"Y. Yang\"},{\"authorId\":\"39491387\",\"name\":\"J. Zhou\"},{\"authorId\":\"21576252\",\"name\":\"Jiangbo Ai\"},{\"authorId\":\"2105743\",\"name\":\"Y. Bin\"},{\"authorId\":\"1718099\",\"name\":\"A. Hanjalic\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"},{\"authorId\":\"50006507\",\"name\":\"Yanli Ji\"}],\"doi\":\"10.1109/TIP.2018.2855422\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fd3d94fac6a282414406716040b10c1746634ecd\",\"title\":\"Video Captioning by Adversarial LSTM\",\"url\":\"https://www.semanticscholar.org/paper/fd3d94fac6a282414406716040b10c1746634ecd\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3158899\",\"name\":\"Mariam Bouchakwa\"},{\"authorId\":\"2135034\",\"name\":\"Yassine Ayadi\"},{\"authorId\":\"1784204\",\"name\":\"I. Amous\"}],\"doi\":\"10.1007/s11042-020-08862-1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"445df9ebc8c43c39faeaa58518383f980fdd0da9\",\"title\":\"A review on visual content-based and users\\u2019 tags-based image annotation: methods and techniques\",\"url\":\"https://www.semanticscholar.org/paper/445df9ebc8c43c39faeaa58518383f980fdd0da9\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"2002.05512\",\"authors\":[{\"authorId\":\"3466717\",\"name\":\"Yuanbo Xiangli\"},{\"authorId\":\"48362742\",\"name\":\"Yubin Deng\"},{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7a2c9cc48062fcfd77a2e6e97aa48119a21c9f7d\",\"title\":\"Real or Not Real, that is the Question\",\"url\":\"https://www.semanticscholar.org/paper/7a2c9cc48062fcfd77a2e6e97aa48119a21c9f7d\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98831710\",\"name\":\"B. Yang\"},{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"35325151\",\"name\":\"Yuexian Zou\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"86010b6cb557103eda7e28fa2b497c9a9697fa8d\",\"title\":\"Non-Autoregressive Video Captioning with Iterative Refinement\",\"url\":\"https://www.semanticscholar.org/paper/86010b6cb557103eda7e28fa2b497c9a9697fa8d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2ac1d4b125b4de515ecbaeda6d803d7143d9cdb9\",\"title\":\"Exploring Possible Improvements to Momentum Strategies with Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/2ac1d4b125b4de515ecbaeda6d803d7143d9cdb9\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"14320047\",\"name\":\"C. Patil\"},{\"authorId\":\"34326205\",\"name\":\"Manasi S. Patwardhan\"}],\"doi\":\"10.1145/3383465\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9e081431cfbab4d5c8823efa2620ca0accfa124e\",\"title\":\"Visual Question Generation\",\"url\":\"https://www.semanticscholar.org/paper/9e081431cfbab4d5c8823efa2620ca0accfa124e\",\"venue\":\"ACM Comput. Surv.\",\"year\":2020},{\"arxivId\":\"1903.05942\",\"authors\":[{\"authorId\":\"40622539\",\"name\":\"Dong-Jin Kim\"},{\"authorId\":\"49331178\",\"name\":\"Jinsoo Choi\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"2398271\",\"name\":\"In-So Kweon\"}],\"doi\":\"10.1109/CVPR.2019.00643\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"79de42d6ca8d1bf2952c46eb74e6e0561f979257\",\"title\":\"Dense Relational Captioning: Triple-Stream Networks for Relationship-Based Captioning\",\"url\":\"https://www.semanticscholar.org/paper/79de42d6ca8d1bf2952c46eb74e6e0561f979257\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145113946\",\"name\":\"J. Tang\"},{\"authorId\":\"144005516\",\"name\":\"Jing Wang\"},{\"authorId\":\"3233021\",\"name\":\"Zechao Li\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1145/3291925\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"a437bb550d1df02188e4b145e01675551da36336\",\"title\":\"Show, Reward, and Tell\",\"url\":\"https://www.semanticscholar.org/paper/a437bb550d1df02188e4b145e01675551da36336\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":\"1906.00717\",\"authors\":[{\"authorId\":\"2903539\",\"name\":\"Junlong Gao\"},{\"authorId\":\"2802555\",\"name\":\"Xi Meng\"},{\"authorId\":null,\"name\":\"Shiqi Wang\"},{\"authorId\":\"50078954\",\"name\":\"Xia Li\"},{\"authorId\":\"1755176\",\"name\":\"Shanshe Wang\"},{\"authorId\":\"51130683\",\"name\":\"S. Ma\"},{\"authorId\":\"48385803\",\"name\":\"W. Gao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"36a3cfa6ed48988e23cf68b3abcbe097b29e594a\",\"title\":\"Masked Non-Autoregressive Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/36a3cfa6ed48988e23cf68b3abcbe097b29e594a\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39682947\",\"name\":\"Jiyun Li\"},{\"authorId\":\"1405889059\",\"name\":\"Yongliang Hong\"}],\"doi\":\"10.1145/3357254.3357256\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5db340fa84558628ac67df84559c1d5e8632fbc8\",\"title\":\"Label generation system based on generative adversarial network for medical image\",\"url\":\"https://www.semanticscholar.org/paper/5db340fa84558628ac67df84559c1d5e8632fbc8\",\"venue\":\"AIPR '19\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24508084\",\"name\":\"Deshraj Yadav\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"47704402\",\"name\":\"H. Agrawal\"},{\"authorId\":\"40424000\",\"name\":\"Prithvijit Chattopadhyay\"},{\"authorId\":\"2781522\",\"name\":\"T. Singh\"},{\"authorId\":\"49148034\",\"name\":\"Akash Jain\"},{\"authorId\":null,\"name\":\"Shiv Baran Singh\"},{\"authorId\":\"1790311\",\"name\":\"S. Lee\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"07d570d0f7af78767c8e8ea9a58fc40cbceb5863\",\"title\":\"EvalAI: Towards Better Evaluation of AI Agents\",\"url\":\"https://www.semanticscholar.org/paper/07d570d0f7af78767c8e8ea9a58fc40cbceb5863\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1811.10652\",\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/CVPR.2019.00850\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8e59cf8c3becbedced0089028a1cddac8b19b251\",\"title\":\"Show, Control and Tell: A Framework for Generating Controllable and Grounded Captions\",\"url\":\"https://www.semanticscholar.org/paper/8e59cf8c3becbedced0089028a1cddac8b19b251\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1803.08314\",\"authors\":[{\"authorId\":\"46522599\",\"name\":\"Xihui Liu\"},{\"authorId\":\"49404547\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"144478188\",\"name\":\"J. Shao\"},{\"authorId\":\"143982372\",\"name\":\"Dapeng Chen\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1007/978-3-030-01267-0_21\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"caab1c1d53718315f54bc4df42eb9a727fa18483\",\"title\":\"Show, Tell and Discriminate: Image Captioning by Self-retrieval with Partially Labeled Data\",\"url\":\"https://www.semanticscholar.org/paper/caab1c1d53718315f54bc4df42eb9a727fa18483\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51001584\",\"name\":\"Hyung-min Lee\"},{\"authorId\":\"153481384\",\"name\":\"Il-Koo Kim\"}],\"doi\":\"10.1109/IJCNN.2019.8851892\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b89d030332f7ff66ef270160dfc93e6b3122f34b\",\"title\":\"Generating Natural Video Descriptions using Semantic Gate\",\"url\":\"https://www.semanticscholar.org/paper/b89d030332f7ff66ef270160dfc93e6b3122f34b\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":\"1909.03409\",\"authors\":[{\"authorId\":\"145066132\",\"name\":\"Bin Guo\"},{\"authorId\":null,\"name\":\"Hao Wang\"},{\"authorId\":\"151260226\",\"name\":\"Y. Ding\"},{\"authorId\":\"117889029\",\"name\":\"Shaoyang Hao\"},{\"authorId\":\"79953570\",\"name\":\"Y. Sun\"},{\"authorId\":\"2256618\",\"name\":\"Z. Yu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4cd7ce0d1ad83b2afbc2468d5d43ff8de0d9ae28\",\"title\":\"c-TextGen: Conditional Text Generation for Harmonious Human-Machine Interaction\",\"url\":\"https://www.semanticscholar.org/paper/4cd7ce0d1ad83b2afbc2468d5d43ff8de0d9ae28\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1706.01554\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"145721096\",\"name\":\"A. Kannan\"},{\"authorId\":\"145743311\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8cdd241b474bf7b0632162403ac2a3c4799252ad\",\"title\":\"Best of Both Worlds: Transferring Knowledge from Discriminative Learning to a Generative Visual Dialog Model\",\"url\":\"https://www.semanticscholar.org/paper/8cdd241b474bf7b0632162403ac2a3c4799252ad\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"2007.11731\",\"authors\":[{\"authorId\":\"1828787912\",\"name\":\"Yiwu Zhong\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"101777533\",\"name\":\"J. Chen\"},{\"authorId\":null,\"name\":\"Dong Yu\"},{\"authorId\":\"47002659\",\"name\":\"Yanchao Li\"}],\"doi\":\"10.1007/978-3-030-58568-6_13\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"66ed8795eb6de5d2a6b204baac9378d6d28136cc\",\"title\":\"Comprehensive Image Captioning via Scene Graph Decomposition\",\"url\":\"https://www.semanticscholar.org/paper/66ed8795eb6de5d2a6b204baac9378d6d28136cc\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2005.00340\",\"authors\":[{\"authorId\":\"49890130\",\"name\":\"Y. Zhang\"},{\"authorId\":\"117638983\",\"name\":\"Rania Briq\"},{\"authorId\":\"15716390\",\"name\":\"Julian Tanke\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a097417919d5fa82741a660124709dcf05b7e896\",\"title\":\"Adversarial Synthesis of Human Pose from Text\",\"url\":\"https://www.semanticscholar.org/paper/a097417919d5fa82741a660124709dcf05b7e896\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.03708\",\"authors\":[{\"authorId\":\"80389349\",\"name\":\"Zhuowan Li\"},{\"authorId\":\"2536742\",\"name\":\"Quan Hung Tran\"},{\"authorId\":\"2712573\",\"name\":\"Long Mai\"},{\"authorId\":\"145527698\",\"name\":\"Zhe Lin\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.1109/CVPR42600.2020.00350\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"477b70ed4753745e2700dd2791c3a5fb966f8b64\",\"title\":\"Context-Aware Group Captioning via Self-Attention and Contrastive Features\",\"url\":\"https://www.semanticscholar.org/paper/477b70ed4753745e2700dd2791c3a5fb966f8b64\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020}],\"corpusId\":665667,\"doi\":\"10.1109/ICCV.2017.323\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":42,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"24dc571a49d3431e8cb1f1008f86d5dd5b7a1613\",\"references\":[{\"arxivId\":\"1412.2306\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/TPAMI.2016.2598339\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"title\":\"Deep Visual-Semantic Alignments for Generating Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"145297531\",\"name\":\"A. Lai\"},{\"authorId\":\"2170746\",\"name\":\"M. Hodosh\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"}],\"doi\":\"10.1162/tacl_a_00166\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"44040913380206991b1991daf1192942e038fe31\",\"title\":\"From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions\",\"url\":\"https://www.semanticscholar.org/paper/44040913380206991b1991daf1192942e038fe31\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2014},{\"arxivId\":\"1605.05396\",\"authors\":[{\"authorId\":\"144828948\",\"name\":\"S. Reed\"},{\"authorId\":\"2893664\",\"name\":\"Zeynep Akata\"},{\"authorId\":\"3084614\",\"name\":\"Xinchen Yan\"},{\"authorId\":\"2876316\",\"name\":\"L. Logeswaran\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6c7f040a150abf21dbcefe1f22e0f98fa184f41a\",\"title\":\"Generative Adversarial Text to Image Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/6c7f040a150abf21dbcefe1f22e0f98fa184f41a\",\"venue\":\"ICML\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1888731\",\"name\":\"M. Hejrati\"},{\"authorId\":\"21160985\",\"name\":\"M. Sadeghi\"},{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"3125805\",\"name\":\"Cyrus Rashtchian\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"144016256\",\"name\":\"D. Forsyth\"}],\"doi\":\"10.1007/978-3-642-15561-1_2\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eaaed23a2d94feb2f1c3ff22a25777c7a78f3141\",\"title\":\"Every Picture Tells a Story: Generating Sentences from Images\",\"url\":\"https://www.semanticscholar.org/paper/eaaed23a2d94feb2f1c3ff22a25777c7a78f3141\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":\"1707.09700\",\"authors\":[{\"authorId\":\"2180892\",\"name\":\"Yikang Li\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"48884894\",\"name\":\"K. Wang\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1109/ICCV.2017.142\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cf2de559e5a6235783e0762862f6e42192f142a8\",\"title\":\"Scene Graph Generation from Objects, Phrases and Region Captions\",\"url\":\"https://www.semanticscholar.org/paper/cf2de559e5a6235783e0762862f6e42192f142a8\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1611.07004\",\"authors\":[{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"1822702\",\"name\":\"Tinghui Zhou\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1109/CVPR.2017.632\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8acbe90d5b852dadea7810345451a99608ee54c7\",\"title\":\"Image-to-Image Translation with Conditional Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/8acbe90d5b852dadea7810345451a99608ee54c7\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1411.1784\",\"authors\":[{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"2217144\",\"name\":\"Simon Osindero\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"353ecf7b66b3e9ff5e9f41145a147e899a2eea5c\",\"title\":\"Conditional Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/353ecf7b66b3e9ff5e9f41145a147e899a2eea5c\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":\"1612.00563\",\"authors\":[{\"authorId\":\"2071376\",\"name\":\"Steven J. Rennie\"},{\"authorId\":\"2293163\",\"name\":\"E. Marcheret\"},{\"authorId\":\"2211263\",\"name\":\"Youssef Mroueh\"},{\"authorId\":\"39320489\",\"name\":\"J. Ross\"},{\"authorId\":\"1782589\",\"name\":\"V. Goel\"}],\"doi\":\"10.1109/CVPR.2017.131\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6c8353697cdbb98dfba4f493875778c4286d3e3a\",\"title\":\"Self-Critical Sequence Training for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6c8353697cdbb98dfba4f493875778c4286d3e3a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1704.03114\",\"authors\":[{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"46867115\",\"name\":\"Yuqi Zhang\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/CVPR.2017.352\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5fcd93997b7dde90594dc1caa27ba9d560bbe63d\",\"title\":\"Detecting Visual Relationships with Deep Relational Networks\",\"url\":\"https://www.semanticscholar.org/paper/5fcd93997b7dde90594dc1caa27ba9d560bbe63d\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1611.06607\",\"authors\":[{\"authorId\":\"2285165\",\"name\":\"J. Krause\"},{\"authorId\":\"153365679\",\"name\":\"J. Johnson\"},{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2017.356\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3a7011346ce939e3251915e92ae2f252e4c7f777\",\"title\":\"A Hierarchical Approach for Generating Descriptive Image Paragraphs\",\"url\":\"https://www.semanticscholar.org/paper/3a7011346ce939e3251915e92ae2f252e4c7f777\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1411.4952\",\"authors\":[{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3346186\",\"name\":\"Forrest N. Iandola\"},{\"authorId\":\"2100612\",\"name\":\"R. Srivastava\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"144189092\",\"name\":\"John C. Platt\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"}],\"doi\":\"10.1109/CVPR.2015.7298754\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"title\":\"From captions to visual concepts and back\",\"url\":\"https://www.semanticscholar.org/paper/15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2157958\",\"name\":\"Michael J. Denkowski\"},{\"authorId\":\"1784914\",\"name\":\"A. Lavie\"}],\"doi\":\"10.3115/v1/W14-3348\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"26adb749fc5d80502a6d889966e50b31391560d3\",\"title\":\"Meteor Universal: Language Specific Translation Evaluation for Any Target Language\",\"url\":\"https://www.semanticscholar.org/paper/26adb749fc5d80502a6d889966e50b31391560d3\",\"venue\":\"WMT@ACL\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1403025868\",\"name\":\"Jean Pouget-Abadie\"},{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"144738865\",\"name\":\"Bing Xu\"},{\"authorId\":\"1393680089\",\"name\":\"David Warde-Farley\"},{\"authorId\":\"1955694\",\"name\":\"Sherjil Ozair\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"title\":\"Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1505.04467\",\"authors\":[{\"authorId\":\"39172707\",\"name\":\"J. Devlin\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3ca194773fe583661b988fbdf33f7680764438b3\",\"title\":\"Exploring Nearest Neighbor Approaches for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/3ca194773fe583661b988fbdf33f7680764438b3\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47087291\",\"name\":\"Z. Yang\"},{\"authorId\":\"30556331\",\"name\":\"Y. Yuan\"},{\"authorId\":\"9287688\",\"name\":\"Yuexin Wu\"},{\"authorId\":\"50056360\",\"name\":\"William W. Cohen\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"61d2dda8d96a10a714636475c7589bd149bda053\",\"title\":\"Review Networks for Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/61d2dda8d96a10a714636475c7589bd149bda053\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3323275\",\"name\":\"Kishore Papineni\"},{\"authorId\":\"1781292\",\"name\":\"S. Roukos\"},{\"authorId\":\"144582029\",\"name\":\"T. Ward\"},{\"authorId\":\"2587983\",\"name\":\"Wei-Jing Zhu\"}],\"doi\":\"10.3115/1073083.1073135\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d7da009f457917aa381619facfa5ffae9329a6e9\",\"title\":\"Bleu: a Method for Automatic Evaluation of Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/d7da009f457917aa381619facfa5ffae9329a6e9\",\"venue\":\"ACL\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2015.7298932\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"title\":\"Deep visual-semantic alignments for generating image descriptions\",\"url\":\"https://www.semanticscholar.org/paper/ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"venue\":\"CVPR\",\"year\":2015},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699645\",\"name\":\"R. Sutton\"},{\"authorId\":\"145689002\",\"name\":\"David A. McAllester\"},{\"authorId\":\"1699868\",\"name\":\"Satinder Singh\"},{\"authorId\":\"144830983\",\"name\":\"Y. Mansour\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a20f0ce0616def7cc9a87446c228906cd5da093b\",\"title\":\"Policy Gradient Methods for Reinforcement Learning with Function Approximation\",\"url\":\"https://www.semanticscholar.org/paper/a20f0ce0616def7cc9a87446c228906cd5da093b\",\"venue\":\"NIPS\",\"year\":1999},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145564333\",\"name\":\"G. Kulkarni\"},{\"authorId\":\"3128210\",\"name\":\"Visruth Premraj\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"2985883\",\"name\":\"Sagnik Dhar\"},{\"authorId\":\"50341924\",\"name\":\"Siming Li\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/TPAMI.2012.162\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5cb6700d94c6118ee13f4f4fecac99f111189812\",\"title\":\"BabyTalk: Understanding and Generating Simple Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/5cb6700d94c6118ee13f4f4fecac99f111189812\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2013},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1612.01887\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":\"10.1109/CVPR.2017.345\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9f4d7d622d1f7319cc511bfef661cd973e881a4c\",\"title\":\"Knowing When to Look: Adaptive Attention via a Visual Sentinel for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9f4d7d622d1f7319cc511bfef661cd973e881a4c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1603.03925\",\"authors\":[{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2016.503\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bf55591e09b58ea9ce8d66110d6d3000ee804bdd\",\"title\":\"Image Captioning with Semantic Attention\",\"url\":\"https://www.semanticscholar.org/paper/bf55591e09b58ea9ce8d66110d6d3000ee804bdd\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1162/neco.1997.9.8.1735\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"title\":\"Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"venue\":\"Neural Computation\",\"year\":1997},{\"arxivId\":\"1411.5726\",\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2015.7299087\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"258986132bf17755fe8263e42429fe73218c1534\",\"title\":\"CIDEr: Consensus-based image description evaluation\",\"url\":\"https://www.semanticscholar.org/paper/258986132bf17755fe8263e42429fe73218c1534\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Y. Wu\"},{\"authorId\":null,\"name\":\"W. W. Cohen\"},{\"authorId\":null,\"name\":\"R. R.\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Salakhutdi - nov . Review networks for caption generation\",\"url\":\"\",\"venue\":\"Advances in Neural Information Processing Systems\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47130333\",\"name\":\"Siqi Liu\"},{\"authorId\":\"39815369\",\"name\":\"Z. Zhu\"},{\"authorId\":\"145361612\",\"name\":\"N. Ye\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":\"10.1109/ICCV.2017.100\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"163a474747fd63ab62ae586711fa5e5a2ac91bd8\",\"title\":\"Improved Image Captioning via Policy Gradient optimization of SPIDEr\",\"url\":\"https://www.semanticscholar.org/paper/163a474747fd63ab62ae586711fa5e5a2ac91bd8\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1505.01809\",\"authors\":[{\"authorId\":\"39172707\",\"name\":\"J. Devlin\"},{\"authorId\":\"47413820\",\"name\":\"Hao Cheng\"},{\"authorId\":\"145204655\",\"name\":\"Hao Fang\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"}],\"doi\":\"10.3115/v1/P15-2017\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f142c849ffef66f7520aff4e0b40ac964ccb8cc1\",\"title\":\"Language Models for Image Captioning: The Quirks and What Works\",\"url\":\"https://www.semanticscholar.org/paper/f142c849ffef66f7520aff4e0b40ac964ccb8cc1\",\"venue\":\"ACL\",\"year\":2015},{\"arxivId\":\"1612.00370\",\"authors\":[{\"authorId\":\"47130333\",\"name\":\"Siqi Liu\"},{\"authorId\":\"39815369\",\"name\":\"Z. Zhu\"},{\"authorId\":\"145361612\",\"name\":\"N. Ye\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":\"10.1109/ICCV.2017.100\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"665a311c538fc021c27acd3953f171924cc5905c\",\"title\":\"Optimization of image description metrics using policy gradient methods\",\"url\":\"https://www.semanticscholar.org/paper/665a311c538fc021c27acd3953f171924cc5905c\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1781574\",\"name\":\"Chin-Yew Lin\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"60b05f32c32519a809f21642ef1eb3eaf3848008\",\"title\":\"ROUGE: A Package for Automatic Evaluation of Summaries\",\"url\":\"https://www.semanticscholar.org/paper/60b05f32c32519a809f21642ef1eb3eaf3848008\",\"venue\":\"ACL 2004\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50341924\",\"name\":\"Siming Li\"},{\"authorId\":\"145564333\",\"name\":\"G. Kulkarni\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fbdbe747c6aa8b35b981d21e475ff1506a1bae66\",\"title\":\"Composing Simple Image Descriptions using Web-scale N-grams\",\"url\":\"https://www.semanticscholar.org/paper/fbdbe747c6aa8b35b981d21e475ff1506a1bae66\",\"venue\":\"CoNLL\",\"year\":2011},{\"arxivId\":\"1609.05473\",\"authors\":[{\"authorId\":\"3469209\",\"name\":\"Lantao Yu\"},{\"authorId\":\"8031058\",\"name\":\"W. Zhang\"},{\"authorId\":\"39055225\",\"name\":\"J. Wang\"},{\"authorId\":\"1811427\",\"name\":\"Y. Yu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2966ecd82505ecd55ead0e6a327a304c8f9868e3\",\"title\":\"SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient\",\"url\":\"https://www.semanticscholar.org/paper/2966ecd82505ecd55ead0e6a327a304c8f9868e3\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2677364\",\"name\":\"Luowei Zhou\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"},{\"authorId\":\"31717541\",\"name\":\"Parker A. Koch\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1145/3126686.3126717\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1e83adb616b8466639a14e78f3d26120be7caf48\",\"title\":\"Watch What You Just Said: Image Captioning with Text-Conditional Attention\",\"url\":\"https://www.semanticscholar.org/paper/1e83adb616b8466639a14e78f3d26120be7caf48\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":\"1606.04621\",\"authors\":[{\"authorId\":\"2677364\",\"name\":\"Luowei Zhou\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"},{\"authorId\":\"31717541\",\"name\":\"Parker A. Koch\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a861313608ef58ed09ab7c35a589ae22088ff2e9\",\"title\":\"Image Caption Generation with Text-Conditional Semantic Attention\",\"url\":\"https://www.semanticscholar.org/paper/a861313608ef58ed09ab7c35a589ae22088ff2e9\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1607.08822\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1007/978-3-319-46454-1_24\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1c54acd7d9ed8017acdc5674c9b7faac738fd651\",\"title\":\"SPICE: Semantic Propositional Image Caption Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/1c54acd7d9ed8017acdc5674c9b7faac738fd651\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145592791\",\"name\":\"P. Kuznetsova\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2a0d0f6c5a69b264710df0230696f47c5918e2f2\",\"title\":\"Collective Generation of Natural Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/2a0d0f6c5a69b264710df0230696f47c5918e2f2\",\"venue\":\"ACL\",\"year\":2012},{\"arxivId\":\"1412.8419\",\"authors\":[{\"authorId\":\"2875254\",\"name\":\"R\\u00e9mi Lebret\"},{\"authorId\":\"2708655\",\"name\":\"Pedro H. O. Pinheiro\"},{\"authorId\":\"2939803\",\"name\":\"Ronan Collobert\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"015d25f66514ce0a966300944201d45968a104ba\",\"title\":\"Simple Image Description Generator via a Linear Phrase-Based Approach\",\"url\":\"https://www.semanticscholar.org/paper/015d25f66514ce0a966300944201d45968a104ba\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015}],\"title\":\"Towards Diverse and Natural Image Descriptions via a Conditional GAN\",\"topics\":[{\"topic\":\"Interpreter (computing)\",\"topicId\":\"2760\",\"url\":\"https://www.semanticscholar.org/topic/2760\"},{\"topic\":\"Gradient\",\"topicId\":\"3221\",\"url\":\"https://www.semanticscholar.org/topic/3221\"},{\"topic\":\"Usability testing\",\"topicId\":\"34160\",\"url\":\"https://www.semanticscholar.org/topic/34160\"},{\"topic\":\"Reinforcement learning\",\"topicId\":\"2557\",\"url\":\"https://www.semanticscholar.org/topic/2557\"},{\"topic\":\"METEOR\",\"topicId\":\"609251\",\"url\":\"https://www.semanticscholar.org/topic/609251\"},{\"topic\":\"Essence\",\"topicId\":\"340250\",\"url\":\"https://www.semanticscholar.org/topic/340250\"},{\"topic\":\"BLEU\",\"topicId\":\"250421\",\"url\":\"https://www.semanticscholar.org/topic/250421\"},{\"topic\":\"End-to-end principle\",\"topicId\":\"299633\",\"url\":\"https://www.semanticscholar.org/topic/299633\"},{\"topic\":\"Relevance\",\"topicId\":\"503\",\"url\":\"https://www.semanticscholar.org/topic/503\"},{\"topic\":\"Stemming\",\"topicId\":\"4937\",\"url\":\"https://www.semanticscholar.org/topic/4937\"},{\"topic\":\"Generative adversarial networks\",\"topicId\":\"258908\",\"url\":\"https://www.semanticscholar.org/topic/258908\"},{\"topic\":\"FITS\",\"topicId\":\"342298\",\"url\":\"https://www.semanticscholar.org/topic/342298\"},{\"topic\":\"Heart rate variability\",\"topicId\":\"48524\",\"url\":\"https://www.semanticscholar.org/topic/48524\"}],\"url\":\"https://www.semanticscholar.org/paper/24dc571a49d3431e8cb1f1008f86d5dd5b7a1613\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017}\n"