"{\"abstract\":\"Future frame prediction in videos is a promising avenue for unsupervised video representation learning. Video frames are naturally generated by the inherent pixel flows from preceding frames based on the appearance and motion dynamics in the video. However, existing methods focus on directly hallucinating pixel values, resulting in blurry predictions. In this paper, we develop a dual motion Generative Adversarial Net (GAN) architecture, which learns to explicitly enforce future-frame predictions to be consistent with the pixel-wise flows in the video through a duallearning mechanism. The primal future-frame prediction and dual future-flow prediction form a closed loop, generating informative feedback signals to each other for better video prediction. To make both synthesized future frames and flows indistinguishable from reality, a dual adversarial training method is proposed to ensure that the futureflow prediction is able to help infer realistic future-frames, while the future-frame prediction in turn leads to realistic optical flows. Our dual motion GAN also handles natural motion uncertainty in different pixel locations with a new probabilistic motion encoder, which is based on variational autoencoders. Extensive experiments demonstrate that the proposed dual motion GAN significantly outperforms stateof-the-art approaches on synthesizing new video frames and predicting future flows. Our model generalizes well across diverse visual scenes and shows superiority in unsupervised video representation learning.\",\"arxivId\":\"1708.00284\",\"authors\":[{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\",\"url\":\"https://www.semanticscholar.org/author/40250403\"},{\"authorId\":\"87068304\",\"name\":\"L. Lee\",\"url\":\"https://www.semanticscholar.org/author/87068304\"},{\"authorId\":\"143716171\",\"name\":\"Wei Dai\",\"url\":\"https://www.semanticscholar.org/author/143716171\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\",\"url\":\"https://www.semanticscholar.org/author/143977260\"}],\"citationVelocity\":64,\"citations\":[{\"arxivId\":\"1804.00892\",\"authors\":[{\"authorId\":\"41022481\",\"name\":\"Yazan Abu Farha\"},{\"authorId\":\"32774629\",\"name\":\"A. Richard\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1109/CVPR.2018.00560\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"33b1843afc8b76314c9fbe11ca11c23fa0966c08\",\"title\":\"When will you do what? - Anticipating Temporal Occurrences of Activities\",\"url\":\"https://www.semanticscholar.org/paper/33b1843afc8b76314c9fbe11ca11c23fa0966c08\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3399307\",\"name\":\"Jae-Hyeok Lee\"},{\"authorId\":\"47090333\",\"name\":\"S. Lee\"},{\"authorId\":\"3009805\",\"name\":\"Hak Gu Kim\"},{\"authorId\":\"9497778\",\"name\":\"Sa-Kwang Song\"},{\"authorId\":\"2600421\",\"name\":\"S. Kim\"},{\"authorId\":\"7251290\",\"name\":\"Yong Man Ro\"}],\"doi\":\"10.1109/TGRS.2019.2955538\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7376cb3aadff769362612285b2b0a20cc5e476ed\",\"title\":\"MCSIP Net: Multichannel Satellite Image Prediction via Deep Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/7376cb3aadff769362612285b2b0a20cc5e476ed\",\"venue\":\"IEEE Transactions on Geoscience and Remote Sensing\",\"year\":2020},{\"arxivId\":\"1907.01886\",\"authors\":[{\"authorId\":\"48211327\",\"name\":\"Jia Liu\"},{\"authorId\":\"50013361\",\"name\":\"Y. Ke\"},{\"authorId\":\"48805634\",\"name\":\"Z. Zhang\"},{\"authorId\":\"144470378\",\"name\":\"Y. Lei\"},{\"authorId\":\"39467398\",\"name\":\"J. Li\"},{\"authorId\":\"2337436\",\"name\":\"Minqing Zhang\"},{\"authorId\":\"40171150\",\"name\":\"Xiaoyuan Yang\"}],\"doi\":\"10.1109/ACCESS.2020.2983175\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"181da52e378256c38db5b9055b9984e371369b16\",\"title\":\"Recent Advances of Image Steganography With Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/181da52e378256c38db5b9055b9984e371369b16\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1811.03205\",\"authors\":[{\"authorId\":\"1690006\",\"name\":\"Kiran Koshy Thekumparampil\"},{\"authorId\":\"3083159\",\"name\":\"Ashish Khetan\"},{\"authorId\":\"3354281\",\"name\":\"Z. Lin\"},{\"authorId\":\"34184418\",\"name\":\"Sewoong Oh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"64c8b1c27d8e50eaa4a335977bb6379fcd00243b\",\"title\":\"Robustness of Conditional GANs to Noisy Labels\",\"url\":\"https://www.semanticscholar.org/paper/64c8b1c27d8e50eaa4a335977bb6379fcd00243b\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1768964\",\"name\":\"Jimei Yang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"59d8f54ac2346a1e31aead38e8a88da64199f941\",\"title\":\"With the emergence of deep neural networks , learning-based techniques have become an increasingly popular tool for novel view synthesis\",\"url\":\"https://www.semanticscholar.org/paper/59d8f54ac2346a1e31aead38e8a88da64199f941\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2028218872\",\"name\":\"Kara Marie Schatz\"},{\"authorId\":\"1607110764\",\"name\":\"Erik Quintanilla\"},{\"authorId\":\"50415746\",\"name\":\"Shruti Vyas\"},{\"authorId\":\"2116440\",\"name\":\"Y. Rawat\"}],\"doi\":\"10.1007/978-3-030-58583-9_25\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"64eba0de822754df1bc1303f96163265dea9ac4f\",\"title\":\"A Recurrent Transformer Network for Novel View Action Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/64eba0de822754df1bc1303f96163265dea9ac4f\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49991541\",\"name\":\"Jinxuan Sun\"},{\"authorId\":\"2421012\",\"name\":\"Guoqiang Zhong\"},{\"authorId\":\"50581244\",\"name\":\"Y. Chen\"},{\"authorId\":\"49421522\",\"name\":\"Yongbin Liu\"},{\"authorId\":\"153051027\",\"name\":\"Tao Li\"},{\"authorId\":\"5380819\",\"name\":\"K. Huang\"}],\"doi\":\"10.1016/j.neunet.2019.11.003\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"64b207312ed762f405e0cdd732f72f9e21d2bb36\",\"title\":\"Generative adversarial networks with mixture of t-distributions noise for diverse image generation\",\"url\":\"https://www.semanticscholar.org/paper/64b207312ed762f405e0cdd732f72f9e21d2bb36\",\"venue\":\"Neural Networks\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"120201968\",\"name\":\"Hongyang Yu\"},{\"authorId\":\"46439250\",\"name\":\"Guorong Li\"},{\"authorId\":\"2448188\",\"name\":\"Li Su\"},{\"authorId\":\"122246162\",\"name\":\"Bineng Zhong\"},{\"authorId\":\"31255274\",\"name\":\"Hongxun Yao\"},{\"authorId\":\"153159021\",\"name\":\"Qingming Huang\"}],\"doi\":\"10.1016/j.patrec.2019.12.018\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"957d185f5f7f810734adff507a623d5bca5a0c1c\",\"title\":\"Conditional GAN based individual and global motion fusion for multiple object tracking in UAV videos\",\"url\":\"https://www.semanticscholar.org/paper/957d185f5f7f810734adff507a623d5bca5a0c1c\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2020},{\"arxivId\":\"1909.12400\",\"authors\":[{\"authorId\":\"1389556562\",\"name\":\"V. Yushchenko\"},{\"authorId\":\"1942495\",\"name\":\"Nikita Araslanov\"},{\"authorId\":\"46840930\",\"name\":\"S. Roth\"}],\"doi\":\"10.1109/ICCVW.2019.00190\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aa6bb4f4ad12ca1ff14faff0c2147de3be059e79\",\"title\":\"Markov Decision Process for Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/aa6bb4f4ad12ca1ff14faff0c2147de3be059e79\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145746402\",\"name\":\"X. Jin\"},{\"authorId\":\"31482866\",\"name\":\"Zhibo Chen\"},{\"authorId\":\"2345721\",\"name\":\"S. Liu\"},{\"authorId\":\"1720145\",\"name\":\"Wei Zhou\"}],\"doi\":\"10.1007/978-3-030-03398-9_38\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"8244984fb91dca8f24d3d8ded565586faf9ed9d8\",\"title\":\"Augmented Coarse-to-Fine Video Frame Synthesis with Semantic Loss\",\"url\":\"https://www.semanticscholar.org/paper/8244984fb91dca8f24d3d8ded565586faf9ed9d8\",\"venue\":\"PRCV\",\"year\":2018},{\"arxivId\":\"1911.01655\",\"authors\":[{\"authorId\":\"144543406\",\"name\":\"R. Villegas\"},{\"authorId\":\"8104240\",\"name\":\"A. Pathak\"},{\"authorId\":\"143862402\",\"name\":\"Harini Kannan\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"aec380c44646a7e467cd9f6d78cba301f877734c\",\"title\":\"High Fidelity Video Prediction with Large Stochastic Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/aec380c44646a7e467cd9f6d78cba301f877734c\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"108623673\",\"name\":\"Peiyao Sheng\"},{\"authorId\":\"12107336\",\"name\":\"Z. Yang\"},{\"authorId\":\"2480051\",\"name\":\"Yanmin Qian\"}],\"doi\":\"10.1109/ASRU46091.2019.9003933\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0cf10caa86d4b409a76d44f4dc079a45f875c45e\",\"title\":\"GANs for Children: A Generative Data Augmentation Strategy for Children Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/0cf10caa86d4b409a76d44f4dc079a45f875c45e\",\"venue\":\"2019 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)\",\"year\":2019},{\"arxivId\":\"2003.08074\",\"authors\":[{\"authorId\":\"147300966\",\"name\":\"Luke Ditria\"},{\"authorId\":\"21485467\",\"name\":\"B. J. Meyer\"},{\"authorId\":\"114729021\",\"name\":\"Tom Drummond\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"663df917647bf527e6664dfc6cb9ea6ea3d77da0\",\"title\":\"OpenGAN: Open Set Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/663df917647bf527e6664dfc6cb9ea6ea3d77da0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1804.11228\",\"authors\":[{\"authorId\":\"1591133581\",\"name\":\"Yujia Zhang\"},{\"authorId\":\"8199702\",\"name\":\"Michael Kampffmeyer\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"39901030\",\"name\":\"Dingwen Zhang\"},{\"authorId\":\"2554604\",\"name\":\"M. Tan\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":\"10.1145/3321408.3322622\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ee5e22fd01b4c8719e0b2df5830d21db8150477f\",\"title\":\"DTR-GAN: dilated temporal relational adversarial network for video summarization\",\"url\":\"https://www.semanticscholar.org/paper/ee5e22fd01b4c8719e0b2df5830d21db8150477f\",\"venue\":\"ACM TUR-C\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3207491\",\"name\":\"Chunpeng Wu\"},{\"authorId\":\"100895685\",\"name\":\"Ang Li\"},{\"authorId\":null,\"name\":\"Bing Li\"},{\"authorId\":null,\"name\":\"Yiran Chen\"}],\"doi\":\"10.1109/SiPS47522.2019.9020572\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"99bf7734663031a0c00a545cc53075f8bb160b28\",\"title\":\"Efficiently Learning a Robust Self-Driving Model with Neuron Coverage Aware Adaptive Filter Reuse\",\"url\":\"https://www.semanticscholar.org/paper/99bf7734663031a0c00a545cc53075f8bb160b28\",\"venue\":\"2019 IEEE International Workshop on Signal Processing Systems (SiPS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134888279\",\"name\":\"Yung-Han Ho\"},{\"authorId\":\"1381649479\",\"name\":\"Chuan-Yuan Cho\"},{\"authorId\":\"51259830\",\"name\":\"Guo-Lun Jin\"},{\"authorId\":\"1749122\",\"name\":\"Wen-Hsiao Peng\"}],\"doi\":\"10.1109/ICCV.2019.01056\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ffc7c3ac48bdff347fd48404fc867a877c156b3b\",\"title\":\"SME-Net: Sparse Motion Estimation for Parametric Video Prediction Through Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/ffc7c3ac48bdff347fd48404fc867a877c156b3b\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"17659319\",\"name\":\"Zackary P. T. Sin\"},{\"authorId\":\"2774268\",\"name\":\"P. H. Ng\"},{\"authorId\":\"1738911\",\"name\":\"S. Shiu\"},{\"authorId\":\"145288211\",\"name\":\"K. Chung\"},{\"authorId\":\"1714454\",\"name\":\"H. Leong\"}],\"doi\":\"10.1145/3297280.3297301\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a1cf969cca9a3dcbe042ecf0a4a0ec5bb80022c1\",\"title\":\"2D character animating networks: bringing static characters to move via motion transfer\",\"url\":\"https://www.semanticscholar.org/paper/a1cf969cca9a3dcbe042ecf0a4a0ec5bb80022c1\",\"venue\":\"SAC\",\"year\":2019},{\"arxivId\":\"2005.06582\",\"authors\":[{\"authorId\":\"26902477\",\"name\":\"Amir Rasouli\"},{\"authorId\":\"3468296\",\"name\":\"Iuliia Kotseruba\"},{\"authorId\":\"1727853\",\"name\":\"John K. Tsotsos\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"472b3df8920f0939dda0a80bdc51e293130c1124\",\"title\":\"Pedestrian Action Anticipation using Contextual Feature Fusion in Stacked RNNs\",\"url\":\"https://www.semanticscholar.org/paper/472b3df8920f0939dda0a80bdc51e293130c1124\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"2012.01642\",\"authors\":[{\"authorId\":\"84267967\",\"name\":\"C. Thomas\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0e6fd339e247604e00f4ca40de44438a96835471\",\"title\":\"Learning to Transfer Visual Effects from Videos to Images\",\"url\":\"https://www.semanticscholar.org/paper/0e6fd339e247604e00f4ca40de44438a96835471\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1907.10949\",\"authors\":[{\"authorId\":\"3366919\",\"name\":\"Massimiliano Patacchiola\"},{\"authorId\":\"1401704946\",\"name\":\"P. Fox-Roberts\"},{\"authorId\":\"1721991\",\"name\":\"E. Rosten\"}],\"doi\":\"10.1016/J.PATREC.2020.09.025\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e5c870b9908c561380db64b893b0c88bac3a5b83\",\"title\":\"Y-Autoencoders: disentangling latent representations via sequential-encoding\",\"url\":\"https://www.semanticscholar.org/paper/e5c870b9908c561380db64b893b0c88bac3a5b83\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2587808\",\"name\":\"Liang-Yan Gui\"},{\"authorId\":\"2302062\",\"name\":\"Yu-Xiong Wang\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"144915495\",\"name\":\"Jos\\u00e9 M. F. Moura\"}],\"doi\":\"10.1007/978-3-030-01225-0_48\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ca64cd82c7221beaeb5c7c85550339683ba1ecc5\",\"title\":\"Adversarial Geometry-Aware Human Motion Prediction\",\"url\":\"https://www.semanticscholar.org/paper/ca64cd82c7221beaeb5c7c85550339683ba1ecc5\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"84200540\",\"name\":\"Lu Sheng\"},{\"authorId\":\"1720856277\",\"name\":\"Junting Pan\"},{\"authorId\":\"48605271\",\"name\":\"J. Guo\"},{\"authorId\":\"144478191\",\"name\":\"J. Shao\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"}],\"doi\":\"10.1007/s11263-020-01334-x\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"991649f2903d05a27243a7d26016c4df735a6fbb\",\"title\":\"High-Quality Video Generation from Static Structural Annotations\",\"url\":\"https://www.semanticscholar.org/paper/991649f2903d05a27243a7d26016c4df735a6fbb\",\"venue\":\"International Journal of Computer Vision\",\"year\":2020},{\"arxivId\":\"1812.02636\",\"authors\":[{\"authorId\":\"145844227\",\"name\":\"Yan Zuo\"},{\"authorId\":\"46246850\",\"name\":\"Gil Avraham\"},{\"authorId\":\"144418842\",\"name\":\"Tom Drummond\"}],\"doi\":\"10.1007/978-3-030-20887-5_37\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ebac8173e857a69c6dc1c97a53464913deb76114\",\"title\":\"Traversing Latent Space using Decision Ferns\",\"url\":\"https://www.semanticscholar.org/paper/ebac8173e857a69c6dc1c97a53464913deb76114\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"1812.01210\",\"authors\":[{\"authorId\":\"36001694\",\"name\":\"Liangzhe Yuan\"},{\"authorId\":\"47557600\",\"name\":\"Yibo Chen\"},{\"authorId\":\"50855889\",\"name\":\"H. Liu\"},{\"authorId\":\"145868989\",\"name\":\"T. Kong\"},{\"authorId\":\"46865129\",\"name\":\"J. Shi\"}],\"doi\":\"10.1109/CVPR.2019.01246\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"152c11700a6924e94955f6cf00b5a7522b406ec3\",\"title\":\"Zoom-In-To-Check: Boosting Video Interpolation via Instance-Level Discrimination\",\"url\":\"https://www.semanticscholar.org/paper/152c11700a6924e94955f6cf00b5a7522b406ec3\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1807.02635\",\"authors\":[{\"authorId\":\"2338742\",\"name\":\"Y. Jang\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"5ec868ebe59918f94140bb2889b9027c55c09b65\",\"title\":\"Video Prediction with Appearance and Motion Conditions\",\"url\":\"https://www.semanticscholar.org/paper/5ec868ebe59918f94140bb2889b9027c55c09b65\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3306557\",\"name\":\"Liangyan Gui\"},{\"authorId\":\"1951703\",\"name\":\"K. Zhang\"},{\"authorId\":\"2302062\",\"name\":\"Yu-Xiong Wang\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"144915495\",\"name\":\"Jos\\u00e9 M. F. Moura\"},{\"authorId\":\"1956361\",\"name\":\"M. Veloso\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6f05c1fb945cd31755f7aed52b1a2695adde5d2b\",\"title\":\"Encoder Decoder Conditioning motion Seed motion PredictionPredictor Groundtruth Real or Generated Discriminator Training : Inference : Encoder Decoder Predictor Predicted Motions Demonstration of Prediction Skeleton Generation Conditioning motion\",\"url\":\"https://www.semanticscholar.org/paper/6f05c1fb945cd31755f7aed52b1a2695adde5d2b\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1912.12773\",\"authors\":[{\"authorId\":\"88726258\",\"name\":\"Karl Schmeckpeper\"},{\"authorId\":\"14484808\",\"name\":\"Annie Xie\"},{\"authorId\":\"40900227\",\"name\":\"Oleh Rybkin\"},{\"authorId\":\"71692259\",\"name\":\"Stephen Tian\"},{\"authorId\":\"1751586\",\"name\":\"Kostas Daniilidis\"},{\"authorId\":\"1381906625\",\"name\":\"Sergey Levine\"},{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"}],\"doi\":\"10.1007/978-3-030-58565-5_42\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"124ec2c95bc0fe417be2bb0d0701f88583d6a16a\",\"title\":\"Learning Predictive Models From Observation and Interaction\",\"url\":\"https://www.semanticscholar.org/paper/124ec2c95bc0fe417be2bb0d0701f88583d6a16a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2689633\",\"name\":\"Andrew Jaegle\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"29be236bb68e503a6df6bb4932984fbca5452669\",\"title\":\"Learning, Moving, And Predicting With Global Motion Representations\",\"url\":\"https://www.semanticscholar.org/paper/29be236bb68e503a6df6bb4932984fbca5452669\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47818720\",\"name\":\"L. Chen\"},{\"authorId\":\"1697700\",\"name\":\"Jiwen Lu\"},{\"authorId\":\"2450987\",\"name\":\"Z. Song\"},{\"authorId\":\"49640256\",\"name\":\"J. Zhou\"}],\"doi\":\"10.1007/978-3-030-01219-9_26\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bec3c3e6bb9c738dad942f00fc69848018c3b1cc\",\"title\":\"Part-Activated Deep Reinforcement Learning for Action Prediction\",\"url\":\"https://www.semanticscholar.org/paper/bec3c3e6bb9c738dad942f00fc69848018c3b1cc\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145809312\",\"name\":\"D. Pavlyuk\"}],\"doi\":\"10.1109/MTITS.2019.8883353\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"6841a30442965ecabc65fcb6ddfcf7d1d23b6a3a\",\"title\":\"Spatiotemporal Traffic Forecasting as a Video Prediction Problem\",\"url\":\"https://www.semanticscholar.org/paper/6841a30442965ecabc65fcb6ddfcf7d1d23b6a3a\",\"venue\":\"2019 6th International Conference on Models and Technologies for Intelligent Transportation Systems (MT-ITS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2011845\",\"name\":\"Yuke Li\"}],\"doi\":\"10.1145/3240508.3240551\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"40ff3276e62f03fe216d8592d2fc994d8eead010\",\"title\":\"Video Forecasting with Forward-Backward-Net: Delving Deeper into Spatiotemporal Consistency\",\"url\":\"https://www.semanticscholar.org/paper/40ff3276e62f03fe216d8592d2fc994d8eead010\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9400214\",\"name\":\"Guangxing Han\"},{\"authorId\":\"37735027\",\"name\":\"Xuan Zhang\"},{\"authorId\":\"3244057\",\"name\":\"Chongrong Li\"}],\"doi\":\"10.1145/3240508.3240693\",\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"c5bacb5489537012805e88ad7f4f70c96a438f88\",\"title\":\"Semi-Supervised DFF: Decoupling Detection and Feature Flow for Video Object Detectors\",\"url\":\"https://www.semanticscholar.org/paper/c5bacb5489537012805e88ad7f4f70c96a438f88\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9384558\",\"name\":\"Runsheng Yu\"},{\"authorId\":\"46451107\",\"name\":\"Zhenyu Shi\"},{\"authorId\":\"2343895\",\"name\":\"Laiyun Qing\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b8d8501595f38974e001a66752dc7098db13dfec\",\"title\":\"Unsupervised Learning aids Prediction: Using Future Representation Learning Variantial Autoencoder for Human Action Prediction\",\"url\":\"https://www.semanticscholar.org/paper/b8d8501595f38974e001a66752dc7098db13dfec\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8082703\",\"name\":\"Xiongtao Chen\"},{\"authorId\":\"46315174\",\"name\":\"Wenmin Wang\"}],\"doi\":\"10.1109/TMM.2019.2946475\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"e0cd4513409f0e4942dc5890d2530ddeda1b800e\",\"title\":\"Uni-and-Bi-Directional Video Prediction via Learning Object-Centric Transformation\",\"url\":\"https://www.semanticscholar.org/paper/e0cd4513409f0e4942dc5890d2530ddeda1b800e\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"1803.04108\",\"authors\":[{\"authorId\":\"145808756\",\"name\":\"Xuanyi Dong\"},{\"authorId\":\"144761066\",\"name\":\"Yan Yan\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":null,\"name\":\"Yi Yang\"}],\"doi\":\"10.1109/CVPR.2018.00047\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"77875d6e4d8c7ed3baeb259fd5696e921f59d7ad\",\"title\":\"Style Aggregated Network for Facial Landmark Detection\",\"url\":\"https://www.semanticscholar.org/paper/77875d6e4d8c7ed3baeb259fd5696e921f59d7ad\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1810.01325\",\"authors\":[{\"authorId\":\"51466944\",\"name\":\"Sandra Aigner\"},{\"authorId\":\"119567230\",\"name\":\"Marco Korner\"}],\"doi\":\"10.5194/isprs-archives-xlii-2-w16-3-2019\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"b6cad0b0ffd5d7b5ec1db60173c194ae2a9ec947\",\"title\":\"FutureGAN: Anticipating the Future Frames of Video Sequences using Spatio-Temporal 3d Convolutions in Progressively Growing GANs\",\"url\":\"https://www.semanticscholar.org/paper/b6cad0b0ffd5d7b5ec1db60173c194ae2a9ec947\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2002.09905\",\"authors\":[{\"authorId\":\"146270823\",\"name\":\"Beibei Jin\"},{\"authorId\":\"1943030\",\"name\":\"Y. Hu\"},{\"authorId\":\"31431435\",\"name\":\"Qiankun Tang\"},{\"authorId\":\"66692321\",\"name\":\"Jingyu Niu\"},{\"authorId\":\"144578811\",\"name\":\"Z. Shi\"},{\"authorId\":\"152713339\",\"name\":\"Yinhe Han\"},{\"authorId\":\"40613624\",\"name\":\"Xiaowei Li\"}],\"doi\":\"10.1109/cvpr42600.2020.00461\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a280048e69d41750c42d6f96e451e75c52c07741\",\"title\":\"Exploring Spatial-Temporal Multi-Frequency Analysis for High-Fidelity and Temporal-Consistency Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/a280048e69d41750c42d6f96e451e75c52c07741\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2029288\",\"name\":\"Diego Valsesia\"},{\"authorId\":\"3187585\",\"name\":\"G. Fracastoro\"},{\"authorId\":\"1702477\",\"name\":\"E. Magli\"}],\"doi\":\"10.1109/TMM.2020.2976627\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"23abafcf34d38c60cd38474470031561e2345ff8\",\"title\":\"Learning Localized Representations of Point Clouds With Graph-Convolutional Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/23abafcf34d38c60cd38474470031561e2345ff8\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yufan Zhou\"},{\"authorId\":\"119807589\",\"name\":\"H. Dong\"},{\"authorId\":\"9363305\",\"name\":\"A. El Saddik\"}],\"doi\":\"10.1109/ACCESS.2020.2987281\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cd400ae50c0bed1fe47a7a07bbdcfb20ef5b5389\",\"title\":\"Deep Learning in Next-Frame Prediction: A Benchmark Review\",\"url\":\"https://www.semanticscholar.org/paper/cd400ae50c0bed1fe47a7a07bbdcfb20ef5b5389\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1804.01523\",\"authors\":[{\"authorId\":\"49250083\",\"name\":\"Alex X. Lee\"},{\"authorId\":\"2844849\",\"name\":\"Richard Zhang\"},{\"authorId\":\"27535721\",\"name\":\"Frederik Ebert\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"},{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9f67271a1edea3bf80c64c2d54e2a0a57612a567\",\"title\":\"Stochastic Adversarial Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/9f67271a1edea3bf80c64c2d54e2a0a57612a567\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"73772533\",\"name\":\"Robert Pottorff\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"623fcfca03386bd48be46679d3305c7ef4436b7d\",\"title\":\"Video Prediction with Invertible Linear Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/623fcfca03386bd48be46679d3305c7ef4436b7d\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2003.01460\",\"authors\":[{\"authorId\":\"3965182\",\"name\":\"V. Guen\"},{\"authorId\":\"1728523\",\"name\":\"N. Thome\"}],\"doi\":\"10.1109/cvpr42600.2020.01149\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"603a0764092fbda01f3414071ea2813c49e1efa3\",\"title\":\"Disentangling Physical Dynamics From Unknown Factors for Unsupervised Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/603a0764092fbda01f3414071ea2813c49e1efa3\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1912.02401\",\"authors\":[{\"authorId\":\"8080821\",\"name\":\"Megha Nawhal\"},{\"authorId\":\"1936990\",\"name\":\"Mengyao Zhai\"},{\"authorId\":\"20812150\",\"name\":\"Andreas M. Lehrmann\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"}],\"doi\":\"10.1007/978-3-030-58610-2_23\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4ebb4985c6da258fe47a63d1f9dc1ae491e6db62\",\"title\":\"Generating Videos of Zero-Shot Compositions of Actions and Objects\",\"url\":\"https://www.semanticscholar.org/paper/4ebb4985c6da258fe47a63d1f9dc1ae491e6db62\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8080821\",\"name\":\"Megha Nawhal\"},{\"authorId\":\"2453402\",\"name\":\"Meng-Yao Zhai\"},{\"authorId\":\"20812150\",\"name\":\"Andreas M. Lehrmann\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"53ea5e0448c309c3614bba25bac58f46f06690c7\",\"title\":\"Zero-Shot Generation of Human-Object Interaction Videos\",\"url\":\"https://www.semanticscholar.org/paper/53ea5e0448c309c3614bba25bac58f46f06690c7\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47508738\",\"name\":\"Shuangshuang Guo\"},{\"authorId\":\"2343895\",\"name\":\"Laiyun Qing\"},{\"authorId\":\"145235303\",\"name\":\"Jun Miao\"},{\"authorId\":\"7667827\",\"name\":\"L. Duan\"}],\"doi\":\"10.1109/BigMM.2018.8499470\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ee15b67b606ff49cd17467b062c11441e3b2dd70\",\"title\":\"Deep Residual Feature Learning for Action Prediction\",\"url\":\"https://www.semanticscholar.org/paper/ee15b67b606ff49cd17467b062c11441e3b2dd70\",\"venue\":\"2018 IEEE Fourth International Conference on Multimedia Big Data (BigMM)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4116725\",\"name\":\"Qing Wu\"},{\"authorId\":\"2007154\",\"name\":\"Y. Liu\"},{\"authorId\":\"144682668\",\"name\":\"Q. Li\"},{\"authorId\":\"33367707\",\"name\":\"Shaoli Jin\"},{\"authorId\":\"1774622\",\"name\":\"Fengzhong Li\"}],\"doi\":\"10.1117/12.2505431\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3f8b5b2b123c09caf9871dbfb682903e14b40ebc\",\"title\":\"The application of deep learning in computer vision\",\"url\":\"https://www.semanticscholar.org/paper/3f8b5b2b123c09caf9871dbfb682903e14b40ebc\",\"venue\":\"2017 Chinese Automation Congress (CAC)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"102509914\",\"name\":\"Radamanthys Stivaktakis\"},{\"authorId\":\"47952527\",\"name\":\"G. Tsagkatakis\"},{\"authorId\":\"1694755\",\"name\":\"P. Tsakalides\"}],\"doi\":\"10.3390/make2030017\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d3d8366c5186914be2cfbf43a6457df6d83db861\",\"title\":\"Semantic Predictive Coding with Arbitrated Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/d3d8366c5186914be2cfbf43a6457df6d83db861\",\"venue\":\"Mach. Learn. Knowl. Extr.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29901316\",\"name\":\"Prateep Bhattacharjee\"},{\"authorId\":\"144009889\",\"name\":\"Sukhendu Das\"}],\"doi\":\"10.1007/978-3-030-11015-4_15\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"92592480ff60ed8bdf068c90bf614c1d7a8c0eb8\",\"title\":\"Context Graph Based Video Frame Prediction Using Locally Guided Objective\",\"url\":\"https://www.semanticscholar.org/paper/92592480ff60ed8bdf068c90bf614c1d7a8c0eb8\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1819153751\",\"name\":\"Pengfei Sun\"},{\"authorId\":\"145809273\",\"name\":\"Xin Su\"},{\"authorId\":\"1818552572\",\"name\":\"Shangqi Guo\"},{\"authorId\":\"144180417\",\"name\":\"Feng Chen\"}],\"doi\":\"10.1007/s10489-020-01750-z\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c64e475888c76f3313f9eeebeeb38eb4d9fb0dd\",\"title\":\"Cycle representation-disentangling network: learning to completely disentangle spatial-temporal features in video\",\"url\":\"https://www.semanticscholar.org/paper/6c64e475888c76f3313f9eeebeeb38eb4d9fb0dd\",\"venue\":\"Applied Intelligence\",\"year\":2020},{\"arxivId\":\"1804.04786\",\"authors\":[{\"authorId\":\"115504645\",\"name\":\"Y. Song\"},{\"authorId\":\"145532978\",\"name\":\"Jingwen Zhu\"},{\"authorId\":\"49620929\",\"name\":\"Dawei Li\"},{\"authorId\":\"39635018\",\"name\":\"Xiaolong Wang\"},{\"authorId\":\"144117139\",\"name\":\"Hairong Qi\"}],\"doi\":\"10.24963/ijcai.2019/129\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7c223baccf679fc212dd4d9ecbebf30b7a8616af\",\"title\":\"Talking Face Generation by Conditional Recurrent Adversarial Network\",\"url\":\"https://www.semanticscholar.org/paper/7c223baccf679fc212dd4d9ecbebf30b7a8616af\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"1712.00080\",\"authors\":[{\"authorId\":\"40175280\",\"name\":\"Huaizu Jiang\"},{\"authorId\":\"3232265\",\"name\":\"Deqing Sun\"},{\"authorId\":\"2745026\",\"name\":\"V. Jampani\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"1389846455\",\"name\":\"E. Learned-Miller\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":\"10.1109/CVPR.2018.00938\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"baa1ae74fbf7ed6204f2f6364d51375ff81aabc1\",\"title\":\"Super SloMo: High Quality Estimation of Multiple Intermediate Frames for Video Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/baa1ae74fbf7ed6204f2f6364d51375ff81aabc1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3444315\",\"name\":\"W. Tang\"},{\"authorId\":\"48265485\",\"name\":\"B. Liu\"},{\"authorId\":\"1453627264\",\"name\":\"Nenghaif Yu\"}],\"doi\":\"10.1117/1.JEI.28.6.063004\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"099c49e058d5169518d9644a433c1186eb89a14a\",\"title\":\"Anomaly residual prediction with spatial\\u2013temporal and perceptual constraints\",\"url\":\"https://www.semanticscholar.org/paper/099c49e058d5169518d9644a433c1186eb89a14a\",\"venue\":\"J. Electronic Imaging\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47883221\",\"name\":\"Jingwei Xu\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"15469693\",\"name\":\"Xiaokang Yang\"}],\"doi\":\"10.1007/s11263-020-01389-w\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6e81249d8f00e54a627785a47e62c694cce119e3\",\"title\":\"Progressive Multi-granularity Analysis for Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/6e81249d8f00e54a627785a47e62c694cce119e3\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Marco Pleines\"}],\"doi\":\"10.1007/978-3-658-29562-2_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6ef1d27202560090908e3334b5bc466c0c27f583\",\"title\":\"Generative Adversarial Networks: Verschiedene Varianten und Anwendungen aus der Praxis\",\"url\":\"https://www.semanticscholar.org/paper/6ef1d27202560090908e3334b5bc466c0c27f583\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22803355\",\"name\":\"Beibei Jin\"},{\"authorId\":\"144985887\",\"name\":\"Y. Hu\"},{\"authorId\":\"145492828\",\"name\":\"Y. Zeng\"},{\"authorId\":\"31431435\",\"name\":\"Qiankun Tang\"},{\"authorId\":\"32758259\",\"name\":\"Shice Liu\"},{\"authorId\":\"144030865\",\"name\":\"Jing Ye\"}],\"doi\":\"10.1109/IROS.2018.8594264\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9431e81519d16c87859a55bb1735f61a9e013f7e\",\"title\":\"VarNet: Exploring Variations for Unsupervised Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/9431e81519d16c87859a55bb1735f61a9e013f7e\",\"venue\":\"2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"68974015\",\"name\":\"Ke Xuel\"},{\"authorId\":\"3022373\",\"name\":\"Pei Di\"},{\"authorId\":\"46507431\",\"name\":\"Hongyu Wang\"},{\"authorId\":\"2235318\",\"name\":\"Fengshan Zou\"}],\"doi\":\"10.1109/HFR.2018.8633515\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dce4e5f4c365d2b40cc032c779e0d62b07c88d63\",\"title\":\"Predicting human trajectory with virtual HRI environment\",\"url\":\"https://www.semanticscholar.org/paper/dce4e5f4c365d2b40cc032c779e0d62b07c88d63\",\"venue\":\"2018 11th International Workshop on Human Friendly Robotics (HFR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1679427\",\"name\":\"Marina L. Gavrilova\"},{\"authorId\":\"144891213\",\"name\":\"Jian Chang\"},{\"authorId\":\"41183001\",\"name\":\"Nadia Magnenat Thalmann\"},{\"authorId\":\"3278789\",\"name\":\"Eckhard Hitzer\"},{\"authorId\":\"145102331\",\"name\":\"Hiroshi Ishikawa\"}],\"doi\":\"10.1007/978-3-030-22514-8\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8a4583c3db9ffb78c8942b0054024465033a76d2\",\"title\":\"Advances in Computer Graphics\",\"url\":\"https://www.semanticscholar.org/paper/8a4583c3db9ffb78c8942b0054024465033a76d2\",\"venue\":\"Lecture Notes in Computer Science\",\"year\":2019},{\"arxivId\":\"2003.08635\",\"authors\":[{\"authorId\":\"49006120\",\"name\":\"Osamu Shouno\"}],\"doi\":null,\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"a274a36cd1d4f2562f92d8e32cb8e72db3993f21\",\"title\":\"Photo-Realistic Video Prediction on Natural Videos of Largely Changing Frames\",\"url\":\"https://www.semanticscholar.org/paper/a274a36cd1d4f2562f92d8e32cb8e72db3993f21\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145031814\",\"name\":\"J. Walker\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"66af27ae7c29f5fadf83f29b710a1b9c89987d09\",\"title\":\"Data-Driven Visual Forecasting\",\"url\":\"https://www.semanticscholar.org/paper/66af27ae7c29f5fadf83f29b710a1b9c89987d09\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51466944\",\"name\":\"Sandra Aigner\"},{\"authorId\":\"2388085\",\"name\":\"M. K\\u00f6rner\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0fc9b202107bafa4b755c913c904d8ab046b8113\",\"title\":\"FutureGAN: Anticipating the Future Frames of Video Sequences using Spatio-Temporal 3d Convolutions in Progressively Growing Autoencoder GANs\",\"url\":\"https://www.semanticscholar.org/paper/0fc9b202107bafa4b755c913c904d8ab046b8113\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1811.10673\",\"authors\":[{\"authorId\":\"49899501\",\"name\":\"Sungsoo Kim\"},{\"authorId\":\"2199399\",\"name\":\"J. Park\"},{\"authorId\":\"46920670\",\"name\":\"C. G. Bampis\"},{\"authorId\":\"6226178\",\"name\":\"Jaeseong Lee\"},{\"authorId\":\"8306347\",\"name\":\"M. Markey\"},{\"authorId\":\"1718469\",\"name\":\"A. Dimakis\"},{\"authorId\":\"1747569\",\"name\":\"A. Bovik\"}],\"doi\":\"10.1109/ICASSP40776.2020.9054165\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c351a76401c3f1fef420ce634c3e9a87131fa826\",\"title\":\"Adversarial Video Compression Guided by Soft Edge Detection\",\"url\":\"https://www.semanticscholar.org/paper/c351a76401c3f1fef420ce634c3e9a87131fa826\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1591133581\",\"name\":\"Yujia Zhang\"},{\"authorId\":\"8199702\",\"name\":\"Michael Kampffmeyer\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"39901030\",\"name\":\"Dingwen Zhang\"},{\"authorId\":\"2554604\",\"name\":\"M. Tan\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":\"10.1007/s11042-019-08175-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5c6628a9b7ff29c113b1902e95267bd0614974c8\",\"title\":\"Dilated temporal relational adversarial network for generic video summarization\",\"url\":\"https://www.semanticscholar.org/paper/5c6628a9b7ff29c113b1902e95267bd0614974c8\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3030828\",\"name\":\"Arun Sankisa\"},{\"authorId\":\"48654737\",\"name\":\"Arjun Punjabi\"},{\"authorId\":\"144842935\",\"name\":\"A. Katsaggelos\"}],\"doi\":\"10.1007/s11760-020-01671-x\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d4eb9d45b42bea8abc3aeb591f45049ae7595525\",\"title\":\"Temporal capsule networks for video motion estimation and error concealment\",\"url\":\"https://www.semanticscholar.org/paper/d4eb9d45b42bea8abc3aeb591f45049ae7595525\",\"venue\":\"Signal Image Video Process.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46398521\",\"name\":\"Y. Liu\"},{\"authorId\":\"66821424\",\"name\":\"Yi-Tung Liao\"},{\"authorId\":\"1744044\",\"name\":\"Yen-Yu Lin\"},{\"authorId\":\"143708263\",\"name\":\"Yung-Yu Chuang\"}],\"doi\":\"10.1609/AAAI.V33I01.33018794\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"92f3548ff323a65981aed274c0b124053dce2e73\",\"title\":\"Deep Video Frame Interpolation Using Cyclic Frame Generation\",\"url\":\"https://www.semanticscholar.org/paper/92f3548ff323a65981aed274c0b124053dce2e73\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1905.12702\",\"authors\":[{\"authorId\":\"2076641\",\"name\":\"J. Toutouh\"},{\"authorId\":\"1807219\",\"name\":\"E. Hemberg\"},{\"authorId\":\"1398192342\",\"name\":\"U. O\\u2019Reilly\"}],\"doi\":\"10.1145/3321707.3321860\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"85a38c605b92827d3620135b237d8f2bcd404e2c\",\"title\":\"Spatial evolutionary generative adversarial networks\",\"url\":\"https://www.semanticscholar.org/paper/85a38c605b92827d3620135b237d8f2bcd404e2c\",\"venue\":\"GECCO\",\"year\":2019},{\"arxivId\":\"1803.07201\",\"authors\":[{\"authorId\":\"40366599\",\"name\":\"W. Liu\"},{\"authorId\":null,\"name\":\"Abhishek Sharma\"},{\"authorId\":\"1694992\",\"name\":\"O. Camps\"},{\"authorId\":\"1687866\",\"name\":\"M. Sznaier\"}],\"doi\":\"10.1007/978-3-030-01258-8_11\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b53259a81dcfa9913495bb47f62627c51e20f086\",\"title\":\"DYAN: A Dynamical Atoms-Based Network for Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/b53259a81dcfa9913495bb47f62627c51e20f086\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1807.07688\",\"authors\":[{\"authorId\":\"2870143\",\"name\":\"Bochao Wang\"},{\"authorId\":\"48212984\",\"name\":\"Hongwei Zhang\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"117744990\",\"name\":\"Y. Chen\"},{\"authorId\":\"1737218\",\"name\":\"L. Lin\"},{\"authorId\":\"50367201\",\"name\":\"Meng Yang\"}],\"doi\":\"10.1007/978-3-030-01261-8_36\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eff3ccb8a50e69d5839055dd1f3ddf21661ec60d\",\"title\":\"Toward Characteristic-Preserving Image-based Virtual Try-On Network\",\"url\":\"https://www.semanticscholar.org/paper/eff3ccb8a50e69d5839055dd1f3ddf21661ec60d\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66438378\",\"name\":\"Kongtao Zhu\"},{\"authorId\":\"3300934\",\"name\":\"Xiwei Liu\"},{\"authorId\":\"27391286\",\"name\":\"Hongxue Yang\"}],\"doi\":\"10.1109/CAC.2018.8623645\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"f571725ffc18c6249702ab457b287495302a4e68\",\"title\":\"A Survey of Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/f571725ffc18c6249702ab457b287495302a4e68\",\"venue\":\"2018 Chinese Automation Congress (CAC)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145965455\",\"name\":\"Wonmin Byeon\"},{\"authorId\":\"50621646\",\"name\":\"Qin Wang\"},{\"authorId\":\"2100612\",\"name\":\"R. Srivastava\"},{\"authorId\":\"1802604\",\"name\":\"P. Koumoutsakos\"}],\"doi\":\"10.1007/978-3-030-01270-0_46\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"86163c4270fa1173640e7b1f526ffdb482f45f17\",\"title\":\"ContextVP: Fully Context-Aware Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/86163c4270fa1173640e7b1f526ffdb482f45f17\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2594429\",\"name\":\"Na-Young Kim\"},{\"authorId\":\"52177701\",\"name\":\"Je-Won Kang\"}],\"doi\":\"10.1109/ICIP.2018.8451079\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"35f57dfe596a19c1ae3393cbb088769d6f517684\",\"title\":\"Long-Term Video Generation with Evolving Residual Video Frames\",\"url\":\"https://www.semanticscholar.org/paper/35f57dfe596a19c1ae3393cbb088769d6f517684\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2587808\",\"name\":\"Liang-Yan Gui\"},{\"authorId\":\"144552149\",\"name\":\"Kevin Zhang\"},{\"authorId\":\"2302062\",\"name\":\"Yu-Xiong Wang\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"144915495\",\"name\":\"Jos\\u00e9 M. F. Moura\"},{\"authorId\":\"145684307\",\"name\":\"M. Veloso\"}],\"doi\":\"10.1109/IROS.2018.8594452\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb8a57457e44bff50930e9f93f5b939e90ee3bc3\",\"title\":\"Teaching Robots to Predict Human Motion\",\"url\":\"https://www.semanticscholar.org/paper/eb8a57457e44bff50930e9f93f5b939e90ee3bc3\",\"venue\":\"2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2018},{\"arxivId\":\"1904.02912\",\"authors\":[{\"authorId\":\"40897201\",\"name\":\"Tsun-Hsuan Wang\"},{\"authorId\":\"94288126\",\"name\":\"Y. Cheng\"},{\"authorId\":\"49044307\",\"name\":\"Chieh Hubert Lin\"},{\"authorId\":\"1803730\",\"name\":\"Hwann-Tzong Chen\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":\"10.1109/ICCV.2019.01059\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"cb0a151cf8740c66b461ff809e086b91f14bd23b\",\"title\":\"Point-to-Point Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/cb0a151cf8740c66b461ff809e086b91f14bd23b\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2003.09565\",\"authors\":[{\"authorId\":\"2274692\",\"name\":\"Abhishek Aich\"},{\"authorId\":\"150015249\",\"name\":\"Akash Gupta\"},{\"authorId\":\"1819152\",\"name\":\"R. Panda\"},{\"authorId\":\"12212948\",\"name\":\"Rakib Hyder\"},{\"authorId\":\"27996204\",\"name\":\"M. Asif\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":\"10.1109/cvpr42600.2020.00613\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6a55aad6a51662da2d1e454a41878935a86a5d4a\",\"title\":\"Non-Adversarial Video Synthesis with Learned Priors\",\"url\":\"https://www.semanticscholar.org/paper/6a55aad6a51662da2d1e454a41878935a86a5d4a\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2002.09219\",\"authors\":[{\"authorId\":\"35622441\",\"name\":\"Jean-Yves Franceschi\"},{\"authorId\":\"32278921\",\"name\":\"Edouard Delasalles\"},{\"authorId\":\"51301828\",\"name\":\"Mickael Chen\"},{\"authorId\":\"1782552\",\"name\":\"Sylvain Lamprier\"},{\"authorId\":\"150259685\",\"name\":\"P. Gallinari\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e277ba39f761dcfbdc6efc40b2b89492566f3477\",\"title\":\"Stochastic Latent Residual Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/e277ba39f761dcfbdc6efc40b2b89492566f3477\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":\"2006.05127\",\"authors\":[{\"authorId\":\"46882417\",\"name\":\"Yuzhen Niu\"},{\"authorId\":\"49833153\",\"name\":\"Wei-Feng Shi\"},{\"authorId\":\"143800486\",\"name\":\"Wenxi Liu\"},{\"authorId\":\"2548483\",\"name\":\"Shengfeng He\"},{\"authorId\":\"143938045\",\"name\":\"Jia Pan\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9dc50cbd1a9c5a25363755f95b8c59ebcabf4d44\",\"title\":\"Over-crowdedness Alert! Forecasting the Future Crowd Distribution\",\"url\":\"https://www.semanticscholar.org/paper/9dc50cbd1a9c5a25363755f95b8c59ebcabf4d44\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1811.09245\",\"authors\":[{\"authorId\":\"144648787\",\"name\":\"M. Saito\"},{\"authorId\":\"3083107\",\"name\":\"Shunta Saito\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ef29d5c85b70fd9dbe04a7b839fbc7d413b161e6\",\"title\":\"TGANv2: Efficient Training of Large Models for Video Generation with Multiple Subsampling Layers\",\"url\":\"https://www.semanticscholar.org/paper/ef29d5c85b70fd9dbe04a7b839fbc7d413b161e6\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1809.08318\",\"authors\":[{\"authorId\":\"15995259\",\"name\":\"Adam W. Terwilliger\"},{\"authorId\":\"47604355\",\"name\":\"G. Brazil\"},{\"authorId\":\"38284381\",\"name\":\"X. Liu\"}],\"doi\":\"10.1109/WACV.2019.00186\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d7919088b12e861fd449c47dd8622db9f584af9e\",\"title\":\"Recurrent Flow-Guided Semantic Forecasting\",\"url\":\"https://www.semanticscholar.org/paper/d7919088b12e861fd449c47dd8622db9f584af9e\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26902477\",\"name\":\"Amir Rasouli\"},{\"authorId\":\"3468296\",\"name\":\"Iuliia Kotseruba\"},{\"authorId\":\"3211787\",\"name\":\"Toni Kunic\"},{\"authorId\":\"1727853\",\"name\":\"John K. Tsotsos\"}],\"doi\":\"10.1109/ICCV.2019.00636\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"36194c76ce53be8e8fba71acbf8d235c7b39342b\",\"title\":\"PIE: A Large-Scale Dataset and Models for Pedestrian Intention Estimation and Trajectory Prediction\",\"url\":\"https://www.semanticscholar.org/paper/36194c76ce53be8e8fba71acbf8d235c7b39342b\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134888279\",\"name\":\"Yung-Han Ho\"},{\"authorId\":\"2576217\",\"name\":\"C. Chan\"},{\"authorId\":\"1749122\",\"name\":\"Wen-Hsiao Peng\"}],\"doi\":\"10.1109/ICIP40778.2020.9191154\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b8133ab8dacfad2da83e2199c1b5431fbee794d3\",\"title\":\"Deep Video Prediction Through Sparse Motion Regularization\",\"url\":\"https://www.semanticscholar.org/paper/b8133ab8dacfad2da83e2199c1b5431fbee794d3\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"2010.08188\",\"authors\":[{\"authorId\":\"52061414\",\"name\":\"SungHyun Park\"},{\"authorId\":\"1438418837\",\"name\":\"Kangyeol Kim\"},{\"authorId\":\"48174707\",\"name\":\"J. Lee\"},{\"authorId\":\"1934247587\",\"name\":\"Jaegul Choo\"},{\"authorId\":\"2119006\",\"name\":\"Joonseok Lee\"},{\"authorId\":\"49899493\",\"name\":\"Sookyung Kim\"},{\"authorId\":\"1387328701\",\"name\":\"Edward Choi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"58db26d7064d16bd45d2fda6b5ded997f47278e5\",\"title\":\"Vid-ODE: Continuous-Time Video Generation with Neural Ordinary Differential Equation\",\"url\":\"https://www.semanticscholar.org/paper/58db26d7064d16bd45d2fda6b5ded997f47278e5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10397877\",\"name\":\"Jiameng Pu\"},{\"authorId\":\"2007928171\",\"name\":\"Neal Mangaokar\"},{\"authorId\":\"2081795\",\"name\":\"Bolun Wang\"},{\"authorId\":\"144417520\",\"name\":\"C. K. Reddy\"},{\"authorId\":\"34824488\",\"name\":\"B. Viswanath\"}],\"doi\":\"10.1145/3427228.3427285\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9fa3abb82e00f4c97deb807de330f3449f8fc511\",\"title\":\"NoiseScope: Detecting Deepfake Images in a Blind Setting\",\"url\":\"https://www.semanticscholar.org/paper/9fa3abb82e00f4c97deb807de330f3449f8fc511\",\"venue\":\"ACSAC\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"118833440\",\"name\":\"Kristijan Fugosic\"},{\"authorId\":\"101947437\",\"name\":\"J. Saric\"},{\"authorId\":\"3166278\",\"name\":\"Sinisa Segvic\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"efcdbe35f5ee47fef8d65e2672ac030ff512cc2e\",\"title\":\"Multimodal semantic forecasting based on conditional generation of future features\",\"url\":\"https://www.semanticscholar.org/paper/efcdbe35f5ee47fef8d65e2672ac030ff512cc2e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50244843\",\"name\":\"E. Barsoum\"}],\"doi\":\"10.7916/d8-sq89-mm29\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d8d9ab14c06bbbe084232517c8a67581d16d4ef0\",\"title\":\"Human Motion Anticipation and Recognition from RGB-D\",\"url\":\"https://www.semanticscholar.org/paper/d8d9ab14c06bbbe084232517c8a67581d16d4ef0\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144620586\",\"name\":\"X. Wu\"},{\"authorId\":\"144024533\",\"name\":\"Kun Xu\"},{\"authorId\":\"144003456\",\"name\":\"P. Hall\"}],\"doi\":\"10.23919/TST.2017.8195348\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"722514cf193ea8b301475de9da5a0061f2e47bdd\",\"title\":\"A survey of image synthesis and editing with generative adversarial networks\",\"url\":\"https://www.semanticscholar.org/paper/722514cf193ea8b301475de9da5a0061f2e47bdd\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49415643\",\"name\":\"Y. Wang\"},{\"authorId\":\"46696648\",\"name\":\"L. Zhou\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1109/CVPR.2018.00557\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1b8b9332886ea661e5a46bb87118956f1f4c15f3\",\"title\":\"Temporal Hallucinating for Action Recognition with Few Still Images\",\"url\":\"https://www.semanticscholar.org/paper/1b8b9332886ea661e5a46bb87118956f1f4c15f3\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145809312\",\"name\":\"D. Pavlyuk\"}],\"doi\":\"10.1007/978-3-030-44610-9_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eeefcaaa7a3033b0da4a8ac613e06110b5f05c98\",\"title\":\"Make It Flat: Multidimensional Scaling of Citywide Traffic Data\",\"url\":\"https://www.semanticscholar.org/paper/eeefcaaa7a3033b0da4a8ac613e06110b5f05c98\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1909.10833\",\"authors\":[{\"authorId\":\"144027562\",\"name\":\"P. K\\u00f6nig\"},{\"authorId\":\"51466944\",\"name\":\"Sandra Aigner\"},{\"authorId\":\"2388085\",\"name\":\"M. K\\u00f6rner\"}],\"doi\":\"10.1109/ITSC.2019.8917046\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5bacdc2068aa755016faf585f2d2f90b9046d4eb\",\"title\":\"Enhancing Traffic Scene Predictions with Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/5bacdc2068aa755016faf585f2d2f90b9046d4eb\",\"venue\":\"2019 IEEE Intelligent Transportation Systems Conference (ITSC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50844674\",\"name\":\"Xiaojuan Qi\"},{\"authorId\":\"2926099\",\"name\":\"Zhengzhe Liu\"},{\"authorId\":\"143832240\",\"name\":\"Qifeng Chen\"},{\"authorId\":\"2949183\",\"name\":\"Jiaya Jia\"}],\"doi\":\"10.1109/CVPR.2019.00786\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1d217d9234a3da82dc641a91ea5a1cfa0594a326\",\"title\":\"3D Motion Decomposition for RGBD Future Dynamic Scene Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/1d217d9234a3da82dc641a91ea5a1cfa0594a326\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1808.00661\",\"authors\":[{\"authorId\":\"31506147\",\"name\":\"Q. Zhou\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"144194066\",\"name\":\"K. Gong\"},{\"authorId\":\"1737218\",\"name\":\"L. Lin\"}],\"doi\":\"10.1145/3240508.3240660\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"313c068bf4864f156d388376657edc60a8db6282\",\"title\":\"Adaptive Temporal Encoding Network for Video Instance-level Human Parsing\",\"url\":\"https://www.semanticscholar.org/paper/313c068bf4864f156d388376657edc60a8db6282\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12694833\",\"name\":\"Shijie Nie\"},{\"authorId\":\"51515749\",\"name\":\"Lin Gu\"},{\"authorId\":\"1405779995\",\"name\":\"Art Subpa-Asa\"},{\"authorId\":\"1419473623\",\"name\":\"Ilyes Kacher\"},{\"authorId\":\"153162213\",\"name\":\"Ko Nishino\"},{\"authorId\":\"1746794\",\"name\":\"I. Sato\"}],\"doi\":\"10.1007/978-3-030-20876-9_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"41a1b0defacdb99256bb8149054a8fde321dee45\",\"title\":\"A Data-Driven Approach for Direct and Global Component Separation from a Single Image\",\"url\":\"https://www.semanticscholar.org/paper/41a1b0defacdb99256bb8149054a8fde321dee45\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2244591\",\"name\":\"D. Jonietz\"},{\"authorId\":\"46952925\",\"name\":\"Michael Kopp\"}],\"doi\":\"10.4230/LIPIcs.COSIT.2019.27\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b68b06c782cf459068b683f9d6b6eb4059ccb4a8\",\"title\":\"Towards Modeling Geographical Processes with Generative Adversarial Networks (GANs) (Short Paper)\",\"url\":\"https://www.semanticscholar.org/paper/b68b06c782cf459068b683f9d6b6eb4059ccb4a8\",\"venue\":\"COSIT\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2346355\",\"name\":\"Ashish Bora\"},{\"authorId\":\"4989538\",\"name\":\"E. Price\"},{\"authorId\":\"1718469\",\"name\":\"A. Dimakis\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b959d5655a3b2f92c2c1a8a7896fecafafea979d\",\"title\":\"AmbientGAN: Generative models from lossy measurements\",\"url\":\"https://www.semanticscholar.org/paper/b959d5655a3b2f92c2c1a8a7896fecafafea979d\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50768687\",\"name\":\"Zheng Lei\"},{\"authorId\":\"144688691\",\"name\":\"F. Deng\"},{\"authorId\":\"50030836\",\"name\":\"Xudong Yang\"}],\"doi\":\"10.1145/3317640.3317644\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"11c006797085bdaa0ea26f813036c88e8be120a7\",\"title\":\"Spatial Temporal Balanced Generative Adversarial AutoEncoder for Anomaly Detection\",\"url\":\"https://www.semanticscholar.org/paper/11c006797085bdaa0ea26f813036c88e8be120a7\",\"venue\":\"IVSP 2019\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134888279\",\"name\":\"Yung-Han Ho\"},{\"authorId\":\"1381649479\",\"name\":\"Chuan-Yuan Cho\"},{\"authorId\":\"1749122\",\"name\":\"Wen-Hsiao Peng\"}],\"doi\":\"10.1109/ICIP.2019.8803825\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5316dac900b55d1099d65b2a7e6598bc761be239\",\"title\":\"Deep Reinforcement Learning for Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/5316dac900b55d1099d65b2a7e6598bc761be239\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"1710.08518\",\"authors\":[{\"authorId\":\"145965455\",\"name\":\"Wonmin Byeon\"},{\"authorId\":\"152300135\",\"name\":\"Qin Wang\"},{\"authorId\":\"2100612\",\"name\":\"R. Srivastava\"},{\"authorId\":\"1802604\",\"name\":\"P. Koumoutsakos\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ebb9d53668205c5797045ba130df18842e3eadef\",\"title\":\"Fully Context-Aware Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/ebb9d53668205c5797045ba130df18842e3eadef\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1903.06571\",\"authors\":[{\"authorId\":\"2350325\",\"name\":\"D. Lee\"},{\"authorId\":\"1945962\",\"name\":\"T. Pfister\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/CVPR.2019.01030\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bcad284af2a484d508a695dc534b0363812b1993\",\"title\":\"Inserting Videos Into Videos\",\"url\":\"https://www.semanticscholar.org/paper/bcad284af2a484d508a695dc534b0363812b1993\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46489265\",\"name\":\"Yu-Ying Yeh\"},{\"authorId\":\"1614039983\",\"name\":\"Y. Liu\"},{\"authorId\":\"37811787\",\"name\":\"Wei-Chen Chiu\"},{\"authorId\":null,\"name\":\"Yu-Chiang Frank Wang\"}],\"doi\":\"10.1109/TETCI.2020.2968599\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d96db0e2164f464ef9dc5dd030672ea3e3c02d57\",\"title\":\"Static2Dynamic: Video Inference From a Deep Glimpse\",\"url\":\"https://www.semanticscholar.org/paper/d96db0e2164f464ef9dc5dd030672ea3e3c02d57\",\"venue\":\"IEEE Transactions on Emerging Topics in Computational Intelligence\",\"year\":2020},{\"arxivId\":\"1811.09245\",\"authors\":[{\"authorId\":\"1725418556\",\"name\":\"Masaki Saito\"},{\"authorId\":\"3083107\",\"name\":\"Shunta Saito\"},{\"authorId\":\"152400765\",\"name\":\"Masanori Koyama\"},{\"authorId\":\"3456592\",\"name\":\"S. Kobayashi\"}],\"doi\":\"10.1007/s11263-020-01333-y\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"14b175654024c6b57653239674305fe91bca89a1\",\"title\":\"Train Sparsely, Generate Densely: Memory-Efficient Unsupervised Training of High-Resolution Temporal GAN\",\"url\":\"https://www.semanticscholar.org/paper/14b175654024c6b57653239674305fe91bca89a1\",\"venue\":\"International Journal of Computer Vision\",\"year\":2020},{\"arxivId\":\"1902.06162\",\"authors\":[{\"authorId\":\"29724362\",\"name\":\"Longlong Jing\"},{\"authorId\":\"35484757\",\"name\":\"Yingli Tian\"}],\"doi\":\"10.1109/tpami.2020.2992393\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4c94ee7df6bc2bfcac76703be4f059a79010f7e5\",\"title\":\"Self-supervised Visual Feature Learning with Deep Neural Networks: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/4c94ee7df6bc2bfcac76703be4f059a79010f7e5\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"2004.14878\",\"authors\":[{\"authorId\":\"46207490\",\"name\":\"Zden\\u011bk Straka\"},{\"authorId\":\"51181107\",\"name\":\"Tom\\u00e1\\u0161 Svoboda\"},{\"authorId\":\"152703120\",\"name\":\"M. Hoffmann\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"cd70bf6e980b0b962c8e18a9ae9878da55072178\",\"title\":\"PreCNet: Next Frame Video Prediction Based on Predictive Coding\",\"url\":\"https://www.semanticscholar.org/paper/cd70bf6e980b0b962c8e18a9ae9878da55072178\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1812.07460\",\"authors\":[{\"authorId\":\"48194309\",\"name\":\"Julian Krebs\"},{\"authorId\":\"1781157\",\"name\":\"H. Delingette\"},{\"authorId\":\"1892637\",\"name\":\"B. Mailh\\u00e9\"},{\"authorId\":\"144827643\",\"name\":\"N. Ayache\"},{\"authorId\":\"2219355\",\"name\":\"T. Mansi\"}],\"doi\":\"10.1109/TMI.2019.2897112\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9995628af5c31429d5dadd734a069cfd244f370c\",\"title\":\"Learning a Probabilistic Model for Diffeomorphic Registration\",\"url\":\"https://www.semanticscholar.org/paper/9995628af5c31429d5dadd734a069cfd244f370c\",\"venue\":\"IEEE Transactions on Medical Imaging\",\"year\":2019},{\"arxivId\":\"1902.08716\",\"authors\":[{\"authorId\":\"47059386\",\"name\":\"Ling Zhang\"},{\"authorId\":\"50706692\",\"name\":\"Le Lu\"},{\"authorId\":\"144440354\",\"name\":\"Robert Zhu\"},{\"authorId\":\"3774191\",\"name\":\"M. Bagheri\"},{\"authorId\":\"144838131\",\"name\":\"R. Summers\"},{\"authorId\":\"1722252\",\"name\":\"J. Yao\"}],\"doi\":\"10.1109/TMI.2019.2943841\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"575554f11fccb1a67c1fbb69d58ed42702f638ea\",\"title\":\"Spatio-Temporal Convolutional LSTMs for Tumor Growth Prediction by Learning 4D Longitudinal Patient Data\",\"url\":\"https://www.semanticscholar.org/paper/575554f11fccb1a67c1fbb69d58ed42702f638ea\",\"venue\":\"IEEE Transactions on Medical Imaging\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144898072\",\"name\":\"Xiao Jin\"},{\"authorId\":\"2989256\",\"name\":\"Peiguang Jing\"},{\"authorId\":\"2788104\",\"name\":\"Yuting Su\"}],\"doi\":\"10.1109/ACCESS.2018.2867370\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"878de992815b4e491a9795239f525b5647986d17\",\"title\":\"AMFNet: An Adversarial Network for Median Filtering Detection\",\"url\":\"https://www.semanticscholar.org/paper/878de992815b4e491a9795239f525b5647986d17\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":\"1801.00543\",\"authors\":[{\"authorId\":\"46868809\",\"name\":\"Y. Zhang\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"39901030\",\"name\":\"Dingwen Zhang\"},{\"authorId\":\"143810339\",\"name\":\"M. Tan\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":\"10.1016/J.PATREC.2018.07.030\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c6e20087e39f997631416b54fb67882817f36b56\",\"title\":\"Unsupervised Object-Level Video Summarization with Online Motion Auto-Encoder\",\"url\":\"https://www.semanticscholar.org/paper/c6e20087e39f997631416b54fb67882817f36b56\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3407762\",\"name\":\"Apratim Bhattacharyya\"},{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f51817280e744d5af61574890214dc2ddeaa6809\",\"title\":\"Long-Term Image Boundary Prediction\",\"url\":\"https://www.semanticscholar.org/paper/f51817280e744d5af61574890214dc2ddeaa6809\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"2007.08509\",\"authors\":[{\"authorId\":\"36508529\",\"name\":\"Arun Mallya\"},{\"authorId\":\"2195314\",\"name\":\"T. Wang\"},{\"authorId\":\"36775862\",\"name\":\"K. Sapra\"},{\"authorId\":\"1596793949\",\"name\":\"M. Liu\"}],\"doi\":\"10.1007/978-3-030-58598-3_22\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"633a7a0c92dd8c254b65a11b759b99c157e115c7\",\"title\":\"World-Consistent Video-to-Video Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/633a7a0c92dd8c254b65a11b759b99c157e115c7\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"1682058\",\"name\":\"H. Zhang\"},{\"authorId\":\"1737218\",\"name\":\"L. Lin\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":\"10.1007/978-3-030-01261-8_34\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a1653e88be986aee2f37792c3fb05f0ee7fbef94\",\"title\":\"Generative Semantic Manipulation with Mask-Contrasting GAN\",\"url\":\"https://www.semanticscholar.org/paper/a1653e88be986aee2f37792c3fb05f0ee7fbef94\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37145669\",\"name\":\"Lu Sheng\"},{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"},{\"authorId\":\"47093626\",\"name\":\"Jiaming Guo\"},{\"authorId\":\"145965208\",\"name\":\"J. Shao\"},{\"authorId\":null,\"name\":\"Xiaogang Wang\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"545f3b0c15a0a555fda0d2377646c0c70090c185\",\"title\":\"Tgt . ( a ) GT sequence ( b ) ImagineFlow ( c ) Backward warping Before After\",\"url\":\"https://www.semanticscholar.org/paper/545f3b0c15a0a555fda0d2377646c0c70090c185\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"95115816\",\"name\":\"J. Wang\"},{\"authorId\":\"1993672083\",\"name\":\"Tong Sha\"},{\"authorId\":\"2236084\",\"name\":\"Weitong Zhang\"},{\"authorId\":\"2282019\",\"name\":\"Zhoujun Li\"},{\"authorId\":\"153040576\",\"name\":\"T. Mei\"}],\"doi\":\"10.1145/3394171.3413514\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6c540a814bf2112d8140b15abcbaf70cf7b7091b\",\"title\":\"Down to the Last Detail: Virtual Try-on with Fine-grained Details\",\"url\":\"https://www.semanticscholar.org/paper/6c540a814bf2112d8140b15abcbaf70cf7b7091b\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47882735\",\"name\":\"Jingwei Xu\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"46948132\",\"name\":\"Zefan Li\"},{\"authorId\":\"3392007\",\"name\":\"Shuo Cheng\"},{\"authorId\":\"1795291\",\"name\":\"X. Yang\"}],\"doi\":\"10.1109/CVPR.2018.00158\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6ff497677f27d3e45e4633550c1a0e5243b8fa3b\",\"title\":\"Structure Preserving Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/6ff497677f27d3e45e4633550c1a0e5243b8fa3b\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153439700\",\"name\":\"Y. Kwon\"},{\"authorId\":\"49360298\",\"name\":\"M. Park\"}],\"doi\":\"10.1109/CVPR.2019.00191\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f373bccc69bec811fa93b27d59a560b9e4ed0946\",\"title\":\"Predicting Future Frames Using Retrospective Cycle GAN\",\"url\":\"https://www.semanticscholar.org/paper/f373bccc69bec811fa93b27d59a560b9e4ed0946\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1901.01649\",\"authors\":[{\"authorId\":\"67083303\",\"name\":\"Guohao Ying\"},{\"authorId\":\"50817744\",\"name\":\"Yingtian Zou\"},{\"authorId\":\"144363232\",\"name\":\"L. Wan\"},{\"authorId\":\"1736595\",\"name\":\"Yiming Hu\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":\"10.1007/978-3-030-20876-9_18\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"62f4f3654f9e4c3b94aa70dd4a158c961288fbc4\",\"title\":\"Better Guider Predicts Future Better: Difference Guided Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/62f4f3654f9e4c3b94aa70dd4a158c961288fbc4\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"1809.01372\",\"authors\":[{\"authorId\":\"7192666\",\"name\":\"H. Huang\"},{\"authorId\":\"2063358\",\"name\":\"Senzhe Xu\"},{\"authorId\":\"15996814\",\"name\":\"Junxiong Cai\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"144110127\",\"name\":\"S. Hu\"}],\"doi\":\"10.1109/TIP.2019.2925550\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"14d1e3c6405ed22d30d88d577275233cca89d3a0\",\"title\":\"Temporally Coherent Video Harmonization Using Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/14d1e3c6405ed22d30d88d577275233cca89d3a0\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2621181\",\"name\":\"Haoye Dong\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"50457502\",\"name\":\"Xiaohui Shen\"},{\"authorId\":\"152365288\",\"name\":\"B. Wu\"},{\"authorId\":\"8567485\",\"name\":\"Bing-cheng Chen\"},{\"authorId\":\"144926874\",\"name\":\"J. Yin\"}],\"doi\":\"10.1109/ICCV.2019.00125\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"69a1e9a45eff33105a5f236e36876c917b278a0e\",\"title\":\"FW-GAN: Flow-Navigated Warping GAN for Video Virtual Try-On\",\"url\":\"https://www.semanticscholar.org/paper/69a1e9a45eff33105a5f236e36876c917b278a0e\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51189950\",\"name\":\"M. C. Comes\"},{\"authorId\":\"1564226524\",\"name\":\"J. Filippi\"},{\"authorId\":\"1717202\",\"name\":\"A. Mencattini\"},{\"authorId\":\"47233879\",\"name\":\"P. Casti\"},{\"authorId\":\"153937073\",\"name\":\"G. Cerrato\"},{\"authorId\":\"7019503\",\"name\":\"A. Sauvat\"},{\"authorId\":\"5049762\",\"name\":\"E. Vacchelli\"},{\"authorId\":\"7429517\",\"name\":\"A. De Ninno\"},{\"authorId\":\"26627439\",\"name\":\"D. Di Giuseppe\"},{\"authorId\":\"1561708132\",\"name\":\"M. D'Orazio\"},{\"authorId\":\"98905579\",\"name\":\"F. Mattei\"},{\"authorId\":\"103903938\",\"name\":\"G. Schiavoni\"},{\"authorId\":\"2281062\",\"name\":\"L. Businaro\"},{\"authorId\":\"48258172\",\"name\":\"C. Di Natale\"},{\"authorId\":\"145056884\",\"name\":\"G. Kroemer\"},{\"authorId\":\"1664192352\",\"name\":\"E. Martinelli\"}],\"doi\":\"10.1007/s00521-020-05226-6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6c72442cc6bef3bf0d0fe61c13895bb687d5442a\",\"title\":\"Multi-scale generative adversarial network for improved evaluation of cell\\u2013cell interactions observed in organ-on-chip experiments\",\"url\":\"https://www.semanticscholar.org/paper/6c72442cc6bef3bf0d0fe61c13895bb687d5442a\",\"venue\":\"Neural Computing and Applications\",\"year\":2020},{\"arxivId\":\"2009.01142\",\"authors\":[{\"authorId\":\"41022481\",\"name\":\"Yazan Abu Farha\"},{\"authorId\":\"143969578\",\"name\":\"Qiuhong Ke\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d39c1a6ba3083510d9f697458a6bfdca1be27340\",\"title\":\"Long-Term Anticipation of Activities with Cycle Consistency\",\"url\":\"https://www.semanticscholar.org/paper/d39c1a6ba3083510d9f697458a6bfdca1be27340\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2153397\",\"name\":\"Runpeng Cui\"},{\"authorId\":\"1576511129\",\"name\":\"Zhong Cao\"},{\"authorId\":\"2782958\",\"name\":\"Weishen Pan\"},{\"authorId\":\"14966740\",\"name\":\"Changshui Zhang\"},{\"authorId\":\"1724003\",\"name\":\"J. Wang\"}],\"doi\":\"10.1109/TMM.2019.2960700\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dd47c05f454a3c3980a6c623201db45acb08a70c\",\"title\":\"Deep Gesture Video Generation With Learning on Regions of Interest\",\"url\":\"https://www.semanticscholar.org/paper/dd47c05f454a3c3980a6c623201db45acb08a70c\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40366599\",\"name\":\"W. Liu\"},{\"authorId\":null,\"name\":\"Abhishek Sharma\"},{\"authorId\":\"1694992\",\"name\":\"O. Camps\"},{\"authorId\":\"1687866\",\"name\":\"M. Sznaier\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ded41c9b027c8a7f4800e61b7cfb793edaeb2817\",\"title\":\"DYAN: A Dynamical Atoms Network for Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/ded41c9b027c8a7f4800e61b7cfb793edaeb2817\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1811.00684\",\"authors\":[{\"authorId\":\"3291967\",\"name\":\"F. Reda\"},{\"authorId\":\"2457939\",\"name\":\"Guilin Liu\"},{\"authorId\":\"143953573\",\"name\":\"K. Shih\"},{\"authorId\":\"144391743\",\"name\":\"R. Kirby\"},{\"authorId\":\"32406400\",\"name\":\"J. Barker\"},{\"authorId\":\"2924393\",\"name\":\"D. Tarjan\"},{\"authorId\":\"29955511\",\"name\":\"A. Tao\"},{\"authorId\":\"2301680\",\"name\":\"Bryan Catanzaro\"}],\"doi\":\"10.1007/978-3-030-01234-2_44\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c165003060eeb01e05800a5ee4cd327f1e0bf5e3\",\"title\":\"SDC-Net: Video Prediction Using Spatially-Displaced Convolution\",\"url\":\"https://www.semanticscholar.org/paper/c165003060eeb01e05800a5ee4cd327f1e0bf5e3\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1912.10150\",\"authors\":[{\"authorId\":\"2920297\",\"name\":\"Zhenyi Wang\"},{\"authorId\":\"144909203\",\"name\":\"Ping Yu\"},{\"authorId\":\"34340526\",\"name\":\"Y. Zhao\"},{\"authorId\":\"1390533012\",\"name\":\"Ruiyi Zhang\"},{\"authorId\":\"1652060942\",\"name\":\"Yufan Zhou\"},{\"authorId\":\"48837492\",\"name\":\"J. Yuan\"},{\"authorId\":\"1752041\",\"name\":\"Changyou Chen\"}],\"doi\":\"10.1609/AAAI.V34I07.6911\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7dd9a3410b90fe4230e924d9f565fe88622858a5\",\"title\":\"Learning Diverse Stochastic Human-Action Generators by Learning Smooth Latent Transitions\",\"url\":\"https://www.semanticscholar.org/paper/7dd9a3410b90fe4230e924d9f565fe88622858a5\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2005.00356\",\"authors\":[{\"authorId\":\"1666222692\",\"name\":\"Nagabhushan Somraj\"},{\"authorId\":\"1455704811\",\"name\":\"Manoj Surya Kashi\"},{\"authorId\":\"35144264\",\"name\":\"S. Arun\"},{\"authorId\":\"1474594567\",\"name\":\"Rajiv Soundararajan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ef58af8835dfaf3ccc8bee7173a7b38d83ea8661\",\"title\":\"A Naturalness Evaluation Database for Video Prediction Models\",\"url\":\"https://www.semanticscholar.org/paper/ef58af8835dfaf3ccc8bee7173a7b38d83ea8661\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1801.01726\",\"authors\":[{\"authorId\":\"3446352\",\"name\":\"P. Li\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"3229527\",\"name\":\"Daoyuan Jia\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a7a66d713776e78ae60617eee2715443a8565a23\",\"title\":\"Semantic-aware Grad-GAN for Virtual-to-Real Urban Scene Adaption\",\"url\":\"https://www.semanticscholar.org/paper/a7a66d713776e78ae60617eee2715443a8565a23\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":\"2007.00095\",\"authors\":[{\"authorId\":\"26902477\",\"name\":\"Amir Rasouli\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9f28b8965e0e1dab3c38ea6c95a6a3ad60d83785\",\"title\":\"Deep Learning for Vision-based Prediction: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/9f28b8965e0e1dab3c38ea6c95a6a3ad60d83785\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.02793\",\"authors\":[{\"authorId\":\"1596793949\",\"name\":\"M. Liu\"},{\"authorId\":\"47932904\",\"name\":\"Xun Huang\"},{\"authorId\":\"150167366\",\"name\":\"Jiahui Yu\"},{\"authorId\":\"2195314\",\"name\":\"T. Wang\"},{\"authorId\":\"36508529\",\"name\":\"Arun Mallya\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"555e7029e8fd3b759300edfd2a4b7dfa2fd34a48\",\"title\":\"Generative Adversarial Networks for Image and Video Synthesis: Algorithms and Applications\",\"url\":\"https://www.semanticscholar.org/paper/555e7029e8fd3b759300edfd2a4b7dfa2fd34a48\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153269936\",\"name\":\"J. Xiao\"},{\"authorId\":\"49997317\",\"name\":\"Xiaojun Bi\"}],\"doi\":\"10.1109/ACCESS.2020.2995705\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"da8b5876438d5c7f4caf6cfabc4252e0863dac8b\",\"title\":\"Multi-Scale Attention Generative Adversarial Networks for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/da8b5876438d5c7f4caf6cfabc4252e0863dac8b\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1909.05690\",\"authors\":[{\"authorId\":\"50394968\",\"name\":\"Kaili Wang\"},{\"authorId\":\"108666950\",\"name\":\"J. Oramas\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"df5b6cc171a06718a358f4f6a38b83f066bb43cd\",\"title\":\"LSTMs can capture information beyond order\",\"url\":\"https://www.semanticscholar.org/paper/df5b6cc171a06718a358f4f6a38b83f066bb43cd\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9723532\",\"name\":\"Subham Mukherjee\"},{\"authorId\":\"29780808\",\"name\":\"S. Ghosh\"},{\"authorId\":\"7137430\",\"name\":\"S. Ghosh\"},{\"authorId\":\"144385555\",\"name\":\"P. Kumar\"},{\"authorId\":\"40813600\",\"name\":\"P. Roy\"}],\"doi\":\"10.1109/ICASSP.2019.8682158\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"554cf535bdb6e8c36a13fb85c22aa4f23fdc735a\",\"title\":\"Predicting Video-frames Using Encoder-convlstm Combination\",\"url\":\"https://www.semanticscholar.org/paper/554cf535bdb6e8c36a13fb85c22aa4f23fdc735a\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46758964\",\"name\":\"Jie Yan\"},{\"authorId\":\"1783055\",\"name\":\"Guihe Qin\"},{\"authorId\":\"10431066\",\"name\":\"R. Zhao\"},{\"authorId\":\"46992126\",\"name\":\"Yan-hua Liang\"},{\"authorId\":\"150270946\",\"name\":\"Qianyi Xu\"}],\"doi\":\"10.1109/ACCESS.2019.2961383\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c19ef8d8dfefb8ca898fc3b9b58cb3b499ed3836\",\"title\":\"Mixpred: Video Prediction Beyond Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/c19ef8d8dfefb8ca898fc3b9b58cb3b499ed3836\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"2011.10812\",\"authors\":[{\"authorId\":\"143611184\",\"name\":\"Fan Lu\"},{\"authorId\":\"143930563\",\"name\":\"G. Chen\"},{\"authorId\":\"2341727\",\"name\":\"Y. Liu\"},{\"authorId\":\"1860369299\",\"name\":\"Zhijun Li\"},{\"authorId\":\"52532366\",\"name\":\"Sanqing Qu\"},{\"authorId\":\"2028192765\",\"name\":\"Tianpei Zou\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"00942afb551b40b7739d0d1024abeceb266d3f40\",\"title\":\"MoNet: Motion-based Point Cloud Prediction Network\",\"url\":\"https://www.semanticscholar.org/paper/00942afb551b40b7739d0d1024abeceb266d3f40\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2019123888\",\"name\":\"Wei Xu\"},{\"authorId\":\"2024342929\",\"name\":\"Xiangyu Bao\"},{\"authorId\":\"2467634\",\"name\":\"G. Chen\"},{\"authorId\":\"143630011\",\"name\":\"I. Neumann\"}],\"doi\":\"10.3390/s20226439\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5158e73d4e079fbbe3bac0ad7c46f40fcb855707\",\"title\":\"Intelligent Calibration of Static FEA Computations Based on Terrestrial Laser Scanning Reference\",\"url\":\"https://www.semanticscholar.org/paper/5158e73d4e079fbbe3bac0ad7c46f40fcb855707\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yaohui Wang\"},{\"authorId\":\"105070829\",\"name\":\"P. Bilinski\"},{\"authorId\":\"69929964\",\"name\":\"F. Br\\u00e9mond\"},{\"authorId\":\"3299530\",\"name\":\"A. Dantcheva\"}],\"doi\":\"10.1109/WACV45572.2020.9093492\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"493e753062f82e36b9c24ec48a13dd4b424f65a3\",\"title\":\"ImaGINator: Conditional Spatio-Temporal GAN for Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/493e753062f82e36b9c24ec48a13dd4b424f65a3\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"13763932\",\"name\":\"Dongxu Wei\"},{\"authorId\":\"144838755\",\"name\":\"Xiaowei Xu\"},{\"authorId\":\"1888007\",\"name\":\"Haibin Shen\"},{\"authorId\":\"47942157\",\"name\":\"K. Huang\"}],\"doi\":\"10.1109/tmm.2020.3011290\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1df6cc2507dd90adaafe5f9915a261558b88008c\",\"title\":\"GAC-GAN: A General Method for Appearance-Controllable Human Video Motion Transfer\",\"url\":\"https://www.semanticscholar.org/paper/1df6cc2507dd90adaafe5f9915a261558b88008c\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2012.06628\",\"authors\":[{\"authorId\":\"121544228\",\"name\":\"Z. Li\"},{\"authorId\":\"1813796\",\"name\":\"Zhaopeng Cui\"},{\"authorId\":\"1821761\",\"name\":\"M. Oswald\"},{\"authorId\":\"88550057\",\"name\":\"Marc Pollefeys\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bbaa5a95aba6cccb7c9885db0329c413f12bbb22\",\"title\":\"Street-view Panoramic Video Synthesis from a Single Satellite Image\",\"url\":\"https://www.semanticscholar.org/paper/bbaa5a95aba6cccb7c9885db0329c413f12bbb22\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153920582\",\"name\":\"Luk\\u00e1s Neumann\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":\"10.1109/CVPRW.2019.00354\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4eea7f5b0e1365eb7f7354626cc2acb3701e84d2\",\"title\":\"Future Event Prediction: If and When\",\"url\":\"https://www.semanticscholar.org/paper/4eea7f5b0e1365eb7f7354626cc2acb3701e84d2\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8806501\",\"name\":\"Weitang Liu\"},{\"authorId\":\"47223178\",\"name\":\"E. Barsoum\"},{\"authorId\":\"1758404\",\"name\":\"John Douglas Owens\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1a8f40410441a1839a3686799328a687e505fd0d\",\"title\":\"Object Localization and Motion Transfer learning with Capsules\",\"url\":\"https://www.semanticscholar.org/paper/1a8f40410441a1839a3686799328a687e505fd0d\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1812.00452\",\"authors\":[{\"authorId\":null,\"name\":\"Hang Gao\"},{\"authorId\":\"3286703\",\"name\":\"Huazhe Xu\"},{\"authorId\":\"46193391\",\"name\":\"Qi-Zhi Cai\"},{\"authorId\":\"46886239\",\"name\":\"R. Wang\"},{\"authorId\":\"1807197\",\"name\":\"F. Yu\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/ICCV.2019.00910\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"ce71c5b4c959c34715503a5980e457e700db9e70\",\"title\":\"Disentangling Propagation and Generation for Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/ce71c5b4c959c34715503a5980e457e700db9e70\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3030828\",\"name\":\"Arun Sankisa\"},{\"authorId\":\"48654737\",\"name\":\"Arjun Punjabi\"},{\"authorId\":\"144842935\",\"name\":\"A. Katsaggelos\"}],\"doi\":\"10.4018/ijmdem.2019070102\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c609e6c578a34351077c067389f071ee348246a0\",\"title\":\"Optical Flow Prediction for Blind and Non-Blind Video Error Concealment Using Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/c609e6c578a34351077c067389f071ee348246a0\",\"venue\":\"Int. J. Multim. Data Eng. Manag.\",\"year\":2019},{\"arxivId\":\"1807.11152\",\"authors\":[{\"authorId\":\"49984891\",\"name\":\"Ceyuan Yang\"},{\"authorId\":\"40072288\",\"name\":\"Zhe Wang\"},{\"authorId\":\"22689408\",\"name\":\"Xinge Zhu\"},{\"authorId\":\"145544640\",\"name\":\"C. Huang\"},{\"authorId\":\"1788070\",\"name\":\"J. Shi\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1007/978-3-030-01249-6_13\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"da219d1f43cc00de6c5a411e47feca956f88645f\",\"title\":\"Pose Guided Human Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/da219d1f43cc00de6c5a411e47feca956f88645f\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51466944\",\"name\":\"Sandra Aigner\"},{\"authorId\":\"1386326892\",\"name\":\"M. K\\u00f6rner\"}],\"doi\":\"10.3390/make2020006\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dce78cb893437f55e8a6f1b806e7415b0d729045\",\"title\":\"The Importance of Loss Functions for Increasing the Generalization Abilities of a Deep Learning-Based Next Frame Prediction Model for Traffic Scenes\",\"url\":\"https://www.semanticscholar.org/paper/dce78cb893437f55e8a6f1b806e7415b0d729045\",\"venue\":\"Machine Learning and Knowledge Extraction\",\"year\":2020},{\"arxivId\":\"2008.02995\",\"authors\":[{\"authorId\":\"49049939\",\"name\":\"J. Zhang\"},{\"authorId\":\"46385973\",\"name\":\"Wenxuan Zhong\"},{\"authorId\":\"47477714\",\"name\":\"Ping Ma\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6e405e469efaab466d8db87497d1b5b74f9e8cfa\",\"title\":\"A Review on Modern Computational Optimal Transport Methods with Applications in Biomedical Research\",\"url\":\"https://www.semanticscholar.org/paper/6e405e469efaab466d8db87497d1b5b74f9e8cfa\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.05214\",\"authors\":[{\"authorId\":\"152298373\",\"name\":\"Sergiu Oprea\"},{\"authorId\":\"1410236705\",\"name\":\"P. Martinez-Gonzalez\"},{\"authorId\":\"1397392435\",\"name\":\"Alberto Garcia-Garcia\"},{\"authorId\":\"1410269918\",\"name\":\"John Alejandro Castro-Vargas\"},{\"authorId\":\"1405686926\",\"name\":\"S. Orts-Escolano\"},{\"authorId\":\"1429069120\",\"name\":\"J. Garci\\u0301a-Rodri\\u0301guez\"},{\"authorId\":\"1689415\",\"name\":\"Antonis A. Argyros\"}],\"doi\":\"10.1109/TPAMI.2020.3045007\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ded24959bbd7715073fa700d5898cdbb2b8353f7\",\"title\":\"A Review on Deep Learning Techniques for Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/ded24959bbd7715073fa700d5898cdbb2b8353f7\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"94109286\",\"name\":\"Changxu Zhang\"},{\"authorId\":\"22037109\",\"name\":\"T. Chen\"},{\"authorId\":\"2571876\",\"name\":\"H. Liu\"},{\"authorId\":\"3237008\",\"name\":\"Q. Shen\"},{\"authorId\":\"152986975\",\"name\":\"Z. Ma\"}],\"doi\":\"10.1109/ICIP.2019.8803151\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"4843c54e897c79367a97c56602e8810f57bbff1a\",\"title\":\"Looking-Ahead: Neural Future Video Frame Prediction\",\"url\":\"https://www.semanticscholar.org/paper/4843c54e897c79367a97c56602e8810f57bbff1a\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"2005.13194\",\"authors\":[{\"authorId\":\"2317713\",\"name\":\"S. Lee\"},{\"authorId\":\"98080420\",\"name\":\"H. Lee\"},{\"authorId\":\"48271129\",\"name\":\"T. Kim\"},{\"authorId\":\"39847092\",\"name\":\"Sangyoun Lee\"}],\"doi\":\"10.1109/ICIP40778.2020.9191286\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"aff965a62434c25e3465223179771f8b9f689054\",\"title\":\"Extrapolative-Interpolative Cycle-Consistency Learning For Video Frame Extrapolation\",\"url\":\"https://www.semanticscholar.org/paper/aff965a62434c25e3465223179771f8b9f689054\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47054044\",\"name\":\"Cheng Meng\"},{\"authorId\":\"11053409\",\"name\":\"Yuan Ke\"},{\"authorId\":\"47539166\",\"name\":\"Jingyi Zhang\"},{\"authorId\":\"46243254\",\"name\":\"Mengrui Zhang\"},{\"authorId\":\"46385973\",\"name\":\"Wenxuan Zhong\"},{\"authorId\":\"47477714\",\"name\":\"Ping Ma\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3e5b2e90fd35b49190b2ab762c9a2a7b4fbf5b65\",\"title\":\"Large-scale optimal transport map estimation using projection pursuit\",\"url\":\"https://www.semanticscholar.org/paper/3e5b2e90fd35b49190b2ab762c9a2a7b4fbf5b65\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143804836\",\"name\":\"Ruibing Hou\"},{\"authorId\":\"145375324\",\"name\":\"H. Chang\"},{\"authorId\":\"1798982\",\"name\":\"Bingpeng Ma\"},{\"authorId\":\"1710220\",\"name\":\"X. Chen\"}],\"doi\":\"10.1109/FG.2019.8756585\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"88cb11aecad56a2af1dd46e994746cd7a19c5902\",\"title\":\"Video Prediction with Bidirectional Constraint Network\",\"url\":\"https://www.semanticscholar.org/paper/88cb11aecad56a2af1dd46e994746cd7a19c5902\",\"venue\":\"2019 14th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2019)\",\"year\":2019},{\"arxivId\":\"1810.11610\",\"authors\":[{\"authorId\":\"2621181\",\"name\":\"Haoye Dong\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"144194066\",\"name\":\"K. Gong\"},{\"authorId\":\"2356867\",\"name\":\"Hanjiang Lai\"},{\"authorId\":\"50077416\",\"name\":\"Jia Zhu\"},{\"authorId\":\"144926874\",\"name\":\"J. Yin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9611a84f1809bde1412afd8a11424204fc96dfe4\",\"title\":\"Soft-Gated Warping-GAN for Pose-Guided Person Image Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/9611a84f1809bde1412afd8a11424204fc96dfe4\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"2010.09067\",\"authors\":[{\"authorId\":\"1999190651\",\"name\":\"Kristijan Fugovsi'c\"},{\"authorId\":\"1999192240\",\"name\":\"Josip vSari'c\"},{\"authorId\":\"1389866701\",\"name\":\"Sinivsa vSegvi'c\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e4ded9df9c4a0ac08c2592f29bf0c81b0458436f\",\"title\":\"Multimodal semantic forecasting based on conditional generation of future features\",\"url\":\"https://www.semanticscholar.org/paper/e4ded9df9c4a0ac08c2592f29bf0c81b0458436f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1909.05690\",\"authors\":[{\"authorId\":\"1641704401\",\"name\":\"Kaili Wang\"},{\"authorId\":\"108666950\",\"name\":\"J. Oramas\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"18a1dd033c43c4639b041b24fee20de0f91ff265\",\"title\":\"In Defense of LSTMs for Addressing Multiple Instance Learning Problems.\",\"url\":\"https://www.semanticscholar.org/paper/18a1dd033c43c4639b041b24fee20de0f91ff265\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491637046\",\"name\":\"Kang Liao\"},{\"authorId\":\"49043799\",\"name\":\"C. Lin\"},{\"authorId\":\"1517826311\",\"name\":\"Yao Zhao\"},{\"authorId\":\"9219875\",\"name\":\"M. Gabbouj\"}],\"doi\":\"10.1109/TCSVT.2019.2958199\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ea50f28ec26924163c878f89cb33e2b7ab2d4d0c\",\"title\":\"Distortion Rectification From Static to Dynamic: A Distortion Sequence Construction Perspective\",\"url\":\"https://www.semanticscholar.org/paper/ea50f28ec26924163c878f89cb33e2b7ab2d4d0c\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22803355\",\"name\":\"Beibei Jin\"},{\"authorId\":\"145957556\",\"name\":\"Rong Zhou\"},{\"authorId\":\"2357433\",\"name\":\"Zhisheng Zhang\"},{\"authorId\":\"144124218\",\"name\":\"M. Dai\"}],\"doi\":\"10.1109/M2VIP.2018.8600864\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"f30062e3cec68bb313e38e5134e24e25ebb73f65\",\"title\":\"Unsupervised Video Prediction Network with Spatio-temporal Deep Features\",\"url\":\"https://www.semanticscholar.org/paper/f30062e3cec68bb313e38e5134e24e25ebb73f65\",\"venue\":\"2018 25th International Conference on Mechatronics and Machine Vision in Practice (M2VIP)\",\"year\":2018},{\"arxivId\":\"1811.10666\",\"authors\":[{\"authorId\":\"34656387\",\"name\":\"Matteo Tomei\"},{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/CVPR.2019.00600\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b430af071a523b03911e35a23bc12ae96e86bd4c\",\"title\":\"Art2Real: Unfolding the Reality of Artworks via Semantically-Aware Image-To-Image Translation\",\"url\":\"https://www.semanticscholar.org/paper/b430af071a523b03911e35a23bc12ae96e86bd4c\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2004.00542\",\"authors\":[{\"authorId\":\"89971337\",\"name\":\"Yue Wu\"},{\"authorId\":\"48984651\",\"name\":\"Rongrong Gao\"},{\"authorId\":\"2870153\",\"name\":\"Jaesik Park\"},{\"authorId\":\"143832240\",\"name\":\"Qifeng Chen\"}],\"doi\":\"10.1109/cvpr42600.2020.00558\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8bfd55a4b1defa21c9efbbbcae2d04ca9e3b8b97\",\"title\":\"Future Video Synthesis With Object Motion Prediction\",\"url\":\"https://www.semanticscholar.org/paper/8bfd55a4b1defa21c9efbbbcae2d04ca9e3b8b97\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738471\",\"name\":\"Chenyang Zhang\"},{\"authorId\":\"1860612\",\"name\":\"X. Yang\"},{\"authorId\":\"33768582\",\"name\":\"Yongqiang Tang\"},{\"authorId\":\"40538957\",\"name\":\"Wensheng Zhang\"}],\"doi\":\"10.1109/LGRS.2019.2922326\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1ae5b2ef9e7043f3c7015de386d85d42718dc3c3\",\"title\":\"Learning to Generate Radar Image Sequences Using Two-Stage Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/1ae5b2ef9e7043f3c7015de386d85d42718dc3c3\",\"venue\":\"IEEE Geoscience and Remote Sensing Letters\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2587808\",\"name\":\"Liang-Yan Gui\"},{\"authorId\":\"144552149\",\"name\":\"Kevin Zhang\"},{\"authorId\":null,\"name\":\"Yu-Xiong Wang\"},{\"authorId\":\"13246332\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"51283515\",\"name\":\"Jos'e M. F. Moura\"},{\"authorId\":\"1956361\",\"name\":\"M. Veloso\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"51e7d03d66f942f3f147e05d520717c03aa3bf21\",\"title\":\"Encoder Decoder Conditioning motion Seed motion PredictionPredictor Groundtruth Real or fake ? Discriminator Training : Inference : Encoder Decoder\",\"url\":\"https://www.semanticscholar.org/paper/51e7d03d66f942f3f147e05d520717c03aa3bf21\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2008.04776\",\"authors\":[{\"authorId\":\"73329364\",\"name\":\"Jiangning Zhang\"},{\"authorId\":\"145194966\",\"name\":\"Chao Xu\"},{\"authorId\":\"1391190989\",\"name\":\"L. Liu\"},{\"authorId\":\"47446949\",\"name\":\"M. Wang\"},{\"authorId\":\"1490938675\",\"name\":\"Xia Wu\"},{\"authorId\":\"93006732\",\"name\":\"Y. Liu\"},{\"authorId\":\"122376816\",\"name\":\"Yunliang Jiang\"}],\"doi\":\"10.1007/978-3-030-58558-7_18\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c1847cbb4064ca05593f7b408783e9f183953488\",\"title\":\"DTVNet: Dynamic Time-lapse Video Generation via Single Still Image\",\"url\":\"https://www.semanticscholar.org/paper/c1847cbb4064ca05593f7b408783e9f183953488\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1801.09042\",\"authors\":[{\"authorId\":\"49455017\",\"name\":\"Yipin Zhou\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/WACV.2018.00025\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0073c51ee3fcba12c8a01f2481f9fac1101d6e62\",\"title\":\"Image2GIF: Generating Cinemagraphs Using Recurrent Deep Q-Networks\",\"url\":\"https://www.semanticscholar.org/paper/0073c51ee3fcba12c8a01f2481f9fac1101d6e62\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":\"2011.03864\",\"authors\":[{\"authorId\":\"2007745319\",\"name\":\"Cade Gordon\"},{\"authorId\":\"2326758\",\"name\":\"Natalie Parde\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ac4e977aba1731ce1bd5ddeb9ea466fa86c10a5f\",\"title\":\"Latent Neural Differential Equations for Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/ac4e977aba1731ce1bd5ddeb9ea466fa86c10a5f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144650675\",\"name\":\"M. Tang\"},{\"authorId\":\"1788029\",\"name\":\"W. Wang\"},{\"authorId\":\"8082703\",\"name\":\"Xiongtao Chen\"},{\"authorId\":\"7737775\",\"name\":\"Yifeng He\"}],\"doi\":\"10.1007/978-3-030-00776-8_53\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f49c1aef8ef2385ee9f4481f3bd35f4d0540e9d8\",\"title\":\"Adaptive Hierarchical Motion-Focused Model for Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/f49c1aef8ef2385ee9f4481f3bd35f4d0540e9d8\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"117185645\",\"name\":\"Sen-Zhe Xu\"},{\"authorId\":\"1745787\",\"name\":\"J. Hu\"},{\"authorId\":\"145631934\",\"name\":\"M. Wang\"},{\"authorId\":\"31471368\",\"name\":\"Tai-Jiang Mu\"},{\"authorId\":\"145140922\",\"name\":\"S. Hu\"}],\"doi\":\"10.1111/cgf.13566\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d9de93805462d9a5b0676ce4049c7b56a55ed7c0\",\"title\":\"Deep Video Stabilization Using Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/d9de93805462d9a5b0676ce4049c7b56a55ed7c0\",\"venue\":\"Comput. Graph. Forum\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3258842\",\"name\":\"J. Wang\"},{\"authorId\":\"1788029\",\"name\":\"W. Wang\"},{\"authorId\":\"144466591\",\"name\":\"Wen Gao\"}],\"doi\":\"10.1109/TCSVT.2018.2882061\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d5a9167cd2914b9c19315cfca9162e0d4c90621b\",\"title\":\"Predicting Diverse Future Frames With Local Transformation-Guided Masking\",\"url\":\"https://www.semanticscholar.org/paper/d5a9167cd2914b9c19315cfca9162e0d4c90621b\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50622174\",\"name\":\"Islem Rekik\"},{\"authorId\":\"46408185\",\"name\":\"E. Adeli\"},{\"authorId\":\"71537981\",\"name\":\"S. Park\"},{\"authorId\":\"144066759\",\"name\":\"M. Hern\\u00e1ndez\"}],\"doi\":\"10.1007/978-3-030-59354-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d1e9f5ef80f6d75ab729bceedc82e6e95b0f253\",\"title\":\"Predictive Intelligence in Medicine: Third International Workshop, PRIME 2020, Held in Conjunction with MICCAI 2020, Lima, Peru, October 8, 2020, Proceedings\",\"url\":\"https://www.semanticscholar.org/paper/0d1e9f5ef80f6d75ab729bceedc82e6e95b0f253\",\"venue\":\"PRIME@MICCAI\",\"year\":2020},{\"arxivId\":\"2007.07431\",\"authors\":[{\"authorId\":\"2652444\",\"name\":\"K. Saito\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1596793949\",\"name\":\"M. Liu\"}],\"doi\":\"10.1007/978-3-030-58580-8_23\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3dfeba459696a573c72f115f30218e5c348db6d8\",\"title\":\"COCO-FUNIT: Few-Shot Unsupervised Image Translation with a Content Conditioned Style Encoder\",\"url\":\"https://www.semanticscholar.org/paper/3dfeba459696a573c72f115f30218e5c348db6d8\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3030828\",\"name\":\"Arun Sankisa\"},{\"authorId\":\"48654737\",\"name\":\"Arjun Punjabi\"},{\"authorId\":\"144842935\",\"name\":\"A. Katsaggelos\"}],\"doi\":\"10.1109/ICIP.2018.8451090\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6ce6768a34e197e4ef76933c8e6760b6e4833dc4\",\"title\":\"Video Error Concealment Using Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6ce6768a34e197e4ef76933c8e6760b6e4833dc4\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46772115\",\"name\":\"Xinyuan Chen\"},{\"authorId\":\"145371957\",\"name\":\"Chang Xu\"},{\"authorId\":\"15469693\",\"name\":\"Xiaokang Yang\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/TIP.2020.2998297\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7cc5cdb2512894678265cd967e329f0331c81d5a\",\"title\":\"Long-Term Video Prediction via Criticization and Retrospection\",\"url\":\"https://www.semanticscholar.org/paper/7cc5cdb2512894678265cd967e329f0331c81d5a\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"94301984\",\"name\":\"Moritz Venator\"},{\"authorId\":\"30136665\",\"name\":\"Fengyi Shen\"},{\"authorId\":\"1659230948\",\"name\":\"Selcuk Aklanoglu\"},{\"authorId\":\"144876322\",\"name\":\"E. Bruns\"},{\"authorId\":\"1686825\",\"name\":\"K. Diepold\"},{\"authorId\":\"1400135430\",\"name\":\"Andreas Maier\"}],\"doi\":\"10.1109/WACV45572.2020.9093401\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2b54c6624a30b85f28a46314993886205cc04381\",\"title\":\"Dual-Mode Training with Style Control and Quality Enhancement for Road Image Domain Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/2b54c6624a30b85f28a46314993886205cc04381\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Sai Shashidhar Nagabandi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"bc3f9edf329b1db74fbe2b66b74d159be6f3b9ec\",\"title\":\"Self-Supervised Video Representation Learning by Recurrent Networks and Frame Order Prediction\",\"url\":\"https://www.semanticscholar.org/paper/bc3f9edf329b1db74fbe2b66b74d159be6f3b9ec\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5685594\",\"name\":\"G. Lorre\"},{\"authorId\":\"2962220\",\"name\":\"J. Rabarisoa\"},{\"authorId\":\"19258632\",\"name\":\"A. Orcesi\"},{\"authorId\":\"2910432\",\"name\":\"Samia Ainouz\"},{\"authorId\":\"10451773\",\"name\":\"St\\u00e9phane Canu\"}],\"doi\":\"10.1109/WACV45572.2020.9093278\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"90f84c25039d6c69bd25e70c719251aeacc50978\",\"title\":\"Temporal Contrastive Pretraining for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/90f84c25039d6c69bd25e70c719251aeacc50978\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"2003.04035\",\"authors\":[{\"authorId\":\"152831141\",\"name\":\"Pauline Luc\"},{\"authorId\":\"31993415\",\"name\":\"A. Clark\"},{\"authorId\":\"48373216\",\"name\":\"S. Dieleman\"},{\"authorId\":\"40550616\",\"name\":\"D. Casas\"},{\"authorId\":\"2895238\",\"name\":\"Yotam Doron\"},{\"authorId\":\"51042571\",\"name\":\"Albin Cassirer\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e93e16a1a9f060841956ae2eca735f5cce457c8c\",\"title\":\"Transformation-based Adversarial Video Prediction on Large-Scale Data\",\"url\":\"https://www.semanticscholar.org/paper/e93e16a1a9f060841956ae2eca735f5cce457c8c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.07999\",\"authors\":[{\"authorId\":\"46665218\",\"name\":\"Jie Lei\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"143977266\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.706\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9f2a7a912624d850cf9e0587263b4fcd88d44f18\",\"title\":\"What is More Likely to Happen Next? Video-and-Language Future Event Prediction\",\"url\":\"https://www.semanticscholar.org/paper/9f2a7a912624d850cf9e0587263b4fcd88d44f18\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152496419\",\"name\":\"Donghoon Lee\"},{\"authorId\":\"2001015450\",\"name\":\"S. R. Alam\"},{\"authorId\":\"38191498\",\"name\":\"Saad Nadeem\"},{\"authorId\":\"46401067\",\"name\":\"J. Jiang\"},{\"authorId\":\"48754422\",\"name\":\"P. Zhang\"},{\"authorId\":\"9254857\",\"name\":\"Yu-Chi Hu\"}],\"doi\":\"10.1007/978-3-030-59354-4_12\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"51d15899dc27e340c89e89b9d2f5657f103e9537\",\"title\":\"Longitudinal Prediction of Radiation-Induced Anatomical Changes of Parotid Glands During Radiotherapy Using Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/51d15899dc27e340c89e89b9d2f5657f103e9537\",\"venue\":\"PRIME@MICCAI\",\"year\":2020},{\"arxivId\":\"2005.11212\",\"authors\":[{\"authorId\":\"122123672\",\"name\":\"Silviu-Marian Udrescu\"},{\"authorId\":\"2011933\",\"name\":\"Max Tegmark\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3b92bdfdf5d8d65fb5691fee954e4c7cb54909a0\",\"title\":\"Symbolic Pregression: Discovering Physical Laws from Raw Distorted Video\",\"url\":\"https://www.semanticscholar.org/paper/3b92bdfdf5d8d65fb5691fee954e4c7cb54909a0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1909.01818\",\"authors\":[{\"authorId\":\"46522476\",\"name\":\"Xiaoli Liu\"},{\"authorId\":\"1890165\",\"name\":\"J. Yin\"},{\"authorId\":\"2641547\",\"name\":\"H. Liu\"},{\"authorId\":\"102446355\",\"name\":\"Y. Yin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ed7ce10f9bde7512236feb67634862dc7dae65f0\",\"title\":\"PISEP^2: Pseudo Image Sequence Evolution based 3D Pose Prediction\",\"url\":\"https://www.semanticscholar.org/paper/ed7ce10f9bde7512236feb67634862dc7dae65f0\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1901.03728\",\"authors\":[{\"authorId\":\"1695016\",\"name\":\"F. Pirri\"},{\"authorId\":\"65770249\",\"name\":\"L. Mauro\"},{\"authorId\":\"66073991\",\"name\":\"Edoardo Alati\"},{\"authorId\":\"2368860\",\"name\":\"Valsamis Ntouskos\"},{\"authorId\":\"66572445\",\"name\":\"Mahdieh Izadpanahkakhk\"},{\"authorId\":\"66760000\",\"name\":\"E. Omrani\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"37fd19e135c065659875e2e824a455ad56689507\",\"title\":\"Anticipation and next action forecasting in video: an end-to-end model with memory\",\"url\":\"https://www.semanticscholar.org/paper/37fd19e135c065659875e2e824a455ad56689507\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4866145\",\"name\":\"Jilin Tang\"},{\"authorId\":\"2043870\",\"name\":\"H. Hu\"},{\"authorId\":\"7451768\",\"name\":\"Q. Zhou\"},{\"authorId\":\"1692900\",\"name\":\"H. Shan\"},{\"authorId\":\"143827460\",\"name\":\"Chuan Tian\"},{\"authorId\":\"1718541\",\"name\":\"T. Quek\"}],\"doi\":\"10.1109/ICIP.2019.8803792\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"02c8d013c4aca5169e8bc98529ba854e0a981aa4\",\"title\":\"Pose Guided Global and Local GAN for Appearance Preserving Human Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/02c8d013c4aca5169e8bc98529ba854e0a981aa4\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1756881\",\"name\":\"Jiancai Huang\"},{\"authorId\":\"102665406\",\"name\":\"Zhi-peng Chen\"},{\"authorId\":\"50676470\",\"name\":\"Zhaohui Jiang\"},{\"authorId\":\"145202887\",\"name\":\"W. Gui\"}],\"doi\":\"10.1109/JSEN.2020.2974253\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5e13f685b2d68ff5785c9d0e83fa1af7d2c75137\",\"title\":\"3D Topography Measurement and Completion Method of Blast Furnace Burden Surface Using High-Temperature Industrial Endoscope\",\"url\":\"https://www.semanticscholar.org/paper/5e13f685b2d68ff5785c9d0e83fa1af7d2c75137\",\"venue\":\"IEEE Sensors Journal\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1559793886\",\"name\":\"W. Yu\"},{\"authorId\":\"2505474\",\"name\":\"Y. Lu\"},{\"authorId\":\"1693900\",\"name\":\"S. Easterbrook\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"43fae6940c4ef3f47d80b0749c3447012254a615\",\"title\":\"Efficient and Information-Preserving Future Frame Prediction and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/43fae6940c4ef3f47d80b0749c3447012254a615\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3210262\",\"name\":\"Senzhang Wang\"},{\"authorId\":\"1631624238\",\"name\":\"Jiannong Cao\"},{\"authorId\":\"123655327\",\"name\":\"H. Chen\"},{\"authorId\":\"1490937486\",\"name\":\"Hao Peng\"},{\"authorId\":\"1713329\",\"name\":\"Zhiqiu Huang\"}],\"doi\":\"10.1145/3378889\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"39e6762480b742773980e6ba55559b64e41a5ef2\",\"title\":\"SeqST-GAN\",\"url\":\"https://www.semanticscholar.org/paper/39e6762480b742773980e6ba55559b64e41a5ef2\",\"venue\":\"ACM Trans. Spatial Algorithms Syst.\",\"year\":2020},{\"arxivId\":\"1803.09760\",\"authors\":[{\"authorId\":\"2689633\",\"name\":\"Andrew Jaegle\"},{\"authorId\":\"40900227\",\"name\":\"Oleh Rybkin\"},{\"authorId\":\"3150825\",\"name\":\"K. Derpanis\"},{\"authorId\":\"1751586\",\"name\":\"Kostas Daniilidis\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"69f7045d901dab5e949948a16beb89a4b0b38c15\",\"title\":\"Predicting the Future with Transformational States\",\"url\":\"https://www.semanticscholar.org/paper/69f7045d901dab5e949948a16beb89a4b0b38c15\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48954595\",\"name\":\"Akanksha Sharma\"},{\"authorId\":\"2150759\",\"name\":\"Neeru Jindal\"},{\"authorId\":\"1828828101\",\"name\":\"P. S. Rana\"}],\"doi\":\"10.1007/s11042-020-09308-4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"488f1390252f68695957a74ac16f0958c9155f24\",\"title\":\"Potential of generative adversarial net algorithms in image and video processing applications\\u2013 a survey\",\"url\":\"https://www.semanticscholar.org/paper/488f1390252f68695957a74ac16f0958c9155f24\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"2011.02250\",\"authors\":[{\"authorId\":\"51235324\",\"name\":\"Nuha Aldausari\"},{\"authorId\":\"145313633\",\"name\":\"A. Sowmya\"},{\"authorId\":\"47600265\",\"name\":\"N. Marcus\"},{\"authorId\":\"4911295\",\"name\":\"G. Mohammadi\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5c1b1ab734ebc6ba56ea5d8af9d01a9fe8e0ba8b\",\"title\":\"Video Generative Adversarial Networks: A Review\",\"url\":\"https://www.semanticscholar.org/paper/5c1b1ab734ebc6ba56ea5d8af9d01a9fe8e0ba8b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1812.04558\",\"authors\":[{\"authorId\":\"38661780\",\"name\":\"Tushar Nagarajan\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/ICCV.2019.00878\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"316a16485bf9ad67a6a07888f8e0d24604d96b76\",\"title\":\"Grounded Human-Object Interaction Hotspots From Video\",\"url\":\"https://www.semanticscholar.org/paper/316a16485bf9ad67a6a07888f8e0d24604d96b76\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1808.06601\",\"authors\":[{\"authorId\":\"2195314\",\"name\":\"T. Wang\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"47062069\",\"name\":\"Guilin Liu\"},{\"authorId\":\"29955511\",\"name\":\"A. Tao\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"},{\"authorId\":\"2301680\",\"name\":\"Bryan Catanzaro\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c5b55f410365bb889c25a9f0354f2b86ec61c4f0\",\"title\":\"Video-to-Video Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/c5b55f410365bb889c25a9f0354f2b86ec61c4f0\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1712.03534\",\"authors\":[{\"authorId\":\"2017906\",\"name\":\"Wissam J. Baddar\"},{\"authorId\":\"2707832\",\"name\":\"Geonmo Gu\"},{\"authorId\":\"2909533\",\"name\":\"S. Lee\"},{\"authorId\":\"7251290\",\"name\":\"Yong Man Ro\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"deb0cbced8a5986e0771209cf786b0ebdedc119d\",\"title\":\"Dynamics Transfer GAN: Generating Video by Transferring Arbitrary Temporal Dynamics from a Source Video to a Single Target Image\",\"url\":\"https://www.semanticscholar.org/paper/deb0cbced8a5986e0771209cf786b0ebdedc119d\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"2006.05132\",\"authors\":[{\"authorId\":\"145196525\",\"name\":\"A. Jabbar\"},{\"authorId\":\"121856937\",\"name\":\"X. Li\"},{\"authorId\":\"1739254961\",\"name\":\"Bourahla Omar\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d54d8c402785006faaf5de19e81f04eb484a3aa2\",\"title\":\"A Survey on Generative Adversarial Networks: Variants, Applications, and Training\",\"url\":\"https://www.semanticscholar.org/paper/d54d8c402785006faaf5de19e81f04eb484a3aa2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121339452\",\"name\":\"Y. Tian\"},{\"authorId\":\"1810382\",\"name\":\"Zhaohui Che\"},{\"authorId\":\"116279011\",\"name\":\"Wenbo Bao\"},{\"authorId\":\"1509899757\",\"name\":\"Guangtao Zhai\"},{\"authorId\":\"97709070\",\"name\":\"Z. Gao\"}],\"doi\":\"10.1007/978-3-030-58568-6_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"27568c821ab008facaa57dc4f99217a294e196c4\",\"title\":\"Self-supervised Motion Representation via Scattering Local Motion Cues\",\"url\":\"https://www.semanticscholar.org/paper/27568c821ab008facaa57dc4f99217a294e196c4\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1811.02132\",\"authors\":[{\"authorId\":\"49991541\",\"name\":\"Jinxuan Sun\"},{\"authorId\":\"2421012\",\"name\":\"Guoqiang Zhong\"},{\"authorId\":\"39988436\",\"name\":\"Yang Chen\"},{\"authorId\":\"47909171\",\"name\":\"Yongbin Liu\"},{\"authorId\":null,\"name\":\"Tao Li\"},{\"authorId\":\"1748404\",\"name\":\"Zhongwen Guo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"af3b3c5ff429f34d8958b0bdeb66bdd0fb17303a\",\"title\":\"Student's t-Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/af3b3c5ff429f34d8958b0bdeb66bdd0fb17303a\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3698557\",\"name\":\"Y. Lyu\"},{\"authorId\":\"1500379010\",\"name\":\"Zhiwei Han\"},{\"authorId\":\"11323826\",\"name\":\"J. Zhong\"},{\"authorId\":\"46652020\",\"name\":\"Chang-Jiang Li\"},{\"authorId\":\"152614149\",\"name\":\"Z. Liu\"}],\"doi\":\"10.1109/TIM.2019.2954757\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e63c0991e699f65d1e3d241c190a739439e490f7\",\"title\":\"A Generic Anomaly Detection of Catenary Support Components Based on Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/e63c0991e699f65d1e3d241c190a739439e490f7\",\"venue\":\"IEEE Transactions on Instrumentation and Measurement\",\"year\":2020},{\"arxivId\":\"1909.05483\",\"authors\":[{\"authorId\":\"39644974\",\"name\":\"Simon Niklaus\"},{\"authorId\":\"2712573\",\"name\":\"Long Mai\"},{\"authorId\":\"1768964\",\"name\":\"Jimei Yang\"},{\"authorId\":\"48521790\",\"name\":\"F. Liu\"}],\"doi\":\"10.1145/3355089.3356528\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c6ff787a0190e5275e193c9bf57f672c48011d33\",\"title\":\"3D Ken Burns effect from a single image\",\"url\":\"https://www.semanticscholar.org/paper/c6ff787a0190e5275e193c9bf57f672c48011d33\",\"venue\":\"ACM Trans. Graph.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29901316\",\"name\":\"Prateep Bhattacharjee\"},{\"authorId\":\"144009889\",\"name\":\"Sukhendu Das\"}],\"doi\":\"10.1007/978-3-030-20870-7_42\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5ac8807838df5ff426e47e5ffc3eea10d3b103e8\",\"title\":\"Predicting Video Frames Using Feature Based Locally Guided Objectives\",\"url\":\"https://www.semanticscholar.org/paper/5ac8807838df5ff426e47e5ffc3eea10d3b103e8\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"1709.07894\",\"authors\":[{\"authorId\":\"2256817\",\"name\":\"Fahimeh Rezazadegan\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"},{\"authorId\":\"34686772\",\"name\":\"S. Shirazi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"29ffebd5dd7c16fa0c198ecfd238936c3e528514\",\"title\":\"A Real-time Action Prediction Framework by Encoding Temporal Evolution for Assembly Tasks\",\"url\":\"https://www.semanticscholar.org/paper/29ffebd5dd7c16fa0c198ecfd238936c3e528514\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1807.09755\",\"authors\":[{\"authorId\":\"1754382\",\"name\":\"Yijun Li\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"1768964\",\"name\":\"Jimei Yang\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"145574672\",\"name\":\"Xin Lu\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1007/978-3-030-01240-3_37\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"27680266bcfa3febb1a1537180a83129d2be4834\",\"title\":\"Flow-Grounded Spatial-Temporal Video Prediction from Still Images\",\"url\":\"https://www.semanticscholar.org/paper/27680266bcfa3febb1a1537180a83129d2be4834\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1910.12713\",\"authors\":[{\"authorId\":\"2195314\",\"name\":\"T. Wang\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":\"29955511\",\"name\":\"A. Tao\"},{\"authorId\":\"47062069\",\"name\":\"Guilin Liu\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"},{\"authorId\":\"2301680\",\"name\":\"Bryan Catanzaro\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bea92a69b48287caa3a25ff3dfe727bed8888348\",\"title\":\"Few-shot Video-to-Video Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/bea92a69b48287caa3a25ff3dfe727bed8888348\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48805400\",\"name\":\"Zhong-wei Zhang\"}],\"doi\":\"10.1109/ITOEC49072.2020.9141685\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"16aefcf957032088bfaa2d1a3f2b924bcf1a9d4e\",\"title\":\"Research Progress on Generative Adversarial Network with its Applications\",\"url\":\"https://www.semanticscholar.org/paper/16aefcf957032088bfaa2d1a3f2b924bcf1a9d4e\",\"venue\":\"2020 IEEE 5th Information Technology and Mechatronics Engineering Conference (ITOEC)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48096253\",\"name\":\"Long Zhao\"},{\"authorId\":\"144152346\",\"name\":\"Xi Peng\"},{\"authorId\":\"144978989\",\"name\":\"Y. Tian\"},{\"authorId\":\"1379758006\",\"name\":\"Mubbasir Kapadia\"},{\"authorId\":\"1711560\",\"name\":\"D. Metaxas\"}],\"doi\":\"10.1007/s11263-020-01328-9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f0ca9eb353e33e37e725a8f89bd07ca1fc09a285\",\"title\":\"Towards Image-to-Video Translation: A Structure-Aware Approach via Multi-stage Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/f0ca9eb353e33e37e725a8f89bd07ca1fc09a285\",\"venue\":\"International Journal of Computer Vision\",\"year\":2020},{\"arxivId\":\"1711.09265\",\"authors\":[{\"authorId\":\"51281239\",\"name\":\"Yu Runsheng\"},{\"authorId\":\"47134922\",\"name\":\"Shi Zhen-yu\"},{\"authorId\":\"51284306\",\"name\":\"Ma Qiongxiong\"},{\"authorId\":\"51281188\",\"name\":\"Qing Laiyun\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"6a02a6ce130ad3d6c78a5f573fd7badca41c7227\",\"title\":\"Predictive Learning: Using Future Representation Learning Variantial Autoencoder for Human Action Prediction\",\"url\":\"https://www.semanticscholar.org/paper/6a02a6ce130ad3d6c78a5f573fd7badca41c7227\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32919142\",\"name\":\"L. V. Romaguera\"},{\"authorId\":\"1902634\",\"name\":\"Rosalie Plantef\\u00e8ve\"},{\"authorId\":\"145907481\",\"name\":\"F. P. Romero\"},{\"authorId\":\"35485700\",\"name\":\"Fran\\u00e7ois H\\u00e9bert\"},{\"authorId\":\"40418932\",\"name\":\"J. Carrier\"},{\"authorId\":\"1781469\",\"name\":\"S. Kadoury\"}],\"doi\":\"10.1016/j.media.2020.101754\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c0bab5f59f6be62eb0beb8fe7fc9500a91999a88\",\"title\":\"Prediction of in-plane organ deformation during free-breathing radiotherapy via discriminative spatial transformer networks\",\"url\":\"https://www.semanticscholar.org/paper/c0bab5f59f6be62eb0beb8fe7fc9500a91999a88\",\"venue\":\"Medical Image Anal.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"17659319\",\"name\":\"Zackary P. T. Sin\"},{\"authorId\":\"2774268\",\"name\":\"P. H. Ng\"},{\"authorId\":\"1738911\",\"name\":\"S. Shiu\"},{\"authorId\":\"145288211\",\"name\":\"K. Chung\"},{\"authorId\":\"1714454\",\"name\":\"H. Leong\"}],\"doi\":\"10.1007/978-3-030-22514-8_16\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"725d8d026e1b9be741c10ae6bc0608ccea0d8ddb\",\"title\":\"Multi-level Motion-Informed Approach for Video Generation with Key Frames\",\"url\":\"https://www.semanticscholar.org/paper/725d8d026e1b9be741c10ae6bc0608ccea0d8ddb\",\"venue\":\"CGI\",\"year\":2019},{\"arxivId\":\"1903.00913\",\"authors\":[{\"authorId\":\"37145669\",\"name\":\"Lu Sheng\"},{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"},{\"authorId\":\"47093626\",\"name\":\"Jiaming Guo\"},{\"authorId\":\"144478188\",\"name\":\"J. Shao\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"545f3b0c15a0a555fda0d2377646c0c70090c185\",\"title\":\"Unsupervised Bi-directional Flow-based Video Generation from one Snapshot\",\"url\":\"https://www.semanticscholar.org/paper/545f3b0c15a0a555fda0d2377646c0c70090c185\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1712.00311\",\"authors\":[{\"authorId\":\"3305641\",\"name\":\"Marc Oliu\"},{\"authorId\":\"38081877\",\"name\":\"J. Selva\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"}],\"doi\":\"10.1007/978-3-030-01264-9_44\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e0244344a0106fb1cc502b093bd46e0e91418d3b\",\"title\":\"Folded Recurrent Neural Networks for Future Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/e0244344a0106fb1cc502b093bd46e0e91418d3b\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2001.06937\",\"authors\":[{\"authorId\":\"48603577\",\"name\":\"Jie Gui\"},{\"authorId\":\"1757186\",\"name\":\"Z. Sun\"},{\"authorId\":\"145868453\",\"name\":\"Yonggang Wen\"},{\"authorId\":\"145047838\",\"name\":\"Dacheng Tao\"},{\"authorId\":\"2778556\",\"name\":\"Jie-ping Ye\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fbc5486a1ffb9039dbb5046b84f0eb32e4ce8eea\",\"title\":\"A Review on Generative Adversarial Networks: Algorithms, Theory, and Applications\",\"url\":\"https://www.semanticscholar.org/paper/fbc5486a1ffb9039dbb5046b84f0eb32e4ce8eea\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51121093\",\"name\":\"Soumyadeep Kundu\"},{\"authorId\":\"32619549\",\"name\":\"S. Paul\"},{\"authorId\":\"144780056\",\"name\":\"Suman K. Bera\"},{\"authorId\":\"1744000\",\"name\":\"A. Abraham\"},{\"authorId\":\"35846271\",\"name\":\"Ram Sarkar\"}],\"doi\":\"10.1016/j.eswa.2019.112916\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6116f70492d1304018dfa3afa56050c039367d45\",\"title\":\"Text-line extraction from handwritten document images using GAN\",\"url\":\"https://www.semanticscholar.org/paper/6116f70492d1304018dfa3afa56050c039367d45\",\"venue\":\"Expert Syst. Appl.\",\"year\":2020}],\"corpusId\":8432557,\"doi\":\"10.1109/ICCV.2017.194\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":30,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"eb911796464b1e01e98c2b3d007a4ef9310272e2\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6c11626ae08706e6185fceff0a6d05e4bfd6bd06\",\"title\":\"Unsupervised Learning of Visual Representations using Videos\",\"url\":\"https://www.semanticscholar.org/paper/6c11626ae08706e6185fceff0a6d05e4bfd6bd06\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1703.03055\",\"authors\":[{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"1737218\",\"name\":\"L. Lin\"},{\"authorId\":\"1720987\",\"name\":\"X. Shen\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":\"10.1109/CVPR.2017.234\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"40f2560357d19e3b862a685c05cd5b48f3cb3961\",\"title\":\"Interpretable Structure-Evolving LSTM\",\"url\":\"https://www.semanticscholar.org/paper/40f2560357d19e3b862a685c05cd5b48f3cb3961\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1702.02463\",\"authors\":[{\"authorId\":\"3243969\",\"name\":\"Z. Liu\"},{\"authorId\":\"28919105\",\"name\":\"Raymond A. Yeh\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"36966089\",\"name\":\"Y. Liu\"},{\"authorId\":\"1696487\",\"name\":\"A. Agarwala\"}],\"doi\":\"10.1109/ICCV.2017.478\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8970e9caed1fca960ead644e6453a1a7321a7e6d\",\"title\":\"Video Frame Synthesis Using Deep Voxel Flow\",\"url\":\"https://www.semanticscholar.org/paper/8970e9caed1fca960ead644e6453a1a7321a7e6d\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1681442\",\"name\":\"Ce Liu\"},{\"authorId\":\"143738177\",\"name\":\"J. Yuen\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/TPAMI.2010.147\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"af14da35d7fd12d182b10594027232489c6a8b51\",\"title\":\"SIFT Flow: Dense Correspondence across Scenes and Its Applications\",\"url\":\"https://www.semanticscholar.org/paper/af14da35d7fd12d182b10594027232489c6a8b51\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2011},{\"arxivId\":\"1609.02612\",\"authors\":[{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"2367683\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.13016/M26GIH-TNYZ\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ee091ccf24c4f053c5c3dfbefe4a7975ed3447c1\",\"title\":\"Generating Videos with Scene Dynamics\",\"url\":\"https://www.semanticscholar.org/paper/ee091ccf24c4f053c5c3dfbefe4a7975ed3447c1\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1603.06041\",\"authors\":[{\"authorId\":\"1781631\",\"name\":\"Gucan Long\"},{\"authorId\":\"1727013\",\"name\":\"Laurent Kneip\"},{\"authorId\":\"2974008\",\"name\":\"Jose M. Alvarez\"},{\"authorId\":\"40124570\",\"name\":\"Hongdong Li\"},{\"authorId\":\"39045430\",\"name\":\"X. Zhang\"},{\"authorId\":\"9397915\",\"name\":\"Qifeng Yu\"}],\"doi\":\"10.1007/978-3-319-46466-4_26\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f19108c55b7c1831566ce3250322e0f5637d44c9\",\"title\":\"Learning Image Matching by Simply Watching Video\",\"url\":\"https://www.semanticscholar.org/paper/f19108c55b7c1831566ce3250322e0f5637d44c9\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1611.00850\",\"authors\":[{\"authorId\":\"1952002\",\"name\":\"A. Ranjan\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"}],\"doi\":\"10.1109/CVPR.2017.291\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a93d81c7f033f1e2b54d3288b60d214f55ccc010\",\"title\":\"Optical Flow Estimation Using a Spatial Pyramid Network\",\"url\":\"https://www.semanticscholar.org/paper/a93d81c7f033f1e2b54d3288b60d214f55ccc010\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1162/neco.1997.9.8.1735\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"title\":\"Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"venue\":\"Neural Computation\",\"year\":1997},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47237027\",\"name\":\"Andreas Geiger\"},{\"authorId\":\"37108776\",\"name\":\"Philip Lenz\"},{\"authorId\":\"1760556\",\"name\":\"C. Stiller\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"}],\"doi\":\"10.1177/0278364913491297\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"79b949d9b35c3f51dd20fb5c746cc81fc87147eb\",\"title\":\"Vision meets robotics: The KITTI dataset\",\"url\":\"https://www.semanticscholar.org/paper/79b949d9b35c3f51dd20fb5c746cc81fc87147eb\",\"venue\":\"Int. J. Robotics Res.\",\"year\":2013},{\"arxivId\":\"1701.07875\",\"authors\":[{\"authorId\":\"2877311\",\"name\":\"Mart\\u00edn Arjovsky\"},{\"authorId\":\"2127604\",\"name\":\"Soumith Chintala\"},{\"authorId\":\"52184096\",\"name\":\"L. Bottou\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2f85b7376769473d2bed56f855f115e23d727094\",\"title\":\"Wasserstein GAN\",\"url\":\"https://www.semanticscholar.org/paper/2f85b7376769473d2bed56f855f115e23d727094\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1607.02586\",\"authors\":[{\"authorId\":\"3222730\",\"name\":\"Tianfan Xue\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"18555073\",\"name\":\"K. Bouman\"},{\"authorId\":\"36668046\",\"name\":\"B. Freeman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"397e9b56e46d3cc34af1525493e597facb104570\",\"title\":\"Visual Dynamics: Probabilistic Future Frame Synthesis via Cross Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/397e9b56e46d3cc34af1525493e597facb104570\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"2340109\",\"name\":\"C. Wojek\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"}],\"doi\":\"10.1109/cvprw.2009.5206631\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"34724eeef32ba07d4aed8716f00353e3da171a68\",\"title\":\"Pedestrian detection: A benchmark\",\"url\":\"https://www.semanticscholar.org/paper/34724eeef32ba07d4aed8716f00353e3da171a68\",\"venue\":\"2009 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2009},{\"arxivId\":\"1502.04681\",\"authors\":[{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"2711409\",\"name\":\"Elman Mansimov\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"title\":\"Unsupervised Learning of Video Representations using LSTMs\",\"url\":\"https://www.semanticscholar.org/paper/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1511.06309\",\"authors\":[{\"authorId\":\"1756112\",\"name\":\"Viorica Patraucean\"},{\"authorId\":\"34653454\",\"name\":\"A. Handa\"},{\"authorId\":\"1745672\",\"name\":\"R. Cipolla\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b6e7d0ec83f2a40fadc99bb0f1ced8508f5cfee5\",\"title\":\"Spatio-temporal video autoencoder with differentiable memory\",\"url\":\"https://www.semanticscholar.org/paper/b6e7d0ec83f2a40fadc99bb0f1ced8508f5cfee5\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1507.08750\",\"authors\":[{\"authorId\":\"2894414\",\"name\":\"Junhyuk Oh\"},{\"authorId\":\"1955964\",\"name\":\"Xiaoxiao Guo\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"},{\"authorId\":\"46328485\",\"name\":\"R. L. Lewis\"},{\"authorId\":\"1699868\",\"name\":\"Satinder Singh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e4257bc131c36504a04382290cbc27ca8bb27813\",\"title\":\"Action-Conditional Video Prediction using Deep Networks in Atari Games\",\"url\":\"https://www.semanticscholar.org/paper/e4257bc131c36504a04382290cbc27ca8bb27813\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41210105\",\"name\":\"Zhou Wang\"},{\"authorId\":\"144492850\",\"name\":\"A. Bovik\"},{\"authorId\":\"120732976\",\"name\":\"H.R. Sheikh\"},{\"authorId\":\"122128303\",\"name\":\"E.P. Simoncelli\"}],\"doi\":\"10.1109/TIP.2003.819861\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"eae2e0fa72e898c289365c0af16daf57a7a6cf40\",\"title\":\"Image quality assessment: from error visibility to structural similarity\",\"url\":\"https://www.semanticscholar.org/paper/eae2e0fa72e898c289365c0af16daf57a7a6cf40\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2004},{\"arxivId\":\"1703.07022\",\"authors\":[{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"2749311\",\"name\":\"Zhiting Hu\"},{\"authorId\":\"1682058\",\"name\":\"H. Zhang\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":\"10.1109/ICCV.2017.364\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"428818a9edfb547431be6d7ec165c6af576c83d5\",\"title\":\"Recurrent Topic-Transition GAN for Visual Paragraph Generation\",\"url\":\"https://www.semanticscholar.org/paper/428818a9edfb547431be6d7ec165c6af576c83d5\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"H. Pirsiavash C. Vondrick\"},{\"authorId\":null,\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Unsu - pervised learning of video representations using lstms Lecture 6 . 5 - rmsprop : Divide the gradient by a running average of its recent magnitude\",\"url\":\"\",\"venue\":\"COURSERA : Neural networks for machine learning\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"H. Pirsiavash Vondrick\"},{\"authorId\":null,\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Unsu - pervised learning of video representations using lstms Lecture 6 . 5 - rmsprop : Divide the gradient by a running average of its recent magnitude\",\"url\":\"\",\"venue\":\"COURSERA : Neural networks for machine learning\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1621190045\",\"name\":\"Yu-Qin Cao\"},{\"authorId\":\"1617945342\",\"name\":\"Lei Yuan\"},{\"authorId\":\"1618266074\",\"name\":\"Qin Zhao\"},{\"authorId\":\"1617846354\",\"name\":\"Jian-Lin Yuan\"},{\"authorId\":\"1618093177\",\"name\":\"Yung-Fu Chang\"},{\"authorId\":\"1618081648\",\"name\":\"Xin-Tian Wen\"},{\"authorId\":\"1618259371\",\"name\":\"Rui Wu\"},{\"authorId\":\"1617850008\",\"name\":\"Xiao-Bo Huang\"},{\"authorId\":\"1617935592\",\"name\":\"Xin-Feng Han\"},{\"authorId\":\"1618215030\",\"name\":\"Xiao-Ping Ma\"},{\"authorId\":\"1618230784\",\"name\":\"San-Jie Cao\"}],\"doi\":\"10.1515/9783111419787-003\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f1f2981c3146fbd9300bd8fbfd0401ba65f8ce5a\",\"title\":\"H\",\"url\":\"https://www.semanticscholar.org/paper/f1f2981c3146fbd9300bd8fbfd0401ba65f8ce5a\",\"venue\":\"Edinburgh Medical and Surgical Journal\",\"year\":1824},{\"arxivId\":\"1612.03777\",\"authors\":[{\"authorId\":\"31656404\",\"name\":\"N. Sedaghat\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f42dca4a4426e5873a981712102aa961be34539a\",\"title\":\"Next-Flow: Hybrid Multi-Tasking with Next-Frame Prediction to Boost Optical-Flow Estimation in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/f42dca4a4426e5873a981712102aa961be34539a\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1806773\",\"name\":\"I. Misra\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1007/978-3-319-46448-0_32\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6d4e3616d0b27957c4107ae877dc0dd4504b69ab\",\"title\":\"Shuffle and Learn: Unsupervised Learning Using Temporal Order Verification\",\"url\":\"https://www.semanticscholar.org/paper/6d4e3616d0b27957c4107ae877dc0dd4504b69ab\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1606.07873\",\"authors\":[{\"authorId\":\"143928130\",\"name\":\"J. Walker\"},{\"authorId\":\"2786693\",\"name\":\"C. Doersch\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1007/978-3-319-46478-7_51\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5e96c4626e4b3d09727bcbfbdb2672dd9b886743\",\"title\":\"An Uncertain Future: Forecasting from Static Images Using Variational Autoencoders\",\"url\":\"https://www.semanticscholar.org/paper/5e96c4626e4b3d09727bcbfbdb2672dd9b886743\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1501.02565\",\"authors\":[{\"authorId\":\"3428663\",\"name\":\"J\\u00e9r\\u00f4me Revaud\"},{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"1753355\",\"name\":\"Z. Harchaoui\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/CVPR.2015.7298720\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f08e462b77347dc3cf483ca24dcd484c0ba5b432\",\"title\":\"EpicFlow: Edge-preserving interpolation of correspondences for optical flow\",\"url\":\"https://www.semanticscholar.org/paper/f08e462b77347dc3cf483ca24dcd484c0ba5b432\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1605.08104\",\"authors\":[{\"authorId\":\"2023002\",\"name\":\"William Lotter\"},{\"authorId\":\"1852992\",\"name\":\"G. Kreiman\"},{\"authorId\":\"145679323\",\"name\":\"D. Cox\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ad367b44f3434b9ba6b46b41ab083210f6827a9f\",\"title\":\"Deep Predictive Coding Networks for Video Prediction and Unsupervised Learning\",\"url\":\"https://www.semanticscholar.org/paper/ad367b44f3434b9ba6b46b41ab083210f6827a9f\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5886094\",\"name\":\"P. Cochat\"},{\"authorId\":\"13267685\",\"name\":\"L. Vaucoret\"},{\"authorId\":\"31455512\",\"name\":\"J. Sarles\"}],\"doi\":\"10.1016/j.arcped.2012.01.013\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"10d85561e4aafc516d10064f30dff05b41f70afe\",\"title\":\"[Et al].\",\"url\":\"https://www.semanticscholar.org/paper/10d85561e4aafc516d10064f30dff05b41f70afe\",\"venue\":\"Archives de pediatrie : organe officiel de la Societe francaise de pediatrie\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1710872\",\"name\":\"T. Brox\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/TPAMI.2010.143\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"ffd97ed7408fa75b86d4c8e4280f8d730ffa2cf0\",\"title\":\"Large Displacement Optical Flow: Descriptor Matching in Variational Motion Estimation\",\"url\":\"https://www.semanticscholar.org/paper/ffd97ed7408fa75b86d4c8e4280f8d730ffa2cf0\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2011},{\"arxivId\":\"1312.6114\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"1678311\",\"name\":\"M. Welling\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5f5dc5b9a2ba710937e2c413b37b053cd673df02\",\"title\":\"Auto-Encoding Variational Bayes\",\"url\":\"https://www.semanticscholar.org/paper/5f5dc5b9a2ba710937e2c413b37b053cd673df02\",\"venue\":\"ICLR\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Gorban\"},{\"authorId\":null,\"name\":\"H. Idrees\"},{\"authorId\":null,\"name\":\"Y. Jiang\"},{\"authorId\":null,\"name\":\"A. R. Zamir\"},{\"authorId\":null,\"name\":\"I. Laptev\"},{\"authorId\":null,\"name\":\"M. Shah\"},{\"authorId\":null,\"name\":\"R. Sukthankar\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Thumos challenge: Action recognition with a large number of classes\",\"url\":\"\",\"venue\":\"CVPR workshop\",\"year\":2015},{\"arxivId\":\"1703.07027\",\"authors\":[{\"authorId\":\"38774604\",\"name\":\"Prasoon Goyal\"},{\"authorId\":\"2749311\",\"name\":\"Zhiting Hu\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"47073769\",\"name\":\"Chenyu Wang\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"},{\"authorId\":\"144224881\",\"name\":\"C. Mellon\"}],\"doi\":\"10.1109/ICCV.2017.545\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5dbaaf5627d618313410d3b1fed045874c45f148\",\"title\":\"Nonparametric Variational Auto-Encoders for Hierarchical Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/5dbaaf5627d618313410d3b1fed045874c45f148\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"T. Tieleman\"},{\"authorId\":null,\"name\":\"G. Hinton\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude\",\"url\":\"\",\"venue\":\"COURSERA: Neural networks for machine learning,\",\"year\":2012},{\"arxivId\":\"1511.05440\",\"authors\":[{\"authorId\":\"143949035\",\"name\":\"Micha\\u00ebl Mathieu\"},{\"authorId\":\"2341378\",\"name\":\"C. Couprie\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"17fa1c2a24ba8f731c8b21f1244463bc4b465681\",\"title\":\"Deep multi-scale video prediction beyond mean square error\",\"url\":\"https://www.semanticscholar.org/paper/17fa1c2a24ba8f731c8b21f1244463bc4b465681\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":\"1701.01821\",\"authors\":[{\"authorId\":\"3378742\",\"name\":\"Zelun Luo\"},{\"authorId\":\"3378457\",\"name\":\"Boya Peng\"},{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"3304525\",\"name\":\"Alexandre Alahi\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2017.751\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cd5d8244038c4aba6d9b5c6a114b5e6c9c087b37\",\"title\":\"Unsupervised Learning of Long-Term Motion Dynamics for Videos\",\"url\":\"https://www.semanticscholar.org/paper/cd5d8244038c4aba6d9b5c6a114b5e6c9c087b37\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1212.0402\",\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"title\":\"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\",\"url\":\"https://www.semanticscholar.org/paper/da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1403025868\",\"name\":\"Jean Pouget-Abadie\"},{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"144738865\",\"name\":\"Bing Xu\"},{\"authorId\":\"1393680089\",\"name\":\"David Warde-Farley\"},{\"authorId\":\"1955694\",\"name\":\"Sherjil Ozair\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"title\":\"Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1506.04214\",\"authors\":[{\"authorId\":\"3008587\",\"name\":\"Xingjian Shi\"},{\"authorId\":\"2192200\",\"name\":\"Zhourong Chen\"},{\"authorId\":\"49528584\",\"name\":\"Hao Wang\"},{\"authorId\":\"1739816\",\"name\":\"D. Yeung\"},{\"authorId\":\"145771919\",\"name\":\"W. Wong\"},{\"authorId\":\"2183294\",\"name\":\"Wang-chun Woo\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f9c990b1b5724e50e5632b94fdb7484ece8a6ce7\",\"title\":\"Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting\",\"url\":\"https://www.semanticscholar.org/paper/f9c990b1b5724e50e5632b94fdb7484ece8a6ce7\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4746730\",\"name\":\"J. Lackie\"}],\"doi\":\"10.1016/b978-0-12-384931-1.00016-7\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"db750f063bc099e6d1d2d0a92a34d7c213a893e3\",\"title\":\"P\",\"url\":\"https://www.semanticscholar.org/paper/db750f063bc099e6d1d2d0a92a34d7c213a893e3\",\"venue\":\"The Dictionary of Cell & Molecular Biology\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143928130\",\"name\":\"J. Walker\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1109/CVPR.2014.416\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cc0bb8f933e514dd9441e3082a34a9f129e35500\",\"title\":\"Patch to the Future: Unsupervised Visual Prediction\",\"url\":\"https://www.semanticscholar.org/paper/cc0bb8f933e514dd9441e3082a34a9f129e35500\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1502.03167\",\"authors\":[{\"authorId\":\"144147316\",\"name\":\"S. Ioffe\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d376d6978dad0374edfa6709c9556b42d3594d3\",\"title\":\"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\",\"url\":\"https://www.semanticscholar.org/paper/4d376d6978dad0374edfa6709c9556b42d3594d3\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"2367683\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/CVPR.2016.18\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"932ac3707e1ed84ab67526692a1ef8f064f24ab5\",\"title\":\"Anticipating Visual Representations from Unlabeled Video\",\"url\":\"https://www.semanticscholar.org/paper/932ac3707e1ed84ab67526692a1ef8f064f24ab5\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1506.02025\",\"authors\":[{\"authorId\":\"3093886\",\"name\":\"Max Jaderberg\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fe87ea16d5eb1c7509da9a0314bbf4c7b0676506\",\"title\":\"Spatial Transformer Networks\",\"url\":\"https://www.semanticscholar.org/paper/fe87ea16d5eb1c7509da9a0314bbf4c7b0676506\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1504.06852\",\"authors\":[{\"authorId\":\"1382344214\",\"name\":\"A. Dosovitskiy\"},{\"authorId\":\"152702479\",\"name\":\"P. Fischer\"},{\"authorId\":\"48105320\",\"name\":\"Eddy Ilg\"},{\"authorId\":\"2880264\",\"name\":\"Philip H\\u00e4usser\"},{\"authorId\":\"3322806\",\"name\":\"Caner Hazirbas\"},{\"authorId\":\"2943639\",\"name\":\"V. Golkov\"},{\"authorId\":\"1715782\",\"name\":\"P. V. D. Smagt\"},{\"authorId\":\"153685345\",\"name\":\"D. Cremers\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1109/ICCV.2015.316\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c2fb5b39428818d7ec8cc78e152e19c21b7db568\",\"title\":\"FlowNet: Learning Optical Flow with Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/c2fb5b39428818d7ec8cc78e152e19c21b7db568\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015}],\"title\":\"Dual Motion GAN for Future-Flow Embedded Video Prediction\",\"topics\":[{\"topic\":\"Software Engineering Institute\",\"topicId\":\"30534\",\"url\":\"https://www.semanticscholar.org/topic/30534\"},{\"topic\":\"Pixel\",\"topicId\":\"4254\",\"url\":\"https://www.semanticscholar.org/topic/4254\"},{\"topic\":\"Feature learning\",\"topicId\":\"20551\",\"url\":\"https://www.semanticscholar.org/topic/20551\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Encoder\",\"topicId\":\"16744\",\"url\":\"https://www.semanticscholar.org/topic/16744\"},{\"topic\":\"Predictive learning\",\"topicId\":\"301475\",\"url\":\"https://www.semanticscholar.org/topic/301475\"},{\"topic\":\"Multi-agent system\",\"topicId\":\"3830\",\"url\":\"https://www.semanticscholar.org/topic/3830\"},{\"topic\":\"Teaching method\",\"topicId\":\"73414\",\"url\":\"https://www.semanticscholar.org/topic/73414\"},{\"topic\":\"Interaction\",\"topicId\":\"72\",\"url\":\"https://www.semanticscholar.org/topic/72\"},{\"topic\":\"Information\",\"topicId\":\"185548\",\"url\":\"https://www.semanticscholar.org/topic/185548\"},{\"topic\":\"Coherence (physics)\",\"topicId\":\"921\",\"url\":\"https://www.semanticscholar.org/topic/921\"},{\"topic\":\"Closed-loop transfer function\",\"topicId\":\"984980\",\"url\":\"https://www.semanticscholar.org/topic/984980\"},{\"topic\":\"Feedback\",\"topicId\":\"242\",\"url\":\"https://www.semanticscholar.org/topic/242\"},{\"topic\":\"Machine learning\",\"topicId\":\"168\",\"url\":\"https://www.semanticscholar.org/topic/168\"},{\"topic\":\"Calculus of variations\",\"topicId\":\"34187\",\"url\":\"https://www.semanticscholar.org/topic/34187\"}],\"url\":\"https://www.semanticscholar.org/paper/eb911796464b1e01e98c2b3d007a4ef9310272e2\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017}\n"