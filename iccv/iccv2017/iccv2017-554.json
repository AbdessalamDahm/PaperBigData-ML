"{\"abstract\":\"This paper focuses on temporal localization of actions in untrimmed videos. Existing methods typically train classifiers for a pre-defined list of actions and apply them in a sliding window fashion. However, activities in the wild consist of a wide combination of actors, actions and objects; it is difficult to design a proper activity list that meets users\\u2019 needs. We propose to localize activities by natural language queries. Temporal Activity Localization via Language (TALL) is challenging as it requires: (1) suitable design of text and video representations to allow cross-modal matching of actions and language queries; (2) ability to locate actions accurately given features from sliding windows of limited granularity. We propose a novel Cross-modal Temporal Regression Localizer (CTRL) to jointly model text query and video clips, output alignment scores and action boundary regression results for candidate clips. Lor evaluation, we adopt TaCoS dataset, and build a new dataset for this task on top of Charades by adding sentence temporal annotations, called Charades-STA. We also build complex sentence queries in Charades-STA for test. Experimental results show that CTRL outperforms previous methods significantly on both datasets.\",\"arxivId\":\"1705.02101\",\"authors\":[{\"authorId\":\"3029956\",\"name\":\"J. Gao\",\"url\":\"https://www.semanticscholar.org/author/3029956\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\",\"url\":\"https://www.semanticscholar.org/author/144762505\"},{\"authorId\":\"3469030\",\"name\":\"Zhenheng Yang\",\"url\":\"https://www.semanticscholar.org/author/3469030\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\",\"url\":\"https://www.semanticscholar.org/author/144862593\"}],\"citationVelocity\":49,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Zhu Zhang\"},{\"authorId\":\"144197770\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"49290494\",\"name\":\"Zhijie Lin\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"49710696\",\"name\":\"Dexia Cai\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5d145292fd11ca274693ec9ea6941a9147ae5868\",\"title\":\"4 Self-Attention Interaction Localizer 4 . 1 Problem Formulation\",\"url\":\"https://www.semanticscholar.org/paper/5d145292fd11ca274693ec9ea6941a9147ae5868\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2359832\",\"name\":\"Hongya Wang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"46772808\",\"name\":\"X. Chen\"},{\"authorId\":\"2352456\",\"name\":\"Z. Xiong\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1145/3394171.3413975\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7b8d5e6f888c4e165fea9bab809239f7fe5fef65\",\"title\":\"Dual Path Interaction Network for Video Moment Localization\",\"url\":\"https://www.semanticscholar.org/paper/7b8d5e6f888c4e165fea9bab809239f7fe5fef65\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2007.09877\",\"authors\":[{\"authorId\":\"152641281\",\"name\":\"Y. Zhou\"},{\"authorId\":\"7271879\",\"name\":\"M. Wang\"},{\"authorId\":\"121357290\",\"name\":\"Ruolin Wang\"},{\"authorId\":\"19216752\",\"name\":\"Shuwei Huo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5d5710aa2ec37b641754c1268a35028f6fe1341a\",\"title\":\"Graph Neural Network for Video-Query based Video Moment Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/5d5710aa2ec37b641754c1268a35028f6fe1341a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1808.01575\",\"authors\":[{\"authorId\":\"144599697\",\"name\":\"Y. Feng\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"38144094\",\"name\":\"T. Zhang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1007/978-3-030-01264-9_4\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8619ce85b69e6164cb5bb32f225e510a0570bb37\",\"title\":\"Video Re-localization\",\"url\":\"https://www.semanticscholar.org/paper/8619ce85b69e6164cb5bb32f225e510a0570bb37\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1909.00239\",\"authors\":[{\"authorId\":\"1759094\",\"name\":\"Mingfei Gao\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"}],\"doi\":\"10.18653/v1/D19-1157\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a758828d2865592fb7ee0c95fe4d2517cf405196\",\"title\":\"WSLLN: Weakly Supervised Natural Language Localization Networks\",\"url\":\"https://www.semanticscholar.org/paper/a758828d2865592fb7ee0c95fe4d2517cf405196\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3178508\",\"name\":\"Songyang Zhang\"},{\"authorId\":\"34739384\",\"name\":\"Jinsong Su\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":null,\"intent\":[\"methodology\",\"result\"],\"isInfluential\":false,\"paperId\":\"2f84c74b0c1b66420d06ad07f8a6b58fbf215ff6\",\"title\":\"Video Tree Attention Network Phrase Embedding ds Query Phrase Embedding dc Phrase Embedding dm Sentence Embedding hroot Temporal Localization Module Temporal Relationship Module + Matching\",\"url\":\"https://www.semanticscholar.org/paper/2f84c74b0c1b66420d06ad07f8a6b58fbf215ff6\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1906.12165\",\"authors\":[{\"authorId\":\"1764508\",\"name\":\"Z. Zhang\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"34064720\",\"name\":\"Zhijie Lin\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"}],\"doi\":\"10.24963/ijcai.2019/610\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5d145292fd11ca274693ec9ea6941a9147ae5868\",\"title\":\"Localizing Unseen Activities in Video via Image Query\",\"url\":\"https://www.semanticscholar.org/paper/5d145292fd11ca274693ec9ea6941a9147ae5868\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"1812.00087\",\"authors\":[{\"authorId\":\"145979995\",\"name\":\"D. Zhang\"},{\"authorId\":\"3386593\",\"name\":\"X. Dai\"},{\"authorId\":\"48631993\",\"name\":\"Xin Eric Wang\"},{\"authorId\":\"1706938\",\"name\":\"Y. Wang\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/CVPR.2019.00134\",\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"613f59279586bd53aed57bc133246a4eb3c38977\",\"title\":\"MAN: Moment Alignment Network for Natural Language Moment Retrieval via Iterative Graph Adjustment\",\"url\":\"https://www.semanticscholar.org/paper/613f59279586bd53aed57bc133246a4eb3c38977\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2005.06409\",\"authors\":[{\"authorId\":\"51270689\",\"name\":\"Hyounghun Kim\"},{\"authorId\":\"151270642\",\"name\":\"Zineng Tang\"},{\"authorId\":\"143977266\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/2020.acl-main.435\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9a87c1f04bae4ab507ed0e03bfd10d870d733367\",\"title\":\"Dense-Caption Matching and Frame-Selection Gating for Temporal Localization in VideoQA\",\"url\":\"https://www.semanticscholar.org/paper/9a87c1f04bae4ab507ed0e03bfd10d870d733367\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"2005.00706\",\"authors\":[{\"authorId\":\"40027632\",\"name\":\"F. F. Xu\"},{\"authorId\":\"144906579\",\"name\":\"Lei Ji\"},{\"authorId\":\"119700639\",\"name\":\"Botian Shi\"},{\"authorId\":\"3109653\",\"name\":\"Junyi Du\"},{\"authorId\":\"1700325\",\"name\":\"Graham Neubig\"},{\"authorId\":\"3312309\",\"name\":\"Yonatan Bisk\"},{\"authorId\":\"46429989\",\"name\":\"N. Duan\"}],\"doi\":\"10.18653/v1/2020.nlpbt-1.4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"358d7d6333d3edd530e37efd8004cb9da8cfd5d4\",\"title\":\"A Benchmark for Structured Procedural Knowledge Extraction from Cooking Videos\",\"url\":\"https://www.semanticscholar.org/paper/358d7d6333d3edd530e37efd8004cb9da8cfd5d4\",\"venue\":\"NLPBT\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"145905328\",\"name\":\"Kun He\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"a50d2245d46ce0595ddbf25ae9acb8513aa70067\",\"title\":\"Text-to-Clip Video Retrieval with Early Fusion and Re-Captioning\",\"url\":\"https://www.semanticscholar.org/paper/a50d2245d46ce0595ddbf25ae9acb8513aa70067\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1908.03846\",\"authors\":[{\"authorId\":\"3178508\",\"name\":\"Songyang Zhang\"},{\"authorId\":\"34739384\",\"name\":\"Jinsong Su\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1145/3343031.3350879\",\"intent\":[\"methodology\",\"result\"],\"isInfluential\":false,\"paperId\":\"21ad966d7cc9812e2e96f37a577456947e5b694e\",\"title\":\"Exploiting Temporal Relationships in Video Moment Localization with Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/21ad966d7cc9812e2e96f37a577456947e5b694e\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1905.13540\",\"authors\":[{\"authorId\":\"2447631\",\"name\":\"Junyeong Kim\"},{\"authorId\":\"103278467\",\"name\":\"Minuk Ma\"},{\"authorId\":\"3549056\",\"name\":\"K. Kim\"},{\"authorId\":\"72108920\",\"name\":\"S. Kim\"},{\"authorId\":\"145954697\",\"name\":\"C. Yoo\"}],\"doi\":\"10.1109/IJCNN.2019.8852087\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1165b090e5ec6a9311ecba5be4f6aac0a1a4586b\",\"title\":\"Gaining Extra Supervision via Multi-task learning for Multi-Modal Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1165b090e5ec6a9311ecba5be4f6aac0a1a4586b\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Qiuhong Ke\"},{\"authorId\":null,\"name\":\"Mario Fritz\"},{\"authorId\":null,\"name\":\"Bernt Schiele\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aa3e6e3382edc7374cfa64ef69d7b92ee9bde066\",\"title\":\"Future Moment Assessment for Action Query\",\"url\":\"https://www.semanticscholar.org/paper/aa3e6e3382edc7374cfa64ef69d7b92ee9bde066\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1907.12763\",\"authors\":[{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"150234800\",\"name\":\"Mattia Soldan\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"145160922\",\"name\":\"Bryan Russell\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e12a3e3f3f383f222b5d2007802d7b7944364301\",\"title\":\"Temporal Localization of Moments in Video Collections with Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/e12a3e3f3f383f222b5d2007802d7b7944364301\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2004.07967\",\"authors\":[{\"authorId\":\"144810262\",\"name\":\"H. M. Nguyen\"},{\"authorId\":\"3388392\",\"name\":\"T. Miyazaki\"},{\"authorId\":\"2137463\",\"name\":\"Y. Sugaya\"},{\"authorId\":\"1740235\",\"name\":\"S. Omachi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"20b15ddf9efe511961321355bcb4a62c3a29a9ef\",\"title\":\"Multiple Visual-Semantic Embedding for Video Retrieval from Query Sentence\",\"url\":\"https://www.semanticscholar.org/paper/20b15ddf9efe511961321355bcb4a62c3a29a9ef\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"},{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"},{\"authorId\":\"144983134\",\"name\":\"J. Chan\"},{\"authorId\":\"1789840\",\"name\":\"K. Miyazawa\"},{\"authorId\":\"145730148\",\"name\":\"Hassan Mansour\"},{\"authorId\":\"1690385\",\"name\":\"A. Vetro\"},{\"authorId\":\"1398090762\",\"name\":\"Xavier Gir\\u00f3-i-Nieto\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2d5d85a741f7926d8774e037c57a245ae6c94356\",\"title\":\"Online Action Detection in Untrimmed, Streaming Videos - Modeling and Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/2d5d85a741f7926d8774e037c57a245ae6c94356\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1809.01696\",\"authors\":[{\"authorId\":\"46665218\",\"name\":\"Jie Lei\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.18653/v1/D18-1167\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e7e1313061b0d56364bd2c41f017deb954bb05db\",\"title\":\"TVQA: Localized, Compositional Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e7e1313061b0d56364bd2c41f017deb954bb05db\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144069314\",\"name\":\"Bin Jiang\"},{\"authorId\":\"47932618\",\"name\":\"X. Huang\"},{\"authorId\":\"143702931\",\"name\":\"C. Yang\"},{\"authorId\":\"48837492\",\"name\":\"J. Yuan\"}],\"doi\":\"10.1016/j.ipm.2019.102104\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bbc7306c513c42dff502dd0ce3850aab54096216\",\"title\":\"SLTFNet: A spatial and language-temporal tensor fusion network for video moment retrieval\",\"url\":\"https://www.semanticscholar.org/paper/bbc7306c513c42dff502dd0ce3850aab54096216\",\"venue\":\"Inf. Process. Manag.\",\"year\":2019},{\"arxivId\":\"2004.07514\",\"authors\":[{\"authorId\":\"8511875\",\"name\":\"Jonghwan Mun\"},{\"authorId\":\"72643925\",\"name\":\"Minsu Cho\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":\"10.1109/CVPR42600.2020.01082\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7e3d5b20e5df692deb80d9e100e4f34c1a8f8031\",\"title\":\"Local-Global Video-Text Interactions for Temporal Grounding\",\"url\":\"https://www.semanticscholar.org/paper/7e3d5b20e5df692deb80d9e100e4f34c1a8f8031\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2004.13217\",\"authors\":[{\"authorId\":\"34871664\",\"name\":\"R. Cruz\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"145185576\",\"name\":\"Dylan Campbell\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1109/CVPRW50498.2020.00192\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"537b0899452b3ed09a2945cdd5f3d42383611fac\",\"title\":\"Inferring Temporal Compositions of Actions Using Probabilistic Automata\",\"url\":\"https://www.semanticscholar.org/paper/537b0899452b3ed09a2945cdd5f3d42383611fac\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jiazhao Li\"},{\"authorId\":\"153913582\",\"name\":\"Tian-Yu Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"89e55a09acdb1a1aff26a40ffa45a1f35d828581\",\"title\":\"Video Segments Retrieval System based on A entive CNN\",\"url\":\"https://www.semanticscholar.org/paper/89e55a09acdb1a1aff26a40ffa45a1f35d828581\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39650418\",\"name\":\"S. Chen\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1007/978-3-030-58565-5_36\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"853069fa3f976fe368858ce4650b6348a17a3764\",\"title\":\"Hierarchical Visual-Textual Graph for Temporal Activity Localization via Language\",\"url\":\"https://www.semanticscholar.org/paper/853069fa3f976fe368858ce4650b6348a17a3764\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2008.08716\",\"authors\":[{\"authorId\":\"152666334\",\"name\":\"Sudipta Paul\"},{\"authorId\":\"47733442\",\"name\":\"Niluthpol Chowdhury Mithun\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2efdeaa68e94eeef2831536cdd53f3e3868bbdca\",\"title\":\"Text-based Localization of Moments in a Video Corpus\",\"url\":\"https://www.semanticscholar.org/paper/2efdeaa68e94eeef2831536cdd53f3e3868bbdca\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144069314\",\"name\":\"Bin Jiang\"},{\"authorId\":\"49444962\",\"name\":\"X. Huang\"},{\"authorId\":\"143702931\",\"name\":\"C. Yang\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1145/3323873.3325019\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4e1ad4e3eeded53acf7514029ec556ee0ea42c45\",\"title\":\"Cross-Modal Video Moment Retrieval with Spatial and Language-Temporal Attention\",\"url\":\"https://www.semanticscholar.org/paper/4e1ad4e3eeded53acf7514029ec556ee0ea42c45\",\"venue\":\"ICMR\",\"year\":2019},{\"arxivId\":\"2001.06891\",\"authors\":[{\"authorId\":\"1742291\",\"name\":\"Zixing Zhang\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"90148415\",\"name\":\"Yang Zhao\"},{\"authorId\":\"50621207\",\"name\":\"Q. Wang\"},{\"authorId\":\"46936306\",\"name\":\"H. Liu\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"}],\"doi\":\"10.1109/cvpr42600.2020.01068\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0a709bb1b4bce51de5aa67a362ea69e51a43d1e5\",\"title\":\"Where Does It Exist: Spatio-Temporal Video Grounding for Multi-Form Sentences\",\"url\":\"https://www.semanticscholar.org/paper/0a709bb1b4bce51de5aa67a362ea69e51a43d1e5\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2011.00597\",\"authors\":[{\"authorId\":\"2007582232\",\"name\":\"Simon Ging\"},{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"1835025\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"80089ad641bae28b0e57771afef181b60011069e\",\"title\":\"COOT: Cooperative Hierarchical Transformer for Video-Text Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/80089ad641bae28b0e57771afef181b60011069e\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2011.10132\",\"authors\":[{\"authorId\":\"51218991\",\"name\":\"Sisi Qu\"},{\"authorId\":\"150234800\",\"name\":\"Mattia Soldan\"},{\"authorId\":\"97375393\",\"name\":\"Mengmeng Xu\"},{\"authorId\":\"1402915033\",\"name\":\"Jesper Tegn\\u00e9r\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"075ce64105cc54cec2b54c24f8f890f2c62d090b\",\"title\":\"VLG-Net: Video-Language Graph Matching Network for Video Grounding\",\"url\":\"https://www.semanticscholar.org/paper/075ce64105cc54cec2b54c24f8f890f2c62d090b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.03793\",\"authors\":[{\"authorId\":\"30793303\",\"name\":\"Amirhoshang Hoseinpour Dehkordi\"},{\"authorId\":\"153235768\",\"name\":\"M. Alizadeh\"},{\"authorId\":\"1397911258\",\"name\":\"Ali Movaghar-Rahimabadi\"}],\"doi\":\"10.36227/techrxiv.12928544\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"46f097e32ea304a14c8e26648b05f944d530b016\",\"title\":\"Linear Temporal Public Announcement Logic: a new perspective for reasoning the knowledge of multi-classifiers\",\"url\":\"https://www.semanticscholar.org/paper/46f097e32ea304a14c8e26648b05f944d530b016\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1803.07485\",\"authors\":[{\"authorId\":\"32781361\",\"name\":\"Kirill Gavrilyuk\"},{\"authorId\":\"3060081\",\"name\":\"A. Ghodrati\"},{\"authorId\":\"3245057\",\"name\":\"Zhenyang Li\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1109/CVPR.2018.00624\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1e55e9c647832c969e449da28a391205a9704c60\",\"title\":\"Actor and Action Video Segmentation from a Sentence\",\"url\":\"https://www.semanticscholar.org/paper/1e55e9c647832c969e449da28a391205a9704c60\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1911.08199\",\"authors\":[{\"authorId\":\"49290494\",\"name\":\"Zhijie Lin\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"51305348\",\"name\":\"Zhu Zhang\"},{\"authorId\":\"50621207\",\"name\":\"Q. Wang\"},{\"authorId\":\"46936306\",\"name\":\"H. Liu\"}],\"doi\":\"10.1609/AAAI.V34I07.6820\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9388ec8a0de86969afce29947b8b80b5698e4a21\",\"title\":\"Weakly-Supervised Video Moment Retrieval via Semantic Completion Network\",\"url\":\"https://www.semanticscholar.org/paper/9388ec8a0de86969afce29947b8b80b5698e4a21\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1904.03885\",\"authors\":[{\"authorId\":\"2862582\",\"name\":\"Peratham Wiriyathammabhum\"},{\"authorId\":null,\"name\":\"Abhinav Shrivastava\"},{\"authorId\":\"2852035\",\"name\":\"V. Morariu\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.18653/v1/W19-1802\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e164e75632e23a7fba6a46d2ee2dc328720601af\",\"title\":\"Referring to Objects in Videos using Spatio-Temporal Identifying Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/e164e75632e23a7fba6a46d2ee2dc328720601af\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2006.11747\",\"authors\":[{\"authorId\":\"1500408667\",\"name\":\"Zhiyuan Fang\"},{\"authorId\":\"34362536\",\"name\":\"S. Kong\"},{\"authorId\":\"1521319166\",\"name\":\"Zhe Wang\"},{\"authorId\":\"143800213\",\"name\":\"Charless C. Fowlkes\"},{\"authorId\":\"1784500\",\"name\":\"Yezhou Yang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a792ff56eeed530fab1935168510cbb16b0f1b68\",\"title\":\"Weak Supervision and Referring Attention for Temporal-Textual Association Learning\",\"url\":\"https://www.semanticscholar.org/paper/a792ff56eeed530fab1935168510cbb16b0f1b68\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48677815\",\"name\":\"Xinyan Yu\"},{\"authorId\":\"49890039\",\"name\":\"Y. Zhang\"},{\"authorId\":\"143758471\",\"name\":\"Rui Zhang\"}],\"doi\":\"10.1007/978-3-030-30671-7_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"62afe2605541f485bbd2bfe89b41161ce08a5977\",\"title\":\"Cross-Modality Video Segment Retrieval with Ensemble Learning\",\"url\":\"https://www.semanticscholar.org/paper/62afe2605541f485bbd2bfe89b41161ce08a5977\",\"venue\":\"Domain Adaptation for Visual Understanding\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35137594\",\"name\":\"Jinpeng Mi\"},{\"authorId\":\"1939598\",\"name\":\"Jian-Zhi Lyu\"},{\"authorId\":\"1739175813\",\"name\":\"Song Tang\"},{\"authorId\":\"153082688\",\"name\":\"Qingdu Li\"},{\"authorId\":\"50561627\",\"name\":\"J. Zhang\"}],\"doi\":\"10.3389/fnbot.2020.00043\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ceb666a47c683b0555f8976e7d2a0f15f9cf8be2\",\"title\":\"Interactive Natural Language Grounding via Referring Expression Comprehension and Scene Graph Parsing\",\"url\":\"https://www.semanticscholar.org/paper/ceb666a47c683b0555f8976e7d2a0f15f9cf8be2\",\"venue\":\"Frontiers in Neurorobotics\",\"year\":2020},{\"arxivId\":\"1901.06829\",\"authors\":[{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"1749527\",\"name\":\"Xiang Zhao\"},{\"authorId\":\"2864855\",\"name\":\"Jizhou Huang\"},{\"authorId\":\"50984378\",\"name\":\"F. Li\"},{\"authorId\":\"48033101\",\"name\":\"Xiao Liu\"},{\"authorId\":\"35247507\",\"name\":\"Shilei Wen\"}],\"doi\":\"10.1609/aaai.v33i01.33018393\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6fd7e8aa1a031923e3580752e4ab9163e45fe41c\",\"title\":\"Read, Watch, and Move: Reinforcement Learning for Temporally Grounding Natural Language Descriptions in Videos\",\"url\":\"https://www.semanticscholar.org/paper/6fd7e8aa1a031923e3580752e4ab9163e45fe41c\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"2005.00200\",\"authors\":[{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"2378902\",\"name\":\"Yen-Chun Chen\"},{\"authorId\":\"1664725279\",\"name\":\"Yu Cheng\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1520007550\",\"name\":\"Jingjing Liu\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.161\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6961065a16f6c3db4879cfad5875d11ce75e6b2f\",\"title\":\"HERO: Hierarchical Encoder for Video+Language Omni-representation Pre-training\",\"url\":\"https://www.semanticscholar.org/paper/6961065a16f6c3db4879cfad5875d11ce75e6b2f\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2006.10260\",\"authors\":[{\"authorId\":\"29936554\",\"name\":\"Madhawa Vidanapathirana\"},{\"authorId\":\"7351931\",\"name\":\"Supriya Pandhre\"},{\"authorId\":\"1752600856\",\"name\":\"Sonia Raychaudhuri\"},{\"authorId\":\"30060974\",\"name\":\"Anjali Khurana\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9fdc58ef2b1cbd4f7be32fab19cda112e8674d78\",\"title\":\"Video Moment Localization using Object Evidence and Reverse Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9fdc58ef2b1cbd4f7be32fab19cda112e8674d78\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Charades-STA\"},{\"authorId\":null,\"name\":\"ActivityNet\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a2ad7a90e589ae7dd33185edba10498c78da9f3c\",\"title\":\"Uncovering Hidden Challenges in Query-Based Video Moment Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/a2ad7a90e589ae7dd33185edba10498c78da9f3c\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1804.07014\",\"authors\":[{\"authorId\":\"48009996\",\"name\":\"Yitian Yuan\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"145583986\",\"name\":\"Wenwu Zhu\"}],\"doi\":\"10.1609/aaai.v33i01.33019159\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"31bb920739f22b4865161f75692785decfea470c\",\"title\":\"To Find Where You Talk: Temporal Sentence Localization in Video with Attention Based Location Regression\",\"url\":\"https://www.semanticscholar.org/paper/31bb920739f22b4865161f75692785decfea470c\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"2008.02448\",\"authors\":[{\"authorId\":\"51912474\",\"name\":\"Xiaoye Qu\"},{\"authorId\":\"1855095179\",\"name\":\"Pengwei Tang\"},{\"authorId\":\"3008849\",\"name\":\"Zhikang Zhou\"},{\"authorId\":\"5524736\",\"name\":\"Y. Cheng\"},{\"authorId\":\"40240283\",\"name\":\"J. Dong\"},{\"authorId\":\"145232778\",\"name\":\"Pan Zhou\"}],\"doi\":\"10.1145/3394171.3414053\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a4d78df0b175e3cbf811e652184f6b1e9d11caca\",\"title\":\"Fine-grained Iterative Attention Network for Temporal Language Localization in Videos\",\"url\":\"https://www.semanticscholar.org/paper/a4d78df0b175e3cbf811e652184f6b1e9d11caca\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1905.03922\",\"authors\":[{\"authorId\":\"144599697\",\"name\":\"Y. Feng\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"144416719\",\"name\":\"W. Liu\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2019.00138\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c19659297ac67a29d7524fba60062558f2235f8a\",\"title\":\"Spatio-Temporal Video Re-Localization by Warp LSTM\",\"url\":\"https://www.semanticscholar.org/paper/c19659297ac67a29d7524fba60062558f2235f8a\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2011.11071\",\"authors\":[{\"authorId\":\"2028596941\",\"name\":\"Andreea-Maria Oncescu\"},{\"authorId\":\"143848064\",\"name\":\"Jo\\u00e3o F. Henriques\"},{\"authorId\":\"1614034792\",\"name\":\"Yang Liu\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"},{\"authorId\":\"7641268\",\"name\":\"Samuel Albanie\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6ee5d4a6ead378df9949daad5cf245c01563a3fa\",\"title\":\"QuerYD: A video dataset with high-quality textual and audio narrations\",\"url\":\"https://www.semanticscholar.org/paper/6ee5d4a6ead378df9949daad5cf245c01563a3fa\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1804.05113\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"145905328\",\"name\":\"Kun He\"},{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1609/AAAI.V33I01.33019062\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"83b2a55aecd5f917dbedbc0c5ef3ff3b61013958\",\"title\":\"Multilevel Language and Vision Integration for Text-to-Clip Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/83b2a55aecd5f917dbedbc0c5ef3ff3b61013958\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1910.14303\",\"authors\":[{\"authorId\":\"48009996\",\"name\":\"Yitian Yuan\"},{\"authorId\":\"152309770\",\"name\":\"Lin Ma\"},{\"authorId\":\"46584062\",\"name\":\"Junling Wang\"},{\"authorId\":\"1743698\",\"name\":\"Wenyu Liu\"},{\"authorId\":\"145583985\",\"name\":\"Wenwu Zhu\"}],\"doi\":\"10.1109/tpami.2020.3038993\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"613634071acd170fe5c20600f8d49662a8c3b23f\",\"title\":\"Semantic Conditioned Dynamic Modulation for Temporal Sentence Grounding in Videos\",\"url\":\"https://www.semanticscholar.org/paper/613634071acd170fe5c20600f8d49662a8c3b23f\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46447373\",\"name\":\"X. Zhang\"},{\"authorId\":\"48019166\",\"name\":\"J. Zhao\"},{\"authorId\":null,\"name\":\"Long Chen\"},{\"authorId\":\"71074804\",\"name\":\"W. Wang\"}],\"doi\":\"10.1007/978-3-030-64221-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cd8930e23b8aa474df701469a4e9d8c8098c9432\",\"title\":\"Advances in Neural Networks \\u2013 ISNN 2020: 17th International Symposium on Neural Networks, ISNN 2020, Cairo, Egypt, December 4\\u20136, 2020, Proceedings\",\"url\":\"https://www.semanticscholar.org/paper/cd8930e23b8aa474df701469a4e9d8c8098c9432\",\"venue\":\"ISNN\",\"year\":2020},{\"arxivId\":\"2009.08614\",\"authors\":[{\"authorId\":\"2017491\",\"name\":\"J. Wu\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"50016941\",\"name\":\"Xiao-Guang Han\"},{\"authorId\":\"49478124\",\"name\":\"L. Lin\"}],\"doi\":\"10.1145/3394171.3413862\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"949b698f4aaaeea923d451db8175c5b464520f27\",\"title\":\"Reinforcement Learning for Weakly Supervised Temporal Grounding of Natural Language in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/949b698f4aaaeea923d451db8175c5b464520f27\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2001.09308\",\"authors\":[{\"authorId\":\"26907392\",\"name\":\"Zhenfang Chen\"},{\"authorId\":\"152309767\",\"name\":\"L. Ma\"},{\"authorId\":\"145909988\",\"name\":\"Wenhan Luo\"},{\"authorId\":\"144963373\",\"name\":\"Peng Tang\"},{\"authorId\":\"1698116\",\"name\":\"K. Wong\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"02c9abd1c4567ba82289b1a989a51243087c6521\",\"title\":\"Look Closer to Ground Better: Weakly-Supervised Temporal Grounding of Sentence in Video\",\"url\":\"https://www.semanticscholar.org/paper/02c9abd1c4567ba82289b1a989a51243087c6521\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.00325\",\"authors\":[{\"authorId\":\"3186326\",\"name\":\"Mayu Otani\"},{\"authorId\":\"1789677\",\"name\":\"Yuta Nakashima\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"},{\"authorId\":\"48679036\",\"name\":\"J. Heikkila\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a9e1c2820f86b80d4b0b93829ceb982d9890a252\",\"title\":\"Uncovering Hidden Challenges in Query-Based Video Moment Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/a9e1c2820f86b80d4b0b93829ceb982d9890a252\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1731750\",\"name\":\"Weining Wang\"},{\"authorId\":\"49866972\",\"name\":\"Y. Huang\"},{\"authorId\":\"97846606\",\"name\":\"L. Wang\"}],\"doi\":\"10.1016/j.patcog.2020.107248\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"44225a35d3c5f6e5a98963a6428c22bfdd4586d4\",\"title\":\"Long video question answering: A Matching-guided Attention Model\",\"url\":\"https://www.semanticscholar.org/paper/44225a35d3c5f6e5a98963a6428c22bfdd4586d4\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1481012996\",\"name\":\"Evin Pinar \\u00d6rnek\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"63998c9ef7bffaf4a92619af32eeac95320d0b1e\",\"title\":\"Zero-Shot Activity Recognition with Videos\",\"url\":\"https://www.semanticscholar.org/paper/63998c9ef7bffaf4a92619af32eeac95320d0b1e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145488619\",\"name\":\"M. Liu\"},{\"authorId\":null,\"name\":\"Xiang Wang\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":\"7792071\",\"name\":\"X. He\"},{\"authorId\":\"1748939\",\"name\":\"B. Chen\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1145/3209978.3210003\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"519da94369c1d87e09c592f239b55cc9486b5b7c\",\"title\":\"Attentive Moment Retrieval in Videos\",\"url\":\"https://www.semanticscholar.org/paper/519da94369c1d87e09c592f239b55cc9486b5b7c\",\"venue\":\"SIGIR\",\"year\":2018},{\"arxivId\":\"1910.02993\",\"authors\":[{\"authorId\":\"49577833\",\"name\":\"Daniel Y. Fu\"},{\"authorId\":\"41156945\",\"name\":\"W. Crichton\"},{\"authorId\":\"2651173\",\"name\":\"J. Hong\"},{\"authorId\":\"153742294\",\"name\":\"Xinwei Yao\"},{\"authorId\":\"9184695\",\"name\":\"Haotian Zhang\"},{\"authorId\":\"48289103\",\"name\":\"Anh Truong\"},{\"authorId\":\"1381444249\",\"name\":\"Avanika Narayan\"},{\"authorId\":\"1820412\",\"name\":\"M. Agrawala\"},{\"authorId\":\"1803218\",\"name\":\"Christopher R\\u00e9\"},{\"authorId\":\"2789576\",\"name\":\"K. Fatahalian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9eb31de07bd0cd684a46785020f08633e4331e05\",\"title\":\"Rekall: Specifying Video Events using Compositions of Spatiotemporal Labels\",\"url\":\"https://www.semanticscholar.org/paper/9eb31de07bd0cd684a46785020f08633e4331e05\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2011.05049\",\"authors\":[{\"authorId\":\"2008154246\",\"name\":\"Zongheng Tang\"},{\"authorId\":\"47303356\",\"name\":\"Yue Liao\"},{\"authorId\":\"101219260\",\"name\":\"Si Liu\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"2103483\",\"name\":\"X. Jin\"},{\"authorId\":\"2292508\",\"name\":\"Hongxu Jiang\"},{\"authorId\":\"1410184682\",\"name\":\"Qian Yu\"},{\"authorId\":\"1510477221\",\"name\":\"Dong Xu\"}],\"doi\":null,\"intent\":[\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"74c30c601d5de21af098389abf7be0f8261e6c13\",\"title\":\"Human-centric Spatio-Temporal Video Grounding With Visual Transformers\",\"url\":\"https://www.semanticscholar.org/paper/74c30c601d5de21af098389abf7be0f8261e6c13\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98579574\",\"name\":\"Daizong Liu\"},{\"authorId\":\"51912474\",\"name\":\"Xiaoye Qu\"},{\"authorId\":\"1912074118\",\"name\":\"Jianfeng Dong\"},{\"authorId\":\"145232778\",\"name\":\"Pan Zhou\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"83d2f3b57aa07c499c3a19d22fe4f4ef655e9030\",\"title\":\"Reasoning Step-by-Step: Temporal Sentence Localization in Videos via Deep Rectification-Modulation Network\",\"url\":\"https://www.semanticscholar.org/paper/83d2f3b57aa07c499c3a19d22fe4f4ef655e9030\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47740660\",\"name\":\"Jingyuan Chen\"},{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"3179887\",\"name\":\"Xinpeng Chen\"},{\"authorId\":\"2750647\",\"name\":\"Zequn Jie\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"631d21ee2e0de4227be1dfe000006acf1e0fe783\",\"title\":\"Sentence Encoder Video Encoder Frame-Specific Sentence Representation Cross Gating Matching Aggregation Self Interactor Segment Localizer Cross Modal\",\"url\":\"https://www.semanticscholar.org/paper/631d21ee2e0de4227be1dfe000006acf1e0fe783\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"49730189\",\"name\":\"Boyang Li\"},{\"authorId\":\"2018561\",\"name\":\"Vasili Ramanishka\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/WACVW.2019.00011\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"32b3e8f7a673801d6bcfb482a72c52c78e96b006\",\"title\":\"Joint Event Detection and Description in Continuous Video Streams\",\"url\":\"https://www.semanticscholar.org/paper/32b3e8f7a673801d6bcfb482a72c52c78e96b006\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405196499\",\"name\":\"Marcos Baptista-R\\u00edos\"},{\"authorId\":\"1402973336\",\"name\":\"R. L\\u00f3pez-Sastre\"},{\"authorId\":\"1402975934\",\"name\":\"F. J. Acevedo-Rodr\\u00edguez\"},{\"authorId\":\"1412159037\",\"name\":\"Pilar Mart\\u00edn-Mart\\u00edn\"},{\"authorId\":\"1398470117\",\"name\":\"S. Maldonado-Basc\\u00f3n\"}],\"doi\":\"10.3390/s20102953\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"250cff3f869805e76bf0cda34406f5def042148c\",\"title\":\"Unsupervised Action Proposals Using Support Vector Classifiers for Online Video Processing\",\"url\":\"https://www.semanticscholar.org/paper/250cff3f869805e76bf0cda34406f5def042148c\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49420307\",\"name\":\"Y. Liu\"},{\"authorId\":\"1390925314\",\"name\":\"Yue Yao\"},{\"authorId\":\"1390878200\",\"name\":\"Zhengjie Wang\"},{\"authorId\":\"1390011966\",\"name\":\"J. Plested\"},{\"authorId\":\"27011207\",\"name\":\"T. Gedeon\"}],\"doi\":\"10.1109/IJCNN.2019.8852216\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dc225b4fcb30c5c0a62c58bd64a4abdac3388f52\",\"title\":\"Generalized Alignment for Multimodal Physiological Signal Learning\",\"url\":\"https://www.semanticscholar.org/paper/dc225b4fcb30c5c0a62c58bd64a4abdac3388f52\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":\"2009.10434\",\"authors\":[{\"authorId\":\"49687714\",\"name\":\"Haoyu Tang\"},{\"authorId\":\"2237811\",\"name\":\"Jihua Zhu\"},{\"authorId\":\"38813990\",\"name\":\"M. Liu\"},{\"authorId\":\"40465774\",\"name\":\"Z. Gao\"},{\"authorId\":\"46504200\",\"name\":\"Zhiyong Cheng\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d1d28e778c391d07a6c3e7a2e96312fdc53c0ae2\",\"title\":\"Frame-wise Cross-modal Match for Video Moment Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/d1d28e778c391d07a6c3e7a2e96312fdc53c0ae2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.11232\",\"authors\":[{\"authorId\":\"1432778730\",\"name\":\"Binjie Zhang\"},{\"authorId\":\"1940342\",\"name\":\"Y. Li\"},{\"authorId\":\"144204924\",\"name\":\"C. Yuan\"},{\"authorId\":\"50854337\",\"name\":\"D. Xu\"},{\"authorId\":\"2091174\",\"name\":\"Pin Jiang\"},{\"authorId\":\"1387190008\",\"name\":\"Ying Shan\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1e645df446ccdc985b85864ac0b91b053090c14d\",\"title\":\"A Simple Yet Effective Method for Video Temporal Grounding with Cross-Modality Attention\",\"url\":\"https://www.semanticscholar.org/paper/1e645df446ccdc985b85864ac0b91b053090c14d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47795983\",\"name\":\"Yu-Lan Yang\"},{\"authorId\":\"51484605\",\"name\":\"Z. Li\"},{\"authorId\":\"1519001806\",\"name\":\"Gangyan Zeng\"}],\"doi\":\"10.1109/ICCST50977.2020.00123\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"895fdebe3a2584fa87ee7da9eea47f131c09375f\",\"title\":\"A Survey of Temporal Activity Localization via Language in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/895fdebe3a2584fa87ee7da9eea47f131c09375f\",\"venue\":\"2020 International Conference on Culture-oriented Science & Technology (ICCST)\",\"year\":2020},{\"arxivId\":\"1812.00303\",\"authors\":[{\"authorId\":\"144282337\",\"name\":\"B. McIntosh\"},{\"authorId\":\"7839191\",\"name\":\"K. Duarte\"},{\"authorId\":\"2116440\",\"name\":\"Y. Rawat\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b181ae8ed315ceb8f03332ba02ef0849adbe5b4c\",\"title\":\"Multi-modal Capsule Routing for Actor and Action Video Segmentation Conditioned on Natural Language Queries\",\"url\":\"https://www.semanticscholar.org/paper/b181ae8ed315ceb8f03332ba02ef0849adbe5b4c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2008.13362\",\"authors\":[{\"authorId\":\"2532612\",\"name\":\"Mrigank Rochan\"},{\"authorId\":\"1491322959\",\"name\":\"Mahesh Kumar Krishna Reddy\"},{\"authorId\":null,\"name\":\"Yang Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8aa1bf7c6b1505538903c57472e5fa0ed45b303d\",\"title\":\"Sentence Guided Temporal Modulation for Dynamic Video Thumbnail Generation\",\"url\":\"https://www.semanticscholar.org/paper/8aa1bf7c6b1505538903c57472e5fa0ed45b303d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1904.03282\",\"authors\":[{\"authorId\":\"47733442\",\"name\":\"Niluthpol Chowdhury Mithun\"},{\"authorId\":\"49616225\",\"name\":\"Sujoy Paul\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":\"10.1109/CVPR.2019.01186\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ca4d965ab8fd07fd236a2ec5b5c7a520077a3085\",\"title\":\"Weakly Supervised Video Moment Retrieval From Text Queries\",\"url\":\"https://www.semanticscholar.org/paper/ca4d965ab8fd07fd236a2ec5b5c7a520077a3085\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121357290\",\"name\":\"Ruolin Wang\"},{\"authorId\":\"152641281\",\"name\":\"Y. Zhou\"}],\"doi\":\"10.1109/ICIP40778.2020.9190869\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4a343ca82464f8e11aa5626afc7474ab2286ed14\",\"title\":\"A Feature Pair Fusion And Hierarchical Learning Framework For Video Re-Localization\",\"url\":\"https://www.semanticscholar.org/paper/4a343ca82464f8e11aa5626afc7474ab2286ed14\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"1802.10250\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"1728712\",\"name\":\"Boyang Li\"},{\"authorId\":\"2018561\",\"name\":\"Vasili Ramanishka\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/WACV.2019.00048\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"99cdb10443a0543be3466c9231ff922bcc996843\",\"title\":\"Joint Event Detection and Description in Continuous Video Streams\",\"url\":\"https://www.semanticscholar.org/paper/99cdb10443a0543be3466c9231ff922bcc996843\",\"venue\":\"2019 IEEE Winter Applications of Computer Vision Workshops (WACVW)\",\"year\":2019},{\"arxivId\":\"1908.04052\",\"authors\":[{\"authorId\":\"152338671\",\"name\":\"Yiitan Yuan\"},{\"authorId\":\"152309767\",\"name\":\"L. Ma\"},{\"authorId\":\"145583986\",\"name\":\"Wenwu Zhu\"}],\"doi\":\"10.1145/3343031.3350985\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"745242c746b6f379048f6dbdfc009181d9027a60\",\"title\":\"Sentence Specified Dynamic Video Thumbnail Generation\",\"url\":\"https://www.semanticscholar.org/paper/745242c746b6f379048f6dbdfc009181d9027a60\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"2008.10238\",\"authors\":[{\"authorId\":\"103278467\",\"name\":\"Minuk Ma\"},{\"authorId\":\"30559382\",\"name\":\"S. Yoon\"},{\"authorId\":\"2447631\",\"name\":\"Junyeong Kim\"},{\"authorId\":\"1753686270\",\"name\":\"Young-Joon Lee\"},{\"authorId\":\"3315036\",\"name\":\"S. Kang\"},{\"authorId\":\"145954697\",\"name\":\"C. Yoo\"}],\"doi\":\"10.1007/978-3-030-58604-1_10\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"425278984b2be6b5412e264c7a200b797018ae8f\",\"title\":\"VLANet: Video-Language Alignment Network for Weakly-Supervised Video Moment Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/425278984b2be6b5412e264c7a200b797018ae8f\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1807.04821\",\"authors\":[{\"authorId\":\"3029956\",\"name\":\"J. Gao\"},{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1007/978-3-030-01216-8_5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a52d7c53bb0745994e476079bbdea8b8577582a3\",\"title\":\"CTAP: Complementary Temporal Action Proposal Generation\",\"url\":\"https://www.semanticscholar.org/paper/a52d7c53bb0745994e476079bbdea8b8577582a3\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"}],\"doi\":\"10.25781/KAUST-VR909\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b5c549fd9172f2d1be80cc77b0de9e90d3416463\",\"title\":\"Efficient Localization of Human Actions and Moments in Videos\",\"url\":\"https://www.semanticscholar.org/paper/b5c549fd9172f2d1be80cc77b0de9e90d3416463\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2010.06260\",\"authors\":[{\"authorId\":\"145112187\",\"name\":\"Cristian Rodriguez-Opazo\"},{\"authorId\":\"1389646918\",\"name\":\"Edison Marrese-Taylor\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"71200893\",\"name\":\"H. Li\"},{\"authorId\":\"143685465\",\"name\":\"S. Gould\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a7177ae93ed91f3bf34875205396ec97f0873bb7\",\"title\":\"DORi: Discovering Object Relationship for Moment Localization of a Natural-Language Query in Video\",\"url\":\"https://www.semanticscholar.org/paper/a7177ae93ed91f3bf34875205396ec97f0873bb7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.08257\",\"authors\":[{\"authorId\":\"51305348\",\"name\":\"Zhu Zhang\"},{\"authorId\":\"49290494\",\"name\":\"Zhijie Lin\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"1877867\",\"name\":\"J. Zhu\"},{\"authorId\":\"1996703\",\"name\":\"X. He\"}],\"doi\":\"10.1145/3394171.3413967\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"02e5188e19523140b82d05f00bee10933ccc3b50\",\"title\":\"Regularized Two-Branch Proposal Networks for Weakly-Supervised Moment Retrieval in Videos\",\"url\":\"https://www.semanticscholar.org/paper/02e5188e19523140b82d05f00bee10933ccc3b50\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1803.10906\",\"authors\":[{\"authorId\":\"3029956\",\"name\":\"J. Gao\"},{\"authorId\":\"40899706\",\"name\":\"Runzhou Ge\"},{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/CVPR.2018.00688\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f45c3a83e5c6276c6655c5df5833ab6b75e17bdf\",\"title\":\"Motion-Appearance Co-memory Networks for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f45c3a83e5c6276c6655c5df5833ab6b75e17bdf\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48805489\",\"name\":\"Z. Zhang\"},{\"authorId\":\"50144812\",\"name\":\"Z. Zhao\"},{\"authorId\":\"34064720\",\"name\":\"Zhijie Lin\"},{\"authorId\":\"1877867\",\"name\":\"J. Zhu\"},{\"authorId\":\"1996703\",\"name\":\"X. He\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"725989041b70ce21c5e20d90037691a59a483257\",\"title\":\"Counterfactual Contrastive Learning for Weakly-Supervised Vision-Language Grounding\",\"url\":\"https://www.semanticscholar.org/paper/725989041b70ce21c5e20d90037691a59a483257\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"1904.11574\",\"authors\":[{\"authorId\":\"46665218\",\"name\":\"Jie Lei\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/2020.acl-main.730\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb1b368ca847846774ee41af6da906ab77013313\",\"title\":\"TVQA+: Spatio-Temporal Grounding for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/eb1b368ca847846774ee41af6da906ab77013313\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153772546\",\"name\":\"K. Ning\"},{\"authorId\":\"3041937\",\"name\":\"Lingxi Xie\"},{\"authorId\":\"1521935491\",\"name\":\"Fei Wu\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.24963/ijcai.2020/132\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"d358f8939992a8c2c649338810aa5e66ed665568\",\"title\":\"Polar Relative Positional Encoding for Video-Language Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/d358f8939992a8c2c649338810aa5e66ed665568\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49336560\",\"name\":\"Weining Wang\"},{\"authorId\":\"144368926\",\"name\":\"Yan Huang\"},{\"authorId\":\"123865558\",\"name\":\"Liang Wang\"}],\"doi\":\"10.1109/CVPR.2019.00042\",\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"0fa68cde4db12779adacb70a24961cf09b1adf73\",\"title\":\"Language-Driven Temporal Activity Localization: A Semantic Matching Reinforcement Learning Model\",\"url\":\"https://www.semanticscholar.org/paper/0fa68cde4db12779adacb70a24961cf09b1adf73\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1802.06822\",\"authors\":[{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"},{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"},{\"authorId\":\"144983134\",\"name\":\"J. Chan\"},{\"authorId\":\"1789840\",\"name\":\"K. Miyazawa\"},{\"authorId\":\"145730148\",\"name\":\"Hassan Mansour\"},{\"authorId\":\"1690385\",\"name\":\"A. Vetro\"},{\"authorId\":\"1398090762\",\"name\":\"Xavier Gir\\u00f3-i-Nieto\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1007/978-3-030-01219-9_33\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b8b4a0bdfb561edaaed971f6e416c641b295376d\",\"title\":\"Online Detection of Action Start in Untrimmed, Streaming Videos\",\"url\":\"https://www.semanticscholar.org/paper/b8b4a0bdfb561edaaed971f6e416c641b295376d\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2007.02036\",\"authors\":[{\"authorId\":\"2447631\",\"name\":\"Junyeong Kim\"},{\"authorId\":\"103278467\",\"name\":\"Minuk Ma\"},{\"authorId\":\"48920375\",\"name\":\"T. Pham\"},{\"authorId\":\"97531942\",\"name\":\"Kyungsu Kim\"},{\"authorId\":\"145954697\",\"name\":\"C. Yoo\"}],\"doi\":\"10.1109/cvpr42600.2020.01012\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7fa5fdaacc87165a0281babd96949e8ec74d3a41\",\"title\":\"Modality Shifting Attention Network for Multi-Modal Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7fa5fdaacc87165a0281babd96949e8ec74d3a41\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2004.05573\",\"authors\":[{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"47824843\",\"name\":\"W. Wang\"},{\"authorId\":\"1630359492\",\"name\":\"Ludan Ruan\"},{\"authorId\":\"49539732\",\"name\":\"Linli Yao\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"78605f537f6c4a8c5206bdd4f57cea22d9750703\",\"title\":\"YouMakeup VQA Challenge: Towards Fine-grained Action Understanding in Domain-Specific Videos\",\"url\":\"https://www.semanticscholar.org/paper/78605f537f6c4a8c5206bdd4f57cea22d9750703\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1803.03879\",\"authors\":[{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"3029956\",\"name\":\"J. Gao\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/CVPR.2018.00425\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0f66f124bcfa4c3d9d0e54af0c1103f1219c1c8c\",\"title\":\"Knowledge Aided Consistency for Weakly Supervised Phrase Grounding\",\"url\":\"https://www.semanticscholar.org/paper/0f66f124bcfa4c3d9d0e54af0c1103f1219c1c8c\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2007.14164\",\"authors\":[{\"authorId\":\"39650418\",\"name\":\"S. Chen\"},{\"authorId\":\"119897463\",\"name\":\"Wenhao Jiang\"},{\"authorId\":\"1654091065\",\"name\":\"Wei Liu\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1007/978-3-030-58548-8_20\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5fb52197928290d3020b2256ccab22d5bf93c366\",\"title\":\"Learning Modality Interaction for Temporal Sentence Localization and Event Captioning in Videos\",\"url\":\"https://www.semanticscholar.org/paper/5fb52197928290d3020b2256ccab22d5bf93c366\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2003.11618\",\"authors\":[{\"authorId\":\"48211835\",\"name\":\"J. Liu\"},{\"authorId\":\"2928777\",\"name\":\"Wenhu Chen\"},{\"authorId\":\"5524736\",\"name\":\"Y. Cheng\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"35729970\",\"name\":\"Yiming Yang\"},{\"authorId\":\"46700348\",\"name\":\"Jing-jing Liu\"}],\"doi\":\"10.1109/cvpr42600.2020.01091\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"704ec27b8399df574a96da338c428a923509385e\",\"title\":\"Violin: A Large-Scale Dataset for Video-and-Language Inference\",\"url\":\"https://www.semanticscholar.org/paper/704ec27b8399df574a96da338c428a923509385e\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1707.04818\",\"authors\":[{\"authorId\":\"3029956\",\"name\":\"J. Gao\"},{\"authorId\":\"3469030\",\"name\":\"Zhenheng Yang\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.5244/C.31.92\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7ace4330a28ef74f489e581b62cfe21cc9bbc986\",\"title\":\"RED: Reinforced Encoder-Decoder Networks for Action Anticipation\",\"url\":\"https://www.semanticscholar.org/paper/7ace4330a28ef74f489e581b62cfe21cc9bbc986\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3178508\",\"name\":\"Songyang Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"644f6f129debd38fa23da7be411ad981c0d3e534\",\"title\":\"Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/644f6f129debd38fa23da7be411ad981c0d3e534\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2002.00842\",\"authors\":[{\"authorId\":\"3178508\",\"name\":\"Songyang Zhang\"},{\"authorId\":\"2941457\",\"name\":\"Tolga Aktas\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"42884b710491ee66fa4ccea6ffbe40f924a55432\",\"title\":\"Mi YouTube es Su YouTube? Analyzing the Cultures using YouTube Thumbnails of Popular Videos\",\"url\":\"https://www.semanticscholar.org/paper/42884b710491ee66fa4ccea6ffbe40f924a55432\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1906.02497\",\"authors\":[{\"authorId\":\"1764508\",\"name\":\"Z. Zhang\"},{\"authorId\":\"34064720\",\"name\":\"Zhijie Lin\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"123034558\",\"name\":\"Z. Xiao\"}],\"doi\":\"10.1145/3331184.3331235\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"fb53803897d3df3e1f43a43a753ee88a64517c47\",\"title\":\"Cross-Modal Interaction Networks for Query-Based Moment Retrieval in Videos\",\"url\":\"https://www.semanticscholar.org/paper/fb53803897d3df3e1f43a43a753ee88a64517c47\",\"venue\":\"SIGIR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39650418\",\"name\":\"S. Chen\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1609/AAAI.V33I01.33018199\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8548d5a93869a5a4c808f5e81742f59f848c718c\",\"title\":\"Semantic Proposal for Activity Localization in Videos via Sentence Query\",\"url\":\"https://www.semanticscholar.org/paper/8548d5a93869a5a4c808f5e81742f59f848c718c\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47243105\",\"name\":\"P. Zhang\"},{\"authorId\":\"9308544\",\"name\":\"Chunmiao Yuan\"},{\"authorId\":\"3386073\",\"name\":\"Kunliang Liu\"},{\"authorId\":\"46676502\",\"name\":\"Y. Sun\"},{\"authorId\":\"2607232\",\"name\":\"Jiayu Liang\"},{\"authorId\":\"151470674\",\"name\":\"Guanghao Jin\"},{\"authorId\":\"46584793\",\"name\":\"J. Wang\"}],\"doi\":\"10.1007/978-3-030-35231-8_38\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"801a3ada495732f95b34bce187de9dd41a40d10d\",\"title\":\"Fast Video Clip Retrieval Method via Language Query\",\"url\":\"https://www.semanticscholar.org/paper/801a3ada495732f95b34bce187de9dd41a40d10d\",\"venue\":\"ADMA\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144230956\",\"name\":\"Bo Huang\"},{\"authorId\":\"144645740\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1736727\",\"name\":\"Kai Yu\"}],\"doi\":\"10.1145/3301506.3301538\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"befc8b8ee539df950bbbab06d09c89d5b83eaa34\",\"title\":\"MLN: Moment localization Network and Samples Selection for Moment Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/befc8b8ee539df950bbbab06d09c89d5b83eaa34\",\"venue\":\"ICVIP\",\"year\":2018},{\"arxivId\":\"1909.05010\",\"authors\":[{\"authorId\":\"46584062\",\"name\":\"Junling Wang\"},{\"authorId\":\"152309767\",\"name\":\"L. Ma\"},{\"authorId\":\"119897463\",\"name\":\"Wenhao Jiang\"}],\"doi\":\"10.1609/AAAI.V34I07.6897\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"aa6c925c5f2fe61cdf8e09dd4ecbf1e7d220eac0\",\"title\":\"Temporally Grounding Language Queries in Videos by Contextual Boundary-aware Prediction\",\"url\":\"https://www.semanticscholar.org/paper/aa6c925c5f2fe61cdf8e09dd4ecbf1e7d220eac0\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2004.02707\",\"authors\":[{\"authorId\":\"1612421029\",\"name\":\"Yicong Hong\"},{\"authorId\":\"145112187\",\"name\":\"Cristian Rodriguez-Opazo\"},{\"authorId\":\"1509240145\",\"name\":\"Qi Wu\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.271\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c71cf890f1e6169c28407a985dcfd2b0b156d9e2\",\"title\":\"Sub-Instruction Aware Vision-and-Language Navigation\",\"url\":\"https://www.semanticscholar.org/paper/c71cf890f1e6169c28407a985dcfd2b0b156d9e2\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2011.10830\",\"authors\":[{\"authorId\":\"97375393\",\"name\":\"Mengmeng Xu\"},{\"authorId\":\"1397974082\",\"name\":\"Juan-Manuel Perez-Rua\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"145944235\",\"name\":\"B. Mart\\u00ednez\"},{\"authorId\":\"2171228\",\"name\":\"Xiatian Zhu\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"145406420\",\"name\":\"Tao Xiang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"cdc28eb98cd4e5fa28811f4ea6dbe7c64d5fcffe\",\"title\":\"Boundary-sensitive Pre-training for Temporal Localization in Videos\",\"url\":\"https://www.semanticscholar.org/paper/cdc28eb98cd4e5fa28811f4ea6dbe7c64d5fcffe\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145479818\",\"name\":\"D. Cao\"},{\"authorId\":\"1993664989\",\"name\":\"Yawen Zeng\"},{\"authorId\":\"38813990\",\"name\":\"M. Liu\"},{\"authorId\":\"7792071\",\"name\":\"X. He\"},{\"authorId\":\"5332711\",\"name\":\"Meng Wang\"},{\"authorId\":\"145458349\",\"name\":\"Z. Qin\"}],\"doi\":\"10.1145/3394171.3413840\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3e7c91fb6f79dce1ab3e4be0efc97b8592ce7d96\",\"title\":\"STRONG: Spatio-Temporal Reinforcement Learning for Cross-Modal Video Moment Localization\",\"url\":\"https://www.semanticscholar.org/paper/3e7c91fb6f79dce1ab3e4be0efc97b8592ce7d96\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2007565041\",\"name\":\"Vighnesh Reddy Konda\"},{\"authorId\":\"2007593167\",\"name\":\"Mayur Warialani\"},{\"authorId\":\"2007595554\",\"name\":\"Rakesh Prasanth Achari\"},{\"authorId\":\"2006916144\",\"name\":\"Varad Bhatnagar\"},{\"authorId\":\"2006759688\",\"name\":\"Jayaprakash Akula\"},{\"authorId\":\"1409054881\",\"name\":\"P. Jyothi\"},{\"authorId\":\"1859063226\",\"name\":\"Ganesh Ramakrishnan\"},{\"authorId\":\"2561045\",\"name\":\"Gholamreza Haffari\"},{\"authorId\":\"48101909\",\"name\":\"Pankaj Singh\"}],\"doi\":\"10.21437/interspeech.2020-3157\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"8582e5f71abb5b99c2c71e706ae3b50386286b6f\",\"title\":\"Caption Alignment for Low Resource Audio-Visual Data\",\"url\":\"https://www.semanticscholar.org/paper/8582e5f71abb5b99c2c71e706ae3b50386286b6f\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":\"2012.02646\",\"authors\":[{\"authorId\":\"1992634637\",\"name\":\"Songyang Zhang\"},{\"authorId\":\"2484788\",\"name\":\"Houwen Peng\"},{\"authorId\":\"2027130177\",\"name\":\"J. Fu\"},{\"authorId\":\"38534822\",\"name\":\"Y. Lu\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"261582574b9e039be1518bc7c8e405a4af75a41a\",\"title\":\"Multi-Scale 2D Temporal Adjacent Networks for Moment Localization with Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/261582574b9e039be1518bc7c8e405a4af75a41a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.01403\",\"authors\":[{\"authorId\":\"98579574\",\"name\":\"Daizong Liu\"},{\"authorId\":\"51912474\",\"name\":\"Xiaoye Qu\"},{\"authorId\":\"4029028\",\"name\":\"Xiao-Yang Liu\"},{\"authorId\":\"40240283\",\"name\":\"J. Dong\"},{\"authorId\":\"145232778\",\"name\":\"Pan Zhou\"},{\"authorId\":\"2956815\",\"name\":\"Zichuan Xu\"}],\"doi\":\"10.1145/3394171.3414026\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2b632209923bfe3452ac19f23b46c70455fae465\",\"title\":\"Jointly Cross- and Self-Modal Graph Attention Network for Query-Based Moment Localization\",\"url\":\"https://www.semanticscholar.org/paper/2b632209923bfe3452ac19f23b46c70455fae465\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1737799609\",\"name\":\"Tai-Te Chu\"},{\"authorId\":\"49420869\",\"name\":\"Yiting Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bc8a1d9bc331edd01228294b0e46a5ff2e190625\",\"title\":\"NLP301 at the NTCIR-15 Micro-activity Retrieval Task: Incorporating Region of Interest Features into Supervised Encoder\",\"url\":\"https://www.semanticscholar.org/paper/bc8a1d9bc331edd01228294b0e46a5ff2e190625\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"},{\"authorId\":\"48481929\",\"name\":\"Yi-jun Song\"},{\"authorId\":\"47891191\",\"name\":\"Jun Yu\"},{\"authorId\":\"48957872\",\"name\":\"Meng Wang\"},{\"authorId\":\"153159021\",\"name\":\"Qingming Huang\"}],\"doi\":\"10.1007/s11063-020-10205-y\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6c1d607b58d31c582bee0cc78017909a1eed45c9\",\"title\":\"Intra- and Inter-modal Multilinear Pooling with Multitask Learning for Video Grounding\",\"url\":\"https://www.semanticscholar.org/paper/6c1d607b58d31c582bee0cc78017909a1eed45c9\",\"venue\":\"Neural Processing Letters\",\"year\":2020},{\"arxivId\":\"1708.01641\",\"authors\":[{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"39231399\",\"name\":\"O. Wang\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"145160921\",\"name\":\"Bryan C. Russell\"}],\"doi\":\"10.1109/ICCV.2017.618\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ee909ad489244016cf301bb7d7d8eeea423dbf35\",\"title\":\"Localizing Moments in Video with Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/ee909ad489244016cf301bb7d7d8eeea423dbf35\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145583985\",\"name\":\"Wenwu Zhu\"},{\"authorId\":null,\"name\":\"Xin Wang\"},{\"authorId\":\"48385803\",\"name\":\"W. Gao\"}],\"doi\":\"10.1109/TMM.2020.2969791\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a94ac484b3cc19cbf03bdbac0c727579a09fc3b9\",\"title\":\"Multimedia Intelligence: When Multimedia Meets Artificial Intelligence\",\"url\":\"https://www.semanticscholar.org/paper/a94ac484b3cc19cbf03bdbac0c727579a09fc3b9\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"1812.03849\",\"authors\":[{\"authorId\":\"50997773\",\"name\":\"Xuguang Duan\"},{\"authorId\":\"2978255\",\"name\":\"Wen-bing Huang\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"1688516\",\"name\":\"Jingdong Wang\"},{\"authorId\":\"145583986\",\"name\":\"Wenwu Zhu\"},{\"authorId\":\"50882910\",\"name\":\"Junzhou Huang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8735ac2324b5aeaa3a8418af97eb82e9aa1910cb\",\"title\":\"Weakly Supervised Dense Event Captioning in Videos\",\"url\":\"https://www.semanticscholar.org/paper/8735ac2324b5aeaa3a8418af97eb82e9aa1910cb\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48352212\",\"name\":\"Aming Wu\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"}],\"doi\":\"10.24963/ijcai.2018/143\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e2e5cef45c60c52fb0d0415cca6cbf35beab3873\",\"title\":\"Multi-modal Circulant Fusion for Video-to-Language and Backward\",\"url\":\"https://www.semanticscholar.org/paper/e2e5cef45c60c52fb0d0415cca6cbf35beab3873\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":\"2003.07048\",\"authors\":[{\"authorId\":\"2250163\",\"name\":\"Yijun Song\"},{\"authorId\":\"46584062\",\"name\":\"Junling Wang\"},{\"authorId\":\"152309770\",\"name\":\"Lin Ma\"},{\"authorId\":\"1564034697\",\"name\":\"Zhou Yu\"},{\"authorId\":null,\"name\":\"Jun Yu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e655c524630b0fb37f11b01468dab5477c58db0f\",\"title\":\"Weakly-Supervised Multi-Level Attentional Reconstruction Network for Grounding Textual Queries in Videos\",\"url\":\"https://www.semanticscholar.org/paper/e655c524630b0fb37f11b01468dab5477c58db0f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.03545\",\"authors\":[{\"authorId\":\"147992804\",\"name\":\"Runhao Zeng\"},{\"authorId\":\"2342663\",\"name\":\"H. Xu\"},{\"authorId\":\"51026885\",\"name\":\"W. Huang\"},{\"authorId\":\"4965440\",\"name\":\"Peihao Chen\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"}],\"doi\":\"10.1109/cvpr42600.2020.01030\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"355403d7ce4b625307fd3ebb2beea269ecc15213\",\"title\":\"Dense Regression Network for Video Grounding\",\"url\":\"https://www.semanticscholar.org/paper/355403d7ce4b625307fd3ebb2beea269ecc15213\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1904.09936\",\"authors\":[{\"authorId\":\"29132542\",\"name\":\"Meera Hahn\"},{\"authorId\":\"2293919\",\"name\":\"Asim Kadav\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"},{\"authorId\":\"1775043\",\"name\":\"H. Graf\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1378f07a9229f09c7bf6c3be6ade4765403c0ca6\",\"title\":\"Tripping through time: Efficient Localization of Activities in Videos\",\"url\":\"https://www.semanticscholar.org/paper/1378f07a9229f09c7bf6c3be6ade4765403c0ca6\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"73441526\",\"name\":\"R. Tan\"},{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"23fb5231bb8629bec8b7bfc15cccefca2cbd1754\",\"title\":\"wMAN: Weakly-supervised Moment Alignment Network for Text-based Video Segment Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/23fb5231bb8629bec8b7bfc15cccefca2cbd1754\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1909.13784\",\"authors\":[{\"authorId\":\"73441526\",\"name\":\"R. Tan\"},{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3c0d69d243c08eaa1d9030c95541a2ae23e8eb85\",\"title\":\"LoGAN: Latent Graph Co-Attention Network for Weakly-Supervised Video Moment Retrieval.\",\"url\":\"https://www.semanticscholar.org/paper/3c0d69d243c08eaa1d9030c95541a2ae23e8eb85\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1904.02755\",\"authors\":[{\"authorId\":\"3288111\",\"name\":\"S. Ghosh\"},{\"authorId\":\"50714560\",\"name\":\"A. Agarwal\"},{\"authorId\":\"27456119\",\"name\":\"Zarana Parekh\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.18653/v1/N19-1198\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ddf69a6ef015a1b0668ca48a486c4cc7e22a7d9c\",\"title\":\"ExCL: Extractive Clip Localization Using Natural Language Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/ddf69a6ef015a1b0668ca48a486c4cc7e22a7d9c\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":\"1908.07236\",\"authors\":[{\"authorId\":\"145112187\",\"name\":\"Cristian Rodriguez-Opazo\"},{\"authorId\":\"1389646918\",\"name\":\"Edison Marrese-Taylor\"},{\"authorId\":\"9120887\",\"name\":\"F. Saleh\"},{\"authorId\":\"40124570\",\"name\":\"Hongdong Li\"},{\"authorId\":\"47873182\",\"name\":\"S. Gould\"}],\"doi\":\"10.1109/WACV45572.2020.9093328\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"03df26255781ebb71d9430e1b2aaabf8e1af9990\",\"title\":\"Proposal-free Temporal Moment Localization of a Natural-Language Query in Video using Guided Attention\",\"url\":\"https://www.semanticscholar.org/paper/03df26255781ebb71d9430e1b2aaabf8e1af9990\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1909.09944\",\"authors\":[{\"authorId\":\"49172303\",\"name\":\"T. Rahman\"},{\"authorId\":\"3443241\",\"name\":\"Bicheng Xu\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":\"10.1109/ICCV.2019.00900\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7a2de516a4e628a30036193d71faac7240d553ef\",\"title\":\"Watch, Listen and Tell: Multi-Modal Weakly Supervised Dense Event Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7a2de516a4e628a30036193d71faac7240d553ef\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7499906\",\"name\":\"Xiaomeng Song\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"}],\"doi\":\"10.1007/978-3-030-00767-6_32\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8435aa8c48dd41e0341ce7bc3b5966c4f28dc11d\",\"title\":\"VAL: Visual-Attention Action Localizer\",\"url\":\"https://www.semanticscholar.org/paper/8435aa8c48dd41e0341ce7bc3b5966c4f28dc11d\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":\"1804.00100\",\"authors\":[{\"authorId\":null,\"name\":\"Jingwen Wang\"},{\"authorId\":\"2093119\",\"name\":\"W. Jiang\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"144391096\",\"name\":\"Yong Xu\"}],\"doi\":\"10.1109/CVPR.2018.00751\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bb4e2d6a6e3e1067f21a4cad087fc91c671e495d\",\"title\":\"Bidirectional Attentive Fusion with Context Gating for Dense Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/bb4e2d6a6e3e1067f21a4cad087fc91c671e495d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"93353108\",\"name\":\"Cheng Chen\"},{\"authorId\":\"1649999106\",\"name\":\"Xiaodong Gu\"}],\"doi\":\"10.1007/978-3-030-64221-1_11\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c6b6e4860665d9185dfd80af63d93334582c56be\",\"title\":\"Semantic Modulation Based Residual Network for Temporal Language Queries Grounding in Video\",\"url\":\"https://www.semanticscholar.org/paper/c6b6e4860665d9185dfd80af63d93334582c56be\",\"venue\":\"ISNN\",\"year\":2020},{\"arxivId\":\"2010.07999\",\"authors\":[{\"authorId\":\"46665218\",\"name\":\"Jie Lei\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"143977266\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.706\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9f2a7a912624d850cf9e0587263b4fcd88d44f18\",\"title\":\"What is More Likely to Happen Next? Video-and-Language Future Event Prediction\",\"url\":\"https://www.semanticscholar.org/paper/9f2a7a912624d850cf9e0587263b4fcd88d44f18\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145488619\",\"name\":\"M. Liu\"},{\"authorId\":null,\"name\":\"Xiang Wang\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"},{\"authorId\":\"1748939\",\"name\":\"B. Chen\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1145/3240508.3240549\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"175864710def9b3e8b42e4613856d0b840c37615\",\"title\":\"Cross-modal Moment Localization in Videos\",\"url\":\"https://www.semanticscholar.org/paper/175864710def9b3e8b42e4613856d0b840c37615\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47740660\",\"name\":\"Jingyuan Chen\"},{\"authorId\":\"3179887\",\"name\":\"Xinpeng Chen\"},{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"2750647\",\"name\":\"Zequn Jie\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.18653/v1/D18-1015\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"452aca244ef62a533d8b46a54c6212fe9fa3ce9a\",\"title\":\"Temporally Grounding Natural Sentence in Video\",\"url\":\"https://www.semanticscholar.org/paper/452aca244ef62a533d8b46a54c6212fe9fa3ce9a\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145479818\",\"name\":\"D. Cao\"},{\"authorId\":\"1993664989\",\"name\":\"Yawen Zeng\"},{\"authorId\":\"7621447\",\"name\":\"X. Wei\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":\"48043335\",\"name\":\"R. Hong\"},{\"authorId\":\"145458349\",\"name\":\"Z. Qin\"}],\"doi\":\"10.1145/3394171.3413841\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"7928ff4b66e866e7052915cd34861f1db2288cc4\",\"title\":\"Adversarial Video Moment Retrieval by Jointly Modeling Ranking and Localization\",\"url\":\"https://www.semanticscholar.org/paper/7928ff4b66e866e7052915cd34861f1db2288cc4\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d2925b1a75c72728d2d90157c1d1057cbc5da8b9\",\"title\":\"Structured Procedural Knowledge Extraction from Cooking Videos\",\"url\":\"https://www.semanticscholar.org/paper/d2925b1a75c72728d2d90157c1d1057cbc5da8b9\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48016309\",\"name\":\"H. Wang\"},{\"authorId\":\"145102437\",\"name\":\"Cheng Deng\"},{\"authorId\":\"3063894\",\"name\":\"Junchi Yan\"},{\"authorId\":\"145047838\",\"name\":\"Dacheng Tao\"}],\"doi\":\"10.1109/ICCV.2019.00404\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"05fc2ab1eb39f8f4d0f30dda1a2838c8125bff1b\",\"title\":\"Asymmetric Cross-Guided Attention Network for Actor and Action Video Segmentation From Natural Language Query\",\"url\":\"https://www.semanticscholar.org/paper/05fc2ab1eb39f8f4d0f30dda1a2838c8125bff1b\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2001.06680\",\"authors\":[{\"authorId\":\"71170299\",\"name\":\"J. Wu\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"101219260\",\"name\":\"Si Liu\"},{\"authorId\":\"49478124\",\"name\":\"L. Lin\"}],\"doi\":\"10.1609/AAAI.V34I07.6924\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b8e744b1f33b1f3f53fcffb1dafd592e992694ff\",\"title\":\"Tree-Structured Policy based Progressive Reinforcement Learning for Temporally Language Grounding in Video\",\"url\":\"https://www.semanticscholar.org/paper/b8e744b1f33b1f3f53fcffb1dafd592e992694ff\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143688987\",\"name\":\"X. Yan\"},{\"authorId\":\"46461307\",\"name\":\"S. Z. Gilani\"},{\"authorId\":\"3446916\",\"name\":\"Mingtao Feng\"},{\"authorId\":\"2121454\",\"name\":\"Libao Zhang\"},{\"authorId\":\"9493788\",\"name\":\"Han-lin Qin\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"}],\"doi\":\"10.3390/s20236941\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"61de5563ca445cab30b9d4ae2a7112b730c269ce\",\"title\":\"Self-Supervised Learning to Detect Key Frames in Videos\",\"url\":\"https://www.semanticscholar.org/paper/61de5563ca445cab30b9d4ae2a7112b730c269ce\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1752810295\",\"name\":\"Tianyu Li\"},{\"authorId\":\"70435288\",\"name\":\"Xinxiao Wu\"}],\"doi\":\"10.1007/978-3-030-60636-7_12\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"348d92b6b491fdeb641ca40d89ab56782825a6e1\",\"title\":\"Hierarchical Matching and Reasoning for Action Localization via Language Query\",\"url\":\"https://www.semanticscholar.org/paper/348d92b6b491fdeb641ca40d89ab56782825a6e1\",\"venue\":\"PRCV\",\"year\":2020},{\"arxivId\":\"2004.13931\",\"authors\":[{\"authorId\":\"153504695\",\"name\":\"Hao Zhang\"},{\"authorId\":\"1735962\",\"name\":\"Aixin Sun\"},{\"authorId\":\"1492128584\",\"name\":\"Wei Jing\"},{\"authorId\":\"10638646\",\"name\":\"Joey Tianyi Zhou\"}],\"doi\":\"10.18653/v1/2020.acl-main.585\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5a975dcd3dba2a11830e5595d4c4659441cb6836\",\"title\":\"Span-based Localizing Network for Natural Language Video Localization\",\"url\":\"https://www.semanticscholar.org/paper/5a975dcd3dba2a11830e5595d4c4659441cb6836\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"1912.03590\",\"authors\":[{\"authorId\":\"3178508\",\"name\":\"Songyang Zhang\"},{\"authorId\":\"2484788\",\"name\":\"Houwen Peng\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1609/AAAI.V34I07.6984\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cef4a58c08816c3d3bd56826a418508720d4b20d\",\"title\":\"Learning 2D Temporal Adjacent Networks for Moment Localization with Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/cef4a58c08816c3d3bd56826a418508720d4b20d\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2008.08977\",\"authors\":[{\"authorId\":\"152641281\",\"name\":\"Y. Zhou\"},{\"authorId\":\"7271879\",\"name\":\"M. Wang\"},{\"authorId\":\"121357290\",\"name\":\"Ruolin Wang\"},{\"authorId\":\"19216752\",\"name\":\"Shuwei Huo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"22dfa9f5552f3cf57688e41e118965e11c30b28b\",\"title\":\"Generating Adjacency Matrix for Video-Query based Video Moment Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/22dfa9f5552f3cf57688e41e118965e11c30b28b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"}],\"doi\":\"10.7916/D8-SRKZ-T696\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3ea5b4e02a448174cbc6872eaec27695b04e9b87\",\"title\":\"Deep Learning for Action Understanding in Video\",\"url\":\"https://www.semanticscholar.org/paper/3ea5b4e02a448174cbc6872eaec27695b04e9b87\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"BiGRU BiGRU\"},{\"authorId\":null,\"name\":\"BiGRU\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"dd8a531ddff2ba788d02555af04632c46f31ecf0\",\"title\":\"Multi-Stage Cross-modal Interaction Module d ) Moment Retrieval Module q \\\" q # q $ q ) Query\",\"url\":\"https://www.semanticscholar.org/paper/dd8a531ddff2ba788d02555af04632c46f31ecf0\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49290494\",\"name\":\"Zhijie Lin\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"1742291\",\"name\":\"Zixing Zhang\"},{\"authorId\":\"48805561\",\"name\":\"Zijian Zhang\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"}],\"doi\":\"10.1109/TIP.2020.2965987\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5a68ef4d0c1a814dd0920f6824aaad8e15339f66\",\"title\":\"Moment Retrieval via Cross-Modal Interaction Networks With Query Reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/5a68ef4d0c1a814dd0920f6824aaad8e15339f66\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153228843\",\"name\":\"Chujie Lu\"},{\"authorId\":\"143891667\",\"name\":\"Long Chen\"},{\"authorId\":\"71208047\",\"name\":\"C. Tan\"},{\"authorId\":\"47056890\",\"name\":\"Xiao-Lin Li\"},{\"authorId\":\"1384523745\",\"name\":\"Jun Xiao\"}],\"doi\":\"10.18653/v1/D19-1518\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"872091517b0bfad0e9bc1826d4668022d1d57953\",\"title\":\"DEBUG: A Dense Bottom-Up Grounding Approach for Natural Language Video Localization\",\"url\":\"https://www.semanticscholar.org/paper/872091517b0bfad0e9bc1826d4668022d1d57953\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2862582\",\"name\":\"Peratham Wiriyathammabhum\"},{\"authorId\":null,\"name\":\"Abhinav Shrivastava\"},{\"authorId\":\"2852035\",\"name\":\"V. Morariu\"},{\"authorId\":\"145855898\",\"name\":\"L. Davis\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ef6dbe27031265a4663721883008f4c3e6a89c4e\",\"title\":\"Supplementary Material : Referring to Object in Video using Spatio-Temporal Identifying Description\",\"url\":\"https://www.semanticscholar.org/paper/ef6dbe27031265a4663721883008f4c3e6a89c4e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1809.01337\",\"authors\":[{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"39231399\",\"name\":\"O. Wang\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"145160921\",\"name\":\"Bryan C. Russell\"}],\"doi\":\"10.18653/v1/D18-1168\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0b1ff82db09672656157874718860bee942483cf\",\"title\":\"Localizing Moments in Video with Temporal Language\",\"url\":\"https://www.semanticscholar.org/paper/0b1ff82db09672656157874718860bee942483cf\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39650418\",\"name\":\"S. Chen\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.24963/ijcai.2019/877\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eeca19117a8a733aae6fb4a91c51d1c1dc03eb7f\",\"title\":\"Deep Learning for Video Captioning: A Review\",\"url\":\"https://www.semanticscholar.org/paper/eeca19117a8a733aae6fb4a91c51d1c1dc03eb7f\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"1912.02256\",\"authors\":[{\"authorId\":\"143935879\",\"name\":\"Jonathan C. Stroud\"},{\"authorId\":\"32349340\",\"name\":\"Ryan McCaffrey\"},{\"authorId\":\"145557251\",\"name\":\"R. Mihalcea\"},{\"authorId\":\"145820819\",\"name\":\"Jun Deng\"},{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4979560dcff028a66ee44ce285c5bb1e22e1dc24\",\"title\":\"Compositional Temporal Visual Grounding of Natural Language Event Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/4979560dcff028a66ee44ce285c5bb1e22e1dc24\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2011.09046\",\"authors\":[{\"authorId\":\"1490732820\",\"name\":\"Bowen Zhang\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"2119006\",\"name\":\"Joonseok Lee\"},{\"authorId\":\"145327825\",\"name\":\"Mingde Zhao\"},{\"authorId\":\"40600020\",\"name\":\"Sheide Chammas\"},{\"authorId\":\"20048351\",\"name\":\"Vihan Jain\"},{\"authorId\":\"2042413\",\"name\":\"E. Ie\"},{\"authorId\":\"39543696\",\"name\":\"Fei Sha\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fe21d30afa60f8ab72da309ca0a80eee1ac07a66\",\"title\":\"A Hierarchical Multi-Modal Encoder for Moment Localization in Video Corpus\",\"url\":\"https://www.semanticscholar.org/paper/fe21d30afa60f8ab72da309ca0a80eee1ac07a66\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.07517\",\"authors\":[{\"authorId\":\"49606678\",\"name\":\"Jianan Wang\"},{\"authorId\":\"49730189\",\"name\":\"Boyang Li\"},{\"authorId\":\"46515715\",\"name\":\"Xiangyu Fan\"},{\"authorId\":\"1845592115\",\"name\":\"J. Lin\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5f5cbd60f07a19afc3566376e404a490865e5def\",\"title\":\"Data-efficient Alignment of Multimodal Sequences by Aligning Gradient Updates and Internal Feature Distributions\",\"url\":\"https://www.semanticscholar.org/paper/5f5cbd60f07a19afc3566376e404a490865e5def\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"dd7062e6f84750688fa96143209efc801e91f9bd\",\"title\":\"Visual Understanding through Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/dd7062e6f84750688fa96143209efc801e91f9bd\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2008.06941\",\"authors\":[{\"authorId\":\"47294375\",\"name\":\"Zhu Zhang\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"49290494\",\"name\":\"Zhijie Lin\"},{\"authorId\":\"2422046\",\"name\":\"Baoxing Huai\"},{\"authorId\":\"145078771\",\"name\":\"J. Yuan\"}],\"doi\":\"10.24963/ijcai.2020/149\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2086bd08d3921bc1e83fdad306ec0c5ac3b43428\",\"title\":\"Object-Aware Multi-Branch Relation Networks for Spatio-Temporal Video Grounding\",\"url\":\"https://www.semanticscholar.org/paper/2086bd08d3921bc1e83fdad306ec0c5ac3b43428\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":\"1811.08925\",\"authors\":[{\"authorId\":\"40899706\",\"name\":\"Runzhou Ge\"},{\"authorId\":\"3029956\",\"name\":\"J. Gao\"},{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/WACV.2019.00032\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"1d4dcd7ed33666e05e28b18f86a693264783749c\",\"title\":\"MAC: Mining Activity Concepts for Language-Based Temporal Localization\",\"url\":\"https://www.semanticscholar.org/paper/1d4dcd7ed33666e05e28b18f86a693264783749c\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390538450\",\"name\":\"Xun Yang\"},{\"authorId\":\"49544292\",\"name\":\"Xueliang Liu\"},{\"authorId\":\"2980051\",\"name\":\"Meng Jian\"},{\"authorId\":\"1993659018\",\"name\":\"Xinjian Gao\"},{\"authorId\":\"152808542\",\"name\":\"Meng Wang\"}],\"doi\":\"10.1145/3394171.3413610\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b839e6b1f65672d154feb6f6668d64a2333c71ee\",\"title\":\"Weakly-Supervised Video Object Grounding by Exploring Spatio-Temporal Contexts\",\"url\":\"https://www.semanticscholar.org/paper/b839e6b1f65672d154feb6f6668d64a2333c71ee\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144677557\",\"name\":\"C. Li\"},{\"authorId\":\"47827559\",\"name\":\"Yuming Zhao\"},{\"authorId\":\"151474865\",\"name\":\"S. Peng\"},{\"authorId\":\"73708274\",\"name\":\"J. Chen\"}],\"doi\":\"10.1109/ICIP.2019.8802929\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"c943d780edef5c07526e745ac678bfcea79b7bfb\",\"title\":\"Bidirectional Single-Stream Temporal Sentence Query Localization in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/c943d780edef5c07526e745ac678bfcea79b7bfb\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"2011.00786\",\"authors\":[{\"authorId\":\"152905588\",\"name\":\"Jianhua Yang\"},{\"authorId\":\"144368930\",\"name\":\"Yan Huang\"},{\"authorId\":\"2004516791\",\"name\":\"Kai Niu\"},{\"authorId\":\"46953683\",\"name\":\"Zhanyu Ma\"},{\"authorId\":\"123865558\",\"name\":\"Liang Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"57177ff1c7cac4bd05597fc19e683c92ed751e9b\",\"title\":\"Actor and Action Modular Network for Text-based Video Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/57177ff1c7cac4bd05597fc19e683c92ed751e9b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"90191889\",\"name\":\"A. Ghodrati\"},{\"authorId\":\"3245057\",\"name\":\"Zhenyang Li\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"27280d900be88e6b613bc1da4be386bb8b2b1490\",\"title\":\"UvA-DARE ( Digital Academic Repository ) Actor and Action Video Segmentation From a\",\"url\":\"https://www.semanticscholar.org/paper/27280d900be88e6b613bc1da4be386bb8b2b1490\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30793303\",\"name\":\"Amirhoshang Hoseinpour Dehkordi\"},{\"authorId\":\"153235768\",\"name\":\"M. Alizadeh\"},{\"authorId\":\"2005221955\",\"name\":\"Ali Movaghar\"}],\"doi\":\"10.36227/techrxiv.12928544.v1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b678835c5de86ebe2031da902957aead8de931aa\",\"title\":\"Linear Temporal Public Announcement Logic: a new perspective for reasoning the knowledge of multi-classifiers\",\"url\":\"https://www.semanticscholar.org/paper/b678835c5de86ebe2031da902957aead8de931aa\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1423743315\",\"name\":\"Theodoros Georgiou\"},{\"authorId\":\"3546791\",\"name\":\"Y. Liu\"},{\"authorId\":\"47482437\",\"name\":\"W. Chen\"},{\"authorId\":\"1731570\",\"name\":\"M. Lew\"}],\"doi\":\"10.1007/s13735-019-00183-w\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"763495e4ce53c989bf7c2910ae8cb51e4469e195\",\"title\":\"A survey of traditional and deep learning-based feature descriptors for high dimensional data in computer vision\",\"url\":\"https://www.semanticscholar.org/paper/763495e4ce53c989bf7c2910ae8cb51e4469e195\",\"venue\":\"International Journal of Multimedia Information Retrieval\",\"year\":2019},{\"arxivId\":\"2009.02406\",\"authors\":[{\"authorId\":\"28064618\",\"name\":\"Xinli Yu\"},{\"authorId\":\"40031204\",\"name\":\"M. Malmir\"},{\"authorId\":\"6312396\",\"name\":\"C. He\"},{\"authorId\":\"100576986\",\"name\":\"Yue Liu\"},{\"authorId\":\"144667222\",\"name\":\"Rex Wu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b827558cb940ca4ca49c31575cb053da1c4dd9ff\",\"title\":\"Video Moment Retrieval via Natural Language Queries\",\"url\":\"https://www.semanticscholar.org/paper/b827558cb940ca4ca49c31575cb053da1c4dd9ff\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2001.09099\",\"authors\":[{\"authorId\":\"46665218\",\"name\":\"Jie Lei\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"143977266\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.1007/978-3-030-58589-1_27\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"37dd9c725cb800fd5f336a5227f02c160b8723cb\",\"title\":\"TVR: A Large-Scale Dataset for Video-Subtitle Moment Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/37dd9c725cb800fd5f336a5227f02c160b8723cb\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2006.10457\",\"authors\":[{\"authorId\":\"46578437\",\"name\":\"K. Liu\"},{\"authorId\":\"1390538450\",\"name\":\"Xun Yang\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"},{\"authorId\":\"144258295\",\"name\":\"Huadong Ma\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"60e3cc7a1ba3e8617269b801b41692ed5f613b3d\",\"title\":\"Language Guided Networks for Cross-modal Moment Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/60e3cc7a1ba3e8617269b801b41692ed5f613b3d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1910.01442\",\"authors\":[{\"authorId\":\"40879119\",\"name\":\"Kexin Yi\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"3422021\",\"name\":\"Yunzhu Li\"},{\"authorId\":\"143967473\",\"name\":\"P. Kohli\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7f3ecbe546efed8ba42812f977354c16590bad77\",\"title\":\"CLEVRER: CoLlision Events for Video REpresentation and Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/7f3ecbe546efed8ba42812f977354c16590bad77\",\"venue\":\"ICLR\",\"year\":2020}],\"corpusId\":31663499,\"doi\":\"10.1109/ICCV.2017.563\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":61,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"e9bd6f0b04a0ddf9fcdf3a5fd1cfe87f8ae9cfff\",\"references\":[{\"arxivId\":\"1311.2524\",\"authors\":[{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"153652146\",\"name\":\"J. Malik\"}],\"doi\":\"10.1109/CVPR.2014.81\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2f4df08d9072fc2ac181b7fced6a245315ce05c8\",\"title\":\"Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/2f4df08d9072fc2ac181b7fced6a245315ce05c8\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1406.2199\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"title\":\"Two-Stream Convolutional Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1412.2306\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/TPAMI.2016.2598339\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"title\":\"Deep Visual-Semantic Alignments for Generating Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143625300\",\"name\":\"J. Yuan\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"1795291\",\"name\":\"X. Yang\"},{\"authorId\":\"1731233\",\"name\":\"A. Kassim\"}],\"doi\":\"10.1109/CVPR.2016.337\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"374a0df2aa63b26737ee89b6c7df01e59b4d8531\",\"title\":\"Temporal Action Localization with Pyramid of Score Distribution Features\",\"url\":\"https://www.semanticscholar.org/paper/374a0df2aa63b26737ee89b6c7df01e59b4d8531\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1511.02283\",\"authors\":[{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"1808244\",\"name\":\"J. Huang\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"3317152\",\"name\":\"Oana-Maria Camburu\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":\"10.1109/CVPR.2016.9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e65142010431ffc089b272a1174214e00693e503\",\"title\":\"Generation and Comprehension of Unambiguous Object Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/e65142010431ffc089b272a1174214e00693e503\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1703.06189\",\"authors\":[{\"authorId\":\"3029956\",\"name\":\"J. Gao\"},{\"authorId\":\"3469030\",\"name\":\"Zhenheng Yang\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/ICCV.2017.392\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f94841ec597dcf6d1c23e7f40ba35e121f6a81c1\",\"title\":\"TURN TAP: Temporal Unit Regression Network for Temporal Action Proposals\",\"url\":\"https://www.semanticscholar.org/paper/f94841ec597dcf6d1c23e7f40ba35e121f6a81c1\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1511.06984\",\"authors\":[{\"authorId\":\"34149749\",\"name\":\"Serena Yeung\"},{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2016.293\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1bbde7946951d770628cf6b6bcd66c63e4fabb4c\",\"title\":\"End-to-End Learning of Action Detection from Frame Glimpses in Videos\",\"url\":\"https://www.semanticscholar.org/paper/1bbde7946951d770628cf6b6bcd66c63e4fabb4c\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"40404576\",\"name\":\"S. Amin\"},{\"authorId\":\"1906895\",\"name\":\"M. Andriluka\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1109/CVPR.2012.6247801\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"49435aab7cdf259335725acc96691f755e436f55\",\"title\":\"A database for fine grained activity detection of cooking activities\",\"url\":\"https://www.semanticscholar.org/paper/49435aab7cdf259335725acc96691f755e436f55\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1506.02640\",\"authors\":[{\"authorId\":\"40497777\",\"name\":\"Joseph Redmon\"},{\"authorId\":\"2038685\",\"name\":\"S. Divvala\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"47465174\",\"name\":\"Ali Farhadi\"}],\"doi\":\"10.1109/CVPR.2016.91\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f8e79ac0ea341056ef20f2616628b3e964764cfd\",\"title\":\"You Only Look Once: Unified, Real-Time Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/f8e79ac0ea341056ef20f2616628b3e964764cfd\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1506.01497\",\"authors\":[{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"144716314\",\"name\":\"J. Sun\"}],\"doi\":\"10.1109/TPAMI.2016.2577031\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"title\":\"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\",\"url\":\"https://www.semanticscholar.org/paper/424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2909350\",\"name\":\"Alexander Kl\\u00e4ser\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"1689269\",\"name\":\"C. Liu\"}],\"doi\":\"10.1109/CVPR.2011.5995407\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3afbb0e64fcb70496b44b30b76fac9456cc51e34\",\"title\":\"Action recognition by dense trajectories\",\"url\":\"https://www.semanticscholar.org/paper/3afbb0e64fcb70496b44b30b76fac9456cc51e34\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"144332826\",\"name\":\"Chen Kong\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"}],\"doi\":\"10.1109/CVPR.2014.340\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7afd833f484c8032e7fdc5f53188d2ebb0fb9934\",\"title\":\"Visual Semantic Search: Retrieving Videos via Complex Textual Queries\",\"url\":\"https://www.semanticscholar.org/paper/7afd833f484c8032e7fdc5f53188d2ebb0fb9934\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1505.04870\",\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2133220\",\"name\":\"C. Cervantes\"},{\"authorId\":\"145507543\",\"name\":\"Juan C. Caicedo\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1007/s11263-016-0965-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0612745dbd292fc0a548a16d39cd73e127faedde\",\"title\":\"Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models\",\"url\":\"https://www.semanticscholar.org/paper/0612745dbd292fc0a548a16d39cd73e127faedde\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"},{\"authorId\":\"2704179\",\"name\":\"Dongang Wang\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1109/CVPR.2016.119\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"317eaf94573857bec786bbf030605ccdb0fd624d\",\"title\":\"Temporal Action Localization in Untrimmed Videos via Multi-stage CNNs\",\"url\":\"https://www.semanticscholar.org/paper/317eaf94573857bec786bbf030605ccdb0fd624d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1412.6632\",\"authors\":[{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"40579682\",\"name\":\"J. Wang\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745\",\"title\":\"Deep Captioning with Multimodal Recurrent Neural Networks (m-RNN)\",\"url\":\"https://www.semanticscholar.org/paper/54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/CVPR.2015.7298698\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0a28efacb92d16e6e0dd4d87b5aca91b28be8853\",\"title\":\"ActivityNet: A large-scale video benchmark for human activity understanding\",\"url\":\"https://www.semanticscholar.org/paper/0a28efacb92d16e6e0dd4d87b5aca91b28be8853\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1509.07225\",\"authors\":[{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/ICCV.2015.298\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4d925db7c9e3cca2e8fed644f750d218a48cd081\",\"title\":\"Automatic Concept Discovery from Parallel Text and Visual Corpora\",\"url\":\"https://www.semanticscholar.org/paper/4d925db7c9e3cca2e8fed644f750d218a48cd081\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2863531\",\"name\":\"Shugao Ma\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"}],\"doi\":\"10.1109/CVPR.2016.214\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e578bd130eb2a2fdc573ec3f7d80f2186cb221fe\",\"title\":\"Learning Activity Progression in LSTMs for Activity Detection and Early Detection\",\"url\":\"https://www.semanticscholar.org/paper/e578bd130eb2a2fdc573ec3f7d80f2186cb221fe\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1604.01753\",\"authors\":[{\"authorId\":\"34280810\",\"name\":\"Gunnar A. Sigurdsson\"},{\"authorId\":\"2668759\",\"name\":\"G. Varol\"},{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1007/978-3-319-46448-0_31\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"21334d1aac5422da88780f8e24e181bfa15ef0e1\",\"title\":\"Hollywood in Homes: Crowdsourcing Data Collection for Activity Understanding\",\"url\":\"https://www.semanticscholar.org/paper/21334d1aac5422da88780f8e24e181bfa15ef0e1\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1506.06726\",\"authors\":[{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"2214033\",\"name\":\"Y. Zhu\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6e795c6e9916174ae12349f5dc3f516570c17ce8\",\"title\":\"Skip-Thought Vectors\",\"url\":\"https://www.semanticscholar.org/paper/6e795c6e9916174ae12349f5dc3f516570c17ce8\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"},{\"authorId\":\"1760868\",\"name\":\"M. Surdeanu\"},{\"authorId\":\"144661918\",\"name\":\"John Bauer\"},{\"authorId\":\"2784228\",\"name\":\"Jenny Rose Finkel\"},{\"authorId\":\"2105138\",\"name\":\"Steven Bethard\"},{\"authorId\":\"2240597\",\"name\":\"D. McClosky\"}],\"doi\":\"10.3115/v1/P14-5010\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"2f5102ec3f70d0dea98c957cc2cab4d15d83a2da\",\"title\":\"The Stanford CoreNLP Natural Language Processing Toolkit\",\"url\":\"https://www.semanticscholar.org/paper/2f5102ec3f70d0dea98c957cc2cab4d15d83a2da\",\"venue\":\"ACL\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"152821938\",\"name\":\"Sanketh Shetty\"},{\"authorId\":\"120906511\",\"name\":\"T. Leung\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2014.223\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"title\":\"Large-Scale Video Classification with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3006072\",\"name\":\"Sahar Kazemzadeh\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"32215032\",\"name\":\"Mark Matten\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.3115/v1/D14-1086\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"92c141447f51b6732242376164ff961e464731c8\",\"title\":\"ReferItGame: Referring to Objects in Photographs of Natural Scenes\",\"url\":\"https://www.semanticscholar.org/paper/92c141447f51b6732242376164ff961e464731c8\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2485529\",\"name\":\"Michaela Regneri\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"24138684\",\"name\":\"Dominikus Wetzel\"},{\"authorId\":\"1727272\",\"name\":\"Stefan Thater\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"1717560\",\"name\":\"Manfred Pinkal\"}],\"doi\":\"10.1162/tacl_a_00207\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"21b3007f967d39e1346bc91e0fc8b3f16121300c\",\"title\":\"Grounding Action Descriptions in Videos\",\"url\":\"https://www.semanticscholar.org/paper/21b3007f967d39e1346bc91e0fc8b3f16121300c\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"2485529\",\"name\":\"Michaela Regneri\"},{\"authorId\":\"1906895\",\"name\":\"M. Andriluka\"},{\"authorId\":\"40404576\",\"name\":\"S. Amin\"},{\"authorId\":\"1717560\",\"name\":\"Manfred Pinkal\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1007/978-3-642-33718-5_11\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"8623fe8b087cedcaac276e313f8fed6f0dfccc33\",\"title\":\"Script Data for Attribute-Based Recognition of Composite Activities\",\"url\":\"https://www.semanticscholar.org/paper/8623fe8b087cedcaac276e313f8fed6f0dfccc33\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J. Redmon\"},{\"authorId\":null,\"name\":\"S. Divvala\"},{\"authorId\":null,\"name\":\"R. Girshick\"},{\"authorId\":null,\"name\":\"A. Farhadi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"You only look once: Unified\",\"url\":\"\",\"venue\":\"real-time object detection. In CVPR\",\"year\":2016},{\"arxivId\":\"1511.04164\",\"authors\":[{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"3286703\",\"name\":\"Huazhe Xu\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/CVPR.2016.493\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d696a1923288e6c15422660de9553f6fdb6a4fae\",\"title\":\"Natural Language Object Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/d696a1923288e6c15422660de9553f6fdb6a4fae\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1504.08083\",\"authors\":[{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/ICCV.2015.169\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"7ffdbc358b63378f07311e883dddacc9faeeaf4b\",\"title\":\"Fast R-CNN\",\"url\":\"https://www.semanticscholar.org/paper/7ffdbc358b63378f07311e883dddacc9faeeaf4b\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1604.04784\",\"authors\":[{\"authorId\":\"3029956\",\"name\":\"J. Gao\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1145/2911996.2912014\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"30aac3becead355545b5ab7f0c3158040360021e\",\"title\":\"ACD: Action Concept Discovery from Image-Sentence Corpora\",\"url\":\"https://www.semanticscholar.org/paper/30aac3becead355545b5ab7f0c3158040360021e\",\"venue\":\"ICMR\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50702063\",\"name\":\"B. Singh\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"},{\"authorId\":\"145319478\",\"name\":\"Michael J. Jones\"},{\"authorId\":\"2577513\",\"name\":\"Oncel Tuzel\"},{\"authorId\":\"144197068\",\"name\":\"M. Shao\"}],\"doi\":\"10.1109/CVPR.2016.216\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"260d0b7e94777dcca1cd1a9651fb6c42cba2823f\",\"title\":\"A Multi-stream Bi-directional Recurrent Neural Network for Fine-Grained Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/260d0b7e94777dcca1cd1a9651fb6c42cba2823f\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1310.4546\",\"authors\":[{\"authorId\":null,\"name\":\"Tomas Mikolov\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"38644044\",\"name\":\"Kai Chen\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"87f40e6f3022adbc1f1905e3e506abad05a9964f\",\"title\":\"Distributed Representations of Words and Phrases and their Compositionality\",\"url\":\"https://www.semanticscholar.org/paper/87f40e6f3022adbc1f1905e3e506abad05a9964f\",\"venue\":\"NIPS\",\"year\":2013},{\"arxivId\":\"1503.08909\",\"authors\":[{\"authorId\":\"2340579\",\"name\":\"J. Ng\"},{\"authorId\":\"3308897\",\"name\":\"Matthew J. Hausknecht\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"49519592\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"3089272\",\"name\":\"Rajat Monga\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"}],\"doi\":\"10.1109/CVPR.2015.7299101\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5418b2a482720e013d487a385c26fae0f017c6a6\",\"title\":\"Beyond short snippets: Deep networks for video classification\",\"url\":\"https://www.semanticscholar.org/paper/5418b2a482720e013d487a385c26fae0f017c6a6\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1505.06027\",\"authors\":[{\"authorId\":\"2329288\",\"name\":\"P. Bojanowski\"},{\"authorId\":\"3215950\",\"name\":\"R\\u00e9mi Lajugie\"},{\"authorId\":\"3024698\",\"name\":\"E. Grave\"},{\"authorId\":\"144570279\",\"name\":\"Francis R. Bach\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"144189388\",\"name\":\"J. Ponce\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2015.507\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"59ac98f3910dad473e7771ac61f796a038f1708f\",\"title\":\"Weakly-Supervised Alignment of Video with Text\",\"url\":\"https://www.semanticscholar.org/paper/59ac98f3910dad473e7771ac61f796a038f1708f\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/ICCV.2015.510\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"title\":\"Learning Spatiotemporal Features with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015}],\"title\":\"TALL: Temporal Activity Localization via Language Query\",\"topics\":[{\"topic\":\"Video clip\",\"topicId\":\"30493\",\"url\":\"https://www.semanticscholar.org/topic/30493\"},{\"topic\":\"Modal logic\",\"topicId\":\"61528\",\"url\":\"https://www.semanticscholar.org/topic/61528\"},{\"topic\":\"Natural language\",\"topicId\":\"1911\",\"url\":\"https://www.semanticscholar.org/topic/1911\"},{\"topic\":\"Refinement (computing)\",\"topicId\":\"5410\",\"url\":\"https://www.semanticscholar.org/topic/5410\"},{\"topic\":\"Microsoft Windows\",\"topicId\":\"4539\",\"url\":\"https://www.semanticscholar.org/topic/4539\"},{\"topic\":\"Static timing analysis\",\"topicId\":\"34178\",\"url\":\"https://www.semanticscholar.org/topic/34178\"},{\"topic\":\"Linked list\",\"topicId\":\"12862\",\"url\":\"https://www.semanticscholar.org/topic/12862\"}],\"url\":\"https://www.semanticscholar.org/paper/e9bd6f0b04a0ddf9fcdf3a5fd1cfe87f8ae9cfff\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017}\n"