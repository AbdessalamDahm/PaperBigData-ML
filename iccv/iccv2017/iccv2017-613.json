"{\"abstract\":\"Neural networks trained on datasets such as ImageNet have led to major advances in visual object classification. One obstacle that prevents networks from reasoning more deeply about complex scenes and situations, and from integrating visual knowledge with natural language, like humans do, is their lack of common sense knowledge about the physical world. Videos, unlike still images, contain a wealth of detailed information about the physical world. However, most labelled video datasets represent high-level concepts rather than detailed physical aspects about actions and scenes. In this work, we describe our ongoing collection of the \\u201csomething-something\\u201d database of video prediction tasks whose solutions require a common sense understanding of the depicted situation. The database currently contains more than 100,000 videos across 174 classes, which are defined as caption-templates. We also describe the challenges in crowd-sourcing this data at scale.\",\"arxivId\":\"1706.04261\",\"authors\":[{\"authorId\":\"38962424\",\"name\":\"Raghav Goyal\",\"url\":\"https://www.semanticscholar.org/author/38962424\"},{\"authorId\":\"3127597\",\"name\":\"S. Kahou\",\"url\":\"https://www.semanticscholar.org/author/3127597\"},{\"authorId\":\"1748421\",\"name\":\"Vincent Michalski\",\"url\":\"https://www.semanticscholar.org/author/1748421\"},{\"authorId\":\"7654960\",\"name\":\"Joanna Materzynska\",\"url\":\"https://www.semanticscholar.org/author/7654960\"},{\"authorId\":\"12929417\",\"name\":\"S. Westphal\",\"url\":\"https://www.semanticscholar.org/author/12929417\"},{\"authorId\":\"2233986\",\"name\":\"Heuna Kim\",\"url\":\"https://www.semanticscholar.org/author/2233986\"},{\"authorId\":\"7241984\",\"name\":\"V. Haenel\",\"url\":\"https://www.semanticscholar.org/author/7241984\"},{\"authorId\":\"47544625\",\"name\":\"Ingo Fr\\u00fcnd\",\"url\":\"https://www.semanticscholar.org/author/47544625\"},{\"authorId\":\"19265538\",\"name\":\"Peter Yianilos\",\"url\":\"https://www.semanticscholar.org/author/19265538\"},{\"authorId\":\"1414405239\",\"name\":\"Moritz Mueller-Freitag\",\"url\":\"https://www.semanticscholar.org/author/1414405239\"},{\"authorId\":\"143931146\",\"name\":\"F. Hoppe\",\"url\":\"https://www.semanticscholar.org/author/143931146\"},{\"authorId\":\"2020614\",\"name\":\"Christian Thurau\",\"url\":\"https://www.semanticscholar.org/author/2020614\"},{\"authorId\":\"2443288\",\"name\":\"I. Bax\",\"url\":\"https://www.semanticscholar.org/author/2443288\"},{\"authorId\":\"1710604\",\"name\":\"R. Memisevic\",\"url\":\"https://www.semanticscholar.org/author/1710604\"}],\"citationVelocity\":81,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"34608005\",\"name\":\"L. Chen\"},{\"authorId\":\"144207288\",\"name\":\"R. Liu\"},{\"authorId\":\"153450634\",\"name\":\"Dongsheng Zhou\"},{\"authorId\":\"50031413\",\"name\":\"X. Yang\"},{\"authorId\":\"47835286\",\"name\":\"Qing-fang Zhang\"}],\"doi\":\"10.1186/s42492-020-00045-x\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"115880905156feef7d751840b7f59c72987b17a8\",\"title\":\"Fused behavior recognition model based on attention mechanism\",\"url\":\"https://www.semanticscholar.org/paper/115880905156feef7d751840b7f59c72987b17a8\",\"venue\":\"Vis. Comput. Ind. Biomed. Art\",\"year\":2020},{\"arxivId\":\"1903.10520\",\"authors\":[{\"authorId\":\"2383133\",\"name\":\"Siyuan Qiao\"},{\"authorId\":\"46506170\",\"name\":\"Huiyu Wang\"},{\"authorId\":\"50557601\",\"name\":\"Chenxi Liu\"},{\"authorId\":\"144084228\",\"name\":\"Wei Shen\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"caa2704320e3742bc611c30092acd7a7eb87d5d4\",\"title\":\"Weight Standardization\",\"url\":\"https://www.semanticscholar.org/paper/caa2704320e3742bc611c30092acd7a7eb87d5d4\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Roshan Rane\"},{\"authorId\":\"150333998\",\"name\":\"Vageesh Saxena\"},{\"authorId\":\"150096315\",\"name\":\"Edit Sz\\u00fcgyi\"},{\"authorId\":\"35280884\",\"name\":\"Andr\\u00e9 Ofner\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e78232f23508b879c6c5ae372030487ed071ca1f\",\"title\":\"Video Action Classification Using Deep Predictive Coding Networks\",\"url\":\"https://www.semanticscholar.org/paper/e78232f23508b879c6c5ae372030487ed071ca1f\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50202365\",\"name\":\"Shiwen Zhang\"},{\"authorId\":\"49015548\",\"name\":\"Weilin Huang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a19185b1cbb6588682318bb9ce649a611e889162\",\"title\":\"VIDEO-LEVEL REPRESENTATION LEARNING\",\"url\":\"https://www.semanticscholar.org/paper/a19185b1cbb6588682318bb9ce649a611e889162\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2010.11649\",\"authors\":[{\"authorId\":\"2502363\",\"name\":\"Gagan Kanojia\"},{\"authorId\":\"145853779\",\"name\":\"S. Raman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ed9915ad5ce1b469861503be803e6adab2eea985\",\"title\":\"Learning to Sort Image Sequences via Accumulated Temporal Differences\",\"url\":\"https://www.semanticscholar.org/paper/ed9915ad5ce1b469861503be803e6adab2eea985\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1807.10706\",\"authors\":[{\"authorId\":\"19198894\",\"name\":\"Humam Alwassel\"},{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1007/978-3-030-01219-9_16\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1786d26835e0add50c013ef5089afc5ff5796e1e\",\"title\":\"Diagnosing Error in Temporal Action Detectors\",\"url\":\"https://www.semanticscholar.org/paper/1786d26835e0add50c013ef5089afc5ff5796e1e\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145412333\",\"name\":\"L. Lu\"},{\"authorId\":\"48831152\",\"name\":\"Siyuan Li\"},{\"authorId\":\"153708390\",\"name\":\"Niannian Chen\"},{\"authorId\":\"2019262779\",\"name\":\"Lin Gao\"},{\"authorId\":\"2020711614\",\"name\":\"Yong Fan\"},{\"authorId\":\"50262192\",\"name\":\"Yong Jiang\"},{\"authorId\":\"50790156\",\"name\":\"L. Wu\"}],\"doi\":\"10.1007/978-3-030-63820-7_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b64e377a75b9820dbcb08b3ffeea72d4331c1a1e\",\"title\":\"Learning and Distillating the Internal Relationship of Motion Features in Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b64e377a75b9820dbcb08b3ffeea72d4331c1a1e\",\"venue\":\"ICONIP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38962424\",\"name\":\"Raghav Goyal\"},{\"authorId\":\"2454800\",\"name\":\"F. Mahdisoltani\"},{\"authorId\":\"40586522\",\"name\":\"Guillaume Berger\"},{\"authorId\":\"3462264\",\"name\":\"Waseem Gharbieh\"},{\"authorId\":\"2443288\",\"name\":\"I. Bax\"},{\"authorId\":\"1710604\",\"name\":\"R. Memisevic\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b9ac1c21d8dc68643bf214338ff75e554191ccd2\",\"title\":\"Evaluating visual \\\"common sense\\\" using fine-grained classification and captioning tasks\",\"url\":\"https://www.semanticscholar.org/paper/b9ac1c21d8dc68643bf214338ff75e554191ccd2\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1909.08606\",\"authors\":[{\"authorId\":\"25054465\",\"name\":\"Tejo Chalasani\"},{\"authorId\":\"118065745\",\"name\":\"A. Smolic\"}],\"doi\":\"10.1109/ICCVW.2019.00537\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dbafbe80feb24e9d4232aa73c2a4eb78180d2497\",\"title\":\"Simultaneous Segmentation and Recognition: Towards More Accurate Ego Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/dbafbe80feb24e9d4232aa73c2a4eb78180d2497\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"2008.07819\",\"authors\":[{\"authorId\":\"72831997\",\"name\":\"T. Ma\"},{\"authorId\":\"101160956\",\"name\":\"L. Zhang\"},{\"authorId\":\"87641774\",\"name\":\"X. Diao\"},{\"authorId\":\"1411075691\",\"name\":\"O. Ma\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c6a82bcb60db6f0b131e270e4ffb8b84bc01c6e\",\"title\":\"ConvGRU in Fine-grained Pitching Action Recognition for Action Outcome Prediction\",\"url\":\"https://www.semanticscholar.org/paper/1c6a82bcb60db6f0b131e270e4ffb8b84bc01c6e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50750258\",\"name\":\"T. Okawara\"},{\"authorId\":\"80809027\",\"name\":\"M. Yoshida\"},{\"authorId\":\"145800886\",\"name\":\"H. Nagahara\"},{\"authorId\":\"1715071\",\"name\":\"Y. Yagi\"}],\"doi\":\"10.1109/ICCP48838.2020.9105176\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"90ccdae5898712d2cb59d52f6aad0aeb64066eb6\",\"title\":\"Action Recognition from a Single Coded Image\",\"url\":\"https://www.semanticscholar.org/paper/90ccdae5898712d2cb59d52f6aad0aeb64066eb6\",\"venue\":\"2020 IEEE International Conference on Computational Photography (ICCP)\",\"year\":2020},{\"arxivId\":\"2012.08041\",\"authors\":[{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"50557221\",\"name\":\"Chunhui Liu\"},{\"authorId\":\"2521776\",\"name\":\"B. Shuai\"},{\"authorId\":\"1805946041\",\"name\":\"Yi Zhu\"},{\"authorId\":\"48444479\",\"name\":\"Hao Chen\"},{\"authorId\":\"2397422\",\"name\":\"Joseph Tighe\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f0d55ca0b8f1639372e88479516a573e2bf2250b\",\"title\":\"NUTA: Non-uniform Temporal Aggregation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f0d55ca0b8f1639372e88479516a573e2bf2250b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.09434\",\"authors\":[{\"authorId\":\"48031771\",\"name\":\"X. Liu\"},{\"authorId\":\"72285615\",\"name\":\"Yao Hu\"},{\"authorId\":\"98807701\",\"name\":\"Song Bai\"},{\"authorId\":\"1430778662\",\"name\":\"Fei Ding\"},{\"authorId\":\"145905113\",\"name\":\"X. Bai\"},{\"authorId\":null,\"name\":\"Philip H. S. Torr\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"db1b0d0e70f29b0018d1a9462d98dd39559f3e4a\",\"title\":\"Multi-shot Temporal Event Localization: a Benchmark\",\"url\":\"https://www.semanticscholar.org/paper/db1b0d0e70f29b0018d1a9462d98dd39559f3e4a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.05654\",\"authors\":[{\"authorId\":\"39714216\",\"name\":\"F. Ragusa\"},{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"2444519\",\"name\":\"S. Livatino\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a58a0732664b97b471b795df5812f98f24840490\",\"title\":\"The MECCANO Dataset: Understanding Human-Object Interactions from Egocentric Videos in an Industrial-like Domain\",\"url\":\"https://www.semanticscholar.org/paper/a58a0732664b97b471b795df5812f98f24840490\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47827957\",\"name\":\"Y. Zhao\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"656c001e91378f460c898a85b5019e367992b030\",\"title\":\"Trajectory Convolution for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/656c001e91378f460c898a85b5019e367992b030\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"2001.09691\",\"authors\":[{\"authorId\":\"47077615\",\"name\":\"J. Munro\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.1109/ICCVW.2019.00461\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10cf610ca725cdf459f6a4fa68999066b586b93a\",\"title\":\"Multi-Modal Domain Adaptation for Fine-Grained Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/10cf610ca725cdf459f6a4fa68999066b586b93a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1801.04134\",\"authors\":[{\"authorId\":\"35309584\",\"name\":\"Jonas Rothfuss\"},{\"authorId\":\"145839029\",\"name\":\"F. Ferreira\"},{\"authorId\":\"34876449\",\"name\":\"E. Aksoy\"},{\"authorId\":\"46432716\",\"name\":\"Y. Zhou\"},{\"authorId\":\"1722677\",\"name\":\"T. Asfour\"}],\"doi\":\"10.1109/LRA.2018.2860057\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"970a8f1655ab329cba5fe26edf543e62fe354376\",\"title\":\"Deep Episodic Memory: Encoding, Recalling, and Predicting Episodic Experiences for Robot Action Execution\",\"url\":\"https://www.semanticscholar.org/paper/970a8f1655ab329cba5fe26edf543e62fe354376\",\"venue\":\"IEEE Robotics and Automation Letters\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47141093\",\"name\":\"Gursimran Singh\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"1710980\",\"name\":\"J. Little\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"51fadc0803ee53c91eb4fcfb3777720496c9d91f\",\"title\":\"Spatio-temporal Relational Reasoning for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/51fadc0803ee53c91eb4fcfb3777720496c9d91f\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"1912.03716\",\"authors\":[{\"authorId\":\"91060830\",\"name\":\"Zhiyu Yao\"},{\"authorId\":null,\"name\":\"Yunbo Wang\"},{\"authorId\":\"93640403\",\"name\":\"Xingqiang Du\"},{\"authorId\":\"35776445\",\"name\":\"Mingsheng Long\"},{\"authorId\":\"46583978\",\"name\":\"J. Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2df80c3db4550da81854e05a24e658bacec564a2\",\"title\":\"Adversarial Pyramid Network for Video Domain Generalization\",\"url\":\"https://www.semanticscholar.org/paper/2df80c3db4550da81854e05a24e658bacec564a2\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2009.06902\",\"authors\":[{\"authorId\":\"13099867\",\"name\":\"Haisheng Su\"},{\"authorId\":\"1768759403\",\"name\":\"Jing Su\"},{\"authorId\":\"1605763279\",\"name\":\"Dongliang Wang\"},{\"authorId\":\"35893447\",\"name\":\"W. Gan\"},{\"authorId\":\"145717875\",\"name\":\"Wei Wu\"},{\"authorId\":\"47446949\",\"name\":\"M. Wang\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\"},{\"authorId\":\"145858545\",\"name\":\"Y. Qiao\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"882a973e02bfe9717f4ad70fe9fb327a515b16ca\",\"title\":\"Collaborative Distillation in the Parameter and Spectrum Domains for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/882a973e02bfe9717f4ad70fe9fb327a515b16ca\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.10071\",\"authors\":[{\"authorId\":\"48170161\",\"name\":\"L. Wang\"},{\"authorId\":\"9445458\",\"name\":\"Zhan Tong\"},{\"authorId\":\"1511715446\",\"name\":\"Bin Ji\"},{\"authorId\":\"39914710\",\"name\":\"Gangshan Wu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"839a009d4d530483cb9b365012ffc7d76cd88b85\",\"title\":\"TDN: Temporal Difference Networks for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/839a009d4d530483cb9b365012ffc7d76cd88b85\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46297634\",\"name\":\"Shigeru Fujita\"},{\"authorId\":\"151474656\",\"name\":\"Thierry Gidel\"},{\"authorId\":\"151472620\",\"name\":\"Yuki Kaeri\"},{\"authorId\":\"113044406\",\"name\":\"Andrea Tucker\"},{\"authorId\":\"1758500\",\"name\":\"K. Sugawara\"},{\"authorId\":\"145525435\",\"name\":\"C. Moulin\"}],\"doi\":\"10.1109/SMC42975.2020.9282981\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c9076237ebaa1af708d2604ffdc2f6cc18e352ab\",\"title\":\"AI-based Automatic Activity Recognition of Single Persons and Groups During Brainstorming*\",\"url\":\"https://www.semanticscholar.org/paper/c9076237ebaa1af708d2604ffdc2f6cc18e352ab\",\"venue\":\"2020 IEEE International Conference on Systems, Man, and Cybernetics (SMC)\",\"year\":2020},{\"arxivId\":\"1911.08548\",\"authors\":[{\"authorId\":\"47792983\",\"name\":\"J. Ma\"},{\"authorId\":\"46227885\",\"name\":\"Satya Krishna Gorti\"},{\"authorId\":\"1765951\",\"name\":\"Maksims Volkovs\"},{\"authorId\":\"93169948\",\"name\":\"Ilya Stanevich\"},{\"authorId\":\"46546800\",\"name\":\"Guangwei Yu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d8283f38f9e027a38c454957297d4a685b453575\",\"title\":\"Cross-Class Relevance Learning for Temporal Concept Localization\",\"url\":\"https://www.semanticscholar.org/paper/d8283f38f9e027a38c454957297d4a685b453575\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1772198\",\"name\":\"X. Wu\"},{\"authorId\":\"3307319\",\"name\":\"Qing-Ge Ji\"}],\"doi\":\"10.1145/3426826.3426836\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"64469e496132f3e25cdc5bfcfb3b7069c5e15ac4\",\"title\":\"Split and Attentive-Aggregated Learnable Shift Module for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/64469e496132f3e25cdc5bfcfb3b7069c5e15ac4\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2007.04515\",\"authors\":[{\"authorId\":\"3234247\",\"name\":\"Senthil Purushwalkam\"},{\"authorId\":\"1391076188\",\"name\":\"Tian Ye\"},{\"authorId\":\"47924870\",\"name\":\"Saurabh Gupta\"},{\"authorId\":null,\"name\":\"Abhinav Gupta\"}],\"doi\":\"10.1007/978-3-030-58574-7_16\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9e3a6c70799ee375e4b6035f59236677439c41a5\",\"title\":\"Aligning Videos in Space and Time\",\"url\":\"https://www.semanticscholar.org/paper/9e3a6c70799ee375e4b6035f59236677439c41a5\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1801.03150\",\"authors\":[{\"authorId\":\"95743023\",\"name\":\"Mathew Monfort\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"3298267\",\"name\":\"Sarah Adel Bargal\"},{\"authorId\":\"50112310\",\"name\":\"Alex Andonian\"},{\"authorId\":\"12082007\",\"name\":\"Tom Yan\"},{\"authorId\":\"40544169\",\"name\":\"K. Ramakrishnan\"},{\"authorId\":\"49860655\",\"name\":\"L. Brown\"},{\"authorId\":\"33421444\",\"name\":\"Quanfu Fan\"},{\"authorId\":\"1891570\",\"name\":\"Dan Gutfreund\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"}],\"doi\":\"10.1109/TPAMI.2019.2901464\",\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"07174c2f209f15cacf9ad3422b48652df286be69\",\"title\":\"Moments in Time Dataset: One Million Videos for Event Understanding\",\"url\":\"https://www.semanticscholar.org/paper/07174c2f209f15cacf9ad3422b48652df286be69\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":\"2002.09131\",\"authors\":[{\"authorId\":\"152324585\",\"name\":\"Jiahao Su\"},{\"authorId\":\"145965455\",\"name\":\"Wonmin Byeon\"},{\"authorId\":\"40070055\",\"name\":\"F. Huang\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"},{\"authorId\":\"47627049\",\"name\":\"A. Anandkumar\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"260ac6906bb506757ea2212af775fff4b4462663\",\"title\":\"Convolutional Tensor-Train LSTM for Spatio-temporal Learning\",\"url\":\"https://www.semanticscholar.org/paper/260ac6906bb506757ea2212af775fff4b4462663\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"1907.11117\",\"authors\":[{\"authorId\":\"145032628\",\"name\":\"Michael Wray\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b73ff5846772da8575262925aa7709b5e64079a0\",\"title\":\"Learning Visual Actions Using Multiple Verb-Only Labels\",\"url\":\"https://www.semanticscholar.org/paper/b73ff5846772da8575262925aa7709b5e64079a0\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"2012.03457\",\"authors\":[{\"authorId\":\"2151587\",\"name\":\"Sangdoo Yun\"},{\"authorId\":\"2390510\",\"name\":\"Seong Joon Oh\"},{\"authorId\":\"3086596\",\"name\":\"Byeongho Heo\"},{\"authorId\":\"2086576\",\"name\":\"Dongyoon Han\"},{\"authorId\":\"52289773\",\"name\":\"Jinhyung Kim\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0f6830373b3a2758baf5efa50f4ca9ac17b1a377\",\"title\":\"VideoMix: Rethinking Data Augmentation for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/0f6830373b3a2758baf5efa50f4ca9ac17b1a377\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7654960\",\"name\":\"Joanna Materzynska\"},{\"authorId\":\"143868490\",\"name\":\"G. Berger\"},{\"authorId\":\"1557638138\",\"name\":\"Ingo Bax\"},{\"authorId\":\"1557636479\",\"name\":\"Roland Memisevic\"}],\"doi\":\"10.1109/ICCVW.2019.00349\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8ef708ce97183dc9a0e9514a80fc8dacf7ca29c5\",\"title\":\"The Jester Dataset: A Large-Scale Video Dataset of Human Gestures\",\"url\":\"https://www.semanticscholar.org/paper/8ef708ce97183dc9a0e9514a80fc8dacf7ca29c5\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1749627\",\"name\":\"M. Leordeanu\"}],\"doi\":\"10.1007/978-3-030-42128-1_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1431aa3159e932c96265c73f9bf8fbc2fa321926\",\"title\":\"Unsupervised Learning Towards the Future\",\"url\":\"https://www.semanticscholar.org/paper/1431aa3159e932c96265c73f9bf8fbc2fa321926\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2003.07385\",\"authors\":[{\"authorId\":\"34079649\",\"name\":\"N. Krishnaswamy\"},{\"authorId\":\"1707726\",\"name\":\"J. Pustejovsky\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c4984793fb81b42f3fcbc4a2edeff1fc262dc5e\",\"title\":\"A Formal Analysis of Multimodal Referring Strategies Under Common Ground\",\"url\":\"https://www.semanticscholar.org/paper/2c4984793fb81b42f3fcbc4a2edeff1fc262dc5e\",\"venue\":\"LREC\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1398447065\",\"name\":\"Sadjad Asghari-Esfeden\"},{\"authorId\":\"1687866\",\"name\":\"M. Sznaier\"},{\"authorId\":\"143867334\",\"name\":\"O. Camps\"}],\"doi\":\"10.1109/WACV45572.2020.9093500\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"51bcb7de98bedf65215910fcfd08555d5eed682a\",\"title\":\"Dynamic Motion Representation for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/51bcb7de98bedf65215910fcfd08555d5eed682a\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50071092\",\"name\":\"Gao Peng\"},{\"authorId\":null,\"name\":\"Bo Pang\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d2bf569fbf3e407f4b60567a94d45880d35c2a3d\",\"title\":\"Efficient 3D Video Engine Using Frame Redundancy\",\"url\":\"https://www.semanticscholar.org/paper/d2bf569fbf3e407f4b60567a94d45880d35c2a3d\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1910.05577\",\"authors\":[{\"authorId\":\"1821514\",\"name\":\"Xu-Dong Lin\"},{\"authorId\":\"152309767\",\"name\":\"L. Ma\"},{\"authorId\":\"1743698\",\"name\":\"Wenyu Liu\"},{\"authorId\":\"72197815\",\"name\":\"Shih-Fu Chang\"}],\"doi\":\"10.1007/978-3-030-58523-5_41\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"119b1526842c105ef9a5b187c13045eb580220e7\",\"title\":\"Context-Gated Convolution\",\"url\":\"https://www.semanticscholar.org/paper/119b1526842c105ef9a5b187c13045eb580220e7\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.07626\",\"authors\":[{\"authorId\":\"28969692\",\"name\":\"Junwu Weng\"},{\"authorId\":\"9393671\",\"name\":\"Donghao Luo\"},{\"authorId\":null,\"name\":\"Yabiao Wang\"},{\"authorId\":\"144970872\",\"name\":\"Ying Tai\"},{\"authorId\":\"1978245\",\"name\":\"Chengjie Wang\"},{\"authorId\":\"49298244\",\"name\":\"Jilin Li\"},{\"authorId\":\"1835006\",\"name\":\"Feiyue Huang\"},{\"authorId\":\"3307580\",\"name\":\"Xudong Jiang\"},{\"authorId\":\"48837492\",\"name\":\"J. Yuan\"}],\"doi\":\"10.1007/978-3-030-58571-6_22\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"cfb71e0cce6487b6a1cf2dd0cd3755d1d78e908e\",\"title\":\"Temporal Distinct Representation Learning for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cfb71e0cce6487b6a1cf2dd0cd3755d1d78e908e\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.06149\",\"authors\":[{\"authorId\":\"2283619\",\"name\":\"Peisen Zhao\"},{\"authorId\":\"3041937\",\"name\":\"Lingxi Xie\"},{\"authorId\":\"49890039\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/tmm.2020.3025665\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6c1fc76cc67ad82df1f7695b4d9e0b7536a70732\",\"title\":\"Universal-to-Specific Framework for Complex Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6c1fc76cc67ad82df1f7695b4d9e0b7536a70732\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.07949\",\"authors\":[{\"authorId\":\"4965440\",\"name\":\"Peihao Chen\"},{\"authorId\":\"145592817\",\"name\":\"D. Huang\"},{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"46550737\",\"name\":\"Xiang Long\"},{\"authorId\":\"147992804\",\"name\":\"Runhao Zeng\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2336388131b3cb41eb44e927aeac10a1dabbedad\",\"title\":\"RSPNet: Relative Speed Perception for Unsupervised Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/2336388131b3cb41eb44e927aeac10a1dabbedad\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1909.13130\",\"authors\":[{\"authorId\":\"153918891\",\"name\":\"Chenxu Luo\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.1109/ICCV.2019.00561\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8b8fe4727c8094b17e61886e69a602f8d0403091\",\"title\":\"Grouped Spatial-Temporal Aggregation for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b8fe4727c8094b17e61886e69a602f8d0403091\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1906.00038\",\"authors\":[{\"authorId\":\"2003313\",\"name\":\"Stephanie M. Lukin\"},{\"authorId\":\"3202888\",\"name\":\"Claire Bonial\"},{\"authorId\":\"1817166\",\"name\":\"Clare R. Voss\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"29a7bb2ff104e7f4b5cea52c4d6e8e708d5b516d\",\"title\":\"Visual Understanding and Narration: A Deeper Understanding and Explanation of Visual Scenes\",\"url\":\"https://www.semanticscholar.org/paper/29a7bb2ff104e7f4b5cea52c4d6e8e708d5b516d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19177140\",\"name\":\"S. Das\"},{\"authorId\":\"145745355\",\"name\":\"Rui Dai\"},{\"authorId\":\"34561667\",\"name\":\"Michal Koperski\"},{\"authorId\":\"10392396\",\"name\":\"Luca Minciullo\"},{\"authorId\":\"2645224\",\"name\":\"Lorenzo Garattoni\"},{\"authorId\":\"69929964\",\"name\":\"F. Br\\u00e9mond\"},{\"authorId\":\"2647267\",\"name\":\"G. Francesca\"}],\"doi\":\"10.1109/ICCV.2019.00092\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c17f395738bc3494974283ba9460c516a948f7ef\",\"title\":\"Toyota Smarthome: Real-World Activities of Daily Living\",\"url\":\"https://www.semanticscholar.org/paper/c17f395738bc3494974283ba9460c516a948f7ef\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1912.09930\",\"authors\":[{\"authorId\":\"7654960\",\"name\":\"Joanna Materzynska\"},{\"authorId\":\"15727192\",\"name\":\"Tete Xiao\"},{\"authorId\":\"46796686\",\"name\":\"Roei Herzig\"},{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"39635018\",\"name\":\"Xiaolong Wang\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/cvpr42600.2020.00113\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"af06120e7883ff969746ab473bfe09e642a90fc3\",\"title\":\"Something-Else: Compositional Action Recognition With Spatial-Temporal Interaction Networks\",\"url\":\"https://www.semanticscholar.org/paper/af06120e7883ff969746ab473bfe09e642a90fc3\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1711.08496\",\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"50112310\",\"name\":\"Alex Andonian\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1007/978-3-030-01246-5_49\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8ad12d3ee186403b856639b58d7797aa4b89a6c7\",\"title\":\"Temporal Relational Reasoning in Videos\",\"url\":\"https://www.semanticscholar.org/paper/8ad12d3ee186403b856639b58d7797aa4b89a6c7\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"3313330\",\"name\":\"Gedas Bertasius\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"1726095131\",\"name\":\"Abhinav Gupta\"},{\"authorId\":\"2356016\",\"name\":\"Minh Hoai\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"86a9e09459c5a4e436706d0b89f951d780e80a71\",\"title\":\"Supervoxel Attention Graphs for Long-Range Video Modeling\",\"url\":\"https://www.semanticscholar.org/paper/86a9e09459c5a4e436706d0b89f951d780e80a71\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Joao Carreira\"},{\"authorId\":null,\"name\":\"Karen Simonyan\"},{\"authorId\":\"11809518\",\"name\":\"Brian Zhang\"},{\"authorId\":null,\"name\":\"Chloe Hillier\"},{\"authorId\":null,\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":null,\"name\":\"Fabio Viola\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8a7d3d284b468d689a2f9efa603b385da627a0f5\",\"title\":\"Supplementary Material Dynamic Inference: A New Approach Toward Efficient Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8a7d3d284b468d689a2f9efa603b385da627a0f5\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1909.09422\",\"authors\":[{\"authorId\":\"50065546\",\"name\":\"W. Price\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.1109/ICCVW.2019.00173\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3c0cf56b33fdca7529ec5bc308060e307c9ae1bc\",\"title\":\"Retro-Actions: Learning 'Close' by Time-Reversing 'Open' Videos\",\"url\":\"https://www.semanticscholar.org/paper/3c0cf56b33fdca7529ec5bc308060e307c9ae1bc\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4439383\",\"name\":\"Jamie Ray\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"35259685\",\"name\":\"Y. Wang\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1007/978-3-030-01264-9_39\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"71167cf519940a7373adc221401c396198763ab0\",\"title\":\"Scenes-Objects-Actions: A Multi-task, Multi-label Video Dataset\",\"url\":\"https://www.semanticscholar.org/paper/71167cf519940a7373adc221401c396198763ab0\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2005.00343\",\"authors\":[{\"authorId\":\"145089978\",\"name\":\"D. Damen\"},{\"authorId\":\"28798386\",\"name\":\"H. Doughty\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"48842721\",\"name\":\"Evangelos Kazakos\"},{\"authorId\":\"3420479\",\"name\":\"D. Moltisanti\"},{\"authorId\":\"47077615\",\"name\":\"J. Munro\"},{\"authorId\":\"2682004\",\"name\":\"T. Perrett\"},{\"authorId\":\"50065546\",\"name\":\"W. Price\"},{\"authorId\":\"145032628\",\"name\":\"Michael Wray\"}],\"doi\":\"10.1109/TPAMI.2020.2991965\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1badccbe4a3cbf8662b924a97bbeea14fe2f1ac7\",\"title\":\"The EPIC-KITCHENS Dataset: Collection, Challenges and Baselines\",\"url\":\"https://www.semanticscholar.org/paper/1badccbe4a3cbf8662b924a97bbeea14fe2f1ac7\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2802283\",\"name\":\"H. Liu\"},{\"authorId\":\"153108488\",\"name\":\"Bin Ren\"},{\"authorId\":\"47842072\",\"name\":\"M. Liu\"},{\"authorId\":\"2705961\",\"name\":\"R. Ding\"}],\"doi\":\"10.1109/ICIP40778.2020.9190958\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"93011a4d810eacfc4ff3202d3c38e78706ff3341\",\"title\":\"Grouped Temporal Enhancement Module for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/93011a4d810eacfc4ff3202d3c38e78706ff3341\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"2001.06127\",\"authors\":[{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"46585209\",\"name\":\"J. Wang\"},{\"authorId\":\"1765212\",\"name\":\"C. Hori\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"}],\"doi\":\"10.1109/WACV45572.2020.9093291\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e73fa178f729097428059af13b916275c7e92331\",\"title\":\"Spatio-Temporal Ranked-Attention Networks for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/e73fa178f729097428059af13b916275c7e92331\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1906.03349\",\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"}],\"doi\":\"10.1109/cvpr42600.2020.00043\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"45a924794b2c6501b671cf4249c6ac4fa1671597\",\"title\":\"Video Modeling With Correlation Networks\",\"url\":\"https://www.semanticscholar.org/paper/45a924794b2c6501b671cf4249c6ac4fa1671597\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47897687\",\"name\":\"H. Tan\"},{\"authorId\":\"47297550\",\"name\":\"Hongyuan Zhu\"},{\"authorId\":\"6516914\",\"name\":\"J. Lim\"},{\"authorId\":\"1694051\",\"name\":\"Cheston Tan\"}],\"doi\":\"10.1016/J.CVIU.2020.103107\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d79912ee3469c1c93f2c726f9a9b4baf7682ec5f\",\"title\":\"A comprehensive survey of procedural video datasets\",\"url\":\"https://www.semanticscholar.org/paper/d79912ee3469c1c93f2c726f9a9b4baf7682ec5f\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2021},{\"arxivId\":\"2012.06977\",\"authors\":[{\"authorId\":\"47203405\",\"name\":\"Wenhao Wu\"},{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"6873935\",\"name\":\"T. Lin\"},{\"authorId\":\"1998948807\",\"name\":\"F. Li\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"12081764\",\"name\":\"E. Ding\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a6e71b58ea6668dd3872e0c9e6cdd258b4582e2a\",\"title\":\"MVFNet: Multi-View Fusion Network for Efficient Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a6e71b58ea6668dd3872e0c9e6cdd258b4582e2a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.10321\",\"authors\":[{\"authorId\":\"50031265\",\"name\":\"Xitong Yang\"},{\"authorId\":\"40058797\",\"name\":\"Xiaodong Yang\"},{\"authorId\":\"2391885\",\"name\":\"Sifei Liu\"},{\"authorId\":\"3232265\",\"name\":\"Deqing Sun\"},{\"authorId\":\"152296574\",\"name\":\"L. Davis\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1cedd24562c1e95415b246a1a0e9912d8de6f0f7\",\"title\":\"Hierarchical Contrastive Motion Learning for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1cedd24562c1e95415b246a1a0e9912d8de6f0f7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1710.07300\",\"authors\":[{\"authorId\":\"3127597\",\"name\":\"S. Kahou\"},{\"authorId\":\"144179710\",\"name\":\"A. Atkinson\"},{\"authorId\":\"1748421\",\"name\":\"Vincent Michalski\"},{\"authorId\":\"2828538\",\"name\":\"\\u00c1kos K\\u00e1d\\u00e1r\"},{\"authorId\":\"3382568\",\"name\":\"Adam Trischler\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"55ca9fe4ae98904bfe026d22dcf1420ff9c0dd86\",\"title\":\"FigureQA: An Annotated Figure Dataset for Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/55ca9fe4ae98904bfe026d22dcf1420ff9c0dd86\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"81781019\",\"name\":\"Minho Shim\"},{\"authorId\":\"40832988\",\"name\":\"Y. H. Kim\"},{\"authorId\":\"32850725\",\"name\":\"Kyungmin Kim\"},{\"authorId\":\"1754380\",\"name\":\"S. Kim\"}],\"doi\":\"10.1007/978-3-030-01267-0_25\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"041115cb5509466f7449451709387268a008aba2\",\"title\":\"Teaching Machines to Understand Baseball Games: Large-Scale Baseball Video Database for Multiple Video Understanding Tasks\",\"url\":\"https://www.semanticscholar.org/paper/041115cb5509466f7449451709387268a008aba2\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1806.11230\",\"authors\":[{\"authorId\":\"145873652\",\"name\":\"Y. Kong\"},{\"authorId\":\"46956675\",\"name\":\"Yun Fu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"025a44bf059aef8b9ee2e6ca598bebefc59a4a61\",\"title\":\"Human Action Recognition and Prediction: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/025a44bf059aef8b9ee2e6ca598bebefc59a4a61\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Roshan Rane\"},{\"authorId\":\"150333998\",\"name\":\"Vageesh Saxena\"},{\"authorId\":\"150096315\",\"name\":\"Edit Sz\\u00fcgyi\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"bc7ea2da9346c1e77215f0fe139e9036996ad05d\",\"title\":\"Video Action Classification Using PredNet\",\"url\":\"https://www.semanticscholar.org/paper/bc7ea2da9346c1e77215f0fe139e9036996ad05d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2004.01278\",\"authors\":[{\"authorId\":\"1397974082\",\"name\":\"Juan-Manuel Perez-Rua\"},{\"authorId\":\"145944235\",\"name\":\"B. Mart\\u00ednez\"},{\"authorId\":\"2171228\",\"name\":\"Xiatian Zhu\"},{\"authorId\":\"3098817\",\"name\":\"Antoine Toisoul\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"145406420\",\"name\":\"Tao Xiang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8fcc3c2e525307f7a694979500dcca09d0f3a830\",\"title\":\"Knowing What, Where and When to Look: Efficient Video Action Modeling with Attention\",\"url\":\"https://www.semanticscholar.org/paper/8fcc3c2e525307f7a694979500dcca09d0f3a830\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1904.11451\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"145878079\",\"name\":\"Vivek Sharma\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"1576263143\",\"name\":\"Jurgen Gall\"},{\"authorId\":\"49157259\",\"name\":\"R. Stiefelhagen\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-030-58558-7_35\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c2fe9e87e31e6fdb2b7bae5f9cc3c2d2612d13a\",\"title\":\"Large Scale Holistic Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/1c2fe9e87e31e6fdb2b7bae5f9cc3c2d2612d13a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1908.03477\",\"authors\":[{\"authorId\":\"145032628\",\"name\":\"Michael Wray\"},{\"authorId\":\"2295553\",\"name\":\"Diane Larlus\"},{\"authorId\":\"1808423\",\"name\":\"G. Csurka\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.1109/ICCV.2019.00054\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ee3ea76cc54ffae2cdd9ef0e91e05f39c9810a15\",\"title\":\"Fine-Grained Action Retrieval Through Multiple Parts-of-Speech Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/ee3ea76cc54ffae2cdd9ef0e91e05f39c9810a15\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2010.01824\",\"authors\":[{\"authorId\":\"144943440\",\"name\":\"Saptarshi Sinha\"},{\"authorId\":\"1743276\",\"name\":\"H. Ohashi\"},{\"authorId\":\"153823664\",\"name\":\"K. Nakamura\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1516fe9eeca6e8bd3d26723f725d222107cb2551\",\"title\":\"Class-Wise Difficulty-Balanced Loss for Solving Class-Imbalance\",\"url\":\"https://www.semanticscholar.org/paper/1516fe9eeca6e8bd3d26723f725d222107cb2551\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.11757\",\"authors\":[{\"authorId\":\"48239920\",\"name\":\"Chun-Fu Chen\"},{\"authorId\":\"1819152\",\"name\":\"R. Panda\"},{\"authorId\":\"40544169\",\"name\":\"K. Ramakrishnan\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"38060482\",\"name\":\"J. M. Cohn\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"33421444\",\"name\":\"Quanfu Fan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f5c2623a44660ad9fe6cd46710fec6e812a3375a\",\"title\":\"Deep Analysis of CNN-based Spatio-temporal Representations for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f5c2623a44660ad9fe6cd46710fec6e812a3375a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145944235\",\"name\":\"B. Mart\\u00ednez\"},{\"authorId\":\"1996209\",\"name\":\"Davide Modolo\"},{\"authorId\":null,\"name\":\"Yuanjun Xiong\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d9266a16e9213b7406968578b5f7a8dde2c15f43\",\"title\":\"Dribbling Basketball Shooting Basketball Dribbling Basketball Shooting Basketball Baking Cookies Peeling Potatos Baking Cookies Peeling Potatos Smoking Eating BurgerSmoking Eating\",\"url\":\"https://www.semanticscholar.org/paper/d9266a16e9213b7406968578b5f7a8dde2c15f43\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3530540\",\"name\":\"Yunbo Wang\"},{\"authorId\":\"144811736\",\"name\":\"L. Jiang\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"35776445\",\"name\":\"Mingsheng Long\"},{\"authorId\":\"3216322\",\"name\":\"L. Fei-Fei\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2eb604863b671763de17905ad715a225d9fe43e9\",\"title\":\"Unit Frame 3 : T + 2 Frame 1 : T Frame 2 : T + 1 FrameT + 1 FrameT + 2 FrameT + 3\",\"url\":\"https://www.semanticscholar.org/paper/2eb604863b671763de17905ad715a225d9fe43e9\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2007.11365\",\"authors\":[{\"authorId\":\"39440469\",\"name\":\"Sudhakar Kumawat\"},{\"authorId\":\"145879750\",\"name\":\"Manisha Verma\"},{\"authorId\":\"1789677\",\"name\":\"Yuta Nakashima\"},{\"authorId\":\"145853779\",\"name\":\"S. Raman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4914a205aa1ddeaae3c86a449c69703c89484f54\",\"title\":\"Depthwise Spatio-Temporal STFT Convolutional Neural Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4914a205aa1ddeaae3c86a449c69703c89484f54\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.07203\",\"authors\":[{\"authorId\":\"3443095\",\"name\":\"Bruno Korbar\"},{\"authorId\":\"40052301\",\"name\":\"F. Petroni\"},{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a2bf96de7889360dce11b9fc80f578a56e63dcfc\",\"title\":\"Video Understanding as Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/a2bf96de7889360dce11b9fc80f578a56e63dcfc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.03137\",\"authors\":[{\"authorId\":\"144652817\",\"name\":\"Xiaohan Wang\"},{\"authorId\":\"47096706\",\"name\":\"Y. Wu\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":null,\"name\":\"Yi Yang\"}],\"doi\":\"10.1609/AAAI.V34I07.6907\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4bca2665f80765d25e71796c928dd20963e0b26e\",\"title\":\"Symbiotic Attention with Privileged Information for Egocentric Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4bca2665f80765d25e71796c928dd20963e0b26e\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2012.02109\",\"authors\":[{\"authorId\":\"2542995\",\"name\":\"T. Kim\"},{\"authorId\":\"1678633\",\"name\":\"Gregory Hager\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"72b19a0125ddda2752cfcf8c5758a13c52275665\",\"title\":\"SAFCAR: Structured Attention Fusion for Compositional Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/72b19a0125ddda2752cfcf8c5758a13c52275665\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1912.00381\",\"authors\":[{\"authorId\":\"1756362\",\"name\":\"Swathikiran Sudhakaran\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"}],\"doi\":\"10.1109/cvpr42600.2020.00118\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"57cee868188127305f966a178ca22025b397d911\",\"title\":\"Gate-Shift Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/57cee868188127305f966a178ca22025b397d911\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"116904712\",\"name\":\"Victor Hugo Cunha de Melo\"},{\"authorId\":\"115399228\",\"name\":\"Jesimon Barreto Santos\"},{\"authorId\":\"112906725\",\"name\":\"Carlos Ant\\u00f4nio Caetano J\\u00fanior\"},{\"authorId\":\"113523735\",\"name\":\"J\\u00e9ssica Sena de Souza\"},{\"authorId\":\"116203497\",\"name\":\"Ot\\u00e1vio Augusto Bizetto Penatti\"},{\"authorId\":\"134872203\",\"name\":\"William Robson Schwartz\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"352931fa3abb7998ce4a4a152799a7a77b16c7b1\",\"title\":\"Object-Based Temporal Segment Relational Network for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/352931fa3abb7998ce4a4a152799a7a77b16c7b1\",\"venue\":\"2018 31st SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39635018\",\"name\":\"Xiaolong Wang\"}],\"doi\":\"10.1184/R1/9823919\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"dcd6c05a5ef1e6d9247f3eb0bff91ac0c3d7ac01\",\"title\":\"Learning and Reasoning with Visual Correspondence in Time\",\"url\":\"https://www.semanticscholar.org/paper/dcd6c05a5ef1e6d9247f3eb0bff91ac0c3d7ac01\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145496509\",\"name\":\"Jie Shao\"},{\"authorId\":\"143993120\",\"name\":\"K. Hu\"},{\"authorId\":\"3393850\",\"name\":\"Yixin Bao\"},{\"authorId\":\"11320042\",\"name\":\"Yining Lin\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"5b3fd234bd072706af99100edba037b13d5a0069\",\"title\":\"High Order Neural Networks for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/5b3fd234bd072706af99100edba037b13d5a0069\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"cc4618ce3811d2d14f23ec28ee462fa040f469c9\",\"title\":\"Interpretable representation learning for visual intelligence\",\"url\":\"https://www.semanticscholar.org/paper/cc4618ce3811d2d14f23ec28ee462fa040f469c9\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8702449\",\"name\":\"Wanneng Wang\"},{\"authorId\":\"47009814\",\"name\":\"Yanan Ma\"},{\"authorId\":\"144947764\",\"name\":\"Ke Gao\"},{\"authorId\":\"152813130\",\"name\":\"J. Cao\"}],\"doi\":\"10.1145/3343031.3350884\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0be689463698d92433b4fd343379a32e763c9f2c\",\"title\":\"Cost-free Transfer Learning Mechanism: Deep Digging Relationships of Action Categories\",\"url\":\"https://www.semanticscholar.org/paper/0be689463698d92433b4fd343379a32e763c9f2c\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52289773\",\"name\":\"Jinhyung Kim\"},{\"authorId\":\"33532407\",\"name\":\"S. Cha\"},{\"authorId\":\"1405197098\",\"name\":\"Dongyoon Wee\"},{\"authorId\":\"40656963\",\"name\":\"Soonmin Bae\"},{\"authorId\":\"1769295\",\"name\":\"Junmo Kim\"}],\"doi\":\"10.1109/cvpr42600.2020.01212\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"96c0ba91d650c571d20961f1fae0560f8962afa5\",\"title\":\"Regularization on Spatio-Temporally Smoothed Feature for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/96c0ba91d650c571d20961f1fae0560f8962afa5\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3159503\",\"name\":\"Evan Racah\"},{\"authorId\":\"12757989\",\"name\":\"C. Beckham\"},{\"authorId\":\"3422058\",\"name\":\"Tegan Maharaj\"},{\"authorId\":\"3127597\",\"name\":\"S. Kahou\"},{\"authorId\":\"1764912\",\"name\":\"Prabhat\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fd0a1a2ecf69a6c1a6efcb18b8f23e4d5402f601\",\"title\":\"ExtremeWeather: A large-scale climate dataset for semi-supervised detection, localization, and understanding of extreme weather events\",\"url\":\"https://www.semanticscholar.org/paper/fd0a1a2ecf69a6c1a6efcb18b8f23e4d5402f601\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"2006.13256\",\"authors\":[{\"authorId\":\"1677780022\",\"name\":\"Dima Damen\"},{\"authorId\":\"28798386\",\"name\":\"H. Doughty\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"},{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"48842721\",\"name\":\"Evangelos Kazakos\"},{\"authorId\":\"153155867\",\"name\":\"Jian Ma\"},{\"authorId\":\"3420479\",\"name\":\"D. Moltisanti\"},{\"authorId\":\"47077615\",\"name\":\"J. Munro\"},{\"authorId\":\"2682004\",\"name\":\"T. Perrett\"},{\"authorId\":\"50065546\",\"name\":\"W. Price\"},{\"authorId\":\"145032628\",\"name\":\"Michael Wray\"}],\"doi\":\"10.5523/bris.2g1n6qdydwa9u22shpxqzp0t8m\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c1a80daadab9c3bc3fdf183c669070ba7a3fd37\",\"title\":\"Rescaling Egocentric Vision\",\"url\":\"https://www.semanticscholar.org/paper/6c1a80daadab9c3bc3fdf183c669070ba7a3fd37\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.15327\",\"authors\":[{\"authorId\":\"48319922\",\"name\":\"A. Bar\"},{\"authorId\":\"46796686\",\"name\":\"Roei Herzig\"},{\"authorId\":\"122024152\",\"name\":\"Xiaolong Wang\"},{\"authorId\":\"1732280\",\"name\":\"Gal Chechik\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"1786843\",\"name\":\"A. Globerson\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"cdc4ae0adcff94e9ea4591f25b81f88c93cb4fbe\",\"title\":\"Compositional Video Synthesis with Action Graphs\",\"url\":\"https://www.semanticscholar.org/paper/cdc4ae0adcff94e9ea4591f25b81f88c93cb4fbe\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.15781\",\"authors\":[{\"authorId\":\"26663607\",\"name\":\"Baoxiong Jia\"},{\"authorId\":\"49069534\",\"name\":\"Yixin Chen\"},{\"authorId\":\"51442394\",\"name\":\"Siyuan Huang\"},{\"authorId\":\"2672448\",\"name\":\"Yixin Zhu\"},{\"authorId\":\"12554898\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1007/978-3-030-58574-7_46\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cd6b1063f234836a1dcdc7f8a39c10c4d8fdbbbe\",\"title\":\"LEMMA: A Multi-view Dataset for Learning Multi-agent Multi-task Activities\",\"url\":\"https://www.semanticscholar.org/paper/cd6b1063f234836a1dcdc7f8a39c10c4d8fdbbbe\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145089978\",\"name\":\"D. Damen\"},{\"authorId\":\"28798386\",\"name\":\"H. Doughty\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"12387007\",\"name\":\"Evangelos Kazakos\"},{\"authorId\":\"3420479\",\"name\":\"D. Moltisanti\"},{\"authorId\":\"47077615\",\"name\":\"J. Munro\"},{\"authorId\":\"2682004\",\"name\":\"T. Perrett\"},{\"authorId\":\"50065546\",\"name\":\"W. Price\"},{\"authorId\":\"145032628\",\"name\":\"Michael Wray\"}],\"doi\":\"10.1007/978-3-030-01225-0_44\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"443b1a20b30f09a2e4d6c47a8a9412a668f615fd\",\"title\":\"Scaling Egocentric Vision: The Dataset\",\"url\":\"https://www.semanticscholar.org/paper/443b1a20b30f09a2e4d6c47a8a9412a668f615fd\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1806.01810\",\"authors\":[{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1007/978-3-030-01228-1_25\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d7cbf2d3ea63d97b699cc04af98fea521459ee75\",\"title\":\"Videos as Space-Time Region Graphs\",\"url\":\"https://www.semanticscholar.org/paper/d7cbf2d3ea63d97b699cc04af98fea521459ee75\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121213082\",\"name\":\"Cao\"},{\"authorId\":\"2547290\",\"name\":\"Jingwei Ji\"},{\"authorId\":\"3451430\",\"name\":\"Zhangjie Cao\"},{\"authorId\":\"4251916\",\"name\":\"C. Chang\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"03f33ad3f994e03b87ee2d1f711087c9efcd8cf6\",\"title\":\"Few-Shot Video Classification via Temporal Alignment Kaidi\",\"url\":\"https://www.semanticscholar.org/paper/03f33ad3f994e03b87ee2d1f711087c9efcd8cf6\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2454800\",\"name\":\"F. Mahdisoltani\"},{\"authorId\":\"40586522\",\"name\":\"Guillaume Berger\"},{\"authorId\":\"3462264\",\"name\":\"Waseem Gharbieh\"},{\"authorId\":\"1793739\",\"name\":\"David J. Fleet\"},{\"authorId\":\"1710604\",\"name\":\"R. Memisevic\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1b71d3f30238cb6621021a95543cce3aab96a21b\",\"title\":\"Fine-grained Video Classification and Captioning\",\"url\":\"https://www.semanticscholar.org/paper/1b71d3f30238cb6621021a95543cce3aab96a21b\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145586191\",\"name\":\"Can Zhang\"},{\"authorId\":\"26981150\",\"name\":\"Yue-Xian Zou\"},{\"authorId\":\"115151196\",\"name\":\"G. Chen\"},{\"authorId\":\"48204311\",\"name\":\"L. Gan\"}],\"doi\":\"10.1145/3343031.3350876\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ab7f7501d889607d6a9aa3f5ea465a8b1c44f7ff\",\"title\":\"PAN: Persistent Appearance Network with an Efficient Motion Cue for Fast Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ab7f7501d889607d6a9aa3f5ea465a8b1c44f7ff\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143798882\",\"name\":\"Mihir Jain\"},{\"authorId\":\"90191889\",\"name\":\"A. Ghodrati\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1109/CVPR42600.2020.00125\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"370298c893ebb3f55c0d869ea68c5ffa1805ca08\",\"title\":\"ActionBytes: Learning From Trimmed Videos to Localize Actions\",\"url\":\"https://www.semanticscholar.org/paper/370298c893ebb3f55c0d869ea68c5ffa1805ca08\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27648874\",\"name\":\"Changmao Cheng\"},{\"authorId\":\"2832147\",\"name\":\"C. Zhang\"},{\"authorId\":\"1732264\",\"name\":\"Y. Wei\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1145/3343031.3351054\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9f18e562481538493d71d7b36eb12270f03d6339\",\"title\":\"Sparse Temporal Causal Convolution for Efficient Action Modeling\",\"url\":\"https://www.semanticscholar.org/paper/9f18e562481538493d71d7b36eb12270f03d6339\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48093549\",\"name\":\"Jinpeng Wang\"},{\"authorId\":\"29995014\",\"name\":\"Shiren Li\"},{\"authorId\":\"30646831\",\"name\":\"Zhi-kui Duan\"},{\"authorId\":\"48803999\",\"name\":\"Z. Yuan\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053794\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a021daf17351415827420456377f77f6a146fd56\",\"title\":\"Rethinking Temporal-Related Sample for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a021daf17351415827420456377f77f6a146fd56\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"2002.07442\",\"authors\":[{\"authorId\":\"50202365\",\"name\":\"S. Zhang\"},{\"authorId\":\"153098982\",\"name\":\"Sheng Guo\"},{\"authorId\":\"49015548\",\"name\":\"Weilin Huang\"},{\"authorId\":\"1915350\",\"name\":\"M. Scott\"},{\"authorId\":\"29461006\",\"name\":\"L. Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"df2f2591054080d069e563cb9ca4e0592bc6df08\",\"title\":\"V4D: 4D Convolutional Neural Networks for Video-level Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/df2f2591054080d069e563cb9ca4e0592bc6df08\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"2011.02543\",\"authors\":[{\"authorId\":\"30621486\",\"name\":\"Stepan Alekseevich Komkov\"},{\"authorId\":\"2007675511\",\"name\":\"Maksim Dzabraev\"},{\"authorId\":\"1380315305\",\"name\":\"Aleksandr Petiushko\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0e0be00a9dac71413ebfca60ea6b40a5d73c5877\",\"title\":\"Mutual Modality Learning for Video Action Classification\",\"url\":\"https://www.semanticscholar.org/paper/0e0be00a9dac71413ebfca60ea6b40a5d73c5877\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1909.04743\",\"authors\":[{\"authorId\":\"15727192\",\"name\":\"Tete Xiao\"},{\"authorId\":\"33421444\",\"name\":\"Quanfu Fan\"},{\"authorId\":\"1891570\",\"name\":\"Dan Gutfreund\"},{\"authorId\":\"95743023\",\"name\":\"Mathew Monfort\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"}],\"doi\":\"10.1109/ICCV.2019.00402\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"98b6d3f69e37e6bf33ea270ac28773d86e778c34\",\"title\":\"Reasoning About Human-Object Interactions Through Dual Attention Networks\",\"url\":\"https://www.semanticscholar.org/paper/98b6d3f69e37e6bf33ea270ac28773d86e778c34\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2011.12372\",\"authors\":[{\"authorId\":\"50065546\",\"name\":\"W. Price\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f6378d6130b82f083882db4c0bf2065b6a3e59b8\",\"title\":\"Play Fair: Frame Attributions in Video Models\",\"url\":\"https://www.semanticscholar.org/paper/f6378d6130b82f083882db4c0bf2065b6a3e59b8\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31162518\",\"name\":\"Xingyu Liu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c93febcfdd1a1bc1fcf0b98c3ff4f998a13a5adb\",\"title\":\"Learning Video Representations from Correspondence Proposals Supplementary Material\",\"url\":\"https://www.semanticscholar.org/paper/c93febcfdd1a1bc1fcf0b98c3ff4f998a13a5adb\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39307390\",\"name\":\"Bugra Tekin\"},{\"authorId\":\"2988774\",\"name\":\"Federica Bogo\"},{\"authorId\":\"88550057\",\"name\":\"Marc Pollefeys\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d39d3de091a3fe65e42a5034e49ce44ee0397a69\",\"title\":\"Unified Egocentric Recognition of 3 D Hand-Object Poses and Interactions\",\"url\":\"https://www.semanticscholar.org/paper/d39d3de091a3fe65e42a5034e49ce44ee0397a69\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2011.07735\",\"authors\":[{\"authorId\":\"40016108\",\"name\":\"Aman Chadha\"},{\"authorId\":\"2025073690\",\"name\":\"Gurneet Arora\"},{\"authorId\":\"2025065763\",\"name\":\"Navpreet Kaloty\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bcffc406b4cc5b179ed973cd7f974c656e129c4f\",\"title\":\"iPerceive: Applying Common-Sense Reasoning to Multi-Modal Dense Video Captioning and Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/bcffc406b4cc5b179ed973cd7f974c656e129c4f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1908.07625\",\"authors\":[{\"authorId\":\"145944235\",\"name\":\"B. Mart\\u00ednez\"},{\"authorId\":\"1996209\",\"name\":\"Davide Modolo\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"2397422\",\"name\":\"Joseph Tighe\"}],\"doi\":\"10.1109/ICCV.2019.00558\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d5a8fbb37f564b397071e016fb39e4c6a612cc83\",\"title\":\"Action Recognition With Spatial-Temporal Discriminative Filter Banks\",\"url\":\"https://www.semanticscholar.org/paper/d5a8fbb37f564b397071e016fb39e4c6a612cc83\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1912.02401\",\"authors\":[{\"authorId\":\"8080821\",\"name\":\"Megha Nawhal\"},{\"authorId\":\"1936990\",\"name\":\"Mengyao Zhai\"},{\"authorId\":\"20812150\",\"name\":\"Andreas M. Lehrmann\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"}],\"doi\":\"10.1007/978-3-030-58610-2_23\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4ebb4985c6da258fe47a63d1f9dc1ae491e6db62\",\"title\":\"Generating Videos of Zero-Shot Compositions of Actions and Objects\",\"url\":\"https://www.semanticscholar.org/paper/4ebb4985c6da258fe47a63d1f9dc1ae491e6db62\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3275727\",\"name\":\"Linxi (Jim) Fan\"},{\"authorId\":\"8983218\",\"name\":\"S. Buch\"},{\"authorId\":\"96374437\",\"name\":\"Guanzhi Wang\"},{\"authorId\":\"2013547017\",\"name\":\"Ryan Cao\"},{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/978-3-030-58529-7_30\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3ab0c5006bb157b801ec592951a1da2c8af9d158\",\"title\":\"RubiksNet: Learnable 3D-Shift for Efficient Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3ab0c5006bb157b801ec592951a1da2c8af9d158\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143793197\",\"name\":\"V. H. Melo\"},{\"authorId\":\"41169967\",\"name\":\"Jesimon Barreto Santos\"},{\"authorId\":\"144289594\",\"name\":\"C. Caetano\"},{\"authorId\":\"40603133\",\"name\":\"J. S. Souza\"},{\"authorId\":\"3131975\",\"name\":\"O. A. B. Penatti\"},{\"authorId\":\"9385043\",\"name\":\"W. Schwartz\"}],\"doi\":\"10.1109/SIBGRAPI.2018.00020\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b6149cedc54f7c199d086abfd254b3f9a8e3cfb2\",\"title\":\"Object-Based Temporal Segment Relational Network for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b6149cedc54f7c199d086abfd254b3f9a8e3cfb2\",\"venue\":\"SIBGRAPI\",\"year\":2018},{\"arxivId\":\"2006.00626\",\"authors\":[{\"authorId\":\"47002659\",\"name\":\"Yanchao Li\"},{\"authorId\":\"1720749879\",\"name\":\"Miao Liu\"},{\"authorId\":\"50779871\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a48cde936f7dea115cbda99a08e12dbdf45d13fb\",\"title\":\"In the Eye of the Beholder: Gaze and Actions in First Person Video\",\"url\":\"https://www.semanticscholar.org/paper/a48cde936f7dea115cbda99a08e12dbdf45d13fb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50202365\",\"name\":\"S. Zhang\"},{\"authorId\":\"153098982\",\"name\":\"Sheng Guo\"},{\"authorId\":\"49015548\",\"name\":\"Weilin Huang\"},{\"authorId\":\"1915350\",\"name\":\"M. Scott\"},{\"authorId\":\"29461006\",\"name\":\"L. Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"60d95b4ed4f6e9ac38441d130d3969597ce4d626\",\"title\":\"V4D: 4D Covolutional Neural Networks for Video-level Representations Learning\",\"url\":\"https://www.semanticscholar.org/paper/60d95b4ed4f6e9ac38441d130d3969597ce4d626\",\"venue\":\"ICLR 2020\",\"year\":2020},{\"arxivId\":\"2012.08510\",\"authors\":[{\"authorId\":\"144234446\",\"name\":\"Bo He\"},{\"authorId\":\"50031265\",\"name\":\"Xitong Yang\"},{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"48444479\",\"name\":\"Hao Chen\"},{\"authorId\":\"38760573\",\"name\":\"Ser-Nam Lim\"},{\"authorId\":\"51453757\",\"name\":\"Abhinav Shrivastava\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b77967866434f46c41f25baf7149d9b027b600b3\",\"title\":\"GTA: Global Temporal Attention for Video Action Understanding\",\"url\":\"https://www.semanticscholar.org/paper/b77967866434f46c41f25baf7149d9b027b600b3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.03462\",\"authors\":[{\"authorId\":\"145586191\",\"name\":\"Can Zhang\"},{\"authorId\":\"26981150\",\"name\":\"Yue-Xian Zou\"},{\"authorId\":\"143930563\",\"name\":\"G. Chen\"},{\"authorId\":\"48204311\",\"name\":\"L. Gan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"60840dce8073545641198c297796902fa390c719\",\"title\":\"PAN: Towards Fast Action Recognition via Learning Persistence of Appearance\",\"url\":\"https://www.semanticscholar.org/paper/60840dce8073545641198c297796902fa390c719\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143995146\",\"name\":\"Hao Huang\"},{\"authorId\":\"48206987\",\"name\":\"L. Zhou\"},{\"authorId\":\"90638604\",\"name\":\"W. Zhang\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3341898f570384ce310445d6f3f0b6c598831a61\",\"title\":\"Dynamic Graph Modules for Modeling Object-Object Interactions in Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3341898f570384ce310445d6f3f0b6c598831a61\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32346302\",\"name\":\"F. Wang\"},{\"authorId\":\"1423415979\",\"name\":\"Guorui Wang\"},{\"authorId\":\"100975725\",\"name\":\"Yunwen Huang\"},{\"authorId\":\"49276987\",\"name\":\"Hao Chu\"}],\"doi\":\"10.1109/ACCESS.2019.2953113\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"65d934938c27585e144660ae7c293d297dddf64b\",\"title\":\"SAST: Learning Semantic Action-Aware Spatial-Temporal Features for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/65d934938c27585e144660ae7c293d297dddf64b\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46945678\",\"name\":\"T. Singh\"},{\"authorId\":\"47731526\",\"name\":\"D. Vishwakarma\"}],\"doi\":\"10.1007/s10462-018-9651-1\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"9018e160b6e73f6816939a37b3e392033d610f09\",\"title\":\"Video benchmarks of human action datasets: a review\",\"url\":\"https://www.semanticscholar.org/paper/9018e160b6e73f6816939a37b3e392033d610f09\",\"venue\":\"Artificial Intelligence Review\",\"year\":2018},{\"arxivId\":\"2003.13158\",\"authors\":[{\"authorId\":\"146108424\",\"name\":\"A. Kukleva\"},{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"}],\"doi\":\"10.1109/cvpr42600.2020.00987\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d57d0c8071378c26967fa428bf339193713b91a5\",\"title\":\"Learning Interactions and Relationships Between Movie Characters\",\"url\":\"https://www.semanticscholar.org/paper/d57d0c8071378c26967fa428bf339193713b91a5\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2010.06647\",\"authors\":[{\"authorId\":\"153634296\",\"name\":\"Matthew Hutchinson\"},{\"authorId\":\"74882299\",\"name\":\"Vijay Gadepally\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"65955a106905afb90a2a2fa74e48c6d6d597892f\",\"title\":\"Video Action Understanding: A Tutorial\",\"url\":\"https://www.semanticscholar.org/paper/65955a106905afb90a2a2fa74e48c6d6d597892f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.06803\",\"authors\":[{\"authorId\":\"46270766\",\"name\":\"Zhaoyang Liu\"},{\"authorId\":\"29461006\",\"name\":\"L. Wang\"},{\"authorId\":\"3096434\",\"name\":\"W. Wu\"},{\"authorId\":\"7350503\",\"name\":\"Chen Qian\"},{\"authorId\":\"144720251\",\"name\":\"Tong Lu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"3ac6ad718bbdeda6b5b00b61983f8b520d8a6bcb\",\"title\":\"TAM: Temporal Adaptive Module for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3ac6ad718bbdeda6b5b00b61983f8b520d8a6bcb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.12204\",\"authors\":[{\"authorId\":\"134814700\",\"name\":\"T. Wang\"},{\"authorId\":\"50560698\",\"name\":\"Jianqiang Huang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"32222907\",\"name\":\"Qianru Sun\"}],\"doi\":\"10.1109/cvpr42600.2020.01077\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d9d0197c6d9304d6bc179ac21370c49a33fc2388\",\"title\":\"Visual Commonsense R-CNN\",\"url\":\"https://www.semanticscholar.org/paper/d9d0197c6d9304d6bc179ac21370c49a33fc2388\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2012.01634\",\"authors\":[{\"authorId\":\"47989608\",\"name\":\"Ankit Goyal\"},{\"authorId\":\"150180131\",\"name\":\"Kaiyu Yang\"},{\"authorId\":\"150084688\",\"name\":\"Dawei Yang\"},{\"authorId\":\"2026954992\",\"name\":\"Jia Deng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c4d3f7ee5ccfefe8e132d5f394a683034b2eeec7\",\"title\":\"Rel3D: A Minimally Contrastive Benchmark for Grounding Spatial Relations in 3D\",\"url\":\"https://www.semanticscholar.org/paper/c4d3f7ee5ccfefe8e132d5f394a683034b2eeec7\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2011.12619\",\"authors\":[{\"authorId\":\"147084112\",\"name\":\"Jack Humphreys\"},{\"authorId\":\"48354826\",\"name\":\"Z. Chen\"},{\"authorId\":\"145047838\",\"name\":\"Dacheng Tao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e88bff50c417703239e0a832fddb267196ab5a99\",\"title\":\"Recent Progress in Appearance-based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e88bff50c417703239e0a832fddb267196ab5a99\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491240780\",\"name\":\"Z. Shi\"},{\"authorId\":\"144962375\",\"name\":\"Cheng Guan\"},{\"authorId\":\"1491233401\",\"name\":\"Liangjie Cao\"},{\"authorId\":\"1632356255\",\"name\":\"Qianqian Li\"},{\"authorId\":\"1993660232\",\"name\":\"Ju Liang\"},{\"authorId\":\"29344734\",\"name\":\"Zhaorui Gu\"},{\"authorId\":\"2336297\",\"name\":\"Haiyong Zheng\"},{\"authorId\":\"1470709309\",\"name\":\"Bing Zheng\"}],\"doi\":\"10.1007/978-3-030-58539-6_23\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c826e169f505f6fda0872d0a3e1e156e15b5111e\",\"title\":\"CoTeRe-Net: Discovering Collaborative Ternary Relations in Videos\",\"url\":\"https://www.semanticscholar.org/paper/c826e169f505f6fda0872d0a3e1e156e15b5111e\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145359181\",\"name\":\"Yang Yi\"},{\"authorId\":\"145688138\",\"name\":\"Feng Ni\"},{\"authorId\":\"15470287\",\"name\":\"Yuexin Ma\"},{\"authorId\":\"22689408\",\"name\":\"Xinge Zhu\"},{\"authorId\":\"35653798\",\"name\":\"Yuankai Qi\"},{\"authorId\":\"51177968\",\"name\":\"Riming Qiu\"},{\"authorId\":\"2946035\",\"name\":\"Shijie Zhao\"},{\"authorId\":\"143806294\",\"name\":\"Feng Li\"},{\"authorId\":null,\"name\":\"Yongtao Wang\"}],\"doi\":\"10.24963/ijcai.2019/141\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"40060755a791a85a6b9c61bd0f5d859b3a3417a6\",\"title\":\"High Performance Gesture Recognition via Effective and Efficient Temporal Modeling\",\"url\":\"https://www.semanticscholar.org/paper/40060755a791a85a6b9c61bd0f5d859b3a3417a6\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143901333\",\"name\":\"Lin Shao\"},{\"authorId\":\"2178889\",\"name\":\"Toki Migimatsu\"},{\"authorId\":\"153441749\",\"name\":\"Q. Zhang\"},{\"authorId\":\"1990958\",\"name\":\"Karen Yang\"},{\"authorId\":\"1775407\",\"name\":\"Jeannette Bohg\"}],\"doi\":\"10.15607/rss.2020.xvi.082\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c328a1ea31eaa4b357e584285ffb6ff2671b5bd4\",\"title\":\"Concept2Robot: Learning Manipulation Concepts from Instructions and Human Demonstrations\",\"url\":\"https://www.semanticscholar.org/paper/c328a1ea31eaa4b357e584285ffb6ff2671b5bd4\",\"venue\":\"RSS 2020\",\"year\":2020},{\"arxivId\":\"2001.06769\",\"authors\":[{\"authorId\":\"151080964\",\"name\":\"Kaiyu Shan\"},{\"authorId\":null,\"name\":\"Yongtao Wang\"},{\"authorId\":\"5744018\",\"name\":\"Z. Wang\"},{\"authorId\":\"47715977\",\"name\":\"Ting-Ting Liang\"},{\"authorId\":null,\"name\":\"Zhi Tang\"},{\"authorId\":\"50581109\",\"name\":\"Y. Chen\"},{\"authorId\":\"1920864\",\"name\":\"Yangyan Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0c09d3844807f4cbed18f5ff5d5df34a89365d07\",\"title\":\"MixTConv: Mixed Temporal Convolutional Kernels for Efficient Action Recogntion\",\"url\":\"https://www.semanticscholar.org/paper/0c09d3844807f4cbed18f5ff5d5df34a89365d07\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.12667\",\"authors\":[{\"authorId\":\"19198894\",\"name\":\"Humam Alwassel\"},{\"authorId\":\"144542135\",\"name\":\"D. Mahajan\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1ee9df4e96f5021509c438751b48d3de07ae8b75\",\"title\":\"Self-Supervised Learning by Cross-Modal Audio-Video Clustering\",\"url\":\"https://www.semanticscholar.org/paper/1ee9df4e96f5021509c438751b48d3de07ae8b75\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"1904.05349\",\"authors\":[{\"authorId\":\"39307390\",\"name\":\"Bugra Tekin\"},{\"authorId\":\"2988774\",\"name\":\"Federica Bogo\"},{\"authorId\":\"1742208\",\"name\":\"M. Pollefeys\"}],\"doi\":\"10.1109/CVPR.2019.00464\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5b94a0ecfb144423ca7c5275a31d0d16f99c84d1\",\"title\":\"H+O: Unified Egocentric Recognition of 3D Hand-Object Poses and Interactions\",\"url\":\"https://www.semanticscholar.org/paper/5b94a0ecfb144423ca7c5275a31d0d16f99c84d1\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3216212\",\"name\":\"Vladyslav Sydorov\"},{\"authorId\":\"72492981\",\"name\":\"Alahari Karteek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"32045707a041e18f7afd2b4e7024f9b0dad75890\",\"title\":\"Focused Attention for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/32045707a041e18f7afd2b4e7024f9b0dad75890\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8080821\",\"name\":\"Megha Nawhal\"},{\"authorId\":\"2453402\",\"name\":\"Meng-Yao Zhai\"},{\"authorId\":\"20812150\",\"name\":\"Andreas M. Lehrmann\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"53ea5e0448c309c3614bba25bac58f46f06690c7\",\"title\":\"Zero-Shot Generation of Human-Object Interaction Videos\",\"url\":\"https://www.semanticscholar.org/paper/53ea5e0448c309c3614bba25bac58f46f06690c7\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1904.05582\",\"authors\":[{\"authorId\":\"50986865\",\"name\":\"A. Nicolicioiu\"},{\"authorId\":\"51011850\",\"name\":\"Iulia Duta\"},{\"authorId\":\"1749627\",\"name\":\"M. Leordeanu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"56d7309ae0fccc0de5b09c3d426e09287498e4c3\",\"title\":\"Recurrent Space-time Graph Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/56d7309ae0fccc0de5b09c3d426e09287498e4c3\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2000153057\",\"name\":\"Zhikang Qiu\"},{\"authorId\":null,\"name\":\"Xu Zhao\"},{\"authorId\":\"49941675\",\"name\":\"Zhilan Hu\"}],\"doi\":\"10.1109/ICIP40778.2020.9190997\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"593fa71e5cad2afcc4b105c45d5ee4eae101bf54\",\"title\":\"Efficient Temporal-Spatial Feature Grouping For Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/593fa71e5cad2afcc4b105c45d5ee4eae101bf54\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"2012.06567\",\"authors\":[{\"authorId\":\"1805946041\",\"name\":\"Yi Zhu\"},{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"49046944\",\"name\":\"C. Liu\"},{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"22539483\",\"name\":\"Chongruo Wu\"},{\"authorId\":\"152781163\",\"name\":\"Z. Zhang\"},{\"authorId\":\"2397422\",\"name\":\"Joseph Tighe\"},{\"authorId\":\"1758550\",\"name\":\"R. Manmatha\"},{\"authorId\":\"49140510\",\"name\":\"M. Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ee12f02830a5e1f7cadd3623dfed495cf099bc82\",\"title\":\"A Comprehensive Study of Deep Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ee12f02830a5e1f7cadd3623dfed495cf099bc82\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.04755\",\"authors\":[{\"authorId\":\"3370667\",\"name\":\"Yongqin Xian\"},{\"authorId\":\"3443095\",\"name\":\"Bruno Korbar\"},{\"authorId\":\"3271933\",\"name\":\"M. Douze\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"2893664\",\"name\":\"Zeynep Akata\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f5f35c39f9e5979a97cd5d4affe40b7cd3f6dd45\",\"title\":\"Generalized Many-Way Few-Shot Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/f5f35c39f9e5979a97cd5d4affe40b7cd3f6dd45\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.06704\",\"authors\":[{\"authorId\":\"27575517\",\"name\":\"Dian Shao\"},{\"authorId\":\"145454812\",\"name\":\"Yue Zhao\"},{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/cvpr42600.2020.00269\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"f5c35edc9cf622c7dd7e19ce6fbd5d563557de5b\",\"title\":\"FineGym: A Hierarchical Video Dataset for Fine-Grained Action Understanding\",\"url\":\"https://www.semanticscholar.org/paper/f5c35edc9cf622c7dd7e19ce6fbd5d563557de5b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1903.10547\",\"authors\":[{\"authorId\":\"145639633\",\"name\":\"Yao-Hung Hubert Tsai\"},{\"authorId\":\"2038685\",\"name\":\"S. Divvala\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"}],\"doi\":\"10.1109/CVPR.2019.01067\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ce079b5a18054eb9434bf7032bcdffb599fd4f6e\",\"title\":\"Video Relationship Reasoning Using Gated Spatio-Temporal Energy Graph\",\"url\":\"https://www.semanticscholar.org/paper/ce079b5a18054eb9434bf7032bcdffb599fd4f6e\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50986865\",\"name\":\"Andrei Liviu Nicolicioiu\"},{\"authorId\":\"51011850\",\"name\":\"Iulia Duta\"},{\"authorId\":\"1749627\",\"name\":\"Marius Leordeanu\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"69309c61e336a32df3569248765e06abd2f35077\",\"title\":\"Recurrent Space-time Graphs for Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/69309c61e336a32df3569248765e06abd2f35077\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2011.06813\",\"authors\":[{\"authorId\":\"50607073\",\"name\":\"V. Petr\\u00edk\"},{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"400ba0f7479067046a4705331fbb31c59e3994f8\",\"title\":\"Learning Object Manipulation Skills via Approximate State Estimation from Real Videos\",\"url\":\"https://www.semanticscholar.org/paper/400ba0f7479067046a4705331fbb31c59e3994f8\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1812.05637\",\"authors\":[{\"authorId\":\"144449335\",\"name\":\"H. Huang\"},{\"authorId\":\"2677364\",\"name\":\"Luowei Zhou\"},{\"authorId\":null,\"name\":\"Wei Zhang\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"15908912ce3943fc5ec281c1cbf062722cb114d7\",\"title\":\"Dynamic Graph Modules for Modeling Higher-Order Interactions in Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/15908912ce3943fc5ec281c1cbf062722cb114d7\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1806.06157\",\"authors\":[{\"authorId\":\"9943923\",\"name\":\"Fabien Baradel\"},{\"authorId\":\"2759569\",\"name\":\"N. Neverova\"},{\"authorId\":\"144899680\",\"name\":\"C. Wolf\"},{\"authorId\":\"1723242\",\"name\":\"J. Mille\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"}],\"doi\":\"10.1007/978-3-030-01261-8_7\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"49615e80bac044b92d2edec8b053965e846486f2\",\"title\":\"Object Level Visual Reasoning in Videos\",\"url\":\"https://www.semanticscholar.org/paper/49615e80bac044b92d2edec8b053965e846486f2\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3127597\",\"name\":\"S. Kahou\"},{\"authorId\":\"1748421\",\"name\":\"Vincent Michalski\"},{\"authorId\":\"144179710\",\"name\":\"A. Atkinson\"},{\"authorId\":\"2828538\",\"name\":\"\\u00c1kos K\\u00e1d\\u00e1r\"},{\"authorId\":\"3382568\",\"name\":\"Adam Trischler\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"cb6be69c67b0b15ebbda89a126f4dd62a4d32958\",\"title\":\"IGURE QA : A N A NNOTATED F IGURE D ATASET FOR V ISUAL R EASONING\",\"url\":\"https://www.semanticscholar.org/paper/cb6be69c67b0b15ebbda89a126f4dd62a4d32958\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1905.12462\",\"authors\":[{\"authorId\":\"1756362\",\"name\":\"Swathikiran Sudhakaran\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"adec3b5b4ebccbdacdcd0c805f7c73501852b3cd\",\"title\":\"Hierarchical Feature Aggregation Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/adec3b5b4ebccbdacdcd0c805f7c73501852b3cd\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2012.05689\",\"authors\":[{\"authorId\":\"1845885740\",\"name\":\"Rui Yan\"},{\"authorId\":\"3041937\",\"name\":\"Lingxi Xie\"},{\"authorId\":\"2287686\",\"name\":\"Xiangbo Shu\"},{\"authorId\":\"8053308\",\"name\":\"J. Tang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f40225f23d46fd15d35b1529427f2f6055c737d4\",\"title\":\"Interactive Fusion of Multi-level Features for Compositional Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f40225f23d46fd15d35b1529427f2f6055c737d4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.00197\",\"authors\":[{\"authorId\":\"29724362\",\"name\":\"Longlong Jing\"},{\"authorId\":\"1807477\",\"name\":\"T. Parag\"},{\"authorId\":\"152247556\",\"name\":\"Zhe Wu\"},{\"authorId\":\"8193125\",\"name\":\"Y. Tian\"},{\"authorId\":\"3254319\",\"name\":\"Hongcheng Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"637b413488ef5b72a3f04089ea3e3c635caab9ee\",\"title\":\"VideoSSL: Semi-Supervised Learning for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/637b413488ef5b72a3f04089ea3e3c635caab9ee\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"144746444\",\"name\":\"H. Bischof\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"},{\"authorId\":\"40454588\",\"name\":\"J. Frahm\"}],\"doi\":\"10.1007/978-3-030-58577-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"08a578d7f7f3d0edf46470e33f92e2335d19b70b\",\"title\":\"Computer Vision \\u2013 ECCV 2020: 16th European Conference, Glasgow, UK, August 23\\u201328, 2020, Proceedings, Part XXX\",\"url\":\"https://www.semanticscholar.org/paper/08a578d7f7f3d0edf46470e33f92e2335d19b70b\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"93318099\",\"name\":\"J. Lin\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1dc7454bacae9a949db38b8306bd7c4df855fa1c\",\"title\":\"TSM: Temporal Shift Module for Efficient Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/1dc7454bacae9a949db38b8306bd7c4df855fa1c\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33685943\",\"name\":\"Mayoore S. Jaiswal\"},{\"authorId\":\"144222336\",\"name\":\"H. P. Hofstee\"},{\"authorId\":\"15110752\",\"name\":\"V. Chen\"},{\"authorId\":\"21080039\",\"name\":\"Suvadip Paul\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"153035546\",\"name\":\"F. Liu\"},{\"authorId\":\"2055404\",\"name\":\"A. Jagannathan\"},{\"authorId\":\"32272278\",\"name\":\"A. Gattiker\"},{\"authorId\":\"152565412\",\"name\":\"Inseok Hwang\"},{\"authorId\":\"48052648\",\"name\":\"J. Lee\"},{\"authorId\":\"11398739\",\"name\":\"M. Tong\"},{\"authorId\":\"1382198044\",\"name\":\"Sahil Dureja\"},{\"authorId\":\"4353428\",\"name\":\"Soham Shah\"}],\"doi\":\"10.1109/ICCVW.2019.00188\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8873d1369590249113e1f0491ce49d1502395b9c\",\"title\":\"Video-Text Compliance: Activity Verification Based on Natural Language Instructions\",\"url\":\"https://www.semanticscholar.org/paper/8873d1369590249113e1f0491ce49d1502395b9c\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"2006.08335\",\"authors\":[{\"authorId\":\"1750913684\",\"name\":\"Bofan Xue\"},{\"authorId\":\"1774825\",\"name\":\"D. Chan\"},{\"authorId\":\"1729041\",\"name\":\"J. Canny\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5ca80f5097b6ad4f4537d913c48abc470fb37342\",\"title\":\"A Dataset and Benchmarks for Multimedia Social Analysis\",\"url\":\"https://www.semanticscholar.org/paper/5ca80f5097b6ad4f4537d913c48abc470fb37342\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1809.03316\",\"authors\":[{\"authorId\":\"2454800\",\"name\":\"F. Mahdisoltani\"},{\"authorId\":\"1710604\",\"name\":\"R. Memisevic\"},{\"authorId\":\"1793739\",\"name\":\"David J. Fleet\"}],\"doi\":\"10.1007/978-3-030-11018-5_53\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"de94c7faeb3e4baf24bde841ff1bf3af6f38a81a\",\"title\":\"Hierarchical Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/de94c7faeb3e4baf24bde841ff1bf3af6f38a81a\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46331912\",\"name\":\"M. Liu\"},{\"authorId\":\"89507637\",\"name\":\"X. Chen\"},{\"authorId\":\"144781413\",\"name\":\"Y. Zhang\"},{\"authorId\":\"48513361\",\"name\":\"Y. Li\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dc7de1c65a52db271016313980ae577d19aace24\",\"title\":\"Paying More Attention to Motion: Attention Distillation for Learning Video Representations\",\"url\":\"https://www.semanticscholar.org/paper/dc7de1c65a52db271016313980ae577d19aace24\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2001.11394\",\"authors\":[{\"authorId\":\"35041003\",\"name\":\"Lichao Mou\"},{\"authorId\":\"51151222\",\"name\":\"Yuansheng Hua\"},{\"authorId\":\"36352940\",\"name\":\"P. Jin\"},{\"authorId\":\"40049070\",\"name\":\"X. Zhu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4a820785df28ee9693001aa5701bba3828229ef0\",\"title\":\"ERA: A Dataset and Deep Learning Benchmark for Event Recognition in Aerial Videos\",\"url\":\"https://www.semanticscholar.org/paper/4a820785df28ee9693001aa5701bba3828229ef0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2244863\",\"name\":\"X. Zhang\"},{\"authorId\":\"1715708\",\"name\":\"Yaping Huang\"},{\"authorId\":\"2035596033\",\"name\":\"Yang Mi\"},{\"authorId\":\"80996783\",\"name\":\"Yanting Pei\"},{\"authorId\":\"2196589\",\"name\":\"Qi Zou\"},{\"authorId\":\"40696794\",\"name\":\"Song Wang\"}],\"doi\":\"10.1007/s10489-020-01905-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ffd6d8c2f114895c3506b8326a0fdb6b8728e901\",\"title\":\"Video sketch: A middle-level representation for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/ffd6d8c2f114895c3506b8326a0fdb6b8728e901\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2001.06499\",\"authors\":[{\"authorId\":\"46798949\",\"name\":\"H. Shao\"},{\"authorId\":\"152230789\",\"name\":\"Shengju Qian\"},{\"authorId\":\"119924269\",\"name\":\"Y. Liu\"}],\"doi\":\"10.1609/AAAI.V34I07.6872\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a573c125e85d1230626c8f3cf6193354f753958d\",\"title\":\"Temporal Interlacing Network\",\"url\":\"https://www.semanticscholar.org/paper/a573c125e85d1230626c8f3cf6193354f753958d\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2012.11866\",\"authors\":[{\"authorId\":\"2595189\",\"name\":\"Zehua Sun\"},{\"authorId\":\"120809631\",\"name\":\"Jiwang Liu\"},{\"authorId\":\"143969578\",\"name\":\"Qiuhong Ke\"},{\"authorId\":\"1877377\",\"name\":\"H. Rahmani\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"816236bf3219363bfe4b847363e137b1fe6712e7\",\"title\":\"Human Action Recognition from Various Data Modalities: A Review\",\"url\":\"https://www.semanticscholar.org/paper/816236bf3219363bfe4b847363e137b1fe6712e7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1907.04632\",\"authors\":[{\"authorId\":\"145439284\",\"name\":\"Wei Peng\"},{\"authorId\":\"46761465\",\"name\":\"Xiaopeng Hong\"},{\"authorId\":\"1757287\",\"name\":\"G. Zhao\"}],\"doi\":\"10.1109/ICIP.2019.8802919\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eabb3eff8811d4aadcdb7c285505295f39ac1613\",\"title\":\"Video Action Recognition Via Neural Architecture Searching\",\"url\":\"https://www.semanticscholar.org/paper/eabb3eff8811d4aadcdb7c285505295f39ac1613\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10029285\",\"name\":\"Nieves Crasto\"},{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"72492981\",\"name\":\"Alahari Karteek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/CVPR.2019.00807\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6e93bd99350bf03acf870f83bb9c7ab1a7d17147\",\"title\":\"MARS: Motion-Augmented RGB Stream for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6e93bd99350bf03acf870f83bb9c7ab1a7d17147\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32486555\",\"name\":\"D. Epstein\"},{\"authorId\":\"8786274\",\"name\":\"Boyuan Chen\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cc6b00a4f43370644f410330ed6d065f7fa38d5b\",\"title\":\"ops Predicting Unintentional Action in Video\",\"url\":\"https://www.semanticscholar.org/paper/cc6b00a4f43370644f410330ed6d065f7fa38d5b\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2420123\",\"name\":\"D. Dwibedi\"},{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"},{\"authorId\":\"2704494\",\"name\":\"J. Tompson\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2e927d0a2dc4b69fc03124ad876329b22a61f1b0\",\"title\":\"Temporal Reasoning in Videos Using Convolutional Gated Recurrent Units\",\"url\":\"https://www.semanticscholar.org/paper/2e927d0a2dc4b69fc03124ad876329b22a61f1b0\",\"venue\":\"CVPR Workshops\",\"year\":2018},{\"arxivId\":\"1712.04851\",\"authors\":[{\"authorId\":\"1817030\",\"name\":\"Saining Xie\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"1808244\",\"name\":\"J. Huang\"},{\"authorId\":\"144035504\",\"name\":\"Zhuowen Tu\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":\"10.1007/978-3-030-01267-0_19\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"815aa52cfc02961d82415f080384594639a21984\",\"title\":\"Rethinking Spatiotemporal Feature Learning: Speed-Accuracy Trade-offs in Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/815aa52cfc02961d82415f080384594639a21984\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2004.03548\",\"authors\":[{\"authorId\":\"49984891\",\"name\":\"Ceyuan Yang\"},{\"authorId\":\"121983635\",\"name\":\"Yinghao Xu\"},{\"authorId\":\"46865320\",\"name\":\"Jianping Shi\"},{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"}],\"doi\":\"10.1109/cvpr42600.2020.00067\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"10db26c80238d70ca51d8a5293d893b6f1dedc8b\",\"title\":\"Temporal Pyramid Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/10db26c80238d70ca51d8a5293d893b6f1dedc8b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e6435837116d2d08d4f873e2b556c29a4d20812d\",\"title\":\"Holistic Large Scale Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/e6435837116d2d08d4f873e2b556c29a4d20812d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1811.08383\",\"authors\":[{\"authorId\":\"46698300\",\"name\":\"Ji Lin\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"143840275\",\"name\":\"Song Han\"}],\"doi\":\"10.1109/ICCV.2019.00718\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4bbfd46721c145852e443ae4aad35148b814bf91\",\"title\":\"TSM: Temporal Shift Module for Efficient Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/4bbfd46721c145852e443ae4aad35148b814bf91\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2003.12798\",\"authors\":[{\"authorId\":\"2156559\",\"name\":\"Qihang Yu\"},{\"authorId\":\"48513320\",\"name\":\"Yingwei Li\"},{\"authorId\":\"10407760\",\"name\":\"Jieru Mei\"},{\"authorId\":\"7743268\",\"name\":\"Yuyin Zhou\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3743c3c7c30d700f37bcd00048af007137517a18\",\"title\":\"CAKES: Channel-wise Automatic KErnel Shrinking for Efficient 3D Network\",\"url\":\"https://www.semanticscholar.org/paper/3743c3c7c30d700f37bcd00048af007137517a18\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.01455\",\"authors\":[{\"authorId\":\"27629992\",\"name\":\"B. Brattoli\"},{\"authorId\":\"40580686\",\"name\":\"Joe Tighe\"},{\"authorId\":\"2096007\",\"name\":\"Fedor Zhdanov\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"3180200\",\"name\":\"Krzysztof Chalupka\"}],\"doi\":\"10.1109/CVPR42600.2020.00467\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c58c4c6ce9ae60dce8b2f6a02c06d086d7c2e545\",\"title\":\"Rethinking Zero-Shot Video Classification: End-to-End Training for Realistic Applications\",\"url\":\"https://www.semanticscholar.org/paper/c58c4c6ce9ae60dce8b2f6a02c06d086d7c2e545\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1912.03330\",\"authors\":[{\"authorId\":\"11529694\",\"name\":\"Xueting Yan\"},{\"authorId\":\"1806773\",\"name\":\"I. Misra\"},{\"authorId\":null,\"name\":\"Abhinav Gupta\"},{\"authorId\":\"2028234\",\"name\":\"Deepti Ghadiyaram\"},{\"authorId\":\"144542135\",\"name\":\"D. Mahajan\"}],\"doi\":\"10.1109/cvpr42600.2020.00654\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4906a09839dcb6ac96a52e06bc7bd613f0482967\",\"title\":\"ClusterFit: Improving Generalization of Visual Representations\",\"url\":\"https://www.semanticscholar.org/paper/4906a09839dcb6ac96a52e06bc7bd613f0482967\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2008.11378\",\"authors\":[{\"authorId\":\"153420733\",\"name\":\"Haozhi Cao\"},{\"authorId\":\"9734988\",\"name\":\"Yuecong Xu\"},{\"authorId\":\"2562263\",\"name\":\"Jianfei Yang\"},{\"authorId\":\"120974533\",\"name\":\"Kezhi Mao\"},{\"authorId\":\"2037059\",\"name\":\"Jian-Xiong Yin\"},{\"authorId\":\"144308998\",\"name\":\"S. See\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c16a94fe31835a67a8cf5e2d4d1076e0037844a9\",\"title\":\"Effective Action Recognition with Embedded Key Point Shifts\",\"url\":\"https://www.semanticscholar.org/paper/c16a94fe31835a67a8cf5e2d4d1076e0037844a9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.04989\",\"authors\":[{\"authorId\":\"153580352\",\"name\":\"Ionut Cosmin Duta\"},{\"authorId\":\"87109212\",\"name\":\"Li Liu\"},{\"authorId\":\"152506137\",\"name\":\"F. Zhu\"},{\"authorId\":\"40799321\",\"name\":\"Ling Shao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5895ad2f9eb6005b17764022080ff26e7f19ba7a\",\"title\":\"Improved Residual Networks for Image and Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5895ad2f9eb6005b17764022080ff26e7f19ba7a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46698300\",\"name\":\"Ji Lin\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"143840277\",\"name\":\"Song Han\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5925a25dfe107c49c636eccb8f9fd1aeef7b438c\",\"title\":\"Temporal Shift Module for Efficient Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/5925a25dfe107c49c636eccb8f9fd1aeef7b438c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2004.00180\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"2683916\",\"name\":\"Lizhi Yang\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fe9d2d14143e13e20cc318d4483a2a750a5ec55b\",\"title\":\"Spatio-Temporal Action Detection with Multi-Object Interaction\",\"url\":\"https://www.semanticscholar.org/paper/fe9d2d14143e13e20cc318d4483a2a750a5ec55b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.10751\",\"authors\":[{\"authorId\":\"46399266\",\"name\":\"Yang Liu\"},{\"authorId\":\"46950892\",\"name\":\"Zhao-yang Lu\"},{\"authorId\":\"46276828\",\"name\":\"J. Li\"},{\"authorId\":\"144954285\",\"name\":\"T. Yang\"},{\"authorId\":\"144299910\",\"name\":\"C. Yao\"}],\"doi\":\"10.1109/TIP.2019.2957930\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"7cfd5817802102b0326243c95ebfe1c8e14427cd\",\"title\":\"Deep Image-to-Video Adaptation and Fusion Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7cfd5817802102b0326243c95ebfe1c8e14427cd\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21570451\",\"name\":\"A. Barbu\"},{\"authorId\":\"145802205\",\"name\":\"D. Mayo\"},{\"authorId\":\"11906991\",\"name\":\"Julian Alverio\"},{\"authorId\":\"46734229\",\"name\":\"William Luo\"},{\"authorId\":\"50844584\",\"name\":\"Christopher Wang\"},{\"authorId\":\"1891570\",\"name\":\"Dan Gutfreund\"},{\"authorId\":\"114497499\",\"name\":\"Josh Tenenbaum\"},{\"authorId\":\"6104312\",\"name\":\"Boris Katz\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"639174f32a71ecfe9041ad05ff30eb39bd4977bf\",\"title\":\"ObjectNet: A large-scale bias-controlled dataset for pushing the limits of object recognition models\",\"url\":\"https://www.semanticscholar.org/paper/639174f32a71ecfe9041ad05ff30eb39bd4977bf\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1903.02930\",\"authors\":[{\"authorId\":\"49513989\",\"name\":\"Antonios Anastasopoulos\"},{\"authorId\":\"9567965\",\"name\":\"Shankar Kumar\"},{\"authorId\":\"39977619\",\"name\":\"H. Liao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4791dc0c4519988536e4846cbb24ae6382b8fdfd\",\"title\":\"Neural Language Modeling with Visual Features\",\"url\":\"https://www.semanticscholar.org/paper/4791dc0c4519988536e4846cbb24ae6382b8fdfd\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145294961\",\"name\":\"L. Chi\"},{\"authorId\":\"9443552\",\"name\":\"G. Tian\"},{\"authorId\":\"145353089\",\"name\":\"Y. Mu\"},{\"authorId\":\"3041937\",\"name\":\"Lingxi Xie\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1145/3343031.3351029\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"933f2a39e35018db2442c08f7603a14a70efb06b\",\"title\":\"Fast Non-Local Neural Networks with Spectral Residual Learning\",\"url\":\"https://www.semanticscholar.org/paper/933f2a39e35018db2442c08f7603a14a70efb06b\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1908.10136\",\"authors\":[{\"authorId\":\"2659862\",\"name\":\"J. Zhang\"},{\"authorId\":\"38083193\",\"name\":\"F. Shen\"},{\"authorId\":\"1390532590\",\"name\":\"Xing Xu\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f0446862cbdf61974e039a85d349d7f7864f42c1\",\"title\":\"Cooperative Cross-Stream Network for Discriminative Action Representation\",\"url\":\"https://www.semanticscholar.org/paper/f0446862cbdf61974e039a85d349d7f7864f42c1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41022447\",\"name\":\"Okan K\\u00f6p\\u00fckl\\u00fc\"},{\"authorId\":\"145512909\",\"name\":\"G. Rigoll\"}],\"doi\":\"10.1109/IPAS.2018.8708895\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a8d9b1780989dcac2c6027ab155dbe8939bda56c\",\"title\":\"Analysis on Temporal Dimension of Inputs for 3D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/a8d9b1780989dcac2c6027ab155dbe8939bda56c\",\"venue\":\"2018 IEEE International Conference on Image Processing, Applications and Systems (IPAS)\",\"year\":2018},{\"arxivId\":\"2009.07420\",\"authors\":[{\"authorId\":\"3671120\",\"name\":\"Yanyi Zhang\"},{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"144555425\",\"name\":\"I. Marsic\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d951f225ab2d64af36e9c44a658ac79c2afde7f3\",\"title\":\"Multi-Label Activity Recognition using Activity-specific Features\",\"url\":\"https://www.semanticscholar.org/paper/d951f225ab2d64af36e9c44a658ac79c2afde7f3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.05224\",\"authors\":[{\"authorId\":\"3795834\",\"name\":\"J. Chung\"},{\"authorId\":\"1940024152\",\"name\":\"C. Wuu\"},{\"authorId\":\"1940708423\",\"name\":\"Hsuan-ru Yang\"},{\"authorId\":\"5068280\",\"name\":\"Yu-Wing Tai\"},{\"authorId\":\"2088295\",\"name\":\"C. Tang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d5635ee061af4321d5de2076d4834a4f96012551\",\"title\":\"HAA500: Human-Centric Atomic Action Dataset with Curated Videos\",\"url\":\"https://www.semanticscholar.org/paper/d5635ee061af4321d5de2076d4834a4f96012551\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.00649\",\"authors\":[{\"authorId\":\"48444479\",\"name\":\"Hao Chen\"},{\"authorId\":\"51453757\",\"name\":\"Abhinav Shrivastava\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1755381c55d8e52e3a72b3f065a5380874597af1\",\"title\":\"Group Ensemble: Learning an Ensemble of ConvNets in a single ConvNet\",\"url\":\"https://www.semanticscholar.org/paper/1755381c55d8e52e3a72b3f065a5380874597af1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1906.11902\",\"authors\":[{\"authorId\":\"150282338\",\"name\":\"Roshan Prakash Rane\"},{\"authorId\":\"1573750032\",\"name\":\"Edit Szugyi\"},{\"authorId\":\"150333998\",\"name\":\"Vageesh Saxena\"},{\"authorId\":\"35280884\",\"name\":\"Andr\\u00e9 Ofner\"},{\"authorId\":\"2983978\",\"name\":\"S. Stober\"}],\"doi\":\"10.1145/3372278.3390694\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"48c39ab475793b349809d7af2d5797bc1e77f48d\",\"title\":\"PredNet and Predictive Coding: A Critical Review\",\"url\":\"https://www.semanticscholar.org/paper/48c39ab475793b349809d7af2d5797bc1e77f48d\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":\"2006.14582\",\"authors\":[{\"authorId\":\"50079897\",\"name\":\"X. Li\"},{\"authorId\":null,\"name\":\"Yali Wang\"},{\"authorId\":\"1491073267\",\"name\":\"Zhipeng Zhou\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1109/cvpr42600.2020.00117\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"da9b802ea051ffb7ef2de0d8d1003944a60bf44c\",\"title\":\"SmallBigNet: Integrating Core and Contextual Views for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/da9b802ea051ffb7ef2de0d8d1003944a60bf44c\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1904.01172\",\"authors\":[{\"authorId\":\"89093987\",\"name\":\"Shane Storks\"},{\"authorId\":\"3193409\",\"name\":\"Qiaozi Gao\"},{\"authorId\":\"1707259\",\"name\":\"J. Y. Chai\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b1832b749528755dfcbe462717f4f5afc07243b8\",\"title\":\"Commonsense Reasoning for Natural Language Understanding: A Survey of Benchmarks, Resources, and Approaches\",\"url\":\"https://www.semanticscholar.org/paper/b1832b749528755dfcbe462717f4f5afc07243b8\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150346803\",\"name\":\"Yaming Cao\"},{\"authorId\":\"92403023\",\"name\":\"Z. Yang\"},{\"authorId\":\"48016729\",\"name\":\"H. Wang\"},{\"authorId\":\"48448888\",\"name\":\"Xiaodong Peng\"},{\"authorId\":\"1712302\",\"name\":\"C. Gao\"},{\"authorId\":\"121704293\",\"name\":\"Yun Li\"}],\"doi\":\"10.1109/ACCESS.2019.2923674\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2ef31ea5d7ff69e2aefc13cb33c9e5370b8be286\",\"title\":\"Template Matching Based on Geometric Invariance in Deep Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/2ef31ea5d7ff69e2aefc13cb33c9e5370b8be286\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145883076\",\"name\":\"S. Rani\"},{\"authorId\":\"1416537783\",\"name\":\"G. Naidu\"},{\"authorId\":\"145394493\",\"name\":\"V. U. Shree\"}],\"doi\":\"10.35940/ijitee.a4677.119119\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ef016ec90c41e30250e091051e183b80d891bd4e\",\"title\":\"A Fine Grainedresearch Over Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ef016ec90c41e30250e091051e183b80d891bd4e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1910.04744\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"479c6913b92335d77e81af95f559508f0e2753e5\",\"title\":\"CATER: A diagnostic dataset for Compositional Actions and TEmporal Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/479c6913b92335d77e81af95f559508f0e2753e5\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"08d9bea632aa3e32fe6b5436b147edacb69e4660\",\"title\":\"POLITECNICO DI TORINO Master of Science in Mathematical Engineering Deep Learning Algorithms for Video Classification: Application on Real-Time Hand Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/08d9bea632aa3e32fe6b5436b147edacb69e4660\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2012.10671\",\"authors\":[{\"authorId\":\"152957752\",\"name\":\"Shreyank N Gowda\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1403581832\",\"name\":\"Laura Sevilla-Lara\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7c062be0a5ba96b5d0cd606d2eeacd768845a116\",\"title\":\"SMART Frame Selection for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7c062be0a5ba96b5d0cd606d2eeacd768845a116\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1911.09435\",\"authors\":[{\"authorId\":\"46270766\",\"name\":\"Zhaoyang Liu\"},{\"authorId\":\"9393671\",\"name\":\"Donghao Luo\"},{\"authorId\":null,\"name\":\"Yabiao Wang\"},{\"authorId\":\"29461006\",\"name\":\"L. Wang\"},{\"authorId\":\"144970872\",\"name\":\"Ying Tai\"},{\"authorId\":\"1978245\",\"name\":\"Chengjie Wang\"},{\"authorId\":\"49298244\",\"name\":\"Jilin Li\"},{\"authorId\":\"1835006\",\"name\":\"Feiyue Huang\"},{\"authorId\":\"144720251\",\"name\":\"Tong Lu\"}],\"doi\":\"10.1609/AAAI.V34I07.6836\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fa3473f1f5d4f19ec6d561e2700a4d88dad4ccf8\",\"title\":\"TEINet: Towards an Efficient Architecture for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fa3473f1f5d4f19ec6d561e2700a4d88dad4ccf8\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"97649752\",\"name\":\"Janghyung Kim\"},{\"authorId\":\"66486335\",\"name\":\"J. Park\"},{\"authorId\":null,\"name\":\"Yoo Tae Kyung\"}],\"doi\":\"10.5909/JBE.2020.25.4.507\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f288d1897111e430b754d6db1cde7e88436fdf93\",\"title\":\"Analysis of Two-Way Communication Virtual Being Technology and Characteristics in the Content Industry\",\"url\":\"https://www.semanticscholar.org/paper/f288d1897111e430b754d6db1cde7e88436fdf93\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40547902\",\"name\":\"L. M. Dang\"},{\"authorId\":\"114915097\",\"name\":\"Kyungbok Min\"},{\"authorId\":\"1878085541\",\"name\":\"Hanxiang Wang\"},{\"authorId\":\"27648067\",\"name\":\"Md. Jalil Piran\"},{\"authorId\":\"115465984\",\"name\":\"Cheol Hee Lee\"},{\"authorId\":\"73078584\",\"name\":\"Hyeonjoon Moon\"}],\"doi\":\"10.1016/j.patcog.2020.107561\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5b6936905a1fcef9af31bdab49ec99581c03fd83\",\"title\":\"Sensor-based and vision-based human activity recognition: A comprehensive survey\",\"url\":\"https://www.semanticscholar.org/paper/5b6936905a1fcef9af31bdab49ec99581c03fd83\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":\"1905.00561\",\"authors\":[{\"authorId\":\"2028234\",\"name\":\"Deepti Ghadiyaram\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"11529694\",\"name\":\"Xueting Yan\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"144542135\",\"name\":\"D. Mahajan\"}],\"doi\":\"10.1109/CVPR.2019.01232\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4cbaea4c21e15312ef2aeb9529a39baa48bbb522\",\"title\":\"Large-Scale Weakly-Supervised Pre-Training for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4cbaea4c21e15312ef2aeb9529a39baa48bbb522\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1712.02310\",\"authors\":[{\"authorId\":\"1786435\",\"name\":\"David F. Fouhey\"},{\"authorId\":\"7987770\",\"name\":\"Weicheng Kuo\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/CVPR.2018.00524\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"729fb92afe3cf7faaae1b079f7c7a2cd39c01dad\",\"title\":\"From Lifestyle Vlogs to Everyday Interactions\",\"url\":\"https://www.semanticscholar.org/paper/729fb92afe3cf7faaae1b079f7c7a2cd39c01dad\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1423743315\",\"name\":\"Theodoros Georgiou\"},{\"authorId\":\"3546791\",\"name\":\"Y. Liu\"},{\"authorId\":\"47482437\",\"name\":\"W. Chen\"},{\"authorId\":\"1731570\",\"name\":\"M. Lew\"}],\"doi\":\"10.1007/s13735-019-00183-w\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"763495e4ce53c989bf7c2910ae8cb51e4469e195\",\"title\":\"A survey of traditional and deep learning-based feature descriptors for high dimensional data in computer vision\",\"url\":\"https://www.semanticscholar.org/paper/763495e4ce53c989bf7c2910ae8cb51e4469e195\",\"venue\":\"International Journal of Multimedia Information Retrieval\",\"year\":2019},{\"arxivId\":\"2003.07637\",\"authors\":[{\"authorId\":\"49724493\",\"name\":\"H. Zhang\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1007/978-3-030-58565-5_15\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"180d7e45e5fc84138039f738830950dd9b7d0e06\",\"title\":\"Motion-Excited Sampler: Video Adversarial Attack with Sparked Prior\",\"url\":\"https://www.semanticscholar.org/paper/180d7e45e5fc84138039f738830950dd9b7d0e06\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50854337\",\"name\":\"D. Xu\"},{\"authorId\":\"145974111\",\"name\":\"Jun Xiao\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"144899815\",\"name\":\"J. Shao\"},{\"authorId\":\"145982709\",\"name\":\"Di Xie\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1109/CVPR.2019.01058\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"558aeb7aa38cfcf8dd9951bfd24cf77972bd09aa\",\"title\":\"Self-Supervised Spatiotemporal Learning via Video Clip Order Prediction\",\"url\":\"https://www.semanticscholar.org/paper/558aeb7aa38cfcf8dd9951bfd24cf77972bd09aa\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2003.08042\",\"authors\":[{\"authorId\":\"66562585\",\"name\":\"Xu Li\"},{\"authorId\":\"46584062\",\"name\":\"Junling Wang\"},{\"authorId\":\"152309767\",\"name\":\"L. Ma\"},{\"authorId\":\"3397429\",\"name\":\"K. Zhang\"},{\"authorId\":\"1568961008\",\"name\":\"Fengzong Lian\"},{\"authorId\":\"2705857\",\"name\":\"Zhanhui Kang\"},{\"authorId\":\"71563118\",\"name\":\"Jinjun Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"786a010cb738fe28bb44fcff790966a380c9da56\",\"title\":\"STH: Spatio-Temporal Hybrid Convolution for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/786a010cb738fe28bb44fcff790966a380c9da56\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1912.00869\",\"authors\":[{\"authorId\":\"33421444\",\"name\":\"Quanfu Fan\"},{\"authorId\":\"48239920\",\"name\":\"Chun-Fu Chen\"},{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"134455051\",\"name\":\"Marco Pistoia\"},{\"authorId\":\"66305116\",\"name\":\"D. Cox\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9c77ffc223e47388155a6e3bf58ae294f51f9ccb\",\"title\":\"More Is Less: Learning Efficient Video Representations by Big-Little Network and Depthwise Temporal Aggregation\",\"url\":\"https://www.semanticscholar.org/paper/9c77ffc223e47388155a6e3bf58ae294f51f9ccb\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1907.08340\",\"authors\":[{\"authorId\":\"1403581832\",\"name\":\"Laura Sevilla-Lara\"},{\"authorId\":\"2815926\",\"name\":\"Shengxin Zha\"},{\"authorId\":\"3305169\",\"name\":\"Zhicheng Yan\"},{\"authorId\":\"28554843\",\"name\":\"Vedanuj Goswami\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8e79a677855462aa55ea252ffb35c8cac1fed26e\",\"title\":\"Only Time Can Tell: Discovering Temporal Data for Temporal Modeling\",\"url\":\"https://www.semanticscholar.org/paper/8e79a677855462aa55ea252ffb35c8cac1fed26e\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1905.05143\",\"authors\":[{\"authorId\":\"13142264\",\"name\":\"Noureldien Hussein\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"144638781\",\"name\":\"A. Smeulders\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d17bc4c3ffcf9e2ecebcae0f5f24f9ee8cc0dcf\",\"title\":\"VideoGraph: Recognizing Minutes-Long Human Activities in Videos\",\"url\":\"https://www.semanticscholar.org/paper/3d17bc4c3ffcf9e2ecebcae0f5f24f9ee8cc0dcf\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2009.08427\",\"authors\":[{\"authorId\":\"51011850\",\"name\":\"Iulia Duta\"},{\"authorId\":\"50986865\",\"name\":\"A. Nicolicioiu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"343f14319d5e34c37eeb86dea88fa82f56715679\",\"title\":\"Dynamic Regions Graph Neural Networks for Spatio-Temporal Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/343f14319d5e34c37eeb86dea88fa82f56715679\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49120765\",\"name\":\"R. Singh\"},{\"authorId\":\"1387052806\",\"name\":\"Ankur Sonawane\"},{\"authorId\":\"33188415\",\"name\":\"R. Srivastava\"}],\"doi\":\"10.1007/s00530-019-00635-7\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"45a7a721cfe3f179c5bf86ae08340b1f38fdde48\",\"title\":\"Recent evolution of modern datasets for human activity recognition: a deep survey\",\"url\":\"https://www.semanticscholar.org/paper/45a7a721cfe3f179c5bf86ae08340b1f38fdde48\",\"venue\":\"Multimedia Systems\",\"year\":2019},{\"arxivId\":\"1905.07861\",\"authors\":[{\"authorId\":\"48779623\",\"name\":\"A. Edwards\"},{\"authorId\":\"1787816\",\"name\":\"C. Isbell\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7b7762973f445fc3e8c15be2f09a5c2da5197e9f\",\"title\":\"Perceptual Values from Observation\",\"url\":\"https://www.semanticscholar.org/paper/7b7762973f445fc3e8c15be2f09a5c2da5197e9f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"144746444\",\"name\":\"H. Bischof\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"},{\"authorId\":\"40454588\",\"name\":\"J. Frahm\"}],\"doi\":\"10.1007/978-3-030-58539-6\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"72eb837c0d113dcdd51e57958e58d48e1759ea0f\",\"title\":\"Computer Vision \\u2013 ECCV 2020: 16th European Conference, Glasgow, UK, August 23\\u201328, 2020, Proceedings, Part VI\",\"url\":\"https://www.semanticscholar.org/paper/72eb837c0d113dcdd51e57958e58d48e1759ea0f\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2011.00826\",\"authors\":[{\"authorId\":null,\"name\":\"Zihao Wang\"},{\"authorId\":\"5739094\",\"name\":\"Chen Lin\"},{\"authorId\":\"1999541581\",\"name\":\"Lu Sheng\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\"},{\"authorId\":\"1388486428\",\"name\":\"Jing Shao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"316931202b0d02d37672a976f43bb1ed479c6877\",\"title\":\"PV-NAS: Practical Neural Architecture Search for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/316931202b0d02d37672a976f43bb1ed479c6877\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49372683\",\"name\":\"Niamul Quader\"},{\"authorId\":\"150152476\",\"name\":\"Juwei Lu\"},{\"authorId\":\"144287598\",\"name\":\"Peng Dai\"},{\"authorId\":\"122009001\",\"name\":\"Wei Li\"}],\"doi\":\"10.1007/978-3-030-58577-8_3\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"080039e68707b483e5c3c27f38660acc1e51ddde\",\"title\":\"Towards Efficient Coarse-to-Fine Networks for Action and Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/080039e68707b483e5c3c27f38660acc1e51ddde\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.09033\",\"authors\":[{\"authorId\":\"16323128\",\"name\":\"Guoxi Huang\"},{\"authorId\":\"1707271\",\"name\":\"Adrian G. Bors\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"215182fe19015d315cae9cd2c39e3a576b7193bf\",\"title\":\"Region-based Non-local Operation for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/215182fe19015d315cae9cd2c39e3a576b7193bf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152142657\",\"name\":\"Y. Tian\"},{\"authorId\":\"1825799769\",\"name\":\"Guangzhao Zhai\"},{\"authorId\":\"97709070\",\"name\":\"Z. Gao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5768e26731fb55edced4193596f6a470d0029ce6\",\"title\":\"Video-ception Network: Towards Multi-Scale Efficient Asymmetric Spatial-Temporal Interactions\",\"url\":\"https://www.semanticscholar.org/paper/5768e26731fb55edced4193596f6a470d0029ce6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.04981\",\"authors\":[{\"authorId\":\"1491233177\",\"name\":\"Yizhou Zhou\"},{\"authorId\":\"6485172\",\"name\":\"Xiaoyan Sun\"},{\"authorId\":\"2820418\",\"name\":\"Chong Luo\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"}],\"doi\":\"10.1109/cvpr42600.2020.00985\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e7ca185e3a4515471c2b9a411da9f264d55ea563\",\"title\":\"Spatiotemporal Fusion in 3D CNNs: A Probabilistic View\",\"url\":\"https://www.semanticscholar.org/paper/e7ca185e3a4515471c2b9a411da9f264d55ea563\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2009.12434\",\"authors\":[{\"authorId\":\"144701907\",\"name\":\"G. Elahi\"},{\"authorId\":\"35964920\",\"name\":\"Yee-Hong Yang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"048de3aa58e86791aa61ae08316e823528ee11f6\",\"title\":\"Online Learnable Keyframe Extraction in Videos and its Application with Semantic Word Vector in Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/048de3aa58e86791aa61ae08316e823528ee11f6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1908.02486\",\"authors\":[{\"authorId\":\"51128181\",\"name\":\"Boyuan Jiang\"},{\"authorId\":\"47446949\",\"name\":\"M. Wang\"},{\"authorId\":\"35893447\",\"name\":\"W. Gan\"},{\"authorId\":\"145717890\",\"name\":\"W. Wu\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\"}],\"doi\":\"10.1109/ICCV.2019.00209\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b812b20192ffac37b03bde0261934a2a8c7fdf47\",\"title\":\"STM: SpatioTemporal and Motion Encoding for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b812b20192ffac37b03bde0261934a2a8c7fdf47\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2454800\",\"name\":\"F. Mahdisoltani\"},{\"authorId\":\"40586522\",\"name\":\"Guillaume Berger\"},{\"authorId\":\"3462264\",\"name\":\"Waseem Gharbieh\"},{\"authorId\":\"1710604\",\"name\":\"R. Memisevic\"},{\"authorId\":\"1793739\",\"name\":\"David J. Fleet\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c59aa01d1859f3b2d0db11b3d768cb3e526b0464\",\"title\":\"The more fine-grained, the better for transfer learning\",\"url\":\"https://www.semanticscholar.org/paper/c59aa01d1859f3b2d0db11b3d768cb3e526b0464\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46796686\",\"name\":\"Roei Herzig\"},{\"authorId\":\"34490455\",\"name\":\"Elad Levi\"},{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"153585940\",\"name\":\"Hang Gao\"},{\"authorId\":\"2041489\",\"name\":\"E. Brosh\"},{\"authorId\":\"17279245\",\"name\":\"X. Wang\"},{\"authorId\":\"1786843\",\"name\":\"A. Globerson\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/ICCVW.2019.00288\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3be602c7c3812397a29c64e544981a362de80f27\",\"title\":\"Spatio-Temporal Action Graph Networks\",\"url\":\"https://www.semanticscholar.org/paper/3be602c7c3812397a29c64e544981a362de80f27\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"89093987\",\"name\":\"Shane Storks\"},{\"authorId\":\"3193409\",\"name\":\"Qiaozi Gao\"},{\"authorId\":\"1707259\",\"name\":\"J. Y. Chai\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e7c75b16563d07069505cd07dd6466d86f6958f9\",\"title\":\"Recent Advances in Natural Language Inference: A Survey of Benchmarks, Resources, and Approaches\",\"url\":\"https://www.semanticscholar.org/paper/e7c75b16563d07069505cd07dd6466d86f6958f9\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1908.00867\",\"authors\":[{\"authorId\":\"50065546\",\"name\":\"W. Price\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dc4b5fd4cf40b765abefb42bca6db1d845e0caa0\",\"title\":\"An Evaluation of Action Recognition Models on EPIC-Kitchens\",\"url\":\"https://www.semanticscholar.org/paper/dc4b5fd4cf40b765abefb42bca6db1d845e0caa0\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405073588\",\"name\":\"Itsaso Rodr\\u00edguez-Moreno\"},{\"authorId\":\"1401677216\",\"name\":\"J. M. Mart\\u00ednez-Otzeta\"},{\"authorId\":\"144286136\",\"name\":\"B. Sierra\"},{\"authorId\":\"24857630\",\"name\":\"I. Rodriguez\"},{\"authorId\":\"95170363\",\"name\":\"E. Jauregi\"}],\"doi\":\"10.3390/s19143160\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"44f1ae791e8e858a9c7060e42d5db76b170b51e0\",\"title\":\"Video Activity Recognition: State-of-the-Art\",\"url\":\"https://www.semanticscholar.org/paper/44f1ae791e8e858a9c7060e42d5db76b170b51e0\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40465774\",\"name\":\"Z. Gao\"},{\"authorId\":\"2028829514\",\"name\":\"Leming Guo\"},{\"authorId\":\"15880069\",\"name\":\"W. Guan\"},{\"authorId\":\"143602033\",\"name\":\"Anan Liu\"},{\"authorId\":\"1744930\",\"name\":\"T. Ren\"},{\"authorId\":\"1788427\",\"name\":\"Shengyong Chen\"}],\"doi\":\"10.1109/TIP.2020.3038372\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6648479157216bee1f31ef9718fcb64eeafa6843\",\"title\":\"A Pairwise Attentive Adversarial Spatiotemporal Network for Cross-Domain Few-Shot Action Recognition-R2\",\"url\":\"https://www.semanticscholar.org/paper/6648479157216bee1f31ef9718fcb64eeafa6843\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2021},{\"arxivId\":\"1912.00998\",\"authors\":[{\"authorId\":\"100880679\",\"name\":\"Chao-Yuan Wu\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"51506875\",\"name\":\"Philipp Krahenbuhl\"}],\"doi\":\"10.1109/cvpr42600.2020.00023\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b8cc28e11900e4d191651ae7234b4dbd129b1007\",\"title\":\"A Multigrid Method for Efficiently Training Video Models\",\"url\":\"https://www.semanticscholar.org/paper/b8cc28e11900e4d191651ae7234b4dbd129b1007\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2012.14950\",\"authors\":[{\"authorId\":\"26959701\",\"name\":\"Hengduo Li\"},{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"51453757\",\"name\":\"Abhinav Shrivastava\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f434d65e76041d3417715791e052255f924d4efc\",\"title\":\"2D or not 2D? Adaptive 3D Convolution Selection for Efficient Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f434d65e76041d3417715791e052255f924d4efc\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2008.09037\",\"authors\":[{\"authorId\":\"153634296\",\"name\":\"Matthew Hutchinson\"},{\"authorId\":\"2331418\",\"name\":\"S. Samsi\"},{\"authorId\":\"3302251\",\"name\":\"W. Arcand\"},{\"authorId\":\"2159806\",\"name\":\"David Bestor\"},{\"authorId\":\"34001612\",\"name\":\"Bill Bergeron\"},{\"authorId\":\"2098646\",\"name\":\"C. Byun\"},{\"authorId\":\"1850501832\",\"name\":\"Micheal Houle\"},{\"authorId\":\"145238688\",\"name\":\"M. Hubbell\"},{\"authorId\":\"145319478\",\"name\":\"Michael J. Jones\"},{\"authorId\":\"3257323\",\"name\":\"J. Kepner\"},{\"authorId\":\"1983355\",\"name\":\"A. Kirby\"},{\"authorId\":\"1684116\",\"name\":\"P. Michaleas\"},{\"authorId\":\"3385550\",\"name\":\"Lauren Milechin\"},{\"authorId\":\"143913450\",\"name\":\"J. Mullen\"},{\"authorId\":\"2417672\",\"name\":\"A. Prout\"},{\"authorId\":\"144557576\",\"name\":\"A. Rosa\"},{\"authorId\":\"2097629\",\"name\":\"Albert Reuther\"},{\"authorId\":\"145378881\",\"name\":\"C. Yee\"},{\"authorId\":\"74882299\",\"name\":\"Vijay Gadepally\"}],\"doi\":\"10.1109/HPEC43674.2020.9286249\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"48b2b54d27898017b48f158eacabe4952a24a870\",\"title\":\"Accuracy and Performance Comparison of Video Action Recognition Approaches\",\"url\":\"https://www.semanticscholar.org/paper/48b2b54d27898017b48f158eacabe4952a24a870\",\"venue\":\"2020 IEEE High Performance Extreme Computing Conference (HPEC)\",\"year\":2020},{\"arxivId\":\"1804.09066\",\"authors\":[{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"145264990\",\"name\":\"K. Singh\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1007/978-3-030-01216-8_43\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"aa63893b34f523973d0692dc74ff22512daac322\",\"title\":\"ECO: Efficient Convolutional Network for Online Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/aa63893b34f523973d0692dc74ff22512daac322\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144015161\",\"name\":\"Y. Fu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"01aecbebc76d494853f6f525f4d285564e697fa7\",\"title\":\"Human Action Recognition and Prediction: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/01aecbebc76d494853f6f525f4d285564e697fa7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1907.09382\",\"authors\":[{\"authorId\":\"145254119\",\"name\":\"Huseyin Coskun\"},{\"authorId\":\"48151137\",\"name\":\"Z. Zia\"},{\"authorId\":\"39307390\",\"name\":\"Bugra Tekin\"},{\"authorId\":\"2988774\",\"name\":\"Federica Bogo\"},{\"authorId\":\"145587209\",\"name\":\"N. Navab\"},{\"authorId\":\"2266326\",\"name\":\"Federico Tombari\"},{\"authorId\":\"1733393\",\"name\":\"H. Sawhney\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"18cb8c24fae3186487b14fdb28b1b2617057198f\",\"title\":\"Domain-Specific Priors and Meta Learning for Low-shot First-Person Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/18cb8c24fae3186487b14fdb28b1b2617057198f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2002.03342\",\"authors\":[{\"authorId\":\"47203405\",\"name\":\"Wenhao Wu\"},{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"145681032\",\"name\":\"Xiao Tan\"},{\"authorId\":\"2869725\",\"name\":\"Shifeng Chen\"},{\"authorId\":null,\"name\":\"Yi Yang\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"}],\"doi\":\"10.1109/CVPRW50498.2020.00346\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"de79226c40767073dea787327637c8415b1bc60a\",\"title\":\"Dynamic Inference: A New Approach Toward Efficient Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/de79226c40767073dea787327637c8415b1bc60a\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"1911.00232\",\"authors\":[{\"authorId\":\"95743023\",\"name\":\"Mathew Monfort\"},{\"authorId\":\"40544169\",\"name\":\"K. Ramakrishnan\"},{\"authorId\":\"50112310\",\"name\":\"Alex Andonian\"},{\"authorId\":\"150937390\",\"name\":\"Barry A. McNamara\"},{\"authorId\":\"118728832\",\"name\":\"A. Lascelles\"},{\"authorId\":\"35654996\",\"name\":\"B. Pan\"},{\"authorId\":\"33421444\",\"name\":\"Quanfu Fan\"},{\"authorId\":\"1891570\",\"name\":\"Dan Gutfreund\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"da0822f776025dd73698adf6ed29ac63302d1a32\",\"title\":\"Multi-Moments in Time: Learning and Interpreting Models for Multi-Action Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/da0822f776025dd73698adf6ed29ac63302d1a32\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2004.01398\",\"authors\":[{\"authorId\":\"48513712\",\"name\":\"Y. Li\"},{\"authorId\":\"102880425\",\"name\":\"Bin Ji\"},{\"authorId\":\"48203223\",\"name\":\"Xintian Shi\"},{\"authorId\":\"98697812\",\"name\":\"J. Zhang\"},{\"authorId\":\"48418655\",\"name\":\"Bin Kang\"},{\"authorId\":\"48170350\",\"name\":\"Limin Wang\"}],\"doi\":\"10.1109/cvpr42600.2020.00099\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1ebeb84e2b8e1182a2b4821c906200ecc49ae187\",\"title\":\"TEA: Temporal Excitation and Aggregation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1ebeb84e2b8e1182a2b4821c906200ecc49ae187\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1705.08421\",\"authors\":[{\"authorId\":\"39599498\",\"name\":\"C. Gu\"},{\"authorId\":\"94567368\",\"name\":\"C. Sun\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"2997956\",\"name\":\"C. Pantofaru\"},{\"authorId\":\"144711958\",\"name\":\"D. Ross\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"1758054\",\"name\":\"Y. Li\"},{\"authorId\":\"2262946\",\"name\":\"S. Ricco\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"153652146\",\"name\":\"J. Malik\"}],\"doi\":\"10.1109/CVPR.2018.00633\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"54c7c3909c7e1e827befdbe8d2595a3b196ba1b8\",\"title\":\"AVA: A Video Dataset of Spatio-Temporally Localized Atomic Visual Actions\",\"url\":\"https://www.semanticscholar.org/paper/54c7c3909c7e1e827befdbe8d2595a3b196ba1b8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1811.07519\",\"authors\":[{\"authorId\":\"143993120\",\"name\":\"K. Hu\"},{\"authorId\":\"1681921\",\"name\":\"B. Raj\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"41ab8c0c47dd8fce41dbe904ab78ed1a7320dfd6\",\"title\":\"Higher-order Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/41ab8c0c47dd8fce41dbe904ab78ed1a7320dfd6\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1845611487\",\"name\":\"L. Chen\"},{\"authorId\":null,\"name\":\"Liu Rui\"},{\"authorId\":null,\"name\":\"Zhou Dongsheng\"},{\"authorId\":null,\"name\":\"Xin Yang\"},{\"authorId\":null,\"name\":\"Qiang Zhang\"},{\"authorId\":null,\"name\":\"Wei Xiaopeng\"}],\"doi\":\"10.1007/978-3-030-63426-1_1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"62295aaed70cb1e3a40b732e7c92748258cb4ec0\",\"title\":\"ESENet: A Human Behavior Recognition Model Based on Extended Squeeze-and-Excitation Network\",\"url\":\"https://www.semanticscholar.org/paper/62295aaed70cb1e3a40b732e7c92748258cb4ec0\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2007.11460\",\"authors\":[{\"authorId\":\"152142657\",\"name\":\"Y. Tian\"},{\"authorId\":\"144826391\",\"name\":\"Guangtao Zhai\"},{\"authorId\":\"97709070\",\"name\":\"Z. Gao\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d11a695680f0fd0004e1b8b74a0e2f29e7002246\",\"title\":\"Perceptron Synthesis Network: Rethinking the Action Scale Variances in Videos\",\"url\":\"https://www.semanticscholar.org/paper/d11a695680f0fd0004e1b8b74a0e2f29e7002246\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491240780\",\"name\":\"Z. Shi\"},{\"authorId\":\"1491233401\",\"name\":\"Liangjie Cao\"},{\"authorId\":\"153747406\",\"name\":\"Cheng Guan\"},{\"authorId\":\"1993660232\",\"name\":\"Ju Liang\"},{\"authorId\":\"48934241\",\"name\":\"Qianqian Li\"},{\"authorId\":\"29344734\",\"name\":\"Zhaorui Gu\"},{\"authorId\":\"2336297\",\"name\":\"Haiyong Zheng\"},{\"authorId\":\"49721778\",\"name\":\"Bing Zheng\"}],\"doi\":\"10.1145/3394171.3413646\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c0d5f622f775d02e90b715b80485dbcab250e7bd\",\"title\":\"Multi-Group Multi-Attention: Towards Discriminative Spatiotemporal Representation\",\"url\":\"https://www.semanticscholar.org/paper/c0d5f622f775d02e90b715b80485dbcab250e7bd\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47077615\",\"name\":\"J. Munro\"},{\"authorId\":\"1677780022\",\"name\":\"Dima Damen\"}],\"doi\":\"10.1109/cvpr42600.2020.00020\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"646a256e30cd244b668660c32b529ff31a874a78\",\"title\":\"Multi-Modal Domain Adaptation for Fine-Grained Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/646a256e30cd244b668660c32b529ff31a874a78\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2012.09856\",\"authors\":[{\"authorId\":\"47060433\",\"name\":\"Zhe Cao\"},{\"authorId\":\"30407997\",\"name\":\"Ilija Radosavovic\"},{\"authorId\":\"20615377\",\"name\":\"A. Kanazawa\"},{\"authorId\":\"153652147\",\"name\":\"J. Malik\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"217b100fbee9a50e49583498f46a07f9e3d33016\",\"title\":\"Reconstructing Hand-Object Interactions in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/217b100fbee9a50e49583498f46a07f9e3d33016\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2101.00820\",\"authors\":[{\"authorId\":\"38057121\",\"name\":\"Yang Liu\"},{\"authorId\":\"3170394\",\"name\":\"Keze Wang\"},{\"authorId\":\"95686817\",\"name\":\"Haoyuan Lan\"},{\"authorId\":null,\"name\":\"Liang Lin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"66bf88cfa5ecd1e46ab67e8afc55dce4e6fd3aca\",\"title\":\"Temporal Contrastive Graph for Self-supervised Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/66bf88cfa5ecd1e46ab67e8afc55dce4e6fd3aca\",\"venue\":\"\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10029285\",\"name\":\"Nieves Crasto\"},{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"72492981\",\"name\":\"Alahari Karteek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"47e1b171fab52368f14f41955cdc7ca7775ded58\",\"title\":\"RGB TVL 1 Flow RGB + TVL 1 FlowMARS MARS + RGB MERS MERS + RGB Accuracy vs Time on MiniKinetics\",\"url\":\"https://www.semanticscholar.org/paper/47e1b171fab52368f14f41955cdc7ca7775ded58\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2011.13367\",\"authors\":[{\"authorId\":\"32590713\",\"name\":\"A. Deli\\u00e8ge\"},{\"authorId\":\"51006998\",\"name\":\"A. Cioppa\"},{\"authorId\":\"22314218\",\"name\":\"Silvio Giancola\"},{\"authorId\":\"1752865048\",\"name\":\"M. J. Seikavandi\"},{\"authorId\":\"9714545\",\"name\":\"J. V. Dueholm\"},{\"authorId\":\"1803459\",\"name\":\"Kamal Nasrollahi\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"1700569\",\"name\":\"T. Moeslund\"},{\"authorId\":\"46541168\",\"name\":\"Marc Van Droogenbroeck\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"16282981d35e696afc70724b6cc6a186a404fe92\",\"title\":\"SoccerNet-v2 : A Dataset and Benchmarks for Holistic Understanding of Broadcast Soccer Videos\",\"url\":\"https://www.semanticscholar.org/paper/16282981d35e696afc70724b6cc6a186a404fe92\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34041171\",\"name\":\"Akshaya Ramaswamy\"},{\"authorId\":\"49294154\",\"name\":\"J. Gubbi\"},{\"authorId\":\"46390096\",\"name\":\"P. Balamuralidhar\"}],\"doi\":\"10.1109/IJCNN48605.2020.9207305\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9429f5afe3edb33c870f9ed2041a0cf3b968bb5d\",\"title\":\"Video object segmentation using spatio-temporal deep network\",\"url\":\"https://www.semanticscholar.org/paper/9429f5afe3edb33c870f9ed2041a0cf3b968bb5d\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":\"2005.02113\",\"authors\":[{\"authorId\":\"47892681\",\"name\":\"Haoxin Li\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"},{\"authorId\":\"1401057385\",\"name\":\"Yu Tao\"},{\"authorId\":\"37403439\",\"name\":\"H. Hu\"},{\"authorId\":\"153224231\",\"name\":\"Jianhuang Lai\"}],\"doi\":\"10.1109/CVPR42600.2020.00060\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5c02af517dff2ff0d34dee04535731b7d252bbbb\",\"title\":\"Adaptive Interaction Modeling via Graph Operations Search\",\"url\":\"https://www.semanticscholar.org/paper/5c02af517dff2ff0d34dee04535731b7d252bbbb\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1596808016\",\"name\":\"Xiaohan Wang\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"50118837\",\"name\":\"Y. Wu\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1109/tpami.2020.3015894\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7401d3895e1cb78c34fa25db12409fdff56b1661\",\"title\":\"Symbiotic Attention for Egocentric Action Recognition with Object-centric Alignment.\",\"url\":\"https://www.semanticscholar.org/paper/7401d3895e1cb78c34fa25db12409fdff56b1661\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"1807.06980\",\"authors\":[{\"authorId\":\"3060081\",\"name\":\"A. Ghodrati\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"33240704f9efc39f75b4229983c2e10a56ca609f\",\"title\":\"Video Time: Properties, Encoders and Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/33240704f9efc39f75b4229983c2e10a56ca609f\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92599875\",\"name\":\"M. Nadeem\"},{\"authorId\":\"1828728\",\"name\":\"V. N. L. Franqueira\"},{\"authorId\":\"1881146\",\"name\":\"X. Zhai\"},{\"authorId\":\"1741168\",\"name\":\"F. Kurugollu\"}],\"doi\":\"10.1109/ACCESS.2019.2924733\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"255485196a869c98aacce60a86074fccf07c01eb\",\"title\":\"A Survey of Deep Learning Solutions for Multimedia Visual Content Analysis\",\"url\":\"https://www.semanticscholar.org/paper/255485196a869c98aacce60a86074fccf07c01eb\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1804.09235\",\"authors\":[{\"authorId\":\"2454800\",\"name\":\"F. Mahdisoltani\"},{\"authorId\":\"40586522\",\"name\":\"Guillaume Berger\"},{\"authorId\":\"3462264\",\"name\":\"Waseem Gharbieh\"},{\"authorId\":\"143673251\",\"name\":\"D. Fleet\"},{\"authorId\":\"1710604\",\"name\":\"R. Memisevic\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"26106bcf799c66d719e0cdde6d9fbd3f7eb55e13\",\"title\":\"ON THE EFFECTIVENESS OF TASK GRANULARITY FOR TRANSFER LEARNING\",\"url\":\"https://www.semanticscholar.org/paper/26106bcf799c66d719e0cdde6d9fbd3f7eb55e13\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1911.11206\",\"authors\":[{\"authorId\":\"32486555\",\"name\":\"D. Epstein\"},{\"authorId\":\"8786274\",\"name\":\"Boyuan Chen\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"}],\"doi\":\"10.1109/cvpr42600.2020.00100\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2324d55ec54b9a12c4ac5353c51bcfa8440f7b6a\",\"title\":\"Oops! Predicting Unintentional Action in Video\",\"url\":\"https://www.semanticscholar.org/paper/2324d55ec54b9a12c4ac5353c51bcfa8440f7b6a\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1905.07853\",\"authors\":[{\"authorId\":\"31162518\",\"name\":\"Xingyu Liu\"},{\"authorId\":\"1926578\",\"name\":\"Joon-Young Lee\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"}],\"doi\":\"10.1109/CVPR.2019.00440\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"66c21a179824037becb94105cafea75c746ad89a\",\"title\":\"Learning Video Representations From Correspondence Proposals\",\"url\":\"https://www.semanticscholar.org/paper/66c21a179824037becb94105cafea75c746ad89a\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2007.09933\",\"authors\":[{\"authorId\":\"30557120\",\"name\":\"Heeseung Kwon\"},{\"authorId\":\"16142867\",\"name\":\"Manjin Kim\"},{\"authorId\":\"2483916\",\"name\":\"Suha Kwak\"},{\"authorId\":\"72643925\",\"name\":\"Minsu Cho\"}],\"doi\":\"10.1007/978-3-030-58517-4_21\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b5be8a78db1631159500e7cee249729820e355b2\",\"title\":\"MotionSqueeze: Neural Motion Feature Learning for Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/b5be8a78db1631159500e7cee249729820e355b2\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2012.00317\",\"authors\":[{\"authorId\":\"3445691\",\"name\":\"Youngwan Lee\"},{\"authorId\":\"2645625\",\"name\":\"H. Kim\"},{\"authorId\":\"35323281\",\"name\":\"Kimin Yun\"},{\"authorId\":\"3035146\",\"name\":\"Jinyoung Moon\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"87b2f4542659801ab5b4baddbd88b2a7d1296726\",\"title\":\"Diverse Temporal Aggregation and Depthwise Spatiotemporal Factorization for Efficient Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/87b2f4542659801ab5b4baddbd88b2a7d1296726\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1908.09995\",\"authors\":[{\"authorId\":\"2659862\",\"name\":\"J. Zhang\"},{\"authorId\":\"38083193\",\"name\":\"F. Shen\"},{\"authorId\":\"1390532590\",\"name\":\"Xing Xu\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1109/TIP.2020.2985219\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f3b9458522b828c39b1a7d7a9ffa15eae0789bfc\",\"title\":\"Temporal Reasoning Graph for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f3b9458522b828c39b1a7d7a9ffa15eae0789bfc\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"2008.02531\",\"authors\":[{\"authorId\":\"143657833\",\"name\":\"Li Tao\"},{\"authorId\":\"1524733293\",\"name\":\"Xueting Wang\"},{\"authorId\":\"145572095\",\"name\":\"T. Yamasaki\"}],\"doi\":\"10.1145/3394171.3413694\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"de4e13d7fa8de21e7a09b4ce3f6245ee4e13102c\",\"title\":\"Self-supervised Video Representation Learning Using Inter-intra Contrastive Framework\",\"url\":\"https://www.semanticscholar.org/paper/de4e13d7fa8de21e7a09b4ce3f6245ee4e13102c\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3005105\",\"name\":\"Youngkyoon Jang\"},{\"authorId\":\"49300666\",\"name\":\"Brian T. Sullivan\"},{\"authorId\":\"40626572\",\"name\":\"Casimir J H Ludwig\"},{\"authorId\":\"2283822\",\"name\":\"I. Gilchrist\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"},{\"authorId\":\"1398236231\",\"name\":\"W. Mayol-Cuevas\"}],\"doi\":\"10.1109/ICCVW.2019.00547\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e5d1234f99d3c6b9c0dc7545e030cac5a56ffc3f\",\"title\":\"EPIC-Tent: An Egocentric Video Dataset for Camping Tent Assembly\",\"url\":\"https://www.semanticscholar.org/paper/e5d1234f99d3c6b9c0dc7545e030cac5a56ffc3f\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1811.12238\",\"authors\":[{\"authorId\":\"48669017\",\"name\":\"Siyu Huang\"},{\"authorId\":\"3493929\",\"name\":\"Zhi-Qi Cheng\"},{\"authorId\":\"115821065\",\"name\":\"Xi Li\"},{\"authorId\":\"145749204\",\"name\":\"Xiao Wu\"},{\"authorId\":\"9338907\",\"name\":\"Z. Zhang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"188ab311ef518ac996c5277f4878e3dfa5d1f5d6\",\"title\":\"Perceiving Physical Equation by Observing Visual Scenarios\",\"url\":\"https://www.semanticscholar.org/paper/188ab311ef518ac996c5277f4878e3dfa5d1f5d6\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1906.03857\",\"authors\":[{\"authorId\":null,\"name\":\"Yufei Wang\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1732879\",\"name\":\"Lorenzo Torresani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"425c33485b32301df75d16cb9cd224763782da8c\",\"title\":\"UniDual: A Unified Model for Image and Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/425c33485b32301df75d16cb9cd224763782da8c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1804.02748\",\"authors\":[{\"authorId\":\"145089978\",\"name\":\"D. Damen\"},{\"authorId\":\"28798386\",\"name\":\"H. Doughty\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"12387007\",\"name\":\"Evangelos Kazakos\"},{\"authorId\":\"3420479\",\"name\":\"D. Moltisanti\"},{\"authorId\":\"47077615\",\"name\":\"J. Munro\"},{\"authorId\":\"2682004\",\"name\":\"T. Perrett\"},{\"authorId\":\"50065546\",\"name\":\"W. Price\"},{\"authorId\":\"145032628\",\"name\":\"Michael Wray\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fc50c9392fd23b6c88915177c6ae904a498aacea\",\"title\":\"Scaling Egocentric Vision: The EPIC-KITCHENS Dataset\",\"url\":\"https://www.semanticscholar.org/paper/fc50c9392fd23b6c88915177c6ae904a498aacea\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2007.12887\",\"authors\":[{\"authorId\":\"26415158\",\"name\":\"Xinqi Zhu\"},{\"authorId\":\"153250308\",\"name\":\"C. Xu\"},{\"authorId\":\"102853050\",\"name\":\"L. Hui\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/ICCV.2019.00359\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7303ce1fe8f54f45e4558eb81368bda9dfe2793f\",\"title\":\"Approximated Bilinear Modules for Temporal Modeling\",\"url\":\"https://www.semanticscholar.org/paper/7303ce1fe8f54f45e4558eb81368bda9dfe2793f\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1904.02811\",\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"}],\"doi\":\"10.1109/ICCV.2019.00565\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"f4852f5385d60e8870e30db5c65392d120e58574\",\"title\":\"Video Classification With Channel-Separated Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/f4852f5385d60e8870e30db5c65392d120e58574\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1807.10037\",\"authors\":[{\"authorId\":\"2647624\",\"name\":\"Myunggi Lee\"},{\"authorId\":\"51151436\",\"name\":\"Seungeui Lee\"},{\"authorId\":\"9044475\",\"name\":\"Sung Joon Son\"},{\"authorId\":\"51136389\",\"name\":\"G. Park\"},{\"authorId\":\"3160425\",\"name\":\"N. Kwak\"}],\"doi\":\"10.1007/978-3-030-01249-6_24\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"10a1dcbe52547146fa4735274e8c89ae01e70a55\",\"title\":\"Motion Feature Network: Fixed Motion Filter for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/10a1dcbe52547146fa4735274e8c89ae01e70a55\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1805.07550\",\"authors\":[{\"authorId\":\"3162023\",\"name\":\"Xiaokai Chen\"},{\"authorId\":\"144947766\",\"name\":\"Ke Gao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a6dee5bb3ff1b44f160259fa57815fa980b05659\",\"title\":\"DenseImage Network: Video Spatial-Temporal Evolution Encoding and Understanding\",\"url\":\"https://www.semanticscholar.org/paper/a6dee5bb3ff1b44f160259fa57815fa980b05659\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1911.11319\",\"authors\":[{\"authorId\":\"1384480816\",\"name\":\"Pingchuan Ma\"},{\"authorId\":\"120026268\",\"name\":\"Yao Zhou\"},{\"authorId\":null,\"name\":\"Yu Lu\"},{\"authorId\":\"1726357\",\"name\":\"Wayne Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3b5829a65c4eb19ec8922a1575c6900d5f94046f\",\"title\":\"Learning Efficient Video Representation with Video Shuffle Networks\",\"url\":\"https://www.semanticscholar.org/paper/3b5829a65c4eb19ec8922a1575c6900d5f94046f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1909.05165\",\"authors\":[{\"authorId\":\"41022447\",\"name\":\"Okan K\\u00f6p\\u00fckl\\u00fc\"},{\"authorId\":\"32240536\",\"name\":\"Fabian Herzog\"},{\"authorId\":\"145512909\",\"name\":\"G. Rigoll\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6dbf4b5b49ccfa082a3b3c8a3d42713784d3ef1b\",\"title\":\"Comparative Analysis of CNN-based Spatiotemporal Reasoning in Videos\",\"url\":\"https://www.semanticscholar.org/paper/6dbf4b5b49ccfa082a3b3c8a3d42713784d3ef1b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2011.08652\",\"authors\":[{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"2025664854\",\"name\":\"Emad Bahrami Rad\"},{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"2199924\",\"name\":\"M. Noroozi\"},{\"authorId\":\"46408185\",\"name\":\"E. Adeli\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"80ddd8e76480aa92aa071d33c624af7195b0b762\",\"title\":\"3D CNNs with Adaptive Temporal Feature Resolutions\",\"url\":\"https://www.semanticscholar.org/paper/80ddd8e76480aa92aa071d33c624af7195b0b762\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.11040\",\"authors\":[{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"2521776\",\"name\":\"B. Shuai\"},{\"authorId\":\"2397422\",\"name\":\"Joseph Tighe\"}],\"doi\":\"10.1007/978-3-030-58539-6_17\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c40990d00633b63caf78082f8570a55e2ec5abbb\",\"title\":\"Directional Temporal Modeling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c40990d00633b63caf78082f8570a55e2ec5abbb\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1906.11415\",\"authors\":[{\"authorId\":\"48865984\",\"name\":\"Kaidi Cao\"},{\"authorId\":\"2547290\",\"name\":\"Jingwei Ji\"},{\"authorId\":\"3451430\",\"name\":\"Zhangjie Cao\"},{\"authorId\":\"4251916\",\"name\":\"C. Chang\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/cvpr42600.2020.01063\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ede7829b3f057a874c513919d19307e2b60ead23\",\"title\":\"Few-Shot Video Classification via Temporal Alignment\",\"url\":\"https://www.semanticscholar.org/paper/ede7829b3f057a874c513919d19307e2b60ead23\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2004.05214\",\"authors\":[{\"authorId\":\"152298373\",\"name\":\"Sergiu Oprea\"},{\"authorId\":\"1410236705\",\"name\":\"P. Martinez-Gonzalez\"},{\"authorId\":\"1397392435\",\"name\":\"Alberto Garcia-Garcia\"},{\"authorId\":\"1410269918\",\"name\":\"John Alejandro Castro-Vargas\"},{\"authorId\":\"1405686926\",\"name\":\"S. Orts-Escolano\"},{\"authorId\":\"1429069120\",\"name\":\"J. Garci\\u0301a-Rodri\\u0301guez\"},{\"authorId\":\"1689415\",\"name\":\"Antonis A. Argyros\"}],\"doi\":\"10.1109/TPAMI.2020.3045007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ded24959bbd7715073fa700d5898cdbb2b8353f7\",\"title\":\"A Review on Deep Learning Techniques for Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/ded24959bbd7715073fa700d5898cdbb2b8353f7\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020}],\"corpusId\":834612,\"doi\":\"10.1109/ICCV.2017.622\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":70,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"b68811a9b5cafe4795a11c1048541750068b7ad0\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"17173992\",\"name\":\"B. Wrobel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"339093c7ed71919ce59a7e78979a77abd25bad0c\",\"title\":\"Multiple View Geometry in Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/339093c7ed71919ce59a7e78979a77abd25bad0c\",\"venue\":\"K\\u00fcnstliche Intell.\",\"year\":2001},{\"arxivId\":\"1409.4842\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"46641766\",\"name\":\"W. Liu\"},{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"},{\"authorId\":\"48840704\",\"name\":\"Scott Reed\"},{\"authorId\":\"1838674\",\"name\":\"Dragomir Anguelov\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"39863668\",\"name\":\"Andrew Rabinovich\"}],\"doi\":\"10.1109/CVPR.2015.7298594\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"title\":\"Going deeper with convolutions\",\"url\":\"https://www.semanticscholar.org/paper/e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1412.6604\",\"authors\":[{\"authorId\":\"1706809\",\"name\":\"Marc'Aurelio Ranzato\"},{\"authorId\":\"3149531\",\"name\":\"Arthur Szlam\"},{\"authorId\":\"143627859\",\"name\":\"Joan Bruna\"},{\"authorId\":\"143949035\",\"name\":\"Micha\\u00ebl Mathieu\"},{\"authorId\":\"2939803\",\"name\":\"Ronan Collobert\"},{\"authorId\":\"3295092\",\"name\":\"S. Chopra\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"355f98e4827a1b6ad3f29d07ea2bcf9ad078295c\",\"title\":\"Video (language) modeling: a baseline for generative models of natural videos\",\"url\":\"https://www.semanticscholar.org/paper/355f98e4827a1b6ad3f29d07ea2bcf9ad078295c\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/ICCV.2015.510\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"title\":\"Learning Spatiotemporal Features with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143634377\",\"name\":\"H. Levesque\"},{\"authorId\":\"144883814\",\"name\":\"E. Davis\"},{\"authorId\":\"40429476\",\"name\":\"L. Morgenstern\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"128cb6b891aee1b5df099acb48e2efecfcff689f\",\"title\":\"The Winograd Schema Challenge\",\"url\":\"https://www.semanticscholar.org/paper/128cb6b891aee1b5df099acb48e2efecfcff689f\",\"venue\":\"KR\",\"year\":2011},{\"arxivId\":\"1501.02530\",\"authors\":[{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1721168\",\"name\":\"Niket Tandon\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1109/CVPR.2015.7298940\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a5ea0da7b93452bec54b5034706f2255bfb5a8f3\",\"title\":\"A dataset for Movie Description\",\"url\":\"https://www.semanticscholar.org/paper/a5ea0da7b93452bec54b5034706f2255bfb5a8f3\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47237027\",\"name\":\"Andreas Geiger\"},{\"authorId\":\"37108776\",\"name\":\"Philip Lenz\"},{\"authorId\":\"1760556\",\"name\":\"C. Stiller\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"}],\"doi\":\"10.1177/0278364913491297\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"79b949d9b35c3f51dd20fb5c746cc81fc87147eb\",\"title\":\"Vision meets robotics: The KITTI dataset\",\"url\":\"https://www.semanticscholar.org/paper/79b949d9b35c3f51dd20fb5c746cc81fc87147eb\",\"venue\":\"Int. J. Robotics Res.\",\"year\":2013},{\"arxivId\":\"1502.07209\",\"authors\":[{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"49606697\",\"name\":\"J. Wang\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1109/TPAMI.2017.2670560\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1a0a01c78b746f44575f0c4f297e1621eb212dde\",\"title\":\"Exploiting Feature and Class Relationships in Video Categorization with Regularized Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/1a0a01c78b746f44575f0c4f297e1621eb212dde\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"35198686\",\"name\":\"Joseph J. Lim\"},{\"authorId\":\"1777054\",\"name\":\"H. Zhang\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"}],\"doi\":\"10.5244/C.30.39\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"099b097ecbadf722489f2ff9c1a1fcfc28ac7dbb\",\"title\":\"Physics 101: Learning Physical Object Properties from Unlabeled Videos\",\"url\":\"https://www.semanticscholar.org/paper/099b097ecbadf722489f2ff9c1a1fcfc28ac7dbb\",\"venue\":\"BMVC\",\"year\":2016},{\"arxivId\":\"1511.04590\",\"authors\":[{\"authorId\":\"145095579\",\"name\":\"L. Yao\"},{\"authorId\":\"2482072\",\"name\":\"Nicolas Ballas\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"47088868\",\"name\":\"Joshua R. Smith\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":\"10.5244/C.30.141\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"16aac81ae033f7295d82e5b679400d105170a3e1\",\"title\":\"Oracle Performance for Visual Captioning\",\"url\":\"https://www.semanticscholar.org/paper/16aac81ae033f7295d82e5b679400d105170a3e1\",\"venue\":\"BMVC\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2712738\",\"name\":\"C. Sch\\u00fcldt\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"3033284\",\"name\":\"B. Caputo\"}],\"doi\":\"10.1109/icpr.2004.1334462\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b480f6a3750b4cebaf1db205692c8321d45926a2\",\"title\":\"Recognizing human actions: a local SVM approach\",\"url\":\"https://www.semanticscholar.org/paper/b480f6a3750b4cebaf1db205692c8321d45926a2\",\"venue\":\"Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004.\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123135459\",\"name\":\"Mikel D. Rodriguez\"},{\"authorId\":\"144643948\",\"name\":\"Javed Ahmed\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/CVPR.2008.4587727\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1c2629d53fd73ee42fb9a67b4d656688ef6a005f\",\"title\":\"Action MACH a spatio-temporal Maximum Average Correlation Height filter for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/1c2629d53fd73ee42fb9a67b4d656688ef6a005f\",\"venue\":\"2008 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2008},{\"arxivId\":\"1604.01360\",\"authors\":[{\"authorId\":\"34026610\",\"name\":\"Lerrel Pinto\"},{\"authorId\":\"3393217\",\"name\":\"Dhiraj Gandhi\"},{\"authorId\":\"2164288\",\"name\":\"Yuanfeng Han\"},{\"authorId\":\"1783778\",\"name\":\"Yong-Lae Park\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1007/978-3-319-46475-6_1\",\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"d93ececdc44e7700cd84fc75ca069125022d8c9d\",\"title\":\"The Curious Robot: Learning Visual Representations via Physical Interactions\",\"url\":\"https://www.semanticscholar.org/paper/d93ececdc44e7700cd84fc75ca069125022d8c9d\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3502855\",\"name\":\"M. Marszalek\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/cvprw.2009.5206557\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1fd485daa491c0debcd900b3f6bc141c3883812d\",\"title\":\"Actions in context\",\"url\":\"https://www.semanticscholar.org/paper/1fd485daa491c0debcd900b3f6bc141c3883812d\",\"venue\":\"2009 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2009},{\"arxivId\":\"1403.6382\",\"authors\":[{\"authorId\":\"2835963\",\"name\":\"A. Razavian\"},{\"authorId\":\"2622491\",\"name\":\"H. Azizpour\"},{\"authorId\":\"50626295\",\"name\":\"J. Sullivan\"},{\"authorId\":\"144719278\",\"name\":\"S. Carlsson\"}],\"doi\":\"10.1109/CVPRW.2014.131\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6270baedeba28001cd1b563a199335720d6e0fe0\",\"title\":\"CNN Features Off-the-Shelf: An Astounding Baseline for Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6270baedeba28001cd1b563a199335720d6e0fe0\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition Workshops\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/CVPR.2015.7298698\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0a28efacb92d16e6e0dd4d87b5aca91b28be8853\",\"title\":\"ActivityNet: A large-scale video benchmark for human activity understanding\",\"url\":\"https://www.semanticscholar.org/paper/0a28efacb92d16e6e0dd4d87b5aca91b28be8853\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1603.01312\",\"authors\":[{\"authorId\":\"1977806\",\"name\":\"A. Lerer\"},{\"authorId\":\"39793298\",\"name\":\"S. Gross\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b9dd7a59a101fcecc6fe0e7aed517e84a7df7d2e\",\"title\":\"Learning Physical Intuition of Block Towers by Example\",\"url\":\"https://www.semanticscholar.org/paper/b9dd7a59a101fcecc6fe0e7aed517e84a7df7d2e\",\"venue\":\"ICML\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J. Donahue\"},{\"authorId\":null,\"name\":\"Y. Jia\"},{\"authorId\":null,\"name\":\"O. Vinyals\"},{\"authorId\":null,\"name\":\"J. Hoffman\"},{\"authorId\":null,\"name\":\"N. Zhang\"},{\"authorId\":null,\"name\":\"E. Tzeng\"},{\"authorId\":null,\"name\":\"T. Darrell\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Decaf: A deep convolutional acti- 1. Pouring [something]\",\"url\":\"\",\"venue\":\"arXiv preprint arXiv:1310.1531,\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"40404576\",\"name\":\"S. Amin\"},{\"authorId\":\"1906895\",\"name\":\"M. Andriluka\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1109/CVPR.2012.6247801\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"49435aab7cdf259335725acc96691f755e436f55\",\"title\":\"A database for fine grained activity detection of cooking activities\",\"url\":\"https://www.semanticscholar.org/paper/49435aab7cdf259335725acc96691f755e436f55\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J. Wu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Computational perception of physical object properties\",\"url\":\"\",\"venue\":\"Master\\u2019s thesis, Massachusetts Institute of Technology,\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152281547\",\"name\":\"J. Lawler\"},{\"authorId\":\"3223477\",\"name\":\"G. Lakoff\"},{\"authorId\":\"48389783\",\"name\":\"M. Johnson\"}],\"doi\":\"10.2307/414069\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1456fba651c261326d8cbec451aca4925092141f\",\"title\":\"Metaphors We Live by\",\"url\":\"https://www.semanticscholar.org/paper/1456fba651c261326d8cbec451aca4925092141f\",\"venue\":\"\",\"year\":1983},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":\"10.1109/CVPR.2016.339\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d9671ec394ec374021702642713aa634b8556312\",\"title\":\"Harnessing Object and Scene Semantics for Large-Scale Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/d9671ec394ec374021702642713aa634b8556312\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"D. Hofstadter\"},{\"authorId\":null,\"name\":\"D. R. Hofstadter\"},{\"authorId\":null,\"name\":\"E. Sander\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Surfaces and Essences\",\"url\":\"\",\"venue\":\"Basic Books,\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"47680287\",\"name\":\"W. Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2009.5206848\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"1b47265245e8db53a553049dcb27ed3e495fd625\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/1b47265245e8db53a553049dcb27ed3e495fd625\",\"venue\":\"CVPR 2009\",\"year\":2009},{\"arxivId\":\"1705.00754\",\"authors\":[{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"1382195702\",\"name\":\"Kenji Hata\"},{\"authorId\":\"3260219\",\"name\":\"F. Ren\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/ICCV.2017.83\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"96dd1fc39a368d23291816d57763bc6eb4f7b8d6\",\"title\":\"Dense-Captioning Events in Videos\",\"url\":\"https://www.semanticscholar.org/paper/96dd1fc39a368d23291816d57763bc6eb4f7b8d6\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"2373952\",\"name\":\"J. Louradour\"},{\"authorId\":\"2939803\",\"name\":\"Ronan Collobert\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":\"10.1145/1553374.1553380\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8de174ab5419b9d3127695405efd079808e956e8\",\"title\":\"Curriculum learning\",\"url\":\"https://www.semanticscholar.org/paper/8de174ab5419b9d3127695405efd079808e956e8\",\"venue\":\"ICML '09\",\"year\":2009},{\"arxivId\":\"1606.07419\",\"authors\":[{\"authorId\":\"33932184\",\"name\":\"Pulkit Agrawal\"},{\"authorId\":\"3422774\",\"name\":\"Ashvin Nair\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":null,\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"8cf83c619423a1504f26495d5f6a495054c46462\",\"title\":\"Learning to Poke by Poking: Experiential Learning of Intuitive Physics\",\"url\":\"https://www.semanticscholar.org/paper/8cf83c619423a1504f26495d5f6a495054c46462\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1610.03708\",\"authors\":[{\"authorId\":\"34698604\",\"name\":\"H. Heuer\"},{\"authorId\":\"1696402\",\"name\":\"Christof Monz\"},{\"authorId\":\"144638781\",\"name\":\"A. Smeulders\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"904949e9bf204c275ce366237ec1d3ebcf864a1a\",\"title\":\"Generating captions without looking beyond objects\",\"url\":\"https://www.semanticscholar.org/paper/904949e9bf204c275ce366237ec1d3ebcf864a1a\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123532317\",\"name\":\"Robert Greene\"},{\"authorId\":\"143716922\",\"name\":\"G. Lakoff\"},{\"authorId\":\"49808097\",\"name\":\"M. Johnson\"}],\"doi\":\"10.2307/2906247\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"848f30b5eaefd93a6849cd878c4893a379c53690\",\"title\":\"Metaphors We Live by\",\"url\":\"https://www.semanticscholar.org/paper/848f30b5eaefd93a6849cd878c4893a379c53690\",\"venue\":\"\",\"year\":1981},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1109/CVPR.2011.5995347\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0302bb2d5476540cfb21467473f5eca843caf90b\",\"title\":\"Unbiased look at dataset bias\",\"url\":\"https://www.semanticscholar.org/paper/0302bb2d5476540cfb21467473f5eca843caf90b\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":\"1605.09304\",\"authors\":[{\"authorId\":\"151414531\",\"name\":\"Anh M Nguyen\"},{\"authorId\":\"2841331\",\"name\":\"A. Dosovitskiy\"},{\"authorId\":\"2965424\",\"name\":\"J. Yosinski\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"},{\"authorId\":\"2552141\",\"name\":\"J. Clune\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e1ce8d00729f9e61eeb315f3cbd7b5354706adbd\",\"title\":\"Synthesizing the preferred inputs for neurons in neural networks via deep generator networks\",\"url\":\"https://www.semanticscholar.org/paper/e1ce8d00729f9e61eeb315f3cbd7b5354706adbd\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"152821938\",\"name\":\"Sanketh Shetty\"},{\"authorId\":\"120906511\",\"name\":\"T. Leung\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2014.223\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"title\":\"Large-Scale Video Classification with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1710604\",\"name\":\"R. Memisevic\"}],\"doi\":\"10.1109/TPAMI.2013.53\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f282338fa4cd5516cdcd33cd4b6034f9739c45f4\",\"title\":\"Learning to Relate Images\",\"url\":\"https://www.semanticscholar.org/paper/f282338fa4cd5516cdcd33cd4b6034f9739c45f4\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145971173\",\"name\":\"J. Xu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/CVPR.2016.571\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b8e2e9f3ba008e28257195ec69a00e07f260131d\",\"title\":\"MSR-VTT: A Large Video Description Dataset for Bridging Video and Language\",\"url\":\"https://www.semanticscholar.org/paper/b8e2e9f3ba008e28257195ec69a00e07f260131d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1310.1531\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"50196944\",\"name\":\"Judy Hoffman\"},{\"authorId\":null,\"name\":\"Ning Zhang\"},{\"authorId\":\"2368132\",\"name\":\"E. Tzeng\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b8de958fead0d8a9619b55c7299df3257c624a96\",\"title\":\"DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b8de958fead0d8a9619b55c7299df3257c624a96\",\"venue\":\"ICML\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2485529\",\"name\":\"Michaela Regneri\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"24138684\",\"name\":\"Dominikus Wetzel\"},{\"authorId\":\"1727272\",\"name\":\"Stefan Thater\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"1717560\",\"name\":\"Manfred Pinkal\"}],\"doi\":\"10.1162/tacl_a_00207\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"21b3007f967d39e1346bc91e0fc8b3f16121300c\",\"title\":\"Grounding Action Descriptions in Videos\",\"url\":\"https://www.semanticscholar.org/paper/21b3007f967d39e1346bc91e0fc8b3f16121300c\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2013},{\"arxivId\":\"1503.01070\",\"authors\":[{\"authorId\":\"1730844\",\"name\":\"Atousa Torabi\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b1ddb2994e49a6a4f45e878c1cda7562b03177e6\",\"title\":\"Using Descriptive Video Services to Create a Large Data Source for Video Annotation Research\",\"url\":\"https://www.semanticscholar.org/paper/b1ddb2994e49a6a4f45e878c1cda7562b03177e6\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1604.01753\",\"authors\":[{\"authorId\":\"34280810\",\"name\":\"Gunnar A. Sigurdsson\"},{\"authorId\":\"2668759\",\"name\":\"G. Varol\"},{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1007/978-3-319-46448-0_31\",\"intent\":[\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"21334d1aac5422da88780f8e24e181bfa15ef0e1\",\"title\":\"Hollywood in Homes: Crowdsourcing Data Collection for Activity Understanding\",\"url\":\"https://www.semanticscholar.org/paper/21334d1aac5422da88780f8e24e181bfa15ef0e1\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064210\",\"name\":\"Mark Yatskar\"},{\"authorId\":\"1982950\",\"name\":\"Luke Zettlemoyer\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"}],\"doi\":\"10.1109/CVPR.2016.597\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b65faba7088864e134e7eb3b68c8e2f18cc5b4f6\",\"title\":\"Situation Recognition: Visual Semantic Role Labeling for Image Understanding\",\"url\":\"https://www.semanticscholar.org/paper/b65faba7088864e134e7eb3b68c8e2f18cc5b4f6\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1504.08023\",\"authors\":[{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"2367683\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0fb3b63090f95af97723efe565893eb25ea9188c\",\"title\":\"Anticipating the future by watching unlabeled video\",\"url\":\"https://www.semanticscholar.org/paper/0fb3b63090f95af97723efe565893eb25ea9188c\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1748421\",\"name\":\"Vincent Michalski\"},{\"authorId\":\"1710604\",\"name\":\"R. Memisevic\"},{\"authorId\":\"35254095\",\"name\":\"Kishore Reddy Konda\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"544b80ef13bb0d4288c6a1f50c504c03d3a14d37\",\"title\":\"Modeling Deep Temporal Dependencies with Recurrent \\\"Grammar Cells\\\"\",\"url\":\"https://www.semanticscholar.org/paper/544b80ef13bb0d4288c6a1f50c504c03d3a14d37\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012}],\"title\":\"The \\u201cSomething Something\\u201d Video Database for Learning and Evaluating Visual Common Sense\",\"topics\":[{\"topic\":\"ImageNet\",\"topicId\":\"256302\",\"url\":\"https://www.semanticscholar.org/topic/256302\"},{\"topic\":\"Natural language\",\"topicId\":\"1911\",\"url\":\"https://www.semanticscholar.org/topic/1911\"},{\"topic\":\"Crowdsourcing\",\"topicId\":\"85\",\"url\":\"https://www.semanticscholar.org/topic/85\"},{\"topic\":\"Commonsense knowledge (artificial intelligence)\",\"topicId\":\"326287\",\"url\":\"https://www.semanticscholar.org/topic/326287\"},{\"topic\":\"High- and low-level\",\"topicId\":\"33507\",\"url\":\"https://www.semanticscholar.org/topic/33507\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"}],\"url\":\"https://www.semanticscholar.org/paper/b68811a9b5cafe4795a11c1048541750068b7ad0\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017}\n"