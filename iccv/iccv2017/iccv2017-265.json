"{\"abstract\":\"Video super-resolution (SR) aims to generate a highresolution (HR) frame from multiple low-resolution (LR) frames in a local temporal window. The inter-frame temporal relation is as crucial as the intra-frame spatial relation for tackling this problem. However, how to utilize temporal information efficiently and effectively remains challenging since complex motion is difficult to model and can introduce adverse effects if not handled properly. We address this problem from two aspects. First, we propose a temporal adaptive neural network that can adaptively determine the optimal scale of temporal dependency. Filters on various temporal scales are applied to the input LR sequence before their responses are adaptively aggregated. Second, we reduce the complexity of motion between neighboring frames using a spatial alignment network which is much more robust and efficient than competing alignment methods and can be jointly trained with the temporal adaptive network in an end-to-end manner. Our proposed models with learned temporal dynamics are systematically evaluated on public video datasets and achieve state-of-the-art SR results compared with other recent video SR approaches. Both of the temporal adaptation and the spatial alignment modules are demonstrated to considerably improve SR quality over their plain counterparts.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"1771885\",\"name\":\"Ding Liu\",\"url\":\"https://www.semanticscholar.org/author/1771885\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\",\"url\":\"https://www.semanticscholar.org/author/8056043\"},{\"authorId\":\"7888497\",\"name\":\"Yuchen Fan\",\"url\":\"https://www.semanticscholar.org/author/7888497\"},{\"authorId\":\"1958191\",\"name\":\"X. Liu\",\"url\":\"https://www.semanticscholar.org/author/1958191\"},{\"authorId\":\"2969311\",\"name\":\"Zhangyang Wang\",\"url\":\"https://www.semanticscholar.org/author/2969311\"},{\"authorId\":\"3307026\",\"name\":\"S. Chang\",\"url\":\"https://www.semanticscholar.org/author/3307026\"},{\"authorId\":\"1739208\",\"name\":\"T. Huang\",\"url\":\"https://www.semanticscholar.org/author/1739208\"}],\"citationVelocity\":40,\"citations\":[{\"arxivId\":\"1811.09150\",\"authors\":[{\"authorId\":\"3202418\",\"name\":\"Xiandong Meng\"},{\"authorId\":\"50588131\",\"name\":\"Xuan Deng\"},{\"authorId\":\"1719428\",\"name\":\"Shuyuan Zhu\"},{\"authorId\":\"2202149\",\"name\":\"Shuaicheng Liu\"},{\"authorId\":\"40505809\",\"name\":\"C. Wang\"},{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"145530876\",\"name\":\"B. Zeng\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5efccc8d53f24bb50204f43e45713efacb4b417c\",\"title\":\"MGANet: A Robust Model for Quality Enhancement of Compressed Video\",\"url\":\"https://www.semanticscholar.org/paper/5efccc8d53f24bb50204f43e45713efacb4b417c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jiajia Lei\"},{\"authorId\":null,\"name\":\"Xiaohai He\"},{\"authorId\":null,\"name\":\"Chao Ren\"},{\"authorId\":null,\"name\":\"Xiaohong Wu\"},{\"authorId\":null,\"name\":\"Yi Wang\"}],\"doi\":\"10.1117/1.JEI.29.6.063016\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cc0a593577bb978c1e1477f2479e8f071a706997\",\"title\":\"Video super-resolution network via enhanced deep feature extraction and residual up-down block\",\"url\":\"https://www.semanticscholar.org/paper/cc0a593577bb978c1e1477f2479e8f071a706997\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32464128\",\"name\":\"Mengyu Chu\"},{\"authorId\":\"9071227\",\"name\":\"You Xie\"},{\"authorId\":\"1388407684\",\"name\":\"L. Leal-Taix\\u00e9\"},{\"authorId\":\"1786445\",\"name\":\"N. Th\\u00fcrey\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1ad368a4f1e6585b4abe355ed4c7f68601ab162a\",\"title\":\"Temporally Coherent GANs for Video Super-Resolution (TecoGAN)\",\"url\":\"https://www.semanticscholar.org/paper/1ad368a4f1e6585b4abe355ed4c7f68601ab162a\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2094891\",\"name\":\"K. Hayat\"}],\"doi\":\"10.1016/j.dsp.2018.07.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0677dd5377895b3c61cea0e6a143f38b84f1ebd7\",\"title\":\"Multimedia super-resolution via deep learning: A survey\",\"url\":\"https://www.semanticscholar.org/paper/0677dd5377895b3c61cea0e6a143f38b84f1ebd7\",\"venue\":\"Digit. Signal Process.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"13031879\",\"name\":\"Huiqun Li\"},{\"authorId\":\"2352456\",\"name\":\"Z. Xiong\"},{\"authorId\":\"145459175\",\"name\":\"Zhan Shi\"},{\"authorId\":\"7974176\",\"name\":\"L. Wang\"},{\"authorId\":\"1718355\",\"name\":\"Dong Liu\"},{\"authorId\":null,\"name\":\"Feng Wu\"}],\"doi\":\"10.1109/ICIP.2018.8451511\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"902fddd7fb91e7ef6a526856bc7ef54ed49f2443\",\"title\":\"HSVCNN: CNN-Based Hyperspectral Reconstruction from RGB Videos\",\"url\":\"https://www.semanticscholar.org/paper/902fddd7fb91e7ef6a526856bc7ef54ed49f2443\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":\"1909.10692\",\"authors\":[{\"authorId\":\"46395796\",\"name\":\"H. Wang\"},{\"authorId\":\"1390593685\",\"name\":\"Dewei Su\"},{\"authorId\":\"123266263\",\"name\":\"Chuangchuang Liu\"},{\"authorId\":\"40534966\",\"name\":\"Longcun Jin\"},{\"authorId\":\"2303260\",\"name\":\"Xianfang Sun\"},{\"authorId\":\"9245443\",\"name\":\"Xinyi Peng\"}],\"doi\":\"10.1109/ACCESS.2019.2958030\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d9a44c29cf55c0713905dbe2f46ee418d17895e4\",\"title\":\"Deformable Non-Local Network for Video Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/d9a44c29cf55c0713905dbe2f46ee418d17895e4\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1903.10128\",\"authors\":[{\"authorId\":\"145879931\",\"name\":\"M. Haris\"},{\"authorId\":\"2490189\",\"name\":\"Gregory Shakhnarovich\"},{\"authorId\":\"3081689\",\"name\":\"N. Ukita\"}],\"doi\":\"10.1109/CVPR.2019.00402\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"bcba77a81a59dcf0798e538e513d8b15b229634f\",\"title\":\"Recurrent Back-Projection Network for Video Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/bcba77a81a59dcf0798e538e513d8b15b229634f\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2337936\",\"name\":\"Haochen Zhang\"},{\"authorId\":\"1718355\",\"name\":\"Dong Liu\"},{\"authorId\":\"2352456\",\"name\":\"Z. Xiong\"}],\"doi\":\"10.1109/FG.2018.00117\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9077365c9486e54e251dd0b6f6edaeda30ae52b9\",\"title\":\"Convolutional Neural Network-Based Video Super-Resolution for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9077365c9486e54e251dd0b6f6edaeda30ae52b9\",\"venue\":\"2018 13th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2018)\",\"year\":2018},{\"arxivId\":\"2003.04716\",\"authors\":[{\"authorId\":\"2302673\",\"name\":\"Jin-shan Pan\"},{\"authorId\":\"1557320016\",\"name\":\"Songsheng Cheng\"},{\"authorId\":\"1519062623\",\"name\":\"Jiawei Zhang\"},{\"authorId\":\"8053308\",\"name\":\"J. Tang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"982afbb7b753f68423d5103dccce4df262114a5e\",\"title\":\"Deep Blind Video Super-resolution\",\"url\":\"https://www.semanticscholar.org/paper/982afbb7b753f68423d5103dccce4df262114a5e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7888497\",\"name\":\"Yuchen Fan\"},{\"authorId\":\"46380478\",\"name\":\"J. Yu\"},{\"authorId\":\"1739208\",\"name\":\"T. Huang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"849d129b86dfb8f1b1b20f11b7b1c1897fa6cf97\",\"title\":\"Wide-activated Deep Residual Networks based Restoration for BPG-compressed Images\",\"url\":\"https://www.semanticscholar.org/paper/849d129b86dfb8f1b1b20f11b7b1c1897fa6cf97\",\"venue\":\"CVPR Workshops\",\"year\":2018},{\"arxivId\":\"1903.05577\",\"authors\":[{\"authorId\":\"50993183\",\"name\":\"Haochen Zhang\"},{\"authorId\":\"48928981\",\"name\":\"Dong Liu\"},{\"authorId\":\"2352456\",\"name\":\"Z. Xiong\"}],\"doi\":\"10.1109/ICCV.2019.00889\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cb72cbdb5476118a207a51054787f6419d5ec055\",\"title\":\"Two-Stream Action Recognition-Oriented Video Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/cb72cbdb5476118a207a51054787f6419d5ec055\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38467984\",\"name\":\"Peng Yi\"},{\"authorId\":\"48708411\",\"name\":\"Zhongyuan Wang\"},{\"authorId\":\"51360637\",\"name\":\"Kui Jiang\"},{\"authorId\":\"1708439\",\"name\":\"J. Jiang\"},{\"authorId\":\"8555475\",\"name\":\"Jiayi Ma\"}],\"doi\":\"10.1109/ICCV.2019.00320\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"755227d7ea41b1d90df31f411f9ecbc998c20d26\",\"title\":\"Progressive Fusion Video Super-Resolution Network via Exploiting Non-Local Spatio-Temporal Correlations\",\"url\":\"https://www.semanticscholar.org/paper/755227d7ea41b1d90df31f411f9ecbc998c20d26\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2009.13856\",\"authors\":[{\"authorId\":\"1974350981\",\"name\":\"Maayan Shuvi\"},{\"authorId\":\"144275050\",\"name\":\"N. Fish\"},{\"authorId\":\"3451442\",\"name\":\"Kfir Aberman\"},{\"authorId\":\"2947946\",\"name\":\"Ariel Shamir\"},{\"authorId\":\"1388323541\",\"name\":\"D. Cohen-Or\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"473bd89f926da2fe7b287f7c67d34391ec909c2b\",\"title\":\"Neural Alignment for Face De-pixelization\",\"url\":\"https://www.semanticscholar.org/paper/473bd89f926da2fe7b287f7c67d34391ec909c2b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491623266\",\"name\":\"Vikram Singh\"},{\"authorId\":\"1644317146\",\"name\":\"Keerthan Ramnath\"},{\"authorId\":\"50853059\",\"name\":\"Anurag Mittal\"}],\"doi\":\"10.1016/j.cviu.2020.103034\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"28fea51f5cb67fda5b9c7e29fff9c8fa7b8ef526\",\"title\":\"Refining high-frequencies for sharper super-resolution and deblurring\",\"url\":\"https://www.semanticscholar.org/paper/28fea51f5cb67fda5b9c7e29fff9c8fa7b8ef526\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"17804683\",\"name\":\"Jonathan Mojoo\"},{\"authorId\":\"26839206\",\"name\":\"Motaz Sabri\"},{\"authorId\":\"50433510\",\"name\":\"Takio Kurita\"}],\"doi\":\"10.1109/IJCNN.2019.8852127\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5eaf3db7ed249c970d9149f36a841bc2c883b5c1\",\"title\":\"Video Super Resolution with Estimation of Motion Information by Using Higher Resolution Images Obtained by Single Image Super Resolution\",\"url\":\"https://www.semanticscholar.org/paper/5eaf3db7ed249c970d9149f36a841bc2c883b5c1\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":\"1906.06520\",\"authors\":[{\"authorId\":\"144125030\",\"name\":\"S. Weiss\"},{\"authorId\":\"32464128\",\"name\":\"Mengyu Chu\"},{\"authorId\":\"1786445\",\"name\":\"N. Th\\u00fcrey\"},{\"authorId\":\"145491004\",\"name\":\"R. Westermann\"}],\"doi\":\"10.1109/tvcg.2019.2956697\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2a53ec1db4acd2bc84c6adb308bc72062aa9514a\",\"title\":\"Volumetric Isosurface Rendering with Deep Learning-Based Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/2a53ec1db4acd2bc84c6adb308bc72062aa9514a\",\"venue\":\"IEEE transactions on visualization and computer graphics\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2935341\",\"name\":\"Jianping Luo\"},{\"authorId\":\"1993594049\",\"name\":\"Shaofei Huang\"},{\"authorId\":\"153197501\",\"name\":\"Yuan Yuan\"}],\"doi\":\"10.1145/3394171.3413587\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d21e592b94fa9deb10cbc1bd27aac5833e53deab\",\"title\":\"Video Super-Resolution using Multi-scale Pyramid 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d21e592b94fa9deb10cbc1bd27aac5833e53deab\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1905.02716\",\"authors\":[{\"authorId\":\"47119707\",\"name\":\"Xintao Wang\"},{\"authorId\":\"12009218\",\"name\":\"Kelvin C. K. Chan\"},{\"authorId\":\"47841301\",\"name\":\"K. Yu\"},{\"authorId\":\"144964867\",\"name\":\"C. Dong\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"}],\"doi\":\"10.1109/CVPRW.2019.00247\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"28b3833743ab00904da1f4a30cd6c771cc164c0d\",\"title\":\"EDVR: Video Restoration With Enhanced Deformable Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/28b3833743ab00904da1f4a30cd6c771cc164c0d\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":\"1807.10993\",\"authors\":[{\"authorId\":\"51150124\",\"name\":\"R. Prabhu\"},{\"authorId\":\"47166189\",\"name\":\"Xiaojing Yu\"},{\"authorId\":\"2969311\",\"name\":\"Zhangyang Wang\"},{\"authorId\":\"1771885\",\"name\":\"Ding Liu\"},{\"authorId\":\"144000092\",\"name\":\"Anxiao Jiang\"}],\"doi\":\"10.1007/978-3-030-25614-2_3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"beead74924f1f33c9dce7c0fb7c7f7d92868dfa9\",\"title\":\"U-Finger: Multi-Scale Dilated Convolutional Network for Fingerprint Image Denoising and Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/beead74924f1f33c9dce7c0fb7c7f7d92868dfa9\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40648435\",\"name\":\"Seungjun Nah\"},{\"authorId\":\"1732855\",\"name\":\"R. Timofte\"},{\"authorId\":\"2476317\",\"name\":\"Shuhang Gu\"},{\"authorId\":\"148009160\",\"name\":\"Sungyong Baik\"},{\"authorId\":\"78563236\",\"name\":\"Seok-Il Hong\"},{\"authorId\":\"3458134\",\"name\":\"Gyeongsik Moon\"},{\"authorId\":\"4640997\",\"name\":\"Sanghyun Son\"},{\"authorId\":\"2135837\",\"name\":\"Kyoung Mu Lee\"},{\"authorId\":\"47119707\",\"name\":\"Xintao Wang\"},{\"authorId\":\"12009218\",\"name\":\"Kelvin C. K. Chan\"},{\"authorId\":\"1482485970\",\"name\":\"Ke Yu\"},{\"authorId\":\"30459277\",\"name\":\"C. Dong\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"},{\"authorId\":\"143668321\",\"name\":\"Yuchen Fan\"},{\"authorId\":\"150167366\",\"name\":\"Jiahui Yu\"},{\"authorId\":\"39332427\",\"name\":\"D. Liu\"},{\"authorId\":\"1739208\",\"name\":\"T. Huang\"},{\"authorId\":null,\"name\":\"Xiao Liu\"},{\"authorId\":\"1414569274\",\"name\":\"Chao Li\"},{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"14668667\",\"name\":\"Yukang Ding\"},{\"authorId\":\"35247507\",\"name\":\"Shilei Wen\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"},{\"authorId\":\"2563691\",\"name\":\"R. Kalarot\"},{\"authorId\":\"153735675\",\"name\":\"Muhammad Haris\"},{\"authorId\":\"2490189\",\"name\":\"Gregory Shakhnarovich\"},{\"authorId\":\"3081689\",\"name\":\"N. Ukita\"},{\"authorId\":\"38467984\",\"name\":\"Peng Yi\"},{\"authorId\":\"38655501\",\"name\":\"Zhongyuan Wang\"},{\"authorId\":\"51360637\",\"name\":\"Kui Jiang\"},{\"authorId\":\"1708439\",\"name\":\"J. Jiang\"},{\"authorId\":\"8555475\",\"name\":\"Jiayi Ma\"},{\"authorId\":\"1500397702\",\"name\":\"Hang Dong\"},{\"authorId\":\"143850015\",\"name\":\"X. Zhang\"},{\"authorId\":\"144869273\",\"name\":\"Zhe Hu\"},{\"authorId\":\"2159594\",\"name\":\"Kwan-Young Kim\"},{\"authorId\":\"1417474762\",\"name\":\"Dong Un Kang\"},{\"authorId\":\"34971370\",\"name\":\"S. Chun\"},{\"authorId\":\"8107818\",\"name\":\"K. Purohit\"},{\"authorId\":\"143891066\",\"name\":\"A. Rajagopalan\"},{\"authorId\":\"34777509\",\"name\":\"Yapeng Tian\"},{\"authorId\":\"2410227\",\"name\":\"Yulun Zhang\"},{\"authorId\":\"145692782\",\"name\":\"Yun Fu\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"},{\"authorId\":\"1747853\",\"name\":\"A. Tekalp\"},{\"authorId\":\"50644949\",\"name\":\"M. Yilmaz\"},{\"authorId\":\"89944783\",\"name\":\"C. Korkmaz\"},{\"authorId\":\"152877244\",\"name\":\"M. Sharma\"},{\"authorId\":\"48454422\",\"name\":\"Megh Makwana\"},{\"authorId\":\"150893294\",\"name\":\"A. Badhwar\"},{\"authorId\":\"96453604\",\"name\":\"A. P. Singh\"},{\"authorId\":\"153918267\",\"name\":\"Avinash Upadhyay\"},{\"authorId\":\"41052499\",\"name\":\"R. Mukhopadhyay\"},{\"authorId\":\"1404142920\",\"name\":\"Ankit Shukla\"},{\"authorId\":\"1644942104\",\"name\":\"Dheeraj Khanna\"},{\"authorId\":\"144819665\",\"name\":\"A. Mandal\"},{\"authorId\":\"144725842\",\"name\":\"S. Chaudhury\"},{\"authorId\":\"9267486\",\"name\":\"Si Miao\"},{\"authorId\":\"49780784\",\"name\":\"Y. Zhu\"},{\"authorId\":\"144140995\",\"name\":\"X. Huo\"}],\"doi\":\"10.1109/CVPRW.2019.00250\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"098d7a729c7df5a47e83179e056a00101d74b90f\",\"title\":\"NTIRE 2019 Challenge on Video Super-Resolution: Methods and Results\",\"url\":\"https://www.semanticscholar.org/paper/098d7a729c7df5a47e83179e056a00101d74b90f\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":\"2007.10595\",\"authors\":[{\"authorId\":\"70116446\",\"name\":\"T. Isobe\"},{\"authorId\":\"153061158\",\"name\":\"Songjiang Li\"},{\"authorId\":\"1641711590\",\"name\":\"Xu Jia\"},{\"authorId\":\"3325819\",\"name\":\"Shanxin Yuan\"},{\"authorId\":\"1729399584\",\"name\":\"Gregory Slabaugh\"},{\"authorId\":\"1691522\",\"name\":\"Chunjing Xu\"},{\"authorId\":\"47002847\",\"name\":\"Ya-Li Li\"},{\"authorId\":\"103307901\",\"name\":\"Shengjin Wang\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/cvpr42600.2020.00803\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4e289323bd2ce0c8b979c65d9247c7cc092e6f2e\",\"title\":\"Video Super-Resolution With Temporal Group Attention\",\"url\":\"https://www.semanticscholar.org/paper/4e289323bd2ce0c8b979c65d9247c7cc092e6f2e\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1739216152\",\"name\":\"Zhuojun Cai\"},{\"authorId\":\"2573672\",\"name\":\"Yaowu Chen\"},{\"authorId\":\"1629984773\",\"name\":\"Xiang Tian\"},{\"authorId\":\"3115947\",\"name\":\"Rongxin Jiang\"}],\"doi\":\"10.1117/1.JEI.29.3.033005\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d0bf0db08152f35e9b9ab65e3e7ba7e6cd305c75\",\"title\":\"Video super-resolution with phase-aided deformable alignment network\",\"url\":\"https://www.semanticscholar.org/paper/d0bf0db08152f35e9b9ab65e3e7ba7e6cd305c75\",\"venue\":\"J. Electronic Imaging\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1898092\",\"name\":\"Bahetiyaer Bare\"},{\"authorId\":\"145613609\",\"name\":\"Bo Yan\"},{\"authorId\":\"49679098\",\"name\":\"Chenxi Ma\"},{\"authorId\":\"104106360\",\"name\":\"Ke Li\"}],\"doi\":\"10.1016/J.NEUCOM.2019.07.089\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"349d221fc29da0be009f1c6f1e73721854cfd79e\",\"title\":\"Real-time video super-resolution via motion convolution kernel estimation\",\"url\":\"https://www.semanticscholar.org/paper/349d221fc29da0be009f1c6f1e73721854cfd79e\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50008226\",\"name\":\"Younghyun Jo\"},{\"authorId\":\"3451982\",\"name\":\"S. Oh\"},{\"authorId\":\"2784241\",\"name\":\"Jaeyeon Kang\"},{\"authorId\":\"1754380\",\"name\":\"S. Kim\"}],\"doi\":\"10.1109/CVPR.2018.00340\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c6a8ff4d9dcdf9e5d82310b847af999ed6655f65\",\"title\":\"Deep Video Super-Resolution Network Using Dynamic Upsampling Filters Without Explicit Motion Compensation\",\"url\":\"https://www.semanticscholar.org/paper/c6a8ff4d9dcdf9e5d82310b847af999ed6655f65\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46912432\",\"name\":\"W. Sun\"},{\"authorId\":\"1862316\",\"name\":\"Jinqiu Sun\"},{\"authorId\":\"11733729\",\"name\":\"Y. Zhu\"},{\"authorId\":\"48379046\",\"name\":\"Y. Zhang\"}],\"doi\":\"10.1016/j.neucom.2020.04.039\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ab8a452ddc4316b8889ed9a577f0248806977db6\",\"title\":\"Video super-resolution via dense non-local spatial-temporal convolutional network\",\"url\":\"https://www.semanticscholar.org/paper/ab8a452ddc4316b8889ed9a577f0248806977db6\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"2004.02803\",\"authors\":[{\"authorId\":\"108535454\",\"name\":\"Xinyi Ying\"},{\"authorId\":\"29957038\",\"name\":\"Longguang Wang\"},{\"authorId\":null,\"name\":\"Yingqian Wang\"},{\"authorId\":\"49343026\",\"name\":\"Weidong Sheng\"},{\"authorId\":\"144813586\",\"name\":\"Wei An\"},{\"authorId\":\"2985328\",\"name\":\"Yulan Guo\"}],\"doi\":\"10.1109/LSP.2020.3013518\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3429544baf4031cc93e7b6ccc76837134a9f383d\",\"title\":\"Deformable 3D Convolution for Video Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/3429544baf4031cc93e7b6ccc76837134a9f383d\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144273442\",\"name\":\"Guo Lu\"},{\"authorId\":\"49469756\",\"name\":\"X. Zhang\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"145481056\",\"name\":\"D. Xu\"},{\"authorId\":\"144423422\",\"name\":\"L. Chen\"},{\"authorId\":\"97709070\",\"name\":\"Z. Gao\"}],\"doi\":\"10.1109/TIP.2019.2943214\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"866390a79170cd8ddca2e785ddaf8bfac5642224\",\"title\":\"Deep Non-Local Kalman Network for Video Compression Artifact Reduction\",\"url\":\"https://www.semanticscholar.org/paper/866390a79170cd8ddca2e785ddaf8bfac5642224\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"2004.04351\",\"authors\":[{\"authorId\":\"91046908\",\"name\":\"Lan Chen\"},{\"authorId\":\"21458018\",\"name\":\"Xiaopeng Zhang\"},{\"authorId\":\"145548256\",\"name\":\"J. Ye\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b9b09a658be6004eaf4bbd6e68c55f441f3f2be3\",\"title\":\"Multi-feature super-resolution network for cloth wrinkle synthesis\",\"url\":\"https://www.semanticscholar.org/paper/b9b09a658be6004eaf4bbd6e68c55f441f3f2be3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1389572577\",\"name\":\"Dario Fuoli\"},{\"authorId\":\"2029246\",\"name\":\"Xiaoyong Shen\"},{\"authorId\":\"2651615\",\"name\":\"Shutao Xia\"},{\"authorId\":\"41219101\",\"name\":\"Yurong Dai\"},{\"authorId\":\"40661332\",\"name\":\"J. Jia\"},{\"authorId\":\"38467984\",\"name\":\"Peng Yi\"},{\"authorId\":\"38655501\",\"name\":\"Zhongyuan Wang\"},{\"authorId\":\"51360637\",\"name\":\"Kui Jiang\"},{\"authorId\":\"1708439\",\"name\":\"J. Jiang\"},{\"authorId\":\"8555475\",\"name\":\"Jiayi Ma\"},{\"authorId\":\"50676070\",\"name\":\"Zhiwei Zhong\"},{\"authorId\":\"2476317\",\"name\":\"Shuhang Gu\"},{\"authorId\":\"47074071\",\"name\":\"Chenyang Wang\"},{\"authorId\":\"1958191\",\"name\":\"X. Liu\"},{\"authorId\":\"51166756\",\"name\":\"R. Timofte\"},{\"authorId\":\"49902634\",\"name\":\"Xin Tao\"},{\"authorId\":\"47112872\",\"name\":\"Wenbo Li\"},{\"authorId\":\"1468599886\",\"name\":\"Taian Guo\"},{\"authorId\":\"10042932\",\"name\":\"Zijun Deng\"},{\"authorId\":\"49196263\",\"name\":\"Liying Lu\"},{\"authorId\":\"151470385\",\"name\":\"Tao Dai\"}],\"doi\":\"10.1109/ICCVW.2019.00430\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a1f45352af251af746c0a0d7826d4ac95d15b605\",\"title\":\"AIM 2019 Challenge on Video Extreme Super-Resolution: Methods and Results\",\"url\":\"https://www.semanticscholar.org/paper/a1f45352af251af746c0a0d7826d4ac95d15b605\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"2007.07355\",\"authors\":[{\"authorId\":\"2935412\",\"name\":\"U. Demir\"},{\"authorId\":\"2116440\",\"name\":\"Y. Rawat\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f00fcda3127dc697fd2aa30569eafa5e1b0c2f8c\",\"title\":\"TinyVIRAT: Low-resolution Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f00fcda3127dc697fd2aa30569eafa5e1b0c2f8c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1912.03445\",\"authors\":[{\"authorId\":\"119837762\",\"name\":\"Junru Wu\"},{\"authorId\":null,\"name\":\"Xiang Yu\"},{\"authorId\":\"1771885\",\"name\":\"Ding Liu\"},{\"authorId\":\"2099305\",\"name\":\"Manmohan Chandraker\"},{\"authorId\":\"2969311\",\"name\":\"Zhangyang Wang\"}],\"doi\":\"10.1109/WACV45572.2020.9093529\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4b745add3720480731b32846bbda03f954c3b8ae\",\"title\":\"DAVID: Dual-Attentional Video Deblurring\",\"url\":\"https://www.semanticscholar.org/paper/4b745add3720480731b32846bbda03f954c3b8ae\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150167366\",\"name\":\"Jiahui Yu\"},{\"authorId\":\"143668321\",\"name\":\"Yuchen Fan\"},{\"authorId\":\"1739208\",\"name\":\"T. Huang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7c1774b01a4725935c400a4ee90f2358942ba1a5\",\"title\":\"Wide Activation for Efficient Image and Video Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/7c1774b01a4725935c400a4ee90f2358942ba1a5\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144850642\",\"name\":\"W. Ren\"},{\"authorId\":\"47538816\",\"name\":\"Jingang Zhang\"},{\"authorId\":\"2291143\",\"name\":\"Xiangyu Xu\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"1719250\",\"name\":\"Xiaochun Cao\"},{\"authorId\":\"3182192\",\"name\":\"Gaofeng Meng\"},{\"authorId\":\"143775741\",\"name\":\"W. Liu\"}],\"doi\":\"10.1109/TIP.2018.2876178\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"281b8c4e4ed6a9237a5b65a6f95048882340253c\",\"title\":\"Deep Video Dehazing With Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/281b8c4e4ed6a9237a5b65a6f95048882340253c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1898172\",\"name\":\"W. Yang\"},{\"authorId\":\"145412876\",\"name\":\"Y. Yuan\"},{\"authorId\":\"144850642\",\"name\":\"W. Ren\"},{\"authorId\":\"49722217\",\"name\":\"J. Liu\"},{\"authorId\":\"2613438\",\"name\":\"W. Scheirer\"},{\"authorId\":\"2969311\",\"name\":\"Zhangyang Wang\"},{\"authorId\":\"97112392\",\"name\":\"Taiheng Zhang\"},{\"authorId\":\"1842317\",\"name\":\"Qiaoyong Zhong\"},{\"authorId\":\"50322310\",\"name\":\"Di Xie\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"},{\"authorId\":\"47833511\",\"name\":\"Y. Zheng\"},{\"authorId\":\"9274274\",\"name\":\"Yanyun Qu\"},{\"authorId\":\"46268909\",\"name\":\"Yuhong Xie\"},{\"authorId\":\"100501008\",\"name\":\"L. Chen\"},{\"authorId\":\"51194203\",\"name\":\"Zhonghao Li\"},{\"authorId\":\"143753663\",\"name\":\"Chen Hong\"},{\"authorId\":\"152743747\",\"name\":\"Hao Jiang\"},{\"authorId\":\"49080481\",\"name\":\"S. Yang\"},{\"authorId\":\"46400027\",\"name\":\"Y. Liu\"},{\"authorId\":\"148377132\",\"name\":\"Xiaochao Qu\"},{\"authorId\":\"37124370\",\"name\":\"P. Wan\"},{\"authorId\":\"1410058013\",\"name\":\"Shuai Zheng\"},{\"authorId\":\"1601420507\",\"name\":\"Minhui Zhong\"},{\"authorId\":\"1600656912\",\"name\":\"Taiyi Su\"},{\"authorId\":\"12754800\",\"name\":\"Lingzhi He\"},{\"authorId\":\"48302281\",\"name\":\"Y. Guo\"},{\"authorId\":\"46317075\",\"name\":\"Yuhang Zhao\"},{\"authorId\":\"1749780\",\"name\":\"Zhenfeng Zhu\"},{\"authorId\":\"12771034\",\"name\":\"Jinxiu Liang\"},{\"authorId\":\"48093314\",\"name\":\"Jing-Wen Wang\"},{\"authorId\":\"153489787\",\"name\":\"Tianyi Chen\"},{\"authorId\":\"2217653\",\"name\":\"Y. Quan\"},{\"authorId\":\"20100813\",\"name\":\"Y. Xu\"},{\"authorId\":\"118122478\",\"name\":\"B. Liu\"},{\"authorId\":\"71447506\",\"name\":\"X. Liu\"},{\"authorId\":\"123555217\",\"name\":\"Q. Sun\"},{\"authorId\":\"51486843\",\"name\":\"Tingyu Lin\"},{\"authorId\":\"1502879401\",\"name\":\"X. Li\"},{\"authorId\":\"1388864077\",\"name\":\"Feng Lu\"},{\"authorId\":\"151484085\",\"name\":\"Lin Gu\"},{\"authorId\":\"52201112\",\"name\":\"Shengdi Zhou\"},{\"authorId\":\"48319843\",\"name\":\"Cong Cao\"},{\"authorId\":\"101266543\",\"name\":\"Shifeng Zhang\"},{\"authorId\":\"143700133\",\"name\":\"Cheng Chi\"},{\"authorId\":\"51172717\",\"name\":\"Chubin Zhuang\"},{\"authorId\":\"1600629256\",\"name\":\"Zhen Lei\"},{\"authorId\":\"39756350\",\"name\":\"S. Li\"},{\"authorId\":\"1697619\",\"name\":\"Shizheng Wang\"},{\"authorId\":\"2756364\",\"name\":\"R. Liu\"},{\"authorId\":\"1382585998\",\"name\":\"Dong Yi\"},{\"authorId\":\"40760781\",\"name\":\"Zheming Zuo\"},{\"authorId\":\"2686775\",\"name\":\"Jianning Chi\"},{\"authorId\":\"46507194\",\"name\":\"Haiquan Wang\"},{\"authorId\":\"73019850\",\"name\":\"Kai Wang\"},{\"authorId\":\"113317930\",\"name\":\"Yi-xiu Liu\"},{\"authorId\":\"46757744\",\"name\":\"Xingyu Gao\"},{\"authorId\":\"9220930\",\"name\":\"Zhenyu Chen\"},{\"authorId\":\"144157639\",\"name\":\"C. Guo\"},{\"authorId\":\"47002329\",\"name\":\"Yongzhou Li\"},{\"authorId\":\"48579116\",\"name\":\"H. Zhong\"},{\"authorId\":\"2574085\",\"name\":\"Jui-Ting Huang\"},{\"authorId\":\"47331634\",\"name\":\"H. Guo\"},{\"authorId\":\"2562263\",\"name\":\"Jianfei Yang\"},{\"authorId\":\"48739855\",\"name\":\"Wenjuan Liao\"},{\"authorId\":\"37953925\",\"name\":\"J. Yang\"},{\"authorId\":\"49718614\",\"name\":\"Liguo Zhou\"},{\"authorId\":\"3058714\",\"name\":\"Mingyue Feng\"},{\"authorId\":\"1601163844\",\"name\":\"Likun Qin\"}],\"doi\":\"10.1109/TIP.2020.2981922\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e3ee5c8b170add8a6ffb59c471b50d63ef476a28\",\"title\":\"Advancing Image Understanding in Poor Visibility Environments: A Collective Benchmark Study\",\"url\":\"https://www.semanticscholar.org/paper/e3ee5c8b170add8a6ffb59c471b50d63ef476a28\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1411123821\",\"name\":\"Santiago L\\u00f3pez-Tapia\"},{\"authorId\":\"119576342\",\"name\":\"A. Lucas\"},{\"authorId\":\"143719659\",\"name\":\"R. Molina\"},{\"authorId\":\"123905575\",\"name\":\"Aggelos K. Katsaggelos\"}],\"doi\":\"10.23919/Eusipco47968.2020.9287713\",\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"f30a0c920531de01624439e9b1eb43be4e0bcbd1\",\"title\":\"Gated Recurrent Networks for Video Super Resolution\",\"url\":\"https://www.semanticscholar.org/paper/f30a0c920531de01624439e9b1eb43be4e0bcbd1\",\"venue\":\"2020 28th European Signal Processing Conference (EUSIPCO)\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48928783\",\"name\":\"Ding Liu\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"7888497\",\"name\":\"Yuchen Fan\"},{\"authorId\":\"1958191\",\"name\":\"X. Liu\"},{\"authorId\":\"2969311\",\"name\":\"Zhangyang Wang\"},{\"authorId\":\"3307026\",\"name\":\"S. Chang\"},{\"authorId\":\"2714904\",\"name\":\"X. Wang\"},{\"authorId\":\"1739208\",\"name\":\"T. Huang\"}],\"doi\":\"10.1109/TIP.2018.2820807\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1773d65c1dc566fd6128db65e907ac91b4583bed\",\"title\":\"Learning Temporal Dynamics for Video Super-Resolution: A Deep Learning Approach\",\"url\":\"https://www.semanticscholar.org/paper/1773d65c1dc566fd6128db65e907ac91b4583bed\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":\"2002.06378\",\"authors\":[{\"authorId\":\"1937135\",\"name\":\"J. Xin\"},{\"authorId\":\"144050302\",\"name\":\"Nannan Wang\"},{\"authorId\":\"46276358\",\"name\":\"Jie Li\"},{\"authorId\":\"49779747\",\"name\":\"Xinbo Gao\"},{\"authorId\":\"9247990\",\"name\":\"Zhifeng Li\"}],\"doi\":\"10.1609/AAAI.V34I07.6934\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5d887317ac22c2b6b8f210072cea2f52396e08b9\",\"title\":\"Video Face Super-Resolution with Motion-Adaptive Feedback Cell\",\"url\":\"https://www.semanticscholar.org/paper/5d887317ac22c2b6b8f210072cea2f52396e08b9\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2008.10710\",\"authors\":[{\"authorId\":\"46522414\",\"name\":\"Xiaohong Liu\"},{\"authorId\":\"153250595\",\"name\":\"K. Shi\"},{\"authorId\":\"96309470\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Jun Chen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3f93bb19eac964e1a49a1e7467b41160447d3d37\",\"title\":\"Exploit Camera Raw Data for Video Super-Resolution via Hidden Markov Model Inference\",\"url\":\"https://www.semanticscholar.org/paper/3f93bb19eac964e1a49a1e7467b41160447d3d37\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.02228\",\"authors\":[{\"authorId\":\"151493135\",\"name\":\"Sachin Mehta\"},{\"authorId\":\"50333013\",\"name\":\"A. Kumar\"},{\"authorId\":\"3291967\",\"name\":\"F. Reda\"},{\"authorId\":\"2031916319\",\"name\":\"Varun Nasery\"},{\"authorId\":\"2031915345\",\"name\":\"Vikram Mulukutla\"},{\"authorId\":\"2481463\",\"name\":\"R. Ranjan\"},{\"authorId\":\"50105587\",\"name\":\"Vikas Chandra\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d7e169b4386ce81f5f953530fcd8ede2f1110331\",\"title\":\"EVRNet: Efficient Video Restoration on Edge Devices\",\"url\":\"https://www.semanticscholar.org/paper/d7e169b4386ce81f5f953530fcd8ede2f1110331\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1902.06068\",\"authors\":[{\"authorId\":\"40072272\",\"name\":\"Zhihao Wang\"},{\"authorId\":\"37503277\",\"name\":\"Jian Chen\"},{\"authorId\":\"1741126\",\"name\":\"S. Hoi\"}],\"doi\":\"10.1109/TPAMI.2020.2982166\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bef416fd2e16bf7215eca7394ad1581f7caa8250\",\"title\":\"Deep Learning for Image Super-resolution: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/bef416fd2e16bf7215eca7394ad1581f7caa8250\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"2006.11708\",\"authors\":[{\"authorId\":\"3814221\",\"name\":\"Vasileios Lioutas\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1e52ac07025009463171c429c84d703c3bf73c45\",\"title\":\"Mapping Low-Resolution Images To Multiple High-Resolution Images Using Non-Adversarial Mapping\",\"url\":\"https://www.semanticscholar.org/paper/1e52ac07025009463171c429c84d703c3bf73c45\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491623266\",\"name\":\"Vikram Singh\"},{\"authorId\":\"36385266\",\"name\":\"Akshay Sharma\"},{\"authorId\":\"1659233430\",\"name\":\"S. Devanathan\"},{\"authorId\":\"50853059\",\"name\":\"Anurag Mittal\"}],\"doi\":\"10.1109/WACV45572.2020.9093572\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"abd900d75f71a54db2ec046c01d6ca28dcf3a36e\",\"title\":\"High-Frequency Refinement for Sharper Video Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/abd900d75f71a54db2ec046c01d6ca28dcf3a36e\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1411123821\",\"name\":\"Santiago L\\u00f3pez-Tapia\"},{\"authorId\":\"119576342\",\"name\":\"A. Lucas\"},{\"authorId\":\"122587290\",\"name\":\"R. Molina\"},{\"authorId\":\"144842935\",\"name\":\"A. Katsaggelos\"}],\"doi\":\"10.1109/ICIP.2019.8803709\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"fabd652662c464f270cb11e7001aca0fc7b56c7b\",\"title\":\"Gan-Based Video Super-Resolution With Direct Regularized Inversion of the Low-Resolution Formation Model\",\"url\":\"https://www.semanticscholar.org/paper/fabd652662c464f270cb11e7001aca0fc7b56c7b\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"1809.08573\",\"authors\":[{\"authorId\":\"29957038\",\"name\":\"Longguang Wang\"},{\"authorId\":\"2985328\",\"name\":\"Yulan Guo\"},{\"authorId\":\"7766962\",\"name\":\"Zaiping Lin\"},{\"authorId\":\"9409172\",\"name\":\"Xinpu Deng\"},{\"authorId\":\"4431471\",\"name\":\"Wei An\"}],\"doi\":\"10.1007/978-3-030-20887-5_32\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"bf122481f80d692a5e45ecfd46f780d6ca5cc377\",\"title\":\"Learning for Video Super-Resolution through HR Optical Flow Estimation\",\"url\":\"https://www.semanticscholar.org/paper/bf122481f80d692a5e45ecfd46f780d6ca5cc377\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144273442\",\"name\":\"Guo Lu\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"38188040\",\"name\":\"Dong Xu\"},{\"authorId\":\"9117564\",\"name\":\"X. Zhang\"},{\"authorId\":\"145071557\",\"name\":\"Z. Gao\"},{\"authorId\":\"144463557\",\"name\":\"M. Sun\"}],\"doi\":\"10.1007/978-3-030-01264-9_35\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"36b2b8ede289ddd53e8afc8c066d9463969d40a2\",\"title\":\"Deep Kalman Filtering Network for Video Compression Artifact Reduction\",\"url\":\"https://www.semanticscholar.org/paper/36b2b8ede289ddd53e8afc8c066d9463969d40a2\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2007.12928\",\"authors\":[{\"authorId\":\"48447409\",\"name\":\"H. Liu\"},{\"authorId\":\"1833327426\",\"name\":\"Zhubo Ruan\"},{\"authorId\":\"144426582\",\"name\":\"Peng Zhao\"},{\"authorId\":\"3062185\",\"name\":\"F. Shang\"},{\"authorId\":\"120378243\",\"name\":\"Linlin Yang\"},{\"authorId\":\"3740432\",\"name\":\"Y. Liu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3e37a567b4cec88fc0dd26df4497a34b316ac3b6\",\"title\":\"Video Super Resolution Based on Deep Learning: A comprehensive survey\",\"url\":\"https://www.semanticscholar.org/paper/3e37a567b4cec88fc0dd26df4497a34b316ac3b6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1907.01399\",\"authors\":[{\"authorId\":\"1411123821\",\"name\":\"Santiago L\\u00f3pez-Tapia\"},{\"authorId\":\"119576342\",\"name\":\"A. Lucas\"},{\"authorId\":\"122587290\",\"name\":\"R. Molina\"},{\"authorId\":\"144842935\",\"name\":\"A. Katsaggelos\"}],\"doi\":\"10.1016/j.dsp.2020.102801\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"da9542d38e54f7f1419da700a687bb5487c10369\",\"title\":\"A Single Video Super-Resolution GAN for Multiple Downsampling Operators based on Pseudo-Inverse Image Formation Models\",\"url\":\"https://www.semanticscholar.org/paper/da9542d38e54f7f1419da700a687bb5487c10369\",\"venue\":\"Digit. Signal Process.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1739585132\",\"name\":\"Zichen Gong\"},{\"authorId\":\"1738467233\",\"name\":\"Toshiya Hori\"},{\"authorId\":\"145452473\",\"name\":\"H. Watanabe\"},{\"authorId\":\"24333182\",\"name\":\"T. Ikai\"},{\"authorId\":\"3310346\",\"name\":\"Takeshi Chujoh\"},{\"authorId\":\"66773061\",\"name\":\"E. Sasaki\"},{\"authorId\":\"92402209\",\"name\":\"N. Ito\"}],\"doi\":\"10.1117/12.2566219\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"de9a460dc1d7e5fc22c2fca95fe3afb804d5923b\",\"title\":\"A selective fusion module for video super resolution with recurrent architecture\",\"url\":\"https://www.semanticscholar.org/paper/de9a460dc1d7e5fc22c2fca95fe3afb804d5923b\",\"venue\":\"Other Conferences\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"103850047\",\"name\":\"So-Hyeong Kim\"},{\"authorId\":\"1390810340\",\"name\":\"Guanju Li\"},{\"authorId\":\"1389572577\",\"name\":\"Dario Fuoli\"},{\"authorId\":\"2488938\",\"name\":\"Martin Danelljan\"},{\"authorId\":\"145314891\",\"name\":\"Z. Huang\"},{\"authorId\":\"2476317\",\"name\":\"Shuhang Gu\"},{\"authorId\":\"51166756\",\"name\":\"R. Timofte\"}],\"doi\":\"10.1109/ICCVW.2019.00446\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3ccbcd94c9230b7e81c3be4e32697c8253ca0f78\",\"title\":\"The Vid3oC and IntVID Datasets for Video Super Resolution and Quality Mapping\",\"url\":\"https://www.semanticscholar.org/paper/3ccbcd94c9230b7e81c3be4e32697c8253ca0f78\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37634267\",\"name\":\"A. Davy\"},{\"authorId\":\"40142302\",\"name\":\"T. Ehret\"},{\"authorId\":\"27053481\",\"name\":\"J. Morel\"},{\"authorId\":\"138547340\",\"name\":\"Pablo Arias\"},{\"authorId\":\"1724244\",\"name\":\"G. Facciolo\"}],\"doi\":\"10.1109/ICIP.2019.8803314\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8bdb15e6f5167f376a6d1389fefca137d4cb1516\",\"title\":\"A Non-Local CNN for Video Denoising\",\"url\":\"https://www.semanticscholar.org/paper/8bdb15e6f5167f376a6d1389fefca137d4cb1516\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"1807.07930\",\"authors\":[{\"authorId\":\"1405198343\",\"name\":\"Eduardo P\\u00e9rez-Pellitero\"},{\"authorId\":\"2283034\",\"name\":\"Mehdi S. M. Sajjadi\"},{\"authorId\":\"144566512\",\"name\":\"M. Hirsch\"},{\"authorId\":\"1707625\",\"name\":\"B. Sch\\u00f6lkopf\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"85c7985cd6f2be1840f1ec885bf5ef8479b21324\",\"title\":\"Photorealistic Video Super Resolution\",\"url\":\"https://www.semanticscholar.org/paper/85c7985cd6f2be1840f1ec885bf5ef8479b21324\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1909.08080\",\"authors\":[{\"authorId\":\"1389572577\",\"name\":\"Dario Fuoli\"},{\"authorId\":\"2476317\",\"name\":\"Shuhang Gu\"},{\"authorId\":\"1732855\",\"name\":\"R. Timofte\"}],\"doi\":\"10.1109/ICCVW.2019.00431\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1defd5b4163a5ea7c1bb272f616a1256cb7826a6\",\"title\":\"Efficient Video Super-Resolution through Recurrent Latent Space Propagation\",\"url\":\"https://www.semanticscholar.org/paper/1defd5b4163a5ea7c1bb272f616a1256cb7826a6\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"2001.01162\",\"authors\":[{\"authorId\":\"49544454\",\"name\":\"X. Liu\"},{\"authorId\":\"1477284652\",\"name\":\"Lingshi Kong\"},{\"authorId\":\"32025363\",\"name\":\"Yang Zhou\"},{\"authorId\":\"1728718\",\"name\":\"Jiying Zhao\"},{\"authorId\":null,\"name\":\"Jun Chen\"}],\"doi\":\"10.1109/WACV45572.2020.9093552\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"fc7599d494cc7ab451c813ed562d4b310a862abd\",\"title\":\"End-To-End Trainable Video Super-Resolution Based on a New Mechanism for Implicit Motion Estimation and Compensation\",\"url\":\"https://www.semanticscholar.org/paper/fc7599d494cc7ab451c813ed562d4b310a862abd\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1910.12286\",\"authors\":[{\"authorId\":\"153018917\",\"name\":\"Y. Xu\"},{\"authorId\":\"3036495\",\"name\":\"Longwen Gao\"},{\"authorId\":\"47853648\",\"name\":\"Kai Tian\"},{\"authorId\":\"1788230\",\"name\":\"Shuigeng Zhou\"},{\"authorId\":\"52177693\",\"name\":\"Huyang Sun\"}],\"doi\":\"10.1109/ICCV.2019.00714\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"76b76aeb4add1f2f6a59e08b4c6b2ca3dc7685b8\",\"title\":\"Non-Local ConvLSTM for Video Compression Artifact Reduction\",\"url\":\"https://www.semanticscholar.org/paper/76b76aeb4add1f2f6a59e08b4c6b2ca3dc7685b8\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"119576342\",\"name\":\"A. Lucas\"},{\"authorId\":\"12379923\",\"name\":\"Santiago Lopez Tapia\"},{\"authorId\":\"122587290\",\"name\":\"R. Molina\"},{\"authorId\":\"144842935\",\"name\":\"A. Katsaggelos\"}],\"doi\":\"10.1109/ICIP.2018.8451714\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"50267be2d0d072cecd8b443071c28541cc57e2de\",\"title\":\"Generative Adversarial Networks and Perceptual Losses for Video Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/50267be2d0d072cecd8b443071c28541cc57e2de\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":\"2011.10974\",\"authors\":[{\"authorId\":\"39431125\",\"name\":\"Shuyang Gu\"},{\"authorId\":\"9324504\",\"name\":\"Jian-min Bao\"},{\"authorId\":\"2013406166\",\"name\":\"Dong Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"906c0c47fea0842a6dc5d1301c916eae025a2d90\",\"title\":\"Learnable Sampling 3D Convolution for Video Enhancement and Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/906c0c47fea0842a6dc5d1301c916eae025a2d90\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.07265\",\"authors\":[{\"authorId\":\"12009218\",\"name\":\"Kelvin C. K. Chan\"},{\"authorId\":\"47119707\",\"name\":\"Xintao Wang\"},{\"authorId\":\"47841301\",\"name\":\"K. Yu\"},{\"authorId\":\"30459277\",\"name\":\"C. Dong\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"45ddf05fe644114def892da75999f4c5778abd04\",\"title\":\"Understanding Deformable Alignment in Video Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/45ddf05fe644114def892da75999f4c5778abd04\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1806.05764\",\"authors\":[{\"authorId\":\"119576342\",\"name\":\"A. Lucas\"},{\"authorId\":\"1404976026\",\"name\":\"Santiago L&#x00F3;pez-Tapia\"},{\"authorId\":\"122587290\",\"name\":\"R. Molina\"},{\"authorId\":\"144842935\",\"name\":\"A. Katsaggelos\"}],\"doi\":\"10.1109/TIP.2019.2895768\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9cbd61e73c1157a62370af8a7980ee3f1e918ba4\",\"title\":\"Generative Adversarial Networks and Perceptual Losses for Video Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/9cbd61e73c1157a62370af8a7980ee3f1e918ba4\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"2003.06141\",\"authors\":[{\"authorId\":\"50993183\",\"name\":\"Haochen Zhang\"},{\"authorId\":\"50439333\",\"name\":\"DongSheng Liu\"},{\"authorId\":\"2352456\",\"name\":\"Z. Xiong\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5712e1775e06cdedcb23d5abb624874334b8e22f\",\"title\":\"Is There Tradeoff between Spatial and Temporal in Video Super-Resolution?\",\"url\":\"https://www.semanticscholar.org/paper/5712e1775e06cdedcb23d5abb624874334b8e22f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1812.09079\",\"authors\":[{\"authorId\":\"5168807\",\"name\":\"Soo Ye Kim\"},{\"authorId\":\"1828062\",\"name\":\"Jeongyeon Lim\"},{\"authorId\":\"2591818\",\"name\":\"Taeyoung Na\"},{\"authorId\":\"144366095\",\"name\":\"M. Kim\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"e35f65b0878c8c033cfe8665fa77500e13879831\",\"title\":\"3DSRnet: Video Super-resolution using 3D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/e35f65b0878c8c033cfe8665fa77500e13879831\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1805.02704\",\"authors\":[{\"authorId\":\"143911112\",\"name\":\"Wei Han\"},{\"authorId\":\"3307026\",\"name\":\"S. Chang\"},{\"authorId\":\"1771885\",\"name\":\"Ding Liu\"},{\"authorId\":\"2482533\",\"name\":\"Mo Yu\"},{\"authorId\":\"2819135\",\"name\":\"M. Witbrock\"},{\"authorId\":\"1739208\",\"name\":\"T. Huang\"}],\"doi\":\"10.1109/CVPR.2018.00178\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"175f74a09241b6cb5101a2a09978095720db7d5f\",\"title\":\"Image Super-Resolution via Dual-State Recurrent Networks\",\"url\":\"https://www.semanticscholar.org/paper/175f74a09241b6cb5101a2a09978095720db7d5f\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72413769\",\"name\":\"Amar B. Deshmukh\"},{\"authorId\":\"145913404\",\"name\":\"N. U. Rani\"}],\"doi\":\"10.4018/ijdcf.2020070106\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ccc2098442735629c1774d9704f24b58c017a48b\",\"title\":\"Optimization-Driven Kernel and Deep Convolutional Neural Network for Multi-View Face Video Super Resolution\",\"url\":\"https://www.semanticscholar.org/paper/ccc2098442735629c1774d9704f24b58c017a48b\",\"venue\":\"Int. J. Digit. Crime Forensics\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145526138\",\"name\":\"Peng Yi\"},{\"authorId\":\"48708411\",\"name\":\"Zhongyuan Wang\"},{\"authorId\":\"51360637\",\"name\":\"Kui Jiang\"},{\"authorId\":\"38461328\",\"name\":\"ZhenFeng Shao\"},{\"authorId\":\"8555475\",\"name\":\"Jiayi Ma\"}],\"doi\":\"10.1109/TCSVT.2019.2925844\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"32098c16b6fc2bdfd9adfe8e950861414ac085ec\",\"title\":\"Multi-Temporal Ultra Dense Memory Network for Video Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/32098c16b6fc2bdfd9adfe8e950861414ac085ec\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1914700964\",\"name\":\"Shurui Gui\"},{\"authorId\":\"1409848027\",\"name\":\"Chaoyue Wang\"},{\"authorId\":\"47261253\",\"name\":\"Q. Chen\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/cvpr42600.2020.01402\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"48d49e5e85a5659853f8ad2f31e05b8ba81866e2\",\"title\":\"FeatureFlow: Robust Video Interpolation via Structure-to-Texture Generation\",\"url\":\"https://www.semanticscholar.org/paper/48d49e5e85a5659853f8ad2f31e05b8ba81866e2\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1904.04474\",\"authors\":[{\"authorId\":\"30556331\",\"name\":\"Y. Yuan\"},{\"authorId\":\"1898172\",\"name\":\"W. Yang\"},{\"authorId\":\"144850642\",\"name\":\"W. Ren\"},{\"authorId\":\"49722217\",\"name\":\"Jiaying Liu\"},{\"authorId\":\"2613438\",\"name\":\"W. Scheirer\"},{\"authorId\":\"2969311\",\"name\":\"Zhangyang Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0e583e7424813b33f024a4e13e0c8580f693d9e8\",\"title\":\"UG2 Track 2: A Collective Benchmark Effort for Evaluating and Advancing Image Understanding in Poor Visibility Environments\",\"url\":\"https://www.semanticscholar.org/paper/0e583e7424813b33f024a4e13e0c8580f693d9e8\",\"venue\":\"CVPR 2019\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12379923\",\"name\":\"Santiago Lopez Tapia\"},{\"authorId\":\"119576342\",\"name\":\"A. Lucas\"},{\"authorId\":\"122587290\",\"name\":\"R. Molina\"},{\"authorId\":\"144842935\",\"name\":\"A. Katsaggelos\"}],\"doi\":\"10.23919/EUSIPCO.2019.8902338\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"15e311a1d644f3e3a43a9f92fd3ed7a5f0ba2b2c\",\"title\":\"Multiple-Degradation Video Super-Resolution with Direct Inversion of the Low-Resolution Formation Model\",\"url\":\"https://www.semanticscholar.org/paper/15e311a1d644f3e3a43a9f92fd3ed7a5f0ba2b2c\",\"venue\":\"2019 27th European Signal Processing Conference (EUSIPCO)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8107818\",\"name\":\"K. Purohit\"},{\"authorId\":\"2169103\",\"name\":\"S. Mandal\"},{\"authorId\":\"143891066\",\"name\":\"A. Rajagopalan\"}],\"doi\":\"10.1016/j.neucom.2019.02.069\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3f19c6bdd54a627c15da479e240d0e5ff8a5cfc6\",\"title\":\"Mixed-dense connection networks for image and video super-resolution\",\"url\":\"https://www.semanticscholar.org/paper/3f19c6bdd54a627c15da479e240d0e5ff8a5cfc6\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"2007.11803\",\"authors\":[{\"authorId\":\"1509486338\",\"name\":\"Wenbo Li\"},{\"authorId\":\"49902634\",\"name\":\"Xin Tao\"},{\"authorId\":\"1468599886\",\"name\":\"Taian Guo\"},{\"authorId\":\"144851028\",\"name\":\"Lu Qi\"},{\"authorId\":\"1715148\",\"name\":\"Jiangbo Lu\"},{\"authorId\":\"2949183\",\"name\":\"Jiaya Jia\"}],\"doi\":\"10.1007/978-3-030-58607-2_20\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"de01b47996936c810b49fc1919522eea34155070\",\"title\":\"MuCAN: Multi-Correspondence Aggregation Network for Video Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/de01b47996936c810b49fc1919522eea34155070\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71506962\",\"name\":\"Zhiqiang Tian\"},{\"authorId\":null,\"name\":\"Yudiao Wang\"},{\"authorId\":\"144410771\",\"name\":\"S. Du\"},{\"authorId\":\"2498428\",\"name\":\"X. Lan\"}],\"doi\":\"10.1371/journal.pone.0235352\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a9713bdf64530b598c863668ee1271d0935b949e\",\"title\":\"A multiresolution mixture generative adversarial network for video super-resolution\",\"url\":\"https://www.semanticscholar.org/paper/a9713bdf64530b598c863668ee1271d0935b949e\",\"venue\":\"PloS one\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1898172\",\"name\":\"W. Yang\"},{\"authorId\":\"145772051\",\"name\":\"Sifeng Xia\"},{\"authorId\":\"41127426\",\"name\":\"Jiaying Liu\"},{\"authorId\":\"35310979\",\"name\":\"Zongming Guo\"}],\"doi\":\"10.1109/TCSVT.2018.2838453\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"50df2131edb688fe538dd816e7f80c37b85542bf\",\"title\":\"Reference-Guided Deep Super-Resolution via Manifold Localized External Compensation\",\"url\":\"https://www.semanticscholar.org/paper/50df2131edb688fe538dd816e7f80c37b85542bf\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1706347\",\"name\":\"Jieping Xu\"},{\"authorId\":\"48503624\",\"name\":\"Yonghui Liang\"},{\"authorId\":\"48210854\",\"name\":\"J. Liu\"},{\"authorId\":\"29992311\",\"name\":\"Z. Huang\"},{\"authorId\":\"48032588\",\"name\":\"Xuewen Liu\"}],\"doi\":\"10.1186/S13640-018-0376-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"35c9dc5c0b7c1ba4a0b03a87b9dab995edc83691\",\"title\":\"Online multi-frame super-resolution of image sequences\",\"url\":\"https://www.semanticscholar.org/paper/35c9dc5c0b7c1ba4a0b03a87b9dab995edc83691\",\"venue\":\"EURASIP J. Image Video Process.\",\"year\":2018},{\"arxivId\":\"2011.04566\",\"authors\":[{\"authorId\":\"153526355\",\"name\":\"Armin Mehri\"},{\"authorId\":\"2009419556\",\"name\":\"Parichehr Behjati Ardakani\"},{\"authorId\":\"1782314\",\"name\":\"A. Sappa\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"580b755bd473b14b4c4a72a558889e4df6b4c3c4\",\"title\":\"MPRNet: Multi-Path Residual Network for Lightweight Image Super Resolution\",\"url\":\"https://www.semanticscholar.org/paper/580b755bd473b14b4c4a72a558889e4df6b4c3c4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.03199\",\"authors\":[{\"authorId\":\"1491623266\",\"name\":\"Vikram Singh\"},{\"authorId\":\"50853059\",\"name\":\"Anurag Mittal\"}],\"doi\":\"10.1109/jstsp.2020.3044182\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fadf3938e43a267e16b5535c48bc0b8bf9077e8f\",\"title\":\"WDN: A Wide and Deep Network to Divide-and-Conquer Image Super-resolution\",\"url\":\"https://www.semanticscholar.org/paper/fadf3938e43a267e16b5535c48bc0b8bf9077e8f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5168807\",\"name\":\"Soo Ye Kim\"},{\"authorId\":\"1828062\",\"name\":\"Jeongyeon Lim\"},{\"authorId\":\"2591818\",\"name\":\"Taeyoung Na\"},{\"authorId\":\"144366095\",\"name\":\"M. Kim\"}],\"doi\":\"10.1109/ICIP.2019.8803297\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"f9f541f50deeb0e8967d4ee190f017e325af1e03\",\"title\":\"Video Super-Resolution Based on 3D-CNNS with Consideration of Scene Change\",\"url\":\"https://www.semanticscholar.org/paper/f9f541f50deeb0e8967d4ee190f017e325af1e03\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"1808.08718\",\"authors\":[{\"authorId\":\"46380478\",\"name\":\"J. Yu\"},{\"authorId\":\"7888497\",\"name\":\"Yuchen Fan\"},{\"authorId\":\"1706007\",\"name\":\"Jianchao Yang\"},{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"2714904\",\"name\":\"X. Wang\"},{\"authorId\":\"1739208\",\"name\":\"T. Huang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"16ba65426ed5e1e3367eff5bd507dcf6d99bd7c2\",\"title\":\"Wide Activation for Efficient and Accurate Image Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/16ba65426ed5e1e3367eff5bd507dcf6d99bd7c2\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47978407\",\"name\":\"Peilin Chen\"},{\"authorId\":\"1898172\",\"name\":\"W. Yang\"},{\"authorId\":\"1476719517\",\"name\":\"Long Sun\"},{\"authorId\":\"51257183\",\"name\":\"Shiqi Wang\"}],\"doi\":\"10.1145/3394171.3413504\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"1f35d2eeeb86e99f7254819e614e012acba4e535\",\"title\":\"When Bitstream Prior Meets Deep Prior: Compressed Video Super-resolution with Learning from Decoding\",\"url\":\"https://www.semanticscholar.org/paper/1f35d2eeeb86e99f7254819e614e012acba4e535\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405198343\",\"name\":\"Eduardo P\\u00e9rez-Pellitero\"},{\"authorId\":\"2283034\",\"name\":\"Mehdi S. M. Sajjadi\"},{\"authorId\":\"144566512\",\"name\":\"M. Hirsch\"},{\"authorId\":\"46224364\",\"name\":\"B. Sch\\u00f6lkopf\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8b268dfb22e80862d84855ada1a1d85fee5d7d20\",\"title\":\"Perceptual Video Super Resolution with Enhanced Temporal Consistency.\",\"url\":\"https://www.semanticscholar.org/paper/8b268dfb22e80862d84855ada1a1d85fee5d7d20\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1435353062\",\"name\":\"Hetao Cui\"},{\"authorId\":\"152842848\",\"name\":\"Quansen Sun\"}],\"doi\":\"10.1007/978-3-030-36189-1_35\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dbfc9be2cdb450401530a26e608fc572941adf55\",\"title\":\"Multi-scale Residual Dense Block for Video Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/dbfc9be2cdb450401530a26e608fc572941adf55\",\"venue\":\"IScIDE\",\"year\":2019},{\"arxivId\":\"1712.04143\",\"authors\":[{\"authorId\":\"7480219\",\"name\":\"Boyi Li\"},{\"authorId\":\"144850642\",\"name\":\"W. Ren\"},{\"authorId\":\"32718221\",\"name\":\"Dengpan Fu\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\"},{\"authorId\":\"145318724\",\"name\":\"D. Feng\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"},{\"authorId\":\"2969311\",\"name\":\"Zhangyang Wang\"}],\"doi\":\"10.1109/TIP.2018.2867951\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"abf75b81b96ff2cd262086675deba55f907108db\",\"title\":\"Benchmarking Single-Image Dehazing and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/abf75b81b96ff2cd262086675deba55f907108db\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"1812.02898\",\"authors\":[{\"authorId\":\"34777509\",\"name\":\"Yapeng Tian\"},{\"authorId\":\"2410227\",\"name\":\"Yulun Zhang\"},{\"authorId\":\"46956675\",\"name\":\"Yun Fu\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":\"10.1109/cvpr42600.2020.00342\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"02c6f4bb3adb4ce080575c122eb6430d2dc2a8ef\",\"title\":\"TDAN: Temporally-Deformable Alignment Network for Video Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/02c6f4bb3adb4ce080575c122eb6430d2dc2a8ef\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2004.02432\",\"authors\":[{\"authorId\":\"2784241\",\"name\":\"Jaeyeon Kang\"},{\"authorId\":\"50008226\",\"name\":\"Younghyun Jo\"},{\"authorId\":\"3451982\",\"name\":\"S. Oh\"},{\"authorId\":\"48682997\",\"name\":\"P. Vajda\"},{\"authorId\":\"1754380\",\"name\":\"S. Kim\"}],\"doi\":\"10.1007/978-3-030-58607-2_41\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fa3392f59cbf455a2083af5a4690903a0dbc15c8\",\"title\":\"Deep Space-Time Video Upsampling Networks\",\"url\":\"https://www.semanticscholar.org/paper/fa3392f59cbf455a2083af5a4690903a0dbc15c8\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1801.09710\",\"authors\":[{\"authorId\":\"47779150\",\"name\":\"Y. Xie\"},{\"authorId\":\"35358480\",\"name\":\"Erik Franz\"},{\"authorId\":\"32464128\",\"name\":\"Mengyu Chu\"},{\"authorId\":\"1786445\",\"name\":\"N. Th\\u00fcrey\"}],\"doi\":\"10.1145/3072959.3073643\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"07b924a1677e0c44aeedd18dbba349d5bc9ca10b\",\"title\":\"tempoGAN: A Temporally Coherent, Volumetric GAN for Super-resolution Fluid Flow\",\"url\":\"https://www.semanticscholar.org/paper/07b924a1677e0c44aeedd18dbba349d5bc9ca10b\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2517940\",\"name\":\"Haoyu Ren\"},{\"authorId\":\"1382637019\",\"name\":\"Mostafa El-Khamy\"},{\"authorId\":\"4914711\",\"name\":\"J. Lee\"}],\"doi\":\"10.1109/ICMEW.2018.8551569\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"2631e33cf221f3f32bb8e605eab3eb454a4cb140\",\"title\":\"Video Super Resolution Based on Deep Convolution Neural Network With Two-Stage Motion Compensation\",\"url\":\"https://www.semanticscholar.org/paper/2631e33cf221f3f32bb8e605eab3eb454a4cb140\",\"venue\":\"2018 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2018},{\"arxivId\":\"2009.06290\",\"authors\":[{\"authorId\":\"1389572577\",\"name\":\"Dario Fuoli\"},{\"authorId\":\"145314891\",\"name\":\"Z. Huang\"},{\"authorId\":\"2476317\",\"name\":\"Shuhang Gu\"},{\"authorId\":\"51166756\",\"name\":\"R. Timofte\"},{\"authorId\":\"2167647\",\"name\":\"Arnau Raventos\"},{\"authorId\":\"14954802\",\"name\":\"A. Esfandiari\"},{\"authorId\":\"1900939\",\"name\":\"S. Karout\"},{\"authorId\":\"47158219\",\"name\":\"Xuan Xu\"},{\"authorId\":\"51376876\",\"name\":\"X. Li\"},{\"authorId\":\"1742524784\",\"name\":\"Xin Xiong\"},{\"authorId\":\"2196950\",\"name\":\"Jin-ge Wang\"},{\"authorId\":\"1827887\",\"name\":\"Pablo Navarrete Michelini\"},{\"authorId\":\"47527956\",\"name\":\"Wen-Hao Zhang\"},{\"authorId\":\"46334734\",\"name\":\"D. Zhang\"},{\"authorId\":\"151482176\",\"name\":\"Hanwei Zhu\"},{\"authorId\":\"50321213\",\"name\":\"Dan Xia\"},{\"authorId\":\"9435454\",\"name\":\"H. Chen\"},{\"authorId\":\"4398255\",\"name\":\"Jinjin Gu\"},{\"authorId\":\"48806109\",\"name\":\"Z. Zhang\"},{\"authorId\":\"5872678\",\"name\":\"Tongtong Zhao\"},{\"authorId\":\"145382023\",\"name\":\"Shanshan Zhao\"},{\"authorId\":\"38957626\",\"name\":\"K. Akita\"},{\"authorId\":\"3081689\",\"name\":\"N. Ukita\"},{\"authorId\":\"1668049982\",\"name\":\"S. HrishikeshP.\"},{\"authorId\":\"1667997430\",\"name\":\"Densen Puthussery\"},{\"authorId\":\"1668035436\",\"name\":\"V. JijiC.\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c7ca1c9e187bf302833ce12b7f09de2e75e4eef1\",\"title\":\"AIM 2020 Challenge on Video Extreme Super-Resolution: Methods and Results\",\"url\":\"https://www.semanticscholar.org/paper/c7ca1c9e187bf302833ce12b7f09de2e75e4eef1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48003910\",\"name\":\"F. Li\"},{\"authorId\":\"7465771\",\"name\":\"Huihui Bai\"},{\"authorId\":\"46317075\",\"name\":\"Yuhang Zhao\"}],\"doi\":\"10.1109/TIP.2020.2972118\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9104d21f6dc42ee40d2cbaf9cbd26cd223f65021\",\"title\":\"Learning a Deep Dual Attention Network for Video Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/9104d21f6dc42ee40d2cbaf9cbd26cd223f65021\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"2003.13552\",\"authors\":[{\"authorId\":\"1490938140\",\"name\":\"Di Ma\"},{\"authorId\":\"151481685\",\"name\":\"Fangfang Zhang\"},{\"authorId\":\"1730897\",\"name\":\"D. Bull\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"47ba19b18bdb1071e0d7e9fb2bc3ed188cda7b0f\",\"title\":\"BVI-DVC: A Training Database for Deep Video Compression\",\"url\":\"https://www.semanticscholar.org/paper/47ba19b18bdb1071e0d7e9fb2bc3ed188cda7b0f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2563691\",\"name\":\"R. Kalarot\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"}],\"doi\":\"10.1109/CVPRW.2019.00258\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4495aecd4f02155822fc09ffea2c23ad3a2526c4\",\"title\":\"MultiBoot Vsr: Multi-Stage Multi-Reference Bootstrapping for Video Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/4495aecd4f02155822fc09ffea2c23ad3a2526c4\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1749968\",\"name\":\"X. Xiang\"},{\"authorId\":\"1628807044\",\"name\":\"Hao Wei\"},{\"authorId\":\"2302673\",\"name\":\"Jin-shan Pan\"}],\"doi\":\"10.1109/TIP.2020.3023534\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"25baa7b79380dd9890c285bfd4ecf4104c2fe4ed\",\"title\":\"Deep Video Deblurring Using Sharpness Features From Exemplars\",\"url\":\"https://www.semanticscholar.org/paper/25baa7b79380dd9890c285bfd4ecf4104c2fe4ed\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491623266\",\"name\":\"Vikram Singh\"},{\"authorId\":\"1644317146\",\"name\":\"Keerthan Ramnath\"},{\"authorId\":\"1644221561\",\"name\":\"Subrahmanyam Arunachalam\"},{\"authorId\":\"50853059\",\"name\":\"Anurag Mittal\"}],\"doi\":\"10.1109/WACV45572.2020.9093317\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a0bf9addeaf270fd4a0fa793cc86d1a1bc7b5b32\",\"title\":\"Going Much Wider with Deep Networks for Image Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/a0bf9addeaf270fd4a0fa793cc86d1a1bc7b5b32\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"2010.00154\",\"authors\":[{\"authorId\":\"47158219\",\"name\":\"Xuan Xu\"},{\"authorId\":\"1742524784\",\"name\":\"Xin Xiong\"},{\"authorId\":\"2196950\",\"name\":\"Jin-ge Wang\"},{\"authorId\":\"3223020\",\"name\":\"Xin Li\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0446af32dc10062925fa2a1514b620cd80725181\",\"title\":\"Deformable Kernel Convolutional Network for Video Extreme Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/0446af32dc10062925fa2a1514b620cd80725181\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98481989\",\"name\":\"Shi Li\"},{\"authorId\":\"1740041\",\"name\":\"Xiao-Diao Chen\"},{\"authorId\":\"1809333\",\"name\":\"S. Zhou\"},{\"authorId\":\"1864356\",\"name\":\"Wan-Bin Pan\"},{\"authorId\":null,\"name\":\"Yigang Wang\"}],\"doi\":\"10.1109/ACCESS.2020.2981575\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c3ecaf3e466243ca00ac206af276041a83ce0b80\",\"title\":\"SAR Analysis for Real Video Super- Resolution Improvement\",\"url\":\"https://www.semanticscholar.org/paper/c3ecaf3e466243ca00ac206af276041a83ce0b80\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"103674589\",\"name\":\"M. Haitham\"},{\"authorId\":\"32287807\",\"name\":\"A. Zaghloul\"},{\"authorId\":\"1409263716\",\"name\":\"Mostafa AbdEl-Azeem\"}],\"doi\":\"10.1007/978-3-030-44289-7_47\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"58d836078ac4e4d41ba98a8ce7b92b322d7bf6a9\",\"title\":\"RDB-FSU: Residual Dense Network with Feature Selection Unit for Image Super Resolution\",\"url\":\"https://www.semanticscholar.org/paper/58d836078ac4e4d41ba98a8ce7b92b322d7bf6a9\",\"venue\":\"AICV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46867387\",\"name\":\"Yiwei Zhang\"},{\"authorId\":\"36766903\",\"name\":\"H. Huang\"},{\"authorId\":\"3240077\",\"name\":\"Q. Chen\"},{\"authorId\":\"47957556\",\"name\":\"X. Zhang\"},{\"authorId\":\"9434648\",\"name\":\"Jianxing Liang\"},{\"authorId\":\"47064076\",\"name\":\"H. Yin\"},{\"authorId\":\"50482010\",\"name\":\"X. Feng\"},{\"authorId\":\"1517195291\",\"name\":\"Shasha Wang\"}],\"doi\":\"10.1109/ICSAI48974.2019.9010122\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3e8c661f2a5d54e152382b5912e52c29f8fb20eb\",\"title\":\"Cascade Wide Activation Multi-Scale Networks for Single Image Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/3e8c661f2a5d54e152382b5912e52c29f8fb20eb\",\"venue\":\"2019 6th International Conference on Systems and Informatics (ICSAI)\",\"year\":2019},{\"arxivId\":\"1911.11136\",\"authors\":[{\"authorId\":\"2082794\",\"name\":\"Chaowei Fang\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"50016941\",\"name\":\"Xiao-Guang Han\"},{\"authorId\":\"66616425\",\"name\":\"Yizhou Yu\"}],\"doi\":\"10.1109/TIP.2019.2955640\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5c774bd3ad4367a9d14c6590b8329864f14b9edc\",\"title\":\"Self-Enhanced Convolutional Network for Facial Video Hallucination\",\"url\":\"https://www.semanticscholar.org/paper/5c774bd3ad4367a9d14c6590b8329864f14b9edc\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1801.04590\",\"authors\":[{\"authorId\":\"2283034\",\"name\":\"Mehdi S. M. Sajjadi\"},{\"authorId\":\"39963722\",\"name\":\"Raviteja Vemulapalli\"},{\"authorId\":\"144735789\",\"name\":\"M. Brown\"}],\"doi\":\"10.1109/CVPR.2018.00693\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"aa3f7330f9b27e57745c4d14753893964ad91d5a\",\"title\":\"Frame-Recurrent Video Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/aa3f7330f9b27e57745c4d14753893964ad91d5a\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1804.00213\",\"authors\":[{\"authorId\":\"144850642\",\"name\":\"W. Ren\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"1718428\",\"name\":\"Jiawei Zhang\"},{\"authorId\":\"9416881\",\"name\":\"J. Pan\"},{\"authorId\":\"1719250\",\"name\":\"Xiaochun Cao\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/CVPR.2018.00343\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dbd21420cd1299fdab9a04c6b4b3b5b4d4a38a6d\",\"title\":\"Gated Fusion Network for Single Image Dehazing\",\"url\":\"https://www.semanticscholar.org/paper/dbd21420cd1299fdab9a04c6b4b3b5b4d4a38a6d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66283463\",\"name\":\"Flow\"},{\"authorId\":\"9071227\",\"name\":\"You Xie\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6c110e724ac33243f9d02ac061007057e0b30adf\",\"title\":\"tempoGAN: A Temporally Coherent, Volumetric GAN for Super-resolution Fluid Flow\",\"url\":\"https://www.semanticscholar.org/paper/6c110e724ac33243f9d02ac061007057e0b30adf\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143668321\",\"name\":\"Yuchen Fan\"},{\"authorId\":\"150167366\",\"name\":\"Jiahui Yu\"},{\"authorId\":\"1771885\",\"name\":\"Ding Liu\"},{\"authorId\":\"143750392\",\"name\":\"T. Huang\"}],\"doi\":\"10.1109/CVPRW.2019.00269\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"79d344c5705b3a54fc2af2c6783b0b4c65c706a0\",\"title\":\"An Empirical Investigation of Efficient Spatio-Temporal Modeling in Video Restoration\",\"url\":\"https://www.semanticscholar.org/paper/79d344c5705b3a54fc2af2c6783b0b4c65c706a0\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":\"1706.04695\",\"authors\":[{\"authorId\":\"19234500\",\"name\":\"Ricardo Augusto Borsoi\"},{\"authorId\":\"2883958\",\"name\":\"Guilherme Holsbach Costa\"},{\"authorId\":\"144907068\",\"name\":\"J. Bermudez\"}],\"doi\":\"10.1109/TIP.2018.2866181\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d1ee81648b3ac08c4394e4162bc1230a713dc7b1\",\"title\":\"A New Adaptive Video Super-Resolution Algorithm With Improved Robustness to Innovations\",\"url\":\"https://www.semanticscholar.org/paper/d1ee81648b3ac08c4394e4162bc1230a713dc7b1\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"1712.07732\",\"authors\":[{\"authorId\":\"1771885\",\"name\":\"Ding Liu\"},{\"authorId\":\"50563570\",\"name\":\"Bowen Cheng\"},{\"authorId\":\"2969311\",\"name\":\"Zhangyang Wang\"},{\"authorId\":\"46701859\",\"name\":\"H. Zhang\"},{\"authorId\":\"1739208\",\"name\":\"T. Huang\"}],\"doi\":\"10.1109/TIP.2019.2908802\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"735b81a9e5f3c2f8d92a1a57c643fffae5d5f6b2\",\"title\":\"Enhance Visual Recognition Under Adverse Conditions via Deep Networks\",\"url\":\"https://www.semanticscholar.org/paper/735b81a9e5f3c2f8d92a1a57c643fffae5d5f6b2\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"1811.09393\",\"authors\":[{\"authorId\":\"32464128\",\"name\":\"Mengyu Chu\"},{\"authorId\":\"9071227\",\"name\":\"You Xie\"},{\"authorId\":\"2208679\",\"name\":\"Jonas Mayer\"},{\"authorId\":\"1388407684\",\"name\":\"L. Leal-Taix\\u00e9\"},{\"authorId\":\"1786445\",\"name\":\"N. Th\\u00fcrey\"}],\"doi\":\"10.1145/3386569.3392457\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9e52488ea7e83bf44aaa94c86b337a66f326c5e6\",\"title\":\"Learning temporal coherence via self-supervision for GAN-based video generation\",\"url\":\"https://www.semanticscholar.org/paper/9e52488ea7e83bf44aaa94c86b337a66f326c5e6\",\"venue\":\"ACM Trans. Graph.\",\"year\":2020},{\"arxivId\":\"2001.02129\",\"authors\":[{\"authorId\":\"29957038\",\"name\":\"Longguang Wang\"},{\"authorId\":\"2985328\",\"name\":\"Yulan Guo\"},{\"authorId\":\"2553333\",\"name\":\"L. Liu\"},{\"authorId\":\"7766962\",\"name\":\"Zaiping Lin\"},{\"authorId\":\"9409172\",\"name\":\"Xinpu Deng\"},{\"authorId\":\"144813586\",\"name\":\"Wei An\"}],\"doi\":\"10.1109/tip.2020.2967596\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"07445e71c473bd3813a4f4ce7d6e6a15e278f36e\",\"title\":\"Deep Video Super-Resolution Using HR Optical Flow Estimation\",\"url\":\"https://www.semanticscholar.org/paper/07445e71c473bd3813a4f4ce7d6e6a15e278f36e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"2012.13033\",\"authors\":[{\"authorId\":\"1389572577\",\"name\":\"Dario Fuoli\"},{\"authorId\":\"145314891\",\"name\":\"Z. Huang\"},{\"authorId\":\"35268081\",\"name\":\"D. Paudel\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"1732855\",\"name\":\"R. Timofte\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c890b5ef847de07393526be4b6e337215e9dc1b6\",\"title\":\"An Efficient Recurrent Adversarial Framework for Unsupervised Real-Time Video Enhancement\",\"url\":\"https://www.semanticscholar.org/paper/c890b5ef847de07393526be4b6e337215e9dc1b6\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2101.00150\",\"authors\":[{\"authorId\":null,\"name\":\"Pablo Navarrete Michelini\"},{\"authorId\":null,\"name\":\"Wenbin Chen\"},{\"authorId\":null,\"name\":\"Hanwen Liu\"},{\"authorId\":null,\"name\":\"Dan Zhu\"},{\"authorId\":\"11796959\",\"name\":\"Xingqun Jiang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7264ddb2b66a4228d707a3ae4a50b0abf0caa5cc\",\"title\":\"Multi-Grid Back-Projection Networks\",\"url\":\"https://www.semanticscholar.org/paper/7264ddb2b66a4228d707a3ae4a50b0abf0caa5cc\",\"venue\":\"\",\"year\":2021},{\"arxivId\":\"1709.03919\",\"authors\":[{\"authorId\":\"7480219\",\"name\":\"Boyi Li\"},{\"authorId\":\"3050945\",\"name\":\"X. Peng\"},{\"authorId\":\"2969311\",\"name\":\"Zhangyang Wang\"},{\"authorId\":\"1697982\",\"name\":\"Jizheng Xu\"},{\"authorId\":\"49732222\",\"name\":\"Dan Feng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2054d011a64b2d4bb2e99529c7a717966f096797\",\"title\":\"End-to-End United Video Dehazing and Detection\",\"url\":\"https://www.semanticscholar.org/paper/2054d011a64b2d4bb2e99529c7a717966f096797\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1679219\",\"name\":\"T. Kim\"},{\"authorId\":\"2283034\",\"name\":\"Mehdi S. M. Sajjadi\"},{\"authorId\":\"144566512\",\"name\":\"M. Hirsch\"},{\"authorId\":\"1707625\",\"name\":\"B. Sch\\u00f6lkopf\"}],\"doi\":\"10.1007/978-3-030-01219-9_7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"96b1b632fbc3694ff648bb7c22657dc4525f29f2\",\"title\":\"Spatio-Temporal Transformer Network for Video Restoration\",\"url\":\"https://www.semanticscholar.org/paper/96b1b632fbc3694ff648bb7c22657dc4525f29f2\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144783081\",\"name\":\"You Xie\"},{\"authorId\":\"35358480\",\"name\":\"Erik Franz\"},{\"authorId\":\"32464128\",\"name\":\"Mengyu Chu\"},{\"authorId\":\"1786445\",\"name\":\"N. Th\\u00fcrey\"}],\"doi\":\"10.1145/3197517.3201304\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2e0605ba5cfe30864a514c8a69460dbb59d68df3\",\"title\":\"tempoGAN: A Temporally Coherent, Volumetric GAN for Super-resolution Fluid Flow\",\"url\":\"https://www.semanticscholar.org/paper/2e0605ba5cfe30864a514c8a69460dbb59d68df3\",\"venue\":\"ACM Trans. Graph.\",\"year\":2018},{\"arxivId\":\"2006.11161\",\"authors\":[{\"authorId\":\"40016108\",\"name\":\"Aman Chadha\"}],\"doi\":\"10.1007/s41095-020-0175-7\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"96848693030ba20518ebb12b3dd2c4d4e04ec886\",\"title\":\"iSeeBetter: Spatio-temporal video super-resolution using recurrent generative back-projection networks\",\"url\":\"https://www.semanticscholar.org/paper/96848693030ba20518ebb12b3dd2c4d4e04ec886\",\"venue\":\"Computational Visual Media\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48550129\",\"name\":\"Jiajun Deng\"},{\"authorId\":\"34413938\",\"name\":\"Haichao Yu\"},{\"authorId\":\"2969311\",\"name\":\"Zhangyang Wang\"},{\"authorId\":\"48631088\",\"name\":\"Xinchao Wang\"},{\"authorId\":\"1739208\",\"name\":\"T. Huang\"}],\"doi\":\"10.1109/MIPR.2019.00042\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4e20404e8cd2ccac389b1ce6ff4690f1fd29404e\",\"title\":\"Self-Reproducing Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/4e20404e8cd2ccac389b1ce6ff4690f1fd29404e\",\"venue\":\"2019 IEEE Conference on Multimedia Information Processing and Retrieval (MIPR)\",\"year\":2019},{\"arxivId\":\"2008.00455\",\"authors\":[{\"authorId\":\"70116446\",\"name\":\"T. Isobe\"},{\"authorId\":\"1641711590\",\"name\":\"Xu Jia\"},{\"authorId\":\"2476317\",\"name\":\"Shuhang Gu\"},{\"authorId\":\"153061158\",\"name\":\"Songjiang Li\"},{\"authorId\":\"103307901\",\"name\":\"Shengjin Wang\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1007/978-3-030-58610-2_38\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3337fd0fa0ab5420e350714edc7c20aed9717965\",\"title\":\"Video Super-Resolution with Recurrent Structure-Detail Network\",\"url\":\"https://www.semanticscholar.org/paper/3337fd0fa0ab5420e350714edc7c20aed9717965\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145108524\",\"name\":\"Yanan Wu\"},{\"authorId\":\"31365222\",\"name\":\"S. Kamata\"}],\"doi\":\"10.1145/3376067.3376079\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ec85b4d25d4c50b57f82a1f3e957eabff13aed60\",\"title\":\"Video Super-Resolution Using Wave-Shape Network\",\"url\":\"https://www.semanticscholar.org/paper/ec85b4d25d4c50b57f82a1f3e957eabff13aed60\",\"venue\":\"ICVIP\",\"year\":2019},{\"arxivId\":\"1909.00073\",\"authors\":[{\"authorId\":\"19234500\",\"name\":\"R. Borsoi\"}],\"doi\":\"10.1016/j.sigpro.2020.107575\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b630fb52f14f6b00554ca6175594927d33cf4ad2\",\"title\":\"Robust Online Video Super-Resolution Using an Efficient Alternating Projections Scheme\",\"url\":\"https://www.semanticscholar.org/paper/b630fb52f14f6b00554ca6175594927d33cf4ad2\",\"venue\":\"Signal Process.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1771885\",\"name\":\"Ding Liu\"}],\"doi\":\"10.24963/ijcai.2018/831\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ed7ea78ebd2d18e9b97e96b773de3e27003738a0\",\"title\":\"Connecting Low-Level Image Processing and High-Level Vision via Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/ed7ea78ebd2d18e9b97e96b773de3e27003738a0\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3492121\",\"name\":\"D. Li\"},{\"authorId\":\"47908786\",\"name\":\"Y. Liu\"},{\"authorId\":\"1766719\",\"name\":\"Z. Wang\"}],\"doi\":\"10.1109/TIP.2018.2877334\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"76e0ed528dfb78ae5d8b8665a853fe6bc72e3869\",\"title\":\"Video Super-Resolution Using Non-Simultaneous Fully Recurrent Convolutional Network\",\"url\":\"https://www.semanticscholar.org/paper/76e0ed528dfb78ae5d8b8665a853fe6bc72e3869\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48708411\",\"name\":\"Zhongyuan Wang\"},{\"authorId\":\"145526138\",\"name\":\"Peng Yi\"},{\"authorId\":\"51360637\",\"name\":\"Kui Jiang\"},{\"authorId\":\"1708439\",\"name\":\"J. Jiang\"},{\"authorId\":\"144725609\",\"name\":\"Zhen Han\"},{\"authorId\":\"41213081\",\"name\":\"T. Lu\"},{\"authorId\":\"8555475\",\"name\":\"Jiayi Ma\"}],\"doi\":\"10.1109/TIP.2018.2887017\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a17b87c4af86d4cdd9d1aa0ea336295669e40c91\",\"title\":\"Multi-Memory Convolutional Neural Network for Video Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/a17b87c4af86d4cdd9d1aa0ea336295669e40c91\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40648435\",\"name\":\"Seungjun Nah\"},{\"authorId\":\"148009160\",\"name\":\"Sungyong Baik\"},{\"authorId\":\"150297656\",\"name\":\"Seokil Hong\"},{\"authorId\":\"3458134\",\"name\":\"Gyeongsik Moon\"},{\"authorId\":\"4640997\",\"name\":\"Sanghyun Son\"},{\"authorId\":\"1732855\",\"name\":\"R. Timofte\"},{\"authorId\":\"2135837\",\"name\":\"Kyoung Mu Lee\"}],\"doi\":\"10.1109/CVPRW.2019.00251\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"24cfdfff5e2794600b018e867ddbf07d80467dec\",\"title\":\"NTIRE 2019 Challenge on Video Deblurring and Super-Resolution: Dataset and Study\",\"url\":\"https://www.semanticscholar.org/paper/24cfdfff5e2794600b018e867ddbf07d80467dec\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":\"1908.03826\",\"authors\":[{\"authorId\":\"47133874\",\"name\":\"Orest Kupyn\"},{\"authorId\":\"101029400\",\"name\":\"Tetiana Martyniuk\"},{\"authorId\":\"14737712\",\"name\":\"Junru Wu\"},{\"authorId\":\"2969311\",\"name\":\"Zhangyang Wang\"}],\"doi\":\"10.1109/ICCV.2019.00897\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"81c1dc00b32d12edfab00656593f5db56cfa79e0\",\"title\":\"DeblurGAN-v2: Deblurring (Orders-of-Magnitude) Faster and Better\",\"url\":\"https://www.semanticscholar.org/paper/81c1dc00b32d12edfab00656593f5db56cfa79e0\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1878633286\",\"name\":\"Xi Ling\"},{\"authorId\":\"2300036\",\"name\":\"Chun-Ling Yang\"},{\"authorId\":\"1878920158\",\"name\":\"Hanqi Pei\"}],\"doi\":\"10.1109/ICME46284.2020.9102723\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d60fed4858b5fa9f4694e40011325992cdeb88e2\",\"title\":\"Compressed Video Sensing Network Based On Alignment Prediction And Residual Reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/d60fed4858b5fa9f4694e40011325992cdeb88e2\",\"venue\":\"2020 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46912432\",\"name\":\"W. Sun\"},{\"authorId\":\"48379046\",\"name\":\"Y. Zhang\"}],\"doi\":\"10.1016/j.neucom.2020.03.068\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b02f0133133fd0d367d119ae21344f7ebb043626\",\"title\":\"Attention-guided dual spatial-temporal non-local network for video super-resolution\",\"url\":\"https://www.semanticscholar.org/paper/b02f0133133fd0d367d119ae21344f7ebb043626\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"2007.07099\",\"authors\":[{\"authorId\":\"1490938140\",\"name\":\"Di Ma\"},{\"authorId\":\"151481685\",\"name\":\"Fangfang Zhang\"},{\"authorId\":\"1730897\",\"name\":\"D. Bull\"}],\"doi\":\"10.1109/JSTSP.2020.3043064\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d4a1b6751045767cc1e0c42bda029c9c00b31c3c\",\"title\":\"MFRNet: A New CNN Architecture for Post-Processing and In-loop Filtering\",\"url\":\"https://www.semanticscholar.org/paper/d4a1b6751045767cc1e0c42bda029c9c00b31c3c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1456030258\",\"name\":\"Wei Xue\"},{\"authorId\":\"119636186\",\"name\":\"H. Ai\"},{\"authorId\":\"48789454\",\"name\":\"Tianyu Sun\"},{\"authorId\":\"3358591\",\"name\":\"Chunfeng Song\"},{\"authorId\":\"144368930\",\"name\":\"Yan Huang\"},{\"authorId\":\"123865558\",\"name\":\"Liang Wang\"}],\"doi\":\"10.1016/j.neucom.2019.11.015\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4f2ec817c142710d6f53e90c1ff25327b823eddb\",\"title\":\"Frame-GAN: Increasing the frame rate of gait videos with generative adversarial networks\",\"url\":\"https://www.semanticscholar.org/paper/4f2ec817c142710d6f53e90c1ff25327b823eddb\",\"venue\":\"Neurocomputing\",\"year\":2020}],\"corpusId\":23339528,\"doi\":\"10.1109/ICCV.2017.274\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":18,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"e378ce25579f3676ca50c8f6454e92a886b9e4d7\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"1771885\",\"name\":\"Ding Liu\"},{\"authorId\":\"1706007\",\"name\":\"Jianchao Yang\"},{\"authorId\":\"143911112\",\"name\":\"Wei Han\"},{\"authorId\":\"1739208\",\"name\":\"T. Huang\"}],\"doi\":\"10.1109/ICCV.2015.50\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"27fc88ebb3e325a062a6ff48a7a76611af1ecd5a\",\"title\":\"Deep Networks for Image Super-Resolution with Sparse Prior\",\"url\":\"https://www.semanticscholar.org/paper/27fc88ebb3e325a062a6ff48a7a76611af1ecd5a\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145557639\",\"name\":\"V. Nair\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a538b05ebb01a40323997629e171c91aa28b8e2f\",\"title\":\"Rectified Linear Units Improve Restricted Boltzmann Machines\",\"url\":\"https://www.semanticscholar.org/paper/a538b05ebb01a40323997629e171c91aa28b8e2f\",\"venue\":\"ICML\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145128145\",\"name\":\"Lior Wolf\"},{\"authorId\":\"1756099\",\"name\":\"Tal Hassner\"},{\"authorId\":\"3352629\",\"name\":\"Itay Maoz\"}],\"doi\":\"10.1109/CVPR.2011.5995566\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f61a7a7cd13e2702f0fbacc05e13b355c1e297e2\",\"title\":\"Face recognition in unconstrained videos with matched background similarity\",\"url\":\"https://www.semanticscholar.org/paper/f61a7a7cd13e2702f0fbacc05e13b355c1e297e2\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Y. Chen\"},{\"authorId\":null,\"name\":\"L. Van Gool\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Max - imum a posteriori video super - resolution using a new multi - channel image prior\",\"url\":\"\",\"venue\":\"\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40441990\",\"name\":\"Armin Kappeler\"},{\"authorId\":\"7291752\",\"name\":\"Seunghwan Yoo\"},{\"authorId\":\"33764127\",\"name\":\"Qiqin Dai\"},{\"authorId\":\"144842935\",\"name\":\"A. Katsaggelos\"}],\"doi\":\"10.1109/TCI.2016.2532323\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e2bfd94a11226b31e7d477306c39a035551e6f56\",\"title\":\"Video Super-Resolution With Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/e2bfd94a11226b31e7d477306c39a035551e6f56\",\"venue\":\"IEEE Transactions on Computational Imaging\",\"year\":2016},{\"arxivId\":\"1601.04153\",\"authors\":[{\"authorId\":\"2969311\",\"name\":\"Zhangyang Wang\"},{\"authorId\":\"3307026\",\"name\":\"S. Chang\"},{\"authorId\":\"2680237\",\"name\":\"Yingzhen Yang\"},{\"authorId\":\"1771885\",\"name\":\"Ding Liu\"},{\"authorId\":\"1739208\",\"name\":\"T. Huang\"}],\"doi\":\"10.1109/CVPR.2016.518\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"288d2704205d9ca68660b9f3a8fda17e18329c13\",\"title\":\"Studying Very Low Resolution Recognition Using Deep Networks\",\"url\":\"https://www.semanticscholar.org/paper/288d2704205d9ca68660b9f3a8fda17e18329c13\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1608.00367\",\"authors\":[{\"authorId\":\"144964868\",\"name\":\"C. Dong\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1007/978-3-319-46475-6_25\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"79da740db9006b2aa3e7b571d038ec895e323121\",\"title\":\"Accelerating the Super-Resolution Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/79da740db9006b2aa3e7b571d038ec895e323121\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"28454117\",\"name\":\"J. Lin\"},{\"authorId\":\"145401371\",\"name\":\"R. Song\"},{\"authorId\":\"2672825\",\"name\":\"E. Wu\"},{\"authorId\":\"2048271\",\"name\":\"Tsung-Jung Liu\"},{\"authorId\":\"48016293\",\"name\":\"H. Wang\"},{\"authorId\":\"9363144\",\"name\":\"C.-C. Jay Kuo\"}],\"doi\":\"10.1016/j.jvcir.2015.02.012\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9b68b03bec9b15da2723fb5302cd96ec7b1f1d4d\",\"title\":\"MCL-V: A streaming video quality assessment database\",\"url\":\"https://www.semanticscholar.org/paper/9b68b03bec9b15da2723fb5302cd96ec7b1f1d4d\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1944405\",\"name\":\"M. Dorr\"},{\"authorId\":\"1764560\",\"name\":\"T. Martinetz\"},{\"authorId\":\"3322056\",\"name\":\"K. Gegenfurtner\"},{\"authorId\":\"143969565\",\"name\":\"E. Barth\"}],\"doi\":\"10.1167/10.10.28\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"31f6fccd1bed7dbb4f63a3c22ec7752ae97f0dba\",\"title\":\"Variability of eye movements when viewing dynamic natural scenes.\",\"url\":\"https://www.semanticscholar.org/paper/31f6fccd1bed7dbb4f63a3c22ec7752ae97f0dba\",\"venue\":\"Journal of vision\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"144968898\",\"name\":\"W. Lin\"},{\"authorId\":\"7175017\",\"name\":\"Chenwei Deng\"},{\"authorId\":\"1684869\",\"name\":\"K. N. Ngan\"}],\"doi\":\"10.1109/ISCAS.2012.6271858\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b64827ec86c8a03568aaa61ab38428c774b1aaed\",\"title\":\"Study of subjective and objective quality assessment of retargeted images\",\"url\":\"https://www.semanticscholar.org/paper/b64827ec86c8a03568aaa61ab38428c774b1aaed\",\"venue\":\"2012 IEEE International Symposium on Circuits and Systems\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50439289\",\"name\":\"D. Liu\"},{\"authorId\":\"50218411\",\"name\":\"Z. Wang\"},{\"authorId\":\"1766554\",\"name\":\"B. Wen\"},{\"authorId\":\"1706007\",\"name\":\"Jianchao Yang\"},{\"authorId\":\"143911112\",\"name\":\"Wei Han\"},{\"authorId\":\"143750392\",\"name\":\"T. Huang\"}],\"doi\":\"10.1109/TIP.2016.2564643\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"230fdf30c888fff2c274ed0eada9eab9ee8e3fa2\",\"title\":\"Robust Single Image Super-Resolution via Deep Networks With Sparse Prior.\",\"url\":\"https://www.semanticscholar.org/paper/230fdf30c888fff2c274ed0eada9eab9ee8e3fa2\",\"venue\":\"IEEE transactions on image processing : a publication of the IEEE Signal Processing Society\",\"year\":2016},{\"arxivId\":\"1506.02025\",\"authors\":[{\"authorId\":\"3093886\",\"name\":\"Max Jaderberg\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fe87ea16d5eb1c7509da9a0314bbf4c7b0676506\",\"title\":\"Spatial Transformer Networks\",\"url\":\"https://www.semanticscholar.org/paper/fe87ea16d5eb1c7509da9a0314bbf4c7b0676506\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1711485\",\"name\":\"K. Seshadrinathan\"},{\"authorId\":\"2510315\",\"name\":\"R. Soundararajan\"},{\"authorId\":\"1393477616\",\"name\":\"Alan Conrad Bovik\"},{\"authorId\":\"1392690388\",\"name\":\"L. Cormack\"}],\"doi\":\"10.1109/TIP.2010.2042111\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2fbc5ff6378caf42df5dc916cc92001e683fae56\",\"title\":\"Study of Subjective and Objective Quality Assessment of Video\",\"url\":\"https://www.semanticscholar.org/paper/2fbc5ff6378caf42df5dc916cc92001e683fae56\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2010},{\"arxivId\":\"1609.05158\",\"authors\":[{\"authorId\":\"2700496\",\"name\":\"W. Shi\"},{\"authorId\":\"145372820\",\"name\":\"J. Caballero\"},{\"authorId\":\"3108066\",\"name\":\"Ferenc Husz\\u00e1r\"},{\"authorId\":\"1853456\",\"name\":\"J. Totz\"},{\"authorId\":\"49931957\",\"name\":\"A. Aitken\"},{\"authorId\":\"50784424\",\"name\":\"R. Bishop\"},{\"authorId\":\"1717710\",\"name\":\"D. Rueckert\"},{\"authorId\":\"34627233\",\"name\":\"Zehan Wang\"}],\"doi\":\"10.1109/CVPR.2016.207\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"03a5b2aac53443e6078f0f63b35d4f95d6d54c5d\",\"title\":\"Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/03a5b2aac53443e6078f0f63b35d4f95d6d54c5d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144964868\",\"name\":\"C. Dong\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1007/978-3-319-10593-2_13\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"0504945cc2d03550fecb6ff02e637f9421107c25\",\"title\":\"Learning a Deep Convolutional Network for Image Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/0504945cc2d03550fecb6ff02e637f9421107c25\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2376789\",\"name\":\"Z. Ma\"},{\"authorId\":\"2246396\",\"name\":\"Renjie Liao\"},{\"authorId\":\"37983219\",\"name\":\"X. Tao\"},{\"authorId\":\"144574904\",\"name\":\"L. Xu\"},{\"authorId\":\"1729056\",\"name\":\"J. Jia\"},{\"authorId\":\"145344139\",\"name\":\"Enhua Wu\"}],\"doi\":\"10.1109/CVPR.2015.7299159\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ae22f04749de2cb06c0ad3ce8f3848141e112f22\",\"title\":\"Handling motion blur in multi-frame super-resolution\",\"url\":\"https://www.semanticscholar.org/paper/ae22f04749de2cb06c0ad3ce8f3848141e112f22\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1511.04491\",\"authors\":[{\"authorId\":\"82101466\",\"name\":\"J. Kim\"},{\"authorId\":\"3088401\",\"name\":\"J. Lee\"},{\"authorId\":\"2135837\",\"name\":\"Kyoung Mu Lee\"}],\"doi\":\"10.1109/CVPR.2016.181\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"06c06885fd53b2cbd407704cf14f658842ed48e5\",\"title\":\"Deeply-Recursive Convolutional Network for Image Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/06c06885fd53b2cbd407704cf14f658842ed48e5\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1408.5093\",\"authors\":[{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"1782282\",\"name\":\"Evan Shelhamer\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"3049736\",\"name\":\"S. Karayev\"},{\"authorId\":\"144361581\",\"name\":\"J. Long\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1145/2647868.2654889\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6bdb186ec4726e00a8051119636d4df3b94043b5\",\"title\":\"Caffe: Convolutional Architecture for Fast Feature Embedding\",\"url\":\"https://www.semanticscholar.org/paper/6bdb186ec4726e00a8051119636d4df3b94043b5\",\"venue\":\"ACM Multimedia\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1681442\",\"name\":\"Ce Liu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"66313d48a6352e731e40450f80a66c64aabae817\",\"title\":\"Exploring new representations and applications for motion analysis\",\"url\":\"https://www.semanticscholar.org/paper/66313d48a6352e731e40450f80a66c64aabae817\",\"venue\":\"\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1695360\",\"name\":\"H. Takeda\"},{\"authorId\":\"1718280\",\"name\":\"P. Milanfar\"},{\"authorId\":\"2941687\",\"name\":\"M. Protter\"},{\"authorId\":\"1753908\",\"name\":\"Michael Elad\"}],\"doi\":\"10.1109/tip.2009.2023703\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1056e2f995f9f205dfbad6faf1d1e2994a82230b\",\"title\":\"Super-Resolution Without Explicit Subpixel Motion Estimation\",\"url\":\"https://www.semanticscholar.org/paper/1056e2f995f9f205dfbad6faf1d1e2994a82230b\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2009},{\"arxivId\":\"1409.4842\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"46641766\",\"name\":\"W. Liu\"},{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"},{\"authorId\":\"48840704\",\"name\":\"Scott Reed\"},{\"authorId\":\"1838674\",\"name\":\"Dragomir Anguelov\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"39863668\",\"name\":\"Andrew Rabinovich\"}],\"doi\":\"10.1109/CVPR.2015.7298594\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"title\":\"Going deeper with convolutions\",\"url\":\"https://www.semanticscholar.org/paper/e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2860210\",\"name\":\"Stefanos P. Belekos\"},{\"authorId\":\"143949487\",\"name\":\"N. Galatsanos\"},{\"authorId\":\"144842935\",\"name\":\"A. Katsaggelos\"}],\"doi\":\"10.1109/TIP.2010.2042115\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9c27e20d65f1592378e82aeefc59391729e11927\",\"title\":\"Maximum a Posteriori Video Super-Resolution Using a New Multichannel Image Prior\",\"url\":\"https://www.semanticscholar.org/paper/9c27e20d65f1592378e82aeefc59391729e11927\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766409\",\"name\":\"Christian Keimel\"},{\"authorId\":\"1767289\",\"name\":\"Julian Habigt\"},{\"authorId\":\"3213142\",\"name\":\"Tim Habigt\"},{\"authorId\":\"1988394\",\"name\":\"Martin Rothbucher\"},{\"authorId\":\"1686825\",\"name\":\"K. Diepold\"}],\"doi\":\"10.1109/MMSP.2010.5662052\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9eb4b4dd1665bf95eaaafa76fcd2bc8784d6c039\",\"title\":\"Visual quality of current coding technologies at high definition IPTV bitrates\",\"url\":\"https://www.semanticscholar.org/paper/9eb4b4dd1665bf95eaaafa76fcd2bc8784d6c039\",\"venue\":\"2010 IEEE International Workshop on Multimedia Signal Processing\",\"year\":2010},{\"arxivId\":\"1511.04587\",\"authors\":[{\"authorId\":\"3968500\",\"name\":\"Jiwon Kim\"},{\"authorId\":\"3088401\",\"name\":\"J. Lee\"},{\"authorId\":\"2135837\",\"name\":\"Kyoung Mu Lee\"}],\"doi\":\"10.1109/CVPR.2016.182\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b5f3e5d2912bedbcd9458952d664b08db6aed962\",\"title\":\"Accurate Image Super-Resolution Using Very Deep Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/b5f3e5d2912bedbcd9458952d664b08db6aed962\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Sina Farsiu\"},{\"authorId\":\"46622873\",\"name\":\"M. D. Robinson\"},{\"authorId\":\"1753908\",\"name\":\"Michael Elad\"},{\"authorId\":\"1718280\",\"name\":\"P. Milanfar\"}],\"doi\":\"10.1109/TIP.2004.834669\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"61997bb7d5a041353582599caf52fd5014cf60cb\",\"title\":\"Fast and robust multiframe super resolution\",\"url\":\"https://www.semanticscholar.org/paper/61997bb7d5a041353582599caf52fd5014cf60cb\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2004},{\"arxivId\":\"1509.07009\",\"authors\":[{\"authorId\":\"1778526\",\"name\":\"Dengxin Dai\"},{\"authorId\":\"2297600\",\"name\":\"Yujian Wang\"},{\"authorId\":\"49069469\",\"name\":\"Y. Chen\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/WACV.2016.7477613\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f3e9d7f7b71768c5fb179e5c98243febfe79d668\",\"title\":\"Is image super-resolution helpful for other vision tasks?\",\"url\":\"https://www.semanticscholar.org/paper/f3e9d7f7b71768c5fb179e5c98243febfe79d668\",\"venue\":\"2016 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2246396\",\"name\":\"Renjie Liao\"},{\"authorId\":\"37983219\",\"name\":\"X. Tao\"},{\"authorId\":\"48881927\",\"name\":\"R. Li\"},{\"authorId\":\"2376789\",\"name\":\"Z. Ma\"},{\"authorId\":\"1729056\",\"name\":\"J. Jia\"}],\"doi\":\"10.1109/ICCV.2015.68\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"30b5998c47079de5c83d7acb9359ce760c72709e\",\"title\":\"Video Super-Resolution via Deep Draft-Ensemble Learning\",\"url\":\"https://www.semanticscholar.org/paper/30b5998c47079de5c83d7acb9359ce760c72709e\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1681442\",\"name\":\"Ce Liu\"},{\"authorId\":\"3232265\",\"name\":\"Deqing Sun\"}],\"doi\":\"10.1109/TPAMI.2013.127\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f6ff6a8ad657cc7bbf38443e9ad6d18625caff2f\",\"title\":\"On Bayesian adaptive video super resolution.\",\"url\":\"https://www.semanticscholar.org/paper/f6ff6a8ad657cc7bbf38443e9ad6d18625caff2f\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49867037\",\"name\":\"Y. Huang\"},{\"authorId\":\"41173169\",\"name\":\"W. Wang\"},{\"authorId\":null,\"name\":\"Liang Wang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1ace46f46455262123e1decbc7cbf8f27bdd61c5\",\"title\":\"Bidirectional Recurrent Convolutional Networks for Multi-Frame Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/1ace46f46455262123e1decbc7cbf8f27bdd61c5\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1701.00823\",\"authors\":[{\"authorId\":\"1771885\",\"name\":\"Ding Liu\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"8147588\",\"name\":\"N. Nasrabadi\"},{\"authorId\":\"1739208\",\"name\":\"T. Huang\"}],\"doi\":\"10.1007/978-3-319-54187-7_10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0f111f49d0de8bc90ed02baef42b2968f6519bae\",\"title\":\"Learning a Mixture of Deep Networks for Single Image Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/0f111f49d0de8bc90ed02baef42b2968f6519bae\",\"venue\":\"ACCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":\"1501.00092\",\"authors\":[{\"authorId\":\"144964868\",\"name\":\"C. Dong\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1109/TPAMI.2015.2439281\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"66e9dc728b5041271bff0cd6ac0d7eadcd88442f\",\"title\":\"Image Super-Resolution Using Deep Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/66e9dc728b5041271bff0cd6ac0d7eadcd88442f\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2016}],\"title\":\"Robust Video Super-Resolution with Learned Temporal Dynamics\",\"topics\":[{\"topic\":\"Super-resolution imaging\",\"topicId\":\"127408\",\"url\":\"https://www.semanticscholar.org/topic/127408\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"},{\"topic\":\"Intra-frame coding\",\"topicId\":\"401454\",\"url\":\"https://www.semanticscholar.org/topic/401454\"},{\"topic\":\"End-to-end principle\",\"topicId\":\"299633\",\"url\":\"https://www.semanticscholar.org/topic/299633\"},{\"topic\":\"LR parser\",\"topicId\":\"81039\",\"url\":\"https://www.semanticscholar.org/topic/81039\"}],\"url\":\"https://www.semanticscholar.org/paper/e378ce25579f3676ca50c8f6454e92a886b9e4d7\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017}\n"