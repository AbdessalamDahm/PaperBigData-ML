"{\"abstract\":\"In this paper we introduce a novel Depth-Aware Video Saliency approach to predict human focus of attention when viewing videos that contain a depth map (RGBD) on a 2D screen. Saliency estimation in this scenario is highly important since in the near future 3D video content will be easily acquired yet hard to display. Despite considerable progress in 3D display technologies, most are still expensive and require special glasses for viewing, so RGBD content is primarily viewed on 2D screens, removing the depth channel from the final viewing experience. We train a generative convolutional neural network that predicts the 2D viewing saliency map for a given frame using the RGBD pixel values and previous fixation estimates in the video. To evaluate the performance of our approach, we present a new comprehensive database of 2D viewing eye-fixation ground-truth for RGBD videos. Our experiments indicate that it is beneficial to integrate depth into video saliency estimates for content that is viewed on a 2D display. We demonstrate that our approach outperforms state-of-the-art methods for video saliency, achieving 15% relative improvement.\",\"arxivId\":\"1603.03669\",\"authors\":[{\"authorId\":\"2190047\",\"name\":\"G. Leifman\",\"url\":\"https://www.semanticscholar.org/author/2190047\"},{\"authorId\":\"40635259\",\"name\":\"D. Rudoy\",\"url\":\"https://www.semanticscholar.org/author/40635259\"},{\"authorId\":\"2161276\",\"name\":\"Tristan Swedish\",\"url\":\"https://www.semanticscholar.org/author/2161276\"},{\"authorId\":\"1398734187\",\"name\":\"E. Bayro-Corrochano\",\"url\":\"https://www.semanticscholar.org/author/1398734187\"},{\"authorId\":\"145711633\",\"name\":\"R. Raskar\",\"url\":\"https://www.semanticscholar.org/author/145711633\"}],\"citationVelocity\":8,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1412924865\",\"name\":\"Kevin Cortacero\"},{\"authorId\":\"144881168\",\"name\":\"Tobias Fischer\"},{\"authorId\":\"1699337\",\"name\":\"Y. Demiris\"}],\"doi\":\"10.1109/ICCVW.2019.00147\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3081c8dc80ec3a0b653eb1bfa32fb2a579dd29fc\",\"title\":\"RT-BENE: A Dataset and Baselines for Real-Time Blink Estimation in Natural Environments\",\"url\":\"https://www.semanticscholar.org/paper/3081c8dc80ec3a0b653eb1bfa32fb2a579dd29fc\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38111179\",\"name\":\"Siavash Gorji\"},{\"authorId\":\"47125588\",\"name\":\"James J. Clark\"}],\"doi\":\"10.1109/CVPR.2018.00783\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9a2fae46c67189fb2aea33f12091772e635361f1\",\"title\":\"Going from Image to Video Saliency: Augmenting Image Salience with Dynamic Attentional Push\",\"url\":\"https://www.semanticscholar.org/paper/9a2fae46c67189fb2aea33f12091772e635361f1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1812.00722\",\"authors\":[{\"authorId\":\"2539459\",\"name\":\"Petros Koutras\"},{\"authorId\":\"1750686\",\"name\":\"P. Maragos\"}],\"doi\":\"10.1109/CVPRW.2019.00109\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e330af2d061ade245622b9445d5be9717f66b60f\",\"title\":\"SUSiNet: See, Understand and Summarize It\",\"url\":\"https://www.semanticscholar.org/paper/e330af2d061ade245622b9445d5be9717f66b60f\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":\"2001.03063\",\"authors\":[{\"authorId\":\"3200442\",\"name\":\"A. Tsiami\"},{\"authorId\":\"2539459\",\"name\":\"Petros Koutras\"},{\"authorId\":\"1750686\",\"name\":\"P. Maragos\"}],\"doi\":\"10.1109/cvpr42600.2020.00482\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e296a1f529d9caa125e8c6a56cac61423e04b41b\",\"title\":\"STAViS: Spatio-Temporal AudioVisual Saliency Network\",\"url\":\"https://www.semanticscholar.org/paper/e296a1f529d9caa125e8c6a56cac61423e04b41b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2012.11863\",\"authors\":[{\"authorId\":\"1739174065\",\"name\":\"Ke Wang\"},{\"authorId\":\"1400359889\",\"name\":\"Sai Ma\"},{\"authorId\":\"1740146246\",\"name\":\"Junlan Chen\"},{\"authorId\":\"49301701\",\"name\":\"Jianbo Lu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4efe76d5c2ddb45e2a87c4e3d71531f83e1275d7\",\"title\":\"Salient Bundle Adjustment for Visual SLAM\",\"url\":\"https://www.semanticscholar.org/paper/4efe76d5c2ddb45e2a87c4e3d71531f83e1275d7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1802.02522\",\"authors\":[{\"authorId\":\"26902477\",\"name\":\"Amir Rasouli\"},{\"authorId\":\"1727853\",\"name\":\"John K. Tsotsos\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6270914cf5f60627a1332bcc3f5951c9eea3be0\",\"title\":\"Joint Attention in Driver-Pedestrian Interaction: from Theory to Practice\",\"url\":\"https://www.semanticscholar.org/paper/a6270914cf5f60627a1332bcc3f5951c9eea3be0\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1582477446\",\"name\":\"Yasser Abdelaziz Dahou Djilali\"},{\"authorId\":\"49863790\",\"name\":\"M. Sayah\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"}],\"doi\":\"10.5220/0008875600270036\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"43cdf14f35966eab2d0e3418cea53715342cfce0\",\"title\":\"3DSAL: An Efficient 3D-CNN Architecture for Video Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/43cdf14f35966eab2d0e3418cea53715342cfce0\",\"venue\":\"VISIGRAPP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2539459\",\"name\":\"Petros Koutras\"},{\"authorId\":\"3411472\",\"name\":\"G. Panagiotaropoulou\"},{\"authorId\":\"3200442\",\"name\":\"A. Tsiami\"},{\"authorId\":\"1750686\",\"name\":\"P. Maragos\"}],\"doi\":\"10.1109/CVPRW.2018.00269\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"113eda25ece35fd7ecb51cb104182a973ea2313e\",\"title\":\"Audio-Visual Temporal Saliency Modeling Validated by fMRI Data\",\"url\":\"https://www.semanticscholar.org/paper/113eda25ece35fd7ecb51cb104182a973ea2313e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Xinyi Wu\"},{\"authorId\":\"153006222\",\"name\":\"Zhenyao Wu\"},{\"authorId\":\"24392163\",\"name\":\"J. Zhang\"},{\"authorId\":\"47668707\",\"name\":\"Li-li Ju\"},{\"authorId\":\"40696794\",\"name\":\"Song Wang\"}],\"doi\":\"10.1609/AAAI.V34I07.6927\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3d51ce14a3be17ffc37bb94f9664429d0dad4564\",\"title\":\"SalSAC: A Video Saliency Prediction Model with Shuffled Attentions and Correlation-Based ConvLSTM\",\"url\":\"https://www.semanticscholar.org/paper/3d51ce14a3be17ffc37bb94f9664429d0dad4564\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3327256\",\"name\":\"M. Favorskaya\"},{\"authorId\":\"122575918\",\"name\":\"L. C. Jain\"}],\"doi\":\"10.31799/1684-8853-2019-3-10-36\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6fe7379f40fd2354e5bbe5f8be79069feb0c6ea2\",\"title\":\"Saliency detection in deep learning era: trends of development\",\"url\":\"https://www.semanticscholar.org/paper/6fe7379f40fd2354e5bbe5f8be79069feb0c6ea2\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1709809\",\"name\":\"C. Chrysouli\"},{\"authorId\":\"1738865\",\"name\":\"N. Vretos\"},{\"authorId\":\"1747572\",\"name\":\"P. Daras\"}],\"doi\":\"10.1109/MLSP.2018.8517010\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b38590f323fa08f8585e35e2b7343d517f686a12\",\"title\":\"AFFECTIVE STATE RECOGNITION BASED ON EYE GAZE ANALYSIS USING TWO\\u2013STREAM CONVOLUTIONAL NETWORKS\",\"url\":\"https://www.semanticscholar.org/paper/b38590f323fa08f8585e35e2b7343d517f686a12\",\"venue\":\"2018 IEEE 28th International Workshop on Machine Learning for Signal Processing (MLSP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3200442\",\"name\":\"A. Tsiami\"},{\"authorId\":\"2539459\",\"name\":\"Petros Koutras\"},{\"authorId\":\"2243473\",\"name\":\"Athanasios Katsamanis\"},{\"authorId\":\"46788705\",\"name\":\"A. Vatakis\"},{\"authorId\":\"1750686\",\"name\":\"P. Maragos\"}],\"doi\":\"10.1016/J.IMAGE.2019.05.001\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5cfa95cd409a47fbacce89c6a1df6d0410b810e5\",\"title\":\"A behaviorally inspired fusion approach for computational audiovisual saliency modeling\",\"url\":\"https://www.semanticscholar.org/paper/5cfa95cd409a47fbacce89c6a1df6d0410b810e5\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d173893dd3f22fd73acc16b94f0ea98469c9855\",\"title\":\"Saliency Prediction in the Deep Learning Era: Successes, Limitations, and Future Challenges\",\"url\":\"https://www.semanticscholar.org/paper/3d173893dd3f22fd73acc16b94f0ea98469c9855\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5021307\",\"name\":\"Vincent Sitzmann\"},{\"authorId\":\"143772343\",\"name\":\"Ana Serrano\"},{\"authorId\":\"48453720\",\"name\":\"A. Pavel\"},{\"authorId\":\"1820412\",\"name\":\"M. Agrawala\"},{\"authorId\":\"143876232\",\"name\":\"D. Gutierrez\"},{\"authorId\":\"1731170\",\"name\":\"G. Wetzstein\"}],\"doi\":\"10.1109/TVCG.2018.2793599\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c3d382d1aad38e7e1a9249a7bd323f9a5cf92ca8\",\"title\":\"Saliency in VR: How Do People Explore Virtual Environments?\",\"url\":\"https://www.semanticscholar.org/paper/c3d382d1aad38e7e1a9249a7bd323f9a5cf92ca8\",\"venue\":\"IEEE Transactions on Visualization and Computer Graphics\",\"year\":2018},{\"arxivId\":\"1907.02364\",\"authors\":[{\"authorId\":\"35180251\",\"name\":\"Dongze Lian\"},{\"authorId\":\"22265339\",\"name\":\"Zehao Yu\"},{\"authorId\":\"1702868\",\"name\":\"Shenghua Gao\"}],\"doi\":\"10.1007/978-3-030-20893-6_3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"28e73003f58d2a28a73591243060517b753dbe17\",\"title\":\"Believe It or Not, We Know What You Are Looking At!\",\"url\":\"https://www.semanticscholar.org/paper/28e73003f58d2a28a73591243060517b753dbe17\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71992420\",\"name\":\"Demet Yesiltepe\"},{\"authorId\":\"71215015\",\"name\":\"Ayse Ozbil Torun\"},{\"authorId\":\"2624078\",\"name\":\"A. Coutrot\"},{\"authorId\":\"97599447\",\"name\":\"M. Hornberger\"},{\"authorId\":\"145689135\",\"name\":\"H. Spiers\"},{\"authorId\":\"34872106\",\"name\":\"R. Dalton\"}],\"doi\":\"10.1080/13875868.2020.1830993\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c2d11165ed31f4dbf688461b47bd4ea1244e0ab2\",\"title\":\"Computer models of saliency alone fail to predict subjective visual attention to landmarks during observed navigation\",\"url\":\"https://www.semanticscholar.org/paper/c2d11165ed31f4dbf688461b47bd4ea1244e0ab2\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1612.04335\",\"authors\":[{\"authorId\":\"5021307\",\"name\":\"Vincent Sitzmann\"},{\"authorId\":\"145192940\",\"name\":\"Ana Serrano\"},{\"authorId\":\"48453720\",\"name\":\"A. Pavel\"},{\"authorId\":\"1820412\",\"name\":\"M. Agrawala\"},{\"authorId\":\"143876232\",\"name\":\"D. Gutierrez\"},{\"authorId\":\"1775667\",\"name\":\"B. Masi\\u00e1\"},{\"authorId\":\"1731170\",\"name\":\"G. Wetzstein\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c6b4459c4f27b9c4107ae7f708059e987e7f3f08\",\"title\":\"How do people explore virtual environments\",\"url\":\"https://www.semanticscholar.org/paper/c6b4459c4f27b9c4107ae7f708059e987e7f3f08\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152686790\",\"name\":\"O. Krishna\"},{\"authorId\":\"152686790\",\"name\":\"O. Krishna\"},{\"authorId\":\"46363837\",\"name\":\"K. Aizawa\"},{\"authorId\":\"144990548\",\"name\":\"Go Irie\"}],\"doi\":\"10.1007/s11042-020-09474-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ff2af7d5edb6a5a57a09396374dbfd2c90c784c9\",\"title\":\"Computational attention model for children, adults and the elderly\",\"url\":\"https://www.semanticscholar.org/paper/ff2af7d5edb6a5a57a09396374dbfd2c90c784c9\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1810.03716\",\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4df34e0194faa27078832cb5078a2af6c9d0ea9b\",\"title\":\"Saliency Prediction in the Deep Learning Era: An Empirical Investigation\",\"url\":\"https://www.semanticscholar.org/paper/4df34e0194faa27078832cb5078a2af6c9d0ea9b\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145074627\",\"name\":\"Gina M. Notaro\"},{\"authorId\":\"31586582\",\"name\":\"S. Diamond\"}],\"doi\":\"10.1145/3290511.3290526\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"be71e31eaa91d74bbd88d419613a69f8b10c3e3c\",\"title\":\"Development and demonstration of an integrated EEG, eye-tracking, and behavioral data acquisition system to assess online learning\",\"url\":\"https://www.semanticscholar.org/paper/be71e31eaa91d74bbd88d419613a69f8b10c3e3c\",\"venue\":\"ICETC '18\",\"year\":2018},{\"arxivId\":\"1811.08594\",\"authors\":[{\"authorId\":\"144864671\",\"name\":\"T. T. Nguyen\"},{\"authorId\":\"144129240\",\"name\":\"D. Nguyen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c342a0103d6e0df908f50e3bb21dd5a666f3cd1c\",\"title\":\"Learning to Attend Relevant Regions in Videos from Eye Fixations\",\"url\":\"https://www.semanticscholar.org/paper/c342a0103d6e0df908f50e3bb21dd5a666f3cd1c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1811.07480\",\"authors\":[{\"authorId\":\"50251712\",\"name\":\"Ziqi Zhou\"},{\"authorId\":\"40514580\",\"name\":\"Z. Wang\"},{\"authorId\":\"1790976\",\"name\":\"H. Lu\"},{\"authorId\":\"47673404\",\"name\":\"S. Wang\"},{\"authorId\":\"2736861\",\"name\":\"M. Sun\"}],\"doi\":\"10.1016/j.patcog.2020.107275\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b7de478275fdc5e154f6d904b910e8d291033edd\",\"title\":\"Global and Local Sensitivity Guided Key Salient Object Re-augmentation for Video Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/b7de478275fdc5e154f6d904b910e8d291033edd\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49890030\",\"name\":\"Youqiang Zhang\"},{\"authorId\":\"143743503\",\"name\":\"Feng Dai\"},{\"authorId\":\"3193532\",\"name\":\"Yike Ma\"},{\"authorId\":\"49404814\",\"name\":\"Hongliang Li\"},{\"authorId\":\"49033408\",\"name\":\"Q. Zhao\"},{\"authorId\":\"121310224\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.1109/JSTSP.2019.2955824\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"059dcad31aca80e2393fb2ccdea0dffc4499e1be\",\"title\":\"Saliency Prediction Network for $360^\\\\circ$ Videos\",\"url\":\"https://www.semanticscholar.org/paper/059dcad31aca80e2393fb2ccdea0dffc4499e1be\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738865\",\"name\":\"N. Vretos\"},{\"authorId\":\"1747572\",\"name\":\"P. Daras\"},{\"authorId\":\"1753719\",\"name\":\"S. Asteriadis\"},{\"authorId\":\"3334492\",\"name\":\"E. Hortal\"},{\"authorId\":\"2398366\",\"name\":\"E. Ghaleb\"},{\"authorId\":\"144116678\",\"name\":\"E. Spyrou\"},{\"authorId\":\"32115102\",\"name\":\"H. C. Leligou\"},{\"authorId\":\"2735131\",\"name\":\"P. Karkazis\"},{\"authorId\":\"1891352\",\"name\":\"P. Trakadas\"},{\"authorId\":\"8061483\",\"name\":\"K. Assimakopoulos\"}],\"doi\":\"10.1007/s10055-018-0357-0\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"20a0f71d2c667f3c69df18f097f2b5678ac7d214\",\"title\":\"Exploiting sensing devices availability in AR/VR deployments to foster engagement\",\"url\":\"https://www.semanticscholar.org/paper/20a0f71d2c667f3c69df18f097f2b5678ac7d214\",\"venue\":\"Virtual Reality\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"39380386\",\"name\":\"Jianwen Xie\"},{\"authorId\":\"37535930\",\"name\":\"Ming-Ming Cheng\"},{\"authorId\":\"1805398\",\"name\":\"Haibin Ling\"},{\"authorId\":\"51004202\",\"name\":\"A. Borji\"}],\"doi\":\"10.1109/TPAMI.2019.2924417\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"60782ad3f40d13fae19fbe26b6f7c0ac5011f83d\",\"title\":\"Revisiting Video Saliency Prediction in the Deep Learning Era\",\"url\":\"https://www.semanticscholar.org/paper/60782ad3f40d13fae19fbe26b6f7c0ac5011f83d\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2021}],\"corpusId\":7104471,\"doi\":\"10.1109/ICCV.2017.188\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"ca1ff286ad8eba2aa6bc442f0f8321572fd0b090\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"33687539\",\"name\":\"Ran Ju\"},{\"authorId\":\"49152964\",\"name\":\"L. Ge\"},{\"authorId\":\"2428394\",\"name\":\"W. Geng\"},{\"authorId\":\"1744930\",\"name\":\"T. Ren\"},{\"authorId\":\"39914710\",\"name\":\"Gangshan Wu\"}],\"doi\":\"10.1109/ICIP.2014.7025222\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1a64a37af7205a7f6b208c740bd702027eadecff\",\"title\":\"Depth saliency based on anisotropic center-surround difference\",\"url\":\"https://www.semanticscholar.org/paper/1a64a37af7205a7f6b208c740bd702027eadecff\",\"venue\":\"2014 IEEE International Conference on Image Processing (ICIP)\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37710702\",\"name\":\"Stefan Mathe\"},{\"authorId\":\"1781120\",\"name\":\"C. Sminchisescu\"}],\"doi\":\"10.1007/978-3-642-33709-3_60\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bef862006a045d846d716346b0d27d3ca6cbf21b\",\"title\":\"Dynamic Eye Movement Datasets and Learnt Saliency Models for Visual Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/bef862006a045d846d716346b0d27d3ca6cbf21b\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Borji\"},{\"authorId\":null,\"name\":\"L.\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Itti . Exploiting local and global patch raities for saliency detection\",\"url\":\"\",\"venue\":\"CVPR , pages\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"D. Rudoy\"},{\"authorId\":null,\"name\":\"D. Goldman\"},{\"authorId\":null,\"name\":\"E. Shechtman\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"and L\",\"url\":\"\",\"venue\":\"Zelnik-Manor . Learning video saliency from human gaze using candidate selection. InCVPR, pages 1147\\u20131154\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1701293\",\"name\":\"J. Zhang\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"}],\"doi\":\"10.1109/ICCV.2013.26\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"75ee5cd7712b6ad13d64c3b4de24aa592a869fc1\",\"title\":\"Saliency Detection: A Boolean Map Approach\",\"url\":\"https://www.semanticscholar.org/paper/75ee5cd7712b6ad13d64c3b4de24aa592a869fc1\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1109/TIP.2004.834657\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bbb456acfec69d279b3f653b53dc1182d1b44eb6\",\"title\":\"Automatic foveation for video compression using a neurobiological model of visual attention\",\"url\":\"https://www.semanticscholar.org/paper/bbb456acfec69d279b3f653b53dc1182d1b44eb6\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2306103\",\"name\":\"Parag K. Mital\"},{\"authorId\":\"145165599\",\"name\":\"T. Smith\"},{\"authorId\":\"3252072\",\"name\":\"R. L. Hill\"},{\"authorId\":\"1889476\",\"name\":\"J. Henderson\"}],\"doi\":\"10.1007/s12559-010-9074-z\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"27266e3be4d9b9572e8e11f4ef34110a2a00f515\",\"title\":\"Clustering of Gaze During Dynamic Scene Viewing is Predicted by Motion\",\"url\":\"https://www.semanticscholar.org/paper/27266e3be4d9b9572e8e11f4ef34110a2a00f515\",\"venue\":\"Cognitive Computation\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5886094\",\"name\":\"P. Cochat\"},{\"authorId\":\"13267685\",\"name\":\"L. Vaucoret\"},{\"authorId\":\"31455512\",\"name\":\"J. Sarles\"}],\"doi\":\"10.1016/j.arcped.2012.01.013\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10d85561e4aafc516d10064f30dff05b41f70afe\",\"title\":\"[Et al].\",\"url\":\"https://www.semanticscholar.org/paper/10d85561e4aafc516d10064f30dff05b41f70afe\",\"venue\":\"Archives de pediatrie : organe officiel de la Societe francaise de pediatrie\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48493294\",\"name\":\"V. Mahadevan\"},{\"authorId\":\"1699559\",\"name\":\"N. Vasconcelos\"}],\"doi\":\"10.1109/TPAMI.2009.112\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"62eb421cdac9de9255578f14fba55146d958be44\",\"title\":\"Spatiotemporal Saliency in Dynamic Scenes\",\"url\":\"https://www.semanticscholar.org/paper/62eb421cdac9de9255578f14fba55146d958be44\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40599257\",\"name\":\"J. Xiao\"},{\"authorId\":\"144956994\",\"name\":\"Andrew Owens\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/ICCV.2013.458\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"723e52c0d0140df7a6e264f1042af89ce9277e6e\",\"title\":\"SUN3D: A Database of Big Spaces Reconstructed Using SfM and Object Labels\",\"url\":\"https://www.semanticscholar.org/paper/723e52c0d0140df7a6e264f1042af89ce9277e6e\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50813206\",\"name\":\"F. Zhou\"},{\"authorId\":\"1738740\",\"name\":\"S. B. Kang\"},{\"authorId\":\"1694613\",\"name\":\"M. Cohen\"}],\"doi\":\"10.1109/CVPR.2014.429\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5fe57bffe456e8a042c9c2292d9cd5ad24ab0e3a\",\"title\":\"Time-Mapping Using Space-Time Saliency\",\"url\":\"https://www.semanticscholar.org/paper/5fe57bffe456e8a042c9c2292d9cd5ad24ab0e3a\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1787538\",\"name\":\"Hansang Kim\"},{\"authorId\":\"34324678\",\"name\":\"Y. Kim\"},{\"authorId\":\"37874485\",\"name\":\"J. Sim\"},{\"authorId\":\"145767112\",\"name\":\"C. Kim\"}],\"doi\":\"10.1109/TIP.2015.2425544\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fb32962c8272eb8273fd8b2c8e08cb0eaf164fcb\",\"title\":\"Spatiotemporal Saliency Detection for Video Sequences Based on Random Walk With Restart\",\"url\":\"https://www.semanticscholar.org/paper/fb32962c8272eb8273fd8b2c8e08cb0eaf164fcb\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J. Sturm\"},{\"authorId\":null,\"name\":\"N. Engelhard\"},{\"authorId\":null,\"name\":\"F. Endres\"},{\"authorId\":null,\"name\":\"W. Burgard\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and D\",\"url\":\"\",\"venue\":\"Cre mers. A benchmark for the evaluation of RGB-D slam systems. InIROS, pages 573\\u2013580\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1109/CVPR.2012.6247711\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5e3d92c27e2fbb407243a6279dfafe9260a3732d\",\"title\":\"Exploiting local and global patch rarities for saliency detection\",\"url\":\"https://www.semanticscholar.org/paper/5e3d92c27e2fbb407243a6279dfafe9260a3732d\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3084719\",\"name\":\"Xiaodi Hou\"},{\"authorId\":\"5381034\",\"name\":\"L. Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4e7ec75337766f2b649bb9f99c6887ee0f1674a6\",\"title\":\"Dynamic visual attention: searching for coding length increments\",\"url\":\"https://www.semanticscholar.org/paper/4e7ec75337766f2b649bb9f99c6887ee0f1674a6\",\"venue\":\"NIPS\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3151890\",\"name\":\"N. Ouerhani\"},{\"authorId\":\"152447339\",\"name\":\"Heinz Hugli\"}],\"doi\":\"10.1109/ICPR.2000.905356\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"684366a39de80dc43c44c15925bbe37761a0a901\",\"title\":\"Computing visual attention from scene depth\",\"url\":\"https://www.semanticscholar.org/paper/684366a39de80dc43c44c15925bbe37761a0a901\",\"venue\":\"Proceedings 15th International Conference on Pattern Recognition. ICPR-2000\",\"year\":2000},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2760273\",\"name\":\"Karthik Desingh\"},{\"authorId\":\"145211574\",\"name\":\"K. Krishna\"},{\"authorId\":\"145383458\",\"name\":\"D. Rajan\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"}],\"doi\":\"10.5244/C.27.98\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"89163f33e3bb961bef1ceccd50135d937d1730f9\",\"title\":\"Depth really Matters: Improving Visual Salient Region Detection with Depth\",\"url\":\"https://www.semanticscholar.org/paper/89163f33e3bb961bef1ceccd50135d937d1730f9\",\"venue\":\"BMVC\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49293102\",\"name\":\"Z. Liu\"},{\"authorId\":\"47786533\",\"name\":\"Junhao Li\"},{\"authorId\":\"2373631\",\"name\":\"L. Ye\"},{\"authorId\":\"2272337\",\"name\":\"Guangling Sun\"},{\"authorId\":\"1683512\",\"name\":\"Liquan Shen\"}],\"doi\":\"10.1109/TCSVT.2016.2595324\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"25e37cb318d2b72b5adf3d08f87404dd86e88431\",\"title\":\"Saliency Detection for Unconstrained Videos Using Superpixel-Level Graph and Spatiotemporal Propagation\",\"url\":\"https://www.semanticscholar.org/paper/25e37cb318d2b72b5adf3d08f87404dd86e88431\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2753356\",\"name\":\"J. Wang\"},{\"authorId\":\"1776651\",\"name\":\"P. Callet\"},{\"authorId\":\"3059667\",\"name\":\"S. Tourancheau\"},{\"authorId\":\"1764950\",\"name\":\"V. Ricordel\"},{\"authorId\":\"21340060\",\"name\":\"Matthieu Perreira Da Silva\"}],\"doi\":\"10.16910/JEMR.5.5.1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b3f02f3d691eb8c995b938e4f411ac1d7e20bd51\",\"title\":\"Study of depth bias of observers in free viewing of still stereoscopic synthetic stimuli\",\"url\":\"https://www.semanticscholar.org/paper/b3f02f3d691eb8c995b938e4f411ac1d7e20bd51\",\"venue\":\"\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J. Masci\"},{\"authorId\":null,\"name\":\"U. Meier\"},{\"authorId\":null,\"name\":\"D. Cire\\u015fan\"},{\"authorId\":null,\"name\":\"J. Schmidhuber\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Sta cked convolutional auto-encoders for hierarchical feature ext raction\",\"url\":\"\",\"venue\":\"ICANN, pages 52\\u201359\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144007359\",\"name\":\"W. Kienzle\"},{\"authorId\":\"1707625\",\"name\":\"B. Sch\\u00f6lkopf\"},{\"authorId\":\"1924112\",\"name\":\"Felix Wichmann\"},{\"authorId\":\"30541601\",\"name\":\"M. Franz\"}],\"doi\":\"10.1007/978-3-540-74936-3_41\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0ba14e60ce379703c81fba1afd6210a73426a320\",\"title\":\"How to Find Interesting Locations in Video: A Spatiotemporal Interest Point Detector Learned from Human Eye Movements\",\"url\":\"https://www.semanticscholar.org/paper/0ba14e60ce379703c81fba1afd6210a73426a320\",\"venue\":\"DAGM-Symposium\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2286640\",\"name\":\"N. Silberman\"},{\"authorId\":\"2433269\",\"name\":\"Derek Hoiem\"},{\"authorId\":\"143967473\",\"name\":\"P. Kohli\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":\"10.1007/978-3-642-33715-4_54\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c1994ba5946456fc70948c549daf62363f13fa2d\",\"title\":\"Indoor Segmentation and Support Inference from RGBD Images\",\"url\":\"https://www.semanticscholar.org/paper/c1994ba5946456fc70948c549daf62363f13fa2d\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3244141\",\"name\":\"A. Ciptadi\"},{\"authorId\":\"145767346\",\"name\":\"Tucker Hermans\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.5244/C.27.112\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"28c0de3d69326859f99003b650bf808a4f17760a\",\"title\":\"An In Depth View of Saliency\",\"url\":\"https://www.semanticscholar.org/paper/28c0de3d69326859f99003b650bf808a4f17760a\",\"venue\":\"BMVC\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2484788\",\"name\":\"Houwen Peng\"},{\"authorId\":\"49730034\",\"name\":\"B. Li\"},{\"authorId\":\"2214855\",\"name\":\"Weihua Xiong\"},{\"authorId\":\"40506509\",\"name\":\"W. Hu\"},{\"authorId\":\"145592290\",\"name\":\"R. Ji\"}],\"doi\":\"10.1007/978-3-319-10578-9_7\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fd455bef8dea04acc37f1a4b4be47068bbf58303\",\"title\":\"RGBD Salient Object Detection: A Benchmark and Algorithms\",\"url\":\"https://www.semanticscholar.org/paper/fd455bef8dea04acc37f1a4b4be47068bbf58303\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1789744\",\"name\":\"O. Meur\"},{\"authorId\":\"1776651\",\"name\":\"P. Callet\"},{\"authorId\":\"144812989\",\"name\":\"D. Barba\"}],\"doi\":\"10.1016/j.visres.2007.06.015\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"122134f9242785383949caaaea4601861beebad8\",\"title\":\"Predicting visual fixations on video based on low-level visual features\",\"url\":\"https://www.semanticscholar.org/paper/122134f9242785383949caaaea4601861beebad8\",\"venue\":\"Vision Research\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2426718\",\"name\":\"J. Masci\"},{\"authorId\":\"2514691\",\"name\":\"U. Meier\"},{\"authorId\":\"1895356\",\"name\":\"Dan C. Ciresan\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1007/978-3-642-21735-7_7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1c6d990c80e60aa0b0059415444cdf94b3574f0f\",\"title\":\"Stacked Convolutional Auto-Encoders for Hierarchical Feature Extraction\",\"url\":\"https://www.semanticscholar.org/paper/1c6d990c80e60aa0b0059415444cdf94b3574f0f\",\"venue\":\"ICANN\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1941997\",\"name\":\"Chenlei Guo\"},{\"authorId\":\"144818403\",\"name\":\"Qi Ma\"},{\"authorId\":\"29906646\",\"name\":\"L. Zhang\"}],\"doi\":\"10.1109/CVPR.2008.4587715\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"16f4cfd4cbf504a151827b5a94df5deafd4930ac\",\"title\":\"Spatio-temporal Saliency detection using phase spectrum of quaternion fourier transform\",\"url\":\"https://www.semanticscholar.org/paper/16f4cfd4cbf504a151827b5a94df5deafd4930ac\",\"venue\":\"2008 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Y. Liu\"},{\"authorId\":null,\"name\":\"L. K. Cormack\"},{\"authorId\":null,\"name\":\"A. C. Bovik\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Natural scene stat  is-  tics at stereo fixations\",\"url\":\"\",\"venue\":\"InSymposium on Eye-Tracking Research&Applications  , pages 161\\u2013164. ACM\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2286630\",\"name\":\"E. Vig\"},{\"authorId\":\"1944405\",\"name\":\"M. Dorr\"},{\"authorId\":\"2042941\",\"name\":\"D. Cox\"}],\"doi\":\"10.1109/CVPR.2014.358\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8693c32dff29e851760fa0b6af464050ffc383d6\",\"title\":\"Large-Scale Optimization of Hierarchical Features for Saliency Prediction in Natural Images\",\"url\":\"https://www.semanticscholar.org/paper/8693c32dff29e851760fa0b6af464050ffc383d6\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143775672\",\"name\":\"Tilke Judd\"},{\"authorId\":\"1865091\",\"name\":\"Krista A. Ehinger\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/ICCV.2009.5459462\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c7614898de1cfee1a3a1c564f52c1e67879c29b3\",\"title\":\"Learning to predict where humans look\",\"url\":\"https://www.semanticscholar.org/paper/c7614898de1cfee1a3a1c564f52c1e67879c29b3\",\"venue\":\"2009 IEEE 12th International Conference on Computer Vision\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145131953\",\"name\":\"L. Wang\"},{\"authorId\":\"1790976\",\"name\":\"H. Lu\"},{\"authorId\":\"144526777\",\"name\":\"X. Ruan\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/CVPR.2015.7298938\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"338e14e0c5e368efc79361adc5ba4957d1c17ef1\",\"title\":\"Deep networks for saliency detection via local estimation and global search\",\"url\":\"https://www.semanticscholar.org/paper/338e14e0c5e368efc79361adc5ba4957d1c17ef1\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3350185\",\"name\":\"C. Lang\"},{\"authorId\":\"34646933\",\"name\":\"T. V. Nguyen\"},{\"authorId\":\"2478739\",\"name\":\"H. Katti\"},{\"authorId\":\"2447444\",\"name\":\"Karthik Yadati\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"}],\"doi\":\"10.1007/978-3-642-33709-3_8\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6166927f1fc3eea4b20a280ed898359e87eb332d\",\"title\":\"Depth Matters: Influence of Depth Cues on Visual Saliency\",\"url\":\"https://www.semanticscholar.org/paper/6166927f1fc3eea4b20a280ed898359e87eb332d\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7326223\",\"name\":\"L. Itti\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"},{\"authorId\":\"3271571\",\"name\":\"E. Niebur\"}],\"doi\":\"10.1109/34.730558\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4816f0b6f0d05da3901441bfa5cc7be044b4da8b\",\"title\":\"A Model of Saliency-Based Visual Attention for Rapid Scene Analysis\",\"url\":\"https://www.semanticscholar.org/paper/4816f0b6f0d05da3901441bfa5cc7be044b4da8b\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1630277553\",\"name\":\"M. Sankar\"}],\"doi\":\"10.1515/9783111548050-024\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"517a45c35f9ad52ac75a27c5a5f190d41cbc5e65\",\"title\":\"M\",\"url\":\"https://www.semanticscholar.org/paper/517a45c35f9ad52ac75a27c5a5f190d41cbc5e65\",\"venue\":\"Edinburgh Medical and Surgical Journal\",\"year\":1824},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Borji\"},{\"authorId\":null,\"name\":\"D. N. Sihite\"},{\"authorId\":null,\"name\":\"L. Itti\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Salient object detect ion: A benchmark\",\"url\":\"\",\"venue\":\"InECCV, pages 414\\u2013429\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"},{\"authorId\":\"1776374\",\"name\":\"Juho Kannala\"},{\"authorId\":\"50664676\",\"name\":\"Mikko Salo\"},{\"authorId\":\"3111194\",\"name\":\"J. Heikkil\\u00e4\"}],\"doi\":\"10.1007/978-3-642-15555-0_27\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c413d55baf1ee96df29256a879e96daf4c2cc072\",\"title\":\"Segmenting Salient Objects from Images and Videos\",\"url\":\"https://www.semanticscholar.org/paper/c413d55baf1ee96df29256a879e96daf4c2cc072\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2812440\",\"name\":\"S. Zhong\"},{\"authorId\":\"47909587\",\"name\":\"Y. Liu\"},{\"authorId\":\"36027198\",\"name\":\"Feifei Ren\"},{\"authorId\":\"47539861\",\"name\":\"J. Zhang\"},{\"authorId\":\"1744930\",\"name\":\"T. Ren\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"25c65c87968b94631d3dcca253478d9f50806be3\",\"title\":\"Video Saliency Detection via Dynamic Consistent Spatio-Temporal Attention Modelling\",\"url\":\"https://www.semanticscholar.org/paper/25c65c87968b94631d3dcca253478d9f50806be3\",\"venue\":\"AAAI\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2637872\",\"name\":\"Y. Niu\"},{\"authorId\":\"2209062\",\"name\":\"Yujie Geng\"},{\"authorId\":\"1739207\",\"name\":\"X. Li\"},{\"authorId\":\"40513795\",\"name\":\"Feng Liu\"}],\"doi\":\"10.1109/CVPR.2012.6247708\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b718058b2a758a69147bc32ae54571057ec6694f\",\"title\":\"Leveraging stereopsis for saliency analysis\",\"url\":\"https://www.semanticscholar.org/paper/b718058b2a758a69147bc32ae54571057ec6694f\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"K. Desingh\"},{\"authorId\":null,\"name\":\"M. Krishna\"},{\"authorId\":null,\"name\":\"D. Rajan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and C\",\"url\":\"\",\"venue\":\"Jawahar. Depth really matters: Improving visual salient region detection with depth.BMVC, pages 1\\u201311\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34526725\",\"name\":\"Wonjun Kim\"},{\"authorId\":\"2024203\",\"name\":\"Chanho Jung\"},{\"authorId\":\"145568138\",\"name\":\"Changick Kim\"}],\"doi\":\"10.1109/TCSVT.2011.2125450\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b96e94d318b583066df5fa946d5c2010d1704892\",\"title\":\"Spatiotemporal Saliency Detection and Its Applications in Static and Dynamic Scenes\",\"url\":\"https://www.semanticscholar.org/paper/b96e94d318b583066df5fa946d5c2010d1704892\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1401681792\",\"name\":\"Q. Huynh-Thu\"},{\"authorId\":\"1758627\",\"name\":\"M. Barkowsky\"},{\"authorId\":\"1776651\",\"name\":\"P. Callet\"}],\"doi\":\"10.1109/TBC.2011.2128250\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"559ce3e8a470b4b0a787a0ce388bd781e8511a09\",\"title\":\"The Importance of Visual Attention in Improving the 3D-TV Viewing Experience: Overview and New Perspectives\",\"url\":\"https://www.semanticscholar.org/paper/559ce3e8a470b4b0a787a0ce388bd781e8511a09\",\"venue\":\"IEEE Transactions on Broadcasting\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3326805\",\"name\":\"Hae Jong Seo\"},{\"authorId\":\"1718280\",\"name\":\"P. Milanfar\"}],\"doi\":\"10.1167/9.12.15\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"143973e23364190bc687fe694eb863417e8ba0ba\",\"title\":\"Static and space-time visual saliency detection by self-resemblance.\",\"url\":\"https://www.semanticscholar.org/paper/143973e23364190bc687fe694eb863417e8ba0ba\",\"venue\":\"Journal of vision\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"V. Mahadevan\"},{\"authorId\":null,\"name\":\"N. Vasconcelos\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Spatiotemporal salie ncy in dynamic scenes\",\"url\":\"\",\"venue\":\"TPAMI, 32(1):171\\u2013177\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2341854\",\"name\":\"M. Baccouche\"},{\"authorId\":\"2408697\",\"name\":\"F. Mamalet\"},{\"authorId\":\"144899680\",\"name\":\"C. Wolf\"},{\"authorId\":\"144723337\",\"name\":\"C. Garcia\"},{\"authorId\":\"1739898\",\"name\":\"A. Baskurt\"}],\"doi\":\"10.5244/C.26.124\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"93e6069f2bd4f6bceb591d35968613f03b1cffc9\",\"title\":\"Spatio-Temporal Convolutional Sparse Auto-Encoder for Sequence Classification\",\"url\":\"https://www.semanticscholar.org/paper/93e6069f2bd4f6bceb591d35968613f03b1cffc9\",\"venue\":\"BMVC\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1779676\",\"name\":\"J. Sturm\"},{\"authorId\":\"2337344\",\"name\":\"N. Engelhard\"},{\"authorId\":\"2015943\",\"name\":\"F. Endres\"},{\"authorId\":\"1725973\",\"name\":\"W. Burgard\"},{\"authorId\":\"1695302\",\"name\":\"D. Cremers\"}],\"doi\":\"10.1109/IROS.2012.6385773\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5eb4c55740165defacf08329beaae5314d7fbfe6\",\"title\":\"A benchmark for the evaluation of RGB-D SLAM systems\",\"url\":\"https://www.semanticscholar.org/paper/5eb4c55740165defacf08329beaae5314d7fbfe6\",\"venue\":\"2012 IEEE/RSJ International Conference on Intelligent Robots and Systems\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J. Harel\"},{\"authorId\":null,\"name\":\"C. Koch\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"and P\",\"url\":\"\",\"venue\":\"Perona. Graph-based visual saliency.Advances in neural inf. proc. systems , 19:545\\u2013552\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144566149\",\"name\":\"M. Hirsch\"},{\"authorId\":\"1731170\",\"name\":\"G. Wetzstein\"},{\"authorId\":\"145711633\",\"name\":\"R. Raskar\"}],\"doi\":\"10.1145/2614066.2614075\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6240a691531e4c0a152740d4f59beef8fe5cca1c\",\"title\":\"A compressive light field projection system\",\"url\":\"https://www.semanticscholar.org/paper/6240a691531e4c0a152740d4f59beef8fe5cca1c\",\"venue\":\"SIGGRAPH '14\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49421390\",\"name\":\"Y. Liu\"},{\"authorId\":\"1727781\",\"name\":\"L. Cormack\"},{\"authorId\":\"1747569\",\"name\":\"A. Bovik\"}],\"doi\":\"10.1145/1743666.1743706\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d960e44b81d01e7d0d4df54d8ee6d00ad1638151\",\"title\":\"Natural scene statistics at stereo fixations\",\"url\":\"https://www.semanticscholar.org/paper/d960e44b81d01e7d0d4df54d8ee6d00ad1638151\",\"venue\":\"ETRA '10\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"2037692\",\"name\":\"Dicky N. Sihite\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1007/978-3-642-33709-3_30\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0ffb5ec8dc5de8bb51b9181b6db744159d6010b4\",\"title\":\"Salient Object Detection: A Benchmark\",\"url\":\"https://www.semanticscholar.org/paper/0ffb5ec8dc5de8bb51b9181b6db744159d6010b4\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J Harel\"},{\"authorId\":null,\"name\":\"C Koch\"},{\"authorId\":null,\"name\":\"P Perona\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Graph-based visual saliency Advances in neural inf. proc. systems\",\"url\":\"\",\"venue\":\"Graph-based visual saliency Advances in neural inf. proc. systems\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46310002\",\"name\":\"Lina Jansen\"},{\"authorId\":\"2469837\",\"name\":\"Selim Onat\"},{\"authorId\":\"40089171\",\"name\":\"P. K\\u00f6nig\"}],\"doi\":\"10.1167/9.1.29\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"709087f8965194b312d4cd73becbba824514303c\",\"title\":\"Influence of disparity on fixation and saccades in free viewing of natural scenes.\",\"url\":\"https://www.semanticscholar.org/paper/709087f8965194b312d4cd73becbba824514303c\",\"venue\":\"Journal of vision\",\"year\":2009},{\"arxivId\":\"1604.05495\",\"authors\":[{\"authorId\":\"47022712\",\"name\":\"Gayoung Lee\"},{\"authorId\":\"5068280\",\"name\":\"Yu-Wing Tai\"},{\"authorId\":\"1769295\",\"name\":\"Junmo Kim\"}],\"doi\":\"10.1109/CVPR.2016.78\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b1ec1f1515eb29b9f2b26280b8daffe0d8804215\",\"title\":\"Deep Saliency with Encoded Low Level Distance Map and High Level Features\",\"url\":\"https://www.semanticscholar.org/paper/b1ec1f1515eb29b9f2b26280b8daffe0d8804215\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"C. Richardt\"},{\"authorId\":null,\"name\":\"C. Stoll\"},{\"authorId\":null,\"name\":\"N. Dodgson\"},{\"authorId\":null,\"name\":\"H. Seidel\"},{\"authorId\":null,\"name\":\"C. Theobalt\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Coherent spatiotemporal filtering\",\"url\":\"\",\"venue\":\"upsamplin g and rendering of RGBZ videos. Computer Graphics Forum , 31(2)\",\"year\":2012},{\"arxivId\":\"1411.5928\",\"authors\":[{\"authorId\":\"2841331\",\"name\":\"A. Dosovitskiy\"},{\"authorId\":\"2060551\",\"name\":\"Jost Tobias Springenberg\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1109/CVPR.2015.7298761\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b437b5a0445f17b06b12791bc48aeb8110e95dc5\",\"title\":\"Learning to generate chairs with convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/b437b5a0445f17b06b12791bc48aeb8110e95dc5\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145258674\",\"name\":\"K. Lai\"},{\"authorId\":\"144651486\",\"name\":\"L. Bo\"},{\"authorId\":\"145197953\",\"name\":\"D. Fox\"}],\"doi\":\"10.1109/ICRA.2014.6907298\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"db44da40c6db1edfbaa95fb7c46b542e04743b5d\",\"title\":\"Unsupervised feature learning for 3D scene labeling\",\"url\":\"https://www.semanticscholar.org/paper/db44da40c6db1edfbaa95fb7c46b542e04743b5d\",\"venue\":\"2014 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Y. Liu\"},{\"authorId\":null,\"name\":\"L. K. Cormack\"},{\"authorId\":null,\"name\":\"A. C. Bovik\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Natural scene stat istics at stereo fixations\",\"url\":\"\",\"venue\":\"InSymposium on Eye-Tracking Research&Applications , pages 161\\u2013164. ACM\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J. H\\u00e4kkinen\"},{\"authorId\":null,\"name\":\"T. Kawai\"},{\"authorId\":null,\"name\":\"J. Takatalo\"},{\"authorId\":null,\"name\":\"R. Mitsuya\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and G\",\"url\":\"\",\"venue\":\"Ny man. What do people look at when they watch stereoscopic movies? InIS&T/SPIE Electronic Imaging \",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7451623\",\"name\":\"Qian-Yi Zhou\"},{\"authorId\":\"145231047\",\"name\":\"V. Koltun\"}],\"doi\":\"10.1145/2461912.2461919\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"96b8050416c8a673ce96c5dbc0d2814606843b52\",\"title\":\"Dense scene reconstruction with points of interest\",\"url\":\"https://www.semanticscholar.org/paper/96b8050416c8a673ce96c5dbc0d2814606843b52\",\"venue\":\"ACM Trans. Graph.\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39810944\",\"name\":\"Jonathan Harel\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"}],\"doi\":\"10.7551/mitpress/7503.003.0073\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f412bb31ec9ef8bbef70eefc7ffd04420c1365d9\",\"title\":\"Graph-Based Visual Saliency\",\"url\":\"https://www.semanticscholar.org/paper/f412bb31ec9ef8bbef70eefc7ffd04420c1365d9\",\"venue\":\"NIPS\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":\"10.1126/SCIENCE.1127647\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"46eb79e5eec8a4e2b2f5652b66441e8a4c921c3e\",\"title\":\"Reducing the Dimensionality of Data with Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/46eb79e5eec8a4e2b2f5652b66441e8a4c921c3e\",\"venue\":\"Science\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12525266\",\"name\":\"Xinyi Cui\"},{\"authorId\":\"50383828\",\"name\":\"Qingshan Liu\"},{\"authorId\":\"1711560\",\"name\":\"D. Metaxas\"}],\"doi\":\"10.1145/1631272.1631370\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b3257d74e4ad050a1a518a53b0d23751f771f483\",\"title\":\"Temporal spectral residual: fast motion saliency detection\",\"url\":\"https://www.semanticscholar.org/paper/b3257d74e4ad050a1a518a53b0d23751f771f483\",\"venue\":\"MM '09\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40635259\",\"name\":\"D. Rudoy\"},{\"authorId\":\"1976171\",\"name\":\"D. Goldman\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"1398327241\",\"name\":\"L. Zelnik-Manor\"}],\"doi\":\"10.1109/CVPR.2013.152\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3d7924e07914a147d7f6b868050d4edd093b952d\",\"title\":\"Learning Video Saliency from Human Gaze Using Candidate Selection\",\"url\":\"https://www.semanticscholar.org/paper/3d7924e07914a147d7f6b868050d4edd093b952d\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9211580\",\"name\":\"Jukka H\\u00e4kkinen\"},{\"authorId\":\"47440520\",\"name\":\"T. Kawai\"},{\"authorId\":\"2240961\",\"name\":\"J. Takatalo\"},{\"authorId\":\"12973670\",\"name\":\"Reiko Mitsuya\"},{\"authorId\":\"1683424\",\"name\":\"G. Nyman\"}],\"doi\":\"10.1117/12.838857\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b6047a7a65f018522b26161c909b2e68252a413f\",\"title\":\"What do people look at when they watch stereoscopic movies?\",\"url\":\"https://www.semanticscholar.org/paper/b6047a7a65f018522b26161c909b2e68252a413f\",\"venue\":\"Electronic Imaging\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29810094\",\"name\":\"S. Winkler\"},{\"authorId\":\"1742936\",\"name\":\"S. Ramanathan\"}],\"doi\":\"10.1109/QoMEX.2013.6603239\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c102b22b59f3d59c3e78c33fbe29962eda46c2c5\",\"title\":\"Overview of Eye tracking Datasets\",\"url\":\"https://www.semanticscholar.org/paper/c102b22b59f3d59c3e78c33fbe29962eda46c2c5\",\"venue\":\"2013 Fifth International Workshop on Quality of Multimedia Experience (QoMEX)\",\"year\":2013},{\"arxivId\":\"1503.06917\",\"authors\":[{\"authorId\":null,\"name\":\"Qiang Zhang\"},{\"authorId\":\"46395101\",\"name\":\"Yilin Wang\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dc3c2b37e9dc95462b560e2d78a47622a38830e7\",\"title\":\"Unsupervised Video Analysis Based on a Spatiotemporal Saliency Detector\",\"url\":\"https://www.semanticscholar.org/paper/dc3c2b37e9dc95462b560e2d78a47622a38830e7\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1401681792\",\"name\":\"Q. Huynh-Thu\"},{\"authorId\":\"39365480\",\"name\":\"Luca Schiatti\"}],\"doi\":\"10.1117/12.872382\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf95f5218e6a48111d7b384177c6d1203561ac1d\",\"title\":\"Examination of 3D visual attention in stereoscopic video content\",\"url\":\"https://www.semanticscholar.org/paper/cf95f5218e6a48111d7b384177c6d1203561ac1d\",\"venue\":\"Electronic Imaging\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1819028\",\"name\":\"C. Richardt\"},{\"authorId\":\"2217934\",\"name\":\"Carsten Stoll\"},{\"authorId\":\"1743917\",\"name\":\"N. Dodgson\"},{\"authorId\":\"145156858\",\"name\":\"H. Seidel\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"}],\"doi\":\"10.1111/j.1467-8659.2012.03003.x\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"16c7e69c94468dad8393c452da5356ecc47943f6\",\"title\":\"Coherent Spatiotemporal Filtering, Upsampling and Rendering of RGBZ Videos\",\"url\":\"https://www.semanticscholar.org/paper/16c7e69c94468dad8393c452da5356ecc47943f6\",\"venue\":\"Comput. Graph. Forum\",\"year\":2012},{\"arxivId\":\"1610.01563\",\"authors\":[{\"authorId\":\"2997408\",\"name\":\"Matthias K\\u00fcmmerer\"},{\"authorId\":\"49737748\",\"name\":\"Thomas S. A. Wallis\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d160d375a7c187dfe10c110e9e733f36accb87e6\",\"title\":\"DeepGaze II: Reading fixations from deep features trained on object recognition\",\"url\":\"https://www.semanticscholar.org/paper/d160d375a7c187dfe10c110e9e733f36accb87e6\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Dosovitskiy\"},{\"authorId\":null,\"name\":\"J. T. Springenberg\"},{\"authorId\":null,\"name\":\"T. Brox\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Learnin g to generate chairs with convolutional neural networks\",\"url\":\"\",\"venue\":\"CVPR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A.\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Torralba . Sun 3 d : A database of big spaces reconstructed using SFM and object labels\",\"url\":\"\",\"venue\":\"\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"85021c84383d18a7a4434d76dc8135fc6bdc0aa6\",\"title\":\"Deep Boltzmann Machines\",\"url\":\"https://www.semanticscholar.org/paper/85021c84383d18a7a4434d76dc8135fc6bdc0aa6\",\"venue\":\"AISTATS\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2753356\",\"name\":\"J. Wang\"},{\"authorId\":\"21340060\",\"name\":\"Matthieu Perreira Da Silva\"},{\"authorId\":\"1776651\",\"name\":\"P. Callet\"},{\"authorId\":\"1764950\",\"name\":\"V. Ricordel\"}],\"doi\":\"10.1109/TIP.2013.2246176\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"93ec3ba9c312fd1f5a4c040953325d465f72c00a\",\"title\":\"Computational Model of Stereoscopic 3D Visual Saliency\",\"url\":\"https://www.semanticscholar.org/paper/93ec3ba9c312fd1f5a4c040953325d465f72c00a\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2013},{\"arxivId\":\"2001.00987\",\"authors\":[{\"authorId\":\"37615584\",\"name\":\"K. Karsch\"},{\"authorId\":\"1681442\",\"name\":\"Ce Liu\"},{\"authorId\":\"1738740\",\"name\":\"S. B. Kang\"}],\"doi\":\"10.1109/TPAMI.2014.2316835\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5f8f3e0fa482cf38a77af3af08b0375f1c49415a\",\"title\":\"Depth Transfer: Depth Extraction from Video Using Non-Parametric Sampling\",\"url\":\"https://www.semanticscholar.org/paper/5f8f3e0fa482cf38a77af3af08b0375f1c49415a\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Q.-Y. Zhou\"},{\"authorId\":null,\"name\":\"V. Koltun\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Dense scene reconstruction wi th points of interest.TOG\",\"url\":\"\",\"venue\":\"\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"E. Rahtu\"},{\"authorId\":null,\"name\":\"J. Kannala\"},{\"authorId\":null,\"name\":\"M. Salo\"},{\"authorId\":null,\"name\":\"J. Heikkil\\u00e4\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Segment ing salient objects from images and videos\",\"url\":\"\",\"venue\":\"ECCV, pages 366\\u2013379\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6376655\",\"name\":\"E. Herbst\"},{\"authorId\":\"46426476\",\"name\":\"X. Ren\"},{\"authorId\":\"145197953\",\"name\":\"D. Fox\"}],\"doi\":\"10.1109/ICRA.2013.6630885\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b65bea5349e4157b81781e04c0f3023116455912\",\"title\":\"RGB-D flow: Dense 3-D motion estimation using color and depth\",\"url\":\"https://www.semanticscholar.org/paper/b65bea5349e4157b81781e04c0f3023116455912\",\"venue\":\"2013 IEEE International Conference on Robotics and Automation\",\"year\":2013}],\"title\":\"Learning Gaze Transitions from Depth to Improve Video Saliency Estimation\",\"topics\":[{\"topic\":\"Convolutional neural network\",\"topicId\":\"29860\",\"url\":\"https://www.semanticscholar.org/topic/29860\"},{\"topic\":\"Data compression\",\"topicId\":\"41454\",\"url\":\"https://www.semanticscholar.org/topic/41454\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"},{\"topic\":\"Digital video\",\"topicId\":\"44670\",\"url\":\"https://www.semanticscholar.org/topic/44670\"},{\"topic\":\"Depth map\",\"topicId\":\"23196\",\"url\":\"https://www.semanticscholar.org/topic/23196\"},{\"topic\":\"Display device\",\"topicId\":\"21727\",\"url\":\"https://www.semanticscholar.org/topic/21727\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Usability testing\",\"topicId\":\"34160\",\"url\":\"https://www.semanticscholar.org/topic/34160\"},{\"topic\":\"Pixel\",\"topicId\":\"4254\",\"url\":\"https://www.semanticscholar.org/topic/4254\"},{\"topic\":\"Ground truth\",\"topicId\":\"33313\",\"url\":\"https://www.semanticscholar.org/topic/33313\"}],\"url\":\"https://www.semanticscholar.org/paper/ca1ff286ad8eba2aa6bc442f0f8321572fd0b090\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017}\n"