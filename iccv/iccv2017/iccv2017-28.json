"{\"abstract\":\"Standard video frame interpolation methods first estimate optical flow between input frames and then synthesize an intermediate frame guided by motion. Recent approaches merge these two steps into a single convolution process by convolving input frames with spatially adaptive kernels that account for motion and re-sampling simultaneously. These methods require large kernels to handle large motion, which limits the number of pixels whose kernels can be estimated at once due to the large memory demand. To address this problem, this paper formulates frame interpolation as local separable convolution over input frames using pairs of 1D kernels. Compared to regular 2D kernels, the 1D kernels require significantly fewer parameters to be estimated. Our method develops a deep fully convolutional neural network that takes two input frames and estimates pairs of 1D kernels for all pixels simultaneously. Since our method is able to estimate kernels and synthesizes the whole video frame at once, it allows for the incorporation of perceptual loss to train the neural network to produce visually pleasing frames. This deep neural network is trained end-to-end using widely available video data without any human annotation. Both qualitative and quantitative experiments show that our method provides a practical solution to high-quality video frame interpolation.\",\"arxivId\":\"1708.01692\",\"authors\":[{\"authorId\":\"39644974\",\"name\":\"Simon Niklaus\",\"url\":\"https://www.semanticscholar.org/author/39644974\"},{\"authorId\":\"2712573\",\"name\":\"Long Mai\",\"url\":\"https://www.semanticscholar.org/author/2712573\"},{\"authorId\":\"40513795\",\"name\":\"Feng Liu\",\"url\":\"https://www.semanticscholar.org/author/40513795\"}],\"citationVelocity\":87,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"8526699\",\"name\":\"Jean Begaint\"},{\"authorId\":\"1679157\",\"name\":\"Franck Galpin\"},{\"authorId\":\"1871505\",\"name\":\"Philippe Guillotel\"},{\"authorId\":\"1780587\",\"name\":\"Christine Guillemot\"}],\"doi\":\"10.1109/DCC.2019.00068\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"866fd28fc5381032a96d45e81c551c1af99bdec9\",\"title\":\"Deep Frame Interpolation for Video Compression\",\"url\":\"https://www.semanticscholar.org/paper/866fd28fc5381032a96d45e81c551c1af99bdec9\",\"venue\":\"2019 Data Compression Conference (DCC)\",\"year\":2019},{\"arxivId\":\"2009.02978\",\"authors\":[{\"authorId\":\"48230793\",\"name\":\"Nan Meng\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"46700604\",\"name\":\"J. Liu\"},{\"authorId\":\"1725389\",\"name\":\"E. Lam\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"04dbcd86777f646f38d490f1025d67500a62d32e\",\"title\":\"Light Field View Synthesis via Aperture Flow and Propagation Confidence Map\",\"url\":\"https://www.semanticscholar.org/paper/04dbcd86777f646f38d490f1025d67500a62d32e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.01280\",\"authors\":[{\"authorId\":\"39644974\",\"name\":\"Simon Niklaus\"},{\"authorId\":\"2712573\",\"name\":\"Long Mai\"},{\"authorId\":\"1660745575\",\"name\":\"Oliver Wang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"88b1113f94c0ab9521af358f4d9f7e9bff643e12\",\"title\":\"Revisiting Adaptive Convolutions for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/88b1113f94c0ab9521af358f4d9f7e9bff643e12\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"91926911\",\"name\":\"Minho Park\"},{\"authorId\":\"2909533\",\"name\":\"Sangmin Lee\"},{\"authorId\":\"7251290\",\"name\":\"Yong Man Ro\"}],\"doi\":\"10.1109/ICASSP40776.2020.9054744\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"bf10a08700cda8de85650cb4a8c5762ed9c47a22\",\"title\":\"Video Frame Interpolation Via Exceptional Motion-Aware Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/bf10a08700cda8de85650cb4a8c5762ed9c47a22\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"2009.12537\",\"authors\":[{\"authorId\":\"1698838706\",\"name\":\"Jing Jin\"},{\"authorId\":\"40630305\",\"name\":\"J. Hou\"},{\"authorId\":\"48148100\",\"name\":\"Zhiyu Zhu\"},{\"authorId\":\"50762898\",\"name\":\"Jie Chen\"},{\"authorId\":\"1687386\",\"name\":\"S. Kwong\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b7dd18d6effea07bd621a2344c676fc6697d7d34\",\"title\":\"Deep Selective Combinatorial Embedding and Consistency Regularization for Light Field Super-resolution\",\"url\":\"https://www.semanticscholar.org/paper/b7dd18d6effea07bd621a2344c676fc6697d7d34\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1763523\",\"name\":\"Abdelaziz Djelouah\"},{\"authorId\":\"144816141\",\"name\":\"J. Campos\"},{\"authorId\":\"1412432168\",\"name\":\"Simone Schaub-Meyer\"},{\"authorId\":\"2604867\",\"name\":\"Christopher Schroers\"}],\"doi\":\"10.1109/ICCV.2019.00652\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f587e6b59d4c5ff21efa076ac9349b3b6d777a34\",\"title\":\"Neural Inter-Frame Compression for Video Coding\",\"url\":\"https://www.semanticscholar.org/paper/f587e6b59d4c5ff21efa076ac9349b3b6d777a34\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152128102\",\"name\":\"Yuan Gao\"},{\"authorId\":\"144839904\",\"name\":\"R. Koch\"},{\"authorId\":\"2340064\",\"name\":\"R. Bregovic\"},{\"authorId\":\"1799559\",\"name\":\"A. Gotchev\"}],\"doi\":\"10.1109/ICIP.2019.8803436\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"de3680029069acdc287c62fa0b632f8140b1578a\",\"title\":\"Fast: Flow-Assisted Shearlet Transform for Densely-Sampled Light Field Reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/de3680029069acdc287c62fa0b632f8140b1578a\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51152279\",\"name\":\"Daniel Gehrig\"},{\"authorId\":\"8329387\",\"name\":\"M. Gehrig\"},{\"authorId\":\"1406402485\",\"name\":\"Javier Hidalgo-Carri'o\"},{\"authorId\":\"2075371\",\"name\":\"D. Scaramuzza\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f877010d390ea6ab73608637ba1f0865ba066f12\",\"title\":\"Video to Events: Bringing Modern Computer Vision Closer to Event Cameras\",\"url\":\"https://www.semanticscholar.org/paper/f877010d390ea6ab73608637ba1f0865ba066f12\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2001.11698\",\"authors\":[{\"authorId\":\"1491292845\",\"name\":\"Zhaotao Wu\"},{\"authorId\":\"1471334007\",\"name\":\"J. Wei\"},{\"authorId\":\"150341007\",\"name\":\"Wenguang Yuan\"},{\"authorId\":\"2246972\",\"name\":\"J. Wang\"},{\"authorId\":\"3198175\",\"name\":\"T. Tasdizen\"}],\"doi\":\"10.3233/FAIA200314\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f81d115ec43e49ec7f0eb8ed8f9afdfa65ded5c1\",\"title\":\"Inter-slice image augmentation based on frame interpolation for boosting medical image segmentation accuracy\",\"url\":\"https://www.semanticscholar.org/paper/f81d115ec43e49ec7f0eb8ed8f9afdfa65ded5c1\",\"venue\":\"ECAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143668913\",\"name\":\"A. Kokaram\"},{\"authorId\":\"90126681\",\"name\":\"Davinder Singh\"},{\"authorId\":\"2000355837\",\"name\":\"Simon Robinson\"}],\"doi\":\"10.1109/ICIP40778.2020.9191152\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"74510e871016eb629b504bab5df12f8b4ca9e9ec\",\"title\":\"A Bayesian View of Frame Interpolation and a Comparison with Existing Motion Picture Effects Tools\",\"url\":\"https://www.semanticscholar.org/paper/74510e871016eb629b504bab5df12f8b4ca9e9ec\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49404171\",\"name\":\"Haopeng Li\"},{\"authorId\":\"49521471\",\"name\":\"Y. Yuan\"},{\"authorId\":\"39669401\",\"name\":\"Q. Wang\"}],\"doi\":\"10.1109/ACCESS.2019.2936549\",\"intent\":[\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"00b75d8ef0a8250a27e8dacedf8a6f4c4ca126d2\",\"title\":\"FI-Net: A Lightweight Video Frame Interpolation Network Using Feature-Level Flow\",\"url\":\"https://www.semanticscholar.org/paper/00b75d8ef0a8250a27e8dacedf8a6f4c4ca126d2\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1825026\",\"name\":\"Yang Zhou\"},{\"authorId\":\"144204050\",\"name\":\"L. Chen\"},{\"authorId\":\"1728718\",\"name\":\"Jiying Zhao\"}],\"doi\":\"10.1109/PACRIM47961.2019.8985104\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9b114ba0c42b77ea0f7def03e8431b506ade16cc\",\"title\":\"Video Super-Resolution with Compensation in Feature Extraction\",\"url\":\"https://www.semanticscholar.org/paper/9b114ba0c42b77ea0f7def03e8431b506ade16cc\",\"venue\":\"2019 IEEE Pacific Rim Conference on Communications, Computers and Signal Processing (PACRIM)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1396445187\",\"name\":\"Tejas Jayashankar\"},{\"authorId\":\"2136396\",\"name\":\"P. Moulin\"},{\"authorId\":\"103267155\",\"name\":\"T. Blu\"},{\"authorId\":\"1393149454\",\"name\":\"Chris Gilliam\"}],\"doi\":\"10.1109/ICIP.2019.8803484\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4fcd9125493f669f219e5e5e649ecfaa77ff334f\",\"title\":\"Lap-Based Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/4fcd9125493f669f219e5e5e649ecfaa77ff334f\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"20789359\",\"name\":\"Jung-Kyung Lee\"},{\"authorId\":\"1681225\",\"name\":\"Na-young Kim\"},{\"authorId\":\"49467251\",\"name\":\"Seunghyun Cho\"},{\"authorId\":\"153041302\",\"name\":\"Jewon Kang\"}],\"doi\":\"10.1109/ACCESS.2020.2993566\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7c7bc4ac7d28f3646e8fecf8c5e160d7c65442c5\",\"title\":\"Deep Video Prediction Network-ased Inter-Frame Coding in HEVC\",\"url\":\"https://www.semanticscholar.org/paper/7c7bc4ac7d28f3646e8fecf8c5e160d7c65442c5\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30903985\",\"name\":\"Haoxian Zhang\"},{\"authorId\":\"49908329\",\"name\":\"Ronggang Wang\"},{\"authorId\":null,\"name\":\"Yang Zhao\"}],\"doi\":\"10.1109/ACCESS.2019.2940510\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9d01de72d62f89e9e7c1b691a1bd3ca2b67b2664\",\"title\":\"Multi-Frame Pyramid Refinement Network for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/9d01de72d62f89e9e7c1b691a1bd3ca2b67b2664\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1909.07957\",\"authors\":[{\"authorId\":\"49724177\",\"name\":\"Hao-Tian Zhang\"},{\"authorId\":\"2712573\",\"name\":\"Long Mai\"},{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":\"50218411\",\"name\":\"Z. Wang\"},{\"authorId\":\"1680236\",\"name\":\"J. Collomosse\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"}],\"doi\":\"10.1109/ICCV.2019.00281\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ccbb652bca1b5f795333c7dc148ad2f01caf9e35\",\"title\":\"An Internal Learning Approach to Video Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/ccbb652bca1b5f795333c7dc148ad2f01caf9e35\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2003.09294\",\"authors\":[{\"authorId\":\"152128102\",\"name\":\"Yuan Gao\"},{\"authorId\":\"2340064\",\"name\":\"R. Bregovic\"},{\"authorId\":\"1799559\",\"name\":\"A. Gotchev\"}],\"doi\":\"10.1109/LSP.2020.3008082\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"540e02b0ec5fbc470ebecb58689a16aba49f848e\",\"title\":\"Self-Supervised Light Field Reconstruction Using Shearlet Transform and Cycle Consistency\",\"url\":\"https://www.semanticscholar.org/paper/540e02b0ec5fbc470ebecb58689a16aba49f848e\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"93299623\",\"name\":\"Bumjun Park\"},{\"authorId\":\"150311567\",\"name\":\"Songhyun Yu\"},{\"authorId\":\"1557273080\",\"name\":\"Jechang Jeong\"}],\"doi\":\"10.1109/ICCVW.2019.00433\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2141bb1226997c49123731d97b484ca19696485a\",\"title\":\"Robust Temporal Super-Resolution for Dynamic Motion Videos\",\"url\":\"https://www.semanticscholar.org/paper/2141bb1226997c49123731d97b484ca19696485a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8686372\",\"name\":\"Jiawen Gu\"},{\"authorId\":\"51115365\",\"name\":\"Bichuan Guo\"},{\"authorId\":\"36849762\",\"name\":\"J. Wen\"}],\"doi\":\"10.1109/ICME.2019.00067\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7b20b18fad3af20dbff1369c5fd5c7afd1b39423\",\"title\":\"High Efficiency Light Field Compression via Virtual Reference and Hierarchical MV-HEVC\",\"url\":\"https://www.semanticscholar.org/paper/7b20b18fad3af20dbff1369c5fd5c7afd1b39423\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50105307\",\"name\":\"Wenchao Hu\"},{\"authorId\":\"50218026\",\"name\":\"Z. Wang\"}],\"doi\":\"10.1007/978-3-030-31723-2_34\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7f9224ec46346e53aeaa5951906e48699f914b9f\",\"title\":\"A Multi-frame Video Interpolation Neural Network for Large Motion\",\"url\":\"https://www.semanticscholar.org/paper/7f9224ec46346e53aeaa5951906e48699f914b9f\",\"venue\":\"PRCV\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1898092\",\"name\":\"Bahetiyaer Bare\"},{\"authorId\":\"145613609\",\"name\":\"Bo Yan\"},{\"authorId\":\"49679098\",\"name\":\"Chenxi Ma\"},{\"authorId\":\"104106360\",\"name\":\"Ke Li\"}],\"doi\":\"10.1016/J.NEUCOM.2019.07.089\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"349d221fc29da0be009f1c6f1e73721854cfd79e\",\"title\":\"Real-time video super-resolution via motion convolution kernel estimation\",\"url\":\"https://www.semanticscholar.org/paper/349d221fc29da0be009f1c6f1e73721854cfd79e\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"1904.00523\",\"authors\":[{\"authorId\":\"22275884\",\"name\":\"Jianrui Cai\"},{\"authorId\":\"72910911\",\"name\":\"Hui Zeng\"},{\"authorId\":\"7906116\",\"name\":\"Hongwei Yong\"},{\"authorId\":\"2824404\",\"name\":\"Zisheng Cao\"},{\"authorId\":\"47058801\",\"name\":\"Lei Zhang\"}],\"doi\":\"10.1109/ICCV.2019.00318\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a646c1e52c081a266638785134d3e6dc3a3e7068\",\"title\":\"Toward Real-World Single Image Super-Resolution: A New Benchmark and a New Model\",\"url\":\"https://www.semanticscholar.org/paper/a646c1e52c081a266638785134d3e6dc3a3e7068\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1902.09680\",\"authors\":[{\"authorId\":\"51495548\",\"name\":\"Zihao W. Wang\"},{\"authorId\":\"8385095\",\"name\":\"Weixin Jiang\"},{\"authorId\":\"144842935\",\"name\":\"A. Katsaggelos\"},{\"authorId\":\"1793812\",\"name\":\"O. Cossairt\"}],\"doi\":\"10.1109/ICCVW.2019.00532\",\"intent\":[\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"0ab864d234049df7745416cc0d2e9357842a6b11\",\"title\":\"Event-Driven Video Frame Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/0ab864d234049df7745416cc0d2e9357842a6b11\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"2002.10981\",\"authors\":[{\"authorId\":\"48359318\",\"name\":\"Sanchita Ghose\"},{\"authorId\":\"2845029\",\"name\":\"John J. Prevost\"}],\"doi\":\"10.1109/TMM.2020.3005033\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1337db4d3283e77e959a683ef5cb15949f1d5400\",\"title\":\"AutoFoley: Artificial Synthesis of Synchronized Sound Tracks for Silent Videos with Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/1337db4d3283e77e959a683ef5cb15949f1d5400\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46398521\",\"name\":\"Y. Liu\"},{\"authorId\":\"66821424\",\"name\":\"Yi-Tung Liao\"},{\"authorId\":\"1744044\",\"name\":\"Yen-Yu Lin\"},{\"authorId\":\"143708263\",\"name\":\"Yung-Yu Chuang\"}],\"doi\":\"10.1609/AAAI.V33I01.33018794\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"92f3548ff323a65981aed274c0b124053dce2e73\",\"title\":\"Deep Video Frame Interpolation Using Cyclic Frame Generation\",\"url\":\"https://www.semanticscholar.org/paper/92f3548ff323a65981aed274c0b124053dce2e73\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145772051\",\"name\":\"Sifeng Xia\"},{\"authorId\":\"1898172\",\"name\":\"W. Yang\"},{\"authorId\":\"9956463\",\"name\":\"Yueyu Hu\"},{\"authorId\":\"41127426\",\"name\":\"Jiaying Liu\"}],\"doi\":\"10.1109/ICIP.2019.8803148\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ae08cc53f2830f50d872433074c2dd747c18e011\",\"title\":\"Deep Inter Prediction Via Pixel-Wise Motion Oriented Reference Generation\",\"url\":\"https://www.semanticscholar.org/paper/ae08cc53f2830f50d872433074c2dd747c18e011\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"1906.05928\",\"authors\":[{\"authorId\":\"3291967\",\"name\":\"F. Reda\"},{\"authorId\":\"3232265\",\"name\":\"Deqing Sun\"},{\"authorId\":\"2130620\",\"name\":\"A. Dundar\"},{\"authorId\":\"1911755\",\"name\":\"M. Shoeybi\"},{\"authorId\":\"47062069\",\"name\":\"Guilin Liu\"},{\"authorId\":\"143953573\",\"name\":\"K. Shih\"},{\"authorId\":\"29955511\",\"name\":\"A. Tao\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"},{\"authorId\":\"2301680\",\"name\":\"Bryan Catanzaro\"}],\"doi\":\"10.1109/ICCV.2019.00098\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d0cacb90967827cb7bf1876dc49e6bd8881e4d81\",\"title\":\"Unsupervised Video Interpolation Using Cycle Consistency\",\"url\":\"https://www.semanticscholar.org/paper/d0cacb90967827cb7bf1876dc49e6bd8881e4d81\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8187964\",\"name\":\"R. Aoki\"},{\"authorId\":\"1800246\",\"name\":\"R. Miyamoto\"}],\"doi\":\"10.1109/MetroArchaeo43810.2018.13594\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5220c60d57f7a5889737c1a29a35693e946238dc\",\"title\":\"Problems in Three-Dimensional Measurement of Japanese Kenjutsu Using Existing Sensing Devices\",\"url\":\"https://www.semanticscholar.org/paper/5220c60d57f7a5889737c1a29a35693e946238dc\",\"venue\":\"2018 Metrology for Archaeology and Cultural Heritage (MetroArchaeo)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"117185645\",\"name\":\"Sen-Zhe Xu\"},{\"authorId\":\"1745787\",\"name\":\"J. Hu\"},{\"authorId\":\"145631934\",\"name\":\"M. Wang\"},{\"authorId\":\"31471368\",\"name\":\"Tai-Jiang Mu\"},{\"authorId\":\"145140922\",\"name\":\"S. Hu\"}],\"doi\":\"10.1111/cgf.13566\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d9de93805462d9a5b0676ce4049c7b56a55ed7c0\",\"title\":\"Deep Video Stabilization Using Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/d9de93805462d9a5b0676ce4049c7b56a55ed7c0\",\"venue\":\"Comput. Graph. Forum\",\"year\":2018},{\"arxivId\":\"1712.06463\",\"authors\":[{\"authorId\":\"143904396\",\"name\":\"Xu Jia\"},{\"authorId\":\"145375324\",\"name\":\"H. Chang\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f311724bfd2e3b49b2944363c0dbc214488aaac2\",\"title\":\"Super-Resolution with Deep Adaptive Image Resampling\",\"url\":\"https://www.semanticscholar.org/paper/f311724bfd2e3b49b2944363c0dbc214488aaac2\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32168317\",\"name\":\"Neerav Karani\"},{\"authorId\":\"145057506\",\"name\":\"C. Tanner\"},{\"authorId\":\"3299349\",\"name\":\"S. Kozerke\"},{\"authorId\":\"1796918\",\"name\":\"E. Konukoglu\"}],\"doi\":\"10.1109/TMI.2018.2831442\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"87466fa5073fd3f66ca53a1c8896b5fad406b7c4\",\"title\":\"Reducing Navigators in Free-Breathing Abdominal MRI via Temporal Interpolation Using Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/87466fa5073fd3f66ca53a1c8896b5fad406b7c4\",\"venue\":\"IEEE Transactions on Medical Imaging\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2004189772\",\"name\":\"Qing Guo\"},{\"authorId\":\"1389940060\",\"name\":\"Felix Juefei-Xu\"},{\"authorId\":\"145564459\",\"name\":\"X. Xie\"},{\"authorId\":\"143828252\",\"name\":\"L. Ma\"},{\"authorId\":\"152924492\",\"name\":\"Jian Wang\"},{\"authorId\":\"1485043101\",\"name\":\"Bing Yu\"},{\"authorId\":\"2031553111\",\"name\":\"Wei Feng\"},{\"authorId\":\"38057121\",\"name\":\"Yang Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"3e3ab0ee7f9c7faa0501049ac50419b15b16e612\",\"title\":\"Watch out! Motion is Blurring Blurring the Vision of Your Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/3e3ab0ee7f9c7faa0501049ac50419b15b16e612\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2003.00389\",\"authors\":[{\"authorId\":\"32879676\",\"name\":\"Jiezhang Cao\"},{\"authorId\":\"90891818\",\"name\":\"Langyuan Mo\"},{\"authorId\":\"150270181\",\"name\":\"Qing Du\"},{\"authorId\":\"143670622\",\"name\":\"Yong Guo\"},{\"authorId\":\"144259957\",\"name\":\"P. Zhao\"},{\"authorId\":\"50882910\",\"name\":\"Junzhou Huang\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3cec7f2172d4e09db5a62e8a4f83c4f32a3e32e9\",\"title\":\"Joint Wasserstein Distribution Matching\",\"url\":\"https://www.semanticscholar.org/paper/3cec7f2172d4e09db5a62e8a4f83c4f32a3e32e9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1804.00884\",\"authors\":[{\"authorId\":\"50113176\",\"name\":\"S. Meyer\"},{\"authorId\":\"1763523\",\"name\":\"Abdelaziz Djelouah\"},{\"authorId\":\"46936952\",\"name\":\"Brian McWilliams\"},{\"authorId\":\"1388791172\",\"name\":\"Alexander Sorkine-Hornung\"},{\"authorId\":\"144877478\",\"name\":\"M. Gross\"},{\"authorId\":\"2604867\",\"name\":\"Christopher Schroers\"}],\"doi\":\"10.1109/CVPR.2018.00059\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b934bdaaaed7af7269a368a8c93c87c293f876f8\",\"title\":\"PhaseNet for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/b934bdaaaed7af7269a368a8c93c87c293f876f8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1808.03232\",\"authors\":[{\"authorId\":\"3230188\",\"name\":\"Simone Meyer\"},{\"authorId\":\"51217206\",\"name\":\"Victor Cornill\\u00e8re\"},{\"authorId\":\"1763523\",\"name\":\"Abdelaziz Djelouah\"},{\"authorId\":\"2604867\",\"name\":\"Christopher Schroers\"},{\"authorId\":\"144877478\",\"name\":\"M. Gross\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0c40c6505c2133321f17c7d02c1bb356f581da89\",\"title\":\"Deep Video Color Propagation\",\"url\":\"https://www.semanticscholar.org/paper/0c40c6505c2133321f17c7d02c1bb356f581da89\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":\"2004.02806\",\"authors\":[{\"authorId\":\"3313413\",\"name\":\"Zewen Li\"},{\"authorId\":\"47718298\",\"name\":\"W. Yang\"},{\"authorId\":\"1612537626\",\"name\":\"Shouheng Peng\"},{\"authorId\":\"153035664\",\"name\":\"Fan Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1de68f12db136526116c6ac7064fd13965f2c966\",\"title\":\"A Survey of Convolutional Neural Networks: Analysis, Applications, and Prospects\",\"url\":\"https://www.semanticscholar.org/paper/1de68f12db136526116c6ac7064fd13965f2c966\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.05084\",\"authors\":[{\"authorId\":\"145906067\",\"name\":\"Y. Chen\"},{\"authorId\":\"92493482\",\"name\":\"M. Alain\"},{\"authorId\":\"118065745\",\"name\":\"A. Smolic\"}],\"doi\":\"10.1109/MMSP48831.2020.9287105\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b9456d33164705981170f0bd94ed6c93a1eeb792\",\"title\":\"Self-supervised Light Field View Synthesis Using Cycle Consistency\",\"url\":\"https://www.semanticscholar.org/paper/b9456d33164705981170f0bd94ed6c93a1eeb792\",\"venue\":\"2020 IEEE 22nd International Workshop on Multimedia Signal Processing (MMSP)\",\"year\":2020},{\"arxivId\":\"2002.12106\",\"authors\":[{\"authorId\":\"51308376\",\"name\":\"A. Paliwal\"},{\"authorId\":\"1717070\",\"name\":\"Nima Khademi Kalantari\"}],\"doi\":\"10.1109/TPAMI.2020.2987316\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5c82944c88e0be99857a280d8246593842c515a0\",\"title\":\"Deep Slow Motion Video Reconstruction With Hybrid Imaging System\",\"url\":\"https://www.semanticscholar.org/paper/5c82944c88e0be99857a280d8246593842c515a0\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51313391\",\"name\":\"HuangKai Cai\"},{\"authorId\":\"143822920\",\"name\":\"He Jiang\"},{\"authorId\":\"144335593\",\"name\":\"X. Huang\"},{\"authorId\":\"1688428\",\"name\":\"Jie Yang\"}],\"doi\":\"10.1007/978-3-030-03398-9_31\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8d8d871334104077c8ffa3167dc23c6480c9e070\",\"title\":\"New Motion Estimation with Angular-Distance Median Filter for Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/8d8d871334104077c8ffa3167dc23c6480c9e070\",\"venue\":\"PRCV\",\"year\":2018},{\"arxivId\":\"2005.13194\",\"authors\":[{\"authorId\":\"2317713\",\"name\":\"S. Lee\"},{\"authorId\":\"98080420\",\"name\":\"H. Lee\"},{\"authorId\":\"48271129\",\"name\":\"T. Kim\"},{\"authorId\":\"39847092\",\"name\":\"Sangyoun Lee\"}],\"doi\":\"10.1109/ICIP40778.2020.9191286\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"aff965a62434c25e3465223179771f8b9f689054\",\"title\":\"Extrapolative-Interpolative Cycle-Consistency Learning For Video Frame Extrapolation\",\"url\":\"https://www.semanticscholar.org/paper/aff965a62434c25e3465223179771f8b9f689054\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"2002.12680\",\"authors\":[{\"authorId\":\"7000208\",\"name\":\"Yu-yu Guo\"},{\"authorId\":\"49117537\",\"name\":\"Lei Bi\"},{\"authorId\":\"2130901\",\"name\":\"Euijoon Ahn\"},{\"authorId\":\"11675891\",\"name\":\"D. Feng\"},{\"authorId\":\"49110419\",\"name\":\"Q. Wang\"},{\"authorId\":\"46454386\",\"name\":\"Jinman Kim\"}],\"doi\":\"10.1109/cvpr42600.2020.00478\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"57561a45ccde67ea6e3db870e4994106e4d61a69\",\"title\":\"A Spatiotemporal Volumetric Interpolation Network for 4D Dynamic Medical Image\",\"url\":\"https://www.semanticscholar.org/paper/57561a45ccde67ea6e3db870e4994106e4d61a69\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144952644\",\"name\":\"D. Y. Choi\"},{\"authorId\":\"10774886\",\"name\":\"B. Song\"}],\"doi\":\"10.1109/ACCESS.2020.3006958\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"773a1bca38f4dfa28325d59eb6bbf0656852ad95\",\"title\":\"Facial Micro-Expression Recognition Using Two-Dimensional Landmark Feature Maps\",\"url\":\"https://www.semanticscholar.org/paper/773a1bca38f4dfa28325d59eb6bbf0656852ad95\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1812.01037\",\"authors\":[{\"authorId\":\"46793780\",\"name\":\"Ximeng Sun\"},{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/WACV45572.2020.9093557\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"05c43f1791787e78e343536a65a2853af699fe68\",\"title\":\"TwoStreamVAN: Improving Motion Modeling in Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/05c43f1791787e78e343536a65a2853af699fe68\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145567286\",\"name\":\"Hoang Le\"},{\"authorId\":\"50208066\",\"name\":\"F. Liu\"}],\"doi\":\"10.1111/cgf.13860\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"26d8da3d2f67e914aa564942d2721e89e221ef52\",\"title\":\"Appearance Flow Completion for Novel View Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/26d8da3d2f67e914aa564942d2721e89e221ef52\",\"venue\":\"Comput. Graph. Forum\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2679394\",\"name\":\"Tim Brooks\"},{\"authorId\":\"50329510\",\"name\":\"J. Barron\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a42e4c2b70a74b9315c1c19f0d4a7993c0727fcf\",\"title\":\"Learning to Synthesize Motion Blur Supplement\",\"url\":\"https://www.semanticscholar.org/paper/a42e4c2b70a74b9315c1c19f0d4a7993c0727fcf\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1912.02401\",\"authors\":[{\"authorId\":\"8080821\",\"name\":\"Megha Nawhal\"},{\"authorId\":\"1936990\",\"name\":\"Mengyao Zhai\"},{\"authorId\":\"20812150\",\"name\":\"Andreas M. Lehrmann\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"}],\"doi\":\"10.1007/978-3-030-58610-2_23\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4ebb4985c6da258fe47a63d1f9dc1ae491e6db62\",\"title\":\"Generating Videos of Zero-Shot Compositions of Actions and Objects\",\"url\":\"https://www.semanticscholar.org/paper/4ebb4985c6da258fe47a63d1f9dc1ae491e6db62\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1910.12713\",\"authors\":[{\"authorId\":\"2195314\",\"name\":\"T. Wang\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":\"29955511\",\"name\":\"A. Tao\"},{\"authorId\":\"47062069\",\"name\":\"Guilin Liu\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"},{\"authorId\":\"2301680\",\"name\":\"Bryan Catanzaro\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bea92a69b48287caa3a25ff3dfe727bed8888348\",\"title\":\"Few-shot Video-to-Video Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/bea92a69b48287caa3a25ff3dfe727bed8888348\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48550129\",\"name\":\"Jiajun Deng\"},{\"authorId\":\"34413938\",\"name\":\"Haichao Yu\"},{\"authorId\":\"2969311\",\"name\":\"Zhangyang Wang\"},{\"authorId\":\"48631088\",\"name\":\"Xinchao Wang\"},{\"authorId\":\"1739208\",\"name\":\"T. Huang\"}],\"doi\":\"10.1109/MIPR.2019.00042\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4e20404e8cd2ccac389b1ce6ff4690f1fd29404e\",\"title\":\"Self-Reproducing Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/4e20404e8cd2ccac389b1ce6ff4690f1fd29404e\",\"venue\":\"2019 IEEE Conference on Multimedia Information Processing and Retrieval (MIPR)\",\"year\":2019},{\"arxivId\":\"1907.12013\",\"authors\":[{\"authorId\":\"2943460\",\"name\":\"Thomas Vandal\"},{\"authorId\":\"48834077\",\"name\":\"R. Nemani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0454d9ef912a08585d14921b94f8eda11a43bb0a\",\"title\":\"Temporal Interpolation of Geostationary Satellite Imagery with Task Specific Optical Flow.\",\"url\":\"https://www.semanticscholar.org/paper/0454d9ef912a08585d14921b94f8eda11a43bb0a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2012.08103\",\"authors\":[{\"authorId\":\"5168807\",\"name\":\"Soo Ye Kim\"},{\"authorId\":\"72551720\",\"name\":\"Hyeonjun Sim\"},{\"authorId\":\"123446757\",\"name\":\"M. Kim\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ab4b179ed63441d49dbd903cb6bc06bd691ae137\",\"title\":\"KOALAnet: Blind Super-Resolution using Kernel-Oriented Adaptive Local Adjustment\",\"url\":\"https://www.semanticscholar.org/paper/ab4b179ed63441d49dbd903cb6bc06bd691ae137\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"89909440\",\"name\":\"Se\\u00e1n Bruton\"},{\"authorId\":\"89087926\",\"name\":\"D. Ganter\"},{\"authorId\":\"1790513\",\"name\":\"M. Manzke\"}],\"doi\":\"10.1007/978-3-030-41590-7_14\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0118366a4a6a88d5dc890ff1d719e957c64b6692\",\"title\":\"Fast Approximate Light Field Volume Rendering: Using Volume Data to Improve Light Field Synthesis via Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/0118366a4a6a88d5dc890ff1d719e957c64b6692\",\"venue\":\"VISIGRAPP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Chance Hamilton\"},{\"authorId\":\"6439443\",\"name\":\"J. Ventura\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"c0ca6a22a0b5a2e7ec1544e72a27758a3c790bc2\",\"title\":\"Video Frame Interpolation via Pixel Polynomial Modeling\",\"url\":\"https://www.semanticscholar.org/paper/c0ca6a22a0b5a2e7ec1544e72a27758a3c790bc2\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2006.00781\",\"authors\":[{\"authorId\":\"2026424\",\"name\":\"X. Yin\"},{\"authorId\":\"2433068\",\"name\":\"Dongxue Liang\"},{\"authorId\":\"1693096275\",\"name\":\"Lu Wang\"},{\"authorId\":\"145505348\",\"name\":\"Jing Qiu\"},{\"authorId\":\"47087084\",\"name\":\"Z. Yang\"},{\"authorId\":\"46951283\",\"name\":\"J. Xing\"},{\"authorId\":\"28094546\",\"name\":\"Jian-zeng Dong\"},{\"authorId\":\"1903011\",\"name\":\"Zhaoyuan Ma\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"88cc19540cd3785ae2225980220bfe8f91dd0015\",\"title\":\"Reducing the X-ray radiation exposure frequency in cardio-angiography via deep-learning based video interpolation\",\"url\":\"https://www.semanticscholar.org/paper/88cc19540cd3785ae2225980220bfe8f91dd0015\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143744989\",\"name\":\"Qianshu Zhu\"},{\"authorId\":\"1641959671\",\"name\":\"Chu Han\"},{\"authorId\":\"2513505\",\"name\":\"Guoqiang Han\"},{\"authorId\":\"50350340\",\"name\":\"Tien-Tsin Wong\"},{\"authorId\":\"2548483\",\"name\":\"Shengfeng He\"}],\"doi\":\"10.1109/tpami.2020.3001644\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"27500d4c7a6cef1deb79abdff016217e34a2af71\",\"title\":\"Video Snapshot: Single Image Motion Expansion via Invertible Motion Embedding.\",\"url\":\"https://www.semanticscholar.org/paper/27500d4c7a6cef1deb79abdff016217e34a2af71\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1711298\",\"name\":\"W. Cheng\"},{\"authorId\":\"1769295\",\"name\":\"Junmo Kim\"},{\"authorId\":\"1423665164\",\"name\":\"Wei-Ta Chu\"},{\"authorId\":\"150258564\",\"name\":\"Peng Cui\"},{\"authorId\":\"143832924\",\"name\":\"Joung-Woo Choi\"},{\"authorId\":\"2345240\",\"name\":\"Min-Chun Hu\"},{\"authorId\":\"7627712\",\"name\":\"W. D. Neve\"}],\"doi\":\"10.1007/978-3-030-37731-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fc1063a8af03fbb9dfcbaabe8af30a4f863809f9\",\"title\":\"MultiMedia Modeling: 26th International Conference, MMM 2020, Daejeon, South Korea, January 5\\u20138, 2020, Proceedings, Part I\",\"url\":\"https://www.semanticscholar.org/paper/fc1063a8af03fbb9dfcbaabe8af30a4f863809f9\",\"venue\":\"MMM\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32764534\",\"name\":\"Songnan Lin\"},{\"authorId\":\"1519062623\",\"name\":\"Jiawei Zhang\"},{\"authorId\":\"9416881\",\"name\":\"J. Pan\"},{\"authorId\":\"1625349614\",\"name\":\"Zhe Jiang\"},{\"authorId\":\"2780914\",\"name\":\"Dongqing Zou\"},{\"authorId\":null,\"name\":\"Yongtian Wang\"},{\"authorId\":\"47739910\",\"name\":\"J. Chen\"},{\"authorId\":\"145335572\",\"name\":\"J. Ren\"}],\"doi\":\"10.1007/978-3-030-58598-3_41\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b949d975aac0d5864b9f27ecc517f198571b4ccf\",\"title\":\"Learning Event-Driven Video Deblurring and Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/b949d975aac0d5864b9f27ecc517f198571b4ccf\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1384709008\",\"name\":\"Xianhang Cheng\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"}],\"doi\":\"10.1109/TCSVT.2019.2939143\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7229f4ba7d8fb287d9603095b166f5e1d3e6e590\",\"title\":\"A Multi-Scale Position Feature Transform Network for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/7229f4ba7d8fb287d9603095b166f5e1d3e6e590\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"65779048\",\"name\":\"Wenjun Wang\"},{\"authorId\":\"144533004\",\"name\":\"Chao Ren\"},{\"authorId\":\"2146255\",\"name\":\"X. He\"},{\"authorId\":\"6222832\",\"name\":\"Honggang Chen\"},{\"authorId\":\"3334291\",\"name\":\"Linbo Qing\"}],\"doi\":\"10.1109/ACCESS.2018.2829908\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0c027c004925541dcc6072dcc296ec75acd9401f\",\"title\":\"Video Super-Resolution via Residual Learning\",\"url\":\"https://www.semanticscholar.org/paper/0c027c004925541dcc6072dcc296ec75acd9401f\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":\"2006.13205\",\"authors\":[{\"authorId\":\"31719101\",\"name\":\"Karl Pertsch\"},{\"authorId\":\"40900227\",\"name\":\"Oleh Rybkin\"},{\"authorId\":\"27535721\",\"name\":\"Frederik Ebert\"},{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"},{\"authorId\":\"144348441\",\"name\":\"Dinesh Jayaraman\"},{\"authorId\":\"152198491\",\"name\":\"Sergey Levine\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8dd3ec3ca1b7400d998e747356d07763a7ac1fb0\",\"title\":\"Long-Horizon Visual Planning with Goal-Conditioned Hierarchical Predictors\",\"url\":\"https://www.semanticscholar.org/paper/8dd3ec3ca1b7400d998e747356d07763a7ac1fb0\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40648435\",\"name\":\"Seungjun Nah\"},{\"authorId\":\"148009160\",\"name\":\"Sungyong Baik\"},{\"authorId\":\"150297656\",\"name\":\"Seokil Hong\"},{\"authorId\":\"3458134\",\"name\":\"Gyeongsik Moon\"},{\"authorId\":\"4640997\",\"name\":\"Sanghyun Son\"},{\"authorId\":\"1732855\",\"name\":\"R. Timofte\"},{\"authorId\":\"2135837\",\"name\":\"Kyoung Mu Lee\"}],\"doi\":\"10.1109/CVPRW.2019.00251\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"24cfdfff5e2794600b018e867ddbf07d80467dec\",\"title\":\"NTIRE 2019 Challenge on Video Deblurring and Super-Resolution: Dataset and Study\",\"url\":\"https://www.semanticscholar.org/paper/24cfdfff5e2794600b018e867ddbf07d80467dec\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":\"2002.12259\",\"authors\":[{\"authorId\":\"93263637\",\"name\":\"W. Shen\"},{\"authorId\":\"8613898\",\"name\":\"Wenbo Bao\"},{\"authorId\":\"144826391\",\"name\":\"Guangtao Zhai\"},{\"authorId\":\"69856210\",\"name\":\"Li Chen\"},{\"authorId\":\"2246414\",\"name\":\"Xiongkuo Min\"},{\"authorId\":\"97709070\",\"name\":\"Z. Gao\"}],\"doi\":\"10.1109/cvpr42600.2020.00516\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"34a51b7e4523a15f184fb05809a9c8ad6cfc6be0\",\"title\":\"Blurry Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/34a51b7e4523a15f184fb05809a9c8ad6cfc6be0\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1906.06475\",\"authors\":[{\"authorId\":\"145903796\",\"name\":\"Jonathan Pan\"}],\"doi\":\"10.1109/IoTaIS47347.2019.8980385\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f38516a02857b4e70832d32fd4ba3d390f0c4af6\",\"title\":\"Physical Integrity Attack Detection of Surveillance Camera with Deep Learning based Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/f38516a02857b4e70832d32fd4ba3d390f0c4af6\",\"venue\":\"2019 IEEE International Conference on Internet of Things and Intelligence System (IoTaIS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1471436975\",\"name\":\"Anh-Duc Nguyen\"},{\"authorId\":\"2257525\",\"name\":\"W. Kim\"},{\"authorId\":\"2078790\",\"name\":\"Jongyoo Kim\"},{\"authorId\":\"144968899\",\"name\":\"W. Lin\"},{\"authorId\":\"104009756\",\"name\":\"S. Lee\"}],\"doi\":\"10.1109/ACCESS.2019.2959019\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"6cf97ff4821d9af7e370e153fac865077d0f26f5\",\"title\":\"Video Frame Synthesis via Plug-and-Play Deep Locally Temporal Embedding\",\"url\":\"https://www.semanticscholar.org/paper/6cf97ff4821d9af7e370e153fac865077d0f26f5\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"88677858\",\"name\":\"Juan Luis Gonzalez Bello\"},{\"authorId\":\"3031085\",\"name\":\"Min-Soeng Kim\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"7ad521cad5821683a9fac7dc82c85f13d7075de0\",\"title\":\"CONVOLUTIONS WITH GLOBAL AND LOCAL ADAPTIVE DILATIONS\",\"url\":\"https://www.semanticscholar.org/paper/7ad521cad5821683a9fac7dc82c85f13d7075de0\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1905.10240\",\"authors\":[{\"authorId\":\"2469811\",\"name\":\"Yunpeng Li\"},{\"authorId\":\"3181733\",\"name\":\"Dominik Roblek\"},{\"authorId\":\"1749128\",\"name\":\"M. Tagliasacchi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"063700c45e10362f5642c08849348c41ee5b08a3\",\"title\":\"From Here to There: Video Inbetweening Using Direct 3D Convolutions\",\"url\":\"https://www.semanticscholar.org/paper/063700c45e10362f5642c08849348c41ee5b08a3\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1712.00080\",\"authors\":[{\"authorId\":\"40175280\",\"name\":\"Huaizu Jiang\"},{\"authorId\":\"3232265\",\"name\":\"Deqing Sun\"},{\"authorId\":\"2745026\",\"name\":\"V. Jampani\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"1389846455\",\"name\":\"E. Learned-Miller\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":\"10.1109/CVPR.2018.00938\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"baa1ae74fbf7ed6204f2f6364d51375ff81aabc1\",\"title\":\"Super SloMo: High Quality Estimation of Multiple Intermediate Frames for Video Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/baa1ae74fbf7ed6204f2f6364d51375ff81aabc1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2008193806\",\"name\":\"Sheikh Tanjila Naurin\"},{\"authorId\":\"2008216114\",\"name\":\"Antora Saha\"},{\"authorId\":\"2008193763\",\"name\":\"Khadija Akter\"},{\"authorId\":\"48488481\",\"name\":\"Sabbir Ahmed\"}],\"doi\":\"10.1109/TENSYMP50017.2020.9230901\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3fb0a1539ad2defeaf085285e5a08a6769635ba6\",\"title\":\"A Proposed Architecture to Suspect and Trace Criminal Activity Using Surveillance Cameras\",\"url\":\"https://www.semanticscholar.org/paper/3fb0a1539ad2defeaf085285e5a08a6769635ba6\",\"venue\":\"2020 IEEE Region 10 Symposium (TENSYMP)\",\"year\":2020},{\"arxivId\":\"2008.10680\",\"authors\":[{\"authorId\":\"49473017\",\"name\":\"Zhihao Shi\"},{\"authorId\":\"46522414\",\"name\":\"Xiaohong Liu\"},{\"authorId\":\"153250595\",\"name\":\"K. Shi\"},{\"authorId\":\"84102771\",\"name\":\"L. Dai\"},{\"authorId\":null,\"name\":\"Jun Chen\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"adc89874c2b2546850dcc1394c663fe22c3b4f6b\",\"title\":\"Video Interpolation via Generalized Deformable Convolution\",\"url\":\"https://www.semanticscholar.org/paper/adc89874c2b2546850dcc1394c663fe22c3b4f6b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8107818\",\"name\":\"K. Purohit\"},{\"authorId\":\"1400414483\",\"name\":\"Maitreya Suin\"},{\"authorId\":\"51238264\",\"name\":\"P. Kandula\"},{\"authorId\":\"1938782\",\"name\":\"Rajagopalan Ambasamudram\"}],\"doi\":\"10.1109/ICCVW.2019.00424\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"595e429b7a9c11b73cceaedf2780d823830a044c\",\"title\":\"Depth-Guided Dense Dynamic Filtering Network for Bokeh Effect Rendering\",\"url\":\"https://www.semanticscholar.org/paper/595e429b7a9c11b73cceaedf2780d823830a044c\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"2008.04694\",\"authors\":[{\"authorId\":\"145906067\",\"name\":\"Y. Chen\"},{\"authorId\":\"92493482\",\"name\":\"M. Alain\"},{\"authorId\":\"52610836\",\"name\":\"A. Smoli\\u0107\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e1ffdd5804d9198180610fd2043a8301092ffa4b\",\"title\":\"A Study of Efficient Light Field Subsampling and Reconstruction Strategies\",\"url\":\"https://www.semanticscholar.org/paper/e1ffdd5804d9198180610fd2043a8301092ffa4b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46489265\",\"name\":\"Yu-Ying Yeh\"},{\"authorId\":\"1614039983\",\"name\":\"Y. Liu\"},{\"authorId\":\"37811787\",\"name\":\"Wei-Chen Chiu\"},{\"authorId\":null,\"name\":\"Yu-Chiang Frank Wang\"}],\"doi\":\"10.1109/TETCI.2020.2968599\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d96db0e2164f464ef9dc5dd030672ea3e3c02d57\",\"title\":\"Static2Dynamic: Video Inference From a Deep Glimpse\",\"url\":\"https://www.semanticscholar.org/paper/d96db0e2164f464ef9dc5dd030672ea3e3c02d57\",\"venue\":\"IEEE Transactions on Emerging Topics in Computational Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"77537461\",\"name\":\"J. K. Lee\"},{\"authorId\":null,\"name\":\"kim na young\"},{\"authorId\":\"153041302\",\"name\":\"Jewon Kang\"}],\"doi\":\"10.5909/JBE.2018.23.5.718\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"05111030e09d825244ee18e855b1d0888c649d72\",\"title\":\"Deep Learning based Inter Prediction Technique for Video Coding\",\"url\":\"https://www.semanticscholar.org/paper/05111030e09d825244ee18e855b1d0888c649d72\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11242144\",\"name\":\"Satoshi Yamanaka\"},{\"authorId\":\"2414439\",\"name\":\"Chonho Lee\"},{\"authorId\":\"1940550\",\"name\":\"S. Date\"}],\"doi\":\"10.1109/CSCI49370.2019.00121\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e47b6ab786002ab64ecf73f779d99fee93abeb54\",\"title\":\"A Parallel LSTM-Based Missing Body Feature Point Completion in Video Frames\",\"url\":\"https://www.semanticscholar.org/paper/e47b6ab786002ab64ecf73f779d99fee93abeb54\",\"venue\":\"2019 International Conference on Computational Science and Computational Intelligence (CSCI)\",\"year\":2019},{\"arxivId\":\"1811.11745\",\"authors\":[{\"authorId\":\"145661449\",\"name\":\"T. Brooks\"},{\"authorId\":\"50329510\",\"name\":\"J. Barron\"}],\"doi\":\"10.1109/CVPR.2019.00700\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c945dfec0137bcd7886898fa61f46705e00173dc\",\"title\":\"Learning to Synthesize Motion Blur\",\"url\":\"https://www.semanticscholar.org/paper/c945dfec0137bcd7886898fa61f46705e00173dc\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2011.06294\",\"authors\":[{\"authorId\":\"14042304\",\"name\":\"Zhewei Huang\"},{\"authorId\":\"123437116\",\"name\":\"Tianyuan Zhang\"},{\"authorId\":\"145577184\",\"name\":\"Wen Heng\"},{\"authorId\":\"151485124\",\"name\":\"Boxin Shi\"},{\"authorId\":\"35132667\",\"name\":\"Shuchang Zhou\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"62282171ef5ea9fa6dd5be80874336f04cfb6939\",\"title\":\"RIFE: Real-Time Intermediate Flow Estimation for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/62282171ef5ea9fa6dd5be80874336f04cfb6939\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1904.03567\",\"authors\":[{\"authorId\":\"10634370\",\"name\":\"S. Ma\"},{\"authorId\":\"3175853\",\"name\":\"Xinfeng Zhang\"},{\"authorId\":\"3366824\",\"name\":\"Chuanmin Jia\"},{\"authorId\":\"48633955\",\"name\":\"Zhenghui Zhao\"},{\"authorId\":\"1705047\",\"name\":\"S. Wang\"},{\"authorId\":\"1755176\",\"name\":\"Shanshe Wang\"}],\"doi\":\"10.1109/TCSVT.2019.2910119\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9458cd20bca3feb339085ce7d808bb32bb000b83\",\"title\":\"Image and Video Compression With Neural Networks: A Review\",\"url\":\"https://www.semanticscholar.org/paper/9458cd20bca3feb339085ce7d808bb32bb000b83\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"2002.03500\",\"authors\":[{\"authorId\":\"49259808\",\"name\":\"Q. Guo\"},{\"authorId\":\"1389940060\",\"name\":\"Felix Juefei-Xu\"},{\"authorId\":\"49419199\",\"name\":\"Xiaofei Xie\"},{\"authorId\":\"143828252\",\"name\":\"L. Ma\"},{\"authorId\":null,\"name\":\"Jian Wang\"},{\"authorId\":\"1485043101\",\"name\":\"Bing Yu\"},{\"authorId\":\"1409949029\",\"name\":\"W. Feng\"},{\"authorId\":\"38057121\",\"name\":\"Yang Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"62fc847ae50b004c114ce7f44861331fdce37e79\",\"title\":\"Watch out! Motion is Blurring the Vision of Your Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/62fc847ae50b004c114ce7f44861331fdce37e79\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37310105\",\"name\":\"L. Zhao\"},{\"authorId\":\"1705047\",\"name\":\"S. Wang\"},{\"authorId\":\"3175853\",\"name\":\"Xinfeng Zhang\"},{\"authorId\":\"1755176\",\"name\":\"Shanshe Wang\"},{\"authorId\":\"10634370\",\"name\":\"S. Ma\"},{\"authorId\":\"48385803\",\"name\":\"W. Gao\"}],\"doi\":\"10.1109/ICIP.2018.8451465\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5ceb6240f266c2c1ab7aaef9c89f228b328b1c1a\",\"title\":\"Enhanced Ctu-Level Inter Prediction with Deep Frame Rate Up-Conversion for High Efficiency Video Coding\",\"url\":\"https://www.semanticscholar.org/paper/5ceb6240f266c2c1ab7aaef9c89f228b328b1c1a\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":\"2002.03500\",\"authors\":[{\"authorId\":\"49259808\",\"name\":\"Q. Guo\"},{\"authorId\":\"1389940060\",\"name\":\"Felix Juefei-Xu\"},{\"authorId\":\"49419199\",\"name\":\"Xiaofei Xie\"},{\"authorId\":\"143828252\",\"name\":\"L. Ma\"},{\"authorId\":\"50814744\",\"name\":\"J. Wang\"},{\"authorId\":\"1409949029\",\"name\":\"W. Feng\"},{\"authorId\":\"40457423\",\"name\":\"Y. Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7e597736f1209a358c13c1d432883b6b4f720c0b\",\"title\":\"ABBA: Saliency-Regularized Motion-Based Adversarial Blur Attack\",\"url\":\"https://www.semanticscholar.org/paper/7e597736f1209a358c13c1d432883b6b4f720c0b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8080821\",\"name\":\"Megha Nawhal\"},{\"authorId\":\"2453402\",\"name\":\"Meng-Yao Zhai\"},{\"authorId\":\"20812150\",\"name\":\"Andreas M. Lehrmann\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"53ea5e0448c309c3614bba25bac58f46f06690c7\",\"title\":\"Zero-Shot Generation of Human-Object Interaction Videos\",\"url\":\"https://www.semanticscholar.org/paper/53ea5e0448c309c3614bba25bac58f46f06690c7\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1802.08091\",\"authors\":[{\"authorId\":\"145631934\",\"name\":\"M. Wang\"},{\"authorId\":\"35912331\",\"name\":\"G. Yang\"},{\"authorId\":\"40370556\",\"name\":\"Jin-Kun Lin\"},{\"authorId\":\"2947946\",\"name\":\"Ariel Shamir\"},{\"authorId\":\"7671691\",\"name\":\"Song-Hai Zhang\"},{\"authorId\":\"144918349\",\"name\":\"Shao-Ping Lu\"},{\"authorId\":\"145140922\",\"name\":\"S. Hu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fa2d3996a0095eef90f8e0fcec7ab3b4ba63cd3f\",\"title\":\"Deep Online Video Stabilization\",\"url\":\"https://www.semanticscholar.org/paper/fa2d3996a0095eef90f8e0fcec7ab3b4ba63cd3f\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1908.03826\",\"authors\":[{\"authorId\":\"47133874\",\"name\":\"Orest Kupyn\"},{\"authorId\":\"101029400\",\"name\":\"Tetiana Martyniuk\"},{\"authorId\":\"14737712\",\"name\":\"Junru Wu\"},{\"authorId\":\"2969311\",\"name\":\"Zhangyang Wang\"}],\"doi\":\"10.1109/ICCV.2019.00897\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"81c1dc00b32d12edfab00656593f5db56cfa79e0\",\"title\":\"DeblurGAN-v2: Deblurring (Orders-of-Magnitude) Faster and Better\",\"url\":\"https://www.semanticscholar.org/paper/81c1dc00b32d12edfab00656593f5db56cfa79e0\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39866194\",\"name\":\"Meiguang Jin\"},{\"authorId\":\"144869275\",\"name\":\"Zhe Hu\"},{\"authorId\":\"144707901\",\"name\":\"P. Favaro\"}],\"doi\":\"10.1109/CVPR.2019.00830\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9e9e9da2cd3f4946570d19891a108a02b93611ad\",\"title\":\"Learning to Extract Flawless Slow Motion From Blurry Videos\",\"url\":\"https://www.semanticscholar.org/paper/9e9e9da2cd3f4946570d19891a108a02b93611ad\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1906.09683\",\"authors\":[{\"authorId\":\"71418271\",\"name\":\"Z. Cheng\"},{\"authorId\":\"3294614\",\"name\":\"H. Sun\"},{\"authorId\":\"1719455\",\"name\":\"M. Takeuchi\"},{\"authorId\":\"1788294\",\"name\":\"J. Katto\"}],\"doi\":\"10.1109/CVPR.2019.01031\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7d29e102bda996bb648faa31c72ac725a0db5773\",\"title\":\"Learning Image and Video Compression Through Spatial-Temporal Energy Compaction\",\"url\":\"https://www.semanticscholar.org/paper/7d29e102bda996bb648faa31c72ac725a0db5773\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2243964\",\"name\":\"C. Li\"},{\"authorId\":\"51210542\",\"name\":\"Donghao Gu\"},{\"authorId\":\"50088361\",\"name\":\"X. Ma\"},{\"authorId\":\"145164031\",\"name\":\"Kai Yang\"},{\"authorId\":\"1743348\",\"name\":\"S. Liu\"},{\"authorId\":\"144999037\",\"name\":\"Feng Jiang\"}],\"doi\":\"10.1109/DSC.2018.00089\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"26575ad9e75efb440a7dc4ef8e548eed4e19dbd1\",\"title\":\"Video Frame Interpolation Based on Multi-scale Convolutional Network and Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/26575ad9e75efb440a7dc4ef8e548eed4e19dbd1\",\"venue\":\"2018 IEEE Third International Conference on Data Science in Cyberspace (DSC)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143668549\",\"name\":\"Y. Tanaka\"},{\"authorId\":\"144943482\",\"name\":\"Toshiaki Omori\"}],\"doi\":\"10.1145/3325773.3325777\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"37cbb412eac2eef8243facaabcdf85de85544e53\",\"title\":\"Spatio-Temporal Convolutional Neural Network for Frame Rate Up-Conversion\",\"url\":\"https://www.semanticscholar.org/paper/37cbb412eac2eef8243facaabcdf85de85544e53\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2011.10974\",\"authors\":[{\"authorId\":\"39431125\",\"name\":\"Shuyang Gu\"},{\"authorId\":\"9324504\",\"name\":\"Jian-min Bao\"},{\"authorId\":\"2013406166\",\"name\":\"Dong Chen\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"906c0c47fea0842a6dc5d1301c916eae025a2d90\",\"title\":\"Learnable Sampling 3D Convolution for Video Enhancement and Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/906c0c47fea0842a6dc5d1301c916eae025a2d90\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134888279\",\"name\":\"Yung-Han Ho\"},{\"authorId\":\"1381649479\",\"name\":\"Chuan-Yuan Cho\"},{\"authorId\":\"51259830\",\"name\":\"Guo-Lun Jin\"},{\"authorId\":\"1749122\",\"name\":\"Wen-Hsiao Peng\"}],\"doi\":\"10.1109/ICCV.2019.01056\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ffc7c3ac48bdff347fd48404fc867a877c156b3b\",\"title\":\"SME-Net: Sparse Motion Estimation for Parametric Video Prediction Through Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/ffc7c3ac48bdff347fd48404fc867a877c156b3b\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153269936\",\"name\":\"J. Xiao\"},{\"authorId\":\"49997317\",\"name\":\"Xiaojun Bi\"}],\"doi\":\"10.1109/ACCESS.2020.2995705\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"da8b5876438d5c7f4caf6cfabc4252e0863dac8b\",\"title\":\"Multi-Scale Attention Generative Adversarial Networks for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/da8b5876438d5c7f4caf6cfabc4252e0863dac8b\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10755743\",\"name\":\"Takayuki Nakatsuka\"},{\"authorId\":\"2844427\",\"name\":\"M. Hamanaka\"},{\"authorId\":\"1490867805\",\"name\":\"Shigeo Morishima\"}],\"doi\":\"10.5220/0008876600270035\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6c1de74772253f4b9ebb4ea86b1602fa1445786f\",\"title\":\"Audio-guided Video Interpolation via Human Pose Features\",\"url\":\"https://www.semanticscholar.org/paper/6c1de74772253f4b9ebb4ea86b1602fa1445786f\",\"venue\":\"VISIGRAPP\",\"year\":2020},{\"arxivId\":\"1904.05065\",\"authors\":[{\"authorId\":\"7523259\",\"name\":\"Shangchen Zhou\"},{\"authorId\":\"145345506\",\"name\":\"J. Zhang\"},{\"authorId\":\"1724520\",\"name\":\"W. Zuo\"},{\"authorId\":\"3451627\",\"name\":\"Haozhe Xie\"},{\"authorId\":\"9416881\",\"name\":\"J. Pan\"},{\"authorId\":\"145335572\",\"name\":\"J. Ren\"}],\"doi\":\"10.1109/CVPR.2019.01125\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"902d00fc7296b2372e48e337c84c80dfa0b021dd\",\"title\":\"DAVANet: Stereo Deblurring With View Aggregation\",\"url\":\"https://www.semanticscholar.org/paper/902d00fc7296b2372e48e337c84c80dfa0b021dd\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1912.04950\",\"authors\":[{\"authorId\":\"34246012\",\"name\":\"Ryan Szeto\"},{\"authorId\":\"1382637019\",\"name\":\"Mostafa El-Khamy\"},{\"authorId\":\"35462690\",\"name\":\"Jungwon Lee\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d52448d649ce5d35189abdeecdc62db647b4246\",\"title\":\"HyperCon: Image-To-Video Model Transfer for Video-To-Video Translation Tasks\",\"url\":\"https://www.semanticscholar.org/paper/0d52448d649ce5d35189abdeecdc62db647b4246\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1904.12257\",\"authors\":[{\"authorId\":\"7523259\",\"name\":\"Shangchen Zhou\"},{\"authorId\":\"145345506\",\"name\":\"J. Zhang\"},{\"authorId\":\"9416881\",\"name\":\"J. Pan\"},{\"authorId\":\"3451627\",\"name\":\"Haozhe Xie\"},{\"authorId\":\"1724520\",\"name\":\"W. Zuo\"},{\"authorId\":\"46606038\",\"name\":\"Jimmy Ren\"}],\"doi\":\"10.1109/ICCV.2019.00257\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a2227f3eeeb7d588b5647a4d599e69c154c66a73\",\"title\":\"Spatio-Temporal Filter Adaptive Network for Video Deblurring\",\"url\":\"https://www.semanticscholar.org/paper/a2227f3eeeb7d588b5647a4d599e69c154c66a73\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1711.09078\",\"authors\":[{\"authorId\":\"3222730\",\"name\":\"Tianfan Xue\"},{\"authorId\":\"5114023\",\"name\":\"B. Chen\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"1766333\",\"name\":\"D. Wei\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"}],\"doi\":\"10.1007/s11263-018-01144-2\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c1045435c208a20f65b79baaa2d79783c2409c09\",\"title\":\"Video Enhancement with Task-Oriented Flow\",\"url\":\"https://www.semanticscholar.org/paper/c1045435c208a20f65b79baaa2d79783c2409c09\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018},{\"arxivId\":\"2012.06131\",\"authors\":[{\"authorId\":\"1503438566\",\"name\":\"Xin Li\"},{\"authorId\":\"145746387\",\"name\":\"Xin Jin\"},{\"authorId\":\"152278376\",\"name\":\"Tao Yu\"},{\"authorId\":\"1423588674\",\"name\":\"Yingxue Pang\"},{\"authorId\":\"23134878\",\"name\":\"Simeng Sun\"},{\"authorId\":\"1486397342\",\"name\":\"Zhizheng Zhang\"},{\"authorId\":\"143912275\",\"name\":\"Zhibo Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"36fac56c02597f9ea7c9c05419fd7a7109de1056\",\"title\":\"Learning Omni-frequency Region-adaptive Representations for Real Image Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/36fac56c02597f9ea7c9c05419fd7a7109de1056\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1711.06045\",\"authors\":[{\"authorId\":\"3038326\",\"name\":\"Joost R. van Amersfoort\"},{\"authorId\":\"2700496\",\"name\":\"W. Shi\"},{\"authorId\":\"145987822\",\"name\":\"A. Acosta\"},{\"authorId\":\"35163474\",\"name\":\"Francisco Massa\"},{\"authorId\":\"1853456\",\"name\":\"J. Totz\"},{\"authorId\":\"34627233\",\"name\":\"Zehan Wang\"},{\"authorId\":\"145372820\",\"name\":\"J. Caballero\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"8d6569a94dd0a2446bfdbc4e026d69a0eb69743f\",\"title\":\"Frame Interpolation with Multi-Scale Deep Loss Functions and Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/8d6569a94dd0a2446bfdbc4e026d69a0eb69743f\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150358901\",\"name\":\"Zhifeng Zhang\"},{\"authorId\":\"1391025682\",\"name\":\"L. Song\"},{\"authorId\":\"1381430536\",\"name\":\"Rang Xie\"},{\"authorId\":\"144423422\",\"name\":\"L. Chen\"}],\"doi\":\"10.1109/BigMM.2018.8499065\",\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"c81bd3c7d9949daeba47f87dd439c48d8f1fdd19\",\"title\":\"Video Frame Interpolation Using Recurrent Convolutional Layers\",\"url\":\"https://www.semanticscholar.org/paper/c81bd3c7d9949daeba47f87dd439c48d8f1fdd19\",\"venue\":\"2018 IEEE Fourth International Conference on Multimedia Big Data (BigMM)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143792910\",\"name\":\"Yuan Gao\"},{\"authorId\":\"144839904\",\"name\":\"R. Koch\"}],\"doi\":\"10.1109/ICMEW.2018.8551583\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0fb770c1ca849e2f4762bbd98330939ab6f880f6\",\"title\":\"Parallax View Generation for Static Scenes Using Parallax-Interpolation Adaptive Separable Convolution\",\"url\":\"https://www.semanticscholar.org/paper/0fb770c1ca849e2f4762bbd98330939ab6f880f6\",\"venue\":\"2018 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72551720\",\"name\":\"Hyeonjun Sim\"},{\"authorId\":\"144366095\",\"name\":\"M. Kim\"}],\"doi\":\"10.1109/CVPRW.2019.00267\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d4dafcd3e0b03f68f8f031ea1bbc02d0d31b59d2\",\"title\":\"A Deep Motion Deblurring Network Based on Per-Pixel Adaptive Kernels With Residual Down-Up and Up-Down Modules\",\"url\":\"https://www.semanticscholar.org/paper/d4dafcd3e0b03f68f8f031ea1bbc02d0d31b59d2\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49404171\",\"name\":\"Haopeng Li\"},{\"authorId\":\"153197501\",\"name\":\"Yuan Yuan\"},{\"authorId\":\"50621207\",\"name\":\"Q. Wang\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053987\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"23c9b2b3d315dd81563f57bbec8fda28d53700a6\",\"title\":\"Video Frame Interpolation Via Residue Refinement\",\"url\":\"https://www.semanticscholar.org/paper/23c9b2b3d315dd81563f57bbec8fda28d53700a6\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2844849\",\"name\":\"Richard Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f9f86d087e84eaf0e6a09575982aa7b41fa62451\",\"title\":\"Image Synthesis for Self-Supervised Visual Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/f9f86d087e84eaf0e6a09575982aa7b41fa62451\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1712.02874\",\"authors\":[{\"authorId\":\"144869276\",\"name\":\"Zhe Hu\"},{\"authorId\":\"2191237\",\"name\":\"Y. Ma\"},{\"authorId\":\"8452947\",\"name\":\"L. Ma\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"bd60560a8e2e97e90a6a26e350f75ba7263966c8\",\"title\":\"Multi-Scale Video Frame-Synthesis Network with Transitive Consistency Loss\",\"url\":\"https://www.semanticscholar.org/paper/bd60560a8e2e97e90a6a26e350f75ba7263966c8\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32168317\",\"name\":\"Neerav Karani\"},{\"authorId\":\"40062416\",\"name\":\"L. Zhang\"},{\"authorId\":\"145057506\",\"name\":\"C. Tanner\"},{\"authorId\":\"1796918\",\"name\":\"E. Konukoglu\"}],\"doi\":\"10.1016/j.media.2019.02.008\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9358edc050f8df0d86c93e43a0a9bd532bd6bda6\",\"title\":\"An image interpolation approach for acquisition time reduction in navigator\\u2010based 4D MRI\",\"url\":\"https://www.semanticscholar.org/paper/9358edc050f8df0d86c93e43a0a9bd532bd6bda6\",\"venue\":\"Medical Image Anal.\",\"year\":2019},{\"arxivId\":\"1910.01089\",\"authors\":[{\"authorId\":\"88677858\",\"name\":\"Juan Luis Gonzalez Bello\"},{\"authorId\":\"123446757\",\"name\":\"M. Kim\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"bfee48cc26b52e166e545d611e4df4ec851163b8\",\"title\":\"Deep 3D Pan via adaptive \\\"t-shaped\\\" convolutions with global and local adaptive dilations\",\"url\":\"https://www.semanticscholar.org/paper/bfee48cc26b52e166e545d611e4df4ec851163b8\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150311567\",\"name\":\"Songhyun Yu\"},{\"authorId\":\"93299623\",\"name\":\"Bumjun Park\"},{\"authorId\":\"1557273080\",\"name\":\"Jechang Jeong\"}],\"doi\":\"10.1109/ICCVW.2019.00434\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5981bb0678578dcf75536bdc476a38a7e501a301\",\"title\":\"PoSNet: 4x Video Frame Interpolation Using Position-Specific Flow\",\"url\":\"https://www.semanticscholar.org/paper/5981bb0678578dcf75536bdc476a38a7e501a301\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1804.01523\",\"authors\":[{\"authorId\":\"49250083\",\"name\":\"Alex X. Lee\"},{\"authorId\":\"2844849\",\"name\":\"Richard Zhang\"},{\"authorId\":\"27535721\",\"name\":\"Frederik Ebert\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"},{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9f67271a1edea3bf80c64c2d54e2a0a57612a567\",\"title\":\"Stochastic Adversarial Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/9f67271a1edea3bf80c64c2d54e2a0a57612a567\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3035324\",\"name\":\"Tomer Peleg\"},{\"authorId\":\"15589668\",\"name\":\"P. Szekely\"},{\"authorId\":\"40462685\",\"name\":\"Doron Sabo\"},{\"authorId\":\"3059895\",\"name\":\"O. Sendik\"}],\"doi\":\"10.1109/CVPR.2019.00250\",\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"089f2072c95c244f3b7f4df404562bb4afe24448\",\"title\":\"IM-Net for High Resolution Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/089f2072c95c244f3b7f4df404562bb4afe24448\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yanru Wang\"},{\"authorId\":\"144616958\",\"name\":\"Zhihao Huang\"},{\"authorId\":\"145153297\",\"name\":\"Hao Zhu\"},{\"authorId\":\"48625282\",\"name\":\"Wei-peng Li\"},{\"authorId\":\"2001120\",\"name\":\"Xun Cao\"},{\"authorId\":\"38958903\",\"name\":\"Ruigang Yang\"}],\"doi\":\"10.1016/j.vrih.2020.04.004\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c40e16d81def08d8f9f789acb3f681165fedc78a\",\"title\":\"Interactive free-viewpoint video generation\",\"url\":\"https://www.semanticscholar.org/paper/c40e16d81def08d8f9f789acb3f681165fedc78a\",\"venue\":\"Virtual Real. Intell. Hardw.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46221860\",\"name\":\"Shreyank Jyoti\"},{\"authorId\":\"144984131\",\"name\":\"G. Sharma\"},{\"authorId\":\"1735697\",\"name\":\"Abhinav Dhall\"}],\"doi\":\"10.1109/DICTA.2018.8615852\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"924ba14f62e3c8da005082401625b3f71587198a\",\"title\":\"A Single Hierarchical Network for Face, Action Unit and Emotion Detection\",\"url\":\"https://www.semanticscholar.org/paper/924ba14f62e3c8da005082401625b3f71587198a\",\"venue\":\"2018 Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"101736874\",\"name\":\"Ignacio Reimat Corbella\"},{\"authorId\":\"1693381468\",\"name\":\"Irene Viola\"},{\"authorId\":\"1665018544\",\"name\":\"Pablo C\\u00e9sar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ce84cb3209c0da9a250d64a78d91b937add0e84f\",\"title\":\"Temporal Interpolation of human point clouds using neural networks and body part segmentation\",\"url\":\"https://www.semanticscholar.org/paper/ce84cb3209c0da9a250d64a78d91b937add0e84f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150358901\",\"name\":\"Zhifeng Zhang\"},{\"authorId\":\"144423422\",\"name\":\"L. Chen\"},{\"authorId\":\"1773394\",\"name\":\"Rong Xie\"},{\"authorId\":\"1391025682\",\"name\":\"L. Song\"}],\"doi\":\"10.1109/ICIP.2018.8451847\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0e3935a84c68cf4ddd696e09e56a2689a10957da\",\"title\":\"Frame Interpolation via Refined Deep Voxel Flow\",\"url\":\"https://www.semanticscholar.org/paper/0e3935a84c68cf4ddd696e09e56a2689a10957da\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1474216945\",\"name\":\"Xiuxiu Jing\"},{\"authorId\":\"3193532\",\"name\":\"Yike Ma\"},{\"authorId\":\"144251709\",\"name\":\"Q. Zhao\"},{\"authorId\":\"8196181\",\"name\":\"Ke Lyu\"},{\"authorId\":\"152130996\",\"name\":\"F. Dai\"}],\"doi\":\"10.1007/978-3-030-37731-1_1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a9574281a05d8221e600bbf7645d79a93e79fd0c\",\"title\":\"Light Field Reconstruction Using Dynamically Generated Filters\",\"url\":\"https://www.semanticscholar.org/paper/a9574281a05d8221e600bbf7645d79a93e79fd0c\",\"venue\":\"MMM\",\"year\":2020},{\"arxivId\":\"1802.02226\",\"authors\":[{\"authorId\":\"145289907\",\"name\":\"Nhat M. Nguyen\"},{\"authorId\":\"1772846\",\"name\":\"N. Ray\"}],\"doi\":\"10.1109/CRV.2019.00025\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"adec52d80810ab9d7000325f6dac675fc2d07631\",\"title\":\"Generative Adversarial Networks Using Adaptive Convolution\",\"url\":\"https://www.semanticscholar.org/paper/adec52d80810ab9d7000325f6dac675fc2d07631\",\"venue\":\"2019 16th Conference on Computer and Robot Vision (CRV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1914700964\",\"name\":\"Shurui Gui\"},{\"authorId\":\"1409848027\",\"name\":\"Chaoyue Wang\"},{\"authorId\":\"47261253\",\"name\":\"Q. Chen\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/cvpr42600.2020.01402\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"48d49e5e85a5659853f8ad2f31e05b8ba81866e2\",\"title\":\"FeatureFlow: Robust Video Interpolation via Structure-to-Texture Generation\",\"url\":\"https://www.semanticscholar.org/paper/48d49e5e85a5659853f8ad2f31e05b8ba81866e2\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2007.08336\",\"authors\":[{\"authorId\":\"14630719\",\"name\":\"Bishan Wang\"},{\"authorId\":\"47752316\",\"name\":\"Jingwei He\"},{\"authorId\":\"49296869\",\"name\":\"L. Yu\"},{\"authorId\":\"51280933\",\"name\":\"G. Xia\"},{\"authorId\":\"49230398\",\"name\":\"Wen Yang\"}],\"doi\":\"10.1007/978-3-030-58601-0_10\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bfd62b88ca037f8d59f1b3efe3dc74dea1b433aa\",\"title\":\"Event Enhanced High-Quality Image Recovery\",\"url\":\"https://www.semanticscholar.org/paper/bfd62b88ca037f8d59f1b3efe3dc74dea1b433aa\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2318546\",\"name\":\"Shiping Wen\"},{\"authorId\":\"49663634\",\"name\":\"W. Liu\"},{\"authorId\":\"46286125\",\"name\":\"Y. Yang\"},{\"authorId\":\"145582475\",\"name\":\"T. Huang\"},{\"authorId\":\"145043786\",\"name\":\"Z. Zeng\"}],\"doi\":\"10.1109/TCSVT.2018.2867934\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"84e5e611baa362ccce571eef737c98de7a5331b5\",\"title\":\"Generating Realistic Videos From Keyframes With Concatenated GANs\",\"url\":\"https://www.semanticscholar.org/paper/84e5e611baa362ccce571eef737c98de7a5331b5\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":\"1804.04440\",\"authors\":[{\"authorId\":\"47058844\",\"name\":\"Lin Zhang\"},{\"authorId\":\"32168317\",\"name\":\"Neerav Karani\"},{\"authorId\":\"145057506\",\"name\":\"C. Tanner\"},{\"authorId\":\"1796918\",\"name\":\"E. Konukoglu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0e7eb94ae7311ec9d8d0c8b75c6d675ec8d7e16b\",\"title\":\"Temporal Interpolation via Motion Field Prediction\",\"url\":\"https://www.semanticscholar.org/paper/0e7eb94ae7311ec9d8d0c8b75c6d675ec8d7e16b\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2004.02215\",\"authors\":[{\"authorId\":\"1500385929\",\"name\":\"Jing Jin\"},{\"authorId\":\"40630305\",\"name\":\"J. Hou\"},{\"authorId\":\"49252457\",\"name\":\"J. Chen\"},{\"authorId\":\"1687386\",\"name\":\"S. Kwong\"}],\"doi\":\"10.1109/cvpr42600.2020.00233\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1e56f7717c7dcf49928e1ccc2c74dfd9f7308e0b\",\"title\":\"Light Field Spatial Super-Resolution via Deep Combinatorial Geometry Embedding and Structural Consistency Regularization\",\"url\":\"https://www.semanticscholar.org/paper/1e56f7717c7dcf49928e1ccc2c74dfd9f7308e0b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2002.11616\",\"authors\":[{\"authorId\":\"48147750\",\"name\":\"Xiaoyu Xiang\"},{\"authorId\":\"34777509\",\"name\":\"Yapeng Tian\"},{\"authorId\":\"2410227\",\"name\":\"Yulun Zhang\"},{\"authorId\":\"144015161\",\"name\":\"Y. Fu\"},{\"authorId\":\"1741931\",\"name\":\"J. Allebach\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":\"10.1109/cvpr42600.2020.00343\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a140ca6ac4847c13219bf9f4401153ad53fce71e\",\"title\":\"Zooming Slow-Mo: Fast and Accurate One-Stage Space-Time Video Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/a140ca6ac4847c13219bf9f4401153ad53fce71e\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1811.00684\",\"authors\":[{\"authorId\":\"3291967\",\"name\":\"F. Reda\"},{\"authorId\":\"2457939\",\"name\":\"Guilin Liu\"},{\"authorId\":\"143953573\",\"name\":\"K. Shih\"},{\"authorId\":\"144391743\",\"name\":\"R. Kirby\"},{\"authorId\":\"32406400\",\"name\":\"J. Barker\"},{\"authorId\":\"2924393\",\"name\":\"D. Tarjan\"},{\"authorId\":\"29955511\",\"name\":\"A. Tao\"},{\"authorId\":\"2301680\",\"name\":\"Bryan Catanzaro\"}],\"doi\":\"10.1007/978-3-030-01234-2_44\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c165003060eeb01e05800a5ee4cd327f1e0bf5e3\",\"title\":\"SDC-Net: Video Prediction Using Spatially-Displaced Convolution\",\"url\":\"https://www.semanticscholar.org/paper/c165003060eeb01e05800a5ee4cd327f1e0bf5e3\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2004.11076\",\"authors\":[{\"authorId\":\"15678386\",\"name\":\"Z. Wang\"},{\"authorId\":\"49461394\",\"name\":\"Guoqing Li\"},{\"authorId\":\"46772427\",\"name\":\"X. Chen\"},{\"authorId\":\"78711732\",\"name\":\"H. Han\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"74c7f393a7596c9b55b4fa5a2a73a32e3ce4b687\",\"title\":\"DAN: A Deformation-Aware Network for Consecutive Biomedical Image Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/74c7f393a7596c9b55b4fa5a2a73a32e3ce4b687\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2744923\",\"name\":\"L. Zhou\"},{\"authorId\":\"2573672\",\"name\":\"Yaowu Chen\"},{\"authorId\":\"2512006\",\"name\":\"Xiang Tian\"},{\"authorId\":\"3115947\",\"name\":\"Rongxin Jiang\"}],\"doi\":\"10.1117/1.JEI.28.4.043002\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"579c0f9efe9932469f036bdf10c333455c2b3bd5\",\"title\":\"Multiframe interpolation for video using phase features\",\"url\":\"https://www.semanticscholar.org/paper/579c0f9efe9932469f036bdf10c333455c2b3bd5\",\"venue\":\"J. Electronic Imaging\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48915513\",\"name\":\"P. Johnston\"},{\"authorId\":\"1807106\",\"name\":\"Eyad Elyan\"}],\"doi\":\"10.1016/J.DIIN.2019.03.006\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cd5080bc7bc45a40ed55b3f3c809dbba44698a5d\",\"title\":\"A review of digital video tampering: From simple editing to full synthesis\",\"url\":\"https://www.semanticscholar.org/paper/cd5080bc7bc45a40ed55b3f3c809dbba44698a5d\",\"venue\":\"Digit. Investig.\",\"year\":2019},{\"arxivId\":\"1804.02684\",\"authors\":[{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"2984787\",\"name\":\"Ronnachai Jaroensri\"},{\"authorId\":\"9340074\",\"name\":\"Changil Kim\"},{\"authorId\":\"1854465\",\"name\":\"M. Elgharib\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"},{\"authorId\":\"1752521\",\"name\":\"W. Matusik\"}],\"doi\":\"10.1007/978-3-030-01225-0_39\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"07b8da845ff5b23428ad98307bb2d703d96eb337\",\"title\":\"Learning-based Video Motion Magnification\",\"url\":\"https://www.semanticscholar.org/paper/07b8da845ff5b23428ad98307bb2d703d96eb337\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2004.00779\",\"authors\":[{\"authorId\":\"83500873\",\"name\":\"Myungsub Choi\"},{\"authorId\":\"9535762\",\"name\":\"Janghoon Choi\"},{\"authorId\":\"148009160\",\"name\":\"Sungyong Baik\"},{\"authorId\":\"40592441\",\"name\":\"T. Kim\"},{\"authorId\":\"2135837\",\"name\":\"Kyoung Mu Lee\"}],\"doi\":\"10.1109/cvpr42600.2020.00946\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"45e87cea5afe99417ec48bd67555ce8a6213e8f8\",\"title\":\"Scene-Adaptive Video Frame Interpolation via Meta-Learning\",\"url\":\"https://www.semanticscholar.org/paper/45e87cea5afe99417ec48bd67555ce8a6213e8f8\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"89909440\",\"name\":\"Se\\u00e1n Bruton\"},{\"authorId\":\"89087926\",\"name\":\"D. Ganter\"},{\"authorId\":\"1790513\",\"name\":\"M. Manzke\"}],\"doi\":\"10.5220/0007407200960105\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"34ba8ce89e54bef43848e9487ff0982bdc4ff822\",\"title\":\"Synthesising Light Field Volumetric Visualizations in Real-time using a Compressed Volume Representation\",\"url\":\"https://www.semanticscholar.org/paper/34ba8ce89e54bef43848e9487ff0982bdc4ff822\",\"venue\":\"VISIGRAPP\",\"year\":2019},{\"arxivId\":\"1901.02840\",\"authors\":[{\"authorId\":\"2295608\",\"name\":\"Y. Wang\"},{\"authorId\":\"3119608\",\"name\":\"Haibin Huang\"},{\"authorId\":\"47074942\",\"name\":\"Chuan Wang\"},{\"authorId\":\"145633170\",\"name\":\"Tong He\"},{\"authorId\":\"48094509\",\"name\":\"J. Wang\"},{\"authorId\":\"2356016\",\"name\":\"Minh Hoai\"}],\"doi\":\"10.1109/CVPR.2019.00151\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"75ab4f41c28bddefbd997744617e3ec6e3b478dc\",\"title\":\"GIF2Video: Color Dequantization and Temporal Interpolation of GIF Images\",\"url\":\"https://www.semanticscholar.org/paper/75ab4f41c28bddefbd997744617e3ec6e3b478dc\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1912.04421\",\"authors\":[{\"authorId\":\"31384397\",\"name\":\"Zhihao Xia\"},{\"authorId\":\"2942259\",\"name\":\"Federico Perazzi\"},{\"authorId\":\"153348155\",\"name\":\"M. Gharbi\"},{\"authorId\":\"2454127\",\"name\":\"Kalyan Sunkavalli\"},{\"authorId\":\"38534744\",\"name\":\"A. Chakrabarti\"}],\"doi\":\"10.1109/cvpr42600.2020.01186\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"fa06a6dc92faf4b69e7905461aaa4baccb3d4cd2\",\"title\":\"Basis Prediction Networks for Effective Burst Denoising With Large Kernels\",\"url\":\"https://www.semanticscholar.org/paper/fa06a6dc92faf4b69e7905461aaa4baccb3d4cd2\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144489175\",\"name\":\"Y. Zhou\"},{\"authorId\":\"49544454\",\"name\":\"X. Liu\"},{\"authorId\":\"49330176\",\"name\":\"Lei Chen\"},{\"authorId\":\"1728718\",\"name\":\"Jiying Zhao\"}],\"doi\":\"10.1109/GLOBALSIP.2018.8646501\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c26fecf281ec14d3c6a06081eb5e1623c35560d3\",\"title\":\"Video Super-Resolution via Dynamic Local Filter Network\",\"url\":\"https://www.semanticscholar.org/paper/c26fecf281ec14d3c6a06081eb5e1623c35560d3\",\"venue\":\"2018 IEEE Global Conference on Signal and Information Processing (GlobalSIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49050685\",\"name\":\"N. Zeng\"},{\"authorId\":\"50579892\",\"name\":\"Y. Chen\"},{\"authorId\":\"66471163\",\"name\":\"Y. Gu\"},{\"authorId\":\"27630525\",\"name\":\"Dong-dong Liu\"},{\"authorId\":\"1430778430\",\"name\":\"Yunbing Xing\"}],\"doi\":\"10.1109/SMC42975.2020.9283193\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6aa69d640c39e28f36386dee39a3bfae7a2d042e\",\"title\":\"Highly Fluent Sign Language Synthesis Based on Variable Motion Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/6aa69d640c39e28f36386dee39a3bfae7a2d042e\",\"venue\":\"2020 IEEE International Conference on Systems, Man, and Cybernetics (SMC)\",\"year\":2020},{\"arxivId\":\"1907.10244\",\"authors\":[{\"authorId\":\"98080420\",\"name\":\"H. Lee\"},{\"authorId\":\"48271129\",\"name\":\"T. Kim\"},{\"authorId\":\"3191728\",\"name\":\"T. Chung\"},{\"authorId\":\"48322708\",\"name\":\"D. Pak\"},{\"authorId\":\"2417978\",\"name\":\"Yuseok Ban\"},{\"authorId\":\"39847092\",\"name\":\"Sangyoun Lee\"}],\"doi\":\"10.1109/cvpr42600.2020.00536\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"af480bfec4eb0a8182ad52c0d0699fb86da8609b\",\"title\":\"AdaCoF: Adaptive Collaboration of Flows for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/af480bfec4eb0a8182ad52c0d0699fb86da8609b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1657493720\",\"name\":\"Mengshun Hu\"},{\"authorId\":\"144326503\",\"name\":\"L. Liao\"},{\"authorId\":\"91353860\",\"name\":\"Jing Xiao\"},{\"authorId\":\"151484085\",\"name\":\"Lin Gu\"},{\"authorId\":\"144404414\",\"name\":\"S. Satoh\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053223\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6dd58d9765210b676ef07298470e227a077c160b\",\"title\":\"Motion Feedback Design for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/6dd58d9765210b676ef07298470e227a077c160b\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51210542\",\"name\":\"Donghao Gu\"},{\"authorId\":\"151270904\",\"name\":\"Zhaojing Wen\"},{\"authorId\":\"151483658\",\"name\":\"Wenxue Cui\"},{\"authorId\":\"39618906\",\"name\":\"Rui Wang\"},{\"authorId\":\"144999037\",\"name\":\"Feng Jiang\"},{\"authorId\":\"1743348\",\"name\":\"S. Liu\"}],\"doi\":\"10.1109/ICME.2019.00304\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"614abce0a5e2dcade4c34e903e3bb67329d7c3d8\",\"title\":\"Continuous Bidirectional Optical Flow for Video Frame Sequence Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/614abce0a5e2dcade4c34e903e3bb67329d7c3d8\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":\"2012.04515\",\"authors\":[{\"authorId\":\"2033380760\",\"name\":\"Omer Dahary\"},{\"authorId\":\"2033358084\",\"name\":\"Matan Jacoby\"},{\"authorId\":\"121014776\",\"name\":\"A. M. Bronstein\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3dddbce4a7ef4e8e84d176707ec564602b6f025a\",\"title\":\"Digital Gimbal: End-to-end Deep Image Stabilization with Learnable Exposure Times\",\"url\":\"https://www.semanticscholar.org/paper/3dddbce4a7ef4e8e84d176707ec564602b6f025a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1803.10967\",\"authors\":[{\"authorId\":\"39644974\",\"name\":\"Simon Niklaus\"},{\"authorId\":\"40405236\",\"name\":\"Feng Liu\"}],\"doi\":\"10.1109/CVPR.2018.00183\",\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":false,\"paperId\":\"65fadccad0fc743876a259c2b779622636c2ffde\",\"title\":\"Context-Aware Synthesis for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/65fadccad0fc743876a259c2b779622636c2ffde\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1911.00627\",\"authors\":[{\"authorId\":\"48669892\",\"name\":\"Xiangyu Xu\"},{\"authorId\":\"31060460\",\"name\":\"Li Si-Yao\"},{\"authorId\":\"8397576\",\"name\":\"Wenxiu Sun\"},{\"authorId\":\"123100665\",\"name\":\"Q. Yin\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6296ec34c6e792729ec47195727d2ab17d27a50e\",\"title\":\"Quadratic video interpolation\",\"url\":\"https://www.semanticscholar.org/paper/6296ec34c6e792729ec47195727d2ab17d27a50e\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"13515609\",\"name\":\"Shangshu Qian\"},{\"authorId\":\"50251852\",\"name\":\"Zhiling Zhou\"},{\"authorId\":\"50081012\",\"name\":\"S. Lai\"}],\"doi\":\"10.1109/GEOINFORMATICS.2018.8557169\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c8ab4fbcf1f32bc9a9f7d7957704853fed60b2bc\",\"title\":\"Frame Interpolation Using Deep Pyramid Flow\",\"url\":\"https://www.semanticscholar.org/paper/c8ab4fbcf1f32bc9a9f7d7957704853fed60b2bc\",\"venue\":\"2018 26th International Conference on Geoinformatics\",\"year\":2018},{\"arxivId\":\"1912.03445\",\"authors\":[{\"authorId\":\"119837762\",\"name\":\"Junru Wu\"},{\"authorId\":null,\"name\":\"Xiang Yu\"},{\"authorId\":\"1771885\",\"name\":\"Ding Liu\"},{\"authorId\":\"2099305\",\"name\":\"Manmohan Chandraker\"},{\"authorId\":\"2969311\",\"name\":\"Zhangyang Wang\"}],\"doi\":\"10.1109/WACV45572.2020.9093529\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4b745add3720480731b32846bbda03f954c3b8ae\",\"title\":\"DAVID: Dual-Attentional Video Deblurring\",\"url\":\"https://www.semanticscholar.org/paper/4b745add3720480731b32846bbda03f954c3b8ae\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1909.02641\",\"authors\":[{\"authorId\":\"49331178\",\"name\":\"Jinsoo Choi\"},{\"authorId\":\"98758720\",\"name\":\"I. Kweon\"}],\"doi\":\"10.1145/3363550\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c1d6d8458ba00395159871106a0665403a00cfe5\",\"title\":\"Deep Iterative Frame Interpolation for Full-frame Video Stabilization\",\"url\":\"https://www.semanticscholar.org/paper/c1d6d8458ba00395159871106a0665403a00cfe5\",\"venue\":\"ACM Trans. Graph.\",\"year\":2020},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9a8cbc4196622722c0f4c3d7119c7c2903525f7c\",\"title\":\"Input Route Reference Motion Set ... ... Reference 1 Reference 2 Reference N R Reference Motion Search Reference i New Style Motion Local Motion Composition Global Motion Composition\",\"url\":\"https://www.semanticscholar.org/paper/9a8cbc4196622722c0f4c3d7119c7c2903525f7c\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1804.06919\",\"authors\":[{\"authorId\":\"2978413\",\"name\":\"Chao-Yuan Wu\"},{\"authorId\":\"40943290\",\"name\":\"Nayan Singhal\"},{\"authorId\":\"2562966\",\"name\":\"Philipp Kr\\u00e4henb\\u00fchl\"}],\"doi\":\"10.1007/978-3-030-01237-3_26\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e2ab15c1f84a5a5080e06129daf7b22c8990411f\",\"title\":\"Video Compression through Image Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/e2ab15c1f84a5a5080e06129daf7b22c8990411f\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993383158\",\"name\":\"Zeyu Xiao\"},{\"authorId\":\"2352456\",\"name\":\"Z. Xiong\"},{\"authorId\":\"3061449\",\"name\":\"Xueyang Fu\"},{\"authorId\":\"153626238\",\"name\":\"D. Liu\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"}],\"doi\":\"10.1145/3394171.3413667\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"19b051580cb309ef990b77875d13ac7dd4e5950a\",\"title\":\"Space-Time Video Super-Resolution Using Temporal Profiles\",\"url\":\"https://www.semanticscholar.org/paper/19b051580cb309ef990b77875d13ac7dd4e5950a\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150258541\",\"name\":\"Paulino Cristovao\"},{\"authorId\":\"1754192\",\"name\":\"H. Nakada\"},{\"authorId\":\"144739206\",\"name\":\"Yusuke Tanimura\"},{\"authorId\":\"7142317\",\"name\":\"Hideki Asoh\"}],\"doi\":\"10.1109/ACCESS.2020.3016313\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"bb617a6b46c8f3b6bccaf8974853143d161221ed\",\"title\":\"Generating In-Between Images Through Learned Latent Space Representation Using Variational Autoencoders\",\"url\":\"https://www.semanticscholar.org/paper/bb617a6b46c8f3b6bccaf8974853143d161221ed\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2007.02018\",\"authors\":[{\"authorId\":\"12771034\",\"name\":\"Jinxiu Liang\"},{\"authorId\":\"121983569\",\"name\":\"Yanchen Xu\"},{\"authorId\":\"2217653\",\"name\":\"Y. Quan\"},{\"authorId\":\"48093314\",\"name\":\"Jing-Wen Wang\"},{\"authorId\":\"29116642\",\"name\":\"H. Ling\"},{\"authorId\":\"90137165\",\"name\":\"H. Ji\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"06a4a6c34385aff144e4da5a7299f432703cf6e9\",\"title\":\"Deep Bilateral Retinex for Low-Light Image Enhancement\",\"url\":\"https://www.semanticscholar.org/paper/06a4a6c34385aff144e4da5a7299f432703cf6e9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145879931\",\"name\":\"M. Haris\"},{\"authorId\":\"46208708\",\"name\":\"G. Shakhnarovich\"},{\"authorId\":\"3081689\",\"name\":\"N. Ukita\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"3e7750cf83808b9af0ded0586fb85483623c825d\",\"title\":\"Space-Time-Aware Multi-Resolution Video Enhancement \\u2014Supplementary Materials\\u2014\",\"url\":\"https://www.semanticscholar.org/paper/3e7750cf83808b9af0ded0586fb85483623c825d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2866383\",\"name\":\"Dong-Yoon Choi\"},{\"authorId\":\"3835816\",\"name\":\"D. Kim\"},{\"authorId\":\"10774886\",\"name\":\"B. Song\"}],\"doi\":\"10.1109/ICIP.2018.8451359\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8ab76d6cf2225603f6c4f6ea519a88b5d6a84a8f\",\"title\":\"Recognizing Fine Facial Micro-Expressions Using Two-Dimensional Landmark Feature\",\"url\":\"https://www.semanticscholar.org/paper/8ab76d6cf2225603f6c4f6ea519a88b5d6a84a8f\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145871212\",\"name\":\"M. Lu\"},{\"authorId\":\"143657776\",\"name\":\"M. Cheng\"},{\"authorId\":\"3237008\",\"name\":\"Q. Shen\"},{\"authorId\":\"1800270\",\"name\":\"Y. Xu\"},{\"authorId\":\"1762531\",\"name\":\"Zhan Ma\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"375f3cf2950dc948cbecc6eede13123979ab5f92\",\"title\":\"Collaborative Processing System for Networked Video Applications\",\"url\":\"https://www.semanticscholar.org/paper/375f3cf2950dc948cbecc6eede13123979ab5f92\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"70489777\",\"name\":\"Ha-Eun Ahn\"},{\"authorId\":\"1683954\",\"name\":\"Jinwoo Jeong\"},{\"authorId\":\"2433705\",\"name\":\"J. Kim\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5c1e1e4fd2825d27033a4dcafa87580219d75e0a\",\"title\":\"A Fast 4 K Video Frame Interpolation Using a Hybrid Task-Based Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/5c1e1e4fd2825d27033a4dcafa87580219d75e0a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1905.06567\",\"authors\":[{\"authorId\":\"41127426\",\"name\":\"Jiaying Liu\"},{\"authorId\":\"145772051\",\"name\":\"Sifeng Xia\"},{\"authorId\":\"1898172\",\"name\":\"W. Yang\"}],\"doi\":\"10.1109/TMM.2019.2961504\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d873fdfc43afd675432af22362283bf202837164\",\"title\":\"Deep Reference Generation With Multi-Domain Hierarchical Constraints for Inter Prediction\",\"url\":\"https://www.semanticscholar.org/paper/d873fdfc43afd675432af22362283bf202837164\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49331178\",\"name\":\"Jinsoo Choi\"},{\"authorId\":\"145017149\",\"name\":\"I. S. Kweon\"}],\"doi\":\"10.1109/ICCVW.2019.00463\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3b259156df1f12fd7be68c29462b0f70b97bdb70\",\"title\":\"DIFRINT: Deep Iterative Frame Interpolation for Full-Frame Video Stabilization\",\"url\":\"https://www.semanticscholar.org/paper/3b259156df1f12fd7be68c29462b0f70b97bdb70\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"2006.08070\",\"authors\":[{\"authorId\":\"1384709008\",\"name\":\"Xianhang Cheng\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"db79a9a20acb3c15256655d52bb40e8831bb2345\",\"title\":\"Multiple Video Frame Interpolation via Enhanced Deformable Separable Convolution\",\"url\":\"https://www.semanticscholar.org/paper/db79a9a20acb3c15256655d52bb40e8831bb2345\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.06965\",\"authors\":[{\"authorId\":\"40946340\",\"name\":\"Yu-Syuan Xu\"},{\"authorId\":\"51119986\",\"name\":\"Shou-Yao Roy Tseng\"},{\"authorId\":\"47984199\",\"name\":\"Y. Tseng\"},{\"authorId\":\"2836806\",\"name\":\"Hsien-Kai Kuo\"},{\"authorId\":\"2033674\",\"name\":\"Yi-Min Tsai\"}],\"doi\":\"10.1109/CVPR42600.2020.01251\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ff36187041e08237bd075ca56b8ad17347376784\",\"title\":\"Unified Dynamic Convolutional Network for Super-Resolution With Variational Degradations\",\"url\":\"https://www.semanticscholar.org/paper/ff36187041e08237bd075ca56b8ad17347376784\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1711.08682\",\"authors\":[{\"authorId\":\"30017683\",\"name\":\"Haoye Cai\"},{\"authorId\":\"49588814\",\"name\":\"Chunyan Bai\"},{\"authorId\":\"5068280\",\"name\":\"Yu-Wing Tai\"},{\"authorId\":\"2088295\",\"name\":\"C. Tang\"}],\"doi\":\"10.1007/978-3-030-01216-8_23\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a35fd89c4ea33d741b0ce0cf17bfb2e750aea51e\",\"title\":\"Deep Video Generation, Prediction and Completion of Human Action Sequences\",\"url\":\"https://www.semanticscholar.org/paper/a35fd89c4ea33d741b0ce0cf17bfb2e750aea51e\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2005.01233\",\"authors\":[{\"authorId\":\"40648435\",\"name\":\"Seungjun Nah\"},{\"authorId\":\"48206011\",\"name\":\"Hee-won Kim\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"},{\"authorId\":null,\"name\":\"Ning Xu\"},{\"authorId\":\"97866501\",\"name\":\"Bumjun Park\"},{\"authorId\":\"152283843\",\"name\":\"Songhyun Yu\"},{\"authorId\":\"48388801\",\"name\":\"S. Kim\"},{\"authorId\":\"46973317\",\"name\":\"J. Jeong\"},{\"authorId\":\"93263637\",\"name\":\"W. Shen\"},{\"authorId\":\"8613898\",\"name\":\"Wenbo Bao\"},{\"authorId\":\"144826391\",\"name\":\"Guangtao Zhai\"},{\"authorId\":\"4640997\",\"name\":\"Sanghyun Son\"},{\"authorId\":\"152875291\",\"name\":\"L. Chen\"},{\"authorId\":\"1585142097\",\"name\":\"Zhiyong Gaon\"},{\"authorId\":\"2812984\",\"name\":\"G. Chen\"},{\"authorId\":\"7774660\",\"name\":\"Yunhua Lu\"},{\"authorId\":\"46585842\",\"name\":\"R. Duan\"},{\"authorId\":\"150321531\",\"name\":\"Tong Liu\"},{\"authorId\":\"47059427\",\"name\":\"L. Zhang\"},{\"authorId\":\"120878650\",\"name\":\"Woonsung Park\"},{\"authorId\":\"47596916\",\"name\":\"M. Kim\"},{\"authorId\":\"1387998946\",\"name\":\"George Pisha\"},{\"authorId\":\"1732855\",\"name\":\"R. Timofte\"},{\"authorId\":\"1557634128\",\"name\":\"Eyal Naor\"},{\"authorId\":\"104101992\",\"name\":\"L. Aloni\"},{\"authorId\":\"2135837\",\"name\":\"Kyoung Mu Lee\"},{\"authorId\":\"31060460\",\"name\":\"Li Si-Yao\"},{\"authorId\":\"116295634\",\"name\":\"Ze Pan\"},{\"authorId\":\"48669892\",\"name\":\"Xiangyu Xu\"},{\"authorId\":\"8397576\",\"name\":\"Wenxiu Sun\"},{\"authorId\":\"83500873\",\"name\":\"Myungsub Choi\"}],\"doi\":\"10.1109/ICCVW.2019.00421\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3247a8640db63c638a1386493a87202aa2a0b15b\",\"title\":\"AIM 2019 Challenge on Video Temporal Super-Resolution: Methods and Results\",\"url\":\"https://www.semanticscholar.org/paper/3247a8640db63c638a1386493a87202aa2a0b15b\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1626101034\",\"name\":\"Nguyen Van Thang\"},{\"authorId\":\"1390764531\",\"name\":\"Kyujoong Lee\"},{\"authorId\":\"3090069\",\"name\":\"Hyuk-Jae Lee\"}],\"doi\":\"10.1109/ACCESS.2020.2982039\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1a2edb287693a4c82bc3fd82ccf2f2544c127e5d\",\"title\":\"A Stacked Deep MEMC Network for Frame Rate Up Conversion and its Application to HEVC\",\"url\":\"https://www.semanticscholar.org/paper/1a2edb287693a4c82bc3fd82ccf2f2544c127e5d\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2008.03633\",\"authors\":[{\"authorId\":\"88677858\",\"name\":\"Juan Luis Gonzalez Bello\"},{\"authorId\":\"3031085\",\"name\":\"Min-Soeng Kim\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b5a2480ee4b144fdd08076e53b798e0b15a137b0\",\"title\":\"Forget About the LiDAR: Self-Supervised Depth Estimators with MED Probability Volumes\",\"url\":\"https://www.semanticscholar.org/paper/b5a2480ee4b144fdd08076e53b798e0b15a137b0\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48795116\",\"name\":\"H. W. F. Yeung\"},{\"authorId\":\"40630305\",\"name\":\"J. Hou\"},{\"authorId\":\"48282890\",\"name\":\"Xiaoming Chen\"},{\"authorId\":\"1800745\",\"name\":\"J. Chen\"},{\"authorId\":\"31482866\",\"name\":\"Zhibo Chen\"},{\"authorId\":\"1798753\",\"name\":\"Y. Y. Chung\"}],\"doi\":\"10.1109/TIP.2018.2885236\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d78ca1386301ec40d91ef32f831737c4bbcf8bed\",\"title\":\"Light Field Spatial Super-Resolution Using Deep Efficient Spatial-Angular Separable Convolution\",\"url\":\"https://www.semanticscholar.org/paper/d78ca1386301ec40d91ef32f831737c4bbcf8bed\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152359151\",\"name\":\"Chenxi Tu\"},{\"authorId\":\"49567362\",\"name\":\"E. Takeuchi\"},{\"authorId\":\"1856242\",\"name\":\"Alexander Carballo\"},{\"authorId\":\"1709999\",\"name\":\"K. Takeda\"}],\"doi\":\"10.1109/ACCESS.2019.2935253\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f1f39bcb64a8483a57c6301bc878fe95628ec78b\",\"title\":\"Real-Time Streaming Point Cloud Compression for 3D LiDAR Sensor Using U-Net\",\"url\":\"https://www.semanticscholar.org/paper/f1f39bcb64a8483a57c6301bc878fe95628ec78b\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1818918\",\"name\":\"Sung-Jun Yoon\"},{\"authorId\":\"2029917\",\"name\":\"H. Kim\"},{\"authorId\":\"144366095\",\"name\":\"M. Kim\"}],\"doi\":\"10.1109/TIP.2018.2861567\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b9ee4d83403c76177bd434672bb3427944d4e054\",\"title\":\"Hierarchical Extended Bilateral Motion Estimation-Based Frame Rate Upconversion Using Learning-Based Linear Mapping\",\"url\":\"https://www.semanticscholar.org/paper/b9ee4d83403c76177bd434672bb3427944d4e054\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"88677858\",\"name\":\"Juan Luis Gonzalez Bello\"},{\"authorId\":\"3031085\",\"name\":\"Min-Soeng Kim\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d23c551f8b8f3990077a4b006c0018b8b3b0c56f\",\"title\":\"Deep 3D Pan via local adaptive \\\"t-shaped\\\" convolutions with global and local adaptive dilations\",\"url\":\"https://www.semanticscholar.org/paper/d23c551f8b8f3990077a4b006c0018b8b3b0c56f\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"2005.03155\",\"authors\":[{\"authorId\":\"3325819\",\"name\":\"Shanxin Yuan\"},{\"authorId\":\"1732855\",\"name\":\"R. Timofte\"},{\"authorId\":\"1732672\",\"name\":\"A. Leonardis\"},{\"authorId\":\"7622560\",\"name\":\"G. Slabaugh\"},{\"authorId\":\"2047166\",\"name\":\"Xiaotong Luo\"},{\"authorId\":\"49050940\",\"name\":\"Jiangtao Zhang\"},{\"authorId\":\"9274274\",\"name\":\"Yanyun Qu\"},{\"authorId\":\"143662630\",\"name\":\"Ming Hong\"},{\"authorId\":\"1410066063\",\"name\":\"Yuan Xie\"},{\"authorId\":\"39168930\",\"name\":\"C. Li\"},{\"authorId\":\"1575684088\",\"name\":\"Dejia Xu\"},{\"authorId\":\"1685548005\",\"name\":\"Yihao Chu\"},{\"authorId\":\"49144700\",\"name\":\"Qingyan Sun\"},{\"authorId\":\"1390630067\",\"name\":\"Shuai Liu\"},{\"authorId\":\"1672982693\",\"name\":\"Ziyao Zong\"},{\"authorId\":\"48144637\",\"name\":\"Nan Nan\"},{\"authorId\":\"48161878\",\"name\":\"LI\"},{\"authorId\":\"48388801\",\"name\":\"S. Kim\"},{\"authorId\":\"1685503131\",\"name\":\"Hyungjoon Nam\"},{\"authorId\":\"49475883\",\"name\":\"Jisu Kim\"},{\"authorId\":\"46973317\",\"name\":\"J. Jeong\"},{\"authorId\":\"35997085\",\"name\":\"M. Cheon\"},{\"authorId\":\"1818918\",\"name\":\"Sung-Jun Yoon\"},{\"authorId\":\"1684766994\",\"name\":\"Byungyeon Kang\"},{\"authorId\":\"9174449\",\"name\":\"Junwoo Lee\"},{\"authorId\":\"152869379\",\"name\":\"Bolun Zheng\"},{\"authorId\":\"49544454\",\"name\":\"X. Liu\"},{\"authorId\":\"84102771\",\"name\":\"L. Dai\"},{\"authorId\":null,\"name\":\"Jun Chen\"},{\"authorId\":\"48684288\",\"name\":\"Xi Cheng\"},{\"authorId\":\"37876634\",\"name\":\"Zhenyong Fu\"},{\"authorId\":\"25758169\",\"name\":\"J. Yang\"},{\"authorId\":\"117523938\",\"name\":\"C. Lee\"},{\"authorId\":\"35351918\",\"name\":\"Vien Gia An\"},{\"authorId\":\"115252570\",\"name\":\"Hyunkook Park\"},{\"authorId\":\"20915110\",\"name\":\"D. Nathan\"},{\"authorId\":\"49100402\",\"name\":\"M. Beham\"},{\"authorId\":\"1684760292\",\"name\":\"S. M. Roomi\"},{\"authorId\":\"150102111\",\"name\":\"F. Lemarchand\"},{\"authorId\":\"2063012\",\"name\":\"M. Pelcat\"},{\"authorId\":\"2443938\",\"name\":\"E. Nogues\"},{\"authorId\":\"1667997430\",\"name\":\"Densen Puthussery\"},{\"authorId\":\"1668049982\",\"name\":\"S. HrishikeshP.\"},{\"authorId\":\"1668035436\",\"name\":\"V. JijiC.\"},{\"authorId\":\"47270703\",\"name\":\"A. Sinha\"},{\"authorId\":\"143786941\",\"name\":\"Xuan Zhao\"}],\"doi\":\"10.1109/CVPRW50498.2020.00238\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9bbec0d1c2f7ff561aad602e7c443c22ed3f5f3b\",\"title\":\"NTIRE 2020 Challenge on Image Demoireing: Methods and Results\",\"url\":\"https://www.semanticscholar.org/paper/9bbec0d1c2f7ff561aad602e7c443c22ed3f5f3b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"2012.08512\",\"authors\":[{\"authorId\":\"2655351\",\"name\":\"Tarun Kalluri\"},{\"authorId\":\"2004879394\",\"name\":\"Deepak Pathak\"},{\"authorId\":\"1491032137\",\"name\":\"M. Chandraker\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5ca230da787b25643150c8b2df474e2d6d8ec7c9\",\"title\":\"FLAVR: Flow-Agnostic Video Representations for Fast Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/5ca230da787b25643150c8b2df474e2d6d8ec7c9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48633955\",\"name\":\"Zhenghui Zhao\"},{\"authorId\":\"1705047\",\"name\":\"S. Wang\"},{\"authorId\":\"1755176\",\"name\":\"Shanshe Wang\"},{\"authorId\":\"3175853\",\"name\":\"Xinfeng Zhang\"},{\"authorId\":\"10634370\",\"name\":\"S. Ma\"},{\"authorId\":\"46477671\",\"name\":\"Jiansheng Yang\"}],\"doi\":\"10.1109/TCSVT.2018.2876399\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eca81541bf67741779bcb51760b43ecacc473d8f\",\"title\":\"Enhanced Bi-Prediction With Convolutional Neural Network for High-Efficiency Video Coding\",\"url\":\"https://www.semanticscholar.org/paper/eca81541bf67741779bcb51760b43ecacc473d8f\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":\"2009.12987\",\"authors\":[{\"authorId\":\"4640997\",\"name\":\"Sanghyun Son\"},{\"authorId\":\"71710083\",\"name\":\"Jaerin Lee\"},{\"authorId\":\"40648435\",\"name\":\"Seungjun Nah\"},{\"authorId\":\"51166756\",\"name\":\"R. Timofte\"},{\"authorId\":\"2135837\",\"name\":\"Kyoung Mu Lee\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a9e01b6bdab1407798c1fdd51defb27bc5b2d0a2\",\"title\":\"AIM 2020 Challenge on Video Temporal Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/a9e01b6bdab1407798c1fdd51defb27bc5b2d0a2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.08222\",\"authors\":[{\"authorId\":\"120809851\",\"name\":\"Jianbo Liu\"},{\"authorId\":\"47752269\",\"name\":\"Junjun He\"},{\"authorId\":\"145335572\",\"name\":\"J. Ren\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"119885708\",\"name\":\"Hongsheng Li\"}],\"doi\":\"10.1007/978-3-030-58595-2_46\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2a395866a78704dbc2132a15c3195b3196236a27\",\"title\":\"Learning to Predict Context-adaptive Convolution for Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/2a395866a78704dbc2132a15c3195b3196236a27\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46793780\",\"name\":\"Ximeng Sun\"},{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"99cd8f9920ba94ec9d85517f4975e1c4bee3c60a\",\"title\":\"A Two-Stream Variational Adversarial Network for Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/99cd8f9920ba94ec9d85517f4975e1c4bee3c60a\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98080420\",\"name\":\"Hyeongmin Lee\"},{\"authorId\":\"48271129\",\"name\":\"Taeoh Kim\"},{\"authorId\":\"3305074\",\"name\":\"Tae-Young Chung\"},{\"authorId\":\"48322708\",\"name\":\"Daehyun Pak\"},{\"authorId\":\"2417978\",\"name\":\"Yuseok Ban\"},{\"authorId\":\"3055035\",\"name\":\"Sangyoun Lee\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"946a9a5d18a423de9c109087ecae818809276b9c\",\"title\":\"Learning Spatial Transform for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/946a9a5d18a423de9c109087ecae818809276b9c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1910.00132\",\"authors\":[{\"authorId\":\"7839191\",\"name\":\"K. Duarte\"},{\"authorId\":\"2116440\",\"name\":\"Y. Rawat\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/ICCV.2019.00857\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2f4b5bfe6b7399797e2048695577eb60253f0bbc\",\"title\":\"CapsuleVOS: Semi-Supervised Video Object Segmentation Using Capsule Routing\",\"url\":\"https://www.semanticscholar.org/paper/2f4b5bfe6b7399797e2048695577eb60253f0bbc\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1904.02909\",\"authors\":[{\"authorId\":\"9757384\",\"name\":\"Woon-Sung Park\"},{\"authorId\":\"144366095\",\"name\":\"M. Kim\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b87df69011057c700f581798e8c13667f5205b8e\",\"title\":\"Deep Predictive Video Compression with Bi-directional Prediction\",\"url\":\"https://www.semanticscholar.org/paper/b87df69011057c700f581798e8c13667f5205b8e\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1712.02327\",\"authors\":[{\"authorId\":\"2577533\",\"name\":\"Ben Mildenhall\"},{\"authorId\":\"50329510\",\"name\":\"J. Barron\"},{\"authorId\":\"1967685\",\"name\":\"Jiawen Chen\"},{\"authorId\":\"2665634\",\"name\":\"Dillon Sharlet\"},{\"authorId\":\"47383180\",\"name\":\"R. Ng\"},{\"authorId\":\"144264200\",\"name\":\"Robert Carroll\"}],\"doi\":\"10.1109/CVPR.2018.00265\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"84fc681efa7a7030098daf0c122ce6b770351c85\",\"title\":\"Burst Denoising with Kernel Prediction Networks\",\"url\":\"https://www.semanticscholar.org/paper/84fc681efa7a7030098daf0c122ce6b770351c85\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2482675\",\"name\":\"Z. \\u00c1. Milacski\"},{\"authorId\":\"1719347\",\"name\":\"B. P\\u00f3czos\"},{\"authorId\":\"32414762\",\"name\":\"A. L\\u00f6rincz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"42d7856dc20be6b0b6584ec6ee09d558025150bb\",\"title\":\"VideoOneNet: Bidirectional Convolutional Recurrent OneNet with Trainable Data Steps for Video Processing\",\"url\":\"https://www.semanticscholar.org/paper/42d7856dc20be6b0b6584ec6ee09d558025150bb\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144667531\",\"name\":\"Jean B\\u00e9gaint\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"412a4ba6f1a8b525ece09963c39c5e6758056ba8\",\"title\":\"Towards novel inter-prediction methods for image and video compression. (Nouvelles m\\u00e9thodes de pr\\u00e9diction inter-images pour la compression d'images et de vid\\u00e9os)\",\"url\":\"https://www.semanticscholar.org/paper/412a4ba6f1a8b525ece09963c39c5e6758056ba8\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3222730\",\"name\":\"Tianfan Xue\"},{\"authorId\":\"1766333\",\"name\":\"D. Wei\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5708b5345e42279b54fa213187120d878c0fdb7e\",\"title\":\"With Ground Truth Flows Case II : With Task-Oriented Flows Input frames TOFlow Warped by TOFlow Denoised frame Video Denoising ?\",\"url\":\"https://www.semanticscholar.org/paper/5708b5345e42279b54fa213187120d878c0fdb7e\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66152807\",\"name\":\"J. Lee\"},{\"authorId\":\"1731170\",\"name\":\"G. Wetzstein\"},{\"authorId\":\"34273166\",\"name\":\"Hoang M. Le\"},{\"authorId\":\"153035663\",\"name\":\"F. Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"55ce6d69f6b91d13e0da440e1864e6017ab614f8\",\"title\":\"/ Appearance Flow Completion for Novel View Synthesis Dense Flow Estimator Sparse Flow Estimator Sparse Flow Estimator Sparse Flow Estimator\",\"url\":\"https://www.semanticscholar.org/paper/55ce6d69f6b91d13e0da440e1864e6017ab614f8\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2009.05666\",\"authors\":[{\"authorId\":\"3320198\",\"name\":\"Hyomin Choi\"},{\"authorId\":\"1730101\",\"name\":\"I. Bajic\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7583d4f74b2e3dd76084a1166bdc9ea1ecbbe075\",\"title\":\"Affine Transformation-Based Deep Frame Prediction\",\"url\":\"https://www.semanticscholar.org/paper/7583d4f74b2e3dd76084a1166bdc9ea1ecbbe075\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2011.10185\",\"authors\":[{\"authorId\":\"2545360\",\"name\":\"Zhouyong Liu\"},{\"authorId\":\"1996150477\",\"name\":\"Shun Luo\"},{\"authorId\":\"3335945\",\"name\":\"Wubin Li\"},{\"authorId\":\"2027604839\",\"name\":\"Jingben Lu\"},{\"authorId\":\"1390683331\",\"name\":\"Yufan Wu\"},{\"authorId\":\"1726286\",\"name\":\"Chunguo Li\"},{\"authorId\":\"97745176\",\"name\":\"L. Yang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"43df53137dfaac590600c4c3dfe1fa0f54148774\",\"title\":\"ConvTransformer: A Convolutional Transformer Network for Video Frame Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/43df53137dfaac590600c4c3dfe1fa0f54148774\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1904.02912\",\"authors\":[{\"authorId\":\"40897201\",\"name\":\"Tsun-Hsuan Wang\"},{\"authorId\":\"94288126\",\"name\":\"Y. Cheng\"},{\"authorId\":\"49044307\",\"name\":\"Chieh Hubert Lin\"},{\"authorId\":\"1803730\",\"name\":\"Hwann-Tzong Chen\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":\"10.1109/ICCV.2019.01059\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cb0a151cf8740c66b461ff809e086b91f14bd23b\",\"title\":\"Point-to-Point Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/cb0a151cf8740c66b461ff809e086b91f14bd23b\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46179701\",\"name\":\"Yicun Liu\"},{\"authorId\":\"1500380173\",\"name\":\"Jimmy Ren\"},{\"authorId\":\"1519062623\",\"name\":\"Jiawei Zhang\"},{\"authorId\":\"120809851\",\"name\":\"Jianbo Liu\"},{\"authorId\":\"3388973\",\"name\":\"Mude Lin\"}],\"doi\":\"10.1109/cvpr42600.2020.00210\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b131d255bf8bff6c4bac765c57190e2f448b2b2b\",\"title\":\"Visually Imbalanced Stereo Matching\",\"url\":\"https://www.semanticscholar.org/paper/b131d255bf8bff6c4bac765c57190e2f448b2b2b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1753738047\",\"name\":\"Kshitija Pandya\"},{\"authorId\":\"1753737879\",\"name\":\"Disha Varshney\"},{\"authorId\":\"1753607722\",\"name\":\"Ashray Aggarwal\"},{\"authorId\":\"115827410\",\"name\":\"Anil Singh Parihar\"}],\"doi\":\"10.1109/ICICCS48265.2020.9120989\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"682e288a5870f182e0f92bb4735f5659dff8b94c\",\"title\":\"An Analytical Study of CNN-based Video Frame Interpolation Techniques\",\"url\":\"https://www.semanticscholar.org/paper/682e288a5870f182e0f92bb4735f5659dff8b94c\",\"venue\":\"2020 4th International Conference on Intelligent Computing and Control Systems (ICICCS)\",\"year\":2020},{\"arxivId\":\"1809.00263\",\"authors\":[{\"authorId\":\"12601304\",\"name\":\"Qiangeng Xu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":null,\"name\":\"Weiyue Wang\"},{\"authorId\":\"1767767\",\"name\":\"P. Belhumeur\"},{\"authorId\":\"143840663\",\"name\":\"U. Neumann\"}],\"doi\":\"10.1109/WACV45572.2020.9093530\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"56568a54bdb34d6164cf1267a94f07f81ca3a508\",\"title\":\"Stochastic Dynamics for Video Infilling\",\"url\":\"https://www.semanticscholar.org/paper/56568a54bdb34d6164cf1267a94f07f81ca3a508\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491637046\",\"name\":\"Kang Liao\"},{\"authorId\":\"49043799\",\"name\":\"C. Lin\"},{\"authorId\":\"1517826311\",\"name\":\"Yao Zhao\"},{\"authorId\":\"9219875\",\"name\":\"M. Gabbouj\"}],\"doi\":\"10.1109/TCSVT.2019.2958199\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ea50f28ec26924163c878f89cb33e2b7ab2d4d0c\",\"title\":\"Distortion Rectification From Static to Dynamic: A Distortion Sequence Construction Perspective\",\"url\":\"https://www.semanticscholar.org/paper/ea50f28ec26924163c878f89cb33e2b7ab2d4d0c\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"1909.09725\",\"authors\":[{\"authorId\":\"2181063\",\"name\":\"Qiqi Hou\"},{\"authorId\":\"48521790\",\"name\":\"F. Liu\"}],\"doi\":\"10.1109/ICCV.2019.00423\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9b966323f8ba738d9a50bc093fb6ab9fef7a9f3d\",\"title\":\"Context-Aware Image Matting for Simultaneous Foreground and Alpha Estimation\",\"url\":\"https://www.semanticscholar.org/paper/9b966323f8ba738d9a50bc093fb6ab9fef7a9f3d\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2007.12622\",\"authors\":[{\"authorId\":\"115539898\",\"name\":\"J. Park\"},{\"authorId\":\"51268282\",\"name\":\"Keunsoo Ko\"},{\"authorId\":\"1699113\",\"name\":\"C. Lee\"},{\"authorId\":\"96521675\",\"name\":\"Chang-Su Kim\"}],\"doi\":\"10.1007/978-3-030-58568-6_7\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f38a0b306789afac22ed7f35291a17b8fbfa686f\",\"title\":\"BMBC: Bilateral Motion Estimation with Bilateral Cost Volume for Video Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/f38a0b306789afac22ed7f35291a17b8fbfa686f\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2004.13784\",\"authors\":[{\"authorId\":\"49573957\",\"name\":\"D. Verma\"},{\"authorId\":\"1678985\",\"name\":\"A. Baghaie\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"17465f424f26b2a4861c283bebd4f86243e6de6b\",\"title\":\"Convolutional Neural Networks vs. Deformable Image Registration For Medical Slice Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/17465f424f26b2a4861c283bebd4f86243e6de6b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.05532\",\"authors\":[{\"authorId\":\"14925412\",\"name\":\"Prasan A. Shedligeri\"},{\"authorId\":\"71834567\",\"name\":\"S. Anupama\"},{\"authorId\":\"1879114299\",\"name\":\"Kaushik Mitra\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"57cbe673125a9e6775e9e16c7355f062ce6eae82\",\"title\":\"A Unified Framework for Compressive Video Recovery from Coded Exposure Techniques\",\"url\":\"https://www.semanticscholar.org/paper/57cbe673125a9e6775e9e16c7355f062ce6eae82\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"115539898\",\"name\":\"J. Park\"},{\"authorId\":\"39876415\",\"name\":\"C. Lee\"},{\"authorId\":\"96521675\",\"name\":\"Chang-Su Kim\"}],\"doi\":\"10.1109/APSIPAASC47483.2019.9023270\",\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"dd5a32ee12e1d49b3c69863c583ef063b753a289\",\"title\":\"Deep Learning Approach to Video Frame Rate Up-Conversion Using Bilateral Motion Estimation\",\"url\":\"https://www.semanticscholar.org/paper/dd5a32ee12e1d49b3c69863c583ef063b753a289\",\"venue\":\"2019 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"70489777\",\"name\":\"Ha-Eun Ahn\"},{\"authorId\":\"1683954\",\"name\":\"Jinwoo Jeong\"},{\"authorId\":\"2433705\",\"name\":\"J. Kim\"},{\"authorId\":\"92733026\",\"name\":\"Soon-chul Kwon\"},{\"authorId\":\"1773696\",\"name\":\"Ji-Sang Yoo\"}],\"doi\":\"10.3390/sym11101251\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"20e1a4824df1cf8583e5d64f95ef6b3b0acae1cb\",\"title\":\"A Fast 4K Video Frame Interpolation Using a Multi-Scale Optical Flow Reconstruction Network\",\"url\":\"https://www.semanticscholar.org/paper/20e1a4824df1cf8583e5d64f95ef6b3b0acae1cb\",\"venue\":\"Symmetry\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123797012\",\"name\":\"Christopher May\"},{\"authorId\":\"145869839\",\"name\":\"M. Oliveira\"},{\"authorId\":\"1698910\",\"name\":\"D. Aliaga\"}],\"doi\":\"10.1109/TVCG.2020.2992670\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e37d7a35e7bf448f027e5e33d1a91143d18b7ad2\",\"title\":\"Video Folding: Increased Framerate for Semi-Repetitive Sequences.\",\"url\":\"https://www.semanticscholar.org/paper/e37d7a35e7bf448f027e5e33d1a91143d18b7ad2\",\"venue\":\"IEEE transactions on visualization and computer graphics\",\"year\":2020},{\"arxivId\":\"1909.12942\",\"authors\":[{\"authorId\":\"92403059\",\"name\":\"Zheyu Yang\"},{\"authorId\":\"72500851\",\"name\":\"Yujie Wu\"},{\"authorId\":\"80816621\",\"name\":\"Guanrui Wang\"},{\"authorId\":\"3365623\",\"name\":\"Y. Yang\"},{\"authorId\":\"1730243\",\"name\":\"Guoqi Li\"},{\"authorId\":\"144284633\",\"name\":\"Lei Deng\"},{\"authorId\":\"47055094\",\"name\":\"J. Zhu\"},{\"authorId\":\"29889772\",\"name\":\"Luping Shi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"636e62fc0b06c6e5b7d87e07a5bf088eb3ab711e\",\"title\":\"DashNet: A Hybrid Artificial and Spiking Neural Network for High-speed Object Tracking\",\"url\":\"https://www.semanticscholar.org/paper/636e62fc0b06c6e5b7d87e07a5bf088eb3ab711e\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1904.00830\",\"authors\":[{\"authorId\":\"8613898\",\"name\":\"Wenbo Bao\"},{\"authorId\":\"2268189\",\"name\":\"Wei-Sheng Lai\"},{\"authorId\":\"46658056\",\"name\":\"Chao Ma\"},{\"authorId\":\"49469756\",\"name\":\"X. Zhang\"},{\"authorId\":\"145071557\",\"name\":\"Z. Gao\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/CVPR.2019.00382\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6c8a56ae495e5c8871061d1cd0f863d174f5e2ce\",\"title\":\"Depth-Aware Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/6c8a56ae495e5c8871061d1cd0f863d174f5e2ce\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2009.04642\",\"authors\":[{\"authorId\":\"49422053\",\"name\":\"Yihao Liu\"},{\"authorId\":\"1604613100\",\"name\":\"Liangbin Xie\"},{\"authorId\":\"31060460\",\"name\":\"Li Si-Yao\"},{\"authorId\":\"8397576\",\"name\":\"Wenxiu Sun\"},{\"authorId\":\"145858545\",\"name\":\"Y. Qiao\"},{\"authorId\":\"30459277\",\"name\":\"C. Dong\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"091ffbd9852f9ba4f333af2ef9e77c0d70e6429a\",\"title\":\"Enhanced Quadratic Video Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/091ffbd9852f9ba4f333af2ef9e77c0d70e6429a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1810.08768\",\"authors\":[{\"authorId\":\"8613898\",\"name\":\"Wenbo Bao\"},{\"authorId\":\"2268189\",\"name\":\"Wei-Sheng Lai\"},{\"authorId\":\"9117564\",\"name\":\"X. Zhang\"},{\"authorId\":\"145071557\",\"name\":\"Z. Gao\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/tpami.2019.2941941\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d833c48334e906537f21757b6f9fa44da66f6c76\",\"title\":\"MEMC-Net: Motion Estimation and Motion Compensation Driven Neural Network for Video Interpolation and Enhancement\",\"url\":\"https://www.semanticscholar.org/paper/d833c48334e906537f21757b6f9fa44da66f6c76\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2019},{\"arxivId\":\"2011.13084\",\"authors\":[{\"authorId\":\"8763474\",\"name\":\"Z. Li\"},{\"authorId\":\"39644974\",\"name\":\"Simon Niklaus\"},{\"authorId\":\"1830653\",\"name\":\"Noah Snavely\"},{\"authorId\":\"1660745575\",\"name\":\"Oliver Wang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"13034a395d5c6728c9b11e777828d9998018cbf6\",\"title\":\"Neural Scene Flow Fields for Space-Time View Synthesis of Dynamic Scenes\",\"url\":\"https://www.semanticscholar.org/paper/13034a395d5c6728c9b11e777828d9998018cbf6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49528654\",\"name\":\"Huiling Wang\"},{\"authorId\":\"2785022\",\"name\":\"T. Raiko\"},{\"authorId\":\"1688468\",\"name\":\"L. Lensu\"},{\"authorId\":\"46958572\",\"name\":\"T. Wang\"},{\"authorId\":\"1703769\",\"name\":\"J. Karhunen\"}],\"doi\":\"10.1007/978-3-030-20893-6\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8f0c1d7dd99ea904da834204da1fc7ce94314d49\",\"title\":\"Computer Vision \\u2013 ACCV 2018\",\"url\":\"https://www.semanticscholar.org/paper/8f0c1d7dd99ea904da834204da1fc7ce94314d49\",\"venue\":\"Lecture Notes in Computer Science\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143834635\",\"name\":\"Jing Jin\"},{\"authorId\":\"40630305\",\"name\":\"J. Hou\"},{\"authorId\":\"40445654\",\"name\":\"J. Chen\"},{\"authorId\":\"1747380\",\"name\":\"H. Zeng\"},{\"authorId\":\"1687386\",\"name\":\"S. Kwong\"},{\"authorId\":\"47891011\",\"name\":\"Jingyi Yu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7d975ce610b69447aea2ef7762fa96eccd3f0c4b\",\"title\":\"Flexible, Fast and Accurate Densely-Sampled Light Field Reconstruction Network\",\"url\":\"https://www.semanticscholar.org/paper/7d975ce610b69447aea2ef7762fa96eccd3f0c4b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1809.07759\",\"authors\":[{\"authorId\":\"84509959\",\"name\":\"Mart Kartasev\"},{\"authorId\":\"84650046\",\"name\":\"Carlo Rapisarda\"},{\"authorId\":\"47414172\",\"name\":\"Dominik Fay\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"f1aed5cd540275f86b7019e494be57437c604715\",\"title\":\"Implementing Adaptive Separable Convolution for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/f1aed5cd540275f86b7019e494be57437c604715\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2943460\",\"name\":\"Thomas Vandal\"},{\"authorId\":\"153866793\",\"name\":\"R. Nemani\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"003ef05f414b2eca59d2a04712138f75b4b4d318\",\"title\":\"Optical Flow for Intermediate Frame Interpolation of Multispectral Geostationary Satellite Data\",\"url\":\"https://www.semanticscholar.org/paper/003ef05f414b2eca59d2a04712138f75b4b4d318\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1812.01210\",\"authors\":[{\"authorId\":\"36001694\",\"name\":\"Liangzhe Yuan\"},{\"authorId\":\"47557600\",\"name\":\"Yibo Chen\"},{\"authorId\":\"50855889\",\"name\":\"H. Liu\"},{\"authorId\":\"145868989\",\"name\":\"T. Kong\"},{\"authorId\":\"46865129\",\"name\":\"J. Shi\"}],\"doi\":\"10.1109/CVPR.2019.01246\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"152c11700a6924e94955f6cf00b5a7522b406ec3\",\"title\":\"Zoom-In-To-Check: Boosting Video Interpolation via Instance-Level Discrimination\",\"url\":\"https://www.semanticscholar.org/paper/152c11700a6924e94955f6cf00b5a7522b406ec3\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1801.03924\",\"authors\":[{\"authorId\":\"2844849\",\"name\":\"Richard Zhang\"},{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"39231399\",\"name\":\"O. Wang\"}],\"doi\":\"10.1109/CVPR.2018.00068\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c468bbde6a22d961829e1970e6ad5795e05418d1\",\"title\":\"The Unreasonable Effectiveness of Deep Features as a Perceptual Metric\",\"url\":\"https://www.semanticscholar.org/paper/c468bbde6a22d961829e1970e6ad5795e05418d1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1809.08317\",\"authors\":[{\"authorId\":\"49820715\",\"name\":\"J. Wulff\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"}],\"doi\":\"10.1007/978-3-030-12939-2_39\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"47b0e2fde37b3d1810a5b5a19597765fd76c691e\",\"title\":\"Temporal Interpolation as an Unsupervised Pretraining Task for Optical Flow Estimation\",\"url\":\"https://www.semanticscholar.org/paper/47b0e2fde37b3d1810a5b5a19597765fd76c691e\",\"venue\":\"GCPR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9534924\",\"name\":\"A. Rakowski\"},{\"authorId\":\"1481760103\",\"name\":\"Jovany G. Merham\"},{\"authorId\":\"67245245\",\"name\":\"L. Li\"},{\"authorId\":\"2005235092\",\"name\":\"Pirre Baldi\"},{\"authorId\":\"2004649395\",\"name\":\"Joesph Patterson\"}],\"doi\":\"10.1017/S1431927620016360\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0d818ffbd68a8961e019ebdee6f24d2bbb348d71\",\"title\":\"Learning Frame Interpolation for Tilt Series Tomography\",\"url\":\"https://www.semanticscholar.org/paper/0d818ffbd68a8961e019ebdee6f24d2bbb348d71\",\"venue\":\"Microscopy and Microanalysis\",\"year\":2020},{\"arxivId\":\"1912.03095\",\"authors\":[{\"authorId\":\"51152279\",\"name\":\"Daniel Gehrig\"},{\"authorId\":\"8329387\",\"name\":\"M. Gehrig\"},{\"authorId\":\"1406402485\",\"name\":\"Javier Hidalgo-Carri'o\"},{\"authorId\":\"2075371\",\"name\":\"D. Scaramuzza\"}],\"doi\":\"10.1109/cvpr42600.2020.00364\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7d6d6f121e8dd049b1dee993599123c3e9852d07\",\"title\":\"Video to Events: Recycling Video Datasets for Event Cameras\",\"url\":\"https://www.semanticscholar.org/paper/7d6d6f121e8dd049b1dee993599123c3e9852d07\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1807.01462\",\"authors\":[{\"authorId\":\"1886286\",\"name\":\"Anh-Duc Nguyen\"},{\"authorId\":\"47902684\",\"name\":\"Woojae Kim\"},{\"authorId\":\"2078790\",\"name\":\"Jongyoo Kim\"},{\"authorId\":\"48602162\",\"name\":\"Sanghoon Lee\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d510492c0885d439ec6f9f40775f0b07694f3d9\",\"title\":\"Video Frame Interpolation by Plug-and-Play Deep Locally Linear Embedding\",\"url\":\"https://www.semanticscholar.org/paper/4d510492c0885d439ec6f9f40775f0b07694f3d9\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1845898483\",\"name\":\"Keito Suzuki\"},{\"authorId\":\"145990152\",\"name\":\"Masaaki Ikehara\"}],\"doi\":\"10.1109/ACCESS.2020.3010846\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"94a51246d971fae266384e94f518bf3be7578908\",\"title\":\"Residual Learning of Video Frame Interpolation Using Convolutional LSTM\",\"url\":\"https://www.semanticscholar.org/paper/94a51246d971fae266384e94f518bf3be7578908\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1905.01025\",\"authors\":[{\"authorId\":\"145871212\",\"name\":\"M. Lu\"},{\"authorId\":\"143657776\",\"name\":\"M. Cheng\"},{\"authorId\":\"1800270\",\"name\":\"Y. Xu\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"},{\"authorId\":\"3237008\",\"name\":\"Q. Shen\"},{\"authorId\":\"1762531\",\"name\":\"Zhan Ma\"}],\"doi\":\"10.1109/ICIP.2019.8803049\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2776ae2b595a76aa86ae2d8231b2ef18d1a78218\",\"title\":\"Learned Quality Enhancement via Multi-Frame Priors for HEVC Compliant Low-Delay Applications\",\"url\":\"https://www.semanticscholar.org/paper/2776ae2b595a76aa86ae2d8231b2ef18d1a78218\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"77537461\",\"name\":\"J. K. Lee\"},{\"authorId\":\"2594429\",\"name\":\"Na-Young Kim\"},{\"authorId\":\"3204439\",\"name\":\"Seunghyun Cho\"},{\"authorId\":\"52177701\",\"name\":\"Je-Won Kang\"}],\"doi\":\"10.23919/APSIPA.2018.8659611\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"efbd1def12954e16ae358f71544557a4fec7a262\",\"title\":\"Convolution Neural Network based Video Coding Technique using Reference Video Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/efbd1def12954e16ae358f71544557a4fec7a262\",\"venue\":\"2018 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)\",\"year\":2018},{\"arxivId\":\"1809.10352\",\"authors\":[{\"authorId\":\"8047613\",\"name\":\"Tahmida Mahmud\"},{\"authorId\":\"15702255\",\"name\":\"M. Billah\"},{\"authorId\":\"2968713\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":\"10.1109/GlobalSIP.2018.8646380\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6b04ee4e92e990519cf0a554862fa111cabf83e3\",\"title\":\"MULTI-VIEW FRAME RECONSTRUCTION WITH CONDITIONAL GAN\",\"url\":\"https://www.semanticscholar.org/paper/6b04ee4e92e990519cf0a554862fa111cabf83e3\",\"venue\":\"2018 IEEE Global Conference on Signal and Information Processing (GlobalSIP)\",\"year\":2018},{\"arxivId\":\"2001.01026\",\"authors\":[{\"authorId\":\"46917346\",\"name\":\"Amy Zhao\"},{\"authorId\":\"47231927\",\"name\":\"G. Balakrishnan\"},{\"authorId\":\"40649030\",\"name\":\"Kathleen M. Lewis\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"1724429\",\"name\":\"J. Guttag\"},{\"authorId\":\"3046516\",\"name\":\"Adrian V. Dalca\"}],\"doi\":\"10.1109/cvpr42600.2020.00846\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5e65da0b6621deb8427b8c6794a1b08b47c4a907\",\"title\":\"Painting Many Pasts: Synthesizing Time Lapse Videos of Paintings\",\"url\":\"https://www.semanticscholar.org/paper/5e65da0b6621deb8427b8c6794a1b08b47c4a907\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40648435\",\"name\":\"Seungjun Nah\"},{\"authorId\":\"1732855\",\"name\":\"R. Timofte\"},{\"authorId\":\"2476317\",\"name\":\"Shuhang Gu\"},{\"authorId\":\"148009160\",\"name\":\"Sungyong Baik\"},{\"authorId\":\"78563236\",\"name\":\"Seok-Il Hong\"},{\"authorId\":\"3458134\",\"name\":\"Gyeongsik Moon\"},{\"authorId\":\"4640997\",\"name\":\"Sanghyun Son\"},{\"authorId\":\"2135837\",\"name\":\"Kyoung Mu Lee\"},{\"authorId\":\"47119707\",\"name\":\"Xintao Wang\"},{\"authorId\":\"12009218\",\"name\":\"Kelvin C. K. Chan\"},{\"authorId\":\"1482485970\",\"name\":\"Ke Yu\"},{\"authorId\":\"30459277\",\"name\":\"C. Dong\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"},{\"authorId\":\"143668321\",\"name\":\"Yuchen Fan\"},{\"authorId\":\"150167366\",\"name\":\"Jiahui Yu\"},{\"authorId\":\"39332427\",\"name\":\"D. Liu\"},{\"authorId\":\"1739208\",\"name\":\"T. Huang\"},{\"authorId\":null,\"name\":\"Xiao Liu\"},{\"authorId\":\"1414569274\",\"name\":\"Chao Li\"},{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"14668667\",\"name\":\"Yukang Ding\"},{\"authorId\":\"35247507\",\"name\":\"Shilei Wen\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"},{\"authorId\":\"2563691\",\"name\":\"R. Kalarot\"},{\"authorId\":\"153735675\",\"name\":\"Muhammad Haris\"},{\"authorId\":\"2490189\",\"name\":\"Gregory Shakhnarovich\"},{\"authorId\":\"3081689\",\"name\":\"N. Ukita\"},{\"authorId\":\"38467984\",\"name\":\"Peng Yi\"},{\"authorId\":\"38655501\",\"name\":\"Zhongyuan Wang\"},{\"authorId\":\"51360637\",\"name\":\"Kui Jiang\"},{\"authorId\":\"1708439\",\"name\":\"J. Jiang\"},{\"authorId\":\"8555475\",\"name\":\"Jiayi Ma\"},{\"authorId\":\"1500397702\",\"name\":\"Hang Dong\"},{\"authorId\":\"143850015\",\"name\":\"X. Zhang\"},{\"authorId\":\"144869273\",\"name\":\"Zhe Hu\"},{\"authorId\":\"2159594\",\"name\":\"Kwan-Young Kim\"},{\"authorId\":\"1417474762\",\"name\":\"Dong Un Kang\"},{\"authorId\":\"34971370\",\"name\":\"S. Chun\"},{\"authorId\":\"8107818\",\"name\":\"K. Purohit\"},{\"authorId\":\"143891066\",\"name\":\"A. Rajagopalan\"},{\"authorId\":\"34777509\",\"name\":\"Yapeng Tian\"},{\"authorId\":\"2410227\",\"name\":\"Yulun Zhang\"},{\"authorId\":\"145692782\",\"name\":\"Yun Fu\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"},{\"authorId\":\"1747853\",\"name\":\"A. Tekalp\"},{\"authorId\":\"50644949\",\"name\":\"M. Yilmaz\"},{\"authorId\":\"89944783\",\"name\":\"C. Korkmaz\"},{\"authorId\":\"152877244\",\"name\":\"M. Sharma\"},{\"authorId\":\"48454422\",\"name\":\"Megh Makwana\"},{\"authorId\":\"150893294\",\"name\":\"A. Badhwar\"},{\"authorId\":\"96453604\",\"name\":\"A. P. Singh\"},{\"authorId\":\"153918267\",\"name\":\"Avinash Upadhyay\"},{\"authorId\":\"41052499\",\"name\":\"R. Mukhopadhyay\"},{\"authorId\":\"1404142920\",\"name\":\"Ankit Shukla\"},{\"authorId\":\"1644942104\",\"name\":\"Dheeraj Khanna\"},{\"authorId\":\"144819665\",\"name\":\"A. Mandal\"},{\"authorId\":\"144725842\",\"name\":\"S. Chaudhury\"},{\"authorId\":\"9267486\",\"name\":\"Si Miao\"},{\"authorId\":\"49780784\",\"name\":\"Y. Zhu\"},{\"authorId\":\"144140995\",\"name\":\"X. Huo\"}],\"doi\":\"10.1109/CVPRW.2019.00250\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"098d7a729c7df5a47e83179e056a00101d74b90f\",\"title\":\"NTIRE 2019 Challenge on Video Super-Resolution: Methods and Results\",\"url\":\"https://www.semanticscholar.org/paper/098d7a729c7df5a47e83179e056a00101d74b90f\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":\"1812.00568\",\"authors\":[{\"authorId\":\"27535721\",\"name\":\"Frederik Ebert\"},{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"},{\"authorId\":\"36076404\",\"name\":\"Sudeep Dasari\"},{\"authorId\":\"14484808\",\"name\":\"Annie Xie\"},{\"authorId\":\"49250083\",\"name\":\"Alex X. Lee\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"54cd5a5ddd286442fa94da7ec344a7e76b9a6ccd\",\"title\":\"Visual Foresight: Model-Based Deep Reinforcement Learning for Vision-Based Robotic Control\",\"url\":\"https://www.semanticscholar.org/paper/54cd5a5ddd286442fa94da7ec344a7e76b9a6ccd\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2003302045\",\"name\":\"Rahul Vanam\"},{\"authorId\":\"1694122\",\"name\":\"Y. Reznik\"}],\"doi\":\"10.1109/ICIP40778.2020.9191325\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1c9979628e4aaaeed4ce259b8afd1aa58919297a\",\"title\":\"Frame Rate Up-Conversion Using Bi-Directional Optical Flows With Dual Regularization\",\"url\":\"https://www.semanticscholar.org/paper/1c9979628e4aaaeed4ce259b8afd1aa58919297a\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"2011.09697\",\"authors\":[{\"authorId\":\"143944802\",\"name\":\"M. Ali\"},{\"authorId\":\"2026855912\",\"name\":\"Sangjoon Yu\"},{\"authorId\":\"40592441\",\"name\":\"T. Kim\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"20a1dc1ab646c3487360ea43a1d28a56615c929e\",\"title\":\"Learning Deep Video Stabilization without Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/20a1dc1ab646c3487360ea43a1d28a56615c929e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9508145\",\"name\":\"Morten Hannemose\"},{\"authorId\":\"144454181\",\"name\":\"Janus N\\u00f8rtoft Jensen\"},{\"authorId\":\"48660142\",\"name\":\"G. Einarsson\"},{\"authorId\":\"2579225\",\"name\":\"J. Wilm\"},{\"authorId\":\"2253200\",\"name\":\"A. Dahl\"},{\"authorId\":\"2661305\",\"name\":\"J. Frisvad\"}],\"doi\":\"10.1007/978-3-030-20205-7_26\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7eb50a9f19eefb7db02d5955edc6c681a5d23e72\",\"title\":\"Video Frame Interpolation via Cyclic Fine-Tuning and Asymmetric Reverse Flow\",\"url\":\"https://www.semanticscholar.org/paper/7eb50a9f19eefb7db02d5955edc6c681a5d23e72\",\"venue\":\"SCIA\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3220632\",\"name\":\"Hao Tao\"},{\"authorId\":\"144906876\",\"name\":\"L. Yu\"},{\"authorId\":\"121423004\",\"name\":\"Zhuo Kuang\"},{\"authorId\":\"1486522700\",\"name\":\"Hongkui Wang\"},{\"authorId\":\"46423009\",\"name\":\"Xiaofeng Huang\"}],\"doi\":\"10.1109/PCS48520.2019.8954532\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1941c4d5e50adcc7ba143b3d596e558e81bad000\",\"title\":\"An Extended Skip Strategy for Inter Prediction\",\"url\":\"https://www.semanticscholar.org/paper/1941c4d5e50adcc7ba143b3d596e558e81bad000\",\"venue\":\"2019 Picture Coding Symposium (PCS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46179701\",\"name\":\"Yicun Liu\"},{\"authorId\":\"145345504\",\"name\":\"JiaWei Zhang\"},{\"authorId\":\"1485278258\",\"name\":\"Ye Ma\"},{\"authorId\":\"145335572\",\"name\":\"J. Ren\"}],\"doi\":\"10.1109/WACV45572.2020.9093472\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"50383869a54f2070ef7cd470880835bed3429e91\",\"title\":\"Self-Guided Novel View Synthesis via Elastic Displacement Network\",\"url\":\"https://www.semanticscholar.org/paper/50383869a54f2070ef7cd470880835bed3429e91\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"2002.11263\",\"authors\":[{\"authorId\":\"143834621\",\"name\":\"J. Jin\"},{\"authorId\":\"40630305\",\"name\":\"J. Hou\"},{\"authorId\":\"48118954\",\"name\":\"Heng Yuan\"},{\"authorId\":\"1687386\",\"name\":\"S. Kwong\"}],\"doi\":\"10.1609/AAAI.V34I07.6771\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"418be6752cfdf0a04698e0b72b5c923ecd75c9bb\",\"title\":\"Learning Light Field Angular Super-Resolution via a Geometry-Aware Network\",\"url\":\"https://www.semanticscholar.org/paper/418be6752cfdf0a04698e0b72b5c923ecd75c9bb\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2007.11762\",\"authors\":[{\"authorId\":\"35793956\",\"name\":\"Zhixiang Chi\"},{\"authorId\":\"49456126\",\"name\":\"R. Nasiri\"},{\"authorId\":\"2114344\",\"name\":\"Z. Liu\"},{\"authorId\":\"150152476\",\"name\":\"Juwei Lu\"},{\"authorId\":\"37864689\",\"name\":\"Jin Tang\"},{\"authorId\":\"37932469\",\"name\":\"K. Plataniotis\"}],\"doi\":\"10.1007/978-3-030-58583-9_7\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e07d015d548162756e479934b245299e4aa737d0\",\"title\":\"All at Once: Temporally Adaptive Multi-Frame Interpolation with Advanced Motion Modeling\",\"url\":\"https://www.semanticscholar.org/paper/e07d015d548162756e479934b245299e4aa737d0\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34246012\",\"name\":\"Ryan Szeto\"},{\"authorId\":\"46793780\",\"name\":\"Ximeng Sun\"},{\"authorId\":\"103356373\",\"name\":\"Kunyi Lu\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1109/TPAMI.2019.2951667\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"64dadf96304f65af96fc6b4f82c11bc69589f547\",\"title\":\"A Temporally-Aware Interpolation Network for Video Frame Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/64dadf96304f65af96fc6b4f82c11bc69589f547\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":\"1904.01693\",\"authors\":[{\"authorId\":\"34362536\",\"name\":\"S. Kong\"},{\"authorId\":\"143800213\",\"name\":\"Charless C. Fowlkes\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"225dc18db507147de068710839941900996a7329\",\"title\":\"Multigrid Predictive Filter Flow for Unsupervised Learning on Videos\",\"url\":\"https://www.semanticscholar.org/paper/225dc18db507147de068710839941900996a7329\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"98f54360f4b3396523d130aab335ce757e37c6ec\",\"title\":\"Learning to Restore ssTEM Images from Deformation and Corruption\",\"url\":\"https://www.semanticscholar.org/paper/98f54360f4b3396523d130aab335ce757e37c6ec\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145824256\",\"name\":\"S. Jin\"},{\"authorId\":\"80848808\",\"name\":\"Ruiynag Liu\"},{\"authorId\":\"145306197\",\"name\":\"Y. Ji\"},{\"authorId\":\"2431628\",\"name\":\"J. Ye\"},{\"authorId\":\"2152356\",\"name\":\"J. Yu\"}],\"doi\":\"10.1007/978-3-030-01264-9_14\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"95249f6e5d5e1b25d307db6e82e224e09beb5775\",\"title\":\"Learning to Dodge A Bullet: Concyclic View Morphing via Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/95249f6e5d5e1b25d307db6e82e224e09beb5775\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"},{\"authorId\":\"40913232\",\"name\":\"P. Chen\"},{\"authorId\":\"1381434830\",\"name\":\"Alfredo Cuzzocrea\"},{\"authorId\":\"46993406\",\"name\":\"Xiaoyong Du\"},{\"authorId\":\"144408238\",\"name\":\"Orhun Kara\"},{\"authorId\":\"152244126\",\"name\":\"Ting Liu\"},{\"authorId\":\"1731022\",\"name\":\"K. Sivalingam\"},{\"authorId\":\"145514738\",\"name\":\"D. Slezak\"},{\"authorId\":\"1704749\",\"name\":\"T. Washio\"},{\"authorId\":\"50031361\",\"name\":\"X. Yang\"},{\"authorId\":\"145078769\",\"name\":\"J. Yuan\"},{\"authorId\":\"145337089\",\"name\":\"S. Barbosa\"},{\"authorId\":\"2977267\",\"name\":\"A. P. Cl\\u00e1udio\"},{\"authorId\":\"1767919\",\"name\":\"K. Bouatouch\"},{\"authorId\":\"2571670\",\"name\":\"Manuela Chessa\"},{\"authorId\":\"1717982\",\"name\":\"A. Paljic\"},{\"authorId\":\"2569160\",\"name\":\"A. Kerren\"},{\"authorId\":\"2433007\",\"name\":\"C. Hurter\"},{\"authorId\":\"1704567\",\"name\":\"A. Tr\\u00e9meau\"}],\"doi\":\"10.1007/978-3-030-41590-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bfd34a5453210cfd476d9ba8e2be5c47fcb7eaf7\",\"title\":\"Computer Vision, Imaging and Computer Graphics Theory and Applications: 14th International Joint Conference, VISIGRAPP 2019, Prague, Czech Republic, February 25\\u201327, 2019, Revised Selected Papers\",\"url\":\"https://www.semanticscholar.org/paper/bfd34a5453210cfd476d9ba8e2be5c47fcb7eaf7\",\"venue\":\"VISIGRAPP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48795116\",\"name\":\"H. W. F. Yeung\"},{\"authorId\":\"40630305\",\"name\":\"J. Hou\"},{\"authorId\":\"1800745\",\"name\":\"J. Chen\"},{\"authorId\":\"1798753\",\"name\":\"Y. Y. Chung\"},{\"authorId\":\"39717899\",\"name\":\"X. Chen\"}],\"doi\":\"10.1007/978-3-030-01231-1_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4586cb1b10832f5594894e8ab39ba5cd9b36c8ad\",\"title\":\"Fast Light Field Reconstruction with Deep Coarse-to-Fine Modeling of Spatial-Angular Clues\",\"url\":\"https://www.semanticscholar.org/paper/4586cb1b10832f5594894e8ab39ba5cd9b36c8ad\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49890383\",\"name\":\"Yu Zhang\"},{\"authorId\":\"2780914\",\"name\":\"Dongqing Zou\"},{\"authorId\":\"145335572\",\"name\":\"J. Ren\"},{\"authorId\":\"144667540\",\"name\":\"Z. Jiang\"},{\"authorId\":\"10775732\",\"name\":\"Xiaohao Chen\"}],\"doi\":\"10.1109/CVPR.2019.00601\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"06e89127926108353b02fd64e60e80fc24412816\",\"title\":\"Structure-Preserving Stereoscopic View Synthesis With Multi-Scale Adversarial Correlation Matching\",\"url\":\"https://www.semanticscholar.org/paper/06e89127926108353b02fd64e60e80fc24412816\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2003.08865\",\"authors\":[{\"authorId\":\"152128102\",\"name\":\"Yuan Gao\"},{\"authorId\":\"2340064\",\"name\":\"R. Bregovic\"},{\"authorId\":\"144839904\",\"name\":\"R. Koch\"},{\"authorId\":\"1799559\",\"name\":\"A. Gotchev\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"578b97e26768e117768b034ba113f1f1b284ee36\",\"title\":\"DRST: Deep Residual Shearlet Transform for Densely Sampled Light Field Reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/578b97e26768e117768b034ba113f1f1b284ee36\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10399052\",\"name\":\"Irene Viola\"},{\"authorId\":\"32111266\",\"name\":\"J. Mulder\"},{\"authorId\":\"36517415\",\"name\":\"F. Simone\"},{\"authorId\":\"144022557\",\"name\":\"P. C\\u00e9sar\"}],\"doi\":\"10.1109/AIVR46125.2019.00022\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7d5101a12d7f38f23e92952dcdada2c8b79aeb3e\",\"title\":\"Temporal Interpolation of Dynamic Digital Humans using Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/7d5101a12d7f38f23e92952dcdada2c8b79aeb3e\",\"venue\":\"2019 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"88677858\",\"name\":\"Juan Luis Gonzalez Bello\"},{\"authorId\":\"123446757\",\"name\":\"M. Kim\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4e6d4c7235fe0a4decd34b4964d4a11b9755a0c2\",\"title\":\"LUTIONS WITH GLOBAL AND LOCAL ADAPTIVE DILA- TIONS\",\"url\":\"https://www.semanticscholar.org/paper/4e6d4c7235fe0a4decd34b4964d4a11b9755a0c2\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"102510752\",\"name\":\"W. Shen\"},{\"authorId\":\"8613898\",\"name\":\"Wenbo Bao\"},{\"authorId\":\"144826391\",\"name\":\"Guangtao Zhai\"},{\"authorId\":\"152875291\",\"name\":\"L. Chen\"},{\"authorId\":\"2246414\",\"name\":\"Xiongkuo Min\"},{\"authorId\":\"153731442\",\"name\":\"Zhiyong Gao\"}],\"doi\":\"10.1109/TIP.2020.3033617\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a3f5ff974ab479ebbe3fa533522c12253204bec1\",\"title\":\"Video Frame Interpolation and Enhancement via Pyramid Recurrent Framework\",\"url\":\"https://www.semanticscholar.org/paper/a3f5ff974ab479ebbe3fa533522c12253204bec1\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2021},{\"arxivId\":\"2012.10066\",\"authors\":[{\"authorId\":\"143611184\",\"name\":\"Fan Lu\"},{\"authorId\":\"143930563\",\"name\":\"G. Chen\"},{\"authorId\":\"52532366\",\"name\":\"Sanqing Qu\"},{\"authorId\":\"46946977\",\"name\":\"Zhijun Li\"},{\"authorId\":\"2341727\",\"name\":\"Y. Liu\"},{\"authorId\":\"152948808\",\"name\":\"A. Knoll\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b7e6377d5d5d42c8b06a197465a281624dca8a4d\",\"title\":\"PointINet: Point Cloud Frame Interpolation Network\",\"url\":\"https://www.semanticscholar.org/paper/b7e6377d5d5d42c8b06a197465a281624dca8a4d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2006.10300\",\"authors\":[{\"authorId\":\"48148100\",\"name\":\"Zhiyu Zhu\"},{\"authorId\":\"40630305\",\"name\":\"J. Hou\"},{\"authorId\":\"50762898\",\"name\":\"Jie Chen\"},{\"authorId\":\"72910910\",\"name\":\"Huanqiang Zeng\"},{\"authorId\":\"1735685\",\"name\":\"Jiantao Zhou\"}],\"doi\":\"10.1109/TIP.2020.3044214\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1fef46d8af2ef066da2b415c3a2d9ae22c02762a\",\"title\":\"Hyperspectral Image Super-resolution via Deep Progressive Zero-centric Residual Learning\",\"url\":\"https://www.semanticscholar.org/paper/1fef46d8af2ef066da2b415c3a2d9ae22c02762a\",\"venue\":\"IEEE transactions on image processing : a publication of the IEEE Signal Processing Society\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1762967\",\"name\":\"J. Munkberg\"},{\"authorId\":\"2266452\",\"name\":\"J. Hasselgren\"}],\"doi\":\"10.1111/cgf.14049\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"42f9541fa8d48370e87043450c8c4ab2a8d9c187\",\"title\":\"Neural Denoising with Layer Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/42f9541fa8d48370e87043450c8c4ab2a8d9c187\",\"venue\":\"Comput. Graph. Forum\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152128102\",\"name\":\"Yuan Gao\"},{\"authorId\":\"2340064\",\"name\":\"R. Bregovic\"},{\"authorId\":\"1799559\",\"name\":\"A. Gotchev\"},{\"authorId\":\"144839904\",\"name\":\"R. Koch\"}],\"doi\":\"10.1109/ICME.2019.00040\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e64ee0308d0223ce0ff06d071dd6c628baf2e9fc\",\"title\":\"MAST: Mask-Accelerated Shearlet Transform for Densely-Sampled Light Field Reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/e64ee0308d0223ce0ff06d071dd6c628baf2e9fc\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":\"1803.07218\",\"authors\":[{\"authorId\":\"46793780\",\"name\":\"Ximeng Sun\"},{\"authorId\":\"34246012\",\"name\":\"Ryan Szeto\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1007/978-3-030-20893-6_16\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3819d2b6992be3e224e90371cc83bc5c60345e63\",\"title\":\"A Temporally-Aware Interpolation Network for Video Frame Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/3819d2b6992be3e224e90371cc83bc5c60345e63\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1557382867\",\"name\":\"Siyao Li\"},{\"authorId\":\"48669892\",\"name\":\"Xiangyu Xu\"},{\"authorId\":\"98350705\",\"name\":\"Z. Pan\"},{\"authorId\":\"8397576\",\"name\":\"Wenxiu Sun\"}],\"doi\":\"10.1109/ICCVW.2019.00425\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e83e0bb28817b7dde11c973e8efb8b1b7e0b2e92\",\"title\":\"Quadratic Video Interpolation for VTSR Challenge\",\"url\":\"https://www.semanticscholar.org/paper/e83e0bb28817b7dde11c973e8efb8b1b7e0b2e92\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2744923\",\"name\":\"L. Zhou\"},{\"authorId\":\"2573672\",\"name\":\"Yaowu Chen\"},{\"authorId\":\"145037825\",\"name\":\"Xiang Tian\"},{\"authorId\":\"3115947\",\"name\":\"Rongxin Jiang\"}],\"doi\":\"10.1109/ICIP.2019.8803678\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a3078e39137a59af12f49a985c3b1e1765d51eba\",\"title\":\"Frame Interpolation Using Phase and Amplitude Feature Pyramids\",\"url\":\"https://www.semanticscholar.org/paper/a3078e39137a59af12f49a985c3b1e1765d51eba\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"1901.00062\",\"authors\":[{\"authorId\":\"3320198\",\"name\":\"Hyomin Choi\"},{\"authorId\":\"1730101\",\"name\":\"I. Bajic\"}],\"doi\":\"10.1109/TCSVT.2019.2924657\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"61d4062392f476edf0346900cef020ef18cd1760\",\"title\":\"Deep Frame Prediction for Video Coding\",\"url\":\"https://www.semanticscholar.org/paper/61d4062392f476edf0346900cef020ef18cd1760\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"1909.01341\",\"authors\":[{\"authorId\":\"1500385929\",\"name\":\"Jing Jin\"},{\"authorId\":\"40630305\",\"name\":\"J. Hou\"},{\"authorId\":\"50762898\",\"name\":\"Jie Chen\"},{\"authorId\":\"1747380\",\"name\":\"H. Zeng\"},{\"authorId\":\"1687386\",\"name\":\"S. Kwong\"},{\"authorId\":\"47891011\",\"name\":\"Jingyi Yu\"}],\"doi\":\"10.1109/TPAMI.2020.3026039\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fca47422bf67fb621b6eb58613c75936bc679880\",\"title\":\"Deep Coarse-to-fine Dense Light Field Reconstruction with Flexible Sampling and Geometry-aware Fusion.\",\"url\":\"https://www.semanticscholar.org/paper/fca47422bf67fb621b6eb58613c75936bc679880\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"2003.11209\",\"authors\":[{\"authorId\":\"120026004\",\"name\":\"Y. Zhou\"},{\"authorId\":\"49394654\",\"name\":\"Jianfeng Xu\"},{\"authorId\":\"2764854\",\"name\":\"K. Tasaka\"},{\"authorId\":\"143912275\",\"name\":\"Zhibo Chen\"},{\"authorId\":\"89187407\",\"name\":\"W. Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"12d1c0279b81bb86e2163b35d1d56156eaaf15a4\",\"title\":\"Prior-enlightened and Motion-robust Video Deblurring\",\"url\":\"https://www.semanticscholar.org/paper/12d1c0279b81bb86e2163b35d1d56156eaaf15a4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.13170\",\"authors\":[{\"authorId\":\"145879931\",\"name\":\"M. Haris\"},{\"authorId\":\"46208708\",\"name\":\"G. Shakhnarovich\"},{\"authorId\":\"3081689\",\"name\":\"N. Ukita\"}],\"doi\":\"10.1109/CVPR42600.2020.00293\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c54199e6f1f9553ab32148f60c7e49af55cc1d6a\",\"title\":\"Space-Time-Aware Multi-Resolution Video Enhancement\",\"url\":\"https://www.semanticscholar.org/paper/c54199e6f1f9553ab32148f60c7e49af55cc1d6a\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123878263\",\"name\":\"Pierre A. David\"},{\"authorId\":\"51232337\",\"name\":\"Mika\\u00ebl Le Pendu\"},{\"authorId\":\"1780587\",\"name\":\"C. Guillemot\"}],\"doi\":\"10.1109/icme46284.2020.9102968\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5d3824523feb057b01c90efe3e1fbcb1bc84f83e\",\"title\":\"Angularly Consistent Light Field Video Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/5d3824523feb057b01c90efe3e1fbcb1bc84f83e\",\"venue\":\"2020 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40648435\",\"name\":\"Seungjun Nah\"},{\"authorId\":\"1732855\",\"name\":\"R. Timofte\"},{\"authorId\":\"148009160\",\"name\":\"Sungyong Baik\"},{\"authorId\":\"150297656\",\"name\":\"Seokil Hong\"},{\"authorId\":\"3458134\",\"name\":\"Gyeongsik Moon\"},{\"authorId\":\"4640997\",\"name\":\"Sanghyun Son\"},{\"authorId\":\"2135837\",\"name\":\"Kyoung Mu Lee\"},{\"authorId\":\"47119707\",\"name\":\"Xintao Wang\"},{\"authorId\":\"12009218\",\"name\":\"Kelvin C. K. Chan\"},{\"authorId\":\"1482485970\",\"name\":\"Ke Yu\"},{\"authorId\":\"30459277\",\"name\":\"C. Dong\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"},{\"authorId\":\"143668321\",\"name\":\"Yuchen Fan\"},{\"authorId\":\"150167366\",\"name\":\"Jiahui Yu\"},{\"authorId\":\"39332427\",\"name\":\"D. Liu\"},{\"authorId\":\"1739208\",\"name\":\"T. Huang\"},{\"authorId\":\"72551720\",\"name\":\"Hyeonjun Sim\"},{\"authorId\":\"144366095\",\"name\":\"M. Kim\"},{\"authorId\":\"1596817608\",\"name\":\"Dongwon Park\"},{\"authorId\":\"30855666\",\"name\":\"J. Kim\"},{\"authorId\":\"34971370\",\"name\":\"S. Chun\"},{\"authorId\":\"153735675\",\"name\":\"Muhammad Haris\"},{\"authorId\":\"2490189\",\"name\":\"Gregory Shakhnarovich\"},{\"authorId\":\"3081689\",\"name\":\"N. Ukita\"},{\"authorId\":\"3323621\",\"name\":\"Syed Waqas Zamir\"},{\"authorId\":\"153150198\",\"name\":\"Aditya Arora\"},{\"authorId\":\"1508543349\",\"name\":\"Salman Khan\"},{\"authorId\":\"2358803\",\"name\":\"F. Khan\"},{\"authorId\":\"144951205\",\"name\":\"Ling Shao\"},{\"authorId\":\"153382031\",\"name\":\"R. Gupta\"},{\"authorId\":\"38824959\",\"name\":\"Vishal M. Chudasama\"},{\"authorId\":\"48270906\",\"name\":\"Heena Patel\"},{\"authorId\":\"3004725\",\"name\":\"K. Upla\"},{\"authorId\":\"33908381\",\"name\":\"Hongfei Fan\"},{\"authorId\":\"30368089\",\"name\":\"Guo Li\"},{\"authorId\":\"1591118895\",\"name\":\"Yumei Zhang\"},{\"authorId\":\"47875796\",\"name\":\"Xiang Li\"},{\"authorId\":\"19262604\",\"name\":\"W. Zhang\"},{\"authorId\":\"1491483086\",\"name\":\"Qingwen He\"},{\"authorId\":\"8107818\",\"name\":\"K. Purohit\"},{\"authorId\":\"143891066\",\"name\":\"A. Rajagopalan\"},{\"authorId\":\"1590804685\",\"name\":\"Jeonghun Kim\"},{\"authorId\":\"1792080\",\"name\":\"Mohammad Tofighi\"},{\"authorId\":\"151231303\",\"name\":\"Tiantong Guo\"},{\"authorId\":\"3346079\",\"name\":\"V. Monga\"}],\"doi\":\"10.1109/CVPRW.2019.00249\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"13bd21fb44696c9a556e222cbc540243fdc284ae\",\"title\":\"NTIRE 2019 Challenge on Video Deblurring: Methods and Results\",\"url\":\"https://www.semanticscholar.org/paper/13bd21fb44696c9a556e222cbc540243fdc284ae\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143691153\",\"name\":\"T. Zhang\"},{\"authorId\":\"7465771\",\"name\":\"Huihui Bai\"},{\"authorId\":\"49515937\",\"name\":\"F. Li\"},{\"authorId\":\"38161033\",\"name\":\"Y. Zhao\"}],\"doi\":\"10.23919/APSIPA.2018.8659604\",\"intent\":[\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"3eb35c73be67f57c12c184c527f49c7915b0a894\",\"title\":\"Optical Flow-Guided Multi-Scale Dense Network for Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/3eb35c73be67f57c12c184c527f49c7915b0a894\",\"venue\":\"2018 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153690347\",\"name\":\"Yoonmo Yang\"},{\"authorId\":\"1831183\",\"name\":\"Byung Tae Oh\"}],\"doi\":\"10.1016/j.image.2020.115982\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a18bd84728b5d9e3208dcc4ce9bbe11d2c0fca1c\",\"title\":\"Video frame interpolation using deep cascaded network structure\",\"url\":\"https://www.semanticscholar.org/paper/a18bd84728b5d9e3208dcc4ce9bbe11d2c0fca1c\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2020},{\"arxivId\":\"2007.02501\",\"authors\":[{\"authorId\":\"116046679\",\"name\":\"Zixu Zhao\"},{\"authorId\":\"33981465\",\"name\":\"Yueming Jin\"},{\"authorId\":\"143953230\",\"name\":\"Xiaojie Gao\"},{\"authorId\":\"46981662\",\"name\":\"Qi Dou\"},{\"authorId\":\"72434829\",\"name\":\"P. Heng\"}],\"doi\":\"10.1007/978-3-030-59716-0_65\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"434c8edb70cb682691f1c677a18b681edf709e06\",\"title\":\"Learning Motion Flows for Semi-supervised Instrument Segmentation from Robotic Surgical Video\",\"url\":\"https://www.semanticscholar.org/paper/434c8edb70cb682691f1c677a18b681edf709e06\",\"venue\":\"MICCAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152128102\",\"name\":\"Yuan Gao\"},{\"authorId\":\"144839904\",\"name\":\"R. Koch\"},{\"authorId\":\"2340064\",\"name\":\"R. Bregovic\"},{\"authorId\":\"1799559\",\"name\":\"A. Gotchev\"}],\"doi\":\"10.23919/EUSIPCO.2019.8903168\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7dab3d6708d1032403a50d2a3202ae9aea4b94d2\",\"title\":\"IEST: Interpolation-Enhanced Shearlet Transform for Light Field Reconstruction Using Adaptive Separable Convolution\",\"url\":\"https://www.semanticscholar.org/paper/7dab3d6708d1032403a50d2a3202ae9aea4b94d2\",\"venue\":\"2019 27th European Signal Processing Conference (EUSIPCO)\",\"year\":2019},{\"arxivId\":\"2008.10162\",\"authors\":[{\"authorId\":\"1900527137\",\"name\":\"Jingwei Xu\"},{\"authorId\":\"3286703\",\"name\":\"Huazhe Xu\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"15469693\",\"name\":\"Xiaokang Yang\"},{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1007/978-3-030-58621-8_11\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a413973f74e250b69990c39ed4f1ca07c523c432\",\"title\":\"Hierarchical Style-based Networks for Motion Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/a413973f74e250b69990c39ed4f1ca07c523c432\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2009.01005\",\"authors\":[{\"authorId\":\"150015249\",\"name\":\"Akash Gupta\"},{\"authorId\":\"2274692\",\"name\":\"Abhishek Aich\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":\"10.1145/3394171.3413686\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3ed87dfe5ec1b3efa33016adf188d6d772aaef62\",\"title\":\"ALANET: Adaptive Latent Attention Network for Joint Video Deblurring and Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/3ed87dfe5ec1b3efa33016adf188d6d772aaef62\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2663413\",\"name\":\"Z. Jin\"},{\"authorId\":\"145815040\",\"name\":\"Ping An\"},{\"authorId\":\"1683512\",\"name\":\"Liquan Shen\"}],\"doi\":\"10.1016/J.NEUCOM.2019.02.064\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"89f4793dc4f7ab18114437d7d5f0717c496f0aa1\",\"title\":\"Video intra prediction using convolutional encoder decoder network\",\"url\":\"https://www.semanticscholar.org/paper/89f4793dc4f7ab18114437d7d5f0717c496f0aa1\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143805731\",\"name\":\"L. Zhao\"},{\"authorId\":\"1705047\",\"name\":\"S. Wang\"},{\"authorId\":\"3175853\",\"name\":\"Xinfeng Zhang\"},{\"authorId\":\"1755176\",\"name\":\"Shanshe Wang\"},{\"authorId\":\"10634370\",\"name\":\"S. Ma\"},{\"authorId\":\"48385803\",\"name\":\"W. Gao\"}],\"doi\":\"10.1109/TIP.2019.2913545\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"47eea66c92a8e6f9fbb8497eb83f24540874eb70\",\"title\":\"Enhanced Motion-Compensated Video Coding With Deep Virtual Reference Frame Generation\",\"url\":\"https://www.semanticscholar.org/paper/47eea66c92a8e6f9fbb8497eb83f24540874eb70\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1764950\",\"name\":\"V. Ricordel\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"41d7d51fd1d39fa5243d4800f34b01cf967cf9f8\",\"title\":\"Outils et m\\u00e9thodes pour le codage vid\\u00e9o perceptuel\",\"url\":\"https://www.semanticscholar.org/paper/41d7d51fd1d39fa5243d4800f34b01cf967cf9f8\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2594429\",\"name\":\"Na-Young Kim\"},{\"authorId\":\"79933654\",\"name\":\"Jung Kyung Lee\"},{\"authorId\":\"16264878\",\"name\":\"Chae Hwa Yoo\"},{\"authorId\":\"3204439\",\"name\":\"Seunghyun Cho\"},{\"authorId\":\"52177701\",\"name\":\"Je-Won Kang\"}],\"doi\":\"10.23919/APSIPA.2018.8659743\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"da3c857fe575d95d3f3806e22bb28fb6a8b26306\",\"title\":\"Video Generation and Synthesis Network for Long-term Video Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/da3c857fe575d95d3f3806e22bb28fb6a8b26306\",\"venue\":\"2018 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8613898\",\"name\":\"Wenbo Bao\"},{\"authorId\":\"2268189\",\"name\":\"Wei-Sheng Lai\"},{\"authorId\":\"144992103\",\"name\":\"C. Ma\"},{\"authorId\":\"49469756\",\"name\":\"X. Zhang\"},{\"authorId\":\"145071557\",\"name\":\"Z. Gao\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"77f5496935d01c06a4e0c301be42d388e9d73a99\",\"title\":\"Depth-Aware Video Frame Interpolation Supplementary Material\",\"url\":\"https://www.semanticscholar.org/paper/77f5496935d01c06a4e0c301be42d388e9d73a99\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1412432168\",\"name\":\"Simone Schaub-Meyer\"}],\"doi\":\"10.3929/ethz-b-000315026\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"971b2b96c43e5dc0bd2946a1de92e1072a36f82a\",\"title\":\"Video Frame Interpolation and Editing with Implicit Motion Estimation\",\"url\":\"https://www.semanticscholar.org/paper/971b2b96c43e5dc0bd2946a1de92e1072a36f82a\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1909.04391\",\"authors\":[{\"authorId\":\"5168807\",\"name\":\"Soo Ye Kim\"},{\"authorId\":\"107606159\",\"name\":\"Jihyong Oh\"},{\"authorId\":\"123446757\",\"name\":\"M. Kim\"}],\"doi\":\"10.1609/AAAI.V34I07.6789\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c0fc2813735c4f089ba50aa71f73b6429597cb16\",\"title\":\"JSI-GAN: GAN-Based Joint Super-Resolution and Inverse Tone-Mapping with Pixel-Wise Task-Specific Filters for UHD HDR Video\",\"url\":\"https://www.semanticscholar.org/paper/c0fc2813735c4f089ba50aa71f73b6429597cb16\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2006.15617\",\"authors\":[{\"authorId\":\"1390625723\",\"name\":\"Zhihao Liu\"},{\"authorId\":\"153010888\",\"name\":\"Hailiang Yin\"},{\"authorId\":\"1737825594\",\"name\":\"Y. Mi\"},{\"authorId\":\"51516578\",\"name\":\"Mengyang Pu\"},{\"authorId\":\"40696794\",\"name\":\"Song Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0b41b79d35605cec59f36642c375a18b58d45144\",\"title\":\"Shadow Removal by a Lightness-Guided Network with Training on Unpaired Data\",\"url\":\"https://www.semanticscholar.org/paper/0b41b79d35605cec59f36642c375a18b58d45144\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.02432\",\"authors\":[{\"authorId\":\"2784241\",\"name\":\"Jaeyeon Kang\"},{\"authorId\":\"50008226\",\"name\":\"Younghyun Jo\"},{\"authorId\":\"3451982\",\"name\":\"S. Oh\"},{\"authorId\":\"48682997\",\"name\":\"P. Vajda\"},{\"authorId\":\"1754380\",\"name\":\"S. Kim\"}],\"doi\":\"10.1007/978-3-030-58607-2_41\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fa3392f59cbf455a2083af5a4690903a0dbc15c8\",\"title\":\"Deep Space-Time Video Upsampling Networks\",\"url\":\"https://www.semanticscholar.org/paper/fa3392f59cbf455a2083af5a4690903a0dbc15c8\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144395844\",\"name\":\"Y. Chen\"}],\"doi\":\"10.1109/SIPROCESS.2019.8868640\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7d5cbb699a5e4a1f6bd7c3f477c76d80154bf677\",\"title\":\"Combine Voxel Flow and Adaptive Convolutional Kernel for Video Colorization\",\"url\":\"https://www.semanticscholar.org/paper/7d5cbb699a5e4a1f6bd7c3f477c76d80154bf677\",\"venue\":\"2019 IEEE 4th International Conference on Signal and Image Processing (ICSIP)\",\"year\":2019},{\"arxivId\":\"2008.04149\",\"authors\":[{\"authorId\":\"1597361648\",\"name\":\"Xiaoyu Li\"},{\"authorId\":\"1723442179\",\"name\":\"Bo Zhang\"},{\"authorId\":\"1851024702\",\"name\":\"Jing Liao\"},{\"authorId\":\"145891472\",\"name\":\"Pedro V. Sander\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"034300b0576f3291c8bb5f29bd9ef221d4244c6b\",\"title\":\"Deep Sketch-guided Cartoon Video Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/034300b0576f3291c8bb5f29bd9ef221d4244c6b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.05534\",\"authors\":[{\"authorId\":\"39644974\",\"name\":\"Simon Niklaus\"},{\"authorId\":\"98220548\",\"name\":\"F. Liu\"}],\"doi\":\"10.1109/CVPR42600.2020.00548\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"82da38e2ddd8aebbc13d9e4505bc86ad83c0d6da\",\"title\":\"Softmax Splatting for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/82da38e2ddd8aebbc13d9e4505bc86ad83c0d6da\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144461645\",\"name\":\"B. Wang\"},{\"authorId\":\"143740449\",\"name\":\"Q. Peng\"},{\"authorId\":\"48663706\",\"name\":\"E. Wang\"},{\"authorId\":\"144802392\",\"name\":\"K. Han\"},{\"authorId\":\"1697333\",\"name\":\"Wei Xiang\"}],\"doi\":\"10.1109/ACCESS.2019.2907572\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"33a8a8cd458321120b3043256433be45fdd994e5\",\"title\":\"Region-of-Interest Compression and View Synthesis for Light Field Video Streaming\",\"url\":\"https://www.semanticscholar.org/paper/33a8a8cd458321120b3043256433be45fdd994e5\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30903985\",\"name\":\"Haoxian Zhang\"},{\"authorId\":\"6615978\",\"name\":\"Yang Zhao\"},{\"authorId\":\"49908329\",\"name\":\"Ronggang Wang\"}],\"doi\":\"10.1007/978-3-030-58595-2_29\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f291dd047bae0aa8d91921c3ae2f51e8d8effb61\",\"title\":\"A Flexible Recurrent Residual Pyramid Network for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/f291dd047bae0aa8d91921c3ae2f51e8d8effb61\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2003.08872\",\"authors\":[{\"authorId\":\"1573986321\",\"name\":\"Liad Pollak Zuckerman\"},{\"authorId\":\"1944189\",\"name\":\"S. Bagon\"},{\"authorId\":\"1557634128\",\"name\":\"Eyal Naor\"},{\"authorId\":\"1387998946\",\"name\":\"George Pisha\"},{\"authorId\":\"144611617\",\"name\":\"M. Irani\"}],\"doi\":\"10.1007/978-3-030-58571-6_4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"02772404c8c6e1903a00798ce01492bc6820f665\",\"title\":\"Across Scales \\\\& Across Dimensions: Temporal Super-Resolution using Deep Internal Learning\",\"url\":\"https://www.semanticscholar.org/paper/02772404c8c6e1903a00798ce01492bc6820f665\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1878705236\",\"name\":\"Chunle Guo\"},{\"authorId\":\"145000882\",\"name\":\"J. Jin\"},{\"authorId\":\"40630305\",\"name\":\"J. Hou\"},{\"authorId\":\"40445654\",\"name\":\"J. Chen\"}],\"doi\":\"10.1109/icme46284.2020.9102829\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c4a2ab7a3055fd68e6ae1fc3be5fabc09f422151\",\"title\":\"Accurate Light Field Depth Estimation via an Occlusion-Aware Network\",\"url\":\"https://www.semanticscholar.org/paper/c4a2ab7a3055fd68e6ae1fc3be5fabc09f422151\",\"venue\":\"2020 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1961467739\",\"name\":\"M. Tseng\"},{\"authorId\":\"2007619711\",\"name\":\"Yen-Chung Chen\"},{\"authorId\":\"1959578097\",\"name\":\"Yi-Lun Lee\"},{\"authorId\":\"2268189\",\"name\":\"Wei-Sheng Lai\"},{\"authorId\":\"2580349\",\"name\":\"Yi-Hsuan Tsai\"},{\"authorId\":\"37811787\",\"name\":\"Wei-Chen Chiu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6614ebe57fff2dd31c8393ca16c22f84f27c132\",\"title\":\"Dual-Stream Fusion Network for Spatiotemporal Video Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/a6614ebe57fff2dd31c8393ca16c22f84f27c132\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2004.05214\",\"authors\":[{\"authorId\":\"152298373\",\"name\":\"Sergiu Oprea\"},{\"authorId\":\"1410236705\",\"name\":\"P. Martinez-Gonzalez\"},{\"authorId\":\"1397392435\",\"name\":\"Alberto Garcia-Garcia\"},{\"authorId\":\"1410269918\",\"name\":\"John Alejandro Castro-Vargas\"},{\"authorId\":\"1405686926\",\"name\":\"S. Orts-Escolano\"},{\"authorId\":\"1429069120\",\"name\":\"J. Garci\\u0301a-Rodri\\u0301guez\"},{\"authorId\":\"1689415\",\"name\":\"Antonis A. Argyros\"}],\"doi\":\"10.1109/TPAMI.2020.3045007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ded24959bbd7715073fa700d5898cdbb2b8353f7\",\"title\":\"A Review on Deep Learning Techniques for Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/ded24959bbd7715073fa700d5898cdbb2b8353f7\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020}],\"corpusId\":13697803,\"doi\":\"10.1109/ICCV.2017.37\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":81,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"ed74b9390eda908060fa3501b8f20a836ec98d63\",\"references\":[{\"arxivId\":\"1703.07514\",\"authors\":[{\"authorId\":\"39644974\",\"name\":\"Simon Niklaus\"},{\"authorId\":\"2712573\",\"name\":\"Long Mai\"},{\"authorId\":\"40513795\",\"name\":\"Feng Liu\"}],\"doi\":\"10.1109/CVPR.2017.244\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"841832fae29497f20ed795604ce76358ed7e51c3\",\"title\":\"Video Frame Interpolation via Adaptive Convolution\",\"url\":\"https://www.semanticscholar.org/paper/841832fae29497f20ed795604ce76358ed7e51c3\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1511.06702\",\"authors\":[{\"authorId\":\"3332944\",\"name\":\"Maxim Tatarchenko\"},{\"authorId\":\"2841331\",\"name\":\"A. Dosovitskiy\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1007/978-3-319-46478-7_20\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8e002fbf85c8453d760aacc32225308d1514f8b6\",\"title\":\"Multi-view 3D Models from Single Images with a Convolutional Network\",\"url\":\"https://www.semanticscholar.org/paper/8e002fbf85c8453d760aacc32225308d1514f8b6\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"M. Hradis P. Svoboda\"},{\"authorId\":null,\"name\":\"D. Barina\"},{\"authorId\":null,\"name\":\"P. Zemc\\u0131\\u0301k\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Compres - sion artifacts removal using convolutional neural networks\",\"url\":\"\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1604.03650\",\"authors\":[{\"authorId\":\"2369548\",\"name\":\"Junyuan Xie\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"}],\"doi\":\"10.1007/978-3-319-46493-0_51\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"28fc7e119ec7d3bd0cf7988a0aa6cdfad1152b31\",\"title\":\"Deep3D: Fully Automatic 2D-to-3D Video Conversion with Deep Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/28fc7e119ec7d3bd0cf7988a0aa6cdfad1152b31\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1504.06852\",\"authors\":[{\"authorId\":\"1382344214\",\"name\":\"A. Dosovitskiy\"},{\"authorId\":\"152702479\",\"name\":\"P. Fischer\"},{\"authorId\":\"48105320\",\"name\":\"Eddy Ilg\"},{\"authorId\":\"2880264\",\"name\":\"Philip H\\u00e4usser\"},{\"authorId\":\"3322806\",\"name\":\"Caner Hazirbas\"},{\"authorId\":\"2943639\",\"name\":\"V. Golkov\"},{\"authorId\":\"1715782\",\"name\":\"P. V. D. Smagt\"},{\"authorId\":\"153685345\",\"name\":\"D. Cremers\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1109/ICCV.2015.316\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c2fb5b39428818d7ec8cc78e152e19c21b7db568\",\"title\":\"FlowNet: Learning Optical Flow with Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/c2fb5b39428818d7ec8cc78e152e19c21b7db568\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1506.03011\",\"authors\":[{\"authorId\":\"2558463\",\"name\":\"R. Goroshin\"},{\"authorId\":\"143949035\",\"name\":\"Micha\\u00ebl Mathieu\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"dd2fa69647160bb2ea25dcc7b2f6409b01e40222\",\"title\":\"Learning to Linearize Under Uncertainty\",\"url\":\"https://www.semanticscholar.org/paper/dd2fa69647160bb2ea25dcc7b2f6409b01e40222\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"S. Chetlur\"},{\"authorId\":null,\"name\":\"C. Woolley\"},{\"authorId\":null,\"name\":\"P. Vandermersch\"},{\"authorId\":null,\"name\":\"J. Cohen\"},{\"authorId\":null,\"name\":\"J. Tran\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Efficient primitives for deep learning\",\"url\":\"\",\"venue\":\"IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":\"1612.01105\",\"authors\":[{\"authorId\":\"3459894\",\"name\":\"Hengshuang Zhao\"},{\"authorId\":\"1788070\",\"name\":\"J. Shi\"},{\"authorId\":\"50844674\",\"name\":\"Xiaojuan Qi\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"},{\"authorId\":\"1729056\",\"name\":\"J. Jia\"}],\"doi\":\"10.1109/CVPR.2017.660\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1031a69923b80ad01cf3fbb703d10757a80e699b\",\"title\":\"Pyramid Scene Parsing Network\",\"url\":\"https://www.semanticscholar.org/paper/1031a69923b80ad01cf3fbb703d10757a80e699b\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1702.06295\",\"authors\":[{\"authorId\":\"2201435\",\"name\":\"Armen Aghajanyan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a12d079b4e661f50ee7cfd2a823abeccfff9cd5a\",\"title\":\"Convolution Aware Initialization\",\"url\":\"https://www.semanticscholar.org/paper/a12d079b4e661f50ee7cfd2a823abeccfff9cd5a\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144574904\",\"name\":\"L. Xu\"},{\"authorId\":\"1729056\",\"name\":\"J. Jia\"},{\"authorId\":\"1774618\",\"name\":\"Yasuyuki Matsushita\"}],\"doi\":\"10.1109/TPAMI.2011.236\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"66f9ee80721a20b1d191e06c5f5ab42e542a1241\",\"title\":\"Motion Detail Preserving Optical Flow Estimation\",\"url\":\"https://www.semanticscholar.org/paper/66f9ee80721a20b1d191e06c5f5ab42e542a1241\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Bansal\"},{\"authorId\":null,\"name\":\"X. Chen\"},{\"authorId\":null,\"name\":\"B. Russell\"},{\"authorId\":null,\"name\":\"A. Gupta\"},{\"authorId\":null,\"name\":\"D. Ramanan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"PixelNet: Representation of the pixels\",\"url\":\"\",\"venue\":\"by the pixels, and for the pixels. arXiv/1702.06506\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"1738740\",\"name\":\"S. B. Kang\"},{\"authorId\":\"143711233\",\"name\":\"Matthew Uyttendaele\"},{\"authorId\":\"2818882\",\"name\":\"S. Winder\"},{\"authorId\":\"1717841\",\"name\":\"R. Szeliski\"}],\"doi\":\"10.1145/1015706.1015766\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5d4aef53879770ce33e647264230b42ebaba1828\",\"title\":\"High-quality video view interpolation using a layered representation\",\"url\":\"https://www.semanticscholar.org/paper/5d4aef53879770ce33e647264230b42ebaba1828\",\"venue\":\"SIGGRAPH 2004\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2939803\",\"name\":\"Ronan Collobert\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"},{\"authorId\":\"2256269\",\"name\":\"C. Farabet\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3449b65008b27f6e60a73d80c1fd990f0481126b\",\"title\":\"Torch7: A Matlab-like Environment for Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/3449b65008b27f6e60a73d80c1fd990f0481126b\",\"venue\":\"NIPS 2011\",\"year\":2011},{\"arxivId\":\"1511.06409\",\"authors\":[{\"authorId\":\"39770136\",\"name\":\"J. Snell\"},{\"authorId\":\"1788247\",\"name\":\"K. Ridgeway\"},{\"authorId\":\"2246396\",\"name\":\"Renjie Liao\"},{\"authorId\":\"2199890\",\"name\":\"Brett D. Roads\"},{\"authorId\":\"144473519\",\"name\":\"M. Mozer\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":\"10.1109/ICIP.2017.8297089\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"90e4f12fa8fb126d0f416c8b61bfb5f73f8b7b74\",\"title\":\"Learning to generate images with perceptual similarity metrics\",\"url\":\"https://www.semanticscholar.org/paper/90e4f12fa8fb126d0f416c8b61bfb5f73f8b7b74\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145347688\",\"name\":\"S. Baker\"},{\"authorId\":\"1709053\",\"name\":\"D. Scharstein\"},{\"authorId\":\"69395700\",\"name\":\"J. Lewis\"},{\"authorId\":\"145920814\",\"name\":\"S. Roth\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"},{\"authorId\":\"1717841\",\"name\":\"R. Szeliski\"}],\"doi\":\"10.1007/s11263-010-0390-2\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"804836b8ad86ef8042e3dcbd45442a52f031ee03\",\"title\":\"A Database and Evaluation Methodology for Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/804836b8ad86ef8042e3dcbd45442a52f031ee03\",\"venue\":\"2007 IEEE 11th International Conference on Computer Vision\",\"year\":2007},{\"arxivId\":\"1603.06041\",\"authors\":[{\"authorId\":\"1781631\",\"name\":\"Gucan Long\"},{\"authorId\":\"1727013\",\"name\":\"Laurent Kneip\"},{\"authorId\":\"2974008\",\"name\":\"Jose M. Alvarez\"},{\"authorId\":\"40124570\",\"name\":\"Hongdong Li\"},{\"authorId\":\"39045430\",\"name\":\"X. Zhang\"},{\"authorId\":\"9397915\",\"name\":\"Qifeng Yu\"}],\"doi\":\"10.1007/978-3-319-46466-4_26\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f19108c55b7c1831566ce3250322e0f5637d44c9\",\"title\":\"Learning Image Matching by Simply Watching Video\",\"url\":\"https://www.semanticscholar.org/paper/f19108c55b7c1831566ce3250322e0f5637d44c9\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"3428663\",\"name\":\"J\\u00e9r\\u00f4me Revaud\"},{\"authorId\":\"113130084\",\"name\":\"Zaid Harchaoui\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2013.175\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"56493a503eecb659bbef2fe4dd1fb915d251cac0\",\"title\":\"DeepFlow: Large Displacement Optical Flow with Deep Matching\",\"url\":\"https://www.semanticscholar.org/paper/56493a503eecb659bbef2fe4dd1fb915d251cac0\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":\"1605.07157\",\"authors\":[{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f110cfdbe9ded7a384bcf5c0d56e536bd275a7eb\",\"title\":\"Unsupervised Learning for Physical Interaction through Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/f110cfdbe9ded7a384bcf5c0d56e536bd275a7eb\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1511.05440\",\"authors\":[{\"authorId\":\"143949035\",\"name\":\"Micha\\u00ebl Mathieu\"},{\"authorId\":\"2341378\",\"name\":\"C. Couprie\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"17fa1c2a24ba8f731c8b21f1244463bc4b465681\",\"title\":\"Deep multi-scale video prediction beyond mean square error\",\"url\":\"https://www.semanticscholar.org/paper/17fa1c2a24ba8f731c8b21f1244463bc4b465681\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50113176\",\"name\":\"S. Meyer\"},{\"authorId\":\"47520207\",\"name\":\"O. Wang\"},{\"authorId\":\"1405719070\",\"name\":\"H. Zimmer\"},{\"authorId\":\"3044090\",\"name\":\"M. Grosse\"},{\"authorId\":\"1388791172\",\"name\":\"Alexander Sorkine-Hornung\"}],\"doi\":\"10.1109/CVPR.2015.7298747\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"87b83fefb82216aad1c14cd1898d195722bcee42\",\"title\":\"Phase-based frame interpolation for video\",\"url\":\"https://www.semanticscholar.org/paper/87b83fefb82216aad1c14cd1898d195722bcee42\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1603.08155\",\"authors\":[{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"3304525\",\"name\":\"Alexandre Alahi\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/978-3-319-46475-6_43\",\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"9fa3720371e78d04973ce9752781bc337480b68f\",\"title\":\"Perceptual Losses for Real-Time Style Transfer and Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/9fa3720371e78d04973ce9752781bc337480b68f\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"D. Scharstein\"},{\"authorId\":null,\"name\":\"J. P. Lewis\"},{\"authorId\":null,\"name\":\"S. Roth\"},{\"authorId\":null,\"name\":\"M. J. Black\"},{\"authorId\":null,\"name\":\"R. Szeliski\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Aghajanyan . Convolution aware initialization Flow Fields : Dense correspondence fields for highly accurate large displacement optical flow estimation\",\"url\":\"\",\"venue\":\"In ICCV\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144361581\",\"name\":\"J. Long\"},{\"authorId\":\"1782282\",\"name\":\"Evan Shelhamer\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/CVPR.2015.7298965\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9201bf6f8222c2335913002e13fbac640fc0f4ec\",\"title\":\"Fully convolutional networks for semantic segmentation\",\"url\":\"https://www.semanticscholar.org/paper/9201bf6f8222c2335913002e13fbac640fc0f4ec\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1506.06825\",\"authors\":[{\"authorId\":\"48001135\",\"name\":\"J. Flynn\"},{\"authorId\":\"1725327\",\"name\":\"Ivan Neulander\"},{\"authorId\":\"144781398\",\"name\":\"J. Philbin\"},{\"authorId\":\"1830653\",\"name\":\"Noah Snavely\"}],\"doi\":\"10.1109/CVPR.2016.595\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"73c8acd433c33e09916eaa1b0311c3ea7b2610d2\",\"title\":\"Deep Stereo: Learning to Predict New Views from the World's Imagery\",\"url\":\"https://www.semanticscholar.org/paper/73c8acd433c33e09916eaa1b0311c3ea7b2610d2\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"P. Svoboda\"},{\"authorId\":null,\"name\":\"M. Hradis\"},{\"authorId\":null,\"name\":\"D. Barina\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and P\",\"url\":\"\",\"venue\":\"Zemc\\u0131\\u0301k. Compression artifacts removal using convolutional neural networks. arXiv/1605.00366\",\"year\":2016},{\"arxivId\":\"1609.04802\",\"authors\":[{\"authorId\":\"1779917\",\"name\":\"C. Ledig\"},{\"authorId\":\"2073063\",\"name\":\"L. Theis\"},{\"authorId\":\"3108066\",\"name\":\"Ferenc Husz\\u00e1r\"},{\"authorId\":\"79382929\",\"name\":\"J. Caballero\"},{\"authorId\":\"83015038\",\"name\":\"Andrew Aitken\"},{\"authorId\":\"41203992\",\"name\":\"Alykhan Tejani\"},{\"authorId\":\"1853456\",\"name\":\"J. Totz\"},{\"authorId\":\"34627233\",\"name\":\"Zehan Wang\"},{\"authorId\":\"152554375\",\"name\":\"W. Shi\"}],\"doi\":\"10.1109/CVPR.2017.19\",\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"df0c54fe61f0ffb9f0e36a17c2038d9a1964cba3\",\"title\":\"Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network\",\"url\":\"https://www.semanticscholar.org/paper/df0c54fe61f0ffb9f0e36a17c2038d9a1964cba3\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1601.07532\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1007/978-3-319-54193-8_26\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3788cb8e73e1c0a62b762731da7769288a9098c9\",\"title\":\"Learning to Extract Motion from Videos in Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/3788cb8e73e1c0a62b762731da7769288a9098c9\",\"venue\":\"ACCV\",\"year\":2016},{\"arxivId\":\"1604.04382\",\"authors\":[{\"authorId\":\"153228286\",\"name\":\"Chuan Li\"},{\"authorId\":\"1723149\",\"name\":\"M. Wand\"}],\"doi\":\"10.1007/978-3-319-46487-9_43\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"102a2096ba2e2947dc252445f764e7583b557680\",\"title\":\"Precomputed Real-Time Texture Synthesis with Markovian Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/102a2096ba2e2947dc252445f764e7583b557680\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35167546\",\"name\":\"H. Burger\"},{\"authorId\":\"1814533\",\"name\":\"C. Schuler\"},{\"authorId\":\"1734990\",\"name\":\"S. Harmeling\"}],\"doi\":\"10.1109/CVPR.2012.6247952\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1d70937202d843664c5591fde4fb0d48627d1cf6\",\"title\":\"Image denoising: Can plain neural networks compete with BM3D?\",\"url\":\"https://www.semanticscholar.org/paper/1d70937202d843664c5591fde4fb0d48627d1cf6\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":\"1605.09673\",\"authors\":[{\"authorId\":\"40347509\",\"name\":\"Xu Jia\"},{\"authorId\":\"3384995\",\"name\":\"Bert De Brabandere\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aba48504f4f9563eafa44e0cfb22e1345d767c80\",\"title\":\"Dynamic Filter Networks\",\"url\":\"https://www.semanticscholar.org/paper/aba48504f4f9563eafa44e0cfb22e1345d767c80\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1412.6604\",\"authors\":[{\"authorId\":\"1706809\",\"name\":\"Marc'Aurelio Ranzato\"},{\"authorId\":\"3149531\",\"name\":\"Arthur Szlam\"},{\"authorId\":\"143627859\",\"name\":\"Joan Bruna\"},{\"authorId\":\"143949035\",\"name\":\"Micha\\u00ebl Mathieu\"},{\"authorId\":\"2939803\",\"name\":\"Ronan Collobert\"},{\"authorId\":\"3295092\",\"name\":\"S. Chopra\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"355f98e4827a1b6ad3f29d07ea2bcf9ad078295c\",\"title\":\"Video (language) modeling: a baseline for generative models of natural videos\",\"url\":\"https://www.semanticscholar.org/paper/355f98e4827a1b6ad3f29d07ea2bcf9ad078295c\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":\"1504.06993\",\"authors\":[{\"authorId\":\"144964868\",\"name\":\"C. Dong\"},{\"authorId\":\"48362742\",\"name\":\"Yubin Deng\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1109/ICCV.2015.73\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"09642681d46282e76fd9d1336001ef6473b72ec8\",\"title\":\"Compression Artifacts Reduction by a Deep Convolutional Network\",\"url\":\"https://www.semanticscholar.org/paper/09642681d46282e76fd9d1336001ef6473b72ec8\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1764325\",\"name\":\"R. Neal\"}],\"doi\":\"10.1198/tech.2007.s518\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3bb5a439a0d610a7eac68f73068cdd278b8c9775\",\"title\":\"Pattern Recognition and Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/3bb5a439a0d610a7eac68f73068cdd278b8c9775\",\"venue\":\"Technometrics\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2369548\",\"name\":\"Junyuan Xie\"},{\"authorId\":\"2230211\",\"name\":\"Linli Xu\"},{\"authorId\":\"144378760\",\"name\":\"E. Chen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a2017ec2c60d542af5e9993176ba68f89529dbce\",\"title\":\"Image Denoising and Inpainting with Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/a2017ec2c60d542af5e9993176ba68f89529dbce\",\"venue\":\"NIPS\",\"year\":2012},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1601.00706\",\"authors\":[{\"authorId\":\"1768964\",\"name\":\"Jimei Yang\"},{\"authorId\":\"144828948\",\"name\":\"S. Reed\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3411535f7888a943853895e8eef2bb0b6d328c2a\",\"title\":\"Weakly-supervised Disentangling with Recurrent Transformations for 3D View Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/3411535f7888a943853895e8eef2bb0b6d328c2a\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1501.00092\",\"authors\":[{\"authorId\":\"144964868\",\"name\":\"C. Dong\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1109/TPAMI.2015.2439281\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"66e9dc728b5041271bff0cd6ac0d7eadcd88442f\",\"title\":\"Image Super-Resolution Using Deep Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/66e9dc728b5041271bff0cd6ac0d7eadcd88442f\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2016},{\"arxivId\":\"1609.03552\",\"authors\":[{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"2562966\",\"name\":\"Philipp Kr\\u00e4henb\\u00fchl\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1007/978-3-319-46454-1_36\",\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"fc7822f56dd255a872326b9536a0821bbf0277dd\",\"title\":\"Generative Visual Manipulation on the Natural Image Manifold\",\"url\":\"https://www.semanticscholar.org/paper/fc7822f56dd255a872326b9536a0821bbf0277dd\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144574904\",\"name\":\"L. Xu\"},{\"authorId\":\"145335572\",\"name\":\"J. Ren\"},{\"authorId\":\"1681442\",\"name\":\"Ce Liu\"},{\"authorId\":\"1729056\",\"name\":\"J. Jia\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"750cc7813da3559dfd653cfbbf56ca3356b3162f\",\"title\":\"Deep Convolutional Neural Network for Image Deconvolution\",\"url\":\"https://www.semanticscholar.org/paper/750cc7813da3559dfd653cfbbf56ca3356b3162f\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1609.02974\",\"authors\":[{\"authorId\":\"1717070\",\"name\":\"Nima Khademi Kalantari\"},{\"authorId\":\"2195314\",\"name\":\"T. Wang\"},{\"authorId\":\"1752236\",\"name\":\"R. Ramamoorthi\"}],\"doi\":\"10.1145/2980179.2980251\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8bc52fa1687bc8ef596a9b81d1b7c1d172a111e8\",\"title\":\"Learning-based view synthesis for light field cameras\",\"url\":\"https://www.semanticscholar.org/paper/8bc52fa1687bc8ef596a9b81d1b7c1d172a111e8\",\"venue\":\"ACM Trans. Graph.\",\"year\":2016},{\"arxivId\":\"1502.04681\",\"authors\":[{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"2711409\",\"name\":\"Elman Mansimov\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"title\":\"Unsupervised Learning of Video Representations using LSTMs\",\"url\":\"https://www.semanticscholar.org/paper/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1511.06681\",\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/CVPRW.2016.57\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7249091dd41c1c072b033f8327bbabb10ac20c82\",\"title\":\"Deep End2End Voxel2Voxel Prediction\",\"url\":\"https://www.semanticscholar.org/paper/7249091dd41c1c072b033f8327bbabb10ac20c82\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2016},{\"arxivId\":\"1702.06506\",\"authors\":[{\"authorId\":\"3294630\",\"name\":\"Aayush Bansal\"},{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"145160921\",\"name\":\"Bryan C. Russell\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ec3472acc24fe5ef9eb07a31697f2cd446c8facc\",\"title\":\"PixelNet: Representation of the pixels, by the pixels, and for the pixels\",\"url\":\"https://www.semanticscholar.org/paper/ec3472acc24fe5ef9eb07a31697f2cd446c8facc\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1605.00366\",\"authors\":[{\"authorId\":\"47071858\",\"name\":\"P. Svoboda\"},{\"authorId\":\"1700956\",\"name\":\"Michal Hradi\\u0161\"},{\"authorId\":\"1977196\",\"name\":\"David Barina\"},{\"authorId\":\"1722571\",\"name\":\"P. Zem\\u010d\\u00edk\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d175d2bd607f7e749484be7696ca5f8f78d8b01d\",\"title\":\"Compression Artifacts Removal Using Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/d175d2bd607f7e749484be7696ca5f8f78d8b01d\",\"venue\":\"J. WSCG\",\"year\":2016},{\"arxivId\":\"1607.02586\",\"authors\":[{\"authorId\":\"3222730\",\"name\":\"Tianfan Xue\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"18555073\",\"name\":\"K. Bouman\"},{\"authorId\":\"36668046\",\"name\":\"B. Freeman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"397e9b56e46d3cc34af1525493e597facb104570\",\"title\":\"Visual Dynamics: Probabilistic Future Frame Synthesis via Cross Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/397e9b56e46d3cc34af1525493e597facb104570\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4746730\",\"name\":\"J. Lackie\"}],\"doi\":\"10.1016/b978-0-12-384931-1.00016-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"db750f063bc099e6d1d2d0a92a34d7c213a893e3\",\"title\":\"P\",\"url\":\"https://www.semanticscholar.org/paper/db750f063bc099e6d1d2d0a92a34d7c213a893e3\",\"venue\":\"The Dictionary of Cell & Molecular Biology\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48799969\",\"name\":\"Matthew D. Zeiler\"},{\"authorId\":\"144639556\",\"name\":\"Graham W. Taylor\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":\"10.1109/ICCV.2011.6126474\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d743430cb2329caa5d446c17fc9ec07f5e916ab0\",\"title\":\"Adaptive deconvolutional networks for mid and high level feature learning\",\"url\":\"https://www.semanticscholar.org/paper/d743430cb2329caa5d446c17fc9ec07f5e916ab0\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2886023\",\"name\":\"Manuel Werlberger\"},{\"authorId\":\"1730097\",\"name\":\"T. Pock\"},{\"authorId\":\"2443335\",\"name\":\"M. Unger\"},{\"authorId\":\"144746444\",\"name\":\"H. Bischof\"}],\"doi\":\"10.1007/978-3-642-23094-3_20\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fd86cc929225d6a9a725e5f30aa918f3582b8960\",\"title\":\"Optical Flow Guided TV-L1 Video Interpolation and Restoration\",\"url\":\"https://www.semanticscholar.org/paper/fd86cc929225d6a9a725e5f30aa918f3582b8960\",\"venue\":\"EMMCVPR\",\"year\":2011},{\"arxivId\":\"1502.03167\",\"authors\":[{\"authorId\":\"144147316\",\"name\":\"S. Ioffe\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d376d6978dad0374edfa6709c9556b42d3594d3\",\"title\":\"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\",\"url\":\"https://www.semanticscholar.org/paper/4d376d6978dad0374edfa6709c9556b42d3594d3\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2624088\",\"name\":\"Augustus Odena\"},{\"authorId\":\"3074927\",\"name\":\"Vincent Dumoulin\"},{\"authorId\":\"39628969\",\"name\":\"Christopher Olah\"}],\"doi\":\"10.23915/DISTILL.00003\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d9dab7574d56ae81efe6c90c213c6509b36cf950\",\"title\":\"Deconvolution and Checkerboard Artifacts\",\"url\":\"https://www.semanticscholar.org/paper/d9dab7574d56ae81efe6c90c213c6509b36cf950\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1605.03557\",\"authors\":[{\"authorId\":\"1822702\",\"name\":\"Tinghui Zhou\"},{\"authorId\":\"2757335\",\"name\":\"Shubham Tulsiani\"},{\"authorId\":\"8397461\",\"name\":\"Weilun Sun\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1007/978-3-319-46493-0_18\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5b635705558b9ffcc973966371415b7124830007\",\"title\":\"View Synthesis by Appearance Flow\",\"url\":\"https://www.semanticscholar.org/paper/5b635705558b9ffcc973966371415b7124830007\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1609.05158\",\"authors\":[{\"authorId\":\"2700496\",\"name\":\"W. Shi\"},{\"authorId\":\"145372820\",\"name\":\"J. Caballero\"},{\"authorId\":\"3108066\",\"name\":\"Ferenc Husz\\u00e1r\"},{\"authorId\":\"1853456\",\"name\":\"J. Totz\"},{\"authorId\":\"49931957\",\"name\":\"A. Aitken\"},{\"authorId\":\"50784424\",\"name\":\"R. Bishop\"},{\"authorId\":\"1717710\",\"name\":\"D. Rueckert\"},{\"authorId\":\"34627233\",\"name\":\"Zehan Wang\"}],\"doi\":\"10.1109/CVPR.2016.207\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"03a5b2aac53443e6078f0f63b35d4f95d6d54c5d\",\"title\":\"Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/03a5b2aac53443e6078f0f63b35d4f95d6d54c5d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1512.01815\",\"authors\":[{\"authorId\":\"3117463\",\"name\":\"David Gadot\"},{\"authorId\":\"145128145\",\"name\":\"Lior Wolf\"}],\"doi\":\"10.1109/CVPR.2016.459\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cdae1edd4bd2c4c110f992cca57e88afecf5658a\",\"title\":\"PatchBatch: A Batch Augmented Loss for Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/cdae1edd4bd2c4c110f992cca57e88afecf5658a\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1602.02644\",\"authors\":[{\"authorId\":\"2841331\",\"name\":\"A. Dosovitskiy\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"9179e740dad4ca4c183f7677b854e5b15f9a122f\",\"title\":\"Generating Images with Perceptual Similarity Metrics based on Deep Networks\",\"url\":\"https://www.semanticscholar.org/paper/9179e740dad4ca4c183f7677b854e5b15f9a122f\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1410.0759\",\"authors\":[{\"authorId\":\"3003738\",\"name\":\"Sharan Chetlur\"},{\"authorId\":\"2266717\",\"name\":\"C. Woolley\"},{\"authorId\":\"2101730\",\"name\":\"Philippe Vandermersch\"},{\"authorId\":\"145678733\",\"name\":\"J. Cohen\"},{\"authorId\":\"145927488\",\"name\":\"John Tran\"},{\"authorId\":\"2301680\",\"name\":\"Bryan Catanzaro\"},{\"authorId\":\"1782282\",\"name\":\"Evan Shelhamer\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"31c36d445367ba204244bb74893c5654e31c3869\",\"title\":\"cuDNN: Efficient Primitives for Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/31c36d445367ba204244bb74893c5654e31c3869\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"M. W. Tao\"},{\"authorId\":null,\"name\":\"J. Bai\"},{\"authorId\":null,\"name\":\"P. Kohli\"},{\"authorId\":null,\"name\":\"S. Paris\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"SimpleFlow: A non-iterative\",\"url\":\"\",\"venue\":\"sublinear optical flow algorithm. Computer Graphics Forum, 31(2):345\\u2013353\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3270016\",\"name\":\"Michael W. Tao\"},{\"authorId\":\"18798164\",\"name\":\"Jiamin Bai\"},{\"authorId\":\"143967473\",\"name\":\"P. Kohli\"},{\"authorId\":\"145799132\",\"name\":\"Sylvain Paris\"}],\"doi\":\"10.1111/j.1467-8659.2012.03013.x\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"09a54064c94475c042e24225531b45edc7542521\",\"title\":\"SimpleFlow: A Non\\u2010iterative, Sublinear Optical Flow Algorithm\",\"url\":\"https://www.semanticscholar.org/paper/09a54064c94475c042e24225531b45edc7542521\",\"venue\":\"Comput. Graph. Forum\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Farhadi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Deep 3 D : Fully automatic 2 Dto - 3 D video conversion with deep convolutional neural networks Image denoising and inpainting with deep neural networks\",\"url\":\"\",\"venue\":\"Advances in Neural Information Processing Systems\",\"year\":2012},{\"arxivId\":\"1411.5928\",\"authors\":[{\"authorId\":\"2841331\",\"name\":\"A. Dosovitskiy\"},{\"authorId\":\"2060551\",\"name\":\"Jost Tobias Springenberg\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1109/CVPR.2015.7298761\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b437b5a0445f17b06b12791bc48aeb8110e95dc5\",\"title\":\"Learning to generate chairs with convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/b437b5a0445f17b06b12791bc48aeb8110e95dc5\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1702.02463\",\"authors\":[{\"authorId\":\"3243969\",\"name\":\"Z. Liu\"},{\"authorId\":\"28919105\",\"name\":\"Raymond A. Yeh\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"36966089\",\"name\":\"Y. Liu\"},{\"authorId\":\"1696487\",\"name\":\"A. Agarwala\"}],\"doi\":\"10.1109/ICCV.2017.478\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8970e9caed1fca960ead644e6453a1a7321a7e6d\",\"title\":\"Video Frame Synthesis Using Deep Voxel Flow\",\"url\":\"https://www.semanticscholar.org/paper/8970e9caed1fca960ead644e6453a1a7321a7e6d\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1611.00850\",\"authors\":[{\"authorId\":\"1952002\",\"name\":\"A. Ranjan\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"}],\"doi\":\"10.1109/CVPR.2017.291\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a93d81c7f033f1e2b54d3288b60d214f55ccc010\",\"title\":\"Optical Flow Estimation Using a Spatial Pyramid Network\",\"url\":\"https://www.semanticscholar.org/paper/a93d81c7f033f1e2b54d3288b60d214f55ccc010\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3349249\",\"name\":\"Fatma G\\u00fcney\"},{\"authorId\":\"47237027\",\"name\":\"Andreas Geiger\"}],\"doi\":\"10.1007/978-3-319-54190-7_13\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8d192bb3feae3e445b3b30948edee907a1d2324a\",\"title\":\"Deep Discrete Flow\",\"url\":\"https://www.semanticscholar.org/paper/8d192bb3feae3e445b3b30948edee907a1d2324a\",\"venue\":\"ACCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144542135\",\"name\":\"D. Mahajan\"},{\"authorId\":\"37021642\",\"name\":\"F. Huang\"},{\"authorId\":\"1752521\",\"name\":\"W. Matusik\"},{\"authorId\":\"1752236\",\"name\":\"R. Ramamoorthi\"},{\"authorId\":\"1767767\",\"name\":\"P. Belhumeur\"}],\"doi\":\"10.1145/1576246.1531348\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d746c54a1636c448e98c16bc6fb8ce07aeeb042e\",\"title\":\"Moving gradients: a path-based method for plausible image interpolation\",\"url\":\"https://www.semanticscholar.org/paper/d746c54a1636c448e98c16bc6fb8ce07aeeb042e\",\"venue\":\"SIGGRAPH '09\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"R. B. Girshick\"},{\"authorId\":null,\"name\":\"A.\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Farhadi . Deep 3 D : Fully automatic 2 Dto - 3 D video conversion with deep convolutional neural networks\",\"url\":\"\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1644300403\",\"name\":\"TaoMichael\"},{\"authorId\":\"1644271239\",\"name\":\"BaiJiamin\"},{\"authorId\":\"1643847570\",\"name\":\"KohliPushmeet\"},{\"authorId\":\"1644065509\",\"name\":\"ParisSylvain\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"30dc08586c6d253089a7bbc3edb5902f3f16102a\",\"title\":\"SimpleFlow: A Non-iterative, Sublinear Optical Flow Algorithm\",\"url\":\"https://www.semanticscholar.org/paper/30dc08586c6d253089a7bbc3edb5902f3f16102a\",\"venue\":\"\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153009621\",\"name\":\"Zhefei Yu\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"},{\"authorId\":\"2969311\",\"name\":\"Zhangyang Wang\"},{\"authorId\":\"1694827\",\"name\":\"Zeng Hu\"},{\"authorId\":\"1735257\",\"name\":\"C. Chen\"}],\"doi\":\"10.1109/TCSVT.2013.2242631\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c83b1573163b8794b85e35021a0650945e958da\",\"title\":\"Multi-Level Video Frame Interpolation: Exploiting the Interaction Among Different Levels\",\"url\":\"https://www.semanticscholar.org/paper/2c83b1573163b8794b85e35021a0650945e958da\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2013},{\"arxivId\":\"1701.04128\",\"authors\":[{\"authorId\":\"49756115\",\"name\":\"W. Luo\"},{\"authorId\":\"1980990\",\"name\":\"Y. Li\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"01a4f33da8ad94ced3cf58548b28dbbb44148571\",\"title\":\"Understanding the Effective Receptive Field in Deep Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/01a4f33da8ad94ced3cf58548b28dbbb44148571\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1503.00593\",\"authors\":[{\"authorId\":\"39838944\",\"name\":\"J. Sun\"},{\"authorId\":\"3102315\",\"name\":\"Wenfei Cao\"},{\"authorId\":\"7814629\",\"name\":\"Zongben Xu\"},{\"authorId\":\"144189388\",\"name\":\"J. Ponce\"}],\"doi\":\"10.1109/CVPR.2015.7298677\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"03eb5c9e91031b20f95ff9cf3f47013086fea9a2\",\"title\":\"Learning a convolutional neural network for non-uniform motion blur removal\",\"url\":\"https://www.semanticscholar.org/paper/03eb5c9e91031b20f95ff9cf3f47013086fea9a2\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2598904\",\"name\":\"Christian Bailer\"},{\"authorId\":\"2847305\",\"name\":\"Bertram Taetz\"},{\"authorId\":\"143749919\",\"name\":\"D. Stricker\"}],\"doi\":\"10.1109/ICCV.2015.457\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e8371a6a7ff5f3bf0dcdda4742bfe8edfc5e9054\",\"title\":\"Flow Fields: Dense Correspondence Fields for Highly Accurate Large Displacement Optical Flow Estimation\",\"url\":\"https://www.semanticscholar.org/paper/e8371a6a7ff5f3bf0dcdda4742bfe8edfc5e9054\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1891828\",\"name\":\"Leon A. Gatys\"},{\"authorId\":\"1746183\",\"name\":\"Alexander S. Ecker\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":\"10.1109/CVPR.2016.265\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7568d13a82f7afa4be79f09c295940e48ec6db89\",\"title\":\"Image Style Transfer Using Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/7568d13a82f7afa4be79f09c295940e48ec6db89\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1612.07919\",\"authors\":[{\"authorId\":\"2283034\",\"name\":\"Mehdi S. M. Sajjadi\"},{\"authorId\":\"1707625\",\"name\":\"B. Sch\\u00f6lkopf\"},{\"authorId\":\"144566512\",\"name\":\"M. Hirsch\"}],\"doi\":\"10.1109/ICCV.2017.481\",\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"fddc32f3880688238847077fd927ab3025db7a6a\",\"title\":\"EnhanceNet: Single Image Super-Resolution Through Automated Texture Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/fddc32f3880688238847077fd927ab3025db7a6a\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1609.04836\",\"authors\":[{\"authorId\":\"2844898\",\"name\":\"N. Keskar\"},{\"authorId\":\"2205699\",\"name\":\"D. Mudigere\"},{\"authorId\":\"2784955\",\"name\":\"J. Nocedal\"},{\"authorId\":\"1711231\",\"name\":\"M. Smelyanskiy\"},{\"authorId\":\"144669504\",\"name\":\"P. Tang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8ec5896b4490c6e127d1718ffc36a3439d84cb81\",\"title\":\"On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima\",\"url\":\"https://www.semanticscholar.org/paper/8ec5896b4490c6e127d1718ffc36a3439d84cb81\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"70047172\",\"name\":\"Roberto Rigamonti\"},{\"authorId\":\"2861464\",\"name\":\"Amos Sironi\"},{\"authorId\":\"1689738\",\"name\":\"Vincent Lepetit\"},{\"authorId\":\"1717736\",\"name\":\"P. Fua\"}],\"doi\":\"10.1109/CVPR.2013.355\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"6436ab45779f90a4d9c473354672b86e465e3ff7\",\"title\":\"Learning Separable Filters\",\"url\":\"https://www.semanticscholar.org/paper/6436ab45779f90a4d9c473354672b86e465e3ff7\",\"venue\":\"CVPR\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"C. Couprie M. Mathieu\"},{\"authorId\":null,\"name\":\"Y.\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"LeCun . Deep multi - scale video prediction beyond mean square error\",\"url\":\"\",\"venue\":\"ACM Trans . Graph .\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144542135\",\"name\":\"D. Mahajan\"},{\"authorId\":\"37021642\",\"name\":\"F. Huang\"},{\"authorId\":\"1752521\",\"name\":\"W. Matusik\"},{\"authorId\":\"1752236\",\"name\":\"R. Ramamoorthi\"},{\"authorId\":\"1767767\",\"name\":\"P. Belhumeur\"}],\"doi\":\"10.1145/1531326.1531348\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7f40e7fefd0bc9fc59520337017787798315881f\",\"title\":\"Moving gradients: a path-based method for plausible image interpolation\",\"url\":\"https://www.semanticscholar.org/paper/7f40e7fefd0bc9fc59520337017787798315881f\",\"venue\":\"SIGGRAPH 2009\",\"year\":2009},{\"arxivId\":\"1503.03167\",\"authors\":[{\"authorId\":\"1954876\",\"name\":\"Tejas D. Kulkarni\"},{\"authorId\":\"3376546\",\"name\":\"William F. Whitney\"},{\"authorId\":\"143967473\",\"name\":\"P. Kohli\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"687e80eb70c7bbad6001006d9269b202650a3354\",\"title\":\"Deep Convolutional Inverse Graphics Network\",\"url\":\"https://www.semanticscholar.org/paper/687e80eb70c7bbad6001006d9269b202650a3354\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1603.08511\",\"authors\":[{\"authorId\":\"2844849\",\"name\":\"Richard Zhang\"},{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1007/978-3-319-46487-9_40\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8201e6e687f2de477258e9be53ba7b73ee30d7de\",\"title\":\"Colorful Image Colorization\",\"url\":\"https://www.semanticscholar.org/paper/8201e6e687f2de477258e9be53ba7b73ee30d7de\",\"venue\":\"ECCV\",\"year\":2016}],\"title\":\"Video Frame Interpolation via Adaptive Separable Convolution\",\"topics\":[{\"topic\":\"Motion interpolation\",\"topicId\":\"21402\",\"url\":\"https://www.semanticscholar.org/topic/21402\"},{\"topic\":\"Convolution\",\"topicId\":\"571\",\"url\":\"https://www.semanticscholar.org/topic/571\"},{\"topic\":\"Pixel\",\"topicId\":\"4254\",\"url\":\"https://www.semanticscholar.org/topic/4254\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"},{\"topic\":\"Convolutional neural network\",\"topicId\":\"29860\",\"url\":\"https://www.semanticscholar.org/topic/29860\"},{\"topic\":\"Motion estimation\",\"topicId\":\"21398\",\"url\":\"https://www.semanticscholar.org/topic/21398\"},{\"topic\":\"Optical flow\",\"topicId\":\"26430\",\"url\":\"https://www.semanticscholar.org/topic/26430\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Deep learning\",\"topicId\":\"2762\",\"url\":\"https://www.semanticscholar.org/topic/2762\"},{\"topic\":\"Full-frame digital SLR\",\"topicId\":\"1484843\",\"url\":\"https://www.semanticscholar.org/topic/1484843\"},{\"topic\":\"End-to-end principle\",\"topicId\":\"299633\",\"url\":\"https://www.semanticscholar.org/topic/299633\"},{\"topic\":\"Approximation algorithm\",\"topicId\":\"87\",\"url\":\"https://www.semanticscholar.org/topic/87\"},{\"topic\":\"Sampling (signal processing)\",\"topicId\":\"7839\",\"url\":\"https://www.semanticscholar.org/topic/7839\"}],\"url\":\"https://www.semanticscholar.org/paper/ed74b9390eda908060fa3501b8f20a836ec98d63\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017}\n"