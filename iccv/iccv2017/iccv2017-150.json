"{\"abstract\":\"This paper proposes a network architecture to perform variable length semantic video generation using captions. We adopt a new perspective towards video generation where we allow the captions to be combined with the long-term and short-term dependencies between video frames and thus generate a video in an incremental manner. Our experiments demonstrate our network architecture\\u2019s ability to distinguish between objects, actions and interactions in a video and combine them to generate videos for unseen captions. The network also exhibits the capability to perform spatio-temporal style transfer when asked to generate videos for a sequence of captions. We also show that the network\\u2019s ability to learn a latent representation allows it generate videos in an unsupervised manner and perform other tasks such as action recognition.\",\"arxivId\":\"1708.05980\",\"authors\":[{\"authorId\":\"8268761\",\"name\":\"T. Marwah\",\"url\":\"https://www.semanticscholar.org/author/8268761\"},{\"authorId\":\"47351893\",\"name\":\"G. Mittal\",\"url\":\"https://www.semanticscholar.org/author/47351893\"},{\"authorId\":\"1699429\",\"name\":\"V. Balasubramanian\",\"url\":\"https://www.semanticscholar.org/author/1699429\"}],\"citationVelocity\":8,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"19235216\",\"name\":\"Zekun Hao\"},{\"authorId\":\"47932904\",\"name\":\"Xun Huang\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"}],\"doi\":\"10.1109/CVPR.2018.00819\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d629ee73070e7c693ae6924aa52df129a127b33\",\"title\":\"Controllable Video Generation with Sparse Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/9d629ee73070e7c693ae6924aa52df129a127b33\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9723532\",\"name\":\"Subham Mukherjee\"},{\"authorId\":\"29780808\",\"name\":\"S. Ghosh\"},{\"authorId\":\"7137430\",\"name\":\"S. Ghosh\"},{\"authorId\":\"144385555\",\"name\":\"P. Kumar\"},{\"authorId\":\"40813600\",\"name\":\"P. Roy\"}],\"doi\":\"10.1109/ICASSP.2019.8682158\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"554cf535bdb6e8c36a13fb85c22aa4f23fdc735a\",\"title\":\"Predicting Video-frames Using Encoder-convlstm Combination\",\"url\":\"https://www.semanticscholar.org/paper/554cf535bdb6e8c36a13fb85c22aa4f23fdc735a\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":\"1711.08682\",\"authors\":[{\"authorId\":\"30017683\",\"name\":\"Haoye Cai\"},{\"authorId\":\"49588814\",\"name\":\"Chunyan Bai\"},{\"authorId\":\"5068280\",\"name\":\"Yu-Wing Tai\"},{\"authorId\":\"2088295\",\"name\":\"C. Tang\"}],\"doi\":\"10.1007/978-3-030-01216-8_23\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a35fd89c4ea33d741b0ce0cf17bfb2e750aea51e\",\"title\":\"Deep Video Generation, Prediction and Completion of Human Action Sequences\",\"url\":\"https://www.semanticscholar.org/paper/a35fd89c4ea33d741b0ce0cf17bfb2e750aea51e\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11611009\",\"name\":\"Chun-ye Li\"},{\"authorId\":\"8756547\",\"name\":\"Liya Kong\"},{\"authorId\":\"153043900\",\"name\":\"Zhi-Ping Zhou\"}],\"doi\":\"10.1016/j.jvcir.2020.102956\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"32a9b74561ee7c7b2d9663248b515168676d9321\",\"title\":\"Improved-StoryGAN for sequential images visualization\",\"url\":\"https://www.semanticscholar.org/paper/32a9b74561ee7c7b2d9663248b515168676d9321\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50218076\",\"name\":\"Z. Wang\"},{\"authorId\":\"51300955\",\"name\":\"Taiping Yao\"},{\"authorId\":\"48056150\",\"name\":\"Huawei Wei\"},{\"authorId\":\"51303943\",\"name\":\"Shanyan Guan\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"}],\"doi\":\"10.1007/978-3-030-00767-6_29\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bf52f10c6f23f99cda01b7c33541f4dab1f7667d\",\"title\":\"Multi-person/Group Interactive Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/bf52f10c6f23f99cda01b7c33541f4dab1f7667d\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1854982013\",\"name\":\"Haijun Xia\"}],\"doi\":\"10.1145/3379337.3415845\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b1ed6eed4562a3dd635aa02fe2b74ba7ad0908f7\",\"title\":\"Crosspower: Bridging Graphics and Linguistics\",\"url\":\"https://www.semanticscholar.org/paper/b1ed6eed4562a3dd635aa02fe2b74ba7ad0908f7\",\"venue\":\"UIST\",\"year\":2020},{\"arxivId\":\"1910.06699\",\"authors\":[{\"authorId\":\"37868227\",\"name\":\"C. D. Souza\"},{\"authorId\":\"1799820\",\"name\":\"Adrien Gaidon\"},{\"authorId\":\"3407519\",\"name\":\"Y. Cabon\"},{\"authorId\":\"26734366\",\"name\":\"N. Murray\"},{\"authorId\":\"3940956\",\"name\":\"A. Pe\\u00f1a\"}],\"doi\":\"10.1007/s11263-019-01222-z\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"099bdf9cf1c59c7f5ed201759157fb505f51a762\",\"title\":\"Generating Human Action Videos by Coupling 3D Game Engines and Probabilistic Graphical Models\",\"url\":\"https://www.semanticscholar.org/paper/099bdf9cf1c59c7f5ed201759157fb505f51a762\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"1905.03820\",\"authors\":[{\"authorId\":\"1753356\",\"name\":\"Lele Chen\"},{\"authorId\":\"4053196\",\"name\":\"Ross K. Maddox\"},{\"authorId\":\"3270912\",\"name\":\"Z. Duan\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":\"10.1109/CVPR.2019.00802\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a0852cd9a026bc90168fa85fa422cb0e48f98394\",\"title\":\"Hierarchical Cross-Modal Talking Face Generation With Dynamic Pixel-Wise Loss\",\"url\":\"https://www.semanticscholar.org/paper/a0852cd9a026bc90168fa85fa422cb0e48f98394\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699429\",\"name\":\"V. Balasubramanian\"}],\"doi\":\"10.1007/978-981-13-0716-4_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4a52bf74e6bcbba58e80fbba11f96c1af61f890a\",\"title\":\"From Recognition to Generation Using Deep Learning: A Case Study with Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/4a52bf74e6bcbba58e80fbba11f96c1af61f890a\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1804.03608\",\"authors\":[{\"authorId\":\"1911972\",\"name\":\"Tanmay Gupta\"},{\"authorId\":\"34846449\",\"name\":\"D. Schwenk\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"2433269\",\"name\":\"Derek Hoiem\"},{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"}],\"doi\":\"10.1007/978-3-030-01237-3_37\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8de82efafb912de15bde3bf2e40a31c1cf3dc1b7\",\"title\":\"Imagine This! Scripts to Compositions to Videos\",\"url\":\"https://www.semanticscholar.org/paper/8de82efafb912de15bde3bf2e40a31c1cf3dc1b7\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47882735\",\"name\":\"Jingwei Xu\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"46948132\",\"name\":\"Zefan Li\"},{\"authorId\":\"3392007\",\"name\":\"Shuo Cheng\"},{\"authorId\":\"1795291\",\"name\":\"X. Yang\"}],\"doi\":\"10.1109/CVPR.2018.00158\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6ff497677f27d3e45e4633550c1a0e5243b8fa3b\",\"title\":\"Structure Preserving Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/6ff497677f27d3e45e4633550c1a0e5243b8fa3b\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46772290\",\"name\":\"X. Chen\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"}],\"doi\":\"10.1109/ICME.2019.00280\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"70b69cc055bf7f36d65269aa071daaf234333c14\",\"title\":\"Multi-Timescale Context Encoding for Scene Parsing Prediction\",\"url\":\"https://www.semanticscholar.org/paper/70b69cc055bf7f36d65269aa071daaf234333c14\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1854982013\",\"name\":\"Haijun Xia\"},{\"authorId\":\"145675849\",\"name\":\"Jennifer Jacobs\"},{\"authorId\":\"1820412\",\"name\":\"M. Agrawala\"}],\"doi\":\"10.1145/3379337.3415882\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0398b2953ee825a0646e1ab2c34019828f7d4369\",\"title\":\"Crosscast: Adding Visuals to Audio Travel Podcasts\",\"url\":\"https://www.semanticscholar.org/paper/0398b2953ee825a0646e1ab2c34019828f7d4369\",\"venue\":\"UIST\",\"year\":2020},{\"arxivId\":\"2006.15327\",\"authors\":[{\"authorId\":\"48319922\",\"name\":\"A. Bar\"},{\"authorId\":\"46796686\",\"name\":\"Roei Herzig\"},{\"authorId\":\"122024152\",\"name\":\"Xiaolong Wang\"},{\"authorId\":\"1732280\",\"name\":\"Gal Chechik\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"1786843\",\"name\":\"A. Globerson\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cdc4ae0adcff94e9ea4591f25b81f88c93cb4fbe\",\"title\":\"Compositional Video Synthesis with Action Graphs\",\"url\":\"https://www.semanticscholar.org/paper/cdc4ae0adcff94e9ea4591f25b81f88c93cb4fbe\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46772115\",\"name\":\"Xinyuan Chen\"},{\"authorId\":\"145371957\",\"name\":\"Chang Xu\"},{\"authorId\":\"15469693\",\"name\":\"Xiaokang Yang\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/TIP.2020.2998297\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7cc5cdb2512894678265cd967e329f0331c81d5a\",\"title\":\"Long-Term Video Prediction via Criticization and Retrospection\",\"url\":\"https://www.semanticscholar.org/paper/7cc5cdb2512894678265cd967e329f0331c81d5a\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1523761688\",\"name\":\"Aziz Siyaev\"},{\"authorId\":\"144089347\",\"name\":\"G. Jo\"}],\"doi\":\"10.1007/978-3-030-41964-6_26\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2ef69c67e3129526ad616985a38fbd51f360d218\",\"title\":\"GOHAG: GANs Orchestration for Human Actions Generation\",\"url\":\"https://www.semanticscholar.org/paper/2ef69c67e3129526ad616985a38fbd51f360d218\",\"venue\":\"ACIIDS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7351931\",\"name\":\"Supriya Pandhre\"},{\"authorId\":\"1699429\",\"name\":\"V. Balasubramanian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"522d816e52024863a940bc2ef61c3dae2a465740\",\"title\":\"Understanding Graph Data Through DeepLearning Lens\",\"url\":\"https://www.semanticscholar.org/paper/522d816e52024863a940bc2ef61c3dae2a465740\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"100576986\",\"name\":\"Yue Liu\"},{\"authorId\":\"122024145\",\"name\":\"Xin Wang\"},{\"authorId\":\"48009996\",\"name\":\"Yitian Yuan\"},{\"authorId\":\"145583986\",\"name\":\"Wenwu Zhu\"}],\"doi\":\"10.1145/3343031.3350986\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"3bd195e11cb554cb5f3a7ac6aab8111d03cb46c6\",\"title\":\"Cross-Modal Dual Learning for Sentence-to-Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/3bd195e11cb554cb5f3a7ac6aab8111d03cb46c6\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1807.02635\",\"authors\":[{\"authorId\":\"2338742\",\"name\":\"Y. Jang\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5ec868ebe59918f94140bb2889b9027c55c09b65\",\"title\":\"Video Prediction with Appearance and Motion Conditions\",\"url\":\"https://www.semanticscholar.org/paper/5ec868ebe59918f94140bb2889b9027c55c09b65\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":\"1706.00212\",\"authors\":[{\"authorId\":\"1780882\",\"name\":\"W. Zhang\"},{\"authorId\":\"143750989\",\"name\":\"F. Gao\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"7667912\",\"name\":\"L. Duan\"},{\"authorId\":\"3460423\",\"name\":\"Yichao Yan\"},{\"authorId\":\"47882735\",\"name\":\"Jingwei Xu\"},{\"authorId\":\"1795291\",\"name\":\"X. Yang\"}],\"doi\":\"10.1145/3240508.3240584\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"141cf9795a1d4986d604a606184ce4317da49733\",\"title\":\"Depth Structure Preserving Scene Image Generation\",\"url\":\"https://www.semanticscholar.org/paper/141cf9795a1d4986d604a606184ce4317da49733\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1812.01261\",\"authors\":[{\"authorId\":\"48333400\",\"name\":\"S. Yamamoto\"},{\"authorId\":\"1399435786\",\"name\":\"Antonio Tejero-de-Pablos\"},{\"authorId\":\"3250559\",\"name\":\"Y. Ushiku\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e8de3d97d14344d13d15701eea8d6a27c696e27a\",\"title\":\"Conditional Video Generation Using Action-Appearance Captions\",\"url\":\"https://www.semanticscholar.org/paper/e8de3d97d14344d13d15701eea8d6a27c696e27a\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144839067\",\"name\":\"Amir Mazaheri\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"fa2030f41aa0b54965420eb7836c7c32a91b087b\",\"title\":\"Video Content Understanding Using Text\",\"url\":\"https://www.semanticscholar.org/paper/fa2030f41aa0b54965420eb7836c7c32a91b087b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1904.02912\",\"authors\":[{\"authorId\":\"40897201\",\"name\":\"Tsun-Hsuan Wang\"},{\"authorId\":\"94288126\",\"name\":\"Y. Cheng\"},{\"authorId\":\"49044307\",\"name\":\"Chieh Hubert Lin\"},{\"authorId\":\"1803730\",\"name\":\"Hwann-Tzong Chen\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":\"10.1109/ICCV.2019.01059\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cb0a151cf8740c66b461ff809e086b91f14bd23b\",\"title\":\"Point-to-Point Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/cb0a151cf8740c66b461ff809e086b91f14bd23b\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1819450790\",\"name\":\"Qi Chen\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"49251914\",\"name\":\"Jun-kai Chen\"},{\"authorId\":\"8277017\",\"name\":\"Q. Wu\"},{\"authorId\":\"133678193\",\"name\":\"A. van den Hengel\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"}],\"doi\":\"10.1109/TIP.2020.3003227\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5a2418fd9c453492f1ca833d5595571249a3ee55\",\"title\":\"Scripted Video Generation With a Bottom-Up Generative Adversarial Network\",\"url\":\"https://www.semanticscholar.org/paper/5a2418fd9c453492f1ca833d5595571249a3ee55\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020}],\"corpusId\":26547274,\"doi\":\"10.1109/ICCV.2017.159\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":1,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"1491b98d8e9ccca13bec883f94d935d2dff24053\",\"references\":[{\"arxivId\":\"1212.0402\",\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"title\":\"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\",\"url\":\"https://www.semanticscholar.org/paper/da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":\"1612.03242\",\"authors\":[{\"authorId\":\"120811666\",\"name\":\"Han Zhang\"},{\"authorId\":\"145017761\",\"name\":\"Tao Xu\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"}],\"doi\":\"10.1109/ICCV.2017.629\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ea67d2d5f2a7d5760ec6b67ea93d11dd5affa921\",\"title\":\"StackGAN: Text to Photo-Realistic Image Synthesis with Stacked Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/ea67d2d5f2a7d5760ec6b67ea93d11dd5affa921\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"28919105\",\"name\":\"Raymond A. Yeh\"},{\"authorId\":\"1696291\",\"name\":\"Chen Chen\"},{\"authorId\":\"33494814\",\"name\":\"Teck-Yian Lim\"},{\"authorId\":\"1399115926\",\"name\":\"M. Hasegawa-Johnson\"},{\"authorId\":\"1834451\",\"name\":\"M. Do\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a1b3d8a94323122d63a1ec31c1d722d30c509cb4\",\"title\":\"Semantic Image Inpainting with Perceptual and Contextual Losses\",\"url\":\"https://www.semanticscholar.org/paper/a1b3d8a94323122d63a1ec31c1d722d30c509cb4\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1610.00527\",\"authors\":[{\"authorId\":\"2583391\",\"name\":\"Nal Kalchbrenner\"},{\"authorId\":\"3422336\",\"name\":\"A. Oord\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1841008\",\"name\":\"Ivo Danihelka\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b01871c114b122340209562972ff515b86b16ccf\",\"title\":\"Video Pixel Networks\",\"url\":\"https://www.semanticscholar.org/paper/b01871c114b122340209562972ff515b86b16ccf\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1748557\",\"name\":\"P. Smolensky\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4f7476037408ac3d993f5088544aab427bc319c1\",\"title\":\"Information processing in dynamical systems: foundations of harmony theory\",\"url\":\"https://www.semanticscholar.org/paper/4f7476037408ac3d993f5088544aab427bc319c1\",\"venue\":\"\",\"year\":1986},{\"arxivId\":\"1605.07723\",\"authors\":[{\"authorId\":\"50003118\",\"name\":\"Alexander J. Ratner\"},{\"authorId\":\"1801197\",\"name\":\"C. D. Sa\"},{\"authorId\":\"144766615\",\"name\":\"Sen Wu\"},{\"authorId\":\"2196579\",\"name\":\"Daniel Selsam\"},{\"authorId\":\"144988097\",\"name\":\"C. R\\u00e9\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"37acbbbcfe9d8eb89e5b01da28dac6d44c3903ee\",\"title\":\"Data Programming: Creating Large Training Sets, Quickly\",\"url\":\"https://www.semanticscholar.org/paper/37acbbbcfe9d8eb89e5b01da28dac6d44c3903ee\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3285716\",\"name\":\"Xinye Lin\"},{\"authorId\":\"9527255\",\"name\":\"Yixin Chen\"},{\"authorId\":\"1871246\",\"name\":\"X. Chang\"},{\"authorId\":\"1723807\",\"name\":\"X. Liu\"},{\"authorId\":\"47119262\",\"name\":\"X. Wang\"}],\"doi\":\"10.1145/3161412\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"299b07ec255398c7f9d147cb39d113e4926cc51b\",\"title\":\"SHOW\",\"url\":\"https://www.semanticscholar.org/paper/299b07ec255398c7f9d147cb39d113e4926cc51b\",\"venue\":\"IMWUT\",\"year\":2018},{\"arxivId\":\"1607.07539\",\"authors\":[{\"authorId\":\"28919105\",\"name\":\"Raymond A. Yeh\"},{\"authorId\":\"1696291\",\"name\":\"Chen Chen\"},{\"authorId\":\"33494814\",\"name\":\"Teck-Yian Lim\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"1399115926\",\"name\":\"M. Hasegawa-Johnson\"},{\"authorId\":\"1834451\",\"name\":\"M. Do\"}],\"doi\":\"10.1109/CVPR.2017.728\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a3bf4d403a39ed33f0fa8cf78dc906d6130595f\",\"title\":\"Semantic Image Inpainting with Deep Generative Models\",\"url\":\"https://www.semanticscholar.org/paper/8a3bf4d403a39ed33f0fa8cf78dc906d6130595f\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1409.3215\",\"authors\":[{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cea967b59209c6be22829699f05b8b1ac4dc092d\",\"title\":\"Sequence to Sequence Learning with Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/cea967b59209c6be22829699f05b8b1ac4dc092d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1605.05396\",\"authors\":[{\"authorId\":\"144828948\",\"name\":\"S. Reed\"},{\"authorId\":\"2893664\",\"name\":\"Zeynep Akata\"},{\"authorId\":\"3084614\",\"name\":\"Xinchen Yan\"},{\"authorId\":\"2876316\",\"name\":\"L. Logeswaran\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c7f040a150abf21dbcefe1f22e0f98fa184f41a\",\"title\":\"Generative Adversarial Text to Image Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/6c7f040a150abf21dbcefe1f22e0f98fa184f41a\",\"venue\":\"ICML\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"R. Kiros\"},{\"authorId\":null,\"name\":\"Y. Zhu\"},{\"authorId\":null,\"name\":\"R. R. Salakhutdinov\"},{\"authorId\":null,\"name\":\"R. Zemel\"},{\"authorId\":null,\"name\":\"R. Urtasun\"},{\"authorId\":null,\"name\":\"A. Torralba\"},{\"authorId\":null,\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Skip-thought vectors. In Advances in neural information processing\",\"url\":\"\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"85021c84383d18a7a4434d76dc8135fc6bdc0aa6\",\"title\":\"Deep Boltzmann Machines\",\"url\":\"https://www.semanticscholar.org/paper/85021c84383d18a7a4434d76dc8135fc6bdc0aa6\",\"venue\":\"AISTATS\",\"year\":2009},{\"arxivId\":\"1611.06624\",\"authors\":[{\"authorId\":\"144648787\",\"name\":\"M. Saito\"},{\"authorId\":\"8252749\",\"name\":\"E. Matsumoto\"},{\"authorId\":\"3083107\",\"name\":\"Shunta Saito\"}],\"doi\":\"10.1109/ICCV.2017.308\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"062c41dad67bb68fefd9ff0c5c4d296e796004dc\",\"title\":\"Temporal Generative Adversarial Nets with Singular Value Clipping\",\"url\":\"https://www.semanticscholar.org/paper/062c41dad67bb68fefd9ff0c5c4d296e796004dc\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"},{\"authorId\":\"2217144\",\"name\":\"Simon Osindero\"},{\"authorId\":\"1725303\",\"name\":\"Y. Teh\"}],\"doi\":\"10.1162/neco.2006.18.7.1527\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8978cf7574ceb35f4c3096be768c7547b28a35d0\",\"title\":\"A Fast Learning Algorithm for Deep Belief Nets\",\"url\":\"https://www.semanticscholar.org/paper/8978cf7574ceb35f4c3096be768c7547b28a35d0\",\"venue\":\"Neural Computation\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1403025868\",\"name\":\"Jean Pouget-Abadie\"},{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"144738865\",\"name\":\"Bing Xu\"},{\"authorId\":\"1393680089\",\"name\":\"David Warde-Farley\"},{\"authorId\":\"1955694\",\"name\":\"Sherjil Ozair\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"title\":\"Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1609.02612\",\"authors\":[{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"2367683\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.13016/M26GIH-TNYZ\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ee091ccf24c4f053c5c3dfbefe4a7975ed3447c1\",\"title\":\"Generating Videos with Scene Dynamics\",\"url\":\"https://www.semanticscholar.org/paper/ee091ccf24c4f053c5c3dfbefe4a7975ed3447c1\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/ICCV.2015.510\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"title\":\"Learning Spatiotemporal Features with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1502.04623\",\"authors\":[{\"authorId\":\"144717963\",\"name\":\"K. Gregor\"},{\"authorId\":\"1841008\",\"name\":\"Ivo Danihelka\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"1748523\",\"name\":\"Danilo Jimenez Rezende\"},{\"authorId\":\"1688276\",\"name\":\"Daan Wierstra\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a2785f66c20fbdf30ec26c0931584c6d6a0f4fca\",\"title\":\"DRAW: A Recurrent Neural Network For Image Generation\",\"url\":\"https://www.semanticscholar.org/paper/a2785f66c20fbdf30ec26c0931584c6d6a0f4fca\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2712738\",\"name\":\"C. Sch\\u00fcldt\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"3033284\",\"name\":\"B. Caputo\"}],\"doi\":\"10.1109/icpr.2004.1334462\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b480f6a3750b4cebaf1db205692c8321d45926a2\",\"title\":\"Recognizing human actions: a local SVM approach\",\"url\":\"https://www.semanticscholar.org/paper/b480f6a3750b4cebaf1db205692c8321d45926a2\",\"venue\":\"Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004.\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144648787\",\"name\":\"M. Saito\"},{\"authorId\":\"8252749\",\"name\":\"E. Matsumoto\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f0f4f16d5b5f9efe304369120651fa688a03d495\",\"title\":\"Temporal Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/f0f4f16d5b5f9efe304369120651fa688a03d495\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"152821938\",\"name\":\"Sanketh Shetty\"},{\"authorId\":\"120906511\",\"name\":\"T. Leung\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2014.223\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"title\":\"Large-Scale Video Classification with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1609.04802\",\"authors\":[{\"authorId\":\"1779917\",\"name\":\"C. Ledig\"},{\"authorId\":\"2073063\",\"name\":\"L. Theis\"},{\"authorId\":\"3108066\",\"name\":\"Ferenc Husz\\u00e1r\"},{\"authorId\":\"79382929\",\"name\":\"J. Caballero\"},{\"authorId\":\"83015038\",\"name\":\"Andrew Aitken\"},{\"authorId\":\"41203992\",\"name\":\"Alykhan Tejani\"},{\"authorId\":\"1853456\",\"name\":\"J. Totz\"},{\"authorId\":\"34627233\",\"name\":\"Zehan Wang\"},{\"authorId\":\"152554375\",\"name\":\"W. Shi\"}],\"doi\":\"10.1109/CVPR.2017.19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"df0c54fe61f0ffb9f0e36a17c2038d9a1964cba3\",\"title\":\"Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network\",\"url\":\"https://www.semanticscholar.org/paper/df0c54fe61f0ffb9f0e36a17c2038d9a1964cba3\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1502.04681\",\"authors\":[{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"2711409\",\"name\":\"Elman Mansimov\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"title\":\"Unsupervised Learning of Video Representations using LSTMs\",\"url\":\"https://www.semanticscholar.org/paper/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1410.5401\",\"authors\":[{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"89504302\",\"name\":\"G. Wayne\"},{\"authorId\":\"1841008\",\"name\":\"Ivo Danihelka\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c3823aacea60bc1f2cabb9283144690a3d015db5\",\"title\":\"Neural Turing Machines\",\"url\":\"https://www.semanticscholar.org/paper/c3823aacea60bc1f2cabb9283144690a3d015db5\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":\"1506.06726\",\"authors\":[{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"2214033\",\"name\":\"Y. Zhu\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6e795c6e9916174ae12349f5dc3f516570c17ce8\",\"title\":\"Skip-Thought Vectors\",\"url\":\"https://www.semanticscholar.org/paper/6e795c6e9916174ae12349f5dc3f516570c17ce8\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5886094\",\"name\":\"P. Cochat\"},{\"authorId\":\"13267685\",\"name\":\"L. Vaucoret\"},{\"authorId\":\"31455512\",\"name\":\"J. Sarles\"}],\"doi\":\"10.1016/j.arcped.2012.01.013\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"10d85561e4aafc516d10064f30dff05b41f70afe\",\"title\":\"[Et al].\",\"url\":\"https://www.semanticscholar.org/paper/10d85561e4aafc516d10064f30dff05b41f70afe\",\"venue\":\"Archives de pediatrie : organe officiel de la Societe francaise de pediatrie\",\"year\":2012},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"65911798\",\"name\":\"A. Spring\"},{\"authorId\":\"7753714\",\"name\":\"M. Lewerentz\"},{\"authorId\":\"32009199\",\"name\":\"T. Bluhm\"},{\"authorId\":\"144508212\",\"name\":\"P. Heimann\"},{\"authorId\":\"24269814\",\"name\":\"C. Hennig\"},{\"authorId\":\"92119326\",\"name\":\"G. K\\u00fchner\"},{\"authorId\":\"153933286\",\"name\":\"H. Kroiss\"},{\"authorId\":\"40378213\",\"name\":\"J. Krom\"},{\"authorId\":\"152933601\",\"name\":\"H. Laqua\"},{\"authorId\":\"46816398\",\"name\":\"J. Maier\"},{\"authorId\":\"40588319\",\"name\":\"H. Riemann\"},{\"authorId\":\"46356567\",\"name\":\"J. Schacht\"},{\"authorId\":\"49058670\",\"name\":\"A. Werner\"},{\"authorId\":\"7411314\",\"name\":\"M. Zilker\"}],\"doi\":\"10.1007/3-540-26367-5_1\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"70fd66e78add02052f0883363e1d80dcd3f6baab\",\"title\":\"A\",\"url\":\"https://www.semanticscholar.org/paper/70fd66e78add02052f0883363e1d80dcd3f6baab\",\"venue\":\"Therapielexikon Neurologie\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1729571\",\"name\":\"Kihyuk Sohn\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"},{\"authorId\":\"3084614\",\"name\":\"Xinchen Yan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"3f25e17eb717e5894e0404ea634451332f85d287\",\"title\":\"Learning Structured Output Representation using Deep Conditional Generative Models\",\"url\":\"https://www.semanticscholar.org/paper/3f25e17eb717e5894e0404ea634451332f85d287\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1511.02793\",\"authors\":[{\"authorId\":\"2711409\",\"name\":\"Elman Mansimov\"},{\"authorId\":\"3166516\",\"name\":\"Emilio Parisotto\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0875fc92cce33df5cf7df169590dbf0ca00d2652\",\"title\":\"Generating Images from Captions with Attention\",\"url\":\"https://www.semanticscholar.org/paper/0875fc92cce33df5cf7df169590dbf0ca00d2652\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":\"1609.03499\",\"authors\":[{\"authorId\":\"3422336\",\"name\":\"A. Oord\"},{\"authorId\":\"48373216\",\"name\":\"S. Dieleman\"},{\"authorId\":\"1691713\",\"name\":\"H. Zen\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"2583391\",\"name\":\"Nal Kalchbrenner\"},{\"authorId\":\"33666044\",\"name\":\"A. Senior\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"df0402517a7338ae28bc54acaac400de6b456a46\",\"title\":\"WaveNet: A Generative Model for Raw Audio\",\"url\":\"https://www.semanticscholar.org/paper/df0402517a7338ae28bc54acaac400de6b456a46\",\"venue\":\"SSW\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1162/neco.1997.9.8.1735\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"title\":\"Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"venue\":\"Neural Computation\",\"year\":1997},{\"arxivId\":\"1312.6114\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"1678311\",\"name\":\"M. Welling\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5f5dc5b9a2ba710937e2c413b37b053cd673df02\",\"title\":\"Auto-Encoding Variational Bayes\",\"url\":\"https://www.semanticscholar.org/paper/5f5dc5b9a2ba710937e2c413b37b053cd673df02\",\"venue\":\"ICLR\",\"year\":2014},{\"arxivId\":\"1606.07873\",\"authors\":[{\"authorId\":\"143928130\",\"name\":\"J. Walker\"},{\"authorId\":\"2786693\",\"name\":\"C. Doersch\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1007/978-3-319-46478-7_51\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5e96c4626e4b3d09727bcbfbdb2672dd9b886743\",\"title\":\"An Uncertain Future: Forecasting from Static Images Using Variational Autoencoders\",\"url\":\"https://www.semanticscholar.org/paper/5e96c4626e4b3d09727bcbfbdb2672dd9b886743\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1511.06434\",\"authors\":[{\"authorId\":\"38909097\",\"name\":\"A. Radford\"},{\"authorId\":\"2096458\",\"name\":\"Luke Metz\"},{\"authorId\":\"2127604\",\"name\":\"Soumith Chintala\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8388f1be26329fa45e5807e968a641ce170ea078\",\"title\":\"Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/8388f1be26329fa45e5807e968a641ce170ea078\",\"venue\":\"ICLR\",\"year\":2016}],\"title\":\"Attentive Semantic Video Generation Using Captions\",\"topics\":[{\"topic\":\"Network architecture\",\"topicId\":\"58473\",\"url\":\"https://www.semanticscholar.org/topic/58473\"},{\"topic\":\"Unsupervised learning\",\"topicId\":\"7721\",\"url\":\"https://www.semanticscholar.org/topic/7721\"},{\"topic\":\"Interaction\",\"topicId\":\"72\",\"url\":\"https://www.semanticscholar.org/topic/72\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"}],\"url\":\"https://www.semanticscholar.org/paper/1491b98d8e9ccca13bec883f94d935d2dff24053\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017}\n"