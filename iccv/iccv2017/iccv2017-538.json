"{\"abstract\":\"The inherent dependencies between visual elements and aural elements are crucial for affective video content analyses, yet have not been successfully exploited. Therefore, we propose a multimodal deep regression Bayesian network (MMDRBN) to capture the dependencies between visual elements and aural elements for affective video content analyses. The regression Bayesian network (RBN) is a directed graphical model consisting of one latent layer and one visible layer. Due to the explaining away effect in Bayesian networks (BN), RBN is able to capture both the dependencies among the latent variables given the observation and the dependencies among visible variables. We propose a fast learning algorithm to learn the RBN. For the MMDRB-N, first, we learn several RBNs layer-wisely from visual modality and audio modality respectively. Then we stack these RBNs and obtain two deep networks. After that, a joint representation is extracted from the top layers of the two deep networks, and thus captures the high order dependencies between visual modality and audio modality. In order to predict the valence or arousal score of video contents, we initialize a feed-forward inference network from the MMDRBN whose inference is intractable by minimizing the KullbackCLeibler (KL)divergence between the two networks. The back propagation algorithm is adopted for finetuning the inference network. Experimental results on the LIRIS-ACCEDE database demonstrate that the proposed MMDRBN successfully captures the dependencies between visual and audio elements, and thus achieves better performance compared with state-of-the-art work.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"2316359\",\"name\":\"Q. Gan\",\"url\":\"https://www.semanticscholar.org/author/2316359\"},{\"authorId\":\"1791319\",\"name\":\"Shangfei Wang\",\"url\":\"https://www.semanticscholar.org/author/1791319\"},{\"authorId\":\"32273998\",\"name\":\"L. Hao\",\"url\":\"https://www.semanticscholar.org/author/32273998\"},{\"authorId\":\"50426357\",\"name\":\"Q. Ji\",\"url\":\"https://www.semanticscholar.org/author/50426357\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"151488176\",\"name\":\"B. Li\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"},{\"authorId\":\"98482059\",\"name\":\"Shan Li\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"}],\"doi\":\"10.1109/ICME.2019.00150\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7d255b0ba6a3f6142a0c0402f28a8b1494861108\",\"title\":\"Affective Video Content Analyses by Using Cross-Modal Embedding Learning Features\",\"url\":\"https://www.semanticscholar.org/paper/7d255b0ba6a3f6142a0c0402f28a8b1494861108\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144392699\",\"name\":\"T. Ogawa\"},{\"authorId\":\"3493510\",\"name\":\"Y. Sasaka\"},{\"authorId\":\"47761580\",\"name\":\"K. Maeda\"},{\"authorId\":\"144029207\",\"name\":\"M. Haseyama\"}],\"doi\":\"10.1109/ACCESS.2018.2876710\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"9e2f9966df1e270c32246d32cce722170d322f53\",\"title\":\"Favorite Video Classification Based on Multimodal Bidirectional LSTM\",\"url\":\"https://www.semanticscholar.org/paper/9e2f9966df1e270c32246d32cce722170d322f53\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31531431\",\"name\":\"Y. Yi\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"1409762283\",\"name\":\"Qinyu Li\"}],\"doi\":\"10.1109/TMM.2019.2955300\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"3beaebdfeff10f55fef4de5e6802b7eb54509e2d\",\"title\":\"Affective Video Content Analysis With Adaptive Fusion Recurrent Network\",\"url\":\"https://www.semanticscholar.org/paper/3beaebdfeff10f55fef4de5e6802b7eb54509e2d\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4509077\",\"name\":\"Xiaowei Gu\"},{\"authorId\":\"144798254\",\"name\":\"Lu Lu\"},{\"authorId\":\"9215533\",\"name\":\"Shaojian Qiu\"},{\"authorId\":\"153150524\",\"name\":\"Quan-Yi Zou\"},{\"authorId\":\"47087340\",\"name\":\"Zhanyu Yang\"}],\"doi\":\"10.1016/j.neucom.2020.05.026\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c76840ebf65e9d4e99ec71242048723e8f81f945\",\"title\":\"Sentiment key frame extraction in user-generated micro-videos via low-rank and sparse representation\",\"url\":\"https://www.semanticscholar.org/paper/c76840ebf65e9d4e99ec71242048723e8f81f945\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150354134\",\"name\":\"Yaochen Zhu\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"},{\"authorId\":\"51239188\",\"name\":\"Fengcheng Wu\"}],\"doi\":\"10.1145/3343031.3350997\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dfe75696f84da05a7b7a16e751772f5f16343f39\",\"title\":\"Multimodal Deep Denoise Framework for Affective Video Content Analysis\",\"url\":\"https://www.semanticscholar.org/paper/dfe75696f84da05a7b7a16e751772f5f16343f39\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1909.01763\",\"authors\":[{\"authorId\":\"98697840\",\"name\":\"Jie Zhang\"},{\"authorId\":\"47827239\",\"name\":\"Yin Zhao\"},{\"authorId\":\"2651246\",\"name\":\"Longjun Cai\"},{\"authorId\":\"144789277\",\"name\":\"Chaoping Tu\"},{\"authorId\":\"144031978\",\"name\":\"Wu Wei\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"72ffabfbc7a633dce5e634f4b613569572894bc3\",\"title\":\"Video Affective Effects Prediction with Multi-modal Fusion and Shot-Long Temporal Context\",\"url\":\"https://www.semanticscholar.org/paper/72ffabfbc7a633dce5e634f4b613569572894bc3\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51264244\",\"name\":\"Xingliang Cheng\"},{\"authorId\":\"50982400\",\"name\":\"Xiaotong Zhang\"},{\"authorId\":\"9450377\",\"name\":\"Mingxing Xu\"},{\"authorId\":\"1732885\",\"name\":\"T. Zheng\"}],\"doi\":\"10.23919/APSIPA.2018.8659514\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"94600a3d8a4a678841349fd19c0325f3836b9d1c\",\"title\":\"MMANN: Multimodal Multilevel Attention Neural Network for Horror Clip Detection\",\"url\":\"https://www.semanticscholar.org/paper/94600a3d8a4a678841349fd19c0325f3836b9d1c\",\"venue\":\"2018 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1791319\",\"name\":\"Shangfei Wang\"},{\"authorId\":\"32273998\",\"name\":\"L. Hao\"},{\"authorId\":\"50426357\",\"name\":\"Q. Ji\"}],\"doi\":\"10.1109/TMM.2019.2934824\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e15c41e45323d66f513b3807567efe9c8c3b7ea8\",\"title\":\"Knowledge-Augmented Multimodal Deep Regression Bayesian Networks for Emotion Video Tagging\",\"url\":\"https://www.semanticscholar.org/paper/e15c41e45323d66f513b3807567efe9c8c3b7ea8\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47093250\",\"name\":\"J. Guo\"},{\"authorId\":\"144977494\",\"name\":\"Bin Song\"},{\"authorId\":\"33487571\",\"name\":\"Peng Zhang\"},{\"authorId\":\"49147132\",\"name\":\"Mengdi Ma\"},{\"authorId\":\"5937630\",\"name\":\"Wenwen Luo\"},{\"authorId\":\"6766051\",\"name\":\"J. Lv\"}],\"doi\":\"10.1016/J.INFFUS.2019.02.007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b800f96b2c32def48bf4c6a302499244f5a23689\",\"title\":\"Affective video content analysis based on multimodal data fusion in heterogeneous networks\",\"url\":\"https://www.semanticscholar.org/paper/b800f96b2c32def48bf4c6a302499244f5a23689\",\"venue\":\"Inf. Fusion\",\"year\":2019}],\"corpusId\":6926927,\"doi\":\"10.1109/ICCV.2017.547\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"32afaf0c0ce2977d38b567972ce80d35151bc119\",\"references\":[{\"arxivId\":\"1312.6114\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"1678311\",\"name\":\"M. Welling\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5f5dc5b9a2ba710937e2c413b37b053cd673df02\",\"title\":\"Auto-Encoding Variational Bayes\",\"url\":\"https://www.semanticscholar.org/paper/5f5dc5b9a2ba710937e2c413b37b053cd673df02\",\"venue\":\"ICLR\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144834368\",\"name\":\"L. Pang\"},{\"authorId\":\"2066429\",\"name\":\"Shiai Zhu\"},{\"authorId\":\"143977389\",\"name\":\"C. Ngo\"}],\"doi\":\"10.1109/TMM.2015.2482228\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ab40909f4e6ce016df8a8e13a23c526d7e526bd6\",\"title\":\"Deep Multimodal Learning for Affective Analysis and Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/ab40909f4e6ce016df8a8e13a23c526d7e526bd6\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1400943991\",\"name\":\"E. Douglas-Cowie\"},{\"authorId\":\"145635430\",\"name\":\"R. Cowie\"},{\"authorId\":\"145688200\",\"name\":\"I. Sneddon\"},{\"authorId\":\"33199546\",\"name\":\"C. Cox\"},{\"authorId\":\"145865833\",\"name\":\"Orla Lowry\"},{\"authorId\":\"2314861\",\"name\":\"M. McRorie\"},{\"authorId\":\"28174013\",\"name\":\"J. Martin\"},{\"authorId\":\"1713369\",\"name\":\"L. Devillers\"},{\"authorId\":\"2094223\",\"name\":\"S. Abrilian\"},{\"authorId\":\"1745089\",\"name\":\"A. Batliner\"},{\"authorId\":\"34858847\",\"name\":\"N. Amir\"},{\"authorId\":\"1715144\",\"name\":\"K. Karpouzis\"}],\"doi\":\"10.1007/978-3-540-74889-2_43\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2d6e537b4eda87c5acb1678aba83a2339e5433db\",\"title\":\"The HUMAINE Database: Addressing the Collection and Annotation of Naturalistic and Induced Emotional Data\",\"url\":\"https://www.semanticscholar.org/paper/2d6e537b4eda87c5acb1678aba83a2339e5433db\",\"venue\":\"ACII\",\"year\":2007},{\"arxivId\":\"1304.5634\",\"authors\":[{\"authorId\":\"145371957\",\"name\":\"Chang Xu\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"},{\"authorId\":\"31796215\",\"name\":\"Chao Xu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"032d67d27ecacbf6c5b82eb67e5d02d81fb43a7a\",\"title\":\"A Survey on Multi-view Learning\",\"url\":\"https://www.semanticscholar.org/paper/032d67d27ecacbf6c5b82eb67e5d02d81fb43a7a\",\"venue\":\"ArXiv\",\"year\":2013},{\"arxivId\":\"cs/9603102\",\"authors\":[{\"authorId\":\"1796044\",\"name\":\"L. Saul\"},{\"authorId\":\"35132120\",\"name\":\"T. Jaakkola\"},{\"authorId\":\"1694621\",\"name\":\"Michael I. Jordan\"}],\"doi\":\"10.1613/jair.251\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0a79433b5feacd9e8feeafa629dae5a85f362fef\",\"title\":\"Mean Field Theory for Sigmoid Belief Networks\",\"url\":\"https://www.semanticscholar.org/paper/0a79433b5feacd9e8feeafa629dae5a85f362fef\",\"venue\":\"J. Artif. Intell. Res.\",\"year\":1996},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1748523\",\"name\":\"Danilo Jimenez Rezende\"},{\"authorId\":\"14594344\",\"name\":\"S. Mohamed\"},{\"authorId\":\"1688276\",\"name\":\"Daan Wierstra\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"484ad17c926292fbe0d5211540832a8c8a8e958b\",\"title\":\"Stochastic Backpropagation and Approximate Inference in Deep Generative Models\",\"url\":\"https://www.semanticscholar.org/paper/484ad17c926292fbe0d5211540832a8c8a8e958b\",\"venue\":\"ICML\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1791319\",\"name\":\"Shangfei Wang\"},{\"authorId\":\"50426357\",\"name\":\"Q. Ji\"}],\"doi\":\"10.1109/TAFFC.2015.2432791\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"33e4b0221e99afbc4aa8e6cd412bc02b921da5ba\",\"title\":\"Video Affective Content Analysis: A Survey of State-of-the-Art Methods\",\"url\":\"https://www.semanticscholar.org/paper/33e4b0221e99afbc4aa8e6cd412bc02b921da5ba\",\"venue\":\"IEEE Transactions on Affective Computing\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3272087\",\"name\":\"Omar Seddati\"},{\"authorId\":\"40531114\",\"name\":\"Emre Kulah\"},{\"authorId\":\"3221280\",\"name\":\"Gueorgui Pironkov\"},{\"authorId\":\"144436412\",\"name\":\"S. Dupont\"},{\"authorId\":\"144711671\",\"name\":\"S. Mahmoudi\"},{\"authorId\":\"49164810\",\"name\":\"T. Dutoit\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7044d56b1ab16a2a1bea6145bc561f54aa382004\",\"title\":\"UMons at MediaEval 2015 Affective Impact of Movies Task including Violent Scenes Detection\",\"url\":\"https://www.semanticscholar.org/paper/7044d56b1ab16a2a1bea6145bc561f54aa382004\",\"venue\":\"MediaEval\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"S. Sun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"A survey of multi-view machine learning\",\"url\":\"\",\"venue\":\"Neural Computing and Applications, 23(7-8):2031\\u20132038\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50998716\",\"name\":\"G. E. Hinton\"},{\"authorId\":\"1790646\",\"name\":\"P. Dayan\"},{\"authorId\":\"1749650\",\"name\":\"B. Frey\"},{\"authorId\":\"1764325\",\"name\":\"R. Neal\"}],\"doi\":\"10.1126/SCIENCE.7761831\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6dd01cd9c17d1491ead8c9f97597fbc61dead8ea\",\"title\":\"The \\\"wake-sleep\\\" algorithm for unsupervised neural networks.\",\"url\":\"https://www.semanticscholar.org/paper/6dd01cd9c17d1491ead8c9f97597fbc61dead8ea\",\"venue\":\"Science\",\"year\":1995},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"E. Douglas-Cowie\"},{\"authorId\":null,\"name\":\"R. Cowie\"},{\"authorId\":null,\"name\":\"I. Sneddon\"},{\"authorId\":null,\"name\":\"C. Cox\"},{\"authorId\":null,\"name\":\"O. Lowry\"},{\"authorId\":null,\"name\":\"M. Mcrorie\"},{\"authorId\":null,\"name\":\"J.-C. Martin\"},{\"authorId\":null,\"name\":\"L. Devillers\"},{\"authorId\":null,\"name\":\"S. Abrilian\"},{\"authorId\":null,\"name\":\"A. Batliner\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"et al\",\"url\":\"\",\"venue\":\"The humaine database: addressing the collection and annotation of naturalistic and induced emotional data. In International Conference on Affective Computing and Intelligent Interaction, pages 488\\u2013500. Springer\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"2229862\",\"name\":\"Baohan Xu\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e9ab17d68a35f35e026c025904d053a653b7c02e\",\"title\":\"Predicting Emotions in User-Generated Videos\",\"url\":\"https://www.semanticscholar.org/paper/e9ab17d68a35f35e026c025904d053a653b7c02e\",\"venue\":\"AAAI\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"20632291\",\"name\":\"Shiliang Sun\"}],\"doi\":\"10.1007/s00521-013-1362-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3fdd37c3a30da1dd0e376889bf2bdddc637b0b34\",\"title\":\"A survey of multi-view machine learning\",\"url\":\"https://www.semanticscholar.org/paper/3fdd37c3a30da1dd0e376889bf2bdddc637b0b34\",\"venue\":\"Neural Computing and Applications\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"5726c7b40fcc454b77d989656c085520bf6c15fa\",\"title\":\"Multimodal learning with deep Boltzmann machines\",\"url\":\"https://www.semanticscholar.org/paper/5726c7b40fcc454b77d989656c085520bf6c15fa\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145648751\",\"name\":\"H. Robbins\"}],\"doi\":\"10.1214/AOMS/1177729586\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"34ddd8865569c2c32dec9bf7ffc817ff42faaa01\",\"title\":\"A Stochastic Approximation Method\",\"url\":\"https://www.semanticscholar.org/paper/34ddd8865569c2c32dec9bf7ffc817ff42faaa01\",\"venue\":\"\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2333423\",\"name\":\"P. MarinVlastelica\"},{\"authorId\":\"34849289\",\"name\":\"S. Hayrapetyan\"},{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"123972d5b8da47a7c60c7e702c4c96f2acb59254\",\"title\":\"KIT at MediaEval 2015 - Evaluating Visual Cues for Affective Impact of Movies Task\",\"url\":\"https://www.semanticscholar.org/paper/123972d5b8da47a7c60c7e702c4c96f2acb59254\",\"venue\":\"MediaEval\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66668190\",\"name\":\"A. Vogler\"}],\"doi\":\"10.1198/tech.2004.s754\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9ecae668ad78e5ab6ef099808fea219f815cf5c4\",\"title\":\"An Introduction to Multivariate Statistical Analysis\",\"url\":\"https://www.semanticscholar.org/paper/9ecae668ad78e5ab6ef099808fea219f815cf5c4\",\"venue\":\"\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8242182\",\"name\":\"Anastasia-Theodora Timoleon\"},{\"authorId\":\"1735046\",\"name\":\"L. Hadjileontiadis\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"440c6a06368844763be9fa076c8b8d6f8122f4b0\",\"title\":\"AUTH-SGP in MediaEval 2016 Emotional Impact of Movies Task\",\"url\":\"https://www.semanticscholar.org/paper/440c6a06368844763be9fa076c8b8d6f8122f4b0\",\"venue\":\"MediaEval\",\"year\":2016},{\"arxivId\":\"cs/0609071\",\"authors\":[{\"authorId\":\"143683998\",\"name\":\"S. Akaho\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d374c48cf79d8dfb767e27474a619542c0d75406\",\"title\":\"A kernel method for canonical correlation analysis\",\"url\":\"https://www.semanticscholar.org/paper/d374c48cf79d8dfb767e27474a619542c0d75406\",\"venue\":\"ArXiv\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2612511\",\"name\":\"Shiyu Chen\"},{\"authorId\":\"1791319\",\"name\":\"Shangfei Wang\"},{\"authorId\":\"2935752\",\"name\":\"Chongliang Wu\"},{\"authorId\":\"143709116\",\"name\":\"Zhen Gao\"},{\"authorId\":\"1713704\",\"name\":\"Xiaoxiao Shi\"},{\"authorId\":\"50426357\",\"name\":\"Q. Ji\"}],\"doi\":\"10.1109/ICPR.2016.7899649\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dfe88e70e0524a5be9f14245fea38b0dcffebc95\",\"title\":\"Implicit hybrid video emotion tagging by integrating video content and users' multiple physiological responses\",\"url\":\"https://www.semanticscholar.org/paper/dfe88e70e0524a5be9f14245fea38b0dcffebc95\",\"venue\":\"2016 23rd International Conference on Pattern Recognition (ICPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2079441\",\"name\":\"Sander Koelstra\"},{\"authorId\":\"1753164\",\"name\":\"C. M\\u00fchl\"},{\"authorId\":\"152714397\",\"name\":\"M. Soleymani\"},{\"authorId\":\"48173549\",\"name\":\"J. Lee\"},{\"authorId\":\"40131608\",\"name\":\"A. Yazdani\"},{\"authorId\":\"1681498\",\"name\":\"T. Ebrahimi\"},{\"authorId\":\"134804484\",\"name\":\"T. Pun\"},{\"authorId\":\"144483472\",\"name\":\"A. Nijholt\"},{\"authorId\":\"50058816\",\"name\":\"I. Patras\"}],\"doi\":\"10.1109/T-AFFC.2011.15\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"5a2892f91addeea2f4600d28b23e684be32f5b2c\",\"title\":\"DEAP: A Database for Emotion Analysis ;Using Physiological Signals\",\"url\":\"https://www.semanticscholar.org/paper/5a2892f91addeea2f4600d28b23e684be32f5b2c\",\"venue\":\"IEEE Transactions on Affective Computing\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3323241\",\"name\":\"A. Jan\"},{\"authorId\":\"8594981\",\"name\":\"Yona Falinie Binti A. Gaus\"},{\"authorId\":\"37192632\",\"name\":\"H. Meng\"},{\"authorId\":\"47191084\",\"name\":\"F. Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"bc8404c6896e5392f42607a39135e90c5a9e5abd\",\"title\":\"BUL in MediaEval 2016 Emotional Impact of Movies Task\",\"url\":\"https://www.semanticscholar.org/paper/bc8404c6896e5392f42607a39135e90c5a9e5abd\",\"venue\":\"MediaEval\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J. Ngiam\"},{\"authorId\":null,\"name\":\"M. Kim\"},{\"authorId\":null,\"name\":\"J. Nam\"},{\"authorId\":null,\"name\":\"H. Lee\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Multimodal deep learning Deep multimodal learning for affective analysis and retrieval\",\"url\":\"\",\"venue\":\"In MediaEval Proceedings of the 31 st International Conference on Machine Learning\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144339350\",\"name\":\"G. Andrew\"},{\"authorId\":\"144365054\",\"name\":\"R. Arora\"},{\"authorId\":\"1748118\",\"name\":\"J. Bilmes\"},{\"authorId\":\"2924113\",\"name\":\"Karen Livescu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e2257e3f56ccb12875a57bc0a8cca1d9d7e93ec6\",\"title\":\"Deep Canonical Correlation Analysis\",\"url\":\"https://www.semanticscholar.org/paper/e2257e3f56ccb12875a57bc0a8cca1d9d7e93ec6\",\"venue\":\"ICML\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766204\",\"name\":\"M. Sj\\u00f6berg\"},{\"authorId\":\"3264811\",\"name\":\"Yoann Baveye\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"143725193\",\"name\":\"Vu Lam Quang\"},{\"authorId\":\"1796198\",\"name\":\"B. Ionescu\"},{\"authorId\":\"1718878\",\"name\":\"E. Dellandr\\u00e9a\"},{\"authorId\":\"144125621\",\"name\":\"M. Schedl\"},{\"authorId\":\"1996351\",\"name\":\"Claire-H\\u00e9l\\u00e8ne Demarty\"},{\"authorId\":\"144177718\",\"name\":\"Liming Chen\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"ff691f9f7d2de7efc1c6c364c28cfef227d68488\",\"title\":\"The MediaEval 2015 Affective Impact of Movies Task\",\"url\":\"https://www.semanticscholar.org/paper/ff691f9f7d2de7efc1c6c364c28cfef227d68488\",\"venue\":\"MediaEval\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5886094\",\"name\":\"P. Cochat\"},{\"authorId\":\"13267685\",\"name\":\"L. Vaucoret\"},{\"authorId\":\"31455512\",\"name\":\"J. Sarles\"}],\"doi\":\"10.1016/j.arcped.2012.01.013\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"10d85561e4aafc516d10064f30dff05b41f70afe\",\"title\":\"[Et al].\",\"url\":\"https://www.semanticscholar.org/paper/10d85561e4aafc516d10064f30dff05b41f70afe\",\"venue\":\"Archives de pediatrie : organe officiel de la Societe francaise de pediatrie\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1702290\",\"name\":\"Weiran Wang\"},{\"authorId\":\"144365054\",\"name\":\"R. Arora\"},{\"authorId\":\"2924113\",\"name\":\"Karen Livescu\"},{\"authorId\":\"1748118\",\"name\":\"J. Bilmes\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"fc57291062df473c678bc89eba56056259bd2546\",\"title\":\"On Deep Multi-View Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/fc57291062df473c678bc89eba56056259bd2546\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"883b8a189fe1bb97b9ad2a382e057ba7e2a2e56f\",\"title\":\"The Convergence of Contrastive Divergences\",\"url\":\"https://www.semanticscholar.org/paper/883b8a189fe1bb97b9ad2a382e057ba7e2a2e56f\",\"venue\":\"NIPS\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1718878\",\"name\":\"E. Dellandr\\u00e9a\"},{\"authorId\":\"34086868\",\"name\":\"L. Chen\"},{\"authorId\":\"3264811\",\"name\":\"Yoann Baveye\"},{\"authorId\":\"1766204\",\"name\":\"M. Sj\\u00f6berg\"},{\"authorId\":\"2765755\",\"name\":\"Christel Chamaret\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"cc2890c73f6dd2ae76f5b9243bfe8b5fb0b47bf6\",\"title\":\"The MediaEval 2016 Emotional Impact of Movies Task\",\"url\":\"https://www.semanticscholar.org/paper/cc2890c73f6dd2ae76f5b9243bfe8b5fb0b47bf6\",\"venue\":\"MediaEval\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1709829\",\"name\":\"H. L. Wang\"},{\"authorId\":\"6835136\",\"name\":\"L. Cheong\"}],\"doi\":\"10.1109/TCSVT.2006.873781\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"0df2a8b1eb6bf3efb3003ca908cf0e4b75fbcebc\",\"title\":\"Affective understanding in film\",\"url\":\"https://www.semanticscholar.org/paper/0df2a8b1eb6bf3efb3003ca908cf0e4b75fbcebc\",\"venue\":\"IEEE Trans. Circuits Syst. Video Technol.\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34778274\",\"name\":\"Esra Acar\"},{\"authorId\":\"1759761\",\"name\":\"F. Hopfgartner\"},{\"authorId\":\"1722170\",\"name\":\"S. Albayrak\"}],\"doi\":\"10.1007/978-3-319-04114-8_26\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2bcb1c752663fc9650d71c341aa1708c6642cc85\",\"title\":\"Understanding Affective Content of Music Videos through Learned Representations\",\"url\":\"https://www.semanticscholar.org/paper/2bcb1c752663fc9650d71c341aa1708c6642cc85\",\"venue\":\"MMM\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"D. Tao\"},{\"authorId\":null,\"name\":\"C. Xu\"},{\"authorId\":null,\"name\":\"E. Skodras\"},{\"authorId\":null,\"name\":\"N. Fakotakis\"},{\"authorId\":null,\"name\":\"T. Ebrahimi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"timedia content analysis for emotional characterization of music video clips\",\"url\":\"\",\"venue\":\"Proceedings of the 32 nd International Conference on Machine Learning ( ICML - 15 )\",\"year\":null},{\"arxivId\":\"1402.0030\",\"authors\":[{\"authorId\":\"1714004\",\"name\":\"A. Mnih\"},{\"authorId\":\"144717963\",\"name\":\"K. Gregor\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"018300f5f0e679cee5241d9c69c8d88e00e8bf31\",\"title\":\"Neural Variational Inference and Learning in Belief Networks\",\"url\":\"https://www.semanticscholar.org/paper/018300f5f0e679cee5241d9c69c8d88e00e8bf31\",\"venue\":\"ICML\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1791335\",\"name\":\"Rupayan Chakraborty\"},{\"authorId\":\"2448592\",\"name\":\"A. Maurya\"},{\"authorId\":\"2034953\",\"name\":\"Meghna Pandharipande\"},{\"authorId\":\"6620636\",\"name\":\"E. Hassan\"},{\"authorId\":\"2448141\",\"name\":\"H. Ghosh\"},{\"authorId\":\"1809276\",\"name\":\"Sunil Kumar Kopparapu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"27443a352a92e14ff95bac528b69bee23fa6a82b\",\"title\":\"TCS-ILAB - MediaEval 2015: Affective Impact of Movies and Violent Scene Detection\",\"url\":\"https://www.semanticscholar.org/paper/27443a352a92e14ff95bac528b69bee23fa6a82b\",\"venue\":\"MediaEval\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40131608\",\"name\":\"A. Yazdani\"},{\"authorId\":\"2762745\",\"name\":\"E. Skodras\"},{\"authorId\":\"1726527\",\"name\":\"N. Fakotakis\"},{\"authorId\":\"1681498\",\"name\":\"T. Ebrahimi\"}],\"doi\":\"10.1186/1687-5281-2013-26\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d31e84c44c650a9e6249a81d68d77e221c1decee\",\"title\":\"Multimedia content analysis for emotional characterization of music video clips\",\"url\":\"https://www.semanticscholar.org/paper/d31e84c44c650a9e6249a81d68d77e221c1decee\",\"venue\":\"EURASIP J. Image Video Process.\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2271653\",\"name\":\"Luca Canini\"},{\"authorId\":\"38378783\",\"name\":\"Sergio Benini\"},{\"authorId\":\"47830218\",\"name\":\"R. Leonardi\"}],\"doi\":\"10.1109/TCSVT.2012.2211935\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"11e8b12cd79334c151dec0a510e466fbaefd3119\",\"title\":\"Affective Recommendation of Movies Based on Selected Connotative Features\",\"url\":\"https://www.semanticscholar.org/paper/11e8b12cd79334c151dec0a510e466fbaefd3119\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"M. Sj\\u00f6berg\"},{\"authorId\":null,\"name\":\"Y. Baveye\"},{\"authorId\":null,\"name\":\"H. Wang\"},{\"authorId\":null,\"name\":\"V. L. Quang\"},{\"authorId\":null,\"name\":\"B. Ionescu\"},{\"authorId\":null,\"name\":\"E. Dellandr\\u00e9a\"},{\"authorId\":null,\"name\":\"M. Schedl\"},{\"authorId\":null,\"name\":\"C.-H. Demarty\"},{\"authorId\":null,\"name\":\"L. Chen\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"The 5121  mediaeval 2015 affective impact of movies task\",\"url\":\"\",\"venue\":\"MediaEval 2015 Workshop\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48521241\",\"name\":\"Ye Ma\"},{\"authorId\":\"7818093\",\"name\":\"Zipeng Ye\"},{\"authorId\":\"9450377\",\"name\":\"Mingxing Xu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4371d98ec3d8c0529d3c0c23fb96fedd4237c01d\",\"title\":\"THU-HCSI at MediaEval 2016: Emotional Impact of Movies Task\",\"url\":\"https://www.semanticscholar.org/paper/4371d98ec3d8c0529d3c0c23fb96fedd4237c01d\",\"venue\":\"MediaEval\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1759152\",\"name\":\"Ionut Mironica\"},{\"authorId\":\"1796198\",\"name\":\"B. Ionescu\"},{\"authorId\":\"1766204\",\"name\":\"M. Sj\\u00f6berg\"},{\"authorId\":\"144125621\",\"name\":\"M. Schedl\"},{\"authorId\":\"1735402\",\"name\":\"Marcin Skowron\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7a46a00e40fa9d013194622440f2caba53311021\",\"title\":\"RFA at MediaEval 2015 Affective Impact of Movies Task: A Multimodal Approach\",\"url\":\"https://www.semanticscholar.org/paper/7a46a00e40fa9d013194622440f2caba53311021\",\"venue\":\"MediaEval\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1776581\",\"name\":\"S. Zhang\"},{\"authorId\":\"1689702\",\"name\":\"Q. Huang\"},{\"authorId\":\"1696610\",\"name\":\"S. Jiang\"},{\"authorId\":\"48385803\",\"name\":\"W. Gao\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/TMM.2010.2059634\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fd70bfe69bfacb9392395133d6bf68b324ddcdac\",\"title\":\"Affective Visualization and Retrieval for Music Video\",\"url\":\"https://www.semanticscholar.org/paper/fd70bfe69bfacb9392395133d6bf68b324ddcdac\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144954807\",\"name\":\"Q. Dai\"},{\"authorId\":\"3066866\",\"name\":\"Rui-Wei Zhao\"},{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"47119743\",\"name\":\"X. Wang\"},{\"authorId\":\"2650085\",\"name\":\"Zichen Gu\"},{\"authorId\":\"144791707\",\"name\":\"Wenhai Wu\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7f70649aee3fcd5532f25db325b6bf6f925870ce\",\"title\":\"Fudan-Huawei at MediaEval 2015: Detecting Violent Scenes and Affective Impact in Movies with Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/7f70649aee3fcd5532f25db325b6bf6f925870ce\",\"venue\":\"MediaEval\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152714397\",\"name\":\"M. Soleymani\"},{\"authorId\":\"2796371\",\"name\":\"J. Lichtenauer\"},{\"authorId\":\"1809085\",\"name\":\"T. Pun\"},{\"authorId\":\"145387780\",\"name\":\"M. Pantic\"}],\"doi\":\"10.1109/T-AFFC.2011.25\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3a60678ad2b862fa7c27b11f04c93c010cc6c430\",\"title\":\"A Multimodal Database for Affect Recognition and Implicit Tagging\",\"url\":\"https://www.semanticscholar.org/paper/3a60678ad2b862fa7c27b11f04c93c010cc6c430\",\"venue\":\"IEEE Transactions on Affective Computing\",\"year\":2012},{\"arxivId\":\"1310.8499\",\"authors\":[{\"authorId\":\"144717963\",\"name\":\"K. Gregor\"},{\"authorId\":\"1841008\",\"name\":\"Ivo Danihelka\"},{\"authorId\":\"1714004\",\"name\":\"A. Mnih\"},{\"authorId\":\"1723876\",\"name\":\"Charles Blundell\"},{\"authorId\":\"1688276\",\"name\":\"Daan Wierstra\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"695a2c95eacdbccb7a73d2f1e90e7b35b4b3d864\",\"title\":\"Deep AutoRegressive Networks\",\"url\":\"https://www.semanticscholar.org/paper/695a2c95eacdbccb7a73d2f1e90e7b35b4b3d864\",\"venue\":\"ICML\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145885988\",\"name\":\"Vu Lam\"},{\"authorId\":\"144801511\",\"name\":\"S. Le\"},{\"authorId\":\"1802416\",\"name\":\"D. Le\"},{\"authorId\":\"1700567\",\"name\":\"Shin'ichi Satoh\"},{\"authorId\":\"2258974\",\"name\":\"D. Duong\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"f66c2e42d24cec8b5fa30b68c1d396898947961d\",\"title\":\"NII-UIT at MediaEval 2015 Affective Impact of Movies Task\",\"url\":\"https://www.semanticscholar.org/paper/f66c2e42d24cec8b5fa30b68c1d396898947961d\",\"venue\":\"MediaEval\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40013547\",\"name\":\"Yang Liu\"},{\"authorId\":\"29739214\",\"name\":\"Zhonglei Gu\"},{\"authorId\":\"1682848\",\"name\":\"Y. Zhang\"},{\"authorId\":\"38384862\",\"name\":\"Yan Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7abbbf2ec4f590c0177b2f18573eb4abe2628aa1\",\"title\":\"Mining Emotional Features of Movies\",\"url\":\"https://www.semanticscholar.org/paper/7abbbf2ec4f590c0177b2f18573eb4abe2628aa1\",\"venue\":\"MediaEval\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2020608\",\"name\":\"J. Ngiam\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"4738460\",\"name\":\"Mingyu Kim\"},{\"authorId\":\"145578392\",\"name\":\"Juhan Nam\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"},{\"authorId\":\"34699434\",\"name\":\"A. Ng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"80e9e3fc3670482c1fee16b2542061b779f47c4f\",\"title\":\"Multimodal Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/80e9e3fc3670482c1fee16b2542061b779f47c4f\",\"venue\":\"ICML\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":\"10.1126/SCIENCE.1127647\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"46eb79e5eec8a4e2b2f5652b66441e8a4c921c3e\",\"title\":\"Reducing the Dimensionality of Data with Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/46eb79e5eec8a4e2b2f5652b66441e8a4c921c3e\",\"venue\":\"Science\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2814229\",\"name\":\"George Trigeorgis\"},{\"authorId\":\"6766944\",\"name\":\"E. Coutinho\"},{\"authorId\":\"2124680\",\"name\":\"Fabien Ringeval\"},{\"authorId\":\"1779097\",\"name\":\"E. Marchi\"},{\"authorId\":\"1776444\",\"name\":\"S. Zafeiriou\"},{\"authorId\":\"145411696\",\"name\":\"B. Schuller\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"aa7d725e7ff1528b20a457818630f968b8f4d190\",\"title\":\"The ICL-TUM-PASSAU Approach for the MediaEval 2015 \\\"Affective Impact of Movies\\\" Task\",\"url\":\"https://www.semanticscholar.org/paper/aa7d725e7ff1528b20a457818630f968b8f4d190\",\"venue\":\"MediaEval\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3264811\",\"name\":\"Yoann Baveye\"},{\"authorId\":\"1718878\",\"name\":\"E. Dellandr\\u00e9a\"},{\"authorId\":\"2765755\",\"name\":\"Christel Chamaret\"},{\"authorId\":\"47818198\",\"name\":\"L. Chen\"}],\"doi\":\"10.1109/TAFFC.2015.2396531\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1a3b7b3f5096b369f8af7e657c4251c7e70cc194\",\"title\":\"LIRIS-ACCEDE: A Video Database for Affective Content Analysis\",\"url\":\"https://www.semanticscholar.org/paper/1a3b7b3f5096b369f8af7e657c4251c7e70cc194\",\"venue\":\"IEEE Transactions on Affective Computing\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48620041\",\"name\":\"Yun Yi\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"3047890\",\"name\":\"Bowen Zhang\"},{\"authorId\":\"1740321\",\"name\":\"Jian Yu\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"423e4c4fd8916c454b2755b89f32893536f09840\",\"title\":\"MIC-TJU in MediaEval 2015 Affective Impact of Movies Task\",\"url\":\"https://www.semanticscholar.org/paper/423e4c4fd8916c454b2755b89f32893536f09840\",\"venue\":\"MediaEval\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1718099\",\"name\":\"A. Hanjalic\"},{\"authorId\":\"143950256\",\"name\":\"Li-Qun Xu\"}],\"doi\":\"10.1109/TMM.2004.840618\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c015d547c56db99388faa29a0628b86f318e1d3\",\"title\":\"Affective video content representation and modeling\",\"url\":\"https://www.semanticscholar.org/paper/6c015d547c56db99388faa29a0628b86f318e1d3\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"1721329\",\"name\":\"Q. Jin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1a459bf9586a9649a3c580f88fb004040302f005\",\"title\":\"RUC at MediaEval 2016 Emotional Impact of Movies Task: Fusion of Multimodal Features\",\"url\":\"https://www.semanticscholar.org/paper/1a459bf9586a9649a3c580f88fb004040302f005\",\"venue\":\"MediaEval\",\"year\":2016}],\"title\":\"A Multimodal Deep Regression Bayesian Network for Affective Video Content Analyses\",\"topics\":[{\"topic\":\"Bayesian network\",\"topicId\":\"14005\",\"url\":\"https://www.semanticscholar.org/topic/14005\"},{\"topic\":\"Digital video\",\"topicId\":\"44670\",\"url\":\"https://www.semanticscholar.org/topic/44670\"},{\"topic\":\"Multimodal interaction\",\"topicId\":\"42592\",\"url\":\"https://www.semanticscholar.org/topic/42592\"},{\"topic\":\"Algorithm\",\"topicId\":\"305\",\"url\":\"https://www.semanticscholar.org/topic/305\"},{\"topic\":\"Graphical model\",\"topicId\":\"16839\",\"url\":\"https://www.semanticscholar.org/topic/16839\"},{\"topic\":\"Modality (human\\u2013computer interaction)\",\"topicId\":\"462\",\"url\":\"https://www.semanticscholar.org/topic/462\"},{\"topic\":\"Boolean network\",\"topicId\":\"590\",\"url\":\"https://www.semanticscholar.org/topic/590\"},{\"topic\":\"Feedforward neural network\",\"topicId\":\"153499\",\"url\":\"https://www.semanticscholar.org/topic/153499\"},{\"topic\":\"Latent variable\",\"topicId\":\"79039\",\"url\":\"https://www.semanticscholar.org/topic/79039\"},{\"topic\":\"Backpropagation\",\"topicId\":\"11998\",\"url\":\"https://www.semanticscholar.org/topic/11998\"},{\"topic\":\"Interaction information\",\"topicId\":\"418749\",\"url\":\"https://www.semanticscholar.org/topic/418749\"},{\"topic\":\"Kullback\\u2013Leibler divergence\",\"topicId\":\"21299\",\"url\":\"https://www.semanticscholar.org/topic/21299\"},{\"topic\":\"Marginal model\",\"topicId\":\"770245\",\"url\":\"https://www.semanticscholar.org/topic/770245\"},{\"topic\":\"Software propagation\",\"topicId\":\"2021211\",\"url\":\"https://www.semanticscholar.org/topic/2021211\"}],\"url\":\"https://www.semanticscholar.org/paper/32afaf0c0ce2977d38b567972ce80d35151bc119\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017}\n"