"{\"abstract\":\"Visual question answering (VQA) is challenging because it requires a simultaneous understanding of both the visual content of images and the textual content of questions. The approaches used to represent the images and questions in a fine-grained manner and questions and to fuse these multimodal features play key roles in performance. Bilinear pooling based models have been shown to outperform traditional linear models for VQA, but their high-dimensional representations and high computational complexity may seriously limit their applicability in practice. For multimodal feature fusion, here we develop a Multi-modal Factorized Bilinear (MFB) pooling approach to efficiently and effectively combine multi-modal features, which results in superior performance for VQA compared with other bilinear pooling approaches. For fine-grained image and question representation, we develop a \\u2018co-attention\\u2019 mechanism using an end-to-end deep network architecture to jointly learn both the image and question attentions. Combining the proposed MFB approach with co-attention learning in a new network architecture provides a unified model for VQA. Our experimental results demonstrate that the single MFB with co-attention model achieves new state-of-theart performance on the real-world VQA dataset. Code available at https://github.com/yuzcccc/mfb.\",\"arxivId\":\"1708.01471\",\"authors\":[{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\",\"url\":\"https://www.semanticscholar.org/author/144007938\"},{\"authorId\":\"50812077\",\"name\":\"J. Yu\",\"url\":\"https://www.semanticscholar.org/author/50812077\"},{\"authorId\":\"144147221\",\"name\":\"Jianping Fan\",\"url\":\"https://www.semanticscholar.org/author/144147221\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\",\"url\":\"https://www.semanticscholar.org/author/143719920\"}],\"citationVelocity\":77,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993592720\",\"name\":\"Zhaobo Qi\"},{\"authorId\":\"47672591\",\"name\":\"Shuhui Wang\"},{\"authorId\":\"145422145\",\"name\":\"Chi Su\"},{\"authorId\":\"153142919\",\"name\":\"Li Su\"},{\"authorId\":\"153159021\",\"name\":\"Qingming Huang\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1145/3394171.3413954\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"1d71c6ecb0d7ca618665e6402e84c2f5d39b761f\",\"title\":\"Towards More Explainability: Concept Knowledge Mining Network for Event Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1d71c6ecb0d7ca618665e6402e84c2f5d39b761f\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"82972947\",\"name\":\"Felipe Riquelme\"},{\"authorId\":\"1978662985\",\"name\":\"Alfredo De Goyeneche\"},{\"authorId\":\"49890233\",\"name\":\"Yundong Zhang\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"144949755\",\"name\":\"\\u00c1. Soto\"}],\"doi\":\"10.1016/j.imavis.2020.103968\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d2c956be94129de11a4deba6f1d34c5ae18b3fde\",\"title\":\"Explaining VQA predictions using visual grounding and a knowledge base\",\"url\":\"https://www.semanticscholar.org/paper/d2c956be94129de11a4deba6f1d34c5ae18b3fde\",\"venue\":\"Image Vis. Comput.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1600703039\",\"name\":\"Janani Ramaswamy\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053895\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"380e7cc65c7be734f2179953bd921630afdee6ec\",\"title\":\"What Makes the Sound?: A Dual-Modality Interacting Network for Audio-Visual Event Localization\",\"url\":\"https://www.semanticscholar.org/paper/380e7cc65c7be734f2179953bd921630afdee6ec\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145374305\",\"name\":\"Xin Yan\"},{\"authorId\":\"32529463\",\"name\":\"L. Li\"},{\"authorId\":\"150961077\",\"name\":\"Chulin Xie\"},{\"authorId\":\"1384523745\",\"name\":\"Jun Xiao\"},{\"authorId\":\"51515749\",\"name\":\"Lin Gu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"c7dbeea4258174e0eece7239e24f7bd909f2d606\",\"title\":\"Zhejiang University at ImageCLEF 2019 Visual Question Answering in the Medical Domain\",\"url\":\"https://www.semanticscholar.org/paper/c7dbeea4258174e0eece7239e24f7bd909f2d606\",\"venue\":\"CLEF\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49597404\",\"name\":\"Z. Fang\"},{\"authorId\":\"7187373\",\"name\":\"J. Liu\"},{\"authorId\":null,\"name\":\"Qu Tang\"},{\"authorId\":\"49112842\",\"name\":\"Y. Li\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1007/978-3-030-20887-5_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8463ff93a6725017bd1875eeb7ae4d0f0e7df568\",\"title\":\"Answer Distillation for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8463ff93a6725017bd1875eeb7ae4d0f0e7df568\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49961530\",\"name\":\"Justin Wilson\"},{\"authorId\":\"40069761\",\"name\":\"Auston Sterling\"},{\"authorId\":\"144247566\",\"name\":\"M. Lin\"}],\"doi\":\"10.1109/IROS40897.2019.8968118\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fbc8cafd65ed371e99feee56305c4ba17321b206\",\"title\":\"Analyzing Liquid Pouring Sequences via Audio-Visual Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/fbc8cafd65ed371e99feee56305c4ba17321b206\",\"venue\":\"2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7361508\",\"name\":\"Zhiqiang Wan\"},{\"authorId\":\"144996615\",\"name\":\"Haibo He\"}],\"doi\":\"10.1109/TBDATA.2018.2884486\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8524d0447d84c6b2dc41e4bca81e0daf6b1b67ac\",\"title\":\"AnswerNet: Learning to Answer Questions\",\"url\":\"https://www.semanticscholar.org/paper/8524d0447d84c6b2dc41e4bca81e0daf6b1b67ac\",\"venue\":\"IEEE Transactions on Big Data\",\"year\":2019},{\"arxivId\":\"1806.04860\",\"authors\":[{\"authorId\":\"47008023\",\"name\":\"Z. Su\"},{\"authorId\":\"144469723\",\"name\":\"C. Zhu\"},{\"authorId\":\"3431029\",\"name\":\"Y. Dong\"},{\"authorId\":\"1751449\",\"name\":\"Dongqi Cai\"},{\"authorId\":\"6060281\",\"name\":\"Y. Chen\"},{\"authorId\":\"46277052\",\"name\":\"J. Li\"}],\"doi\":\"10.1109/CVPR.2018.00807\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"33f08157b959070ba802afbb135f4336c5a426fd\",\"title\":\"Learning Visual Knowledge Memory Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/33f08157b959070ba802afbb135f4336c5a426fd\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2012.00822\",\"authors\":[{\"authorId\":\"1387720883\",\"name\":\"Haozheng Luo\"},{\"authorId\":\"1443782482\",\"name\":\"Ruiyang Qin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b1fe97e5fd1b7151d5ab6565bfe3ca6efe034575\",\"title\":\"Open-Ended Multi-Modal Relational Reason for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b1fe97e5fd1b7151d5ab6565bfe3ca6efe034575\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40912088\",\"name\":\"M. Tanaka\"},{\"authorId\":\"51491153\",\"name\":\"Takayuki Itamochi\"},{\"authorId\":\"3193466\",\"name\":\"K. Narioka\"},{\"authorId\":\"152599661\",\"name\":\"Ikuro Sato\"},{\"authorId\":\"3250559\",\"name\":\"Y. Ushiku\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.1109/ICCV.2019.00589\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"949959250e487617faa3035b05b52aa03a8e9895\",\"title\":\"Generating Easy-to-Understand Referring Expressions for Target Identifications\",\"url\":\"https://www.semanticscholar.org/paper/949959250e487617faa3035b05b52aa03a8e9895\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3287750\",\"name\":\"Tan Yu\"},{\"authorId\":\"48694117\",\"name\":\"Y. Cai\"},{\"authorId\":\"1768151568\",\"name\":\"Ping Li\"}],\"doi\":\"10.1007/978-3-030-58529-7_13\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6c6dfecf9cd59336b4ef3b3d6fe5f68b7b574acf\",\"title\":\"Toward Faster and Simpler Matrix Normalization via Rank-1 Update\",\"url\":\"https://www.semanticscholar.org/paper/6c6dfecf9cd59336b4ef3b3d6fe5f68b7b574acf\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2639734\",\"name\":\"Qingbao Huang\"},{\"authorId\":\"1754240987\",\"name\":\"Jielong Wei\"},{\"authorId\":\"1752876325\",\"name\":\"Yi Cai\"},{\"authorId\":\"150068355\",\"name\":\"Changmeng Zheng\"},{\"authorId\":\"47740571\",\"name\":\"J. Chen\"},{\"authorId\":\"1701688\",\"name\":\"Ho-fung Leung\"},{\"authorId\":\"145138436\",\"name\":\"Qing Li\"}],\"doi\":\"10.18653/v1/2020.acl-main.642\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"ede49ec0dd27849e57152d5116770bcbe3e01874\",\"title\":\"Aligned Dual Channel Graph Convolutional Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ede49ec0dd27849e57152d5116770bcbe3e01874\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51173122\",\"name\":\"Yalei Peng\"},{\"authorId\":\"2929047\",\"name\":\"F. Liu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0776b31a90d714f3bfd42ad8927546b4c67c8228\",\"title\":\"UMass at ImageCLEF Medical Visual Question Answering(Med-VQA) 2018 Task\",\"url\":\"https://www.semanticscholar.org/paper/0776b31a90d714f3bfd42ad8927546b4c67c8228\",\"venue\":\"CLEF\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50974488\",\"name\":\"Mingrui Lao\"},{\"authorId\":\"49813983\",\"name\":\"Yanming Guo\"},{\"authorId\":\"49528152\",\"name\":\"H. Wang\"},{\"authorId\":\"49468999\",\"name\":\"Xin Zhang\"}],\"doi\":\"10.1109/ACCESS.2018.2873570\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"161876ad06d5a349ccde4b4db3d3759ef43268a8\",\"title\":\"Multimodal Local Perception Bilinear Pooling for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/161876ad06d5a349ccde4b4db3d3759ef43268a8\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1895813\",\"name\":\"Yibing Zhan\"},{\"authorId\":\"143923524\",\"name\":\"J. Yu\"},{\"authorId\":\"144478228\",\"name\":\"T. Yu\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\"}],\"doi\":\"10.1007/s11263-020-01353-8\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c40d14f9af8888dbc3713d790c161c7ef007fa52\",\"title\":\"Multi-task Compositional Network for Visual Relationship Detection\",\"url\":\"https://www.semanticscholar.org/paper/c40d14f9af8888dbc3713d790c161c7ef007fa52\",\"venue\":\"International Journal of Computer Vision\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38941306\",\"name\":\"Nagashri N. Lakshminarayana\"},{\"authorId\":\"1557796060\",\"name\":\"Deen Dayal Mohan\"},{\"authorId\":\"33396604\",\"name\":\"N. Sankaran\"},{\"authorId\":\"1800513\",\"name\":\"S. Setlur\"},{\"authorId\":\"1723877\",\"name\":\"V. Govindaraju\"}],\"doi\":\"10.1007/978-3-030-30671-7_7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aca82836e9648a8da81428fee45c1e3a4da5cfc1\",\"title\":\"Multi-modal Conditional Feature Enhancement for Facial Action Unit Recognition\",\"url\":\"https://www.semanticscholar.org/paper/aca82836e9648a8da81428fee45c1e3a4da5cfc1\",\"venue\":\"Domain Adaptation for Visual Understanding\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47781687\",\"name\":\"Z. Liu\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"},{\"authorId\":\"49050918\",\"name\":\"J. Zhang\"}],\"doi\":\"10.1007/s11063-018-09972-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"33c615be88df63dfd0e8f1b770066f062ee8d157\",\"title\":\"Spatiotemporal Fusion Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/33c615be88df63dfd0e8f1b770066f062ee8d157\",\"venue\":\"Neural Processing Letters\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152968916\",\"name\":\"Tianhao Yang\"},{\"authorId\":\"51260253\",\"name\":\"Z. Zha\"},{\"authorId\":\"143994657\",\"name\":\"Hongtao Xie\"},{\"authorId\":\"152808542\",\"name\":\"Meng Wang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"}],\"doi\":\"10.1145/3343031.3350969\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2af3819e12239162525259295111d2114d7e3072\",\"title\":\"Question-Aware Tube-Switch Network for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2af3819e12239162525259295111d2114d7e3072\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2991581\",\"name\":\"Guoqing Chao\"}],\"doi\":\"10.1007/s11063-018-9823-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5615b863fb6757fa2a5f01a7c5499c751ea0cdb5\",\"title\":\"Discriminative K-Means Laplacian Clustering\",\"url\":\"https://www.semanticscholar.org/paper/5615b863fb6757fa2a5f01a7c5499c751ea0cdb5\",\"venue\":\"Neural Processing Letters\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2309856\",\"name\":\"Zhenhui Tang\"},{\"authorId\":\"2258508\",\"name\":\"Engang Tian\"},{\"authorId\":null,\"name\":\"Yongxiong Wang\"},{\"authorId\":\"46659726\",\"name\":\"L. Wang\"},{\"authorId\":\"1400294730\",\"name\":\"T. Yang\"}],\"doi\":\"10.1109/TII.2020.2985159\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4b405cfb8b11fe40452f6b038315679f7b319983\",\"title\":\"Nondestructive Defect Detection in Castings by Using Spatial Attention Bilinear Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/4b405cfb8b11fe40452f6b038315679f7b319983\",\"venue\":\"IEEE Transactions on Industrial Informatics\",\"year\":2021},{\"arxivId\":\"1806.03724\",\"authors\":[{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"38784892\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"}],\"doi\":\"10.1109/CVPR.2018.00569\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"04427d8371cb9e66e2cdcd2035756203398a8bf1\",\"title\":\"Learning Answer Embeddings for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/04427d8371cb9e66e2cdcd2035756203398a8bf1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48300165\",\"name\":\"Jingjing Luo\"},{\"authorId\":\"2303260\",\"name\":\"Xianfang Sun\"},{\"authorId\":\"1722082\",\"name\":\"Man Lung Yiu\"},{\"authorId\":\"40534966\",\"name\":\"Longcun Jin\"},{\"authorId\":\"1937823\",\"name\":\"Xinyi Peng\"}],\"doi\":\"10.1016/j.ins.2018.06.030\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0363832774727dba24e5b4ec0af9f8b29acebe1b\",\"title\":\"Piecewise linear regression-based single image super-resolution via Hadamard transform\",\"url\":\"https://www.semanticscholar.org/paper/0363832774727dba24e5b4ec0af9f8b29acebe1b\",\"venue\":\"Inf. Sci.\",\"year\":2018},{\"arxivId\":\"1911.11390\",\"authors\":[{\"authorId\":\"28964453\",\"name\":\"Van-Quang Nguyen\"},{\"authorId\":\"9114621\",\"name\":\"Masanori Suganuma\"},{\"authorId\":\"1718872\",\"name\":\"Takayuki Okatani\"}],\"doi\":\"10.1007/978-3-030-58586-0_14\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"468d5c15df63892ff06fb94c7b5cad0242685d02\",\"title\":\"Efficient Attention Mechanism for Visual Dialog that Can Handle All the Interactions Between Multiple Inputs\",\"url\":\"https://www.semanticscholar.org/paper/468d5c15df63892ff06fb94c7b5cad0242685d02\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1908.05819\",\"authors\":[{\"authorId\":\"3450321\",\"name\":\"Binghui Chen\"},{\"authorId\":\"1774956\",\"name\":\"W. Deng\"},{\"authorId\":\"23224233\",\"name\":\"Jiani Hu\"}],\"doi\":\"10.1109/ICCV.2019.00046\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"061f205009b39438e39448164064233162884252\",\"title\":\"Mixed High-Order Attention Network for Person Re-Identification\",\"url\":\"https://www.semanticscholar.org/paper/061f205009b39438e39448164064233162884252\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1735739\",\"name\":\"Weifeng Zhang\"},{\"authorId\":\"47864783\",\"name\":\"H. Hu\"},{\"authorId\":\"144645443\",\"name\":\"H. Hu\"},{\"authorId\":\"49402458\",\"name\":\"J. Yu\"}],\"doi\":\"10.1007/s11042-019-07929-y\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b11e52778c26529ec1407f466870857763d83218\",\"title\":\"Automatic image annotation via category labels\",\"url\":\"https://www.semanticscholar.org/paper/b11e52778c26529ec1407f466870857763d83218\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"1712.09439\",\"authors\":[{\"authorId\":\"2991581\",\"name\":\"Guoqing Chao\"}],\"doi\":\"10.1007/s11063-018-9847-z\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"322382a9524b723212dc12d6ce1a0a506c60b545\",\"title\":\"RETRACTED ARTICLE: Multi-view Sparse Vector Decomposition to Deal with Missing Values in Alcohol Dependence Study\",\"url\":\"https://www.semanticscholar.org/paper/322382a9524b723212dc12d6ce1a0a506c60b545\",\"venue\":\"Neural Processing Letters\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145764583\",\"name\":\"F. Liu\"},{\"authorId\":\"40628473\",\"name\":\"Jing Liu\"},{\"authorId\":\"49597404\",\"name\":\"Z. Fang\"},{\"authorId\":\"48043335\",\"name\":\"R. Hong\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.24963/ijcai.2019/122\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"99dc8f4c6be75b32a584608cea2c0da0de47db8d\",\"title\":\"Densely Connected Attention Flow for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/99dc8f4c6be75b32a584608cea2c0da0de47db8d\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"1809.05848\",\"authors\":[{\"authorId\":\"46700331\",\"name\":\"J. Liu\"},{\"authorId\":\"51305314\",\"name\":\"Zehuan Yuan\"},{\"authorId\":\"1697065\",\"name\":\"C. Wang\"}],\"doi\":\"10.1007/978-3-030-11018-5_26\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1dc373458adf54678b6b981ce458ccdbe3f9d112\",\"title\":\"Towards Good Practices for Multi-modal Fusion in Large-scale Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/1dc373458adf54678b6b981ce458ccdbe3f9d112\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40362476\",\"name\":\"Liming Zhan\"},{\"authorId\":\"73548014\",\"name\":\"Bo Liu\"},{\"authorId\":\"145451510\",\"name\":\"L. Fan\"},{\"authorId\":\"145905368\",\"name\":\"Jiaxin Chen\"},{\"authorId\":\"1772198\",\"name\":\"X. Wu\"}],\"doi\":\"10.1145/3394171.3413761\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b8d5b853f2212cbb48a43f1edec9b96d76d388ec\",\"title\":\"Medical Visual Question Answering via Conditional Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/b8d5b853f2212cbb48a43f1edec9b96d76d388ec\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2548483\",\"name\":\"Shengfeng He\"},{\"authorId\":\"14898006\",\"name\":\"Chu Han\"},{\"authorId\":\"2513505\",\"name\":\"Guoqiang Han\"},{\"authorId\":\"145947071\",\"name\":\"Jing Qin\"}],\"doi\":\"10.1109/TNNLS.2019.2933439\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"3d3c31f077c002d476d7eb85e94d43830243e4bf\",\"title\":\"Exploring Duality in Visual Question-Driven Top-Down Saliency\",\"url\":\"https://www.semanticscholar.org/paper/3d3c31f077c002d476d7eb85e94d43830243e4bf\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3433406\",\"name\":\"Gongwen Xu\"},{\"authorId\":\"49287715\",\"name\":\"L. Xu\"},{\"authorId\":\"50495887\",\"name\":\"Meijia Zhang\"},{\"authorId\":\"48568764\",\"name\":\"Xiaomei Li\"}],\"doi\":\"10.23940/IJPE.18.04.P21.795804\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"013559249ba1400ea6d59e7cce6f7b22620977f2\",\"title\":\"Two-Stage Semantic Matching for Cross-Media Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/013559249ba1400ea6d59e7cce6f7b22620977f2\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40055538\",\"name\":\"C. Yang\"},{\"authorId\":\"144889898\",\"name\":\"Mengqi Jiang\"},{\"authorId\":\"144069314\",\"name\":\"Bin Jiang\"},{\"authorId\":\"46351963\",\"name\":\"Weixin Zhou\"},{\"authorId\":\"2181606\",\"name\":\"K. Li\"}],\"doi\":\"10.1109/ACCESS.2019.2908035\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f0734fd670605a578b9e4b908e58b63e4142625e\",\"title\":\"Co-Attention Network With Question Type for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f0734fd670605a578b9e4b908e58b63e4142625e\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1908.10585\",\"authors\":[{\"authorId\":\"35301620\",\"name\":\"Katrien Laenen\"},{\"authorId\":\"145446752\",\"name\":\"Marie-Francine Moens\"}],\"doi\":\"10.1007/978-3-030-55218-3_4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"89445545cbd7abd0e9588e8b80be9d0721c0e816\",\"title\":\"Attention-based Fusion for Outfit Recommendation\",\"url\":\"https://www.semanticscholar.org/paper/89445545cbd7abd0e9588e8b80be9d0721c0e816\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1906.06216\",\"authors\":[{\"authorId\":\"51270689\",\"name\":\"Hyounghun Kim\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/P19-1351\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"8501712706efa6f314438143de18507471781060\",\"title\":\"Improving Visual Question Answering by Referring to Generated Paragraph Captions\",\"url\":\"https://www.semanticscholar.org/paper/8501712706efa6f314438143de18507471781060\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"146992883\",\"name\":\"I. Participants\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d1e8a08aafc64661206c495e963e0b244dfe59cd\",\"title\":\"R 4-A . 1 : Dynamics-Based Video Analytics\",\"url\":\"https://www.semanticscholar.org/paper/d1e8a08aafc64661206c495e963e0b244dfe59cd\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1911.10354\",\"authors\":[{\"authorId\":\"51215319\",\"name\":\"Kohei Uehara\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.18653/v1/2020.nlpbt-1.6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fc4598d636b599c4752a376cc074541c5a0ec97a\",\"title\":\"Unsupervised Keyword Extraction for Full-sentence VQA\",\"url\":\"https://www.semanticscholar.org/paper/fc4598d636b599c4752a376cc074541c5a0ec97a\",\"venue\":\"NLPBT\",\"year\":2020},{\"arxivId\":\"2004.11883\",\"authors\":[{\"authorId\":\"41022273\",\"name\":\"Duy-Kien Nguyen\"},{\"authorId\":\"28554843\",\"name\":\"Vedanuj Goswami\"},{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c7faa44bde54f017e164ad8e687bd1963005988\",\"title\":\"Revisiting Modulated Convolutions for Visual Counting and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/6c7faa44bde54f017e164ad8e687bd1963005988\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49890233\",\"name\":\"Yundong Zhang\"},{\"authorId\":\"46477230\",\"name\":\"Hang Wu\"},{\"authorId\":\"30949464\",\"name\":\"Huiye Liu\"},{\"authorId\":\"147377128\",\"name\":\"L. Tong\"},{\"authorId\":\"1741624\",\"name\":\"M. Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"31b3fecfa8213b6ac5e34607207a99aa0168afad\",\"title\":\"Mitigating the Effect of Dataset Bias on Training Deep Models for Chest X-rays\",\"url\":\"https://www.semanticscholar.org/paper/31b3fecfa8213b6ac5e34607207a99aa0168afad\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30895384\",\"name\":\"Titir Dutta\"},{\"authorId\":\"145702363\",\"name\":\"S. Biswas\"}],\"doi\":\"10.1109/WACV45572.2020.9093289\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d5142a6da6298a778ceb8dc797d00b999648a743\",\"title\":\"s-SBIR: Style Augmented Sketch based Image Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/d5142a6da6298a778ceb8dc797d00b999648a743\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1906.10770\",\"authors\":[{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"},{\"authorId\":\"9919436\",\"name\":\"J. Yu\"},{\"authorId\":\"30513139\",\"name\":\"Yuhao Cui\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/CVPR.2019.00644\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a1744da011375d711ed75fc2d160c6fdca2cf89\",\"title\":\"Deep Modular Co-Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8a1744da011375d711ed75fc2d160c6fdca2cf89\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Guohao Li\"},{\"authorId\":\"72541452\",\"name\":\"X. Wang\"},{\"authorId\":\"145583986\",\"name\":\"Wenwu Zhu\"}],\"doi\":\"10.1145/3343031.3350922\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"35074d64a1d70172cab24a1343ae08ea3c078ce2\",\"title\":\"Perceptual Visual Reasoning with Knowledge Propagation\",\"url\":\"https://www.semanticscholar.org/paper/35074d64a1d70172cab24a1343ae08ea3c078ce2\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3443768\",\"name\":\"M. A. Rahman\"},{\"authorId\":null,\"name\":\"Robert Lagani\\u00e8re\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a70b46841bdf48f8a15508f1f48b51937d082efa\",\"title\":\"Mid-level Fusion for End-to-End Temporal Activity Detection in Untrimmed Video\",\"url\":\"https://www.semanticscholar.org/paper/a70b46841bdf48f8a15508f1f48b51937d082efa\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144963976\",\"name\":\"Weidong Tian\"},{\"authorId\":\"145380213\",\"name\":\"B. He\"},{\"authorId\":\"1977865899\",\"name\":\"Nan-Xun Wang\"},{\"authorId\":\"33698309\",\"name\":\"Zhong-Qiu Zhao\"}],\"doi\":\"10.1109/IJCNN48605.2020.9207058\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"99a01a687f7959de4c86102342d4bcfec6382aa8\",\"title\":\"Multi-Channel Co-Attention Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/99a01a687f7959de4c86102342d4bcfec6382aa8\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48632022\",\"name\":\"Xin Wang\"},{\"authorId\":\"98285543\",\"name\":\"X. Wang\"},{\"authorId\":\"145126329\",\"name\":\"C. Wang\"},{\"authorId\":\"98227873\",\"name\":\"Xiao Bai\"},{\"authorId\":\"49387492\",\"name\":\"Jing Wu\"},{\"authorId\":\"69407115\",\"name\":\"E. Hancock\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fee91f7d99ed489457352fc1ec4a5fbfaa565480\",\"title\":\"Discriminative Features Matter: Multi-layer Bilinear Pooling for Camera Localization\",\"url\":\"https://www.semanticscholar.org/paper/fee91f7d99ed489457352fc1ec4a5fbfaa565480\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"1909.00301\",\"authors\":[{\"authorId\":\"46700226\",\"name\":\"Jiacheng Liu\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"}],\"doi\":\"10.18653/v1/D19-1515\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9abeabd42883b55a1b01e812aa8856280abe0bad\",\"title\":\"Phrase Grounding by Soft-Label Chain Conditional Random Field\",\"url\":\"https://www.semanticscholar.org/paper/9abeabd42883b55a1b01e812aa8856280abe0bad\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yan Zhang\"},{\"authorId\":\"2276351\",\"name\":\"Krikamol Muandet\"},{\"authorId\":null,\"name\":\"Qianli Ma\"},{\"authorId\":\"144718494\",\"name\":\"H. Neumann\"},{\"authorId\":\"39578749\",\"name\":\"Siyu Tang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3588725a4fb22db3a1506eaed75eb97fba09ecc3\",\"title\":\"Low-rank Random Tensor for Bilinear Pooling\",\"url\":\"https://www.semanticscholar.org/paper/3588725a4fb22db3a1506eaed75eb97fba09ecc3\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50846763\",\"name\":\"W. Zhang\"},{\"authorId\":\"48632022\",\"name\":\"Xin Wang\"},{\"authorId\":\"1774936\",\"name\":\"Siliang Tang\"},{\"authorId\":\"1993631009\",\"name\":\"Haizhou Shi\"},{\"authorId\":\"1490931889\",\"name\":\"Haochen Shi\"},{\"authorId\":\"145974114\",\"name\":\"Jun Xiao\"},{\"authorId\":\"2125211\",\"name\":\"Yueting Zhuang\"},{\"authorId\":\"49336516\",\"name\":\"W. Wang\"}],\"doi\":\"10.1145/3394171.3413746\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9fa8f78e665c037da28a7e35a98c4d2521e3f12e\",\"title\":\"Relational Graph Learning for Grounded Video Description Generation\",\"url\":\"https://www.semanticscholar.org/paper/9fa8f78e665c037da28a7e35a98c4d2521e3f12e\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50826496\",\"name\":\"Jiannan Fang\"},{\"authorId\":\"74213550\",\"name\":\"Lingling Sun\"},{\"authorId\":null,\"name\":\"Yaqi Wang\"}],\"doi\":\"10.1117/12.2539615\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"6e077e28cadfc36eda163a01702deb795824d939\",\"title\":\"Video question answering by frame attention\",\"url\":\"https://www.semanticscholar.org/paper/6e077e28cadfc36eda163a01702deb795824d939\",\"venue\":\"International Conference on Digital Image Processing\",\"year\":2019},{\"arxivId\":\"2002.05556\",\"authors\":[{\"authorId\":\"144869806\",\"name\":\"Pedro Henrique Martins\"},{\"authorId\":\"2114966\",\"name\":\"Vlad Niculae\"},{\"authorId\":\"2566656\",\"name\":\"Zita Marinho\"},{\"authorId\":\"145644643\",\"name\":\"Andr\\u00e9 F. T. Martins\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4e627eb9f17369770f2cef5d71360c93c8494785\",\"title\":\"Sparse and Structured Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4e627eb9f17369770f2cef5d71360c93c8494785\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1811.11903\",\"authors\":[{\"authorId\":\"46382824\",\"name\":\"Hui Li\"},{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2019.00648\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f3d5130277fd028c0c9e621c73a4782621b14bf2\",\"title\":\"Visual Question Answering as Reading Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/f3d5130277fd028c0c9e621c73a4782621b14bf2\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3316122\",\"name\":\"Jingwei Yan\"},{\"authorId\":\"40608983\",\"name\":\"W. Zheng\"},{\"authorId\":\"144801562\",\"name\":\"Zhen Cui\"},{\"authorId\":\"2397257\",\"name\":\"Chuangao Tang\"},{\"authorId\":\"38144094\",\"name\":\"T. Zhang\"},{\"authorId\":\"145887139\",\"name\":\"Yuan Zong\"}],\"doi\":\"10.1016/j.neucom.2018.03.068\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5cf9b509bc8192bd23ce7d9f2e6a17bf992358c7\",\"title\":\"Multi-cue fusion for emotion recognition in the wild\",\"url\":\"https://www.semanticscholar.org/paper/5cf9b509bc8192bd23ce7d9f2e6a17bf992358c7\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40069761\",\"name\":\"Auston Sterling\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"9e404eb374035b8a79b45ef4fcb6f728f4372ef2\",\"title\":\"AUDIO-MATERIAL MODELING AND RECONSTRUCTION FOR MULTIMODAL INTERACTION\",\"url\":\"https://www.semanticscholar.org/paper/9e404eb374035b8a79b45ef4fcb6f728f4372ef2\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"16149902\",\"name\":\"Janani Ramaswamy\"},{\"authorId\":\"144009889\",\"name\":\"Sukhendu Das\"}],\"doi\":\"10.1109/WACV45572.2020.9093616\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c911d81bddb48490a02258e79379b6428246ddc2\",\"title\":\"See the Sound, Hear the Pixels\",\"url\":\"https://www.semanticscholar.org/paper/c911d81bddb48490a02258e79379b6428246ddc2\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1840482010\",\"name\":\"Anjan Dutta\"},{\"authorId\":\"2893664\",\"name\":\"Zeynep Akata\"}],\"doi\":\"10.1007/s11263-020-01350-x\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"66b92cfd4f5d79ba8e9369cc451f996146294660\",\"title\":\"Semantically Tied Paired Cycle Consistency for Any-Shot Sketch-Based Image Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/66b92cfd4f5d79ba8e9369cc451f996146294660\",\"venue\":\"International Journal of Computer Vision\",\"year\":2020},{\"arxivId\":\"1806.03726\",\"authors\":[{\"authorId\":\"38784892\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"}],\"doi\":\"10.1109/CVPR.2018.00599\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"1bfc74bad04b407d1792a70d73a3f5dc0be0506d\",\"title\":\"Cross-Dataset Adaptation for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1bfc74bad04b407d1792a70d73a3f5dc0be0506d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1893101\",\"name\":\"Sreyasee Das Bhattacharjee\"},{\"authorId\":\"2284272\",\"name\":\"William J. Tolone\"},{\"authorId\":\"1505820260\",\"name\":\"Roy Cheria\"},{\"authorId\":\"1505786182\",\"name\":\"Urmimala Sarka\"}],\"doi\":\"10.1109/BigData47090.2019.9005499\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0dd95ddec80c2cbc08d5e2271f47b417b08422b8\",\"title\":\"Multimodal, Context-Aware, Feature Representation Learning for Classification and Localization\",\"url\":\"https://www.semanticscholar.org/paper/0dd95ddec80c2cbc08d5e2271f47b417b08422b8\",\"venue\":\"2019 IEEE International Conference on Big Data (Big Data)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66406598\",\"name\":\"Hankyeol Lee\"},{\"authorId\":\"31335213\",\"name\":\"Seokeon Choi\"},{\"authorId\":\"88470948\",\"name\":\"Y. Kim\"},{\"authorId\":\"145568138\",\"name\":\"Changick Kim\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c12fe367f3083901cc96a87dec98ab46c4d3288b\",\"title\":\"Bilinear Siamese Networks with Background Suppression for Visual Object Tracking\",\"url\":\"https://www.semanticscholar.org/paper/c12fe367f3083901cc96a87dec98ab46c4d3288b\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2605815\",\"name\":\"Haofeng Zhang\"},{\"authorId\":\"144325904\",\"name\":\"Yang Long\"},{\"authorId\":\"2345507\",\"name\":\"Wankou Yang\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"}],\"doi\":\"10.1016/j.ins.2018.08.048\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"be611a55959b673296b0d0fcd845b66a45539657\",\"title\":\"Dual-verification network for zero-shot learning\",\"url\":\"https://www.semanticscholar.org/paper/be611a55959b673296b0d0fcd845b66a45539657\",\"venue\":\"Inf. Sci.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"100775859\",\"name\":\"Chuanfei Hu\"},{\"authorId\":null,\"name\":\"Yongxiong Wang\"}],\"doi\":\"10.1109/TIE.2019.2962437\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"24d73ba7868648ae304c87957c6a240d963ae4e3\",\"title\":\"An Efficient Convolutional Neural Network Model Based on Object-Level Attention Mechanism for Casting Defect Detection on Radiography Images\",\"url\":\"https://www.semanticscholar.org/paper/24d73ba7868648ae304c87957c6a240d963ae4e3\",\"venue\":\"IEEE Transactions on Industrial Electronics\",\"year\":2020},{\"arxivId\":\"2007.06198\",\"authors\":[{\"authorId\":\"9748140\",\"name\":\"K. Gouthaman\"},{\"authorId\":\"50853059\",\"name\":\"Anurag Mittal\"}],\"doi\":\"10.1007/978-3-030-58601-0_2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"06b869a92a22db711e4fbe8b141c83523c7c4604\",\"title\":\"Reducing Language Biases in Visual Question Answering with Visually-Grounded Question Encoder\",\"url\":\"https://www.semanticscholar.org/paper/06b869a92a22db711e4fbe8b141c83523c7c4604\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1904.11141\",\"authors\":[{\"authorId\":\"47002847\",\"name\":\"Ya-Li Li\"},{\"authorId\":\"1678689\",\"name\":\"S. Wang\"}],\"doi\":\"10.1109/TIP.2019.2957850\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"1e63c6436361bee3f37715c2bffb7affe9504a0d\",\"title\":\"HAR-Net: Joint Learning of Hybrid Attention for Single-Stage Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/1e63c6436361bee3f37715c2bffb7affe9504a0d\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1906.10096\",\"authors\":[{\"authorId\":\"50171614\",\"name\":\"X. Wu\"},{\"authorId\":\"145611842\",\"name\":\"Eric Granger\"},{\"authorId\":\"4729239\",\"name\":\"X. Feng\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2981694e0b92472b0906bd65125f0431e13829e1\",\"title\":\"Audio-Visual Kinship Verification\",\"url\":\"https://www.semanticscholar.org/paper/2981694e0b92472b0906bd65125f0431e13829e1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1910.03230\",\"authors\":[{\"authorId\":\"2928777\",\"name\":\"Wenhu Chen\"},{\"authorId\":\"153731335\",\"name\":\"Zhe Gan\"},{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"153655416\",\"name\":\"Yu Cheng\"},{\"authorId\":\"152876475\",\"name\":\"William W. J. Wang\"},{\"authorId\":\"32556571\",\"name\":\"J. Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d0bbae624efbfeee01bd38185c6d754c08417de7\",\"title\":\"Meta Module Network for Compositional Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/d0bbae624efbfeee01bd38185c6d754c08417de7\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1910.04964\",\"authors\":[{\"authorId\":\"145583986\",\"name\":\"Wenwu Zhu\"},{\"authorId\":\"72541452\",\"name\":\"X. Wang\"},{\"authorId\":\"1786871\",\"name\":\"Hongzhi Li\"}],\"doi\":\"10.1109/TCSVT.2019.2940647\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3d92574b3eb8a90736afb0d6a56f581eee79bdea\",\"title\":\"Multi-Modal Deep Analysis for Multimedia\",\"url\":\"https://www.semanticscholar.org/paper/3d92574b3eb8a90736afb0d6a56f581eee79bdea\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1514929766\",\"name\":\"Chongqing Chen\"},{\"authorId\":\"1840771\",\"name\":\"D. Han\"},{\"authorId\":\"71563119\",\"name\":\"Jun Wang\"}],\"doi\":\"10.1109/ACCESS.2020.2975093\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e75fa8852f5a4779cfdf2f22bd87e213f57b2d20\",\"title\":\"Multimodal Encoder-Decoder Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e75fa8852f5a4779cfdf2f22bd87e213f57b2d20\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46270655\",\"name\":\"Zilong Liu\"},{\"authorId\":\"121954937\",\"name\":\"Chi-Man Pun\"}],\"doi\":\"10.1016/j.ins.2017.12.044\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"86ef1800a36d258a2ed420c73548f784521c123a\",\"title\":\"Reversible data-hiding in encrypted images by redundant space transfer\",\"url\":\"https://www.semanticscholar.org/paper/86ef1800a36d258a2ed420c73548f784521c123a\",\"venue\":\"Inf. Sci.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1796706\",\"name\":\"Daojian Zeng\"},{\"authorId\":\"1400347434\",\"name\":\"Guanhong Zhou\"},{\"authorId\":\"9491882\",\"name\":\"J. Wang\"}],\"doi\":\"10.1109/ICECIE47765.2019.8974765\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"01163764edf888ded242e992845badaaf6c6ec6e\",\"title\":\"Residual Self-Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/01163764edf888ded242e992845badaaf6c6ec6e\",\"venue\":\"2019 1st International Conference on Electrical, Control and Instrumentation Engineering (ICECIE)\",\"year\":2019},{\"arxivId\":\"1810.10656\",\"authors\":[{\"authorId\":\"2909186\",\"name\":\"Ben Zion Vatashsky\"},{\"authorId\":\"1743045\",\"name\":\"S. Ullman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"86553974fabf38bbe022dc44794f345339b45c0b\",\"title\":\"Understand, Compose and Respond - Answering Visual Questions by a Composition of Abstract Procedures\",\"url\":\"https://www.semanticscholar.org/paper/86553974fabf38bbe022dc44794f345339b45c0b\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39746700\",\"name\":\"D. Kim\"},{\"authorId\":\"46207897\",\"name\":\"Seonhoon Kim\"},{\"authorId\":\"3160425\",\"name\":\"N. Kwak\"}],\"doi\":\"10.18653/v1/P19-1347\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b7e3b4e36476519c27c7e433b768636fc23eca5b\",\"title\":\"Textbook Question Answering with Multi-modal Context Graph Understanding and Self-supervised Open-set Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/b7e3b4e36476519c27c7e433b768636fc23eca5b\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1612.00837\",\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"7595427\",\"name\":\"Tejas Khot\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2017.670\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"title\":\"Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51021265\",\"name\":\"T. Yu\"},{\"authorId\":\"97583812\",\"name\":\"J. Yu\"},{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/TIP.2019.2940677\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"ef33aedbab68b0771f6dd7ca8ec2492f12d7ea51\",\"title\":\"Compositional Attention Networks With Two-Stream Fusion for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ef33aedbab68b0771f6dd7ca8ec2492f12d7ea51\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49303626\",\"name\":\"K. Su\"},{\"authorId\":\"144904233\",\"name\":\"Hang Su\"},{\"authorId\":\"104545113\",\"name\":\"J. Li\"},{\"authorId\":\"1557387379\",\"name\":\"Jun Zhu\"}],\"doi\":\"10.3389/frobt.2020.00109\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"22e2a19bef88c30a37402da5b54fac34655d77ea\",\"title\":\"Toward Accurate Visual Reasoning With Dual-Path Neural Module Networks\",\"url\":\"https://www.semanticscholar.org/paper/22e2a19bef88c30a37402da5b54fac34655d77ea\",\"venue\":\"Frontiers in Robotics and AI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2223252\",\"name\":\"Y. Zhou\"},{\"authorId\":\"1572139630\",\"name\":\"Rongrong Ji\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"1993645531\",\"name\":\"Gen Luo\"},{\"authorId\":\"46761465\",\"name\":\"Xiaopeng Hong\"},{\"authorId\":\"34739384\",\"name\":\"Jinsong Su\"},{\"authorId\":\"2713947\",\"name\":\"Xinghao Ding\"},{\"authorId\":\"40799321\",\"name\":\"Ling Shao\"}],\"doi\":\"10.1145/3394171.3413998\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"72687e467b4ab4d4799cca976013c5936ccb74b1\",\"title\":\"K-armed Bandit based Multi-Modal Network Architecture Search for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/72687e467b4ab4d4799cca976013c5936ccb74b1\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48620041\",\"name\":\"Yun Yi\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"}],\"doi\":\"10.1007/s11042-018-5662-9\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"74056b33f3b520bb8bb78863ee99267d5dccd98e\",\"title\":\"Multi-modal learning for affective content analysis in movies\",\"url\":\"https://www.semanticscholar.org/paper/74056b33f3b520bb8bb78863ee99267d5dccd98e\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"},{\"authorId\":\"48481929\",\"name\":\"Yi-jun Song\"},{\"authorId\":\"47891191\",\"name\":\"Jun Yu\"},{\"authorId\":\"48957872\",\"name\":\"Meng Wang\"},{\"authorId\":\"153159021\",\"name\":\"Qingming Huang\"}],\"doi\":\"10.1007/s11063-020-10205-y\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"6c1d607b58d31c582bee0cc78017909a1eed45c9\",\"title\":\"Intra- and Inter-modal Multilinear Pooling with Multitask Learning for Video Grounding\",\"url\":\"https://www.semanticscholar.org/paper/6c1d607b58d31c582bee0cc78017909a1eed45c9\",\"venue\":\"Neural Processing Letters\",\"year\":2020},{\"arxivId\":\"1803.02284\",\"authors\":[{\"authorId\":\"144820063\",\"name\":\"Yuming Shen\"},{\"authorId\":\"40241836\",\"name\":\"L. Liu\"},{\"authorId\":\"144618699\",\"name\":\"F. Shen\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"}],\"doi\":\"10.1109/CVPR.2018.00379\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1af4fb9ab061645cf0fb09d20b7cc7d834fd01ab\",\"title\":\"Zero-Shot Sketch-Image Hashing\",\"url\":\"https://www.semanticscholar.org/paper/1af4fb9ab061645cf0fb09d20b7cc7d834fd01ab\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145829609\",\"name\":\"Hung T. Le\"},{\"authorId\":\"6254479\",\"name\":\"T. Tran\"},{\"authorId\":\"144162181\",\"name\":\"S. Venkatesh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"44ba9ce0586fe6a7e55bb0702fd81d15fb755128\",\"title\":\"Self-Assttentive Associative Memory\",\"url\":\"https://www.semanticscholar.org/paper/44ba9ce0586fe6a7e55bb0702fd81d15fb755128\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2010.16010\",\"authors\":[{\"authorId\":\"1390575046\",\"name\":\"Yangyang Guo\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":\"46504200\",\"name\":\"Zhiyong Cheng\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9b9e35875ad771961ad2d35f7b9cd645b96afd04\",\"title\":\"Loss-rescaling VQA: Revisiting Language Prior Problem from a Class-imbalance View\",\"url\":\"https://www.semanticscholar.org/paper/9b9e35875ad771961ad2d35f7b9cd645b96afd04\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1802.07303\",\"authors\":[{\"authorId\":\"2298630\",\"name\":\"M. Gou\"},{\"authorId\":\"145373705\",\"name\":\"F. Xiong\"},{\"authorId\":\"1694992\",\"name\":\"O. Camps\"},{\"authorId\":\"1687866\",\"name\":\"M. Sznaier\"}],\"doi\":\"10.1109/CVPR.2018.00335\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d8a54c9f9f81e771059530934c9740c865ec328c\",\"title\":\"MoNet: Moments Embedding Network\",\"url\":\"https://www.semanticscholar.org/paper/d8a54c9f9f81e771059530934c9740c865ec328c\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2008.08909\",\"authors\":[{\"authorId\":\"1688272723\",\"name\":\"Guangshuai Gao\"},{\"authorId\":\"2954369\",\"name\":\"W. Zhao\"},{\"authorId\":\"150270468\",\"name\":\"Qingjie Liu\"},{\"authorId\":null,\"name\":\"Yunhong Wang\"}],\"doi\":\"10.1109/tcsvt.2020.2992054\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"97d45c4f4a24382da56997e1814223777fd02bc3\",\"title\":\"Co-Saliency Detection with Co-Attention Fully Convolutional Network\",\"url\":\"https://www.semanticscholar.org/paper/97d45c4f4a24382da56997e1814223777fd02bc3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47058196\",\"name\":\"X. Li\"},{\"authorId\":\"145776313\",\"name\":\"L. Lei\"},{\"authorId\":\"1500378392\",\"name\":\"Yuli Sun\"},{\"authorId\":\"50651883\",\"name\":\"M. Li\"},{\"authorId\":\"66930346\",\"name\":\"Gangyao Kuang\"}],\"doi\":\"10.1109/JSTARS.2020.2975252\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ec712742b813a98e38bdc72cb572a27e91abf6ab\",\"title\":\"Multimodal Bilinear Fusion Network With Second-Order Attention-Based Channel Selection for Land Cover Classification\",\"url\":\"https://www.semanticscholar.org/paper/ec712742b813a98e38bdc72cb572a27e91abf6ab\",\"venue\":\"IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing\",\"year\":2020},{\"arxivId\":\"2010.08189\",\"authors\":[{\"authorId\":\"2283009\",\"name\":\"W. Chen\"},{\"authorId\":\"46315247\",\"name\":\"W. Wang\"},{\"authorId\":\"87109212\",\"name\":\"Li Liu\"},{\"authorId\":\"1731570\",\"name\":\"M. Lew\"}],\"doi\":\"10.1016/j.neucom.2020.10.042\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"61ba6969078b7358c61f7eb93b4150ab0e4f329b\",\"title\":\"New Ideas and Trends in Deep Multimodal Content Understanding: A Review\",\"url\":\"https://www.semanticscholar.org/paper/61ba6969078b7358c61f7eb93b4150ab0e4f329b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40246571\",\"name\":\"X. Liu\"},{\"authorId\":\"1856494\",\"name\":\"Jiajia Geng\"},{\"authorId\":\"1805398\",\"name\":\"Haibin Ling\"},{\"authorId\":\"143840540\",\"name\":\"Yiu-ming Cheung\"}],\"doi\":\"10.1016/j.patcog.2018.12.011\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b4d841bd560a52523846c7cc5533411151eb0b94\",\"title\":\"Attention guided deep audio-face fusion for efficient speaker naming\",\"url\":\"https://www.semanticscholar.org/paper/b4d841bd560a52523846c7cc5533411151eb0b94\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151472652\",\"name\":\"Yuqi Huo\"},{\"authorId\":\"101246507\",\"name\":\"Xiaoli Xu\"},{\"authorId\":\"46215480\",\"name\":\"Yao Lu\"},{\"authorId\":\"2520427\",\"name\":\"Yulei Niu\"},{\"authorId\":\"48876151\",\"name\":\"Mingyu Ding\"},{\"authorId\":\"1776220\",\"name\":\"Zhiwu Lu\"},{\"authorId\":\"145406420\",\"name\":\"Tao Xiang\"},{\"authorId\":\"153693432\",\"name\":\"Jirong Wen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"89fafbe91b31d43dc3314ffabffa79a5f5ad746f\",\"title\":\"Lightweight Action Recognition in Compressed Videos\",\"url\":\"https://www.semanticscholar.org/paper/89fafbe91b31d43dc3314ffabffa79a5f5ad746f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152303308\",\"name\":\"Mengfei Li\"},{\"authorId\":\"152553572\",\"name\":\"Huan Shao\"},{\"authorId\":\"144911521\",\"name\":\"Y. Ji\"},{\"authorId\":\"49308130\",\"name\":\"Yang Yang\"},{\"authorId\":\"6681872\",\"name\":\"Chunping Liu\"}],\"doi\":\"10.1109/ICMEW.2019.00045\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"054b5c14785494d4c991155592b95928d7e9d14a\",\"title\":\"Question Splitting and Unbalanced Multi-modal Pooling for VQA\",\"url\":\"https://www.semanticscholar.org/paper/054b5c14785494d4c991155592b95928d7e9d14a\",\"venue\":\"2019 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2019},{\"arxivId\":\"1902.00038\",\"authors\":[{\"authorId\":\"1405301761\",\"name\":\"Hedi Ben-younes\"},{\"authorId\":\"7535126\",\"name\":\"R\\u00e9mi Cad\\u00e8ne\"},{\"authorId\":\"1728523\",\"name\":\"N. Thome\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"}],\"doi\":\"10.1609/aaai.v33i01.33018102\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a154867c7b45456abb14708a7bbc9c849aeecf4f\",\"title\":\"BLOCK: Bilinear Superdiagonal Fusion for Visual Question Answering and Visual Relationship Detection\",\"url\":\"https://www.semanticscholar.org/paper/a154867c7b45456abb14708a7bbc9c849aeecf4f\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10405058\",\"name\":\"Chenfei Wu\"},{\"authorId\":\"46700331\",\"name\":\"J. Liu\"},{\"authorId\":\"38542466\",\"name\":\"X. Wang\"},{\"authorId\":\"143672034\",\"name\":\"X. Dong\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"184002001b3b514f432e538f872aebce3c7db060\",\"title\":\"Chain of Reasoning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/184002001b3b514f432e538f872aebce3c7db060\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2681569\",\"name\":\"Haoqi Fan\"},{\"authorId\":\"27329137\",\"name\":\"Jiatong Zhou\"}],\"doi\":\"10.1109/CVPR.2018.00118\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"135c71101af5d030f8cf470c454e7b655d699920\",\"title\":\"Stacked Latent Attention for Multimodal Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/135c71101af5d030f8cf470c454e7b655d699920\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1906.04464\",\"authors\":[{\"authorId\":\"3144952\",\"name\":\"Sibei Yang\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"66616425\",\"name\":\"Yizhou Yu\"}],\"doi\":\"10.1109/tpami.2020.2973983\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"14204fd579ad2802490a8f4a781392ca7ba19c80\",\"title\":\"Relationship-Embedded Representation Learning for Grounding Referring Expressions.\",\"url\":\"https://www.semanticscholar.org/paper/14204fd579ad2802490a8f4a781392ca7ba19c80\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"1811.08481\",\"authors\":[{\"authorId\":\"2909186\",\"name\":\"Ben Zion Vatashsky\"},{\"authorId\":\"1743045\",\"name\":\"S. Ullman\"}],\"doi\":\"10.1109/CVPR42600.2020.01039\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"66ccd32be901da217799c78af229676418c7a882\",\"title\":\"VQA With No Questions-Answers Training\",\"url\":\"https://www.semanticscholar.org/paper/66ccd32be901da217799c78af229676418c7a882\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35880964\",\"name\":\"Siddhant M. Jayakumar\"},{\"authorId\":\"10698483\",\"name\":\"Jacob Menick\"},{\"authorId\":\"49281458\",\"name\":\"W. Czarnecki\"},{\"authorId\":\"86943666\",\"name\":\"J. Schwarz\"},{\"authorId\":\"34269227\",\"name\":\"Jack W. Rae\"},{\"authorId\":\"2217144\",\"name\":\"Simon Osindero\"},{\"authorId\":\"1725303\",\"name\":\"Y. Teh\"},{\"authorId\":\"3367786\",\"name\":\"T. Harley\"},{\"authorId\":\"1996134\",\"name\":\"Razvan Pascanu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"caa31faab39d34ecbb8100911640dfaec76f9ee9\",\"title\":\"Multiplicative Interactions and Where to Find Them\",\"url\":\"https://www.semanticscholar.org/paper/caa31faab39d34ecbb8100911640dfaec76f9ee9\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"2003.10065\",\"authors\":[{\"authorId\":\"2826839\",\"name\":\"Qingxing Cao\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"3170394\",\"name\":\"Keze Wang\"},{\"authorId\":\"49478124\",\"name\":\"L. Lin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e4e90d80721fc24ac40f4711f8692aba08dc14e0\",\"title\":\"Linguistically Driven Graph Capsule Network for Visual Question Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/e4e90d80721fc24ac40f4711f8692aba08dc14e0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1902.00579\",\"authors\":[{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"145215470\",\"name\":\"Yu Cheng\"},{\"authorId\":\"1877430\",\"name\":\"A. E. Kholy\"},{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"38079056\",\"name\":\"Jingjing Liu\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":\"10.18653/v1/P19-1648\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"8d9f1eaac344b7e6cc76396f576c5dc0bd0b34f4\",\"title\":\"Multi-step Reasoning via Recurrent Dual Attention for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/8d9f1eaac344b7e6cc76396f576c5dc0bd0b34f4\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31438037\",\"name\":\"Guimin Lin\"},{\"authorId\":\"1768361\",\"name\":\"Q. Wu\"},{\"authorId\":\"20686917\",\"name\":\"Lida Qiu\"},{\"authorId\":\"4952576\",\"name\":\"X. Huang\"}],\"doi\":\"10.1016/j.neucom.2017.09.062\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"33cb59083d3dd2ebea9423985ede6516f87ffa87\",\"title\":\"Image super-resolution using a dilated convolutional neural network\",\"url\":\"https://www.semanticscholar.org/paper/33cb59083d3dd2ebea9423985ede6516f87ffa87\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":\"2007.09867\",\"authors\":[{\"authorId\":\"48219073\",\"name\":\"Boren Li\"},{\"authorId\":\"1823658702\",\"name\":\"Po-Yu Zhuang\"},{\"authorId\":\"39894414\",\"name\":\"Jian Gu\"},{\"authorId\":\"150218408\",\"name\":\"Mingyang Li\"},{\"authorId\":\"22063354\",\"name\":\"Ping Tan\"}],\"doi\":\"10.1007/978-3-030-58604-1_12\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dd7dc3555e985cea80c71d1646ab3e87001b3c46\",\"title\":\"Interpretable Foreground Object Search As Knowledge Distillation\",\"url\":\"https://www.semanticscholar.org/paper/dd7dc3555e985cea80c71d1646ab3e87001b3c46\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144612044\",\"name\":\"H. Chauhan\"},{\"authorId\":\"40195882\",\"name\":\"M. Firdaus\"},{\"authorId\":\"1734904\",\"name\":\"Asif Ekbal\"},{\"authorId\":\"145532184\",\"name\":\"P. Bhattacharyya\"}],\"doi\":\"10.18653/v1/P19-1540\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"314b6a975373f69f7628f2bc8647084181c84ac9\",\"title\":\"Ordinal and Attribute Aware Response Generation in a Multimodal Dialogue System\",\"url\":\"https://www.semanticscholar.org/paper/314b6a975373f69f7628f2bc8647084181c84ac9\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47056886\",\"name\":\"Xiangpeng Li\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"9764377\",\"name\":\"Xuanhan Wang\"},{\"authorId\":\"51347989\",\"name\":\"W. Liu\"},{\"authorId\":\"1390532590\",\"name\":\"Xing Xu\"},{\"authorId\":\"152555512\",\"name\":\"Heng Tao Shen\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"}],\"doi\":\"10.1145/3343031.3350971\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f133f3daed70c50d1828cc6a46bc2e8dbd7880de\",\"title\":\"Learnable Aggregating Net with Diversity Learning for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f133f3daed70c50d1828cc6a46bc2e8dbd7880de\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1911.03897\",\"authors\":[{\"authorId\":\"19677945\",\"name\":\"Yaoyiran Li\"},{\"authorId\":\"144924128\",\"name\":\"Jing Jiang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"863bc093e87a2963a0f6b5fc6c2d8b7451b8a7b2\",\"title\":\"Two-Headed Monster And Crossed Co-Attention Networks\",\"url\":\"https://www.semanticscholar.org/paper/863bc093e87a2963a0f6b5fc6c2d8b7451b8a7b2\",\"venue\":\"AACL\",\"year\":2020},{\"arxivId\":\"2002.03519\",\"authors\":[{\"authorId\":\"145829609\",\"name\":\"Hung T. Le\"},{\"authorId\":\"6254479\",\"name\":\"T. Tran\"},{\"authorId\":\"144162181\",\"name\":\"S. Venkatesh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2e286108e8b83e8951abf5947a93032106514fe4\",\"title\":\"Self-Attentive Associative Memory\",\"url\":\"https://www.semanticscholar.org/paper/2e286108e8b83e8951abf5947a93032106514fe4\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":\"2010.10019\",\"authors\":[{\"authorId\":\"47267313\",\"name\":\"T. Le\"},{\"authorId\":\"144672395\",\"name\":\"Vuong Le\"},{\"authorId\":\"144162181\",\"name\":\"S. Venkatesh\"},{\"authorId\":\"6254479\",\"name\":\"T. Tran\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"93ff44e056befc6306abab75307aa23bce22ca70\",\"title\":\"Hierarchical Conditional Relation Networks for Multimodal Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/93ff44e056befc6306abab75307aa23bce22ca70\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"31081539\",\"name\":\"Pengpeng Zeng\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"4495301\",\"name\":\"Yuan-Fang Li\"},{\"authorId\":\"1686917\",\"name\":\"Wu Liu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1609/AAAI.V33I01.33016391\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"524879e9a072489110e9578cf2689e50c5531f05\",\"title\":\"Structured Two-Stream Attention Network for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/524879e9a072489110e9578cf2689e50c5531f05\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49597404\",\"name\":\"Z. Fang\"},{\"authorId\":null,\"name\":\"Jing Liu\"},{\"authorId\":\"49544292\",\"name\":\"Xueliang Liu\"},{\"authorId\":null,\"name\":\"Qu Tang\"},{\"authorId\":\"50025104\",\"name\":\"Yonghong Li\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1145/3282469\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2c74311cc5e18a120bebf331b0dd85c72426380d\",\"title\":\"BTDP: Toward Sparse Fusion with Block Term Decomposition Pooling for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2c74311cc5e18a120bebf331b0dd85c72426380d\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":\"1910.14671\",\"authors\":[{\"authorId\":\"9852531\",\"name\":\"J. Lin\"},{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1743587c272c36dbda0adc50496bf7f34b8148f1\",\"title\":\"TAB-VCR: Tags and Attributes based Visual Commonsense Reasoning Baselines\",\"url\":\"https://www.semanticscholar.org/paper/1743587c272c36dbda0adc50496bf7f34b8148f1\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1901.04889\",\"authors\":[{\"authorId\":\"26296787\",\"name\":\"Yuanyuan Zhang\"},{\"authorId\":\"2855286\",\"name\":\"Z. Wang\"},{\"authorId\":\"145419855\",\"name\":\"J. Du\"}],\"doi\":\"10.1109/IJCNN.2019.8851942\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c21431579679b1fd50216dca0f0e9e04060ab863\",\"title\":\"Deep Fusion: An Attention Guided Factorized Bilinear Pooling for Audio-video Emotion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c21431579679b1fd50216dca0f0e9e04060ab863\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33396604\",\"name\":\"N. Sankaran\"},{\"authorId\":\"33754562\",\"name\":\"D. Mohan\"},{\"authorId\":\"1800513\",\"name\":\"S. Setlur\"},{\"authorId\":\"51023269\",\"name\":\"V. Govindaraju\"},{\"authorId\":\"83368994\",\"name\":\"D. Fedorishin\"}],\"doi\":\"10.1109/FG.2019.8756519\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1c270ea47fc3aa68121855d7e2cdecafc12955a2\",\"title\":\"Representation Learning Through Cross-Modality Supervision\",\"url\":\"https://www.semanticscholar.org/paper/1c270ea47fc3aa68121855d7e2cdecafc12955a2\",\"venue\":\"2019 14th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2019)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"94011352\",\"name\":\"S. Chen\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"456108dc68bc5d2a2e39cbeb69f51c65d0acf53e\",\"title\":\"AiR: Attention with Reasoning Capability (Supplementary Materials)\",\"url\":\"https://www.semanticscholar.org/paper/456108dc68bc5d2a2e39cbeb69f51c65d0acf53e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"81267766\",\"name\":\"Benjamin Sertolli\"},{\"authorId\":\"1709997\",\"name\":\"Nicholas Cummins\"},{\"authorId\":\"2562651\",\"name\":\"Abdulkadir Seng\\u00fcr\"},{\"authorId\":\"145411696\",\"name\":\"B. Schuller\"}],\"doi\":\"10.1145/3242969.3243683\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4687e2b57a3d8f433abcaa5f2daf56e737dc5ec5\",\"title\":\"Deep End-to-End Representation Learning for Food Type Recognition from Speech\",\"url\":\"https://www.semanticscholar.org/paper/4687e2b57a3d8f433abcaa5f2daf56e737dc5ec5\",\"venue\":\"ICMI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1692274\",\"name\":\"Y. Zhou\"},{\"authorId\":\"3303251\",\"name\":\"Fan-Zhi Zeng\"},{\"authorId\":\"32140356\",\"name\":\"Jiechang Qian\"},{\"authorId\":\"2257769\",\"name\":\"Xintong Han\"}],\"doi\":\"10.1016/j.ins.2018.09.051\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6611e910378693d8bdcc4dee77b75f57e5fe87f8\",\"title\":\"3D shape classification and retrieval based on polar view\",\"url\":\"https://www.semanticscholar.org/paper/6611e910378693d8bdcc4dee77b75f57e5fe87f8\",\"venue\":\"Inf. Sci.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9024867\",\"name\":\"Jongkwang Hong\"},{\"authorId\":\"48079221\",\"name\":\"Sungho Park\"},{\"authorId\":\"1703310\",\"name\":\"Hyeran Byun\"}],\"doi\":\"10.1016/j.neucom.2020.03.098\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"72e48298519b5ff583e585a65eeea3ac10556adf\",\"title\":\"Selective residual learning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/72e48298519b5ff583e585a65eeea3ac10556adf\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144493079\",\"name\":\"Z. Hu\"},{\"authorId\":\"1754240987\",\"name\":\"Jielong Wei\"},{\"authorId\":\"2639734\",\"name\":\"Qingbao Huang\"},{\"authorId\":\"1904290800\",\"name\":\"Hanyu Liang\"},{\"authorId\":\"1908173213\",\"name\":\"Xingmao Zhang\"},{\"authorId\":\"1901543027\",\"name\":\"Qingguang Liu\"}],\"doi\":\"10.1109/DSC50466.2020.00040\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2ad3b719a1a0868c29dbf72e81c8c3d226196c28\",\"title\":\"Graph Convolutional Network for Visual Question Answering Based on Fine-grained Question Representation\",\"url\":\"https://www.semanticscholar.org/paper/2ad3b719a1a0868c29dbf72e81c8c3d226196c28\",\"venue\":\"2020 IEEE Fifth International Conference on Data Science in Cyberspace (DSC)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2003641204\",\"name\":\"Bumjun Jung\"},{\"authorId\":\"144204227\",\"name\":\"Lin Gu\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2834564e95feaf1ff5bbba786c0cbcc94a333ae5\",\"title\":\"bumjun_jung at VQA-Med 2020: VQA Model Based on Feature Extraction and Multi-modal Feature Fusion\",\"url\":\"https://www.semanticscholar.org/paper/2834564e95feaf1ff5bbba786c0cbcc94a333ae5\",\"venue\":\"CLEF\",\"year\":2020},{\"arxivId\":\"1906.02467\",\"authors\":[{\"authorId\":\"48567197\",\"name\":\"Zhou Yu\"},{\"authorId\":\"50854337\",\"name\":\"D. Xu\"},{\"authorId\":\"1720236\",\"name\":\"J. Yu\"},{\"authorId\":\"144478231\",\"name\":\"T. Yu\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1609/aaai.v33i01.33019127\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4f2c1af57c056102806a184517313804f66e7447\",\"title\":\"ActivityNet-QA: A Dataset for Understanding Complex Web Videos via Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/4f2c1af57c056102806a184517313804f66e7447\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48352212\",\"name\":\"Aming Wu\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"}],\"doi\":\"10.24963/ijcai.2018/143\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e2e5cef45c60c52fb0d0415cca6cbf35beab3873\",\"title\":\"Multi-modal Circulant Fusion for Video-to-Language and Backward\",\"url\":\"https://www.semanticscholar.org/paper/e2e5cef45c60c52fb0d0415cca6cbf35beab3873\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144454465\",\"name\":\"L. Peng\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":\"32518385\",\"name\":\"Z. Wang\"},{\"authorId\":\"153028349\",\"name\":\"Xiao Wu\"},{\"authorId\":\"83672162\",\"name\":\"Zi Huang\"}],\"doi\":\"10.1145/3343031.3350925\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb488ee07fc078eb0200c3a4ca119bc67303e507\",\"title\":\"CRA-Net: Composed Relation Attention Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/eb488ee07fc078eb0200c3a4ca119bc67303e507\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2712862\",\"name\":\"D. Zhang\"},{\"authorId\":\"145690873\",\"name\":\"R. Cao\"},{\"authorId\":\"1765710\",\"name\":\"Sai Wu\"}],\"doi\":\"10.1016/J.INFFUS.2019.03.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"91118408f8192c2addade2a0401a32c3bbd47818\",\"title\":\"Information fusion in visual question answering: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/91118408f8192c2addade2a0401a32c3bbd47818\",\"venue\":\"Inf. Fusion\",\"year\":2019},{\"arxivId\":\"2010.09283\",\"authors\":[{\"authorId\":\"3469411\",\"name\":\"Mohammed Haroon Dupty\"},{\"authorId\":\"46605464\",\"name\":\"W. S. Lee\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4e6327d41b1263eccc4c27edd5dbe43489be3a92\",\"title\":\"Neuralizing Efficient Higher-order Belief Propagation\",\"url\":\"https://www.semanticscholar.org/paper/4e6327d41b1263eccc4c27edd5dbe43489be3a92\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38203465\",\"name\":\"Zhenzhong Kuang\"},{\"authorId\":\"1720236\",\"name\":\"J. Yu\"},{\"authorId\":\"144147221\",\"name\":\"Jianping Fan\"},{\"authorId\":\"46699144\",\"name\":\"Min Tan\"}],\"doi\":\"10.1109/ICME.2018.8486479\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b863c5cc7b8f8f817662c398f3dd305bb2b23be7\",\"title\":\"Deep Point Convolutional Approach for 3D Model Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/b863c5cc7b8f8f817662c398f3dd305bb2b23be7\",\"venue\":\"2018 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2018},{\"arxivId\":\"2009.12770\",\"authors\":[{\"authorId\":\"1865719481\",\"name\":\"Deepak Gupta\"},{\"authorId\":\"1492191087\",\"name\":\"Swati Suman\"},{\"authorId\":\"152800923\",\"name\":\"A. Ekbal\"}],\"doi\":\"10.1016/J.ESWA.2020.113993\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"9fe3eeafbe022de014aeb54d0b55502e2a2e46fe\",\"title\":\"Hierarchical Deep Multi-modal Network for Medical Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/9fe3eeafbe022de014aeb54d0b55502e2a2e46fe\",\"venue\":\"Expert Syst. Appl.\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39449550\",\"name\":\"J. Zhang\"},{\"authorId\":\"144344681\",\"name\":\"Y. Xia\"},{\"authorId\":\"23212559\",\"name\":\"Haoyue Zeng\"},{\"authorId\":\"1801395\",\"name\":\"Y. Zhang\"}],\"doi\":\"10.1016/j.neucom.2018.08.022\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3078ce7bea51c5d2452f57eb9eb15897b88e401d\",\"title\":\"NODULe: Combining constrained multi-scale LoG filters with densely dilated 3D deep convolutional neural network for pulmonary nodule detection\",\"url\":\"https://www.semanticscholar.org/paper/3078ce7bea51c5d2452f57eb9eb15897b88e401d\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1711219\",\"name\":\"Juzheng Li\"},{\"authorId\":\"144904238\",\"name\":\"H. Su\"},{\"authorId\":\"145254043\",\"name\":\"J. Zhu\"},{\"authorId\":\"49846744\",\"name\":\"Bo Zhang\"}],\"doi\":\"10.1109/ICME.2018.8486468\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c1655b32a30165f7863ece52c54270662a28be0e\",\"title\":\"Essay-Anchor Attentive Multi-Modal Bilinear Pooling for Textbook Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/c1655b32a30165f7863ece52c54270662a28be0e\",\"venue\":\"2018 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2018},{\"arxivId\":\"2012.10285\",\"authors\":[{\"authorId\":\"14358891\",\"name\":\"T. Winterbottom\"},{\"authorId\":\"7750732\",\"name\":\"S. Xiao\"},{\"authorId\":\"145147517\",\"name\":\"A. McLean\"},{\"authorId\":\"1875235\",\"name\":\"N. A. Moubayed\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f06224d597451ce1d440ca0c8542dee4a5767afe\",\"title\":\"Trying Bilinear Pooling in Video-QA\",\"url\":\"https://www.semanticscholar.org/paper/f06224d597451ce1d440ca0c8542dee4a5767afe\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144286903\",\"name\":\"Q. Yang\"},{\"authorId\":\"51145694\",\"name\":\"Gaosheng Wu\"},{\"authorId\":\"47003385\",\"name\":\"Yujun Li\"},{\"authorId\":\"1773599\",\"name\":\"R. Li\"},{\"authorId\":\"70387082\",\"name\":\"Xiwu Gu\"},{\"authorId\":\"1720853808\",\"name\":\"Huicai Deng\"},{\"authorId\":\"1720822983\",\"name\":\"Junzhuang Wu\"}],\"doi\":\"10.1109/TCSS.2020.2986778\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6f11d9836aa871891d40604e6a19fa8ed3dd2dc2\",\"title\":\"AMNN: Attention-Based Multimodal Neural Network Model for Hashtag Recommendation\",\"url\":\"https://www.semanticscholar.org/paper/6f11d9836aa871891d40604e6a19fa8ed3dd2dc2\",\"venue\":\"IEEE Transactions on Computational Social Systems\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51042088\",\"name\":\"Ramit Sawhney\"},{\"authorId\":\"1825741695\",\"name\":\"Shivam Agarwal\"},{\"authorId\":\"2008177547\",\"name\":\"Arnav Wadhwa\"},{\"authorId\":\"1805378638\",\"name\":\"Rajiv Ratn Shah\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.676\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0b2b5e2c60f5c0d7cb9535b5e94fd1612d3ec21c\",\"title\":\"Deep Attentive Learning for Stock Movement Prediction From Social Media Text and Company Correlations\",\"url\":\"https://www.semanticscholar.org/paper/0b2b5e2c60f5c0d7cb9535b5e94fd1612d3ec21c\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2010.12917\",\"authors\":[{\"authorId\":\"3442255\",\"name\":\"Zan-Xia Jin\"},{\"authorId\":\"2003456770\",\"name\":\"Heran Wu\"},{\"authorId\":\"46962194\",\"name\":\"C. Yang\"},{\"authorId\":\"31679477\",\"name\":\"Fang Zhou\"},{\"authorId\":\"2005306\",\"name\":\"Jingyan Qin\"},{\"authorId\":\"145628818\",\"name\":\"Lei Xiao\"},{\"authorId\":\"120644708\",\"name\":\"XuCheng Yin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d209f0d94492447713541b28373d9b6cad5edeb9\",\"title\":\"RUArt: A Novel Text-Centered Solution for Text-Based Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d209f0d94492447713541b28373d9b6cad5edeb9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2358244\",\"name\":\"Naotsuna Fujimori\"},{\"authorId\":\"1809999\",\"name\":\"R. Endo\"},{\"authorId\":\"48230523\",\"name\":\"Yoshihiko Kawai\"},{\"authorId\":\"48281114\",\"name\":\"T. Mochizuki\"}],\"doi\":\"10.1007/978-3-030-41299-9_32\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d0b5627630177a11ed1aa9e42a0a76ceedaa8ba0\",\"title\":\"Modality-Specific Learning Rate Control for Multimodal Classification\",\"url\":\"https://www.semanticscholar.org/paper/d0b5627630177a11ed1aa9e42a0a76ceedaa8ba0\",\"venue\":\"ACPR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144544920\",\"name\":\"Fei Liu\"},{\"authorId\":\"1749850\",\"name\":\"J. Liu\"},{\"authorId\":\"49597404\",\"name\":\"Z. Fang\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1109/ICIP.2019.8803670\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"cd71651126f11162d262ff0dcb9ae094f51dcffd\",\"title\":\"Language and Visual Relations Encoding for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/cd71651126f11162d262ff0dcb9ae094f51dcffd\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7535126\",\"name\":\"R\\u00e9mi Cad\\u00e8ne\"},{\"authorId\":\"1405301761\",\"name\":\"Hedi Ben-younes\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"},{\"authorId\":\"1728523\",\"name\":\"N. Thome\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"cfc9ef5c7ef8056cff7bf1f1cfdd75e120f28231\",\"title\":\"Multimodal Relational Reasoning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/cfc9ef5c7ef8056cff7bf1f1cfdd75e120f28231\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3144952\",\"name\":\"Sibei Yang\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"66616425\",\"name\":\"Yizhou Yu\"}],\"doi\":\"10.1109/CVPR.2019.00427\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1db245d9d2873ed433774f55b74e5b0274a71bd8\",\"title\":\"Cross-Modal Relationship Inference for Grounding Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/1db245d9d2873ed433774f55b74e5b0274a71bd8\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1909.07583\",\"authors\":[{\"authorId\":\"1388780256\",\"name\":\"Yaser Alwatter\"},{\"authorId\":\"1798719\",\"name\":\"Yuhong Guo\"}],\"doi\":\"10.22215/etd/2019-13929\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"48795928eb87d1e8a038063b3aebee180e424d04\",\"title\":\"Inverse Visual Question Answering with Multi-Level Attentions\",\"url\":\"https://www.semanticscholar.org/paper/48795928eb87d1e8a038063b3aebee180e424d04\",\"venue\":\"ACML\",\"year\":2020},{\"arxivId\":\"2011.12870\",\"authors\":[{\"authorId\":\"1960607091\",\"name\":\"Yi Zhou\"},{\"authorId\":\"8157338\",\"name\":\"Zhenhao Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"14e5d984af4ac965579644bd0ea4ae42587b6a00\",\"title\":\"Multimodal Learning for Hateful Memes Detection\",\"url\":\"https://www.semanticscholar.org/paper/14e5d984af4ac965579644bd0ea4ae42587b6a00\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145878079\",\"name\":\"Vivek Sharma\"}],\"doi\":\"10.5445/IR/1000119819\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"3605e0e6ea610576fa85fcf8737b9f20ddd87180\",\"title\":\"Self-supervised Face Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/3605e0e6ea610576fa85fcf8737b9f20ddd87180\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1910.06745\",\"authors\":[{\"authorId\":\"49890233\",\"name\":\"Yundong Zhang\"},{\"authorId\":\"46477230\",\"name\":\"Hang Wu\"},{\"authorId\":\"30949464\",\"name\":\"Huiye Liu\"},{\"authorId\":\"145464469\",\"name\":\"L. Tong\"},{\"authorId\":\"1741624\",\"name\":\"M. Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d2e075b74f00f83237fbf8996ba6209f668ec7eb\",\"title\":\"Improve Model Generalization and Robustness to Dataset Bias with Bias-regularized Learning and Domain-guided Augmentation\",\"url\":\"https://www.semanticscholar.org/paper/d2e075b74f00f83237fbf8996ba6209f668ec7eb\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145770650\",\"name\":\"Lei Shi\"},{\"authorId\":\"112884785\",\"name\":\"Feifan Liu\"},{\"authorId\":\"6898369\",\"name\":\"Max P. Rosen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"1b0ae121c79437bb122d0cd20d744776445792a4\",\"title\":\"Deep Multimodal Learning for Medical Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1b0ae121c79437bb122d0cd20d744776445792a4\",\"venue\":\"CLEF\",\"year\":2019},{\"arxivId\":\"2001.04732\",\"authors\":[{\"authorId\":\"51238351\",\"name\":\"Andr\\u00e9s Mafla\"},{\"authorId\":\"2166891\",\"name\":\"S. Dey\"},{\"authorId\":\"35570245\",\"name\":\"Ali Furkan Biten\"},{\"authorId\":\"51231577\",\"name\":\"Llu\\u00eds G\\u00f3mez\"},{\"authorId\":\"1694974\",\"name\":\"Dimosthenis Karatzas\"}],\"doi\":\"10.1109/WACV45572.2020.9093373\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"871f316cb02dcc4327adbbb363e8925d6f05e1d0\",\"title\":\"Fine-grained Image Classification and Retrieval by Combining Visual and Locally Pooled Textual Features\",\"url\":\"https://www.semanticscholar.org/paper/871f316cb02dcc4327adbbb363e8925d6f05e1d0\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50171614\",\"name\":\"X. Wu\"},{\"authorId\":\"52194462\",\"name\":\"\\u00c9ric Granger\"},{\"authorId\":\"2385738\",\"name\":\"T. Kinnunen\"},{\"authorId\":\"51321428\",\"name\":\"X. Feng\"},{\"authorId\":\"46606565\",\"name\":\"A. Hadid\"}],\"doi\":\"10.1109/ICB45273.2019.8987241\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5eb9cac59fa92ab4ea76b0e74de58acd59186939\",\"title\":\"Audio-Visual Kinship Verification in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/5eb9cac59fa92ab4ea76b0e74de58acd59186939\",\"venue\":\"2019 International Conference on Biometrics (ICB)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1735739\",\"name\":\"Weifeng Zhang\"},{\"authorId\":\"119883573\",\"name\":\"J. Yu\"},{\"authorId\":\"47864783\",\"name\":\"H. Hu\"},{\"authorId\":\"144645443\",\"name\":\"H. Hu\"},{\"authorId\":\"70565757\",\"name\":\"Zengchang Qin\"}],\"doi\":\"10.1016/J.INFFUS.2019.08.009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"04afa0417dc2a4555c15243a69e6a54ce44ecf63\",\"title\":\"Multimodal feature fusion by relational reasoning and attention for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/04afa0417dc2a4555c15243a69e6a54ce44ecf63\",\"venue\":\"Inf. Fusion\",\"year\":2020},{\"arxivId\":\"2011.04779\",\"authors\":[{\"authorId\":\"120533531\",\"name\":\"M. Belaid\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3da0d3c35ea8994f4a538bc9ddae0abb07283242\",\"title\":\"After All, Only The Last Neuron Matters: Comparing Multi-modal Fusion Functions for Scene Graph Generation\",\"url\":\"https://www.semanticscholar.org/paper/3da0d3c35ea8994f4a538bc9ddae0abb07283242\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"7595427\",\"name\":\"Tejas Khot\"},{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1007/s11263-018-1116-0\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7e232313a59d735ef7c8a9f4cc7bc980a29deb5e\",\"title\":\"Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7e232313a59d735ef7c8a9f4cc7bc980a29deb5e\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018},{\"arxivId\":\"1812.01922\",\"authors\":[{\"authorId\":\"48379459\",\"name\":\"Y. Zhang\"},{\"authorId\":\"39578749\",\"name\":\"Siyu Tang\"},{\"authorId\":\"2276351\",\"name\":\"Krikamol Muandet\"},{\"authorId\":\"7595315\",\"name\":\"Christian Jarvers\"},{\"authorId\":\"144718494\",\"name\":\"H. Neumann\"}],\"doi\":\"10.1109/CVPR.2019.01228\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"428934f26e240aadeec86b40b23182455fb25c1a\",\"title\":\"Local Temporal Bilinear Pooling for Fine-Grained Action Parsing\",\"url\":\"https://www.semanticscholar.org/paper/428934f26e240aadeec86b40b23182455fb25c1a\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50974488\",\"name\":\"Mingrui Lao\"},{\"authorId\":\"49813983\",\"name\":\"Yanming Guo\"},{\"authorId\":\"49528566\",\"name\":\"Hui Wang\"},{\"authorId\":\"35742440\",\"name\":\"X. Zhang\"}],\"doi\":\"10.1109/ACCESS.2018.2844789\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2609626519d8fa0ccc53bce49a3a21b928deeca6\",\"title\":\"Cross-Modal Multistep Fusion Network With Co-Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2609626519d8fa0ccc53bce49a3a21b928deeca6\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":\"2004.12070\",\"authors\":[{\"authorId\":\"1564034697\",\"name\":\"Zhou Yu\"},{\"authorId\":\"30513139\",\"name\":\"Yuhao Cui\"},{\"authorId\":null,\"name\":\"Jun Yu\"},{\"authorId\":\"152808542\",\"name\":\"Meng Wang\"},{\"authorId\":\"1490934465\",\"name\":\"Dacheng Tao\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1145/3394171.3413977\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f40ed567148f724028952e5fe20a34a0b671dd2e\",\"title\":\"Deep Multimodal Neural Architecture Search\",\"url\":\"https://www.semanticscholar.org/paper/f40ed567148f724028952e5fe20a34a0b671dd2e\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2006.06195\",\"authors\":[{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"50580345\",\"name\":\"Yen-Chun Chen\"},{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"1431754650\",\"name\":\"C. Zhu\"},{\"authorId\":\"5524736\",\"name\":\"Y. Cheng\"},{\"authorId\":\"46700348\",\"name\":\"Jing-jing Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8dc49a2041a8a269fbf64911a4f2c8cef6738a5c\",\"title\":\"Large-Scale Adversarial Training for Vision-and-Language Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/8dc49a2041a8a269fbf64911a4f2c8cef6738a5c\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"1909.10128\",\"authors\":[{\"authorId\":\"2826839\",\"name\":\"Qingxing Cao\"},{\"authorId\":\"51473867\",\"name\":\"Bailin Li\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"49478124\",\"name\":\"L. Lin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4cede1c63336de84344922876e6ee23617e2afb3\",\"title\":\"Explainable High-order Visual Question Reasoning: A New Benchmark and Knowledge-routed Network\",\"url\":\"https://www.semanticscholar.org/paper/4cede1c63336de84344922876e6ee23617e2afb3\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144866446\",\"name\":\"Feng Cheng\"},{\"authorId\":\"2453151\",\"name\":\"Shi-Lin Wang\"},{\"authorId\":\"1733300\",\"name\":\"A. Liew\"}],\"doi\":\"10.1016/j.patcog.2018.06.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"df07f6696f7e1fd6a25e9ad8a9211fb343cea131\",\"title\":\"Visual speaker authentication with random prompt texts by a dual-task CNN framework\",\"url\":\"https://www.semanticscholar.org/paper/df07f6696f7e1fd6a25e9ad8a9211fb343cea131\",\"venue\":\"Pattern Recognit.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50498297\",\"name\":\"Liang Peng\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":\"2105743\",\"name\":\"Y. Bin\"},{\"authorId\":\"145833207\",\"name\":\"Ning Xie\"},{\"authorId\":\"144618699\",\"name\":\"F. Shen\"},{\"authorId\":\"50006507\",\"name\":\"Yanli Ji\"},{\"authorId\":\"47158869\",\"name\":\"Xing Xu\"}],\"doi\":\"10.1007/s11042-018-6389-3\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"713dd629c183056202f31c2a98e5e37e0d83efa4\",\"title\":\"Word-to-region attention network for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/713dd629c183056202f31c2a98e5e37e0d83efa4\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":\"1711.06370\",\"authors\":[{\"authorId\":\"3194022\",\"name\":\"Bohan Zhuang\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2018.00447\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"7299465d70181e423480fdb252aa2e28c18aa012\",\"title\":\"Parallel Attention: A Unified Framework for Visual Object Discovery Through Dialogs and Queries\",\"url\":\"https://www.semanticscholar.org/paper/7299465d70181e423480fdb252aa2e28c18aa012\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144326109\",\"name\":\"Q. Li\"},{\"authorId\":\"144914662\",\"name\":\"F. Xiao\"},{\"authorId\":\"143728443\",\"name\":\"Le An\"},{\"authorId\":\"2989422\",\"name\":\"Xianzhong Long\"},{\"authorId\":\"48305363\",\"name\":\"Xiaochuan Sun\"}],\"doi\":\"10.1145/3300938\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f49c6c3b864a3e66c7f0d70b43ab76176a8aeb44\",\"title\":\"Semantic Concept Network and Deep Walk-based Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f49c6c3b864a3e66c7f0d70b43ab76176a8aeb44\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"28964453\",\"name\":\"Van-Quang Nguyen\"},{\"authorId\":\"9114621\",\"name\":\"Masanori Suganuma\"},{\"authorId\":\"1718872\",\"name\":\"Takayuki Okatani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"fe05479dc4bf2698fcc4e29f09743f8eb1b0f9ec\",\"title\":\"Efficient Attention Mechanism for Handling All the Interactions between Many Inputs with Application to Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/fe05479dc4bf2698fcc4e29f09743f8eb1b0f9ec\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144544920\",\"name\":\"Fei Liu\"},{\"authorId\":\"1749850\",\"name\":\"J. Liu\"},{\"authorId\":\"48043335\",\"name\":\"R. Hong\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1145/3343031.3350993\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"6834deeabfbc3ca5989ca7a3bd76dc5a84c5a346\",\"title\":\"Erasing-based Attention Learning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/6834deeabfbc3ca5989ca7a3bd76dc5a84c5a346\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"2001.06354\",\"authors\":[{\"authorId\":\"51270689\",\"name\":\"Hyounghun Kim\"},{\"authorId\":\"47300698\",\"name\":\"Hao Tan\"},{\"authorId\":\"143977266\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.1609/AAAI.V34I05.6320\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0cad92e34323aa135d13d692c759246a8da54d05\",\"title\":\"Modality-Balanced Models for Visual Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/0cad92e34323aa135d13d692c759246a8da54d05\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2010.12852\",\"authors\":[{\"authorId\":\"34408936\",\"name\":\"R. Dua\"},{\"authorId\":\"2003624403\",\"name\":\"Sai Srinivas Kancheti\"},{\"authorId\":\"1699429\",\"name\":\"V. Balasubramanian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fc80d27ca291823fc0be464a736cf72dbb4ac191\",\"title\":\"Beyond VQA: Generating Multi-word Answer and Rationale to Visual Questions\",\"url\":\"https://www.semanticscholar.org/paper/fc80d27ca291823fc0be464a736cf72dbb4ac191\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.00145\",\"authors\":[{\"authorId\":\"119883573\",\"name\":\"J. Yu\"},{\"authorId\":\"49659134\",\"name\":\"Zihao Zhu\"},{\"authorId\":null,\"name\":\"Yujing Wang\"},{\"authorId\":\"1735739\",\"name\":\"Weifeng Zhang\"},{\"authorId\":\"1581498565\",\"name\":\"Yue Hu\"},{\"authorId\":\"2573626\",\"name\":\"Jianlong Tan\"}],\"doi\":\"10.1016/j.patcog.2020.107563\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e526624783b3b5687da54b8cd4a7190a26a0b5e8\",\"title\":\"Cross-modal Knowledge Reasoning for Knowledge-based Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e526624783b3b5687da54b8cd4a7190a26a0b5e8\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":\"1911.03977\",\"authors\":[{\"authorId\":\"145282222\",\"name\":\"C. Zhang\"},{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"144718783\",\"name\":\"Li Deng\"}],\"doi\":\"10.1109/JSTSP.2020.2987728\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"415efb7b4d9d1e5b64dbaf3fe4229ad462acce71\",\"title\":\"Multimodal Intelligence: Representation Learning, Information Fusion, and Applications\",\"url\":\"https://www.semanticscholar.org/paper/415efb7b4d9d1e5b64dbaf3fe4229ad462acce71\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020},{\"arxivId\":\"1808.00265\",\"authors\":[{\"authorId\":\"2373307\",\"name\":\"Y. Zhang\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"144106940\",\"name\":\"A. Soto\"}],\"doi\":\"10.1109/WACV.2019.00043\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b1b852d4bf934863397e7b965a5dd0124ad8670c\",\"title\":\"Interpretable Visual Question Answering by Visual Grounding From Attention Supervision Mining\",\"url\":\"https://www.semanticscholar.org/paper/b1b852d4bf934863397e7b965a5dd0124ad8670c\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145030935\",\"name\":\"H. Hu\"},{\"authorId\":\"51432978\",\"name\":\"Zhongke Liao\"},{\"authorId\":\"144653471\",\"name\":\"X. Xiao\"}],\"doi\":\"10.1007/s11063-018-9932-3\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5e64440c4088ae1b871fb3f6af8dd5c4e7dbe00a\",\"title\":\"Action Recognition Using Multiple Pooling Strategies of CNN Features\",\"url\":\"https://www.semanticscholar.org/paper/5e64440c4088ae1b871fb3f6af8dd5c4e7dbe00a\",\"venue\":\"Neural Processing Letters\",\"year\":2018},{\"arxivId\":\"1907.09815\",\"authors\":[{\"authorId\":\"145422343\",\"name\":\"Dalu Guo\"},{\"authorId\":\"145371954\",\"name\":\"Chang Xu\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"87b60156ac40e9b1f404e785cec7aa7b4365a489\",\"title\":\"Graph Reasoning Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/87b60156ac40e9b1f404e785cec7aa7b4365a489\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49741227\",\"name\":\"Haifeng Sang\"},{\"authorId\":\"1445362522\",\"name\":\"Zi-Zhen Chen\"},{\"authorId\":\"30877108\",\"name\":\"Da-Kuo He\"}],\"doi\":\"10.1007/s11042-019-08269-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6c60676553c66cc506f9924278695addbaf91021\",\"title\":\"Human Motion prediction based on attention mechanism\",\"url\":\"https://www.semanticscholar.org/paper/6c60676553c66cc506f9924278695addbaf91021\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10405058\",\"name\":\"Chenfei Wu\"},{\"authorId\":\"46700331\",\"name\":\"J. Liu\"},{\"authorId\":\"1680068\",\"name\":\"X. Wang\"},{\"authorId\":\"143672034\",\"name\":\"X. Dong\"}],\"doi\":\"10.1145/3240508.3240513\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"34c9753893fe4713568542e7d96dc9a9e6545ec8\",\"title\":\"Object-Difference Attention: A Simple Relational Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/34c9753893fe4713568542e7d96dc9a9e6545ec8\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1803.05268\",\"authors\":[{\"authorId\":\"3296335\",\"name\":\"D. Mascharka\"},{\"authorId\":\"46450184\",\"name\":\"Philip Tran\"},{\"authorId\":\"49902902\",\"name\":\"Ryan Soklaski\"},{\"authorId\":\"2905057\",\"name\":\"A. Majumdar\"}],\"doi\":\"10.1109/CVPR.2018.00519\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cd0a7c58964905ccfddbad1614165320ccc56393\",\"title\":\"Transparency by Design: Closing the Gap Between Performance and Interpretability in Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/cd0a7c58964905ccfddbad1614165320ccc56393\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1902.09774\",\"authors\":[{\"authorId\":\"145422343\",\"name\":\"Dalu Guo\"},{\"authorId\":\"48258751\",\"name\":\"Chang Xu\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/CVPR.2019.01068\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e5eb953608ab5eb95dd054a44980b5258fd7b8d7\",\"title\":\"Image-Question-Answer Synergistic Network for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/e5eb953608ab5eb95dd054a44980b5258fd7b8d7\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1911.04058\",\"authors\":[{\"authorId\":\"48615049\",\"name\":\"Y. Xu\"},{\"authorId\":\"46308159\",\"name\":\"L. Chen\"},{\"authorId\":\"120235436\",\"name\":\"Zhongwei Cheng\"},{\"authorId\":\"71138167\",\"name\":\"Lixin Duan\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.34\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2fdcc61d9a02412f5eb5d596ee41c8504a83c20a\",\"title\":\"Open-Ended Visual Question Answering by Multi-Modal Domain Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/2fdcc61d9a02412f5eb5d596ee41c8504a83c20a\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2010.14095\",\"authors\":[{\"authorId\":\"25263842\",\"name\":\"Aisha Urooj Khan\"},{\"authorId\":\"144839067\",\"name\":\"Amir Mazaheri\"},{\"authorId\":\"1700665\",\"name\":\"N. Lobo\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.417\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bf8a0cda4f26c889d1b6d16fe070fa3d907a8686\",\"title\":\"MMFT-BERT: Multimodal Fusion Transformer with BERT Encodings for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/bf8a0cda4f26c889d1b6d16fe070fa3d907a8686\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47860328\",\"name\":\"Shagun Uppal\"},{\"authorId\":\"73368394\",\"name\":\"Sarthak Bhagat\"},{\"authorId\":\"8223433\",\"name\":\"Devamanyu Hazarika\"},{\"authorId\":\"1999177921\",\"name\":\"Navonil Majumdar\"},{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"153015119\",\"name\":\"R. Zimmermann\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0f23b548ff7b3517f028164a30c8bf186f11a1a6\",\"title\":\"Emerging Trends of Multimodal Research in Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/0f23b548ff7b3517f028164a30c8bf186f11a1a6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1909.11874\",\"authors\":[{\"authorId\":\"52220768\",\"name\":\"T. Do\"},{\"authorId\":\"3354627\",\"name\":\"Thanh-Toan Do\"},{\"authorId\":\"134083550\",\"name\":\"Huy Tran\"},{\"authorId\":\"1387964524\",\"name\":\"Erman Tjiputra\"},{\"authorId\":\"20135953\",\"name\":\"Q. D. Tran\"}],\"doi\":\"10.1109/ICCV.2019.00048\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"27cb0b42e0573c4891ae2ca444776dee57bfe2ac\",\"title\":\"Compact Trilinear Interaction for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/27cb0b42e0573c4891ae2ca444776dee57bfe2ac\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1811.12104\",\"authors\":[{\"authorId\":\"40912088\",\"name\":\"M. Tanaka\"},{\"authorId\":\"51491153\",\"name\":\"Takayuki Itamochi\"},{\"authorId\":\"3193466\",\"name\":\"K. Narioka\"},{\"authorId\":\"143973868\",\"name\":\"Ikuro Sato\"},{\"authorId\":\"3250559\",\"name\":\"Y. Ushiku\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3c5907ba6b921841a49e77632c14db64e4db4fd4\",\"title\":\"Towards Human-Friendly Referring Expression Generation\",\"url\":\"https://www.semanticscholar.org/paper/3c5907ba6b921841a49e77632c14db64e4db4fd4\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1907.00661\",\"authors\":[{\"authorId\":\"32185652\",\"name\":\"Yusuke Yamaura\"},{\"authorId\":\"150246288\",\"name\":\"Nobuya Kanemaki\"},{\"authorId\":\"3184895\",\"name\":\"Yukihiro Tsuboshita\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"75952cb7d5945d001d0758a994eb8017ddca3733\",\"title\":\"The Resale Price Prediction of Secondhand Jewelry Items Using a Multi-modal Deep Model with Iterative Co-Attention\",\"url\":\"https://www.semanticscholar.org/paper/75952cb7d5945d001d0758a994eb8017ddca3733\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145147427\",\"name\":\"T. Song\"},{\"authorId\":\"46538836\",\"name\":\"Shanchen Pang\"},{\"authorId\":\"1406117303\",\"name\":\"Shaohua Hao\"},{\"authorId\":\"1397793046\",\"name\":\"A. Rodr\\u00edguez-Pat\\u00f3n\"},{\"authorId\":\"46699610\",\"name\":\"Pan Zheng\"}],\"doi\":\"10.1007/s11063-018-9947-9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dc16b53b3fff974fa2878bf024012d51b26ce9cf\",\"title\":\"A Parallel Image Skeletonizing Method Using Spiking Neural P Systems with Weights\",\"url\":\"https://www.semanticscholar.org/paper/dc16b53b3fff974fa2878bf024012d51b26ce9cf\",\"venue\":\"Neural Processing Letters\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40069761\",\"name\":\"Auston Sterling\"},{\"authorId\":\"46939093\",\"name\":\"J. Wilson\"},{\"authorId\":\"40623145\",\"name\":\"S. Lowe\"},{\"authorId\":\"144247566\",\"name\":\"M. Lin\"}],\"doi\":\"10.1007/978-3-030-01267-0_34\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"4d95d29db6778c6a2c6c6415f22814864348708e\",\"title\":\"ISNN: Impact Sound Neural Network for Audio-Visual Object Classification\",\"url\":\"https://www.semanticscholar.org/paper/4d95d29db6778c6a2c6c6415f22814864348708e\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50974488\",\"name\":\"Mingrui Lao\"},{\"authorId\":\"49813983\",\"name\":\"Yanming Guo\"},{\"authorId\":\"49528566\",\"name\":\"Hui Wang\"},{\"authorId\":\"145863022\",\"name\":\"X. Zhang\"}],\"doi\":\"10.20944/PREPRINTS201804.0313.V1\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2329335263b2911a05c36c8c3747d9ee96eb6fee\",\"title\":\"Cross-Modal Multistep Fusion Network With Co-Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2329335263b2911a05c36c8c3747d9ee96eb6fee\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1576818877\",\"name\":\"Kento Terao\"},{\"authorId\":\"134811419\",\"name\":\"Toru Tamaki\"},{\"authorId\":\"1688940\",\"name\":\"B. Raytchev\"},{\"authorId\":\"1686272\",\"name\":\"K. Kaneda\"},{\"authorId\":\"144404414\",\"name\":\"S. Satoh\"}],\"doi\":\"10.1109/ACCESS.2020.3022063\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c7583d58aec662313bd5b0082b656d9f44956dc3\",\"title\":\"An Entropy Clustering Approach for Assessing Visual Question Difficulty\",\"url\":\"https://www.semanticscholar.org/paper/c7583d58aec662313bd5b0082b656d9f44956dc3\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9359529\",\"name\":\"K. Wang\"},{\"authorId\":\"46522414\",\"name\":\"Xiaohong Liu\"},{\"authorId\":\"145574468\",\"name\":\"Kang Zhang\"},{\"authorId\":\"145669910\",\"name\":\"Ting Chen\"},{\"authorId\":\"144922248\",\"name\":\"G. Wang\"}],\"doi\":\"10.1007/978-3-030-59722-1_63\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"da651cb2ce932a9459146bbd3e9920492721e86e\",\"title\":\"Anterior Segment Eye Lesion Segmentation with Advanced Fusion Strategies and Auxiliary Tasks\",\"url\":\"https://www.semanticscholar.org/paper/da651cb2ce932a9459146bbd3e9920492721e86e\",\"venue\":\"MICCAI\",\"year\":2020},{\"arxivId\":\"2010.11562\",\"authors\":[{\"authorId\":\"25703683\",\"name\":\"Amit Gajbhiye\"},{\"authorId\":\"14358891\",\"name\":\"T. Winterbottom\"},{\"authorId\":\"1711819\",\"name\":\"Noura Al Moubayed\"},{\"authorId\":\"47090732\",\"name\":\"stacey. bradley\"}],\"doi\":\"10.1007/978-3-030-61609-0_50\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2c6e654fd91526557c07a10b53b5a5850c26c6a4\",\"title\":\"Bilinear Fusion of Commonsense Knowledge with Attention-Based NLI Models\",\"url\":\"https://www.semanticscholar.org/paper/2c6e654fd91526557c07a10b53b5a5850c26c6a4\",\"venue\":\"ICANN\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51228129\",\"name\":\"Shailza Jolly\"},{\"authorId\":\"7413674\",\"name\":\"S. Kapoor\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.257\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"683b1230f53eddb0c03f4ad656579269eae2227d\",\"title\":\"Can Pre-training help VQA with Lexical Variations?\",\"url\":\"https://www.semanticscholar.org/paper/683b1230f53eddb0c03f4ad656579269eae2227d\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49597404\",\"name\":\"Z. Fang\"},{\"authorId\":\"46700426\",\"name\":\"J. Liu\"},{\"authorId\":\"47003032\",\"name\":\"Y. Li\"},{\"authorId\":\"80526284\",\"name\":\"Yanyuan Qiao\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1016/J.PATCOG.2019.01.038\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aa31126aa9dc7665bf236a51c6de31c4bf6c59ad\",\"title\":\"Improving visual question answering using dropout and enhanced question encoder\",\"url\":\"https://www.semanticscholar.org/paper/aa31126aa9dc7665bf236a51c6de31c4bf6c59ad\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":\"2010.13357\",\"authors\":[{\"authorId\":\"1557275666\",\"name\":\"Haibo Su\"},{\"authorId\":\"1490938689\",\"name\":\"Peng Wang\"},{\"authorId\":\"47968029\",\"name\":\"Lingqiao Liu\"},{\"authorId\":null,\"name\":\"Hui Li\"},{\"authorId\":\"49969637\",\"name\":\"Zhuguo Li\"},{\"authorId\":\"48379046\",\"name\":\"Y. Zhang\"}],\"doi\":\"10.1109/tcsvt.2020.3034981\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"90d79a5c01026e700e62f0f7f8182c1744eab1e3\",\"title\":\"Where to Look and How to Describe: Fashion Image Retrieval with an Attentional Heterogeneous Bilinear Network\",\"url\":\"https://www.semanticscholar.org/paper/90d79a5c01026e700e62f0f7f8182c1744eab1e3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2125211\",\"name\":\"Yueting Zhuang\"},{\"authorId\":\"50854337\",\"name\":\"D. Xu\"},{\"authorId\":\"1491414917\",\"name\":\"Xin Yan\"},{\"authorId\":\"4004957\",\"name\":\"W. Cheng\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"},{\"authorId\":\"1384523745\",\"name\":\"Jun Xiao\"}],\"doi\":\"10.1145/3366710\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"26997b5e761bfa0f98331e297b6e9518fef3ece1\",\"title\":\"Multichannel Attention Refinement for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/26997b5e761bfa0f98331e297b6e9518fef3ece1\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152553572\",\"name\":\"Huan Shao\"},{\"authorId\":\"1965723\",\"name\":\"Y. Xu\"},{\"authorId\":\"144602988\",\"name\":\"Yi Ji\"},{\"authorId\":\"7788280\",\"name\":\"J. Yang\"},{\"authorId\":\"47535378\",\"name\":\"Chunping Liu\"}],\"doi\":\"10.1007/978-3-030-36802-9_24\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f21cba46085eba47b299fbff283515284bed7189\",\"title\":\"Intra-Modality Feature Interaction Using Self-attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f21cba46085eba47b299fbff283515284bed7189\",\"venue\":\"ICONIP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153432556\",\"name\":\"Y. Xie\"},{\"authorId\":\"6782471\",\"name\":\"Y. Liu\"},{\"authorId\":\"1777567\",\"name\":\"Yangtao Wang\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"1490938689\",\"name\":\"Peng Wang\"},{\"authorId\":\"143904274\",\"name\":\"Ke Zhou\"}],\"doi\":\"10.24963/ijcai.2020/133\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"47cacfca0187fc5574375d08151d6c429653e6b8\",\"title\":\"Label-Attended Hashing for Multi-Label Image Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/47cacfca0187fc5574375d08151d6c429653e6b8\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145986708\",\"name\":\"Bo Sun\"},{\"authorId\":\"14701865\",\"name\":\"Z. Yao\"},{\"authorId\":\"48380350\",\"name\":\"Yinghui Zhang\"},{\"authorId\":\"8834504\",\"name\":\"Lejun Yu\"}],\"doi\":\"10.1016/j.jvcir.2020.102762\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"86475be7965eebb5edba838788d26c9272f14a3b\",\"title\":\"Local relation network with multilevel attention for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/86475be7965eebb5edba838788d26c9272f14a3b\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6175623\",\"name\":\"Shijie Hao\"},{\"authorId\":\"8280010\",\"name\":\"Yanrong Guo\"},{\"authorId\":\"50412542\",\"name\":\"Zhongliang Wei\"}],\"doi\":\"10.1007/s11042-018-6257-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a9ec70d0d40cd0bdaf762853fff8f2ffa1af6359\",\"title\":\"Lightness-aware contrast enhancement for images with different illumination conditions\",\"url\":\"https://www.semanticscholar.org/paper/a9ec70d0d40cd0bdaf762853fff8f2ffa1af6359\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":\"1804.00775\",\"authors\":[{\"authorId\":\"41022273\",\"name\":\"Duy-Kien Nguyen\"},{\"authorId\":\"1718872\",\"name\":\"Takayuki Okatani\"}],\"doi\":\"10.1109/CVPR.2018.00637\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"f7cc85bed2a3d0b0ef1c0e0258f5b60ee4bb4622\",\"title\":\"Improved Fusion of Visual and Language Representations by Dense Symmetric Co-attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f7cc85bed2a3d0b0ef1c0e0258f5b60ee4bb4622\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36053954\",\"name\":\"Philipp Harzig\"},{\"authorId\":\"1832927\",\"name\":\"C. Eggert\"},{\"authorId\":\"144739319\",\"name\":\"R. Lienhart\"}],\"doi\":\"10.1145/3206025.3206054\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ec21434615f72267d26d8e2d8cb7671561d26fc6\",\"title\":\"Visual Question Answering With a Hybrid Convolution Recurrent Model\",\"url\":\"https://www.semanticscholar.org/paper/ec21434615f72267d26d8e2d8cb7671561d26fc6\",\"venue\":\"ICMR\",\"year\":2018},{\"arxivId\":\"1905.07841\",\"authors\":[{\"authorId\":\"9919436\",\"name\":\"J. Yu\"},{\"authorId\":\"31115234\",\"name\":\"Jing Li\"},{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"},{\"authorId\":\"1689702\",\"name\":\"Q. Huang\"}],\"doi\":\"10.1109/TCSVT.2019.2947482\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"99b5153235b0ee583803bbd7cd6bd9da161d5348\",\"title\":\"Multimodal Transformer With Multi-View Visual Representation for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/99b5153235b0ee583803bbd7cd6bd9da161d5348\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2929047\",\"name\":\"F. Liu\"},{\"authorId\":\"51173122\",\"name\":\"Yalei Peng\"},{\"authorId\":\"6898369\",\"name\":\"M. P. Rosen\"}],\"doi\":\"10.1007/978-3-030-28577-7_20\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1a4d0c6583fa1c0005be1eb76c9ba8d943744bca\",\"title\":\"An Effective Deep Transfer Learning and Information Fusion Framework for Medical Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1a4d0c6583fa1c0005be1eb76c9ba8d943744bca\",\"venue\":\"CLEF\",\"year\":2019},{\"arxivId\":\"2012.07192\",\"authors\":[{\"authorId\":\"2826839\",\"name\":\"Qingxing Cao\"},{\"authorId\":\"51473867\",\"name\":\"Bailin Li\"},{\"authorId\":\"13246332\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"3170394\",\"name\":\"Keze Wang\"},{\"authorId\":\"1737218\",\"name\":\"L. Lin\"}],\"doi\":\"10.1109/TNNLS.2020.3045034\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e452c1aa68173d6a1d3aefd9f08f70e43b0c59f4\",\"title\":\"Knowledge-Routed Visual Question Reasoning: Challenges for Deep Representation Embedding\",\"url\":\"https://www.semanticscholar.org/paper/e452c1aa68173d6a1d3aefd9f08f70e43b0c59f4\",\"venue\":\"IEEE transactions on neural networks and learning systems\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2643877\",\"name\":\"Y. Bai\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"145382463\",\"name\":\"T. Zhao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1007/978-3-030-01258-8_2\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"380d50f3ccc07fa4f41282395a78c51e33985c39\",\"title\":\"Deep Attention Neural Tensor Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/380d50f3ccc07fa4f41282395a78c51e33985c39\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"119063073\",\"name\":\"Francisco Villarroel Ordenes\"},{\"authorId\":\"7670841\",\"name\":\"Shunyuan Zhang\"}],\"doi\":\"10.1108/josm-08-2019-0254\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e2895a3d064dd4f7beb1c5f524cae8ea31953aaf\",\"title\":\"From words to pixels: text and image mining methods for service research\",\"url\":\"https://www.semanticscholar.org/paper/e2895a3d064dd4f7beb1c5f524cae8ea31953aaf\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48352212\",\"name\":\"Aming Wu\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"},{\"authorId\":\"20332986\",\"name\":\"Q. Hu\"},{\"authorId\":\"144894837\",\"name\":\"F. Wu\"}],\"doi\":\"10.1109/TCSVT.2019.2956593\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"230a8581672b3147238eaab2cf686c70fe4f672b\",\"title\":\"Convolutional Reconstruction-to-Sequence for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/230a8581672b3147238eaab2cf686c70fe4f672b\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"1911.00212\",\"authors\":[{\"authorId\":\"48028411\",\"name\":\"T. Jin\"},{\"authorId\":\"48669017\",\"name\":\"Siyu Huang\"},{\"authorId\":\"2367491\",\"name\":\"Y. Li\"},{\"authorId\":\"9338907\",\"name\":\"Z. Zhang\"}],\"doi\":\"10.18653/v1/D19-1207\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"55f546209c01530a7717d4170aa24947c6b92775\",\"title\":\"Low-Rank HOCA: Efficient High-Order Cross-Modal Attention for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/55f546209c01530a7717d4170aa24947c6b92775\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"1912.00835\",\"authors\":[{\"authorId\":\"20402239\",\"name\":\"Sneha Mehta\"},{\"authorId\":\"145344187\",\"name\":\"H. Rangwala\"},{\"authorId\":\"26206130\",\"name\":\"N. Ramakrishnan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"be7378bfae209e91689e707814568da1d9c190a9\",\"title\":\"Low Rank Factorization for Compact Multi-Head Self-Attention\",\"url\":\"https://www.semanticscholar.org/paper/be7378bfae209e91689e707814568da1d9c190a9\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1905.04877\",\"authors\":[{\"authorId\":\"30921555\",\"name\":\"Yangyang Guo\"},{\"authorId\":\"13167100\",\"name\":\"Zhiyong Cheng\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":\"35435925\",\"name\":\"Y. Liu\"},{\"authorId\":\"49417788\",\"name\":\"Yinglong Wang\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":\"10.1145/3331184.3331186\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d00fe8d117a3849d3085d4301d91c56b775ee8b1\",\"title\":\"Quantifying and Alleviating the Language Prior Problem in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d00fe8d117a3849d3085d4301d91c56b775ee8b1\",\"venue\":\"SIGIR\",\"year\":2019},{\"arxivId\":\"2005.06514\",\"authors\":[{\"authorId\":\"8665428\",\"name\":\"Shan Jia\"},{\"authorId\":\"3223020\",\"name\":\"X. Li\"},{\"authorId\":\"2622256\",\"name\":\"Chuanbo Hu\"},{\"authorId\":\"1822413\",\"name\":\"Guodong Guo\"},{\"authorId\":\"1795971\",\"name\":\"Zhengquan Xu\"}],\"doi\":\"10.1109/tcsvt.2020.3044986\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"58c52263f9d8002da85f83df79014c099e099a3c\",\"title\":\"3D Face Anti-spoofing with Factorized Bilinear Coding\",\"url\":\"https://www.semanticscholar.org/paper/58c52263f9d8002da85f83df79014c099e099a3c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.10858\",\"authors\":[{\"authorId\":\"28958635\",\"name\":\"Saadullah Amin\"},{\"authorId\":\"3383477\",\"name\":\"Stalin Varanasi\"},{\"authorId\":\"151072380\",\"name\":\"K. Dunfield\"},{\"authorId\":\"71531491\",\"name\":\"G. Neumann\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0126fce30b412d583f8e33714908dd09b86293d1\",\"title\":\"LowFER: Low-rank Bilinear Pooling for Link Prediction\",\"url\":\"https://www.semanticscholar.org/paper/0126fce30b412d583f8e33714908dd09b86293d1\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":\"2001.06206\",\"authors\":[{\"authorId\":\"9628638\",\"name\":\"Yun-Wei Chu\"},{\"authorId\":\"152923110\",\"name\":\"Kuan-Yen Lin\"},{\"authorId\":\"23608432\",\"name\":\"Chao-Chun Hsu\"},{\"authorId\":\"1746959\",\"name\":\"Lun-Wei Ku\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e885f1523349be48c884a4663d705487fde05b8a\",\"title\":\"Multi-step Joint-Modality Attention Network for Scene-Aware Dialogue System\",\"url\":\"https://www.semanticscholar.org/paper/e885f1523349be48c884a4663d705487fde05b8a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.06800\",\"authors\":[{\"authorId\":\"9208016\",\"name\":\"Aakansha Mishra\"},{\"authorId\":\"47583423\",\"name\":\"A. Anand\"},{\"authorId\":\"46401518\",\"name\":\"Prithwijit Guha\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206913\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"212c2d71f9f404bcbb3cfe8bc35e5e1ea25076c5\",\"title\":\"CQ-VQA: Visual Question Answering on Categorized Questions\",\"url\":\"https://www.semanticscholar.org/paper/212c2d71f9f404bcbb3cfe8bc35e5e1ea25076c5\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":\"1908.10155\",\"authors\":[{\"authorId\":\"151472652\",\"name\":\"Yuqi Huo\"},{\"authorId\":\"101246507\",\"name\":\"Xiaoli Xu\"},{\"authorId\":\"145525059\",\"name\":\"Yao Lu\"},{\"authorId\":\"2520427\",\"name\":\"Yulei Niu\"},{\"authorId\":\"1776220\",\"name\":\"Zhiwu Lu\"},{\"authorId\":\"153693432\",\"name\":\"Jirong Wen\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"16c8f1d316e0235d20a60cae8fb9f5f83e35574c\",\"title\":\"Mobile Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/16c8f1d316e0235d20a60cae8fb9f5f83e35574c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46961137\",\"name\":\"Chen Cui\"},{\"authorId\":\"49336556\",\"name\":\"Wenjie Wang\"},{\"authorId\":\"33977299\",\"name\":\"X. Song\"},{\"authorId\":\"1730108\",\"name\":\"Minlie Huang\"},{\"authorId\":\"40620796\",\"name\":\"Xin-Shun Xu\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"}],\"doi\":\"10.1145/3331184.3331226\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"e92a32c45ccc0c933553d6f28b3551f0293bcd20\",\"title\":\"User Attention-guided Multimodal Dialog Systems\",\"url\":\"https://www.semanticscholar.org/paper/e92a32c45ccc0c933553d6f28b3551f0293bcd20\",\"venue\":\"SIGIR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1741390809\",\"name\":\"Weidong Tian\"},{\"authorId\":\"1657469716\",\"name\":\"Rencai Zhou\"},{\"authorId\":\"151481257\",\"name\":\"Zhong-Qiu Zhao\"}],\"doi\":\"10.1109/IJCNN48605.2020.9207390\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"0ff3ccd867a94b77f519e73cf2de9772aa8ae905\",\"title\":\"Cascading Top-Down Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0ff3ccd867a94b77f519e73cf2de9772aa8ae905\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1734904\",\"name\":\"Asif Ekbal\"}],\"doi\":\"10.1007/s40012-020-00304-5\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6f302691678e3c1a7c6ef1b7c808132cdbd1fe26\",\"title\":\"Towards building an affect-aware dialogue agent with deep neural networks\",\"url\":\"https://www.semanticscholar.org/paper/6f302691678e3c1a7c6ef1b7c808132cdbd1fe26\",\"venue\":\"CSI Transactions on ICT\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9024867\",\"name\":\"Jongkwang Hong\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"2847986\",\"name\":\"Youngjung Uh\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"144036125\",\"name\":\"H. Byun\"}],\"doi\":\"10.1016/J.NEUCOM.2019.03.035\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b09f952de35e1ce98b01e14c2be036430ecace43\",\"title\":\"Exploiting hierarchical visual features for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/b09f952de35e1ce98b01e14c2be036430ecace43\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49597404\",\"name\":\"Z. Fang\"},{\"authorId\":null,\"name\":\"Jing Liu\"},{\"authorId\":\"80526284\",\"name\":\"Yanyuan Qiao\"},{\"authorId\":null,\"name\":\"Qu Tang\"},{\"authorId\":\"47002702\",\"name\":\"Y. Li\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1145/3240508.3240662\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a1f1a06b840558c4433f0e06a4e9172539469e21\",\"title\":\"Enhancing Visual Question Answering Using Dropout\",\"url\":\"https://www.semanticscholar.org/paper/a1f1a06b840558c4433f0e06a4e9172539469e21\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1802.00209\",\"authors\":[{\"authorId\":\"143757036\",\"name\":\"Ahmed Osman\"},{\"authorId\":\"1699054\",\"name\":\"W. Samek\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7b66dababebd800e95d23a1fde299d44a52e98ed\",\"title\":\"Dual Recurrent Attention Units for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7b66dababebd800e95d23a1fde299d44a52e98ed\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8889792\",\"name\":\"Jihun Choi\"},{\"authorId\":\"5041757\",\"name\":\"Taeuk Kim\"},{\"authorId\":\"1734101\",\"name\":\"S. Lee\"}],\"doi\":\"10.18653/v1/S18-2012\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"cb94ea16f12bde2de91d3cf3fac03a20b02611b1\",\"title\":\"Element-wise Bilinear Interaction for Sentence Matching\",\"url\":\"https://www.semanticscholar.org/paper/cb94ea16f12bde2de91d3cf3fac03a20b02611b1\",\"venue\":\"*SEM@NAACL-HLT\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2203994\",\"name\":\"Tengfei Xing\"},{\"authorId\":\"50218964\",\"name\":\"Zhaohui Wang\"},{\"authorId\":\"7788280\",\"name\":\"J. Yang\"},{\"authorId\":\"144602988\",\"name\":\"Yi Ji\"},{\"authorId\":\"6681872\",\"name\":\"Chunping Liu\"}],\"doi\":\"10.1007/978-3-030-00764-5_68\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2147e0ef8507e1a4880a916e46c27e15c11d65f4\",\"title\":\"Text to Region: Visual-Word Guided Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/2147e0ef8507e1a4880a916e46c27e15c11d65f4\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152924581\",\"name\":\"Jicheng Wang\"},{\"authorId\":\"51288875\",\"name\":\"Y. Zhou\"},{\"authorId\":\"1438588470\",\"name\":\"Zhenzhen Hu\"},{\"authorId\":\"47957556\",\"name\":\"X. Zhang\"},{\"authorId\":\"31048669\",\"name\":\"M. Wang\"}],\"doi\":\"10.1007/s11042-019-08439-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0c48de74a40736498d6443f84ecdddc08275359f\",\"title\":\"Sequential image encoding for vision-to-language problems\",\"url\":\"https://www.semanticscholar.org/paper/0c48de74a40736498d6443f84ecdddc08275359f\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46700331\",\"name\":\"J. Liu\"},{\"authorId\":\"10405058\",\"name\":\"Chenfei Wu\"},{\"authorId\":\"39527132\",\"name\":\"Xiaojie Wang\"},{\"authorId\":\"143672034\",\"name\":\"X. Dong\"}],\"doi\":\"10.1109/CCIS.2018.8691361\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e074ccab7b7c46b48d643c1026e71e563878885f\",\"title\":\"Sequential Visual Reasoning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e074ccab7b7c46b48d643c1026e71e563878885f\",\"venue\":\"2018 5th IEEE International Conference on Cloud Computing and Intelligence Systems (CCIS)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144952644\",\"name\":\"D. Y. Choi\"},{\"authorId\":\"1687433\",\"name\":\"Deok-Hwan Kim\"},{\"authorId\":\"10774886\",\"name\":\"B. Song\"}],\"doi\":\"10.1109/ACCESS.2020.3036877\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"29af086d2a9e80b5528c55e6e99c63364a7281e1\",\"title\":\"Multimodal Attention Network for Continuous-Time Emotion Recognition Using Video and EEG Signals\",\"url\":\"https://www.semanticscholar.org/paper/29af086d2a9e80b5528c55e6e99c63364a7281e1\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1911.04192\",\"authors\":[{\"authorId\":\"29068663\",\"name\":\"Ruize Wang\"},{\"authorId\":\"2712533\",\"name\":\"Zhongyu Wei\"},{\"authorId\":\"2193560\",\"name\":\"Piji Li\"},{\"authorId\":\"5006870\",\"name\":\"Haijun Shan\"},{\"authorId\":\"24263694\",\"name\":\"J. Zhang\"},{\"authorId\":\"1409702669\",\"name\":\"Qi Zhang\"},{\"authorId\":\"144052385\",\"name\":\"X. Huang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6c87e0cc7234d9a5fb2a33b8203d7d68c3d85d1d\",\"title\":\"Keep it Consistent: Topic-Aware Storytelling from an Image Stream via Iterative Multi-agent Communication\",\"url\":\"https://www.semanticscholar.org/paper/6c87e0cc7234d9a5fb2a33b8203d7d68c3d85d1d\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2673176\",\"name\":\"M. Alizadeh\"},{\"authorId\":\"66658845\",\"name\":\"B. D. Eugenio\"}],\"doi\":\"10.1142/S1793351X20400085\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eca1e3a8ecfd39026d3f7de4717ad0429d406602\",\"title\":\"Incorporating Verb Semantic Information in Visual Question Answering Through Multitask Learning Paradigm\",\"url\":\"https://www.semanticscholar.org/paper/eca1e3a8ecfd39026d3f7de4717ad0429d406602\",\"venue\":\"Int. J. Semantic Comput.\",\"year\":2020},{\"arxivId\":\"2007.14419\",\"authors\":[{\"authorId\":\"94011352\",\"name\":\"S. Chen\"},{\"authorId\":\"1405907659\",\"name\":\"Ming Jiang\"},{\"authorId\":\"7788087\",\"name\":\"J. Yang\"},{\"authorId\":\"153386875\",\"name\":\"Q. Zhao\"}],\"doi\":\"10.1007/978-3-030-58452-8_6\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"96150d2fdbb72e11882ad06b346d6e0d2e819d51\",\"title\":\"AiR: Attention with Reasoning Capability\",\"url\":\"https://www.semanticscholar.org/paper/96150d2fdbb72e11882ad06b346d6e0d2e819d51\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2144284\",\"name\":\"Tsung-Yu Lin\"}],\"doi\":\"10.7275/WSCA-M707\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b63b443885a5f2a54f58757481944f738d1e3092\",\"title\":\"Higher-Order Representations for Visual Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b63b443885a5f2a54f58757481944f738d1e3092\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1921879239\",\"name\":\"Shirong He\"},{\"authorId\":\"9100598\",\"name\":\"Dezhi Han\"}],\"doi\":\"10.3390/s20174897\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e52cae3e1df7ef76854645abf250db9282d01f27\",\"title\":\"An Effective Dense Co-Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e52cae3e1df7ef76854645abf250db9282d01f27\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"73312190\",\"name\":\"W. Zhang\"},{\"authorId\":\"1774936\",\"name\":\"Siliang Tang\"},{\"authorId\":\"3245182\",\"name\":\"Yanpeng Cao\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"},{\"authorId\":\"144894837\",\"name\":\"F. Wu\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1109/TMM.2019.2935678\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"8559c89a4df40ec6250cc8a04d1a5d5f3a84623e\",\"title\":\"Frame Augmented Alternating Attention Network for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8559c89a4df40ec6250cc8a04d1a5d5f3a84623e\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32482521\",\"name\":\"P. Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"00432309c1125d3b99d27c686f8da28ead6f7cf8\",\"title\":\"Towards Interpretable Vision Systems\",\"url\":\"https://www.semanticscholar.org/paper/00432309c1125d3b99d27c686f8da28ead6f7cf8\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1968780\",\"name\":\"Guiqing He\"},{\"authorId\":\"2638850\",\"name\":\"Siyuan Xing\"},{\"authorId\":\"1917901\",\"name\":\"Zhaoqiang Xia\"},{\"authorId\":\"47809594\",\"name\":\"Qingqing Huang\"},{\"authorId\":\"144147221\",\"name\":\"Jianping Fan\"}],\"doi\":\"10.1007/s00138-018-0964-5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f03f8912b0711c9f69f2154f988054d6acdd0f96\",\"title\":\"Panchromatic and multi-spectral image fusion for new satellites based on multi-channel deep model\",\"url\":\"https://www.semanticscholar.org/paper/f03f8912b0711c9f69f2154f988054d6acdd0f96\",\"venue\":\"Machine Vision and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33396604\",\"name\":\"N. Sankaran\"},{\"authorId\":\"1557796060\",\"name\":\"Deen Dayal Mohan\"},{\"authorId\":\"38941306\",\"name\":\"Nagashri N. Lakshminarayana\"},{\"authorId\":\"1800513\",\"name\":\"S. Setlur\"},{\"authorId\":\"1723877\",\"name\":\"V. Govindaraju\"}],\"doi\":\"10.1016/j.patcog.2019.107127\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2e3d507df0bb0f1e2dea14bb157e2f278e38a8ed\",\"title\":\"Domain adaptive representation learning for facial action unit recognition\",\"url\":\"https://www.semanticscholar.org/paper/2e3d507df0bb0f1e2dea14bb157e2f278e38a8ed\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":\"1809.01810\",\"authors\":[{\"authorId\":\"2826839\",\"name\":\"Qingxing Cao\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"46708631\",\"name\":\"Bailin Li\"},{\"authorId\":\"1737218\",\"name\":\"L. Lin\"}],\"doi\":\"10.1109/tpami.2019.2943456\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"97b93509f6c3c33dd3665d05b1878e36d58a1efb\",\"title\":\"Interpretable Visual Question Answering by Reasoning on Dependency Trees\",\"url\":\"https://www.semanticscholar.org/paper/97b93509f6c3c33dd3665d05b1878e36d58a1efb\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9852531\",\"name\":\"J. Lin\"},{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eefddfa610243968135726f9fddf4f69696863ed\",\"title\":\"TAB-VCR: Tags and Attributes based VCR Baselines\",\"url\":\"https://www.semanticscholar.org/paper/eefddfa610243968135726f9fddf4f69696863ed\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143757036\",\"name\":\"Ahmed Osman\"},{\"authorId\":\"1699054\",\"name\":\"W. Samek\"}],\"doi\":\"10.1016/j.cviu.2019.05.001\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"cb32b338023f9deb1eb2fb89d33784e12bdb5653\",\"title\":\"DRAU: Dual Recurrent Attention Units for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/cb32b338023f9deb1eb2fb89d33784e12bdb5653\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2019},{\"arxivId\":\"1808.02632\",\"authors\":[{\"authorId\":\"144579867\",\"name\":\"P. Gao\"},{\"authorId\":\"2887562\",\"name\":\"Pan Lu\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"88479495\",\"name\":\"S. Li\"},{\"authorId\":\"2180892\",\"name\":\"Yikang Li\"},{\"authorId\":\"1741126\",\"name\":\"S. Hoi\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1007/978-3-030-01246-5_29\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"391af839051826ec317a6ea61010734baf536551\",\"title\":\"Question-Guided Hybrid Convolution for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/391af839051826ec317a6ea61010734baf536551\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"119883573\",\"name\":\"J. Yu\"},{\"authorId\":\"49039449\",\"name\":\"Weifeng Zhang\"},{\"authorId\":\"7774960\",\"name\":\"Yuhang Lu\"},{\"authorId\":\"31055300\",\"name\":\"Zengchang Qin\"},{\"authorId\":\"1703234\",\"name\":\"Yue Hu\"},{\"authorId\":\"2573626\",\"name\":\"Jianlong Tan\"},{\"authorId\":\"49018095\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1109/TMM.2020.2972830\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9ebcac11090f3c5a7b987c668d91c3e5fec0718b\",\"title\":\"Reasoning on the Relation: Enhancing Visual Representation for Visual Question Answering and Cross-Modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/9ebcac11090f3c5a7b987c668d91c3e5fec0718b\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"2007.13262\",\"authors\":[{\"authorId\":\"39209233\",\"name\":\"Siwen Luo\"},{\"authorId\":\"2046142\",\"name\":\"S. Han\"},{\"authorId\":\"33053279\",\"name\":\"Kaiyuan Sun\"},{\"authorId\":\"48422087\",\"name\":\"Josiah Poon\"}],\"doi\":\"10.1007/978-3-030-63830-6_44\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5225c9ca12387634ad93d6ccc547f5b2347d88a3\",\"title\":\"REXUP: I REason, I EXtract, I UPdate with Structured Compositional Reasoning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/5225c9ca12387634ad93d6ccc547f5b2347d88a3\",\"venue\":\"ICONIP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1935044135\",\"name\":\"Wenbo Zheng\"},{\"authorId\":\"1935044135\",\"name\":\"Wenbo Zheng\"},{\"authorId\":\"151486225\",\"name\":\"L. Yan\"},{\"authorId\":\"1491637173\",\"name\":\"Chao Gou\"},{\"authorId\":\"143754347\",\"name\":\"F. Wang\"}],\"doi\":\"10.1016/j.inffus.2020.10.007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"03a8f5098e8ffeed7a38f1ae8705f71b18d24e0e\",\"title\":\"KM4: Visual reasoning via Knowledge Embedding Memory Model with Mutual Modulation\",\"url\":\"https://www.semanticscholar.org/paper/03a8f5098e8ffeed7a38f1ae8705f71b18d24e0e\",\"venue\":\"\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2625271\",\"name\":\"Mengfei Li\"},{\"authorId\":\"143628183\",\"name\":\"Li Gu\"},{\"authorId\":\"144602988\",\"name\":\"Yi Ji\"},{\"authorId\":\"6681872\",\"name\":\"Chunping Liu\"}],\"doi\":\"10.1007/978-3-030-00764-5_69\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"87f208c3716a80f5251d35196b8ac5c42fa791ea\",\"title\":\"Text-Guided Dual-Branch Attention Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/87f208c3716a80f5251d35196b8ac5c42fa791ea\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47111044\",\"name\":\"Mingqin Chen\"},{\"authorId\":null,\"name\":\"Yilei Wang\"},{\"authorId\":\"145675052\",\"name\":\"Shan Chen\"},{\"authorId\":\"48607932\",\"name\":\"Yingjie Wu\"}],\"doi\":\"10.1109/ISPA-BDCloud-SustainCom-SocialCom48970.2019.00167\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f69228901c1bb6a139a96fab87e1a5827ba08a2a\",\"title\":\"Counting Attention Based on Classification Confidence for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f69228901c1bb6a139a96fab87e1a5827ba08a2a\",\"venue\":\"2019 IEEE Intl Conf on Parallel & Distributed Processing with Applications, Big Data & Cloud Computing, Sustainable Computing & Communications, Social Computing & Networking (ISPA/BDCloud/SocialCom/SustainCom)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40295709\",\"name\":\"F. Liu\"},{\"authorId\":null,\"name\":\"Jing Liu\"},{\"authorId\":\"48386951\",\"name\":\"Xinxin Zhu\"},{\"authorId\":\"120313754\",\"name\":\"Richang Hong\"},{\"authorId\":\"1699900\",\"name\":\"H. Lu\"}],\"doi\":\"10.1145/3394171.3413649\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"063235546b312ee4cb5cc67578b6e879461c6d83\",\"title\":\"Dual Hierarchical Temporal Convolutional Network with QA-Aware Dynamic Normalization for Video Story Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/063235546b312ee4cb5cc67578b6e879461c6d83\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2001.11673\",\"authors\":[{\"authorId\":\"2673176\",\"name\":\"M. Alizadeh\"},{\"authorId\":\"1745798\",\"name\":\"B. D. Eugenio\"}],\"doi\":\"10.1109/ICSC.2020.00013\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8ee926c62a30a40727529fd6be129a6f942d4722\",\"title\":\"Augmenting Visual Question Answering with Semantic Frame Information in a Multitask Learning Approach\",\"url\":\"https://www.semanticscholar.org/paper/8ee926c62a30a40727529fd6be129a6f942d4722\",\"venue\":\"2020 IEEE 14th International Conference on Semantic Computing (ICSC)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46314993\",\"name\":\"Wei-ying Wang\"},{\"authorId\":\"1994473516\",\"name\":\"Jieting Chen\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"}],\"doi\":\"10.1145/3394171.3413890\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b116c8cd44a34f440f260a890e0600b61d92c262\",\"title\":\"VideoIC: A Video Interactive Comments Dataset and Multimodal Multitask Learning for Comments Generation\",\"url\":\"https://www.semanticscholar.org/paper/b116c8cd44a34f440f260a890e0600b61d92c262\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3368782\",\"name\":\"Yuetan Lin\"},{\"authorId\":\"7372283\",\"name\":\"Zhangyang Pang\"},{\"authorId\":\"144199812\",\"name\":\"D. Wang\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.24963/ijcai.2018/586\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f15ad07b9f6686bc72c45bf781c91f8eeb035899\",\"title\":\"Feature Enhancement in Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f15ad07b9f6686bc72c45bf781c91f8eeb035899\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1865719481\",\"name\":\"Deepak Gupta\"},{\"authorId\":\"27563697\",\"name\":\"Pabitra Lenka\"},{\"authorId\":\"1734904\",\"name\":\"Asif Ekbal\"},{\"authorId\":\"145532184\",\"name\":\"P. Bhattacharyya\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6ba2a128dd8dadc2925b3b9c01fb6db01bd75066\",\"title\":\"A Unified Framework for Multilingual and Code-Mixed Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/6ba2a128dd8dadc2925b3b9c01fb6db01bd75066\",\"venue\":\"AACL/IJCNLP\",\"year\":2020},{\"arxivId\":\"2006.11397\",\"authors\":[{\"authorId\":\"39083167\",\"name\":\"A. Dutta\"},{\"authorId\":\"2893664\",\"name\":\"Zeynep Akata\"}],\"doi\":\"10.1109/CVPR.2019.00523\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"96112f58cae6cbb85528ab1cb01550d106dc4ae8\",\"title\":\"Semantically Tied Paired Cycle Consistency for Zero-Shot Sketch-Based Image Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/96112f58cae6cbb85528ab1cb01550d106dc4ae8\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2011.12662\",\"authors\":[{\"authorId\":\"47792675\",\"name\":\"Jie Ma\"},{\"authorId\":\"120809631\",\"name\":\"Jiwang Liu\"},{\"authorId\":\"49297808\",\"name\":\"Junjun Li\"},{\"authorId\":\"50320297\",\"name\":\"Qinghua Zheng\"},{\"authorId\":\"3393799\",\"name\":\"Qingyu Yin\"},{\"authorId\":\"1708169071\",\"name\":\"Jianlong Zhou\"},{\"authorId\":\"121240779\",\"name\":\"Y. Huang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"ec666fc061c3e5276dfc1afd9b7a1ae39da69ba6\",\"title\":\"XTQA: Span-Level Explanations of the Textbook Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ec666fc061c3e5276dfc1afd9b7a1ae39da69ba6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1908.04107\",\"authors\":[{\"authorId\":\"23165772\",\"name\":\"Z. Yu\"},{\"authorId\":\"30513139\",\"name\":\"Yuhao Cui\"},{\"authorId\":\"97583812\",\"name\":\"J. Yu\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a3d3df29fc98e0d674bf02bab69726795f4c7b78\",\"title\":\"Multimodal Unified Attention Networks for Vision-and-Language Interactions\",\"url\":\"https://www.semanticscholar.org/paper/a3d3df29fc98e0d674bf02bab69726795f4c7b78\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1902.09487\",\"authors\":[{\"authorId\":\"7535126\",\"name\":\"R\\u00e9mi Cad\\u00e8ne\"},{\"authorId\":\"1405301761\",\"name\":\"Hedi Ben-younes\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"},{\"authorId\":\"1728523\",\"name\":\"N. Thome\"}],\"doi\":\"10.1109/CVPR.2019.00209\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"0a9f1a1321958df7dfb2efce3e9d1e99b9f5ccb3\",\"title\":\"MUREL: Multimodal Relational Reasoning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0a9f1a1321958df7dfb2efce3e9d1e99b9f5ccb3\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35301620\",\"name\":\"Katrien Laenen\"},{\"authorId\":\"145446752\",\"name\":\"Marie-Francine Moens\"}],\"doi\":\"10.1016/j.ipm.2020.102316\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c04d535a0710cbe306a392e63c688ba71842bf93\",\"title\":\"A Comparative Study of Outfit Recommendation Methods with a Focus on Attention-based Fusion\",\"url\":\"https://www.semanticscholar.org/paper/c04d535a0710cbe306a392e63c688ba71842bf93\",\"venue\":\"Inf. Process. Manag.\",\"year\":2020},{\"arxivId\":\"2008.00397\",\"authors\":[{\"authorId\":\"51115516\",\"name\":\"L. Yang\"},{\"authorId\":\"49435166\",\"name\":\"Fanqi Meng\"},{\"authorId\":\"31395194\",\"name\":\"Ming-Kuang Daniel Wu\"},{\"authorId\":\"1850625173\",\"name\":\"Vicent Ying\"},{\"authorId\":\"150345115\",\"name\":\"Xianchao Xu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c711f0b0f9e214d6ee462cffcac733221bf07026\",\"title\":\"SeqDialN: Sequential Visual Dialog Networks in Joint Visual-Linguistic Representation Space\",\"url\":\"https://www.semanticscholar.org/paper/c711f0b0f9e214d6ee462cffcac733221bf07026\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.04315\",\"authors\":[{\"authorId\":\"2520427\",\"name\":\"Yulei Niu\"},{\"authorId\":\"10817432\",\"name\":\"Kaihua Tang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1776220\",\"name\":\"Zhiwu Lu\"},{\"authorId\":\"143863244\",\"name\":\"Xian-Sheng Hua\"},{\"authorId\":\"112957699\",\"name\":\"Ji-Rong Wen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3e3f55cb25b919c4e8158195fd3ce2f23cfa7723\",\"title\":\"Counterfactual VQA: A Cause-Effect Look at Language Bias\",\"url\":\"https://www.semanticscholar.org/paper/3e3f55cb25b919c4e8158195fd3ce2f23cfa7723\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1906.01004\",\"authors\":[{\"authorId\":null,\"name\":\"Yan Zhang\"},{\"authorId\":\"2276351\",\"name\":\"Krikamol Muandet\"},{\"authorId\":\"152284539\",\"name\":\"Qianli Ma\"},{\"authorId\":\"143627576\",\"name\":\"Heiko Neumann\"},{\"authorId\":\"39578749\",\"name\":\"Siyu Tang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"8d8bf28727f1b2bc1a47425f3b6ec59bb8381f5b\",\"title\":\"Frontal Low-rank Random Tensors for Fine-grained Action Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/8d8bf28727f1b2bc1a47425f3b6ec59bb8381f5b\",\"venue\":\"\",\"year\":2019}],\"corpusId\":3005731,\"doi\":\"10.1109/ICCV.2017.202\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":44,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"8e9ad6f8b2bc97f0412fa0cc243ac6975864534a\",\"references\":[{\"arxivId\":\"1410.0210\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"ac64fb7e6d2ddf236332ec9f371fe85d308c114d\",\"title\":\"A Multi-World Approach to Question Answering about Real-World Scenes based on Uncertain Input\",\"url\":\"https://www.semanticscholar.org/paper/ac64fb7e6d2ddf236332ec9f371fe85d308c114d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1611.05709\",\"authors\":[{\"authorId\":\"3128506\",\"name\":\"Yanghao Li\"},{\"authorId\":\"48246959\",\"name\":\"Naiyan Wang\"},{\"authorId\":\"41127426\",\"name\":\"Jiaying Liu\"},{\"authorId\":\"3084719\",\"name\":\"Xiaodi Hou\"}],\"doi\":\"10.1109/ICCV.2017.229\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"34919cf24b78ae1a71c10f5800f4084600ecd36d\",\"title\":\"Factorized Bilinear Models for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/34919cf24b78ae1a71c10f5800f4084600ecd36d\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1601.01705\",\"authors\":[{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"38666915\",\"name\":\"D. Klein\"}],\"doi\":\"10.18653/v1/N16-1181\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"75ddc7ee15be14013a3462c01b38b0548486fbcb\",\"title\":\"Learning to Compose Neural Networks for Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/75ddc7ee15be14013a3462c01b38b0548486fbcb\",\"venue\":\"HLT-NAACL\",\"year\":2016},{\"arxivId\":\"1511.02274\",\"authors\":[{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"46234526\",\"name\":\"Alex Smola\"}],\"doi\":\"10.1109/CVPR.2016.10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c1890864c1c2b750f48316dc8b650ba4772adc5\",\"title\":\"Stacked Attention Networks for Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2c1890864c1c2b750f48316dc8b650ba4772adc5\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1511.02570\",\"authors\":[{\"authorId\":\"71984337\",\"name\":\"Peng Wang\"},{\"authorId\":\"49018095\",\"name\":\"Qi Wu\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.24963/ijcai.2017/179\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0b0a1cd432413978e4ef3d0418ebf3bb07af6c7a\",\"title\":\"Explicit Knowledge-based Reasoning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0b0a1cd432413978e4ef3d0418ebf3bb07af6c7a\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":\"1511.06973\",\"authors\":[{\"authorId\":\"34902783\",\"name\":\"Qi Wu\"},{\"authorId\":\"48319305\",\"name\":\"P. Wang\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2016.500\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"20dbdf02497aa84510970d0f5e8b599073bca1bc\",\"title\":\"Ask Me Anything: Free-Form Visual Question Answering Based on Knowledge from External Sources\",\"url\":\"https://www.semanticscholar.org/paper/20dbdf02497aa84510970d0f5e8b599073bca1bc\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1511.05234\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1007/978-3-319-46478-7_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1cf6bc0866226c1f8e282463adc8b75d92fba9bb\",\"title\":\"Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1cf6bc0866226c1f8e282463adc8b75d92fba9bb\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1505.01121\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":\"10.1109/ICCV.2015.9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bd7bd1d2945a58cdcc1797ba9698b8810fe68f60\",\"title\":\"Ask Your Neurons: A Neural-Based Approach to Answering Questions about Images\",\"url\":\"https://www.semanticscholar.org/paper/bd7bd1d2945a58cdcc1797ba9698b8810fe68f60\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"9390267\",\"name\":\"Qifan Yang\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"},{\"authorId\":\"3945955\",\"name\":\"X. He\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.24963/ijcai.2017/492\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a05e84f77e1dacaa1c59ba0d92919bdcfe4debbb\",\"title\":\"Video Question Answering via Hierarchical Spatio-Temporal Attention Networks\",\"url\":\"https://www.semanticscholar.org/paper/a05e84f77e1dacaa1c59ba0d92919bdcfe4debbb\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":\"1606.06108\",\"authors\":[{\"authorId\":\"2652444\",\"name\":\"K. Saito\"},{\"authorId\":\"145568592\",\"name\":\"Andrew Shin\"},{\"authorId\":\"3250559\",\"name\":\"Y. Ushiku\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.1109/ICME.2017.8019436\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"121a9a160f1f2819a01edbe522024b58dbfee798\",\"title\":\"DualNet: Domain-invariant network for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/121a9a160f1f2819a01edbe522024b58dbfee798\",\"venue\":\"2017 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2017},{\"arxivId\":\"1505.00468\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-016-0966-6\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"title\":\"VQA: Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1611.00471\",\"authors\":[{\"authorId\":\"34758272\",\"name\":\"H. Nam\"},{\"authorId\":\"2577039\",\"name\":\"Jung-Woo Ha\"},{\"authorId\":\"2947441\",\"name\":\"J. Kim\"}],\"doi\":\"10.1109/CVPR.2017.232\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f651593fa6c83d717fc961482696a53b6fca5ab5\",\"title\":\"Dual Attention Networks for Multimodal Reasoning and Matching\",\"url\":\"https://www.semanticscholar.org/paper/f651593fa6c83d717fc961482696a53b6fca5ab5\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fa236a1ef29c6632fd3aebdfcbfdb04d945e48d7\",\"title\":\"Separating Style and Content\",\"url\":\"https://www.semanticscholar.org/paper/fa236a1ef29c6632fd3aebdfcbfdb04d945e48d7\",\"venue\":\"NIPS\",\"year\":1996},{\"arxivId\":\"1606.03647\",\"authors\":[{\"authorId\":\"2018393\",\"name\":\"Hyeonwoo Noh\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b58e08741fb9803fa2a870eee139137d3bade332\",\"title\":\"Training Recurrent Answering Units with Joint Loss Minimization for VQA\",\"url\":\"https://www.semanticscholar.org/paper/b58e08741fb9803fa2a870eee139137d3bade332\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1606.01847\",\"authors\":[{\"authorId\":\"50599725\",\"name\":\"A. Fukui\"},{\"authorId\":\"3422202\",\"name\":\"Dong Huk Park\"},{\"authorId\":\"3422876\",\"name\":\"Daylen Yang\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.18653/v1/D16-1044\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fddc15480d086629b960be5bff96232f967f2252\",\"title\":\"Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/fddc15480d086629b960be5bff96232f967f2252\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":\"1606.00061\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"145743311\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b\",\"title\":\"Hierarchical Question-Image Co-Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1511.07394\",\"authors\":[{\"authorId\":\"143953573\",\"name\":\"K. Shih\"},{\"authorId\":\"37415643\",\"name\":\"S. Singh\"},{\"authorId\":\"2433269\",\"name\":\"Derek Hoiem\"}],\"doi\":\"10.1109/CVPR.2016.499\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"175e9bb50cc062c6c1742a5d90c8dfe31d2e4e22\",\"title\":\"Where to Look: Focus Regions for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/175e9bb50cc062c6c1742a5d90c8dfe31d2e4e22\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143845796\",\"name\":\"Jeffrey Pennington\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.3115/v1/D14-1162\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"title\":\"Glove: Global Vectors for Word Representation\",\"url\":\"https://www.semanticscholar.org/paper/f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1506.06726\",\"authors\":[{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"2214033\",\"name\":\"Y. Zhu\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6e795c6e9916174ae12349f5dc3f516570c17ce8\",\"title\":\"Skip-Thought Vectors\",\"url\":\"https://www.semanticscholar.org/paper/6e795c6e9916174ae12349f5dc3f516570c17ce8\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1602.07332\",\"authors\":[{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"50499889\",\"name\":\"O. Groth\"},{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"1382195702\",\"name\":\"Kenji Hata\"},{\"authorId\":\"40591424\",\"name\":\"J. Kravitz\"},{\"authorId\":\"6000646\",\"name\":\"Stephanie Chen\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"1388344504\",\"name\":\"David A. Shamma\"},{\"authorId\":\"1379506718\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-016-0981-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"title\":\"Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations\",\"url\":\"https://www.semanticscholar.org/paper/afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":\"1511.04670\",\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"2351434\",\"name\":\"Zhongwen Xu\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9ed7d774684a1770445c1c53e276011a8364b9e2\",\"title\":\"Uncovering Temporal Context for Video Question and Answering\",\"url\":\"https://www.semanticscholar.org/paper/9ed7d774684a1770445c1c53e276011a8364b9e2\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1511.02799\",\"authors\":[{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"38666915\",\"name\":\"D. Klein\"}],\"doi\":\"10.1109/CVPR.2016.12\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"21c99706bb26e9012bfb4d8d48009a3d45af59b2\",\"title\":\"Neural Module Networks\",\"url\":\"https://www.semanticscholar.org/paper/21c99706bb26e9012bfb4d8d48009a3d45af59b2\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1511.05756\",\"authors\":[{\"authorId\":\"2018393\",\"name\":\"Hyeonwoo Noh\"},{\"authorId\":\"14454974\",\"name\":\"P. H. Seo\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":\"10.1109/CVPR.2016.11\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"385c18cc4024a3b3206c508c512e037b9c00b8f3\",\"title\":\"Image Question Answering Using Convolutional Neural Network with Dynamic Parameter Prediction\",\"url\":\"https://www.semanticscholar.org/paper/385c18cc4024a3b3206c508c512e037b9c00b8f3\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1603.01417\",\"authors\":[{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"3375440\",\"name\":\"Stephen Merity\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f96898d15a1bf1fa8925b1280d0e07a7a8e72194\",\"title\":\"Dynamic Memory Networks for Visual and Textual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f96898d15a1bf1fa8925b1280d0e07a7a8e72194\",\"venue\":\"ICML\",\"year\":2016},{\"arxivId\":\"1604.01485\",\"authors\":[{\"authorId\":\"3393294\",\"name\":\"Ilija Ilievski\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7214daf035ab005b3d1e739750dd597b4f4513fa\",\"title\":\"A Focused Dynamic Attention Model for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7214daf035ab005b3d1e739750dd597b4f4513fa\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1511.05960\",\"authors\":[{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"36650957\",\"name\":\"Jiang Wang\"},{\"authorId\":\"34192119\",\"name\":\"Liang-Chieh Chen\"},{\"authorId\":\"2345388\",\"name\":\"Haoyuan Gao\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b196bc11ad516c8e6ff96f83acfc443fd7161730\",\"title\":\"ABC-CNN: An Attention Based Convolutional Neural Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b196bc11ad516c8e6ff96f83acfc443fd7161730\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1606.01455\",\"authors\":[{\"authorId\":\"2684967\",\"name\":\"J. Kim\"},{\"authorId\":\"3226948\",\"name\":\"Sang-Woo Lee\"},{\"authorId\":\"3422869\",\"name\":\"Dong-Hyun Kwak\"},{\"authorId\":\"2939188\",\"name\":\"Min-Oh Heo\"},{\"authorId\":\"2947441\",\"name\":\"J. Kim\"},{\"authorId\":\"2577039\",\"name\":\"Jung-Woo Ha\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1afb710a5b35a2352a6495e4bf6eef66808daf1b\",\"title\":\"Multimodal Residual Learning for Visual QA\",\"url\":\"https://www.semanticscholar.org/paper/1afb710a5b35a2352a6495e4bf6eef66808daf1b\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"},{\"authorId\":\"144894849\",\"name\":\"Fei Wu\"},{\"authorId\":\"144455838\",\"name\":\"Yunhe Pan\"}],\"doi\":\"10.1109/TMM.2008.917359\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b022b9c7319c19217fdf17bd99606dcf68942d60\",\"title\":\"Harmonizing Hierarchical Manifolds for Multimedia Document Semantics Understanding and Cross-Media Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/b022b9c7319c19217fdf17bd99606dcf68942d60\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2008},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1408.5093\",\"authors\":[{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"1782282\",\"name\":\"Evan Shelhamer\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"3049736\",\"name\":\"S. Karayev\"},{\"authorId\":\"144361581\",\"name\":\"J. Long\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1145/2647868.2654889\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6bdb186ec4726e00a8051119636d4df3b94043b5\",\"title\":\"Caffe: Convolutional Architecture for Fast Feature Embedding\",\"url\":\"https://www.semanticscholar.org/paper/6bdb186ec4726e00a8051119636d4df3b94043b5\",\"venue\":\"ACM Multimedia\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J.-H. Kim\"},{\"authorId\":null,\"name\":\"K. W. On\"},{\"authorId\":null,\"name\":\"J. Kim\"},{\"authorId\":null,\"name\":\"J.-W. Ha\"},{\"authorId\":null,\"name\":\"B.-T. Zhang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Hadamard product for low-rank bilinear pooling\",\"url\":\"\",\"venue\":\"arXiv preprint arXiv:1610.04325,\",\"year\":2016},{\"arxivId\":\"1606.05433\",\"authors\":[{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"121177698\",\"name\":\"A. Dick\"},{\"authorId\":\"133678193\",\"name\":\"A. van den Hengel\"}],\"doi\":\"10.1109/TPAMI.2017.2754246\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b60630911d7746fba06de7c34abe98c9a61c6bcc\",\"title\":\"FVQA: Fact-Based Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b60630911d7746fba06de7c34abe98c9a61c6bcc\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2843982\",\"name\":\"S. Rendle\"}],\"doi\":\"10.1109/ICDM.2010.127\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"df93596d4ed71d2863532c063c4c693711216abf\",\"title\":\"Factorization Machines\",\"url\":\"https://www.semanticscholar.org/paper/df93596d4ed71d2863532c063c4c693711216abf\",\"venue\":\"2010 IEEE International Conference on Data Mining\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"},{\"authorId\":\"144894849\",\"name\":\"Fei Wu\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1145/2600428.2609563\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8087f878039728a766167b42cc1ea40190dc7fe2\",\"title\":\"Discriminative coupled dictionary hashing for fast cross-media retrieval\",\"url\":\"https://www.semanticscholar.org/paper/8087f878039728a766167b42cc1ea40190dc7fe2\",\"venue\":\"SIGIR\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1162/neco.1997.9.8.1735\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"title\":\"Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"venue\":\"Neural Computation\",\"year\":1997},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1504.07889\",\"authors\":[{\"authorId\":\"2144284\",\"name\":\"Tsung-Yu Lin\"},{\"authorId\":\"2895705\",\"name\":\"Aruni RoyChowdhury\"},{\"authorId\":\"35208858\",\"name\":\"Subhransu Maji\"}],\"doi\":\"10.1109/ICCV.2015.170\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3d3f789a56dca288b2c8e23ef047a2b342184950\",\"title\":\"Bilinear CNN Models for Fine-Grained Visual Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3d3f789a56dca288b2c8e23ef047a2b342184950\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1512.02167\",\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"39402399\",\"name\":\"Yuandong Tian\"},{\"authorId\":\"2265067\",\"name\":\"Sainbayar Sukhbaatar\"},{\"authorId\":\"3149531\",\"name\":\"Arthur Szlam\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"267fb4ac632449dbe84f7acf17c8c7527cb25b0d\",\"title\":\"Simple Baseline for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/267fb4ac632449dbe84f7acf17c8c7527cb25b0d\",\"venue\":\"ArXiv\",\"year\":2015}],\"title\":\"Multi-modal Factorized Bilinear Pooling with Co-attention Learning for Visual Question Answering\",\"topics\":[{\"topic\":\"Modal logic\",\"topicId\":\"61528\",\"url\":\"https://www.semanticscholar.org/topic/61528\"},{\"topic\":\"Question answering\",\"topicId\":\"18817\",\"url\":\"https://www.semanticscholar.org/topic/18817\"},{\"topic\":\"Bilinear transform\",\"topicId\":\"397622\",\"url\":\"https://www.semanticscholar.org/topic/397622\"},{\"topic\":\"Bilinear filtering\",\"topicId\":\"1123309\",\"url\":\"https://www.semanticscholar.org/topic/1123309\"},{\"topic\":\"Network architecture\",\"topicId\":\"58473\",\"url\":\"https://www.semanticscholar.org/topic/58473\"},{\"topic\":\"Multimodal interaction\",\"topicId\":\"42592\",\"url\":\"https://www.semanticscholar.org/topic/42592\"},{\"topic\":\"Unified Model\",\"topicId\":\"90488\",\"url\":\"https://www.semanticscholar.org/topic/90488\"},{\"topic\":\"Linear model\",\"topicId\":\"41514\",\"url\":\"https://www.semanticscholar.org/topic/41514\"},{\"topic\":\"The Australian\",\"topicId\":\"38542\",\"url\":\"https://www.semanticscholar.org/topic/38542\"},{\"topic\":\"End-to-end principle\",\"topicId\":\"299633\",\"url\":\"https://www.semanticscholar.org/topic/299633\"},{\"topic\":\"Computational complexity theory\",\"topicId\":\"1133\",\"url\":\"https://www.semanticscholar.org/topic/1133\"}],\"url\":\"https://www.semanticscholar.org/paper/8e9ad6f8b2bc97f0412fa0cc243ac6975864534a\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017}\n"