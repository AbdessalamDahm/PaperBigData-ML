"{\"abstract\":\"Human actions captured in video sequences are threedimensional signals characterizing visual appearance and motion dynamics. To learn action patterns, existing methods adopt Convolutional and/or Recurrent Neural Networks (CNNs and RNNs). CNN based methods are effective in learning spatial appearances, but are limited in modeling long-term motion dynamics. RNNs, especially Long Short- Term Memory (LSTM), are able to learn temporal motion dynamics. However, naively applying RNNs to video sequences in a convolutional manner implicitly assumes that motions in videos are stationary across different spatial locations. This assumption is valid for short-term motions but invalid when the duration of the motion is long.,,In this work, we propose Lattice-LSTM (L2STM), which extends LSTM by learning independent hidden state transitions of memory cells for individual spatial locations. This method effectively enhances the ability to model dynamics across time and addresses the non-stationary issue of long-term motion dynamics without significantly increasing the model complexity. Additionally, we introduce a novel multi-modal training procedure for training our network. Unlike traditional two-stream architectures which use RGB and optical flow information as input, our two-stream model leverages both modalities to jointly train both input gates and both forget gates in the network rather than treating the two streams as separate entities with no information about the other. We apply this end-to-end system to benchmark datasets (UCF-101 and HMDB-51) of human action recognition. Experiments show that on both datasets, our proposed method outperforms all existing ones that are based on LSTM and/or CNNs of similar model complexities.\",\"arxivId\":\"1708.03958\",\"authors\":[{\"authorId\":\"41191188\",\"name\":\"Lin Sun\",\"url\":\"https://www.semanticscholar.org/author/41191188\"},{\"authorId\":\"2370507\",\"name\":\"K. Jia\",\"url\":\"https://www.semanticscholar.org/author/2370507\"},{\"authorId\":\"143887468\",\"name\":\"Kevin Chen\",\"url\":\"https://www.semanticscholar.org/author/143887468\"},{\"authorId\":\"1739816\",\"name\":\"D. Yeung\",\"url\":\"https://www.semanticscholar.org/author/1739816\"},{\"authorId\":\"2131088\",\"name\":\"B. Shi\",\"url\":\"https://www.semanticscholar.org/author/2131088\"},{\"authorId\":\"1702137\",\"name\":\"S. Savarese\",\"url\":\"https://www.semanticscholar.org/author/1702137\"}],\"citationVelocity\":25,\"citations\":[{\"arxivId\":\"2002.02100\",\"authors\":[{\"authorId\":\"153037548\",\"name\":\"S. H. Shabbeer Basha\"},{\"authorId\":\"51485920\",\"name\":\"Viswanath Pulabaigari\"},{\"authorId\":\"34356161\",\"name\":\"Snehasis Mukherjee\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"42bf5be4b315c0eb68dd8d7fd4a6519304217c25\",\"title\":\"An Information-rich Sampling Technique over Spatio-Temporal CNN for Classification of Human Actions in Videos\",\"url\":\"https://www.semanticscholar.org/paper/42bf5be4b315c0eb68dd8d7fd4a6519304217c25\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48805860\",\"name\":\"Zhimeng Zhang\"},{\"authorId\":\"145453305\",\"name\":\"Xin Ma\"},{\"authorId\":\"2610029\",\"name\":\"H. Wu\"},{\"authorId\":\"48513221\",\"name\":\"Yibin Li\"}],\"doi\":\"10.1109/ACCESS.2018.2887144\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cb42378c1fee81bc25caeb159a98bfca3e8a2e69\",\"title\":\"Fall Detection in Videos With Trajectory-Weighted Deep-Convolutional Rank-Pooling Descriptor\",\"url\":\"https://www.semanticscholar.org/paper/cb42378c1fee81bc25caeb159a98bfca3e8a2e69\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48096554\",\"name\":\"L. Zhao\"},{\"authorId\":\"2005595217\",\"name\":\"Ailian Zhang\"},{\"authorId\":\"19432190\",\"name\":\"Y. Liu\"},{\"authorId\":\"46959445\",\"name\":\"Hao Fei\"}],\"doi\":\"10.1016/j.patrec.2020.07.017\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"591de9bd68b192dcd18efc1b326e1d25676aaef4\",\"title\":\"Encoding multi-granularity structural information for joint Chinese word segmentation and POS tagging\",\"url\":\"https://www.semanticscholar.org/paper/591de9bd68b192dcd18efc1b326e1d25676aaef4\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47039680\",\"name\":\"X. Zhao\"},{\"authorId\":\"145359183\",\"name\":\"Y. Yi\"},{\"authorId\":\"144186239\",\"name\":\"Zemin Qiu\"},{\"authorId\":\"9235546\",\"name\":\"Qingqing Zeng\"}],\"doi\":\"10.1109/ICCCS49078.2020.9118516\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b90a1655ac7cbabef6c7a8ea4a70fa03526c6819\",\"title\":\"Feature Retrieving for Human Action Recognition by Mixed Scale Deep Feature Combined with Attention Model\",\"url\":\"https://www.semanticscholar.org/paper/b90a1655ac7cbabef6c7a8ea4a70fa03526c6819\",\"venue\":\"2020 5th International Conference on Computer and Communication Systems (ICCCS)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"69458617\",\"name\":\"Albert Clap\\u00e9s i Sintes\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9a00c447f626be388bb402faeac3653d8555785e\",\"title\":\"Learning to recognize human actions: from hand-crafted to deep-learning based visual representations\",\"url\":\"https://www.semanticscholar.org/paper/9a00c447f626be388bb402faeac3653d8555785e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a87ab836771164adb95d6744027e62e05f47fd96\",\"title\":\"Understanding human-human interactions: a survey\",\"url\":\"https://www.semanticscholar.org/paper/a87ab836771164adb95d6744027e62e05f47fd96\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3381029\",\"name\":\"J. Wang\"},{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1016/j.cviu.2019.102898\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"62af68e20481f9f98509bfed69ef1300a8e9485e\",\"title\":\"Cascade multi-head attention networks for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/62af68e20481f9f98509bfed69ef1300a8e9485e\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2020},{\"arxivId\":\"1712.00636\",\"authors\":[{\"authorId\":\"2978413\",\"name\":\"Chao-Yuan Wu\"},{\"authorId\":\"1771307\",\"name\":\"M. Zaheer\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"1758550\",\"name\":\"R. Manmatha\"},{\"authorId\":\"46234526\",\"name\":\"Alex Smola\"},{\"authorId\":\"2562966\",\"name\":\"Philipp Kr\\u00e4henb\\u00fchl\"}],\"doi\":\"10.1109/CVPR.2018.00631\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9d98a956aadaff727e495b14b7c532d40ea49e16\",\"title\":\"Compressed Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9d98a956aadaff727e495b14b7c532d40ea49e16\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1709.01421\",\"authors\":[{\"authorId\":\"26433379\",\"name\":\"Konstantin Sozykin\"},{\"authorId\":\"1714762\",\"name\":\"A. Khan\"},{\"authorId\":\"145683466\",\"name\":\"Stanislav Protasov\"},{\"authorId\":\"2225364\",\"name\":\"R. Hussain\"}],\"doi\":\"10.1109/SNPD.2018.8441034\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"93b53df454e272873438082a638574b1fe424414\",\"title\":\"Multi-label Class-imbalanced Action Recognition in Hockey Videos via 3D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/93b53df454e272873438082a638574b1fe424414\",\"venue\":\"2018 19th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"18186434\",\"name\":\"Nudrat Nida\"},{\"authorId\":null,\"name\":\"Muhammad Haroon Yousaf\"},{\"authorId\":null,\"name\":\"Aun Irtaza\"},{\"authorId\":null,\"name\":\"Sergio A. Velastin\"}],\"doi\":\"10.3906/elk-1907-214\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2ba6d9f33113ef9c29ce403c69ada4b011ffe980\",\"title\":\"Deep temporal motion descriptor DTMD for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/2ba6d9f33113ef9c29ce403c69ada4b011ffe980\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"13676352\",\"name\":\"Zhiyun Li\"},{\"authorId\":\"46649145\",\"name\":\"Ning Ding\"},{\"authorId\":\"49293248\",\"name\":\"Z. Liu\"},{\"authorId\":\"11863188\",\"name\":\"H. Zheng\"},{\"authorId\":\"143822679\",\"name\":\"Ying Shen\"}],\"doi\":\"10.18653/v1/P19-1430\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7334f45c06555d4b6bf7e6b4437574c11369697e\",\"title\":\"Chinese Relation Extraction with Multi-Grained Information and External Linguistic Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/7334f45c06555d4b6bf7e6b4437574c11369697e\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35654996\",\"name\":\"B. Pan\"},{\"authorId\":\"2282025\",\"name\":\"Jiankai Sun\"},{\"authorId\":\"35992009\",\"name\":\"Wuwei Lin\"},{\"authorId\":\"48170350\",\"name\":\"Limin Wang\"},{\"authorId\":\"8131625\",\"name\":\"W. Lin\"}],\"doi\":\"10.1109/CVPRW.2019.00059\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3e9285552fc3c1402a09e3d29ee09c130cf2d419\",\"title\":\"Cross-Stream Selective Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3e9285552fc3c1402a09e3d29ee09c130cf2d419\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66275285\",\"name\":\"Hemerson Tacon\"},{\"authorId\":\"51519347\",\"name\":\"A. Brito\"},{\"authorId\":\"67244903\",\"name\":\"H. Chaves\"},{\"authorId\":\"3052490\",\"name\":\"M. Vieira\"},{\"authorId\":\"3387755\",\"name\":\"S. Villela\"},{\"authorId\":\"8125221\",\"name\":\"H. Maia\"},{\"authorId\":\"66088742\",\"name\":\"Darwin Ttito Concha\"},{\"authorId\":\"1743455\",\"name\":\"H. Pedrini\"}],\"doi\":\"10.1007/978-3-030-24289-3_26\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a2c302047b5c0b66e0be4594200006d93c30c565\",\"title\":\"Human Action Recognition Using Convolutional Neural Networks with Symmetric Time Extension of Visual Rhythms\",\"url\":\"https://www.semanticscholar.org/paper/a2c302047b5c0b66e0be4594200006d93c30c565\",\"venue\":\"ICCSA\",\"year\":2019},{\"arxivId\":\"1911.01060\",\"authors\":[{\"authorId\":\"152641281\",\"name\":\"Y. Zhou\"},{\"authorId\":\"1410071510\",\"name\":\"Hongru Li\"},{\"authorId\":\"144410963\",\"name\":\"S. Kung\"}],\"doi\":\"10.1109/tmm.2020.3042077\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fbcb5f600f0fde2cc94f90b96a830652a47e7af5\",\"title\":\"Temporal Action Localization using Long Short-Term Dependency\",\"url\":\"https://www.semanticscholar.org/paper/fbcb5f600f0fde2cc94f90b96a830652a47e7af5\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52022007\",\"name\":\"Vasileios Choutas\"},{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"3428663\",\"name\":\"J\\u00e9r\\u00f4me Revaud\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/CVPR.2018.00734\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6009bba115904bc3bf876224db90b232c4f0a48f\",\"title\":\"PoTion: Pose MoTion Representation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6009bba115904bc3bf876224db90b232c4f0a48f\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1904.13072\",\"authors\":[{\"authorId\":\"49370704\",\"name\":\"Dong Wang\"},{\"authorId\":\"145377162\",\"name\":\"Y. Yuan\"},{\"authorId\":\"39669401\",\"name\":\"Q. Wang\"}],\"doi\":\"10.1109/ICASSP.2018.8461792\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ef9a4d76698ebb3cddd705b801a0739a6b06959b\",\"title\":\"Cross-Modal Message Passing for Two-Stream Fusion\",\"url\":\"https://www.semanticscholar.org/paper/ef9a4d76698ebb3cddd705b801a0739a6b06959b\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":\"2002.02603\",\"authors\":[{\"authorId\":\"67288955\",\"name\":\"Wanxiang Yang\"},{\"authorId\":\"151494647\",\"name\":\"Y. Yan\"},{\"authorId\":\"143640801\",\"name\":\"S. Chen\"}],\"doi\":\"10.1016/j.neucom.2019.02.042\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"773eaa5f9d2a6c8557fff9c4ed7c78e0247961d6\",\"title\":\"Adaptive deep metric embeddings for person re-identification under occlusions\",\"url\":\"https://www.semanticscholar.org/paper/773eaa5f9d2a6c8557fff9c4ed7c78e0247961d6\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2896701\",\"name\":\"G. An\"},{\"authorId\":\"4464686\",\"name\":\"ZhenXing Zheng\"},{\"authorId\":\"144953181\",\"name\":\"D. Wu\"},{\"authorId\":\"153168978\",\"name\":\"Wen Zhou\"}],\"doi\":\"10.1016/j.jvcir.2019.102650\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a22e41d8ac3c56072d5fe1136567d1b82d9bb46e\",\"title\":\"Deep spectral feature pyramid in the frequency domain for long-term action recognition\",\"url\":\"https://www.semanticscholar.org/paper/a22e41d8ac3c56072d5fe1136567d1b82d9bb46e\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48094509\",\"name\":\"J. Wang\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f23b737af93469efc4b7438377a3cec2e9c8febb\",\"title\":\"Ju l 2 01 8 Learning Discriminative Video Representations Using Adversarial Perturbations\",\"url\":\"https://www.semanticscholar.org/paper/f23b737af93469efc4b7438377a3cec2e9c8febb\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4464686\",\"name\":\"ZhenXing Zheng\"},{\"authorId\":\"2896701\",\"name\":\"G. An\"},{\"authorId\":\"144953181\",\"name\":\"D. Wu\"},{\"authorId\":\"144695333\",\"name\":\"Q. Ruan\"}],\"doi\":\"10.1016/J.NEUCOM.2019.05.058\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"67d3ec7b1070405575974e449cfdc495b43f7b21\",\"title\":\"Spatial-temporal pyramid based Convolutional Neural Network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/67d3ec7b1070405575974e449cfdc495b43f7b21\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"1809.03705\",\"authors\":[{\"authorId\":\"1410629683\",\"name\":\"Xiaoxiao Du\"},{\"authorId\":\"145386932\",\"name\":\"R. Vasudevan\"},{\"authorId\":\"1389944402\",\"name\":\"M. Johnson-Roberson\"}],\"doi\":\"10.1109/LRA.2019.2895266\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6f8944eb08c103f395485e9ee976fa898342ce2f\",\"title\":\"Bio-LSTM: A Biomechanically Inspired Recurrent Neural Network for 3-D Pedestrian Pose and Gait Prediction\",\"url\":\"https://www.semanticscholar.org/paper/6f8944eb08c103f395485e9ee976fa898342ce2f\",\"venue\":\"IEEE Robotics and Automation Letters\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48094509\",\"name\":\"J. Wang\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"}],\"doi\":\"10.1007/978-3-030-01225-0_42\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8c7a962e1076949d8395e8de6aaae026f673b184\",\"title\":\"Learning Discriminative Video Representations Using Adversarial Perturbations\",\"url\":\"https://www.semanticscholar.org/paper/8c7a962e1076949d8395e8de6aaae026f673b184\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2012.11866\",\"authors\":[{\"authorId\":\"2595189\",\"name\":\"Zehua Sun\"},{\"authorId\":\"120809631\",\"name\":\"Jiwang Liu\"},{\"authorId\":\"143969578\",\"name\":\"Qiuhong Ke\"},{\"authorId\":\"1877377\",\"name\":\"H. Rahmani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"816236bf3219363bfe4b847363e137b1fe6712e7\",\"title\":\"Human Action Recognition from Various Data Modalities: A Review\",\"url\":\"https://www.semanticscholar.org/paper/816236bf3219363bfe4b847363e137b1fe6712e7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51161443\",\"name\":\"Yecheng Yao\"},{\"authorId\":\"151392758\",\"name\":\"Jungho Yi\"},{\"authorId\":\"92735425\",\"name\":\"Shengjun Zhai\"},{\"authorId\":\"3394194\",\"name\":\"Y. Lin\"},{\"authorId\":\"1858365\",\"name\":\"Taekseung Kim\"},{\"authorId\":\"151476145\",\"name\":\"Guihongxuan Zhang\"},{\"authorId\":\"144382576\",\"name\":\"L. Lee\"}],\"doi\":\"10.14419/IJET.V7I3.27.17889\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"253263e354aec8cb3ff4ab89578dd5656db9fa14\",\"title\":\"Predictive Analysis of Cryptocurrency Price Using Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/253263e354aec8cb3ff4ab89578dd5656db9fa14\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1711.11152\",\"authors\":[{\"authorId\":\"47392986\",\"name\":\"S. Sun\"},{\"authorId\":\"1874900\",\"name\":\"Zhanghui Kuang\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"84200540\",\"name\":\"Lu Sheng\"},{\"authorId\":\"1726357\",\"name\":\"Wayne Zhang\"}],\"doi\":\"10.1109/CVPR.2018.00151\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"42517e072406ea6f8d2c579d98ee3f9918a8a1d3\",\"title\":\"Optical Flow Guided Feature: A Fast and Robust Motion Representation for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/42517e072406ea6f8d2c579d98ee3f9918a8a1d3\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8125221\",\"name\":\"H. Maia\"},{\"authorId\":\"66088742\",\"name\":\"Darwin Ttito Concha\"},{\"authorId\":\"1398585275\",\"name\":\"H. Pedrini\"},{\"authorId\":\"66275285\",\"name\":\"Hemerson Tacon\"},{\"authorId\":\"51519347\",\"name\":\"A. Brito\"},{\"authorId\":\"67244903\",\"name\":\"H. Chaves\"},{\"authorId\":\"3052490\",\"name\":\"M. Vieira\"},{\"authorId\":\"3387755\",\"name\":\"S. Villela\"}],\"doi\":\"10.1007/978-981-15-1816-4_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0c426717bed63d0afdfb16dd98c8cba915f52853\",\"title\":\"Action Recognition in Videos Using Multi-stream Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/0c426717bed63d0afdfb16dd98c8cba915f52853\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8125221\",\"name\":\"H. Maia\"},{\"authorId\":\"98024338\",\"name\":\"M. Souza\"},{\"authorId\":\"46602675\",\"name\":\"A. Santos\"},{\"authorId\":\"1743455\",\"name\":\"H. Pedrini\"},{\"authorId\":\"66275285\",\"name\":\"Hemerson Tacon\"},{\"authorId\":\"145807601\",\"name\":\"A. Brito\"},{\"authorId\":\"67244903\",\"name\":\"H. Chaves\"},{\"authorId\":\"144042009\",\"name\":\"M. Vieira\"},{\"authorId\":\"3387755\",\"name\":\"S. Villela\"}],\"doi\":\"10.1109/ICMLA.2019.00290\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"45f35057fb1c653c10fd2256f7df454991698971\",\"title\":\"Learnable Visual Rhythms Based on the Stacking of Convolutional Neural Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/45f35057fb1c653c10fd2256f7df454991698971\",\"venue\":\"2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"87874401\",\"name\":\"Cai Qiang\"},{\"authorId\":\"1409990256\",\"name\":\"Jin Yan\"},{\"authorId\":\"144766132\",\"name\":\"Haisheng Li\"},{\"authorId\":\"2003541846\",\"name\":\"Deng Yibiao\"}],\"doi\":\"10.1007/978-981-15-8450-3_24\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"94c5d2d26bde4c314b7a51e42495192c5affb651\",\"title\":\"Human Action Recognition Method Based on Video-Level Features and Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/94c5d2d26bde4c314b7a51e42495192c5affb651\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2038426504\",\"name\":\"Zhouning Du\"},{\"authorId\":\"2873178\",\"name\":\"H. Mukaidani\"},{\"authorId\":\"1381799120\",\"name\":\"Ramasamy Saravanakumar\"}],\"doi\":\"10.1109/SMC42975.2020.9283429\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d00445b8d5b6da620056aed4685bf9b766a9700b\",\"title\":\"Action Recognition Based on Linear Dynamical Systems with Deep Features in Videos\",\"url\":\"https://www.semanticscholar.org/paper/d00445b8d5b6da620056aed4685bf9b766a9700b\",\"venue\":\"2020 IEEE International Conference on Systems, Man, and Cybernetics (SMC)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1773194\",\"name\":\"Fei Pan\"},{\"authorId\":\"1720424\",\"name\":\"Y. Guo\"},{\"authorId\":\"151485208\",\"name\":\"Z. Yan\"},{\"authorId\":\"50115448\",\"name\":\"Jie Guo\"}],\"doi\":\"10.1109/ICME.2019.00283\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"85427b81ea2d3b0aea44fe82f6520507e7241c2f\",\"title\":\"Temporal Segment Convolutional Kernel Networks for Sequence Modeling of Videos\",\"url\":\"https://www.semanticscholar.org/paper/85427b81ea2d3b0aea44fe82f6520507e7241c2f\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":\"2007.09033\",\"authors\":[{\"authorId\":\"16323128\",\"name\":\"Guoxi Huang\"},{\"authorId\":\"1707271\",\"name\":\"Adrian G. Bors\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"215182fe19015d315cae9cd2c39e3a576b7193bf\",\"title\":\"Region-based Non-local Operation for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/215182fe19015d315cae9cd2c39e3a576b7193bf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1904697\",\"name\":\"Zhenbing Liu\"},{\"authorId\":\"1796258521\",\"name\":\"Zeya Li\"},{\"authorId\":\"49908315\",\"name\":\"Ruili Wang\"},{\"authorId\":\"51251812\",\"name\":\"Ming Zong\"},{\"authorId\":\"29790429\",\"name\":\"Wanting Ji\"}],\"doi\":\"10.1007/s00521-020-05144-7\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"575448ab04aef0856a73d8eba3a75a5321e0506d\",\"title\":\"Spatiotemporal saliency-based multi-stream networks with attention-aware LSTM for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/575448ab04aef0856a73d8eba3a75a5321e0506d\",\"venue\":\"Neural Computing and Applications\",\"year\":2020},{\"arxivId\":\"1902.09928\",\"authors\":[{\"authorId\":\"143781496\",\"name\":\"K. Yang\"},{\"authorId\":\"38373258\",\"name\":\"Jingjing Fu\"},{\"authorId\":\"145762398\",\"name\":\"Xun Guo\"},{\"authorId\":\"144574822\",\"name\":\"Y. Lu\"},{\"authorId\":\"50468629\",\"name\":\"Peng Qiao\"},{\"authorId\":\"144032853\",\"name\":\"Dong-sheng Li\"},{\"authorId\":\"143844357\",\"name\":\"Y. Dou\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"31707c9c377cffb1e6e7435c7b35a46d33976562\",\"title\":\"IF-TTN: Information Fused Temporal Transformation Network for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/31707c9c377cffb1e6e7435c7b35a46d33976562\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1811.07059\",\"authors\":[{\"authorId\":\"3766266\",\"name\":\"Zexi Chen\"},{\"authorId\":\"145704184\",\"name\":\"B. Ramachandra\"},{\"authorId\":\"47353858\",\"name\":\"Tianfu Wu\"},{\"authorId\":\"3001600\",\"name\":\"Ranga Raju Vatsavai\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7b0fe0bc433d894299e249d97ed894671c3748b1\",\"title\":\"Relational Long Short-Term Memory for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7b0fe0bc433d894299e249d97ed894671c3748b1\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2011.12619\",\"authors\":[{\"authorId\":\"147084112\",\"name\":\"Jack Humphreys\"},{\"authorId\":\"48354826\",\"name\":\"Z. Chen\"},{\"authorId\":\"145047838\",\"name\":\"Dacheng Tao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e88bff50c417703239e0a832fddb267196ab5a99\",\"title\":\"Recent Progress in Appearance-based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e88bff50c417703239e0a832fddb267196ab5a99\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8303994\",\"name\":\"Honggang Xie\"},{\"authorId\":\"144033365\",\"name\":\"Jinsheng Xiao\"},{\"authorId\":\"3389703\",\"name\":\"Junfeng Lei\"},{\"authorId\":\"2268470\",\"name\":\"Wenjuan Xie\"},{\"authorId\":\"1729664\",\"name\":\"Reinhard Klette\"}],\"doi\":\"10.1007/978-981-15-3651-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"42636140273d2a8bdeed36df1cd4d8b56f62270c\",\"title\":\"Pattern Recognition: ACPR 2019 Workshops, Auckland, New Zealand, November 26, 2019, Proceedings\",\"url\":\"https://www.semanticscholar.org/paper/42636140273d2a8bdeed36df1cd4d8b56f62270c\",\"venue\":\"ACPR Workshops\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47781560\",\"name\":\"Z. Liu\"},{\"authorId\":\"66454724\",\"name\":\"Zeya Li\"},{\"authorId\":\"150238936\",\"name\":\"Ming Zong\"},{\"authorId\":\"29790429\",\"name\":\"Wanting Ji\"},{\"authorId\":\"49908315\",\"name\":\"Ruili Wang\"},{\"authorId\":\"152714157\",\"name\":\"Y. Tian\"}],\"doi\":\"10.1007/978-981-15-3651-9_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9de826c60e7258e2a69b74836213fec465ef2601\",\"title\":\"Spatiotemporal Saliency Based Multi-stream Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9de826c60e7258e2a69b74836213fec465ef2601\",\"venue\":\"ACPR Workshops\",\"year\":2019},{\"arxivId\":\"2001.11091\",\"authors\":[{\"authorId\":\"1491169373\",\"name\":\"Mohamad Ballout\"},{\"authorId\":\"1381681564\",\"name\":\"Mohammad Tuqan\"},{\"authorId\":\"1790873\",\"name\":\"Daniel C. Asmar\"},{\"authorId\":\"48810394\",\"name\":\"Elie Shammas\"},{\"authorId\":\"1768700\",\"name\":\"George E. Sakr\"}],\"doi\":\"10.1109/IJCNN48605.2020.9207337\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7e01b0c04fd493db4422087a67082a4e3cc4e354\",\"title\":\"The benefits of synthetic data for action categorization\",\"url\":\"https://www.semanticscholar.org/paper/7e01b0c04fd493db4422087a67082a4e3cc4e354\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":\"1904.13085\",\"authors\":[{\"authorId\":\"144766725\",\"name\":\"D. Wang\"},{\"authorId\":\"49521346\",\"name\":\"Y. Yuan\"},{\"authorId\":\"39669401\",\"name\":\"Q. Wang\"}],\"doi\":\"10.1109/ACCESS.2019.2904857\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c20925c3a2fd2fcb6f91263833fd9950eba6157f\",\"title\":\"Early Action Prediction With Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/c20925c3a2fd2fcb6f91263833fd9950eba6157f\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1711.07430\",\"authors\":[{\"authorId\":\"8131625\",\"name\":\"W. Lin\"},{\"authorId\":\"145071344\",\"name\":\"Yang Mi\"},{\"authorId\":\"49388002\",\"name\":\"J. Wu\"},{\"authorId\":\"144392311\",\"name\":\"Ke Lu\"},{\"authorId\":\"144045763\",\"name\":\"Hongkai Xiong\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4f22d424292594c164a5f72846ac2cbfe94cd69f\",\"title\":\"Action Recognition with Coarse-to-Fine Deep Feature Integration and Asynchronous Fusion\",\"url\":\"https://www.semanticscholar.org/paper/4f22d424292594c164a5f72846ac2cbfe94cd69f\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47719677\",\"name\":\"Xiaolei Qin\"},{\"authorId\":\"1766722\",\"name\":\"Y. Ge\"},{\"authorId\":\"107836313\",\"name\":\"Liuwei Zhan\"},{\"authorId\":\"107717257\",\"name\":\"Guangrui Li\"},{\"authorId\":\"1786011\",\"name\":\"Sheng Huang\"},{\"authorId\":\"19226165\",\"name\":\"Hongxing Wang\"},{\"authorId\":\"47591280\",\"name\":\"Feiyu Chen\"}],\"doi\":\"10.1109/VCIP.2018.8698624\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"324f081aa68b93468de13c4c799377d6ab18b37b\",\"title\":\"Joint Deep Learning for RGB-D Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/324f081aa68b93468de13c4c799377d6ab18b37b\",\"venue\":\"2018 IEEE Visual Communications and Image Processing (VCIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49436226\",\"name\":\"Xi Ouyang\"},{\"authorId\":\"23999166\",\"name\":\"Shuangjie Xu\"},{\"authorId\":\"3194878\",\"name\":\"Chaoyun Zhang\"},{\"authorId\":\"33481412\",\"name\":\"Pan Zhou\"},{\"authorId\":\"144757965\",\"name\":\"Y. Yang\"},{\"authorId\":\"145376360\",\"name\":\"G. Liu\"},{\"authorId\":\"1720243\",\"name\":\"X. Li\"}],\"doi\":\"10.1109/ACCESS.2019.2906654\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"48e51c2508e3e3eb6b9c8a331364e5235e7644f3\",\"title\":\"A 3D-CNN and LSTM Based Multi-Task Learning Architecture for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/48e51c2508e3e3eb6b9c8a331364e5235e7644f3\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"2008.08332\",\"authors\":[{\"authorId\":null,\"name\":\"Yuxi Li\"},{\"authorId\":\"8131625\",\"name\":\"W. Lin\"},{\"authorId\":\"143937986\",\"name\":\"John See\"},{\"authorId\":null,\"name\":\"Ning Xu\"},{\"authorId\":\"1802931\",\"name\":\"Shugong Xu\"},{\"authorId\":\"1671290360\",\"name\":\"Ke Yan\"},{\"authorId\":\"46961961\",\"name\":\"Cong Yang\"}],\"doi\":\"10.1007/978-3-030-58517-4_30\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f5140c7251be78ff4fec48efea3b1c6ba581fba9\",\"title\":\"CFAD: Coarse-to-Fine Action Detector for Spatiotemporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/f5140c7251be78ff4fec48efea3b1c6ba581fba9\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"20902247\",\"name\":\"N. Nishida\"},{\"authorId\":\"1770200\",\"name\":\"Y. Kawanishi\"},{\"authorId\":\"1699693\",\"name\":\"D. Deguchi\"},{\"authorId\":\"1679187\",\"name\":\"I. Ide\"},{\"authorId\":\"82910116\",\"name\":\"H. Murase\"},{\"authorId\":\"1430786331\",\"name\":\"Jun Piao\"}],\"doi\":\"10.1109/AVSS.2019.8909825\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f5d8a295509da2069281577e9730f43b49b139d4\",\"title\":\"Exemplar-Based Pseudo-Viewpoint Rotation for White-Cane User Recognition from a 2D Human Pose Sequence\",\"url\":\"https://www.semanticscholar.org/paper/f5d8a295509da2069281577e9730f43b49b139d4\",\"venue\":\"2019 16th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38344581\",\"name\":\"Mengyu Dai\"},{\"authorId\":\"143868575\",\"name\":\"A. Srivastava\"}],\"doi\":\"10.1109/CVPRW.2019.00087\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"38402793cabf5e60de6acfeb155fa7597be3df8b\",\"title\":\"Video-Based Action Recognition Using Dimension Reduction of Deep Covariance Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/38402793cabf5e60de6acfeb155fa7597be3df8b\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66088742\",\"name\":\"Darwin Ttito Concha\"},{\"authorId\":\"8125221\",\"name\":\"H. Maia\"},{\"authorId\":\"1743455\",\"name\":\"H. Pedrini\"},{\"authorId\":\"66275285\",\"name\":\"Hemerson Tacon\"},{\"authorId\":\"51519347\",\"name\":\"A. Brito\"},{\"authorId\":\"67244903\",\"name\":\"H. Chaves\"},{\"authorId\":\"3052490\",\"name\":\"M. Vieira\"}],\"doi\":\"10.1109/ICMLA.2018.00077\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a294e26e92187a447a74bafc2d6123847c4acd7b\",\"title\":\"Multi-stream Convolutional Neural Networks for Action Recognition in Video Sequences Based on Adaptive Visual Rhythms\",\"url\":\"https://www.semanticscholar.org/paper/a294e26e92187a447a74bafc2d6123847c4acd7b\",\"venue\":\"2018 17th IEEE International Conference on Machine Learning and Applications (ICMLA)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"103844313\",\"name\":\"Y. Zhang\"},{\"authorId\":null,\"name\":\"Yile Wang\"},{\"authorId\":\"145889118\",\"name\":\"Jie Yang\"}],\"doi\":\"10.1109/TASLP.2020.2991544\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"07a08e4479037892f46fc58e43daf7f435b92d7e\",\"title\":\"Lattice LSTM for Chinese Sentence Representation\",\"url\":\"https://www.semanticscholar.org/paper/07a08e4479037892f46fc58e43daf7f435b92d7e\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8997813\",\"name\":\"A. Mahjoub\"},{\"authorId\":\"40406356\",\"name\":\"Mohamed Atri\"}],\"doi\":\"10.1142/s021812662050190x\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"71c11ebc99987f6ec10d9e91afd20dfaf55c9455\",\"title\":\"A Flexible High-Level Fusion for an Accurate Human Action Recognition System\",\"url\":\"https://www.semanticscholar.org/paper/71c11ebc99987f6ec10d9e91afd20dfaf55c9455\",\"venue\":\"J. Circuits Syst. Comput.\",\"year\":2020},{\"arxivId\":\"1907.09945\",\"authors\":[{\"authorId\":\"51105591\",\"name\":\"D. Avola\"},{\"authorId\":\"1729018\",\"name\":\"L. Cinque\"},{\"authorId\":\"1965984\",\"name\":\"A. Fagioli\"},{\"authorId\":\"144706031\",\"name\":\"G. Foresti\"},{\"authorId\":\"35404907\",\"name\":\"Cristiano Massaroni\"}],\"doi\":\"10.1109/TAFFC.2020.3003816\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"686f06f7a2f0b0322f27baddc8293f3f14753ba1\",\"title\":\"Deep Temporal Analysis for Non-Acted Body Affect Recognition\",\"url\":\"https://www.semanticscholar.org/paper/686f06f7a2f0b0322f27baddc8293f3f14753ba1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2224475\",\"name\":\"Huogen Wang\"},{\"authorId\":\"9459349\",\"name\":\"Zhanjie Song\"},{\"authorId\":\"15585183\",\"name\":\"W. Li\"},{\"authorId\":\"8120382\",\"name\":\"P. Wang\"}],\"doi\":\"10.3390/s20113305\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3b84d02d6f74a53d1196478689797eef63c306b3\",\"title\":\"A Hybrid Network for Large-Scale Action Recognition from RGB and Depth Modalities\",\"url\":\"https://www.semanticscholar.org/paper/3b84d02d6f74a53d1196478689797eef63c306b3\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"2007.06149\",\"authors\":[{\"authorId\":\"2283619\",\"name\":\"Peisen Zhao\"},{\"authorId\":\"3041937\",\"name\":\"Lingxi Xie\"},{\"authorId\":\"49890039\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/tmm.2020.3025665\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c1fc76cc67ad82df1f7695b4d9e0b7536a70732\",\"title\":\"Universal-to-Specific Framework for Complex Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6c1fc76cc67ad82df1f7695b4d9e0b7536a70732\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144894381\",\"name\":\"A. S. Saif\"},{\"authorId\":\"89330614\",\"name\":\"Md. Akib Shahriar Khan\"},{\"authorId\":\"90906611\",\"name\":\"Abir Mohammad Hadi\"},{\"authorId\":\"89791973\",\"name\":\"Rahul Prashad Karmoker\"},{\"authorId\":\"91007847\",\"name\":\"Joy Julian Gomes\"}],\"doi\":\"10.5815/IJEME.2019.01.02\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d6dc9424b4a0fa5bbf556b984d67b21c5cd1dea3\",\"title\":\"Aggressive Action Estimation: A Comprehensive Review on Neural Network Based Human Segmentation and Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d6dc9424b4a0fa5bbf556b984d67b21c5cd1dea3\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48354916\",\"name\":\"Ze Chen\"},{\"authorId\":\"37514286\",\"name\":\"H. Lu\"}],\"doi\":\"10.1145/3297097.3297107\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f9fff8a34942053fd93760c8c84a40849b9db734\",\"title\":\"Recurrent Spatiotemporal Feature Learning for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f9fff8a34942053fd93760c8c84a40849b9db734\",\"venue\":\"ICRAI 2018\",\"year\":2018},{\"arxivId\":\"1810.11189\",\"authors\":[{\"authorId\":\"144469723\",\"name\":\"C. Zhu\"},{\"authorId\":\"145681036\",\"name\":\"Xiao Tan\"},{\"authorId\":\"145649748\",\"name\":\"F. Zhou\"},{\"authorId\":\"48033101\",\"name\":\"Xiao Liu\"},{\"authorId\":\"39826117\",\"name\":\"Kaiyu Yue\"},{\"authorId\":\"12081764\",\"name\":\"E. Ding\"},{\"authorId\":\"50032031\",\"name\":\"Yi Ma\"}],\"doi\":\"10.1007/978-3-030-01228-1_9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1102250a0fae62263979b32ad3c25749be9bca6b\",\"title\":\"Fine-Grained Video Categorization with Redundancy Reduction Attention\",\"url\":\"https://www.semanticscholar.org/paper/1102250a0fae62263979b32ad3c25749be9bca6b\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3258842\",\"name\":\"J. Wang\"},{\"authorId\":\"1788029\",\"name\":\"W. Wang\"},{\"authorId\":\"48385803\",\"name\":\"W. Gao\"}],\"doi\":\"10.1109/TMM.2018.2855081\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d3aba33ac0025d067bc3ed80d2d73ee883a1c2b1\",\"title\":\"Multiscale Deep Alternative Neural Network for Large-Scale Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/d3aba33ac0025d067bc3ed80d2d73ee883a1c2b1\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":\"1808.00022\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":\"10.1016/j.cviu.2019.102799\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ef7b835c451793a6ea603fa3d5441901832c404e\",\"title\":\"Analyzing human-human interactions: A survey\",\"url\":\"https://www.semanticscholar.org/paper/ef7b835c451793a6ea603fa3d5441901832c404e\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2019},{\"arxivId\":\"1812.05038\",\"authors\":[{\"authorId\":\"2978413\",\"name\":\"Chao-Yuan Wu\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"2681569\",\"name\":\"Haoqi Fan\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2562966\",\"name\":\"Philipp Kr\\u00e4henb\\u00fchl\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/CVPR.2019.00037\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"45cb2cbae5c0b4cc52e524cc191a2f8db674ed42\",\"title\":\"Long-Term Feature Banks for Detailed Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/45cb2cbae5c0b4cc52e524cc191a2f8db674ed42\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"81781019\",\"name\":\"Minho Shim\"},{\"authorId\":\"40832988\",\"name\":\"Y. H. Kim\"},{\"authorId\":\"32850725\",\"name\":\"Kyungmin Kim\"},{\"authorId\":\"1754380\",\"name\":\"S. Kim\"}],\"doi\":\"10.1007/978-3-030-01267-0_25\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"041115cb5509466f7449451709387268a008aba2\",\"title\":\"Teaching Machines to Understand Baseball Games: Large-Scale Baseball Video Database for Multiple Video Understanding Tasks\",\"url\":\"https://www.semanticscholar.org/paper/041115cb5509466f7449451709387268a008aba2\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48882412\",\"name\":\"Tasweer Ahmad\"},{\"authorId\":\"144838978\",\"name\":\"Lianwen Jin\"},{\"authorId\":\"153285152\",\"name\":\"J. Feng\"},{\"authorId\":\"153073573\",\"name\":\"Guozhi Tang\"}],\"doi\":\"10.1109/ACCESS.2019.2937344\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d3fd39dad90b6326b87f0bed5074b4885a013033\",\"title\":\"Human Action Recognition in Unconstrained Trimmed Videos Using Residual Attention Network and Joints Path Signature\",\"url\":\"https://www.semanticscholar.org/paper/d3fd39dad90b6326b87f0bed5074b4885a013033\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24702080\",\"name\":\"S. Tong\"},{\"authorId\":\"7727059\",\"name\":\"Yuzhuo Fu\"},{\"authorId\":\"9543601\",\"name\":\"Xinwei Yue\"},{\"authorId\":\"144125487\",\"name\":\"Hefei Ling\"}],\"doi\":\"10.1109/ACCESS.2018.2874073\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c3fbeda9cbce94bbc0d85494935ed27c49e8a0a6\",\"title\":\"Multi-View Gait Recognition Based on a Spatial-Temporal Deep Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/c3fbeda9cbce94bbc0d85494935ed27c49e8a0a6\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48033101\",\"name\":\"Xiao Liu\"},{\"authorId\":\"50030836\",\"name\":\"Xudong Yang\"}],\"doi\":\"10.1007/978-3-030-04167-0_23\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"caae04e73d362180f9586fabb224244200add105\",\"title\":\"Multi-stream with Deep Convolutional Neural Networks for Human Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/caae04e73d362180f9586fabb224244200add105\",\"venue\":\"ICONIP\",\"year\":2018},{\"arxivId\":\"1812.10071\",\"authors\":[{\"authorId\":\"41191188\",\"name\":\"Lin Sun\"},{\"authorId\":\"2370507\",\"name\":\"Kui Jia\"},{\"authorId\":\"48234805\",\"name\":\"Yuejia Shen\"},{\"authorId\":\"1702137\",\"name\":\"Silvio Savarese\"},{\"authorId\":\"1739816\",\"name\":\"Dit-Yan Yeung\"},{\"authorId\":\"2131088\",\"name\":\"Bertram Emil Shi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"073fabecf18f1421321f1961872b9842d913e4ee\",\"title\":\"Coupled Recurrent Network (CRN)\",\"url\":\"https://www.semanticscholar.org/paper/073fabecf18f1421321f1961872b9842d913e4ee\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1904.13080\",\"authors\":[{\"authorId\":\"145377162\",\"name\":\"Y. Yuan\"},{\"authorId\":\"49370704\",\"name\":\"Dong Wang\"},{\"authorId\":\"39669401\",\"name\":\"Q. Wang\"}],\"doi\":\"10.1609/aaai.v33i01.33019167\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e3fc2a67967b1355609094175f19b2412dd4851d\",\"title\":\"Memory-Augmented Temporal Dynamic Learning for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e3fc2a67967b1355609094175f19b2412dd4851d\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1711.08362\",\"authors\":[{\"authorId\":\"8120382\",\"name\":\"P. Wang\"},{\"authorId\":\"1685696\",\"name\":\"W. Li\"},{\"authorId\":\"1719314\",\"name\":\"P. Ogunbona\"},{\"authorId\":\"145121530\",\"name\":\"Jun Wan\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"}],\"doi\":\"10.1016/j.cviu.2018.04.007\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"224b34acba3597912f8adc288fa8adbb1fca92b4\",\"title\":\"RGB-D-based Human Motion Recognition with Deep Learning: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/224b34acba3597912f8adc288fa8adbb1fca92b4\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144388361\",\"name\":\"C. Li\"},{\"authorId\":\"1740430\",\"name\":\"B. Zhang\"},{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"1694936\",\"name\":\"Q. Ye\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"},{\"authorId\":\"1822413\",\"name\":\"Guodong Guo\"},{\"authorId\":\"145592288\",\"name\":\"Rongrong Ji\"}],\"doi\":\"10.1109/TIP.2019.2912357\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"cc68848151657035ffbd945d99106e8c52e15c20\",\"title\":\"Deep Manifold Structure Transfer for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cc68848151657035ffbd945d99106e8c52e15c20\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7496553\",\"name\":\"Dongli Wang\"},{\"authorId\":\"1724199\",\"name\":\"Jun Yang\"},{\"authorId\":\"46433441\",\"name\":\"Y. Zhou\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7a04144818f52def61cef3856cde3dd81b6dbaf8\",\"title\":\"Human action recognition based on multi-mode spatial-temporal feature fusion\",\"url\":\"https://www.semanticscholar.org/paper/7a04144818f52def61cef3856cde3dd81b6dbaf8\",\"venue\":\"2019 22th International Conference on Information Fusion (FUSION)\",\"year\":2019},{\"arxivId\":\"1806.06157\",\"authors\":[{\"authorId\":\"9943923\",\"name\":\"Fabien Baradel\"},{\"authorId\":\"2759569\",\"name\":\"N. Neverova\"},{\"authorId\":\"144899680\",\"name\":\"C. Wolf\"},{\"authorId\":\"1723242\",\"name\":\"J. Mille\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"}],\"doi\":\"10.1007/978-3-030-01261-8_7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"49615e80bac044b92d2edec8b053965e846486f2\",\"title\":\"Object Level Visual Reasoning in Videos\",\"url\":\"https://www.semanticscholar.org/paper/49615e80bac044b92d2edec8b053965e846486f2\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1805.06184\",\"authors\":[{\"authorId\":\"3358065\",\"name\":\"Xikun Zhang\"},{\"authorId\":\"48258751\",\"name\":\"Chang Xu\"},{\"authorId\":\"40434674\",\"name\":\"X. Tian\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/tnnls.2019.2935173\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c8ca7b5212f22981e2867e51f17b2987e61add52\",\"title\":\"Graph Edge Convolutional Neural Networks for Skeleton-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c8ca7b5212f22981e2867e51f17b2987e61add52\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"13088433\",\"name\":\"Mahshid Majd\"},{\"authorId\":\"1682051\",\"name\":\"R. Safabakhsh\"}],\"doi\":\"10.1007/s10489-018-1395-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c213ea6f39e3c595fc383b43ac9e813ce1c728ae\",\"title\":\"A motion-aware ConvLSTM network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/c213ea6f39e3c595fc383b43ac9e813ce1c728ae\",\"venue\":\"Applied Intelligence\",\"year\":2018},{\"arxivId\":\"2012.06567\",\"authors\":[{\"authorId\":\"1805946041\",\"name\":\"Yi Zhu\"},{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"49046944\",\"name\":\"C. Liu\"},{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"22539483\",\"name\":\"Chongruo Wu\"},{\"authorId\":\"152781163\",\"name\":\"Z. Zhang\"},{\"authorId\":\"2397422\",\"name\":\"Joseph Tighe\"},{\"authorId\":\"1758550\",\"name\":\"R. Manmatha\"},{\"authorId\":\"49140510\",\"name\":\"M. Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ee12f02830a5e1f7cadd3623dfed495cf099bc82\",\"title\":\"A Comprehensive Study of Deep Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ee12f02830a5e1f7cadd3623dfed495cf099bc82\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"13088433\",\"name\":\"Mahshid Majd\"},{\"authorId\":\"1682051\",\"name\":\"R. Safabakhsh\"}],\"doi\":\"10.1016/J.NEUCOM.2018.10.095\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9589c0a89cc807ab6269fff8258278af2b0902ba\",\"title\":\"Correlational Convolutional LSTM for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/9589c0a89cc807ab6269fff8258278af2b0902ba\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47637491\",\"name\":\"M. Lakhal\"},{\"authorId\":\"7840884\",\"name\":\"A. Clap\\u00e9s\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"},{\"authorId\":\"145440152\",\"name\":\"A. Cavallaro\"}],\"doi\":\"10.1007/978-3-030-11012-3_40\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d1a8e7c833318d30d30e3eeb0cef139f86a02bcc\",\"title\":\"Residual Stacked RNNs for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d1a8e7c833318d30d30e3eeb0cef139f86a02bcc\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153082819\",\"name\":\"Qian Li\"},{\"authorId\":\"1992684694\",\"name\":\"Wenzhu Yang\"},{\"authorId\":\"1992715817\",\"name\":\"Xiangyang Chen\"},{\"authorId\":\"50090639\",\"name\":\"Tongtong Yuan\"},{\"authorId\":null,\"name\":\"Yuxia Wang\"}],\"doi\":\"10.1109/ACCESS.2020.3027386\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"0475918d855bbfcf4c693359935d9a483b7541ce\",\"title\":\"Temporal Segment Connection Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/0475918d855bbfcf4c693359935d9a483b7541ce\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1805.02023\",\"authors\":[{\"authorId\":\"48378565\",\"name\":\"Yue Zhang\"},{\"authorId\":\"145889118\",\"name\":\"Jie Yang\"}],\"doi\":\"10.18653/v1/P18-1144\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8fb5a6fe93a3d19ffee50677c0ae563e3377d2d4\",\"title\":\"Chinese NER Using Lattice LSTM\",\"url\":\"https://www.semanticscholar.org/paper/8fb5a6fe93a3d19ffee50677c0ae563e3377d2d4\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":\"1802.07898\",\"authors\":[{\"authorId\":\"9943923\",\"name\":\"Fabien Baradel\"},{\"authorId\":\"144899680\",\"name\":\"C. Wolf\"},{\"authorId\":\"1723242\",\"name\":\"J. Mille\"},{\"authorId\":\"144639556\",\"name\":\"Graham W. Taylor\"}],\"doi\":\"10.1109/CVPR.2018.00056\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ab45ab887b7c1379bba4179579568296448d16d6\",\"title\":\"Glimpse Clouds: Human Activity Recognition from Unstructured Feature Points\",\"url\":\"https://www.semanticscholar.org/paper/ab45ab887b7c1379bba4179579568296448d16d6\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38796462\",\"name\":\"Imen Jegham\"},{\"authorId\":\"1741571899\",\"name\":\"Anouar Khalifa\"},{\"authorId\":\"2880991\",\"name\":\"Ihsen Alouani\"},{\"authorId\":\"1707715\",\"name\":\"M. Mahjoub\"}],\"doi\":\"10.1109/JSEN.2020.3019258\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d9a0b15d54ac277321736886312ddbc4607be032\",\"title\":\"Soft Spatial Attention-Based Multimodal Driver Action Recognition Using Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/d9a0b15d54ac277321736886312ddbc4607be032\",\"venue\":\"IEEE Sensors Journal\",\"year\":2021},{\"arxivId\":\"2004.04730\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"}],\"doi\":\"10.1109/cvpr42600.2020.00028\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"908cca0abefc35acc38033603714fbb1bcadc49d\",\"title\":\"X3D: Expanding Architectures for Efficient Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/908cca0abefc35acc38033603714fbb1bcadc49d\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020}],\"corpusId\":19673112,\"doi\":\"10.1109/ICCV.2017.236\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":7,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"f22d6d59e413ee255e5e0f2104f1e03be1a6722e\",\"references\":[{\"arxivId\":\"1212.0402\",\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"title\":\"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\",\"url\":\"https://www.semanticscholar.org/paper/da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2088368\",\"name\":\"F. Gers\"},{\"authorId\":\"1739396\",\"name\":\"N. N. Schraudolph\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1162/153244303768966139\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"047655e733a9eed9a500afd916efa566915b9110\",\"title\":\"Learning Precise Timing with LSTM Recurrent Networks\",\"url\":\"https://www.semanticscholar.org/paper/047655e733a9eed9a500afd916efa566915b9110\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2002},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1608.00859\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-319-46484-8_2\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"title\":\"Temporal Segment Networks: Towards Good Practices for Deep Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1511.04119\",\"authors\":[{\"authorId\":\"145478041\",\"name\":\"Shikhar Sharma\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7b8810ad8ef9ddd024583f95a51559e6c1b8c754\",\"title\":\"Action Recognition using Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/7b8810ad8ef9ddd024583f95a51559e6c1b8c754\",\"venue\":\"NIPS 2015\",\"year\":2015},{\"arxivId\":\"1405.4506\",\"authors\":[{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"39527134\",\"name\":\"X. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1016/j.cviu.2016.03.013\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"facbedfe90956c720f70aab14767b5e25dcc6478\",\"title\":\"Bag of visual words and fusion methods for action recognition: Comprehensive study and good practice\",\"url\":\"https://www.semanticscholar.org/paper/facbedfe90956c720f70aab14767b5e25dcc6478\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2016},{\"arxivId\":\"1311.2901\",\"authors\":[{\"authorId\":\"48799969\",\"name\":\"Matthew D. Zeiler\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":\"10.1007/978-3-319-10590-1_53\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1a2a770d23b4a171fa81de62a78a3deb0588f238\",\"title\":\"Visualizing and Understanding Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/1a2a770d23b4a171fa81de62a78a3deb0588f238\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"I. Sutskever A. Krizhevsky\"},{\"authorId\":null,\"name\":\"E. G.\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Hinton . ImageNet classification with deep convolutional neural networks\",\"url\":\"\",\"venue\":\"In NPIS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2013.441\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d721f4d64b8e722222c876f0a0f226ed49476347\",\"title\":\"Action Recognition with Improved Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/d721f4d64b8e722222c876f0a0f226ed49476347\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"H. Kuehne\"},{\"authorId\":null,\"name\":\"H. Jhuang\"},{\"authorId\":null,\"name\":\"E. Garrote\"},{\"authorId\":null,\"name\":\"T. Poggio\"},{\"authorId\":null,\"name\":\"T. Serre\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"ageNet classification with deep convolutional neural networks\",\"url\":\"\",\"venue\":\"\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3112334\",\"name\":\"Behrooz Mahasseni\"},{\"authorId\":\"143856428\",\"name\":\"S. Todorovic\"}],\"doi\":\"10.1109/CVPR.2016.333\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7854a9d1eaaac11047c22177b5ad5aa9ce2bf9e3\",\"title\":\"Regularizing Long Short Term Memory with 3D Human-Skeleton Sequences for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7854a9d1eaaac11047c22177b5ad5aa9ce2bf9e3\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/ICCV.2015.510\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"title\":\"Learning Spatiotemporal Features with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1611.02155\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5f4d2f6ad967f7c9369c04e75cda08f12cb8afbd\",\"title\":\"Spatiotemporal Residual Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5f4d2f6ad967f7c9369c04e75cda08f12cb8afbd\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1411.4038\",\"authors\":[{\"authorId\":\"1782282\",\"name\":\"Evan Shelhamer\"},{\"authorId\":\"144361581\",\"name\":\"J. Long\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2572683\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"317aee7fc081f2b137a85c4f20129007fd8e717e\",\"title\":\"Fully Convolutional Networks for Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/317aee7fc081f2b137a85c4f20129007fd8e717e\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":\"1510.00562\",\"authors\":[{\"authorId\":\"41191188\",\"name\":\"Lin Sun\"},{\"authorId\":\"2370507\",\"name\":\"K. Jia\"},{\"authorId\":\"1739816\",\"name\":\"D. Yeung\"},{\"authorId\":\"2131088\",\"name\":\"B. Shi\"}],\"doi\":\"10.1109/ICCV.2015.522\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"95561aec9f00cdf5346e627574e1a022eda3e4f5\",\"title\":\"Human Action Recognition Using Factorized Spatio-Temporal Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/95561aec9f00cdf5346e627574e1a022eda3e4f5\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"M. Elad\"},{\"authorId\":null,\"name\":\"M. Aharon\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"ognizing action at a distance\",\"url\":\"\",\"venue\":\"\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8131625\",\"name\":\"W. Lin\"},{\"authorId\":\"144463557\",\"name\":\"M. Sun\"},{\"authorId\":\"144786412\",\"name\":\"R. Poovendran\"},{\"authorId\":\"1809184\",\"name\":\"Z. Zhang\"}],\"doi\":\"10.1109/ISCAS.2008.4542023\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"458528488b290ec9f8eb1dc3bb5c6722ffff1815\",\"title\":\"Human activity recognition for video surveillance\",\"url\":\"https://www.semanticscholar.org/paper/458528488b290ec9f8eb1dc3bb5c6722ffff1815\",\"venue\":\"2008 IEEE International Symposium on Circuits and Systems\",\"year\":2008},{\"arxivId\":\"1506.04214\",\"authors\":[{\"authorId\":\"3008587\",\"name\":\"Xingjian Shi\"},{\"authorId\":\"2192200\",\"name\":\"Zhourong Chen\"},{\"authorId\":\"49528584\",\"name\":\"Hao Wang\"},{\"authorId\":\"1739816\",\"name\":\"D. Yeung\"},{\"authorId\":\"145771919\",\"name\":\"W. Wong\"},{\"authorId\":\"2183294\",\"name\":\"Wang-chun Woo\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f9c990b1b5724e50e5632b94fdb7484ece8a6ce7\",\"title\":\"Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting\",\"url\":\"https://www.semanticscholar.org/paper/f9c990b1b5724e50e5632b94fdb7484ece8a6ce7\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1502.04681\",\"authors\":[{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"2711409\",\"name\":\"Elman Mansimov\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"title\":\"Unsupervised Learning of Video Representations using LSTMs\",\"url\":\"https://www.semanticscholar.org/paper/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2341854\",\"name\":\"M. Baccouche\"},{\"authorId\":\"2408697\",\"name\":\"F. Mamalet\"},{\"authorId\":\"144899680\",\"name\":\"C. Wolf\"},{\"authorId\":\"144723337\",\"name\":\"C. Garcia\"},{\"authorId\":\"1739898\",\"name\":\"A. Baskurt\"}],\"doi\":\"10.1007/978-3-642-25446-8_4\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"12b6551a0f9f5aa62f7d37f03ebc66631e529c4b\",\"title\":\"Sequential Deep Learning for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/12b6551a0f9f5aa62f7d37f03ebc66631e529c4b\",\"venue\":\"HBU\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1713941\",\"name\":\"Christopher Zach\"},{\"authorId\":\"1730097\",\"name\":\"T. Pock\"},{\"authorId\":\"144746444\",\"name\":\"H. Bischof\"}],\"doi\":\"10.1007/978-3-540-74936-3_22\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"0f6bbe9afab5fd61f36de5461e9e6a30ca462c7c\",\"title\":\"A Duality Based Approach for Realtime TV-L1 Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/0f6bbe9afab5fd61f36de5461e9e6a30ca462c7c\",\"venue\":\"DAGM-Symposium\",\"year\":2007},{\"arxivId\":\"1406.2199\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"title\":\"Two-Stream Convolutional Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1162/neco.1997.9.8.1735\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"title\":\"Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"venue\":\"Neural Computation\",\"year\":1997},{\"arxivId\":\"1505.04868\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1109/CVPR.2015.7299059\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"df658828fb4146877f1031ec9d07052f7eb31186\",\"title\":\"Action recognition with trajectory-pooled deep-convolutional descriptors\",\"url\":\"https://www.semanticscholar.org/paper/df658828fb4146877f1031ec9d07052f7eb31186\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1503.08909\",\"authors\":[{\"authorId\":\"2340579\",\"name\":\"J. Ng\"},{\"authorId\":\"3308897\",\"name\":\"Matthew J. Hausknecht\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"49519592\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"3089272\",\"name\":\"Rajat Monga\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"}],\"doi\":\"10.1109/CVPR.2015.7299101\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5418b2a482720e013d487a385c26fae0f017c6a6\",\"title\":\"Beyond short snippets: Deep networks for video classification\",\"url\":\"https://www.semanticscholar.org/paper/5418b2a482720e013d487a385c26fae0f017c6a6\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"1742248\",\"name\":\"P. Moulin\"},{\"authorId\":\"1795291\",\"name\":\"X. Yang\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"}],\"doi\":\"10.1109/CVPR.2015.7298993\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f467c60a2b3373018c3615f9f6d77611dff89826\",\"title\":\"Motion Part Regularization: Improving action recognition via trajectory group selection\",\"url\":\"https://www.semanticscholar.org/paper/f467c60a2b3373018c3615f9f6d77611dff89826\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Pinz C. Feichtenhofer\"},{\"authorId\":null,\"name\":\"A.\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Zisserman . Convolutional twostream network fusion for video action recognition\",\"url\":\"\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Krizhevsky\"},{\"authorId\":null,\"name\":\"I. Sutskever\"},{\"authorId\":null,\"name\":\"G. E. Hinton\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"ageNet classification with deep convolutional neural networks\",\"url\":\"\",\"venue\":\"In NPIS\",\"year\":2012},{\"arxivId\":\"1607.01794\",\"authors\":[{\"authorId\":\"3245057\",\"name\":\"Zhenyang Li\"},{\"authorId\":\"32781361\",\"name\":\"Kirill Gavrilyuk\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"143798882\",\"name\":\"Mihir Jain\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1016/j.cviu.2017.10.011\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"86031f555c128b82a1ac0db89ff4faeae16a1802\",\"title\":\"VideoLSTM convolves, attends and flows for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/86031f555c128b82a1ac0db89ff4faeae16a1802\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2018},{\"arxivId\":\"1502.03167\",\"authors\":[{\"authorId\":\"144147316\",\"name\":\"S. Ioffe\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d376d6978dad0374edfa6709c9556b42d3594d3\",\"title\":\"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\",\"url\":\"https://www.semanticscholar.org/paper/4d376d6978dad0374edfa6709c9556b42d3594d3\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1604.06573\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2016.213\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9d9aced120e530484609164c836da64548693484\",\"title\":\"Convolutional Two-Stream Network Fusion for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9d9aced120e530484609164c836da64548693484\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"119268487\",\"name\":\"Hueihan Jhuang\"},{\"authorId\":\"1930964\",\"name\":\"E. Garrote\"},{\"authorId\":\"145031878\",\"name\":\"T. Poggio\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"}],\"doi\":\"10.1109/ICCV.2011.6126543\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8b3b8848a311c501e704c45c6d50430ab7068956\",\"title\":\"HMDB: A large video database for human motion recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b3b8848a311c501e704c45c6d50430ab7068956\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145177088\",\"name\":\"David Stutz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"21c64ab3d340390c493534fcb2c6b06124e3d794\",\"title\":\"Neural Codes for Image Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/21c64ab3d340390c493534fcb2c6b06124e3d794\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1610.05256\",\"authors\":[{\"authorId\":\"145814376\",\"name\":\"Wayne Xiong\"},{\"authorId\":\"1755472\",\"name\":\"J. Droppo\"},{\"authorId\":\"144531812\",\"name\":\"Xuedong Huang\"},{\"authorId\":\"1745715\",\"name\":\"F. Seide\"},{\"authorId\":\"36896383\",\"name\":\"Mike Seltzer\"},{\"authorId\":\"1762744\",\"name\":\"A. Stolcke\"},{\"authorId\":\"144580027\",\"name\":\"Dong Yu\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"579e0077a3810510a7965224a8782ecc01766ea0\",\"title\":\"Achieving Human Parity in Conversational Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/579e0077a3810510a7965224a8782ecc01766ea0\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"47680287\",\"name\":\"W. Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2009.5206848\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1b47265245e8db53a553049dcb27ed3e495fd625\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/1b47265245e8db53a553049dcb27ed3e495fd625\",\"venue\":\"CVPR 2009\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1680740\",\"name\":\"Huibin Li\"},{\"authorId\":\"144238414\",\"name\":\"Feng Liu\"}],\"doi\":\"10.1109/ICIG.2009.101\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"485a729d22806303e070adcacb591219012bcf9d\",\"title\":\"Image Denoising Via Sparse and Redundant Representations Over Learned Dictionaries in Wavelet Domain\",\"url\":\"https://www.semanticscholar.org/paper/485a729d22806303e070adcacb591219012bcf9d\",\"venue\":\"2009 Fifth International Conference on Image and Graphics\",\"year\":2009},{\"arxivId\":\"1604.07669\",\"authors\":[{\"authorId\":\"3047890\",\"name\":\"Bowen Zhang\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"}],\"doi\":\"10.1109/CVPR.2016.297\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3d4cf68fad61cd7dc9061670ba3864a7fdf87d4c\",\"title\":\"Real-Time Action Recognition with Enhanced Motion Vector CNNs\",\"url\":\"https://www.semanticscholar.org/paper/3d4cf68fad61cd7dc9061670ba3864a7fdf87d4c\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144361581\",\"name\":\"J. Long\"},{\"authorId\":\"1782282\",\"name\":\"Evan Shelhamer\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/CVPR.2015.7298965\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9201bf6f8222c2335913002e13fbac640fc0f4ec\",\"title\":\"Fully convolutional networks for semantic segmentation\",\"url\":\"https://www.semanticscholar.org/paper/9201bf6f8222c2335913002e13fbac640fc0f4ec\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1753908\",\"name\":\"Michael Elad\"},{\"authorId\":\"40622051\",\"name\":\"M. Aharon\"}],\"doi\":\"10.1109/TIP.2006.881969\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e07416eabd4ba6c69fa473756bb04ae7161177be\",\"title\":\"Image Denoising Via Sparse and Redundant Representations Over Learned Dictionaries\",\"url\":\"https://www.semanticscholar.org/paper/e07416eabd4ba6c69fa473756bb04ae7161177be\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/ICCV.2003.1238420\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"804d86dd7ab3498266922244e73a88c1add5a6ab\",\"title\":\"Recognizing action at a distance\",\"url\":\"https://www.semanticscholar.org/paper/804d86dd7ab3498266922244e73a88c1add5a6ab\",\"venue\":\"Proceedings Ninth IEEE International Conference on Computer Vision\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"2111981\",\"name\":\"Jos\\u00e9 Oramas\"},{\"authorId\":\"3060081\",\"name\":\"A. Ghodrati\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"}],\"doi\":\"10.1109/CVPR.2015.7299176\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5443a1b18fed3173dc426735ff9f486194185172\",\"title\":\"Modeling video evolution for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/5443a1b18fed3173dc426735ff9f486194185172\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"152821938\",\"name\":\"Sanketh Shetty\"},{\"authorId\":\"120906511\",\"name\":\"T. Leung\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2014.223\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"title\":\"Large-Scale Video Classification with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1910299\",\"name\":\"Oren Boiman\"},{\"authorId\":\"144611617\",\"name\":\"M. Irani\"}],\"doi\":\"10.1007/s11263-006-0009-9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"86078efdd0d1bbfaf4b7f821e973f607429751fc\",\"title\":\"Detecting Irregularities in Images and in Video\",\"url\":\"https://www.semanticscholar.org/paper/86078efdd0d1bbfaf4b7f821e973f607429751fc\",\"venue\":\"Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1\",\"year\":2005}],\"title\":\"Lattice Long Short-Term Memory for Human Action Recognition\",\"topics\":[{\"topic\":\"Long short-term memory\",\"topicId\":\"117199\",\"url\":\"https://www.semanticscholar.org/topic/117199\"},{\"topic\":\"Optical flow\",\"topicId\":\"26430\",\"url\":\"https://www.semanticscholar.org/topic/26430\"},{\"topic\":\"Stationary process\",\"topicId\":\"21296\",\"url\":\"https://www.semanticscholar.org/topic/21296\"},{\"topic\":\"Quantum superposition\",\"topicId\":\"380827\",\"url\":\"https://www.semanticscholar.org/topic/380827\"},{\"topic\":\"Recurrent neural network\",\"topicId\":\"16115\",\"url\":\"https://www.semanticscholar.org/topic/16115\"},{\"topic\":\"Convolutional neural network\",\"topicId\":\"29860\",\"url\":\"https://www.semanticscholar.org/topic/29860\"},{\"topic\":\"Complex network\",\"topicId\":\"13725\",\"url\":\"https://www.semanticscholar.org/topic/13725\"},{\"topic\":\"Video content analysis\",\"topicId\":\"98626\",\"url\":\"https://www.semanticscholar.org/topic/98626\"},{\"topic\":\"End-to-end encryption\",\"topicId\":\"854929\",\"url\":\"https://www.semanticscholar.org/topic/854929\"},{\"topic\":\"Memory cell (binary)\",\"topicId\":\"221667\",\"url\":\"https://www.semanticscholar.org/topic/221667\"},{\"topic\":\"End system\",\"topicId\":\"517951\",\"url\":\"https://www.semanticscholar.org/topic/517951\"},{\"topic\":\"Entity\",\"topicId\":\"6664\",\"url\":\"https://www.semanticscholar.org/topic/6664\"},{\"topic\":\"Sampling (signal processing)\",\"topicId\":\"7839\",\"url\":\"https://www.semanticscholar.org/topic/7839\"},{\"topic\":\"Modal logic\",\"topicId\":\"61528\",\"url\":\"https://www.semanticscholar.org/topic/61528\"},{\"topic\":\"Map\",\"topicId\":\"2392\",\"url\":\"https://www.semanticscholar.org/topic/2392\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"},{\"topic\":\"Action potential\",\"topicId\":\"343\",\"url\":\"https://www.semanticscholar.org/topic/343\"}],\"url\":\"https://www.semanticscholar.org/paper/f22d6d59e413ee255e5e0f2104f1e03be1a6722e\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017}\n"