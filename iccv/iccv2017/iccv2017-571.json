"{\"abstract\":\"We present a novel method to realistically puppeteer and animate a face from a single RGB image using a source video sequence. We begin by fitting a multilinear PCA model to obtain the 3D geometry and a single texture of the target face. In order for the animation to be realistic, however, we need dynamic per-frame textures that capture subtle wrinkles and deformations corresponding to the animated facial expressions. This problem is highly undercon-strained, as dynamic textures cannot be obtained directly from a single image. Furthermore, if the target face has a closed mouth, it is not possible to obtain actual images of the mouth interior. To address this issue, we train a Deep Generative Network that can infer realistic per-frame texture deformations, including the mouth interior, of the target identity using the per-frame source textures and the single target texture. By retargeting the PCA expression geometry from the source, as well as using the newly inferred texture, we can both animate the face and perform video face replacement on the source video using the target appearance.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"38376240\",\"name\":\"Kyle Olszewski\",\"url\":\"https://www.semanticscholar.org/author/38376240\"},{\"authorId\":\"2825680\",\"name\":\"Zimo Li\",\"url\":\"https://www.semanticscholar.org/author/2825680\"},{\"authorId\":\"40055538\",\"name\":\"C. Yang\",\"url\":\"https://www.semanticscholar.org/author/40055538\"},{\"authorId\":null,\"name\":\"Yi Zhou\",\"url\":null},{\"authorId\":\"9965153\",\"name\":\"Ronald Yu\",\"url\":\"https://www.semanticscholar.org/author/9965153\"},{\"authorId\":\"145554741\",\"name\":\"Zeng Huang\",\"url\":\"https://www.semanticscholar.org/author/145554741\"},{\"authorId\":\"10745567\",\"name\":\"Sitao Xiang\",\"url\":\"https://www.semanticscholar.org/author/10745567\"},{\"authorId\":\"2059597\",\"name\":\"S. Saito\",\"url\":\"https://www.semanticscholar.org/author/2059597\"},{\"authorId\":\"143967473\",\"name\":\"P. Kohli\",\"url\":\"https://www.semanticscholar.org/author/143967473\"},{\"authorId\":\"1706574\",\"name\":\"Hao Li\",\"url\":\"https://www.semanticscholar.org/author/1706574\"}],\"citationVelocity\":16,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"50488872\",\"name\":\"R. Yi\"},{\"authorId\":\"7818093\",\"name\":\"Zipeng Ye\"},{\"authorId\":\"2938279\",\"name\":\"J. Zhang\"},{\"authorId\":\"1679542\",\"name\":\"H. Bao\"},{\"authorId\":\"46398687\",\"name\":\"Yongjin Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d76d7102edb5668cf425af1e806375b5a01dab33\",\"title\":\"Audio-driven Talking Face Video Generation with Natural Head Pose\",\"url\":\"https://www.semanticscholar.org/paper/d76d7102edb5668cf425af1e806375b5a01dab33\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"88026659\",\"name\":\"T. Ma\"},{\"authorId\":\"49121187\",\"name\":\"B. Peng\"},{\"authorId\":\"46315010\",\"name\":\"W. Wang\"},{\"authorId\":\"143863957\",\"name\":\"J. Dong\"}],\"doi\":\"10.1109/APSIPAASC47483.2019.9023328\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"96077b4fdb828b09cfce969d7da037ebeccb41f7\",\"title\":\"Any-to-one Face Reenactment Based on Conditional Generative Adversarial Network\",\"url\":\"https://www.semanticscholar.org/paper/96077b4fdb828b09cfce969d7da037ebeccb41f7\",\"venue\":\"2019 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48096253\",\"name\":\"Long Zhao\"},{\"authorId\":\"144152346\",\"name\":\"Xi Peng\"},{\"authorId\":\"144978989\",\"name\":\"Y. Tian\"},{\"authorId\":\"1379758006\",\"name\":\"Mubbasir Kapadia\"},{\"authorId\":\"1711560\",\"name\":\"D. Metaxas\"}],\"doi\":\"10.1007/s11263-020-01328-9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f0ca9eb353e33e37e725a8f89bd07ca1fc09a285\",\"title\":\"Towards Image-to-Video Translation: A Structure-Aware Approach via Multi-stage Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/f0ca9eb353e33e37e725a8f89bd07ca1fc09a285\",\"venue\":\"International Journal of Computer Vision\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51112121\",\"name\":\"S. Zaied\"},{\"authorId\":\"1704722\",\"name\":\"Catherine Soladi\\u00e9\"},{\"authorId\":\"31112783\",\"name\":\"P. Richard\"}],\"doi\":\"10.1007/978-3-030-30645-8_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a87a73b922b0e0aa887bef7ee4f872f87eeb9918\",\"title\":\"Personalized Expression Synthesis Using a Hybrid Geometric-Machine Learning Method\",\"url\":\"https://www.semanticscholar.org/paper/a87a73b922b0e0aa887bef7ee4f872f87eeb9918\",\"venue\":\"ICIAP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49192783\",\"name\":\"Lingzhi Li\"},{\"authorId\":\"9324504\",\"name\":\"Jian-min Bao\"},{\"authorId\":\"102320235\",\"name\":\"Hao Yang\"},{\"authorId\":\"144230587\",\"name\":\"D. Chen\"},{\"authorId\":\"1716835\",\"name\":\"Fang Wen\"}],\"doi\":\"10.1109/cvpr42600.2020.00512\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"4f842a92c110f40e9187bc9e6544b5dcb1daa5f3\",\"title\":\"Advancing High Fidelity Identity Swapping for Forgery Detection\",\"url\":\"https://www.semanticscholar.org/paper/4f842a92c110f40e9187bc9e6544b5dcb1daa5f3\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1712.03534\",\"authors\":[{\"authorId\":\"2017906\",\"name\":\"Wissam J. Baddar\"},{\"authorId\":\"2707832\",\"name\":\"Geonmo Gu\"},{\"authorId\":\"2909533\",\"name\":\"S. Lee\"},{\"authorId\":\"7251290\",\"name\":\"Yong Man Ro\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"deb0cbced8a5986e0771209cf786b0ebdedc119d\",\"title\":\"Dynamics Transfer GAN: Generating Video by Transferring Arbitrary Temporal Dynamics from a Source Video to a Single Target Image\",\"url\":\"https://www.semanticscholar.org/paper/deb0cbced8a5986e0771209cf786b0ebdedc119d\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1803.07716\",\"authors\":[{\"authorId\":\"3069144\",\"name\":\"H. X. Pham\"},{\"authorId\":\"32141165\",\"name\":\"Y. Wang\"},{\"authorId\":\"144658464\",\"name\":\"V. Pavlovic\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a45c0cd7f089718e52bbb75bddcb1fdfeb49c4d6\",\"title\":\"Generative Adversarial Talking Head: Bringing Portraits to Life with a Weakly Supervised Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/a45c0cd7f089718e52bbb75bddcb1fdfeb49c4d6\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1905.12043\",\"authors\":[{\"authorId\":\"50383147\",\"name\":\"M. Doukas\"},{\"authorId\":\"1790503\",\"name\":\"V. Sharmanska\"},{\"authorId\":\"1776444\",\"name\":\"S. Zafeiriou\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a2f7e7adbbd2326c7ac7cbb67fa43214108bb372\",\"title\":\"Video-to-Video Translation for Visual Speech Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/a2f7e7adbbd2326c7ac7cbb67fa43214108bb372\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144436744\",\"name\":\"Tao Hu\"},{\"authorId\":\"143869239\",\"name\":\"Chao Liang\"},{\"authorId\":\"1410621160\",\"name\":\"G. Min\"},{\"authorId\":\"153141874\",\"name\":\"Keqin Li\"},{\"authorId\":\"2420700\",\"name\":\"Chunxia Xiao\"}],\"doi\":\"10.1016/j.jvcir.2020.102812\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f6602d8147380dfa3ba8d44662541f033de995c1\",\"title\":\"Generating video animation from single still image in social media based on intelligent computing\",\"url\":\"https://www.semanticscholar.org/paper/f6602d8147380dfa3ba8d44662541f033de995c1\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35756782\",\"name\":\"Jascha Achenbach\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d355214394ddb71d289770284151da71fb6428c\",\"title\":\"Generation of Virtual Humans for Virtual Reality, Medicine, and Domestic Assistance\",\"url\":\"https://www.semanticscholar.org/paper/0d355214394ddb71d289770284151da71fb6428c\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2011.15126\",\"authors\":[{\"authorId\":\"2195314\",\"name\":\"T. Wang\"},{\"authorId\":\"36508529\",\"name\":\"Arun Mallya\"},{\"authorId\":\"1596793949\",\"name\":\"M. Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"88f8974f6f9bc2febfb88ed3ffe12dfc9c441808\",\"title\":\"One-Shot Free-View Neural Talking-Head Synthesis for Video Conferencing\",\"url\":\"https://www.semanticscholar.org/paper/88f8974f6f9bc2febfb88ed3ffe12dfc9c441808\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1906.01524\",\"authors\":[{\"authorId\":\"2416503\",\"name\":\"Ohad Fried\"},{\"authorId\":\"9102722\",\"name\":\"A. Tewari\"},{\"authorId\":\"1699058\",\"name\":\"M. Zollh\\u00f6fer\"},{\"authorId\":\"37737599\",\"name\":\"Adam Finkelstein\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"1976171\",\"name\":\"D. Goldman\"},{\"authorId\":\"32627314\",\"name\":\"Kyle Genova\"},{\"authorId\":\"2165582\",\"name\":\"Zeyu Jin\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"},{\"authorId\":\"1820412\",\"name\":\"M. Agrawala\"}],\"doi\":\"10.1145/3306346.3323028\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"9058988a3078721d4d634961970923bc9ab4b416\",\"title\":\"Text-based editing of talking-head video\",\"url\":\"https://www.semanticscholar.org/paper/9058988a3078721d4d634961970923bc9ab4b416\",\"venue\":\"ACM Trans. Graph.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1740556351\",\"name\":\"Jianwei Fei\"},{\"authorId\":\"47660205\",\"name\":\"Zhihua Xia\"},{\"authorId\":\"1423733566\",\"name\":\"Peipeng Yu\"},{\"authorId\":\"1740545873\",\"name\":\"Fengjun Xiao\"}],\"doi\":\"10.1007/s11042-020-09147-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5bea408b58d44d8fe05dba09aea0a999be6e5ee0\",\"title\":\"Exposing AI-generated videos with motion magnification\",\"url\":\"https://www.semanticscholar.org/paper/5bea408b58d44d8fe05dba09aea0a999be6e5ee0\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"2007.06759\",\"authors\":[{\"authorId\":\"25022309\",\"name\":\"B. Chaudhuri\"},{\"authorId\":\"3407986\",\"name\":\"Noranart Vesdapunt\"},{\"authorId\":\"1809809\",\"name\":\"L. Shapiro\"},{\"authorId\":\"2450889\",\"name\":\"B. Wang\"}],\"doi\":\"10.1007/978-3-030-58558-7_9\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5c9dbe60474a33884f2f8e481be34e8584f95c3e\",\"title\":\"Personalized Face Modeling for Improved Face Reconstruction and Motion Retargeting\",\"url\":\"https://www.semanticscholar.org/paper/5c9dbe60474a33884f2f8e481be34e8584f95c3e\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1908.04338\",\"authors\":[{\"authorId\":\"51358562\",\"name\":\"John Kanji\"},{\"authorId\":\"143774460\",\"name\":\"D. Levin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"91ebf7275a4cc630e41f494b1ac1a16764fdfa6d\",\"title\":\"Convolutional Humanoid Animation via Deformation\",\"url\":\"https://www.semanticscholar.org/paper/91ebf7275a4cc630e41f494b1ac1a16764fdfa6d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1902.09225\",\"authors\":[{\"authorId\":\"31273037\",\"name\":\"Soochan Lee\"},{\"authorId\":\"36078919\",\"name\":\"J. Ha\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0dc02a63400c4f1899c952afdc620479238abedf\",\"title\":\"Harmonizing Maximum Likelihood with GANs for Multimodal Conditional Generation\",\"url\":\"https://www.semanticscholar.org/paper/0dc02a63400c4f1899c952afdc620479238abedf\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1805.11714\",\"authors\":[{\"authorId\":\"3022958\",\"name\":\"H. Kim\"},{\"authorId\":\"39912094\",\"name\":\"P. Garrido\"},{\"authorId\":\"9102722\",\"name\":\"A. Tewari\"},{\"authorId\":\"9765909\",\"name\":\"Weipeng Xu\"},{\"authorId\":\"34105638\",\"name\":\"Justus Thies\"},{\"authorId\":\"2209612\",\"name\":\"M. Nie\\u00dfner\"},{\"authorId\":\"144565371\",\"name\":\"P. P\\u00e9rez\"},{\"authorId\":\"1819028\",\"name\":\"C. Richardt\"},{\"authorId\":\"1699058\",\"name\":\"M. Zollh\\u00f6fer\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"}],\"doi\":\"10.1145/3197517.3201283\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"efb0a4574736a976b6dc3c23be45e5fc0ac6fe41\",\"title\":\"Deep video portraits\",\"url\":\"https://www.semanticscholar.org/paper/efb0a4574736a976b6dc3c23be45e5fc0ac6fe41\",\"venue\":\"ACM Trans. Graph.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31123128\",\"name\":\"Y. Zhao\"},{\"authorId\":\"2848440\",\"name\":\"Meshia C\\u00e9dric Oveneke\"},{\"authorId\":\"48219791\",\"name\":\"Dongmei Jiang\"},{\"authorId\":\"48077408\",\"name\":\"H. Sahli\"}],\"doi\":\"10.1007/s11042-018-6952-y\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6880855cfe631cbd2cbe2df98ff99ef9ddf77c0e\",\"title\":\"A video prediction approach for animating single face image\",\"url\":\"https://www.semanticscholar.org/paper/6880855cfe631cbd2cbe2df98ff99ef9ddf77c0e\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1792471\",\"name\":\"Lingyu Wei\"},{\"authorId\":\"144698110\",\"name\":\"L. Hu\"},{\"authorId\":\"3082383\",\"name\":\"Vladimir G. Kim\"},{\"authorId\":\"8020964\",\"name\":\"Ersin Yumer\"},{\"authorId\":\"1706574\",\"name\":\"Hao Li\"}],\"doi\":\"10.1007/978-3-030-01225-0_7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e325a601a74dca181382a81d1ef2e280729f112a\",\"title\":\"Real-Time Hair Rendering Using Sequential Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/e325a601a74dca181382a81d1ef2e280729f112a\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21697786\",\"name\":\"Zhenglin Geng\"},{\"authorId\":\"143773131\",\"name\":\"C. Cao\"},{\"authorId\":\"145582202\",\"name\":\"S. Tulyakov\"}],\"doi\":\"10.1007/s11263-020-01361-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"57fb5abab8a90a22d46f014d184471046b2dcab4\",\"title\":\"Towards Photo-Realistic Facial Expression Manipulation\",\"url\":\"https://www.semanticscholar.org/paper/57fb5abab8a90a22d46f014d184471046b2dcab4\",\"venue\":\"Int. J. Comput. Vis.\",\"year\":2020},{\"arxivId\":\"2001.04775\",\"authors\":[{\"authorId\":\"38142162\",\"name\":\"A. Richard\"},{\"authorId\":\"7991149\",\"name\":\"Ian Cherabier\"},{\"authorId\":\"1821761\",\"name\":\"M. Oswald\"},{\"authorId\":\"3011006\",\"name\":\"Vagia Tsiminaki\"},{\"authorId\":\"1742208\",\"name\":\"M. Pollefeys\"},{\"authorId\":\"144810819\",\"name\":\"K. Schindler\"}],\"doi\":\"10.1109/3DV.2019.00065\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"63e40140810a8829931dc533d47c09b6c17e5d1d\",\"title\":\"Learned Multi-View Texture Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/63e40140810a8829931dc533d47c09b6c17e5d1d\",\"venue\":\"2019 International Conference on 3D Vision (3DV)\",\"year\":2019},{\"arxivId\":\"1807.09951\",\"authors\":[{\"authorId\":\"48096253\",\"name\":\"Long Zhao\"},{\"authorId\":\"144152346\",\"name\":\"Xi Peng\"},{\"authorId\":\"6812347\",\"name\":\"Yu Tian\"},{\"authorId\":\"143980996\",\"name\":\"Mubbasir Kapadia\"},{\"authorId\":\"1711560\",\"name\":\"D. Metaxas\"}],\"doi\":\"10.1007/978-3-030-01267-0_24\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ec5cdb68fa5a1dc011c9df01e45a0a1c4d59d110\",\"title\":\"Learning to Forecast and Refine Residual Motion for Image-to-Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/ec5cdb68fa5a1dc011c9df01e45a0a1c4d59d110\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2008.02793\",\"authors\":[{\"authorId\":\"1596793949\",\"name\":\"M. Liu\"},{\"authorId\":\"47932904\",\"name\":\"Xun Huang\"},{\"authorId\":\"150167366\",\"name\":\"Jiahui Yu\"},{\"authorId\":\"2195314\",\"name\":\"T. Wang\"},{\"authorId\":\"36508529\",\"name\":\"Arun Mallya\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"555e7029e8fd3b759300edfd2a4b7dfa2fd34a48\",\"title\":\"Generative Adversarial Networks for Image and Video Synthesis: Algorithms and Applications\",\"url\":\"https://www.semanticscholar.org/paper/555e7029e8fd3b759300edfd2a4b7dfa2fd34a48\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48390722\",\"name\":\"Gong Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f128ca4614fdb69ddf89870ca6fd6f975da885f1\",\"title\":\"Artificial intelligence in music : composition and emotion\",\"url\":\"https://www.semanticscholar.org/paper/f128ca4614fdb69ddf89870ca6fd6f975da885f1\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2007.01466\",\"authors\":[{\"authorId\":\"145331259\",\"name\":\"Meng Cao\"},{\"authorId\":\"2711717\",\"name\":\"Haozhi Huang\"},{\"authorId\":\"3705643\",\"name\":\"H. Wang\"},{\"authorId\":null,\"name\":\"Xuan Wang\"},{\"authorId\":\"152148573\",\"name\":\"L. Shen\"},{\"authorId\":\"94385031\",\"name\":\"Sd Wang\"},{\"authorId\":\"2780029\",\"name\":\"Linchao Bao\"},{\"authorId\":\"9247990\",\"name\":\"Zhifeng Li\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ff13757be71ff9deae63150b5572158eb394aa9c\",\"title\":\"Task-agnostic Temporally Consistent Facial Video Editing\",\"url\":\"https://www.semanticscholar.org/paper/ff13757be71ff9deae63150b5572158eb394aa9c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.12452\",\"authors\":[{\"authorId\":\"10745567\",\"name\":\"Sitao Xiang\"},{\"authorId\":\"49986481\",\"name\":\"Yu-ming Gu\"},{\"authorId\":\"31044670\",\"name\":\"P. Xiang\"},{\"authorId\":\"4938340\",\"name\":\"Mingming He\"},{\"authorId\":\"1897417\",\"name\":\"K. Nagano\"},{\"authorId\":\"47666365\",\"name\":\"H. Chen\"},{\"authorId\":\"2733405\",\"name\":\"H. Li\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"37e8ac88190fef3de23c1f441e25b0944e2d9dfa\",\"title\":\"One-Shot Identity-Preserving Portrait Reenactment\",\"url\":\"https://www.semanticscholar.org/paper/37e8ac88190fef3de23c1f441e25b0944e2d9dfa\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2209436\",\"name\":\"M. Planck\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"5542100d280eb670a72b3431fe5155256bafb96e\",\"title\":\"Text-based Editing of Talking-head Video\",\"url\":\"https://www.semanticscholar.org/paper/5542100d280eb670a72b3431fe5155256bafb96e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1801.07632\",\"authors\":[{\"authorId\":\"5478513\",\"name\":\"Zeyuan Chen\"},{\"authorId\":\"35557488\",\"name\":\"Shaoliang Nie\"},{\"authorId\":\"47353858\",\"name\":\"Tianfu Wu\"},{\"authorId\":\"1748811\",\"name\":\"Christopher G. Healey\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c8fc81a54ccef6d8111e7253283fc55e7e0f8ebd\",\"title\":\"High Resolution Face Completion with Multiple Controllable Attributes via Fully End-to-End Progressive Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/c8fc81a54ccef6d8111e7253283fc55e7e0f8ebd\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1409848027\",\"name\":\"Chaoyue Wang\"},{\"authorId\":\"145371957\",\"name\":\"Chang Xu\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/TAI.2020.3031581\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f8ad1580246c895760198888ff7c0ee0237114f7\",\"title\":\"Self-Supervised Pose Adaptation for Cross-Domain Image Animation\",\"url\":\"https://www.semanticscholar.org/paper/f8ad1580246c895760198888ff7c0ee0237114f7\",\"venue\":\"IEEE Transactions on Artificial Intelligence\",\"year\":2020},{\"arxivId\":\"1808.03417\",\"authors\":[{\"authorId\":\"2074378\",\"name\":\"Z. L\\u00e4hner\"},{\"authorId\":\"1695302\",\"name\":\"D. Cremers\"},{\"authorId\":\"144139707\",\"name\":\"Tony Tung\"}],\"doi\":\"10.1007/978-3-030-01225-0_41\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"07974aa8a0824d24bd6582d18e7d542cb86a9921\",\"title\":\"DeepWrinkles: Accurate and Realistic Clothing Modeling\",\"url\":\"https://www.semanticscholar.org/paper/07974aa8a0824d24bd6582d18e7d542cb86a9921\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153275560\",\"name\":\"Jiahao Geng\"},{\"authorId\":\"34620893\",\"name\":\"T. Shao\"},{\"authorId\":\"3049304\",\"name\":\"Youyi Zheng\"},{\"authorId\":\"143663883\",\"name\":\"Y. Weng\"},{\"authorId\":\"144078074\",\"name\":\"K. Zhou\"}],\"doi\":\"10.1145/3272127.3275043\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"59c654d13b3e228a15e83853d23b85dce106f994\",\"title\":\"Warp-guided GANs for single-photo facial animation\",\"url\":\"https://www.semanticscholar.org/paper/59c654d13b3e228a15e83853d23b85dce106f994\",\"venue\":\"ACM Trans. Graph.\",\"year\":2018},{\"arxivId\":\"1912.06253\",\"authors\":[{\"authorId\":\"40389846\",\"name\":\"Chao Yang\"},{\"authorId\":\"38760573\",\"name\":\"Ser-Nam Lim\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"945d53fa3b31ff1f0b52855daa16e9959887a9e3\",\"title\":\"Unconstrained Facial Expression Transfer using Style-based Generator\",\"url\":\"https://www.semanticscholar.org/paper/945d53fa3b31ff1f0b52855daa16e9959887a9e3\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1807.10550\",\"authors\":[{\"authorId\":\"8792285\",\"name\":\"Olivia Wiles\"},{\"authorId\":\"32445716\",\"name\":\"A. Koepke\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/978-3-030-01261-8_41\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9ea992f009492888c482d5f4006281eaa8b758e7\",\"title\":\"X2Face: A network for controlling face generation by using images, audio, and pose codes\",\"url\":\"https://www.semanticscholar.org/paper/9ea992f009492888c482d5f4006281eaa8b758e7\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2002.10137\",\"authors\":[{\"authorId\":\"50488872\",\"name\":\"R. Yi\"},{\"authorId\":\"7818093\",\"name\":\"Zipeng Ye\"},{\"authorId\":\"2938279\",\"name\":\"J. Zhang\"},{\"authorId\":\"1679542\",\"name\":\"H. Bao\"},{\"authorId\":\"46398687\",\"name\":\"Yongjin Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bec253e82076dc363b8fd72d5c8fadf8f5b7e475\",\"title\":\"Audio-driven Talking Face Video Generation with Learning-based Personalized Head Pose\",\"url\":\"https://www.semanticscholar.org/paper/bec253e82076dc363b8fd72d5c8fadf8f5b7e475\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1761320\",\"name\":\"Xueping Wang\"},{\"authorId\":null,\"name\":\"Weixin Li\"},{\"authorId\":\"37626783\",\"name\":\"Guodong Mu\"},{\"authorId\":\"40119164\",\"name\":\"D. Huang\"},{\"authorId\":\"40013375\",\"name\":\"Y. Wang\"}],\"doi\":\"10.1145/3206025.3206068\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a961f1234e963a7945fed70197015678149b37d8\",\"title\":\"Facial Expression Synthesis by U-Net Conditional Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/a961f1234e963a7945fed70197015678149b37d8\",\"venue\":\"ICMR\",\"year\":2018},{\"arxivId\":\"2004.11138\",\"authors\":[{\"authorId\":\"2934352\",\"name\":\"Yisroel Mirsky\"},{\"authorId\":\"49627181\",\"name\":\"W. Lee\"}],\"doi\":\"10.1145/3425780\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"92b4c8deecee703569b9e909dfb88aa70e691219\",\"title\":\"The Creation and Detection of Deepfakes: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/92b4c8deecee703569b9e909dfb88aa70e691219\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3117231\",\"name\":\"Shugo Yamaguchi\"},{\"authorId\":\"2059597\",\"name\":\"S. Saito\"},{\"authorId\":\"1897417\",\"name\":\"K. Nagano\"},{\"authorId\":\"2613340\",\"name\":\"Yajie Zhao\"},{\"authorId\":\"2535947\",\"name\":\"Weikai Chen\"},{\"authorId\":\"38376240\",\"name\":\"Kyle Olszewski\"},{\"authorId\":\"1731030\",\"name\":\"S. Morishima\"},{\"authorId\":\"1706574\",\"name\":\"Hao Li\"}],\"doi\":\"10.1145/3197517.3201364\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d5909f8d82bff4b86cc36ecd000f251c1a76293b\",\"title\":\"High-fidelity facial reflectance and geometry inference from an unconstrained image\",\"url\":\"https://www.semanticscholar.org/paper/d5909f8d82bff4b86cc36ecd000f251c1a76293b\",\"venue\":\"ACM Trans. Graph.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1882695\",\"name\":\"X. Wang\"},{\"authorId\":null,\"name\":\"Yunhong Wang\"},{\"authorId\":null,\"name\":\"Weixin Li\"}],\"doi\":\"10.1145/3355397\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"012c9b12d74285bb49014597e97e87a01f6da6e6\",\"title\":\"U-Net Conditional GANs for Photo-Realistic and Identity-Preserving Facial Expression Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/012c9b12d74285bb49014597e97e87a01f6da6e6\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1912.13457\",\"authors\":[{\"authorId\":\"49192783\",\"name\":\"Lingzhi Li\"},{\"authorId\":\"3093568\",\"name\":\"Jianmin Bao\"},{\"authorId\":\"102320235\",\"name\":\"Hao Yang\"},{\"authorId\":\"153642240\",\"name\":\"Dong Chen\"},{\"authorId\":\"1716835\",\"name\":\"Fang Wen\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"67c6afafc43f7fda5e2aea7db77e86aa95955517\",\"title\":\"FaceShifter: Towards High Fidelity And Occlusion Aware Face Swapping\",\"url\":\"https://www.semanticscholar.org/paper/67c6afafc43f7fda5e2aea7db77e86aa95955517\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49901552\",\"name\":\"Gong Chen\"},{\"authorId\":\"47909587\",\"name\":\"Y. Liu\"},{\"authorId\":\"2812440\",\"name\":\"S. Zhong\"},{\"authorId\":\"46447747\",\"name\":\"X. Zhang\"}],\"doi\":\"10.1145/3240508.3240604\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f9cd1278bda3f3db4b08a5908916d15b842eb47e\",\"title\":\"Musicality-Novelty Generative Adversarial Nets for Algorithmic Composition\",\"url\":\"https://www.semanticscholar.org/paper/f9cd1278bda3f3db4b08a5908916d15b842eb47e\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"2005.10954\",\"authors\":[{\"authorId\":\"46193344\",\"name\":\"Mohammad Rami Koujan\"},{\"authorId\":\"50383147\",\"name\":\"M. Doukas\"},{\"authorId\":\"2931390\",\"name\":\"A. Roussos\"},{\"authorId\":\"1379747201\",\"name\":\"S. Zafeiriou\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e4a787b7177fec50da643a662a57db64ccc91ffc\",\"title\":\"Head2Head: Video-based Neural Head Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/e4a787b7177fec50da643a662a57db64ccc91ffc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"48f3640cbf9747083a07790a9c7a8089f9131cbd\",\"title\":\"HARMONIZING MAXIMUM LIKELIHOOD WITH GANS\",\"url\":\"https://www.semanticscholar.org/paper/48f3640cbf9747083a07790a9c7a8089f9131cbd\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2004.06848\",\"authors\":[{\"authorId\":\"38376240\",\"name\":\"Kyle Olszewski\"},{\"authorId\":\"39686979\",\"name\":\"D. Ceylan\"},{\"authorId\":\"46951242\",\"name\":\"Jun Xing\"},{\"authorId\":\"80452718\",\"name\":\"J. Echevarria\"},{\"authorId\":\"46842761\",\"name\":\"Zhili Chen\"},{\"authorId\":\"2535947\",\"name\":\"Weikai Chen\"},{\"authorId\":\"2733405\",\"name\":\"H. Li\"}],\"doi\":\"10.1109/cvpr42600.2020.00747\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2fefb62c09b34aac789dff28daacab83cba4463f\",\"title\":\"Intuitive, Interactive Beard and Hair Synthesis With Generative Models\",\"url\":\"https://www.semanticscholar.org/paper/2fefb62c09b34aac789dff28daacab83cba4463f\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2003.12869\",\"authors\":[{\"authorId\":\"143702938\",\"name\":\"C. Yang\"},{\"authorId\":\"38760573\",\"name\":\"Ser-Nam Lim\"}],\"doi\":\"10.1109/cvpr42600.2020.00596\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"342c11f5cea38a7d628e99febe82c1c6aad1027f\",\"title\":\"One-Shot Domain Adaptation for Face Generation\",\"url\":\"https://www.semanticscholar.org/paper/342c11f5cea38a7d628e99febe82c1c6aad1027f\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1804.08020\",\"authors\":[{\"authorId\":\"2181480\",\"name\":\"S. Golestaneh\"},{\"authorId\":\"47209857\",\"name\":\"Lina Karam\"}],\"doi\":\"10.1109/CVPRW.2018.00117\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7721389fbcf24e0440c52286af8503df377c6f2e\",\"title\":\"Synthesized Texture Quality Assessment via Multi-scale Spatial and Statistical Texture Attributes of Image and Gradient Magnitude Coefficients\",\"url\":\"https://www.semanticscholar.org/paper/7721389fbcf24e0440c52286af8503df377c6f2e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1897417\",\"name\":\"K. Nagano\"},{\"authorId\":\"2567921\",\"name\":\"Jaewoo Seo\"},{\"authorId\":\"144521811\",\"name\":\"J. Xing\"},{\"authorId\":\"1792471\",\"name\":\"Lingyu Wei\"},{\"authorId\":\"2825680\",\"name\":\"Zimo Li\"},{\"authorId\":\"2059597\",\"name\":\"S. Saito\"},{\"authorId\":\"51153125\",\"name\":\"Aviral Agarwal\"},{\"authorId\":\"2112520\",\"name\":\"Jens Fursund\"},{\"authorId\":\"46178891\",\"name\":\"H. Li\"}],\"doi\":\"10.1145/3272127.3275075\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"38bb99d876d91dbd5b2223de55c271e2b3d39f4d\",\"title\":\"paGAN: real-time avatars using dynamic textures\",\"url\":\"https://www.semanticscholar.org/paper/38bb99d876d91dbd5b2223de55c271e2b3d39f4d\",\"venue\":\"ACM Trans. Graph.\",\"year\":2018},{\"arxivId\":\"1712.03474\",\"authors\":[{\"authorId\":\"3051419\",\"name\":\"Lingxiao Song\"},{\"authorId\":\"9702077\",\"name\":\"Zhihe Lu\"},{\"authorId\":\"143712929\",\"name\":\"R. He\"},{\"authorId\":\"1757186\",\"name\":\"Z. Sun\"},{\"authorId\":\"143874948\",\"name\":\"T. Tan\"}],\"doi\":\"10.1145/3240508.3240612\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f879556115284946637992191563849e840789d1\",\"title\":\"Geometry Guided Adversarial Facial Expression Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/f879556115284946637992191563849e840789d1\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1807.07860\",\"authors\":[{\"authorId\":\"145798292\",\"name\":\"Hang Zhou\"},{\"authorId\":\"40457380\",\"name\":\"Y. Liu\"},{\"authorId\":\"3243969\",\"name\":\"Z. Liu\"},{\"authorId\":\"47571885\",\"name\":\"Ping Luo\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1609/aaai.v33i01.33019299\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1816f98e2a4dd54690c2689cf529699d8843e847\",\"title\":\"Talking Face Generation by Adversarially Disentangled Audio-Visual Representation\",\"url\":\"https://www.semanticscholar.org/paper/1816f98e2a4dd54690c2689cf529699d8843e847\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1912.06265\",\"authors\":[{\"authorId\":\"40389846\",\"name\":\"Chao Yang\"},{\"authorId\":\"49544204\",\"name\":\"Xiao-Feng Liu\"},{\"authorId\":\"49264864\",\"name\":\"Qingming Tang\"},{\"authorId\":\"9363144\",\"name\":\"C.-C. Jay Kuo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6f39341aa091cf9a968a6f0a1740fa529be1c5f4\",\"title\":\"Towards Disentangled Representations for Human Retargeting by Multi-view Learning\",\"url\":\"https://www.semanticscholar.org/paper/6f39341aa091cf9a968a6f0a1740fa529be1c5f4\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"14947926\",\"name\":\"Lingchen Yang\"},{\"authorId\":\"120077579\",\"name\":\"Zefeng Shi\"},{\"authorId\":\"1633041812\",\"name\":\"Yiqian Wu\"},{\"authorId\":\"2028660481\",\"name\":\"Xiang Li\"},{\"authorId\":\"144078054\",\"name\":\"Kun Zhou\"},{\"authorId\":\"3169698\",\"name\":\"Hongbo Fu\"},{\"authorId\":\"3049304\",\"name\":\"Youyi Zheng\"}],\"doi\":\"10.1145/3414685.3417771\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ee6806eb495197f39ef2b50c6fdc5041ce2fdd66\",\"title\":\"iOrthoPredictor: model-guided deep prediction of teeth alignment\",\"url\":\"https://www.semanticscholar.org/paper/ee6806eb495197f39ef2b50c6fdc5041ce2fdd66\",\"venue\":\"ACM Trans. Graph.\",\"year\":2020}],\"corpusId\":8309990,\"doi\":\"10.1109/ICCV.2017.580\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":4,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"4b0bcc134dbcf89abad55beecf9358bacc463544\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"33846296\",\"name\":\"Chenglei Wu\"},{\"authorId\":\"143929823\",\"name\":\"D. Bradley\"},{\"authorId\":\"39912094\",\"name\":\"P. Garrido\"},{\"authorId\":\"1699058\",\"name\":\"M. Zollh\\u00f6fer\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"},{\"authorId\":\"144877478\",\"name\":\"M. Gross\"},{\"authorId\":\"2486770\",\"name\":\"T. Beeler\"}],\"doi\":\"10.1145/2980179.2980233\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"90e0b93e049509bf9058206cce945a4cc2fcc150\",\"title\":\"Model-based teeth reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/90e0b93e049509bf9058206cce945a4cc2fcc150\",\"venue\":\"ACM Trans. Graph.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144039941\",\"name\":\"K. Dale\"},{\"authorId\":\"2454127\",\"name\":\"Kalyan Sunkavalli\"},{\"authorId\":\"13594727\",\"name\":\"Micah K. Johnson\"},{\"authorId\":\"1880628\",\"name\":\"D. Vlasic\"},{\"authorId\":\"1752521\",\"name\":\"W. Matusik\"},{\"authorId\":\"143758236\",\"name\":\"H. Pfister\"}],\"doi\":\"10.1145/2024156.2024164\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f326fd805ae74f3773c5eda789aee890b59cc1fb\",\"title\":\"Video face replacement\",\"url\":\"https://www.semanticscholar.org/paper/f326fd805ae74f3773c5eda789aee890b59cc1fb\",\"venue\":\"SA '11\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1681442\",\"name\":\"Ce Liu\"},{\"authorId\":\"143738177\",\"name\":\"J. Yuen\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"}],\"doi\":\"10.1007/978-3-540-88690-7_3\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ae01610370105f87eeb0d4a90aa723c43f4393bc\",\"title\":\"SIFT Flow: Dense Correspondence across Different Scenes\",\"url\":\"https://www.semanticscholar.org/paper/ae01610370105f87eeb0d4a90aa723c43f4393bc\",\"venue\":\"ECCV\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143636342\",\"name\":\"Sarah L. Taylor\"},{\"authorId\":\"30303590\",\"name\":\"M. Mahler\"},{\"authorId\":\"2785748\",\"name\":\"B. Theobald\"},{\"authorId\":\"1711695\",\"name\":\"I. Matthews\"}],\"doi\":\"10.2312/SCA/SCA12/275-284\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"910bb564f42f298898c1831e6650b1f2efa07b42\",\"title\":\"Dynamic units of visual speech\",\"url\":\"https://www.semanticscholar.org/paper/910bb564f42f298898c1831e6650b1f2efa07b42\",\"venue\":\"SCA '12\",\"year\":2012},{\"arxivId\":\"1604.04382\",\"authors\":[{\"authorId\":\"153228286\",\"name\":\"Chuan Li\"},{\"authorId\":\"1723149\",\"name\":\"M. Wand\"}],\"doi\":\"10.1007/978-3-319-46487-9_43\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"102a2096ba2e2947dc252445f764e7583b557680\",\"title\":\"Precomputed Real-Time Texture Synthesis with Markovian Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/102a2096ba2e2947dc252445f764e7583b557680\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3139470\",\"name\":\"Aleksey Golovinskiy\"},{\"authorId\":\"1752521\",\"name\":\"W. Matusik\"},{\"authorId\":\"143758236\",\"name\":\"H. Pfister\"},{\"authorId\":\"7723706\",\"name\":\"S. Rusinkiewicz\"},{\"authorId\":\"1807080\",\"name\":\"T. Funkhouser\"}],\"doi\":\"10.1145/1179352.1141988\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"468d43be850151291002b1ef48d2f68072053140\",\"title\":\"A statistical model for synthesis of detailed facial geometry\",\"url\":\"https://www.semanticscholar.org/paper/468d43be850151291002b1ef48d2f68072053140\",\"venue\":\"SIGGRAPH '06\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1706355\",\"name\":\"Vivek Kwatra\"},{\"authorId\":\"39685930\",\"name\":\"A. Sch\\u00f6dl\"},{\"authorId\":\"21472040\",\"name\":\"Irfan Essa\"},{\"authorId\":\"1713189\",\"name\":\"Greg Turk\"},{\"authorId\":\"1688328\",\"name\":\"A. Bobick\"}],\"doi\":\"10.1145/1201775.882264\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"55c3ecb47aebba55a9de761c0e4dc0fd6d8d28b0\",\"title\":\"Graphcut textures: image and video synthesis using graph cuts\",\"url\":\"https://www.semanticscholar.org/paper/55c3ecb47aebba55a9de761c0e4dc0fd6d8d28b0\",\"venue\":\"SIGGRAPH '03\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143773131\",\"name\":\"C. Cao\"},{\"authorId\":\"143663883\",\"name\":\"Y. Weng\"},{\"authorId\":\"14547116\",\"name\":\"S. Zhou\"},{\"authorId\":\"3225345\",\"name\":\"Y. Tong\"},{\"authorId\":\"48918534\",\"name\":\"K. Zhou\"}],\"doi\":\"10.1109/TVCG.2013.249\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"df3a207258f3febb98d3dcaf890e8a0f09cd5c12\",\"title\":\"FaceWarehouse: A 3D Facial Expression Database for Visual Computing\",\"url\":\"https://www.semanticscholar.org/paper/df3a207258f3febb98d3dcaf890e8a0f09cd5c12\",\"venue\":\"IEEE Transactions on Visualization and Computer Graphics\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32176501\",\"name\":\"E. Chuang\"},{\"authorId\":\"2428034\",\"name\":\"C. Bregler\"}],\"doi\":\"10.1145/1061347.1061355\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cd7615670f22dee78c72cf6bb03a0126f2bc9fba\",\"title\":\"Mood swings: expressive speech animation\",\"url\":\"https://www.semanticscholar.org/paper/cd7615670f22dee78c72cf6bb03a0126f2bc9fba\",\"venue\":\"TOGS\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145722155\",\"name\":\"Bo Fan\"},{\"authorId\":\"40476154\",\"name\":\"Lijuan Wang\"},{\"authorId\":\"1705574\",\"name\":\"F. Soong\"},{\"authorId\":\"144206968\",\"name\":\"L. Xie\"}],\"doi\":\"10.1109/ICASSP.2015.7178899\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8c028b86f5551757becd4c4304bddebb49e880b3\",\"title\":\"Photo-real talking head with deep bidirectional LSTM\",\"url\":\"https://www.semanticscholar.org/paper/8c028b86f5551757becd4c4304bddebb49e880b3\",\"venue\":\"2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2015},{\"arxivId\":\"1506.00752\",\"authors\":[{\"authorId\":\"37016781\",\"name\":\"Supasorn Suwajanakorn\"},{\"authorId\":\"1397689071\",\"name\":\"Ira Kemelmacher-Shlizerman\"},{\"authorId\":\"1679223\",\"name\":\"S. Seitz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9adefd986898ed9735921843f9a8f47f7e351fe2\",\"title\":\"What Makes Kevin Spacey Look Like Kevin Spacey\",\"url\":\"https://www.semanticscholar.org/paper/9adefd986898ed9735921843f9a8f47f7e351fe2\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"M Mirza\"},{\"authorId\":null,\"name\":\"S Osindero\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Conditional generative adversarial nets. CoRR, abs/1411.1784\",\"url\":\"\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Harvard sentences\",\"url\":\"\",\"venue\":\"\",\"year\":1969},{\"arxivId\":\"1612.00523\",\"authors\":[{\"authorId\":\"2059597\",\"name\":\"S. Saito\"},{\"authorId\":\"1792471\",\"name\":\"Lingyu Wei\"},{\"authorId\":\"144698110\",\"name\":\"L. Hu\"},{\"authorId\":\"1897417\",\"name\":\"K. Nagano\"},{\"authorId\":\"1706574\",\"name\":\"Hao Li\"}],\"doi\":\"10.1109/CVPR.2017.250\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"77be5aea43bb3c32314f5f07672bf833d53d3b6b\",\"title\":\"Photorealistic Facial Texture Inference Using Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/77be5aea43bb3c32314f5f07672bf833d53d3b6b\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1403025868\",\"name\":\"Jean Pouget-Abadie\"},{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"144738865\",\"name\":\"Bing Xu\"},{\"authorId\":\"1393680089\",\"name\":\"David Warde-Farley\"},{\"authorId\":\"1955694\",\"name\":\"Sherjil Ozair\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"title\":\"Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152782371\",\"name\":\"P. Edwards\"},{\"authorId\":\"2483922\",\"name\":\"C. Landreth\"},{\"authorId\":\"3018043\",\"name\":\"E. Fiume\"},{\"authorId\":\"34664064\",\"name\":\"Karan Singh\"}],\"doi\":\"10.1145/2897824.2925984\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"339e662f4a9489e7f5910bc2b047ba86b0f3b7a5\",\"title\":\"JALI: an animator-centric viseme model for expressive lip synchronization\",\"url\":\"https://www.semanticscholar.org/paper/339e662f4a9489e7f5910bc2b047ba86b0f3b7a5\",\"venue\":\"ACM Trans. Graph.\",\"year\":2016},{\"arxivId\":\"1611.07004\",\"authors\":[{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"1822702\",\"name\":\"Tinghui Zhou\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1109/CVPR.2017.632\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"8acbe90d5b852dadea7810345451a99608ee54c7\",\"title\":\"Image-to-Image Translation with Conditional Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/8acbe90d5b852dadea7810345451a99608ee54c7\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2626422\",\"name\":\"V. Kazemi\"},{\"authorId\":\"50626295\",\"name\":\"J. Sullivan\"}],\"doi\":\"10.1109/CVPR.2014.241\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d78b6a5b0dcaa81b1faea5fb0000045a62513567\",\"title\":\"One millisecond face alignment with an ensemble of regression trees\",\"url\":\"https://www.semanticscholar.org/paper/d78b6a5b0dcaa81b1faea5fb0000045a62513567\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144097660\",\"name\":\"M. Turk\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"71d67283157475c4e6460c52408c00e9f6b8d2fe\",\"title\":\"A morphable model for the synthesis of 3D faces\",\"url\":\"https://www.semanticscholar.org/paper/71d67283157475c4e6460c52408c00e9f6b8d2fe\",\"venue\":\"SIGGRAPH 1999\",\"year\":1999},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J.-Y. Zhu P. Isola\"},{\"authorId\":null,\"name\":\"A. A.\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Efros . Imagetoimage translation with conditional adversarial networks\",\"url\":\"\",\"venue\":\"arxiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2428034\",\"name\":\"C. Bregler\"},{\"authorId\":\"1800748\",\"name\":\"M. Covell\"},{\"authorId\":\"145290352\",\"name\":\"M. Slaney\"}],\"doi\":\"10.1145/258734.258880\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3a78995510cf33edf0ee4265abe23ffdc55986cb\",\"title\":\"Video Rewrite: driving visual speech with audio\",\"url\":\"https://www.semanticscholar.org/paper/3a78995510cf33edf0ee4265abe23ffdc55986cb\",\"venue\":\"SIGGRAPH '97\",\"year\":1997},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1681442\",\"name\":\"Ce Liu\"},{\"authorId\":\"144154486\",\"name\":\"H. Shum\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"}],\"doi\":\"10.1007/s11263-006-0029-5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c0e5ebcfa7fd20fa688e6623fdd0dfd5eefc2fad\",\"title\":\"Face Hallucination: Theory and Practice\",\"url\":\"https://www.semanticscholar.org/paper/c0e5ebcfa7fd20fa688e6623fdd0dfd5eefc2fad\",\"venue\":\"International Journal of Computer Vision\",\"year\":2006},{\"arxivId\":\"1611.09577\",\"authors\":[{\"authorId\":\"46400982\",\"name\":\"I. Korshunova\"},{\"authorId\":\"2700496\",\"name\":\"W. Shi\"},{\"authorId\":\"2309489\",\"name\":\"J. Dambre\"},{\"authorId\":\"2073063\",\"name\":\"L. Theis\"}],\"doi\":\"10.1109/ICCV.2017.397\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fd57b5ae466b43f60f1539159891426b5c7f06bd\",\"title\":\"Fast Face-Swap Using Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/fd57b5ae466b43f60f1539159891426b5c7f06bd\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24339276\",\"name\":\"Jon Gauthier\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"42f6f5454dda99d8989f9814989efd50fe807ee8\",\"title\":\"Conditional generative adversarial nets for convolutional face generation\",\"url\":\"https://www.semanticscholar.org/paper/42f6f5454dda99d8989f9814989efd50fe807ee8\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144091198\",\"name\":\"U. Mohammed\"},{\"authorId\":\"144827387\",\"name\":\"S. Prince\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":\"10.1145/1576246.1531363\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e263962c5365333817890e667d08cb4d263dd146\",\"title\":\"Visio-lization: generating novel facial images\",\"url\":\"https://www.semanticscholar.org/paper/e263962c5365333817890e667d08cb4d263dd146\",\"venue\":\"ACM Trans. Graph.\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36436218\",\"name\":\"S. Laine\"},{\"authorId\":\"2976930\",\"name\":\"Tero Karras\"},{\"authorId\":\"1761103\",\"name\":\"Timo Aila\"},{\"authorId\":\"3468872\",\"name\":\"Antti Herva\"},{\"authorId\":\"49244945\",\"name\":\"J. Lehtinen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e6beec2db218e1e8b53033025df9ce982a877719\",\"title\":\"Facial Performance Capture with Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/e6beec2db218e1e8b53033025df9ce982a877719\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145691100\",\"name\":\"K. Wampler\"},{\"authorId\":\"46672137\",\"name\":\"Daichi Sasaki\"},{\"authorId\":\"47059221\",\"name\":\"L. Zhang\"},{\"authorId\":\"1986848\",\"name\":\"Z. Popovic\"}],\"doi\":\"10.2312/SCA/SCA07/053-062\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eec9e6b3198c92059403b66cb2629c7305f4c983\",\"title\":\"Dynamic, expressive speech animation from a single mesh\",\"url\":\"https://www.semanticscholar.org/paper/eec9e6b3198c92059403b66cb2629c7305f4c983\",\"venue\":\"SCA '07\",\"year\":2007},{\"arxivId\":\"1411.1784\",\"authors\":[{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"2217144\",\"name\":\"Simon Osindero\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"353ecf7b66b3e9ff5e9f41145a147e899a2eea5c\",\"title\":\"Conditional Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/353ecf7b66b3e9ff5e9f41145a147e899a2eea5c\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39912094\",\"name\":\"P. Garrido\"},{\"authorId\":\"1797649\",\"name\":\"Levi Valgaerts\"},{\"authorId\":\"33846296\",\"name\":\"Chenglei Wu\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"}],\"doi\":\"10.1145/2508363.2508380\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"976208323fd68f403e3d7c66f66d39f8788fe24c\",\"title\":\"Reconstructing detailed dynamic face geometry from monocular video\",\"url\":\"https://www.semanticscholar.org/paper/976208323fd68f403e3d7c66f66d39f8788fe24c\",\"venue\":\"ACM Trans. Graph.\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1681442\",\"name\":\"Ce Liu\"},{\"authorId\":\"143738177\",\"name\":\"J. Yuen\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/TPAMI.2010.147\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"af14da35d7fd12d182b10594027232489c6a8b51\",\"title\":\"SIFT Flow: Dense Correspondence across Scenes and Its Applications\",\"url\":\"https://www.semanticscholar.org/paper/af14da35d7fd12d182b10594027232489c6a8b51\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2011},{\"arxivId\":\"1611.09969\",\"authors\":[{\"authorId\":\"143702938\",\"name\":\"C. Yang\"},{\"authorId\":\"144834702\",\"name\":\"X. Lu\"},{\"authorId\":\"145527707\",\"name\":\"Zhe L. Lin\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"47520207\",\"name\":\"O. Wang\"},{\"authorId\":\"2733405\",\"name\":\"H. Li\"}],\"doi\":\"10.1109/CVPR.2017.434\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3b9bfdeeb9ac6ada5a5833b1f179cb97f3e6804b\",\"title\":\"High-Resolution Image Inpainting Using Multi-scale Neural Patch Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/3b9bfdeeb9ac6ada5a5833b1f179cb97f3e6804b\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143773131\",\"name\":\"C. Cao\"},{\"authorId\":\"144863596\",\"name\":\"D. Bradley\"},{\"authorId\":\"48918534\",\"name\":\"K. Zhou\"},{\"authorId\":\"2486770\",\"name\":\"T. Beeler\"}],\"doi\":\"10.1145/2766943\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bd671b6dc3394682048a7053bed20eff9691414c\",\"title\":\"Real-time high-fidelity facial performance capture\",\"url\":\"https://www.semanticscholar.org/paper/bd671b6dc3394682048a7053bed20eff9691414c\",\"venue\":\"ACM Trans. Graph.\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39912094\",\"name\":\"P. Garrido\"},{\"authorId\":\"1797649\",\"name\":\"Levi Valgaerts\"},{\"authorId\":\"1401658974\",\"name\":\"Hamid Sarmadi\"},{\"authorId\":\"41178028\",\"name\":\"I. Steiner\"},{\"authorId\":\"13640633\",\"name\":\"K. Varanasi\"},{\"authorId\":\"144565371\",\"name\":\"P. P\\u00e9rez\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"}],\"doi\":\"10.1111/cgf.12552\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8128fb68dc94c086ba213a28ac132e53eb8da02a\",\"title\":\"VDub: Modifying Face Video of Actors for Plausible Visual Alignment to a Dubbed Audio Track\",\"url\":\"https://www.semanticscholar.org/paper/8128fb68dc94c086ba213a28ac132e53eb8da02a\",\"venue\":\"Comput. Graph. Forum\",\"year\":2015},{\"arxivId\":\"1602.02651\",\"authors\":[{\"authorId\":\"39912094\",\"name\":\"P. Garrido\"},{\"authorId\":\"1797649\",\"name\":\"Levi Valgaerts\"},{\"authorId\":\"2020396\",\"name\":\"Ole Rehmsen\"},{\"authorId\":\"2543070\",\"name\":\"Thorsten Thorm\\u00e4hlen\"},{\"authorId\":\"144565371\",\"name\":\"P. P\\u00e9rez\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"}],\"doi\":\"10.1109/CVPR.2014.537\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a285f7d80e47b05ebff83387424cd0df8cb7833d\",\"title\":\"Automatic Face Reenactment\",\"url\":\"https://www.semanticscholar.org/paper/a285f7d80e47b05ebff83387424cd0df8cb7833d\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"2007.14808\",\"authors\":[{\"authorId\":\"34105638\",\"name\":\"Justus Thies\"},{\"authorId\":\"1699058\",\"name\":\"M. Zollh\\u00f6fer\"},{\"authorId\":\"144140066\",\"name\":\"M. Stamminger\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"},{\"authorId\":\"2209612\",\"name\":\"M. Nie\\u00dfner\"}],\"doi\":\"10.1145/3292039\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"bd52d94dd51b131519bbf22641f334e72e5ad3da\",\"title\":\"Face2Face: real-time face capture and reenactment of RGB videos\",\"url\":\"https://www.semanticscholar.org/paper/bd52d94dd51b131519bbf22641f334e72e5ad3da\",\"venue\":\"Commun. ACM\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38376240\",\"name\":\"Kyle Olszewski\"},{\"authorId\":\"35198686\",\"name\":\"Joseph J. Lim\"},{\"authorId\":\"2059597\",\"name\":\"S. Saito\"},{\"authorId\":\"1706574\",\"name\":\"Hao Li\"}],\"doi\":\"10.1145/2980179.2980252\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7f7c8dd0d2a4de4a75880ee5b382f9bccd63488f\",\"title\":\"High-fidelity facial and speech animation for VR HMDs\",\"url\":\"https://www.semanticscholar.org/paper/7f7c8dd0d2a4de4a75880ee5b382f9bccd63488f\",\"venue\":\"ACM Trans. Graph.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2116817\",\"name\":\"Charles Malleson\"},{\"authorId\":\"31798873\",\"name\":\"J. Bazin\"},{\"authorId\":\"47520207\",\"name\":\"O. Wang\"},{\"authorId\":\"144863596\",\"name\":\"D. Bradley\"},{\"authorId\":\"2486770\",\"name\":\"T. Beeler\"},{\"authorId\":\"144046599\",\"name\":\"A. Hilton\"},{\"authorId\":\"1388791172\",\"name\":\"Alexander Sorkine-Hornung\"}],\"doi\":\"10.1109/ICCV.2015.453\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9b243f4a892925af5c7b30bc3536214404c35bbd\",\"title\":\"FaceDirector: Continuous Control of Facial Performance in Video\",\"url\":\"https://www.semanticscholar.org/paper/9b243f4a892925af5c7b30bc3536214404c35bbd\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1604.07379\",\"authors\":[{\"authorId\":\"38236002\",\"name\":\"Deepak Pathak\"},{\"authorId\":\"2562966\",\"name\":\"Philipp Kr\\u00e4henb\\u00fchl\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1109/CVPR.2016.278\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7d0effebfa4bed19b6ba41f3af5b7e5b6890de87\",\"title\":\"Context Encoders: Feature Learning by Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/7d0effebfa4bed19b6ba41f3af5b7e5b6890de87\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21451088\",\"name\":\"P. Ekman\"},{\"authorId\":\"37652085\",\"name\":\"W. Friesen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1566cf20e2ba91ca8857c30083419bf7c127094b\",\"title\":\"Facial action coding system: a technique for the measurement of facial movement\",\"url\":\"https://www.semanticscholar.org/paper/1566cf20e2ba91ca8857c30083419bf7c127094b\",\"venue\":\"\",\"year\":1978},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34105638\",\"name\":\"Justus Thies\"},{\"authorId\":\"1699058\",\"name\":\"M. Zollh\\u00f6fer\"},{\"authorId\":\"2209612\",\"name\":\"M. Nie\\u00dfner\"},{\"authorId\":\"1797649\",\"name\":\"Levi Valgaerts\"},{\"authorId\":\"144140066\",\"name\":\"M. Stamminger\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"}],\"doi\":\"10.1145/2816795.2818056\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"890f137efc064f82450c776e6a4141eb9f08fabc\",\"title\":\"Real-time expression transfer for facial reenactment\",\"url\":\"https://www.semanticscholar.org/paper/890f137efc064f82450c776e6a4141eb9f08fabc\",\"venue\":\"ACM Trans. Graph.\",\"year\":2015}],\"title\":\"Realistic Dynamic Facial Textures from a Single Image Using GANs\",\"topics\":[{\"topic\":\"Autostereogram\",\"topicId\":\"99453\",\"url\":\"https://www.semanticscholar.org/topic/99453\"},{\"topic\":\"Multilinear principal component analysis\",\"topicId\":\"508268\",\"url\":\"https://www.semanticscholar.org/topic/508268\"},{\"topic\":\"Puppeteer\",\"topicId\":\"656928\",\"url\":\"https://www.semanticscholar.org/topic/656928\"},{\"topic\":\"Retargeting\",\"topicId\":\"112399\",\"url\":\"https://www.semanticscholar.org/topic/112399\"}],\"url\":\"https://www.semanticscholar.org/paper/4b0bcc134dbcf89abad55beecf9358bacc463544\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017}\n"