"{\"abstract\":\"Recent studies demonstrate the effectiveness of Recurrent Neural Networks (RNNs) for action recognition in videos. However, previous works mainly utilize video-level category as supervision to train RNNs, which may prohibit RNNs to learn complex motion structures along time. In this paper, we propose a recurrent pose-attention network (RPAN) to address this challenge, where we introduce a novel pose-attention mechanism to adaptively learn pose-related features at every time-step action prediction of RNNs. More specifically, we make three main contributions in this paper. Firstly, unlike previous works on pose-related action recognition, our RPAN is an end-toend recurrent network which can exploit important spatialtemporal evolutions of human pose to assist action recognition in a unified framework. Secondly, instead of learning individual human-joint features separately, our poseattention mechanism learns robust human-part features by sharing attention parameters partially on the semanticallyrelated human joints. These human-part features are then fed into the human-part pooling layer to construct a highlydiscriminative pose-related representation for temporal action modeling. Thirdly, one important byproduct of our RPAN is pose estimation in videos, which can be used for coarse pose annotation in action videos. We evaluate the proposed RPAN quantitatively and qualitatively on two popular benchmarks, i.e., Sub-JHMDB and PennAction. Experimental results show that RPAN outperforms the recent state-of-the-art methods on these challenging datasets.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"35031371\",\"name\":\"Wenbin Du\",\"url\":\"https://www.semanticscholar.org/author/35031371\"},{\"authorId\":\"47903936\",\"name\":\"Yali Wang\",\"url\":\"https://www.semanticscholar.org/author/47903936\"},{\"authorId\":null,\"name\":\"Yu Qiao\",\"url\":null}],\"citationVelocity\":29,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1718226\",\"name\":\"C. Li\"},{\"authorId\":\"3128157\",\"name\":\"Ruofeng Tong\"},{\"authorId\":\"50627816\",\"name\":\"Min Tang\"}],\"doi\":\"10.1007/S13369-018-3189-Z\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f0b7c8345d065f7326f3835fe022e43d020ce050\",\"title\":\"Modelling Human Body Pose for Action Recognition Using Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/f0b7c8345d065f7326f3835fe022e43d020ce050\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3091544\",\"name\":\"Enjie Ding\"},{\"authorId\":\"2643775\",\"name\":\"Zhongyu Liu\"},{\"authorId\":\"46398350\",\"name\":\"Y. Liu\"},{\"authorId\":\"46697303\",\"name\":\"Dawei Xu\"},{\"authorId\":\"2481620\",\"name\":\"Shimin Feng\"},{\"authorId\":\"3222657\",\"name\":\"X. Liu\"}],\"doi\":\"10.1109/GCWkshps45667.2019.9024615\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d4b6ca6991dd154362791fa068cb8405b7eba09d\",\"title\":\"Unsafe Action Recognition of Miners Based on Video Description\",\"url\":\"https://www.semanticscholar.org/paper/d4b6ca6991dd154362791fa068cb8405b7eba09d\",\"venue\":\"2019 IEEE Globecom Workshops (GC Wkshps)\",\"year\":2019},{\"arxivId\":\"1809.02714\",\"authors\":[{\"authorId\":\"51442355\",\"name\":\"Mohamed H. Abdelpakey\"},{\"authorId\":\"144906448\",\"name\":\"M. Shehata\"},{\"authorId\":\"145807940\",\"name\":\"Mostafa M. Mohamed\"}],\"doi\":\"10.1007/978-3-030-03801-4_41\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4bebfa7000d7da4c5e8cb48d662b6b95dcaed163\",\"title\":\"DensSiam: End-to-End Densely-Siamese Network with Self-Attention Model for Object Tracking\",\"url\":\"https://www.semanticscholar.org/paper/4bebfa7000d7da4c5e8cb48d662b6b95dcaed163\",\"venue\":\"ISVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4464686\",\"name\":\"ZhenXing Zheng\"},{\"authorId\":\"2896701\",\"name\":\"G. An\"},{\"authorId\":\"144953181\",\"name\":\"D. Wu\"},{\"authorId\":\"144695333\",\"name\":\"Q. Ruan\"}],\"doi\":\"10.1016/J.NEUCOM.2019.05.058\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"67d3ec7b1070405575974e449cfdc495b43f7b21\",\"title\":\"Spatial-temporal pyramid based Convolutional Neural Network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/67d3ec7b1070405575974e449cfdc495b43f7b21\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3007561\",\"name\":\"Yinghui Kong\"},{\"authorId\":\"47681511\",\"name\":\"L. Li\"},{\"authorId\":\"46459368\",\"name\":\"Ke Zhang\"},{\"authorId\":\"143710669\",\"name\":\"Qiang Ni\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"}],\"doi\":\"10.1117/1.JEI.28.4.043032\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7cefcbafc3484c05a0d1d48fe7588f7af3ae8c37\",\"title\":\"Attention module-based spatial\\u2013temporal graph convolutional networks for skeleton-based action recognition\",\"url\":\"https://www.semanticscholar.org/paper/7cefcbafc3484c05a0d1d48fe7588f7af3ae8c37\",\"venue\":\"J. Electronic Imaging\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49415643\",\"name\":\"Y. Wang\"},{\"authorId\":\"46696648\",\"name\":\"L. Zhou\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1109/CVPR.2018.00557\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1b8b9332886ea661e5a46bb87118956f1f4c15f3\",\"title\":\"Temporal Hallucinating for Action Recognition with Few Still Images\",\"url\":\"https://www.semanticscholar.org/paper/1b8b9332886ea661e5a46bb87118956f1f4c15f3\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2010.08164\",\"authors\":[{\"authorId\":\"47287725\",\"name\":\"Anshul B. Shah\"},{\"authorId\":\"2850880\",\"name\":\"Shlok Kumar Mishra\"},{\"authorId\":\"2068427\",\"name\":\"Ankan Bansal\"},{\"authorId\":\"1391201966\",\"name\":\"Jun-Cheng Chen\"},{\"authorId\":\"69416958\",\"name\":\"Ramalingam Chellappa\"},{\"authorId\":\"51453757\",\"name\":\"Abhinav Shrivastava\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5ac51a6eb28656c670c36a6460be0e458b2e562f\",\"title\":\"Pose And Joint-Aware Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5ac51a6eb28656c670c36a6460be0e458b2e562f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3403397\",\"name\":\"A. Ghosh\"},{\"authorId\":\"9215658\",\"name\":\"R. Chellappa\"}],\"doi\":\"10.1007/s42979-019-0025-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b80646f9b8d51090dfe383575680b00a268410a4\",\"title\":\"Single-Shot 3D Mesh Estimation via Adversarial Domain Adaptation - Learning Directly from Synthetic Data\",\"url\":\"https://www.semanticscholar.org/paper/b80646f9b8d51090dfe383575680b00a268410a4\",\"venue\":\"SN Comput. Sci.\",\"year\":2020},{\"arxivId\":\"2002.08219\",\"authors\":[{\"authorId\":\"1489467112\",\"name\":\"Yeji Kim\"},{\"authorId\":\"122808682\",\"name\":\"Dong-Gyu Lee\"},{\"authorId\":\"50112753\",\"name\":\"Seong-Whan Lee\"}],\"doi\":\"10.1016/j.patcog.2020.107279\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a8baa039ea325efa0a5de795dc820532eb3f8e77\",\"title\":\"Three-Stream Fusion Network for First-Person Interaction Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a8baa039ea325efa0a5de795dc820532eb3f8e77\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":\"1912.01001\",\"authors\":[{\"authorId\":\"13700560\",\"name\":\"J. J. Sun\"},{\"authorId\":\"7818121\",\"name\":\"Jiaping Zhao\"},{\"authorId\":\"34192119\",\"name\":\"Liang-Chieh Chen\"},{\"authorId\":\"3302320\",\"name\":\"Florian Schroff\"},{\"authorId\":\"2595180\",\"name\":\"H. Adam\"},{\"authorId\":\"152244126\",\"name\":\"T. Liu\"}],\"doi\":\"10.1007/978-3-030-58558-7_4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"55cff809c878d91e1c23f33c7e448d11d60bc16a\",\"title\":\"View-Invariant Probabilistic Embedding for Human Pose\",\"url\":\"https://www.semanticscholar.org/paper/55cff809c878d91e1c23f33c7e448d11d60bc16a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1905.13586\",\"authors\":[{\"authorId\":\"47892681\",\"name\":\"Haoxin Li\"},{\"authorId\":\"50204657\",\"name\":\"Yijun Cai\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"}],\"doi\":\"10.1109/CVPR.2019.00812\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"303aa6cb7a182d5437c86d07aff4fb9fdabc744e\",\"title\":\"Deep Dual Relation Modeling for Egocentric Interaction Recognition\",\"url\":\"https://www.semanticscholar.org/paper/303aa6cb7a182d5437c86d07aff4fb9fdabc744e\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1844969\",\"name\":\"Faming Gong\"},{\"authorId\":\"2024256982\",\"name\":\"Ma Yuhui\"},{\"authorId\":\"147858481\",\"name\":\"P. Zheng\"},{\"authorId\":\"145147427\",\"name\":\"T. Song\"},{\"authorId\":\"145147427\",\"name\":\"T. Song\"}],\"doi\":\"10.1016/j.jlp.2020.104043\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d5c9156cd61f03e84a03133e038c943206eef8f4\",\"title\":\"A deep model method for recognizing activities of workers on offshore drilling platform by multistage convolutional pose machine\",\"url\":\"https://www.semanticscholar.org/paper/d5c9156cd61f03e84a03133e038c943206eef8f4\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21518096\",\"name\":\"Zhengyuan Yang\"},{\"authorId\":\"3092578\",\"name\":\"Y. Li\"},{\"authorId\":\"1706007\",\"name\":\"Jianchao Yang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/TCSVT.2018.2864148\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"08cc8c38c25f2bc87d44e35abbccd6a88eb5103b\",\"title\":\"Action Recognition With Spatio\\u2013Temporal Visual Attention on Skeleton Image Sequences\",\"url\":\"https://www.semanticscholar.org/paper/08cc8c38c25f2bc87d44e35abbccd6a88eb5103b\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":\"1810.03851\",\"authors\":[{\"authorId\":\"145539441\",\"name\":\"S. Pu\"},{\"authorId\":\"2255687\",\"name\":\"Yibing Song\"},{\"authorId\":\"46658056\",\"name\":\"Chao Ma\"},{\"authorId\":\"1720776\",\"name\":\"H. Zhang\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5c220558907b035bcbf61e3dab89c9128afae7f9\",\"title\":\"Deep Attentive Tracking via Reciprocative Learning\",\"url\":\"https://www.semanticscholar.org/paper/5c220558907b035bcbf61e3dab89c9128afae7f9\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a87ab836771164adb95d6744027e62e05f47fd96\",\"title\":\"Understanding human-human interactions: a survey\",\"url\":\"https://www.semanticscholar.org/paper/a87ab836771164adb95d6744027e62e05f47fd96\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46276098\",\"name\":\"Jianan Li\"},{\"authorId\":\"49419064\",\"name\":\"Xuemei Xie\"},{\"authorId\":\"1491642326\",\"name\":\"Qingzhe Pan\"},{\"authorId\":\"122210974\",\"name\":\"Yu-Han Cao\"},{\"authorId\":\"32273141\",\"name\":\"Z. Zhao\"},{\"authorId\":\"35367337\",\"name\":\"Guangming Shi\"}],\"doi\":\"10.1016/j.patcog.2020.107356\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a6cd1d88ab7439d73d1163c2eca77ce7134c908f\",\"title\":\"SGM-Net: Skeleton-guided multimodal network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/a6cd1d88ab7439d73d1163c2eca77ce7134c908f\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1557335646\",\"name\":\"Sandar Win\"},{\"authorId\":\"49245080\",\"name\":\"Thin Lai Lai Thein\"}],\"doi\":\"10.1109/ICCA49400.2020.9022822\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"121599243954e4b1397b83ef58405e488b7e98b2\",\"title\":\"Real-Time Human Motion Detection, Tracking and Activity Recognition with Skeletal Model\",\"url\":\"https://www.semanticscholar.org/paper/121599243954e4b1397b83ef58405e488b7e98b2\",\"venue\":\"2020 IEEE Conference on Computer Applications(ICCA)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"102320235\",\"name\":\"Hao Yang\"},{\"authorId\":null,\"name\":\"Chunfeng Yuan\"},{\"authorId\":\"47059008\",\"name\":\"L. Zhang\"},{\"authorId\":\"2545705\",\"name\":\"Yunda Sun\"},{\"authorId\":\"48594951\",\"name\":\"Weiming Hu\"},{\"authorId\":\"144555237\",\"name\":\"S. Maybank\"}],\"doi\":\"10.1109/TIP.2020.2984904\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c900e452bdb47ed6083ce2651ac32afb211f9fc6\",\"title\":\"STA-CNN: Convolutional Spatial-Temporal Attention Learning for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c900e452bdb47ed6083ce2651ac32afb211f9fc6\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"2003.12737\",\"authors\":[{\"authorId\":\"32781361\",\"name\":\"Kirill Gavrilyuk\"},{\"authorId\":\"35663637\",\"name\":\"R. Sanford\"},{\"authorId\":\"145556010\",\"name\":\"M. Javan\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1109/cvpr42600.2020.00092\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c4668668c3b9f0bda4d207b3e6d397034977f0e\",\"title\":\"Actor-Transformers for Group Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c4668668c3b9f0bda4d207b3e6d397034977f0e\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1805.08484\",\"authors\":[{\"authorId\":\"145200778\",\"name\":\"Wei Wang\"},{\"authorId\":\"47539600\",\"name\":\"Jinjin Zhang\"},{\"authorId\":\"39927579\",\"name\":\"Chenyang Si\"},{\"authorId\":\"1693997\",\"name\":\"Liang Wang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d1694200f2fe0676985a8cfe467f9ae010eb3e57\",\"title\":\"Pose-Based Two-Stream Relational Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/d1694200f2fe0676985a8cfe467f9ae010eb3e57\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49051421\",\"name\":\"Jianming Zhang\"},{\"authorId\":\"48607571\",\"name\":\"Y. Wu\"},{\"authorId\":\"150337081\",\"name\":\"Wenjun Feng\"},{\"authorId\":\"9491882\",\"name\":\"J. Wang\"}],\"doi\":\"10.1109/ACCESS.2019.2924944\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5e41f97c4611277401e989cc154093a60f36f95b\",\"title\":\"Spatially Attentive Visual Tracking Using Multi-Model Adaptive Response Fusion\",\"url\":\"https://www.semanticscholar.org/paper/5e41f97c4611277401e989cc154093a60f36f95b\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1912.07249\",\"authors\":[{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"3321919\",\"name\":\"Gr\\u00e9gory Rogez\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8dce5b1cc382f4a341f7ea43c6329c9e8acd202d\",\"title\":\"Mimetics: Towards Understanding Human Actions Out of Context\",\"url\":\"https://www.semanticscholar.org/paper/8dce5b1cc382f4a341f7ea43c6329c9e8acd202d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153924558\",\"name\":\"Hsing-Yu Chen\"},{\"authorId\":\"1696527\",\"name\":\"S. Lai\"}],\"doi\":\"10.1007/978-3-030-41299-9_55\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aa2b2a6ce78eb79952408d426ba1b48efdb81dca\",\"title\":\"Group Activity Recognition via Computing Human Pose Motion History and Collective Map from Video\",\"url\":\"https://www.semanticscholar.org/paper/aa2b2a6ce78eb79952408d426ba1b48efdb81dca\",\"venue\":\"ACPR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2357503\",\"name\":\"Ya-Chun Li\"},{\"authorId\":\"97596774\",\"name\":\"Y. Liu\"},{\"authorId\":\"48935472\",\"name\":\"Chi Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d02a5b52bb47ecf594710ede66c12f1eb660c39\",\"title\":\"What Elements are Essential to Recognize Human Actions?\",\"url\":\"https://www.semanticscholar.org/paper/9d02a5b52bb47ecf594710ede66c12f1eb660c39\",\"venue\":\"CVPR Workshops\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9122942\",\"name\":\"Fangqiang Hu\"},{\"authorId\":\"16040763\",\"name\":\"Qianyu Wu\"},{\"authorId\":\"50202676\",\"name\":\"Sai Zhang\"},{\"authorId\":\"2643261\",\"name\":\"A. Zhu\"},{\"authorId\":\"51303461\",\"name\":\"Zixuan Wang\"},{\"authorId\":\"3379173\",\"name\":\"Y. Bao\"}],\"doi\":\"10.1117/1.JEI.28.4.043018\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a5c7651d3482d3dfe5fa852ab6dfb7aa95309031\",\"title\":\"Pose-based multisource networks using convolutional neural network and long short-term memory for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/a5c7651d3482d3dfe5fa852ab6dfb7aa95309031\",\"venue\":\"J. Electronic Imaging\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153562818\",\"name\":\"Linjiang Huang\"},{\"authorId\":\"49867037\",\"name\":\"Y. Huang\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":null,\"name\":\"Liang Wang\"}],\"doi\":\"10.1016/J.PATCOG.2019.03.010\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"01c2dc6910d4552ddd86cf75dc17f3afeed9c57a\",\"title\":\"Part-aligned pose-guided recurrent network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/01c2dc6910d4552ddd86cf75dc17f3afeed9c57a\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145470590\",\"name\":\"W. Lin\"},{\"authorId\":\"1517108051\",\"name\":\"Jie Yu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8d0a1bdf67767b420fccb1d1847bfa6b65d11f5d\",\"title\":\"Beyond 2D: Fusion of Monocular 3D Pose, Motion and Appearance for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8d0a1bdf67767b420fccb1d1847bfa6b65d11f5d\",\"venue\":\"2019 22th International Conference on Information Fusion (FUSION)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2832627\",\"name\":\"C. Zhang\"},{\"authorId\":\"48016967\",\"name\":\"H. Wang\"},{\"authorId\":\"2422845\",\"name\":\"J. Wen\"},{\"authorId\":\"47994746\",\"name\":\"Li Peng\"}],\"doi\":\"10.1109/ACCESS.2020.3005511\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d600a195ac4870b1d754081ea4e055da9b900ef9\",\"title\":\"Deeper Siamese Network With Stronger Feature Representation for Visual Tracking\",\"url\":\"https://www.semanticscholar.org/paper/d600a195ac4870b1d754081ea4e055da9b900ef9\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390911740\",\"name\":\"Lizong Zhang\"},{\"authorId\":\"11011479\",\"name\":\"Tingting Wu\"},{\"authorId\":\"1382695344\",\"name\":\"Guomin Lu\"},{\"authorId\":\"11386433\",\"name\":\"Long-yong Lin\"},{\"authorId\":\"47407126\",\"name\":\"Kai Zhou\"}],\"doi\":\"10.1109/iThings/GreenCom/CPSCom/SmartData.2019.00154\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4652db69598b19f4f16d1f85912bd4efc0d11776\",\"title\":\"A Behavior Recognition Framework Based on Skeleton Spatio-Temporal Relation\",\"url\":\"https://www.semanticscholar.org/paper/4652db69598b19f4f16d1f85912bd4efc0d11776\",\"venue\":\"2019 International Conference on Internet of Things (iThings) and IEEE Green Computing and Communications (GreenCom) and IEEE Cyber, Physical and Social Computing (CPSCom) and IEEE Smart Data (SmartData)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"89056710\",\"name\":\"Jinhai Yang\"},{\"authorId\":\"48918787\",\"name\":\"Xiao Zhou\"},{\"authorId\":\"71227046\",\"name\":\"H. Yang\"}],\"doi\":\"10.1007/978-981-15-3341-9_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d6968312b4280ca498f6ee55b3fe9b9b17c18b01\",\"title\":\"Attention-Based Top-Down Single-Task Action Recognition in Still Images\",\"url\":\"https://www.semanticscholar.org/paper/d6968312b4280ca498f6ee55b3fe9b9b17c18b01\",\"venue\":\"IFTC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52564092\",\"name\":\"Kanav Vats\"},{\"authorId\":\"40494138\",\"name\":\"H. Neher\"},{\"authorId\":\"1720258\",\"name\":\"David A Clausi\"},{\"authorId\":\"1702003\",\"name\":\"J. Zelek\"}],\"doi\":\"10.1109/CRV.2019.00032\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6e31adfe278a8a3da1d2f42ab2fbdb65ed0099eb\",\"title\":\"Two-Stream Action Recognition in Ice Hockey using Player Pose Sequences and Optical Flows\",\"url\":\"https://www.semanticscholar.org/paper/6e31adfe278a8a3da1d2f42ab2fbdb65ed0099eb\",\"venue\":\"2019 16th Conference on Computer and Robot Vision (CRV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3245101\",\"name\":\"Hu-Cheng Lee\"},{\"authorId\":\"1720818\",\"name\":\"Sebastian Agethen\"},{\"authorId\":\"34471696\",\"name\":\"C. Lin\"},{\"authorId\":\"3241696\",\"name\":\"Hsin-Yu Hsu\"},{\"authorId\":\"145926250\",\"name\":\"Pin-Chun Hsu\"},{\"authorId\":\"46270526\",\"name\":\"Z. Liu\"},{\"authorId\":\"6031817\",\"name\":\"Hanshu Chu\"},{\"authorId\":\"31871157\",\"name\":\"Winston Hsu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7e49a6f11a8843b2ff5bdbf7cf95617c6219f757\",\"title\":\"Multi-Modal Fusion for Moment in Time Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/7e49a6f11a8843b2ff5bdbf7cf95617c6219f757\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35429700\",\"name\":\"Panagiotis Giannakeris\"},{\"authorId\":\"2733886\",\"name\":\"Panagiotis C. Petrantonakis\"},{\"authorId\":\"2735095\",\"name\":\"Konstantinos Avgerinakis\"},{\"authorId\":\"1381295446\",\"name\":\"S. Vrochidis\"},{\"authorId\":\"119661806\",\"name\":\"I. Kompatsiaris\"}],\"doi\":\"10.1007/S11042-020-09902-6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"44c0abc3ac54c69ba68362708c2a5c06b088287b\",\"title\":\"First-person activity recognition from micro-action representations using convolutional neural networks and object flow histograms\",\"url\":\"https://www.semanticscholar.org/paper/44c0abc3ac54c69ba68362708c2a5c06b088287b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48998638\",\"name\":\"P. Ni\"},{\"authorId\":\"1902517\",\"name\":\"Shilei Lv\"},{\"authorId\":\"1945398\",\"name\":\"XiaoXiao Zhu\"},{\"authorId\":\"48142797\",\"name\":\"Qixin Cao\"},{\"authorId\":\"49039567\",\"name\":\"W. Zhang\"}],\"doi\":\"10.1016/j.dcan.2020.05.004\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6282bd563f5283260056f3edeef4c3b2deecefce\",\"title\":\"A light-weight on-line action detection with hand trajectories for industrial surveillance\",\"url\":\"https://www.semanticscholar.org/paper/6282bd563f5283260056f3edeef4c3b2deecefce\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1909.03466\",\"authors\":[{\"authorId\":\"14370059\",\"name\":\"M. U. Khalid\"},{\"authorId\":\"26959611\",\"name\":\"J. Yu\"}],\"doi\":\"10.1109/ICPR.2018.8546131\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"59478365451b82f5227bc4b694a2ff319025cc33\",\"title\":\"Multi-Modal Three-Stream Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/59478365451b82f5227bc4b694a2ff319025cc33\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":\"1801.10304\",\"authors\":[{\"authorId\":\"21518096\",\"name\":\"Zhengyuan Yang\"},{\"authorId\":\"3092578\",\"name\":\"Y. Li\"},{\"authorId\":\"1706007\",\"name\":\"Jianchao Yang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/ICPR.2018.8546012\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e9ef13f6e59361d67f4b4fe7132cb7b3ce1bb6d0\",\"title\":\"Action Recognition with Visual Attention on Skeleton Images\",\"url\":\"https://www.semanticscholar.org/paper/e9ef13f6e59361d67f4b4fe7132cb7b3ce1bb6d0\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":\"1910.11006\",\"authors\":[{\"authorId\":\"2981509\",\"name\":\"Dongxu Li\"},{\"authorId\":\"145112187\",\"name\":\"Cristian Rodriguez-Opazo\"},{\"authorId\":\"144349266\",\"name\":\"X. Yu\"},{\"authorId\":\"40124570\",\"name\":\"Hongdong Li\"}],\"doi\":\"10.1109/WACV45572.2020.9093512\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2dda8d1d7400d49e5ad54bc9abfca96170245763\",\"title\":\"Word-level Deep Sign Language Recognition from Video: A New Large-scale Dataset and Methods Comparison\",\"url\":\"https://www.semanticscholar.org/paper/2dda8d1d7400d49e5ad54bc9abfca96170245763\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"2008.08452\",\"authors\":[{\"authorId\":\"50841913\",\"name\":\"Asif Shahriyar Sushmit\"},{\"authorId\":\"10458138\",\"name\":\"P. Ghosh\"},{\"authorId\":\"1885311407\",\"name\":\"Md.Abrar Istiak\"},{\"authorId\":\"1742267771\",\"name\":\"Nayeeb Rashid\"},{\"authorId\":\"1742267920\",\"name\":\"Ahsan Habib Akash\"},{\"authorId\":\"144782474\",\"name\":\"T. Hasan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d4953e2a564f68bc7eccd8d1af12da3c2c5bbf7c\",\"title\":\"SegCodeNet: Color-Coded Segmentation Masks for Activity Detection from Wearable Cameras\",\"url\":\"https://www.semanticscholar.org/paper/d4953e2a564f68bc7eccd8d1af12da3c2c5bbf7c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35429700\",\"name\":\"Panagiotis Giannakeris\"},{\"authorId\":\"1696389\",\"name\":\"G. Meditskos\"},{\"authorId\":\"2735095\",\"name\":\"Konstantinos Avgerinakis\"},{\"authorId\":\"1381295446\",\"name\":\"S. Vrochidis\"},{\"authorId\":\"1715604\",\"name\":\"Y. Kompatsiaris\"}],\"doi\":\"10.1007/978-3-030-37734-2_49\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0f8bd23919c36db7e1f3eb9c57b7ef72e4632ed1\",\"title\":\"Real-Time Recognition of Daily Actions Based on 3D Joint Movements and Fisher Encoding\",\"url\":\"https://www.semanticscholar.org/paper/0f8bd23919c36db7e1f3eb9c57b7ef72e4632ed1\",\"venue\":\"MMM\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2244863\",\"name\":\"X. Zhang\"},{\"authorId\":\"1715708\",\"name\":\"Yaping Huang\"},{\"authorId\":\"2035596033\",\"name\":\"Yang Mi\"},{\"authorId\":\"80996783\",\"name\":\"Yanting Pei\"},{\"authorId\":\"2196589\",\"name\":\"Qi Zou\"},{\"authorId\":\"40696794\",\"name\":\"Song Wang\"}],\"doi\":\"10.1007/s10489-020-01905-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ffd6d8c2f114895c3506b8326a0fdb6b8728e901\",\"title\":\"Video sketch: A middle-level representation for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/ffd6d8c2f114895c3506b8326a0fdb6b8728e901\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46740612\",\"name\":\"C. Wu\"},{\"authorId\":\"50171534\",\"name\":\"Xiaojun Wu\"},{\"authorId\":\"47091894\",\"name\":\"J. Kittler\"}],\"doi\":\"10.1109/ICCVW.2019.00216\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d0678d9b06fa66786cc6213254820184d8ebfd2a\",\"title\":\"Spatial Residual Layer and Dense Connection Block Enhanced Spatial Temporal Graph Convolutional Network for Skeleton-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d0678d9b06fa66786cc6213254820184d8ebfd2a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49724494\",\"name\":\"Haibo Zhang\"}],\"doi\":\"10.1016/j.jvcir.2018.10.022\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"71751d9bf7881a5100865bd542dddac2df7e4780\",\"title\":\"The literature review of action recognition in traffic context\",\"url\":\"https://www.semanticscholar.org/paper/71751d9bf7881a5100865bd542dddac2df7e4780\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145539441\",\"name\":\"S. Pu\"},{\"authorId\":\"2255687\",\"name\":\"Yibing Song\"},{\"authorId\":\"46658056\",\"name\":\"Chao Ma\"},{\"authorId\":\"1720776\",\"name\":\"H. Zhang\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9fb256ae17d66d8ff2099130aac6734edc45632b\",\"title\":\"Attention Map Input Frame Attention Regularization + Training : Classification loss + Attention regularization Prediction : Binary classification Reciprocate Forward Backward Figure 1\",\"url\":\"https://www.semanticscholar.org/paper/9fb256ae17d66d8ff2099130aac6734edc45632b\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2010.13321\",\"authors\":[{\"authorId\":\"152244126\",\"name\":\"T. Liu\"},{\"authorId\":\"13700560\",\"name\":\"J. J. Sun\"},{\"authorId\":\"48096253\",\"name\":\"Long Zhao\"},{\"authorId\":\"7818121\",\"name\":\"Jiaping Zhao\"},{\"authorId\":\"36001694\",\"name\":\"Liangzhe Yuan\"},{\"authorId\":null,\"name\":\"Yuxiao Wang\"},{\"authorId\":\"34192119\",\"name\":\"Liang-Chieh Chen\"},{\"authorId\":\"3302320\",\"name\":\"Florian Schroff\"},{\"authorId\":\"2595180\",\"name\":\"H. Adam\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ef53ad638f67c26fab1a46a4173487d0fb1e6180\",\"title\":\"View-Invariant, Occlusion-Robust Probabilistic Embedding for Human Pose\",\"url\":\"https://www.semanticscholar.org/paper/ef53ad638f67c26fab1a46a4173487d0fb1e6180\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40494138\",\"name\":\"H. Neher\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7b68d5c017722c72647b8f0dede25d283a080900\",\"title\":\"Hockey Pose Estimation and Action Recognition using Convolutional Neural Networks to Ice Hockey\",\"url\":\"https://www.semanticscholar.org/paper/7b68d5c017722c72647b8f0dede25d283a080900\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9024867\",\"name\":\"Jongkwang Hong\"},{\"authorId\":\"70374238\",\"name\":\"Bora Cho\"},{\"authorId\":\"49058762\",\"name\":\"Yongwon Hong\"},{\"authorId\":\"144036125\",\"name\":\"H. Byun\"}],\"doi\":\"10.3390/s19061382\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"17d77c03c2b552f2046e8c4674db64a3ef9b915b\",\"title\":\"Contextual Action Cues from Camera Sensor for Multi-Stream Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/17d77c03c2b552f2046e8c4674db64a3ef9b915b\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1931096\",\"name\":\"A. Behera\"},{\"authorId\":\"153498049\",\"name\":\"Alexander H. Keidel\"}],\"doi\":\"10.1109/AVSS.2018.8639158\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"c05262834ae13e289f69da7d2fb7cc2a2685c659\",\"title\":\"Latent Body-Pose guided DenseNet for Recognizing Driver\\u2019s Fine-grained Secondary Activities\",\"url\":\"https://www.semanticscholar.org/paper/c05262834ae13e289f69da7d2fb7cc2a2685c659\",\"venue\":\"2018 15th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)\",\"year\":2018},{\"arxivId\":\"2012.11866\",\"authors\":[{\"authorId\":\"2595189\",\"name\":\"Zehua Sun\"},{\"authorId\":\"120809631\",\"name\":\"Jiwang Liu\"},{\"authorId\":\"143969578\",\"name\":\"Qiuhong Ke\"},{\"authorId\":\"1877377\",\"name\":\"H. Rahmani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"816236bf3219363bfe4b847363e137b1fe6712e7\",\"title\":\"Human Action Recognition from Various Data Modalities: A Review\",\"url\":\"https://www.semanticscholar.org/paper/816236bf3219363bfe4b847363e137b1fe6712e7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1490936883\",\"name\":\"M. Geng\"},{\"authorId\":\"46507164\",\"name\":\"Haiying Wang\"},{\"authorId\":\"134899257\",\"name\":\"Yingsen Zeng\"}],\"doi\":\"10.1109/VCIP47243.2019.8965870\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"30571fbc78268c5cd609b95b55be8dfb9372e81f\",\"title\":\"Enhanced Semantic Features via Attention for Real-Time Visual Tracking\",\"url\":\"https://www.semanticscholar.org/paper/30571fbc78268c5cd609b95b55be8dfb9372e81f\",\"venue\":\"2019 IEEE Visual Communications and Image Processing (VCIP)\",\"year\":2019},{\"arxivId\":\"1901.02579\",\"authors\":[{\"authorId\":\"46947776\",\"name\":\"Zhenqiang Li\"},{\"authorId\":\"48355461\",\"name\":\"Yifei Huang\"},{\"authorId\":\"3172280\",\"name\":\"Minjie Cai\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1109/ICCVW.2019.00539\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"70681bc4d3facb1839c3459ee1c68b048d46bca8\",\"title\":\"Manipulation-Skill Assessment from Videos with Spatial Attention Network\",\"url\":\"https://www.semanticscholar.org/paper/70681bc4d3facb1839c3459ee1c68b048d46bca8\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39991406\",\"name\":\"Q. Wang\"},{\"authorId\":\"1943020\",\"name\":\"Z. Teng\"},{\"authorId\":\"1757173\",\"name\":\"Junliang Xing\"},{\"authorId\":\"46930055\",\"name\":\"J. Gao\"},{\"authorId\":\"40506509\",\"name\":\"W. Hu\"},{\"authorId\":\"144555237\",\"name\":\"S. Maybank\"}],\"doi\":\"10.1109/CVPR.2018.00510\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6683442ae358ae4261fdcde0164f83dd1ccd621b\",\"title\":\"Learning Attentions: Residual Attentional Siamese Network for High Performance Online Visual Tracking\",\"url\":\"https://www.semanticscholar.org/paper/6683442ae358ae4261fdcde0164f83dd1ccd621b\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Kevin Lin\"},{\"authorId\":\"30602591\",\"name\":\"Lijuan Wang\"},{\"authorId\":\"145932218\",\"name\":\"Kun Luo\"},{\"authorId\":\"2249952\",\"name\":\"Yinpeng Chen\"},{\"authorId\":\"1691128\",\"name\":\"Zicheng Liu\"},{\"authorId\":\"144463557\",\"name\":\"Ming-Ting Sun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1a9f4c7a5928c4bda69a7612704754dcb2ca9343\",\"title\":\"Synthetic Data w / Part Labels Cross-Domain Complementary Learning Pose Estimation for Cross-Domain Alignment Auxiliary Task Predicting Parts on Real Data\",\"url\":\"https://www.semanticscholar.org/paper/1a9f4c7a5928c4bda69a7612704754dcb2ca9343\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50006507\",\"name\":\"Yanli Ji\"},{\"authorId\":\"49338773\",\"name\":\"Y. Zhan\"},{\"authorId\":\"27718163\",\"name\":\"Y. Yang\"},{\"authorId\":\"1410252832\",\"name\":\"Xing Xu\"},{\"authorId\":\"38083193\",\"name\":\"F. Shen\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1109/TIP.2019.2952088\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ac2b6006886e6693ce85a5c935abceef90ae3b89\",\"title\":\"A Context Knowledge Map Guided Coarse-to-Fine Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ac2b6006886e6693ce85a5c935abceef90ae3b89\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2505740\",\"name\":\"Dennis Ludl\"},{\"authorId\":\"7932331\",\"name\":\"T. Gulde\"},{\"authorId\":\"2174606\",\"name\":\"Crist\\u00f3bal Curio\"}],\"doi\":\"10.1109/TITS.2020.2988504\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5eb8531ef3e5bb2606b2f8aa70664ef70db78f00\",\"title\":\"Enhancing Data-Driven Algorithms for Human Pose Estimation and Action Recognition Through Simulation\",\"url\":\"https://www.semanticscholar.org/paper/5eb8531ef3e5bb2606b2f8aa70664ef70db78f00\",\"venue\":\"IEEE Transactions on Intelligent Transportation Systems\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50367841\",\"name\":\"Qi Bi\"},{\"authorId\":\"100464675\",\"name\":\"Kun Qin\"},{\"authorId\":\"120811666\",\"name\":\"Han Zhang\"},{\"authorId\":\"46947989\",\"name\":\"Zhili Li\"},{\"authorId\":\"153162713\",\"name\":\"K. Xu\"}],\"doi\":\"10.1016/j.neucom.2019.11.068\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c9d7773300b910fd31bee975980a2d4eb70acf97\",\"title\":\"RADC-Net: A residual attention based convolution network for aerial scene classification\",\"url\":\"https://www.semanticscholar.org/paper/c9d7773300b910fd31bee975980a2d4eb70acf97\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49750984\",\"name\":\"C. Chen\"},{\"authorId\":\"2800735\",\"name\":\"C. Zhang\"},{\"authorId\":\"1749704087\",\"name\":\"Tiannuo Wang\"},{\"authorId\":\"49620724\",\"name\":\"Dongnian Li\"},{\"authorId\":\"144794615\",\"name\":\"Y. Guo\"},{\"authorId\":\"24927259\",\"name\":\"Zhengxu Zhao\"},{\"authorId\":\"144705147\",\"name\":\"J. Hong\"}],\"doi\":\"10.3390/s20154208\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"937b9594aa2359deddda346090d64bd874d8eb84\",\"title\":\"Monitoring of Assembly Process Using Deep Learning Technology\",\"url\":\"https://www.semanticscholar.org/paper/937b9594aa2359deddda346090d64bd874d8eb84\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390626541\",\"name\":\"Ziming Liu\"},{\"authorId\":\"47296615\",\"name\":\"Guangyu Gao\"},{\"authorId\":\"1380212680\",\"name\":\"A. K. Qin\"},{\"authorId\":\"150325884\",\"name\":\"T. Wu\"},{\"authorId\":\"1390585158\",\"name\":\"Chi Harold Liu\"}],\"doi\":\"10.1145/3343031.3350916\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"554d3d5cdffa7e2aa292504d4d4507af498e30d2\",\"title\":\"Action Recognition with Bootstrapping based Long-range Temporal Context Attention\",\"url\":\"https://www.semanticscholar.org/paper/554d3d5cdffa7e2aa292504d4d4507af498e30d2\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"108646857\",\"name\":\"Dan Liu\"},{\"authorId\":\"152994876\",\"name\":\"Yunfeng Ji\"},{\"authorId\":\"144560368\",\"name\":\"M. Ye\"},{\"authorId\":\"46636010\",\"name\":\"Y. Gan\"},{\"authorId\":\"1739414\",\"name\":\"Jianwei Zhang\"}],\"doi\":\"10.1109/ACCESS.2020.2983355\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b89aed9287493cc57eb0dcd58eccec4ec0c981b6\",\"title\":\"An Improved Attention-Based Spatiotemporal-Stream Model for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/b89aed9287493cc57eb0dcd58eccec4ec0c981b6\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1908.00497\",\"authors\":[{\"authorId\":\"145294961\",\"name\":\"L. Chi\"},{\"authorId\":\"9443552\",\"name\":\"G. Tian\"},{\"authorId\":\"145353089\",\"name\":\"Y. Mu\"},{\"authorId\":\"144876834\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/ICCVW.2019.00552\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5769318fd67d1104e561b7382b305b5ca810d6d2\",\"title\":\"Two-Stream Video Classification with Cross-Modality Attention\",\"url\":\"https://www.semanticscholar.org/paper/5769318fd67d1104e561b7382b305b5ca810d6d2\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1907.05193\",\"authors\":[{\"authorId\":null,\"name\":\"Kevin Lin\"},{\"authorId\":\"30602591\",\"name\":\"Lijuan Wang\"},{\"authorId\":\"145932218\",\"name\":\"K. Luo\"},{\"authorId\":\"2249952\",\"name\":\"Y. Chen\"},{\"authorId\":\"1691128\",\"name\":\"Zicheng Liu\"},{\"authorId\":\"144463557\",\"name\":\"M. Sun\"}],\"doi\":\"10.1109/TCSVT.2020.2995122\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5839dcda8a2969c49bb2f8e66a2b2078723871fc\",\"title\":\"Cross-Domain Complementary Learning with Synthetic Data for Multi-Person Part Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/5839dcda8a2969c49bb2f8e66a2b2078723871fc\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49970148\",\"name\":\"Zhenqiang Li\"},{\"authorId\":\"48355461\",\"name\":\"Yifei Huang\"},{\"authorId\":\"49678929\",\"name\":\"Y. Sato\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"59e777069a4a24b47dfb27712bb3e5dcf3392f62\",\"title\":\"F \\\" , $ F % , $ conv Conv Fusion conv ReLU concat X $ Spatial Attention Submodule \\u03b1 $ \\u03a3 RNNtask Feature Encoding Attention Pooling Temporal Aggregation\",\"url\":\"https://www.semanticscholar.org/paper/59e777069a4a24b47dfb27712bb3e5dcf3392f62\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2008.00455\",\"authors\":[{\"authorId\":\"70116446\",\"name\":\"T. Isobe\"},{\"authorId\":\"1641711590\",\"name\":\"Xu Jia\"},{\"authorId\":\"2476317\",\"name\":\"Shuhang Gu\"},{\"authorId\":\"153061158\",\"name\":\"Songjiang Li\"},{\"authorId\":\"103307901\",\"name\":\"Shengjin Wang\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1007/978-3-030-58610-2_38\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3337fd0fa0ab5420e350714edc7c20aed9717965\",\"title\":\"Video Super-Resolution with Recurrent Structure-Detail Network\",\"url\":\"https://www.semanticscholar.org/paper/3337fd0fa0ab5420e350714edc7c20aed9717965\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2004.08154\",\"authors\":[{\"authorId\":\"10384643\",\"name\":\"Yong-Lu Li\"},{\"authorId\":\"2128016\",\"name\":\"Xinpeng Liu\"},{\"authorId\":\"1500648246\",\"name\":\"Han Lu\"},{\"authorId\":\"3826706\",\"name\":\"S. Wang\"},{\"authorId\":\"40370720\",\"name\":\"J. Liu\"},{\"authorId\":\"49299169\",\"name\":\"J. Li\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"}],\"doi\":\"10.1109/cvpr42600.2020.01018\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f51b8b8fcdf881d2bb5b5fece37154907b17249b\",\"title\":\"Detailed 2D-3D Joint Representation for Human-Object Interaction\",\"url\":\"https://www.semanticscholar.org/paper/f51b8b8fcdf881d2bb5b5fece37154907b17249b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1911.12509\",\"authors\":[{\"authorId\":\"93242167\",\"name\":\"Lei Shi\"},{\"authorId\":\"40382978\",\"name\":\"Yifan Zhang\"},{\"authorId\":\"48265260\",\"name\":\"Jian Cheng\"},{\"authorId\":\"1699900\",\"name\":\"H. Lu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"9471c5ea8fbd4bcdc780962770d062d1eaa5ce4b\",\"title\":\"Action Recognition via Pose-Based Graph Convolutional Networks with Intermediate Dense Supervision\",\"url\":\"https://www.semanticscholar.org/paper/9471c5ea8fbd4bcdc780962770d062d1eaa5ce4b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9369513\",\"name\":\"Md. Imtiaz Hossain\"},{\"authorId\":\"50876944\",\"name\":\"Ashraf Siddique\"},{\"authorId\":\"101481224\",\"name\":\"Md. Imtiaz Hossain\"},{\"authorId\":\"81133680\",\"name\":\"Md. Sohorab Hossain\"},{\"authorId\":\"1705900\",\"name\":\"E. Huh\"}],\"doi\":\"10.1109/ACCESS.2020.3037529\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2b4d7724aecdd21451648b84bff065132fc6e9d9\",\"title\":\"Batch Entropy Supervised Convolutional Neural Networks for Feature Extraction and Harmonizing for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2b4d7724aecdd21451648b84bff065132fc6e9d9\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52022007\",\"name\":\"Vasileios Choutas\"},{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"3428663\",\"name\":\"J\\u00e9r\\u00f4me Revaud\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/CVPR.2018.00734\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6009bba115904bc3bf876224db90b232c4f0a48f\",\"title\":\"PoTion: Pose MoTion Representation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6009bba115904bc3bf876224db90b232c4f0a48f\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144787162\",\"name\":\"D. Nova\"},{\"authorId\":\"144982894\",\"name\":\"A. Ferreira\"},{\"authorId\":\"145286037\",\"name\":\"P. Cortez\"}],\"doi\":\"10.1007/978-3-030-16447-8_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bacb13982e531e43c236147d65ba2bf5e44a379f\",\"title\":\"A Machine Learning Approach to Detect Violent Behaviour from Video\",\"url\":\"https://www.semanticscholar.org/paper/bacb13982e531e43c236147d65ba2bf5e44a379f\",\"venue\":\"INTETAIN\",\"year\":2018},{\"arxivId\":\"2012.01405\",\"authors\":[{\"authorId\":\"2013369805\",\"name\":\"Long Zhao\"},{\"authorId\":null,\"name\":\"Yuxiao Wang\"},{\"authorId\":\"7818121\",\"name\":\"Jiaping Zhao\"},{\"authorId\":\"36001694\",\"name\":\"Liangzhe Yuan\"},{\"authorId\":\"13700560\",\"name\":\"J. J. Sun\"},{\"authorId\":\"3302320\",\"name\":\"Florian Schroff\"},{\"authorId\":\"2595180\",\"name\":\"H. Adam\"},{\"authorId\":\"144152343\",\"name\":\"Xi Peng\"},{\"authorId\":\"1965047031\",\"name\":\"Dimitris Metaxas\"},{\"authorId\":\"152244126\",\"name\":\"T. Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"933f59d5fed53f06843f8eb12b94862bf45a5d62\",\"title\":\"Learning View-Disentangled Human Pose Representation by Contrastive Cross-View Mutual Information Maximization\",\"url\":\"https://www.semanticscholar.org/paper/933f59d5fed53f06843f8eb12b94862bf45a5d62\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3403397\",\"name\":\"Arthita Ghosh\"}],\"doi\":\"10.13016/jcrn-mnj6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"37f347de55faca664a9c59ea957e5a85129dc2f5\",\"title\":\"Deep Inference on Multi-Sensor Data\",\"url\":\"https://www.semanticscholar.org/paper/37f347de55faca664a9c59ea957e5a85129dc2f5\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2010.08841\",\"authors\":[{\"authorId\":\"151478121\",\"name\":\"Soufiane Lamghari\"},{\"authorId\":\"1705256\",\"name\":\"Guillaume-Alexandre Bilodeau\"},{\"authorId\":\"48676026\",\"name\":\"N. Saunier\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f10fd7dd1b93c253b96952c27546709190d157cc\",\"title\":\"A Grid-based Representation for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f10fd7dd1b93c253b96952c27546709190d157cc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145905489\",\"name\":\"Y. Huang\"},{\"authorId\":\"1696527\",\"name\":\"S. Lai\"},{\"authorId\":\"35392319\",\"name\":\"Shao-Heng Tai\"}],\"doi\":\"10.1007/978-3-030-11012-3_33\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8639c08322b30a456662e439b5bb7edd2e2551e6\",\"title\":\"Human Action Recognition Based on Temporal Pose CNN and Multi-dimensional Fusion\",\"url\":\"https://www.semanticscholar.org/paper/8639c08322b30a456662e439b5bb7edd2e2551e6\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"1711.08362\",\"authors\":[{\"authorId\":\"8120382\",\"name\":\"P. Wang\"},{\"authorId\":\"1685696\",\"name\":\"W. Li\"},{\"authorId\":\"1719314\",\"name\":\"P. Ogunbona\"},{\"authorId\":\"145121530\",\"name\":\"Jun Wan\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"}],\"doi\":\"10.1016/j.cviu.2018.04.007\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"224b34acba3597912f8adc288fa8adbb1fca92b4\",\"title\":\"RGB-D-based Human Motion Recognition with Deep Learning: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/224b34acba3597912f8adc288fa8adbb1fca92b4\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2018},{\"arxivId\":\"1808.00022\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":\"10.1016/j.cviu.2019.102799\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ef7b835c451793a6ea603fa3d5441901832c404e\",\"title\":\"Analyzing human-human interactions: A survey\",\"url\":\"https://www.semanticscholar.org/paper/ef7b835c451793a6ea603fa3d5441901832c404e\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2019},{\"arxivId\":\"1904.09140\",\"authors\":[{\"authorId\":\"2505740\",\"name\":\"Dennis Ludl\"},{\"authorId\":\"7932331\",\"name\":\"T. Gulde\"},{\"authorId\":\"8045043\",\"name\":\"C. Curio\"}],\"doi\":\"10.1109/ITSC.2019.8917128\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f889fe0875881b3cfa7a424eaf99f7dfd02738ce\",\"title\":\"Simple yet efficient real-time pose-based action recognition\",\"url\":\"https://www.semanticscholar.org/paper/f889fe0875881b3cfa7a424eaf99f7dfd02738ce\",\"venue\":\"2019 IEEE Intelligent Transportation Systems Conference (ITSC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47842072\",\"name\":\"M. Liu\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1109/CVPR.2018.00127\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"63f7760e25420803ec969dad25ce40c796a21915\",\"title\":\"Recognizing Human Actions as the Evolution of Pose Estimation Maps\",\"url\":\"https://www.semanticscholar.org/paper/63f7760e25420803ec969dad25ce40c796a21915\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51303461\",\"name\":\"Zixuan Wang\"},{\"authorId\":\"2643261\",\"name\":\"A. Zhu\"},{\"authorId\":\"2646598\",\"name\":\"F. Hu\"},{\"authorId\":\"84175736\",\"name\":\"Qianyu Wu\"},{\"authorId\":\"50025538\",\"name\":\"Y. Li\"}],\"doi\":\"10.1117/1.JEI.29.4.043025\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dd4ae0706b11408070ef88390215b9237f58a0fe\",\"title\":\"Two-stream spatial-temporal neural networks for pose-based action recognition\",\"url\":\"https://www.semanticscholar.org/paper/dd4ae0706b11408070ef88390215b9237f58a0fe\",\"venue\":\"J. Electronic Imaging\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9256770\",\"name\":\"T. Kokul\"},{\"authorId\":\"3140440\",\"name\":\"C. Fookes\"},{\"authorId\":\"1729760\",\"name\":\"S. Sridharan\"},{\"authorId\":\"145410912\",\"name\":\"A. Ramanan\"},{\"authorId\":\"2808342\",\"name\":\"Amalka Pinidiyaarachchi\"}],\"doi\":\"10.1109/TIFS.2019.2935871\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"93f6d3030e139fe2e4a64c4de3eb83c145d8e0b7\",\"title\":\"Target-Specific Siamese Attention Network for Real-Time Object Tracking\",\"url\":\"https://www.semanticscholar.org/paper/93f6d3030e139fe2e4a64c4de3eb83c145d8e0b7\",\"venue\":\"IEEE Transactions on Information Forensics and Security\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47842072\",\"name\":\"M. Liu\"},{\"authorId\":\"1774797\",\"name\":\"Fanyang Meng\"},{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"2525392\",\"name\":\"S. Wu\"}],\"doi\":\"10.1609/AAAI.V33I01.33018762\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"32c216b09b1208585a70cff674460735bd9939fe\",\"title\":\"Joint Dynamic Pose Image and Space Time Reversal for Human Action Recognition from Videos\",\"url\":\"https://www.semanticscholar.org/paper/32c216b09b1208585a70cff674460735bd9939fe\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1740590214\",\"name\":\"Mustansar Fiaz\"},{\"authorId\":\"38243491\",\"name\":\"A. Mahmood\"},{\"authorId\":\"1779835\",\"name\":\"S. K. Jung\"}],\"doi\":\"10.3390/s20144021\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9fe233b41ddb40188187dc7c4122aa59f6809ae8\",\"title\":\"Learning Soft Mask Based Feature Fusion with Channel and Spatial Attention for Robust Visual Object Tracking\",\"url\":\"https://www.semanticscholar.org/paper/9fe233b41ddb40188187dc7c4122aa59f6809ae8\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1720818\",\"name\":\"Sebastian Agethen\"},{\"authorId\":\"3245101\",\"name\":\"Hu-Cheng Lee\"},{\"authorId\":\"1716836\",\"name\":\"W. Hsu\"}],\"doi\":\"10.1109/CVPRW.2019.00357\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"73a006022a64a7de18cd99ba7c7cb570e0566e38\",\"title\":\"Anticipation of Human Actions With Pose-Based Fine-Grained Representations\",\"url\":\"https://www.semanticscholar.org/paper/73a006022a64a7de18cd99ba7c7cb570e0566e38\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2599734\",\"name\":\"I. Lee\"},{\"authorId\":\"8307027\",\"name\":\"D. Y. Kim\"},{\"authorId\":\"72490873\",\"name\":\"S. Lee\"}],\"doi\":\"10.1109/TMM.2020.2978637\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"df84818634b8d82a10faf6a35f2775be002f1a6f\",\"title\":\"3-D Human Behavior Understanding Using Generalized TS-LSTM Networks\",\"url\":\"https://www.semanticscholar.org/paper/df84818634b8d82a10faf6a35f2775be002f1a6f\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2021},{\"arxivId\":\"1912.08077\",\"authors\":[{\"authorId\":\"26988468\",\"name\":\"Diogo C. Luvizon\"},{\"authorId\":\"2397984\",\"name\":\"H. Tabia\"},{\"authorId\":\"145897899\",\"name\":\"D. Picard\"}],\"doi\":\"10.1109/TPAMI.2020.2976014\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"145e426e378b29ea5cf62f5300f337561b3c2784\",\"title\":\"Multi-task Deep Learning for Real-Time 3D Human Pose Estimation and Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/145e426e378b29ea5cf62f5300f337561b3c2784\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47837986\",\"name\":\"An Yan\"},{\"authorId\":null,\"name\":\"Yali Wang\"},{\"authorId\":\"9247990\",\"name\":\"Zhifeng Li\"},{\"authorId\":\"143970608\",\"name\":\"Y. Qiao\"}],\"doi\":\"10.1109/CVPR.2019.00811\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4ef4bdad7673050b3764e06a26085f9f8ef11e50\",\"title\":\"PA3D: Pose-Action 3D Machine for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4ef4bdad7673050b3764e06a26085f9f8ef11e50\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2826103\",\"name\":\"B. Yu\"},{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":null,\"name\":\"Jian Zhou\"}],\"doi\":\"10.1109/ACCESS.2019.2928337\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"157a2031513cfb017850cd603be0d4e7a989d6aa\",\"title\":\"Cross-Media Body-Part Attention Network for Image-to-Video Person Re-Identification\",\"url\":\"https://www.semanticscholar.org/paper/157a2031513cfb017850cd603be0d4e7a989d6aa\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40256896\",\"name\":\"L. Wang\"},{\"authorId\":\"1758267\",\"name\":\"X. Zhao\"},{\"authorId\":\"1701515\",\"name\":\"Y. Liu\"}],\"doi\":\"10.1109/ACCESS.2018.2869751\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7f9b192dad9f85289016c8a089d2a6a65ed1224a\",\"title\":\"Skeleton Feature Fusion Based on Multi-Stream LSTM for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7f9b192dad9f85289016c8a089d2a6a65ed1224a\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2040383318\",\"name\":\"Jia Lu\"},{\"authorId\":\"144688130\",\"name\":\"M. Nguyen\"},{\"authorId\":\"40370973\",\"name\":\"Wei Qi Yan\"}],\"doi\":\"10.1109/IVCNZ51579.2020.9290640\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e47867c1d4c4f9ebf01b9dd876ce4b61b980bcb5\",\"title\":\"Deep Learning Methods for Human Behavior Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e47867c1d4c4f9ebf01b9dd876ce4b61b980bcb5\",\"venue\":\"2020 35th International Conference on Image and Vision Computing New Zealand (IVCNZ)\",\"year\":2020},{\"arxivId\":\"2011.00043\",\"authors\":[{\"authorId\":\"21518096\",\"name\":\"Zhengyuan Yang\"},{\"authorId\":\"48984081\",\"name\":\"A. Kay\"},{\"authorId\":\"66508219\",\"name\":\"Y. Li\"},{\"authorId\":\"5687436\",\"name\":\"W. Cross\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"41595f75fd06219109f57c084b4c8eae1352b410\",\"title\":\"Pose-based Body Language Recognition for Emotion and Psychiatric Symptom Interpretation\",\"url\":\"https://www.semanticscholar.org/paper/41595f75fd06219109f57c084b4c8eae1352b410\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.06317\",\"authors\":[{\"authorId\":\"3458134\",\"name\":\"Gyeongsik Moon\"},{\"authorId\":\"30557120\",\"name\":\"Heeseung Kwon\"},{\"authorId\":\"2135837\",\"name\":\"Kyoung Mu Lee\"},{\"authorId\":\"72643925\",\"name\":\"Minsu Cho\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8230c73193abe9f42306a311d75557a902e785f6\",\"title\":\"IntegralAction: Pose-driven Feature Integration for Robust Human Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/8230c73193abe9f42306a311d75557a902e785f6\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":36571045,\"doi\":\"10.1109/ICCV.2017.402\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":10,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"a470a81f989d5354239f1044c90e07b78c6beed7\",\"references\":[{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1607.01794\",\"authors\":[{\"authorId\":\"3245057\",\"name\":\"Zhenyang Li\"},{\"authorId\":\"32781361\",\"name\":\"Kirill Gavrilyuk\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"143798882\",\"name\":\"Mihir Jain\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1016/j.cviu.2017.10.011\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"86031f555c128b82a1ac0db89ff4faeae16a1802\",\"title\":\"VideoLSTM convolves, attends and flows for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/86031f555c128b82a1ac0db89ff4faeae16a1802\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1975564\",\"name\":\"M. Zanfir\"},{\"authorId\":\"1749627\",\"name\":\"M. Leordeanu\"},{\"authorId\":\"1781120\",\"name\":\"C. Sminchisescu\"}],\"doi\":\"10.1109/ICCV.2013.342\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"55541d61863f7c2171897db0a7d89465bea8420d\",\"title\":\"The Moving Pose: An Efficient 3D Kinematics Descriptor for Low-Latency Action Recognition and Detection\",\"url\":\"https://www.semanticscholar.org/paper/55541d61863f7c2171897db0a7d89465bea8420d\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":\"10.1016/j.imavis.2009.11.014\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d984b580e02da76cd4d991953e6d430fadf3d578\",\"title\":\"A survey on vision-based human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/d984b580e02da76cd4d991953e6d430fadf3d578\",\"venue\":\"Image Vis. Comput.\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2676982\",\"name\":\"Hueihan Jhuang\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"},{\"authorId\":\"2133988\",\"name\":\"S. Zuffi\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"}],\"doi\":\"10.1109/ICCV.2013.396\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"2cee43afc7aad6a8f7c4a6d566b60ebc79d57e7a\",\"title\":\"Towards Understanding Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2cee43afc7aad6a8f7c4a6d566b60ebc79d57e7a\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/ICCV.2015.510\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"title\":\"Learning Spatiotemporal Features with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2013.441\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d721f4d64b8e722222c876f0a0f226ed49476347\",\"title\":\"Action Recognition with Improved Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/d721f4d64b8e722222c876f0a0f226ed49476347\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34792176\",\"name\":\"Xiaohan Nie\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/CVPR.2015.7298734\",\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"bb4291452a25ff2f84f5af6de36b04c1d4d81b12\",\"title\":\"Joint action recognition and pose estimation from video\",\"url\":\"https://www.semanticscholar.org/paper/bb4291452a25ff2f84f5af6de36b04c1d4d81b12\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"88649317\",\"name\":\"G. Johansson\"}],\"doi\":\"10.3758/BF03212378\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"58ea2fa0580b2117618be6e1cc9658a5c9531dba\",\"title\":\"Visual perception of biological motion and a model for its analysis\",\"url\":\"https://www.semanticscholar.org/paper/58ea2fa0580b2117618be6e1cc9658a5c9531dba\",\"venue\":\"\",\"year\":1973},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144061516\",\"name\":\"L. Tao\"},{\"authorId\":\"144020730\",\"name\":\"R. Vidal\"}],\"doi\":\"10.1109/ICCVW.2015.48\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e10083570218be36f982b3819c5dae60f4d81089\",\"title\":\"Moving Poselets: A Discriminative and Interpretable Skeletal Motion Representation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e10083570218be36f982b3819c5dae60f4d81089\",\"venue\":\"2015 IEEE International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2015},{\"arxivId\":\"1510.00562\",\"authors\":[{\"authorId\":\"41191188\",\"name\":\"Lin Sun\"},{\"authorId\":\"2370507\",\"name\":\"K. Jia\"},{\"authorId\":\"1739816\",\"name\":\"D. Yeung\"},{\"authorId\":\"2131088\",\"name\":\"B. Shi\"}],\"doi\":\"10.1109/ICCV.2015.522\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"95561aec9f00cdf5346e627574e1a022eda3e4f5\",\"title\":\"Human Action Recognition Using Factorized Spatio-Temporal Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/95561aec9f00cdf5346e627574e1a022eda3e4f5\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49963740\",\"name\":\"Y. Du\"},{\"authorId\":null,\"name\":\"Wei Wang\"},{\"authorId\":null,\"name\":\"Liang Wang\"}],\"doi\":\"10.1109/CVPR.2015.7298714\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1839e17555160bd897b978c48b8ebd13dd21445f\",\"title\":\"Hierarchical recurrent neural network for skeleton based action recognition\",\"url\":\"https://www.semanticscholar.org/paper/1839e17555160bd897b978c48b8ebd13dd21445f\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3201156\",\"name\":\"Congqi Cao\"},{\"authorId\":\"40382978\",\"name\":\"Yifan Zhang\"},{\"authorId\":\"1713887\",\"name\":\"C. Zhang\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2f66086e4cbb22c5736c836614830489f9594b91\",\"title\":\"Action Recognition with Joints-Pooled 3D Deep Convolutional Descriptors\",\"url\":\"https://www.semanticscholar.org/paper/2f66086e4cbb22c5736c836614830489f9594b91\",\"venue\":\"IJCAI\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121900578\",\"name\":\"Chunyu Wang\"},{\"authorId\":\"1717863\",\"name\":\"Yizhou Wang\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.1109/CVPR.2013.123\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"21258b55048a5038e3f6167b03e4fa2314ecf628\",\"title\":\"An Approach to Pose-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/21258b55048a5038e3f6167b03e4fa2314ecf628\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1506.02897\",\"authors\":[{\"authorId\":\"1945962\",\"name\":\"T. Pfister\"},{\"authorId\":\"145682405\",\"name\":\"J. Charles\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/ICCV.2015.222\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f22f25904f85c657e10fcc262653ebb6187193f9\",\"title\":\"Flowing ConvNets for Human Pose Estimation in Videos\",\"url\":\"https://www.semanticscholar.org/paper/f22f25904f85c657e10fcc262653ebb6187193f9\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1603.06937\",\"authors\":[{\"authorId\":\"31688710\",\"name\":\"Alejandro Newell\"},{\"authorId\":\"34284131\",\"name\":\"Kaiyu Yang\"},{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"}],\"doi\":\"10.1007/978-3-319-46484-8_29\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"848938e6199bad08f1db6f3239b260cfa901e95f\",\"title\":\"Stacked Hourglass Networks for Human Pose Estimation\",\"url\":\"https://www.semanticscholar.org/paper/848938e6199bad08f1db6f3239b260cfa901e95f\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1507.05738\",\"authors\":[{\"authorId\":\"34149749\",\"name\":\"Serena Yeung\"},{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"47243342\",\"name\":\"N. Jin\"},{\"authorId\":\"1906895\",\"name\":\"M. Andriluka\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-017-1013-y\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aa2d1dac4e27aebfb759d6e0b41b8a8ab1b01406\",\"title\":\"Every Moment Counts: Dense Detailed Labeling of Actions in Complex Videos\",\"url\":\"https://www.semanticscholar.org/paper/aa2d1dac4e27aebfb759d6e0b41b8a8ab1b01406\",\"venue\":\"International Journal of Computer Vision\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"152821938\",\"name\":\"Sanketh Shetty\"},{\"authorId\":\"120906511\",\"name\":\"T. Leung\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2014.223\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"title\":\"Large-Scale Video Classification with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1511.04119\",\"authors\":[{\"authorId\":\"145478041\",\"name\":\"Shikhar Sharma\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7b8810ad8ef9ddd024583f95a51559e6c1b8c754\",\"title\":\"Action Recognition using Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/7b8810ad8ef9ddd024583f95a51559e6c1b8c754\",\"venue\":\"NIPS 2015\",\"year\":2015},{\"arxivId\":\"1409.4842\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"46641766\",\"name\":\"W. Liu\"},{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"},{\"authorId\":\"48840704\",\"name\":\"Scott Reed\"},{\"authorId\":\"1838674\",\"name\":\"Dragomir Anguelov\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"39863668\",\"name\":\"Andrew Rabinovich\"}],\"doi\":\"10.1109/CVPR.2015.7298594\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"title\":\"Going deeper with convolutions\",\"url\":\"https://www.semanticscholar.org/paper/e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1406.2199\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"title\":\"Two-Stream Convolutional Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/ICCV.2009.5459303\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"55b29a2505149d06d8c1d616cd30edca40cb029c\",\"title\":\"Poselets: Body part detectors trained using 3D human pose annotations\",\"url\":\"https://www.semanticscholar.org/paper/55b29a2505149d06d8c1d616cd30edca40cb029c\",\"venue\":\"2009 IEEE 12th International Conference on Computer Vision\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49039493\",\"name\":\"W. Zhang\"},{\"authorId\":\"2717876\",\"name\":\"Menglong Zhu\"},{\"authorId\":\"3150825\",\"name\":\"K. Derpanis\"}],\"doi\":\"10.1109/ICCV.2013.280\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"f7636582c8abb648c4bb870b228f9ffbc6843c34\",\"title\":\"From Actemes to Action: A Strongly-Supervised Representation for Detailed Action Understanding\",\"url\":\"https://www.semanticscholar.org/paper/f7636582c8abb648c4bb870b228f9ffbc6843c34\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":\"1502.04681\",\"authors\":[{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"2711409\",\"name\":\"Elman Mansimov\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"title\":\"Unsupervised Learning of Video Representations using LSTMs\",\"url\":\"https://www.semanticscholar.org/paper/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2631071\",\"name\":\"Ninghang Hu\"},{\"authorId\":\"2654643\",\"name\":\"G. Englebienne\"},{\"authorId\":\"39793067\",\"name\":\"Zhongyu Lou\"},{\"authorId\":\"1804676\",\"name\":\"B. Kr\\u00f6se\"}],\"doi\":\"10.1109/ICRA.2014.6906983\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0d20b286c639355d9322b98674a1a61d83abd589\",\"title\":\"Learning latent structure for activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/0d20b286c639355d9322b98674a1a61d83abd589\",\"venue\":\"2014 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2014},{\"arxivId\":\"1412.2302\",\"authors\":[{\"authorId\":\"50759073\",\"name\":\"Weiguang Ding\"},{\"authorId\":\"1892380\",\"name\":\"Ruoyan Wang\"},{\"authorId\":\"40417629\",\"name\":\"F. Mao\"},{\"authorId\":\"144639556\",\"name\":\"Graham W. Taylor\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"937a4f3c6fb6d8a1da41dcb024e1a4ed97bd8fe5\",\"title\":\"Theano-based Large-Scale Visual Recognition with Multiple GPUs\",\"url\":\"https://www.semanticscholar.org/paper/937a4f3c6fb6d8a1da41dcb024e1a4ed97bd8fe5\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1603.09065\",\"authors\":[{\"authorId\":\"145982988\",\"name\":\"Xiao Chu\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"49404547\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1109/CVPR.2016.510\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6e36ca41a32008d506f57f04d7038b2566c40a97\",\"title\":\"Structured Feature Learning for Pose Estimation\",\"url\":\"https://www.semanticscholar.org/paper/6e36ca41a32008d506f57f04d7038b2566c40a97\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1603.04037\",\"authors\":[{\"authorId\":\"145042308\",\"name\":\"U. Iqbal\"},{\"authorId\":\"3370510\",\"name\":\"Martin Garbade\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1109/FG.2017.61\",\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"c5c48fb5d8f1403f8aa5392045fcdfd79b37a934\",\"title\":\"Pose for Action - Action for Pose\",\"url\":\"https://www.semanticscholar.org/paper/c5c48fb5d8f1403f8aa5392045fcdfd79b37a934\",\"venue\":\"2017 12th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2017)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46396571\",\"name\":\"Y. Wang\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c78ba9e1530aa2a54d2e5557c2466952c913ce7f\",\"title\":\"Learning a discriminative hidden part model for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/c78ba9e1530aa2a54d2e5557c2466952c913ce7f\",\"venue\":\"NIPS\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1405.2941\",\"authors\":[{\"authorId\":\"40579682\",\"name\":\"J. Wang\"},{\"authorId\":\"34792176\",\"name\":\"Xiaohan Nie\"},{\"authorId\":\"49289914\",\"name\":\"Y. Xia\"},{\"authorId\":\"50118130\",\"name\":\"Y. Wu\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/CVPR.2014.339\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5de214630011554bd07b41ec5bd493c7f65c532e\",\"title\":\"Cross-View Action Modeling, Learning, and Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5de214630011554bd07b41ec5bd493c7f65c532e\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1507.06550\",\"authors\":[{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"33932184\",\"name\":\"Pulkit Agrawal\"},{\"authorId\":\"1705557\",\"name\":\"K. Fragkiadaki\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/CVPR.2016.512\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"66d4475f0eee4b65983e06b1fbafad533eb81b2a\",\"title\":\"Human Pose Estimation with Iterative Error Feedback\",\"url\":\"https://www.semanticscholar.org/paper/66d4475f0eee4b65983e06b1fbafad533eb81b2a\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1604.06573\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2016.213\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9d9aced120e530484609164c836da64548693484\",\"title\":\"Convolutional Two-Stream Network Fusion for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9d9aced120e530484609164c836da64548693484\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1506.03607\",\"authors\":[{\"authorId\":\"1902524\",\"name\":\"Guilhem Ch\\u00e9ron\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2015.368\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c4697681079de557cc04e209762b1a4c1eaae709\",\"title\":\"P-CNN: Pose-Based CNN Features for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c4697681079de557cc04e209762b1a4c1eaae709\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"}],\"doi\":\"10.1007/s11263-005-1838-7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d2fb2fa53021b2776da0fb8b53c54820ed3982cc\",\"title\":\"On Space-Time Interest Points\",\"url\":\"https://www.semanticscholar.org/paper/d2fb2fa53021b2776da0fb8b53c54820ed3982cc\",\"venue\":\"International Journal of Computer Vision\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743600\",\"name\":\"S. Ji\"},{\"authorId\":\"143836295\",\"name\":\"W. Xu\"},{\"authorId\":\"41216159\",\"name\":\"Ming Yang\"},{\"authorId\":\"144782042\",\"name\":\"Kai Yu\"}],\"doi\":\"10.1109/TPAMI.2012.59\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"80bfcf1be2bf1b95cc6f36d229665cdf22d76190\",\"title\":\"3D Convolutional Neural Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/80bfcf1be2bf1b95cc6f36d229665cdf22d76190\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":\"1507.02159\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1f05473c587e2a3b587f51eb808695a1c10bc153\",\"title\":\"Towards Good Practices for Very Deep Two-Stream ConvNets\",\"url\":\"https://www.semanticscholar.org/paper/1f05473c587e2a3b587f51eb808695a1c10bc153\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2121584\",\"name\":\"Wangjiang Zhu\"},{\"authorId\":\"145815850\",\"name\":\"Jie Hu\"},{\"authorId\":\"143847421\",\"name\":\"Gang Sun\"},{\"authorId\":\"47300766\",\"name\":\"X. Cao\"},{\"authorId\":\"143970608\",\"name\":\"Y. Qiao\"}],\"doi\":\"10.1109/CVPR.2016.219\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4c822785c29ceaf67a0de9c699716c94fefbd37d\",\"title\":\"A Key Volume Mining Deep Framework for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4c822785c29ceaf67a0de9c699716c94fefbd37d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1406.2984\",\"authors\":[{\"authorId\":\"2704494\",\"name\":\"J. Tompson\"},{\"authorId\":\"49147969\",\"name\":\"A. Jain\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"},{\"authorId\":\"2428034\",\"name\":\"C. Bregler\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"12ecc2d786080f638a01b9999518e9386baa157d\",\"title\":\"Joint Training of a Convolutional Network and a Graphical Model for Human Pose Estimation\",\"url\":\"https://www.semanticscholar.org/paper/12ecc2d786080f638a01b9999518e9386baa157d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2909350\",\"name\":\"Alexander Kl\\u00e4ser\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"1689269\",\"name\":\"C. Liu\"}],\"doi\":\"10.1109/CVPR.2011.5995407\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3afbb0e64fcb70496b44b30b76fac9456cc51e34\",\"title\":\"Action recognition by dense trajectories\",\"url\":\"https://www.semanticscholar.org/paper/3afbb0e64fcb70496b44b30b76fac9456cc51e34\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":\"1312.4659\",\"authors\":[{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":\"10.1109/CVPR.2014.214\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2a002ce457f7ab3088fbd2691734f1ce79f750c4\",\"title\":\"DeepPose: Human Pose Estimation via Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/2a002ce457f7ab3088fbd2691734f1ce79f750c4\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1007/978-3-319-10602-1_37\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d9c9b8194ac81f97bfedb7d15124e7b80c3c3d68\",\"title\":\"Video Action Detection with Relational Dynamic-Poselets\",\"url\":\"https://www.semanticscholar.org/paper/d9c9b8194ac81f97bfedb7d15124e7b80c3c3d68\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1505.04868\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1109/CVPR.2015.7299059\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"df658828fb4146877f1031ec9d07052f7eb31186\",\"title\":\"Action recognition with trajectory-pooled deep-convolutional descriptors\",\"url\":\"https://www.semanticscholar.org/paper/df658828fb4146877f1031ec9d07052f7eb31186\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1602.00134\",\"authors\":[{\"authorId\":\"2797981\",\"name\":\"Shih-En Wei\"},{\"authorId\":\"20569810\",\"name\":\"V. Ramakrishna\"},{\"authorId\":\"1733113\",\"name\":\"T. Kanade\"},{\"authorId\":\"1774867\",\"name\":\"Yaser Sheikh\"}],\"doi\":\"10.1109/CVPR.2016.511\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"864e7db59f2ccfec1ee9f6eba79566ac7b0634df\",\"title\":\"Convolutional Pose Machines\",\"url\":\"https://www.semanticscholar.org/paper/864e7db59f2ccfec1ee9f6eba79566ac7b0634df\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1608.00859\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-319-46484-8_2\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"title\":\"Temporal Segment Networks: Towards Good Practices for Deep Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1606.04992\",\"authors\":[{\"authorId\":\"1763954\",\"name\":\"I. Lillo\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"144106940\",\"name\":\"A. Soto\"}],\"doi\":\"10.1109/CVPR.2016.218\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5a60a0a074570d245d0d9c8d505b5c9ae303fed5\",\"title\":\"A Hierarchical Pose-Based Approach to Complex Action Understanding Using Dictionaries of Actionlets and Motion Poselets\",\"url\":\"https://www.semanticscholar.org/paper/5a60a0a074570d245d0d9c8d505b5c9ae303fed5\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1503.08909\",\"authors\":[{\"authorId\":\"2340579\",\"name\":\"J. Ng\"},{\"authorId\":\"3308897\",\"name\":\"Matthew J. Hausknecht\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"49519592\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"3089272\",\"name\":\"Rajat Monga\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"}],\"doi\":\"10.1109/CVPR.2015.7299101\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5418b2a482720e013d487a385c26fae0f017c6a6\",\"title\":\"Beyond short snippets: Deep networks for video classification\",\"url\":\"https://www.semanticscholar.org/paper/5418b2a482720e013d487a385c26fae0f017c6a6\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1511.06432\",\"authors\":[{\"authorId\":\"2482072\",\"name\":\"Nicolas Ballas\"},{\"authorId\":\"145095579\",\"name\":\"L. Yao\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ed95c6bcdc16fb1f68b20d5bcd15c4aca4d0abde\",\"title\":\"Delving Deeper into Convolutional Networks for Learning Video Representations\",\"url\":\"https://www.semanticscholar.org/paper/ed95c6bcdc16fb1f68b20d5bcd15c4aca4d0abde\",\"venue\":\"ICLR\",\"year\":2016}],\"title\":\"RPAN: An End-to-End Recurrent Pose-Attention Network for Action Recognition in Videos\",\"topics\":[{\"topic\":\"Recurrent neural network\",\"topicId\":\"16115\",\"url\":\"https://www.semanticscholar.org/topic/16115\"},{\"topic\":\"Unified Framework\",\"topicId\":\"105596\",\"url\":\"https://www.semanticscholar.org/topic/105596\"},{\"topic\":\"End-to-end principle\",\"topicId\":\"299633\",\"url\":\"https://www.semanticscholar.org/topic/299633\"},{\"topic\":\"Long short-term memory\",\"topicId\":\"117199\",\"url\":\"https://www.semanticscholar.org/topic/117199\"},{\"topic\":\"Neural Networks\",\"topicId\":\"99954\",\"url\":\"https://www.semanticscholar.org/topic/99954\"},{\"topic\":\"3D pose estimation\",\"topicId\":\"16658\",\"url\":\"https://www.semanticscholar.org/topic/16658\"}],\"url\":\"https://www.semanticscholar.org/paper/a470a81f989d5354239f1044c90e07b78c6beed7\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017}\n"