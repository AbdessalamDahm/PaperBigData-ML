"{\"abstract\":\"We present a framework to analyze various aspects of models for video question answering (VideoQA) using customizable synthetic datasets, which are constructed automatically from gameplay videos. Our work is motivated by the fact that existing models are often tested only on datasets that require excessively high-level reasoning or mostly contain instances accessible through single frame inferences. Hence, it is difficult to measure capacity and flexibility of trained models, and existing techniques often rely on adhoc implementations of deep neural networks without clear insight into datasets and models. We are particularly interested in understanding temporal relationships between video events to solve VideoQA problems; this is because reasoning temporal dependency is one of the most distinct components in videos from images. To address this objective, we automatically generate a customized synthetic VideoQA dataset using Super Mario Bros. gameplay videos so that it contains events with different levels of reasoning complexity. Using the dataset, we show that properly constructed datasets with events in various complexity levels are critical to learn effective models and improve overall performance.\",\"arxivId\":\"1612.01669\",\"authors\":[{\"authorId\":\"8511875\",\"name\":\"Jonghwan Mun\",\"url\":\"https://www.semanticscholar.org/author/8511875\"},{\"authorId\":\"14454974\",\"name\":\"P. H. Seo\",\"url\":\"https://www.semanticscholar.org/author/14454974\"},{\"authorId\":\"3386346\",\"name\":\"Ilchae Jung\",\"url\":\"https://www.semanticscholar.org/author/3386346\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\",\"url\":\"https://www.semanticscholar.org/author/40030651\"}],\"citationVelocity\":14,\"citations\":[{\"arxivId\":\"1907.05006\",\"authors\":[{\"authorId\":\"150065958\",\"name\":\"Chiwan Song\"},{\"authorId\":\"40506942\",\"name\":\"Woobin Im\"},{\"authorId\":\"144182454\",\"name\":\"Sung-eui Yoon\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b48cf57d41e81f201a756c6b280fa2ebfe52f9d3\",\"title\":\"Two-stream Spatiotemporal Feature for Video QA Task\",\"url\":\"https://www.semanticscholar.org/paper/b48cf57d41e81f201a756c6b280fa2ebfe52f9d3\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"16726627\",\"name\":\"C. Liu\"},{\"authorId\":\"2785372\",\"name\":\"Ding-Jie Chen\"},{\"authorId\":\"1803730\",\"name\":\"Hwann-Tzong Chen\"},{\"authorId\":\"1805102\",\"name\":\"Tyng-Luh Liu\"}],\"doi\":\"10.1007/978-3-030-20876-9_26\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"1687d0120e937d5efe2022cbeab19b38edba0608\",\"title\":\"A2A: Attention to Attention Reasoning for Movie Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1687d0120e937d5efe2022cbeab19b38edba0608\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"1712.03316\",\"authors\":[{\"authorId\":\"152462964\",\"name\":\"Daniel Gordon\"},{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"},{\"authorId\":\"143887493\",\"name\":\"M. Rastegari\"},{\"authorId\":\"40497777\",\"name\":\"Joseph Redmon\"},{\"authorId\":\"145197953\",\"name\":\"D. Fox\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"}],\"doi\":\"10.1109/CVPR.2018.00430\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b0cd469a06fb2eae3a5cc0c860aa592f71b13f6d\",\"title\":\"IQA: Visual Question Answering in Interactive Environments\",\"url\":\"https://www.semanticscholar.org/paper/b0cd469a06fb2eae3a5cc0c860aa592f71b13f6d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41052836\",\"name\":\"Anya Belz\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"}],\"doi\":\"10.1017/S1351324918000086\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d740802aa22dbc187fe5df39108ba493b34d2839\",\"title\":\"From image to language and back again\",\"url\":\"https://www.semanticscholar.org/paper/d740802aa22dbc187fe5df39108ba493b34d2839\",\"venue\":\"Nat. Lang. Eng.\",\"year\":2018},{\"arxivId\":\"1708.01641\",\"authors\":[{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"39231399\",\"name\":\"O. Wang\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"145160921\",\"name\":\"Bryan C. Russell\"}],\"doi\":\"10.1109/ICCV.2017.618\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ee909ad489244016cf301bb7d7d8eeea423dbf35\",\"title\":\"Localizing Moments in Video with Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/ee909ad489244016cf301bb7d7d8eeea423dbf35\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"dd7062e6f84750688fa96143209efc801e91f9bd\",\"title\":\"Visual Understanding through Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/dd7062e6f84750688fa96143209efc801e91f9bd\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1910.01442\",\"authors\":[{\"authorId\":\"40879119\",\"name\":\"Kexin Yi\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"3422021\",\"name\":\"Yunzhu Li\"},{\"authorId\":\"143967473\",\"name\":\"P. Kohli\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7f3ecbe546efed8ba42812f977354c16590bad77\",\"title\":\"CLEVRER: CoLlision Events for Video REpresentation and Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/7f3ecbe546efed8ba42812f977354c16590bad77\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"1906.09844\",\"authors\":[{\"authorId\":\"2052119\",\"name\":\"Zhaoquan Yuan\"},{\"authorId\":\"47393013\",\"name\":\"Siyuan Sun\"},{\"authorId\":\"2055900\",\"name\":\"Lixin Duan\"},{\"authorId\":\"116155759\",\"name\":\"Xiao Wu\"},{\"authorId\":\"48258806\",\"name\":\"Changsheng Xu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b5b0228f4955add9bdf0edbf66e0d3df6f38a993\",\"title\":\"Adversarial Multimodal Network for Movie Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b5b0228f4955add9bdf0edbf66e0d3df6f38a993\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40295709\",\"name\":\"F. Liu\"},{\"authorId\":null,\"name\":\"Jing Liu\"},{\"authorId\":\"48386951\",\"name\":\"Xinxin Zhu\"},{\"authorId\":\"120313754\",\"name\":\"Richang Hong\"},{\"authorId\":\"1699900\",\"name\":\"H. Lu\"}],\"doi\":\"10.1145/3394171.3413649\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"063235546b312ee4cb5cc67578b6e879461c6d83\",\"title\":\"Dual Hierarchical Temporal Convolutional Network with QA-Aware Dynamic Normalization for Video Story Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/063235546b312ee4cb5cc67578b6e879461c6d83\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1904.00623\",\"authors\":[{\"authorId\":\"15353659\",\"name\":\"Yu-Jung Heo\"},{\"authorId\":\"2943489\",\"name\":\"Kyoung-Woon On\"},{\"authorId\":\"7236400\",\"name\":\"S. Choi\"},{\"authorId\":\"70262116\",\"name\":\"Jaeseo Lim\"},{\"authorId\":\"7951400\",\"name\":\"J. Kim\"},{\"authorId\":\"89496405\",\"name\":\"Jeh-Kwang Ryu\"},{\"authorId\":\"39171461\",\"name\":\"B. Bae\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"b27b6df500b4fc50092f22727a90111b2010a588\",\"title\":\"Constructing Hierarchical Q&A Datasets for Video Story Understanding\",\"url\":\"https://www.semanticscholar.org/paper/b27b6df500b4fc50092f22727a90111b2010a588\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1907.03049\",\"authors\":[{\"authorId\":null,\"name\":\"Yu-Siang Wang\"},{\"authorId\":\"71309591\",\"name\":\"Hung-Ting Su\"},{\"authorId\":\"150053992\",\"name\":\"Chen-Hsi Chang\"},{\"authorId\":\"143822897\",\"name\":\"Zhe Yu Liu\"},{\"authorId\":\"31871157\",\"name\":\"Winston Hsu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"091ad302f5381bd131b41a57e16d802ff4ab9668\",\"title\":\"Video Question Generation via Cross-Modal Self-Attention Networks Learning\",\"url\":\"https://www.semanticscholar.org/paper/091ad302f5381bd131b41a57e16d802ff4ab9668\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1582890834\",\"name\":\"Zekun Yang\"},{\"authorId\":\"26385137\",\"name\":\"Noa Garcia\"},{\"authorId\":\"2427516\",\"name\":\"Chenhui Chu\"},{\"authorId\":\"3186326\",\"name\":\"Mayu Otani\"},{\"authorId\":\"1789677\",\"name\":\"Yuta Nakashima\"},{\"authorId\":\"1748743\",\"name\":\"H. Takemura\"}],\"doi\":\"10.1109/WACV45572.2020.9093596\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"39b2d8b8233a53dc7eadb819c52213369dff8648\",\"title\":\"BERT Representations for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/39b2d8b8233a53dc7eadb819c52213369dff8648\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1906.00067\",\"authors\":[{\"authorId\":\"35789996\",\"name\":\"Kenneth Marino\"},{\"authorId\":\"143887493\",\"name\":\"M. Rastegari\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"3012475\",\"name\":\"R. Mottaghi\"}],\"doi\":\"10.1109/CVPR.2019.00331\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"28ad018c39d1578bea84e7cedf94459e3dbe1e70\",\"title\":\"OK-VQA: A Visual Question Answering Benchmark Requiring External Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/28ad018c39d1578bea84e7cedf94459e3dbe1e70\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1904.11574\",\"authors\":[{\"authorId\":\"46665218\",\"name\":\"Jie Lei\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/2020.acl-main.730\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb1b368ca847846774ee41af6da906ab77013313\",\"title\":\"TVQA+: Spatio-Temporal Grounding for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/eb1b368ca847846774ee41af6da906ab77013313\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"1710.07300\",\"authors\":[{\"authorId\":\"3127597\",\"name\":\"S. Kahou\"},{\"authorId\":\"144179710\",\"name\":\"A. Atkinson\"},{\"authorId\":\"1748421\",\"name\":\"Vincent Michalski\"},{\"authorId\":\"2828538\",\"name\":\"\\u00c1kos K\\u00e1d\\u00e1r\"},{\"authorId\":\"3382568\",\"name\":\"Adam Trischler\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"55ca9fe4ae98904bfe026d22dcf1420ff9c0dd86\",\"title\":\"FigureQA: An Annotated Figure Dataset for Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/55ca9fe4ae98904bfe026d22dcf1420ff9c0dd86\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"2012.05710\",\"authors\":[{\"authorId\":\"14454974\",\"name\":\"P. H. Seo\"},{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"153433844\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b1f6397717d3cbf84e89081a47205f8ed8395d22\",\"title\":\"Look Before you Speak: Visually Contextualized Utterances\",\"url\":\"https://www.semanticscholar.org/paper/b1f6397717d3cbf84e89081a47205f8ed8395d22\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47141093\",\"name\":\"Gursimran Singh\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"1710980\",\"name\":\"J. Little\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"51fadc0803ee53c91eb4fcfb3777720496c9d91f\",\"title\":\"Spatio-temporal Relational Reasoning for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/51fadc0803ee53c91eb4fcfb3777720496c9d91f\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2338742\",\"name\":\"Y. Jang\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"32821535\",\"name\":\"C. D. Kim\"},{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"49170458\",\"name\":\"Youngjin Kim\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1007/s11263-019-01189-x\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1e1bd132613866c176a8fc780cb1b9f9aa43feeb\",\"title\":\"Video Question Answering with Spatio-Temporal Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/1e1bd132613866c176a8fc780cb1b9f9aa43feeb\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"1809.01696\",\"authors\":[{\"authorId\":\"46665218\",\"name\":\"Jie Lei\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.18653/v1/D18-1167\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e7e1313061b0d56364bd2c41f017deb954bb05db\",\"title\":\"TVQA: Localized, Compositional Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e7e1313061b0d56364bd2c41f017deb954bb05db\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"2005.03356\",\"authors\":[{\"authorId\":\"117172343\",\"name\":\"Seongho Choi\"},{\"authorId\":\"2943489\",\"name\":\"Kyoung-Woon On\"},{\"authorId\":\"15353659\",\"name\":\"Yu-Jung Heo\"},{\"authorId\":\"1679974562\",\"name\":\"Ahjeong Seo\"},{\"authorId\":\"1680054988\",\"name\":\"Youwon Jang\"},{\"authorId\":\"153311117\",\"name\":\"Seungchan Lee\"},{\"authorId\":\"1491775096\",\"name\":\"Minsu Lee\"},{\"authorId\":\"152705134\",\"name\":\"B. Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4d21241b930b005847cf4350294c61d6c29ccd9f\",\"title\":\"DramaQA: Character-Centered Video Story Understanding with Hierarchical QA\",\"url\":\"https://www.semanticscholar.org/paper/4d21241b930b005847cf4350294c61d6c29ccd9f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1712.06761\",\"authors\":[{\"authorId\":\"2039154\",\"name\":\"Paul Vicol\"},{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"3436589\",\"name\":\"L. Castrej\\u00f3n\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":\"10.1109/CVPR.2018.00895\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"523574aca71d8981b4122cce8d132f22391ef26e\",\"title\":\"MovieGraphs: Towards Understanding Human-Centric Situations from Videos\",\"url\":\"https://www.semanticscholar.org/paper/523574aca71d8981b4122cce8d132f22391ef26e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1709.07992\",\"authors\":[{\"authorId\":\"14454974\",\"name\":\"P. H. Seo\"},{\"authorId\":\"20812150\",\"name\":\"Andreas M. Lehrmann\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ad8c0489d908d6bb4b48eb56c8c92b8f545216f5\",\"title\":\"Visual Reference Resolution using Attention Memory for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/ad8c0489d908d6bb4b48eb56c8c92b8f545216f5\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1809.01337\",\"authors\":[{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"39231399\",\"name\":\"O. Wang\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"145160921\",\"name\":\"Bryan C. Russell\"}],\"doi\":\"10.18653/v1/D18-1168\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"0b1ff82db09672656157874718860bee942483cf\",\"title\":\"Localizing Moments in Video with Temporal Language\",\"url\":\"https://www.semanticscholar.org/paper/0b1ff82db09672656157874718860bee942483cf\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2964003\",\"name\":\"C. Lee\"},{\"authorId\":\"1706104\",\"name\":\"Hung-yi Lee\"},{\"authorId\":\"2208161\",\"name\":\"Szu-Lin Wu\"},{\"authorId\":\"117660020\",\"name\":\"Chi-Liang Liu\"},{\"authorId\":\"145359071\",\"name\":\"Wei Fang\"},{\"authorId\":\"3451540\",\"name\":\"Juei-Yang Hsu\"},{\"authorId\":\"33870107\",\"name\":\"Bo-Hsiang Tseng\"}],\"doi\":\"10.1109/TASLP.2019.2913499\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"76d095f2e000e3f4bb08e55b1941e81cfe699322\",\"title\":\"Machine Comprehension of Spoken Content: TOEFL Listening Test and Spoken SQuAD\",\"url\":\"https://www.semanticscholar.org/paper/76d095f2e000e3f4bb08e55b1941e81cfe699322\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2019},{\"arxivId\":\"1907.13280\",\"authors\":[{\"authorId\":\"2531558\",\"name\":\"G. Chao\"},{\"authorId\":\"2188497\",\"name\":\"Abhinav Rastogi\"},{\"authorId\":\"3014143\",\"name\":\"Semih Yavuz\"},{\"authorId\":\"152325757\",\"name\":\"D. Hakkani-T\\u00fcr\"},{\"authorId\":\"47740493\",\"name\":\"Jindong Chen\"},{\"authorId\":\"5347612\",\"name\":\"I. Lane\"}],\"doi\":\"10.18653/v1/W19-5926\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fb5af7b7d5ebf9e8ff4164233a73b8fe4fe737a3\",\"title\":\"Learning Question-Guided Video Representation for Multi-Turn Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/fb5af7b7d5ebf9e8ff4164233a73b8fe4fe737a3\",\"venue\":\"ViGIL@NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145691225\",\"name\":\"Santiago Castro\"},{\"authorId\":\"144886349\",\"name\":\"Mahmoud Azab\"},{\"authorId\":\"143935879\",\"name\":\"Jonathan C. Stroud\"},{\"authorId\":\"1724416445\",\"name\":\"Cristina Noujaim\"},{\"authorId\":\"30646659\",\"name\":\"R. Wang\"},{\"authorId\":\"145820819\",\"name\":\"Jun Deng\"},{\"authorId\":\"145557251\",\"name\":\"R. Mihalcea\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4621240ed38a7b42ad4fc77aa24d111c5d947934\",\"title\":\"LifeQA: A Real-life Dataset for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/4621240ed38a7b42ad4fc77aa24d111c5d947934\",\"venue\":\"LREC\",\"year\":2020},{\"arxivId\":\"1911.11938\",\"authors\":[{\"authorId\":\"2545727\",\"name\":\"T. S. Jayram\"},{\"authorId\":\"79805467\",\"name\":\"Vincent Marois\"},{\"authorId\":\"2725083\",\"name\":\"T. Kornuta\"},{\"authorId\":\"88000484\",\"name\":\"V. Albouy\"},{\"authorId\":\"13177954\",\"name\":\"E. Sevgen\"},{\"authorId\":\"50192121\",\"name\":\"A. Ozcan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e32b914586ebf185e9c470a34d89a01f86a2c19e\",\"title\":\"Transfer Learning in Visual and Relational Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/e32b914586ebf185e9c470a34d89a01f86a2c19e\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51021338\",\"name\":\"Nelson Ruwa\"},{\"authorId\":\"3069077\",\"name\":\"Q. Mao\"},{\"authorId\":\"79927338\",\"name\":\"L. Wang\"},{\"authorId\":\"37233332\",\"name\":\"J. Gou\"}],\"doi\":\"10.1016/J.NEUCOM.2019.06.046\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1b6ce7e65130431eecf98db2e6c162893bbe5127\",\"title\":\"Affective question answering on video\",\"url\":\"https://www.semanticscholar.org/paper/1b6ce7e65130431eecf98db2e6c162893bbe5127\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"1908.04950\",\"authors\":[{\"authorId\":\"51906624\",\"name\":\"Catalina Cangea\"},{\"authorId\":\"1829344\",\"name\":\"Eugene Belilovsky\"},{\"authorId\":\"144269589\",\"name\":\"P. Li\\u00f2\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ad732e16296b62ba1de9a22bd01452590b52a2fc\",\"title\":\"VideoNavQA: Bridging the Gap between Visual and Embodied Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ad732e16296b62ba1de9a22bd01452590b52a2fc\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1731750\",\"name\":\"Weining Wang\"},{\"authorId\":\"49866972\",\"name\":\"Y. Huang\"},{\"authorId\":\"97846606\",\"name\":\"L. Wang\"}],\"doi\":\"10.1016/j.patcog.2020.107248\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"44225a35d3c5f6e5a98963a6428c22bfdd4586d4\",\"title\":\"Long video question answering: A Matching-guided Attention Model\",\"url\":\"https://www.semanticscholar.org/paper/44225a35d3c5f6e5a98963a6428c22bfdd4586d4\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3127597\",\"name\":\"S. Kahou\"},{\"authorId\":\"1748421\",\"name\":\"Vincent Michalski\"},{\"authorId\":\"144179710\",\"name\":\"A. Atkinson\"},{\"authorId\":\"2828538\",\"name\":\"\\u00c1kos K\\u00e1d\\u00e1r\"},{\"authorId\":\"3382568\",\"name\":\"Adam Trischler\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"cb6be69c67b0b15ebbda89a126f4dd62a4d32958\",\"title\":\"IGURE QA : A N A NNOTATED F IGURE D ATASET FOR V ISUAL R EASONING\",\"url\":\"https://www.semanticscholar.org/paper/cb6be69c67b0b15ebbda89a126f4dd62a4d32958\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"46172451\",\"name\":\"B. Wang\"},{\"authorId\":\"2248826\",\"name\":\"R. Hong\"},{\"authorId\":\"32996440\",\"name\":\"F. Wu\"}],\"doi\":\"10.1109/TCSVT.2019.2897604\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cb2f25b32344888d644dc3a3e729275a8abee07a\",\"title\":\"Movie Question Answering via Textual Memory and Plot Graph\",\"url\":\"https://www.semanticscholar.org/paper/cb2f25b32344888d644dc3a3e729275a8abee07a\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"48210950\",\"name\":\"Jiawei Liu\"},{\"authorId\":\"49876189\",\"name\":\"T. Yang\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.1145/3320061\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"86ce76f54a7bfc6047f83877408f789449f28df4\",\"title\":\"Spatiotemporal-Textual Co-Attention Network for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/86ce76f54a7bfc6047f83877408f789449f28df4\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2712862\",\"name\":\"D. Zhang\"},{\"authorId\":\"145690873\",\"name\":\"R. Cao\"},{\"authorId\":\"1765710\",\"name\":\"Sai Wu\"}],\"doi\":\"10.1016/J.INFFUS.2019.03.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"91118408f8192c2addade2a0401a32c3bbd47818\",\"title\":\"Information fusion in visual question answering: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/91118408f8192c2addade2a0401a32c3bbd47818\",\"venue\":\"Inf. Fusion\",\"year\":2019},{\"arxivId\":\"2008.12520\",\"authors\":[{\"authorId\":\"26385137\",\"name\":\"Noa Garcia\"},{\"authorId\":\"82729121\",\"name\":\"Chentao Ye\"},{\"authorId\":\"9071958\",\"name\":\"Zihua Liu\"},{\"authorId\":\"32104754\",\"name\":\"Qingtao Hu\"},{\"authorId\":\"3186326\",\"name\":\"Mayu Otani\"},{\"authorId\":\"2427516\",\"name\":\"Chenhui Chu\"},{\"authorId\":\"1789677\",\"name\":\"Yuta Nakashima\"},{\"authorId\":\"1706595\",\"name\":\"T. Mitamura\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fb106fdc2d02b077c100bd0a653395bd6cffcded\",\"title\":\"A Dataset and Baselines for Visual Question Answering on Art\",\"url\":\"https://www.semanticscholar.org/paper/fb106fdc2d02b077c100bd0a653395bd6cffcded\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1803.10906\",\"authors\":[{\"authorId\":\"3029956\",\"name\":\"J. Gao\"},{\"authorId\":\"40899706\",\"name\":\"Runzhou Ge\"},{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/CVPR.2018.00688\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f45c3a83e5c6276c6655c5df5833ab6b75e17bdf\",\"title\":\"Motion-Appearance Co-memory Networks for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f45c3a83e5c6276c6655c5df5833ab6b75e17bdf\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"120016637\",\"name\":\"S.A.A. den Broeder\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"fd8bc8ec6526c554bf0248d1358ea0c5a58b00a0\",\"title\":\"Automatic semantic analysis of gameplay videos of \\u2018This War of Mine\\u2019\",\"url\":\"https://www.semanticscholar.org/paper/fd8bc8ec6526c554bf0248d1358ea0c5a58b00a0\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2004.07514\",\"authors\":[{\"authorId\":\"8511875\",\"name\":\"Jonghwan Mun\"},{\"authorId\":\"72643925\",\"name\":\"Minsu Cho\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":\"10.1109/CVPR42600.2020.01082\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7e3d5b20e5df692deb80d9e100e4f34c1a8f8031\",\"title\":\"Local-Global Video-Text Interactions for Temporal Grounding\",\"url\":\"https://www.semanticscholar.org/paper/7e3d5b20e5df692deb80d9e100e4f34c1a8f8031\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"15634170\",\"name\":\"S. Huang\"},{\"authorId\":\"3225210\",\"name\":\"Shaohan Hu\"},{\"authorId\":\"1466481870\",\"name\":\"Bencheng Yan\"}],\"doi\":\"10.1007/978-3-030-36718-3_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"77465a0ae333a9ce4cf3969b93e756772714fc63\",\"title\":\"Watch and Ask: Video Question Generation\",\"url\":\"https://www.semanticscholar.org/paper/77465a0ae333a9ce4cf3969b93e756772714fc63\",\"venue\":\"ICONIP\",\"year\":2019},{\"arxivId\":\"1910.10706\",\"authors\":[{\"authorId\":\"26385137\",\"name\":\"Noa Garcia\"},{\"authorId\":\"3186326\",\"name\":\"Mayu Otani\"},{\"authorId\":\"2427516\",\"name\":\"Chenhui Chu\"},{\"authorId\":\"1789677\",\"name\":\"Yuta Nakashima\"}],\"doi\":\"10.1609/AAAI.V34I07.6713\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"12f11d56a83516bfdd1f32f60e3695ab92a0f819\",\"title\":\"KnowIT VQA: Answering Knowledge-Based Questions about Videos\",\"url\":\"https://www.semanticscholar.org/paper/12f11d56a83516bfdd1f32f60e3695ab92a0f819\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7499906\",\"name\":\"Xiaomeng Song\"},{\"authorId\":\"46571755\",\"name\":\"Yucheng Shi\"},{\"authorId\":\"46772058\",\"name\":\"X. Chen\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"}],\"doi\":\"10.1145/3240508.3240563\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b08c35f8e529f47a3fdc4f0713ffe77d94c57d87\",\"title\":\"Explore Multi-Step Reasoning in Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b08c35f8e529f47a3fdc4f0713ffe77d94c57d87\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1804.09412\",\"authors\":[{\"authorId\":\"49292319\",\"name\":\"Bo Wang\"},{\"authorId\":\"3429960\",\"name\":\"Youjiang Xu\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"48043335\",\"name\":\"R. Hong\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e5c7798293f8325bbe8d92b185c99a7c7662e330\",\"title\":\"Movie Question Answering: Remembering the Textual Cues for Layered Visual Contents\",\"url\":\"https://www.semanticscholar.org/paper/e5c7798293f8325bbe8d92b185c99a7c7662e330\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"2010.14095\",\"authors\":[{\"authorId\":\"25263842\",\"name\":\"Aisha Urooj Khan\"},{\"authorId\":\"144839067\",\"name\":\"Amir Mazaheri\"},{\"authorId\":\"1700665\",\"name\":\"N. Lobo\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.417\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"bf8a0cda4f26c889d1b6d16fe070fa3d907a8686\",\"title\":\"MMFT-BERT: Multimodal Fusion Transformer with BERT Encodings for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/bf8a0cda4f26c889d1b6d16fe070fa3d907a8686\",\"venue\":\"EMNLP\",\"year\":2020}],\"corpusId\":14142024,\"doi\":\"10.1109/ICCV.2017.312\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":5,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"00672bec9dd0e755f9c375f912c0f1c3918a6b74\",\"references\":[{\"arxivId\":\"1511.05756\",\"authors\":[{\"authorId\":\"2018393\",\"name\":\"Hyeonwoo Noh\"},{\"authorId\":\"14454974\",\"name\":\"P. H. Seo\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":\"10.1109/CVPR.2016.11\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"385c18cc4024a3b3206c508c512e037b9c00b8f3\",\"title\":\"Image Question Answering Using Convolutional Neural Network with Dynamic Parameter Prediction\",\"url\":\"https://www.semanticscholar.org/paper/385c18cc4024a3b3206c508c512e037b9c00b8f3\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"152821938\",\"name\":\"Sanketh Shetty\"},{\"authorId\":\"120906511\",\"name\":\"T. Leung\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2014.223\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"title\":\"Large-Scale Video Classification with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1511.07394\",\"authors\":[{\"authorId\":\"143953573\",\"name\":\"K. Shih\"},{\"authorId\":\"37415643\",\"name\":\"S. Singh\"},{\"authorId\":\"2433269\",\"name\":\"Derek Hoiem\"}],\"doi\":\"10.1109/CVPR.2016.499\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"175e9bb50cc062c6c1742a5d90c8dfe31d2e4e22\",\"title\":\"Where to Look: Focus Regions for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/175e9bb50cc062c6c1742a5d90c8dfe31d2e4e22\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1505.00468\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-016-0966-6\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"title\":\"VQA: Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1602.03935\",\"authors\":[{\"authorId\":\"144999698\",\"name\":\"Yang Zhong\"},{\"authorId\":\"50626295\",\"name\":\"J. Sullivan\"},{\"authorId\":\"40565290\",\"name\":\"Haibo Li\"}],\"doi\":\"10.1109/ICB.2016.7550092\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bfd00e8dba4432d13cb26410fbeec00b071946f8\",\"title\":\"Face attribute prediction using off-the-shelf CNN features\",\"url\":\"https://www.semanticscholar.org/paper/bfd00e8dba4432d13cb26410fbeec00b071946f8\",\"venue\":\"2016 International Conference on Biometrics (ICB)\",\"year\":2016},{\"arxivId\":\"1409.4842\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"46641766\",\"name\":\"W. Liu\"},{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"},{\"authorId\":\"48840704\",\"name\":\"Scott Reed\"},{\"authorId\":\"1838674\",\"name\":\"Dragomir Anguelov\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"39863668\",\"name\":\"Andrew Rabinovich\"}],\"doi\":\"10.1109/CVPR.2015.7298594\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"title\":\"Going deeper with convolutions\",\"url\":\"https://www.semanticscholar.org/paper/e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1511.05960\",\"authors\":[{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"36650957\",\"name\":\"Jiang Wang\"},{\"authorId\":\"34192119\",\"name\":\"Liang-Chieh Chen\"},{\"authorId\":\"2345388\",\"name\":\"Haoyuan Gao\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"b196bc11ad516c8e6ff96f83acfc443fd7161730\",\"title\":\"ABC-CNN: An Attention Based Convolutional Neural Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b196bc11ad516c8e6ff96f83acfc443fd7161730\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1648075979\",\"name\":\"B. A. R. Kernfach\"},{\"authorId\":\"1648268257\",\"name\":\"Nur IM Sommersemester\"},{\"authorId\":\"1648268256\",\"name\":\"\\u00dcbersicht Franz\\u00f6sisch\"},{\"authorId\":\"1648134774\",\"name\":\"\\u00dcbersicht Italienisch\"}],\"doi\":\"10.1515/9783111697888-004\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"fff1b293b45d06c8462021aa6c90c81e743e131b\",\"title\":\"B\",\"url\":\"https://www.semanticscholar.org/paper/fff1b293b45d06c8462021aa6c90c81e743e131b\",\"venue\":\"Edinburgh Medical and Surgical Journal\",\"year\":1824},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1630291648\",\"name\":\"Il Liceo\"},{\"authorId\":\"1630291637\",\"name\":\"Delle Scienze Umane\"},{\"authorId\":\"1630390134\",\"name\":\"Progetto BiologiaAmbiente\"},{\"authorId\":\"1630390134\",\"name\":\"Progetto BiologiaAmbiente\"},{\"authorId\":\"1630311779\",\"name\":\"Profilo IN Uscita\"},{\"authorId\":\"1630291648\",\"name\":\"Il Liceo\"}],\"doi\":\"10.1515/9783111413426-013\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5385b3c2cef5138d2f4f9127ec7565eb8043a1c4\",\"title\":\"L\",\"url\":\"https://www.semanticscholar.org/paper/5385b3c2cef5138d2f4f9127ec7565eb8043a1c4\",\"venue\":\"Edinburgh Medical and Surgical Journal\",\"year\":1824},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"D. H. Park\"},{\"authorId\":null,\"name\":\"D. Yang\"},{\"authorId\":null,\"name\":\"A. Rohrbach\"},{\"authorId\":null,\"name\":\"T. Darrell\"},{\"authorId\":null,\"name\":\"M. Rohrbach\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Learn - ing to compose neural networks for question answering Vqa : Visual question answering\",\"url\":\"\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1601.01705\",\"authors\":[{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"38666915\",\"name\":\"D. Klein\"}],\"doi\":\"10.18653/v1/N16-1181\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"75ddc7ee15be14013a3462c01b38b0548486fbcb\",\"title\":\"Learning to Compose Neural Networks for Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/75ddc7ee15be14013a3462c01b38b0548486fbcb\",\"venue\":\"HLT-NAACL\",\"year\":2016},{\"arxivId\":\"1512.02902\",\"authors\":[{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"2214033\",\"name\":\"Y. Zhu\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":\"10.1109/CVPR.2016.501\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"1bdd75a37f7c601f01e9d31c2551fa9f2067ffd7\",\"title\":\"MovieQA: Understanding Stories in Movies through Question-Answering\",\"url\":\"https://www.semanticscholar.org/paper/1bdd75a37f7c601f01e9d31c2551fa9f2067ffd7\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/ICCV.2015.510\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"title\":\"Learning Spatiotemporal Features with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1511.04670\",\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"2351434\",\"name\":\"Zhongwen Xu\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9ed7d774684a1770445c1c53e276011a8364b9e2\",\"title\":\"Uncovering Temporal Context for Video Question and Answering\",\"url\":\"https://www.semanticscholar.org/paper/9ed7d774684a1770445c1c53e276011a8364b9e2\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1511.06973\",\"authors\":[{\"authorId\":\"34902783\",\"name\":\"Qi Wu\"},{\"authorId\":\"48319305\",\"name\":\"P. Wang\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2016.500\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"20dbdf02497aa84510970d0f5e8b599073bca1bc\",\"title\":\"Ask Me Anything: Free-Form Visual Question Answering Based on Knowledge from External Sources\",\"url\":\"https://www.semanticscholar.org/paper/20dbdf02497aa84510970d0f5e8b599073bca1bc\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1410.0210\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ac64fb7e6d2ddf236332ec9f371fe85d308c114d\",\"title\":\"A Multi-World Approach to Question Answering about Real-World Scenes based on Uncertain Input\",\"url\":\"https://www.semanticscholar.org/paper/ac64fb7e6d2ddf236332ec9f371fe85d308c114d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1512.02167\",\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"39402399\",\"name\":\"Yuandong Tian\"},{\"authorId\":\"2265067\",\"name\":\"Sainbayar Sukhbaatar\"},{\"authorId\":\"3149531\",\"name\":\"Arthur Szlam\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"267fb4ac632449dbe84f7acf17c8c7527cb25b0d\",\"title\":\"Simple Baseline for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/267fb4ac632449dbe84f7acf17c8c7527cb25b0d\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1505.02074\",\"authors\":[{\"authorId\":\"2540599\",\"name\":\"Mengye Ren\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"62a956d7600b10ca455076cd56e604dfd106072a\",\"title\":\"Exploring Models and Data for Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/62a956d7600b10ca455076cd56e604dfd106072a\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1501.02530\",\"authors\":[{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1721168\",\"name\":\"Niket Tandon\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1109/CVPR.2015.7298940\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a5ea0da7b93452bec54b5034706f2255bfb5a8f3\",\"title\":\"A dataset for Movie Description\",\"url\":\"https://www.semanticscholar.org/paper/a5ea0da7b93452bec54b5034706f2255bfb5a8f3\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1612.06890\",\"authors\":[{\"authorId\":\"153365679\",\"name\":\"J. Johnson\"},{\"authorId\":\"73710317\",\"name\":\"B. Hariharan\"},{\"authorId\":\"35341401\",\"name\":\"Laurens van der Maaten\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/CVPR.2017.215\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"03eb382e04cca8cca743f7799070869954f1402a\",\"title\":\"CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/03eb382e04cca8cca743f7799070869954f1402a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1601.00400\",\"authors\":[{\"authorId\":\"3282196\",\"name\":\"Abrar H. Abdulnabi\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"},{\"authorId\":\"1697700\",\"name\":\"Jiwen Lu\"},{\"authorId\":\"2370507\",\"name\":\"K. Jia\"}],\"doi\":\"10.1109/TMM.2015.2477680\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f69cda1175c3ddf2d4e3f3789a6c743b1059ebb2\",\"title\":\"Multi-Task CNN Model for Attribute Prediction\",\"url\":\"https://www.semanticscholar.org/paper/f69cda1175c3ddf2d4e3f3789a6c743b1059ebb2\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"2677488\",\"name\":\"\\u00c0gata Lapedriza\"},{\"authorId\":\"40599257\",\"name\":\"J. Xiao\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9667f8264745b626c6173b1310e2ff0298b09cfc\",\"title\":\"Learning Deep Features for Scene Recognition using Places Database\",\"url\":\"https://www.semanticscholar.org/paper/9667f8264745b626c6173b1310e2ff0298b09cfc\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"H. Xu\"},{\"authorId\":null,\"name\":\"K. Saenko\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Ask\",\"url\":\"\",\"venue\":\"attend and answer: Exploring question-guided spatial attention for visual question answering. In ECCV\",\"year\":2016},{\"arxivId\":\"1502.05698\",\"authors\":[{\"authorId\":\"145183709\",\"name\":\"J. Weston\"},{\"authorId\":\"1713934\",\"name\":\"Antoine Bordes\"},{\"authorId\":\"3295092\",\"name\":\"S. Chopra\"},{\"authorId\":null,\"name\":\"Tomas Mikolov\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"abb33d75dc297993fcc3fb75e0f4498f413eb4f6\",\"title\":\"Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks\",\"url\":\"https://www.semanticscholar.org/paper/abb33d75dc297993fcc3fb75e0f4498f413eb4f6\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":\"1506.06726\",\"authors\":[{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"2214033\",\"name\":\"Y. Zhu\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6e795c6e9916174ae12349f5dc3f516570c17ce8\",\"title\":\"Skip-Thought Vectors\",\"url\":\"https://www.semanticscholar.org/paper/6e795c6e9916174ae12349f5dc3f516570c17ce8\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1603.01417\",\"authors\":[{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"3375440\",\"name\":\"Stephen Merity\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f96898d15a1bf1fa8925b1280d0e07a7a8e72194\",\"title\":\"Dynamic Memory Networks for Visual and Textual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f96898d15a1bf1fa8925b1280d0e07a7a8e72194\",\"venue\":\"ICML\",\"year\":2016},{\"arxivId\":\"1606.01847\",\"authors\":[{\"authorId\":\"50599725\",\"name\":\"A. Fukui\"},{\"authorId\":\"3422202\",\"name\":\"Dong Huk Park\"},{\"authorId\":\"3422876\",\"name\":\"Daylen Yang\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.18653/v1/D16-1044\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"fddc15480d086629b960be5bff96232f967f2252\",\"title\":\"Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/fddc15480d086629b960be5bff96232f967f2252\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":\"1511.05234\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1007/978-3-319-46478-7_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1cf6bc0866226c1f8e282463adc8b75d92fba9bb\",\"title\":\"Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1cf6bc0866226c1f8e282463adc8b75d92fba9bb\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2485529\",\"name\":\"Michaela Regneri\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"24138684\",\"name\":\"Dominikus Wetzel\"},{\"authorId\":\"1727272\",\"name\":\"Stefan Thater\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"1717560\",\"name\":\"Manfred Pinkal\"}],\"doi\":\"10.1162/tacl_a_00207\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"21b3007f967d39e1346bc91e0fc8b3f16121300c\",\"title\":\"Grounding Action Descriptions in Videos\",\"url\":\"https://www.semanticscholar.org/paper/21b3007f967d39e1346bc91e0fc8b3f16121300c\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"65911798\",\"name\":\"A. Spring\"},{\"authorId\":\"7753714\",\"name\":\"M. Lewerentz\"},{\"authorId\":\"32009199\",\"name\":\"T. Bluhm\"},{\"authorId\":\"144508212\",\"name\":\"P. Heimann\"},{\"authorId\":\"24269814\",\"name\":\"C. Hennig\"},{\"authorId\":\"92119326\",\"name\":\"G. K\\u00fchner\"},{\"authorId\":\"153933286\",\"name\":\"H. Kroiss\"},{\"authorId\":\"40378213\",\"name\":\"J. Krom\"},{\"authorId\":\"152933601\",\"name\":\"H. Laqua\"},{\"authorId\":\"46816398\",\"name\":\"J. Maier\"},{\"authorId\":\"40588319\",\"name\":\"H. Riemann\"},{\"authorId\":\"46356567\",\"name\":\"J. Schacht\"},{\"authorId\":\"49058670\",\"name\":\"A. Werner\"},{\"authorId\":\"7411314\",\"name\":\"M. Zilker\"}],\"doi\":\"10.1007/3-540-26367-5_1\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"70fd66e78add02052f0883363e1d80dcd3f6baab\",\"title\":\"A\",\"url\":\"https://www.semanticscholar.org/paper/70fd66e78add02052f0883363e1d80dcd3f6baab\",\"venue\":\"Therapielexikon Neurologie\",\"year\":2005},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/CVPR.2015.7298698\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0a28efacb92d16e6e0dd4d87b5aca91b28be8853\",\"title\":\"ActivityNet: A large-scale video benchmark for human activity understanding\",\"url\":\"https://www.semanticscholar.org/paper/0a28efacb92d16e6e0dd4d87b5aca91b28be8853\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1605.03705\",\"authors\":[{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1730844\",\"name\":\"Atousa Torabi\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1721168\",\"name\":\"Niket Tandon\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1007/s11263-016-0987-1\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"154c22ca5eef149aedc8a986fa684ca1fd14e7dc\",\"title\":\"Movie Description\",\"url\":\"https://www.semanticscholar.org/paper/154c22ca5eef149aedc8a986fa684ca1fd14e7dc\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":\"1511.02274\",\"authors\":[{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"46234526\",\"name\":\"Alex Smola\"}],\"doi\":\"10.1109/CVPR.2016.10\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2c1890864c1c2b750f48316dc8b650ba4772adc5\",\"title\":\"Stacked Attention Networks for Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2c1890864c1c2b750f48316dc8b650ba4772adc5\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2188620\",\"name\":\"Yaniv Taigman\"},{\"authorId\":\"41216159\",\"name\":\"Ming Yang\"},{\"authorId\":\"1706809\",\"name\":\"Marc'Aurelio Ranzato\"},{\"authorId\":\"145128145\",\"name\":\"Lior Wolf\"}],\"doi\":\"10.1109/CVPR.2014.220\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9f2efadf66817f1b38f58b3f50c7c8f34c69d89a\",\"title\":\"DeepFace: Closing the Gap to Human-Level Performance in Face Verification\",\"url\":\"https://www.semanticscholar.org/paper/9f2efadf66817f1b38f58b3f50c7c8f34c69d89a\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"119268487\",\"name\":\"Hueihan Jhuang\"},{\"authorId\":\"1930964\",\"name\":\"E. Garrote\"},{\"authorId\":\"145031878\",\"name\":\"T. Poggio\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"}],\"doi\":\"10.1109/ICCV.2011.6126543\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8b3b8848a311c501e704c45c6d50430ab7068956\",\"title\":\"HMDB: A large video database for human motion recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b3b8848a311c501e704c45c6d50430ab7068956\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011}],\"title\":\"MarioQA: Answering Questions by Watching Gameplay Videos\",\"topics\":[{\"topic\":\"Question answering\",\"topicId\":\"18817\",\"url\":\"https://www.semanticscholar.org/topic/18817\"},{\"topic\":\"Deep learning\",\"topicId\":\"2762\",\"url\":\"https://www.semanticscholar.org/topic/2762\"},{\"topic\":\"Google Questions and Answers\",\"topicId\":\"2898125\",\"url\":\"https://www.semanticscholar.org/topic/2898125\"},{\"topic\":\"High- and low-level\",\"topicId\":\"33507\",\"url\":\"https://www.semanticscholar.org/topic/33507\"},{\"topic\":\"Synthetic intelligence\",\"topicId\":\"1588157\",\"url\":\"https://www.semanticscholar.org/topic/1588157\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"},{\"topic\":\"Algorithm\",\"topicId\":\"305\",\"url\":\"https://www.semanticscholar.org/topic/305\"},{\"topic\":\"Synthetic data\",\"topicId\":\"16840\",\"url\":\"https://www.semanticscholar.org/topic/16840\"}],\"url\":\"https://www.semanticscholar.org/paper/00672bec9dd0e755f9c375f912c0f1c3918a6b74\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017}\n"