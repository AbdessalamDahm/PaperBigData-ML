"{\"abstract\":\"To bridge the gap between humans and machines in image understanding and describing, we need further insight into how people describe a perceived scene. In this paper, we study the agreement between bottom-up saliency-based visual attention and object referrals in scene description constructs. We investigate the properties of human-written descriptions and machine-generated ones. We then propose a saliency-boosted image captioning model in order to investigate benefits from low-level cues in language models. We learn that (1) humans mention more salient objects earlier than less salient ones in their descriptions, (2) the better a captioning model performs, the better attention agreement it has with human descriptions, (3) the proposed saliencyboosted model, compared to its baseline form, does not improve significantly on the MS COCO database, indicating explicit bottom-up boosting does not help when the task is well learnt and tuned on a data, (4) a better generalization is, however, observed for the saliency-boosted model on unseen data.\",\"arxivId\":\"1704.07434\",\"authors\":[{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\",\"url\":\"https://www.semanticscholar.org/author/2319672\"},{\"authorId\":\"38314306\",\"name\":\"Rakshith Shetty\",\"url\":\"https://www.semanticscholar.org/author/38314306\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\",\"url\":\"https://www.semanticscholar.org/author/3177797\"},{\"authorId\":\"1708642\",\"name\":\"Jorma T. Laaksonen\",\"url\":\"https://www.semanticscholar.org/author/1708642\"}],\"citationVelocity\":12,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"4942547\",\"name\":\"Zongjian Zhang\"},{\"authorId\":\"144066903\",\"name\":\"Q. Wu\"},{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"145093625\",\"name\":\"F. Chen\"}],\"doi\":\"10.1109/TMM.2018.2888822\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2bc7959cf6bf0ae64f1a83f5fce1ac8cb2256ed3\",\"title\":\"High-Quality Image Captioning With Fine-Grained and Semantic-Guided Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/2bc7959cf6bf0ae64f1a83f5fce1ac8cb2256ed3\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4942547\",\"name\":\"Zongjian Zhang\"},{\"authorId\":\"145698633\",\"name\":\"Q. Wu\"},{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"145093625\",\"name\":\"F. Chen\"}],\"doi\":\"10.1109/DICTA.2018.8615788\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2ce9fd151c7e67581dfa85b662f5034aca1896e6\",\"title\":\"Size-Invariant Attention Accuracy Metric for Image Captioning with High-Resolution Residual Attention\",\"url\":\"https://www.semanticscholar.org/paper/2ce9fd151c7e67581dfa85b662f5034aca1896e6\",\"venue\":\"2018 Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405686623\",\"name\":\"Nils Murrugarra-Llerena\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":\"10.1109/CVPR.2019.00659\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f23a5c29f227c2653014450284b7aa15ad9f88eb\",\"title\":\"Cross-Modality Personalization for Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/f23a5c29f227c2653014450284b7aa15ad9f88eb\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"47957770\",\"name\":\"Xuying Zhang\"},{\"authorId\":\"40626740\",\"name\":\"Liujuan Cao\"},{\"authorId\":\"47096329\",\"name\":\"Yongjian Wu\"},{\"authorId\":\"1835006\",\"name\":\"Feiyue Huang\"},{\"authorId\":\"1572139630\",\"name\":\"Rongrong Ji\"}],\"doi\":\"10.1145/3394171.3414008\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c19f8380410181249fdca70ec14f6b5f38ae0846\",\"title\":\"Exploring Language Prior for Mode-Sensitive Visual Attention Modeling\",\"url\":\"https://www.semanticscholar.org/paper/c19f8380410181249fdca70ec14f6b5f38ae0846\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3192572\",\"name\":\"Emiel van Miltenburg\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"1791713\",\"name\":\"Piek T. J. M. Vossen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fe400b814cfea5538887c92040f1ab0d6fb45bfe\",\"title\":\"Measuring the Diversity of Automatic Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/fe400b814cfea5538887c92040f1ab0d6fb45bfe\",\"venue\":\"COLING\",\"year\":2018},{\"arxivId\":\"1903.02499\",\"authors\":[{\"authorId\":\"47287647\",\"name\":\"Sen He\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"3251678\",\"name\":\"N. Pugeault\"}],\"doi\":null,\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"3f9f1de36707a7c4885006554be09d16cf3fd6b4\",\"title\":\"A Synchronized Multi-Modal Attention-Caption Dataset and Analysis\",\"url\":\"https://www.semanticscholar.org/paper/3f9f1de36707a7c4885006554be09d16cf3fd6b4\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1391204924\",\"name\":\"Zongjian Zhang\"},{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"50528721\",\"name\":\"Qiuyun Wu\"},{\"authorId\":\"94294263\",\"name\":\"F. Chen\"}],\"doi\":\"10.1109/IJCNN.2019.8851832\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a273df2ac9fc4e796c532feb76f5e676a0773b1c\",\"title\":\"Visual Relationship Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/a273df2ac9fc4e796c532feb76f5e676a0773b1c\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1820939478\",\"name\":\"Preethi Vaidyanathan\"},{\"authorId\":\"113057658\",\"name\":\"Emily Prudhommeaux\"},{\"authorId\":\"144648940\",\"name\":\"Cecilia Ovesdotter Alm\"},{\"authorId\":\"2899726\",\"name\":\"J. Pelz\"}],\"doi\":\"10.1167/jov.20.7.13\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"36f47de2c0d8c8fa6d18423030d31e426586997c\",\"title\":\"Computational framework for fusing eye movements and spoken narratives for image annotation\",\"url\":\"https://www.semanticscholar.org/paper/36f47de2c0d8c8fa6d18423030d31e426586997c\",\"venue\":\"Journal of vision\",\"year\":2020},{\"arxivId\":\"1810.04020\",\"authors\":[{\"authorId\":\"47412302\",\"name\":\"M. Z. Hossain\"},{\"authorId\":\"2470423\",\"name\":\"Ferdous Sohel\"},{\"authorId\":\"2222847\",\"name\":\"M. F. Shiratuddin\"},{\"authorId\":\"47028380\",\"name\":\"Hamid Laga\"}],\"doi\":\"10.1145/3295748\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"7e27d44e3fac723ccb703e0a83b22711bd42efe8\",\"title\":\"A Comprehensive Survey of Deep Learning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7e27d44e3fac723ccb703e0a83b22711bd42efe8\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2007.14419\",\"authors\":[{\"authorId\":\"94011352\",\"name\":\"S. Chen\"},{\"authorId\":\"1405907659\",\"name\":\"Ming Jiang\"},{\"authorId\":\"7788087\",\"name\":\"J. Yang\"},{\"authorId\":\"153386875\",\"name\":\"Q. Zhao\"}],\"doi\":\"10.1007/978-3-030-58452-8_6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"96150d2fdbb72e11882ad06b346d6e0d2e819d51\",\"title\":\"AiR: Attention with Reasoning Capability\",\"url\":\"https://www.semanticscholar.org/paper/96150d2fdbb72e11882ad06b346d6e0d2e819d51\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2002.06701\",\"authors\":[{\"authorId\":\"151430668\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"19b00a2bd1624a0931069a539a971e40b65bfb3a\",\"title\":\"Gaussian Smoothen Semantic Features (GSSF) - Exploring the Linguistic Aspects of Visual Captioning in Indian Languages (Bengali) Using MSCOCO Framework\",\"url\":\"https://www.semanticscholar.org/paper/19b00a2bd1624a0931069a539a971e40b65bfb3a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.10132\",\"authors\":[{\"authorId\":\"151430668\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s11042-020-09865-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c8f8ea39c64cf08792cd49c6ad04e85e3b90c88f\",\"title\":\"CRUR: Coupled-Recurrent Unit for Unification, Conceptualization and Context Capture for Language Representation - A Generalization of Bi Directional LSTM\",\"url\":\"https://www.semanticscholar.org/paper/c8f8ea39c64cf08792cd49c6ad04e85e3b90c88f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32236286\",\"name\":\"Annika Lindh\"},{\"authorId\":\"144394786\",\"name\":\"R. Ross\"},{\"authorId\":\"34967075\",\"name\":\"John D. Kelleher\"}],\"doi\":\"10.21427/D7ZN6Q\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"418896d28c72b67311d522b39eb5871e7334a971\",\"title\":\"Entity-Grounded Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/418896d28c72b67311d522b39eb5871e7334a971\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47287647\",\"name\":\"Sen He\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"3251678\",\"name\":\"N. Pugeault\"}],\"doi\":\"10.1109/ICCV.2019.00862\",\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"e4a91b8c1259e7744784d922f250dd77ea951e9f\",\"title\":\"Human Attention in Image Captioning: Dataset and Analysis\",\"url\":\"https://www.semanticscholar.org/paper/e4a91b8c1259e7744784d922f250dd77ea951e9f\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1007/978-3-030-11018-5_58\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5354d5d70079a14ebeaa0ebb42396d0c878e2731\",\"title\":\"Towards Cycle-Consistent Models for Text and Image Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/5354d5d70079a14ebeaa0ebb42396d0c878e2731\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[\"methodology\",\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"6aee8323be7ad5e568d62ba368bc7123f750515f\",\"title\":\"Paying More Attention to Saliency: Image Captioning with Saliency and Context Attention\",\"url\":\"https://www.semanticscholar.org/paper/6aee8323be7ad5e568d62ba368bc7123f750515f\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48462171\",\"name\":\"Lu Zhang\"},{\"authorId\":\"1519062024\",\"name\":\"Jianming Zhang\"},{\"authorId\":\"145527698\",\"name\":\"Zhe Lin\"},{\"authorId\":\"1790976\",\"name\":\"H. Lu\"},{\"authorId\":\"49990648\",\"name\":\"Y. He\"}],\"doi\":\"10.1109/CVPR.2019.00618\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"791fa4797683469f91b27940253c7725c9717f24\",\"title\":\"CapSal: Leveraging Captioning to Boost Semantics for Salient Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/791fa4797683469f91b27940253c7725c9717f24\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1843795\",\"name\":\"Lorenzo Baraldi\"},{\"authorId\":\"145518528\",\"name\":\"G. Serra\"}],\"doi\":null,\"intent\":[\"methodology\",\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"96fdc0131dc80ffa6d7b9c526e07f080414c54ec\",\"title\":\"1 Paying More A ention to Saliency : Image Captioning with Saliency and Context A ention\",\"url\":\"https://www.semanticscholar.org/paper/96fdc0131dc80ffa6d7b9c526e07f080414c54ec\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1007/s11042-020-09251-4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"af92381f95f28701396abeecaf715383b26ca354\",\"title\":\"A unified cycle-consistent neural model for text and image retrieval\",\"url\":\"https://www.semanticscholar.org/paper/af92381f95f28701396abeecaf715383b26ca354\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"1706.08474\",\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1145/3177745\",\"intent\":[\"methodology\",\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"f3ccdf54a3384e601fa36969e7b3f657e2516a3b\",\"title\":\"Paying More Attention to Saliency\",\"url\":\"https://www.semanticscholar.org/paper/f3ccdf54a3384e601fa36969e7b3f657e2516a3b\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"3288214\",\"name\":\"Rao Muhammad Anwer\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"},{\"authorId\":\"1776374\",\"name\":\"Juho Kannala\"}],\"doi\":\"10.1109/ICIP.2018.8451537\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"09636efc017110b53453aafa7f88d4e1acf6c447\",\"title\":\"Bottom-Up Attention Guidance for Recurrent Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/09636efc017110b53453aafa7f88d4e1acf6c447\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1399904149\",\"name\":\"Tzu-Jui Julius Wang\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"1766204\",\"name\":\"M. Sj\\u00f6berg\"},{\"authorId\":\"1708642\",\"name\":\"Jorma T. Laaksonen\"}],\"doi\":\"10.1145/3347450.3357656\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b45118c19c2c90dd8bad32ffeb5b6f7c69eb3ba9\",\"title\":\"Geometry-aware Relational Exemplar Attention for Dense Captioning\",\"url\":\"https://www.semanticscholar.org/paper/b45118c19c2c90dd8bad32ffeb5b6f7c69eb3ba9\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1904.00767\",\"authors\":[{\"authorId\":\"1807405\",\"name\":\"S. Chen\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1007/978-3-030-01252-6_5\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5cab3ce511ec8345d16a28c00094a2800b3919ce\",\"title\":\"Boosted Attention: Leveraging Human Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/5cab3ce511ec8345d16a28c00094a2800b3919ce\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151430668\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s11042-019-08021-1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1ba03c16bf25d33efc0d977ab51392e1d9b5a0fb\",\"title\":\"Survey of deep learning and architectures for visual captioning\\u2014transitioning between media and natural languages\",\"url\":\"https://www.semanticscholar.org/paper/1ba03c16bf25d33efc0d977ab51392e1d9b5a0fb\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49528408\",\"name\":\"H. Wang\"},{\"authorId\":\"46867445\",\"name\":\"Y. Zhang\"},{\"authorId\":\"9305704\",\"name\":\"Xiaosheng Yu\"}],\"doi\":\"10.1155/2020/3062706\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4b652fa2b4ea242a25a62e2e67eddde867e7e189\",\"title\":\"An Overview of Image Caption Generation Methods\",\"url\":\"https://www.semanticscholar.org/paper/4b652fa2b4ea242a25a62e2e67eddde867e7e189\",\"venue\":\"Comput. Intell. Neurosci.\",\"year\":2020},{\"arxivId\":\"2010.15942\",\"authors\":[{\"authorId\":\"2657185\",\"name\":\"Ruohan Zhang\"},{\"authorId\":\"1720831208\",\"name\":\"Bo Liu\"},{\"authorId\":\"1778450\",\"name\":\"Y. Zhu\"},{\"authorId\":\"1807482896\",\"name\":\"Sihang Guo\"},{\"authorId\":\"2848854\",\"name\":\"M. Hayhoe\"},{\"authorId\":\"1691804\",\"name\":\"D. Ballard\"},{\"authorId\":\"144848112\",\"name\":\"P. Stone\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0af86c8fe633e71aeb38561165609bc14d699290\",\"title\":\"Human versus Machine Attention in Deep Reinforcement Learning Tasks\",\"url\":\"https://www.semanticscholar.org/paper/0af86c8fe633e71aeb38561165609bc14d699290\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"117548227\",\"name\":\"Saloni Kalra\"},{\"authorId\":\"88872765\",\"name\":\"Alka Leekha\"}],\"doi\":\"10.1080/02522667.2020.1715602\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"117333afd2ce2d80dd195dc5c5087f1b2b6bebdc\",\"title\":\"Survey of convolutional neural networks for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/117333afd2ce2d80dd195dc5c5087f1b2b6bebdc\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2002.06436\",\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4ad005019f7069a3aaff959fbaa657f2ef2143fc\",\"title\":\"MRRC: Multiple Role Representation Crossover Interpretation for Image Captioning With R-CNN Feature Distribution Composition (FDC)\",\"url\":\"https://www.semanticscholar.org/paper/4ad005019f7069a3aaff959fbaa657f2ef2143fc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2001.09545\",\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"66a2eb540af6f47db177599bc793ab0c6a6aa47e\",\"title\":\"aiTPR: Attribute Interaction-Tensor Product Representation for Image Caption\",\"url\":\"https://www.semanticscholar.org/paper/66a2eb540af6f47db177599bc793ab0c6a6aa47e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38314306\",\"name\":\"Rakshith Shetty\"},{\"authorId\":\"143852685\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"1708642\",\"name\":\"Jorma T. Laaksonen\"}],\"doi\":\"10.1109/MMUL.2018.112135923\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"da8f9211ea60755bb40811bb92de76be389566c6\",\"title\":\"Image and Video Captioning with Augmented Neural Architectures\",\"url\":\"https://www.semanticscholar.org/paper/da8f9211ea60755bb40811bb92de76be389566c6\",\"venue\":\"IEEE MultiMedia\",\"year\":2018},{\"arxivId\":\"1804.03803\",\"authors\":[{\"authorId\":\"1887625\",\"name\":\"Yuehua Wu\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"39978626\",\"name\":\"Lu Jiang\"},{\"authorId\":null,\"name\":\"Yi Yang\"}],\"doi\":\"10.1145/3240508.3240640\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d64f52b94977b71976327eeb3db702b246ee39ce\",\"title\":\"Decoupled Novel Object Captioner\",\"url\":\"https://www.semanticscholar.org/paper/d64f52b94977b71976327eeb3db702b246ee39ce\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150197175\",\"name\":\"L. Zhou\"},{\"authorId\":\"49890476\",\"name\":\"Yuejie Zhang\"},{\"authorId\":\"49296155\",\"name\":\"Y. Jiang\"},{\"authorId\":\"145326655\",\"name\":\"Tao Zhang\"},{\"authorId\":\"145631869\",\"name\":\"W. Fan\"}],\"doi\":\"10.1109/TIP.2019.2928144\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"95db18799c539c82379585d25af66fd968ff000c\",\"title\":\"Re-Caption: Saliency-Enhanced Image Captioning Through Two-Phase Learning\",\"url\":\"https://www.semanticscholar.org/paper/95db18799c539c82379585d25af66fd968ff000c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s42979-020-00238-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3f732495721356944027051bb14100436a5dbdf5\",\"title\":\"AACR: Feature Fusion Effects of Algebraic Amalgamation Composed Representation on (De)Compositional Network for Caption Generation for Images\",\"url\":\"https://www.semanticscholar.org/paper/3f732495721356944027051bb14100436a5dbdf5\",\"venue\":\"SN Comput. Sci.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2715920\",\"name\":\"Malihe Alikhani\"},{\"authorId\":\"144884556\",\"name\":\"Matthew Stone\"}],\"doi\":\"10.18653/v1/W19-1806\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5834b21b80c8ec68d508684d25a613a604f06479\",\"title\":\"\\u201cCaption\\u201d as a Coherence Relation: Evidence and Implications\",\"url\":\"https://www.semanticscholar.org/paper/5834b21b80c8ec68d508684d25a613a604f06479\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738647655\",\"name\":\"Emiel van Miltenburg\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"adf57a2bdcffc38238e64d4ae797c12405281173\",\"title\":\"How Do Image Description Systems Describe People? A Targeted Assessment of System Competence in the PEOPLE-domain\",\"url\":\"https://www.semanticscholar.org/paper/adf57a2bdcffc38238e64d4ae797c12405281173\",\"venue\":\"LANTERN\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144081629\",\"name\":\"Mario G\\u00f3mez Mart\\u00ednez\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"faa8314259e9de1af8e841c265b0251531b32e04\",\"title\":\"Deep learning for image captioning: an encoder-decoder architecture with soft attention\",\"url\":\"https://www.semanticscholar.org/paper/faa8314259e9de1af8e841c265b0251531b32e04\",\"venue\":\"\",\"year\":2019}],\"corpusId\":19158922,\"doi\":\"10.1109/ICCV.2017.272\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":6,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"e4a11cc697c94fdda9eedbac7d83a865646bd4cc\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"}],\"doi\":\"10.1016/j.sigpro.2012.06.014\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"38652d59b73992f33ea21c7a2e54e9fd6c37389c\",\"title\":\"Learning saliency-based visual attention: A review\",\"url\":\"https://www.semanticscholar.org/paper/38652d59b73992f33ea21c7a2e54e9fd6c37389c\",\"venue\":\"Signal Process.\",\"year\":2013},{\"arxivId\":\"1503.08853\",\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"144022930\",\"name\":\"James Tanner\"}],\"doi\":\"10.1109/TNNLS.2015.2480683\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"04e083e88b178beb71df02bef047f4d6c7f98faf\",\"title\":\"Reconciling Saliency and Object Center-Bias Hypotheses in Explaining Free-Viewing Fixations\",\"url\":\"https://www.semanticscholar.org/paper/04e083e88b178beb71df02bef047f4d6c7f98faf\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3012475\",\"name\":\"R. Mottaghi\"},{\"authorId\":\"34420250\",\"name\":\"X. Chen\"},{\"authorId\":\"144799773\",\"name\":\"Xiaobai Liu\"},{\"authorId\":\"2853939\",\"name\":\"Nam-Gyu Cho\"},{\"authorId\":\"1703007\",\"name\":\"S. Lee\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.1109/CVPR.2014.119\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"3419ccd5c94d301ee08d716d037f0c3c6a62e78e\",\"title\":\"The Role of Context for Object Detection and Semantic Segmentation in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/3419ccd5c94d301ee08d716d037f0c3c6a62e78e\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1601.03896\",\"authors\":[{\"authorId\":\"145040726\",\"name\":\"R. Bernardi\"},{\"authorId\":\"2588033\",\"name\":\"Ruken Cakici\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"},{\"authorId\":\"1398643531\",\"name\":\"N. Ikizler-Cinbis\"},{\"authorId\":\"1393020635\",\"name\":\"F. Keller\"},{\"authorId\":\"35347012\",\"name\":\"A. Muscat\"},{\"authorId\":\"2022124\",\"name\":\"Barbara Plank\"}],\"doi\":\"10.24963/ijcai.2017/704\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6e9aebe54f76d85c6df7e80faa761ef0aec3d54c\",\"title\":\"Automatic Description Generation from Images: A Survey of Models, Datasets, and Evaluation Measures (Extended Abstract)\",\"url\":\"https://www.semanticscholar.org/paper/6e9aebe54f76d85c6df7e80faa761ef0aec3d54c\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"},{\"authorId\":\"1760868\",\"name\":\"M. Surdeanu\"},{\"authorId\":\"144661918\",\"name\":\"John Bauer\"},{\"authorId\":\"2784228\",\"name\":\"Jenny Rose Finkel\"},{\"authorId\":\"2105138\",\"name\":\"Steven Bethard\"},{\"authorId\":\"2240597\",\"name\":\"D. McClosky\"}],\"doi\":\"10.3115/v1/P14-5010\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"2f5102ec3f70d0dea98c957cc2cab4d15d83a2da\",\"title\":\"The Stanford CoreNLP Natural Language Processing Toolkit\",\"url\":\"https://www.semanticscholar.org/paper/2f5102ec3f70d0dea98c957cc2cab4d15d83a2da\",\"venue\":\"ACL\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"143694777\",\"name\":\"Frank Keller\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3f6a4556769e819242d669d073b895f1e45a706f\",\"title\":\"Image Description using Visual Dependency Representations\",\"url\":\"https://www.semanticscholar.org/paper/3f6a4556769e819242d669d073b895f1e45a706f\",\"venue\":\"EMNLP\",\"year\":2013},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1937917\",\"name\":\"A. Clarke\"},{\"authorId\":\"1689233\",\"name\":\"M. Elsner\"},{\"authorId\":\"20937093\",\"name\":\"H. Rohde\"}],\"doi\":\"10.3389/fpsyg.2015.01793\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6b9c232950ff5858c5225efeafa67198c06114be\",\"title\":\"Giving Good Directions: Order of Mention Reflects Visual Salience\",\"url\":\"https://www.semanticscholar.org/paper/6b9c232950ff5858c5225efeafa67198c06114be\",\"venue\":\"Front. Psychol.\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"D. Irwin\"},{\"authorId\":null,\"name\":\"D. Davidson\"},{\"authorId\":null,\"name\":\"W. Levelt\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"tomatic description generation from images : A survey\",\"url\":\"\",\"venue\":\"J . Artif . Intell . Res .\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143615083\",\"name\":\"R. J. Peters\"},{\"authorId\":\"4292093\",\"name\":\"A. Iyer\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"}],\"doi\":\"10.1016/j.visres.2005.03.019\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a7447f7e6197c0875a28686efdffe4ba4beb5460\",\"title\":\"Components of bottom-up gaze allocation in natural images\",\"url\":\"https://www.semanticscholar.org/paper/a7447f7e6197c0875a28686efdffe4ba4beb5460\",\"venue\":\"Vision Research\",\"year\":2005},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1312.7570\",\"authors\":[{\"authorId\":\"37710702\",\"name\":\"Stefan Mathe\"},{\"authorId\":\"1781120\",\"name\":\"C. Sminchisescu\"}],\"doi\":\"10.1109/TPAMI.2014.2366154\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e254d0e670ce8217e74aaf1421c72e63e62929e3\",\"title\":\"Actions in the Eye: Dynamic Gaze Datasets and Learnt Saliency Models for Visual Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e254d0e670ce8217e74aaf1421c72e63e62929e3\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2015},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1505.01121\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":\"10.1109/ICCV.2015.9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bd7bd1d2945a58cdcc1797ba9698b8810fe68f60\",\"title\":\"Ask Your Neurons: A Neural-Based Approach to Answering Questions about Images\",\"url\":\"https://www.semanticscholar.org/paper/bd7bd1d2945a58cdcc1797ba9698b8810fe68f60\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1412.2306\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/TPAMI.2016.2598339\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"title\":\"Deep Visual-Semantic Alignments for Generating Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143775672\",\"name\":\"Tilke Judd\"},{\"authorId\":\"1865091\",\"name\":\"Krista A. Ehinger\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/ICCV.2009.5459462\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c7614898de1cfee1a3a1c564f52c1e67879c29b3\",\"title\":\"Learning to predict where humans look\",\"url\":\"https://www.semanticscholar.org/paper/c7614898de1cfee1a3a1c564f52c1e67879c29b3\",\"venue\":\"2009 IEEE 12th International Conference on Computer Vision\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3125805\",\"name\":\"Cyrus Rashtchian\"},{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"2170746\",\"name\":\"M. Hodosh\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bf60322f83714523e2d7c1d39983151fe9db7146\",\"title\":\"Collecting Image Annotations Using Amazon's Mechanical Turk\",\"url\":\"https://www.semanticscholar.org/paper/bf60322f83714523e2d7c1d39983151fe9db7146\",\"venue\":\"Mturk@HLT-NAACL\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1400884009\",\"name\":\"B. M. \\u2019t Hart\"},{\"authorId\":\"30463125\",\"name\":\"H. Schmidt\"},{\"authorId\":\"47738301\",\"name\":\"C. Roth\"},{\"authorId\":\"1917767\",\"name\":\"W. Einh\\u00e4user\"}],\"doi\":\"10.3389/fpsyg.2013.00455\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d09d6880348a9682a8edd3ec5b41c9c4ac12d83\",\"title\":\"Fixations on objects in natural scenes: dissociating importance from salience\",\"url\":\"https://www.semanticscholar.org/paper/0d09d6880348a9682a8edd3ec5b41c9c4ac12d83\",\"venue\":\"Front. Psychol.\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47253252\",\"name\":\"K. Bock\"},{\"authorId\":\"144135771\",\"name\":\"D. Irwin\"},{\"authorId\":\"33437599\",\"name\":\"D. Davidson\"},{\"authorId\":\"1687230\",\"name\":\"W. Levelt\"}],\"doi\":\"10.1016/S0749-596X(03)00007-X\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8ef6dedecd547978f880919b1782e66c0ce5a681\",\"title\":\"Minding the clock\",\"url\":\"https://www.semanticscholar.org/paper/8ef6dedecd547978f880919b1782e66c0ce5a681\",\"venue\":\"\",\"year\":2003},{\"arxivId\":\"1301.3781\",\"authors\":[{\"authorId\":null,\"name\":\"Tomas Mikolov\"},{\"authorId\":\"38644044\",\"name\":\"Kai Chen\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"330da625c15427c6e42ccfa3b747fb29e5835bf0\",\"title\":\"Efficient Estimation of Word Representations in Vector Space\",\"url\":\"https://www.semanticscholar.org/paper/330da625c15427c6e42ccfa3b747fb29e5835bf0\",\"venue\":\"ICLR\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"143852685\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"2037692\",\"name\":\"Dicky N. Sihite\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1109/ICCV.2013.118\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"05375a7489f0a84d47a316bacb4d86e8a7bda0df\",\"title\":\"Analysis of Scores, Datasets, and Models in Visual Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/05375a7489f0a84d47a316bacb4d86e8a7bda0df\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"145564333\",\"name\":\"G. Kulkarni\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8e080b98efbe65c02a116439205ca2344b9f7cd4\",\"title\":\"Im2Text: Describing Images Using 1 Million Captioned Photographs\",\"url\":\"https://www.semanticscholar.org/paper/8e080b98efbe65c02a116439205ca2344b9f7cd4\",\"venue\":\"NIPS\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32623715\",\"name\":\"A. Meyer\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3fb03af326fa4bfbbf36b055efb68d39a22d9938\",\"title\":\"The use of eye tracking in studies of sentence generation\",\"url\":\"https://www.semanticscholar.org/paper/3fb03af326fa4bfbbf36b055efb68d39a22d9938\",\"venue\":\"\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1888731\",\"name\":\"M. Hejrati\"},{\"authorId\":\"21160985\",\"name\":\"M. Sadeghi\"},{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"3125805\",\"name\":\"Cyrus Rashtchian\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"144016256\",\"name\":\"D. Forsyth\"}],\"doi\":\"10.1007/978-3-642-15561-1_2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eaaed23a2d94feb2f1c3ff22a25777c7a78f3141\",\"title\":\"Every Picture Tells a Story: Generating Sentences from Images\",\"url\":\"https://www.semanticscholar.org/paper/eaaed23a2d94feb2f1c3ff22a25777c7a78f3141\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38314306\",\"name\":\"Rakshith Shetty\"},{\"authorId\":\"143852685\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"1708642\",\"name\":\"Jorma T. Laaksonen\"}],\"doi\":\"10.1145/2983563.2983571\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d6d6edce271935feec96484d0e1f16dcc24973fd\",\"title\":\"Exploiting Scene Context for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/d6d6edce271935feec96484d0e1f16dcc24973fd\",\"venue\":\"iV&L-MM@MM\",\"year\":2016},{\"arxivId\":\"1406.5679\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2319608\",\"name\":\"Armand Joulin\"},{\"authorId\":\"153196308\",\"name\":\"F. Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7f1b111f0bb703b0bd97aba505728a9b0d9b2a54\",\"title\":\"Deep Fragment Embeddings for Bidirectional Image Sentence Mapping\",\"url\":\"https://www.semanticscholar.org/paper/7f1b111f0bb703b0bd97aba505728a9b0d9b2a54\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145678691\",\"name\":\"G. Huang\"},{\"authorId\":\"50736254\",\"name\":\"Qin-Yu Zhu\"},{\"authorId\":\"1683268\",\"name\":\"C. Siew\"}],\"doi\":\"10.1016/j.neucom.2005.12.126\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f2df0c1026ffa474f603a535e48e5c115d3d8629\",\"title\":\"Extreme learning machine: Theory and applications\",\"url\":\"https://www.semanticscholar.org/paper/f2df0c1026ffa474f603a535e48e5c115d3d8629\",\"venue\":\"Neurocomputing\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2136978\",\"name\":\"Michelle R. Greene\"}],\"doi\":\"10.3389/fpsyg.2013.00777\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c12080eb92c8972fee80f8247758292dce6c3c38\",\"title\":\"Statistics of high-level scene context\",\"url\":\"https://www.semanticscholar.org/paper/c12080eb92c8972fee80f8247758292dce6c3c38\",\"venue\":\"Front. Psychol.\",\"year\":2013},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"114241792\",\"name\":\"J. C. Charles\"}],\"doi\":\"10.1037/027592\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bba3d21346d461b50cb31f0425887a6f841a8025\",\"title\":\"Cognition and Sentence Production: A Cross-Linguistic Study.\",\"url\":\"https://www.semanticscholar.org/paper/bba3d21346d461b50cb31f0425887a6f841a8025\",\"venue\":\"\",\"year\":1989},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32623715\",\"name\":\"A. Meyer\"},{\"authorId\":\"51901247\",\"name\":\"Astrid M. Sleiderink\"},{\"authorId\":\"1687230\",\"name\":\"W. Levelt\"}],\"doi\":\"10.1016/S0010-0277(98)00009-2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f5c309684a57cb283174535e9e0e65c21e38a69f\",\"title\":\"Viewing and naming objects: eye movements during noun phrase production\",\"url\":\"https://www.semanticscholar.org/paper/f5c309684a57cb283174535e9e0e65c21e38a69f\",\"venue\":\"Cognition\",\"year\":1998},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"C. Chambers\"},{\"authorId\":null,\"name\":\"J. E. Hanna\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Referen - tial domains in spoken language comprehension : Using eye movements to bridge the product and action traditions\",\"url\":\"\",\"venue\":\"The interface of language , vision , and action : Eye movements and visual world\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3067607\",\"name\":\"Jana Holsanova\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1bb439407df3ccc54c2262f78adc186694b4b621\",\"title\":\"How we focus attention in picture viewing, picture description, and during mental imagery\",\"url\":\"https://www.semanticscholar.org/paper/1bb439407df3ccc54c2262f78adc186694b4b621\",\"venue\":\"\",\"year\":2009},{\"arxivId\":\"1505.01809\",\"authors\":[{\"authorId\":\"39172707\",\"name\":\"J. Devlin\"},{\"authorId\":\"47413820\",\"name\":\"Hao Cheng\"},{\"authorId\":\"145204655\",\"name\":\"Hao Fang\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"}],\"doi\":\"10.3115/v1/P15-2017\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f142c849ffef66f7520aff4e0b40ac964ccb8cc1\",\"title\":\"Language Models for Image Captioning: The Quirks and What Works\",\"url\":\"https://www.semanticscholar.org/paper/f142c849ffef66f7520aff4e0b40ac964ccb8cc1\",\"venue\":\"ACL\",\"year\":2015},{\"arxivId\":\"1608.05203\",\"authors\":[{\"authorId\":\"1751242\",\"name\":\"Yusuke Sugano\"},{\"authorId\":\"3194727\",\"name\":\"Andreas Bulling\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c70ad19c90491e2de8de686b6a49f9bbe44692c0\",\"title\":\"Seeing with Humans: Gaze-Assisted Neural Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/c70ad19c90491e2de8de686b6a49f9bbe44692c0\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1795076\",\"name\":\"M. Arbib\"}],\"doi\":\"10.1017/CBO9780511541599\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b45faf555489ab5d2a0a8c396f7353210583676a\",\"title\":\"Action to language via the mirror neuron system\",\"url\":\"https://www.semanticscholar.org/paper/b45faf555489ab5d2a0a8c396f7353210583676a\",\"venue\":\"\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33230676\",\"name\":\"Kiwon Yun\"},{\"authorId\":\"2699239\",\"name\":\"Yifan Peng\"},{\"authorId\":\"145654220\",\"name\":\"D. Samaras\"},{\"authorId\":\"1696991\",\"name\":\"G. Zelinsky\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.3389/fpsyg.2013.00917\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"13b214d6cebbded0f5599309425fa38192487980\",\"title\":\"Exploring the role of gaze behavior and object detection in scene understanding\",\"url\":\"https://www.semanticscholar.org/paper/13b214d6cebbded0f5599309425fa38192487980\",\"venue\":\"Front. Psychol.\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"145297531\",\"name\":\"A. Lai\"},{\"authorId\":\"2170746\",\"name\":\"M. Hodosh\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"}],\"doi\":\"10.1162/tacl_a_00166\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"44040913380206991b1991daf1192942e038fe31\",\"title\":\"From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions\",\"url\":\"https://www.semanticscholar.org/paper/44040913380206991b1991daf1192942e038fe31\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2157958\",\"name\":\"Michael J. Denkowski\"},{\"authorId\":\"1784914\",\"name\":\"A. Lavie\"}],\"doi\":\"10.3115/v1/W14-3348\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"26adb749fc5d80502a6d889966e50b31391560d3\",\"title\":\"Meteor Universal: Language Specific Translation Evaluation for Any Target Language\",\"url\":\"https://www.semanticscholar.org/paper/26adb749fc5d80502a6d889966e50b31391560d3\",\"venue\":\"WMT@ACL\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"M. k. Tanenhaus\"},{\"authorId\":null,\"name\":\"C. Chambers\"},{\"authorId\":null,\"name\":\"J. E. Hanna\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Referential domains in spoken language comprehension: Using eye movements to bridge the product and action traditions. In The interface of language, vision, and action: Eye movements and visual world\",\"url\":\"\",\"venue\":\"\",\"year\":2004},{\"arxivId\":\"cmp-lg/9508004\",\"authors\":[{\"authorId\":\"1721040\",\"name\":\"D. Sleator\"},{\"authorId\":\"3335864\",\"name\":\"David Temperley\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5752b8dcec5856b7ad6289bbe1177acce535fba4\",\"title\":\"Parsing English with a Link Grammar\",\"url\":\"https://www.semanticscholar.org/paper/5752b8dcec5856b7ad6289bbe1177acce535fba4\",\"venue\":\"IWPT\",\"year\":1993},{\"arxivId\":null,\"authors\":[{\"authorId\":\"114872828\",\"name\":\"S. Sridhar\"}],\"doi\":\"10.1007/978-1-4612-4568-1_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2d354c1b0876946cb02cfde26d48a371f1d7fc5b\",\"title\":\"Models of Sentence Production\",\"url\":\"https://www.semanticscholar.org/paper/2d354c1b0876946cb02cfde26d48a371f1d7fc5b\",\"venue\":\"\",\"year\":1988},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2917857\",\"name\":\"F. Pulverm\\u00fcller\"},{\"authorId\":\"29747547\",\"name\":\"M. H\\u00e4rle\"},{\"authorId\":\"37274549\",\"name\":\"F. Hummel\"}],\"doi\":\"10.1006/brln.2000.2390\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"157993ef78f19fa93804768fbf49e3393599025f\",\"title\":\"Walking or Talking?: Behavioral and Neurophysiological Correlates of Action Verb Processing\",\"url\":\"https://www.semanticscholar.org/paper/157993ef78f19fa93804768fbf49e3393599025f\",\"venue\":\"Brain and Language\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"D. Davidson\"},{\"authorId\":null,\"name\":\"W. Levelt\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"tomatic description generation from images : A survey\",\"url\":\"\",\"venue\":\"J . Artif . Intell . Res .\",\"year\":null},{\"arxivId\":\"1612.01033\",\"authors\":[{\"authorId\":\"3048367\",\"name\":\"M. Pedersoli\"},{\"authorId\":\"144982160\",\"name\":\"T. Lucas\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"34602236\",\"name\":\"Jakob Verbeek\"}],\"doi\":\"10.1109/ICCV.2017.140\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d86f0e22fed5e065ecf54b273d540b2430f014d\",\"title\":\"Areas of Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6d86f0e22fed5e065ecf54b273d540b2430f014d\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39810944\",\"name\":\"Jonathan Harel\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"}],\"doi\":\"10.7551/mitpress/7503.003.0073\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f412bb31ec9ef8bbef70eefc7ffd04420c1365d9\",\"title\":\"Graph-Based Visual Saliency\",\"url\":\"https://www.semanticscholar.org/paper/f412bb31ec9ef8bbef70eefc7ffd04420c1365d9\",\"venue\":\"NIPS\",\"year\":2006},{\"arxivId\":\"1411.4952\",\"authors\":[{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3346186\",\"name\":\"Forrest N. Iandola\"},{\"authorId\":\"2100612\",\"name\":\"R. Srivastava\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"144189092\",\"name\":\"John C. Platt\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"}],\"doi\":\"10.1109/CVPR.2015.7298754\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"title\":\"From captions to visual concepts and back\",\"url\":\"https://www.semanticscholar.org/paper/15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"M. k. Tanenhaus\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Referen - tial domains in spoken language comprehension : Using eye movements to bridge the product and action traditions\",\"url\":\"\",\"venue\":\"\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3056091\",\"name\":\"M. Everingham\"},{\"authorId\":\"143648071\",\"name\":\"S. Eslami\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"145715698\",\"name\":\"C. K. Williams\"},{\"authorId\":\"33652486\",\"name\":\"J. Winn\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/s11263-014-0733-5\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"616b246e332573af1f4859aa91440280774c183a\",\"title\":\"The Pascal Visual Object Classes Challenge: A Retrospective\",\"url\":\"https://www.semanticscholar.org/paper/616b246e332573af1f4859aa91440280774c183a\",\"venue\":\"International Journal of Computer Vision\",\"year\":2014},{\"arxivId\":\"1512.02949\",\"authors\":[{\"authorId\":\"38314306\",\"name\":\"Rakshith Shetty\"},{\"authorId\":\"1708642\",\"name\":\"Jorma T. Laaksonen\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"3bcca85ad84806be6d38d3882f7a6aac0ad90253\",\"title\":\"Video captioning with recurrent networks based on frame- and video-level features and visual content classification\",\"url\":\"https://www.semanticscholar.org/paper/3bcca85ad84806be6d38d3882f7a6aac0ad90253\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1705.10546\",\"authors\":[{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"2253528\",\"name\":\"F. Ahmed\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"1708642\",\"name\":\"Jorma T. Laaksonen\"}],\"doi\":\"10.1109/CVPR.2017.673\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"42f4aeff8219942153104c3ed5d9d661663d0cd3\",\"title\":\"Saliency Revisited: Analysis of Mouse Movements Versus Fixations\",\"url\":\"https://www.semanticscholar.org/paper/42f4aeff8219942153104c3ed5d9d661663d0cd3\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2170746\",\"name\":\"M. Hodosh\"},{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"}],\"doi\":\"10.1613/jair.3994\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9814df8bd00ba999c4d1e305a7e9bca579dc7c75\",\"title\":\"Framing Image Description as a Ranking Task: Data, Models and Evaluation Metrics (Extended Abstract)\",\"url\":\"https://www.semanticscholar.org/paper/9814df8bd00ba999c4d1e305a7e9bca579dc7c75\",\"venue\":\"IJCAI\",\"year\":2013},{\"arxivId\":\"1505.00468\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-016-0966-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"title\":\"VQA: Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50341924\",\"name\":\"Siming Li\"},{\"authorId\":\"145564333\",\"name\":\"G. Kulkarni\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fbdbe747c6aa8b35b981d21e475ff1506a1bae66\",\"title\":\"Composing Simple Image Descriptions using Web-scale N-grams\",\"url\":\"https://www.semanticscholar.org/paper/fbdbe747c6aa8b35b981d21e475ff1506a1bae66\",\"venue\":\"CoNLL\",\"year\":2011},{\"arxivId\":\"1411.5726\",\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2015.7299087\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"258986132bf17755fe8263e42429fe73218c1534\",\"title\":\"CIDEr: Consensus-based image description evaluation\",\"url\":\"https://www.semanticscholar.org/paper/258986132bf17755fe8263e42429fe73218c1534\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1610.06449\",\"authors\":[{\"authorId\":\"143852685\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"1708642\",\"name\":\"Jorma T. Laaksonen\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"}],\"doi\":\"10.1016/j.neucom.2017.03.018\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9995d891a5d6737eadd7b386de23fbd7aef77903\",\"title\":\"Exploiting inter-image similarity and ensemble of extreme learners for fixation prediction using deep features\",\"url\":\"https://www.semanticscholar.org/paper/9995d891a5d6737eadd7b386de23fbd7aef77903\",\"venue\":\"Neurocomputing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2543016\",\"name\":\"M. Cimpoi\"},{\"authorId\":\"35208858\",\"name\":\"Subhransu Maji\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":\"10.1109/cvpr.2015.7299007\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aec822f56ff1794c32f5826cfb266f9b477f4df8\",\"title\":\"Deep filter banks for texture recognition and segmentation\",\"url\":\"https://www.semanticscholar.org/paper/aec822f56ff1794c32f5826cfb266f9b477f4df8\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1722360\",\"name\":\"Hal Daum\\u00e9\"},{\"authorId\":\"34176020\",\"name\":\"Jesse Dodge\"},{\"authorId\":\"46479604\",\"name\":\"Amit Goyal\"},{\"authorId\":\"1682965\",\"name\":\"Xufeng Han\"},{\"authorId\":\"40614240\",\"name\":\"A. Mensch\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"2212748\",\"name\":\"Aneesh Sood\"},{\"authorId\":\"1714215\",\"name\":\"K. Stratos\"},{\"authorId\":\"1721910\",\"name\":\"Kota Yamaguchi\"}],\"doi\":\"10.1109/CVPR.2012.6248100\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5ce04063ecf83a6584813e1a09fb3d81642e5790\",\"title\":\"Understanding and predicting importance in images\",\"url\":\"https://www.semanticscholar.org/paper/5ce04063ecf83a6584813e1a09fb3d81642e5790\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1781574\",\"name\":\"Chin-Yew Lin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"60b05f32c32519a809f21642ef1eb3eaf3848008\",\"title\":\"ROUGE: A Package for Automatic Evaluation of Summaries\",\"url\":\"https://www.semanticscholar.org/paper/60b05f32c32519a809f21642ef1eb3eaf3848008\",\"venue\":\"ACL 2004\",\"year\":2004},{\"arxivId\":\"1406.5774\",\"authors\":[{\"authorId\":\"2622491\",\"name\":\"H. Azizpour\"},{\"authorId\":\"2835963\",\"name\":\"A. Razavian\"},{\"authorId\":\"50626295\",\"name\":\"J. Sullivan\"},{\"authorId\":\"1801052\",\"name\":\"A. Maki\"},{\"authorId\":\"144719278\",\"name\":\"S. Carlsson\"}],\"doi\":\"10.1109/CVPRW.2015.7301270\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dbb684f6a0f95cfd0ddbe324ab476d8e95613cb0\",\"title\":\"From generic to specific deep representations for visual recognition\",\"url\":\"https://www.semanticscholar.org/paper/dbb684f6a0f95cfd0ddbe324ab476d8e95613cb0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33230676\",\"name\":\"Kiwon Yun\"},{\"authorId\":null,\"name\":\"Yifan Peng\"},{\"authorId\":\"145654220\",\"name\":\"D. Samaras\"},{\"authorId\":\"1696991\",\"name\":\"G. Zelinsky\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/CVPR.2013.101\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ad2c0ae801c9e8adece483e74725e12a8544d440\",\"title\":\"Studying Relationships between Human Gaze, Description, and Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/ad2c0ae801c9e8adece483e74725e12a8544d440\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144645142\",\"name\":\"M. Jiang\"},{\"authorId\":\"1961257\",\"name\":\"Shengsheng Huang\"},{\"authorId\":\"2104164\",\"name\":\"Juanyong Duan\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1109/CVPR.2015.7298710\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c71db5d3546e22227662ee0f0ce586495ef18899\",\"title\":\"SALICON: Saliency in Context\",\"url\":\"https://www.semanticscholar.org/paper/c71db5d3546e22227662ee0f0ce586495ef18899\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3269361\",\"name\":\"Z. Griffin\"},{\"authorId\":\"47253252\",\"name\":\"K. Bock\"}],\"doi\":\"10.1111/1467-9280.00255\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ad4e68654bad0b1a492aeece40aae373a6a83688\",\"title\":\"What the Eyes Say About Speaking\",\"url\":\"https://www.semanticscholar.org/paper/ad4e68654bad0b1a492aeece40aae373a6a83688\",\"venue\":\"Psychological science\",\"year\":2000},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/TPAMI.2014.2366143\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f8403bf4e3060487cbc8acceb1fb256a4f1cfc76\",\"title\":\"Adopting Abstract Images for Semantic Scene Understanding\",\"url\":\"https://www.semanticscholar.org/paper/f8403bf4e3060487cbc8acceb1fb256a4f1cfc76\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"G.-B. Huang\"},{\"authorId\":null,\"name\":\"Q.-Y. Zhu\"},{\"authorId\":null,\"name\":\"C.-K. Siew\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Extereme learning machine: Theory and applicatons\",\"url\":\"\",\"venue\":\"Neurocomput., 70,\",\"year\":2006},{\"arxivId\":\"1612.07360\",\"authors\":[{\"authorId\":\"2018561\",\"name\":\"Vasili Ramanishka\"},{\"authorId\":\"40521893\",\"name\":\"Abir Das\"},{\"authorId\":\"1701293\",\"name\":\"J. Zhang\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/CVPR.2017.334\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"76f83380fe193ae8475e660c1c6b12b60521a29f\",\"title\":\"Top-Down Visual Saliency Guided by Captions\",\"url\":\"https://www.semanticscholar.org/paper/76f83380fe193ae8475e660c1c6b12b60521a29f\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3323275\",\"name\":\"Kishore Papineni\"},{\"authorId\":\"1781292\",\"name\":\"S. Roukos\"},{\"authorId\":\"144582029\",\"name\":\"T. Ward\"},{\"authorId\":\"2587983\",\"name\":\"Wei-Jing Zhu\"}],\"doi\":\"10.3115/1073083.1073135\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d7da009f457917aa381619facfa5ffae9329a6e9\",\"title\":\"Bleu: a Method for Automatic Evaluation of Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/d7da009f457917aa381619facfa5ffae9329a6e9\",\"venue\":\"ACL\",\"year\":2002},{\"arxivId\":\"1504.00325\",\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"title\":\"Microsoft COCO Captions: Data Collection and Evaluation Server\",\"url\":\"https://www.semanticscholar.org/paper/696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3269361\",\"name\":\"Z. Griffin\"},{\"authorId\":\"6328135\",\"name\":\"D. Spieler\"}],\"doi\":\"10.1016/j.bandl.2005.08.003\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"83918ea0ebf24a0b259a019aa03598d19f4e90cd\",\"title\":\"Observing the what and when of language production for different age groups by monitoring speakers\\u2019 eye movements\",\"url\":\"https://www.semanticscholar.org/paper/83918ea0ebf24a0b259a019aa03598d19f4e90cd\",\"venue\":\"Brain and Language\",\"year\":2006},{\"arxivId\":\"1506.01698\",\"authors\":[{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1007/978-3-319-24947-6_17\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"49512d11c468dc2fe3fe832d8c4dc8e0a01b0a4b\",\"title\":\"The Long-Short Story of Movie Description\",\"url\":\"https://www.semanticscholar.org/paper/49512d11c468dc2fe3fe832d8c4dc8e0a01b0a4b\",\"venue\":\"GCPR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7326223\",\"name\":\"L. Itti\"},{\"authorId\":\"1795076\",\"name\":\"M. Arbib\"}],\"doi\":\"10.1017/CBO9780511541599.010\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1fbfffc42b13294cbf767db2354ec8d4635a6916\",\"title\":\"Action to Language via the Mirror Neuron System: Attention and the minimal subscene\",\"url\":\"https://www.semanticscholar.org/paper/1fbfffc42b13294cbf767db2354ec8d4635a6916\",\"venue\":\"\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"144509504\",\"name\":\"A. D. Vries\"}],\"doi\":\"10.3115/v1/P15-1005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3bfa75238e15e869b902ceb62b31ffddbe8ccb0d\",\"title\":\"Describing Images using Inferred Visual Dependency Representations\",\"url\":\"https://www.semanticscholar.org/paper/3bfa75238e15e869b902ceb62b31ffddbe8ccb0d\",\"venue\":\"ACL\",\"year\":2015}],\"title\":\"Paying Attention to Descriptions Generated by Image Captioning Models\",\"topics\":[{\"topic\":\"Computer vision\",\"topicId\":\"5332\",\"url\":\"https://www.semanticscholar.org/topic/5332\"},{\"topic\":\"Language model\",\"topicId\":\"26812\",\"url\":\"https://www.semanticscholar.org/topic/26812\"},{\"topic\":\"High- and low-level\",\"topicId\":\"33507\",\"url\":\"https://www.semanticscholar.org/topic/33507\"},{\"topic\":\"Baseline (configuration management)\",\"topicId\":\"3403\",\"url\":\"https://www.semanticscholar.org/topic/3403\"}],\"url\":\"https://www.semanticscholar.org/paper/e4a11cc697c94fdda9eedbac7d83a865646bd4cc\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017}\n"