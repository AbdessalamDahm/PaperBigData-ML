"{\"abstract\":\"Automatically describing an image with a natural language has been an emerging challenge in both fields of computer vision and natural language processing. In this paper, we present Long Short-Term Memory with Attributes (LSTM-A) - a novel architecture that integrates attributes into the successful Convolutional Neural Networks (CNNs) plus Recurrent Neural Networks (RNNs) image captioning framework, by training them in an end-to-end manner. Particularly, the learning of attributes is strengthened by integrating inter-attribute correlations into Multiple Instance Learning (MIL). To incorporate attributes into captioning, we construct variants of architectures by feeding image representations and attributes into RNNs in different ways to explore the mutual but also fuzzy relationship between them. Extensive experiments are conducted on COCO image captioning dataset and our framework shows clear improvements when compared to state-of-the-art deep models. More remarkably, we obtain METEOR/CIDEr-D of 25.5%/100.2% on testing data of widely used and publicly available splits in [10] when extracting image representations by GoogleNet and achieve superior performance on COCO captioning Leaderboard.\",\"arxivId\":\"1611.01646\",\"authors\":[{\"authorId\":\"145690248\",\"name\":\"Ting Yao\",\"url\":\"https://www.semanticscholar.org/author/145690248\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\",\"url\":\"https://www.semanticscholar.org/author/3202968\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\",\"url\":\"https://www.semanticscholar.org/author/3431141\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\",\"url\":\"https://www.semanticscholar.org/author/3430743\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\",\"url\":\"https://www.semanticscholar.org/author/144025741\"}],\"citationVelocity\":108,\"citations\":[{\"arxivId\":\"1905.06139\",\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"7896029\",\"name\":\"Yuanxin Liu\"},{\"authorId\":\"19169659\",\"name\":\"Xuancheng Ren\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"2511091\",\"name\":\"X. Sun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cc663416cbbd577ea02e8b4ef0ea201f5a12d608\",\"title\":\"Aligning Visual Regions and Textual Concepts for Semantic-Grounded Image Representations\",\"url\":\"https://www.semanticscholar.org/paper/cc663416cbbd577ea02e8b4ef0ea201f5a12d608\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"2751871\",\"name\":\"J. Wan\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":\"10.1109/tpami.2020.3013834\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ba341f992ceb10d9a7f032ac6027f18ef5e5f895\",\"title\":\"On Diversity in Image Captioning: Metrics and Methods.\",\"url\":\"https://www.semanticscholar.org/paper/ba341f992ceb10d9a7f032ac6027f18ef5e5f895\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"1904.02887\",\"authors\":[{\"authorId\":\"7988538\",\"name\":\"Yadan Luo\"},{\"authorId\":\"72682876\",\"name\":\"Z. Wang\"},{\"authorId\":\"145622169\",\"name\":\"Zi Huang\"},{\"authorId\":\"46173234\",\"name\":\"Y. Yang\"},{\"authorId\":\"143663452\",\"name\":\"Huimin Lu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"1e4088a5a462d07de8ba0916015888195e56ec8b\",\"title\":\"Snap and Find: Deep Discrete Cross-domain Garment Image Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/1e4088a5a462d07de8ba0916015888195e56ec8b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9073332\",\"name\":\"J. Li\"},{\"authorId\":\"1923156\",\"name\":\"P. Yao\"},{\"authorId\":\"26982950\",\"name\":\"Longteng Guo\"},{\"authorId\":\"49039585\",\"name\":\"Wei-Cun Zhang\"}],\"doi\":\"10.3390/APP9163260\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"47716ca06a3ad4226a6d8706b6f02793b9892fe4\",\"title\":\"Boosted Transformer for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/47716ca06a3ad4226a6d8706b6f02793b9892fe4\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1905.01077\",\"authors\":[{\"authorId\":\"50763020\",\"name\":\"Jingwen Chen\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"47636228\",\"name\":\"H. Chao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1609/aaai.v33i01.33018167\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d40892479541c2d173c836534e6fb2acb597de49\",\"title\":\"Temporal Deformable Convolutional Encoder-Decoder Networks for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/d40892479541c2d173c836534e6fb2acb597de49\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1709.03376\",\"authors\":[{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"},{\"authorId\":\"40894914\",\"name\":\"T. Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7f14e73dade94b8b1f276dcd91257aa7de5f19d7\",\"title\":\"Stack-Captioning: Coarse-to-Fine Learning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7f14e73dade94b8b1f276dcd91257aa7de5f19d7\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"73312190\",\"name\":\"W. Zhang\"},{\"authorId\":\"1774936\",\"name\":\"Siliang Tang\"},{\"authorId\":\"1591412916\",\"name\":\"Jiajie Su\"},{\"authorId\":\"145974114\",\"name\":\"Jun Xiao\"},{\"authorId\":\"2125211\",\"name\":\"Yueting Zhuang\"}],\"doi\":\"10.1007/s11042-020-08832-7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"814cfb898aa0bd011a97ebcf1774e42c32cf469e\",\"title\":\"Tell and guess: cooperative learning for natural image caption generation with hierarchical refined attention\",\"url\":\"https://www.semanticscholar.org/paper/814cfb898aa0bd011a97ebcf1774e42c32cf469e\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30904720\",\"name\":\"Sudipta Rudra\"},{\"authorId\":\"23551520\",\"name\":\"S. K. Thangavel\"}],\"doi\":\"10.1007/978-3-030-30465-2_79\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"438e6aa0184e9656a5a507770224e430837e752b\",\"title\":\"A Robust Q-Learning and Differential Evolution Based Policy Framework for Key Frame Extraction\",\"url\":\"https://www.semanticscholar.org/paper/438e6aa0184e9656a5a507770224e430837e752b\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1726159226\",\"name\":\"Xiangqing Shen\"},{\"authorId\":\"47655360\",\"name\":\"B. Liu\"},{\"authorId\":\"1697439\",\"name\":\"Yong Zhou\"},{\"authorId\":\"1445303213\",\"name\":\"Jiaqi Zhao\"},{\"authorId\":\"49353948\",\"name\":\"Mingming Liu\"}],\"doi\":\"10.1016/j.knosys.2020.105920\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"46fd9996cd945983f5acc9ed073dc244d6d2f32e\",\"title\":\"Remote sensing image captioning via Variational Autoencoder and Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/46fd9996cd945983f5acc9ed073dc244d6d2f32e\",\"venue\":\"Knowl. Based Syst.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"103382547\",\"name\":\"Junzhong Ji\"},{\"authorId\":\"49770078\",\"name\":\"C. Xu\"},{\"authorId\":\"46447188\",\"name\":\"X. Zhang\"},{\"authorId\":\"2692910\",\"name\":\"Boyue Wang\"},{\"authorId\":\"1688375\",\"name\":\"Xinhang Song\"}],\"doi\":\"10.1109/TIP.2020.3004729\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"63632ca4c1a6c16c9b6358624134880c3b23df90\",\"title\":\"Spatio-Temporal Memory Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/63632ca4c1a6c16c9b6358624134880c3b23df90\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50714373\",\"name\":\"A. Agarwal\"},{\"authorId\":\"36960501\",\"name\":\"Swaminathan Gurumurthy\"},{\"authorId\":\"144582538\",\"name\":\"Vasu Sharma\"},{\"authorId\":\"9076478\",\"name\":\"K. Sycara\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"bbf56398dba5593a2aed1c3857fa011442b3aed6\",\"title\":\"Mind Your Language: Learning Visually Grounded Dialog in a Multi-Agent Setting\",\"url\":\"https://www.semanticscholar.org/paper/bbf56398dba5593a2aed1c3857fa011442b3aed6\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1804472\",\"name\":\"H. Chen\"},{\"authorId\":\"38329336\",\"name\":\"G. Ding\"},{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"60af58a2435fe758fe9a172f2009efbb89584f58\",\"title\":\"Temporal-Difference Learning With Sampling Baseline for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/60af58a2435fe758fe9a172f2009efbb89584f58\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40235164\",\"name\":\"J. Wu\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"},{\"authorId\":\"144084568\",\"name\":\"Yi Wu\"}],\"doi\":\"10.1145/3271485\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"744d79cfe0b38b2e674c7425dea67492d4f14807\",\"title\":\"Image Captioning via Semantic Guidance Attention and Consensus Selection Strategy\",\"url\":\"https://www.semanticscholar.org/paper/744d79cfe0b38b2e674c7425dea67492d4f14807\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4942547\",\"name\":\"Zongjian Zhang\"},{\"authorId\":\"144066903\",\"name\":\"Q. Wu\"},{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"145093625\",\"name\":\"F. Chen\"}],\"doi\":\"10.1109/TMM.2018.2888822\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2bc7959cf6bf0ae64f1a83f5fce1ac8cb2256ed3\",\"title\":\"High-Quality Image Captioning With Fine-Grained and Semantic-Guided Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/2bc7959cf6bf0ae64f1a83f5fce1ac8cb2256ed3\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":\"1912.08960\",\"authors\":[{\"authorId\":\"8716902\",\"name\":\"Huiyuan Xie\"},{\"authorId\":\"20662387\",\"name\":\"Tom Sherborne\"},{\"authorId\":\"3449429\",\"name\":\"Alexander Kuhnle\"},{\"authorId\":\"15379653\",\"name\":\"A. Copestake\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a3afabdc3650ef93c771262f31db8ee144d0ff44\",\"title\":\"Going Beneath the Surface: Evaluating Image Captioning for Grammaticality, Truthfulness and Diversity\",\"url\":\"https://www.semanticscholar.org/paper/a3afabdc3650ef93c771262f31db8ee144d0ff44\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1710.08011\",\"authors\":[{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"},{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"19198894\",\"name\":\"Humam Alwassel\"},{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"35163655\",\"name\":\"K. Hata\"},{\"authorId\":\"8983218\",\"name\":\"S. Buch\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ba11083602568bbc2514c0905e0d831a65c2af6e\",\"title\":\"ActivityNet Challenge 2017 Summary\",\"url\":\"https://www.semanticscholar.org/paper/ba11083602568bbc2514c0905e0d831a65c2af6e\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46740305\",\"name\":\"Chunlei Wu\"},{\"authorId\":\"19261873\",\"name\":\"Yiwei Wei\"},{\"authorId\":\"15862607\",\"name\":\"Xiaoliang Chu\"},{\"authorId\":\"152343380\",\"name\":\"Fei Su\"},{\"authorId\":\"2250564\",\"name\":\"Leiquan Wang\"}],\"doi\":\"10.1016/j.image.2018.06.002\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f20d5a6f10c269582bd00fd4733bb0066faee302\",\"title\":\"Modeling visual and word-conditional semantic attention for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/f20d5a6f10c269582bd00fd4733bb0066faee302\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2018},{\"arxivId\":\"1804.00887\",\"authors\":[{\"authorId\":\"2093119\",\"name\":\"W. Jiang\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"3179887\",\"name\":\"Xinpeng Chen\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3dc2c3be0796f65154d2106ed4442889c84546df\",\"title\":\"Learning to Guide Decoding for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/3dc2c3be0796f65154d2106ed4442889c84546df\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1689115\",\"name\":\"Tao Zhang\"},{\"authorId\":\"145960537\",\"name\":\"W. Wang\"},{\"authorId\":\"1693997\",\"name\":\"Liang Wang\"},{\"authorId\":\"144281199\",\"name\":\"Q. Hu\"}],\"doi\":\"10.1007/978-981-10-7299-4_21\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dbcffedbf6c50c3759203b51710d0c43a6d7d81e\",\"title\":\"Relevance and Coherence Based Image Caption\",\"url\":\"https://www.semanticscholar.org/paper/dbcffedbf6c50c3759203b51710d0c43a6d7d81e\",\"venue\":\"CCCV\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32701193\",\"name\":\"Yuanzhi Liang\"},{\"authorId\":\"2643877\",\"name\":\"Y. Bai\"},{\"authorId\":\"48902313\",\"name\":\"Wei Zhang\"},{\"authorId\":\"6468417\",\"name\":\"Xueming Qian\"},{\"authorId\":\"4096586\",\"name\":\"L. Zhu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/ICCV.2019.01050\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"db717d20dc699f4b402db0ddf923135108a9e686\",\"title\":\"VrR-VG: Refocusing Visually-Relevant Relationships\",\"url\":\"https://www.semanticscholar.org/paper/db717d20dc699f4b402db0ddf923135108a9e686\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152356310\",\"name\":\"Danyang Cao\"},{\"authorId\":\"152223852\",\"name\":\"Menggui Zhu\"},{\"authorId\":\"145735014\",\"name\":\"L. Gao\"}],\"doi\":\"10.1007/s11042-019-08116-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3e19260676bbc8185830528773d54b83ba3f12a2\",\"title\":\"An image caption method based on object detection\",\"url\":\"https://www.semanticscholar.org/paper/3e19260676bbc8185830528773d54b83ba3f12a2\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":\"2007.03877\",\"authors\":[{\"authorId\":\"1826472\",\"name\":\"Dooseop Choi\"},{\"authorId\":\"2197109\",\"name\":\"Seung-Jun Han\"},{\"authorId\":\"97999178\",\"name\":\"K. Min\"},{\"authorId\":\"51428464\",\"name\":\"Jeongdan Choi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10ad369ae7920f7305417bf26ba33b1b4490f462\",\"title\":\"PathGAN: Local Path Planning with Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/10ad369ae7920f7305417bf26ba33b1b4490f462\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1805.09137\",\"authors\":[{\"authorId\":\"35681844\",\"name\":\"Vikram Mullachery\"},{\"authorId\":\"46175228\",\"name\":\"Vishal Motwani\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b51dc3abb6cac334d49cfaa8b29e0ebd3b9a52f9\",\"title\":\"Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/b51dc3abb6cac334d49cfaa8b29e0ebd3b9a52f9\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145959949\",\"name\":\"J. Serrano\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e07f8a6b7d805b3622a584ec97a269d54a405e1d\",\"title\":\"Boosting image captioning with an attentional mechanism = Boosting image captioning using diverse beam search\",\"url\":\"https://www.semanticscholar.org/paper/e07f8a6b7d805b3622a584ec97a269d54a405e1d\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1955964\",\"name\":\"Xiaoxiao Guo\"},{\"authorId\":\"144675299\",\"name\":\"H. Wu\"},{\"authorId\":\"2926307\",\"name\":\"Yupeng Gao\"},{\"authorId\":\"2071376\",\"name\":\"Steven J. Rennie\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"32c0166abbf99a962c43722d78cf15ba3f843fbf\",\"title\":\"The Fashion IQ Dataset: Retrieving Images by Combining Side Information and Relative Natural Language Feedback\",\"url\":\"https://www.semanticscholar.org/paper/32c0166abbf99a962c43722d78cf15ba3f843fbf\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1908.08529\",\"authors\":[{\"authorId\":\"29956361\",\"name\":\"Jyoti Aneja\"},{\"authorId\":\"37825612\",\"name\":\"Harsh Agrawal\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1109/ICCV.2019.00436\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"49d46b0245475067bb7192d9bb1538701ae1c014\",\"title\":\"Sequential Latent Spaces for Modeling the Intention During Diverse Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/49d46b0245475067bb7192d9bb1538701ae1c014\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1808.05864\",\"authors\":[{\"authorId\":\"48929163\",\"name\":\"Daqing Liu\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"},{\"authorId\":null,\"name\":\"Feng Wu\"}],\"doi\":\"10.1145/3240508.3240632\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"0574dc64c8275b09ed587dc3977f4d3c990bd4df\",\"title\":\"Context-Aware Visual Policy Network for Sequence-Level Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0574dc64c8275b09ed587dc3977f4d3c990bd4df\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1908.02127\",\"authors\":[{\"authorId\":\"26982950\",\"name\":\"Longteng Guo\"},{\"authorId\":\"1749850\",\"name\":\"J. Liu\"},{\"authorId\":\"8053308\",\"name\":\"J. Tang\"},{\"authorId\":\"49298906\",\"name\":\"Jiangwei Li\"},{\"authorId\":\"145851264\",\"name\":\"Wei Luo\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1145/3343031.3350943\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"133921bb5e559de464c0078f5fa67409aca27917\",\"title\":\"Aligning Linguistic Words and Visual Semantic Units for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/133921bb5e559de464c0078f5fa67409aca27917\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1879303113\",\"name\":\"Depeng Wang\"},{\"authorId\":\"7690231\",\"name\":\"Zhenzhen Hu\"},{\"authorId\":\"1877859275\",\"name\":\"Yuanen Zhou\"},{\"authorId\":\"1390610633\",\"name\":\"Xueliang Liu\"},{\"authorId\":\"152318056\",\"name\":\"L. Wu\"},{\"authorId\":\"48043335\",\"name\":\"R. Hong\"}],\"doi\":\"10.1109/icmew46912.2020.9106007\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"61cc97db488acc841cc31ffe046957829c366b53\",\"title\":\"A Text-Guided Graph Structure for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/61cc97db488acc841cc31ffe046957829c366b53\",\"venue\":\"2020 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2020},{\"arxivId\":\"1904.01410\",\"authors\":[{\"authorId\":\"4332039\",\"name\":\"Guojun Yin\"},{\"authorId\":\"37145669\",\"name\":\"Lu Sheng\"},{\"authorId\":null,\"name\":\"Bin Liu\"},{\"authorId\":\"1708598\",\"name\":\"N. Yu\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"},{\"authorId\":\"144478188\",\"name\":\"J. Shao\"}],\"doi\":\"10.1109/CVPR.2019.00640\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"eba62fe8050e475ffe533b9f70db538074d8d0d1\",\"title\":\"Context and Attribute Grounded Dense Captioning\",\"url\":\"https://www.semanticscholar.org/paper/eba62fe8050e475ffe533b9f70db538074d8d0d1\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1391204924\",\"name\":\"Zongjian Zhang\"},{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"50528721\",\"name\":\"Qiuyun Wu\"},{\"authorId\":\"94294263\",\"name\":\"F. Chen\"}],\"doi\":\"10.1109/IJCNN.2019.8851832\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a273df2ac9fc4e796c532feb76f5e676a0773b1c\",\"title\":\"Visual Relationship Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/a273df2ac9fc4e796c532feb76f5e676a0773b1c\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47084642\",\"name\":\"Heng Song\"},{\"authorId\":\"1756644\",\"name\":\"Junwu Zhu\"},{\"authorId\":\"1591599792\",\"name\":\"Y. Jiang\"}],\"doi\":\"10.1016/j.compeleceng.2020.106630\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9835f38f6d3a8b964d53e78fa01e4490169b9169\",\"title\":\"avtmNet: Adaptive Visual-Text Merging Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9835f38f6d3a8b964d53e78fa01e4490169b9169\",\"venue\":\"Comput. Electr. Eng.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2788104\",\"name\":\"Yuting Su\"},{\"authorId\":\"50025928\",\"name\":\"Yuqian Li\"},{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":\"49285626\",\"name\":\"An-An Liu\"}],\"doi\":\"10.1007/s11063-019-09997-5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"65471c0f2a8ee941363ee009e81d450a1b0bbbf9\",\"title\":\"Hierarchical Deep Neural Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/65471c0f2a8ee941363ee009e81d450a1b0bbbf9\",\"venue\":\"Neural Processing Letters\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48569838\",\"name\":\"Xiangyang Li\"},{\"authorId\":\"1696610\",\"name\":\"S. Jiang\"}],\"doi\":\"10.1109/TMM.2019.2896516\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bc73f0f7d895a089416bc8f6090f3f8707c6a12f\",\"title\":\"Know More Say Less: Image Captioning Based on Scene Graphs\",\"url\":\"https://www.semanticscholar.org/paper/bc73f0f7d895a089416bc8f6090f3f8707c6a12f\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2018472\",\"name\":\"I. Yulita\"},{\"authorId\":null,\"name\":\"Shofiyyah Nadhiroh\"}],\"doi\":\"10.4108/eai.12-10-2019.2296544\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f6a16ef87c04849a52f015e4902704e1b9c19c06\",\"title\":\"Breast Cancer Classification: Comparison of Bayesian Networks, Multilayer Perceptron, and Boosting Method\",\"url\":\"https://www.semanticscholar.org/paper/f6a16ef87c04849a52f015e4902704e1b9c19c06\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1805.06956\",\"authors\":[{\"authorId\":\"46246362\",\"name\":\"Ahmad Babaeian Jelodar\"},{\"authorId\":\"10783605\",\"name\":\"Md Sirajus Salekin\"},{\"authorId\":\"71732787\",\"name\":\"Yu Sun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7deb2c6b9814296be9b3a048ebbe387edcaf73a9\",\"title\":\"Identifying Object States in Cooking-Related Images\",\"url\":\"https://www.semanticscholar.org/paper/7deb2c6b9814296be9b3a048ebbe387edcaf73a9\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687503\",\"name\":\"Yanming Guo\"},{\"authorId\":\"47908786\",\"name\":\"Y. Liu\"},{\"authorId\":\"36158244\",\"name\":\"Maaike H. T. de Boer\"},{\"authorId\":\"46457827\",\"name\":\"Li Liu\"},{\"authorId\":\"1731570\",\"name\":\"M. Lew\"}],\"doi\":\"10.1109/ICME.2018.8486491\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d27272027cd84341070fd4b7eb7e03dcb514d93f\",\"title\":\"A Dual Prediction Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/d27272027cd84341070fd4b7eb7e03dcb514d93f\",\"venue\":\"2018 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48387339\",\"name\":\"Xinxin Zhu\"},{\"authorId\":\"1761970\",\"name\":\"L. Li\"},{\"authorId\":\"40478963\",\"name\":\"J. Liu\"},{\"authorId\":\"7475375\",\"name\":\"H. Peng\"},{\"authorId\":\"3712008\",\"name\":\"X. Niu\"}],\"doi\":\"10.3390/APP8050739\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"da958d2604e9f86f94a441d60488d0e93451c248\",\"title\":\"Captioning Transformer with Stacked Attention Modules\",\"url\":\"https://www.semanticscholar.org/paper/da958d2604e9f86f94a441d60488d0e93451c248\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153083913\",\"name\":\"Qianxia Ma\"},{\"authorId\":\"9305183\",\"name\":\"Jing-Yan Song\"},{\"authorId\":\"103245682\",\"name\":\"T. Zhang\"}],\"doi\":\"10.1109/ROBIO49542.2019.8961665\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c062345ed1263ee0c149dcbe75e396532c299c1b\",\"title\":\"Positional Self-attention Based Hierarchical Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/c062345ed1263ee0c149dcbe75e396532c299c1b\",\"venue\":\"2019 IEEE International Conference on Robotics and Biomimetics (ROBIO)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134680082\",\"name\":\"Raimonda Stani\\u016bt\\u0117\"},{\"authorId\":\"1990294\",\"name\":\"D. Sesok\"}],\"doi\":\"10.3390/APP9102024\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"92ccf5a39c63cb5e1639be518e6db2e357acd58e\",\"title\":\"A Systematic Literature Review on Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/92ccf5a39c63cb5e1639be518e6db2e357acd58e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2003304806\",\"name\":\"Mauricio-Andres Zamora-Hernandez\"},{\"authorId\":\"2003285868\",\"name\":\"Jose Andrez Chaves Ceciliano\"},{\"authorId\":\"145399025\",\"name\":\"Alonso Granados\"},{\"authorId\":\"1410269918\",\"name\":\"John Alejandro Castro-Vargas\"},{\"authorId\":\"2031782865\",\"name\":\"Jos\\u00ed Garc\\u00eda Rodr\\u00edguez\"},{\"authorId\":\"1754830\",\"name\":\"J. L\\u00f3pez\"}],\"doi\":\"10.1007/978-3-030-57802-2_76\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ff70b785887b883f965be3fb93a129ec1dd9c238\",\"title\":\"Manufacturing Description Language for Process Control in Industry 4.0\",\"url\":\"https://www.semanticscholar.org/paper/ff70b785887b883f965be3fb93a129ec1dd9c238\",\"venue\":\"SOCO\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1145/3122865\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8e87853672791ed5254a1cfc4b7582e7a41a89d6\",\"title\":\"Frontiers of Multimedia Research\",\"url\":\"https://www.semanticscholar.org/paper/8e87853672791ed5254a1cfc4b7582e7a41a89d6\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143602033\",\"name\":\"Anan Liu\"},{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"144536249\",\"name\":\"W. Nie\"},{\"authorId\":\"2788104\",\"name\":\"Yuting Su\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.24963/ijcai.2018/114\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2b5a95ec7882bf329c4203513e606aa91d4174c5\",\"title\":\"Multi-Level Policy and Reward Reinforcement Learning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/2b5a95ec7882bf329c4203513e606aa91d4174c5\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9515493\",\"name\":\"Liangfu Cao\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"47158869\",\"name\":\"Xing Xu\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1007/978-3-319-68155-9_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"47d76f7c19c53a83704fa8c91d88add93c5654d1\",\"title\":\"Jointly Learning Attentions with Semantic Cross-Modal Correlation for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/47d76f7c19c53a83704fa8c91d88add93c5654d1\",\"venue\":\"ADC\",\"year\":2017},{\"arxivId\":\"1803.04376\",\"authors\":[{\"authorId\":\"3212867\",\"name\":\"R. Luo\"},{\"authorId\":\"31844147\",\"name\":\"Brian L. Price\"},{\"authorId\":\"145823372\",\"name\":\"S. Cohen\"},{\"authorId\":\"2490189\",\"name\":\"Gregory Shakhnarovich\"}],\"doi\":\"10.1109/CVPR.2018.00728\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7c1802d8d43dfe783650a03f03d41609fa5ae91e\",\"title\":\"Discriminability Objective for Training Descriptive Captions\",\"url\":\"https://www.semanticscholar.org/paper/7c1802d8d43dfe783650a03f03d41609fa5ae91e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49420316\",\"name\":\"Yuan Liu\"},{\"authorId\":\"145950948\",\"name\":\"Xue Li\"},{\"authorId\":\"2558130\",\"name\":\"Z. Shi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e8ce74a73bb0b3197d4194fcb638710d76970654\",\"title\":\"Video Captioning with Listwise Supervision\",\"url\":\"https://www.semanticscholar.org/paper/e8ce74a73bb0b3197d4194fcb638710d76970654\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8157255\",\"name\":\"Zhineng Chen\"},{\"authorId\":\"50549803\",\"name\":\"W. Zhang\"},{\"authorId\":\"145424017\",\"name\":\"B. Deng\"},{\"authorId\":\"143994657\",\"name\":\"Hongtao Xie\"},{\"authorId\":\"47019483\",\"name\":\"X. Gu\"}],\"doi\":\"10.1007/s00530-017-0544-y\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1650bbe9d3be679bedff28534db619762bebb8ce\",\"title\":\"Name-face association with web facial image supervision\",\"url\":\"https://www.semanticscholar.org/paper/1650bbe9d3be679bedff28534db619762bebb8ce\",\"venue\":\"Multimedia Systems\",\"year\":2017},{\"arxivId\":\"1803.11439\",\"authors\":[{\"authorId\":\"3179887\",\"name\":\"Xinpeng Chen\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"2093119\",\"name\":\"W. Jiang\"},{\"authorId\":\"144188763\",\"name\":\"Jian Yao\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"}],\"doi\":\"10.1109/CVPR.2018.00834\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"85e2b2c35b916b1ee4926c155065d01b21c80c60\",\"title\":\"Regularizing RNNs for Caption Generation by Reconstructing the Past with the Present\",\"url\":\"https://www.semanticscholar.org/paper/85e2b2c35b916b1ee4926c155065d01b21c80c60\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48394426\",\"name\":\"Naeha Sharif\"},{\"authorId\":\"39689790\",\"name\":\"L. White\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"2210661\",\"name\":\"S. Shah\"}],\"doi\":\"10.1007/978-3-030-01237-3_3\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"fa9189749a4c95c45ec7d98db49e5f736c51760e\",\"title\":\"NNEval: Neural Network Based Evaluation Metric for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/fa9189749a4c95c45ec7d98db49e5f736c51760e\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1810.12535\",\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":\"10.1007/978-3-030-20870-7_2\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"74eda5e2a4a34b9d4a737da755b136455c947339\",\"title\":\"Gated Hierarchical Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/74eda5e2a4a34b9d4a737da755b136455c947339\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11007025\",\"name\":\"Junjiao Tian\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"df40d057b584de2cf74123a2ef4274de582d6b03\",\"title\":\"Detailed Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/df40d057b584de2cf74123a2ef4274de582d6b03\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1908.06954\",\"authors\":[{\"authorId\":\"48544896\",\"name\":\"Lun Huang\"},{\"authorId\":\"46315174\",\"name\":\"Wenmin Wang\"},{\"authorId\":\"40445654\",\"name\":\"J. Chen\"},{\"authorId\":\"144539992\",\"name\":\"Xiao-Yong Wei\"}],\"doi\":\"10.1109/ICCV.2019.00473\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4c163d4942117179d3e97182e1b280027d7d60a9\",\"title\":\"Attention on Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/4c163d4942117179d3e97182e1b280027d7d60a9\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2059218\",\"name\":\"Ankit Khare\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"01fe0c5f0d033141a29f4958f15520798022bbe7\",\"title\":\"ULTRA-CONTEXT: MAXIMIZING THE CONTEXT FOR BETTER IMAGE CAPTION GENERATION\",\"url\":\"https://www.semanticscholar.org/paper/01fe0c5f0d033141a29f4958f15520798022bbe7\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12211701\",\"name\":\"Jianhui Han\"},{\"authorId\":\"2038787\",\"name\":\"H. Liu\"},{\"authorId\":\"152808709\",\"name\":\"M. Wang\"},{\"authorId\":\"1801439\",\"name\":\"Zhaolin Li\"},{\"authorId\":\"7549706\",\"name\":\"Youhui Zhang\"}],\"doi\":\"10.1109/TPDS.2019.2962806\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b3818789b3d64e31a16f55e83f3a00e38e127d59\",\"title\":\"ERA-LSTM: An Efficient ReRAM-Based Architecture for Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/b3818789b3d64e31a16f55e83f3a00e38e127d59\",\"venue\":\"IEEE Transactions on Parallel and Distributed Systems\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50610439\",\"name\":\"Songtao Ding\"},{\"authorId\":\"2641875\",\"name\":\"Shiru Qu\"},{\"authorId\":\"6962569\",\"name\":\"Yuling Xi\"},{\"authorId\":\"3097765\",\"name\":\"A. K. Sangaiah\"},{\"authorId\":\"31197849\",\"name\":\"Shaohua Wan\"}],\"doi\":\"10.1016/J.PATREC.2019.03.021\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"96829c628b8db61c67f3e72dd3f25035bff2d985\",\"title\":\"Image caption generation with high-level image features\",\"url\":\"https://www.semanticscholar.org/paper/96829c628b8db61c67f3e72dd3f25035bff2d985\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19261873\",\"name\":\"Yiwei Wei\"},{\"authorId\":\"2250564\",\"name\":\"Leiquan Wang\"},{\"authorId\":\"51172982\",\"name\":\"Haiwen Cao\"},{\"authorId\":\"134473682\",\"name\":\"Mingwen Shao\"},{\"authorId\":\"46740305\",\"name\":\"Chunlei Wu\"}],\"doi\":\"10.1016/j.neucom.2019.12.073\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"50260b547a481a95a2346759da8dba9366e89348\",\"title\":\"Multi-Attention Generative Adversarial Network for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/50260b547a481a95a2346759da8dba9366e89348\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153083913\",\"name\":\"Qianxia Ma\"},{\"authorId\":\"2034274745\",\"name\":\"Yongfang Nie\"},{\"authorId\":\"2011460\",\"name\":\"J. Song\"},{\"authorId\":\"103245682\",\"name\":\"T. Zhang\"}],\"doi\":\"10.1109/ACCESS.2020.3041447\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"59c7c7076ece69a4552505f9a3615d4a0c70188d\",\"title\":\"Multimodal Data Processing Framework for Smart City: A Positional-Attention Based Deep Learning Approach\",\"url\":\"https://www.semanticscholar.org/paper/59c7c7076ece69a4552505f9a3615d4a0c70188d\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1711.06475\",\"authors\":[{\"authorId\":\"3165417\",\"name\":\"J. Wu\"},{\"authorId\":\"145565491\",\"name\":\"He Zheng\"},{\"authorId\":\"143946810\",\"name\":\"Bo Zhao\"},{\"authorId\":\"47003565\",\"name\":\"Yixin Li\"},{\"authorId\":\"50736086\",\"name\":\"Baoming Yan\"},{\"authorId\":\"143978866\",\"name\":\"R. Liang\"},{\"authorId\":\"46314609\",\"name\":\"Wenjia Wang\"},{\"authorId\":\"14547213\",\"name\":\"Shipei Zhou\"},{\"authorId\":\"33344887\",\"name\":\"Guosen Lin\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"36637369\",\"name\":\"Y. Wang\"},{\"authorId\":\"47904050\",\"name\":\"Y. Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3ff40f0760bd8d3c46d72147b0f5b0d4aee2a24f\",\"title\":\"AI Challenger : A Large-scale Dataset for Going Deeper in Image Understanding\",\"url\":\"https://www.semanticscholar.org/paper/3ff40f0760bd8d3c46d72147b0f5b0d4aee2a24f\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1708.02478\",\"authors\":[{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"8280077\",\"name\":\"Yuyu Guo\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"1720243\",\"name\":\"X. Li\"},{\"authorId\":\"1718099\",\"name\":\"A. Hanjalic\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1109/TNNLS.2018.2851077\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7d78c47093fbf3d85225fd502674aba4a29b3987\",\"title\":\"From Deterministic to Generative: Multimodal Stochastic RNNs for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7d78c47093fbf3d85225fd502674aba4a29b3987\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40974715\",\"name\":\"Bhargav Kanuparthi\"},{\"authorId\":\"2309967\",\"name\":\"D. Arpit\"},{\"authorId\":\"51922896\",\"name\":\"Giancarlo Kerg\"},{\"authorId\":\"145604319\",\"name\":\"Nan Rosemary Ke\"},{\"authorId\":null,\"name\":\"Ioannis Mitliagkas\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1d17baa369d635c817875dbe32b5e5264926a15f\",\"title\":\"WARDS BETTER OPTIMIZATION\",\"url\":\"https://www.semanticscholar.org/paper/1d17baa369d635c817875dbe32b5e5264926a15f\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26982950\",\"name\":\"Longteng Guo\"},{\"authorId\":\"1749850\",\"name\":\"J. Liu\"},{\"authorId\":\"145523338\",\"name\":\"Peng Yao\"},{\"authorId\":\"49298906\",\"name\":\"Jiangwei Li\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1109/CVPR.2019.00433\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4fef1313fd4948fed09dee318e2e231216c4fb3b\",\"title\":\"MSCap: Multi-Style Image Captioning With Unpaired Stylized Text\",\"url\":\"https://www.semanticscholar.org/paper/4fef1313fd4948fed09dee318e2e231216c4fb3b\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"97636424\",\"name\":\"G. Li\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"144303230\",\"name\":\"Ping Liu\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1109/ICCV.2019.00902\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7c4530882cfcef1d2b4aa2996f494dfac626b5d9\",\"title\":\"Entangled Transformer for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7c4530882cfcef1d2b4aa2996f494dfac626b5d9\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s42979-020-00238-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3f732495721356944027051bb14100436a5dbdf5\",\"title\":\"AACR: Feature Fusion Effects of Algebraic Amalgamation Composed Representation on (De)Compositional Network for Caption Generation for Images\",\"url\":\"https://www.semanticscholar.org/paper/3f732495721356944027051bb14100436a5dbdf5\",\"venue\":\"SN Comput. Sci.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49672743\",\"name\":\"C. Li\"},{\"authorId\":\"50763392\",\"name\":\"J. Chen\"},{\"authorId\":\"47718901\",\"name\":\"Weitao Wan\"},{\"authorId\":\"2641581\",\"name\":\"Tianpeng Li\"}],\"doi\":\"10.1007/978-3-319-71607-7_54\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"edc7f610c6dadc2e8c854c0fd9de320457ae942c\",\"title\":\"Combining Object-Based Attention and Attributes for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/edc7f610c6dadc2e8c854c0fd9de320457ae942c\",\"venue\":\"ICIG\",\"year\":2017},{\"arxivId\":\"1810.04020\",\"authors\":[{\"authorId\":\"47412302\",\"name\":\"M. Z. Hossain\"},{\"authorId\":\"2470423\",\"name\":\"Ferdous Sohel\"},{\"authorId\":\"2222847\",\"name\":\"M. F. Shiratuddin\"},{\"authorId\":\"47028380\",\"name\":\"Hamid Laga\"}],\"doi\":\"10.1145/3295748\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"7e27d44e3fac723ccb703e0a83b22711bd42efe8\",\"title\":\"A Comprehensive Survey of Deep Learning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7e27d44e3fac723ccb703e0a83b22711bd42efe8\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47130333\",\"name\":\"Siqi Liu\"},{\"authorId\":\"39815369\",\"name\":\"Z. Zhu\"},{\"authorId\":\"145361612\",\"name\":\"N. Ye\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":\"10.1109/ICCV.2017.100\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"163a474747fd63ab62ae586711fa5e5a2ac91bd8\",\"title\":\"Improved Image Captioning via Policy Gradient optimization of SPIDEr\",\"url\":\"https://www.semanticscholar.org/paper/163a474747fd63ab62ae586711fa5e5a2ac91bd8\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1812.11004\",\"authors\":[{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"1770664\",\"name\":\"X. Li\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1109/TPAMI.2019.2894139\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c0343f9cc5f16166bda83815812c4c71ab3258e3\",\"title\":\"Hierarchical LSTMs with Adaptive Attention for Visual Captioning\",\"url\":\"https://www.semanticscholar.org/paper/c0343f9cc5f16166bda83815812c4c71ab3258e3\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26982950\",\"name\":\"Longteng Guo\"},{\"authorId\":\"46700004\",\"name\":\"J. Liu\"},{\"authorId\":\"116829059\",\"name\":\"Shi-chen Lu\"},{\"authorId\":\"1699900\",\"name\":\"H. Lu\"}],\"doi\":\"10.1109/TMM.2019.2951226\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"837a513a43c7bcce903edbacbfc507cba6451e21\",\"title\":\"Show, Tell, and Polish: Ruminant Decoding for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/837a513a43c7bcce903edbacbfc507cba6451e21\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1804472\",\"name\":\"H. Chen\"},{\"authorId\":\"38329336\",\"name\":\"G. Ding\"},{\"authorId\":\"1818920\",\"name\":\"Zijia Lin\"},{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"}],\"doi\":\"10.24963/ijcai.2018/84\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b4ae889c38444939ae4312ab38bf7036f6df739f\",\"title\":\"Show, Observe and Tell: Attribute-driven Attention Model for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/b4ae889c38444939ae4312ab38bf7036f6df739f\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":\"1810.04101\",\"authors\":[{\"authorId\":\"1809420\",\"name\":\"Loris Bazzani\"},{\"authorId\":\"2120874\",\"name\":\"Tobias Domhan\"},{\"authorId\":\"2521764\",\"name\":\"F. Hieber\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d76c73ab62d960f5417dfa8aff9e63d357c5fd5d\",\"title\":\"Image Captioning as Neural Machine Translation Task in SOCKEYE\",\"url\":\"https://www.semanticscholar.org/paper/d76c73ab62d960f5417dfa8aff9e63d357c5fd5d\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1906.05894\",\"authors\":[{\"authorId\":\"3090299\",\"name\":\"Sungmin Eum\"},{\"authorId\":\"1688527\",\"name\":\"Heesung Kwon\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"13dbe53ebfff320af9fa7d2a346179cd3410f352\",\"title\":\"Semantics to Space(S2S): Embedding semantics into spatial space for zero-shot verb-object query inferencing\",\"url\":\"https://www.semanticscholar.org/paper/13dbe53ebfff320af9fa7d2a346179cd3410f352\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2206630\",\"name\":\"A. Yu\"}],\"doi\":\"10.26153/TSW/5810\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10c442b72cab257b2078be1575577e8b5f22888a\",\"title\":\"Fine-grained visual comparisons\",\"url\":\"https://www.semanticscholar.org/paper/10c442b72cab257b2078be1575577e8b5f22888a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11219408\",\"name\":\"Yuxuan Ding\"},{\"authorId\":\"46314444\",\"name\":\"W. Wang\"},{\"authorId\":\"151118825\",\"name\":\"Mengmeng Jiang\"},{\"authorId\":\"48446599\",\"name\":\"H. Liu\"},{\"authorId\":\"30631999\",\"name\":\"Donghu Deng\"},{\"authorId\":\"145673165\",\"name\":\"Wei Wei\"},{\"authorId\":\"2094026\",\"name\":\"Chunna Tian\"}],\"doi\":\"10.1007/978-3-030-31726-3_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6b1c6af412cc94e5cc5dcc11663b9828307aa21e\",\"title\":\"Jointing Cross-Modality Retrieval to Reweight Attributes for Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/6b1c6af412cc94e5cc5dcc11663b9828307aa21e\",\"venue\":\"PRCV\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"50172036\",\"name\":\"X. Wu\"},{\"authorId\":\"1993634137\",\"name\":\"Shen Ge\"},{\"authorId\":\"47958349\",\"name\":\"X. Zhang\"},{\"authorId\":\"144934703\",\"name\":\"Wei Fan\"},{\"authorId\":\"35325151\",\"name\":\"Yuexian Zou\"}],\"doi\":\"10.1145/3394171.3414004\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0f24a830cdacb07415f335784cd0a7e81eb42f3a\",\"title\":\"Bridging the Gap between Vision and Language Domains for Improved Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0f24a830cdacb07415f335784cd0a7e81eb42f3a\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3158899\",\"name\":\"Mariam Bouchakwa\"},{\"authorId\":\"2135034\",\"name\":\"Yassine Ayadi\"},{\"authorId\":\"1784204\",\"name\":\"I. Amous\"}],\"doi\":\"10.1007/s11042-020-08862-1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"445df9ebc8c43c39faeaa58518383f980fdd0da9\",\"title\":\"A review on visual content-based and users\\u2019 tags-based image annotation: methods and techniques\",\"url\":\"https://www.semanticscholar.org/paper/445df9ebc8c43c39faeaa58518383f980fdd0da9\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"2003.03923\",\"authors\":[{\"authorId\":\"1410097225\",\"name\":\"X. Yang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"50490213\",\"name\":\"Jianfei Cai\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1e420efcd3fbace6f219c812a78d33cb64e25445\",\"title\":\"Deconfounded Image Captioning: A Causal Retrospect\",\"url\":\"https://www.semanticscholar.org/paper/1e420efcd3fbace6f219c812a78d33cb64e25445\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1806.04342\",\"authors\":[{\"authorId\":\"145604319\",\"name\":\"N. Ke\"},{\"authorId\":\"7912420\",\"name\":\"Konrad Zolna\"},{\"authorId\":\"2041695\",\"name\":\"Alessandro Sordoni\"},{\"authorId\":\"3146592\",\"name\":\"Zhouhan Lin\"},{\"authorId\":\"3382568\",\"name\":\"Adam Trischler\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"145134886\",\"name\":\"Joelle Pineau\"},{\"authorId\":\"1778839\",\"name\":\"Laurent Charlin\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8d9b48c0c50e06ccfef722ea6ac88c5000615534\",\"title\":\"Focused Hierarchical RNNs for Conditional Sequence Processing\",\"url\":\"https://www.semanticscholar.org/paper/8d9b48c0c50e06ccfef722ea6ac88c5000615534\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1862138\",\"name\":\"Dmitriy Serdyuk\"},{\"authorId\":\"145604319\",\"name\":\"N. Ke\"},{\"authorId\":\"2041695\",\"name\":\"Alessandro Sordoni\"},{\"authorId\":\"3382568\",\"name\":\"Adam Trischler\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6402703b62325865d00da1f58dbbcaf9a2bc417d\",\"title\":\"Twin Networks: Matching the Future for Sequence Generation\",\"url\":\"https://www.semanticscholar.org/paper/6402703b62325865d00da1f58dbbcaf9a2bc417d\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145293956\",\"name\":\"Zhihao Zhu\"},{\"authorId\":\"14598300\",\"name\":\"Zhan Xue\"},{\"authorId\":\"33762094\",\"name\":\"Zejian Yuan\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"4eb2d13871582ae4d1d744ff1f7945e12880693f\",\"title\":\"Think and Tell: Preview Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/4eb2d13871582ae4d1d744ff1f7945e12880693f\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":\"1903.12020\",\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":\"10.1109/CVPR.2019.00432\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"90579a68e46b772a8e9aaca8ecbd06942d0b9b35\",\"title\":\"Describing Like Humans: On Diversity in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/90579a68e46b772a8e9aaca8ecbd06942d0b9b35\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153804074\",\"name\":\"Heng Quan Liu\"},{\"authorId\":\"2094026\",\"name\":\"Chunna Tian\"},{\"authorId\":\"151118825\",\"name\":\"Mengmeng Jiang\"}],\"doi\":\"10.1117/12.2524235\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"67f717df98ebaa35ac1995f31bc7b678fb8536e0\",\"title\":\"When visual object-context features meet generic and specific semantic priors in image captioning\",\"url\":\"https://www.semanticscholar.org/paper/67f717df98ebaa35ac1995f31bc7b678fb8536e0\",\"venue\":\"International Conference on Graphic and Image Processing\",\"year\":2019},{\"arxivId\":\"1910.06475\",\"authors\":[{\"authorId\":\"152325076\",\"name\":\"H. Ge\"},{\"authorId\":\"79403975\",\"name\":\"Zehang Yan\"},{\"authorId\":\"96280392\",\"name\":\"K. Zhang\"},{\"authorId\":\"145327825\",\"name\":\"Mingde Zhao\"},{\"authorId\":\"46732983\",\"name\":\"Liang Sun\"}],\"doi\":\"10.1109/ICCV.2019.00184\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4b5231149f566fc8a78797b6fb448f9bca416380\",\"title\":\"Exploring Overall Contextual Information for Image Captioning in Human-Like Cognitive Style\",\"url\":\"https://www.semanticscholar.org/paper/4b5231149f566fc8a78797b6fb448f9bca416380\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144081629\",\"name\":\"Mario G\\u00f3mez Mart\\u00ednez\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"faa8314259e9de1af8e841c265b0251531b32e04\",\"title\":\"Deep learning for image captioning: an encoder-decoder architecture with soft attention\",\"url\":\"https://www.semanticscholar.org/paper/faa8314259e9de1af8e841c265b0251531b32e04\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41078388\",\"name\":\"Mark Bugeja\"},{\"authorId\":\"1804046\",\"name\":\"Alexiei Dingli\"},{\"authorId\":\"145221463\",\"name\":\"Maria Attard\"},{\"authorId\":\"1793044\",\"name\":\"Dylan Seychell\"}],\"doi\":\"10.1145/3349622.3355448\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"84e2fbee5cb7b3492d7c1a628bde744f697d330d\",\"title\":\"A Framework for Queryable Video Analysis: A Case-Study on Transport Modelling\",\"url\":\"https://www.semanticscholar.org/paper/84e2fbee5cb7b3492d7c1a628bde744f697d330d\",\"venue\":\"SMAS@MobiCom\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"20630261\",\"name\":\"X. Xiao\"},{\"authorId\":\"40585252\",\"name\":\"L. Wang\"},{\"authorId\":\"33969294\",\"name\":\"K. Ding\"},{\"authorId\":\"1683738\",\"name\":\"S. Xiang\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.1016/J.PATCOG.2019.01.028\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"18cb67e5970c4b1f0949a6f6db8f8cbaa68b2eb1\",\"title\":\"Dense semantic embedding network for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/18cb67e5970c4b1f0949a6f6db8f8cbaa68b2eb1\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"89766800\",\"name\":\"Zhenru Li\"},{\"authorId\":\"121704343\",\"name\":\"Yaoyi Li\"},{\"authorId\":\"37514286\",\"name\":\"H. Lu\"}],\"doi\":\"10.1007/978-3-030-36802-9_11\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c3a3cf7cbd5601d332de35a4c488da75b3a20047\",\"title\":\"Improve Image Captioning by Self-attention\",\"url\":\"https://www.semanticscholar.org/paper/c3a3cf7cbd5601d332de35a4c488da75b3a20047\",\"venue\":\"ICONIP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jing Wang\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"8053308\",\"name\":\"J. Tang\"},{\"authorId\":\"3233021\",\"name\":\"Zechao Li\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b8218640e95bb2d925a617b1c3012eed7d209351\",\"title\":\"Show, Reward and Tell: Automatic Generation of Narrative Paragraph From Photo Stream by Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/b8218640e95bb2d925a617b1c3012eed7d209351\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"2003.09971\",\"authors\":[{\"authorId\":\"3212867\",\"name\":\"R. Luo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b57c9a293934b7434b99807c82d6146634cafa61\",\"title\":\"A Better Variant of Self-Critical Sequence Training\",\"url\":\"https://www.semanticscholar.org/paper/b57c9a293934b7434b99807c82d6146634cafa61\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47968201\",\"name\":\"Lixin Liu\"},{\"authorId\":\"145078589\",\"name\":\"Xiaojun Wan\"},{\"authorId\":\"35310979\",\"name\":\"Zongming Guo\"}],\"doi\":\"10.1145/3240508.3241910\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c064c00fb5aecfb181ef33d430dfc3053f1dc646\",\"title\":\"Images2Poem: Generating Chinese Poetry from Image Streams\",\"url\":\"https://www.semanticscholar.org/paper/c064c00fb5aecfb181ef33d430dfc3053f1dc646\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1910.14208\",\"authors\":[{\"authorId\":\"9095876\",\"name\":\"Jipeng Wu\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"61b1bb801d03a9b0da5721c6beaabf1dc6cd90c0\",\"title\":\"Hidden State Guidance: Improving Image Captioning Using an Image Conditioned Autoencoder\",\"url\":\"https://www.semanticscholar.org/paper/61b1bb801d03a9b0da5721c6beaabf1dc6cd90c0\",\"venue\":\"ViGIL@NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48064309\",\"name\":\"L. Yang\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"},{\"authorId\":\"150311018\",\"name\":\"Songlong Xing\"},{\"authorId\":\"150344317\",\"name\":\"Xinlong Lu\"}],\"doi\":\"10.1145/3386725\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1546133a67bfab09c64a9e2875266b1286ccab55\",\"title\":\"Constrained LSTM and Residual Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/1546133a67bfab09c64a9e2875266b1286ccab55\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2020},{\"arxivId\":\"2008.07935\",\"authors\":[{\"authorId\":\"48269537\",\"name\":\"Ye Zhu\"},{\"authorId\":\"50118837\",\"name\":\"Y. Wu\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"},{\"authorId\":\"96519714\",\"name\":\"Yan Yan\"}],\"doi\":\"10.1007/978-3-030-58592-1_10\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"29ef96b859c2ec55b67fca6f2e59ac27a6bc2cb1\",\"title\":\"Describing Unseen Videos via Multi-Modal Cooperative Dialog Agents\",\"url\":\"https://www.semanticscholar.org/paper/29ef96b859c2ec55b67fca6f2e59ac27a6bc2cb1\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49770170\",\"name\":\"C. Xu\"},{\"authorId\":\"33538504\",\"name\":\"Gengming Zhu\"},{\"authorId\":\"40367854\",\"name\":\"Lixin Wang\"}],\"doi\":\"10.1145/3318299.3318375\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"798f1e5ca775fd0186c82786865859cebba52d84\",\"title\":\"Image Captioning Based on Automatic Constraint Loss\",\"url\":\"https://www.semanticscholar.org/paper/798f1e5ca775fd0186c82786865859cebba52d84\",\"venue\":\"ICMLC '19\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47672526\",\"name\":\"Shiwei Wang\"},{\"authorId\":\"2410125\",\"name\":\"Long Lan\"},{\"authorId\":\"46447554\",\"name\":\"Xiaodong Zhang\"},{\"authorId\":\"48593034\",\"name\":\"Guohua Dong\"},{\"authorId\":\"145254061\",\"name\":\"Z. Luo\"}],\"doi\":\"10.1109/ACCESS.2019.2917979\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"c5a759bbf042fe8852f23567cf14daf3d9f180bc\",\"title\":\"Cascade Semantic Fusion for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/c5a759bbf042fe8852f23567cf14daf3d9f180bc\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39541577\",\"name\":\"Sheng Li\"},{\"authorId\":\"6018169\",\"name\":\"Zhiqiang Tao\"},{\"authorId\":\"104510214\",\"name\":\"K. Li\"},{\"authorId\":\"145692782\",\"name\":\"Yun Fu\"}],\"doi\":\"10.1109/TETCI.2019.2892755\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"125b0bde4ac0b4cb9453b205bc0c5c184af3dec2\",\"title\":\"Visual to Text: Survey of Image and Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/125b0bde4ac0b4cb9453b205bc0c5c184af3dec2\",\"venue\":\"IEEE Transactions on Emerging Topics in Computational Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35458817\",\"name\":\"Sudan Jha\"},{\"authorId\":\"143699471\",\"name\":\"Anirban Dey\"},{\"authorId\":\"145835018\",\"name\":\"R. Kumar\"},{\"authorId\":\"2245174\",\"name\":\"Vijender Kumar Solanki\"}],\"doi\":\"10.9781/IJIMAI.2018.08.004\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a47093ac41db735b837e6b9e8f3cccdfc46e20f3\",\"title\":\"A Novel Approach on Visual Question Answering by Parameter Prediction using Faster Region Based Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/a47093ac41db735b837e6b9e8f3cccdfc46e20f3\",\"venue\":\"Int. J. Interact. Multim. Artif. Intell.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145840350\",\"name\":\"P. Anderson\"}],\"doi\":\"10.25911/5D00D4EC451CC\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c2ce1912727a3e8c88b4af65c9ca088b3c8eb1a0\",\"title\":\"Vision and Language Learning: From Image Captioning and Visual Question Answering towards Embodied Agents\",\"url\":\"https://www.semanticscholar.org/paper/c2ce1912727a3e8c88b4af65c9ca088b3c8eb1a0\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2002.12585\",\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"19169659\",\"name\":\"Xuancheng Ren\"},{\"authorId\":\"7896029\",\"name\":\"Yuanxin Liu\"},{\"authorId\":\"145558281\",\"name\":\"Kai Lei\"},{\"authorId\":\"48305273\",\"name\":\"Xu Sun\"}],\"doi\":\"10.24963/ijcai.2019/708\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b23622ba3eef8a82036710271c6c35bd8a49ce8f\",\"title\":\"Exploring and Distilling Cross-Modal Information for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/b23622ba3eef8a82036710271c6c35bd8a49ce8f\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"153152064\",\"name\":\"A. Liu\"},{\"authorId\":\"153576783\",\"name\":\"Weizhi Nie\"},{\"authorId\":\"2788104\",\"name\":\"Yuting Su\"},{\"authorId\":\"48693981\",\"name\":\"J. Nie\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.1109/TMM.2019.2941820\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aff890f20d28a13b9fb89d192fad35d92381c410\",\"title\":\"Multi-Level Policy and Reward-Based Deep Reinforcement Learning Framework for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/aff890f20d28a13b9fb89d192fad35d92381c410\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34739384\",\"name\":\"Jinsong Su\"},{\"authorId\":\"150164718\",\"name\":\"Jialong Tang\"},{\"authorId\":null,\"name\":\"Ziyao Lu\"},{\"authorId\":\"3194601\",\"name\":\"Xianpei Han\"},{\"authorId\":\"2999092\",\"name\":\"H. Zhang\"}],\"doi\":\"10.1016/J.NEUCOM.2019.08.012\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2fb096118ebbe6615afe98c733c80f55bb40d2cf\",\"title\":\"A neural image captioning model with caption-to-images semantic constructor\",\"url\":\"https://www.semanticscholar.org/paper/2fb096118ebbe6615afe98c733c80f55bb40d2cf\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"1810.09630\",\"authors\":[{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"345a222fef6f5c1415056319ae7e87a369940d3f\",\"title\":\"A Neural Compositional Paradigm for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/345a222fef6f5c1415056319ae7e87a369940d3f\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3491491\",\"name\":\"Shiyang Yan\"},{\"authorId\":\"1410066063\",\"name\":\"Yuan Xie\"},{\"authorId\":\"152345893\",\"name\":\"F. Wu\"},{\"authorId\":\"33830793\",\"name\":\"J. Smith\"},{\"authorId\":\"40178769\",\"name\":\"Wenjin Lu\"},{\"authorId\":\"46824190\",\"name\":\"B. Zhang\"}],\"doi\":\"10.1016/j.sigpro.2019.107329\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ea53299a067694a24e5e9cf8e852e122d5918847\",\"title\":\"Image captioning via hierarchical attention mechanism and policy gradient optimization\",\"url\":\"https://www.semanticscholar.org/paper/ea53299a067694a24e5e9cf8e852e122d5918847\",\"venue\":\"Signal Process.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38314306\",\"name\":\"Rakshith Shetty\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1109/ICCV.2017.398\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"7fac20f3908c69bd336ea252e28c79f5abaa6dbe\",\"title\":\"Speaking the Same Language: Matching Machine to Human Captions by Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/7fac20f3908c69bd336ea252e28c79f5abaa6dbe\",\"venue\":\"ICCV 2017\",\"year\":2017},{\"arxivId\":\"1803.07950\",\"authors\":[{\"authorId\":\"4322411\",\"name\":\"L. Li\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"}],\"doi\":\"10.1109/WACV.2019.00042\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"abcf7dd1e35575eaac12332aa4bc7575ccdd6965\",\"title\":\"End-to-End Video Captioning With Multitask Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/abcf7dd1e35575eaac12332aa4bc7575ccdd6965\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":\"1803.08314\",\"authors\":[{\"authorId\":\"46522599\",\"name\":\"Xihui Liu\"},{\"authorId\":\"49404547\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"144478188\",\"name\":\"J. Shao\"},{\"authorId\":\"143982372\",\"name\":\"Dapeng Chen\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1007/978-3-030-01267-0_21\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"caab1c1d53718315f54bc4df42eb9a727fa18483\",\"title\":\"Show, Tell and Discriminate: Image Captioning by Self-retrieval with Partially Labeled Data\",\"url\":\"https://www.semanticscholar.org/paper/caab1c1d53718315f54bc4df42eb9a727fa18483\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134518946\",\"name\":\"Nanxing Li\"},{\"authorId\":\"50678073\",\"name\":\"Bei Liu\"},{\"authorId\":\"2904100\",\"name\":\"Z. Han\"},{\"authorId\":\"46399275\",\"name\":\"Yu-Shen Liu\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"}],\"doi\":\"10.1145/3323873.3325050\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"426ce52b0c4ac73e6226c532d4d8a2171f12e9fb\",\"title\":\"Emotion Reinforced Visual Storytelling\",\"url\":\"https://www.semanticscholar.org/paper/426ce52b0c4ac73e6226c532d4d8a2171f12e9fb\",\"venue\":\"ICMR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48283024\",\"name\":\"Xinghan Chen\"},{\"authorId\":\"145179162\",\"name\":\"Mingxing Zhang\"},{\"authorId\":\"48708844\",\"name\":\"Zheng Wang\"},{\"authorId\":\"144898145\",\"name\":\"Lin Zuo\"},{\"authorId\":\"92160187\",\"name\":\"Bo Li\"},{\"authorId\":\"46173234\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1016/J.PATREC.2018.12.018\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a74042d5da6eecf8929008f95c3becf4218a3cce\",\"title\":\"Leveraging unpaired out-of-domain data for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/a74042d5da6eecf8929008f95c3becf4218a3cce\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2020},{\"arxivId\":\"2009.14405\",\"authors\":[{\"authorId\":\"2458059\",\"name\":\"Y. Huang\"},{\"authorId\":\"47739902\",\"name\":\"J. Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6caaf71d18f093aebd0cffdcf246b86400092ab5\",\"title\":\"Teacher-Critical Training Strategies for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6caaf71d18f093aebd0cffdcf246b86400092ab5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1805.08170\",\"authors\":[{\"authorId\":\"1788124\",\"name\":\"Qiuyuan Huang\"},{\"authorId\":\"9325940\",\"name\":\"Pengchuan Zhang\"},{\"authorId\":\"144953174\",\"name\":\"Dapeng Wu\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a484b7eda0e5389ae62ab1549f27594050a60f71\",\"title\":\"Turbo Learning for Captionbot and Drawingbot\",\"url\":\"https://www.semanticscholar.org/paper/a484b7eda0e5389ae62ab1549f27594050a60f71\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51288875\",\"name\":\"Y. Zhou\"},{\"authorId\":\"49941674\",\"name\":\"Zhenzhen Hu\"},{\"authorId\":\"2896799\",\"name\":\"Ye Zhao\"},{\"authorId\":\"3076466\",\"name\":\"X. Liu\"},{\"authorId\":\"48043335\",\"name\":\"R. Hong\"}],\"doi\":\"10.1109/BigMM.2018.8499172\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"96418bb981ac738468340c7836a8362fa08cc1f2\",\"title\":\"Enhanced Text-Guided Attention Model for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/96418bb981ac738468340c7836a8362fa08cc1f2\",\"venue\":\"2018 IEEE Fourth International Conference on Multimedia Big Data (BigMM)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"113001756\",\"name\":\"A. Deshpande\"},{\"authorId\":\"29956361\",\"name\":\"Jyoti Aneja\"},{\"authorId\":\"24952249\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"144016256\",\"name\":\"D. Forsyth\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b2c60061ad32e28eb1e20aff42e062c9160786be\",\"title\":\"Diverse and Controllable Image Captioning with Part-of-Speech Guidance\",\"url\":\"https://www.semanticscholar.org/paper/b2c60061ad32e28eb1e20aff42e062c9160786be\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3428883\",\"name\":\"Zhengxia Gao\"},{\"authorId\":\"3335651\",\"name\":\"Aiwen Jiang\"},{\"authorId\":\"33876479\",\"name\":\"Jianyi Wan\"}],\"doi\":\"10.1117/12.2502901\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2f7b31b06ebdc65a295dff62bae960d5458def3c\",\"title\":\"Explore fine-grained discriminative visual explanation when making classification decision\",\"url\":\"https://www.semanticscholar.org/paper/2f7b31b06ebdc65a295dff62bae960d5458def3c\",\"venue\":\"International Conference on Digital Image Processing\",\"year\":2018},{\"arxivId\":\"1909.03169\",\"authors\":[{\"authorId\":\"32095408\",\"name\":\"Fawaz Sammani\"},{\"authorId\":\"67001969\",\"name\":\"Mahmoud Elsayed\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7af5c94fedc32f3104a08301a46c62f51b044a81\",\"title\":\"Look and Modify: Modification Networks for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7af5c94fedc32f3104a08301a46c62f51b044a81\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143692915\",\"name\":\"Ying Hua Tan\"},{\"authorId\":\"2863960\",\"name\":\"Chee Seng Chan\"}],\"doi\":\"10.1016/j.neucom.2018.12.026\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"760a7ed58cf49fa5dbcfb7f06b67cea2cd35f768\",\"title\":\"Phrase-based image caption generator with hierarchical LSTM network\",\"url\":\"https://www.semanticscholar.org/paper/760a7ed58cf49fa5dbcfb7f06b67cea2cd35f768\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"1907.03240\",\"authors\":[{\"authorId\":\"38921864\",\"name\":\"J. Li\"},{\"authorId\":\"21184593\",\"name\":\"Haizhou Shi\"},{\"authorId\":\"1774936\",\"name\":\"Siliang Tang\"},{\"authorId\":\"32996440\",\"name\":\"F. Wu\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1145/3343031.3350918\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1b2bb2ce93f2a48f998b6ca1e4364e8f2707e3e6\",\"title\":\"Informative Visual Storytelling with Cross-modal Rules\",\"url\":\"https://www.semanticscholar.org/paper/1b2bb2ce93f2a48f998b6ca1e4364e8f2707e3e6\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"2012.13122\",\"authors\":[{\"authorId\":\"48394426\",\"name\":\"Naeha Sharif\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"40366581\",\"name\":\"Wei Liu\"},{\"authorId\":\"14752125\",\"name\":\"Syed Afaq Ali Shah\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5318abd4f12a5b25c2847e9c66713951341af504\",\"title\":\"SubICap: Towards Subword-informed Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/5318abd4f12a5b25c2847e9c66713951341af504\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152281902\",\"name\":\"S. Wu\"},{\"authorId\":\"2087470\",\"name\":\"S. Fan\"},{\"authorId\":\"1700911\",\"name\":\"Zhiqi Shen\"},{\"authorId\":\"145977143\",\"name\":\"Mohan S. Kankanhalli\"},{\"authorId\":\"1699730\",\"name\":\"Anthony K. H. Tung\"}],\"doi\":\"10.1145/3394171.3413589\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"35ba6ed07ef68db187674498e684de7f3e160716\",\"title\":\"Who You Are Decides How You Tell\",\"url\":\"https://www.semanticscholar.org/paper/35ba6ed07ef68db187674498e684de7f3e160716\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1909.09060\",\"authors\":[{\"authorId\":\"48544896\",\"name\":\"Lun Huang\"},{\"authorId\":\"1788029\",\"name\":\"W. Wang\"},{\"authorId\":\"49289638\",\"name\":\"Y. Xia\"},{\"authorId\":\"40445654\",\"name\":\"J. Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"312799645adfafb886f156708a7a36f2db459c62\",\"title\":\"Adaptively Aligned Image Captioning via Adaptive Attention Time\",\"url\":\"https://www.semanticscholar.org/paper/312799645adfafb886f156708a7a36f2db459c62\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92057141\",\"name\":\"H. Wei\"},{\"authorId\":\"49969428\",\"name\":\"Z. Li\"},{\"authorId\":\"104269832\",\"name\":\"Canlong Zhang\"},{\"authorId\":\"144137447\",\"name\":\"Tao Zhou\"},{\"authorId\":\"1391051492\",\"name\":\"Y. Quan\"}],\"doi\":\"10.1109/IJCNN.2019.8852118\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f76cf186f93a0f5b3f57a8d0a1545e5b626e664e\",\"title\":\"Image Captioning Based On Sentence-Level And Word-Level Attention\",\"url\":\"https://www.semanticscholar.org/paper/f76cf186f93a0f5b3f57a8d0a1545e5b626e664e\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48195668\",\"name\":\"Jin Yuan\"},{\"authorId\":\"47059067\",\"name\":\"L. Zhang\"},{\"authorId\":\"2836997\",\"name\":\"Songrui Guo\"},{\"authorId\":\"1406190317\",\"name\":\"Y. Xiao\"},{\"authorId\":\"152985786\",\"name\":\"Z. Li\"}],\"doi\":\"10.1145/3394955\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2f977b1d34ad883483727a3c8c52e20b260ac0ad\",\"title\":\"Image Captioning with a Joint Attention Mechanism by Visual Concept Samples\",\"url\":\"https://www.semanticscholar.org/paper/2f977b1d34ad883483727a3c8c52e20b260ac0ad\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2020},{\"arxivId\":\"1809.07041\",\"authors\":[{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1007/978-3-030-01264-9_42\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"0000fcfd467a19cf0e59169c2f07d730a0f3a8b9\",\"title\":\"Exploring Visual Relationship for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0000fcfd467a19cf0e59169c2f07d730a0f3a8b9\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2002.06701\",\"authors\":[{\"authorId\":\"151430668\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"19b00a2bd1624a0931069a539a971e40b65bfb3a\",\"title\":\"Gaussian Smoothen Semantic Features (GSSF) - Exploring the Linguistic Aspects of Visual Captioning in Indian Languages (Bengali) Using MSCOCO Framework\",\"url\":\"https://www.semanticscholar.org/paper/19b00a2bd1624a0931069a539a971e40b65bfb3a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.10115\",\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"50c6889b547cc08a203842d5cf5bcb4c58e052b5\",\"title\":\"TPsgtR: Neural-Symbolic Tensor Product Scene-Graph-Triplet Representation for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/50c6889b547cc08a203842d5cf5bcb4c58e052b5\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2011.00927\",\"authors\":[{\"authorId\":\"2000125058\",\"name\":\"Feicheng Huang\"},{\"authorId\":\"144111674\",\"name\":\"Zhixin Li\"},{\"authorId\":\"92057141\",\"name\":\"H. Wei\"},{\"authorId\":\"104269832\",\"name\":\"Canlong Zhang\"},{\"authorId\":\"1998838209\",\"name\":\"Huifang Ma\"}],\"doi\":\"10.1007/s10994-020-05919-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"899b365ce70207f1fd456e982583841d9e4701bf\",\"title\":\"Boost Image Captioning with Knowledge Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/899b365ce70207f1fd456e982583841d9e4701bf\",\"venue\":\"Mach. Learn.\",\"year\":2020},{\"arxivId\":\"1911.10132\",\"authors\":[{\"authorId\":\"151430668\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s11042-020-09865-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c8f8ea39c64cf08792cd49c6ad04e85e3b90c88f\",\"title\":\"CRUR: Coupled-Recurrent Unit for Unification, Conceptualization and Context Capture for Language Representation - A Generalization of Bi Directional LSTM\",\"url\":\"https://www.semanticscholar.org/paper/c8f8ea39c64cf08792cd49c6ad04e85e3b90c88f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2042707165\",\"name\":\"Anfal Attai\"},{\"authorId\":\"145973534\",\"name\":\"Ashraf Elnagar\"}],\"doi\":\"10.1109/IIT50501.2020.9299027\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"002544729825daf6843a471ccb22d446969511b7\",\"title\":\"A survey on Arabic Image Captioning Systems Using Deep Learning Models\",\"url\":\"https://www.semanticscholar.org/paper/002544729825daf6843a471ccb22d446969511b7\",\"venue\":\"2020 14th International Conference on Innovations in Information Technology (IIT)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47196880\",\"name\":\"Ziwei Wang\"},{\"authorId\":\"145622169\",\"name\":\"Zi Huang\"},{\"authorId\":\"150350159\",\"name\":\"Yadan Luo\"}],\"doi\":\"10.1007/978-3-030-39469-1_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7fb87759fff098cbb487d74404ce8ca1098253a1\",\"title\":\"PAIC: Parallelised Attentive Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7fb87759fff098cbb487d74404ce8ca1098253a1\",\"venue\":\"ADC\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2000125058\",\"name\":\"Feicheng Huang\"},{\"authorId\":\"49969428\",\"name\":\"Z. Li\"},{\"authorId\":\"1856671082\",\"name\":\"Shengjia Chen\"},{\"authorId\":\"104269832\",\"name\":\"Canlong Zhang\"},{\"authorId\":\"1998838209\",\"name\":\"Huifang Ma\"}],\"doi\":\"10.1145/3340531.3411948\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3428bac9141f6db961fc4665db1cbc9a196152da\",\"title\":\"Image Captioning with Internal and External Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/3428bac9141f6db961fc4665db1cbc9a196152da\",\"venue\":\"CIKM\",\"year\":2020},{\"arxivId\":\"1804.08274\",\"authors\":[{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"47636228\",\"name\":\"H. Chao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2018.00782\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"19d7f83c3d7147f0eed1e1471438066eb4fe51fb\",\"title\":\"Jointly Localizing and Describing Events for Dense Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/19d7f83c3d7147f0eed1e1471438066eb4fe51fb\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1810.03023\",\"authors\":[{\"authorId\":\"2309967\",\"name\":\"D. Arpit\"},{\"authorId\":\"40974715\",\"name\":\"Bhargav Kanuparthi\"},{\"authorId\":\"51922896\",\"name\":\"Giancarlo Kerg\"},{\"authorId\":\"145604319\",\"name\":\"N. Ke\"},{\"authorId\":\"3168518\",\"name\":\"Ioannis Mitliagkas\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5f44f56c754cbd5e99e26d7fcad9d83d67d97cf1\",\"title\":\"h-detach: Modifying the LSTM Gradient Towards Better Optimization\",\"url\":\"https://www.semanticscholar.org/paper/5f44f56c754cbd5e99e26d7fcad9d83d67d97cf1\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36595248\",\"name\":\"Fang Fang\"},{\"authorId\":\"8194130\",\"name\":\"Qinyu Li\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"8275214\",\"name\":\"P. Tang\"}],\"doi\":\"10.1109/ICME.2018.8486437\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e0f0076476fc81a344b8bdec771802a8584dd10f\",\"title\":\"Refining Attention: A Sequential Attention Model for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/e0f0076476fc81a344b8bdec771802a8584dd10f\",\"venue\":\"2018 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144841441\",\"name\":\"J. Xu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1145/3123266.3123448\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ff172624dd0a3bd31ca925b73cd7295d596173e2\",\"title\":\"Learning Multimodal Attention LSTM Networks for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/ff172624dd0a3bd31ca925b73cd7295d596173e2\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"1706673\",\"name\":\"C. Zhang\"}],\"doi\":\"10.1145/3123266.3130141\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dac85b9bc9313e1d6ed01234b6d3e4bdbcd47999\",\"title\":\"Deep Learning for Intelligent Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/dac85b9bc9313e1d6ed01234b6d3e4bdbcd47999\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1564563694\",\"name\":\"Harshitha Katpally\"},{\"authorId\":\"1477947756\",\"name\":\"Ajay Bansal\"}],\"doi\":\"10.1109/ICSC.2020.00016\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5c0c24a4b19e97ea92b716b28efd31de4cc38c4e\",\"title\":\"Ensemble Learning on Deep Neural Networks for Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/5c0c24a4b19e97ea92b716b28efd31de4cc38c4e\",\"venue\":\"2020 IEEE 14th International Conference on Semantic Computing (ICSC)\",\"year\":2020},{\"arxivId\":\"1804.08281\",\"authors\":[{\"authorId\":\"48141156\",\"name\":\"Qi Cai\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"7590116\",\"name\":\"C. Yan\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2018.00429\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"78e41d3eb2acd47083a4ec4765ad443617a109ef\",\"title\":\"Memory Matching Networks for One-Shot Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/78e41d3eb2acd47083a4ec4765ad443617a109ef\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1788124\",\"name\":\"Qiuyuan Huang\"},{\"authorId\":\"1748557\",\"name\":\"P. Smolensky\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"144953174\",\"name\":\"Dapeng Wu\"}],\"doi\":\"10.18653/v1/N18-1114\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f2df65bc38690ec56c4fe24380f9993ba2904e9c\",\"title\":\"Tensor Product Generation Networks for Deep NLP Modeling\",\"url\":\"https://www.semanticscholar.org/paper/f2df65bc38690ec56c4fe24380f9993ba2904e9c\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":\"1808.08732\",\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"19169659\",\"name\":\"Xuancheng Ren\"},{\"authorId\":\"7896029\",\"name\":\"Yuanxin Liu\"},{\"authorId\":\"1781885\",\"name\":\"Houfeng Wang\"},{\"authorId\":\"2511091\",\"name\":\"X. Sun\"}],\"doi\":\"10.18653/v1/D18-1013\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8968072ad12bcb96c513ae1c01abf6abdae810df\",\"title\":\"simNet: Stepwise Image-Topic Merging Network for Generating Detailed and Comprehensive Image Captions\",\"url\":\"https://www.semanticscholar.org/paper/8968072ad12bcb96c513ae1c01abf6abdae810df\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"1811.07212\",\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"143953573\",\"name\":\"K. Shih\"},{\"authorId\":\"121704643\",\"name\":\"Yichen Li\"},{\"authorId\":\"145031845\",\"name\":\"Ke Xu\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/TPAMI.2020.3029008\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0e0fbead3da9e16b03894b63efc6816fa3ef6d0e\",\"title\":\"Revisiting Image-Language Networks for Open-ended Phrase Detection.\",\"url\":\"https://www.semanticscholar.org/paper/0e0fbead3da9e16b03894b63efc6816fa3ef6d0e\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"1802.00176\",\"authors\":[{\"authorId\":\"2033687\",\"name\":\"Xuemei Xie\"},{\"authorId\":\"144310853\",\"name\":\"Jiang Du\"},{\"authorId\":\"35367337\",\"name\":\"Guangming Shi\"},{\"authorId\":\"145872985\",\"name\":\"Chenye Wang\"},{\"authorId\":\"153030385\",\"name\":\"X. Xu\"}],\"doi\":\"10.1007/978-3-030-03338-5_23\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a45885b29e4d2efaf75759131fb8bb524cffbd94\",\"title\":\"Perceptual Compressive Sensing\",\"url\":\"https://www.semanticscholar.org/paper/a45885b29e4d2efaf75759131fb8bb524cffbd94\",\"venue\":\"PRCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2123563\",\"name\":\"Shihao Wang\"},{\"authorId\":\"81983870\",\"name\":\"Hong Mo\"},{\"authorId\":\"1749615\",\"name\":\"Yue Xu\"},{\"authorId\":\"145717893\",\"name\":\"W. Wu\"},{\"authorId\":\"144812501\",\"name\":\"Zhong Zhou\"}],\"doi\":\"10.1007/978-3-030-00764-5_20\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"51c48633735a10c2e509374ba7fad8e267f322e1\",\"title\":\"Intra-Image Region Context for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/51c48633735a10c2e509374ba7fad8e267f322e1\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":\"1711.09151\",\"authors\":[{\"authorId\":\"29956361\",\"name\":\"Jyoti Aneja\"},{\"authorId\":\"113001756\",\"name\":\"A. Deshpande\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1109/CVPR.2018.00583\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9fb5e3db385588f671b11cfc8bf18efb90ee7b19\",\"title\":\"Convolutional Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9fb5e3db385588f671b11cfc8bf18efb90ee7b19\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1911.10082\",\"authors\":[{\"authorId\":\"52150251\",\"name\":\"A. Goel\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"103192742\",\"name\":\"T. Nguyen\"},{\"authorId\":\"2518212\",\"name\":\"Hakan Bilen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e4dcd3fa308b263cee8c7581e2d695dc15c2f51f\",\"title\":\"Injecting Prior Knowledge into Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/e4dcd3fa308b263cee8c7581e2d695dc15c2f51f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48394426\",\"name\":\"Naeha Sharif\"},{\"authorId\":\"39689790\",\"name\":\"L. White\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"2210661\",\"name\":\"S. Shah\"}],\"doi\":\"10.18653/v1/P18-3003\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"954a39752ca5ebc19eb7563c28a5773f70bff452\",\"title\":\"Learning-based Composite Metrics for Improved Caption Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/954a39752ca5ebc19eb7563c28a5773f70bff452\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":\"1707.07998\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"31790073\",\"name\":\"C. Buehler\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":\"10.1109/CVPR.2018.00636\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"title\":\"Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1906.02365\",\"authors\":[{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"48929163\",\"name\":\"Daqing Liu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"},{\"authorId\":\"144864336\",\"name\":\"F. Wu\"}],\"doi\":\"10.1109/TPAMI.2019.2909864\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d0134f63879cedf3cdfe795bd2fd7c48d9554e4a\",\"title\":\"Context-Aware Visual Policy Network for Fine-Grained Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/d0134f63879cedf3cdfe795bd2fd7c48d9554e4a\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2019},{\"arxivId\":\"1906.07016\",\"authors\":[{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"46515076\",\"name\":\"D. Li\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"48141156\",\"name\":\"Qi Cai\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"38791e8ca76e1bb44e7123ec92f97299d7d19d15\",\"title\":\"Trimmed Action Recognition, Dense-Captioning Events in Videos, and Spatio-temporal Action Localization with Focus on ActivityNet Challenge 2019\",\"url\":\"https://www.semanticscholar.org/paper/38791e8ca76e1bb44e7123ec92f97299d7d19d15\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98482977\",\"name\":\"\\u0411\\u043e\\u0440\\u0438\\u0441\\u043e\\u0432 \\u0413\\u0435\\u043e\\u0440\\u0433\\u0438\\u0439 \\u0410\\u043b\\u0435\\u043a\\u0441\\u0430\\u043d\\u0434\\u0440\\u043e\\u0432\\u0438\\u0447\"},{\"authorId\":\"97625681\",\"name\":\"\\u0422\\u0438\\u0445\\u043e\\u043c\\u0438\\u0440\\u043e\\u0432\\u0430 \\u0422\\u0430\\u043c\\u0430\\u0440\\u0430 \\u041f\\u0435\\u0442\\u0440\\u043e\\u0432\\u043d\\u0430\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0de0cec214cf34d089a9fce9015256b63534cd08\",\"title\":\"\\u0417\\u0430\\u0434\\u0430\\u0447\\u0438 \\u0438 \\u043c\\u0435\\u0442\\u043e\\u0434\\u044b \\u0440\\u0435\\u0441\\u0443\\u0440\\u0441\\u043e\\u0441\\u0431\\u0435\\u0440\\u0435\\u0433\\u0430\\u044e\\u0449\\u0435\\u0439 \\u043e\\u043f\\u0442\\u0438\\u043c\\u0438\\u0437\\u0430\\u0446\\u0438\\u0438 \\u0432 \\u044d\\u043b\\u0435\\u043a\\u0442\\u0440\\u043e\\u044d\\u043d\\u0435\\u0440\\u0433\\u0435\\u0442\\u0438\\u0447\\u0435\\u0441\\u043a\\u043e\\u0439 \\u0441\\u0438\\u0441\\u0442\\u0435\\u043c\\u0435\",\"url\":\"https://www.semanticscholar.org/paper/0de0cec214cf34d089a9fce9015256b63534cd08\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1908.00249\",\"authors\":[{\"authorId\":\"144005516\",\"name\":\"Jing Wang\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"8053308\",\"name\":\"J. Tang\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.24963/ijcai.2019/132\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0b8f0e00f953ae51a7ea72ba51c699bb959cc948\",\"title\":\"Convolutional Auto-encoding of Sentence Topics for Image Paragraph Generation\",\"url\":\"https://www.semanticscholar.org/paper/0b8f0e00f953ae51a7ea72ba51c699bb959cc948\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"1905.08843\",\"authors\":[{\"authorId\":\"46246362\",\"name\":\"Ahmad Babaeian Jelodar\"},{\"authorId\":\"144825833\",\"name\":\"Yu Sun\"}],\"doi\":\"10.1109/ICIP.2019.8803530\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0e9f082d0ca6d670325c5623563e8e8fa47547ae\",\"title\":\"Joint Object and State Recognition Using Language Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/0e9f082d0ca6d670325c5623563e8e8fa47547ae\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"1902.00313\",\"authors\":[{\"authorId\":\"32701193\",\"name\":\"Yuanzhi Liang\"},{\"authorId\":\"2643877\",\"name\":\"Y. Bai\"},{\"authorId\":null,\"name\":\"Wei Zhang\"},{\"authorId\":\"6468417\",\"name\":\"Xueming Qian\"},{\"authorId\":\"4096586\",\"name\":\"L. Zhu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ab88c48e7829029c47ac6deea5c0ccbff3614c5c\",\"title\":\"Rethinking Visual Relationships for High-level Image Understanding\",\"url\":\"https://www.semanticscholar.org/paper/ab88c48e7829029c47ac6deea5c0ccbff3614c5c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2007.00222\",\"authors\":[{\"authorId\":\"67318326\",\"name\":\"Y. Koizumi\"},{\"authorId\":\"1423768681\",\"name\":\"Ryo Masumura\"},{\"authorId\":\"2963420\",\"name\":\"Kyosuke Nishida\"},{\"authorId\":\"50131290\",\"name\":\"M. Yasuda\"},{\"authorId\":\"2880610\",\"name\":\"S. Saito\"}],\"doi\":\"10.21437/interspeech.2020-2087\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cd1b307eff4e0a72e8c975e90bea6ec6be286718\",\"title\":\"A Transformer-based Audio Captioning Model with Keyword Estimation\",\"url\":\"https://www.semanticscholar.org/paper/cd1b307eff4e0a72e8c975e90bea6ec6be286718\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s13735-020-00198-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8c85757cdd7de5f99ab1717a6355a09bb717013c\",\"title\":\"MRECN: mixed representation enhanced (de)compositional network for caption generation from visual features, modeling as pseudo tensor product representation\",\"url\":\"https://www.semanticscholar.org/paper/8c85757cdd7de5f99ab1717a6355a09bb717013c\",\"venue\":\"Int. J. Multim. Inf. Retr.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50610439\",\"name\":\"Songtao Ding\"},{\"authorId\":\"2641875\",\"name\":\"Shiru Qu\"},{\"authorId\":\"6962569\",\"name\":\"Yuling Xi\"},{\"authorId\":\"49725227\",\"name\":\"Shaohua Wan\"}],\"doi\":\"10.1016/J.NEUCOM.2019.04.095\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"088d11c03ac72c6d2a85dea758b283a09d4e519f\",\"title\":\"Stimulus-driven and concept-driven analysis for image caption generation\",\"url\":\"https://www.semanticscholar.org/paper/088d11c03ac72c6d2a85dea758b283a09d4e519f\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"1770664\",\"name\":\"X. Li\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e060c24c57930007d9496edc6847ed78ef1b0ddd\",\"title\":\"Image Input OR Video Hierarchical LSTMs with Adaptive Attention ( hLSTMat ) Feature Extraction Generated Captions Losses\",\"url\":\"https://www.semanticscholar.org/paper/e060c24c57930007d9496edc6847ed78ef1b0ddd\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"113519586\",\"name\":\"T. X. Dang\"},{\"authorId\":\"31704596\",\"name\":\"A. Oh\"},{\"authorId\":\"9483271\",\"name\":\"In-Seop Na\"},{\"authorId\":\"2183069\",\"name\":\"S. Kim\"}],\"doi\":\"10.1145/3310986.3311002\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eeb782dcf29651caca5a2bcb6019b54c3ddee1a0\",\"title\":\"The Role of Attention Mechanism and Multi-Feature in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/eeb782dcf29651caca5a2bcb6019b54c3ddee1a0\",\"venue\":\"ICMLSC 2019\",\"year\":2019},{\"arxivId\":\"1908.02632\",\"authors\":[{\"authorId\":\"151482698\",\"name\":\"Chen Shen\"},{\"authorId\":\"145592288\",\"name\":\"Rongrong Ji\"},{\"authorId\":\"2642638\",\"name\":\"Fuhai Chen\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"48569526\",\"name\":\"Xiangming Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c7f60b69ccafc9fb1aabc0aaac9942d68d9166cf\",\"title\":\"Scene-based Factored Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/c7f60b69ccafc9fb1aabc0aaac9942d68d9166cf\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766628\",\"name\":\"Wei-Ta Chu\"},{\"authorId\":\"36704967\",\"name\":\"Hung-Jui Guo\"}],\"doi\":\"10.1145/3132515.3132516\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f27f2415c8c2f71d740a7328703a52c3904a82b6\",\"title\":\"Movie Genre Classification based on Poster Images with Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/f27f2415c8c2f71d740a7328703a52c3904a82b6\",\"venue\":\"MUSA2@MM\",\"year\":2017},{\"arxivId\":\"1612.01887\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":\"10.1109/CVPR.2017.345\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9f4d7d622d1f7319cc511bfef661cd973e881a4c\",\"title\":\"Knowing When to Look: Adaptive Attention via a Visual Sentinel for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9f4d7d622d1f7319cc511bfef661cd973e881a4c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51349878\",\"name\":\"Y. C. Yoon\"},{\"authorId\":\"49591454\",\"name\":\"SoYoung Park\"},{\"authorId\":\"14966100\",\"name\":\"Soo Park\"},{\"authorId\":\"153803012\",\"name\":\"H. Lim\"}],\"doi\":\"10.4218/ETRIJ.2018-0621\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ef2c1911a95122d62d2886b70ab91a7595954bd4\",\"title\":\"Image classification and captioning model considering a CAM\\u2010based disagreement loss\",\"url\":\"https://www.semanticscholar.org/paper/ef2c1911a95122d62d2886b70ab91a7595954bd4\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1811.10787\",\"authors\":[{\"authorId\":\"144599697\",\"name\":\"Y. Feng\"},{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"40474876\",\"name\":\"Wei Liu\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2019.00425\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"580fd9a601314ea32dc85ec98267b411dd3465cf\",\"title\":\"Unsupervised Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/580fd9a601314ea32dc85ec98267b411dd3465cf\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1905.10515\",\"authors\":[{\"authorId\":\"2153067\",\"name\":\"Baohua Sun\"},{\"authorId\":\"144890162\",\"name\":\"L. Yang\"},{\"authorId\":\"144485124\",\"name\":\"M. Lin\"},{\"authorId\":\"50674008\",\"name\":\"C. Young\"},{\"authorId\":\"46195424\",\"name\":\"P. Dong\"},{\"authorId\":\"47528094\",\"name\":\"Wenhan Zhang\"},{\"authorId\":\"35287113\",\"name\":\"Jason Dong\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"70471f7d38c875e6e2912737729043e67272c326\",\"title\":\"SuperCaptioning: Image Captioning Using Two-dimensional Word Embedding\",\"url\":\"https://www.semanticscholar.org/paper/70471f7d38c875e6e2912737729043e67272c326\",\"venue\":\"BigMine@KDD\",\"year\":2019},{\"arxivId\":\"1804.08473\",\"authors\":[{\"authorId\":\"143672100\",\"name\":\"Bei Liu\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"32878737\",\"name\":\"M. Kato\"},{\"authorId\":\"1740865\",\"name\":\"M. Yoshikawa\"}],\"doi\":\"10.1145/3240508.3240587\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"99e56f1fd88d967aab6be2a51f3633697e2df667\",\"title\":\"Beyond Narrative Description: Generating Poetry from Images by Multi-Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/99e56f1fd88d967aab6be2a51f3633697e2df667\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3186804\",\"name\":\"Xinxin Zhu\"},{\"authorId\":\"1761970\",\"name\":\"L. Li\"},{\"authorId\":null,\"name\":\"Jing Liu\"},{\"authorId\":\"46948270\",\"name\":\"Ziyi Li\"},{\"authorId\":\"7475375\",\"name\":\"H. Peng\"},{\"authorId\":\"3712008\",\"name\":\"X. Niu\"}],\"doi\":\"10.1016/j.neucom.2018.08.069\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"299c4aebcc81dd311f5632f3eec5f8a3bd17a226\",\"title\":\"Image captioning with triple-attention and stack parallel LSTM\",\"url\":\"https://www.semanticscholar.org/paper/299c4aebcc81dd311f5632f3eec5f8a3bd17a226\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":\"1803.05526\",\"authors\":[{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"},{\"authorId\":\"2708940\",\"name\":\"Shafiq R. Joty\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"}],\"doi\":\"10.1007/978-3-030-01246-5_31\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"05544876b7bc58b59b9ec5a8ee09e3ce9b4791ce\",\"title\":\"Unpaired Image Captioning by Language Pivoting\",\"url\":\"https://www.semanticscholar.org/paper/05544876b7bc58b59b9ec5a8ee09e3ce9b4791ce\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145704540\",\"name\":\"Li Ren\"},{\"authorId\":\"66719728\",\"name\":\"Kien A. Hua\"}],\"doi\":\"10.1109/ISM.2018.00021\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"95bba8c514f63c666e0a85bdf9c6e3b8113d1f8f\",\"title\":\"Improved Image Description Via Embedded Object Structure Graph and Semantic Feature Matching\",\"url\":\"https://www.semanticscholar.org/paper/95bba8c514f63c666e0a85bdf9c6e3b8113d1f8f\",\"venue\":\"2018 IEEE International Symposium on Multimedia (ISM)\",\"year\":2018},{\"arxivId\":\"1908.09317\",\"authors\":[{\"authorId\":\"3422200\",\"name\":\"I. Laina\"},{\"authorId\":\"49359942\",\"name\":\"C. Rupprecht\"},{\"authorId\":\"145587209\",\"name\":\"N. Navab\"}],\"doi\":\"10.1109/ICCV.2019.00751\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a4ff2a0b65b7dfdecee8d2e4bc0c5f7e1fee03be\",\"title\":\"Towards Unsupervised Image Captioning With Shared Multimodal Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/a4ff2a0b65b7dfdecee8d2e4bc0c5f7e1fee03be\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47672526\",\"name\":\"Shiwei Wang\"},{\"authorId\":\"2410125\",\"name\":\"Long Lan\"},{\"authorId\":\"49470127\",\"name\":\"X. Zhang\"},{\"authorId\":\"48593034\",\"name\":\"Guohua Dong\"},{\"authorId\":\"1406222945\",\"name\":\"Zhigang Luo\"}],\"doi\":\"10.1007/s11042-019-08209-5\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"311ee1284e6bdf035f8c3a1a20d00c5841b2e341\",\"title\":\"Object-aware semantics of attention for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/311ee1284e6bdf035f8c3a1a20d00c5841b2e341\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49933533\",\"name\":\"Jing Yun\"},{\"authorId\":\"49933533\",\"name\":\"Jing Yun\"},{\"authorId\":\"48559698\",\"name\":\"Zhiwei Xu\"},{\"authorId\":\"1807620\",\"name\":\"Guanglai Gao\"}],\"doi\":\"10.1155/2020/9562587\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a20a9b1345d8919b692f7f7fe919937bf823358\",\"title\":\"Gated Object-Attribute Matching Network for Detailed Image Caption\",\"url\":\"https://www.semanticscholar.org/paper/8a20a9b1345d8919b692f7f7fe919937bf823358\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1804472\",\"name\":\"H. Chen\"},{\"authorId\":\"38329336\",\"name\":\"G. Ding\"},{\"authorId\":\"1818920\",\"name\":\"Zijia Lin\"},{\"authorId\":\"34811036\",\"name\":\"Yuchen Guo\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"}],\"doi\":\"10.1007/978-3-030-00563-4_16\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"18d99d29834ddd8c70878504998ca9f63f7b3ce1\",\"title\":\"Attend to Knowledge: Memory-Enhanced Attention Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/18d99d29834ddd8c70878504998ca9f63f7b3ce1\",\"venue\":\"BICS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47666606\",\"name\":\"Hui Chen\"},{\"authorId\":\"38329336\",\"name\":\"G. Ding\"},{\"authorId\":\"1818920\",\"name\":\"Zijia Lin\"},{\"authorId\":\"34811036\",\"name\":\"Yuchen Guo\"},{\"authorId\":\"10795229\",\"name\":\"Caifeng Shan\"},{\"authorId\":\"144762952\",\"name\":\"J. Han\"}],\"doi\":\"10.1007/s12559-019-09656-w\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e99a3163815a0c40705ffd6347c6cdbf19fa5237\",\"title\":\"Image Captioning with Memorized Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/e99a3163815a0c40705ffd6347c6cdbf19fa5237\",\"venue\":\"Cognitive Computation\",\"year\":2019},{\"arxivId\":\"2003.03107\",\"authors\":[{\"authorId\":\"32095408\",\"name\":\"Fawaz Sammani\"},{\"authorId\":\"1411260673\",\"name\":\"Luke Melas-Kyriazi\"}],\"doi\":\"10.1109/cvpr42600.2020.00486\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e9419436682726232e1b37a04c53bba919b12025\",\"title\":\"Show, Edit and Tell: A Framework for Editing Image Captions\",\"url\":\"https://www.semanticscholar.org/paper/e9419436682726232e1b37a04c53bba919b12025\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2007.05608\",\"authors\":[{\"authorId\":\"11007025\",\"name\":\"Junjiao Tian\"},{\"authorId\":\"143904954\",\"name\":\"Jean Oh\"}],\"doi\":\"10.24963/ijcai.2019/496\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"18403a06a67b7060645e137a36ad15122ee2c2f9\",\"title\":\"Image Captioning with Compositional Neural Module Networks\",\"url\":\"https://www.semanticscholar.org/paper/18403a06a67b7060645e137a36ad15122ee2c2f9\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"1805.09019\",\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cbc3ebf2809edcaa04e252d25f4373c924f4136b\",\"title\":\"CNN+CNN: Convolutional Decoders for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/cbc3ebf2809edcaa04e252d25f4373c924f4136b\",\"venue\":\"CVPR 2018\",\"year\":2018},{\"arxivId\":\"1804.00100\",\"authors\":[{\"authorId\":null,\"name\":\"Jingwen Wang\"},{\"authorId\":\"2093119\",\"name\":\"W. Jiang\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"144391096\",\"name\":\"Yong Xu\"}],\"doi\":\"10.1109/CVPR.2018.00751\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bb4e2d6a6e3e1067f21a4cad087fc91c671e495d\",\"title\":\"Bidirectional Attentive Fusion with Context Gating for Dense Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/bb4e2d6a6e3e1067f21a4cad087fc91c671e495d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1703.10476\",\"authors\":[{\"authorId\":\"38314306\",\"name\":\"Rakshith Shetty\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1109/ICCV.2017.445\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c0a6854b793ca8ad281513c184318b73d4868c4\",\"title\":\"Speaking the Same Language: Matching Machine to Human Captions by Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/1c0a6854b793ca8ad281513c184318b73d4868c4\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"2008.04200\",\"authors\":[{\"authorId\":\"1646872838\",\"name\":\"Yahui Liu\"},{\"authorId\":\"7405787\",\"name\":\"Marco De Nadai\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"},{\"authorId\":\"1490815081\",\"name\":\"Huayang Li\"},{\"authorId\":\"1382657362\",\"name\":\"Xavier Alameda-Pineda\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"},{\"authorId\":\"49305855\",\"name\":\"Bruno Lepri\"}],\"doi\":\"10.1145/3394171.3413505\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a13d21c301d3874baf1ca7a442649eb665ef5418\",\"title\":\"Describe What to Change: A Text-guided Unsupervised Image-to-image Translation Approach\",\"url\":\"https://www.semanticscholar.org/paper/a13d21c301d3874baf1ca7a442649eb665ef5418\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1904.08608\",\"authors\":[{\"authorId\":\"47008946\",\"name\":\"X. Yang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"}],\"doi\":\"10.1109/ICCV.2019.00435\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"45f9856d418527d23dc7c89197627fa1f3b215f9\",\"title\":\"Learning to Collocate Neural Modules for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/45f9856d418527d23dc7c89197627fa1f3b215f9\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1903.10663\",\"authors\":[{\"authorId\":\"100707516\",\"name\":\"HeeJae Jun\"},{\"authorId\":\"9726578\",\"name\":\"ByungSoo Ko\"},{\"authorId\":\"2268229\",\"name\":\"Youngjoon Kim\"},{\"authorId\":\"6160148\",\"name\":\"Insik Kim\"},{\"authorId\":\"2744147\",\"name\":\"Jongtack Kim\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"529b3f7560a68bb6981594ebd6c809dca14fecc8\",\"title\":\"Combination of Multiple Global Descriptors for Image Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/529b3f7560a68bb6981594ebd6c809dca14fecc8\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143704786\",\"name\":\"David Balderas\"},{\"authorId\":\"144302764\",\"name\":\"P. Ponce\"},{\"authorId\":\"144394807\",\"name\":\"A. Molina\"}],\"doi\":\"10.1016/J.ESWA.2018.12.055\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dca5599927a69bc8b8c315197cbd1b877e8af556\",\"title\":\"Convolutional long short term memory deep neural networks for image sequence prediction\",\"url\":\"https://www.semanticscholar.org/paper/dca5599927a69bc8b8c315197cbd1b877e8af556\",\"venue\":\"Expert Syst. Appl.\",\"year\":2019},{\"arxivId\":\"1812.02378\",\"authors\":[{\"authorId\":\"47008946\",\"name\":\"X. Yang\"},{\"authorId\":\"10817432\",\"name\":\"Kaihua Tang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"}],\"doi\":\"10.1109/CVPR.2019.01094\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f6feb1af1809dfd872d868dfcc13021cc42f496c\",\"title\":\"Auto-Encoding Scene Graphs for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/f6feb1af1809dfd872d868dfcc13021cc42f496c\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4421716\",\"name\":\"F. Wang\"},{\"authorId\":\"21776508\",\"name\":\"X. Gong\"},{\"authorId\":\"1754542\",\"name\":\"Linpeng Huang\"}],\"doi\":\"10.1109/ICPR.2018.8545355\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1a1a77e953736ce25949395d5856fc1762bbf8c6\",\"title\":\"Time-Dependent Pre-attention Model for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/1a1a77e953736ce25949395d5856fc1762bbf8c6\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1400934093\",\"name\":\"Sergio Mart\\u00ednez-Ag\\u00fcero\"},{\"authorId\":\"1397324853\",\"name\":\"I. Mora-Jim\\u00e9nez\"},{\"authorId\":\"1400917043\",\"name\":\"J. \\u00c1lvarez-Rodr\\u00edguez\"},{\"authorId\":\"145135725\",\"name\":\"A. Marques\"},{\"authorId\":\"1397324826\",\"name\":\"C. Soguero-Ru\\u00edz\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3c71edee6452d16ad4b2f4f0550a6478bd7b614c\",\"title\":\"Aplying LSTM Networks to Predict Multi-drug Resistance Using Binary Multivariate Clinical Sequences\",\"url\":\"https://www.semanticscholar.org/paper/3c71edee6452d16ad4b2f4f0550a6478bd7b614c\",\"venue\":\"STAIRS@ECAI\",\"year\":2020},{\"arxivId\":\"1805.05062\",\"authors\":[{\"authorId\":\"46183659\",\"name\":\"Maha Elbayad\"},{\"authorId\":\"143823463\",\"name\":\"L. Besacier\"},{\"authorId\":\"34602236\",\"name\":\"Jakob Verbeek\"}],\"doi\":\"10.18653/v1/P18-1195\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"db3340742a56a4bbb9d7ee8dba1958fb132a3c0a\",\"title\":\"Token-level and sequence-level loss smoothing for RNN language models\",\"url\":\"https://www.semanticscholar.org/paper/db3340742a56a4bbb9d7ee8dba1958fb132a3c0a\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":\"1904.11251\",\"authors\":[{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"47636228\",\"name\":\"H. Chao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2019.01278\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"6dc67482ee0530e9ff535775891481ed9fd5f6ad\",\"title\":\"Pointing Novel Objects in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6dc67482ee0530e9ff535775891481ed9fd5f6ad\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1912.11872\",\"authors\":[{\"authorId\":\"153040576\",\"name\":\"T. Mei\"},{\"authorId\":\"101586660\",\"name\":\"W. Zhang\"},{\"authorId\":\"48577275\",\"name\":\"Ting Yao\"}],\"doi\":\"10.1017/ATSIP.2020.10\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"3ba3e7970fac892ed3079d570ef019fa0940fec2\",\"title\":\"Vision and Language: from Visual Perception to Content Creation\",\"url\":\"https://www.semanticscholar.org/paper/3ba3e7970fac892ed3079d570ef019fa0940fec2\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31696860\",\"name\":\"Shurong Sheng\"},{\"authorId\":\"145446752\",\"name\":\"Marie-Francine Moens\"}],\"doi\":\"10.1145/3343031.3350972\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d35c56b2a86d928fabe380f5380e83a7992c1d7a\",\"title\":\"Generating Captions for Images of Ancient Artworks\",\"url\":\"https://www.semanticscholar.org/paper/d35c56b2a86d928fabe380f5380e83a7992c1d7a\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1807.09986\",\"authors\":[{\"authorId\":\"2093119\",\"name\":\"W. Jiang\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"38144094\",\"name\":\"T. Zhang\"}],\"doi\":\"10.1007/978-3-030-01216-8_31\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"04cd9168dcf1a0d2cf01db95a1af53d0900bc346\",\"title\":\"Recurrent Fusion Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/04cd9168dcf1a0d2cf01db95a1af53d0900bc346\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49251978\",\"name\":\"J. Chen\"},{\"authorId\":\"41079034\",\"name\":\"Hong-Yang Chao\"}],\"doi\":\"10.1145/3394171.3416291\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"598ad06c164043c45c952dbde37e0c75991e66aa\",\"title\":\"VideoTRM: Pre-training for Video Captioning Challenge 2020\",\"url\":\"https://www.semanticscholar.org/paper/598ad06c164043c45c952dbde37e0c75991e66aa\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2006.11807\",\"authors\":[{\"authorId\":\"144910087\",\"name\":\"Zhan Shi\"},{\"authorId\":\"152482200\",\"name\":\"X. Zhou\"},{\"authorId\":\"1767521\",\"name\":\"Xipeng Qiu\"},{\"authorId\":\"150345740\",\"name\":\"Xiao-Dan Zhu\"}],\"doi\":\"10.18653/v1/2020.acl-main.664\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7e0f91e51ee372939c96714c7919dde6dc756849\",\"title\":\"Improving Image Captioning with Better Use of Captions\",\"url\":\"https://www.semanticscholar.org/paper/7e0f91e51ee372939c96714c7919dde6dc756849\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"2011.01385\",\"authors\":[{\"authorId\":\"3280656\",\"name\":\"Litao Yu\"},{\"authorId\":\"123275544\",\"name\":\"Jian Zhang\"},{\"authorId\":\"47506551\",\"name\":\"Qiang Wu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b0aa35ac0caf5230cdd1c5022b246e2381f87aac\",\"title\":\"Dual Attention on Pyramid Feature Maps for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/b0aa35ac0caf5230cdd1c5022b246e2381f87aac\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151430668\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s11042-019-08021-1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1ba03c16bf25d33efc0d977ab51392e1d9b5a0fb\",\"title\":\"Survey of deep learning and architectures for visual captioning\\u2014transitioning between media and natural languages\",\"url\":\"https://www.semanticscholar.org/paper/1ba03c16bf25d33efc0d977ab51392e1d9b5a0fb\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":\"1909.06814\",\"authors\":[{\"authorId\":\"41019330\",\"name\":\"Leshem Choshen\"},{\"authorId\":\"2769805\",\"name\":\"Omri Abend\"}],\"doi\":\"10.18653/v1/K19-1028\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"68755920089b78a99ee400bc8eb03ee387e2fcc2\",\"title\":\"Automatically Extracting Challenge Sets for Non local Phenomena in Neural Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/68755920089b78a99ee400bc8eb03ee387e2fcc2\",\"venue\":\"CoNLL\",\"year\":2019},{\"arxivId\":\"1812.06587\",\"authors\":[{\"authorId\":\"2677364\",\"name\":\"Luowei Zhou\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.1109/CVPR.2019.00674\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"171a027fc6c7f4194569170accc48187c8bb5aaa\",\"title\":\"Grounded Video Description\",\"url\":\"https://www.semanticscholar.org/paper/171a027fc6c7f4194569170accc48187c8bb5aaa\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2846025\",\"name\":\"D. Yu\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/CVPR.2017.446\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d740d0a960368633ed32fc84877b8391993acdca\",\"title\":\"Multi-level Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d740d0a960368633ed32fc84877b8391993acdca\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48707795\",\"name\":\"Ziwei Wang\"},{\"authorId\":\"7988538\",\"name\":\"Yadan Luo\"},{\"authorId\":null,\"name\":\"Yang Li\"},{\"authorId\":\"145622169\",\"name\":\"Zi Huang\"},{\"authorId\":\"2416851\",\"name\":\"Hongzhi Yin\"}],\"doi\":\"10.1145/3240508.3240583\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f9853c76065b72a8a25d984f7aa4f2c65a2df623\",\"title\":\"Look Deeper See Richer: Depth-aware Image Paragraph Captioning\",\"url\":\"https://www.semanticscholar.org/paper/f9853c76065b72a8a25d984f7aa4f2c65a2df623\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1810.06245\",\"authors\":[{\"authorId\":\"35935570\",\"name\":\"Jean-Benoit Delbrouck\"},{\"authorId\":\"144436412\",\"name\":\"S. Dupont\"}],\"doi\":null,\"intent\":[\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"58d16e23e1192be4acaf6a29c1f5995817146554\",\"title\":\"Bringing back simplicity and lightliness into neural image captioning\",\"url\":\"https://www.semanticscholar.org/paper/58d16e23e1192be4acaf6a29c1f5995817146554\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1903.06994\",\"authors\":[{\"authorId\":\"86912250\",\"name\":\"Peixi Xiong\"},{\"authorId\":\"7573997\",\"name\":\"Huayi Zhan\"},{\"authorId\":null,\"name\":\"Xin Wang\"},{\"authorId\":\"67250414\",\"name\":\"B. Sinha\"},{\"authorId\":\"50118130\",\"name\":\"Y. Wu\"}],\"doi\":\"10.1109/CVPR.2019.00855\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d9e326ff03bbaf6426bfb3a9331d49a24dc4e4c\",\"title\":\"Visual Query Answering by Entity-Attribute Graph Matching and Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/6d9e326ff03bbaf6426bfb3a9331d49a24dc4e4c\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1903.01072\",\"authors\":[{\"authorId\":\"47060391\",\"name\":\"J. Tan\"},{\"authorId\":\"2863960\",\"name\":\"Chee Seng Chan\"},{\"authorId\":\"38900275\",\"name\":\"Joon Huang Chuah\"}],\"doi\":\"10.1109/TMM.2019.2904878\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d6dbaf44d4437d9a27970bbc65e542706eae49f\",\"title\":\"COMIC: Toward A Compact Image Captioning Model With Attention\",\"url\":\"https://www.semanticscholar.org/paper/9d6dbaf44d4437d9a27970bbc65e542706eae49f\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"},{\"authorId\":\"31790073\",\"name\":\"C. Buehler\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"46878216\",\"name\":\"M. Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a79b694bd4ef51207787da1948ed473903b751ef\",\"title\":\"Bottom-Up and Top-Down Attention for Image Captioning and VQA\",\"url\":\"https://www.semanticscholar.org/paper/a79b694bd4ef51207787da1948ed473903b751ef\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2458059\",\"name\":\"Y. Huang\"},{\"authorId\":\"46651452\",\"name\":\"Cong Li\"},{\"authorId\":\"2641581\",\"name\":\"Tianpeng Li\"},{\"authorId\":\"47718901\",\"name\":\"Weitao Wan\"},{\"authorId\":\"47739902\",\"name\":\"J. Chen\"}],\"doi\":\"10.1109/ICIP.2019.8803108\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ff24050374748529fa2a1fee6941af08296449f8\",\"title\":\"Image Captioning with Attribute Refinement\",\"url\":\"https://www.semanticscholar.org/paper/ff24050374748529fa2a1fee6941af08296449f8\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5947095\",\"name\":\"Byeong Jo Kim\"},{\"authorId\":\"47634928\",\"name\":\"Yong Hoon Choi\"}],\"doi\":\"10.1145/3341105.3374063\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"ad8dd9815372778e0d2617a67cc0ace7771c3fb3\",\"title\":\"Automatic baseball commentary generation using deep learning\",\"url\":\"https://www.semanticscholar.org/paper/ad8dd9815372778e0d2617a67cc0ace7771c3fb3\",\"venue\":\"SAC\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7437104\",\"name\":\"Chih-Yao Ma\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"9202076\",\"name\":\"G. Al-Regib\"},{\"authorId\":\"48682997\",\"name\":\"P. Vajda\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"145276578\",\"name\":\"Z. Kira\"}],\"doi\":\"10.1007/978-3-030-58523-5_21\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f692df9ca116884860d580902fa642370bd1be5d\",\"title\":\"Learning to Generate Grounded Visual Captions Without Localization Supervision\",\"url\":\"https://www.semanticscholar.org/paper/f692df9ca116884860d580902fa642370bd1be5d\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52150251\",\"name\":\"A. Goel\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"103192742\",\"name\":\"T. Nguyen\"},{\"authorId\":\"2518212\",\"name\":\"Hakan Bilen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"3d807fed82f61bc48aea76f191d2e19e2fc38f5d\",\"title\":\"Learning to Caption Images with Two-Stream Attention and Sentence Auto-Encoder\",\"url\":\"https://www.semanticscholar.org/paper/3d807fed82f61bc48aea76f191d2e19e2fc38f5d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153297544\",\"name\":\"X. Yang\"},{\"authorId\":\"118565563\",\"name\":\"Chong-Yang Gao\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"}],\"doi\":\"10.1145/3394171.3413859\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"96389251e4f0f8494dfc8dc67c05992eed8e192b\",\"title\":\"Hierarchical Scene Graph Encoder-Decoder for Image Paragraph Captioning\",\"url\":\"https://www.semanticscholar.org/paper/96389251e4f0f8494dfc8dc67c05992eed8e192b\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1696589727\",\"name\":\"Dongming Zhou\"},{\"authorId\":\"7924036\",\"name\":\"Canlong Zhang\"},{\"authorId\":\"144111674\",\"name\":\"Zhixin Li\"},{\"authorId\":\"48708659\",\"name\":\"Zhiwen Wang\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206932\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a32ac0995afcbc748fa6533b941e9834ec7bfc2e\",\"title\":\"Multi-level Visual Fusion Networks for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/a32ac0995afcbc748fa6533b941e9834ec7bfc2e\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36960501\",\"name\":\"Swaminathan Gurumurthy\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"41121dd73ce28ebe31ebf9c9a402cf575665ea32\",\"title\":\"Removing the i\\u2019s from i.i.d : Testing generalization on hard datasets\",\"url\":\"https://www.semanticscholar.org/paper/41121dd73ce28ebe31ebf9c9a402cf575665ea32\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1404555727\",\"name\":\"Renata Borovica-Gajic\"},{\"authorId\":\"39899794\",\"name\":\"Jianzhong Qi\"},{\"authorId\":\"47824837\",\"name\":\"Weiqing Wang\"},{\"authorId\":\"1743774\",\"name\":\"Elisa Bertino\"}],\"doi\":\"10.1007/978-3-030-39469-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e79fb7f9c357265afdd8dd839be19b9ae324afc4\",\"title\":\"Databases Theory and Applications: 31st Australasian Database Conference, ADC 2020, Melbourne, VIC, Australia, February 3\\u20137, 2020, Proceedings\",\"url\":\"https://www.semanticscholar.org/paper/e79fb7f9c357265afdd8dd839be19b9ae324afc4\",\"venue\":\"ADC\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150112916\",\"name\":\"Gabino Luis\"},{\"authorId\":\"47756806\",\"name\":\"D. Suarez\"},{\"authorId\":\"145940020\",\"name\":\"A. Mateos\"}],\"doi\":\"10.14201/ADCAIJ2018741726\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"0dcf93dde3488d42e244999f6be62a1bb9732521\",\"title\":\"Multi-Agent Word Guessing Game\",\"url\":\"https://www.semanticscholar.org/paper/0dcf93dde3488d42e244999f6be62a1bb9732521\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1912.01881\",\"authors\":[{\"authorId\":\"1443435125\",\"name\":\"Zhengcong Fei\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"03158341c61b8bfedc9ccd503610ab150678a7c1\",\"title\":\"Better Understanding Hierarchical Visual Relationship for Image Caption\",\"url\":\"https://www.semanticscholar.org/paper/03158341c61b8bfedc9ccd503610ab150678a7c1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2458059\",\"name\":\"Y. Huang\"},{\"authorId\":\"1752427\",\"name\":\"Jiansheng Chen\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"47718901\",\"name\":\"Weitao Wan\"},{\"authorId\":\"153447481\",\"name\":\"Youze Xue\"}],\"doi\":\"10.1109/TIP.2020.2969330\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ff5a1ec81f327b711a5433e4cd40467215a13f39\",\"title\":\"Image Captioning With End-to-End Attribute Detection and Subsequent Attributes Prediction\",\"url\":\"https://www.semanticscholar.org/paper/ff5a1ec81f327b711a5433e4cd40467215a13f39\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48902313\",\"name\":\"Wei Zhang\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"2066429\",\"name\":\"Shiai Zhu\"},{\"authorId\":\"30889568\",\"name\":\"Abdulmotaleb El Saddik\"}],\"doi\":\"10.1145/3279952\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"bb9e418469d018be7f5ac2c4b2435ccac50088a3\",\"title\":\"Deep Learning\\u2013Based Multimedia Analytics\",\"url\":\"https://www.semanticscholar.org/paper/bb9e418469d018be7f5ac2c4b2435ccac50088a3\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46447188\",\"name\":\"X. Zhang\"},{\"authorId\":\"2548483\",\"name\":\"Shengfeng He\"},{\"authorId\":\"1688375\",\"name\":\"Xinhang Song\"},{\"authorId\":\"1726262\",\"name\":\"R. Lau\"},{\"authorId\":\"24350293\",\"name\":\"J. Jiao\"},{\"authorId\":\"1694936\",\"name\":\"Q. Ye\"}],\"doi\":\"10.1016/J.NEUCOM.2018.02.112\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f7a305d80eae6a9b9fecbeeb7ade0b25d412219d\",\"title\":\"Image captioning via semantic element embedding\",\"url\":\"https://www.semanticscholar.org/paper/f7a305d80eae6a9b9fecbeeb7ade0b25d412219d\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39054424\",\"name\":\"Min Gao\"},{\"authorId\":\"121685794\",\"name\":\"Xian-Hua Han\"},{\"authorId\":\"36190812\",\"name\":\"Jing Li\"},{\"authorId\":\"144562060\",\"name\":\"Hui Ji\"},{\"authorId\":\"2856513\",\"name\":\"Huaxiang Zhang\"},{\"authorId\":\"51299154\",\"name\":\"Jiande Sun\"}],\"doi\":\"10.1007/s11042-018-6751-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b737a81ff05e64e29596415c65dbc156e3481f95\",\"title\":\"Image super-resolution based on two-level residual learning CNN\",\"url\":\"https://www.semanticscholar.org/paper/b737a81ff05e64e29596415c65dbc156e3481f95\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1145/3077136.3084144\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7cdf9b822b07199415f0e25aa0517c82b1bd499a\",\"title\":\"Seeing Bot\",\"url\":\"https://www.semanticscholar.org/paper/7cdf9b822b07199415f0e25aa0517c82b1bd499a\",\"venue\":\"SIGIR\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3055959\",\"name\":\"Veena Thenkanidiyoor\"},{\"authorId\":\"47798961\",\"name\":\"R. Prasath\"},{\"authorId\":\"150255310\",\"name\":\"Odelu Vanga\"},{\"authorId\":\"145960032\",\"name\":\"R. Goebel\"},{\"authorId\":\"144865865\",\"name\":\"Y. Tanaka\"}],\"doi\":\"10.1007/978-3-030-66187-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b326e950ca86368056d2846444c25c61fedbc111\",\"title\":\"Mining Intelligence and Knowledge Exploration: 7th International Conference, MIKE 2019, Goa, India, December 19\\u201322, 2019, Proceedings\",\"url\":\"https://www.semanticscholar.org/paper/b326e950ca86368056d2846444c25c61fedbc111\",\"venue\":\"MIKE\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145949274\",\"name\":\"V. Srinivasan\"},{\"authorId\":\"50629423\",\"name\":\"Sashank Santhanam\"},{\"authorId\":\"145102721\",\"name\":\"S. Shaikh\"}],\"doi\":\"10.1007/s10844-020-00626-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"50dde952a48a8c8d64a324d2c16b5e743d47200b\",\"title\":\"Using reinforcement learning with external rewards for open-domain natural language generation\",\"url\":\"https://www.semanticscholar.org/paper/50dde952a48a8c8d64a324d2c16b5e743d47200b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2012.13136\",\"authors\":[{\"authorId\":\"48394426\",\"name\":\"Naeha Sharif\"},{\"authorId\":\"39689790\",\"name\":\"L. White\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"46641911\",\"name\":\"W. Liu\"},{\"authorId\":\"14752125\",\"name\":\"Syed Afaq Ali Shah\"}],\"doi\":\"10.1007/s11263-019-01206-z\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"47286105575aacaed5ef74af9ae007e258abc60a\",\"title\":\"LCEval: Learned Composite Metric for Caption Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/47286105575aacaed5ef74af9ae007e258abc60a\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"2012.02033\",\"authors\":[{\"authorId\":\"152332057\",\"name\":\"Baohua Sun\"},{\"authorId\":\"1999579263\",\"name\":\"Michael Lin\"},{\"authorId\":\"1505825326\",\"name\":\"Hao Sha\"},{\"authorId\":\"1986616718\",\"name\":\"Lin Yang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b366c17a5a0daf851ec4a5d94b29accb4c643b73\",\"title\":\"SuperOCR: A Conversion from Optical Character Recognition to Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/b366c17a5a0daf851ec4a5d94b29accb4c643b73\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3238408\",\"name\":\"P. Madhyastha\"},{\"authorId\":\"2635321\",\"name\":\"Josiah Wang\"},{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"}],\"doi\":\"10.1017/S1351324918000116\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2df61fcd01b6a70a94dff2b25d6ed8dc4c16e422\",\"title\":\"The role of image representations in vision to language tasks\",\"url\":\"https://www.semanticscholar.org/paper/2df61fcd01b6a70a94dff2b25d6ed8dc4c16e422\",\"venue\":\"Nat. Lang. Eng.\",\"year\":2018},{\"arxivId\":\"1809.04835\",\"authors\":[{\"authorId\":\"3404500\",\"name\":\"Haichao Shi\"},{\"authorId\":\"144326612\",\"name\":\"P. Li\"},{\"authorId\":\"49292319\",\"name\":\"Bo Wang\"},{\"authorId\":\"2960930\",\"name\":\"Z. Wang\"}],\"doi\":\"10.1145/3240876.3240900\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dec04588b73efb1192d1778b2b818842ccd242e7\",\"title\":\"Image captioning based on deep reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/dec04588b73efb1192d1778b2b818842ccd242e7\",\"venue\":\"ICIMCS '18\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145443283\",\"name\":\"A. Asadi\"},{\"authorId\":\"1682051\",\"name\":\"R. Safabakhsh\"}],\"doi\":\"10.1007/978-3-030-31756-0_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0e299ff8156d4c935f55edae12a1aa884de27e8a\",\"title\":\"The Encoder-Decoder Framework and Its Applications\",\"url\":\"https://www.semanticscholar.org/paper/0e299ff8156d4c935f55edae12a1aa884de27e8a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2846025\",\"name\":\"D. Yu\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"40434674\",\"name\":\"X. Tian\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1145/3316767\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b0ce44270916fd6e254fd9e75dd77ee1cf9f212a\",\"title\":\"Multi-source Multi-level Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b0ce44270916fd6e254fd9e75dd77ee1cf9f212a\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":\"2009.07717\",\"authors\":[{\"authorId\":\"145950651\",\"name\":\"S. Ahmed\"},{\"authorId\":\"1757030\",\"name\":\"Berrin A. Yanikoglu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5808e60a45d2243da47915a2eca85b2dec350680\",\"title\":\"Relative Attribute Classification with Deep Rank SVM\",\"url\":\"https://www.semanticscholar.org/paper/5808e60a45d2243da47915a2eca85b2dec350680\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.08899\",\"authors\":[{\"authorId\":\"2533559\",\"name\":\"Dhomas Hatta Fudholi\"},{\"authorId\":\"88823036\",\"name\":\"Yurio Windiatmoko\"},{\"authorId\":\"104526200\",\"name\":\"Nurdi Afrianto\"},{\"authorId\":\"1392876189\",\"name\":\"P. Susanto\"},{\"authorId\":\"80939610\",\"name\":\"Magfirah Suyuti\"},{\"authorId\":\"30726945\",\"name\":\"A. Hidayatullah\"},{\"authorId\":\"2938889\",\"name\":\"R. Rahmadi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2291e4f1eb85ec2415aee119c5ca67d8bb64b30f\",\"title\":\"Image Captioning with Attention for Smart Local Tourism using EfficientNet\",\"url\":\"https://www.semanticscholar.org/paper/2291e4f1eb85ec2415aee119c5ca67d8bb64b30f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1612.00370\",\"authors\":[{\"authorId\":\"47130333\",\"name\":\"Siqi Liu\"},{\"authorId\":\"39815369\",\"name\":\"Z. Zhu\"},{\"authorId\":\"145361612\",\"name\":\"N. Ye\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":\"10.1109/ICCV.2017.100\",\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"665a311c538fc021c27acd3953f171924cc5905c\",\"title\":\"Optimization of image description metrics using policy gradient methods\",\"url\":\"https://www.semanticscholar.org/paper/665a311c538fc021c27acd3953f171924cc5905c\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"117548227\",\"name\":\"Saloni Kalra\"},{\"authorId\":\"88872765\",\"name\":\"Alka Leekha\"}],\"doi\":\"10.1080/02522667.2020.1715602\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"117333afd2ce2d80dd195dc5c5087f1b2b6bebdc\",\"title\":\"Survey of convolutional neural networks for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/117333afd2ce2d80dd195dc5c5087f1b2b6bebdc\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1812.03849\",\"authors\":[{\"authorId\":\"50997773\",\"name\":\"Xuguang Duan\"},{\"authorId\":\"2978255\",\"name\":\"Wen-bing Huang\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"1688516\",\"name\":\"Jingdong Wang\"},{\"authorId\":\"145583986\",\"name\":\"Wenwu Zhu\"},{\"authorId\":\"50882910\",\"name\":\"Junzhou Huang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8735ac2324b5aeaa3a8418af97eb82e9aa1910cb\",\"title\":\"Weakly Supervised Dense Event Captioning in Videos\",\"url\":\"https://www.semanticscholar.org/paper/8735ac2324b5aeaa3a8418af97eb82e9aa1910cb\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145350881\",\"name\":\"Y. Tian\"},{\"authorId\":\"47120369\",\"name\":\"X. Wang\"},{\"authorId\":\"13013695\",\"name\":\"Jiachen Wu\"},{\"authorId\":\"49908315\",\"name\":\"Ruili Wang\"},{\"authorId\":\"7324474\",\"name\":\"Bailin Yang\"}],\"doi\":\"10.1613/jair.1.11338\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"cfeda236987b04250a218b688e32b6b35c617ba4\",\"title\":\"Multi-scale Hierarchical Residual Network for Dense Captioning\",\"url\":\"https://www.semanticscholar.org/paper/cfeda236987b04250a218b688e32b6b35c617ba4\",\"venue\":\"J. Artif. Intell. Res.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"1491236221\",\"name\":\"Meng Gao\"},{\"authorId\":\"1747773\",\"name\":\"T. Zhang\"},{\"authorId\":\"35325151\",\"name\":\"Yuexian Zou\"}],\"doi\":\"10.1109/ICDM.2019.00054\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8f04013efcdf606d65145859f4f9eb6c48908869\",\"title\":\"Exploring Semantic Relationships for Image Captioning without Parallel Data\",\"url\":\"https://www.semanticscholar.org/paper/8f04013efcdf606d65145859f4f9eb6c48908869\",\"venue\":\"2019 IEEE International Conference on Data Mining (ICDM)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47672526\",\"name\":\"Shiwei Wang\"},{\"authorId\":\"2410125\",\"name\":\"Long Lan\"},{\"authorId\":\"49470127\",\"name\":\"X. Zhang\"},{\"authorId\":\"1406222945\",\"name\":\"Zhigang Luo\"}],\"doi\":\"10.1007/s11042-019-08567-0\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"49280cc9fa8c9854a655afbfd213c1437c52f1e3\",\"title\":\"GateCap: Gated spatial and semantic attention model for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/49280cc9fa8c9854a655afbfd213c1437c52f1e3\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49292427\",\"name\":\"B. Wang\"},{\"authorId\":\"3429418\",\"name\":\"Cun-gang Wang\"},{\"authorId\":\"47834797\",\"name\":\"Qian Zhang\"},{\"authorId\":\"1749725513\",\"name\":\"Ying Su\"},{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"48615794\",\"name\":\"Yanyan Xu\"}],\"doi\":\"10.1109/ACCESS.2020.2999568\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1fac7ac22af5db06edde0fbda2bc61a97c7c9625\",\"title\":\"Cross-Lingual Image Caption Generation Based on Visual Attention Model\",\"url\":\"https://www.semanticscholar.org/paper/1fac7ac22af5db06edde0fbda2bc61a97c7c9625\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144751998\",\"name\":\"C. He\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1145/3292058\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1b0ef7ccad215c682a784d1aec4988b675d779b9\",\"title\":\"Image Captioning With Visual-Semantic Double Attention\",\"url\":\"https://www.semanticscholar.org/paper/1b0ef7ccad215c682a784d1aec4988b675d779b9\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":\"2003.14080\",\"authors\":[{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"1490772804\",\"name\":\"Tao Mei\"}],\"doi\":\"10.1109/cvpr42600.2020.01098\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4adfa7b83342b77c830f2b0f6fc1b784c21e7ed0\",\"title\":\"X-Linear Attention Networks for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/4adfa7b83342b77c830f2b0f6fc1b784c21e7ed0\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2001.01037\",\"authors\":[{\"authorId\":\"46969089\",\"name\":\"J. Sun\"},{\"authorId\":\"3633358\",\"name\":\"S. Lapuschkin\"},{\"authorId\":\"1699054\",\"name\":\"W. Samek\"},{\"authorId\":\"49345823\",\"name\":\"Alexander Binder\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"82e836be97e706dca7029ce6a0553b4890726593\",\"title\":\"Understanding Image Captioning Models beyond Visualizing Attention\",\"url\":\"https://www.semanticscholar.org/paper/82e836be97e706dca7029ce6a0553b4890726593\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.09742\",\"authors\":[{\"authorId\":\"48386951\",\"name\":\"Xinxin Zhu\"},{\"authorId\":\"49336560\",\"name\":\"Weining Wang\"},{\"authorId\":\"26982950\",\"name\":\"Longteng Guo\"},{\"authorId\":null,\"name\":\"Jing Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb3f19de52d330ded5b3eebb79b89876648f67cb\",\"title\":\"AutoCaption: Image Captioning with Neural Architecture Search\",\"url\":\"https://www.semanticscholar.org/paper/eb3f19de52d330ded5b3eebb79b89876648f67cb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9719479\",\"name\":\"Ziyue Luo\"},{\"authorId\":\"122090721\",\"name\":\"Huixian Kang\"},{\"authorId\":\"51250530\",\"name\":\"Pin Yao\"},{\"authorId\":\"145524181\",\"name\":\"W. Wan\"}],\"doi\":\"10.1109/ICALIP.2018.8455856\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3a4a539281f805a623f5afafa10efb76d029c6b4\",\"title\":\"Chinese Image Caption Based on Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/3a4a539281f805a623f5afafa10efb76d029c6b4\",\"venue\":\"2018 International Conference on Audio, Language and Image Processing (ICALIP)\",\"year\":2018},{\"arxivId\":\"1906.08876\",\"authors\":[{\"authorId\":\"3038511\",\"name\":\"Sanqiang Zhao\"},{\"authorId\":\"48267618\",\"name\":\"Piyush Sharma\"},{\"authorId\":\"2900341\",\"name\":\"Tomer Levinboim\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"}],\"doi\":\"10.18653/v1/P19-1650\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"68490e9e0bca2f0b1ae2ca636effcd8fc63d2008\",\"title\":\"Informative Image Captioning with External Sources of Information\",\"url\":\"https://www.semanticscholar.org/paper/68490e9e0bca2f0b1ae2ca636effcd8fc63d2008\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1909.02860\",\"authors\":[{\"authorId\":\"49544460\",\"name\":\"Xuejing Liu\"},{\"authorId\":\"73596205\",\"name\":\"L. Li\"},{\"authorId\":\"47672591\",\"name\":\"Shuhui Wang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"145235479\",\"name\":\"L. Su\"},{\"authorId\":\"47809582\",\"name\":\"Qingming Huang\"}],\"doi\":\"10.1145/3343031.3351074\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"28691804ea6e9bb00249d864be36354f6c548ba5\",\"title\":\"Knowledge-guided Pairwise Reconstruction Network for Weakly Supervised Referring Expression Grounding\",\"url\":\"https://www.semanticscholar.org/paper/28691804ea6e9bb00249d864be36354f6c548ba5\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1703.06233\",\"authors\":[{\"authorId\":\"36508529\",\"name\":\"Arun Mallya\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1109/ICCV.2017.57\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"afc7d76c94c9b73aa28f4aa42407b21aa0572a1b\",\"title\":\"Recurrent Models for Situation Recognition\",\"url\":\"https://www.semanticscholar.org/paper/afc7d76c94c9b73aa28f4aa42407b21aa0572a1b\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1807.09958\",\"authors\":[{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"50816334\",\"name\":\"D. Ye\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1007/978-3-030-01228-1_18\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"94e3b75a6732b5918c4c2b87d127a9216ff07efc\",\"title\":\"Rethinking the Form of Latent States in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/94e3b75a6732b5918c4c2b87d127a9216ff07efc\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1804.00819\",\"authors\":[{\"authorId\":\"2677364\",\"name\":\"Luowei Zhou\"},{\"authorId\":\"34872128\",\"name\":\"Yingbo Zhou\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"}],\"doi\":\"10.1109/CVPR.2018.00911\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"35ed258aede3df17ee20a6635364cb5fd2461049\",\"title\":\"End-to-End Dense Video Captioning with Masked Transformer\",\"url\":\"https://www.semanticscholar.org/paper/35ed258aede3df17ee20a6635364cb5fd2461049\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1811.05253\",\"authors\":[{\"authorId\":\"3491491\",\"name\":\"Shiyang Yan\"},{\"authorId\":\"5145427\",\"name\":\"Fangyu Wu\"},{\"authorId\":\"33830793\",\"name\":\"Jeremy S. Smith\"},{\"authorId\":\"40178769\",\"name\":\"Wenjin Lu\"},{\"authorId\":\"1782912\",\"name\":\"Bailing Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b7294dd0ec8ff8d3353286bce6b4ace60f957a08\",\"title\":\"Image Captioning Based on a Hierarchical Attention Mechanism and Policy Gradient Optimization\",\"url\":\"https://www.semanticscholar.org/paper/b7294dd0ec8ff8d3353286bce6b4ace60f957a08\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1901.08942\",\"authors\":[{\"authorId\":\"143959713\",\"name\":\"Yimin Zhou\"},{\"authorId\":\"3156408\",\"name\":\"Y. Sun\"},{\"authorId\":\"145513516\",\"name\":\"Vasant G Honavar\"}],\"doi\":\"10.1109/WACV.2019.00036\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"f4c45108cb41051010d8a5175b8da23eb246c967\",\"title\":\"Improving Image Captioning by Leveraging Knowledge Graphs\",\"url\":\"https://www.semanticscholar.org/paper/f4c45108cb41051010d8a5175b8da23eb246c967\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":\"1802.10240\",\"authors\":[{\"authorId\":\"3174935\",\"name\":\"Wenshan Wang\"},{\"authorId\":\"4456978\",\"name\":\"S. Yang\"},{\"authorId\":\"1954076\",\"name\":\"W. Zhang\"},{\"authorId\":\"2985995\",\"name\":\"J. Zhang\"}],\"doi\":\"10.1049/iet-cvi.2019.0361\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e2f950677e6a42beb234e507b3022964980b6556\",\"title\":\"Neural Aesthetic Image Reviewer\",\"url\":\"https://www.semanticscholar.org/paper/e2f950677e6a42beb234e507b3022964980b6556\",\"venue\":\"IET Comput. Vis.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50763020\",\"name\":\"Jingwen Chen\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"47636228\",\"name\":\"H. Chao\"}],\"doi\":\"10.1007/s11042-018-5746-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a69cf2990ab1eeb57248307fbb7926c9fee65317\",\"title\":\"See and chat: automatically generating viewer-level comments on images\",\"url\":\"https://www.semanticscholar.org/paper/a69cf2990ab1eeb57248307fbb7926c9fee65317\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"816766ae8d708d088d64403c5fb278e56dc82bb3\",\"title\":\"Grounding natural language phrases in images and video\",\"url\":\"https://www.semanticscholar.org/paper/816766ae8d708d088d64403c5fb278e56dc82bb3\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51058812\",\"name\":\"X. Liu\"},{\"authorId\":\"98355791\",\"name\":\"W. Liu\"},{\"authorId\":\"145767616\",\"name\":\"Weiwei Xing\"}],\"doi\":\"10.1109/ICEIEC.2019.8784585\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8ca688fbaaf93771d59ab59a92b62ecffd22013d\",\"title\":\"Image Captioning with Emotional Information via Multiple Model\",\"url\":\"https://www.semanticscholar.org/paper/8ca688fbaaf93771d59ab59a92b62ecffd22013d\",\"venue\":\"2019 IEEE 9th International Conference on Electronics Information and Emergency Communication (ICEIEC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66916694\",\"name\":\"X. Xiao\"},{\"authorId\":\"46660013\",\"name\":\"L. Wang\"},{\"authorId\":\"33969294\",\"name\":\"K. Ding\"},{\"authorId\":\"1683738\",\"name\":\"S. Xiang\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.1109/TMM.2019.2915033\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bbb9f5378eac3eb8245cbd0f998a95cef2954508\",\"title\":\"Deep Hierarchical Encoder\\u2013Decoder Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/bbb9f5378eac3eb8245cbd0f998a95cef2954508\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49528408\",\"name\":\"H. Wang\"},{\"authorId\":\"46867445\",\"name\":\"Y. Zhang\"},{\"authorId\":\"9305704\",\"name\":\"Xiaosheng Yu\"}],\"doi\":\"10.1155/2020/3062706\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4b652fa2b4ea242a25a62e2e67eddde867e7e189\",\"title\":\"An Overview of Image Caption Generation Methods\",\"url\":\"https://www.semanticscholar.org/paper/4b652fa2b4ea242a25a62e2e67eddde867e7e189\",\"venue\":\"Comput. Intell. Neurosci.\",\"year\":2020},{\"arxivId\":\"1708.05271\",\"authors\":[{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2017.559\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"10480a42957a8e08e4c543185e135d7c254583a5\",\"title\":\"Incorporating Copying Mechanism in Image Captioning for Learning Novel Objects\",\"url\":\"https://www.semanticscholar.org/paper/10480a42957a8e08e4c543185e135d7c254583a5\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3490541\",\"name\":\"Aaron Chan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b775774edc1c2edcc9782f37eb2682cd01cfd94a\",\"title\":\"A Survey of Image Captioning Methods\",\"url\":\"https://www.semanticscholar.org/paper/b775774edc1c2edcc9782f37eb2682cd01cfd94a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1726159226\",\"name\":\"Xiangqing Shen\"},{\"authorId\":\"49167055\",\"name\":\"B. Liu\"},{\"authorId\":\"1697439\",\"name\":\"Yong Zhou\"},{\"authorId\":\"1491078664\",\"name\":\"Jiaqi Zhao\"}],\"doi\":\"10.1007/s11042-020-09294-7\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"20d2de48968f3ed1dc00be6ded0e2271d0f1a1a4\",\"title\":\"Remote sensing image caption generation via transformer and reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/20d2de48968f3ed1dc00be6ded0e2271d0f1a1a4\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"1905.12794\",\"authors\":[{\"authorId\":\"121433787\",\"name\":\"Xiaoxiao Guo\"},{\"authorId\":\"47987329\",\"name\":\"H. Wu\"},{\"authorId\":\"2926307\",\"name\":\"Yupeng Gao\"},{\"authorId\":\"2071376\",\"name\":\"Steven J. Rennie\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f472b819ce521337c01e4ebf91714f93413d9997\",\"title\":\"Fashion IQ: A New Dataset towards Retrieving Images by Natural Language Feedback\",\"url\":\"https://www.semanticscholar.org/paper/f472b819ce521337c01e4ebf91714f93413d9997\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1810.11536\",\"authors\":[{\"authorId\":\"145293956\",\"name\":\"Zhihao Zhu\"},{\"authorId\":\"14598300\",\"name\":\"Zhan Xue\"},{\"authorId\":\"33762094\",\"name\":\"Zejian Yuan\"}],\"doi\":\"10.1007/978-3-030-20876-9_12\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"695420559bd694f0fe084b64556e8241c3d02868\",\"title\":\"Automatic Graphics Program Generation using Attention-Based Hierarchical Decoder\",\"url\":\"https://www.semanticscholar.org/paper/695420559bd694f0fe084b64556e8241c3d02868\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"1703.09137\",\"authors\":[{\"authorId\":\"32227979\",\"name\":\"M. Tanti\"},{\"authorId\":\"1700894\",\"name\":\"Albert Gatt\"},{\"authorId\":\"2370774\",\"name\":\"K. Camilleri\"}],\"doi\":\"10.1017/S1351324918000098\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"6cc46899b415ebef4a70068b2cbd8a50e955aeb6\",\"title\":\"Where to put the Image in an Image Caption Generator\",\"url\":\"https://www.semanticscholar.org/paper/6cc46899b415ebef4a70068b2cbd8a50e955aeb6\",\"venue\":\"Nat. Lang. Eng.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50610439\",\"name\":\"Songtao Ding\"},{\"authorId\":\"2641875\",\"name\":\"Shiru Qu\"},{\"authorId\":\"6962569\",\"name\":\"Yuling Xi\"},{\"authorId\":\"31197849\",\"name\":\"Shaohua Wan\"}],\"doi\":\"10.1016/J.FUTURE.2018.10.054\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"36f66917c5726b0ff65fad588e24874fcfbc2c88\",\"title\":\"A long video caption generation algorithm for big video data retrieval\",\"url\":\"https://www.semanticscholar.org/paper/36f66917c5726b0ff65fad588e24874fcfbc2c88\",\"venue\":\"Future Gener. Comput. Syst.\",\"year\":2019},{\"arxivId\":\"1811.00228\",\"authors\":[{\"authorId\":\"143827145\",\"name\":\"Daouda Sow\"},{\"authorId\":\"70565757\",\"name\":\"Zengchang Qin\"},{\"authorId\":\"51910760\",\"name\":\"Mouhamed Niasse\"},{\"authorId\":\"46579572\",\"name\":\"T. Wan\"}],\"doi\":\"10.1109/ICASSP.2019.8682505\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f8ffba70ea41640a4f24fa22613f9e94bdc55576\",\"title\":\"A Sequential Guiding Network with Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/f8ffba70ea41640a4f24fa22613f9e94bdc55576\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66511580\",\"name\":\"Mirza Muhammad Ali Baig\"},{\"authorId\":\"67307335\",\"name\":\"Mian Ihtisham Shah\"},{\"authorId\":\"9223428\",\"name\":\"Muhammad Abdullah Wajahat\"},{\"authorId\":\"2384836\",\"name\":\"Nauman Zafar\"},{\"authorId\":\"1744665\",\"name\":\"Omar Arif\"}],\"doi\":\"10.1109/DICTA.2018.8615810\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d3aef1e8acf2b1760d7685d73f08d614f95ef75d\",\"title\":\"Image Caption Generator with Novel Object Injection\",\"url\":\"https://www.semanticscholar.org/paper/d3aef1e8acf2b1760d7685d73f08d614f95ef75d\",\"venue\":\"2018 Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"9764377\",\"name\":\"Xuanhan Wang\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"46399266\",\"name\":\"Yang Liu\"}],\"doi\":\"10.1016/J.NEUCOM.2018.06.096\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"31b28e96a337dfcf2dbfde104a1ec46f4e755844\",\"title\":\"Fused GRU with semantic-temporal attention for video captioning\",\"url\":\"https://www.semanticscholar.org/paper/31b28e96a337dfcf2dbfde104a1ec46f4e755844\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1917800589\",\"name\":\"Xuewei Ding\"},{\"authorId\":\"1918733632\",\"name\":\"Yehao Li\"},{\"authorId\":\"51018452\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"50190972\",\"name\":\"Dan Zeng\"},{\"authorId\":\"1917497790\",\"name\":\"Ting Yao\"}],\"doi\":\"10.1109/MIPR49039.2020.00065\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bf64558dad6729720abd47dd2dde281765baa079\",\"title\":\"Exploring Depth Information for Spatial Relation Recognition\",\"url\":\"https://www.semanticscholar.org/paper/bf64558dad6729720abd47dd2dde281765baa079\",\"venue\":\"2020 IEEE Conference on Multimedia Information Processing and Retrieval (MIPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152309767\",\"name\":\"L. Ma\"},{\"authorId\":\"119897463\",\"name\":\"Wenhao Jiang\"},{\"authorId\":\"2750647\",\"name\":\"Zequn Jie\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"40143631\",\"name\":\"W. Liu\"}],\"doi\":\"10.1109/TCSVT.2019.2916167\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4f15a43aba873c83f688fe3fd0d11eedb2398a23\",\"title\":\"Matching Image and Sentence With Multi-Faceted Representations\",\"url\":\"https://www.semanticscholar.org/paper/4f15a43aba873c83f688fe3fd0d11eedb2398a23\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"1807.00686\",\"authors\":[{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"145950948\",\"name\":\"Xue Li\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3aea4d43c157d8e2fcf692b172e2c1c1e4bae6ec\",\"title\":\"YH Technologies at ActivityNet Challenge 2018\",\"url\":\"https://www.semanticscholar.org/paper/3aea4d43c157d8e2fcf692b172e2c1c1e4bae6ec\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1707.07102\",\"authors\":[{\"authorId\":\"8135633\",\"name\":\"Xuwang Yin\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"}],\"doi\":\"10.18653/v1/D17-1017\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2cc6ba3dfd6bf1f6257b2e4651f4cae355284286\",\"title\":\"Obj2Text: Generating Visually Descriptive Language from Object Layouts\",\"url\":\"https://www.semanticscholar.org/paper/2cc6ba3dfd6bf1f6257b2e4651f4cae355284286\",\"venue\":\"EMNLP\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8280077\",\"name\":\"Yuyu Guo\"},{\"authorId\":\"3145905\",\"name\":\"Jingqiu Zhang\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"}],\"doi\":\"10.1007/s11280-018-0530-0\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a304bea200da57e4a7ee3ca6ad36b5496763a6d0\",\"title\":\"Exploiting long-term temporal dynamics for video captioning\",\"url\":\"https://www.semanticscholar.org/paper/a304bea200da57e4a7ee3ca6ad36b5496763a6d0\",\"venue\":\"World Wide Web\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48394426\",\"name\":\"Naeha Sharif\"},{\"authorId\":\"3256307\",\"name\":\"M. A. A. K. Jalwana\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"1980026040\",\"name\":\"Wei Liu\"},{\"authorId\":\"2210661\",\"name\":\"S. Shah\"}],\"doi\":\"10.1109/IVCNZ51579.2020.9290719\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8b88b5bc5fe9af08df2d953b1c14c6f5cacd9564\",\"title\":\"Leveraging Linguistically-aware Object Relations and NASNet for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/8b88b5bc5fe9af08df2d953b1c14c6f5cacd9564\",\"venue\":\"2020 35th International Conference on Image and Vision Computing New Zealand (IVCNZ)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1519969356\",\"name\":\"Xiaobo Wang\"},{\"authorId\":\"1500409356\",\"name\":\"Tianyu Fu\"},{\"authorId\":\"40397682\",\"name\":\"S. Liao\"},{\"authorId\":\"1390900682\",\"name\":\"S. Wang\"},{\"authorId\":\"1600629256\",\"name\":\"Zhen Lei\"},{\"authorId\":\"2004280042\",\"name\":\"Tao Mei\"}],\"doi\":\"10.1007/978-3-030-58586-0_20\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e8b78ce0d1749b4549b492f398db0c01b8a57841\",\"title\":\"Exclusivity-Consistency Regularized Knowledge Distillation for Face Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e8b78ce0d1749b4549b492f398db0c01b8a57841\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49418270\",\"name\":\"Yong Wang\"},{\"authorId\":\"1485232293\",\"name\":\"Wenkai Zhang\"},{\"authorId\":\"47362549\",\"name\":\"Qing Liu\"},{\"authorId\":\"9708577\",\"name\":\"Zhengyuan Zhang\"},{\"authorId\":\"11732382\",\"name\":\"X. Gao\"},{\"authorId\":\"9758599\",\"name\":\"Xi-an Sun\"}],\"doi\":\"10.1145/3394171.3413877\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a05a96d5d9bac88d7c8b34be2e57f58f17a6e53d\",\"title\":\"Improving Intra- and Inter-Modality Visual Relation for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/a05a96d5d9bac88d7c8b34be2e57f58f17a6e53d\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2001.05876\",\"authors\":[{\"authorId\":\"46659203\",\"name\":\"L. Wang\"},{\"authorId\":\"1486057423\",\"name\":\"Zechen Bai\"},{\"authorId\":\"48378975\",\"name\":\"Yonghua Zhang\"},{\"authorId\":\"37514286\",\"name\":\"H. Lu\"}],\"doi\":\"10.1609/aaai.v34i07.6898\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"85079d64d6fdd0ba5318fda119d152f2d2946391\",\"title\":\"Show, Recall, and Tell: Image Captioning with Recall Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/85079d64d6fdd0ba5318fda119d152f2d2946391\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38329336\",\"name\":\"G. Ding\"},{\"authorId\":\"8408809\",\"name\":\"M. Chen\"},{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"47666390\",\"name\":\"H. Chen\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"},{\"authorId\":\"47362455\",\"name\":\"Q. Liu\"}],\"doi\":\"10.1007/s12559-018-9581-x\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"848602d3de1b1ab9a06146e8b8f3f836cacbce91\",\"title\":\"Neural Image Caption Generation with Weighted Training and Reference\",\"url\":\"https://www.semanticscholar.org/paper/848602d3de1b1ab9a06146e8b8f3f836cacbce91\",\"venue\":\"Cognitive Computation\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152969844\",\"name\":\"N. Zakharov\"},{\"authorId\":\"144904238\",\"name\":\"H. Su\"},{\"authorId\":\"39197903\",\"name\":\"Jun Zhu\"},{\"authorId\":\"2151203\",\"name\":\"J. Gl\\u00e4scher\"}],\"doi\":\"10.1016/J.JVCIR.2019.102574\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1e0d5efef6e620050435280f8a3e2df982dce8ea\",\"title\":\"Towards controllable image descriptions with semi-supervised VAE\",\"url\":\"https://www.semanticscholar.org/paper/1e0d5efef6e620050435280f8a3e2df982dce8ea\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":\"1708.06742\",\"authors\":[{\"authorId\":\"1862138\",\"name\":\"Dmitriy Serdyuk\"},{\"authorId\":\"145604319\",\"name\":\"N. Ke\"},{\"authorId\":\"2041695\",\"name\":\"Alessandro Sordoni\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b44415a13f29ddc1af497b3876a2396673c3cfc0\",\"title\":\"Twin Networks: Using the Future as a Regularizer\",\"url\":\"https://www.semanticscholar.org/paper/b44415a13f29ddc1af497b3876a2396673c3cfc0\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1736464\",\"name\":\"M. Khademi\"},{\"authorId\":\"2166203\",\"name\":\"O. Schulte\"}],\"doi\":\"10.1109/CVPRW.2018.00260\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2bd5fceb1f885f690f63a58c289607c85069be3d\",\"title\":\"Image Caption Generation with Hierarchical Contextual Visual Spatial Attention\",\"url\":\"https://www.semanticscholar.org/paper/2bd5fceb1f885f690f63a58c289607c85069be3d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2018},{\"arxivId\":\"1904.03870\",\"authors\":[{\"authorId\":\"8511875\",\"name\":\"Jonghwan Mun\"},{\"authorId\":\"2889075\",\"name\":\"L. Yang\"},{\"authorId\":\"145888238\",\"name\":\"Zhou Ren\"},{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":\"10.1109/CVPR.2019.00675\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c5a757427132fda0c66e18a0d059eca8e2472d13\",\"title\":\"Streamlined Dense Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/c5a757427132fda0c66e18a0d059eca8e2472d13\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1812.06624\",\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5f3c111425a1e2f6316f01b9b0f3d09fa146b134\",\"title\":\"Feature Fusion Effects of Tensor Product Representation on (De)Compositional Network for Caption Generation for Images\",\"url\":\"https://www.semanticscholar.org/paper/5f3c111425a1e2f6316f01b9b0f3d09fa146b134\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145179162\",\"name\":\"Mingxing Zhang\"},{\"authorId\":\"144757965\",\"name\":\"Y. Yang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"50006507\",\"name\":\"Yanli Ji\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1109/TIP.2018.2855415\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"16a2a1bf612f9f9719a7945485f7e73324d18783\",\"title\":\"More is Better: Precise and Detailed Image Captioning Using Online Positive Recall and Missing Concepts Mining\",\"url\":\"https://www.semanticscholar.org/paper/16a2a1bf612f9f9719a7945485f7e73324d18783\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8275214\",\"name\":\"P. Tang\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"8194130\",\"name\":\"Qinyu Li\"}],\"doi\":\"10.1145/3303083\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"91aa0eb38446643cd622b060a76043b0ca2d7991\",\"title\":\"Rich Visual and Language Representation with Complementary Semantics for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/91aa0eb38446643cd622b060a76043b0ca2d7991\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145113946\",\"name\":\"J. Tang\"},{\"authorId\":\"144005516\",\"name\":\"Jing Wang\"},{\"authorId\":\"3233021\",\"name\":\"Zechao Li\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1145/3291925\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a437bb550d1df02188e4b145e01675551da36336\",\"title\":\"Show, Reward, and Tell\",\"url\":\"https://www.semanticscholar.org/paper/a437bb550d1df02188e4b145e01675551da36336\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"},{\"authorId\":\"88265392\",\"name\":\"P. Liu\"},{\"authorId\":\"3343198\",\"name\":\"Yingjie Zhou\"},{\"authorId\":\"144953181\",\"name\":\"D. Wu\"}],\"doi\":\"10.1109/BIGCOM.2019.00013\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a203fb561497774689ff4bb80cb18c9e00bf47b6\",\"title\":\"Semantic Tensor Product for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/a203fb561497774689ff4bb80cb18c9e00bf47b6\",\"venue\":\"2019 5th International Conference on Big Data Computing and Communications (BIGCOM)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47968201\",\"name\":\"Lixin Liu\"},{\"authorId\":\"46741143\",\"name\":\"Jiajun Tang\"},{\"authorId\":\"145078589\",\"name\":\"Xiaojun Wan\"},{\"authorId\":\"35310979\",\"name\":\"Zongming Guo\"}],\"doi\":\"10.1109/ICCV.2019.00434\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b774d6cd89cb27e62f03f183b89b7cacc412e131\",\"title\":\"Generating Diverse and Descriptive Image Captions Using Visual Paraphrases\",\"url\":\"https://www.semanticscholar.org/paper/b774d6cd89cb27e62f03f183b89b7cacc412e131\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145282222\",\"name\":\"C. Zhang\"},{\"authorId\":\"48625377\",\"name\":\"Weiming Li\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"81436348\",\"name\":\"Q. Wang\"},{\"authorId\":\"46392484\",\"name\":\"Wooshik Kim\"},{\"authorId\":\"48836299\",\"name\":\"Sunghoon Hong\"}],\"doi\":\"10.1145/3343031.3351063\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4dbc17138e7b610214359bb1659a30e01d183482\",\"title\":\"Referring Expression Comprehension with Semantic Visual Relationship and Word Mapping\",\"url\":\"https://www.semanticscholar.org/paper/4dbc17138e7b610214359bb1659a30e01d183482\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1912.06365\",\"authors\":[{\"authorId\":\"1443435125\",\"name\":\"Zhengcong Fei\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"38e48d6b39ce94ddc2a0bf20320598739187bfef\",\"title\":\"Fast Image Caption Generation with Position Alignment\",\"url\":\"https://www.semanticscholar.org/paper/38e48d6b39ce94ddc2a0bf20320598739187bfef\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1624658620\",\"name\":\"Chunlei Wu\"},{\"authorId\":\"1429199889\",\"name\":\"Shaozu Yuan\"},{\"authorId\":\"51172982\",\"name\":\"Haiwen Cao\"},{\"authorId\":\"19261873\",\"name\":\"Yiwei Wei\"},{\"authorId\":\"2250564\",\"name\":\"Leiquan Wang\"}],\"doi\":\"10.1109/ACCESS.2020.2981513\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"711be95a04da16c93b6bc880169532b68cdca37a\",\"title\":\"Hierarchical Attention-Based Fusion for Image Caption With Multi-Grained Rewards\",\"url\":\"https://www.semanticscholar.org/paper/711be95a04da16c93b6bc880169532b68cdca37a\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2001.09545\",\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"66a2eb540af6f47db177599bc793ab0c6a6aa47e\",\"title\":\"aiTPR: Attribute Interaction-Tensor Product Representation for Image Caption\",\"url\":\"https://www.semanticscholar.org/paper/66a2eb540af6f47db177599bc793ab0c6a6aa47e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"97713340\",\"name\":\"X. Liu\"},{\"authorId\":\"1943870\",\"name\":\"Weibin Liu\"},{\"authorId\":\"145767616\",\"name\":\"Weiwei Xing\"}],\"doi\":\"10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00152\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f55a588eef043cbb72ee548714d623b573c21e9b\",\"title\":\"Image Caption Generation with Local Semantic Information and Global Information\",\"url\":\"https://www.semanticscholar.org/paper/f55a588eef043cbb72ee548714d623b573c21e9b\",\"venue\":\"2019 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48520780\",\"name\":\"X. Yang\"},{\"authorId\":\"10817432\",\"name\":\"Kaihua Tang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"50490213\",\"name\":\"Jianfei Cai\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"38bbace118817cd18677f169a8c8e6c8b005df18\",\"title\":\"Auto-Encoding Graphical Inductive Bias for Descriptive Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/38bbace118817cd18677f169a8c8e6c8b005df18\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47824598\",\"name\":\"W. Wang\"},{\"authorId\":\"47814961\",\"name\":\"Y. Ding\"},{\"authorId\":\"2094026\",\"name\":\"Chunna Tian\"}],\"doi\":\"10.1109/ICASSP.2018.8461507\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"54969341ec539ddaaf7537b7353e3cea84790eac\",\"title\":\"A Novel Semantic Attribute-Based Feature for Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/54969341ec539ddaaf7537b7353e3cea84790eac\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":\"2002.06436\",\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4ad005019f7069a3aaff959fbaa657f2ef2143fc\",\"title\":\"MRRC: Multiple Role Representation Crossover Interpretation for Image Captioning With R-CNN Feature Distribution Composition (FDC)\",\"url\":\"https://www.semanticscholar.org/paper/4ad005019f7069a3aaff959fbaa657f2ef2143fc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.09580\",\"authors\":[{\"authorId\":\"41036094\",\"name\":\"C. Deng\"},{\"authorId\":\"46649124\",\"name\":\"Ning Ding\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"},{\"authorId\":\"1509240145\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1007/978-3-030-58601-0_42\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2320f853059c29ce7e70409fa559074d727da5a2\",\"title\":\"Length-Controllable Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/2320f853059c29ce7e70409fa559074d727da5a2\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1904.13148\",\"authors\":[{\"authorId\":\"3110609\",\"name\":\"Zhennan Wang\"},{\"authorId\":\"2568383\",\"name\":\"Wenbin Zou\"},{\"authorId\":\"144282087\",\"name\":\"C. Xu\"}],\"doi\":\"10.1109/ICCV.2019.00611\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b7c074e0fce985164989f0163cef8e7bb59a3612\",\"title\":\"PR Product: A Substitute for Inner Product in Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/b7c074e0fce985164989f0163cef8e7bb59a3612\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1808.04359\",\"authors\":[{\"authorId\":\"50714373\",\"name\":\"A. Agarwal\"},{\"authorId\":\"36960501\",\"name\":\"Swaminathan Gurumurthy\"},{\"authorId\":\"144582538\",\"name\":\"Vasu Sharma\"},{\"authorId\":\"35084211\",\"name\":\"M. Lewis\"},{\"authorId\":\"9076478\",\"name\":\"K. Sycara\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"79414eab0f7283af26c2fa9dd3db738fabe52c88\",\"title\":\"Community Regularization of Visually-Grounded Dialog\",\"url\":\"https://www.semanticscholar.org/paper/79414eab0f7283af26c2fa9dd3db738fabe52c88\",\"venue\":\"AAMAS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150197175\",\"name\":\"L. Zhou\"},{\"authorId\":\"49890476\",\"name\":\"Yuejie Zhang\"},{\"authorId\":\"49296155\",\"name\":\"Y. Jiang\"},{\"authorId\":\"145326655\",\"name\":\"Tao Zhang\"},{\"authorId\":\"145631869\",\"name\":\"W. Fan\"}],\"doi\":\"10.1109/TIP.2019.2928144\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"95db18799c539c82379585d25af66fd968ff000c\",\"title\":\"Re-Caption: Saliency-Enhanced Image Captioning Through Two-Phase Learning\",\"url\":\"https://www.semanticscholar.org/paper/95db18799c539c82379585d25af66fd968ff000c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144101175\",\"name\":\"Zhou Lei\"},{\"authorId\":\"1831825\",\"name\":\"Congcong Zhou\"},{\"authorId\":\"35155467\",\"name\":\"Shengbo Chen\"},{\"authorId\":\"1722738282\",\"name\":\"Yiyong Huang\"},{\"authorId\":\"1726027121\",\"name\":\"Xianrui Liu\"}],\"doi\":\"10.1109/ACCESS.2020.3024639\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e85fdae1b5e297f1d8925c9bd5cd7e243a305116\",\"title\":\"A Sparse Transformer-Based Approach for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/e85fdae1b5e297f1d8925c9bd5cd7e243a305116\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2007.03338\",\"authors\":[{\"authorId\":\"40651988\",\"name\":\"Marzieh Heidari\"},{\"authorId\":\"2862462\",\"name\":\"Mehdi Ghatee\"},{\"authorId\":\"1780566\",\"name\":\"A. Nickabadi\"},{\"authorId\":\"1796299590\",\"name\":\"Arash Pourhasan Nezhad\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"20b332af8399233b5fc33a7e7f98538bd4a82ab0\",\"title\":\"Diverse and Styled Image Captioning Using SVD-Based Mixture of Recurrent Experts\",\"url\":\"https://www.semanticscholar.org/paper/20b332af8399233b5fc33a7e7f98538bd4a82ab0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1908.11824\",\"authors\":[{\"authorId\":\"2265229\",\"name\":\"Lei Ke\"},{\"authorId\":\"1678473\",\"name\":\"W. Pei\"},{\"authorId\":\"47731271\",\"name\":\"Ruiyu Li\"},{\"authorId\":\"2029246\",\"name\":\"Xiaoyong Shen\"},{\"authorId\":\"5068280\",\"name\":\"Yu-Wing Tai\"}],\"doi\":\"10.1109/ICCV.2019.00898\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0db903dd28a3be3e57f40033c16cce574231f78e\",\"title\":\"Reflective Decoding Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0db903dd28a3be3e57f40033c16cce574231f78e\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1736464\",\"name\":\"M. Khademi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4819ce65a0322a748c6d606d0678e8a0f78dafcc\",\"title\":\"Graph neural networks for multimodal learning and representation\",\"url\":\"https://www.semanticscholar.org/paper/4819ce65a0322a748c6d606d0678e8a0f78dafcc\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9510649\",\"name\":\"Yongchao Xu\"},{\"authorId\":\"47687418\",\"name\":\"L. Ma\"},{\"authorId\":\"145338251\",\"name\":\"F. Yang\"},{\"authorId\":\"49068828\",\"name\":\"Y. Chen\"},{\"authorId\":\"123870263\",\"name\":\"K. Ma\"},{\"authorId\":\"30860323\",\"name\":\"Jiehua Yang\"},{\"authorId\":\"47008519\",\"name\":\"Xian Yang\"},{\"authorId\":\"7377810\",\"name\":\"Y. Chen\"},{\"authorId\":\"81623000\",\"name\":\"C. Shu\"},{\"authorId\":\"47774608\",\"name\":\"Z. Fan\"},{\"authorId\":\"1741261316\",\"name\":\"Jiefeng Gan\"},{\"authorId\":\"121488879\",\"name\":\"Xinyu Zou\"},{\"authorId\":\"1742024793\",\"name\":\"Renhao Huang\"},{\"authorId\":\"1409844494\",\"name\":\"Changzheng Zhang\"},{\"authorId\":\"1740642118\",\"name\":\"X. Liu\"},{\"authorId\":\"1741043296\",\"name\":\"Dandan Tu\"},{\"authorId\":\"82719817\",\"name\":\"Chu-ou Xu\"},{\"authorId\":\"1664633007\",\"name\":\"Wenqing Zhang\"},{\"authorId\":\"88577601\",\"name\":\"Dehua Yang\"},{\"authorId\":\"144534606\",\"name\":\"Ming-Wei Wang\"},{\"authorId\":\"47119872\",\"name\":\"X. Wang\"},{\"authorId\":\"1739184468\",\"name\":\"X. Xie\"},{\"authorId\":\"1739132210\",\"name\":\"Hongxiang Leng\"},{\"authorId\":\"39267896\",\"name\":\"N. Holalkere\"},{\"authorId\":\"2558731\",\"name\":\"Neil J. Halin\"},{\"authorId\":\"1786864\",\"name\":\"I. Kamel\"},{\"authorId\":\"10423763\",\"name\":\"J. Wu\"},{\"authorId\":\"1481856635\",\"name\":\"Xue-Hua Peng\"},{\"authorId\":\"15591977\",\"name\":\"X. Wang\"},{\"authorId\":\"48385032\",\"name\":\"Jianbo Shao\"},{\"authorId\":\"47774791\",\"name\":\"Pattanasak Mongkolwat\"},{\"authorId\":\"28021451\",\"name\":\"J. Zhang\"},{\"authorId\":\"143648587\",\"name\":\"D. Rubin\"},{\"authorId\":\"48738239\",\"name\":\"G. Wang\"},{\"authorId\":\"1740807372\",\"name\":\"Chuangsheng Zheng\"},{\"authorId\":\"49970107\",\"name\":\"Zike Li\"},{\"authorId\":\"145905113\",\"name\":\"X. Bai\"},{\"authorId\":\"1737585\",\"name\":\"T. Xia\"}],\"doi\":\"10.1101/2020.05.10.20096073\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cb3b31a9689432915797aa26a1f3191eaec335b5\",\"title\":\"A collaborative online AI engine for CT-based COVID-19 diagnosis\",\"url\":\"https://www.semanticscholar.org/paper/cb3b31a9689432915797aa26a1f3191eaec335b5\",\"venue\":\"medRxiv\",\"year\":2020},{\"arxivId\":\"1806.09278\",\"authors\":[{\"authorId\":\"49420316\",\"name\":\"Yuan Liu\"},{\"authorId\":\"50980046\",\"name\":\"Moyini Yao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8b87e33101a5564cbd3d212246aa48e2b6123227\",\"title\":\"Best Vision Technologies Submission to ActivityNet Challenge 2018-Task: Dense-Captioning Events in Videos\",\"url\":\"https://www.semanticscholar.org/paper/8b87e33101a5564cbd3d212246aa48e2b6123227\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1804.08286\",\"authors\":[{\"authorId\":\"1716661\",\"name\":\"Y. Zhang\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"1718355\",\"name\":\"Dong Liu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2018.00712\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7c30ee6470500f47eefacfa0560a8918e229138c\",\"title\":\"Fully Convolutional Adaptation Networks for Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/7c30ee6470500f47eefacfa0560a8918e229138c\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1811.00696\",\"authors\":[{\"authorId\":\"1940556\",\"name\":\"Ruiyi Zhang\"},{\"authorId\":\"2624978\",\"name\":\"C. Chen\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"2900282\",\"name\":\"W. Wang\"},{\"authorId\":\"50811121\",\"name\":\"Liqun Chen\"},{\"authorId\":\"19178763\",\"name\":\"Dinghan Shen\"},{\"authorId\":\"1700522\",\"name\":\"Guoyin Wang\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"261783ef9c98986652ee11c4df20173edafae826\",\"title\":\"Sequence Generation with Guider Network\",\"url\":\"https://www.semanticscholar.org/paper/261783ef9c98986652ee11c4df20173edafae826\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2250564\",\"name\":\"Leiquan Wang\"},{\"authorId\":\"15862607\",\"name\":\"Xiaoliang Chu\"},{\"authorId\":\"1954076\",\"name\":\"W. Zhang\"},{\"authorId\":\"19261873\",\"name\":\"Yiwei Wei\"},{\"authorId\":\"2037988\",\"name\":\"Weichen Sun\"},{\"authorId\":\"32324177\",\"name\":\"C. Wu\"}],\"doi\":\"10.3390/s18020646\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e4b9c14951cea6259dd9d522586ba2c5bb1fbcce\",\"title\":\"Social Image Captioning: Exploring Visual Attention and User Attention\",\"url\":\"https://www.semanticscholar.org/paper/e4b9c14951cea6259dd9d522586ba2c5bb1fbcce\",\"venue\":\"Sensors\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47956883\",\"name\":\"Xiangrong Zhang\"},{\"authorId\":null,\"name\":\"Xin Wang\"},{\"authorId\":\"144474380\",\"name\":\"X. Tang\"},{\"authorId\":\"46544755\",\"name\":\"Huiyu Zhou\"},{\"authorId\":\"33161908\",\"name\":\"C. Li\"}],\"doi\":\"10.3390/rs11060612\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"944e93e74379afedced307ca30fc6d31365dc96e\",\"title\":\"Description Generation for Remote Sensing Images Using Attribute Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/944e93e74379afedced307ca30fc6d31365dc96e\",\"venue\":\"Remote. Sens.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52366010\",\"name\":\"Zhi-bin Guan\"},{\"authorId\":\"49600007\",\"name\":\"Kang Liu\"},{\"authorId\":\"47009350\",\"name\":\"Yan Ma\"},{\"authorId\":\"144222488\",\"name\":\"Xu Qian\"},{\"authorId\":\"35260608\",\"name\":\"Tongkai Ji\"}],\"doi\":\"10.3390/sym10110626\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d6b701c003c3aecfdbcf1700496cde74ea05642\",\"title\":\"Sequential Dual Attention: Coarse-to-Fine-Grained Hierarchical Generation for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0d6b701c003c3aecfdbcf1700496cde74ea05642\",\"venue\":\"Symmetry\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"34779291\",\"name\":\"Fuchen Long\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"153216896\",\"name\":\"D. Li\"},{\"authorId\":\"153040576\",\"name\":\"T. Mei\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c3ecbfb72986111f3489704e9fe4a12175b0240\",\"title\":\"MSR Asia MSM at ActivityNet Challenge 2017: Trimmed Action Recognition, Temporal Action Proposals and Dense-Captioning Events in Videos\",\"url\":\"https://www.semanticscholar.org/paper/6c3ecbfb72986111f3489704e9fe4a12175b0240\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47767554\",\"name\":\"L. Wu\"},{\"authorId\":\"40444400\",\"name\":\"M. Xu\"},{\"authorId\":\"1783122\",\"name\":\"J. Wang\"},{\"authorId\":\"144242192\",\"name\":\"Stuart Perry\"}],\"doi\":\"10.1109/TMM.2019.2931815\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5b8b83bbb8ea54873be904ff77b1764267b3bd33\",\"title\":\"Recall What You See Continually Using GridLSTM in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/5b8b83bbb8ea54873be904ff77b1764267b3bd33\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"1911.03738\",\"authors\":[{\"authorId\":\"32227979\",\"name\":\"Marc Tanti\"},{\"authorId\":\"145464131\",\"name\":\"Albert Gatt\"},{\"authorId\":\"2370774\",\"name\":\"Kenneth P. Camilleri\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"a55f5de768a455ab01fbe0432962f2f6f1a0a7db\",\"title\":\"On Architectures for Including Visual Information in Neural Language Models for Image Description\",\"url\":\"https://www.semanticscholar.org/paper/a55f5de768a455ab01fbe0432962f2f6f1a0a7db\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47458613\",\"name\":\"A. Tripathi\"},{\"authorId\":\"145305735\",\"name\":\"Siddharth Srivastava\"},{\"authorId\":\"144174561\",\"name\":\"R. Kothari\"}],\"doi\":\"10.1007/978-3-030-04780-1_23\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a819e54b2d980dcff85ac8ab13801178aac5b59a\",\"title\":\"Deep Neural Network Based Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/a819e54b2d980dcff85ac8ab13801178aac5b59a\",\"venue\":\"BDA\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9728275\",\"name\":\"Huanhou Xiao\"},{\"authorId\":\"34875762\",\"name\":\"J. Shi\"}],\"doi\":\"10.1109/ICIP.2019.8803785\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"da0cce8d791ca90b01696c6ef0de96c7904dd8cf\",\"title\":\"A Novel Attribute Selection Mechanism for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/da0cce8d791ca90b01696c6ef0de96c7904dd8cf\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"1708.04390\",\"authors\":[{\"authorId\":\"2896042\",\"name\":\"Weiyu Lan\"},{\"authorId\":\"9931285\",\"name\":\"Xirong Li\"},{\"authorId\":\"40240283\",\"name\":\"J. Dong\"}],\"doi\":\"10.1145/3123266.3123366\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"39f3f9d22a072d0ccf423aa31bacbb4071ac0644\",\"title\":\"Fluency-Guided Cross-Lingual Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/39f3f9d22a072d0ccf423aa31bacbb4071ac0644\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":\"1801.08186\",\"authors\":[{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"145527707\",\"name\":\"Zhe L. Lin\"},{\"authorId\":\"1720987\",\"name\":\"X. Shen\"},{\"authorId\":\"1768964\",\"name\":\"Jimei Yang\"},{\"authorId\":\"145574672\",\"name\":\"Xin Lu\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/CVPR.2018.00142\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fdce9cbe5c726201575b3c8a8c1af0752f1af53f\",\"title\":\"MAttNet: Modular Attention Network for Referring Expression Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/fdce9cbe5c726201575b3c8a8c1af0752f1af53f\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2206630\",\"name\":\"A. Yu\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1007/s11263-020-01344-9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8576b8bb3cee30feef33f6bc9cbe9880c6e4a076\",\"title\":\"Densifying Supervision for Fine-Grained Visual Comparisons\",\"url\":\"https://www.semanticscholar.org/paper/8576b8bb3cee30feef33f6bc9cbe9880c6e4a076\",\"venue\":\"International Journal of Computer Vision\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38889850\",\"name\":\"Pengfei Xia\"},{\"authorId\":\"50774917\",\"name\":\"Jingsong He\"},{\"authorId\":\"153781930\",\"name\":\"Jin Yin\"}],\"doi\":\"10.1007/s11042-020-09110-2\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"17cefd99f2d04fc01663ba261d6afee54e8408d5\",\"title\":\"Boosting image caption generation with feature fusion module\",\"url\":\"https://www.semanticscholar.org/paper/17cefd99f2d04fc01663ba261d6afee54e8408d5\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"2012.07061\",\"authors\":[{\"authorId\":\"9665187\",\"name\":\"Jiayi Ji\"},{\"authorId\":\"46491945\",\"name\":\"Yunpeng Luo\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"2642638\",\"name\":\"F. Chen\"},{\"authorId\":\"1993645531\",\"name\":\"Gen Luo\"},{\"authorId\":\"47096329\",\"name\":\"Yongjian Wu\"},{\"authorId\":\"40366236\",\"name\":\"Yue Gao\"},{\"authorId\":\"1572139630\",\"name\":\"Rongrong Ji\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7217b5d8d0fb753532026cc36b0aaa056960c6f8\",\"title\":\"Improving Image Captioning by Leveraging Intra- and Inter-layer Global Representation in Transformer Network\",\"url\":\"https://www.semanticscholar.org/paper/7217b5d8d0fb753532026cc36b0aaa056960c6f8\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36595248\",\"name\":\"Fang Fang\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"8275214\",\"name\":\"P. Tang\"}],\"doi\":\"10.1109/ICIP.2018.8451558\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c5f6ed9efc222fe2773135ffb4e5c567d98e64ea\",\"title\":\"Image Captioning with Word Level Attention\",\"url\":\"https://www.semanticscholar.org/paper/c5f6ed9efc222fe2773135ffb4e5c567d98e64ea\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":\"1611.07675\",\"authors\":[{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2017.111\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0d3b5ffff118326fea73341a86a7c29423eb95f0\",\"title\":\"Video Captioning with Transferred Semantic Attributes\",\"url\":\"https://www.semanticscholar.org/paper/0d3b5ffff118326fea73341a86a7c29423eb95f0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36595248\",\"name\":\"Fang Fang\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"50581334\",\"name\":\"Y. Chen\"},{\"authorId\":\"8275214\",\"name\":\"P. Tang\"}],\"doi\":\"10.1007/s11042-018-6228-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c580b0a8dc655a8831ddbb7954bb929b1f236ebc\",\"title\":\"Looking deeper and transferring attention for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/c580b0a8dc655a8831ddbb7954bb929b1f236ebc\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46583706\",\"name\":\"J. Wang\"},{\"authorId\":\"145200778\",\"name\":\"Wei Wang\"},{\"authorId\":\"123865558\",\"name\":\"Liang Wang\"},{\"authorId\":\"50857536\",\"name\":\"Z. Wang\"},{\"authorId\":\"145855523\",\"name\":\"D. Feng\"},{\"authorId\":\"145808910\",\"name\":\"Tieniu Tan\"}],\"doi\":\"10.1016/j.patcog.2019.107075\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"70b03dfb947ca136e3476c9f49b8f6b044d0c1d9\",\"title\":\"Learning visual relationship and context-aware attention for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/70b03dfb947ca136e3476c9f49b8f6b044d0c1d9\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":\"1805.12589\",\"authors\":[{\"authorId\":\"31121723\",\"name\":\"A. Deshpande\"},{\"authorId\":\"29956361\",\"name\":\"Jyoti Aneja\"},{\"authorId\":\"39709900\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"144016256\",\"name\":\"D. Forsyth\"}],\"doi\":\"10.1109/CVPR.2019.01095\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e7fe886600399448f3282c8da8fd98ab7e50eae3\",\"title\":\"Fast, Diverse and Accurate Image Captioning Guided by Part-Of-Speech\",\"url\":\"https://www.semanticscholar.org/paper/e7fe886600399448f3282c8da8fd98ab7e50eae3\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1443435125\",\"name\":\"Zhengcong Fei\"}],\"doi\":\"10.1145/3372278.3390679\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f1fd4006dd7edbdf6c28fb6db21c59dda8e16d08\",\"title\":\"Actor-Critic Sequence Generation for Relative Difference Captioning\",\"url\":\"https://www.semanticscholar.org/paper/f1fd4006dd7edbdf6c28fb6db21c59dda8e16d08\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":\"1809.06227\",\"authors\":[{\"authorId\":\"3441420\",\"name\":\"Tszhang Guo\"},{\"authorId\":\"3307026\",\"name\":\"S. Chang\"},{\"authorId\":\"2482533\",\"name\":\"Mo Yu\"},{\"authorId\":\"144654778\",\"name\":\"K. Bai\"}],\"doi\":\"10.18653/v1/D18-1083\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a78199a2cc678818489087454fe1150db4870196\",\"title\":\"Improving Reinforcement Learning Based Image Captioning with Natural Language Prior\",\"url\":\"https://www.semanticscholar.org/paper/a78199a2cc678818489087454fe1150db4870196\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5482750\",\"name\":\"J. Wang\"},{\"authorId\":\"145200778\",\"name\":\"Wei Wang\"},{\"authorId\":\"49867037\",\"name\":\"Y. Huang\"},{\"authorId\":\"1693997\",\"name\":\"Liang Wang\"},{\"authorId\":\"143874948\",\"name\":\"T. Tan\"}],\"doi\":\"10.1145/3240508.3240538\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"72f9116a04e584081635500e9f0789fa26e4d15f\",\"title\":\"Hierarchical Memory Modelling for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/72f9116a04e584081635500e9f0789fa26e4d15f\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1809.04144\",\"authors\":[{\"authorId\":\"3238408\",\"name\":\"P. Madhyastha\"},{\"authorId\":\"2635321\",\"name\":\"Josiah Wang\"},{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6610cecb59fdd108c8fcb73cac3562fa10d5e845\",\"title\":\"End-to-end Image Captioning Exploits Multimodal Distributional Similarity\",\"url\":\"https://www.semanticscholar.org/paper/6610cecb59fdd108c8fcb73cac3562fa10d5e845\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49544460\",\"name\":\"Xuejing Liu\"},{\"authorId\":\"143931909\",\"name\":\"L. Li\"},{\"authorId\":\"47672591\",\"name\":\"Shuhui Wang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"49356099\",\"name\":\"Dechao Meng\"},{\"authorId\":\"1689702\",\"name\":\"Q. Huang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8e59f4cd2651ffb36a6009231dead1cae16d5987\",\"title\":\"Language Attention Proposal Attention + Training Inference man in white on the left holding a bat Subject Location Context Input query Input image\",\"url\":\"https://www.semanticscholar.org/paper/8e59f4cd2651ffb36a6009231dead1cae16d5987\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1909.03918\",\"authors\":[{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/ICCV.2019.00271\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"05106b86ec45914d1136719d311078182d437872\",\"title\":\"Hierarchy Parsing for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/05106b86ec45914d1136719d311078182d437872\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1908.10568\",\"authors\":[{\"authorId\":\"49544460\",\"name\":\"Xuejing Liu\"},{\"authorId\":\"143931909\",\"name\":\"L. Li\"},{\"authorId\":\"47672591\",\"name\":\"Shuhui Wang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"49356099\",\"name\":\"Dechao Meng\"},{\"authorId\":\"1689702\",\"name\":\"Q. Huang\"}],\"doi\":\"10.1109/ICCV.2019.00270\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"958f102ce7fdaa9f2467f0c2f6b3071b824394af\",\"title\":\"Adaptive Reconstruction Network for Weakly Supervised Referring Expression Grounding\",\"url\":\"https://www.semanticscholar.org/paper/958f102ce7fdaa9f2467f0c2f6b3071b824394af\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3409740\",\"name\":\"Ziyu Xue\"},{\"authorId\":\"39494411\",\"name\":\"Lei Wang\"},{\"authorId\":\"2834810\",\"name\":\"Peiyu Guo\"}],\"doi\":\"10.1109/icis46139.2019.8940218\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7344b254af85b53c5e989579b1d18fbf946c03de\",\"title\":\"Slot based Image Captioning with WGAN\",\"url\":\"https://www.semanticscholar.org/paper/7344b254af85b53c5e989579b1d18fbf946c03de\",\"venue\":\"2019 IEEE/ACIS 18th International Conference on Computer and Information Science (ICIS)\",\"year\":2019},{\"arxivId\":\"1812.03426\",\"authors\":[{\"authorId\":\"3179887\",\"name\":\"Xinpeng Chen\"},{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"47740660\",\"name\":\"Jingyuan Chen\"},{\"authorId\":\"2750647\",\"name\":\"Zequn Jie\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e9db75c5dc7c2a11f3623ac5f83aa7a5297951bb\",\"title\":\"Real-Time Referring Expression Comprehension by Single-Stage Grounding Network\",\"url\":\"https://www.semanticscholar.org/paper/e9db75c5dc7c2a11f3623ac5f83aa7a5297951bb\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1905.07841\",\"authors\":[{\"authorId\":\"9919436\",\"name\":\"J. Yu\"},{\"authorId\":\"31115234\",\"name\":\"Jing Li\"},{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"},{\"authorId\":\"1689702\",\"name\":\"Q. Huang\"}],\"doi\":\"10.1109/TCSVT.2019.2947482\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"99b5153235b0ee583803bbd7cd6bd9da161d5348\",\"title\":\"Multimodal Transformer With Multi-View Visual Representation for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/99b5153235b0ee583803bbd7cd6bd9da161d5348\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"1805.07112\",\"authors\":[{\"authorId\":\"1828568\",\"name\":\"Chen Chen\"},{\"authorId\":\"39108991\",\"name\":\"Shuai Mu\"},{\"authorId\":\"1410650653\",\"name\":\"Wanpeng Xiao\"},{\"authorId\":\"1410066883\",\"name\":\"Zexiong Ye\"},{\"authorId\":\"1410052649\",\"name\":\"Liesi Wu\"},{\"authorId\":\"102396462\",\"name\":\"Fuming Ma\"},{\"authorId\":\"34974680\",\"name\":\"Q. Ju\"}],\"doi\":\"10.1609/aaai.v33i01.33018142\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0daa3a4118e00b9f63b2d014a16ff1bc3ca9ff7e\",\"title\":\"Improving Image Captioning with Conditional Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/0daa3a4118e00b9f63b2d014a16ff1bc3ca9ff7e\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"2007.10662\",\"authors\":[{\"authorId\":\"69544685\",\"name\":\"Jie Wu\"},{\"authorId\":\"1765674\",\"name\":\"Tianshui Chen\"},{\"authorId\":\"1721715\",\"name\":\"Hefeng Wu\"},{\"authorId\":\"10665619\",\"name\":\"Z. Yang\"},{\"authorId\":\"1773818\",\"name\":\"Guangchun Luo\"},{\"authorId\":\"49478124\",\"name\":\"L. Lin\"}],\"doi\":\"10.1109/tmm.2020.3011317\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f0edc8eb2d2b53482faf34906dacf996bc4127f6\",\"title\":\"Fine-Grained Image Captioning with Global-Local Discriminative Objective\",\"url\":\"https://www.semanticscholar.org/paper/f0edc8eb2d2b53482faf34906dacf996bc4127f6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1904.02633\",\"authors\":[{\"authorId\":\"3026553\",\"name\":\"G. Liu\"},{\"authorId\":\"31375865\",\"name\":\"T. H. Hsu\"},{\"authorId\":\"41153596\",\"name\":\"Matthew B. A. McDermott\"},{\"authorId\":\"31809608\",\"name\":\"Willie Boag\"},{\"authorId\":\"2088565\",\"name\":\"Wei-Hung Weng\"},{\"authorId\":\"1679873\",\"name\":\"Peter Szolovits\"},{\"authorId\":\"145348788\",\"name\":\"M. Ghassemi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"435d5d96daff445bcc5f44a0e3cecdc46d4120d9\",\"title\":\"Clinically Accurate Chest X-Ray Report Generation\",\"url\":\"https://www.semanticscholar.org/paper/435d5d96daff445bcc5f44a0e3cecdc46d4120d9\",\"venue\":\"MLHC\",\"year\":2019},{\"arxivId\":\"2009.13862\",\"authors\":[{\"authorId\":\"50232214\",\"name\":\"Wenjia Xu\"},{\"authorId\":\"51175635\",\"name\":\"Jiuniu Wang\"},{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"3287827\",\"name\":\"Guangluan Xu\"},{\"authorId\":\"7413451\",\"name\":\"Daoyu Lin\"},{\"authorId\":\"1379498558\",\"name\":\"Wei Dai\"},{\"authorId\":\"48607717\",\"name\":\"Y. Wu\"}],\"doi\":\"10.1109/JSTSP.2020.2987729\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7c056c388f4deb0ff87932eb6e7789b23eb22d22\",\"title\":\"Where is the Model Looking At? \\u2013 Concentrate and Explain the Network Attention\",\"url\":\"https://www.semanticscholar.org/paper/7c056c388f4deb0ff87932eb6e7789b23eb22d22\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020},{\"arxivId\":\"1909.02489\",\"authors\":[{\"authorId\":\"47748186\",\"name\":\"Wei Wei\"},{\"authorId\":\"144996789\",\"name\":\"L. Cheng\"},{\"authorId\":\"2089102\",\"name\":\"X. Mao\"},{\"authorId\":\"143652253\",\"name\":\"G. Zhou\"},{\"authorId\":\"143663410\",\"name\":\"F. Zhu\"}],\"doi\":\"10.1109/ACCESS.2020.3018752\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b1e8e509a62c424055ffc050dc7cb41329674ea9\",\"title\":\"Stack-VS: Stacked Visual-Semantic Attention for Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/b1e8e509a62c424055ffc050dc7cb41329674ea9\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4942547\",\"name\":\"Zongjian Zhang\"},{\"authorId\":\"145698633\",\"name\":\"Q. Wu\"},{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"145093625\",\"name\":\"F. Chen\"}],\"doi\":\"10.1109/WACV.2018.00190\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"6107d5107e7e0d94a3f0f43b642c4cfd1cba3b79\",\"title\":\"Fine-Grained and Semantic-Guided Visual Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6107d5107e7e0d94a3f0f43b642c4cfd1cba3b79\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"101726081\",\"name\":\"S. Rawat\"},{\"authorId\":\"1992911636\",\"name\":\"Kartikeyan Singh Rawat\"},{\"authorId\":\"1381574702\",\"name\":\"Rahul Nijhawan\"}],\"doi\":\"10.1109/ICSSIT48917.2020.9214109\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0c73865aa2634a5e6b0099fe49221d1e56a2b875\",\"title\":\"A Novel Convolutional Neural Network-Gated Recurrent Unit approach for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0c73865aa2634a5e6b0099fe49221d1e56a2b875\",\"venue\":\"2020 Third International Conference on Smart Systems and Inventive Technology (ICSSIT)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1978802390\",\"name\":\"Haolei Pei\"},{\"authorId\":\"8559954\",\"name\":\"Q. Chen\"},{\"authorId\":\"13257164\",\"name\":\"J. Wang\"},{\"authorId\":\"123555217\",\"name\":\"Q. Sun\"},{\"authorId\":\"1680030\",\"name\":\"Yubo Jia\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206815\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"129f71acdcec4b171a4f11beec4f10463d5ffa38\",\"title\":\"Visual Relational Reasoning for Image Caption\",\"url\":\"https://www.semanticscholar.org/paper/129f71acdcec4b171a4f11beec4f10463d5ffa38\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144469308\",\"name\":\"Jian Wang\"},{\"authorId\":\"145534714\",\"name\":\"Jie Feng\"}],\"doi\":\"10.1109/ACCESS.2020.3018546\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"123361e4769f2f8a17742197aa52cc676a4caa9a\",\"title\":\"Hybrid Attention Distribution and Factorized Embedding Matrix in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/123361e4769f2f8a17742197aa52cc676a4caa9a\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1783874\",\"name\":\"T. Wang\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"},{\"authorId\":\"144751998\",\"name\":\"C. He\"}],\"doi\":\"10.1007/s11063-019-09979-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a54a18073b4b4a788e106d540d26817c8c898a63\",\"title\":\"Image Caption with Endogenous\\u2013Exogenous Attention\",\"url\":\"https://www.semanticscholar.org/paper/a54a18073b4b4a788e106d540d26817c8c898a63\",\"venue\":\"Neural Processing Letters\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Nannan Li\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"}],\"doi\":\"10.24963/ijcai.2018/110\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"47921216d4758a16cf7b5bfc85cc7b9178bffe6a\",\"title\":\"Image Cationing with Visual-Semantic LSTM\",\"url\":\"https://www.semanticscholar.org/paper/47921216d4758a16cf7b5bfc85cc7b9178bffe6a\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152747612\",\"name\":\"Zhenyu Yang\"},{\"authorId\":\"153874396\",\"name\":\"Qiao Liu\"}],\"doi\":\"10.1109/ACCESS.2020.2980578\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"059093bc3bb44949e9754fb4366f0be7cea34bac\",\"title\":\"ATT-BM-SOM: A Framework of Effectively Choosing Image Information and Optimizing Syntax for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/059093bc3bb44949e9754fb4366f0be7cea34bac\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1384259000\",\"name\":\"Muchao Ye\"},{\"authorId\":\"47353599\",\"name\":\"M. Dai\"},{\"authorId\":\"50251617\",\"name\":\"Z. Zhou\"},{\"authorId\":\"19183333\",\"name\":\"Ruzheng Zhao\"}],\"doi\":\"10.23919/ChiCC.2019.8866119\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cd194a673633fb0e68f8827e172edf62e1c03257\",\"title\":\"Local Statistical Active Contour Energy Functional based on Cauchy-Schwarz Divergence for Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/cd194a673633fb0e68f8827e172edf62e1c03257\",\"venue\":\"2019 Chinese Control Conference (CCC)\",\"year\":2019},{\"arxivId\":\"1906.00283\",\"authors\":[{\"authorId\":\"7437104\",\"name\":\"Chih-Yao Ma\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"9202076\",\"name\":\"G. Al-Regib\"},{\"authorId\":\"122175026\",\"name\":\"P\\u00e9ter Vajda\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"145276578\",\"name\":\"Z. Kira\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"93c7166af45c86caec363e0b84dfd85ed3b51acc\",\"title\":\"Learning to Generate Grounded Image Captions without Localization Supervision\",\"url\":\"https://www.semanticscholar.org/paper/93c7166af45c86caec363e0b84dfd85ed3b51acc\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"7896029\",\"name\":\"Yuanxin Liu\"},{\"authorId\":\"19169659\",\"name\":\"Xuancheng Ren\"},{\"authorId\":\"145558284\",\"name\":\"Kai Lei\"},{\"authorId\":\"2511091\",\"name\":\"X. Sun\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4eb0b7ced6c022eef4c6fb2ed3dcdbdccfc056dc\",\"title\":\"Aligning Visual Regions and Textual Concepts: Learning Fine-Grained Image Representations for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/4eb0b7ced6c022eef4c6fb2ed3dcdbdccfc056dc\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3491491\",\"name\":\"Shiyang Yan\"},{\"authorId\":\"151472634\",\"name\":\"Y. Hua\"},{\"authorId\":\"46406827\",\"name\":\"N. Robertson\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9f964bc4f8405491bc69c9e03e6f466ec609b9dd\",\"title\":\"SC-RANK: Improving Convolutional Image Captioning with Self-Critical Learning and Ranking Metric-based Reward\",\"url\":\"https://www.semanticscholar.org/paper/9f964bc4f8405491bc69c9e03e6f466ec609b9dd\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7504183\",\"name\":\"B. Zhang\"},{\"authorId\":\"50703807\",\"name\":\"L. Li\"},{\"authorId\":\"153142919\",\"name\":\"Li Su\"},{\"authorId\":\"47672591\",\"name\":\"Shuhui Wang\"},{\"authorId\":\"1994580036\",\"name\":\"Jincan Deng\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"153159021\",\"name\":\"Qingming Huang\"}],\"doi\":\"10.1145/3394171.3413885\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4b0209f6fa41030e7e590f2cb5568f47563a759a\",\"title\":\"Structural Semantic Adversarial Active Learning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/4b0209f6fa41030e7e590f2cb5568f47563a759a\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1805.07030\",\"authors\":[{\"authorId\":\"3175685\",\"name\":\"A. Mathews\"},{\"authorId\":\"33650938\",\"name\":\"Lexing Xie\"},{\"authorId\":\"33913193\",\"name\":\"Xuming He\"}],\"doi\":\"10.1109/CVPR.2018.00896\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"beeebd2af0d8f130dcf234231de4569d584cb7fd\",\"title\":\"SemStyle: Learning to Generate Stylised Image Captions Using Unaligned Text\",\"url\":\"https://www.semanticscholar.org/paper/beeebd2af0d8f130dcf234231de4569d584cb7fd\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1905.10521\",\"authors\":[{\"authorId\":\"2490092\",\"name\":\"Kyungwoo Song\"},{\"authorId\":\"91586945\",\"name\":\"Joonho Jang\"},{\"authorId\":\"120296402\",\"name\":\"Seung-Jae Shin\"},{\"authorId\":\"1729306\",\"name\":\"I. Moon\"}],\"doi\":\"10.1609/AAAI.V34I04.6039\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"61bb0b9bf5aba11ab06e2a578ba32b21c4bd6611\",\"title\":\"Bivariate Beta LSTM\",\"url\":\"https://www.semanticscholar.org/paper/61bb0b9bf5aba11ab06e2a578ba32b21c4bd6611\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2007.02375\",\"authors\":[{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"5891694\",\"name\":\"J. Luo\"},{\"authorId\":\"37184350\",\"name\":\"J. Xu\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"1490772804\",\"name\":\"Tao Mei\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ad9d41b29f7b7b35278f466dc2eafedaf7f57db1\",\"title\":\"Auto-captions on GIF: A Large-scale Video-sentence Dataset for Vision-language Pre-training\",\"url\":\"https://www.semanticscholar.org/paper/ad9d41b29f7b7b35278f466dc2eafedaf7f57db1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1910.06426\",\"authors\":[{\"authorId\":\"23999166\",\"name\":\"Shuangjie Xu\"},{\"authorId\":\"143979421\",\"name\":\"F. Xu\"},{\"authorId\":\"153655416\",\"name\":\"Yu Cheng\"},{\"authorId\":\"145232778\",\"name\":\"Pan Zhou\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dc9b8dbd11e3786d6f8dee167a8b8353a0b8ffd1\",\"title\":\"Tell-the-difference: Fine-grained Visual Descriptor via a Discriminating Referee\",\"url\":\"https://www.semanticscholar.org/paper/dc9b8dbd11e3786d6f8dee167a8b8353a0b8ffd1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"28909797\",\"name\":\"Xiyao Fu\"},{\"authorId\":\"2105743\",\"name\":\"Y. Bin\"},{\"authorId\":null,\"name\":\"Zheng Wang\"},{\"authorId\":\"143760554\",\"name\":\"Q. Wei\"},{\"authorId\":\"47336231\",\"name\":\"S. Chen\"}],\"doi\":\"10.1007/978-3-030-26075-0_4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"42c6c030ea35449ee824cbab20031add67d1f999\",\"title\":\"Supervised Hashing with Recurrent Scaling\",\"url\":\"https://www.semanticscholar.org/paper/42c6c030ea35449ee824cbab20031add67d1f999\",\"venue\":\"APWeb/WAIM\",\"year\":2019},{\"arxivId\":\"1804.08264\",\"authors\":[{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1145/3123266.3127905\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"883224c3b28b0563a393746066738f52e6fcc70d\",\"title\":\"To Create What You Tell: Generating Videos from Captions\",\"url\":\"https://www.semanticscholar.org/paper/883224c3b28b0563a393746066738f52e6fcc70d\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":\"1710.02534\",\"authors\":[{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"83d66c1f808962536a68418587b691f30221c5a1\",\"title\":\"Contrastive Learning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/83d66c1f808962536a68418587b691f30221c5a1\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48394426\",\"name\":\"Naeha Sharif\"},{\"authorId\":\"8799308\",\"name\":\"U. Nadeem\"},{\"authorId\":\"14752125\",\"name\":\"Syed Afaq Ali Shah\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"1980026040\",\"name\":\"Wei Liu\"}],\"doi\":\"10.1007/978-3-030-49724-8_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8885ae1cbdac1d27443167689ed872dfe46c9e3f\",\"title\":\"Vision to Language: Methods, Metrics and Datasets\",\"url\":\"https://www.semanticscholar.org/paper/8885ae1cbdac1d27443167689ed872dfe46c9e3f\",\"venue\":\"\",\"year\":2020}],\"corpusId\":1868294,\"doi\":\"10.1109/ICCV.2017.524\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":41,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"5785466bc14529e94e54baa4ed051f7037f3b1d3\",\"references\":[{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2358515\",\"name\":\"Gabriel Murray\"},{\"authorId\":\"47996780\",\"name\":\"S. Renals\"},{\"authorId\":\"50717217\",\"name\":\"J. Carletta\"},{\"authorId\":\"81479509\",\"name\":\"J. D. Moore\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"4774432f02ef4c5285952dd8c7daff0852c3a601\",\"title\":\"Proceedings of the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization\",\"url\":\"https://www.semanticscholar.org/paper/4774432f02ef4c5285952dd8c7daff0852c3a601\",\"venue\":\"ACL 2005\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3285716\",\"name\":\"Xinye Lin\"},{\"authorId\":\"9527255\",\"name\":\"Yixin Chen\"},{\"authorId\":\"1871246\",\"name\":\"X. Chang\"},{\"authorId\":\"1723807\",\"name\":\"X. Liu\"},{\"authorId\":\"47119262\",\"name\":\"X. Wang\"}],\"doi\":\"10.1145/3161412\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"299b07ec255398c7f9d147cb39d113e4926cc51b\",\"title\":\"SHOW\",\"url\":\"https://www.semanticscholar.org/paper/299b07ec255398c7f9d147cb39d113e4926cc51b\",\"venue\":\"IMWUT\",\"year\":2018},{\"arxivId\":\"1408.5093\",\"authors\":[{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"1782282\",\"name\":\"Evan Shelhamer\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"3049736\",\"name\":\"S. Karayev\"},{\"authorId\":\"144361581\",\"name\":\"J. Long\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1145/2647868.2654889\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6bdb186ec4726e00a8051119636d4df3b94043b5\",\"title\":\"Caffe: Convolutional Architecture for Fast Feature Embedding\",\"url\":\"https://www.semanticscholar.org/paper/6bdb186ec4726e00a8051119636d4df3b94043b5\",\"venue\":\"ACM Multimedia\",\"year\":2014},{\"arxivId\":\"1409.4842\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"46641766\",\"name\":\"W. Liu\"},{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"},{\"authorId\":\"48840704\",\"name\":\"Scott Reed\"},{\"authorId\":\"1838674\",\"name\":\"Dragomir Anguelov\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"39863668\",\"name\":\"Andrew Rabinovich\"}],\"doi\":\"10.1109/CVPR.2015.7298594\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"title\":\"Going deeper with convolutions\",\"url\":\"https://www.semanticscholar.org/paper/e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1506.01144\",\"authors\":[{\"authorId\":\"34902783\",\"name\":\"Qi Wu\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2016.29\",\"intent\":[\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"00fe3d95d0fd5f1433d81405bee772c4fe9af9c6\",\"title\":\"What Value Do Explicit High Level Concepts Have in Vision to Language Problems?\",\"url\":\"https://www.semanticscholar.org/paper/00fe3d95d0fd5f1433d81405bee772c4fe9af9c6\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1603.09016\",\"authors\":[{\"authorId\":\"143690259\",\"name\":\"K. Tran\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/CVPRW.2016.61\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"18f1143c64e6557c933b206fb8b2a7bd1f389afd\",\"title\":\"Rich Image Captioning in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/18f1143c64e6557c933b206fb8b2a7bd1f389afd\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2016},{\"arxivId\":\"1301.3781\",\"authors\":[{\"authorId\":null,\"name\":\"Tomas Mikolov\"},{\"authorId\":\"38644044\",\"name\":\"Kai Chen\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"330da625c15427c6e42ccfa3b747fb29e5835bf0\",\"title\":\"Efficient Estimation of Word Representations in Vector Space\",\"url\":\"https://www.semanticscholar.org/paper/330da625c15427c6e42ccfa3b747fb29e5835bf0\",\"venue\":\"ICLR\",\"year\":2013},{\"arxivId\":\"1505.01809\",\"authors\":[{\"authorId\":\"39172707\",\"name\":\"J. Devlin\"},{\"authorId\":\"47413820\",\"name\":\"Hao Cheng\"},{\"authorId\":\"145204655\",\"name\":\"Hao Fang\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"}],\"doi\":\"10.3115/v1/P15-2017\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f142c849ffef66f7520aff4e0b40ac964ccb8cc1\",\"title\":\"Language Models for Image Captioning: The Quirks and What Works\",\"url\":\"https://www.semanticscholar.org/paper/f142c849ffef66f7520aff4e0b40ac964ccb8cc1\",\"venue\":\"ACL\",\"year\":2015},{\"arxivId\":\"1607.08822\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1007/978-3-319-46454-1_24\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1c54acd7d9ed8017acdc5674c9b7faac738fd651\",\"title\":\"SPICE: Semantic Propositional Image Caption Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/1c54acd7d9ed8017acdc5674c9b7faac738fd651\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1409.0473\",\"authors\":[{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"title\":\"Neural Machine Translation by Jointly Learning to Align and Translate\",\"url\":\"https://www.semanticscholar.org/paper/fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Junhua Mao\"},{\"authorId\":null,\"name\":\"Wei Xu\"},{\"authorId\":null,\"name\":\"Yi Yang\"},{\"authorId\":null,\"name\":\"Jiang Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Yuille . Explain images with multimodal recurrent neural networks\",\"url\":\"\",\"venue\":\"NIPS Workshop on Deep Learning\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Q. Wu\"},{\"authorId\":null,\"name\":\"C. Shen\"},{\"authorId\":null,\"name\":\"L. Liu\"},{\"authorId\":null,\"name\":\"A. Dick\"}],\"doi\":null,\"intent\":[\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"and A\",\"url\":\"\",\"venue\":\"v. d. Hengel. What value do explicit high level concepts have in vision to language problems? In CVPR\",\"year\":2016},{\"arxivId\":\"1708.05271\",\"authors\":[{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2017.559\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10480a42957a8e08e4c543185e135d7c254583a5\",\"title\":\"Incorporating Copying Mechanism in Image Captioning for Learning Novel Objects\",\"url\":\"https://www.semanticscholar.org/paper/10480a42957a8e08e4c543185e135d7c254583a5\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3141511\",\"name\":\"S. Banerjee\"},{\"authorId\":\"1784914\",\"name\":\"A. Lavie\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"0cd18e4400ff75b2f8b58d60ddb9b0bc12f489e7\",\"title\":\"METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments\",\"url\":\"https://www.semanticscholar.org/paper/0cd18e4400ff75b2f8b58d60ddb9b0bc12f489e7\",\"venue\":\"IEEvaluation@ACL\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"145564333\",\"name\":\"G. Kulkarni\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8e080b98efbe65c02a116439205ca2344b9f7cd4\",\"title\":\"Im2Text: Describing Images Using 1 Million Captioned Photographs\",\"url\":\"https://www.semanticscholar.org/paper/8e080b98efbe65c02a116439205ca2344b9f7cd4\",\"venue\":\"NIPS\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Quanzeng You\"},{\"authorId\":null,\"name\":\"Hailin Jin\"},{\"authorId\":null,\"name\":\"Zhaowen Wang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Chen Fang, and Jiebo Luo. Image captioning with semantic attention\",\"url\":\"\",\"venue\":\"CVPR\",\"year\":2016},{\"arxivId\":\"1410.1090\",\"authors\":[{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"40579682\",\"name\":\"J. Wang\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"82fdca623c65b6acf6b06bdeed48b2a9ebdb80a9\",\"title\":\"Explain Images with Multimodal Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/82fdca623c65b6acf6b06bdeed48b2a9ebdb80a9\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145564333\",\"name\":\"G. Kulkarni\"},{\"authorId\":\"3128210\",\"name\":\"Visruth Premraj\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"2985883\",\"name\":\"Sagnik Dhar\"},{\"authorId\":\"50341924\",\"name\":\"Siming Li\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/TPAMI.2012.162\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5cb6700d94c6118ee13f4f4fecac99f111189812\",\"title\":\"BabyTalk: Understanding and Generating Simple Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/5cb6700d94c6118ee13f4f4fecac99f111189812\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2013},{\"arxivId\":\"1505.01861\",\"authors\":[{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/CVPR.2016.497\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"68478207cf3e4fc44bf1602abe82c7ac7f288872\",\"title\":\"Jointly Modeling Embedding and Translation to Bridge Video and Language\",\"url\":\"https://www.semanticscholar.org/paper/68478207cf3e4fc44bf1602abe82c7ac7f288872\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1411.5726\",\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2015.7299087\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"258986132bf17755fe8263e42429fe73218c1534\",\"title\":\"CIDEr: Consensus-based image description evaluation\",\"url\":\"https://www.semanticscholar.org/paper/258986132bf17755fe8263e42429fe73218c1534\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1411.4952\",\"authors\":[{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3346186\",\"name\":\"Forrest N. Iandola\"},{\"authorId\":\"2100612\",\"name\":\"R. Srivastava\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"144189092\",\"name\":\"John C. Platt\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"}],\"doi\":\"10.1109/CVPR.2015.7298754\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"title\":\"From captions to visual concepts and back\",\"url\":\"https://www.semanticscholar.org/paper/15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1412.2306\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/TPAMI.2016.2598339\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"title\":\"Deep Visual-Semantic Alignments for Generating Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":\"1409.3215\",\"authors\":[{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"cea967b59209c6be22829699f05b8b1ac4dc092d\",\"title\":\"Sequence to Sequence Learning with Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/cea967b59209c6be22829699f05b8b1ac4dc092d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2677364\",\"name\":\"Luowei Zhou\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"},{\"authorId\":\"31717541\",\"name\":\"Parker A. Koch\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1145/3126686.3126717\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1e83adb616b8466639a14e78f3d26120be7caf48\",\"title\":\"Watch What You Just Said: Image Captioning with Text-Conditional Attention\",\"url\":\"https://www.semanticscholar.org/paper/1e83adb616b8466639a14e78f3d26120be7caf48\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"fad611e35b3731740b4d8b754241e77add5a70b9\",\"title\":\"Multimodal Neural Language Models\",\"url\":\"https://www.semanticscholar.org/paper/fad611e35b3731740b4d8b754241e77add5a70b9\",\"venue\":\"ICML\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5886094\",\"name\":\"P. Cochat\"},{\"authorId\":\"13267685\",\"name\":\"L. Vaucoret\"},{\"authorId\":\"31455512\",\"name\":\"J. Sarles\"}],\"doi\":\"10.1016/j.arcped.2012.01.013\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"10d85561e4aafc516d10064f30dff05b41f70afe\",\"title\":\"[Et al].\",\"url\":\"https://www.semanticscholar.org/paper/10d85561e4aafc516d10064f30dff05b41f70afe\",\"venue\":\"Archives de pediatrie : organe officiel de la Societe francaise de pediatrie\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"143977389\",\"name\":\"C. Ngo\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2015.7298826\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"22d90529f2f4eab4b4d7108fc10d51e7a8bcbac9\",\"title\":\"Semi-supervised Domain Adaptation with Subspace Learning for visual recognition\",\"url\":\"https://www.semanticscholar.org/paper/22d90529f2f4eab4b4d7108fc10d51e7a8bcbac9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1612.00370\",\"authors\":[{\"authorId\":\"47130333\",\"name\":\"Siqi Liu\"},{\"authorId\":\"39815369\",\"name\":\"Z. Zhu\"},{\"authorId\":\"145361612\",\"name\":\"N. Ye\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":\"10.1109/ICCV.2017.100\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"665a311c538fc021c27acd3953f171924cc5905c\",\"title\":\"Optimization of image description metrics using policy gradient methods\",\"url\":\"https://www.semanticscholar.org/paper/665a311c538fc021c27acd3953f171924cc5905c\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1612.01887\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":\"10.1109/CVPR.2017.345\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9f4d7d622d1f7319cc511bfef661cd973e881a4c\",\"title\":\"Knowing When to Look: Adaptive Attention via a Visual Sentinel for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9f4d7d622d1f7319cc511bfef661cd973e881a4c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1603.03925\",\"authors\":[{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2016.503\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"bf55591e09b58ea9ce8d66110d6d3000ee804bdd\",\"title\":\"Image Captioning with Semantic Attention\",\"url\":\"https://www.semanticscholar.org/paper/bf55591e09b58ea9ce8d66110d6d3000ee804bdd\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1504.00325\",\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"title\":\"Microsoft COCO Captions: Data Collection and Evaluation Server\",\"url\":\"https://www.semanticscholar.org/paper/696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1888731\",\"name\":\"M. Hejrati\"},{\"authorId\":\"21160985\",\"name\":\"M. Sadeghi\"},{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"3125805\",\"name\":\"Cyrus Rashtchian\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"144016256\",\"name\":\"D. Forsyth\"}],\"doi\":\"10.1007/978-3-642-15561-1_2\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"eaaed23a2d94feb2f1c3ff22a25777c7a78f3141\",\"title\":\"Every Picture Tells a Story: Generating Sentences from Images\",\"url\":\"https://www.semanticscholar.org/paper/eaaed23a2d94feb2f1c3ff22a25777c7a78f3141\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"1756655\",\"name\":\"C. L. Teo\"},{\"authorId\":\"1722360\",\"name\":\"Hal Daum\\u00e9\"},{\"authorId\":\"1697493\",\"name\":\"Y. Aloimonos\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"76a1dca3a9c2b0229c1b12c95752dcf40dc95a11\",\"title\":\"Corpus-Guided Sentence Generation of Natural Images\",\"url\":\"https://www.semanticscholar.org/paper/76a1dca3a9c2b0229c1b12c95752dcf40dc95a11\",\"venue\":\"EMNLP\",\"year\":2011},{\"arxivId\":\"1611.07675\",\"authors\":[{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2017.111\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d3b5ffff118326fea73341a86a7c29423eb95f0\",\"title\":\"Video Captioning with Transferred Semantic Attributes\",\"url\":\"https://www.semanticscholar.org/paper/0d3b5ffff118326fea73341a86a7c29423eb95f0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1781574\",\"name\":\"Chin-Yew Lin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"60b05f32c32519a809f21642ef1eb3eaf3848008\",\"title\":\"ROUGE: A Package for Automatic Evaluation of Summaries\",\"url\":\"https://www.semanticscholar.org/paper/60b05f32c32519a809f21642ef1eb3eaf3848008\",\"venue\":\"ACL 2004\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3323275\",\"name\":\"Kishore Papineni\"},{\"authorId\":\"1781292\",\"name\":\"S. Roukos\"},{\"authorId\":\"144582029\",\"name\":\"T. Ward\"},{\"authorId\":\"2587983\",\"name\":\"Wei-Jing Zhu\"}],\"doi\":\"10.3115/1073083.1073135\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d7da009f457917aa381619facfa5ffae9329a6e9\",\"title\":\"Bleu: a Method for Automatic Evaluation of Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/d7da009f457917aa381619facfa5ffae9329a6e9\",\"venue\":\"ACL\",\"year\":2002},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1409.0575\",\"authors\":[{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"71309570\",\"name\":\"H. Su\"},{\"authorId\":\"2285165\",\"name\":\"J. Krause\"},{\"authorId\":\"145031342\",\"name\":\"S. Satheesh\"},{\"authorId\":\"145423516\",\"name\":\"S. Ma\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-015-0816-y\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"title\":\"ImageNet Large Scale Visual Recognition Challenge\",\"url\":\"https://www.semanticscholar.org/paper/e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":\"1606.04621\",\"authors\":[{\"authorId\":\"2677364\",\"name\":\"Luowei Zhou\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"},{\"authorId\":\"31717541\",\"name\":\"Parker A. Koch\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a861313608ef58ed09ab7c35a589ae22088ff2e9\",\"title\":\"Image Caption Generation with Text-Conditional Semantic Attention\",\"url\":\"https://www.semanticscholar.org/paper/a861313608ef58ed09ab7c35a589ae22088ff2e9\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c8206df8d5ffaa8c4d3598718bf361556a6d651\",\"title\":\"Learning Deep Intrinsic Video Representation by Exploring Temporal Coherence and Graph Structure\",\"url\":\"https://www.semanticscholar.org/paper/1c8206df8d5ffaa8c4d3598718bf361556a6d651\",\"venue\":\"IJCAI\",\"year\":2016},{\"arxivId\":\"1612.00563\",\"authors\":[{\"authorId\":\"2071376\",\"name\":\"Steven J. Rennie\"},{\"authorId\":\"2293163\",\"name\":\"E. Marcheret\"},{\"authorId\":\"2211263\",\"name\":\"Youssef Mroueh\"},{\"authorId\":\"39320489\",\"name\":\"J. Ross\"},{\"authorId\":\"1782589\",\"name\":\"V. Goel\"}],\"doi\":\"10.1109/CVPR.2017.131\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6c8353697cdbb98dfba4f493875778c4286d3e3a\",\"title\":\"Self-Critical Sequence Training for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6c8353697cdbb98dfba4f493875778c4286d3e3a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"34176020\",\"name\":\"Jesse Dodge\"},{\"authorId\":\"46479604\",\"name\":\"Amit Goyal\"},{\"authorId\":\"1721910\",\"name\":\"Kota Yamaguchi\"},{\"authorId\":\"1714215\",\"name\":\"K. Stratos\"},{\"authorId\":\"1682965\",\"name\":\"Xufeng Han\"},{\"authorId\":\"40614240\",\"name\":\"A. Mensch\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1722360\",\"name\":\"Hal Daum\\u00e9\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"355de7460120ddc1150d9ce3756f9848983f7ff4\",\"title\":\"Midge: Generating Image Descriptions From Computer Vision Detections\",\"url\":\"https://www.semanticscholar.org/paper/355de7460120ddc1150d9ce3756f9848983f7ff4\",\"venue\":\"EACL\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/ICCV.2011.6126281\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"23e568fcf0192e4ff5e6bed7507ee5b9e6c43598\",\"title\":\"Relative attributes\",\"url\":\"https://www.semanticscholar.org/paper/23e568fcf0192e4ff5e6bed7507ee5b9e6c43598\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2727656\",\"name\":\"X. Chen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"94e3e7bc3d23276f0ee2d1cb8f9d14aa19668d5f\",\"title\":\"Under Review as a Conference Paper at Iclr 2017 Delving into Transferable Adversarial Ex- Amples and Black-box Attacks\",\"url\":\"https://www.semanticscholar.org/paper/94e3e7bc3d23276f0ee2d1cb8f9d14aa19668d5f\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47087291\",\"name\":\"Z. Yang\"},{\"authorId\":\"30556331\",\"name\":\"Y. Yuan\"},{\"authorId\":\"9287688\",\"name\":\"Yuexin Wu\"},{\"authorId\":\"50056360\",\"name\":\"William W. Cohen\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"61d2dda8d96a10a714636475c7589bd149bda053\",\"title\":\"Review Networks for Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/61d2dda8d96a10a714636475c7589bd149bda053\",\"venue\":\"NIPS\",\"year\":2016}],\"title\":\"Boosting Image Captioning with Attributes\",\"topics\":[{\"topic\":\"Convolutional neural network\",\"topicId\":\"29860\",\"url\":\"https://www.semanticscholar.org/topic/29860\"},{\"topic\":\"Natural language processing\",\"topicId\":\"1914\",\"url\":\"https://www.semanticscholar.org/topic/1914\"},{\"topic\":\"Multiple instance learning\",\"topicId\":\"97196\",\"url\":\"https://www.semanticscholar.org/topic/97196\"},{\"topic\":\"Computer vision\",\"topicId\":\"5332\",\"url\":\"https://www.semanticscholar.org/topic/5332\"},{\"topic\":\"Recurrent neural network\",\"topicId\":\"16115\",\"url\":\"https://www.semanticscholar.org/topic/16115\"},{\"topic\":\"Meteor\",\"topicId\":\"131649\",\"url\":\"https://www.semanticscholar.org/topic/131649\"},{\"topic\":\"Long short-term memory\",\"topicId\":\"117199\",\"url\":\"https://www.semanticscholar.org/topic/117199\"},{\"topic\":\"End-to-end principle\",\"topicId\":\"299633\",\"url\":\"https://www.semanticscholar.org/topic/299633\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Neural Networks\",\"topicId\":\"99954\",\"url\":\"https://www.semanticscholar.org/topic/99954\"}],\"url\":\"https://www.semanticscholar.org/paper/5785466bc14529e94e54baa4ed051f7037f3b1d3\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017}\n"