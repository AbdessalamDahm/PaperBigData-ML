"{\"abstract\":\"Convolutional Neural Networks (CNN) have been regarded as a powerful class of models for image recognition problems. Nevertheless, it is not trivial when utilizing a CNN for learning spatio-temporal video representation. A few studies have shown that performing 3D convolutions is a rewarding approach to capture both spatial and temporal dimensions in videos. However, the development of a very deep 3D CNN from scratch results in expensive computational cost and memory demand. A valid question is why not recycle off-the-shelf 2D networks for a 3D CNN. In this paper, we devise multiple variants of bottleneck building blocks in a residual learning framework by simulating 3 x 3 x 3 convolutions with 1 \\u00d7 3 \\u00d7 3 convolutional filters on spatial domain (equivalent to 2D CNN) plus 3 \\u00d7 1 \\u00d7 1 convolutions to construct temporal connections on adjacent feature maps in time. Furthermore, we propose a new architecture, named Pseudo-3D Residual Net (P3D ResNet), that exploits all the variants of blocks but composes each in different placement of ResNet, following the philosophy that enhancing structural diversity with going deep could improve the power of neural networks. Our P3D ResNet achieves clear improvements on Sports-1M video classification dataset against 3D CNN and frame-based 2D CNN by 5.3% and 1.8%, respectively. We further examine the generalization performance of video representation produced by our pre-trained P3D ResNet on five different benchmarks and three different tasks, demonstrating superior performances over several state-of-the-art techniques.\",\"arxivId\":\"1711.10305\",\"authors\":[{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\",\"url\":\"https://www.semanticscholar.org/author/3430743\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\",\"url\":\"https://www.semanticscholar.org/author/145690248\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\",\"url\":\"https://www.semanticscholar.org/author/144025741\"}],\"citationVelocity\":195,\"citations\":[{\"arxivId\":\"2001.07501\",\"authors\":[{\"authorId\":\"2719454\",\"name\":\"W. Wang\"},{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"48265260\",\"name\":\"Jian Cheng\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6b06383710f5dff3028db31d1497914d65888194\",\"title\":\"A Comprehensive Study on Temporal Modeling for Online Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/6b06383710f5dff3028db31d1497914d65888194\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yi Zhou\"},{\"authorId\":\"40241836\",\"name\":\"L. Liu\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"}],\"doi\":\"10.1109/TIP.2018.2819820\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d5a6d12b39c6574fe284d779d2c23c2800bb283\",\"title\":\"Vehicle Re-Identification by Deep Hidden Multi-View Inference\",\"url\":\"https://www.semanticscholar.org/paper/9d5a6d12b39c6574fe284d779d2c23c2800bb283\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49724000\",\"name\":\"H. Zhang\"},{\"authorId\":\"46867310\",\"name\":\"Yi-Xiang Zhang\"},{\"authorId\":\"40296597\",\"name\":\"B. Zhong\"},{\"authorId\":\"2619654\",\"name\":\"Qing Lei\"},{\"authorId\":\"48064117\",\"name\":\"Lijie Yang\"},{\"authorId\":\"3721965\",\"name\":\"Ji-Xiang Du\"},{\"authorId\":\"123204699\",\"name\":\"Duan-Sheng Chen\"}],\"doi\":\"10.3390/s19051005\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"c0e55d740d07b16a50b5eb491117b92965d315c9\",\"title\":\"A Comprehensive Survey of Vision-Based Human Action Recognition Methods\",\"url\":\"https://www.semanticscholar.org/paper/c0e55d740d07b16a50b5eb491117b92965d315c9\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":\"1806.09278\",\"authors\":[{\"authorId\":\"49420316\",\"name\":\"Yuan Liu\"},{\"authorId\":\"50980046\",\"name\":\"Moyini Yao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8b87e33101a5564cbd3d212246aa48e2b6123227\",\"title\":\"Best Vision Technologies Submission to ActivityNet Challenge 2018-Task: Dense-Captioning Events in Videos\",\"url\":\"https://www.semanticscholar.org/paper/8b87e33101a5564cbd3d212246aa48e2b6123227\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1806.10319\",\"authors\":[{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"50984378\",\"name\":\"F. Li\"},{\"authorId\":\"2273005\",\"name\":\"Qijie Zhao\"},{\"authorId\":\"144858226\",\"name\":\"Xiang Long\"},{\"authorId\":\"145413801\",\"name\":\"Y. Fu\"},{\"authorId\":\"35247507\",\"name\":\"Shilei Wen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10370545ea747c6adec26142dbfc499681876570\",\"title\":\"Exploiting Spatial-Temporal Modelling and Multi-Modal Fusion for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/10370545ea747c6adec26142dbfc499681876570\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1912.04430\",\"authors\":[{\"authorId\":\"3121735\",\"name\":\"Paritosh Parmar\"},{\"authorId\":\"49059658\",\"name\":\"B. Morris.\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7aef63bbe103760e78f359223e35562cdaed16c1\",\"title\":\"HalluciNet-ing Spatiotemporal Representations Using 2D-CNN\",\"url\":\"https://www.semanticscholar.org/paper/7aef63bbe103760e78f359223e35562cdaed16c1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31320085\",\"name\":\"Li Liang-hua\"},{\"authorId\":\"31190693\",\"name\":\"Wang Yong-xiong\"}],\"doi\":\"10.12086/OEE.2020.190139\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"676fcbc0e65f6440bef432085b28cae1d8684d31\",\"title\":\"Efficient 3D dense residual network and its application in human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/676fcbc0e65f6440bef432085b28cae1d8684d31\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2087534\",\"name\":\"Y. Zhu\"},{\"authorId\":\"1990768\",\"name\":\"Guangcan Liu\"}],\"doi\":\"10.1007/s00371-019-01770-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"084655e3d230385103d080544d900aa4aa91cf10\",\"title\":\"Fine-grained action recognition using multi-view attentions\",\"url\":\"https://www.semanticscholar.org/paper/084655e3d230385103d080544d900aa4aa91cf10\",\"venue\":\"The Visual Computer\",\"year\":2019},{\"arxivId\":\"1810.00207\",\"authors\":[{\"authorId\":\"7868449\",\"name\":\"Yongyi Tang\"},{\"authorId\":\"46447561\",\"name\":\"X. Zhang\"},{\"authorId\":null,\"name\":\"Jingwen Wang\"},{\"authorId\":\"39650418\",\"name\":\"S. Chen\"},{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1007/978-3-030-11018-5_20\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"507f398b79e94a1ebde61c0a854c3954e7bb3d33\",\"title\":\"Non-local NetVLAD Encoding for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/507f398b79e94a1ebde61c0a854c3954e7bb3d33\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"2001.11394\",\"authors\":[{\"authorId\":\"35041003\",\"name\":\"Lichao Mou\"},{\"authorId\":\"51151222\",\"name\":\"Yuansheng Hua\"},{\"authorId\":\"36352940\",\"name\":\"P. Jin\"},{\"authorId\":\"40049070\",\"name\":\"X. Zhu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4a820785df28ee9693001aa5701bba3828229ef0\",\"title\":\"ERA: A Dataset and Deep Learning Benchmark for Event Recognition in Aerial Videos\",\"url\":\"https://www.semanticscholar.org/paper/4a820785df28ee9693001aa5701bba3828229ef0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1908.01449\",\"authors\":[{\"authorId\":\"2177037\",\"name\":\"Andrew Kae\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"}],\"doi\":\"10.1109/WACV45572.2020.9093645\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e776cc129ed89303af6f2075ccfcea596243ff5d\",\"title\":\"Image to Video Domain Adaptation Using Web Supervision\",\"url\":\"https://www.semanticscholar.org/paper/e776cc129ed89303af6f2075ccfcea596243ff5d\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491240780\",\"name\":\"Z. Shi\"},{\"authorId\":\"1491233401\",\"name\":\"Liangjie Cao\"},{\"authorId\":\"153747406\",\"name\":\"Cheng Guan\"},{\"authorId\":\"1993660232\",\"name\":\"Ju Liang\"},{\"authorId\":\"48934241\",\"name\":\"Qianqian Li\"},{\"authorId\":\"29344734\",\"name\":\"Zhaorui Gu\"},{\"authorId\":\"2336297\",\"name\":\"Haiyong Zheng\"},{\"authorId\":\"49721778\",\"name\":\"Bing Zheng\"}],\"doi\":\"10.1145/3394171.3413646\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c0d5f622f775d02e90b715b80485dbcab250e7bd\",\"title\":\"Multi-Group Multi-Attention: Towards Discriminative Spatiotemporal Representation\",\"url\":\"https://www.semanticscholar.org/paper/c0d5f622f775d02e90b715b80485dbcab250e7bd\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"3313330\",\"name\":\"Gedas Bertasius\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"1726095131\",\"name\":\"Abhinav Gupta\"},{\"authorId\":\"2356016\",\"name\":\"Minh Hoai\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"86a9e09459c5a4e436706d0b89f951d780e80a71\",\"title\":\"Supervoxel Attention Graphs for Long-Range Video Modeling\",\"url\":\"https://www.semanticscholar.org/paper/86a9e09459c5a4e436706d0b89f951d780e80a71\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2007.09835\",\"authors\":[{\"authorId\":\"48643324\",\"name\":\"Wei Niu\"},{\"authorId\":\"8712588\",\"name\":\"Mengshu Sun\"},{\"authorId\":\"48459506\",\"name\":\"Z. Li\"},{\"authorId\":\"84681008\",\"name\":\"J. Chen\"},{\"authorId\":\"1823636176\",\"name\":\"Jiexiong Guan\"},{\"authorId\":\"47435542\",\"name\":\"Xipeng Shen\"},{\"authorId\":null,\"name\":\"Yanzhi Wang\"},{\"authorId\":\"1662772707\",\"name\":\"Xue Lin\"},{\"authorId\":\"153108488\",\"name\":\"Bin Ren\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2ea24183f37578404d455dccc816a7088b0d0f99\",\"title\":\"Achieving Real-Time Execution of 3D Convolutional Neural Networks on Mobile Devices\",\"url\":\"https://www.semanticscholar.org/paper/2ea24183f37578404d455dccc816a7088b0d0f99\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2803030\",\"name\":\"Jungchan Cho\"},{\"authorId\":\"2104494\",\"name\":\"Hyoseok Hwang\"}],\"doi\":\"10.3390/s20123491\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a96207034c05387dc84c76de6c5b63795c499809\",\"title\":\"Spatio-Temporal Representation of an Electoencephalogram for Emotion Recognition Using a Three-Dimensional Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/a96207034c05387dc84c76de6c5b63795c499809\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"2007.09861\",\"authors\":[{\"authorId\":\"9096071\",\"name\":\"Jianchao Wu\"},{\"authorId\":\"1874900\",\"name\":\"Zhanghui Kuang\"},{\"authorId\":\"48170161\",\"name\":\"L. Wang\"},{\"authorId\":\"1726357\",\"name\":\"Wayne Zhang\"},{\"authorId\":\"39914710\",\"name\":\"Gangshan Wu\"}],\"doi\":\"10.1007/978-3-030-58595-2_27\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cf0bc1e97049ece897db97ba605594a89df50c34\",\"title\":\"Context-Aware RCNN: A Baseline for Action Detection in Videos\",\"url\":\"https://www.semanticscholar.org/paper/cf0bc1e97049ece897db97ba605594a89df50c34\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2653622\",\"name\":\"Junfu Pu\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"413a354acbc42a0455ce1bbbd5d5c75cc38bc53d\",\"title\":\"Iterative Alignment Network for Continuous Sign Language\",\"url\":\"https://www.semanticscholar.org/paper/413a354acbc42a0455ce1bbbd5d5c75cc38bc53d\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"2004.07967\",\"authors\":[{\"authorId\":\"144810262\",\"name\":\"H. M. Nguyen\"},{\"authorId\":\"3388392\",\"name\":\"T. Miyazaki\"},{\"authorId\":\"2137463\",\"name\":\"Y. Sugaya\"},{\"authorId\":\"1740235\",\"name\":\"S. Omachi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"20b15ddf9efe511961321355bcb4a62c3a29a9ef\",\"title\":\"Multiple Visual-Semantic Embedding for Video Retrieval from Query Sentence\",\"url\":\"https://www.semanticscholar.org/paper/20b15ddf9efe511961321355bcb4a62c3a29a9ef\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2596486\",\"name\":\"Zhijian Hou\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"152650698\",\"name\":\"Chong-Wah Ngo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ec28b73028e7651894323e33409b82d235d2be39\",\"title\":\"VireoJD-MM @ TRECVid 2019: Activities in Extended Video (ActEV)\",\"url\":\"https://www.semanticscholar.org/paper/ec28b73028e7651894323e33409b82d235d2be39\",\"venue\":\"TRECVID\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153188471\",\"name\":\"J. Kim\"},{\"authorId\":\"1706549\",\"name\":\"C. Won\"}],\"doi\":\"10.1109/ACCESS.2020.2983427\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d091af317fa1e58c6e8222d0048fd5de8cfa3065\",\"title\":\"Action Recognition in Videos Using Pre-Trained 2D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/d091af317fa1e58c6e8222d0048fd5de8cfa3065\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24849962\",\"name\":\"Chuanpan Zheng\"},{\"authorId\":\"49537231\",\"name\":\"Xiaoliang Fan\"},{\"authorId\":\"2869063\",\"name\":\"Chenglu Wen\"},{\"authorId\":\"2053864\",\"name\":\"Longbiao Chen\"},{\"authorId\":\"41130715\",\"name\":\"C. Wang\"},{\"authorId\":\"1753959\",\"name\":\"J. Li\"}],\"doi\":\"10.1109/TITS.2019.2932785\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"da91393cd2a46ebedeec2463d09a12f8c4bc0c09\",\"title\":\"DeepSTD: Mining Spatio-Temporal Disturbances of Multiple Context Factors for Citywide Traffic Flow Prediction\",\"url\":\"https://www.semanticscholar.org/paper/da91393cd2a46ebedeec2463d09a12f8c4bc0c09\",\"venue\":\"IEEE Transactions on Intelligent Transportation Systems\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46276482\",\"name\":\"J. Li\"},{\"authorId\":\"145708711\",\"name\":\"Ping Wei\"},{\"authorId\":\"1978363545\",\"name\":\"Yongchi Zhang\"},{\"authorId\":\"153873673\",\"name\":\"N. Zheng\"}],\"doi\":\"10.1145/3394171.3413641\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"05444a5a49f717dc199957b66e9c472219171f88\",\"title\":\"A Slow-I-Fast-P Architecture for Compressed Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/05444a5a49f717dc199957b66e9c472219171f88\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3381029\",\"name\":\"J. Wang\"},{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1016/j.cviu.2019.102898\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"62af68e20481f9f98509bfed69ef1300a8e9485e\",\"title\":\"Cascade multi-head attention networks for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/62af68e20481f9f98509bfed69ef1300a8e9485e\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19198359\",\"name\":\"Yatao Zhong\"},{\"authorId\":null,\"name\":\"Bicheng Xu\"},{\"authorId\":\"2057809\",\"name\":\"G. Zhou\"},{\"authorId\":\"3004771\",\"name\":\"L. Bornn\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"883e59ac3e386023d6ad8ef97d5c881a2009741c\",\"title\":\"Next : When , Where , What ? \\u201c Pass \\u201d \\u201c Receive \\u201d \\u201c Carry \\u201d \\u201c Dump \\u201d\",\"url\":\"https://www.semanticscholar.org/paper/883e59ac3e386023d6ad8ef97d5c881a2009741c\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123390466\",\"name\":\"M. Bengs\"},{\"authorId\":\"38212285\",\"name\":\"N. Gessert\"},{\"authorId\":\"3236423\",\"name\":\"A. Schlaefer\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f0186fee56f9f24277b42c03b263db45245b0cdc\",\"title\":\"Current Directions in Biomedical Engineering\",\"url\":\"https://www.semanticscholar.org/paper/f0186fee56f9f24277b42c03b263db45245b0cdc\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1908.07934\",\"authors\":[{\"authorId\":\"9277545\",\"name\":\"Xiangyi Li\"},{\"authorId\":\"1716948\",\"name\":\"Huaming Wu\"}],\"doi\":\"10.1109/LWC.2020.2964550\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8ba52479d11af7037cbe4da5e955d25bf5ae02af\",\"title\":\"Spatio-Temporal Representation With Deep Neural Recurrent Network in MIMO CSI Feedback\",\"url\":\"https://www.semanticscholar.org/paper/8ba52479d11af7037cbe4da5e955d25bf5ae02af\",\"venue\":\"IEEE Wireless Communications Letters\",\"year\":2020},{\"arxivId\":\"1906.02817\",\"authors\":[{\"authorId\":\"1834450\",\"name\":\"Zhuotun Zhu\"},{\"authorId\":\"50557601\",\"name\":\"Chenxi Liu\"},{\"authorId\":\"150084685\",\"name\":\"Dong Yang\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"},{\"authorId\":\"3262394\",\"name\":\"Daguang Xu\"}],\"doi\":\"10.1109/3DV.2019.00035\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1e2da6a1cc63afe7a95c0d05f4fa817527a6e723\",\"title\":\"V-NAS: Neural Architecture Search for Volumetric Medical Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/1e2da6a1cc63afe7a95c0d05f4fa817527a6e723\",\"venue\":\"2019 International Conference on 3D Vision (3DV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144388361\",\"name\":\"C. Li\"},{\"authorId\":\"1740430\",\"name\":\"B. Zhang\"},{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"1694936\",\"name\":\"Q. Ye\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"},{\"authorId\":\"1822413\",\"name\":\"Guodong Guo\"},{\"authorId\":\"145592288\",\"name\":\"Rongrong Ji\"}],\"doi\":\"10.1109/TIP.2019.2912357\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"cc68848151657035ffbd945d99106e8c52e15c20\",\"title\":\"Deep Manifold Structure Transfer for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cc68848151657035ffbd945d99106e8c52e15c20\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"2006.14582\",\"authors\":[{\"authorId\":\"50079897\",\"name\":\"X. Li\"},{\"authorId\":null,\"name\":\"Yali Wang\"},{\"authorId\":\"1491073267\",\"name\":\"Zhipeng Zhou\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1109/cvpr42600.2020.00117\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"da9b802ea051ffb7ef2de0d8d1003944a60bf44c\",\"title\":\"SmallBigNet: Integrating Core and Contextual Views for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/da9b802ea051ffb7ef2de0d8d1003944a60bf44c\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47827957\",\"name\":\"Y. Zhao\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/CVPR.2018.00687\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d66e13a5e128a4ecad78e0c1c128893684292dec\",\"title\":\"Recognize Actions by Disentangling Components of Dynamics\",\"url\":\"https://www.semanticscholar.org/paper/d66e13a5e128a4ecad78e0c1c128893684292dec\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143985656\",\"name\":\"Manuel Martin\"},{\"authorId\":\"33390229\",\"name\":\"Alina Roitberg\"},{\"authorId\":\"67310661\",\"name\":\"Monica Haurilet\"},{\"authorId\":\"37255582\",\"name\":\"M. Horne\"},{\"authorId\":\"1845905584\",\"name\":\"Simon Rei\\u00df\"},{\"authorId\":\"145265390\",\"name\":\"M. Voit\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"}],\"doi\":\"10.1109/ICCV.2019.00289\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"5f6dd9cdbf3419c6bd2ad670f0ff2a3419e384d6\",\"title\":\"Drive&Act: A Multi-Modal Dataset for Fine-Grained Driver Behavior Recognition in Autonomous Vehicles\",\"url\":\"https://www.semanticscholar.org/paper/5f6dd9cdbf3419c6bd2ad670f0ff2a3419e384d6\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1381737458\",\"name\":\"Bo Fu\"},{\"authorId\":\"8045693\",\"name\":\"Shilin Fu\"},{\"authorId\":\"49681151\",\"name\":\"Liyan Wang\"},{\"authorId\":\"1388030824\",\"name\":\"Yuhan Dong\"},{\"authorId\":\"51110571\",\"name\":\"Y. Ren\"}],\"doi\":\"10.1109/MMUL.2020.3021799\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5ef53db8150825f6f79fd84982fa8e2affd7df03\",\"title\":\"Deep Residual Split Directed Graph Convolutional Neural Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5ef53db8150825f6f79fd84982fa8e2affd7df03\",\"venue\":\"IEEE MultiMedia\",\"year\":2020},{\"arxivId\":\"2011.12619\",\"authors\":[{\"authorId\":\"147084112\",\"name\":\"Jack Humphreys\"},{\"authorId\":\"48354826\",\"name\":\"Z. Chen\"},{\"authorId\":\"145047838\",\"name\":\"Dacheng Tao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e88bff50c417703239e0a832fddb267196ab5a99\",\"title\":\"Recent Progress in Appearance-based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e88bff50c417703239e0a832fddb267196ab5a99\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1842515\",\"name\":\"A. Crimi\"},{\"authorId\":\"3199900\",\"name\":\"S. Bakas\"},{\"authorId\":\"1743774\",\"name\":\"E. Bertino\"}],\"doi\":\"10.1007/978-3-030-46640-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5b9658e593c2bcdcf49de9f848eabf6d7eb75fc0\",\"title\":\"Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries: 5th International Workshop, BrainLes 2019, Held in Conjunction with MICCAI 2019, Shenzhen, China, October 17, 2019, Revised Selected Papers, Part I\",\"url\":\"https://www.semanticscholar.org/paper/5b9658e593c2bcdcf49de9f848eabf6d7eb75fc0\",\"venue\":\"BrainLes@MICCAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"80061847\",\"name\":\"Riccardo Fantinel\"},{\"authorId\":\"113450865\",\"name\":\"A. Cenedese\"}],\"doi\":\"10.1117/12.2521455\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a13b1afe4ef08154d9c533b7dcdbcb346703eae7\",\"title\":\"Visual inspection for metallic surfaces: CNN driven by features\",\"url\":\"https://www.semanticscholar.org/paper/a13b1afe4ef08154d9c533b7dcdbcb346703eae7\",\"venue\":\"International Conference on Quality Control by Artificial Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3400273\",\"name\":\"Chuan-Yih Chen\"},{\"authorId\":\"31398188\",\"name\":\"Kenli Li\"},{\"authorId\":\"2766305\",\"name\":\"Sin G. Teo\"},{\"authorId\":\"48439012\",\"name\":\"Xiaofeng Zou\"},{\"authorId\":\"153141874\",\"name\":\"Keqin Li\"},{\"authorId\":\"3111797\",\"name\":\"Z. Zeng\"}],\"doi\":\"10.1145/3385414\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"8af41682af9a33f833543dc8ba70b88084c94ba4\",\"title\":\"Citywide Traffic Flow Prediction Based on Multiple Gated Spatio-temporal Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/8af41682af9a33f833543dc8ba70b88084c94ba4\",\"venue\":\"ACM Trans. Knowl. Discov. Data\",\"year\":2020},{\"arxivId\":\"2008.08502\",\"authors\":[{\"authorId\":\"2670195\",\"name\":\"L. Wang\"},{\"authorId\":\"50439333\",\"name\":\"DongSheng Liu\"},{\"authorId\":\"3246780\",\"name\":\"Rohit Puri\"},{\"authorId\":\"1711560\",\"name\":\"D. Metaxas\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"76e71fe84643b72ffb61afe54c9034be824604e3\",\"title\":\"Learning Trailer Moments in Full-Length Movies\",\"url\":\"https://www.semanticscholar.org/paper/76e71fe84643b72ffb61afe54c9034be824604e3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.10531\",\"authors\":[{\"authorId\":\"2775025\",\"name\":\"Ruicong Xu\"},{\"authorId\":\"1716055\",\"name\":\"Li Niu\"},{\"authorId\":\"49051251\",\"name\":\"Jianfu Zhang\"},{\"authorId\":\"48571700\",\"name\":\"L. Zhang\"}],\"doi\":\"10.1609/AAAI.V34I07.6941\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b92762e958f1ddc712f1e1608a3cb3188720f977\",\"title\":\"A Proposal-based Approach for Activity Image-to-Video Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/b92762e958f1ddc712f1e1608a3cb3188720f977\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1906.02851\",\"authors\":[{\"authorId\":\"29724362\",\"name\":\"Longlong Jing\"},{\"authorId\":\"19263938\",\"name\":\"Elahe Vahdani\"},{\"authorId\":\"1747703\",\"name\":\"Matt Huenerfauth\"},{\"authorId\":\"35484757\",\"name\":\"Yingli Tian\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"39fc7acf294739c27078c337706376a1c03dfa06\",\"title\":\"Recognizing American Sign Language Manual Signs from RGB-D Videos\",\"url\":\"https://www.semanticscholar.org/paper/39fc7acf294739c27078c337706376a1c03dfa06\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1903.09616\",\"authors\":[{\"authorId\":\"7885067\",\"name\":\"Xinshuo Weng\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"27dd4c88b990f54f8b2c6039b98fa1de72d27150\",\"title\":\"On the Importance of Video Action Recognition for Visual Lipreading\",\"url\":\"https://www.semanticscholar.org/paper/27dd4c88b990f54f8b2c6039b98fa1de72d27150\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1805.02860\",\"authors\":[{\"authorId\":\"49417387\",\"name\":\"Y. Wang\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f414a4f51748d548c2e72971f1e428ebb34754bd\",\"title\":\"Visual Attribute-augmented Three-dimensional Convolutional Neural Network for Enhanced Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f414a4f51748d548c2e72971f1e428ebb34754bd\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1807.10066\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"2786693\",\"name\":\"C. Doersch\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6fb3940ddd658e549a111870f10ca77ba3c4cf37\",\"title\":\"A Better Baseline for AVA\",\"url\":\"https://www.semanticscholar.org/paper/6fb3940ddd658e549a111870f10ca77ba3c4cf37\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1576331745\",\"name\":\"Bozhen Hu\"},{\"authorId\":\"152632389\",\"name\":\"B. Gao\"},{\"authorId\":\"1809986\",\"name\":\"W. L. Woo\"},{\"authorId\":\"153319682\",\"name\":\"Lingfeng Ruan\"},{\"authorId\":\"31394809\",\"name\":\"J. Jin\"},{\"authorId\":\"46173234\",\"name\":\"Y. Yang\"},{\"authorId\":\"5354755\",\"name\":\"Yong-Jie Yu\"}],\"doi\":\"10.1109/TIP.2020.3036770\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5b48a06ac2d2d778c09acbcae70ba6fab7f65fe8\",\"title\":\"A Lightweight Spatial and Temporal Multi-Feature Fusion Network for Defect Detection\",\"url\":\"https://www.semanticscholar.org/paper/5b48a06ac2d2d778c09acbcae70ba6fab7f65fe8\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2180291\",\"name\":\"Ruichi Yu\"},{\"authorId\":\"48016412\",\"name\":\"H. Wang\"},{\"authorId\":\"145476833\",\"name\":\"Ang Li\"},{\"authorId\":\"7674316\",\"name\":\"Jingxiao Zheng\"},{\"authorId\":\"2852035\",\"name\":\"V. Morariu\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4cac9eda716a0addb73bd7ffea2a5fb0e6ec2367\",\"title\":\"Representing Videos based on Scene Layouts for Recognizing Agent-in-Place Actions\",\"url\":\"https://www.semanticscholar.org/paper/4cac9eda716a0addb73bd7ffea2a5fb0e6ec2367\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2008.10428\",\"authors\":[{\"authorId\":\"1400188907\",\"name\":\"Hezhen Hu\"},{\"authorId\":\"51476742\",\"name\":\"Wengang Zhou\"},{\"authorId\":\"2653622\",\"name\":\"Junfu Pu\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"cc338010de2bfba5dcf52d61bbb0ea3fe5495cea\",\"title\":\"Global-local Enhancement Network for NMFs-aware Sign Language Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cc338010de2bfba5dcf52d61bbb0ea3fe5495cea\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1903.09917\",\"authors\":[{\"authorId\":\"47058824\",\"name\":\"Lamei Zhang\"},{\"authorId\":\"39256302\",\"name\":\"H. Dong\"},{\"authorId\":\"143625022\",\"name\":\"B. Zou\"}],\"doi\":\"10.1016/j.isprsjprs.2019.09.002\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a4de5c52aec1eec59de4d68215ef52016498885b\",\"title\":\"Efficiently utilizing complex-valued PolSAR image data via a multi-task deep learning framework\",\"url\":\"https://www.semanticscholar.org/paper/a4de5c52aec1eec59de4d68215ef52016498885b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29850862\",\"name\":\"He-Yen Hsieh\"},{\"authorId\":\"2785372\",\"name\":\"Ding-Jie Chen\"},{\"authorId\":\"1805102\",\"name\":\"Tyng-Luh Liu\"}],\"doi\":\"10.1109/ICIP40778.2020.9190975\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8d0a1105f231ffc200d7b299fb962d8b673369be\",\"title\":\"Temporal Action Proposal Generation Via Deep Feature Enhancement\",\"url\":\"https://www.semanticscholar.org/paper/8d0a1105f231ffc200d7b299fb962d8b673369be\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46930271\",\"name\":\"Junyu Gao\"},{\"authorId\":\"1907582\",\"name\":\"T. Zhang\"},{\"authorId\":\"48258806\",\"name\":\"C. Xu\"}],\"doi\":\"10.1109/CVPR.2019.00478\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"53970ae69a73f547a56661fd25f6711746d277fb\",\"title\":\"Graph Convolutional Tracking\",\"url\":\"https://www.semanticscholar.org/paper/53970ae69a73f547a56661fd25f6711746d277fb\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1810.06807\",\"authors\":[{\"authorId\":\"145490315\",\"name\":\"Kartik Hegde\"},{\"authorId\":\"50843533\",\"name\":\"R. Agrawal\"},{\"authorId\":\"51463024\",\"name\":\"Yulun Yao\"},{\"authorId\":\"2012099\",\"name\":\"Christopher W. Fletcher\"}],\"doi\":\"10.1109/MICRO.2018.00080\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5a77877689e44e3ed48250f53e05b0d37bd901d7\",\"title\":\"Morph: Flexible Acceleration for 3D CNN-Based Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/5a77877689e44e3ed48250f53e05b0d37bd901d7\",\"venue\":\"2018 51st Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1474224022\",\"name\":\"Sun'ao Liu\"},{\"authorId\":\"145802910\",\"name\":\"H. Xu\"},{\"authorId\":\"46399157\",\"name\":\"Yizhi Liu\"},{\"authorId\":\"143994657\",\"name\":\"Hongtao Xie\"}],\"doi\":\"10.1007/978-3-030-37731-1_59\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"85ef1569b2b18212629016f082878b3df04dcc61\",\"title\":\"Improving Brain Tumor Segmentation with Dilated Pseudo-3D Convolution and Multi-direction Fusion\",\"url\":\"https://www.semanticscholar.org/paper/85ef1569b2b18212629016f082878b3df04dcc61\",\"venue\":\"MMM\",\"year\":2020},{\"arxivId\":\"2008.04146\",\"authors\":[{\"authorId\":\"46399672\",\"name\":\"Yiheng Liu\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"1916469\",\"name\":\"M. Xi\"},{\"authorId\":\"1865995287\",\"name\":\"Sanjing Shen\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"}],\"doi\":\"10.1145/3394171.3413984\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7f261b047f4b5d182af129a12935a512c0a65385\",\"title\":\"Vision Meets Wireless Positioning: Effective Person Re-identification with Recurrent Context Propagation\",\"url\":\"https://www.semanticscholar.org/paper/7f261b047f4b5d182af129a12935a512c0a65385\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2007.01044\",\"authors\":[{\"authorId\":\"123390466\",\"name\":\"M. Bengs\"},{\"authorId\":\"38212285\",\"name\":\"N. Gessert\"},{\"authorId\":\"3236423\",\"name\":\"A. Schlaefer\"}],\"doi\":\"10.1515/cdbme-2020-0001\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1914eefe3602addd0d348a5f2bd3a99e33f51ca6\",\"title\":\"4D spatio-temporal convolutional networks for object position estimation in OCT volumes\",\"url\":\"https://www.semanticscholar.org/paper/1914eefe3602addd0d348a5f2bd3a99e33f51ca6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993592720\",\"name\":\"Zhaobo Qi\"},{\"authorId\":\"47672591\",\"name\":\"Shuhui Wang\"},{\"authorId\":\"145422145\",\"name\":\"Chi Su\"},{\"authorId\":\"153142919\",\"name\":\"Li Su\"},{\"authorId\":\"153159021\",\"name\":\"Qingming Huang\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1145/3394171.3413954\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1d71c6ecb0d7ca618665e6402e84c2f5d39b761f\",\"title\":\"Towards More Explainability: Concept Knowledge Mining Network for Event Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1d71c6ecb0d7ca618665e6402e84c2f5d39b761f\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"1403581832\",\"name\":\"Laura Sevilla-Lara\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"11445222\",\"name\":\"H. Wang\"}],\"doi\":\"10.1609/AAAI.V34I07.7012\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d718baf9187fa5851a9389e5e250d47ba1210e0e\",\"title\":\"FASTER Recurrent Networks for Efficient Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/d718baf9187fa5851a9389e5e250d47ba1210e0e\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1801.01769\",\"authors\":[{\"authorId\":\"35681420\",\"name\":\"Suichan Li\"}],\"doi\":\"10.1117/12.2502012\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1ff84e253e643993521e181726e480799b382609\",\"title\":\"3D-DETNet: a single stage video-based vehicle detector\",\"url\":\"https://www.semanticscholar.org/paper/1ff84e253e643993521e181726e480799b382609\",\"venue\":\"International Workshop on Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1908.08178\",\"authors\":[{\"authorId\":\"48754312\",\"name\":\"Pengfei Zhang\"},{\"authorId\":\"48696416\",\"name\":\"Y. Cao\"},{\"authorId\":\"1761508\",\"name\":\"B. Liu\"}],\"doi\":\"10.1109/ICIP.2019.8803564\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f0ba9505b5f625fae2a0b50c89224744f5b11207\",\"title\":\"Multi-Stream Single Shot Spatial-Temporal Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/f0ba9505b5f625fae2a0b50c89224744f5b11207\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144785131\",\"name\":\"Ping Li\"},{\"authorId\":\"1749395\",\"name\":\"Xianghua Xu\"}],\"doi\":\"10.1109/ACCESS.2020.3003939\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f99d0990c255c635f731cefa434912b09598e8cd\",\"title\":\"Recurrent Compressed Convolutional Networks for Short Video Event Detection\",\"url\":\"https://www.semanticscholar.org/paper/f99d0990c255c635f731cefa434912b09598e8cd\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2002.03342\",\"authors\":[{\"authorId\":\"47203405\",\"name\":\"Wenhao Wu\"},{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"145681032\",\"name\":\"Xiao Tan\"},{\"authorId\":\"2869725\",\"name\":\"Shifeng Chen\"},{\"authorId\":null,\"name\":\"Yi Yang\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"}],\"doi\":\"10.1109/CVPRW50498.2020.00346\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"de79226c40767073dea787327637c8415b1bc60a\",\"title\":\"Dynamic Inference: A New Approach Toward Efficient Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/de79226c40767073dea787327637c8415b1bc60a\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"2008.12432\",\"authors\":[{\"authorId\":\"3349165\",\"name\":\"Pallabi Ghosh\"},{\"authorId\":\"19173161\",\"name\":\"Nirat Saini\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"},{\"authorId\":\"51453757\",\"name\":\"Abhinav Shrivastava\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"117595877c1fca610f94c8d07009105092939ecc\",\"title\":\"All About Knowledge Graphs for Actions\",\"url\":\"https://www.semanticscholar.org/paper/117595877c1fca610f94c8d07009105092939ecc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2000519679\",\"name\":\"Cheng Ming\"},{\"authorId\":\"2024215885\",\"name\":\"Cai Kunjing\"},{\"authorId\":\"143740589\",\"name\":\"Li Ming\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"091a6ac9f23460f91bda48084a608b51280e5be1\",\"title\":\"RWF-2000: An Open Large Scale Video Database for Violence Detection\",\"url\":\"https://www.semanticscholar.org/paper/091a6ac9f23460f91bda48084a608b51280e5be1\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1808.05085\",\"authors\":[{\"authorId\":\"40192003\",\"name\":\"Z. Zhang\"},{\"authorId\":\"1874900\",\"name\":\"Zhanghui Kuang\"},{\"authorId\":\"144389951\",\"name\":\"P. Luo\"},{\"authorId\":\"1739512\",\"name\":\"Litong Feng\"},{\"authorId\":\"1726357\",\"name\":\"Wayne Zhang\"}],\"doi\":\"10.1145/3240508.3240534\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d4c467adc09fb50c5e799fc124f3e82da8c3c22\",\"title\":\"Temporal Sequence Distillation: Towards Few-Frame Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/9d4c467adc09fb50c5e799fc124f3e82da8c3c22\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1711.06330\",\"authors\":[{\"authorId\":\"7437104\",\"name\":\"Chih-Yao Ma\"},{\"authorId\":\"2293919\",\"name\":\"Asim Kadav\"},{\"authorId\":\"50162780\",\"name\":\"I. Melvin\"},{\"authorId\":\"145276578\",\"name\":\"Z. Kira\"},{\"authorId\":\"9202076\",\"name\":\"G. Al-Regib\"},{\"authorId\":\"1775043\",\"name\":\"H. Graf\"}],\"doi\":\"10.1109/CVPR.2018.00710\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"66aebb3af16aaa78579344784212ae10f60ec27e\",\"title\":\"Attend and Interact: Higher-Order Object Interactions for Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/66aebb3af16aaa78579344784212ae10f60ec27e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7300621\",\"name\":\"Ziyu Jia\"},{\"authorId\":\"2468548\",\"name\":\"You-Fang Lin\"},{\"authorId\":\"103013328\",\"name\":\"Xiyang Cai\"},{\"authorId\":\"47666266\",\"name\":\"Haobin Chen\"},{\"authorId\":\"1993709739\",\"name\":\"Haijun Gou\"},{\"authorId\":\"2031695\",\"name\":\"Junchang Wang\"}],\"doi\":\"10.1145/3394171.3413724\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fc0c9b69b8b635791c0d0288cb046830e48d3dca\",\"title\":\"SST-EmotionNet: Spatial-Spectral-Temporal based Attention 3D Dense Network for EEG Emotion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fc0c9b69b8b635791c0d0288cb046830e48d3dca\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"87874401\",\"name\":\"Cai Qiang\"},{\"authorId\":\"1409990256\",\"name\":\"Jin Yan\"},{\"authorId\":\"144766132\",\"name\":\"Haisheng Li\"},{\"authorId\":\"2003541846\",\"name\":\"Deng Yibiao\"}],\"doi\":\"10.1007/978-981-15-8450-3_24\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"94c5d2d26bde4c314b7a51e42495192c5affb651\",\"title\":\"Human Action Recognition Method Based on Video-Level Features and Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/94c5d2d26bde4c314b7a51e42495192c5affb651\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121569773\",\"name\":\"Yuqian Fu\"},{\"authorId\":\"48586318\",\"name\":\"Chengrong Wang\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":null,\"name\":\"Yu-Xiong Wang\"},{\"authorId\":\"151495118\",\"name\":\"Cong Bai\"},{\"authorId\":\"48002027\",\"name\":\"X. Xue\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1145/3343031.3351015\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d54af916d7b813e798fa27327bfb0a909d816fd7\",\"title\":\"Embodied One-Shot Video Recognition: Learning from Actions of a Virtual Embodied Agent\",\"url\":\"https://www.semanticscholar.org/paper/d54af916d7b813e798fa27327bfb0a909d816fd7\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1910.08250\",\"authors\":[{\"authorId\":\"2724075\",\"name\":\"Yiping Tang\"},{\"authorId\":\"51431831\",\"name\":\"Chuang Niu\"},{\"authorId\":\"35182090\",\"name\":\"Minghao Dong\"},{\"authorId\":\"10648494\",\"name\":\"Shenghan Ren\"},{\"authorId\":\"145157018\",\"name\":\"J. Liang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"6bfb4ef35fd5e9820e23e130aff6c09aa2c6b75c\",\"title\":\"AFO-TAD: Anchor-free One-Stage Detector for Temporal Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/6bfb4ef35fd5e9820e23e130aff6c09aa2c6b75c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2010.06647\",\"authors\":[{\"authorId\":\"153634296\",\"name\":\"Matthew Hutchinson\"},{\"authorId\":\"74882299\",\"name\":\"Vijay Gadepally\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"65955a106905afb90a2a2fa74e48c6d6d597892f\",\"title\":\"Video Action Understanding: A Tutorial\",\"url\":\"https://www.semanticscholar.org/paper/65955a106905afb90a2a2fa74e48c6d6d597892f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.09215\",\"authors\":[{\"authorId\":\"50218817\",\"name\":\"Zhengwei Wang\"},{\"authorId\":\"1486411393\",\"name\":\"Qi She\"},{\"authorId\":\"25054465\",\"name\":\"Tejo Chalasani\"},{\"authorId\":\"118065745\",\"name\":\"A. Smolic\"}],\"doi\":\"10.1109/CVPRW50498.2020.00123\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"190999dcc6895c0218961a11ae3ef4d5d03ae5f0\",\"title\":\"CatNet: Class Incremental 3D ConvNets for Lifelong Egocentric Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/190999dcc6895c0218961a11ae3ef4d5d03ae5f0\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"2004.07485\",\"authors\":[{\"authorId\":\"152949394\",\"name\":\"J. Tang\"},{\"authorId\":\"49597328\",\"name\":\"J. Xia\"},{\"authorId\":\"13812767\",\"name\":\"Xinzhi Mu\"},{\"authorId\":\"1560385163\",\"name\":\"Bo Pang\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"}],\"doi\":\"10.1007/978-3-030-58555-6_5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e820578147cac31a6748c3f6ef2eeaccac066b41\",\"title\":\"Asynchronous Interaction Aggregation for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/e820578147cac31a6748c3f6ef2eeaccac066b41\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153082819\",\"name\":\"Qian Li\"},{\"authorId\":\"1992684694\",\"name\":\"Wenzhu Yang\"},{\"authorId\":\"1992715817\",\"name\":\"Xiangyang Chen\"},{\"authorId\":\"50090639\",\"name\":\"Tongtong Yuan\"},{\"authorId\":null,\"name\":\"Yuxia Wang\"}],\"doi\":\"10.1109/ACCESS.2020.3027386\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0475918d855bbfcf4c693359935d9a483b7541ce\",\"title\":\"Temporal Segment Connection Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/0475918d855bbfcf4c693359935d9a483b7541ce\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10001427\",\"name\":\"H. Fan\"},{\"authorId\":\"152604028\",\"name\":\"Cheng Luo\"},{\"authorId\":\"31902430\",\"name\":\"Chenglong Zeng\"},{\"authorId\":\"100998451\",\"name\":\"M. Ferianc\"},{\"authorId\":\"144514893\",\"name\":\"Zhiqiang Que\"},{\"authorId\":\"6287360\",\"name\":\"S. Liu\"},{\"authorId\":\"143825108\",\"name\":\"Xinyu Niu\"},{\"authorId\":\"144708627\",\"name\":\"W. Luk\"}],\"doi\":\"10.1109/ASAP.2019.00-44\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"fe692ad45181356472e507ec6cf78667e652f182\",\"title\":\"F-E3D: FPGA-based Acceleration of an Efficient 3D Convolutional Neural Network for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fe692ad45181356472e507ec6cf78667e652f182\",\"venue\":\"2019 IEEE 30th International Conference on Application-specific Systems, Architectures and Processors (ASAP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1878475584\",\"name\":\"Xin Gao\"},{\"authorId\":\"1878338267\",\"name\":\"Xusheng Liu\"},{\"authorId\":\"1879512992\",\"name\":\"Taotao Yang\"},{\"authorId\":\"34604525\",\"name\":\"G. Deng\"},{\"authorId\":\"1878360893\",\"name\":\"Hao Peng\"},{\"authorId\":\"1877628045\",\"name\":\"Qiaosong Zhang\"},{\"authorId\":\"97584815\",\"name\":\"H. Li\"},{\"authorId\":\"1879297772\",\"name\":\"Junhui Liu\"}],\"doi\":\"10.1109/ICMEW46912.2020.9106051\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"31e55bc719db796d8022b2c9b1e9285812fb0da8\",\"title\":\"Automatic Key Moment Extraction and Highlights Generation Based on Comprehensive Soccer Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/31e55bc719db796d8022b2c9b1e9285812fb0da8\",\"venue\":\"2020 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2020},{\"arxivId\":\"1905.12462\",\"authors\":[{\"authorId\":\"1756362\",\"name\":\"Swathikiran Sudhakaran\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"adec3b5b4ebccbdacdcd0c805f7c73501852b3cd\",\"title\":\"Hierarchical Feature Aggregation Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/adec3b5b4ebccbdacdcd0c805f7c73501852b3cd\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1811.07468\",\"authors\":[{\"authorId\":\"2259852\",\"name\":\"Jianing Li\"},{\"authorId\":\"47179758\",\"name\":\"Shiliang Zhang\"},{\"authorId\":\"34097174\",\"name\":\"Tiejun Huang\"}],\"doi\":\"10.1609/aaai.v33i01.33018618\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"242e19b95f1cf77a74f1a99a899a8dc7d34f7c10\",\"title\":\"Multi-scale 3D Convolution Network for Video Based Person Re-Identification\",\"url\":\"https://www.semanticscholar.org/paper/242e19b95f1cf77a74f1a99a899a8dc7d34f7c10\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1907.01847\",\"authors\":[{\"authorId\":\"73383712\",\"name\":\"W. Li\"},{\"authorId\":\"51305314\",\"name\":\"Zehuan Yuan\"},{\"authorId\":\"20412557\",\"name\":\"Dashan Guo\"},{\"authorId\":\"144585903\",\"name\":\"L. Huang\"},{\"authorId\":\"1706164\",\"name\":\"X. Fang\"},{\"authorId\":\"1697065\",\"name\":\"C. Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c33e9aaec527dfeb733fc10c1d2bda417f546b37\",\"title\":\"Deformable Tube Network for Action Detection in Videos\",\"url\":\"https://www.semanticscholar.org/paper/c33e9aaec527dfeb733fc10c1d2bda417f546b37\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[],\"doi\":\"10.1007/978-981-15-4584-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b89036fc9082a9b1871d04a679d68b284069fdb8\",\"title\":\"The Development of Deep Learning Technologies: Research on the Development of Electronic Information Engineering Technology in China\",\"url\":\"https://www.semanticscholar.org/paper/b89036fc9082a9b1871d04a679d68b284069fdb8\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47837986\",\"name\":\"An Yan\"},{\"authorId\":null,\"name\":\"Yali Wang\"},{\"authorId\":\"9247990\",\"name\":\"Zhifeng Li\"},{\"authorId\":\"143970608\",\"name\":\"Y. Qiao\"}],\"doi\":\"10.1109/CVPR.2019.00811\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4ef4bdad7673050b3764e06a26085f9f8ef11e50\",\"title\":\"PA3D: Pose-Action 3D Machine for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4ef4bdad7673050b3764e06a26085f9f8ef11e50\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2912976\",\"name\":\"W. N. Khotimah\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"2795743\",\"name\":\"Farid Boussa\\u00efd\"},{\"authorId\":\"19324907\",\"name\":\"F. Sohel\"},{\"authorId\":\"152660969\",\"name\":\"D. Edwards\"}],\"doi\":\"10.3390/rs12193137\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"10f9ac6408659b9ecee1df601f4567bce5995e26\",\"title\":\"A High-Performance Spectral-Spatial Residual Network for Hyperspectral Image Classification with Small Training Data\",\"url\":\"https://www.semanticscholar.org/paper/10f9ac6408659b9ecee1df601f4567bce5995e26\",\"venue\":\"Remote. Sens.\",\"year\":2020},{\"arxivId\":\"2008.09753\",\"authors\":[{\"authorId\":\"82176786\",\"name\":\"Yisi Luo\"},{\"authorId\":\"3394214\",\"name\":\"Xile Zhao\"},{\"authorId\":\"22173072\",\"name\":\"Tai-Xiang Jiang\"},{\"authorId\":\"103429531\",\"name\":\"Yu-Bang Zheng\"},{\"authorId\":\"145882798\",\"name\":\"Yi Chang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"727977072a8ffc9342f72353f5cf67d7b4f7c898\",\"title\":\"Unsupervised Hyperspectral Mixed Noise Removal Via Spatial-Spectral Constrained Deep Image Prior\",\"url\":\"https://www.semanticscholar.org/paper/727977072a8ffc9342f72353f5cf67d7b4f7c898\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1809.04096\",\"authors\":[{\"authorId\":\"49147616\",\"name\":\"Felix Gonda\"},{\"authorId\":\"1766333\",\"name\":\"D. Wei\"},{\"authorId\":\"1807477\",\"name\":\"T. Parag\"},{\"authorId\":\"143758236\",\"name\":\"H. Pfister\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3557b92c64d17717253a3a6136fc85cf41ee3036\",\"title\":\"Parallel Separable 3D Convolution for Video and Volumetric Data Understanding\",\"url\":\"https://www.semanticscholar.org/paper/3557b92c64d17717253a3a6136fc85cf41ee3036\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":\"1804.01429\",\"authors\":[{\"authorId\":\"2180291\",\"name\":\"Ruichi Yu\"},{\"authorId\":\"48016412\",\"name\":\"H. Wang\"},{\"authorId\":\"145476833\",\"name\":\"Ang Li\"},{\"authorId\":\"7674316\",\"name\":\"Jingxiao Zheng\"},{\"authorId\":\"2852035\",\"name\":\"V. Morariu\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/ICCV.2019.00135\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9664f41b8e21125fed01fa3858ca40949fb73e01\",\"title\":\"Layout-Induced Video Representation for Recognizing Agent-in-Place Actions\",\"url\":\"https://www.semanticscholar.org/paper/9664f41b8e21125fed01fa3858ca40949fb73e01\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2006.15560\",\"authors\":[{\"authorId\":\"1391155455\",\"name\":\"Yin-Dong Zheng\"},{\"authorId\":\"46270766\",\"name\":\"Zhaoyang Liu\"},{\"authorId\":\"144720251\",\"name\":\"Tong Lu\"},{\"authorId\":\"29461006\",\"name\":\"L. Wang\"}],\"doi\":\"10.1109/TIP.2020.3007826\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3ee328e73acc9be44d874756dab4c13c65a835c0\",\"title\":\"Dynamic Sampling Networks for Efficient Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/3ee328e73acc9be44d874756dab4c13c65a835c0\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"2008.01432\",\"authors\":[{\"authorId\":\"13657788\",\"name\":\"Y. Bai\"},{\"authorId\":null,\"name\":\"Yingying Wang\"},{\"authorId\":\"8230405\",\"name\":\"Y. Tong\"},{\"authorId\":\"46285717\",\"name\":\"Y. Yang\"},{\"authorId\":\"150270503\",\"name\":\"Qiyue Liu\"},{\"authorId\":\"48211752\",\"name\":\"Jun-Hui Liu\"}],\"doi\":\"10.1007/978-3-030-58604-1_8\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ab87795177c3d53913cc91771162420ef75671e3\",\"title\":\"Boundary Content Graph Neural Network for Temporal Action Proposal Generation\",\"url\":\"https://www.semanticscholar.org/paper/ab87795177c3d53913cc91771162420ef75671e3\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3275727\",\"name\":\"Linxi (Jim) Fan\"},{\"authorId\":\"8983218\",\"name\":\"S. Buch\"},{\"authorId\":\"96374437\",\"name\":\"Guanzhi Wang\"},{\"authorId\":\"2013547017\",\"name\":\"Ryan Cao\"},{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/978-3-030-58529-7_30\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3ab0c5006bb157b801ec592951a1da2c8af9d158\",\"title\":\"RubiksNet: Learnable 3D-Shift for Efficient Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3ab0c5006bb157b801ec592951a1da2c8af9d158\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1904.10666\",\"authors\":[{\"authorId\":\"3306760\",\"name\":\"Hsu-Kuang Chiu\"},{\"authorId\":\"3419364\",\"name\":\"E. Adeli\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/LRA.2020.2992184\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"73c28cef6c0d58b101204609137af39c3e94c047\",\"title\":\"Segmenting the Future\",\"url\":\"https://www.semanticscholar.org/paper/73c28cef6c0d58b101204609137af39c3e94c047\",\"venue\":\"IEEE Robotics and Automation Letters\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145082678\",\"name\":\"G. Chen\"},{\"authorId\":\"35325151\",\"name\":\"Yuexian Zou\"},{\"authorId\":\"47423370\",\"name\":\"Can Zhang\"}],\"doi\":\"10.1007/978-3-030-05710-7_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"64a157d61e72b204013acb70bb5c16b55ce7ba09\",\"title\":\"STMP: Spatial Temporal Multi-level Proposal Network for Activity Detection\",\"url\":\"https://www.semanticscholar.org/paper/64a157d61e72b204013acb70bb5c16b55ce7ba09\",\"venue\":\"MMM\",\"year\":2019},{\"arxivId\":\"2002.07358\",\"authors\":[{\"authorId\":\"2283619\",\"name\":\"Peisen Zhao\"},{\"authorId\":\"3041937\",\"name\":\"Lingxi Xie\"},{\"authorId\":\"2899544\",\"name\":\"C. Ju\"},{\"authorId\":\"49890039\",\"name\":\"Y. Zhang\"},{\"authorId\":null,\"name\":\"Yanfeng Wang\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1007/978-3-030-58598-3_32\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"44e8ddac792f35105dd4db176345515f531a0b71\",\"title\":\"Bottom-Up Temporal Action Localization with Mutual Regularization\",\"url\":\"https://www.semanticscholar.org/paper/44e8ddac792f35105dd4db176345515f531a0b71\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39576371\",\"name\":\"A. Manglik\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"28b9478ac3df9ffa5a8a635af339fdae51fc6999\",\"title\":\"Real-Time Collision Forecasting from Monocular Video\",\"url\":\"https://www.semanticscholar.org/paper/28b9478ac3df9ffa5a8a635af339fdae51fc6999\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1809.03770\",\"authors\":[{\"authorId\":\"34596685\",\"name\":\"Aaron S. Jackson\"},{\"authorId\":\"82960150\",\"name\":\"Chris Manafas\"},{\"authorId\":\"2610880\",\"name\":\"Georgios Tzimiropoulos\"}],\"doi\":\"10.1007/978-3-030-11018-5_6\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e4c08dd93faf88005ab923fa284c74aea6c55928\",\"title\":\"3D Human Body Reconstruction from a Single Image via Volumetric Regression\",\"url\":\"https://www.semanticscholar.org/paper/e4c08dd93faf88005ab923fa284c74aea6c55928\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"1906.07944\",\"authors\":[{\"authorId\":\"49141069\",\"name\":\"Mingjie Li\"},{\"authorId\":\"2904330\",\"name\":\"Youqian Feng\"},{\"authorId\":\"2903790\",\"name\":\"Zhonghai Yin\"},{\"authorId\":\"1776984\",\"name\":\"Cheng Zhou\"},{\"authorId\":\"146700602\",\"name\":\"Fanghao Dong\"},{\"authorId\":\"71219669\",\"name\":\"Yuan Lin\"},{\"authorId\":\"4864147\",\"name\":\"Yuhao Dong\"}],\"doi\":\"10.1088/1742-6596/1325/1/012073\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a3920ab70d6a8448a23f1ef621d1be57af8b7579\",\"title\":\"An Action Recognition network for specific target based on rMC and RPN\",\"url\":\"https://www.semanticscholar.org/paper/a3920ab70d6a8448a23f1ef621d1be57af8b7579\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143668321\",\"name\":\"Yuchen Fan\"},{\"authorId\":\"150167366\",\"name\":\"Jiahui Yu\"},{\"authorId\":\"1771885\",\"name\":\"Ding Liu\"},{\"authorId\":\"143750392\",\"name\":\"T. Huang\"}],\"doi\":\"10.1109/CVPRW.2019.00269\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"79d344c5705b3a54fc2af2c6783b0b4c65c706a0\",\"title\":\"An Empirical Investigation of Efficient Spatio-Temporal Modeling in Video Restoration\",\"url\":\"https://www.semanticscholar.org/paper/79d344c5705b3a54fc2af2c6783b0b4c65c706a0\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390477390\",\"name\":\"Zhenhao Sun\"},{\"authorId\":\"15592126\",\"name\":\"Xiaodong Wang\"},{\"authorId\":\"30024940\",\"name\":\"Qiudan Zhang\"},{\"authorId\":\"145054089\",\"name\":\"J. Jiang\"}],\"doi\":\"10.1109/ACCESS.2019.2946479\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3e896d6e00cd47f8ec07cf4a641d48f032895058\",\"title\":\"Real-Time Video Saliency Prediction Via 3D Residual Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/3e896d6e00cd47f8ec07cf4a641d48f032895058\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"2004.01278\",\"authors\":[{\"authorId\":\"1397974082\",\"name\":\"Juan-Manuel Perez-Rua\"},{\"authorId\":\"145944235\",\"name\":\"B. Mart\\u00ednez\"},{\"authorId\":\"2171228\",\"name\":\"Xiatian Zhu\"},{\"authorId\":\"3098817\",\"name\":\"Antoine Toisoul\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"145406420\",\"name\":\"Tao Xiang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8fcc3c2e525307f7a694979500dcca09d0f3a830\",\"title\":\"Knowing What, Where and When to Look: Efficient Video Action Modeling with Attention\",\"url\":\"https://www.semanticscholar.org/paper/8fcc3c2e525307f7a694979500dcca09d0f3a830\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"69893872\",\"name\":\"Yuri Yudhaswana Joefrie\"},{\"authorId\":\"96853476\",\"name\":\"Masaki Aono\"}],\"doi\":\"10.1109/ACCESS.2020.3025931\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0ef9affa9c633e1c2713cef266f246c4a0a23821\",\"title\":\"Multi-Label Multi-Class Action Recognition With Deep Spatio-Temporal Layers Based on Temporal Gaussian Mixtures\",\"url\":\"https://www.semanticscholar.org/paper/0ef9affa9c633e1c2713cef266f246c4a0a23821\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1808.00022\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":\"10.1016/j.cviu.2019.102799\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ef7b835c451793a6ea603fa3d5441901832c404e\",\"title\":\"Analyzing human-human interactions: A survey\",\"url\":\"https://www.semanticscholar.org/paper/ef7b835c451793a6ea603fa3d5441901832c404e\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2019},{\"arxivId\":\"1912.03716\",\"authors\":[{\"authorId\":\"91060830\",\"name\":\"Zhiyu Yao\"},{\"authorId\":null,\"name\":\"Yunbo Wang\"},{\"authorId\":\"93640403\",\"name\":\"Xingqiang Du\"},{\"authorId\":\"35776445\",\"name\":\"Mingsheng Long\"},{\"authorId\":\"46583978\",\"name\":\"J. Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2df80c3db4550da81854e05a24e658bacec564a2\",\"title\":\"Adversarial Pyramid Network for Video Domain Generalization\",\"url\":\"https://www.semanticscholar.org/paper/2df80c3db4550da81854e05a24e658bacec564a2\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1409413243\",\"name\":\"Hongwei Dong\"},{\"authorId\":\"47058824\",\"name\":\"Lamei Zhang\"},{\"authorId\":\"46564716\",\"name\":\"Bin Zou\"}],\"doi\":\"10.3390/rs12030396\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aa04538df61d90bb4665c0b7b601cec585af98fc\",\"title\":\"PolSAR Image Classification with Lightweight 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/aa04538df61d90bb4665c0b7b601cec585af98fc\",\"venue\":\"Remote. Sens.\",\"year\":2020},{\"arxivId\":\"2006.13017\",\"authors\":[{\"authorId\":\"143657833\",\"name\":\"Li Tao\"},{\"authorId\":\"1524733293\",\"name\":\"Xueting Wang\"},{\"authorId\":\"145572095\",\"name\":\"T. Yamasaki\"}],\"doi\":\"10.1109/ICIP40778.2020.9191133\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3cfee833437b81b89bb272dd4f5a501b61f2c0d1\",\"title\":\"Motion Representation Using Residual Frames with 3D CNN\",\"url\":\"https://www.semanticscholar.org/paper/3cfee833437b81b89bb272dd4f5a501b61f2c0d1\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"1808.07272\",\"authors\":[{\"authorId\":\"2527741\",\"name\":\"Sibo Song\"},{\"authorId\":\"143770929\",\"name\":\"N. Cheung\"},{\"authorId\":\"1802086\",\"name\":\"V. Chandrasekhar\"},{\"authorId\":\"1709001\",\"name\":\"B. Mandal\"}],\"doi\":\"10.1145/3240508.3240713\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d09d663055b3b6d588bf4de2f386bb144d09aea8\",\"title\":\"Deep Adaptive Temporal Pooling for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d09d663055b3b6d588bf4de2f386bb144d09aea8\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145625558\",\"name\":\"Chuankun Li\"},{\"authorId\":\"3292845\",\"name\":\"Y. Hou\"},{\"authorId\":\"40508657\",\"name\":\"W. Li\"},{\"authorId\":\"8120382\",\"name\":\"P. Wang\"}],\"doi\":\"10.1016/j.jvcir.2019.102640\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c960014ee78d90479d34f2a0c75e46f4f3a78c86\",\"title\":\"Learning attentive dynamic maps (ADMs) for Understanding Human Actions\",\"url\":\"https://www.semanticscholar.org/paper/c960014ee78d90479d34f2a0c75e46f4f3a78c86\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":\"1904.10631\",\"authors\":[{\"authorId\":\"145193121\",\"name\":\"N. S. Sohoni\"},{\"authorId\":\"3133156\",\"name\":\"C. R. Aberger\"},{\"authorId\":\"37866790\",\"name\":\"Megan Leszczynski\"},{\"authorId\":\"1679327\",\"name\":\"Jian Zhang\"},{\"authorId\":\"144988097\",\"name\":\"C. R\\u00e9\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0b5d7a79205b44952e24025ce5d46e9f3aa401a1\",\"title\":\"Low-Memory Neural Network Training: A Technical Report\",\"url\":\"https://www.semanticscholar.org/paper/0b5d7a79205b44952e24025ce5d46e9f3aa401a1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1811.08362\",\"authors\":[{\"authorId\":\"91060830\",\"name\":\"Zhiyu Yao\"},{\"authorId\":null,\"name\":\"Yunbo Wang\"},{\"authorId\":\"35776445\",\"name\":\"Mingsheng Long\"},{\"authorId\":\"1519286448\",\"name\":\"J. Wang\"},{\"authorId\":\"144019071\",\"name\":\"Philip S. Yu\"},{\"authorId\":\"153552276\",\"name\":\"J. Sun\"}],\"doi\":\"10.1109/ICME46284.2020.9102724\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"371ab565b512a5ef9133831c8b7b04fb5b1905c4\",\"title\":\"Multi-Task Learning of Generalizable Representations for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/371ab565b512a5ef9133831c8b7b04fb5b1905c4\",\"venue\":\"2020 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2020},{\"arxivId\":\"2007.06149\",\"authors\":[{\"authorId\":\"2283619\",\"name\":\"Peisen Zhao\"},{\"authorId\":\"3041937\",\"name\":\"Lingxi Xie\"},{\"authorId\":\"49890039\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/tmm.2020.3025665\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6c1fc76cc67ad82df1f7695b4d9e0b7536a70732\",\"title\":\"Universal-to-Specific Framework for Complex Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6c1fc76cc67ad82df1f7695b4d9e0b7536a70732\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72613367\",\"name\":\"Xingyu Xu\"},{\"authorId\":\"15626401\",\"name\":\"X. Wu\"},{\"authorId\":\"47227094\",\"name\":\"G. Wang\"},{\"authorId\":\"48017178\",\"name\":\"H. Wang\"}],\"doi\":\"10.1109/ISCID.2018.00079\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2465ebbe1d40f289a8db4b0dcaf3dbbb9cdc494b\",\"title\":\"Violent Video Classification Based on Spatial-Temporal Cues Using Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/2465ebbe1d40f289a8db4b0dcaf3dbbb9cdc494b\",\"venue\":\"2018 11th International Symposium on Computational Intelligence and Design (ISCID)\",\"year\":2018},{\"arxivId\":\"1905.12681\",\"authors\":[{\"authorId\":\"7634810\",\"name\":\"Weiyao Wang\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4b434904230cd2c09f349cc69b72baa670b5d815\",\"title\":\"What Makes Training Multi-Modal Networks Hard?\",\"url\":\"https://www.semanticscholar.org/paper/4b434904230cd2c09f349cc69b72baa670b5d815\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2012.08041\",\"authors\":[{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"50557221\",\"name\":\"Chunhui Liu\"},{\"authorId\":\"2521776\",\"name\":\"B. Shuai\"},{\"authorId\":\"1805946041\",\"name\":\"Yi Zhu\"},{\"authorId\":\"48444479\",\"name\":\"Hao Chen\"},{\"authorId\":\"2397422\",\"name\":\"Joseph Tighe\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"f0d55ca0b8f1639372e88479516a573e2bf2250b\",\"title\":\"NUTA: Non-uniform Temporal Aggregation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f0d55ca0b8f1639372e88479516a573e2bf2250b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151484259\",\"name\":\"Lianwei Li\"},{\"authorId\":\"1793858\",\"name\":\"Shiyin Qin\"},{\"authorId\":\"144868793\",\"name\":\"Z. Lu\"},{\"authorId\":\"2875815\",\"name\":\"Kuanhong Xu\"},{\"authorId\":\"89726331\",\"name\":\"Zhongying Hu\"}],\"doi\":\"10.1007/s11042-019-08429-9\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"585796bb282b60d632189cf21368836db9954f0f\",\"title\":\"One-shot learning gesture recognition based on joint training of 3D ResNet and memory module\",\"url\":\"https://www.semanticscholar.org/paper/585796bb282b60d632189cf21368836db9954f0f\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123331898\",\"name\":\"Y. Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a6e60bc1a90aa660320476bd422239cfaa1d9ee5\",\"title\":\"Refinement of Boundary Regression Using Uncertainty in Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/a6e60bc1a90aa660320476bd422239cfaa1d9ee5\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144077750\",\"name\":\"Hang Zhao\"},{\"authorId\":null,\"name\":\"Zhicheng Yan\"},{\"authorId\":null,\"name\":\"Heng Wang\"},{\"authorId\":null,\"name\":\"Lorenzo Torresani\"}],\"doi\":\"10.1109/ICCV.2019.00876\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5aeef2c4f3eb125ec1db9c20392f95e64ef62b41\",\"title\":\"HACS: Human Action Clips and Segments Dataset for Recognition and Temporal Localization\",\"url\":\"https://www.semanticscholar.org/paper/5aeef2c4f3eb125ec1db9c20392f95e64ef62b41\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3258842\",\"name\":\"J. Wang\"},{\"authorId\":\"1788029\",\"name\":\"W. Wang\"},{\"authorId\":\"48385803\",\"name\":\"W. Gao\"}],\"doi\":\"10.1109/TMM.2018.2855081\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d3aba33ac0025d067bc3ed80d2d73ee883a1c2b1\",\"title\":\"Multiscale Deep Alternative Neural Network for Large-Scale Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/d3aba33ac0025d067bc3ed80d2d73ee883a1c2b1\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"},{\"authorId\":\"48481929\",\"name\":\"Yi-jun Song\"},{\"authorId\":\"47891191\",\"name\":\"Jun Yu\"},{\"authorId\":\"48957872\",\"name\":\"Meng Wang\"},{\"authorId\":\"153159021\",\"name\":\"Qingming Huang\"}],\"doi\":\"10.1007/s11063-020-10205-y\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c1d607b58d31c582bee0cc78017909a1eed45c9\",\"title\":\"Intra- and Inter-modal Multilinear Pooling with Multitask Learning for Video Grounding\",\"url\":\"https://www.semanticscholar.org/paper/6c1d607b58d31c582bee0cc78017909a1eed45c9\",\"venue\":\"Neural Processing Letters\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"97232650\",\"name\":\"W. Dai\"},{\"authorId\":\"50579817\",\"name\":\"Yi-min Chen\"},{\"authorId\":\"73067906\",\"name\":\"C. Huang\"},{\"authorId\":\"71543140\",\"name\":\"Mingke Gao\"},{\"authorId\":\"50812964\",\"name\":\"Xinyu Zhang\"}],\"doi\":\"10.1109/IJCNN.2019.8851702\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"414e4a17e5b661c36e20937223bbe312ed227efc\",\"title\":\"Two-Stream Convolution Neural Network with Video-stream for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/414e4a17e5b661c36e20937223bbe312ed227efc\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":\"1902.06162\",\"authors\":[{\"authorId\":\"29724362\",\"name\":\"Longlong Jing\"},{\"authorId\":\"35484757\",\"name\":\"Yingli Tian\"}],\"doi\":\"10.1109/tpami.2020.2992393\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4c94ee7df6bc2bfcac76703be4f059a79010f7e5\",\"title\":\"Self-supervised Visual Feature Learning with Deep Neural Networks: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/4c94ee7df6bc2bfcac76703be4f059a79010f7e5\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21518096\",\"name\":\"Zhengyuan Yang\"},{\"authorId\":\"3092578\",\"name\":\"Y. Li\"},{\"authorId\":\"1706007\",\"name\":\"Jianchao Yang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/TCSVT.2018.2864148\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"08cc8c38c25f2bc87d44e35abbccd6a88eb5103b\",\"title\":\"Action Recognition With Spatio\\u2013Temporal Visual Attention on Skeleton Image Sequences\",\"url\":\"https://www.semanticscholar.org/paper/08cc8c38c25f2bc87d44e35abbccd6a88eb5103b\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":\"2009.09818\",\"authors\":[{\"authorId\":\"145098776\",\"name\":\"Umar Asif\"},{\"authorId\":\"2363364\",\"name\":\"D. Mehta\"},{\"authorId\":\"2103918\",\"name\":\"Stefan von Cavallar\"},{\"authorId\":\"2328282\",\"name\":\"J. Tang\"},{\"authorId\":\"40639323\",\"name\":\"S. Harrer\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0f64c5330704d9d0909044fb653313c23e4a02ef\",\"title\":\"DeepActsNet: Spatial and Motion features from Face, Hands, and Body Combined with Convolutional and Graph Networks for Improved Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/0f64c5330704d9d0909044fb653313c23e4a02ef\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92533069\",\"name\":\"L. Chi\"},{\"authorId\":\"2704823\",\"name\":\"Ze-Huan Yuan\"},{\"authorId\":\"145353089\",\"name\":\"Y. Mu\"},{\"authorId\":\"1697065\",\"name\":\"C. Wang\"}],\"doi\":\"10.1109/cvpr42600.2020.01182\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6dcb726b4e1afa5fa6f8684081f19508e61b45c0\",\"title\":\"Non-Local Neural Networks With Grouped Bilinear Attentional Transforms\",\"url\":\"https://www.semanticscholar.org/paper/6dcb726b4e1afa5fa6f8684081f19508e61b45c0\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46365948\",\"name\":\"J. Wu\"},{\"authorId\":\"145951569\",\"name\":\"Wu Luo\"},{\"authorId\":\"120639867\",\"name\":\"Weiwei Liu\"},{\"authorId\":\"50445905\",\"name\":\"Chongyang Zhang\"}],\"doi\":\"10.1109/ICASSP40776.2020.9054282\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2f20c25ef69171a64549b5aa9b0dc62e98878ff0\",\"title\":\"Global and Local Discriminative Patches Exploiting for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2f20c25ef69171a64549b5aa9b0dc62e98878ff0\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"2005.00253\",\"authors\":[{\"authorId\":\"19263938\",\"name\":\"Elahe Vahdani\"},{\"authorId\":\"29724362\",\"name\":\"Longlong Jing\"},{\"authorId\":\"145587605\",\"name\":\"Y. Tian\"},{\"authorId\":\"1747703\",\"name\":\"Matt Huenerfauth\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"206beeef56a1cb5409d5b5a4395255ffe9c38bbe\",\"title\":\"Recognizing American Sign Language Nonmanual Signal Grammar Errors in Continuous Videos\",\"url\":\"https://www.semanticscholar.org/paper/206beeef56a1cb5409d5b5a4395255ffe9c38bbe\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.12424\",\"authors\":[{\"authorId\":\"1596823732\",\"name\":\"Baifeng Shi\"},{\"authorId\":\"152464732\",\"name\":\"Qi Dai\"},{\"authorId\":\"145353089\",\"name\":\"Y. Mu\"},{\"authorId\":\"1688516\",\"name\":\"Jingdong Wang\"}],\"doi\":\"10.1109/CVPR42600.2020.00109\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3e9901bccd0b210daff1fbeff758cea3cc0ec7f9\",\"title\":\"Weakly-Supervised Action Localization by Generative Attention Modeling\",\"url\":\"https://www.semanticscholar.org/paper/3e9901bccd0b210daff1fbeff758cea3cc0ec7f9\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3530540\",\"name\":\"Yunbo Wang\"},{\"authorId\":\"91060830\",\"name\":\"Zhiyu Yao\"},{\"authorId\":\"7296530\",\"name\":\"Hongyu Zhu\"},{\"authorId\":\"35776445\",\"name\":\"Mingsheng Long\"},{\"authorId\":\"1751179\",\"name\":\"J. Wang\"},{\"authorId\":\"144019071\",\"name\":\"Philip S. Yu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"10f7551bb9f6fa992660e70cb2896b8d5bdcc406\",\"title\":\"Reversing Two-Stream Networks with Decoding Discrepancy Penalty for Robust Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/10f7551bb9f6fa992660e70cb2896b8d5bdcc406\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"14542853\",\"name\":\"K. Hu\"},{\"authorId\":\"48708295\",\"name\":\"Z. Wang\"},{\"authorId\":\"153321393\",\"name\":\"K. E. Martens\"},{\"authorId\":\"144506986\",\"name\":\"S. Lewis\"}],\"doi\":\"10.1007/978-3-030-20887-5_35\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f40c2c3080f20a1c435e547f1020ab88352df9da\",\"title\":\"Vision-Based Freezing of Gait Detection with Anatomic Patch Based Representation\",\"url\":\"https://www.semanticscholar.org/paper/f40c2c3080f20a1c435e547f1020ab88352df9da\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"1808.02536\",\"authors\":[{\"authorId\":\"145979995\",\"name\":\"D. Zhang\"},{\"authorId\":\"3386593\",\"name\":\"X. Dai\"},{\"authorId\":\"1706938\",\"name\":\"Y. Wang\"}],\"doi\":\"10.1007/978-3-030-20870-7_44\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"929c8a73fceb88148847c6abca98a4d413d15415\",\"title\":\"Dynamic Temporal Pyramid Network: A Closer Look at Multi-Scale Modeling for Activity Detection\",\"url\":\"https://www.semanticscholar.org/paper/929c8a73fceb88148847c6abca98a4d413d15415\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"2006.08247\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":\"10.1016/j.patrec.2020.11.012\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9c9ee02e3394adde596c35d1966566b2d971f426\",\"title\":\"Learn to cycle: Time-consistent feature discovery for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/9c9ee02e3394adde596c35d1966566b2d971f426\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.09837\",\"authors\":[{\"authorId\":\"46554630\",\"name\":\"L. Yang\"},{\"authorId\":\"2484788\",\"name\":\"Houwen Peng\"},{\"authorId\":\"39901030\",\"name\":\"Dingwen Zhang\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"122200133\",\"name\":\"J. Han\"}],\"doi\":\"10.1109/TIP.2020.3016486\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"086057656b94de8bfd0d50ebe935e3d433f593d3\",\"title\":\"Revisiting Anchor Mechanisms for Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/086057656b94de8bfd0d50ebe935e3d433f593d3\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48669017\",\"name\":\"Siyu Huang\"},{\"authorId\":\"40286484\",\"name\":\"Xi Li\"},{\"authorId\":\"1720488\",\"name\":\"Zhongfei Zhang\"},{\"authorId\":\"144894849\",\"name\":\"Fei Wu\"},{\"authorId\":\"7181955\",\"name\":\"J. Han\"}],\"doi\":\"10.1109/TIP.2018.2889265\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8e3ec088d483f2302aa8b67069c82e8b59deb16d\",\"title\":\"User-Ranking Video Summarization With Multi-Stage Spatio\\u2013Temporal Representation\",\"url\":\"https://www.semanticscholar.org/paper/8e3ec088d483f2302aa8b67069c82e8b59deb16d\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145914256\",\"name\":\"H. Jin\"},{\"authorId\":\"47655718\",\"name\":\"Bo Liu\"},{\"authorId\":\"2868159\",\"name\":\"Wenbin Jiang\"},{\"authorId\":\"144249534\",\"name\":\"Y. Ma\"},{\"authorId\":\"1678835\",\"name\":\"X. Shi\"},{\"authorId\":\"143824511\",\"name\":\"B. He\"},{\"authorId\":\"7420378\",\"name\":\"Shaofeng Zhao\"}],\"doi\":\"10.1145/3243904\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9888edfb6276887eb56a6da7fe561e508e72a517\",\"title\":\"Layer-Centric Memory Reuse and Data Migration for Extreme-Scale Deep Learning on Many-Core Architectures\",\"url\":\"https://www.semanticscholar.org/paper/9888edfb6276887eb56a6da7fe561e508e72a517\",\"venue\":\"ACM Trans. Archit. Code Optim.\",\"year\":2018},{\"arxivId\":\"2009.06902\",\"authors\":[{\"authorId\":\"13099867\",\"name\":\"Haisheng Su\"},{\"authorId\":\"1768759403\",\"name\":\"Jing Su\"},{\"authorId\":\"1605763279\",\"name\":\"Dongliang Wang\"},{\"authorId\":\"35893447\",\"name\":\"W. Gan\"},{\"authorId\":\"145717875\",\"name\":\"Wei Wu\"},{\"authorId\":\"47446949\",\"name\":\"M. Wang\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\"},{\"authorId\":\"145858545\",\"name\":\"Y. Qiao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"882a973e02bfe9717f4ad70fe9fb327a515b16ca\",\"title\":\"Collaborative Distillation in the Parameter and Spectrum Domains for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/882a973e02bfe9717f4ad70fe9fb327a515b16ca\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.00975\",\"authors\":[{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"1591131960\",\"name\":\"Yiheng Zhang\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"1490772804\",\"name\":\"Tao Mei\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7b4741f8e6667664f1b21c390830b2022eca2da0\",\"title\":\"SeCo: Exploring Sequence Supervision for Unsupervised Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/7b4741f8e6667664f1b21c390830b2022eca2da0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47320160\",\"name\":\"Shengchao Li\"},{\"authorId\":\"47058844\",\"name\":\"Lin Zhang\"},{\"authorId\":\"2256493\",\"name\":\"Xiumin Diao\"}],\"doi\":\"10.1109/ROMAN.2018.8525781\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e667250b0407b262e9d15929c86b6da347f9cdc9\",\"title\":\"Improving Human Intention Prediction Using Data Augmentation\",\"url\":\"https://www.semanticscholar.org/paper/e667250b0407b262e9d15929c86b6da347f9cdc9\",\"venue\":\"2018 27th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47703700\",\"name\":\"Kun Hu\"},{\"authorId\":\"50857536\",\"name\":\"Z. Wang\"},{\"authorId\":\"39145049\",\"name\":\"W. Wang\"},{\"authorId\":\"66155252\",\"name\":\"Kaylena A Ehgoetz Martens\"},{\"authorId\":\"144143336\",\"name\":\"Liang Wang\"},{\"authorId\":\"145808910\",\"name\":\"Tieniu Tan\"},{\"authorId\":\"144119247\",\"name\":\"S. J. Lewis\"},{\"authorId\":\"145855523\",\"name\":\"D. Feng\"}],\"doi\":\"10.1109/TIP.2019.2946469\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"bf6a957eba57632f240cd3617bc6e88b51806403\",\"title\":\"Graph Sequence Recurrent Neural Network for Vision-Based Freezing of Gait Detection\",\"url\":\"https://www.semanticscholar.org/paper/bf6a957eba57632f240cd3617bc6e88b51806403\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49527668\",\"name\":\"Haonan Wang\"},{\"authorId\":\"95163406\",\"name\":\"Y. Mei\"},{\"authorId\":\"95339157\",\"name\":\"J. Lin\"},{\"authorId\":\"2539310\",\"name\":\"Z. Wang\"}],\"doi\":\"10.1109/SiPS50750.2020.9195240\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"0612a6a61f26dc9d8cd50dfa9c6f83e268e2ae58\",\"title\":\"Temporal Residual Feature Learning for Efficient 3D Convolutional Neural Network on Action Recognition Task\",\"url\":\"https://www.semanticscholar.org/paper/0612a6a61f26dc9d8cd50dfa9c6f83e268e2ae58\",\"venue\":\"2020 IEEE Workshop on Signal Processing Systems (SiPS)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50024784\",\"name\":\"Ye Li\"},{\"authorId\":\"7188881\",\"name\":\"Guangqiang Yin\"},{\"authorId\":\"145802850\",\"name\":\"S. Hou\"},{\"authorId\":\"16176062\",\"name\":\"Jianhai Cui\"},{\"authorId\":\"2105845\",\"name\":\"Zicheng Huang\"}],\"doi\":\"10.1007/978-3-030-23597-0_15\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"33e44db6706969ca9f16d81805089c3d05519b75\",\"title\":\"Spatiotemporal Feature Extraction for Pedestrian Re-identification\",\"url\":\"https://www.semanticscholar.org/paper/33e44db6706969ca9f16d81805089c3d05519b75\",\"venue\":\"WASA\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48028411\",\"name\":\"T. Jin\"},{\"authorId\":\"2367491\",\"name\":\"Y. Li\"},{\"authorId\":\"9338907\",\"name\":\"Z. Zhang\"}],\"doi\":\"10.1016/j.neucom.2019.08.042\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"00b350e4211dd5ed4791744920e664880cd3fd3a\",\"title\":\"Recurrent convolutional video captioning with global and local attention\",\"url\":\"https://www.semanticscholar.org/paper/00b350e4211dd5ed4791744920e664880cd3fd3a\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"2002.02918\",\"authors\":[{\"authorId\":\"47968272\",\"name\":\"Li-Yu Daisy Liu\"},{\"authorId\":\"3143130\",\"name\":\"Dongyang Cai\"},{\"authorId\":\"49723003\",\"name\":\"J. Liu\"},{\"authorId\":\"145534763\",\"name\":\"N. Ding\"},{\"authorId\":\"1491094850\",\"name\":\"Tao Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aff765ae3c6be6c83c731ae1289facaa87dbb6b0\",\"title\":\"iqiyi Submission to ActivityNet Challenge 2019 Kinetics-700 challenge: Hierarchical Group-wise Attention\",\"url\":\"https://www.semanticscholar.org/paper/aff765ae3c6be6c83c731ae1289facaa87dbb6b0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1906.04226\",\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"1403581832\",\"name\":\"Laura Sevilla-Lara\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"},{\"authorId\":\"143907244\",\"name\":\"Yi Yang\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a71b7cf982cf1b54cda4f0746d4ba7c7ea3f4e4\",\"title\":\"FASTER Recurrent Networks for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/8a71b7cf982cf1b54cda4f0746d4ba7c7ea3f4e4\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1908.09511\",\"authors\":[{\"authorId\":\"48550129\",\"name\":\"Jiajun Deng\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/ICCV.2019.00712\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1376675731b8dc3d87464ff54905b9f5233169b5\",\"title\":\"Relation Distillation Networks for Video Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/1376675731b8dc3d87464ff54905b9f5233169b5\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1382437938\",\"name\":\"Zhongdao Jia\"},{\"authorId\":\"50314602\",\"name\":\"Zhimin Yuan\"},{\"authorId\":\"46407948\",\"name\":\"J. Peng\"}],\"doi\":\"10.1007/978-3-030-33226-6_15\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e42e76d32251d8e716b83de6e5ce6fdd2ba24bef\",\"title\":\"Multimodal Brain Tumor Segmentation Using Encoder-Decoder with Hierarchical Separable Convolution\",\"url\":\"https://www.semanticscholar.org/paper/e42e76d32251d8e716b83de6e5ce6fdd2ba24bef\",\"venue\":\"MBIA/MFCA@MICCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48093158\",\"name\":\"Jinpeng Wang\"},{\"authorId\":\"145517136\",\"name\":\"A. Ma\"}],\"doi\":\"10.1007/978-3-030-34120-6_7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9ad5dce0e3d9663a5d0c4044c927776e4bcef2e2\",\"title\":\"Spatial-Temporal Bottom-Up Top-Down Attention Model for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9ad5dce0e3d9663a5d0c4044c927776e4bcef2e2\",\"venue\":\"ICIG\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12373810\",\"name\":\"S. Li\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d9c99179fb0ee3ec5e0466a531d22bb1e800c40f\",\"title\":\"Development of Recurrent Neural Networks and Its Applications to Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d9c99179fb0ee3ec5e0466a531d22bb1e800c40f\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46930271\",\"name\":\"Junyu Gao\"},{\"authorId\":\"48258806\",\"name\":\"C. Xu\"}],\"doi\":\"10.1109/TMM.2020.2969787\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9548b20d7347ae098e03a73eef98f42d0db3775b\",\"title\":\"CI-GNN: Building a Category-Instance Graph for Zero-Shot Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/9548b20d7347ae098e03a73eef98f42d0db3775b\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"2011.11893\",\"authors\":[{\"authorId\":\"1596823732\",\"name\":\"Baifeng Shi\"},{\"authorId\":\"2000157278\",\"name\":\"Qi Dai\"},{\"authorId\":\"50196944\",\"name\":\"Judy Hoffman\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"80126506f744e1efd827e69951bdb6e558eb77a7\",\"title\":\"Temporal Action Detection with Multi-level Supervision\",\"url\":\"https://www.semanticscholar.org/paper/80126506f744e1efd827e69951bdb6e558eb77a7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.07728\",\"authors\":[{\"authorId\":\"46554630\",\"name\":\"L. Yang\"},{\"authorId\":\"39901030\",\"name\":\"Dingwen Zhang\"},{\"authorId\":null,\"name\":\"Tao Zhao\"},{\"authorId\":\"122200133\",\"name\":\"J. Han\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c065821de73b6bb87a2a2376134ac9c28008486\",\"title\":\"Equivalent Classification Mapping for Weakly Supervised Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/1c065821de73b6bb87a2a2376134ac9c28008486\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1906.11415\",\"authors\":[{\"authorId\":\"48865984\",\"name\":\"Kaidi Cao\"},{\"authorId\":\"2547290\",\"name\":\"Jingwei Ji\"},{\"authorId\":\"3451430\",\"name\":\"Zhangjie Cao\"},{\"authorId\":\"4251916\",\"name\":\"C. Chang\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/cvpr42600.2020.01063\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ede7829b3f057a874c513919d19307e2b60ead23\",\"title\":\"Few-Shot Video Classification via Temporal Alignment\",\"url\":\"https://www.semanticscholar.org/paper/ede7829b3f057a874c513919d19307e2b60ead23\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1806.09648\",\"authors\":[{\"authorId\":\"145829312\",\"name\":\"Ke Yan\"},{\"authorId\":\"3774191\",\"name\":\"M. Bagheri\"},{\"authorId\":\"144838131\",\"name\":\"R. Summers\"}],\"doi\":\"10.1007/978-3-030-00928-1_58\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"705ba90496aa6e793395a14baff62c9091a32130\",\"title\":\"3D Context Enhanced Region-based Convolutional Neural Network for End-to-End Lesion Detection\",\"url\":\"https://www.semanticscholar.org/paper/705ba90496aa6e793395a14baff62c9091a32130\",\"venue\":\"MICCAI\",\"year\":2018},{\"arxivId\":\"1908.02486\",\"authors\":[{\"authorId\":\"51128181\",\"name\":\"Boyuan Jiang\"},{\"authorId\":\"47446949\",\"name\":\"M. Wang\"},{\"authorId\":\"35893447\",\"name\":\"W. Gan\"},{\"authorId\":\"145717890\",\"name\":\"W. Wu\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\"}],\"doi\":\"10.1109/ICCV.2019.00209\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b812b20192ffac37b03bde0261934a2a8c7fdf47\",\"title\":\"STM: SpatioTemporal and Motion Encoding for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b812b20192ffac37b03bde0261934a2a8c7fdf47\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1909.10236\",\"authors\":[{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"1591131960\",\"name\":\"Yiheng Zhang\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"0194898fea5464fe016d0ca202458a26485bf932\",\"title\":\"Scheduled Differentiable Architecture Search for Visual Recognition\",\"url\":\"https://www.semanticscholar.org/paper/0194898fea5464fe016d0ca202458a26485bf932\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145586191\",\"name\":\"Can Zhang\"},{\"authorId\":\"26981150\",\"name\":\"Yue-Xian Zou\"},{\"authorId\":\"115151196\",\"name\":\"G. Chen\"},{\"authorId\":\"48204311\",\"name\":\"L. Gan\"}],\"doi\":\"10.1145/3343031.3350876\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ab7f7501d889607d6a9aa3f5ea465a8b1c44f7ff\",\"title\":\"PAN: Persistent Appearance Network with an Efficient Motion Cue for Fast Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ab7f7501d889607d6a9aa3f5ea465a8b1c44f7ff\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993657441\",\"name\":\"Beibei Lin\"},{\"authorId\":\"2042151\",\"name\":\"Shunli Zhang\"},{\"authorId\":\"39677488\",\"name\":\"F. Bao\"}],\"doi\":\"10.1145/3394171.3413861\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a7d3b24dd73d35f358da1265709dbcab848593a5\",\"title\":\"Gait Recognition with Multiple-Temporal-Scale 3D Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/a7d3b24dd73d35f358da1265709dbcab848593a5\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2002.09461\",\"authors\":[{\"authorId\":\"1405834398\",\"name\":\"Peng Xu\"},{\"authorId\":\"46578437\",\"name\":\"K. Liu\"},{\"authorId\":\"145406420\",\"name\":\"Tao Xiang\"},{\"authorId\":\"79456794\",\"name\":\"Timothy M. Hospedales\"},{\"authorId\":\"46953683\",\"name\":\"Zhanyu Ma\"},{\"authorId\":\"145886114\",\"name\":\"Jun Guo\"},{\"authorId\":\"1705408\",\"name\":\"Yi-Zhe Song\"}],\"doi\":\"10.1109/tcsvt.2020.3014491\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b5c8c79a9a943ababce9bd6892da97d297d0b3e1\",\"title\":\"Fine-Grained Instance-Level Sketch-Based Video Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/b5c8c79a9a943ababce9bd6892da97d297d0b3e1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49597328\",\"name\":\"J. Xia\"},{\"authorId\":\"48624966\",\"name\":\"Wei Li\"},{\"authorId\":\"15316116\",\"name\":\"J. Shao\"},{\"authorId\":\"51305314\",\"name\":\"Zehuan Yuan\"},{\"authorId\":\"46741143\",\"name\":\"Jiajun Tang\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"},{\"authorId\":\"1697065\",\"name\":\"C. Wang\"},{\"authorId\":null,\"name\":\"ByteDance AI Lab\"},{\"authorId\":\"46197004\",\"name\":\"S. Tong\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ec00a57820335f136efe96eada551fddb83cde08\",\"title\":\"Multiple Attempts for AVA-Kinetics challenge 2020\",\"url\":\"https://www.semanticscholar.org/paper/ec00a57820335f136efe96eada551fddb83cde08\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152325076\",\"name\":\"H. Ge\"},{\"authorId\":\"79403975\",\"name\":\"Zehang Yan\"},{\"authorId\":null,\"name\":\"Wenhao Yu\"},{\"authorId\":\"144526347\",\"name\":\"L. Sun\"}],\"doi\":\"10.1007/s11042-019-7404-z\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9804bbb0724c333e9b900d849e492db00b20dbde\",\"title\":\"An attention mechanism based convolutional LSTM network for video action recognition\",\"url\":\"https://www.semanticscholar.org/paper/9804bbb0724c333e9b900d849e492db00b20dbde\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":\"2007.11365\",\"authors\":[{\"authorId\":\"39440469\",\"name\":\"Sudhakar Kumawat\"},{\"authorId\":\"145879750\",\"name\":\"Manisha Verma\"},{\"authorId\":\"1789677\",\"name\":\"Yuta Nakashima\"},{\"authorId\":\"145853779\",\"name\":\"S. Raman\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4914a205aa1ddeaae3c86a449c69703c89484f54\",\"title\":\"Depthwise Spatio-Temporal STFT Convolutional Neural Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4914a205aa1ddeaae3c86a449c69703c89484f54\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.06318\",\"authors\":[{\"authorId\":\"80493733\",\"name\":\"Toby P. Breckon\"},{\"authorId\":\"2394549\",\"name\":\"A. Alsehaim\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a10833dc1285d2121949c740b1849e5b46c10f33\",\"title\":\"Not 3D Re-ID: a Simple Single Stream 2D Convolution for Robust Video Re-identification\",\"url\":\"https://www.semanticscholar.org/paper/a10833dc1285d2121949c740b1849e5b46c10f33\",\"venue\":\"ICPR 2020\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"93318099\",\"name\":\"J. Lin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1dc7454bacae9a949db38b8306bd7c4df855fa1c\",\"title\":\"TSM: Temporal Shift Module for Efficient Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/1dc7454bacae9a949db38b8306bd7c4df855fa1c\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"81333974\",\"name\":\"J. Pessoa\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"4ec25a47f6bcf0b19d6cd5103b16b10900284b90\",\"title\":\"VIDEO COMPRESSION USING (END-TO-END) DEEP LEARNING\",\"url\":\"https://www.semanticscholar.org/paper/4ec25a47f6bcf0b19d6cd5103b16b10900284b90\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1912.05003\",\"authors\":[{\"authorId\":\"1409955695\",\"name\":\"B. Chen\"},{\"authorId\":\"49621014\",\"name\":\"De-Cai Li\"},{\"authorId\":\"101084939\",\"name\":\"Y. He\"},{\"authorId\":\"3110318\",\"name\":\"Chunsheng Hua\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fd4b09b78f20c62b32ceefd9675f307f03a048c0\",\"title\":\"SCR-Graph: Spatial-Causal Relationships based Graph Reasoning Network for Human Action Prediction\",\"url\":\"https://www.semanticscholar.org/paper/fd4b09b78f20c62b32ceefd9675f307f03a048c0\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8712588\",\"name\":\"Mengshu Sun\"},{\"authorId\":\"46737456\",\"name\":\"Pu Zhao\"},{\"authorId\":\"32661932\",\"name\":\"M. Gungor\"},{\"authorId\":\"69467609\",\"name\":\"M. Pedram\"},{\"authorId\":\"1710866\",\"name\":\"M. Leeser\"},{\"authorId\":\"145282404\",\"name\":\"X. Lin\"}],\"doi\":\"10.1109/DAC18072.2020.9218571\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8fc582afcb3b81b724ea2af73175ae3c594cef0c\",\"title\":\"3D CNN Acceleration on FPGA using Hardware-Aware Pruning\",\"url\":\"https://www.semanticscholar.org/paper/8fc582afcb3b81b724ea2af73175ae3c594cef0c\",\"venue\":\"2020 57th ACM/IEEE Design Automation Conference (DAC)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92709220\",\"name\":\"Yao-Sen Chen\"},{\"authorId\":\"1455126232\",\"name\":\"Bing Guo\"},{\"authorId\":\"143736944\",\"name\":\"Yan Shen\"},{\"authorId\":\"115438571\",\"name\":\"W. Wang\"},{\"authorId\":\"1836290988\",\"name\":\"Xinhua Suo\"},{\"authorId\":\"1409738616\",\"name\":\"Zhang Zhen\"}],\"doi\":\"10.1007/s11760-020-01758-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0e47005fae57dfc1e4e3f3abcbd61a8d2cc9aead\",\"title\":\"Using efficient group pseudo-3D network to learn spatio-temporal features\",\"url\":\"https://www.semanticscholar.org/paper/0e47005fae57dfc1e4e3f3abcbd61a8d2cc9aead\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145496509\",\"name\":\"Jie Shao\"},{\"authorId\":\"143993120\",\"name\":\"K. Hu\"},{\"authorId\":\"3393850\",\"name\":\"Yixin Bao\"},{\"authorId\":\"11320042\",\"name\":\"Yining Lin\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5b3fd234bd072706af99100edba037b13d5a0069\",\"title\":\"High Order Neural Networks for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/5b3fd234bd072706af99100edba037b13d5a0069\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3404403\",\"name\":\"Longteng Kong\"},{\"authorId\":\"145022824\",\"name\":\"D. Huang\"},{\"authorId\":\"145546921\",\"name\":\"J. Qin\"},{\"authorId\":\"40013375\",\"name\":\"Y. Wang\"}],\"doi\":\"10.1109/TCSVT.2019.2893318\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"ef022983983d8b948ab27a686da4e76cf92d18b1\",\"title\":\"A Joint Framework for Athlete Tracking and Action Recognition in Sports Videos\",\"url\":\"https://www.semanticscholar.org/paper/ef022983983d8b948ab27a686da4e76cf92d18b1\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"1909.03580\",\"authors\":[{\"authorId\":\"66438699\",\"name\":\"Yucai Bai\"},{\"authorId\":\"153740190\",\"name\":\"Giang Dai\"},{\"authorId\":null,\"name\":\"Long Chen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1132b5161dc26ccefeb7187a35251df9f7d0ba3f\",\"title\":\"Extreme Low Resolution Activity Recognition with Spatial-Temporal Attention Transfer\",\"url\":\"https://www.semanticscholar.org/paper/1132b5161dc26ccefeb7187a35251df9f7d0ba3f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1811.07519\",\"authors\":[{\"authorId\":\"143993120\",\"name\":\"K. Hu\"},{\"authorId\":\"1681921\",\"name\":\"B. Raj\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"41ab8c0c47dd8fce41dbe904ab78ed1a7320dfd6\",\"title\":\"Higher-order Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/41ab8c0c47dd8fce41dbe904ab78ed1a7320dfd6\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1801.10304\",\"authors\":[{\"authorId\":\"21518096\",\"name\":\"Zhengyuan Yang\"},{\"authorId\":\"3092578\",\"name\":\"Y. Li\"},{\"authorId\":\"1706007\",\"name\":\"Jianchao Yang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/ICPR.2018.8546012\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e9ef13f6e59361d67f4b4fe7132cb7b3ce1bb6d0\",\"title\":\"Action Recognition with Visual Attention on Skeleton Images\",\"url\":\"https://www.semanticscholar.org/paper/e9ef13f6e59361d67f4b4fe7132cb7b3ce1bb6d0\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":\"2001.08740\",\"authors\":[{\"authorId\":\"2299381\",\"name\":\"Fanyi Xiao\"},{\"authorId\":\"144756076\",\"name\":\"Y. Lee\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"153652147\",\"name\":\"J. Malik\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"80685dc522d30b18f3feb97d6c977f71fa746325\",\"title\":\"Audiovisual SlowFast Networks for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/80685dc522d30b18f3feb97d6c977f71fa746325\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390626541\",\"name\":\"Ziming Liu\"},{\"authorId\":\"2041335607\",\"name\":\"Jinyang Li\"},{\"authorId\":\"47296615\",\"name\":\"Guangyu Gao\"},{\"authorId\":\"2041264362\",\"name\":\"Alex K. Qin\"}],\"doi\":\"10.1109/ACCESS.2020.3043386\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"16df18da2ab27ef1affeefe62ab842ce0f9d8520\",\"title\":\"Temporal Memory Network Towards Real-Time Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/16df18da2ab27ef1affeefe62ab842ce0f9d8520\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1711.08580\",\"authors\":[{\"authorId\":\"47130333\",\"name\":\"Siqi Liu\"},{\"authorId\":\"3262394\",\"name\":\"Daguang Xu\"},{\"authorId\":\"145668226\",\"name\":\"S. Zhou\"},{\"authorId\":\"79819296\",\"name\":\"T. Mertelmeier\"},{\"authorId\":\"12091651\",\"name\":\"Julia Wicklein\"},{\"authorId\":\"1809776\",\"name\":\"Anna K. Jerebko\"},{\"authorId\":\"1764071\",\"name\":\"S. Grbic\"},{\"authorId\":\"2178555\",\"name\":\"Olivier Pauly\"},{\"authorId\":\"1923367\",\"name\":\"T. Cai\"},{\"authorId\":\"1685020\",\"name\":\"D. Comaniciu\"}],\"doi\":\"10.1007/978-3-030-00934-2_94\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"dca4bde7c4bb6fc9a62e774671f3fed673461a87\",\"title\":\"3D Anisotropic Hybrid Network: Transferring Convolutional Features from 2D Images to 3D Anisotropic Volumes\",\"url\":\"https://www.semanticscholar.org/paper/dca4bde7c4bb6fc9a62e774671f3fed673461a87\",\"venue\":\"MICCAI\",\"year\":2018},{\"arxivId\":\"1806.07754\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"2713759\",\"name\":\"M. M. Arzani\"},{\"authorId\":\"9456273\",\"name\":\"Rahman Yousefzadeh\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-030-01225-0_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"85fb0d6cc991cf49ebc4f506b5edd44214979f65\",\"title\":\"Spatio-Temporal Channel Correlation Networks for Action Classification\",\"url\":\"https://www.semanticscholar.org/paper/85fb0d6cc991cf49ebc4f506b5edd44214979f65\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2229862\",\"name\":\"Baohan Xu\"},{\"authorId\":\"145222820\",\"name\":\"H. Ye\"},{\"authorId\":\"3015119\",\"name\":\"Y. Zheng\"},{\"authorId\":null,\"name\":\"Heng Wang\"},{\"authorId\":\"1840008\",\"name\":\"Tianyu Luwang\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1145/3206025.3206028\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"398e0771e64cab6ca5d21754e32dce63f9e3c223\",\"title\":\"Dense Dilated Network for Few Shot Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/398e0771e64cab6ca5d21754e32dce63f9e3c223\",\"venue\":\"ICMR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"82148497\",\"name\":\"Jin-rui Yang\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"},{\"authorId\":\"88280909\",\"name\":\"Q. Yang\"},{\"authorId\":\"1882545\",\"name\":\"Y. Chen\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/CVPR42600.2020.00335\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c433ac3494a01094254aecc3d55b3d53bcb53edf\",\"title\":\"Spatial-Temporal Graph Convolutional Network for Video-Based Person Re-Identification\",\"url\":\"https://www.semanticscholar.org/paper/c433ac3494a01094254aecc3d55b3d53bcb53edf\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22710849\",\"name\":\"Patrick Bordes\"},{\"authorId\":\"39541096\",\"name\":\"Eloi Zablocki\"},{\"authorId\":\"145159652\",\"name\":\"L. Soulier\"},{\"authorId\":\"1703777\",\"name\":\"Benjamin Piwowarski\"},{\"authorId\":\"1741426\",\"name\":\"P. Gallinari\"}],\"doi\":\"10.24348/coria.2019.CORIA_2019_paper_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"175ee94e33c3871edd198d6fca9d33669ab24d6d\",\"title\":\"Un mod\\u00e8le multimodal d'apprentissage de repr\\u00e9sentations de phrases qui pr\\u00e9serve la s\\u00e9mantique visuelle\",\"url\":\"https://www.semanticscholar.org/paper/175ee94e33c3871edd198d6fca9d33669ab24d6d\",\"venue\":\"CORIA\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8598253\",\"name\":\"Wang-Li Hao\"},{\"authorId\":\"1500387021\",\"name\":\"Ruixian Zhang\"},{\"authorId\":\"47319226\",\"name\":\"Shancang Li\"},{\"authorId\":\"1492111607\",\"name\":\"Junyu Li\"},{\"authorId\":\"49515557\",\"name\":\"F. Li\"},{\"authorId\":\"145382022\",\"name\":\"Shanshan Zhao\"},{\"authorId\":\"3103971\",\"name\":\"Wuping Zhang\"}],\"doi\":\"10.1155/2020/8876056\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d28cdcbeb04898c1ed0ff3f36e8fcb5b7e1d30a0\",\"title\":\"Anomaly Event Detection in Security Surveillance Using Two-Stream Based Model\",\"url\":\"https://www.semanticscholar.org/paper/d28cdcbeb04898c1ed0ff3f36e8fcb5b7e1d30a0\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33069327\",\"name\":\"Pengbo Zhang\"},{\"authorId\":\"1729353\",\"name\":\"X. Wang\"},{\"authorId\":\"1985287\",\"name\":\"W. Zhang\"},{\"authorId\":\"49252547\",\"name\":\"Junfeng Chen\"}],\"doi\":\"10.1109/TNSRE.2018.2884641\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"8b8aba271eb7163ac6af37ffb130adfbca89968e\",\"title\":\"Learning Spatial\\u2013Spectral\\u2013Temporal EEG Features With Recurrent 3D Convolutional Neural Networks for Cross-Task Mental Workload Assessment\",\"url\":\"https://www.semanticscholar.org/paper/8b8aba271eb7163ac6af37ffb130adfbca89968e\",\"venue\":\"IEEE Transactions on Neural Systems and Rehabilitation Engineering\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49050918\",\"name\":\"J. Zhang\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1109/ACCESS.2019.2895472\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"82d4b2272799f0c4acc284bbc6ed3eaeeefdc7c0\",\"title\":\"Deep Spatiotemporal Relation Learning With 3D Multi-Level Dense Fusion for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/82d4b2272799f0c4acc284bbc6ed3eaeeefdc7c0\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66589187\",\"name\":\"Hanjian Song\"},{\"authorId\":\"144569176\",\"name\":\"Lihua Tian\"},{\"authorId\":\"1414577137\",\"name\":\"Chen Li\"}],\"doi\":\"10.1007/s11042-020-08771-3\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"195bbbb21261fe1f1a7380646fc9042228989df8\",\"title\":\"Action temporal detection method based on confidence curve analysis\",\"url\":\"https://www.semanticscholar.org/paper/195bbbb21261fe1f1a7380646fc9042228989df8\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"1907.13369\",\"authors\":[{\"authorId\":\"50224945\",\"name\":\"Wenhao Wu\"},{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"145681032\",\"name\":\"Xiao Tan\"},{\"authorId\":\"2869725\",\"name\":\"Shifeng Chen\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"}],\"doi\":\"10.1109/ICCV.2019.00632\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2d8d533980774f7fa28f480b743c1998343fa3dd\",\"title\":\"Multi-Agent Reinforcement Learning Based Frame Sampling for Effective Untrimmed Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2d8d533980774f7fa28f480b743c1998343fa3dd\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1911.09435\",\"authors\":[{\"authorId\":\"46270766\",\"name\":\"Zhaoyang Liu\"},{\"authorId\":\"9393671\",\"name\":\"Donghao Luo\"},{\"authorId\":null,\"name\":\"Yabiao Wang\"},{\"authorId\":\"29461006\",\"name\":\"L. Wang\"},{\"authorId\":\"144970872\",\"name\":\"Ying Tai\"},{\"authorId\":\"1978245\",\"name\":\"Chengjie Wang\"},{\"authorId\":\"49298244\",\"name\":\"Jilin Li\"},{\"authorId\":\"1835006\",\"name\":\"Feiyue Huang\"},{\"authorId\":\"144720251\",\"name\":\"Tong Lu\"}],\"doi\":\"10.1609/AAAI.V34I07.6836\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fa3473f1f5d4f19ec6d561e2700a4d88dad4ccf8\",\"title\":\"TEINet: Towards an Efficient Architecture for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fa3473f1f5d4f19ec6d561e2700a4d88dad4ccf8\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2003.12798\",\"authors\":[{\"authorId\":\"2156559\",\"name\":\"Qihang Yu\"},{\"authorId\":\"48513320\",\"name\":\"Yingwei Li\"},{\"authorId\":\"10407760\",\"name\":\"Jieru Mei\"},{\"authorId\":\"7743268\",\"name\":\"Yuyin Zhou\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3743c3c7c30d700f37bcd00048af007137517a18\",\"title\":\"CAKES: Channel-wise Automatic KErnel Shrinking for Efficient 3D Network\",\"url\":\"https://www.semanticscholar.org/paper/3743c3c7c30d700f37bcd00048af007137517a18\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1812.05038\",\"authors\":[{\"authorId\":\"2978413\",\"name\":\"Chao-Yuan Wu\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"2681569\",\"name\":\"Haoqi Fan\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2562966\",\"name\":\"Philipp Kr\\u00e4henb\\u00fchl\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/CVPR.2019.00037\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"45cb2cbae5c0b4cc52e524cc191a2f8db674ed42\",\"title\":\"Long-Term Feature Banks for Detailed Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/45cb2cbae5c0b4cc52e524cc191a2f8db674ed42\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1906.03349\",\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"}],\"doi\":\"10.1109/cvpr42600.2020.00043\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"45a924794b2c6501b671cf4249c6ac4fa1671597\",\"title\":\"Video Modeling With Correlation Networks\",\"url\":\"https://www.semanticscholar.org/paper/45a924794b2c6501b671cf4249c6ac4fa1671597\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23278631\",\"name\":\"Guangle Yao\"},{\"authorId\":\"144673774\",\"name\":\"T. Lei\"},{\"authorId\":\"23227806\",\"name\":\"Jiandan Zhong\"}],\"doi\":\"10.1016/j.patrec.2018.05.018\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2c12495bfb2f47881191ce0cb672f0372c6a31e2\",\"title\":\"A review of Convolutional-Neural-Network-based action recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c12495bfb2f47881191ce0cb672f0372c6a31e2\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2019},{\"arxivId\":\"2002.03187\",\"authors\":[{\"authorId\":null,\"name\":\"Hao Zhou\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"24520518\",\"name\":\"Y. Zhou\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"}],\"doi\":\"10.1609/AAAI.V34I07.7001\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a1e2665ac39dcb389e12f3f993004b4b4651826d\",\"title\":\"Spatial-Temporal Multi-Cue Network for Continuous Sign Language Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a1e2665ac39dcb389e12f3f993004b4b4651826d\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2259852\",\"name\":\"Jianing Li\"},{\"authorId\":\"46583677\",\"name\":\"J. Wang\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"},{\"authorId\":\"101001846\",\"name\":\"Wen Gao\"},{\"authorId\":\"1776581\",\"name\":\"S. Zhang\"}],\"doi\":\"10.1109/ICCV.2019.00406\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a4ae54757da23ad0551308e5a5a314bc5a9515ff\",\"title\":\"Global-Local Temporal Representations for Video Person Re-Identification\",\"url\":\"https://www.semanticscholar.org/paper/a4ae54757da23ad0551308e5a5a314bc5a9515ff\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"73270188\",\"name\":\"Samir Bouindour\"},{\"authorId\":\"2103629\",\"name\":\"H. Snoussi\"},{\"authorId\":\"2775884\",\"name\":\"Mohamad Mazen Hittawe\"},{\"authorId\":\"39409830\",\"name\":\"N. Tazi\"},{\"authorId\":\"50819719\",\"name\":\"T. Wang\"}],\"doi\":\"10.3390/APP9040757\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bfe3a0be93579fd49c6146105292ecf77be12ffe\",\"title\":\"An On-Line and Adaptive Method for Detecting Abnormal Events in Videos Using Spatio-Temporal ConvNet\",\"url\":\"https://www.semanticscholar.org/paper/bfe3a0be93579fd49c6146105292ecf77be12ffe\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2000153057\",\"name\":\"Zhikang Qiu\"},{\"authorId\":null,\"name\":\"Xu Zhao\"},{\"authorId\":\"49941675\",\"name\":\"Zhilan Hu\"}],\"doi\":\"10.1109/ICIP40778.2020.9190997\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"593fa71e5cad2afcc4b105c45d5ee4eae101bf54\",\"title\":\"Efficient Temporal-Spatial Feature Grouping For Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/593fa71e5cad2afcc4b105c45d5ee4eae101bf54\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"2007.09033\",\"authors\":[{\"authorId\":\"16323128\",\"name\":\"Guoxi Huang\"},{\"authorId\":\"1707271\",\"name\":\"Adrian G. Bors\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"215182fe19015d315cae9cd2c39e3a576b7193bf\",\"title\":\"Region-based Non-local Operation for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/215182fe19015d315cae9cd2c39e3a576b7193bf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"70249755\",\"name\":\"Zachary Wharton\"},{\"authorId\":\"1931096\",\"name\":\"A. Behera\"},{\"authorId\":\"152891407\",\"name\":\"Y. Liu\"},{\"authorId\":\"2004428132\",\"name\":\"Nikolaos Bessis\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1b3e3b52ac85512fb87be2df7ad4f0e67c99a8b1\",\"title\":\"Coarse Temporal Attention Network (CTA-Net) for Driver\\u2019s Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1b3e3b52ac85512fb87be2df7ad4f0e67c99a8b1\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3091223\",\"name\":\"S. Laraba\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4ec04e32a90c5d98de25e46c85e9369ecc90ac5a\",\"title\":\"Deep Learning for Skeleton-Based Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4ec04e32a90c5d98de25e46c85e9369ecc90ac5a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47141093\",\"name\":\"Gursimran Singh\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"1710980\",\"name\":\"J. Little\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"51fadc0803ee53c91eb4fcfb3777720496c9d91f\",\"title\":\"Spatio-temporal Relational Reasoning for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/51fadc0803ee53c91eb4fcfb3777720496c9d91f\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47968723\",\"name\":\"Zhenyu Mao\"},{\"authorId\":\"145376847\",\"name\":\"Yi Su\"},{\"authorId\":\"7322490\",\"name\":\"Guangquan Xu\"},{\"authorId\":\"145672258\",\"name\":\"X. Wang\"},{\"authorId\":\"72051965\",\"name\":\"Y. Huang\"},{\"authorId\":\"35481850\",\"name\":\"W. Yue\"},{\"authorId\":\"51240979\",\"name\":\"L. Sun\"},{\"authorId\":\"145826495\",\"name\":\"N. Xiong\"}],\"doi\":\"10.1016/J.INS.2019.05.043\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1a2b0383369172e08d91bc60fb70a9a988c317cc\",\"title\":\"Spatio-temporal deep learning method for ADHD fMRI classification\",\"url\":\"https://www.semanticscholar.org/paper/1a2b0383369172e08d91bc60fb70a9a988c317cc\",\"venue\":\"Inf. Sci.\",\"year\":2019},{\"arxivId\":\"1811.01549\",\"authors\":[{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"47230289\",\"name\":\"Zhichao Zhou\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"31442858\",\"name\":\"F. Li\"},{\"authorId\":\"48033101\",\"name\":\"Xiao Liu\"},{\"authorId\":\"47001910\",\"name\":\"Y. Li\"},{\"authorId\":\"48170161\",\"name\":\"L. Wang\"},{\"authorId\":\"35247507\",\"name\":\"Shilei Wen\"}],\"doi\":\"10.1609/aaai.v33i01.33018401\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"94d67304c6c0d23c7dfcf008cbf799b54b8d20b9\",\"title\":\"StNet: Local and Global Spatial-Temporal Modeling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/94d67304c6c0d23c7dfcf008cbf799b54b8d20b9\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"2004.05054\",\"authors\":[{\"authorId\":\"51000619\",\"name\":\"Evgeny Izutov\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f4436c77e4232d36d95f95989d2e5ae2fa0b0514\",\"title\":\"ASL Recognition with Metric-Learning based Lightweight Network\",\"url\":\"https://www.semanticscholar.org/paper/f4436c77e4232d36d95f95989d2e5ae2fa0b0514\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2872774\",\"name\":\"W. Dong\"},{\"authorId\":\"49527968\",\"name\":\"H. Wang\"},{\"authorId\":\"145844363\",\"name\":\"F. Wu\"},{\"authorId\":\"35367337\",\"name\":\"Guangming Shi\"},{\"authorId\":\"51376876\",\"name\":\"X. Li\"}],\"doi\":\"10.1109/TCI.2019.2911881\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e7e4d2dd46e0efbfb69131fb924012084337e034\",\"title\":\"Deep Spatial\\u2013Spectral Representation Learning for Hyperspectral Image Denoising\",\"url\":\"https://www.semanticscholar.org/paper/e7e4d2dd46e0efbfb69131fb924012084337e034\",\"venue\":\"IEEE Transactions on Computational Imaging\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31101125\",\"name\":\"K. Papadimitriou\"},{\"authorId\":\"1423737852\",\"name\":\"Gerasimos Potamianos\"}],\"doi\":\"10.21437/interspeech.2020-2691\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dc236d5851fbd6e83df5db535f2845f71e6a72f7\",\"title\":\"Multimodal Sign Language Recognition via Temporal Deformable Convolutional Sequence Learning\",\"url\":\"https://www.semanticscholar.org/paper/dc236d5851fbd6e83df5db535f2845f71e6a72f7\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491085071\",\"name\":\"Xiafei Yu\"}],\"doi\":\"10.20381/RUOR-24213\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"52b1cfb13c672f06aa6a43133d8b9b071d1f6226\",\"title\":\"Wide Activated Separate 3D Convolution for Video Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/52b1cfb13c672f06aa6a43133d8b9b071d1f6226\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2498892\",\"name\":\"Pengxiang Wu\"},{\"authorId\":\"1814286\",\"name\":\"Siheng Chen\"},{\"authorId\":\"1711560\",\"name\":\"Dimitris N. Metaxas\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6234435197b5325b0b9caf2f5336c2e41e93a268\",\"title\":\"MotionNet: Joint Perception and Motion Prediction for Autonomous Driving Based on Birda\\u0302\\u2022Z\\u030cs Eye View Maps /Author=Wu, Pengxiang; Chen, Siheng /CreationDate=June 9, 2020 /Subject=Artificial Intelligence, Computer Vision, Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/6234435197b5325b0b9caf2f5336c2e41e93a268\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50031413\",\"name\":\"X. Yang\"},{\"authorId\":\"2342535\",\"name\":\"Lequan Yu\"},{\"authorId\":\"50341585\",\"name\":\"Shengli Li\"},{\"authorId\":\"13215359\",\"name\":\"H. Wen\"},{\"authorId\":\"49017141\",\"name\":\"D. Luo\"},{\"authorId\":\"50009437\",\"name\":\"Cheng Bian\"},{\"authorId\":\"145947079\",\"name\":\"J. Qin\"},{\"authorId\":\"145410044\",\"name\":\"Dong Ni\"},{\"authorId\":\"1714602\",\"name\":\"P. Heng\"}],\"doi\":\"10.1109/TMI.2018.2858779\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"82a1cc9cc758248320a1562087ed3c9f81b89dea\",\"title\":\"Towards Automated Semantic Segmentation in Prenatal Volumetric Ultrasound\",\"url\":\"https://www.semanticscholar.org/paper/82a1cc9cc758248320a1562087ed3c9f81b89dea\",\"venue\":\"IEEE Transactions on Medical Imaging\",\"year\":2019},{\"arxivId\":\"1812.04172\",\"authors\":[{\"authorId\":\"3313330\",\"name\":\"Gedas Bertasius\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"46865129\",\"name\":\"J. Shi\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e412efc9baecddac274639c0a5140aa28446792c\",\"title\":\"Learning Discriminative Motion Features Through Detection\",\"url\":\"https://www.semanticscholar.org/paper/e412efc9baecddac274639c0a5140aa28446792c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1908.04519\",\"authors\":[{\"authorId\":\"97765655\",\"name\":\"J. Xia\"},{\"authorId\":\"46741143\",\"name\":\"Jiajun Tang\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a82614927db94b233415975ab98f92e9468e6492\",\"title\":\"Three Branches: Detecting Actions With Richer Features\",\"url\":\"https://www.semanticscholar.org/paper/a82614927db94b233415975ab98f92e9468e6492\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1909.03309\",\"authors\":[{\"authorId\":\"2502363\",\"name\":\"Gagan Kanojia\"},{\"authorId\":\"39440469\",\"name\":\"Sudhakar Kumawat\"},{\"authorId\":\"145853779\",\"name\":\"S. Raman\"}],\"doi\":\"10.1007/978-981-15-8697-2_10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5ea90b8a0ff9fe3c9f1f0bee8e1fe137e112dd4f\",\"title\":\"Exploring Temporal Differences in 3D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/5ea90b8a0ff9fe3c9f1f0bee8e1fe137e112dd4f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1920920163\",\"name\":\"Haofei Wang\"},{\"authorId\":\"49298973\",\"name\":\"Junfeng Li\"}],\"doi\":\"10.1109/ACCESS.2020.3017076\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d2602fe505d3615889456eeb6fcdc71f8f855de7\",\"title\":\"Human Action Recognition Algorithm Based on Multi-Feature Map Fusion\",\"url\":\"https://www.semanticscholar.org/paper/d2602fe505d3615889456eeb6fcdc71f8f855de7\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2092543\",\"name\":\"Gediminas Bertasius\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5dee122d4a5e8726ba280dd3c9a804b1e69e7406\",\"title\":\"Embodied Visual Perception Models For Human Behavior Understanding\",\"url\":\"https://www.semanticscholar.org/paper/5dee122d4a5e8726ba280dd3c9a804b1e69e7406\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2004.13567\",\"authors\":[{\"authorId\":\"72347325\",\"name\":\"X. Yang\"},{\"authorId\":\"72541446\",\"name\":\"Xu Wang\"},{\"authorId\":null,\"name\":\"Yi Wang\"},{\"authorId\":\"10669778\",\"name\":\"Haoran Dou\"},{\"authorId\":\"50341585\",\"name\":\"Shengli Li\"},{\"authorId\":\"13215359\",\"name\":\"H. Wen\"},{\"authorId\":\"119916397\",\"name\":\"Y. Lin\"},{\"authorId\":\"72434829\",\"name\":\"P. Heng\"},{\"authorId\":\"1491625649\",\"name\":\"Dong Ni\"}],\"doi\":\"10.1016/j.cmpb.2020.105519\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"80210982b014e8bc4dca98b19fbd0a8e327bd8f5\",\"title\":\"Hybrid Attention for Automatic Segmentation of Whole Fetal Head in Prenatal Ultrasound Volumes\",\"url\":\"https://www.semanticscholar.org/paper/80210982b014e8bc4dca98b19fbd0a8e327bd8f5\",\"venue\":\"Comput. Methods Programs Biomed.\",\"year\":2020},{\"arxivId\":\"1912.04316\",\"authors\":[{\"authorId\":\"34656387\",\"name\":\"Matteo Tomei\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2175529\",\"name\":\"Simone Calderara\"},{\"authorId\":\"102613292\",\"name\":\"Simone Bronzin\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ad16dbe1a5c3b192de961a1f1c3fedeba8bf2783\",\"title\":\"STAGE: Spatio-Temporal Attention on Graph Entities for Video Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/ad16dbe1a5c3b192de961a1f1c3fedeba8bf2783\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7634810\",\"name\":\"Weiyao Wang\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"}],\"doi\":\"10.1109/CVPR42600.2020.01271\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f6caf91f731fab861ef420f680cf691f12f70134\",\"title\":\"What Makes Training Multi-Modal Classification Networks Hard?\",\"url\":\"https://www.semanticscholar.org/paper/f6caf91f731fab861ef420f680cf691f12f70134\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1906.04928\",\"authors\":[{\"authorId\":\"3210262\",\"name\":\"Senzhang Wang\"},{\"authorId\":\"144115026\",\"name\":\"J. Cao\"},{\"authorId\":\"144019071\",\"name\":\"Philip S. Yu\"}],\"doi\":\"10.1109/tkde.2020.3025580\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a54c647f6db73621ec496ea86355726161c0898d\",\"title\":\"Deep Learning for Spatio-Temporal Data Mining: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/a54c647f6db73621ec496ea86355726161c0898d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35041003\",\"name\":\"Lichao Mou\"},{\"authorId\":\"51151222\",\"name\":\"Yuansheng Hua\"},{\"authorId\":\"2038525606\",\"name\":\"Pu Jin\"},{\"authorId\":\"46875441\",\"name\":\"X. X. Zhu\"}],\"doi\":\"10.1109/MGRS.2020.3005751\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f6770c2a1d5777c1bf4c266485deb3440d8f32c2\",\"title\":\"ERA: A Data Set and Deep Learning Benchmark for Event Recognition in Aerial Videos [Software and Data Sets]\",\"url\":\"https://www.semanticscholar.org/paper/f6770c2a1d5777c1bf4c266485deb3440d8f32c2\",\"venue\":\"IEEE Geoscience and Remote Sensing Magazine\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2028898625\",\"name\":\"Mingfeng Hao\"},{\"authorId\":\"2028900009\",\"name\":\"Mutelep Mamut\"},{\"authorId\":\"1869945\",\"name\":\"K. Ubul\"}],\"doi\":\"10.1145/3421558.3421563\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"562b845c63b44d5dd695e60c35716034835824fb\",\"title\":\"A Survey of Lipreading Methods Based on Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/562b845c63b44d5dd695e60c35716034835824fb\",\"venue\":\"ICIP 2020\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145380510\",\"name\":\"L. Rossetto\"},{\"authorId\":\"145779317\",\"name\":\"R. Gasser\"},{\"authorId\":\"1693655\",\"name\":\"Jakub Loko\\u010d\"},{\"authorId\":\"35537256\",\"name\":\"W. Bailer\"},{\"authorId\":\"1937120\",\"name\":\"K. Sch\\u00f6ffmann\"},{\"authorId\":\"2251616\",\"name\":\"Bernd M\\u00fcnzer\"},{\"authorId\":\"40037607\",\"name\":\"T. Soucek\"},{\"authorId\":\"32860700\",\"name\":\"P. Nguyen\"},{\"authorId\":\"1982596\",\"name\":\"Paolo Bolettieri\"},{\"authorId\":\"3403185\",\"name\":\"A. Leibetseder\"},{\"authorId\":\"1381295446\",\"name\":\"S. Vrochidis\"}],\"doi\":\"10.1109/TMM.2020.2980944\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"67ea56e031a77eed8214bede62c52004e201cb9f\",\"title\":\"Interactive Video Retrieval in the Age of Deep Learning \\u2013 Detailed Evaluation of VBS 2019\",\"url\":\"https://www.semanticscholar.org/paper/67ea56e031a77eed8214bede62c52004e201cb9f\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2021},{\"arxivId\":\"2011.12384\",\"authors\":[{\"authorId\":\"9385903\",\"name\":\"S. Zhu\"},{\"authorId\":\"1390892946\",\"name\":\"Taojiannan Yang\"},{\"authorId\":\"1422036273\",\"name\":\"Mat'ias Mendieta\"},{\"authorId\":\"143916976\",\"name\":\"Chen Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ba1dda6494709cac7c48c95c81afff7a087f2031\",\"title\":\"A3D: Adaptive 3D Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ba1dda6494709cac7c48c95c81afff7a087f2031\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1807.00686\",\"authors\":[{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"145950948\",\"name\":\"Xue Li\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"3aea4d43c157d8e2fcf692b172e2c1c1e4bae6ec\",\"title\":\"YH Technologies at ActivityNet Challenge 2018\",\"url\":\"https://www.semanticscholar.org/paper/3aea4d43c157d8e2fcf692b172e2c1c1e4bae6ec\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38467984\",\"name\":\"Peng Yi\"},{\"authorId\":\"48708411\",\"name\":\"Zhongyuan Wang\"},{\"authorId\":\"51360637\",\"name\":\"Kui Jiang\"},{\"authorId\":\"1708439\",\"name\":\"J. Jiang\"},{\"authorId\":\"8555475\",\"name\":\"Jiayi Ma\"}],\"doi\":\"10.1109/ICCV.2019.00320\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"755227d7ea41b1d90df31f411f9ecbc998c20d26\",\"title\":\"Progressive Fusion Video Super-Resolution Network via Exploiting Non-Local Spatio-Temporal Correlations\",\"url\":\"https://www.semanticscholar.org/paper/755227d7ea41b1d90df31f411f9ecbc998c20d26\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1566489065\",\"name\":\"Yukun Huang\"},{\"authorId\":\"2425471\",\"name\":\"Yongcai Guo\"},{\"authorId\":\"153686290\",\"name\":\"C. Gao\"}],\"doi\":\"10.1109/ACCESS.2020.2978223\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dd59c68dc58e350b51288d2b6ee6d5ea52ad9f84\",\"title\":\"Efficient Parallel Inflated 3D Convolution Architecture for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/dd59c68dc58e350b51288d2b6ee6d5ea52ad9f84\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50202365\",\"name\":\"Shiwen Zhang\"},{\"authorId\":\"49015548\",\"name\":\"Weilin Huang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a19185b1cbb6588682318bb9ce649a611e889162\",\"title\":\"VIDEO-LEVEL REPRESENTATION LEARNING\",\"url\":\"https://www.semanticscholar.org/paper/a19185b1cbb6588682318bb9ce649a611e889162\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40354734\",\"name\":\"Haoze Wu\"},{\"authorId\":\"51260253\",\"name\":\"Z. Zha\"},{\"authorId\":\"145919634\",\"name\":\"X. Wen\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"},{\"authorId\":\"153626293\",\"name\":\"Dong Liu\"},{\"authorId\":\"46772808\",\"name\":\"X. Chen\"}],\"doi\":\"10.1145/3343031.3350891\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b725e11efdc4b4bd367e555dd2a70530b9002c68\",\"title\":\"Cross-Fiber Spatial-Temporal Co-enhanced Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b725e11efdc4b4bd367e555dd2a70530b9002c68\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3458261\",\"name\":\"Quanle Liu\"},{\"authorId\":\"1961065\",\"name\":\"Xiangjiu Che\"},{\"authorId\":\"3079649\",\"name\":\"Mei Bie\"}],\"doi\":\"10.1109/ACCESS.2019.2923651\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c93fea9dba471ad0b42ba7b217cbe5ee1bc74a26\",\"title\":\"R-STAN: Residual Spatial-Temporal Attention Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c93fea9dba471ad0b42ba7b217cbe5ee1bc74a26\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32273141\",\"name\":\"Z. Zhao\"},{\"authorId\":\"2033687\",\"name\":\"Xuemei Xie\"},{\"authorId\":\"97829466\",\"name\":\"W. Liu\"},{\"authorId\":\"1491642326\",\"name\":\"Qingzhe Pan\"}],\"doi\":\"10.1109/ACCESS.2020.2969290\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ad5392cff1c693ca07804071b26ad907f3a5ba63\",\"title\":\"A Hybrid-3D Convolutional Network for Video Compressive Sensing\",\"url\":\"https://www.semanticscholar.org/paper/ad5392cff1c693ca07804071b26ad907f3a5ba63\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144422820\",\"name\":\"Xiang Xiang\"},{\"authorId\":\"145509096\",\"name\":\"Y. Tian\"},{\"authorId\":\"3207112\",\"name\":\"A. Reiter\"},{\"authorId\":\"1678633\",\"name\":\"Gregory Hager\"},{\"authorId\":\"1709073\",\"name\":\"Trac D. Tran\"}],\"doi\":\"10.1109/ICIP.2018.8451364\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bd5b26509ae667cf65fdd6db7c6ac9b578870e3e\",\"title\":\"S3D: Stacking Segmental P3D for Action Quality Assessment\",\"url\":\"https://www.semanticscholar.org/paper/bd5b26509ae667cf65fdd6db7c6ac9b578870e3e\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1994488088\",\"name\":\"Lianyu Hu\"},{\"authorId\":\"152150149\",\"name\":\"Lin Feng\"},{\"authorId\":\"8602618\",\"name\":\"Shenglan Liu\"}],\"doi\":\"10.1145/3422844.3423052\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"661a89fbbe1fadc94c145af3a6a1ddb79c7d99a1\",\"title\":\"HFNet: A Novel Model for Human Focused Sports Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/661a89fbbe1fadc94c145af3a6a1ddb79c7d99a1\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1812.08249\",\"authors\":[{\"authorId\":\"143935879\",\"name\":\"Jonathan C. Stroud\"},{\"authorId\":\"144711958\",\"name\":\"D. Ross\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"}],\"doi\":\"10.1109/WACV45572.2020.9093274\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2766379db5d9907766dab034a52867d7394a265e\",\"title\":\"D3D: Distilled 3D Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2766379db5d9907766dab034a52867d7394a265e\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3530540\",\"name\":\"Yunbo Wang\"},{\"authorId\":\"144811736\",\"name\":\"L. Jiang\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"35776445\",\"name\":\"Mingsheng Long\"},{\"authorId\":\"3216322\",\"name\":\"L. Fei-Fei\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2eb604863b671763de17905ad715a225d9fe43e9\",\"title\":\"Unit Frame 3 : T + 2 Frame 1 : T Frame 2 : T + 1 FrameT + 1 FrameT + 2 FrameT + 3\",\"url\":\"https://www.semanticscholar.org/paper/2eb604863b671763de17905ad715a225d9fe43e9\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12888106\",\"name\":\"H. Cho\"},{\"authorId\":\"46696307\",\"name\":\"H. Kim\"},{\"authorId\":\"151487048\",\"name\":\"Daekwan Ko\"},{\"authorId\":\"51492435\",\"name\":\"Soo-Chul Lim\"},{\"authorId\":\"34600044\",\"name\":\"Wonjun Hwang\"}],\"doi\":\"10.1109/RITAPP.2019.8932854\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0263b72d3cea4281a1bf010c041b9a0f4b888bc1\",\"title\":\"Which LSTM Type is Better for Interaction Force Estimation?\",\"url\":\"https://www.semanticscholar.org/paper/0263b72d3cea4281a1bf010c041b9a0f4b888bc1\",\"venue\":\"2019 7th International Conference on Robot Intelligence Technology and Applications (RiTA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153504672\",\"name\":\"Hong Zhang\"},{\"authorId\":\"2000677733\",\"name\":\"Jiexiong Rong\"}],\"doi\":\"10.1007/S11042-020-09564-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fe960aebd7429164f20643301456b06fadb89165\",\"title\":\"Enhanced 3D residual network for video event recognition in shipping monitoring\",\"url\":\"https://www.semanticscholar.org/paper/fe960aebd7429164f20643301456b06fadb89165\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1904697\",\"name\":\"Zhenbing Liu\"},{\"authorId\":\"1796258521\",\"name\":\"Zeya Li\"},{\"authorId\":\"49908315\",\"name\":\"Ruili Wang\"},{\"authorId\":\"51251812\",\"name\":\"Ming Zong\"},{\"authorId\":\"29790429\",\"name\":\"Wanting Ji\"}],\"doi\":\"10.1007/s00521-020-05144-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"575448ab04aef0856a73d8eba3a75a5321e0506d\",\"title\":\"Spatiotemporal saliency-based multi-stream networks with attention-aware LSTM for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/575448ab04aef0856a73d8eba3a75a5321e0506d\",\"venue\":\"Neural Computing and Applications\",\"year\":2020},{\"arxivId\":\"1904.07442\",\"authors\":[{\"authorId\":\"102665943\",\"name\":\"Yupan Huang\"},{\"authorId\":\"144954807\",\"name\":\"Q. Dai\"},{\"authorId\":\"35150586\",\"name\":\"Yutong Lu\"}],\"doi\":\"10.1109/ICME.2019.00224\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"785bc0ad262a51c5b66d36e19628f00dec22dcd2\",\"title\":\"Decoupling Localization and Classification in Single Shot Temporal Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/785bc0ad262a51c5b66d36e19628f00dec22dcd2\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8549944\",\"name\":\"J. Li\"},{\"authorId\":\"6820648\",\"name\":\"Xianglong Liu\"},{\"authorId\":\"47473953\",\"name\":\"Mingyuan Zhang\"},{\"authorId\":\"47859105\",\"name\":\"De-qing Wang\"}],\"doi\":\"10.1016/j.patcog.2019.107037\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ec7d8bd083690391c0a40800321554f3a55a2125\",\"title\":\"Spatio-temporal deformable 3D ConvNets with attention for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/ec7d8bd083690391c0a40800321554f3a55a2125\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":\"2002.10698\",\"authors\":[{\"authorId\":\"47267313\",\"name\":\"T. Le\"},{\"authorId\":\"144672395\",\"name\":\"Vuong Le\"},{\"authorId\":\"144162181\",\"name\":\"S. Venkatesh\"},{\"authorId\":\"6254479\",\"name\":\"T. Tran\"}],\"doi\":\"10.1109/cvpr42600.2020.00999\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"53de96cf981c9d58a86697d812484808945b47f5\",\"title\":\"Hierarchical Conditional Relation Networks for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/53de96cf981c9d58a86697d812484808945b47f5\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46930271\",\"name\":\"Junyu Gao\"},{\"authorId\":\"1907582\",\"name\":\"T. Zhang\"},{\"authorId\":\"145194969\",\"name\":\"C. Xu\"}],\"doi\":\"10.1145/3240508.3240566\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"eb904609f211216a98bdab0a6d12c2f82ef89b0f\",\"title\":\"Watch, Think and Attend: End-to-End Video Classification via Dynamic Knowledge Evolution Modeling\",\"url\":\"https://www.semanticscholar.org/paper/eb904609f211216a98bdab0a6d12c2f82ef89b0f\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"2002.02651\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"},{\"authorId\":\"1739867\",\"name\":\"R. Veltkamp\"}],\"doi\":\"10.3390/app10186241\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c30d284bcba14754bbc020c7cf2688e2f831e97e\",\"title\":\"Learning Class Regularized Features for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c30d284bcba14754bbc020c7cf2688e2f831e97e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.06567\",\"authors\":[{\"authorId\":\"1805946041\",\"name\":\"Yi Zhu\"},{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"49046944\",\"name\":\"C. Liu\"},{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"22539483\",\"name\":\"Chongruo Wu\"},{\"authorId\":\"152781163\",\"name\":\"Z. Zhang\"},{\"authorId\":\"2397422\",\"name\":\"Joseph Tighe\"},{\"authorId\":\"1758550\",\"name\":\"R. Manmatha\"},{\"authorId\":\"49140510\",\"name\":\"M. Li\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ee12f02830a5e1f7cadd3623dfed495cf099bc82\",\"title\":\"A Comprehensive Study of Deep Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ee12f02830a5e1f7cadd3623dfed495cf099bc82\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50202365\",\"name\":\"S. Zhang\"},{\"authorId\":\"153098982\",\"name\":\"Sheng Guo\"},{\"authorId\":\"49015548\",\"name\":\"Weilin Huang\"},{\"authorId\":\"1915350\",\"name\":\"M. Scott\"},{\"authorId\":\"29461006\",\"name\":\"L. Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"60d95b4ed4f6e9ac38441d130d3969597ce4d626\",\"title\":\"V4D: 4D Covolutional Neural Networks for Video-level Representations Learning\",\"url\":\"https://www.semanticscholar.org/paper/60d95b4ed4f6e9ac38441d130d3969597ce4d626\",\"venue\":\"ICLR 2020\",\"year\":2020},{\"arxivId\":\"2003.08743\",\"authors\":[{\"authorId\":\"1397408750\",\"name\":\"D. Huh\"},{\"authorId\":\"1573578354\",\"name\":\"Sai Gurrapu\"},{\"authorId\":\"100776037\",\"name\":\"Frederick F Olson\"},{\"authorId\":\"145344187\",\"name\":\"H. Rangwala\"},{\"authorId\":\"144009395\",\"name\":\"Parth Pathak\"},{\"authorId\":\"1743020\",\"name\":\"J. Kosecka\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"84aee38a5b6d17136bab3f82bc6ede7a7db8fcf4\",\"title\":\"Generative Multi-Stream Architecture For American Sign Language Recognition\",\"url\":\"https://www.semanticscholar.org/paper/84aee38a5b6d17136bab3f82bc6ede7a7db8fcf4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.14950\",\"authors\":[{\"authorId\":\"26959701\",\"name\":\"Hengduo Li\"},{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"51453757\",\"name\":\"Abhinav Shrivastava\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f434d65e76041d3417715791e052255f924d4efc\",\"title\":\"2D or not 2D? Adaptive 3D Convolution Selection for Efficient Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f434d65e76041d3417715791e052255f924d4efc\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1910.05577\",\"authors\":[{\"authorId\":\"1821514\",\"name\":\"Xu-Dong Lin\"},{\"authorId\":\"152309767\",\"name\":\"L. Ma\"},{\"authorId\":\"1743698\",\"name\":\"Wenyu Liu\"},{\"authorId\":\"72197815\",\"name\":\"Shih-Fu Chang\"}],\"doi\":\"10.1007/978-3-030-58523-5_41\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"119b1526842c105ef9a5b187c13045eb580220e7\",\"title\":\"Context-Gated Convolution\",\"url\":\"https://www.semanticscholar.org/paper/119b1526842c105ef9a5b187c13045eb580220e7\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2563751\",\"name\":\"Y. Zhu\"},{\"authorId\":\"145015817\",\"name\":\"Gang Yu\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"},{\"authorId\":\"10212005\",\"name\":\"K. Ma\"}],\"doi\":\"10.1109/ICIP.2018.8451430\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a6badaa9bbd8e222a2f06389261e27c5a599df68\",\"title\":\"Selecting Informative Frames for Action Recognition with Partial Observations\",\"url\":\"https://www.semanticscholar.org/paper/a6badaa9bbd8e222a2f06389261e27c5a599df68\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39816387\",\"name\":\"C. Li\"},{\"authorId\":\"144916982\",\"name\":\"Zhi Hou\"},{\"authorId\":\"35843399\",\"name\":\"Jiaxu Chen\"},{\"authorId\":\"3272118\",\"name\":\"Yilei Bu\"},{\"authorId\":\"9162532\",\"name\":\"Jiqiang Zhou\"},{\"authorId\":\"1842317\",\"name\":\"Qiaoyong Zhong\"},{\"authorId\":\"50322310\",\"name\":\"Di Xie\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ac559873b288f3ac28ee8a38c0f3710ea3f986d9\",\"title\":\"Team DEEP-HRI Moments in Time Challenge 2018 Technical Report\",\"url\":\"https://www.semanticscholar.org/paper/ac559873b288f3ac28ee8a38c0f3710ea3f986d9\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47781687\",\"name\":\"Z. Liu\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1109/ACCESS.2019.2894025\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9e1dbea5bb15fa88af384ec1baf4a20cffb6e6a8\",\"title\":\"Spatiotemporal Relation Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9e1dbea5bb15fa88af384ec1baf4a20cffb6e6a8\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1384783474\",\"name\":\"Ailin Li\"},{\"authorId\":\"40142564\",\"name\":\"Zhao-Wei Shang\"}],\"doi\":\"10.1109/IJCNN.2019.8851917\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"85f59fec904dce130337ec60cfbe4ad8ca043494\",\"title\":\"A new Spectral-Spatial Pseudo-3D Dense Network for Hyperspectral Image Classification\",\"url\":\"https://www.semanticscholar.org/paper/85f59fec904dce130337ec60cfbe4ad8ca043494\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48599063\",\"name\":\"Ziqi Yang\"},{\"authorId\":\"46810102\",\"name\":\"X. Gong\"},{\"authorId\":\"46791330\",\"name\":\"Ying Guo\"},{\"authorId\":\"49663403\",\"name\":\"Wenbin Liu\"}],\"doi\":\"10.1109/ACCESS.2020.2990683\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"52b6cb41e3603efadcacac33ee0ce0e92dc344bc\",\"title\":\"A Temporal Sequence Dual-Branch Network for Classifying Hybrid Ultrasound Data of Breast Cancer\",\"url\":\"https://www.semanticscholar.org/paper/52b6cb41e3603efadcacac33ee0ce0e92dc344bc\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2001.06769\",\"authors\":[{\"authorId\":\"151080964\",\"name\":\"Kaiyu Shan\"},{\"authorId\":null,\"name\":\"Yongtao Wang\"},{\"authorId\":\"5744018\",\"name\":\"Z. Wang\"},{\"authorId\":\"47715977\",\"name\":\"Ting-Ting Liang\"},{\"authorId\":null,\"name\":\"Zhi Tang\"},{\"authorId\":\"50581109\",\"name\":\"Y. Chen\"},{\"authorId\":\"1920864\",\"name\":\"Yangyan Li\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0c09d3844807f4cbed18f5ff5d5df34a89365d07\",\"title\":\"MixTConv: Mixed Temporal Convolutional Kernels for Efficient Action Recogntion\",\"url\":\"https://www.semanticscholar.org/paper/0c09d3844807f4cbed18f5ff5d5df34a89365d07\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48707764\",\"name\":\"Zhenzhen Wang\"},{\"authorId\":\"3493754\",\"name\":\"Weixiang Hong\"},{\"authorId\":\"30915941\",\"name\":\"Y. Tan\"},{\"authorId\":\"145078769\",\"name\":\"J. Yuan\"}],\"doi\":\"10.1109/TMM.2019.2950523\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"bf2a57ab2ee450ab14304ad91929a44c98fb5272\",\"title\":\"Pruning 3D Filters For Accelerating 3D ConvNets\",\"url\":\"https://www.semanticscholar.org/paper/bf2a57ab2ee450ab14304ad91929a44c98fb5272\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47319654\",\"name\":\"S. Li\"},{\"authorId\":\"1741668\",\"name\":\"Zhicheng Zhao\"},{\"authorId\":\"152343380\",\"name\":\"Fei Su\"}],\"doi\":\"10.1109/VCIP47243.2019.8965878\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"eced654a4b8467a6b52194af8e4d83bcbe1730cb\",\"title\":\"A Spatio-temporal Hybrid Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eced654a4b8467a6b52194af8e4d83bcbe1730cb\",\"venue\":\"2019 IEEE Visual Communications and Image Processing (VCIP)\",\"year\":2019},{\"arxivId\":\"1909.13474\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":\"10.1109/ICMLA.2019.00036\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"df3b3722df9f1c6a6b586a1c81a109c61ae7f9a9\",\"title\":\"Spatio-Temporal FAST 3D Convolutions for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/df3b3722df9f1c6a6b586a1c81a109c61ae7f9a9\",\"venue\":\"2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51046192\",\"name\":\"Yixiong Zou\"},{\"authorId\":\"3040136\",\"name\":\"Yemin Shi\"},{\"authorId\":\"1576036690\",\"name\":\"Daochen Shi\"},{\"authorId\":null,\"name\":\"Yaowei Wang\"},{\"authorId\":\"3342777\",\"name\":\"Yongsheng Liang\"},{\"authorId\":\"144051792\",\"name\":\"Yonghong Tian\"}],\"doi\":\"10.1109/TMM.2020.2972128\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"94ebd897b1be9b15b547cff41a3aff2efbca2854\",\"title\":\"Adaptation-Oriented Feature Projection for One-Shot Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/94ebd897b1be9b15b547cff41a3aff2efbca2854\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40242953\",\"name\":\"R. Belmonte\"},{\"authorId\":\"2128037\",\"name\":\"N. Ihaddadene\"},{\"authorId\":\"1694537\",\"name\":\"Pierre Tirilly\"},{\"authorId\":\"3036685\",\"name\":\"Ioan Marius Bilasco\"},{\"authorId\":\"1705776\",\"name\":\"C. Djeraba\"}],\"doi\":\"10.1109/WACV.2019.00228\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0a2546319c4926a56fb82cfa475d2d8e6ab96ab1\",\"title\":\"Video-Based Face Alignment With Local Motion Modeling\",\"url\":\"https://www.semanticscholar.org/paper/0a2546319c4926a56fb82cfa475d2d8e6ab96ab1\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1527097295\",\"name\":\"Yue Li\"},{\"authorId\":\"31399226\",\"name\":\"Wenrui Ding\"},{\"authorId\":\"2563751\",\"name\":\"Y. Zhu\"},{\"authorId\":\"46843692\",\"name\":\"Yuanjun Huang\"},{\"authorId\":\"9325297\",\"name\":\"Yalong Jiang\"},{\"authorId\":\"46242227\",\"name\":\"B. Zhang\"}],\"doi\":\"10.1109/ICIP40778.2020.9191306\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a3f7e4074a356474113cdb6cb4c7ca7cb3e097d5\",\"title\":\"Cam-Net: Compressed Attentive Multi-Granularity Network For Dynamic Scene Classification\",\"url\":\"https://www.semanticscholar.org/paper/a3f7e4074a356474113cdb6cb4c7ca7cb3e097d5\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48902313\",\"name\":\"Wei Zhang\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"2066429\",\"name\":\"Shiai Zhu\"},{\"authorId\":\"30889568\",\"name\":\"Abdulmotaleb El Saddik\"}],\"doi\":\"10.1145/3279952\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bb9e418469d018be7f5ac2c4b2435ccac50088a3\",\"title\":\"Deep Learning\\u2013Based Multimedia Analytics\",\"url\":\"https://www.semanticscholar.org/paper/bb9e418469d018be7f5ac2c4b2435ccac50088a3\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144290805\",\"name\":\"L. Shi\"},{\"authorId\":\"40382978\",\"name\":\"Yifan Zhang\"},{\"authorId\":\"144228565\",\"name\":\"Jian Cheng\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1109/CVPR.2019.00810\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"68a024d7b70ef3989a6751678f635cbe754440fc\",\"title\":\"Skeleton-Based Action Recognition With Directed Graph Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/68a024d7b70ef3989a6751678f635cbe754440fc\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1906.05571\",\"authors\":[{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"143977389\",\"name\":\"C. Ngo\"},{\"authorId\":\"40434674\",\"name\":\"X. Tian\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2019.01233\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e65e8c434895601b27cda0bef9b1bd9ff1475bf3\",\"title\":\"Learning Spatio-Temporal Representation With Local and Global Diffusion\",\"url\":\"https://www.semanticscholar.org/paper/e65e8c434895601b27cda0bef9b1bd9ff1475bf3\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2004.04968\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"1628244042\",\"name\":\"Tenga Wakamiya\"},{\"authorId\":\"2199251\",\"name\":\"K. Hara\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4b1ca549b3378ff8ae52db1528f9f7402544cfd7\",\"title\":\"Would Mega-scale Datasets Further Enhance Spatiotemporal 3D CNNs?\",\"url\":\"https://www.semanticscholar.org/paper/4b1ca549b3378ff8ae52db1528f9f7402544cfd7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.12034\",\"authors\":[{\"authorId\":\"1809218238\",\"name\":\"Xiaofang Wang\"},{\"authorId\":\"3182065\",\"name\":\"Xuehan Xiong\"},{\"authorId\":\"7679232\",\"name\":\"M. Neumann\"},{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"},{\"authorId\":\"2148510\",\"name\":\"A. Angelova\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"},{\"authorId\":\"145221796\",\"name\":\"W. Hua\"}],\"doi\":\"10.1007/978-3-030-58598-3_27\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"858a9f482e2dc1cebf7a116a740ddd0cf1f13506\",\"title\":\"AttentionNAS: Spatiotemporal Attention Cell Search for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/858a9f482e2dc1cebf7a116a740ddd0cf1f13506\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48447537\",\"name\":\"Haijun Liu\"},{\"authorId\":\"2019481\",\"name\":\"S. Wang\"},{\"authorId\":\"97520398\",\"name\":\"Wen Wang\"},{\"authorId\":\"144569543\",\"name\":\"J. Cheng\"}],\"doi\":\"10.1109/TMM.2019.2929923\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e0ab0522090b2c1e84dd7a4245d3f784ac17f59e\",\"title\":\"Multi-Scale Based Context-Aware Net for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/e0ab0522090b2c1e84dd7a4245d3f784ac17f59e\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"1811.12506\",\"authors\":[{\"authorId\":\"32234354\",\"name\":\"Yingda Xia\"},{\"authorId\":\"41028084\",\"name\":\"Fengze Liu\"},{\"authorId\":\"144041880\",\"name\":\"D. Yang\"},{\"authorId\":\"3457945\",\"name\":\"Jinzheng Cai\"},{\"authorId\":\"2342535\",\"name\":\"Lequan Yu\"},{\"authorId\":\"1834450\",\"name\":\"Zhuotun Zhu\"},{\"authorId\":\"3262394\",\"name\":\"Daguang Xu\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"},{\"authorId\":\"144531567\",\"name\":\"H. Roth\"}],\"doi\":\"10.1109/WACV45572.2020.9093608\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d7000a609c9aa59c1fd893cdfa6f51cd9cd22354\",\"title\":\"3D Semi-Supervised Learning with Uncertainty-Aware Multi-View Co-Training\",\"url\":\"https://www.semanticscholar.org/paper/d7000a609c9aa59c1fd893cdfa6f51cd9cd22354\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1908.09442\",\"authors\":[{\"authorId\":\"47057388\",\"name\":\"X. Li\"},{\"authorId\":\"6873935\",\"name\":\"T. Lin\"},{\"authorId\":\"153201747\",\"name\":\"Xiao Liu\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"1724520\",\"name\":\"W. Zuo\"},{\"authorId\":\"46651287\",\"name\":\"C. Li\"},{\"authorId\":\"46550771\",\"name\":\"X. Long\"},{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"32379958\",\"name\":\"Fu Li\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"}],\"doi\":\"10.1145/3394171.3413860\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"317e0392d2a830df88dd093df01ef4d2943e5c96\",\"title\":\"Deep Concept-wise Temporal Convolutional Networks for Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/317e0392d2a830df88dd093df01ef4d2943e5c96\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2768467\",\"name\":\"Jennifer Vandoni\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"91afdf0d1a19def1127e278ff2f0b9e26b12fd2b\",\"title\":\"Ensemble Methods for Pedestrian Detection in Dense Crowds. (M\\u00e9thodes d'ensembles pour la d\\u00e9tection de pi\\u00e9tons en foules denses)\",\"url\":\"https://www.semanticscholar.org/paper/91afdf0d1a19def1127e278ff2f0b9e26b12fd2b\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1912.01180\",\"authors\":[{\"authorId\":\"145954571\",\"name\":\"Y. Zhang\"},{\"authorId\":\"12732902\",\"name\":\"Xinyue Wei\"},{\"authorId\":\"3256056\",\"name\":\"Weichao Qiu\"},{\"authorId\":\"9381483\",\"name\":\"Zihao Xiao\"},{\"authorId\":\"1678633\",\"name\":\"Gregory Hager\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b3260a2fb397b9a04d96546f0823ce7b84ba8e3d\",\"title\":\"RSA: Randomized Simulation as Augmentation for Robust Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b3260a2fb397b9a04d96546f0823ce7b84ba8e3d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2007.03560\",\"authors\":[{\"authorId\":\"48550129\",\"name\":\"Jiajun Deng\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"},{\"authorId\":\"1490772804\",\"name\":\"Tao Mei\"}],\"doi\":\"10.1109/tmm.2020.2990070\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"57c38661af2d1ac5ac79cc51a443f5f1cca4b03b\",\"title\":\"Single Shot Video Object Detector\",\"url\":\"https://www.semanticscholar.org/paper/57c38661af2d1ac5ac79cc51a443f5f1cca4b03b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47652825\",\"name\":\"Ming Zong\"},{\"authorId\":\"47652825\",\"name\":\"Ming Zong\"},{\"authorId\":\"1962363403\",\"name\":\"Ruili Wang\"},{\"authorId\":\"1962363403\",\"name\":\"Ruili Wang\"},{\"authorId\":\"150356113\",\"name\":\"Zhe Chen\"},{\"authorId\":\"2018580\",\"name\":\"M. Wang\"},{\"authorId\":\"1725522\",\"name\":\"X. Wang\"},{\"authorId\":\"1725522\",\"name\":\"X. Wang\"},{\"authorId\":\"144783648\",\"name\":\"J. Potgieter\"}],\"doi\":\"10.1007/s00521-020-05313-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"721fe37281bf9ea474a0c4f1441f02a7d6e4e4ed\",\"title\":\"Multi-cue based 3D residual network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/721fe37281bf9ea474a0c4f1441f02a7d6e4e4ed\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1911.10477\",\"authors\":[{\"authorId\":\"47988339\",\"name\":\"Jiancheng Yang\"},{\"authorId\":\"97620448\",\"name\":\"Xiaoyang. Huang\"},{\"authorId\":\"2007540200\",\"name\":\"Yi He\"},{\"authorId\":\"51458977\",\"name\":\"J. Xu\"},{\"authorId\":\"1429834069\",\"name\":\"Canqian Yang\"},{\"authorId\":\"7314697\",\"name\":\"Guozheng Xu\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7384a5a54c6bc376e4bde319e5a3fe3e935407b2\",\"title\":\"Reinventing 2D Convolutions for 3D Images\",\"url\":\"https://www.semanticscholar.org/paper/7384a5a54c6bc376e4bde319e5a3fe3e935407b2\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1923065213\",\"name\":\"Qinghongya Shi\"},{\"authorId\":\"46702837\",\"name\":\"Hongbo Zhang\"},{\"authorId\":\"89616898\",\"name\":\"Haotian Ren\"},{\"authorId\":\"3721965\",\"name\":\"Ji-Xiang Du\"},{\"authorId\":\"48841342\",\"name\":\"Qing Lei\"}],\"doi\":\"10.1186/s13640-020-00519-1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b76ca4e12247ed63f98b0c1949a4eb9105ec1407\",\"title\":\"Consistent constraint-based video-level learning for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/b76ca4e12247ed63f98b0c1949a4eb9105ec1407\",\"venue\":\"EURASIP J. Image Video Process.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"14547418\",\"name\":\"Shengwei Zhou\"},{\"authorId\":\"153555891\",\"name\":\"L. Bai\"},{\"authorId\":\"1500530481\",\"name\":\"Haoran Wang\"},{\"authorId\":\"123580511\",\"name\":\"Zhi-Hong Deng\"},{\"authorId\":\"121330693\",\"name\":\"X. Zhu\"},{\"authorId\":\"143724074\",\"name\":\"C. Gong\"}],\"doi\":\"10.12783/dtcse/cisnrc2019/33302\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f1b8e2c68d93617489b838c223d402fa4f425f8e\",\"title\":\"A Spatial-temporal Attention Module for 3D Convolution Network in Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f1b8e2c68d93617489b838c223d402fa4f425f8e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39419353\",\"name\":\"L. Deng\"},{\"authorId\":\"2627016\",\"name\":\"Q. Gao\"},{\"authorId\":\"87380552\",\"name\":\"D. Xu\"}],\"doi\":\"10.1007/978-981-15-7981-3_34\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7df36dc35b31a24d40828f8f08525eb29d087313\",\"title\":\"Self-service Behavior Recognition Algorithm Based on Improved Motion History Image Network\",\"url\":\"https://www.semanticscholar.org/paper/7df36dc35b31a24d40828f8f08525eb29d087313\",\"venue\":\"ICPCSEE\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48599170\",\"name\":\"Zhikai Yang\"},{\"authorId\":\"9420592\",\"name\":\"Leping Bu\"},{\"authorId\":\"1783874\",\"name\":\"T. Wang\"},{\"authorId\":\"67253263\",\"name\":\"Jineng Ouyang\"},{\"authorId\":\"145142116\",\"name\":\"P. Yuan\"}],\"doi\":\"10.1109/ICISCE.2018.00056\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"663c35da2431d551bb61a05a7a58981a96a304ff\",\"title\":\"Fire Alarm for Video Surveillance Based on Convolutional Neural Network and SRU\",\"url\":\"https://www.semanticscholar.org/paper/663c35da2431d551bb61a05a7a58981a96a304ff\",\"venue\":\"2018 5th International Conference on Information Science and Control Engineering (ICISCE)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6486893\",\"name\":\"Chao Pu\"},{\"authorId\":null,\"name\":\"Hikvision\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"88997434c3dcfe1b9355edae84c78429e423600c\",\"title\":\"Spatiotemporal Feature Learning for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/88997434c3dcfe1b9355edae84c78429e423600c\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39440469\",\"name\":\"Sudhakar Kumawat\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"68881e3828f18c304189755c5a64979752d4a3eb\",\"title\":\"LP-3 DCNN : Unveiling Local Phase in 3 D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/68881e3828f18c304189755c5a64979752d4a3eb\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1804.00413\",\"authors\":[{\"authorId\":\"2548303\",\"name\":\"Lijie Fan\"},{\"authorId\":\"2978255\",\"name\":\"Wen-bing Huang\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"2490652\",\"name\":\"S. Ermon\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"},{\"authorId\":\"1768190\",\"name\":\"J. Huang\"}],\"doi\":\"10.1109/CVPR.2018.00630\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"259dcd1afe22e569132ccc41697ac368504c4dd1\",\"title\":\"End-to-End Learning of Motion Representation for Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/259dcd1afe22e569132ccc41697ac368504c4dd1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1685776\",\"name\":\"Y. Li\"},{\"authorId\":\"1695600\",\"name\":\"X. Chai\"},{\"authorId\":\"1710220\",\"name\":\"X. Chen\"}],\"doi\":\"10.1007/978-3-030-00767-6_12\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f2eb32ef5538ae65e0fbe905ba6cfe7387b6eb3f\",\"title\":\"End-To-End Learning for Action Quality Assessment\",\"url\":\"https://www.semanticscholar.org/paper/f2eb32ef5538ae65e0fbe905ba6cfe7387b6eb3f\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":\"1809.05848\",\"authors\":[{\"authorId\":\"46700331\",\"name\":\"J. Liu\"},{\"authorId\":\"51305314\",\"name\":\"Zehuan Yuan\"},{\"authorId\":\"1697065\",\"name\":\"C. Wang\"}],\"doi\":\"10.1007/978-3-030-11018-5_26\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1dc373458adf54678b6b981ce458ccdbe3f9d112\",\"title\":\"Towards Good Practices for Multi-modal Fusion in Large-scale Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/1dc373458adf54678b6b981ce458ccdbe3f9d112\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47130333\",\"name\":\"Siqi Liu\"},{\"authorId\":\"3262394\",\"name\":\"Daguang Xu\"},{\"authorId\":\"145668226\",\"name\":\"S. Zhou\"},{\"authorId\":\"79819296\",\"name\":\"T. Mertelmeier\"},{\"authorId\":\"12091651\",\"name\":\"Julia Wicklein\"},{\"authorId\":\"80354455\",\"name\":\"Anna Jerebko\"},{\"authorId\":\"1764071\",\"name\":\"S. Grbic\"},{\"authorId\":\"2178555\",\"name\":\"Olivier Pauly\"},{\"authorId\":\"122905659\",\"name\":\"Weidong Cai\"},{\"authorId\":\"1685020\",\"name\":\"D. Comaniciu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"bc561e8ceefdc1530805492ab1b7fadc9ba5a5b0\",\"title\":\"3 D Anisotropic Hybrid Network : Transferring Convolutional Features from 2 D Images to 3 D Anisotropic Volumes\",\"url\":\"https://www.semanticscholar.org/paper/bc561e8ceefdc1530805492ab1b7fadc9ba5a5b0\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2010.12573\",\"authors\":[{\"authorId\":\"34973011\",\"name\":\"Qichuan Geng\"},{\"authorId\":\"9184786\",\"name\":\"H. Zhang\"},{\"authorId\":\"48272798\",\"name\":\"N. Jiang\"},{\"authorId\":\"50844674\",\"name\":\"Xiaojuan Qi\"},{\"authorId\":\"47059724\",\"name\":\"L. Zhang\"},{\"authorId\":\"1750157\",\"name\":\"Zhong Zhou\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b4d1ef00c8029a42cf0faeb11c4e1f9965a8329a\",\"title\":\"Object-aware Feature Aggregation for Video Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/b4d1ef00c8029a42cf0faeb11c4e1f9965a8329a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1742445396\",\"name\":\"Lin Wang\"},{\"authorId\":\"1935766044\",\"name\":\"Jingqian Jia\"},{\"authorId\":\"32585571\",\"name\":\"Nan-nan Mao\"}],\"doi\":\"10.23919/CCC50068.2020.9188920\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2b23c6d01df6320161e7a34df91435f65fec64ab\",\"title\":\"Micro-Expression Recognition Based on 2D-3D CNN\",\"url\":\"https://www.semanticscholar.org/paper/2b23c6d01df6320161e7a34df91435f65fec64ab\",\"venue\":\"2020 39th Chinese Control Conference (CCC)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10033841\",\"name\":\"Xinzhe Zhou\"},{\"authorId\":\"145353089\",\"name\":\"Y. Mu\"}],\"doi\":\"10.1145/3372278.3390687\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fe1b4f10431881512b6dc4c4ece9545732db6f83\",\"title\":\"Google Helps YouTube: Learning Few-Shot Video Classification from Historic Tasks and Cross-Domain Sample Transfer\",\"url\":\"https://www.semanticscholar.org/paper/fe1b4f10431881512b6dc4c4ece9545732db6f83\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1406152923\",\"name\":\"Tingting Han\"},{\"authorId\":\"31255274\",\"name\":\"Hongxun Yao\"},{\"authorId\":\"2648498\",\"name\":\"Wenlong Xie\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":null,\"name\":\"Jun Yu\"}],\"doi\":\"10.1016/j.patcog.2020.107267\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"93dc1e7e7fbcb3110e19d6a8bca55b11b85a4604\",\"title\":\"TVENet: Temporal variance embedding network for fine-grained action representation\",\"url\":\"https://www.semanticscholar.org/paper/93dc1e7e7fbcb3110e19d6a8bca55b11b85a4604\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":\"1806.01810\",\"authors\":[{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1007/978-3-030-01228-1_25\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d7cbf2d3ea63d97b699cc04af98fea521459ee75\",\"title\":\"Videos as Space-Time Region Graphs\",\"url\":\"https://www.semanticscholar.org/paper/d7cbf2d3ea63d97b699cc04af98fea521459ee75\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1908.00497\",\"authors\":[{\"authorId\":\"145294961\",\"name\":\"L. Chi\"},{\"authorId\":\"9443552\",\"name\":\"G. Tian\"},{\"authorId\":\"145353089\",\"name\":\"Y. Mu\"},{\"authorId\":\"144876834\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/ICCVW.2019.00552\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5769318fd67d1104e561b7382b305b5ca810d6d2\",\"title\":\"Two-Stream Video Classification with Cross-Modality Attention\",\"url\":\"https://www.semanticscholar.org/paper/5769318fd67d1104e561b7382b305b5ca810d6d2\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1909.07725\",\"authors\":[{\"authorId\":\"40809222\",\"name\":\"Luxuan Li\"},{\"authorId\":\"145868988\",\"name\":\"Tao Kong\"},{\"authorId\":\"143823065\",\"name\":\"F. Sun\"},{\"authorId\":\"2641547\",\"name\":\"H. Liu\"}],\"doi\":\"10.1007/978-3-030-36718-3_40\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8f27170bf174d81e646492173ba9e9c97753853c\",\"title\":\"Deep Point-wise Prediction for Action Temporal Proposal\",\"url\":\"https://www.semanticscholar.org/paper/8f27170bf174d81e646492173ba9e9c97753853c\",\"venue\":\"ICONIP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2724075\",\"name\":\"Yiping Tang\"},{\"authorId\":\"51431831\",\"name\":\"Chuang Niu\"},{\"authorId\":\"35182090\",\"name\":\"Minghao Dong\"},{\"authorId\":\"10648494\",\"name\":\"Shenghan Ren\"},{\"authorId\":\"145157018\",\"name\":\"J. Liang\"}],\"doi\":\"10.1007/978-3-030-31723-2_47\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0603f946c7613af4122ebd9cee6d10885f008501\",\"title\":\"Poleward Moving Aurora Recognition with Deep Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/0603f946c7613af4122ebd9cee6d10885f008501\",\"venue\":\"PRCV\",\"year\":2019},{\"arxivId\":\"1907.09702\",\"authors\":[{\"authorId\":\"6873935\",\"name\":\"T. Lin\"},{\"authorId\":\"48032598\",\"name\":\"X. Liu\"},{\"authorId\":\"48568672\",\"name\":\"Xin Li\"},{\"authorId\":\"12081764\",\"name\":\"E. Ding\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"}],\"doi\":\"10.1109/ICCV.2019.00399\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"faf5651d82885243f5d310ced0e39e0703add073\",\"title\":\"BMN: Boundary-Matching Network for Temporal Action Proposal Generation\",\"url\":\"https://www.semanticscholar.org/paper/faf5651d82885243f5d310ced0e39e0703add073\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2004.11475\",\"authors\":[{\"authorId\":\"9247631\",\"name\":\"M. N. Rizve\"},{\"authorId\":\"2935412\",\"name\":\"U. Demir\"},{\"authorId\":\"82021814\",\"name\":\"Praveen Tirupattur\"},{\"authorId\":\"1564031469\",\"name\":\"A. J. Rana\"},{\"authorId\":\"7839191\",\"name\":\"K. Duarte\"},{\"authorId\":\"27058669\",\"name\":\"I. Dave\"},{\"authorId\":\"2116440\",\"name\":\"Y. Rawat\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"beb5336d3babd2307887fd7ac7db5d946160f8a1\",\"title\":\"Gabriella: An Online System for Real-Time Activity Detection in Untrimmed Security Videos\",\"url\":\"https://www.semanticscholar.org/paper/beb5336d3babd2307887fd7ac7db5d946160f8a1\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33524797\",\"name\":\"J. You\"},{\"authorId\":\"1719045\",\"name\":\"Jari Korhonen\"}],\"doi\":\"10.1109/ICIP40778.2020.9190996\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"73950a18eba6a112275e6e20a3919f8627a25801\",\"title\":\"Attention Boosted Deep Networks For Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/73950a18eba6a112275e6e20a3919f8627a25801\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145764891\",\"name\":\"Bo Xu\"},{\"authorId\":\"2044516\",\"name\":\"J. Wang\"},{\"authorId\":\"102517285\",\"name\":\"Cheng Lu\"},{\"authorId\":\"49813886\",\"name\":\"Yandong Guo\"}],\"doi\":\"10.1109/WACV45572.2020.9093314\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"58fd3c2efd2c9079c836ad2c9de642315115d779\",\"title\":\"Watch to Listen Clearly: Visual Speech Enhancement Driven Multi-modality Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/58fd3c2efd2c9079c836ad2c9de642315115d779\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46868809\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1720627\",\"name\":\"Lai Man Po\"},{\"authorId\":\"49354358\",\"name\":\"Mengyang Liu\"},{\"authorId\":\"6260845\",\"name\":\"Yasar Abbas Ur Rehman\"},{\"authorId\":\"144981001\",\"name\":\"W. Ou\"},{\"authorId\":\"103425198\",\"name\":\"Yuzhi Zhao\"}],\"doi\":\"10.1016/j.eswa.2020.113203\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"70ee88042c9bd87903b40b535973afecb6c2a49d\",\"title\":\"Data-level information enhancement: Motion-patch-based Siamese Convolutional Neural Networks for human activity recognition in videos\",\"url\":\"https://www.semanticscholar.org/paper/70ee88042c9bd87903b40b535973afecb6c2a49d\",\"venue\":\"Expert Syst. Appl.\",\"year\":2020},{\"arxivId\":\"2001.10695\",\"authors\":[{\"authorId\":\"48016410\",\"name\":\"H. Wang\"},{\"authorId\":\"13468744\",\"name\":\"H. C. Koydemir\"},{\"authorId\":\"1679220\",\"name\":\"Y. Qiu\"},{\"authorId\":\"153759853\",\"name\":\"B. Bai\"},{\"authorId\":\"48380268\",\"name\":\"Y. Zhang\"},{\"authorId\":\"52187516\",\"name\":\"Y. Jin\"},{\"authorId\":\"151424629\",\"name\":\"Sabiha Tok\"},{\"authorId\":\"1491008163\",\"name\":\"Enis Cagatay Yilmaz\"},{\"authorId\":\"137389022\",\"name\":\"Esin Gumustekin\"},{\"authorId\":\"48156295\",\"name\":\"Y. Rivenson\"},{\"authorId\":\"2660014\",\"name\":\"A. Ozcan\"}],\"doi\":\"10.1038/s41377-020-00358-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"56d56f9890487c752739780ede4cd4251bdddc86\",\"title\":\"Early detection and classification of live bacteria using time-lapse coherent imaging and deep learning\",\"url\":\"https://www.semanticscholar.org/paper/56d56f9890487c752739780ede4cd4251bdddc86\",\"venue\":\"Light, science & applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491240780\",\"name\":\"Z. Shi\"},{\"authorId\":\"144962375\",\"name\":\"Cheng Guan\"},{\"authorId\":\"1491233401\",\"name\":\"Liangjie Cao\"},{\"authorId\":\"1632356255\",\"name\":\"Qianqian Li\"},{\"authorId\":\"1993660232\",\"name\":\"Ju Liang\"},{\"authorId\":\"29344734\",\"name\":\"Zhaorui Gu\"},{\"authorId\":\"2336297\",\"name\":\"Haiyong Zheng\"},{\"authorId\":\"1470709309\",\"name\":\"Bing Zheng\"}],\"doi\":\"10.1007/978-3-030-58539-6_23\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c826e169f505f6fda0872d0a3e1e156e15b5111e\",\"title\":\"CoTeRe-Net: Discovering Collaborative Ternary Relations in Videos\",\"url\":\"https://www.semanticscholar.org/paper/c826e169f505f6fda0872d0a3e1e156e15b5111e\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144864744\",\"name\":\"Wen-Jun Zeng\"}],\"doi\":\"10.1017/atsip.2019.26\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e83046ed4d7c021b19801bc747c4cc1a6fb7df91\",\"title\":\"Toward human-centric deep video understanding\",\"url\":\"https://www.semanticscholar.org/paper/e83046ed4d7c021b19801bc747c4cc1a6fb7df91\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49898078\",\"name\":\"Xierong Zhu\"},{\"authorId\":\"1471355792\",\"name\":\"Jiawei Liu\"},{\"authorId\":\"40354734\",\"name\":\"Haoze Wu\"},{\"authorId\":\"5332711\",\"name\":\"Meng Wang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"}],\"doi\":\"10.1145/3394171.3413843\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"42f81abff3a2a3c6594f167d51347e4aeb3ee01d\",\"title\":\"ASTA-Net: Adaptive Spatio-Temporal Attention Network for Person Re-Identification in Videos\",\"url\":\"https://www.semanticscholar.org/paper/42f81abff3a2a3c6594f167d51347e4aeb3ee01d\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2005.02113\",\"authors\":[{\"authorId\":\"47892681\",\"name\":\"Haoxin Li\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"},{\"authorId\":\"1401057385\",\"name\":\"Yu Tao\"},{\"authorId\":\"37403439\",\"name\":\"H. Hu\"},{\"authorId\":\"153224231\",\"name\":\"Jianhuang Lai\"}],\"doi\":\"10.1109/CVPR42600.2020.00060\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5c02af517dff2ff0d34dee04535731b7d252bbbb\",\"title\":\"Adaptive Interaction Modeling via Graph Operations Search\",\"url\":\"https://www.semanticscholar.org/paper/5c02af517dff2ff0d34dee04535731b7d252bbbb\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47203405\",\"name\":\"Wenhao Wu\"},{\"authorId\":\"2192303\",\"name\":\"Dongliang He\"},{\"authorId\":\"145681030\",\"name\":\"Xiao Tan\"},{\"authorId\":\"2869725\",\"name\":\"Shifeng Chen\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5cea56f516de4e239467d2c4b77488725765e4e3\",\"title\":\"Agent 1 Agent 2 Agent 3 Predicted as Hopscotch Action Observation Observation Observation Action Action Step by step Untrimmed video All agents stop\",\"url\":\"https://www.semanticscholar.org/paper/5cea56f516de4e239467d2c4b77488725765e4e3\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144749224\",\"name\":\"Jun Kong\"},{\"authorId\":\"1516881495\",\"name\":\"Zhende Teng\"},{\"authorId\":\"145309461\",\"name\":\"Min Jiang\"},{\"authorId\":\"2254164\",\"name\":\"Hongtao Huo\"}],\"doi\":\"10.1117/1.JEI.29.1.013001\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"86e6f7cfe8c37c41cfdbb11da8499ddf98feedb5\",\"title\":\"Video-based person re-identification with parallel spatial\\u2013temporal attention module\",\"url\":\"https://www.semanticscholar.org/paper/86e6f7cfe8c37c41cfdbb11da8499ddf98feedb5\",\"venue\":\"J. Electronic Imaging\",\"year\":2020},{\"arxivId\":\"1711.09577\",\"authors\":[{\"authorId\":\"2199251\",\"name\":\"K. Hara\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"}],\"doi\":\"10.1109/CVPR.2018.00685\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"d716435f0cb0cac56237f74b1ced940aabce6a2b\",\"title\":\"Can Spatiotemporal 3D CNNs Retrace the History of 2D CNNs and ImageNet?\",\"url\":\"https://www.semanticscholar.org/paper/d716435f0cb0cac56237f74b1ced940aabce6a2b\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29724362\",\"name\":\"Longlong Jing\"},{\"authorId\":\"35484757\",\"name\":\"Yingli Tian\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"3eb9f4ca21bd104b1d9963a5a74e0ad48a1a1bdf\",\"title\":\"Self-supervised Spatiotemporal Feature Learning by Video Geometric Transformations\",\"url\":\"https://www.semanticscholar.org/paper/3eb9f4ca21bd104b1d9963a5a74e0ad48a1a1bdf\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1646959833\",\"name\":\"Yuecong Min\"},{\"authorId\":\"152550038\",\"name\":\"Xiujuan Chai\"},{\"authorId\":\"9055516\",\"name\":\"L. Zhao\"},{\"authorId\":\"1710220\",\"name\":\"X. Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fb74477f987459e27bc6b667b4535c378442bd6b\",\"title\":\"FlickerNet: Adaptive 3D Gesture Recognition from Sparse Point Clouds\",\"url\":\"https://www.semanticscholar.org/paper/fb74477f987459e27bc6b667b4535c378442bd6b\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"69893872\",\"name\":\"Yuri Yudhaswana Joefrie\"},{\"authorId\":\"96853476\",\"name\":\"Masaki Aono\"}],\"doi\":\"10.1109/ICAICTA.2019.8904245\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6ccba260ccaa7fb9a649497e80aefa737756b3b0\",\"title\":\"Action Recognition by Composite Deep Learning Architecture I3D-DenseLSTM\",\"url\":\"https://www.semanticscholar.org/paper/6ccba260ccaa7fb9a649497e80aefa737756b3b0\",\"venue\":\"2019 International Conference of Advanced Informatics: Concepts, Theory and Applications (ICAICTA)\",\"year\":2019},{\"arxivId\":\"2006.11416\",\"authors\":[{\"authorId\":\"48084289\",\"name\":\"S. Kumar\"},{\"authorId\":\"1411543040\",\"name\":\"Ehsan Yaghoubi\"},{\"authorId\":\"1712429\",\"name\":\"Hugo Proen\\u00e7a\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bb2bea2b34e7e67fd611924d10c06e4b70c6d016\",\"title\":\"A Symbolic Temporal Pooling method for Video-based Person Re-Identification\",\"url\":\"https://www.semanticscholar.org/paper/bb2bea2b34e7e67fd611924d10c06e4b70c6d016\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41022447\",\"name\":\"Okan K\\u00f6p\\u00fckl\\u00fc\"},{\"authorId\":\"1862703\",\"name\":\"N. Kose\"},{\"authorId\":\"66999822\",\"name\":\"Ahmet Gunduz\"},{\"authorId\":\"46343645\",\"name\":\"G. Rigoll\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d712fdf54d2d4c56afdc89e779208113b6edeafb\",\"title\":\"Resource Efficient 3 D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/d712fdf54d2d4c56afdc89e779208113b6edeafb\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1908.09535\",\"authors\":[{\"authorId\":\"32584231\",\"name\":\"Canmiao Fu\"},{\"authorId\":\"1678473\",\"name\":\"W. Pei\"},{\"authorId\":\"46632720\",\"name\":\"Q. Cao\"},{\"authorId\":\"51181069\",\"name\":\"C. Zhang\"},{\"authorId\":\"88823210\",\"name\":\"Yarou Zhao\"},{\"authorId\":\"2029246\",\"name\":\"Xiaoyong Shen\"},{\"authorId\":\"5068280\",\"name\":\"Yu-Wing Tai\"}],\"doi\":\"10.1109/ICCV.2019.00641\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"41621f06c2d262f12a59b5f0472080dd9e9afc53\",\"title\":\"Non-Local Recurrent Neural Memory for Supervised Sequence Modeling\",\"url\":\"https://www.semanticscholar.org/paper/41621f06c2d262f12a59b5f0472080dd9e9afc53\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"93385858\",\"name\":\"Z. Han\"},{\"authorId\":\"9260001\",\"name\":\"Yaling Liang\"},{\"authorId\":\"115023860\",\"name\":\"Zengqun Chen\"},{\"authorId\":\"6364267\",\"name\":\"Zhiheng Zhou\"}],\"doi\":\"10.3233/jifs-192067\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1eb45acc4f27fc47ed13249273cf5cb86476b154\",\"title\":\"A two-stream network with joint spatial-temporal distance for video-based person re-identification\",\"url\":\"https://www.semanticscholar.org/paper/1eb45acc4f27fc47ed13249273cf5cb86476b154\",\"venue\":\"J. Intell. Fuzzy Syst.\",\"year\":2020},{\"arxivId\":\"2003.06754\",\"authors\":[{\"authorId\":\"2498892\",\"name\":\"Pengxiang Wu\"},{\"authorId\":\"145552439\",\"name\":\"Siheng Chen\"},{\"authorId\":\"1711560\",\"name\":\"D. Metaxas\"}],\"doi\":\"10.1109/cvpr42600.2020.01140\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5e84232f179034b039bfc4d1dae3c91c1a50bfa2\",\"title\":\"MotionNet: Joint Perception and Motion Prediction for Autonomous Driving Based on Bird\\u2019s Eye View Maps\",\"url\":\"https://www.semanticscholar.org/paper/5e84232f179034b039bfc4d1dae3c91c1a50bfa2\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145554928\",\"name\":\"J. Chan\"},{\"authorId\":\"5170308\",\"name\":\"V. Kearney\"},{\"authorId\":\"51192714\",\"name\":\"Samuel Haaf\"},{\"authorId\":\"50425713\",\"name\":\"Susan Wu\"},{\"authorId\":\"30019780\",\"name\":\"M. Bogdanov\"},{\"authorId\":\"87772906\",\"name\":\"Mariah Reddick\"},{\"authorId\":\"48477361\",\"name\":\"N. Dixit\"},{\"authorId\":\"49626341\",\"name\":\"A. Sudhyadhom\"},{\"authorId\":\"32018154\",\"name\":\"J. Chen\"},{\"authorId\":\"5124875\",\"name\":\"S. Yom\"},{\"authorId\":\"2286161\",\"name\":\"T. Solberg\"}],\"doi\":\"10.1002/mp.13495\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4656fa1257d009fe756a3d6e29de848dbdaeb689\",\"title\":\"A convolutional neural network algorithm for automatic segmentation of head and neck organs at risk using deep lifelong learning.\",\"url\":\"https://www.semanticscholar.org/paper/4656fa1257d009fe756a3d6e29de848dbdaeb689\",\"venue\":\"Medical physics\",\"year\":2019},{\"arxivId\":\"1905.02419\",\"authors\":[{\"authorId\":\"8706479\",\"name\":\"Z. Yu\"},{\"authorId\":\"20868803\",\"name\":\"Xiao-Bai Li\"},{\"authorId\":\"1757287\",\"name\":\"G. Zhao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"364ec52bba0bcd43c6deb588bf7f1d8269be84b9\",\"title\":\"Remote Photoplethysmograph Signal Measurement from Facial Videos Using Spatio-Temporal Networks\",\"url\":\"https://www.semanticscholar.org/paper/364ec52bba0bcd43c6deb588bf7f1d8269be84b9\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49120765\",\"name\":\"R. Singh\"},{\"authorId\":\"1387052806\",\"name\":\"Ankur Sonawane\"},{\"authorId\":\"33188415\",\"name\":\"R. Srivastava\"}],\"doi\":\"10.1007/s00530-019-00635-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"45a7a721cfe3f179c5bf86ae08340b1f38fdde48\",\"title\":\"Recent evolution of modern datasets for human activity recognition: a deep survey\",\"url\":\"https://www.semanticscholar.org/paper/45a7a721cfe3f179c5bf86ae08340b1f38fdde48\",\"venue\":\"Multimedia Systems\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4158401\",\"name\":\"Yeguang Li\"},{\"authorId\":\"48985434\",\"name\":\"Mingyuan Zhang\"},{\"authorId\":\"1384843518\",\"name\":\"L. Hu\"},{\"authorId\":\"49298479\",\"name\":\"J. Li\"},{\"authorId\":\"1792722\",\"name\":\"Deqing Wang\"}],\"doi\":\"10.1016/j.jvcir.2020.102818\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5392fc56f99ab7f9fc01ca2bca94a13acd8cf280\",\"title\":\"Candidate region correlation for video action detection\",\"url\":\"https://www.semanticscholar.org/paper/5392fc56f99ab7f9fc01ca2bca94a13acd8cf280\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2020},{\"arxivId\":\"1910.03579\",\"authors\":[{\"authorId\":\"2511001\",\"name\":\"Yin Bi\"},{\"authorId\":\"33998511\",\"name\":\"Aaron Chadha\"},{\"authorId\":\"2822935\",\"name\":\"Alhabib Abbas\"},{\"authorId\":\"2820254\",\"name\":\"Eirina Bourtsoulatze\"},{\"authorId\":\"2747620\",\"name\":\"Y. Andreopoulos\"}],\"doi\":\"10.1109/TIP.2020.3023597\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5a5cf60486c7bf1937e7725ccccbdd95c4eb1f1b\",\"title\":\"Graph-Based Spatio-Temporal Feature Learning for Neuromorphic Vision Sensing\",\"url\":\"https://www.semanticscholar.org/paper/5a5cf60486c7bf1937e7725ccccbdd95c4eb1f1b\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1912.00381\",\"authors\":[{\"authorId\":\"1756362\",\"name\":\"Swathikiran Sudhakaran\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"}],\"doi\":\"10.1109/cvpr42600.2020.00118\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"57cee868188127305f966a178ca22025b397d911\",\"title\":\"Gate-Shift Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/57cee868188127305f966a178ca22025b397d911\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2008.11378\",\"authors\":[{\"authorId\":\"153420733\",\"name\":\"Haozhi Cao\"},{\"authorId\":\"9734988\",\"name\":\"Yuecong Xu\"},{\"authorId\":\"2562263\",\"name\":\"Jianfei Yang\"},{\"authorId\":\"120974533\",\"name\":\"Kezhi Mao\"},{\"authorId\":\"2037059\",\"name\":\"Jian-Xiong Yin\"},{\"authorId\":\"144308998\",\"name\":\"S. See\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c16a94fe31835a67a8cf5e2d4d1076e0037844a9\",\"title\":\"Effective Action Recognition with Embedded Key Point Shifts\",\"url\":\"https://www.semanticscholar.org/paper/c16a94fe31835a67a8cf5e2d4d1076e0037844a9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40354734\",\"name\":\"Haoze Wu\"},{\"authorId\":\"48210950\",\"name\":\"Jiawei Liu\"},{\"authorId\":\"49898078\",\"name\":\"Xierong Zhu\"},{\"authorId\":\"152808542\",\"name\":\"Meng Wang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"}],\"doi\":\"10.24963/ijcai.2020/105\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f4fb429109591a5d20136fe884b5fd7c7584a62c\",\"title\":\"Multi-Scale Spatial-Temporal Integration Convolutional Tube for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f4fb429109591a5d20136fe884b5fd7c7584a62c\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":\"2011.10830\",\"authors\":[{\"authorId\":\"97375393\",\"name\":\"Mengmeng Xu\"},{\"authorId\":\"1397974082\",\"name\":\"Juan-Manuel Perez-Rua\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"145944235\",\"name\":\"B. Mart\\u00ednez\"},{\"authorId\":\"2171228\",\"name\":\"Xiatian Zhu\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"145406420\",\"name\":\"Tao Xiang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cdc28eb98cd4e5fa28811f4ea6dbe7c64d5fcffe\",\"title\":\"Boundary-sensitive Pre-training for Temporal Localization in Videos\",\"url\":\"https://www.semanticscholar.org/paper/cdc28eb98cd4e5fa28811f4ea6dbe7c64d5fcffe\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.11319\",\"authors\":[{\"authorId\":\"1384480816\",\"name\":\"Pingchuan Ma\"},{\"authorId\":\"120026268\",\"name\":\"Yao Zhou\"},{\"authorId\":null,\"name\":\"Yu Lu\"},{\"authorId\":\"1726357\",\"name\":\"Wayne Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3b5829a65c4eb19ec8922a1575c6900d5f94046f\",\"title\":\"Learning Efficient Video Representation with Video Shuffle Networks\",\"url\":\"https://www.semanticscholar.org/paper/3b5829a65c4eb19ec8922a1575c6900d5f94046f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144422820\",\"name\":\"Xiang Xiang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c6cdf39c70aabf973a56db1ea009ab275f3f6ee8\",\"title\":\"Image-set, Temporal and Spatiotemporal Representations of Videos for Recognizing, Localizing and Quantifying Actions\",\"url\":\"https://www.semanticscholar.org/paper/c6cdf39c70aabf973a56db1ea009ab275f3f6ee8\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1492114969\",\"name\":\"Jason Li\"},{\"authorId\":null,\"name\":\"Helen Qiu jasonkli\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"3e2bbf3cdc651c1531a9bafbda59a6807417d578\",\"title\":\"Comparing Attention-based Neural Architectures for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/3e2bbf3cdc651c1531a9bafbda59a6807417d578\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1811.07157\",\"authors\":[{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"247ee3e4519381a84fdfe655223c270c4ef1ad75\",\"title\":\"Recurrence to the Rescue: Towards Causal Spatiotemporal Representations\",\"url\":\"https://www.semanticscholar.org/paper/247ee3e4519381a84fdfe655223c270c4ef1ad75\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32860700\",\"name\":\"P. Nguyen\"},{\"authorId\":\"1563062373\",\"name\":\"Jiaxiin Wu\"},{\"authorId\":\"152650698\",\"name\":\"Chong-Wah Ngo\"},{\"authorId\":\"34382594\",\"name\":\"D. Francis\"},{\"authorId\":\"145880168\",\"name\":\"B. Huet\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f629a5cfc144bc08f7e3ecb411c909c4ccf6f1a3\",\"title\":\"VIREO-EURECOM @ TRECVID 2019: Ad-hoc Video Search (AVS)\",\"url\":\"https://www.semanticscholar.org/paper/f629a5cfc144bc08f7e3ecb411c909c4ccf6f1a3\",\"venue\":\"TRECVID\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8706479\",\"name\":\"Z. Yu\"},{\"authorId\":\"33672691\",\"name\":\"X. Li\"},{\"authorId\":\"1757287\",\"name\":\"G. Zhao\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9839040bb11373864d33c6d0e26b7df76a4125af\",\"title\":\"Recovering remote Photoplethysmograph Signal from Facial videos Using Spatio-Temporal Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/9839040bb11373864d33c6d0e26b7df76a4125af\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1844576260\",\"name\":\"Changchen Zhao\"},{\"authorId\":\"1844602717\",\"name\":\"Weiran Han\"},{\"authorId\":\"121238673\",\"name\":\"Zan Chen\"},{\"authorId\":\"48514786\",\"name\":\"Yong-qiang Li\"},{\"authorId\":\"9196693\",\"name\":\"Yuanjing Feng\"}],\"doi\":\"10.1109/CVPRW50498.2020.00147\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7653220ce9b9ce531946fadf3b5329b69bfed043\",\"title\":\"Remote Estimation of Heart Rate Based on Multi-Scale Facial ROIs\",\"url\":\"https://www.semanticscholar.org/paper/7653220ce9b9ce531946fadf3b5329b69bfed043\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"1808.03766\",\"authors\":[{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"},{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"19198894\",\"name\":\"Humam Alwassel\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"8983218\",\"name\":\"S. Buch\"},{\"authorId\":\"3409955\",\"name\":\"C. D. Dao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5468c96e3846da23c26b59c28c313506bffbf7ce\",\"title\":\"The ActivityNet Large-Scale Activity Recognition Challenge 2018 Summary\",\"url\":\"https://www.semanticscholar.org/paper/5468c96e3846da23c26b59c28c313506bffbf7ce\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2027003826\",\"name\":\"Mingfeng Hao\"},{\"authorId\":\"26957200\",\"name\":\"Mutallip Mamut\"},{\"authorId\":\"2027003608\",\"name\":\"Nurbiya Yadikar\"},{\"authorId\":\"2119595\",\"name\":\"A. Aysa\"},{\"authorId\":\"1869945\",\"name\":\"K. Ubul\"}],\"doi\":\"10.1109/ACCESS.2020.3036865\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3014cc7546ad2c35d47fd6627233d92d7ae40a85\",\"title\":\"A Survey of Research on Lipreading Technology\",\"url\":\"https://www.semanticscholar.org/paper/3014cc7546ad2c35d47fd6627233d92d7ae40a85\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1808.01556\",\"authors\":[{\"authorId\":\"22198846\",\"name\":\"Rongtian Ye\"},{\"authorId\":\"144097210\",\"name\":\"Fangyu Liu\"},{\"authorId\":\"1746430\",\"name\":\"L. Zhang\"}],\"doi\":\"10.1007/978-3-030-18305-9_15\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a985f8c3b245659d6d80cffb10a5430560bde89c\",\"title\":\"3D Depthwise Convolution: Reducing Model Parameters in 3D Vision Tasks\",\"url\":\"https://www.semanticscholar.org/paper/a985f8c3b245659d6d80cffb10a5430560bde89c\",\"venue\":\"Canadian Conference on AI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34779291\",\"name\":\"Fuchen Long\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"144954807\",\"name\":\"Q. Dai\"},{\"authorId\":\"40434674\",\"name\":\"X. Tian\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1145/3209978.3209999\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f27fd21273e3c31f166fad08c53f1fe27caf2490\",\"title\":\"Deep Domain Adaptation Hashing with Adversarial Learning\",\"url\":\"https://www.semanticscholar.org/paper/f27fd21273e3c31f166fad08c53f1fe27caf2490\",\"venue\":\"SIGIR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48321132\",\"name\":\"Y. Zou\"},{\"authorId\":\"9641665\",\"name\":\"X. Ren\"}],\"doi\":\"10.1007/978-981-15-8458-9_68\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a960a1e5184f5a90a7779cb7ffcc2d33140ec68f\",\"title\":\"An Efficient Action Recognition Framework Based on ELM and 3D CNN\",\"url\":\"https://www.semanticscholar.org/paper/a960a1e5184f5a90a7779cb7ffcc2d33140ec68f\",\"venue\":\"\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49455479\",\"name\":\"Y. Zhou\"},{\"authorId\":\"6485172\",\"name\":\"Xiaoyan Sun\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"cb2917413c9b36c3bb9739bce6c03a1a6eb619b3\",\"title\":\"MiCT : Mixed 3 D / 2 D Convolutional Tube for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cb2917413c9b36c3bb9739bce6c03a1a6eb619b3\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1808.04063\",\"authors\":[{\"authorId\":\"19198359\",\"name\":\"Yatao Zhong\"},{\"authorId\":\"3443241\",\"name\":\"Bicheng Xu\"},{\"authorId\":\"2057809\",\"name\":\"G. Zhou\"},{\"authorId\":\"3004771\",\"name\":\"L. Bornn\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1751a191e76eb57b1e132cf3ed3bb5964b3ddfe7\",\"title\":\"Time Perception Machine: Temporal Point Processes for the When, Where and What of Activity Prediction\",\"url\":\"https://www.semanticscholar.org/paper/1751a191e76eb57b1e132cf3ed3bb5964b3ddfe7\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3150525\",\"name\":\"E. Chen\"},{\"authorId\":\"144981720\",\"name\":\"Xue Bai\"},{\"authorId\":\"145735014\",\"name\":\"L. Gao\"},{\"authorId\":\"74806144\",\"name\":\"H. Tinega\"},{\"authorId\":\"1761058\",\"name\":\"Y. Ding\"}],\"doi\":\"10.1109/ACCESS.2019.2910604\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"41bfc72e40cb5878e1f6e54f450abb69345f8a99\",\"title\":\"A Spatiotemporal Heterogeneous Two-Stream Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/41bfc72e40cb5878e1f6e54f450abb69345f8a99\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"2008.05924\",\"authors\":[{\"authorId\":\"1387822126\",\"name\":\"Xingxun Jiang\"},{\"authorId\":\"48115912\",\"name\":\"Yuan Zong\"},{\"authorId\":\"153811981\",\"name\":\"Wenming Zheng\"},{\"authorId\":\"2397257\",\"name\":\"Chuangao Tang\"},{\"authorId\":\"1382744618\",\"name\":\"Wanchuang Xia\"},{\"authorId\":\"102517285\",\"name\":\"Cheng Lu\"},{\"authorId\":\"1390977843\",\"name\":\"Jiateng Liu\"}],\"doi\":\"10.1145/3394171.3413620\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"061d69640ba6b544bbdfa8fa4637fa867fb42d2d\",\"title\":\"DFEW: A Large-Scale Database for Recognizing Dynamic Facial Expressions in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/061d69640ba6b544bbdfa8fa4637fa867fb42d2d\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9024867\",\"name\":\"Jongkwang Hong\"},{\"authorId\":\"70374238\",\"name\":\"Bora Cho\"},{\"authorId\":\"49058762\",\"name\":\"Yongwon Hong\"},{\"authorId\":\"144036125\",\"name\":\"H. Byun\"}],\"doi\":\"10.3390/s19061382\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"17d77c03c2b552f2046e8c4674db64a3ef9b915b\",\"title\":\"Contextual Action Cues from Camera Sensor for Multi-Stream Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/17d77c03c2b552f2046e8c4674db64a3ef9b915b\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49010385\",\"name\":\"Yuan Jing\"},{\"authorId\":\"1384219309\",\"name\":\"Jinshan Hao\"},{\"authorId\":\"143666997\",\"name\":\"P. Li\"}],\"doi\":\"10.1109/ACCESS.2019.2946870\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c4d47dfb02ef1787d51a8eab65969a4e18d70920\",\"title\":\"Learning Spatiotemporal Features of CSI for Indoor Localization With Dual-Stream 3D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/c4d47dfb02ef1787d51a8eab65969a4e18d70920\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2014145\",\"name\":\"Mohammad Tavakolian\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"46606565\",\"name\":\"A. Hadid\"}],\"doi\":\"10.1109/ICCV.2019.00811\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"acd1e0773799658a4481693220f38157f204f9bf\",\"title\":\"AWSD: Adaptive Weighted Spatiotemporal Distillation for Video Representation\",\"url\":\"https://www.semanticscholar.org/paper/acd1e0773799658a4481693220f38157f204f9bf\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":\"10.1109/ICCVW.2019.00183\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"718418a88461c44a77bc4c0a1bdc9f3e6434fbab\",\"title\":\"Recurrent Convolutions for Causal 3D CNNs\",\"url\":\"https://www.semanticscholar.org/paper/718418a88461c44a77bc4c0a1bdc9f3e6434fbab\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1908.09550\",\"authors\":[{\"authorId\":\"49890660\",\"name\":\"Yiheng Zhang\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"1800425\",\"name\":\"Jingen Liu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"122914212\",\"name\":\"Dong Liu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2019.01191\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f8c551e3b51aeec4013e2b82d9cc97affd02972a\",\"title\":\"Customizable Architecture Search for Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/f8c551e3b51aeec4013e2b82d9cc97affd02972a\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1908.10136\",\"authors\":[{\"authorId\":\"2659862\",\"name\":\"J. Zhang\"},{\"authorId\":\"38083193\",\"name\":\"F. Shen\"},{\"authorId\":\"1390532590\",\"name\":\"Xing Xu\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f0446862cbdf61974e039a85d349d7f7864f42c1\",\"title\":\"Cooperative Cross-Stream Network for Discriminative Action Representation\",\"url\":\"https://www.semanticscholar.org/paper/f0446862cbdf61974e039a85d349d7f7864f42c1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1393588876\",\"name\":\"Fei Han\"},{\"authorId\":\"49357069\",\"name\":\"Dejun Zhang\"},{\"authorId\":\"2846159\",\"name\":\"Yiqi Wu\"},{\"authorId\":\"117454237\",\"name\":\"Zirui Qiu\"},{\"authorId\":\"1562396274\",\"name\":\"Longyong Wu\"},{\"authorId\":\"49015700\",\"name\":\"W. Huang\"}],\"doi\":\"10.1007/978-981-15-3651-9_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d4fd6a090c2e098ff21e2b09015328c7c898035b\",\"title\":\"Human Action Recognition Based on Dual Correlation Network\",\"url\":\"https://www.semanticscholar.org/paper/d4fd6a090c2e098ff21e2b09015328c7c898035b\",\"venue\":\"ACPR Workshops\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49694933\",\"name\":\"Ziheng Guo\"},{\"authorId\":\"145906066\",\"name\":\"Yang Chen\"},{\"authorId\":\"47504563\",\"name\":\"W. Huang\"},{\"authorId\":null,\"name\":\"Junhao Zhang\"}],\"doi\":\"10.1007/978-3-030-30508-6_26\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c615e11e6480390eeb7cb0bf6761971fddeffa36\",\"title\":\"An Efficient 3D-NAS Method for Video-Based Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c615e11e6480390eeb7cb0bf6761971fddeffa36\",\"venue\":\"ICANN\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2004228925\",\"name\":\"Jinhao Duan\"},{\"authorId\":\"40463478\",\"name\":\"H. Xu\"},{\"authorId\":\"48030229\",\"name\":\"Xiaozhu Lin\"},{\"authorId\":\"2004346653\",\"name\":\"Shangchao Zhu\"},{\"authorId\":\"115394762\",\"name\":\"Y. Du\"}],\"doi\":\"10.1016/j.imavis.2020.103988\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"68e1892f95de0a982571c0c5df1c12c42364ee11\",\"title\":\"Multi-semantic long-range dependencies capturing for efficient video representation learning\",\"url\":\"https://www.semanticscholar.org/paper/68e1892f95de0a982571c0c5df1c12c42364ee11\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6146190\",\"name\":\"S. Li\"},{\"authorId\":\"47058844\",\"name\":\"Lin Zhang\"},{\"authorId\":\"2256493\",\"name\":\"Xiumin Diao\"}],\"doi\":\"10.1007/S10846-019-01049-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2eafdd1aa5aab7ec1b116e28a7d1ab3c44bb3f37\",\"title\":\"Deep-Learning-Based Human Intention Prediction Using RGB Images and Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/2eafdd1aa5aab7ec1b116e28a7d1ab3c44bb3f37\",\"venue\":\"J. Intell. Robotic Syst.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1772198\",\"name\":\"X. Wu\"},{\"authorId\":\"3307319\",\"name\":\"Qing-Ge Ji\"}],\"doi\":\"10.1145/3426826.3426836\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"64469e496132f3e25cdc5bfcfb3b7069c5e15ac4\",\"title\":\"Split and Attentive-Aggregated Learnable Shift Module for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/64469e496132f3e25cdc5bfcfb3b7069c5e15ac4\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1901.09244\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":\"10.1109/ICCV.2019.00094\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8c05c3ec1cf5ca7865cd0e73dd688e94537d5f1a\",\"title\":\"DistInit: Learning Video Representations Without a Single Labeled Video\",\"url\":\"https://www.semanticscholar.org/paper/8c05c3ec1cf5ca7865cd0e73dd688e94537d5f1a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1704.00389\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1007/978-3-030-20893-6_23\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"47195627755d88121af2513646ac41eec8645fb7\",\"title\":\"Hidden Two-Stream Convolutional Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/47195627755d88121af2513646ac41eec8645fb7\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40465774\",\"name\":\"Z. Gao\"},{\"authorId\":\"2028829514\",\"name\":\"Leming Guo\"},{\"authorId\":\"15880069\",\"name\":\"W. Guan\"},{\"authorId\":\"143602033\",\"name\":\"Anan Liu\"},{\"authorId\":\"1744930\",\"name\":\"T. Ren\"},{\"authorId\":\"1788427\",\"name\":\"Shengyong Chen\"}],\"doi\":\"10.1109/TIP.2020.3038372\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6648479157216bee1f31ef9718fcb64eeafa6843\",\"title\":\"A Pairwise Attentive Adversarial Spatiotemporal Network for Cross-Domain Few-Shot Action Recognition-R2\",\"url\":\"https://www.semanticscholar.org/paper/6648479157216bee1f31ef9718fcb64eeafa6843\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2021},{\"arxivId\":\"1812.03982\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"2681569\",\"name\":\"Haoqi Fan\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"}],\"doi\":\"10.1109/ICCV.2019.00630\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8b47b9c3c35b2b2a78bff7822605b3040f87d699\",\"title\":\"SlowFast Networks for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b47b9c3c35b2b2a78bff7822605b3040f87d699\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2008.13705\",\"authors\":[{\"authorId\":\"34779291\",\"name\":\"Fuchen Long\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"40434674\",\"name\":\"X. Tian\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"},{\"authorId\":\"1490772804\",\"name\":\"Tao Mei\"}],\"doi\":\"10.1007/978-3-030-58580-8_9\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"2ae9cea622f68e1e32b7e6ae5a3c92213e192bf8\",\"title\":\"Learning to Localize Actions from Moments\",\"url\":\"https://www.semanticscholar.org/paper/2ae9cea622f68e1e32b7e6ae5a3c92213e192bf8\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51496700\",\"name\":\"Shuosen Guan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d4a8c77140ca02504c67007685c3acb1fceedb5d\",\"title\":\"SYSU iSEE submission to Moments in Time Challenge 2018\",\"url\":\"https://www.semanticscholar.org/paper/d4a8c77140ca02504c67007685c3acb1fceedb5d\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40471656\",\"name\":\"Dong Li\"},{\"authorId\":\"145690246\",\"name\":\"T. Yao\"},{\"authorId\":\"7667912\",\"name\":\"L. Duan\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/TMM.2018.2862341\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"0d8d0ce66eb661fbf12a04130dd7d51454f1f196\",\"title\":\"Unified Spatio-Temporal Attention Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/0d8d0ce66eb661fbf12a04130dd7d51454f1f196\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"04a82bb033a713ae88f2e3e2306822272c30ddd9\",\"title\":\"Video representation learning with deep neural networks\",\"url\":\"https://www.semanticscholar.org/paper/04a82bb033a713ae88f2e3e2306822272c30ddd9\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71003925\",\"name\":\"Jusong Li\"},{\"authorId\":\"6820648\",\"name\":\"Xianglong Liu\"},{\"authorId\":\"1384523745\",\"name\":\"Jun Xiao\"},{\"authorId\":\"9100047\",\"name\":\"Hainan Li\"},{\"authorId\":\"1390900682\",\"name\":\"S. Wang\"},{\"authorId\":null,\"name\":\"Liang Liu\"}],\"doi\":\"10.1109/ICDMW.2019.00098\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7fc246181ac6c8b1eb9cb138dd34d35b7dde1a74\",\"title\":\"Dynamic Spatio-Temporal Feature Learning via Graph Convolution in 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/7fc246181ac6c8b1eb9cb138dd34d35b7dde1a74\",\"venue\":\"2019 International Conference on Data Mining Workshops (ICDMW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"632909a8b314a186af98d88d4f058b6ed73d3afd\",\"title\":\"Deep Spatio-temporal Convolutional Long-short Memory Network\",\"url\":\"https://www.semanticscholar.org/paper/632909a8b314a186af98d88d4f058b6ed73d3afd\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2302223\",\"name\":\"Manolis Vasileiadis\"},{\"authorId\":\"4408876\",\"name\":\"C. Bouganis\"},{\"authorId\":\"15784009\",\"name\":\"G. Stavropoulos\"},{\"authorId\":\"143636644\",\"name\":\"D. Tzovaras\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"24db2c29d4a1b2b4130ff2123816873ed6b90a4e\",\"title\":\"Optimising 3D-CNN Design towards Human Pose Estimation on Low Power Devices\",\"url\":\"https://www.semanticscholar.org/paper/24db2c29d4a1b2b4130ff2123816873ed6b90a4e\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49455479\",\"name\":\"Y. Zhou\"},{\"authorId\":\"6485172\",\"name\":\"Xiaoyan Sun\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"}],\"doi\":\"10.1109/CVPR.2018.00054\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b85b79d0535da7e994e419a75f65b2758bf90f21\",\"title\":\"MiCT: Mixed 3D/2D Convolutional Tube for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b85b79d0535da7e994e419a75f65b2758bf90f21\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46895558\",\"name\":\"W. Song\"},{\"authorId\":\"38763335\",\"name\":\"Xinguo Yu\"}],\"doi\":\"10.1007/978-3-030-34879-3_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6dd4965e33dbb9acbe22dd77bb9a7200b7b30134\",\"title\":\"Double Channel 3D Convolutional Neural Network for Exam Scene Classification of Invigilation Videos\",\"url\":\"https://www.semanticscholar.org/paper/6dd4965e33dbb9acbe22dd77bb9a7200b7b30134\",\"venue\":\"PSIVT\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1519286259\",\"name\":\"JianYu Wang\"},{\"authorId\":\"51235164\",\"name\":\"Jianxin Chen\"},{\"authorId\":\"1768588917\",\"name\":\"Yihao Cai\"}],\"doi\":\"10.1117/12.2574424\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d279c051e5884041e66e1c5411415d74081effa3\",\"title\":\"A framework for multimodal sign language recognition under small sample based on key-frame sampling\",\"url\":\"https://www.semanticscholar.org/paper/d279c051e5884041e66e1c5411415d74081effa3\",\"venue\":\"International Workshop on Pattern Recognition\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"15249710\",\"name\":\"Hong-xia Xie\"},{\"authorId\":\"1388566371\",\"name\":\"Ling Lo\"},{\"authorId\":\"2426757\",\"name\":\"Hong-Han Shuai\"},{\"authorId\":\"1711298\",\"name\":\"W. Cheng\"}],\"doi\":\"10.1145/3394171.3414012\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"575e7b9108552381992653aecb214cd5a3a72f15\",\"title\":\"AU-assisted Graph Attention Convolutional Network for Micro-Expression Recognition\",\"url\":\"https://www.semanticscholar.org/paper/575e7b9108552381992653aecb214cd5a3a72f15\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9304398\",\"name\":\"Jiawei Zuo\"},{\"authorId\":\"16098412\",\"name\":\"Y. Chen\"},{\"authorId\":\"40476136\",\"name\":\"L. Wang\"},{\"authorId\":\"51018452\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"1917497790\",\"name\":\"Ting Yao\"},{\"authorId\":\"78646416\",\"name\":\"K. Wang\"},{\"authorId\":\"153040576\",\"name\":\"T. Mei\"}],\"doi\":\"10.1145/3394171.3414453\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"506381a1079874281f895b3a4ffeaa59cdf6c57d\",\"title\":\"iDirector: An Intelligent Directing System for Live Broadcast\",\"url\":\"https://www.semanticscholar.org/paper/506381a1079874281f895b3a4ffeaa59cdf6c57d\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1811.08383\",\"authors\":[{\"authorId\":\"46698300\",\"name\":\"Ji Lin\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"143840275\",\"name\":\"Song Han\"}],\"doi\":\"10.1109/ICCV.2019.00718\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4bbfd46721c145852e443ae4aad35148b814bf91\",\"title\":\"TSM: Temporal Shift Module for Efficient Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/4bbfd46721c145852e443ae4aad35148b814bf91\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1909.09300\",\"authors\":[{\"authorId\":\"3928052\",\"name\":\"T. Li\"},{\"authorId\":\"2548303\",\"name\":\"Lijie Fan\"},{\"authorId\":\"2931940\",\"name\":\"M. Zhao\"},{\"authorId\":\"51149370\",\"name\":\"Yingcheng Liu\"},{\"authorId\":\"1785714\",\"name\":\"D. Katabi\"}],\"doi\":\"10.1109/ICCV.2019.00096\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"02ec4b311978f8a16ae4ecd232e2464c08e59d84\",\"title\":\"Making the Invisible Visible: Action Recognition Through Walls and Occlusions\",\"url\":\"https://www.semanticscholar.org/paper/02ec4b311978f8a16ae4ecd232e2464c08e59d84\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2008.13759\",\"authors\":[{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"67968b5b59b08ea1dd8a1266b422ee38e3ca8ad5\",\"title\":\"Online Spatiotemporal Action Detection and Prediction via Causal Representations\",\"url\":\"https://www.semanticscholar.org/paper/67968b5b59b08ea1dd8a1266b422ee38e3ca8ad5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1907.05640\",\"authors\":[{\"authorId\":\"2014145\",\"name\":\"Mohammad Tavakolian\"},{\"authorId\":\"2884918\",\"name\":\"M. Sabokrou\"},{\"authorId\":\"144979251\",\"name\":\"A. Hadid\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1bd2c92ff77126f7352b32d3b00f998f15bfdf07\",\"title\":\"AVD: Adversarial Video Distillation\",\"url\":\"https://www.semanticscholar.org/paper/1bd2c92ff77126f7352b32d3b00f998f15bfdf07\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"28969692\",\"name\":\"Junwu Weng\"},{\"authorId\":\"34608228\",\"name\":\"Xu-dong Jiang\"},{\"authorId\":\"3108302\",\"name\":\"Wei-Long Zheng\"},{\"authorId\":\"145078769\",\"name\":\"J. Yuan\"}],\"doi\":\"10.1109/TCSVT.2020.2976789\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"07f712eb18f2357e917f63692a8e9ab2ed9d279e\",\"title\":\"Early Action Recognition With Category Exclusion Using Policy-Based Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/07f712eb18f2357e917f63692a8e9ab2ed9d279e\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144018882\",\"name\":\"T. Liu\"},{\"authorId\":\"1400357285\",\"name\":\"Yun Tian\"},{\"authorId\":\"150311919\",\"name\":\"Shifeng Zhao\"},{\"authorId\":\"49445303\",\"name\":\"Xiaoying Huang\"},{\"authorId\":\"115986457\",\"name\":\"Yang Xu\"},{\"authorId\":\"9996009\",\"name\":\"Gaoyuan Jiang\"},{\"authorId\":\"49110624\",\"name\":\"Qingjun Wang\"}],\"doi\":\"10.1007/978-3-030-39074-7_25\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0b25cb8fc33dbe60b483b162f0554928b6cdf484\",\"title\":\"Pseudo-3D Network for Multi-sequence Cardiac MR Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/0b25cb8fc33dbe60b483b162f0554928b6cdf484\",\"venue\":\"STACOM@MICCAI\",\"year\":2019},{\"arxivId\":\"2012.08770\",\"authors\":[{\"authorId\":\"30996283\",\"name\":\"Shigong Zhang\"},{\"authorId\":\"1720735789\",\"name\":\"Jincheng Xu\"},{\"authorId\":\"49070146\",\"name\":\"Y. Chen\"},{\"authorId\":\"47792543\",\"name\":\"Jiechao Ma\"},{\"authorId\":\"1390752638\",\"name\":\"Zihao Li\"},{\"authorId\":null,\"name\":\"Yizhou Wang\"},{\"authorId\":\"66616425\",\"name\":\"Yizhou Yu\"}],\"doi\":\"10.1007/978-3-030-59719-1_53\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"c44b9d621c416b2aed483aa32dcb4dfb1143315e\",\"title\":\"Revisiting 3D Context Modeling with Supervised Pre-training for Universal Lesion Detection in CT Slices\",\"url\":\"https://www.semanticscholar.org/paper/c44b9d621c416b2aed483aa32dcb4dfb1143315e\",\"venue\":\"MICCAI\",\"year\":2020},{\"arxivId\":\"2011.13202\",\"authors\":[{\"authorId\":\"2029244883\",\"name\":\"Soroosh Poorgholi\"},{\"authorId\":\"50311569\",\"name\":\"O. Kayhan\"},{\"authorId\":\"1738975\",\"name\":\"J. C. V. Gemert\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5960bbc43b3fddde32a9f57f8821f7f978343de4\",\"title\":\"t-EVA: Time-Efficient t-SNE Video Annotation\",\"url\":\"https://www.semanticscholar.org/paper/5960bbc43b3fddde32a9f57f8821f7f978343de4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.08434\",\"authors\":[{\"authorId\":\"3471257\",\"name\":\"Xinqian Gu\"},{\"authorId\":\"120076009\",\"name\":\"H. Chang\"},{\"authorId\":\"1798982\",\"name\":\"Bingpeng Ma\"},{\"authorId\":\"1490939067\",\"name\":\"Hongkai Zhang\"},{\"authorId\":\"1710220\",\"name\":\"X. Chen\"}],\"doi\":\"10.1007/978-3-030-58536-5_14\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"468c12b1ff6a5c4f2630cdbaca214e6df0c935cc\",\"title\":\"Appearance-Preserving 3D Convolution for Video-based Person Re-identification\",\"url\":\"https://www.semanticscholar.org/paper/468c12b1ff6a5c4f2630cdbaca214e6df0c935cc\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"115512283\",\"name\":\"Yong Hu\"},{\"authorId\":\"4590286\",\"name\":\"Heyan Huang\"},{\"authorId\":\"1720731753\",\"name\":\"Anfan Chen\"},{\"authorId\":\"134880677\",\"name\":\"Xian-Ling Mao\"}],\"doi\":\"10.1007/978-3-030-60450-9_55\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ff6bf5223fca625e982f151448cb17ecd74db9cb\",\"title\":\"A Cross-Modal Classification Dataset on Social Network\",\"url\":\"https://www.semanticscholar.org/paper/ff6bf5223fca625e982f151448cb17ecd74db9cb\",\"venue\":\"NLPCC\",\"year\":2020},{\"arxivId\":\"1908.10049\",\"authors\":[{\"authorId\":\"47787021\",\"name\":\"J. Li\"},{\"authorId\":\"47179758\",\"name\":\"Shiliang Zhang\"},{\"authorId\":\"50592933\",\"name\":\"Tiejun Huang\"}],\"doi\":\"10.1109/TIP.2020.2972108\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a4ae54757da23ad0551308e5a5a314bc5a9515ff\",\"title\":\"Multi-Scale Temporal Cues Learning for Video Person Re-Identification\",\"url\":\"https://www.semanticscholar.org/paper/a4ae54757da23ad0551308e5a5a314bc5a9515ff\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1803.04831\",\"authors\":[{\"authorId\":\"12373810\",\"name\":\"S. Li\"},{\"authorId\":\"1685696\",\"name\":\"W. Li\"},{\"authorId\":\"87707893\",\"name\":\"C. Cook\"},{\"authorId\":\"143754862\",\"name\":\"C. Zhu\"},{\"authorId\":\"35061196\",\"name\":\"Y. Gao\"}],\"doi\":\"10.1109/CVPR.2018.00572\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"565ab57eede8bf6ef9c42df51216b9f85287c234\",\"title\":\"Independently Recurrent Neural Network (IndRNN): Building A Longer and Deeper RNN\",\"url\":\"https://www.semanticscholar.org/paper/565ab57eede8bf6ef9c42df51216b9f85287c234\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1912.11872\",\"authors\":[{\"authorId\":\"153040576\",\"name\":\"T. Mei\"},{\"authorId\":\"101586660\",\"name\":\"W. Zhang\"},{\"authorId\":\"48577275\",\"name\":\"Ting Yao\"}],\"doi\":\"10.1017/ATSIP.2020.10\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3ba3e7970fac892ed3079d570ef019fa0940fec2\",\"title\":\"Vision and Language: from Visual Perception to Content Creation\",\"url\":\"https://www.semanticscholar.org/paper/3ba3e7970fac892ed3079d570ef019fa0940fec2\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1596808016\",\"name\":\"Xiaohan Wang\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"50118837\",\"name\":\"Y. Wu\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1109/tpami.2020.3015894\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7401d3895e1cb78c34fa25db12409fdff56b1661\",\"title\":\"Symbiotic Attention for Egocentric Action Recognition with Object-centric Alignment.\",\"url\":\"https://www.semanticscholar.org/paper/7401d3895e1cb78c34fa25db12409fdff56b1661\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47781560\",\"name\":\"Z. Liu\"},{\"authorId\":\"66454724\",\"name\":\"Zeya Li\"},{\"authorId\":\"150238936\",\"name\":\"Ming Zong\"},{\"authorId\":\"29790429\",\"name\":\"Wanting Ji\"},{\"authorId\":\"49908315\",\"name\":\"Ruili Wang\"},{\"authorId\":\"152714157\",\"name\":\"Y. Tian\"}],\"doi\":\"10.1007/978-981-15-3651-9_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9de826c60e7258e2a69b74836213fec465ef2601\",\"title\":\"Spatiotemporal Saliency Based Multi-stream Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9de826c60e7258e2a69b74836213fec465ef2601\",\"venue\":\"ACPR Workshops\",\"year\":2019},{\"arxivId\":\"1904.03498\",\"authors\":[{\"authorId\":\"39440469\",\"name\":\"Sudhakar Kumawat\"},{\"authorId\":\"145853779\",\"name\":\"S. Raman\"}],\"doi\":\"10.1109/CVPR.2019.00504\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"75544f83d38ef1686d70c763deb43305c5dc8a48\",\"title\":\"LP-3DCNN: Unveiling Local Phase in 3D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/75544f83d38ef1686d70c763deb43305c5dc8a48\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46651287\",\"name\":\"C. Li\"},{\"authorId\":\"153317948\",\"name\":\"Shaobo Lin\"},{\"authorId\":\"150048347\",\"name\":\"B. Wang\"},{\"authorId\":\"47058944\",\"name\":\"L. Zhang\"},{\"authorId\":\"143863244\",\"name\":\"Xian-Sheng Hua\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4d607aeef85b2fc0b66d7b58da442bd4b4551ded\",\"title\":\"Alibaba-AIC : Submission to Multi-Moments in Time Challenge 2019 \\u2217\",\"url\":\"https://www.semanticscholar.org/paper/4d607aeef85b2fc0b66d7b58da442bd4b4551ded\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"79755154\",\"name\":\"Hongje Seong\"},{\"authorId\":\"2246939\",\"name\":\"Junhyuk Hyun\"},{\"authorId\":\"70400973\",\"name\":\"Euntai Kim\"}],\"doi\":\"10.1109/ICCVW.2019.00194\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0be0313db9a4fd54a2e3a4f427772498a1419db8\",\"title\":\"Video Multitask Transformer Network\",\"url\":\"https://www.semanticscholar.org/paper/0be0313db9a4fd54a2e3a4f427772498a1419db8\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50706692\",\"name\":\"Le Lu\"},{\"authorId\":\"2026596\",\"name\":\"Xiaosong Wang\"},{\"authorId\":\"50453737\",\"name\":\"Gustavo Carneiro\"},{\"authorId\":\"95057768\",\"name\":\"L. Yang\"}],\"doi\":\"10.1007/978-3-030-13969-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5c5f44c7c7ca139a5ff7a7c5f6456620834c29db\",\"title\":\"Deep Learning and Convolutional Neural Networks for Medical Imaging and Clinical Informatics\",\"url\":\"https://www.semanticscholar.org/paper/5c5f44c7c7ca139a5ff7a7c5f6456620834c29db\",\"venue\":\"Advances in Computer Vision and Pattern Recognition\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1989829\",\"name\":\"Yunkai Li\"},{\"authorId\":\"1765822\",\"name\":\"Ziyao Xu\"},{\"authorId\":\"145742724\",\"name\":\"Q. Wu\"},{\"authorId\":\"144149888\",\"name\":\"Y. Cao\"},{\"authorId\":\"50202110\",\"name\":\"Shiwei Zhang\"},{\"authorId\":\"144741081\",\"name\":\"L. Song\"},{\"authorId\":\"38706634\",\"name\":\"Jianwen Jiang\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"145844907\",\"name\":\"Gang Yu\"},{\"authorId\":\"48935207\",\"name\":\"C. Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b0bf1be8731c60b2caf3a27f1e95b73875c4220b\",\"title\":\"Submission to Moments in Time Challenge 2018\",\"url\":\"https://www.semanticscholar.org/paper/b0bf1be8731c60b2caf3a27f1e95b73875c4220b\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27648874\",\"name\":\"Changmao Cheng\"},{\"authorId\":\"2832147\",\"name\":\"C. Zhang\"},{\"authorId\":\"1732264\",\"name\":\"Y. Wei\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1145/3343031.3351054\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"9f18e562481538493d71d7b36eb12270f03d6339\",\"title\":\"Sparse Temporal Causal Convolution for Efficient Action Modeling\",\"url\":\"https://www.semanticscholar.org/paper/9f18e562481538493d71d7b36eb12270f03d6339\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1904.11492\",\"authors\":[{\"authorId\":\"1696087\",\"name\":\"Yue Cao\"},{\"authorId\":\"7169566\",\"name\":\"J. Xu\"},{\"authorId\":\"145676588\",\"name\":\"Stephen Lin\"},{\"authorId\":\"2480483\",\"name\":\"Fangyun Wei\"},{\"authorId\":\"1805197\",\"name\":\"H. Hu\"}],\"doi\":\"10.1109/ICCVW.2019.00246\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"66143960c0325c70329a3869cc8052f0416b87aa\",\"title\":\"GCNet: Non-Local Networks Meet Squeeze-Excitation Networks and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/66143960c0325c70329a3869cc8052f0416b87aa\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1804.06057\",\"authors\":[{\"authorId\":\"3401864\",\"name\":\"Ryota Hinami\"},{\"authorId\":\"1915796\",\"name\":\"Junwei Liang\"},{\"authorId\":\"1700567\",\"name\":\"Shin'ichi Satoh\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"81f63e7344cc242416e37d791f7eb83ec2c07681\",\"title\":\"Multimodal Co-Training for Selecting Good Examples from Webly Labeled Video\",\"url\":\"https://www.semanticscholar.org/paper/81f63e7344cc242416e37d791f7eb83ec2c07681\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51202149\",\"name\":\"Menglin Wang\"},{\"authorId\":\"35884242\",\"name\":\"Y. Zhu\"},{\"authorId\":\"13223807\",\"name\":\"Z. Sun\"},{\"authorId\":\"3748616\",\"name\":\"Zihao Cao\"},{\"authorId\":\"39790137\",\"name\":\"Peng Xiong\"},{\"authorId\":\"145473087\",\"name\":\"Y. Zheng\"},{\"authorId\":\"22686210\",\"name\":\"Shijin Song\"}],\"doi\":\"10.1109/ICCCBDA.2019.8725621\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0c8516ce328d55086dcdc3e20f49f33a882ffd5d\",\"title\":\"Abnormal Behavior Detection of ATM Surveillance Videos Based on Pseudo-3D Residual Network\",\"url\":\"https://www.semanticscholar.org/paper/0c8516ce328d55086dcdc3e20f49f33a882ffd5d\",\"venue\":\"2019 IEEE 4th International Conference on Cloud Computing and Big Data Analysis (ICCCBDA)\",\"year\":2019},{\"arxivId\":\"1712.00636\",\"authors\":[{\"authorId\":\"2978413\",\"name\":\"Chao-Yuan Wu\"},{\"authorId\":\"1771307\",\"name\":\"M. Zaheer\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"1758550\",\"name\":\"R. Manmatha\"},{\"authorId\":\"46234526\",\"name\":\"Alex Smola\"},{\"authorId\":\"2562966\",\"name\":\"Philipp Kr\\u00e4henb\\u00fchl\"}],\"doi\":\"10.1109/CVPR.2018.00631\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d98a956aadaff727e495b14b7c532d40ea49e16\",\"title\":\"Compressed Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9d98a956aadaff727e495b14b7c532d40ea49e16\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2002.12096\",\"authors\":[{\"authorId\":\"32173804\",\"name\":\"Hiteshi Jain\"},{\"authorId\":\"1491172147\",\"name\":\"Gaurav Harit\"},{\"authorId\":\"89583233\",\"name\":\"A. Sharma\"}],\"doi\":\"10.1109/tcsvt.2020.3017727\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"048a58973dbaca3e310dd87133e38969d57ab51b\",\"title\":\"Action Quality Assessment using Siamese Network-Based Deep Metric Learning\",\"url\":\"https://www.semanticscholar.org/paper/048a58973dbaca3e310dd87133e38969d57ab51b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.03152\",\"authors\":[{\"authorId\":\"47968272\",\"name\":\"Li-Yu Daisy Liu\"},{\"authorId\":\"1491094850\",\"name\":\"Tao Wang\"},{\"authorId\":\"49723003\",\"name\":\"J. Liu\"},{\"authorId\":\"50463545\",\"name\":\"Yang Guan\"},{\"authorId\":\"9963055\",\"name\":\"Qi Bu\"},{\"authorId\":\"49576139\",\"name\":\"Longfei Yang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9f0320cd101ed6426a4330ecb395015c266e976c\",\"title\":\"CTM: Collaborative Temporal Modeling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9f0320cd101ed6426a4330ecb395015c266e976c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50341802\",\"name\":\"S. Li\"},{\"authorId\":\"87046280\",\"name\":\"H. Yang\"},{\"authorId\":\"1560347965\",\"name\":\"Jun Sun\"}],\"doi\":\"10.1109/ICIP40778.2020.9191071\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a4b39edaf6ca123705d2f77cba77753154a0a64\",\"title\":\"Multilevel Interaction Reasoning For Complex Event Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8a4b39edaf6ca123705d2f77cba77753154a0a64\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"2011.06958\",\"authors\":[{\"authorId\":\"1632971845\",\"name\":\"Guillaume Vaudaux-Ruth\"},{\"authorId\":\"1403862742\",\"name\":\"Adrien Chan-Hon-Tong\"},{\"authorId\":\"1787641\",\"name\":\"C. Achard\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4545cdb909f2be23ce6542defef6091912729648\",\"title\":\"SALAD: Self-Assessment Learning for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/4545cdb909f2be23ce6542defef6091912729648\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40214720\",\"name\":\"L. Long\"},{\"authorId\":\"5278544\",\"name\":\"Z. V. Johnson\"},{\"authorId\":\"1600243424\",\"name\":\"Junyu Li\"},{\"authorId\":\"1600853953\",\"name\":\"Tucker J Lancaster\"},{\"authorId\":\"1601570335\",\"name\":\"Vineeth Aljapur\"},{\"authorId\":\"145914793\",\"name\":\"J. T. Streelman\"},{\"authorId\":\"4984693\",\"name\":\"P. T. McGrath\"}],\"doi\":\"10.1016/j.isci.2020.101591\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2da83837d144ff1060c2e7bf030496284d874ddc\",\"title\":\"Automatic Classification of Cichlid Behaviors Using 3D Convolutional Residual Networks\",\"url\":\"https://www.semanticscholar.org/paper/2da83837d144ff1060c2e7bf030496284d874ddc\",\"venue\":\"iScience\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48380268\",\"name\":\"Y. Zhang\"},{\"authorId\":\"50997033\",\"name\":\"Mengxing Ouyang\"},{\"authorId\":\"47655995\",\"name\":\"A. Ray\"},{\"authorId\":\"9262259\",\"name\":\"Tairan Liu\"},{\"authorId\":\"12668386\",\"name\":\"Janay E Kong\"},{\"authorId\":\"153759853\",\"name\":\"B. Bai\"},{\"authorId\":\"40183540\",\"name\":\"D. Kim\"},{\"authorId\":\"52138155\",\"name\":\"Alexander Guziak\"},{\"authorId\":\"152908460\",\"name\":\"Y. Luo\"},{\"authorId\":\"2479685\",\"name\":\"Alborz Feizi\"},{\"authorId\":\"47257369\",\"name\":\"K. Tsai\"},{\"authorId\":\"121359426\",\"name\":\"Zhuoran Duan\"},{\"authorId\":\"120281342\",\"name\":\"Xiaowei Liu\"},{\"authorId\":\"47181813\",\"name\":\"D. Kim\"},{\"authorId\":\"17061867\",\"name\":\"C. Cheung\"},{\"authorId\":\"52169888\",\"name\":\"Sener Yalcin\"},{\"authorId\":\"13459478\",\"name\":\"Hatice Ceylan Koydemir\"},{\"authorId\":\"4135344\",\"name\":\"O. Garner\"},{\"authorId\":\"1917433\",\"name\":\"D. Di Carlo\"},{\"authorId\":\"145701870\",\"name\":\"Aydogan Ozcan\"}],\"doi\":\"10.1038/s41377-019-0203-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e9dd9cbf6bb81b794d3c55c262155ec5731e899c\",\"title\":\"Computational cytometer based on magnetically modulated coherent imaging and deep learning\",\"url\":\"https://www.semanticscholar.org/paper/e9dd9cbf6bb81b794d3c55c262155ec5731e899c\",\"venue\":\"Light, science & applications\",\"year\":2019},{\"arxivId\":\"1705.02953\",\"authors\":[{\"authorId\":\"119770705\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"134339866\",\"name\":\"L. V. Van Gool\"}],\"doi\":\"10.1109/TPAMI.2018.2868668\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"37c970a2f27810987e2b47dd5b8e0cc9bb976a38\",\"title\":\"Temporal Segment Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/37c970a2f27810987e2b47dd5b8e0cc9bb976a38\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52454948\",\"name\":\"A. Verma\"},{\"authorId\":\"2903495\",\"name\":\"T. Meenpal\"},{\"authorId\":\"2456349\",\"name\":\"Bibhudendra Acharya\"}],\"doi\":\"10.1111/coin.12419\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3fa95ecd010ac58a0149c08c90965d78fca8d3b6\",\"title\":\"Multiperson interaction recognition in images: A body keypoint based feature image analysis\",\"url\":\"https://www.semanticscholar.org/paper/3fa95ecd010ac58a0149c08c90965d78fca8d3b6\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2005.05592\",\"authors\":[{\"authorId\":\"145764891\",\"name\":\"Bo Xu\"},{\"authorId\":\"102517285\",\"name\":\"Cheng Lu\"},{\"authorId\":\"49813886\",\"name\":\"Yandong Guo\"},{\"authorId\":\"2044516\",\"name\":\"J. Wang\"}],\"doi\":\"10.1109/CVPR42600.2020.01444\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1a75b57ecbc140553b4dc2ce2337ed78786da338\",\"title\":\"Discriminative Multi-Modality Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1a75b57ecbc140553b4dc2ce2337ed78786da338\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2003.00197\",\"authors\":[{\"authorId\":\"29724362\",\"name\":\"Longlong Jing\"},{\"authorId\":\"1807477\",\"name\":\"T. Parag\"},{\"authorId\":\"152247556\",\"name\":\"Zhe Wu\"},{\"authorId\":\"8193125\",\"name\":\"Y. Tian\"},{\"authorId\":\"3254319\",\"name\":\"Hongcheng Wang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"637b413488ef5b72a3f04089ea3e3c635caab9ee\",\"title\":\"VideoSSL: Semi-Supervised Learning for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/637b413488ef5b72a3f04089ea3e3c635caab9ee\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1711.06354\",\"authors\":[{\"authorId\":\"7437104\",\"name\":\"Chih-Yao Ma\"},{\"authorId\":\"2293919\",\"name\":\"Asim Kadav\"},{\"authorId\":\"50162780\",\"name\":\"I. Melvin\"},{\"authorId\":\"145276578\",\"name\":\"Z. Kira\"},{\"authorId\":\"9202076\",\"name\":\"G. Al-Regib\"},{\"authorId\":\"1775043\",\"name\":\"H. Graf\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"28ee8af25582c9c3a04fa0f0809367d7ee936dca\",\"title\":\"Grounded Objects and Interactions for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/28ee8af25582c9c3a04fa0f0809367d7ee936dca\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"2012.08804\",\"authors\":[{\"authorId\":\"46276098\",\"name\":\"Jianan Li\"},{\"authorId\":\"49419064\",\"name\":\"Xuemei Xie\"},{\"authorId\":\"32273141\",\"name\":\"Z. Zhao\"},{\"authorId\":\"1840060274\",\"name\":\"Yuhan Cao\"},{\"authorId\":\"1491642326\",\"name\":\"Qingzhe Pan\"},{\"authorId\":\"35367337\",\"name\":\"Guangming Shi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"700233fa6e243a056e4243f89b2f32b2cdcc86b9\",\"title\":\"Temporal Graph Modeling for Skeleton-based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/700233fa6e243a056e4243f89b2f32b2cdcc86b9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2101.00468\",\"authors\":[{\"authorId\":null,\"name\":\"Alina Roitberg\"},{\"authorId\":null,\"name\":\"Monica Haurilet\"},{\"authorId\":\"1663261712\",\"name\":\"M. Mart\\u00ednez\"},{\"authorId\":null,\"name\":\"Rainer Stiefelhagen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"558038947f541eaed14d6e0258a5ad9294070bf8\",\"title\":\"Uncertainty-sensitive Activity Recognition: a Reliability Benchmark and the CARING Models\",\"url\":\"https://www.semanticscholar.org/paper/558038947f541eaed14d6e0258a5ad9294070bf8\",\"venue\":\"\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49417387\",\"name\":\"Y. Wang\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"}],\"doi\":\"10.1109/ICMEW.2018.8551536\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"48994f8671d2a3bdff929eefd6086cb8f2f2c4d0\",\"title\":\"Enhanced Action Recognition With Visual Attribute-Augmented 3D Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/48994f8671d2a3bdff929eefd6086cb8f2f2c4d0\",\"venue\":\"2018 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2018},{\"arxivId\":\"1806.11230\",\"authors\":[{\"authorId\":\"145873652\",\"name\":\"Y. Kong\"},{\"authorId\":\"46956675\",\"name\":\"Yun Fu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"025a44bf059aef8b9ee2e6ca598bebefc59a4a61\",\"title\":\"Human Action Recognition and Prediction: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/025a44bf059aef8b9ee2e6ca598bebefc59a4a61\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1384279038\",\"name\":\"Shenqiang Yuan\"},{\"authorId\":\"46728598\",\"name\":\"Xue Mei\"},{\"authorId\":\"46968435\",\"name\":\"Yi He\"},{\"authorId\":\"48180876\",\"name\":\"Jin Zhang\"}],\"doi\":\"10.1007/978-3-030-36189-1_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f05fa8951324b2f603360a845a610d2596d60aa4\",\"title\":\"Soft Transferring and Progressive Learning for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f05fa8951324b2f603360a845a610d2596d60aa4\",\"venue\":\"IScIDE\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145359181\",\"name\":\"Yang Yi\"},{\"authorId\":\"145688138\",\"name\":\"Feng Ni\"},{\"authorId\":\"15470287\",\"name\":\"Yuexin Ma\"},{\"authorId\":\"22689408\",\"name\":\"Xinge Zhu\"},{\"authorId\":\"35653798\",\"name\":\"Yuankai Qi\"},{\"authorId\":\"51177968\",\"name\":\"Riming Qiu\"},{\"authorId\":\"2946035\",\"name\":\"Shijie Zhao\"},{\"authorId\":\"143806294\",\"name\":\"Feng Li\"},{\"authorId\":null,\"name\":\"Yongtao Wang\"}],\"doi\":\"10.24963/ijcai.2019/141\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"40060755a791a85a6b9c61bd0f5d859b3a3417a6\",\"title\":\"High Performance Gesture Recognition via Effective and Efficient Temporal Modeling\",\"url\":\"https://www.semanticscholar.org/paper/40060755a791a85a6b9c61bd0f5d859b3a3417a6\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"2009.14639\",\"authors\":[{\"authorId\":\"1976000468\",\"name\":\"Okan Kopuklu\"},{\"authorId\":\"114991183\",\"name\":\"Stefan Hormann\"},{\"authorId\":\"32240536\",\"name\":\"Fabian Herzog\"},{\"authorId\":\"2277308\",\"name\":\"Hakan Cevikalp\"},{\"authorId\":\"46343645\",\"name\":\"G. Rigoll\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d197d0ab852c20122ffb1833fb29199ca77ce9bb\",\"title\":\"Dissected 3D CNNs: Temporal Skip Connections for Efficient Online Video Processing\",\"url\":\"https://www.semanticscholar.org/paper/d197d0ab852c20122ffb1833fb29199ca77ce9bb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47930257\",\"name\":\"R. S. C. Oliveira\"}],\"doi\":\"10.25911/5dfc956bbd86c\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"388212b4fbc19e6a685eb929f35a7e1c3c06f814\",\"title\":\"Visual Recognition From Structured Supervision\",\"url\":\"https://www.semanticscholar.org/paper/388212b4fbc19e6a685eb929f35a7e1c3c06f814\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49597328\",\"name\":\"J. Xia\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aaa5e03a926af11472a6c47dcbfe3941a0f2004b\",\"title\":\"Weakly Supervised EM Process For Temporal Localization Within Video\",\"url\":\"https://www.semanticscholar.org/paper/aaa5e03a926af11472a6c47dcbfe3941a0f2004b\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51181811\",\"name\":\"J. Zhang\"},{\"authorId\":\"47779342\",\"name\":\"Yutong Xie\"},{\"authorId\":\"48754192\",\"name\":\"Pingping Zhang\"},{\"authorId\":null,\"name\":\"Hao Chen\"},{\"authorId\":\"49289855\",\"name\":\"Y. Xia\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"}],\"doi\":\"10.24963/ijcai.2019/593\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f07486a42470219d8e08e764a9c988e5eeea7622\",\"title\":\"Light-Weight Hybrid Convolutional Network for Liver Tumor Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/f07486a42470219d8e08e764a9c988e5eeea7622\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"2002.07442\",\"authors\":[{\"authorId\":\"50202365\",\"name\":\"S. Zhang\"},{\"authorId\":\"153098982\",\"name\":\"Sheng Guo\"},{\"authorId\":\"49015548\",\"name\":\"Weilin Huang\"},{\"authorId\":\"1915350\",\"name\":\"M. Scott\"},{\"authorId\":\"29461006\",\"name\":\"L. Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"df2f2591054080d069e563cb9ca4e0592bc6df08\",\"title\":\"V4D: 4D Convolutional Neural Networks for Video-level Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/df2f2591054080d069e563cb9ca4e0592bc6df08\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145182602\",\"name\":\"Dong Li\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"144954807\",\"name\":\"Q. Dai\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1007/978-3-030-01231-1_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b6d977251b551471f5dddfb0a2e8f9c542e684d2\",\"title\":\"Recurrent Tubelet Proposal and Recognition Networks for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/b6d977251b551471f5dddfb0a2e8f9c542e684d2\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"1706673\",\"name\":\"C. Zhang\"}],\"doi\":\"10.1145/3123266.3130141\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dac85b9bc9313e1d6ed01234b6d3e4bdbcd47999\",\"title\":\"Deep Learning for Intelligent Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/dac85b9bc9313e1d6ed01234b6d3e4bdbcd47999\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40354734\",\"name\":\"Haoze Wu\"},{\"authorId\":\"48210950\",\"name\":\"Jiawei Liu\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"},{\"authorId\":\"6485172\",\"name\":\"Xiaoyan Sun\"}],\"doi\":\"10.24963/ijcai.2019/136\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"21526c9cb9ba45e4748fb9a967f51c9bd9c0bf16\",\"title\":\"Mutually Reinforced Spatio-Temporal Convolutional Tube for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/21526c9cb9ba45e4748fb9a967f51c9bd9c0bf16\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49050918\",\"name\":\"J. Zhang\"},{\"authorId\":\"37403439\",\"name\":\"H. Hu\"},{\"authorId\":\"150344317\",\"name\":\"Xinlong Lu\"}],\"doi\":\"10.1145/3321511\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"51738887bb680cc01bdd40fed98442c1b0b226cb\",\"title\":\"Moving Foreground-Aware Visual Attention and Key Volume Mining for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/51738887bb680cc01bdd40fed98442c1b0b226cb\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":\"1903.09102\",\"authors\":[{\"authorId\":\"39576371\",\"name\":\"A. Manglik\"},{\"authorId\":\"7885067\",\"name\":\"Xinshuo Weng\"},{\"authorId\":\"1401940506\",\"name\":\"Eshed Ohn-Bar\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"11e677e2721f0196c7ab93d15cc59047bfa3ff17\",\"title\":\"Future Near-Collision Prediction from Monocular Video: Feasibility, Dataset, and Challenges\",\"url\":\"https://www.semanticscholar.org/paper/11e677e2721f0196c7ab93d15cc59047bfa3ff17\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1832019\",\"name\":\"Fuhua Shang\"},{\"authorId\":\"145421603\",\"name\":\"Tao Han\"},{\"authorId\":\"152236895\",\"name\":\"Feng Tian\"},{\"authorId\":\"1884170385\",\"name\":\"Jun Tao\"},{\"authorId\":\"40465774\",\"name\":\"Z. Gao\"}],\"doi\":\"10.1109/ACCESS.2020.3014691\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1c93dfb167a90c2a5a7b802c629327224d4ee806\",\"title\":\"A Multimodal Pairwise Discrimination Network for Cross-Domain Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1c93dfb167a90c2a5a7b802c629327224d4ee806\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2011.10974\",\"authors\":[{\"authorId\":\"39431125\",\"name\":\"Shuyang Gu\"},{\"authorId\":\"9324504\",\"name\":\"Jian-min Bao\"},{\"authorId\":\"2013406166\",\"name\":\"Dong Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"906c0c47fea0842a6dc5d1301c916eae025a2d90\",\"title\":\"Learnable Sampling 3D Convolution for Video Enhancement and Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/906c0c47fea0842a6dc5d1301c916eae025a2d90\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3367790\",\"name\":\"Seong Jae Hwang\"},{\"authorId\":\"2119006\",\"name\":\"Joonseok Lee\"},{\"authorId\":\"2758088\",\"name\":\"B. Varadarajan\"},{\"authorId\":\"152894252\",\"name\":\"A. Gordon\"},{\"authorId\":\"144755346\",\"name\":\"Zheng Xu\"},{\"authorId\":\"1820908\",\"name\":\"A. Natsev\"}],\"doi\":\"10.1145/3292500.3330653\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f811e87c0e50dcd1e494be69afbd23f1fae73c5e\",\"title\":\"Large-Scale Training Framework for Video Annotation\",\"url\":\"https://www.semanticscholar.org/paper/f811e87c0e50dcd1e494be69afbd23f1fae73c5e\",\"venue\":\"KDD\",\"year\":2019},{\"arxivId\":\"1904.02811\",\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"}],\"doi\":\"10.1109/ICCV.2019.00565\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f4852f5385d60e8870e30db5c65392d120e58574\",\"title\":\"Video Classification With Channel-Separated Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/f4852f5385d60e8870e30db5c65392d120e58574\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47703700\",\"name\":\"Kun Hu\"},{\"authorId\":\"39532571\",\"name\":\"Zhiyong Wang\"},{\"authorId\":\"1745727\",\"name\":\"S. Mei\"},{\"authorId\":\"66155252\",\"name\":\"Kaylena A Ehgoetz Martens\"},{\"authorId\":\"145188375\",\"name\":\"Tingting Yao\"},{\"authorId\":\"144506986\",\"name\":\"S. Lewis\"},{\"authorId\":\"145855523\",\"name\":\"D. Feng\"}],\"doi\":\"10.1109/JBHI.2019.2923209\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf71cc460d0e857f5801410d10314f853380246d\",\"title\":\"Vision-Based Freezing of Gait Detection With Anatomic Directed Graph Representation\",\"url\":\"https://www.semanticscholar.org/paper/cf71cc460d0e857f5801410d10314f853380246d\",\"venue\":\"IEEE Journal of Biomedical and Health Informatics\",\"year\":2020},{\"arxivId\":\"2011.13322\",\"authors\":[{\"authorId\":\"1845783022\",\"name\":\"Zhen Huang\"},{\"authorId\":\"94123138\",\"name\":\"X. Shen\"},{\"authorId\":\"40434674\",\"name\":\"X. Tian\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"},{\"authorId\":\"50535670\",\"name\":\"Jian-qiang Huang\"},{\"authorId\":\"143863242\",\"name\":\"Xiansheng Hua\"}],\"doi\":\"10.1145/3394171.3413666\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"71918fb33871497f7c4722246e63e8beaaf588fa\",\"title\":\"Spatio-Temporal Inception Graph Convolutional Networks for Skeleton-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/71918fb33871497f7c4722246e63e8beaaf588fa\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144406781\",\"name\":\"Lijun He\"},{\"authorId\":\"2035803194\",\"name\":\"Shuai Wen\"},{\"authorId\":\"2199437\",\"name\":\"L. Wang\"},{\"authorId\":\"1825677658\",\"name\":\"Fan Li\"}],\"doi\":\"10.1007/s10489-020-01933-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb68cda0fdd2e9fec857ff8016b3a74912ceb57e\",\"title\":\"Vehicle theft recognition from surveillance video based on spatiotemporal attention\",\"url\":\"https://www.semanticscholar.org/paper/eb68cda0fdd2e9fec857ff8016b3a74912ceb57e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46276098\",\"name\":\"Jianan Li\"},{\"authorId\":\"49419064\",\"name\":\"Xuemei Xie\"},{\"authorId\":\"1491642326\",\"name\":\"Qingzhe Pan\"},{\"authorId\":\"122210974\",\"name\":\"Yu-Han Cao\"},{\"authorId\":\"32273141\",\"name\":\"Z. Zhao\"},{\"authorId\":\"35367337\",\"name\":\"Guangming Shi\"}],\"doi\":\"10.1016/j.patcog.2020.107356\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a6cd1d88ab7439d73d1163c2eca77ce7134c908f\",\"title\":\"SGM-Net: Skeleton-guided multimodal network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/a6cd1d88ab7439d73d1163c2eca77ce7134c908f\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143838039\",\"name\":\"J. Quiroga\"},{\"authorId\":\"1388438702\",\"name\":\"H. Carrillo\"},{\"authorId\":\"50424329\",\"name\":\"E. Maldonado\"},{\"authorId\":\"153833567\",\"name\":\"J. Ruiz\"},{\"authorId\":\"101207901\",\"name\":\"L. M. Zapata\"}],\"doi\":\"10.1109/CVPRW50498.2020.00455\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6957b1881a3ffad8fce745d0bc003ba117c01101\",\"title\":\"As Seen on TV: Automatic Basketball Video Production using Gaussian-based Actionness and Game States Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6957b1881a3ffad8fce745d0bc003ba117c01101\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"2007.09883\",\"authors\":[{\"authorId\":\"13099867\",\"name\":\"Haisheng Su\"},{\"authorId\":\"153285206\",\"name\":\"J. Feng\"},{\"authorId\":\"46798949\",\"name\":\"H. Shao\"},{\"authorId\":\"1768672172\",\"name\":\"Zhenyu Jiang\"},{\"authorId\":\"40951853\",\"name\":\"Manyuan Zhang\"},{\"authorId\":\"145717875\",\"name\":\"Wei Wu\"},{\"authorId\":\"30752055\",\"name\":\"Y. Liu\"},{\"authorId\":\"119885708\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3e7b4c49ad5754e9d7e9019684a777ae66ee5eed\",\"title\":\"Complementary Boundary Generator with Scale-Invariant Relation Modeling for Temporal Action Localization: Submission to ActivityNet Challenge 2020\",\"url\":\"https://www.semanticscholar.org/paper/3e7b4c49ad5754e9d7e9019684a777ae66ee5eed\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"1800425\",\"name\":\"Jingen Liu\"}],\"doi\":\"10.1145/3240508.3241474\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"93b8041a997b0c9ab79aa470b7c13615f9defa5d\",\"title\":\"Human Behavior Understanding: From Action Recognition to Complex Event Detection\",\"url\":\"https://www.semanticscholar.org/paper/93b8041a997b0c9ab79aa470b7c13615f9defa5d\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"2012.11866\",\"authors\":[{\"authorId\":\"2595189\",\"name\":\"Zehua Sun\"},{\"authorId\":\"120809631\",\"name\":\"Jiwang Liu\"},{\"authorId\":\"143969578\",\"name\":\"Qiuhong Ke\"},{\"authorId\":\"1877377\",\"name\":\"H. Rahmani\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"816236bf3219363bfe4b847363e137b1fe6712e7\",\"title\":\"Human Action Recognition from Various Data Modalities: A Review\",\"url\":\"https://www.semanticscholar.org/paper/816236bf3219363bfe4b847363e137b1fe6712e7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2001.05691\",\"authors\":[{\"authorId\":\"122460701\",\"name\":\"Tianhao Li\"},{\"authorId\":\"119770705\",\"name\":\"L. Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2783c13471060300e62a1eed458d9d2888b5b5be\",\"title\":\"Learning Spatiotemporal Features via Video and Text Pair Discrimination\",\"url\":\"https://www.semanticscholar.org/paper/2783c13471060300e62a1eed458d9d2888b5b5be\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993592720\",\"name\":\"Zhaobo Qi\"},{\"authorId\":\"47672591\",\"name\":\"Shuhui Wang\"},{\"authorId\":\"145422145\",\"name\":\"Chi Su\"},{\"authorId\":\"153142919\",\"name\":\"Li Su\"},{\"authorId\":\"46246550\",\"name\":\"W. Zhang\"},{\"authorId\":\"153159021\",\"name\":\"Qingming Huang\"}],\"doi\":\"10.1145/3394171.3413618\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1f26caf22fd05659802db690c7e6c9db289be340\",\"title\":\"Modeling Temporal Concept Receptive Field Dynamically for Untrimmed Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/1f26caf22fd05659802db690c7e6c9db289be340\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6873935\",\"name\":\"T. Lin\"},{\"authorId\":\"13099867\",\"name\":\"Haisheng Su\"},{\"authorId\":\"1758267\",\"name\":\"X. Zhao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"448c3a671ff66fd9184f2a8482dfbe223913035c\",\"title\":\"Boundary Sensitive Network : Submission to ActivityNet Challenge 2018\",\"url\":\"https://www.semanticscholar.org/paper/448c3a671ff66fd9184f2a8482dfbe223913035c\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151495731\",\"name\":\"Huaizheng Zhang\"},{\"authorId\":\"11453764\",\"name\":\"Linsen Dong\"},{\"authorId\":\"143853502\",\"name\":\"Guanyu Gao\"},{\"authorId\":\"100541102\",\"name\":\"H. Hu\"},{\"authorId\":\"145868453\",\"name\":\"Yonggang Wen\"},{\"authorId\":\"1800055\",\"name\":\"K. Guan\"}],\"doi\":\"10.1109/TMM.2020.2973828\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9edfd38396c10cabf7a0297261ec6446fc9088d0\",\"title\":\"DeepQoE: A Multimodal Learning Framework for Video Quality of Experience (QoE) Prediction\",\"url\":\"https://www.semanticscholar.org/paper/9edfd38396c10cabf7a0297261ec6446fc9088d0\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2802283\",\"name\":\"H. Liu\"},{\"authorId\":\"153108488\",\"name\":\"Bin Ren\"},{\"authorId\":\"47842072\",\"name\":\"M. Liu\"},{\"authorId\":\"2705961\",\"name\":\"R. Ding\"}],\"doi\":\"10.1109/ICIP40778.2020.9190958\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"93011a4d810eacfc4ff3202d3c38e78706ff3341\",\"title\":\"Grouped Temporal Enhancement Module for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/93011a4d810eacfc4ff3202d3c38e78706ff3341\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30904720\",\"name\":\"Sudipta Rudra\"},{\"authorId\":\"23551520\",\"name\":\"S. K. Thangavel\"}],\"doi\":\"10.1007/978-3-030-30465-2_79\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"438e6aa0184e9656a5a507770224e430837e752b\",\"title\":\"A Robust Q-Learning and Differential Evolution Based Policy Framework for Key Frame Extraction\",\"url\":\"https://www.semanticscholar.org/paper/438e6aa0184e9656a5a507770224e430837e752b\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145294961\",\"name\":\"L. Chi\"},{\"authorId\":\"9443552\",\"name\":\"G. Tian\"},{\"authorId\":\"145353089\",\"name\":\"Y. Mu\"},{\"authorId\":\"3041937\",\"name\":\"Lingxi Xie\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1145/3343031.3351029\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"933f2a39e35018db2442c08f7603a14a70efb06b\",\"title\":\"Fast Non-Local Neural Networks with Spectral Residual Learning\",\"url\":\"https://www.semanticscholar.org/paper/933f2a39e35018db2442c08f7603a14a70efb06b\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1394415540\",\"name\":\"Xiankun Pei\"},{\"authorId\":\"49319111\",\"name\":\"Dan Guo\"},{\"authorId\":\"97522088\",\"name\":\"Ye Zhao\"}],\"doi\":\"10.1145/3347319.3356837\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"91ef86ef55d7e70bdcc4e5ac20d798055f845736\",\"title\":\"Continuous Sign Language Recognition Based on Pseudo-supervised Learning\",\"url\":\"https://www.semanticscholar.org/paper/91ef86ef55d7e70bdcc4e5ac20d798055f845736\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1906.07016\",\"authors\":[{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"46515076\",\"name\":\"D. Li\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"48141156\",\"name\":\"Qi Cai\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"38791e8ca76e1bb44e7123ec92f97299d7d19d15\",\"title\":\"Trimmed Action Recognition, Dense-Captioning Events in Videos, and Spatio-temporal Action Localization with Focus on ActivityNet Challenge 2019\",\"url\":\"https://www.semanticscholar.org/paper/38791e8ca76e1bb44e7123ec92f97299d7d19d15\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1906.08547\",\"authors\":[{\"authorId\":\"34779291\",\"name\":\"Fuchen Long\"},{\"authorId\":\"48141156\",\"name\":\"Qi Cai\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"2596486\",\"name\":\"Zhijian Hou\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"143977389\",\"name\":\"C. Ngo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"714d6ca486fe5347571052e8049d77920c6e5e07\",\"title\":\"vireoJD-MM at Activity Detection in Extended Videos\",\"url\":\"https://www.semanticscholar.org/paper/714d6ca486fe5347571052e8049d77920c6e5e07\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48841342\",\"name\":\"Qing Lei\"},{\"authorId\":\"1701928\",\"name\":\"Jixiang Du\"},{\"authorId\":\"49173384\",\"name\":\"Hongbo Zhang\"},{\"authorId\":\"47416429\",\"name\":\"Shuang Ye\"},{\"authorId\":\"123204699\",\"name\":\"Duan-Sheng Chen\"}],\"doi\":\"10.3390/s19194129\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fdcd429a8d6ae1928d71dd2c89e67b31138c13e1\",\"title\":\"A Survey of Vision-Based Human Action Evaluation Methods\",\"url\":\"https://www.semanticscholar.org/paper/fdcd429a8d6ae1928d71dd2c89e67b31138c13e1\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"28933059\",\"name\":\"Jiangchuan Wei\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"50130622\",\"name\":\"Yun Yi\"},{\"authorId\":\"8194130\",\"name\":\"Qinyu Li\"},{\"authorId\":\"8312366\",\"name\":\"De-Shuang Huang\"}],\"doi\":\"10.1109/ICIP.2019.8802979\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6c4e7471cd845223b852efe09e5985544332b22a\",\"title\":\"P3D-CTN: Pseudo-3D Convolutional Tube Network for Spatio-Temporal Action Detection in Videos\",\"url\":\"https://www.semanticscholar.org/paper/6c4e7471cd845223b852efe09e5985544332b22a\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"1812.04914\",\"authors\":[{\"authorId\":\"36024030\",\"name\":\"Z. Xu\"},{\"authorId\":\"50062008\",\"name\":\"Ziyi Wu\"},{\"authorId\":\"144698893\",\"name\":\"J. Feng\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"19ea943b2c0957fe38ac6d3f8d26f2cd6e7dca5e\",\"title\":\"CFUN: Combining Faster R-CNN and U-net Network for Efficient Whole Heart Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/19ea943b2c0957fe38ac6d3f8d26f2cd6e7dca5e\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1812.00477\",\"authors\":[{\"authorId\":\"40468514\",\"name\":\"Liang Yang\"},{\"authorId\":\"47067803\",\"name\":\"Hao Jiang\"},{\"authorId\":\"1742202\",\"name\":\"J. Xiao\"},{\"authorId\":\"3382735\",\"name\":\"Z. Huo\"}],\"doi\":\"10.1109/CVPRW.2019.00050\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b6539443f5e6b52de3436518abc44ab0793b4dc1\",\"title\":\"Visual-GPS: Ego-Downward and Ambient Video Based Person Location Association\",\"url\":\"https://www.semanticscholar.org/paper/b6539443f5e6b52de3436518abc44ab0793b4dc1\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":\"2008.03462\",\"authors\":[{\"authorId\":\"145586191\",\"name\":\"Can Zhang\"},{\"authorId\":\"26981150\",\"name\":\"Yue-Xian Zou\"},{\"authorId\":\"143930563\",\"name\":\"G. Chen\"},{\"authorId\":\"48204311\",\"name\":\"L. Gan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"60840dce8073545641198c297796902fa390c719\",\"title\":\"PAN: Towards Fast Action Recognition via Learning Persistence of Appearance\",\"url\":\"https://www.semanticscholar.org/paper/60840dce8073545641198c297796902fa390c719\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1801.09184\",\"authors\":[{\"authorId\":\"2860057\",\"name\":\"Yancheng Bai\"},{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"601d81b164afceecf6f155d60bfb400510a5be4e\",\"title\":\"Contextual Multi-Scale Region Convolutional 3D Network for Activity Detection\",\"url\":\"https://www.semanticscholar.org/paper/601d81b164afceecf6f155d60bfb400510a5be4e\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491240780\",\"name\":\"Zhensheng Shi\"},{\"authorId\":\"1491233401\",\"name\":\"Liangjie Cao\"},{\"authorId\":\"153747406\",\"name\":\"Cheng Guan\"},{\"authorId\":\"2336297\",\"name\":\"Haiyong Zheng\"},{\"authorId\":\"29344734\",\"name\":\"Zhaorui Gu\"},{\"authorId\":\"144803009\",\"name\":\"Z. Yu\"},{\"authorId\":\"49721778\",\"name\":\"B. Zheng\"}],\"doi\":\"10.1109/ACCESS.2020.2968024\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c8744061c96cbcf492d5e504d3f6cfc7d0059643\",\"title\":\"Learning Attention-Enhanced Spatiotemporal Representation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c8744061c96cbcf492d5e504d3f6cfc7d0059643\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32734037\",\"name\":\"Chaonan Gu\"},{\"authorId\":\"122112989\",\"name\":\"Xiaoyu Wu\"},{\"authorId\":\"103307901\",\"name\":\"Shengjin Wang\"}],\"doi\":\"10.1109/ACCESS.2020.2992617\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"443403fc542ceb9f40c66edc9845d1269f53d1ca\",\"title\":\"Violent Video Detection Based on Semantic Correspondence\",\"url\":\"https://www.semanticscholar.org/paper/443403fc542ceb9f40c66edc9845d1269f53d1ca\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1608.05267\",\"authors\":[{\"authorId\":\"143969578\",\"name\":\"Qiuhong Ke\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"1782428\",\"name\":\"S. An\"},{\"authorId\":\"2470423\",\"name\":\"Ferdous Sohel\"},{\"authorId\":\"3417987\",\"name\":\"F. Boussaid\"}],\"doi\":\"10.1109/TMM.2017.2778559\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"83f8c54605689f093199bea52fdabaa9902ff4aa\",\"title\":\"Leveraging Structural Context Models and Ranking Score Fusion for Human Interaction Prediction\",\"url\":\"https://www.semanticscholar.org/paper/83f8c54605689f093199bea52fdabaa9902ff4aa\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1730228\",\"name\":\"M. Liu\"},{\"authorId\":\"47781541\",\"name\":\"Z. Liu\"}],\"doi\":\"10.1145/3347450.3357654\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d062058cdef85163512c3984f0f1ba78f625582e\",\"title\":\"Deep Reinforcement Learning Visual-Text Attention for Multimodal Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/d062058cdef85163512c3984f0f1ba78f625582e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1742340859\",\"name\":\"Kehan Li\"},{\"authorId\":\"51036744\",\"name\":\"Jiming Chen\"},{\"authorId\":\"2425630\",\"name\":\"B. Yu\"},{\"authorId\":\"1742395342\",\"name\":\"Zhangchong Shen\"},{\"authorId\":\"87330334\",\"name\":\"C. Li\"},{\"authorId\":\"35372976\",\"name\":\"Shibo He\"}],\"doi\":\"10.1109/IPSN48710.2020.00-51\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"606b108e69db50785a10376e284edea85bc3d4e3\",\"title\":\"Supreme: Fine-grained Radio Map Reconstruction via Spatial-Temporal Fusion Network\",\"url\":\"https://www.semanticscholar.org/paper/606b108e69db50785a10376e284edea85bc3d4e3\",\"venue\":\"2020 19th ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)\",\"year\":2020},{\"arxivId\":\"2011.00826\",\"authors\":[{\"authorId\":null,\"name\":\"Zihao Wang\"},{\"authorId\":\"5739094\",\"name\":\"Chen Lin\"},{\"authorId\":\"1999541581\",\"name\":\"Lu Sheng\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\"},{\"authorId\":\"1388486428\",\"name\":\"Jing Shao\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"316931202b0d02d37672a976f43bb1ed479c6877\",\"title\":\"PV-NAS: Practical Neural Architecture Search for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/316931202b0d02d37672a976f43bb1ed479c6877\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1912.04538\",\"authors\":[{\"authorId\":\"115023832\",\"name\":\"Zhi-Kai Chen\"},{\"authorId\":\"3041937\",\"name\":\"Lingxi Xie\"},{\"authorId\":\"2852872\",\"name\":\"S. Pang\"},{\"authorId\":\"51004368\",\"name\":\"Y. He\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b9f01b9054517581a675fb919850ad558d4640d7\",\"title\":\"Appending Adversarial Frames for Universal Video Attack\",\"url\":\"https://www.semanticscholar.org/paper/b9f01b9054517581a675fb919850ad558d4640d7\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1907.12743\",\"authors\":[{\"authorId\":\"50133145\",\"name\":\"Min-Hung Chen\"},{\"authorId\":\"145276578\",\"name\":\"Z. Kira\"},{\"authorId\":\"9202076\",\"name\":\"G. Al-Regib\"},{\"authorId\":\"66370228\",\"name\":\"J. Yoo\"},{\"authorId\":\"3090152\",\"name\":\"Ruxin Chen\"},{\"authorId\":\"15460136\",\"name\":\"Jianqiu Zheng\"}],\"doi\":\"10.1109/ICCV.2019.00642\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"89917e19175eb4f3bca02e0bace8f99d6910b054\",\"title\":\"Temporal Attentive Alignment for Large-Scale Video Domain Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/89917e19175eb4f3bca02e0bace8f99d6910b054\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2010.05264\",\"authors\":[{\"authorId\":\"2653622\",\"name\":\"Junfu Pu\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"1400188907\",\"name\":\"Hezhen Hu\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"}],\"doi\":\"10.1145/3394171.3413931\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ce50fa888551b640fe3dddc57289c27f325c029b\",\"title\":\"Boosting Continuous Sign Language Recognition via Cross Modality Augmentation\",\"url\":\"https://www.semanticscholar.org/paper/ce50fa888551b640fe3dddc57289c27f325c029b\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2012.06977\",\"authors\":[{\"authorId\":\"47203405\",\"name\":\"Wenhao Wu\"},{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"6873935\",\"name\":\"T. Lin\"},{\"authorId\":\"1998948807\",\"name\":\"F. Li\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"12081764\",\"name\":\"E. Ding\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a6e71b58ea6668dd3872e0c9e6cdd258b4582e2a\",\"title\":\"MVFNet: Multi-View Fusion Network for Efficient Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a6e71b58ea6668dd3872e0c9e6cdd258b4582e2a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121339452\",\"name\":\"Y. Tian\"},{\"authorId\":\"1810382\",\"name\":\"Zhaohui Che\"},{\"authorId\":\"116279011\",\"name\":\"Wenbo Bao\"},{\"authorId\":\"1509899757\",\"name\":\"Guangtao Zhai\"},{\"authorId\":\"97709070\",\"name\":\"Z. Gao\"}],\"doi\":\"10.1007/978-3-030-58568-6_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"27568c821ab008facaa57dc4f99217a294e196c4\",\"title\":\"Self-supervised Motion Representation via Scattering Local Motion Cues\",\"url\":\"https://www.semanticscholar.org/paper/27568c821ab008facaa57dc4f99217a294e196c4\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33390229\",\"name\":\"Alina Roitberg\"},{\"authorId\":\"67310661\",\"name\":\"Monica Haurilet\"},{\"authorId\":\"1845905584\",\"name\":\"Simon Rei\\u00df\"},{\"authorId\":\"49157259\",\"name\":\"R. Stiefelhagen\"}],\"doi\":\"10.1109/ITSC45102.2020.9294731\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"afe640b4cfcbaf0885147eafd7d92887096e0e99\",\"title\":\"CNN-based Driver Activity Understanding: Shedding Light on Deep Spatiotemporal Representations\",\"url\":\"https://www.semanticscholar.org/paper/afe640b4cfcbaf0885147eafd7d92887096e0e99\",\"venue\":\"2020 IEEE 23rd International Conference on Intelligent Transportation Systems (ITSC)\",\"year\":2020},{\"arxivId\":\"2010.10019\",\"authors\":[{\"authorId\":\"47267313\",\"name\":\"T. Le\"},{\"authorId\":\"144672395\",\"name\":\"Vuong Le\"},{\"authorId\":\"144162181\",\"name\":\"S. Venkatesh\"},{\"authorId\":\"6254479\",\"name\":\"T. Tran\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"93ff44e056befc6306abab75307aa23bce22ca70\",\"title\":\"Hierarchical Conditional Relation Networks for Multimodal Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/93ff44e056befc6306abab75307aa23bce22ca70\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152514378\",\"name\":\"Hao Zheng\"},{\"authorId\":\"11499126\",\"name\":\"L. Yang\"},{\"authorId\":\"145401247\",\"name\":\"J. Han\"},{\"authorId\":\"3272356\",\"name\":\"Yizhe Zhang\"},{\"authorId\":\"35686071\",\"name\":\"Peixian Liang\"},{\"authorId\":\"47122808\",\"name\":\"Zhuo Zhao\"},{\"authorId\":\"152745080\",\"name\":\"Chao-li Wang\"},{\"authorId\":\"1743881\",\"name\":\"D. Chen\"}],\"doi\":\"10.1007/978-3-030-32245-8_84\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d287869b814d1b943c5f2a17f80fbf215463eea6\",\"title\":\"HFA-Net: 3D Cardiovascular Image Segmentation with Asymmetrical Pooling and Content-Aware Fusion\",\"url\":\"https://www.semanticscholar.org/paper/d287869b814d1b943c5f2a17f80fbf215463eea6\",\"venue\":\"MICCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47988339\",\"name\":\"Jiancheng Yang\"},{\"authorId\":\"97620448\",\"name\":\"Xiaoyang. Huang\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"51458977\",\"name\":\"J. Xu\"},{\"authorId\":\"1429834069\",\"name\":\"Canqian Yang\"},{\"authorId\":\"7314697\",\"name\":\"Guozheng Xu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1881b72a1d5abc9d016e88203e8bb04b831a4586\",\"title\":\"Reinventing 2D Convolutions for 3D Medical Images\",\"url\":\"https://www.semanticscholar.org/paper/1881b72a1d5abc9d016e88203e8bb04b831a4586\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1904.10666\",\"authors\":[{\"authorId\":\"3306760\",\"name\":\"Hsu-Kuang Chiu\"},{\"authorId\":\"46408185\",\"name\":\"Ehsan Adeli\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"119131638\",\"name\":\"Stanford\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"73c28cef6c0d58b101204609137af39c3e94c047\",\"title\":\"Video Frames Output : Future Semantic Segmentation Semantic Segmentation Forecasting Input : Past Video Frames Output : Future Semantic Segmentation Semantic Forecasting\",\"url\":\"https://www.semanticscholar.org/paper/73c28cef6c0d58b101204609137af39c3e94c047\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144963124\",\"name\":\"Huanan Dong\"},{\"authorId\":\"48960121\",\"name\":\"Ming Yang Wen\"},{\"authorId\":\"2016529\",\"name\":\"Zhouwang Yang\"}],\"doi\":\"10.3390/FI11060123\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"df8b25ac1a6cc8777b975bc9f5bee37c0c36de2f\",\"title\":\"Vehicle Speed Estimation Based on 3D ConvNets and Non-Local Blocks\",\"url\":\"https://www.semanticscholar.org/paper/df8b25ac1a6cc8777b975bc9f5bee37c0c36de2f\",\"venue\":\"Future Internet\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50089882\",\"name\":\"Haiyang Jiang\"},{\"authorId\":\"7303419\",\"name\":\"Yaozong Pan\"},{\"authorId\":\"101594813\",\"name\":\"J. Zhang\"},{\"authorId\":\"145664195\",\"name\":\"H. Yang\"}],\"doi\":\"10.3390/SYM11060761\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"66a8b5f9d2578fc2b533bf93d1e4df14cd993643\",\"title\":\"Battlefield Target Aggregation Behavior Recognition Model Based on Multi-Scale Feature Fusion\",\"url\":\"https://www.semanticscholar.org/paper/66a8b5f9d2578fc2b533bf93d1e4df14cd993643\",\"venue\":\"Symmetry\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1629172313\",\"name\":\"Liqing Wan\"},{\"authorId\":\"145767616\",\"name\":\"Weiwei Xing\"},{\"authorId\":\"2042151\",\"name\":\"Shunli Zhang\"},{\"authorId\":\"34985619\",\"name\":\"Xiaoping Che\"}],\"doi\":\"10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00168\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bad812d6500b3e3269880ebf81be9f8f6cbc5c09\",\"title\":\"A Fast Action Recognition Method with Cascaded Networks\",\"url\":\"https://www.semanticscholar.org/paper/bad812d6500b3e3269880ebf81be9f8f6cbc5c09\",\"venue\":\"2019 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)\",\"year\":2019},{\"arxivId\":\"2006.09675\",\"authors\":[{\"authorId\":\"46578437\",\"name\":\"K. Liu\"},{\"authorId\":\"1686917\",\"name\":\"Wu Liu\"},{\"authorId\":\"144258295\",\"name\":\"Huadong Ma\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"}],\"doi\":\"10.1109/tcsvt.2020.2984569\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"046f98d55c557d574ef84631cae8d65d709585ed\",\"title\":\"A Real-time Action Representation with Temporal Encoding and Deep Compression\",\"url\":\"https://www.semanticscholar.org/paper/046f98d55c557d574ef84631cae8d65d709585ed\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.03263\",\"authors\":[{\"authorId\":\"93242167\",\"name\":\"Lei Shi\"},{\"authorId\":\"48380079\",\"name\":\"Yi-Fan Zhang\"},{\"authorId\":\"48265260\",\"name\":\"Jian Cheng\"},{\"authorId\":\"1699900\",\"name\":\"H. Lu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"df131f9d1fa5570192a5a3c040fe42ebe4bdfe5f\",\"title\":\"Decoupled Spatial-Temporal Attention Network for Skeleton-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/df131f9d1fa5570192a5a3c040fe42ebe4bdfe5f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.06288\",\"authors\":[{\"authorId\":\"49279229\",\"name\":\"Lifang Wu\"},{\"authorId\":\"98256637\",\"name\":\"Zhou Yang\"},{\"authorId\":\"50621207\",\"name\":\"Q. Wang\"},{\"authorId\":\"46946060\",\"name\":\"M. Jian\"},{\"authorId\":\"49217626\",\"name\":\"Boxuan Zhao\"},{\"authorId\":\"3063894\",\"name\":\"Junchi Yan\"},{\"authorId\":\"1735257\",\"name\":\"C. Chen\"}],\"doi\":\"10.1016/j.neucom.2020.07.003\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"50efde486726ae435c28211b6cd123c6b61e3a99\",\"title\":\"Fusing Motion Patterns and Key Visual Information for Semantic Event Recognition in Basketball Videos\",\"url\":\"https://www.semanticscholar.org/paper/50efde486726ae435c28211b6cd123c6b61e3a99\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"2003.11851\",\"authors\":[{\"authorId\":\"143707982\",\"name\":\"Lu Wang\"},{\"authorId\":\"2433068\",\"name\":\"Dongxue Liang\"},{\"authorId\":\"2026424\",\"name\":\"X. Yin\"},{\"authorId\":\"145505348\",\"name\":\"Jing Qiu\"},{\"authorId\":\"39632903\",\"name\":\"Z. Yang\"},{\"authorId\":\"46951283\",\"name\":\"J. Xing\"},{\"authorId\":\"65906901\",\"name\":\"Jian-zeng Dong\"},{\"authorId\":\"1903011\",\"name\":\"Zhaoyuan Ma\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"867db00148be8bc966a49a15eeb0621310e9e376\",\"title\":\"Coronary Artery Segmentation in Angiographic Videos Using A 3D-2D CE-Net\",\"url\":\"https://www.semanticscholar.org/paper/867db00148be8bc966a49a15eeb0621310e9e376\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.07641\",\"authors\":[{\"authorId\":\"13099867\",\"name\":\"Haisheng Su\"},{\"authorId\":\"35893447\",\"name\":\"W. Gan\"},{\"authorId\":\"145717875\",\"name\":\"Wei Wu\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\"},{\"authorId\":\"145858545\",\"name\":\"Y. Qiao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b8c80205302c237a93aedeeb8a26f0c25eae7674\",\"title\":\"BSN++: Complementary Boundary Regressor with Scale-Balanced Relation Modeling for Temporal Action Proposal Generation\",\"url\":\"https://www.semanticscholar.org/paper/b8c80205302c237a93aedeeb8a26f0c25eae7674\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"73227160\",\"name\":\"W. Chen\"},{\"authorId\":\"1721622\",\"name\":\"H. Wei\"},{\"authorId\":\"46244742\",\"name\":\"Suting Peng\"},{\"authorId\":\"6135447\",\"name\":\"Jiawei Sun\"},{\"authorId\":\"143639110\",\"name\":\"X. Qiao\"},{\"authorId\":\"2952027\",\"name\":\"Boqiang Liu\"}],\"doi\":\"10.1109/ACCESS.2019.2921434\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b46285ed37b16df2714eb097acf5e4d50bb82ca6\",\"title\":\"HSN: Hybrid Segmentation Network for Small Cell Lung Cancer Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/b46285ed37b16df2714eb097acf5e4d50bb82ca6\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"2010.05654\",\"authors\":[{\"authorId\":\"39714216\",\"name\":\"F. Ragusa\"},{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"2444519\",\"name\":\"S. Livatino\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a58a0732664b97b471b795df5812f98f24840490\",\"title\":\"The MECCANO Dataset: Understanding Human-Object Interactions from Egocentric Videos in an Industrial-like Domain\",\"url\":\"https://www.semanticscholar.org/paper/a58a0732664b97b471b795df5812f98f24840490\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121209369\",\"name\":\"J. Cai\"},{\"authorId\":\"50779096\",\"name\":\"J. Hu\"}],\"doi\":\"10.1007/s00371-019-01733-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"324054c22c974b24bff452cd0144df07665fa00e\",\"title\":\"3D RANs: 3D Residual Attention Networks for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/324054c22c974b24bff452cd0144df07665fa00e\",\"venue\":\"The Visual Computer\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47845267\",\"name\":\"Da Zhang\"},{\"authorId\":\"3386593\",\"name\":\"X. Dai\"},{\"authorId\":null,\"name\":\"Yuan-Fang Wang\"}],\"doi\":\"10.1109/cvpr42600.2020.00394\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"daf161f0f763bf19246ad51338764c9f732d11f0\",\"title\":\"METAL: Minimum Effort Temporal Activity Localization in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/daf161f0f763bf19246ad51338764c9f732d11f0\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993679831\",\"name\":\"Bojia Zi\"},{\"authorId\":\"1993705762\",\"name\":\"Minghao Chang\"},{\"authorId\":\"12564022\",\"name\":\"J. Chen\"},{\"authorId\":\"9576855\",\"name\":\"Xingjun Ma\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1145/3394171.3413769\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2060fa23185747294541f428c39640177450b8fb\",\"title\":\"WildDeepfake: A Challenging Real-World Dataset for Deepfake Detection\",\"url\":\"https://www.semanticscholar.org/paper/2060fa23185747294541f428c39640177450b8fb\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145798691\",\"name\":\"T. Han\"},{\"authorId\":\"1720100\",\"name\":\"H. Yao\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"2648498\",\"name\":\"Wenlong Xie\"},{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"144323097\",\"name\":\"W. Yu\"}],\"doi\":\"10.1016/J.NEUCOM.2019.03.099\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c9695232daa85651937569d1b7b2541faf2633dc\",\"title\":\"Actionness-pooled Deep-convolutional Descriptor for fine-grained action recognition\",\"url\":\"https://www.semanticscholar.org/paper/c9695232daa85651937569d1b7b2541faf2633dc\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145887139\",\"name\":\"Yuan Zong\"},{\"authorId\":\"40608983\",\"name\":\"W. Zheng\"},{\"authorId\":\"47932625\",\"name\":\"Xiaohua Huang\"},{\"authorId\":\"2473859\",\"name\":\"J. Shi\"},{\"authorId\":\"144801562\",\"name\":\"Zhen Cui\"},{\"authorId\":\"1757287\",\"name\":\"G. Zhao\"}],\"doi\":\"10.1109/TIP.2018.2797479\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"39642a1bc80ad3e2149114ea419536de32df7479\",\"title\":\"Domain Regeneration for Cross-Database Micro-Expression Recognition\",\"url\":\"https://www.semanticscholar.org/paper/39642a1bc80ad3e2149114ea419536de32df7479\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49443983\",\"name\":\"Wei Yuan\"},{\"authorId\":\"7550863\",\"name\":\"Y. Zhang\"},{\"authorId\":\"47027584\",\"name\":\"Xiaojun Hu\"},{\"authorId\":\"145126238\",\"name\":\"M. Song\"}],\"doi\":\"10.1007/978-3-030-29513-4_16\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"020e4ec36d0dc80dc94c5eb57dea430fa1f78a24\",\"title\":\"Automatic Curation System Using Multimodal Analysis Approach (MAA)\",\"url\":\"https://www.semanticscholar.org/paper/020e4ec36d0dc80dc94c5eb57dea430fa1f78a24\",\"venue\":\"IntelliSys\",\"year\":2019},{\"arxivId\":\"1905.02540\",\"authors\":[{\"authorId\":\"7885067\",\"name\":\"Xinshuo Weng\"},{\"authorId\":\"144040368\",\"name\":\"K. Kitani\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"607048b431cea997ae9dd01f029a73c502d0273f\",\"title\":\"Learning Spatio-Temporal Features with Two-Stream Deep 3D CNNs for Lipreading\",\"url\":\"https://www.semanticscholar.org/paper/607048b431cea997ae9dd01f029a73c502d0273f\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2227667\",\"name\":\"Naifan Zhuang\"},{\"authorId\":\"49502400\",\"name\":\"G. Qi\"},{\"authorId\":\"29765068\",\"name\":\"T. Kieu\"},{\"authorId\":\"1730455\",\"name\":\"K. Hua\"}],\"doi\":\"10.1145/3337928\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"43e5251d30ae8090511d26df83be26ba90d03092\",\"title\":\"Rethinking the Combined and Individual Orders of Derivative of States for Differential Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/43e5251d30ae8090511d26df83be26ba90d03092\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":\"2011.03949\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d7728ed8dd12e0ad64514ae9ec5d0bdf0576dadc\",\"title\":\"Right on Time: Multi-Temporal Convolutions for Human Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/d7728ed8dd12e0ad64514ae9ec5d0bdf0576dadc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2027172024\",\"name\":\"Kavin Ruengprateepsang\"},{\"authorId\":\"2351793\",\"name\":\"S. Wangsiripitak\"},{\"authorId\":\"2056653\",\"name\":\"Kitsuchart Pasupa\"}],\"doi\":\"10.1007/978-3-030-63830-6_31\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"96b28c526b8d6b063d9be5f6916f90ba882c6db1\",\"title\":\"Hybrid Training of Speaker and Sentence Models for One-Shot Lip Password\",\"url\":\"https://www.semanticscholar.org/paper/96b28c526b8d6b063d9be5f6916f90ba882c6db1\",\"venue\":\"ICONIP\",\"year\":2020},{\"arxivId\":\"2005.10033\",\"authors\":[{\"authorId\":\"38212285\",\"name\":\"N. Gessert\"},{\"authorId\":\"123390466\",\"name\":\"M. Bengs\"},{\"authorId\":\"9540121\",\"name\":\"M. Schl\\u00fcter\"},{\"authorId\":\"3236423\",\"name\":\"A. Schlaefer\"}],\"doi\":\"10.1016/j.media.2020.101730\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9c81029be43318d5dc6b8e0eeae5d66d091eb22c\",\"title\":\"Deep learning with 4D spatio-temporal data representations for OCT-based force estimation\",\"url\":\"https://www.semanticscholar.org/paper/9c81029be43318d5dc6b8e0eeae5d66d091eb22c\",\"venue\":\"Medical Image Anal.\",\"year\":2020},{\"arxivId\":\"1908.00707\",\"authors\":[{\"authorId\":\"3235708\",\"name\":\"Guoqiang Gong\"},{\"authorId\":\"9693996\",\"name\":\"Liangfeng Zheng\"},{\"authorId\":\"144654776\",\"name\":\"Kun Bai\"},{\"authorId\":\"145353089\",\"name\":\"Y. Mu\"}],\"doi\":\"10.1109/icme46284.2020.9102850\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3bba21a50bdd896cc4ebddcb8b6ce807f4a26287\",\"title\":\"Scale Matters: Temporal Scale Aggregation Network For Precise Action Localization In Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/3bba21a50bdd896cc4ebddcb8b6ce807f4a26287\",\"venue\":\"2020 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2020},{\"arxivId\":\"2004.04730\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"}],\"doi\":\"10.1109/cvpr42600.2020.00028\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"908cca0abefc35acc38033603714fbb1bcadc49d\",\"title\":\"X3D: Expanding Architectures for Efficient Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/908cca0abefc35acc38033603714fbb1bcadc49d\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1912.04487\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":\"10.1109/cvpr42600.2020.01047\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c4128ba8deeb67e731cf52fb98addcfddd487e55\",\"title\":\"Listen to Look: Action Recognition by Previewing Audio\",\"url\":\"https://www.semanticscholar.org/paper/c4128ba8deeb67e731cf52fb98addcfddd487e55\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151493680\",\"name\":\"Jingjun Chen\"},{\"authorId\":\"1682580\",\"name\":\"Y. Song\"},{\"authorId\":\"1591129121\",\"name\":\"Yuanlin Zhang\"}],\"doi\":\"10.1109/ICME.2019.00185\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1bbeaa4279bd31729d718c76d62c0b314fe7b20b\",\"title\":\"Spatial Mask ConvLSTM Network and Intra-Class Joint Training Method for Human Action Recognition in Video\",\"url\":\"https://www.semanticscholar.org/paper/1bbeaa4279bd31729d718c76d62c0b314fe7b20b\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121213082\",\"name\":\"Cao\"},{\"authorId\":\"2547290\",\"name\":\"Jingwei Ji\"},{\"authorId\":\"3451430\",\"name\":\"Zhangjie Cao\"},{\"authorId\":\"4251916\",\"name\":\"C. Chang\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"03f33ad3f994e03b87ee2d1f711087c9efcd8cf6\",\"title\":\"Few-Shot Video Classification via Temporal Alignment Kaidi\",\"url\":\"https://www.semanticscholar.org/paper/03f33ad3f994e03b87ee2d1f711087c9efcd8cf6\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1904.05410\",\"authors\":[{\"authorId\":\"2295608\",\"name\":\"Y. Wang\"},{\"authorId\":\"143889270\",\"name\":\"V. Tran\"},{\"authorId\":\"3313330\",\"name\":\"Gedas Bertasius\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2356016\",\"name\":\"Minh Hoai\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fdff096ae7f7f72a435481e27623ad1a6276900b\",\"title\":\"Attentive Action and Context Factorization\",\"url\":\"https://www.semanticscholar.org/paper/fdff096ae7f7f72a435481e27623ad1a6276900b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49913895\",\"name\":\"Romain Belmonte\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"6b7fefd13817bb4b5f028b5f98d69a573d308435\",\"title\":\"Facial Landmark Detection with Local and Global Motion Modeling. (D\\u00e9tection des points caract\\u00e9ristiques du visage par mod\\u00e9lisation des mouvements locaux et globaux)\",\"url\":\"https://www.semanticscholar.org/paper/6b7fefd13817bb4b5f028b5f98d69a573d308435\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1711.11248\",\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"4439383\",\"name\":\"Jamie Ray\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/CVPR.2018.00675\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"89c3050522a0bb9820c32dc7444e003ef0d3e2e4\",\"title\":\"A Closer Look at Spatiotemporal Convolutions for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/89c3050522a0bb9820c32dc7444e003ef0d3e2e4\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1808.04234\",\"authors\":[{\"authorId\":\"22246693\",\"name\":\"Shitao Tang\"},{\"authorId\":\"1739512\",\"name\":\"Litong Feng\"},{\"authorId\":\"1874900\",\"name\":\"Zhanghui Kuang\"},{\"authorId\":\"9407393\",\"name\":\"Y. Chen\"},{\"authorId\":\"1726357\",\"name\":\"Wayne Zhang\"}],\"doi\":\"10.1007/978-3-030-20887-5_36\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c5a784d96aaf6cd41f1460d58259480503df7270\",\"title\":\"Fast Video Shot Transition Localization with Deep Structured Models\",\"url\":\"https://www.semanticscholar.org/paper/c5a784d96aaf6cd41f1460d58259480503df7270\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"2012.10071\",\"authors\":[{\"authorId\":\"48170161\",\"name\":\"L. Wang\"},{\"authorId\":\"9445458\",\"name\":\"Zhan Tong\"},{\"authorId\":\"1511715446\",\"name\":\"Bin Ji\"},{\"authorId\":\"39914710\",\"name\":\"Gangshan Wu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"839a009d4d530483cb9b365012ffc7d76cd88b85\",\"title\":\"TDN: Temporal Difference Networks for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/839a009d4d530483cb9b365012ffc7d76cd88b85\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50993183\",\"name\":\"Haochen Zhang\"},{\"authorId\":\"1718355\",\"name\":\"Dong Liu\"},{\"authorId\":\"2352456\",\"name\":\"Z. Xiong\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"39e04aa60e7e7824f26988fc9df3b42143bc8222\",\"title\":\"Two-Stream Oriented Video Super-Resolution for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/39e04aa60e7e7824f26988fc9df3b42143bc8222\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1903.01197\",\"authors\":[{\"authorId\":\"46651287\",\"name\":\"C. Li\"},{\"authorId\":\"1842317\",\"name\":\"Qiaoyong Zhong\"},{\"authorId\":\"145982709\",\"name\":\"Di Xie\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"}],\"doi\":\"10.1109/CVPR.2019.00806\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a2f8f9ae3de0ce1a4d8976c0dd1d9ff90af80ee8\",\"title\":\"Collaborative Spatiotemporal Feature Learning for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a2f8f9ae3de0ce1a4d8976c0dd1d9ff90af80ee8\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3143130\",\"name\":\"Dongyang Cai\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"2a08147bf88041c6e0354e26762b4e4d65d5163f\",\"title\":\"Trimmed Event Recognition ( Moments in Time ) : Submission to ActivityNet Challenge 2018\",\"url\":\"https://www.semanticscholar.org/paper/2a08147bf88041c6e0354e26762b4e4d65d5163f\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1909.13130\",\"authors\":[{\"authorId\":\"153918891\",\"name\":\"Chenxu Luo\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.1109/ICCV.2019.00561\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8b8fe4727c8094b17e61886e69a602f8d0403091\",\"title\":\"Grouped Spatial-Temporal Aggregation for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b8fe4727c8094b17e61886e69a602f8d0403091\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1909.03877\",\"authors\":[{\"authorId\":\"34779291\",\"name\":\"Fuchen Long\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"40434674\",\"name\":\"X. Tian\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2019.00043\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"10cb36f95b6f56b70c1f01bf8f73bbae11c9b2f1\",\"title\":\"Gaussian Temporal Awareness Networks for Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/10cb36f95b6f56b70c1f01bf8f73bbae11c9b2f1\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144125487\",\"name\":\"Hefei Ling\"},{\"authorId\":\"51066371\",\"name\":\"Yuli Chen\"},{\"authorId\":\"1722881\",\"name\":\"Jiazhong Chen\"},{\"authorId\":\"47767769\",\"name\":\"Lei Wu\"},{\"authorId\":\"1753219181\",\"name\":\"Yuxuan Shi\"},{\"authorId\":\"144401327\",\"name\":\"Jing Deng\"}],\"doi\":\"10.1007/s11042-020-09137-5\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"08a34d85465a3ee611d8bc48ae3083f578f6833d\",\"title\":\"XwiseNet: action recognition with Xwise separable convolutions\",\"url\":\"https://www.semanticscholar.org/paper/08a34d85465a3ee611d8bc48ae3083f578f6833d\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3076130\",\"name\":\"Keyang Cheng\"},{\"authorId\":\"1845915519\",\"name\":\"Eric Kasangu Lubamba\"},{\"authorId\":\"92581630\",\"name\":\"Q. Liu\"}],\"doi\":\"10.1109/ACCESS.2020.3008848\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5c7c4556126f7219886cd28e4f33c85586f24955\",\"title\":\"Action Prediction Based on Partial Video Observation via Context and Temporal Sequential Network With Deformable Convolution\",\"url\":\"https://www.semanticscholar.org/paper/5c7c4556126f7219886cd28e4f33c85586f24955\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2001.10953\",\"authors\":[{\"authorId\":\"1491010174\",\"name\":\"Nihar Bendre\"},{\"authorId\":\"51182462\",\"name\":\"Nima Ebadi\"},{\"authorId\":\"39409158\",\"name\":\"John J. Prevost\"},{\"authorId\":\"71756373\",\"name\":\"Peyman Najafirad\"}],\"doi\":\"10.1109/ACCESS.2020.2982364\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6de953ddfb8349de892772edccfcffb0d58dd59\",\"title\":\"Human Action Performance Using Deep Neuro-Fuzzy Recurrent Attention Model\",\"url\":\"https://www.semanticscholar.org/paper/a6de953ddfb8349de892772edccfcffb0d58dd59\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2011.10927\",\"authors\":[{\"authorId\":\"1564031469\",\"name\":\"A. J. Rana\"},{\"authorId\":\"2116440\",\"name\":\"Y. Rawat\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d61f90fe39caa04f3540e0496aa8eef9bf0b7221\",\"title\":\"We don't Need Thousand Proposals$\\\\colon$ Single Shot Actor-Action Detection in Videos\",\"url\":\"https://www.semanticscholar.org/paper/d61f90fe39caa04f3540e0496aa8eef9bf0b7221\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1812.00087\",\"authors\":[{\"authorId\":\"145979995\",\"name\":\"D. Zhang\"},{\"authorId\":\"3386593\",\"name\":\"X. Dai\"},{\"authorId\":\"48631993\",\"name\":\"Xin Eric Wang\"},{\"authorId\":\"1706938\",\"name\":\"Y. Wang\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/CVPR.2019.00134\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"613f59279586bd53aed57bc133246a4eb3c38977\",\"title\":\"MAN: Moment Alignment Network for Natural Language Moment Retrieval via Iterative Graph Adjustment\",\"url\":\"https://www.semanticscholar.org/paper/613f59279586bd53aed57bc133246a4eb3c38977\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1811.09908\",\"authors\":[{\"authorId\":\"9726614\",\"name\":\"Haokui Zhang\"},{\"authorId\":\"50024592\",\"name\":\"Y. Li\"},{\"authorId\":\"40486936\",\"name\":\"Peng Wang\"},{\"authorId\":null,\"name\":\"Yu Liu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"01cb3f168a2cc811f6a79c4f0508f769002a49d5\",\"title\":\"RGB-D Based Action Recognition with Light-weight 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/01cb3f168a2cc811f6a79c4f0508f769002a49d5\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46651582\",\"name\":\"C. Li\"},{\"authorId\":\"2891860\",\"name\":\"Yue Ming\"},{\"authorId\":\"1916963\",\"name\":\"Y. Shen\"},{\"authorId\":\"89080361\",\"name\":\"Hui Yu\"}],\"doi\":\"10.1109/ICMEW.2019.00034\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c96638d66c1d3423aea1c2f21436e22bc8cd3d7f\",\"title\":\"Deep Key Clips-Video Feature Fusion Framework for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c96638d66c1d3423aea1c2f21436e22bc8cd3d7f\",\"venue\":\"2019 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2019},{\"arxivId\":\"1711.09125\",\"authors\":[{\"authorId\":\"119770705\",\"name\":\"L. Wang\"},{\"authorId\":\"48625175\",\"name\":\"W. Li\"},{\"authorId\":\"145344553\",\"name\":\"W. Li\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2018.00155\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e6b534d8838f92461a478a3e737b73e08db94748\",\"title\":\"Appearance-and-Relation Networks for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/e6b534d8838f92461a478a3e737b73e08db94748\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47120363\",\"name\":\"X. Wang\"},{\"authorId\":\"3316344\",\"name\":\"Junsan Zhang\"},{\"authorId\":\"2250564\",\"name\":\"Leiquan Wang\"},{\"authorId\":\"144019071\",\"name\":\"Philip S. Yu\"},{\"authorId\":\"47055140\",\"name\":\"J. Zhu\"},{\"authorId\":\"46382188\",\"name\":\"H. Li\"}],\"doi\":\"10.1145/3357384.3357935\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"51e4e7b322c53dac73048fa5bd5dd1c5145b2d82\",\"title\":\"Video-level Multi-model Fusion for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/51e4e7b322c53dac73048fa5bd5dd1c5145b2d82\",\"venue\":\"CIKM\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"108635954\",\"name\":\"H. Guan\"},{\"authorId\":\"50148458\",\"name\":\"Guangyu Yao\"},{\"authorId\":\"22796119\",\"name\":\"Y. Zhang\"},{\"authorId\":\"6084860\",\"name\":\"Yujun Gu\"},{\"authorId\":\"145838238\",\"name\":\"H Zhao\"},{\"authorId\":\"144645740\",\"name\":\"Y. Zhang\"},{\"authorId\":\"145509437\",\"name\":\"Xiao Gu\"}],\"doi\":\"10.1109/VCIP.2018.8698719\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"07a930794d709ba9b80553cbe47678b56adc703a\",\"title\":\"Deep Dual-view Network with Smooth Loss for Spinal Metastases Classification\",\"url\":\"https://www.semanticscholar.org/paper/07a930794d709ba9b80553cbe47678b56adc703a\",\"venue\":\"2018 IEEE Visual Communications and Image Processing (VCIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390916430\",\"name\":\"Huan Liu\"},{\"authorId\":\"2817677\",\"name\":\"Qinghua Zheng\"},{\"authorId\":\"3326677\",\"name\":\"Minnan Luo\"},{\"authorId\":\"152193942\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"152299623\",\"name\":\"C. Yan\"},{\"authorId\":\"46518251\",\"name\":\"L. Yao\"}],\"doi\":\"10.1016/j.knosys.2020.106432\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6072b5407daf1db4871fa27bdac7f63407019091\",\"title\":\"Memory transformation networks for weakly supervised visual classification\",\"url\":\"https://www.semanticscholar.org/paper/6072b5407daf1db4871fa27bdac7f63407019091\",\"venue\":\"Knowl. Based Syst.\",\"year\":2020},{\"arxivId\":\"2005.06803\",\"authors\":[{\"authorId\":\"46270766\",\"name\":\"Zhaoyang Liu\"},{\"authorId\":\"29461006\",\"name\":\"L. Wang\"},{\"authorId\":\"3096434\",\"name\":\"W. Wu\"},{\"authorId\":\"7350503\",\"name\":\"Chen Qian\"},{\"authorId\":\"144720251\",\"name\":\"Tong Lu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"3ac6ad718bbdeda6b5b00b61983f8b520d8a6bcb\",\"title\":\"TAM: Temporal Adaptive Module for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3ac6ad718bbdeda6b5b00b61983f8b520d8a6bcb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1903.05577\",\"authors\":[{\"authorId\":\"50993183\",\"name\":\"Haochen Zhang\"},{\"authorId\":\"48928981\",\"name\":\"Dong Liu\"},{\"authorId\":\"2352456\",\"name\":\"Z. Xiong\"}],\"doi\":\"10.1109/ICCV.2019.00889\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cb72cbdb5476118a207a51054787f6419d5ec055\",\"title\":\"Two-Stream Action Recognition-Oriented Video Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/cb72cbdb5476118a207a51054787f6419d5ec055\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1474224022\",\"name\":\"Sun'ao Liu\"},{\"authorId\":\"1713390\",\"name\":\"Xiaonan Guo\"}],\"doi\":\"10.1007/978-3-030-46640-4_33\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cde425689b34b9baa923a85bbc6e3856a1268efb\",\"title\":\"Improving Brain Tumor Segmentation with Multi-direction Fusion and Fine Class Prediction\",\"url\":\"https://www.semanticscholar.org/paper/cde425689b34b9baa923a85bbc6e3856a1268efb\",\"venue\":\"BrainLes@MICCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51432978\",\"name\":\"Zhongke Liao\"},{\"authorId\":\"46354059\",\"name\":\"Haifeng Hu\"},{\"authorId\":\"49050918\",\"name\":\"J. Zhang\"},{\"authorId\":\"7650248\",\"name\":\"C. Yin\"}],\"doi\":\"10.1016/j.cviu.2019.102821\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fedf56f95e5e80464254573ce2d9648606899ccb\",\"title\":\"Residual attention unit for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/fedf56f95e5e80464254573ce2d9648606899ccb\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2019},{\"arxivId\":\"1904.02422\",\"authors\":[{\"authorId\":\"41022447\",\"name\":\"Okan K\\u00f6p\\u00fckl\\u00fc\"},{\"authorId\":\"1862703\",\"name\":\"N. Kose\"},{\"authorId\":\"66999822\",\"name\":\"Ahmet Gunduz\"},{\"authorId\":\"145512909\",\"name\":\"G. Rigoll\"}],\"doi\":\"10.1109/ICCVW.2019.00240\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b4f307750b6e192239dff6f80f203dcf9e05cb5d\",\"title\":\"Resource Efficient 3D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/b4f307750b6e192239dff6f80f203dcf9e05cb5d\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1912.08860\",\"authors\":[{\"authorId\":\"26432578\",\"name\":\"Emmanuel Kahembwe\"},{\"authorId\":\"47172195\",\"name\":\"S. Ramamoorthy\"}],\"doi\":\"10.1016/j.neunet.2020.09.016\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1f313226533edea306c4de79df945cc5a90d153c\",\"title\":\"Lower Dimensional Kernels for Video Discriminators\",\"url\":\"https://www.semanticscholar.org/paper/1f313226533edea306c4de79df945cc5a90d153c\",\"venue\":\"Neural Networks\",\"year\":2020},{\"arxivId\":\"2008.08072\",\"authors\":[{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"},{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"3462309\",\"name\":\"Juhana Kangaspunta\"},{\"authorId\":\"2148510\",\"name\":\"A. Angelova\"}],\"doi\":\"10.1007/978-3-030-58565-5_39\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a156594c076a8f0e073e5656ae8e3311212d2422\",\"title\":\"AssembleNet++: Assembling Modality Representations via Attention Connections\",\"url\":\"https://www.semanticscholar.org/paper/a156594c076a8f0e073e5656ae8e3311212d2422\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2010.11757\",\"authors\":[{\"authorId\":\"48239920\",\"name\":\"Chun-Fu Chen\"},{\"authorId\":\"1819152\",\"name\":\"R. Panda\"},{\"authorId\":\"40544169\",\"name\":\"K. Ramakrishnan\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"38060482\",\"name\":\"J. M. Cohn\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"33421444\",\"name\":\"Quanfu Fan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f5c2623a44660ad9fe6cd46710fec6e812a3375a\",\"title\":\"Deep Analysis of CNN-based Spatio-temporal Representations for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f5c2623a44660ad9fe6cd46710fec6e812a3375a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152142657\",\"name\":\"Y. Tian\"},{\"authorId\":\"1825799769\",\"name\":\"Guangzhao Zhai\"},{\"authorId\":\"97709070\",\"name\":\"Z. Gao\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5768e26731fb55edced4193596f6a470d0029ce6\",\"title\":\"Video-ception Network: Towards Multi-Scale Efficient Asymmetric Spatial-Temporal Interactions\",\"url\":\"https://www.semanticscholar.org/paper/5768e26731fb55edced4193596f6a470d0029ce6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1510708346\",\"name\":\"Jianbang Qin\"},{\"authorId\":\"1510665624\",\"name\":\"S. Hu\"},{\"authorId\":\"153301546\",\"name\":\"W. Guo\"}],\"doi\":\"10.1117/12.2559286\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"80f0280a05f10f0d95ceb0bc4c435315acfef5bb\",\"title\":\"Global evaluate-and-rescale network: an efficient model for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/80f0280a05f10f0d95ceb0bc4c435315acfef5bb\",\"venue\":\"International Conference on Machine Vision\",\"year\":2020},{\"arxivId\":\"2004.03548\",\"authors\":[{\"authorId\":\"49984891\",\"name\":\"Ceyuan Yang\"},{\"authorId\":\"121983635\",\"name\":\"Yinghao Xu\"},{\"authorId\":\"46865320\",\"name\":\"Jianping Shi\"},{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"}],\"doi\":\"10.1109/cvpr42600.2020.00067\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"10db26c80238d70ca51d8a5293d893b6f1dedc8b\",\"title\":\"Temporal Pyramid Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/10db26c80238d70ca51d8a5293d893b6f1dedc8b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1811.11387\",\"authors\":[{\"authorId\":\"29724362\",\"name\":\"Longlong Jing\"},{\"authorId\":\"40058797\",\"name\":\"Xiaodong Yang\"},{\"authorId\":\"1800425\",\"name\":\"Jingen Liu\"},{\"authorId\":\"8193125\",\"name\":\"Y. Tian\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f7fa3b8ed5f3f75ace4fe8447ccd9abfbb19e621\",\"title\":\"Self-Supervised Spatiotemporal Feature Learning via Video Rotation Prediction.\",\"url\":\"https://www.semanticscholar.org/paper/f7fa3b8ed5f3f75ace4fe8447ccd9abfbb19e621\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1817030\",\"name\":\"Saining Xie\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"1808244\",\"name\":\"J. Huang\"},{\"authorId\":\"144035504\",\"name\":\"Zhuowen Tu\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4fa0d73b8ba114578744c2ebaf610d2ca9694f45\",\"title\":\"Rethinking Spatiotemporal Feature Learning For Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/4fa0d73b8ba114578744c2ebaf610d2ca9694f45\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145929374\",\"name\":\"Xue Bai\"},{\"authorId\":\"3150525\",\"name\":\"Enqing Chen\"},{\"authorId\":\"74806144\",\"name\":\"Haron Chweya Tinega\"}],\"doi\":\"10.1117/12.2540268\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"678b7077b11c3381080b3ecb59c851240ea4cd7c\",\"title\":\"Real-time action recognition based on enhanced motion vector temporal segment network\",\"url\":\"https://www.semanticscholar.org/paper/678b7077b11c3381080b3ecb59c851240ea4cd7c\",\"venue\":\"International Conference on Digital Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47781687\",\"name\":\"Z. Liu\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"},{\"authorId\":\"49050918\",\"name\":\"J. Zhang\"}],\"doi\":\"10.1007/s11063-018-09972-6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"33c615be88df63dfd0e8f1b770066f062ee8d157\",\"title\":\"Spatiotemporal Fusion Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/33c615be88df63dfd0e8f1b770066f062ee8d157\",\"venue\":\"Neural Processing Letters\",\"year\":2019},{\"arxivId\":\"2003.02224\",\"authors\":[{\"authorId\":\"30948969\",\"name\":\"H. Lin\"},{\"authorId\":\"20837586\",\"name\":\"Hyeon Jeong Lee\"},{\"authorId\":\"41078538\",\"name\":\"N. Tague\"},{\"authorId\":\"49388455\",\"name\":\"Jean-Baptiste Lugagne\"},{\"authorId\":\"1471082820\",\"name\":\"Cheng Zong\"},{\"authorId\":\"46886702\",\"name\":\"F. Deng\"},{\"authorId\":\"145864439\",\"name\":\"W. Wong\"},{\"authorId\":\"2197940\",\"name\":\"Mary J. Dunlop\"},{\"authorId\":\"153513525\",\"name\":\"J. Cheng\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"991a32c8476d29a16e4f337ae98c6d17cd057b02\",\"title\":\"Fingerprint Spectroscopic SRS Imaging of Single Living Cells and Whole Brain by Ultrafast Tuning and Spatial-Spectral Learning\",\"url\":\"https://www.semanticscholar.org/paper/991a32c8476d29a16e4f337ae98c6d17cd057b02\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2003.08042\",\"authors\":[{\"authorId\":\"66562585\",\"name\":\"Xu Li\"},{\"authorId\":\"46584062\",\"name\":\"Junling Wang\"},{\"authorId\":\"152309767\",\"name\":\"L. Ma\"},{\"authorId\":\"3397429\",\"name\":\"K. Zhang\"},{\"authorId\":\"1568961008\",\"name\":\"Fengzong Lian\"},{\"authorId\":\"2705857\",\"name\":\"Zhanhui Kang\"},{\"authorId\":\"71563118\",\"name\":\"Jinjun Wang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"786a010cb738fe28bb44fcff790966a380c9da56\",\"title\":\"STH: Spatio-Temporal Hybrid Convolution for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/786a010cb738fe28bb44fcff790966a380c9da56\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"83200181\",\"name\":\"X. Gu\"},{\"authorId\":\"32797485\",\"name\":\"X. Xue\"},{\"authorId\":\"50981614\",\"name\":\"F. Wang\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053928\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4f856ebdb3ec93583e1ed99c0dff5deb57e9e9d7\",\"title\":\"Fine-Grained Action Recognition on a Novel Basketball Dataset\",\"url\":\"https://www.semanticscholar.org/paper/4f856ebdb3ec93583e1ed99c0dff5deb57e9e9d7\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"80061847\",\"name\":\"Riccardo Fantinel\"},{\"authorId\":\"113450865\",\"name\":\"A. Cenedese\"}],\"doi\":\"10.1117/1.JEI.29.4.041005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b55018815390ca8e5ff1094eaeefce89d0a0dde2\",\"title\":\"Multistep hybrid learning: CNN driven by spatial\\u2013temporal features for faults detection on metallic surfaces\",\"url\":\"https://www.semanticscholar.org/paper/b55018815390ca8e5ff1094eaeefce89d0a0dde2\",\"venue\":\"J. Electronic Imaging\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145421769\",\"name\":\"Chih-Yao Chang\"},{\"authorId\":\"7979056\",\"name\":\"Bo-I Chuang\"},{\"authorId\":\"1708559\",\"name\":\"C. Hsia\"},{\"authorId\":\"1802388\",\"name\":\"W. Chen\"},{\"authorId\":\"2345240\",\"name\":\"Min-Chun Hu\"}],\"doi\":\"10.1007/978-3-030-37734-2_57\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1627a96706e0172003b6761f0cd1d54a4e03b187\",\"title\":\"Framework Design for Multiplayer Motion Sensing Game in Mixture Reality\",\"url\":\"https://www.semanticscholar.org/paper/1627a96706e0172003b6761f0cd1d54a4e03b187\",\"venue\":\"MMM\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1685776\",\"name\":\"Y. Li\"},{\"authorId\":\"1695600\",\"name\":\"X. Chai\"},{\"authorId\":\"1710220\",\"name\":\"X. Chen\"}],\"doi\":\"10.1007/978-3-030-20876-9_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2a34f44e3890e8fa1dbf9456375ed5c32afb76e0\",\"title\":\"ScoringNet: Learning Key Fragment for Action Quality Assessment with Ranking Loss in Skilled Sports\",\"url\":\"https://www.semanticscholar.org/paper/2a34f44e3890e8fa1dbf9456375ed5c32afb76e0\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2224475\",\"name\":\"Huogen Wang\"},{\"authorId\":\"9459349\",\"name\":\"Zhanjie Song\"},{\"authorId\":\"15585183\",\"name\":\"W. Li\"},{\"authorId\":\"8120382\",\"name\":\"P. Wang\"}],\"doi\":\"10.3390/s20113305\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3b84d02d6f74a53d1196478689797eef63c306b3\",\"title\":\"A Hybrid Network for Large-Scale Action Recognition from RGB and Depth Modalities\",\"url\":\"https://www.semanticscholar.org/paper/3b84d02d6f74a53d1196478689797eef63c306b3\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2229862\",\"name\":\"Baohan Xu\"},{\"authorId\":\"145222823\",\"name\":\"H. Ye\"},{\"authorId\":\"3015119\",\"name\":\"Y. Zheng\"},{\"authorId\":\"50841852\",\"name\":\"Heng Wang\"},{\"authorId\":\"1840008\",\"name\":\"Tianyu Luwang\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1109/TIP.2019.2917283\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"151ebd3d95ca2acb17da3f2274c898a4f43bdf65\",\"title\":\"Dense Dilated Network for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/151ebd3d95ca2acb17da3f2274c898a4f43bdf65\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2007311898\",\"name\":\"Yangyang Qiao\"},{\"authorId\":\"2007310586\",\"name\":\"Whenhua Cui\"},{\"authorId\":\"1838022\",\"name\":\"Tianwei Shi\"}],\"doi\":\"10.1109/ACCESS.2020.3032533\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2a19004227240cd365422eaa00b589469897a3d7\",\"title\":\"LaM-2SRN: A Method Which Can Enhance Local Features and Detect Moving Objects for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2a19004227240cd365422eaa00b589469897a3d7\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1903.02155\",\"authors\":[{\"authorId\":\"144770282\",\"name\":\"D. Xie\"},{\"authorId\":\"145102437\",\"name\":\"Cheng Deng\"},{\"authorId\":\"49528465\",\"name\":\"Hao Wang\"},{\"authorId\":\"66140038\",\"name\":\"Chao Li\"},{\"authorId\":\"1701119\",\"name\":\"Dapeng Tao\"}],\"doi\":\"10.1609/AAAI.V33I01.33019030\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"19458fa0d29181cc3f72f5f1253b64ba0e02e5f3\",\"title\":\"Semantic Adversarial Network with Multi-scale Pyramid Attention for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/19458fa0d29181cc3f72f5f1253b64ba0e02e5f3\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145951562\",\"name\":\"W. Luo\"},{\"authorId\":\"50445655\",\"name\":\"C. Zhang\"},{\"authorId\":\"49663261\",\"name\":\"W. Liu\"},{\"authorId\":\"91945776\",\"name\":\"J. Wu\"},{\"authorId\":\"8131625\",\"name\":\"W. Lin\"}],\"doi\":\"10.1109/BigMM.2019.00-27\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"de265804b8a955308f42fee71d01dfe45fe83f3b\",\"title\":\"Improving Action Recognition with Valued Patches Exploiting\",\"url\":\"https://www.semanticscholar.org/paper/de265804b8a955308f42fee71d01dfe45fe83f3b\",\"venue\":\"2019 IEEE Fifth International Conference on Multimedia Big Data (BigMM)\",\"year\":2019},{\"arxivId\":\"2009.13087\",\"authors\":[{\"authorId\":\"3173493\",\"name\":\"Y. Li\"},{\"authorId\":\"2050979\",\"name\":\"Zhichao Lu\"},{\"authorId\":\"3182065\",\"name\":\"Xuehan Xiong\"},{\"authorId\":\"4240351\",\"name\":\"Jonathan Huang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c8bf6f41d6df5c6cdc6249aecfa1aab027f0c8e0\",\"title\":\"PERF-Net: Pose Empowered RGB-Flow Net\",\"url\":\"https://www.semanticscholar.org/paper/c8bf6f41d6df5c6cdc6249aecfa1aab027f0c8e0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.03876\",\"authors\":[{\"authorId\":\"9734988\",\"name\":\"Yuecong Xu\"},{\"authorId\":\"2562263\",\"name\":\"Jianfei Yang\"},{\"authorId\":\"153420733\",\"name\":\"Haozhi Cao\"},{\"authorId\":\"120974533\",\"name\":\"Kezhi Mao\"},{\"authorId\":\"2037059\",\"name\":\"Jian-Xiong Yin\"},{\"authorId\":\"144308998\",\"name\":\"S. See\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e30fd64c9659c8cc6b28d37d19395752aae89130\",\"title\":\"ARID: A New Dataset for Recognizing Action in the Dark\",\"url\":\"https://www.semanticscholar.org/paper/e30fd64c9659c8cc6b28d37d19395752aae89130\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1903.09102\",\"authors\":[{\"authorId\":\"39576371\",\"name\":\"A. Manglik\"},{\"authorId\":\"7885067\",\"name\":\"Xinshuo Weng\"},{\"authorId\":\"1401940506\",\"name\":\"Eshed Ohn-Bar\"},{\"authorId\":\"1491177496\",\"name\":\"Kris M. Kitanil\"}],\"doi\":\"10.1109/IROS40897.2019.8967730\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"96faca0c3994a110375b78e47568e0fa10d77279\",\"title\":\"Forecasting Time-to-Collision from Monocular Video: Feasibility, Dataset, and Challenges\",\"url\":\"https://www.semanticscholar.org/paper/96faca0c3994a110375b78e47568e0fa10d77279\",\"venue\":\"2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46461170\",\"name\":\"Yan Yang\"},{\"authorId\":\"27423107\",\"name\":\"Shanzhen Lan\"},{\"authorId\":\"50201744\",\"name\":\"Shengjun Zhang\"},{\"authorId\":\"9963055\",\"name\":\"Qi Bu\"},{\"authorId\":\"47558252\",\"name\":\"Y. Chen\"}],\"doi\":\"10.1109/ICCST50977.2020.00068\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3fab8bb744aa2e1d0c0507ef1449395e3b43d73b\",\"title\":\"Precise Temporal Action Detection for Fine-grained Actions\",\"url\":\"https://www.semanticscholar.org/paper/3fab8bb744aa2e1d0c0507ef1449395e3b43d73b\",\"venue\":\"2020 International Conference on Culture-oriented Science & Technology (ICCST)\",\"year\":2020},{\"arxivId\":\"2012.13375\",\"authors\":[{\"authorId\":null,\"name\":\"Yue Cao\"},{\"authorId\":\"1690418794\",\"name\":\"Jiarui Xu\"},{\"authorId\":\"48639986\",\"name\":\"Stephen Lin\"},{\"authorId\":\"2480483\",\"name\":\"Fangyun Wei\"},{\"authorId\":\"1825704806\",\"name\":\"Han Hu\"}],\"doi\":\"10.1109/TPAMI.2020.3047209\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e1da715b8ae4436c5224e9b573309a3b72c7a53c\",\"title\":\"Global Context Networks.\",\"url\":\"https://www.semanticscholar.org/paper/e1da715b8ae4436c5224e9b573309a3b72c7a53c\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"2012.00317\",\"authors\":[{\"authorId\":\"3445691\",\"name\":\"Youngwan Lee\"},{\"authorId\":\"2645625\",\"name\":\"H. Kim\"},{\"authorId\":\"35323281\",\"name\":\"Kimin Yun\"},{\"authorId\":\"3035146\",\"name\":\"Jinyoung Moon\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"87b2f4542659801ab5b4baddbd88b2a7d1296726\",\"title\":\"Diverse Temporal Aggregation and Depthwise Spatiotemporal Factorization for Efficient Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/87b2f4542659801ab5b4baddbd88b2a7d1296726\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.12434\",\"authors\":[{\"authorId\":\"144701907\",\"name\":\"G. Elahi\"},{\"authorId\":\"35964920\",\"name\":\"Yee-Hong Yang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"048de3aa58e86791aa61ae08316e823528ee11f6\",\"title\":\"Online Learnable Keyframe Extraction in Videos and its Application with Semantic Word Vector in Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/048de3aa58e86791aa61ae08316e823528ee11f6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1659125162\",\"name\":\"Danfeng Zhuang\"},{\"authorId\":\"145309461\",\"name\":\"Min Jiang\"},{\"authorId\":\"1644912978\",\"name\":\"Jun Kong\"},{\"authorId\":\"1878899344\",\"name\":\"Tianshan Liu\"}],\"doi\":\"10.1007/s13042-020-01204-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"88f3b42b45e5f5ee60a22eb30cd41e7acc8662c9\",\"title\":\"Spatiotemporal attention enhanced features fusion network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/88f3b42b45e5f5ee60a22eb30cd41e7acc8662c9\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2003.07637\",\"authors\":[{\"authorId\":\"49724493\",\"name\":\"H. Zhang\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1007/978-3-030-58565-5_15\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"180d7e45e5fc84138039f738830950dd9b7d0e06\",\"title\":\"Motion-Excited Sampler: Video Adversarial Attack with Sparked Prior\",\"url\":\"https://www.semanticscholar.org/paper/180d7e45e5fc84138039f738830950dd9b7d0e06\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144149597\",\"name\":\"Tianshu Yu\"},{\"authorId\":\"89674661\",\"name\":\"Runzhong Wang\"},{\"authorId\":\"3063894\",\"name\":\"Junchi Yan\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b8bd415d5c294e4e928f135d19b6b6f978322d28\",\"title\":\"Learning deep graph matching with channel-independent embedding and Hungarian attention\",\"url\":\"https://www.semanticscholar.org/paper/b8bd415d5c294e4e928f135d19b6b6f978322d28\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yi Wang\"},{\"authorId\":\"15731726\",\"name\":\"Chenchen Qin\"},{\"authorId\":\"9771612\",\"name\":\"Chuanlu Lin\"},{\"authorId\":\"50436781\",\"name\":\"D. Lin\"},{\"authorId\":\"49235395\",\"name\":\"Min Xu\"},{\"authorId\":\"1940219420\",\"name\":\"Xiao Luo\"},{\"authorId\":\"48470103\",\"name\":\"Tianfu Wang\"},{\"authorId\":\"34658203\",\"name\":\"A. Li\"},{\"authorId\":\"1491625649\",\"name\":\"Dong Ni\"}],\"doi\":\"10.1002/mp.14389\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bb55219c7d3416a65ad04884d29e448273530ef8\",\"title\":\"3D Inception U\\u2010net with Asymmetric Loss for Cancer Detection in Automated Breast Ultrasound\",\"url\":\"https://www.semanticscholar.org/paper/bb55219c7d3416a65ad04884d29e448273530ef8\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"145690246\",\"name\":\"T. Yao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/TMM.2017.2759504\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"53db0d992e90f2da8cec471fdf09ac2c6bebeb0e\",\"title\":\"Learning Deep Spatio-Temporal Dependence for Semantic Video Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/53db0d992e90f2da8cec471fdf09ac2c6bebeb0e\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151472652\",\"name\":\"Yuqi Huo\"},{\"authorId\":\"101246507\",\"name\":\"Xiaoli Xu\"},{\"authorId\":\"46215480\",\"name\":\"Yao Lu\"},{\"authorId\":\"2520427\",\"name\":\"Yulei Niu\"},{\"authorId\":\"48876151\",\"name\":\"Mingyu Ding\"},{\"authorId\":\"1776220\",\"name\":\"Zhiwu Lu\"},{\"authorId\":\"145406420\",\"name\":\"Tao Xiang\"},{\"authorId\":\"153693432\",\"name\":\"Jirong Wen\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"89fafbe91b31d43dc3314ffabffa79a5f5ad746f\",\"title\":\"Lightweight Action Recognition in Compressed Videos\",\"url\":\"https://www.semanticscholar.org/paper/89fafbe91b31d43dc3314ffabffa79a5f5ad746f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"120896895\",\"name\":\"Cen Chen\"},{\"authorId\":\"145730774\",\"name\":\"K. Li\"},{\"authorId\":\"2766305\",\"name\":\"Sin G. Teo\"},{\"authorId\":\"27694418\",\"name\":\"Guizi Chen\"},{\"authorId\":\"48439012\",\"name\":\"Xiaofeng Zou\"},{\"authorId\":\"144366588\",\"name\":\"Xulei Yang\"},{\"authorId\":\"49255825\",\"name\":\"Ramaseshan C. Vijay\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"},{\"authorId\":\"3111797\",\"name\":\"Z. Zeng\"}],\"doi\":\"10.1109/ICDM.2018.00107\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6e5119ef9f0af972c82c022b139ef3f2a240cd64\",\"title\":\"Exploiting Spatio-Temporal Correlations with Multiple 3D Convolutional Neural Networks for Citywide Vehicle Flow Prediction\",\"url\":\"https://www.semanticscholar.org/paper/6e5119ef9f0af972c82c022b139ef3f2a240cd64\",\"venue\":\"2018 IEEE International Conference on Data Mining (ICDM)\",\"year\":2018},{\"arxivId\":\"2008.13254\",\"authors\":[{\"authorId\":\"3457945\",\"name\":\"Jinzheng Cai\"},{\"authorId\":\"1671290360\",\"name\":\"Ke Yan\"},{\"authorId\":\"4127040\",\"name\":\"Chi-Tung Cheng\"},{\"authorId\":\"1779360407\",\"name\":\"Jing Xiao\"},{\"authorId\":\"79610728\",\"name\":\"Chien-Hung Liao\"},{\"authorId\":\"50706692\",\"name\":\"Le Lu\"},{\"authorId\":\"2964822\",\"name\":\"Adam P. Harrison\"}],\"doi\":\"10.1007/978-3-030-59719-1_1\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8c73020d052837a897639066be0eee420bb11253\",\"title\":\"Deep Volumetric Universal Lesion Detection using Light-Weight Pseudo 3D Convolution and Surface Point Regression\",\"url\":\"https://www.semanticscholar.org/paper/8c73020d052837a897639066be0eee420bb11253\",\"venue\":\"MICCAI\",\"year\":2020},{\"arxivId\":\"1712.04851\",\"authors\":[{\"authorId\":\"1817030\",\"name\":\"Saining Xie\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"1808244\",\"name\":\"J. Huang\"},{\"authorId\":\"144035504\",\"name\":\"Zhuowen Tu\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":\"10.1007/978-3-030-01267-0_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"815aa52cfc02961d82415f080384594639a21984\",\"title\":\"Rethinking Spatiotemporal Feature Learning: Speed-Accuracy Trade-offs in Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/815aa52cfc02961d82415f080384594639a21984\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1905.10654\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"20718203ce3b9c7ed5f56f13c08c988bfdf154ca\",\"title\":\"Exploring Temporal Information for Improved Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/20718203ce3b9c7ed5f56f13c08c988bfdf154ca\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40138789\",\"name\":\"S. Liu\"},{\"authorId\":\"3262394\",\"name\":\"Daguang Xu\"},{\"authorId\":\"145668226\",\"name\":\"S. Zhou\"},{\"authorId\":\"1764071\",\"name\":\"S. Grbic\"},{\"authorId\":\"122905659\",\"name\":\"Weidong Cai\"},{\"authorId\":\"1685020\",\"name\":\"D. Comaniciu\"}],\"doi\":\"10.1007/978-3-030-13969-8_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0192ed5ab701c5433f152edab88148f738ec1e0e\",\"title\":\"Anisotropic Hybrid Network for Cross-Dimension Transferable Feature Learning in 3D Medical Images\",\"url\":\"https://www.semanticscholar.org/paper/0192ed5ab701c5433f152edab88148f738ec1e0e\",\"venue\":\"Deep Learning and Convolutional Neural Networks for Medical Imaging and Clinical Informatics\",\"year\":2019},{\"arxivId\":\"1812.02707\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"2786693\",\"name\":\"C. Doersch\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2019.00033\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"94bbc4ea271c918705876b60d98d227a0ab55a43\",\"title\":\"Video Action Transformer Network\",\"url\":\"https://www.semanticscholar.org/paper/94bbc4ea271c918705876b60d98d227a0ab55a43\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1903.07256\",\"authors\":[{\"authorId\":\"28891563\",\"name\":\"Jia-Xing Zhong\"},{\"authorId\":null,\"name\":\"Nannan Li\"},{\"authorId\":\"33559754\",\"name\":\"Weijie Kong\"},{\"authorId\":\"50152643\",\"name\":\"S. Liu\"},{\"authorId\":\"50289966\",\"name\":\"Thomas H. Li\"},{\"authorId\":\"47949235\",\"name\":\"G. Li\"}],\"doi\":\"10.1109/CVPR.2019.00133\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a03bda078490e8ee991a1f86b53f27df7cf93a14\",\"title\":\"Graph Convolutional Label Noise Cleaner: Train a Plug-And-Play Action Classifier for Anomaly Detection\",\"url\":\"https://www.semanticscholar.org/paper/a03bda078490e8ee991a1f86b53f27df7cf93a14\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152153140\",\"name\":\"Xiuping Bao\"},{\"authorId\":\"49706674\",\"name\":\"J. Yuan\"},{\"authorId\":null,\"name\":\"Bei Chen\"}],\"doi\":\"10.1109/ICTAI.2019.00089\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"60de1895702532f93b93b616d7a47096dfd1dc6c\",\"title\":\"ECPNet: An Efficient Attention-Based Convolution Network with Pseudo-3D Block for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/60de1895702532f93b93b616d7a47096dfd1dc6c\",\"venue\":\"2019 IEEE 31st International Conference on Tools with Artificial Intelligence (ICTAI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46401013\",\"name\":\"Jian-wen Jiang\"},{\"authorId\":\"153843000\",\"name\":\"Y. Cao\"},{\"authorId\":\"80834369\",\"name\":\"L. Song\"},{\"authorId\":\"50202110\",\"name\":\"Shiwei Zhang\"},{\"authorId\":\"51487081\",\"name\":\"Yunkai Li\"},{\"authorId\":\"70397730\",\"name\":\"Ziyao Xu\"},{\"authorId\":\"47506758\",\"name\":\"Q. Wu\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":null,\"name\":\"Chi Zhang\"},{\"authorId\":\"145844907\",\"name\":\"Gang Yu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"4f968688dcdd8980399265de1996a00a62034913\",\"title\":\"Human Centric Spatio-Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/4f968688dcdd8980399265de1996a00a62034913\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1470727828\",\"name\":\"Yongyang Xu\"},{\"authorId\":\"30411581\",\"name\":\"Y. Feng\"},{\"authorId\":\"145980916\",\"name\":\"Zhong Xie\"},{\"authorId\":\"1491410471\",\"name\":\"Mingyu Xie\"},{\"authorId\":\"102577932\",\"name\":\"W. Luo\"}],\"doi\":\"10.1109/ACCESS.2020.3022407\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b21c6a492e8330111ad19d9a708fb25a0c8eca7f\",\"title\":\"Action Recognition Using High Temporal Resolution 3D Neural Network Based on Dilated Convolution\",\"url\":\"https://www.semanticscholar.org/paper/b21c6a492e8330111ad19d9a708fb25a0c8eca7f\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1810.11189\",\"authors\":[{\"authorId\":\"144469723\",\"name\":\"C. Zhu\"},{\"authorId\":\"145681036\",\"name\":\"Xiao Tan\"},{\"authorId\":\"145649748\",\"name\":\"F. Zhou\"},{\"authorId\":\"48033101\",\"name\":\"Xiao Liu\"},{\"authorId\":\"39826117\",\"name\":\"Kaiyu Yue\"},{\"authorId\":\"12081764\",\"name\":\"E. Ding\"},{\"authorId\":\"50032031\",\"name\":\"Yi Ma\"}],\"doi\":\"10.1007/978-3-030-01228-1_9\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1102250a0fae62263979b32ad3c25749be9bca6b\",\"title\":\"Fine-Grained Video Categorization with Redundancy Reduction Attention\",\"url\":\"https://www.semanticscholar.org/paper/1102250a0fae62263979b32ad3c25749be9bca6b\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50854337\",\"name\":\"D. Xu\"},{\"authorId\":\"145974111\",\"name\":\"Jun Xiao\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"144899815\",\"name\":\"J. Shao\"},{\"authorId\":\"145982709\",\"name\":\"Di Xie\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1109/CVPR.2019.01058\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"558aeb7aa38cfcf8dd9951bfd24cf77972bd09aa\",\"title\":\"Self-Supervised Spatiotemporal Learning via Video Clip Order Prediction\",\"url\":\"https://www.semanticscholar.org/paper/558aeb7aa38cfcf8dd9951bfd24cf77972bd09aa\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8303994\",\"name\":\"Honggang Xie\"},{\"authorId\":\"144033365\",\"name\":\"Jinsheng Xiao\"},{\"authorId\":\"3389703\",\"name\":\"Junfeng Lei\"},{\"authorId\":\"2268470\",\"name\":\"Wenjuan Xie\"},{\"authorId\":\"1729664\",\"name\":\"Reinhard Klette\"}],\"doi\":\"10.1007/978-981-15-3651-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"42636140273d2a8bdeed36df1cd4d8b56f62270c\",\"title\":\"Pattern Recognition: ACPR 2019 Workshops, Auckland, New Zealand, November 26, 2019, Proceedings\",\"url\":\"https://www.semanticscholar.org/paper/42636140273d2a8bdeed36df1cd4d8b56f62270c\",\"venue\":\"ACPR Workshops\",\"year\":2020},{\"arxivId\":\"2003.14065\",\"authors\":[{\"authorId\":\"153216912\",\"name\":\"Dong Li\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1145/3343031.3350978\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"8370ba2cd080bbc82925106b9fa6c914928cb90b\",\"title\":\"Long Short-Term Relation Networks for Video Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/8370ba2cd080bbc82925106b9fa6c914928cb90b\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"2008.13426\",\"authors\":[{\"authorId\":\"46584859\",\"name\":\"Jiangliu Wang\"},{\"authorId\":\"2840852\",\"name\":\"Jianbo Jiao\"},{\"authorId\":\"2780029\",\"name\":\"Linchao Bao\"},{\"authorId\":\"2548483\",\"name\":\"Shengfeng He\"},{\"authorId\":\"1654091065\",\"name\":\"Wei Liu\"},{\"authorId\":\"47908910\",\"name\":\"Y. Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b38e482488359da26a25ed9ef5341cd38a2b6562\",\"title\":\"Self-supervised Video Representation Learning by Uncovering Spatio-temporal Statistics\",\"url\":\"https://www.semanticscholar.org/paper/b38e482488359da26a25ed9ef5341cd38a2b6562\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4522297\",\"name\":\"Z. Zhang\"},{\"authorId\":\"2653622\",\"name\":\"Junfu Pu\"},{\"authorId\":\"1734743\",\"name\":\"L. Zhuang\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"}],\"doi\":\"10.1109/ICIP.2019.8802972\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"f452255860e37af6090e9558e66495441141e0d5\",\"title\":\"Continuous Sign Language Recognition via Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/f452255860e37af6090e9558e66495441141e0d5\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34608005\",\"name\":\"L. Chen\"},{\"authorId\":\"144207288\",\"name\":\"R. Liu\"},{\"authorId\":\"153450634\",\"name\":\"Dongsheng Zhou\"},{\"authorId\":\"50031413\",\"name\":\"X. Yang\"},{\"authorId\":\"47835286\",\"name\":\"Qing-fang Zhang\"}],\"doi\":\"10.1186/s42492-020-00045-x\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"115880905156feef7d751840b7f59c72987b17a8\",\"title\":\"Fused behavior recognition model based on attention mechanism\",\"url\":\"https://www.semanticscholar.org/paper/115880905156feef7d751840b7f59c72987b17a8\",\"venue\":\"Vis. Comput. Ind. Biomed. Art\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"81781019\",\"name\":\"Minho Shim\"},{\"authorId\":\"40832988\",\"name\":\"Y. H. Kim\"},{\"authorId\":\"32850725\",\"name\":\"Kyungmin Kim\"},{\"authorId\":\"1754380\",\"name\":\"S. Kim\"}],\"doi\":\"10.1007/978-3-030-01267-0_25\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"041115cb5509466f7449451709387268a008aba2\",\"title\":\"Teaching Machines to Understand Baseball Games: Large-Scale Baseball Video Database for Multiple Video Understanding Tasks\",\"url\":\"https://www.semanticscholar.org/paper/041115cb5509466f7449451709387268a008aba2\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1812.06203\",\"authors\":[{\"authorId\":\"3386593\",\"name\":\"X. Dai\"},{\"authorId\":\"50702063\",\"name\":\"B. Singh\"},{\"authorId\":\"2340579\",\"name\":\"J. Ng\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/WACV.2019.00022\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"6fc28617ad940d214cbc6a9a0805d3f0047e08f7\",\"title\":\"TAN: Temporal Aggregation Network for Dense Multi-Label Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6fc28617ad940d214cbc6a9a0805d3f0047e08f7\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1388559096\",\"name\":\"J. Paulo\"},{\"authorId\":\"7627107\",\"name\":\"P. Gir\\u00e3o\"},{\"authorId\":\"143696506\",\"name\":\"P. Peixoto\"}],\"doi\":\"10.1007/978-3-030-31635-8_205\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7ef7db0c84f2dae52aa6329c72d09dc3b1b6c8d2\",\"title\":\"Multi-view Robust Gesture Recognition for Assistive Interfaces\",\"url\":\"https://www.semanticscholar.org/paper/7ef7db0c84f2dae52aa6329c72d09dc3b1b6c8d2\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51051716\",\"name\":\"B. Lu\"},{\"authorId\":\"145772858\",\"name\":\"Zhihan Lv\"},{\"authorId\":\"2508428\",\"name\":\"Songhao Zhu\"}],\"doi\":\"10.1109/CAC48633.2019.8996830\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2aea919eee1de6a618190c9e6a126aab26dcd4d6\",\"title\":\"Pseudo-3D Residual Networks Based Anomaly Detection in Surveillance Videos\",\"url\":\"https://www.semanticscholar.org/paper/2aea919eee1de6a618190c9e6a126aab26dcd4d6\",\"venue\":\"2019 Chinese Automation Congress (CAC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3386593\",\"name\":\"X. Dai\"}],\"doi\":\"10.13016/IFOP-IT5W\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0b77a9dd4cd19af8f7822993ed463debccf894ed\",\"title\":\"Modeling Deep Context in Spatial and Temporal Domain\",\"url\":\"https://www.semanticscholar.org/paper/0b77a9dd4cd19af8f7822993ed463debccf894ed\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144740100\",\"name\":\"M. Kong\"},{\"authorId\":\"47474586\",\"name\":\"Pin Lv\"}],\"doi\":\"10.1007/978-3-030-32456-8_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ac887b31488b78f9e6e1a98f3a1859454828a3ba\",\"title\":\"Global Features of Fused Frame Relationships Help Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/ac887b31488b78f9e6e1a98f3a1859454828a3ba\",\"venue\":\"ICNC-FSKD\",\"year\":2019},{\"arxivId\":\"1908.09995\",\"authors\":[{\"authorId\":\"2659862\",\"name\":\"J. Zhang\"},{\"authorId\":\"38083193\",\"name\":\"F. Shen\"},{\"authorId\":\"1390532590\",\"name\":\"Xing Xu\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1109/TIP.2020.2985219\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f3b9458522b828c39b1a7d7a9ffa15eae0789bfc\",\"title\":\"Temporal Reasoning Graph for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f3b9458522b828c39b1a7d7a9ffa15eae0789bfc\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36768094\",\"name\":\"Yitian Shao\"},{\"authorId\":\"1717829\",\"name\":\"V. Hayward\"},{\"authorId\":\"3322706\",\"name\":\"Y. Visell\"}],\"doi\":\"10.1126/sciadv.aaz1158\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eaed21b9ae4c1d1ad71ec608208850ae57c37670\",\"title\":\"Compression of dynamic tactile information in the human hand\",\"url\":\"https://www.semanticscholar.org/paper/eaed21b9ae4c1d1ad71ec608208850ae57c37670\",\"venue\":\"Science Advances\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5278544\",\"name\":\"Z. V. Johnson\"},{\"authorId\":\"40214720\",\"name\":\"L. Long\"},{\"authorId\":\"1600243424\",\"name\":\"Junyu Li\"},{\"authorId\":\"1601570617\",\"name\":\"Manu Tej Sharma Arrojwala\"},{\"authorId\":\"1601570335\",\"name\":\"Vineeth Aljapur\"},{\"authorId\":\"40763934\",\"name\":\"T. Lee\"},{\"authorId\":\"1601570575\",\"name\":\"Mark C Lowder\"},{\"authorId\":\"34192264\",\"name\":\"K. Gu\"},{\"authorId\":\"1600853953\",\"name\":\"Tucker J Lancaster\"},{\"authorId\":\"91189856\",\"name\":\"Joseph I Stockert\"},{\"authorId\":\"1601570398\",\"name\":\"Jean M Moorman\"},{\"authorId\":\"1601570828\",\"name\":\"Rachel L Lecesne\"},{\"authorId\":\"145914793\",\"name\":\"J. T. Streelman\"},{\"authorId\":\"4984693\",\"name\":\"P. T. McGrath\"}],\"doi\":\"10.1101/2020.02.27.968511\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"42a64687a44a3dc82970239bc8f5bedaca8d5618\",\"title\":\"Automated measurement of long-term bower behaviors in Lake Malawi cichlids using depth sensing and action recognition\",\"url\":\"https://www.semanticscholar.org/paper/42a64687a44a3dc82970239bc8f5bedaca8d5618\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2004.04981\",\"authors\":[{\"authorId\":\"1491233177\",\"name\":\"Yizhou Zhou\"},{\"authorId\":\"6485172\",\"name\":\"Xiaoyan Sun\"},{\"authorId\":\"2820418\",\"name\":\"Chong Luo\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"}],\"doi\":\"10.1109/cvpr42600.2020.00985\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e7ca185e3a4515471c2b9a411da9f264d55ea563\",\"title\":\"Spatiotemporal Fusion in 3D CNNs: A Probabilistic View\",\"url\":\"https://www.semanticscholar.org/paper/e7ca185e3a4515471c2b9a411da9f264d55ea563\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1912.00998\",\"authors\":[{\"authorId\":\"100880679\",\"name\":\"Chao-Yuan Wu\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"51506875\",\"name\":\"Philipp Krahenbuhl\"}],\"doi\":\"10.1109/cvpr42600.2020.00023\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b8cc28e11900e4d191651ae7234b4dbd129b1007\",\"title\":\"A Multigrid Method for Efficiently Training Video Models\",\"url\":\"https://www.semanticscholar.org/paper/b8cc28e11900e4d191651ae7234b4dbd129b1007\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2001.05661\",\"authors\":[{\"authorId\":\"143657833\",\"name\":\"Li Tao\"},{\"authorId\":\"1524733293\",\"name\":\"Xueting Wang\"},{\"authorId\":\"145572095\",\"name\":\"T. Yamasaki\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"18726788e8a74aed4420745fc420dddd3950e1c6\",\"title\":\"Rethinking Motion Representation: Residual Frames with 3D ConvNets for Better Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/18726788e8a74aed4420745fc420dddd3950e1c6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1485630780\",\"name\":\"Yanbin Hao\"},{\"authorId\":\"145063759\",\"name\":\"Hao Zhang\"},{\"authorId\":\"143977389\",\"name\":\"C. Ngo\"},{\"authorId\":\"48874063\",\"name\":\"Q. Liu\"},{\"authorId\":\"144635784\",\"name\":\"X. Hu\"}],\"doi\":\"10.1145/3394171.3413595\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"1e29826ff34cc39f04d23784ad8ec6649717e1ce\",\"title\":\"Compact Bilinear Augmented Query Structured Attention for Sport Highlights Classification\",\"url\":\"https://www.semanticscholar.org/paper/1e29826ff34cc39f04d23784ad8ec6649717e1ce\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2003.14111\",\"authors\":[{\"authorId\":null,\"name\":\"Ziyu Liu\"},{\"authorId\":\"49724467\",\"name\":\"Hongwen Zhang\"},{\"authorId\":\"2075098\",\"name\":\"Zhenghao Chen\"},{\"authorId\":\"50857536\",\"name\":\"Z. Wang\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"}],\"doi\":\"10.1109/cvpr42600.2020.00022\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4f1ae8eea7f9a4a8f894f71a94bb13e26cd65a62\",\"title\":\"Disentangling and Unifying Graph Convolutions for Skeleton-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4f1ae8eea7f9a4a8f894f71a94bb13e26cd65a62\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2002.07358\",\"authors\":[{\"authorId\":\"2283619\",\"name\":\"Peisen Zhao\"},{\"authorId\":\"3041937\",\"name\":\"Lingxi Xie\"},{\"authorId\":\"2899544\",\"name\":\"C. Ju\"},{\"authorId\":\"49890039\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a5021e7621b1aa90642208d65ea5c20ad83bbcba\",\"title\":\"Constraining Temporal Relationship for Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/a5021e7621b1aa90642208d65ea5c20ad83bbcba\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1596821842\",\"name\":\"Yao Luo\"},{\"authorId\":\"2657905\",\"name\":\"Zhong-Hui Duan\"},{\"authorId\":\"145113946\",\"name\":\"J. Tang\"}],\"doi\":\"10.1016/j.cviu.2020.103100\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6b246717103c240b44b420daf5ff6686f52c557c\",\"title\":\"Bi-branch network for dynamic scene deblurring\",\"url\":\"https://www.semanticscholar.org/paper/6b246717103c240b44b420daf5ff6686f52c557c\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1519286161\",\"name\":\"Junjie Wang\"},{\"authorId\":\"51311907\",\"name\":\"Xueyan Wen\"}],\"doi\":\"10.1088/1742-6596/1651/1/012193\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"61a78b9873ca5a0ce47eea5f4c1115dce7658d1e\",\"title\":\"A Spatio-Temporal Attention Convolution Block for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/61a78b9873ca5a0ce47eea5f4c1115dce7658d1e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2670195\",\"name\":\"L. Wang\"},{\"authorId\":\"50439333\",\"name\":\"DongSheng Liu\"},{\"authorId\":\"3246780\",\"name\":\"Rohit Puri\"},{\"authorId\":\"1711560\",\"name\":\"D. Metaxas\"}],\"doi\":\"10.1007/978-3-030-58523-5_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b26d5d20b073828898087f99b81736c0629c1798\",\"title\":\"Learning Trailer Moments in Full-Length Movies with Co-Contrastive Attention\",\"url\":\"https://www.semanticscholar.org/paper/b26d5d20b073828898087f99b81736c0629c1798\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2653622\",\"name\":\"Junfu Pu\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"}],\"doi\":\"10.24963/ijcai.2018/123\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d8ef2cbaaf8281600135670d44dda3acd82e1aa\",\"title\":\"Dilated Convolutional Network with Iterative Optimization for Continuous Sign Language Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9d8ef2cbaaf8281600135670d44dda3acd82e1aa\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":\"1804.08274\",\"authors\":[{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"47636228\",\"name\":\"H. Chao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2018.00782\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"19d7f83c3d7147f0eed1e1471438066eb4fe51fb\",\"title\":\"Jointly Localizing and Describing Events for Dense Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/19d7f83c3d7147f0eed1e1471438066eb4fe51fb\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46698300\",\"name\":\"Ji Lin\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"143840277\",\"name\":\"Song Han\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5925a25dfe107c49c636eccb8f9fd1aeef7b438c\",\"title\":\"Temporal Shift Module for Efficient Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/5925a25dfe107c49c636eccb8f9fd1aeef7b438c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"34779291\",\"name\":\"Fuchen Long\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"153216896\",\"name\":\"D. Li\"},{\"authorId\":\"153040576\",\"name\":\"T. Mei\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6c3ecbfb72986111f3489704e9fe4a12175b0240\",\"title\":\"MSR Asia MSM at ActivityNet Challenge 2017: Trimmed Action Recognition, Temporal Action Proposals and Dense-Captioning Events in Videos\",\"url\":\"https://www.semanticscholar.org/paper/6c3ecbfb72986111f3489704e9fe4a12175b0240\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2653622\",\"name\":\"Junfu Pu\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"}],\"doi\":\"10.1109/CVPR.2019.00429\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"714df3e97817ec56b8dbc7217155adadf2a0487f\",\"title\":\"Iterative Alignment Network for Continuous Sign Language Recognition\",\"url\":\"https://www.semanticscholar.org/paper/714df3e97817ec56b8dbc7217155adadf2a0487f\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"08d9bea632aa3e32fe6b5436b147edacb69e4660\",\"title\":\"POLITECNICO DI TORINO Master of Science in Mathematical Engineering Deep Learning Algorithms for Video Classification: Application on Real-Time Hand Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/08d9bea632aa3e32fe6b5436b147edacb69e4660\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39635018\",\"name\":\"Xiaolong Wang\"}],\"doi\":\"10.1184/R1/9823919\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dcd6c05a5ef1e6d9247f3eb0bff91ac0c3d7ac01\",\"title\":\"Learning and Reasoning with Visual Correspondence in Time\",\"url\":\"https://www.semanticscholar.org/paper/dcd6c05a5ef1e6d9247f3eb0bff91ac0c3d7ac01\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2007.00394\",\"authors\":[{\"authorId\":\"1410307807\",\"name\":\"Yizhak Ben-Shabat\"},{\"authorId\":\"1490933487\",\"name\":\"Xin Yu\"},{\"authorId\":\"9120887\",\"name\":\"F. Saleh\"},{\"authorId\":\"145185576\",\"name\":\"Dylan Campbell\"},{\"authorId\":\"145112187\",\"name\":\"Cristian Rodriguez-Opazo\"},{\"authorId\":\"71200893\",\"name\":\"H. Li\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"947b868aa1c38940df280ebeb8077d4e729fb988\",\"title\":\"The IKEA ASM Dataset: Understanding People Assembling Furniture through Actions, Objects and Pose\",\"url\":\"https://www.semanticscholar.org/paper/947b868aa1c38940df280ebeb8077d4e729fb988\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47557746\",\"name\":\"Y. Chen\"},{\"authorId\":\"2175693\",\"name\":\"He-Fei Ling\"},{\"authorId\":\"1722881\",\"name\":\"Jiazhong Chen\"},{\"authorId\":\"152318075\",\"name\":\"Lei Wu\"},{\"authorId\":\"1753219181\",\"name\":\"Yuxuan Shi\"}],\"doi\":\"10.1109/IJCNN48605.2020.9207404\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e2807495123a402bee172b9697f3a98a2351d134\",\"title\":\"Lightweight Action Recognition with Sequence-Specific Global Context\",\"url\":\"https://www.semanticscholar.org/paper/e2807495123a402bee172b9697f3a98a2351d134\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34779291\",\"name\":\"Fuchen Long\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"40434674\",\"name\":\"X. Tian\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/TMM.2019.2943204\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"881103d13eda11f231f88205b7ed2c6f6c8eea1b\",\"title\":\"Coarse-to-Fine Localization of Temporal Action Proposals\",\"url\":\"https://www.semanticscholar.org/paper/881103d13eda11f231f88205b7ed2c6f6c8eea1b\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52289773\",\"name\":\"Jinhyung Kim\"},{\"authorId\":\"33532407\",\"name\":\"S. Cha\"},{\"authorId\":\"1405197098\",\"name\":\"Dongyoon Wee\"},{\"authorId\":\"40656963\",\"name\":\"Soonmin Bae\"},{\"authorId\":\"1769295\",\"name\":\"Junmo Kim\"}],\"doi\":\"10.1109/cvpr42600.2020.01212\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"96c0ba91d650c571d20961f1fae0560f8962afa5\",\"title\":\"Regularization on Spatio-Temporally Smoothed Feature for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/96c0ba91d650c571d20961f1fae0560f8962afa5\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1911.04127\",\"authors\":[{\"authorId\":\"51266875\",\"name\":\"Chuming Lin\"},{\"authorId\":\"50683988\",\"name\":\"J. Li\"},{\"authorId\":null,\"name\":\"Yabiao Wang\"},{\"authorId\":\"144970872\",\"name\":\"Ying Tai\"},{\"authorId\":\"9393671\",\"name\":\"Donghao Luo\"},{\"authorId\":\"20595955\",\"name\":\"Zhipeng Cui\"},{\"authorId\":\"1978245\",\"name\":\"Chengjie Wang\"},{\"authorId\":\"49298244\",\"name\":\"Jilin Li\"},{\"authorId\":\"1835006\",\"name\":\"Feiyue Huang\"},{\"authorId\":\"145592288\",\"name\":\"Rongrong Ji\"}],\"doi\":\"10.1609/AAAI.V34I07.6815\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e2534a3c894c93053341d514967c45c78657969c\",\"title\":\"Fast Learning of Temporal Action Proposal via Dense Boundary Generator\",\"url\":\"https://www.semanticscholar.org/paper/e2534a3c894c93053341d514967c45c78657969c\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1391201846\",\"name\":\"Jianyu Chen\"},{\"authorId\":\"144749222\",\"name\":\"J. Kong\"},{\"authorId\":\"1801474\",\"name\":\"Hui Sun\"},{\"authorId\":\"49507094\",\"name\":\"H. Xu\"},{\"authorId\":\"4058024\",\"name\":\"X. Liu\"},{\"authorId\":\"1774877\",\"name\":\"Ying-hua Lu\"},{\"authorId\":\"5858971\",\"name\":\"Caixia Zheng\"}],\"doi\":\"10.3390/s20113126\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"12afacc80852a3cffa18722ef43c0d82746ff66c\",\"title\":\"Spatiotemporal Interaction Residual Networks with Pseudo3D for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/12afacc80852a3cffa18722ef43c0d82746ff66c\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1564031469\",\"name\":\"Aayush Jung Rana\"},{\"authorId\":\"82021814\",\"name\":\"Praveen Tirupattur\"},{\"authorId\":\"9247631\",\"name\":\"M. N. Rizve\"},{\"authorId\":\"7839191\",\"name\":\"K. Duarte\"},{\"authorId\":\"2935412\",\"name\":\"U. Demir\"},{\"authorId\":\"2116440\",\"name\":\"Y. Rawat\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d4b8626336566f34c7e1d17ddf7b144636812c18\",\"title\":\"An Online System for Real-Time Activity Detection in Untrimmed Surveillance Videos\",\"url\":\"https://www.semanticscholar.org/paper/d4b8626336566f34c7e1d17ddf7b144636812c18\",\"venue\":\"TRECVID\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50621207\",\"name\":\"Q. Wang\"},{\"authorId\":\"48090391\",\"name\":\"Qiang Li\"},{\"authorId\":\"40286455\",\"name\":\"Xuelong Li\"}],\"doi\":\"10.1109/tie.2020.3038096\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c57aa100383d7c7d65d556a30e8a61d5fd9e28ba\",\"title\":\"Hyperspectral Image Super-Resolution Using Spectrum and Feature Context\",\"url\":\"https://www.semanticscholar.org/paper/c57aa100383d7c7d65d556a30e8a61d5fd9e28ba\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46331912\",\"name\":\"M. Liu\"},{\"authorId\":\"89507637\",\"name\":\"X. Chen\"},{\"authorId\":\"144781413\",\"name\":\"Y. Zhang\"},{\"authorId\":\"48513361\",\"name\":\"Y. Li\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"dc7de1c65a52db271016313980ae577d19aace24\",\"title\":\"Paying More Attention to Motion: Attention Distillation for Learning Video Representations\",\"url\":\"https://www.semanticscholar.org/paper/dc7de1c65a52db271016313980ae577d19aace24\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1903.07067\",\"authors\":[{\"authorId\":\"2978590\",\"name\":\"Rohan Ghosh\"},{\"authorId\":\"1712264\",\"name\":\"A. Gupta\"},{\"authorId\":\"46892885\",\"name\":\"A. N. Silva\"},{\"authorId\":\"40136476\",\"name\":\"Alcimar Soares\"},{\"authorId\":\"145146201\",\"name\":\"N. Thakor\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ad0d13bee5171c60a8e65d44687723ad8008b323\",\"title\":\"Spatiotemporal Filtering for Event-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ad0d13bee5171c60a8e65d44687723ad8008b323\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2547290\",\"name\":\"Jingwei Ji\"},{\"authorId\":\"8983218\",\"name\":\"S. Buch\"},{\"authorId\":\"144106940\",\"name\":\"A. Soto\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1007/978-3-030-01225-0_43\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"62c1a6558a2a0d5fd6df4c0fec99dd9027d1c448\",\"title\":\"End-to-End Joint Semantic Segmentation of Actors and Actions in Video\",\"url\":\"https://www.semanticscholar.org/paper/62c1a6558a2a0d5fd6df4c0fec99dd9027d1c448\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144015161\",\"name\":\"Y. Fu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"01aecbebc76d494853f6f525f4d285564e697fa7\",\"title\":\"Human Action Recognition and Prediction: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/01aecbebc76d494853f6f525f4d285564e697fa7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1912.04075\",\"authors\":[{\"authorId\":\"46933964\",\"name\":\"Gabrielle Ras\"},{\"authorId\":\"2396027\",\"name\":\"L. Ambrogioni\"},{\"authorId\":\"80777440\",\"name\":\"U. G\\u00fc\\u00e7l\\u00fc\"},{\"authorId\":\"143799386\",\"name\":\"M. V. Gerven\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4f90ba2a26a7647eb9d3d7936ce596cd138d1dd9\",\"title\":\"Temporal Factorization of 3D Convolutional Kernels\",\"url\":\"https://www.semanticscholar.org/paper/4f90ba2a26a7647eb9d3d7936ce596cd138d1dd9\",\"venue\":\"BNAIC/BENELEARN\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47842072\",\"name\":\"M. Liu\"},{\"authorId\":\"1774797\",\"name\":\"Fanyang Meng\"},{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"2525392\",\"name\":\"S. Wu\"}],\"doi\":\"10.1609/AAAI.V33I01.33018762\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"32c216b09b1208585a70cff674460735bd9939fe\",\"title\":\"Joint Dynamic Pose Image and Space Time Reversal for Human Action Recognition from Videos\",\"url\":\"https://www.semanticscholar.org/paper/32c216b09b1208585a70cff674460735bd9939fe\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"2011.07557\",\"authors\":[{\"authorId\":\"80007827\",\"name\":\"Dalu Feng\"},{\"authorId\":\"7389074\",\"name\":\"S. Yang\"},{\"authorId\":\"144481158\",\"name\":\"S. Shan\"},{\"authorId\":\"51069511\",\"name\":\"X. Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9bd00f2545b89e538a524bf2330ba32d39d9bfcd\",\"title\":\"Learn an Effective Lip Reading Model without Pains\",\"url\":\"https://www.semanticscholar.org/paper/9bd00f2545b89e538a524bf2330ba32d39d9bfcd\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31595791\",\"name\":\"J. Li\"},{\"authorId\":\"6820648\",\"name\":\"Xianglong Liu\"},{\"authorId\":\"150341144\",\"name\":\"Wenxuan Zhang\"},{\"authorId\":\"47473953\",\"name\":\"Mingyuan Zhang\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":\"10.1109/TMM.2020.2965434\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2ea173f972d39b8631e9ac8fe59a947c70ba31e3\",\"title\":\"Spatio-Temporal Attention Networks for Action Recognition and Detection\",\"url\":\"https://www.semanticscholar.org/paper/2ea173f972d39b8631e9ac8fe59a947c70ba31e3\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5998740\",\"name\":\"T. Wang\"},{\"authorId\":\"145906066\",\"name\":\"Yang Chen\"},{\"authorId\":\"47896919\",\"name\":\"Hongqiang Lv\"},{\"authorId\":\"1680217\",\"name\":\"Jing Teng\"},{\"authorId\":\"2103629\",\"name\":\"H. Snoussi\"},{\"authorId\":\"152412578\",\"name\":\"Fei Tao\"}],\"doi\":\"10.1109/TII.2020.2997032\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c33b896f43e41d3cf04fc8ad53f88de985666107\",\"title\":\"Online Detection of Action Start via Soft Computing for Smart City\",\"url\":\"https://www.semanticscholar.org/paper/c33b896f43e41d3cf04fc8ad53f88de985666107\",\"venue\":\"IEEE Transactions on Industrial Informatics\",\"year\":2021},{\"arxivId\":\"1911.01059\",\"authors\":[{\"authorId\":\"145081300\",\"name\":\"L. Zhu\"},{\"authorId\":\"1891221\",\"name\":\"Qi She\"},{\"authorId\":\"152569618\",\"name\":\"Lidan Zhang\"},{\"authorId\":\"113192074\",\"name\":\"Ping Guo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"28a62b2cf1ec46ca16c6a76431759c43d086ca1b\",\"title\":\"A Spectral Nonlocal Block for Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/28a62b2cf1ec46ca16c6a76431759c43d086ca1b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46324489\",\"name\":\"Qing Zhang\"},{\"authorId\":\"2849542\",\"name\":\"H. Yan\"},{\"authorId\":\"46660013\",\"name\":\"L. Wang\"}],\"doi\":\"10.1007/978-3-030-31654-9_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e78f395fe206fe3db5efb64bb891bee23b0fa2cf\",\"title\":\"Multi-scale Spatial-Temporal Attention for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e78f395fe206fe3db5efb64bb891bee23b0fa2cf\",\"venue\":\"PRCV\",\"year\":2019},{\"arxivId\":\"1807.02929\",\"authors\":[{\"authorId\":\"28891563\",\"name\":\"Jia-Xing Zhong\"},{\"authorId\":null,\"name\":\"Nannan Li\"},{\"authorId\":\"33559754\",\"name\":\"Weijie Kong\"},{\"authorId\":\"1689115\",\"name\":\"Tao Zhang\"},{\"authorId\":\"50289966\",\"name\":\"Thomas H. Li\"},{\"authorId\":\"47949235\",\"name\":\"G. Li\"}],\"doi\":\"10.1145/3240508.3240511\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d66b80614f873bab0adbb7b1902fcff39fe63fdd\",\"title\":\"Step-by-step Erasion, One-by-one Collection: A Weakly Supervised Temporal Action Detector\",\"url\":\"https://www.semanticscholar.org/paper/d66b80614f873bab0adbb7b1902fcff39fe63fdd\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1911.11462\",\"authors\":[{\"authorId\":\"97375393\",\"name\":\"Mengmeng Xu\"},{\"authorId\":null,\"name\":\"Chen Zhao\"},{\"authorId\":\"144723836\",\"name\":\"D. Rojas\"},{\"authorId\":\"35869086\",\"name\":\"A. Thabet\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1109/cvpr42600.2020.01017\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"720abe3b7a1cbec9e9a14c65e67ee5ec58679893\",\"title\":\"G-TAD: Sub-Graph Localization for Temporal Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/720abe3b7a1cbec9e9a14c65e67ee5ec58679893\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2001.03569\",\"authors\":[{\"authorId\":\"7667912\",\"name\":\"L. Duan\"},{\"authorId\":\"41127426\",\"name\":\"Jiaying Liu\"},{\"authorId\":\"1898172\",\"name\":\"W. Yang\"},{\"authorId\":\"50592933\",\"name\":\"Tiejun Huang\"},{\"authorId\":\"48385803\",\"name\":\"W. Gao\"}],\"doi\":\"10.1109/TIP.2020.3016485\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4c1007dd5518ac0ce41f2d8f72ed8c5fd4971caf\",\"title\":\"Video Coding for Machines: A Paradigm of Collaborative Compression and Intelligent Analytics\",\"url\":\"https://www.semanticscholar.org/paper/4c1007dd5518ac0ce41f2d8f72ed8c5fd4971caf\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1811.10575\",\"authors\":[{\"authorId\":\"3349165\",\"name\":\"Pallabi Ghosh\"},{\"authorId\":\"153462555\",\"name\":\"Yi Yao\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"},{\"authorId\":\"1696401\",\"name\":\"Ajay Divakaran\"}],\"doi\":\"10.1109/WACV45572.2020.9093361\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3efc52b9a5190f7f24febb01a969bfdeb804e5fe\",\"title\":\"Stacked Spatio-Temporal Graph Convolutional Networks for Action Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/3efc52b9a5190f7f24febb01a969bfdeb804e5fe\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1564031469\",\"name\":\"A. J. Rana\"},{\"authorId\":\"2116440\",\"name\":\"Y. Rawat\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f6dd3595637c470f7f008b80a4db131da929e35e\",\"title\":\"We don't Need Thousand Proposals: Single Shot Actor-Action Detection in Videos\",\"url\":\"https://www.semanticscholar.org/paper/f6dd3595637c470f7f008b80a4db131da929e35e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"70171641\",\"name\":\"Ashish A. Patel\"},{\"authorId\":\"40056738\",\"name\":\"G. Merlino\"},{\"authorId\":\"2539936\",\"name\":\"D. Bruneo\"},{\"authorId\":\"1721699\",\"name\":\"A. Puliafito\"},{\"authorId\":\"144144239\",\"name\":\"O. P. Vyas\"},{\"authorId\":\"3191045\",\"name\":\"Muneendra Ojha\"}],\"doi\":\"10.3233/sw-200393\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5871821e9216016a075acb999ca3b798209b0c49\",\"title\":\"Video representation and suspicious event detection using semantic technologies\",\"url\":\"https://www.semanticscholar.org/paper/5871821e9216016a075acb999ca3b798209b0c49\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2012.09434\",\"authors\":[{\"authorId\":\"48031771\",\"name\":\"X. Liu\"},{\"authorId\":\"72285615\",\"name\":\"Yao Hu\"},{\"authorId\":\"98807701\",\"name\":\"Song Bai\"},{\"authorId\":\"1430778662\",\"name\":\"Fei Ding\"},{\"authorId\":\"145905113\",\"name\":\"X. Bai\"},{\"authorId\":null,\"name\":\"Philip H. S. Torr\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"db1b0d0e70f29b0018d1a9462d98dd39559f3e4a\",\"title\":\"Multi-shot Temporal Event Localization: a Benchmark\",\"url\":\"https://www.semanticscholar.org/paper/db1b0d0e70f29b0018d1a9462d98dd39559f3e4a\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":6070160,\"doi\":\"10.1109/ICCV.2017.590\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":82,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"024d037d46ae933c7e12fd16af61953c7161773a\",\"references\":[{\"arxivId\":\"1604.04494\",\"authors\":[{\"authorId\":\"2668759\",\"name\":\"G. Varol\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/TPAMI.2017.2712608\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"47e3ef70f2539386bcef604097fa9235246c6d53\",\"title\":\"Long-Term Temporal Convolutions for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/47e3ef70f2539386bcef604097fa9235246c6d53\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"153082769\",\"name\":\"Q. Li\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"153040576\",\"name\":\"T. Mei\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6999e84899bdd967532463e8cbb99de423ad7faa\",\"title\":\"MSR Asia MSM at THUMOS Challenge 2015\",\"url\":\"https://www.semanticscholar.org/paper/6999e84899bdd967532463e8cbb99de423ad7faa\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"E. Mansimov\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"A dataset of 101 human action classes from videos in the wild\",\"url\":\"\",\"venue\":\"\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743600\",\"name\":\"S. Ji\"},{\"authorId\":\"143836295\",\"name\":\"W. Xu\"},{\"authorId\":\"41216159\",\"name\":\"Ming Yang\"},{\"authorId\":\"144782042\",\"name\":\"Kai Yu\"}],\"doi\":\"10.1109/TPAMI.2012.59\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"80bfcf1be2bf1b95cc6f36d229665cdf22d76190\",\"title\":\"3D Convolutional Neural Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/80bfcf1be2bf1b95cc6f36d229665cdf22d76190\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2013.441\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d721f4d64b8e722222c876f0a0f226ed49476347\",\"title\":\"Action Recognition with Improved Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/d721f4d64b8e722222c876f0a0f226ed49476347\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":\"1611.05725\",\"authors\":[{\"authorId\":\"8442655\",\"name\":\"Xingcheng Zhang\"},{\"authorId\":\"2675450\",\"name\":\"Zhizhong Li\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/CVPR.2017.415\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aad34665649953fa4bbacdc6eff4edb5408df6b3\",\"title\":\"PolyNet: A Pursuit of Structural Diversity in Very Deep Networks\",\"url\":\"https://www.semanticscholar.org/paper/aad34665649953fa4bbacdc6eff4edb5408df6b3\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/CVPR.2015.7298698\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"0a28efacb92d16e6e0dd4d87b5aca91b28be8853\",\"title\":\"ActivityNet: A large-scale video benchmark for human activity understanding\",\"url\":\"https://www.semanticscholar.org/paper/0a28efacb92d16e6e0dd4d87b5aca91b28be8853\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1212.0402\",\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"title\":\"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\",\"url\":\"https://www.semanticscholar.org/paper/da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Y.-G. Jiang\"},{\"authorId\":null,\"name\":\"Z. Wu\"},{\"authorId\":null,\"name\":\"J. Wang\"},{\"authorId\":null,\"name\":\"X. Xue\"},{\"authorId\":null,\"name\":\"S.-F. Chang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"ploiting feature and class relationships in video categorization with regularized deep neural networks\",\"url\":\"\",\"venue\":\"IEEE Trans . on PAMI\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1723883\",\"name\":\"F. Perronnin\"},{\"authorId\":\"143995438\",\"name\":\"J. S\\u00e1nchez\"},{\"authorId\":\"1722052\",\"name\":\"Thomas Mensink\"}],\"doi\":\"10.1007/978-3-642-15561-1_11\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"39f3b1804b8df5be645a1dcb4a876e128385d9be\",\"title\":\"Improving the Fisher Kernel for Large-Scale Image Classification\",\"url\":\"https://www.semanticscholar.org/paper/39f3b1804b8df5be645a1dcb4a876e128385d9be\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"N. Srivastava\"},{\"authorId\":null,\"name\":\"E. Mansimov\"},{\"authorId\":null,\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"A dataset of 101 human action classes from videos in the wild\",\"url\":\"\",\"venue\":\"\",\"year\":2012},{\"arxivId\":\"1502.04681\",\"authors\":[{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"2711409\",\"name\":\"Elman Mansimov\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"title\":\"Unsupervised Learning of Video Representations using LSTMs\",\"url\":\"https://www.semanticscholar.org/paper/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1406.2199\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"title\":\"Two-Stream Convolutional Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1404610182\",\"name\":\"Orit Kliper-Gross\"},{\"authorId\":\"2916582\",\"name\":\"Yaron Gurovich\"},{\"authorId\":\"1756099\",\"name\":\"Tal Hassner\"},{\"authorId\":\"145128144\",\"name\":\"L. Wolf\"}],\"doi\":\"10.1007/978-3-642-33783-3_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"993a2c02a5a3263b3047202e3d86aa9a0dd6ebfe\",\"title\":\"Motion Interchange Patterns for Action Recognition in Unconstrained Videos\",\"url\":\"https://www.semanticscholar.org/paper/993a2c02a5a3263b3047202e3d86aa9a0dd6ebfe\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"3502855\",\"name\":\"M. Marszalek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"3261451\",\"name\":\"Benjamin Rozenfeld\"}],\"doi\":\"10.1109/CVPR.2008.4587756\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f86767732f76f478d5845f2e59f99ba106e9265\",\"title\":\"Learning realistic human actions from movies\",\"url\":\"https://www.semanticscholar.org/paper/0f86767732f76f478d5845f2e59f99ba106e9265\",\"venue\":\"2008 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3048032\",\"name\":\"P. Scovanner\"},{\"authorId\":\"38245610\",\"name\":\"Saad Ali\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1145/1291233.1291311\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fe1b412ce7a4a36664734c4cad97b939b6ea6015\",\"title\":\"A 3-dimensional sift descriptor and its application to action recognition\",\"url\":\"https://www.semanticscholar.org/paper/fe1b412ce7a4a36664734c4cad97b939b6ea6015\",\"venue\":\"ACM Multimedia\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3150825\",\"name\":\"K. Derpanis\"},{\"authorId\":\"3330606\",\"name\":\"Matthieu Lecce\"},{\"authorId\":\"1751586\",\"name\":\"Kostas Daniilidis\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":\"10.1109/CVPR.2012.6247815\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"6af4bad878d543d9ac83fbcaecdfa0703037d6e4\",\"title\":\"Dynamic scene understanding: The role of orientation features in space and time in scene classification\",\"url\":\"https://www.semanticscholar.org/paper/6af4bad878d543d9ac83fbcaecdfa0703037d6e4\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":\"1505.04868\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1109/CVPR.2015.7299059\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"df658828fb4146877f1031ec9d07052f7eb31186\",\"title\":\"Action recognition with trajectory-pooled deep-convolutional descriptors\",\"url\":\"https://www.semanticscholar.org/paper/df658828fb4146877f1031ec9d07052f7eb31186\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Karpathy\"},{\"authorId\":null,\"name\":\"S. Shetty\"},{\"authorId\":null,\"name\":\"T. Leung\"},{\"authorId\":null,\"name\":\"R. Sukthankar\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"ploiting feature and class relationships in video categorization with regularized deep neural networks\",\"url\":\"\",\"venue\":\"IEEE Trans . on PAMI\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1404610182\",\"name\":\"Orit Kliper-Gross\"},{\"authorId\":\"1756099\",\"name\":\"Tal Hassner\"},{\"authorId\":\"145128144\",\"name\":\"L. Wolf\"}],\"doi\":\"10.1109/TPAMI.2011.209\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1fbde67e87890e5d45864e66edb86136fbdbe20e\",\"title\":\"The Action Similarity Labeling Challenge\",\"url\":\"https://www.semanticscholar.org/paper/1fbde67e87890e5d45864e66edb86136fbdbe20e\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2909350\",\"name\":\"Alexander Kl\\u00e4ser\"},{\"authorId\":\"3502855\",\"name\":\"M. Marszalek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.5244/C.22.99\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"56e95f8efb7dbbc0b1820eaf365edc6f3b3f6719\",\"title\":\"A Spatio-Temporal Descriptor Based on 3D-Gradients\",\"url\":\"https://www.semanticscholar.org/paper/56e95f8efb7dbbc0b1820eaf365edc6f3b3f6719\",\"venue\":\"BMVC\",\"year\":2008},{\"arxivId\":\"1409.4842\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"46641766\",\"name\":\"W. Liu\"},{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"},{\"authorId\":\"48840704\",\"name\":\"Scott Reed\"},{\"authorId\":\"1838674\",\"name\":\"Dragomir Anguelov\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"39863668\",\"name\":\"Andrew Rabinovich\"}],\"doi\":\"10.1109/CVPR.2015.7298594\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"title\":\"Going deeper with convolutions\",\"url\":\"https://www.semanticscholar.org/paper/e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"3205375\",\"name\":\"T. Lindeberg\"}],\"doi\":\"10.1109/ICCV.2003.1238378\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f90d79809325d2b78e35a79ecb372407f81b3993\",\"title\":\"Space-time interest points\",\"url\":\"https://www.semanticscholar.org/paper/f90d79809325d2b78e35a79ecb372407f81b3993\",\"venue\":\"Proceedings Ninth IEEE International Conference on Computer Vision\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1c46943103bd7b7a2c7be86859995a4144d1938b\",\"title\":\"Visualizing Data using t-SNE\",\"url\":\"https://www.semanticscholar.org/paper/1c46943103bd7b7a2c7be86859995a4144d1938b\",\"venue\":\"\",\"year\":2008},{\"arxivId\":\"1611.09502\",\"authors\":[{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2017.435\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ab4c97575b17b9ce9b7523743ce7cae4fa9572e5\",\"title\":\"Deep Quantization: Encoding Convolutional Activations with Deep Generative Model\",\"url\":\"https://www.semanticscholar.org/paper/ab4c97575b17b9ce9b7523743ce7cae4fa9572e5\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/ICCV.2015.510\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"title\":\"Learning Spatiotemporal Features with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37335907\",\"name\":\"G. Willems\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-540-88688-4_48\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"117d576d72515e900e6fc5a4a0e7f1d0142a8924\",\"title\":\"An Efficient Dense and Scale-Invariant Spatio-Temporal Interest Point Detector\",\"url\":\"https://www.semanticscholar.org/paper/117d576d72515e900e6fc5a4a0e7f1d0142a8924\",\"venue\":\"ECCV\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"I Laptev\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"On space-time interest points. International journal of computer vision\",\"url\":\"\",\"venue\":\"\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34711525\",\"name\":\"Nitesh Shroff\"},{\"authorId\":\"143655174\",\"name\":\"P. Turaga\"},{\"authorId\":\"9215658\",\"name\":\"R. Chellappa\"}],\"doi\":\"10.1109/CVPR.2010.5539864\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"0db36bf08140d53807595b6313201a7339470cfe\",\"title\":\"Moving vistas: Exploiting motion for describing scenes\",\"url\":\"https://www.semanticscholar.org/paper/0db36bf08140d53807595b6313201a7339470cfe\",\"venue\":\"2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition\",\"year\":2010},{\"arxivId\":\"1604.06573\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2016.213\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d9aced120e530484609164c836da64548693484\",\"title\":\"Convolutional Two-Stream Network Fusion for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9d9aced120e530484609164c836da64548693484\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1608.00859\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-319-46484-8_2\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"title\":\"Temporal Segment Networks: Towards Good Practices for Deep Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1510.00562\",\"authors\":[{\"authorId\":\"41191188\",\"name\":\"Lin Sun\"},{\"authorId\":\"2370507\",\"name\":\"K. Jia\"},{\"authorId\":\"1739816\",\"name\":\"D. Yeung\"},{\"authorId\":\"2131088\",\"name\":\"B. Shi\"}],\"doi\":\"10.1109/ICCV.2015.522\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"95561aec9f00cdf5346e627574e1a022eda3e4f5\",\"title\":\"Human Action Recognition Using Factorized Spatio-Temporal Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/95561aec9f00cdf5346e627574e1a022eda3e4f5\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"143740449\",\"name\":\"Q. Peng\"},{\"authorId\":\"51251184\",\"name\":\"Q. Wang\"}],\"doi\":\"10.1109/LSP.2014.2320530\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e53b64ad300a11094a8fc43ef93c4e3146d5f87e\",\"title\":\"Large Margin Dimensionality Reduction for Action Similarity Labeling\",\"url\":\"https://www.semanticscholar.org/paper/e53b64ad300a11094a8fc43ef93c4e3146d5f87e\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48933900\",\"name\":\"Q. Li\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1007/s13735-016-0117-4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6f5e40d483e0ccbd3087b4da2e2715d774457665\",\"title\":\"Learning hierarchical video representation for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/6f5e40d483e0ccbd3087b4da2e2715d774457665\",\"venue\":\"International Journal of Multimedia Information Retrieval\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"G. Toderici A. Karpathy\"},{\"authorId\":null,\"name\":\"S. Shetty\"},{\"authorId\":null,\"name\":\"T. Leung\"},{\"authorId\":null,\"name\":\"R. Sukthankar\"},{\"authorId\":null,\"name\":\"L. Fei-Fei\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"ploiting feature and class relationships in video categorization with regularized deep neural networks\",\"url\":\"\",\"venue\":\"IEEE Trans . on PAMI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2909350\",\"name\":\"Alexander Kl\\u00e4ser\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"1689269\",\"name\":\"C. Liu\"}],\"doi\":\"10.1109/CVPR.2011.5995407\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3afbb0e64fcb70496b44b30b76fac9456cc51e34\",\"title\":\"Action recognition by dense trajectories\",\"url\":\"https://www.semanticscholar.org/paper/3afbb0e64fcb70496b44b30b76fac9456cc51e34\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":\"1503.08909\",\"authors\":[{\"authorId\":\"2340579\",\"name\":\"J. Ng\"},{\"authorId\":\"3308897\",\"name\":\"Matthew J. Hausknecht\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"49519592\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"3089272\",\"name\":\"Rajat Monga\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"}],\"doi\":\"10.1109/CVPR.2015.7299101\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5418b2a482720e013d487a385c26fae0f017c6a6\",\"title\":\"Beyond short snippets: Deep networks for video classification\",\"url\":\"https://www.semanticscholar.org/paper/5418b2a482720e013d487a385c26fae0f017c6a6\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":\"10.1109/CVPR.2014.343\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f6b17876e48b194184243a93677c0c9ffc14cd9b\",\"title\":\"Bags of Spacetime Energies for Dynamic Scene Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f6b17876e48b194184243a93677c0c9ffc14cd9b\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2121584\",\"name\":\"Wangjiang Zhu\"},{\"authorId\":\"145815850\",\"name\":\"Jie Hu\"},{\"authorId\":\"143847421\",\"name\":\"Gang Sun\"},{\"authorId\":\"47300766\",\"name\":\"X. Cao\"},{\"authorId\":\"143970608\",\"name\":\"Y. Qiao\"}],\"doi\":\"10.1109/CVPR.2016.219\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4c822785c29ceaf67a0de9c699716c94fefbd37d\",\"title\":\"A Key Volume Mining Deep Framework for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4c822785c29ceaf67a0de9c699716c94fefbd37d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"152821938\",\"name\":\"Sanketh Shetty\"},{\"authorId\":\"120906511\",\"name\":\"T. Leung\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2014.223\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"title\":\"Large-Scale Video Classification with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26392036\",\"name\":\"Christian Theriault\"},{\"authorId\":\"1728523\",\"name\":\"N. Thome\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"}],\"doi\":\"10.1109/CVPR.2013.336\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"02ce7baee9d67bb3dff10fea2005017c7ffa066a\",\"title\":\"Dynamic Scene Classification: Learning Motion Descriptors with Slow Features Analysis\",\"url\":\"https://www.semanticscholar.org/paper/02ce7baee9d67bb3dff10fea2005017c7ffa066a\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48933900\",\"name\":\"Q. Li\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1145/2911996.2912001\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1128a4f57148cec96c0ef4ae3b5a0fbf07efbad9\",\"title\":\"Action Recognition by Learning Deep Multi-Granular Spatio-Temporal Video Representation\",\"url\":\"https://www.semanticscholar.org/paper/1128a4f57148cec96c0ef4ae3b5a0fbf07efbad9\",\"venue\":\"ICMR\",\"year\":2016},{\"arxivId\":\"1611.02155\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5f4d2f6ad967f7c9369c04e75cda08f12cb8afbd\",\"title\":\"Spatiotemporal Residual Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5f4d2f6ad967f7c9369c04e75cda08f12cb8afbd\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1502.07209\",\"authors\":[{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"49606697\",\"name\":\"J. Wang\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1109/TPAMI.2017.2670560\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1a0a01c78b746f44575f0c4f297e1621eb212dde\",\"title\":\"Exploiting Feature and Class Relationships in Video Categorization with Regularized Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/1a0a01c78b746f44575f0c4f297e1621eb212dde\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018}],\"title\":\"Learning Spatio-Temporal Representation with Pseudo-3D Residual Networks\",\"topics\":[{\"topic\":\"Convolution\",\"topicId\":\"571\",\"url\":\"https://www.semanticscholar.org/topic/571\"},{\"topic\":\"2.5D\",\"topicId\":\"33594\",\"url\":\"https://www.semanticscholar.org/topic/33594\"},{\"topic\":\"Feature learning\",\"topicId\":\"20551\",\"url\":\"https://www.semanticscholar.org/topic/20551\"},{\"topic\":\"Convolutional neural network\",\"topicId\":\"29860\",\"url\":\"https://www.semanticscholar.org/topic/29860\"},{\"topic\":\"Optical flow\",\"topicId\":\"26430\",\"url\":\"https://www.semanticscholar.org/topic/26430\"},{\"topic\":\"2D Filters\",\"topicId\":\"559569\",\"url\":\"https://www.semanticscholar.org/topic/559569\"},{\"topic\":\"Computer vision\",\"topicId\":\"5332\",\"url\":\"https://www.semanticscholar.org/topic/5332\"},{\"topic\":\"Algorithmic efficiency\",\"topicId\":\"19973\",\"url\":\"https://www.semanticscholar.org/topic/19973\"},{\"topic\":\"Performance\",\"topicId\":\"3097\",\"url\":\"https://www.semanticscholar.org/topic/3097\"},{\"topic\":\"Video clip\",\"topicId\":\"30493\",\"url\":\"https://www.semanticscholar.org/topic/30493\"},{\"topic\":\"Simulation\",\"topicId\":\"194\",\"url\":\"https://www.semanticscholar.org/topic/194\"},{\"topic\":\"Computation\",\"topicId\":\"339\",\"url\":\"https://www.semanticscholar.org/topic/339\"},{\"topic\":\"Map\",\"topicId\":\"2392\",\"url\":\"https://www.semanticscholar.org/topic/2392\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"},{\"topic\":\"Gabor filter\",\"topicId\":\"1264\",\"url\":\"https://www.semanticscholar.org/topic/1264\"},{\"topic\":\"Machine learning\",\"topicId\":\"168\",\"url\":\"https://www.semanticscholar.org/topic/168\"}],\"url\":\"https://www.semanticscholar.org/paper/024d037d46ae933c7e12fd16af61953c7161773a\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017}\n"