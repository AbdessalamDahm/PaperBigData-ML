"{\"abstract\":\"General human action recognition requires understanding of various visual cues. In this paper, we propose a network architecture that computes and integrates the most important visual cues for action recognition: pose, motion, and the raw images. For the integration, we introduce a Markov chain model which adds cues successively. The resulting approach is efficient and applicable to action classification as well as to spatial and temporal action localization. The two contributions clearly improve the performance over respective baselines. The overall approach achieves state-of-the-art action classification performance on HMDB51, J-HMDB and NTU RGB+D datasets. Moreover, it yields state-of-the-art spatio-temporal action localization results on UCF101 and J-HMDB.\",\"arxivId\":\"1704.00616\",\"authors\":[{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\",\"url\":\"https://www.semanticscholar.org/author/2890820\"},{\"authorId\":\"144590074\",\"name\":\"Gabriel L. Oliveira\",\"url\":\"https://www.semanticscholar.org/author/144590074\"},{\"authorId\":\"31656404\",\"name\":\"N. Sedaghat\",\"url\":\"https://www.semanticscholar.org/author/31656404\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\",\"url\":\"https://www.semanticscholar.org/author/1710872\"}],\"citationVelocity\":42,\"citations\":[{\"arxivId\":\"1907.09658\",\"authors\":[{\"authorId\":\"145338228\",\"name\":\"Fan Yang\"},{\"authorId\":\"1783949\",\"name\":\"Sakriani Sakti\"},{\"authorId\":\"145175309\",\"name\":\"Y. Wu\"},{\"authorId\":\"145223960\",\"name\":\"S. Nakamura\"}],\"doi\":\"10.1145/3338533.3366569\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a94e1b573836ab358845fea8faf93b15671fdc69\",\"title\":\"Make Skeleton-based Action Recognition Model Smaller, Faster and Better\",\"url\":\"https://www.semanticscholar.org/paper/a94e1b573836ab358845fea8faf93b15671fdc69\",\"venue\":\"MMAsia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2505740\",\"name\":\"Dennis Ludl\"},{\"authorId\":\"7932331\",\"name\":\"T. Gulde\"},{\"authorId\":\"2174606\",\"name\":\"Crist\\u00f3bal Curio\"}],\"doi\":\"10.1109/TITS.2020.2988504\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5eb8531ef3e5bb2606b2f8aa70664ef70db78f00\",\"title\":\"Enhancing Data-Driven Algorithms for Human Pose Estimation and Action Recognition Through Simulation\",\"url\":\"https://www.semanticscholar.org/paper/5eb8531ef3e5bb2606b2f8aa70664ef70db78f00\",\"venue\":\"IEEE Transactions on Intelligent Transportation Systems\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3005105\",\"name\":\"Youngkyoon Jang\"},{\"authorId\":\"49300666\",\"name\":\"Brian T. Sullivan\"},{\"authorId\":\"40626572\",\"name\":\"Casimir J H Ludwig\"},{\"authorId\":\"2283822\",\"name\":\"I. Gilchrist\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"},{\"authorId\":\"1398236231\",\"name\":\"W. Mayol-Cuevas\"}],\"doi\":\"10.1109/ICCVW.2019.00547\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e5d1234f99d3c6b9c0dc7545e030cac5a56ffc3f\",\"title\":\"EPIC-Tent: An Egocentric Video Dataset for Camping Tent Assembly\",\"url\":\"https://www.semanticscholar.org/paper/e5d1234f99d3c6b9c0dc7545e030cac5a56ffc3f\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2244863\",\"name\":\"X. Zhang\"},{\"authorId\":\"1715708\",\"name\":\"Yaping Huang\"},{\"authorId\":\"2035596033\",\"name\":\"Yang Mi\"},{\"authorId\":\"80996783\",\"name\":\"Yanting Pei\"},{\"authorId\":\"2196589\",\"name\":\"Qi Zou\"},{\"authorId\":\"40696794\",\"name\":\"Song Wang\"}],\"doi\":\"10.1007/s10489-020-01905-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ffd6d8c2f114895c3506b8326a0fdb6b8728e901\",\"title\":\"Video sketch: A middle-level representation for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/ffd6d8c2f114895c3506b8326a0fdb6b8728e901\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"94041056\",\"name\":\"Q. Liu\"},{\"authorId\":\"3150525\",\"name\":\"E. Chen\"},{\"authorId\":\"145735014\",\"name\":\"L. Gao\"},{\"authorId\":\"144446381\",\"name\":\"Chengwu Liang\"},{\"authorId\":\"48447072\",\"name\":\"H. Liu\"}],\"doi\":\"10.3390/s20174673\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fc19368b11d0f782fe321e55904b04b57bf6bdd3\",\"title\":\"Energy-Guided Temporal Segmentation Network for Multimodal Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fc19368b11d0f782fe321e55904b04b57bf6bdd3\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1686917\",\"name\":\"Wu Liu\"},{\"authorId\":\"8768914\",\"name\":\"Cheng Zhang\"},{\"authorId\":\"144258295\",\"name\":\"Huadong Ma\"},{\"authorId\":\"2395139\",\"name\":\"Shuangqun Li\"}],\"doi\":\"10.1007/s12021-018-9362-4\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8bbe9023cbed60b79d5325a0e2f47db7005b66d0\",\"title\":\"Learning Efficient Spatial-Temporal Gait Features with Deep Learning for Human Identification\",\"url\":\"https://www.semanticscholar.org/paper/8bbe9023cbed60b79d5325a0e2f47db7005b66d0\",\"venue\":\"Neuroinformatics\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2704179\",\"name\":\"Dongang Wang\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"50135099\",\"name\":\"W. Li\"},{\"authorId\":\"145481070\",\"name\":\"D. Xu\"}],\"doi\":\"10.1007/978-3-030-01240-3_28\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d2003d6e1de789b7fe60819257d8dfd54d267517\",\"title\":\"Dividing and Aggregating Network for Multi-view Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d2003d6e1de789b7fe60819257d8dfd54d267517\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1712247436\",\"name\":\"Felix Hertlein\"},{\"authorId\":\"153443035\",\"name\":\"D. M\\u00fcnch\"},{\"authorId\":\"144006867\",\"name\":\"M. Arens\"}],\"doi\":\"10.1109/WACVW50321.2020.9096934\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f2da22aa90be9036b60ac7dbe0683c09e7f30a03\",\"title\":\"Context Sensitivity of Spatio-Temporal Activity Detection using Hierarchical Deep Neural Networks in Extended Videos\",\"url\":\"https://www.semanticscholar.org/paper/f2da22aa90be9036b60ac7dbe0683c09e7f30a03\",\"venue\":\"2020 IEEE Winter Applications of Computer Vision Workshops (WACVW)\",\"year\":2020},{\"arxivId\":\"1711.01467\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"90bb40d96fcd16129eb85ce5dc4ee3b2380d74c8\",\"title\":\"Attentional Pooling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/90bb40d96fcd16129eb85ce5dc4ee3b2380d74c8\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41127426\",\"name\":\"Jiaying Liu\"},{\"authorId\":\"3384254\",\"name\":\"Sijie Song\"},{\"authorId\":\"48093650\",\"name\":\"Chunhui Liu\"},{\"authorId\":\"48513679\",\"name\":\"Yanghao Li\"},{\"authorId\":\"9956463\",\"name\":\"Yueyu Hu\"}],\"doi\":\"10.1145/3365212\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"76f6ca119c719cd9f9362a160fb15af2b895095f\",\"title\":\"A Benchmark Dataset and Comparison Study for Multi-modal Human Action Analytics\",\"url\":\"https://www.semanticscholar.org/paper/76f6ca119c719cd9f9362a160fb15af2b895095f\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153023158\",\"name\":\"Z. Zhao\"},{\"authorId\":\"49901469\",\"name\":\"G. Chen\"},{\"authorId\":\"49750905\",\"name\":\"Chong Chen\"},{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"51470719\",\"name\":\"Xuanlu Xiang\"},{\"authorId\":\"49339105\",\"name\":\"Yanyun Zhao\"},{\"authorId\":\"152343380\",\"name\":\"Fei Su\"}],\"doi\":\"10.1109/ICCVW.2019.00234\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9a841017d4da8382841d1216ebeed8605bfaafaf\",\"title\":\"Instance-Based Video Search via Multi-Task Retrieval and Re-Ranking\",\"url\":\"https://www.semanticscholar.org/paper/9a841017d4da8382841d1216ebeed8605bfaafaf\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1912.07249\",\"authors\":[{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"3321919\",\"name\":\"Gr\\u00e9gory Rogez\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8dce5b1cc382f4a341f7ea43c6329c9e8acd202d\",\"title\":\"Mimetics: Towards Understanding Human Actions Out of Context\",\"url\":\"https://www.semanticscholar.org/paper/8dce5b1cc382f4a341f7ea43c6329c9e8acd202d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121961634\",\"name\":\"Yutang Wu\"},{\"authorId\":\"23604671\",\"name\":\"H. Wang\"},{\"authorId\":\"47672901\",\"name\":\"Shuheng Wang\"},{\"authorId\":\"8194130\",\"name\":\"Qinyu Li\"}],\"doi\":\"10.1109/ICASSP40776.2020.9054394\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"886653a4a10986596d39c45711f6f1f49b9d4e70\",\"title\":\"Enhanced Action Tubelet Detector for Spatio-Temporal Video Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/886653a4a10986596d39c45711f6f1f49b9d4e70\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"1912.06971\",\"authors\":[{\"authorId\":\"144861502\",\"name\":\"Lei Shi\"},{\"authorId\":\"40382978\",\"name\":\"Yifan Zhang\"},{\"authorId\":\"48265260\",\"name\":\"Jian Cheng\"},{\"authorId\":\"1694235\",\"name\":\"Hanqing Lu\"}],\"doi\":\"10.1109/TIP.2020.3028207\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5376cbbf263fb6433da15a81948c9d4060677a59\",\"title\":\"Skeleton-Based Action Recognition With Multi-Stream Adaptive Graph Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/5376cbbf263fb6433da15a81948c9d4060677a59\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"- ING\"},{\"authorId\":\"69354043\",\"name\":\"Ang\"},{\"authorId\":null,\"name\":\"- IDA\"},{\"authorId\":\"102770090\",\"name\":\"Ussain\"},{\"authorId\":null,\"name\":\"- ESONG\"},{\"authorId\":\"115925168\",\"name\":\"Ei\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"fab04dfcb35a29a46504d2ad3acbc642c602c7e8\",\"title\":\"Trajectory-based 3D Convolutional Descriptors for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/fab04dfcb35a29a46504d2ad3acbc642c602c7e8\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47837986\",\"name\":\"An Yan\"},{\"authorId\":null,\"name\":\"Yali Wang\"},{\"authorId\":\"9247990\",\"name\":\"Zhifeng Li\"},{\"authorId\":\"143970608\",\"name\":\"Y. Qiao\"}],\"doi\":\"10.1109/CVPR.2019.00811\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4ef4bdad7673050b3764e06a26085f9f8ef11e50\",\"title\":\"PA3D: Pose-Action 3D Machine for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4ef4bdad7673050b3764e06a26085f9f8ef11e50\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2704179\",\"name\":\"Dongang Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ffab858d6ecb12dad89ccab4cce6c856ba28fe21\",\"title\":\"Action Recognition in Multi-view Videos\",\"url\":\"https://www.semanticscholar.org/paper/ffab858d6ecb12dad89ccab4cce6c856ba28fe21\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1904.03326\",\"authors\":[{\"authorId\":\"94299235\",\"name\":\"Julius Surya Sumantri\"},{\"authorId\":\"145789132\",\"name\":\"I. K. Park\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ef5c9e275f4e4aa069f23bcdd040f497f653b874\",\"title\":\"360 Panorama Synthesis from a Sparse Set of Images with Unknown FOV\",\"url\":\"https://www.semanticscholar.org/paper/ef5c9e275f4e4aa069f23bcdd040f497f653b874\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1912.05534\",\"authors\":[{\"authorId\":\"150140884\",\"name\":\"Jin-Woo Choi\"},{\"authorId\":\"49281242\",\"name\":\"C. Gao\"},{\"authorId\":\"79959317\",\"name\":\"Joseph C.E. Messou\"},{\"authorId\":\"3068086\",\"name\":\"Jia-Bin Huang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"439fd498e7b682dea5aa7e910267c10bf2ccb722\",\"title\":\"Why Can't I Dance in the Mall? Learning to Mitigate Scene Bias in Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/439fd498e7b682dea5aa7e910267c10bf2ccb722\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1780440\",\"name\":\"Yadong Pan\"},{\"authorId\":\"49621610\",\"name\":\"Ryo Kawai\"},{\"authorId\":\"1753594859\",\"name\":\"Noboru Yoshida\"},{\"authorId\":\"47969470\",\"name\":\"Hiroo Ikeda\"},{\"authorId\":\"1382175791\",\"name\":\"Shoji Nishimura\"}],\"doi\":\"10.1007/s42979-020-00217-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"60f65cfa28baec240b3d63e9e88272a768327d64\",\"title\":\"Training Physical and Geometrical Mid-Points for Multi-person Pose Estimation and Human Detection Under Congestion and Low Resolution\",\"url\":\"https://www.semanticscholar.org/paper/60f65cfa28baec240b3d63e9e88272a768327d64\",\"venue\":\"SN Comput. Sci.\",\"year\":2020},{\"arxivId\":\"2001.11657\",\"authors\":[{\"authorId\":\"3384254\",\"name\":\"Sijie Song\"},{\"authorId\":\"41127426\",\"name\":\"Jiaying Liu\"},{\"authorId\":\"48513679\",\"name\":\"Yanghao Li\"},{\"authorId\":\"35310979\",\"name\":\"Zongming Guo\"}],\"doi\":\"10.1109/tip.2020.2967577\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"4d22e56c688b18b9e28fd20dc31a31c3594aad1f\",\"title\":\"Modality Compensation Network: Cross-Modal Adaptation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4d22e56c688b18b9e28fd20dc31a31c3594aad1f\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"1388834506\",\"name\":\"Hao Jiang\"}],\"doi\":\"10.1109/CVPR.2019.01213\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5b5c59d5ee264227a370ea68929bfcac0209b4e0\",\"title\":\"Action4D: Online Action Recognition in the Crowd and Clutter\",\"url\":\"https://www.semanticscholar.org/paper/5b5c59d5ee264227a370ea68929bfcac0209b4e0\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"20261417\",\"name\":\"H. Jiang\"},{\"authorId\":\"3128506\",\"name\":\"Yanghao Li\"},{\"authorId\":\"3384254\",\"name\":\"Sijie Song\"},{\"authorId\":\"41127426\",\"name\":\"Jiaying Liu\"}],\"doi\":\"10.1007/978-3-030-00764-5_17\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c8cafacad128b443470bed644b6f6cf93a31c236\",\"title\":\"Rethinking Fusion Baselines for Multi-modal Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c8cafacad128b443470bed644b6f6cf93a31c236\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"cb0bf65ab4a316a5caeee766a9e5840c34934023\",\"title\":\"LSTM with Hand-crafted View-Invariant and Differential Cues (HVDC) for 3D Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cb0bf65ab4a316a5caeee766a9e5840c34934023\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"117454237\",\"name\":\"Zirui Qiu\"},{\"authorId\":\"144359415\",\"name\":\"J. Sun\"},{\"authorId\":\"51163848\",\"name\":\"Mingyue Guo\"},{\"authorId\":\"21836351\",\"name\":\"Mantao Wang\"},{\"authorId\":\"46334637\",\"name\":\"D. Zhang\"}],\"doi\":\"10.1007/978-981-15-0121-0_1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"71e47cea739e472da47756040e78fdae8bd21752\",\"title\":\"Survey on Deep Learning for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/71e47cea739e472da47756040e78fdae8bd21752\",\"venue\":\"ICPCSEE\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144289594\",\"name\":\"C. Caetano\"},{\"authorId\":\"143793197\",\"name\":\"V. H. Melo\"},{\"authorId\":\"144103389\",\"name\":\"F. Br\\u00e9mond\"},{\"authorId\":\"6141311\",\"name\":\"J. A. D. Santos\"},{\"authorId\":\"9385043\",\"name\":\"W. Schwartz\"}],\"doi\":\"10.1016/J.JVCIR.2019.102596\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c3c201c48d14e0e7135d4558590a4ad3f7bc864c\",\"title\":\"Magnitude-Orientation Stream network and depth information applied to activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/c3c201c48d14e0e7135d4558590a4ad3f7bc864c\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":\"2007.05840\",\"authors\":[{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"1980683\",\"name\":\"S. Aeron\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4a2ef52618bc02c12e9edf59088d9fafee829185\",\"title\":\"Representation Learning via Adversarially-Contrastive Optimal Transport\",\"url\":\"https://www.semanticscholar.org/paper/4a2ef52618bc02c12e9edf59088d9fafee829185\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50197336\",\"name\":\"N. Nair\"},{\"authorId\":\"144634420\",\"name\":\"Chinchu Thomas\"},{\"authorId\":\"1705782\",\"name\":\"Dinesh Babu Jayagopi\"}],\"doi\":\"10.1145/3266157.3266221\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"22951a9d6cb56b83ef830021ca512296a3eabe16\",\"title\":\"Human Activity Recognition Using Temporal Convolutional Network\",\"url\":\"https://www.semanticscholar.org/paper/22951a9d6cb56b83ef830021ca512296a3eabe16\",\"venue\":\"iWOAR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34880426\",\"name\":\"L. Zhou\"},{\"authorId\":\"51111989\",\"name\":\"Guowang Du\"},{\"authorId\":\"2635083\",\"name\":\"Ruxin Wang\"},{\"authorId\":\"1701119\",\"name\":\"Dapeng Tao\"},{\"authorId\":\"31189357\",\"name\":\"Lizhen Wang\"},{\"authorId\":\"144703461\",\"name\":\"J. Cheng\"},{\"authorId\":null,\"name\":\"Jing Wang\"}],\"doi\":\"10.1016/j.patcog.2018.10.021\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"56f78c84afdcab9af450f2112c350464545125e2\",\"title\":\"A tensor framework for geosensor data forecasting of significant societal events\",\"url\":\"https://www.semanticscholar.org/paper/56f78c84afdcab9af450f2112c350464545125e2\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":\"1905.04757\",\"authors\":[{\"authorId\":\"40940512\",\"name\":\"Jun Liu\"},{\"authorId\":\"3000984\",\"name\":\"Amir Shahroudy\"},{\"authorId\":\"121247048\",\"name\":\"Mauricio Perez\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"},{\"authorId\":\"7667912\",\"name\":\"L. Duan\"},{\"authorId\":\"1711097\",\"name\":\"A. Kot\"}],\"doi\":\"10.1109/TPAMI.2019.2916873\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1b632712cd0d1f14784ba938f135960f71a52e5c\",\"title\":\"NTU RGB+D 120: A Large-Scale Benchmark for 3D Human Activity Understanding\",\"url\":\"https://www.semanticscholar.org/paper/1b632712cd0d1f14784ba938f135960f71a52e5c\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":\"1806.11008\",\"authors\":[{\"authorId\":\"1902524\",\"name\":\"Guilhem Ch\\u00e9ron\"},{\"authorId\":\"145319877\",\"name\":\"Anton Osokin\"},{\"authorId\":\"143991676\",\"name\":\"Ivan Laptev\"},{\"authorId\":\"2462253\",\"name\":\"Cordelia Schmid\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"14fee990a372bcc4cb6dc024ab7fc4ecf09dba2b\",\"title\":\"Modeling Spatio-Temporal Human Track Structure for Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/14fee990a372bcc4cb6dc024ab7fc4ecf09dba2b\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1557335646\",\"name\":\"Sandar Win\"},{\"authorId\":\"49245080\",\"name\":\"Thin Lai Lai Thein\"}],\"doi\":\"10.1109/ICCA49400.2020.9022822\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"121599243954e4b1397b83ef58405e488b7e98b2\",\"title\":\"Real-Time Human Motion Detection, Tracking and Activity Recognition with Skeletal Model\",\"url\":\"https://www.semanticscholar.org/paper/121599243954e4b1397b83ef58405e488b7e98b2\",\"venue\":\"2020 IEEE Conference on Computer Applications(ICCA)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2686079\",\"name\":\"Dinh Viet Sang\"},{\"authorId\":\"31118991\",\"name\":\"Hoang Trung Dung\"}],\"doi\":\"10.1145/3287921.3287972\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c717bc959a204751c279879435394f13c95aa531\",\"title\":\"Two-stream Deep Residual Learning with Fisher Criterion for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c717bc959a204751c279879435394f13c95aa531\",\"venue\":\"SoICT 2018\",\"year\":2018},{\"arxivId\":\"1711.08362\",\"authors\":[{\"authorId\":\"8120382\",\"name\":\"P. Wang\"},{\"authorId\":\"1685696\",\"name\":\"W. Li\"},{\"authorId\":\"1719314\",\"name\":\"P. Ogunbona\"},{\"authorId\":\"145121530\",\"name\":\"Jun Wan\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"}],\"doi\":\"10.1016/j.cviu.2018.04.007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"224b34acba3597912f8adc288fa8adbb1fca92b4\",\"title\":\"RGB-D-based Human Motion Recognition with Deep Learning: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/224b34acba3597912f8adc288fa8adbb1fca92b4\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2018},{\"arxivId\":\"1911.08511\",\"authors\":[{\"authorId\":\"51207689\",\"name\":\"Michael Peven\"},{\"authorId\":\"1678633\",\"name\":\"Gregory Hager\"},{\"authorId\":\"3207112\",\"name\":\"A. Reiter\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b5a3276c943aea32d6331c317649e5d1dc1faf91\",\"title\":\"Action Recognition Using Volumetric Motion Representations\",\"url\":\"https://www.semanticscholar.org/paper/b5a3276c943aea32d6331c317649e5d1dc1faf91\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1805.06184\",\"authors\":[{\"authorId\":\"3358065\",\"name\":\"Xikun Zhang\"},{\"authorId\":\"48258751\",\"name\":\"Chang Xu\"},{\"authorId\":\"40434674\",\"name\":\"X. Tian\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/tnnls.2019.2935173\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c8ca7b5212f22981e2867e51f17b2987e61add52\",\"title\":\"Graph Edge Convolutional Neural Networks for Skeleton-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c8ca7b5212f22981e2867e51f17b2987e61add52\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2020},{\"arxivId\":\"1705.08421\",\"authors\":[{\"authorId\":\"39599498\",\"name\":\"C. Gu\"},{\"authorId\":\"94567368\",\"name\":\"C. Sun\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"2997956\",\"name\":\"C. Pantofaru\"},{\"authorId\":\"144711958\",\"name\":\"D. Ross\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"1758054\",\"name\":\"Y. Li\"},{\"authorId\":\"2262946\",\"name\":\"S. Ricco\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"153652146\",\"name\":\"J. Malik\"}],\"doi\":\"10.1109/CVPR.2018.00633\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"54c7c3909c7e1e827befdbe8d2595a3b196ba1b8\",\"title\":\"AVA: A Video Dataset of Spatio-Temporally Localized Atomic Visual Actions\",\"url\":\"https://www.semanticscholar.org/paper/54c7c3909c7e1e827befdbe8d2595a3b196ba1b8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1812.05231\",\"authors\":[{\"authorId\":\"5911068\",\"name\":\"V. Kaushik\"},{\"authorId\":\"2550012\",\"name\":\"Prerana Mukherjee\"},{\"authorId\":\"143632379\",\"name\":\"Brejesh Lall\"}],\"doi\":\"10.1145/3293353.3293419\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d99fd437137b8562ed4f4ece533d4d363ebcf0b2\",\"title\":\"Nrityantar: Pose oblivious Indian classical dance sequence classification system\",\"url\":\"https://www.semanticscholar.org/paper/d99fd437137b8562ed4f4ece533d4d363ebcf0b2\",\"venue\":\"ICVGIP\",\"year\":2018},{\"arxivId\":\"2007.06288\",\"authors\":[{\"authorId\":\"49279229\",\"name\":\"Lifang Wu\"},{\"authorId\":\"98256637\",\"name\":\"Zhou Yang\"},{\"authorId\":\"50621207\",\"name\":\"Q. Wang\"},{\"authorId\":\"46946060\",\"name\":\"M. Jian\"},{\"authorId\":\"49217626\",\"name\":\"Boxuan Zhao\"},{\"authorId\":\"3063894\",\"name\":\"Junchi Yan\"},{\"authorId\":\"1735257\",\"name\":\"C. Chen\"}],\"doi\":\"10.1016/j.neucom.2020.07.003\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"50efde486726ae435c28211b6cd123c6b61e3a99\",\"title\":\"Fusing Motion Patterns and Key Visual Information for Semantic Event Recognition in Basketball Videos\",\"url\":\"https://www.semanticscholar.org/paper/50efde486726ae435c28211b6cd123c6b61e3a99\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2691929\",\"name\":\"Anoop Cherian\"},{\"authorId\":\"1980683\",\"name\":\"Shuchin Aeron\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b8c001c449cec20221ba3daa76536a124cddc0e5\",\"title\":\"Representation Learning via Adversarially-Contrastive Optimal Transport /Author=Cherian, Anoop; Aeron, Shuchin /CreationDate=July 3, 2020 /Subject=Artificial Intelligence, Computer Vision, Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/b8c001c449cec20221ba3daa76536a124cddc0e5\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1808.00297\",\"authors\":[{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":null,\"name\":\"Suman Saha\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":\"10.1007/978-3-030-20876-9_27\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"563fcc87934a4e6c8843c81b58273cb366918bfb\",\"title\":\"TraMNet - Transition Matrix Network for Efficient Action Tube Proposals\",\"url\":\"https://www.semanticscholar.org/paper/563fcc87934a4e6c8843c81b58273cb366918bfb\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150282005\",\"name\":\"Rizard Renanda Adhi Pramono\"},{\"authorId\":\"73365425\",\"name\":\"Y. Chen\"},{\"authorId\":\"122315920\",\"name\":\"Wen-Hsien Fang\"}],\"doi\":\"10.1109/ICCV.2019.00015\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3b76da17a060f1edb80b26f489f4b6256d785c57\",\"title\":\"Hierarchical Self-Attention Network for Action Localization in Videos\",\"url\":\"https://www.semanticscholar.org/paper/3b76da17a060f1edb80b26f489f4b6256d785c57\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"94628221\",\"name\":\"Sophie Aubrey\"},{\"authorId\":\"3091223\",\"name\":\"S. Laraba\"},{\"authorId\":\"3102364\",\"name\":\"J. Tilmanne\"},{\"authorId\":\"49164810\",\"name\":\"T. Dutoit\"}],\"doi\":\"10.1051/MATECCONF/201927702034\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dc55a0bd15f2852f4025541b709ad0f0e21a8720\",\"title\":\"Action recognition based on 2D skeletons extracted from RGB videos\",\"url\":\"https://www.semanticscholar.org/paper/dc55a0bd15f2852f4025541b709ad0f0e21a8720\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"94299235\",\"name\":\"Julius Surya Sumantri\"},{\"authorId\":\"145789132\",\"name\":\"I. K. Park\"}],\"doi\":\"10.1109/WACV45572.2020.9093582\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e9f36e5ead5453f77e6b19cad22627ef71406031\",\"title\":\"360 Panorama Synthesis from a Sparse Set of Images with Unknown Field of View\",\"url\":\"https://www.semanticscholar.org/paper/e9f36e5ead5453f77e6b19cad22627ef71406031\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4464686\",\"name\":\"ZhenXing Zheng\"},{\"authorId\":\"2896701\",\"name\":\"G. An\"},{\"authorId\":\"144953181\",\"name\":\"D. Wu\"},{\"authorId\":\"144695333\",\"name\":\"Q. Ruan\"}],\"doi\":\"10.1016/J.NEUCOM.2019.05.058\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"67d3ec7b1070405575974e449cfdc495b43f7b21\",\"title\":\"Spatial-temporal pyramid based Convolutional Neural Network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/67d3ec7b1070405575974e449cfdc495b43f7b21\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52022007\",\"name\":\"Vasileios Choutas\"},{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"3428663\",\"name\":\"J\\u00e9r\\u00f4me Revaud\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/CVPR.2018.00734\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6009bba115904bc3bf876224db90b232c4f0a48f\",\"title\":\"PoTion: Pose MoTion Representation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6009bba115904bc3bf876224db90b232c4f0a48f\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19177140\",\"name\":\"Srijan Das\"},{\"authorId\":\"52622630\",\"name\":\"Kaustubh Sakhalkar\"},{\"authorId\":\"34561667\",\"name\":\"Michal Koperski\"},{\"authorId\":\"144103389\",\"name\":\"Fran\\u00e7ois Br\\u00e9mond\"}],\"doi\":\"10.1145/3293353.3293376\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"631a704edb53b0a4b852421891172ff785879727\",\"title\":\"Spatio-Temporal Grids for Daily Living Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/631a704edb53b0a4b852421891172ff785879727\",\"venue\":\"ICVGIP\",\"year\":2018},{\"arxivId\":\"1812.05770\",\"authors\":[{\"authorId\":\"1696573\",\"name\":\"Jiagang Zhu\"},{\"authorId\":\"145251501\",\"name\":\"W. Zou\"},{\"authorId\":\"47775885\",\"name\":\"Liang Xu\"},{\"authorId\":\"1736595\",\"name\":\"Yiming Hu\"},{\"authorId\":\"144168342\",\"name\":\"Zheng Zhu\"},{\"authorId\":\"143864262\",\"name\":\"Manyu Chang\"},{\"authorId\":null,\"name\":\"Junjie Huang\"},{\"authorId\":\"143986385\",\"name\":\"G. Huang\"},{\"authorId\":\"40359161\",\"name\":\"Dalong Du\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"38d0dd93755b83b2390815fda926866f7ec624ce\",\"title\":\"Action Machine: Rethinking Action Recognition in Trimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/38d0dd93755b83b2390815fda926866f7ec624ce\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1807.11332\",\"authors\":[{\"authorId\":\"143716515\",\"name\":\"V. Fontana\"},{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":\"51152717\",\"name\":\"Stephen Akrigg\"},{\"authorId\":\"51149466\",\"name\":\"Manuele Di Maio\"},{\"authorId\":null,\"name\":\"Suman Saha\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fd71ae9599e8a51d8a61e31e6faaaf4a23a17d81\",\"title\":\"Action Detection from a Robot-Car Perspective\",\"url\":\"https://www.semanticscholar.org/paper/fd71ae9599e8a51d8a61e31e6faaaf4a23a17d81\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1907.13051\",\"authors\":[{\"authorId\":\"21518096\",\"name\":\"Zhengyuan Yang\"},{\"authorId\":\"66508219\",\"name\":\"Y. Li\"},{\"authorId\":\"9145768\",\"name\":\"Linjie Yang\"},{\"authorId\":null,\"name\":\"Ning Zhang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ec2cce9c7a5de69abe526562cae3e5f096bb090a\",\"title\":\"Weakly Supervised Body Part Parsing with Pose based Part Priors\",\"url\":\"https://www.semanticscholar.org/paper/ec2cce9c7a5de69abe526562cae3e5f096bb090a\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52622630\",\"name\":\"Kaustubh Sakhalkar\"},{\"authorId\":\"1729410\",\"name\":\"F. Bremond\"}],\"doi\":\"10.1109/IPAS.2018.8708877\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a367717713174d18b3adc4a90d7af7d171dd8ce7\",\"title\":\"Learning to Represent Spatio-Temporal Features for Fine Grained Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a367717713174d18b3adc4a90d7af7d171dd8ce7\",\"venue\":\"2018 IEEE International Conference on Image Processing, Applications and Systems (IPAS)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8962288\",\"name\":\"Zichen zhou\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"498a1e7c6de343dac40f374c4e812e64c6c7826f\",\"title\":\"Attention Before and After Feature Extraction for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/498a1e7c6de343dac40f374c4e812e64c6c7826f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19177140\",\"name\":\"S. Das\"},{\"authorId\":\"1686585\",\"name\":\"M. Thonnat\"},{\"authorId\":\"52622630\",\"name\":\"Kaustubh Sakhalkar\"},{\"authorId\":\"34561667\",\"name\":\"Michal Koperski\"},{\"authorId\":\"1729410\",\"name\":\"F. Bremond\"},{\"authorId\":\"2647267\",\"name\":\"G. Francesca\"}],\"doi\":\"10.1007/978-3-030-05716-9_40\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aec8dde46fe52105ff0642a905373c97ee7eced9\",\"title\":\"A New Hybrid Architecture for Human Activity Recognition from RGB-D Videos\",\"url\":\"https://www.semanticscholar.org/paper/aec8dde46fe52105ff0642a905373c97ee7eced9\",\"venue\":\"MMM\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47842072\",\"name\":\"M. Liu\"},{\"authorId\":\"1774797\",\"name\":\"Fanyang Meng\"},{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"2525392\",\"name\":\"S. Wu\"}],\"doi\":\"10.1609/AAAI.V33I01.33018762\",\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"32c216b09b1208585a70cff674460735bd9939fe\",\"title\":\"Joint Dynamic Pose Image and Space Time Reversal for Human Action Recognition from Videos\",\"url\":\"https://www.semanticscholar.org/paper/32c216b09b1208585a70cff674460735bd9939fe\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"2003.06156\",\"authors\":[{\"authorId\":\"2592382\",\"name\":\"Raphael Memmesheimer\"},{\"authorId\":\"51151710\",\"name\":\"Nick Theisen\"},{\"authorId\":\"153543876\",\"name\":\"D. Paulus\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0e5dbd3d58645c13e7517e0610faa4d854930db3\",\"title\":\"Gimme Signals: Discriminative signal encoding for multimodal activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/0e5dbd3d58645c13e7517e0610faa4d854930db3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1712.04851\",\"authors\":[{\"authorId\":\"1817030\",\"name\":\"Saining Xie\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"1808244\",\"name\":\"J. Huang\"},{\"authorId\":\"144035504\",\"name\":\"Zhuowen Tu\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":\"10.1007/978-3-030-01267-0_19\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"815aa52cfc02961d82415f080384594639a21984\",\"title\":\"Rethinking Spatiotemporal Feature Learning: Speed-Accuracy Trade-offs in Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/815aa52cfc02961d82415f080384594639a21984\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47930257\",\"name\":\"R. S. C. Oliveira\"}],\"doi\":\"10.25911/5dfc956bbd86c\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"388212b4fbc19e6a685eb929f35a7e1c3c06f814\",\"title\":\"Visual Recognition From Structured Supervision\",\"url\":\"https://www.semanticscholar.org/paper/388212b4fbc19e6a685eb929f35a7e1c3c06f814\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35031371\",\"name\":\"Wenbin Du\"},{\"authorId\":\"2799162\",\"name\":\"Y. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1109/TIP.2017.2778563\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"57eeaceb14a01a2560d0b90d38205e512dcca691\",\"title\":\"Recurrent Spatial-Temporal Attention Network for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/57eeaceb14a01a2560d0b90d38205e512dcca691\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"120425481\",\"name\":\"Sohee Park\"},{\"authorId\":\"2417743\",\"name\":\"Arani Bhattacharya\"},{\"authorId\":\"152747658\",\"name\":\"Z. Yang\"},{\"authorId\":\"48374961\",\"name\":\"Mallesham Dasari\"},{\"authorId\":\"1691843\",\"name\":\"Samir R Das\"},{\"authorId\":\"1686020\",\"name\":\"D. Samaras\"}],\"doi\":\"10.23919/IFIPNetworking.2019.8816847\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dc8905e22cf4c869c780e51976704bfb6545fd6b\",\"title\":\"Advancing User Quality of Experience in 360-degree Video Streaming\",\"url\":\"https://www.semanticscholar.org/paper/dc8905e22cf4c869c780e51976704bfb6545fd6b\",\"venue\":\"2019 IFIP Networking Conference (IFIP Networking)\",\"year\":2019},{\"arxivId\":\"2012.06567\",\"authors\":[{\"authorId\":\"1805946041\",\"name\":\"Yi Zhu\"},{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"49046944\",\"name\":\"C. Liu\"},{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"22539483\",\"name\":\"Chongruo Wu\"},{\"authorId\":\"152781163\",\"name\":\"Z. Zhang\"},{\"authorId\":\"2397422\",\"name\":\"Joseph Tighe\"},{\"authorId\":\"1758550\",\"name\":\"R. Manmatha\"},{\"authorId\":\"49140510\",\"name\":\"M. Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ee12f02830a5e1f7cadd3623dfed495cf099bc82\",\"title\":\"A Comprehensive Study of Deep Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ee12f02830a5e1f7cadd3623dfed495cf099bc82\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.05977\",\"authors\":[{\"authorId\":\"1876283791\",\"name\":\"Ling-An Zeng\"},{\"authorId\":\"94281814\",\"name\":\"Fa-Ting Hong\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"},{\"authorId\":\"40538505\",\"name\":\"Q. Yu\"},{\"authorId\":\"1491635278\",\"name\":\"Wei Zeng\"},{\"authorId\":null,\"name\":\"Yao-Wei Wang\"},{\"authorId\":\"153224231\",\"name\":\"Jianhuang Lai\"}],\"doi\":\"10.1145/1122445.1122456\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ff255c162a2e91bcc871bb9285bdf07d9385ece8\",\"title\":\"Hybrid Dynamic-static Context-aware Attention Network for Action Assessment in Long Videos\",\"url\":\"https://www.semanticscholar.org/paper/ff255c162a2e91bcc871bb9285bdf07d9385ece8\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50089882\",\"name\":\"Haiyang Jiang\"},{\"authorId\":\"7303419\",\"name\":\"Yaozong Pan\"},{\"authorId\":\"101594813\",\"name\":\"J. Zhang\"},{\"authorId\":\"145664195\",\"name\":\"H. Yang\"}],\"doi\":\"10.3390/SYM11060761\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"66a8b5f9d2578fc2b533bf93d1e4df14cd993643\",\"title\":\"Battlefield Target Aggregation Behavior Recognition Model Based on Multi-Scale Feature Fusion\",\"url\":\"https://www.semanticscholar.org/paper/66a8b5f9d2578fc2b533bf93d1e4df14cd993643\",\"venue\":\"Symmetry\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49394516\",\"name\":\"J. Xu\"},{\"authorId\":\"2764854\",\"name\":\"K. Tasaka\"},{\"authorId\":\"1796620\",\"name\":\"H. Yanagihara\"}],\"doi\":\"10.1109/ICPR.2018.8546165\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0920e6a665c9b99fcc2ea1a06ff93673c3fd041d\",\"title\":\"Beyond Two-stream: Skeleton-based Three-stream Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/0920e6a665c9b99fcc2ea1a06ff93673c3fd041d\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"120425481\",\"name\":\"Sohee Park\"},{\"authorId\":\"120736326\",\"name\":\"A. Bhattacharya\"},{\"authorId\":\"48598731\",\"name\":\"Zhibo Yang\"},{\"authorId\":\"48374961\",\"name\":\"Mallesham Dasari\"},{\"authorId\":\"1691843\",\"name\":\"Samir R Das\"},{\"authorId\":\"1686020\",\"name\":\"D. Samaras\"}],\"doi\":\"10.23919/IFIPNetworking46909.2019.8999460\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ea47c6281000429bb43bc50e9585cb8ec185a1eb\",\"title\":\"Advancing user quality of experience in 360-degree video streaming\",\"url\":\"https://www.semanticscholar.org/paper/ea47c6281000429bb43bc50e9585cb8ec185a1eb\",\"venue\":\"2019 IFIP Networking Conference (IFIP Networking)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22015276\",\"name\":\"Y. Wu\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"8194130\",\"name\":\"Qinyu Li\"}],\"doi\":\"10.1007/978-3-030-00767-6_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"069ab36fee71b15e9e6e8652e066f59d768ea071\",\"title\":\"Three-Stream Action Tubelet Detector for Spatiotemporal Action Detection in Videos\",\"url\":\"https://www.semanticscholar.org/paper/069ab36fee71b15e9e6e8652e066f59d768ea071\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":\"2012.11866\",\"authors\":[{\"authorId\":\"2595189\",\"name\":\"Zehua Sun\"},{\"authorId\":\"120809631\",\"name\":\"Jiwang Liu\"},{\"authorId\":\"143969578\",\"name\":\"Qiuhong Ke\"},{\"authorId\":\"1877377\",\"name\":\"H. Rahmani\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"816236bf3219363bfe4b847363e137b1fe6712e7\",\"title\":\"Human Action Recognition from Various Data Modalities: A Review\",\"url\":\"https://www.semanticscholar.org/paper/816236bf3219363bfe4b847363e137b1fe6712e7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2357503\",\"name\":\"Ya-Chun Li\"},{\"authorId\":\"97596774\",\"name\":\"Y. Liu\"},{\"authorId\":\"48935472\",\"name\":\"Chi Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d02a5b52bb47ecf594710ede66c12f1eb660c39\",\"title\":\"What Elements are Essential to Recognize Human Actions?\",\"url\":\"https://www.semanticscholar.org/paper/9d02a5b52bb47ecf594710ede66c12f1eb660c39\",\"venue\":\"CVPR Workshops\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"47067803\",\"name\":\"Hao Jiang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"53ff10d5c64f8b753e7ba04c8ab554901eb0e1b0\",\"title\":\"Action 4 D : Online Action Recognition in the Crowd and Clutter Quanzeng\",\"url\":\"https://www.semanticscholar.org/paper/53ff10d5c64f8b753e7ba04c8ab554901eb0e1b0\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1398447065\",\"name\":\"Sadjad Asghari-Esfeden\"},{\"authorId\":\"1687866\",\"name\":\"M. Sznaier\"},{\"authorId\":\"143867334\",\"name\":\"O. Camps\"}],\"doi\":\"10.1109/WACV45572.2020.9093500\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"51bcb7de98bedf65215910fcfd08555d5eed682a\",\"title\":\"Dynamic Motion Representation for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/51bcb7de98bedf65215910fcfd08555d5eed682a\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46276098\",\"name\":\"Jianan Li\"},{\"authorId\":\"49419064\",\"name\":\"Xuemei Xie\"},{\"authorId\":\"1491642326\",\"name\":\"Qingzhe Pan\"},{\"authorId\":\"122210974\",\"name\":\"Yu-Han Cao\"},{\"authorId\":\"32273141\",\"name\":\"Z. Zhao\"},{\"authorId\":\"35367337\",\"name\":\"Guangming Shi\"}],\"doi\":\"10.1016/j.patcog.2020.107356\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a6cd1d88ab7439d73d1163c2eca77ce7134c908f\",\"title\":\"SGM-Net: Skeleton-guided multimodal network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/a6cd1d88ab7439d73d1163c2eca77ce7134c908f\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":\"2011.07787\",\"authors\":[{\"authorId\":\"81226618\",\"name\":\"Jinmiao Cai\"},{\"authorId\":\"2855391\",\"name\":\"N. Jiang\"},{\"authorId\":\"50016941\",\"name\":\"Xiao-Guang Han\"},{\"authorId\":\"49104090\",\"name\":\"Kui Jia\"},{\"authorId\":\"1715148\",\"name\":\"Jiangbo Lu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c2664de9388332008077c54278c4f59025dc0bab\",\"title\":\"JOLO-GCN: Mining Joint-Centered Light-Weight Information for Skeleton-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c2664de9388332008077c54278c4f59025dc0bab\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.06317\",\"authors\":[{\"authorId\":\"3458134\",\"name\":\"Gyeongsik Moon\"},{\"authorId\":\"30557120\",\"name\":\"Heeseung Kwon\"},{\"authorId\":\"2135837\",\"name\":\"Kyoung Mu Lee\"},{\"authorId\":\"72643925\",\"name\":\"Minsu Cho\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8230c73193abe9f42306a311d75557a902e785f6\",\"title\":\"IntegralAction: Pose-driven Feature Integration for Robust Human Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/8230c73193abe9f42306a311d75557a902e785f6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3091223\",\"name\":\"S. Laraba\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4ec04e32a90c5d98de25e46c85e9369ecc90ac5a\",\"title\":\"Deep Learning for Skeleton-Based Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4ec04e32a90c5d98de25e46c85e9369ecc90ac5a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1804.09066\",\"authors\":[{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"145264990\",\"name\":\"K. Singh\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1007/978-3-030-01216-8_43\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aa63893b34f523973d0692dc74ff22512daac322\",\"title\":\"ECO: Efficient Convolutional Network for Online Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/aa63893b34f523973d0692dc74ff22512daac322\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49494523\",\"name\":\"Ishwar Singh\"},{\"authorId\":\"150345740\",\"name\":\"Xiao-Dan Zhu\"},{\"authorId\":\"35019530\",\"name\":\"M. Greenspan\"}],\"doi\":\"10.1109/ICIP40778.2020.9191034\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"94e1219f1af29dc2aaf1ea362ed661c7c3fd2a4e\",\"title\":\"Multi-Modal Fusion With Observation Points For Skeleton Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/94e1219f1af29dc2aaf1ea362ed661c7c3fd2a4e\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8194130\",\"name\":\"Qinyu Li\"},{\"authorId\":\"46307804\",\"name\":\"L. Chen\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"2535030\",\"name\":\"Xianhui Liu\"}],\"doi\":\"10.1007/978-3-030-37731-1_36\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f16256ffdedf1028d44c7cf40a30af1af86b8dde\",\"title\":\"Wonderful Clips of Playing Basketball: A Database for Localizing Wonderful Actions\",\"url\":\"https://www.semanticscholar.org/paper/f16256ffdedf1028d44c7cf40a30af1af86b8dde\",\"venue\":\"MMM\",\"year\":2020},{\"arxivId\":\"2011.13399\",\"authors\":[{\"authorId\":\"151136071\",\"name\":\"Mattia Segu\"},{\"authorId\":\"1781788981\",\"name\":\"Federico Pirovano\"},{\"authorId\":\"2029237675\",\"name\":\"Gianmario Fumagalli\"},{\"authorId\":\"1557389943\",\"name\":\"Amedeo Fabris\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ff46dc2fe07d291e4a829b49b450df29f788efc2\",\"title\":\"Depth-Aware Action Recognition: Pose-Motion Encoding through Temporal Heatmaps\",\"url\":\"https://www.semanticscholar.org/paper/ff46dc2fe07d291e4a829b49b450df29f788efc2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1912.08077\",\"authors\":[{\"authorId\":\"26988468\",\"name\":\"Diogo C. Luvizon\"},{\"authorId\":\"2397984\",\"name\":\"H. Tabia\"},{\"authorId\":\"145897899\",\"name\":\"D. Picard\"}],\"doi\":\"10.1109/TPAMI.2020.2976014\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"145e426e378b29ea5cf62f5300f337561b3c2784\",\"title\":\"Multi-task Deep Learning for Real-Time 3D Human Pose Estimation and Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/145e426e378b29ea5cf62f5300f337561b3c2784\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143750989\",\"name\":\"F. Gao\"},{\"authorId\":\"49982480\",\"name\":\"Yuanyuan Ge\"},{\"authorId\":\"47909272\",\"name\":\"Y. Liu\"}],\"doi\":\"10.1007/s11042-018-5868-x\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ffcfe47a28929135c2e8905d36f7f8732d217d5d\",\"title\":\"Remember and forget: video and text fusion for video question answering\",\"url\":\"https://www.semanticscholar.org/paper/ffcfe47a28929135c2e8905d36f7f8732d217d5d\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144821367\",\"name\":\"Tian Jin\"},{\"authorId\":\"152237365\",\"name\":\"Zhihao He\"},{\"authorId\":\"152449715\",\"name\":\"Amlan Basu\"},{\"authorId\":\"1684980\",\"name\":\"J. Soraghan\"},{\"authorId\":\"27469280\",\"name\":\"G. Di Caterina\"},{\"authorId\":\"69329588\",\"name\":\"L. Petropoulakis\"}],\"doi\":\"10.1109/ICCAR.2019.8813408\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0c245c67fcf0e472bb2eb1fe6fa9821c0c4bd2f0\",\"title\":\"Dense Convolutional Networks for Efficient Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/0c245c67fcf0e472bb2eb1fe6fa9821c0c4bd2f0\",\"venue\":\"2019 5th International Conference on Control, Automation and Robotics (ICCAR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3076846\",\"name\":\"Chandni\"},{\"authorId\":\"51498323\",\"name\":\"Rajat Khurana\"},{\"authorId\":\"47556759\",\"name\":\"Alok K. Kushwaha\"}],\"doi\":\"10.1007/978-981-13-2685-1_32\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d7e425c71e2231f09530c6bb14fe1d02d74862c5\",\"title\":\"Delving Deeper with Dual-Stream CNN for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d7e425c71e2231f09530c6bb14fe1d02d74862c5\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48386255\",\"name\":\"Yun Han\"},{\"authorId\":\"36479497\",\"name\":\"Sheng-Luen Chung\"},{\"authorId\":\"50358287\",\"name\":\"Sheng-Fang Chen\"},{\"authorId\":\"145434054\",\"name\":\"S. Su\"}],\"doi\":\"10.1109/SMC.2018.00600\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6b592c33d70c35a709956df767ec8fa63a9cf3ec\",\"title\":\"Two-Stream LSTM for Action Recognition with RGB-D-Based Hand-Crafted Features and Feature Combination\",\"url\":\"https://www.semanticscholar.org/paper/6b592c33d70c35a709956df767ec8fa63a9cf3ec\",\"venue\":\"2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC)\",\"year\":2018},{\"arxivId\":\"1910.06699\",\"authors\":[{\"authorId\":\"37868227\",\"name\":\"C. D. Souza\"},{\"authorId\":\"1799820\",\"name\":\"Adrien Gaidon\"},{\"authorId\":\"3407519\",\"name\":\"Y. Cabon\"},{\"authorId\":\"26734366\",\"name\":\"N. Murray\"},{\"authorId\":\"3940956\",\"name\":\"A. Pe\\u00f1a\"}],\"doi\":\"10.1007/s11263-019-01222-z\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"099bdf9cf1c59c7f5ed201759157fb505f51a762\",\"title\":\"Generating Human Action Videos by Coupling 3D Game Engines and Probabilistic Graphical Models\",\"url\":\"https://www.semanticscholar.org/paper/099bdf9cf1c59c7f5ed201759157fb505f51a762\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144349170\",\"name\":\"Meet Pandya\"},{\"authorId\":\"1753967\",\"name\":\"A. Pillai\"},{\"authorId\":\"2007484554\",\"name\":\"Himanshu Rupani\"}],\"doi\":\"10.1007/978-981-15-3383-9_1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fb09c4472916a9385c67c62f82509da877d951b0\",\"title\":\"Segregating and Recognizing Human Actions from Video Footages Using LRCN Technique\",\"url\":\"https://www.semanticscholar.org/paper/fb09c4472916a9385c67c62f82509da877d951b0\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1808.07712\",\"authors\":[{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":null,\"name\":\"Suman Saha\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":\"10.1007/978-3-030-11015-4_11\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7ffcf3435b1e7a984836bac25800481fb5140d97\",\"title\":\"Predicting Action Tubes\",\"url\":\"https://www.semanticscholar.org/paper/7ffcf3435b1e7a984836bac25800481fb5140d97\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1780440\",\"name\":\"Yadong Pan\"},{\"authorId\":\"1382175791\",\"name\":\"Shoji Nishimura\"}],\"doi\":\"10.1007/978-3-030-41404-7_17\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8790fa4fda5c690856462cc96c23d0ad7686862d\",\"title\":\"Multi-person Pose Estimation with Mid-Points for Human Detection under Real-World Surveillance\",\"url\":\"https://www.semanticscholar.org/paper/8790fa4fda5c690856462cc96c23d0ad7686862d\",\"venue\":\"ACPR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2925544\",\"name\":\"Zahra Gharaee\"}],\"doi\":\"10.1016/j.cogsys.2020.05.002\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"483d6d9fb281b2c471d6b989e9b8ab8f37bdb3f1\",\"title\":\"Hierarchical growing grid networks for skeleton based action recognition\",\"url\":\"https://www.semanticscholar.org/paper/483d6d9fb281b2c471d6b989e9b8ab8f37bdb3f1\",\"venue\":\"Cognitive Systems Research\",\"year\":2020},{\"arxivId\":\"1909.09566\",\"authors\":[{\"authorId\":\"3421983\",\"name\":\"Behnaz Rezaei\"},{\"authorId\":\"1388732358\",\"name\":\"Yiorgos Christakis\"},{\"authorId\":\"91252281\",\"name\":\"Bryan Ho\"},{\"authorId\":\"49773841\",\"name\":\"K. Thomas\"},{\"authorId\":\"145859998\",\"name\":\"K. Erb\"},{\"authorId\":\"2225783\",\"name\":\"S. Ostadabbas\"},{\"authorId\":\"50260566\",\"name\":\"S. Patel\"}],\"doi\":\"10.3390/s19194266\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"84b5e88e319346385bbedb5d6c8d539693a3397f\",\"title\":\"Target-Specific Action Classification for Automated Assessment of Human Motor Behavior from Video\",\"url\":\"https://www.semanticscholar.org/paper/84b5e88e319346385bbedb5d6c8d539693a3397f\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48466004\",\"name\":\"Isaac Sanou\"},{\"authorId\":\"144353664\",\"name\":\"D. Conte\"},{\"authorId\":\"2436386\",\"name\":\"H. Cardot\"}],\"doi\":\"10.5220/0007253301910199\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"68a87599c33c597f1792709c4f0cfd673b5e1b61\",\"title\":\"An Extensible Deep Architecture for Action Recognition Problem\",\"url\":\"https://www.semanticscholar.org/paper/68a87599c33c597f1792709c4f0cfd673b5e1b61\",\"venue\":\"VISIGRAPP\",\"year\":2019},{\"arxivId\":\"2002.12886\",\"authors\":[{\"authorId\":\"1965933798\",\"name\":\"Alban Main De Boissiere\"},{\"authorId\":\"2479033\",\"name\":\"Rita Noumeir\"}],\"doi\":\"10.1109/ACCESS.2020.3023599\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f67eca7b8511a3253d58fd12b0768c9caa12610d\",\"title\":\"Infrared and 3D Skeleton Feature Fusion for RGB-D Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f67eca7b8511a3253d58fd12b0768c9caa12610d\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19177140\",\"name\":\"S. Das\"},{\"authorId\":\"38905965\",\"name\":\"Arpit Chaudhary\"},{\"authorId\":\"1729410\",\"name\":\"F. Bremond\"},{\"authorId\":\"1686585\",\"name\":\"M. Thonnat\"}],\"doi\":\"10.1109/WACV.2019.00015\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e25f9d3a5b28d8c04a44b8d9fcfcf1d0ac1d08ef\",\"title\":\"Where to Focus on for Human Action Recognition?\",\"url\":\"https://www.semanticscholar.org/paper/e25f9d3a5b28d8c04a44b8d9fcfcf1d0ac1d08ef\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":\"1903.00304\",\"authors\":[{\"authorId\":\"145949475\",\"name\":\"B. Hu\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"144530541\",\"name\":\"T. Cham\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f982a23ba54201fa650e2d943fe14b271d353ada\",\"title\":\"Progress Regression RNN for Online Spatial-Temporal Action Localization in Unconstrained Videos\",\"url\":\"https://www.semanticscholar.org/paper/f982a23ba54201fa650e2d943fe14b271d353ada\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1696573\",\"name\":\"Jiagang Zhu\"},{\"authorId\":\"9276071\",\"name\":\"Wei Zou\"},{\"authorId\":\"49659001\",\"name\":\"Zheng Zhu\"},{\"authorId\":\"97474510\",\"name\":\"L. Xu\"},{\"authorId\":\"153940079\",\"name\":\"Guan Huang\"}],\"doi\":\"10.1109/LSP.2019.2942739\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d45d6e1625af82c656ee9cc6d98fd7f58c923636\",\"title\":\"Action Machine: Toward Person-Centric Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/d45d6e1625af82c656ee9cc6d98fd7f58c923636\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3216212\",\"name\":\"Vladyslav Sydorov\"},{\"authorId\":\"72492981\",\"name\":\"Alahari Karteek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"32045707a041e18f7afd2b4e7024f9b0dad75890\",\"title\":\"Focused Attention for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/32045707a041e18f7afd2b4e7024f9b0dad75890\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1416650467\",\"name\":\"Vida Adeli\"},{\"authorId\":\"1707752\",\"name\":\"E. F. Ersi\"},{\"authorId\":\"1734678\",\"name\":\"A. Harati\"}],\"doi\":\"10.1016/j.imavis.2019.08.009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"da6e00eeee9c068e081e24836b230024eaa2eeae\",\"title\":\"A component-based video content representation for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/da6e00eeee9c068e081e24836b230024eaa2eeae\",\"venue\":\"Image Vis. Comput.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47719677\",\"name\":\"Xiaolei Qin\"},{\"authorId\":\"1766722\",\"name\":\"Y. Ge\"},{\"authorId\":\"107836313\",\"name\":\"Liuwei Zhan\"},{\"authorId\":\"107717257\",\"name\":\"Guangrui Li\"},{\"authorId\":\"1786011\",\"name\":\"Sheng Huang\"},{\"authorId\":\"19226165\",\"name\":\"Hongxing Wang\"},{\"authorId\":\"47591280\",\"name\":\"Feiyu Chen\"}],\"doi\":\"10.1109/VCIP.2018.8698624\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"324f081aa68b93468de13c4c799377d6ab18b37b\",\"title\":\"Joint Deep Learning for RGB-D Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/324f081aa68b93468de13c4c799377d6ab18b37b\",\"venue\":\"2018 IEEE Visual Communications and Image Processing (VCIP)\",\"year\":2018},{\"arxivId\":\"1806.11328\",\"authors\":[{\"authorId\":\"1902524\",\"name\":\"Guilhem Ch\\u00e9ron\"},{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a230350dc8a135fc390f9bb634249d08a07cea4e\",\"title\":\"A flexible model for training action localization with varying levels of supervision\",\"url\":\"https://www.semanticscholar.org/paper/a230350dc8a135fc390f9bb634249d08a07cea4e\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1806.02424\",\"authors\":[{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"143891655\",\"name\":\"H. Jiang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"21e1d7a8b0e472e478eef1585e7823210e7ab92d\",\"title\":\"Action4D: Real-time Action Recognition in the Crowd and Clutter\",\"url\":\"https://www.semanticscholar.org/paper/21e1d7a8b0e472e478eef1585e7823210e7ab92d\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"65773211\",\"name\":\"Carlos Ant\\u00f4nio Caetano J\\u00fanior\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"21f42f737204ab5a8a0e9dbf1417b1bb26a07273\",\"title\":\"Motion-based representations for activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/21f42f737204ab5a8a0e9dbf1417b1bb26a07273\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1817030\",\"name\":\"Saining Xie\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"1808244\",\"name\":\"J. Huang\"},{\"authorId\":\"144035504\",\"name\":\"Zhuowen Tu\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4fa0d73b8ba114578744c2ebaf610d2ca9694f45\",\"title\":\"Rethinking Spatiotemporal Feature Learning For Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/4fa0d73b8ba114578744c2ebaf610d2ca9694f45\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35286235\",\"name\":\"Erick Hendra Putra Alwando\"},{\"authorId\":\"1736618\",\"name\":\"Y. Chen\"},{\"authorId\":\"9319953\",\"name\":\"W. Fang\"}],\"doi\":\"10.1109/TCSVT.2018.2887283\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"728412cd6d7f2e7e6dcb2917751f8b40f4313008\",\"title\":\"CNN-Based Multiple Path Search for Action Tube Detection in Videos\",\"url\":\"https://www.semanticscholar.org/paper/728412cd6d7f2e7e6dcb2917751f8b40f4313008\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"1912.04070\",\"authors\":[{\"authorId\":\"82657029\",\"name\":\"G. Varol\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d9cd1ffcd91ef7e51b7a6bb4e65a3fada4e11244\",\"title\":\"Synthetic Humans for Action Recognition from Unseen Viewpoints\",\"url\":\"https://www.semanticscholar.org/paper/d9cd1ffcd91ef7e51b7a6bb4e65a3fada4e11244\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2010.08164\",\"authors\":[{\"authorId\":\"47287725\",\"name\":\"Anshul B. Shah\"},{\"authorId\":\"2850880\",\"name\":\"Shlok Kumar Mishra\"},{\"authorId\":\"2068427\",\"name\":\"Ankan Bansal\"},{\"authorId\":\"1391201966\",\"name\":\"Jun-Cheng Chen\"},{\"authorId\":\"69416958\",\"name\":\"Ramalingam Chellappa\"},{\"authorId\":\"51453757\",\"name\":\"Abhinav Shrivastava\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5ac51a6eb28656c670c36a6460be0e458b2e562f\",\"title\":\"Pose And Joint-Aware Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5ac51a6eb28656c670c36a6460be0e458b2e562f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39893135\",\"name\":\"M. Yu\"},{\"authorId\":\"1712773\",\"name\":\"Weizhe Zhang\"},{\"authorId\":\"48411615\",\"name\":\"Qingxiang Zeng\"},{\"authorId\":\"47074418\",\"name\":\"C. Wang\"},{\"authorId\":\"38158055\",\"name\":\"J. Li\"}],\"doi\":\"10.1109/ICAIIC.2019.8669069\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ad0dba3713a1210f0b89c66c25e93b22e5e04d9e\",\"title\":\"Human-Object Contour for Action Recognition with Attentional Multi-modal Fusion Network\",\"url\":\"https://www.semanticscholar.org/paper/ad0dba3713a1210f0b89c66c25e93b22e5e04d9e\",\"venue\":\"2019 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)\",\"year\":2019},{\"arxivId\":\"2010.08841\",\"authors\":[{\"authorId\":\"151478121\",\"name\":\"Soufiane Lamghari\"},{\"authorId\":\"1705256\",\"name\":\"Guillaume-Alexandre Bilodeau\"},{\"authorId\":\"48676026\",\"name\":\"N. Saunier\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f10fd7dd1b93c253b96952c27546709190d157cc\",\"title\":\"A Grid-based Representation for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f10fd7dd1b93c253b96952c27546709190d157cc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1639344722\",\"name\":\"Junqing Miao\"},{\"authorId\":\"1791880\",\"name\":\"Hailun Xia\"},{\"authorId\":\"7801828\",\"name\":\"Zhimin Zeng\"}],\"doi\":\"10.1109/ICCC47050.2019.9064443\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3c6f5ee9b64bf6bd7557193665bc38b3e9a0ac1f\",\"title\":\"Exploiting Pose Mask Features For Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3c6f5ee9b64bf6bd7557193665bc38b3e9a0ac1f\",\"venue\":\"2019 IEEE 5th International Conference on Computer and Communications (ICCC)\",\"year\":2019},{\"arxivId\":\"1711.09618\",\"authors\":[{\"authorId\":\"8197937\",\"name\":\"K. Ohnishi\"},{\"authorId\":\"48333400\",\"name\":\"S. Yamamoto\"},{\"authorId\":\"3250559\",\"name\":\"Y. Ushiku\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e25c57a6395b7c8861088699eef1a56b6f1d70ad\",\"title\":\"Hierarchical Video Generation from Orthogonal Information: Optical Flow and Texture\",\"url\":\"https://www.semanticscholar.org/paper/e25c57a6395b7c8861088699eef1a56b6f1d70ad\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"2011.00553\",\"authors\":[{\"authorId\":\"1485725797\",\"name\":\"Guoliang Liu\"},{\"authorId\":\"47835373\",\"name\":\"Qinghui Zhang\"},{\"authorId\":\"9310782\",\"name\":\"Y. Cao\"},{\"authorId\":\"46276708\",\"name\":\"Jun-Wei Li\"},{\"authorId\":\"1491232360\",\"name\":\"Hao Wu\"},{\"authorId\":\"153418687\",\"name\":\"Guohui Tian\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b0242f0b5b81ed30e404a211ee5664a620122926\",\"title\":\"Memory Group Sampling Based Online Action Recognition Using Kinetic Skeleton Features\",\"url\":\"https://www.semanticscholar.org/paper/b0242f0b5b81ed30e404a211ee5664a620122926\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144787162\",\"name\":\"D. Nova\"},{\"authorId\":\"144982894\",\"name\":\"A. Ferreira\"},{\"authorId\":\"145286037\",\"name\":\"P. Cortez\"}],\"doi\":\"10.1007/978-3-030-16447-8_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bacb13982e531e43c236147d65ba2bf5e44a379f\",\"title\":\"A Machine Learning Approach to Detect Violent Behaviour from Video\",\"url\":\"https://www.semanticscholar.org/paper/bacb13982e531e43c236147d65ba2bf5e44a379f\",\"venue\":\"INTETAIN\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3136303\",\"name\":\"G. Cong\"},{\"authorId\":\"2972684\",\"name\":\"G. Domeniconi\"},{\"authorId\":\"47377263\",\"name\":\"Joshua Shapiro\"},{\"authorId\":\"34765265\",\"name\":\"C. Yang\"},{\"authorId\":\"144969569\",\"name\":\"B. Chen\"}],\"doi\":\"10.1109/WACV.2019.00013\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dcdf68e007737ebae40e27239b3340b236337f03\",\"title\":\"Video Action Recognition With an Additional End-to-End Trained Temporal Stream\",\"url\":\"https://www.semanticscholar.org/paper/dcdf68e007737ebae40e27239b3340b236337f03\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8708983\",\"name\":\"Nour El Din Elmadany\"},{\"authorId\":\"7737775\",\"name\":\"Yifeng He\"},{\"authorId\":\"1721867\",\"name\":\"L. Guan\"}],\"doi\":\"10.1109/TIP.2018.2855438\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3e28bb5189c06ac97cf2b7702dbdf0b4fece14da\",\"title\":\"Information Fusion for Human Action Recognition via Biset/Multiset Globality Locality Preserving Canonical Correlation Analysis\",\"url\":\"https://www.semanticscholar.org/paper/3e28bb5189c06ac97cf2b7702dbdf0b4fece14da\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":\"1904.09140\",\"authors\":[{\"authorId\":\"2505740\",\"name\":\"Dennis Ludl\"},{\"authorId\":\"7932331\",\"name\":\"T. Gulde\"},{\"authorId\":\"8045043\",\"name\":\"C. Curio\"}],\"doi\":\"10.1109/ITSC.2019.8917128\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f889fe0875881b3cfa7a424eaf99f7dfd02738ce\",\"title\":\"Simple yet efficient real-time pose-based action recognition\",\"url\":\"https://www.semanticscholar.org/paper/f889fe0875881b3cfa7a424eaf99f7dfd02738ce\",\"venue\":\"2019 IEEE Intelligent Transportation Systems Conference (ITSC)\",\"year\":2019},{\"arxivId\":\"2009.13087\",\"authors\":[{\"authorId\":\"3173493\",\"name\":\"Y. Li\"},{\"authorId\":\"2050979\",\"name\":\"Zhichao Lu\"},{\"authorId\":\"3182065\",\"name\":\"Xuehan Xiong\"},{\"authorId\":\"4240351\",\"name\":\"Jonathan Huang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c8bf6f41d6df5c6cdc6249aecfa1aab027f0c8e0\",\"title\":\"PERF-Net: Pose Empowered RGB-Flow Net\",\"url\":\"https://www.semanticscholar.org/paper/c8bf6f41d6df5c6cdc6249aecfa1aab027f0c8e0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3384254\",\"name\":\"Sijie Song\"},{\"authorId\":\"40093162\",\"name\":\"Cuiling Lan\"},{\"authorId\":\"1757173\",\"name\":\"Junliang Xing\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"},{\"authorId\":\"41127426\",\"name\":\"Jiaying Liu\"}],\"doi\":\"10.1109/ICME.2018.8486486\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d2b142684220e1e04b4cc5f95f0a68ae643175cc\",\"title\":\"Skeleton-Indexed Deep Multi-Modal Feature Learning for High Performance Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d2b142684220e1e04b4cc5f95f0a68ae643175cc\",\"venue\":\"2018 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152460549\",\"name\":\"Antonia Breuer\"},{\"authorId\":\"153269740\",\"name\":\"Jana Kirschner\"},{\"authorId\":\"1694892\",\"name\":\"S. Homoceanu\"},{\"authorId\":\"1679795\",\"name\":\"T. Fingscheidt\"}],\"doi\":\"10.1109/IVS.2019.8813816\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d16fab6cfc5f5a324e00e026d2b68c970f1b3702\",\"title\":\"Towards Tactical Maneuver Detection for Autonomous Driving Based on Vision Only\",\"url\":\"https://www.semanticscholar.org/paper/d16fab6cfc5f5a324e00e026d2b68c970f1b3702\",\"venue\":\"2019 IEEE Intelligent Vehicles Symposium (IV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19177140\",\"name\":\"S. Das\"},{\"authorId\":\"49796048\",\"name\":\"M. Thonnat\"},{\"authorId\":\"69929964\",\"name\":\"F. Br\\u00e9mond\"}],\"doi\":\"10.1109/WACV45572.2020.9093575\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8cdc241f90d578a1dd79db11081f291211986ac9\",\"title\":\"Looking deeper into Time for Activities of Daily Living Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8cdc241f90d578a1dd79db11081f291211986ac9\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1807.10982\",\"authors\":[{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"1781242\",\"name\":\"Abhinav Shrivastava\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1007/978-3-030-01252-6_20\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6b325af08a63bc8f94c39ae1c12509dce23d755c\",\"title\":\"Actor-Centric Relation Network\",\"url\":\"https://www.semanticscholar.org/paper/6b325af08a63bc8f94c39ae1c12509dce23d755c\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2011.00043\",\"authors\":[{\"authorId\":\"21518096\",\"name\":\"Zhengyuan Yang\"},{\"authorId\":\"48984081\",\"name\":\"A. Kay\"},{\"authorId\":\"66508219\",\"name\":\"Y. Li\"},{\"authorId\":\"5687436\",\"name\":\"W. Cross\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"41595f75fd06219109f57c084b4c8eae1352b410\",\"title\":\"Pose-based Body Language Recognition for Emotion and Psychiatric Symptom Interpretation\",\"url\":\"https://www.semanticscholar.org/paper/41595f75fd06219109f57c084b4c8eae1352b410\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19177140\",\"name\":\"S. Das\"},{\"authorId\":\"34561667\",\"name\":\"Michal Koperski\"},{\"authorId\":\"1729410\",\"name\":\"F. Bremond\"},{\"authorId\":\"2647267\",\"name\":\"G. Francesca\"}],\"doi\":\"10.1109/AVSS.2018.8639122\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e0793b85c46c29387a1cc3ef801dcbc4782126e3\",\"title\":\"Deep-Temporal LSTM for Daily Living Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e0793b85c46c29387a1cc3ef801dcbc4782126e3\",\"venue\":\"2018 15th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24289349\",\"name\":\"Didik Purwanto\"},{\"authorId\":\"150282005\",\"name\":\"Rizard Renanda Adhi Pramono\"},{\"authorId\":\"49069045\",\"name\":\"Y. Chen\"},{\"authorId\":\"9319953\",\"name\":\"W. Fang\"}],\"doi\":\"10.1109/LSP.2019.2923918\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6d5ef23c727f979867ca1791d3ea7106a76f7066\",\"title\":\"Three-Stream Network With Bidirectional Self-Attention for Action Recognition in Extreme Low Resolution Videos\",\"url\":\"https://www.semanticscholar.org/paper/6d5ef23c727f979867ca1791d3ea7106a76f7066\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"28933059\",\"name\":\"Jiangchuan Wei\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"50130622\",\"name\":\"Yun Yi\"},{\"authorId\":\"8194130\",\"name\":\"Qinyu Li\"},{\"authorId\":\"8312366\",\"name\":\"De-Shuang Huang\"}],\"doi\":\"10.1109/ICIP.2019.8802979\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6c4e7471cd845223b852efe09e5985544332b22a\",\"title\":\"P3D-CTN: Pseudo-3D Convolutional Tube Network for Spatio-Temporal Action Detection in Videos\",\"url\":\"https://www.semanticscholar.org/paper/6c4e7471cd845223b852efe09e5985544332b22a\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"2003.12737\",\"authors\":[{\"authorId\":\"32781361\",\"name\":\"Kirill Gavrilyuk\"},{\"authorId\":\"35663637\",\"name\":\"R. Sanford\"},{\"authorId\":\"145556010\",\"name\":\"M. Javan\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1109/cvpr42600.2020.00092\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c4668668c3b9f0bda4d207b3e6d397034977f0e\",\"title\":\"Actor-Transformers for Group Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c4668668c3b9f0bda4d207b3e6d397034977f0e\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1876283791\",\"name\":\"Ling-An Zeng\"},{\"authorId\":\"94281814\",\"name\":\"Fa-Ting Hong\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"},{\"authorId\":\"50543849\",\"name\":\"Q. Yu\"},{\"authorId\":\"8434337\",\"name\":\"W. Zeng\"},{\"authorId\":null,\"name\":\"Yao-Wei Wang\"},{\"authorId\":\"153224231\",\"name\":\"Jianhuang Lai\"}],\"doi\":\"10.1145/3394171.3413560\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"971eab82480e3f3b75c2446561aab820b0dee300\",\"title\":\"Hybrid Dynamic-static Context-aware Attention Network for Action Assessment in Long Videos\",\"url\":\"https://www.semanticscholar.org/paper/971eab82480e3f3b75c2446561aab820b0dee300\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"94299235\",\"name\":\"Julius Surya Sumantri\"},{\"authorId\":\"145789132\",\"name\":\"I. K. Park\"}],\"doi\":\"10.1109/TCI.2020.3011854\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6f35a9bb59b1ec7eb0d125682d88343c71d7c492\",\"title\":\"360 Panorama Synthesis from a Sparse Set of Images on a Low-Power Device\",\"url\":\"https://www.semanticscholar.org/paper/6f35a9bb59b1ec7eb0d125682d88343c71d7c492\",\"venue\":\"IEEE Transactions on Computational Imaging\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2896701\",\"name\":\"G. An\"},{\"authorId\":\"4464686\",\"name\":\"ZhenXing Zheng\"},{\"authorId\":\"144953181\",\"name\":\"D. Wu\"},{\"authorId\":\"153168978\",\"name\":\"Wen Zhou\"}],\"doi\":\"10.1016/j.jvcir.2019.102650\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a22e41d8ac3c56072d5fe1136567d1b82d9bb46e\",\"title\":\"Deep spectral feature pyramid in the frequency domain for long-term action recognition\",\"url\":\"https://www.semanticscholar.org/paper/a22e41d8ac3c56072d5fe1136567d1b82d9bb46e\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38243491\",\"name\":\"A. Mahmood\"},{\"authorId\":\"31330222\",\"name\":\"S. Al-M\\u00e1adeed\"}],\"doi\":\"10.1007/s00138-019-01039-3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c0d3024822152d4dd948dd8222eef22c1e5c342e\",\"title\":\"Action recognition in poor-quality spectator crowd videos using head distribution-based person segmentation\",\"url\":\"https://www.semanticscholar.org/paper/c0d3024822152d4dd948dd8222eef22c1e5c342e\",\"venue\":\"Machine Vision and Applications\",\"year\":2019},{\"arxivId\":\"1902.10024\",\"authors\":[{\"authorId\":\"143884578\",\"name\":\"W. McNally\"},{\"authorId\":\"144821966\",\"name\":\"A. Wong\"},{\"authorId\":\"144304939\",\"name\":\"J. McPhee\"}],\"doi\":\"10.1109/CRV.2019.00015\",\"intent\":[\"methodology\",\"result\"],\"isInfluential\":false,\"paperId\":\"bf3e15a9392621c45da6141a78a60d341ab2e506\",\"title\":\"STAR-Net: Action Recognition using Spatio-Temporal Activation Reprojection\",\"url\":\"https://www.semanticscholar.org/paper/bf3e15a9392621c45da6141a78a60d341ab2e506\",\"venue\":\"2019 16th Conference on Computer and Robot Vision (CRV)\",\"year\":2019},{\"arxivId\":\"1907.13051\",\"authors\":[{\"authorId\":\"21518096\",\"name\":\"Zhengyuan Yang\"},{\"authorId\":\"66508219\",\"name\":\"Y. Li\"},{\"authorId\":\"9145768\",\"name\":\"Linjie Yang\"},{\"authorId\":\"49410859\",\"name\":\"Ning Zhang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a0f398145f6c67059a13798476ebc96abf2f622\",\"title\":\"Weakly Supervised Body Part Segmentation with Pose based Part Priors.\",\"url\":\"https://www.semanticscholar.org/paper/8a0f398145f6c67059a13798476ebc96abf2f622\",\"venue\":\"\",\"year\":2020}],\"corpusId\":10611376,\"doi\":\"10.1109/ICCV.2017.316\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":12,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"eac1b644492c10546a50f3e125a1f790ec46365f\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"P. Weinzaepfel\"},{\"authorId\":null,\"name\":\"X. Martin\"},{\"authorId\":null,\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Towards weaklysupervised action localization\",\"url\":\"\",\"venue\":\"CoRR, abs/1605.05197,\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"N. Sedaghat\"},{\"authorId\":null,\"name\":\"M. Zolfaghari\"},{\"authorId\":null,\"name\":\"T. Brox\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Orientationboosted voxel nets for 3d object recognition\",\"url\":\"\",\"venue\":\"CoRR, abs/1604.03351,\",\"year\":2016},{\"arxivId\":\"1212.0402\",\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"title\":\"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\",\"url\":\"https://www.semanticscholar.org/paper/da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":\"1506.03607\",\"authors\":[{\"authorId\":\"1902524\",\"name\":\"Guilhem Ch\\u00e9ron\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2015.368\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c4697681079de557cc04e209762b1a4c1eaae709\",\"title\":\"P-CNN: Pose-Based CNN Features for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c4697681079de557cc04e209762b1a4c1eaae709\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1007/978-3-319-46493-0_45\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ddbd24a73ba3d74028596f393bb07a6b87a469c0\",\"title\":\"Multi-region Two-Stream R-CNN for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/ddbd24a73ba3d74028596f393bb07a6b87a469c0\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1713941\",\"name\":\"Christopher Zach\"},{\"authorId\":\"1730097\",\"name\":\"T. Pock\"},{\"authorId\":\"144746444\",\"name\":\"H. Bischof\"}],\"doi\":\"10.1007/978-3-540-74936-3_22\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f6bbe9afab5fd61f36de5461e9e6a30ca462c7c\",\"title\":\"A Duality Based Approach for Realtime TV-L1 Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/0f6bbe9afab5fd61f36de5461e9e6a30ca462c7c\",\"venue\":\"DAGM-Symposium\",\"year\":2007},{\"arxivId\":\"1604.02808\",\"authors\":[{\"authorId\":\"3000984\",\"name\":\"Amir Shahroudy\"},{\"authorId\":\"40940512\",\"name\":\"Jun Liu\"},{\"authorId\":\"2475944\",\"name\":\"Tian-Tsong Ng\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"}],\"doi\":\"10.1109/CVPR.2016.115\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"091e4d3c85dc0a8212afea875cd3b162d273d46b\",\"title\":\"NTU RGB+D: A Large Scale Dataset for 3D Human Activity Analysis\",\"url\":\"https://www.semanticscholar.org/paper/091e4d3c85dc0a8212afea875cd3b162d273d46b\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1505.04868\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1109/CVPR.2015.7299059\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"df658828fb4146877f1031ec9d07052f7eb31186\",\"title\":\"Action recognition with trajectory-pooled deep-convolutional descriptors\",\"url\":\"https://www.semanticscholar.org/paper/df658828fb4146877f1031ec9d07052f7eb31186\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1406.2199\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"title\":\"Two-Stream Convolutional Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144590074\",\"name\":\"Gabriel L. Oliveira\"},{\"authorId\":\"1725973\",\"name\":\"W. Burgard\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1109/IROS.2016.7759717\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"965eb97c3c98a62b975c960c8d78e774aea745e3\",\"title\":\"Efficient deep models for monocular road segmentation\",\"url\":\"https://www.semanticscholar.org/paper/965eb97c3c98a62b975c960c8d78e774aea745e3\",\"venue\":\"2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48950628\",\"name\":\"N. Dalal\"},{\"authorId\":\"1756114\",\"name\":\"B. Triggs\"}],\"doi\":\"10.1109/CVPR.2005.177\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cec734d7097ab6b1e60d95228ffd64248eb89d66\",\"title\":\"Histograms of oriented gradients for human detection\",\"url\":\"https://www.semanticscholar.org/paper/cec734d7097ab6b1e60d95228ffd64248eb89d66\",\"venue\":\"2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48933900\",\"name\":\"Q. Li\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1145/2911996.2912001\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1128a4f57148cec96c0ef4ae3b5a0fbf07efbad9\",\"title\":\"Action Recognition by Learning Deep Multi-Granular Spatio-Temporal Video Representation\",\"url\":\"https://www.semanticscholar.org/paper/1128a4f57148cec96c0ef4ae3b5a0fbf07efbad9\",\"venue\":\"ICMR\",\"year\":2016},{\"arxivId\":\"1408.5093\",\"authors\":[{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"1782282\",\"name\":\"Evan Shelhamer\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"3049736\",\"name\":\"S. Karayev\"},{\"authorId\":\"144361581\",\"name\":\"J. Long\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1145/2647868.2654889\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6bdb186ec4726e00a8051119636d4df3b94043b5\",\"title\":\"Caffe: Convolutional Architecture for Fast Feature Embedding\",\"url\":\"https://www.semanticscholar.org/paper/6bdb186ec4726e00a8051119636d4df3b94043b5\",\"venue\":\"ACM Multimedia\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390562671\",\"name\":\"J. S\\u00e1nchez\"},{\"authorId\":\"1723883\",\"name\":\"F. Perronnin\"},{\"authorId\":\"1722052\",\"name\":\"Thomas Mensink\"},{\"authorId\":\"1721683\",\"name\":\"J. Verbeek\"}],\"doi\":\"10.1007/s11263-013-0636-x\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d4cede3acfd94fccc927519e04384a8debfec705\",\"title\":\"Image Classification with the Fisher Vector: Theory and Practice\",\"url\":\"https://www.semanticscholar.org/paper/d4cede3acfd94fccc927519e04384a8debfec705\",\"venue\":\"International Journal of Computer Vision\",\"year\":2013},{\"arxivId\":\"1608.07138\",\"authors\":[{\"authorId\":\"37868227\",\"name\":\"C. D. Souza\"},{\"authorId\":\"1799820\",\"name\":\"Adrien Gaidon\"},{\"authorId\":\"2286630\",\"name\":\"E. Vig\"},{\"authorId\":\"3940956\",\"name\":\"A. Pe\\u00f1a\"}],\"doi\":\"10.1007/978-3-319-46478-7_43\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4191d91b6f8c6e48ba6aed3451384b6122ab4a15\",\"title\":\"Sympathy for the Details: Dense Trajectories and Hybrid Classification Architectures for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4191d91b6f8c6e48ba6aed3451384b6122ab4a15\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1411.6660\",\"authors\":[{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"144247571\",\"name\":\"Ming Lin\"},{\"authorId\":\"2314980\",\"name\":\"X. Li\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"},{\"authorId\":\"1681921\",\"name\":\"B. Raj\"}],\"doi\":\"10.1109/CVPR.2015.7298616\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10af69f11301679b6fbb23855bf10f6af1f3d2e6\",\"title\":\"Beyond Gaussian Pyramid: Multi-skip Feature Stacking for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/10af69f11301679b6fbb23855bf10f6af1f3d2e6\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1608.08851\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"3451338\",\"name\":\"A. Pazandeh\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d309e414f0d6e56e7ba45736d28ee58ae2bad478\",\"title\":\"Efficient Two-Stream Motion and Appearance 3D CNNs for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/d309e414f0d6e56e7ba45736d28ee58ae2bad478\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2121584\",\"name\":\"Wangjiang Zhu\"},{\"authorId\":\"145815850\",\"name\":\"Jie Hu\"},{\"authorId\":\"143847421\",\"name\":\"Gang Sun\"},{\"authorId\":\"47300766\",\"name\":\"X. Cao\"},{\"authorId\":\"143970608\",\"name\":\"Y. Qiao\"}],\"doi\":\"10.1109/CVPR.2016.219\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4c822785c29ceaf67a0de9c699716c94fefbd37d\",\"title\":\"A Key Volume Mining Deep Framework for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4c822785c29ceaf67a0de9c699716c94fefbd37d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2013.441\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d721f4d64b8e722222c876f0a0f226ed49476347\",\"title\":\"Action Recognition with Improved Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/d721f4d64b8e722222c876f0a0f226ed49476347\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2341854\",\"name\":\"M. Baccouche\"},{\"authorId\":\"2408697\",\"name\":\"F. Mamalet\"},{\"authorId\":\"144899680\",\"name\":\"C. Wolf\"},{\"authorId\":\"144723337\",\"name\":\"C. Garcia\"},{\"authorId\":\"1739898\",\"name\":\"A. Baskurt\"}],\"doi\":\"10.1007/978-3-642-25446-8_4\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"12b6551a0f9f5aa62f7d37f03ebc66631e529c4b\",\"title\":\"Sequential Deep Learning for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/12b6551a0f9f5aa62f7d37f03ebc66631e529c4b\",\"venue\":\"HBU\",\"year\":2011},{\"arxivId\":\"1604.08826\",\"authors\":[{\"authorId\":\"8197937\",\"name\":\"K. Ohnishi\"},{\"authorId\":\"2859204\",\"name\":\"Masatoshi Hidaka\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.1145/2964284.2967222\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"da48af74960c84750de3cfc1c9c9a5b5252d330c\",\"title\":\"Improved Dense Trajectory with Cross Streams\",\"url\":\"https://www.semanticscholar.org/paper/da48af74960c84750de3cfc1c9c9a5b5252d330c\",\"venue\":\"ACM Multimedia\",\"year\":2016},{\"arxivId\":\"1606.04992\",\"authors\":[{\"authorId\":\"1763954\",\"name\":\"I. Lillo\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"144106940\",\"name\":\"A. Soto\"}],\"doi\":\"10.1109/CVPR.2016.218\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5a60a0a074570d245d0d9c8d505b5c9ae303fed5\",\"title\":\"A Hierarchical Pose-Based Approach to Complex Action Understanding Using Dictionaries of Actionlets and Motion Poselets\",\"url\":\"https://www.semanticscholar.org/paper/5a60a0a074570d245d0d9c8d505b5c9ae303fed5\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1504.06852\",\"authors\":[{\"authorId\":\"1382344214\",\"name\":\"A. Dosovitskiy\"},{\"authorId\":\"152702479\",\"name\":\"P. Fischer\"},{\"authorId\":\"48105320\",\"name\":\"Eddy Ilg\"},{\"authorId\":\"2880264\",\"name\":\"Philip H\\u00e4usser\"},{\"authorId\":\"3322806\",\"name\":\"Caner Hazirbas\"},{\"authorId\":\"2943639\",\"name\":\"V. Golkov\"},{\"authorId\":\"1715782\",\"name\":\"P. V. D. Smagt\"},{\"authorId\":\"153685345\",\"name\":\"D. Cremers\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1109/ICCV.2015.316\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c2fb5b39428818d7ec8cc78e152e19c21b7db568\",\"title\":\"FlowNet: Learning Optical Flow with Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/c2fb5b39428818d7ec8cc78e152e19c21b7db568\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1411.4038\",\"authors\":[{\"authorId\":\"1782282\",\"name\":\"Evan Shelhamer\"},{\"authorId\":\"144361581\",\"name\":\"J. Long\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2572683\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"317aee7fc081f2b137a85c4f20129007fd8e717e\",\"title\":\"Fully Convolutional Networks for Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/317aee7fc081f2b137a85c4f20129007fd8e717e\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A Diba\"},{\"authorId\":null,\"name\":\"A M Pazandeh\"},{\"authorId\":null,\"name\":\"L V Gool\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Efficient twostream motion and appearance 3d cnns for video classification . CoRR, abs/1608\",\"url\":\"\",\"venue\":\"Efficient twostream motion and appearance 3d cnns for video classification . CoRR, abs/1608\",\"year\":2016},{\"arxivId\":\"1604.07279\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2016.296\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1e667851f67aaa4d3f75d662760a783f45ea4b05\",\"title\":\"Actionness Estimation Using Hybrid Fully Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/1e667851f67aaa4d3f75d662760a783f45ea4b05\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1411.6031\",\"authors\":[{\"authorId\":\"2082991\",\"name\":\"Georgia Gkioxari\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/CVPR.2015.7298676\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"295a1c000c5e3fd5959bb250e8376a06efa405b1\",\"title\":\"Finding action tubes\",\"url\":\"https://www.semanticscholar.org/paper/295a1c000c5e3fd5959bb250e8376a06efa405b1\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"119268487\",\"name\":\"Hueihan Jhuang\"},{\"authorId\":\"1930964\",\"name\":\"E. Garrote\"},{\"authorId\":\"145031878\",\"name\":\"T. Poggio\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"}],\"doi\":\"10.1109/ICCV.2011.6126543\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"8b3b8848a311c501e704c45c6d50430ab7068956\",\"title\":\"HMDB: A large video database for human motion recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b3b8848a311c501e704c45c6d50430ab7068956\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2676982\",\"name\":\"Hueihan Jhuang\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"},{\"authorId\":\"2133988\",\"name\":\"S. Zuffi\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"}],\"doi\":\"10.1109/ICCV.2013.396\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2cee43afc7aad6a8f7c4a6d566b60ebc79d57e7a\",\"title\":\"Towards Understanding Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2cee43afc7aad6a8f7c4a6d566b60ebc79d57e7a\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":\"1604.04494\",\"authors\":[{\"authorId\":\"2668759\",\"name\":\"G. Varol\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/TPAMI.2017.2712608\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"47e3ef70f2539386bcef604097fa9235246c6d53\",\"title\":\"Long-Term Temporal Convolutions for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/47e3ef70f2539386bcef604097fa9235246c6d53\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":\"1604.03351\",\"authors\":[{\"authorId\":\"96140284\",\"name\":\"N. Sedaghat\"},{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.5244/C.31.97\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"29cc23dd873a25f28690752d22d290cba7147849\",\"title\":\"Orientation-boosted Voxel Nets for 3D Object Recognition\",\"url\":\"https://www.semanticscholar.org/paper/29cc23dd873a25f28690752d22d290cba7147849\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"3205375\",\"name\":\"T. Lindeberg\"}],\"doi\":\"10.1109/ICCV.2003.1238378\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f90d79809325d2b78e35a79ecb372407f81b3993\",\"title\":\"Space-time interest points\",\"url\":\"https://www.semanticscholar.org/paper/f90d79809325d2b78e35a79ecb372407f81b3993\",\"venue\":\"Proceedings Ninth IEEE International Conference on Computer Vision\",\"year\":2003},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/ICCV.2003.1238663\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"642e328cae81c5adb30069b680cf60ba6b475153\",\"title\":\"Video Google: a text retrieval approach to object matching in videos\",\"url\":\"https://www.semanticscholar.org/paper/642e328cae81c5adb30069b680cf60ba6b475153\",\"venue\":\"Proceedings Ninth IEEE International Conference on Computer Vision\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3112334\",\"name\":\"Behrooz Mahasseni\"},{\"authorId\":\"143856428\",\"name\":\"S. Todorovic\"}],\"doi\":\"10.1109/CVPR.2016.333\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7854a9d1eaaac11047c22177b5ad5aa9ce2bf9e3\",\"title\":\"Regularizing Long Short Term Memory with 3D Human-Skeleton Sequences for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7854a9d1eaaac11047c22177b5ad5aa9ce2bf9e3\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145015817\",\"name\":\"Gang Yu\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1109/CVPR.2015.7298735\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"22df6b6c87d26f51c0ccf3d4dddad07ce839deb0\",\"title\":\"Fast action proposals for human action detection and search\",\"url\":\"https://www.semanticscholar.org/paper/22df6b6c87d26f51c0ccf3d4dddad07ce839deb0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/ICCV.2015.510\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"title\":\"Learning Spatiotemporal Features with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1735300\",\"name\":\"S. Haykin\"},{\"authorId\":\"35299277\",\"name\":\"B. Kosko\"}],\"doi\":\"10.1109/9780470544976.CH9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f42b865e20e61a954239f421b42007236e671f19\",\"title\":\"GradientBased Learning Applied to Document Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f42b865e20e61a954239f421b42007236e671f19\",\"venue\":\"\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"152821938\",\"name\":\"Sanketh Shetty\"},{\"authorId\":\"120906511\",\"name\":\"T. Leung\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2014.223\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"title\":\"Large-Scale Video Classification with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1401940506\",\"name\":\"Eshed Ohn-Bar\"},{\"authorId\":\"1713989\",\"name\":\"M. Trivedi\"}],\"doi\":\"10.1109/CVPRW.2013.76\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ae1dc5ca9fd0a6f0c143590f7729bc12487f82e6\",\"title\":\"Joint Angles Similarities and HOG2 for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ae1dc5ca9fd0a6f0c143590f7729bc12487f82e6\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition Workshops\",\"year\":2013},{\"arxivId\":\"1505.04597\",\"authors\":[{\"authorId\":\"1737326\",\"name\":\"O. Ronneberger\"},{\"authorId\":\"152702479\",\"name\":\"P. Fischer\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1007/978-3-319-24574-4_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6364fdaa0a0eccd823a779fcdd489173f938e91a\",\"title\":\"U-Net: Convolutional Networks for Biomedical Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/6364fdaa0a0eccd823a779fcdd489173f938e91a\",\"venue\":\"MICCAI\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"C. Wang\"},{\"authorId\":null,\"name\":\"Y. Wang\"},{\"authorId\":null,\"name\":\"A. L. Yuille\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"An approach to posebased action recognition\",\"url\":\"\",\"venue\":\"In Proceedings of the 2013 IEEE Conference on Computer Vision and Pattern Recognition,\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"1803711\",\"name\":\"H. Idrees\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/CVPR.2016.290\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"68bd9fa880a368b82782f617deefbde9552cac28\",\"title\":\"Predicting the Where and What of Actors and Actions through Online Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/68bd9fa880a368b82782f617deefbde9552cac28\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1608.00859\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-319-46484-8_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"title\":\"Temporal Segment Networks: Towards Good Practices for Deep Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1506.01929\",\"authors\":[{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"1753355\",\"name\":\"Z. Harchaoui\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2015.362\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2f488a8139630e3b2499ea2d3ff192e33387f7de\",\"title\":\"Learning to Track for Spatio-Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/2f488a8139630e3b2499ea2d3ff192e33387f7de\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121900578\",\"name\":\"Chunyu Wang\"},{\"authorId\":\"1717863\",\"name\":\"Yizhou Wang\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.1109/CVPR.2013.123\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"21258b55048a5038e3f6167b03e4fa2314ecf628\",\"title\":\"An Approach to Pose-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/21258b55048a5038e3f6167b03e4fa2314ecf628\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"P Weinzaepfel\"},{\"authorId\":null,\"name\":\"X Martin\"},{\"authorId\":null,\"name\":\"C Schmid\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Towards weaklysupervised action localization. CoRR, abs/1605\",\"url\":\"\",\"venue\":\"Towards weaklysupervised action localization. CoRR, abs/1605\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2155311\",\"name\":\"Eunbyung Park\"},{\"authorId\":\"1682965\",\"name\":\"Xufeng Han\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"}],\"doi\":\"10.1109/WACV.2016.7477589\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ec44bf99ba11f3b6d0bb32dd5bc6ac08dd0c63d6\",\"title\":\"Combining multiple sources of knowledge in deep CNNs for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/ec44bf99ba11f3b6d0bb32dd5bc6ac08dd0c63d6\",\"venue\":\"2016 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143798882\",\"name\":\"Mihir Jain\"},{\"authorId\":\"1738975\",\"name\":\"J. C. V. Gemert\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1109/CVPR.2015.7298599\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"90d44ce126b1ca7107f555db4d546d0e1843d075\",\"title\":\"What do 15,000 object categories tell us about classifying and localizing actions?\",\"url\":\"https://www.semanticscholar.org/paper/90d44ce126b1ca7107f555db4d546d0e1843d075\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1607.07043\",\"authors\":[{\"authorId\":\"40940512\",\"name\":\"Jun Liu\"},{\"authorId\":\"3000984\",\"name\":\"Amir Shahroudy\"},{\"authorId\":\"145481070\",\"name\":\"D. Xu\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"}],\"doi\":\"10.1007/978-3-319-46487-9_50\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9afbd70a4727df98a0c38c437b94b14eba6577c4\",\"title\":\"Spatio-Temporal LSTM with Trust Gates for 3D Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9afbd70a4727df98a0c38c437b94b14eba6577c4\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1906895\",\"name\":\"M. Andriluka\"},{\"authorId\":\"2299109\",\"name\":\"L. Pishchulin\"},{\"authorId\":\"2871555\",\"name\":\"P. Gehler\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1109/CVPR.2014.471\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"da8d53f9a85b40a695585aa461286e373c6b74d4\",\"title\":\"2D Human Pose Estimation: New Benchmark and State of the Art Analysis\",\"url\":\"https://www.semanticscholar.org/paper/da8d53f9a85b40a695585aa461286e373c6b74d4\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8520539\",\"name\":\"Jianfang Hu\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"},{\"authorId\":\"66117656\",\"name\":\"J. Lai\"},{\"authorId\":\"1744844\",\"name\":\"J. Zhang\"}],\"doi\":\"10.1109/TPAMI.2016.2640292\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5478e03e02c3af80be42614b745e214b9c8efa93\",\"title\":\"Jointly Learning Heterogeneous Features for RGB-D Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5478e03e02c3af80be42614b745e214b9c8efa93\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":\"1509.06086\",\"authors\":[{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"47119743\",\"name\":\"X. Wang\"},{\"authorId\":\"145222820\",\"name\":\"H. Ye\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"},{\"authorId\":null,\"name\":\"Jun Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dc9443e3ae2fe70282b1b30e3eda3717b58c0808\",\"title\":\"Fusing Multi-Stream Deep Networks for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/dc9443e3ae2fe70282b1b30e3eda3717b58c0808\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1604.06573\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2016.213\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9d9aced120e530484609164c836da64548693484\",\"title\":\"Convolutional Two-Stream Network Fusion for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9d9aced120e530484609164c836da64548693484\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1506.04579\",\"authors\":[{\"authorId\":\"40255545\",\"name\":\"W. Liu\"},{\"authorId\":\"39863668\",\"name\":\"Andrew Rabinovich\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2173f1b8172c9b5bed4650c81b69988717bd6df6\",\"title\":\"ParseNet: Looking Wider to See Better\",\"url\":\"https://www.semanticscholar.org/paper/2173f1b8172c9b5bed4650c81b69988717bd6df6\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1502.07411\",\"authors\":[{\"authorId\":\"2254178\",\"name\":\"Fayao Liu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2604251\",\"name\":\"Guosheng Lin\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"}],\"doi\":\"10.1109/TPAMI.2015.2505283\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9c21b3ffdac5f2450b82dd6660ac69f72bb9018b\",\"title\":\"Learning Depth from Single Monocular Images Using Deep Convolutional Neural Fields\",\"url\":\"https://www.semanticscholar.org/paper/9c21b3ffdac5f2450b82dd6660ac69f72bb9018b\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"},{\"authorId\":\"52184096\",\"name\":\"L. Bottou\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"1721248\",\"name\":\"P. Haffner\"}],\"doi\":\"10.1109/5.726791\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"162d958ff885f1462aeda91cd72582323fd6a1f4\",\"title\":\"Gradient-based learning applied to document recognition\",\"url\":\"https://www.semanticscholar.org/paper/162d958ff885f1462aeda91cd72582323fd6a1f4\",\"venue\":\"\",\"year\":1998},{\"arxivId\":\"1511.00561\",\"authors\":[{\"authorId\":\"2442177\",\"name\":\"Vijay Badrinarayanan\"},{\"authorId\":\"47645184\",\"name\":\"Alex Kendall\"},{\"authorId\":\"1745672\",\"name\":\"R. Cipolla\"}],\"doi\":\"10.1109/TPAMI.2016.2644615\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b0c065cd43aa7280e766b5dcbcc7e26abce59330\",\"title\":\"SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/b0c065cd43aa7280e766b5dcbcc7e26abce59330\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017}],\"title\":\"Chained Multi-stream Networks Exploiting Pose, Motion, and Appearance for Action Classification and Detection\",\"topics\":[{\"topic\":\"Markov chain\",\"topicId\":\"5418\",\"url\":\"https://www.semanticscholar.org/topic/5418\"},{\"topic\":\"Network architecture\",\"topicId\":\"58473\",\"url\":\"https://www.semanticscholar.org/topic/58473\"},{\"topic\":\"Overfitting\",\"topicId\":\"70499\",\"url\":\"https://www.semanticscholar.org/topic/70499\"},{\"topic\":\"Human Metabolome Database\",\"topicId\":\"214982\",\"url\":\"https://www.semanticscholar.org/topic/214982\"},{\"topic\":\"Network interface device\",\"topicId\":\"353029\",\"url\":\"https://www.semanticscholar.org/topic/353029\"},{\"topic\":\"Baseline (configuration management)\",\"topicId\":\"3403\",\"url\":\"https://www.semanticscholar.org/topic/3403\"},{\"topic\":\"Robotics\",\"topicId\":\"2759\",\"url\":\"https://www.semanticscholar.org/topic/2759\"},{\"topic\":\"Action potential\",\"topicId\":\"343\",\"url\":\"https://www.semanticscholar.org/topic/343\"},{\"topic\":\"Mutual exclusion\",\"topicId\":\"31132\",\"url\":\"https://www.semanticscholar.org/topic/31132\"}],\"url\":\"https://www.semanticscholar.org/paper/eac1b644492c10546a50f3e125a1f790ec46365f\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017}\n"