"{\"abstract\":\"Understanding where people look in images is an important problem in computer vision. Despite significant research, it remains unclear to what extent human fixations can be predicted by low-level (contrast) compared to highlevel (presence of objects) image features. Here we address this problem by introducing two novel models that use different feature spaces but the same readout architecture. The first model predicts human fixations based on deep neural network features trained on object recognition. This model sets a new state-of-the art in fixation prediction by achieving top performance in area under the curve metrics on the MIT300 hold-out benchmark (AUC = 88%, sAUC = 77%, NSS = 2.34). The second model uses purely low-level (isotropic contrast) features. This model achieves better performance than all models not using features pretrained on object recognition, making it a strong baseline to assess the utility of high-level features. We then evaluate and visualize which fixations are better explained by lowlevel compared to high-level image features. Surprisingly we find that a substantial proportion of fixations are better explained by the simple low-level model than the stateof- the-art model. Comparing different features within the same powerful readout architecture allows us to better understand the relevance of low- versus high-level features in predicting fixation locations, while simultaneously achieving state-of-the-art saliency prediction.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"2997408\",\"name\":\"Matthias K\\u00fcmmerer\",\"url\":\"https://www.semanticscholar.org/author/2997408\"},{\"authorId\":\"49737748\",\"name\":\"Thomas S. A. Wallis\",\"url\":\"https://www.semanticscholar.org/author/49737748\"},{\"authorId\":\"1891828\",\"name\":\"Leon A. Gatys\",\"url\":\"https://www.semanticscholar.org/author/1891828\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\",\"url\":\"https://www.semanticscholar.org/author/1731199\"}],\"citationVelocity\":41,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"37495810\",\"name\":\"Lihua Fu\"},{\"authorId\":\"2278517\",\"name\":\"Haogang Ding\"},{\"authorId\":\"49672731\",\"name\":\"Cancan Li\"},{\"authorId\":\"49370397\",\"name\":\"D. Wang\"},{\"authorId\":\"2219764\",\"name\":\"Y. Feng\"}],\"doi\":\"10.1117/1.JEI.27.5.053003\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5762871dbb5ea4a74838083793c826ccd7058fd6\",\"title\":\"Deep learning framework for saliency object detection based on global prior and local context\",\"url\":\"https://www.semanticscholar.org/paper/5762871dbb5ea4a74838083793c826ccd7058fd6\",\"venue\":\"J. Electronic Imaging\",\"year\":2018},{\"arxivId\":\"1909.05654\",\"authors\":[{\"authorId\":\"40360280\",\"name\":\"Di Fu\"},{\"authorId\":\"1798067\",\"name\":\"Cornelius Weber\"},{\"authorId\":\"3784179\",\"name\":\"G. Yang\"},{\"authorId\":\"2991958\",\"name\":\"Matthias Kerzel\"},{\"authorId\":\"5226074\",\"name\":\"Weizhi Nan\"},{\"authorId\":\"144039833\",\"name\":\"Pablo Barros\"},{\"authorId\":\"1748494\",\"name\":\"H. Wu\"},{\"authorId\":\"144227938\",\"name\":\"X. Liu\"},{\"authorId\":\"1736513\",\"name\":\"S. Wermter\"}],\"doi\":\"10.31234/osf.io/sx3uc\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0ba822ad3cd3d2bae8ec94182e57be3f30f21b43\",\"title\":\"What can computational models learn from human selective attention? A review from an audiovisual crossmodal perspective\",\"url\":\"https://www.semanticscholar.org/paper/0ba822ad3cd3d2bae8ec94182e57be3f30f21b43\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144897958\",\"name\":\"J. M. Henderson\"},{\"authorId\":\"1753709740\",\"name\":\"Jessica E. Goold\"},{\"authorId\":\"50582226\",\"name\":\"Wonil Choi\"},{\"authorId\":\"2506727\",\"name\":\"Taylor R. Hayes\"}],\"doi\":\"10.1162/jocn_a_01599\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"40c586bf1e90e6af2eca091643a2554b4cdd613d\",\"title\":\"Neural Correlates of Fixated Low- and High-level Scene Properties during Active Scene Viewing\",\"url\":\"https://www.semanticscholar.org/paper/40c586bf1e90e6af2eca091643a2554b4cdd613d\",\"venue\":\"Journal of Cognitive Neuroscience\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1810382\",\"name\":\"Zhaohui Che\"},{\"authorId\":\"51004202\",\"name\":\"A. Borji\"},{\"authorId\":\"144826390\",\"name\":\"G. Zhai\"},{\"authorId\":\"2246414\",\"name\":\"Xiongkuo Min\"},{\"authorId\":\"1822413\",\"name\":\"Guodong Guo\"},{\"authorId\":\"1776651\",\"name\":\"P. Callet\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c01a827fd687791b92e393b203028fa1bca4c5ff\",\"title\":\"Leverage eye-movement data for saliency modeling: Invariance Analysis and a Robust New Model\",\"url\":\"https://www.semanticscholar.org/paper/c01a827fd687791b92e393b203028fa1bca4c5ff\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390936291\",\"name\":\"Haoran Liang\"},{\"authorId\":\"1410304992\",\"name\":\"Ming Jiang\"},{\"authorId\":\"4487395\",\"name\":\"Ronghua Liang\"},{\"authorId\":\"153386875\",\"name\":\"Q. Zhao\"}],\"doi\":\"10.1016/j.neucom.2019.09.085\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"126e0801de465f8d2092af3eb88a89a8f2e995f7\",\"title\":\"A structure-guided approach to the prediction of natural image saliency\",\"url\":\"https://www.semanticscholar.org/paper/126e0801de465f8d2092af3eb88a89a8f2e995f7\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37203857\",\"name\":\"L. Meng\"},{\"authorId\":\"47319689\",\"name\":\"Shuai Li\"},{\"authorId\":\"1423668854\",\"name\":\"Jiaqi Feng\"},{\"authorId\":\"71222824\",\"name\":\"Y. Liu\"},{\"authorId\":\"143754859\",\"name\":\"C. Zhu\"}],\"doi\":\"10.1109/CCHI.2019.8901953\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9cb8ec27e942758268f869f2b5a7e0c708553443\",\"title\":\"Multiple Context Aggregation Network for Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/9cb8ec27e942758268f869f2b5a7e0c708553443\",\"venue\":\"2019 2nd China Symposium on Cognitive Computing and Hybrid Intelligence (CCHI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23535421\",\"name\":\"A. Flechsenhar\"},{\"authorId\":\"52055641\",\"name\":\"O. Larson\"},{\"authorId\":\"4850937\",\"name\":\"A. End\"},{\"authorId\":\"1712636\",\"name\":\"M. Gamer\"}],\"doi\":\"10.1167/18.12.11\",\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"f0ed134a594bd12cecd2f982a9138dcbb21d3920\",\"title\":\"Investigating overt and covert shifts of attention within social naturalistic scenes.\",\"url\":\"https://www.semanticscholar.org/paper/f0ed134a594bd12cecd2f982a9138dcbb21d3920\",\"venue\":\"Journal of vision\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143648851\",\"name\":\"G. Boccignone\"},{\"authorId\":\"1896593\",\"name\":\"Vittorio Cuculo\"},{\"authorId\":\"1411402819\",\"name\":\"Alessandro D\\u2019Amelio\"},{\"authorId\":\"1771623\",\"name\":\"G. Grossi\"},{\"authorId\":\"144750464\",\"name\":\"Raffaella Lanzarotti\"}],\"doi\":\"10.1109/ACCESS.2020.3021211\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ddb7ca502031376d50eaa9ae8a26048a703606b6\",\"title\":\"On Gaze Deployment to Audio-Visual Cues of Social Interactions\",\"url\":\"https://www.semanticscholar.org/paper/ddb7ca502031376d50eaa9ae8a26048a703606b6\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"14209394\",\"name\":\"Maria Laura Mele\"},{\"authorId\":\"2364585\",\"name\":\"Silvia Colabrese\"},{\"authorId\":\"150184927\",\"name\":\"Luca Calabria\"},{\"authorId\":\"39405204\",\"name\":\"D. Millar\"},{\"authorId\":\"3081076\",\"name\":\"Christiaan Erik Rijnders\"}],\"doi\":\"10.1007/978-3-030-22643-5_26\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d4c5308cfac7c7776a4a0370894db11be7e3ed7a\",\"title\":\"The Assessment of Sencogi: A Visual Complexity Model Predicting Visual Fixations\",\"url\":\"https://www.semanticscholar.org/paper/d4c5308cfac7c7776a4a0370894db11be7e3ed7a\",\"venue\":\"HCI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1767658\",\"name\":\"Yingyue Xu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bb6a1cab0cfd4adc3de102eb8835d40ffd99874c\",\"title\":\"Computational modeling for visual attention analysis\",\"url\":\"https://www.semanticscholar.org/paper/bb6a1cab0cfd4adc3de102eb8835d40ffd99874c\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3376641\",\"name\":\"A. Nuthmann\"},{\"authorId\":\"46510545\",\"name\":\"Immo Schuetz\"},{\"authorId\":\"48116275\",\"name\":\"W. Einh\\u00e4user\"}],\"doi\":\"10.1038/s41598-020-78203-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d998b33fb566a6f95d8b678bd8b389d2f09c3b8c\",\"title\":\"Salience-based object prioritization during active viewing of naturalistic scenes in young and older adults\",\"url\":\"https://www.semanticscholar.org/paper/d998b33fb566a6f95d8b678bd8b389d2f09c3b8c\",\"venue\":\"Scientific reports\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48065888\",\"name\":\"Di Fu\"},{\"authorId\":\"152448143\",\"name\":\"C. Weber\"},{\"authorId\":\"9878059\",\"name\":\"Guochun Yang\"},{\"authorId\":\"2991958\",\"name\":\"Matthias Kerzel\"},{\"authorId\":\"1406707237\",\"name\":\"Weizhi Nan\"},{\"authorId\":\"144039832\",\"name\":\"P. Barros\"},{\"authorId\":\"49498866\",\"name\":\"Haiyan Wu\"},{\"authorId\":\"144227938\",\"name\":\"X. Liu\"},{\"authorId\":\"47291450\",\"name\":\"Stefan Wermter\"}],\"doi\":\"10.3389/fnint.2020.00010\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e302e57072bd160b6420ba5b190b0d7286ab74e9\",\"title\":\"What Can Computational Models Learn From Human Selective Attention? A Review From an Audiovisual Unimodal and Crossmodal Perspective\",\"url\":\"https://www.semanticscholar.org/paper/e302e57072bd160b6420ba5b190b0d7286ab74e9\",\"venue\":\"Frontiers in Integrative Neuroscience\",\"year\":2020},{\"arxivId\":\"2003.04942\",\"authors\":[{\"authorId\":\"1557425970\",\"name\":\"Navyasri Reddy\"},{\"authorId\":\"151444035\",\"name\":\"Samyak Jain\"},{\"authorId\":\"34935738\",\"name\":\"Pradeep Yarlagadda\"},{\"authorId\":\"145091336\",\"name\":\"V. Gandhi\"}],\"doi\":null,\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"46d71e96013107c1d2be0b6ec44f4def7ac7fbe2\",\"title\":\"Tidying Deep Saliency Prediction Architectures\",\"url\":\"https://www.semanticscholar.org/paper/46d71e96013107c1d2be0b6ec44f4def7ac7fbe2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36465167\",\"name\":\"F. Leit\\u00e3o\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d4eae81c7b7f1d5e9f9d85e3340ed10b9c355cec\",\"title\":\"Predicting Eye Fixations with a Deep Reconstruction-Based Approach\",\"url\":\"https://www.semanticscholar.org/paper/d4eae81c7b7f1d5e9f9d85e3340ed10b9c355cec\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32289836\",\"name\":\"S. Yamaguchi\"},{\"authorId\":\"2817435\",\"name\":\"M. Nishiyama\"},{\"authorId\":\"1389966566\",\"name\":\"Yoshio Iwai\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"133d772c7fdbe41da3c594c4f59e141ed5e0c531\",\"title\":\"Gender Classification using Weighted Random Forest with Gaze Distribution\",\"url\":\"https://www.semanticscholar.org/paper/133d772c7fdbe41da3c594c4f59e141ed5e0c531\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2012.14185\",\"authors\":[{\"authorId\":\"83015253\",\"name\":\"Alex Hern\\u00e1ndez-Garc\\u00eda\"}],\"doi\":null,\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5e21d7ce531a81817d5f4de8ff5de3e444cf6629\",\"title\":\"Data augmentation and image understanding\",\"url\":\"https://www.semanticscholar.org/paper/5e21d7ce531a81817d5f4de8ff5de3e444cf6629\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1909.07953\",\"authors\":[{\"authorId\":\"152932130\",\"name\":\"Lei Shi\"},{\"authorId\":\"117234894\",\"name\":\"Cosmin Copot\"},{\"authorId\":\"152406744\",\"name\":\"S. Vanlanduit\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4fac129fd840dc37a75a7bf396440b5ecc7e7177\",\"title\":\"What Are You Looking at? Detecting Human Intention in Gaze based Human-Robot Interaction\",\"url\":\"https://www.semanticscholar.org/paper/4fac129fd840dc37a75a7bf396440b5ecc7e7177\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47849651\",\"name\":\"A. Clarke\"},{\"authorId\":\"2240067\",\"name\":\"A. Nowakowska\"},{\"authorId\":\"114026666\",\"name\":\"A. Hunt\"}],\"doi\":\"10.3390/vision3030046\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"52a0da4b742f66b4149113fd5b8955dc224a0daf\",\"title\":\"Seeing Beyond Salience and Guidance: The Role of Bias and Decision in Visual Search\",\"url\":\"https://www.semanticscholar.org/paper/52a0da4b742f66b4149113fd5b8955dc224a0daf\",\"venue\":\"Vision\",\"year\":2019},{\"arxivId\":\"1810.03716\",\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"4df34e0194faa27078832cb5078a2af6c9d0ea9b\",\"title\":\"Saliency Prediction in the Deep Learning Era: An Empirical Investigation\",\"url\":\"https://www.semanticscholar.org/paper/4df34e0194faa27078832cb5078a2af6c9d0ea9b\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2235266\",\"name\":\"B. de Haas\"},{\"authorId\":\"91826616\",\"name\":\"Alexios L. Iakovidis\"},{\"authorId\":\"120452522\",\"name\":\"D. S. Schwarzkopf\"},{\"authorId\":\"3322056\",\"name\":\"K. Gegenfurtner\"}],\"doi\":\"10.1073/pnas.1820553116\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1033684c4c0292269857d8184182e79c6dbb5397\",\"title\":\"Individual differences in visual salience vary along semantic dimensions\",\"url\":\"https://www.semanticscholar.org/paper/1033684c4c0292269857d8184182e79c6dbb5397\",\"venue\":\"Proceedings of the National Academy of Sciences\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1696991\",\"name\":\"G. Zelinsky\"},{\"authorId\":\"48598731\",\"name\":\"Zhibo Yang\"},{\"authorId\":\"37012552\",\"name\":\"L. Huang\"},{\"authorId\":\"152829057\",\"name\":\"Yupei Chen\"},{\"authorId\":\"144078005\",\"name\":\"Seoyoung Ahn\"},{\"authorId\":\"83942844\",\"name\":\"Zi-jun Wei\"},{\"authorId\":\"32363057\",\"name\":\"H. Adeli\"},{\"authorId\":\"1686020\",\"name\":\"D. Samaras\"},{\"authorId\":\"2356016\",\"name\":\"Minh Hoai\"}],\"doi\":\"10.1109/CVPRW.2019.00111\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10d8c854a366b05433a41c59cc1efd13e8a93214\",\"title\":\"Benchmarking Gaze Prediction for Categorical Visual Search\",\"url\":\"https://www.semanticscholar.org/paper/10d8c854a366b05433a41c59cc1efd13e8a93214\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"73919690\",\"name\":\"Nidhinandana Salian\"}],\"doi\":\"10.1007/978-981-13-2907-4_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b2a0048e23a2e88768d155eac351443573cd4f5d\",\"title\":\"Visual Attention and Memory Augmented Activity Recognition and Behavioral Prediction\",\"url\":\"https://www.semanticscholar.org/paper/b2a0048e23a2e88768d155eac351443573cd4f5d\",\"venue\":\"ATIS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38591458\",\"name\":\"Phutphalla Kong\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"275e09dfebd01409ddb38da8972ae4d53aed06a5\",\"title\":\"Saliency and Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/275e09dfebd01409ddb38da8972ae4d53aed06a5\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2997408\",\"name\":\"Matthias K\\u00fcmmerer\"},{\"authorId\":\"49737748\",\"name\":\"Thomas S. A. Wallis\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":\"10.1007/978-3-030-01270-0_47\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d9a484f6ffd5fc006401dee749493142623ba4c9\",\"title\":\"Saliency Benchmarking Made Easy: Separating Models, Maps and Metrics\",\"url\":\"https://www.semanticscholar.org/paper/d9a484f6ffd5fc006401dee749493142623ba4c9\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47968942\",\"name\":\"K. Zhang\"},{\"authorId\":\"3332324\",\"name\":\"X. Zhao\"},{\"authorId\":\"47378234\",\"name\":\"R. Mo\"}],\"doi\":\"10.1007/978-3-030-00563-4_44\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bdd4e7be19d1942937f803aad1ffc69b5c4eaeb5\",\"title\":\"Bottom-Up Saliency Prediction by Simulating End-Stopping with Log-Gabor\",\"url\":\"https://www.semanticscholar.org/paper/bdd4e7be19d1942937f803aad1ffc69b5c4eaeb5\",\"venue\":\"BICS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"46887280\",\"name\":\"Giuseppe Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"49859d84cd3884d7bc61b5049222e454c46ff8ac\",\"title\":\"Attentive ConvLSTM Learned Priors ( x 2 ) \\u03bc , \\u03c3\\u03bc , \\u03c3\\u03bc , \\u03c3 Dilated Convolutional Network Input Image Saliency\",\"url\":\"https://www.semanticscholar.org/paper/49859d84cd3884d7bc61b5049222e454c46ff8ac\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"47957770\",\"name\":\"Xuying Zhang\"},{\"authorId\":\"40626740\",\"name\":\"Liujuan Cao\"},{\"authorId\":\"47096329\",\"name\":\"Yongjian Wu\"},{\"authorId\":\"1835006\",\"name\":\"Feiyue Huang\"},{\"authorId\":\"1572139630\",\"name\":\"Rongrong Ji\"}],\"doi\":\"10.1145/3394171.3414008\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c19f8380410181249fdca70ec14f6b5f38ae0846\",\"title\":\"Exploring Language Prior for Mode-Sensitive Visual Attention Modeling\",\"url\":\"https://www.semanticscholar.org/paper/c19f8380410181249fdca70ec14f6b5f38ae0846\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1903.02499\",\"authors\":[{\"authorId\":\"47287647\",\"name\":\"Sen He\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"3251678\",\"name\":\"N. Pugeault\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3f9f1de36707a7c4885006554be09d16cf3fd6b4\",\"title\":\"A Synchronized Multi-Modal Attention-Caption Dataset and Analysis\",\"url\":\"https://www.semanticscholar.org/paper/3f9f1de36707a7c4885006554be09d16cf3fd6b4\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1720774\",\"name\":\"M. Su\"},{\"authorId\":\"1485468411\",\"name\":\"U. Tat-Meng\"},{\"authorId\":\"48820477\",\"name\":\"Y. Hsieh\"},{\"authorId\":\"1471301574\",\"name\":\"Zhe-Fu Yeh\"},{\"authorId\":\"3404430\",\"name\":\"Shu-Fang Lee\"},{\"authorId\":\"2385778\",\"name\":\"Shih-Syun Lin\"}],\"doi\":\"10.3390/s20010025\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ef9eea1d3d2d3ef4e9aab73c771e03eb116da796\",\"title\":\"An Eye-Tracking System based on Inner Corner-Pupil Center Vector and Deep Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/ef9eea1d3d2d3ef4e9aab73c771e03eb116da796\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145556868\",\"name\":\"Ali Mahdi\"},{\"authorId\":\"47901325\",\"name\":\"J. Qin\"}],\"doi\":\"10.1016/j.jvcir.2019.102662\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4ce8857aa18acd253aa33b618e37cc0bab58e23d\",\"title\":\"An extensive evaluation of deep featuresof convolutional neural networks for saliency prediction of human visual attention\",\"url\":\"https://www.semanticscholar.org/paper/4ce8857aa18acd253aa33b618e37cc0bab58e23d\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"117914495\",\"name\":\"Marek A. Pedziwiatr\"},{\"authorId\":\"2997408\",\"name\":\"Matthias K\\u00fcmmerer\"},{\"authorId\":\"2986600\",\"name\":\"C. Teufel\"}],\"doi\":\"10.1016/j.cognition.2020.104465\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dc55fa2fa5adfe2847117db1c4364781597fd815\",\"title\":\"Meaning maps and saliency models based on deep convolutional neural networks are insensitive to image meaning when predicting human fixations\",\"url\":\"https://www.semanticscholar.org/paper/dc55fa2fa5adfe2847117db1c4364781597fd815\",\"venue\":\"Cognition\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3043414\",\"name\":\"Przemys\\u0142aw Skurowski\"},{\"authorId\":\"1809939\",\"name\":\"Pawel Kasprowski\"}],\"doi\":\"10.1109/IPAS.2018.8708858\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"026b9d7913cf7b4ceff87c7c633042eb16151c71\",\"title\":\"Evaluation of Saliency Maps in a Hard Case \\u2013 Images of Camouflaged Animals\",\"url\":\"https://www.semanticscholar.org/paper/026b9d7913cf7b4ceff87c7c633042eb16151c71\",\"venue\":\"2018 IEEE International Conference on Image Processing, Applications and Systems (IPAS)\",\"year\":2018},{\"arxivId\":\"2009.04015\",\"authors\":[{\"authorId\":\"41036829\",\"name\":\"Tamay Aykut\"},{\"authorId\":\"1952976052\",\"name\":\"Basak Gulezyuz\"},{\"authorId\":\"1739786\",\"name\":\"B. Girod\"},{\"authorId\":\"1713579\",\"name\":\"E. Steinbach\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2ab56d8519a24ea4fabffb631a250c5e280afb55\",\"title\":\"HSMF-Net: Semantic Viewport Prediction for Immersive Telepresence and On-Demand 360-degree Video\",\"url\":\"https://www.semanticscholar.org/paper/2ab56d8519a24ea4fabffb631a250c5e280afb55\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3327256\",\"name\":\"M. Favorskaya\"},{\"authorId\":\"122575918\",\"name\":\"L. C. Jain\"}],\"doi\":\"10.31799/1684-8853-2019-3-10-36\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6fe7379f40fd2354e5bbe5f8be79069feb0c6ea2\",\"title\":\"Saliency detection in deep learning era: trends of development\",\"url\":\"https://www.semanticscholar.org/paper/6fe7379f40fd2354e5bbe5f8be79069feb0c6ea2\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1397071800\",\"name\":\"Lisa F Schwetlick\"},{\"authorId\":\"47881795\",\"name\":\"Lars O M Rothkegel\"},{\"authorId\":\"5181971\",\"name\":\"H. Trukenbrod\"},{\"authorId\":\"3258874\",\"name\":\"Ralf Engbert\"}],\"doi\":\"10.1038/s42003-020-01429-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e670bdd1332b799df59105a69f13fa6942bcea00\",\"title\":\"Modeling the effects of perisaccadic attention on gaze statistics during scene viewing\",\"url\":\"https://www.semanticscholar.org/paper/e670bdd1332b799df59105a69f13fa6942bcea00\",\"venue\":\"Communications biology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144138440\",\"name\":\"Xiaoying Ding\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"}],\"doi\":\"10.1109/TMM.2018.2851389\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0592689b643aa45b45d3e32e21135ccf84f9e1be\",\"title\":\"Improving Saliency Detection Based on Modeling Photographer's Intention\",\"url\":\"https://www.semanticscholar.org/paper/0592689b643aa45b45d3e32e21135ccf84f9e1be\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2235266\",\"name\":\"B. de Haas\"},{\"authorId\":\"91826616\",\"name\":\"Alexios L. Iakovidis\"},{\"authorId\":\"120452522\",\"name\":\"D. S. Schwarzkopf\"},{\"authorId\":\"3322056\",\"name\":\"K. Gegenfurtner\"}],\"doi\":\"10.1101/444257\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f18d6c7a277adb518be9806c22be18730b575b66\",\"title\":\"Individual differences in visual salience vary along semantic dimensions\",\"url\":\"https://www.semanticscholar.org/paper/f18d6c7a277adb518be9806c22be18730b575b66\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2580656\",\"name\":\"R. Pflugfelder\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0a400fd7f0ee28694889baaa4faef150b6912dfa\",\"title\":\"An In-Depth Analysis of Visual Tracking with Siamese Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/0a400fd7f0ee28694889baaa4faef150b6912dfa\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5328426\",\"name\":\"Jochen Laubrock\"},{\"authorId\":\"51038504\",\"name\":\"David Dubray\"}],\"doi\":\"10.1007/978-3-030-05716-9_61\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"61617f3eb15f64f51e108238a73d81abed13bb46\",\"title\":\"CNN-Based Classification of Illustrator Style in Graphic Novels: Which Features Contribute Most?\",\"url\":\"https://www.semanticscholar.org/paper/61617f3eb15f64f51e108238a73d81abed13bb46\",\"venue\":\"MMM\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47287647\",\"name\":\"Sen He\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"3251678\",\"name\":\"N. Pugeault\"}],\"doi\":\"10.1109/ICCV.2019.00862\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e4a91b8c1259e7744784d922f250dd77ea951e9f\",\"title\":\"Human Attention in Image Captioning: Dataset and Analysis\",\"url\":\"https://www.semanticscholar.org/paper/e4a91b8c1259e7744784d922f250dd77ea951e9f\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Shree Nath Dutt Sharma\"},{\"authorId\":\"1686020\",\"name\":\"D. Samaras\"},{\"authorId\":\"35217367\",\"name\":\"Niranjan Balasubramanian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"385c9cb10e5f46af0057c8103edccd9062bc721a\",\"title\":\"Ordering Salient Objects in Images\",\"url\":\"https://www.semanticscholar.org/paper/385c9cb10e5f46af0057c8103edccd9062bc721a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1819851387\",\"name\":\"Alessandro Bruno\"},{\"authorId\":\"27053388\",\"name\":\"Francesco Gugliuzza\"},{\"authorId\":\"1720275\",\"name\":\"R. Pirrone\"},{\"authorId\":\"98705023\",\"name\":\"E. Ardizzone\"}],\"doi\":\"10.1109/ACCESS.2020.3006700\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1a4a5c24c2ee500819b81da6dd07483ef4112846\",\"title\":\"A Multi-Scale Colour and Keypoint Density-Based Approach for Visual Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/1a4a5c24c2ee500819b81da6dd07483ef4112846\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1805367\",\"name\":\"Sen Jia\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3ba81addcc50e8b4a0bad42fa84b6fe26a9b8a6f\",\"title\":\"EML-NET : An Expandable Multi-Layer NETwork for Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/3ba81addcc50e8b4a0bad42fa84b6fe26a9b8a6f\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"13726384\",\"name\":\"Ritwick Chaudhry\"},{\"authorId\":\"66814047\",\"name\":\"Manoj Kilaru\"},{\"authorId\":\"35223379\",\"name\":\"Sumit Shekhar\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0fb0ef444438dbc2fe36ce727ed131638e72467c\",\"title\":\"Show and Recall @ MediaEval 2018 ViMemNet: Predicting Video Memorability\",\"url\":\"https://www.semanticscholar.org/paper/0fb0ef444438dbc2fe36ce727ed131638e72467c\",\"venue\":\"MediaEval\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48084733\",\"name\":\"Macario O. Cordel\"},{\"authorId\":\"2087470\",\"name\":\"S. Fan\"},{\"authorId\":\"1700911\",\"name\":\"Zhiqi Shen\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":\"10.1109/CVPR.2019.00415\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d61bd9bc9a09731bcdfb7c84ef57b71ebb06a1e3\",\"title\":\"Emotion-Aware Human Attention Prediction\",\"url\":\"https://www.semanticscholar.org/paper/d61bd9bc9a09731bcdfb7c84ef57b71ebb06a1e3\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1795037\",\"name\":\"Y. Chen\"},{\"authorId\":\"2976416\",\"name\":\"K. Chang\"},{\"authorId\":\"2580349\",\"name\":\"Yi-Hsuan Tsai\"},{\"authorId\":null,\"name\":\"Yu-Chiang Frank Wang\"},{\"authorId\":\"37811787\",\"name\":\"Wei-Chen Chiu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"05001ed38ce1be0d96c22fadf09571526f7fd684\",\"title\":\"Guide Your Eyes: Learning Image Manipulation under Saliency Guidance\",\"url\":\"https://www.semanticscholar.org/paper/05001ed38ce1be0d96c22fadf09571526f7fd684\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"2001.11921\",\"authors\":[{\"authorId\":\"1696991\",\"name\":\"G. Zelinsky\"},{\"authorId\":\"152829057\",\"name\":\"Yupei Chen\"},{\"authorId\":\"144078005\",\"name\":\"Seoyoung Ahn\"},{\"authorId\":\"32363057\",\"name\":\"H. Adeli\"},{\"authorId\":\"48598731\",\"name\":\"Zhibo Yang\"},{\"authorId\":\"37012552\",\"name\":\"L. Huang\"},{\"authorId\":\"48801624\",\"name\":\"D. Samaras\"},{\"authorId\":\"2356016\",\"name\":\"Minh Hoai\"}],\"doi\":\"10.1167/jov.20.11.1632\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2b2900d14b7ef87decfdbc092c55d4ff944dfafa\",\"title\":\"Predicting Goal-directed Attention Control Using Inverse-Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/2b2900d14b7ef87decfdbc092c55d4ff944dfafa\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1805.01047\",\"authors\":[{\"authorId\":\"1805367\",\"name\":\"Sen Jia\"}],\"doi\":\"10.1016/j.imavis.2020.103887\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"49a94c25bcb323defe63796cf3afd52e2bfd8d48\",\"title\":\"EML-NET: An Expandable Multi-Layer NETwork for Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/49a94c25bcb323defe63796cf3afd52e2bfd8d48\",\"venue\":\"Image Vis. Comput.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1715361\",\"name\":\"Giuseppe Boccignone\"},{\"authorId\":\"1896593\",\"name\":\"Vittorio Cuculo\"},{\"authorId\":\"1411402819\",\"name\":\"Alessandro D\\u2019Amelio\"}],\"doi\":\"10.1007/978-3-030-54994-7_10\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b2936bc03c0a6d49aa98b67775531f8defb029fb\",\"title\":\"How to Look Next? A Data-Driven Approach for Scanpath Prediction\",\"url\":\"https://www.semanticscholar.org/paper/b2936bc03c0a6d49aa98b67775531f8defb029fb\",\"venue\":\"FM Workshops\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49941672\",\"name\":\"Zhiming Hu\"},{\"authorId\":\"72917175\",\"name\":\"Sheng Li\"},{\"authorId\":\"73114045\",\"name\":\"Congyi Zhang\"},{\"authorId\":\"1499256520\",\"name\":\"Kangrui Yi\"},{\"authorId\":\"92491739\",\"name\":\"G. Wang\"},{\"authorId\":\"1699159\",\"name\":\"D. Manocha\"}],\"doi\":\"10.1109/TVCG.2020.2973473\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5dc84061cb26efead2e73a7e7999d8c9b08674f0\",\"title\":\"DGaze: CNN-Based Gaze Prediction in Dynamic Scenes\",\"url\":\"https://www.semanticscholar.org/paper/5dc84061cb26efead2e73a7e7999d8c9b08674f0\",\"venue\":\"IEEE Transactions on Visualization and Computer Graphics\",\"year\":2020},{\"arxivId\":\"1902.08137\",\"authors\":[{\"authorId\":\"51038504\",\"name\":\"David Dubray\"},{\"authorId\":\"5328426\",\"name\":\"Jochen Laubrock\"}],\"doi\":\"10.1109/icdar.2019.00200\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"38d8dc12c7bd49619b39ebe28d1459fb2cfa1960\",\"title\":\"Deep CNN-Based Speech Balloon Detection and Segmentation for Comic Books\",\"url\":\"https://www.semanticscholar.org/paper/38d8dc12c7bd49619b39ebe28d1459fb2cfa1960\",\"venue\":\"2019 International Conference on Document Analysis and Recognition (ICDAR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1471387090\",\"name\":\"Sorachi Nakazawa\"},{\"authorId\":\"67226460\",\"name\":\"S. Ushijima\"},{\"authorId\":\"2833782\",\"name\":\"Yohei Nakada\"}],\"doi\":\"10.1145/3368926.3369672\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8831ced147d8938300804c969908e2f7e7287631\",\"title\":\"An EM Algorithm based Method for Constructing Dynamic Saliency Maps considering Characteristics while Driving\",\"url\":\"https://www.semanticscholar.org/paper/8831ced147d8938300804c969908e2f7e7287631\",\"venue\":\"SoICT 2019\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3923889\",\"name\":\"J. J. V. van Assen\"},{\"authorId\":\"49813322\",\"name\":\"S. Nishida\"},{\"authorId\":\"2436224\",\"name\":\"R. Fleming\"}],\"doi\":\"10.1371/journal.pcbi.1008018\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"de32c428a44aa2bc99de0421b113a20282549bc0\",\"title\":\"Visual perception of liquids: Insights from deep neural networks\",\"url\":\"https://www.semanticscholar.org/paper/de32c428a44aa2bc99de0421b113a20282549bc0\",\"venue\":\"PLoS computational biology\",\"year\":2020},{\"arxivId\":\"1712.06492\",\"authors\":[{\"authorId\":\"1891828\",\"name\":\"Leon A. Gatys\"},{\"authorId\":\"2997408\",\"name\":\"Matthias K\\u00fcmmerer\"},{\"authorId\":\"49737748\",\"name\":\"Thomas S. A. Wallis\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0fb277156823934efb1bd00b9143b88040fb1986\",\"title\":\"Guiding human gaze with convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/0fb277156823934efb1bd00b9143b88040fb1986\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"2008.03922\",\"authors\":[{\"authorId\":\"1519065889\",\"name\":\"Jiyong Zhang\"},{\"authorId\":\"145403635\",\"name\":\"T. Deng\"},{\"authorId\":\"144535339\",\"name\":\"Fei Yan\"},{\"authorId\":\"49663245\",\"name\":\"W. Liu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"67b3c369784ba31b0864a1f42a6971388298a939\",\"title\":\"Lane Detection Model Based on Spatio-Temporal Network with Double ConvGRUs.\",\"url\":\"https://www.semanticscholar.org/paper/67b3c369784ba31b0864a1f42a6971388298a939\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"147552063\",\"name\":\"M. L. Nguy\\u1ec5n\"},{\"authorId\":\"2847306\",\"name\":\"Prarinya Siritanawan\"},{\"authorId\":\"1791753\",\"name\":\"K. Kotani\"}],\"doi\":\"10.23919/SICE.2019.8859898\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"edb5a343d72e65072e967401f4ac508a31df3ac7\",\"title\":\"Saliency Map Extraction in Human Crowd RGB Data\",\"url\":\"https://www.semanticscholar.org/paper/edb5a343d72e65072e967401f4ac508a31df3ac7\",\"venue\":\"2019 58th Annual Conference of the Society of Instrument and Control Engineers of Japan (SICE)\",\"year\":2019},{\"arxivId\":\"2005.14310\",\"authors\":[{\"authorId\":\"48598731\",\"name\":\"Zhibo Yang\"},{\"authorId\":\"37012552\",\"name\":\"L. Huang\"},{\"authorId\":\"152829057\",\"name\":\"Yupei Chen\"},{\"authorId\":\"2647061\",\"name\":\"Zijun Wei\"},{\"authorId\":\"144078005\",\"name\":\"Seoyoung Ahn\"},{\"authorId\":\"1696991\",\"name\":\"G. Zelinsky\"},{\"authorId\":\"1686020\",\"name\":\"D. Samaras\"},{\"authorId\":\"2356016\",\"name\":\"Minh Hoai\"}],\"doi\":\"10.1109/cvpr42600.2020.00027\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8b9346af26e460bc37d0e3a4e957a6c42beb3677\",\"title\":\"Predicting Goal-Directed Human Attention Using Inverse Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/8b9346af26e460bc37d0e3a4e957a6c42beb3677\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2733405\",\"name\":\"H. Li\"},{\"authorId\":\"46534309\",\"name\":\"Fei Qi\"},{\"authorId\":\"35367337\",\"name\":\"Guangming Shi\"},{\"authorId\":\"67079406\",\"name\":\"Chunhuan Lin\"}],\"doi\":\"10.1016/J.JVCIR.2019.102611\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6c7feb802ed7303f7e9238276d292b17b561f3ac\",\"title\":\"A multiscale dilated dense convolutional network for saliency prediction with instance-level attention competition\",\"url\":\"https://www.semanticscholar.org/paper/6c7feb802ed7303f7e9238276d292b17b561f3ac\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50024334\",\"name\":\"Y. Li\"},{\"authorId\":\"1896187\",\"name\":\"Zhenni Li\"},{\"authorId\":\"2413210\",\"name\":\"Atsunori Kanemura\"}],\"doi\":\"10.1109/ACCESS.2019.2908010\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a416cd77a30dd2dbfc8ba9b5351bced43f7b35aa\",\"title\":\"An  $\\\\ell_{1/2}$ -Norm Regularizer-Based Sparse Coding Framework for Gaze Prediction in First-Person Videos\",\"url\":\"https://www.semanticscholar.org/paper/a416cd77a30dd2dbfc8ba9b5351bced43f7b35aa\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"2009.08373\",\"authors\":[{\"authorId\":\"1947172233\",\"name\":\"M. Sclar\"},{\"authorId\":\"1946864700\",\"name\":\"G. Bujia\"},{\"authorId\":\"145184799\",\"name\":\"S. Vita\"},{\"authorId\":\"3985471\",\"name\":\"G. Solovey\"},{\"authorId\":\"2941980\",\"name\":\"J. E. Kamienkowski\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5d4dbd9b7c504d33403027e721468847d8d91fdb\",\"title\":\"Modeling human visual search: A combined Bayesian searcher and saliency map approach for eye movement guidance in natural scenes\",\"url\":\"https://www.semanticscholar.org/paper/5d4dbd9b7c504d33403027e721468847d8d91fdb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1709.02495\",\"authors\":[{\"authorId\":\"145556868\",\"name\":\"Ali Mahdi\"},{\"authorId\":\"145669352\",\"name\":\"Jun Qin\"},{\"authorId\":\"39333164\",\"name\":\"G. Crosby\"}],\"doi\":\"10.1109/TCDS.2019.2894561\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c69f5261edb4dde001fcea4d32b06fdf9dd9358a\",\"title\":\"DeepFeat: A Bottom-Up and Top-Down Saliency Model Based on Deep Features of Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/c69f5261edb4dde001fcea4d32b06fdf9dd9358a\",\"venue\":\"IEEE Transactions on Cognitive and Developmental Systems\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"83015253\",\"name\":\"Alex Hern\\u00e1ndez-Garc\\u00eda\"},{\"authorId\":\"10995269\",\"name\":\"Ricardo Ramos Gameiro\"},{\"authorId\":\"46203125\",\"name\":\"A. Grillini\"},{\"authorId\":\"144027562\",\"name\":\"P. K\\u00f6nig\"}],\"doi\":\"10.1167/jov.20.7.27\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d267fd8706d7ff33f3c03904e717799fc4a6810c\",\"title\":\"Global visual salience of competing stimuli\",\"url\":\"https://www.semanticscholar.org/paper/d267fd8706d7ff33f3c03904e717799fc4a6810c\",\"venue\":\"Journal of vision\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1810382\",\"name\":\"Zhaohui Che\"},{\"authorId\":\"51004202\",\"name\":\"A. Borji\"},{\"authorId\":\"144826390\",\"name\":\"G. Zhai\"},{\"authorId\":\"2246414\",\"name\":\"Xiongkuo Min\"},{\"authorId\":\"1822413\",\"name\":\"Guodong Guo\"},{\"authorId\":\"1776651\",\"name\":\"P. Callet\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ad0b345436e8a2d507fbcd7e6477deb399a062a4\",\"title\":\"GazeGAN: A Generative Adversarial Saliency Model based on Invariance Analysis of Human Gaze During Scene Free Viewing\",\"url\":\"https://www.semanticscholar.org/paper/ad0b345436e8a2d507fbcd7e6477deb399a062a4\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1905.00954\",\"authors\":[{\"authorId\":\"2539841\",\"name\":\"Zhongang Qi\"},{\"authorId\":\"33353193\",\"name\":\"S. Khorram\"},{\"authorId\":\"3141988\",\"name\":\"F. Li\"}],\"doi\":\"10.1609/aaai.v34i07.6863\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1c9932feb06a3b873361a3318183396214fba4b5\",\"title\":\"Visualizing Deep Networks by Optimizing with Integrated Gradients\",\"url\":\"https://www.semanticscholar.org/paper/1c9932feb06a3b873361a3318183396214fba4b5\",\"venue\":\"CVPR Workshops\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2022821746\",\"name\":\"Fu Lihua\"},{\"authorId\":\"2024659110\",\"name\":\"Ding Haogang\"},{\"authorId\":\"66969083\",\"name\":\"Li Cancan\"},{\"authorId\":\"2346227\",\"name\":\"W. Dan\"},{\"authorId\":\"2024676824\",\"name\":\"Feng Yujia\"}],\"doi\":\"10.1117/1.JEI.27.5.053003\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7cb8dd4c2968a94610ca88c4a20eea7a3d64826d\",\"title\":\"Deep learning framework for saliency object detection based on global prior and local context\",\"url\":\"https://www.semanticscholar.org/paper/7cb8dd4c2968a94610ca88c4a20eea7a3d64826d\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2115104\",\"name\":\"Wenjia Niu\"},{\"authorId\":\"100613971\",\"name\":\"Gang Li\"},{\"authorId\":\"8190315\",\"name\":\"Jiqiang Liu\"},{\"authorId\":\"40062477\",\"name\":\"J. Tan\"},{\"authorId\":\"72055377\",\"name\":\"L. Guo\"},{\"authorId\":\"114687731\",\"name\":\"Zhen Han\"},{\"authorId\":\"1731028\",\"name\":\"L. Batten\"}],\"doi\":\"10.1007/978-3-662-48683-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"58f4852816ffc8733c8a687a1b0e38a2c2ee2f2d\",\"title\":\"Applications and Techniques in Information Security\",\"url\":\"https://www.semanticscholar.org/paper/58f4852816ffc8733c8a687a1b0e38a2c2ee2f2d\",\"venue\":\"Communications in Computer and Information Science\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50024334\",\"name\":\"Y. Li\"},{\"authorId\":\"143683998\",\"name\":\"S. Akaho\"},{\"authorId\":\"7142317\",\"name\":\"Hideki Asoh\"},{\"authorId\":\"34578251\",\"name\":\"Benying Tan\"}],\"doi\":\"10.1109/ACCESS.2019.2892945\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3ec5c25a8e08cf604965688dee67d229871f1e1a\",\"title\":\"Supervised Saliency Mapping for First-Person Videos With an Inverse Sparse Coding Framework\",\"url\":\"https://www.semanticscholar.org/paper/3ec5c25a8e08cf604965688dee67d229871f1e1a\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2997408\",\"name\":\"Matthias K\\u00fcmmerer\"},{\"authorId\":\"49737748\",\"name\":\"Thomas S. A. Wallis\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":\"10.32470/ccn.2019.1235-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4433e189d529087f41749cde74948e6694a2943e\",\"title\":\"DeepGaze III: Using Deep Learning to Probe Interactions Between Scene Content and Scanpath History in Fixation Selection\",\"url\":\"https://www.semanticscholar.org/paper/4433e189d529087f41749cde74948e6694a2943e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1805367\",\"name\":\"Sen Jia\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7d329bb72b3497ddeaa804d389d5d5f27bdca911\",\"title\":\"Revisiting Saliency Metrics: Farthest-Neighbor Area Under Curve\",\"url\":\"https://www.semanticscholar.org/paper/7d329bb72b3497ddeaa804d389d5d5f27bdca911\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2342453\",\"name\":\"Wentao Bao\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"}],\"doi\":\"10.1016/j.neucom.2020.03.060\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d7e4167fc24c7a64953cbabdd0a6d7790d45102\",\"title\":\"Human scanpath prediction based on deep convolutional saccadic model\",\"url\":\"https://www.semanticscholar.org/paper/0d7e4167fc24c7a64953cbabdd0a6d7790d45102\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"2002.10540\",\"authors\":[{\"authorId\":null,\"name\":\"Sen Jia\"},{\"authorId\":\"2866780\",\"name\":\"Neil D. B. Bruce\"}],\"doi\":\"10.1109/cvpr42600.2020.00274\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"68d3ff5267302cd396b831cd3a67fb0b2002d711\",\"title\":\"Revisiting Saliency Metrics: Farthest-Neighbor Area Under Curve\",\"url\":\"https://www.semanticscholar.org/paper/68d3ff5267302cd396b831cd3a67fb0b2002d711\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2007882802\",\"name\":\"Matthias Tangemann\"},{\"authorId\":\"2997408\",\"name\":\"Matthias K\\u00fcmmerer\"},{\"authorId\":\"49737748\",\"name\":\"Thomas S. A. Wallis\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":\"10.1007/978-3-030-58604-1_40\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d7fcbd3d09a3029c3912b7c222c188bcba79920b\",\"title\":\"Measuring the Importance of Temporal Features in Video Saliency\",\"url\":\"https://www.semanticscholar.org/paper/d7fcbd3d09a3029c3912b7c222c188bcba79920b\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145556862\",\"name\":\"Ali Mahdi\"},{\"authorId\":\"145849768\",\"name\":\"J. Qin\"}],\"doi\":\"10.1117/1.JEI.28.3.033033\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"07abe8e63d233a9e8cb5c8267df1d2024d179270\",\"title\":\"Evaluation of bottom-up saliency model using deep features pretrained by deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/07abe8e63d233a9e8cb5c8267df1d2024d179270\",\"venue\":\"J. Electronic Imaging\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"15669390\",\"name\":\"Liang Tong\"},{\"authorId\":\"1697516\",\"name\":\"Minzhe Guo\"},{\"authorId\":\"152435970\",\"name\":\"A. Prakash\"},{\"authorId\":\"1699600\",\"name\":\"Y. Vorobeychik\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c425a7c336c1552c19ef81da5234c1499d319d2c\",\"title\":\"Towards Robustness against Unsuspicious Adversarial Examples Original Sample Corrupted Background Corrupted Foreground\",\"url\":\"https://www.semanticscholar.org/paper/c425a7c336c1552c19ef81da5234c1499d319d2c\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144897958\",\"name\":\"J. M. Henderson\"},{\"authorId\":\"2506727\",\"name\":\"Taylor R. Hayes\"}],\"doi\":\"10.1167/18.6.10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5882b08cd2968d8d10dbc6f7cbe69bb1cdb383b6\",\"title\":\"Meaning guides attention in real-world scene images: Evidence from eye movements and meaning maps\",\"url\":\"https://www.semanticscholar.org/paper/5882b08cd2968d8d10dbc6f7cbe69bb1cdb383b6\",\"venue\":\"Journal of vision\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144897958\",\"name\":\"J. M. Henderson\"},{\"authorId\":\"2506727\",\"name\":\"Taylor R. Hayes\"},{\"authorId\":\"32194041\",\"name\":\"Candace E. Peacock\"},{\"authorId\":\"4945704\",\"name\":\"Gwendolyn Rehrig\"}],\"doi\":\"10.3390/vision3020019\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2fa26ac1b99a2587c47519f6344fd5ae625b4d34\",\"title\":\"Meaning and Attentional Guidance in Scenes: A Review of the Meaning Map Approach\",\"url\":\"https://www.semanticscholar.org/paper/2fa26ac1b99a2587c47519f6344fd5ae625b4d34\",\"venue\":\"Vision\",\"year\":2019},{\"arxivId\":\"1711.10959\",\"authors\":[{\"authorId\":\"4218304\",\"name\":\"C. Wloka\"},{\"authorId\":\"3468296\",\"name\":\"Iuliia Kotseruba\"},{\"authorId\":\"1727853\",\"name\":\"John K. Tsotsos\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"475b423d03a56e272c0fb40d087e300d3e28d5d9\",\"title\":\"Saccade Sequence Prediction: Beyond Static Saliency Maps\",\"url\":\"https://www.semanticscholar.org/paper/475b423d03a56e272c0fb40d087e300d3e28d5d9\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49679796\",\"name\":\"C. P. Hung\"},{\"authorId\":\"1404640530\",\"name\":\"Chloe Callahan-Flintoft\"},{\"authorId\":\"38325900\",\"name\":\"P. Fedele\"},{\"authorId\":\"70069155\",\"name\":\"Kim F. Fluitt\"},{\"authorId\":\"4220002\",\"name\":\"Kachi Odoemene\"},{\"authorId\":\"145883908\",\"name\":\"A. J. Walker\"},{\"authorId\":\"1406772141\",\"name\":\"Andre V Harrison\"},{\"authorId\":\"94862781\",\"name\":\"B. Vaughan\"},{\"authorId\":\"1818639971\",\"name\":\"Matthew S Jaswa\"},{\"authorId\":\"1381667122\",\"name\":\"Min Wei\"}],\"doi\":\"10.1167/jov.20.7.9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b1ac3242cd7b4f7359017bc6a192c44547cb4179\",\"title\":\"Abrupt darkening under high dynamic range (HDR) luminance invokes facilitation for high-contrast targets and grouping by luminance similarity\",\"url\":\"https://www.semanticscholar.org/paper/b1ac3242cd7b4f7359017bc6a192c44547cb4179\",\"venue\":\"Journal of vision\",\"year\":2020},{\"arxivId\":\"1905.00954\",\"authors\":[{\"authorId\":\"2539841\",\"name\":\"Zhongang Qi\"},{\"authorId\":\"33353193\",\"name\":\"Saeed Khorram\"},{\"authorId\":\"3141988\",\"name\":\"Fuxin Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"43d13820af76788f662610420d9e85a4b8636d28\",\"title\":\"Visualizing Deep Networks by Optimizing with Integrated Gradients\",\"url\":\"https://www.semanticscholar.org/paper/43d13820af76788f662610420d9e85a4b8636d28\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1710.03011\",\"authors\":[{\"authorId\":\"7869872\",\"name\":\"Y. Xu\"},{\"authorId\":\"1702868\",\"name\":\"Shenghua Gao\"},{\"authorId\":\"119837762\",\"name\":\"Junru Wu\"},{\"authorId\":\"2317822\",\"name\":\"Nianyi Li\"},{\"authorId\":\"46380769\",\"name\":\"Jingyi Yu\"}],\"doi\":\"10.1109/TPAMI.2018.2866563\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4f3ca89c6c7cdf359c621870c8f71a4251cecc1b\",\"title\":\"Personalized Saliency and Its Prediction\",\"url\":\"https://www.semanticscholar.org/paper/4f3ca89c6c7cdf359c621870c8f71a4251cecc1b\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48598731\",\"name\":\"Zhibo Yang\"},{\"authorId\":\"98206513\",\"name\":\"Lihan Huang\"},{\"authorId\":\"152829057\",\"name\":\"Yupei Chen\"},{\"authorId\":\"2647061\",\"name\":\"Zijun Wei\"},{\"authorId\":\"144078005\",\"name\":\"Seoyoung Ahn\"},{\"authorId\":\"1696991\",\"name\":\"G. Zelinsky\"},{\"authorId\":\"1686020\",\"name\":\"D. Samaras\"},{\"authorId\":\"2356016\",\"name\":\"Minh Hoai\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1b4fb1fd767968b20db2ff9288c78fd2a8179a9f\",\"title\":\"Supplementary Material: Predicting Goal-directed Human Attention Using Inverse Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/1b4fb1fd767968b20db2ff9288c78fd2a8179a9f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1611.09571\",\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/TIP.2018.2851672\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b7e336a7d3cd82ae8cd5e85d3cb62f0b6091a0e5\",\"title\":\"Predicting Human Eye Fixations via an LSTM-Based Saliency Attentive Model\",\"url\":\"https://www.semanticscholar.org/paper/b7e336a7d3cd82ae8cd5e85d3cb62f0b6091a0e5\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":\"2010.00516\",\"authors\":[{\"authorId\":\"8025400\",\"name\":\"Meenakshi Khosla\"},{\"authorId\":\"123218096\",\"name\":\"Gia H. Ngo\"},{\"authorId\":\"33892350\",\"name\":\"K. Jamison\"},{\"authorId\":\"1688401830\",\"name\":\"A. Kuceyeski\"},{\"authorId\":\"2369409\",\"name\":\"M. Sabuncu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fc85d96cc349a2e99fd70b3415ca4db77282864d\",\"title\":\"Neural encoding with visual attention\",\"url\":\"https://www.semanticscholar.org/paper/fc85d96cc349a2e99fd70b3415ca4db77282864d\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"1912.08136\",\"authors\":[{\"authorId\":\"145378987\",\"name\":\"Yan Luo\"},{\"authorId\":\"3026404\",\"name\":\"Yongkang Wong\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"},{\"authorId\":\"153386875\",\"name\":\"Q. Zhao\"}],\"doi\":\"10.1109/TPAMI.2019.2963387\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"52b94fb0e0bad38835662d1fb3e86a7be584f8f6\",\"title\":\"Direction Concentration Learning: Enhancing Congruency in Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/52b94fb0e0bad38835662d1fb3e86a7be584f8f6\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2007931\",\"name\":\"Kao Zhang\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"}],\"doi\":\"10.1109/TCSVT.2018.2883305\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6c54dfdace2a84d4b70fc31e87a3053be09cd863\",\"title\":\"Video Saliency Prediction Based on Spatial-Temporal Two-Stream Network\",\"url\":\"https://www.semanticscholar.org/paper/6c54dfdace2a84d4b70fc31e87a3053be09cd863\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1952480\",\"name\":\"E. Dauc\\u00e9\"},{\"authorId\":\"1382220168\",\"name\":\"Pierre Albiges\"},{\"authorId\":\"1843878\",\"name\":\"L. Perrinet\"}],\"doi\":\"10.1101/725879\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d71b783b5cbdb505a242c06ef4b14619da33b981\",\"title\":\"A dual foveal-peripheral visual processing model implements efficient saccade selection\",\"url\":\"https://www.semanticscholar.org/paper/d71b783b5cbdb505a242c06ef4b14619da33b981\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1971623\",\"name\":\"C. Hung\"},{\"authorId\":\"1404640530\",\"name\":\"Chloe Callahan-Flintoft\"},{\"authorId\":\"38325900\",\"name\":\"P. Fedele\"},{\"authorId\":\"70069155\",\"name\":\"Kim F. Fluitt\"},{\"authorId\":\"4220002\",\"name\":\"Kachi Odoemene\"},{\"authorId\":\"94862781\",\"name\":\"B. Vaughan\"},{\"authorId\":\"145883908\",\"name\":\"A. J. Walker\"},{\"authorId\":\"1748817\",\"name\":\"Matthew Jaswa\"},{\"authorId\":\"1381667122\",\"name\":\"Min Wei\"},{\"authorId\":\"1406772141\",\"name\":\"Andre V Harrison\"}],\"doi\":\"10.1101/718437\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c67d3bb2f9bbed3f55bcbaf6ccf39ea5f916f852\",\"title\":\"An 11-bit High Dynamic Range (HDR) Luminance Display and Its Use to Discover Contextual Mechanisms of Real-World Luminance Normalization for Visual Acuity and Target Discrimination\",\"url\":\"https://www.semanticscholar.org/paper/c67d3bb2f9bbed3f55bcbaf6ccf39ea5f916f852\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67321830\",\"name\":\"Weijie Wei\"},{\"authorId\":\"3211706\",\"name\":\"Zhusong Liu\"},{\"authorId\":\"47033364\",\"name\":\"Lijin Huang\"},{\"authorId\":\"1395583740\",\"name\":\"Alexis Nebout\"},{\"authorId\":\"1789744\",\"name\":\"O. Meur\"},{\"authorId\":\"153913573\",\"name\":\"T. Zhang\"},{\"authorId\":\"7897836\",\"name\":\"J. Wang\"},{\"authorId\":\"119556705\",\"name\":\"Li-hua Xu\"}],\"doi\":\"10.1016/j.neucom.2020.06.125\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ce2cf6e39d5c03d7d224eda614ad803a1347d145\",\"title\":\"Predicting atypical visual saliency for autism spectrum disorder via scale-adaptive inception module and discriminative region enhancement loss\",\"url\":\"https://www.semanticscholar.org/paper/ce2cf6e39d5c03d7d224eda614ad803a1347d145\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1878895877\",\"name\":\"Yucheng Zhu\"},{\"authorId\":\"13903793\",\"name\":\"Guangtao Zhai\"},{\"authorId\":\"2246414\",\"name\":\"Xiongkuo Min\"},{\"authorId\":\"1735685\",\"name\":\"Jiantao Zhou\"}],\"doi\":\"10.1109/TMM.2019.2957986\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"42f8fc610fed03fb9e91a05dbb132956fb719f60\",\"title\":\"The Prediction of Saliency Map for Head and Eye Movements in 360 Degree Images\",\"url\":\"https://www.semanticscholar.org/paper/42f8fc610fed03fb9e91a05dbb132956fb719f60\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"2005.04272\",\"authors\":[{\"authorId\":\"15669390\",\"name\":\"Liang Tong\"},{\"authorId\":\"1697516\",\"name\":\"Minzhe Guo\"},{\"authorId\":\"152435970\",\"name\":\"A. Prakash\"},{\"authorId\":\"1699600\",\"name\":\"Y. Vorobeychik\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9e0c29f758a36d2651ce6c9e27a4badddf2e8e21\",\"title\":\"Towards Robustness against Unsuspicious Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/9e0c29f758a36d2651ce6c9e27a4badddf2e8e21\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1710.10755\",\"authors\":[{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"3383051\",\"name\":\"Yuhang Song\"},{\"authorId\":\"49606288\",\"name\":\"Jianyi Wang\"},{\"authorId\":\"27647516\",\"name\":\"Minglang Qiao\"},{\"authorId\":\"27661057\",\"name\":\"Liangyu Huo\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"}],\"doi\":\"10.1109/TPAMI.2018.2858783\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"27bf4a794a535994e43c2eb41b81b6795bcddfd0\",\"title\":\"Predicting Head Movement in Panoramic Video: A Deep Reinforcement Learning Approach\",\"url\":\"https://www.semanticscholar.org/paper/27bf4a794a535994e43c2eb41b81b6795bcddfd0\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"83143774\",\"name\":\"Sofia Krasovskaya\"},{\"authorId\":\"48268905\",\"name\":\"W. J. MacInnes\"}],\"doi\":\"10.3390/vision3040056\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f5dbdbb939d6b16c380bb930e7a52196f5d0e7a3\",\"title\":\"Salience Models: A Computational Cognitive Neuroscience Review\",\"url\":\"https://www.semanticscholar.org/paper/f5dbdbb939d6b16c380bb930e7a52196f5d0e7a3\",\"venue\":\"Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1395725948\",\"name\":\"Bashir Ghariba\"},{\"authorId\":\"144906448\",\"name\":\"M. Shehata\"},{\"authorId\":\"2903414\",\"name\":\"P. McGuire\"}],\"doi\":\"10.7717/peerj-cs.280\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"c981fee8b6cb0af49e6c22e701d760a238aee591\",\"title\":\"A novel fully convolutional network for visual saliency prediction\",\"url\":\"https://www.semanticscholar.org/paper/c981fee8b6cb0af49e6c22e701d760a238aee591\",\"venue\":\"PeerJ Comput. Sci.\",\"year\":2020},{\"arxivId\":\"2005.06583\",\"authors\":[{\"authorId\":\"3468296\",\"name\":\"Iuliia Kotseruba\"},{\"authorId\":\"4218304\",\"name\":\"C. Wloka\"},{\"authorId\":\"26902477\",\"name\":\"Amir Rasouli\"},{\"authorId\":\"1727853\",\"name\":\"John K. Tsotsos\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f003e9630253d6f94708b10492ce747c7dfca13c\",\"title\":\"Do Saliency Models Detect Odd-One-Out Targets? New Datasets and Evaluations\",\"url\":\"https://www.semanticscholar.org/paper/f003e9630253d6f94708b10492ce747c7dfca13c\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38591458\",\"name\":\"Phutphalla Kong\"},{\"authorId\":\"1681157\",\"name\":\"M. Mancas\"},{\"authorId\":\"51266101\",\"name\":\"Nimol Thuon\"},{\"authorId\":\"9289244\",\"name\":\"Seng Kheang\"},{\"authorId\":\"50276543\",\"name\":\"B. Gosselin\"}],\"doi\":\"10.1109/ICIP.2018.8451809\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"262ca560946e754c24d7072fe50ad2f2d630b058\",\"title\":\"Do Deep-Learning Saliency Models Really Model Saliency?\",\"url\":\"https://www.semanticscholar.org/paper/262ca560946e754c24d7072fe50ad2f2d630b058\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1384783507\",\"name\":\"Anni Li\"},{\"authorId\":\"2601046\",\"name\":\"J. Qi\"},{\"authorId\":\"153176123\",\"name\":\"Huchuan Lu\"}],\"doi\":\"10.1016/j.neucom.2020.06.021\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7a551e9bce44d57c390dc34aa40d023cb9a889ee\",\"title\":\"Multi-attention guided feature fusion network for salient object detection\",\"url\":\"https://www.semanticscholar.org/paper/7a551e9bce44d57c390dc34aa40d023cb9a889ee\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5328426\",\"name\":\"Jochen Laubrock\"},{\"authorId\":\"35652132\",\"name\":\"A. Dunst\"}],\"doi\":\"10.1111/tops.12476\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aedde007e39c8ddf67ca58e055e138b518402825\",\"title\":\"Computational Approaches to Comics Analysis\",\"url\":\"https://www.semanticscholar.org/paper/aedde007e39c8ddf67ca58e055e138b518402825\",\"venue\":\"Top. Cogn. Sci.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40397539\",\"name\":\"C. Wang\"},{\"authorId\":\"1886943\",\"name\":\"S. Zhu\"},{\"authorId\":\"38903655\",\"name\":\"Desheng Lyu\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"}],\"doi\":\"10.1007/s11042-019-08265-x\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"fcfcdeb5e3da63e3e88ec37434dfd71a04df13da\",\"title\":\"What is damaged: a benchmark dataset for abnormal traffic object classification\",\"url\":\"https://www.semanticscholar.org/paper/fcfcdeb5e3da63e3e88ec37434dfd71a04df13da\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27651985\",\"name\":\"Austin Le\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0de58d1192a0a844738ca0dd919f0c1cd743576f\",\"title\":\"Predicting Visual Saliency : Where Do People Look ?\",\"url\":\"https://www.semanticscholar.org/paper/0de58d1192a0a844738ca0dd919f0c1cd743576f\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2494584\",\"name\":\"G. Dimas\"},{\"authorId\":\"143932347\",\"name\":\"D. Iakovidis\"},{\"authorId\":\"47352212\",\"name\":\"A. Koulaouzidis\"}],\"doi\":\"10.1109/BIBE.2019.00071\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b8b496b2ba8490c9b8463d9757ee719f32700362\",\"title\":\"MedGaze: Gaze Estimation on WCE Images Based on a CNN Autoencoder\",\"url\":\"https://www.semanticscholar.org/paper/b8b496b2ba8490c9b8463d9757ee719f32700362\",\"venue\":\"2019 IEEE 19th International Conference on Bioinformatics and Bioengineering (BIBE)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2007931\",\"name\":\"Kao Zhang\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"},{\"authorId\":\"1792817\",\"name\":\"S. Liu\"}],\"doi\":\"10.1109/TIP.2020.3036749\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"51b23ce1f48d769a31a4a4f4982fbfe5d4de41f4\",\"title\":\"A Spatial-Temporal Recurrent Neural Network for Video Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/51b23ce1f48d769a31a4a4f4982fbfe5d4de41f4\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49941672\",\"name\":\"Zhiming Hu\"},{\"authorId\":\"29862039\",\"name\":\"Congyi Zhang\"},{\"authorId\":\"79399264\",\"name\":\"S. Li\"},{\"authorId\":\"50248545\",\"name\":\"G. Wang\"},{\"authorId\":\"1699159\",\"name\":\"D. Manocha\"}],\"doi\":\"10.1109/TVCG.2019.2899187\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d78aedcfd74c8dc12d70f63ac104636c8729df04\",\"title\":\"SGaze: A Data-Driven Eye-Head Coordination Model for Realtime Gaze Prediction\",\"url\":\"https://www.semanticscholar.org/paper/d78aedcfd74c8dc12d70f63ac104636c8729df04\",\"venue\":\"IEEE Transactions on Visualization and Computer Graphics\",\"year\":2019},{\"arxivId\":\"1903.02501\",\"authors\":[{\"authorId\":\"47287647\",\"name\":\"Sen He\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"145071344\",\"name\":\"Yang Mi\"},{\"authorId\":\"3251678\",\"name\":\"N. Pugeault\"}],\"doi\":\"10.1109/CVPR.2019.01045\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"38410376deedfdfc32e53b7369b9ea2297fa521f\",\"title\":\"Understanding and Visualizing Deep Visual Saliency Models\",\"url\":\"https://www.semanticscholar.org/paper/38410376deedfdfc32e53b7369b9ea2297fa521f\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2005.12073\",\"authors\":[{\"authorId\":\"1716202788\",\"name\":\"Mancas Matei\"},{\"authorId\":\"38591458\",\"name\":\"Phutphalla Kong\"},{\"authorId\":\"50276543\",\"name\":\"B. Gosselin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"98d6b0b58cfbf1caece6fa7f65d83d61b8168552\",\"title\":\"Visual Attention: Deep Rare Features\",\"url\":\"https://www.semanticscholar.org/paper/98d6b0b58cfbf1caece6fa7f65d83d61b8168552\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1696991\",\"name\":\"G. Zelinsky\"}],\"doi\":\"10.32470/ccn.2019.1086-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cadcd75cee1d7844c4eb5f59eb417180fb95a021\",\"title\":\"Using Inverse Reinforcement Learning to Predict Goal-directed Shifts of Attention\",\"url\":\"https://www.semanticscholar.org/paper/cadcd75cee1d7844c4eb5f59eb417180fb95a021\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"},{\"authorId\":\"49934787\",\"name\":\"Wanjie Sun\"}],\"doi\":\"10.24963/ijcai.2018/89\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6eea0ee0a4663077701bce317614ff97f05385dd\",\"title\":\"Scanpath Prediction for Visual Attention using IOR-ROI LSTM\",\"url\":\"https://www.semanticscholar.org/paper/6eea0ee0a4663077701bce317614ff97f05385dd\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":\"1910.13066\",\"authors\":[{\"authorId\":\"51925488\",\"name\":\"David Berga\"},{\"authorId\":\"1390040513\",\"name\":\"X. R. Fdez-Vidal\"},{\"authorId\":\"2556319\",\"name\":\"X. Otazu\"},{\"authorId\":\"40538374\",\"name\":\"Xos\\u00e9 M. Pardo\"}],\"doi\":\"10.1109/ICCV.2019.00888\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d24f772368b77ac9d67eb72fa6b95d880dc64b97\",\"title\":\"SID4VAM: A Benchmark Dataset With Synthetic Images for Visual Attention Modeling\",\"url\":\"https://www.semanticscholar.org/paper/d24f772368b77ac9d67eb72fa6b95d880dc64b97\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24962320\",\"name\":\"T. Uejima\"},{\"authorId\":\"3271571\",\"name\":\"E. Niebur\"},{\"authorId\":\"1398026219\",\"name\":\"R. Etienne-Cummings\"}],\"doi\":\"10.1109/BIOCAS.2018.8584749\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cbb0e0b82e1da40ba59da6642ead39cacee24278\",\"title\":\"Proto-Object Based Saliency Model with Second-Order Texture Feature\",\"url\":\"https://www.semanticscholar.org/paper/cbb0e0b82e1da40ba59da6642ead39cacee24278\",\"venue\":\"2018 IEEE Biomedical Circuits and Systems Conference (BioCAS)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22284491\",\"name\":\"Y. Yang\"},{\"authorId\":null,\"name\":\"Bei Li\"},{\"authorId\":\"36167749\",\"name\":\"P. Li\"},{\"authorId\":\"1726270\",\"name\":\"Q. Liu\"}],\"doi\":\"10.1109/TMM.2018.2867742\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"88b90abf1c71989ad1dd86adaffe7fead4e087c7\",\"title\":\"A Two-Stage Clustering Based 3D Visual Saliency Model for Dynamic Scenarios\",\"url\":\"https://www.semanticscholar.org/paper/88b90abf1c71989ad1dd86adaffe7fead4e087c7\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"117020602\",\"name\":\"R. Li\"},{\"authorId\":\"120931191\",\"name\":\"Chi-Hao Wu\"},{\"authorId\":\"2202149\",\"name\":\"Shuaicheng Liu\"},{\"authorId\":\"46585209\",\"name\":\"J. Wang\"},{\"authorId\":\"3065597\",\"name\":\"Guangfu Wang\"},{\"authorId\":\"1624153165\",\"name\":\"Guanghui Liu\"},{\"authorId\":\"108249855\",\"name\":\"Bing Zeng\"}],\"doi\":\"10.1109/TIP.2020.3036754\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"040c24003b439194f1efcb4c08e4ca41ecf65536\",\"title\":\"SDP-GAN: Saliency Detail Preservation Generative Adversarial Networks for High Perceptual Quality Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/040c24003b439194f1efcb4c08e4ca41ecf65536\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1952480\",\"name\":\"E. Dauc\\u00e9\"},{\"authorId\":\"1382220168\",\"name\":\"Pierre Albiges\"},{\"authorId\":\"3253101\",\"name\":\"Laurent Udo Perrinet\"}],\"doi\":\"10.1167/jov.20.8.22\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"36c8af6fd43c03476d5114d2461592f5287e76c8\",\"title\":\"A dual foveal-peripheral visual processing model implements efficient saccade selection\",\"url\":\"https://www.semanticscholar.org/paper/36c8af6fd43c03476d5114d2461592f5287e76c8\",\"venue\":\"Journal of Vision\",\"year\":2020},{\"arxivId\":\"2005.02181\",\"authors\":[{\"authorId\":\"31712060\",\"name\":\"W. Ma\"},{\"authorId\":\"37626579\",\"name\":\"Benjamin Peters\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c6afba8d8867cc34579285f54cfec14e261e702\",\"title\":\"A neural network walks into a lab: towards using deep nets as models for human behavior\",\"url\":\"https://www.semanticscholar.org/paper/1c6afba8d8867cc34579285f54cfec14e261e702\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403601542\",\"name\":\"Noa Malem-Shinitski\"},{\"authorId\":\"52184854\",\"name\":\"S. Seelig\"},{\"authorId\":\"50156670\",\"name\":\"Sebastian Reich\"},{\"authorId\":\"3258874\",\"name\":\"Ralf Engbert\"}],\"doi\":\"10.32470/ccn.2019.1246-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e874b7fd2bf82d568359aee8221eb6f0c9ce3c03\",\"title\":\"Bayesian inference for an exploration-exploitation model of human gaze control\",\"url\":\"https://www.semanticscholar.org/paper/e874b7fd2bf82d568359aee8221eb6f0c9ce3c03\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1904.07080\",\"authors\":[{\"authorId\":\"1743773\",\"name\":\"Mai Xu\"},{\"authorId\":\"40248914\",\"name\":\"Li Yang\"},{\"authorId\":\"144978572\",\"name\":\"Xiaoming Tao\"},{\"authorId\":\"1866977\",\"name\":\"Yiping Duan\"},{\"authorId\":\"1754571\",\"name\":\"Zulin Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"89fdf25a9ced9484512c911e23afbbb54f98b9ad\",\"title\":\"Saliency Prediction on Omnidirectional Images with Generative Adversarial Imitation Learning\",\"url\":\"https://www.semanticscholar.org/paper/89fdf25a9ced9484512c911e23afbbb54f98b9ad\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50313388\",\"name\":\"Y. Fang\"},{\"authorId\":\"47957022\",\"name\":\"Xiaoqiang Zhang\"},{\"authorId\":\"152443510\",\"name\":\"Feiniu Yuan\"},{\"authorId\":\"1830032\",\"name\":\"N. Imamoglu\"},{\"authorId\":\"49958431\",\"name\":\"H. Liu\"}],\"doi\":\"10.1016/J.PATCOG.2019.106987\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"860a93926d62569b3e93214adca5a65e30f7a7c8\",\"title\":\"Video saliency detection by gestalt theory\",\"url\":\"https://www.semanticscholar.org/paper/860a93926d62569b3e93214adca5a65e30f7a7c8\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34863269\",\"name\":\"Tanmay Nath\"},{\"authorId\":\"2068891\",\"name\":\"Alexander Mathis\"},{\"authorId\":\"48162930\",\"name\":\"A. Chen\"},{\"authorId\":\"27182731\",\"name\":\"Amir Patel\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"},{\"authorId\":\"4058359\",\"name\":\"M. Mathis\"}],\"doi\":\"10.1038/s41596-019-0176-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"47459906df95e4ab149209feee8088c610faa7a3\",\"title\":\"Using DeepLabCut for 3D markerless pose estimation across species and behaviors\",\"url\":\"https://www.semanticscholar.org/paper/47459906df95e4ab149209feee8088c610faa7a3\",\"venue\":\"Nature Protocols\",\"year\":2019},{\"arxivId\":\"1904.03571\",\"authors\":[{\"authorId\":\"144545126\",\"name\":\"S. Yang\"},{\"authorId\":\"2604251\",\"name\":\"Guosheng Lin\"},{\"authorId\":\"3318404\",\"name\":\"Qiuping Jiang\"},{\"authorId\":\"144968898\",\"name\":\"W. Lin\"}],\"doi\":\"10.1109/TMM.2019.2947352\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"023b11c04e5ea605fe999b015cbf62502cab068b\",\"title\":\"A Dilated Inception Network for Visual Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/023b11c04e5ea605fe999b015cbf62502cab068b\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2246414\",\"name\":\"Xiongkuo Min\"},{\"authorId\":\"144826391\",\"name\":\"Guangtao Zhai\"},{\"authorId\":\"1735685\",\"name\":\"Jiantao Zhou\"},{\"authorId\":\"120069998\",\"name\":\"Xiaoping Zhang\"},{\"authorId\":\"15469693\",\"name\":\"Xiaokang Yang\"},{\"authorId\":\"145394028\",\"name\":\"X. Guan\"}],\"doi\":\"10.1109/TIP.2020.2966082\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c597fc740c296c3f3713cd88e9d65f5b119790c\",\"title\":\"A Multimodal Saliency Model for Videos With High Audio-Visual Correspondence\",\"url\":\"https://www.semanticscholar.org/paper/1c597fc740c296c3f3713cd88e9d65f5b119790c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4218304\",\"name\":\"C. Wloka\"},{\"authorId\":\"3468296\",\"name\":\"Iuliia Kotseruba\"},{\"authorId\":\"1727853\",\"name\":\"John K. Tsotsos\"}],\"doi\":\"10.1109/CVPR.2018.00336\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dddef2c9c6d8b38a7eba838f801e0855d50c85a4\",\"title\":\"Active Fixation Control to Predict Saccade Sequences\",\"url\":\"https://www.semanticscholar.org/paper/dddef2c9c6d8b38a7eba838f801e0855d50c85a4\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152829057\",\"name\":\"Yupei Chen\"},{\"authorId\":\"2851379\",\"name\":\"Zhibo Yang\"},{\"authorId\":\"117396297\",\"name\":\"Seoyoung Ahn\"},{\"authorId\":\"1686020\",\"name\":\"D. Samaras\"},{\"authorId\":\"2356016\",\"name\":\"Minh Hoai\"},{\"authorId\":\"1696991\",\"name\":\"G. Zelinsky\"}],\"doi\":\"10.1101/2020.07.27.221499\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8381ae03629962ab8bd0782f6a8075597c1e63f7\",\"title\":\"COCO-Search18: A Dataset for Predicting Goal-directed Attention Control\",\"url\":\"https://www.semanticscholar.org/paper/8381ae03629962ab8bd0782f6a8075597c1e63f7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9643927\",\"name\":\"A. Prahara\"},{\"authorId\":\"67341375\",\"name\":\"M. Murinto\"},{\"authorId\":\"9730852\",\"name\":\"Dewi Pramudi Ismi\"}],\"doi\":\"10.26555/ijain.v6i1.469\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fa18cf4ddface96d9ea891a46dda43f697b25040\",\"title\":\"Bottom-up visual attention model for still image: a preliminary study\",\"url\":\"https://www.semanticscholar.org/paper/fa18cf4ddface96d9ea891a46dda43f697b25040\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3d173893dd3f22fd73acc16b94f0ea98469c9855\",\"title\":\"Saliency Prediction in the Deep Learning Era: Successes, Limitations, and Future Challenges\",\"url\":\"https://www.semanticscholar.org/paper/3d173893dd3f22fd73acc16b94f0ea98469c9855\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143648851\",\"name\":\"G. Boccignone\"},{\"authorId\":\"1896593\",\"name\":\"Vittorio Cuculo\"},{\"authorId\":\"1411402819\",\"name\":\"Alessandro D\\u2019Amelio\"}],\"doi\":\"10.1007/978-3-030-30645-8_4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ab0cc4ea1f758265b216187fd67a7f395cadc2b5\",\"title\":\"Problems with Saliency Maps\",\"url\":\"https://www.semanticscholar.org/paper/ab0cc4ea1f758265b216187fd67a7f395cadc2b5\",\"venue\":\"ICIAP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2506727\",\"name\":\"Taylor R. Hayes\"},{\"authorId\":\"144897958\",\"name\":\"J. M. Henderson\"}],\"doi\":\"10.3758/s13423-019-01642-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c52f4072e89a74c4b335997d932800328624576d\",\"title\":\"Scene semantics involuntarily guide attention during visual search.\",\"url\":\"https://www.semanticscholar.org/paper/c52f4072e89a74c4b335997d932800328624576d\",\"venue\":\"Psychonomic bulletin & review\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"117914495\",\"name\":\"Marek A. Pedziwiatr\"},{\"authorId\":\"2997408\",\"name\":\"Matthias K\\u00fcmmerer\"},{\"authorId\":\"49737748\",\"name\":\"Thomas S. A. Wallis\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"},{\"authorId\":\"2986600\",\"name\":\"C. Teufel\"}],\"doi\":\"10.1101/840256\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ff2bb372b6a419d274284379f2ce309cd4f6d425\",\"title\":\"Meaning maps and saliency models based on deep convolutional neural networks are insensitive to image meaning when predicting human fixations\",\"url\":\"https://www.semanticscholar.org/paper/ff2bb372b6a419d274284379f2ce309cd4f6d425\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144897958\",\"name\":\"J. M. Henderson\"},{\"authorId\":\"2506727\",\"name\":\"Taylor R. Hayes\"}],\"doi\":\"10.1101/207076\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dbbdef149409f8805d414f129d3e3530e92871c9\",\"title\":\"Meaning Guides Attention in Real-World Scene Images: Evidence from Eye Movements and Meaning Maps\",\"url\":\"https://www.semanticscholar.org/paper/dbbdef149409f8805d414f129d3e3530e92871c9\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1812.08848\",\"authors\":[{\"authorId\":\"4218304\",\"name\":\"C. Wloka\"},{\"authorId\":\"3211787\",\"name\":\"Toni Kunic\"},{\"authorId\":\"3468296\",\"name\":\"Iuliia Kotseruba\"},{\"authorId\":\"52349494\",\"name\":\"Ramin Fahimi\"},{\"authorId\":\"27737461\",\"name\":\"Nicholas Frosst\"},{\"authorId\":\"2866780\",\"name\":\"Neil D. B. Bruce\"},{\"authorId\":\"1727853\",\"name\":\"John K. Tsotsos\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"6b8a26d45c8f1c058a4454792d7c43c05ca5f76a\",\"title\":\"SMILER: Saliency Model Implementation Library for Experimental Research\",\"url\":\"https://www.semanticscholar.org/paper/6b8a26d45c8f1c058a4454792d7c43c05ca5f76a\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46515199\",\"name\":\"J. Lodge\"},{\"authorId\":\"143926115\",\"name\":\"W. J. Harrison\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4de60e5ffee6c5579aaaf5d5a9dc1fddf702ef8e\",\"title\":\"The Role of Attention in Learning in the Digital Age\",\"url\":\"https://www.semanticscholar.org/paper/4de60e5ffee6c5579aaaf5d5a9dc1fddf702ef8e\",\"venue\":\"The Yale journal of biology and medicine\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143741775\",\"name\":\"F. Zhou\"},{\"authorId\":\"80947730\",\"name\":\"Rongguo Yao\"},{\"authorId\":\"1474234993\",\"name\":\"Guangsen Liao\"},{\"authorId\":\"3185721\",\"name\":\"Bozhi Liu\"},{\"authorId\":\"1713506\",\"name\":\"Guoping Qiu\"}],\"doi\":\"10.1109/TIP.2020.3016464\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10d15860ece08b185b115da2b03075d7e8065f4e\",\"title\":\"Visual Saliency via Embedding Hierarchical Knowledge in a Deep Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/10d15860ece08b185b115da2b03075d7e8065f4e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4945704\",\"name\":\"Gwendolyn Rehrig\"},{\"authorId\":\"2506727\",\"name\":\"Taylor R. Hayes\"},{\"authorId\":\"144897958\",\"name\":\"J. M. Henderson\"},{\"authorId\":\"144652472\",\"name\":\"F. Ferreira\"}],\"doi\":\"10.3758/S13421-020-01050-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"03c2371b68ee5199870b88eb3bc095d172f6fad2\",\"title\":\"When scenes speak louder than words: Verbal encoding does not mediate the relationship between scene meaning and visual attention.\",\"url\":\"https://www.semanticscholar.org/paper/03c2371b68ee5199870b88eb3bc095d172f6fad2\",\"venue\":\"Memory & cognition\",\"year\":2020},{\"arxivId\":\"1907.02336\",\"authors\":[{\"authorId\":\"150007878\",\"name\":\"Alexandre Bruckert\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"143962642\",\"name\":\"Zhi Liu\"},{\"authorId\":\"1701717\",\"name\":\"M. Christie\"},{\"authorId\":\"1789744\",\"name\":\"O. Meur\"}],\"doi\":\"10.1016/j.neucom.2020.06.131\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"79c5b0d6dc39e7b0f59690520c17e33007a6b985\",\"title\":\"Deep Saliency Models : The Quest For The Loss Function\",\"url\":\"https://www.semanticscholar.org/paper/79c5b0d6dc39e7b0f59690520c17e33007a6b985\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40442204\",\"name\":\"W. Abbott\"},{\"authorId\":\"40892845\",\"name\":\"J. A. Harston\"},{\"authorId\":\"49796804\",\"name\":\"A. Faisal\"}],\"doi\":\"10.1101/2020.02.08.938514\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"39c3f432f66a736a40dd58b7493bea66a96ff778\",\"title\":\"Linear Embodied Saliency: a Model of Full-Body Kinematics-based Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/39c3f432f66a736a40dd58b7493bea66a96ff778\",\"venue\":\"\",\"year\":2020}],\"corpusId\":6019990,\"doi\":\"10.1109/ICCV.2017.513\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":16,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"53d77b463ec744491ab68ed49f5d2152cbbcbf9d\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1619078806\",\"name\":\"A. ADoefaa\"},{\"authorId\":\"1619192001\",\"name\":\"H. P. Doetsch\"},{\"authorId\":\"1619263939\",\"name\":\"Draweng Table\"},{\"authorId\":\"1619192001\",\"name\":\"H. P. Doetsch\"}],\"doi\":\"10.2307/j.ctvrnfqk1.10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4dc21a168070dc87266accd9ce2c06ee6115a285\",\"title\":\"? ? ? ? f ? ? ? ? ?\",\"url\":\"https://www.semanticscholar.org/paper/4dc21a168070dc87266accd9ce2c06ee6115a285\",\"venue\":\"\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47059693\",\"name\":\"L. Zhang\"},{\"authorId\":\"49488601\",\"name\":\"M. Tong\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"},{\"authorId\":\"2207531\",\"name\":\"Honghao Shan\"},{\"authorId\":\"48524582\",\"name\":\"G. Cottrell\"}],\"doi\":\"10.1167/8.7.32\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e80c48441351fc1d928524710b4500a0de8315bb\",\"title\":\"SUN: A Bayesian framework for saliency using natural statistics.\",\"url\":\"https://www.semanticscholar.org/paper/e80c48441351fc1d928524710b4500a0de8315bb\",\"venue\":\"Journal of vision\",\"year\":2008},{\"arxivId\":\"1207.2370\",\"authors\":[{\"authorId\":\"7767501\",\"name\":\"Simon Barthelm\\u00e9\"},{\"authorId\":\"5181971\",\"name\":\"H. Trukenbrod\"},{\"authorId\":\"3258874\",\"name\":\"Ralf Engbert\"},{\"authorId\":\"1924112\",\"name\":\"Felix Wichmann\"}],\"doi\":\"10.1167/13.12.1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0888fb9802226f8fe9540b4e8f6fd715b8c72723\",\"title\":\"Modeling fixation locations using spatial point processes.\",\"url\":\"https://www.semanticscholar.org/paper/0888fb9802226f8fe9540b4e8f6fd715b8c72723\",\"venue\":\"Journal of vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38497468\",\"name\":\"M. Cerf\"},{\"authorId\":\"39810944\",\"name\":\"Jonathan Harel\"},{\"authorId\":\"1917767\",\"name\":\"W. Einh\\u00e4user\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a48dc9c898d6ff1cdb96dcf8a297bafb8ac1b9e2\",\"title\":\"Predicting human gaze using low-level saliency combined with face detection\",\"url\":\"https://www.semanticscholar.org/paper/a48dc9c898d6ff1cdb96dcf8a297bafb8ac1b9e2\",\"venue\":\"NIPS\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3369864\",\"name\":\"B. Tatler\"},{\"authorId\":\"1849998\",\"name\":\"B. Vincent\"}],\"doi\":\"10.16910/JEMR.2.2.5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3ba38425b1f71d29e7e4add7af0ac18f75a80fd3\",\"title\":\"Systematic tendencies in scene viewing\",\"url\":\"https://www.semanticscholar.org/paper/3ba38425b1f71d29e7e4add7af0ac18f75a80fd3\",\"venue\":\"\",\"year\":2008},{\"arxivId\":\"1610.01708\",\"authors\":[{\"authorId\":\"145021890\",\"name\":\"N. Liu\"},{\"authorId\":\"7181955\",\"name\":\"J. Han\"}],\"doi\":\"10.1109/TIP.2018.2817047\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"40bc3b9cfe74a4f164e53bf2e037e61256f8d354\",\"title\":\"A Deep Spatial Contextual Long-Term Recurrent Convolutional Network for Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/40bc3b9cfe74a4f164e53bf2e037e61256f8d354\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3141668\",\"name\":\"Kathryn Koehler\"},{\"authorId\":\"152831016\",\"name\":\"F. Guo\"},{\"authorId\":\"38654394\",\"name\":\"Shenmin Zhang\"},{\"authorId\":\"1895768\",\"name\":\"M. Eckstein\"}],\"doi\":\"10.1167/14.3.14\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0ab4347176ac94b17065fea285f952b1de32c2c0\",\"title\":\"What do saliency models predict?\",\"url\":\"https://www.semanticscholar.org/paper/0ab4347176ac94b17065fea285f952b1de32c2c0\",\"venue\":\"Journal of vision\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3369864\",\"name\":\"B. Tatler\"},{\"authorId\":\"34931109\",\"name\":\"R. Baddeley\"},{\"authorId\":\"2283822\",\"name\":\"I. Gilchrist\"}],\"doi\":\"10.1016/j.visres.2004.09.017\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ae38ed953333fb39eb671fce0247db65a09b3a80\",\"title\":\"Visual correlates of fixation selection: effects of scale and time\",\"url\":\"https://www.semanticscholar.org/paper/ae38ed953333fb39eb671fce0247db65a09b3a80\",\"venue\":\"Vision Research\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2866780\",\"name\":\"Neil D. B. Bruce\"},{\"authorId\":\"1727853\",\"name\":\"John K. Tsotsos\"}],\"doi\":\"10.1167/9.3.5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"25e67f4ca6f45533cbe5cec4c6d169b7daf3af2b\",\"title\":\"Saliency, attention, and visual search: an information theoretic approach.\",\"url\":\"https://www.semanticscholar.org/paper/25e67f4ca6f45533cbe5cec4c6d169b7daf3af2b\",\"venue\":\"Journal of vision\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143775672\",\"name\":\"Tilke Judd\"},{\"authorId\":\"1865091\",\"name\":\"Krista A. Ehinger\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/ICCV.2009.5459462\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c7614898de1cfee1a3a1c564f52c1e67879c29b3\",\"title\":\"Learning to predict where humans look\",\"url\":\"https://www.semanticscholar.org/paper/c7614898de1cfee1a3a1c564f52c1e67879c29b3\",\"venue\":\"2009 IEEE 12th International Conference on Computer Vision\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51245102\",\"name\":\"Shafin Rahman\"},{\"authorId\":\"2866780\",\"name\":\"Neil D. B. Bruce\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"27318149a1fc136202c5b5f48ea8d21d0574d9ed\",\"title\":\"Saliency, Scale and Information: Towards a Unifying Theory\",\"url\":\"https://www.semanticscholar.org/paper/27318149a1fc136202c5b5f48ea8d21d0574d9ed\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1917767\",\"name\":\"W. Einh\\u00e4user\"},{\"authorId\":\"38163342\",\"name\":\"Merrielle Spain\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"}],\"doi\":\"10.1167/8.14.18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c032ef5e4ce9536de5669bbe487e1f618d3a12a6\",\"title\":\"Objects predict fixations better than early saliency.\",\"url\":\"https://www.semanticscholar.org/paper/c032ef5e4ce9536de5669bbe487e1f618d3a12a6\",\"venue\":\"Journal of vision\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2286630\",\"name\":\"E. Vig\"},{\"authorId\":\"1944405\",\"name\":\"M. Dorr\"},{\"authorId\":\"2042941\",\"name\":\"D. Cox\"}],\"doi\":\"10.1109/CVPR.2014.358\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8693c32dff29e851760fa0b6af464050ffc383d6\",\"title\":\"Large-Scale Optimization of Hierarchical Features for Saliency Prediction in Natural Images\",\"url\":\"https://www.semanticscholar.org/paper/8693c32dff29e851760fa0b6af464050ffc383d6\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1408.5093\",\"authors\":[{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"1782282\",\"name\":\"Evan Shelhamer\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"3049736\",\"name\":\"S. Karayev\"},{\"authorId\":\"144361581\",\"name\":\"J. Long\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1145/2647868.2654889\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6bdb186ec4726e00a8051119636d4df3b94043b5\",\"title\":\"Caffe: Convolutional Architecture for Fast Feature Embedding\",\"url\":\"https://www.semanticscholar.org/paper/6bdb186ec4726e00a8051119636d4df3b94043b5\",\"venue\":\"ACM Multimedia\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2989773\",\"name\":\"Nicolas Riche\"},{\"authorId\":\"1681157\",\"name\":\"M. Mancas\"},{\"authorId\":\"2896417\",\"name\":\"Matthieu Duvinage\"},{\"authorId\":\"3028207\",\"name\":\"Makiese Mibulumukini\"},{\"authorId\":\"50276543\",\"name\":\"B. Gosselin\"},{\"authorId\":\"49164810\",\"name\":\"T. Dutoit\"}],\"doi\":\"10.1016/j.image.2013.03.009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"83ec029e1a7b41669f8254b24c070050d9d01d75\",\"title\":\"RARE2012: A multi-scale rarity-based saliency detection with its comparative statistical analysis\",\"url\":\"https://www.semanticscholar.org/paper/83ec029e1a7b41669f8254b24c070050d9d01d75\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2013},{\"arxivId\":\"1510.02927\",\"authors\":[{\"authorId\":\"1784761\",\"name\":\"S. Kruthiventi\"},{\"authorId\":\"50430041\",\"name\":\"Kumar Ayush\"},{\"authorId\":\"144682140\",\"name\":\"R. Venkatesh Babu\"}],\"doi\":\"10.1109/TIP.2017.2710620\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1295cbaf3b03de2eb8c79530289f5939d7819e5c\",\"title\":\"DeepFix: A Fully Convolutional Neural Network for Predicting Human Eye Fixations\",\"url\":\"https://www.semanticscholar.org/paper/1295cbaf3b03de2eb8c79530289f5939d7819e5c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"2037692\",\"name\":\"Dicky N. Sihite\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1167/13.10.18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5183694a7cd0189d3017ba561801a964503d74d9\",\"title\":\"Objects do not predict fixations better than early saliency: a re-analysis of Einhauser et al.'s data.\",\"url\":\"https://www.semanticscholar.org/paper/5183694a7cd0189d3017ba561801a964503d74d9\",\"venue\":\"Journal of vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1644030275\",\"name\":\"BorjiAli\"},{\"authorId\":\"1644040739\",\"name\":\"IttiLaurent\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4a80571c22eacc0c995cdbc15be77c576af83614\",\"title\":\"State-of-the-Art in Visual Attention Modeling\",\"url\":\"https://www.semanticscholar.org/paper/4a80571c22eacc0c995cdbc15be77c576af83614\",\"venue\":\"\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3369864\",\"name\":\"B. Tatler\"},{\"authorId\":\"2848854\",\"name\":\"M. Hayhoe\"},{\"authorId\":\"40466012\",\"name\":\"M. Land\"},{\"authorId\":\"153332539\",\"name\":\"D. Ballard\"}],\"doi\":\"10.1167/11.5.5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7ad8fb4a8af5e4a22b6bd40df055f8a3e0ec69dd\",\"title\":\"Eye guidance in natural vision: reinterpreting salience.\",\"url\":\"https://www.semanticscholar.org/paper/7ad8fb4a8af5e4a22b6bd40df055f8a3e0ec69dd\",\"venue\":\"Journal of vision\",\"year\":2011},{\"arxivId\":\"1804.01793\",\"authors\":[{\"authorId\":\"35129473\",\"name\":\"Saumya Jetley\"},{\"authorId\":\"26734366\",\"name\":\"N. Murray\"},{\"authorId\":\"2286630\",\"name\":\"E. Vig\"}],\"doi\":\"10.1109/CVPR.2016.620\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a4d42c041bf30021550e581775c1e04f253edf54\",\"title\":\"End-to-End Saliency Mapping via Probability Distribution Prediction\",\"url\":\"https://www.semanticscholar.org/paper/a4d42c041bf30021550e581775c1e04f253edf54\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152627906\",\"name\":\"T. Judd\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"daef3fdc4190927c063ae94c12437cf82a6d1c20\",\"title\":\"A Benchmark of Computational Models of Saliency to Predict Human Fixations\",\"url\":\"https://www.semanticscholar.org/paper/daef3fdc4190927c063ae94c12437cf82a6d1c20\",\"venue\":\"\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3084719\",\"name\":\"Xiaodi Hou\"},{\"authorId\":\"5381034\",\"name\":\"L. Zhang\"}],\"doi\":\"10.1109/CVPR.2007.383267\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9ce3c18eb4fa86fd19bce46227be39895de4e4ab\",\"title\":\"Saliency Detection: A Spectral Residual Approach\",\"url\":\"https://www.semanticscholar.org/paper/9ce3c18eb4fa86fd19bce46227be39895de4e4ab\",\"venue\":\"2007 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2608733\",\"name\":\"Stas Goferman\"},{\"authorId\":\"1398327241\",\"name\":\"L. Zelnik-Manor\"},{\"authorId\":\"49653522\",\"name\":\"A. Tal\"}],\"doi\":\"10.1109/CVPR.2010.5539929\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"32e072aa603a64ca5b40fdc6b4c94c951166a310\",\"title\":\"Context-aware saliency detection\",\"url\":\"https://www.semanticscholar.org/paper/32e072aa603a64ca5b40fdc6b4c94c951166a310\",\"venue\":\"2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2997408\",\"name\":\"Matthias K\\u00fcmmerer\"},{\"authorId\":\"49737748\",\"name\":\"Thomas S. A. Wallis\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":\"10.1073/pnas.1510393112\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"01058e4aabd61571da9e43a618834c90aabaf691\",\"title\":\"Information-theoretic model comparison unifies saliency metrics\",\"url\":\"https://www.semanticscholar.org/paper/01058e4aabd61571da9e43a618834c90aabaf691\",\"venue\":\"Proceedings of the National Academy of Sciences\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"S Goferman\"},{\"authorId\":null,\"name\":\"L Zelnik-Manor\"},{\"authorId\":null,\"name\":\"A Tal\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Context-aware saliency detection. Pattern Analysis and Machine Intelligence\",\"url\":\"\",\"venue\":\"IEEE Transactions on\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"M. K\\u00fcmmerer\"},{\"authorId\":null,\"name\":\"T.S.A. Wallis\"},{\"authorId\":null,\"name\":\"M. Bethge\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Saliency benchmarking: Separating models\",\"url\":\"\",\"venue\":\"maps and metrics. arXiv e-prints, abs/1704.08615\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"S. Rahman\"},{\"authorId\":null,\"name\":\"N. Bruce\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Saliency\",\"url\":\"\",\"venue\":\"scale and information: Towards a unifying theory. In Advances in Neural Information Processing Systems 28, pages 2188\\u20132196\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7326223\",\"name\":\"L. Itti\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"},{\"authorId\":\"3271571\",\"name\":\"E. Niebur\"}],\"doi\":\"10.1109/34.730558\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4816f0b6f0d05da3901441bfa5cc7be044b4da8b\",\"title\":\"A Model of Saliency-Based Visual Attention for Rapid Scene Analysis\",\"url\":\"https://www.semanticscholar.org/paper/4816f0b6f0d05da3901441bfa5cc7be044b4da8b\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"2060684\",\"name\":\"Monica S. Castelhano\"},{\"authorId\":\"1889476\",\"name\":\"J. Henderson\"}],\"doi\":\"10.1037/0033-295X.113.4.766\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b35e4d00d9a9bfae83a8b0914eb1073a77a11d78\",\"title\":\"Contextual guidance of eye movements and attention in real-world scenes: the role of global features in object search.\",\"url\":\"https://www.semanticscholar.org/paper/b35e4d00d9a9bfae83a8b0914eb1073a77a11d78\",\"venue\":\"Psychological review\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"47680287\",\"name\":\"W. Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2009.5206848\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1b47265245e8db53a553049dcb27ed3e495fd625\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/1b47265245e8db53a553049dcb27ed3e495fd625\",\"venue\":\"CVPR 2009\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"N. D. Bruce\"},{\"authorId\":null,\"name\":\"J. K. Tsotsos\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Saliency\",\"url\":\"\",\"venue\":\"attention, and visual search: An information theoretic approach. Journal of vision, 9(3)\",\"year\":2009},{\"arxivId\":\"1606.00110\",\"authors\":[{\"authorId\":\"51285293\",\"name\":\"Christopher Thomas\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"36541e5dcc7964f80bd622e6212fa5808730fe95\",\"title\":\"OpenSalicon: An Open Source Implementation of the Salicon Saliency Model\",\"url\":\"https://www.semanticscholar.org/paper/36541e5dcc7964f80bd622e6212fa5808730fe95\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145270377\",\"name\":\"H. Hong\"},{\"authorId\":\"40657572\",\"name\":\"D. Yamins\"},{\"authorId\":\"2034026\",\"name\":\"N. Majaj\"},{\"authorId\":\"1865831\",\"name\":\"J. DiCarlo\"}],\"doi\":\"10.1038/nn.4247\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"09eb087fc5730589e59673aafa0dfc788768611a\",\"title\":\"Explicit information for category-orthogonal object properties increases along the ventral stream\",\"url\":\"https://www.semanticscholar.org/paper/09eb087fc5730589e59673aafa0dfc788768611a\",\"venue\":\"Nature Neuroscience\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1849998\",\"name\":\"B. Vincent\"},{\"authorId\":\"144053329\",\"name\":\"R. Baddeley\"},{\"authorId\":\"4742310\",\"name\":\"A. Correani\"},{\"authorId\":\"4997851\",\"name\":\"T. Troscianko\"},{\"authorId\":\"46706417\",\"name\":\"U. Leonards\"}],\"doi\":\"10.1080/13506280902916691\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6eb67a182982c1b9d0be9fa7bb6ce2d09a55dccc\",\"title\":\"Do we look at lights? Using mixture modelling to distinguish between low- and high-level factors in natural image viewing\",\"url\":\"https://www.semanticscholar.org/paper/6eb67a182982c1b9d0be9fa7bb6ce2d09a55dccc\",\"venue\":\"\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144645142\",\"name\":\"M. Jiang\"},{\"authorId\":\"1961257\",\"name\":\"Shengsheng Huang\"},{\"authorId\":\"2104164\",\"name\":\"Juanyong Duan\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1109/CVPR.2015.7298710\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c71db5d3546e22227662ee0f0ce586495ef18899\",\"title\":\"SALICON: Saliency in Context\",\"url\":\"https://www.semanticscholar.org/paper/c71db5d3546e22227662ee0f0ce586495ef18899\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1409.4842\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"46641766\",\"name\":\"W. Liu\"},{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"},{\"authorId\":\"48840704\",\"name\":\"Scott Reed\"},{\"authorId\":\"1838674\",\"name\":\"Dragomir Anguelov\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"39863668\",\"name\":\"Andrew Rabinovich\"}],\"doi\":\"10.1109/CVPR.2015.7298594\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"title\":\"Going deeper with convolutions\",\"url\":\"https://www.semanticscholar.org/paper/e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144247007\",\"name\":\"X. Huang\"},{\"authorId\":\"3329744\",\"name\":\"Chengyao Shen\"},{\"authorId\":\"2343486\",\"name\":\"X. Boix\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1109/ICCV.2015.38\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1281e443d2cf1c1dd71ed3b7b0376d408d0958af\",\"title\":\"SALICON: Reducing the Semantic Gap in Saliency Prediction by Adapting Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/1281e443d2cf1c1dd71ed3b7b0376d408d0958af\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3249046\",\"name\":\"C. Rothkopf\"},{\"authorId\":\"153332539\",\"name\":\"D. Ballard\"},{\"authorId\":\"2848854\",\"name\":\"M. Hayhoe\"}],\"doi\":\"10.1167/7.14.16\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a35b871562e8480bd5a1a20914268a4db5aaac45\",\"title\":\"Task and context determine where you look.\",\"url\":\"https://www.semanticscholar.org/paper/a35b871562e8480bd5a1a20914268a4db5aaac45\",\"venue\":\"Journal of vision\",\"year\":2007},{\"arxivId\":\"1411.1045\",\"authors\":[{\"authorId\":\"2997408\",\"name\":\"Matthias K\\u00fcmmerer\"},{\"authorId\":\"2073063\",\"name\":\"L. Theis\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"652e652bca63f60c2c5f5840d4a34bb743f699b9\",\"title\":\"Deep Gaze I: Boosting Saliency Prediction with Feature Maps Trained on ImageNet\",\"url\":\"https://www.semanticscholar.org/paper/652e652bca63f60c2c5f5840d4a34bb743f699b9\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1080/13506280444000661\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"463c3e8403b95b88f8e19cdaa3d9ec0a3105f6ac\",\"title\":\"Quantifying the contribution of low-level saliency to human eye movements in dynamic scenes\",\"url\":\"https://www.semanticscholar.org/paper/463c3e8403b95b88f8e19cdaa3d9ec0a3105f6ac\",\"venue\":\"\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144007359\",\"name\":\"W. Kienzle\"},{\"authorId\":\"30541601\",\"name\":\"M. Franz\"},{\"authorId\":\"1707625\",\"name\":\"B. Sch\\u00f6lkopf\"},{\"authorId\":\"1924112\",\"name\":\"Felix Wichmann\"}],\"doi\":\"10.1167/9.5.7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"090e7d6ef689854e0213ff43f8fe8f369d9f7a52\",\"title\":\"Center-surround patterns emerge as optimal predictors for human saccade targets.\",\"url\":\"https://www.semanticscholar.org/paper/090e7d6ef689854e0213ff43f8fe8f369d9f7a52\",\"venue\":\"Journal of vision\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7767501\",\"name\":\"Simon Barthelm\\u00e9\"},{\"authorId\":\"5181971\",\"name\":\"H. Trukenbrod\"},{\"authorId\":\"3258874\",\"name\":\"Ralf Engbert\"},{\"authorId\":\"1924112\",\"name\":\"Felix Wichmann\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8f0c694932afde87c300b911ab848b02856b0570\",\"title\":\"Modelling fixation locations using spatial point processes\",\"url\":\"https://www.semanticscholar.org/paper/8f0c694932afde87c300b911ab848b02856b0570\",\"venue\":\"\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1891828\",\"name\":\"Leon A. Gatys\"},{\"authorId\":\"1746183\",\"name\":\"Alexander S. Ecker\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":\"10.1109/CVPR.2016.265\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7568d13a82f7afa4be79f09c295940e48ec6db89\",\"title\":\"Image Style Transfer Using Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/7568d13a82f7afa4be79f09c295940e48ec6db89\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143615083\",\"name\":\"R. J. Peters\"},{\"authorId\":\"4292093\",\"name\":\"A. Iyer\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"}],\"doi\":\"10.1016/j.visres.2005.03.019\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a7447f7e6197c0875a28686efdffe4ba4beb5460\",\"title\":\"Components of bottom-up gaze allocation in natural images\",\"url\":\"https://www.semanticscholar.org/paper/a7447f7e6197c0875a28686efdffe4ba4beb5460\",\"venue\":\"Vision Research\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2866780\",\"name\":\"Neil D. B. Bruce\"},{\"authorId\":\"8025545\",\"name\":\"Christopher Catton\"},{\"authorId\":\"8464855\",\"name\":\"S. Janjic\"}],\"doi\":\"10.1109/CVPR.2016.62\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3fedbcec10c2ba74efe3ad256850e3cdec770ff5\",\"title\":\"A Deeper Look at Saliency: Feature Contrast, Semantics, and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/3fedbcec10c2ba74efe3ad256850e3cdec770ff5\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1701293\",\"name\":\"J. Zhang\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"}],\"doi\":\"10.1109/ICCV.2013.26\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"75ee5cd7712b6ad13d64c3b4de24aa592a869fc1\",\"title\":\"Saliency Detection: A Boolean Map Approach\",\"url\":\"https://www.semanticscholar.org/paper/75ee5cd7712b6ad13d64c3b4de24aa592a869fc1\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"}],\"doi\":\"10.1167/13.4.11\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9896b03aeb17e06181c1842773fec4b742d7c51f\",\"title\":\"Visual saliency estimation by nonlinearly integrating features using region covariances.\",\"url\":\"https://www.semanticscholar.org/paper/9896b03aeb17e06181c1842773fec4b742d7c51f\",\"venue\":\"Journal of vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3369864\",\"name\":\"B. Tatler\"}],\"doi\":\"10.1167/7.14.4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"caed9b6de0142c9a4e07c96043e85e38ec22dd1e\",\"title\":\"The central fixation bias in scene viewing: selecting an optimal viewing position independently of motor biases and image feature distributions.\",\"url\":\"https://www.semanticscholar.org/paper/caed9b6de0142c9a4e07c96043e85e38ec22dd1e\",\"venue\":\"Journal of vision\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144114624\",\"name\":\"Juan Xu\"},{\"authorId\":\"144889908\",\"name\":\"M. Jiang\"},{\"authorId\":\"40440632\",\"name\":\"Shuo Wang\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"},{\"authorId\":\"51027614\",\"name\":\"Q. Zhao\"}],\"doi\":\"10.1167/14.1.28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"709e8791193cc3fe9fef9ad983afcd2891e6c680\",\"title\":\"Predicting human gaze beyond pixels.\",\"url\":\"https://www.semanticscholar.org/paper/709e8791193cc3fe9fef9ad983afcd2891e6c680\",\"venue\":\"Journal of vision\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2866780\",\"name\":\"Neil D. B. Bruce\"},{\"authorId\":\"4218304\",\"name\":\"C. Wloka\"},{\"authorId\":\"8207080\",\"name\":\"Nick Frosst\"},{\"authorId\":\"51245102\",\"name\":\"Shafin Rahman\"},{\"authorId\":\"1727853\",\"name\":\"John K. Tsotsos\"}],\"doi\":\"10.1016/j.visres.2015.01.010\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"43236b0c968e08b7444742dc71811127288e804c\",\"title\":\"On computational modeling of visual saliency: Examining what\\u2019s right, and what\\u2019s left\",\"url\":\"https://www.semanticscholar.org/paper/43236b0c968e08b7444742dc71811127288e804c\",\"venue\":\"Vision Research\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39810944\",\"name\":\"Jonathan Harel\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"}],\"doi\":\"10.7551/mitpress/7503.003.0073\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f412bb31ec9ef8bbef70eefc7ffd04420c1365d9\",\"title\":\"Graph-Based Visual Saliency\",\"url\":\"https://www.semanticscholar.org/paper/f412bb31ec9ef8bbef70eefc7ffd04420c1365d9\",\"venue\":\"NIPS\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J Sohl-Dickstein\"},{\"authorId\":null,\"name\":\"B Poole\"},{\"authorId\":null,\"name\":\"S Ganguli\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Fast largescale optimization by unifying stochastic gradient and quasinewton methods\",\"url\":\"\",\"venue\":\"\",\"year\":2013}],\"title\":\"Understanding Low- and High-Level Contributions to Fixation Prediction\",\"topics\":[{\"topic\":\"High- and low-level\",\"topicId\":\"33507\",\"url\":\"https://www.semanticscholar.org/topic/33507\"},{\"topic\":\"Computer vision\",\"topicId\":\"5332\",\"url\":\"https://www.semanticscholar.org/topic/5332\"},{\"topic\":\"Deep learning\",\"topicId\":\"2762\",\"url\":\"https://www.semanticscholar.org/topic/2762\"},{\"topic\":\"Outline of object recognition\",\"topicId\":\"34569\",\"url\":\"https://www.semanticscholar.org/topic/34569\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"},{\"topic\":\"Relevance\",\"topicId\":\"503\",\"url\":\"https://www.semanticscholar.org/topic/503\"},{\"topic\":\"Baseline (configuration management)\",\"topicId\":\"3403\",\"url\":\"https://www.semanticscholar.org/topic/3403\"},{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"}],\"url\":\"https://www.semanticscholar.org/paper/53d77b463ec744491ab68ed49f5d2152cbbcbf9d\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017}\n"