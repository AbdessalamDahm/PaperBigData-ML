"{\"abstract\":\"We present a model for gaze prediction in egocentric video by leveraging the implicit cues that exist in camera wearer's behaviors. Specifically, we compute the camera wearer's head motion and hand location from the video and combine them to estimate where the eyes look. We further model the dynamic behavior of the gaze, in particular fixations, as latent variables to improve the gaze prediction. Our gaze prediction results outperform the state-of-the-art algorithms by a large margin on publicly available egocentric vision datasets. In addition, we demonstrate that we get a significant performance boost in recognizing daily actions and segmenting foreground objects by plugging in our gaze predictions into state-of-the-art methods.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"1738814\",\"name\":\"Y. Li\",\"url\":\"https://www.semanticscholar.org/author/1738814\"},{\"authorId\":\"47683829\",\"name\":\"A. Fathi\",\"url\":\"https://www.semanticscholar.org/author/47683829\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\",\"url\":\"https://www.semanticscholar.org/author/144177248\"}],\"citationVelocity\":26,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"096a518224a4cdfd5d2ddd2ce5405b72b028be26\",\"title\":\"SKILL MEASUREMENT VIA EGOCENTRIC VISION IN WETLAB\",\"url\":\"https://www.semanticscholar.org/paper/096a518224a4cdfd5d2ddd2ce5405b72b028be26\",\"venue\":\"\",\"year\":2013},{\"arxivId\":\"1809.07408\",\"authors\":[{\"authorId\":\"145545664\",\"name\":\"Y. Yao\"},{\"authorId\":\"143847408\",\"name\":\"Mingze Xu\"},{\"authorId\":\"37435569\",\"name\":\"Chiho Choi\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"},{\"authorId\":\"144729148\",\"name\":\"E. Atkins\"},{\"authorId\":\"2086607\",\"name\":\"B. Dariush\"}],\"doi\":\"10.1109/ICRA.2019.8794474\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"497db84d084c34cf2db8883f95000953deeeddcc\",\"title\":\"Egocentric Vision-based Future Vehicle Localization for Intelligent Driving Assistance Systems\",\"url\":\"https://www.semanticscholar.org/paper/497db84d084c34cf2db8883f95000953deeeddcc\",\"venue\":\"2019 International Conference on Robotics and Automation (ICRA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145086911\",\"name\":\"A. Betancourt\"},{\"authorId\":\"2322579\",\"name\":\"Pietro Morerio\"},{\"authorId\":\"1689330\",\"name\":\"L. Marcenaro\"},{\"authorId\":\"145741020\",\"name\":\"E. Barakova\"},{\"authorId\":\"1736974\",\"name\":\"M. Rauterberg\"},{\"authorId\":\"9587913\",\"name\":\"C. Regazzoni\"}],\"doi\":\"10.1109/ICMEW.2015.7169784\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"91b76a3a1d3679b771f60592c81468021ec77fe0\",\"title\":\"Towards a unified framework for hand-based methods in First Person Vision\",\"url\":\"https://www.semanticscholar.org/paper/91b76a3a1d3679b771f60592c81468021ec77fe0\",\"venue\":\"2015 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1400685790\",\"name\":\"Jessica Beltr\\u00e1n-M\\u00e1rquez\"},{\"authorId\":\"1399106107\",\"name\":\"M. Garc\\u00eda-V\\u00e1zquez\"},{\"authorId\":\"1381345946\",\"name\":\"J. Benois-Pineau\"},{\"authorId\":\"1384122700\",\"name\":\"L. Guti\\u00e9rrez-Robledo\"},{\"authorId\":\"80153973\",\"name\":\"J. Dartigues\"}],\"doi\":\"10.1155/2018/2676409\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f9a94545c781b455d962690c0d5b3e076bad233c\",\"title\":\"Computational Techniques for Eye Movements Analysis towards Supporting Early Diagnosis of Alzheimer's Disease: A Review\",\"url\":\"https://www.semanticscholar.org/paper/f9a94545c781b455d962690c0d5b3e076bad233c\",\"venue\":\"Comput. Math. Methods Medicine\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47295036\",\"name\":\"Zehua Zhang\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"},{\"authorId\":\"145864858\",\"name\":\"Chen Yu\"},{\"authorId\":\"2798750\",\"name\":\"Sven Bambach\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5a089bc28160fa236f219c6760b6a48c9b8d3d10\",\"title\":\"From Coarse Attention to Fine-Grained Gaze: A Two-stage 3D Fully Convolutional Network for Predicting Eye Gaze in First Person Video\",\"url\":\"https://www.semanticscholar.org/paper/5a089bc28160fa236f219c6760b6a48c9b8d3d10\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35299091\",\"name\":\"Yansong Tang\"},{\"authorId\":\"145987219\",\"name\":\"Y. Tian\"},{\"authorId\":\"1697700\",\"name\":\"Jiwen Lu\"},{\"authorId\":\"144698893\",\"name\":\"J. Feng\"},{\"authorId\":\"49640256\",\"name\":\"J. Zhou\"}],\"doi\":\"10.1109/ICIP.2017.8296915\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8fb68bb0b02a16f3e55fc210d3342aeef4226e1f\",\"title\":\"Action recognition in RGB-D egocentric videos\",\"url\":\"https://www.semanticscholar.org/paper/8fb68bb0b02a16f3e55fc210d3342aeef4226e1f\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48518145\",\"name\":\"Yantao Lu\"},{\"authorId\":\"1714074\",\"name\":\"Senem Velipasalar\"}],\"doi\":\"10.1109/GlobalSIP.2018.8646367\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c28cadedb6b05ba3ed806be920f2730c5114633b\",\"title\":\"HUMAN ACTIVITY CLASSIFICATION INCORPORATING EGOCENTRIC VIDEO AND INERTIAL MEASUREMENT UNIT DATA\",\"url\":\"https://www.semanticscholar.org/paper/c28cadedb6b05ba3ed806be920f2730c5114633b\",\"venue\":\"2018 IEEE Global Conference on Signal and Information Processing (GlobalSIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"1843583\",\"name\":\"Zhefan Ye\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1109/CVPR.2015.7298625\",\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"08b1a3f8c6dc175b1e45818024def4ba311b21e6\",\"title\":\"Delving into egocentric actions\",\"url\":\"https://www.semanticscholar.org/paper/08b1a3f8c6dc175b1e45818024def4ba311b21e6\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1511.06783\",\"authors\":[{\"authorId\":\"8197937\",\"name\":\"K. Ohnishi\"},{\"authorId\":\"2551640\",\"name\":\"Atsushi Kanehira\"},{\"authorId\":\"2554424\",\"name\":\"Asako Kanezaki\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.1109/CVPR.2016.338\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"09b0ef3248ff8f1a05b8704a1b4cf64951575be9\",\"title\":\"Recognizing Activities of Daily Living with a Wrist-Mounted Camera\",\"url\":\"https://www.semanticscholar.org/paper/09b0ef3248ff8f1a05b8704a1b4cf64951575be9\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145676753\",\"name\":\"Z. Zhou\"},{\"authorId\":\"49867037\",\"name\":\"Y. Huang\"},{\"authorId\":null,\"name\":\"Wei Wang\"},{\"authorId\":null,\"name\":\"Liang Wang\"},{\"authorId\":\"143874948\",\"name\":\"T. Tan\"}],\"doi\":\"10.1109/CVPR.2017.717\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f1df5f74477658df45814743f2e605656e8ac16e\",\"title\":\"See the Forest for the Trees: Joint Spatial and Temporal Recurrent Neural Networks for Video-Based Person Re-identification\",\"url\":\"https://www.semanticscholar.org/paper/f1df5f74477658df45814743f2e605656e8ac16e\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2256574\",\"name\":\"K. Inoue\"},{\"authorId\":\"147558190\",\"name\":\"Misa Ono\"},{\"authorId\":\"2593208\",\"name\":\"M. Yoshioka\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2567ab620a9baef594a6b6a1753f0e2c96a8d3a5\",\"title\":\"Hand Detection in Egocentric Video and Investigation Towards Fine-grained Cooking Activities Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2567ab620a9baef594a6b6a1753f0e2c96a8d3a5\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21007367\",\"name\":\"K. T. Ma\"},{\"authorId\":\"35718875\",\"name\":\"L. Li\"},{\"authorId\":\"15450116\",\"name\":\"Peilun Dai\"},{\"authorId\":\"6516914\",\"name\":\"J. Lim\"},{\"authorId\":\"3329744\",\"name\":\"Chengyao Shen\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1109/ICIP.2017.8296927\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"92235c1c8d94fb3adbab40e51f94d583dd3d367f\",\"title\":\"Multi-layer linear model for top-down modulation of visual attention in natural egocentric vision\",\"url\":\"https://www.semanticscholar.org/paper/92235c1c8d94fb3adbab40e51f94d583dd3d367f\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":\"2009.07470\",\"authors\":[{\"authorId\":\"24057502\",\"name\":\"Sathyanarayanan N. Aakur\"},{\"authorId\":\"46836072\",\"name\":\"S. Kundu\"},{\"authorId\":\"1945699686\",\"name\":\"Nikhil Gunti\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"051dc6c1821721151bea555307c5a6bc72965a55\",\"title\":\"Knowledge Guided Learning: Towards Open Domain Egocentric Action Recognition with Zero Supervision\",\"url\":\"https://www.semanticscholar.org/paper/051dc6c1821721151bea555307c5a6bc72965a55\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48039353\",\"name\":\"Suriya Singh\"},{\"authorId\":\"145676233\",\"name\":\"Chetan Arora\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"}],\"doi\":\"10.1109/CVPR.2016.287\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"28efff48583dfbcf8e6e552f5720278db1ae0fe3\",\"title\":\"First Person Action Recognition Using Deep Learned Descriptors\",\"url\":\"https://www.semanticscholar.org/paper/28efff48583dfbcf8e6e552f5720278db1ae0fe3\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19212071\",\"name\":\"Fran\\u00e7ois De La Bourdonnaye\"},{\"authorId\":\"2343276\",\"name\":\"R. Setchi\"},{\"authorId\":\"1397287187\",\"name\":\"C. Zanni-Merk\"}],\"doi\":\"10.1016/J.IFACOL.2016.10.473\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e49efb623bd1450271d6e743d67cb32afe438084\",\"title\":\"Gaze trajectory prediction in the context of social robotics\",\"url\":\"https://www.semanticscholar.org/paper/e49efb623bd1450271d6e743d67cb32afe438084\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46366007\",\"name\":\"Jiaxin Wu\"},{\"authorId\":\"2812440\",\"name\":\"S. Zhong\"},{\"authorId\":\"80398011\",\"name\":\"Z. Ma\"},{\"authorId\":\"38821423\",\"name\":\"S. Heinen\"},{\"authorId\":\"145054089\",\"name\":\"J. Jiang\"}],\"doi\":\"10.1007/978-3-030-00767-6_27\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"09c9222c188866351c994fee3ac2a2beaa843cc8\",\"title\":\"Gaze Aware Deep Learning Model for Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/09c9222c188866351c994fee3ac2a2beaa843cc8\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2418491\",\"name\":\"M. Zhang\"},{\"authorId\":\"1397677751\",\"name\":\"Keng Teck Ma\"},{\"authorId\":\"9183286\",\"name\":\"Joo-Hwee Lim\"},{\"authorId\":\"153386875\",\"name\":\"Q. Zhao\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":\"10.1109/TPAMI.2018.2871688\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2f04a3d8eacfa22a299e0c5a7edcc69d0fdd5933\",\"title\":\"Anticipating Where People will Look Using Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/2f04a3d8eacfa22a299e0c5a7edcc69d0fdd5933\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144108036\",\"name\":\"S. Kumano\"},{\"authorId\":\"1713258\",\"name\":\"K. Otsuka\"},{\"authorId\":\"1736448\",\"name\":\"Ryo Ishii\"},{\"authorId\":\"1710918\",\"name\":\"J. Yamato\"}],\"doi\":\"10.1109/TMM.2016.2608002\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5481464c7058475da126796df43c6942ee12c11b\",\"title\":\"Collective First-Person Vision for Automatic Gaze Analysis in Multiparty Conversations\",\"url\":\"https://www.semanticscholar.org/paper/5481464c7058475da126796df43c6942ee12c11b\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145718481\",\"name\":\"Min Sun\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1685978\",\"name\":\"B. Taskar\"},{\"authorId\":\"1679223\",\"name\":\"S. Seitz\"}],\"doi\":\"10.1007/978-3-319-10584-0_31\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8150f267cd2852f27639d4d85c3a311360346c88\",\"title\":\"Salient Montages from Unconstrained Videos\",\"url\":\"https://www.semanticscholar.org/paper/8150f267cd2852f27639d4d85c3a311360346c88\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1605.03688\",\"authors\":[{\"authorId\":\"2238622\",\"name\":\"Minghuang Ma\"},{\"authorId\":\"2681569\",\"name\":\"Haoqi Fan\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"}],\"doi\":\"10.1109/CVPR.2016.209\",\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"444eba373d46c9f7d58cad74989ec9109b0d5219\",\"title\":\"Going Deeper into First-Person Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/444eba373d46c9f7d58cad74989ec9109b0d5219\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2421496\",\"name\":\"Tanik Saikh\"},{\"authorId\":\"2352983\",\"name\":\"Dipankar Das\"},{\"authorId\":\"1722399\",\"name\":\"Sivaji Bandyopadhyay\"}],\"doi\":\"10.1007/978-3-319-58130-9_12\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ca2c98eb97303e77d62e3e142d494d648c4682c8\",\"title\":\"Identifying and Pruning Features for Classifying Translated and Post-edited Gaze Durations\",\"url\":\"https://www.semanticscholar.org/paper/ca2c98eb97303e77d62e3e142d494d648c4682c8\",\"venue\":\"MIKE\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50077884\",\"name\":\"Zhiwen Yu\"},{\"authorId\":\"1396691772\",\"name\":\"C. Becker\"},{\"authorId\":\"144289197\",\"name\":\"Guoliang Xing\"}],\"doi\":\"10.1007/978-3-030-64243-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d6429665573eafcf401c697e4783a758694e0b6c\",\"title\":\"Green, Pervasive, and Cloud Computing: 15th International Conference, GPC 2020, Xi'an, China, November 13\\u201315, 2020, Proceedings\",\"url\":\"https://www.semanticscholar.org/paper/d6429665573eafcf401c697e4783a758694e0b6c\",\"venue\":\"GPC\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2533140\",\"name\":\"Min-Chun Tuan\"},{\"authorId\":\"35129740\",\"name\":\"Shih-Lun Chen\"},{\"authorId\":\"1896933\",\"name\":\"Ting-Lan Lin\"},{\"authorId\":\"49922778\",\"name\":\"H. Lee\"}],\"doi\":\"10.1109/PANPACIFIC.2016.7428419\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"95da96b44c31f5d5daf36e351d0ec3ff99fbc066\",\"title\":\"An efficient micro control unit VLSI design for wearable electronics and sensor networks\",\"url\":\"https://www.semanticscholar.org/paper/95da96b44c31f5d5daf36e351d0ec3ff99fbc066\",\"venue\":\"2016 Pan Pacific Microelectronics Symposium (Pan Pacific)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1995028\",\"name\":\"K. Suma\"},{\"authorId\":\"71879392\",\"name\":\"G. Aditya\"},{\"authorId\":\"34356161\",\"name\":\"Snehasis Mukherjee\"}],\"doi\":\"10.1145/3293353.3293362\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"dc5e3095ce86de685418fb7ca2062eab21214801\",\"title\":\"Activity Recognition in Egocentric Videos Using Bag of Key Action Units\",\"url\":\"https://www.semanticscholar.org/paper/dc5e3095ce86de685418fb7ca2062eab21214801\",\"venue\":\"ICVGIP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46867171\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1109/WACV.2017.21\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"67f49376d610b8e11505d455cdabb83811aaf431\",\"title\":\"First-Person Action Decomposition and Zero-Shot Learning\",\"url\":\"https://www.semanticscholar.org/paper/67f49376d610b8e11505d455cdabb83811aaf431\",\"venue\":\"2017 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1793739\",\"name\":\"David J. Fleet\"},{\"authorId\":\"1758039\",\"name\":\"T. Pajdla\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"}],\"doi\":\"10.1007/978-3-319-10602-1\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"18101bfc08381ddea8fd944a3300dc8cffe34e63\",\"title\":\"Computer Vision \\u2013 ECCV 2014\",\"url\":\"https://www.semanticscholar.org/paper/18101bfc08381ddea8fd944a3300dc8cffe34e63\",\"venue\":\"Lecture Notes in Computer Science\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10978611\",\"name\":\"Akanksha Saran\"},{\"authorId\":\"41175924\",\"name\":\"Srinjoy Majumdar\"},{\"authorId\":\"1682788\",\"name\":\"A. Thomaz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fcd61f12ca9c21e5bb4d216ad82c6a51ddd31353\",\"title\":\"Real-time Human Gaze following for Human-Robot Interaction\",\"url\":\"https://www.semanticscholar.org/paper/fcd61f12ca9c21e5bb4d216ad82c6a51ddd31353\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143874453\",\"name\":\"Evonne Ng\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"2480239\",\"name\":\"Donglai Xiang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"918b67624d6f579567b7a191d01375339dd9298f\",\"title\":\"You 2 Me : Inferring Body Pose in Egocentric Video via First and Second Person Interactions by Evonne\",\"url\":\"https://www.semanticscholar.org/paper/918b67624d6f579567b7a191d01375339dd9298f\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2197410\",\"name\":\"S. Jayaraman\"},{\"authorId\":\"2836466\",\"name\":\"L. Smith\"}],\"doi\":\"10.1016/j.visres.2018.05.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b62da47e43e85baf5e6016b8bf22cf6f2baf2f18\",\"title\":\"Faces in early visual environments are persistent not just frequent\",\"url\":\"https://www.semanticscholar.org/paper/b62da47e43e85baf5e6016b8bf22cf6f2baf2f18\",\"venue\":\"Vision Research\",\"year\":2018},{\"arxivId\":\"1505.04803\",\"authors\":[{\"authorId\":\"144756076\",\"name\":\"Y. Lee\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1007/s11263-014-0794-5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ec3d9f304f173362007f5c2e3c6c616d24b85c9f\",\"title\":\"Predicting Important Objects for Egocentric Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/ec3d9f304f173362007f5c2e3c6c616d24b85c9f\",\"venue\":\"International Journal of Computer Vision\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39707211\",\"name\":\"Karan Sikka\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4ca95f79a40e2a2851b3c66dd5e326203b8753cd\",\"title\":\"Latent Dynamic Space-Time Volumes for Predicting Human Facial Behavior in Videos\",\"url\":\"https://www.semanticscholar.org/paper/4ca95f79a40e2a2851b3c66dd5e326203b8753cd\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2421496\",\"name\":\"Tanik Saikh\"},{\"authorId\":\"35313721\",\"name\":\"S. Bangalore\"},{\"authorId\":\"93671213\",\"name\":\"M. Carl\"},{\"authorId\":\"1722399\",\"name\":\"Sivaji Bandyopadhyay\"}],\"doi\":\"10.1109/CCIP.2015.7100708\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"64da72829e4098edb4e94a6cfcf7a8ae0f2bb656\",\"title\":\"Predicting source gaze fixation duration: A machine learning approach\",\"url\":\"https://www.semanticscholar.org/paper/64da72829e4098edb4e94a6cfcf7a8ae0f2bb656\",\"venue\":\"2015 International Conference on Cognitive Computing and Information Processing(CCIP)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2926663\",\"name\":\"Yair Poleg\"},{\"authorId\":\"145676235\",\"name\":\"C. Arora\"},{\"authorId\":\"144406261\",\"name\":\"Shmuel Peleg\"}],\"doi\":\"10.1109/CVPR.2014.325\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"579c88f5fd1b1e2e84c7659b6ed589aeee06035f\",\"title\":\"Temporal Segmentation of Egocentric Videos\",\"url\":\"https://www.semanticscholar.org/paper/579c88f5fd1b1e2e84c7659b6ed589aeee06035f\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2853924\",\"name\":\"Deepak Akkil\"},{\"authorId\":\"1697649\",\"name\":\"Poika Isokoski\"}],\"doi\":\"10.1145/2858036.2858127\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"97f98b3ad457acd6572241b39e555c79c11246b3\",\"title\":\"Gaze Augmentation in Egocentric Video Improves Awareness of Intention\",\"url\":\"https://www.semanticscholar.org/paper/97f98b3ad457acd6572241b39e555c79c11246b3\",\"venue\":\"CHI\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3378756\",\"name\":\"H. Inoue\"},{\"authorId\":\"2639141\",\"name\":\"T. Hirayama\"},{\"authorId\":\"1747218\",\"name\":\"Keisuke Doman\"},{\"authorId\":\"1770200\",\"name\":\"Y. Kawanishi\"},{\"authorId\":\"1679187\",\"name\":\"I. Ide\"},{\"authorId\":\"1699693\",\"name\":\"D. Deguchi\"},{\"authorId\":\"82910116\",\"name\":\"H. Murase\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"784e8b95d879d43a2625d423a3a4dbcdc0489b46\",\"title\":\"Cooking Operation Classification Based on Analysis of Eye Movement Patterns\",\"url\":\"https://www.semanticscholar.org/paper/784e8b95d879d43a2625d423a3a4dbcdc0489b46\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1907.09382\",\"authors\":[{\"authorId\":\"145254119\",\"name\":\"Huseyin Coskun\"},{\"authorId\":\"48151137\",\"name\":\"Z. Zia\"},{\"authorId\":\"39307390\",\"name\":\"Bugra Tekin\"},{\"authorId\":\"2988774\",\"name\":\"Federica Bogo\"},{\"authorId\":\"145587209\",\"name\":\"N. Navab\"},{\"authorId\":\"2266326\",\"name\":\"Federico Tombari\"},{\"authorId\":\"1733393\",\"name\":\"H. Sawhney\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"18cb8c24fae3186487b14fdb28b1b2617057198f\",\"title\":\"Domain-Specific Priors and Meta Learning for Low-shot First-Person Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/18cb8c24fae3186487b14fdb28b1b2617057198f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144752314\",\"name\":\"Bo Xiong\"}],\"doi\":\"10.26153/TSW/5847\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4b64bcb39e979cf6eaeb7739af468b0a08e6250d\",\"title\":\"Learning to compose photos and videos from passive cameras\",\"url\":\"https://www.semanticscholar.org/paper/4b64bcb39e979cf6eaeb7739af468b0a08e6250d\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145279153\",\"name\":\"S. Huang\"},{\"authorId\":\"145472490\",\"name\":\"Weiqiang Wang\"},{\"authorId\":\"144106250\",\"name\":\"K. Lu\"}],\"doi\":\"10.1109/ICPR.2016.7899706\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cd577e2a3819b24674a82328acc4869608d03b85\",\"title\":\"Egocentric hand detection via region growth\",\"url\":\"https://www.semanticscholar.org/paper/cd577e2a3819b24674a82328acc4869608d03b85\",\"venue\":\"2016 23rd International Conference on Pattern Recognition (ICPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50024334\",\"name\":\"Y. Li\"},{\"authorId\":\"1896187\",\"name\":\"Zhenni Li\"},{\"authorId\":\"2413210\",\"name\":\"Atsunori Kanemura\"}],\"doi\":\"10.1109/ACCESS.2019.2908010\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a416cd77a30dd2dbfc8ba9b5351bced43f7b35aa\",\"title\":\"An  $\\\\ell_{1/2}$ -Norm Regularizer-Based Sparse Coding Framework for Gaze Prediction in First-Person Videos\",\"url\":\"https://www.semanticscholar.org/paper/a416cd77a30dd2dbfc8ba9b5351bced43f7b35aa\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6937593\",\"name\":\"Shih-Han Chou\"},{\"authorId\":\"49070447\",\"name\":\"Y. Chen\"},{\"authorId\":\"32970572\",\"name\":\"Kuo-Hao Zeng\"},{\"authorId\":\"10712411\",\"name\":\"Hou-Ning Hu\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f54252274514e8eb54adb6b9af7594f6189ec63a\",\"title\":\"Self-view Grounding Given a Narrated 360\\u00b0 Video\",\"url\":\"https://www.semanticscholar.org/paper/f54252274514e8eb54adb6b9af7594f6189ec63a\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1901.01874\",\"authors\":[{\"authorId\":\"48355461\",\"name\":\"Yifei Huang\"},{\"authorId\":\"46947776\",\"name\":\"Zhenqiang Li\"},{\"authorId\":\"3172280\",\"name\":\"Minjie Cai\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1109/TIP.2020.3007841\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"78d95b989b807f28ef624318e3cb583ca1d73a3e\",\"title\":\"Mutual Context Network for Jointly Estimating Egocentric Gaze and Action\",\"url\":\"https://www.semanticscholar.org/paper/78d95b989b807f28ef624318e3cb583ca1d73a3e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40977902\",\"name\":\"Seita Kayukawa\"},{\"authorId\":\"34575696\",\"name\":\"Keita Higuchi\"},{\"authorId\":\"1899753\",\"name\":\"Ryo Yonetani\"},{\"authorId\":\"144086483\",\"name\":\"M. Nakamura\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"},{\"authorId\":\"1731030\",\"name\":\"S. Morishima\"}],\"doi\":\"10.1145/3170427.3186501\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"94d177db3f198a3571576e562b4d3d9e816eb3cf\",\"title\":\"Dynamic Object Scanning: Object-Based Elastic Timeline for Quickly Browsing First-Person Videos\",\"url\":\"https://www.semanticscholar.org/paper/94d177db3f198a3571576e562b4d3d9e816eb3cf\",\"venue\":\"CHI Extended Abstracts\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153823664\",\"name\":\"K. Nakamura\"},{\"authorId\":\"34149749\",\"name\":\"Serena Yeung\"},{\"authorId\":\"3304525\",\"name\":\"Alexandre Alahi\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2017.721\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"36e093e2c6142017e61c37200e915fd08d2456a1\",\"title\":\"Jointly Learning Energy Expenditures and Activities Using Egocentric Multimodal Signals\",\"url\":\"https://www.semanticscholar.org/paper/36e093e2c6142017e61c37200e915fd08d2456a1\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1504.07469\",\"authors\":[{\"authorId\":\"2926663\",\"name\":\"Yair Poleg\"},{\"authorId\":\"2077454\",\"name\":\"A. Ephrat\"},{\"authorId\":\"144406261\",\"name\":\"Shmuel Peleg\"},{\"authorId\":\"145676235\",\"name\":\"C. Arora\"}],\"doi\":\"10.1109/WACV.2016.7477708\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6f2b075d527e7d3b29219e5955f294f539c4764f\",\"title\":\"Compact CNN for indexing egocentric videos\",\"url\":\"https://www.semanticscholar.org/paper/6f2b075d527e7d3b29219e5955f294f539c4764f\",\"venue\":\"2016 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145708707\",\"name\":\"P. Wei\"},{\"authorId\":\"46179714\",\"name\":\"Y. Liu\"},{\"authorId\":\"1844358\",\"name\":\"Tianmin Shu\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/CVPR.2018.00711\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"07098ec7f9b66ddeb21314fd3630a9e45decdd4e\",\"title\":\"Where and Why are They Looking? Jointly Inferring Human Attention and Intentions in Complex Tasks\",\"url\":\"https://www.semanticscholar.org/paper/07098ec7f9b66ddeb21314fd3630a9e45decdd4e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50398746\",\"name\":\"B. Xiong\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1007/978-3-319-10602-1_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aea8047ec01c18fd3f279e9e7e55822cbd4b4d46\",\"title\":\"Detecting Snap Points in Egocentric Video with a Web Photo Prior\",\"url\":\"https://www.semanticscholar.org/paper/aea8047ec01c18fd3f279e9e7e55822cbd4b4d46\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2798750\",\"name\":\"Sven Bambach\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"de2e8127105a37ff1f59be13a010ab0d3f4fa650\",\"title\":\"Analyzing hands with first-person computer vision\",\"url\":\"https://www.semanticscholar.org/paper/de2e8127105a37ff1f59be13a010ab0d3f4fa650\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2599451\",\"name\":\"Shervin Ardeshir\"},{\"authorId\":\"3177797\",\"name\":\"Ali Borji\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a1099173f9df4173f8f68ecd00ce780ac9ef2df4\",\"title\":\"Egocentric Meets Surveillance\",\"url\":\"https://www.semanticscholar.org/paper/a1099173f9df4173f8f68ecd00ce780ac9ef2df4\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50024839\",\"name\":\"Yujie Li\"},{\"authorId\":\"2413210\",\"name\":\"Atsunori Kanemura\"},{\"authorId\":\"7142317\",\"name\":\"Hideki Asoh\"},{\"authorId\":\"2151048\",\"name\":\"Taiki Miyanishi\"},{\"authorId\":\"1716788\",\"name\":\"M. Kawanabe\"}],\"doi\":\"10.1109/ICASSP.2018.8462640\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"463fad48fae29f1ecccb13680638f4475342ab9c\",\"title\":\"A Sparse Coding Framework for Gaze Prediction in Egocentric Video\",\"url\":\"https://www.semanticscholar.org/paper/463fad48fae29f1ecccb13680638f4475342ab9c\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":\"1803.09125\",\"authors\":[{\"authorId\":\"48355461\",\"name\":\"Yifei Huang\"},{\"authorId\":\"3172280\",\"name\":\"Minjie Cai\"},{\"authorId\":\"46947776\",\"name\":\"Zhenqiang Li\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1007/978-3-030-01225-0_46\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7e236d33dce5d30348aeb494e491a13468133b4e\",\"title\":\"Predicting Gaze in Egocentric Video by Learning Task-dependent Attention Transition\",\"url\":\"https://www.semanticscholar.org/paper/7e236d33dce5d30348aeb494e491a13468133b4e\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39872583\",\"name\":\"M. Wang\"},{\"authorId\":\"2206888\",\"name\":\"Changzhi Luo\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"143625300\",\"name\":\"J. Yuan\"},{\"authorId\":\"49606802\",\"name\":\"Jianfeng Wang\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"}],\"doi\":\"10.1109/TCSVT.2017.2716819\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5b300b85e10aa312dfe31d8064d86f764d0aaa68\",\"title\":\"First-Person Daily Activity Recognition With Manipulated Object Proposals and Non-Linear Feature Fusion\",\"url\":\"https://www.semanticscholar.org/paper/5b300b85e10aa312dfe31d8064d86f764d0aaa68\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1806522\",\"name\":\"H. Park\"},{\"authorId\":\"46865129\",\"name\":\"J. Shi\"}],\"doi\":\"10.1109/CVPR.2015.7299110\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4571986c2629319dd66595e95b4e891355ee4377\",\"title\":\"Social saliency prediction\",\"url\":\"https://www.semanticscholar.org/paper/4571986c2629319dd66595e95b4e891355ee4377\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1904.09882\",\"authors\":[{\"authorId\":\"143874453\",\"name\":\"Evonne Ng\"},{\"authorId\":\"2480239\",\"name\":\"Donglai Xiang\"},{\"authorId\":\"7996087\",\"name\":\"Hanbyul Joo\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/cvpr42600.2020.00991\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fe87da6f364417d87ecaf525e563851718ffdb07\",\"title\":\"You2Me: Inferring Body Pose in Egocentric Video via First and Second Person Interactions\",\"url\":\"https://www.semanticscholar.org/paper/fe87da6f364417d87ecaf525e563851718ffdb07\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48183487\",\"name\":\"S. Samiei\"},{\"authorId\":\"134598664\",\"name\":\"Pejman Rasti\"},{\"authorId\":\"145631453\",\"name\":\"P. Richard\"},{\"authorId\":\"3395751\",\"name\":\"G. Galopin\"},{\"authorId\":\"153766356\",\"name\":\"D. Rousseau\"}],\"doi\":\"10.3390/s20154173\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c2195df91a37dc03f682ecb12ebaa5db7f77fc54\",\"title\":\"Toward Joint Acquisition-Annotation of Images with Egocentric Devices for a Lower-Cost Machine Learning Application to Apple Detection\",\"url\":\"https://www.semanticscholar.org/paper/c2195df91a37dc03f682ecb12ebaa5db7f77fc54\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"1603.04908\",\"authors\":[{\"authorId\":\"3313330\",\"name\":\"Gedas Bertasius\"},{\"authorId\":\"1806522\",\"name\":\"H. Park\"},{\"authorId\":\"2251428\",\"name\":\"S. Yu\"},{\"authorId\":\"46865129\",\"name\":\"J. Shi\"}],\"doi\":\"10.15607/RSS.2017.XIII.012\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6021af236342c11c44f681d2aa21b0b46756236a\",\"title\":\"First Person Action-Object Detection with EgoNet\",\"url\":\"https://www.semanticscholar.org/paper/6021af236342c11c44f681d2aa21b0b46756236a\",\"venue\":\"Robotics: Science and Systems\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145089978\",\"name\":\"D. Damen\"},{\"authorId\":\"3067867\",\"name\":\"T. Leelasawassuk\"},{\"authorId\":\"2356868\",\"name\":\"Osian Haines\"},{\"authorId\":\"3336943\",\"name\":\"A. Calway\"},{\"authorId\":\"1398236231\",\"name\":\"W. Mayol-Cuevas\"}],\"doi\":\"10.5244/C.28.30\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6d37a63088d0f296b3dc5f587944cd3c65d1e52e\",\"title\":\"You-Do, I-Learn: Discovering Task Relevant Objects and their Modes of Interaction from Multi-User Egocentric Video\",\"url\":\"https://www.semanticscholar.org/paper/6d37a63088d0f296b3dc5f587944cd3c65d1e52e\",\"venue\":\"BMVC\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36549981\",\"name\":\"Cheng-Sheng Chan\"},{\"authorId\":\"50357993\",\"name\":\"Shou-Zhong Chen\"},{\"authorId\":\"1717126\",\"name\":\"Pei-Xuan Xie\"},{\"authorId\":\"145982994\",\"name\":\"Chiung-Chih Chang\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":\"10.1007/978-3-319-46493-0_31\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a985a3e0fb59493356b488ae9aa7cd1c71ee1c7c\",\"title\":\"Recognition from Hand Cameras: A Revisit with Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/a985a3e0fb59493356b488ae9aa7cd1c71ee1c7c\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3194727\",\"name\":\"Andreas Bulling\"},{\"authorId\":\"2974034\",\"name\":\"O. Cakmakci\"},{\"authorId\":\"143973307\",\"name\":\"K. Kunze\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.4230/DagRep.6.1.160\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"29bd05b3d3977043706400ec00efae1fda88bc43\",\"title\":\"Eyewear Computing - Augmenting the Human with Head-mounted Wearable Assistants (Dagstuhl Seminar 16042)\",\"url\":\"https://www.semanticscholar.org/paper/29bd05b3d3977043706400ec00efae1fda88bc43\",\"venue\":\"Dagstuhl Reports\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"46331912\",\"name\":\"M. Liu\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1007/978-3-030-01228-1_38\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fa1723b216b1f41b085b62b450b7b0bd9f2fd281\",\"title\":\"In the Eye of Beholder: Joint Learning of Gaze and Actions in First Person Video\",\"url\":\"https://www.semanticscholar.org/paper/fa1723b216b1f41b085b62b450b7b0bd9f2fd281\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144489175\",\"name\":\"Y. Zhou\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"48043335\",\"name\":\"R. Hong\"},{\"authorId\":\"1795291\",\"name\":\"X. Yang\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/CVPR.2016.210\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7de1d463fef3c63cb228f5b4a6a72e62f66630e6\",\"title\":\"Cascaded Interactional Targeting Network for Egocentric Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/7de1d463fef3c63cb228f5b4a6a72e62f66630e6\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1802223\",\"name\":\"Ikuhisa Mitsugami\"},{\"authorId\":\"32622468\",\"name\":\"Y. Okinaka\"},{\"authorId\":\"1715071\",\"name\":\"Y. Yagi\"}],\"doi\":\"10.1109/WACVW.2017.15\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c5ba403eacb53105079092ae92bfb1049ce169da\",\"title\":\"Gaze Estimation Based on Eyeball-Head Dynamics\",\"url\":\"https://www.semanticscholar.org/paper/c5ba403eacb53105079092ae92bfb1049ce169da\",\"venue\":\"2017 IEEE Winter Applications of Computer Vision Workshops (WACVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49901750\",\"name\":\"Guang Chen\"}],\"doi\":\"10.32469/10355/44157\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f3f7df3315fcb8d651efaa85ce59b82c4f46cc08\",\"title\":\"Object detection for big data\",\"url\":\"https://www.semanticscholar.org/paper/f3f7df3315fcb8d651efaa85ce59b82c4f46cc08\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3172280\",\"name\":\"Minjie Cai\"},{\"authorId\":\"145053996\",\"name\":\"Feng Lu\"},{\"authorId\":\"35350470\",\"name\":\"Yue Gao\"}],\"doi\":\"10.1109/TCYB.2018.2806381\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2565c9ea9edf4275cba0679c3ef6a8f3bea8aa52\",\"title\":\"Desktop Action Recognition From First-Person Point-of-View\",\"url\":\"https://www.semanticscholar.org/paper/2565c9ea9edf4275cba0679c3ef6a8f3bea8aa52\",\"venue\":\"IEEE Transactions on Cybernetics\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144180678\",\"name\":\"Minlong Lu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"972b1d8842df8ad06c50a33782af1cfdc9ffd411\",\"title\":\"Action analysis and control strategy for rat robot automatic navigation\",\"url\":\"https://www.semanticscholar.org/paper/972b1d8842df8ad06c50a33782af1cfdc9ffd411\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1476813805\",\"name\":\"M. Al-Naser\"},{\"authorId\":\"29005173\",\"name\":\"S. Siddiqui\"},{\"authorId\":\"151425311\",\"name\":\"Hiroki Ohashi\"},{\"authorId\":\"144723875\",\"name\":\"S. Ahmed\"},{\"authorId\":\"1476817066\",\"name\":\"Nakamura Katsuyki\"},{\"authorId\":\"35920106\",\"name\":\"T. Sato\"},{\"authorId\":\"145279674\",\"name\":\"A. Dengel\"}],\"doi\":\"10.1109/DICTA47822.2019.8945893\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"697f3ccd584b7be126cbea9ced53d5b5e00372f1\",\"title\":\"OGaze: Gaze Prediction in Egocentric Videos for Attentional Object Selection\",\"url\":\"https://www.semanticscholar.org/paper/697f3ccd584b7be126cbea9ced53d5b5e00372f1\",\"venue\":\"2019 Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"80519596\",\"name\":\"A. Betancourt\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"eef4ac6942c76651d204116a221994baa5808ec8\",\"title\":\"EgoHands : a unified framework for hand-based methods in first person vision videos\",\"url\":\"https://www.semanticscholar.org/paper/eef4ac6942c76651d204116a221994baa5808ec8\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144348441\",\"name\":\"Dinesh Jayaraman\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2018.00135\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"be6712aba5b1d35c1d4062664fbd6bcdad06c71f\",\"title\":\"Learning to Look Around: Intelligently Exploring Unseen Environments for Unknown Tasks\",\"url\":\"https://www.semanticscholar.org/paper/be6712aba5b1d35c1d4062664fbd6bcdad06c71f\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1707.06436\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":null,\"name\":\"Yun He\"},{\"authorId\":\"9935341\",\"name\":\"S. Ueta\"},{\"authorId\":\"5014206\",\"name\":\"T. Suzuki\"},{\"authorId\":\"49897653\",\"name\":\"K. Abe\"},{\"authorId\":\"2554424\",\"name\":\"Asako Kanezaki\"},{\"authorId\":\"49133490\",\"name\":\"Shinichiro Morita\"},{\"authorId\":\"22219521\",\"name\":\"Toshiyuki Yabe\"},{\"authorId\":\"50544018\",\"name\":\"Yoshihiro Kanehara\"},{\"authorId\":\"22174281\",\"name\":\"Hiroya Yatsuyanagi\"},{\"authorId\":\"1692565\",\"name\":\"S. Maruyama\"},{\"authorId\":\"10756539\",\"name\":\"Ryousuke Takasawa\"},{\"authorId\":\"3217653\",\"name\":\"Masataka Fuchida\"},{\"authorId\":\"2642022\",\"name\":\"Y. Miyashita\"},{\"authorId\":\"34935749\",\"name\":\"Kazushige Okayasu\"},{\"authorId\":\"20505300\",\"name\":\"Yuta Matsuzaki\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"title\":\"cvpaper.challenge in 2016: Futuristic Computer Vision through 1, 600 Papers Survey\",\"url\":\"https://www.semanticscholar.org/paper/8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46250215\",\"name\":\"Yen-Chia Chiu\"},{\"authorId\":\"14837960\",\"name\":\"Li-Yi Liu\"},{\"authorId\":\"40167628\",\"name\":\"Tsaipei Wang\"}],\"doi\":\"10.1007/s11042-017-4910-8\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c530d2e2939bd195ad321d45fb43ace38dea779b\",\"title\":\"Automatic segmentation and summarization for videos taken with smart glasses\",\"url\":\"https://www.semanticscholar.org/paper/c530d2e2939bd195ad321d45fb43ace38dea779b\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2017},{\"arxivId\":\"1412.6505\",\"authors\":[{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"},{\"authorId\":\"1904850\",\"name\":\"B. Rothrock\"},{\"authorId\":\"1782162\",\"name\":\"L. Matthies\"}],\"doi\":\"10.1109/CVPR.2015.7298691\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0229829e9a1eed5769a2b5eccddcaa7cd9460b92\",\"title\":\"Pooled motion features for first-person videos\",\"url\":\"https://www.semanticscholar.org/paper/0229829e9a1eed5769a2b5eccddcaa7cd9460b92\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2197410\",\"name\":\"S. Jayaraman\"},{\"authorId\":\"47350509\",\"name\":\"Caitlin Fausey\"},{\"authorId\":\"2836466\",\"name\":\"L. Smith\"}],\"doi\":\"10.1037/dev0000230\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"881d7327cef3e2800a1425d0bb865d90a63a03c2\",\"title\":\"Why are Faces Denser in the Visual Experiences of Younger Than Older Infants?\",\"url\":\"https://www.semanticscholar.org/paper/881d7327cef3e2800a1425d0bb865d90a63a03c2\",\"venue\":\"Developmental psychology\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9764377\",\"name\":\"Xuanhan Wang\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"34798935\",\"name\":\"Xiantong Zhen\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1016/j.neucom.2017.08.063\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c5e8046c5393847439232c94846b7556ad201ba4\",\"title\":\"Deep appearance and motion learning for egocentric activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/c5e8046c5393847439232c94846b7556ad201ba4\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3172280\",\"name\":\"Minjie Cai\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1109/THMS.2017.2681423\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1b4af2d16e2578f0c00735c78aa262200625293e\",\"title\":\"An Ego-Vision System for Hand Grasp Analysis\",\"url\":\"https://www.semanticscholar.org/paper/1b4af2d16e2578f0c00735c78aa262200625293e\",\"venue\":\"IEEE Transactions on Human-Machine Systems\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2418491\",\"name\":\"M. Zhang\"},{\"authorId\":\"21007367\",\"name\":\"K. T. Ma\"},{\"authorId\":\"153239355\",\"name\":\"J. H. Lim\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":\"10.1109/CVPR.2017.377\",\"intent\":[\"methodology\",\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"f95e349489aa48fc57494aab101d58c496cc35f5\",\"title\":\"Deep Future Gaze: Gaze Anticipation on Egocentric Videos Using Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/f95e349489aa48fc57494aab101d58c496cc35f5\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1708.00908\",\"authors\":[{\"authorId\":\"39832600\",\"name\":\"E. Chong\"},{\"authorId\":\"2059400\",\"name\":\"C. Nitschke\"},{\"authorId\":\"23276966\",\"name\":\"A. Nakazawa\"},{\"authorId\":\"2244531\",\"name\":\"Agata Rozga\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a10acc429d5828ee70117c3e828e7eea114fb342\",\"title\":\"Noninvasive Corneal Image-Based Gaze Measurement System\",\"url\":\"https://www.semanticscholar.org/paper/a10acc429d5828ee70117c3e828e7eea114fb342\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2418491\",\"name\":\"M. Zhang\"},{\"authorId\":\"21007367\",\"name\":\"K. T. Ma\"},{\"authorId\":\"153239355\",\"name\":\"J. H. Lim\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1109/ICIP.2017.8296977\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b47d27d29a178c92a64c204909cec7affbff9f9b\",\"title\":\"Foveated neural network: Gaze prediction on egocentric videos\",\"url\":\"https://www.semanticscholar.org/paper/b47d27d29a178c92a64c204909cec7affbff9f9b\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":\"2008.07961\",\"authors\":[{\"authorId\":\"48269537\",\"name\":\"Ye Zhu\"},{\"authorId\":\"49483094\",\"name\":\"Yan Yan\"},{\"authorId\":\"1778350\",\"name\":\"Oleg V. Komogortsev\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"af3687ebd3461a48a76eb49c0c161957390bc34f\",\"title\":\"Hierarchical HMM for Eye Movement Classification\",\"url\":\"https://www.semanticscholar.org/paper/af3687ebd3461a48a76eb49c0c161957390bc34f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1711.03677\",\"authors\":[{\"authorId\":\"145279153\",\"name\":\"S. Huang\"},{\"authorId\":\"145472490\",\"name\":\"Weiqiang Wang\"},{\"authorId\":\"2548483\",\"name\":\"Shengfeng He\"},{\"authorId\":\"1726262\",\"name\":\"R. Lau\"}],\"doi\":\"10.1145/3152129\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"855a46ffdf244fe70698f10c802af2bdbde25736\",\"title\":\"Egocentric Hand Detection Via Dynamic Region Growing\",\"url\":\"https://www.semanticscholar.org/paper/855a46ffdf244fe70698f10c802af2bdbde25736\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3378756\",\"name\":\"H. Inoue\"},{\"authorId\":\"2639141\",\"name\":\"T. Hirayama\"},{\"authorId\":\"1679187\",\"name\":\"I. Ide\"},{\"authorId\":\"47233528\",\"name\":\"D. Deguchi\"},{\"authorId\":\"82910116\",\"name\":\"H. Murase\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b9d66850bd09187dea9f10e60c3e93c8d9d149c0\",\"title\":\"Toward understanding cooking activities based on gaze analysis\",\"url\":\"https://www.semanticscholar.org/paper/b9d66850bd09187dea9f10e60c3e93c8d9d149c0\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1843583\",\"name\":\"Zhefan Ye\"},{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"47909637\",\"name\":\"Yun Liu\"},{\"authorId\":\"39936376\",\"name\":\"C. Bridges\"},{\"authorId\":\"2244531\",\"name\":\"Agata Rozga\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1109/FG.2015.7163095\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d385f4a1c7153b061b414ef361e72c0a5da7b0b7\",\"title\":\"Detecting bids for eye contact using a wearable camera\",\"url\":\"https://www.semanticscholar.org/paper/d385f4a1c7153b061b414ef361e72c0a5da7b0b7\",\"venue\":\"2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145086911\",\"name\":\"A. Betancourt\"},{\"authorId\":\"2322579\",\"name\":\"Pietro Morerio\"},{\"authorId\":\"9587913\",\"name\":\"C. Regazzoni\"},{\"authorId\":\"1736974\",\"name\":\"M. Rauterberg\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"990bf0171deae7f788f4867c155a276fca5c891a\",\"title\":\"An Overview of First Person Vision and Egocentric Video Analysis for Personal Mobile Wearable Devices\",\"url\":\"https://www.semanticscholar.org/paper/990bf0171deae7f788f4867c155a276fca5c891a\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1808039\",\"name\":\"Emrah Basaran\"},{\"authorId\":\"10428247\",\"name\":\"Yonatan Tariku Tesfaye\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1c838b9f37d1b4633e2addfbca2e51df0e24b0e3\",\"title\":\"Person Re-identification in Videos Acquired by Mobile Devices with First-Person Point-of-View\",\"url\":\"https://www.semanticscholar.org/paper/1c838b9f37d1b4633e2addfbca2e51df0e24b0e3\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2001.04583\",\"authors\":[{\"authorId\":\"38661780\",\"name\":\"Tushar Nagarajan\"},{\"authorId\":\"48513679\",\"name\":\"Yanghao Li\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR42600.2020.00024\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7d8f6dd70e8c15105e52b5ac4666db7085689939\",\"title\":\"Ego-Topo: Environment Affordances From Egocentric Video\",\"url\":\"https://www.semanticscholar.org/paper/7d8f6dd70e8c15105e52b5ac4666db7085689939\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1704.00098\",\"authors\":[{\"authorId\":\"145022261\",\"name\":\"Shan Su\"},{\"authorId\":\"46865129\",\"name\":\"J. Shi\"},{\"authorId\":\"1806522\",\"name\":\"H. Park\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"603dee8661aa9bf0d7af6c61fe5fa2e85227f166\",\"title\":\"Customizing First Person Image Through Desired Actions\",\"url\":\"https://www.semanticscholar.org/paper/603dee8661aa9bf0d7af6c61fe5fa2e85227f166\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2418061\",\"name\":\"J. Vickers\"},{\"authorId\":\"3005766\",\"name\":\"J. Causer\"},{\"authorId\":\"1389965396\",\"name\":\"Dan Vanhooren\"}],\"doi\":\"10.3389/fpsyg.2019.02424\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e522d74d4264c5751e1a4b64b77bff3d26d761e6\",\"title\":\"The Role of Quiet Eye Timing and Location in the Basketball Three-Point Shot: A New Research Paradigm\",\"url\":\"https://www.semanticscholar.org/paper/e522d74d4264c5751e1a4b64b77bff3d26d761e6\",\"venue\":\"Front. Psychol.\",\"year\":2019},{\"arxivId\":\"1909.08150\",\"authors\":[{\"authorId\":\"51128743\",\"name\":\"Srikanth Malla\"},{\"authorId\":\"37435569\",\"name\":\"Chiho Choi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1ee3537572b04bd3b09c9cda832f89e41ddeaf35\",\"title\":\"NEMO: Future Object Localization Using Noisy Ego Priors\",\"url\":\"https://www.semanticscholar.org/paper/1ee3537572b04bd3b09c9cda832f89e41ddeaf35\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1704.06340\",\"authors\":[{\"authorId\":\"2047692\",\"name\":\"Chenyou Fan\"},{\"authorId\":\"2813082\",\"name\":\"J. Lee\"},{\"authorId\":\"143847408\",\"name\":\"Mingze Xu\"},{\"authorId\":\"50339742\",\"name\":\"Krishna Kumar Singh\"},{\"authorId\":\"144756076\",\"name\":\"Y. Lee\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1109/CVPR.2017.503\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fab723592e19acfcceb7420d688a3de76e911426\",\"title\":\"Identifying First-Person Camera Wearers in Third-Person Videos\",\"url\":\"https://www.semanticscholar.org/paper/fab723592e19acfcceb7420d688a3de76e911426\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1882027\",\"name\":\"Henny Admoni\"},{\"authorId\":\"1752197\",\"name\":\"S. Srinivasa\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"690a95f65038492a8385fe2663d187c8f7b7e9c4\",\"title\":\"Predicting User Intent Through Eye Gaze for Shared Autonomy\",\"url\":\"https://www.semanticscholar.org/paper/690a95f65038492a8385fe2663d187c8f7b7e9c4\",\"venue\":\"AAAI Fall Symposia\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153652147\",\"name\":\"Jagannath Malik\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9ffc9a0da2a9877ab793b9d0f2f3a9eafd67cc29\",\"title\":\"Test-Time Training for Improved Object Affordance Prediction\",\"url\":\"https://www.semanticscholar.org/paper/9ffc9a0da2a9877ab793b9d0f2f3a9eafd67cc29\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410010039\",\"name\":\"Hao Zhao\"},{\"authorId\":\"123554573\",\"name\":\"M. Lu\"},{\"authorId\":\"1405606408\",\"name\":\"Anbang Yao\"},{\"authorId\":\"6060281\",\"name\":\"Y. Chen\"},{\"authorId\":\"48571207\",\"name\":\"L. Zhang\"}],\"doi\":\"10.1007/s11263-019-01263-4\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5b153c7410571339ff11b3b8d1fdbc54cc832d86\",\"title\":\"Learning to Draw Sight Lines\",\"url\":\"https://www.semanticscholar.org/paper/5b153c7410571339ff11b3b8d1fdbc54cc832d86\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1806522\",\"name\":\"H. Park\"},{\"authorId\":\"46865129\",\"name\":\"J. Shi\"}],\"doi\":\"10.1109/TPAMI.2018.2883327\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3c56e90cc0a9baa3582931313e313784ecc6e507\",\"title\":\"Force from Motion: Decoding Control Force of Activity in a First-Person Video\",\"url\":\"https://www.semanticscholar.org/paper/3c56e90cc0a9baa3582931313e313784ecc6e507\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1951233\",\"name\":\"Patrik Polatsek\"},{\"authorId\":\"2678977\",\"name\":\"W. Benesova\"},{\"authorId\":\"2065653\",\"name\":\"L. Paletta\"},{\"authorId\":\"2386156\",\"name\":\"R. Perko\"}],\"doi\":\"10.1109/LSP.2016.2523339\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e632641321aff694788104c06d3e6736e0b8c39b\",\"title\":\"Novelty-based Spatiotemporal Saliency Detection for Prediction of Gaze in Egocentric Video\",\"url\":\"https://www.semanticscholar.org/paper/e632641321aff694788104c06d3e6736e0b8c39b\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40413015\",\"name\":\"M. Cornacchia\"},{\"authorId\":\"40408041\",\"name\":\"K. Ozcan\"},{\"authorId\":\"47833440\",\"name\":\"Yu Zheng\"},{\"authorId\":\"1714074\",\"name\":\"Senem Velipasalar\"}],\"doi\":\"10.1109/JSEN.2016.2628346\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"46c73ac90c8107e9580950eef9df6834edccd183\",\"title\":\"A Survey on Activity Detection and Classification Using Wearable Sensors\",\"url\":\"https://www.semanticscholar.org/paper/46c73ac90c8107e9580950eef9df6834edccd183\",\"venue\":\"IEEE Sensors Journal\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40645942\",\"name\":\"Juan Sebastian Olier\"},{\"authorId\":\"9587913\",\"name\":\"C. Regazzoni\"},{\"authorId\":\"1689330\",\"name\":\"L. Marcenaro\"},{\"authorId\":\"1736974\",\"name\":\"M. Rauterberg\"}],\"doi\":\"10.1007/978-3-319-19258-1_39\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"89dcf3d6f42f1a2fcdb0c81982ac1ea9e4ce2339\",\"title\":\"Convolutional Neural Networks for Detecting and Mapping Crowds in First Person Vision Applications\",\"url\":\"https://www.semanticscholar.org/paper/89dcf3d6f42f1a2fcdb0c81982ac1ea9e4ce2339\",\"venue\":\"IWANN\",\"year\":2015},{\"arxivId\":\"1607.06986\",\"authors\":[{\"authorId\":\"2599451\",\"name\":\"Shervin Ardeshir\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":\"10.1007/978-3-319-46454-1_16\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f4f3b7fd4d77cd7d315971f1803d9f68e1109aa5\",\"title\":\"Ego2Top: Matching Viewers in Egocentric and Top-View Videos\",\"url\":\"https://www.semanticscholar.org/paper/f4f3b7fd4d77cd7d315971f1803d9f68e1109aa5\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1510.04862\",\"authors\":[{\"authorId\":\"145089978\",\"name\":\"Dima Damen\"},{\"authorId\":\"3067867\",\"name\":\"Teesid Leelasawassuk\"},{\"authorId\":\"1398236231\",\"name\":\"Walterio W. Mayol-Cuevas\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"560ad4b6e1a183ccbb1ed6d44ce578eaf63d78af\",\"title\":\"You-Do, I-Learn: Unsupervised Multi-User egocentric Approach Towards Video-Based Guidance\",\"url\":\"https://www.semanticscholar.org/paper/560ad4b6e1a183ccbb1ed6d44ce578eaf63d78af\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150185312\",\"name\":\"Longfei Chen\"},{\"authorId\":\"67164385\",\"name\":\"Y. Nakamura\"},{\"authorId\":\"1942816\",\"name\":\"K. Kondo\"}],\"doi\":null,\"intent\":[\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"aa70dd8a39cecf7ceec8263ec03d56c2f6f18447\",\"title\":\"Toward Adaptive Guidance: Modeling the Variety of User Behaviors in Continuous-Skill-Improving Experiences of Machine Operation Tasks\",\"url\":\"https://www.semanticscholar.org/paper/aa70dd8a39cecf7ceec8263ec03d56c2f6f18447\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153410129\",\"name\":\"J. Hashemi\"},{\"authorId\":\"1730544\",\"name\":\"M. Tepper\"},{\"authorId\":\"8962959\",\"name\":\"Thiago Vallin Spina\"},{\"authorId\":\"2911548\",\"name\":\"A. Esler\"},{\"authorId\":\"1827707\",\"name\":\"V. Morellas\"},{\"authorId\":\"1696163\",\"name\":\"N. Papanikolopoulos\"},{\"authorId\":\"36509010\",\"name\":\"H. Egger\"},{\"authorId\":\"145862897\",\"name\":\"G. Dawson\"},{\"authorId\":\"1699339\",\"name\":\"G. Sapiro\"}],\"doi\":\"10.1155/2014/935686\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a8c83d5090bbc403a9ede0da48bf17d6f4c885cc\",\"title\":\"Computer Vision Tools for Low-Cost and Noninvasive Measurement of Autism-Related Behaviors in Infants\",\"url\":\"https://www.semanticscholar.org/paper/a8c83d5090bbc403a9ede0da48bf17d6f4c885cc\",\"venue\":\"Autism research and treatment\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1685141\",\"name\":\"F. Paci\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"},{\"authorId\":\"1710649\",\"name\":\"L. Benini\"}],\"doi\":\"10.1007/978-3-319-46604-0_42\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d7f847daae00895e34eacc4afed81096ed017f38\",\"title\":\"Context Change Detection for an Ultra-Low Power Low-Resolution Ego-Vision Imager\",\"url\":\"https://www.semanticscholar.org/paper/d7f847daae00895e34eacc4afed81096ed017f38\",\"venue\":\"ECCV Workshops\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143775793\",\"name\":\"J. Kumar\"},{\"authorId\":\"144326109\",\"name\":\"Q. Li\"},{\"authorId\":\"2164893\",\"name\":\"Survi Kyal\"},{\"authorId\":\"2164140\",\"name\":\"E. Bernal\"},{\"authorId\":\"145652623\",\"name\":\"R. Bala\"}],\"doi\":\"10.1109/CVPRW.2015.7301344\",\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"3ca4ce8ab704b44701bf7ef8dda01c8dbb226fac\",\"title\":\"On-the-fly hand detection training with application in egocentric action recognition\",\"url\":\"https://www.semanticscholar.org/paper/3ca4ce8ab704b44701bf7ef8dda01c8dbb226fac\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40408041\",\"name\":\"K. Ozcan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3169f6e77b4892755cf4750b7d24622fc2619cdc\",\"title\":\"Computer Vision Algorithms for Mobile Camera Applications\",\"url\":\"https://www.semanticscholar.org/paper/3169f6e77b4892755cf4750b7d24622fc2619cdc\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2599451\",\"name\":\"Shervin Ardeshir\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"72fa069d1ff70730493b1b814c78b498df3e1030\",\"title\":\"Ego 2 Top : Matching Viewers in Egocentric and Top-view Cameras\",\"url\":\"https://www.semanticscholar.org/paper/72fa069d1ff70730493b1b814c78b498df3e1030\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3727644\",\"name\":\"Satoshi Tsutsui\"},{\"authorId\":\"2798750\",\"name\":\"Sven Bambach\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"},{\"authorId\":\"145864858\",\"name\":\"Chen Yu\"}],\"doi\":\"10.1145/3242969.3242982\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5415611fc9a55355d9dc7ff044bd9e2e3ca38c6b\",\"title\":\"Estimating Head Motion from Egocentric Vision\",\"url\":\"https://www.semanticscholar.org/paper/5415611fc9a55355d9dc7ff044bd9e2e3ca38c6b\",\"venue\":\"ICMI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46867171\",\"name\":\"Y. Zhang\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1145/3214291\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"73b5261948b9b1e998bc84edf061efd354dac479\",\"title\":\"Watching the TV Watchers\",\"url\":\"https://www.semanticscholar.org/paper/73b5261948b9b1e998bc84edf061efd354dac479\",\"venue\":\"Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144243028\",\"name\":\"Mohammad Moghimi\"},{\"authorId\":\"39541653\",\"name\":\"P. Azagra\"},{\"authorId\":\"2987153\",\"name\":\"L. Montesano\"},{\"authorId\":\"1991008\",\"name\":\"A. C. Murillo\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"}],\"doi\":\"10.1109/CVPRW.2014.94\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1aa0fdce35699eab78286a4d37960522ab46d490\",\"title\":\"Experiments on an RGB-D Wearable Vision System for Egocentric Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1aa0fdce35699eab78286a4d37960522ab46d490\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition Workshops\",\"year\":2014},{\"arxivId\":\"2003.06045\",\"authors\":[{\"authorId\":\"47295036\",\"name\":\"Zehua Zhang\"},{\"authorId\":\"1947383\",\"name\":\"Ashish Tawari\"},{\"authorId\":\"1841835\",\"name\":\"Sujitha Martin\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"}],\"doi\":\"10.1109/ICRA40945.2020.9197104\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb51e17fc3e88c759ea3d41c9099e22ae7397e85\",\"title\":\"Interaction Graphs for Object Importance Estimation in On-road Driving Videos\",\"url\":\"https://www.semanticscholar.org/paper/eb51e17fc3e88c759ea3d41c9099e22ae7397e85\",\"venue\":\"2020 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40413834\",\"name\":\"J. Imran\"},{\"authorId\":\"1796442\",\"name\":\"B. Raman\"}],\"doi\":\"10.1145/3293353.3293363\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d397bd70dd4073db8f18fea3ac6d9717004e53f5\",\"title\":\"Multimodal Egocentric Activity Recognition Using Multi-stream CNN\",\"url\":\"https://www.semanticscholar.org/paper/d397bd70dd4073db8f18fea3ac6d9717004e53f5\",\"venue\":\"ICVGIP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72608846\",\"name\":\"Mohammad Moghimi Najafabadi\"}],\"doi\":\"10.7298/X4F47M34\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d66f0f69b73ae5faf10021fc59e4f9bcbeaf7cc3\",\"title\":\"Analyzing life-logging image sequences\",\"url\":\"https://www.semanticscholar.org/paper/d66f0f69b73ae5faf10021fc59e4f9bcbeaf7cc3\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40977902\",\"name\":\"Seita Kayukawa\"},{\"authorId\":\"34575696\",\"name\":\"Keita Higuchi\"},{\"authorId\":\"1899753\",\"name\":\"Ryo Yonetani\"},{\"authorId\":\"144086483\",\"name\":\"M. Nakamura\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"},{\"authorId\":\"1731030\",\"name\":\"S. Morishima\"}],\"doi\":\"10.1145/3170427.3189085\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"12e28bf2af2b2c12ad041bf949bff66718d84899\",\"title\":\"Dynamic Object Scanning: Object-Based Elastic Timeline for Quickly Browsing First-Person Videos\",\"url\":\"https://www.semanticscholar.org/paper/12e28bf2af2b2c12ad041bf949bff66718d84899\",\"venue\":\"CHI Extended Abstracts\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1806522\",\"name\":\"H. Park\"},{\"authorId\":\"2351486\",\"name\":\"Jyh-Jing Hwang\"},{\"authorId\":\"46865129\",\"name\":\"J. Shi\"}],\"doi\":\"10.1109/CVPR.2016.416\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3c5b3c90f951ca0f4b4e3a0ac3dd6aacae4adf72\",\"title\":\"Force from Motion: Decoding Physical Sensation in a First Person Video\",\"url\":\"https://www.semanticscholar.org/paper/3c5b3c90f951ca0f4b4e3a0ac3dd6aacae4adf72\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50333150\",\"name\":\"Ning Zhuang\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"5925215\",\"name\":\"Y. Xu\"},{\"authorId\":\"50031361\",\"name\":\"X. Yang\"},{\"authorId\":\"144913615\",\"name\":\"W. Zhang\"},{\"authorId\":\"46948132\",\"name\":\"Zefan Li\"},{\"authorId\":\"101001846\",\"name\":\"Wen Gao\"}],\"doi\":\"10.1109/TCSVT.2019.2940479\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"db2d2b1b4fbf791157bf094530fc22d3f4f79344\",\"title\":\"MUGGLE: MUlti-Stream Group Gaze Learning and Estimation\",\"url\":\"https://www.semanticscholar.org/paper/db2d2b1b4fbf791157bf094530fc22d3f4f79344\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48039353\",\"name\":\"Suriya Singh\"},{\"authorId\":\"145676233\",\"name\":\"Chetan Arora\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d20efdf05444a9d7509b85f6d5cd59359b1062f2\",\"title\":\"First Person Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d20efdf05444a9d7509b85f6d5cd59359b1062f2\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1812.00312\",\"authors\":[{\"authorId\":\"50857765\",\"name\":\"Jayant Sharma\"},{\"authorId\":\"9737003\",\"name\":\"Zixing Wang\"},{\"authorId\":\"1732945\",\"name\":\"Alberto Speranzon\"},{\"authorId\":\"3100301\",\"name\":\"Vijay Venkataraman\"},{\"authorId\":\"1806522\",\"name\":\"Hyun Soo Park\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fccfd318e56b5c5ea6ffb93f422b40eade39661e\",\"title\":\"ECO: Egocentric Cognitive Mapping\",\"url\":\"https://www.semanticscholar.org/paper/fccfd318e56b5c5ea6ffb93f422b40eade39661e\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51243449\",\"name\":\"Atanas Poibrenski\"},{\"authorId\":\"1798357\",\"name\":\"M. Klusch\"},{\"authorId\":\"1596870919\",\"name\":\"Igor Vozniak\"},{\"authorId\":\"143851843\",\"name\":\"C. M\\u00fcller\"}],\"doi\":\"10.1145/3341105.3373877\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6a6af33e8117079372b60ba65dc15a4738105162\",\"title\":\"M2P3: multimodal multi-pedestrian path prediction by self-driving cars with egocentric vision\",\"url\":\"https://www.semanticscholar.org/paper/6a6af33e8117079372b60ba65dc15a4738105162\",\"venue\":\"SAC\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145089978\",\"name\":\"D. Damen\"},{\"authorId\":\"2356868\",\"name\":\"Osian Haines\"},{\"authorId\":\"3067867\",\"name\":\"T. Leelasawassuk\"},{\"authorId\":\"3336943\",\"name\":\"A. Calway\"},{\"authorId\":\"1398236231\",\"name\":\"W. Mayol-Cuevas\"}],\"doi\":\"10.1007/978-3-319-16199-0_34\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4c31433c3647f6e1cca335ac94b932a6d0b12c60\",\"title\":\"Multi-User Egocentric Online System for Unsupervised Assistance on Object Usage\",\"url\":\"https://www.semanticscholar.org/paper/4c31433c3647f6e1cca335ac94b932a6d0b12c60\",\"venue\":\"ECCV Workshops\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2876810\",\"name\":\"Bilge Soran\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1809809\",\"name\":\"L. Shapiro\"}],\"doi\":\"10.1007/978-3-319-16814-2_12\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c2371629ad7bcde46e62859b2e812f6e5fc64cf\",\"title\":\"Action Recognition in the Presence of One Egocentric and Multiple Static Cameras\",\"url\":\"https://www.semanticscholar.org/paper/2c2371629ad7bcde46e62859b2e812f6e5fc64cf\",\"venue\":\"ACCV\",\"year\":2014},{\"arxivId\":\"1409.1484\",\"authors\":[{\"authorId\":\"145086911\",\"name\":\"A. Betancourt\"},{\"authorId\":\"2322579\",\"name\":\"Pietro Morerio\"},{\"authorId\":\"9587913\",\"name\":\"C. Regazzoni\"},{\"authorId\":\"1736974\",\"name\":\"M. Rauterberg\"}],\"doi\":\"10.1109/TCSVT.2015.2409731\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d317bf369e62fca415d54b091d9025b9e0e63181\",\"title\":\"The Evolution of First Person Vision Methods: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/d317bf369e62fca415d54b091d9025b9e0e63181\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2753116\",\"name\":\"Hana Vrzakova\"},{\"authorId\":\"1685243\",\"name\":\"R. Bednarik\"},{\"authorId\":\"1718158\",\"name\":\"Yukiko I. Nakano\"},{\"authorId\":\"3029535\",\"name\":\"Fumio Nihei\"}],\"doi\":\"10.1145/2857491.2857522\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e71f2829bd738f693b19b8e4215f164731f426e8\",\"title\":\"Speakers' head and gaze dynamics weakly correlate in group conversation\",\"url\":\"https://www.semanticscholar.org/paper/e71f2829bd738f693b19b8e4215f164731f426e8\",\"venue\":\"ETRA\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"119858851\",\"name\":\"J. Xu\"},{\"authorId\":\"144324490\",\"name\":\"Lopamudra Mukherjee\"},{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"40450406\",\"name\":\"J. Warner\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"},{\"authorId\":\"144711711\",\"name\":\"V. Singh\"}],\"doi\":\"10.1109/CVPR.2015.7298836\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2aacb2a897dfddd49bb162d87ca80863ca8ef1c2\",\"title\":\"Gaze-enabled egocentric video summarization via constrained submodular maximization\",\"url\":\"https://www.semanticscholar.org/paper/2aacb2a897dfddd49bb162d87ca80863ca8ef1c2\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32591784\",\"name\":\"T. Nguyen\"},{\"authorId\":\"3085605\",\"name\":\"Jean-Christophe Nebel\"},{\"authorId\":\"1404190954\",\"name\":\"Francisco Fl\\u00f3rez-Revuelta\"}],\"doi\":\"10.3390/s16010072\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5a48999cf31b26191e2db60d80794163d5f8c43d\",\"title\":\"Recognition of Activities of Daily Living with Egocentric Vision: A Review\",\"url\":\"https://www.semanticscholar.org/paper/5a48999cf31b26191e2db60d80794163d5f8c43d\",\"venue\":\"Sensors\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144348441\",\"name\":\"Dinesh Jayaraman\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1007/s11263-017-1001-2\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"246eb49fcd73e2dcd19cf3a76a06e4fd895a62a4\",\"title\":\"Learning Image Representations Tied to Egomotion from Unlabeled Video\",\"url\":\"https://www.semanticscholar.org/paper/246eb49fcd73e2dcd19cf3a76a06e4fd895a62a4\",\"venue\":\"International Journal of Computer Vision\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2876810\",\"name\":\"Bilge Soran\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e227058f661d9dd644753c4f81c02b8e46ec89b1\",\"title\":\"Action Recognition and Prediction with Applications to Medical Diagnosis and Daily Living\",\"url\":\"https://www.semanticscholar.org/paper/e227058f661d9dd644753c4f81c02b8e46ec89b1\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1904.06090\",\"authors\":[{\"authorId\":\"143852685\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"},{\"authorId\":\"1776374\",\"name\":\"Juho Kannala\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":\"10.1109/WACV.2019.00035\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b14286fdc78b3039fc724274c18aa24caee8b59e\",\"title\":\"Digging Deeper Into Egocentric Gaze Prediction\",\"url\":\"https://www.semanticscholar.org/paper/b14286fdc78b3039fc724274c18aa24caee8b59e\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150965117\",\"name\":\"Daniel Alejandro Castro Chin\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b24c218e8545bdbe58d3a614aee6c9063dd40d62\",\"title\":\"Understanding The Motion of A Human State In Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/b24c218e8545bdbe58d3a614aee6c9063dd40d62\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51137244\",\"name\":\"Tsukasa Okumura\"},{\"authorId\":\"122150713\",\"name\":\"Shuichi Urabe\"},{\"authorId\":\"2256574\",\"name\":\"K. Inoue\"},{\"authorId\":\"2593208\",\"name\":\"M. Yoshioka\"}],\"doi\":\"10.1145/3230519.3230591\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7c8d7f70dbddcbeab171e882cea89ccd8891eeac\",\"title\":\"Cooking activities recognition in egocentric videos using hand shape feature with openpose\",\"url\":\"https://www.semanticscholar.org/paper/7c8d7f70dbddcbeab171e882cea89ccd8891eeac\",\"venue\":\"CEA@IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1717313\",\"name\":\"Oya Celiktutan\"},{\"authorId\":\"1781916\",\"name\":\"H. Gunes\"}],\"doi\":\"10.1109/ROMAN.2015.7333602\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6446089a2a383ad9e4315aea0199084dc61490f9\",\"title\":\"Computational analysis of human-robot interactions through first-person vision: Personality and interaction experience\",\"url\":\"https://www.semanticscholar.org/paper/6446089a2a383ad9e4315aea0199084dc61490f9\",\"venue\":\"2015 24th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3067867\",\"name\":\"T. Leelasawassuk\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"},{\"authorId\":\"1398236231\",\"name\":\"W. Mayol-Cuevas\"}],\"doi\":\"10.1145/2802083.2808394\",\"intent\":[\"methodology\",\"result\"],\"isInfluential\":false,\"paperId\":\"29ca84eafad4c4045e48626c89f5f1563f70c385\",\"title\":\"Estimating visual attention from a head mounted IMU\",\"url\":\"https://www.semanticscholar.org/paper/29ca84eafad4c4045e48626c89f5f1563f70c385\",\"venue\":\"SEMWEB\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50088082\",\"name\":\"X. Ma\"},{\"authorId\":\"2842970\",\"name\":\"X. Xie\"},{\"authorId\":\"144847940\",\"name\":\"K. Lam\"},{\"authorId\":\"72768321\",\"name\":\"Y. Zhong\"}],\"doi\":\"10.1016/j.jvcir.2015.04.008\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"58043e75f81af0fb805ead68d49072e61f320c7c\",\"title\":\"Efficient saliency analysis based on wavelet transform and entropy theory\",\"url\":\"https://www.semanticscholar.org/paper/58043e75f81af0fb805ead68d49072e61f320c7c\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2015},{\"arxivId\":\"1709.00507\",\"authors\":[{\"authorId\":\"144348441\",\"name\":\"Dinesh Jayaraman\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e2d0be2e48e743732dde766e59bdfd96f290f9f3\",\"title\":\"Learning to look around\",\"url\":\"https://www.semanticscholar.org/paper/e2d0be2e48e743732dde766e59bdfd96f290f9f3\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1701.02586\",\"authors\":[{\"authorId\":\"3067867\",\"name\":\"T. Leelasawassuk\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"},{\"authorId\":\"1398236231\",\"name\":\"W. Mayol-Cuevas\"}],\"doi\":\"10.1145/3041164.3041185\",\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"8a52355cdea89428742a3e2bc8472c89bfd68f04\",\"title\":\"Automated capture and delivery of assistive task guidance with an eyewear computer: the GlaciAR system\",\"url\":\"https://www.semanticscholar.org/paper/8a52355cdea89428742a3e2bc8472c89bfd68f04\",\"venue\":\"AH\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144478646\",\"name\":\"Z. Guo\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"34798935\",\"name\":\"Xiantong Zhen\"},{\"authorId\":\"1824641\",\"name\":\"F. Zou\"},{\"authorId\":\"144618699\",\"name\":\"F. Shen\"},{\"authorId\":\"145487536\",\"name\":\"Kai Zheng\"}],\"doi\":\"10.1016/j.neucom.2016.03.083\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"08728bd75bde86c095832d84232d17a6b05cecce\",\"title\":\"Spatial and temporal scoring for egocentric video summarization\",\"url\":\"https://www.semanticscholar.org/paper/08728bd75bde86c095832d84232d17a6b05cecce\",\"venue\":\"Neurocomputing\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1780197\",\"name\":\"Dong Seon Cheng\"},{\"authorId\":\"1723008\",\"name\":\"Marco Cristani\"}],\"doi\":\"10.1017/9781316676202.024\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"defb1dfcf6d7fa9e5355c57b445256b0e5b5350b\",\"title\":\"Social Signal Processing for Surveillance\",\"url\":\"https://www.semanticscholar.org/paper/defb1dfcf6d7fa9e5355c57b445256b0e5b5350b\",\"venue\":\"Social Signal Processing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46366007\",\"name\":\"Jiaxin Wu\"},{\"authorId\":\"2812440\",\"name\":\"S. Zhong\"},{\"authorId\":\"80398011\",\"name\":\"Z. Ma\"},{\"authorId\":\"38821423\",\"name\":\"S. Heinen\"},{\"authorId\":\"145054089\",\"name\":\"J. Jiang\"}],\"doi\":\"10.1007/s11042-018-5953-1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"14389a8a68fe7a23de82285ea813c7c9f8a433c9\",\"title\":\"Foveated convolutional neural networks for video summarization\",\"url\":\"https://www.semanticscholar.org/paper/14389a8a68fe7a23de82285ea813c7c9f8a433c9\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145279153\",\"name\":\"S. Huang\"},{\"authorId\":\"145472490\",\"name\":\"Weiqiang Wang\"},{\"authorId\":\"2548483\",\"name\":\"Shengfeng He\"},{\"authorId\":\"1726262\",\"name\":\"R. Lau\"}],\"doi\":\"10.1109/TIP.2017.2772904\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7a955ee69174fb97c7017f2e227a5fa26b900537\",\"title\":\"Egocentric Temporal Action Proposals\",\"url\":\"https://www.semanticscholar.org/paper/7a955ee69174fb97c7017f2e227a5fa26b900537\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9362227\",\"name\":\"Sagar Verma\"},{\"authorId\":\"145676232\",\"name\":\"Chetan Arora\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"72379808573cc333f63a3c774457d1770aca052d\",\"title\":\"Action recognition in egocentric videos\",\"url\":\"https://www.semanticscholar.org/paper/72379808573cc333f63a3c774457d1770aca052d\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"2238622\",\"name\":\"Minghuang Ma\"},{\"authorId\":\"2650832\",\"name\":\"W. Ma\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"}],\"doi\":\"10.1109/CVPR.2015.7298666\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d3669356313e2afff6ab80181ff5cdf4885bd61d\",\"title\":\"How do we use our hands? Discovering a diverse set of common grasps\",\"url\":\"https://www.semanticscholar.org/paper/d3669356313e2afff6ab80181ff5cdf4885bd61d\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10978611\",\"name\":\"Akanksha Saran\"},{\"authorId\":\"41175924\",\"name\":\"Srinjoy Majumdar\"},{\"authorId\":\"32775309\",\"name\":\"Elaine Schaertl Short\"},{\"authorId\":\"1682788\",\"name\":\"A. Thomaz\"},{\"authorId\":\"2791038\",\"name\":\"S. Niekum\"}],\"doi\":\"10.1109/IROS.2018.8593580\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"295c3be3e603b3349d23f8733c3c3eb1744b103c\",\"title\":\"Human Gaze Following for Human-Robot Interaction\",\"url\":\"https://www.semanticscholar.org/paper/295c3be3e603b3349d23f8733c3c3eb1744b103c\",\"venue\":\"2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2018},{\"arxivId\":\"1809.08381\",\"authors\":[{\"authorId\":\"29132542\",\"name\":\"Meera Hahn\"},{\"authorId\":\"31601235\",\"name\":\"Nataniel Ruiz\"},{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a7c9b3eb8737d29a779a0e21e355543c22ccca49\",\"title\":\"Learning to Localize and Align Fine-Grained Actions to Sparse Instructions\",\"url\":\"https://www.semanticscholar.org/paper/a7c9b3eb8737d29a779a0e21e355543c22ccca49\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1905.13586\",\"authors\":[{\"authorId\":\"47892681\",\"name\":\"Haoxin Li\"},{\"authorId\":\"50204657\",\"name\":\"Yijun Cai\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"}],\"doi\":\"10.1109/CVPR.2019.00812\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"303aa6cb7a182d5437c86d07aff4fb9fdabc744e\",\"title\":\"Deep Dual Relation Modeling for Egocentric Interaction Recognition\",\"url\":\"https://www.semanticscholar.org/paper/303aa6cb7a182d5437c86d07aff4fb9fdabc744e\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1812.09570\",\"authors\":[{\"authorId\":\"1808039\",\"name\":\"Emrah Basaran\"},{\"authorId\":\"10428247\",\"name\":\"Yonatan Tariku Tesfaye\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c8ca231a21c28c57d15ace1d9057879046a7f08c\",\"title\":\"EgoReID: Person re-identification in Egocentric Videos Acquired by Mobile Devices with First-Person Point-of-View\",\"url\":\"https://www.semanticscholar.org/paper/c8ca231a21c28c57d15ace1d9057879046a7f08c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1604.02115\",\"authors\":[{\"authorId\":\"48039353\",\"name\":\"Suriya Singh\"},{\"authorId\":\"145676235\",\"name\":\"C. Arora\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"}],\"doi\":\"10.1016/j.patcog.2016.07.031\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"45b6562ffd8df53de69e39c91b1f28abece412d9\",\"title\":\"Trajectory aligned features for first person action recognition\",\"url\":\"https://www.semanticscholar.org/paper/45b6562ffd8df53de69e39c91b1f28abece412d9\",\"venue\":\"Pattern Recognit.\",\"year\":2017},{\"arxivId\":\"1711.08664\",\"authors\":[{\"authorId\":\"6937593\",\"name\":\"Shih-Han Chou\"},{\"authorId\":\"49070447\",\"name\":\"Y. Chen\"},{\"authorId\":\"32970572\",\"name\":\"Kuo-Hao Zeng\"},{\"authorId\":\"10712411\",\"name\":\"Hou-Ning Hu\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1cfbaa9af05f0eea03ac7c28cc0e588687cd8343\",\"title\":\"Self-view Grounding Given a Narrated 360{\\\\deg} Video\",\"url\":\"https://www.semanticscholar.org/paper/1cfbaa9af05f0eea03ac7c28cc0e588687cd8343\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2760194\",\"name\":\"Yunyang Xiong\"},{\"authorId\":\"66185025\",\"name\":\"Hyun-woo Kim\"},{\"authorId\":\"97658883\",\"name\":\"V. Singh\"}],\"doi\":\"10.1109/CVPR.2019.00793\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"649b03e22186cbbe921c31d8bfa3399ae475d85d\",\"title\":\"Mixed Effects Neural Networks (MeNets) With Applications to Gaze Estimation\",\"url\":\"https://www.semanticscholar.org/paper/649b03e22186cbbe921c31d8bfa3399ae475d85d\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145086911\",\"name\":\"A. Betancourt\"},{\"authorId\":\"2322579\",\"name\":\"Pietro Morerio\"},{\"authorId\":\"145741020\",\"name\":\"E. Barakova\"},{\"authorId\":\"1689330\",\"name\":\"L. Marcenaro\"},{\"authorId\":\"1736974\",\"name\":\"M. Rauterberg\"},{\"authorId\":\"9587913\",\"name\":\"C. Regazzoni\"}],\"doi\":\"10.1007/978-3-319-23192-1_23\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c160bcbc8f0517a97e46042c84343bf3f0477478\",\"title\":\"A Dynamic Approach and a New Dataset for Hand-detection in First Person Vision\",\"url\":\"https://www.semanticscholar.org/paper/c160bcbc8f0517a97e46042c84343bf3f0477478\",\"venue\":\"CAIP\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145558934\",\"name\":\"S. Mann\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"},{\"authorId\":\"144756076\",\"name\":\"Y. Lee\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"},{\"authorId\":\"47683829\",\"name\":\"A. Fathi\"}],\"doi\":\"10.1109/CVPRW.2014.133\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3a192e0391c357124cd2ec2287b1706f523ecdfd\",\"title\":\"An Introduction to the 3rd Workshop on Egocentric (First-Person) Vision\",\"url\":\"https://www.semanticscholar.org/paper/3a192e0391c357124cd2ec2287b1706f523ecdfd\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition Workshops\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35299091\",\"name\":\"Yansong Tang\"},{\"authorId\":\"50218246\",\"name\":\"Z. Wang\"},{\"authorId\":\"1697700\",\"name\":\"Jiwen Lu\"},{\"authorId\":\"144698893\",\"name\":\"J. Feng\"},{\"authorId\":\"49640256\",\"name\":\"J. Zhou\"}],\"doi\":\"10.1109/TCSVT.2018.2875441\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a90a56267b66c060b235339a0080a00585fdeb41\",\"title\":\"Multi-Stream Deep Neural Networks for RGB-D Egocentric Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a90a56267b66c060b235339a0080a00585fdeb41\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1999236\",\"name\":\"H. Chang\"},{\"authorId\":\"1403754530\",\"name\":\"Guillermo Garcia-Hernando\"},{\"authorId\":\"40245930\",\"name\":\"Danhang Tang\"},{\"authorId\":\"143617697\",\"name\":\"Tae-Kyun Kim\"}],\"doi\":\"10.1016/j.cviu.2016.01.010\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"46f2ea77b15922239cad3c151705f59050bebc4a\",\"title\":\"Spatio-Temporal Hough Forest for efficient detection-localisation-recognition of fingerwriting in egocentric camera\",\"url\":\"https://www.semanticscholar.org/paper/46f2ea77b15922239cad3c151705f59050bebc4a\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150185312\",\"name\":\"Longfei Chen\"},{\"authorId\":\"24265259\",\"name\":\"Y. Nakamura\"},{\"authorId\":\"1942816\",\"name\":\"K. Kondo\"},{\"authorId\":\"1398236231\",\"name\":\"W. Mayol-Cuevas\"}],\"doi\":\"10.1587/TRANSINF.2018EDP7146\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e255819a13d32c106e9a31f12644da0efb0ef369\",\"title\":\"Hotspot Modeling of Hand-Machine Interaction Experiences from a Head-Mounted RGB-D Camera\",\"url\":\"https://www.semanticscholar.org/paper/e255819a13d32c106e9a31f12644da0efb0ef369\",\"venue\":\"IEICE Trans. Inf. Syst.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29001103\",\"name\":\"Rafael Possas\"},{\"authorId\":\"1405712007\",\"name\":\"Sheila M. Pinto-Caceres\"},{\"authorId\":\"145726167\",\"name\":\"F. Ramos\"}],\"doi\":\"10.1109/CVPR.2018.00625\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bcafefd074937caa6a56f3ffe0068075c6f631e8\",\"title\":\"Egocentric Activity Recognition on a Budget\",\"url\":\"https://www.semanticscholar.org/paper/bcafefd074937caa6a56f3ffe0068075c6f631e8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21007367\",\"name\":\"K. T. Ma\"},{\"authorId\":\"26497929\",\"name\":\"Rosary Lim\"},{\"authorId\":\"15450116\",\"name\":\"Peilun Dai\"},{\"authorId\":\"35718875\",\"name\":\"L. Li\"},{\"authorId\":\"1414601089\",\"name\":\"Lim Joo-Hwee\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"6cca1f9c2eb6cae5f211cf703ab2f1d55f60cbf1\",\"title\":\"Unconstrained ego-centric videos with eye-tracking data\",\"url\":\"https://www.semanticscholar.org/paper/6cca1f9c2eb6cae5f211cf703ab2f1d55f60cbf1\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1512.01881\",\"authors\":[{\"authorId\":\"36549981\",\"name\":\"Cheng-Sheng Chan\"},{\"authorId\":\"50357993\",\"name\":\"Shou-Zhong Chen\"},{\"authorId\":\"1717126\",\"name\":\"Pei-Xuan Xie\"},{\"authorId\":\"145982994\",\"name\":\"Chiung-Chih Chang\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e5a4649a57d4e8b1ba06c0aaa8b7297efa7dced9\",\"title\":\"Recognition from Hand Cameras\",\"url\":\"https://www.semanticscholar.org/paper/e5a4649a57d4e8b1ba06c0aaa8b7297efa7dced9\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144180678\",\"name\":\"M. Lu\"},{\"authorId\":\"1689656\",\"name\":\"Z. Li\"},{\"authorId\":\"7135663\",\"name\":\"Y. Wang\"},{\"authorId\":\"144563871\",\"name\":\"Gang Pan\"}],\"doi\":\"10.1109/TIP.2019.2901707\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"355f769cc896ff3ea302423587c9a1b7c2301c4e\",\"title\":\"Deep Attention Network for Egocentric Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/355f769cc896ff3ea302423587c9a1b7c2301c4e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47002659\",\"name\":\"Yanchao Li\"},{\"authorId\":\"1843583\",\"name\":\"Zhefan Ye\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"66d5842b7392bed57f473f8179dc04735412fb42\",\"title\":\"Motion , Object and Egocentric Cues\",\"url\":\"https://www.semanticscholar.org/paper/66d5842b7392bed57f473f8179dc04735412fb42\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403182605\",\"name\":\"V. L\\u00f3pez-L\\u00f3pez\"},{\"authorId\":\"48145938\",\"name\":\"L. Escobedo\"},{\"authorId\":\"145963958\",\"name\":\"L. Trujillo\"}],\"doi\":\"10.1111/exsy.12572\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3c74dddf19938324e229acb2d52309e2b9d8de6c\",\"title\":\"Towards an automatic coding of observational studies: Coding neurofeedback therapies of children with autism\",\"url\":\"https://www.semanticscholar.org/paper/3c74dddf19938324e229acb2d52309e2b9d8de6c\",\"venue\":\"Expert Syst. J. Knowl. Eng.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"},{\"authorId\":\"1782162\",\"name\":\"L. Matthies\"}],\"doi\":\"10.1007/s11263-015-0847-4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"080e81f425dc129c4e4022568e2a23674ca41307\",\"title\":\"First-Person Activity Recognition: Feature, Temporal Structure, and Prediction\",\"url\":\"https://www.semanticscholar.org/paper/080e81f425dc129c4e4022568e2a23674ca41307\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":\"1912.13457\",\"authors\":[{\"authorId\":\"49192783\",\"name\":\"Lingzhi Li\"},{\"authorId\":\"3093568\",\"name\":\"Jianmin Bao\"},{\"authorId\":\"102320235\",\"name\":\"Hao Yang\"},{\"authorId\":\"153642240\",\"name\":\"Dong Chen\"},{\"authorId\":\"1716835\",\"name\":\"Fang Wen\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"67c6afafc43f7fda5e2aea7db77e86aa95955517\",\"title\":\"FaceShifter: Towards High Fidelity And Occlusion Aware Face Swapping\",\"url\":\"https://www.semanticscholar.org/paper/67c6afafc43f7fda5e2aea7db77e86aa95955517\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49192783\",\"name\":\"Lingzhi Li\"},{\"authorId\":\"9324504\",\"name\":\"Jian-min Bao\"},{\"authorId\":\"102320235\",\"name\":\"Hao Yang\"},{\"authorId\":\"144230587\",\"name\":\"D. Chen\"},{\"authorId\":\"1716835\",\"name\":\"Fang Wen\"}],\"doi\":\"10.1109/cvpr42600.2020.00512\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4f842a92c110f40e9187bc9e6544b5dcb1daa5f3\",\"title\":\"Advancing High Fidelity Identity Swapping for Forgery Detection\",\"url\":\"https://www.semanticscholar.org/paper/4f842a92c110f40e9187bc9e6544b5dcb1daa5f3\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1612.08153\",\"authors\":[{\"authorId\":\"2599451\",\"name\":\"Shervin Ardeshir\"},{\"authorId\":\"8348054\",\"name\":\"Sandesh Sharma\"},{\"authorId\":\"8262483\",\"name\":\"Ali Broji\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6355f7fd956466e8e9f09b297e6cdd155d66740e\",\"title\":\"EgoReID: Cross-view Self-Identification and Human Re-identification in Egocentric and Surveillance Videos\",\"url\":\"https://www.semanticscholar.org/paper/6355f7fd956466e8e9f09b297e6cdd155d66740e\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48518145\",\"name\":\"Yantao Lu\"},{\"authorId\":\"1714074\",\"name\":\"Senem Velipasalar\"}],\"doi\":\"10.1109/JSEN.2019.2934678\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5541850d7b646107370c1448317e45ad1eb66b63\",\"title\":\"Autonomous Human Activity Classification From Wearable Multi-Modal Sensors\",\"url\":\"https://www.semanticscholar.org/paper/5541850d7b646107370c1448317e45ad1eb66b63\",\"venue\":\"IEEE Sensors Journal\",\"year\":2019},{\"arxivId\":\"1904.05250\",\"authors\":[{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1742452\",\"name\":\"S. Battiato\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":\"10.1016/j.jvcir.2017.10.004\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b67282a73c79438095799de916bf44ae55f1d310\",\"title\":\"Next-active-object prediction from egocentric videos\",\"url\":\"https://www.semanticscholar.org/paper/b67282a73c79438095799de916bf44ae55f1d310\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"},{\"authorId\":\"1904850\",\"name\":\"B. Rothrock\"},{\"authorId\":\"47517530\",\"name\":\"C. Fleming\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2deed841cfde51ce3b4e90880894efbbfdc18f18\",\"title\":\"Privacy-Preserving Egocentric Activity Recognition from Extreme Low Resolution\",\"url\":\"https://www.semanticscholar.org/paper/2deed841cfde51ce3b4e90880894efbbfdc18f18\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50398746\",\"name\":\"B. Xiong\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1007/978-3-319-24702-1_4\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"4a4b20a36846a5f5aed427a483a5a64c6870c145\",\"title\":\"Intentional Photos from an Unintentional Photographer: Detecting Snap Points in Egocentric Video with a Web Photo Prior\",\"url\":\"https://www.semanticscholar.org/paper/4a4b20a36846a5f5aed427a483a5a64c6870c145\",\"venue\":\"Mobile Cloud Visual Media Computing\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48518145\",\"name\":\"Yantao Lu\"},{\"authorId\":\"1714074\",\"name\":\"Senem Velipasalar\"}],\"doi\":\"10.1007/978-3-030-16949-7_7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c668ea181468f88bf713d861e321f7f26063c68c\",\"title\":\"Wearable Sensor Applications: Processing of Egocentric Videos and Inertial Measurement Unit Data\",\"url\":\"https://www.semanticscholar.org/paper/c668ea181468f88bf713d861e321f7f26063c68c\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2003.03025\",\"authors\":[{\"authorId\":\"9138537\",\"name\":\"Chen Long-fei\"},{\"authorId\":\"67164385\",\"name\":\"Y. Nakamura\"},{\"authorId\":\"1942816\",\"name\":\"K. Kondo\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"17ceea133b812d31fc7fb2c145e464d66756b4f2\",\"title\":\"Modeling User Behaviors in Machine Operation Tasks for Adaptive Guidance\",\"url\":\"https://www.semanticscholar.org/paper/17ceea133b812d31fc7fb2c145e464d66756b4f2\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1906.04002\",\"authors\":[{\"authorId\":\"150185312\",\"name\":\"Longfei Chen\"},{\"authorId\":\"67164385\",\"name\":\"Y. Nakamura\"},{\"authorId\":\"1942816\",\"name\":\"K. Kondo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f3fc350f031292fc61f98f63ec4a1e4df2f05fac\",\"title\":\"Detecting Clues for Skill Levels and Machine Operation Difficulty from Egocentric Vision\",\"url\":\"https://www.semanticscholar.org/paper/f3fc350f031292fc61f98f63ec4a1e4df2f05fac\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1509.00651\",\"authors\":[{\"authorId\":\"2206888\",\"name\":\"Changzhi Luo\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"143625300\",\"name\":\"J. Yuan\"},{\"authorId\":\"38504661\",\"name\":\"J. Wang\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"},{\"authorId\":\"47446553\",\"name\":\"M. Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3dfe949687a422b6b022a36ad46700450966f5fc\",\"title\":\"Manipulated Object Proposal: A Discriminative Object Extraction and Feature Fusion Framework for First-Person Daily Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3dfe949687a422b6b022a36ad46700450966f5fc\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1509.02094\",\"authors\":[{\"authorId\":\"1806522\",\"name\":\"H. Park\"},{\"authorId\":\"39294088\",\"name\":\"Yedong Niu\"},{\"authorId\":\"46865129\",\"name\":\"J. Shi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"37a4199e63312f7901af853998951883e52ab062\",\"title\":\"Future Localization from an Egocentric Depth Image\",\"url\":\"https://www.semanticscholar.org/paper/37a4199e63312f7901af853998951883e52ab062\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1899753\",\"name\":\"Ryo Yonetani\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1109/CVPR.2016.288\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"16461bc1f06c781b5357cb1157248d28dc3672a0\",\"title\":\"Recognizing Micro-Actions and Reactions from Paired Egocentric Videos\",\"url\":\"https://www.semanticscholar.org/paper/16461bc1f06c781b5357cb1157248d28dc3672a0\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"2002.12557\",\"authors\":[{\"authorId\":\"2150647\",\"name\":\"Kyungjun Lee\"},{\"authorId\":\"51453757\",\"name\":\"Abhinav Shrivastava\"},{\"authorId\":\"1745229\",\"name\":\"Hernisa Kacorri\"}],\"doi\":\"10.1109/WACV45572.2020.9093353\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fb634ac5f4d8166e7ba56bfd089cc0809ac6d71f\",\"title\":\"Hand-Priming in Object Localization for Assistive Egocentric Vision\",\"url\":\"https://www.semanticscholar.org/paper/fb634ac5f4d8166e7ba56bfd089cc0809ac6d71f\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1910.14260\",\"authors\":[{\"authorId\":\"47295036\",\"name\":\"Zehua Zhang\"},{\"authorId\":\"46756438\",\"name\":\"Chen Yu\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b41e631c08be054ab19a88e3fb07077e03a6c53e\",\"title\":\"A Self Validation Network for Object-Level Human Attention Estimation\",\"url\":\"https://www.semanticscholar.org/paper/b41e631c08be054ab19a88e3fb07077e03a6c53e\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1510.02073\",\"authors\":[{\"authorId\":\"3115428\",\"name\":\"Vinay Bettadapura\"},{\"authorId\":\"21472040\",\"name\":\"Irfan Essa\"},{\"authorId\":\"2997956\",\"name\":\"C. Pantofaru\"}],\"doi\":\"10.1109/WACV.2015.89\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"40c4445c9a560068ee90a6a659e6928190805b82\",\"title\":\"Egocentric Field-of-View Localization Using First-Person Point-of-View Devices\",\"url\":\"https://www.semanticscholar.org/paper/40c4445c9a560068ee90a6a659e6928190805b82\",\"venue\":\"2015 IEEE Winter Conference on Applications of Computer Vision\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2798750\",\"name\":\"Sven Bambach\"},{\"authorId\":\"2836466\",\"name\":\"L. Smith\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"},{\"authorId\":\"145864858\",\"name\":\"Chen Yu\"}],\"doi\":\"10.1109/DEVLRN.2016.7846804\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"183973fe1460753b7fb6bb505f68fb9484f626cc\",\"title\":\"Objects in the center: How the infant's body constrains infant scenes\",\"url\":\"https://www.semanticscholar.org/paper/183973fe1460753b7fb6bb505f68fb9484f626cc\",\"venue\":\"2016 Joint IEEE International Conference on Development and Learning and Epigenetic Robotics (ICDL-EpiRob)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145089978\",\"name\":\"D. Damen\"},{\"authorId\":\"3067867\",\"name\":\"T. Leelasawassuk\"},{\"authorId\":\"1398236231\",\"name\":\"W. Mayol-Cuevas\"}],\"doi\":\"10.1016/j.cviu.2016.02.016\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f2fd5c5ac90864d5a927d7096b5223896898de1c\",\"title\":\"You-Do, I-Learn: Egocentric unsupervised discovery of objects and their modes of interaction towards video-based guidance\",\"url\":\"https://www.semanticscholar.org/paper/f2fd5c5ac90864d5a927d7096b5223896898de1c\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2016},{\"arxivId\":\"1505.02206\",\"authors\":[{\"authorId\":\"144348441\",\"name\":\"Dinesh Jayaraman\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/ICCV.2015.166\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c426ba865e9158a0f7962a86a50575aa943051b1\",\"title\":\"Learning Image Representations Tied to Ego-Motion\",\"url\":\"https://www.semanticscholar.org/paper/c426ba865e9158a0f7962a86a50575aa943051b1\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"2006.00626\",\"authors\":[{\"authorId\":\"47002659\",\"name\":\"Yanchao Li\"},{\"authorId\":\"1720749879\",\"name\":\"Miao Liu\"},{\"authorId\":\"50779871\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a48cde936f7dea115cbda99a08e12dbdf45d13fb\",\"title\":\"In the Eye of the Beholder: Gaze and Actions in First Person Video\",\"url\":\"https://www.semanticscholar.org/paper/a48cde936f7dea115cbda99a08e12dbdf45d13fb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"87116461\",\"name\":\"M. Silva\"},{\"authorId\":\"3459502\",\"name\":\"Washington L. S. Ramos\"},{\"authorId\":\"3360914\",\"name\":\"Alan C. Neves\"},{\"authorId\":\"51929166\",\"name\":\"Edson Roteia Araujo Junior\"},{\"authorId\":\"4661295\",\"name\":\"M. Campos\"},{\"authorId\":\"80510807\",\"name\":\"E. Nascimento\"}],\"doi\":\"10.1109/SIBGRAPI-T.2019.00009\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"380d34da59c0d4c5f03e6b4695e046353cc304ae\",\"title\":\"Fast-Forward Methods for Egocentric Videos: A Review\",\"url\":\"https://www.semanticscholar.org/paper/380d34da59c0d4c5f03e6b4695e046353cc304ae\",\"venue\":\"2019 32nd SIBGRAPI Conference on Graphics, Patterns and Images Tutorials (SIBGRAPI-T)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49455017\",\"name\":\"Yipin Zhou\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/ICCV.2015.511\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d12c567768b401f8d7f1ad532a2b23320ca29b49\",\"title\":\"Temporal Perception and Prediction in Ego-Centric Video\",\"url\":\"https://www.semanticscholar.org/paper/d12c567768b401f8d7f1ad532a2b23320ca29b49\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144348441\",\"name\":\"Dinesh Jayaraman\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3935cabb73d75939ade5fc8839cfd946fbdc8057\",\"title\":\"Learning image representations equivariant to ego-motion\",\"url\":\"https://www.semanticscholar.org/paper/3935cabb73d75939ade5fc8839cfd946fbdc8057\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1606.02031\",\"authors\":[{\"authorId\":\"145194973\",\"name\":\"C. Xu\"},{\"authorId\":\"2722143\",\"name\":\"L. Govindarajan\"},{\"authorId\":\"145874477\",\"name\":\"Li Cheng\"}],\"doi\":\"10.1016/j.patcog.2017.08.009\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3597dce344b088f913689abde927a59a0bedde48\",\"title\":\"Hand action detection from ego-centric depth sequences with error-correcting Hough transform\",\"url\":\"https://www.semanticscholar.org/paper/3597dce344b088f913689abde927a59a0bedde48\",\"venue\":\"Pattern Recognit.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145718481\",\"name\":\"Min Sun\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1685978\",\"name\":\"B. Taskar\"},{\"authorId\":\"1679223\",\"name\":\"S. Seitz\"}],\"doi\":\"10.1109/TPAMI.2016.2623699\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c9974b7d35d9425faf8d31ede581c605f4f0abc1\",\"title\":\"Summarizing Unconstrained Videos Using Salient Montages\",\"url\":\"https://www.semanticscholar.org/paper/c9974b7d35d9425faf8d31ede581c605f4f0abc1\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7869872\",\"name\":\"Y. Xu\"},{\"authorId\":\"49266038\",\"name\":\"Yanbing Dong\"},{\"authorId\":\"3423101\",\"name\":\"Junru Wu\"},{\"authorId\":\"30581936\",\"name\":\"Zhengzhong Sun\"},{\"authorId\":\"34692825\",\"name\":\"Zhiru Shi\"},{\"authorId\":\"2152356\",\"name\":\"J. Yu\"},{\"authorId\":\"1702868\",\"name\":\"Shenghua Gao\"}],\"doi\":\"10.1109/CVPR.2018.00559\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cc3bd1659d005ee25c26e3f6aab3c7361f6172b7\",\"title\":\"Gaze Prediction in Dynamic 360\\u00b0 Immersive Videos\",\"url\":\"https://www.semanticscholar.org/paper/cc3bd1659d005ee25c26e3f6aab3c7361f6172b7\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145708707\",\"name\":\"P. Wei\"},{\"authorId\":\"48811777\",\"name\":\"Dan Xie\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.24963/ijcai.2017/180\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fab0d19c58815eccb0db7215fe45d6a32066ca1c\",\"title\":\"Inferring Human Attention by Learning Latent Intentions\",\"url\":\"https://www.semanticscholar.org/paper/fab0d19c58815eccb0db7215fe45d6a32066ca1c\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":\"1604.00906\",\"authors\":[{\"authorId\":\"39523296\",\"name\":\"Yu-Chuan Su\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1007/978-3-319-46454-1_28\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2a0957d2238a8dca24aa4a276c3370fad671c104\",\"title\":\"Detecting Engagement in Egocentric Video\",\"url\":\"https://www.semanticscholar.org/paper/2a0957d2238a8dca24aa4a276c3370fad671c104\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1608.08334\",\"authors\":[{\"authorId\":\"2599451\",\"name\":\"Shervin Ardeshir\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":\"10.1109/TPAMI.2018.2832121\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f00c1fcf43e0ff2de19ffe5b209b1fe85acb4d50\",\"title\":\"Egocentric Meets Top-View\",\"url\":\"https://www.semanticscholar.org/paper/f00c1fcf43e0ff2de19ffe5b209b1fe85acb4d50\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":\"2001.11580\",\"authors\":[{\"authorId\":\"24057502\",\"name\":\"Sathyanarayanan N. Aakur\"},{\"authorId\":\"144227173\",\"name\":\"A. Bagavathi\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"af5c027f9435bb4c26cbf48bb28a1d8456e164e0\",\"title\":\"Unsupervised Gaze Prediction in Egocentric Videos by Energy-based Surprise Modeling\",\"url\":\"https://www.semanticscholar.org/paper/af5c027f9435bb4c26cbf48bb28a1d8456e164e0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3378756\",\"name\":\"H. Inoue\"},{\"authorId\":\"2639141\",\"name\":\"T. Hirayama\"},{\"authorId\":\"1747218\",\"name\":\"Keisuke Doman\"},{\"authorId\":\"1770200\",\"name\":\"Y. Kawanishi\"},{\"authorId\":\"1679187\",\"name\":\"I. Ide\"},{\"authorId\":\"1699693\",\"name\":\"D. Deguchi\"},{\"authorId\":\"82910116\",\"name\":\"H. Murase\"}],\"doi\":\"10.1145/2857491.2857500\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f7b1296c2a913060cdcaf943b4f34d50c4e986b4\",\"title\":\"A classification method of cooking operations based on eye movement patterns\",\"url\":\"https://www.semanticscholar.org/paper/f7b1296c2a913060cdcaf943b4f34d50c4e986b4\",\"venue\":\"ETRA\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1806522\",\"name\":\"H. Park\"},{\"authorId\":\"2351486\",\"name\":\"Jyh-Jing Hwang\"},{\"authorId\":\"39294088\",\"name\":\"Yedong Niu\"},{\"authorId\":\"46865129\",\"name\":\"J. Shi\"}],\"doi\":\"10.1109/CVPR.2016.508\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6abc95865cade4cd81eddaf1979f70115dc7bf37\",\"title\":\"Egocentric Future Localization\",\"url\":\"https://www.semanticscholar.org/paper/6abc95865cade4cd81eddaf1979f70115dc7bf37\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1604.03196\",\"authors\":[{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"},{\"authorId\":\"1904850\",\"name\":\"B. Rothrock\"},{\"authorId\":\"47517530\",\"name\":\"C. Fleming\"},{\"authorId\":\"3014315\",\"name\":\"H. Yang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f393c5a809fac223461e764495d933c7f18e6ec0\",\"title\":\"Privacy-Preserving Human Activity Recognition from Extreme Low Resolution\",\"url\":\"https://www.semanticscholar.org/paper/f393c5a809fac223461e764495d933c7f18e6ec0\",\"venue\":\"AAAI\",\"year\":2017}],\"corpusId\":15749797,\"doi\":\"10.1109/ICCV.2013.399\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":19,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"cd6f8f20f549bd9d6711c1c7e89c3350ed48f8c1\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"144136729\",\"name\":\"Chen Yu\"},{\"authorId\":\"1691804\",\"name\":\"D. Ballard\"}],\"doi\":\"10.1007/3-540-36181-2_61\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"626e65927cd53e96fd257bad645abaab090e5634\",\"title\":\"Understanding Human Behaviors Based on Eye-Head-Hand Coordination\",\"url\":\"https://www.semanticscholar.org/paper/626e65927cd53e96fd257bad645abaab090e5634\",\"venue\":\"Biologically Motivated Computer Vision\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"2060684\",\"name\":\"Monica S. Castelhano\"},{\"authorId\":\"1889476\",\"name\":\"J. Henderson\"}],\"doi\":\"10.1037/0033-295X.113.4.766\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b35e4d00d9a9bfae83a8b0914eb1073a77a11d78\",\"title\":\"Contextual guidance of eye movements and attention in real-world scenes: the role of global features in object search.\",\"url\":\"https://www.semanticscholar.org/paper/b35e4d00d9a9bfae83a8b0914eb1073a77a11d78\",\"venue\":\"Psychological review\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3084719\",\"name\":\"Xiaodi Hou\"},{\"authorId\":\"5381034\",\"name\":\"L. Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4e7ec75337766f2b649bb9f99c6887ee0f1674a6\",\"title\":\"Dynamic visual attention: searching for coding length increments\",\"url\":\"https://www.semanticscholar.org/paper/4e7ec75337766f2b649bb9f99c6887ee0f1674a6\",\"venue\":\"NIPS\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50295846\",\"name\":\"K. Yamada\"},{\"authorId\":\"1751242\",\"name\":\"Yusuke Sugano\"},{\"authorId\":\"1943600\",\"name\":\"T. Okabe\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"},{\"authorId\":\"143993575\",\"name\":\"A. Sugimoto\"},{\"authorId\":\"1805464\",\"name\":\"K. Hiraki\"}],\"doi\":\"10.1007/978-3-642-25367-6_25\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f2e5b460fbc692e63e160cdef26141d236f5211f\",\"title\":\"Attention Prediction in Egocentric Video Using Motion and Visual Saliency\",\"url\":\"https://www.semanticscholar.org/paper/f2e5b460fbc692e63e160cdef26141d236f5211f\",\"venue\":\"PSIVT\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47683829\",\"name\":\"A. Fathi\"},{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1007/978-3-642-33718-5_23\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"985e1f2dc17db0d590de883cbf1e30535169cb1a\",\"title\":\"Learning to Recognize Daily Actions Using Gaze\",\"url\":\"https://www.semanticscholar.org/paper/985e1f2dc17db0d590de883cbf1e30535169cb1a\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Y. Li A. Fathi\"},{\"authorId\":null,\"name\":\"M. J.\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Rehg . Understanding egocentric activities\",\"url\":\"\",\"venue\":\"\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40466012\",\"name\":\"M. Land\"},{\"authorId\":\"2848854\",\"name\":\"M. Hayhoe\"}],\"doi\":\"10.1016/S0042-6989(01)00102-X\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"5302f7e69537e9abc2e81173f044a8651259609d\",\"title\":\"In what ways do eye movements contribute to everyday activities?\",\"url\":\"https://www.semanticscholar.org/paper/5302f7e69537e9abc2e81173f044a8651259609d\",\"venue\":\"Vision Research\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Fathi\"},{\"authorId\":null,\"name\":\"A. Farhadi\"},{\"authorId\":null,\"name\":\"J.\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Rehg . Understanding egocentric activities\",\"url\":\"\",\"venue\":\"\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143962892\",\"name\":\"L. Ren\"},{\"authorId\":\"145630395\",\"name\":\"J. Crawford\"}],\"doi\":\"10.1007/s00221-009-1811-8\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1dd6c4357ef3ec144d8967f0331d8972b98474d3\",\"title\":\"Coordinate transformations for hand-guided saccades\",\"url\":\"https://www.semanticscholar.org/paper/1dd6c4357ef3ec144d8967f0331d8972b98474d3\",\"venue\":\"Experimental Brain Research\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7326223\",\"name\":\"L. Itti\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"},{\"authorId\":\"3271571\",\"name\":\"E. Niebur\"}],\"doi\":\"10.1109/34.730558\",\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"4816f0b6f0d05da3901441bfa5cc7be044b4da8b\",\"title\":\"A Model of Saliency-Based Visual Attention for Rapid Scene Analysis\",\"url\":\"https://www.semanticscholar.org/paper/4816f0b6f0d05da3901441bfa5cc7be044b4da8b\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2899726\",\"name\":\"J. Pelz\"},{\"authorId\":\"2848854\",\"name\":\"M. Hayhoe\"},{\"authorId\":\"32259738\",\"name\":\"R. Loeber\"}],\"doi\":\"10.1007/s002210100745\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0555b0aded41322a34e8d1be6dfdedd3f6501091\",\"title\":\"The coordination of eye, head, and hand movements in a natural task\",\"url\":\"https://www.semanticscholar.org/paper/0555b0aded41322a34e8d1be6dfdedd3f6501091\",\"venue\":\"Experimental Brain Research\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Fathi\"},{\"authorId\":null,\"name\":\"A. Farhadi\"},{\"authorId\":null,\"name\":\"J.\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Rehg . Understanding egocentric activities\",\"url\":\"\",\"venue\":\"\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143774737\",\"name\":\"J. Shotton\"},{\"authorId\":\"33652486\",\"name\":\"J. Winn\"},{\"authorId\":\"1756036\",\"name\":\"C. Rother\"},{\"authorId\":\"1716777\",\"name\":\"A. Criminisi\"}],\"doi\":\"10.1007/11744023_1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fb444dc25bab36a8e273ed654d49e3841905e5af\",\"title\":\"TextonBoost: Joint Appearance, Shape and Context Modeling for Multi-class Object Recognition and Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/fb444dc25bab36a8e273ed654d49e3841905e5af\",\"venue\":\"ECCV\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Borji\"},{\"authorId\":null,\"name\":\"L.\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Itti . Stateoftheart in visual attention modeling\",\"url\":\"\",\"venue\":\"TPAMI\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3084719\",\"name\":\"Xiaodi Hou\"},{\"authorId\":\"39810944\",\"name\":\"Jonathan Harel\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"}],\"doi\":\"10.1109/TPAMI.2011.146\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"48c2b8a35ce9468b84ac032af70cf2b100f5c1fc\",\"title\":\"Image Signature: Highlighting Sparse Salient Regions\",\"url\":\"https://www.semanticscholar.org/paper/48c2b8a35ce9468b84ac032af70cf2b100f5c1fc\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"2037692\",\"name\":\"Dicky N. Sihite\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1109/CVPR.2012.6247710\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6666ffdc35f3b80f291b63e62fdcc29462662c47\",\"title\":\"Probabilistic learning of task-specific visual attention\",\"url\":\"https://www.semanticscholar.org/paper/6666ffdc35f3b80f291b63e62fdcc29462662c47\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2398457\",\"name\":\"Ekaterina H. Spriggs\"},{\"authorId\":\"143867160\",\"name\":\"F. Torre\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1109/CVPRW.2009.5204354\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1aaf8e1e8164e8968f693a100fee4343580b1d61\",\"title\":\"Temporal segmentation and activity classification from first-person sensing\",\"url\":\"https://www.semanticscholar.org/paper/1aaf8e1e8164e8968f693a100fee4343580b1d61\",\"venue\":\"2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39810944\",\"name\":\"Jonathan Harel\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"}],\"doi\":\"10.7551/mitpress/7503.003.0073\",\"intent\":[\"methodology\",\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"f412bb31ec9ef8bbef70eefc7ffd04420c1365d9\",\"title\":\"Graph-Based Visual Saliency\",\"url\":\"https://www.semanticscholar.org/paper/f412bb31ec9ef8bbef70eefc7ffd04420c1365d9\",\"venue\":\"NIPS\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144756076\",\"name\":\"Y. Lee\"},{\"authorId\":\"34724702\",\"name\":\"Joydeep Ghosh\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2012.6247820\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"616a23ebf79e35033c84797993943013c5dde5a0\",\"title\":\"Discovering important people and objects for egocentric video summarization\",\"url\":\"https://www.semanticscholar.org/paper/616a23ebf79e35033c84797993943013c5dde5a0\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143775672\",\"name\":\"Tilke Judd\"},{\"authorId\":\"1865091\",\"name\":\"Krista A. Ehinger\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/ICCV.2009.5459462\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c7614898de1cfee1a3a1c564f52c1e67879c29b3\",\"title\":\"Learning to predict where humans look\",\"url\":\"https://www.semanticscholar.org/paper/c7614898de1cfee1a3a1c564f52c1e67879c29b3\",\"venue\":\"2009 IEEE 12th International Conference on Computer Vision\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1710872\",\"name\":\"T. Brox\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/TPAMI.2010.143\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ffd97ed7408fa75b86d4c8e4280f8d730ffa2cf0\",\"title\":\"Large Displacement Optical Flow: Descriptor Matching in Variational Motion Estimation\",\"url\":\"https://www.semanticscholar.org/paper/ffd97ed7408fa75b86d4c8e4280f8d730ffa2cf0\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1109/TPAMI.2012.89\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"aa57b9bdb0736cbb38abf0a9d12047212c2a2425\",\"title\":\"State-of-the-Art in Visual Attention Modeling\",\"url\":\"https://www.semanticscholar.org/paper/aa57b9bdb0736cbb38abf0a9d12047212c2a2425\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"1781120\",\"name\":\"C. Sminchisescu\"}],\"doi\":\"10.1109/CVPR.2010.5540063\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4131a2862d9f926c6727da6dc75c8fda25f4a9e5\",\"title\":\"Constrained parametric min-cuts for automatic object segmentation\",\"url\":\"https://www.semanticscholar.org/paper/4131a2862d9f926c6727da6dc75c8fda25f4a9e5\",\"venue\":\"2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2226198\",\"name\":\"M. Nystr\\u00f6m\"},{\"authorId\":\"3165327\",\"name\":\"K. Holmqvist\"}],\"doi\":\"10.3758/BRM.42.1.188\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"8d4b356db6eaf8bff66de9a3be87e5f0ed6da67e\",\"title\":\"An adaptive algorithm for fixation, saccade, and glissade detection in eyetracking data\",\"url\":\"https://www.semanticscholar.org/paper/8d4b356db6eaf8bff66de9a3be87e5f0ed6da67e\",\"venue\":\"Behavior research methods\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"D. N. Sihite A. Borji\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Itti . Stateoftheart in visual attention modeling\",\"url\":\"\",\"venue\":\"TPAMI\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2367683\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":\"10.1109/CVPR.2012.6248010\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9e81caf9dd31b893ebbee3970c312619b7eac7bf\",\"title\":\"Detecting activities of daily living in first-person camera views\",\"url\":\"https://www.semanticscholar.org/paper/9e81caf9dd31b893ebbee3970c312619b7eac7bf\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40466012\",\"name\":\"M. Land\"}],\"doi\":\"10.1007/s00221-004-1951-9\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"002bb7cd16eef36dcc6477af9da8df2b5f985ec7\",\"title\":\"The coordination of rotations of the eyes, head and trunk in saccadic turns produced in natural situations\",\"url\":\"https://www.semanticscholar.org/paper/002bb7cd16eef36dcc6477af9da8df2b5f985ec7\",\"venue\":\"Experimental Brain Research\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47683829\",\"name\":\"A. Fathi\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1109/ICCV.2011.6126269\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bfc71c97f21b354ddfe69d17115e52db4fd4dce8\",\"title\":\"Understanding egocentric activities\",\"url\":\"https://www.semanticscholar.org/paper/bfc71c97f21b354ddfe69d17115e52db4fd4dce8\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Borji\"},{\"authorId\":null,\"name\":\"D. N. Sihite\"},{\"authorId\":null,\"name\":\"L. Itti\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Probabilistic learning of taskspecific visual attention\",\"url\":\"\",\"venue\":\"In CVPR, pages 470\\u2013477,\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46792849\",\"name\":\"A. Mishra\"},{\"authorId\":\"1697493\",\"name\":\"Y. Aloimonos\"},{\"authorId\":\"6835136\",\"name\":\"L. Cheong\"},{\"authorId\":\"1731233\",\"name\":\"A. Kassim\"}],\"doi\":\"10.1109/TPAMI.2011.171\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e44c2685799373039d058c50f9e74a73c63dbc9c\",\"title\":\"Active Visual Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/e44c2685799373039d058c50f9e74a73c63dbc9c\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1733113\",\"name\":\"T. Kanade\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1109/JPROC.2012.2200554\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ac520a1addd2d5e64aa6379072b013729e856df4\",\"title\":\"First-Person Vision\",\"url\":\"https://www.semanticscholar.org/paper/ac520a1addd2d5e64aa6379072b013729e856df4\",\"venue\":\"Proceedings of the IEEE\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1684507\",\"name\":\"Sileye O. Ba\"},{\"authorId\":\"1719610\",\"name\":\"J. Odobez\"}],\"doi\":\"10.1109/TPAMI.2010.69\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a1b3d2f4600961adeb30ce2ec094bcc22028737c\",\"title\":\"Multiperson Visual Focus of Attention from Head Pose and Meeting Contextual Cues\",\"url\":\"https://www.semanticscholar.org/paper/a1b3d2f4600961adeb30ce2ec094bcc22028737c\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2011}],\"title\":\"Learning to Predict Gaze in Egocentric Video\",\"topics\":[{\"topic\":\"Latent variable\",\"topicId\":\"79039\",\"url\":\"https://www.semanticscholar.org/topic/79039\"},{\"topic\":\"Algorithm\",\"topicId\":\"305\",\"url\":\"https://www.semanticscholar.org/topic/305\"},{\"topic\":\"IBM Notes\",\"topicId\":\"82564\",\"url\":\"https://www.semanticscholar.org/topic/82564\"},{\"topic\":\"Ubiquitous computing\",\"topicId\":\"15038\",\"url\":\"https://www.semanticscholar.org/topic/15038\"}],\"url\":\"https://www.semanticscholar.org/paper/cd6f8f20f549bd9d6711c1c7e89c3350ed48f8c1\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013}\n"