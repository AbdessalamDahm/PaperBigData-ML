"{\"abstract\":\"Significant recent progress has been made in developing high-quality saliency models. However, less effort has been undertaken on fair assessment of these models, over large standardized datasets and correctly addressing confounding factors. In this study, we pursue a critical and quantitative look at challenges (e.g., center-bias, map smoothing) in saliency modeling and the way they affect model accuracy. We quantitatively compare 32 state-of-the-art models (using the shuffled AUC score to discount center-bias) on 4 benchmark eye movement datasets, for prediction of human fixation locations and scan path sequence. We also account for the role of map smoothing. We find that, although model rankings vary, some (e.g., AWS, LG, AIM, and HouNIPS) consistently outperform other models over all datasets. Some models work well for prediction of both fixation locations and scan path sequence (e.g., Judd, GBVS). Our results show low prediction accuracy for models over emotional stimuli from the NUSEF dataset. Our last benchmark, for the first time, gauges the ability of models to decode the stimulus category from statistics of fixations, saccades, and model saliency values at fixated locations. In this test, ITTI and AIM models win over other models. Our benchmark provides a comprehensive high-level picture of the strengths and weaknesses of many popular models, and suggests future research directions in saliency modeling.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\",\"url\":\"https://www.semanticscholar.org/author/3177797\"},{\"authorId\":\"143852685\",\"name\":\"H. Tavakoli\",\"url\":\"https://www.semanticscholar.org/author/143852685\"},{\"authorId\":\"2037692\",\"name\":\"Dicky N. Sihite\",\"url\":\"https://www.semanticscholar.org/author/2037692\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\",\"url\":\"https://www.semanticscholar.org/author/7326223\"}],\"citationVelocity\":26,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"39879254\",\"name\":\"J. Zhang\"},{\"authorId\":\"47446553\",\"name\":\"M. Wang\"},{\"authorId\":\"1737218\",\"name\":\"L. Lin\"},{\"authorId\":\"2028727\",\"name\":\"X. Yang\"},{\"authorId\":null,\"name\":\"Jun Gao\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1145/3107956\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c53d869a767acb7f25488dbb00668c8c9f72466d\",\"title\":\"Saliency Detection on Light Field\",\"url\":\"https://www.semanticscholar.org/paper/c53d869a767acb7f25488dbb00668c8c9f72466d\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1395725948\",\"name\":\"Bashir Ghariba\"},{\"authorId\":\"153448727\",\"name\":\"M. Shehata\"},{\"authorId\":\"2810321\",\"name\":\"P. Mcguire\"}],\"doi\":\"10.3390/INFO10080257\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"816094379592bb9faeebbaeea4275340c731fa82\",\"title\":\"Visual Saliency Prediction Based on Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/816094379592bb9faeebbaeea4275340c731fa82\",\"venue\":\"Inf.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145519708\",\"name\":\"J. Li\"},{\"authorId\":\"2749565\",\"name\":\"Changqun Xia\"},{\"authorId\":\"2839196\",\"name\":\"Yafei Song\"},{\"authorId\":\"145021810\",\"name\":\"Shu Fang\"},{\"authorId\":\"33610144\",\"name\":\"X. Chen\"}],\"doi\":\"10.1109/ICCV.2015.30\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3e32b6325e6aa267a5f0cde1edd45c5a72ed3de6\",\"title\":\"A Data-Driven Metric for Comprehensive Evaluation of Saliency Models\",\"url\":\"https://www.semanticscholar.org/paper/3e32b6325e6aa267a5f0cde1edd45c5a72ed3de6\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1505.04364\",\"authors\":[{\"authorId\":\"2787873\",\"name\":\"Kai-Fu Yang\"},{\"authorId\":null,\"name\":\"Hui Li\"},{\"authorId\":\"2171904\",\"name\":\"Chao-Yi Li\"},{\"authorId\":\"6960951\",\"name\":\"Yong-Jie Li\"}],\"doi\":\"10.1109/TIP.2016.2572600\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5c53f5e3ccf1eb6caafe31fe4b6c4dba11d48687\",\"title\":\"Salient Structure Detection by Context-Guided Visual Search\",\"url\":\"https://www.semanticscholar.org/paper/5c53f5e3ccf1eb6caafe31fe4b6c4dba11d48687\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1901.01874\",\"authors\":[{\"authorId\":\"48355461\",\"name\":\"Yifei Huang\"},{\"authorId\":\"46947776\",\"name\":\"Zhenqiang Li\"},{\"authorId\":\"3172280\",\"name\":\"Minjie Cai\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1109/TIP.2020.3007841\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"78d95b989b807f28ef624318e3cb583ca1d73a3e\",\"title\":\"Mutual Context Network for Jointly Estimating Egocentric Gaze and Action\",\"url\":\"https://www.semanticscholar.org/paper/78d95b989b807f28ef624318e3cb583ca1d73a3e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1806.11314\",\"authors\":[{\"authorId\":\"1830032\",\"name\":\"N. Imamoglu\"},{\"authorId\":\"2858878\",\"name\":\"Y. Oishi\"},{\"authorId\":\"1890230\",\"name\":\"X. Zhang\"},{\"authorId\":\"50164924\",\"name\":\"Guanqun Ding\"},{\"authorId\":\"4639656\",\"name\":\"Y. Fang\"},{\"authorId\":\"38390863\",\"name\":\"T. Kouyama\"},{\"authorId\":\"144612113\",\"name\":\"R. Nakamura\"}],\"doi\":\"10.1109/QoMEX.2018.8463428\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9ca0c4daf08d76a63d6735c91846ec90c6ab0dfa\",\"title\":\"Hyperspectral Image Dataset for Benchmarking on Salient Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/9ca0c4daf08d76a63d6735c91846ec90c6ab0dfa\",\"venue\":\"2018 Tenth International Conference on Quality of Multimedia Experience (QoMEX)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1917344125\",\"name\":\"Samad Zabihi\"},{\"authorId\":\"2772489\",\"name\":\"Eghbal G. Mansoori\"},{\"authorId\":\"145105283\",\"name\":\"M. Yazdi\"}],\"doi\":\"10.1016/J.JVCIR.2020.102931\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"20bcfc052b6f47b0eeead32d43c3f7c0bee0a26b\",\"title\":\"Exploiting object features in deep gaze prediction models\",\"url\":\"https://www.semanticscholar.org/paper/20bcfc052b6f47b0eeead32d43c3f7c0bee0a26b\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1395725948\",\"name\":\"Bashir Ghariba\"},{\"authorId\":\"144906448\",\"name\":\"M. Shehata\"},{\"authorId\":\"2903414\",\"name\":\"P. McGuire\"}],\"doi\":\"10.7717/peerj-cs.280\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c981fee8b6cb0af49e6c22e701d760a238aee591\",\"title\":\"A novel fully convolutional network for visual saliency prediction\",\"url\":\"https://www.semanticscholar.org/paper/c981fee8b6cb0af49e6c22e701d760a238aee591\",\"venue\":\"PeerJ Comput. Sci.\",\"year\":2020},{\"arxivId\":\"1907.02336\",\"authors\":[{\"authorId\":\"150007878\",\"name\":\"Alexandre Bruckert\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"143962642\",\"name\":\"Zhi Liu\"},{\"authorId\":\"1701717\",\"name\":\"M. Christie\"},{\"authorId\":\"1789744\",\"name\":\"O. Meur\"}],\"doi\":\"10.1016/j.neucom.2020.06.131\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"79c5b0d6dc39e7b0f59690520c17e33007a6b985\",\"title\":\"Deep Saliency Models : The Quest For The Loss Function\",\"url\":\"https://www.semanticscholar.org/paper/79c5b0d6dc39e7b0f59690520c17e33007a6b985\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144018782\",\"name\":\"M. Soliman\"},{\"authorId\":\"143852685\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"1708642\",\"name\":\"Jorma T. Laaksonen\"}],\"doi\":\"10.1109/IPTA.2016.7821028\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a4788460f09baa3fa256b3b4ed405daa04c4c97c\",\"title\":\"Towards gaze-based video annotation\",\"url\":\"https://www.semanticscholar.org/paper/a4788460f09baa3fa256b3b4ed405daa04c4c97c\",\"venue\":\"2016 Sixth International Conference on Image Processing Theory, Tools and Applications (IPTA)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34560661\",\"name\":\"M. Haass\"},{\"authorId\":\"145771264\",\"name\":\"A. Wilson\"},{\"authorId\":\"34636768\",\"name\":\"L. Matzen\"},{\"authorId\":\"3424845\",\"name\":\"Kristin M. Divis\"}],\"doi\":\"10.1007/978-3-319-39907-2_12\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"fd9e2d0f2a07b07cb6382dcc39e143f4891d6a07\",\"title\":\"Modeling Human Comprehension of Data Visualizations\",\"url\":\"https://www.semanticscholar.org/paper/fd9e2d0f2a07b07cb6382dcc39e143f4891d6a07\",\"venue\":\"HCI\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47295036\",\"name\":\"Zehua Zhang\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"},{\"authorId\":\"145864858\",\"name\":\"Chen Yu\"},{\"authorId\":\"2798750\",\"name\":\"Sven Bambach\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5a089bc28160fa236f219c6760b6a48c9b8d3d10\",\"title\":\"From Coarse Attention to Fine-Grained Gaze: A Two-stage 3D Fully Convolutional Network for Predicting Eye Gaze in First Person Video\",\"url\":\"https://www.semanticscholar.org/paper/5a089bc28160fa236f219c6760b6a48c9b8d3d10\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":\"1904.08155\",\"authors\":[{\"authorId\":\"102373436\",\"name\":\"Justin Le Louedec\"},{\"authorId\":\"27568508\",\"name\":\"Thomas Guntz\"},{\"authorId\":\"145687022\",\"name\":\"J. Crowley\"},{\"authorId\":\"2903379\",\"name\":\"D. Vaufreydaz\"}],\"doi\":\"10.1145/3314111.3319827\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8c9043a50d95807c5d2d4e2e4e1c82a79a3e20a1\",\"title\":\"Deep learning investigation for chess player attention prediction using eye-tracking and game data\",\"url\":\"https://www.semanticscholar.org/paper/8c9043a50d95807c5d2d4e2e4e1c82a79a3e20a1\",\"venue\":\"ETRA\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1701293\",\"name\":\"J. Zhang\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"04a37151ce74b63f99863c84f24738c32b1225ae\",\"title\":\"Boolean Maps Attention Maps Mean Attention Map \\u03a3 Input Image Activation\",\"url\":\"https://www.semanticscholar.org/paper/04a37151ce74b63f99863c84f24738c32b1225ae\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1711499\",\"name\":\"G. Lavou\\u00e9\"},{\"authorId\":\"17271411\",\"name\":\"Fr\\u00e9d\\u00e9ric Cordier\"},{\"authorId\":\"39308883\",\"name\":\"Hyewon Seo\"},{\"authorId\":\"1755023\",\"name\":\"Mohamed-Chaker Larabi\"}],\"doi\":\"10.1111/cgf.13353\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f2e24d5ff742c28dc9decb2f7233563164c221e7\",\"title\":\"Visual Attention for Rendered 3D Shapes\",\"url\":\"https://www.semanticscholar.org/paper/f2e24d5ff742c28dc9decb2f7233563164c221e7\",\"venue\":\"Comput. Graph. Forum\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1951233\",\"name\":\"Patrik Polatsek\"},{\"authorId\":\"40351264\",\"name\":\"M. Waldner\"},{\"authorId\":\"1736888\",\"name\":\"I. Viola\"},{\"authorId\":\"3059024\",\"name\":\"P. Kapec\"},{\"authorId\":\"2678977\",\"name\":\"W. Benesova\"}],\"doi\":\"10.1016/j.cag.2018.01.010\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b4bd14734b58cfb788755201b46bb61394773b57\",\"title\":\"Exploring visual attention and saliency modeling for task-based visual analysis\",\"url\":\"https://www.semanticscholar.org/paper/b4bd14734b58cfb788755201b46bb61394773b57\",\"venue\":\"Comput. Graph.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3240394\",\"name\":\"F. Li\"},{\"authorId\":\"1698137\",\"name\":\"Xia Li\"},{\"authorId\":\"2568383\",\"name\":\"Wenbin Zou\"},{\"authorId\":null,\"name\":\"Yu Chen\"}],\"doi\":\"10.1109/MFI.2014.6997677\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e7b7f5082f5390855dc7a35741aeec290a0b51fa\",\"title\":\"Visual saliency detection by DCT coefficient dissimilarity\",\"url\":\"https://www.semanticscholar.org/paper/e7b7f5082f5390855dc7a35741aeec290a0b51fa\",\"venue\":\"2014 International Conference on Multisensor Fusion and Information Integration for Intelligent Systems (MFI)\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40217518\",\"name\":\"Q. Zhou\"},{\"authorId\":\"2576377\",\"name\":\"Yawen Fan\"},{\"authorId\":\"2147977\",\"name\":\"W. Ou\"},{\"authorId\":\"143663452\",\"name\":\"Huimin Lu\"}],\"doi\":\"10.1007/978-3-030-04946-1_20\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b40f22f8c8c4ec030b4f7e16d493d84b46a28747\",\"title\":\"Saliency Detection via Objectness Transferring\",\"url\":\"https://www.semanticscholar.org/paper/b40f22f8c8c4ec030b4f7e16d493d84b46a28747\",\"venue\":\"Cognitive Internet of Things\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2417978\",\"name\":\"Yuseok Ban\"}],\"doi\":\"10.1145/3387168.3387171\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1ae320600b3d69f1b88cd9c82289a7377d5e74bc\",\"title\":\"Detecting Protuberant Saliency from a Depth Image\",\"url\":\"https://www.semanticscholar.org/paper/1ae320600b3d69f1b88cd9c82289a7377d5e74bc\",\"venue\":\"ICVISP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1756108\",\"name\":\"N. Anantrasirichai\"},{\"authorId\":\"47043085\",\"name\":\"Katherine A J Daniels\"},{\"authorId\":\"3988217\",\"name\":\"J. Burn\"},{\"authorId\":\"2283822\",\"name\":\"I. Gilchrist\"},{\"authorId\":\"1730897\",\"name\":\"D. Bull\"}],\"doi\":\"10.1109/TCYB.2017.2734946\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"35f72d85384f4e5841587b37da2c309d678149f5\",\"title\":\"Fixation Prediction and Visual Priority Maps for Biped Locomotion\",\"url\":\"https://www.semanticscholar.org/paper/35f72d85384f4e5841587b37da2c309d678149f5\",\"venue\":\"IEEE Transactions on Cybernetics\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2866780\",\"name\":\"Neil D. B. Bruce\"},{\"authorId\":\"4218304\",\"name\":\"C. Wloka\"},{\"authorId\":\"8207080\",\"name\":\"Nick Frosst\"},{\"authorId\":\"51245102\",\"name\":\"Shafin Rahman\"},{\"authorId\":\"1727853\",\"name\":\"John K. Tsotsos\"}],\"doi\":\"10.1016/j.visres.2015.01.010\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"43236b0c968e08b7444742dc71811127288e804c\",\"title\":\"On computational modeling of visual saliency: Examining what\\u2019s right, and what\\u2019s left\",\"url\":\"https://www.semanticscholar.org/paper/43236b0c968e08b7444742dc71811127288e804c\",\"venue\":\"Vision Research\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1401645197\",\"name\":\"Marco San-Biagio\"},{\"authorId\":\"1809420\",\"name\":\"Loris Bazzani\"},{\"authorId\":\"1723008\",\"name\":\"Marco Cristani\"},{\"authorId\":\"1727204\",\"name\":\"Vittorio Murino\"}],\"doi\":\"10.1109/ICIP.2014.7025553\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4f5f62964beea0b069b36f6bf300009cb0ccac3a\",\"title\":\"Weighted bag of visual words for object recognition\",\"url\":\"https://www.semanticscholar.org/paper/4f5f62964beea0b069b36f6bf300009cb0ccac3a\",\"venue\":\"2014 IEEE International Conference on Image Processing (ICIP)\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143741775\",\"name\":\"F. Zhou\"},{\"authorId\":\"80947730\",\"name\":\"Rongguo Yao\"},{\"authorId\":\"1474234993\",\"name\":\"Guangsen Liao\"},{\"authorId\":\"3185721\",\"name\":\"Bozhi Liu\"},{\"authorId\":\"1713506\",\"name\":\"Guoping Qiu\"}],\"doi\":\"10.1109/TIP.2020.3016464\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"10d15860ece08b185b115da2b03075d7e8065f4e\",\"title\":\"Visual Saliency via Embedding Hierarchical Knowledge in a Deep Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/10d15860ece08b185b115da2b03075d7e8065f4e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1601.02852\",\"authors\":[{\"authorId\":\"49331178\",\"name\":\"Jinsoo Choi\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"2398271\",\"name\":\"In-So Kweon\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"225058b5b34c8ac42b07edaaf59186d440961f90\",\"title\":\"Human Attention Estimation for Natural Images: An Automatic Gaze Refinement Approach\",\"url\":\"https://www.semanticscholar.org/paper/225058b5b34c8ac42b07edaaf59186d440961f90\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50562082\",\"name\":\"J. Zhang\"},{\"authorId\":\"3106442\",\"name\":\"F. Malmberg\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"}],\"doi\":\"10.1007/978-3-030-04831-0_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e5628b41a109510d8c04c127a384b48c51afacb2\",\"title\":\"Boolean Map Saliency: A Surprisingly Simple Method\",\"url\":\"https://www.semanticscholar.org/paper/e5628b41a109510d8c04c127a384b48c51afacb2\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1951233\",\"name\":\"Patrik Polatsek\"},{\"authorId\":\"2678977\",\"name\":\"W. Benesova\"},{\"authorId\":\"2065653\",\"name\":\"L. Paletta\"},{\"authorId\":\"2386156\",\"name\":\"R. Perko\"}],\"doi\":\"10.1109/LSP.2016.2523339\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"e632641321aff694788104c06d3e6736e0b8c39b\",\"title\":\"Novelty-based Spatiotemporal Saliency Detection for Prediction of Gaze in Egocentric Video\",\"url\":\"https://www.semanticscholar.org/paper/e632641321aff694788104c06d3e6736e0b8c39b\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2468613\",\"name\":\"V. Kachurka\"},{\"authorId\":\"39759946\",\"name\":\"K. Madani\"},{\"authorId\":\"46355228\",\"name\":\"C. Sabourin\"},{\"authorId\":\"7687283\",\"name\":\"V. Golovko\"}],\"doi\":\"10.1007/978-3-319-19258-1_15\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"51c3e8c5618846e88cd2edb59cc93ca3c00a8c4b\",\"title\":\"From Human Eye Fixation to Human-like Autonomous Artificial Vision\",\"url\":\"https://www.semanticscholar.org/paper/51c3e8c5618846e88cd2edb59cc93ca3c00a8c4b\",\"venue\":\"IWANN\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50436294\",\"name\":\"C. Xia\"},{\"authorId\":\"50426894\",\"name\":\"Rong Quan\"}],\"doi\":\"10.1109/ACCESS.2020.2966628\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7281b31ad8f47a0fa2cd8fa20b3bc247a79f5bb5\",\"title\":\"Predicting Saccadic Eye Movements in Free Viewing of Webpages\",\"url\":\"https://www.semanticscholar.org/paper/7281b31ad8f47a0fa2cd8fa20b3bc247a79f5bb5\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2866780\",\"name\":\"Neil D. B. Bruce\"},{\"authorId\":\"8025545\",\"name\":\"Christopher Catton\"},{\"authorId\":\"8464855\",\"name\":\"S. Janjic\"}],\"doi\":\"10.1109/CVPR.2016.62\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3fedbcec10c2ba74efe3ad256850e3cdec770ff5\",\"title\":\"A Deeper Look at Saliency: Feature Contrast, Semantics, and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/3fedbcec10c2ba74efe3ad256850e3cdec770ff5\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1702.04657\",\"authors\":[{\"authorId\":\"1789744\",\"name\":\"Olivier Le Meur\"},{\"authorId\":\"2624078\",\"name\":\"Antoine Coutrot\"},{\"authorId\":\"37066739\",\"name\":\"Zhi Liu\"},{\"authorId\":\"9558003\",\"name\":\"Adrien Le Roch\"},{\"authorId\":\"5331893\",\"name\":\"Andrea Helo\"},{\"authorId\":\"38538945\",\"name\":\"Pia Rama\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c25964b946289b6823765af748e3aec90bec4d88\",\"title\":\"Computational Model for Predicting Visual Fixations from Childhood to Adulthood\",\"url\":\"https://www.semanticscholar.org/paper/c25964b946289b6823765af748e3aec90bec4d88\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1805367\",\"name\":\"Sen Jia\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7d329bb72b3497ddeaa804d389d5d5f27bdca911\",\"title\":\"Revisiting Saliency Metrics: Farthest-Neighbor Area Under Curve\",\"url\":\"https://www.semanticscholar.org/paper/7d329bb72b3497ddeaa804d389d5d5f27bdca911\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46802612\",\"name\":\"Binbin Ye\"},{\"authorId\":\"1751242\",\"name\":\"Yusuke Sugano\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1145/2578153.2578199\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c72e8d4e2bcc05d87ca0a7f4711138222e1c3bba\",\"title\":\"Influence of stimulus and viewing task types on a learning-based visual saliency model\",\"url\":\"https://www.semanticscholar.org/paper/c72e8d4e2bcc05d87ca0a7f4711138222e1c3bba\",\"venue\":\"ETRA\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39759946\",\"name\":\"K. Madani\"},{\"authorId\":\"2468613\",\"name\":\"V. Kachurka\"},{\"authorId\":\"46355228\",\"name\":\"C. Sabourin\"},{\"authorId\":\"1785410\",\"name\":\"V. Amarger\"},{\"authorId\":\"7687283\",\"name\":\"V. Golovko\"},{\"authorId\":\"47509592\",\"name\":\"Lucile Rossi\"}],\"doi\":\"10.1007/s10489-017-1053-6\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fec2c01deeff6aeae67977598d5a2d0e31024310\",\"title\":\"A human-like visual-attention-based artificial vision system for wildland firefighting assistance\",\"url\":\"https://www.semanticscholar.org/paper/fec2c01deeff6aeae67977598d5a2d0e31024310\",\"venue\":\"Applied Intelligence\",\"year\":2017},{\"arxivId\":\"1811.06458\",\"authors\":[{\"authorId\":\"51925488\",\"name\":\"David Berga\"},{\"authorId\":\"1390040513\",\"name\":\"X. R. Fdez-Vidal\"},{\"authorId\":\"2556319\",\"name\":\"X. Otazu\"},{\"authorId\":\"1760977\",\"name\":\"V. Lebor\\u00e1n\"},{\"authorId\":\"1768258\",\"name\":\"X. Pardo\"}],\"doi\":\"10.1016/j.visres.2018.10.006\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e499f7ffe8bc904aedbb072b427fbab6c6206ee6\",\"title\":\"Psychophysical evaluation of individual low-level feature influences on visual attention\",\"url\":\"https://www.semanticscholar.org/paper/e499f7ffe8bc904aedbb072b427fbab6c6206ee6\",\"venue\":\"Vision Research\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1409283465\",\"name\":\"Hamed R.-Tavakoli\"},{\"authorId\":\"145324681\",\"name\":\"A. Atyabi\"},{\"authorId\":\"29823592\",\"name\":\"Antti Rantanen\"},{\"authorId\":\"1791020\",\"name\":\"S. Laukka\"},{\"authorId\":\"1398847991\",\"name\":\"S. Nefti-Meziani\"},{\"authorId\":\"3111194\",\"name\":\"J. Heikkil\\u00e4\"}],\"doi\":\"10.1371/journal.pone.0141174\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"360a6325237a2a412f3999fac09f30e5d45c1a7b\",\"title\":\"Correction: Predicting the Valence of a Scene from Observers' Eye Movements\",\"url\":\"https://www.semanticscholar.org/paper/360a6325237a2a412f3999fac09f30e5d45c1a7b\",\"venue\":\"PloS one\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7181955\",\"name\":\"J. Han\"},{\"authorId\":\"49357208\",\"name\":\"Dingwen Zhang\"},{\"authorId\":null,\"name\":\"Gong Cheng\"},{\"authorId\":\"145021890\",\"name\":\"N. Liu\"},{\"authorId\":\"38188040\",\"name\":\"Dong Xu\"}],\"doi\":\"10.1109/MSP.2017.2749125\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"943c372336ced4b28e15e02fe8db1f4b23bf6835\",\"title\":\"Advanced Deep-Learning Techniques for Salient and Category-Specific Object Detection: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/943c372336ced4b28e15e02fe8db1f4b23bf6835\",\"venue\":\"IEEE Signal Processing Magazine\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31735819\",\"name\":\"Y. Li\"},{\"authorId\":\"1693839\",\"name\":\"X. Mou\"}],\"doi\":\"10.1117/12.2236817\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eeecc93501d1701618d839c2b3dd4018e02806dd\",\"title\":\"A local correlation based visual saliency model\",\"url\":\"https://www.semanticscholar.org/paper/eeecc93501d1701618d839c2b3dd4018e02806dd\",\"venue\":\"Optical Engineering + Applications\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1510764103\",\"name\":\"Juan Anaya-Jaimes\"},{\"authorId\":\"1510763835\",\"name\":\"Angie Garc\\u00eda-Castro\"},{\"authorId\":\"1510738925\",\"name\":\"R. E. Guti\\u00e9rrez-Carvajal\"}],\"doi\":\"10.1117/12.2557135\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1b4e5133fce53d41e3d270b5298bc3f20ab139f2\",\"title\":\"Performance of bottom-up visual attention models when compared in contextless and context awareness scenarios\",\"url\":\"https://www.semanticscholar.org/paper/1b4e5133fce53d41e3d270b5298bc3f20ab139f2\",\"venue\":\"International Conference on Machine Vision\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1680599662\",\"name\":\"Padideh Yazdan-Shahmorad\"},{\"authorId\":\"3363325\",\"name\":\"Negar Sammaknejad\"},{\"authorId\":\"9390477\",\"name\":\"F. Bakouie\"}],\"doi\":\"10.1038/s41598-020-63951-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3acb6d57adbb86eb5cc670cd84bc4f0c5c6bf9c0\",\"title\":\"Graph-Based Analysis of Visual Scanning Patterns: A Developmental Study on Green and Normal Images\",\"url\":\"https://www.semanticscholar.org/paper/3acb6d57adbb86eb5cc670cd84bc4f0c5c6bf9c0\",\"venue\":\"Scientific Reports\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1810382\",\"name\":\"Zhaohui Che\"},{\"authorId\":\"51004202\",\"name\":\"A. Borji\"},{\"authorId\":\"144826390\",\"name\":\"G. Zhai\"},{\"authorId\":\"2246414\",\"name\":\"Xiongkuo Min\"},{\"authorId\":\"1822413\",\"name\":\"Guodong Guo\"},{\"authorId\":\"1776651\",\"name\":\"P. Callet\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ad0b345436e8a2d507fbcd7e6477deb399a062a4\",\"title\":\"GazeGAN: A Generative Adversarial Saliency Model based on Invariance Analysis of Human Gaze During Scene Free Viewing\",\"url\":\"https://www.semanticscholar.org/paper/ad0b345436e8a2d507fbcd7e6477deb399a062a4\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3d173893dd3f22fd73acc16b94f0ea98469c9855\",\"title\":\"Saliency Prediction in the Deep Learning Era: Successes, Limitations, and Future Challenges\",\"url\":\"https://www.semanticscholar.org/paper/3d173893dd3f22fd73acc16b94f0ea98469c9855\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3438717\",\"name\":\"S. Azam\"},{\"authorId\":\"2455342\",\"name\":\"S. Gilani\"},{\"authorId\":\"145745152\",\"name\":\"M. Jeon\"},{\"authorId\":\"144800633\",\"name\":\"Rehan Yousaf\"},{\"authorId\":\"2967633\",\"name\":\"Jeong-Bae Kim\"}],\"doi\":\"10.5220/0005678701340142\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"6a564ac7efde70fd730ecdd1d1a1cbfd19473552\",\"title\":\"A Benchmark of Computational Models of Saliency to Predict Human Fixations in Videos\",\"url\":\"https://www.semanticscholar.org/paper/6a564ac7efde70fd730ecdd1d1a1cbfd19473552\",\"venue\":\"VISIGRAPP\",\"year\":2016},{\"arxivId\":\"1901.05002\",\"authors\":[{\"authorId\":\"51430629\",\"name\":\"Shanghua Xiao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8399ce2555984ba5e309be575ca217f0e15a7fc3\",\"title\":\"Light-weighted Saliency Detection with Distinctively Lower Memory Cost and Model Size\",\"url\":\"https://www.semanticscholar.org/paper/8399ce2555984ba5e309be575ca217f0e15a7fc3\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3251678\",\"name\":\"N. Pugeault\"},{\"authorId\":\"145398628\",\"name\":\"R. Bowden\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"bb9686ea6f154a64fbdc3551fe223da42663baa9\",\"title\":\"How much of driving is pre-attentive ?\",\"url\":\"https://www.semanticscholar.org/paper/bb9686ea6f154a64fbdc3551fe223da42663baa9\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2418491\",\"name\":\"M. Zhang\"},{\"authorId\":\"1397677751\",\"name\":\"Keng Teck Ma\"},{\"authorId\":\"9183286\",\"name\":\"Joo-Hwee Lim\"},{\"authorId\":\"153386875\",\"name\":\"Q. Zhao\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":\"10.1109/TPAMI.2018.2871688\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2f04a3d8eacfa22a299e0c5a7edcc69d0fdd5933\",\"title\":\"Anticipating Where People will Look Using Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/2f04a3d8eacfa22a299e0c5a7edcc69d0fdd5933\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2637872\",\"name\":\"Y. Niu\"},{\"authorId\":\"73708454\",\"name\":\"J. Chen\"},{\"authorId\":\"145672212\",\"name\":\"Xiao Ke\"},{\"authorId\":\"47740854\",\"name\":\"J. Chen\"}],\"doi\":\"10.1109/ACCESS.2019.2897404\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e81e1edf77c00e11976d0026b3966c62cf4978c6\",\"title\":\"Stereoscopic Image Saliency Detection Optimization: A Multi-Cue-Driven Approach\",\"url\":\"https://www.semanticscholar.org/paper/e81e1edf77c00e11976d0026b3966c62cf4978c6\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2418491\",\"name\":\"M. Zhang\"},{\"authorId\":\"21007367\",\"name\":\"K. T. Ma\"},{\"authorId\":\"153239355\",\"name\":\"J. H. Lim\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1109/ICIP.2017.8296977\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b47d27d29a178c92a64c204909cec7affbff9f9b\",\"title\":\"Foveated neural network: Gaze prediction on egocentric videos\",\"url\":\"https://www.semanticscholar.org/paper/b47d27d29a178c92a64c204909cec7affbff9f9b\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":\"1604.03605\",\"authors\":[{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"},{\"authorId\":\"152627906\",\"name\":\"T. Judd\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"}],\"doi\":\"10.1109/TPAMI.2018.2815601\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"bfdf3431ff5182b585b3b0c11fa8cbfc13a6bde4\",\"title\":\"What Do Different Evaluation Metrics Tell Us About Saliency Models?\",\"url\":\"https://www.semanticscholar.org/paper/bfdf3431ff5182b585b3b0c11fa8cbfc13a6bde4\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":\"1810.03716\",\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4df34e0194faa27078832cb5078a2af6c9d0ea9b\",\"title\":\"Saliency Prediction in the Deep Learning Era: An Empirical Investigation\",\"url\":\"https://www.semanticscholar.org/paper/4df34e0194faa27078832cb5078a2af6c9d0ea9b\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2418491\",\"name\":\"Mengmi Zhang\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"},{\"authorId\":\"153239355\",\"name\":\"J. H. Lim\"},{\"authorId\":\"47521917\",\"name\":\"Q. Zhao\"},{\"authorId\":\"1852992\",\"name\":\"G. Kreiman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eadcb8f9c0e9474dc24a5dd2dd0593a42b42163c\",\"title\":\"TaskVisual Search Task ? ? ? ? ?\",\"url\":\"https://www.semanticscholar.org/paper/eadcb8f9c0e9474dc24a5dd2dd0593a42b42163c\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1810.04456\",\"authors\":[{\"authorId\":\"1810382\",\"name\":\"Zhaohui Che\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"144826390\",\"name\":\"G. Zhai\"},{\"authorId\":\"2246414\",\"name\":\"Xiongkuo Min\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"be0d5d28fafe262e509a04b7fc7673d63f563747\",\"title\":\"Invariance Analysis of Saliency Models versus Human Gaze During Scene Free Viewing\",\"url\":\"https://www.semanticscholar.org/paper/be0d5d28fafe262e509a04b7fc7673d63f563747\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3295782\",\"name\":\"Esther Horbert\"},{\"authorId\":\"3199987\",\"name\":\"Germ\\u00e1n Mart\\u00edn Garc\\u00eda\"},{\"authorId\":\"1800953\",\"name\":\"S. Frintrop\"},{\"authorId\":\"1789756\",\"name\":\"B. Leibe\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8e1527d2eb1f38bd2a2e3c7eb2b1151f5d1f0aac\",\"title\":\"Sequence Level Salient Object Proposals for Generic Object Detection in Video\",\"url\":\"https://www.semanticscholar.org/paper/8e1527d2eb1f38bd2a2e3c7eb2b1151f5d1f0aac\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2418491\",\"name\":\"Mengmi Zhang\"},{\"authorId\":\"2343486\",\"name\":\"X. Boix\"},{\"authorId\":\"21007367\",\"name\":\"K. T. Ma\"},{\"authorId\":\"144889909\",\"name\":\"M. Jiang\"},{\"authorId\":\"153239355\",\"name\":\"J. H. Lim\"},{\"authorId\":\"153386875\",\"name\":\"Q. Zhao\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"da7db2567a81df22ede6396cb88649c42cc9b5e0\",\"title\":\"Deep Scanpath: Predicting Human Sequences of Eye-Fixations using Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/da7db2567a81df22ede6396cb88649c42cc9b5e0\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1904.01231\",\"authors\":[{\"authorId\":\"1810382\",\"name\":\"Zhaohui Che\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"144826390\",\"name\":\"G. Zhai\"},{\"authorId\":\"23993939\",\"name\":\"Suiyi Ling\"},{\"authorId\":\"1822413\",\"name\":\"Guodong Guo\"},{\"authorId\":\"1776651\",\"name\":\"P. Callet\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d32715b0e3fa60115823a61a2eb7a5ba0cdcc247\",\"title\":\"Adversarial Attacks against Deep Saliency Models\",\"url\":\"https://www.semanticscholar.org/paper/d32715b0e3fa60115823a61a2eb7a5ba0cdcc247\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2647061\",\"name\":\"Zijun Wei\"},{\"authorId\":\"32363057\",\"name\":\"H. Adeli\"},{\"authorId\":\"2356016\",\"name\":\"Minh Hoai\"},{\"authorId\":\"1696991\",\"name\":\"G. Zelinsky\"},{\"authorId\":\"145654220\",\"name\":\"D. Samaras\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"235714eb00fbb9aac753855429cd516d365eceae\",\"title\":\"Learned Region Sparsity and Diversity Also Predicts Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/235714eb00fbb9aac753855429cd516d365eceae\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2154106\",\"name\":\"Lien Dupont\"},{\"authorId\":\"40584477\",\"name\":\"K. Ooms\"},{\"authorId\":\"2754982\",\"name\":\"M. Antrop\"},{\"authorId\":\"7150168\",\"name\":\"V. V. Eetvelde\"}],\"doi\":\"10.1016/J.LANDURBPLAN.2015.12.007\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8c2e406409d0a559ec4f039bcd0f6a10e181fb81\",\"title\":\"Comparing saliency maps and eye-tracking focus maps: The potential use in visual impact assessment based on landscape photographs\",\"url\":\"https://www.semanticscholar.org/paper/8c2e406409d0a559ec4f039bcd0f6a10e181fb81\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143852685\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"1708642\",\"name\":\"Jorma T. Laaksonen\"}],\"doi\":\"10.1007/978-3-319-54407-6_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aa804644b886535440db045117a1375b47536c76\",\"title\":\"Bottom-Up Fixation Prediction Using Unsupervised Hierarchical Models\",\"url\":\"https://www.semanticscholar.org/paper/aa804644b886535440db045117a1375b47536c76\",\"venue\":\"ACCV Workshops\",\"year\":2016},{\"arxivId\":\"1611.09571\",\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/TIP.2018.2851672\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b7e336a7d3cd82ae8cd5e85d3cb62f0b6091a0e5\",\"title\":\"Predicting Human Eye Fixations via an LSTM-Based Saliency Attentive Model\",\"url\":\"https://www.semanticscholar.org/paper/b7e336a7d3cd82ae8cd5e85d3cb62f0b6091a0e5\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405907659\",\"name\":\"Ming Jiang\"},{\"authorId\":\"94011352\",\"name\":\"S. Chen\"},{\"authorId\":\"7788087\",\"name\":\"J. Yang\"},{\"authorId\":\"153386875\",\"name\":\"Q. Zhao\"}],\"doi\":\"10.1109/cvpr42600.2020.00305\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b3739681eb93295d05e9d6716f2ba94c48f047f3\",\"title\":\"Fantastic Answers and Where to Find Them: Immersive Question-Directed Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/b3739681eb93295d05e9d6716f2ba94c48f047f3\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1905.07984\",\"authors\":[{\"authorId\":\"144656873\",\"name\":\"O. Sidorov\"},{\"authorId\":\"3276066\",\"name\":\"M. Pedersen\"},{\"authorId\":\"2201320\",\"name\":\"N. W. Kim\"},{\"authorId\":\"35223379\",\"name\":\"Sumit Shekhar\"}],\"doi\":\"10.1145/3334480.3382980\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"995268b5ed1b688bc801337034e492cc49cff927\",\"title\":\"Are All the Frames Equally Important?\",\"url\":\"https://www.semanticscholar.org/paper/995268b5ed1b688bc801337034e492cc49cff927\",\"venue\":\"CHI Extended Abstracts\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2468613\",\"name\":\"V. Kachurka\"},{\"authorId\":\"39759946\",\"name\":\"K. Madani\"},{\"authorId\":\"46355228\",\"name\":\"C. Sabourin\"},{\"authorId\":\"7687283\",\"name\":\"V. Golovko\"}],\"doi\":\"10.1109/IDAACS.2015.7340736\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"afec02b655ec444fcb8160eede8e841578dd4757\",\"title\":\"Visual saliency based approach to object detection in computer vision systems: Real life applications\",\"url\":\"https://www.semanticscholar.org/paper/afec02b655ec444fcb8160eede8e841578dd4757\",\"venue\":\"2015 IEEE 8th International Conference on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications (IDAACS)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51181816\",\"name\":\"Jianming Zhang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3676c29babe1563ee64a1149d2ae2f9f1369fe25\",\"title\":\"Visual saliency computation for image analysis\",\"url\":\"https://www.semanticscholar.org/paper/3676c29babe1563ee64a1149d2ae2f9f1369fe25\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1712.02048\",\"authors\":[{\"authorId\":\"51484264\",\"name\":\"Shivanthan A.C. Yohanandan\"},{\"authorId\":\"2483748\",\"name\":\"A. Dyer\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\"},{\"authorId\":\"49077845\",\"name\":\"Andy Song\"}],\"doi\":\"10.1007/978-3-030-01231-1_15\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c07aed544463018e6afdb0cffa6ad1aa98fa6c98\",\"title\":\"Saliency Preservation in Low-Resolution Grayscale Images\",\"url\":\"https://www.semanticscholar.org/paper/c07aed544463018e6afdb0cffa6ad1aa98fa6c98\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9379498\",\"name\":\"F. Sun\"},{\"authorId\":\"145742543\",\"name\":\"W. Li\"}],\"doi\":\"10.1117/1.JEI.27.4.043014\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d50772bcae752337be1f6990297bf10c436d5926\",\"title\":\"Saliency detection based on aggregated Wasserstein distance\",\"url\":\"https://www.semanticscholar.org/paper/d50772bcae752337be1f6990297bf10c436d5926\",\"venue\":\"J. Electronic Imaging\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1409283465\",\"name\":\"Hamed R.-Tavakoli\"},{\"authorId\":\"145324681\",\"name\":\"A. Atyabi\"},{\"authorId\":\"29823592\",\"name\":\"Antti Rantanen\"},{\"authorId\":\"1791020\",\"name\":\"S. Laukka\"},{\"authorId\":\"1398847991\",\"name\":\"S. Nefti-Meziani\"},{\"authorId\":\"52005960\",\"name\":\"J. Heikkil\\u00e4\"}],\"doi\":\"10.1371/journal.pone.0138198\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9661f8d89263138627c401abaf65c5cf29d154dc\",\"title\":\"Predicting the Valence of a Scene from Observers\\u2019 Eye Movements\",\"url\":\"https://www.semanticscholar.org/paper/9661f8d89263138627c401abaf65c5cf29d154dc\",\"venue\":\"PloS one\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1452351471\",\"name\":\"D. Albayrak\"},{\"authorId\":\"1452353300\",\"name\":\"Mehmet Bahadir Askin\"},{\"authorId\":\"144992601\",\"name\":\"T. \\u00c7apin\"},{\"authorId\":\"3045902\",\"name\":\"Ufuk Celikcan\"}],\"doi\":\"10.1109/CW.2019.00019\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8869a446bd58f6c52b89b71e2778ccc9acdab2de\",\"title\":\"Visual Saliency Prediction in Dynamic Virtual Reality Environments Experienced with Head-Mounted Displays: An Exploratory Study\",\"url\":\"https://www.semanticscholar.org/paper/8869a446bd58f6c52b89b71e2778ccc9acdab2de\",\"venue\":\"2019 International Conference on Cyberworlds (CW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2787873\",\"name\":\"Kai-Fu Yang\"},{\"authorId\":null,\"name\":\"Hui Li\"},{\"authorId\":\"2171904\",\"name\":\"Chao-Yi Li\"},{\"authorId\":\"6960951\",\"name\":\"Yong-Jie Li\"}],\"doi\":\"10.1109/TIP.2016.2572600\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"6438cdd6d1ec30b58c47f45c5271f778f6173248\",\"title\":\"A Unified Framework for Salient Structure Detection by Contour-Guided Visual Search\",\"url\":\"https://www.semanticscholar.org/paper/6438cdd6d1ec30b58c47f45c5271f778f6173248\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2088899\",\"name\":\"Daria Stefic\"},{\"authorId\":\"50058816\",\"name\":\"I. Patras\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"757dde12aa67c0bb8f01493c9e3d6b265257d11a\",\"title\":\"SALIENCY USING TOPOGRAPHIC INDEPENDENT COMPONENT ANALYSIS\",\"url\":\"https://www.semanticscholar.org/paper/757dde12aa67c0bb8f01493c9e3d6b265257d11a\",\"venue\":\"\",\"year\":2014},{\"arxivId\":\"1905.06803\",\"authors\":[{\"authorId\":\"1810382\",\"name\":\"Zhaohui Che\"},{\"authorId\":\"51004202\",\"name\":\"A. Borji\"},{\"authorId\":\"144826391\",\"name\":\"Guangtao Zhai\"},{\"authorId\":\"2246414\",\"name\":\"Xiongkuo Min\"},{\"authorId\":\"1822413\",\"name\":\"Guodong Guo\"},{\"authorId\":\"134585167\",\"name\":\"P. le Callet\"}],\"doi\":\"10.1109/TIP.2019.2945857\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"183802f07521d16b78d27c5229002d49a789b298\",\"title\":\"How is Gaze Influenced by Image Transformations? Dataset and Model\",\"url\":\"https://www.semanticscholar.org/paper/183802f07521d16b78d27c5229002d49a789b298\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2691271\",\"name\":\"Jiatong Bao\"},{\"authorId\":\"2562552\",\"name\":\"Yunyi Jia\"},{\"authorId\":\"145172313\",\"name\":\"Yu Cheng\"},{\"authorId\":\"49181013\",\"name\":\"N. Xi\"}],\"doi\":\"10.3390/s150921054\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bde8bf85711cda3c468c55d3769133d45f069638\",\"title\":\"Saliency-Guided Detection of Unknown Objects in RGB-D Indoor Scenes\",\"url\":\"https://www.semanticscholar.org/paper/bde8bf85711cda3c468c55d3769133d45f069638\",\"venue\":\"Sensors\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1701293\",\"name\":\"J. Zhang\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"}],\"doi\":\"10.1109/TPAMI.2015.2473844\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"48f6af7b895465440ea13e6e85ae38d7209d5a5c\",\"title\":\"Exploiting Surroundedness for Saliency Detection: A Boolean Map Approach\",\"url\":\"https://www.semanticscholar.org/paper/48f6af7b895465440ea13e6e85ae38d7209d5a5c\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1756108\",\"name\":\"N. Anantrasirichai\"},{\"authorId\":\"2283822\",\"name\":\"I. Gilchrist\"},{\"authorId\":\"1730897\",\"name\":\"D. Bull\"}],\"doi\":\"10.1109/ICIP.2016.7532628\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fa42ef73f715a8bd85499ffeb4d6241e1dfb9b03\",\"title\":\"Visual salience and priority estimation for locomotion using a deep convolutional neural network\",\"url\":\"https://www.semanticscholar.org/paper/fa42ef73f715a8bd85499ffeb4d6241e1dfb9b03\",\"venue\":\"2016 IEEE International Conference on Image Processing (ICIP)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24962320\",\"name\":\"T. Uejima\"},{\"authorId\":\"3271571\",\"name\":\"E. Niebur\"},{\"authorId\":\"1398026219\",\"name\":\"R. Etienne-Cummings\"}],\"doi\":\"10.1109/BIOCAS.2018.8584749\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cbb0e0b82e1da40ba59da6642ead39cacee24278\",\"title\":\"Proto-Object Based Saliency Model with Second-Order Texture Feature\",\"url\":\"https://www.semanticscholar.org/paper/cbb0e0b82e1da40ba59da6642ead39cacee24278\",\"venue\":\"2018 IEEE Biomedical Circuits and Systems Conference (BioCAS)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1744930\",\"name\":\"T. Ren\"},{\"authorId\":\"38384862\",\"name\":\"Yan Liu\"},{\"authorId\":\"33687539\",\"name\":\"Ran Ju\"},{\"authorId\":\"39914710\",\"name\":\"Gangshan Wu\"}],\"doi\":\"10.1007/s11042-015-2875-z\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d7b37975003a4d4166e54c2cbcc5094734fc1286\",\"title\":\"How important is location information in saliency detection of natural images\",\"url\":\"https://www.semanticscholar.org/paper/d7b37975003a4d4166e54c2cbcc5094734fc1286\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47067741\",\"name\":\"Han Jiang\"},{\"authorId\":\"1963167\",\"name\":\"Karmen Dykstra\"},{\"authorId\":\"143973061\",\"name\":\"Jacob Whitehill\"}],\"doi\":\"10.1109/FG.2018.00094\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1c646545a001eb4e32a4a2ee3cb713dcb316da14\",\"title\":\"Predicting When Teachers Look at Their Students in 1-on-1 Tutoring Sessions\",\"url\":\"https://www.semanticscholar.org/paper/1c646545a001eb4e32a4a2ee3cb713dcb316da14\",\"venue\":\"2018 13th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2018)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"46887280\",\"name\":\"Giuseppe Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"49859d84cd3884d7bc61b5049222e454c46ff8ac\",\"title\":\"Attentive ConvLSTM Learned Priors ( x 2 ) \\u03bc , \\u03c3\\u03bc , \\u03c3\\u03bc , \\u03c3 Dilated Convolutional Network Input Image Saliency\",\"url\":\"https://www.semanticscholar.org/paper/49859d84cd3884d7bc61b5049222e454c46ff8ac\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30469750\",\"name\":\"Qiuxia Lai\"},{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"144812765\",\"name\":\"S. Khan\"},{\"authorId\":\"11901550\",\"name\":\"J. Shen\"},{\"authorId\":\"145947590\",\"name\":\"Hanqiu Sun\"},{\"authorId\":\"144951205\",\"name\":\"Ling Shao\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ba651908d6cb9dd10635ee4d44069d9cb7399eb7\",\"title\":\"Human vs Machine Attention in Neural Networks: A Comparative Study\",\"url\":\"https://www.semanticscholar.org/paper/ba651908d6cb9dd10635ee4d44069d9cb7399eb7\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1811.06308\",\"authors\":[{\"authorId\":\"51925488\",\"name\":\"David Berga\"},{\"authorId\":\"2556319\",\"name\":\"X. Otazu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"603bead9775c7523efe6c56431ab7f124b1bdee8\",\"title\":\"A Neurodynamic model of Saliency prediction in V1\",\"url\":\"https://www.semanticscholar.org/paper/603bead9775c7523efe6c56431ab7f124b1bdee8\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145873103\",\"name\":\"Shailee Jain\"},{\"authorId\":\"145870789\",\"name\":\"S. S. Kamath\"}],\"doi\":\"10.1007/978-3-319-56687-0_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"08484b4dbee2a5d0b5a5337282f0d25893b13c2d\",\"title\":\"Saliency Prediction for Visual Regions of Interest with Applications in Advertising\",\"url\":\"https://www.semanticscholar.org/paper/08484b4dbee2a5d0b5a5337282f0d25893b13c2d\",\"venue\":\"VAAM/FFER@ICPR\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40217518\",\"name\":\"Q. Zhou\"},{\"authorId\":\"2317822\",\"name\":\"Nianyi Li\"},{\"authorId\":\"10212134\",\"name\":\"J. Chen\"},{\"authorId\":\"145688734\",\"name\":\"Shu Cai\"},{\"authorId\":\"1686678\",\"name\":\"L. Latecki\"}],\"doi\":\"10.1109/ICASSP.2015.7178213\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"112e03cc5294bafa7d8e7d3879792da14ade5bdc\",\"title\":\"Salient object detection via background contrast\",\"url\":\"https://www.semanticscholar.org/paper/112e03cc5294bafa7d8e7d3879792da14ade5bdc\",\"venue\":\"2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2215920\",\"name\":\"Vlad Hosu\"},{\"authorId\":\"47177940\",\"name\":\"F. Hahn\"},{\"authorId\":\"47670521\",\"name\":\"O. Wiedemann\"},{\"authorId\":\"4289089\",\"name\":\"Sung-Hwan Jung\"},{\"authorId\":\"1775428\",\"name\":\"D. Saupe\"}],\"doi\":\"10.1109/PCS.2016.7906397\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d45ee19ddd9a4245f958a142cfd819eda7aceeb7\",\"title\":\"Saliency-driven image coding improves overall perceived JPEG quality\",\"url\":\"https://www.semanticscholar.org/paper/d45ee19ddd9a4245f958a142cfd819eda7aceeb7\",\"venue\":\"2016 Picture Coding Symposium (PCS)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39632942\",\"name\":\"L. Dunbar\"},{\"authorId\":\"2537623\",\"name\":\"F. Nicolls\"}],\"doi\":\"10.1109/ROBOMECH.2015.7359491\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"71506e8992eaf99d971043243ea61098c4cac4fe\",\"title\":\"Using the earth mover's distance for perceptually meaningful visual saliency\",\"url\":\"https://www.semanticscholar.org/paper/71506e8992eaf99d971043243ea61098c4cac4fe\",\"venue\":\"2015 Pattern Recognition Association of South Africa and Robotics and Mechatronics International Conference (PRASA-RobMech)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145800409\",\"name\":\"Anna Volokitin\"},{\"authorId\":\"3037160\",\"name\":\"Michael Gygli\"},{\"authorId\":\"2343486\",\"name\":\"X. Boix\"}],\"doi\":\"10.1109/CVPR.2016.65\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e2d6767123e26ab804401278e5d6941c9484f6f3\",\"title\":\"Predicting When Saliency Maps are Accurate and Eye Fixations Consistent\",\"url\":\"https://www.semanticscholar.org/paper/e2d6767123e26ab804401278e5d6941c9484f6f3\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2007931\",\"name\":\"Kao Zhang\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"},{\"authorId\":\"1792817\",\"name\":\"S. Liu\"}],\"doi\":\"10.1109/TIP.2020.3036749\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"51b23ce1f48d769a31a4a4f4982fbfe5d4de41f4\",\"title\":\"A Spatial-Temporal Recurrent Neural Network for Video Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/51b23ce1f48d769a31a4a4f4982fbfe5d4de41f4\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34570209\",\"name\":\"Kshitij Dwivedi\"},{\"authorId\":\"145729589\",\"name\":\"Nitin Singh\"},{\"authorId\":\"1392783891\",\"name\":\"Sabari R. Shanmugham\"},{\"authorId\":\"153792660\",\"name\":\"M. Kumar\"}],\"doi\":\"10.1007/978-981-32-9291-8_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c794ac6077b2926e05cf0a6f2ca0a3263ada6139\",\"title\":\"DeepAttent: Saliency Prediction with Deep Multi-scale Residual Network\",\"url\":\"https://www.semanticscholar.org/paper/c794ac6077b2926e05cf0a6f2ca0a3263ada6139\",\"venue\":\"CVIP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1763785\",\"name\":\"Luming Zhang\"},{\"authorId\":\"1720243\",\"name\":\"X. Li\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":null,\"name\":\"Yi Yang\"},{\"authorId\":\"1780668\",\"name\":\"Yingjie Xia\"}],\"doi\":\"10.1109/TCYB.2015.2400821\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5120c8e0e2ce4bdce8a5474b55f5b5297e68170b\",\"title\":\"Weakly Supervised Human Fixations Prediction\",\"url\":\"https://www.semanticscholar.org/paper/5120c8e0e2ce4bdce8a5474b55f5b5297e68170b\",\"venue\":\"IEEE Transactions on Cybernetics\",\"year\":2016},{\"arxivId\":\"1803.09125\",\"authors\":[{\"authorId\":\"48355461\",\"name\":\"Yifei Huang\"},{\"authorId\":\"3172280\",\"name\":\"Minjie Cai\"},{\"authorId\":\"46947776\",\"name\":\"Zhenqiang Li\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1007/978-3-030-01225-0_46\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"7e236d33dce5d30348aeb494e491a13468133b4e\",\"title\":\"Predicting Gaze in Egocentric Video by Learning Task-dependent Attention Transition\",\"url\":\"https://www.semanticscholar.org/paper/7e236d33dce5d30348aeb494e491a13468133b4e\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49938170\",\"name\":\"Z. He\"},{\"authorId\":\"46772058\",\"name\":\"X. Chen\"},{\"authorId\":\"145456009\",\"name\":\"L. Sun\"}],\"doi\":\"10.1155/2015/875735\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e786f401fbb022eee27f8844589eb601705c216b\",\"title\":\"Saliency Mapping Enhanced by Structure Tensor\",\"url\":\"https://www.semanticscholar.org/paper/e786f401fbb022eee27f8844589eb601705c216b\",\"venue\":\"Comput. Intell. Neurosci.\",\"year\":2015},{\"arxivId\":\"1902.10993\",\"authors\":[{\"authorId\":\"1830032\",\"name\":\"N. Imamoglu\"},{\"authorId\":\"50164924\",\"name\":\"Guanqun Ding\"},{\"authorId\":\"4639656\",\"name\":\"Y. Fang\"},{\"authorId\":\"2554424\",\"name\":\"Asako Kanezaki\"},{\"authorId\":\"38390863\",\"name\":\"T. Kouyama\"},{\"authorId\":\"144612113\",\"name\":\"R. Nakamura\"}],\"doi\":\"10.1109/ICASSP.2019.8682522\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"93a0d9b9d48c77553a306cfec13a73f9a7ff08ec\",\"title\":\"Salient Object Detection on Hyperspectral Images Using Features Learned from Unsupervised Segmentation Task\",\"url\":\"https://www.semanticscholar.org/paper/93a0d9b9d48c77553a306cfec13a73f9a7ff08ec\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":\"1905.10693\",\"authors\":[{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"51004202\",\"name\":\"A. Borji\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"},{\"authorId\":\"1776374\",\"name\":\"Juho Kannala\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"827b68bdb1e38bb75e0db020ce764d25997b4c60\",\"title\":\"DAVE: A Deep Audio-Visual Embedding for Dynamic Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/827b68bdb1e38bb75e0db020ce764d25997b4c60\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2088899\",\"name\":\"Daria Stefic\"},{\"authorId\":\"50058816\",\"name\":\"I. Patras\"}],\"doi\":\"10.1109/ICIP.2014.7025225\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"76a9c40370401d1c5328ddd90bef6a52f68d4ad7\",\"title\":\"Learning visual saliency using topographic independent component analysis\",\"url\":\"https://www.semanticscholar.org/paper/76a9c40370401d1c5328ddd90bef6a52f68d4ad7\",\"venue\":\"2014 IEEE International Conference on Image Processing (ICIP)\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49890030\",\"name\":\"Youqiang Zhang\"},{\"authorId\":\"143743503\",\"name\":\"Feng Dai\"},{\"authorId\":\"3193532\",\"name\":\"Yike Ma\"},{\"authorId\":\"49404814\",\"name\":\"Hongliang Li\"},{\"authorId\":\"49033408\",\"name\":\"Q. Zhao\"},{\"authorId\":\"121310224\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.1109/JSTSP.2019.2955824\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"059dcad31aca80e2393fb2ccdea0dffc4499e1be\",\"title\":\"Saliency Prediction Network for $360^\\\\circ$ Videos\",\"url\":\"https://www.semanticscholar.org/paper/059dcad31aca80e2393fb2ccdea0dffc4499e1be\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32363057\",\"name\":\"H. Adeli\"},{\"authorId\":\"6318398\",\"name\":\"F. Vitu\"},{\"authorId\":\"1696991\",\"name\":\"G. Zelinsky\"}],\"doi\":\"10.1523/JNEUROSCI.0825-16.2016\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"397f990b3f3857671792cc0a2c7be411ae50fc39\",\"title\":\"A Model of the Superior Colliculus Predicts Fixation Locations during Scene Viewing and Visual Search\",\"url\":\"https://www.semanticscholar.org/paper/397f990b3f3857671792cc0a2c7be411ae50fc39\",\"venue\":\"The Journal of Neuroscience\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47119743\",\"name\":\"X. Wang\"},{\"authorId\":\"2287283\",\"name\":\"David Lindlbauer\"},{\"authorId\":\"1777246\",\"name\":\"C. Lessig\"},{\"authorId\":\"13413677\",\"name\":\"M. Maertens\"},{\"authorId\":\"1751554\",\"name\":\"M. Alexa\"}],\"doi\":\"10.1109/MCG.2016.47\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ab87baaf566e791a5d3fbb750395832ce73c4ec9\",\"title\":\"Measuring the Visual Salience of 3D Printed Objects\",\"url\":\"https://www.semanticscholar.org/paper/ab87baaf566e791a5d3fbb750395832ce73c4ec9\",\"venue\":\"IEEE Computer Graphics and Applications\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2997408\",\"name\":\"Matthias K\\u00fcmmerer\"},{\"authorId\":\"49737748\",\"name\":\"Thomas S. A. Wallis\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":\"10.1073/pnas.1510393112\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"01058e4aabd61571da9e43a618834c90aabaf691\",\"title\":\"Information-theoretic model comparison unifies saliency metrics\",\"url\":\"https://www.semanticscholar.org/paper/01058e4aabd61571da9e43a618834c90aabaf691\",\"venue\":\"Proceedings of the National Academy of Sciences\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2007931\",\"name\":\"Kao Zhang\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"}],\"doi\":\"10.1109/TCSVT.2018.2883305\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6c54dfdace2a84d4b70fc31e87a3053be09cd863\",\"title\":\"Video Saliency Prediction Based on Spatial-Temporal Two-Stream Network\",\"url\":\"https://www.semanticscholar.org/paper/6c54dfdace2a84d4b70fc31e87a3053be09cd863\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"145076397\",\"name\":\"Yun Ren\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"}],\"doi\":\"10.1109/ICCV.2015.445\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c9e88b0b46713e412962820ba238396064689b47\",\"title\":\"Learning to Predict Saliency on Face Images\",\"url\":\"https://www.semanticscholar.org/paper/c9e88b0b46713e412962820ba238396064689b47\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29810094\",\"name\":\"S. Winkler\"},{\"authorId\":\"3309825\",\"name\":\"Florian M. Savoy\"},{\"authorId\":\"1742936\",\"name\":\"S. Ramanathan\"}],\"doi\":\"10.1117/12.2042433\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a4ec5c20e2493943cf2281a6843ff4ddcbed5f1\",\"title\":\"X-Eye: A reference format for eye tracking data to facilitate analyses across databases\",\"url\":\"https://www.semanticscholar.org/paper/8a4ec5c20e2493943cf2281a6843ff4ddcbed5f1\",\"venue\":\"Electronic Imaging\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8683310\",\"name\":\"R. Naqvi\"},{\"authorId\":\"15668895\",\"name\":\"M. Arsalan\"},{\"authorId\":\"4634733\",\"name\":\"K. Park\"}],\"doi\":\"10.3390/s17040862\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1ad8ef3589bf76531c410493510fe949eb553408\",\"title\":\"Fuzzy System-Based Target Selection for a NIR Camera-Based Gaze Tracker\",\"url\":\"https://www.semanticscholar.org/paper/1ad8ef3589bf76531c410493510fe949eb553408\",\"venue\":\"Sensors\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2068253\",\"name\":\"A. Yaghoobi\"},{\"authorId\":\"143852685\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"3213064\",\"name\":\"J. R\\u00f6ning\"}],\"doi\":\"10.1007/978-3-319-16181-5_28\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b02ad34cc26ed5c8d565eaef475ca007d6221cbc\",\"title\":\"Affordances in Video Surveillance\",\"url\":\"https://www.semanticscholar.org/paper/b02ad34cc26ed5c8d565eaef475ca007d6221cbc\",\"venue\":\"ECCV Workshops\",\"year\":2014},{\"arxivId\":\"1704.07434\",\"authors\":[{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"38314306\",\"name\":\"Rakshith Shetty\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"1708642\",\"name\":\"Jorma T. Laaksonen\"}],\"doi\":\"10.1109/ICCV.2017.272\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e4a11cc697c94fdda9eedbac7d83a865646bd4cc\",\"title\":\"Paying Attention to Descriptions Generated by Image Captioning Models\",\"url\":\"https://www.semanticscholar.org/paper/e4a11cc697c94fdda9eedbac7d83a865646bd4cc\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1898053\",\"name\":\"Ala Aboudib\"},{\"authorId\":\"144916029\",\"name\":\"Vincent Gripon\"},{\"authorId\":\"2804081\",\"name\":\"G. Coppin\"}],\"doi\":\"10.1007/s12559-016-9430-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"53e7ec3f66743d9c21d6fd9d61057b9522be1108\",\"title\":\"A Biologically Inspired Framework for Visual Information Processing and an Application on Modeling Bottom-Up Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/53e7ec3f66743d9c21d6fd9d61057b9522be1108\",\"venue\":\"Cognitive Computation\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40092548\",\"name\":\"Thuyen Ngo\"},{\"authorId\":\"50591689\",\"name\":\"B. S. Manjunath\"}],\"doi\":\"10.1109/ICIP.2017.8296920\",\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"67dd2d536023814f4b29023436a0f34b6ce1850d\",\"title\":\"Saccade gaze prediction using a recurrent neural network\",\"url\":\"https://www.semanticscholar.org/paper/67dd2d536023814f4b29023436a0f34b6ce1850d\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":\"1807.11926\",\"authors\":[{\"authorId\":\"2418491\",\"name\":\"Mengmi Zhang\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"},{\"authorId\":\"153239355\",\"name\":\"J. H. Lim\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"},{\"authorId\":\"1852992\",\"name\":\"G. Kreiman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"efb01e07ee994fec890ad83b89c9b652349da50e\",\"title\":\"What am I searching for?\",\"url\":\"https://www.semanticscholar.org/paper/efb01e07ee994fec890ad83b89c9b652349da50e\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2007.12562\",\"authors\":[{\"authorId\":\"1832290473\",\"name\":\"Carola Figueroa-Flores\"},{\"authorId\":\"3262395\",\"name\":\"B. Raducanu\"},{\"authorId\":\"51925488\",\"name\":\"David Berga\"},{\"authorId\":\"2820687\",\"name\":\"Joost van de Weijer\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9452d851c2cc617d2e67515d409f6f608f4eac97\",\"title\":\"Hallucinating Saliency Maps for Fine-Grained Image Classification for Limited Data Domains\",\"url\":\"https://www.semanticscholar.org/paper/9452d851c2cc617d2e67515d409f6f608f4eac97\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39759946\",\"name\":\"K. Madani\"},{\"authorId\":\"2468613\",\"name\":\"V. Kachurka\"},{\"authorId\":\"46355228\",\"name\":\"C. Sabourin\"},{\"authorId\":\"7687283\",\"name\":\"V. Golovko\"}],\"doi\":\"10.1007/S00500-017-2931-X\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0ecf109e9292f040bce121086065f48391739999\",\"title\":\"A soft-computing-based approach to artificial visual attention using human eye-fixation paradigm: toward a human-like skill in robot vision\",\"url\":\"https://www.semanticscholar.org/paper/0ecf109e9292f040bce121086065f48391739999\",\"venue\":\"Soft Comput.\",\"year\":2019},{\"arxivId\":\"2002.10540\",\"authors\":[{\"authorId\":null,\"name\":\"Sen Jia\"},{\"authorId\":\"2866780\",\"name\":\"Neil D. B. Bruce\"}],\"doi\":\"10.1109/cvpr42600.2020.00274\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"68d3ff5267302cd396b831cd3a67fb0b2002d711\",\"title\":\"Revisiting Saliency Metrics: Farthest-Neighbor Area Under Curve\",\"url\":\"https://www.semanticscholar.org/paper/68d3ff5267302cd396b831cd3a67fb0b2002d711\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46199065\",\"name\":\"Chih-Yang Chen\"},{\"authorId\":\"4277629\",\"name\":\"D. Matrov\"},{\"authorId\":\"1733084797\",\"name\":\"R. Veale\"},{\"authorId\":\"2223545\",\"name\":\"H. Onoe\"},{\"authorId\":\"51496697\",\"name\":\"M. Yoshida\"},{\"authorId\":\"1705283\",\"name\":\"K. Miura\"},{\"authorId\":\"49366294\",\"name\":\"T. Isa\"}],\"doi\":\"10.1101/2020.05.27.120428\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9a347e59b862c65a95f2611966cbafd813ae2683\",\"title\":\"Common properties of visually-guided saccadic behavior and bottom-up attention in marmoset, macaque, and human\",\"url\":\"https://www.semanticscholar.org/paper/9a347e59b862c65a95f2611966cbafd813ae2683\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2366042\",\"name\":\"Pingmei Xu\"},{\"authorId\":\"1751242\",\"name\":\"Yusuke Sugano\"},{\"authorId\":\"3194727\",\"name\":\"Andreas Bulling\"}],\"doi\":\"10.1145/2858036.2858479\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6384a0b3940a71c2abe2447d9180a1d075a1a189\",\"title\":\"Spatio-Temporal Modeling and Prediction of Visual Attention in Graphical User Interfaces\",\"url\":\"https://www.semanticscholar.org/paper/6384a0b3940a71c2abe2447d9180a1d075a1a189\",\"venue\":\"CHI\",\"year\":2016},{\"arxivId\":\"1809.00644\",\"authors\":[{\"authorId\":\"51430629\",\"name\":\"Shanghua Xiao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"155d51a08dc15e7a77a3e7f317ab434e5842de8b\",\"title\":\"Learning Saliency Prediction From Sparse Fixation Pixel Map\",\"url\":\"https://www.semanticscholar.org/paper/155d51a08dc15e7a77a3e7f317ab434e5842de8b\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2366042\",\"name\":\"Pingmei Xu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c89d3b0945d60697dbfd2a93e2dba30f767eb0a4\",\"title\":\"UNDERSTANDING AND PREDICTING HUMAN VISUAL ATTENTION\",\"url\":\"https://www.semanticscholar.org/paper/c89d3b0945d60697dbfd2a93e2dba30f767eb0a4\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143852685\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"3180583\",\"name\":\"Victoria Yanulevskaya\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"},{\"authorId\":\"52005960\",\"name\":\"J. Heikkil\\u00e4\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":\"10.1109/ICPR.2014.798\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3522fdac173c7452cd02fd9d4e5b708e2a55d35c\",\"title\":\"Emotional Valence Recognition, Analysis of Salience and Eye Movements\",\"url\":\"https://www.semanticscholar.org/paper/3522fdac173c7452cd02fd9d4e5b708e2a55d35c\",\"venue\":\"2014 22nd International Conference on Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48926031\",\"name\":\"Chen Xia\"},{\"authorId\":\"145877494\",\"name\":\"J. Han\"},{\"authorId\":\"46534309\",\"name\":\"Fei Qi\"},{\"authorId\":\"143713952\",\"name\":\"G. Shi\"}],\"doi\":\"10.1109/TIP.2019.2897966\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ed56acb6964af0c814266f289d46859c33b8b5be\",\"title\":\"Predicting Human Saccadic Scanpaths Based on Iterative Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/ed56acb6964af0c814266f289d46859c33b8b5be\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"1705.10546\",\"authors\":[{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"2253528\",\"name\":\"F. Ahmed\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"1708642\",\"name\":\"Jorma T. Laaksonen\"}],\"doi\":\"10.1109/CVPR.2017.673\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"42f4aeff8219942153104c3ed5d9d661663d0cd3\",\"title\":\"Saliency Revisited: Analysis of Mouse Movements Versus Fixations\",\"url\":\"https://www.semanticscholar.org/paper/42f4aeff8219942153104c3ed5d9d661663d0cd3\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3756587\",\"name\":\"Daniel Walper\"},{\"authorId\":\"1712238074\",\"name\":\"Julia Kassau\"},{\"authorId\":\"9526899\",\"name\":\"P. Methfessel\"},{\"authorId\":\"70293194\",\"name\":\"Timo Pronold\"},{\"authorId\":\"1917767\",\"name\":\"W. Einh\\u00e4user\"}],\"doi\":\"10.1145/3379156.3391351\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"af46644138c04ae75f1120715033f8552997b135\",\"title\":\"Optimizing user interfaces in food production: gaze tracking is more sensitive for A-B-testing than behavioral data alone\",\"url\":\"https://www.semanticscholar.org/paper/af46644138c04ae75f1120715033f8552997b135\",\"venue\":\"ETRA Short Papers\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134310797\",\"name\":\"Luis A. Leiva\"},{\"authorId\":\"46364507\",\"name\":\"Y. Xue\"},{\"authorId\":\"1977519209\",\"name\":\"Avya Bansal\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"1977535062\",\"name\":\"Tu\\u00f0\\u00e7e K\\u00f6ro\\u00f0lu\"},{\"authorId\":\"1977523763\",\"name\":\"Jingzhou Du\"},{\"authorId\":\"3229795\",\"name\":\"N. Dayama\"},{\"authorId\":\"2663734\",\"name\":\"Antti Oulasvirta\"}],\"doi\":\"10.1145/3379503.3403557\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7a74c3af655784448f353620b86a2cf69e937ed8\",\"title\":\"Understanding Visual Saliency in Mobile User Interfaces\",\"url\":\"https://www.semanticscholar.org/paper/7a74c3af655784448f353620b86a2cf69e937ed8\",\"venue\":\"MobileHCI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"},{\"authorId\":\"2203252\",\"name\":\"M. Borkin\"},{\"authorId\":\"2426112\",\"name\":\"N. Kim\"},{\"authorId\":\"143758231\",\"name\":\"H. Pfister\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"}],\"doi\":\"10.1007/978-3-319-47024-5_14\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"67089163a209c68318f17b25d744d680d73a7f80\",\"title\":\"Eye Fixation Metrics for Large Scale Evaluation and Comparison of Information Visualizations\",\"url\":\"https://www.semanticscholar.org/paper/67089163a209c68318f17b25d744d680d73a7f80\",\"venue\":\"ETVIS\",\"year\":2015},{\"arxivId\":\"1901.10957\",\"authors\":[{\"authorId\":\"1937240\",\"name\":\"Tariq Alshawi\"},{\"authorId\":\"2493314\",\"name\":\"Z. Long\"},{\"authorId\":\"9202076\",\"name\":\"G. Al-Regib\"}],\"doi\":\"10.1109/ICME.2016.7552913\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"11ab60ec340d8c32f2e5bf9614d5dc41afa563a6\",\"title\":\"Understanding spatial correlation in eye-fixation maps for visual attention in videos\",\"url\":\"https://www.semanticscholar.org/paper/11ab60ec340d8c32f2e5bf9614d5dc41afa563a6\",\"venue\":\"2016 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1810382\",\"name\":\"Zhaohui Che\"},{\"authorId\":\"51004202\",\"name\":\"A. Borji\"},{\"authorId\":\"144826390\",\"name\":\"G. Zhai\"},{\"authorId\":\"2246414\",\"name\":\"Xiongkuo Min\"},{\"authorId\":\"1822413\",\"name\":\"Guodong Guo\"},{\"authorId\":\"1776651\",\"name\":\"P. Callet\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c01a827fd687791b92e393b203028fa1bca4c5ff\",\"title\":\"Leverage eye-movement data for saliency modeling: Invariance Analysis and a Robust New Model\",\"url\":\"https://www.semanticscholar.org/paper/c01a827fd687791b92e393b203028fa1bca4c5ff\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1504.06755\",\"authors\":[{\"authorId\":\"2366042\",\"name\":\"Pingmei Xu\"},{\"authorId\":\"1865091\",\"name\":\"Krista A. Ehinger\"},{\"authorId\":\"2507239\",\"name\":\"Y. Zhang\"},{\"authorId\":\"37737599\",\"name\":\"Adam Finkelstein\"},{\"authorId\":\"1697413\",\"name\":\"S. Kulkarni\"},{\"authorId\":\"40599257\",\"name\":\"J. Xiao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3433627f803953280b66ae1576d083fc9a68385a\",\"title\":\"TurkerGaze: Crowdsourcing Saliency with Webcam based Eye Tracking\",\"url\":\"https://www.semanticscholar.org/paper/3433627f803953280b66ae1576d083fc9a68385a\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47417815\",\"name\":\"Di Liu\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"}],\"doi\":\"10.1016/j.jvcir.2018.10.002\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6a0abd13e2a124ae7c4403c0d964508af624f701\",\"title\":\"Disparity tuning guided stereoscopic saliency detection for eye fixation prediction\",\"url\":\"https://www.semanticscholar.org/paper/6a0abd13e2a124ae7c4403c0d964508af624f701\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2018},{\"arxivId\":\"2009.08373\",\"authors\":[{\"authorId\":\"1947172233\",\"name\":\"M. Sclar\"},{\"authorId\":\"1946864700\",\"name\":\"G. Bujia\"},{\"authorId\":\"145184799\",\"name\":\"S. Vita\"},{\"authorId\":\"3985471\",\"name\":\"G. Solovey\"},{\"authorId\":\"2941980\",\"name\":\"J. E. Kamienkowski\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5d4dbd9b7c504d33403027e721468847d8d91fdb\",\"title\":\"Modeling human visual search: A combined Bayesian searcher and saliency map approach for eye movement guidance in natural scenes\",\"url\":\"https://www.semanticscholar.org/paper/5d4dbd9b7c504d33403027e721468847d8d91fdb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1767658\",\"name\":\"Yingyue Xu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"bb6a1cab0cfd4adc3de102eb8835d40ffd99874c\",\"title\":\"Computational modeling for visual attention analysis\",\"url\":\"https://www.semanticscholar.org/paper/bb6a1cab0cfd4adc3de102eb8835d40ffd99874c\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143852685\",\"name\":\"H. Tavakoli\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"142ab7253bbf1d0144faa741d0c5c83033b362bc\",\"title\":\"Visual saliency and eye movement : modeling and applications\",\"url\":\"https://www.semanticscholar.org/paper/142ab7253bbf1d0144faa741d0c5c83033b362bc\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50219447\",\"name\":\"Zheng Wang\"},{\"authorId\":\"145811527\",\"name\":\"J. Ren\"},{\"authorId\":\"119745921\",\"name\":\"Dong Zhang\"},{\"authorId\":\"2736861\",\"name\":\"M. Sun\"},{\"authorId\":\"145054089\",\"name\":\"J. Jiang\"}],\"doi\":\"10.1016/j.neucom.2018.01.076\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a35ba189491bb8ae59df3c8b41a5f157e34231d2\",\"title\":\"A deep-learning based feature hybrid framework for spatiotemporal saliency detection inside videos\",\"url\":\"https://www.semanticscholar.org/paper/a35ba189491bb8ae59df3c8b41a5f157e34231d2\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":\"1806.10257\",\"authors\":[{\"authorId\":\"2749565\",\"name\":\"Changqun Xia\"},{\"authorId\":\"46275685\",\"name\":\"Jia Li\"},{\"authorId\":\"5349760\",\"name\":\"Jinming Su\"},{\"authorId\":\"3177797\",\"name\":\"Ali Borji\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c5d08cf523115ec8a3c656f1435291d0fb0cfa73\",\"title\":\"Learning a Saliency Evaluation Metric Using Crowdsourced Perceptual Judgments\",\"url\":\"https://www.semanticscholar.org/paper/c5d08cf523115ec8a3c656f1435291d0fb0cfa73\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b0c001b2f619ee55114b29ded767c0295d88ce02\",\"title\":\"Computational perception for multi-modal document understanding\",\"url\":\"https://www.semanticscholar.org/paper/b0c001b2f619ee55114b29ded767c0295d88ce02\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1901.01550\",\"authors\":[{\"authorId\":\"1937240\",\"name\":\"Tariq Alshawi\"},{\"authorId\":\"2493314\",\"name\":\"Z. Long\"},{\"authorId\":\"9202076\",\"name\":\"G. Al-Regib\"}],\"doi\":\"10.1109/TIP.2018.2813159\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"29dc368ee29bbabf6f3be0504e78154f72ce570b\",\"title\":\"Unsupervised Uncertainty Estimation Using Spatiotemporal Cues in Video Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/29dc368ee29bbabf6f3be0504e78154f72ce570b\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39168231\",\"name\":\"Guangyu Zhong\"},{\"authorId\":\"34469457\",\"name\":\"R. Liu\"},{\"authorId\":\"1839803\",\"name\":\"J. Cao\"},{\"authorId\":\"4642456\",\"name\":\"Z. Su\"}],\"doi\":\"10.1007/s00371-015-1077-z\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a97fa1561def3768f2e300e511b4fde407887092\",\"title\":\"A generalized nonlocal mean framework with object-level cues for saliency detection\",\"url\":\"https://www.semanticscholar.org/paper/a97fa1561def3768f2e300e511b4fde407887092\",\"venue\":\"The Visual Computer\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2811292\",\"name\":\"Rachit Dubey\"},{\"authorId\":\"32134234\",\"name\":\"A. Dave\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1007/978-3-319-16811-1_22\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5cc9354d077649d56808c648cc77184f0d9dc7b9\",\"title\":\"Improving Saliency Models by Predicting Human Fixation Patches\",\"url\":\"https://www.semanticscholar.org/paper/5cc9354d077649d56808c648cc77184f0d9dc7b9\",\"venue\":\"ACCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143770997\",\"name\":\"Haroon Qureshi\"},{\"authorId\":\"2544782\",\"name\":\"Nicolas Tizon\"}],\"doi\":\"10.1007/978-1-4939-2026-6_6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"22f893dc677d621923ec31b7906a747fab217f42\",\"title\":\"Visual Attention Modelling in a 3D Context\",\"url\":\"https://www.semanticscholar.org/paper/22f893dc677d621923ec31b7906a747fab217f42\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143612308\",\"name\":\"D. Parks\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1016/j.visres.2014.10.027\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"de133b03624e91db8861ca94f075998dc26259ee\",\"title\":\"Augmented saliency model using automatic 3D head pose detection and learned gaze following in natural scenes\",\"url\":\"https://www.semanticscholar.org/paper/de133b03624e91db8861ca94f075998dc26259ee\",\"venue\":\"Vision Research\",\"year\":2015},{\"arxivId\":\"1411.5878\",\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"37535930\",\"name\":\"Ming-Ming Cheng\"},{\"authorId\":\"40175280\",\"name\":\"Huaizu Jiang\"},{\"authorId\":\"97483166\",\"name\":\"J. Li\"}],\"doi\":\"10.1007/s41095-019-0149-9\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f6bbd62f7b5a33d10a6ca8935db76c58f6256d25\",\"title\":\"Salient object detection: A survey\",\"url\":\"https://www.semanticscholar.org/paper/f6bbd62f7b5a33d10a6ca8935db76c58f6256d25\",\"venue\":\"Computational Visual Media\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21120270\",\"name\":\"Olivier Le Meur\"},{\"authorId\":\"2624078\",\"name\":\"A. Coutrot\"},{\"authorId\":\"37066739\",\"name\":\"Zhi Liu\"},{\"authorId\":\"2432723\",\"name\":\"P. R\\u00e4m\\u00e4\"},{\"authorId\":\"120123035\",\"name\":\"Adrien Le Roch\"},{\"authorId\":\"5331893\",\"name\":\"A. Helo\"}],\"doi\":\"10.1109/TIP.2017.2722238\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8fa384ac69b93f9bcf075203cf64bc15da76546c\",\"title\":\"Visual Attention Saccadic Models Learn to Emulate Gaze Patterns From Childhood to Adulthood\",\"url\":\"https://www.semanticscholar.org/paper/8fa384ac69b93f9bcf075203cf64bc15da76546c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1744930\",\"name\":\"T. Ren\"},{\"authorId\":\"33687539\",\"name\":\"Ran Ju\"},{\"authorId\":\"38384862\",\"name\":\"Yan Liu\"},{\"authorId\":\"39914710\",\"name\":\"Gangshan Wu\"}],\"doi\":\"10.1145/2632856.2632945\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"654da235cb5f29f57276b07ae9d03d9752b943ea\",\"title\":\"How Important is Location in Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/654da235cb5f29f57276b07ae9d03d9752b943ea\",\"venue\":\"ICIMCS '14\",\"year\":2014},{\"arxivId\":\"1703.06554\",\"authors\":[{\"authorId\":\"1730952\",\"name\":\"Ravi Kiran Sarvadevabhatla\"},{\"authorId\":\"144440277\",\"name\":\"S. Suresh\"},{\"authorId\":\"134685329\",\"name\":\"R. Venkatesh Babu\"}],\"doi\":\"10.1109/TIP.2017.2675539\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"062ebea1c4861cf90f18c369b3d729b79b076f8f\",\"title\":\"Object Category Understanding via Eye Fixations on Freehand Sketches\",\"url\":\"https://www.semanticscholar.org/paper/062ebea1c4861cf90f18c369b3d729b79b076f8f\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1167/14.3.29\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"639722c2c23e8c8033b715d039e1f14d79cb970e\",\"title\":\"Defending Yarbus: eye movements reveal observers' task.\",\"url\":\"https://www.semanticscholar.org/paper/639722c2c23e8c8033b715d039e1f14d79cb970e\",\"venue\":\"Journal of vision\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40217518\",\"name\":\"Q. Zhou\"},{\"authorId\":\"145688734\",\"name\":\"Shu Cai\"},{\"authorId\":\"40534924\",\"name\":\"Shaojun Zhu\"},{\"authorId\":\"143918844\",\"name\":\"Baoyu Zheng\"}],\"doi\":\"10.1007/978-3-319-16811-1_15\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"790bce6cbe30ef9bc4431c988d0d747da1c6bb1d\",\"title\":\"Salient Object Detection Using Window Mask Transferring with Multi-layer Background Contrast\",\"url\":\"https://www.semanticscholar.org/paper/790bce6cbe30ef9bc4431c988d0d747da1c6bb1d\",\"venue\":\"ACCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2418491\",\"name\":\"M. Zhang\"},{\"authorId\":\"21007367\",\"name\":\"K. T. Ma\"},{\"authorId\":\"153239355\",\"name\":\"J. H. Lim\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":\"10.1109/CVPR.2017.377\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f95e349489aa48fc57494aab101d58c496cc35f5\",\"title\":\"Deep Future Gaze: Gaze Anticipation on Egocentric Videos Using Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/f95e349489aa48fc57494aab101d58c496cc35f5\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47539491\",\"name\":\"J. Zhang\"},{\"authorId\":\"47446553\",\"name\":\"M. Wang\"},{\"authorId\":\"1761159\",\"name\":\"S. Zhang\"},{\"authorId\":\"1720243\",\"name\":\"X. Li\"},{\"authorId\":\"1748808\",\"name\":\"X. Wu\"}],\"doi\":\"10.1109/TNNLS.2015.2464316\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"710c11be249e99ec15af16a3ddbd1e7cef63107e\",\"title\":\"Spatiochromatic Context Modeling for Color Saliency Analysis\",\"url\":\"https://www.semanticscholar.org/paper/710c11be249e99ec15af16a3ddbd1e7cef63107e\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24282910\",\"name\":\"Aoqi Li\"},{\"authorId\":\"48379249\",\"name\":\"Yingxue Zhang\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"}],\"doi\":\"10.1109/ICME.2017.8019507\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"15b998dce2e493c584e2d135b1180d31ba280307\",\"title\":\"Scanpath mining of eye movement trajectories for visual attention analysis\",\"url\":\"https://www.semanticscholar.org/paper/15b998dce2e493c584e2d135b1180d31ba280307\",\"venue\":\"2017 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2017},{\"arxivId\":\"1610.06449\",\"authors\":[{\"authorId\":\"143852685\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"1708642\",\"name\":\"Jorma T. Laaksonen\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"}],\"doi\":\"10.1016/j.neucom.2017.03.018\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9995d891a5d6737eadd7b386de23fbd7aef77903\",\"title\":\"Exploiting inter-image similarity and ensemble of extreme learners for fixation prediction using deep features\",\"url\":\"https://www.semanticscholar.org/paper/9995d891a5d6737eadd7b386de23fbd7aef77903\",\"venue\":\"Neurocomputing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145378987\",\"name\":\"Yan Luo\"},{\"authorId\":\"3026404\",\"name\":\"Yongkang Wong\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1109/CVPR.2015.7299141\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3ba45341925ffe39c1061997af428cc3523479ea\",\"title\":\"Label Consistent Quadratic Surrogate model for visual saliency prediction\",\"url\":\"https://www.semanticscholar.org/paper/3ba45341925ffe39c1061997af428cc3523479ea\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143852685\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"38314306\",\"name\":\"Rakshith Shetty\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"1708642\",\"name\":\"J. Laaksonen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"204184e8a54c42bac589c19c3fa0c5d3d2c6009b\",\"title\":\"Can Saliency Information Benefit Image Captioning Models?\",\"url\":\"https://www.semanticscholar.org/paper/204184e8a54c42bac589c19c3fa0c5d3d2c6009b\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46614560\",\"name\":\"A. Verma\"},{\"authorId\":\"144774497\",\"name\":\"D. Sen\"}],\"doi\":\"10.23919/EUSIPCO.2019.8902643\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"46e752ef221c95dd367ce28165d198d179bba5dc\",\"title\":\"HMM-based Convolutional LSTM for Visual Scanpath Prediction\",\"url\":\"https://www.semanticscholar.org/paper/46e752ef221c95dd367ce28165d198d179bba5dc\",\"venue\":\"2019 27th European Signal Processing Conference (EUSIPCO)\",\"year\":2019},{\"arxivId\":\"1702.04292\",\"authors\":[{\"authorId\":\"26902477\",\"name\":\"A. Rasouli\"},{\"authorId\":\"1727853\",\"name\":\"John K. Tsotsos\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cbf612d59cb611f2f45d341d617b3cf595d1c77f\",\"title\":\"Integrating Three Mechanisms of Visual Attention for Active Visual Search\",\"url\":\"https://www.semanticscholar.org/paper/cbf612d59cb611f2f45d341d617b3cf595d1c77f\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3045902\",\"name\":\"Ufuk Celikcan\"},{\"authorId\":\"1452353300\",\"name\":\"Mehmet Bahadir Askin\"},{\"authorId\":\"1452351471\",\"name\":\"D. Albayrak\"},{\"authorId\":\"144992601\",\"name\":\"T. \\u00c7apin\"}],\"doi\":\"10.1016/j.cag.2020.03.006\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7f703ac2d9e216a0aee90d4c69e6f8ee350869fe\",\"title\":\"Deep into visual saliency for immersive VR environments rendered in real-time\",\"url\":\"https://www.semanticscholar.org/paper/7f703ac2d9e216a0aee90d4c69e6f8ee350869fe\",\"venue\":\"Comput. Graph.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3376641\",\"name\":\"A. Nuthmann\"},{\"authorId\":\"1917767\",\"name\":\"W. Einh\\u00e4user\"},{\"authorId\":\"46510545\",\"name\":\"Immo Schuetz\"}],\"doi\":\"10.3389/fnhum.2017.00491\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e1c2d5aeb31709e9ffd5ffe0b259805f38d16ae5\",\"title\":\"How Well Can Saliency Models Predict Fixation Selection in Scenes Beyond Central Bias? A New Approach to Model Evaluation Using Generalized Linear Mixed Models\",\"url\":\"https://www.semanticscholar.org/paper/e1c2d5aeb31709e9ffd5ffe0b259805f38d16ae5\",\"venue\":\"Front. Hum. Neurosci.\",\"year\":2017},{\"arxivId\":\"2011.04076\",\"authors\":[{\"authorId\":\"48090391\",\"name\":\"Qiang Li\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b7b9c782a5a73118fb4e7f07ba5f40d14b66a6b1\",\"title\":\"An HVS-Oriented Saliency Map Prediction Modeling\",\"url\":\"https://www.semanticscholar.org/paper/b7b9c782a5a73118fb4e7f07ba5f40d14b66a6b1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"},{\"authorId\":\"4265660\",\"name\":\"E. M. DeGennaro\"},{\"authorId\":\"2533298\",\"name\":\"R. Rajalingham\"},{\"authorId\":\"35236664\",\"name\":\"H. Ruda\"},{\"authorId\":\"51028388\",\"name\":\"J. Zhang\"},{\"authorId\":\"51421045\",\"name\":\"J. K. Tsotsos\"}],\"doi\":\"10.1016/j.visres.2015.04.007\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"de4bcded33b562a8af7f601d17c3202965eb4034\",\"title\":\"Towards the quantitative evaluation of visual attention models\",\"url\":\"https://www.semanticscholar.org/paper/de4bcded33b562a8af7f601d17c3202965eb4034\",\"venue\":\"Vision Research\",\"year\":2015},{\"arxivId\":\"1412.5027\",\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":\"10.1109/TIP.2014.2383320\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8bb4e1ddfec4c5868c31685b6dfe8673df1d3e38\",\"title\":\"What is a Salient Object? A Dataset and a Baseline Model for Salient Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/8bb4e1ddfec4c5868c31685b6dfe8673df1d3e38\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1398172020\",\"name\":\"Jes\\u00fas Guti\\u00e9rrez-Cill\\u00e1n\"},{\"authorId\":\"145316303\",\"name\":\"E. J. David\"},{\"authorId\":\"2624078\",\"name\":\"A. Coutrot\"},{\"authorId\":\"21340060\",\"name\":\"Matthieu Perreira Da Silva\"},{\"authorId\":\"1776651\",\"name\":\"P. Callet\"}],\"doi\":\"10.1109/QoMEX.2018.8463369\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a63d4653ed0b453f61c91e4e3aab2c1fa77f12bc\",\"title\":\"Introducing UN Salient360! Benchmark: A platform for evaluating visual attention models for 360\\u00b0 contents\",\"url\":\"https://www.semanticscholar.org/paper/a63d4653ed0b453f61c91e4e3aab2c1fa77f12bc\",\"venue\":\"2018 Tenth International Conference on Quality of Multimedia Experience (QoMEX)\",\"year\":2018},{\"arxivId\":\"1409.7686\",\"authors\":[{\"authorId\":\"2997408\",\"name\":\"Matthias K\\u00fcmmerer\"},{\"authorId\":\"39928067\",\"name\":\"T. Wallis\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":\"10.15496/PUBLIKATION-4858\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"abfd3d1fb0c0117905978a470897db053dc7afbb\",\"title\":\"How close are we to understanding image-based saliency?\",\"url\":\"https://www.semanticscholar.org/paper/abfd3d1fb0c0117905978a470897db053dc7afbb\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1720841\",\"name\":\"X. Wang\"},{\"authorId\":\"3419220\",\"name\":\"Jialun Dai\"},{\"authorId\":\"48269582\",\"name\":\"Yafei Zhu\"},{\"authorId\":\"2336297\",\"name\":\"Haiyong Zheng\"},{\"authorId\":\"2926414\",\"name\":\"Xiaoyan Qiao\"}],\"doi\":\"10.1117/1.JEI.25.2.023020\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bbbde179d91caa07b7fc9a01ba5c09930e796220\",\"title\":\"Spectral saliency via automatic adaptive amplitude spectrum analysis\",\"url\":\"https://www.semanticscholar.org/paper/bbbde179d91caa07b7fc9a01ba5c09930e796220\",\"venue\":\"J. Electronic Imaging\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"1975008\",\"name\":\"Andreas Lennartz\"},{\"authorId\":\"1739588\",\"name\":\"M. Pomplun\"}],\"doi\":\"10.1016/j.neucom.2014.07.055\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d25974eb72fe9ba020a40064cd7b68df137c0358\",\"title\":\"What do eyes reveal about the mind?: Algorithmic inference of search targets from fixations\",\"url\":\"https://www.semanticscholar.org/paper/d25974eb72fe9ba020a40064cd7b68df137c0358\",\"venue\":\"Neurocomputing\",\"year\":2015},{\"arxivId\":\"1510.02927\",\"authors\":[{\"authorId\":\"1784761\",\"name\":\"S. Kruthiventi\"},{\"authorId\":\"50430041\",\"name\":\"Kumar Ayush\"},{\"authorId\":\"144682140\",\"name\":\"R. Venkatesh Babu\"}],\"doi\":\"10.1109/TIP.2017.2710620\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1295cbaf3b03de2eb8c79530289f5939d7819e5c\",\"title\":\"DeepFix: A Fully Convolutional Neural Network for Predicting Human Eye Fixations\",\"url\":\"https://www.semanticscholar.org/paper/1295cbaf3b03de2eb8c79530289f5939d7819e5c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2417978\",\"name\":\"Yuseok Ban\"},{\"authorId\":\"1939652\",\"name\":\"Minglei Li\"},{\"authorId\":\"48243862\",\"name\":\"Lei Sun\"},{\"authorId\":\"2316043\",\"name\":\"Q. Huo\"}],\"doi\":\"10.1109/ICIP.2017.8296909\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aff1e7d608479160332b012968eed86a31921efc\",\"title\":\"Fingertip detection based on protuberant saliency from depth image\",\"url\":\"https://www.semanticscholar.org/paper/aff1e7d608479160332b012968eed86a31921efc\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":\"1912.09581\",\"authors\":[{\"authorId\":\"2105451\",\"name\":\"Kaifu Yang\"},{\"authorId\":\"1388747144\",\"name\":\"Wenwen Jiang\"},{\"authorId\":\"26374549\",\"name\":\"Tengfei Zhan\"},{\"authorId\":\"6960951\",\"name\":\"Yong-Jie Li\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"796406e940f99bbf9e34d3c01521e2a971a92ea5\",\"title\":\"Line Drawings of Natural Scenes Guide Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/796406e940f99bbf9e34d3c01521e2a971a92ea5\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38370207\",\"name\":\"Dekel Abeles\"},{\"authorId\":\"34745005\",\"name\":\"Roy Amit\"},{\"authorId\":\"1403245031\",\"name\":\"S. Yuval-Greenberg\"}],\"doi\":\"10.1371/journal.pone.0198242\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a03a924d87a7e0fa3a6d2b6972b2eb467a02feb6\",\"title\":\"Oculomotor behavior during non-visual tasks: The role of visual saliency\",\"url\":\"https://www.semanticscholar.org/paper/a03a924d87a7e0fa3a6d2b6972b2eb467a02feb6\",\"venue\":\"PloS one\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1767658\",\"name\":\"Yingyue Xu\"},{\"authorId\":\"46761465\",\"name\":\"Xiaopeng Hong\"},{\"authorId\":\"2512942\",\"name\":\"Qiuhai He\"},{\"authorId\":\"1757287\",\"name\":\"G. Zhao\"},{\"authorId\":\"145962204\",\"name\":\"M. Pietik\\u00e4inen\"}],\"doi\":\"10.1007/978-3-319-25903-1_55\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6b222931c89aed5a4dce3719a439722a5516a4ff\",\"title\":\"A Task-Driven Eye Tracking Dataset for Visual Attention Analysis\",\"url\":\"https://www.semanticscholar.org/paper/6b222931c89aed5a4dce3719a439722a5516a4ff\",\"venue\":\"ACIVS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"16991648\",\"name\":\"Pierre Duthon\"},{\"authorId\":\"3129191\",\"name\":\"J. Quinton\"},{\"authorId\":\"144297121\",\"name\":\"M. Colomb\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"653c5fadd1b64987aa357cd13b9f8a9f105ca1a7\",\"title\":\"Visual saliency on the road: model and database dependent detection\",\"url\":\"https://www.semanticscholar.org/paper/653c5fadd1b64987aa357cd13b9f8a9f105ca1a7\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2951229\",\"name\":\"Hisham Cholakkal\"},{\"authorId\":\"2027515\",\"name\":\"J. Johnson\"},{\"authorId\":\"145383458\",\"name\":\"D. Rajan\"}],\"doi\":\"10.1109/CVPR.2016.570\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"47e7ded00144817f2513a6b3d8f6a9f9bb9c8c2c\",\"title\":\"Backtracking ScSPM Image Classifier for Weakly Supervised Top-Down Saliency\",\"url\":\"https://www.semanticscholar.org/paper/47e7ded00144817f2513a6b3d8f6a9f9bb9c8c2c\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144645142\",\"name\":\"M. Jiang\"},{\"authorId\":\"2343486\",\"name\":\"X. Boix\"},{\"authorId\":\"144596911\",\"name\":\"Gemma Roig\"},{\"authorId\":\"1946538\",\"name\":\"J. Xu\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1109/TNNLS.2015.2496306\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0137aa37210b305a041b1155b0dae6537e2780d1\",\"title\":\"Learning to Predict Sequences of Human Visual Fixations\",\"url\":\"https://www.semanticscholar.org/paper/0137aa37210b305a041b1155b0dae6537e2780d1\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2724702\",\"name\":\"Ziming Zhao\"},{\"authorId\":\"1720429\",\"name\":\"Gail-Joon Ahn\"},{\"authorId\":\"7150554\",\"name\":\"H. Hu\"}],\"doi\":\"10.1145/2701423\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"405b7750df7f920d34ef59b95059941f5ad9500f\",\"title\":\"Picture Gesture Authentication\",\"url\":\"https://www.semanticscholar.org/paper/405b7750df7f920d34ef59b95059941f5ad9500f\",\"venue\":\"ACM Trans. Inf. Syst. Secur.\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6838061\",\"name\":\"J. Wang\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"9363144\",\"name\":\"C.-C. Jay Kuo\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1109/TIP.2016.2522380\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"57cf6509377136530db3e72e4fd907665a6a4831\",\"title\":\"Learning a Combined Model of Visual Saliency for Fixation Prediction\",\"url\":\"https://www.semanticscholar.org/paper/57cf6509377136530db3e72e4fd907665a6a4831\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145556868\",\"name\":\"Ali Mahdi\"},{\"authorId\":\"50708949\",\"name\":\"Mei Su\"},{\"authorId\":\"37777082\",\"name\":\"M. Schlesinger\"},{\"authorId\":\"47901325\",\"name\":\"J. Qin\"}],\"doi\":\"10.1109/TCDS.2017.2696439\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6546a9b48810edfb527e3af45cb5ee36f573cf5a\",\"title\":\"A Comparison Study of Saliency Models for Fixation Prediction on Infants and Adults\",\"url\":\"https://www.semanticscholar.org/paper/6546a9b48810edfb527e3af45cb5ee36f573cf5a\",\"venue\":\"IEEE Transactions on Cognitive and Developmental Systems\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143770997\",\"name\":\"Haroon Qureshi\"},{\"authorId\":\"39574452\",\"name\":\"Markus Ludwig\"}],\"doi\":\"10.5220/0005303305120516\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0f4cdfe389fff70a1a8f0895b595167883aff2ec\",\"title\":\"Motion Compensated Temporal Image Signature Approach\",\"url\":\"https://www.semanticscholar.org/paper/0f4cdfe389fff70a1a8f0895b595167883aff2ec\",\"venue\":\"VISAPP\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150007878\",\"name\":\"Alexandre Bruckert\"},{\"authorId\":\"50811413\",\"name\":\"Yat Hong Jacky Lam\"},{\"authorId\":\"1701717\",\"name\":\"M. Christie\"},{\"authorId\":\"1789744\",\"name\":\"O. Meur\"}],\"doi\":\"10.1109/ICIP.2019.8803596\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e698a6c7cc2f7cdcf551833fb15ae3e3f9c1cfe8\",\"title\":\"Deep Learning For Inter-Observer Congruency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/e698a6c7cc2f7cdcf551833fb15ae3e3f9c1cfe8\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3251678\",\"name\":\"N. Pugeault\"},{\"authorId\":\"145398628\",\"name\":\"R. Bowden\"}],\"doi\":\"10.1109/TVT.2015.2487826\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"11a092c80e64e36f41178e779345d17d03fb9c6f\",\"title\":\"How Much of Driving Is Preattentive?\",\"url\":\"https://www.semanticscholar.org/paper/11a092c80e64e36f41178e779345d17d03fb9c6f\",\"venue\":\"IEEE Transactions on Vehicular Technology\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1800953\",\"name\":\"S. Frintrop\"},{\"authorId\":\"3199987\",\"name\":\"Germ\\u00e1n Mart\\u00edn Garc\\u00eda\"},{\"authorId\":\"1786309\",\"name\":\"A. Cremers\"}],\"doi\":\"10.1109/ICPR.2014.404\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6845cc4e9ceb13e8204cfe8ec818c91b0cc21f52\",\"title\":\"A Cognitive Approach for Object Discovery\",\"url\":\"https://www.semanticscholar.org/paper/6845cc4e9ceb13e8204cfe8ec818c91b0cc21f52\",\"venue\":\"2014 22nd International Conference on Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41133681\",\"name\":\"Jayachandra Chilukamari\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c1697e396a20aa5a421cb79b7ed2e626b5c28133\",\"title\":\"A computational model of visual attention\",\"url\":\"https://www.semanticscholar.org/paper/c1697e396a20aa5a421cb79b7ed2e626b5c28133\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2468613\",\"name\":\"V. Kachurka\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"501b619a0c321aee8d9506e318e5c8f22d563f2f\",\"title\":\"Contribution to Perception and Artificial Bio-inspired Visual Attention for Acquisition and Conceptualization of Knowledge in Autonomous Robotics. (Contribution \\u00e0 la perception et l'attention visuelle artificielle bio-inspir\\u00e9e pour acquisition et conceptualisation de la connaissance en robotique aut\",\"url\":\"https://www.semanticscholar.org/paper/501b619a0c321aee8d9506e318e5c8f22d563f2f\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36465167\",\"name\":\"F. Leit\\u00e3o\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d4eae81c7b7f1d5e9f9d85e3340ed10b9c355cec\",\"title\":\"Predicting Eye Fixations with a Deep Reconstruction-Based Approach\",\"url\":\"https://www.semanticscholar.org/paper/d4eae81c7b7f1d5e9f9d85e3340ed10b9c355cec\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2656263\",\"name\":\"Kamel Guissous\"},{\"authorId\":\"1398826846\",\"name\":\"V. Gouet-Brunet\"}],\"doi\":\"10.1109/IPTA.2017.8310131\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"97fd7cefd5d4a08957dd6c70c2c886f5cb25b493\",\"title\":\"Image retrieval based on saliency for urban image contents\",\"url\":\"https://www.semanticscholar.org/paper/97fd7cefd5d4a08957dd6c70c2c886f5cb25b493\",\"venue\":\"2017 Seventh International Conference on Image Processing Theory, Tools and Applications (IPTA)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1740586345\",\"name\":\"Naoyuki Awano\"},{\"authorId\":\"1740584291\",\"name\":\"Y. Hayashi\"}],\"doi\":\"10.1007/s41095-020-0169-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"431dddd3de684ac0d208f46dceef3fe206444e1d\",\"title\":\"Psychological potential field and human eye fixation on binary line-drawing images: A comparative experimental study\",\"url\":\"https://www.semanticscholar.org/paper/431dddd3de684ac0d208f46dceef3fe206444e1d\",\"venue\":\"Computational Visual Media\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4722457\",\"name\":\"Boris Qu\\u00e9tard\"},{\"authorId\":\"145671681\",\"name\":\"J. C. Quinton\"},{\"authorId\":\"2634712\",\"name\":\"M. Mermillod\"},{\"authorId\":\"143961022\",\"name\":\"L. Barca\"},{\"authorId\":\"1746694\",\"name\":\"G. Pezzulo\"},{\"authorId\":\"144297121\",\"name\":\"M. Colomb\"},{\"authorId\":\"4842272\",\"name\":\"M. Izaute\"}],\"doi\":\"10.1167/16.11.28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d12f4c827739b91db063162b01bb0da25f24966f\",\"title\":\"Differential effects of visual uncertainty and contextual guidance on perceptual decisions: Evidence from eye and mouse tracking in visual search.\",\"url\":\"https://www.semanticscholar.org/paper/d12f4c827739b91db063162b01bb0da25f24966f\",\"venue\":\"Journal of vision\",\"year\":2016},{\"arxivId\":\"2006.11035\",\"authors\":[{\"authorId\":\"1753459288\",\"name\":\"Lapo Faggi\"},{\"authorId\":\"3409251\",\"name\":\"A. Betti\"},{\"authorId\":\"9952297\",\"name\":\"Dario Zanca\"},{\"authorId\":\"1760309\",\"name\":\"S. Melacci\"},{\"authorId\":\"1491505431\",\"name\":\"M. Gori\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"37d54769754c613ff494035f56f7c42ae22ad3fd\",\"title\":\"Wave Propagation of Visual Stimuli in Focus of Attention\",\"url\":\"https://www.semanticscholar.org/paper/37d54769754c613ff494035f56f7c42ae22ad3fd\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":877732,\"doi\":\"10.1109/ICCV.2013.118\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":20,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"05375a7489f0a84d47a316bacb4d86e8a7bda0df\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"2295441\",\"name\":\"K. Fukunaga\"},{\"authorId\":\"2322936\",\"name\":\"L. Hostetler\"}],\"doi\":\"10.1109/TIT.1975.1055330\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"98431da7222ee3fe12d277facf5ca1561c56d4f3\",\"title\":\"The estimation of the gradient of a density function, with applications in pattern recognition\",\"url\":\"https://www.semanticscholar.org/paper/98431da7222ee3fe12d277facf5ca1561c56d4f3\",\"venue\":\"IEEE Trans. Inf. Theory\",\"year\":1975},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1789744\",\"name\":\"O. Meur\"},{\"authorId\":\"1776651\",\"name\":\"P. Callet\"},{\"authorId\":\"144812989\",\"name\":\"D. Barba\"}],\"doi\":\"10.1016/j.visres.2007.06.015\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"122134f9242785383949caaaea4601861beebad8\",\"title\":\"Predicting visual fixations on video based on low-level visual features\",\"url\":\"https://www.semanticscholar.org/paper/122134f9242785383949caaaea4601861beebad8\",\"venue\":\"Vision Research\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37210378\",\"name\":\"Peng Bian\"},{\"authorId\":\"48571513\",\"name\":\"L. Zhang\"}],\"doi\":\"10.1007/978-3-642-02490-0_31\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6cf3c7f5b0d47d5a638f68bc03af41c107121ace\",\"title\":\"Biological Plausibility of Spectral Domain Approach for Spatiotemporal Visual Saliency\",\"url\":\"https://www.semanticscholar.org/paper/6cf3c7f5b0d47d5a638f68bc03af41c107121ace\",\"venue\":\"ICONIP\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3369864\",\"name\":\"B. Tatler\"},{\"authorId\":\"34931109\",\"name\":\"R. Baddeley\"},{\"authorId\":\"2283822\",\"name\":\"I. Gilchrist\"}],\"doi\":\"10.1016/j.visres.2004.09.017\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ae38ed953333fb39eb671fce0247db65a09b3a80\",\"title\":\"Visual correlates of fixation selection: effects of scale and time\",\"url\":\"https://www.semanticscholar.org/paper/ae38ed953333fb39eb671fce0247db65a09b3a80\",\"venue\":\"Vision Research\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"M. Mancas\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Computational attention: Modelisation and application to audio and image processing\",\"url\":\"\",\"venue\":\"PhD. thesis\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3063894\",\"name\":\"Junchi Yan\"},{\"authorId\":\"48211673\",\"name\":\"J. Liu\"},{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"40264733\",\"name\":\"Zhibin Niu\"},{\"authorId\":\"1701515\",\"name\":\"Y. Liu\"}],\"doi\":\"10.1109/ICIP.2010.5652280\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a216994a701af18e856daabb9e53756ce660a0bb\",\"title\":\"Visual saliency detection via rank-sparsity decomposition\",\"url\":\"https://www.semanticscholar.org/paper/a216994a701af18e856daabb9e53756ce660a0bb\",\"venue\":\"2010 IEEE International Conference on Image Processing\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152172815\",\"name\":\"P. Lang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"788e2f5a24784ce952eec8a57902a6f03cd9318c\",\"title\":\"International affective picture system (IAPS) : affective ratings of pictures and instruction manual\",\"url\":\"https://www.semanticscholar.org/paper/788e2f5a24784ce952eec8a57902a6f03cd9318c\",\"venue\":\"\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Borji\"},{\"authorId\":null,\"name\":\"D. N. Sihite\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and L\",\"url\":\"\",\"venue\":\"Itti. Objects do not predict fixations better than early saliency: A re-analysis of Einh\\u00e4user et al.\\u2019s data, Journal of Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26734366\",\"name\":\"N. Murray\"},{\"authorId\":\"144465192\",\"name\":\"M. Vanrell\"},{\"authorId\":\"2556319\",\"name\":\"X. Otazu\"},{\"authorId\":\"145983916\",\"name\":\"C. P\\u00e1rraga\"}],\"doi\":\"10.1109/CVPR.2011.5995506\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"42f80d9186370cb9d21d7b244051e0b08dd51372\",\"title\":\"Saliency estimation using a non-parametric low-level vision model\",\"url\":\"https://www.semanticscholar.org/paper/42f80d9186370cb9d21d7b244051e0b08dd51372\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"}],\"doi\":\"10.1167/13.4.11\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9896b03aeb17e06181c1842773fec4b742d7c51f\",\"title\":\"Visual saliency estimation by nonlinearly integrating features using region covariances.\",\"url\":\"https://www.semanticscholar.org/paper/9896b03aeb17e06181c1842773fec4b742d7c51f\",\"venue\":\"Journal of vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3369864\",\"name\":\"B. Tatler\"}],\"doi\":\"10.1167/7.14.4\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"caed9b6de0142c9a4e07c96043e85e38ec22dd1e\",\"title\":\"The central fixation bias in scene viewing: selecting an optimal viewing position independently of motor biases and image feature distributions.\",\"url\":\"https://www.semanticscholar.org/paper/caed9b6de0142c9a4e07c96043e85e38ec22dd1e\",\"venue\":\"Journal of vision\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405709304\",\"name\":\"Tien Ho-Phuoc\"},{\"authorId\":\"2134577\",\"name\":\"Laurent Alacoque\"},{\"authorId\":\"2016536\",\"name\":\"Antoine Dupret\"},{\"authorId\":\"1398547891\",\"name\":\"Anne Gu\\u00e9rin-Dugu\\u00e9\"},{\"authorId\":\"39887981\",\"name\":\"Arnaud Verdant\"}],\"doi\":\"10.1117/12.908681\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"183478aa2462e0438a31613d73925421bc38e279\",\"title\":\"A unified method for comparison of algorithms of saliency extraction\",\"url\":\"https://www.semanticscholar.org/paper/183478aa2462e0438a31613d73925421bc38e279\",\"venue\":\"Electronic Imaging\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2991689\",\"name\":\"S. Marat\"},{\"authorId\":\"1398547895\",\"name\":\"T. Ho-Phuoc\"},{\"authorId\":\"2704802\",\"name\":\"L. Granjon\"},{\"authorId\":\"3252109\",\"name\":\"N. Guyader\"},{\"authorId\":\"31617713\",\"name\":\"D. Pellerin\"},{\"authorId\":\"1398547891\",\"name\":\"A. Gu\\u00e9rin-Dugu\\u00e9\"}],\"doi\":\"10.1007/s11263-009-0215-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c0491fa65bd730e30c4a5673008d5480507a9d5e\",\"title\":\"Modelling Spatio-Temporal Saliency to Predict Gaze Direction for\\u00a0Short Videos\",\"url\":\"https://www.semanticscholar.org/paper/c0491fa65bd730e30c4a5673008d5480507a9d5e\",\"venue\":\"International Journal of Computer Vision\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1364/JOSAA.20.001407\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4e8862366617f9ce13d603ac9311d396fb2d2e25\",\"title\":\"Modeling global scene factors in attention.\",\"url\":\"https://www.semanticscholar.org/paper/4e8862366617f9ce13d603ac9311d396fb2d2e25\",\"venue\":\"Journal of the Optical Society of America. A, Optics, image science, and vision\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47521917\",\"name\":\"Q. Zhao\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"}],\"doi\":\"10.1167/11.3.9\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b380725466e69717ab4c2520c80cff4bba2cc05c\",\"title\":\"Learning a saliency map using fixated locations in natural scenes.\",\"url\":\"https://www.semanticscholar.org/paper/b380725466e69717ab4c2520c80cff4bba2cc05c\",\"venue\":\"Journal of vision\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1396144799\",\"name\":\"A. Garc\\u00eda-D\\u00edaz\"},{\"authorId\":\"1398290502\",\"name\":\"Xos\\u00e9 R. Fern\\u00e1ndez-Vidal\"},{\"authorId\":\"1768258\",\"name\":\"X. Pardo\"},{\"authorId\":\"1751198\",\"name\":\"Raquel Dosil\"}],\"doi\":\"10.1007/978-3-642-04697-1_32\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"749e554382fd343fc7c81ec61dfc7cd2fd997745\",\"title\":\"Decorrelation and Distinctiveness Provide with Human-Like Saliency\",\"url\":\"https://www.semanticscholar.org/paper/749e554382fd343fc7c81ec61dfc7cd2fd997745\",\"venue\":\"ACIVS\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7326223\",\"name\":\"L. Itti\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"}],\"doi\":\"10.1016/S0042-6989(99)00163-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7b4b801de1ba8a4456adcde7b1a9c5bc5cf09fc3\",\"title\":\"A saliency-based search mechanism for overt and covert shifts of visual attention\",\"url\":\"https://www.semanticscholar.org/paper/7b4b801de1ba8a4456adcde7b1a9c5bc5cf09fc3\",\"venue\":\"Vision Research\",\"year\":2000},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2036170\",\"name\":\"Dashan Gao\"},{\"authorId\":\"34287739\",\"name\":\"Sunhyoung Han\"},{\"authorId\":\"1699559\",\"name\":\"N. Vasconcelos\"}],\"doi\":\"10.1109/TPAMI.2009.27\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aee90db1f66b77113b0a62701deb01ca96b6d9e6\",\"title\":\"Discriminant Saliency, the Detection of Suspicious Coincidences, and Applications to Visual Recognition\",\"url\":\"https://www.semanticscholar.org/paper/aee90db1f66b77113b0a62701deb01ca96b6d9e6\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3084719\",\"name\":\"Xiaodi Hou\"},{\"authorId\":\"39810944\",\"name\":\"Jonathan Harel\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"}],\"doi\":\"10.1109/TPAMI.2011.146\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"48c2b8a35ce9468b84ac032af70cf2b100f5c1fc\",\"title\":\"Image Signature: Highlighting Sparse Salient Regions\",\"url\":\"https://www.semanticscholar.org/paper/48c2b8a35ce9468b84ac032af70cf2b100f5c1fc\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1789744\",\"name\":\"O. Meur\"},{\"authorId\":\"1776651\",\"name\":\"P. Callet\"},{\"authorId\":\"144812989\",\"name\":\"D. Barba\"},{\"authorId\":\"144843363\",\"name\":\"D. Thoreau\"}],\"doi\":\"10.1109/TPAMI.2006.86\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f30fed23882675422aada3bd60ed7d1ae84fcb09\",\"title\":\"A coherent computational approach to model bottom-up visual attention\",\"url\":\"https://www.semanticscholar.org/paper/f30fed23882675422aada3bd60ed7d1ae84fcb09\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A Khosla\"},{\"authorId\":null,\"name\":\"J Xiao\"},{\"authorId\":null,\"name\":\"A Torralba\"},{\"authorId\":null,\"name\":\"A Oliva\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Memorability of Image Regions. NIPS\",\"url\":\"\",\"venue\":\"Memorability of Image Regions. NIPS\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39810944\",\"name\":\"Jonathan Harel\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"}],\"doi\":\"10.7551/mitpress/7503.003.0073\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f412bb31ec9ef8bbef70eefc7ffd04420c1365d9\",\"title\":\"Graph-Based Visual Saliency\",\"url\":\"https://www.semanticscholar.org/paper/f412bb31ec9ef8bbef70eefc7ffd04420c1365d9\",\"venue\":\"NIPS\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2401039\",\"name\":\"Derrick J. Parkhurst\"},{\"authorId\":\"3271571\",\"name\":\"E. Niebur\"}],\"doi\":\"10.1163/15685680360511645\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cfaea99353a30bbca2431ae23c7742605334d950\",\"title\":\"Scene content selected by active vision.\",\"url\":\"https://www.semanticscholar.org/paper/cfaea99353a30bbca2431ae23c7742605334d950\",\"venue\":\"Spatial vision\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1800953\",\"name\":\"S. Frintrop\"}],\"doi\":\"10.1007/11682110\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2032694f88ee16fb7ebadfb39b9eec4fa2aafa26\",\"title\":\"VOCUS: A Visual Attention System for Object Detection and Goal-Directed Search\",\"url\":\"https://www.semanticscholar.org/paper/2032694f88ee16fb7ebadfb39b9eec4fa2aafa26\",\"venue\":\"Lecture Notes in Computer Science\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47059693\",\"name\":\"L. Zhang\"},{\"authorId\":\"49488601\",\"name\":\"M. Tong\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"},{\"authorId\":\"2207531\",\"name\":\"Honghao Shan\"},{\"authorId\":\"48524582\",\"name\":\"G. Cottrell\"}],\"doi\":\"10.1167/8.7.32\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e80c48441351fc1d928524710b4500a0de8315bb\",\"title\":\"SUN: A Bayesian framework for saliency using natural statistics.\",\"url\":\"https://www.semanticscholar.org/paper/e80c48441351fc1d928524710b4500a0de8315bb\",\"venue\":\"Journal of vision\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"40599257\",\"name\":\"J. Xiao\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"540a8b3f2a8eb6104db0b37d89f3918cb6324815\",\"title\":\"Memorability of Image Regions\",\"url\":\"https://www.semanticscholar.org/paper/540a8b3f2a8eb6104db0b37d89f3918cb6324815\",\"venue\":\"NIPS\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1685020\",\"name\":\"D. Comaniciu\"},{\"authorId\":\"145776090\",\"name\":\"P. Meer\"}],\"doi\":\"10.1109/34.1000236\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"74f4ecc3e4e5b91fbb54330b285ed5214afe2001\",\"title\":\"Mean Shift: A Robust Approach Toward Feature Space Analysis\",\"url\":\"https://www.semanticscholar.org/paper/74f4ecc3e4e5b91fbb54330b285ed5214afe2001\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1109/CVPR.2012.6247711\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5e3d92c27e2fbb407243a6279dfafe9260a3732d\",\"title\":\"Exploiting local and global patch rarities for saliency detection\",\"url\":\"https://www.semanticscholar.org/paper/5e3d92c27e2fbb407243a6279dfafe9260a3732d\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7326223\",\"name\":\"L. Itti\"},{\"authorId\":\"144902513\",\"name\":\"P. Baldi\"}],\"doi\":\"10.1016/j.visres.2008.09.007\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aebd8bab5cff769fed204dba35112e364a47e504\",\"title\":\"Bayesian surprise attracts human attention\",\"url\":\"https://www.semanticscholar.org/paper/aebd8bab5cff769fed204dba35112e364a47e504\",\"venue\":\"Vision Research\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"115007758\",\"name\":\"A. L. I\\ufe20A\\ufe21rbus\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5e7ebb251691ab4c19ec47171d5a40bee5d55b82\",\"title\":\"Eye Movements and Vision\",\"url\":\"https://www.semanticscholar.org/paper/5e7ebb251691ab4c19ec47171d5a40bee5d55b82\",\"venue\":\"\",\"year\":1967},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"S Winkler\"},{\"authorId\":null,\"name\":\"R Subramanian\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Overview of Eye tracking Datasets, Quality of Multimedia Experience\",\"url\":\"\",\"venue\":\"Overview of Eye tracking Datasets, Quality of Multimedia Experience\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1756619\",\"name\":\"Lior Elazary\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1167/8.3.3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"611c084900a847781f77e8b563113256b060d9f1\",\"title\":\"Interesting objects are visually salient.\",\"url\":\"https://www.semanticscholar.org/paper/611c084900a847781f77e8b563113256b060d9f1\",\"venue\":\"Journal of vision\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3084719\",\"name\":\"Xiaodi Hou\"},{\"authorId\":\"5381034\",\"name\":\"L. Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4e7ec75337766f2b649bb9f99c6887ee0f1674a6\",\"title\":\"Dynamic visual attention: searching for coding length increments\",\"url\":\"https://www.semanticscholar.org/paper/4e7ec75337766f2b649bb9f99c6887ee0f1674a6\",\"venue\":\"NIPS\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2866720\",\"name\":\"Tamar Avraham\"},{\"authorId\":\"1727935\",\"name\":\"M. Lindenbaum\"}],\"doi\":\"10.1109/TPAMI.2009.53\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1af8ab48bb6da746070a09d7b4582a53e51de86c\",\"title\":\"Esaliency (Extended Saliency): Meaningful Attention Using Stochastic Image Modeling\",\"url\":\"https://www.semanticscholar.org/paper/1af8ab48bb6da746070a09d7b4582a53e51de86c\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2136978\",\"name\":\"Michelle R. Greene\"},{\"authorId\":\"145774036\",\"name\":\"Tommy F. Liu\"},{\"authorId\":\"1717172\",\"name\":\"J. Wolfe\"}],\"doi\":\"10.1016/j.visres.2012.03.019\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"904565935ffa3e485be2487c28a3ce3d5424133a\",\"title\":\"Reconsidering Yarbus: A failure to predict observers\\u2019 task from eye movement patterns\",\"url\":\"https://www.semanticscholar.org/paper/904565935ffa3e485be2487c28a3ce3d5424133a\",\"venue\":\"Vision Research\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47398600\",\"name\":\"D. Walther\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"}],\"doi\":\"10.1016/j.neunet.2006.10.001\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b73f2d7b58bfc555d8037b3fdb673c4cec1aecf0\",\"title\":\"Modeling attention to salient proto-objects\",\"url\":\"https://www.semanticscholar.org/paper/b73f2d7b58bfc555d8037b3fdb673c4cec1aecf0\",\"venue\":\"Neural Networks\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152627906\",\"name\":\"T. Judd\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"daef3fdc4190927c063ae94c12437cf82a6d1c20\",\"title\":\"A Benchmark of Computational Models of Saliency to Predict Human Fixations\",\"url\":\"https://www.semanticscholar.org/paper/daef3fdc4190927c063ae94c12437cf82a6d1c20\",\"venue\":\"\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3376641\",\"name\":\"A. Nuthmann\"},{\"authorId\":\"1889476\",\"name\":\"J. Henderson\"}],\"doi\":\"10.1167/10.8.20\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"87571e525b14c5e6134a6be15b44f5d9a992ab41\",\"title\":\"Object-based attentional selection in scene viewing.\",\"url\":\"https://www.semanticscholar.org/paper/87571e525b14c5e6134a6be15b44f5d9a992ab41\",\"venue\":\"Journal of vision\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"2037692\",\"name\":\"Dicky N. Sihite\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1109/CVPR.2012.6247710\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6666ffdc35f3b80f291b63e62fdcc29462662c47\",\"title\":\"Probabilistic learning of task-specific visual attention\",\"url\":\"https://www.semanticscholar.org/paper/6666ffdc35f3b80f291b63e62fdcc29462662c47\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"D. Gao\"},{\"authorId\":null,\"name\":\"S. Han\"},{\"authorId\":null,\"name\":\"N. Vasconcelos\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Discriminant saliency\",\"url\":\"\",\"venue\":\"the detection of suspicious coincidences and applications to visual recognition. PAMI\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J Yan\"},{\"authorId\":null,\"name\":\"J Liu\"},{\"authorId\":null,\"name\":\"Y Li\"},{\"authorId\":null,\"name\":\"Y Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Visual saliency via sparsity rank decomposition . ICIP\",\"url\":\"\",\"venue\":\"Visual saliency via sparsity rank decomposition . ICIP\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2602925\",\"name\":\"Boris Schauerte\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"}],\"doi\":\"10.1007/978-3-642-33709-3_9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5a0d596ef86c7563c0907c052273113f51006479\",\"title\":\"Quaternion-Based Spectral Saliency Detection for Eye Fixation Prediction\",\"url\":\"https://www.semanticscholar.org/paper/5a0d596ef86c7563c0907c052273113f51006479\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766832\",\"name\":\"U. Engelke\"},{\"authorId\":\"3307573\",\"name\":\"H. Liu\"},{\"authorId\":\"2753356\",\"name\":\"J. Wang\"},{\"authorId\":\"1776651\",\"name\":\"P. Callet\"},{\"authorId\":\"145412643\",\"name\":\"I. Heynderickx\"},{\"authorId\":\"48546175\",\"name\":\"H. Zepernick\"},{\"authorId\":\"144426436\",\"name\":\"A. Maeder\"}],\"doi\":\"10.1109/TIP.2012.2227767\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d439a468ab2de9e3b222d6689b1b714b3a1c4d6e\",\"title\":\"Comparative Study of Fixation Density Maps\",\"url\":\"https://www.semanticscholar.org/paper/d439a468ab2de9e3b222d6689b1b714b3a1c4d6e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"15499981\",\"name\":\"Katherine Humphrey\"},{\"authorId\":\"1908277\",\"name\":\"G. Underwood\"},{\"authorId\":\"1688110\",\"name\":\"Tony Lambert\"}],\"doi\":\"10.1167/12.1.22\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"135ec24ac7d8ebefe2d2883eaeb88e73cfc0a1bd\",\"title\":\"Salience of the lambs: a test of the saliency map hypothesis with pictures of emotive objects.\",\"url\":\"https://www.semanticscholar.org/paper/135ec24ac7d8ebefe2d2883eaeb88e73cfc0a1bd\",\"venue\":\"Journal of vision\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1619078806\",\"name\":\"A. ADoefaa\"},{\"authorId\":\"1619192001\",\"name\":\"H. P. Doetsch\"},{\"authorId\":\"1619263939\",\"name\":\"Draweng Table\"},{\"authorId\":\"1619192001\",\"name\":\"H. P. Doetsch\"}],\"doi\":\"10.2307/j.ctvrnfqk1.10\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4dc21a168070dc87266accd9ce2c06ee6115a285\",\"title\":\"? ? ? ? f ? ? ? ? ?\",\"url\":\"https://www.semanticscholar.org/paper/4dc21a168070dc87266accd9ce2c06ee6115a285\",\"venue\":\"\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38497468\",\"name\":\"M. Cerf\"},{\"authorId\":\"39810944\",\"name\":\"Jonathan Harel\"},{\"authorId\":\"1917767\",\"name\":\"W. Einh\\u00e4user\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a48dc9c898d6ff1cdb96dcf8a297bafb8ac1b9e2\",\"title\":\"Predicting human gaze using low-level saliency combined with face detection\",\"url\":\"https://www.semanticscholar.org/paper/a48dc9c898d6ff1cdb96dcf8a297bafb8ac1b9e2\",\"venue\":\"NIPS\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"CHRISTUS\"},{\"authorId\":null,\"name\":\"WUKSCH\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"967f32841955b72f358190436baa5510839d9ab3\",\"title\":\"A General Method Applicable to the Search for Similarities in the Amino Acid Sequence of Two Proteins\",\"url\":\"https://www.semanticscholar.org/paper/967f32841955b72f358190436baa5510839d9ab3\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"S. Marat\"},{\"authorId\":null,\"name\":\"T. Ho-Phuoc\"},{\"authorId\":null,\"name\":\"L. Granjon\"},{\"authorId\":null,\"name\":\"N. Guyader\"},{\"authorId\":null,\"name\":\"D. Pellerin\"},{\"authorId\":null,\"name\":\"A. Gu\\u00e9rin- Dugu\\u00e9\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Modeling saliency to predict gaze direction for short videos\",\"url\":\"\",\"venue\":\"IJCV\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143615083\",\"name\":\"R. J. Peters\"},{\"authorId\":\"4292093\",\"name\":\"A. Iyer\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"}],\"doi\":\"10.1016/j.visres.2005.03.019\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a7447f7e6197c0875a28686efdffe4ba4beb5460\",\"title\":\"Components of bottom-up gaze allocation in natural images\",\"url\":\"https://www.semanticscholar.org/paper/a7447f7e6197c0875a28686efdffe4ba4beb5460\",\"venue\":\"Vision Research\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1630291648\",\"name\":\"Il Liceo\"},{\"authorId\":\"1630291637\",\"name\":\"Delle Scienze Umane\"},{\"authorId\":\"1630390134\",\"name\":\"Progetto BiologiaAmbiente\"},{\"authorId\":\"1630390134\",\"name\":\"Progetto BiologiaAmbiente\"},{\"authorId\":\"1630311779\",\"name\":\"Profilo IN Uscita\"},{\"authorId\":\"1630291648\",\"name\":\"Il Liceo\"}],\"doi\":\"10.1515/9783111413426-013\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5385b3c2cef5138d2f4f9127ec7565eb8043a1c4\",\"title\":\"L\",\"url\":\"https://www.semanticscholar.org/paper/5385b3c2cef5138d2f4f9127ec7565eb8043a1c4\",\"venue\":\"Edinburgh Medical and Surgical Journal\",\"year\":1824},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40527314\",\"name\":\"G. Kootstra\"},{\"authorId\":\"47772152\",\"name\":\"Arco Nederveen\"},{\"authorId\":\"3464677\",\"name\":\"B. Boer\"}],\"doi\":\"10.5244/C.22.111\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"33558c6003cde5a1a2169e308dc43308b42509cb\",\"title\":\"Paying Attention to Symmetry\",\"url\":\"https://www.semanticscholar.org/paper/33558c6003cde5a1a2169e308dc43308b42509cb\",\"venue\":\"BMVC\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1941997\",\"name\":\"Chenlei Guo\"},{\"authorId\":\"29906646\",\"name\":\"L. Zhang\"}],\"doi\":\"10.1109/TIP.2009.2030969\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"01825573781674bcf85d0f5d2ec456842f75ad3c\",\"title\":\"A Novel Multiresolution Spatiotemporal Saliency Detection Model and Its Applications in Image and Video Compression\",\"url\":\"https://www.semanticscholar.org/paper/01825573781674bcf85d0f5d2ec456842f75ad3c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3326805\",\"name\":\"Hae Jong Seo\"},{\"authorId\":\"1718280\",\"name\":\"P. Milanfar\"}],\"doi\":\"10.1167/9.12.15\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"143973e23364190bc687fe694eb863417e8ba0ba\",\"title\":\"Static and space-time visual saliency detection by self-resemblance.\",\"url\":\"https://www.semanticscholar.org/paper/143973e23364190bc687fe694eb863417e8ba0ba\",\"venue\":\"Journal of vision\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143775672\",\"name\":\"Tilke Judd\"},{\"authorId\":\"1865091\",\"name\":\"Krista A. Ehinger\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/ICCV.2009.5459462\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c7614898de1cfee1a3a1c564f52c1e67879c29b3\",\"title\":\"Learning to predict where humans look\",\"url\":\"https://www.semanticscholar.org/paper/c7614898de1cfee1a3a1c564f52c1e67879c29b3\",\"venue\":\"2009 IEEE 12th International Conference on Computer Vision\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1435508274\",\"name\":\"A. News\"},{\"authorId\":\"1999089\",\"name\":\"E. Lu\"},{\"authorId\":\"3028232\",\"name\":\"Minmin Zhou\"},{\"authorId\":null,\"name\":\"Rong Mocsai\"},{\"authorId\":\"145950435\",\"name\":\"A. Myers\"},{\"authorId\":\"1741991003\",\"name\":\"Erin E. Huang\"},{\"authorId\":\"153309963\",\"name\":\"B. Jackson\"},{\"authorId\":\"153501574\",\"name\":\"D. Ferrari\"},{\"authorId\":\"46448509\",\"name\":\"V. Tybulewicz\"},{\"authorId\":null,\"name\":\"Victor Lowell\"},{\"authorId\":\"11048382\",\"name\":\"C. Lepore\"},{\"authorId\":\"116515431\",\"name\":\"J. Koretzky\"},{\"authorId\":\"46292705\",\"name\":\"Gary Kahn\"},{\"authorId\":null,\"name\":\"Mark L\"},{\"authorId\":\"143807167\",\"name\":\"F. Achard\"},{\"authorId\":\"1491458517\",\"name\":\"H. D. Eva\"},{\"authorId\":null,\"name\":\"Ernst-Detlef See Also Schulze\"},{\"authorId\":\"5329613\",\"name\":\"J. Acharya\"},{\"authorId\":\"49185789\",\"name\":\"U. Acharya\"},{\"authorId\":\"49185789\",\"name\":\"U. Acharya\"},{\"authorId\":\"6077599\",\"name\":\"S. Patel\"},{\"authorId\":\"6398536\",\"name\":\"E. Koundakjian\"},{\"authorId\":\"48913846\",\"name\":\"K. Nagashima\"},{\"authorId\":\"87719226\",\"name\":\"X. Han\"},{\"authorId\":\"5329613\",\"name\":\"J. Acharya\"},{\"authorId\":\"144861008\",\"name\":\"D. Adams\"},{\"authorId\":null,\"name\":\"Jonathan C And Horton\"},{\"authorId\":null,\"name\":\"Blood\"},{\"authorId\":\"49185181\",\"name\":\"M. Adams\"},{\"authorId\":\"46775174\",\"name\":\"M. Mcvey\"},{\"authorId\":\"5909720\",\"name\":\"J. Sekelsky\"},{\"authorId\":\"52569394\",\"name\":\"J. Adamson\"},{\"authorId\":\"47920829\",\"name\":\"G. G. Kochendoerfer\"},{\"authorId\":\"7745713\",\"name\":\"A. W. Adeleke\"},{\"authorId\":null,\"name\":\"A See Kamdem-Toham\"},{\"authorId\":\"3111940\",\"name\":\"A. Aderem\"},{\"authorId\":\"152676651\",\"name\":\"C. Picard\"},{\"authorId\":\"115759360\",\"name\":\"Aeschlimann\"},{\"authorId\":\"4858956\",\"name\":\"G. Haug\"},{\"authorId\":\"2332181\",\"name\":\"G. S. Agarwal\"},{\"authorId\":\"50460883\",\"name\":\"M. Scully\"},{\"authorId\":\"144699300\",\"name\":\"H. Aguilaniu\"},{\"authorId\":\"46832542\",\"name\":\"L. Gustafsson\"},{\"authorId\":\"5667177\",\"name\":\"M. Rigoulet\"},{\"authorId\":\"145009924\",\"name\":\"T. Nystr\\u00f6m\"},{\"authorId\":null,\"name\":\"Asymmetric Inheri\"},{\"authorId\":\"46954724\",\"name\":\"Ferhaan Ahmad\"},{\"authorId\":\"6434784\",\"name\":\"J. P. Schmitt\"},{\"authorId\":\"153372043\",\"name\":\"Misako Aida\"},{\"authorId\":\"144767879\",\"name\":\"Salai C. Ammal\"},{\"authorId\":\"46324591\",\"name\":\"J. Aizenberg\"},{\"authorId\":\"3052861\",\"name\":\"D. Muller\"},{\"authorId\":\"117756927\",\"name\":\"John L. Grazul\"},{\"authorId\":\"145165160\",\"name\":\"D. R. Hamann\"},{\"authorId\":\"97839749\",\"name\":\"J. Ajioka\"},{\"authorId\":\"133799849\",\"name\":\"C. Su\"},{\"authorId\":\"50767520\",\"name\":\"A. Akella\"},{\"authorId\":\"38948478\",\"name\":\"M. Alam\"},{\"authorId\":\"47411788\",\"name\":\"F. Gao\"},{\"authorId\":\"4464233\",\"name\":\"A. Alatas\"},{\"authorId\":\"50169977\",\"name\":\"H. Sinn\"},{\"authorId\":\"7480073\",\"name\":\"Titus V. Albu\"},{\"authorId\":\"8204857\",\"name\":\"P. S. Zuev\"},{\"authorId\":\"1402325831\",\"name\":\"M. Al-Dayeh\"},{\"authorId\":\"117860354\",\"name\":\"J. Dwyer\"},{\"authorId\":\"114606050\",\"name\":\"A. Al-ghonaium\"},{\"authorId\":null,\"name\":\"Sami See Al-Hajjar\"},{\"authorId\":\"1421934622\",\"name\":\"S. Al-Jumaah\"},{\"authorId\":\"46591015\",\"name\":\"A. Allakhverdov\"},{\"authorId\":\"144263358\",\"name\":\"V. Pokrovsky\"},{\"authorId\":\"114745157\",\"name\":\"Allen\"},{\"authorId\":\"9441807\",\"name\":\"A. Brown\"},{\"authorId\":\"1475801484\",\"name\":\"J. H. Allen\"},{\"authorId\":\"9441807\",\"name\":\"A. Brown\"},{\"authorId\":null,\"name\":\"James H Gillooly\"},{\"authorId\":\"1443579396\",\"name\":\"James\"}],\"doi\":\"10.5406/j.ctvpj7hjj.15\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3e0e337b477e0c226da00eae03fd29882275a469\",\"title\":\"What are \\u201c A \\u201d and \\u201c B \\u201d ?\",\"url\":\"https://www.semanticscholar.org/paper/3e0e337b477e0c226da00eae03fd29882275a469\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1644210546\",\"name\":\"MaratSophie\"},{\"authorId\":\"1644209634\",\"name\":\"Ho PhuocTien\"},{\"authorId\":\"1644211221\",\"name\":\"GranjonLionel\"},{\"authorId\":\"1644023894\",\"name\":\"GuyaderNathalie\"},{\"authorId\":\"1644210979\",\"name\":\"PellerinDenis\"},{\"authorId\":\"1644233229\",\"name\":\"Gu\\u00e9rin-Dugu\\u00e9Anne\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8571ff1117df87bfc7781750364db576c4f6b30b\",\"title\":\"Modelling Spatio-Temporal Saliency to Predict Gaze Direction for Short Videos\",\"url\":\"https://www.semanticscholar.org/paper/8571ff1117df87bfc7781750364db576c4f6b30b\",\"venue\":\"\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"S Marat\"},{\"authorId\":null,\"name\":\"T Ho-Phuoc\"},{\"authorId\":null,\"name\":\"L Granjon\"},{\"authorId\":null,\"name\":\"N Guyader\"},{\"authorId\":null,\"name\":\"D Pellerin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Gu\\u00e9rin- Dugu\\u00e9. Modeling saliency to predict gaze direction for short videos\",\"url\":\"\",\"venue\":\"Gu\\u00e9rin- Dugu\\u00e9. Modeling saliency to predict gaze direction for short videos\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":\"10.1109/CVPR.2012.6247706\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5817841d769baa45122ba0bf38af8cab3aeb5dd4\",\"title\":\"Boosting bottom-up and top-down visual features for saliency estimation\",\"url\":\"https://www.semanticscholar.org/paper/5817841d769baa45122ba0bf38af8cab3aeb5dd4\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12568146\",\"name\":\"D. Noton\"},{\"authorId\":\"144145222\",\"name\":\"L. Stark\"}],\"doi\":\"10.1016/0042-6989(71)90213-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2aea0b1d01e298052220461fe4d2c2686313504c\",\"title\":\"Scanpaths in saccadic eye movements while viewing and recognizing patterns.\",\"url\":\"https://www.semanticscholar.org/paper/2aea0b1d01e298052220461fe4d2c2686313504c\",\"venue\":\"Vision research\",\"year\":1971},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3068086\",\"name\":\"Jia-Bin Huang\"},{\"authorId\":\"145237406\",\"name\":\"N. Ahuja\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9ed37c8341351e0cee7de519352ca4a0174fd367\",\"title\":\"Saliency detection via divergence analysis: A unified perspective\",\"url\":\"https://www.semanticscholar.org/paper/9ed37c8341351e0cee7de519352ca4a0174fd367\",\"venue\":\"Proceedings of the 21st International Conference on Pattern Recognition (ICPR2012)\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"2037692\",\"name\":\"Dicky N. Sihite\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1167/13.10.18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5183694a7cd0189d3017ba561801a964503d74d9\",\"title\":\"Objects do not predict fixations better than early saliency: a re-analysis of Einhauser et al.'s data.\",\"url\":\"https://www.semanticscholar.org/paper/5183694a7cd0189d3017ba561801a964503d74d9\",\"venue\":\"Journal of vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J. Yan\"},{\"authorId\":null,\"name\":\"J. Liu\"},{\"authorId\":null,\"name\":\"Y. Li\"},{\"authorId\":null,\"name\":\"Y. Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Visual saliency via sparsity rank decomposition\",\"url\":\"\",\"venue\":\"ICIP\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"143832119\",\"name\":\"Y. Zhou\"},{\"authorId\":\"3063894\",\"name\":\"Junchi Yan\"},{\"authorId\":\"40264733\",\"name\":\"Zhibin Niu\"},{\"authorId\":\"1688428\",\"name\":\"Jie Yang\"}],\"doi\":\"10.1007/978-3-642-12307-8_23\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4359175f361900de5df0b6b3d2483df2e05c743a\",\"title\":\"Visual Saliency Based on Conditional Entropy\",\"url\":\"https://www.semanticscholar.org/paper/4359175f361900de5df0b6b3d2483df2e05c743a\",\"venue\":\"ACCV\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2351052\",\"name\":\"Milind S. Gide\"},{\"authorId\":\"30103343\",\"name\":\"J. Karam\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1769e9a263cef74e2facf5bfb231ca58f9df40f4\",\"title\":\"COMPARATIVE EVALUATION OF VISUAL SALIENCY MODELS FOR QUALITY ASSESSMENT TASK\",\"url\":\"https://www.semanticscholar.org/paper/1769e9a263cef74e2facf5bfb231ca58f9df40f4\",\"venue\":\"\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2866780\",\"name\":\"Neil D. B. Bruce\"},{\"authorId\":\"1727853\",\"name\":\"John K. Tsotsos\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4f847b4ddc105d73bc78f3e7220e6c1f71a7dfb6\",\"title\":\"Saliency Based on Information Maximization\",\"url\":\"https://www.semanticscholar.org/paper/4f847b4ddc105d73bc78f3e7220e6c1f71a7dfb6\",\"venue\":\"NIPS\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1080/13506280444000661\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"463c3e8403b95b88f8e19cdaa3d9ec0a3105f6ac\",\"title\":\"Quantifying the contribution of low-level saliency to human eye movements in dynamic scenes\",\"url\":\"https://www.semanticscholar.org/paper/463c3e8403b95b88f8e19cdaa3d9ec0a3105f6ac\",\"venue\":\"\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145519708\",\"name\":\"J. Li\"},{\"authorId\":\"40161651\",\"name\":\"Yonghong Tian\"},{\"authorId\":\"34097174\",\"name\":\"Tiejun Huang\"},{\"authorId\":\"48385803\",\"name\":\"W. Gao\"}],\"doi\":\"10.1007/s11263-010-0354-6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d1ca0711576a4d6e1145502821f3dca8e3ce69bd\",\"title\":\"Probabilistic Multi-Task Learning for Visual Saliency Estimation in Video\",\"url\":\"https://www.semanticscholar.org/paper/d1ca0711576a4d6e1145502821f3dca8e3ce69bd\",\"venue\":\"International Journal of Computer Vision\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145624227\",\"name\":\"C. Koch\"},{\"authorId\":\"1743045\",\"name\":\"S. Ullman\"}],\"doi\":\"10.1007/978-94-009-3833-5_5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0ce672e6ef09e9ab4c43f1eb75443dc7a5cb38c6\",\"title\":\"Shifts in selective visual attention: towards the underlying neural circuitry.\",\"url\":\"https://www.semanticscholar.org/paper/0ce672e6ef09e9ab4c43f1eb75443dc7a5cb38c6\",\"venue\":\"Human neurobiology\",\"year\":1985},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1789744\",\"name\":\"O. Meur\"},{\"authorId\":\"1731790\",\"name\":\"T. Baccino\"}],\"doi\":\"10.3758/s13428-012-0226-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a98a0079fef4c434e5e1f775ce47f8151149bf47\",\"title\":\"Methods for comparing scanpaths and saliency maps: strengths and weaknesses\",\"url\":\"https://www.semanticscholar.org/paper/a98a0079fef4c434e5e1f775ce47f8151149bf47\",\"venue\":\"Behavior research methods\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1917767\",\"name\":\"W. Einh\\u00e4user\"},{\"authorId\":\"38163342\",\"name\":\"Merrielle Spain\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"}],\"doi\":\"10.1167/8.14.18\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c032ef5e4ce9536de5669bbe487e1f618d3a12a6\",\"title\":\"Objects predict fixations better than early saliency.\",\"url\":\"https://www.semanticscholar.org/paper/c032ef5e4ce9536de5669bbe487e1f618d3a12a6\",\"venue\":\"Journal of vision\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3369864\",\"name\":\"B. Tatler\"},{\"authorId\":\"46656894\",\"name\":\"N. Wade\"},{\"authorId\":\"1860865\",\"name\":\"H. Kwan\"},{\"authorId\":\"143951357\",\"name\":\"J. M. Findlay\"},{\"authorId\":\"2835449\",\"name\":\"B. Velichkovsky\"}],\"doi\":\"10.1068/i0382\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ec51d2b44efc4433ecdef4f89dd785dcf43fa1f9\",\"title\":\"Yarbus, eye movements, and vision\",\"url\":\"https://www.semanticscholar.org/paper/ec51d2b44efc4433ecdef4f89dd785dcf43fa1f9\",\"venue\":\"i-Perception\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145426739\",\"name\":\"D. Berg\"},{\"authorId\":\"2065725\",\"name\":\"S. Boehnke\"},{\"authorId\":\"28122884\",\"name\":\"Robert A. Marino\"},{\"authorId\":\"144440243\",\"name\":\"D. Munoz\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1167/9.5.19\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0d8a1ee9a24520a3109a8e538adc388478ec50e8\",\"title\":\"Free viewing of dynamic stimuli by humans and monkeys.\",\"url\":\"https://www.semanticscholar.org/paper/0d8a1ee9a24520a3109a8e538adc388478ec50e8\",\"venue\":\"Journal of vision\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1109/TPAMI.2012.89\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aa57b9bdb0736cbb38abf0a9d12047212c2a2425\",\"title\":\"State-of-the-Art in Visual Attention Modeling\",\"url\":\"https://www.semanticscholar.org/paper/aa57b9bdb0736cbb38abf0a9d12047212c2a2425\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3084719\",\"name\":\"Xiaodi Hou\"},{\"authorId\":\"5381034\",\"name\":\"L. Zhang\"}],\"doi\":\"10.1109/CVPR.2007.383267\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9ce3c18eb4fa86fd19bce46227be39895de4e4ab\",\"title\":\"Saliency Detection: A Spectral Residual Approach\",\"url\":\"https://www.semanticscholar.org/paper/9ce3c18eb4fa86fd19bce46227be39895de4e4ab\",\"venue\":\"2007 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143852685\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"},{\"authorId\":\"3111194\",\"name\":\"J. Heikkil\\u00e4\"}],\"doi\":\"10.1007/978-3-642-21227-7_62\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0161777b4419411a4d2c5971a22683ee8691643f\",\"title\":\"Fast and Efficient Saliency Detection Using Sparse Sampling and Kernel Density Estimation\",\"url\":\"https://www.semanticscholar.org/paper/0161777b4419411a4d2c5971a22683ee8691643f\",\"venue\":\"SCIA\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1742936\",\"name\":\"S. Ramanathan\"},{\"authorId\":\"2478739\",\"name\":\"H. Katti\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1007/978-3-642-15561-1_3\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ec80f411ef1c08eae586047d97977f9ef59dd6f5\",\"title\":\"An Eye Fixation Database for Saliency Detection in Images\",\"url\":\"https://www.semanticscholar.org/paper/ec80f411ef1c08eae586047d97977f9ef59dd6f5\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29810094\",\"name\":\"S. Winkler\"},{\"authorId\":\"1742936\",\"name\":\"S. Ramanathan\"}],\"doi\":\"10.1109/QoMEX.2013.6603239\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c102b22b59f3d59c3e78c33fbe29962eda46c2c5\",\"title\":\"Overview of Eye tracking Datasets\",\"url\":\"https://www.semanticscholar.org/paper/c102b22b59f3d59c3e78c33fbe29962eda46c2c5\",\"venue\":\"2013 Fifth International Workshop on Quality of Multimedia Experience (QoMEX)\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38163342\",\"name\":\"Merrielle Spain\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"}],\"doi\":\"10.1007/s11263-010-0376-0\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8bfbd28e6684e5507a150b7cc26392648b394e49\",\"title\":\"Measuring and Predicting Object Importance\",\"url\":\"https://www.semanticscholar.org/paper/8bfbd28e6684e5507a150b7cc26392648b394e49\",\"venue\":\"International Journal of Computer Vision\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1953466\",\"name\":\"C. Privitera\"},{\"authorId\":\"1731863\",\"name\":\"L. Stark\"}],\"doi\":\"10.1109/34.877520\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"60c2b03024f89c3f67d05d6b60d4ba1b032942c4\",\"title\":\"Algorithms for Defining Visual Regions-of-Interest: Comparison with Eye Fixations\",\"url\":\"https://www.semanticscholar.org/paper/60c2b03024f89c3f67d05d6b60d4ba1b032942c4\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2000},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7326223\",\"name\":\"L. Itti\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"},{\"authorId\":\"3271571\",\"name\":\"E. Niebur\"}],\"doi\":\"10.1109/34.730558\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4816f0b6f0d05da3901441bfa5cc7be044b4da8b\",\"title\":\"A Model of Saliency-Based Visual Attention for Rapid Scene Analysis\",\"url\":\"https://www.semanticscholar.org/paper/4816f0b6f0d05da3901441bfa5cc7be044b4da8b\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2502152\",\"name\":\"A. Treisman\"},{\"authorId\":\"46475250\",\"name\":\"G. Gelade\"}],\"doi\":\"10.1016/0010-0285(80)90005-5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"76361a44e145732a39dbc68d9418871038c83be2\",\"title\":\"A feature-integration theory of attention\",\"url\":\"https://www.semanticscholar.org/paper/76361a44e145732a39dbc68d9418871038c83be2\",\"venue\":\"Cognitive Psychology\",\"year\":1980},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"2037692\",\"name\":\"Dicky N. Sihite\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1109/TIP.2012.2210727\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c0b60d02b2d59123f6b336fe2e287bdb02a2a776\",\"title\":\"Quantitative Analysis of Human-Model Agreement in Visual Saliency Modeling: A Comparative Study\",\"url\":\"https://www.semanticscholar.org/paper/c0b60d02b2d59123f6b336fe2e287bdb02a2a776\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"17036668\",\"name\":\"A. L. Yarbus\"}],\"doi\":\"10.1007/978-1-4899-5379-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b5a712dd07fa65d7ad60d6e791053c29448ecb97\",\"title\":\"Eye Movements and Vision\",\"url\":\"https://www.semanticscholar.org/paper/b5a712dd07fa65d7ad60d6e791053c29448ecb97\",\"venue\":\"Springer US\",\"year\":1967}],\"title\":\"Analysis of Scores, Datasets, and Models in Visual Saliency Prediction\",\"topics\":[{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"},{\"topic\":\"Smoothing\",\"topicId\":\"16185\",\"url\":\"https://www.semanticscholar.org/topic/16185\"},{\"topic\":\"High- and low-level\",\"topicId\":\"33507\",\"url\":\"https://www.semanticscholar.org/topic/33507\"},{\"topic\":\"Amazon Web Services\",\"topicId\":\"8552\",\"url\":\"https://www.semanticscholar.org/topic/8552\"},{\"topic\":\"AIM alliance\",\"topicId\":\"1279609\",\"url\":\"https://www.semanticscholar.org/topic/1279609\"}],\"url\":\"https://www.semanticscholar.org/paper/05375a7489f0a84d47a316bacb4d86e8a7bda0df\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013}\n"