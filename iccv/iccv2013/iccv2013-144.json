"{\"abstract\":\"Visual saliency has been an increasingly active research area in the last ten years with dozens of saliency models recently published. Nowadays, one of the big challenges in the field is to find a way to fairly evaluate all of these models. In this paper, on human eye fixations, we compare the ranking of 12 state-of-the art saliency models using 12 similarity metrics. The comparison is done on Jian Li's database containing several hundreds of natural images. Based on Kendall concordance coefficient, it is shown that some of the metrics are strongly correlated leading to a redundancy in the performance metrics reported in the available benchmarks. On the other hand, other metrics provide a more diverse picture of models' overall performance. As a recommendation, three similarity metrics should be used to obtain a complete point of view of saliency model performance.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"2989773\",\"name\":\"Nicolas Riche\",\"url\":\"https://www.semanticscholar.org/author/2989773\"},{\"authorId\":\"2896417\",\"name\":\"Matthieu Duvinage\",\"url\":\"https://www.semanticscholar.org/author/2896417\"},{\"authorId\":\"1681157\",\"name\":\"M. Mancas\",\"url\":\"https://www.semanticscholar.org/author/1681157\"},{\"authorId\":\"50276543\",\"name\":\"B. Gosselin\",\"url\":\"https://www.semanticscholar.org/author/50276543\"},{\"authorId\":\"49164810\",\"name\":\"T. Dutoit\",\"url\":\"https://www.semanticscholar.org/author/49164810\"}],\"citationVelocity\":30,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"22206915\",\"name\":\"Marc Assens\"},{\"authorId\":\"3100480\",\"name\":\"Xavier Giro-i-Nieto\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"}],\"doi\":\"10.1016/j.image.2018.06.006\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e3510517f900dce12167622c5da0656ecfc39b14\",\"title\":\"Scanpath and saliency prediction on 360 degree images\",\"url\":\"https://www.semanticscholar.org/paper/e3510517f900dce12167622c5da0656ecfc39b14\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2018},{\"arxivId\":\"1705.10546\",\"authors\":[{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"2253528\",\"name\":\"F. Ahmed\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"1708642\",\"name\":\"Jorma T. Laaksonen\"}],\"doi\":\"10.1109/CVPR.2017.673\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"42f4aeff8219942153104c3ed5d9d661663d0cd3\",\"title\":\"Saliency Revisited: Analysis of Mouse Movements Versus Fixations\",\"url\":\"https://www.semanticscholar.org/paper/42f4aeff8219942153104c3ed5d9d661663d0cd3\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39168231\",\"name\":\"Guangyu Zhong\"},{\"authorId\":\"34469457\",\"name\":\"R. Liu\"},{\"authorId\":\"1839803\",\"name\":\"J. Cao\"},{\"authorId\":\"4642456\",\"name\":\"Z. Su\"}],\"doi\":\"10.1007/s00371-015-1077-z\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"a97fa1561def3768f2e300e511b4fde407887092\",\"title\":\"A generalized nonlocal mean framework with object-level cues for saliency detection\",\"url\":\"https://www.semanticscholar.org/paper/a97fa1561def3768f2e300e511b4fde407887092\",\"venue\":\"The Visual Computer\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143852685\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"1708642\",\"name\":\"Jorma T. Laaksonen\"}],\"doi\":\"10.1007/978-3-319-54407-6_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aa804644b886535440db045117a1375b47536c76\",\"title\":\"Bottom-Up Fixation Prediction Using Unsupervised Hierarchical Models\",\"url\":\"https://www.semanticscholar.org/paper/aa804644b886535440db045117a1375b47536c76\",\"venue\":\"ACCV Workshops\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Wei Zhang\"},{\"authorId\":\"3307573\",\"name\":\"H. Liu\"}],\"doi\":\"10.1016/j.neucom.2017.03.054\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"44d69762b3d1c2acfd6c1f26338f6d1308239068\",\"title\":\"Learning picture quality from visual distraction: Psychophysical studies and computational models\",\"url\":\"https://www.semanticscholar.org/paper/44d69762b3d1c2acfd6c1f26338f6d1308239068\",\"venue\":\"Neurocomputing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35272243\",\"name\":\"M. Feng\"},{\"authorId\":\"144445685\",\"name\":\"E. Peck\"},{\"authorId\":\"144029353\",\"name\":\"Lane Harrison\"}],\"doi\":\"10.1109/TVCG.2018.2865117\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f799c88e50ab30a08b83b9b72c24398c4c56021f\",\"title\":\"Patterns and Pace: Quantifying Diverse Exploration Behavior with Visualizations on the Web\",\"url\":\"https://www.semanticscholar.org/paper/f799c88e50ab30a08b83b9b72c24398c4c56021f\",\"venue\":\"IEEE Transactions on Visualization and Computer Graphics\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2790509\",\"name\":\"Ovidiu Gherman\"},{\"authorId\":\"2716436\",\"name\":\"Ovidiu Andrei Schipor\"},{\"authorId\":\"40698673\",\"name\":\"Bogdan-Florin Gheran\"}],\"doi\":\"10.1109/DAAS.2018.8396088\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ed04b5eda3283697f08c4a0b0212369ba22e42cb\",\"title\":\"VErGE: A system for collecting voice, eye gaze, gesture, and EEG data for experimental studies\",\"url\":\"https://www.semanticscholar.org/paper/ed04b5eda3283697f08c4a0b0212369ba22e42cb\",\"venue\":\"2018 International Conference on Development and Application Systems (DAS)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b0c001b2f619ee55114b29ded767c0295d88ce02\",\"title\":\"Computational perception for multi-modal document understanding\",\"url\":\"https://www.semanticscholar.org/paper/b0c001b2f619ee55114b29ded767c0295d88ce02\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Wei Zhang\"},{\"authorId\":\"3307573\",\"name\":\"H. Liu\"}],\"doi\":\"10.1109/TIP.2017.2681424\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2a7357fbe75a0b6fe6a54a767a77e691a250782a\",\"title\":\"Toward a Reliable Collection of Eye-Tracking Data for Image Quality Research: Challenges, Solutions, and Applications\",\"url\":\"https://www.semanticscholar.org/paper/2a7357fbe75a0b6fe6a54a767a77e691a250782a\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"47ce131f8904027f18eaf8f55fccbcedef351d11\",\"title\":\"The Time Dimension of Visual Attention Models\",\"url\":\"https://www.semanticscholar.org/paper/47ce131f8904027f18eaf8f55fccbcedef351d11\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2607232\",\"name\":\"Jiayu Liang\"},{\"authorId\":\"1791911\",\"name\":\"S. Yuen\"}],\"doi\":\"10.1007/s12559-016-9406-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c6475cadc6f5a14f56180e66163ce9a11841721c\",\"title\":\"A Novel Saliency Prediction Method Based on Fast Radial Symmetry Transform and Its Generalization\",\"url\":\"https://www.semanticscholar.org/paper/c6475cadc6f5a14f56180e66163ce9a11841721c\",\"venue\":\"Cognitive Computation\",\"year\":2016},{\"arxivId\":\"1803.04845\",\"authors\":[{\"authorId\":\"1398288379\",\"name\":\"A. Banitalebi-Dehkordi\"},{\"authorId\":\"2976069\",\"name\":\"Eleni Nasiopoulos\"},{\"authorId\":\"49617585\",\"name\":\"M. Pourazad\"},{\"authorId\":\"1687935\",\"name\":\"P. Nasiopoulos\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"516a8e8cd836ec33ac2b3faf8cdafcfef86a8c1a\",\"title\":\"Benchmark 3D eye-tracking dataset for visual saliency prediction on stereoscopic 3D video\",\"url\":\"https://www.semanticscholar.org/paper/516a8e8cd836ec33ac2b3faf8cdafcfef86a8c1a\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1510.02927\",\"authors\":[{\"authorId\":\"1784761\",\"name\":\"S. Kruthiventi\"},{\"authorId\":\"50430041\",\"name\":\"Kumar Ayush\"},{\"authorId\":\"144682140\",\"name\":\"R. Venkatesh Babu\"}],\"doi\":\"10.1109/TIP.2017.2710620\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1295cbaf3b03de2eb8c79530289f5939d7819e5c\",\"title\":\"DeepFix: A Fully Convolutional Neural Network for Predicting Human Eye Fixations\",\"url\":\"https://www.semanticscholar.org/paper/1295cbaf3b03de2eb8c79530289f5939d7819e5c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2072528\",\"name\":\"K. Latorella\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6888ac12afdc9c43e7b57722abbf92aa55afd409\",\"title\":\"Avionics Configuration Assessment for Flightdeck Interval Management: A Comparison of Avionics and Notification Methods\",\"url\":\"https://www.semanticscholar.org/paper/6888ac12afdc9c43e7b57722abbf92aa55afd409\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1701.01081\",\"authors\":[{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"},{\"authorId\":\"1399086207\",\"name\":\"C. Canton-Ferrer\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"},{\"authorId\":\"147166602\",\"name\":\"J. Torres\"},{\"authorId\":\"2470219\",\"name\":\"E. Sayrol\"},{\"authorId\":\"3100480\",\"name\":\"Xavier Giro-i-Nieto\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"258fad95e709b6d0572ae6cc99efbbb14d32bdf2\",\"title\":\"SalGAN: Visual Saliency Prediction with Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/258fad95e709b6d0572ae6cc99efbbb14d32bdf2\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38591458\",\"name\":\"Phutphalla Kong\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"275e09dfebd01409ddb38da8972ae4d53aed06a5\",\"title\":\"Saliency and Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/275e09dfebd01409ddb38da8972ae4d53aed06a5\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1704.08615\",\"authors\":[{\"authorId\":\"2997408\",\"name\":\"Matthias K\\u00fcmmerer\"},{\"authorId\":\"49737748\",\"name\":\"Thomas S. A. Wallis\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ebe8e8f2196fd947c091db64b1035737a072b496\",\"title\":\"Saliency Benchmarking: Separating Models, Maps and Metrics\",\"url\":\"https://www.semanticscholar.org/paper/ebe8e8f2196fd947c091db64b1035737a072b496\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2866780\",\"name\":\"Neil D. B. Bruce\"},{\"authorId\":\"4218304\",\"name\":\"C. Wloka\"},{\"authorId\":\"8207080\",\"name\":\"Nick Frosst\"},{\"authorId\":\"51245102\",\"name\":\"Shafin Rahman\"},{\"authorId\":\"1727853\",\"name\":\"John K. Tsotsos\"}],\"doi\":\"10.1016/j.visres.2015.01.010\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"43236b0c968e08b7444742dc71811127288e804c\",\"title\":\"On computational modeling of visual saliency: Examining what\\u2019s right, and what\\u2019s left\",\"url\":\"https://www.semanticscholar.org/paper/43236b0c968e08b7444742dc71811127288e804c\",\"venue\":\"Vision Research\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2997408\",\"name\":\"Matthias K\\u00fcmmerer\"},{\"authorId\":\"49737748\",\"name\":\"Thomas S. A. Wallis\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":\"10.1073/pnas.1510393112\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"01058e4aabd61571da9e43a618834c90aabaf691\",\"title\":\"Information-theoretic model comparison unifies saliency metrics\",\"url\":\"https://www.semanticscholar.org/paper/01058e4aabd61571da9e43a618834c90aabaf691\",\"venue\":\"Proceedings of the National Academy of Sciences\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3376641\",\"name\":\"A. Nuthmann\"},{\"authorId\":\"1917767\",\"name\":\"W. Einh\\u00e4user\"},{\"authorId\":\"46510545\",\"name\":\"Immo Schuetz\"}],\"doi\":\"10.3389/fnhum.2017.00491\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e1c2d5aeb31709e9ffd5ffe0b259805f38d16ae5\",\"title\":\"How Well Can Saliency Models Predict Fixation Selection in Scenes Beyond Central Bias? A New Approach to Model Evaluation Using Generalized Linear Mixed Models\",\"url\":\"https://www.semanticscholar.org/paper/e1c2d5aeb31709e9ffd5ffe0b259805f38d16ae5\",\"venue\":\"Front. Hum. Neurosci.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1722881\",\"name\":\"Jiazhong Chen\"},{\"authorId\":\"47422623\",\"name\":\"Q. Li\"},{\"authorId\":\"144785138\",\"name\":\"P. Li\"},{\"authorId\":\"145312326\",\"name\":\"Y. Han\"},{\"authorId\":\"145233508\",\"name\":\"Lei Wu\"},{\"authorId\":\"144125487\",\"name\":\"Hefei Ling\"},{\"authorId\":\"9315669\",\"name\":\"Weimin Wu\"}],\"doi\":\"10.1016/J.JVCIR.2019.02.026\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d7e6b579a40169e2158858f75e36b1be54969cf4\",\"title\":\"Saliency prediction by Mahalanobis distance of topological feature on deep color components\",\"url\":\"https://www.semanticscholar.org/paper/d7e6b579a40169e2158858f75e36b1be54969cf4\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145520454\",\"name\":\"A. Silva\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"82f6fb6d993f6898db5ee5413e8d5d9c039c7683\",\"title\":\"No-reference video quality assessment model based on artifact metrics for digital transmission applications\",\"url\":\"https://www.semanticscholar.org/paper/82f6fb6d993f6898db5ee5413e8d5d9c039c7683\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"102300440\",\"name\":\"Jakob Wiesinger\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"90d8bec9414f1c9dbca3be1ef9ff0fd0cd7b4f36\",\"title\":\"Video Saliency Detection Using Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/90d8bec9414f1c9dbca3be1ef9ff0fd0cd7b4f36\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1789744\",\"name\":\"O. Meur\"},{\"authorId\":\"2624078\",\"name\":\"A. Coutrot\"},{\"authorId\":\"9558003\",\"name\":\"A. L. Roch\"},{\"authorId\":\"5331893\",\"name\":\"A. Helo\"},{\"authorId\":\"38538945\",\"name\":\"P. Rama\"},{\"authorId\":\"37066739\",\"name\":\"Zhi Liu\"}],\"doi\":\"10.1109/ICIP.2017.8296981\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"32f937dfae3de8b62e870c876167c150894b9e3e\",\"title\":\"Age-dependent saccadic models for predicting eye movements\",\"url\":\"https://www.semanticscholar.org/paper/32f937dfae3de8b62e870c876167c150894b9e3e\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2418491\",\"name\":\"M. Zhang\"},{\"authorId\":\"21007367\",\"name\":\"K. T. Ma\"},{\"authorId\":\"153239355\",\"name\":\"J. H. Lim\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":\"10.1109/CVPR.2017.377\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f95e349489aa48fc57494aab101d58c496cc35f5\",\"title\":\"Deep Future Gaze: Gaze Anticipation on Egocentric Videos Using Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/f95e349489aa48fc57494aab101d58c496cc35f5\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"},{\"authorId\":\"4265660\",\"name\":\"E. M. DeGennaro\"},{\"authorId\":\"2533298\",\"name\":\"R. Rajalingham\"},{\"authorId\":\"35236664\",\"name\":\"H. Ruda\"},{\"authorId\":\"51028388\",\"name\":\"J. Zhang\"},{\"authorId\":\"51421045\",\"name\":\"J. K. Tsotsos\"}],\"doi\":\"10.1016/j.visres.2015.04.007\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"de4bcded33b562a8af7f601d17c3202965eb4034\",\"title\":\"Towards the quantitative evaluation of visual attention models\",\"url\":\"https://www.semanticscholar.org/paper/de4bcded33b562a8af7f601d17c3202965eb4034\",\"venue\":\"Vision Research\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1007/978-3-319-48881-3_21\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"874b49dc4f20dcc01f8163a92f8562a36bd30161\",\"title\":\"Multi-level Net: A Visual Saliency Prediction Model\",\"url\":\"https://www.semanticscholar.org/paper/874b49dc4f20dcc01f8163a92f8562a36bd30161\",\"venue\":\"ECCV Workshops\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2468613\",\"name\":\"V. Kachurka\"},{\"authorId\":\"39759946\",\"name\":\"K. Madani\"},{\"authorId\":\"46355228\",\"name\":\"C. Sabourin\"},{\"authorId\":\"7687283\",\"name\":\"V. Golovko\"}],\"doi\":\"10.1109/IDAACS.2015.7340736\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"afec02b655ec444fcb8160eede8e841578dd4757\",\"title\":\"Visual saliency based approach to object detection in computer vision systems: Real life applications\",\"url\":\"https://www.semanticscholar.org/paper/afec02b655ec444fcb8160eede8e841578dd4757\",\"venue\":\"2015 IEEE 8th International Conference on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications (IDAACS)\",\"year\":2015},{\"arxivId\":\"1707.06029\",\"authors\":[{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"1899119\",\"name\":\"Jongwook Choi\"},{\"authorId\":\"4945045\",\"name\":\"Yeonhwa Kim\"},{\"authorId\":\"143912065\",\"name\":\"Kyung Yoo\"},{\"authorId\":\"2135453\",\"name\":\"S. Lee\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1109/CVPR.2017.648\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1a7f16a3b5acaf4aaf9581e2a5a15867e883a95d\",\"title\":\"Supervising Neural Attention Models for Video Captioning by Human Gaze Data\",\"url\":\"https://www.semanticscholar.org/paper/1a7f16a3b5acaf4aaf9581e2a5a15867e883a95d\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1705.02544\",\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"}],\"doi\":\"10.1109/TIP.2017.2787612\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"65c1a8cde4030217bec7cb96b8bf94c5321e8d8e\",\"title\":\"Deep Visual Attention Prediction\",\"url\":\"https://www.semanticscholar.org/paper/65c1a8cde4030217bec7cb96b8bf94c5321e8d8e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":\"1905.10444\",\"authors\":[{\"authorId\":\"144656873\",\"name\":\"Oleksii Sidorov\"},{\"authorId\":\"39296455\",\"name\":\"Joshua S. Harvey\"},{\"authorId\":\"3246878\",\"name\":\"Hannah E. Smithson\"},{\"authorId\":\"1993363\",\"name\":\"Jon Y. Hardeberg\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a9f7a9db9a53d5dc3debc2dee010331131c56b5e\",\"title\":\"Overt visual attention on rendered 3D objects\",\"url\":\"https://www.semanticscholar.org/paper/a9f7a9db9a53d5dc3debc2dee010331131c56b5e\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2021805\",\"name\":\"V. Buso\"},{\"authorId\":\"1381345946\",\"name\":\"J. Benois-Pineau\"},{\"authorId\":\"1746076\",\"name\":\"Jean-Philippe Domenger\"}],\"doi\":\"10.1007/s11042-015-2803-2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2bd8fd3f9ac207600460ab0c9fe7fa8a136f9618\",\"title\":\"Geometrical cues in visual saliency models for active object recognition in egocentric videos\",\"url\":\"https://www.semanticscholar.org/paper/2bd8fd3f9ac207600460ab0c9fe7fa8a136f9618\",\"venue\":\"PIVP '14\",\"year\":2014},{\"arxivId\":\"1606.07324\",\"authors\":[{\"authorId\":\"36477236\",\"name\":\"Aniello Raffaele Patrone\"},{\"authorId\":\"2926660\",\"name\":\"Christian Valuch\"},{\"authorId\":\"2172674\",\"name\":\"Ulrich Ansorge\"},{\"authorId\":\"3191024\",\"name\":\"Otmar Scherzer\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4c0d6d5f648008ecae6166551fc9776ed57d8f92\",\"title\":\"Dynamical optical flow of saliency maps for predicting visual attention\",\"url\":\"https://www.semanticscholar.org/paper/4c0d6d5f648008ecae6166551fc9776ed57d8f92\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1809.00644\",\"authors\":[{\"authorId\":\"51430629\",\"name\":\"Shanghua Xiao\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"155d51a08dc15e7a77a3e7f317ab434e5842de8b\",\"title\":\"Learning Saliency Prediction From Sparse Fixation Pixel Map\",\"url\":\"https://www.semanticscholar.org/paper/155d51a08dc15e7a77a3e7f317ab434e5842de8b\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47415361\",\"name\":\"Tao Deng\"},{\"authorId\":\"48506762\",\"name\":\"Hongmei Yan\"},{\"authorId\":\"40548435\",\"name\":\"L. Qin\"},{\"authorId\":\"40092548\",\"name\":\"Thuyen Ngo\"},{\"authorId\":\"50591689\",\"name\":\"B. S. Manjunath\"}],\"doi\":\"10.1109/TITS.2019.2915540\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f612076edfc2959d2bab2bfa470654845bf84a5d\",\"title\":\"How Do Drivers Allocate Their Potential Attention? Driving Fixation Prediction via Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/f612076edfc2959d2bab2bfa470654845bf84a5d\",\"venue\":\"IEEE Transactions on Intelligent Transportation Systems\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1722881\",\"name\":\"Jiazhong Chen\"},{\"authorId\":\"1798982\",\"name\":\"Bingpeng Ma\"},{\"authorId\":\"47709738\",\"name\":\"Hua Cao\"},{\"authorId\":\"47740650\",\"name\":\"Jian Jhen Chen\"},{\"authorId\":\"2644590\",\"name\":\"Yebin Fan\"},{\"authorId\":\"143680320\",\"name\":\"T. Xia\"},{\"authorId\":\"3990155\",\"name\":\"R. Li\"}],\"doi\":\"10.1016/j.neucom.2017.04.020\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ad70ed23b5e40f3d113f2bcba1b9f4006aaca633\",\"title\":\"Attention region detection based on closure prior in layered bit Planes\",\"url\":\"https://www.semanticscholar.org/paper/ad70ed23b5e40f3d113f2bcba1b9f4006aaca633\",\"venue\":\"Neurocomputing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"83143774\",\"name\":\"Sofia Krasovskaya\"},{\"authorId\":\"48268905\",\"name\":\"W. J. MacInnes\"}],\"doi\":\"10.3390/vision3040056\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f5dbdbb939d6b16c380bb930e7a52196f5d0e7a3\",\"title\":\"Salience Models: A Computational Cognitive Neuroscience Review\",\"url\":\"https://www.semanticscholar.org/paper/f5dbdbb939d6b16c380bb930e7a52196f5d0e7a3\",\"venue\":\"Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2302174\",\"name\":\"Dounia Awad\"},{\"authorId\":\"1747906\",\"name\":\"V. Courboulay\"},{\"authorId\":\"39482544\",\"name\":\"A. Revel\"}],\"doi\":\"10.1007/978-1-4939-3435-5_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"44f5840e0aaf6f49b07c6b05bfcf9f5ed6683b0e\",\"title\":\"Attentive Content-Based Image Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/44f5840e0aaf6f49b07c6b05bfcf9f5ed6683b0e\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145519708\",\"name\":\"J. Li\"},{\"authorId\":\"2749565\",\"name\":\"Changqun Xia\"},{\"authorId\":\"2839196\",\"name\":\"Yafei Song\"},{\"authorId\":\"145021810\",\"name\":\"Shu Fang\"},{\"authorId\":\"33610144\",\"name\":\"X. Chen\"}],\"doi\":\"10.1109/ICCV.2015.30\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3e32b6325e6aa267a5f0cde1edd45c5a72ed3de6\",\"title\":\"A Data-Driven Metric for Comprehensive Evaluation of Saliency Models\",\"url\":\"https://www.semanticscholar.org/paper/3e32b6325e6aa267a5f0cde1edd45c5a72ed3de6\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1803.05759\",\"authors\":[{\"authorId\":\"47287647\",\"name\":\"Sen He\"},{\"authorId\":\"3251678\",\"name\":\"N. Pugeault\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"1da3e74e10b8fe2708c81ddabb480e8d7929a589\",\"title\":\"Salient Region Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/1da3e74e10b8fe2708c81ddabb480e8d7929a589\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"2509726\",\"name\":\"Xingping Dong\"},{\"authorId\":\"51004202\",\"name\":\"A. Borji\"},{\"authorId\":\"38958903\",\"name\":\"Ruigang Yang\"}],\"doi\":\"10.1109/TPAMI.2019.2905607\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"39e79c92a0a7653ee4177c6b94eee4368f6ca4b0\",\"title\":\"Inferring Salient Objects from Human Fixations\",\"url\":\"https://www.semanticscholar.org/paper/39e79c92a0a7653ee4177c6b94eee4368f6ca4b0\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143741775\",\"name\":\"F. Zhou\"},{\"authorId\":\"80947730\",\"name\":\"Rongguo Yao\"},{\"authorId\":\"1474234993\",\"name\":\"Guangsen Liao\"},{\"authorId\":\"3185721\",\"name\":\"Bozhi Liu\"},{\"authorId\":\"1713506\",\"name\":\"Guoping Qiu\"}],\"doi\":\"10.1109/TIP.2020.3016464\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"10d15860ece08b185b115da2b03075d7e8065f4e\",\"title\":\"Visual Saliency via Embedding Hierarchical Knowledge in a Deep Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/10d15860ece08b185b115da2b03075d7e8065f4e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1803.09125\",\"authors\":[{\"authorId\":\"48355461\",\"name\":\"Yifei Huang\"},{\"authorId\":\"3172280\",\"name\":\"Minjie Cai\"},{\"authorId\":\"46947776\",\"name\":\"Zhenqiang Li\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1007/978-3-030-01225-0_46\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"7e236d33dce5d30348aeb494e491a13468133b4e\",\"title\":\"Predicting Gaze in Egocentric Video by Learning Task-dependent Attention Transition\",\"url\":\"https://www.semanticscholar.org/paper/7e236d33dce5d30348aeb494e491a13468133b4e\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2602925\",\"name\":\"Boris Schauerte\"},{\"authorId\":\"2159324\",\"name\":\"T. W\\u00f6rtwein\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"}],\"doi\":\"10.1109/ICIP.2015.7351144\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5e22d0203fb48179268206f14bff9e63861718e5\",\"title\":\"Color decorrelation helps visual saliency detection\",\"url\":\"https://www.semanticscholar.org/paper/5e22d0203fb48179268206f14bff9e63861718e5\",\"venue\":\"2015 IEEE International Conference on Image Processing (ICIP)\",\"year\":2015},{\"arxivId\":\"2012.14185\",\"authors\":[{\"authorId\":\"83015253\",\"name\":\"Alex Hern\\u00e1ndez-Garc\\u00eda\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"5e21d7ce531a81817d5f4de8ff5de3e444cf6629\",\"title\":\"Data augmentation and image understanding\",\"url\":\"https://www.semanticscholar.org/paper/5e21d7ce531a81817d5f4de8ff5de3e444cf6629\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1604.03605\",\"authors\":[{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"},{\"authorId\":\"152627906\",\"name\":\"T. Judd\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"}],\"doi\":\"10.1109/TPAMI.2018.2815601\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"bfdf3431ff5182b585b3b0c11fa8cbfc13a6bde4\",\"title\":\"What Do Different Evaluation Metrics Tell Us About Saliency Models?\",\"url\":\"https://www.semanticscholar.org/paper/bfdf3431ff5182b585b3b0c11fa8cbfc13a6bde4\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5550675\",\"name\":\"Y. Li\"},{\"authorId\":\"1678689\",\"name\":\"S. Wang\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"},{\"authorId\":\"48539971\",\"name\":\"X. Ding\"}],\"doi\":\"10.1016/j.neucom.2014.08.003\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e1842bc0fcf21972200a97c91216a449eda4903d\",\"title\":\"A survey of recent advances in visual feature detection\",\"url\":\"https://www.semanticscholar.org/paper/e1842bc0fcf21972200a97c91216a449eda4903d\",\"venue\":\"Neurocomputing\",\"year\":2015},{\"arxivId\":\"1909.06761\",\"authors\":[{\"authorId\":\"51463388\",\"name\":\"G. Kapidis\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"},{\"authorId\":\"8297919\",\"name\":\"E. V. Dam\"},{\"authorId\":\"144882447\",\"name\":\"L. Noldus\"},{\"authorId\":\"47329105\",\"name\":\"Remco C. Veltkamp\"}],\"doi\":\"10.1109/ICCVW.2019.00540\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"8cca4d9e7831cad9d7b4e9693a1be9b6eaea8805\",\"title\":\"Multitask Learning to Improve Egocentric Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8cca4d9e7831cad9d7b4e9693a1be9b6eaea8805\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1485579309\",\"name\":\"Juliette Aychet\"},{\"authorId\":\"1473788000\",\"name\":\"Pablo Pezzino\"},{\"authorId\":\"48313108\",\"name\":\"Arnaud Rossard\"},{\"authorId\":\"4671042\",\"name\":\"P. Bec\"},{\"authorId\":\"1398411092\",\"name\":\"C. Blois-Heulin\"},{\"authorId\":\"144965558\",\"name\":\"A. Lemasson\"}],\"doi\":\"10.1038/s41598-020-69847-6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"91eda09846c35fa52fe6a732b7b5dc4253f6b9d7\",\"title\":\"Red-capped mangabeys (Cercocebus torquatus) adapt their interspecific gestural communication to the recipient\\u2019s behaviour\",\"url\":\"https://www.semanticscholar.org/paper/91eda09846c35fa52fe6a732b7b5dc4253f6b9d7\",\"venue\":\"Scientific Reports\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2569326\",\"name\":\"I. Rigas\"},{\"authorId\":\"1778350\",\"name\":\"Oleg V. Komogortsev\"}],\"doi\":\"10.1109/TIFS.2014.2350960\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c50ff6a74f7a948fbb8ed43eaecda3b586020105\",\"title\":\"Biometric Recognition via Probabilistic Spatial Projection of Eye Movement Trajectories in Dynamic Visual Environments\",\"url\":\"https://www.semanticscholar.org/paper/c50ff6a74f7a948fbb8ed43eaecda3b586020105\",\"venue\":\"IEEE Transactions on Information Forensics and Security\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145517048\",\"name\":\"D. Benjamin\"},{\"authorId\":\"34796819\",\"name\":\"D. Lyons\"},{\"authorId\":\"50179497\",\"name\":\"Hong Yue\"}],\"doi\":\"10.1117/12.2229551\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"acc450477d0b2d6bd4c7648922277b59008e1243\",\"title\":\"Progress in building a cognitive vision system\",\"url\":\"https://www.semanticscholar.org/paper/acc450477d0b2d6bd4c7648922277b59008e1243\",\"venue\":\"Commercial + Scientific Sensing and Imaging\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"117562053\",\"name\":\"M. A. Reina\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1f1996c60dec75d575f20880a49d646a42584f3a\",\"title\":\"The temporal dimension of visual attention models\",\"url\":\"https://www.semanticscholar.org/paper/1f1996c60dec75d575f20880a49d646a42584f3a\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1803.04842\",\"authors\":[{\"authorId\":\"1398288379\",\"name\":\"A. Banitalebi-Dehkordi\"},{\"authorId\":\"49617585\",\"name\":\"M. Pourazad\"},{\"authorId\":\"1687935\",\"name\":\"P. Nasiopoulos\"}],\"doi\":\"10.1007/s11042-016-4155-y\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d38a6ce1f01d2d51da65291f532b773e27b4bf21\",\"title\":\"A learning-based visual saliency prediction model for stereoscopic 3D video (LBVS-3D)\",\"url\":\"https://www.semanticscholar.org/paper/d38a6ce1f01d2d51da65291f532b773e27b4bf21\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47295036\",\"name\":\"Zehua Zhang\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"},{\"authorId\":\"145864858\",\"name\":\"Chen Yu\"},{\"authorId\":\"2798750\",\"name\":\"Sven Bambach\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"5a089bc28160fa236f219c6760b6a48c9b8d3d10\",\"title\":\"From Coarse Attention to Fine-Grained Gaze: A Two-stage 3D Fully Convolutional Network for Predicting Eye Gaze in First Person Video\",\"url\":\"https://www.semanticscholar.org/paper/5a089bc28160fa236f219c6760b6a48c9b8d3d10\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7181955\",\"name\":\"J. Han\"},{\"authorId\":\"2162917\",\"name\":\"L. Sun\"},{\"authorId\":\"39901030\",\"name\":\"Dingwen Zhang\"},{\"authorId\":\"1742535\",\"name\":\"X. Hu\"},{\"authorId\":null,\"name\":\"Gong Cheng\"},{\"authorId\":\"143621713\",\"name\":\"L. Guo\"}],\"doi\":\"10.1109/ICME.2014.6890215\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"acd82620203bcab17044007ba8ff33b765d45c87\",\"title\":\"Visual attention computation in video of driving environment\",\"url\":\"https://www.semanticscholar.org/paper/acd82620203bcab17044007ba8ff33b765d45c87\",\"venue\":\"2014 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49047213\",\"name\":\"Congcong Liu\"},{\"authorId\":\"49069718\",\"name\":\"Y. Chen\"},{\"authorId\":\"70308463\",\"name\":\"L. Tai\"},{\"authorId\":\"9947757\",\"name\":\"Haoyang Ye\"},{\"authorId\":\"145111960\",\"name\":\"Ming Liu\"},{\"authorId\":\"2131088\",\"name\":\"B. Shi\"}],\"doi\":\"10.1145/3314111.3319846\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"327546dbb99837e4e14e5013ecb5db7587ff067a\",\"title\":\"A gaze model improves autonomous driving\",\"url\":\"https://www.semanticscholar.org/paper/327546dbb99837e4e14e5013ecb5db7587ff067a\",\"venue\":\"ETRA\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145800409\",\"name\":\"Anna Volokitin\"},{\"authorId\":\"3037160\",\"name\":\"Michael Gygli\"},{\"authorId\":\"2343486\",\"name\":\"X. Boix\"}],\"doi\":\"10.1109/CVPR.2016.65\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e2d6767123e26ab804401278e5d6941c9484f6f3\",\"title\":\"Predicting When Saliency Maps are Accurate and Eye Fixations Consistent\",\"url\":\"https://www.semanticscholar.org/paper/e2d6767123e26ab804401278e5d6941c9484f6f3\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46663708\",\"name\":\"J. Y. Lee\"},{\"authorId\":\"7137846\",\"name\":\"Joonbum Lee\"},{\"authorId\":\"70249222\",\"name\":\"J. Lee\"}],\"doi\":\"10.1177/1541931213601427\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4d0bb2beae156b8287e999d83af02ff00e2b74da\",\"title\":\"A Visual Search Model for In-Vehicle Interface Design\",\"url\":\"https://www.semanticscholar.org/paper/4d0bb2beae156b8287e999d83af02ff00e2b74da\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1707.03123\",\"authors\":[{\"authorId\":\"22206915\",\"name\":\"Marc Assens\"},{\"authorId\":\"3100480\",\"name\":\"Xavier Giro-i-Nieto\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"}],\"doi\":\"10.1109/ICCVW.2017.275\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10816358c78a6f7372620e4f59b54ba1c69c2022\",\"title\":\"SaltiNet: Scan-Path Prediction on 360 Degree Images Using Saliency Volumes\",\"url\":\"https://www.semanticscholar.org/paper/10816358c78a6f7372620e4f59b54ba1c69c2022\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2978154\",\"name\":\"Hossam Fraihat\"},{\"authorId\":\"39759946\",\"name\":\"K. Madani\"},{\"authorId\":\"46355228\",\"name\":\"C. Sabourin\"}],\"doi\":\"10.1007/978-3-319-59147-6_55\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e923497fd753780675ac06a6d40aa9c406364547\",\"title\":\"A Pseudo-3D Vision-Based Dual Approach for Machine-Awareness in Indoor Environment Combining Multi-resolution Visual Information\",\"url\":\"https://www.semanticscholar.org/paper/e923497fd753780675ac06a6d40aa9c406364547\",\"venue\":\"IWANN\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"83015253\",\"name\":\"Alex Hern\\u00e1ndez-Garc\\u00eda\"},{\"authorId\":\"10995269\",\"name\":\"Ricardo Ramos Gameiro\"},{\"authorId\":\"46203125\",\"name\":\"A. Grillini\"},{\"authorId\":\"144027562\",\"name\":\"P. K\\u00f6nig\"}],\"doi\":\"10.1167/jov.20.7.27\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d267fd8706d7ff33f3c03904e717799fc4a6810c\",\"title\":\"Global visual salience of competing stimuli\",\"url\":\"https://www.semanticscholar.org/paper/d267fd8706d7ff33f3c03904e717799fc4a6810c\",\"venue\":\"Journal of vision\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144298302\",\"name\":\"B. Hu\"},{\"authorId\":\"1456739624\",\"name\":\"Ralinkae Kane-Jackson\"},{\"authorId\":\"3271571\",\"name\":\"E. Niebur\"}],\"doi\":\"10.1016/j.visres.2015.12.004\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bbb8d04505db360bcc89c6c6b7917a7aa63948ba\",\"title\":\"A proto-object based saliency model in three-dimensional space\",\"url\":\"https://www.semanticscholar.org/paper/bbb8d04505db360bcc89c6c6b7917a7aa63948ba\",\"venue\":\"Vision Research\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2418491\",\"name\":\"M. Zhang\"},{\"authorId\":\"1397677751\",\"name\":\"Keng Teck Ma\"},{\"authorId\":\"9183286\",\"name\":\"Joo-Hwee Lim\"},{\"authorId\":\"153386875\",\"name\":\"Q. Zhao\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":\"10.1109/TPAMI.2018.2871688\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2f04a3d8eacfa22a299e0c5a7edcc69d0fdd5933\",\"title\":\"Anticipating Where People will Look Using Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/2f04a3d8eacfa22a299e0c5a7edcc69d0fdd5933\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153147523\",\"name\":\"Kanghan Oh\"},{\"authorId\":\"1827953\",\"name\":\"Myungeun Lee\"},{\"authorId\":\"7856608\",\"name\":\"Yura Lee\"},{\"authorId\":\"2355626\",\"name\":\"Soohyung Kim\"}],\"doi\":\"10.1016/j.ins.2017.01.019\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b5f24abf3b35cd7e39b2cf140496187f0ff568e7\",\"title\":\"Salient object detection using recursive regional feature clustering\",\"url\":\"https://www.semanticscholar.org/paper/b5f24abf3b35cd7e39b2cf140496187f0ff568e7\",\"venue\":\"Inf. Sci.\",\"year\":2017},{\"arxivId\":\"1901.05002\",\"authors\":[{\"authorId\":\"51430629\",\"name\":\"Shanghua Xiao\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8399ce2555984ba5e309be575ca217f0e15a7fc3\",\"title\":\"Light-weighted Saliency Detection with Distinctively Lower Memory Cost and Model Size\",\"url\":\"https://www.semanticscholar.org/paper/8399ce2555984ba5e309be575ca217f0e15a7fc3\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1904.03571\",\"authors\":[{\"authorId\":\"144545126\",\"name\":\"S. Yang\"},{\"authorId\":\"2604251\",\"name\":\"Guosheng Lin\"},{\"authorId\":\"3318404\",\"name\":\"Qiuping Jiang\"},{\"authorId\":\"144968898\",\"name\":\"W. Lin\"}],\"doi\":\"10.1109/TMM.2019.2947352\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"023b11c04e5ea605fe999b015cbf62502cab068b\",\"title\":\"A Dilated Inception Network for Visual Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/023b11c04e5ea605fe999b015cbf62502cab068b\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2997408\",\"name\":\"Matthias K\\u00fcmmerer\"},{\"authorId\":\"49737748\",\"name\":\"Thomas S. A. Wallis\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":\"10.1007/978-3-030-01270-0_47\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d9a484f6ffd5fc006401dee749493142623ba4c9\",\"title\":\"Saliency Benchmarking Made Easy: Separating Models, Maps and Metrics\",\"url\":\"https://www.semanticscholar.org/paper/d9a484f6ffd5fc006401dee749493142623ba4c9\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1609.01064\",\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/ICPR.2016.7900174\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"57e143c96a41ba81d9d59120a1cd0dc04905d3f1\",\"title\":\"A deep multi-level network for saliency prediction\",\"url\":\"https://www.semanticscholar.org/paper/57e143c96a41ba81d9d59120a1cd0dc04905d3f1\",\"venue\":\"2016 23rd International Conference on Pattern Recognition (ICPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2911844\",\"name\":\"C\\u00e9line Craye\"},{\"authorId\":\"1771194\",\"name\":\"David Filliat\"},{\"authorId\":\"150146854\",\"name\":\"Jean-Fra\\u00e7ois Goudou\"}],\"doi\":\"10.1109/TCDS.2018.2806227\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4adde75d14e9720263a963fd23546f2363be30eb\",\"title\":\"BioVision: A Biomimetics Platform for Intrinsically Motivated Visual Saliency Learning\",\"url\":\"https://www.semanticscholar.org/paper/4adde75d14e9720263a963fd23546f2363be30eb\",\"venue\":\"IEEE Transactions on Cognitive and Developmental Systems\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"83143774\",\"name\":\"Sofia Krasovskaya\"},{\"authorId\":\"84336221\",\"name\":\"Georgiy Zhulikov\"},{\"authorId\":\"1738746616\",\"name\":\"Joseph W. MacInnes\"}],\"doi\":\"10.2139/ssrn.3262650\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"890a2e4354fe1ced953a3e8e58065fdbe0072317\",\"title\":\"Deep Learning Neural Networks as a Model of Saccadic Generation\",\"url\":\"https://www.semanticscholar.org/paper/890a2e4354fe1ced953a3e8e58065fdbe0072317\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1409.7686\",\"authors\":[{\"authorId\":\"2997408\",\"name\":\"Matthias K\\u00fcmmerer\"},{\"authorId\":\"39928067\",\"name\":\"T. Wallis\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":\"10.15496/PUBLIKATION-4858\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"abfd3d1fb0c0117905978a470897db053dc7afbb\",\"title\":\"How close are we to understanding image-based saliency?\",\"url\":\"https://www.semanticscholar.org/paper/abfd3d1fb0c0117905978a470897db053dc7afbb\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2637872\",\"name\":\"Y. Niu\"},{\"authorId\":\"73708454\",\"name\":\"J. Chen\"},{\"authorId\":\"145672212\",\"name\":\"Xiao Ke\"},{\"authorId\":\"47740854\",\"name\":\"J. Chen\"}],\"doi\":\"10.1109/ACCESS.2019.2897404\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e81e1edf77c00e11976d0026b3966c62cf4978c6\",\"title\":\"Stereoscopic Image Saliency Detection Optimization: A Multi-Cue-Driven Approach\",\"url\":\"https://www.semanticscholar.org/paper/e81e1edf77c00e11976d0026b3966c62cf4978c6\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1967201\",\"name\":\"Kui Fu\"},{\"authorId\":null,\"name\":\"Jia Li\"},{\"authorId\":\"121194391\",\"name\":\"Hongze Shen\"},{\"authorId\":\"144051792\",\"name\":\"Yonghong Tian\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"737ca6dd41d8bc4f3ce06161bc2e3050a37b050a\",\"title\":\"How Drones Look: Crowdsourced Knowledge Transfer for Aerial Video Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/737ca6dd41d8bc4f3ce06161bc2e3050a37b050a\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145378980\",\"name\":\"Ye Luo\"},{\"authorId\":\"6835136\",\"name\":\"L. Cheong\"},{\"authorId\":\"3154763\",\"name\":\"J. Cabibihan\"}],\"doi\":\"10.1007/978-3-319-16811-1_14\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ca90ab0d39b5a6a42f035cb76885414591cc9665\",\"title\":\"Modeling the Temporality of Saliency\",\"url\":\"https://www.semanticscholar.org/paper/ca90ab0d39b5a6a42f035cb76885414591cc9665\",\"venue\":\"ACCV\",\"year\":2014},{\"arxivId\":\"1604.04825\",\"authors\":[{\"authorId\":\"2177805\",\"name\":\"S. Roy\"},{\"authorId\":\"144240262\",\"name\":\"P. Mitra\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d10b4efd0895bc0d36f6c36d53df9c477d94c8e\",\"title\":\"Visual saliency detection: a Kalman filter based approach\",\"url\":\"https://www.semanticscholar.org/paper/4d10b4efd0895bc0d36f6c36d53df9c477d94c8e\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2215920\",\"name\":\"Vlad Hosu\"},{\"authorId\":\"47177940\",\"name\":\"F. Hahn\"},{\"authorId\":\"2467595\",\"name\":\"I. Zingman\"},{\"authorId\":\"1775428\",\"name\":\"D. Saupe\"}],\"doi\":\"10.21437/PQS.2016-25\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"19d4cdf0a664c5b7ad11b394bdf66f5d37476941\",\"title\":\"Reported Attention as a Promising Alternative to Gaze in IQA Tasks\",\"url\":\"https://www.semanticscholar.org/paper/19d4cdf0a664c5b7ad11b394bdf66f5d37476941\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2430707\",\"name\":\"G. Boato\"},{\"authorId\":\"1381816609\",\"name\":\"Duc-Tien Dang-Nguyen\"},{\"authorId\":\"3302934\",\"name\":\"O. Muratov\"},{\"authorId\":\"1755194\",\"name\":\"N. Alajlan\"},{\"authorId\":\"144211458\",\"name\":\"F. Natale\"}],\"doi\":\"10.1007/s11042-015-2526-4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bc5ad8104ec7591d038bbde485bf70e3c0e3969a\",\"title\":\"Exploiting visual saliency for increasing diversity of image retrieval results\",\"url\":\"https://www.semanticscholar.org/paper/bc5ad8104ec7591d038bbde485bf70e3c0e3969a\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22206915\",\"name\":\"Marc Assens\"},{\"authorId\":\"1398090762\",\"name\":\"Xavier Gir\\u00f3-i-Nieto\"},{\"authorId\":\"145470863\",\"name\":\"K. McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"504eb02718b3ad839d1bb10b19f39fbf3ab4883f\",\"title\":\"Related Work 2 . 1 Visual Saliency Prediction Saliency maps\",\"url\":\"https://www.semanticscholar.org/paper/504eb02718b3ad839d1bb10b19f39fbf3ab4883f\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1395725948\",\"name\":\"Bashir Ghariba\"},{\"authorId\":\"144906448\",\"name\":\"M. Shehata\"},{\"authorId\":\"2903414\",\"name\":\"P. McGuire\"}],\"doi\":\"10.7717/peerj-cs.280\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c981fee8b6cb0af49e6c22e701d760a238aee591\",\"title\":\"A novel fully convolutional network for visual saliency prediction\",\"url\":\"https://www.semanticscholar.org/paper/c981fee8b6cb0af49e6c22e701d760a238aee591\",\"venue\":\"PeerJ Comput. Sci.\",\"year\":2020},{\"arxivId\":\"1809.00567\",\"authors\":[{\"authorId\":\"22206915\",\"name\":\"Marc Assens\"},{\"authorId\":\"3100480\",\"name\":\"Xavier Giro-i-Nieto\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"}],\"doi\":\"10.1007/978-3-030-11021-5_25\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1e1a4f7e2d8dd172e278f148cca1172f313966b4\",\"title\":\"PathGAN: Visual Scanpath Prediction with Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/1e1a4f7e2d8dd172e278f148cca1172f313966b4\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2302174\",\"name\":\"Dounia Awad\"},{\"authorId\":\"1681157\",\"name\":\"M. Mancas\"},{\"authorId\":\"2989773\",\"name\":\"Nicolas Riche\"},{\"authorId\":\"1747906\",\"name\":\"V. Courboulay\"},{\"authorId\":\"39482544\",\"name\":\"A. Revel\"}],\"doi\":\"10.1109/EUSIPCO.2015.7362639\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"055c66028fd23be57025c4ebaf3aa68cb4c3adf4\",\"title\":\"A CBIR-based evaluation framework for visual attention models\",\"url\":\"https://www.semanticscholar.org/paper/055c66028fd23be57025c4ebaf3aa68cb4c3adf4\",\"venue\":\"2015 23rd European Signal Processing Conference (EUSIPCO)\",\"year\":2015},{\"arxivId\":\"1802.07931\",\"authors\":[{\"authorId\":\"10814650\",\"name\":\"Sikun Lin\"},{\"authorId\":\"143966172\",\"name\":\"P. Hui\"}],\"doi\":\"10.14711/thesis-991012554569603412\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a1fdf45e6649b0020eb533c70d6062b9183561ff\",\"title\":\"Where's YOUR focus: Personalized Attention\",\"url\":\"https://www.semanticscholar.org/paper/a1fdf45e6649b0020eb533c70d6062b9183561ff\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1805.01047\",\"authors\":[{\"authorId\":\"1805367\",\"name\":\"Sen Jia\"}],\"doi\":\"10.1016/j.imavis.2020.103887\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"49a94c25bcb323defe63796cf3afd52e2bfd8d48\",\"title\":\"EML-NET: An Expandable Multi-Layer NETwork for Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/49a94c25bcb323defe63796cf3afd52e2bfd8d48\",\"venue\":\"Image Vis. Comput.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1803942\",\"name\":\"R. Kannan\"},{\"authorId\":\"1795412\",\"name\":\"G. Ghinea\"},{\"authorId\":\"1808749\",\"name\":\"S. Swaminathan\"}],\"doi\":\"10.1016/j.image.2015.07.004\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a28b470e5679312051d0e754ce8bf2b596e4b2ab\",\"title\":\"Discovering salient objects from videos using spatiotemporal salient region detection\",\"url\":\"https://www.semanticscholar.org/paper/a28b470e5679312051d0e754ce8bf2b596e4b2ab\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144774497\",\"name\":\"D. Sen\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":\"10.1016/j.image.2015.02.002\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8395c4f5b005d0358e90063d3ce1ff41d5848baf\",\"title\":\"Salience computation in images based on perceptual distinctness\",\"url\":\"https://www.semanticscholar.org/paper/8395c4f5b005d0358e90063d3ce1ff41d5848baf\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"20823563\",\"name\":\"H. Takimoto\"},{\"authorId\":\"24785136\",\"name\":\"Syuhei Hitomi\"},{\"authorId\":\"47739449\",\"name\":\"H. Yamauchi\"},{\"authorId\":\"1763187\",\"name\":\"M. Kishihara\"},{\"authorId\":\"2288024\",\"name\":\"K. Okubo\"}],\"doi\":\"10.1587/TRANSINF.2016EDP7413\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3b9f2fc7e5cd3ec8ae8c1f106fe2edde0baecba4\",\"title\":\"Image Modification Based on Spatial Frequency Components for Visual Attention Retargeting\",\"url\":\"https://www.semanticscholar.org/paper/3b9f2fc7e5cd3ec8ae8c1f106fe2edde0baecba4\",\"venue\":\"IEICE Trans. Inf. Syst.\",\"year\":2017},{\"arxivId\":\"1803.04836\",\"authors\":[{\"authorId\":\"9023711\",\"name\":\"A. B. Dehkordi\"}],\"doi\":\"10.14288/1.0166613\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"58141c9f8cf4f6cec747fa71bdcdedb78a79519d\",\"title\":\"3D video quality assessment\",\"url\":\"https://www.semanticscholar.org/paper/58141c9f8cf4f6cec747fa71bdcdedb78a79519d\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2602985\",\"name\":\"Alan Dolhasz\"},{\"authorId\":\"2201800\",\"name\":\"M. F. Pascual\"},{\"authorId\":\"144847579\",\"name\":\"I. Williams\"}],\"doi\":\"10.1109/ISMAR-Adjunct.2017.21\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b318b7292af371e582cf4ef9316cf9acdc7a1596\",\"title\":\"[POSTER] Composite Realism: Effects of Object Knowledge and Mismatched Feature Type on Observer Gaze and Subjective Quality\",\"url\":\"https://www.semanticscholar.org/paper/b318b7292af371e582cf4ef9316cf9acdc7a1596\",\"venue\":\"2017 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39759946\",\"name\":\"K. Madani\"},{\"authorId\":\"2468613\",\"name\":\"V. Kachurka\"},{\"authorId\":\"46355228\",\"name\":\"C. Sabourin\"},{\"authorId\":\"7687283\",\"name\":\"V. Golovko\"}],\"doi\":\"10.1007/S00500-017-2931-X\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0ecf109e9292f040bce121086065f48391739999\",\"title\":\"A soft-computing-based approach to artificial visual attention using human eye-fixation paradigm: toward a human-like skill in robot vision\",\"url\":\"https://www.semanticscholar.org/paper/0ecf109e9292f040bce121086065f48391739999\",\"venue\":\"Soft Comput.\",\"year\":2019},{\"arxivId\":\"1607.04730\",\"authors\":[{\"authorId\":\"34847250\",\"name\":\"\\u00c7agdas Bak\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dac2e8365df576e6d3f16b01d48e0d5e4156b81f\",\"title\":\"Two-Stream Convolutional Networks for Dynamic Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/dac2e8365df576e6d3f16b01d48e0d5e4156b81f\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1976417\",\"name\":\"Christian Frisson\"},{\"authorId\":\"2989773\",\"name\":\"Nicolas Riche\"},{\"authorId\":\"2624078\",\"name\":\"A. Coutrot\"},{\"authorId\":\"3366146\",\"name\":\"Charles-Alexandre Delestage\"},{\"authorId\":\"153352427\",\"name\":\"S. Dupont\"},{\"authorId\":\"2578330\",\"name\":\"Onur Ferhat\"},{\"authorId\":\"3252109\",\"name\":\"N. Guyader\"},{\"authorId\":\"1777727\",\"name\":\"S. Mahmoudi\"},{\"authorId\":\"1681157\",\"name\":\"M. Mancas\"},{\"authorId\":\"2306103\",\"name\":\"Parag K. Mital\"},{\"authorId\":null,\"name\":\"Alicia Prieto Ech\\u00e1niz\"},{\"authorId\":\"144463020\",\"name\":\"F. Rocca\"},{\"authorId\":\"39300341\",\"name\":\"Alexis Rochette\"},{\"authorId\":\"3076844\",\"name\":\"W. Yvart\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1f3f56d4a8f31350db155a62319713987a1681d2\",\"title\":\"Auracle: how are salient cues situated in audiovisual content?\",\"url\":\"https://www.semanticscholar.org/paper/1f3f56d4a8f31350db155a62319713987a1681d2\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5021307\",\"name\":\"Vincent Sitzmann\"},{\"authorId\":\"143772343\",\"name\":\"Ana Serrano\"},{\"authorId\":\"48453720\",\"name\":\"A. Pavel\"},{\"authorId\":\"1820412\",\"name\":\"M. Agrawala\"},{\"authorId\":\"143876232\",\"name\":\"D. Gutierrez\"},{\"authorId\":\"1731170\",\"name\":\"G. Wetzstein\"}],\"doi\":\"10.1109/TVCG.2018.2793599\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c3d382d1aad38e7e1a9249a7bd323f9a5cf92ca8\",\"title\":\"Saliency in VR: How Do People Explore Virtual Environments?\",\"url\":\"https://www.semanticscholar.org/paper/c3d382d1aad38e7e1a9249a7bd323f9a5cf92ca8\",\"venue\":\"IEEE Transactions on Visualization and Computer Graphics\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143852685\",\"name\":\"H. Tavakoli\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"142ab7253bbf1d0144faa741d0c5c83033b362bc\",\"title\":\"Visual saliency and eye movement : modeling and applications\",\"url\":\"https://www.semanticscholar.org/paper/142ab7253bbf1d0144faa741d0c5c83033b362bc\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4800511\",\"name\":\"Don Adjeroh\"},{\"authorId\":\"49014513\",\"name\":\"T. Bell\"},{\"authorId\":\"143887818\",\"name\":\"A. Mukherjee\"},{\"authorId\":\"143783379\",\"name\":\"Yonina C. Eldar\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"edd9d3323c451b1b25da1d624324f45024e17075\",\"title\":\"Foundations and Trends R \\u00a9 in Signal Processing\",\"url\":\"https://www.semanticscholar.org/paper/edd9d3323c451b1b25da1d624324f45024e17075\",\"venue\":\"\",\"year\":2013},{\"arxivId\":\"1910.13066\",\"authors\":[{\"authorId\":\"51925488\",\"name\":\"David Berga\"},{\"authorId\":\"1390040513\",\"name\":\"X. R. Fdez-Vidal\"},{\"authorId\":\"2556319\",\"name\":\"X. Otazu\"},{\"authorId\":\"40538374\",\"name\":\"Xos\\u00e9 M. Pardo\"}],\"doi\":\"10.1109/ICCV.2019.00888\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d24f772368b77ac9d67eb72fa6b95d880dc64b97\",\"title\":\"SID4VAM: A Benchmark Dataset With Synthetic Images for Visual Attention Modeling\",\"url\":\"https://www.semanticscholar.org/paper/d24f772368b77ac9d67eb72fa6b95d880dc64b97\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37503295\",\"name\":\"J. Chen\"},{\"authorId\":\"47422623\",\"name\":\"Q. Li\"},{\"authorId\":\"102937546\",\"name\":\"Weimin Wu\"},{\"authorId\":\"2175693\",\"name\":\"He-Fei Ling\"},{\"authorId\":\"152318075\",\"name\":\"Lei Wu\"},{\"authorId\":\"17668082\",\"name\":\"Baiyan Zhang\"},{\"authorId\":\"2420746\",\"name\":\"P. Li\"}],\"doi\":\"10.1109/ICIP.2019.8802611\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ad2ba1e97dc2c75ecf03e80b4212e6b3f08b811e\",\"title\":\"Saliency Detection via Topological Feature Modulated Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/ad2ba1e97dc2c75ecf03e80b4212e6b3f08b811e\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49457521\",\"name\":\"E. C\\u00e1ceres\"},{\"authorId\":\"145124058\",\"name\":\"M. Carrasco\"},{\"authorId\":\"144550998\",\"name\":\"S. R\\u00edos\"}],\"doi\":\"10.1016/j.heliyon.2018.e00574\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f1aba0212a27549dce7153c7ede7f4523b32dda1\",\"title\":\"Evaluation of an eye-pointer interaction device for human-computer interaction\",\"url\":\"https://www.semanticscholar.org/paper/f1aba0212a27549dce7153c7ede7f4523b32dda1\",\"venue\":\"Heliyon\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1756108\",\"name\":\"N. Anantrasirichai\"},{\"authorId\":\"2283822\",\"name\":\"I. Gilchrist\"},{\"authorId\":\"1730897\",\"name\":\"D. Bull\"}],\"doi\":\"10.1109/ICIP.2016.7532628\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fa42ef73f715a8bd85499ffeb4d6241e1dfb9b03\",\"title\":\"Visual salience and priority estimation for locomotion using a deep convolutional neural network\",\"url\":\"https://www.semanticscholar.org/paper/fa42ef73f715a8bd85499ffeb4d6241e1dfb9b03\",\"venue\":\"2016 IEEE International Conference on Image Processing (ICIP)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144494743\",\"name\":\"Zhe Wu\"},{\"authorId\":\"145235479\",\"name\":\"L. Su\"},{\"authorId\":\"1689702\",\"name\":\"Q. Huang\"},{\"authorId\":\"143847266\",\"name\":\"Bo Wu\"},{\"authorId\":\"33122401\",\"name\":\"J. Li\"},{\"authorId\":\"46439250\",\"name\":\"Guorong Li\"}],\"doi\":\"10.1109/ICME.2016.7552929\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3252c6c520ae06bfa82084822f857519e262103b\",\"title\":\"Video saliency prediction with optimized optical flow and gravity center bias\",\"url\":\"https://www.semanticscholar.org/paper/3252c6c520ae06bfa82084822f857519e262103b\",\"venue\":\"2016 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"90357138\",\"name\":\"Marta Coll Pol\"}],\"doi\":null,\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"be0947fa430a3bf16436d20239550c39d1425d08\",\"title\":\"The importance of time in visual attention models\",\"url\":\"https://www.semanticscholar.org/paper/be0947fa430a3bf16436d20239550c39d1425d08\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2418491\",\"name\":\"M. Zhang\"},{\"authorId\":\"21007367\",\"name\":\"K. T. Ma\"},{\"authorId\":\"153239355\",\"name\":\"J. H. Lim\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1109/ICIP.2017.8296977\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b47d27d29a178c92a64c204909cec7affbff9f9b\",\"title\":\"Foveated neural network: Gaze prediction on egocentric videos\",\"url\":\"https://www.semanticscholar.org/paper/b47d27d29a178c92a64c204909cec7affbff9f9b\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144774497\",\"name\":\"D. Sen\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":\"10.1007/s11045-016-0456-6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f1ba697bf5cc98687a4f7801d7b66a105f1bc876\",\"title\":\"Early biological vision inspired system for salience computation in images\",\"url\":\"https://www.semanticscholar.org/paper/f1ba697bf5cc98687a4f7801d7b66a105f1bc876\",\"venue\":\"Multidimens. Syst. Signal Process.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2021805\",\"name\":\"V. Buso\"},{\"authorId\":\"1401651727\",\"name\":\"J. Benois-Pineau\"},{\"authorId\":\"1746076\",\"name\":\"Jean-Philippe Domenger\"}],\"doi\":\"10.1145/2662996.2663007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d33c73d344b33ca9ad72eaee26e59ae0a4cd2c9e\",\"title\":\"Geometrical Cues in Visual Saliency Models for Active Object Recognition in Egocentric Videos\",\"url\":\"https://www.semanticscholar.org/paper/d33c73d344b33ca9ad72eaee26e59ae0a4cd2c9e\",\"venue\":\"PIVP@MM\",\"year\":2014},{\"arxivId\":\"2008.13745\",\"authors\":[{\"authorId\":\"46533364\",\"name\":\"Sandeep Mishra\"},{\"authorId\":\"49194775\",\"name\":\"Oindrila Saha\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"13fa6726305b77aa815b148469c495b6ceeed72b\",\"title\":\"RecSal : Deep Recursive Supervision for Visual Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/13fa6726305b77aa815b148469c495b6ceeed72b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2007931\",\"name\":\"Kao Zhang\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"}],\"doi\":\"10.1109/TCSVT.2018.2883305\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6c54dfdace2a84d4b70fc31e87a3053be09cd863\",\"title\":\"Video Saliency Prediction Based on Spatial-Temporal Two-Stream Network\",\"url\":\"https://www.semanticscholar.org/paper/6c54dfdace2a84d4b70fc31e87a3053be09cd863\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":\"2011.04076\",\"authors\":[{\"authorId\":\"48090391\",\"name\":\"Qiang Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"b7b9c782a5a73118fb4e7f07ba5f40d14b66a6b1\",\"title\":\"An HVS-Oriented Saliency Map Prediction Modeling\",\"url\":\"https://www.semanticscholar.org/paper/b7b9c782a5a73118fb4e7f07ba5f40d14b66a6b1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2911844\",\"name\":\"C\\u00e9line Craye\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ade2eced31197aad4a2637ee03a06407ffdeb277\",\"title\":\"Intrinsic motivation mecanisms for incremental learning of visual saliency. (Apprentissage incr\\u00e9mental de la saillance visuelle par des m\\u00e9canismes de motivation intrins\\u00e8que)\",\"url\":\"https://www.semanticscholar.org/paper/ade2eced31197aad4a2637ee03a06407ffdeb277\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1806.10257\",\"authors\":[{\"authorId\":\"2749565\",\"name\":\"Changqun Xia\"},{\"authorId\":\"46275685\",\"name\":\"Jia Li\"},{\"authorId\":\"5349760\",\"name\":\"Jinming Su\"},{\"authorId\":\"3177797\",\"name\":\"Ali Borji\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c5d08cf523115ec8a3c656f1435291d0fb0cfa73\",\"title\":\"Learning a Saliency Evaluation Metric Using Crowdsourced Perceptual Judgments\",\"url\":\"https://www.semanticscholar.org/paper/c5d08cf523115ec8a3c656f1435291d0fb0cfa73\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35997085\",\"name\":\"M. Cheon\"},{\"authorId\":\"33311464\",\"name\":\"J. Lee\"}],\"doi\":\"10.1016/j.image.2015.05.010\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"33eac5e6ecbf110ae5dcfe99be573eb79bc32c01\",\"title\":\"Temporal resolution vs. visual saliency in videos: Analysis of gaze patterns and evaluation of saliency models\",\"url\":\"https://www.semanticscholar.org/paper/33eac5e6ecbf110ae5dcfe99be573eb79bc32c01\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40503509\",\"name\":\"X. Zhao\"},{\"authorId\":\"1745028\",\"name\":\"Hanhe Lin\"},{\"authorId\":\"1742263224\",\"name\":\"Pengfei Guo\"},{\"authorId\":\"1775428\",\"name\":\"D. Saupe\"},{\"authorId\":\"3307573\",\"name\":\"H. Liu\"}],\"doi\":\"10.1109/ICIP40778.2020.9191203\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dadd7c7ceb7493a612cb046af2432a289884e76b\",\"title\":\"Deep Learning VS. Traditional Algorithms for Saliency Prediction of Distorted Images\",\"url\":\"https://www.semanticscholar.org/paper/dadd7c7ceb7493a612cb046af2432a289884e76b\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1771700\",\"name\":\"K. Wang\"},{\"authorId\":\"1883826\",\"name\":\"S. Wang\"},{\"authorId\":\"50426357\",\"name\":\"Q. Ji\"}],\"doi\":\"10.1145/2857491.2857515\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"71faaa29079862320e2417d87f3109ca88916238\",\"title\":\"Deep eye fixation map learning for calibration-free eye gaze tracking\",\"url\":\"https://www.semanticscholar.org/paper/71faaa29079862320e2417d87f3109ca88916238\",\"venue\":\"ETRA\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37425637\",\"name\":\"G. Wen\"},{\"authorId\":\"1414183747\",\"name\":\"Brenda Rodriguez-Ni\\u00f1o\"},{\"authorId\":\"15972695\",\"name\":\"Furkan Y. Pecen\"},{\"authorId\":\"40521265\",\"name\":\"D. Vining\"},{\"authorId\":\"67154482\",\"name\":\"N. Garg\"},{\"authorId\":\"8306347\",\"name\":\"M. Markey\"}],\"doi\":\"10.1117/1.JMI.4.2.025503\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f55de2c4a2af1416041fdde3f830cfd1c49ff09f\",\"title\":\"Comparative study of computational visual attention models on two-dimensional medical images\",\"url\":\"https://www.semanticscholar.org/paper/f55de2c4a2af1416041fdde3f830cfd1c49ff09f\",\"venue\":\"Journal of medical imaging\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145855479\",\"name\":\"C. Fernandez\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6fad552aa486e27fd3efbff95b6e11235ca4d98f\",\"title\":\"Saliency Map Optimization\",\"url\":\"https://www.semanticscholar.org/paper/6fad552aa486e27fd3efbff95b6e11235ca4d98f\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3056962\",\"name\":\"Shujon Naha\"},{\"authorId\":null,\"name\":\"Alimoor Reza\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"80338d1010c36fcbe87c3ce2323b350139521523\",\"title\":\"Localizing Novel Attended Objects in Egocentric Views\",\"url\":\"https://www.semanticscholar.org/paper/80338d1010c36fcbe87c3ce2323b350139521523\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1904.04449\",\"authors\":[{\"authorId\":\"1967201\",\"name\":\"Kui Fu\"},{\"authorId\":null,\"name\":\"Jia Li\"},{\"authorId\":\"2839196\",\"name\":\"Yafei Song\"},{\"authorId\":\"39076047\",\"name\":\"Y. Zhang\"},{\"authorId\":\"39646508\",\"name\":\"Shiming Ge\"},{\"authorId\":\"144051792\",\"name\":\"Yonghong Tian\"}],\"doi\":\"10.1609/AAAI.V34I07.6710\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1b995069e1930fd9a2d87fb35fc4d9b3632cb82d\",\"title\":\"Ultrafast Video Attention Prediction with Coupled Knowledge Distillation\",\"url\":\"https://www.semanticscholar.org/paper/1b995069e1930fd9a2d87fb35fc4d9b3632cb82d\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1702.00714\",\"authors\":[{\"authorId\":\"2624078\",\"name\":\"A. Coutrot\"},{\"authorId\":\"3252109\",\"name\":\"N. Guyader\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c7e7e251a4a69af23cf2de2eea49b4675ba49d2b\",\"title\":\"Learning a time-dependent master saliency map from eye-tracking data in videos\",\"url\":\"https://www.semanticscholar.org/paper/c7e7e251a4a69af23cf2de2eea49b4675ba49d2b\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2624078\",\"name\":\"A. Coutrot\"},{\"authorId\":\"2392506\",\"name\":\"J. Hsiao\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":\"10.3758/s13428-017-0876-8\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"407327ee932afaf9542075a89e0a963090601774\",\"title\":\"Scanpath modeling and classification with hidden Markov models\",\"url\":\"https://www.semanticscholar.org/paper/407327ee932afaf9542075a89e0a963090601774\",\"venue\":\"Behavior research methods\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1756108\",\"name\":\"N. Anantrasirichai\"},{\"authorId\":\"47043085\",\"name\":\"Katherine A J Daniels\"},{\"authorId\":\"3988217\",\"name\":\"J. Burn\"},{\"authorId\":\"2283822\",\"name\":\"I. Gilchrist\"},{\"authorId\":\"1730897\",\"name\":\"D. Bull\"}],\"doi\":\"10.1109/TCYB.2017.2734946\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"35f72d85384f4e5841587b37da2c309d678149f5\",\"title\":\"Fixation Prediction and Visual Priority Maps for Biped Locomotion\",\"url\":\"https://www.semanticscholar.org/paper/35f72d85384f4e5841587b37da2c309d678149f5\",\"venue\":\"IEEE Transactions on Cybernetics\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2033590\",\"name\":\"N. Sidaty\"},{\"authorId\":\"1755023\",\"name\":\"Mohamed-Chaker Larabi\"},{\"authorId\":\"2715507\",\"name\":\"A. Saadane\"}],\"doi\":\"10.1016/j.neucom.2016.08.130\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c3406594d884560833ad65d06aa0a83e0f44eb09\",\"title\":\"Toward an audiovisual attention model for multimodal video content\",\"url\":\"https://www.semanticscholar.org/paper/c3406594d884560833ad65d06aa0a83e0f44eb09\",\"venue\":\"Neurocomputing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1951233\",\"name\":\"Patrik Polatsek\"},{\"authorId\":\"2678977\",\"name\":\"W. Benesova\"}],\"doi\":\"10.1145/2788539.2788557\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b3dddf97a9e7d6d2373d44092d4f414f0d658009\",\"title\":\"Bottom-up saliency model generation using superpixels\",\"url\":\"https://www.semanticscholar.org/paper/b3dddf97a9e7d6d2373d44092d4f414f0d658009\",\"venue\":\"SCCG\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3068843\",\"name\":\"Z. Tang\"},{\"authorId\":\"7988538\",\"name\":\"Yadan Luo\"},{\"authorId\":\"144142354\",\"name\":\"Rui Zhang\"},{\"authorId\":\"145730363\",\"name\":\"H. Jiang\"}],\"doi\":\"10.1117/1.JEI.26.5.053018\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"37dec0d1392b6f629803ed61ce273bfb41e6c308\",\"title\":\"Motion saliency detection for compressed videos\",\"url\":\"https://www.semanticscholar.org/paper/37dec0d1392b6f629803ed61ce273bfb41e6c308\",\"venue\":\"J. Electronic Imaging\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152424508\",\"name\":\"M. Sarret\"},{\"authorId\":\"1737981\",\"name\":\"C. Gurrin\"},{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"}],\"doi\":null,\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"5d42a5e7c97db2c89f9c358c23685fc7375a7045\",\"title\":\"EgoMon Gaze and Video Dataset for Visual Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/5d42a5e7c97db2c89f9c358c23685fc7375a7045\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"2008.13227\",\"authors\":[{\"authorId\":\"1917344125\",\"name\":\"Samad Zabihi\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"51004202\",\"name\":\"A. Borji\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b7dd07f677210aa27defdd0f471771860566f674\",\"title\":\"A Compact Deep Architecture for Real-time Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/b7dd07f677210aa27defdd0f471771860566f674\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50543166\",\"name\":\"Anne-Flore Perrin\"},{\"authorId\":\"3163032\",\"name\":\"Vassilios Krassanakis\"},{\"authorId\":\"1429346658\",\"name\":\"Lu Zhang\"},{\"authorId\":\"1764950\",\"name\":\"V. Ricordel\"},{\"authorId\":\"21340060\",\"name\":\"Matthieu Perreira Da Silva\"},{\"authorId\":\"1789744\",\"name\":\"O. Meur\"}],\"doi\":\"10.3390/drones4010002\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cd04ba0a3e183ee86221ecf98efb73c3495ec929\",\"title\":\"EyeTrackUAV2: a Large-Scale Binocular Eye-Tracking Dataset for UAV Videos\",\"url\":\"https://www.semanticscholar.org/paper/cd04ba0a3e183ee86221ecf98efb73c3495ec929\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34560661\",\"name\":\"M. Haass\"},{\"authorId\":\"145771264\",\"name\":\"A. Wilson\"},{\"authorId\":\"34636768\",\"name\":\"L. Matzen\"},{\"authorId\":\"3424845\",\"name\":\"Kristin M. Divis\"}],\"doi\":\"10.1007/978-3-319-39907-2_12\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fd9e2d0f2a07b07cb6382dcc39e143f4891d6a07\",\"title\":\"Modeling Human Comprehension of Data Visualizations\",\"url\":\"https://www.semanticscholar.org/paper/fd9e2d0f2a07b07cb6382dcc39e143f4891d6a07\",\"venue\":\"HCI\",\"year\":2016},{\"arxivId\":\"1708.00169\",\"authors\":[{\"authorId\":\"2351052\",\"name\":\"Milind S. Gide\"},{\"authorId\":\"47209857\",\"name\":\"Lina Karam\"}],\"doi\":\"10.1109/TIP.2016.2577498\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"db9f1eb50d004f010af8f8981cdda86e8f1b810e\",\"title\":\"A Locally Weighted Fixation Density-Based Metric for Assessing the Quality of Visual Saliency Predictions\",\"url\":\"https://www.semanticscholar.org/paper/db9f1eb50d004f010af8f8981cdda86e8f1b810e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2016},{\"arxivId\":\"2001.11580\",\"authors\":[{\"authorId\":\"24057502\",\"name\":\"Sathyanarayanan N. Aakur\"},{\"authorId\":\"144227173\",\"name\":\"A. Bagavathi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"af5c027f9435bb4c26cbf48bb28a1d8456e164e0\",\"title\":\"Unsupervised Gaze Prediction in Egocentric Videos by Energy-based Surprise Modeling\",\"url\":\"https://www.semanticscholar.org/paper/af5c027f9435bb4c26cbf48bb28a1d8456e164e0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1809939\",\"name\":\"P. Kasprowski\"},{\"authorId\":\"1765949\",\"name\":\"K. Harezlak\"}],\"doi\":\"10.1145/3204493.3204529\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cc046d1a7520c0eb95008cac1491e0902c65c1db\",\"title\":\"Comparison of mapping algorithms for implicit calibration using probable fixation targets\",\"url\":\"https://www.semanticscholar.org/paper/cc046d1a7520c0eb95008cac1491e0902c65c1db\",\"venue\":\"ETRA\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"46887280\",\"name\":\"Giuseppe Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"49859d84cd3884d7bc61b5049222e454c46ff8ac\",\"title\":\"Attentive ConvLSTM Learned Priors ( x 2 ) \\u03bc , \\u03c3\\u03bc , \\u03c3\\u03bc , \\u03c3 Dilated Convolutional Network Input Image Saliency\",\"url\":\"https://www.semanticscholar.org/paper/49859d84cd3884d7bc61b5049222e454c46ff8ac\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"73196969\",\"name\":\"Bharathi Murugaraj\"},{\"authorId\":\"47497899\",\"name\":\"J. Amudha\"}],\"doi\":\"10.1007/978-3-319-68385-0_29\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1991e03877be1524d11d07ffe8313bc012962eb6\",\"title\":\"Performance Assessment Framework for Computational Models of Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/1991e03877be1524d11d07ffe8313bc012962eb6\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40063957\",\"name\":\"Eric Arazo Sanchez\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"55761bdf5cbbff5fbede8ee9d0573d1561a9254b\",\"title\":\"The impact of visual saliency prediction in image classification\",\"url\":\"https://www.semanticscholar.org/paper/55761bdf5cbbff5fbede8ee9d0573d1561a9254b\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1401448518\",\"name\":\"Miguel Angel Fernandez-Torres\"},{\"authorId\":\"1398693138\",\"name\":\"I. Gonz\\u00e1lez-D\\u00edaz\"},{\"authorId\":\"1397907559\",\"name\":\"F. D\\u00edaz-de-Mar\\u00eda\"}],\"doi\":\"10.1109/CBMI.2016.7500272\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d9acd775d0338cb9f7659e25fde76afbb2747421\",\"title\":\"A probabilistic topic approach for context-aware visual attention modeling\",\"url\":\"https://www.semanticscholar.org/paper/d9acd775d0338cb9f7659e25fde76afbb2747421\",\"venue\":\"2016 14th International Workshop on Content-Based Multimedia Indexing (CBMI)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1947664\",\"name\":\"S. Egner\"},{\"authorId\":\"3187578\",\"name\":\"R. H\\u00f6ger\"},{\"authorId\":\"152835399\",\"name\":\"S. Reimann\"},{\"authorId\":\"2728222\",\"name\":\"W. Zangemeister\"}],\"doi\":\"10.16910/JEMR.11.6.4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a321c3305be9e1d991013e8d330bdfe88dd4a5c1\",\"title\":\"Attention and Information Acquisition: Comparison of Mouse-Click with Eye-Movement Attention Tracking\",\"url\":\"https://www.semanticscholar.org/paper/a321c3305be9e1d991013e8d330bdfe88dd4a5c1\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36465167\",\"name\":\"F. Leit\\u00e3o\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d4eae81c7b7f1d5e9f9d85e3340ed10b9c355cec\",\"title\":\"Predicting Eye Fixations with a Deep Reconstruction-Based Approach\",\"url\":\"https://www.semanticscholar.org/paper/d4eae81c7b7f1d5e9f9d85e3340ed10b9c355cec\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2624078\",\"name\":\"A. Coutrot\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fd5034b37c7a1ab690765bba6f753bef3b3dc19f\",\"title\":\"Influence du son lors de l\\u2019exploration de sce\\u0300nes naturelles dynamiques\",\"url\":\"https://www.semanticscholar.org/paper/fd5034b37c7a1ab690765bba6f753bef3b3dc19f\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152548815\",\"name\":\"Harshit Chauhan\"},{\"authorId\":\"2041987349\",\"name\":\"Anmol Prasad\"},{\"authorId\":\"39554170\",\"name\":\"Jainendra Shukla\"}],\"doi\":\"10.1145/3395035.3425256\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b4937246f70da0dea6267bb7f63ec17c0d0f6584\",\"title\":\"Engagement Analysis of ADHD Students using Visual Cues from Eye Tracker\",\"url\":\"https://www.semanticscholar.org/paper/b4937246f70da0dea6267bb7f63ec17c0d0f6584\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1904.04992\",\"authors\":[{\"authorId\":null,\"name\":\"Jia Li\"},{\"authorId\":\"1967201\",\"name\":\"Kui Fu\"},{\"authorId\":\"152836873\",\"name\":\"Shengwei Zhao\"},{\"authorId\":\"39646508\",\"name\":\"Shiming Ge\"}],\"doi\":\"10.1109/TIP.2019.2946102\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3f76324a4a26ff3d9097642676878aa7b1122581\",\"title\":\"Spatiotemporal Knowledge Distillation for Efficient Estimation of Aerial Video Saliency\",\"url\":\"https://www.semanticscholar.org/paper/3f76324a4a26ff3d9097642676878aa7b1122581\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1601.02852\",\"authors\":[{\"authorId\":\"49331178\",\"name\":\"Jinsoo Choi\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"2398271\",\"name\":\"In-So Kweon\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"225058b5b34c8ac42b07edaaf59186d440961f90\",\"title\":\"Human Attention Estimation for Natural Images: An Automatic Gaze Refinement Approach\",\"url\":\"https://www.semanticscholar.org/paper/225058b5b34c8ac42b07edaaf59186d440961f90\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48984885\",\"name\":\"Felipe Vera\"},{\"authorId\":\"32124610\",\"name\":\"V. Cort\\u00e9s\"},{\"authorId\":\"32830698\",\"name\":\"Gabriel Iturrra\"},{\"authorId\":\"145323794\",\"name\":\"J. Vel\\u00e1squez\"},{\"authorId\":\"145132845\",\"name\":\"P. Maldonado\"},{\"authorId\":\"5842513\",\"name\":\"A. Couve\"}],\"doi\":\"10.1109/ICDMW.2017.90\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"82256e82e9ae58538f8b68f2f6cd1e667818cb18\",\"title\":\"Akori: A Tool Based in Eye-Tracking Techniques for Analyzing Web User Behaviour on a Web Site\",\"url\":\"https://www.semanticscholar.org/paper/82256e82e9ae58538f8b68f2f6cd1e667818cb18\",\"venue\":\"2017 IEEE International Conference on Data Mining Workshops (ICDMW)\",\"year\":2017},{\"arxivId\":\"1604.03882\",\"authors\":[{\"authorId\":\"2351052\",\"name\":\"Milind S. Gide\"},{\"authorId\":\"143635238\",\"name\":\"Samuel F. Dodge\"},{\"authorId\":\"47209857\",\"name\":\"Lina Karam\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"06d365adbe388ccb85942383bb3b47a5184dcfce\",\"title\":\"The Effect of Distortions on the Prediction of Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/06d365adbe388ccb85942383bb3b47a5184dcfce\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1909.04610\",\"authors\":[{\"authorId\":\"1964372\",\"name\":\"Suren Deepak Rajasekaran\"},{\"authorId\":\"48654391\",\"name\":\"Hao Kang\"},{\"authorId\":\"1788393\",\"name\":\"Bedrich Benes\"},{\"authorId\":\"2120977\",\"name\":\"Martin Cad\\u00edk\"},{\"authorId\":\"2427513\",\"name\":\"Eric Galin\"},{\"authorId\":\"49217796\",\"name\":\"E. Gu\\u00e9rin\"},{\"authorId\":\"2056039\",\"name\":\"A. Peytavie\"},{\"authorId\":\"2307764\",\"name\":\"P. Slav\\u00edk\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0dc0c2b65e74bb92bfb0cc1994f28eae2e2c0e23\",\"title\":\"PTRM: Perceived Terrain Realism Metrics\",\"url\":\"https://www.semanticscholar.org/paper/0dc0c2b65e74bb92bfb0cc1994f28eae2e2c0e23\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144418348\",\"name\":\"R. Xu\"},{\"authorId\":\"2631458\",\"name\":\"Stephen Wittkopf\"},{\"authorId\":\"34959202\",\"name\":\"Christian R Roeske\"}],\"doi\":\"10.3390/EN10050668\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6295fc8526c8c1c3fe639ea3946d056e8d8cde8d\",\"title\":\"Quantitative Evaluation of BIPV Visual Impact in Building Retrofits Using Saliency Models\",\"url\":\"https://www.semanticscholar.org/paper/6295fc8526c8c1c3fe639ea3946d056e8d8cde8d\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1720841\",\"name\":\"X. Wang\"},{\"authorId\":\"3419220\",\"name\":\"Jialun Dai\"},{\"authorId\":\"48269582\",\"name\":\"Yafei Zhu\"},{\"authorId\":\"2336297\",\"name\":\"Haiyong Zheng\"},{\"authorId\":\"2926414\",\"name\":\"Xiaoyan Qiao\"}],\"doi\":\"10.1117/1.JEI.25.2.023020\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bbbde179d91caa07b7fc9a01ba5c09930e796220\",\"title\":\"Spectral saliency via automatic adaptive amplitude spectrum analysis\",\"url\":\"https://www.semanticscholar.org/paper/bbbde179d91caa07b7fc9a01ba5c09930e796220\",\"venue\":\"J. Electronic Imaging\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"146007280\",\"name\":\"Andrew A. Anderson\"},{\"authorId\":\"1519478862\",\"name\":\"Jonathan Dodge\"},{\"authorId\":\"88727643\",\"name\":\"Amrita Sadarangani\"},{\"authorId\":\"88728623\",\"name\":\"Zoe Juozapaitis\"},{\"authorId\":\"145364055\",\"name\":\"Evan Newman\"},{\"authorId\":\"1519978688\",\"name\":\"Jed Irvine\"},{\"authorId\":\"1680063325\",\"name\":\"Souti Chattopadhyay\"},{\"authorId\":\"113923179\",\"name\":\"Matthew H. Olson\"},{\"authorId\":\"145841336\",\"name\":\"A. Fern\"},{\"authorId\":\"69854669\",\"name\":\"M. Burnett\"}],\"doi\":\"10.1145/3366485\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e654e71b65de3c8b549a553c526f3779042f1e2e\",\"title\":\"Mental Models of Mere Mortals with Explanations of Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/e654e71b65de3c8b549a553c526f3779042f1e2e\",\"venue\":\"ACM Trans. Interact. Intell. Syst.\",\"year\":2020},{\"arxivId\":\"1903.09708\",\"authors\":[{\"authorId\":\"144390852\",\"name\":\"A. Anderson\"},{\"authorId\":\"48983294\",\"name\":\"J. Dodge\"},{\"authorId\":\"88727643\",\"name\":\"Amrita Sadarangani\"},{\"authorId\":\"88728623\",\"name\":\"Zoe Juozapaitis\"},{\"authorId\":\"145364055\",\"name\":\"Evan Newman\"},{\"authorId\":\"49920503\",\"name\":\"J. Irvine\"},{\"authorId\":\"40093488\",\"name\":\"S. Chattopadhyay\"},{\"authorId\":\"145841336\",\"name\":\"A. Fern\"},{\"authorId\":\"145830592\",\"name\":\"M. Burnett\"}],\"doi\":\"10.24963/ijcai.2019/184\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"54669fdad30a3d98d71e091c3c184cd43dd9c85f\",\"title\":\"Explaining Reinforcement Learning to Mere Mortals: An Empirical Study\",\"url\":\"https://www.semanticscholar.org/paper/54669fdad30a3d98d71e091c3c184cd43dd9c85f\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144774497\",\"name\":\"D. Sen\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":\"10.1016/j.jvcir.2015.04.010\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6f0f14bf64657aca5961a9736660478ee00d69ab\",\"title\":\"A bio-inspired center-surround model for salience computation in images\",\"url\":\"https://www.semanticscholar.org/paper/6f0f14bf64657aca5961a9736660478ee00d69ab\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39759946\",\"name\":\"K. Madani\"},{\"authorId\":\"2468613\",\"name\":\"V. Kachurka\"},{\"authorId\":\"46355228\",\"name\":\"C. Sabourin\"},{\"authorId\":\"1785410\",\"name\":\"V. Amarger\"},{\"authorId\":\"7687283\",\"name\":\"V. Golovko\"},{\"authorId\":\"47509592\",\"name\":\"Lucile Rossi\"}],\"doi\":\"10.1007/s10489-017-1053-6\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"fec2c01deeff6aeae67977598d5a2d0e31024310\",\"title\":\"A human-like visual-attention-based artificial vision system for wildland firefighting assistance\",\"url\":\"https://www.semanticscholar.org/paper/fec2c01deeff6aeae67977598d5a2d0e31024310\",\"venue\":\"Applied Intelligence\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2459642\",\"name\":\"P. Vaidyanathan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6769c46715b7d79b4d02374f4e3d4c3e36398ae7\",\"title\":\"Visual-Linguistic Semantic Alignment: Fusing Human Gaze and Spoken Narratives for Image Region Annotation\",\"url\":\"https://www.semanticscholar.org/paper/6769c46715b7d79b4d02374f4e3d4c3e36398ae7\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39759946\",\"name\":\"K. Madani\"},{\"authorId\":\"2978154\",\"name\":\"Hossam Fraihat\"},{\"authorId\":\"46355228\",\"name\":\"C. Sabourin\"}],\"doi\":\"10.1109/IDAACS.2017.8095116\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1ac82cff3d8f1919621095c9c5f09571e9d00b89\",\"title\":\"Machine-awareness in indoor environment: A pseudo-3D vision-based approach combining multi-resolution visual information\",\"url\":\"https://www.semanticscholar.org/paper/1ac82cff3d8f1919621095c9c5f09571e9d00b89\",\"venue\":\"2017 9th IEEE International Conference on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications (IDAACS)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67074535\",\"name\":\"W. Zhang\"},{\"authorId\":\"145144074\",\"name\":\"Wenjie Zou\"},{\"authorId\":\"1805476\",\"name\":\"Fuzheng Yang\"}],\"doi\":\"10.1016/J.IMAGE.2019.04.007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b99cff38236b1b2c00ae8f20068c7aba8ca195e0\",\"title\":\"Linking visual saliency deviation to image quality degradation: A saliency deviation-based image quality index\",\"url\":\"https://www.semanticscholar.org/paper/b99cff38236b1b2c00ae8f20068c7aba8ca195e0\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1740586345\",\"name\":\"Naoyuki Awano\"},{\"authorId\":\"1740584291\",\"name\":\"Y. Hayashi\"}],\"doi\":\"10.1007/s41095-020-0169-5\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"431dddd3de684ac0d208f46dceef3fe206444e1d\",\"title\":\"Psychological potential field and human eye fixation on binary line-drawing images: A comparative experimental study\",\"url\":\"https://www.semanticscholar.org/paper/431dddd3de684ac0d208f46dceef3fe206444e1d\",\"venue\":\"Computational Visual Media\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2021805\",\"name\":\"V. Buso\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8add9c8bad1f479f81f9cfaaf7b0e210fc3d929c\",\"title\":\"Perceptual object of interest recognition : application to the interpretation of instrumental activities of daily living for dementia studies. (Reconnaissance perceptuelle des objets d'Int\\u00e9r\\u00eat : application \\u00e0 l'interpre'tation des activite's instrumentales de la vie quotidienne pour les \\u00e9tudes de de\",\"url\":\"https://www.semanticscholar.org/paper/8add9c8bad1f479f81f9cfaaf7b0e210fc3d929c\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2351052\",\"name\":\"Milind S. Gide\"},{\"authorId\":\"47209857\",\"name\":\"Lina Karam\"}],\"doi\":\"10.1561/2000000055\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"783296b4846ca4dbc2ee5aa11319bfc86e1acbcd\",\"title\":\"Computational Visual Attention Models\",\"url\":\"https://www.semanticscholar.org/paper/783296b4846ca4dbc2ee5aa11319bfc86e1acbcd\",\"venue\":\"Found. Trends Signal Process.\",\"year\":2017},{\"arxivId\":\"1901.01874\",\"authors\":[{\"authorId\":\"48355461\",\"name\":\"Yifei Huang\"},{\"authorId\":\"46947776\",\"name\":\"Zhenqiang Li\"},{\"authorId\":\"3172280\",\"name\":\"Minjie Cai\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1109/TIP.2020.3007841\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"78d95b989b807f28ef624318e3cb583ca1d73a3e\",\"title\":\"Mutual Context Network for Jointly Estimating Egocentric Gaze and Action\",\"url\":\"https://www.semanticscholar.org/paper/78d95b989b807f28ef624318e3cb583ca1d73a3e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1806.03960\",\"authors\":[{\"authorId\":\"2657185\",\"name\":\"Ruohan Zhang\"},{\"authorId\":\"2619658\",\"name\":\"Zhuode Liu\"},{\"authorId\":\"13800723\",\"name\":\"L. Zhang\"},{\"authorId\":\"51002225\",\"name\":\"Jake A. Whritner\"},{\"authorId\":\"47136793\",\"name\":\"K. Muller\"},{\"authorId\":\"2848854\",\"name\":\"M. Hayhoe\"},{\"authorId\":\"1691804\",\"name\":\"D. Ballard\"}],\"doi\":\"10.1007/978-3-030-01252-6_41\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"170643ea1794c4285a491bcea7dede2d35806726\",\"title\":\"AGIL: Learning Attention from Human for Visuomotor Tasks\",\"url\":\"https://www.semanticscholar.org/paper/170643ea1794c4285a491bcea7dede2d35806726\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48569496\",\"name\":\"X. Li\"},{\"authorId\":\"2211151\",\"name\":\"C. Camerer\"}],\"doi\":\"10.2139/ssrn.3308886\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"9f669fd7b06bd251c4f2a10a4b943ccfed311036\",\"title\":\"Using Visual Salience in Empirical Game Theory\",\"url\":\"https://www.semanticscholar.org/paper/9f669fd7b06bd251c4f2a10a4b943ccfed311036\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2009.08373\",\"authors\":[{\"authorId\":\"1947172233\",\"name\":\"M. Sclar\"},{\"authorId\":\"1946864700\",\"name\":\"G. Bujia\"},{\"authorId\":\"145184799\",\"name\":\"S. Vita\"},{\"authorId\":\"3985471\",\"name\":\"G. Solovey\"},{\"authorId\":\"2941980\",\"name\":\"J. E. Kamienkowski\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5d4dbd9b7c504d33403027e721468847d8d91fdb\",\"title\":\"Modeling human visual search: A combined Bayesian searcher and saliency map approach for eye movement guidance in natural scenes\",\"url\":\"https://www.semanticscholar.org/paper/5d4dbd9b7c504d33403027e721468847d8d91fdb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.10540\",\"authors\":[{\"authorId\":null,\"name\":\"Sen Jia\"},{\"authorId\":\"2866780\",\"name\":\"Neil D. B. Bruce\"}],\"doi\":\"10.1109/cvpr42600.2020.00274\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"68d3ff5267302cd396b831cd3a67fb0b2002d711\",\"title\":\"Revisiting Saliency Metrics: Farthest-Neighbor Area Under Curve\",\"url\":\"https://www.semanticscholar.org/paper/68d3ff5267302cd396b831cd3a67fb0b2002d711\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1805367\",\"name\":\"Sen Jia\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7d329bb72b3497ddeaa804d389d5d5f27bdca911\",\"title\":\"Revisiting Saliency Metrics: Farthest-Neighbor Area Under Curve\",\"url\":\"https://www.semanticscholar.org/paper/7d329bb72b3497ddeaa804d389d5d5f27bdca911\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Wei Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"979aab3eb970ecf66718b5478dfacb845ecd2f93\",\"title\":\"Visual saliency in image quality assessment\",\"url\":\"https://www.semanticscholar.org/paper/979aab3eb970ecf66718b5478dfacb845ecd2f93\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33385883\",\"name\":\"F. Schenk\"},{\"authorId\":\"3265438\",\"name\":\"Philipp Aichinger\"},{\"authorId\":\"2145989\",\"name\":\"I. Roesner\"},{\"authorId\":\"1765657\",\"name\":\"M. Urschler\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"136dd72b91aff2bfab5ac1adc817deb34530895b\",\"title\":\"Automatic high-speed video glottis segmentation using salient regions and 3D geodesic active contours\",\"url\":\"https://www.semanticscholar.org/paper/136dd72b91aff2bfab5ac1adc817deb34530895b\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1907.02336\",\"authors\":[{\"authorId\":\"150007878\",\"name\":\"Alexandre Bruckert\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"143962642\",\"name\":\"Zhi Liu\"},{\"authorId\":\"1701717\",\"name\":\"M. Christie\"},{\"authorId\":\"1789744\",\"name\":\"O. Meur\"}],\"doi\":\"10.1016/j.neucom.2020.06.131\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"79c5b0d6dc39e7b0f59690520c17e33007a6b985\",\"title\":\"Deep Saliency Models : The Quest For The Loss Function\",\"url\":\"https://www.semanticscholar.org/paper/79c5b0d6dc39e7b0f59690520c17e33007a6b985\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1716038\",\"name\":\"D. Erro\"},{\"authorId\":\"144004474\",\"name\":\"I. Hern\\u00e1ez\"},{\"authorId\":null,\"name\":\"Albert Ali Salah\"},{\"authorId\":\"3141704\",\"name\":\"A. Camurri\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"bbdbddb8a46155622d34fd5c0bf289956bdf0747\",\"title\":\"eNTERFACE Steering Committee\",\"url\":\"https://www.semanticscholar.org/paper/bbdbddb8a46155622d34fd5c0bf289956bdf0747\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1904.08377\",\"authors\":[{\"authorId\":\"50580946\",\"name\":\"Y. Chen\"},{\"authorId\":\"49047213\",\"name\":\"Congcong Liu\"},{\"authorId\":\"70308463\",\"name\":\"L. Tai\"},{\"authorId\":\"145111960\",\"name\":\"Ming Liu\"},{\"authorId\":\"2131088\",\"name\":\"B. Shi\"}],\"doi\":\"10.1109/IROS40897.2019.8967843\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ce72866daa2582988f71b106e547507a78c91514\",\"title\":\"Gaze Training by Modulated Dropout Improves Imitation Learning\",\"url\":\"https://www.semanticscholar.org/paper/ce72866daa2582988f71b106e547507a78c91514\",\"venue\":\"2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2378312\",\"name\":\"Iana Iatsun\"},{\"authorId\":\"1755023\",\"name\":\"Mohamed-Chaker Larabi\"},{\"authorId\":\"1397922695\",\"name\":\"C. Fernandez-Maloigne\"}],\"doi\":\"10.1016/j.image.2015.05.009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ddc3839e4973dcb3291f770bde0d4156c0d06a69\",\"title\":\"A visual attention model for stereoscopic 3D images using monocular cues\",\"url\":\"https://www.semanticscholar.org/paper/ddc3839e4973dcb3291f770bde0d4156c0d06a69\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2977601\",\"name\":\"H. Nemoto\"},{\"authorId\":\"3311105\",\"name\":\"Philippe Hanhart\"},{\"authorId\":\"2831839\",\"name\":\"P. Korshunov\"},{\"authorId\":\"1681498\",\"name\":\"T. Ebrahimi\"}],\"doi\":\"10.1145/2647868.2654917\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c1a93fa7697197486dc64b68c3357bec0bafb551\",\"title\":\"Impact of Ultra High Definition on Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/c1a93fa7697197486dc64b68c3357bec0bafb551\",\"venue\":\"ACM Multimedia\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2351052\",\"name\":\"Milind S. Gide\"},{\"authorId\":\"143635238\",\"name\":\"Samuel F. Dodge\"},{\"authorId\":\"47209857\",\"name\":\"Lina Karam\"}],\"doi\":\"10.1109/ICIP.2016.7532868\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"735c39f002ef311804acbd1efaa72074191031b6\",\"title\":\"Visual attention quality database for benchmarking performance evaluation metrics\",\"url\":\"https://www.semanticscholar.org/paper/735c39f002ef311804acbd1efaa72074191031b6\",\"venue\":\"2016 IEEE International Conference on Image Processing (ICIP)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49890030\",\"name\":\"Youqiang Zhang\"},{\"authorId\":\"143743503\",\"name\":\"Feng Dai\"},{\"authorId\":\"3193532\",\"name\":\"Yike Ma\"},{\"authorId\":\"49404814\",\"name\":\"Hongliang Li\"},{\"authorId\":\"49033408\",\"name\":\"Q. Zhao\"},{\"authorId\":\"121310224\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.1109/JSTSP.2019.2955824\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"059dcad31aca80e2393fb2ccdea0dffc4499e1be\",\"title\":\"Saliency Prediction Network for $360^\\\\circ$ Videos\",\"url\":\"https://www.semanticscholar.org/paper/059dcad31aca80e2393fb2ccdea0dffc4499e1be\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020},{\"arxivId\":\"1811.10004\",\"authors\":[{\"authorId\":\"21319564\",\"name\":\"J. Li\"},{\"authorId\":\"2966504\",\"name\":\"Daowei Li\"},{\"authorId\":\"1967201\",\"name\":\"Kui Fu\"},{\"authorId\":\"1690940\",\"name\":\"L. Xu\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6d17074e5b6a6b2e92141560479ad4ab5eb66af5\",\"title\":\"Visual Attention on the Sun: What Do Existing Models Actually Predict?\",\"url\":\"https://www.semanticscholar.org/paper/6d17074e5b6a6b2e92141560479ad4ab5eb66af5\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1398288379\",\"name\":\"A. Banitalebi-Dehkordi\"},{\"authorId\":\"2976069\",\"name\":\"Eleni Nasiopoulos\"},{\"authorId\":\"1396793869\",\"name\":\"Mahsa T. Pourazad\"},{\"authorId\":\"1687935\",\"name\":\"P. Nasiopoulos\"}],\"doi\":\"10.1117/1.JEI.25.1.013008\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4806b41de126842c2bb5c382827cfe990f4d5a31\",\"title\":\"Benchmark three-dimensional eye-tracking dataset for visual saliency prediction on stereoscopic three-dimensional video\",\"url\":\"https://www.semanticscholar.org/paper/4806b41de126842c2bb5c382827cfe990f4d5a31\",\"venue\":\"J. Electronic Imaging\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4218304\",\"name\":\"C. Wloka\"},{\"authorId\":\"7382216\",\"name\":\"John Tstotsos\"}],\"doi\":\"10.1109/CVPR.2016.63\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"2774dfff4416ffc51679aadd83905147e7dcb95e\",\"title\":\"Spatially Binned ROC: A Comprehensive Saliency Metric\",\"url\":\"https://www.semanticscholar.org/paper/2774dfff4416ffc51679aadd83905147e7dcb95e\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1612.04335\",\"authors\":[{\"authorId\":\"5021307\",\"name\":\"Vincent Sitzmann\"},{\"authorId\":\"145192940\",\"name\":\"Ana Serrano\"},{\"authorId\":\"48453720\",\"name\":\"A. Pavel\"},{\"authorId\":\"1820412\",\"name\":\"M. Agrawala\"},{\"authorId\":\"143876232\",\"name\":\"D. Gutierrez\"},{\"authorId\":\"1775667\",\"name\":\"B. Masi\\u00e1\"},{\"authorId\":\"1731170\",\"name\":\"G. Wetzstein\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c6b4459c4f27b9c4107ae7f708059e987e7f3f08\",\"title\":\"How do people explore virtual environments\",\"url\":\"https://www.semanticscholar.org/paper/c6b4459c4f27b9c4107ae7f708059e987e7f3f08\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51995491\",\"name\":\"Colm O. Fearghail\"},{\"authorId\":\"3034941\",\"name\":\"S. Knorr\"},{\"authorId\":\"52610836\",\"name\":\"A. Smoli\\u0107\"}],\"doi\":\"10.1109/IC3D48390.2019.8975990\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2085c9f13e2d1934df077d57200d6a3be06c368f\",\"title\":\"Analysis of Intended Viewing Area vs Estimated Saliency on Narrative Plot Structures in VR Film\",\"url\":\"https://www.semanticscholar.org/paper/2085c9f13e2d1934df077d57200d6a3be06c368f\",\"venue\":\"2019 International Conference on 3D Immersion (IC3D)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2860038\",\"name\":\"Pierre Marighetto\"},{\"authorId\":\"30170254\",\"name\":\"I. Abdelkader\"},{\"authorId\":\"49031335\",\"name\":\"S. Duzelier\"},{\"authorId\":\"3265104\",\"name\":\"M. Decombas\"},{\"authorId\":\"2989773\",\"name\":\"Nicolas Riche\"},{\"authorId\":\"34913672\",\"name\":\"J\\u00e9r\\u00e9mie Jakubowicz\"},{\"authorId\":\"1681157\",\"name\":\"M. Mancas\"},{\"authorId\":\"50276543\",\"name\":\"B. Gosselin\"},{\"authorId\":\"2035718\",\"name\":\"R. Lagani\\u00e8re\"}],\"doi\":\"10.1109/ICIP.2016.7532866\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a93534f8bd1304cc3311b54321cdd3f60a609a41\",\"title\":\"FUNNRAR: Hybrid rarity/learning visual saliency\",\"url\":\"https://www.semanticscholar.org/paper/a93534f8bd1304cc3311b54321cdd3f60a609a41\",\"venue\":\"2016 IEEE International Conference on Image Processing (ICIP)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1789744\",\"name\":\"O. Meur\"},{\"authorId\":\"1712219465\",\"name\":\"PIERRE-ADRIEN Fons\"}],\"doi\":\"10.1145/3379156.3391362\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c72ba40459e6ca39e30af999db2bb2668372b6e2\",\"title\":\"Predicting image influence on visual saliency distribution: the focal and ambient dichotomy\",\"url\":\"https://www.semanticscholar.org/paper/c72ba40459e6ca39e30af999db2bb2668372b6e2\",\"venue\":\"ETRA Short Papers\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Wei Zhang\"},{\"authorId\":\"3307573\",\"name\":\"H. Liu\"}],\"doi\":\"10.1109/MMSP.2016.7813334\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0f8d0a027360e88fdae46bc0e0a7a0cc8f2b4941\",\"title\":\"SIQ288: A saliency dataset for image quality research\",\"url\":\"https://www.semanticscholar.org/paper/0f8d0a027360e88fdae46bc0e0a7a0cc8f2b4941\",\"venue\":\"2016 IEEE 18th International Workshop on Multimedia Signal Processing (MMSP)\",\"year\":2016},{\"arxivId\":\"1811.06458\",\"authors\":[{\"authorId\":\"51925488\",\"name\":\"David Berga\"},{\"authorId\":\"1390040513\",\"name\":\"X. R. Fdez-Vidal\"},{\"authorId\":\"2556319\",\"name\":\"X. Otazu\"},{\"authorId\":\"1760977\",\"name\":\"V. Lebor\\u00e1n\"},{\"authorId\":\"1768258\",\"name\":\"X. Pardo\"}],\"doi\":\"10.1016/j.visres.2018.10.006\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e499f7ffe8bc904aedbb072b427fbab6c6206ee6\",\"title\":\"Psychophysical evaluation of individual low-level feature influences on visual attention\",\"url\":\"https://www.semanticscholar.org/paper/e499f7ffe8bc904aedbb072b427fbab6c6206ee6\",\"venue\":\"Vision Research\",\"year\":2019},{\"arxivId\":\"2002.04407\",\"authors\":[{\"authorId\":\"9952297\",\"name\":\"Dario Zanca\"},{\"authorId\":\"1760309\",\"name\":\"S. Melacci\"},{\"authorId\":\"1491505431\",\"name\":\"M. Gori\"}],\"doi\":\"10.1109/IJCNN48605.2020.9207438\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"a375165db82be679bc457ea8c305870640ecf47f\",\"title\":\"Toward Improving the Evaluation of Visual Attention Models: a Crowdsourcing Approach\",\"url\":\"https://www.semanticscholar.org/paper/a375165db82be679bc457ea8c305870640ecf47f\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2468613\",\"name\":\"V. Kachurka\"},{\"authorId\":\"39759946\",\"name\":\"K. Madani\"},{\"authorId\":\"46355228\",\"name\":\"C. Sabourin\"},{\"authorId\":\"7687283\",\"name\":\"V. Golovko\"}],\"doi\":\"10.1007/978-3-319-19258-1_15\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"51c3e8c5618846e88cd2edb59cc93ca3c00a8c4b\",\"title\":\"From Human Eye Fixation to Human-like Autonomous Artificial Vision\",\"url\":\"https://www.semanticscholar.org/paper/51c3e8c5618846e88cd2edb59cc93ca3c00a8c4b\",\"venue\":\"IWANN\",\"year\":2015},{\"arxivId\":\"1902.06634\",\"authors\":[{\"authorId\":\"144373348\",\"name\":\"A. Kroner\"},{\"authorId\":\"2581474\",\"name\":\"Mario Senden\"},{\"authorId\":\"1695114\",\"name\":\"K. Driessens\"},{\"authorId\":\"145960031\",\"name\":\"R. Goebel\"}],\"doi\":\"10.1016/j.neunet.2020.05.004\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4fa6aac2143c713561603083a5f953c395ba2131\",\"title\":\"Contextual Encoder-Decoder Network for Visual Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/4fa6aac2143c713561603083a5f953c395ba2131\",\"venue\":\"Neural Networks\",\"year\":2020},{\"arxivId\":\"2007.13839\",\"authors\":[{\"authorId\":\"48380246\",\"name\":\"Yifeng Zhang\"},{\"authorId\":\"1405907659\",\"name\":\"Ming Jiang\"},{\"authorId\":\"153386875\",\"name\":\"Q. Zhao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4ba67b0734477ff392367f52542ad2dab179da83\",\"title\":\"Saliency Prediction with External Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/4ba67b0734477ff392367f52542ad2dab179da83\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145733564\",\"name\":\"A. F. Silva\"},{\"authorId\":\"1804534\",\"name\":\"Myl\\u00e8ne C. Q. Farias\"},{\"authorId\":\"1708715\",\"name\":\"J. Redi\"}],\"doi\":\"10.1117/12.2083487\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e40308a01bfbcc406ad2c47a085fb8d28df4edeb\",\"title\":\"Assessing the influence of combinations of blockiness, blurriness, and packet loss impairments on visual attention deployment\",\"url\":\"https://www.semanticscholar.org/paper/e40308a01bfbcc406ad2c47a085fb8d28df4edeb\",\"venue\":\"Electronic Imaging\",\"year\":2015},{\"arxivId\":\"1908.02511\",\"authors\":[{\"authorId\":\"40104742\",\"name\":\"Dmitry Nikulin\"},{\"authorId\":\"13241013\",\"name\":\"A. Ianina\"},{\"authorId\":\"144961117\",\"name\":\"V. Aliev\"},{\"authorId\":\"1742235\",\"name\":\"S. Nikolenko\"}],\"doi\":\"10.1109/ICCVW.2019.00522\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fde7739ae64675bdeeaf9ca629c7abaa4e7dfe52\",\"title\":\"Free-Lunch Saliency via Attention in Atari Agents\",\"url\":\"https://www.semanticscholar.org/paper/fde7739ae64675bdeeaf9ca629c7abaa4e7dfe52\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29366618\",\"name\":\"L. M. Cano\"},{\"authorId\":\"1400685790\",\"name\":\"Jessica Beltr\\u00e1n-M\\u00e1rquez\"},{\"authorId\":\"33008495\",\"name\":\"Ren\\u00e9 F. Navarro\"},{\"authorId\":\"1399106107\",\"name\":\"M. Garc\\u00eda-V\\u00e1zquez\"},{\"authorId\":\"145529530\",\"name\":\"L. A. Castro\"}],\"doi\":\"10.1145/3123024.3125613\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"30676e235a980017cf17fed1783961acae03bdf9\",\"title\":\"Towards early dementia detection by oculomotor performance analysis on leisure web content\",\"url\":\"https://www.semanticscholar.org/paper/30676e235a980017cf17fed1783961acae03bdf9\",\"venue\":\"UbiComp/ISWC Adjunct\",\"year\":2017},{\"arxivId\":\"1611.09571\",\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/TIP.2018.2851672\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b7e336a7d3cd82ae8cd5e85d3cb62f0b6091a0e5\",\"title\":\"Predicting Human Eye Fixations via an LSTM-Based Saliency Attentive Model\",\"url\":\"https://www.semanticscholar.org/paper/b7e336a7d3cd82ae8cd5e85d3cb62f0b6091a0e5\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2494584\",\"name\":\"G. Dimas\"},{\"authorId\":\"143932347\",\"name\":\"D. Iakovidis\"},{\"authorId\":\"47352212\",\"name\":\"A. Koulaouzidis\"}],\"doi\":\"10.1109/BIBE.2019.00071\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b8b496b2ba8490c9b8463d9757ee719f32700362\",\"title\":\"MedGaze: Gaze Estimation on WCE Images Based on a CNN Autoencoder\",\"url\":\"https://www.semanticscholar.org/paper/b8b496b2ba8490c9b8463d9757ee719f32700362\",\"venue\":\"2019 IEEE 19th International Conference on Bioinformatics and Bioengineering (BIBE)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2212471\",\"name\":\"H. Alers\"},{\"authorId\":\"1708715\",\"name\":\"J. Redi\"},{\"authorId\":\"3307573\",\"name\":\"H. Liu\"},{\"authorId\":\"145412643\",\"name\":\"I. Heynderickx\"}],\"doi\":\"10.1117/1.JEI.24.2.023030\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0ef3b9e28f69354950e7746fe6556dabb183c128\",\"title\":\"Effects of task and image properties on visual-attention deployment in image-quality assessment\",\"url\":\"https://www.semanticscholar.org/paper/0ef3b9e28f69354950e7746fe6556dabb183c128\",\"venue\":\"J. Electronic Imaging\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2007931\",\"name\":\"Kao Zhang\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"},{\"authorId\":\"1792817\",\"name\":\"S. Liu\"}],\"doi\":\"10.1109/TIP.2020.3036749\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"51b23ce1f48d769a31a4a4f4982fbfe5d4de41f4\",\"title\":\"A Spatial-Temporal Recurrent Neural Network for Video Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/51b23ce1f48d769a31a4a4f4982fbfe5d4de41f4\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2468613\",\"name\":\"V. Kachurka\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"501b619a0c321aee8d9506e318e5c8f22d563f2f\",\"title\":\"Contribution to Perception and Artificial Bio-inspired Visual Attention for Acquisition and Conceptualization of Knowledge in Autonomous Robotics. (Contribution \\u00e0 la perception et l'attention visuelle artificielle bio-inspir\\u00e9e pour acquisition et conceptualisation de la connaissance en robotique aut\",\"url\":\"https://www.semanticscholar.org/paper/501b619a0c321aee8d9506e318e5c8f22d563f2f\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1811.06308\",\"authors\":[{\"authorId\":\"51925488\",\"name\":\"David Berga\"},{\"authorId\":\"2556319\",\"name\":\"X. Otazu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"603bead9775c7523efe6c56431ab7f124b1bdee8\",\"title\":\"A Neurodynamic model of Saliency prediction in V1\",\"url\":\"https://www.semanticscholar.org/paper/603bead9775c7523efe6c56431ab7f124b1bdee8\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2021805\",\"name\":\"V. Buso\"},{\"authorId\":\"1398693138\",\"name\":\"I. Gonz\\u00e1lez-D\\u00edaz\"},{\"authorId\":\"1381345946\",\"name\":\"J. Benois-Pineau\"}],\"doi\":\"10.1016/j.image.2015.05.006\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"01cebfb804e99c941c2ee138e6f06da2675e2fa7\",\"title\":\"Goal-oriented top-down probabilistic visual attention model for recognition of manipulated objects in egocentric videos\",\"url\":\"https://www.semanticscholar.org/paper/01cebfb804e99c941c2ee138e6f06da2675e2fa7\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1395725948\",\"name\":\"Bashir Ghariba\"},{\"authorId\":\"153448727\",\"name\":\"M. Shehata\"},{\"authorId\":\"152293645\",\"name\":\"P. McGuire\"}],\"doi\":\"10.1109/CCECE47787.2020.9255692\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b95ad78e7aeb9c32e4bba9f9a079bc2257fb6694\",\"title\":\"Performance Evaluation of Pre-Trained CNN Models for Visual Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/b95ad78e7aeb9c32e4bba9f9a079bc2257fb6694\",\"venue\":\"2020 IEEE Canadian Conference on Electrical and Computer Engineering (CCECE)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144272947\",\"name\":\"Chen Xia\"},{\"authorId\":\"46534309\",\"name\":\"Fei Qi\"},{\"authorId\":\"143713952\",\"name\":\"Guangming Shi\"}],\"doi\":\"10.1109/TNNLS.2015.2512898\",\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"9d9e633203204193616bac34294e127b9665927b\",\"title\":\"Bottom\\u2013Up Visual Saliency Estimation With Deep Autoencoder-Based Sparse Reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/9d9e633203204193616bac34294e127b9665927b\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2016},{\"arxivId\":\"1811.05625\",\"authors\":[{\"authorId\":\"1967201\",\"name\":\"Kui Fu\"},{\"authorId\":null,\"name\":\"Jia Li\"},{\"authorId\":\"2803144\",\"name\":\"Y. Zhang\"},{\"authorId\":\"121194391\",\"name\":\"Hongze Shen\"},{\"authorId\":\"144051792\",\"name\":\"Yonghong Tian\"}],\"doi\":\"10.1109/TIP.2020.2998977\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fd2b919b6abb91657aa9104dfc2e7c18c114cbae\",\"title\":\"Model-Guided Multi-Path Knowledge Aggregation for Aerial Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/fd2b919b6abb91657aa9104dfc2e7c18c114cbae\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020}],\"corpusId\":457301,\"doi\":\"10.1109/ICCV.2013.147\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":31,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"79c761353fe46544a758b284813dfa2908664db2\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"47521917\",\"name\":\"Q. Zhao\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"}],\"doi\":\"10.1167/11.3.9\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b380725466e69717ab4c2520c80cff4bba2cc05c\",\"title\":\"Learning a saliency map using fixated locations in natural scenes.\",\"url\":\"https://www.semanticscholar.org/paper/b380725466e69717ab4c2520c80cff4bba2cc05c\",\"venue\":\"Journal of vision\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"2037692\",\"name\":\"Dicky N. Sihite\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1109/TIP.2012.2210727\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c0b60d02b2d59123f6b336fe2e287bdb02a2a776\",\"title\":\"Quantitative Analysis of Human-Model Agreement in Visual Saliency Modeling: A Comparative Study\",\"url\":\"https://www.semanticscholar.org/paper/c0b60d02b2d59123f6b336fe2e287bdb02a2a776\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2013},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Attention Group. Computational Attention Website\",\"url\":\"\",\"venue\":\"Attention Group. Computational Attention Website\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152627906\",\"name\":\"T. Judd\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"daef3fdc4190927c063ae94c12437cf82a6d1c20\",\"title\":\"A Benchmark of Computational Models of Saliency to Predict Human Fixations\",\"url\":\"https://www.semanticscholar.org/paper/daef3fdc4190927c063ae94c12437cf82a6d1c20\",\"venue\":\"\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2582552\",\"name\":\"Ofir Pele\"},{\"authorId\":\"27379268\",\"name\":\"M. Werman\"}],\"doi\":\"10.1109/ICCV.2009.5459199\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8ab6d616f812a3108ae85b4ab130b62b650c5677\",\"title\":\"Fast and robust Earth Mover's Distances\",\"url\":\"https://www.semanticscholar.org/paper/8ab6d616f812a3108ae85b4ab130b62b650c5677\",\"venue\":\"2009 IEEE 12th International Conference on Computer Vision\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1396144799\",\"name\":\"A. Garc\\u00eda-D\\u00edaz\"},{\"authorId\":\"1398290502\",\"name\":\"Xos\\u00e9 R. Fern\\u00e1ndez-Vidal\"},{\"authorId\":\"1768258\",\"name\":\"X. Pardo\"},{\"authorId\":\"1751198\",\"name\":\"Raquel Dosil\"}],\"doi\":\"10.1007/978-3-642-04697-1_32\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"749e554382fd343fc7c81ec61dfc7cd2fd997745\",\"title\":\"Decorrelation and Distinctiveness Provide with Human-Like Saliency\",\"url\":\"https://www.semanticscholar.org/paper/749e554382fd343fc7c81ec61dfc7cd2fd997745\",\"venue\":\"ACIVS\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7326223\",\"name\":\"L. Itti\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"},{\"authorId\":\"3271571\",\"name\":\"E. Niebur\"}],\"doi\":\"10.1109/34.730558\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4816f0b6f0d05da3901441bfa5cc7be044b4da8b\",\"title\":\"A Model of Saliency-Based Visual Attention for Rapid Scene Analysis\",\"url\":\"https://www.semanticscholar.org/paper/4816f0b6f0d05da3901441bfa5cc7be044b4da8b\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1364/JOSAA.20.001407\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4e8862366617f9ce13d603ac9311d396fb2d2e25\",\"title\":\"Modeling global scene factors in attention.\",\"url\":\"https://www.semanticscholar.org/paper/4e8862366617f9ce13d603ac9311d396fb2d2e25\",\"venue\":\"Journal of the Optical Society of America. A, Optics, image science, and vision\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47059693\",\"name\":\"L. Zhang\"},{\"authorId\":\"49488601\",\"name\":\"M. Tong\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"},{\"authorId\":\"2207531\",\"name\":\"Honghao Shan\"},{\"authorId\":\"48524582\",\"name\":\"G. Cottrell\"}],\"doi\":\"10.1167/8.7.32\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e80c48441351fc1d928524710b4500a0de8315bb\",\"title\":\"SUN: A Bayesian framework for saliency using natural statistics.\",\"url\":\"https://www.semanticscholar.org/paper/e80c48441351fc1d928524710b4500a0de8315bb\",\"venue\":\"Journal of vision\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3084719\",\"name\":\"Xiaodi Hou\"},{\"authorId\":\"5381034\",\"name\":\"L. Zhang\"}],\"doi\":\"10.1109/CVPR.2007.383267\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9ce3c18eb4fa86fd19bce46227be39895de4e4ab\",\"title\":\"Saliency Detection: A Spectral Residual Approach\",\"url\":\"https://www.semanticscholar.org/paper/9ce3c18eb4fa86fd19bce46227be39895de4e4ab\",\"venue\":\"2007 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3151890\",\"name\":\"N. Ouerhani\"},{\"authorId\":\"1939985\",\"name\":\"R. Wartburg\"},{\"authorId\":\"152447339\",\"name\":\"Heinz Hugli\"},{\"authorId\":\"34663587\",\"name\":\"R. M\\u00fcri\"}],\"doi\":\"10.5565/REV/ELCVIA.66\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cda602caa9c53889f5a9656e6c61ec57bfd7bdfc\",\"title\":\"Empirical Validation of the Saliency-based Model of Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/cda602caa9c53889f5a9656e6c61ec57bfd7bdfc\",\"venue\":\"\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143615083\",\"name\":\"R. J. Peters\"},{\"authorId\":\"4292093\",\"name\":\"A. Iyer\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"}],\"doi\":\"10.1016/j.visres.2005.03.019\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a7447f7e6197c0875a28686efdffe4ba4beb5460\",\"title\":\"Components of bottom-up gaze allocation in natural images\",\"url\":\"https://www.semanticscholar.org/paper/a7447f7e6197c0875a28686efdffe4ba4beb5460\",\"venue\":\"Vision Research\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"R. Von Wartburg N. Ouerhani\"},{\"authorId\":null,\"name\":\"H. Hugli\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"pirical validation of the saliency - based model of visual attention . Electronic letters on computer vision and image analy\",\"url\":\"\",\"venue\":\"\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2989773\",\"name\":\"Nicolas Riche\"},{\"authorId\":\"1681157\",\"name\":\"M. Mancas\"},{\"authorId\":\"2896417\",\"name\":\"Matthieu Duvinage\"},{\"authorId\":\"3028207\",\"name\":\"Makiese Mibulumukini\"},{\"authorId\":\"50276543\",\"name\":\"B. Gosselin\"},{\"authorId\":\"49164810\",\"name\":\"T. Dutoit\"}],\"doi\":\"10.1016/j.image.2013.03.009\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"83ec029e1a7b41669f8254b24c070050d9d01d75\",\"title\":\"RARE2012: A multi-scale rarity-based saliency detection with its comparative statistical analysis\",\"url\":\"https://www.semanticscholar.org/paper/83ec029e1a7b41669f8254b24c070050d9d01d75\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145624227\",\"name\":\"C. Koch\"},{\"authorId\":\"1743045\",\"name\":\"S. Ullman\"}],\"doi\":\"10.1007/978-94-009-3833-5_5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0ce672e6ef09e9ab4c43f1eb75443dc7a5cb38c6\",\"title\":\"Shifts in selective visual attention: towards the underlying neural circuitry.\",\"url\":\"https://www.semanticscholar.org/paper/0ce672e6ef09e9ab4c43f1eb75443dc7a5cb38c6\",\"venue\":\"Human neurobiology\",\"year\":1985},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1789744\",\"name\":\"O. Meur\"},{\"authorId\":\"1776651\",\"name\":\"P. Callet\"},{\"authorId\":\"144812989\",\"name\":\"D. Barba\"}],\"doi\":\"10.1016/j.visres.2007.06.015\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"122134f9242785383949caaaea4601861beebad8\",\"title\":\"Predicting visual fixations on video based on low-level visual features\",\"url\":\"https://www.semanticscholar.org/paper/122134f9242785383949caaaea4601861beebad8\",\"venue\":\"Vision Research\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1789744\",\"name\":\"O. Meur\"},{\"authorId\":\"1731790\",\"name\":\"T. Baccino\"}],\"doi\":\"10.3758/s13428-012-0226-9\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a98a0079fef4c434e5e1f775ce47f8151149bf47\",\"title\":\"Methods for comparing scanpaths and saliency maps: strengths and weaknesses\",\"url\":\"https://www.semanticscholar.org/paper/a98a0079fef4c434e5e1f775ce47f8151149bf47\",\"venue\":\"Behavior research methods\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3084719\",\"name\":\"Xiaodi Hou\"},{\"authorId\":\"5381034\",\"name\":\"L. Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4e7ec75337766f2b649bb9f99c6887ee0f1674a6\",\"title\":\"Dynamic visual attention: searching for coding length increments\",\"url\":\"https://www.semanticscholar.org/paper/4e7ec75337766f2b649bb9f99c6887ee0f1674a6\",\"venue\":\"NIPS\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2582552\",\"name\":\"Ofir Pele\"},{\"authorId\":\"27379268\",\"name\":\"M. Werman\"}],\"doi\":\"10.1007/978-3-540-88690-7_37\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ca5b659520cf1fadaa2feced59fe318d15ca55b4\",\"title\":\"A Linear Time Histogram Metric for Improved SIFT Matching\",\"url\":\"https://www.semanticscholar.org/paper/ca5b659520cf1fadaa2feced59fe318d15ca55b4\",\"venue\":\"ECCV\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143615083\",\"name\":\"R. J. Peters\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1145/1279920.1279923\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"395ab4920c34df5c61f4615ae79a685a54966bbe\",\"title\":\"Applying computational tools to predict gaze direction in interactive visual environments\",\"url\":\"https://www.semanticscholar.org/paper/395ab4920c34df5c61f4615ae79a685a54966bbe\",\"venue\":\"TAP\",\"year\":2008},{\"arxivId\":\"1605.01999\",\"authors\":[{\"authorId\":\"1701502\",\"name\":\"Jian Li\"},{\"authorId\":\"3631473\",\"name\":\"M. Levine\"},{\"authorId\":\"2888872\",\"name\":\"X. An\"},{\"authorId\":\"145813731\",\"name\":\"X. Xu\"},{\"authorId\":\"3302754\",\"name\":\"Hangen He\"}],\"doi\":\"10.1109/TPAMI.2012.147\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0c760f678c99b4a7eacc4b0ef7a42d4e6c734983\",\"title\":\"Visual Saliency Based on Scale-Space Analysis in the Frequency Domain\",\"url\":\"https://www.semanticscholar.org/paper/0c760f678c99b4a7eacc4b0ef7a42d4e6c734983\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"R. Von Wartburg N. Ouerhani\"},{\"authorId\":null,\"name\":\"H. Hugli\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"pirical validation of the saliency - based model of visual attention . Electronic letters on computer vision and image analy\",\"url\":\"\",\"venue\":\"\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2771014\",\"name\":\"U. Rajashekar\"},{\"authorId\":\"1727781\",\"name\":\"L. Cormack\"},{\"authorId\":\"1747569\",\"name\":\"A. Bovik\"}],\"doi\":\"10.1117/12.537118\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7263be567269386f02c605af0be3626a199366ae\",\"title\":\"Point-of-gaze analysis reveals visual search strategies\",\"url\":\"https://www.semanticscholar.org/paper/7263be567269386f02c605af0be3626a199366ae\",\"venue\":\"IS&T/SPIE Electronic Imaging\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47331421\",\"name\":\"H. Guo\"},{\"authorId\":\"2133634\",\"name\":\"K. Woodbridge\"},{\"authorId\":\"121684195\",\"name\":\"C. Baker\"}],\"doi\":\"10.1109/RADAR.2008.4720810\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e11070a414d77b71bffd37141b7901d9f764dd8e\",\"title\":\"Evaluation of WiFi beacon transmissions for wireless based passive radar\",\"url\":\"https://www.semanticscholar.org/paper/e11070a414d77b71bffd37141b7901d9f764dd8e\",\"venue\":\"2008 IEEE Radar Conference\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2118589\",\"name\":\"R. Achanta\"},{\"authorId\":\"1720838\",\"name\":\"S. Hemami\"},{\"authorId\":\"145337110\",\"name\":\"F. J. Estrada\"},{\"authorId\":\"1735035\",\"name\":\"S. S\\u00fcsstrunk\"}],\"doi\":\"10.1109/CVPR.2009.5206596\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"63d523a58d2cd24efbc1ab35acccc64e0f93162b\",\"title\":\"Frequency-tuned salient region detection\",\"url\":\"https://www.semanticscholar.org/paper/63d523a58d2cd24efbc1ab35acccc64e0f93162b\",\"venue\":\"CVPR 2009\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1941997\",\"name\":\"Chenlei Guo\"},{\"authorId\":\"144818403\",\"name\":\"Qi Ma\"},{\"authorId\":\"29906646\",\"name\":\"L. Zhang\"}],\"doi\":\"10.1109/CVPR.2008.4587715\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"16f4cfd4cbf504a151827b5a94df5deafd4930ac\",\"title\":\"Spatio-temporal Saliency detection using phase spectrum of quaternion fourier transform\",\"url\":\"https://www.semanticscholar.org/paper/16f4cfd4cbf504a151827b5a94df5deafd4930ac\",\"venue\":\"2008 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"F. Estrada\"},{\"authorId\":null,\"name\":\"S. Susstrunk\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Frequency - tuned salient region detection State - ofthe - art in visual attention modeling\",\"url\":\"\",\"venue\":\"IEEE Transactions on PAMI\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2866780\",\"name\":\"Neil D. B. Bruce\"},{\"authorId\":\"1727853\",\"name\":\"John K. Tsotsos\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4f847b4ddc105d73bc78f3e7220e6c1f71a7dfb6\",\"title\":\"Saliency Based on Information Maximization\",\"url\":\"https://www.semanticscholar.org/paper/4f847b4ddc105d73bc78f3e7220e6c1f71a7dfb6\",\"venue\":\"NIPS\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1727853\",\"name\":\"John K. Tsotsos\"},{\"authorId\":\"2888197\",\"name\":\"Sean M. Culhane\"},{\"authorId\":\"2676061\",\"name\":\"W. K. Wai\"},{\"authorId\":\"1399956386\",\"name\":\"Yuzhong Lai\"},{\"authorId\":\"46903986\",\"name\":\"N. Davis\"},{\"authorId\":\"1397804046\",\"name\":\"Fernando Nuflo\"}],\"doi\":\"10.1016/0004-3702(95)00025-9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8930f62a4b5eb1cbabf224cf84aa009ea798cfee\",\"title\":\"Modeling Visual Attention via Selective Tuning\",\"url\":\"https://www.semanticscholar.org/paper/8930f62a4b5eb1cbabf224cf84aa009ea798cfee\",\"venue\":\"Artif. Intell.\",\"year\":1995},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3369864\",\"name\":\"B. Tatler\"},{\"authorId\":\"34931109\",\"name\":\"R. Baddeley\"},{\"authorId\":\"2283822\",\"name\":\"I. Gilchrist\"}],\"doi\":\"10.1016/j.visres.2004.09.017\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ae38ed953333fb39eb671fce0247db65a09b3a80\",\"title\":\"Visual correlates of fixation selection: effects of scale and time\",\"url\":\"https://www.semanticscholar.org/paper/ae38ed953333fb39eb671fce0247db65a09b3a80\",\"venue\":\"Vision Research\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A Borji\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Evaluation measures for saliency maps. https://sites.google.com/site/ saliencyevaluation/home\",\"url\":\"\",\"venue\":\"Evaluation measures for saliency maps. https://sites.google.com/site/ saliencyevaluation/home\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1944545\",\"name\":\"A. Toet\"}],\"doi\":\"10.1109/TPAMI.2011.53\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b26b2bf08f0b8d0b7f5ac904ff745c2778e860d5\",\"title\":\"Computational versus Psychophysical Bottom-Up Image Saliency: A Comparative Evaluation Study\",\"url\":\"https://www.semanticscholar.org/paper/b26b2bf08f0b8d0b7f5ac904ff745c2778e860d5\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145175410\",\"name\":\"D. Howell\"}],\"doi\":\"10.2307/2348956\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0991abe016abaa13ce431e83ac8d5863cdbce1e2\",\"title\":\"Statistical Methods for Psychology\",\"url\":\"https://www.semanticscholar.org/paper/0991abe016abaa13ce431e83ac8d5863cdbce1e2\",\"venue\":\"\",\"year\":1987},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"N Bruce\"},{\"authorId\":null,\"name\":\"J Tsotsos\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Saliency based on information maximization Advances in neural information processing systems\",\"url\":\"\",\"venue\":\"Saliency based on information maximization Advances in neural information processing systems\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"2060684\",\"name\":\"Monica S. Castelhano\"},{\"authorId\":\"1889476\",\"name\":\"J. Henderson\"}],\"doi\":\"10.1037/0033-295X.113.4.766\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b35e4d00d9a9bfae83a8b0914eb1073a77a11d78\",\"title\":\"Contextual guidance of eye movements and attention in real-world scenes: the role of global features in object search.\",\"url\":\"https://www.semanticscholar.org/paper/b35e4d00d9a9bfae83a8b0914eb1073a77a11d78\",\"venue\":\"Psychological review\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1109/TPAMI.2012.89\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aa57b9bdb0736cbb38abf0a9d12047212c2a2425\",\"title\":\"State-of-the-Art in Visual Attention Modeling\",\"url\":\"https://www.semanticscholar.org/paper/aa57b9bdb0736cbb38abf0a9d12047212c2a2425\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013}],\"title\":\"Saliency and Human Fixations: State-of-the-Art and Study of Comparison Metrics\",\"topics\":[{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"},{\"topic\":\"Coefficient\",\"topicId\":\"3129\",\"url\":\"https://www.semanticscholar.org/topic/3129\"},{\"topic\":\"Concordance (publishing)\",\"topicId\":\"61477\",\"url\":\"https://www.semanticscholar.org/topic/61477\"},{\"topic\":\"Semantic similarity\",\"topicId\":\"34825\",\"url\":\"https://www.semanticscholar.org/topic/34825\"}],\"url\":\"https://www.semanticscholar.org/paper/79c761353fe46544a758b284813dfa2908664db2\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013}\n"