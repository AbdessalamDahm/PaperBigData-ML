"{\"abstract\":\"We present a method to continuously blend between multiple facial performances of an actor, which can contain different facial expressions or emotional states. As an example, given sad and angry video takes of a scene, our method empowers the movie director to specify arbitrary weighted combinations and smooth transitions between the two takes in post-production. Our contributions include (1) a robust nonlinear audio-visual synchronization technique that exploits complementary properties of audio and visual cues to automatically determine robust, dense spatiotemporal correspondences between takes, and (2) a seamless facial blending approach that provides the director full control to interpolate timing, facial expression, and local appearance, in order to generate novel performances after filming. In contrast to most previous works, our approach operates entirely in image space, avoiding the need of 3D facial reconstruction. We demonstrate that our method can synthesize visually believable performances with applications in emotion transition, performance correction, and timing control.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"2116817\",\"name\":\"Charles Malleson\",\"url\":\"https://www.semanticscholar.org/author/2116817\"},{\"authorId\":\"31798873\",\"name\":\"J. Bazin\",\"url\":\"https://www.semanticscholar.org/author/31798873\"},{\"authorId\":\"47520207\",\"name\":\"O. Wang\",\"url\":\"https://www.semanticscholar.org/author/47520207\"},{\"authorId\":\"144863596\",\"name\":\"D. Bradley\",\"url\":\"https://www.semanticscholar.org/author/144863596\"},{\"authorId\":\"2486770\",\"name\":\"T. Beeler\",\"url\":\"https://www.semanticscholar.org/author/2486770\"},{\"authorId\":\"144046599\",\"name\":\"A. Hilton\",\"url\":\"https://www.semanticscholar.org/author/144046599\"},{\"authorId\":\"1388791172\",\"name\":\"Alexander Sorkine-Hornung\",\"url\":\"https://www.semanticscholar.org/author/1388791172\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":\"2009.00922\",\"authors\":[{\"authorId\":\"1390111049\",\"name\":\"A. Hilsmann\"},{\"authorId\":\"108056181\",\"name\":\"Philipp Fechteler\"},{\"authorId\":\"1442117232\",\"name\":\"W. Morgenstern\"},{\"authorId\":\"2760845\",\"name\":\"Wolfgang Paier\"},{\"authorId\":\"2924267\",\"name\":\"I. Feldmann\"},{\"authorId\":\"47004189\",\"name\":\"O. Schreer\"},{\"authorId\":\"46588404\",\"name\":\"P. Eisert\"}],\"doi\":\"10.1049/iet-cvi.2019.0786\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"72c109f1fb8e733afdebe43862798a7badf6ff1e\",\"title\":\"Going beyond Free Viewpoint: Creating Animatable Volumetric Video of Human Performances\",\"url\":\"https://www.semanticscholar.org/paper/72c109f1fb8e733afdebe43862798a7badf6ff1e\",\"venue\":\"IET Comput. Vis.\",\"year\":2020},{\"arxivId\":\"1805.00780\",\"authors\":[{\"authorId\":\"46238394\",\"name\":\"Maren Awiszus\"},{\"authorId\":\"23620370\",\"name\":\"Stella Grasshof\"},{\"authorId\":\"17126804\",\"name\":\"F. Kuhnke\"},{\"authorId\":\"144835580\",\"name\":\"J. Ostermann\"}],\"doi\":\"10.1109/CVPRW.2018.00156\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b3478486f9703c64ee91f9cbce24571e2809b072\",\"title\":\"Unsupervised Features for Facial Expression Intensity Estimation Over Time\",\"url\":\"https://www.semanticscholar.org/paper/b3478486f9703c64ee91f9cbce24571e2809b072\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2712411\",\"name\":\"Swapna Agarwal\"},{\"authorId\":\"145478199\",\"name\":\"D. Mukherjee\"}],\"doi\":\"10.1109/TMM.2018.2871417\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c644218ba51df87fa7b5c740a962c1b5b1ae131d\",\"title\":\"Synthesis of Realistic Facial Expressions Using Expression Map\",\"url\":\"https://www.semanticscholar.org/paper/c644218ba51df87fa7b5c740a962c1b5b1ae131d\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699058\",\"name\":\"M. Zollh\\u00f6fer\"},{\"authorId\":\"34105638\",\"name\":\"Justus Thies\"},{\"authorId\":\"39912094\",\"name\":\"P. Garrido\"},{\"authorId\":\"143929823\",\"name\":\"D. Bradley\"},{\"authorId\":\"2486770\",\"name\":\"T. Beeler\"},{\"authorId\":\"144565371\",\"name\":\"P. P\\u00e9rez\"},{\"authorId\":\"144140066\",\"name\":\"M. Stamminger\"},{\"authorId\":\"2209612\",\"name\":\"M. Nie\\u00dfner\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"}],\"doi\":\"10.1111/cgf.13382\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fda48e021f7c1445406fa7db32a443726e0ef8d3\",\"title\":\"State of the Art on Monocular 3D Face Reconstruction, Tracking, and Applications\",\"url\":\"https://www.semanticscholar.org/paper/fda48e021f7c1445406fa7db32a443726e0ef8d3\",\"venue\":\"Comput. Graph. Forum\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39765532\",\"name\":\"Miao Wang\"},{\"authorId\":\"17291694\",\"name\":\"Jun-Bang Liang\"},{\"authorId\":\"7671691\",\"name\":\"Song-Hai Zhang\"},{\"authorId\":\"3075033\",\"name\":\"Shao-Ping Lu\"},{\"authorId\":\"2947946\",\"name\":\"Ariel Shamir\"},{\"authorId\":\"145140922\",\"name\":\"S. Hu\"}],\"doi\":\"10.1109/TIP.2017.2749143\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3835c94da7047896760ef9cc3b65c335f180f923\",\"title\":\"Hyper-Lapse From Multiple Spatially-Overlapping Videos\",\"url\":\"https://www.semanticscholar.org/paper/3835c94da7047896760ef9cc3b65c335f180f923\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4263161\",\"name\":\"Yuji Kawase\"},{\"authorId\":\"50513204\",\"name\":\"S. Yoshida\"},{\"authorId\":\"1747343\",\"name\":\"T. Narumi\"},{\"authorId\":\"3237529\",\"name\":\"S. Ueda\"},{\"authorId\":\"47243384\",\"name\":\"M. Ikeda\"},{\"authorId\":\"71403642\",\"name\":\"J. Watanabe\"},{\"authorId\":\"1734112\",\"name\":\"T. Tanikawa\"},{\"authorId\":\"2709152\",\"name\":\"Tetsuya Kawamoto\"},{\"authorId\":\"145582886\",\"name\":\"M. Hirose\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"d82c226e8590a039a7e52c17ec545a23170e718f\",\"title\":\"Mob Scene Filter : Conversion of Facial Appearance by Changing Position and Size of Facial Regions\",\"url\":\"https://www.semanticscholar.org/paper/d82c226e8590a039a7e52c17ec545a23170e718f\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38376240\",\"name\":\"Kyle Olszewski\"},{\"authorId\":\"2825680\",\"name\":\"Zimo Li\"},{\"authorId\":\"40055538\",\"name\":\"C. Yang\"},{\"authorId\":null,\"name\":\"Yi Zhou\"},{\"authorId\":\"9965153\",\"name\":\"Ronald Yu\"},{\"authorId\":\"145554741\",\"name\":\"Zeng Huang\"},{\"authorId\":\"10745567\",\"name\":\"Sitao Xiang\"},{\"authorId\":\"2059597\",\"name\":\"S. Saito\"},{\"authorId\":\"143967473\",\"name\":\"Pushmeet Kohli\"},{\"authorId\":\"1706574\",\"name\":\"Hao Li\"}],\"doi\":\"10.1109/ICCV.2017.580\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4b0bcc134dbcf89abad55beecf9358bacc463544\",\"title\":\"Realistic Dynamic Facial Textures from a Single Image Using GANs\",\"url\":\"https://www.semanticscholar.org/paper/4b0bcc134dbcf89abad55beecf9358bacc463544\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1968170\",\"name\":\"G. Fyffe\"},{\"authorId\":\"1897417\",\"name\":\"K. Nagano\"},{\"authorId\":\"143682166\",\"name\":\"L. Huynh\"},{\"authorId\":\"2059597\",\"name\":\"S. Saito\"},{\"authorId\":\"2815984\",\"name\":\"Jay Busch\"},{\"authorId\":\"145776381\",\"name\":\"A. Jones\"},{\"authorId\":\"1706574\",\"name\":\"Hao Li\"},{\"authorId\":\"1778676\",\"name\":\"P. Debevec\"}],\"doi\":\"10.1111/cgf.13127\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"79096aa11fb5f293f7f63e71924fe7b0b702520b\",\"title\":\"Multi\\u2010View Stereo on Consistent Face Topology\",\"url\":\"https://www.semanticscholar.org/paper/79096aa11fb5f293f7f63e71924fe7b0b702520b\",\"venue\":\"Comput. Graph. Forum\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46228775\",\"name\":\"Yoonjae Cho\"},{\"authorId\":\"33085949\",\"name\":\"Dohyeong Kim\"},{\"authorId\":\"116406543\",\"name\":\"Edwin M. Truman\"},{\"authorId\":\"153427058\",\"name\":\"Jean-Charles Bazin\"}],\"doi\":\"10.1109/ICCVW.2019.00458\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"337825eef0731eea6bc67544f6d30cf3f383c78f\",\"title\":\"FaceSyncNet: A Deep Learning-Based Approach for Non-Linear Synchronization of Facial Performance Videos\",\"url\":\"https://www.semanticscholar.org/paper/337825eef0731eea6bc67544f6d30cf3f383c78f\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152823345\",\"name\":\"M. Sol\\u00e8r\"},{\"authorId\":\"31798873\",\"name\":\"J. Bazin\"},{\"authorId\":\"47520207\",\"name\":\"O. Wang\"},{\"authorId\":\"153243248\",\"name\":\"A. Krause\"},{\"authorId\":\"1388791172\",\"name\":\"Alexander Sorkine-Hornung\"}],\"doi\":\"10.1007/978-3-319-48881-3_59\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"333aa36e80f1a7fa29cf069d81d4d2e12679bc67\",\"title\":\"Suggesting Sounds for Images from Video Collections\",\"url\":\"https://www.semanticscholar.org/paper/333aa36e80f1a7fa29cf069d81d4d2e12679bc67\",\"venue\":\"ECCV Workshops\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1394987422\",\"name\":\"\\u4f51\\u53f8 \\u5ddd\\u702c\"},{\"authorId\":\"73262118\",\"name\":\"\\u6210\\u6717 \\u5409\\u7530\"},{\"authorId\":\"52096214\",\"name\":\"\\u62d3\\u5fd7 \\u9cf4\\u6d77\"},{\"authorId\":\"73289361\",\"name\":\"\\u7965\\u4ee3 \\u4e0a\\u7530\"},{\"authorId\":\"69065715\",\"name\":\"\\u6c60\\u7530 \\u307e\\u3055\\u307f\"},{\"authorId\":\"1397323356\",\"name\":\"\\u6df3\\u53f8 \\u6e21\\u908a\"},{\"authorId\":\"52122183\",\"name\":\"\\u667a\\u6d0b \\u8c37\\u5ddd\"},{\"authorId\":\"71518827\",\"name\":\"\\u54f2\\u4e5f \\u5ddd\\u672c\"},{\"authorId\":\"52107480\",\"name\":\"\\u901a\\u5b5d \\u5ee3\\u702c\"}],\"doi\":\"10.18974/TVRSJ.21.3_483\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"56b4697df6b6c57e3d63c3022d2d639c1b2aedfb\",\"title\":\"Mob Scene Filter: \\u9854\\u90e8\\u4f4d\\u306e\\u5f62\\u72b6\\u30fb\\u4f4d\\u7f6e\\u5909\\u5f62\\u3092\\u5229\\u7528\\u3057\\u305f\\u4ed6\\u4eba\\u9854\\u5909\\u63db\\u624b\\u6cd5\",\"url\":\"https://www.semanticscholar.org/paper/56b4697df6b6c57e3d63c3022d2d639c1b2aedfb\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31798873\",\"name\":\"J. Bazin\"},{\"authorId\":\"1388791172\",\"name\":\"Alexander Sorkine-Hornung\"}],\"doi\":\"10.1007/978-3-319-46454-1_10\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"351c02d4775ae95e04ab1e5dd0c758d2d80c3ddd\",\"title\":\"ActionSnapping: Motion-Based Video Synchronization\",\"url\":\"https://www.semanticscholar.org/paper/351c02d4775ae95e04ab1e5dd0c758d2d80c3ddd\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145089247\",\"name\":\"L. Ma\"},{\"authorId\":\"144996593\",\"name\":\"Z. Deng\"}],\"doi\":\"10.1111/cgf.13586\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3829a78a84faf5c2610737f381cab0c4b496aaf3\",\"title\":\"Real\\u2010Time Facial Expression Transformation for Monocular RGB Video\",\"url\":\"https://www.semanticscholar.org/paper/3829a78a84faf5c2610737f381cab0c4b496aaf3\",\"venue\":\"Comput. Graph. Forum\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34846285\",\"name\":\"Julian F. P. Kooij\"},{\"authorId\":\"1738975\",\"name\":\"J. C. V. Gemert\"}],\"doi\":\"10.1007/978-3-319-46484-8_28\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4d3e166acd82bd1fb12a8d8d671b4c1f941352d5\",\"title\":\"Depth-Aware Motion Magnification\",\"url\":\"https://www.semanticscholar.org/paper/4d3e166acd82bd1fb12a8d8d671b4c1f941352d5\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1908.04338\",\"authors\":[{\"authorId\":\"51358562\",\"name\":\"John Kanji\"},{\"authorId\":\"143774460\",\"name\":\"D. Levin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"91ebf7275a4cc630e41f494b1ac1a16764fdfa6d\",\"title\":\"Convolutional Humanoid Animation via Deformation\",\"url\":\"https://www.semanticscholar.org/paper/91ebf7275a4cc630e41f494b1ac1a16764fdfa6d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46588404\",\"name\":\"P. Eisert\"},{\"authorId\":\"3353355\",\"name\":\"A. Hilsmann\"}],\"doi\":\"10.1007/978-3-030-41816-8_7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ff8ee35491d24f9c0d7430169bd450b16d5981ab\",\"title\":\"Hybrid Human Modeling: Making Volumetric Video Animatable\",\"url\":\"https://www.semanticscholar.org/paper/ff8ee35491d24f9c0d7430169bd450b16d5981ab\",\"venue\":\"Real VR\",\"year\":2020}],\"corpusId\":1678870,\"doi\":\"10.1109/ICCV.2015.453\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":2,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"9b243f4a892925af5c7b30bc3536214404c35bbd\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"143929823\",\"name\":\"D. Bradley\"},{\"authorId\":\"1752192\",\"name\":\"W. Heidrich\"},{\"authorId\":\"143943935\",\"name\":\"T. Popa\"},{\"authorId\":\"1778286\",\"name\":\"A. Sheffer\"}],\"doi\":\"10.1145/1833349.1778778\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"220f6b1de39b24e2017bb0a2d80d222b8528cf9e\",\"title\":\"High resolution passive facial performance capture\",\"url\":\"https://www.semanticscholar.org/paper/220f6b1de39b24e2017bb0a2d80d222b8528cf9e\",\"venue\":\"SIGGRAPH '10\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"P Sand\"},{\"authorId\":null,\"name\":\"S J Teller\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Video matching. TOG (SIGGRAPH)\",\"url\":\"\",\"venue\":\"Video matching. TOG (SIGGRAPH)\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jing Liao\"},{\"authorId\":\"104576341\",\"name\":\"Rodolfo S. Lima\"},{\"authorId\":\"1764421\",\"name\":\"Diego F. Nehab\"},{\"authorId\":\"144201188\",\"name\":\"Hugues Hoppe\"},{\"authorId\":\"145891472\",\"name\":\"Pedro V. Sander\"}],\"doi\":\"10.1111/cgf.12412\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3b13d90eb882d7bc398c0fdd76313c2de5c576c8\",\"title\":\"Semi\\u2010Automated Video Morphing\",\"url\":\"https://www.semanticscholar.org/paper/3b13d90eb882d7bc398c0fdd76313c2de5c576c8\",\"venue\":\"Comput. Graph. Forum\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32951485\",\"name\":\"A. Ghosh\"},{\"authorId\":\"1968170\",\"name\":\"G. Fyffe\"},{\"authorId\":\"2590229\",\"name\":\"Borom Tunwattanapong\"},{\"authorId\":\"2815984\",\"name\":\"Jay Busch\"},{\"authorId\":\"1934150\",\"name\":\"Xueming Yu\"},{\"authorId\":\"1778676\",\"name\":\"P. Debevec\"}],\"doi\":\"10.1145/2024156.2024163\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"644f2d0aeb563ddb6ccde0d76d7bb451356a9ce5\",\"title\":\"Multiview face capture using polarized spherical gradient illumination\",\"url\":\"https://www.semanticscholar.org/paper/644f2d0aeb563ddb6ccde0d76d7bb451356a9ce5\",\"venue\":\"SA '11\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"O. Sorkine\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Least-squares rigid motion using SVD\",\"url\":\"\",\"venue\":\"Technical report\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143636342\",\"name\":\"Sarah L. Taylor\"},{\"authorId\":\"30303590\",\"name\":\"M. Mahler\"},{\"authorId\":\"2785748\",\"name\":\"B. Theobald\"},{\"authorId\":\"1711695\",\"name\":\"I. Matthews\"}],\"doi\":\"10.2312/SCA/SCA12/275-284\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"910bb564f42f298898c1831e6650b1f2efa07b42\",\"title\":\"Dynamic units of visual speech\",\"url\":\"https://www.semanticscholar.org/paper/910bb564f42f298898c1831e6650b1f2efa07b42\",\"venue\":\"SCA '12\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47520207\",\"name\":\"O. Wang\"},{\"authorId\":\"2604867\",\"name\":\"Christopher Schroers\"},{\"authorId\":\"1405719070\",\"name\":\"H. Zimmer\"},{\"authorId\":\"144877478\",\"name\":\"M. Gross\"},{\"authorId\":\"1388791172\",\"name\":\"Alexander Sorkine-Hornung\"}],\"doi\":\"10.1145/2601097.2601208\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"bf0a9079e064c8277e7a930289a9ea08dbb6f690\",\"title\":\"VideoSnapping: interactive synchronization of multiple videos\",\"url\":\"https://www.semanticscholar.org/paper/bf0a9079e064c8277e7a930289a9ea08dbb6f690\",\"venue\":\"ACM Trans. Graph.\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1880628\",\"name\":\"D. Vlasic\"},{\"authorId\":\"144549270\",\"name\":\"M. Brand\"},{\"authorId\":\"143758236\",\"name\":\"H. Pfister\"},{\"authorId\":\"145492783\",\"name\":\"J. Popovic\"}],\"doi\":\"10.1145/1186822.1073209\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a2290765ce72ea84af8ac7535d4159f223eefdd3\",\"title\":\"Face transfer with multilinear models\",\"url\":\"https://www.semanticscholar.org/paper/a2290765ce72ea84af8ac7535d4159f223eefdd3\",\"venue\":\"ACM Trans. Graph.\",\"year\":2005},{\"arxivId\":\"1602.02651\",\"authors\":[{\"authorId\":\"39912094\",\"name\":\"P. Garrido\"},{\"authorId\":\"1797649\",\"name\":\"Levi Valgaerts\"},{\"authorId\":\"2020396\",\"name\":\"Ole Rehmsen\"},{\"authorId\":\"2543070\",\"name\":\"Thorsten Thorm\\u00e4hlen\"},{\"authorId\":\"144565371\",\"name\":\"P. P\\u00e9rez\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"}],\"doi\":\"10.1109/CVPR.2014.537\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a285f7d80e47b05ebff83387424cd0df8cb7833d\",\"title\":\"Automatic Face Reenactment\",\"url\":\"https://www.semanticscholar.org/paper/a285f7d80e47b05ebff83387424cd0df8cb7833d\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J Liao\"},{\"authorId\":null,\"name\":\"R S Lima\"},{\"authorId\":null,\"name\":\"D Nehab\"},{\"authorId\":null,\"name\":\"H Hoppe\"},{\"authorId\":null,\"name\":\"P V Sander\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Semi-automated video morphing. CGF (Eurographics Symposium on Rendering)\",\"url\":\"\",\"venue\":\"Semi-automated video morphing. CGF (Eurographics Symposium on Rendering)\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40566964\",\"name\":\"Claudia Kuster\"},{\"authorId\":\"2775650\",\"name\":\"Tiberiu Popa\"},{\"authorId\":\"31798873\",\"name\":\"J. Bazin\"},{\"authorId\":\"1724072\",\"name\":\"C. Gotsman\"},{\"authorId\":\"144877478\",\"name\":\"M. Gross\"}],\"doi\":\"10.1145/2366145.2366193\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8645b57bbe376e67b719de96b14ad2c02daa1701\",\"title\":\"Gaze correction for home video conferencing\",\"url\":\"https://www.semanticscholar.org/paper/8645b57bbe376e67b719de96b14ad2c02daa1701\",\"venue\":\"TOGS\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36706427\",\"name\":\"Fuhao Shi\"},{\"authorId\":\"1775992\",\"name\":\"H. Wu\"},{\"authorId\":\"49144235\",\"name\":\"X. Tong\"},{\"authorId\":\"1759700\",\"name\":\"Jinxiang Chai\"}],\"doi\":\"10.1145/2661229.2661290\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ca8739de82b3cfcd81468f8bf50333dfed0894b9\",\"title\":\"Automatic acquisition of high-fidelity facial performances using monocular videos\",\"url\":\"https://www.semanticscholar.org/paper/ca8739de82b3cfcd81468f8bf50333dfed0894b9\",\"venue\":\"ACM Trans. Graph.\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145290352\",\"name\":\"M. Slaney\"},{\"authorId\":\"1800748\",\"name\":\"M. Covell\"},{\"authorId\":\"143898048\",\"name\":\"B. Lassiter\"}],\"doi\":\"10.1109/ICASSP.1996.543292\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4af23d7c949353919bfe7cf25a8fd80cbe1015db\",\"title\":\"Automatic audio morphing\",\"url\":\"https://www.semanticscholar.org/paper/4af23d7c949353919bfe7cf25a8fd80cbe1015db\",\"venue\":\"1996 IEEE International Conference on Acoustics, Speech, and Signal Processing Conference Proceedings\",\"year\":1996},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143979425\",\"name\":\"F. Xu\"},{\"authorId\":\"1759700\",\"name\":\"Jinxiang Chai\"},{\"authorId\":\"2935689\",\"name\":\"Yilong Liu\"},{\"authorId\":\"49144235\",\"name\":\"X. Tong\"}],\"doi\":\"10.1145/2601097.2601210\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1b08bbf97631d0aeda579ff91f88e162dc1bbc44\",\"title\":\"Controllable high-fidelity facial performance transfer\",\"url\":\"https://www.semanticscholar.org/paper/1b08bbf97631d0aeda579ff91f88e162dc1bbc44\",\"venue\":\"ACM Trans. Graph.\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1899617\",\"name\":\"Wan-Chun Ma\"},{\"authorId\":\"145776381\",\"name\":\"A. Jones\"},{\"authorId\":\"39058402\",\"name\":\"J. Chiang\"},{\"authorId\":\"1684297\",\"name\":\"T. Hawkins\"},{\"authorId\":\"40578921\",\"name\":\"S. Frederiksen\"},{\"authorId\":\"1808270\",\"name\":\"P. Peers\"},{\"authorId\":\"46761813\",\"name\":\"M. Vukovic\"},{\"authorId\":\"1744863\",\"name\":\"M. Ouhyoung\"},{\"authorId\":\"1778676\",\"name\":\"P. Debevec\"}],\"doi\":\"10.1145/1457515.1409074\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ca8ab21e3394b58506a76a4ee78175db7aa28902\",\"title\":\"Facial performance synthesis using deformation-driven polynomial displacement maps\",\"url\":\"https://www.semanticscholar.org/paper/ca8ab21e3394b58506a76a4ee78175db7aa28902\",\"venue\":\"SIGGRAPH Asia '08\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39692235\",\"name\":\"E. Hsu\"},{\"authorId\":\"1704409\",\"name\":\"K. Pulli\"},{\"authorId\":\"145492783\",\"name\":\"J. Popovic\"}],\"doi\":\"10.1145/1186822.1073315\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0399e4998454068e210373c88c99f34a27612d5f\",\"title\":\"Style translation for human motion\",\"url\":\"https://www.semanticscholar.org/paper/0399e4998454068e210373c88c99f34a27612d5f\",\"venue\":\"ACM Trans. Graph.\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"T Ezzat\"},{\"authorId\":null,\"name\":\"G Geiger\"},{\"authorId\":null,\"name\":\"T Poggio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Trainable videorealistic speech animation. TOG (SIGGRAPH)\",\"url\":\"\",\"venue\":\"Trainable videorealistic speech animation. TOG (SIGGRAPH)\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144039941\",\"name\":\"K. Dale\"},{\"authorId\":\"2454127\",\"name\":\"Kalyan Sunkavalli\"},{\"authorId\":\"13594727\",\"name\":\"Micah K. Johnson\"},{\"authorId\":\"1880628\",\"name\":\"D. Vlasic\"},{\"authorId\":\"1752521\",\"name\":\"W. Matusik\"},{\"authorId\":\"143758236\",\"name\":\"H. Pfister\"}],\"doi\":\"10.1145/2024156.2024164\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f326fd805ae74f3773c5eda789aee890b59cc1fb\",\"title\":\"Video face replacement\",\"url\":\"https://www.semanticscholar.org/paper/f326fd805ae74f3773c5eda789aee890b59cc1fb\",\"venue\":\"SA '11\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144565371\",\"name\":\"P. P\\u00e9rez\"},{\"authorId\":\"1752496\",\"name\":\"M. Gangnet\"},{\"authorId\":\"145162067\",\"name\":\"A. Blake\"}],\"doi\":\"10.1145/1201775.882269\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6dbc8145124d338a96ee59bc745f0bbce1f00c76\",\"title\":\"Poisson image editing\",\"url\":\"https://www.semanticscholar.org/paper/6dbc8145124d338a96ee59bc745f0bbce1f00c76\",\"venue\":\"SIGGRAPH '03\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"P P\\u00e9rez\"},{\"authorId\":null,\"name\":\"M Gangnet\"},{\"authorId\":null,\"name\":\"A Blake\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Poisson image editing. TOG (SIGGRAPH)\",\"url\":\"\",\"venue\":\"Poisson image editing. TOG (SIGGRAPH)\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47018987\",\"name\":\"P. Sand\"},{\"authorId\":\"1720894\",\"name\":\"S. Teller\"}],\"doi\":\"10.1145/1186562.1015765\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6723dde31ddd81671d8bd7a9fb309acf0a8f6a0b\",\"title\":\"Video matching\",\"url\":\"https://www.semanticscholar.org/paper/6723dde31ddd81671d8bd7a9fb309acf0a8f6a0b\",\"venue\":\"ACM Trans. Graph.\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10685417\",\"name\":\"M. Hunt\"},{\"authorId\":\"144092947\",\"name\":\"C. Lefebvre\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ca07eebbb3a94fcd58b8cec53926d34515ec0972\",\"title\":\"Distance measures for speech recognition\",\"url\":\"https://www.semanticscholar.org/paper/ca07eebbb3a94fcd58b8cec53926d34515ec0972\",\"venue\":\"\",\"year\":1989},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145086151\",\"name\":\"Carlo Tomasi\"},{\"authorId\":\"1737048\",\"name\":\"R. Manduchi\"}],\"doi\":\"10.1109/ICCV.1998.710815\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bfeaf424a2ea6ca4702d545c6e959e2caeb68e9b\",\"title\":\"Bilateral filtering for gray and color images\",\"url\":\"https://www.semanticscholar.org/paper/bfeaf424a2ea6ca4702d545c6e959e2caeb68e9b\",\"venue\":\"Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)\",\"year\":1998},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2428034\",\"name\":\"C. Bregler\"},{\"authorId\":\"1800748\",\"name\":\"M. Covell\"},{\"authorId\":\"145290352\",\"name\":\"M. Slaney\"}],\"doi\":\"10.1145/258734.258880\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3a78995510cf33edf0ee4265abe23ffdc55986cb\",\"title\":\"Video Rewrite: driving visual speech with audio\",\"url\":\"https://www.semanticscholar.org/paper/3a78995510cf33edf0ee4265abe23ffdc55986cb\",\"venue\":\"SIGGRAPH '97\",\"year\":1997},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2486770\",\"name\":\"T. Beeler\"},{\"authorId\":\"152761038\",\"name\":\"F. Hahn\"},{\"authorId\":\"143929823\",\"name\":\"D. Bradley\"},{\"authorId\":\"3083909\",\"name\":\"B. Bickel\"},{\"authorId\":\"1777539\",\"name\":\"P. Beardsley\"},{\"authorId\":\"1724072\",\"name\":\"C. Gotsman\"},{\"authorId\":\"1693475\",\"name\":\"R. W. Sumner\"},{\"authorId\":\"144877478\",\"name\":\"M. Gross\"}],\"doi\":\"10.1145/2010324.1964970\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"121e4a468b4dc75f62c7d7384bc899a5b3c14460\",\"title\":\"High-quality passive facial performance capture using anchor frames\",\"url\":\"https://www.semanticscholar.org/paper/121e4a468b4dc75f62c7d7384bc899a5b3c14460\",\"venue\":\"SIGGRAPH 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1710872\",\"name\":\"T. Brox\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/TPAMI.2010.143\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ffd97ed7408fa75b86d4c8e4280f8d730ffa2cf0\",\"title\":\"Large Displacement Optical Flow: Descriptor Matching in Variational Motion Estimation\",\"url\":\"https://www.semanticscholar.org/paper/ffd97ed7408fa75b86d4c8e4280f8d730ffa2cf0\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1899617\",\"name\":\"Wan-Chun Ma\"},{\"authorId\":\"1684297\",\"name\":\"T. Hawkins\"},{\"authorId\":\"1808270\",\"name\":\"P. Peers\"},{\"authorId\":\"14373700\",\"name\":\"C. Chabert\"},{\"authorId\":\"40167211\",\"name\":\"M. Weiss\"},{\"authorId\":\"1778676\",\"name\":\"P. Debevec\"}],\"doi\":\"10.2312/EGWR/EGSR07/183-194\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"58cc55a88275cf453239fe1d4f8ca4ff4f7cd47b\",\"title\":\"Rapid Acquisition of Specular and Diffuse Normal Maps from Polarized Spherical Gradient Illumination\",\"url\":\"https://www.semanticscholar.org/paper/58cc55a88275cf453239fe1d4f8ca4ff4f7cd47b\",\"venue\":\"Rendering Techniques\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2875539\",\"name\":\"O. Alexander\"},{\"authorId\":\"145616731\",\"name\":\"M. Rogers\"},{\"authorId\":\"2938800\",\"name\":\"W. Lambeth\"},{\"authorId\":\"39058402\",\"name\":\"J. Chiang\"},{\"authorId\":\"1899617\",\"name\":\"Wan-Chun Ma\"},{\"authorId\":\"3231752\",\"name\":\"Chuan-Chang Wang\"},{\"authorId\":\"1778676\",\"name\":\"P. Debevec\"}],\"doi\":\"10.1109/MCG.2010.65\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f62fc04914c8bde6d67f8138559332939485dba5\",\"title\":\"The Digital Emily Project: Achieving a Photorealistic Digital Actor\",\"url\":\"https://www.semanticscholar.org/paper/f62fc04914c8bde6d67f8138559332939485dba5\",\"venue\":\"IEEE Computer Graphics and Applications\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143904172\",\"name\":\"K. S. Bhat\"},{\"authorId\":\"3298007\",\"name\":\"Rony Goldenthal\"},{\"authorId\":\"40508248\",\"name\":\"Yuting Ye\"},{\"authorId\":\"34969147\",\"name\":\"Ronald Mallet\"},{\"authorId\":\"2324048\",\"name\":\"Michael Koperwas\"}],\"doi\":\"10.1145/2485895.2485915\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0e790f7da09a3540cfbacb7875401bd01d1fe88a\",\"title\":\"High fidelity facial animation capture and retargeting with contours\",\"url\":\"https://www.semanticscholar.org/paper/0e790f7da09a3540cfbacb7875401bd01d1fe88a\",\"venue\":\"SCA '13\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1797649\",\"name\":\"Levi Valgaerts\"},{\"authorId\":\"33846296\",\"name\":\"Chenglei Wu\"},{\"authorId\":\"144031005\",\"name\":\"A. Bruhn\"},{\"authorId\":\"145156858\",\"name\":\"H. Seidel\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"}],\"doi\":\"10.1145/2366145.2366206\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4f8d647ddc09473e9310c461e0a5f5adf908a169\",\"title\":\"Lightweight binocular facial performance capture under uncontrolled lighting\",\"url\":\"https://www.semanticscholar.org/paper/4f8d647ddc09473e9310c461e0a5f5adf908a169\",\"venue\":\"TOGS\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jing Liao\"},{\"authorId\":\"104576341\",\"name\":\"Rodolfo S. Lima\"},{\"authorId\":\"1764421\",\"name\":\"Diego F. Nehab\"},{\"authorId\":\"144201188\",\"name\":\"Hugues Hoppe\"},{\"authorId\":\"145891472\",\"name\":\"Pedro V. Sander\"},{\"authorId\":\"34331831\",\"name\":\"J. Yu\"}],\"doi\":\"10.1145/2629494\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6deccd44d25d8651583cea133d74d4fdff34cb62\",\"title\":\"Automating Image Morphing Using Structural Similarity on a Halfway Domain\",\"url\":\"https://www.semanticscholar.org/paper/6deccd44d25d8651583cea133d74d4fdff34cb62\",\"venue\":\"TOGS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49172741\",\"name\":\"P. Mermelstein\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a086b8bcaf7a3ef2eee498ada4481c33a5e43fcf\",\"title\":\"Distance measures for speech recognition, psychological and instrumental\",\"url\":\"https://www.semanticscholar.org/paper/a086b8bcaf7a3ef2eee498ada4481c33a5e43fcf\",\"venue\":\"\",\"year\":1976},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2486770\",\"name\":\"T. Beeler\"},{\"authorId\":\"152761038\",\"name\":\"F. Hahn\"},{\"authorId\":\"143929823\",\"name\":\"D. Bradley\"},{\"authorId\":\"3083909\",\"name\":\"B. Bickel\"},{\"authorId\":\"1777539\",\"name\":\"P. Beardsley\"},{\"authorId\":\"1724072\",\"name\":\"C. Gotsman\"},{\"authorId\":\"1693475\",\"name\":\"R. W. Sumner\"},{\"authorId\":\"143720818\",\"name\":\"M. Gro\\u00df\"}],\"doi\":\"10.1145/1964921.1964970\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e48437eddcacfbeff01c3edd409369c9637a3357\",\"title\":\"High-quality passive facial performance capture using anchor frames\",\"url\":\"https://www.semanticscholar.org/paper/e48437eddcacfbeff01c3edd409369c9637a3357\",\"venue\":\"SIGGRAPH '11\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39912094\",\"name\":\"P. Garrido\"},{\"authorId\":\"1797649\",\"name\":\"Levi Valgaerts\"},{\"authorId\":\"1401658974\",\"name\":\"Hamid Sarmadi\"},{\"authorId\":\"41178028\",\"name\":\"I. Steiner\"},{\"authorId\":\"13640633\",\"name\":\"K. Varanasi\"},{\"authorId\":\"144565371\",\"name\":\"P. P\\u00e9rez\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"}],\"doi\":\"10.1111/cgf.12552\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8128fb68dc94c086ba213a28ac132e53eb8da02a\",\"title\":\"VDub: Modifying Face Video of Actors for Plausible Visual Alignment to a Dubbed Audio Track\",\"url\":\"https://www.semanticscholar.org/paper/8128fb68dc94c086ba213a28ac132e53eb8da02a\",\"venue\":\"Comput. Graph. Forum\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145649748\",\"name\":\"F. Zhou\"},{\"authorId\":\"143867160\",\"name\":\"F. Torre\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"51cc757cc4ce56385471c21e47d48084d8f8356b\",\"title\":\"Canonical Time Warping for Alignment of Human Behavior\",\"url\":\"https://www.semanticscholar.org/paper/51cc757cc4ce56385471c21e47d48084d8f8356b\",\"venue\":\"NIPS\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1932050\",\"name\":\"T. Ezzat\"}],\"doi\":\"10.1145/566570.566594\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8b989c8d332ce16f35e9edf90a1194373f046fee\",\"title\":\"Trainable videorealistic speech animation\",\"url\":\"https://www.semanticscholar.org/paper/8b989c8d332ce16f35e9edf90a1194373f046fee\",\"venue\":\"Sixth IEEE International Conference on Automatic Face and Gesture Recognition, 2004. Proceedings.\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1706574\",\"name\":\"Hao Li\"},{\"authorId\":\"2977637\",\"name\":\"J. Yu\"},{\"authorId\":\"40508248\",\"name\":\"Yuting Ye\"},{\"authorId\":\"2428034\",\"name\":\"C. Bregler\"}],\"doi\":\"10.1145/2461912.2462019\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eca7098c427567c4d5f4c37872d8f3b7f5427c26\",\"title\":\"Realtime facial animation with on-the-fly correctives\",\"url\":\"https://www.semanticscholar.org/paper/eca7098c427567c4d5f4c37872d8f3b7f5427c26\",\"venue\":\"ACM Trans. Graph.\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35119991\",\"name\":\"Sofien Bouaziz\"},{\"authorId\":\"47906224\",\"name\":\"Yangang Wang\"},{\"authorId\":\"143674021\",\"name\":\"M. Pauly\"}],\"doi\":\"10.1145/2461912.2461976\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"944a54f54b156ffced95c0ea0bb47b35ee1a62d1\",\"title\":\"Online modeling for realtime facial animation\",\"url\":\"https://www.semanticscholar.org/paper/944a54f54b156ffced95c0ea0bb47b35ee1a62d1\",\"venue\":\"ACM Trans. Graph.\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2454127\",\"name\":\"Kalyan Sunkavalli\"},{\"authorId\":\"13594727\",\"name\":\"Micah K. Johnson\"},{\"authorId\":\"1752521\",\"name\":\"W. Matusik\"},{\"authorId\":\"143758236\",\"name\":\"H. Pfister\"}],\"doi\":\"10.1145/1833349.1778862\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10cb8726afafc668884d8f70b08e3e9000584959\",\"title\":\"Multi-scale image harmonization\",\"url\":\"https://www.semanticscholar.org/paper/10cb8726afafc668884d8f70b08e3e9000584959\",\"venue\":\"SIGGRAPH '10\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2161851\",\"name\":\"F. Diego\"},{\"authorId\":\"143941608\",\"name\":\"J. Serrat\"},{\"authorId\":\"3940956\",\"name\":\"A. Pe\\u00f1a\"}],\"doi\":\"10.1109/TMM.2013.2247390\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9c9dbb880225a712c596d4315f83fc0f4ed9495e\",\"title\":\"Joint Spatio-Temporal Alignment of Sequences\",\"url\":\"https://www.semanticscholar.org/paper/9c9dbb880225a712c596d4315f83fc0f4ed9495e\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2842099\",\"name\":\"Floraine Berthouzoz\"},{\"authorId\":\"2812691\",\"name\":\"W. Li\"},{\"authorId\":\"1820412\",\"name\":\"M. Agrawala\"}],\"doi\":\"10.1145/2185520.2185563\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"760007cd0443d9211b8deb31b587e5976d1aa359\",\"title\":\"Tools for placing cuts and transitions in interview video\",\"url\":\"https://www.semanticscholar.org/paper/760007cd0443d9211b8deb31b587e5976d1aa359\",\"venue\":\"TOGS\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36005450\",\"name\":\"Chen Cao\"},{\"authorId\":\"7939453\",\"name\":\"Q. Hou\"},{\"authorId\":\"144078074\",\"name\":\"K. Zhou\"}],\"doi\":\"10.1145/2601097.2601204\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"75ed53365aace52cae1128aacc84b51536fe10ca\",\"title\":\"Displaced dynamic expression regression for real-time facial tracking and animation\",\"url\":\"https://www.semanticscholar.org/paper/75ed53365aace52cae1128aacc84b51536fe10ca\",\"venue\":\"ACM Trans. Graph.\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2095619\",\"name\":\"S. Grofit\"},{\"authorId\":\"3256763\",\"name\":\"Yizhar Lavner\"}],\"doi\":\"10.1109/TASL.2007.909444\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c54787bf1c4e342f328b19a3bbef8c0ba9bb8e55\",\"title\":\"Time-Scale Modification of Audio Signals Using Enhanced WSOLA With Management of Transients\",\"url\":\"https://www.semanticscholar.org/paper/c54787bf1c4e342f328b19a3bbef8c0ba9bb8e55\",\"venue\":\"IEEE Transactions on Audio, Speech, and Language Processing\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1397689071\",\"name\":\"Ira Kemelmacher-Shlizerman\"},{\"authorId\":\"145630386\",\"name\":\"Aditya Sankar\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"1679223\",\"name\":\"S. Seitz\"}],\"doi\":\"10.1007/978-3-642-15549-9_25\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7862f646d640cbf9f88e5ba94a7d642e2a552ec9\",\"title\":\"Being John Malkovich\",\"url\":\"https://www.semanticscholar.org/paper/7862f646d640cbf9f88e5ba94a7d642e2a552ec9\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40019208\",\"name\":\"T. Beier\"},{\"authorId\":\"35176778\",\"name\":\"S. Neely\"}],\"doi\":\"10.1145/133994.134003\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"be73726c6a538bc3ed05e62ba5faec183f777ff6\",\"title\":\"Feature-based image metamorphosis\",\"url\":\"https://www.semanticscholar.org/paper/be73726c6a538bc3ed05e62ba5faec183f777ff6\",\"venue\":\"SIGGRAPH '92\",\"year\":1992},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46319694\",\"name\":\"F. Yang\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"36541522\",\"name\":\"J. Wang\"},{\"authorId\":\"1711560\",\"name\":\"D. Metaxas\"}],\"doi\":\"10.1109/CVPR.2012.6247759\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"53ba88d5d5355d070361d594c68476754099128d\",\"title\":\"Facial expression editing in video using a temporally-smooth factorization\",\"url\":\"https://www.semanticscholar.org/paper/53ba88d5d5355d070361d594c68476754099128d\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3182065\",\"name\":\"Xuehan Xiong\"},{\"authorId\":\"143867160\",\"name\":\"F. Torre\"}],\"doi\":\"10.1109/CVPR.2013.75\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2b942261c49553bba62c340b197cf6ef373fd5a4\",\"title\":\"Supervised Descent Method and Its Applications to Face Alignment\",\"url\":\"https://www.semanticscholar.org/paper/2b942261c49553bba62c340b197cf6ef373fd5a4\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"K Dale\"},{\"authorId\":null,\"name\":\"K Sunkavalli\"},{\"authorId\":null,\"name\":\"M K Johnson\"},{\"authorId\":null,\"name\":\"D Vlasic\"},{\"authorId\":null,\"name\":\"W Matusik\"},{\"authorId\":null,\"name\":\"H Pfister\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Video face replacement. TOG (SIG- GRAPH Asia)\",\"url\":\"\",\"venue\":\"Video face replacement. TOG (SIG- GRAPH Asia)\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145649748\",\"name\":\"F. Zhou\"},{\"authorId\":\"143867160\",\"name\":\"F. Torre\"}],\"doi\":\"10.1109/CVPR.2012.6247812\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7f47bb886e9e68c7febdd8c6663f684cfaaf5915\",\"title\":\"Generalized time warping for multi-modal alignment of human motion\",\"url\":\"https://www.semanticscholar.org/paper/7f47bb886e9e68c7febdd8c6663f684cfaaf5915\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39912094\",\"name\":\"P. Garrido\"},{\"authorId\":\"1797649\",\"name\":\"Levi Valgaerts\"},{\"authorId\":\"33846296\",\"name\":\"Chenglei Wu\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"}],\"doi\":\"10.1145/2508363.2508380\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"976208323fd68f403e3d7c66f66d39f8788fe24c\",\"title\":\"Reconstructing detailed dynamic face geometry from monocular video\",\"url\":\"https://www.semanticscholar.org/paper/976208323fd68f403e3d7c66f66d39f8788fe24c\",\"venue\":\"ACM Trans. Graph.\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144094699\",\"name\":\"T. Rhee\"},{\"authorId\":\"2341249\",\"name\":\"Youngkyoo Hwang\"},{\"authorId\":\"40570319\",\"name\":\"J. Kim\"},{\"authorId\":\"1686725\",\"name\":\"Chang-Yeong Kim\"}],\"doi\":\"10.1145/2019406.2019435\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"40e60bd771c34f6177f1683479337361b43362bf\",\"title\":\"Real-time facial animation from live video tracking\",\"url\":\"https://www.semanticscholar.org/paper/40e60bd771c34f6177f1683479337361b43362bf\",\"venue\":\"SCA '11\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1768641\",\"name\":\"M. Klaudiny\"},{\"authorId\":\"144046599\",\"name\":\"A. Hilton\"}],\"doi\":\"10.1109/3DIMPVT.2012.67\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"04c5469a162b7927a3814fc92b79b8ee732a2e52\",\"title\":\"High-Detail 3D Capture and Non-sequential Alignment of Facial Performance\",\"url\":\"https://www.semanticscholar.org/paper/04c5469a162b7927a3814fc92b79b8ee732a2e52\",\"venue\":\"2012 Second International Conference on 3D Imaging, Modeling, Processing, Visualization & Transmission\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"I Kemelmacher-Shlizerman\"},{\"authorId\":null,\"name\":\"A Sankar\"},{\"authorId\":null,\"name\":\"E Shechtman\"},{\"authorId\":null,\"name\":\"S M Seitz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Being John Malkovich. In ECCV\",\"url\":\"\",\"venue\":\"Being John Malkovich. In ECCV\",\"year\":2010}],\"title\":\"FaceDirector: Continuous Control of Facial Performance in Video\",\"topics\":[{\"topic\":\"Performance\",\"topicId\":\"3097\",\"url\":\"https://www.semanticscholar.org/topic/3097\"},{\"topic\":\"Interpolation\",\"topicId\":\"1131\",\"url\":\"https://www.semanticscholar.org/topic/1131\"},{\"topic\":\"Alpha compositing\",\"topicId\":\"184704\",\"url\":\"https://www.semanticscholar.org/topic/184704\"},{\"topic\":\"Temporal logic\",\"topicId\":\"480\",\"url\":\"https://www.semanticscholar.org/topic/480\"},{\"topic\":\"Nonlinear system\",\"topicId\":\"5329\",\"url\":\"https://www.semanticscholar.org/topic/5329\"},{\"topic\":\"Seamless3d\",\"topicId\":\"4101624\",\"url\":\"https://www.semanticscholar.org/topic/4101624\"},{\"topic\":\"Align (company)\",\"topicId\":\"439709\",\"url\":\"https://www.semanticscholar.org/topic/439709\"},{\"topic\":\"Koch snowflake\",\"topicId\":\"549032\",\"url\":\"https://www.semanticscholar.org/topic/549032\"},{\"topic\":\"Schmidt decomposition\",\"topicId\":\"414294\",\"url\":\"https://www.semanticscholar.org/topic/414294\"},{\"topic\":\"OLGA (technology)\",\"topicId\":\"352116\",\"url\":\"https://www.semanticscholar.org/topic/352116\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Anton (computer)\",\"topicId\":\"214146\",\"url\":\"https://www.semanticscholar.org/topic/214146\"}],\"url\":\"https://www.semanticscholar.org/paper/9b243f4a892925af5c7b30bc3536214404c35bbd\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015}\n"