"{\"abstract\":\"Saliency in Context (SALICON) is an ongoing effort that aims at understanding and predicting visual attention. Conventional saliency models typically rely on low-level image statistics to predict human fixations. While these models perform significantly better than chance, there is still a large gap between model prediction and human behavior. This gap is largely due to the limited capability of models in predicting eye fixations with strong semantic content, the so-called semantic gap. This paper presents a focused study to narrow the semantic gap with an architecture based on Deep Neural Network (DNN). It leverages the representational power of high-level semantics encoded in DNNs pretrained for object recognition. Two key components are fine-tuning the DNNs fully convolutionally with an objective function based on the saliency evaluation metrics, and integrating information at different image scales. We compare our method with 14 saliency models on 6 public eye tracking benchmark datasets. Results demonstrate that our DNNs can automatically learn features particularly for saliency prediction that surpass by a big margin the state-of-the-art. In addition, our model ranks top to date under all seven metrics on the MIT300 challenge set.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"144247007\",\"name\":\"X. Huang\",\"url\":\"https://www.semanticscholar.org/author/144247007\"},{\"authorId\":\"3329744\",\"name\":\"Chengyao Shen\",\"url\":\"https://www.semanticscholar.org/author/3329744\"},{\"authorId\":\"2343486\",\"name\":\"X. Boix\",\"url\":\"https://www.semanticscholar.org/author/2343486\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\",\"url\":\"https://www.semanticscholar.org/author/49033321\"}],\"citationVelocity\":90,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"145378987\",\"name\":\"Yan Luo\"},{\"authorId\":\"144889891\",\"name\":\"M. Jiang\"},{\"authorId\":\"153386875\",\"name\":\"Q. Zhao\"}],\"doi\":\"10.1109/CVPRW.2019.00110\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"3ca3a708d0b2e2b8cb1010c364e89de3c85adfe2\",\"title\":\"Visual Attention in Multi-Label Image Classification\",\"url\":\"https://www.semanticscholar.org/paper/3ca3a708d0b2e2b8cb1010c364e89de3c85adfe2\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145021890\",\"name\":\"N. Liu\"},{\"authorId\":\"7181955\",\"name\":\"J. Han\"},{\"authorId\":\"145251057\",\"name\":\"T. Liu\"},{\"authorId\":\"50080046\",\"name\":\"X. Li\"}],\"doi\":\"10.1109/TNNLS.2016.2628878\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cf18c239a819dc179d4261fdfb39d16f0356b8d3\",\"title\":\"Learning to Predict Eye Fixations via Multiresolution Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/cf18c239a819dc179d4261fdfb39d16f0356b8d3\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2018},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"47ce131f8904027f18eaf8f55fccbcedef351d11\",\"title\":\"The Time Dimension of Visual Attention Models\",\"url\":\"https://www.semanticscholar.org/paper/47ce131f8904027f18eaf8f55fccbcedef351d11\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30024940\",\"name\":\"Qiudan Zhang\"},{\"authorId\":\"72541446\",\"name\":\"Xu Wang\"},{\"authorId\":null,\"name\":\"Shiqi Wang\"},{\"authorId\":\"47320103\",\"name\":\"Shi-kai Li\"},{\"authorId\":\"1687386\",\"name\":\"S. Kwong\"},{\"authorId\":\"145054089\",\"name\":\"J. Jiang\"}],\"doi\":\"10.1109/CVPR.2019.00998\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"273ebb14fc10d578a88a2c6cfea997e1c1b91009\",\"title\":\"Learning to Explore Intrinsic Saliency for Stereoscopic Video\",\"url\":\"https://www.semanticscholar.org/paper/273ebb14fc10d578a88a2c6cfea997e1c1b91009\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145975320\",\"name\":\"A. D. Abreu\"},{\"authorId\":\"2705863\",\"name\":\"C. Ozcinar\"},{\"authorId\":\"118065745\",\"name\":\"A. Smolic\"}],\"doi\":\"10.1109/QoMEX.2017.7965634\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"957fc379cb6ec1f95c7d6202b98c93aa2aaa7265\",\"title\":\"Look around you: Saliency maps for omnidirectional images in VR applications\",\"url\":\"https://www.semanticscholar.org/paper/957fc379cb6ec1f95c7d6202b98c93aa2aaa7265\",\"venue\":\"2017 Ninth International Conference on Quality of Multimedia Experience (QoMEX)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72541446\",\"name\":\"Xu Wang\"},{\"authorId\":\"1390477390\",\"name\":\"Zhenhao Sun\"},{\"authorId\":\"30024940\",\"name\":\"Qiudan Zhang\"},{\"authorId\":\"50313388\",\"name\":\"Y. Fang\"},{\"authorId\":\"152309767\",\"name\":\"L. Ma\"},{\"authorId\":null,\"name\":\"Shiqi Wang\"},{\"authorId\":\"1431724385\",\"name\":\"S. Kwong\"}],\"doi\":\"10.1109/TCSVT.2020.2985427\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"64a6b2773c24291cddbea984fbf2a7c6b1d65a55\",\"title\":\"Multi-Exposure Decomposition-Fusion Model for High Dynamic Range Image Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/64a6b2773c24291cddbea984fbf2a7c6b1d65a55\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50742407\",\"name\":\"Xuebin Qin\"},{\"authorId\":\"5630943\",\"name\":\"Zichen Zhang\"},{\"authorId\":\"50418713\",\"name\":\"Chenyang Huang\"},{\"authorId\":\"144036348\",\"name\":\"C. Gao\"},{\"authorId\":\"145319396\",\"name\":\"M. Dehghan\"},{\"authorId\":\"3160299\",\"name\":\"Martin J\\u00e4gersand\"}],\"doi\":\"10.1109/CVPR.2019.00766\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cebd4ab4ab52be88b26d976aa7d4fb35cc19c2a2\",\"title\":\"BASNet: Boundary-Aware Salient Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/cebd4ab4ab52be88b26d976aa7d4fb35cc19c2a2\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37425637\",\"name\":\"G. Wen\"},{\"authorId\":\"1414183747\",\"name\":\"Brenda Rodriguez-Ni\\u00f1o\"},{\"authorId\":\"15972695\",\"name\":\"Furkan Y. Pecen\"},{\"authorId\":\"40521265\",\"name\":\"D. Vining\"},{\"authorId\":\"67154482\",\"name\":\"N. Garg\"},{\"authorId\":\"8306347\",\"name\":\"M. Markey\"}],\"doi\":\"10.1117/1.JMI.4.2.025503\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f55de2c4a2af1416041fdde3f830cfd1c49ff09f\",\"title\":\"Comparative study of computational visual attention models on two-dimensional medical images\",\"url\":\"https://www.semanticscholar.org/paper/f55de2c4a2af1416041fdde3f830cfd1c49ff09f\",\"venue\":\"Journal of medical imaging\",\"year\":2017},{\"arxivId\":\"1707.03123\",\"authors\":[{\"authorId\":\"22206915\",\"name\":\"Marc Assens\"},{\"authorId\":\"3100480\",\"name\":\"Xavier Giro-i-Nieto\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"}],\"doi\":\"10.1109/ICCVW.2017.275\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"10816358c78a6f7372620e4f59b54ba1c69c2022\",\"title\":\"SaltiNet: Scan-Path Prediction on 360 Degree Images Using Saliency Volumes\",\"url\":\"https://www.semanticscholar.org/paper/10816358c78a6f7372620e4f59b54ba1c69c2022\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":\"1803.01687\",\"authors\":[{\"authorId\":\"23922616\",\"name\":\"Vandit Gajjar\"},{\"authorId\":\"26425477\",\"name\":\"Yash Khandhediya\"},{\"authorId\":\"27343041\",\"name\":\"Ayesha Gurnani\"},{\"authorId\":\"22239413\",\"name\":\"Viraj Mavani\"},{\"authorId\":\"2318791\",\"name\":\"M. S. Raval\"}],\"doi\":\"10.1109/CVPRW.2018.00256\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6ca3fff996c62abd07bd13f36a9d552e91d8ba5b\",\"title\":\"ViS-HuD: Using Visual Saliency to Improve Human Detection with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6ca3fff996c62abd07bd13f36a9d552e91d8ba5b\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50589478\",\"name\":\"Lina Wei\"},{\"authorId\":\"145382023\",\"name\":\"Shanshan Zhao\"},{\"authorId\":\"22273493\",\"name\":\"Omar El Farouk Bourahla\"},{\"authorId\":\"47056905\",\"name\":\"Xi Li\"},{\"authorId\":\"39918420\",\"name\":\"F. Wu\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1109/TIP.2019.2909649\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b3b0e253928c6b8afa3d1005095fc54355a1182c\",\"title\":\"Deep Group-Wise Fully Convolutional Network for Co-Saliency Detection With Graph Propagation\",\"url\":\"https://www.semanticscholar.org/paper/b3b0e253928c6b8afa3d1005095fc54355a1182c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49969564\",\"name\":\"Z. Li\"},{\"authorId\":\"30561276\",\"name\":\"Xiao-yan Zhang\"}],\"doi\":\"10.1109/ICME.2019.00052\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fc346eddd59f861d44ac08d428aae292b37809bc\",\"title\":\"Collaborative Deep Reinforcement Learning for Image Cropping\",\"url\":\"https://www.semanticscholar.org/paper/fc346eddd59f861d44ac08d428aae292b37809bc\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":\"1803.05753\",\"authors\":[{\"authorId\":\"47287647\",\"name\":\"Sen He\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"145071344\",\"name\":\"Yang Mi\"},{\"authorId\":\"3251678\",\"name\":\"N. Pugeault\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4ce33cd6c192f3226d52e59f5f26b2091727780f\",\"title\":\"What Catches the Eye? Visualizing and Understanding Deep Saliency Models\",\"url\":\"https://www.semanticscholar.org/paper/4ce33cd6c192f3226d52e59f5f26b2091727780f\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1909.07953\",\"authors\":[{\"authorId\":\"152932130\",\"name\":\"Lei Shi\"},{\"authorId\":\"117234894\",\"name\":\"Cosmin Copot\"},{\"authorId\":\"152406744\",\"name\":\"S. Vanlanduit\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4fac129fd840dc37a75a7bf396440b5ecc7e7177\",\"title\":\"What Are You Looking at? Detecting Human Intention in Gaze based Human-Robot Interaction\",\"url\":\"https://www.semanticscholar.org/paper/4fac129fd840dc37a75a7bf396440b5ecc7e7177\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47294797\",\"name\":\"Ziheng Zhang\"},{\"authorId\":\"7869872\",\"name\":\"Y. Xu\"},{\"authorId\":\"2152356\",\"name\":\"J. Yu\"},{\"authorId\":\"1702868\",\"name\":\"Shenghua Gao\"}],\"doi\":\"10.1007/978-3-030-01234-2_30\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6887fa749b8719f84aff3ed23b8cef0225583d1b\",\"title\":\"Saliency Detection in 360 ^\\\\circ \\u2218 Videos\",\"url\":\"https://www.semanticscholar.org/paper/6887fa749b8719f84aff3ed23b8cef0225583d1b\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1706.08474\",\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1145/3177745\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f3ccdf54a3384e601fa36969e7b3f657e2516a3b\",\"title\":\"Paying More Attention to Saliency\",\"url\":\"https://www.semanticscholar.org/paper/f3ccdf54a3384e601fa36969e7b3f657e2516a3b\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22631231\",\"name\":\"Dongyu She\"},{\"authorId\":\"1755872\",\"name\":\"Jufeng Yang\"},{\"authorId\":\"37535930\",\"name\":\"Ming-Ming Cheng\"},{\"authorId\":\"144891983\",\"name\":\"Yu-Kun Lai\"},{\"authorId\":\"1734823\",\"name\":\"Paul L. Rosin\"},{\"authorId\":\"144143336\",\"name\":\"Liang Wang\"}],\"doi\":\"10.1109/TMM.2019.2939744\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f9e1ed189a2fef330b07953a6c20e9df01b89fab\",\"title\":\"WSCNet: Weakly Supervised Coupled Networks for Visual Sentiment Classification and Detection\",\"url\":\"https://www.semanticscholar.org/paper/f9e1ed189a2fef330b07953a6c20e9df01b89fab\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47056905\",\"name\":\"Xi Li\"},{\"authorId\":\"46586815\",\"name\":\"Liming Zhao\"},{\"authorId\":\"50589478\",\"name\":\"Lina Wei\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"144894845\",\"name\":\"Fei Wu\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"},{\"authorId\":\"1805398\",\"name\":\"Haibin Ling\"},{\"authorId\":\"1688516\",\"name\":\"Jingdong Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"877628547f227c874d20d28a36d6de11d9dadde2\",\"title\":\"DeepSaliency : MultiTask Deep Neural Network Model for Salient Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/877628547f227c874d20d28a36d6de11d9dadde2\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1476813805\",\"name\":\"M. Al-Naser\"},{\"authorId\":\"29005173\",\"name\":\"S. Siddiqui\"},{\"authorId\":\"151425311\",\"name\":\"Hiroki Ohashi\"},{\"authorId\":\"144723875\",\"name\":\"S. Ahmed\"},{\"authorId\":\"1476817066\",\"name\":\"Nakamura Katsuyki\"},{\"authorId\":\"35920106\",\"name\":\"T. Sato\"},{\"authorId\":\"145279674\",\"name\":\"A. Dengel\"}],\"doi\":\"10.1109/DICTA47822.2019.8945893\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"697f3ccd584b7be126cbea9ced53d5b5e00372f1\",\"title\":\"OGaze: Gaze Prediction in Egocentric Videos for Attentional Object Selection\",\"url\":\"https://www.semanticscholar.org/paper/697f3ccd584b7be126cbea9ced53d5b5e00372f1\",\"venue\":\"2019 Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3185668\",\"name\":\"Haoran Liang\"},{\"authorId\":\"144645142\",\"name\":\"M. Jiang\"},{\"authorId\":\"4487395\",\"name\":\"Ronghua Liang\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1109/SMC.2017.8123171\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ebb90d21b947edd2f1dd1d001b8153f572367520\",\"title\":\"Visual-verbal consistency of image saliency\",\"url\":\"https://www.semanticscholar.org/paper/ebb90d21b947edd2f1dd1d001b8153f572367520\",\"venue\":\"2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2008164304\",\"name\":\"Alberta Ansah\"},{\"authorId\":\"1408451650\",\"name\":\"Caitlin Mills\"},{\"authorId\":\"1718579\",\"name\":\"Orit Shaer\"},{\"authorId\":\"1693270\",\"name\":\"Andrew L. Kun\"}],\"doi\":\"10.1145/3380867.3426209\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"62e26b67e8da6be47a149a6d12e6ed1da1a6f398\",\"title\":\"Towards Computational Identification of Visual Attention on Interactive Tabletops\",\"url\":\"https://www.semanticscholar.org/paper/62e26b67e8da6be47a149a6d12e6ed1da1a6f398\",\"venue\":\"ISS Companion\",\"year\":2020},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"87add2533f4937b5878c66ed3bcc2924aad4fda4\",\"title\":\"Visual Perception Based Assistance for Fundus Image\",\"url\":\"https://www.semanticscholar.org/paper/87add2533f4937b5878c66ed3bcc2924aad4fda4\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1710.03011\",\"authors\":[{\"authorId\":\"7869872\",\"name\":\"Y. Xu\"},{\"authorId\":\"1702868\",\"name\":\"Shenghua Gao\"},{\"authorId\":\"119837762\",\"name\":\"Junru Wu\"},{\"authorId\":\"2317822\",\"name\":\"Nianyi Li\"},{\"authorId\":\"46380769\",\"name\":\"Jingyi Yu\"}],\"doi\":\"10.1109/TPAMI.2018.2866563\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4f3ca89c6c7cdf359c621870c8f71a4251cecc1b\",\"title\":\"Personalized Saliency and Its Prediction\",\"url\":\"https://www.semanticscholar.org/paper/4f3ca89c6c7cdf359c621870c8f71a4251cecc1b\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":\"1508.05038\",\"authors\":[{\"authorId\":\"67100504\",\"name\":\"C. Thomas\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":\"10.1109/CVPR.2016.380\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2e5fadbaab27af0c2b5cc6a3481c11b2b83c4f94\",\"title\":\"Seeing Behind the Camera: Identifying the Authorship of a Photograph\",\"url\":\"https://www.semanticscholar.org/paper/2e5fadbaab27af0c2b5cc6a3481c11b2b83c4f94\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2418491\",\"name\":\"M. Zhang\"},{\"authorId\":\"1397677751\",\"name\":\"Keng Teck Ma\"},{\"authorId\":\"9183286\",\"name\":\"Joo-Hwee Lim\"},{\"authorId\":\"153386875\",\"name\":\"Q. Zhao\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":\"10.1109/TPAMI.2018.2871688\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"2f04a3d8eacfa22a299e0c5a7edcc69d0fdd5933\",\"title\":\"Anticipating Where People will Look Using Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/2f04a3d8eacfa22a299e0c5a7edcc69d0fdd5933\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":\"1710.10755\",\"authors\":[{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"3383051\",\"name\":\"Yuhang Song\"},{\"authorId\":\"49606288\",\"name\":\"Jianyi Wang\"},{\"authorId\":\"27647516\",\"name\":\"Minglang Qiao\"},{\"authorId\":\"27661057\",\"name\":\"Liangyu Huo\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"}],\"doi\":\"10.1109/TPAMI.2018.2858783\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"27bf4a794a535994e43c2eb41b81b6795bcddfd0\",\"title\":\"Predicting Head Movement in Panoramic Video: A Deep Reinforcement Learning Approach\",\"url\":\"https://www.semanticscholar.org/paper/27bf4a794a535994e43c2eb41b81b6795bcddfd0\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5021307\",\"name\":\"Vincent Sitzmann\"},{\"authorId\":\"143772343\",\"name\":\"Ana Serrano\"},{\"authorId\":\"48453720\",\"name\":\"A. Pavel\"},{\"authorId\":\"1820412\",\"name\":\"M. Agrawala\"},{\"authorId\":\"143876232\",\"name\":\"D. Gutierrez\"},{\"authorId\":\"1731170\",\"name\":\"G. Wetzstein\"}],\"doi\":\"10.1109/TVCG.2018.2793599\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c3d382d1aad38e7e1a9249a7bd323f9a5cf92ca8\",\"title\":\"Saliency in VR: How Do People Explore Virtual Environments?\",\"url\":\"https://www.semanticscholar.org/paper/c3d382d1aad38e7e1a9249a7bd323f9a5cf92ca8\",\"venue\":\"IEEE Transactions on Visualization and Computer Graphics\",\"year\":2018},{\"arxivId\":\"1904.11276\",\"authors\":[{\"authorId\":\"37634267\",\"name\":\"A. Davy\"},{\"authorId\":\"40142302\",\"name\":\"T. Ehret\"},{\"authorId\":\"27053481\",\"name\":\"J. Morel\"},{\"authorId\":\"2346590\",\"name\":\"M. Delbracio\"}],\"doi\":\"10.1109/ICIP.2018.8451059\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8fd0e087b07a0551611bf9f9d8b93cfb7f823653\",\"title\":\"Reducing Anomaly Detection in Images to Detection in Noise\",\"url\":\"https://www.semanticscholar.org/paper/8fd0e087b07a0551611bf9f9d8b93cfb7f823653\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":\"1904.03571\",\"authors\":[{\"authorId\":\"144545126\",\"name\":\"S. Yang\"},{\"authorId\":\"2604251\",\"name\":\"Guosheng Lin\"},{\"authorId\":\"3318404\",\"name\":\"Qiuping Jiang\"},{\"authorId\":\"144968898\",\"name\":\"W. Lin\"}],\"doi\":\"10.1109/TMM.2019.2947352\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"023b11c04e5ea605fe999b015cbf62502cab068b\",\"title\":\"A Dilated Inception Network for Visual Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/023b11c04e5ea605fe999b015cbf62502cab068b\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2212080\",\"name\":\"Yifan Cai\"},{\"authorId\":\"37050393\",\"name\":\"Harshita Sharma\"},{\"authorId\":\"47728776\",\"name\":\"P. Chatelain\"},{\"authorId\":\"144870105\",\"name\":\"J. Noble\"}],\"doi\":\"10.1007/978-3-030-00928-1_98\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6fb7097cc37f717b1d267ec86f279e77c9d5cfe6\",\"title\":\"Multi-task SonoEyeNet: Detection of Fetal Standardized Planes Assisted by Generated Sonographer Attention Maps\",\"url\":\"https://www.semanticscholar.org/paper/6fb7097cc37f717b1d267ec86f279e77c9d5cfe6\",\"venue\":\"MICCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6271074\",\"name\":\"Kirsten A Dalrymple\"},{\"authorId\":\"144645142\",\"name\":\"M. Jiang\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"},{\"authorId\":\"3048594\",\"name\":\"J. Elison\"}],\"doi\":\"10.1038/s41598-019-42764-z\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5920514d8807b434fed19cb938c9a434b6979265\",\"title\":\"Machine learning accurately classifies age of toddlers based on eye tracking\",\"url\":\"https://www.semanticscholar.org/paper/5920514d8807b434fed19cb938c9a434b6979265\",\"venue\":\"Scientific Reports\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2007882802\",\"name\":\"Matthias Tangemann\"},{\"authorId\":\"2997408\",\"name\":\"Matthias K\\u00fcmmerer\"},{\"authorId\":\"49737748\",\"name\":\"Thomas S. A. Wallis\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":\"10.1007/978-3-030-58604-1_40\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d7fcbd3d09a3029c3912b7c222c188bcba79920b\",\"title\":\"Measuring the Importance of Temporal Features in Video Saliency\",\"url\":\"https://www.semanticscholar.org/paper/d7fcbd3d09a3029c3912b7c222c188bcba79920b\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143865718\",\"name\":\"Vittorio Ferrari\"},{\"authorId\":\"145670946\",\"name\":\"Martial Hebert\"},{\"authorId\":\"1781120\",\"name\":\"Cristian Sminchisescu\"},{\"authorId\":\"30400079\",\"name\":\"Yair Weiss\"}],\"doi\":\"10.1007/978-3-030-01264-9\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5e47ada58f5b7817acc46240f1090ba51dd0c637\",\"title\":\"Computer Vision \\u2013 ECCV 2018\",\"url\":\"https://www.semanticscholar.org/paper/5e47ada58f5b7817acc46240f1090ba51dd0c637\",\"venue\":\"Lecture Notes in Computer Science\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1805367\",\"name\":\"Sen Jia\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3ba81addcc50e8b4a0bad42fa84b6fe26a9b8a6f\",\"title\":\"EML-NET : An Expandable Multi-Layer NETwork for Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/3ba81addcc50e8b4a0bad42fa84b6fe26a9b8a6f\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52164159\",\"name\":\"Yuya Moroto\"},{\"authorId\":\"47761580\",\"name\":\"K. Maeda\"},{\"authorId\":\"5057217\",\"name\":\"Takahiro Ogawa\"},{\"authorId\":\"144029207\",\"name\":\"M. Haseyama\"}],\"doi\":\"10.1109/LifeTech.2019.8883990\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"122960d36c9536216c40749c868a26a1ef97e116\",\"title\":\"Estimation of Visual Attention via Canonical Correlation between Visual and Gaze-based Features\",\"url\":\"https://www.semanticscholar.org/paper/122960d36c9536216c40749c868a26a1ef97e116\",\"venue\":\"2019 IEEE 1st Global Conference on Life Sciences and Technologies (LifeTech)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6654149\",\"name\":\"Z. Nan\"},{\"authorId\":\"1844358\",\"name\":\"Tianmin Shu\"},{\"authorId\":\"48096046\",\"name\":\"R. Gong\"},{\"authorId\":\"40108354\",\"name\":\"Shu Wang\"},{\"authorId\":\"145708711\",\"name\":\"Ping Wei\"},{\"authorId\":\"12554898\",\"name\":\"S. Zhu\"},{\"authorId\":\"153873673\",\"name\":\"N. Zheng\"}],\"doi\":\"10.1016/j.patcog.2020.107314\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e66370aec2ccef6e2d063eb21504f4b1f51681f8\",\"title\":\"Learning to infer human attention in daily activities\",\"url\":\"https://www.semanticscholar.org/paper/e66370aec2ccef6e2d063eb21504f4b1f51681f8\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1951233\",\"name\":\"Patrik Polatsek\"},{\"authorId\":\"40351264\",\"name\":\"M. Waldner\"},{\"authorId\":\"1736888\",\"name\":\"I. Viola\"},{\"authorId\":\"3059024\",\"name\":\"P. Kapec\"},{\"authorId\":\"2678977\",\"name\":\"W. Benesova\"}],\"doi\":\"10.1016/j.cag.2018.01.010\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b4bd14734b58cfb788755201b46bb61394773b57\",\"title\":\"Exploring visual attention and saliency modeling for task-based visual analysis\",\"url\":\"https://www.semanticscholar.org/paper/b4bd14734b58cfb788755201b46bb61394773b57\",\"venue\":\"Comput. Graph.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33719665\",\"name\":\"Saulo A. F. Oliveira\"},{\"authorId\":\"2269331\",\"name\":\"A. R. Neto\"},{\"authorId\":\"144227442\",\"name\":\"J. Gomes\"}],\"doi\":\"10.1109/BRACIS.2016.077\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4be46e79aa958b2fde0948488084c48cb8a9b6c6\",\"title\":\"Towards Fixation Prediction: A Nonparametric Estimation-Based Approach through Key-Points\",\"url\":\"https://www.semanticscholar.org/paper/4be46e79aa958b2fde0948488084c48cb8a9b6c6\",\"venue\":\"2016 5th Brazilian Conference on Intelligent Systems (BRACIS)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46700619\",\"name\":\"Jing Liu\"},{\"authorId\":\"3493187\",\"name\":\"Jincheng Lv\"},{\"authorId\":\"2026992233\",\"name\":\"Min Yuan\"},{\"authorId\":\"50560979\",\"name\":\"J. Zhang\"},{\"authorId\":\"153011269\",\"name\":\"Yuting Su\"}],\"doi\":\"10.1109/LSP.2020.3035065\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1a469d135239fe0e6ac9105a8a1068c9d694dc64\",\"title\":\"ABSNet: Aesthetics-Based Saliency Network Using Multi-Task Convolutional Network\",\"url\":\"https://www.semanticscholar.org/paper/1a469d135239fe0e6ac9105a8a1068c9d694dc64\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67321830\",\"name\":\"Weijie Wei\"},{\"authorId\":\"49292977\",\"name\":\"Z. Liu\"},{\"authorId\":\"47033364\",\"name\":\"Lijin Huang\"},{\"authorId\":\"1395583740\",\"name\":\"Alexis Nebout\"},{\"authorId\":\"1789744\",\"name\":\"O. Meur\"}],\"doi\":\"10.1109/ICMEW.2019.00119\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"38a01116545b7621d0e3223e8bce1a6533976b22\",\"title\":\"Saliency Prediction via Multi-Level Features and Deep Supervision for Children with Autism Spectrum Disorder\",\"url\":\"https://www.semanticscholar.org/paper/38a01116545b7621d0e3223e8bce1a6533976b22\",\"venue\":\"2019 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2019},{\"arxivId\":\"1908.05786\",\"authors\":[{\"authorId\":\"41018180\",\"name\":\"Kyle Min\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1109/ICCV.2019.00248\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5b93aaf71e4c18d304ab9b3e77598cb0423d0952\",\"title\":\"TASED-Net: Temporally-Aggregating Spatial Encoder-Decoder Network for Video Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/5b93aaf71e4c18d304ab9b3e77598cb0423d0952\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1605.01101\",\"authors\":[{\"authorId\":\"3250505\",\"name\":\"Avisek Lahiri\"},{\"authorId\":\"2177805\",\"name\":\"S. Roy\"},{\"authorId\":\"1915908\",\"name\":\"Anirban Santara\"},{\"authorId\":\"144240262\",\"name\":\"P. Mitra\"},{\"authorId\":\"1758797\",\"name\":\"P. Biswas\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"c73f015ab7c90f4cc97efad29c27361cec87d351\",\"title\":\"WEPSAM: Weakly Pre-Learnt Saliency Model\",\"url\":\"https://www.semanticscholar.org/paper/c73f015ab7c90f4cc97efad29c27361cec87d351\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1902.06634\",\"authors\":[{\"authorId\":\"144373348\",\"name\":\"A. Kroner\"},{\"authorId\":\"2581474\",\"name\":\"Mario Senden\"},{\"authorId\":\"1695114\",\"name\":\"K. Driessens\"},{\"authorId\":\"145960031\",\"name\":\"R. Goebel\"}],\"doi\":\"10.1016/j.neunet.2020.05.004\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4fa6aac2143c713561603083a5f953c395ba2131\",\"title\":\"Contextual Encoder-Decoder Network for Visual Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/4fa6aac2143c713561603083a5f953c395ba2131\",\"venue\":\"Neural Networks\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"46887280\",\"name\":\"Giuseppe Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"49859d84cd3884d7bc61b5049222e454c46ff8ac\",\"title\":\"Attentive ConvLSTM Learned Priors ( x 2 ) \\u03bc , \\u03c3\\u03bc , \\u03c3\\u03bc , \\u03c3 Dilated Convolutional Network Input Image Saliency\",\"url\":\"https://www.semanticscholar.org/paper/49859d84cd3884d7bc61b5049222e454c46ff8ac\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145829312\",\"name\":\"Ke Yan\"},{\"authorId\":null,\"name\":\"Yaowei Wang\"},{\"authorId\":\"49487364\",\"name\":\"D. Liang\"},{\"authorId\":\"50592933\",\"name\":\"Tiejun Huang\"},{\"authorId\":\"40161651\",\"name\":\"Yonghong Tian\"}],\"doi\":\"10.1145/2964284.2967252\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4b30c2431b8a27a8480d43996f7bb550e73fb268\",\"title\":\"CNN vs. SIFT for Image Retrieval: Alternative or Complementary?\",\"url\":\"https://www.semanticscholar.org/paper/4b30c2431b8a27a8480d43996f7bb550e73fb268\",\"venue\":\"ACM Multimedia\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27343041\",\"name\":\"Ayesha Gurnani\"},{\"authorId\":\"23922616\",\"name\":\"Vandit Gajjar\"},{\"authorId\":\"22239413\",\"name\":\"Viraj Mavani\"},{\"authorId\":\"26425477\",\"name\":\"Yash Khandhediya\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0435a34e93b8dda459de49b499dd71dbb478dc18\",\"title\":\"VEGAC: Visual Saliency-based Age, Gender, and Facial Expression Classification Using Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/0435a34e93b8dda459de49b499dd71dbb478dc18\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"2509726\",\"name\":\"Xingping Dong\"},{\"authorId\":\"51004202\",\"name\":\"A. Borji\"},{\"authorId\":\"38958903\",\"name\":\"Ruigang Yang\"}],\"doi\":\"10.1109/TPAMI.2019.2905607\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"39e79c92a0a7653ee4177c6b94eee4368f6ca4b0\",\"title\":\"Inferring Salient Objects from Human Fixations\",\"url\":\"https://www.semanticscholar.org/paper/39e79c92a0a7653ee4177c6b94eee4368f6ca4b0\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"50085218\",\"name\":\"Xiankai Lu\"},{\"authorId\":\"1741126\",\"name\":\"S. Hoi\"},{\"authorId\":\"29116642\",\"name\":\"H. Ling\"}],\"doi\":\"10.1109/tpami.2020.2966453\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d68898ef2835de010154711291d7d457b2ac6c18\",\"title\":\"Paying Attention to Video Object Pattern Understanding.\",\"url\":\"https://www.semanticscholar.org/paper/d68898ef2835de010154711291d7d457b2ac6c18\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"1905.00161\",\"authors\":[{\"authorId\":\"49235564\",\"name\":\"M. Xu\"},{\"authorId\":\"32462959\",\"name\":\"Chen Li\"},{\"authorId\":\"15661018\",\"name\":\"Shanyi Zhang\"},{\"authorId\":\"1776651\",\"name\":\"P. Callet\"}],\"doi\":\"10.1109/JSTSP.2020.2966864\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"42251c77e93610b753afd6b520bc36d5b1f0f33d\",\"title\":\"State-of-the-Art in 360\\u00b0 Video/Image Processing: Perception, Assessment and Compression\",\"url\":\"https://www.semanticscholar.org/paper/42251c77e93610b753afd6b520bc36d5b1f0f33d\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020},{\"arxivId\":\"1912.12148\",\"authors\":[{\"authorId\":\"47469967\",\"name\":\"Jianwu Fang\"},{\"authorId\":\"117426689\",\"name\":\"Dingxin Yan\"},{\"authorId\":\"51198614\",\"name\":\"J. Qiao\"},{\"authorId\":\"40689776\",\"name\":\"J. Xue\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"39b6dd39873c4508953cdb45588b4013a5fc21a6\",\"title\":\"DADA: A Large-scale Benchmark and Model for Driver Attention Prediction in Accidental Scenarios\",\"url\":\"https://www.semanticscholar.org/paper/39b6dd39873c4508953cdb45588b4013a5fc21a6\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145586319\",\"name\":\"A. Nguyen\"},{\"authorId\":\"2656592\",\"name\":\"Zhisheng Yan\"},{\"authorId\":\"1688353\",\"name\":\"K. Nahrstedt\"}],\"doi\":\"10.1145/3240508.3240669\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"79f1bd70cc474b02bafd5c89063aff204f43959c\",\"title\":\"Your Attention is Unique: Detecting 360-Degree Video Saliency in Head-Mounted Display for Head Movement Prediction\",\"url\":\"https://www.semanticscholar.org/paper/79f1bd70cc474b02bafd5c89063aff204f43959c\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10604706\",\"name\":\"Ali Selman Aydin\"},{\"authorId\":\"113653487\",\"name\":\"Shirin Feiz\"},{\"authorId\":\"145070406\",\"name\":\"V. Ashok\"},{\"authorId\":\"1519965383\",\"name\":\"I. Ramakrishnan\"}],\"doi\":\"10.1145/3377325.3377494\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b581597fe0576ebc88a0aade41cbf1366a33ecb8\",\"title\":\"Towards making videos accessible for low vision screen magnifier users\",\"url\":\"https://www.semanticscholar.org/paper/b581597fe0576ebc88a0aade41cbf1366a33ecb8\",\"venue\":\"IUI\",\"year\":2020},{\"arxivId\":\"2010.01220\",\"authors\":[{\"authorId\":\"1986291097\",\"name\":\"Giovanni Bellitto\"},{\"authorId\":\"1985894550\",\"name\":\"Federica Proietto Salanitri\"},{\"authorId\":\"1409705906\",\"name\":\"S. Palazzo\"},{\"authorId\":\"50528328\",\"name\":\"F. Rundo\"},{\"authorId\":\"35906202\",\"name\":\"D. Giordano\"},{\"authorId\":\"2441118\",\"name\":\"C. Spampinato\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"36081963c58871adc8706e2cfcbf94872a42c5ae\",\"title\":\"Video Saliency Detection with Domain Adaptation using Hierarchical Gradient Reversal Layers\",\"url\":\"https://www.semanticscholar.org/paper/36081963c58871adc8706e2cfcbf94872a42c5ae\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.10600\",\"authors\":[{\"authorId\":\"1582477446\",\"name\":\"Yasser Abdelaziz Dahou Djilali\"},{\"authorId\":\"2028199013\",\"name\":\"Marouane Tliba\"},{\"authorId\":\"123746715\",\"name\":\"K. McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"39ebe1ff6f4087119fa9c70ff981f31b60613452\",\"title\":\"ATSal: An Attention Based Architecture for Saliency Prediction in 360 Videos\",\"url\":\"https://www.semanticscholar.org/paper/39ebe1ff6f4087119fa9c70ff981f31b60613452\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"47420847\",\"name\":\"Lai Jiang\"},{\"authorId\":\"3238659\",\"name\":\"Zhaoting Ye\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"}],\"doi\":\"10.1016/j.patcog.2016.05.023\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c94b00fc7731fcab82d7babeaf8127edbe88360a\",\"title\":\"Bottom-up saliency detection with sparse representation of learnt texture atoms\",\"url\":\"https://www.semanticscholar.org/paper/c94b00fc7731fcab82d7babeaf8127edbe88360a\",\"venue\":\"Pattern Recognit.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410886873\",\"name\":\"Thomas P O'Connell\"},{\"authorId\":\"3286262\",\"name\":\"M. Chun\"}],\"doi\":\"10.2139/SSRN.3155608\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2f5669af8ac4fe30fd0bd5ffb7239ae26576fc71\",\"title\":\"Predicting Eye Movements from Deep Neural Network Activity Decoded from fMRI Responses to Natural Scenes\",\"url\":\"https://www.semanticscholar.org/paper/2f5669af8ac4fe30fd0bd5ffb7239ae26576fc71\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1810.10974\",\"authors\":[{\"authorId\":\"37759796\",\"name\":\"S. Palazzo\"},{\"authorId\":\"2441118\",\"name\":\"C. Spampinato\"},{\"authorId\":\"2912641\",\"name\":\"I. Kavasidis\"},{\"authorId\":\"144027622\",\"name\":\"D. Giordano\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/tpami.2020.2995909\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0232f39cf09a47982c24e311a7424f466f964b22\",\"title\":\"Decoding Brain Representations by Multimodal Learning of Neural Activity and Visual Features\",\"url\":\"https://www.semanticscholar.org/paper/0232f39cf09a47982c24e311a7424f466f964b22\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"1606.00110\",\"authors\":[{\"authorId\":\"51285293\",\"name\":\"Christopher Thomas\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"36541e5dcc7964f80bd622e6212fa5808730fe95\",\"title\":\"OpenSalicon: An Open Source Implementation of the Salicon Saliency Model\",\"url\":\"https://www.semanticscholar.org/paper/36541e5dcc7964f80bd622e6212fa5808730fe95\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51362310\",\"name\":\"Lin Guo\"},{\"authorId\":\"1793858\",\"name\":\"Shiyin Qin\"}],\"doi\":\"10.3390/sym11010005\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ea85d2b73d04dc653e3a246031bc739bd5a9c7e4\",\"title\":\"High Precision Detection of Salient Objects Based on Deep Convolutional Networks with Proper Combinations of Shallow and Deep Connections\",\"url\":\"https://www.semanticscholar.org/paper/ea85d2b73d04dc653e3a246031bc739bd5a9c7e4\",\"venue\":\"Symmetry\",\"year\":2019},{\"arxivId\":\"1912.12027\",\"authors\":[{\"authorId\":\"90816540\",\"name\":\"F. Mostafaie\"},{\"authorId\":\"9142083\",\"name\":\"Zahra Nabizadeh\"},{\"authorId\":\"66935672\",\"name\":\"N. Karimi\"},{\"authorId\":\"143837075\",\"name\":\"S. Samavi\"}],\"doi\":\"10.1109/MVIP49855.2020.9116881\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1e7718924722cb35c251cbdb630cc18932edd087\",\"title\":\"A General Framework for Saliency Detection Methods\",\"url\":\"https://www.semanticscholar.org/paper/1e7718924722cb35c251cbdb630cc18932edd087\",\"venue\":\"2020 International Conference on Machine Vision and Image Processing (MVIP)\",\"year\":2020},{\"arxivId\":\"2001.03063\",\"authors\":[{\"authorId\":\"3200442\",\"name\":\"A. Tsiami\"},{\"authorId\":\"2539459\",\"name\":\"Petros Koutras\"},{\"authorId\":\"1750686\",\"name\":\"P. Maragos\"}],\"doi\":\"10.1109/cvpr42600.2020.00482\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e296a1f529d9caa125e8c6a56cac61423e04b41b\",\"title\":\"STAViS: Spatio-Temporal AudioVisual Saliency Network\",\"url\":\"https://www.semanticscholar.org/paper/e296a1f529d9caa125e8c6a56cac61423e04b41b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1811.07480\",\"authors\":[{\"authorId\":\"50251712\",\"name\":\"Ziqi Zhou\"},{\"authorId\":\"40514580\",\"name\":\"Z. Wang\"},{\"authorId\":\"1790976\",\"name\":\"H. Lu\"},{\"authorId\":\"47673404\",\"name\":\"S. Wang\"},{\"authorId\":\"2736861\",\"name\":\"M. Sun\"}],\"doi\":\"10.1016/j.patcog.2020.107275\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b7de478275fdc5e154f6d904b910e8d291033edd\",\"title\":\"Global and Local Sensitivity Guided Key Salient Object Re-augmentation for Video Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/b7de478275fdc5e154f6d904b910e8d291033edd\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46237872\",\"name\":\"Issei Mochizuki\"},{\"authorId\":\"2343461\",\"name\":\"Masahiro Toyoura\"},{\"authorId\":\"2084839\",\"name\":\"X. Mao\"}],\"doi\":\"10.1007/s00371-018-1518-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bcc10f963d4816cbb3dd8e77b8135d8869ef6ba3\",\"title\":\"Visual attention prediction for images with leading line structure\",\"url\":\"https://www.semanticscholar.org/paper/bcc10f963d4816cbb3dd8e77b8135d8869ef6ba3\",\"venue\":\"The Visual Computer\",\"year\":2018},{\"arxivId\":\"1702.00372\",\"authors\":[{\"authorId\":\"143635238\",\"name\":\"Samuel F. Dodge\"},{\"authorId\":\"47209857\",\"name\":\"Lina Karam\"}],\"doi\":\"10.1109/TIP.2018.2834826\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2fc290cec880b22ca61544eca84157821ea7b0c6\",\"title\":\"Visual Saliency Prediction Using a Mixture of Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/2fc290cec880b22ca61544eca84157821ea7b0c6\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":\"1809.04226\",\"authors\":[{\"authorId\":\"47641027\",\"name\":\"Z. Deng\"},{\"authorId\":\"101372834\",\"name\":\"G. Gao\"},{\"authorId\":\"1800953\",\"name\":\"S. Frintrop\"},{\"authorId\":\"50562323\",\"name\":\"J. Zhang\"}],\"doi\":\"10.3389/fnbot.2019.00060\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bc632becec9941ac8577d7cc380d2235940a657a\",\"title\":\"Attention Based Visual Analysis for Fast Grasp Planning With a Multi-Fingered Robotic Hand\",\"url\":\"https://www.semanticscholar.org/paper/bc632becec9941ac8577d7cc380d2235940a657a\",\"venue\":\"Front. Neurorobot.\",\"year\":2019},{\"arxivId\":\"1905.07984\",\"authors\":[{\"authorId\":\"144656873\",\"name\":\"O. Sidorov\"},{\"authorId\":\"3276066\",\"name\":\"M. Pedersen\"},{\"authorId\":\"2201320\",\"name\":\"N. W. Kim\"},{\"authorId\":\"35223379\",\"name\":\"Sumit Shekhar\"}],\"doi\":\"10.1145/3334480.3382980\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"995268b5ed1b688bc801337034e492cc49cff927\",\"title\":\"Are All the Frames Equally Important?\",\"url\":\"https://www.semanticscholar.org/paper/995268b5ed1b688bc801337034e492cc49cff927\",\"venue\":\"CHI Extended Abstracts\",\"year\":2020},{\"arxivId\":\"1812.01802\",\"authors\":[{\"authorId\":\"143775710\",\"name\":\"S. Pal\"},{\"authorId\":\"4211203\",\"name\":\"T. Mohandoss\"},{\"authorId\":\"144240262\",\"name\":\"P. Mitra\"}],\"doi\":\"10.1117/12.2522915\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a0faa94ed3b14e56cf3c3dd0eeb71a381e028c81\",\"title\":\"Visual attention for behavioral cloning in autonomous driving\",\"url\":\"https://www.semanticscholar.org/paper/a0faa94ed3b14e56cf3c3dd0eeb71a381e028c81\",\"venue\":\"International Conference on Machine Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3185668\",\"name\":\"Haoran Liang\"},{\"authorId\":\"144645142\",\"name\":\"M. Jiang\"},{\"authorId\":\"4487395\",\"name\":\"Ronghua Liang\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1109/SMC.2017.8123170\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2b5e96889b823fa421278b9824913969d28dc2c6\",\"title\":\"Saliency prediction with scene structural guidance\",\"url\":\"https://www.semanticscholar.org/paper/2b5e96889b823fa421278b9824913969d28dc2c6\",\"venue\":\"2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47295036\",\"name\":\"Zehua Zhang\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"},{\"authorId\":\"145864858\",\"name\":\"Chen Yu\"},{\"authorId\":\"2798750\",\"name\":\"Sven Bambach\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5a089bc28160fa236f219c6760b6a48c9b8d3d10\",\"title\":\"From Coarse Attention to Fine-Grained Gaze: A Two-stage 3D Fully Convolutional Network for Predicting Eye Gaze in First Person Video\",\"url\":\"https://www.semanticscholar.org/paper/5a089bc28160fa236f219c6760b6a48c9b8d3d10\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"},{\"authorId\":\"2470219\",\"name\":\"E. Sayrol\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"da951412f75aac6cffb310656770552548a11798\",\"title\":\"SalGAN : Visual Saliency Prediction with Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/da951412f75aac6cffb310656770552548a11798\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"2003.13987\",\"authors\":[{\"authorId\":\"32372088\",\"name\":\"Nora Castner\"},{\"authorId\":\"3175376\",\"name\":\"T. K\\u00fcbler\"},{\"authorId\":\"144573050\",\"name\":\"Katharina Scheiter\"},{\"authorId\":\"48974795\",\"name\":\"Juliane Richter\"},{\"authorId\":\"115823623\",\"name\":\"T. Eder\"},{\"authorId\":\"39386916\",\"name\":\"F. Huettig\"},{\"authorId\":\"11690969\",\"name\":\"C. Keutel\"},{\"authorId\":\"48960757\",\"name\":\"Enkelejda Kasneci\"}],\"doi\":\"10.1145/3379155.3391320\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"7e999f9dc3d4dd8fafd4356fac243892d151143b\",\"title\":\"Deep semantic gaze embedding and scanpath comparison for expertise classification during OPT viewing\",\"url\":\"https://www.semanticscholar.org/paper/7e999f9dc3d4dd8fafd4356fac243892d151143b\",\"venue\":\"ETRA\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1409985550\",\"name\":\"Linardos Panagiotis\"},{\"authorId\":\"2890278\",\"name\":\"Eva Mohedano\"},{\"authorId\":\"51245064\",\"name\":\"M. Cherto\"},{\"authorId\":\"1737981\",\"name\":\"C. Gurrin\"},{\"authorId\":\"1398090762\",\"name\":\"Xavier Gir\\u00f3-i-Nieto\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1b02efcd0b2c26c9e68b3807d7e958af763b56ab\",\"title\":\"The impact of temporal regularisation in egocentric saliency prediction\",\"url\":\"https://www.semanticscholar.org/paper/1b02efcd0b2c26c9e68b3807d7e958af763b56ab\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"47957770\",\"name\":\"Xuying Zhang\"},{\"authorId\":\"40626740\",\"name\":\"Liujuan Cao\"},{\"authorId\":\"47096329\",\"name\":\"Yongjian Wu\"},{\"authorId\":\"1835006\",\"name\":\"Feiyue Huang\"},{\"authorId\":\"1572139630\",\"name\":\"Rongrong Ji\"}],\"doi\":\"10.1145/3394171.3414008\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c19f8380410181249fdca70ec14f6b5f38ae0846\",\"title\":\"Exploring Language Prior for Mode-Sensitive Visual Attention Modeling\",\"url\":\"https://www.semanticscholar.org/paper/c19f8380410181249fdca70ec14f6b5f38ae0846\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11288506\",\"name\":\"Jiaxiao Wu\"},{\"authorId\":\"1922280\",\"name\":\"Olga Veksler\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"12a667874046307412076f47ce3bf6bacc2f7ede\",\"title\":\"Learning Regularization Weight for CRF Optimization\",\"url\":\"https://www.semanticscholar.org/paper/12a667874046307412076f47ce3bf6bacc2f7ede\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3461088\",\"name\":\"L. Wang\"},{\"authorId\":\"145131953\",\"name\":\"L. Wang\"},{\"authorId\":\"1790976\",\"name\":\"H. Lu\"},{\"authorId\":\"48754192\",\"name\":\"Pingping Zhang\"},{\"authorId\":\"144526777\",\"name\":\"X. Ruan\"}],\"doi\":\"10.1007/978-3-319-46493-0_50\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7a7a18e1f3dddcc351403237ea5255099441d5d5\",\"title\":\"Saliency Detection with Recurrent Fully Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/7a7a18e1f3dddcc351403237ea5255099441d5d5\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2418491\",\"name\":\"M. Zhang\"},{\"authorId\":\"21007367\",\"name\":\"K. T. Ma\"},{\"authorId\":\"153239355\",\"name\":\"J. H. Lim\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1109/ICIP.2017.8296977\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b47d27d29a178c92a64c204909cec7affbff9f9b\",\"title\":\"Foveated neural network: Gaze prediction on egocentric videos\",\"url\":\"https://www.semanticscholar.org/paper/b47d27d29a178c92a64c204909cec7affbff9f9b\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1727853\",\"name\":\"John K. Tsotsos\"},{\"authorId\":\"3468296\",\"name\":\"Iuliia Kotseruba\"},{\"authorId\":\"4218304\",\"name\":\"C. Wloka\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a654db1b4955fb58930f292716a60214113e159a\",\"title\":\"Early Salient Region Selection Does Not Drive Rapid Visual Categorization\",\"url\":\"https://www.semanticscholar.org/paper/a654db1b4955fb58930f292716a60214113e159a\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1903.07912\",\"authors\":[{\"authorId\":\"30927077\",\"name\":\"Vitaliy Lyudvichenko\"},{\"authorId\":\"34966076\",\"name\":\"M. Erofeev\"},{\"authorId\":\"87834429\",\"name\":\"Alexander Ploshkin\"},{\"authorId\":\"1776883\",\"name\":\"D. Vatolin\"}],\"doi\":\"10.1145/3332340.3332358\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d6cc5dbb2a6f1af3ab8bb7e60611986c6d8aa23f\",\"title\":\"Improving Video Compression with Deep Visual-attention Models\",\"url\":\"https://www.semanticscholar.org/paper/d6cc5dbb2a6f1af3ab8bb7e60611986c6d8aa23f\",\"venue\":\"IMIP '19\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51444483\",\"name\":\"Jila Hosseinkhani\"},{\"authorId\":\"145388725\",\"name\":\"C. Joslin\"}],\"doi\":\"10.4018/IJMDEM.2019040101\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7fc3323ea6593155e017ee709913c930769bb946\",\"title\":\"A Biologically Inspired Saliency Priority Extraction Using Bayesian Framework\",\"url\":\"https://www.semanticscholar.org/paper/7fc3323ea6593155e017ee709913c930769bb946\",\"venue\":\"Int. J. Multim. Data Eng. Manag.\",\"year\":2019},{\"arxivId\":\"1911.11702\",\"authors\":[{\"authorId\":\"1410334693\",\"name\":\"Miguel Fabian Romero-Rond\\u00f3n\"},{\"authorId\":\"1750472\",\"name\":\"L. Sassatelli\"},{\"authorId\":\"1398078454\",\"name\":\"R. Aparicio-Pardo\"},{\"authorId\":\"150103589\",\"name\":\"F. Precioso\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fbc949df3b994709a806ddb2a3d4ce5414657cd0\",\"title\":\"Revisiting Deep Architectures for Head Motion Prediction in 360\\u00b0 Videos\",\"url\":\"https://www.semanticscholar.org/paper/fbc949df3b994709a806ddb2a3d4ce5414657cd0\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19269060\",\"name\":\"Huiyu Duan\"},{\"authorId\":\"144826390\",\"name\":\"G. Zhai\"},{\"authorId\":\"2246414\",\"name\":\"Xiongkuo Min\"},{\"authorId\":\"144145642\",\"name\":\"Y. Fang\"},{\"authorId\":\"1810382\",\"name\":\"Zhaohui Che\"},{\"authorId\":\"1795291\",\"name\":\"X. Yang\"},{\"authorId\":\"144849929\",\"name\":\"C. Zhi\"},{\"authorId\":\"47912242\",\"name\":\"Hua Yang\"},{\"authorId\":\"145915295\",\"name\":\"N. Liu\"}],\"doi\":\"10.1109/ICIP.2018.8451338\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7bb7eb09cf95ff9e637e420103a6a6c6cadf5103\",\"title\":\"Learning to Predict where the Children with Asd Look\",\"url\":\"https://www.semanticscholar.org/paper/7bb7eb09cf95ff9e637e420103a6a6c6cadf5103\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":\"1803.00127\",\"authors\":[{\"authorId\":\"3345547\",\"name\":\"Huai-Jen Liang\"},{\"authorId\":\"9217768\",\"name\":\"N. J. Sanket\"},{\"authorId\":\"1759899\",\"name\":\"C. Ferm\\u00fcller\"},{\"authorId\":\"1697493\",\"name\":\"Y. Aloimonos\"}],\"doi\":\"10.1109/TASE.2019.2900980\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"52e19729230252b7f77b20a644921949f755aa37\",\"title\":\"SalientDSO: Bringing Attention to Direct Sparse Odometry\",\"url\":\"https://www.semanticscholar.org/paper/52e19729230252b7f77b20a644921949f755aa37\",\"venue\":\"IEEE Transactions on Automation Science and Engineering\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144313479\",\"name\":\"Peng Lu\"},{\"authorId\":\"40588149\",\"name\":\"Hao Zhang\"},{\"authorId\":\"8249814\",\"name\":\"Xujun Peng\"},{\"authorId\":\"143621876\",\"name\":\"X. Peng\"}],\"doi\":\"10.1016/J.IMAGE.2019.05.010\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"042a825ca52d51b7e4766fd43715e4dcd330b767\",\"title\":\"Aesthetic guided deep regression network for image cropping\",\"url\":\"https://www.semanticscholar.org/paper/042a825ca52d51b7e4766fd43715e4dcd330b767\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2019},{\"arxivId\":\"2005.06583\",\"authors\":[{\"authorId\":\"3468296\",\"name\":\"Iuliia Kotseruba\"},{\"authorId\":\"4218304\",\"name\":\"C. Wloka\"},{\"authorId\":\"26902477\",\"name\":\"Amir Rasouli\"},{\"authorId\":\"1727853\",\"name\":\"John K. Tsotsos\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f003e9630253d6f94708b10492ce747c7dfca13c\",\"title\":\"Do Saliency Models Detect Odd-One-Out Targets? New Datasets and Evaluations\",\"url\":\"https://www.semanticscholar.org/paper/f003e9630253d6f94708b10492ce747c7dfca13c\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"1907.00480\",\"authors\":[{\"authorId\":\"30927077\",\"name\":\"Vitaliy Lyudvichenko\"},{\"authorId\":\"1776883\",\"name\":\"D. Vatolin\"}],\"doi\":\"10.30987/graphicon-2019-2-127-130\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"33e150f9891e06d057d23daa579f1c68a95956f3\",\"title\":\"Predicting video saliency using crowdsourced mouse-tracking data\",\"url\":\"https://www.semanticscholar.org/paper/33e150f9891e06d057d23daa579f1c68a95956f3\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1801.05787\",\"authors\":[{\"authorId\":\"2073063\",\"name\":\"L. Theis\"},{\"authorId\":\"46400982\",\"name\":\"I. Korshunova\"},{\"authorId\":\"41203992\",\"name\":\"Alykhan Tejani\"},{\"authorId\":\"3108066\",\"name\":\"Ferenc Husz\\u00e1r\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d4d3008262697d379d0cb1642e39a8e0c756ab2c\",\"title\":\"Faster gaze prediction with dense networks and Fisher pruning\",\"url\":\"https://www.semanticscholar.org/paper/d4d3008262697d379d0cb1642e39a8e0c756ab2c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40477851\",\"name\":\"S. Croci\"},{\"authorId\":\"3034941\",\"name\":\"S. Knorr\"},{\"authorId\":\"1741139\",\"name\":\"A. Smolic\"}],\"doi\":\"10.1145/3150165.3150168\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d451d4572e3a190bcb9e25c3369d5e24d677347\",\"title\":\"Saliency-Based Sharpness Mismatch Detection For Stereoscopic Omnidirectional Images\",\"url\":\"https://www.semanticscholar.org/paper/3d451d4572e3a190bcb9e25c3369d5e24d677347\",\"venue\":\"CVMP\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743039\",\"name\":\"Yun Ren\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"}],\"doi\":\"10.1109/ACCESS.2017.2689776\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"55092057c690d6460faeed108dc40d605c7b237d\",\"title\":\"Learning-Based Saliency Detection of Face Images\",\"url\":\"https://www.semanticscholar.org/paper/55092057c690d6460faeed108dc40d605c7b237d\",\"venue\":\"IEEE Access\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36465167\",\"name\":\"F. Leit\\u00e3o\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d4eae81c7b7f1d5e9f9d85e3340ed10b9c355cec\",\"title\":\"Predicting Eye Fixations with a Deep Reconstruction-Based Approach\",\"url\":\"https://www.semanticscholar.org/paper/d4eae81c7b7f1d5e9f9d85e3340ed10b9c355cec\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"119923978\",\"name\":\"Yufan Liu\"},{\"authorId\":\"27647516\",\"name\":\"Minglang Qiao\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"1996319848\",\"name\":\"Bing Li\"},{\"authorId\":\"48594951\",\"name\":\"Weiming Hu\"},{\"authorId\":\"51004202\",\"name\":\"A. Borji\"}],\"doi\":\"10.1007/978-3-030-58565-5_25\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2e4da9223bbaea0dd7d4ed44f3cc0a7d1e7a3b17\",\"title\":\"Learning to Predict Salient Faces: A Novel Visual-Audio Saliency Model\",\"url\":\"https://www.semanticscholar.org/paper/2e4da9223bbaea0dd7d4ed44f3cc0a7d1e7a3b17\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2733405\",\"name\":\"H. Li\"},{\"authorId\":\"46534309\",\"name\":\"Fei Qi\"},{\"authorId\":\"35367337\",\"name\":\"Guangming Shi\"},{\"authorId\":\"67079406\",\"name\":\"Chunhuan Lin\"}],\"doi\":\"10.1016/J.JVCIR.2019.102611\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6c7feb802ed7303f7e9238276d292b17b561f3ac\",\"title\":\"A multiscale dilated dense convolutional network for saliency prediction with instance-level attention competition\",\"url\":\"https://www.semanticscholar.org/paper/6c7feb802ed7303f7e9238276d292b17b561f3ac\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2087470\",\"name\":\"S. Fan\"},{\"authorId\":\"34861255\",\"name\":\"Bryan L. Koenig\"},{\"authorId\":\"153386875\",\"name\":\"Q. Zhao\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":\"10.1007/s42979-019-0061-5\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"be2e75a806c39bd6d4b8c3657097298e2cbac692\",\"title\":\"A Deeper Look at Human Visual Perception of Images\",\"url\":\"https://www.semanticscholar.org/paper/be2e75a806c39bd6d4b8c3657097298e2cbac692\",\"venue\":\"SN Comput. Sci.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47908786\",\"name\":\"Y. Liu\"},{\"authorId\":\"1687503\",\"name\":\"Yanming Guo\"},{\"authorId\":\"1778365\",\"name\":\"T. Georgiou\"},{\"authorId\":\"1731570\",\"name\":\"M. Lew\"}],\"doi\":\"10.1007/s11042-018-5691-4\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4e83df2bf849eb6af24bf919ddc7bb25c7249c39\",\"title\":\"Fusion that matters: convolutional fusion networks for visual recognition\",\"url\":\"https://www.semanticscholar.org/paper/4e83df2bf849eb6af24bf919ddc7bb25c7249c39\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49499747\",\"name\":\"Jia-wei Yang\"},{\"authorId\":\"13903793\",\"name\":\"Guangtao Zhai\"},{\"authorId\":\"19269060\",\"name\":\"Huiyu Duan\"}],\"doi\":\"10.1109/VCIP47243.2019.8965925\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"77eff2a691a9861c175069bf66a4af129efa3c62\",\"title\":\"Predicting the visual saliency of the people with VIMS\",\"url\":\"https://www.semanticscholar.org/paper/77eff2a691a9861c175069bf66a4af129efa3c62\",\"venue\":\"2019 IEEE Visual Communications and Image Processing (VCIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46534309\",\"name\":\"Fei Qi\"},{\"authorId\":\"67079406\",\"name\":\"Chunhuan Lin\"},{\"authorId\":\"143713952\",\"name\":\"G. Shi\"},{\"authorId\":\"46382323\",\"name\":\"Hao Li\"}],\"doi\":\"10.1109/ACCESS.2019.2915630\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"75405582ec7883539fd15ceedb999a569f77ce93\",\"title\":\"A Convolutional Encoder-Decoder Network With Skip Connections for Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/75405582ec7883539fd15ceedb999a569f77ce93\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1742368876\",\"name\":\"Heecheol Kim\"},{\"authorId\":\"1771982\",\"name\":\"Y. Ohmura\"},{\"authorId\":\"73394480\",\"name\":\"Y. Kuniyoshi\"}],\"doi\":\"10.1109/LRA.2020.2998410\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"72db25e29524f84f29bc4598d72a3a60a2b348bd\",\"title\":\"Using Human Gaze to Improve Robustness Against Irrelevant Objects in Robot Manipulation Tasks\",\"url\":\"https://www.semanticscholar.org/paper/72db25e29524f84f29bc4598d72a3a60a2b348bd\",\"venue\":\"IEEE Robotics and Automation Letters\",\"year\":2020},{\"arxivId\":\"1807.06329\",\"authors\":[{\"authorId\":\"145884183\",\"name\":\"T. Suzuki\"},{\"authorId\":\"47456929\",\"name\":\"T. Yamanaka\"}],\"doi\":\"10.1109/SMC.2018.00358\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4aff70c46da7abfdb1e14b9369618f6e672fb114\",\"title\":\"Saliency Map Estimation for Omni-Directional Image Considering Prior Distributions\",\"url\":\"https://www.semanticscholar.org/paper/4aff70c46da7abfdb1e14b9369618f6e672fb114\",\"venue\":\"2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2576295\",\"name\":\"Chen-Ping Yu\"},{\"authorId\":\"49957558\",\"name\":\"Huidong Liu\"},{\"authorId\":\"145654220\",\"name\":\"D. Samaras\"},{\"authorId\":\"1696991\",\"name\":\"G. Zelinsky\"}],\"doi\":\"10.1101/473124\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"94c5b413549e40e7ab7f0a3e3982293c123142cf\",\"title\":\"Modeling Attention Control Using A Convolutional Neural Network Designed After The Ventral Visual Pathway\",\"url\":\"https://www.semanticscholar.org/paper/94c5b413549e40e7ab7f0a3e3982293c123142cf\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48084733\",\"name\":\"Macario O. Cordel\"},{\"authorId\":\"2087470\",\"name\":\"S. Fan\"},{\"authorId\":\"1700911\",\"name\":\"Zhiqi Shen\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"166aa31fc7b37b1a4c4abc64b1c56f34ceb81bdc\",\"title\":\"Supplementary Material for Paper \\u201c Emotion-Aware Human Attention Prediction \\u201d\",\"url\":\"https://www.semanticscholar.org/paper/166aa31fc7b37b1a4c4abc64b1c56f34ceb81bdc\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7509100\",\"name\":\"S. B. Rangrej\"},{\"authorId\":\"1790095\",\"name\":\"J. Sivaswamy\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"107877ce17bf265f52292b630d09261504677e17\",\"title\":\"ALES : an assistive system for fundus image readers by\",\"url\":\"https://www.semanticscholar.org/paper/107877ce17bf265f52292b630d09261504677e17\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39648348\",\"name\":\"Heiko H. Sch\\u00fctt\"},{\"authorId\":\"8547877\",\"name\":\"Lars O. M. Rothkegel\"},{\"authorId\":\"5181971\",\"name\":\"H. Trukenbrod\"},{\"authorId\":\"3258874\",\"name\":\"Ralf Engbert\"},{\"authorId\":\"1924112\",\"name\":\"F. Wichmann\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8b59966f85f5111beafc6fcfd898a6e9b04227ba\",\"title\":\"Disentangling bottom-up vs . top-down and low-level vs . high-level influences on eye movements over time\",\"url\":\"https://www.semanticscholar.org/paper/8b59966f85f5111beafc6fcfd898a6e9b04227ba\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7709247\",\"name\":\"Yupei Wang\"},{\"authorId\":\"145679685\",\"name\":\"X. Zhao\"},{\"authorId\":\"51055981\",\"name\":\"Xuecai Hu\"},{\"authorId\":\"48513361\",\"name\":\"Y. Li\"},{\"authorId\":\"2887871\",\"name\":\"K. Huang\"}],\"doi\":\"10.1109/TIP.2019.2891055\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"40ac9ab670908eef9104e8eb6a1f0e4d254b1526\",\"title\":\"Focal Boundary Guided Salient Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/40ac9ab670908eef9104e8eb6a1f0e4d254b1526\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"1705.10546\",\"authors\":[{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"2253528\",\"name\":\"F. Ahmed\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"1708642\",\"name\":\"Jorma T. Laaksonen\"}],\"doi\":\"10.1109/CVPR.2017.673\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"42f4aeff8219942153104c3ed5d9d661663d0cd3\",\"title\":\"Saliency Revisited: Analysis of Mouse Movements Versus Fixations\",\"url\":\"https://www.semanticscholar.org/paper/42f4aeff8219942153104c3ed5d9d661663d0cd3\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1384783507\",\"name\":\"Anni Li\"},{\"authorId\":\"2601046\",\"name\":\"J. Qi\"},{\"authorId\":\"153176123\",\"name\":\"Huchuan Lu\"}],\"doi\":\"10.1016/j.neucom.2020.06.021\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7a551e9bce44d57c390dc34aa40d023cb9a889ee\",\"title\":\"Multi-attention guided feature fusion network for salient object detection\",\"url\":\"https://www.semanticscholar.org/paper/7a551e9bce44d57c390dc34aa40d023cb9a889ee\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"1604.07090\",\"authors\":[{\"authorId\":\"39901030\",\"name\":\"Dingwen Zhang\"},{\"authorId\":\"1929093\",\"name\":\"Huazhu Fu\"},{\"authorId\":\"7181955\",\"name\":\"J. Han\"},{\"authorId\":null,\"name\":\"Feng Wu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5c3542f1639f1928628e24309d39258829a8088d\",\"title\":\"A Review of Co-saliency Detection Technique: Fundamentals, Applications, and Challenges\",\"url\":\"https://www.semanticscholar.org/paper/5c3542f1639f1928628e24309d39258829a8088d\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2997408\",\"name\":\"Matthias K\\u00fcmmerer\"},{\"authorId\":\"49737748\",\"name\":\"Thomas S. A. Wallis\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":\"10.1007/978-3-030-01270-0_47\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d9a484f6ffd5fc006401dee749493142623ba4c9\",\"title\":\"Saliency Benchmarking Made Easy: Separating Models, Maps and Metrics\",\"url\":\"https://www.semanticscholar.org/paper/d9a484f6ffd5fc006401dee749493142623ba4c9\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2539459\",\"name\":\"Petros Koutras\"},{\"authorId\":\"3411472\",\"name\":\"G. Panagiotaropoulou\"},{\"authorId\":\"3200442\",\"name\":\"A. Tsiami\"},{\"authorId\":\"1750686\",\"name\":\"P. Maragos\"}],\"doi\":\"10.1109/CVPRW.2018.00269\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"113eda25ece35fd7ecb51cb104182a973ea2313e\",\"title\":\"Audio-Visual Temporal Saliency Modeling Validated by fMRI Data\",\"url\":\"https://www.semanticscholar.org/paper/113eda25ece35fd7ecb51cb104182a973ea2313e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390477390\",\"name\":\"Zhenhao Sun\"},{\"authorId\":\"15592126\",\"name\":\"Xiaodong Wang\"},{\"authorId\":\"30024940\",\"name\":\"Qiudan Zhang\"},{\"authorId\":\"145054089\",\"name\":\"J. Jiang\"}],\"doi\":\"10.1109/ACCESS.2019.2946479\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3e896d6e00cd47f8ec07cf4a641d48f032895058\",\"title\":\"Real-Time Video Saliency Prediction Via 3D Residual Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/3e896d6e00cd47f8ec07cf4a641d48f032895058\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1751242\",\"name\":\"Yusuke Sugano\"},{\"authorId\":\"3194727\",\"name\":\"Andreas Bulling\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"456983805a8781d6429bed1ed66dc9f3902767af\",\"title\":\"Seeing with Humans : Gaze-Assisted Neural Image\",\"url\":\"https://www.semanticscholar.org/paper/456983805a8781d6429bed1ed66dc9f3902767af\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1902.01372\",\"authors\":[{\"authorId\":\"19170117\",\"name\":\"Amrita Mazumdar\"},{\"authorId\":\"144843868\",\"name\":\"Brandon Haynes\"},{\"authorId\":\"1718134\",\"name\":\"M. Balazinska\"},{\"authorId\":\"1717411\",\"name\":\"L. Ceze\"},{\"authorId\":\"144385783\",\"name\":\"A. Cheung\"},{\"authorId\":\"1723213\",\"name\":\"M. Oskin\"}],\"doi\":\"10.1145/3357223.3362725\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"16e6bf86b01a8f4a32a0f18eecf58c3d5b466c77\",\"title\":\"Perceptual Compression for Video Storage and Processing Systems\",\"url\":\"https://www.semanticscholar.org/paper/16e6bf86b01a8f4a32a0f18eecf58c3d5b466c77\",\"venue\":\"SoCC\",\"year\":2019},{\"arxivId\":\"1804.01793\",\"authors\":[{\"authorId\":\"35129473\",\"name\":\"Saumya Jetley\"},{\"authorId\":\"26734366\",\"name\":\"N. Murray\"},{\"authorId\":\"2286630\",\"name\":\"E. Vig\"}],\"doi\":\"10.1109/CVPR.2016.620\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a4d42c041bf30021550e581775c1e04f253edf54\",\"title\":\"End-to-End Saliency Mapping via Probability Distribution Prediction\",\"url\":\"https://www.semanticscholar.org/paper/a4d42c041bf30021550e581775c1e04f253edf54\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1811.08728\",\"authors\":[{\"authorId\":\"47368376\",\"name\":\"C. Wilms\"},{\"authorId\":\"1800953\",\"name\":\"S. Frintrop\"}],\"doi\":\"10.1007/978-3-030-20890-5_43\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"25e8b5844118fcace64890e9b7efc5940d230f9c\",\"title\":\"AttentionMask: Attentive, Efficient Object Proposal Generation Focusing on Small Objects\",\"url\":\"https://www.semanticscholar.org/paper/25e8b5844118fcace64890e9b7efc5940d230f9c\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"1810.03716\",\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4df34e0194faa27078832cb5078a2af6c9d0ea9b\",\"title\":\"Saliency Prediction in the Deep Learning Era: An Empirical Investigation\",\"url\":\"https://www.semanticscholar.org/paper/4df34e0194faa27078832cb5078a2af6c9d0ea9b\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3383051\",\"name\":\"Yuhang Song\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"27647516\",\"name\":\"Minglang Qiao\"},{\"authorId\":\"49606288\",\"name\":\"Jianyi Wang\"},{\"authorId\":\"27661057\",\"name\":\"Liangyu Huo\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6c67a441e1ebaa3773bb7734a7eb1690236f81a6\",\"title\":\"Modeling Attention in Panoramic Video: A Deep Reinforcement Learning Approach\",\"url\":\"https://www.semanticscholar.org/paper/6c67a441e1ebaa3773bb7734a7eb1690236f81a6\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145556868\",\"name\":\"Ali Mahdi\"},{\"authorId\":\"47901325\",\"name\":\"J. Qin\"}],\"doi\":\"10.1016/j.jvcir.2019.102662\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4ce8857aa18acd253aa33b618e37cc0bab58e23d\",\"title\":\"An extensive evaluation of deep featuresof convolutional neural networks for saliency prediction of human visual attention\",\"url\":\"https://www.semanticscholar.org/paper/4ce8857aa18acd253aa33b618e37cc0bab58e23d\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":\"1903.10831\",\"authors\":[{\"authorId\":\"3059957\",\"name\":\"L. Li\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"50142326\",\"name\":\"X. Wang\"},{\"authorId\":\"47420847\",\"name\":\"Lai Jiang\"},{\"authorId\":\"3995100\",\"name\":\"H. Liu\"}],\"doi\":\"10.1109/CVPR.2019.01082\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"97fb5a7a5ce79da0cdc5f2d28063373303ef4f8f\",\"title\":\"Attention Based Glaucoma Detection: A Large-Scale Database and CNN Model\",\"url\":\"https://www.semanticscholar.org/paper/97fb5a7a5ce79da0cdc5f2d28063373303ef4f8f\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410334693\",\"name\":\"Miguel Fabian Romero-Rond\\u00f3n\"},{\"authorId\":\"1750472\",\"name\":\"L. Sassatelli\"},{\"authorId\":\"1398078454\",\"name\":\"R. Aparicio-Pardo\"},{\"authorId\":\"1406778933\",\"name\":\"F. Precioso\"}],\"doi\":\"10.1145/3339825.3394934\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"510ce0a4796e467b8c0a4a4dcf71bf2d64255435\",\"title\":\"A unified evaluation framework for head motion prediction methods in 360\\u00b0 videos\",\"url\":\"https://www.semanticscholar.org/paper/510ce0a4796e467b8c0a4a4dcf71bf2d64255435\",\"venue\":\"MMSys\",\"year\":2020},{\"arxivId\":\"1610.06449\",\"authors\":[{\"authorId\":\"143852685\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"1708642\",\"name\":\"Jorma T. Laaksonen\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"}],\"doi\":\"10.1016/j.neucom.2017.03.018\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"9995d891a5d6737eadd7b386de23fbd7aef77903\",\"title\":\"Exploiting inter-image similarity and ensemble of extreme learners for fixation prediction using deep features\",\"url\":\"https://www.semanticscholar.org/paper/9995d891a5d6737eadd7b386de23fbd7aef77903\",\"venue\":\"Neurocomputing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1965894899\",\"name\":\"Kelam Goutam\"},{\"authorId\":\"144021807\",\"name\":\"S. Balasubramanian\"}],\"doi\":\"10.1007/978-981-15-8697-2_20\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e1e4c26de91726ab92a6c3f5b6db68c95c220433\",\"title\":\"iSalGAN - An Improvised Saliency GAN\",\"url\":\"https://www.semanticscholar.org/paper/e1e4c26de91726ab92a6c3f5b6db68c95c220433\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143852685\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"1708642\",\"name\":\"Jorma T. Laaksonen\"}],\"doi\":\"10.1007/978-3-319-54407-6_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aa804644b886535440db045117a1375b47536c76\",\"title\":\"Bottom-Up Fixation Prediction Using Unsupervised Hierarchical Models\",\"url\":\"https://www.semanticscholar.org/paper/aa804644b886535440db045117a1375b47536c76\",\"venue\":\"ACCV Workshops\",\"year\":2016},{\"arxivId\":\"1709.06316\",\"authors\":[{\"authorId\":\"47420847\",\"name\":\"Lai Jiang\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"}],\"doi\":\"10.1007/978-3-030-01264-9_37\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"fb0942800a4bc36881785d1bd878b5e8c95d9fe4\",\"title\":\"Predicting Video Saliency with Object-to-Motion CNN and Two-layer Convolutional LSTM\",\"url\":\"https://www.semanticscholar.org/paper/fb0942800a4bc36881785d1bd878b5e8c95d9fe4\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1007/978-3-319-48881-3_21\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"874b49dc4f20dcc01f8163a92f8562a36bd30161\",\"title\":\"Multi-level Net: A Visual Saliency Prediction Model\",\"url\":\"https://www.semanticscholar.org/paper/874b49dc4f20dcc01f8163a92f8562a36bd30161\",\"venue\":\"ECCV Workshops\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1737311\",\"name\":\"Yufan Liu\"},{\"authorId\":null,\"name\":\"Songyang Zhang\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"33913193\",\"name\":\"Xuming He\"}],\"doi\":\"10.1109/CVPR.2017.343\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5c3318d66f78c2ed8cbbdd1791e5a70ba2f64ead\",\"title\":\"Predicting Salient Face in Multiple-Face Videos\",\"url\":\"https://www.semanticscholar.org/paper/5c3318d66f78c2ed8cbbdd1791e5a70ba2f64ead\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1907.01432\",\"authors\":[{\"authorId\":\"144313479\",\"name\":\"Peng Lu\"},{\"authorId\":\"145140331\",\"name\":\"Hao Zhang\"},{\"authorId\":\"8249814\",\"name\":\"Xujun Peng\"},{\"authorId\":\"150344105\",\"name\":\"Xiaofu Jin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dfb66f262653b10aa50380eabbb5b7d5136f9f29\",\"title\":\"An End-to-End Neural Network for Image Cropping by Learning Composition from Aesthetic Photos\",\"url\":\"https://www.semanticscholar.org/paper/dfb66f262653b10aa50380eabbb5b7d5136f9f29\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390936291\",\"name\":\"Haoran Liang\"},{\"authorId\":\"1410304992\",\"name\":\"Ming Jiang\"},{\"authorId\":\"4487395\",\"name\":\"Ronghua Liang\"},{\"authorId\":\"153386875\",\"name\":\"Q. Zhao\"}],\"doi\":\"10.1016/j.neucom.2019.09.085\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"126e0801de465f8d2092af3eb88a89a8f2e995f7\",\"title\":\"A structure-guided approach to the prediction of natural image saliency\",\"url\":\"https://www.semanticscholar.org/paper/126e0801de465f8d2092af3eb88a89a8f2e995f7\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Shree Nath Dutt Sharma\"},{\"authorId\":\"1686020\",\"name\":\"D. Samaras\"},{\"authorId\":\"35217367\",\"name\":\"Niranjan Balasubramanian\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"385c9cb10e5f46af0057c8103edccd9062bc721a\",\"title\":\"Ordering Salient Objects in Images\",\"url\":\"https://www.semanticscholar.org/paper/385c9cb10e5f46af0057c8103edccd9062bc721a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"6aee8323be7ad5e568d62ba368bc7123f750515f\",\"title\":\"Paying More Attention to Saliency: Image Captioning with Saliency and Context Attention\",\"url\":\"https://www.semanticscholar.org/paper/6aee8323be7ad5e568d62ba368bc7123f750515f\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1811.05625\",\"authors\":[{\"authorId\":\"1967201\",\"name\":\"Kui Fu\"},{\"authorId\":\"9073063\",\"name\":\"Jiugang Li\"},{\"authorId\":\"2803144\",\"name\":\"Y. Zhang\"},{\"authorId\":\"121194391\",\"name\":\"Hongze Shen\"},{\"authorId\":\"144051792\",\"name\":\"Yonghong Tian\"}],\"doi\":\"10.1109/TIP.2020.2998977\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fd2b919b6abb91657aa9104dfc2e7c18c114cbae\",\"title\":\"Model-Guided Multi-Path Knowledge Aggregation for Aerial Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/fd2b919b6abb91657aa9104dfc2e7c18c114cbae\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1760977\",\"name\":\"V. Lebor\\u00e1n\"},{\"authorId\":\"1396144799\",\"name\":\"A. Garc\\u00eda-D\\u00edaz\"},{\"authorId\":\"1398517622\",\"name\":\"Xose R. Fdez-Vidal\"},{\"authorId\":\"1397906798\",\"name\":\"Xose M. Pardo\"}],\"doi\":\"10.1109/TPAMI.2016.2567391\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"822cf4868af46453dd7e9232ad8011e62c9c0400\",\"title\":\"Dynamic Whitening Saliency\",\"url\":\"https://www.semanticscholar.org/paper/822cf4868af46453dd7e9232ad8011e62c9c0400\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2087470\",\"name\":\"S. Fan\"},{\"authorId\":\"144506018\",\"name\":\"Z. Shen\"},{\"authorId\":\"144645142\",\"name\":\"M. Jiang\"},{\"authorId\":\"34861255\",\"name\":\"Bryan L. Koenig\"},{\"authorId\":\"1946538\",\"name\":\"J. Xu\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1109/CVPR.2018.00785\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c46d02e64fbd70080c2f6ab6cc96c9c36f3107f1\",\"title\":\"Emotional Attention: A Study of Image Sentiment and Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/c46d02e64fbd70080c2f6ab6cc96c9c36f3107f1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2444586\",\"name\":\"Lester C. Loschky\"},{\"authorId\":\"3303327\",\"name\":\"Adam M. Larson\"},{\"authorId\":\"50168186\",\"name\":\"Tim J. Smith\"},{\"authorId\":\"66256479\",\"name\":\"Joseph P. Magliano\"}],\"doi\":\"10.1111/tops.12455\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4d95fb4739a85fe37624bc84d654ee31ad957672\",\"title\":\"The Scene Perception & Event Comprehension Theory (SPECT) Applied to Visual Narratives\",\"url\":\"https://www.semanticscholar.org/paper/4d95fb4739a85fe37624bc84d654ee31ad957672\",\"venue\":\"Top. Cogn. Sci.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49637078\",\"name\":\"W. Shan\"},{\"authorId\":\"2272337\",\"name\":\"Guangling Sun\"},{\"authorId\":\"37066739\",\"name\":\"Zhi Liu\"}],\"doi\":\"10.1007/978-981-10-4211-9_13\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2ea1196a3fb9052b923cef624526ba4b31c8babf\",\"title\":\"Webpage Image Saliency Prediction via Adaptive SVM\",\"url\":\"https://www.semanticscholar.org/paper/2ea1196a3fb9052b923cef624526ba4b31c8babf\",\"venue\":\"IFTC\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150188542\",\"name\":\"Lai Jiang\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"15661018\",\"name\":\"Shanyi Zhang\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":\"10.1016/j.patcog.2020.107234\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"947b42503e78f29fd64ab864a76721dae8cad26e\",\"title\":\"DeepCT: A novel deep complex-valued network with learnable transform for video saliency prediction\",\"url\":\"https://www.semanticscholar.org/paper/947b42503e78f29fd64ab864a76721dae8cad26e\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47786249\",\"name\":\"J. Li\"},{\"authorId\":\"9083492\",\"name\":\"Yangjie Zhao\"},{\"authorId\":\"50236144\",\"name\":\"W. Ye\"},{\"authorId\":\"46330829\",\"name\":\"Kai-Wen Yu\"},{\"authorId\":\"102999346\",\"name\":\"Shiming Ge\"}],\"doi\":\"10.1109/JSTSP.2019.2953950\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"641f0a8280c28de5251f8e0f28dec90a40918793\",\"title\":\"Attentive Deep Stitching and Quality Assessment for 360$^{\\\\circ }$ Omnidirectional Images\",\"url\":\"https://www.semanticscholar.org/paper/641f0a8280c28de5251f8e0f28dec90a40918793\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020},{\"arxivId\":\"1809.00567\",\"authors\":[{\"authorId\":\"22206915\",\"name\":\"Marc Assens\"},{\"authorId\":\"3100480\",\"name\":\"Xavier Giro-i-Nieto\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"}],\"doi\":\"10.1007/978-3-030-11021-5_25\",\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"1e1a4f7e2d8dd172e278f148cca1172f313966b4\",\"title\":\"PathGAN: Visual Scanpath Prediction with Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/1e1a4f7e2d8dd172e278f148cca1172f313966b4\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405686623\",\"name\":\"Nils Murrugarra-Llerena\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":\"10.1109/WACV.2017.63\",\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"eba9452ba55a9d37e84dae7a4caf11c6ddd377d5\",\"title\":\"Learning Attributes from Human Gaze\",\"url\":\"https://www.semanticscholar.org/paper/eba9452ba55a9d37e84dae7a4caf11c6ddd377d5\",\"venue\":\"2017 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145378987\",\"name\":\"Yan Luo\"},{\"authorId\":\"2343486\",\"name\":\"X. Boix\"},{\"authorId\":\"144596911\",\"name\":\"Gemma Roig\"},{\"authorId\":\"145031878\",\"name\":\"T. Poggio\"},{\"authorId\":\"153386875\",\"name\":\"Q. Zhao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e80121c1719efe46e226f296e0a920a1aa191dc6\",\"title\":\"Foveation-based Mechanisms Alleviate Adversarial Examples of Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/e80121c1719efe46e226f296e0a920a1aa191dc6\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2296560\",\"name\":\"Yasin Kavak\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"}],\"doi\":\"10.1016/j.image.2019.115694\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"03a6ad701627efdea485ef26dad1626c11fc8c86\",\"title\":\"Hedging static saliency models to predict dynamic saliency\",\"url\":\"https://www.semanticscholar.org/paper/03a6ad701627efdea485ef26dad1626c11fc8c86\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2020},{\"arxivId\":\"1904.06090\",\"authors\":[{\"authorId\":\"143852685\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"},{\"authorId\":\"1776374\",\"name\":\"Juho Kannala\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":\"10.1109/WACV.2019.00035\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b14286fdc78b3039fc724274c18aa24caee8b59e\",\"title\":\"Digging Deeper Into Egocentric Gaze Prediction\",\"url\":\"https://www.semanticscholar.org/paper/b14286fdc78b3039fc724274c18aa24caee8b59e\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":\"1608.05203\",\"authors\":[{\"authorId\":\"1751242\",\"name\":\"Yusuke Sugano\"},{\"authorId\":\"3194727\",\"name\":\"Andreas Bulling\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c70ad19c90491e2de8de686b6a49f9bbe44692c0\",\"title\":\"Seeing with Humans: Gaze-Assisted Neural Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/c70ad19c90491e2de8de686b6a49f9bbe44692c0\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"145076397\",\"name\":\"Yun Ren\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"},{\"authorId\":\"8189996\",\"name\":\"Jingxian Liu\"},{\"authorId\":\"144978572\",\"name\":\"X. Tao\"}],\"doi\":\"10.1109/TMM.2017.2767784\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"5ecacb98ac7e2ad9d28f6bc20d7bb449b888afe9\",\"title\":\"Saliency Detection in Face Videos: A Data-Driven Approach\",\"url\":\"https://www.semanticscholar.org/paper/5ecacb98ac7e2ad9d28f6bc20d7bb449b888afe9\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"117562053\",\"name\":\"M. A. Reina\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1f1996c60dec75d575f20880a49d646a42584f3a\",\"title\":\"The temporal dimension of visual attention models\",\"url\":\"https://www.semanticscholar.org/paper/1f1996c60dec75d575f20880a49d646a42584f3a\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2525711\",\"name\":\"J. Li\"},{\"authorId\":\"123042167\",\"name\":\"Xiaomei Feng\"},{\"authorId\":\"145677752\",\"name\":\"Hui Fan\"}],\"doi\":\"10.1007/s41095-020-0172-x\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9f4d4d6e7a8cd74be299818108b3b976091ca0e9\",\"title\":\"Saliency-based image correction for colorblind patients\",\"url\":\"https://www.semanticscholar.org/paper/9f4d4d6e7a8cd74be299818108b3b976091ca0e9\",\"venue\":\"Computational Visual Media\",\"year\":2020},{\"arxivId\":\"1708.06433\",\"authors\":[{\"authorId\":\"143905571\",\"name\":\"Nian Liu\"},{\"authorId\":\"7181955\",\"name\":\"J. Han\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8d7c2c3d03ae5360bb73ac818a0e36f324f1e8ce\",\"title\":\"PiCANet: Learning Pixel-wise Contextual Attention in ConvNets and Its Application in Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/8d7c2c3d03ae5360bb73ac818a0e36f324f1e8ce\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143741775\",\"name\":\"F. Zhou\"},{\"authorId\":\"80947730\",\"name\":\"Rongguo Yao\"},{\"authorId\":\"1474234993\",\"name\":\"Guangsen Liao\"},{\"authorId\":\"3185721\",\"name\":\"Bozhi Liu\"},{\"authorId\":\"1713506\",\"name\":\"Guoping Qiu\"}],\"doi\":\"10.1109/TIP.2020.3016464\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"10d15860ece08b185b115da2b03075d7e8065f4e\",\"title\":\"Visual Saliency via Embedding Hierarchical Knowledge in a Deep Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/10d15860ece08b185b115da2b03075d7e8065f4e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1909.06761\",\"authors\":[{\"authorId\":\"51463388\",\"name\":\"G. Kapidis\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"},{\"authorId\":\"8297919\",\"name\":\"E. V. Dam\"},{\"authorId\":\"144882447\",\"name\":\"L. Noldus\"},{\"authorId\":\"47329105\",\"name\":\"Remco C. Veltkamp\"}],\"doi\":\"10.1109/ICCVW.2019.00540\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8cca4d9e7831cad9d7b4e9693a1be9b6eaea8805\",\"title\":\"Multitask Learning to Improve Egocentric Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8cca4d9e7831cad9d7b4e9693a1be9b6eaea8805\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40217518\",\"name\":\"Q. Zhou\"},{\"authorId\":\"48265412\",\"name\":\"J. Cheng\"},{\"authorId\":\"143663452\",\"name\":\"Huimin Lu\"},{\"authorId\":\"2576377\",\"name\":\"Yawen Fan\"},{\"authorId\":\"2819904\",\"name\":\"Suofei Zhang\"},{\"authorId\":\"34885692\",\"name\":\"X. Wu\"},{\"authorId\":\"143918844\",\"name\":\"Baoyu Zheng\"},{\"authorId\":\"2147977\",\"name\":\"W. Ou\"},{\"authorId\":\"1686678\",\"name\":\"L. Latecki\"}],\"doi\":\"10.1007/s11042-018-6770-2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"64be44cb454246afc8323d239e7c4539f6df326b\",\"title\":\"Learning adaptive contrast combinations for visual saliency detection\",\"url\":\"https://www.semanticscholar.org/paper/64be44cb454246afc8323d239e7c4539f6df326b\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48551624\",\"name\":\"Z. Wu\"},{\"authorId\":\"145235481\",\"name\":\"Li Su\"},{\"authorId\":\"1689702\",\"name\":\"Q. Huang\"}],\"doi\":\"10.1109/TCSVT.2018.2870954\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a9c59b7910e5291937c0ee0c93343b810fbc89c0\",\"title\":\"Learning Coupled Convolutional Networks Fusion for Video Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/a9c59b7910e5291937c0ee0c93343b810fbc89c0\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":\"1801.08926\",\"authors\":[{\"authorId\":\"40014058\",\"name\":\"Aaditya Prakash\"},{\"authorId\":\"33072734\",\"name\":\"N. Moran\"},{\"authorId\":\"50304331\",\"name\":\"Solomon Garber\"},{\"authorId\":\"39432646\",\"name\":\"Antonella DiLillo\"},{\"authorId\":\"1770857\",\"name\":\"J. Storer\"}],\"doi\":\"10.1109/CVPR.2018.00894\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f5e602bf3d59d2ea1553f06a94e9e94880af065d\",\"title\":\"Deflecting Adversarial Attacks with Pixel Deflection\",\"url\":\"https://www.semanticscholar.org/paper/f5e602bf3d59d2ea1553f06a94e9e94880af065d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"73596111\",\"name\":\"L. Li\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"3995100\",\"name\":\"H. Liu\"},{\"authorId\":null,\"name\":\"Yang Li\"},{\"authorId\":\"50142326\",\"name\":\"X. Wang\"},{\"authorId\":\"150188542\",\"name\":\"Lai Jiang\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"},{\"authorId\":\"143955709\",\"name\":\"Xiang Fan\"},{\"authorId\":\"52155290\",\"name\":\"N. Wang\"}],\"doi\":\"10.1109/TMI.2019.2927226\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6df26bef856d4839c8a1f82e89767d66ea07e8e6\",\"title\":\"A Large-Scale Database and a CNN Model for Attention-Based Glaucoma Detection\",\"url\":\"https://www.semanticscholar.org/paper/6df26bef856d4839c8a1f82e89767d66ea07e8e6\",\"venue\":\"IEEE Transactions on Medical Imaging\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153385438\",\"name\":\"A. Mane\"},{\"authorId\":\"151440546\",\"name\":\"S. Mali\"},{\"authorId\":\"90315386\",\"name\":\"Priyanka D. Mali\"},{\"authorId\":\"151426605\",\"name\":\"Sonam Mulik\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9066cd93949c29c0197f4e4fceaf00888532f46d\",\"title\":\"International Journal of Scientific Research in Computer Science, Engineering and Information Technology\",\"url\":\"https://www.semanticscholar.org/paper/9066cd93949c29c0197f4e4fceaf00888532f46d\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1803.07352\",\"authors\":[{\"authorId\":\"29349147\",\"name\":\"Heiko H. Schutt\"},{\"authorId\":\"47881795\",\"name\":\"Lars O M Rothkegel\"},{\"authorId\":\"5181971\",\"name\":\"H. Trukenbrod\"},{\"authorId\":\"3258874\",\"name\":\"Ralf Engbert\"},{\"authorId\":\"1924112\",\"name\":\"Felix Wichmann\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"24acb0110e57de29f5be55f52887b3cd41d1bf12\",\"title\":\"Disentangling top-down vs. bottom-up and low-level vs. high-level influences on eye movements over time\",\"url\":\"https://www.semanticscholar.org/paper/24acb0110e57de29f5be55f52887b3cd41d1bf12\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50178930\",\"name\":\"A. Gupta\"},{\"authorId\":\"101535191\",\"name\":\"A. Seal\"},{\"authorId\":\"145499324\",\"name\":\"Mukesh Prasad\"},{\"authorId\":\"2466508\",\"name\":\"P. Khanna\"}],\"doi\":\"10.3390/e22101174\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c04d9e067cfcb805b20ac514b42085fc81a7bccd\",\"title\":\"Salient Object Detection Techniques in Computer Vision\\u2014A Survey\",\"url\":\"https://www.semanticscholar.org/paper/c04d9e067cfcb805b20ac514b42085fc81a7bccd\",\"venue\":\"Entropy\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39901030\",\"name\":\"Dingwen Zhang\"},{\"authorId\":\"1929093\",\"name\":\"Huazhu Fu\"},{\"authorId\":\"7181955\",\"name\":\"J. Han\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"1720243\",\"name\":\"X. Li\"}],\"doi\":\"10.1145/3158674\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0eafd44e93966e7c8d52dc45f2f66cf234e9fc62\",\"title\":\"A Review of Co-Saliency Detection Algorithms\",\"url\":\"https://www.semanticscholar.org/paper/0eafd44e93966e7c8d52dc45f2f66cf234e9fc62\",\"venue\":\"ACM Trans. Intell. Syst. Technol.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46674323\",\"name\":\"Yunfeng Sui\"},{\"authorId\":\"37203857\",\"name\":\"Lingtong Meng\"},{\"authorId\":\"48440758\",\"name\":\"Jiaqi Feng\"},{\"authorId\":\"47601467\",\"name\":\"Shixuan Zhao\"},{\"authorId\":\"145070239\",\"name\":\"Zhi Cheng\"}],\"doi\":\"10.1145/3239576.3239587\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e9dc71d62098848d8bd8aab5cbe455c5637d6461\",\"title\":\"Transferring CNN Intermediate Layers via Weakly-Supervised Learning and Latent Semantic Analysis\",\"url\":\"https://www.semanticscholar.org/paper/e9dc71d62098848d8bd8aab5cbe455c5637d6461\",\"venue\":\"ICAIP '18\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2317822\",\"name\":\"Nianyi Li\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"315511e474b59b6469f5697e8b4e4abd14663b66\",\"title\":\"Human attention simulation on nature scenes in computer vision\",\"url\":\"https://www.semanticscholar.org/paper/315511e474b59b6469f5697e8b4e4abd14663b66\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1904.08155\",\"authors\":[{\"authorId\":\"102373436\",\"name\":\"Justin Le Louedec\"},{\"authorId\":\"27568508\",\"name\":\"Thomas Guntz\"},{\"authorId\":\"145687022\",\"name\":\"J. Crowley\"},{\"authorId\":\"2903379\",\"name\":\"D. Vaufreydaz\"}],\"doi\":\"10.1145/3314111.3319827\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8c9043a50d95807c5d2d4e2e4e1c82a79a3e20a1\",\"title\":\"Deep learning investigation for chess player attention prediction using eye-tracking and game data\",\"url\":\"https://www.semanticscholar.org/paper/8c9043a50d95807c5d2d4e2e4e1c82a79a3e20a1\",\"venue\":\"ETRA\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1388070721\",\"name\":\"Alexander Makrigiorgos\"},{\"authorId\":\"144793784\",\"name\":\"Aldo Faisal\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"867c8a5b96962d674e2f2978ad016e2fc86a468f\",\"title\":\"Improving Autonomous Driving Agents using Bio-Inspired Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/867c8a5b96962d674e2f2978ad016e2fc86a468f\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48084733\",\"name\":\"Macario O. Cordel\"},{\"authorId\":\"2087470\",\"name\":\"S. Fan\"},{\"authorId\":\"1700911\",\"name\":\"Zhiqi Shen\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":\"10.1109/CVPR.2019.00415\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d61bd9bc9a09731bcdfb7c84ef57b71ebb06a1e3\",\"title\":\"Emotion-Aware Human Attention Prediction\",\"url\":\"https://www.semanticscholar.org/paper/d61bd9bc9a09731bcdfb7c84ef57b71ebb06a1e3\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39648348\",\"name\":\"Heiko H. Sch\\u00fctt\"},{\"authorId\":\"8547877\",\"name\":\"Lars O. M. Rothkegel\"},{\"authorId\":\"5181971\",\"name\":\"H. Trukenbrod\"},{\"authorId\":\"3258874\",\"name\":\"Ralf Engbert\"},{\"authorId\":\"1924112\",\"name\":\"Felix Wichmann\"}],\"doi\":\"10.1167/19.3.1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fe7e6d127ecb74688af3fedec6c705c8223d5e2a\",\"title\":\"Disentangling bottom-up versus top-down and low-level versus high-level influences on eye movements over time.\",\"url\":\"https://www.semanticscholar.org/paper/fe7e6d127ecb74688af3fedec6c705c8223d5e2a\",\"venue\":\"Journal of vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51149716\",\"name\":\"Taiki Oyama\"},{\"authorId\":\"47456929\",\"name\":\"T. Yamanaka\"}],\"doi\":\"10.1109/ACPR.2017.143\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d702248cf46124600c680608a510e03a30b4d63b\",\"title\":\"Fully Convolutional DenseNet for Saliency-Map Prediction\",\"url\":\"https://www.semanticscholar.org/paper/d702248cf46124600c680608a510e03a30b4d63b\",\"venue\":\"2017 4th IAPR Asian Conference on Pattern Recognition (ACPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"3288214\",\"name\":\"Rao Muhammad Anwer\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"},{\"authorId\":\"1776374\",\"name\":\"Juho Kannala\"}],\"doi\":\"10.1109/ICIP.2018.8451537\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"09636efc017110b53453aafa7f88d4e1acf6c447\",\"title\":\"Bottom-Up Attention Guidance for Recurrent Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/09636efc017110b53453aafa7f88d4e1acf6c447\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":\"1803.09331\",\"authors\":[{\"authorId\":\"3422097\",\"name\":\"Xingyi Zhou\"},{\"authorId\":\"30899347\",\"name\":\"Arjun Karpur\"},{\"authorId\":\"40359898\",\"name\":\"L. Luo\"},{\"authorId\":\"32798502\",\"name\":\"Qixing Huang\"}],\"doi\":\"10.1007/978-3-030-01246-5_20\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8b6afef69b14b97a272c667b6b9004e441085c89\",\"title\":\"StarMap for Category-Agnostic Keypoint and Viewpoint Estimation\",\"url\":\"https://www.semanticscholar.org/paper/8b6afef69b14b97a272c667b6b9004e441085c89\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22206915\",\"name\":\"Marc Assens\"},{\"authorId\":\"1398090762\",\"name\":\"Xavier Gir\\u00f3-i-Nieto\"},{\"authorId\":\"145470863\",\"name\":\"K. McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"}],\"doi\":null,\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"504eb02718b3ad839d1bb10b19f39fbf3ab4883f\",\"title\":\"Related Work 2 . 1 Visual Saliency Prediction Saliency maps\",\"url\":\"https://www.semanticscholar.org/paper/504eb02718b3ad839d1bb10b19f39fbf3ab4883f\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1802.07931\",\"authors\":[{\"authorId\":\"10814650\",\"name\":\"Sikun Lin\"},{\"authorId\":\"143966172\",\"name\":\"P. Hui\"}],\"doi\":\"10.14711/thesis-991012554569603412\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a1fdf45e6649b0020eb533c70d6062b9183561ff\",\"title\":\"Where's YOUR focus: Personalized Attention\",\"url\":\"https://www.semanticscholar.org/paper/a1fdf45e6649b0020eb533c70d6062b9183561ff\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1803.09125\",\"authors\":[{\"authorId\":\"48355461\",\"name\":\"Yifei Huang\"},{\"authorId\":\"3172280\",\"name\":\"Minjie Cai\"},{\"authorId\":\"46947776\",\"name\":\"Zhenqiang Li\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1007/978-3-030-01225-0_46\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"7e236d33dce5d30348aeb494e491a13468133b4e\",\"title\":\"Predicting Gaze in Egocentric Video by Learning Task-dependent Attention Transition\",\"url\":\"https://www.semanticscholar.org/paper/7e236d33dce5d30348aeb494e491a13468133b4e\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1603.00845\",\"authors\":[{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"},{\"authorId\":\"2470219\",\"name\":\"E. Sayrol\"},{\"authorId\":\"3100480\",\"name\":\"Xavier Giro-i-Nieto\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"}],\"doi\":\"10.1109/CVPR.2016.71\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9528e2e8c20517ab916f803c0371abb4f0ed488b\",\"title\":\"Shallow and Deep Convolutional Networks for Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/9528e2e8c20517ab916f803c0371abb4f0ed488b\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1905.10693\",\"authors\":[{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"51004202\",\"name\":\"A. Borji\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"},{\"authorId\":\"1776374\",\"name\":\"Juho Kannala\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"827b68bdb1e38bb75e0db020ce764d25997b4c60\",\"title\":\"DAVE: A Deep Audio-Visual Embedding for Dynamic Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/827b68bdb1e38bb75e0db020ce764d25997b4c60\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145556862\",\"name\":\"Ali Mahdi\"},{\"authorId\":\"145849768\",\"name\":\"J. Qin\"}],\"doi\":\"10.1117/1.JEI.28.3.033033\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"07abe8e63d233a9e8cb5c8267df1d2024d179270\",\"title\":\"Evaluation of bottom-up saliency model using deep features pretrained by deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/07abe8e63d233a9e8cb5c8267df1d2024d179270\",\"venue\":\"J. Electronic Imaging\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b0c001b2f619ee55114b29ded767c0295d88ce02\",\"title\":\"Computational perception for multi-modal document understanding\",\"url\":\"https://www.semanticscholar.org/paper/b0c001b2f619ee55114b29ded767c0295d88ce02\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1423668854\",\"name\":\"Jiaqi Feng\"},{\"authorId\":\"47319689\",\"name\":\"Shuai Li\"},{\"authorId\":\"46674323\",\"name\":\"Yunfeng Sui\"},{\"authorId\":\"37203857\",\"name\":\"L. Meng\"},{\"authorId\":\"143754861\",\"name\":\"Ce Zhu\"}],\"doi\":\"10.1109/APSIPAASC47483.2019.9023127\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"540bdbf95acdeb1a05102b995b4ffc3d3a04bf51\",\"title\":\"Integrating Action-aware Features for Saliency Prediction via Weakly Supervised Learning\",\"url\":\"https://www.semanticscholar.org/paper/540bdbf95acdeb1a05102b995b4ffc3d3a04bf51\",\"venue\":\"2019 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3028166\",\"name\":\"M. Cordel\"}],\"doi\":\"10.1109/BigData47090.2019.9006300\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f449a737aee8804f37e1a09123f00a3f5dc34627\",\"title\":\"Modeling human attention by learning from large amount of emotional images\",\"url\":\"https://www.semanticscholar.org/paper/f449a737aee8804f37e1a09123f00a3f5dc34627\",\"venue\":\"2019 IEEE International Conference on Big Data (Big Data)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143858624\",\"name\":\"Zhen Deng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c1aacd34b21c3a27a2d80ceb150e7676551591fa\",\"title\":\"Integrating Perception and Optimization for Dexterous Grasping and Manipulation\",\"url\":\"https://www.semanticscholar.org/paper/c1aacd34b21c3a27a2d80ceb150e7676551591fa\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48984885\",\"name\":\"Felipe Vera\"},{\"authorId\":\"32124610\",\"name\":\"V. Cort\\u00e9s\"},{\"authorId\":\"32830698\",\"name\":\"Gabriel Iturrra\"},{\"authorId\":\"145323794\",\"name\":\"J. Vel\\u00e1squez\"},{\"authorId\":\"145132845\",\"name\":\"P. Maldonado\"},{\"authorId\":\"5842513\",\"name\":\"A. Couve\"}],\"doi\":\"10.1109/ICDMW.2017.90\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"82256e82e9ae58538f8b68f2f6cd1e667818cb18\",\"title\":\"Akori: A Tool Based in Eye-Tracking Techniques for Analyzing Web User Behaviour on a Web Site\",\"url\":\"https://www.semanticscholar.org/paper/82256e82e9ae58538f8b68f2f6cd1e667818cb18\",\"venue\":\"2017 IEEE International Conference on Data Mining Workshops (ICDMW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36195510\",\"name\":\"S. Hegde\"},{\"authorId\":\"15328368\",\"name\":\"Jitender Maurya\"},{\"authorId\":\"3177394\",\"name\":\"R. Hebbalaguppe\"},{\"authorId\":\"1699607987\",\"name\":\"Aniruddha Kalkar\"}],\"doi\":\"10.1109/WACV45572.2020.9093587\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"520f2aaa00ed05239f497e617472490a96900e92\",\"title\":\"SmartOverlays: A Visual Saliency Driven Label Placement for Intelligent Human-Computer Interfaces\",\"url\":\"https://www.semanticscholar.org/paper/520f2aaa00ed05239f497e617472490a96900e92\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1395725948\",\"name\":\"Bashir Ghariba\"},{\"authorId\":\"144906448\",\"name\":\"M. Shehata\"},{\"authorId\":\"2903414\",\"name\":\"P. McGuire\"}],\"doi\":\"10.7717/peerj-cs.280\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c981fee8b6cb0af49e6c22e701d760a238aee591\",\"title\":\"A novel fully convolutional network for visual saliency prediction\",\"url\":\"https://www.semanticscholar.org/paper/c981fee8b6cb0af49e6c22e701d760a238aee591\",\"venue\":\"PeerJ Comput. Sci.\",\"year\":2020},{\"arxivId\":\"1611.09571\",\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/TIP.2018.2851672\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b7e336a7d3cd82ae8cd5e85d3cb62f0b6091a0e5\",\"title\":\"Predicting Human Eye Fixations via an LSTM-Based Saliency Attentive Model\",\"url\":\"https://www.semanticscholar.org/paper/b7e336a7d3cd82ae8cd5e85d3cb62f0b6091a0e5\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38562041\",\"name\":\"Khimya Khetarpal\"},{\"authorId\":\"2617152\",\"name\":\"E. Jain\"}],\"doi\":\"10.1109/ICMEW.2016.7574728\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5c21b3daa170b12d42edb89017b48247b87b852b\",\"title\":\"A preliminary benchmark of four saliency algorithms on comic art\",\"url\":\"https://www.semanticscholar.org/paper/5c21b3daa170b12d42edb89017b48247b87b852b\",\"venue\":\"2016 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2418491\",\"name\":\"Mengmi Zhang\"},{\"authorId\":\"2343486\",\"name\":\"X. Boix\"},{\"authorId\":\"21007367\",\"name\":\"K. T. Ma\"},{\"authorId\":\"144889909\",\"name\":\"M. Jiang\"},{\"authorId\":\"153239355\",\"name\":\"J. H. Lim\"},{\"authorId\":\"153386875\",\"name\":\"Q. Zhao\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"da7db2567a81df22ede6396cb88649c42cc9b5e0\",\"title\":\"Deep Scanpath: Predicting Human Sequences of Eye-Fixations using Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/da7db2567a81df22ede6396cb88649c42cc9b5e0\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1607.04730\",\"authors\":[{\"authorId\":\"34847250\",\"name\":\"\\u00c7agdas Bak\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dac2e8365df576e6d3f16b01d48e0d5e4156b81f\",\"title\":\"Two-Stream Convolutional Networks for Dynamic Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/dac2e8365df576e6d3f16b01d48e0d5e4156b81f\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7869872\",\"name\":\"Y. Xu\"},{\"authorId\":\"49266038\",\"name\":\"Yanbing Dong\"},{\"authorId\":\"3423101\",\"name\":\"Junru Wu\"},{\"authorId\":\"30581936\",\"name\":\"Zhengzhong Sun\"},{\"authorId\":\"34692825\",\"name\":\"Zhiru Shi\"},{\"authorId\":\"2152356\",\"name\":\"J. Yu\"},{\"authorId\":\"1702868\",\"name\":\"Shenghua Gao\"}],\"doi\":\"10.1109/CVPR.2018.00559\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cc3bd1659d005ee25c26e3f6aab3c7361f6172b7\",\"title\":\"Gaze Prediction in Dynamic 360\\u00b0 Immersive Videos\",\"url\":\"https://www.semanticscholar.org/paper/cc3bd1659d005ee25c26e3f6aab3c7361f6172b7\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1904.07080\",\"authors\":[{\"authorId\":\"1743773\",\"name\":\"Mai Xu\"},{\"authorId\":\"40248914\",\"name\":\"Li Yang\"},{\"authorId\":\"144978572\",\"name\":\"Xiaoming Tao\"},{\"authorId\":\"1866977\",\"name\":\"Yiping Duan\"},{\"authorId\":\"1754571\",\"name\":\"Zulin Wang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"89fdf25a9ced9484512c911e23afbbb54f98b9ad\",\"title\":\"Saliency Prediction on Omnidirectional Images with Generative Adversarial Imitation Learning\",\"url\":\"https://www.semanticscholar.org/paper/89fdf25a9ced9484512c911e23afbbb54f98b9ad\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"83143774\",\"name\":\"Sofia Krasovskaya\"},{\"authorId\":\"84336221\",\"name\":\"Georgiy Zhulikov\"},{\"authorId\":\"1738746616\",\"name\":\"Joseph W. MacInnes\"}],\"doi\":\"10.2139/ssrn.3262650\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"890a2e4354fe1ced953a3e8e58065fdbe0072317\",\"title\":\"Deep Learning Neural Networks as a Model of Saccadic Generation\",\"url\":\"https://www.semanticscholar.org/paper/890a2e4354fe1ced953a3e8e58065fdbe0072317\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30024940\",\"name\":\"Qiudan Zhang\"},{\"authorId\":\"72541446\",\"name\":\"Xu Wang\"},{\"authorId\":null,\"name\":\"Shiqi Wang\"},{\"authorId\":\"1390477390\",\"name\":\"Zhenhao Sun\"},{\"authorId\":\"1687386\",\"name\":\"S. Kwong\"},{\"authorId\":\"145931655\",\"name\":\"Jianmin Jiang\"}],\"doi\":\"10.1109/TIP.2020.2985531\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"917666c6ff2993f75dd77009ca41e69c81369707\",\"title\":\"Learning to Explore Saliency for Stereoscopic Videos Via Component-Based Interaction\",\"url\":\"https://www.semanticscholar.org/paper/917666c6ff2993f75dd77009ca41e69c81369707\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47294217\",\"name\":\"Ziheng Zhang\"},{\"authorId\":\"7869872\",\"name\":\"Y. Xu\"},{\"authorId\":\"2152356\",\"name\":\"J. Yu\"},{\"authorId\":\"1702868\",\"name\":\"Shenghua Gao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"219bac0d46072291b129748809973618646935e6\",\"title\":\"Saliency Detection in 360\\u00b0 Videos\",\"url\":\"https://www.semanticscholar.org/paper/219bac0d46072291b129748809973618646935e6\",\"venue\":\"ECCV 2018\",\"year\":2018},{\"arxivId\":\"1904.04449\",\"authors\":[{\"authorId\":\"1967201\",\"name\":\"Kui Fu\"},{\"authorId\":null,\"name\":\"Jia Li\"},{\"authorId\":\"2839196\",\"name\":\"Yafei Song\"},{\"authorId\":\"39076047\",\"name\":\"Y. Zhang\"},{\"authorId\":\"39646508\",\"name\":\"Shiming Ge\"},{\"authorId\":\"144051792\",\"name\":\"Yonghong Tian\"}],\"doi\":\"10.1609/AAAI.V34I07.6710\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1b995069e1930fd9a2d87fb35fc4d9b3632cb82d\",\"title\":\"Ultrafast Video Attention Prediction with Coupled Knowledge Distillation\",\"url\":\"https://www.semanticscholar.org/paper/1b995069e1930fd9a2d87fb35fc4d9b3632cb82d\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145112355\",\"name\":\"Daniel S. Ferreira\"},{\"authorId\":\"2005560\",\"name\":\"G. Ramalho\"},{\"authorId\":\"89658165\",\"name\":\"D. Torres\"},{\"authorId\":\"143948090\",\"name\":\"A. H. G. Tobias\"},{\"authorId\":\"31434323\",\"name\":\"M. T. Rezende\"},{\"authorId\":\"145730933\",\"name\":\"F. Medeiros\"},{\"authorId\":\"49667365\",\"name\":\"Andrea G. C. Bianchi\"},{\"authorId\":\"143717689\",\"name\":\"C. Carneiro\"},{\"authorId\":\"1811543\",\"name\":\"D. Ushizima\"}],\"doi\":\"10.1016/j.cmpb.2019.105053\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1a2a5e8b15e5efa4ad54db2c4c3d6767cea6f2fb\",\"title\":\"Saliency-driven system models for cell analysis with deep learning\",\"url\":\"https://www.semanticscholar.org/paper/1a2a5e8b15e5efa4ad54db2c4c3d6767cea6f2fb\",\"venue\":\"Comput. Methods Programs Biomed.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2083603\",\"name\":\"Tianfei Zhou\"},{\"authorId\":\"47785924\",\"name\":\"Jianwu Li\"},{\"authorId\":\"9437193\",\"name\":\"Shunzhou Wang\"},{\"authorId\":\"47599902\",\"name\":\"R. Tao\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"}],\"doi\":\"10.1109/TIP.2020.3013162\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a633a8537a0e5d0ac28ea3dec36caae5777d9ce7\",\"title\":\"MATNet: Motion-Attentive Transition Network for Zero-Shot Video Object Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/a633a8537a0e5d0ac28ea3dec36caae5777d9ce7\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26937848\",\"name\":\"X. Feng\"},{\"authorId\":\"1692826961\",\"name\":\"Yao Liu\"},{\"authorId\":\"1504978364\",\"name\":\"Sheng Wei\"}],\"doi\":\"10.1109/VR46266.2020.1584727730619\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2a0729022af9291559e23a43917bf036c5593c2f\",\"title\":\"LiveDeep: Online Viewport Prediction for Live Virtual Reality Streaming Using Lifelong Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/2a0729022af9291559e23a43917bf036c5593c2f\",\"venue\":\"2020 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40257358\",\"name\":\"He Tang\"},{\"authorId\":\"2500502\",\"name\":\"Chuanbo Chen\"},{\"authorId\":\"31564288\",\"name\":\"Xiaobing Pei\"}],\"doi\":\"10.1007/s11042-016-4248-7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d2fa9a636794c9e1a353d883c08fd1b9af799171\",\"title\":\"Saliency detection from one time sampling for eye fixation prediction\",\"url\":\"https://www.semanticscholar.org/paper/d2fa9a636794c9e1a353d883c08fd1b9af799171\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"39380386\",\"name\":\"Jianwen Xie\"},{\"authorId\":\"37535930\",\"name\":\"Ming-Ming Cheng\"},{\"authorId\":\"1805398\",\"name\":\"Haibin Ling\"},{\"authorId\":\"51004202\",\"name\":\"A. Borji\"}],\"doi\":\"10.1109/TPAMI.2019.2924417\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"60782ad3f40d13fae19fbe26b6f7c0ac5011f83d\",\"title\":\"Revisiting Video Saliency Prediction in the Deep Learning Era\",\"url\":\"https://www.semanticscholar.org/paper/60782ad3f40d13fae19fbe26b6f7c0ac5011f83d\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2021},{\"arxivId\":\"1909.13240\",\"authors\":[{\"authorId\":\"29928742\",\"name\":\"Jialun Pei\"},{\"authorId\":\"153498894\",\"name\":\"H. Tang\"},{\"authorId\":\"70587110\",\"name\":\"Chao Liu\"},{\"authorId\":\"2500502\",\"name\":\"Chuanbo Chen\"}],\"doi\":\"10.1016/j.neucom.2020.04.022\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"573218b76b6873e4e4cd9cd160eff2bec0d598bb\",\"title\":\"Salient Instance Segmentation via Subitizing and Clustering\",\"url\":\"https://www.semanticscholar.org/paper/573218b76b6873e4e4cd9cd160eff2bec0d598bb\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"1805.01047\",\"authors\":[{\"authorId\":\"1805367\",\"name\":\"Sen Jia\"}],\"doi\":\"10.1016/j.imavis.2020.103887\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"49a94c25bcb323defe63796cf3afd52e2bfd8d48\",\"title\":\"EML-NET: An Expandable Multi-Layer NETwork for Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/49a94c25bcb323defe63796cf3afd52e2bfd8d48\",\"venue\":\"Image Vis. Comput.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3200442\",\"name\":\"A. Tsiami\"},{\"authorId\":\"2539459\",\"name\":\"Petros Koutras\"},{\"authorId\":\"2243473\",\"name\":\"Athanasios Katsamanis\"},{\"authorId\":\"46788705\",\"name\":\"A. Vatakis\"},{\"authorId\":\"1750686\",\"name\":\"P. Maragos\"}],\"doi\":\"10.1016/J.IMAGE.2019.05.001\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5cfa95cd409a47fbacce89c6a1df6d0410b810e5\",\"title\":\"A behaviorally inspired fusion approach for computational audiovisual saliency modeling\",\"url\":\"https://www.semanticscholar.org/paper/5cfa95cd409a47fbacce89c6a1df6d0410b810e5\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50313388\",\"name\":\"Y. Fang\"},{\"authorId\":\"50164924\",\"name\":\"Guanqun Ding\"},{\"authorId\":\"29451560\",\"name\":\"Wenying Wen\"},{\"authorId\":\"152443510\",\"name\":\"Feiniu Yuan\"},{\"authorId\":\"49308434\",\"name\":\"Y. Yang\"},{\"authorId\":\"35301080\",\"name\":\"Zhijun Fang\"},{\"authorId\":\"144968898\",\"name\":\"W. Lin\"}],\"doi\":\"10.1109/TIE.2019.2956418\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f1b7d823481fdf2442db36aae5e9d7abc299affd\",\"title\":\"Salient Object Detection by Spatiotemporal and Semantic Features in Real-Time Video Processing Systems\",\"url\":\"https://www.semanticscholar.org/paper/f1b7d823481fdf2442db36aae5e9d7abc299affd\",\"venue\":\"IEEE Transactions on Industrial Electronics\",\"year\":2020},{\"arxivId\":\"2007.12562\",\"authors\":[{\"authorId\":\"1832290473\",\"name\":\"Carola Figueroa-Flores\"},{\"authorId\":\"3262395\",\"name\":\"B. Raducanu\"},{\"authorId\":\"51925488\",\"name\":\"David Berga\"},{\"authorId\":\"2820687\",\"name\":\"Joost van de Weijer\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9452d851c2cc617d2e67515d409f6f608f4eac97\",\"title\":\"Hallucinating Saliency Maps for Fine-Grained Image Classification for Limited Data Domains\",\"url\":\"https://www.semanticscholar.org/paper/9452d851c2cc617d2e67515d409f6f608f4eac97\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1808.02564\",\"authors\":[{\"authorId\":\"40142302\",\"name\":\"T. Ehret\"},{\"authorId\":\"37634267\",\"name\":\"A. Davy\"},{\"authorId\":\"27053481\",\"name\":\"J. Morel\"},{\"authorId\":\"2346590\",\"name\":\"M. Delbracio\"}],\"doi\":\"10.1007/s10851-019-00885-0\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c8924e3265e3f16af3177e619cf68a5ef764442f\",\"title\":\"Image Anomalies: A Review and Synthesis of Detection Methods\",\"url\":\"https://www.semanticscholar.org/paper/c8924e3265e3f16af3177e619cf68a5ef764442f\",\"venue\":\"Journal of Mathematical Imaging and Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38111179\",\"name\":\"Siavash Gorji\"},{\"authorId\":\"47125588\",\"name\":\"James J. Clark\"}],\"doi\":\"10.1109/CVPR.2017.370\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9285f4a6a06e975bde3ae3267fccd971d4fff98a\",\"title\":\"Attentional Push: A Deep Convolutional Network for Augmenting Image Salience with Shared Attention Modeling in Social Scenes\",\"url\":\"https://www.semanticscholar.org/paper/9285f4a6a06e975bde3ae3267fccd971d4fff98a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145062693\",\"name\":\"Anh Nguyen\"},{\"authorId\":\"2656592\",\"name\":\"Zhisheng Yan\"}],\"doi\":\"10.1145/3304109.3325820\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"25488bb3a7d469d49822f8a27e779d7e963368a2\",\"title\":\"A saliency dataset for 360-degree videos\",\"url\":\"https://www.semanticscholar.org/paper/25488bb3a7d469d49822f8a27e779d7e963368a2\",\"venue\":\"MMSys\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48462171\",\"name\":\"Lu Zhang\"},{\"authorId\":\"1519062024\",\"name\":\"Jianming Zhang\"},{\"authorId\":\"2005172320\",\"name\":\"Zhe Lin\"},{\"authorId\":\"41193203\",\"name\":\"R. Mech\"},{\"authorId\":\"153176123\",\"name\":\"Huchuan Lu\"},{\"authorId\":\"2986047\",\"name\":\"You He\"}],\"doi\":\"10.1007/978-3-030-58568-6_29\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d0e7468e30d0be1bfacca5eb65499f95979c9253\",\"title\":\"Unsupervised Video Object Segmentation with Joint Hotspot Tracking\",\"url\":\"https://www.semanticscholar.org/paper/d0e7468e30d0be1bfacca5eb65499f95979c9253\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1801.07424\",\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"143929120\",\"name\":\"F. Guo\"},{\"authorId\":\"37535930\",\"name\":\"Ming-Ming Cheng\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":\"10.1109/CVPR.2018.00514\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"fdf8c9c4c30c6005c2f0e92ce9db3de5ab8b5d29\",\"title\":\"Revisiting Video Saliency: A Large-Scale Benchmark and a New Model\",\"url\":\"https://www.semanticscholar.org/paper/fdf8c9c4c30c6005c2f0e92ce9db3de5ab8b5d29\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1903.04047\",\"authors\":[{\"authorId\":\"143965164\",\"name\":\"Michael Xuelin Huang\"},{\"authorId\":\"3194727\",\"name\":\"Andreas Bulling\"}],\"doi\":\"10.1145/3317956.3321553\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c78358c34f3968a9306ade6c65116ac37046e166\",\"title\":\"SacCalib: reducing calibration distortion for stationary eye trackers using saccadic eye movements\",\"url\":\"https://www.semanticscholar.org/paper/c78358c34f3968a9306ade6c65116ac37046e166\",\"venue\":\"ETRA\",\"year\":2019},{\"arxivId\":\"1810.04456\",\"authors\":[{\"authorId\":\"1810382\",\"name\":\"Zhaohui Che\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"144826390\",\"name\":\"G. Zhai\"},{\"authorId\":\"2246414\",\"name\":\"Xiongkuo Min\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"be0d5d28fafe262e509a04b7fc7673d63f563747\",\"title\":\"Invariance Analysis of Saliency Models versus Human Gaze During Scene Free Viewing\",\"url\":\"https://www.semanticscholar.org/paper/be0d5d28fafe262e509a04b7fc7673d63f563747\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2003.05477\",\"authors\":[{\"authorId\":\"1430747783\",\"name\":\"Richard Droste\"},{\"authorId\":\"2840852\",\"name\":\"Jianbo Jiao\"},{\"authorId\":\"144870105\",\"name\":\"J. Noble\"}],\"doi\":\"10.1007/978-3-030-58558-7_25\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b01cb5c42ba693c84967bfd2ec94e420586164cc\",\"title\":\"Unified Image and Video Saliency Modeling\",\"url\":\"https://www.semanticscholar.org/paper/b01cb5c42ba693c84967bfd2ec94e420586164cc\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151071329\",\"name\":\"Kavita Chachadi\"},{\"authorId\":\"35351628\",\"name\":\"Vanraj Vala\"},{\"authorId\":\"153394743\",\"name\":\"Shilpa Kamath\"}],\"doi\":\"10.1007/978-981-15-5397-4_22\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"697464e3638c4801101f700f9d10631d25aef1e4\",\"title\":\"Empty Region Detection in an Image Using Deep Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/697464e3638c4801101f700f9d10631d25aef1e4\",\"venue\":\"\",\"year\":2021},{\"arxivId\":\"1810.05680\",\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"}],\"doi\":\"10.1007/978-1-4614-7320-6_100656-1\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"554fecc6cc5d0ca43cdde2eee30a9f819fe49ae6\",\"title\":\"Bottom-up Attention, Models of\",\"url\":\"https://www.semanticscholar.org/paper/554fecc6cc5d0ca43cdde2eee30a9f819fe49ae6\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144545118\",\"name\":\"Sheng Yang\"},{\"authorId\":\"144968899\",\"name\":\"W. Lin\"}],\"doi\":\"10.1117/12.2521507\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"73a3861710b7d89b5b702d49df5e7a2996ee2792\",\"title\":\"Predicting visual saliency via a dilated inception module-based model\",\"url\":\"https://www.semanticscholar.org/paper/73a3861710b7d89b5b702d49df5e7a2996ee2792\",\"venue\":\"Other Conferences\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410886873\",\"name\":\"Thomas P O'Connell\"},{\"authorId\":\"3286262\",\"name\":\"Marvin M. Chun\"}],\"doi\":\"10.1101/166421\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f065b9124f7873ce9d3330c93ee99e5e38aca2be\",\"title\":\"Predicting eye movements from deep neural network activity decoded from fMRI responses to natural scenes\",\"url\":\"https://www.semanticscholar.org/paper/f065b9124f7873ce9d3330c93ee99e5e38aca2be\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1901.01874\",\"authors\":[{\"authorId\":\"48355461\",\"name\":\"Yifei Huang\"},{\"authorId\":\"46947776\",\"name\":\"Zhenqiang Li\"},{\"authorId\":\"3172280\",\"name\":\"Minjie Cai\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1109/TIP.2020.3007841\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"78d95b989b807f28ef624318e3cb583ca1d73a3e\",\"title\":\"Mutual Context Network for Jointly Estimating Egocentric Gaze and Action\",\"url\":\"https://www.semanticscholar.org/paper/78d95b989b807f28ef624318e3cb583ca1d73a3e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1582477446\",\"name\":\"Yasser Abdelaziz Dahou Djilali\"},{\"authorId\":\"49863790\",\"name\":\"M. Sayah\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"}],\"doi\":\"10.5220/0008875600270036\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"43cdf14f35966eab2d0e3418cea53715342cfce0\",\"title\":\"3DSAL: An Efficient 3D-CNN Architecture for Video Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/43cdf14f35966eab2d0e3418cea53715342cfce0\",\"venue\":\"VISIGRAPP\",\"year\":2020},{\"arxivId\":\"1812.08848\",\"authors\":[{\"authorId\":\"4218304\",\"name\":\"C. Wloka\"},{\"authorId\":\"3211787\",\"name\":\"Toni Kunic\"},{\"authorId\":\"3468296\",\"name\":\"Iuliia Kotseruba\"},{\"authorId\":\"52349494\",\"name\":\"Ramin Fahimi\"},{\"authorId\":\"27737461\",\"name\":\"Nicholas Frosst\"},{\"authorId\":\"2866780\",\"name\":\"Neil D. B. Bruce\"},{\"authorId\":\"1727853\",\"name\":\"John K. Tsotsos\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"6b8a26d45c8f1c058a4454792d7c43c05ca5f76a\",\"title\":\"SMILER: Saliency Model Implementation Library for Experimental Research\",\"url\":\"https://www.semanticscholar.org/paper/6b8a26d45c8f1c058a4454792d7c43c05ca5f76a\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22206915\",\"name\":\"Marc Assens\"},{\"authorId\":\"3100480\",\"name\":\"Xavier Giro-i-Nieto\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"}],\"doi\":\"10.1016/j.image.2018.06.006\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e3510517f900dce12167622c5da0656ecfc39b14\",\"title\":\"Scanpath and saliency prediction on 360 degree images\",\"url\":\"https://www.semanticscholar.org/paper/e3510517f900dce12167622c5da0656ecfc39b14\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150358307\",\"name\":\"Zhuanghui Wu\"},{\"authorId\":\"144354728\",\"name\":\"M. Meng\"},{\"authorId\":\"1737844\",\"name\":\"J. Wu\"}],\"doi\":\"10.1007/s11063-020-10201-2\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"13af7ffba51eb9e6e789163bb02483b5dabf470b\",\"title\":\"Visual Sentiment Prediction with Attribute Augmentation and Multi-attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/13af7ffba51eb9e6e789163bb02483b5dabf470b\",\"venue\":\"Neural Processing Letters\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50333150\",\"name\":\"Ning Zhuang\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"5925215\",\"name\":\"Y. Xu\"},{\"authorId\":\"50031361\",\"name\":\"X. Yang\"},{\"authorId\":\"144913615\",\"name\":\"W. Zhang\"},{\"authorId\":\"46948132\",\"name\":\"Zefan Li\"},{\"authorId\":\"101001846\",\"name\":\"Wen Gao\"}],\"doi\":\"10.1109/TCSVT.2019.2940479\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"db2d2b1b4fbf791157bf094530fc22d3f4f79344\",\"title\":\"MUGGLE: MUlti-Stream Group Gaze Learning and Estimation\",\"url\":\"https://www.semanticscholar.org/paper/db2d2b1b4fbf791157bf094530fc22d3f4f79344\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47420847\",\"name\":\"Lai Jiang\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"92349749\",\"name\":\"T. Liu\"},{\"authorId\":\"27647516\",\"name\":\"Minglang Qiao\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"}],\"doi\":\"10.1007/978-3-030-01264-9_37\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"184ffa4a4c36051de56e07d785e5b53928d8c472\",\"title\":\"DeepVS: A Deep Learning Based Video Saliency Prediction Approach\",\"url\":\"https://www.semanticscholar.org/paper/184ffa4a4c36051de56e07d785e5b53928d8c472\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145076397\",\"name\":\"Yun Ren\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"79439415\",\"name\":\"Haoyu Dong\"},{\"authorId\":\"2560900\",\"name\":\"Shengxi Li\"}],\"doi\":\"10.1109/CVPRW.2017.208\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f7d81091f909f718425eb428336ff72de5f3ad0e\",\"title\":\"Learning Dynamic GMM for Attention Distribution on Single-Face Videos\",\"url\":\"https://www.semanticscholar.org/paper/f7d81091f909f718425eb428336ff72de5f3ad0e\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":\"1510.02927\",\"authors\":[{\"authorId\":\"1784761\",\"name\":\"S. Kruthiventi\"},{\"authorId\":\"50430041\",\"name\":\"Kumar Ayush\"},{\"authorId\":\"144682140\",\"name\":\"R. Venkatesh Babu\"}],\"doi\":\"10.1109/TIP.2017.2710620\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1295cbaf3b03de2eb8c79530289f5939d7819e5c\",\"title\":\"DeepFix: A Fully Convolutional Neural Network for Predicting Human Eye Fixations\",\"url\":\"https://www.semanticscholar.org/paper/1295cbaf3b03de2eb8c79530289f5939d7819e5c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":\"1603.08199\",\"authors\":[{\"authorId\":\"1809420\",\"name\":\"Loris Bazzani\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f3158ce4e1c9e908e7d06533d711d84205c973b9\",\"title\":\"Recurrent Mixture Density Network for Spatiotemporal Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/f3158ce4e1c9e908e7d06533d711d84205c973b9\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"88725812\",\"name\":\"Robert G. Alexander\"},{\"authorId\":\"36009845\",\"name\":\"S. Waite\"},{\"authorId\":\"1969116\",\"name\":\"S. Macknik\"},{\"authorId\":\"1397397140\",\"name\":\"S. Martinez-Conde\"}],\"doi\":\"10.1167/jov.20.10.17\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3e6b37ff676a367a107613dbdd44a694f7416704\",\"title\":\"What do radiologists look for? Advances and limitations of perceptual learning in radiologic search\",\"url\":\"https://www.semanticscholar.org/paper/3e6b37ff676a367a107613dbdd44a694f7416704\",\"venue\":\"Journal of vision\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30469750\",\"name\":\"Qiuxia Lai\"},{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145947590\",\"name\":\"Hanqiu Sun\"},{\"authorId\":\"11901550\",\"name\":\"J. Shen\"}],\"doi\":\"10.1109/TIP.2019.2936112\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"be34dd48c374b0313db1f0b70347464cbe0b8f22\",\"title\":\"Video Saliency Prediction Using Spatiotemporal Residual Attentive Networks\",\"url\":\"https://www.semanticscholar.org/paper/be34dd48c374b0313db1f0b70347464cbe0b8f22\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1808.00262\",\"authors\":[{\"authorId\":\"6475449\",\"name\":\"C. Flores\"},{\"authorId\":\"1403268002\",\"name\":\"Abel Gonzalez-Garcia\"},{\"authorId\":\"2820687\",\"name\":\"Joost van de Weijer\"},{\"authorId\":\"3262395\",\"name\":\"B. Raducanu\"}],\"doi\":\"10.1016/j.patcog.2019.05.002\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"3efc9872196e4b0bcb2e0d7b26581eb8db097469\",\"title\":\"Saliency for Fine-grained Object Recognition in Domains with Scarce Training Data\",\"url\":\"https://www.semanticscholar.org/paper/3efc9872196e4b0bcb2e0d7b26581eb8db097469\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":\"1609.01064\",\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/ICPR.2016.7900174\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"57e143c96a41ba81d9d59120a1cd0dc04905d3f1\",\"title\":\"A deep multi-level network for saliency prediction\",\"url\":\"https://www.semanticscholar.org/paper/57e143c96a41ba81d9d59120a1cd0dc04905d3f1\",\"venue\":\"2016 23rd International Conference on Pattern Recognition (ICPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144645142\",\"name\":\"M. Jiang\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1109/ICCV.2017.354\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"034cf7f98153dada78bcffc72ed5a13890482a94\",\"title\":\"Learning Visual Attention to Identify People with Autism Spectrum Disorder\",\"url\":\"https://www.semanticscholar.org/paper/034cf7f98153dada78bcffc72ed5a13890482a94\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50543166\",\"name\":\"Anne-Flore Perrin\"},{\"authorId\":\"47058954\",\"name\":\"L. Zhang\"},{\"authorId\":\"1789744\",\"name\":\"O. Meur\"}],\"doi\":\"10.1007/978-3-030-29888-3_25\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3f7c9f176df06cf0ec30091ad41d6b8c1ac09384\",\"title\":\"How Well Current Saliency Prediction Models Perform on UAVs Videos?\",\"url\":\"https://www.semanticscholar.org/paper/3f7c9f176df06cf0ec30091ad41d6b8c1ac09384\",\"venue\":\"CAIP\",\"year\":2019},{\"arxivId\":\"1705.03854\",\"authors\":[{\"authorId\":\"38772386\",\"name\":\"A. Palazzi\"},{\"authorId\":\"3309130\",\"name\":\"Davide Abati\"},{\"authorId\":\"2175529\",\"name\":\"Simone Calderara\"},{\"authorId\":\"2059900\",\"name\":\"Francesco Solera\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/TPAMI.2018.2845370\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"914e98db74f29fc608106ff438edde58965037c5\",\"title\":\"Predicting the Driver's Focus of Attention: The DR(eye)VE Project\",\"url\":\"https://www.semanticscholar.org/paper/914e98db74f29fc608106ff438edde58965037c5\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"3309130\",\"name\":\"Davide Abati\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"38772386\",\"name\":\"A. Palazzi\"},{\"authorId\":\"2175529\",\"name\":\"Simone Calderara\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.3233/IA-170033\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9ac1df835f755b5fe73d39a946a50df1e87e554a\",\"title\":\"Attentive models in vision: Computing saliency maps in the deep learning era\",\"url\":\"https://www.semanticscholar.org/paper/9ac1df835f755b5fe73d39a946a50df1e87e554a\",\"venue\":\"Intelligenza Artificiale\",\"year\":2018},{\"arxivId\":\"1712.02048\",\"authors\":[{\"authorId\":\"51484264\",\"name\":\"Shivanthan A.C. Yohanandan\"},{\"authorId\":\"2483748\",\"name\":\"A. Dyer\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\"},{\"authorId\":\"49077845\",\"name\":\"Andy Song\"}],\"doi\":\"10.1007/978-3-030-01231-1_15\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c07aed544463018e6afdb0cffa6ad1aa98fa6c98\",\"title\":\"Saliency Preservation in Low-Resolution Grayscale Images\",\"url\":\"https://www.semanticscholar.org/paper/c07aed544463018e6afdb0cffa6ad1aa98fa6c98\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7509100\",\"name\":\"S. B. Rangrej\"},{\"authorId\":\"1790095\",\"name\":\"J. Sivaswamy\"}],\"doi\":\"10.1117/1.JMI.4.2.024503\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2c7200bbf99c48d73a32f6b91da71629a744a519\",\"title\":\"Assistive lesion-emphasis system: an assistive system for fundus image readers\",\"url\":\"https://www.semanticscholar.org/paper/2c7200bbf99c48d73a32f6b91da71629a744a519\",\"venue\":\"Journal of medical imaging\",\"year\":2017},{\"arxivId\":\"1707.06436\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":null,\"name\":\"Yun He\"},{\"authorId\":\"9935341\",\"name\":\"S. Ueta\"},{\"authorId\":\"5014206\",\"name\":\"T. Suzuki\"},{\"authorId\":\"49897653\",\"name\":\"K. Abe\"},{\"authorId\":\"2554424\",\"name\":\"Asako Kanezaki\"},{\"authorId\":\"49133490\",\"name\":\"Shinichiro Morita\"},{\"authorId\":\"22219521\",\"name\":\"Toshiyuki Yabe\"},{\"authorId\":\"50544018\",\"name\":\"Yoshihiro Kanehara\"},{\"authorId\":\"22174281\",\"name\":\"Hiroya Yatsuyanagi\"},{\"authorId\":\"1692565\",\"name\":\"S. Maruyama\"},{\"authorId\":\"10756539\",\"name\":\"Ryousuke Takasawa\"},{\"authorId\":\"3217653\",\"name\":\"Masataka Fuchida\"},{\"authorId\":\"2642022\",\"name\":\"Y. Miyashita\"},{\"authorId\":\"34935749\",\"name\":\"Kazushige Okayasu\"},{\"authorId\":\"20505300\",\"name\":\"Yuta Matsuzaki\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"title\":\"cvpaper.challenge in 2016: Futuristic Computer Vision through 1, 600 Papers Survey\",\"url\":\"https://www.semanticscholar.org/paper/8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"2035969\",\"name\":\"S. Pini\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1007/978-3-319-73165-0_17\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a14e113d5e31defec38f2233d0783d8c97b4a62a\",\"title\":\"Automatic Image Cropping and Selection Using Saliency: An Application to Historical Manuscripts\",\"url\":\"https://www.semanticscholar.org/paper/a14e113d5e31defec38f2233d0783d8c97b4a62a\",\"venue\":\"IRCDL\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1810382\",\"name\":\"Zhaohui Che\"},{\"authorId\":\"51004202\",\"name\":\"A. Borji\"},{\"authorId\":\"144826390\",\"name\":\"G. Zhai\"},{\"authorId\":\"2246414\",\"name\":\"Xiongkuo Min\"},{\"authorId\":\"1822413\",\"name\":\"Guodong Guo\"},{\"authorId\":\"1776651\",\"name\":\"P. Callet\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ad0b345436e8a2d507fbcd7e6477deb399a062a4\",\"title\":\"GazeGAN: A Generative Adversarial Saliency Model based on Invariance Analysis of Human Gaze During Scene Free Viewing\",\"url\":\"https://www.semanticscholar.org/paper/ad0b345436e8a2d507fbcd7e6477deb399a062a4\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1917344125\",\"name\":\"Samad Zabihi\"},{\"authorId\":\"2772489\",\"name\":\"Eghbal G. Mansoori\"},{\"authorId\":\"145105283\",\"name\":\"M. Yazdi\"}],\"doi\":\"10.1016/J.JVCIR.2020.102931\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"20bcfc052b6f47b0eeead32d43c3f7c0bee0a26b\",\"title\":\"Exploiting object features in deep gaze prediction models\",\"url\":\"https://www.semanticscholar.org/paper/20bcfc052b6f47b0eeead32d43c3f7c0bee0a26b\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1843795\",\"name\":\"Lorenzo Baraldi\"},{\"authorId\":\"145518528\",\"name\":\"G. Serra\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"96fdc0131dc80ffa6d7b9c526e07f080414c54ec\",\"title\":\"1 Paying More A ention to Saliency : Image Captioning with Saliency and Context A ention\",\"url\":\"https://www.semanticscholar.org/paper/96fdc0131dc80ffa6d7b9c526e07f080414c54ec\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"73242412\",\"name\":\"Kristina Landino\"},{\"authorId\":\"34219104\",\"name\":\"Murray H. Loew\"}],\"doi\":\"10.1117/12.2293787\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"571e9398e6d68e3d2acdce072e2cbd2cf54e2310\",\"title\":\"Comparing salience detection algorithms in mammograms\",\"url\":\"https://www.semanticscholar.org/paper/571e9398e6d68e3d2acdce072e2cbd2cf54e2310\",\"venue\":\"Medical Imaging\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1490938524\",\"name\":\"Hongwei Sun\"}],\"doi\":\"10.1109/SPAC46244.2018.8965532\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9fb42d7c969cf8ffbab43a6b68661b4b7172fe59\",\"title\":\"End to End Background Subtraction by Deep Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/9fb42d7c969cf8ffbab43a6b68661b4b7172fe59\",\"venue\":\"2018 International Conference on Security, Pattern Analysis, and Cybernetics (SPAC)\",\"year\":2018},{\"arxivId\":\"1712.06492\",\"authors\":[{\"authorId\":\"1891828\",\"name\":\"Leon A. Gatys\"},{\"authorId\":\"2997408\",\"name\":\"Matthias K\\u00fcmmerer\"},{\"authorId\":\"49737748\",\"name\":\"Thomas S. A. Wallis\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0fb277156823934efb1bd00b9143b88040fb1986\",\"title\":\"Guiding human gaze with convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/0fb277156823934efb1bd00b9143b88040fb1986\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145129042\",\"name\":\"K. Huang\"},{\"authorId\":\"1702868\",\"name\":\"Shenghua Gao\"}],\"doi\":\"10.1007/s00371-019-01734-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"860121e16429c677bb584eb3d650beb0e0551c22\",\"title\":\"Image saliency detection via multi-scale iterative CNN\",\"url\":\"https://www.semanticscholar.org/paper/860121e16429c677bb584eb3d650beb0e0551c22\",\"venue\":\"The Visual Computer\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5784351\",\"name\":\"Y. Yang\"},{\"authorId\":\"1869700\",\"name\":\"Shengjie Jiao\"},{\"authorId\":\"8516282\",\"name\":\"Jinrong He\"},{\"authorId\":\"20660760\",\"name\":\"B. Xia\"},{\"authorId\":\"1492113534\",\"name\":\"Jiabo Li\"},{\"authorId\":\"48676117\",\"name\":\"R. Xiao\"}],\"doi\":\"10.1016/j.future.2020.05.016\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6eb9d829b9edb98aed3131b2937518e3ebc7c3f8\",\"title\":\"Image retrieval via learning content-based deep quality model towards big data\",\"url\":\"https://www.semanticscholar.org/paper/6eb9d829b9edb98aed3131b2937518e3ebc7c3f8\",\"venue\":\"Future Gener. Comput. Syst.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2860038\",\"name\":\"Pierre Marighetto\"},{\"authorId\":\"30170254\",\"name\":\"I. Abdelkader\"},{\"authorId\":\"49031335\",\"name\":\"S. Duzelier\"},{\"authorId\":\"3265104\",\"name\":\"M. Decombas\"},{\"authorId\":\"2989773\",\"name\":\"Nicolas Riche\"},{\"authorId\":\"34913672\",\"name\":\"J\\u00e9r\\u00e9mie Jakubowicz\"},{\"authorId\":\"1681157\",\"name\":\"M. Mancas\"},{\"authorId\":\"50276543\",\"name\":\"B. Gosselin\"},{\"authorId\":\"2035718\",\"name\":\"R. Lagani\\u00e8re\"}],\"doi\":\"10.1109/ICIP.2016.7532866\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a93534f8bd1304cc3311b54321cdd3f60a609a41\",\"title\":\"FUNNRAR: Hybrid rarity/learning visual saliency\",\"url\":\"https://www.semanticscholar.org/paper/a93534f8bd1304cc3311b54321cdd3f60a609a41\",\"venue\":\"2016 IEEE International Conference on Image Processing (ICIP)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/ICMEW.2017.8026277\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"88a9504f6a1e9b6b56393fde313fc0076e0f27b3\",\"title\":\"Visual saliency for image captioning in new multimedia services\",\"url\":\"https://www.semanticscholar.org/paper/88a9504f6a1e9b6b56393fde313fc0076e0f27b3\",\"venue\":\"2017 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2017},{\"arxivId\":\"1811.10004\",\"authors\":[{\"authorId\":\"21319564\",\"name\":\"J. Li\"},{\"authorId\":\"2966504\",\"name\":\"Daowei Li\"},{\"authorId\":\"1967201\",\"name\":\"Kui Fu\"},{\"authorId\":\"1690940\",\"name\":\"L. Xu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6d17074e5b6a6b2e92141560479ad4ab5eb66af5\",\"title\":\"Visual Attention on the Sun: What Do Existing Models Actually Predict?\",\"url\":\"https://www.semanticscholar.org/paper/6d17074e5b6a6b2e92141560479ad4ab5eb66af5\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"3309130\",\"name\":\"Davide Abati\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"38772386\",\"name\":\"A. Palazzi\"},{\"authorId\":\"2175529\",\"name\":\"Simone Calderara\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8ed04802b462f6b10865251acdc9b718dfa57f1b\",\"title\":\"Attentive Models in Vision 3 Input Image Human Fixation Map Loss Function Final Convolutional Layers Learned Prior Low , Medium and High Level Features Predicted Saliency Map Fully Convolutional Network\",\"url\":\"https://www.semanticscholar.org/paper/8ed04802b462f6b10865251acdc9b718dfa57f1b\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4218304\",\"name\":\"C. Wloka\"},{\"authorId\":\"3468296\",\"name\":\"Iuliia Kotseruba\"},{\"authorId\":\"1727853\",\"name\":\"John K. Tsotsos\"}],\"doi\":\"10.1109/CVPR.2018.00336\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"dddef2c9c6d8b38a7eba838f801e0855d50c85a4\",\"title\":\"Active Fixation Control to Predict Saccade Sequences\",\"url\":\"https://www.semanticscholar.org/paper/dddef2c9c6d8b38a7eba838f801e0855d50c85a4\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19269060\",\"name\":\"Huiyu Duan\"},{\"authorId\":\"2246414\",\"name\":\"Xiongkuo Min\"},{\"authorId\":\"47291418\",\"name\":\"Yi Fang\"},{\"authorId\":\"144509573\",\"name\":\"Lei Fan\"},{\"authorId\":\"50031361\",\"name\":\"X. Yang\"},{\"authorId\":\"13903793\",\"name\":\"Guangtao Zhai\"}],\"doi\":\"10.1145/3337066\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e01f0475ac9a96da307b2b10778ab6c9283381fb\",\"title\":\"Visual Attention Analysis and Prediction on Human Faces for Children with Autism Spectrum Disorder\",\"url\":\"https://www.semanticscholar.org/paper/e01f0475ac9a96da307b2b10778ab6c9283381fb\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1711.06406\",\"authors\":[{\"authorId\":\"27678837\",\"name\":\"Y. Xia\"},{\"authorId\":\"46334890\",\"name\":\"Danqing Zhang\"},{\"authorId\":\"2569534\",\"name\":\"J. Kim\"},{\"authorId\":\"50605758\",\"name\":\"K. Nakayama\"},{\"authorId\":\"2769532\",\"name\":\"K. Zipser\"},{\"authorId\":\"143659729\",\"name\":\"D. Whitney\"}],\"doi\":\"10.1007/978-3-030-20873-8_42\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"43385e3cb891f34a0bf3b4fb0afde1fd21cf28e9\",\"title\":\"Predicting Driver Attention in Critical Situations\",\"url\":\"https://www.semanticscholar.org/paper/43385e3cb891f34a0bf3b4fb0afde1fd21cf28e9\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"1705.02544\",\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"}],\"doi\":\"10.1109/TIP.2017.2787612\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"65c1a8cde4030217bec7cb96b8bf94c5321e8d8e\",\"title\":\"Deep Visual Attention Prediction\",\"url\":\"https://www.semanticscholar.org/paper/65c1a8cde4030217bec7cb96b8bf94c5321e8d8e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":\"1610.01708\",\"authors\":[{\"authorId\":\"145021890\",\"name\":\"N. Liu\"},{\"authorId\":\"7181955\",\"name\":\"J. Han\"}],\"doi\":\"10.1109/TIP.2018.2817047\",\"intent\":[\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"40bc3b9cfe74a4f164e53bf2e037e61256f8d354\",\"title\":\"A Deep Spatial Contextual Long-Term Recurrent Convolutional Network for Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/40bc3b9cfe74a4f164e53bf2e037e61256f8d354\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":\"2003.06045\",\"authors\":[{\"authorId\":\"47295036\",\"name\":\"Zehua Zhang\"},{\"authorId\":\"1947383\",\"name\":\"Ashish Tawari\"},{\"authorId\":\"1841835\",\"name\":\"Sujitha Martin\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"}],\"doi\":\"10.1109/ICRA40945.2020.9197104\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb51e17fc3e88c759ea3d41c9099e22ae7397e85\",\"title\":\"Interaction Graphs for Object Importance Estimation in On-road Driving Videos\",\"url\":\"https://www.semanticscholar.org/paper/eb51e17fc3e88c759ea3d41c9099e22ae7397e85\",\"venue\":\"2020 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21007367\",\"name\":\"K. T. Ma\"},{\"authorId\":\"35718875\",\"name\":\"L. Li\"},{\"authorId\":\"15450116\",\"name\":\"Peilun Dai\"},{\"authorId\":\"6516914\",\"name\":\"J. Lim\"},{\"authorId\":\"3329744\",\"name\":\"Chengyao Shen\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1109/ICIP.2017.8296927\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"92235c1c8d94fb3adbab40e51f94d583dd3d367f\",\"title\":\"Multi-layer linear model for top-down modulation of visual attention in natural egocentric vision\",\"url\":\"https://www.semanticscholar.org/paper/92235c1c8d94fb3adbab40e51f94d583dd3d367f\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27651985\",\"name\":\"Austin Le\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"0de58d1192a0a844738ca0dd919f0c1cd743576f\",\"title\":\"Predicting Visual Saliency : Where Do People Look ?\",\"url\":\"https://www.semanticscholar.org/paper/0de58d1192a0a844738ca0dd919f0c1cd743576f\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6482830\",\"name\":\"T. Akram\"},{\"authorId\":\"37441280\",\"name\":\"S. Naqvi\"},{\"authorId\":\"10954707\",\"name\":\"S. Haider\"},{\"authorId\":\"2006452\",\"name\":\"M. Kamran\"}],\"doi\":\"10.1016/j.compeleceng.2017.02.020\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7ce2080b4ff8ab4975700055298e2c7b3d404c77\",\"title\":\"Towards real-time crops surveillance for disease classification: exploiting parallelism in computer vision\",\"url\":\"https://www.semanticscholar.org/paper/7ce2080b4ff8ab4975700055298e2c7b3d404c77\",\"venue\":\"Comput. Electr. Eng.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71670265\",\"name\":\"Weiqian Liu\"},{\"authorId\":\"46674323\",\"name\":\"Yunfeng Sui\"},{\"authorId\":\"37203857\",\"name\":\"L. Meng\"},{\"authorId\":\"145070239\",\"name\":\"Z. Cheng\"},{\"authorId\":\"47601467\",\"name\":\"Shixuan Zhao\"}],\"doi\":\"10.1109/ITNEC.2019.8729365\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b59fd61c89153802b6f4622f7b1b09e1b658ef63\",\"title\":\"Multiscope Contextual Information for Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/b59fd61c89153802b6f4622f7b1b09e1b658ef63\",\"venue\":\"2019 IEEE 3rd Information Technology, Networking, Electronic and Automation Control Conference (ITNEC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2822290\",\"name\":\"Suraj Srinivas\"},{\"authorId\":\"1730952\",\"name\":\"Ravi Kiran Sarvadevabhatla\"},{\"authorId\":\"2217000\",\"name\":\"Konda Reddy Mopuri\"},{\"authorId\":\"40390520\",\"name\":\"N. Prabhu\"},{\"authorId\":\"1784761\",\"name\":\"S. Kruthiventi\"},{\"authorId\":\"144682140\",\"name\":\"R. Venkatesh Babu\"}],\"doi\":\"10.1016/B978-0-12-810408-8.00003-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"783cd91797aad234b1558099689e794b48694092\",\"title\":\"An Introduction to Deep Convolutional Neural Nets for Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/783cd91797aad234b1558099689e794b48694092\",\"venue\":\"Deep Learning for Medical Image Analysis\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3486445\",\"name\":\"Guillaume Lio\"},{\"authorId\":\"5615932\",\"name\":\"R. Fadda\"},{\"authorId\":\"3804703\",\"name\":\"G. Doneddu\"},{\"authorId\":\"50117547\",\"name\":\"J. Duhamel\"},{\"authorId\":\"2643325\",\"name\":\"A. Sirigu\"}],\"doi\":\"10.1038/s41467-019-13285-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ddfa5afa2f18715619946bf0b99633849412d89d\",\"title\":\"Digit-tracking as a new tactile interface for visual perception analysis\",\"url\":\"https://www.semanticscholar.org/paper/ddfa5afa2f18715619946bf0b99633849412d89d\",\"venue\":\"Nature Communications\",\"year\":2019},{\"arxivId\":\"1807.05511\",\"authors\":[{\"authorId\":\"33698309\",\"name\":\"Zhong-Qiu Zhao\"},{\"authorId\":\"144528245\",\"name\":\"P. Zheng\"},{\"authorId\":\"51132438\",\"name\":\"Shou-tao Xu\"},{\"authorId\":\"1748808\",\"name\":\"X. Wu\"}],\"doi\":\"10.1109/TNNLS.2018.2876865\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7998468d99ab07bb982294d1c9b53a3bf3934fa6\",\"title\":\"Object Detection With Deep Learning: A Review\",\"url\":\"https://www.semanticscholar.org/paper/7998468d99ab07bb982294d1c9b53a3bf3934fa6\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7974268\",\"name\":\"Linzhao Wang\"},{\"authorId\":\"145131953\",\"name\":\"L. Wang\"},{\"authorId\":\"1790976\",\"name\":\"H. Lu\"},{\"authorId\":\"48754192\",\"name\":\"Pingping Zhang\"},{\"authorId\":\"144526777\",\"name\":\"X. Ruan\"}],\"doi\":\"10.1109/TPAMI.2018.2846598\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"55e0b7cae68a817d91756d02c7eb04a7079d7b5a\",\"title\":\"Salient Object Detection with Recurrent Fully Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/55e0b7cae68a817d91756d02c7eb04a7079d7b5a\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2418491\",\"name\":\"M. Zhang\"},{\"authorId\":\"21007367\",\"name\":\"K. T. Ma\"},{\"authorId\":\"153239355\",\"name\":\"J. H. Lim\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":\"10.1109/CVPR.2017.377\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f95e349489aa48fc57494aab101d58c496cc35f5\",\"title\":\"Deep Future Gaze: Gaze Anticipation on Egocentric Videos Using Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/f95e349489aa48fc57494aab101d58c496cc35f5\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4639656\",\"name\":\"Y. Fang\"},{\"authorId\":\"50164924\",\"name\":\"Guanqun Ding\"},{\"authorId\":null,\"name\":\"Jia Li\"},{\"authorId\":\"35301080\",\"name\":\"Zhijun Fang\"}],\"doi\":\"10.1109/TIP.2018.2885229\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6f2f48d03ed81c79b23ea68fced0ca1492036e98\",\"title\":\"Deep3DSaliency: Deep Stereoscopic Video Saliency Detection Model by 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/6f2f48d03ed81c79b23ea68fced0ca1492036e98\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1819851387\",\"name\":\"Alessandro Bruno\"},{\"authorId\":\"27053388\",\"name\":\"Francesco Gugliuzza\"},{\"authorId\":\"1720275\",\"name\":\"R. Pirrone\"},{\"authorId\":\"98705023\",\"name\":\"E. Ardizzone\"}],\"doi\":\"10.1109/ACCESS.2020.3006700\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1a4a5c24c2ee500819b81da6dd07483ef4112846\",\"title\":\"A Multi-Scale Colour and Keypoint Density-Based Approach for Visual Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/1a4a5c24c2ee500819b81da6dd07483ef4112846\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2001.00292\",\"authors\":[{\"authorId\":\"29874425\",\"name\":\"Jyun-Ruei Chen\"},{\"authorId\":\"2163097\",\"name\":\"Huihui Song\"},{\"authorId\":\"11735382\",\"name\":\"K. Zhang\"},{\"authorId\":\"35954057\",\"name\":\"Bo Liu\"},{\"authorId\":\"143960771\",\"name\":\"Qingshan Liu\"}],\"doi\":\"10.1016/j.patcog.2020.107615\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"866cedefb15e4a4a3f1b1cf3b9bd844654eb6af1\",\"title\":\"Video Saliency Prediction Using Enhanced Spatiotemporal Alignment Network\",\"url\":\"https://www.semanticscholar.org/paper/866cedefb15e4a4a3f1b1cf3b9bd844654eb6af1\",\"venue\":\"Pattern Recognit.\",\"year\":2021},{\"arxivId\":\"1904.04992\",\"authors\":[{\"authorId\":null,\"name\":\"Jia Li\"},{\"authorId\":\"1967201\",\"name\":\"Kui Fu\"},{\"authorId\":\"152836873\",\"name\":\"Shengwei Zhao\"},{\"authorId\":\"39646508\",\"name\":\"Shiming Ge\"}],\"doi\":\"10.1109/TIP.2019.2946102\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3f76324a4a26ff3d9097642676878aa7b1122581\",\"title\":\"Spatiotemporal Knowledge Distillation for Efficient Estimation of Aerial Video Saliency\",\"url\":\"https://www.semanticscholar.org/paper/3f76324a4a26ff3d9097642676878aa7b1122581\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46550490\",\"name\":\"Cai Lile\"},{\"authorId\":\"48034429\",\"name\":\"Li Yi-qun\"}],\"doi\":\"10.1109/ICIP.2017.8296692\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b07a01e3d5989316cf9204622463dedffd7bc128\",\"title\":\"Anomaly detection in thermal images using deep neural networks\",\"url\":\"https://www.semanticscholar.org/paper/b07a01e3d5989316cf9204622463dedffd7bc128\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40142302\",\"name\":\"T. Ehret\"},{\"authorId\":\"37634267\",\"name\":\"A. Davy\"},{\"authorId\":\"2346590\",\"name\":\"M. Delbracio\"},{\"authorId\":\"27053481\",\"name\":\"J. Morel\"}],\"doi\":\"10.5201/ipol.2019.263\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8ea22449703c0b9c1b949ed3190d2ca3a47ed1bd\",\"title\":\"How to Reduce Anomaly Detection in Images to Anomaly Detection in Noise\",\"url\":\"https://www.semanticscholar.org/paper/8ea22449703c0b9c1b949ed3190d2ca3a47ed1bd\",\"venue\":\"Image Process. Line\",\"year\":2019},{\"arxivId\":\"1904.01231\",\"authors\":[{\"authorId\":\"1810382\",\"name\":\"Zhaohui Che\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"144826390\",\"name\":\"G. Zhai\"},{\"authorId\":\"23993939\",\"name\":\"Suiyi Ling\"},{\"authorId\":\"1822413\",\"name\":\"Guodong Guo\"},{\"authorId\":\"1776651\",\"name\":\"P. Callet\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d32715b0e3fa60115823a61a2eb7a5ba0cdcc247\",\"title\":\"Adversarial Attacks against Deep Saliency Models\",\"url\":\"https://www.semanticscholar.org/paper/d32715b0e3fa60115823a61a2eb7a5ba0cdcc247\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2576295\",\"name\":\"Chen-Ping Yu\"},{\"authorId\":\"49957558\",\"name\":\"Huidong Liu\"},{\"authorId\":\"48801624\",\"name\":\"D. Samaras\"},{\"authorId\":\"1696991\",\"name\":\"G. Zelinsky\"}],\"doi\":\"10.1080/13506285.2019.1661927\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"be35317a1196d46bb44207f8d5a41ac4b70938b8\",\"title\":\"Modelling attention control using a convolutional neural network designed after the ventral visual pathway\",\"url\":\"https://www.semanticscholar.org/paper/be35317a1196d46bb44207f8d5a41ac4b70938b8\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47968942\",\"name\":\"K. Zhang\"},{\"authorId\":\"3332324\",\"name\":\"X. Zhao\"},{\"authorId\":\"47378234\",\"name\":\"R. Mo\"}],\"doi\":\"10.1007/978-3-030-00563-4_44\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bdd4e7be19d1942937f803aad1ffc69b5c4eaeb5\",\"title\":\"Bottom-Up Saliency Prediction by Simulating End-Stopping with Log-Gabor\",\"url\":\"https://www.semanticscholar.org/paper/bdd4e7be19d1942937f803aad1ffc69b5c4eaeb5\",\"venue\":\"BICS\",\"year\":2018},{\"arxivId\":\"1808.09559\",\"authors\":[{\"authorId\":\"51244663\",\"name\":\"Panagiotis Linardos\"},{\"authorId\":\"2890278\",\"name\":\"Eva Mohedano\"},{\"authorId\":\"51245064\",\"name\":\"M. Cherto\"},{\"authorId\":\"1737981\",\"name\":\"C. Gurrin\"},{\"authorId\":\"1398090762\",\"name\":\"Xavier Gir\\u00f3-i-Nieto\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cf664deef0dbd74d4a7abf744560fe03bf90e863\",\"title\":\"Temporal Saliency Adaptation in Egocentric Videos\",\"url\":\"https://www.semanticscholar.org/paper/cf664deef0dbd74d4a7abf744560fe03bf90e863\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27343041\",\"name\":\"Ayesha Gurnani\"},{\"authorId\":\"23922616\",\"name\":\"Vandit Gajjar\"},{\"authorId\":\"22239413\",\"name\":\"Viraj Mavani\"},{\"authorId\":\"26425477\",\"name\":\"Yash Khandhediya\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c6c691b772822881c5c52b779100928f0d54fdd7\",\"title\":\"Using Visual Saliency to Improve Human Detection with Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/c6c691b772822881c5c52b779100928f0d54fdd7\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2212080\",\"name\":\"Yifan Cai\"},{\"authorId\":\"1430747783\",\"name\":\"Richard Droste\"},{\"authorId\":\"1796341399\",\"name\":\"Harshita Sharma\"},{\"authorId\":\"1430746442\",\"name\":\"P. Chatelain\"},{\"authorId\":\"46763663\",\"name\":\"L. Drukker\"},{\"authorId\":\"101461032\",\"name\":\"A. T. Papageorghiou\"},{\"authorId\":\"152169633\",\"name\":\"J. A. Noble\"}],\"doi\":\"10.1016/j.media.2020.101762\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d96f24408ea2e671e358372a9935c6c90fd337ea\",\"title\":\"Spatio-temporal visual attention modelling of standard biometry plane-finding navigation\",\"url\":\"https://www.semanticscholar.org/paper/d96f24408ea2e671e358372a9935c6c90fd337ea\",\"venue\":\"Medical Image Anal.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34570209\",\"name\":\"Kshitij Dwivedi\"},{\"authorId\":\"145729589\",\"name\":\"Nitin Singh\"},{\"authorId\":\"1392783891\",\"name\":\"Sabari R. Shanmugham\"},{\"authorId\":\"153792660\",\"name\":\"M. Kumar\"}],\"doi\":\"10.1007/978-981-32-9291-8_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c794ac6077b2926e05cf0a6f2ca0a3263ada6139\",\"title\":\"DeepAttent: Saliency Prediction with Deep Multi-scale Residual Network\",\"url\":\"https://www.semanticscholar.org/paper/c794ac6077b2926e05cf0a6f2ca0a3263ada6139\",\"venue\":\"CVIP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2087470\",\"name\":\"S. Fan\"},{\"authorId\":\"144645142\",\"name\":\"M. Jiang\"},{\"authorId\":\"144506018\",\"name\":\"Z. Shen\"},{\"authorId\":\"34861255\",\"name\":\"Bryan L. Koenig\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1145/3123266.3123445\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6f8144a880e92aa6757dfb80e0be7d2acdc1e1e7\",\"title\":\"The Role of Visual Attention in Sentiment Prediction\",\"url\":\"https://www.semanticscholar.org/paper/6f8144a880e92aa6757dfb80e0be7d2acdc1e1e7\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2121169\",\"name\":\"Lishan Wu\"},{\"authorId\":\"37066739\",\"name\":\"Zhi Liu\"},{\"authorId\":\"2016134\",\"name\":\"Hangke Song\"},{\"authorId\":\"1789744\",\"name\":\"O. Meur\"}],\"doi\":\"10.1007/s11042-017-5576-y\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"de5e7586e534f2bcec3cfed4c41a48787225868c\",\"title\":\"RGBD co-saliency detection via multiple kernel boosting and fusion\",\"url\":\"https://www.semanticscholar.org/paper/de5e7586e534f2bcec3cfed4c41a48787225868c\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2017},{\"arxivId\":\"1711.01467\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"90bb40d96fcd16129eb85ce5dc4ee3b2380d74c8\",\"title\":\"Attentional Pooling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/90bb40d96fcd16129eb85ce5dc4ee3b2380d74c8\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1811.06308\",\"authors\":[{\"authorId\":\"51925488\",\"name\":\"David Berga\"},{\"authorId\":\"2556319\",\"name\":\"X. Otazu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"603bead9775c7523efe6c56431ab7f124b1bdee8\",\"title\":\"A Neurodynamic model of Saliency prediction in V1\",\"url\":\"https://www.semanticscholar.org/paper/603bead9775c7523efe6c56431ab7f124b1bdee8\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9228892\",\"name\":\"P. Zhang\"},{\"authorId\":\"47155200\",\"name\":\"X. Hua\"},{\"authorId\":\"50141120\",\"name\":\"X. Wang\"},{\"authorId\":\"34668628\",\"name\":\"Ting Rui\"},{\"authorId\":\"49724535\",\"name\":\"H. Zhang\"},{\"authorId\":\"51294540\",\"name\":\"Faming Shao\"},{\"authorId\":\"24981485\",\"name\":\"Dong Wang\"}],\"doi\":\"10.1109/access.2020.3012185\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bc6450c2444a642f0204786828ce1472f2737bea\",\"title\":\"VSA-CGAN: An Intelligent Generation Model for Deep Learning Sample Database Construction\",\"url\":\"https://www.semanticscholar.org/paper/bc6450c2444a642f0204786828ce1472f2737bea\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152686790\",\"name\":\"O. Krishna\"},{\"authorId\":\"152686790\",\"name\":\"O. Krishna\"},{\"authorId\":\"46363837\",\"name\":\"K. Aizawa\"},{\"authorId\":\"144990548\",\"name\":\"Go Irie\"}],\"doi\":\"10.1007/s11042-020-09474-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ff2af7d5edb6a5a57a09396374dbfd2c90c784c9\",\"title\":\"Computational attention model for children, adults and the elderly\",\"url\":\"https://www.semanticscholar.org/paper/ff2af7d5edb6a5a57a09396374dbfd2c90c784c9\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2007931\",\"name\":\"Kao Zhang\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"}],\"doi\":\"10.1109/TCSVT.2018.2883305\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6c54dfdace2a84d4b70fc31e87a3053be09cd863\",\"title\":\"Video Saliency Prediction Based on Spatial-Temporal Two-Stream Network\",\"url\":\"https://www.semanticscholar.org/paper/6c54dfdace2a84d4b70fc31e87a3053be09cd863\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":\"2008.13227\",\"authors\":[{\"authorId\":\"1917344125\",\"name\":\"Samad Zabihi\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"51004202\",\"name\":\"A. Borji\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"b7dd07f677210aa27defdd0f471771860566f674\",\"title\":\"A Compact Deep Architecture for Real-time Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/b7dd07f677210aa27defdd0f471771860566f674\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37503295\",\"name\":\"J. Chen\"},{\"authorId\":\"47422623\",\"name\":\"Q. Li\"},{\"authorId\":\"102937546\",\"name\":\"Weimin Wu\"},{\"authorId\":\"2175693\",\"name\":\"He-Fei Ling\"},{\"authorId\":\"152318075\",\"name\":\"Lei Wu\"},{\"authorId\":\"17668082\",\"name\":\"Baiyan Zhang\"},{\"authorId\":\"2420746\",\"name\":\"P. Li\"}],\"doi\":\"10.1109/ICIP.2019.8802611\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ad2ba1e97dc2c75ecf03e80b4212e6b3f08b811e\",\"title\":\"Saliency Detection via Topological Feature Modulated Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/ad2ba1e97dc2c75ecf03e80b4212e6b3f08b811e\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"1701.01081\",\"authors\":[{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"},{\"authorId\":\"1399086207\",\"name\":\"C. Canton-Ferrer\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"},{\"authorId\":\"147166602\",\"name\":\"J. Torres\"},{\"authorId\":\"2470219\",\"name\":\"E. Sayrol\"},{\"authorId\":\"3100480\",\"name\":\"Xavier Giro-i-Nieto\"}],\"doi\":null,\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"258fad95e709b6d0572ae6cc99efbbb14d32bdf2\",\"title\":\"SalGAN: Visual Saliency Prediction with Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/258fad95e709b6d0572ae6cc99efbbb14d32bdf2\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"80937411\",\"name\":\"Quanlong Zheng\"},{\"authorId\":\"2840852\",\"name\":\"Jianbo Jiao\"},{\"authorId\":\"143864954\",\"name\":\"Y. Cao\"},{\"authorId\":\"1726262\",\"name\":\"R. Lau\"}],\"doi\":\"10.1007/978-3-030-01264-9_18\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"83990b5527c2447085125fd79cffb3ce34a7b517\",\"title\":\"Task-Driven Webpage Saliency\",\"url\":\"https://www.semanticscholar.org/paper/83990b5527c2447085125fd79cffb3ce34a7b517\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1901.05002\",\"authors\":[{\"authorId\":\"51430629\",\"name\":\"Shanghua Xiao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"8399ce2555984ba5e309be575ca217f0e15a7fc3\",\"title\":\"Light-weighted Saliency Detection with Distinctively Lower Memory Cost and Model Size\",\"url\":\"https://www.semanticscholar.org/paper/8399ce2555984ba5e309be575ca217f0e15a7fc3\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121216817\",\"name\":\"Ming-hao Ning\"},{\"authorId\":\"50815695\",\"name\":\"C. Lu\"},{\"authorId\":\"1804482\",\"name\":\"Jianwei Gong\"}],\"doi\":\"10.1109/ITSC.2019.8917337\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8207fd1d0c27b3a979ef7aeb0466fa9c11623662\",\"title\":\"An Efficient Model for Driving Focus of Attention Prediction using Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/8207fd1d0c27b3a979ef7aeb0466fa9c11623662\",\"venue\":\"2019 IEEE Intelligent Transportation Systems Conference (ITSC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2190047\",\"name\":\"G. Leifman\"},{\"authorId\":\"2401277\",\"name\":\"Elizabeth Shtrom\"},{\"authorId\":\"3226509\",\"name\":\"A. Tal\"}],\"doi\":\"10.1109/CVPR.2012.6247703\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"65dc75918d6476051604a96a138216ea04e2026d\",\"title\":\"Surface Regions of Interest for Viewpoint Selection\",\"url\":\"https://www.semanticscholar.org/paper/65dc75918d6476051604a96a138216ea04e2026d\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2016},{\"arxivId\":\"1610.01563\",\"authors\":[{\"authorId\":\"2997408\",\"name\":\"Matthias K\\u00fcmmerer\"},{\"authorId\":\"49737748\",\"name\":\"Thomas S. A. Wallis\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d160d375a7c187dfe10c110e9e733f36accb87e6\",\"title\":\"DeepGaze II: Reading fixations from deep features trained on object recognition\",\"url\":\"https://www.semanticscholar.org/paper/d160d375a7c187dfe10c110e9e733f36accb87e6\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40665624\",\"name\":\"D. Zhu\"},{\"authorId\":\"50580169\",\"name\":\"Y. Chen\"},{\"authorId\":\"48985515\",\"name\":\"T. Han\"},{\"authorId\":\"1878665478\",\"name\":\"Defang Zhao\"},{\"authorId\":\"1878895877\",\"name\":\"Yucheng Zhu\"},{\"authorId\":\"2222210\",\"name\":\"Qiangqiang Zhou\"},{\"authorId\":\"13903793\",\"name\":\"Guangtao Zhai\"},{\"authorId\":\"15469693\",\"name\":\"Xiaokang Yang\"}],\"doi\":\"10.1109/ICME46284.2020.9102867\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3c9edaf2d18ac86032e900cec8ca0173e4b2c641\",\"title\":\"Ransp: Ranking Attention Network For Saliency Prediction On Omnidirectional Images\",\"url\":\"https://www.semanticscholar.org/paper/3c9edaf2d18ac86032e900cec8ca0173e4b2c641\",\"venue\":\"2020 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993656298\",\"name\":\"Jingwen Hou\"},{\"authorId\":\"144545118\",\"name\":\"Sheng Yang\"},{\"authorId\":\"144968899\",\"name\":\"W. Lin\"}],\"doi\":\"10.1145/3394171.3413695\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3be8cfb1299582b8ac6eca28350537c8b6f3777f\",\"title\":\"Object-level Attention for Aesthetic Rating Distribution Prediction\",\"url\":\"https://www.semanticscholar.org/paper/3be8cfb1299582b8ac6eca28350537c8b6f3777f\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37203857\",\"name\":\"L. Meng\"},{\"authorId\":\"47319689\",\"name\":\"Shuai Li\"},{\"authorId\":\"1423668854\",\"name\":\"Jiaqi Feng\"},{\"authorId\":\"71222824\",\"name\":\"Y. Liu\"},{\"authorId\":\"143754859\",\"name\":\"C. Zhu\"}],\"doi\":\"10.1109/CCHI.2019.8901953\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9cb8ec27e942758268f869f2b5a7e0c708553443\",\"title\":\"Multiple Context Aggregation Network for Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/9cb8ec27e942758268f869f2b5a7e0c708553443\",\"venue\":\"2019 2nd China Symposium on Cognitive Computing and Hybrid Intelligence (CCHI)\",\"year\":2019},{\"arxivId\":\"1907.02336\",\"authors\":[{\"authorId\":\"150007878\",\"name\":\"Alexandre Bruckert\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"143962642\",\"name\":\"Zhi Liu\"},{\"authorId\":\"1701717\",\"name\":\"M. Christie\"},{\"authorId\":\"1789744\",\"name\":\"O. Meur\"}],\"doi\":\"10.1016/j.neucom.2020.06.131\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"79c5b0d6dc39e7b0f59690520c17e33007a6b985\",\"title\":\"Deep Saliency Models : The Quest For The Loss Function\",\"url\":\"https://www.semanticscholar.org/paper/79c5b0d6dc39e7b0f59690520c17e33007a6b985\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21120270\",\"name\":\"Olivier Le Meur\"},{\"authorId\":\"1993250191\",\"name\":\"Tugdual Le Pen\"},{\"authorId\":\"1993250955\",\"name\":\"R\\u00e9mi Cozot\"}],\"doi\":\"10.1371/journal.pone.0239980\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"52ab2027e9e9939f5fbad8652b8c017821a4c545\",\"title\":\"Can we accurately predict where we look at paintings?\",\"url\":\"https://www.semanticscholar.org/paper/52ab2027e9e9939f5fbad8652b8c017821a4c545\",\"venue\":\"PloS one\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1769388\",\"name\":\"Baofeng Li\"},{\"authorId\":\"8048561\",\"name\":\"Zhengxing Sun\"},{\"authorId\":\"71184918\",\"name\":\"J. Xu\"},{\"authorId\":\"16230569\",\"name\":\"S. Wang\"},{\"authorId\":\"1484104565\",\"name\":\"Peiwen Yu\"}],\"doi\":\"10.1007/s11042-020-09458-5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"71308cb8f2eb0260df28a4c0d4ce0e93d3a5b010\",\"title\":\"Saliency based multiple object cosegmentation by ensemble MIML learning\",\"url\":\"https://www.semanticscholar.org/paper/71308cb8f2eb0260df28a4c0d4ce0e93d3a5b010\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"1901.04908\",\"authors\":[{\"authorId\":\"1727853\",\"name\":\"John K. Tsotsos\"},{\"authorId\":\"3468296\",\"name\":\"Iuliia Kotseruba\"},{\"authorId\":\"4218304\",\"name\":\"C. Wloka\"}],\"doi\":\"10.1371/journal.pone.0224306\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8c5965c95288ed05f220ee3250b85391ee7016aa\",\"title\":\"Rapid visual categorization is not guided by early salience-based selection\",\"url\":\"https://www.semanticscholar.org/paper/8c5965c95288ed05f220ee3250b85391ee7016aa\",\"venue\":\"PloS one\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"83143774\",\"name\":\"Sofia Krasovskaya\"},{\"authorId\":\"48268905\",\"name\":\"W. J. MacInnes\"}],\"doi\":\"10.3390/vision3040056\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f5dbdbb939d6b16c380bb930e7a52196f5d0e7a3\",\"title\":\"Salience Models: A Computational Cognitive Neuroscience Review\",\"url\":\"https://www.semanticscholar.org/paper/f5dbdbb939d6b16c380bb930e7a52196f5d0e7a3\",\"venue\":\"Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2004323567\",\"name\":\"Lai Jiang\"},{\"authorId\":\"2004323567\",\"name\":\"Lai Jiang\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":\"10.1007/s11263-020-01371-6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"540b4082b83335de2e08ac8a8e08e74e7756c9b5\",\"title\":\"DeepVS2.0: A Saliency-Structured Deep Learning Method for Predicting Dynamic Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/540b4082b83335de2e08ac8a8e08e74e7756c9b5\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1810382\",\"name\":\"Zhaohui Che\"},{\"authorId\":\"51004202\",\"name\":\"A. Borji\"},{\"authorId\":\"144826390\",\"name\":\"G. Zhai\"},{\"authorId\":\"2246414\",\"name\":\"Xiongkuo Min\"},{\"authorId\":\"1822413\",\"name\":\"Guodong Guo\"},{\"authorId\":\"1776651\",\"name\":\"P. Callet\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c01a827fd687791b92e393b203028fa1bca4c5ff\",\"title\":\"Leverage eye-movement data for saliency modeling: Invariance Analysis and a Robust New Model\",\"url\":\"https://www.semanticscholar.org/paper/c01a827fd687791b92e393b203028fa1bca4c5ff\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7869872\",\"name\":\"Y. Xu\"},{\"authorId\":\"2317822\",\"name\":\"Nianyi Li\"},{\"authorId\":\"3423101\",\"name\":\"Junru Wu\"},{\"authorId\":\"2152356\",\"name\":\"J. Yu\"},{\"authorId\":\"1702868\",\"name\":\"Shenghua Gao\"}],\"doi\":\"10.24963/ijcai.2017/543\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"aca8c4a62ed6e590889f1e859d7bc79311fa6f4d\",\"title\":\"Beyond Universal Saliency: Personalized Saliency Prediction with Multi-task CNN\",\"url\":\"https://www.semanticscholar.org/paper/aca8c4a62ed6e590889f1e859d7bc79311fa6f4d\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1398421283\",\"name\":\"U. Markowska-Kaczmar\"},{\"authorId\":\"153318273\",\"name\":\"H. Kwasnicka\"}],\"doi\":\"10.1007/978-3-319-73891-8_7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0302fed107f5bee6cc4ea4a48eb1dfb26554ef83\",\"title\":\"Deep Learning\\u2014A New Era in Bridging the Semantic Gap\",\"url\":\"https://www.semanticscholar.org/paper/0302fed107f5bee6cc4ea4a48eb1dfb26554ef83\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1812.00722\",\"authors\":[{\"authorId\":\"2539459\",\"name\":\"Petros Koutras\"},{\"authorId\":\"1750686\",\"name\":\"P. Maragos\"}],\"doi\":\"10.1109/CVPRW.2019.00109\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e330af2d061ade245622b9445d5be9717f66b60f\",\"title\":\"SUSiNet: See, Understand and Summarize It\",\"url\":\"https://www.semanticscholar.org/paper/e330af2d061ade245622b9445d5be9717f66b60f\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49050949\",\"name\":\"J. Zhang\"},{\"authorId\":\"1681554\",\"name\":\"Yuchao Dai\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"}],\"doi\":\"10.1109/WACV.2017.8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"63660c50e2669a5115c2379e622549d8ed79be00\",\"title\":\"Deep Salient Object Detection by Integrating Multi-level Cues\",\"url\":\"https://www.semanticscholar.org/paper/63660c50e2669a5115c2379e622549d8ed79be00\",\"venue\":\"2017 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2017},{\"arxivId\":\"2008.13745\",\"authors\":[{\"authorId\":\"46533364\",\"name\":\"Sandeep Mishra\"},{\"authorId\":\"49194775\",\"name\":\"Oindrila Saha\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"13fa6726305b77aa815b148469c495b6ceeed72b\",\"title\":\"RecSal : Deep Recursive Supervision for Visual Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/13fa6726305b77aa815b148469c495b6ceeed72b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145800409\",\"name\":\"Anna Volokitin\"},{\"authorId\":\"3037160\",\"name\":\"Michael Gygli\"},{\"authorId\":\"2343486\",\"name\":\"X. Boix\"}],\"doi\":\"10.1109/CVPR.2016.65\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e2d6767123e26ab804401278e5d6941c9484f6f3\",\"title\":\"Predicting When Saliency Maps are Accurate and Eye Fixations Consistent\",\"url\":\"https://www.semanticscholar.org/paper/e2d6767123e26ab804401278e5d6941c9484f6f3\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3185668\",\"name\":\"Haoran Liang\"},{\"authorId\":\"144645142\",\"name\":\"M. Jiang\"},{\"authorId\":\"4487395\",\"name\":\"Ronghua Liang\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1145/3200767\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4df36f11cddb2cfd01cd062b53f10d206db752e5\",\"title\":\"CapVis: Toward Better Understanding of Visual-Verbal Saliency Consistency\",\"url\":\"https://www.semanticscholar.org/paper/4df36f11cddb2cfd01cd062b53f10d206db752e5\",\"venue\":\"ACM Trans. Intell. Syst. Technol.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"145622169\",\"name\":\"Zi Huang\"},{\"authorId\":\"2416851\",\"name\":\"Hongzhi Yin\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8dc540300335e27773e2b5f16c481476448d5b83\",\"title\":\"An Integrated Model for Effective Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/8dc540300335e27773e2b5f16c481476448d5b83\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"147552063\",\"name\":\"M. L. Nguy\\u1ec5n\"},{\"authorId\":\"2847306\",\"name\":\"Prarinya Siritanawan\"},{\"authorId\":\"1791753\",\"name\":\"K. Kotani\"}],\"doi\":\"10.23919/SICE.2019.8859898\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"edb5a343d72e65072e967401f4ac508a31df3ac7\",\"title\":\"Saliency Map Extraction in Human Crowd RGB Data\",\"url\":\"https://www.semanticscholar.org/paper/edb5a343d72e65072e967401f4ac508a31df3ac7\",\"venue\":\"2019 58th Annual Conference of the Society of Instrument and Control Engineers of Japan (SICE)\",\"year\":2019},{\"arxivId\":\"2005.14310\",\"authors\":[{\"authorId\":\"48598731\",\"name\":\"Zhibo Yang\"},{\"authorId\":\"37012552\",\"name\":\"L. Huang\"},{\"authorId\":\"152829057\",\"name\":\"Yupei Chen\"},{\"authorId\":\"2647061\",\"name\":\"Zijun Wei\"},{\"authorId\":\"144078005\",\"name\":\"Seoyoung Ahn\"},{\"authorId\":\"1696991\",\"name\":\"G. Zelinsky\"},{\"authorId\":\"1686020\",\"name\":\"D. Samaras\"},{\"authorId\":\"2356016\",\"name\":\"Minh Hoai\"}],\"doi\":\"10.1109/cvpr42600.2020.00027\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8b9346af26e460bc37d0e3a4e957a6c42beb3677\",\"title\":\"Predicting Goal-Directed Human Attention Using Inverse Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/8b9346af26e460bc37d0e3a4e957a6c42beb3677\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1904851593\",\"name\":\"Maria Tsiourva\"},{\"authorId\":\"2682660\",\"name\":\"C. Papachristos\"}],\"doi\":\"10.1109/AERO47225.2020.9172576\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a4803df5337676175fdc9f5a2ab781e9b6b83af7\",\"title\":\"Multi-modal Visual-Thermal Saliency-based Object Detection in Visually-degraded Environments\",\"url\":\"https://www.semanticscholar.org/paper/a4803df5337676175fdc9f5a2ab781e9b6b83af7\",\"venue\":\"2020 IEEE Aerospace Conference\",\"year\":2020},{\"arxivId\":\"1709.02495\",\"authors\":[{\"authorId\":\"145556868\",\"name\":\"Ali Mahdi\"},{\"authorId\":\"145669352\",\"name\":\"Jun Qin\"},{\"authorId\":\"39333164\",\"name\":\"G. Crosby\"}],\"doi\":\"10.1109/TCDS.2019.2894561\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c69f5261edb4dde001fcea4d32b06fdf9dd9358a\",\"title\":\"DeepFeat: A Bottom-Up and Top-Down Saliency Model Based on Deep Features of Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/c69f5261edb4dde001fcea4d32b06fdf9dd9358a\",\"venue\":\"IEEE Transactions on Cognitive and Developmental Systems\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144480984\",\"name\":\"Qiang Hu\"},{\"authorId\":\"49895169\",\"name\":\"J. Zhou\"},{\"authorId\":\"47957191\",\"name\":\"Xiao-yun Zhang\"},{\"authorId\":\"34692825\",\"name\":\"Zhiru Shi\"},{\"authorId\":\"49538591\",\"name\":\"Z. Gao\"}],\"doi\":\"10.1007/s11042-019-08390-7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9fcb0a329cff574b89567e2b26a7bb4d79a77744\",\"title\":\"Viewport-adaptive 360-degree video coding\",\"url\":\"https://www.semanticscholar.org/paper/9fcb0a329cff574b89567e2b26a7bb4d79a77744\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"51004202\",\"name\":\"A. Borji\"},{\"authorId\":\"1776374\",\"name\":\"Juho Kannala\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"}],\"doi\":\"10.1145/3379156.3391337\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"117877a5d29a6e3d0ad6f7520e6ff8b114d5670b\",\"title\":\"Deep Audio-Visual Saliency: Baseline Model and Data\",\"url\":\"https://www.semanticscholar.org/paper/117877a5d29a6e3d0ad6f7520e6ff8b114d5670b\",\"venue\":\"ETRA Short Papers\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37634267\",\"name\":\"A. Davy\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"31a35a503461da5c4c361afc049e770af3f3ca80\",\"title\":\"Mod\\u00e9lisation de fonds complexes statiques et en mouvement : application \\u00e0 la d\\u00e9tection d'\\u00e9v\\u00e9nements rares dans les s\\u00e9ries d'images\",\"url\":\"https://www.semanticscholar.org/paper/31a35a503461da5c4c361afc049e770af3f3ca80\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405907659\",\"name\":\"Ming Jiang\"},{\"authorId\":\"94011352\",\"name\":\"S. Chen\"},{\"authorId\":\"7788087\",\"name\":\"J. Yang\"},{\"authorId\":\"153386875\",\"name\":\"Q. Zhao\"}],\"doi\":\"10.1109/cvpr42600.2020.00305\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b3739681eb93295d05e9d6716f2ba94c48f047f3\",\"title\":\"Fantastic Answers and Where to Find Them: Immersive Question-Directed Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/b3739681eb93295d05e9d6716f2ba94c48f047f3\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1482544048\",\"name\":\"Camilo Fosco\"},{\"authorId\":\"117232498\",\"name\":\"Anelise Newman\"},{\"authorId\":\"1482544051\",\"name\":\"Pat Sukhum\"},{\"authorId\":\"2204049\",\"name\":\"Y. Zhang\"},{\"authorId\":\"51150125\",\"name\":\"Nanxuan Zhao\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"},{\"authorId\":\"1618896088\",\"name\":\"Hong Kong\"}],\"doi\":\"10.1109/cvpr42600.2020.00453\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cffc481c86d46ca812eff85030f812588bb20b80\",\"title\":\"How Much Time Do You Have? Modeling Multi-Duration Saliency\",\"url\":\"https://www.semanticscholar.org/paper/cffc481c86d46ca812eff85030f812588bb20b80\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1912.08136\",\"authors\":[{\"authorId\":\"145378987\",\"name\":\"Yan Luo\"},{\"authorId\":\"3026404\",\"name\":\"Yongkang Wong\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"},{\"authorId\":\"153386875\",\"name\":\"Q. Zhao\"}],\"doi\":\"10.1109/TPAMI.2019.2963387\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"52b94fb0e0bad38835662d1fb3e86a7be584f8f6\",\"title\":\"Direction Concentration Learning: Enhancing Congruency in Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/52b94fb0e0bad38835662d1fb3e86a7be584f8f6\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"119923978\",\"name\":\"Yufan Liu\"},{\"authorId\":\"145143111\",\"name\":\"R. Hu\"},{\"authorId\":\"143684018\",\"name\":\"F. He\"}],\"doi\":\"10.1109/TIP.2018.2837106\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9f1a854d574d0bd14786c41247db272be6062581\",\"title\":\"Find Who to Look at: Turning From Action to Saliency\",\"url\":\"https://www.semanticscholar.org/paper/9f1a854d574d0bd14786c41247db272be6062581\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":\"1612.04335\",\"authors\":[{\"authorId\":\"5021307\",\"name\":\"Vincent Sitzmann\"},{\"authorId\":\"145192940\",\"name\":\"Ana Serrano\"},{\"authorId\":\"48453720\",\"name\":\"A. Pavel\"},{\"authorId\":\"1820412\",\"name\":\"M. Agrawala\"},{\"authorId\":\"143876232\",\"name\":\"D. Gutierrez\"},{\"authorId\":\"1775667\",\"name\":\"B. Masi\\u00e1\"},{\"authorId\":\"1731170\",\"name\":\"G. Wetzstein\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c6b4459c4f27b9c4107ae7f708059e987e7f3f08\",\"title\":\"How do people explore virtual environments\",\"url\":\"https://www.semanticscholar.org/paper/c6b4459c4f27b9c4107ae7f708059e987e7f3f08\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3d173893dd3f22fd73acc16b94f0ea98469c9855\",\"title\":\"Saliency Prediction in the Deep Learning Era: Successes, Limitations, and Future Challenges\",\"url\":\"https://www.semanticscholar.org/paper/3d173893dd3f22fd73acc16b94f0ea98469c9855\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3043414\",\"name\":\"Przemys\\u0142aw Skurowski\"},{\"authorId\":\"1809939\",\"name\":\"Pawel Kasprowski\"}],\"doi\":\"10.1109/IPAS.2018.8708858\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"026b9d7913cf7b4ceff87c7c633042eb16151c71\",\"title\":\"Evaluation of Saliency Maps in a Hard Case \\u2013 Images of Camouflaged Animals\",\"url\":\"https://www.semanticscholar.org/paper/026b9d7913cf7b4ceff87c7c633042eb16151c71\",\"venue\":\"2018 IEEE International Conference on Image Processing, Applications and Systems (IPAS)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49047213\",\"name\":\"Congcong Liu\"},{\"authorId\":\"49069718\",\"name\":\"Y. Chen\"},{\"authorId\":\"70308463\",\"name\":\"L. Tai\"},{\"authorId\":\"9947757\",\"name\":\"Haoyang Ye\"},{\"authorId\":\"145111960\",\"name\":\"Ming Liu\"},{\"authorId\":\"2131088\",\"name\":\"B. Shi\"}],\"doi\":\"10.1145/3314111.3319846\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"327546dbb99837e4e14e5013ecb5db7587ff067a\",\"title\":\"A gaze model improves autonomous driving\",\"url\":\"https://www.semanticscholar.org/paper/327546dbb99837e4e14e5013ecb5db7587ff067a\",\"venue\":\"ETRA\",\"year\":2019},{\"arxivId\":\"1712.02142\",\"authors\":[{\"authorId\":\"47119743\",\"name\":\"Xi Wang\"},{\"authorId\":\"1751554\",\"name\":\"Marc Alexa\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3c138e780db882893631567329bfa6e031c967a0\",\"title\":\"Maps of Visual Importance\",\"url\":\"https://www.semanticscholar.org/paper/3c138e780db882893631567329bfa6e031c967a0\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2452552\",\"name\":\"S. Alletto\"},{\"authorId\":\"38772386\",\"name\":\"A. Palazzi\"},{\"authorId\":\"2059900\",\"name\":\"Francesco Solera\"},{\"authorId\":\"2175529\",\"name\":\"Simone Calderara\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/CVPRW.2016.14\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9037fd1a7c309921a058f3831145db2639105537\",\"title\":\"DR(eye)VE: A Dataset for Attention-Based Tasks with Applications to Autonomous and Assisted Driving\",\"url\":\"https://www.semanticscholar.org/paper/9037fd1a7c309921a058f3831145db2639105537\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3327256\",\"name\":\"M. Favorskaya\"},{\"authorId\":\"122575918\",\"name\":\"L. C. Jain\"}],\"doi\":\"10.31799/1684-8853-2019-3-10-36\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6fe7379f40fd2354e5bbe5f8be79069feb0c6ea2\",\"title\":\"Saliency detection in deep learning era: trends of development\",\"url\":\"https://www.semanticscholar.org/paper/6fe7379f40fd2354e5bbe5f8be79069feb0c6ea2\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1708.02660\",\"authors\":[{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"},{\"authorId\":\"2201320\",\"name\":\"N. W. Kim\"},{\"authorId\":\"1411051436\",\"name\":\"P. O'Donovan\"},{\"authorId\":\"145899760\",\"name\":\"Sami Alsheikh\"},{\"authorId\":\"7232330\",\"name\":\"Spandan Madan\"},{\"authorId\":\"143758231\",\"name\":\"H. Pfister\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"145160921\",\"name\":\"Bryan C. Russell\"},{\"authorId\":\"1747779\",\"name\":\"Aaron Hertzmann\"}],\"doi\":\"10.1145/3126594.3126653\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3342f13fa0809c0429866f6126cb5bc3281b91ae\",\"title\":\"Learning Visual Importance for Graphic Designs and Data Visualizations\",\"url\":\"https://www.semanticscholar.org/paper/3342f13fa0809c0429866f6126cb5bc3281b91ae\",\"venue\":\"UIST\",\"year\":2017},{\"arxivId\":\"1711.03726\",\"authors\":[{\"authorId\":\"46479926\",\"name\":\"Prakhar Gupta\"},{\"authorId\":\"28823342\",\"name\":\"Shubh Gupta\"},{\"authorId\":\"30039163\",\"name\":\"Ajaykrishnan Jayagopal\"},{\"authorId\":\"143775710\",\"name\":\"S. Pal\"},{\"authorId\":\"2703103\",\"name\":\"R. Sinha\"}],\"doi\":\"10.1109/WACV.2018.00171\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"329836fe1afe6d3ee48c901175a0219756dd2927\",\"title\":\"Saliency Prediction for Mobile User Interfaces\",\"url\":\"https://www.semanticscholar.org/paper/329836fe1afe6d3ee48c901175a0219756dd2927\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":\"1910.14260\",\"authors\":[{\"authorId\":\"47295036\",\"name\":\"Zehua Zhang\"},{\"authorId\":\"46756438\",\"name\":\"Chen Yu\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b41e631c08be054ab19a88e3fb07077e03a6c53e\",\"title\":\"A Self Validation Network for Object-Level Human Attention Estimation\",\"url\":\"https://www.semanticscholar.org/paper/b41e631c08be054ab19a88e3fb07077e03a6c53e\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50814507\",\"name\":\"Cagdas Bak\"},{\"authorId\":\"3044594\",\"name\":\"Aysun Kocak\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"}],\"doi\":\"10.1109/TMM.2017.2777665\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1ebd1083ad9e10ed2feded8319c5d472bf9f420b\",\"title\":\"Spatio-Temporal Saliency Networks for Dynamic Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/1ebd1083ad9e10ed2feded8319c5d472bf9f420b\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38591458\",\"name\":\"Phutphalla Kong\"},{\"authorId\":\"1681157\",\"name\":\"M. Mancas\"},{\"authorId\":\"51266101\",\"name\":\"Nimol Thuon\"},{\"authorId\":\"9289244\",\"name\":\"Seng Kheang\"},{\"authorId\":\"50276543\",\"name\":\"B. Gosselin\"}],\"doi\":\"10.1109/ICIP.2018.8451809\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"262ca560946e754c24d7072fe50ad2f2d630b058\",\"title\":\"Do Deep-Learning Saliency Models Really Model Saliency?\",\"url\":\"https://www.semanticscholar.org/paper/262ca560946e754c24d7072fe50ad2f2d630b058\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":\"1709.05307\",\"authors\":[{\"authorId\":\"2004177\",\"name\":\"F. Murabito\"},{\"authorId\":\"2441118\",\"name\":\"C. Spampinato\"},{\"authorId\":\"37759796\",\"name\":\"S. Palazzo\"},{\"authorId\":\"3403160\",\"name\":\"Konstantin Pogorelov\"},{\"authorId\":\"1410046696\",\"name\":\"Michael Riegler\"}],\"doi\":\"10.1016/j.cviu.2018.03.005\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"706f314f3b66f0ede47ec9ca7157426915739244\",\"title\":\"Top-Down Saliency Detection Driven by Visual Classification\",\"url\":\"https://www.semanticscholar.org/paper/706f314f3b66f0ede47ec9ca7157426915739244\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"3309130\",\"name\":\"Davide Abati\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"38772386\",\"name\":\"A. Palazzi\"},{\"authorId\":\"2175529\",\"name\":\"Simone Calderara\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1007/978-3-319-70169-1_29\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fcab88ece5f4ce26a79f660c56051ebf27c39f1f\",\"title\":\"Attentive Models in Vision: Computing Saliency Maps in the Deep Learning Era\",\"url\":\"https://www.semanticscholar.org/paper/fcab88ece5f4ce26a79f660c56051ebf27c39f1f\",\"venue\":\"AI*IA\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7986654\",\"name\":\"Yunpeng Xiao\"},{\"authorId\":\"47786247\",\"name\":\"J. Li\"},{\"authorId\":\"1585297850\",\"name\":\"Yangfu Zhu\"},{\"authorId\":\"153082819\",\"name\":\"Qian Li\"}],\"doi\":\"10.1109/TCSS.2020.2969484\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b7ef29ab36e28d8a44bba91c2aab84a27109b4b1\",\"title\":\"User Behavior Prediction of Social Hotspots Based on Multimessage Interaction and Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/b7ef29ab36e28d8a44bba91c2aab84a27109b4b1\",\"venue\":\"IEEE Transactions on Computational Social Systems\",\"year\":2020},{\"arxivId\":\"1510.05484\",\"authors\":[{\"authorId\":\"40286484\",\"name\":\"Xi Li\"},{\"authorId\":\"46586815\",\"name\":\"Liming Zhao\"},{\"authorId\":\"50589478\",\"name\":\"Lina Wei\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"144894849\",\"name\":\"Fei Wu\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"},{\"authorId\":\"1805398\",\"name\":\"Haibin Ling\"},{\"authorId\":\"1688516\",\"name\":\"Jingdong Wang\"}],\"doi\":\"10.1109/TIP.2016.2579306\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4b2197fad455f016eaa7a08a8861ed752ca1cd96\",\"title\":\"DeepSaliency: Multi-Task Deep Neural Network Model for Salient Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/4b2197fad455f016eaa7a08a8861ed752ca1cd96\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2997408\",\"name\":\"Matthias K\\u00fcmmerer\"},{\"authorId\":\"49737748\",\"name\":\"Thomas S. A. Wallis\"},{\"authorId\":\"1891828\",\"name\":\"Leon A. Gatys\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":\"10.1109/ICCV.2017.513\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"53d77b463ec744491ab68ed49f5d2152cbbcbf9d\",\"title\":\"Understanding Low- and High-Level Contributions to Fixation Prediction\",\"url\":\"https://www.semanticscholar.org/paper/53d77b463ec744491ab68ed49f5d2152cbbcbf9d\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48116275\",\"name\":\"W. Einh\\u00e4user\"},{\"authorId\":\"1656665391\",\"name\":\"Charlotte Atzert\"},{\"authorId\":\"3376641\",\"name\":\"A. Nuthmann\"}],\"doi\":\"10.1167/jov.20.4.15\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4420909e85cfb6a4f0ce23830954df3aeaa0e9c1\",\"title\":\"Fixation durations in natural scene viewing are guided by peripheral scene content\",\"url\":\"https://www.semanticscholar.org/paper/4420909e85cfb6a4f0ce23830954df3aeaa0e9c1\",\"venue\":\"Journal of vision\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48379607\",\"name\":\"Yu Zhang\"},{\"authorId\":\"10699750\",\"name\":\"X. Gao\"},{\"authorId\":\"1753049\",\"name\":\"Lihuo He\"},{\"authorId\":\"145440138\",\"name\":\"Wen Lu\"},{\"authorId\":\"143712929\",\"name\":\"R. He\"}],\"doi\":\"10.1109/TNNLS.2018.2890310\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"496883e35e362524799ad0dc937925389713969e\",\"title\":\"Objective Video Quality Assessment Combining Transfer Learning With CNN\",\"url\":\"https://www.semanticscholar.org/paper/496883e35e362524799ad0dc937925389713969e\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"9284635\",\"name\":\"Hongmei Song\"},{\"authorId\":\"152836879\",\"name\":\"Shuyang Zhao\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"2901725\",\"name\":\"Sanyuan Zhao\"},{\"authorId\":\"1741126\",\"name\":\"S. Hoi\"},{\"authorId\":\"1805398\",\"name\":\"Haibin Ling\"}],\"doi\":\"10.1109/CVPR.2019.00318\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f53761ea6276df40089753a4e008d1283f28e768\",\"title\":\"Learning Unsupervised Video Object Segmentation Through Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/f53761ea6276df40089753a4e008d1283f28e768\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48598731\",\"name\":\"Zhibo Yang\"},{\"authorId\":\"98206513\",\"name\":\"Lihan Huang\"},{\"authorId\":\"152829057\",\"name\":\"Yupei Chen\"},{\"authorId\":\"2647061\",\"name\":\"Zijun Wei\"},{\"authorId\":\"144078005\",\"name\":\"Seoyoung Ahn\"},{\"authorId\":\"1696991\",\"name\":\"G. Zelinsky\"},{\"authorId\":\"1686020\",\"name\":\"D. Samaras\"},{\"authorId\":\"2356016\",\"name\":\"Minh Hoai\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"1b4fb1fd767968b20db2ff9288c78fd2a8179a9f\",\"title\":\"Supplementary Material: Predicting Goal-directed Human Attention Using Inverse Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/1b4fb1fd767968b20db2ff9288c78fd2a8179a9f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2003.04942\",\"authors\":[{\"authorId\":\"1557425970\",\"name\":\"Navyasri Reddy\"},{\"authorId\":\"151444035\",\"name\":\"Samyak Jain\"},{\"authorId\":\"34935738\",\"name\":\"Pradeep Yarlagadda\"},{\"authorId\":\"145091336\",\"name\":\"V. Gandhi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"46d71e96013107c1d2be0b6ec44f4def7ac7fbe2\",\"title\":\"Tidying Deep Saliency Prediction Architectures\",\"url\":\"https://www.semanticscholar.org/paper/46d71e96013107c1d2be0b6ec44f4def7ac7fbe2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1807.10657\",\"authors\":[{\"authorId\":\"51149716\",\"name\":\"Taiki Oyama\"},{\"authorId\":\"47456929\",\"name\":\"T. Yamanaka\"}],\"doi\":\"10.1049/TRIT.2018.1012\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5df11c59e3b47189486445f5833675bf08359bfe\",\"title\":\"Influence of Image Classification Accuracy on Saliency Map Estimation\",\"url\":\"https://www.semanticscholar.org/paper/5df11c59e3b47189486445f5833675bf08359bfe\",\"venue\":\"CAAI Trans. Intell. Technol.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40565055\",\"name\":\"Shiwei Cheng\"},{\"authorId\":\"152223743\",\"name\":\"Jing Fan\"},{\"authorId\":\"2000421283\",\"name\":\"Yilin Hu\"}],\"doi\":\"10.1007/S00779-020-01463-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"226a09bc91d7b1cd99c4b6206623dd0ec97ee68b\",\"title\":\"Visual saliency model based on crowdsourcing eye tracking data and its application in visual design\",\"url\":\"https://www.semanticscholar.org/paper/226a09bc91d7b1cd99c4b6206623dd0ec97ee68b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1511.06292\",\"authors\":[{\"authorId\":\"145378987\",\"name\":\"Yan Luo\"},{\"authorId\":\"2343486\",\"name\":\"X. Boix\"},{\"authorId\":\"144596911\",\"name\":\"Gemma Roig\"},{\"authorId\":\"1685292\",\"name\":\"T. Poggio\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"301aa261120059b0a7b62103c49504c48ead5de0\",\"title\":\"Foveation-based Mechanisms Alleviate Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/301aa261120059b0a7b62103c49504c48ead5de0\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1722881\",\"name\":\"Jiazhong Chen\"},{\"authorId\":\"47422623\",\"name\":\"Q. Li\"},{\"authorId\":\"144785138\",\"name\":\"P. Li\"},{\"authorId\":\"145312326\",\"name\":\"Y. Han\"},{\"authorId\":\"145233508\",\"name\":\"Lei Wu\"},{\"authorId\":\"144125487\",\"name\":\"Hefei Ling\"},{\"authorId\":\"9315669\",\"name\":\"Weimin Wu\"}],\"doi\":\"10.1016/J.JVCIR.2019.02.026\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d7e6b579a40169e2158858f75e36b1be54969cf4\",\"title\":\"Saliency prediction by Mahalanobis distance of topological feature on deep color components\",\"url\":\"https://www.semanticscholar.org/paper/d7e6b579a40169e2158858f75e36b1be54969cf4\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":\"1903.02501\",\"authors\":[{\"authorId\":\"47287647\",\"name\":\"Sen He\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"145071344\",\"name\":\"Yang Mi\"},{\"authorId\":\"3251678\",\"name\":\"N. Pugeault\"}],\"doi\":\"10.1109/CVPR.2019.01045\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"38410376deedfdfc32e53b7369b9ea2297fa521f\",\"title\":\"Understanding and Visualizing Deep Visual Saliency Models\",\"url\":\"https://www.semanticscholar.org/paper/38410376deedfdfc32e53b7369b9ea2297fa521f\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47543815\",\"name\":\"Eunsoo Park\"},{\"authorId\":\"2932704\",\"name\":\"S. Kim\"},{\"authorId\":\"2267529\",\"name\":\"E. Ryu\"}],\"doi\":\"10.5909/JBE.2020.25.3.374\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7b238a27ab62caaaaf80dd685c0244a844978a49\",\"title\":\"Preprocessing Technique for Improving Action Recognition Performance in ERP Video with Multiple Objects\",\"url\":\"https://www.semanticscholar.org/paper/7b238a27ab62caaaaf80dd685c0244a844978a49\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"2509726\",\"name\":\"Xingping Dong\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":\"10.1109/CVPR.2018.00184\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"41aa48241071f8fa15145c3452679aa91c13459e\",\"title\":\"Salient Object Detection Driven by Fixation Prediction\",\"url\":\"https://www.semanticscholar.org/paper/41aa48241071f8fa15145c3452679aa91c13459e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1809.00644\",\"authors\":[{\"authorId\":\"51430629\",\"name\":\"Shanghua Xiao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"155d51a08dc15e7a77a3e7f317ab434e5842de8b\",\"title\":\"Learning Saliency Prediction From Sparse Fixation Pixel Map\",\"url\":\"https://www.semanticscholar.org/paper/155d51a08dc15e7a77a3e7f317ab434e5842de8b\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1811.03736\",\"authors\":[{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"cf1c7f158d8b4704d01f3b111e48d9640abc4557\",\"title\":\"Semantic and Contrast-Aware Saliency\",\"url\":\"https://www.semanticscholar.org/paper/cf1c7f158d8b4704d01f3b111e48d9640abc4557\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2966504\",\"name\":\"Daowei Li\"},{\"authorId\":\"1967201\",\"name\":\"Kui Fu\"},{\"authorId\":\"151469503\",\"name\":\"Yifan Zhao\"},{\"authorId\":\"1690940\",\"name\":\"L. Xu\"},{\"authorId\":\"9073063\",\"name\":\"Jiugang Li\"}],\"doi\":\"10.1109/MIPR49039.2020.00011\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6b4cce9a454de5ef9d83edc6494d5046e52ae7ce\",\"title\":\"Cross-Domain Visual Attention Model Adaption with One-Shot GAN\",\"url\":\"https://www.semanticscholar.org/paper/6b4cce9a454de5ef9d83edc6494d5046e52ae7ce\",\"venue\":\"2020 IEEE Conference on Multimedia Information Processing and Retrieval (MIPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49047213\",\"name\":\"Congcong Liu\"},{\"authorId\":\"49069718\",\"name\":\"Y. Chen\"},{\"authorId\":\"36523639\",\"name\":\"Meilin Liu\"},{\"authorId\":\"2131088\",\"name\":\"B. Shi\"}],\"doi\":\"10.1109/TNNLS.2020.2996386\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"616f8dcebefe472c73b3cf77642617c3d1a58d05\",\"title\":\"Using Eye Gaze to Enhance Generalization of Imitation Networks to Unseen Environments.\",\"url\":\"https://www.semanticscholar.org/paper/616f8dcebefe472c73b3cf77642617c3d1a58d05\",\"venue\":\"IEEE transactions on neural networks and learning systems\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10604706\",\"name\":\"Ali Selman Aydin\"},{\"authorId\":\"113653487\",\"name\":\"Shirin Feiz\"},{\"authorId\":\"145070406\",\"name\":\"V. Ashok\"},{\"authorId\":\"1519965383\",\"name\":\"I. Ramakrishnan\"}],\"doi\":\"10.1145/3377325.3377540\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5bb5375a3e63568447dc3b7e20e8e3c6aee2da8d\",\"title\":\"SaIL: saliency-driven injection of ARIA landmarks\",\"url\":\"https://www.semanticscholar.org/paper/5bb5375a3e63568447dc3b7e20e8e3c6aee2da8d\",\"venue\":\"IUI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2606799\",\"name\":\"P. Huang\"},{\"authorId\":\"145015815\",\"name\":\"G. Yu\"},{\"authorId\":\"143663445\",\"name\":\"Hua Lu\"},{\"authorId\":\"8977489\",\"name\":\"Danhua Liu\"},{\"authorId\":\"34991757\",\"name\":\"L. Xing\"},{\"authorId\":\"120286247\",\"name\":\"Y. Yin\"},{\"authorId\":\"145574965\",\"name\":\"N. Kovalchuk\"},{\"authorId\":\"144218958\",\"name\":\"L. Xing\"},{\"authorId\":\"32154962\",\"name\":\"D. Li\"}],\"doi\":\"10.1002/mp.13510\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"41072ea8c0a852fd70bf8143496e13ecf9ab2918\",\"title\":\"Attention-aware fully convolutional neural network with convolutional long short-term memory network for ultrasound-based motion tracking.\",\"url\":\"https://www.semanticscholar.org/paper/41072ea8c0a852fd70bf8143496e13ecf9ab2918\",\"venue\":\"Medical physics\",\"year\":2019},{\"arxivId\":\"1711.10959\",\"authors\":[{\"authorId\":\"4218304\",\"name\":\"C. Wloka\"},{\"authorId\":\"3468296\",\"name\":\"Iuliia Kotseruba\"},{\"authorId\":\"1727853\",\"name\":\"John K. Tsotsos\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"475b423d03a56e272c0fb40d087e300d3e28d5d9\",\"title\":\"Saccade Sequence Prediction: Beyond Static Saliency Maps\",\"url\":\"https://www.semanticscholar.org/paper/475b423d03a56e272c0fb40d087e300d3e28d5d9\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144027562\",\"name\":\"P. K\\u00f6nig\"},{\"authorId\":\"49022076\",\"name\":\"Niklas Wilming\"},{\"authorId\":\"32599522\",\"name\":\"T. Kietzmann\"},{\"authorId\":\"5083684\",\"name\":\"J. Ossand\\u00f3n\"},{\"authorId\":\"2469837\",\"name\":\"Selim Onat\"},{\"authorId\":\"46483677\",\"name\":\"Benedikt V. Ehinger\"},{\"authorId\":\"3293976\",\"name\":\"R. Gameiro\"},{\"authorId\":\"1969196\",\"name\":\"K. Kaspar\"}],\"doi\":\"10.16910/JEMR.9.5.3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"52ed19ec4c3d2bc2112df413ec0f559c6725b2dc\",\"title\":\"Eye movements as a window to cognitive processes\",\"url\":\"https://www.semanticscholar.org/paper/52ed19ec4c3d2bc2112df413ec0f559c6725b2dc\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49501675\",\"name\":\"Puneet Gupta\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"}],\"doi\":\"10.1109/ICCV.2019.00681\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a90aefbe8961013dbb0a6669644ea9d60854cacb\",\"title\":\"CIIDefence: Defeating Adversarial Attacks by Fusing Class-Specific Image Inpainting and Image Denoising\",\"url\":\"https://www.semanticscholar.org/paper/a90aefbe8961013dbb0a6669644ea9d60854cacb\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24962320\",\"name\":\"T. Uejima\"},{\"authorId\":\"1491180171\",\"name\":\"Ernst Niebur\"},{\"authorId\":\"1398026219\",\"name\":\"R. Etienne-Cummings\"}],\"doi\":\"10.3389/fncom.2020.541581\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d800b1df83ab5408c4cb2c84edbd679fb5970473\",\"title\":\"Proto-Object Based Saliency Model With Texture Detection Channel\",\"url\":\"https://www.semanticscholar.org/paper/d800b1df83ab5408c4cb2c84edbd679fb5970473\",\"venue\":\"Frontiers in Computational Neuroscience\",\"year\":2020},{\"arxivId\":\"2007.13839\",\"authors\":[{\"authorId\":\"48380246\",\"name\":\"Yifeng Zhang\"},{\"authorId\":\"1405907659\",\"name\":\"Ming Jiang\"},{\"authorId\":\"153386875\",\"name\":\"Q. Zhao\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"4ba67b0734477ff392367f52542ad2dab179da83\",\"title\":\"Saliency Prediction with External Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/4ba67b0734477ff392367f52542ad2dab179da83\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":7676247,\"doi\":\"10.1109/ICCV.2015.38\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":78,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"1281e443d2cf1c1dd71ed3b7b0376d408d0958af\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"2256269\",\"name\":\"C. Farabet\"},{\"authorId\":\"2341378\",\"name\":\"C. Couprie\"},{\"authorId\":\"1688714\",\"name\":\"Laurent Najman\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"}],\"doi\":\"10.1109/TPAMI.2012.231\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"237a04dd8291cbdb59b6dc4b53e689af743fe2a3\",\"title\":\"Learning Hierarchical Features for Scene Labeling\",\"url\":\"https://www.semanticscholar.org/paper/237a04dd8291cbdb59b6dc4b53e689af743fe2a3\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143615083\",\"name\":\"R. J. Peters\"},{\"authorId\":\"4292093\",\"name\":\"A. Iyer\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"}],\"doi\":\"10.1016/j.visres.2005.03.019\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"a7447f7e6197c0875a28686efdffe4ba4beb5460\",\"title\":\"Components of bottom-up gaze allocation in natural images\",\"url\":\"https://www.semanticscholar.org/paper/a7447f7e6197c0875a28686efdffe4ba4beb5460\",\"venue\":\"Vision Research\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1396144799\",\"name\":\"A. Garc\\u00eda-D\\u00edaz\"},{\"authorId\":\"1398290502\",\"name\":\"Xos\\u00e9 R. Fern\\u00e1ndez-Vidal\"},{\"authorId\":\"1768258\",\"name\":\"X. Pardo\"},{\"authorId\":\"1751198\",\"name\":\"Raquel Dosil\"}],\"doi\":\"10.1016/j.imavis.2011.11.007\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b089afcf58bfdc73a956e015c82a8005ec313dac\",\"title\":\"Saliency from hierarchical adaptation through decorrelation and variance normalization\",\"url\":\"https://www.semanticscholar.org/paper/b089afcf58bfdc73a956e015c82a8005ec313dac\",\"venue\":\"Image Vis. Comput.\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2608733\",\"name\":\"Stas Goferman\"},{\"authorId\":\"1398327241\",\"name\":\"L. Zelnik-Manor\"},{\"authorId\":\"49653522\",\"name\":\"A. Tal\"}],\"doi\":\"10.1109/TPAMI.2011.272\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"fbe18b90b9e3031bfb7044226882cfc763e0a1ee\",\"title\":\"Context-Aware Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/fbe18b90b9e3031bfb7044226882cfc763e0a1ee\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38497468\",\"name\":\"M. Cerf\"},{\"authorId\":\"39810944\",\"name\":\"Jonathan Harel\"},{\"authorId\":\"1917767\",\"name\":\"W. Einh\\u00e4user\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a48dc9c898d6ff1cdb96dcf8a297bafb8ac1b9e2\",\"title\":\"Predicting human gaze using low-level saliency combined with face detection\",\"url\":\"https://www.semanticscholar.org/paper/a48dc9c898d6ff1cdb96dcf8a297bafb8ac1b9e2\",\"venue\":\"NIPS\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1109/CVPR.2012.6247711\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5e3d92c27e2fbb407243a6279dfafe9260a3732d\",\"title\":\"Exploiting local and global patch rarities for saliency detection\",\"url\":\"https://www.semanticscholar.org/paper/5e3d92c27e2fbb407243a6279dfafe9260a3732d\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2602925\",\"name\":\"Boris Schauerte\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"}],\"doi\":\"10.1007/978-3-642-33709-3_9\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5a0d596ef86c7563c0907c052273113f51006479\",\"title\":\"Quaternion-Based Spectral Saliency Detection for Eye Fixation Prediction\",\"url\":\"https://www.semanticscholar.org/paper/5a0d596ef86c7563c0907c052273113f51006479\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7326223\",\"name\":\"L. Itti\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"}],\"doi\":\"10.1016/S0042-6989(99)00163-7\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7b4b801de1ba8a4456adcde7b1a9c5bc5cf09fc3\",\"title\":\"A saliency-based search mechanism for overt and covert shifts of visual attention\",\"url\":\"https://www.semanticscholar.org/paper/7b4b801de1ba8a4456adcde7b1a9c5bc5cf09fc3\",\"venue\":\"Vision Research\",\"year\":2000},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143775672\",\"name\":\"Tilke Judd\"},{\"authorId\":\"1865091\",\"name\":\"Krista A. Ehinger\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/ICCV.2009.5459462\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c7614898de1cfee1a3a1c564f52c1e67879c29b3\",\"title\":\"Learning to predict where humans look\",\"url\":\"https://www.semanticscholar.org/paper/c7614898de1cfee1a3a1c564f52c1e67879c29b3\",\"venue\":\"2009 IEEE 12th International Conference on Computer Vision\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39810944\",\"name\":\"Jonathan Harel\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"}],\"doi\":\"10.7551/mitpress/7503.003.0073\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f412bb31ec9ef8bbef70eefc7ffd04420c1365d9\",\"title\":\"Graph-Based Visual Saliency\",\"url\":\"https://www.semanticscholar.org/paper/f412bb31ec9ef8bbef70eefc7ffd04420c1365d9\",\"venue\":\"NIPS\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2500502\",\"name\":\"Chuanbo Chen\"},{\"authorId\":\"153498894\",\"name\":\"H. Tang\"},{\"authorId\":\"2217669\",\"name\":\"Z. Lyu\"},{\"authorId\":\"48333321\",\"name\":\"Hu Liang\"},{\"authorId\":\"49897626\",\"name\":\"Jun Shang\"},{\"authorId\":\"3221422\",\"name\":\"M. Sarem\"}],\"doi\":\"10.1117/1.JEI.23.5.053023\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"645194693abd70a0c8947f336c3be357251e572d\",\"title\":\"Saliency modeling via outlier detection\",\"url\":\"https://www.semanticscholar.org/paper/645194693abd70a0c8947f336c3be357251e572d\",\"venue\":\"J. Electronic Imaging\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152627906\",\"name\":\"T. Judd\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"daef3fdc4190927c063ae94c12437cf82a6d1c20\",\"title\":\"A Benchmark of Computational Models of Saliency to Predict Human Fixations\",\"url\":\"https://www.semanticscholar.org/paper/daef3fdc4190927c063ae94c12437cf82a6d1c20\",\"venue\":\"\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145624227\",\"name\":\"C. Koch\"},{\"authorId\":\"1743045\",\"name\":\"S. Ullman\"}],\"doi\":\"10.1007/978-94-009-3833-5_5\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0ce672e6ef09e9ab4c43f1eb75443dc7a5cb38c6\",\"title\":\"Shifts in selective visual attention: towards the underlying neural circuitry.\",\"url\":\"https://www.semanticscholar.org/paper/0ce672e6ef09e9ab4c43f1eb75443dc7a5cb38c6\",\"venue\":\"Human neurobiology\",\"year\":1985},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145897550\",\"name\":\"D. M. Green\"},{\"authorId\":\"2498246\",\"name\":\"J. Swets\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"faf2933887410cb110cd7c68487cb0dd81d363ee\",\"title\":\"Signal detection theory and psychophysics\",\"url\":\"https://www.semanticscholar.org/paper/faf2933887410cb110cd7c68487cb0dd81d363ee\",\"venue\":\"\",\"year\":1966},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2989773\",\"name\":\"Nicolas Riche\"},{\"authorId\":\"1681157\",\"name\":\"M. Mancas\"},{\"authorId\":\"2896417\",\"name\":\"Matthieu Duvinage\"},{\"authorId\":\"3028207\",\"name\":\"Makiese Mibulumukini\"},{\"authorId\":\"50276543\",\"name\":\"B. Gosselin\"},{\"authorId\":\"49164810\",\"name\":\"T. Dutoit\"}],\"doi\":\"10.1016/j.image.2013.03.009\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"83ec029e1a7b41669f8254b24c070050d9d01d75\",\"title\":\"RARE2012: A multi-scale rarity-based saliency detection with its comparative statistical analysis\",\"url\":\"https://www.semanticscholar.org/paper/83ec029e1a7b41669f8254b24c070050d9d01d75\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2502152\",\"name\":\"A. Treisman\"},{\"authorId\":\"46475250\",\"name\":\"G. Gelade\"}],\"doi\":\"10.1016/0010-0285(80)90005-5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"76361a44e145732a39dbc68d9418871038c83be2\",\"title\":\"A feature-integration theory of attention\",\"url\":\"https://www.semanticscholar.org/paper/76361a44e145732a39dbc68d9418871038c83be2\",\"venue\":\"Cognitive Psychology\",\"year\":1980},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1917767\",\"name\":\"W. Einh\\u00e4user\"},{\"authorId\":\"38163342\",\"name\":\"Merrielle Spain\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"}],\"doi\":\"10.1167/8.14.18\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c032ef5e4ce9536de5669bbe487e1f618d3a12a6\",\"title\":\"Objects predict fixations better than early saliency.\",\"url\":\"https://www.semanticscholar.org/paper/c032ef5e4ce9536de5669bbe487e1f618d3a12a6\",\"venue\":\"Journal of vision\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3329744\",\"name\":\"Chengyao Shen\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1016/j.neucom.2013.09.053\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c47bb003c2c8063cb45d690232448b3259462aaf\",\"title\":\"Learning to predict eye fixations for semantic contents using multi-layer sparse network\",\"url\":\"https://www.semanticscholar.org/paper/c47bb003c2c8063cb45d690232448b3259462aaf\",\"venue\":\"Neurocomputing\",\"year\":2014},{\"arxivId\":\"1311.2901\",\"authors\":[{\"authorId\":\"48799969\",\"name\":\"Matthew D. Zeiler\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":\"10.1007/978-3-319-10590-1_53\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"1a2a770d23b4a171fa81de62a78a3deb0588f238\",\"title\":\"Visualizing and Understanding Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/1a2a770d23b4a171fa81de62a78a3deb0588f238\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1701293\",\"name\":\"J. Zhang\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"}],\"doi\":\"10.1109/ICCV.2013.26\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"75ee5cd7712b6ad13d64c3b4de24aa592a869fc1\",\"title\":\"Saliency Detection: A Boolean Map Approach\",\"url\":\"https://www.semanticscholar.org/paper/75ee5cd7712b6ad13d64c3b4de24aa592a869fc1\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":\"1411.1045\",\"authors\":[{\"authorId\":\"2997408\",\"name\":\"Matthias K\\u00fcmmerer\"},{\"authorId\":\"2073063\",\"name\":\"L. Theis\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"652e652bca63f60c2c5f5840d4a34bb743f699b9\",\"title\":\"Deep Gaze I: Boosting Saliency Prediction with Feature Maps Trained on ImageNet\",\"url\":\"https://www.semanticscholar.org/paper/652e652bca63f60c2c5f5840d4a34bb743f699b9\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47059693\",\"name\":\"L. Zhang\"},{\"authorId\":\"49488601\",\"name\":\"M. Tong\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"},{\"authorId\":\"2207531\",\"name\":\"Honghao Shan\"},{\"authorId\":\"48524582\",\"name\":\"G. Cottrell\"}],\"doi\":\"10.1167/8.7.32\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e80c48441351fc1d928524710b4500a0de8315bb\",\"title\":\"SUN: A Bayesian framework for saliency using natural statistics.\",\"url\":\"https://www.semanticscholar.org/paper/e80c48441351fc1d928524710b4500a0de8315bb\",\"venue\":\"Journal of vision\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144361581\",\"name\":\"J. Long\"},{\"authorId\":\"1782282\",\"name\":\"Evan Shelhamer\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/CVPR.2015.7298965\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9201bf6f8222c2335913002e13fbac640fc0f4ec\",\"title\":\"Fully convolutional networks for semantic segmentation\",\"url\":\"https://www.semanticscholar.org/paper/9201bf6f8222c2335913002e13fbac640fc0f4ec\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143905571\",\"name\":\"Nian Liu\"},{\"authorId\":\"7181955\",\"name\":\"J. Han\"},{\"authorId\":\"39901030\",\"name\":\"Dingwen Zhang\"},{\"authorId\":\"2330182\",\"name\":\"S. Wen\"},{\"authorId\":\"145251057\",\"name\":\"T. Liu\"}],\"doi\":\"10.1109/CVPR.2015.7298633\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"c6551c3c5e4c9779b2bbc6c8edcdeab545bc824d\",\"title\":\"Predicting eye fixations using convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/c6551c3c5e4c9779b2bbc6c8edcdeab545bc824d\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2286630\",\"name\":\"E. Vig\"},{\"authorId\":\"1944405\",\"name\":\"M. Dorr\"},{\"authorId\":\"2042941\",\"name\":\"D. Cox\"}],\"doi\":\"10.1109/CVPR.2014.358\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8693c32dff29e851760fa0b6af464050ffc383d6\",\"title\":\"Large-Scale Optimization of Hierarchical Features for Saliency Prediction in Natural Images\",\"url\":\"https://www.semanticscholar.org/paper/8693c32dff29e851760fa0b6af464050ffc383d6\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2866780\",\"name\":\"Neil D. B. Bruce\"},{\"authorId\":\"1727853\",\"name\":\"John K. Tsotsos\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4f847b4ddc105d73bc78f3e7220e6c1f71a7dfb6\",\"title\":\"Saliency Based on Information Maximization\",\"url\":\"https://www.semanticscholar.org/paper/4f847b4ddc105d73bc78f3e7220e6c1f71a7dfb6\",\"venue\":\"NIPS\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3084719\",\"name\":\"Xiaodi Hou\"},{\"authorId\":\"39810944\",\"name\":\"Jonathan Harel\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"}],\"doi\":\"10.1109/TPAMI.2011.146\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"48c2b8a35ce9468b84ac032af70cf2b100f5c1fc\",\"title\":\"Image Signature: Highlighting Sparse Salient Regions\",\"url\":\"https://www.semanticscholar.org/paper/48c2b8a35ce9468b84ac032af70cf2b100f5c1fc\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2012},{\"arxivId\":\"1409.4842\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"46641766\",\"name\":\"W. Liu\"},{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"},{\"authorId\":\"48840704\",\"name\":\"Scott Reed\"},{\"authorId\":\"1838674\",\"name\":\"Dragomir Anguelov\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"39863668\",\"name\":\"Andrew Rabinovich\"}],\"doi\":\"10.1109/CVPR.2015.7298594\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"title\":\"Going deeper with convolutions\",\"url\":\"https://www.semanticscholar.org/paper/e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3056091\",\"name\":\"M. Everingham\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"145715698\",\"name\":\"C. K. Williams\"},{\"authorId\":\"33652486\",\"name\":\"J. Winn\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/s11263-009-0275-4\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"82635fb63640ae95f90ee9bdc07832eb461ca881\",\"title\":\"The Pascal Visual Object Classes (VOC) Challenge\",\"url\":\"https://www.semanticscholar.org/paper/82635fb63640ae95f90ee9bdc07832eb461ca881\",\"venue\":\"International Journal of Computer Vision\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"}],\"doi\":\"10.1167/13.4.11\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9896b03aeb17e06181c1842773fec4b742d7c51f\",\"title\":\"Visual saliency estimation by nonlinearly integrating features using region covariances.\",\"url\":\"https://www.semanticscholar.org/paper/9896b03aeb17e06181c1842773fec4b742d7c51f\",\"venue\":\"Journal of vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7326223\",\"name\":\"L. Itti\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"}],\"doi\":\"10.1038/35058500\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"320b36777d57e772d88d278ceeccd1f5e746304c\",\"title\":\"Computational modelling of visual attention\",\"url\":\"https://www.semanticscholar.org/paper/320b36777d57e772d88d278ceeccd1f5e746304c\",\"venue\":\"Nature Reviews Neuroscience\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3369864\",\"name\":\"B. Tatler\"},{\"authorId\":\"34931109\",\"name\":\"R. Baddeley\"},{\"authorId\":\"2283822\",\"name\":\"I. Gilchrist\"}],\"doi\":\"10.1016/j.visres.2004.09.017\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ae38ed953333fb39eb671fce0247db65a09b3a80\",\"title\":\"Visual correlates of fixation selection: effects of scale and time\",\"url\":\"https://www.semanticscholar.org/paper/ae38ed953333fb39eb671fce0247db65a09b3a80\",\"venue\":\"Vision Research\",\"year\":2005},{\"arxivId\":\"1406.2807\",\"authors\":[{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"3084719\",\"name\":\"Xiaodi Hou\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.1109/CVPR.2014.43\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"40e71c10edc2afc68d079546e8f4952cd52dc671\",\"title\":\"The Secrets of Salient Object Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/40e71c10edc2afc68d079546e8f4952cd52dc671\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"C Chen\"},{\"authorId\":null,\"name\":\"H Tang\"},{\"authorId\":null,\"name\":\"Z Lyu\"},{\"authorId\":null,\"name\":\"H Liang\"},{\"authorId\":null,\"name\":\"J Shang\"},{\"authorId\":null,\"name\":\"M Serem\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Saliency modeling via outlier detection. JEI\",\"url\":\"\",\"venue\":\"Saliency modeling via outlier detection. JEI\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1742936\",\"name\":\"S. Ramanathan\"},{\"authorId\":\"2478739\",\"name\":\"H. Katti\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1007/978-3-642-15561-1_3\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"ec80f411ef1c08eae586047d97977f9ef59dd6f5\",\"title\":\"An Eye Fixation Database for Saliency Detection in Images\",\"url\":\"https://www.semanticscholar.org/paper/ec80f411ef1c08eae586047d97977f9ef59dd6f5\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7326223\",\"name\":\"L. Itti\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"},{\"authorId\":\"3271571\",\"name\":\"E. Niebur\"}],\"doi\":\"10.1109/34.730558\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4816f0b6f0d05da3901441bfa5cc7be044b4da8b\",\"title\":\"A Model of Saliency-Based Visual Attention for Rapid Scene Analysis\",\"url\":\"https://www.semanticscholar.org/paper/4816f0b6f0d05da3901441bfa5cc7be044b4da8b\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144114624\",\"name\":\"Juan Xu\"},{\"authorId\":\"144889908\",\"name\":\"M. Jiang\"},{\"authorId\":\"40440632\",\"name\":\"Shuo Wang\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"},{\"authorId\":\"51027614\",\"name\":\"Q. Zhao\"}],\"doi\":\"10.1167/14.1.28\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"709e8791193cc3fe9fef9ad983afcd2891e6c680\",\"title\":\"Predicting human gaze beyond pixels.\",\"url\":\"https://www.semanticscholar.org/paper/709e8791193cc3fe9fef9ad983afcd2891e6c680\",\"venue\":\"Journal of vision\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2681887\",\"name\":\"D. Rumelhart\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"},{\"authorId\":\"40410858\",\"name\":\"R. J. Williams\"}],\"doi\":\"10.1038/323533a0\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"052b1d8ce63b07fec3de9dbb583772d860b7c769\",\"title\":\"Learning representations by back-propagating errors\",\"url\":\"https://www.semanticscholar.org/paper/052b1d8ce63b07fec3de9dbb583772d860b7c769\",\"venue\":\"Nature\",\"year\":1986},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"134861178\",\"name\":\"Wei Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPRW.2009.5206848\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d2c733e34d48784a37d717fe43d9e93277a8c53e\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/d2c733e34d48784a37d717fe43d9e93277a8c53e\",\"venue\":\"2009 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32369256\",\"name\":\"T. Jost\"},{\"authorId\":\"3151890\",\"name\":\"N. Ouerhani\"},{\"authorId\":\"1939985\",\"name\":\"R. Wartburg\"},{\"authorId\":\"34663587\",\"name\":\"R. M\\u00fcri\"},{\"authorId\":\"152447339\",\"name\":\"Heinz Hugli\"}],\"doi\":\"10.1016/j.cviu.2004.10.009\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"72fc3f2d4805c3d7b060d4a6aa19326d2ad37fbc\",\"title\":\"Assessing the contribution of color in visual attention\",\"url\":\"https://www.semanticscholar.org/paper/72fc3f2d4805c3d7b060d4a6aa19326d2ad37fbc\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47521917\",\"name\":\"Q. Zhao\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"}],\"doi\":\"10.1167/12.6.22\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a020ea916bb8fa9cbc4cb7da4c22e7f35d81f3f3\",\"title\":\"Learning visual saliency by combining feature maps in a nonlinear manner using AdaBoost.\",\"url\":\"https://www.semanticscholar.org/paper/a020ea916bb8fa9cbc4cb7da4c22e7f35d81f3f3\",\"venue\":\"Journal of vision\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"S. Sclaroff\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Predicting human gaze beyond pixels Visualizing and understanding convolutional networks\",\"url\":\"\",\"venue\":\"\",\"year\":2014},{\"arxivId\":\"1412.4564\",\"authors\":[{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"3257286\",\"name\":\"Karel Lenc\"}],\"doi\":\"10.1145/2733373.2807412\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0bde8d9367d1004c7396dd69cb27ed97dc2f8d77\",\"title\":\"MatConvNet: Convolutional Neural Networks for MATLAB\",\"url\":\"https://www.semanticscholar.org/paper/0bde8d9367d1004c7396dd69cb27ed97dc2f8d77\",\"venue\":\"ACM Multimedia\",\"year\":2015}],\"title\":\"SALICON: Reducing the Semantic Gap in Saliency Prediction by Adapting Deep Neural Networks\",\"topics\":[{\"topic\":\"Deep learning\",\"topicId\":\"2762\",\"url\":\"https://www.semanticscholar.org/topic/2762\"},{\"topic\":\"Eye tracking\",\"topicId\":\"7621\",\"url\":\"https://www.semanticscholar.org/topic/7621\"},{\"topic\":\"Scene statistics\",\"topicId\":\"315338\",\"url\":\"https://www.semanticscholar.org/topic/315338\"},{\"topic\":\"High- and low-level\",\"topicId\":\"33507\",\"url\":\"https://www.semanticscholar.org/topic/33507\"},{\"topic\":\"Outline of object recognition\",\"topicId\":\"34569\",\"url\":\"https://www.semanticscholar.org/topic/34569\"},{\"topic\":\"Optimization problem\",\"topicId\":\"12682\",\"url\":\"https://www.semanticscholar.org/topic/12682\"},{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"},{\"topic\":\"Loss function\",\"topicId\":\"3650\",\"url\":\"https://www.semanticscholar.org/topic/3650\"}],\"url\":\"https://www.semanticscholar.org/paper/1281e443d2cf1c1dd71ed3b7b0376d408d0958af\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015}\n"