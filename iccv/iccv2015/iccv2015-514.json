"{\"abstract\":\"Human actions in video sequences are three-dimensional (3D) spatio-temporal signals characterizing both the visual appearance and motion dynamics of the involved humans and objects. Inspired by the success of convolutional neural networks (CNN) for image classification, recent attempts have been made to learn 3D CNNs for recognizing human actions in videos. However, partly due to the high complexity of training 3D convolution kernels and the need for large quantities of training videos, only limited success has been reported. This has triggered us to investigate in this paper a new deep architecture which can handle 3D signals more effectively. Specifically, we propose factorized spatio-temporal convolutional networks (FstCN) that factorize the original 3D convolution kernel learning as a sequential process of learning 2D spatial kernels in the lower layers (called spatial convolutional layers), followed by learning 1D temporal kernels in the upper layers (called temporal convolutional layers). We introduce a novel transformation and permutation operator to make factorization in FstCN possible. Moreover, to address the issue of sequence alignment, we propose an effective training and inference strategy based on sampling multiple video clips from a given action video sequence. We have tested FstCN on two commonly used benchmark datasets (UCF-101 and HMDB-51). Without using auxiliary training videos to boost the performance, FstCN outperforms existing CNN based methods and achieves comparable performance with a recent method that benefits from using auxiliary training videos.\",\"arxivId\":\"1510.00562\",\"authors\":[{\"authorId\":\"41191188\",\"name\":\"Lin Sun\",\"url\":\"https://www.semanticscholar.org/author/41191188\"},{\"authorId\":\"2370507\",\"name\":\"K. Jia\",\"url\":\"https://www.semanticscholar.org/author/2370507\"},{\"authorId\":\"1739816\",\"name\":\"D. Yeung\",\"url\":\"https://www.semanticscholar.org/author/1739816\"},{\"authorId\":\"2131088\",\"name\":\"B. Shi\",\"url\":\"https://www.semanticscholar.org/author/2131088\"}],\"citationVelocity\":89,\"citations\":[{\"arxivId\":\"1806.07754\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"2713759\",\"name\":\"M. M. Arzani\"},{\"authorId\":\"9456273\",\"name\":\"Rahman Yousefzadeh\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-030-01225-0_18\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"85fb0d6cc991cf49ebc4f506b5edd44214979f65\",\"title\":\"Spatio-Temporal Channel Correlation Networks for Action Classification\",\"url\":\"https://www.semanticscholar.org/paper/85fb0d6cc991cf49ebc4f506b5edd44214979f65\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1711.11152\",\"authors\":[{\"authorId\":\"47392986\",\"name\":\"S. Sun\"},{\"authorId\":\"1874900\",\"name\":\"Zhanghui Kuang\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"84200540\",\"name\":\"Lu Sheng\"},{\"authorId\":\"1726357\",\"name\":\"Wayne Zhang\"}],\"doi\":\"10.1109/CVPR.2018.00151\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"42517e072406ea6f8d2c579d98ee3f9918a8a1d3\",\"title\":\"Optical Flow Guided Feature: A Fast and Robust Motion Representation for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/42517e072406ea6f8d2c579d98ee3f9918a8a1d3\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"70573226\",\"name\":\"Chien-Cheng Lee\"},{\"authorId\":\"145947730\",\"name\":\"W. Gao\"},{\"authorId\":\"117788097\",\"name\":\"P. Lui\"}],\"doi\":\"10.1109/IPTA.2019.8936075\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"720a87fa17d19f9da26a112dd5b58dad17615c76\",\"title\":\"Rat Grooming Behavior Detection with Two-stream Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/720a87fa17d19f9da26a112dd5b58dad17615c76\",\"venue\":\"2019 Ninth International Conference on Image Processing Theory, Tools and Applications (IPTA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7680552\",\"name\":\"Ziliang Ren\"},{\"authorId\":\"51286715\",\"name\":\"Qieshi Zhang\"},{\"authorId\":\"46757766\",\"name\":\"X. Gao\"},{\"authorId\":\"51289240\",\"name\":\"Pengyi Hao\"},{\"authorId\":\"114675671\",\"name\":\"J. Cheng\"}],\"doi\":\"10.1007/s11042-019-08576-z\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"683646753df25cb5ad91bdecc4bf6bb7bdf2f0bf\",\"title\":\"Multi-modality learning for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/683646753df25cb5ad91bdecc4bf6bb7bdf2f0bf\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"1712.04851\",\"authors\":[{\"authorId\":\"1817030\",\"name\":\"Saining Xie\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"1808244\",\"name\":\"J. Huang\"},{\"authorId\":\"144035504\",\"name\":\"Zhuowen Tu\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":\"10.1007/978-3-030-01267-0_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"815aa52cfc02961d82415f080384594639a21984\",\"title\":\"Rethinking Spatiotemporal Feature Learning: Speed-Accuracy Trade-offs in Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/815aa52cfc02961d82415f080384594639a21984\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9173291\",\"name\":\"L. Wang\"},{\"authorId\":\"14800230\",\"name\":\"J. Zang\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"1786361\",\"name\":\"Zhenxing Niu\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"}],\"doi\":\"10.3390/s18071979\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"2588acc7a730d864f84d4e1a050070ff873b03d5\",\"title\":\"Action Recognition by an Attention-Aware Temporal Weighted Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/2588acc7a730d864f84d4e1a050070ff873b03d5\",\"venue\":\"Sensors\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1832019\",\"name\":\"Fuhua Shang\"},{\"authorId\":\"145421603\",\"name\":\"Tao Han\"},{\"authorId\":\"152236895\",\"name\":\"Feng Tian\"},{\"authorId\":\"1884170385\",\"name\":\"Jun Tao\"},{\"authorId\":\"40465774\",\"name\":\"Z. Gao\"}],\"doi\":\"10.1109/ACCESS.2020.3014691\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c93dfb167a90c2a5a7b802c629327224d4ee806\",\"title\":\"A Multimodal Pairwise Discrimination Network for Cross-Domain Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1c93dfb167a90c2a5a7b802c629327224d4ee806\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7496553\",\"name\":\"Dongli Wang\"},{\"authorId\":\"1724199\",\"name\":\"Jun Yang\"},{\"authorId\":\"46433441\",\"name\":\"Y. Zhou\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7a04144818f52def61cef3856cde3dd81b6dbaf8\",\"title\":\"Human action recognition based on multi-mode spatial-temporal feature fusion\",\"url\":\"https://www.semanticscholar.org/paper/7a04144818f52def61cef3856cde3dd81b6dbaf8\",\"venue\":\"2019 22th International Conference on Information Fusion (FUSION)\",\"year\":2019},{\"arxivId\":\"1908.10136\",\"authors\":[{\"authorId\":\"2659862\",\"name\":\"J. Zhang\"},{\"authorId\":\"38083193\",\"name\":\"F. Shen\"},{\"authorId\":\"1390532590\",\"name\":\"Xing Xu\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f0446862cbdf61974e039a85d349d7f7864f42c1\",\"title\":\"Cooperative Cross-Stream Network for Discriminative Action Representation\",\"url\":\"https://www.semanticscholar.org/paper/f0446862cbdf61974e039a85d349d7f7864f42c1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1714016\",\"name\":\"F. W\\u00f6rg\\u00f6tter\"},{\"authorId\":\"20624177\",\"name\":\"F. Ziaeetabar\"},{\"authorId\":\"153091386\",\"name\":\"S. Pfeiffer\"},{\"authorId\":\"144108901\",\"name\":\"O. Kaya\"},{\"authorId\":\"1518685532\",\"name\":\"T. Kulvicius\"},{\"authorId\":\"152716499\",\"name\":\"M. Tamosiunaite\"}],\"doi\":\"10.1038/s41598-020-60923-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8ca4989ac8316cfe0e243c7cd54f8a517f58aea0\",\"title\":\"Humans Predict Action using Grammar-like Structures\",\"url\":\"https://www.semanticscholar.org/paper/8ca4989ac8316cfe0e243c7cd54f8a517f58aea0\",\"venue\":\"Scientific Reports\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1787575\",\"name\":\"Ruibin Bai\"},{\"authorId\":\"1730925\",\"name\":\"Qing Zhao\"},{\"authorId\":\"3373601\",\"name\":\"Sanping Zhou\"},{\"authorId\":\"48514605\",\"name\":\"Y. Li\"},{\"authorId\":\"74491229\",\"name\":\"Xueji Zhao\"},{\"authorId\":\"32014778\",\"name\":\"J. Wang\"}],\"doi\":\"10.1109/ICPR.2018.8546019\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f8462eea5a986ac4a38be9f19229bf70461dc262\",\"title\":\"Continuous Action Recognition and Segmentation in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/f8462eea5a986ac4a38be9f19229bf70461dc262\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":\"1904.13080\",\"authors\":[{\"authorId\":\"145377162\",\"name\":\"Y. Yuan\"},{\"authorId\":\"49370704\",\"name\":\"Dong Wang\"},{\"authorId\":\"39669401\",\"name\":\"Q. Wang\"}],\"doi\":\"10.1609/aaai.v33i01.33019167\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e3fc2a67967b1355609094175f19b2412dd4851d\",\"title\":\"Memory-Augmented Temporal Dynamic Learning for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e3fc2a67967b1355609094175f19b2412dd4851d\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48916825\",\"name\":\"I. Lassoued\"},{\"authorId\":\"1684187\",\"name\":\"E. Zagrouba\"}],\"doi\":\"10.1007/s11042-017-5477-0\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"0e415707ef6824dfffe9bb33b16a0a4a77485f53\",\"title\":\"Human actions recognition: an approach based on stable motion boundary fields\",\"url\":\"https://www.semanticscholar.org/paper/0e415707ef6824dfffe9bb33b16a0a4a77485f53\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153008120\",\"name\":\"Zineng Xu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6eee0fd08e8b33bf2affb355a6ecd3523860aa11\",\"title\":\"Action recognition in videos\",\"url\":\"https://www.semanticscholar.org/paper/6eee0fd08e8b33bf2affb355a6ecd3523860aa11\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"114498698\",\"name\":\"Ankush Manocha\"},{\"authorId\":\"50631782\",\"name\":\"R. Singh\"}],\"doi\":\"10.1007/S12652-019-01277-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8f9337a88b22f0177727c20d3c8159b3e3af7392\",\"title\":\"An intelligent monitoring system for indoor safety of individuals suffering from Autism Spectrum Disorder (ASD)\",\"url\":\"https://www.semanticscholar.org/paper/8f9337a88b22f0177727c20d3c8159b3e3af7392\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48321132\",\"name\":\"Y. Zou\"},{\"authorId\":\"9641665\",\"name\":\"X. Ren\"}],\"doi\":\"10.1007/978-981-15-8458-9_68\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a960a1e5184f5a90a7779cb7ffcc2d33140ec68f\",\"title\":\"An Efficient Action Recognition Framework Based on ELM and 3D CNN\",\"url\":\"https://www.semanticscholar.org/paper/a960a1e5184f5a90a7779cb7ffcc2d33140ec68f\",\"venue\":\"\",\"year\":2021},{\"arxivId\":\"1912.01180\",\"authors\":[{\"authorId\":\"145954571\",\"name\":\"Y. Zhang\"},{\"authorId\":\"12732902\",\"name\":\"Xinyue Wei\"},{\"authorId\":\"3256056\",\"name\":\"Weichao Qiu\"},{\"authorId\":\"9381483\",\"name\":\"Zihao Xiao\"},{\"authorId\":\"1678633\",\"name\":\"Gregory Hager\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b3260a2fb397b9a04d96546f0823ce7b84ba8e3d\",\"title\":\"RSA: Randomized Simulation as Augmentation for Robust Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b3260a2fb397b9a04d96546f0823ce7b84ba8e3d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144692146\",\"name\":\"Ming Tong\"},{\"authorId\":\"27746265\",\"name\":\"Mengao Zhao\"},{\"authorId\":\"5442167\",\"name\":\"Yiran Chen\"},{\"authorId\":\"49527719\",\"name\":\"Houyi Wang\"}],\"doi\":\"10.1016/j.neucom.2018.09.086\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d98642db8d4fc5330190c7832b86e8bbf85b46ca\",\"title\":\"D3-LND: A two-stream framework with discriminant deep descriptor, linear CMDT and nonlinear KCMDT descriptors for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/d98642db8d4fc5330190c7832b86e8bbf85b46ca\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49121030\",\"name\":\"Rajiv Singh\"},{\"authorId\":\"39727023\",\"name\":\"Swati Nigam\"}],\"doi\":\"10.1007/978-3-030-15887-3_32\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6fe2ae40ea54aca412628913a7e69543b607aa6c\",\"title\":\"Deep Neural Networks for Human Behavior Understanding\",\"url\":\"https://www.semanticscholar.org/paper/6fe2ae40ea54aca412628913a7e69543b607aa6c\",\"venue\":\"Handbook of Multimedia Information Security\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49325258\",\"name\":\"Mingzhi Pang\"},{\"authorId\":\"8314653\",\"name\":\"X. Yang\"},{\"authorId\":\"49722131\",\"name\":\"J. Liu\"},{\"authorId\":\"10367284\",\"name\":\"Peihao Li\"},{\"authorId\":\"2028614762\",\"name\":\"Faren Yan\"},{\"authorId\":\"70173441\",\"name\":\"P. Chen\"}],\"doi\":\"10.1007/978-981-33-4214-9_17\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b150cc58f6972fc8f2497d6b6589ea70f00aba51\",\"title\":\"Device-Free Activity Recognition: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/b150cc58f6972fc8f2497d6b6589ea70f00aba51\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145061360\",\"name\":\"S. Ravi\"},{\"authorId\":\"30430452\",\"name\":\"M. Suman\"},{\"authorId\":\"144186025\",\"name\":\"P. Kishore\"},{\"authorId\":\"79324299\",\"name\":\"Kiran Kumar Eepuri\"},{\"authorId\":\"48387925\",\"name\":\"Maddala Teja Kiran Kumar\"},{\"authorId\":\"41212177\",\"name\":\"D. Kumar\"}],\"doi\":\"10.1016/J.COLA.2019.04.002\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fed9af888038dcffd51d648c9e81e8a53c7efcd2\",\"title\":\"Multi modal spatio temporal co-trained CNNs with single modal testing on RGB-D based sign language gesture recognition\",\"url\":\"https://www.semanticscholar.org/paper/fed9af888038dcffd51d648c9e81e8a53c7efcd2\",\"venue\":\"J. Comput. Lang.\",\"year\":2019},{\"arxivId\":\"1709.06495\",\"authors\":[{\"authorId\":\"1756362\",\"name\":\"Swathikiran Sudhakaran\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"}],\"doi\":\"10.1109/ICCVW.2017.276\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5155499812dafee92316bdbca5937f0e134514f3\",\"title\":\"Convolutional Long Short-Term Memory Networks for Recognizing First Person Interactions\",\"url\":\"https://www.semanticscholar.org/paper/5155499812dafee92316bdbca5937f0e134514f3\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153580352\",\"name\":\"Ionut Cosmin Duta\"}],\"doi\":null,\"intent\":[\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"558fc9a2bce3d3993a9c1f41b6c7f290cefcf92f\",\"title\":\"Efficient and Effective Solutions for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/558fc9a2bce3d3993a9c1f41b6c7f290cefcf92f\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40354734\",\"name\":\"Haoze Wu\"},{\"authorId\":\"51260253\",\"name\":\"Z. Zha\"},{\"authorId\":\"145919634\",\"name\":\"X. Wen\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"},{\"authorId\":\"153626293\",\"name\":\"Dong Liu\"},{\"authorId\":\"46772808\",\"name\":\"X. Chen\"}],\"doi\":\"10.1145/3343031.3350891\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b725e11efdc4b4bd367e555dd2a70530b9002c68\",\"title\":\"Cross-Fiber Spatial-Temporal Co-enhanced Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b725e11efdc4b4bd367e555dd2a70530b9002c68\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49419064\",\"name\":\"Xuemei Xie\"},{\"authorId\":\"102868457\",\"name\":\"W. Li\"},{\"authorId\":\"46276098\",\"name\":\"Jianan Li\"},{\"authorId\":\"1735328\",\"name\":\"X. Xu\"},{\"authorId\":\"144410724\",\"name\":\"K. Jin\"}],\"doi\":\"10.1145/3234804.3234821\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a3dcdfdedc119bc3ae63dbe7f3ed6baa3218ed5f\",\"title\":\"Local Feature Analysis for real-time Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a3dcdfdedc119bc3ae63dbe7f3ed6baa3218ed5f\",\"venue\":\"ICDLT '18\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2704179\",\"name\":\"Dongang Wang\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"50135099\",\"name\":\"W. Li\"},{\"authorId\":\"145481070\",\"name\":\"D. Xu\"}],\"doi\":\"10.1007/978-3-030-01240-3_28\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d2003d6e1de789b7fe60819257d8dfd54d267517\",\"title\":\"Dividing and Aggregating Network for Multi-view Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d2003d6e1de789b7fe60819257d8dfd54d267517\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145161471\",\"name\":\"Y. Yoon\"},{\"authorId\":\"2199479\",\"name\":\"Jongmin Yu\"},{\"authorId\":\"2184044\",\"name\":\"Moongu Jeon\"}],\"doi\":\"10.1109/AVSS.2019.8909868\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"60d7c89c12351d5b05f221092ed537d0869228b2\",\"title\":\"Spatio-Temporal Feature Extraction and Distance Metric Learning for Unconstrained Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/60d7c89c12351d5b05f221092ed537d0869228b2\",\"venue\":\"2019 16th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738282\",\"name\":\"Y. Zheng\"},{\"authorId\":\"1720100\",\"name\":\"H. Yao\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"}],\"doi\":\"10.1016/j.sigpro.2017.10.022\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"778e6aee04548ec06a52fd3f6aff32074132abdd\",\"title\":\"Distinctive action sketch for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/778e6aee04548ec06a52fd3f6aff32074132abdd\",\"venue\":\"Signal Process.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2001082\",\"name\":\"Maryam Koohzadi\"},{\"authorId\":\"1755153\",\"name\":\"N. M. Charkari\"}],\"doi\":\"10.1049/iet-cvi.2016.0355\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c0ba4aa78802bb51daeb2264df2e11bf11ecfbbe\",\"title\":\"Survey on deep learning methods in human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/c0ba4aa78802bb51daeb2264df2e11bf11ecfbbe\",\"venue\":\"IET Comput. Vis.\",\"year\":2017},{\"arxivId\":\"2004.00945\",\"authors\":[{\"authorId\":\"10384643\",\"name\":\"Yong-Lu Li\"},{\"authorId\":\"151484848\",\"name\":\"Liang Xu\"},{\"authorId\":\"2128016\",\"name\":\"Xinpeng Liu\"},{\"authorId\":\"49444914\",\"name\":\"X. Huang\"},{\"authorId\":\"1409933106\",\"name\":\"Yue Xu\"},{\"authorId\":\"3826706\",\"name\":\"S. Wang\"},{\"authorId\":\"122851212\",\"name\":\"Haoshu Fang\"},{\"authorId\":\"145136705\",\"name\":\"Ze Ma\"},{\"authorId\":\"48622851\",\"name\":\"Mingyang Chen\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"}],\"doi\":\"10.1109/cvpr42600.2020.00046\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"37d2e1c24e4da0021504667cf528f1d7ef2291dd\",\"title\":\"PaStaNet: Toward Human Activity Knowledge Engine\",\"url\":\"https://www.semanticscholar.org/paper/37d2e1c24e4da0021504667cf528f1d7ef2291dd\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2014145\",\"name\":\"Mohammad Tavakolian\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"46606565\",\"name\":\"A. Hadid\"}],\"doi\":\"10.1109/ICCV.2019.00811\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"acd1e0773799658a4481693220f38157f204f9bf\",\"title\":\"AWSD: Adaptive Weighted Spatiotemporal Distillation for Video Representation\",\"url\":\"https://www.semanticscholar.org/paper/acd1e0773799658a4481693220f38157f204f9bf\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1708.05824\",\"authors\":[{\"authorId\":\"143638039\",\"name\":\"Y. Zhao\"},{\"authorId\":\"24052900\",\"name\":\"Rennong Yang\"},{\"authorId\":\"87494776\",\"name\":\"Guillaume Chevalier\"},{\"authorId\":\"48696158\",\"name\":\"R. Shah\"},{\"authorId\":\"3451951\",\"name\":\"Rob Romijnders\"}],\"doi\":\"10.1016/j.ijleo.2017.12.038\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"09fc69a06f4c709846719a06a00a8bce533928d7\",\"title\":\"Applying Deep Bidirectional LSTM and Mixture Density Network for Basketball Trajectory Prediction\",\"url\":\"https://www.semanticscholar.org/paper/09fc69a06f4c709846719a06a00a8bce533928d7\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50141555\",\"name\":\"X. Wang\"},{\"authorId\":\"48030848\",\"name\":\"W. Xie\"},{\"authorId\":\"13916793\",\"name\":\"Jiayi Song\"}],\"doi\":\"10.1109/ICSP.2018.8652354\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"39b7d5c3114938c3b18f24546e65a23fa0898e73\",\"title\":\"Learning Spatiotemporal Features With 3DCNN and ConvGRU for Video Anomaly Detection\",\"url\":\"https://www.semanticscholar.org/paper/39b7d5c3114938c3b18f24546e65a23fa0898e73\",\"venue\":\"2018 14th IEEE International Conference on Signal Processing (ICSP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50993183\",\"name\":\"Haochen Zhang\"},{\"authorId\":\"1718355\",\"name\":\"Dong Liu\"},{\"authorId\":\"2352456\",\"name\":\"Z. Xiong\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"39e04aa60e7e7824f26988fc9df3b42143bc8222\",\"title\":\"Two-Stream Oriented Video Super-Resolution for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/39e04aa60e7e7824f26988fc9df3b42143bc8222\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1812.00722\",\"authors\":[{\"authorId\":\"2539459\",\"name\":\"Petros Koutras\"},{\"authorId\":\"1750686\",\"name\":\"P. Maragos\"}],\"doi\":\"10.1109/CVPRW.2019.00109\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e330af2d061ade245622b9445d5be9717f66b60f\",\"title\":\"SUSiNet: See, Understand and Summarize It\",\"url\":\"https://www.semanticscholar.org/paper/e330af2d061ade245622b9445d5be9717f66b60f\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738282\",\"name\":\"Y. Zheng\"},{\"authorId\":\"1720100\",\"name\":\"H. Yao\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"49835905\",\"name\":\"Xuesong Jiang\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"}],\"doi\":\"10.1007/s11042-017-5038-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf784156547c3be146706e2763c1a52d939d1722\",\"title\":\"Breaking video into pieces for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/cf784156547c3be146706e2763c1a52d939d1722\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1888678\",\"name\":\"Miao Xin\"},{\"authorId\":\"46702644\",\"name\":\"H. Zhang\"},{\"authorId\":\"145070659\",\"name\":\"M. Sun\"},{\"authorId\":\"144437722\",\"name\":\"D. Yuan\"}],\"doi\":\"10.1109/IJCNN.2016.7727234\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8c7136d250f731b0ca8c274a67a07830a69a08fd\",\"title\":\"Recurrent Temporal Sparse Autoencoder for attention-based action recognition\",\"url\":\"https://www.semanticscholar.org/paper/8c7136d250f731b0ca8c274a67a07830a69a08fd\",\"venue\":\"2016 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1557606546\",\"name\":\"Jose M. Rodriguez-Borbon\"},{\"authorId\":\"72445820\",\"name\":\"X. Ma\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"},{\"authorId\":\"1778860\",\"name\":\"W. Najjar\"}],\"doi\":\"10.1109/TCSVT.2019.2895304\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"62be6ce7cab06e635281bb9a8d39062b5737d43c\",\"title\":\"Heterogeneous Acceleration of HAR Applications\",\"url\":\"https://www.semanticscholar.org/paper/62be6ce7cab06e635281bb9a8d39062b5737d43c\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"2011.09216\",\"authors\":[{\"authorId\":\"30857985\",\"name\":\"Nishant Bhattacharya\"},{\"authorId\":\"2000307852\",\"name\":\"Suresh Sundaram\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"06adf1a80e110f4c78c31f072824726aeeed1a1a\",\"title\":\"CGAP2: Context and gap aware predictive pose framework for early detection of gestures\",\"url\":\"https://www.semanticscholar.org/paper/06adf1a80e110f4c78c31f072824726aeeed1a1a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48114960\",\"name\":\"Ali Mohammad Nickfarjam\"},{\"authorId\":\"1402318194\",\"name\":\"H. Ebrahimpour-Komleh\"}],\"doi\":\"10.1007/s11042-018-7076-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cf0f92513a4c7000c7e54ff7f4edb9cab0b06629\",\"title\":\"Multi-input 1-dimensional deep belief network: action and activity recognition as case study\",\"url\":\"https://www.semanticscholar.org/paper/cf0f92513a4c7000c7e54ff7f4edb9cab0b06629\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":\"1807.07203\",\"authors\":[{\"authorId\":\"1718406\",\"name\":\"N. Inoue\"},{\"authorId\":\"1704408\",\"name\":\"Koichi Shinoda\"}],\"doi\":\"10.1145/3240508.3240592\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb285efdb73d57ab425fbbffc4327c4f1f441c85\",\"title\":\"Few-Shot Adaptation for Multimedia Semantic Indexing\",\"url\":\"https://www.semanticscholar.org/paper/eb285efdb73d57ab425fbbffc4327c4f1f441c85\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2303172\",\"name\":\"Peng Lei\"},{\"authorId\":\"143856428\",\"name\":\"S. Todorovic\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b9306e90facafc2001e6f01f209ddbb0694d61fb\",\"title\":\"AN ABSTRACT OF THE DISSERTATION OF\",\"url\":\"https://www.semanticscholar.org/paper/b9306e90facafc2001e6f01f209ddbb0694d61fb\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1920920163\",\"name\":\"Haofei Wang\"},{\"authorId\":\"49298973\",\"name\":\"Junfeng Li\"}],\"doi\":\"10.1109/ACCESS.2020.3017076\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d2602fe505d3615889456eeb6fcdc71f8f855de7\",\"title\":\"Human Action Recognition Algorithm Based on Multi-Feature Map Fusion\",\"url\":\"https://www.semanticscholar.org/paper/d2602fe505d3615889456eeb6fcdc71f8f855de7\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2004905657\",\"name\":\"Rihem Mahmoud\"},{\"authorId\":\"1757886\",\"name\":\"S. Belgacem\"},{\"authorId\":\"3169159\",\"name\":\"M. Omri\"}],\"doi\":\"10.1016/j.jksuci.2020.08.017\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"52540e1aa5e0b0b2c571f41b638659a2b59c9792\",\"title\":\"Deep Signature-based Isolated and Large Scale Continuous Gesture Recognition Approach\",\"url\":\"https://www.semanticscholar.org/paper/52540e1aa5e0b0b2c571f41b638659a2b59c9792\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40354734\",\"name\":\"Haoze Wu\"},{\"authorId\":\"48210950\",\"name\":\"Jiawei Liu\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"},{\"authorId\":\"6485172\",\"name\":\"Xiaoyan Sun\"}],\"doi\":\"10.24963/ijcai.2019/136\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"21526c9cb9ba45e4748fb9a967f51c9bd9c0bf16\",\"title\":\"Mutually Reinforced Spatio-Temporal Convolutional Tube for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/21526c9cb9ba45e4748fb9a967f51c9bd9c0bf16\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153580352\",\"name\":\"Ionut Cosmin Duta\"},{\"authorId\":\"1796198\",\"name\":\"B. Ionescu\"},{\"authorId\":\"1712839\",\"name\":\"K. Aizawa\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":\"10.1007/978-3-319-51811-4_30\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"be5276e9744c4445fe5b12b785650e8f173f56ff\",\"title\":\"Spatio-Temporal VLAD Encoding for Human Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/be5276e9744c4445fe5b12b785650e8f173f56ff\",\"venue\":\"MMM\",\"year\":2017},{\"arxivId\":\"1812.00615\",\"authors\":[{\"authorId\":\"40909443\",\"name\":\"Y. Hu\"},{\"authorId\":\"50655168\",\"name\":\"MingQi Lu\"},{\"authorId\":\"144898651\",\"name\":\"Xiaobo Lu\"}],\"doi\":\"10.1109/ICARCV.2018.8581201\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"392cb066a9710548b503a80760d986b3449c5298\",\"title\":\"Spatial-Temporal Fusion Convolutional Neural Network for Simulated Driving Behavior Recognition\",\"url\":\"https://www.semanticscholar.org/paper/392cb066a9710548b503a80760d986b3449c5298\",\"venue\":\"2018 15th International Conference on Control, Automation, Robotics and Vision (ICARCV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1415701973\",\"name\":\"Giovanni Menegozzo\"},{\"authorId\":\"1404346140\",\"name\":\"Diego Dall\\u2019Alba\"},{\"authorId\":\"48811671\",\"name\":\"Chiara Zandona\"},{\"authorId\":\"1779713\",\"name\":\"P. Fiorini\"}],\"doi\":\"10.1109/ISMR.2019.8710178\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"18f3e9b35e70e1dc2016c34da27fc4c0372919e9\",\"title\":\"Surgical gesture recognition with time delay neural network based on kinematic data\",\"url\":\"https://www.semanticscholar.org/paper/18f3e9b35e70e1dc2016c34da27fc4c0372919e9\",\"venue\":\"2019 International Symposium on Medical Robotics (ISMR)\",\"year\":2019},{\"arxivId\":\"1708.06637\",\"authors\":[{\"authorId\":\"144289593\",\"name\":\"C. A. Caetano\"},{\"authorId\":\"143793197\",\"name\":\"V. H. Melo\"},{\"authorId\":\"6141311\",\"name\":\"J. A. D. Santos\"},{\"authorId\":\"9385043\",\"name\":\"W. Schwartz\"}],\"doi\":\"10.1109/SIBGRAPI.2017.13\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c6c086748474dcda06d773891848aa1472de3560\",\"title\":\"Activity Recognition Based on a Magnitude-Orientation Stream Network\",\"url\":\"https://www.semanticscholar.org/paper/c6c086748474dcda06d773891848aa1472de3560\",\"venue\":\"2017 30th SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)\",\"year\":2017},{\"arxivId\":\"1703.10025\",\"authors\":[{\"authorId\":\"2578924\",\"name\":\"X. Zhu\"},{\"authorId\":null,\"name\":\"Yujie Wang\"},{\"authorId\":\"3304536\",\"name\":\"Jifeng Dai\"},{\"authorId\":\"145347147\",\"name\":\"Lu Yuan\"},{\"authorId\":\"1732264\",\"name\":\"Y. Wei\"}],\"doi\":\"10.1109/ICCV.2017.52\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0246f6754c38324a837c0ebd1b51976f413f80ad\",\"title\":\"Flow-Guided Feature Aggregation for Video Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/0246f6754c38324a837c0ebd1b51976f413f80ad\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"- ING\"},{\"authorId\":\"69354043\",\"name\":\"Ang\"},{\"authorId\":null,\"name\":\"- IDA\"},{\"authorId\":\"102770090\",\"name\":\"Ussain\"},{\"authorId\":null,\"name\":\"- ESONG\"},{\"authorId\":\"115925168\",\"name\":\"Ei\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fab04dfcb35a29a46504d2ad3acbc642c602c7e8\",\"title\":\"Trajectory-based 3D Convolutional Descriptors for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/fab04dfcb35a29a46504d2ad3acbc642c602c7e8\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31176543\",\"name\":\"Juan Buhagiar\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"43b4b13f1a928834b4f5eed725305a60d9ba6641\",\"title\":\"Temporal localization of actions in untrimmed videos\",\"url\":\"https://www.semanticscholar.org/paper/43b4b13f1a928834b4f5eed725305a60d9ba6641\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2002.08219\",\"authors\":[{\"authorId\":\"1489467112\",\"name\":\"Yeji Kim\"},{\"authorId\":\"122808682\",\"name\":\"Dong-Gyu Lee\"},{\"authorId\":\"50112753\",\"name\":\"Seong-Whan Lee\"}],\"doi\":\"10.1016/j.patcog.2020.107279\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a8baa039ea325efa0a5de795dc820532eb3f8e77\",\"title\":\"Three-Stream Fusion Network for First-Person Interaction Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a8baa039ea325efa0a5de795dc820532eb3f8e77\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46329495\",\"name\":\"Amin Ullah\"},{\"authorId\":\"143997136\",\"name\":\"Khan Muhammad\"},{\"authorId\":\"29438845\",\"name\":\"I. Haq\"},{\"authorId\":\"1777998\",\"name\":\"S. Baik\"}],\"doi\":\"10.1016/J.FUTURE.2019.01.029\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c40639b5a2be2ac13e2c982348b45e92584ad9c0\",\"title\":\"Action recognition using optimized deep autoencoder and CNN for surveillance data streams of non-stationary environments\",\"url\":\"https://www.semanticscholar.org/paper/c40639b5a2be2ac13e2c982348b45e92584ad9c0\",\"venue\":\"Future Gener. Comput. Syst.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9764377\",\"name\":\"Xuanhan Wang\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1109/LSP.2016.2611485\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4d972b4b6d2eae0bc810225dc3fd3b89e861dd56\",\"title\":\"Beyond Frame-level CNN: Saliency-Aware 3-D CNN With LSTM for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4d972b4b6d2eae0bc810225dc3fd3b89e861dd56\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145937063\",\"name\":\"A. Zare\"},{\"authorId\":\"2060085\",\"name\":\"H. Moghaddam\"},{\"authorId\":\"144499901\",\"name\":\"A. Sharifi\"}],\"doi\":\"10.1007/s10044-019-00788-1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8147e421fee31608fdaf9e189d5ac2ec1bf78e16\",\"title\":\"Video spatiotemporal mapping for human action recognition by convolutional neural network\",\"url\":\"https://www.semanticscholar.org/paper/8147e421fee31608fdaf9e189d5ac2ec1bf78e16\",\"venue\":\"Pattern Analysis and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39095434\",\"name\":\"Aarti Sathyanarayana\"},{\"authorId\":\"2708940\",\"name\":\"Shafiq R. Joty\"},{\"authorId\":\"1400859800\",\"name\":\"L. Fern\\u00e1ndez-Luque\"},{\"authorId\":\"1727159\",\"name\":\"Ferda Ofli\"},{\"authorId\":\"144235071\",\"name\":\"J. Srivastava\"},{\"authorId\":\"40394220\",\"name\":\"A. Elmagarmid\"},{\"authorId\":\"3076771\",\"name\":\"T. Arora\"},{\"authorId\":\"38199958\",\"name\":\"S. Taheri\"}],\"doi\":\"10.2196/MHEALTH.6562\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c82884f9d6d39c8a89ac46b8f688669fb2931144\",\"title\":\"Sleep Quality Prediction From Wearable Data Using Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/c82884f9d6d39c8a89ac46b8f688669fb2931144\",\"venue\":\"JMIR mHealth and uHealth\",\"year\":2016},{\"arxivId\":\"2101.01073\",\"authors\":[{\"authorId\":null,\"name\":\"R. Maqsood\"},{\"authorId\":null,\"name\":\"UI. Bajwa\"},{\"authorId\":null,\"name\":\"G. Saleem\"},{\"authorId\":null,\"name\":\"Rana H. Raza\"},{\"authorId\":\"2044066216\",\"name\":\"MW. Anwar\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2bbeb5fa64ff7f6e6c83910e124c74753cb98956\",\"title\":\"Anomaly Recognition from surveillance videos using 3D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/2bbeb5fa64ff7f6e6c83910e124c74753cb98956\",\"venue\":\"\",\"year\":2021},{\"arxivId\":\"1909.05165\",\"authors\":[{\"authorId\":\"41022447\",\"name\":\"Okan K\\u00f6p\\u00fckl\\u00fc\"},{\"authorId\":\"32240536\",\"name\":\"Fabian Herzog\"},{\"authorId\":\"145512909\",\"name\":\"G. Rigoll\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6dbf4b5b49ccfa082a3b3c8a3d42713784d3ef1b\",\"title\":\"Comparative Analysis of CNN-based Spatiotemporal Reasoning in Videos\",\"url\":\"https://www.semanticscholar.org/paper/6dbf4b5b49ccfa082a3b3c8a3d42713784d3ef1b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2014145\",\"name\":\"Mohammad Tavakolian\"},{\"authorId\":\"144979251\",\"name\":\"A. Hadid\"}],\"doi\":\"10.1007/s11263-019-01191-3\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"abd8cd4596accf16962c8ea324e229f765bf1200\",\"title\":\"A Spatiotemporal Convolutional Neural Network for Automatic Pain Intensity Estimation from Facial Dynamics\",\"url\":\"https://www.semanticscholar.org/paper/abd8cd4596accf16962c8ea324e229f765bf1200\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403243307\",\"name\":\"Maryam Asadi-Aghbolaghi\"},{\"authorId\":\"7840884\",\"name\":\"A. Clap\\u00e9s\"},{\"authorId\":\"9762642\",\"name\":\"Marco Bellantonio\"},{\"authorId\":\"1742688\",\"name\":\"H. Escalante\"},{\"authorId\":\"1402295723\",\"name\":\"V\\u00edctor Ponce-L\\u00f3pez\"},{\"authorId\":\"46176857\",\"name\":\"X. Bar\\u00f3\"},{\"authorId\":\"46987321\",\"name\":\"I. Guyon\"},{\"authorId\":\"145194506\",\"name\":\"S. Kasaei\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"}],\"doi\":\"10.1109/FG.2017.150\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"722a78670f48ffd29dea008f7a94624fc229cad8\",\"title\":\"A Survey on Deep Learning Based Approaches for Action and Gesture Recognition in Image Sequences\",\"url\":\"https://www.semanticscholar.org/paper/722a78670f48ffd29dea008f7a94624fc229cad8\",\"venue\":\"2017 12th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2017)\",\"year\":2017},{\"arxivId\":\"1611.05215\",\"authors\":[{\"authorId\":\"38179026\",\"name\":\"Y. Shi\"},{\"authorId\":\"40161651\",\"name\":\"Yonghong Tian\"},{\"authorId\":\"5765799\",\"name\":\"Yaowei Wang\"},{\"authorId\":\"34097174\",\"name\":\"Tiejun Huang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b3b532e8ea6304446b1623e83b0b9a96968f926c\",\"title\":\"Joint Network based Attention for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b3b532e8ea6304446b1623e83b0b9a96968f926c\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40471656\",\"name\":\"Dong Li\"},{\"authorId\":\"145690246\",\"name\":\"T. Yao\"},{\"authorId\":\"7667912\",\"name\":\"L. Duan\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/TMM.2018.2862341\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d8d0ce66eb661fbf12a04130dd7d51454f1f196\",\"title\":\"Unified Spatio-Temporal Attention Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/0d8d0ce66eb661fbf12a04130dd7d51454f1f196\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50854337\",\"name\":\"D. Xu\"},{\"authorId\":\"145974111\",\"name\":\"Jun Xiao\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"144899815\",\"name\":\"J. Shao\"},{\"authorId\":\"145982709\",\"name\":\"Di Xie\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1109/CVPR.2019.01058\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"558aeb7aa38cfcf8dd9951bfd24cf77972bd09aa\",\"title\":\"Self-Supervised Spatiotemporal Learning via Video Clip Order Prediction\",\"url\":\"https://www.semanticscholar.org/paper/558aeb7aa38cfcf8dd9951bfd24cf77972bd09aa\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Gangireddy Prabhakar Reddy\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"cdcdc33b4bf2381fa5e48a6f715f453b31bf8140\",\"title\":\"Review Of Improving Healthcare Services Through Human Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cdcdc33b4bf2381fa5e48a6f715f453b31bf8140\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"03f22e50461b897e596bd2cac5c37c6cd5a117d9\",\"title\":\"Two-Stage Human Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/03f22e50461b897e596bd2cac5c37c6cd5a117d9\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134649559\",\"name\":\"R. Kiziltepe\"},{\"authorId\":\"3000774\",\"name\":\"J. Gan\"}],\"doi\":\"10.1007/978-3-030-62362-3_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1e543b9710b3dba5d9f77b8f863067bd26422ab6\",\"title\":\"Simple Effective Methods for Decision-Level Fusion in Two-Stream Convolutional Neural Networks for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/1e543b9710b3dba5d9f77b8f863067bd26422ab6\",\"venue\":\"IDEAL\",\"year\":2020},{\"arxivId\":\"1808.04228\",\"authors\":[{\"authorId\":\"1754077\",\"name\":\"Zhan Yang\"},{\"authorId\":\"78371785\",\"name\":\"Osolo Ian Raymond\"},{\"authorId\":\"39978786\",\"name\":\"C. Zhang\"},{\"authorId\":\"48991107\",\"name\":\"Y. Wan\"},{\"authorId\":\"145883335\",\"name\":\"J. Long\"}],\"doi\":\"10.1109/ACCESS.2018.2873315\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"096a4b3fb836dd9fa8f83889bb64d2b62266ff46\",\"title\":\"DFTerNet: Towards 2-bit Dynamic Fusion Networks for Accurate Human Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/096a4b3fb836dd9fa8f83889bb64d2b62266ff46\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47818720\",\"name\":\"L. Chen\"},{\"authorId\":\"2450987\",\"name\":\"Z. Song\"},{\"authorId\":\"1697700\",\"name\":\"Jiwen Lu\"},{\"authorId\":\"49640256\",\"name\":\"J. Zhou\"}],\"doi\":\"10.1016/j.patcog.2018.08.016\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d2c6f39799392aaacf2fb342518d420e30e24785\",\"title\":\"Learning principal orientations and residual descriptor for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/d2c6f39799392aaacf2fb342518d420e30e24785\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49436226\",\"name\":\"Xi Ouyang\"},{\"authorId\":\"23999166\",\"name\":\"Shuangjie Xu\"},{\"authorId\":\"3194878\",\"name\":\"Chaoyun Zhang\"},{\"authorId\":\"33481412\",\"name\":\"Pan Zhou\"},{\"authorId\":\"144757965\",\"name\":\"Y. Yang\"},{\"authorId\":\"145376360\",\"name\":\"G. Liu\"},{\"authorId\":\"1720243\",\"name\":\"X. Li\"}],\"doi\":\"10.1109/ACCESS.2019.2906654\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"48e51c2508e3e3eb6b9c8a331364e5235e7644f3\",\"title\":\"A 3D-CNN and LSTM Based Multi-Task Learning Architecture for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/48e51c2508e3e3eb6b9c8a331364e5235e7644f3\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66471378\",\"name\":\"Allah Bux\"}],\"doi\":\"10.17635/LANCASTER/THESIS/186\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"12002e37fd9cf69a68c3c216c9ee78fcfac2fab5\",\"title\":\"Vision-based human action recognition using machine learning techniques\",\"url\":\"https://www.semanticscholar.org/paper/12002e37fd9cf69a68c3c216c9ee78fcfac2fab5\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1405.4506\",\"authors\":[{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"39527134\",\"name\":\"X. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1016/j.cviu.2016.03.013\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"facbedfe90956c720f70aab14767b5e25dcc6478\",\"title\":\"Bag of visual words and fusion methods for action recognition: Comprehensive study and good practice\",\"url\":\"https://www.semanticscholar.org/paper/facbedfe90956c720f70aab14767b5e25dcc6478\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31965574\",\"name\":\"Minah Lee\"},{\"authorId\":\"2167197\",\"name\":\"B. Mudassar\"},{\"authorId\":\"40191008\",\"name\":\"Taesik Na\"},{\"authorId\":\"144192724\",\"name\":\"S. Mukhopadhyay\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bb8321f527569684f0066843ae8231c94a96deb2\",\"title\":\"N 1 . Backbone 2 . Activity RPN 4 . Activity Classification 3 . ROI Pooling Class Scores Regression C 3 D ROI Pooling GRU Linear CNN res\",\"url\":\"https://www.semanticscholar.org/paper/bb8321f527569684f0066843ae8231c94a96deb2\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145228463\",\"name\":\"Muhammad Aamir\"},{\"authorId\":\"145760130\",\"name\":\"Ziaur Rahman\"},{\"authorId\":\"51940432\",\"name\":\"Waheed Ahmed Abro\"},{\"authorId\":\"90140313\",\"name\":\"Muhammad Mohsin Tahir\"},{\"authorId\":\"39946973\",\"name\":\"Syed M. Ahmed\"}],\"doi\":\"10.5815/ijigsp.2019.10.05\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"714acbd5fc8d898c02d057b4c0a2cf349d07b7d3\",\"title\":\"An Optimized Architecture of Image Classification Using Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/714acbd5fc8d898c02d057b4c0a2cf349d07b7d3\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4210401\",\"name\":\"Junqing Yu\"},{\"authorId\":\"51048125\",\"name\":\"Aiping Lei\"},{\"authorId\":\"15429809\",\"name\":\"Yangliu Hu\"}],\"doi\":\"10.1007/978-3-030-05716-9_31\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"168ebf77527329bc2dbd0ce82bddb9905c3aa7ee\",\"title\":\"Soccer Video Event Detection Based on Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/168ebf77527329bc2dbd0ce82bddb9905c3aa7ee\",\"venue\":\"MMM\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10779576\",\"name\":\"Sunder Ali Khowaja\"},{\"authorId\":\"1685677\",\"name\":\"Seok-Lyong Lee\"}],\"doi\":\"10.1007/s00521-019-04578-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5295accd08f555354de16f2b860f2c09e6889b65\",\"title\":\"Hybrid and hierarchical fusion networks: a deep cross-modal learning architecture for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/5295accd08f555354de16f2b860f2c09e6889b65\",\"venue\":\"Neural Computing and Applications\",\"year\":2019},{\"arxivId\":\"1909.03309\",\"authors\":[{\"authorId\":\"2502363\",\"name\":\"Gagan Kanojia\"},{\"authorId\":\"39440469\",\"name\":\"Sudhakar Kumawat\"},{\"authorId\":\"145853779\",\"name\":\"S. Raman\"}],\"doi\":\"10.1007/978-981-15-8697-2_10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5ea90b8a0ff9fe3c9f1f0bee8e1fe137e112dd4f\",\"title\":\"Exploring Temporal Differences in 3D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/5ea90b8a0ff9fe3c9f1f0bee8e1fe137e112dd4f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1803.06962\",\"authors\":[{\"authorId\":\"37041694\",\"name\":\"S. L. Pintea\"},{\"authorId\":\"40892875\",\"name\":\"Pascal Mettes\"},{\"authorId\":\"1738975\",\"name\":\"J. C. V. Gemert\"},{\"authorId\":\"144638781\",\"name\":\"A. Smeulders\"}],\"doi\":\"10.1109/ICIP.2016.7532346\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"21fc5f5734373e140bc2f06193272cade2a28199\",\"title\":\"Featureless: Bypassing feature extraction in action categorization\",\"url\":\"https://www.semanticscholar.org/paper/21fc5f5734373e140bc2f06193272cade2a28199\",\"venue\":\"2016 IEEE International Conference on Image Processing (ICIP)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24735756\",\"name\":\"Zhengkui Weng\"},{\"authorId\":\"40641593\",\"name\":\"Y. Guan\"}],\"doi\":\"10.1117/1.JEI.28.2.021004\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"42ae9506ead8b8b81729ea1ffa72a756ef71118d\",\"title\":\"Trajectory-aware three-stream CNN for video action recognition\",\"url\":\"https://www.semanticscholar.org/paper/42ae9506ead8b8b81729ea1ffa72a756ef71118d\",\"venue\":\"J. Electronic Imaging\",\"year\":2019},{\"arxivId\":\"1807.08259\",\"authors\":[{\"authorId\":\"2014145\",\"name\":\"Mohammad Tavakolian\"},{\"authorId\":\"144979251\",\"name\":\"A. Hadid\"}],\"doi\":\"10.1007/978-3-030-01225-0_24\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"6fef65bd7287b57f0c3b36bf8e6bc987fd161b7d\",\"title\":\"Deep Discriminative Model for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/6fef65bd7287b57f0c3b36bf8e6bc987fd161b7d\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1709.03655\",\"authors\":[{\"authorId\":\"1696573\",\"name\":\"Jiagang Zhu\"},{\"authorId\":\"145251501\",\"name\":\"W. Zou\"},{\"authorId\":\"144168342\",\"name\":\"Zheng Zhu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"e19ebad4739d59f999d192bac7d596b20b887f78\",\"title\":\"Learning Gating ConvNet for Two-Stream based Methods in Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e19ebad4739d59f999d192bac7d596b20b887f78\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6146190\",\"name\":\"S. Li\"},{\"authorId\":\"47058844\",\"name\":\"Lin Zhang\"},{\"authorId\":\"2256493\",\"name\":\"Xiumin Diao\"}],\"doi\":\"10.1007/S10846-019-01049-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2eafdd1aa5aab7ec1b116e28a7d1ab3c44bb3f37\",\"title\":\"Deep-Learning-Based Human Intention Prediction Using RGB Images and Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/2eafdd1aa5aab7ec1b116e28a7d1ab3c44bb3f37\",\"venue\":\"J. Intell. Robotic Syst.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153562818\",\"name\":\"Linjiang Huang\"},{\"authorId\":\"49867037\",\"name\":\"Y. Huang\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":null,\"name\":\"Liang Wang\"}],\"doi\":\"10.1016/J.PATCOG.2019.03.010\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"01c2dc6910d4552ddd86cf75dc17f3afeed9c57a\",\"title\":\"Part-aligned pose-guided recurrent network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/01c2dc6910d4552ddd86cf75dc17f3afeed9c57a\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23278631\",\"name\":\"Guangle Yao\"},{\"authorId\":\"144673774\",\"name\":\"T. Lei\"},{\"authorId\":\"23227806\",\"name\":\"Jiandan Zhong\"}],\"doi\":\"10.1016/j.patrec.2018.05.018\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2c12495bfb2f47881191ce0cb672f0372c6a31e2\",\"title\":\"A review of Convolutional-Neural-Network-based action recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c12495bfb2f47881191ce0cb672f0372c6a31e2\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2019},{\"arxivId\":\"1704.00389\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1007/978-3-030-20893-6_23\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"47195627755d88121af2513646ac41eec8645fb7\",\"title\":\"Hidden Two-Stream Convolutional Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/47195627755d88121af2513646ac41eec8645fb7\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144130711\",\"name\":\"C. Lin\"},{\"authorId\":\"2003807524\",\"name\":\"Mengxiang Lin\"},{\"authorId\":\"2003808280\",\"name\":\"Suhui Yang\"}],\"doi\":\"10.1109/ACCESS.2020.3032430\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"25db1ba302821f83040021e164e34d323354b154\",\"title\":\"SOPNet Method for the Fine-Grained Measurement and Prediction of Precipitation Intensity Using Outdoor Surveillance Cameras\",\"url\":\"https://www.semanticscholar.org/paper/25db1ba302821f83040021e164e34d323354b154\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"69458617\",\"name\":\"Albert Clap\\u00e9s i Sintes\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9a00c447f626be388bb402faeac3653d8555785e\",\"title\":\"Learning to recognize human actions: from hand-crafted to deep-learning based visual representations\",\"url\":\"https://www.semanticscholar.org/paper/9a00c447f626be388bb402faeac3653d8555785e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49995756\",\"name\":\"Jaehoon Jeong\"},{\"authorId\":\"66826603\",\"name\":\"So-Hyeon Jo\"},{\"authorId\":\"71191889\",\"name\":\"J. Woo\"},{\"authorId\":\"47381836\",\"name\":\"Dongheon Lee\"},{\"authorId\":\"32488631\",\"name\":\"T. Sung\"},{\"authorId\":\"66126641\",\"name\":\"Gi-sig Byun\"}],\"doi\":\"10.1007/s42835-020-00507-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"be96298e2612c3f39491d5edaf958f0f93d87dec\",\"title\":\"Parallel Neural Network\\u2013Convolutional Neural Networks for Wearable Motorcycle Airbag System\",\"url\":\"https://www.semanticscholar.org/paper/be96298e2612c3f39491d5edaf958f0f93d87dec\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3568955\",\"name\":\"Allison M. Rossetto\"},{\"authorId\":\"2007739628\",\"name\":\"Wenjin Zhou\"}],\"doi\":\"10.1145/3388440.3412487\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7abdece9ce09ec3293f6adf397b56b91e33dcdac\",\"title\":\"GANDALF: Peptide Generation for Drug Design using Sequential and Structural Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/7abdece9ce09ec3293f6adf397b56b91e33dcdac\",\"venue\":\"BCB\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yongjian Wang\"},{\"authorId\":\"9100217\",\"name\":\"Hongguang Li\"}],\"doi\":\"10.1016/j.compchemeng.2020.106877\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fbd811b2ad8adc6885e64cf04a086d15d57b7129\",\"title\":\"Industrial process time-series modeling based on adapted receptive field temporal convolution networks concerning multi-region operations\",\"url\":\"https://www.semanticscholar.org/paper/fbd811b2ad8adc6885e64cf04a086d15d57b7129\",\"venue\":\"Comput. Chem. Eng.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2224475\",\"name\":\"Huogen Wang\"},{\"authorId\":\"9459349\",\"name\":\"Zhanjie Song\"},{\"authorId\":\"15585183\",\"name\":\"W. Li\"},{\"authorId\":\"8120382\",\"name\":\"P. Wang\"}],\"doi\":\"10.3390/s20113305\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3b84d02d6f74a53d1196478689797eef63c306b3\",\"title\":\"A Hybrid Network for Large-Scale Action Recognition from RGB and Depth Modalities\",\"url\":\"https://www.semanticscholar.org/paper/3b84d02d6f74a53d1196478689797eef63c306b3\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145742542\",\"name\":\"W. Li\"},{\"authorId\":\"144536247\",\"name\":\"Weizhi Nie\"},{\"authorId\":\"2788104\",\"name\":\"Yuting Su\"}],\"doi\":\"10.1109/ACCESS.2018.2863943\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"cd22e6532211f679ba6057d15a801ba448b9915c\",\"title\":\"Human Action Recognition Based on Selected Spatio-Temporal Features via Bidirectional LSTM\",\"url\":\"https://www.semanticscholar.org/paper/cd22e6532211f679ba6057d15a801ba448b9915c\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1488671202\",\"name\":\"Amany Abdelbaky\"},{\"authorId\":\"1704207\",\"name\":\"Saleh Aly\"}],\"doi\":\"10.1109/ITCE48509.2020.9047769\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7834932066cbfb0e9af41637834157e3011ff250\",\"title\":\"Human Action Recognition based on Simple Deep Convolution Network PCANet\",\"url\":\"https://www.semanticscholar.org/paper/7834932066cbfb0e9af41637834157e3011ff250\",\"venue\":\"2020 International Conference on Innovative Trends in Communication and Computer Engineering (ITCE)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3271835\",\"name\":\"Sherin M. Mathews\"}],\"doi\":\"10.1007/978-3-030-22868-2_90\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"72be39943d06037a11c804c36fce652494f6404c\",\"title\":\"Explainable Artificial Intelligence Applications in NLP, Biomedical, and Malware Classification: A Literature Review\",\"url\":\"https://www.semanticscholar.org/paper/72be39943d06037a11c804c36fce652494f6404c\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1703.10667\",\"authors\":[{\"authorId\":\"7437104\",\"name\":\"Chih-Yao Ma\"},{\"authorId\":\"50133145\",\"name\":\"Min-Hung Chen\"},{\"authorId\":\"145276578\",\"name\":\"Z. Kira\"},{\"authorId\":\"9202076\",\"name\":\"G. Al-Regib\"}],\"doi\":\"10.1016/j.image.2018.09.003\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"aac934f2eed758d4a27562dae4e9c5415ff4cdb7\",\"title\":\"TS-LSTM and Temporal-Inception: Exploiting Spatiotemporal Dynamics for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/aac934f2eed758d4a27562dae4e9c5415ff4cdb7\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2019},{\"arxivId\":\"1904.11407\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"}],\"doi\":\"10.1109/ICCV.2019.00629\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"296bce85d5a844caa63ab41a96898fd8559e4bb0\",\"title\":\"DynamoNet: Dynamic Action and Motion Network\",\"url\":\"https://www.semanticscholar.org/paper/296bce85d5a844caa63ab41a96898fd8559e4bb0\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1612.08871\",\"authors\":[{\"authorId\":\"47841989\",\"name\":\"D. Nilsson\"},{\"authorId\":\"1781120\",\"name\":\"C. Sminchisescu\"}],\"doi\":\"10.1109/CVPR.2018.00713\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c0006a2268d299644e9f1b455601bcbe89ddc2b5\",\"title\":\"Semantic Video Segmentation by Gated Recurrent Flow Propagation\",\"url\":\"https://www.semanticscholar.org/paper/c0006a2268d299644e9f1b455601bcbe89ddc2b5\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2983562\",\"name\":\"Huafeng Chen\"},{\"authorId\":\"38373223\",\"name\":\"J. Chen\"},{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"37254976\",\"name\":\"RuiMin Hu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4205cb47ba4d3c0f21840633bcd49349d1dc02c1\",\"title\":\"RECOGNITIONWITH GRADIENT BOUNDARY CONVOLUTIONAL NETWORK\",\"url\":\"https://www.semanticscholar.org/paper/4205cb47ba4d3c0f21840633bcd49349d1dc02c1\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1812.10071\",\"authors\":[{\"authorId\":\"41191188\",\"name\":\"Lin Sun\"},{\"authorId\":\"2370507\",\"name\":\"Kui Jia\"},{\"authorId\":\"48234805\",\"name\":\"Yuejia Shen\"},{\"authorId\":\"1702137\",\"name\":\"Silvio Savarese\"},{\"authorId\":\"1739816\",\"name\":\"Dit-Yan Yeung\"},{\"authorId\":\"2131088\",\"name\":\"Bertram Emil Shi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"073fabecf18f1421321f1961872b9842d913e4ee\",\"title\":\"Coupled Recurrent Network (CRN)\",\"url\":\"https://www.semanticscholar.org/paper/073fabecf18f1421321f1961872b9842d913e4ee\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145706766\",\"name\":\"B. Zhang\"},{\"authorId\":\"2708397\",\"name\":\"C. Xu\"},{\"authorId\":\"27648874\",\"name\":\"Changmao Cheng\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b4d7ca26deb83cec1922a6964c1193e8dd7270e7\",\"title\":\"Learning to score and summarize figure skating sport videos\",\"url\":\"https://www.semanticscholar.org/paper/b4d7ca26deb83cec1922a6964c1193e8dd7270e7\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2352432\",\"name\":\"H. Zhang\"},{\"authorId\":\"3372558\",\"name\":\"Chenxing Xia\"},{\"authorId\":\"4831929\",\"name\":\"Xiuju Gao\"}],\"doi\":\"10.1007/S11042-018-6622-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"20cc248585941445645d8b7f258fd7df495b3887\",\"title\":\"Action recognition based on multi-stage jointly training convolutional network\",\"url\":\"https://www.semanticscholar.org/paper/20cc248585941445645d8b7f258fd7df495b3887\",\"venue\":\"Multim. Tools Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2518212\",\"name\":\"Hakan Bilen\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1bbec7190ac3ba34ca91d28f145e356a11418b67\",\"title\":\"Explorer Action Recognition with Dynamic Image Networks\",\"url\":\"https://www.semanticscholar.org/paper/1bbec7190ac3ba34ca91d28f145e356a11418b67\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1811.08383\",\"authors\":[{\"authorId\":\"46698300\",\"name\":\"Ji Lin\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"143840275\",\"name\":\"Song Han\"}],\"doi\":\"10.1109/ICCV.2019.00718\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4bbfd46721c145852e443ae4aad35148b814bf91\",\"title\":\"TSM: Temporal Shift Module for Efficient Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/4bbfd46721c145852e443ae4aad35148b814bf91\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4831929\",\"name\":\"Xiuju Gao\"},{\"authorId\":\"2352432\",\"name\":\"H. Zhang\"}],\"doi\":\"10.2991/icmit-16.2016.46\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"141a8db223541a8a7154c93b8dbe7de3eb3232dc\",\"title\":\"The Very Deep Multi-stage Two-stream Convolutional Neural Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/141a8db223541a8a7154c93b8dbe7de3eb3232dc\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1711.08362\",\"authors\":[{\"authorId\":\"8120382\",\"name\":\"P. Wang\"},{\"authorId\":\"1685696\",\"name\":\"W. Li\"},{\"authorId\":\"1719314\",\"name\":\"P. Ogunbona\"},{\"authorId\":\"145121530\",\"name\":\"Jun Wan\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"}],\"doi\":\"10.1016/j.cviu.2018.04.007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"224b34acba3597912f8adc288fa8adbb1fca92b4\",\"title\":\"RGB-D-based Human Motion Recognition with Deep Learning: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/224b34acba3597912f8adc288fa8adbb1fca92b4\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2018},{\"arxivId\":\"1704.02895\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"145160921\",\"name\":\"Bryan C. Russell\"}],\"doi\":\"10.1109/CVPR.2017.337\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"63213d080a43660ac59ea12e3c35e6953f6d7ce8\",\"title\":\"ActionVLAD: Learning Spatio-Temporal Aggregation for Action Classification\",\"url\":\"https://www.semanticscholar.org/paper/63213d080a43660ac59ea12e3c35e6953f6d7ce8\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12277476\",\"name\":\"Lifei Song\"},{\"authorId\":\"1779987\",\"name\":\"Liguo Weng\"},{\"authorId\":\"46660013\",\"name\":\"L. Wang\"},{\"authorId\":\"47715056\",\"name\":\"Min Xia\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.1109/ICIP.2018.8451662\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9c23acb6e9b76dd9b4bdacf4974b42e8c45f5260\",\"title\":\"Two-Stream Designed 2D/3D Residual Networks with Lstms for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/9c23acb6e9b76dd9b4bdacf4974b42e8c45f5260\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31802065\",\"name\":\"Zhaoxuan Fan\"},{\"authorId\":\"6873935\",\"name\":\"T. Lin\"},{\"authorId\":\"1758267\",\"name\":\"X. Zhao\"},{\"authorId\":\"47896893\",\"name\":\"W. Jiang\"},{\"authorId\":\"39866461\",\"name\":\"T. Xu\"},{\"authorId\":\"2909406\",\"name\":\"Ming Yang\"}],\"doi\":\"10.1007/978-3-319-71607-7_23\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0471a93e6bf5435fad106da97fcbbed7dbab4006\",\"title\":\"An Online Approach for Gesture Recognition Toward Real-World Applications\",\"url\":\"https://www.semanticscholar.org/paper/0471a93e6bf5435fad106da97fcbbed7dbab4006\",\"venue\":\"ICIG\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38179026\",\"name\":\"Y. Shi\"},{\"authorId\":\"40161651\",\"name\":\"Yonghong Tian\"},{\"authorId\":\"5765799\",\"name\":\"Yaowei Wang\"},{\"authorId\":\"34097174\",\"name\":\"Tiejun Huang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c829be73584966e3162f7ccae72d9284a2ebf358\",\"title\":\"shuttleNet: A biologically-inspired RNN with loop connection and parameter sharing\",\"url\":\"https://www.semanticscholar.org/paper/c829be73584966e3162f7ccae72d9284a2ebf358\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3458261\",\"name\":\"Quanle Liu\"},{\"authorId\":\"1961065\",\"name\":\"Xiangjiu Che\"},{\"authorId\":\"3079649\",\"name\":\"Mei Bie\"}],\"doi\":\"10.1109/ACCESS.2019.2923651\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c93fea9dba471ad0b42ba7b217cbe5ee1bc74a26\",\"title\":\"R-STAN: Residual Spatial-Temporal Attention Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c93fea9dba471ad0b42ba7b217cbe5ee1bc74a26\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"31493847\",\"name\":\"A. H. Karami\"},{\"authorId\":\"2713759\",\"name\":\"M. M. Arzani\"},{\"authorId\":\"9456273\",\"name\":\"Rahman Yousefzadeh\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"92679c8cff92442f39de3405c21c8028162fe56a\",\"title\":\"Temporal 3D ConvNets Using Temporal Transition Layer\",\"url\":\"https://www.semanticscholar.org/paper/92679c8cff92442f39de3405c21c8028162fe56a\",\"venue\":\"CVPR Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153626248\",\"name\":\"D. Liu\"},{\"authorId\":\"40349048\",\"name\":\"Y. Wang\"},{\"authorId\":\"1718829\",\"name\":\"J. Kato\"}],\"doi\":\"10.1109/DICTA.2017.8227428\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0b8b33481e92189044fd595ed9d177812017e0f3\",\"title\":\"Evaluation of Triple-Stream Convolutional Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/0b8b33481e92189044fd595ed9d177812017e0f3\",\"venue\":\"2017 International Conference on Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2017},{\"arxivId\":\"1512.00795\",\"authors\":[{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1109/CVPR.2016.291\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8d093efcfadda3ac7de7b0e1ca7d9aa2005c2ec3\",\"title\":\"Actions ~ Transformations\",\"url\":\"https://www.semanticscholar.org/paper/8d093efcfadda3ac7de7b0e1ca7d9aa2005c2ec3\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144422820\",\"name\":\"Xiang Xiang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c6cdf39c70aabf973a56db1ea009ab275f3f6ee8\",\"title\":\"Image-set, Temporal and Spatiotemporal Representations of Videos for Recognizing, Localizing and Quantifying Actions\",\"url\":\"https://www.semanticscholar.org/paper/c6cdf39c70aabf973a56db1ea009ab275f3f6ee8\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49913895\",\"name\":\"Romain Belmonte\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6b7fefd13817bb4b5f028b5f98d69a573d308435\",\"title\":\"Facial Landmark Detection with Local and Global Motion Modeling. (D\\u00e9tection des points caract\\u00e9ristiques du visage par mod\\u00e9lisation des mouvements locaux et globaux)\",\"url\":\"https://www.semanticscholar.org/paper/6b7fefd13817bb4b5f028b5f98d69a573d308435\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3439933\",\"name\":\"R. Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a7c0e745335c8f72ff0db1ee79836d4ca4023f3e\",\"title\":\"Machine learning methods for autonomous object recognition and restoration in images\",\"url\":\"https://www.semanticscholar.org/paper/a7c0e745335c8f72ff0db1ee79836d4ca4023f3e\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1905.10654\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"20718203ce3b9c7ed5f56f13c08c988bfdf154ca\",\"title\":\"Exploring Temporal Information for Improved Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/20718203ce3b9c7ed5f56f13c08c988bfdf154ca\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2720195\",\"name\":\"Y. Li\"},{\"authorId\":\"104269236\",\"name\":\"Q. Li\"},{\"authorId\":\"145298361\",\"name\":\"Q. Huang\"},{\"authorId\":\"31280147\",\"name\":\"Rongjie Xia\"},{\"authorId\":\"40286455\",\"name\":\"Xuelong Li\"}],\"doi\":\"10.1117/1.JEI.28.3.033002\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1cd2f99475097dfc1e4c37e67c1771a9df72b47f\",\"title\":\"Spatiotemporal interest point detector exploiting appearance and motion-variation information\",\"url\":\"https://www.semanticscholar.org/paper/1cd2f99475097dfc1e4c37e67c1771a9df72b47f\",\"venue\":\"J. Electronic Imaging\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1419461174\",\"name\":\"Younes Ed-doughmi\"},{\"authorId\":\"2833164\",\"name\":\"N. Idrissi\"},{\"authorId\":\"2625598\",\"name\":\"Youssef Hbali\"}],\"doi\":\"10.3390/jimaging6030008\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"11efcb0b1ec16650c59183664b89eff4332e9bb8\",\"title\":\"Real-Time System for Driver Fatigue Detection Based on a Recurrent Neuronal Network\",\"url\":\"https://www.semanticscholar.org/paper/11efcb0b1ec16650c59183664b89eff4332e9bb8\",\"venue\":\"J. Imaging\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48805860\",\"name\":\"Zhimeng Zhang\"},{\"authorId\":\"145453305\",\"name\":\"Xin Ma\"},{\"authorId\":\"145401371\",\"name\":\"R. Song\"},{\"authorId\":\"2924438\",\"name\":\"Xuewen Rong\"},{\"authorId\":\"32004054\",\"name\":\"X. Tian\"},{\"authorId\":\"49209779\",\"name\":\"G. Tian\"},{\"authorId\":\"29275442\",\"name\":\"Yibin Li\"}],\"doi\":\"10.1109/CAC.2017.8243438\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2063222c5ce0dd233fa3056ddc245fca26bd5cf2\",\"title\":\"Deep learning based human action recognition: A survey\",\"url\":\"https://www.semanticscholar.org/paper/2063222c5ce0dd233fa3056ddc245fca26bd5cf2\",\"venue\":\"2017 Chinese Automation Congress (CAC)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23124669\",\"name\":\"Jiewan Zheng\"},{\"authorId\":\"40916581\",\"name\":\"Xianbin Cao\"},{\"authorId\":\"1740430\",\"name\":\"B. Zhang\"},{\"authorId\":\"34798935\",\"name\":\"Xiantong Zhen\"},{\"authorId\":\"7883602\",\"name\":\"Xiangbo Su\"}],\"doi\":\"10.1109/TNNLS.2018.2844464\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dc95fb644c12ee9caa989390af29c969b4c1d646\",\"title\":\"Deep Ensemble Machine for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/dc95fb644c12ee9caa989390af29c969b4c1d646\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29901316\",\"name\":\"Prateep Bhattacharjee\"},{\"authorId\":\"144009889\",\"name\":\"Sukhendu Das\"}],\"doi\":\"10.1007/978-3-319-69900-4_70\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"bf2eb77e9b795a4a0a38ed4b1c8dd4b2c9a74317\",\"title\":\"Two-Stream Convolutional Network with Multi-level Feature Fusion for Categorization of Human Action from Videos\",\"url\":\"https://www.semanticscholar.org/paper/bf2eb77e9b795a4a0a38ed4b1c8dd4b2c9a74317\",\"venue\":\"PReMI\",\"year\":2017},{\"arxivId\":\"1903.09761\",\"authors\":[{\"authorId\":\"145062693\",\"name\":\"Anh Nguyen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"af4df89ad28580d98113fa6a816195137f7d1a1d\",\"title\":\"Scene Understanding for Autonomous Manipulation with Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/af4df89ad28580d98113fa6a816195137f7d1a1d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145632270\",\"name\":\"O. P. Mishra\"},{\"authorId\":\"145598806\",\"name\":\"Rajiv Kapoor\"}],\"doi\":\"10.5815/ijigsp.2019.09.04\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"074a131c50bbb7f9b612861d1e4cd7679fe83385\",\"title\":\"Human Action Recognition Using Modified Bag of Visual Word based on Spectral Perception\",\"url\":\"https://www.semanticscholar.org/paper/074a131c50bbb7f9b612861d1e4cd7679fe83385\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1607.04867\",\"authors\":[{\"authorId\":\"39095434\",\"name\":\"Aarti Sathyanarayana\"},{\"authorId\":\"1727159\",\"name\":\"Ferda Ofli\"},{\"authorId\":\"81780580\",\"name\":\"L. Fern\\u00e1ndez-Luque\"},{\"authorId\":\"144235071\",\"name\":\"J. Srivastava\"},{\"authorId\":\"145188857\",\"name\":\"A. Elmagarmid\"},{\"authorId\":\"3076771\",\"name\":\"T. Arora\"},{\"authorId\":\"38199958\",\"name\":\"S. Taheri\"}],\"doi\":\"10.1109/ICDMW.2016.0077\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d964aa6f07800ff64fb7d0f6dd99ef2b335dfc69\",\"title\":\"Robust Automated Human Activity Recognition and Its Application to Sleep Research\",\"url\":\"https://www.semanticscholar.org/paper/d964aa6f07800ff64fb7d0f6dd99ef2b335dfc69\",\"venue\":\"2016 IEEE 16th International Conference on Data Mining Workshops (ICDMW)\",\"year\":2016},{\"arxivId\":\"1803.07179\",\"authors\":[{\"authorId\":\"14800230\",\"name\":\"J. Zang\"},{\"authorId\":\"46659696\",\"name\":\"L. Wang\"},{\"authorId\":\"9071789\",\"name\":\"Z. Liu\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"1786361\",\"name\":\"Zhenxing Niu\"},{\"authorId\":\"144988570\",\"name\":\"Gang Hua\"},{\"authorId\":\"1715389\",\"name\":\"Nanning Zheng\"}],\"doi\":\"10.1007/978-3-319-92007-8_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dd613000f7b2b6161548b1c1044ab46c7327a901\",\"title\":\"Attention-based Temporal Weighted Convolutional Neural Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/dd613000f7b2b6161548b1c1044ab46c7327a901\",\"venue\":\"AIAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405073588\",\"name\":\"Itsaso Rodr\\u00edguez-Moreno\"},{\"authorId\":\"1401677216\",\"name\":\"J. M. Mart\\u00ednez-Otzeta\"},{\"authorId\":\"144286136\",\"name\":\"B. Sierra\"},{\"authorId\":\"24857630\",\"name\":\"I. Rodriguez\"},{\"authorId\":\"95170363\",\"name\":\"E. Jauregi\"}],\"doi\":\"10.3390/s19143160\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"44f1ae791e8e858a9c7060e42d5db76b170b51e0\",\"title\":\"Video Activity Recognition: State-of-the-Art\",\"url\":\"https://www.semanticscholar.org/paper/44f1ae791e8e858a9c7060e42d5db76b170b51e0\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8120382\",\"name\":\"P. Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d320f2f86571f117dc3929c4952fd1fc6e3beeeb\",\"title\":\"Action recognition from RGB-D data\",\"url\":\"https://www.semanticscholar.org/paper/d320f2f86571f117dc3929c4952fd1fc6e3beeeb\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1604.08826\",\"authors\":[{\"authorId\":\"8197937\",\"name\":\"K. Ohnishi\"},{\"authorId\":\"2859204\",\"name\":\"Masatoshi Hidaka\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.1145/2964284.2967222\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"da48af74960c84750de3cfc1c9c9a5b5252d330c\",\"title\":\"Improved Dense Trajectory with Cross Streams\",\"url\":\"https://www.semanticscholar.org/paper/da48af74960c84750de3cfc1c9c9a5b5252d330c\",\"venue\":\"ACM Multimedia\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145489794\",\"name\":\"K. Huang\"},{\"authorId\":\"145458349\",\"name\":\"Z. Qin\"},{\"authorId\":\"2168639\",\"name\":\"Kaiping Xu\"},{\"authorId\":\"19204816\",\"name\":\"Shuxiong Ye\"},{\"authorId\":\"1886528\",\"name\":\"Guolong Wang\"}],\"doi\":\"10.1007/978-3-319-77383-4_14\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c48f20b4fba0b629cab97e330c8c4a3423dc5d00\",\"title\":\"Multi-modality Fusion Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c48f20b4fba0b629cab97e330c8c4a3423dc5d00\",\"venue\":\"PCM\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50081925\",\"name\":\"L. Zhang\"},{\"authorId\":\"2032648\",\"name\":\"J. Varadarajan\"},{\"authorId\":\"47332572\",\"name\":\"Yong Pei\"}],\"doi\":\"10.1007/978-3-030-56150-5_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a8b682a04b2e14dedc4de6e889ba641078bd9d64\",\"title\":\"Action Recognition Using Co-trained Deep Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/a8b682a04b2e14dedc4de6e889ba641078bd9d64\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9127897\",\"name\":\"A. Sasithradevi\"},{\"authorId\":\"2010132\",\"name\":\"S. Roomi\"}],\"doi\":\"10.1016/j.patcog.2019.107099\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"96e1bde6095d0db64ff46c689fda3d27ce0c02c8\",\"title\":\"Video classification and retrieval through spatio-temporal Radon features\",\"url\":\"https://www.semanticscholar.org/paper/96e1bde6095d0db64ff46c689fda3d27ce0c02c8\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40566477\",\"name\":\"H. Yang\"},{\"authorId\":null,\"name\":\"Chunfeng Yuan\"},{\"authorId\":\"1757173\",\"name\":\"Junliang Xing\"},{\"authorId\":\"40506509\",\"name\":\"W. Hu\"}],\"doi\":\"10.1109/ICIP.2017.8296802\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cc6d3ccc9e3dd0a43313a714316c8783cd879572\",\"title\":\"Diversity encouraging ensemble of convolutional networks for high performance action recognition\",\"url\":\"https://www.semanticscholar.org/paper/cc6d3ccc9e3dd0a43313a714316c8783cd879572\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":\"2012.11009\",\"authors\":[{\"authorId\":\"134329588\",\"name\":\"L. H. Rodr\\u00edguez\"},{\"authorId\":\"10016958\",\"name\":\"Alexei A Kananenka\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b19d710196bddbe9cf2af75dfa0fdb884f1f4d3a\",\"title\":\"Convolutional neural networks for long-time dissipative quantum dynamics\",\"url\":\"https://www.semanticscholar.org/paper/b19d710196bddbe9cf2af75dfa0fdb884f1f4d3a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24944572\",\"name\":\"Shahela Saif\"},{\"authorId\":\"51935429\",\"name\":\"Samabia Tehseen\"},{\"authorId\":\"1880755\",\"name\":\"Sumaira Kausar\"}],\"doi\":\"10.3390/s18113979\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fe4aa088362d371daf15ccf9290291c8867e4f23\",\"title\":\"A Survey of the Techniques for The Identification and Classification of Human Actions from Visual Data\",\"url\":\"https://www.semanticscholar.org/paper/fe4aa088362d371daf15ccf9290291c8867e4f23\",\"venue\":\"Sensors\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"93318099\",\"name\":\"J. Lin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1dc7454bacae9a949db38b8306bd7c4df855fa1c\",\"title\":\"TSM: Temporal Shift Module for Efficient Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/1dc7454bacae9a949db38b8306bd7c4df855fa1c\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144985898\",\"name\":\"B. Su\"},{\"authorId\":\"2415109\",\"name\":\"Jiahuan Zhou\"},{\"authorId\":\"145507765\",\"name\":\"X. Ding\"},{\"authorId\":\"47095827\",\"name\":\"Y. Wu\"}],\"doi\":\"10.1109/TIP.2017.2745212\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ab0981d1da654f37620ca39c6b42de21d7eb58eb\",\"title\":\"Unsupervised Hierarchical Dynamic Parsing and Encoding for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ab0981d1da654f37620ca39c6b42de21d7eb58eb\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":\"1906.03349\",\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"}],\"doi\":\"10.1109/cvpr42600.2020.00043\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"45a924794b2c6501b671cf4249c6ac4fa1671597\",\"title\":\"Video Modeling With Correlation Networks\",\"url\":\"https://www.semanticscholar.org/paper/45a924794b2c6501b671cf4249c6ac4fa1671597\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3471544\",\"name\":\"Feixiang He\"},{\"authorId\":\"2254178\",\"name\":\"Fayao Liu\"},{\"authorId\":\"145786594\",\"name\":\"Rui Yao\"},{\"authorId\":\"2604251\",\"name\":\"Guosheng Lin\"}],\"doi\":\"10.1016/J.IMAVIS.2018.12.002\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"17eaac80a260bc5d665e1035d7291293b056d3b6\",\"title\":\"Local fusion networks with chained residual pooling for video action recognition\",\"url\":\"https://www.semanticscholar.org/paper/17eaac80a260bc5d665e1035d7291293b056d3b6\",\"venue\":\"Image Vis. Comput.\",\"year\":2019},{\"arxivId\":\"1612.00738\",\"authors\":[{\"authorId\":\"2518212\",\"name\":\"Hakan Bilen\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":\"10.1109/TPAMI.2017.2769085\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2fe8c43aa9427582906c684afadebbc6a86fa036\",\"title\":\"Action Recognition with Dynamic Image Networks\",\"url\":\"https://www.semanticscholar.org/paper/2fe8c43aa9427582906c684afadebbc6a86fa036\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":\"1705.02953\",\"authors\":[{\"authorId\":\"119770705\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"134339866\",\"name\":\"L. V. Van Gool\"}],\"doi\":\"10.1109/TPAMI.2018.2868668\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"37c970a2f27810987e2b47dd5b8e0cc9bb976a38\",\"title\":\"Temporal Segment Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/37c970a2f27810987e2b47dd5b8e0cc9bb976a38\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50814507\",\"name\":\"Cagdas Bak\"},{\"authorId\":\"3044594\",\"name\":\"Aysun Kocak\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"}],\"doi\":\"10.1109/TMM.2017.2777665\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1ebd1083ad9e10ed2feded8319c5d472bf9f420b\",\"title\":\"Spatio-Temporal Saliency Networks for Dynamic Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/1ebd1083ad9e10ed2feded8319c5d472bf9f420b\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":\"1608.07138\",\"authors\":[{\"authorId\":\"37868227\",\"name\":\"C. D. Souza\"},{\"authorId\":\"1799820\",\"name\":\"Adrien Gaidon\"},{\"authorId\":\"2286630\",\"name\":\"E. Vig\"},{\"authorId\":\"3940956\",\"name\":\"A. Pe\\u00f1a\"}],\"doi\":\"10.1007/978-3-319-46478-7_43\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4191d91b6f8c6e48ba6aed3451384b6122ab4a15\",\"title\":\"Sympathy for the Details: Dense Trajectories and Hybrid Classification Architectures for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4191d91b6f8c6e48ba6aed3451384b6122ab4a15\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1768624101\",\"name\":\"Akram Mihanpour\"},{\"authorId\":\"2406798\",\"name\":\"Mohammad J. Rashti\"},{\"authorId\":\"52217578\",\"name\":\"S. Alavi\"}],\"doi\":\"10.1109/ICWR49608.2020.9122304\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"e9bea2a45da16ad5ed9f0b711afc512b78d0892b\",\"title\":\"Human Action Recognition in Video Using DB-LSTM and ResNet\",\"url\":\"https://www.semanticscholar.org/paper/e9bea2a45da16ad5ed9f0b711afc512b78d0892b\",\"venue\":\"2020 6th International Conference on Web Research (ICWR)\",\"year\":2020},{\"arxivId\":\"1611.06678\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2017.168\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"645de797f936cb19c1b8dba3b862543645510544\",\"title\":\"Deep Temporal Linear Encoding Networks\",\"url\":\"https://www.semanticscholar.org/paper/645de797f936cb19c1b8dba3b862543645510544\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2027172024\",\"name\":\"Kavin Ruengprateepsang\"},{\"authorId\":\"2351793\",\"name\":\"S. Wangsiripitak\"},{\"authorId\":\"2056653\",\"name\":\"Kitsuchart Pasupa\"}],\"doi\":\"10.1007/978-3-030-63830-6_31\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"96b28c526b8d6b063d9be5f6916f90ba882c6db1\",\"title\":\"Hybrid Training of Speaker and Sentence Models for One-Shot Lip Password\",\"url\":\"https://www.semanticscholar.org/paper/96b28c526b8d6b063d9be5f6916f90ba882c6db1\",\"venue\":\"ICONIP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40078088\",\"name\":\"X. Tang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"99a6492fbea30d57ed7e7edf316a96f93008a17a\",\"title\":\"Video Sequence Classification Using Spatio-temporal Features\",\"url\":\"https://www.semanticscholar.org/paper/99a6492fbea30d57ed7e7edf316a96f93008a17a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32062468\",\"name\":\"H. Ou\"},{\"authorId\":\"2994709\",\"name\":\"J. Sun\"}],\"doi\":\"10.1117/1.JEI.28.2.023009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fbb35c26df06eb8e0afe82d1213b8561af4af7a5\",\"title\":\"Spatiotemporal information deep fusion network with frame attention mechanism for video action recognition\",\"url\":\"https://www.semanticscholar.org/paper/fbb35c26df06eb8e0afe82d1213b8561af4af7a5\",\"venue\":\"J. Electronic Imaging\",\"year\":2019},{\"arxivId\":\"2007.11365\",\"authors\":[{\"authorId\":\"39440469\",\"name\":\"Sudhakar Kumawat\"},{\"authorId\":\"145879750\",\"name\":\"Manisha Verma\"},{\"authorId\":\"1789677\",\"name\":\"Yuta Nakashima\"},{\"authorId\":\"145853779\",\"name\":\"S. Raman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4914a205aa1ddeaae3c86a449c69703c89484f54\",\"title\":\"Depthwise Spatio-Temporal STFT Convolutional Neural Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4914a205aa1ddeaae3c86a449c69703c89484f54\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2199479\",\"name\":\"Jongmin Yu\"},{\"authorId\":\"145423641\",\"name\":\"D. Y. Kim\"},{\"authorId\":\"8770612\",\"name\":\"Yongsang Yoon\"},{\"authorId\":\"145745152\",\"name\":\"M. Jeon\"}],\"doi\":\"10.1007/s00371-019-01751-1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb7a000f5c196dbb09f939674140ebcd1f20899e\",\"title\":\"Action matching network: open-set action recognition using spatio-temporal representation matching\",\"url\":\"https://www.semanticscholar.org/paper/eb7a000f5c196dbb09f939674140ebcd1f20899e\",\"venue\":\"The Visual Computer\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46324489\",\"name\":\"Qing Zhang\"},{\"authorId\":\"2849542\",\"name\":\"H. Yan\"},{\"authorId\":\"46660013\",\"name\":\"L. Wang\"}],\"doi\":\"10.1007/978-3-030-31654-9_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e78f395fe206fe3db5efb64bb891bee23b0fa2cf\",\"title\":\"Multi-scale Spatial-Temporal Attention for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e78f395fe206fe3db5efb64bb891bee23b0fa2cf\",\"venue\":\"PRCV\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92148538\",\"name\":\"Di Wu\"},{\"authorId\":\"2257498\",\"name\":\"N. Sharma\"},{\"authorId\":\"1801266\",\"name\":\"M. Blumenstein\"}],\"doi\":\"10.1109/IJCNN.2017.7966210\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"c3a7262f681fe5c0c4afba73a37b52a7d8b2d8db\",\"title\":\"Recent advances in video-based human action recognition using deep learning: A review\",\"url\":\"https://www.semanticscholar.org/paper/c3a7262f681fe5c0c4afba73a37b52a7d8b2d8db\",\"venue\":\"2017 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1739144906\",\"name\":\"S. Karthickkumar\"},{\"authorId\":\"122751926\",\"name\":\"K. Kumar\"}],\"doi\":\"10.1109/ICCCI48352.2020.9104135\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6df041417b801150b57ffbe56e6864d9cbf319be\",\"title\":\"A survey on Deep learning techniques for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/6df041417b801150b57ffbe56e6864d9cbf319be\",\"venue\":\"2020 International Conference on Computer Communication and Informatics (ICCCI)\",\"year\":2020},{\"arxivId\":\"1711.08200\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"31493847\",\"name\":\"A. H. Karami\"},{\"authorId\":\"2713759\",\"name\":\"M. M. Arzani\"},{\"authorId\":\"9456273\",\"name\":\"Rahman Yousefzadeh\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f5ce640bbb9d6417fd0853ed88a9e7b93d72910d\",\"title\":\"Temporal 3D ConvNets: New Architecture and Transfer Learning for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/f5ce640bbb9d6417fd0853ed88a9e7b93d72910d\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1912.04430\",\"authors\":[{\"authorId\":\"3121735\",\"name\":\"Paritosh Parmar\"},{\"authorId\":\"49059658\",\"name\":\"B. Morris.\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7aef63bbe103760e78f359223e35562cdaed16c1\",\"title\":\"HalluciNet-ing Spatiotemporal Representations Using 2D-CNN\",\"url\":\"https://www.semanticscholar.org/paper/7aef63bbe103760e78f359223e35562cdaed16c1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"70147929\",\"name\":\"H. Yang\"},{\"authorId\":\"18997752\",\"name\":\"Jun Zhang\"},{\"authorId\":\"2721485\",\"name\":\"Shuohao Li\"},{\"authorId\":\"3249639\",\"name\":\"Tingjin Luo\"}],\"doi\":\"10.3233/JIFS-18209\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c6d8c084b395804b68ffbec2724a91b1cf8e269b\",\"title\":\"Bi-direction hierarchical LSTM with spatial-temporal attention for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/c6d8c084b395804b68ffbec2724a91b1cf8e269b\",\"venue\":\"J. Intell. Fuzzy Syst.\",\"year\":2019},{\"arxivId\":\"1602.00224\",\"authors\":[{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1016/j.patcog.2019.03.002\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2cdde47c27a8ecd391cbb6b2dea64b73282c7491\",\"title\":\"Order-aware Convolutional Pooling for Video Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2cdde47c27a8ecd391cbb6b2dea64b73282c7491\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":\"1705.10420\",\"authors\":[{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1007/s11263-017-1030-x\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5615d6045301ecbc5be35e46cab711f676aadf3a\",\"title\":\"Discriminatively Learned Hierarchical Rank Pooling Networks\",\"url\":\"https://www.semanticscholar.org/paper/5615d6045301ecbc5be35e46cab711f676aadf3a\",\"venue\":\"International Journal of Computer Vision\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1686715\",\"name\":\"S. Yu\"},{\"authorId\":\"49388033\",\"name\":\"Y. Cheng\"},{\"authorId\":\"145046855\",\"name\":\"L. Xie\"},{\"authorId\":\"40455111\",\"name\":\"Zhiming Luo\"},{\"authorId\":\"145075206\",\"name\":\"M. Huang\"},{\"authorId\":\"8086812\",\"name\":\"Shaozi Li\"}],\"doi\":\"10.1016/j.jvcir.2017.09.007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b844e211ef0c4bfd9d6b810bdedb7b91d0db14f4\",\"title\":\"A novel recurrent hybrid network for feature fusion in action recognition\",\"url\":\"https://www.semanticscholar.org/paper/b844e211ef0c4bfd9d6b810bdedb7b91d0db14f4\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144350339\",\"name\":\"Chirag I. Patel\"},{\"authorId\":\"2042647646\",\"name\":\"Dileep Labana\"},{\"authorId\":\"47706103\",\"name\":\"S. Pandya\"},{\"authorId\":\"3438822\",\"name\":\"Kirit Modi\"},{\"authorId\":\"3424424\",\"name\":\"H. Ghayvat\"},{\"authorId\":\"1622021877\",\"name\":\"Muhammad Awais\"}],\"doi\":\"10.3390/s20247299\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3fa0ad0a0e3779516e5a9cb74fc40b872448b232\",\"title\":\"Histogram of Oriented Gradient-Based Fusion of Features for Human Action Recognition in Action Video Sequences\",\"url\":\"https://www.semanticscholar.org/paper/3fa0ad0a0e3779516e5a9cb74fc40b872448b232\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"1912.08860\",\"authors\":[{\"authorId\":\"26432578\",\"name\":\"Emmanuel Kahembwe\"},{\"authorId\":\"47172195\",\"name\":\"S. Ramamoorthy\"}],\"doi\":\"10.1016/j.neunet.2020.09.016\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1f313226533edea306c4de79df945cc5a90d153c\",\"title\":\"Lower Dimensional Kernels for Video Discriminators\",\"url\":\"https://www.semanticscholar.org/paper/1f313226533edea306c4de79df945cc5a90d153c\",\"venue\":\"Neural Networks\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98658818\",\"name\":\"C. Lea\"},{\"authorId\":\"3207112\",\"name\":\"A. Reiter\"},{\"authorId\":\"144020730\",\"name\":\"R. Vidal\"},{\"authorId\":\"1678633\",\"name\":\"G. Hager\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b336563d2b639cf1a30a8f34346f71cc6fc8392f\",\"title\":\"Efficient Segmental Inference for Spatiotemporal Modeling of Fine-grained Actions\",\"url\":\"https://www.semanticscholar.org/paper/b336563d2b639cf1a30a8f34346f71cc6fc8392f\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1908.02486\",\"authors\":[{\"authorId\":\"51128181\",\"name\":\"Boyuan Jiang\"},{\"authorId\":\"47446949\",\"name\":\"M. Wang\"},{\"authorId\":\"35893447\",\"name\":\"W. Gan\"},{\"authorId\":\"145717890\",\"name\":\"W. Wu\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\"}],\"doi\":\"10.1109/ICCV.2019.00209\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b812b20192ffac37b03bde0261934a2a8c7fdf47\",\"title\":\"STM: SpatioTemporal and Motion Encoding for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b812b20192ffac37b03bde0261934a2a8c7fdf47\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1706.04122\",\"authors\":[{\"authorId\":\"2838646\",\"name\":\"I. Abbasnejad\"},{\"authorId\":\"1729760\",\"name\":\"S. Sridharan\"},{\"authorId\":\"1980700\",\"name\":\"Simon Denman\"},{\"authorId\":\"3140440\",\"name\":\"C. Fookes\"},{\"authorId\":\"1820249\",\"name\":\"S. Lucey\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e76798bddd0f12ae03de26b7c7743c008d505215\",\"title\":\"Joint Max Margin and Semantic Features for Continuous Event Detection in Complex Scenes\",\"url\":\"https://www.semanticscholar.org/paper/e76798bddd0f12ae03de26b7c7743c008d505215\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46329495\",\"name\":\"Amin Ullah\"},{\"authorId\":\"143636222\",\"name\":\"J. Ahmad\"},{\"authorId\":\"143997136\",\"name\":\"Khan Muhammad\"},{\"authorId\":\"143993371\",\"name\":\"M. Sajjad\"},{\"authorId\":\"1777998\",\"name\":\"S. Baik\"}],\"doi\":\"10.1109/ACCESS.2017.2778011\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b5979489e11edd76607c219a8bdc83ba4a88ab38\",\"title\":\"Action Recognition in Video Sequences using Deep Bi-Directional LSTM With CNN Features\",\"url\":\"https://www.semanticscholar.org/paper/b5979489e11edd76607c219a8bdc83ba4a88ab38\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3381029\",\"name\":\"J. Wang\"},{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1016/j.cviu.2019.102898\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"62af68e20481f9f98509bfed69ef1300a8e9485e\",\"title\":\"Cascade multi-head attention networks for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/62af68e20481f9f98509bfed69ef1300a8e9485e\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2020},{\"arxivId\":\"1811.09974\",\"authors\":[{\"authorId\":\"3128506\",\"name\":\"Yanghao Li\"},{\"authorId\":\"3384254\",\"name\":\"Sijie Song\"},{\"authorId\":\"50023941\",\"name\":\"Y. Li\"},{\"authorId\":\"41127426\",\"name\":\"Jiaying Liu\"}],\"doi\":\"10.1609/aaai.v33i01.33018674\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6ae72dc774f62b190036fb094be4558d827e53d2\",\"title\":\"Temporal Bilinear Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6ae72dc774f62b190036fb094be4558d827e53d2\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"13741850\",\"name\":\"Yijing Lv\"},{\"authorId\":\"39458374\",\"name\":\"H. Zheng\"},{\"authorId\":null,\"name\":\"Wei Zhang\"}],\"doi\":\"10.1007/978-3-030-03335-4_21\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b33742f8b5852c8d89bb9a0236bb88412c8a807f\",\"title\":\"Multi-level Three-Stream Convolutional Networks for Video-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b33742f8b5852c8d89bb9a0236bb88412c8a807f\",\"venue\":\"PRCV\",\"year\":2018},{\"arxivId\":\"1609.03056\",\"authors\":[{\"authorId\":\"38179026\",\"name\":\"Y. Shi\"},{\"authorId\":\"40161651\",\"name\":\"Yonghong Tian\"},{\"authorId\":\"5765799\",\"name\":\"Yaowei Wang\"},{\"authorId\":\"34097174\",\"name\":\"Tiejun Huang\"}],\"doi\":\"10.1109/TMM.2017.2666540\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"776ce1429272028e9c566369cf647177d3522e26\",\"title\":\"Sequential Deep Trajectory Descriptor for Action Recognition With Three-Stream CNN\",\"url\":\"https://www.semanticscholar.org/paper/776ce1429272028e9c566369cf647177d3522e26\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40566477\",\"name\":\"H. Yang\"},{\"authorId\":null,\"name\":\"Chunfeng Yuan\"},{\"authorId\":\"49730034\",\"name\":\"B. Li\"},{\"authorId\":\"144708945\",\"name\":\"Yang Du\"},{\"authorId\":\"1757173\",\"name\":\"Junliang Xing\"},{\"authorId\":\"40506509\",\"name\":\"W. Hu\"},{\"authorId\":\"144555237\",\"name\":\"S. Maybank\"}],\"doi\":\"10.1016/j.patcog.2018.07.028\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"756532d707209f13c44b96e6306ac0c96e6733a5\",\"title\":\"Asymmetric 3D Convolutional Neural Networks for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/756532d707209f13c44b96e6306ac0c96e6733a5\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1796221456\",\"name\":\"Bin Liu\"},{\"authorId\":\"144347268\",\"name\":\"M. Wu\"},{\"authorId\":\"1796272603\",\"name\":\"Minze Tao\"},{\"authorId\":\"30148287\",\"name\":\"Qin Wang\"},{\"authorId\":\"1796267563\",\"name\":\"Luye He\"},{\"authorId\":\"47544023\",\"name\":\"G. Shen\"},{\"authorId\":\"31262025\",\"name\":\"Ke-Han Chen\"},{\"authorId\":\"3063894\",\"name\":\"Junchi Yan\"}],\"doi\":\"10.1109/ACCESS.2020.3005825\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"27e43e35ce810d8aca341034e544bd398ca6491c\",\"title\":\"Video Content Analysis for Compliance Audit in Finance and Security Industry\",\"url\":\"https://www.semanticscholar.org/paper/27e43e35ce810d8aca341034e544bd398ca6491c\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2006.10950\",\"authors\":[{\"authorId\":\"1737817225\",\"name\":\"Zhen Yu\"},{\"authorId\":\"50004409\",\"name\":\"J. Nguyen\"},{\"authorId\":\"144950946\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"47623309\",\"name\":\"J. Kelly\"},{\"authorId\":\"143682056\",\"name\":\"C. Mclean\"},{\"authorId\":\"153824047\",\"name\":\"L. Zhang\"},{\"authorId\":\"153804224\",\"name\":\"V. Mar\"},{\"authorId\":\"144062687\",\"name\":\"Zongyuan Ge\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2bca8cf9045acc94349bafe7d33a7a8aed4e8191\",\"title\":\"Melanoma Diagnosis with Spatio-Temporal Feature Learning on Sequential Dermoscopic Images\",\"url\":\"https://www.semanticscholar.org/paper/2bca8cf9045acc94349bafe7d33a7a8aed4e8191\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47319654\",\"name\":\"S. Li\"},{\"authorId\":\"1741668\",\"name\":\"Zhicheng Zhao\"},{\"authorId\":\"152343380\",\"name\":\"Fei Su\"}],\"doi\":\"10.1109/VCIP47243.2019.8965878\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eced654a4b8467a6b52194af8e4d83bcbe1730cb\",\"title\":\"A Spatio-temporal Hybrid Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eced654a4b8467a6b52194af8e4d83bcbe1730cb\",\"venue\":\"2019 IEEE Visual Communications and Image Processing (VCIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121405052\",\"name\":\"S. V. Kiran\"},{\"authorId\":\"116372419\",\"name\":\"Raj Singh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"09275e4157969c0606efc4c085fd3db43c2186a5\",\"title\":\"Contextual Action Recognition using Tube Convolutional Neural Network (T-CNN)\",\"url\":\"https://www.semanticscholar.org/paper/09275e4157969c0606efc4c085fd3db43c2186a5\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"20992076\",\"name\":\"Timothy Callemein\"},{\"authorId\":\"34855451\",\"name\":\"T. Roussel\"},{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"74922038\",\"name\":\"Floris De Feyter\"},{\"authorId\":\"73664580\",\"name\":\"Wim Boes\"},{\"authorId\":\"1768441\",\"name\":\"L. V. Eycken\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"1727198\",\"name\":\"H. V. hamme\"},{\"authorId\":\"2003472752\",\"name\":\"Tinne Tuytelaars\"},{\"authorId\":\"1752649\",\"name\":\"T. Goedem\\u00e9\"}],\"doi\":\"10.1007/s11042-020-09616-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"32921da55d7127169e901c4b3e5d6e2333185561\",\"title\":\"Show me where the action is!: Automatic capturing and timeline generation for reality TV.\",\"url\":\"https://www.semanticscholar.org/paper/32921da55d7127169e901c4b3e5d6e2333185561\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35900036\",\"name\":\"T. Wang\"},{\"authorId\":\"49298611\",\"name\":\"J. Li\"},{\"authorId\":\"3075750\",\"name\":\"M. Zhang\"},{\"authorId\":\"2643261\",\"name\":\"A. Zhu\"},{\"authorId\":\"2103629\",\"name\":\"H. Snoussi\"},{\"authorId\":\"145685545\",\"name\":\"Chang Choi\"}],\"doi\":\"10.1002/cpe.5302\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d8bfa4233fc87c7f0b3f1aa0c4960ad13475a04e\",\"title\":\"An enhanced 3DCNN\\u2010ConvLSTM for spatiotemporal multimedia data analysis\",\"url\":\"https://www.semanticscholar.org/paper/d8bfa4233fc87c7f0b3f1aa0c4960ad13475a04e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48571637\",\"name\":\"L. Zhang\"},{\"authorId\":\"34798935\",\"name\":\"Xiantong Zhen\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"}],\"doi\":\"10.1109/TIP.2018.2866688\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"69a41c98f6b71764913145dbc2bb4643c9bc4b0a\",\"title\":\"Learning Match Kernels on Grassmann Manifolds for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/69a41c98f6b71764913145dbc2bb4643c9bc4b0a\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153580352\",\"name\":\"Ionut Cosmin Duta\"},{\"authorId\":\"1823362\",\"name\":\"J. Uijlings\"},{\"authorId\":\"1796198\",\"name\":\"B. Ionescu\"},{\"authorId\":\"1712839\",\"name\":\"K. Aizawa\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":\"10.1007/s11042-017-4795-6\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"98127346920bdce9773aba6a2ffc8590b9558a4a\",\"title\":\"Efficient human action recognition using histograms of motion gradients and VLAD with descriptor shape information\",\"url\":\"https://www.semanticscholar.org/paper/98127346920bdce9773aba6a2ffc8590b9558a4a\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1753998\",\"name\":\"N. Dimitriou\"},{\"authorId\":\"46544780\",\"name\":\"G. Kioumourtzis\"},{\"authorId\":\"34297667\",\"name\":\"Anargyros Sideris\"},{\"authorId\":\"3875663\",\"name\":\"G. Stavropoulos\"},{\"authorId\":\"31310029\",\"name\":\"Evdoxia Taka\"},{\"authorId\":\"40544543\",\"name\":\"N. Zotos\"},{\"authorId\":\"3117391\",\"name\":\"G. Leventakis\"},{\"authorId\":\"143636644\",\"name\":\"D. Tzovaras\"}],\"doi\":\"10.1109/EISIC.2017.13\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"38936c4da0ab730d4e0923fdfa6adc8be2791ab7\",\"title\":\"An Integrated Framework for the Timely Detection of Petty Crimes\",\"url\":\"https://www.semanticscholar.org/paper/38936c4da0ab730d4e0923fdfa6adc8be2791ab7\",\"venue\":\"2017 European Intelligence and Security Informatics Conference (EISIC)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46554754\",\"name\":\"Lianping Yang\"},{\"authorId\":\"94362647\",\"name\":\"Y. Qin\"},{\"authorId\":\"3153945\",\"name\":\"Xiangde Zhang\"}],\"doi\":\"10.1007/s11554-020-01025-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9577332304d72f066aa821f0ba4f81fcaad667b0\",\"title\":\"Lightweight densely connected residual network for human pose estimation\",\"url\":\"https://www.semanticscholar.org/paper/9577332304d72f066aa821f0ba4f81fcaad667b0\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92599875\",\"name\":\"M. Nadeem\"},{\"authorId\":\"1828728\",\"name\":\"V. N. L. Franqueira\"},{\"authorId\":\"1881146\",\"name\":\"X. Zhai\"},{\"authorId\":\"1741168\",\"name\":\"F. Kurugollu\"}],\"doi\":\"10.1109/ACCESS.2019.2924733\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"255485196a869c98aacce60a86074fccf07c01eb\",\"title\":\"A Survey of Deep Learning Solutions for Multimedia Visual Content Analysis\",\"url\":\"https://www.semanticscholar.org/paper/255485196a869c98aacce60a86074fccf07c01eb\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403243307\",\"name\":\"Maryam Asadi-Aghbolaghi\"},{\"authorId\":\"35517688\",\"name\":\"Hugo Bertiche\"},{\"authorId\":\"145653560\",\"name\":\"Vicent Roig\"},{\"authorId\":\"1411108625\",\"name\":\"Shohreh Kasaei\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"}],\"doi\":\"10.1109/ICCVW.2017.376\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8ac0cc1b7868333c568aab11dbe22cc4fdbfa62f\",\"title\":\"Action Recognition from RGB-D Data: Comparison and Fusion of Spatio-Temporal Handcrafted Features and Deep Strategies\",\"url\":\"https://www.semanticscholar.org/paper/8ac0cc1b7868333c568aab11dbe22cc4fdbfa62f\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":\"1911.08511\",\"authors\":[{\"authorId\":\"51207689\",\"name\":\"Michael Peven\"},{\"authorId\":\"1678633\",\"name\":\"Gregory Hager\"},{\"authorId\":\"3207112\",\"name\":\"A. Reiter\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b5a3276c943aea32d6331c317649e5d1dc1faf91\",\"title\":\"Action Recognition Using Volumetric Motion Representations\",\"url\":\"https://www.semanticscholar.org/paper/b5a3276c943aea32d6331c317649e5d1dc1faf91\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1912.04075\",\"authors\":[{\"authorId\":\"46933964\",\"name\":\"Gabrielle Ras\"},{\"authorId\":\"2396027\",\"name\":\"L. Ambrogioni\"},{\"authorId\":\"80777440\",\"name\":\"U. G\\u00fc\\u00e7l\\u00fc\"},{\"authorId\":\"143799386\",\"name\":\"M. V. Gerven\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"4f90ba2a26a7647eb9d3d7936ce596cd138d1dd9\",\"title\":\"Temporal Factorization of 3D Convolutional Kernels\",\"url\":\"https://www.semanticscholar.org/paper/4f90ba2a26a7647eb9d3d7936ce596cd138d1dd9\",\"venue\":\"BNAIC/BENELEARN\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145598806\",\"name\":\"Rajiv Kapoor\"},{\"authorId\":\"103825173\",\"name\":\"O. Mishra\"},{\"authorId\":\"50466173\",\"name\":\"Madan Mohan Tripathi\"}],\"doi\":\"10.2478/jee-2019-0077\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"36e4fab99667b646297b3d29f405a30e383a7728\",\"title\":\"Human action recognition using descriptor based on selective finite element analysis\",\"url\":\"https://www.semanticscholar.org/paper/36e4fab99667b646297b3d29f405a30e383a7728\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1749627\",\"name\":\"M. Leordeanu\"}],\"doi\":\"10.1007/978-3-030-42128-1_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1431aa3159e932c96265c73f9bf8fbc2fa321926\",\"title\":\"Unsupervised Learning Towards the Future\",\"url\":\"https://www.semanticscholar.org/paper/1431aa3159e932c96265c73f9bf8fbc2fa321926\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2944007\",\"name\":\"Guanghua Tan\"},{\"authorId\":\"1883252\",\"name\":\"Rui Miao\"},{\"authorId\":\"151471091\",\"name\":\"Y. Xiao\"}],\"doi\":\"10.1007/978-3-030-30508-6_13\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"53c38e91f7315d0e79e61e644ef7dcbcd35678e0\",\"title\":\"Action Recognition Based on Divide-and-Conquer\",\"url\":\"https://www.semanticscholar.org/paper/53c38e91f7315d0e79e61e644ef7dcbcd35678e0\",\"venue\":\"ICANN\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"117454237\",\"name\":\"Zirui Qiu\"},{\"authorId\":\"144359415\",\"name\":\"J. Sun\"},{\"authorId\":\"51163848\",\"name\":\"Mingyue Guo\"},{\"authorId\":\"21836351\",\"name\":\"Mantao Wang\"},{\"authorId\":\"46334637\",\"name\":\"D. Zhang\"}],\"doi\":\"10.1007/978-981-15-0121-0_1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"71e47cea739e472da47756040e78fdae8bd21752\",\"title\":\"Survey on Deep Learning for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/71e47cea739e472da47756040e78fdae8bd21752\",\"venue\":\"ICPCSEE\",\"year\":2019},{\"arxivId\":\"1708.03958\",\"authors\":[{\"authorId\":\"41191188\",\"name\":\"Lin Sun\"},{\"authorId\":\"2370507\",\"name\":\"K. Jia\"},{\"authorId\":\"143887468\",\"name\":\"Kevin Chen\"},{\"authorId\":\"1739816\",\"name\":\"D. Yeung\"},{\"authorId\":\"2131088\",\"name\":\"B. Shi\"},{\"authorId\":\"1702137\",\"name\":\"S. Savarese\"}],\"doi\":\"10.1109/ICCV.2017.236\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f22d6d59e413ee255e5e0f2104f1e03be1a6722e\",\"title\":\"Lattice Long Short-Term Memory for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f22d6d59e413ee255e5e0f2104f1e03be1a6722e\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1611.06646\",\"authors\":[{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2518212\",\"name\":\"Hakan Bilen\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1109/CVPR.2017.607\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7b53a308a41507a2ef2faed78eb48812633e75fb\",\"title\":\"Self-Supervised Video Representation Learning with Odd-One-Out Networks\",\"url\":\"https://www.semanticscholar.org/paper/7b53a308a41507a2ef2faed78eb48812633e75fb\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3438717\",\"name\":\"S. Azam\"},{\"authorId\":\"33276759\",\"name\":\"A. Rafique\"},{\"authorId\":\"145745152\",\"name\":\"M. Jeon\"}],\"doi\":\"10.1109/ICCAIS.2016.7822459\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"97335eedc7abf75e3fa5c3f00ed1236924ad7da1\",\"title\":\"Vehicle pose detection using region based convolutional neural network\",\"url\":\"https://www.semanticscholar.org/paper/97335eedc7abf75e3fa5c3f00ed1236924ad7da1\",\"venue\":\"2016 International Conference on Control, Automation and Information Sciences (ICCAIS)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143612376\",\"name\":\"Simon Fraser\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3b2a2357b12cf0a5c99c8bc06ef7b46e40dd888e\",\"title\":\"Learning Person Trajectory Representations for Team Activity Analysis\",\"url\":\"https://www.semanticscholar.org/paper/3b2a2357b12cf0a5c99c8bc06ef7b46e40dd888e\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"69893872\",\"name\":\"Yuri Yudhaswana Joefrie\"},{\"authorId\":\"96853476\",\"name\":\"Masaki Aono\"}],\"doi\":\"10.1109/ICAICTA.2019.8904245\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6ccba260ccaa7fb9a649497e80aefa737756b3b0\",\"title\":\"Action Recognition by Composite Deep Learning Architecture I3D-DenseLSTM\",\"url\":\"https://www.semanticscholar.org/paper/6ccba260ccaa7fb9a649497e80aefa737756b3b0\",\"venue\":\"2019 International Conference of Advanced Informatics: Concepts, Theory and Applications (ICAICTA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49455479\",\"name\":\"Y. Zhou\"},{\"authorId\":\"6485172\",\"name\":\"Xiaoyan Sun\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cb2917413c9b36c3bb9739bce6c03a1a6eb619b3\",\"title\":\"MiCT : Mixed 3 D / 2 D Convolutional Tube for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cb2917413c9b36c3bb9739bce6c03a1a6eb619b3\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144289594\",\"name\":\"C. Caetano\"},{\"authorId\":\"143793197\",\"name\":\"V. H. Melo\"},{\"authorId\":\"144103389\",\"name\":\"F. Br\\u00e9mond\"},{\"authorId\":\"6141311\",\"name\":\"J. A. D. Santos\"},{\"authorId\":\"9385043\",\"name\":\"W. Schwartz\"}],\"doi\":\"10.1016/J.JVCIR.2019.102596\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c3c201c48d14e0e7135d4558590a4ad3f7bc864c\",\"title\":\"Magnitude-Orientation Stream network and depth information applied to activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/c3c201c48d14e0e7135d4558590a4ad3f7bc864c\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39974958\",\"name\":\"T. Yu\"},{\"authorId\":\"1909131\",\"name\":\"Huxiang Gu\"},{\"authorId\":\"46660013\",\"name\":\"L. Wang\"},{\"authorId\":\"1683738\",\"name\":\"S. Xiang\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.1109/ICIP.2017.8296542\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a9756ca629f73dc8f84ee97cfa8b34b8207392dc\",\"title\":\"Cascaded temporal spatial features for video action recognition\",\"url\":\"https://www.semanticscholar.org/paper/a9756ca629f73dc8f84ee97cfa8b34b8207392dc\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jun Guo\"},{\"authorId\":\"47636228\",\"name\":\"H. Chao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d0398f9d5c6bb83779c7f6ab91be9db3b2235f9\",\"title\":\"Building an End-to-End Spatial-Temporal Convolutional Network for Video Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/6d0398f9d5c6bb83779c7f6ab91be9db3b2235f9\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":\"1707.06436\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":null,\"name\":\"Yun He\"},{\"authorId\":\"9935341\",\"name\":\"S. Ueta\"},{\"authorId\":\"5014206\",\"name\":\"T. Suzuki\"},{\"authorId\":\"49897653\",\"name\":\"K. Abe\"},{\"authorId\":\"2554424\",\"name\":\"Asako Kanezaki\"},{\"authorId\":\"49133490\",\"name\":\"Shinichiro Morita\"},{\"authorId\":\"22219521\",\"name\":\"Toshiyuki Yabe\"},{\"authorId\":\"50544018\",\"name\":\"Yoshihiro Kanehara\"},{\"authorId\":\"22174281\",\"name\":\"Hiroya Yatsuyanagi\"},{\"authorId\":\"1692565\",\"name\":\"S. Maruyama\"},{\"authorId\":\"10756539\",\"name\":\"Ryousuke Takasawa\"},{\"authorId\":\"3217653\",\"name\":\"Masataka Fuchida\"},{\"authorId\":\"2642022\",\"name\":\"Y. Miyashita\"},{\"authorId\":\"34935749\",\"name\":\"Kazushige Okayasu\"},{\"authorId\":\"20505300\",\"name\":\"Yuta Matsuzaki\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"title\":\"cvpaper.challenge in 2016: Futuristic Computer Vision through 1, 600 Papers Survey\",\"url\":\"https://www.semanticscholar.org/paper/8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41189343\",\"name\":\"A. E. Seghrouchni\"},{\"authorId\":\"1707363\",\"name\":\"D. Sarne\"},{\"authorId\":\"145960032\",\"name\":\"R. Goebel\"},{\"authorId\":\"144865865\",\"name\":\"Y. Tanaka\"}],\"doi\":\"10.1007/978-3-030-56150-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ccd6a93d74958ef8993f2b3102ccc4f913e33011\",\"title\":\"Artificial Intelligence. IJCAI 2019 International Workshops: Macao, China, August 10\\u201312, 2019, Revised Selected Best Papers\",\"url\":\"https://www.semanticscholar.org/paper/ccd6a93d74958ef8993f2b3102ccc4f913e33011\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1391201846\",\"name\":\"Jianyu Chen\"},{\"authorId\":\"144749222\",\"name\":\"J. Kong\"},{\"authorId\":\"1801474\",\"name\":\"Hui Sun\"},{\"authorId\":\"49507094\",\"name\":\"H. Xu\"},{\"authorId\":\"4058024\",\"name\":\"X. Liu\"},{\"authorId\":\"1774877\",\"name\":\"Ying-hua Lu\"},{\"authorId\":\"5858971\",\"name\":\"Caixia Zheng\"}],\"doi\":\"10.3390/s20113126\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"12afacc80852a3cffa18722ef43c0d82746ff66c\",\"title\":\"Spatiotemporal Interaction Residual Networks with Pseudo3D for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/12afacc80852a3cffa18722ef43c0d82746ff66c\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Minah Lee\"},{\"authorId\":null,\"name\":\"Burhan Ahmad Mudassar\"},{\"authorId\":\"40191008\",\"name\":\"Taesik Na\"},{\"authorId\":null,\"name\":\"Saibal Mukhopadhyay\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"bb8321f527569684f0066843ae8231c94a96deb2\",\"title\":\"A Spatiotemporal Pre-processing Network for Activity Recognition under Rain\",\"url\":\"https://www.semanticscholar.org/paper/bb8321f527569684f0066843ae8231c94a96deb2\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"1912.00134\",\"authors\":[{\"authorId\":\"32601092\",\"name\":\"R. C. Nascimento\"},{\"authorId\":\"81601597\",\"name\":\"Y. M. Souto\"},{\"authorId\":\"49011978\",\"name\":\"Eduardo Ogasawara\"},{\"authorId\":\"145179575\",\"name\":\"F. Porto\"},{\"authorId\":\"31778392\",\"name\":\"E. Bezerra\"}],\"doi\":\"10.1016/j.neucom.2020.09.060\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"27ffc8850d0ffa529b40b324d7f6d74c7be9a54f\",\"title\":\"STConvS2S: Spatiotemporal Convolutional Sequence to Sequence Network for Weather Forecasting\",\"url\":\"https://www.semanticscholar.org/paper/27ffc8850d0ffa529b40b324d7f6d74c7be9a54f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98658818\",\"name\":\"C. Lea\"},{\"authorId\":\"3207112\",\"name\":\"A. Reiter\"},{\"authorId\":\"144020730\",\"name\":\"R. Vidal\"},{\"authorId\":\"1678633\",\"name\":\"Gregory Hager\"}],\"doi\":\"10.1007/978-3-319-46487-9_3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a900a0b5319d84e212943b63265050c05b51652b\",\"title\":\"Segmental Spatiotemporal CNNs for Fine-Grained Action Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/a900a0b5319d84e212943b63265050c05b51652b\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"2001.02613\",\"authors\":[{\"authorId\":\"72705250\",\"name\":\"V. Patil\"},{\"authorId\":\"66314383\",\"name\":\"Wouter Van Gansbeke\"},{\"authorId\":\"1778526\",\"name\":\"Dengxin Dai\"},{\"authorId\":\"117044719\",\"name\":\"L. Van Gool\"}],\"doi\":\"10.1109/LRA.2020.3017478\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b2ec78fead72012779283ed056117a6bb3cd5f7b\",\"title\":\"Don\\u2019t Forget The Past: Recurrent Depth Estimation from Monocular Video\",\"url\":\"https://www.semanticscholar.org/paper/b2ec78fead72012779283ed056117a6bb3cd5f7b\",\"venue\":\"IEEE Robotics and Automation Letters\",\"year\":2020},{\"arxivId\":\"2012.11866\",\"authors\":[{\"authorId\":\"2595189\",\"name\":\"Zehua Sun\"},{\"authorId\":\"120809631\",\"name\":\"Jiwang Liu\"},{\"authorId\":\"143969578\",\"name\":\"Qiuhong Ke\"},{\"authorId\":\"1877377\",\"name\":\"H. Rahmani\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"816236bf3219363bfe4b847363e137b1fe6712e7\",\"title\":\"Human Action Recognition from Various Data Modalities: A Review\",\"url\":\"https://www.semanticscholar.org/paper/816236bf3219363bfe4b847363e137b1fe6712e7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35031371\",\"name\":\"Wenbin Du\"},{\"authorId\":\"2799162\",\"name\":\"Y. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1109/TIP.2017.2778563\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"57eeaceb14a01a2560d0b90d38205e512dcca691\",\"title\":\"Recurrent Spatial-Temporal Attention Network for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/57eeaceb14a01a2560d0b90d38205e512dcca691\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":\"1608.00859\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-319-46484-8_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"title\":\"Temporal Segment Networks: Towards Good Practices for Deep Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1711.09550\",\"authors\":[{\"authorId\":\"144858226\",\"name\":\"Xiang Long\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144608002\",\"name\":\"Gerard de Melo\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"48033101\",\"name\":\"Xiao Liu\"},{\"authorId\":\"35247507\",\"name\":\"Shilei Wen\"}],\"doi\":\"10.1109/CVPR.2018.00817\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"5406fd98aa22bc2a0c1a8bc2a58ca3eb7a91155d\",\"title\":\"Attention Clusters: Purely Attention Based Local Feature Integration for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/5406fd98aa22bc2a0c1a8bc2a58ca3eb7a91155d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1908.11309\",\"authors\":[{\"authorId\":\"1389611448\",\"name\":\"Radu Sibechi\"},{\"authorId\":\"1777728\",\"name\":\"O. Booij\"},{\"authorId\":\"1820934\",\"name\":\"N. Baka\"},{\"authorId\":\"2789097\",\"name\":\"P. Bloem\"}],\"doi\":\"10.1109/ICCVW.2019.00122\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b37280824d82b03e02fe08d290535f4dd07119de\",\"title\":\"Exploiting Temporality for Semi-Supervised Video Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/b37280824d82b03e02fe08d290535f4dd07119de\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1805.11911\",\"authors\":[{\"authorId\":\"38212285\",\"name\":\"N. Gessert\"},{\"authorId\":\"46199775\",\"name\":\"Torben Priegnitz\"},{\"authorId\":\"3452947\",\"name\":\"T. Saathoff\"},{\"authorId\":\"1994997\",\"name\":\"S. Antoni\"},{\"authorId\":\"143956932\",\"name\":\"D. Meyer\"},{\"authorId\":\"10193733\",\"name\":\"M. Hamann\"},{\"authorId\":\"144690829\",\"name\":\"K. J\\u00fcnemann\"},{\"authorId\":\"34365914\",\"name\":\"C. Otte\"},{\"authorId\":\"3236423\",\"name\":\"A. Schlaefer\"}],\"doi\":\"10.1007/978-3-030-00937-3_26\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"68728c74052b1598a10b2e60f91c54ef5c920887\",\"title\":\"Needle Tip Force Estimation using an OCT Fiber and a Fused convGRU-CNN Architecture\",\"url\":\"https://www.semanticscholar.org/paper/68728c74052b1598a10b2e60f91c54ef5c920887\",\"venue\":\"MICCAI\",\"year\":2018},{\"arxivId\":\"1609.06782\",\"authors\":[{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1145/3122865.3122867\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1a4b6ee6cd846ef5e3030a6ae59f026e5f50eda6\",\"title\":\"Deep Learning for Video Classification and Captioning\",\"url\":\"https://www.semanticscholar.org/paper/1a4b6ee6cd846ef5e3030a6ae59f026e5f50eda6\",\"venue\":\"Frontiers of Multimedia Research\",\"year\":2018},{\"arxivId\":\"1712.01111\",\"authors\":[{\"authorId\":\"145749579\",\"name\":\"R. Hou\"},{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"cb8806e90aaa882ffc212864ae6d6e28c9092aa4\",\"title\":\"An End-to-end 3D Convolutional Neural Network for Action Detection and Segmentation in Videos\",\"url\":\"https://www.semanticscholar.org/paper/cb8806e90aaa882ffc212864ae6d6e28c9092aa4\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3258842\",\"name\":\"J. Wang\"},{\"authorId\":\"1788029\",\"name\":\"W. Wang\"},{\"authorId\":\"144466591\",\"name\":\"Wen Gao\"}],\"doi\":\"10.1109/TCSVT.2018.2887061\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c372c9892fa0e3b36675bbf63b221696cd8a8b1f\",\"title\":\"Fast and Accurate Action Detection in Videos With Motion-Centric Attention Model\",\"url\":\"https://www.semanticscholar.org/paper/c372c9892fa0e3b36675bbf63b221696cd8a8b1f\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145337089\",\"name\":\"S. Barbosa\"},{\"authorId\":\"40913232\",\"name\":\"P. Chen\"},{\"authorId\":\"1381434830\",\"name\":\"Alfredo Cuzzocrea\"},{\"authorId\":\"46993406\",\"name\":\"Xiaoyong Du\"},{\"authorId\":\"144408238\",\"name\":\"Orhun Kara\"},{\"authorId\":\"152244126\",\"name\":\"Ting Liu\"},{\"authorId\":\"1731022\",\"name\":\"K. Sivalingam\"},{\"authorId\":\"145514738\",\"name\":\"D. Slezak\"},{\"authorId\":\"1704749\",\"name\":\"T. Washio\"},{\"authorId\":\"15469693\",\"name\":\"Xiaokang Yang\"},{\"authorId\":\"145078769\",\"name\":\"J. Yuan\"},{\"authorId\":\"1690892\",\"name\":\"R. Prates\"},{\"authorId\":\"15223978\",\"name\":\"Xingming Sun\"},{\"authorId\":\"46583977\",\"name\":\"J. Wang\"},{\"authorId\":\"1743774\",\"name\":\"E. Bertino\"}],\"doi\":\"10.1007/978-981-15-8083-3\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3ec1b3c027cd6f8222d2ad0d6e35135e2d304ac8\",\"title\":\"Artificial Intelligence and Security: 6th International Conference, ICAIS 2020, Hohhot, China, July 17\\u201320, 2020, Proceedings, Part I\",\"url\":\"https://www.semanticscholar.org/paper/3ec1b3c027cd6f8222d2ad0d6e35135e2d304ac8\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37041694\",\"name\":\"S. L. Pintea\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a9c6585c1973d7cb47cd4691120527b68d444a3\",\"title\":\"Continuous learning in computer vision\",\"url\":\"https://www.semanticscholar.org/paper/8a9c6585c1973d7cb47cd4691120527b68d444a3\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1907.05640\",\"authors\":[{\"authorId\":\"2014145\",\"name\":\"Mohammad Tavakolian\"},{\"authorId\":\"2884918\",\"name\":\"M. Sabokrou\"},{\"authorId\":\"144979251\",\"name\":\"A. Hadid\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1bd2c92ff77126f7352b32d3b00f998f15bfdf07\",\"title\":\"AVD: Adversarial Video Distillation\",\"url\":\"https://www.semanticscholar.org/paper/1bd2c92ff77126f7352b32d3b00f998f15bfdf07\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1904.08492\",\"authors\":[{\"authorId\":\"3424093\",\"name\":\"Sumanth Chennupati\"},{\"authorId\":\"66443522\",\"name\":\"Ganesh Sistu\"},{\"authorId\":\"2601522\",\"name\":\"S. Yogamani\"},{\"authorId\":\"48341937\",\"name\":\"S. Rawashdeh\"}],\"doi\":\"10.1109/CVPRW.2019.00159\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e863a6b1bb39a38a88330f2609a560c3dfed6db5\",\"title\":\"MultiNet++: Multi-Stream Feature Aggregation and Geometric Loss Strategy for Multi-Task Learning\",\"url\":\"https://www.semanticscholar.org/paper/e863a6b1bb39a38a88330f2609a560c3dfed6db5\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":\"1901.06792\",\"authors\":[{\"authorId\":\"10779576\",\"name\":\"Sunder Ali Khowaja\"},{\"authorId\":\"1685677\",\"name\":\"Seok-Lyong Lee\"}],\"doi\":\"10.1007/s11263-019-01248-3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b1f9a9bc031f47e972f2fb6cbd48a0474f7ca6c0\",\"title\":\"Semantic Image Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b1f9a9bc031f47e972f2fb6cbd48a0474f7ca6c0\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"73571779\",\"name\":\"Keke Geng\"},{\"authorId\":\"2066794\",\"name\":\"Guodong Yin\"}],\"doi\":\"10.1109/ACCESS.2020.2990636\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c88363c91c90e65bd65018e995f901c44883e5ef\",\"title\":\"Using Deep Learning in Infrared Images to Enable Human Gesture Recognition for Autonomous Vehicles\",\"url\":\"https://www.semanticscholar.org/paper/c88363c91c90e65bd65018e995f901c44883e5ef\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1703.08089\",\"authors\":[{\"authorId\":\"32774629\",\"name\":\"A. Richard\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1016/j.cviu.2016.10.014\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a2af7dfe2769164c14d8ea2f73c5073c2a2f2bbe\",\"title\":\"A bag-of-words equivalent recurrent neural network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/a2af7dfe2769164c14d8ea2f73c5073c2a2f2bbe\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47908694\",\"name\":\"Y. Liu\"},{\"authorId\":\"50535300\",\"name\":\"Jianqiang Huang\"},{\"authorId\":\"144161025\",\"name\":\"C. Zhou\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"},{\"authorId\":\"143863243\",\"name\":\"X. Hua\"}],\"doi\":\"10.1145/3126686.3126705\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"ce11b2d7905d2955c4282db5b68482edb846f29f\",\"title\":\"Spatiotemporal Multi-Task Network for Human Activity Understanding\",\"url\":\"https://www.semanticscholar.org/paper/ce11b2d7905d2955c4282db5b68482edb846f29f\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39440469\",\"name\":\"Sudhakar Kumawat\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"68881e3828f18c304189755c5a64979752d4a3eb\",\"title\":\"LP-3 DCNN : Unveiling Local Phase in 3 D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/68881e3828f18c304189755c5a64979752d4a3eb\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1711.10305\",\"authors\":[{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/ICCV.2017.590\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"024d037d46ae933c7e12fd16af61953c7161773a\",\"title\":\"Learning Spatio-Temporal Representation with Pseudo-3D Residual Networks\",\"url\":\"https://www.semanticscholar.org/paper/024d037d46ae933c7e12fd16af61953c7161773a\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1906.04226\",\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"1403581832\",\"name\":\"Laura Sevilla-Lara\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"},{\"authorId\":\"143907244\",\"name\":\"Yi Yang\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a71b7cf982cf1b54cda4f0746d4ba7c7ea3f4e4\",\"title\":\"FASTER Recurrent Networks for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/8a71b7cf982cf1b54cda4f0746d4ba7c7ea3f4e4\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144858226\",\"name\":\"Xiang Long\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144608002\",\"name\":\"Gerard de Melo\"},{\"authorId\":\"48033101\",\"name\":\"Xiao Liu\"},{\"authorId\":\"48515099\",\"name\":\"Y. Li\"},{\"authorId\":\"50984378\",\"name\":\"F. Li\"},{\"authorId\":\"35247507\",\"name\":\"Shilei Wen\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"686970efdcef5d11a4d2b1f5d77d5515d766f53a\",\"title\":\"Multimodal Keyless Attention Fusion for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/686970efdcef5d11a4d2b1f5d77d5515d766f53a\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2283107\",\"name\":\"Debaditya Roy\"},{\"authorId\":\"70611576\",\"name\":\"C. Krishnamohan\"}],\"doi\":null,\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"62d8bbe48f623f130d243a38674cf77701fbbdb4\",\"title\":\"REPRESENTATION LEARNING FOR ACTION RECOGNITION\",\"url\":\"https://www.semanticscholar.org/paper/62d8bbe48f623f130d243a38674cf77701fbbdb4\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9177510\",\"name\":\"Y. Sun\"},{\"authorId\":\"2125709\",\"name\":\"Xinxiao Wu\"},{\"authorId\":\"40812963\",\"name\":\"Wennan Yu\"},{\"authorId\":\"3450614\",\"name\":\"Feiwu Yu\"}],\"doi\":\"10.1016/j.neucom.2018.02.028\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c7530a91cfad66b18f08b2f466998ff9a0b25223\",\"title\":\"Action recognition with motion map 3D network\",\"url\":\"https://www.semanticscholar.org/paper/c7530a91cfad66b18f08b2f466998ff9a0b25223\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"28717844\",\"name\":\"B. Meng\"},{\"authorId\":\"47058954\",\"name\":\"L. Zhang\"},{\"authorId\":\"1391185091\",\"name\":\"F. Jin\"},{\"authorId\":\"152538521\",\"name\":\"L. Yang\"},{\"authorId\":\"153625729\",\"name\":\"Hong-Yih Cheng\"},{\"authorId\":\"153115430\",\"name\":\"Q. Wang\"}],\"doi\":\"10.1007/978-981-10-5230-9_22\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2ee82d0cc93dd3728ba49c818a0ba5626d4a5294\",\"title\":\"Abnormal Events Detection Using Deep Networks for Video Surveillance\",\"url\":\"https://www.semanticscholar.org/paper/2ee82d0cc93dd3728ba49c818a0ba5626d4a5294\",\"venue\":\"ICCSIP\",\"year\":2016},{\"arxivId\":\"1901.06032\",\"authors\":[{\"authorId\":\"2916228\",\"name\":\"A. Khan\"},{\"authorId\":\"23690960\",\"name\":\"A. Sohail\"},{\"authorId\":\"66666770\",\"name\":\"Umme Zahoora\"},{\"authorId\":\"8852220\",\"name\":\"Aqsa Saeed Qureshi\"}],\"doi\":\"10.1007/s10462-020-09825-6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8452941a175c899628c679523da952b18f63e335\",\"title\":\"A survey of the recent architectures of deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/8452941a175c899628c679523da952b18f63e335\",\"venue\":\"Artificial Intelligence Review\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153580352\",\"name\":\"Ionut Cosmin Duta\"},{\"authorId\":\"1796198\",\"name\":\"B. Ionescu\"},{\"authorId\":\"1712839\",\"name\":\"K. Aizawa\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":\"10.1109/CVPR.2017.341\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e3ce4c3e1279e3dc0c14ff3bb2920aced9e62638\",\"title\":\"Spatio-Temporal Vector of Locally Max Pooled Features for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/e3ce4c3e1279e3dc0c14ff3bb2920aced9e62638\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2283107\",\"name\":\"Debaditya Roy\"},{\"authorId\":\"144987703\",\"name\":\"M. Srinivas\"},{\"authorId\":\"34358756\",\"name\":\"C. K. Mohan\"}],\"doi\":\"10.1016/j.patcog.2016.03.011\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0710ff88f9b2de9c0235787442825fb935a39a22\",\"title\":\"Sparsity-inducing dictionaries for effective action classification\",\"url\":\"https://www.semanticscholar.org/paper/0710ff88f9b2de9c0235787442825fb935a39a22\",\"venue\":\"Pattern Recognit.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"108646857\",\"name\":\"Dan Liu\"},{\"authorId\":\"152994876\",\"name\":\"Yunfeng Ji\"},{\"authorId\":\"144560368\",\"name\":\"M. Ye\"},{\"authorId\":\"46636010\",\"name\":\"Y. Gan\"},{\"authorId\":\"1739414\",\"name\":\"Jianwei Zhang\"}],\"doi\":\"10.1109/ACCESS.2020.2983355\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b89aed9287493cc57eb0dcd58eccec4ec0c981b6\",\"title\":\"An Improved Attention-Based Spatiotemporal-Stream Model for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/b89aed9287493cc57eb0dcd58eccec4ec0c981b6\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144378416\",\"name\":\"Y. Zhong\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"}],\"doi\":\"10.1109/ICIP.2018.8451428\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"430134bf1805c075ae21b499430f27c483d04f65\",\"title\":\"Unsupervised Learning for Forecasting Action Representations\",\"url\":\"https://www.semanticscholar.org/paper/430134bf1805c075ae21b499430f27c483d04f65\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1768624101\",\"name\":\"Akram Mihanpour\"},{\"authorId\":\"2406798\",\"name\":\"Mohammad J. Rashti\"},{\"authorId\":\"153817519\",\"name\":\"S. E. Alavi\"}],\"doi\":\"10.22133/IJWR.2020.242723.1063\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"9064d8220c7fb8fde958d700b825bf03a757dc46\",\"title\":\"CoReHAR: A Hybrid Deep Network for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9064d8220c7fb8fde958d700b825bf03a757dc46\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39974958\",\"name\":\"T. Yu\"},{\"authorId\":\"46181112\",\"name\":\"Chaoxu Guo\"},{\"authorId\":\"46660013\",\"name\":\"L. Wang\"},{\"authorId\":\"1909131\",\"name\":\"Huxiang Gu\"},{\"authorId\":\"1683738\",\"name\":\"S. Xiang\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.1016/j.patrec.2018.07.034\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"403f756f9f18948994e7a650ccb0be359d695530\",\"title\":\"Joint spatial-temporal attention for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/403f756f9f18948994e7a650ccb0be359d695530\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1696573\",\"name\":\"Jiagang Zhu\"},{\"authorId\":\"145251501\",\"name\":\"W. Zou\"},{\"authorId\":\"144168342\",\"name\":\"Zheng Zhu\"}],\"doi\":\"10.1109/ICPR.2018.8545639\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"fe6edc8c6e4cff6a2c115648a2135ffd47b04a08\",\"title\":\"Two-Stream Gated Fusion ConvNets for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fe6edc8c6e4cff6a2c115648a2135ffd47b04a08\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145302989\",\"name\":\"P. Novais\"},{\"authorId\":\"143869061\",\"name\":\"David Camacho\"},{\"authorId\":\"1709042\",\"name\":\"H. Yin\"}],\"doi\":\"10.1007/978-3-030-62362-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2ef549fbd0aa3c6b0cd3cdbc01320e53e72ded9f\",\"title\":\"Intelligent Data Engineering and Automated Learning \\u2013 IDEAL 2020: 21st International Conference, Guimaraes, Portugal, November 4\\u20136, 2020, Proceedings, Part I\",\"url\":\"https://www.semanticscholar.org/paper/2ef549fbd0aa3c6b0cd3cdbc01320e53e72ded9f\",\"venue\":\"IDEAL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145095579\",\"name\":\"L. Yao\"},{\"authorId\":\"144350546\",\"name\":\"Y. Qian\"}],\"doi\":\"10.1007/978-3-030-00776-8_57\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f094bd9360b59afc2880c20ad3a37ee640c6c6c9\",\"title\":\"DT-3DResNet-LSTM: An Architecture for Temporal Activity Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/f094bd9360b59afc2880c20ad3a37ee640c6c6c9\",\"venue\":\"TRECVID\",\"year\":2018},{\"arxivId\":\"1611.05267\",\"authors\":[{\"authorId\":\"98658818\",\"name\":\"C. Lea\"},{\"authorId\":\"49447925\",\"name\":\"M. Flynn\"},{\"authorId\":\"144020730\",\"name\":\"R. Vidal\"},{\"authorId\":\"3207112\",\"name\":\"A. Reiter\"},{\"authorId\":\"1678633\",\"name\":\"Gregory Hager\"}],\"doi\":\"10.1109/CVPR.2017.113\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"210f258524deabc3d08cbbea4e4ca5c2a98f4846\",\"title\":\"Temporal Convolutional Networks for Action Segmentation and Detection\",\"url\":\"https://www.semanticscholar.org/paper/210f258524deabc3d08cbbea4e4ca5c2a98f4846\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1904.03498\",\"authors\":[{\"authorId\":\"39440469\",\"name\":\"Sudhakar Kumawat\"},{\"authorId\":\"145853779\",\"name\":\"S. Raman\"}],\"doi\":\"10.1109/CVPR.2019.00504\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"75544f83d38ef1686d70c763deb43305c5dc8a48\",\"title\":\"LP-3DCNN: Unveiling Local Phase in 3D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/75544f83d38ef1686d70c763deb43305c5dc8a48\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153008120\",\"name\":\"Zineng Xu\"},{\"authorId\":\"1798046\",\"name\":\"Ver\\u00f3nica Vilaplana\"},{\"authorId\":\"2585946\",\"name\":\"J. R. Morros\"}],\"doi\":\"10.1109/CBMI.2018.8516450\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"084a5a1699ab799517baa316bc4c8d0754b145a9\",\"title\":\"Action Tube Extraction Based 3D-CNN for RGB-D Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/084a5a1699ab799517baa316bc4c8d0754b145a9\",\"venue\":\"2018 International Conference on Content-Based Multimedia Indexing (CBMI)\",\"year\":2018},{\"arxivId\":\"1802.02774\",\"authors\":[{\"authorId\":\"2708397\",\"name\":\"C. Xu\"},{\"authorId\":\"144866389\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"40379722\",\"name\":\"B. Zhang\"},{\"authorId\":\"10110775\",\"name\":\"Z. Chen\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"55c68c1237166679d2cb65f266f496d1ecd4bec6\",\"title\":\"Learning to score the figure skating sports videos\",\"url\":\"https://www.semanticscholar.org/paper/55c68c1237166679d2cb65f266f496d1ecd4bec6\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48841342\",\"name\":\"Qing Lei\"},{\"authorId\":\"1701928\",\"name\":\"Jixiang Du\"},{\"authorId\":\"49173384\",\"name\":\"Hongbo Zhang\"},{\"authorId\":\"47416429\",\"name\":\"Shuang Ye\"},{\"authorId\":\"123204699\",\"name\":\"Duan-Sheng Chen\"}],\"doi\":\"10.3390/s19194129\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"fdcd429a8d6ae1928d71dd2c89e67b31138c13e1\",\"title\":\"A Survey of Vision-Based Human Action Evaluation Methods\",\"url\":\"https://www.semanticscholar.org/paper/fdcd429a8d6ae1928d71dd2c89e67b31138c13e1\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1566489065\",\"name\":\"Yukun Huang\"},{\"authorId\":\"2425471\",\"name\":\"Yongcai Guo\"},{\"authorId\":\"153686290\",\"name\":\"C. Gao\"}],\"doi\":\"10.1109/ACCESS.2020.2978223\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dd59c68dc58e350b51288d2b6ee6d5ea52ad9f84\",\"title\":\"Efficient Parallel Inflated 3D Convolution Architecture for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/dd59c68dc58e350b51288d2b6ee6d5ea52ad9f84\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1806.06793\",\"authors\":[{\"authorId\":\"2014145\",\"name\":\"Mohammad Tavakolian\"},{\"authorId\":\"144979251\",\"name\":\"A. Hadid\"}],\"doi\":\"10.1109/ICPR.2018.8545324\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a377f2c99218e0eb624ba65d6711c640b1697b92\",\"title\":\"Deep Spatiotemporal Representation of the Face for Automatic Pain Intensity Estimation\",\"url\":\"https://www.semanticscholar.org/paper/a377f2c99218e0eb624ba65d6711c640b1697b92\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47637491\",\"name\":\"M. Lakhal\"},{\"authorId\":\"7840884\",\"name\":\"A. Clap\\u00e9s\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"},{\"authorId\":\"145440152\",\"name\":\"A. Cavallaro\"}],\"doi\":\"10.1007/978-3-030-11012-3_40\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d1a8e7c833318d30d30e3eeb0cef139f86a02bcc\",\"title\":\"Residual Stacked RNNs for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d1a8e7c833318d30d30e3eeb0cef139f86a02bcc\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144444772\",\"name\":\"S. J. Berlin\"},{\"authorId\":\"34799829\",\"name\":\"M. John\"}],\"doi\":\"10.3233/jifs-191914\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"247324d489f27a5ec66030e4cf0ff2269a88433f\",\"title\":\"Light weight convolutional models with spiking neural network based human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/247324d489f27a5ec66030e4cf0ff2269a88433f\",\"venue\":\"J. Intell. Fuzzy Syst.\",\"year\":2020},{\"arxivId\":\"2008.13759\",\"authors\":[{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"67968b5b59b08ea1dd8a1266b422ee38e3ca8ad5\",\"title\":\"Online Spatiotemporal Action Detection and Prediction via Causal Representations\",\"url\":\"https://www.semanticscholar.org/paper/67968b5b59b08ea1dd8a1266b422ee38e3ca8ad5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35031371\",\"name\":\"Wenbin Du\"},{\"authorId\":\"47903936\",\"name\":\"Yali Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1109/ICCV.2017.402\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a470a81f989d5354239f1044c90e07b78c6beed7\",\"title\":\"RPAN: An End-to-End Recurrent Pose-Attention Network for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/a470a81f989d5354239f1044c90e07b78c6beed7\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145731841\",\"name\":\"P. Lei\"},{\"authorId\":\"143856428\",\"name\":\"S. Todorovic\"}],\"doi\":\"10.1109/CVPR.2018.00705\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4bfcedc30c05b68ba109b9ae71db42f1f1985770\",\"title\":\"Temporal Deformable Residual Networks for Action Segmentation in Videos\",\"url\":\"https://www.semanticscholar.org/paper/4bfcedc30c05b68ba109b9ae71db42f1f1985770\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1703.10664\",\"authors\":[{\"authorId\":\"151185786\",\"name\":\"R. Hou\"},{\"authorId\":\"145430739\",\"name\":\"C. Chen\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/ICCV.2017.620\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"065f55d40d473b63becccc890fe8a57c2f840548\",\"title\":\"Tube Convolutional Neural Network (T-CNN) for Action Detection in Videos\",\"url\":\"https://www.semanticscholar.org/paper/065f55d40d473b63becccc890fe8a57c2f840548\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1711.09618\",\"authors\":[{\"authorId\":\"8197937\",\"name\":\"K. Ohnishi\"},{\"authorId\":\"48333400\",\"name\":\"S. Yamamoto\"},{\"authorId\":\"3250559\",\"name\":\"Y. Ushiku\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e25c57a6395b7c8861088699eef1a56b6f1d70ad\",\"title\":\"Hierarchical Video Generation from Orthogonal Information: Optical Flow and Texture\",\"url\":\"https://www.semanticscholar.org/paper/e25c57a6395b7c8861088699eef1a56b6f1d70ad\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40566477\",\"name\":\"H. Yang\"},{\"authorId\":null,\"name\":\"Chunfeng Yuan\"},{\"authorId\":\"1757173\",\"name\":\"Junliang Xing\"},{\"authorId\":\"40506509\",\"name\":\"W. Hu\"}],\"doi\":\"10.1109/ICIP.2017.8296302\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"0e424b458f4fe94fc74daffda79d6366d8d005e0\",\"title\":\"SCNN: Sequential convolutional neural network for human action recognition in videos\",\"url\":\"https://www.semanticscholar.org/paper/0e424b458f4fe94fc74daffda79d6366d8d005e0\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":\"1612.06371\",\"authors\":[{\"authorId\":\"34280810\",\"name\":\"Gunnar A. Sigurdsson\"},{\"authorId\":\"2038685\",\"name\":\"S. Divvala\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1109/CVPR.2017.599\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e61c8ec6e26df76c8f0a174740f86510a786c93b\",\"title\":\"Asynchronous Temporal Fields for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e61c8ec6e26df76c8f0a174740f86510a786c93b\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9071789\",\"name\":\"Z. Liu\"},{\"authorId\":\"9173291\",\"name\":\"L. Wang\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"}],\"doi\":\"10.1007/978-3-319-92007-8_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d401b48dd13c2a6855c0f2c5f65c7f087f3d5373\",\"title\":\"Content-Aware Attention Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d401b48dd13c2a6855c0f2c5f65c7f087f3d5373\",\"venue\":\"AIAI\",\"year\":2018},{\"arxivId\":\"1912.00381\",\"authors\":[{\"authorId\":\"1756362\",\"name\":\"Swathikiran Sudhakaran\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"}],\"doi\":\"10.1109/cvpr42600.2020.00118\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"57cee868188127305f966a178ca22025b397d911\",\"title\":\"Gate-Shift Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/57cee868188127305f966a178ca22025b397d911\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1712.05896\",\"authors\":[{\"authorId\":\"30174297\",\"name\":\"Congrui Hetang\"},{\"authorId\":\"46636770\",\"name\":\"Hongwei Qin\"},{\"authorId\":\"1743348\",\"name\":\"S. Liu\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c3a7279581df2c01af56b9f7141ab3e8d202aca\",\"title\":\"Impression Network for Video Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/2c3a7279581df2c01af56b9f7141ab3e8d202aca\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9012538\",\"name\":\"Salah Alghyaline\"},{\"authorId\":\"144717607\",\"name\":\"Jun-Wei Hsieh\"},{\"authorId\":\"33689898\",\"name\":\"Chi-Hung Chuang\"}],\"doi\":\"10.1109/SMC.2017.8122640\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f19bf8b5c1860cd81b5339804d5db9e791085aa7\",\"title\":\"Video action classification using symmelets and deep learning\",\"url\":\"https://www.semanticscholar.org/paper/f19bf8b5c1860cd81b5339804d5db9e791085aa7\",\"venue\":\"2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145030935\",\"name\":\"H. Hu\"},{\"authorId\":\"51432978\",\"name\":\"Zhongke Liao\"},{\"authorId\":\"144653471\",\"name\":\"X. Xiao\"}],\"doi\":\"10.1007/s11063-018-9932-3\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5e64440c4088ae1b871fb3f6af8dd5c4e7dbe00a\",\"title\":\"Action Recognition Using Multiple Pooling Strategies of CNN Features\",\"url\":\"https://www.semanticscholar.org/paper/5e64440c4088ae1b871fb3f6af8dd5c4e7dbe00a\",\"venue\":\"Neural Processing Letters\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152342125\",\"name\":\"Han\"},{\"authorId\":\"69354043\",\"name\":\"Ang\"},{\"authorId\":\"100931872\",\"name\":\"Solo\"},{\"authorId\":\"116478202\",\"name\":\"An\"},{\"authorId\":null,\"name\":\"aymond\"},{\"authorId\":\"5614585\",\"name\":\"Heng\"},{\"authorId\":\"74146863\",\"name\":\"Uan\"},{\"authorId\":\"78093827\",\"name\":\"H\\u1eb1ng\"},{\"authorId\":\"52490132\",\"name\":\"Un\"},{\"authorId\":\"118927536\",\"name\":\"Ong\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"35a0d6ab44ac2d0e60059c7e7d5996c7e3c2962f\",\"title\":\"DFTerNet : Towards 2-bit Dynamic Fusion Networks for Accurate Human Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/35a0d6ab44ac2d0e60059c7e7d5996c7e3c2962f\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50986865\",\"name\":\"Andrei Liviu Nicolicioiu\"},{\"authorId\":\"51011850\",\"name\":\"Iulia Duta\"},{\"authorId\":\"1749627\",\"name\":\"Marius Leordeanu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"69309c61e336a32df3569248765e06abd2f35077\",\"title\":\"Recurrent Space-time Graphs for Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/69309c61e336a32df3569248765e06abd2f35077\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145095579\",\"name\":\"Li Yao\"},{\"authorId\":\"144350546\",\"name\":\"Ying Qian\"}],\"doi\":\"10.1109/WACVW.2019.00009\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9f9a9031fdff486aac00815f83cf5a9cc5d7a392\",\"title\":\"Novel Activities Detection Algorithm in Extended Videos\",\"url\":\"https://www.semanticscholar.org/paper/9f9a9031fdff486aac00815f83cf5a9cc5d7a392\",\"venue\":\"2019 IEEE Winter Applications of Computer Vision Workshops (WACVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1381480522\",\"name\":\"Mahmoud Al-Faris\"},{\"authorId\":\"145091554\",\"name\":\"John P. Chiverton\"},{\"authorId\":\"46285941\",\"name\":\"Yanyan Yang\"},{\"authorId\":\"105033173\",\"name\":\"David Ndzi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"728ebcbb1064a54eaea6cb864056876ca41f3a7a\",\"title\":\"UWS Academic Portal Deep learning of fuzzy weighted multi-resolution depth motion maps with spatial feature fusion for action recognition Al-Faris,\",\"url\":\"https://www.semanticscholar.org/paper/728ebcbb1064a54eaea6cb864056876ca41f3a7a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1381480522\",\"name\":\"M. Al-Faris\"},{\"authorId\":\"145091554\",\"name\":\"John P. Chiverton\"},{\"authorId\":\"49308434\",\"name\":\"Y. Yang\"},{\"authorId\":\"2092709\",\"name\":\"D. Ndzi\"}],\"doi\":\"10.3390/jimaging5100082\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ccf756d10bcaa51431f09dc1ef06e5efdcad1d07\",\"title\":\"Deep Learning of Fuzzy Weighted Multi-Resolution Depth Motion Maps with Spatial Feature Fusion for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ccf756d10bcaa51431f09dc1ef06e5efdcad1d07\",\"venue\":\"J. Imaging\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"1403581832\",\"name\":\"Laura Sevilla-Lara\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"11445222\",\"name\":\"H. Wang\"}],\"doi\":\"10.1609/AAAI.V34I07.7012\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d718baf9187fa5851a9389e5e250d47ba1210e0e\",\"title\":\"FASTER Recurrent Networks for Efficient Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/d718baf9187fa5851a9389e5e250d47ba1210e0e\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48799346\",\"name\":\"W. Chang\"},{\"authorId\":\"2395047\",\"name\":\"C. Ye\"},{\"authorId\":\"1725354018\",\"name\":\"Hui Zhou\"}],\"doi\":\"10.1007/978-3-030-50347-5_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"43c49aaee9a83a41e6950add3dc32371f6ef1462\",\"title\":\"Two-Stream Framework for Activity Recognition with 2D Human Pose Estimation\",\"url\":\"https://www.semanticscholar.org/paper/43c49aaee9a83a41e6950add3dc32371f6ef1462\",\"venue\":\"ICIAR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1904697\",\"name\":\"Zhenbing Liu\"},{\"authorId\":\"1796258521\",\"name\":\"Zeya Li\"},{\"authorId\":\"49908315\",\"name\":\"Ruili Wang\"},{\"authorId\":\"51251812\",\"name\":\"Ming Zong\"},{\"authorId\":\"29790429\",\"name\":\"Wanting Ji\"}],\"doi\":\"10.1007/s00521-020-05144-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"575448ab04aef0856a73d8eba3a75a5321e0506d\",\"title\":\"Spatiotemporal saliency-based multi-stream networks with attention-aware LSTM for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/575448ab04aef0856a73d8eba3a75a5321e0506d\",\"venue\":\"Neural Computing and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3130030\",\"name\":\"M. Farrajota\"},{\"authorId\":\"143955056\",\"name\":\"J. Rodrigues\"},{\"authorId\":\"1394604631\",\"name\":\"J. M. H. du Buf\"}],\"doi\":\"10.1007/s10044-018-0727-y\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b999364980e4c21d9c22cc5a9f14501432999ca4\",\"title\":\"Human action recognition in videos with articulated pose information by deep networks\",\"url\":\"https://www.semanticscholar.org/paper/b999364980e4c21d9c22cc5a9f14501432999ca4\",\"venue\":\"Pattern Analysis and Applications\",\"year\":2018},{\"arxivId\":\"1903.01038\",\"authors\":[{\"authorId\":\"3530540\",\"name\":\"Yunbo Wang\"},{\"authorId\":\"35776445\",\"name\":\"Mingsheng Long\"},{\"authorId\":\"1751179\",\"name\":\"J. Wang\"},{\"authorId\":\"144019071\",\"name\":\"Philip S. Yu\"}],\"doi\":\"10.1109/CVPR.2017.226\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f1f66207713871da193af24e19a5d8855bfe7f5a\",\"title\":\"Spatiotemporal Pyramid Network for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f1f66207713871da193af24e19a5d8855bfe7f5a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39974958\",\"name\":\"T. Yu\"},{\"authorId\":\"46181112\",\"name\":\"Chaoxu Guo\"},{\"authorId\":\"40585252\",\"name\":\"L. Wang\"},{\"authorId\":\"1683738\",\"name\":\"S. Xiang\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.1109/LSP.2018.2843295\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0f2ddd35090bf4220c97f0bf1d87f76121c15963\",\"title\":\"Self-Paced AutoEncoder\",\"url\":\"https://www.semanticscholar.org/paper/0f2ddd35090bf4220c97f0bf1d87f76121c15963\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1145/3122865\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8e87853672791ed5254a1cfc4b7582e7a41a89d6\",\"title\":\"Frontiers of Multimedia Research\",\"url\":\"https://www.semanticscholar.org/paper/8e87853672791ed5254a1cfc4b7582e7a41a89d6\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145634568\",\"name\":\"H. Hu\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"1926578\",\"name\":\"Joon-Young Lee\"},{\"authorId\":\"145527707\",\"name\":\"Zhe L. Lin\"},{\"authorId\":\"2272096\",\"name\":\"Guo-Jun Qi\"}],\"doi\":\"10.1109/CVPRW.2017.272\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dee6609615b73b10540f32537a242baa3c9fca4d\",\"title\":\"Temporal Domain Neural Encoder for Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/dee6609615b73b10540f32537a242baa3c9fca4d\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":\"10.1109/ICCVW.2019.00183\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"718418a88461c44a77bc4c0a1bdc9f3e6434fbab\",\"title\":\"Recurrent Convolutions for Causal 3D CNNs\",\"url\":\"https://www.semanticscholar.org/paper/718418a88461c44a77bc4c0a1bdc9f3e6434fbab\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1809.03669\",\"authors\":[{\"authorId\":\"3865974\",\"name\":\"Xiaolin Song\"},{\"authorId\":\"40093162\",\"name\":\"Cuiling Lan\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"},{\"authorId\":\"1757173\",\"name\":\"Junliang Xing\"},{\"authorId\":\"6485172\",\"name\":\"Xiaoyan Sun\"},{\"authorId\":\"40354745\",\"name\":\"J. Yang\"}],\"doi\":\"10.1109/TCSVT.2019.2896029\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"96f0da034d090a3ecadd0fb92333bb681f23ab14\",\"title\":\"Temporal\\u2013Spatial Mapping for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/96f0da034d090a3ecadd0fb92333bb681f23ab14\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2726914\",\"name\":\"Shuren Zhou\"},{\"authorId\":\"49435489\",\"name\":\"X. Zeng\"}],\"doi\":\"10.1007/978-981-15-8083-3_27\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5b40980a4a9cc4535e8578b22e09487ad2ca8206\",\"title\":\"Spatial-Temporal Co-attention Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5b40980a4a9cc4535e8578b22e09487ad2ca8206\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9908119\",\"name\":\"D. Maslov\"},{\"authorId\":\"143948848\",\"name\":\"I. Makarov\"}],\"doi\":\"10.7717/peerj-cs.317\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"660478daa40a4b7890a22d410a0d34806ec33071\",\"title\":\"Online supervised attention-based recurrent depth estimation from monocular video\",\"url\":\"https://www.semanticscholar.org/paper/660478daa40a4b7890a22d410a0d34806ec33071\",\"venue\":\"PeerJ Comput. Sci.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9764377\",\"name\":\"Xuanhan Wang\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"6820648\",\"name\":\"Xianglong Liu\"}],\"doi\":\"10.1109/TMM.2017.2749159\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"93ce62fb04283efb253b512dc3f02b1d169ee7ed\",\"title\":\"Two-Stream 3-D convNet Fusion for Action Recognition in Videos With Arbitrary Size and Length\",\"url\":\"https://www.semanticscholar.org/paper/93ce62fb04283efb253b512dc3f02b1d169ee7ed\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2704179\",\"name\":\"Dongang Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ffab858d6ecb12dad89ccab4cce6c856ba28fe21\",\"title\":\"Action Recognition in Multi-view Videos\",\"url\":\"https://www.semanticscholar.org/paper/ffab858d6ecb12dad89ccab4cce6c856ba28fe21\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26149670\",\"name\":\"Nhu-Tai Do\"},{\"authorId\":\"2355626\",\"name\":\"Soohyung Kim\"},{\"authorId\":\"153453009\",\"name\":\"HyungJeong Yang\"},{\"authorId\":\"144096222\",\"name\":\"G. Lee\"}],\"doi\":\"10.3390/app10186293\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b4fd4126707d1965d381193190949dbcb4c9973d\",\"title\":\"Robust Hand Shape Features for Dynamic Hand Gesture Recognition Using Multi-Level Feature LSTM\",\"url\":\"https://www.semanticscholar.org/paper/b4fd4126707d1965d381193190949dbcb4c9973d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3450479\",\"name\":\"Y. Zhao\"},{\"authorId\":\"1738364\",\"name\":\"Bing Deng\"},{\"authorId\":\"144600664\",\"name\":\"Chen Shen\"},{\"authorId\":\"2354748\",\"name\":\"Yau-Wen Liu\"},{\"authorId\":\"37514286\",\"name\":\"H. Lu\"},{\"authorId\":\"143863244\",\"name\":\"Xian-Sheng Hua\"}],\"doi\":\"10.1145/3123266.3123451\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fef6f1e04fa64f2f26ac9f01cd143dd19e549790\",\"title\":\"Spatio-Temporal AutoEncoder for Video Anomaly Detection\",\"url\":\"https://www.semanticscholar.org/paper/fef6f1e04fa64f2f26ac9f01cd143dd19e549790\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":\"1806.07110\",\"authors\":[{\"authorId\":\"10364164\",\"name\":\"Nerea Centeno Garc\\u00eda\"},{\"authorId\":\"2322579\",\"name\":\"Pietro Morerio\"},{\"authorId\":\"1727204\",\"name\":\"Vittorio Murino\"}],\"doi\":\"10.1007/978-3-030-01237-3_7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4f472fb027775554187fa3688a95aff9c3c5d977\",\"title\":\"Modality Distillation with Multiple Stream Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4f472fb027775554187fa3688a95aff9c3c5d977\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"144478646\",\"name\":\"Z. Guo\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"47158869\",\"name\":\"Xing Xu\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1109/TMM.2017.2729019\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"51b2c1e750b1d3b893072829d012f2352d6bd373\",\"title\":\"Video Captioning With Attention-Based LSTM and Semantic Consistency\",\"url\":\"https://www.semanticscholar.org/paper/51b2c1e750b1d3b893072829d012f2352d6bd373\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152325076\",\"name\":\"H. Ge\"},{\"authorId\":\"79403975\",\"name\":\"Zehang Yan\"},{\"authorId\":null,\"name\":\"Wenhao Yu\"},{\"authorId\":\"144526347\",\"name\":\"L. Sun\"}],\"doi\":\"10.1007/s11042-019-7404-z\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"9804bbb0724c333e9b900d849e492db00b20dbde\",\"title\":\"An attention mechanism based convolutional LSTM network for video action recognition\",\"url\":\"https://www.semanticscholar.org/paper/9804bbb0724c333e9b900d849e492db00b20dbde\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144708945\",\"name\":\"Yang Du\"},{\"authorId\":null,\"name\":\"Chunfeng Yuan\"},{\"authorId\":null,\"name\":\"Bing Li\"},{\"authorId\":\"40506509\",\"name\":\"W. Hu\"},{\"authorId\":\"40566477\",\"name\":\"H. Yang\"},{\"authorId\":\"2937291\",\"name\":\"Zhikang Fu\"},{\"authorId\":\"48096213\",\"name\":\"L. Zhao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"290b8a2fb39043d98cad6bb97595f7d79e394ba4\",\"title\":\"Hierarchical Nonlinear Orthogonal Adaptive-Subspace Self-Organizing Map Based Feature Extraction for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/290b8a2fb39043d98cad6bb97595f7d79e394ba4\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1602.02995\",\"authors\":[{\"authorId\":\"98658818\",\"name\":\"C. Lea\"},{\"authorId\":\"3207112\",\"name\":\"A. Reiter\"},{\"authorId\":\"144020730\",\"name\":\"R. Vidal\"},{\"authorId\":\"1678633\",\"name\":\"Gregory Hager\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0258749b418db624de697ea934b4f1425c961066\",\"title\":\"Segmental Spatio-Temporal CNNs for Fine-grained Action Segmentation and Classification\",\"url\":\"https://www.semanticscholar.org/paper/0258749b418db624de697ea934b4f1425c961066\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2340579\",\"name\":\"J. Ng\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/WACV.2018.00176\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6c1227659878e867a01888eef472dd96b679adb6\",\"title\":\"Temporal Difference Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6c1227659878e867a01888eef472dd96b679adb6\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Wei Zhang\"},{\"authorId\":\"3432527\",\"name\":\"Jiepeng Cen\"},{\"authorId\":\"39458374\",\"name\":\"H. Zheng\"}],\"doi\":\"10.1109/ICPR.2018.8545720\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e39db6a72f533b5adb2ecd9feaadbbab8204e024\",\"title\":\"Temporal Inception Architecture for Action Recognition with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/e39db6a72f533b5adb2ecd9feaadbbab8204e024\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2380070\",\"name\":\"Noor Almaadeed\"},{\"authorId\":\"3436875\",\"name\":\"Omar ElHarrouss\"},{\"authorId\":\"1406702495\",\"name\":\"S. Al-M\\u00e1adeed\"},{\"authorId\":\"1690116\",\"name\":\"A. Bouridane\"},{\"authorId\":\"1731553\",\"name\":\"Azeddine Beghdadi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1e088de792b60b1bfeb639a7f810b833b89c29d4\",\"title\":\"A Novel Approach for Robust Multi Human Action Detection and Recognition based on 3-Dimentional Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/1e088de792b60b1bfeb639a7f810b833b89c29d4\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66786330\",\"name\":\"Palak Girdhar\"},{\"authorId\":\"66786330\",\"name\":\"Palak Girdhar\"},{\"authorId\":\"47497940\",\"name\":\"Prashant Johri\"},{\"authorId\":\"1782083\",\"name\":\"Deepali Virmani\"}],\"doi\":\"10.1080/09720529.2020.1804132\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f1631ec6669e5f50170d9392fc1f5c0c7c08e912\",\"title\":\"Incept_LSTM : Accession for human activity concession in automatic surveillance\",\"url\":\"https://www.semanticscholar.org/paper/f1631ec6669e5f50170d9392fc1f5c0c7c08e912\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1901.09244\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":\"10.1109/ICCV.2019.00094\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8c05c3ec1cf5ca7865cd0e73dd688e94537d5f1a\",\"title\":\"DistInit: Learning Video Representations Without a Single Labeled Video\",\"url\":\"https://www.semanticscholar.org/paper/8c05c3ec1cf5ca7865cd0e73dd688e94537d5f1a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2023281907\",\"name\":\"Alberto Calo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"585dcd9a7332583044a77d9489338ab8eaba0fc8\",\"title\":\"Deep neural networks for detection of solar corona mass ejections\",\"url\":\"https://www.semanticscholar.org/paper/585dcd9a7332583044a77d9489338ab8eaba0fc8\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144406781\",\"name\":\"Lijun He\"},{\"authorId\":\"2035803194\",\"name\":\"Shuai Wen\"},{\"authorId\":\"2199437\",\"name\":\"L. Wang\"},{\"authorId\":\"1825677658\",\"name\":\"Fan Li\"}],\"doi\":\"10.1007/s10489-020-01933-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb68cda0fdd2e9fec857ff8016b3a74912ceb57e\",\"title\":\"Vehicle theft recognition from surveillance video based on spatiotemporal attention\",\"url\":\"https://www.semanticscholar.org/paper/eb68cda0fdd2e9fec857ff8016b3a74912ceb57e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1500392780\",\"name\":\"Allan Wang\"},{\"authorId\":\"1792714\",\"name\":\"A. Steinfeld\"}],\"doi\":\"10.1109/LRA.2020.2969947\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aa6aa461b087dafc59b3041707d9770a8f0e9496\",\"title\":\"Group Split and Merge Prediction With 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/aa6aa461b087dafc59b3041707d9770a8f0e9496\",\"venue\":\"IEEE Robotics and Automation Letters\",\"year\":2020},{\"arxivId\":\"1611.09502\",\"authors\":[{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2017.435\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ab4c97575b17b9ce9b7523743ce7cae4fa9572e5\",\"title\":\"Deep Quantization: Encoding Convolutional Activations with Deep Generative Model\",\"url\":\"https://www.semanticscholar.org/paper/ab4c97575b17b9ce9b7523743ce7cae4fa9572e5\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144444772\",\"name\":\"S. J. Berlin\"},{\"authorId\":\"34799829\",\"name\":\"M. John\"}],\"doi\":\"10.1007/s11042-020-08704-0\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a093bb0526c3e21469be8be537bbbf01198d0616\",\"title\":\"Particle swarm optimization with deep learning for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/a093bb0526c3e21469be8be537bbbf01198d0616\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3429960\",\"name\":\"Youjiang Xu\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"2248826\",\"name\":\"R. Hong\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/TIP.2018.2846664\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7fe2ab9f54242ef8609ef9bf988f008c7d42407c\",\"title\":\"Sequential Video VLAD: Training the Aggregation Locally and Temporally\",\"url\":\"https://www.semanticscholar.org/paper/7fe2ab9f54242ef8609ef9bf988f008c7d42407c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3233968\",\"name\":\"Mahsa Ghafarianzadeh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"53f4c27cc50001c56b9be1fb3f8023f40db95466\",\"title\":\"Towards Temporal Semantic Scene Understanding\",\"url\":\"https://www.semanticscholar.org/paper/53f4c27cc50001c56b9be1fb3f8023f40db95466\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24289349\",\"name\":\"Didik Purwanto\"},{\"authorId\":\"47558808\",\"name\":\"Y. Chen\"},{\"authorId\":\"9319953\",\"name\":\"W. Fang\"}],\"doi\":\"10.1109/TMM.2019.2919434\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b0c6a1c99280b862ad42712682d15317e717f789\",\"title\":\"First-Person Action Recognition With Temporal Pooling and Hilbert\\u2013Huang Transform\",\"url\":\"https://www.semanticscholar.org/paper/b0c6a1c99280b862ad42712682d15317e717f789\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49681148\",\"name\":\"L. Wang\"},{\"authorId\":\"3034546\",\"name\":\"Lianzheng Ge\"},{\"authorId\":\"39975036\",\"name\":\"R. Li\"},{\"authorId\":\"40630660\",\"name\":\"Y. Fang\"}],\"doi\":\"10.1016/j.patrec.2017.04.004\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e378d5258615b542484fb519f2ca28b0ab1f1394\",\"title\":\"Three-stream CNNs for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/e378d5258615b542484fb519f2ca28b0ab1f1394\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48397283\",\"name\":\"Ruiqi Wang\"},{\"authorId\":\"2125709\",\"name\":\"Xinxiao Wu\"}],\"doi\":\"10.1007/S11042-018-6509-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c44ce50b8d369b6ee49c540ff1a74992b1358664\",\"title\":\"Combining multiple deep cues for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/c44ce50b8d369b6ee49c540ff1a74992b1358664\",\"venue\":\"Multim. Tools Appl.\",\"year\":2019},{\"arxivId\":\"2005.10033\",\"authors\":[{\"authorId\":\"38212285\",\"name\":\"N. Gessert\"},{\"authorId\":\"123390466\",\"name\":\"M. Bengs\"},{\"authorId\":\"9540121\",\"name\":\"M. Schl\\u00fcter\"},{\"authorId\":\"3236423\",\"name\":\"A. Schlaefer\"}],\"doi\":\"10.1016/j.media.2020.101730\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9c81029be43318d5dc6b8e0eeae5d66d091eb22c\",\"title\":\"Deep learning with 4D spatio-temporal data representations for OCT-based force estimation\",\"url\":\"https://www.semanticscholar.org/paper/9c81029be43318d5dc6b8e0eeae5d66d091eb22c\",\"venue\":\"Medical Image Anal.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123390466\",\"name\":\"M. Bengs\"},{\"authorId\":\"38212285\",\"name\":\"N. Gessert\"},{\"authorId\":\"3236423\",\"name\":\"A. Schlaefer\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f0186fee56f9f24277b42c03b263db45245b0cdc\",\"title\":\"Current Directions in Biomedical Engineering\",\"url\":\"https://www.semanticscholar.org/paper/f0186fee56f9f24277b42c03b263db45245b0cdc\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2004.01398\",\"authors\":[{\"authorId\":\"48513712\",\"name\":\"Y. Li\"},{\"authorId\":\"102880425\",\"name\":\"Bin Ji\"},{\"authorId\":\"48203223\",\"name\":\"Xintian Shi\"},{\"authorId\":\"98697812\",\"name\":\"J. Zhang\"},{\"authorId\":\"48418655\",\"name\":\"Bin Kang\"},{\"authorId\":\"48170350\",\"name\":\"Limin Wang\"}],\"doi\":\"10.1109/cvpr42600.2020.00099\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1ebeb84e2b8e1182a2b4821c906200ecc49ae187\",\"title\":\"TEA: Temporal Excitation and Aggregation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1ebeb84e2b8e1182a2b4821c906200ecc49ae187\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1911.10751\",\"authors\":[{\"authorId\":\"46399266\",\"name\":\"Yang Liu\"},{\"authorId\":\"46950892\",\"name\":\"Zhao-yang Lu\"},{\"authorId\":\"46276828\",\"name\":\"J. Li\"},{\"authorId\":\"144954285\",\"name\":\"T. Yang\"},{\"authorId\":\"144299910\",\"name\":\"C. Yao\"}],\"doi\":\"10.1109/TIP.2019.2957930\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7cfd5817802102b0326243c95ebfe1c8e14427cd\",\"title\":\"Deep Image-to-Video Adaptation and Fusion Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7cfd5817802102b0326243c95ebfe1c8e14427cd\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9071789\",\"name\":\"Z. Liu\"},{\"authorId\":\"46659696\",\"name\":\"L. Wang\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"2687716\",\"name\":\"Zhanning Gao\"},{\"authorId\":\"1786361\",\"name\":\"Zhenxing Niu\"},{\"authorId\":\"1715389\",\"name\":\"Nanning Zheng\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\"}],\"doi\":\"10.1109/ICCV.2019.00400\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"87ecaaf627d441e5f42465a237a3e3a2c10da5d1\",\"title\":\"Weakly Supervised Temporal Action Localization Through Contrast Based Evaluation Networks\",\"url\":\"https://www.semanticscholar.org/paper/87ecaaf627d441e5f42465a237a3e3a2c10da5d1\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1930831020\",\"name\":\"Lorxayxang Kai\"},{\"authorId\":\"50741340\",\"name\":\"Yang Wu\"},{\"authorId\":\"3017565\",\"name\":\"Xiaodong Dai\"},{\"authorId\":\"81498564\",\"name\":\"M. Ma\"}],\"doi\":\"10.1007/978-3-030-57884-8_71\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7d0b571dcf3897a722309a2dd2974a5475cc70a9\",\"title\":\"Fast Video Classification with CNNs in Compressed Domain\",\"url\":\"https://www.semanticscholar.org/paper/7d0b571dcf3897a722309a2dd2974a5475cc70a9\",\"venue\":\"ICAIS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4322411\",\"name\":\"L. Li\"},{\"authorId\":\"33126875\",\"name\":\"Shuling Dai\"}],\"doi\":\"10.1109/ICVRV.2016.12\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"97fcf8d28d1728fd4c29b441058da2412fcf7eea\",\"title\":\"Action Recognition Based on Local Fisher Discriminant Analysis and Mix Encoding\",\"url\":\"https://www.semanticscholar.org/paper/97fcf8d28d1728fd4c29b441058da2412fcf7eea\",\"venue\":\"2016 International Conference on Virtual Reality and Visualization (ICVRV)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403243307\",\"name\":\"Maryam Asadi-Aghbolaghi\"},{\"authorId\":\"7840884\",\"name\":\"A. Clap\\u00e9s\"},{\"authorId\":\"9762642\",\"name\":\"Marco Bellantonio\"},{\"authorId\":\"1742688\",\"name\":\"H. Escalante\"},{\"authorId\":\"1402295723\",\"name\":\"V\\u00edctor Ponce-L\\u00f3pez\"},{\"authorId\":\"46176857\",\"name\":\"X. Bar\\u00f3\"},{\"authorId\":\"51243976\",\"name\":\"Isabelle Guyon\"},{\"authorId\":\"1411108625\",\"name\":\"Shohreh Kasaei\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"}],\"doi\":\"10.1007/978-3-319-57021-1_19\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"49961d6c2cc42276ff5c5af47687dd9b860bc578\",\"title\":\"Deep Learning for Action and Gesture Recognition in Image Sequences: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/49961d6c2cc42276ff5c5af47687dd9b860bc578\",\"venue\":\"Gesture Recognition\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36054719\",\"name\":\"A. Campilho\"},{\"authorId\":\"122498433\",\"name\":\"F. Karray\"},{\"authorId\":\"1491092225\",\"name\":\"Zhou Wang\"},{\"authorId\":\"1743774\",\"name\":\"E. Bertino\"}],\"doi\":\"10.1007/978-3-030-50347-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6ef4cc8126a312c5e4be1190e28238dc46f50aec\",\"title\":\"Image Analysis and Recognition: 17th International Conference, ICIAR 2020, P\\u00f3voa de Varzim, Portugal, June 24\\u201326, 2020, Proceedings, Part I\",\"url\":\"https://www.semanticscholar.org/paper/6ef4cc8126a312c5e4be1190e28238dc46f50aec\",\"venue\":\"ICIAR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2244863\",\"name\":\"X. Zhang\"},{\"authorId\":\"1715708\",\"name\":\"Yaping Huang\"},{\"authorId\":\"2035596033\",\"name\":\"Yang Mi\"},{\"authorId\":\"80996783\",\"name\":\"Yanting Pei\"},{\"authorId\":\"2196589\",\"name\":\"Qi Zou\"},{\"authorId\":\"40696794\",\"name\":\"Song Wang\"}],\"doi\":\"10.1007/s10489-020-01905-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ffd6d8c2f114895c3506b8326a0fdb6b8728e901\",\"title\":\"Video sketch: A middle-level representation for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/ffd6d8c2f114895c3506b8326a0fdb6b8728e901\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1608.04339\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"}],\"doi\":\"10.1007/978-3-319-46604-0_47\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9abd35b37a49ee1295e8197aac59bde802a934f3\",\"title\":\"Depth2Action: Exploring Embedded Depth for Large-Scale Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9abd35b37a49ee1295e8197aac59bde802a934f3\",\"venue\":\"ECCV Workshops\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2014277\",\"name\":\"G. Zhu\"},{\"authorId\":\"47059230\",\"name\":\"L. Zhang\"},{\"authorId\":\"46665820\",\"name\":\"Lin Mei\"},{\"authorId\":\"145496509\",\"name\":\"Jie Shao\"},{\"authorId\":\"40403682\",\"name\":\"J. Song\"},{\"authorId\":\"12166382\",\"name\":\"Peiyi Shen\"}],\"doi\":\"10.1109/ICPR.2016.7899601\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c1866a3671c9af4dcf6f0236e13a960851669ea6\",\"title\":\"Large-scale Isolated Gesture Recognition using pyramidal 3D convolutional networks\",\"url\":\"https://www.semanticscholar.org/paper/c1866a3671c9af4dcf6f0236e13a960851669ea6\",\"venue\":\"2016 23rd International Conference on Pattern Recognition (ICPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41021382\",\"name\":\"Jefferson Hernandez\"},{\"authorId\":\"3123974\",\"name\":\"A. Abad\"}],\"doi\":\"10.1007/978-3-030-03023-0_1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aaf4ee1e9651db4a1fa487188ce6f998c75a0a32\",\"title\":\"Spatial and Temporal Feature Extraction Using a Restricted Boltzmann Machine Model\",\"url\":\"https://www.semanticscholar.org/paper/aaf4ee1e9651db4a1fa487188ce6f998c75a0a32\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1470727828\",\"name\":\"Yongyang Xu\"},{\"authorId\":\"30411581\",\"name\":\"Y. Feng\"},{\"authorId\":\"145980916\",\"name\":\"Zhong Xie\"},{\"authorId\":\"1491410471\",\"name\":\"Mingyu Xie\"},{\"authorId\":\"102577932\",\"name\":\"W. Luo\"}],\"doi\":\"10.1109/ACCESS.2020.3022407\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b21c6a492e8330111ad19d9a708fb25a0c8eca7f\",\"title\":\"Action Recognition Using High Temporal Resolution 3D Neural Network Based on Dilated Convolution\",\"url\":\"https://www.semanticscholar.org/paper/b21c6a492e8330111ad19d9a708fb25a0c8eca7f\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8768514\",\"name\":\"G. M\\u00e1ttyus\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dffaa942bcc97852dd1a70f712fdc7e4839837fe\",\"title\":\"Joint Information Augmentation of Road Maps, Aerial Images and Ground Images\",\"url\":\"https://www.semanticscholar.org/paper/dffaa942bcc97852dd1a70f712fdc7e4839837fe\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153580352\",\"name\":\"Ionut Cosmin Duta\"},{\"authorId\":\"1796198\",\"name\":\"B. Ionescu\"},{\"authorId\":\"1712839\",\"name\":\"K. Aizawa\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":\"10.1145/3078971.3078988\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8aa1591bf8fcb44f2e9f2f10d1029720ccbb8832\",\"title\":\"Simple, Efficient and Effective Encodings of Local Deep Features for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8aa1591bf8fcb44f2e9f2f10d1029720ccbb8832\",\"venue\":\"ICMR\",\"year\":2017},{\"arxivId\":\"1711.11248\",\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"4439383\",\"name\":\"Jamie Ray\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/CVPR.2018.00675\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"89c3050522a0bb9820c32dc7444e003ef0d3e2e4\",\"title\":\"A Closer Look at Spatiotemporal Convolutions for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/89c3050522a0bb9820c32dc7444e003ef0d3e2e4\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1490672305\",\"name\":\"M. Suresha\"},{\"authorId\":\"98570196\",\"name\":\"S. Kuppa\"},{\"authorId\":\"1490675042\",\"name\":\"D. S. Raghukumar\"}],\"doi\":\"10.1007/s13735-019-00190-x\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ac8f926b205bba37df42bab279c397a5eca07445\",\"title\":\"A study on deep learning spatiotemporal models and feature extraction techniques for video understanding\",\"url\":\"https://www.semanticscholar.org/paper/ac8f926b205bba37df42bab279c397a5eca07445\",\"venue\":\"International Journal of Multimedia Information Retrieval\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39974958\",\"name\":\"T. Yu\"},{\"authorId\":\"46660013\",\"name\":\"L. Wang\"},{\"authorId\":\"49610443\",\"name\":\"Cheng Da\"},{\"authorId\":\"1909131\",\"name\":\"Huxiang Gu\"},{\"authorId\":\"1683738\",\"name\":\"S. Xiang\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.1109/TMM.2019.2907060\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"53dc8bbc0ccf39b916e0833edeef63fa09eea43c\",\"title\":\"Weakly Semantic Guided Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/53dc8bbc0ccf39b916e0833edeef63fa09eea43c\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19007484\",\"name\":\"Haoying Wu\"},{\"authorId\":\"21103123\",\"name\":\"Daimin Jiang\"},{\"authorId\":\"145990240\",\"name\":\"Hao Gao\"}],\"doi\":\"10.1109/IROS.2017.8205964\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"f346afa3b3915e3c730de1bbbbdae5681d9dec7e\",\"title\":\"Tactile motion recognition with convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/f346afa3b3915e3c730de1bbbbdae5681d9dec7e\",\"venue\":\"2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2017},{\"arxivId\":\"1811.07157\",\"authors\":[{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"247ee3e4519381a84fdfe655223c270c4ef1ad75\",\"title\":\"Recurrence to the Rescue: Towards Causal Spatiotemporal Representations\",\"url\":\"https://www.semanticscholar.org/paper/247ee3e4519381a84fdfe655223c270c4ef1ad75\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48072671\",\"name\":\"Dongfeng Gu\"}],\"doi\":\"10.20381/RUOR-21013\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"98a81baa53847a397d7948b9ecfcb72f67691518\",\"title\":\"3D Densely Connected Convolutional Network for the Recognition of Human Shopping Actions\",\"url\":\"https://www.semanticscholar.org/paper/98a81baa53847a397d7948b9ecfcb72f67691518\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2145942\",\"name\":\"Allah Bux Sargano\"},{\"authorId\":\"1719855\",\"name\":\"P. Angelov\"},{\"authorId\":\"2708950\",\"name\":\"Z. Habib\"}],\"doi\":\"10.3390/APP7010110\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"a87e37d43d4c47bef8992ace408de0f872739efc\",\"title\":\"A Comprehensive Review on Handcrafted and Learning-Based Action Representation Approaches for Human Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a87e37d43d4c47bef8992ace408de0f872739efc\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2983562\",\"name\":\"Huafeng Chen\"},{\"authorId\":\"47740566\",\"name\":\"J. Chen\"},{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"144328091\",\"name\":\"R. Hu\"}],\"doi\":\"10.1109/ICIP.2017.8296441\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c0f67e850176bb778b6c048d81c3d7e4d8c41003\",\"title\":\"Action recognition with gradient boundary convolutional network\",\"url\":\"https://www.semanticscholar.org/paper/c0f67e850176bb778b6c048d81c3d7e4d8c41003\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":\"1904.05582\",\"authors\":[{\"authorId\":\"50986865\",\"name\":\"A. Nicolicioiu\"},{\"authorId\":\"51011850\",\"name\":\"Iulia Duta\"},{\"authorId\":\"1749627\",\"name\":\"M. Leordeanu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"56d7309ae0fccc0de5b09c3d426e09287498e4c3\",\"title\":\"Recurrent Space-time Graph Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/56d7309ae0fccc0de5b09c3d426e09287498e4c3\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1711.04161\",\"authors\":[{\"authorId\":\"1696573\",\"name\":\"Jiagang Zhu\"},{\"authorId\":\"9276071\",\"name\":\"Wei Zou\"},{\"authorId\":\"40031201\",\"name\":\"Z. Zhu\"},{\"authorId\":\"12791587\",\"name\":\"Lin Li\"}],\"doi\":\"10.1109/ICPR.2018.8545710\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"8c501a89092252a9f62f76a6f439916efe626251\",\"title\":\"End-to-end Video-level Representation Learning for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8c501a89092252a9f62f76a6f439916efe626251\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":\"1611.05216\",\"authors\":[{\"authorId\":\"38179026\",\"name\":\"Y. Shi\"},{\"authorId\":\"40161651\",\"name\":\"Yonghong Tian\"},{\"authorId\":\"5765799\",\"name\":\"Yaowei Wang\"},{\"authorId\":\"144424248\",\"name\":\"Wei Zeng\"},{\"authorId\":\"34097174\",\"name\":\"Tiejun Huang\"}],\"doi\":\"10.1109/ICCV.2017.84\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d145edb79ec035d6cf3f50714429f51fb18f0a2f\",\"title\":\"Learning Long-Term Dependencies for Action Recognition with a Biologically-Inspired Deep Network\",\"url\":\"https://www.semanticscholar.org/paper/d145edb79ec035d6cf3f50714429f51fb18f0a2f\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4697712\",\"name\":\"Z. Zhu\"},{\"authorId\":\"1696842\",\"name\":\"Hongbing Ji\"},{\"authorId\":\"1786198\",\"name\":\"W. Zhang\"},{\"authorId\":\"1757932\",\"name\":\"Yiping Xu\"}],\"doi\":\"10.1016/j.neucom.2018.08.018\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d92ff82c1b78cfbf2b9c8f65768ad9e4e3d1f47c\",\"title\":\"Rank pooling dynamic network: Learning end-to-end dynamic characteristic for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/d92ff82c1b78cfbf2b9c8f65768ad9e4e3d1f47c\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2720733\",\"name\":\"Wangli Hao\"},{\"authorId\":\"145274329\",\"name\":\"Zhaoxiang Zhang\"}],\"doi\":\"10.1016/J.PATCOG.2019.03.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"04d27bbbc875bd8fe52521112841d47b21950e7c\",\"title\":\"Spatiotemporal distilled dense-connectivity network for video action recognition\",\"url\":\"https://www.semanticscholar.org/paper/04d27bbbc875bd8fe52521112841d47b21950e7c\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":\"1912.00998\",\"authors\":[{\"authorId\":\"100880679\",\"name\":\"Chao-Yuan Wu\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"51506875\",\"name\":\"Philipp Krahenbuhl\"}],\"doi\":\"10.1109/cvpr42600.2020.00023\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b8cc28e11900e4d191651ae7234b4dbd129b1007\",\"title\":\"A Multigrid Method for Efficiently Training Video Models\",\"url\":\"https://www.semanticscholar.org/paper/b8cc28e11900e4d191651ae7234b4dbd129b1007\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35429704\",\"name\":\"D. Zhang\"},{\"authorId\":\"51473137\",\"name\":\"Jose Badilla\"},{\"authorId\":\"46867966\",\"name\":\"Y. Zhang\"},{\"authorId\":\"49370921\",\"name\":\"D. Wang\"}],\"doi\":\"10.1109/ASONAM.2018.8508655\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5dfa5561e5948a153150a97663891eb57b48a915\",\"title\":\"Towards Reliable Missing Truth Discovery in Online Social Media Sensing Applications\",\"url\":\"https://www.semanticscholar.org/paper/5dfa5561e5948a153150a97663891eb57b48a915\",\"venue\":\"2018 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9649314\",\"name\":\"Sheeraz Arif\"},{\"authorId\":\"49605422\",\"name\":\"Jing Wang\"},{\"authorId\":\"4869835\",\"name\":\"T. Hassan\"},{\"authorId\":\"144506604\",\"name\":\"Z. Fei\"}],\"doi\":\"10.3390/fi11020042\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"74aafcf3d7ddfdc0d099269e2335b64bc83f7f2b\",\"title\":\"3D-CNN-Based Fused Feature Maps with LSTM Applied to Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/74aafcf3d7ddfdc0d099269e2335b64bc83f7f2b\",\"venue\":\"Future Internet\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1488671202\",\"name\":\"Amany Abdelbaky\"},{\"authorId\":\"1704207\",\"name\":\"Saleh Aly\"}],\"doi\":\"10.1007/s00521-020-04712-1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eab4b49b6f9dbf0f633874136569d3b8123bd029\",\"title\":\"Human action recognition using short-time motion energy template images and PCANet features\",\"url\":\"https://www.semanticscholar.org/paper/eab4b49b6f9dbf0f633874136569d3b8123bd029\",\"venue\":\"Neural Computing and Applications\",\"year\":2020},{\"arxivId\":\"1706.00893\",\"authors\":[{\"authorId\":\"10386960\",\"name\":\"Nazanin Mehrasa\"},{\"authorId\":\"19198359\",\"name\":\"Yatao Zhong\"},{\"authorId\":\"2123865\",\"name\":\"Frederick Tung\"},{\"authorId\":\"3004771\",\"name\":\"Luke Bornn\"},{\"authorId\":\"10771328\",\"name\":\"Greg Mori\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5141cf2e59fb2ec9bb489b9c1832447d3cd93110\",\"title\":\"Learning Person Trajectory Representations for Team Activity Analysis\",\"url\":\"https://www.semanticscholar.org/paper/5141cf2e59fb2ec9bb489b9c1832447d3cd93110\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2642847\",\"name\":\"Yongbin Gao\"},{\"authorId\":\"79890978\",\"name\":\"Xuehao Xiang\"},{\"authorId\":\"145826495\",\"name\":\"N. Xiong\"},{\"authorId\":\"144230953\",\"name\":\"Bo Huang\"},{\"authorId\":\"4292934\",\"name\":\"H. J. Lee\"},{\"authorId\":\"52240872\",\"name\":\"Rad Alrifai\"},{\"authorId\":\"48324819\",\"name\":\"Xiaoyan Jiang\"},{\"authorId\":\"35301080\",\"name\":\"Zhijun Fang\"}],\"doi\":\"10.1109/ACCESS.2018.2869790\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"11c67d6fedc3dd95b752ade4e46ee143ac494259\",\"title\":\"Human Action Monitoring for Healthcare Based on Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/11c67d6fedc3dd95b752ade4e46ee143ac494259\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46698300\",\"name\":\"Ji Lin\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"143840277\",\"name\":\"Song Han\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5925a25dfe107c49c636eccb8f9fd1aeef7b438c\",\"title\":\"Temporal Shift Module for Efficient Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/5925a25dfe107c49c636eccb8f9fd1aeef7b438c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46329495\",\"name\":\"Amin Ullah\"},{\"authorId\":\"143997136\",\"name\":\"Khan Muhammad\"},{\"authorId\":\"134151536\",\"name\":\"J. Del Ser\"},{\"authorId\":\"1777998\",\"name\":\"S. Baik\"},{\"authorId\":\"51905607\",\"name\":\"V. H. C. de Albuquerque\"}],\"doi\":\"10.1109/TIE.2018.2881943\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"67683171c2000e5194e50996802d39c72000b5e6\",\"title\":\"Activity Recognition Using Temporal Optical Flow Convolutional Features and Multilayer LSTM\",\"url\":\"https://www.semanticscholar.org/paper/67683171c2000e5194e50996802d39c72000b5e6\",\"venue\":\"IEEE Transactions on Industrial Electronics\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3193566\",\"name\":\"Yongbo Bo\"},{\"authorId\":\"19244094\",\"name\":\"Yangdi Lu\"},{\"authorId\":\"145850224\",\"name\":\"Wenbo He\"}],\"doi\":\"10.1109/WACV45572.2020.9093481\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5ced7f13f2c616f770c126eba68626a4830205de\",\"title\":\"Few-Shot Learning of Video Action Recognition Only Based on Video Contents\",\"url\":\"https://www.semanticscholar.org/paper/5ced7f13f2c616f770c126eba68626a4830205de\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1903.10869\",\"authors\":[{\"authorId\":\"145062693\",\"name\":\"Anh Nguyen\"},{\"authorId\":\"3354627\",\"name\":\"Thanh-Toan Do\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"},{\"authorId\":\"1745158\",\"name\":\"D. Caldwell\"},{\"authorId\":\"145887349\",\"name\":\"N. Tsagarakis\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fda87f56010b1e8d05a52a166fdb2750b4dec39b\",\"title\":\"V2CNet: A Deep Learning Framework to Translate Videos to Commands for Robotic Manipulation\",\"url\":\"https://www.semanticscholar.org/paper/fda87f56010b1e8d05a52a166fdb2750b4dec39b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1607.04730\",\"authors\":[{\"authorId\":\"34847250\",\"name\":\"\\u00c7agdas Bak\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dac2e8365df576e6d3f16b01d48e0d5e4156b81f\",\"title\":\"Two-Stream Convolutional Networks for Dynamic Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/dac2e8365df576e6d3f16b01d48e0d5e4156b81f\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3794315\",\"name\":\"Yutong Cai\"},{\"authorId\":\"8131625\",\"name\":\"W. Lin\"},{\"authorId\":\"143937986\",\"name\":\"John See\"},{\"authorId\":\"37535930\",\"name\":\"Ming-Ming Cheng\"},{\"authorId\":\"1990768\",\"name\":\"Guangcan Liu\"},{\"authorId\":\"144045763\",\"name\":\"Hongkai Xiong\"}],\"doi\":\"10.1109/VCIP.2018.8698676\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e51635fe9554db3b10a262cc113c237ffcb759bf\",\"title\":\"Multi-scale Spatiotemporal Information Fusion Network for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e51635fe9554db3b10a262cc113c237ffcb759bf\",\"venue\":\"2018 IEEE Visual Communications and Image Processing (VCIP)\",\"year\":2018},{\"arxivId\":\"1711.03273\",\"authors\":[{\"authorId\":\"143753918\",\"name\":\"Y. Peng\"},{\"authorId\":\"3361463\",\"name\":\"Yunzhen Zhao\"},{\"authorId\":\"3239379\",\"name\":\"J. Zhang\"}],\"doi\":\"10.1109/TCSVT.2018.2808685\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d9bd1b670b1301b9f4d8c366479173fc7903a331\",\"title\":\"Two-Stream Collaborative Learning With Spatial-Temporal Attention for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/d9bd1b670b1301b9f4d8c366479173fc7903a331\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143611428\",\"name\":\"Z. Tu\"},{\"authorId\":\"144561919\",\"name\":\"W. Xie\"},{\"authorId\":\"39952920\",\"name\":\"Q. Qin\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"},{\"authorId\":\"1739867\",\"name\":\"R. Veltkamp\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1016/j.patcog.2018.01.020\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"baa733992a236258adf36a41413b96707c8e9f4c\",\"title\":\"Multi-stream CNN: Learning representations based on human-related regions for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/baa733992a236258adf36a41413b96707c8e9f4c\",\"venue\":\"Pattern Recognit.\",\"year\":2018},{\"arxivId\":\"1812.10222\",\"authors\":[{\"authorId\":\"16340457\",\"name\":\"L. Wu\"},{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"},{\"authorId\":\"39872583\",\"name\":\"M. Wang\"}],\"doi\":\"10.1109/TNNLS.2019.2891244\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"19992d925606520af56ea1b5d2ee7c3ff33e4dde\",\"title\":\"3-D PersonVLAD: Learning Deep Global Representations for Video-Based Person Reidentification\",\"url\":\"https://www.semanticscholar.org/paper/19992d925606520af56ea1b5d2ee7c3ff33e4dde\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2019},{\"arxivId\":\"2007.12887\",\"authors\":[{\"authorId\":\"26415158\",\"name\":\"Xinqi Zhu\"},{\"authorId\":\"153250308\",\"name\":\"C. Xu\"},{\"authorId\":\"102853050\",\"name\":\"L. Hui\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/ICCV.2019.00359\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7303ce1fe8f54f45e4558eb81368bda9dfe2793f\",\"title\":\"Approximated Bilinear Modules for Temporal Modeling\",\"url\":\"https://www.semanticscholar.org/paper/7303ce1fe8f54f45e4558eb81368bda9dfe2793f\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1904.11451\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"145878079\",\"name\":\"Vivek Sharma\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"1576263143\",\"name\":\"Jurgen Gall\"},{\"authorId\":\"49157259\",\"name\":\"R. Stiefelhagen\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-030-58558-7_35\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c2fe9e87e31e6fdb2b7bae5f9cc3c2d2612d13a\",\"title\":\"Large Scale Holistic Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/1c2fe9e87e31e6fdb2b7bae5f9cc3c2d2612d13a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1810.08437\",\"authors\":[{\"authorId\":\"145223169\",\"name\":\"N. C. Garcia\"},{\"authorId\":\"2322579\",\"name\":\"Pietro Morerio\"},{\"authorId\":\"1727204\",\"name\":\"Vittorio Murino\"}],\"doi\":\"10.1109/TPAMI.2019.2929038\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"67d0a881e0c580acc7770c212396171cc64aa76c\",\"title\":\"Learning with Privileged Information via Adversarial Discriminative Modality Distillation\",\"url\":\"https://www.semanticscholar.org/paper/67d0a881e0c580acc7770c212396171cc64aa76c\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2129212\",\"name\":\"M. Leong\"},{\"authorId\":\"145052848\",\"name\":\"D. Prasad\"},{\"authorId\":\"2277707\",\"name\":\"Y. T. Lee\"},{\"authorId\":\"72659791\",\"name\":\"F. Lin\"}],\"doi\":\"10.20944/preprints201912.0086.v1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"29248ee8f8c7032e6d122390f02973a3e76ac6e4\",\"title\":\"Semi-CNN Architecture for Effective Spatio- Temporal Learning in Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/29248ee8f8c7032e6d122390f02973a3e76ac6e4\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2708397\",\"name\":\"C. Xu\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"114945277\",\"name\":\"B. Zhang\"},{\"authorId\":\"13556061\",\"name\":\"Z. Chen\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"}],\"doi\":\"10.1109/TCSVT.2019.2927118\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cfcfe036b2026fbe8761888e43858c61a418331f\",\"title\":\"Learning to Score Figure Skating Sport Videos\",\"url\":\"https://www.semanticscholar.org/paper/cfcfe036b2026fbe8761888e43858c61a418331f\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49455479\",\"name\":\"Y. Zhou\"},{\"authorId\":\"6485172\",\"name\":\"Xiaoyan Sun\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"}],\"doi\":\"10.1109/CVPR.2018.00054\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b85b79d0535da7e994e419a75f65b2758bf90f21\",\"title\":\"MiCT: Mixed 3D/2D Convolutional Tube for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b85b79d0535da7e994e419a75f65b2758bf90f21\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145161471\",\"name\":\"Y. Yoon\"},{\"authorId\":\"2199479\",\"name\":\"Jongmin Yu\"},{\"authorId\":\"2184044\",\"name\":\"Moongu Jeon\"}],\"doi\":\"10.1109/ACCESS.2019.2953455\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"345a2fa96bb50c7986cd39875ac9d55b7f2c7769\",\"title\":\"Spatio-Temporal Representation Matching-Based Open-Set Action Recognition by Joint Learning of Motion and Appearance\",\"url\":\"https://www.semanticscholar.org/paper/345a2fa96bb50c7986cd39875ac9d55b7f2c7769\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144593762\",\"name\":\"Rong Chen\"},{\"authorId\":\"7877133\",\"name\":\"Yuanlong Yu\"},{\"authorId\":\"48783214\",\"name\":\"Z. Huang\"}],\"doi\":\"10.1109/CYBER.2018.8688320\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6f4398943041b00ff4f1f8ed9e0c52477a905ffe\",\"title\":\"Event Recognition Based on 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/6f4398943041b00ff4f1f8ed9e0c52477a905ffe\",\"venue\":\"2018 IEEE 8th Annual International Conference on CYBER Technology in Automation, Control, and Intelligent Systems (CYBER)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699601289\",\"name\":\"A. Prabakaran\"},{\"authorId\":\"1699601298\",\"name\":\"Mallikarjuna Rao Voleti\"},{\"authorId\":\"1699601084\",\"name\":\"Lakshya\"},{\"authorId\":\"1699601302\",\"name\":\"Prathmesh Shirish Manurkar\"}],\"doi\":\"10.1109/ICInPro47689.2019.9092161\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"087f500cfc0f4b0aacf1728e9d81c8b96695242c\",\"title\":\"A Multi-Input Neural Network with Dense Flow and Spatio-Temporal Features for Anomaly Detection\",\"url\":\"https://www.semanticscholar.org/paper/087f500cfc0f4b0aacf1728e9d81c8b96695242c\",\"venue\":\"2019 Fifteenth International Conference on Information Processing (ICINPRO)\",\"year\":2019},{\"arxivId\":\"1909.13130\",\"authors\":[{\"authorId\":\"153918891\",\"name\":\"Chenxu Luo\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.1109/ICCV.2019.00561\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"8b8fe4727c8094b17e61886e69a602f8d0403091\",\"title\":\"Grouped Spatial-Temporal Aggregation for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b8fe4727c8094b17e61886e69a602f8d0403091\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37595110\",\"name\":\"J. Huang\"},{\"authorId\":\"1415000647\",\"name\":\"Colin Samplawski\"},{\"authorId\":\"1742299\",\"name\":\"D. Ganesan\"},{\"authorId\":\"32671580\",\"name\":\"Benjamin Marlin\"},{\"authorId\":\"113427453\",\"name\":\"Heesung Kwon\"}],\"doi\":\"10.1145/3372224.3419215\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a5f6082c5fd84350f898d3d891510ff09e43f051\",\"title\":\"CLIO: enabling automatic compilation of deep learning pipelines across IoT and cloud\",\"url\":\"https://www.semanticscholar.org/paper/a5f6082c5fd84350f898d3d891510ff09e43f051\",\"venue\":\"MobiCom\",\"year\":2020},{\"arxivId\":\"1611.06646\",\"authors\":[{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2518212\",\"name\":\"Hakan Bilen\"},{\"authorId\":\"2304222\",\"name\":\"Efstratios Gavves\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1109/CVPR.2017.607\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"33402ee078a61c7d019b1543bb11cc127c2462d2\",\"title\":\"Self-Supervised Video Representation Learning with Odd-One-Out Networks\",\"url\":\"https://www.semanticscholar.org/paper/33402ee078a61c7d019b1543bb11cc127c2462d2\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47039680\",\"name\":\"X. Zhao\"},{\"authorId\":\"145359183\",\"name\":\"Y. Yi\"},{\"authorId\":\"144186239\",\"name\":\"Zemin Qiu\"},{\"authorId\":\"9235546\",\"name\":\"Qingqing Zeng\"}],\"doi\":\"10.1109/ICCCS49078.2020.9118516\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b90a1655ac7cbabef6c7a8ea4a70fa03526c6819\",\"title\":\"Feature Retrieving for Human Action Recognition by Mixed Scale Deep Feature Combined with Attention Model\",\"url\":\"https://www.semanticscholar.org/paper/b90a1655ac7cbabef6c7a8ea4a70fa03526c6819\",\"venue\":\"2020 5th International Conference on Computer and Communication Systems (ICCCS)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e6435837116d2d08d4f873e2b556c29a4d20812d\",\"title\":\"Holistic Large Scale Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/e6435837116d2d08d4f873e2b556c29a4d20812d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1711.09125\",\"authors\":[{\"authorId\":\"119770705\",\"name\":\"L. Wang\"},{\"authorId\":\"48625175\",\"name\":\"W. Li\"},{\"authorId\":\"145344553\",\"name\":\"W. Li\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2018.00155\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e6b534d8838f92461a478a3e737b73e08db94748\",\"title\":\"Appearance-and-Relation Networks for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/e6b534d8838f92461a478a3e737b73e08db94748\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35678872\",\"name\":\"Hongxin Zhi\"},{\"authorId\":\"1792198\",\"name\":\"H. Yu\"},{\"authorId\":\"8086859\",\"name\":\"Shaomei Li\"},{\"authorId\":\"144036350\",\"name\":\"C. Gao\"}],\"doi\":\"10.1109/SSCI.2017.8285296\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"279459cbbc5c6db4802e9c737cc72a612d76f7fc\",\"title\":\"DMMLN: A deep multi-task and metric learning based network for video classification\",\"url\":\"https://www.semanticscholar.org/paper/279459cbbc5c6db4802e9c737cc72a612d76f7fc\",\"venue\":\"2017 IEEE Symposium Series on Computational Intelligence (SSCI)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21240743\",\"name\":\"Yongqiang Kong\"},{\"authorId\":\"48902208\",\"name\":\"Zhaoqiang Wei\"},{\"authorId\":\"2999650\",\"name\":\"Zhengang Wei\"},{\"authorId\":\"3050837\",\"name\":\"Shengke Wang\"},{\"authorId\":\"143750989\",\"name\":\"F. Gao\"}],\"doi\":\"10.1007/978-3-319-77383-4_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"299e4d4c575fb684f7d234ac1a693f9c75dee9a2\",\"title\":\"Exploiting Sub-region Deep Features for Specific Action Recognition in Combat Sports Video\",\"url\":\"https://www.semanticscholar.org/paper/299e4d4c575fb684f7d234ac1a693f9c75dee9a2\",\"venue\":\"PCM\",\"year\":2017},{\"arxivId\":\"1903.05577\",\"authors\":[{\"authorId\":\"50993183\",\"name\":\"Haochen Zhang\"},{\"authorId\":\"48928981\",\"name\":\"Dong Liu\"},{\"authorId\":\"2352456\",\"name\":\"Z. Xiong\"}],\"doi\":\"10.1109/ICCV.2019.00889\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cb72cbdb5476118a207a51054787f6419d5ec055\",\"title\":\"Two-Stream Action Recognition-Oriented Video Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/cb72cbdb5476118a207a51054787f6419d5ec055\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1605.04988\",\"authors\":[{\"authorId\":\"35696058\",\"name\":\"Samitha Herath\"},{\"authorId\":\"1686714\",\"name\":\"M. Harandi\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"}],\"doi\":\"10.1016/j.imavis.2017.01.010\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9979b794d0bd06a1959a6b169f2cf32ba8ba376b\",\"title\":\"Going deeper into action recognition: A survey\",\"url\":\"https://www.semanticscholar.org/paper/9979b794d0bd06a1959a6b169f2cf32ba8ba376b\",\"venue\":\"Image Vis. Comput.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"18947121\",\"name\":\"Muhammad Attique Khan\"},{\"authorId\":\"7550152\",\"name\":\"Yudong Zhang\"},{\"authorId\":\"46883468\",\"name\":\"S. Khan\"},{\"authorId\":\"1845891052\",\"name\":\"Muhammad Attique\"},{\"authorId\":\"46855540\",\"name\":\"A. Rehman\"},{\"authorId\":\"5686109\",\"name\":\"Sanghyun Seo\"}],\"doi\":\"10.1007/s11042-020-09408-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a42ddba691a30ffd1b2ce059eace768e0a1965a6\",\"title\":\"A resource conscious human action recognition framework using 26-layered deep convolutional neural network\",\"url\":\"https://www.semanticscholar.org/paper/a42ddba691a30ffd1b2ce059eace768e0a1965a6\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"2004.04730\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"}],\"doi\":\"10.1109/cvpr42600.2020.00028\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"908cca0abefc35acc38033603714fbb1bcadc49d\",\"title\":\"X3D: Expanding Architectures for Efficient Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/908cca0abefc35acc38033603714fbb1bcadc49d\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2003.06409\",\"authors\":[{\"authorId\":\"1909776\",\"name\":\"Anthony Hu\"},{\"authorId\":\"30467209\",\"name\":\"Fergal Cotter\"},{\"authorId\":\"145536619\",\"name\":\"N. Mohan\"},{\"authorId\":\"31618584\",\"name\":\"C. Gurau\"},{\"authorId\":\"47645184\",\"name\":\"Alex Kendall\"}],\"doi\":\"10.1007/978-3-030-58517-4_45\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a79685e5b72e31405ded418abe8af86166313aa0\",\"title\":\"Probabilistic Future Prediction for Video Scene Understanding\",\"url\":\"https://www.semanticscholar.org/paper/a79685e5b72e31405ded418abe8af86166313aa0\",\"venue\":\"ECCV\",\"year\":2020}],\"corpusId\":15080417,\"doi\":\"10.1109/ICCV.2015.522\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":30,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"95561aec9f00cdf5346e627574e1a022eda3e4f5\",\"references\":[{\"arxivId\":\"1405.4506\",\"authors\":[{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"39527134\",\"name\":\"X. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1016/j.cviu.2016.03.013\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"facbedfe90956c720f70aab14767b5e25dcc6478\",\"title\":\"Bag of visual words and fusion methods for action recognition: Comprehensive study and good practice\",\"url\":\"https://www.semanticscholar.org/paper/facbedfe90956c720f70aab14767b5e25dcc6478\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2370507\",\"name\":\"K. Jia\"},{\"authorId\":\"1739816\",\"name\":\"D. Yeung\"}],\"doi\":\"10.1109/CVPR.2008.4587732\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0b98241dd626ad66ce77ce367e275a3ad44e7aa0\",\"title\":\"Human action recognition using Local Spatio-Temporal Discriminant Embedding\",\"url\":\"https://www.semanticscholar.org/paper/0b98241dd626ad66ce77ce367e275a3ad44e7aa0\",\"venue\":\"2008 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2008},{\"arxivId\":\"1212.0402\",\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"title\":\"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\",\"url\":\"https://www.semanticscholar.org/paper/da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743600\",\"name\":\"S. Ji\"},{\"authorId\":\"143836295\",\"name\":\"W. Xu\"},{\"authorId\":\"41216159\",\"name\":\"Ming Yang\"},{\"authorId\":\"144782042\",\"name\":\"Kai Yu\"}],\"doi\":\"10.1109/TPAMI.2012.59\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"80bfcf1be2bf1b95cc6f36d229665cdf22d76190\",\"title\":\"3D Convolutional Neural Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/80bfcf1be2bf1b95cc6f36d229665cdf22d76190\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1735300\",\"name\":\"S. Haykin\"},{\"authorId\":\"35299277\",\"name\":\"B. Kosko\"}],\"doi\":\"10.1109/9780470544976.CH9\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f42b865e20e61a954239f421b42007236e671f19\",\"title\":\"GradientBased Learning Applied to Document Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f42b865e20e61a954239f421b42007236e671f19\",\"venue\":\"\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"C Szegedy\"},{\"authorId\":null,\"name\":\"W Liu\"},{\"authorId\":null,\"name\":\"Y Jia\"},{\"authorId\":null,\"name\":\"P Sermanet\"},{\"authorId\":null,\"name\":\"S Reed\"},{\"authorId\":null,\"name\":\"D Anguelov\"},{\"authorId\":null,\"name\":\"D Erhan\"},{\"authorId\":null,\"name\":\"V Vanhoucke\"},{\"authorId\":null,\"name\":\"A Rabinovich\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Going deeper with convolutions. arXiv preprint arXiv:1409\",\"url\":\"\",\"venue\":\"Going deeper with convolutions. arXiv preprint arXiv:1409\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"3205375\",\"name\":\"T. Lindeberg\"}],\"doi\":\"10.1109/ICCV.2003.1238378\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f90d79809325d2b78e35a79ecb372407f81b3993\",\"title\":\"Space-time interest points\",\"url\":\"https://www.semanticscholar.org/paper/f90d79809325d2b78e35a79ecb372407f81b3993\",\"venue\":\"Proceedings Ninth IEEE International Conference on Computer Vision\",\"year\":2003},{\"arxivId\":\"1409.4842\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"46641766\",\"name\":\"W. Liu\"},{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"},{\"authorId\":\"48840704\",\"name\":\"Scott Reed\"},{\"authorId\":\"1838674\",\"name\":\"Dragomir Anguelov\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"39863668\",\"name\":\"Andrew Rabinovich\"}],\"doi\":\"10.1109/CVPR.2015.7298594\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"title\":\"Going deeper with convolutions\",\"url\":\"https://www.semanticscholar.org/paper/e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1907.06670\",\"authors\":[{\"authorId\":\"40521852\",\"name\":\"Z. Zhang\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/TPAMI.2011.157\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"3a6b1896c5d76b2c85467cb0611104d8f9de2b87\",\"title\":\"Slow Feature Analysis for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3a6b1896c5d76b2c85467cb0611104d8f9de2b87\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"L Van Der Maaten\"},{\"authorId\":null,\"name\":\"G Hinton\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Visualizing highdimensional data using t-SNE\",\"url\":\"\",\"venue\":\"Journal of Machine Learning Research\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2013.441\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d721f4d64b8e722222c876f0a0f226ed49476347\",\"title\":\"Action Recognition with Improved Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/d721f4d64b8e722222c876f0a0f226ed49476347\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2712738\",\"name\":\"C. Sch\\u00fcldt\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"3033284\",\"name\":\"B. Caputo\"}],\"doi\":\"10.1109/icpr.2004.1334462\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b480f6a3750b4cebaf1db205692c8321d45926a2\",\"title\":\"Recognizing human actions: a local SVM approach\",\"url\":\"https://www.semanticscholar.org/paper/b480f6a3750b4cebaf1db205692c8321d45926a2\",\"venue\":\"Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004.\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"152821938\",\"name\":\"Sanketh Shetty\"},{\"authorId\":\"120906511\",\"name\":\"T. Leung\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2014.223\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"title\":\"Large-Scale Video Classification with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1408.5093\",\"authors\":[{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"1782282\",\"name\":\"Evan Shelhamer\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"3049736\",\"name\":\"S. Karayev\"},{\"authorId\":\"144361581\",\"name\":\"J. Long\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1145/2647868.2654889\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6bdb186ec4726e00a8051119636d4df3b94043b5\",\"title\":\"Caffe: Convolutional Architecture for Fast Feature Embedding\",\"url\":\"https://www.semanticscholar.org/paper/6bdb186ec4726e00a8051119636d4df3b94043b5\",\"venue\":\"ACM Multimedia\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50170517\",\"name\":\"M. Blank\"},{\"authorId\":\"3089071\",\"name\":\"Lena Gorelick\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"144611617\",\"name\":\"M. Irani\"},{\"authorId\":\"1760994\",\"name\":\"R. Basri\"}],\"doi\":\"10.1109/ICCV.2005.28\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1a9eb04b9b07d4a58aa78eb9f68a77ade0199fab\",\"title\":\"Actions as space-time shapes\",\"url\":\"https://www.semanticscholar.org/paper/1a9eb04b9b07d4a58aa78eb9f68a77ade0199fab\",\"venue\":\"Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41191188\",\"name\":\"Lin Sun\"},{\"authorId\":\"2370507\",\"name\":\"K. Jia\"},{\"authorId\":\"145150387\",\"name\":\"Tsung-Han Chan\"},{\"authorId\":\"50313556\",\"name\":\"Y. Fang\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"}],\"doi\":\"10.1109/CVPR.2014.336\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c1b0296ed47cf3f906f6e24683d9f5444406be53\",\"title\":\"DL-SFA: Deeply-Learned Slow Feature Analysis for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c1b0296ed47cf3f906f6e24683d9f5444406be53\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145177088\",\"name\":\"David Stutz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"21c64ab3d340390c493534fcb2c6b06124e3d794\",\"title\":\"Neural Codes for Image Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/21c64ab3d340390c493534fcb2c6b06124e3d794\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c46943103bd7b7a2c7be86859995a4144d1938b\",\"title\":\"Visualizing Data using t-SNE\",\"url\":\"https://www.semanticscholar.org/paper/1c46943103bd7b7a2c7be86859995a4144d1938b\",\"venue\":\"\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"L. van der Maaten\"},{\"authorId\":null,\"name\":\"G. Hinton\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Visualizing highdimensional data using t-SNE\",\"url\":\"\",\"venue\":\"Journal of Machine Learning Research,\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143607492\",\"name\":\"J. Wright\"},{\"authorId\":\"40984420\",\"name\":\"A. Yang\"},{\"authorId\":\"1701028\",\"name\":\"A. Ganesh\"},{\"authorId\":\"144797536\",\"name\":\"S. Sastry\"},{\"authorId\":\"50032052\",\"name\":\"Y. Ma\"}],\"doi\":\"10.1109/TPAMI.2008.79\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d5eec41043d91964879c4c745c7165f823967f29\",\"title\":\"Robust Face Recognition via Sparse Representation\",\"url\":\"https://www.semanticscholar.org/paper/d5eec41043d91964879c4c745c7165f823967f29\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2909350\",\"name\":\"Alexander Kl\\u00e4ser\"},{\"authorId\":\"3502855\",\"name\":\"M. Marszalek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.5244/C.22.99\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"56e95f8efb7dbbc0b1820eaf365edc6f3b3f6719\",\"title\":\"A Spatio-Temporal Descriptor Based on 3D-Gradients\",\"url\":\"https://www.semanticscholar.org/paper/56e95f8efb7dbbc0b1820eaf365edc6f3b3f6719\",\"venue\":\"BMVC\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1848930\",\"name\":\"Hayko Riemenschneider\"},{\"authorId\":\"1793476\",\"name\":\"M. Donoser\"},{\"authorId\":\"144746444\",\"name\":\"H. Bischof\"}],\"doi\":\"10.5244/C.23.28\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0ba7b15abb5188fac70ed43a89ddc95d41003826\",\"title\":\"Bag of Optical Flow Volumes for Image Sequence Recognition\",\"url\":\"https://www.semanticscholar.org/paper/0ba7b15abb5188fac70ed43a89ddc95d41003826\",\"venue\":\"BMVC\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"},{\"authorId\":\"52184096\",\"name\":\"L. Bottou\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"1721248\",\"name\":\"P. Haffner\"}],\"doi\":\"10.1109/5.726791\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"162d958ff885f1462aeda91cd72582323fd6a1f4\",\"title\":\"Gradient-based learning applied to document recognition\",\"url\":\"https://www.semanticscholar.org/paper/162d958ff885f1462aeda91cd72582323fd6a1f4\",\"venue\":\"\",\"year\":1998},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2256269\",\"name\":\"C. Farabet\"},{\"authorId\":\"2341378\",\"name\":\"C. Couprie\"},{\"authorId\":\"1688714\",\"name\":\"Laurent Najman\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"}],\"doi\":\"10.1109/TPAMI.2012.231\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"237a04dd8291cbdb59b6dc4b53e689af743fe2a3\",\"title\":\"Learning Hierarchical Features for Scene Labeling\",\"url\":\"https://www.semanticscholar.org/paper/237a04dd8291cbdb59b6dc4b53e689af743fe2a3\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"},{\"authorId\":\"52184096\",\"name\":\"L. Bottou\"},{\"authorId\":\"34782608\",\"name\":\"G. Orr\"},{\"authorId\":\"145034054\",\"name\":\"K. M\\u00fcller\"}],\"doi\":\"10.1007/978-3-642-35289-8_3\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b87274e6d9aa4e6ba5148898aa92941617d2b6ed\",\"title\":\"Efficient BackProp\",\"url\":\"https://www.semanticscholar.org/paper/b87274e6d9aa4e6ba5148898aa92941617d2b6ed\",\"venue\":\"Neural Networks: Tricks of the Trade\",\"year\":2012},{\"arxivId\":\"1406.2199\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"title\":\"Two-Stream Convolutional Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"35033378\",\"name\":\"M. M. Ullah\"},{\"authorId\":\"2909350\",\"name\":\"Alexander Kl\\u00e4ser\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.5244/C.23.124\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a39e6968580762ac5ae3cd064e86e1849f3efb7f\",\"title\":\"Evaluation of Local Spatio-temporal Features for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a39e6968580762ac5ae3cd064e86e1849f3efb7f\",\"venue\":\"BMVC\",\"year\":2009},{\"arxivId\":\"1311.2901\",\"authors\":[{\"authorId\":\"48799969\",\"name\":\"Matthew D. Zeiler\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":\"10.1007/978-3-319-10590-1_53\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1a2a770d23b4a171fa81de62a78a3deb0588f238\",\"title\":\"Visualizing and Understanding Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/1a2a770d23b4a171fa81de62a78a3deb0588f238\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Ganesh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Robust face recognition via sparse representation Visualizing and understanding convolutional networks\",\"url\":\"\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2676982\",\"name\":\"Hueihan Jhuang\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"},{\"authorId\":\"145128145\",\"name\":\"Lior Wolf\"},{\"authorId\":\"1685292\",\"name\":\"T. Poggio\"}],\"doi\":\"10.1109/ICCV.2007.4408988\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"124d967683544973581f951ee93b3f7c069e3ced\",\"title\":\"A Biologically Inspired System for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/124d967683544973581f951ee93b3f7c069e3ced\",\"venue\":\"2007 IEEE 11th International Conference on Computer Vision\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"3502855\",\"name\":\"M. Marszalek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"3261451\",\"name\":\"Benjamin Rozenfeld\"}],\"doi\":\"10.1109/CVPR.2008.4587756\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0f86767732f76f478d5845f2e59f99ba106e9265\",\"title\":\"Learning realistic human actions from movies\",\"url\":\"https://www.semanticscholar.org/paper/0f86767732f76f478d5845f2e59f99ba106e9265\",\"venue\":\"2008 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2119821\",\"name\":\"Daniel Weinland\"},{\"authorId\":\"1719388\",\"name\":\"E. Boyer\"}],\"doi\":\"10.1109/CVPR.2008.4587731\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d29865cbe2e66d6ae34d308edb17f636467b98b\",\"title\":\"Action recognition using exemplar-based embedding\",\"url\":\"https://www.semanticscholar.org/paper/9d29865cbe2e66d6ae34d308edb17f636467b98b\",\"venue\":\"2008 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"47680287\",\"name\":\"W. Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2009.5206848\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1b47265245e8db53a553049dcb27ed3e495fd625\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/1b47265245e8db53a553049dcb27ed3e495fd625\",\"venue\":\"CVPR 2009\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"119268487\",\"name\":\"Hueihan Jhuang\"},{\"authorId\":\"1930964\",\"name\":\"E. Garrote\"},{\"authorId\":\"145031878\",\"name\":\"T. Poggio\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"}],\"doi\":\"10.1109/ICCV.2011.6126543\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8b3b8848a311c501e704c45c6d50430ab7068956\",\"title\":\"HMDB: A large video database for human motion recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b3b8848a311c501e704c45c6d50430ab7068956\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35238678\",\"name\":\"D. Lowe\"}],\"doi\":\"10.1109/ICCV.1999.790410\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f9f836d28f52ad260213d32224a6d227f8e8849a\",\"title\":\"Object recognition from local scale-invariant features\",\"url\":\"https://www.semanticscholar.org/paper/f9f836d28f52ad260213d32224a6d227f8e8849a\",\"venue\":\"Proceedings of the Seventh IEEE International Conference on Computer Vision\",\"year\":1999},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33568342\",\"name\":\"C. Myers\"},{\"authorId\":\"73554434\",\"name\":\"L. R. Rabiner\"},{\"authorId\":\"14833627\",\"name\":\"A. E. Rosenberg\"}],\"doi\":\"10.1109/TASSP.1980.1163491\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c2affcf33baef4fe2e595f3f90ec534fb1aa61c5\",\"title\":\"Performance tradeoffs in dynamic time warping algorithms for isolated word recognition\",\"url\":\"https://www.semanticscholar.org/paper/c2affcf33baef4fe2e595f3f90ec534fb1aa61c5\",\"venue\":\"\",\"year\":1980},{\"arxivId\":\"1311.2524\",\"authors\":[{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"153652146\",\"name\":\"J. Malik\"}],\"doi\":\"10.1109/CVPR.2014.81\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2f4df08d9072fc2ac181b7fced6a245315ce05c8\",\"title\":\"Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/2f4df08d9072fc2ac181b7fced6a245315ce05c8\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"3254319\",\"name\":\"Hongcheng Wang\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.5244/C.20.127\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e25d2a9aa691e63657fef30f5850799d757f69e6\",\"title\":\"Unsupervised Learning of Human Action Categories Using Spatial-Temporal Words\",\"url\":\"https://www.semanticscholar.org/paper/e25d2a9aa691e63657fef30f5850799d757f69e6\",\"venue\":\"BMVC\",\"year\":2006},{\"arxivId\":\"1411.4038\",\"authors\":[{\"authorId\":\"1782282\",\"name\":\"Evan Shelhamer\"},{\"authorId\":\"144361581\",\"name\":\"J. Long\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2572683\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"317aee7fc081f2b137a85c4f20129007fd8e717e\",\"title\":\"Fully Convolutional Networks for Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/317aee7fc081f2b137a85c4f20129007fd8e717e\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017}],\"title\":\"Human Action Recognition Using Factorized Spatio-Temporal Convolutional Networks\",\"topics\":[{\"topic\":\"Convolution\",\"topicId\":\"571\",\"url\":\"https://www.semanticscholar.org/topic/571\"},{\"topic\":\"Convolutional neural network\",\"topicId\":\"29860\",\"url\":\"https://www.semanticscholar.org/topic/29860\"},{\"topic\":\"Tcl\",\"topicId\":\"12045\",\"url\":\"https://www.semanticscholar.org/topic/12045\"},{\"topic\":\"Sequence alignment\",\"topicId\":\"35150\",\"url\":\"https://www.semanticscholar.org/topic/35150\"},{\"topic\":\"Computer vision\",\"topicId\":\"5332\",\"url\":\"https://www.semanticscholar.org/topic/5332\"},{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"},{\"topic\":\"Deep learning\",\"topicId\":\"2762\",\"url\":\"https://www.semanticscholar.org/topic/2762\"},{\"topic\":\"Multiple encryption\",\"topicId\":\"132922\",\"url\":\"https://www.semanticscholar.org/topic/132922\"},{\"topic\":\"Algorithm\",\"topicId\":\"305\",\"url\":\"https://www.semanticscholar.org/topic/305\"},{\"topic\":\"Backpropagation\",\"topicId\":\"11998\",\"url\":\"https://www.semanticscholar.org/topic/11998\"},{\"topic\":\"Video clip\",\"topicId\":\"30493\",\"url\":\"https://www.semanticscholar.org/topic/30493\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Angular defect\",\"topicId\":\"75\",\"url\":\"https://www.semanticscholar.org/topic/75\"},{\"topic\":\"Sampling (signal processing)\",\"topicId\":\"7839\",\"url\":\"https://www.semanticscholar.org/topic/7839\"},{\"topic\":\"3D computer graphics\",\"topicId\":\"100829\",\"url\":\"https://www.semanticscholar.org/topic/100829\"},{\"topic\":\"Structured text\",\"topicId\":\"66581\",\"url\":\"https://www.semanticscholar.org/topic/66581\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"},{\"topic\":\"Software propagation\",\"topicId\":\"2021211\",\"url\":\"https://www.semanticscholar.org/topic/2021211\"}],\"url\":\"https://www.semanticscholar.org/paper/95561aec9f00cdf5346e627574e1a022eda3e4f5\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015}\n"