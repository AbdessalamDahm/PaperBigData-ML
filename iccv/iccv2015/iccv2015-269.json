"{\"abstract\":\"In this work we focus on the problem of image caption generation. We propose an extension of the long short term memory (LSTM) model, which we coin gLSTM for short. In particular, we add semantic information extracted from the image as extra input to each unit of the LSTM block, with the aim of guiding the model towards solutions that are more tightly coupled to the image content. Additionally, we explore different length normalization strategies for beam search to avoid bias towards short sentences. On various benchmark datasets such as Flickr8K, Flickr30K and MS COCO, we obtain results that are on par with or better than the current state-of-the-art.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"143904396\",\"name\":\"Xu Jia\",\"url\":\"https://www.semanticscholar.org/author/143904396\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\",\"url\":\"https://www.semanticscholar.org/author/2304222\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\",\"url\":\"https://www.semanticscholar.org/author/1688071\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\",\"url\":\"https://www.semanticscholar.org/author/1704728\"}],\"citationVelocity\":53,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1445076711\",\"name\":\"Cong Xu\"},{\"authorId\":\"3515580\",\"name\":\"Z. Su\"},{\"authorId\":\"48383658\",\"name\":\"Q. Jia\"},{\"authorId\":\"1490778148\",\"name\":\"Dezheng Zhang\"},{\"authorId\":null,\"name\":\"Xie Yonghong\"},{\"authorId\":\"11882891\",\"name\":\"A. Yang\"}],\"doi\":\"10.32604/cmc.2020.05239\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1068736ddfaceccc54ae1c113c6217d2dd518921\",\"title\":\"Neural Dialogue Model with Retrieval Attention for Personalized Response Generation\",\"url\":\"https://www.semanticscholar.org/paper/1068736ddfaceccc54ae1c113c6217d2dd518921\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48496963\",\"name\":\"F. Ahmed\"},{\"authorId\":null,\"name\":\"Md Sultan Mahmud\"},{\"authorId\":\"1828610\",\"name\":\"M. Yeasin\"}],\"doi\":\"10.1109/ICECE.2018.8636726\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"db30478abbb3875ba474994d0cb1fb10e3ffb099\",\"title\":\"Words to Meaningful Sentence: Analytics through Game Interface\",\"url\":\"https://www.semanticscholar.org/paper/db30478abbb3875ba474994d0cb1fb10e3ffb099\",\"venue\":\"2018 10th International Conference on Electrical and Computer Engineering (ICECE)\",\"year\":2018},{\"arxivId\":\"1709.05038\",\"authors\":[{\"authorId\":\"49693168\",\"name\":\"Yang Xian\"},{\"authorId\":\"35484757\",\"name\":\"Yingli Tian\"}],\"doi\":\"10.1109/TIP.2019.2917229\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"54f5c9df478dc510ea8f9c3b52917fb8356904e4\",\"title\":\"Self-Guiding Multimodal LSTM\\u2014When We Do Not Have a Perfect Training Dataset for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/54f5c9df478dc510ea8f9c3b52917fb8356904e4\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491622549\",\"name\":\"Jiahang Shi\"},{\"authorId\":\"118648775\",\"name\":\"H. Li\"},{\"authorId\":\"2313482\",\"name\":\"Shuixiu Wu\"},{\"authorId\":\"1859949\",\"name\":\"Mingwen Wang\"}],\"doi\":\"10.1109/ICIVC47709.2019.8980999\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"229656483f0bdc8c6563a4aa0104493fccfa0cfd\",\"title\":\"Auto Image Comment via Deep Attention\",\"url\":\"https://www.semanticscholar.org/paper/229656483f0bdc8c6563a4aa0104493fccfa0cfd\",\"venue\":\"2019 IEEE 4th International Conference on Image, Vision and Computing (ICIVC)\",\"year\":2019},{\"arxivId\":\"1708.02760\",\"authors\":[{\"authorId\":\"47002704\",\"name\":\"Y. Li\"},{\"authorId\":\"145544640\",\"name\":\"C. Huang\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"}],\"doi\":\"10.1109/ICCV.2017.370\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"acb1ffd5ba92b0c450ec63f36f4f67a972fc35ed\",\"title\":\"Learning to Disambiguate by Asking Discriminative Questions\",\"url\":\"https://www.semanticscholar.org/paper/acb1ffd5ba92b0c450ec63f36f4f67a972fc35ed\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1783874\",\"name\":\"T. Wang\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"},{\"authorId\":\"144751998\",\"name\":\"C. He\"}],\"doi\":\"10.1007/s11063-019-09979-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a54a18073b4b4a788e106d540d26817c8c898a63\",\"title\":\"Image Caption with Endogenous\\u2013Exogenous Attention\",\"url\":\"https://www.semanticscholar.org/paper/a54a18073b4b4a788e106d540d26817c8c898a63\",\"venue\":\"Neural Processing Letters\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"78461875\",\"name\":\"Maedeh Aghaei\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"61da412f446a99dc0eefd3e72753b4101a3b4e5d\",\"title\":\"Social signal processing from egocentric photo-streams\",\"url\":\"https://www.semanticscholar.org/paper/61da412f446a99dc0eefd3e72753b4101a3b4e5d\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1604.06506\",\"authors\":[{\"authorId\":\"2287343\",\"name\":\"Roeland De Geest\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"3060081\",\"name\":\"A. Ghodrati\"},{\"authorId\":\"3245057\",\"name\":\"Zhenyang Li\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"}],\"doi\":\"10.1007/978-3-319-46454-1_17\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"574ab231627eadc1056162c38d0895f372121250\",\"title\":\"Online Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/574ab231627eadc1056162c38d0895f372121250\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"144478646\",\"name\":\"Z. Guo\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"47158869\",\"name\":\"Xing Xu\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1109/TMM.2017.2729019\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"51b2c1e750b1d3b893072829d012f2352d6bd373\",\"title\":\"Video Captioning With Attention-Based LSTM and Semantic Consistency\",\"url\":\"https://www.semanticscholar.org/paper/51b2c1e750b1d3b893072829d012f2352d6bd373\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"20630261\",\"name\":\"X. Xiao\"},{\"authorId\":\"40585252\",\"name\":\"L. Wang\"},{\"authorId\":\"33969294\",\"name\":\"K. Ding\"},{\"authorId\":\"1683738\",\"name\":\"S. Xiang\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.1016/J.PATCOG.2019.01.028\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"18cb67e5970c4b1f0949a6f6db8f8cbaa68b2eb1\",\"title\":\"Dense semantic embedding network for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/18cb67e5970c4b1f0949a6f6db8f8cbaa68b2eb1\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41052836\",\"name\":\"Anya Belz\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"}],\"doi\":\"10.1017/S1351324918000086\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d740802aa22dbc187fe5df39108ba493b34d2839\",\"title\":\"From image to language and back again\",\"url\":\"https://www.semanticscholar.org/paper/d740802aa22dbc187fe5df39108ba493b34d2839\",\"venue\":\"Nat. Lang. Eng.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144161025\",\"name\":\"C. Zhou\"},{\"authorId\":\"26554826\",\"name\":\"Yuzhao Mao\"},{\"authorId\":\"1680068\",\"name\":\"X. Wang\"}],\"doi\":\"10.1007/978-3-319-69005-6_27\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"654afbb93bbff18fb8772993cbdb6e82f9a54716\",\"title\":\"Topic-Specific Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/654afbb93bbff18fb8772993cbdb6e82f9a54716\",\"venue\":\"CCL\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1947015\",\"name\":\"Zhaowei Qu\"},{\"authorId\":\"2148442\",\"name\":\"Bingyu Cao\"},{\"authorId\":\"38435706\",\"name\":\"X. Wang\"},{\"authorId\":\"145987554\",\"name\":\"F. Li\"},{\"authorId\":\"47568790\",\"name\":\"Peirong Xu\"},{\"authorId\":\"121860468\",\"name\":\"Luhan Zhang\"}],\"doi\":\"10.3970/cmc.2018.903.694\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1f267f73a84deacf93e4761622f84a06c91d977a\",\"title\":\"Feedback LSTM network based on attention for image description generator\",\"url\":\"https://www.semanticscholar.org/paper/1f267f73a84deacf93e4761622f84a06c91d977a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8799308\",\"name\":\"U. Nadeem\"},{\"authorId\":\"2210661\",\"name\":\"S. Shah\"},{\"authorId\":\"2470423\",\"name\":\"Ferdous Sohel\"},{\"authorId\":\"2444665\",\"name\":\"R. Togneri\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"}],\"doi\":\"10.1007/978-3-030-11479-4_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e549a9049bbbcb1a9e854de2f05fdfae4fb0da7d\",\"title\":\"Deep Learning for Scene Understanding\",\"url\":\"https://www.semanticscholar.org/paper/e549a9049bbbcb1a9e854de2f05fdfae4fb0da7d\",\"venue\":\"Handbook of Deep Learning Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"117548227\",\"name\":\"Saloni Kalra\"},{\"authorId\":\"88872765\",\"name\":\"Alka Leekha\"}],\"doi\":\"10.1080/02522667.2020.1715602\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"117333afd2ce2d80dd195dc5c5087f1b2b6bebdc\",\"title\":\"Survey of convolutional neural networks for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/117333afd2ce2d80dd195dc5c5087f1b2b6bebdc\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38329336\",\"name\":\"G. Ding\"},{\"authorId\":\"8408809\",\"name\":\"M. Chen\"},{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"47666390\",\"name\":\"H. Chen\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"},{\"authorId\":\"47362455\",\"name\":\"Q. Liu\"}],\"doi\":\"10.1007/s12559-018-9581-x\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"848602d3de1b1ab9a06146e8b8f3f836cacbce91\",\"title\":\"Neural Image Caption Generation with Weighted Training and Reference\",\"url\":\"https://www.semanticscholar.org/paper/848602d3de1b1ab9a06146e8b8f3f836cacbce91\",\"venue\":\"Cognitive Computation\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"89206348\",\"name\":\"J. Xie\"},{\"authorId\":\"122773532\",\"name\":\"R. Li\"},{\"authorId\":\"12378089\",\"name\":\"Shiwei Lv\"},{\"authorId\":null,\"name\":\"Yujing Wang\"},{\"authorId\":\"1390896124\",\"name\":\"Qiangyan Wang\"},{\"authorId\":\"1396101470\",\"name\":\"Yury I. Vorotnitsky\"}],\"doi\":\"10.18280/TS.360206\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b6fb52b970b498b7fa951840ed88f75bd163e962\",\"title\":\"Chinese Alt Text Writing Based on Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/b6fb52b970b498b7fa951840ed88f75bd163e962\",\"venue\":\"Traitement du Signal\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s13735-020-00198-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8c85757cdd7de5f99ab1717a6355a09bb717013c\",\"title\":\"MRECN: mixed representation enhanced (de)compositional network for caption generation from visual features, modeling as pseudo tensor product representation\",\"url\":\"https://www.semanticscholar.org/paper/8c85757cdd7de5f99ab1717a6355a09bb717013c\",\"venue\":\"Int. J. Multim. Inf. Retr.\",\"year\":2020},{\"arxivId\":\"1607.06215\",\"authors\":[{\"authorId\":\"2500189\",\"name\":\"K. Wang\"},{\"authorId\":\"2397961\",\"name\":\"Qiyue Yin\"},{\"authorId\":null,\"name\":\"Wei Wang\"},{\"authorId\":\"50425438\",\"name\":\"S. Wu\"},{\"authorId\":null,\"name\":\"Liang Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6721e26e65c6b72dafae74fd1e7a6f2e6023a312\",\"title\":\"A Comprehensive Survey on Cross-modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/6721e26e65c6b72dafae74fd1e7a6f2e6023a312\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48773674\",\"name\":\"Lydia Weiland\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8cc5ed358764a68140550c1a7fcbafef31560164\",\"title\":\"Understanding the message of images\",\"url\":\"https://www.semanticscholar.org/paper/8cc5ed358764a68140550c1a7fcbafef31560164\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1867415\",\"name\":\"K. Mokhtari\"},{\"authorId\":\"1886387\",\"name\":\"John N. Maidens\"},{\"authorId\":\"1730000\",\"name\":\"A. Bener\"}],\"doi\":\"10.1007/978-3-030-18305-9_56\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fd33c7ec0c213e5be263927ef54bb31d9b60c2e3\",\"title\":\"Predicting Commentaries on a Financial Report with Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/fd33c7ec0c213e5be263927ef54bb31d9b60c2e3\",\"venue\":\"Canadian Conference on AI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36595248\",\"name\":\"Fang Fang\"},{\"authorId\":\"8194130\",\"name\":\"Qinyu Li\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"8275214\",\"name\":\"P. Tang\"}],\"doi\":\"10.1109/ICME.2018.8486437\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e0f0076476fc81a344b8bdec771802a8584dd10f\",\"title\":\"Refining Attention: A Sequential Attention Model for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/e0f0076476fc81a344b8bdec771802a8584dd10f\",\"venue\":\"2018 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49528055\",\"name\":\"Hanzhang Wang\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"3187665\",\"name\":\"Kaisheng Xu\"}],\"doi\":\"10.1109/CVPR.2018.00521\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7fdac774e51e0aa8f9921e857067801d73a8d2d0\",\"title\":\"Categorizing Concepts with Basic Level for Vision-to-Language\",\"url\":\"https://www.semanticscholar.org/paper/7fdac774e51e0aa8f9921e857067801d73a8d2d0\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145040726\",\"name\":\"R. Bernardi\"},{\"authorId\":\"2588033\",\"name\":\"Ruken Cakici\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"},{\"authorId\":\"1398643531\",\"name\":\"N. Ikizler-Cinbis\"},{\"authorId\":\"1393020635\",\"name\":\"F. Keller\"},{\"authorId\":\"35347012\",\"name\":\"A. Muscat\"},{\"authorId\":\"2022124\",\"name\":\"Barbara Plank\"}],\"doi\":\"10.1613/jair.4900\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c162d791b63682d928c09578bd38c3dd61f78c8c\",\"title\":\"Automatic Description Generation from Images: A Survey of Models, Datasets, and Evaluation Measures\",\"url\":\"https://www.semanticscholar.org/paper/c162d791b63682d928c09578bd38c3dd61f78c8c\",\"venue\":\"J. Artif. Intell. Res.\",\"year\":2016},{\"arxivId\":\"2009.12524\",\"authors\":[{\"authorId\":\"1972263989\",\"name\":\"Zanyar Zohourianshahzadi\"},{\"authorId\":\"34694214\",\"name\":\"J. Kalita\"}],\"doi\":\"10.1109/HCCAI49649.2020.00009\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d3cf77a7eb87bf9c85c4631b196c4eb10ff5b51e\",\"title\":\"Neural Twins Talk\",\"url\":\"https://www.semanticscholar.org/paper/d3cf77a7eb87bf9c85c4631b196c4eb10ff5b51e\",\"venue\":\"2020 IEEE International Conference on Humanized Computing and Communication with Artificial Intelligence (HCCAI)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48352212\",\"name\":\"Aming Wu\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"},{\"authorId\":\"20332986\",\"name\":\"Q. Hu\"},{\"authorId\":\"144894837\",\"name\":\"F. Wu\"}],\"doi\":\"10.1109/TCSVT.2019.2956593\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"230a8581672b3147238eaab2cf686c70fe4f672b\",\"title\":\"Convolutional Reconstruction-to-Sequence for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/230a8581672b3147238eaab2cf686c70fe4f672b\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4942547\",\"name\":\"Zongjian Zhang\"},{\"authorId\":\"144066903\",\"name\":\"Q. Wu\"},{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"145093625\",\"name\":\"F. Chen\"}],\"doi\":\"10.1109/TMM.2018.2888822\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"2bc7959cf6bf0ae64f1a83f5fce1ac8cb2256ed3\",\"title\":\"High-Quality Image Captioning With Fine-Grained and Semantic-Guided Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/2bc7959cf6bf0ae64f1a83f5fce1ac8cb2256ed3\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4634604\",\"name\":\"Xinyuan Qi\"},{\"authorId\":\"1795646\",\"name\":\"Z. Cao\"},{\"authorId\":\"144209660\",\"name\":\"Yang Xiao\"},{\"authorId\":\"46584851\",\"name\":\"J. Wang\"},{\"authorId\":null,\"name\":\"Chao Zhang\"}],\"doi\":\"10.1007/978-3-030-03338-5_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e0c828c5700dbd26d351d9b222db1c826ba4e81c\",\"title\":\"The Accurate Guidance for Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/e0c828c5700dbd26d351d9b222db1c826ba4e81c\",\"venue\":\"PRCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46447188\",\"name\":\"X. Zhang\"},{\"authorId\":\"2548483\",\"name\":\"Shengfeng He\"},{\"authorId\":\"1688375\",\"name\":\"Xinhang Song\"},{\"authorId\":\"1726262\",\"name\":\"R. Lau\"},{\"authorId\":\"24350293\",\"name\":\"J. Jiao\"},{\"authorId\":\"1694936\",\"name\":\"Q. Ye\"}],\"doi\":\"10.1016/J.NEUCOM.2018.02.112\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f7a305d80eae6a9b9fecbeeb7ade0b25d412219d\",\"title\":\"Image captioning via semantic element embedding\",\"url\":\"https://www.semanticscholar.org/paper/f7a305d80eae6a9b9fecbeeb7ade0b25d412219d\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36416867\",\"name\":\"J. Wu\"},{\"authorId\":\"30461408\",\"name\":\"Siya Xie\"},{\"authorId\":\"8182911\",\"name\":\"Xinbao Shi\"},{\"authorId\":\"2410016\",\"name\":\"Yaowen Chen\"}],\"doi\":\"10.1007/978-981-10-7299-4_13\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a1c523c5f30b5d005f79428197fa5e801f5b9d95\",\"title\":\"Global-Local Feature Attention Network with Reranking Strategy for Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/a1c523c5f30b5d005f79428197fa5e801f5b9d95\",\"venue\":\"CCCV\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49047213\",\"name\":\"Congcong Liu\"},{\"authorId\":\"1716948\",\"name\":\"Huaming Wu\"}],\"doi\":\"10.1016/j.sigpro.2018.10.019\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ee52088fe6191e19f94709aebfa30819ae5292ae\",\"title\":\"Channel pruning based on mean gradient for accelerating Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/ee52088fe6191e19f94709aebfa30819ae5292ae\",\"venue\":\"Signal Process.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46336997\",\"name\":\"J. Su\"},{\"authorId\":\"2268783\",\"name\":\"Chenghua Lin\"},{\"authorId\":\"48993818\",\"name\":\"M. Zhou\"},{\"authorId\":\"2457312\",\"name\":\"Qingyun Dai\"},{\"authorId\":\"13036580\",\"name\":\"Haoyu Lv\"}],\"doi\":\"10.18653/v1/W18-6702\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fdb4e6aded4580d9109759240d51cb413e332102\",\"title\":\"Generating Description for Sequential Images with Local-Object Attention Conditioned on Global Semantic Context\",\"url\":\"https://www.semanticscholar.org/paper/fdb4e6aded4580d9109759240d51cb413e332102\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46702778\",\"name\":\"H. Zhang\"},{\"authorId\":\"2913523\",\"name\":\"Diedie Qiu\"},{\"authorId\":\"50477983\",\"name\":\"R. Wu\"},{\"authorId\":\"103624776\",\"name\":\"Dong-Hong Ji\"},{\"authorId\":\"49461429\",\"name\":\"Guangli Li\"},{\"authorId\":\"9201022\",\"name\":\"Zhenyu Niu\"},{\"authorId\":\"50289773\",\"name\":\"Tao Li\"}],\"doi\":\"10.1007/S00500-019-03973-W\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7f7104056642c03263508957f20505a1dbba03ce\",\"title\":\"Novel model to integrate word embeddings and syntactic trees for automatic caption generation from images\",\"url\":\"https://www.semanticscholar.org/paper/7f7104056642c03263508957f20505a1dbba03ce\",\"venue\":\"Soft Comput.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34739384\",\"name\":\"Jinsong Su\"},{\"authorId\":\"150164718\",\"name\":\"Jialong Tang\"},{\"authorId\":null,\"name\":\"Ziyao Lu\"},{\"authorId\":\"3194601\",\"name\":\"Xianpei Han\"},{\"authorId\":\"2999092\",\"name\":\"H. Zhang\"}],\"doi\":\"10.1016/J.NEUCOM.2019.08.012\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2fb096118ebbe6615afe98c733c80f55bb40d2cf\",\"title\":\"A neural image captioning model with caption-to-images semantic constructor\",\"url\":\"https://www.semanticscholar.org/paper/2fb096118ebbe6615afe98c733c80f55bb40d2cf\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"1612.07086\",\"authors\":[{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"40894914\",\"name\":\"T. Chen\"}],\"doi\":\"10.1109/ICCV.2017.138\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d85704f4814e9fa5ff0b68b1e5cad9e6527d0bbf\",\"title\":\"An Empirical Study of Language CNN for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/d85704f4814e9fa5ff0b68b1e5cad9e6527d0bbf\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2677364\",\"name\":\"Luowei Zhou\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"},{\"authorId\":\"31717541\",\"name\":\"Parker A. Koch\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1145/3126686.3126717\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1e83adb616b8466639a14e78f3d26120be7caf48\",\"title\":\"Watch What You Just Said: Image Captioning with Text-Conditional Attention\",\"url\":\"https://www.semanticscholar.org/paper/1e83adb616b8466639a14e78f3d26120be7caf48\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":\"1805.11730\",\"authors\":[{\"authorId\":\"2584898\",\"name\":\"K. Liu\"},{\"authorId\":\"3076945\",\"name\":\"Yanen Li\"},{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":\"145603129\",\"name\":\"P. Natarajan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3829607559475bbf15c66850810a497eac1a26e1\",\"title\":\"Learn to Combine Modalities in Multimodal Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/3829607559475bbf15c66850810a497eac1a26e1\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1910.06475\",\"authors\":[{\"authorId\":\"152325076\",\"name\":\"H. Ge\"},{\"authorId\":\"79403975\",\"name\":\"Zehang Yan\"},{\"authorId\":\"96280392\",\"name\":\"K. Zhang\"},{\"authorId\":\"145327825\",\"name\":\"Mingde Zhao\"},{\"authorId\":\"46732983\",\"name\":\"Liang Sun\"}],\"doi\":\"10.1109/ICCV.2019.00184\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4b5231149f566fc8a78797b6fb448f9bca416380\",\"title\":\"Exploring Overall Contextual Information for Image Captioning in Human-Like Cognitive Style\",\"url\":\"https://www.semanticscholar.org/paper/4b5231149f566fc8a78797b6fb448f9bca416380\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143692915\",\"name\":\"Ying Hua Tan\"},{\"authorId\":\"2863960\",\"name\":\"Chee Seng Chan\"}],\"doi\":\"10.1016/j.neucom.2018.12.026\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"760a7ed58cf49fa5dbcfb7f06b67cea2cd35f768\",\"title\":\"Phrase-based image caption generator with hierarchical LSTM network\",\"url\":\"https://www.semanticscholar.org/paper/760a7ed58cf49fa5dbcfb7f06b67cea2cd35f768\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"1810.04020\",\"authors\":[{\"authorId\":\"47412302\",\"name\":\"M. Z. Hossain\"},{\"authorId\":\"2470423\",\"name\":\"Ferdous Sohel\"},{\"authorId\":\"2222847\",\"name\":\"M. F. Shiratuddin\"},{\"authorId\":\"47028380\",\"name\":\"Hamid Laga\"}],\"doi\":\"10.1145/3295748\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7e27d44e3fac723ccb703e0a83b22711bd42efe8\",\"title\":\"A Comprehensive Survey of Deep Learning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7e27d44e3fac723ccb703e0a83b22711bd42efe8\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1607.01794\",\"authors\":[{\"authorId\":\"3245057\",\"name\":\"Zhenyang Li\"},{\"authorId\":\"32781361\",\"name\":\"Kirill Gavrilyuk\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"143798882\",\"name\":\"Mihir Jain\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1016/j.cviu.2017.10.011\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"86031f555c128b82a1ac0db89ff4faeae16a1802\",\"title\":\"VideoLSTM convolves, attends and flows for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/86031f555c128b82a1ac0db89ff4faeae16a1802\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"}],\"doi\":\"10.1109/MSP.2017.2741510\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c5b803c2fee9bbf6d9132f633de70332b5e80a4d\",\"title\":\"Deep Learning for Image-to-Text Generation: A Technical Overview\",\"url\":\"https://www.semanticscholar.org/paper/c5b803c2fee9bbf6d9132f633de70332b5e80a4d\",\"venue\":\"IEEE Signal Processing Magazine\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2038515405\",\"name\":\"Yazid Bounab\"},{\"authorId\":\"1471224685\",\"name\":\"Mourad Oussalah\"},{\"authorId\":\"2038543683\",\"name\":\"Ahlam Ferdenache\"}],\"doi\":\"10.1109/IPTA50016.2020.9286602\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"12246cc5d29c1d8d7177d7a6e820fe3038ccd1d5\",\"title\":\"Reconciling Image Captioning and User\\u2019s Comments for Urban Tourism\",\"url\":\"https://www.semanticscholar.org/paper/12246cc5d29c1d8d7177d7a6e820fe3038ccd1d5\",\"venue\":\"2020 Tenth International Conference on Image Processing Theory, Tools and Applications (IPTA)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2591941\",\"name\":\"Shyam Sundar Rajagopalan\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"},{\"authorId\":\"1756344\",\"name\":\"T. Baltrusaitis\"},{\"authorId\":\"1717204\",\"name\":\"R. Goecke\"}],\"doi\":\"10.1007/978-3-319-46478-7_21\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"88e350a82fc6a30a33f231666455d5076f6c3731\",\"title\":\"Extending Long Short-Term Memory for Multi-View Structured Learning\",\"url\":\"https://www.semanticscholar.org/paper/88e350a82fc6a30a33f231666455d5076f6c3731\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48387339\",\"name\":\"Xinxin Zhu\"},{\"authorId\":\"1761970\",\"name\":\"L. Li\"},{\"authorId\":\"40478963\",\"name\":\"J. Liu\"},{\"authorId\":\"7475375\",\"name\":\"H. Peng\"},{\"authorId\":\"3712008\",\"name\":\"X. Niu\"}],\"doi\":\"10.3390/APP8050739\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"da958d2604e9f86f94a441d60488d0e93451c248\",\"title\":\"Captioning Transformer with Stacked Attention Modules\",\"url\":\"https://www.semanticscholar.org/paper/da958d2604e9f86f94a441d60488d0e93451c248\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2002.06701\",\"authors\":[{\"authorId\":\"151430668\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"19b00a2bd1624a0931069a539a971e40b65bfb3a\",\"title\":\"Gaussian Smoothen Semantic Features (GSSF) - Exploring the Linguistic Aspects of Visual Captioning in Indian Languages (Bengali) Using MSCOCO Framework\",\"url\":\"https://www.semanticscholar.org/paper/19b00a2bd1624a0931069a539a971e40b65bfb3a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39054424\",\"name\":\"Min Gao\"},{\"authorId\":\"121685794\",\"name\":\"Xian-Hua Han\"},{\"authorId\":\"36190812\",\"name\":\"Jing Li\"},{\"authorId\":\"144562060\",\"name\":\"Hui Ji\"},{\"authorId\":\"2856513\",\"name\":\"Huaxiang Zhang\"},{\"authorId\":\"51299154\",\"name\":\"Jiande Sun\"}],\"doi\":\"10.1007/s11042-018-6751-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b737a81ff05e64e29596415c65dbc156e3481f95\",\"title\":\"Image super-resolution based on two-level residual learning CNN\",\"url\":\"https://www.semanticscholar.org/paper/b737a81ff05e64e29596415c65dbc156e3481f95\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49163024\",\"name\":\"Shuang Bai\"},{\"authorId\":\"3380543\",\"name\":\"S. An\"}],\"doi\":\"10.1016/j.neucom.2018.05.080\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fe66fc9e3d9a52497119bab89ac54fc8b5f8859a\",\"title\":\"A survey on automatic image caption generation\",\"url\":\"https://www.semanticscholar.org/paper/fe66fc9e3d9a52497119bab89ac54fc8b5f8859a\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9450784\",\"name\":\"Yuqing Peng\"},{\"authorId\":\"145795117\",\"name\":\"X. Liu\"},{\"authorId\":\"47824943\",\"name\":\"Weihua Wang\"},{\"authorId\":\"48551485\",\"name\":\"Xiaosong Zhao\"},{\"authorId\":\"48958844\",\"name\":\"M. Wei\"}],\"doi\":\"10.1016/J.IMAVIS.2019.03.003\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"836aff52ebe445b1e4c251ef25a3f123d652c732\",\"title\":\"Image caption model of double LSTM with scene factors\",\"url\":\"https://www.semanticscholar.org/paper/836aff52ebe445b1e4c251ef25a3f123d652c732\",\"venue\":\"Image Vis. Comput.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47557007\",\"name\":\"Himanshu Sharma\"},{\"authorId\":\"2704856\",\"name\":\"A. S. Jalal\"}],\"doi\":\"10.1142/s0217984920503157\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b16e790764d0169e06501125ce946123d67f7c30\",\"title\":\"Incorporating external knowledge for image captioning using CNN and LSTM\",\"url\":\"https://www.semanticscholar.org/paper/b16e790764d0169e06501125ce946123d67f7c30\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49478695\",\"name\":\"Teng Jiang\"},{\"authorId\":\"46232306\",\"name\":\"Zehan Zhang\"},{\"authorId\":\"7607492\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1007/s00371-018-1565-z\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d6a788c65190959c1390d0ba8065d755c78d200a\",\"title\":\"Modeling coverage with semantic embedding for image caption generation\",\"url\":\"https://www.semanticscholar.org/paper/d6a788c65190959c1390d0ba8065d755c78d200a\",\"venue\":\"The Visual Computer\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40468514\",\"name\":\"Liang Yang\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1049/EL.2017.2351\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a34035a08043b19e5f01c47d4afc6e092d338715\",\"title\":\"TVPRNN for image caption generation\",\"url\":\"https://www.semanticscholar.org/paper/a34035a08043b19e5f01c47d4afc6e092d338715\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2858325793becd6b5eb122664dabc6b983eab471\",\"title\":\"SMOOTHLY VARYING WEIGHT HYPOTHESIS\",\"url\":\"https://www.semanticscholar.org/paper/2858325793becd6b5eb122664dabc6b983eab471\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1624658620\",\"name\":\"Chunlei Wu\"},{\"authorId\":\"1429199889\",\"name\":\"Shaozu Yuan\"},{\"authorId\":\"51172982\",\"name\":\"Haiwen Cao\"},{\"authorId\":\"19261873\",\"name\":\"Yiwei Wei\"},{\"authorId\":\"2250564\",\"name\":\"Leiquan Wang\"}],\"doi\":\"10.1109/ACCESS.2020.2981513\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"711be95a04da16c93b6bc880169532b68cdca37a\",\"title\":\"Hierarchical Attention-Based Fusion for Image Caption With Multi-Grained Rewards\",\"url\":\"https://www.semanticscholar.org/paper/711be95a04da16c93b6bc880169532b68cdca37a\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"15470287\",\"name\":\"Yuexin Ma\"},{\"authorId\":\"22689408\",\"name\":\"Xinge Zhu\"},{\"authorId\":\"1875352\",\"name\":\"Y. Sun\"},{\"authorId\":\"49225426\",\"name\":\"Bingzheng Yan\"}],\"doi\":\"10.1007/978-3-319-77380-3_3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"06ca178ff11d138147eec1bdf6f94619430e78ec\",\"title\":\"Image Tagging by Joint Deep Visual-Semantic Propagation\",\"url\":\"https://www.semanticscholar.org/paper/06ca178ff11d138147eec1bdf6f94619430e78ec\",\"venue\":\"PCM\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"89981182\",\"name\":\"Reema K. Sans\"},{\"authorId\":\"89292267\",\"name\":\"Reenu Sara Joseph\"},{\"authorId\":\"9002511\",\"name\":\"Rekha Narayanan\"},{\"authorId\":\"66711706\",\"name\":\"V. G. Mohan Prasad\"},{\"authorId\":\"22985130\",\"name\":\"Jisha James\"}],\"doi\":\"10.1007/978-3-030-00665-5_124\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3072672826ac1c8748d9cedc5e0ea0c54235bedf\",\"title\":\"AUGEN: An Ocular Support for Visually Impaired Using Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/3072672826ac1c8748d9cedc5e0ea0c54235bedf\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2788104\",\"name\":\"Yuting Su\"},{\"authorId\":\"50025928\",\"name\":\"Yuqian Li\"},{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":\"49285626\",\"name\":\"An-An Liu\"}],\"doi\":\"10.1007/s11063-019-09997-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"65471c0f2a8ee941363ee009e81d450a1b0bbbf9\",\"title\":\"Hierarchical Deep Neural Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/65471c0f2a8ee941363ee009e81d450a1b0bbbf9\",\"venue\":\"Neural Processing Letters\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4247049\",\"name\":\"Jingyu Liu\"},{\"authorId\":null,\"name\":\"Liang Wang\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/ICCV.2017.520\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"841471bf6f4c980bdb77e712f608ec64f8ad5833\",\"title\":\"Referring Expression Generation and Comprehension via Attributes\",\"url\":\"https://www.semanticscholar.org/paper/841471bf6f4c980bdb77e712f608ec64f8ad5833\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47666606\",\"name\":\"Hui Chen\"},{\"authorId\":\"38329336\",\"name\":\"G. Ding\"},{\"authorId\":\"1818920\",\"name\":\"Zijia Lin\"},{\"authorId\":\"34811036\",\"name\":\"Yuchen Guo\"},{\"authorId\":\"10795229\",\"name\":\"Caifeng Shan\"},{\"authorId\":\"144762952\",\"name\":\"J. Han\"}],\"doi\":\"10.1007/s12559-019-09656-w\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e99a3163815a0c40705ffd6347c6cdbf19fa5237\",\"title\":\"Image Captioning with Memorized Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/e99a3163815a0c40705ffd6347c6cdbf19fa5237\",\"venue\":\"Cognitive Computation\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9610143\",\"name\":\"Zhihao Fan\"},{\"authorId\":\"2712533\",\"name\":\"Zhongyu Wei\"},{\"authorId\":\"50695111\",\"name\":\"Siyuan Wang\"},{\"authorId\":\"1790227\",\"name\":\"X. Huang\"}],\"doi\":\"10.18653/v1/P19-1652\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aaf5e3afd61d0df6c483ca32faf8e7a9198b1557\",\"title\":\"Bridging by Word: Image Grounded Vocabulary Construction for Visual Captioning\",\"url\":\"https://www.semanticscholar.org/paper/aaf5e3afd61d0df6c483ca32faf8e7a9198b1557\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1907.06835\",\"authors\":[{\"authorId\":\"31166271\",\"name\":\"K. Lee\"},{\"authorId\":\"147087848\",\"name\":\"Joonhyun Jeong\"},{\"authorId\":\"40547898\",\"name\":\"Sung-Ho Bae\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7009b67fe86fd7325ee9f2f192fa270f5c152466\",\"title\":\"An Inter-Layer Weight Prediction and Quantization for Deep Neural Networks based on a Smoothly Varying Weight Hypothesis\",\"url\":\"https://www.semanticscholar.org/paper/7009b67fe86fd7325ee9f2f192fa270f5c152466\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2001.10590\",\"authors\":[{\"authorId\":\"115907885\",\"name\":\"Amir Vatani\"},{\"authorId\":\"9506700\",\"name\":\"Milad Taleby Ahvanooey\"},{\"authorId\":\"49872803\",\"name\":\"M. Rahimi\"}],\"doi\":\"10.14569/IJACSA.2018.090338\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"afca5e921965b78920b264545ba8edfeab699b83\",\"title\":\"An Effective Automatic Image Annotation Model Via Attention Model and Data Equilibrium\",\"url\":\"https://www.semanticscholar.org/paper/afca5e921965b78920b264545ba8edfeab699b83\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1908.05407\",\"authors\":[{\"authorId\":\"40280182\",\"name\":\"Yuqing Song\"},{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"50976845\",\"name\":\"Yida Zhao\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"}],\"doi\":\"10.1145/3343031.3350996\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c1056e6e84d52cf45017aad544fa0406441abda0\",\"title\":\"Unpaired Cross-lingual Image Caption Generation with Self-Supervised Rewards\",\"url\":\"https://www.semanticscholar.org/paper/c1056e6e84d52cf45017aad544fa0406441abda0\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1900967\",\"name\":\"U. Zia\"},{\"authorId\":\"145759322\",\"name\":\"M. M. Riaz\"},{\"authorId\":\"144683577\",\"name\":\"A. Ghafoor\"},{\"authorId\":\"145602758\",\"name\":\"Seyyed Salehi Seyyed Ali\"}],\"doi\":\"10.1007/s00521-019-04587-x\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"48473eb93b43e0130fce0d1eabb9b8fa468d8a41\",\"title\":\"Topic sensitive image descriptions\",\"url\":\"https://www.semanticscholar.org/paper/48473eb93b43e0130fce0d1eabb9b8fa468d8a41\",\"venue\":\"Neural Computing and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8053308\",\"name\":\"J. Tang\"},{\"authorId\":\"2287686\",\"name\":\"Xiangbo Shu\"},{\"authorId\":\"3233021\",\"name\":\"Zechao Li\"},{\"authorId\":\"2272096\",\"name\":\"Guo-Jun Qi\"},{\"authorId\":\"1688516\",\"name\":\"Jingdong Wang\"}],\"doi\":\"10.1145/2998574\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"032fb07f1dc510d35529fd302458ae30a1825f2e\",\"title\":\"Generalized Deep Transfer Networks for Knowledge Propagation in Heterogeneous Domains\",\"url\":\"https://www.semanticscholar.org/paper/032fb07f1dc510d35529fd302458ae30a1825f2e\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46671592\",\"name\":\"Y. Xian\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e11ad2a6c18112c13e9e65d64ef85cb1ff4883d0\",\"title\":\"Exploring the Internal Statistics: Single Image Super-Resolution, Completion and Captioning\",\"url\":\"https://www.semanticscholar.org/paper/e11ad2a6c18112c13e9e65d64ef85cb1ff4883d0\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1601.03896\",\"authors\":[{\"authorId\":\"145040726\",\"name\":\"R. Bernardi\"},{\"authorId\":\"2588033\",\"name\":\"Ruken Cakici\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"},{\"authorId\":\"1398643531\",\"name\":\"N. Ikizler-Cinbis\"},{\"authorId\":\"1393020635\",\"name\":\"F. Keller\"},{\"authorId\":\"35347012\",\"name\":\"A. Muscat\"},{\"authorId\":\"2022124\",\"name\":\"Barbara Plank\"}],\"doi\":\"10.24963/ijcai.2017/704\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6e9aebe54f76d85c6df7e80faa761ef0aec3d54c\",\"title\":\"Automatic Description Generation from Images: A Survey of Models, Datasets, and Evaluation Measures (Extended Abstract)\",\"url\":\"https://www.semanticscholar.org/paper/6e9aebe54f76d85c6df7e80faa761ef0aec3d54c\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":\"2011.00927\",\"authors\":[{\"authorId\":\"2000125058\",\"name\":\"Feicheng Huang\"},{\"authorId\":\"144111674\",\"name\":\"Zhixin Li\"},{\"authorId\":\"92057141\",\"name\":\"H. Wei\"},{\"authorId\":\"104269832\",\"name\":\"Canlong Zhang\"},{\"authorId\":\"1998838209\",\"name\":\"Huifang Ma\"}],\"doi\":\"10.1007/s10994-020-05919-y\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"899b365ce70207f1fd456e982583841d9e4701bf\",\"title\":\"Boost Image Captioning with Knowledge Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/899b365ce70207f1fd456e982583841d9e4701bf\",\"venue\":\"Mach. Learn.\",\"year\":2020},{\"arxivId\":\"1702.05552\",\"authors\":[{\"authorId\":\"34735743\",\"name\":\"T. Fernando\"},{\"authorId\":\"1980700\",\"name\":\"Simon Denman\"},{\"authorId\":\"1729760\",\"name\":\"S. Sridharan\"},{\"authorId\":\"3140440\",\"name\":\"C. Fookes\"}],\"doi\":\"10.1016/j.neunet.2018.09.002\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1939447e7ee0140d0e3580a27bd9d71782bc2e9c\",\"title\":\"Soft + Hardwired Attention: An LSTM Framework for Human Trajectory Prediction and Abnormal Event Detection\",\"url\":\"https://www.semanticscholar.org/paper/1939447e7ee0140d0e3580a27bd9d71782bc2e9c\",\"venue\":\"Neural Networks\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4942547\",\"name\":\"Zongjian Zhang\"},{\"authorId\":\"145698633\",\"name\":\"Q. Wu\"},{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"145093625\",\"name\":\"F. Chen\"}],\"doi\":\"10.1109/WACV.2018.00190\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6107d5107e7e0d94a3f0f43b642c4cfd1cba3b79\",\"title\":\"Fine-Grained and Semantic-Guided Visual Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6107d5107e7e0d94a3f0f43b642c4cfd1cba3b79\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":\"2002.06436\",\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4ad005019f7069a3aaff959fbaa657f2ef2143fc\",\"title\":\"MRRC: Multiple Role Representation Crossover Interpretation for Image Captioning With R-CNN Feature Distribution Composition (FDC)\",\"url\":\"https://www.semanticscholar.org/paper/4ad005019f7069a3aaff959fbaa657f2ef2143fc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50597618\",\"name\":\"S. Venkatesan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9e3bdb3776dc13e81be4b4c94b372e2a2bb3c01e\",\"title\":\"Understanding, Exploiting and Improving Inter-view Relationships\",\"url\":\"https://www.semanticscholar.org/paper/9e3bdb3776dc13e81be4b4c94b372e2a2bb3c01e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145328879\",\"name\":\"M. Li\"},{\"authorId\":\"120826117\",\"name\":\"Da Yu\"},{\"authorId\":\"3492315\",\"name\":\"Ziming Chen\"},{\"authorId\":\"30848593\",\"name\":\"K. Xiahou\"},{\"authorId\":\"145336004\",\"name\":\"T. Ji\"},{\"authorId\":\"145048944\",\"name\":\"Q. Wu\"}],\"doi\":\"10.1109/TSTE.2018.2853990\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b400b570c3e9e1f265ef94fe14a1b9c0c0f007c5\",\"title\":\"A Data-Driven Residual-Based Method for Fault Diagnosis and Isolation in Wind Turbines\",\"url\":\"https://www.semanticscholar.org/paper/b400b570c3e9e1f265ef94fe14a1b9c0c0f007c5\",\"venue\":\"IEEE Transactions on Sustainable Energy\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3409740\",\"name\":\"Ziyu Xue\"},{\"authorId\":\"39494411\",\"name\":\"Lei Wang\"},{\"authorId\":\"2834810\",\"name\":\"Peiyu Guo\"}],\"doi\":\"10.1109/icis46139.2019.8940218\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7344b254af85b53c5e989579b1d18fbf946c03de\",\"title\":\"Slot based Image Captioning with WGAN\",\"url\":\"https://www.semanticscholar.org/paper/7344b254af85b53c5e989579b1d18fbf946c03de\",\"venue\":\"2019 IEEE/ACIS 18th International Conference on Computer and Information Science (ICIS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"153152064\",\"name\":\"A. Liu\"},{\"authorId\":\"153576783\",\"name\":\"Weizhi Nie\"},{\"authorId\":\"2788104\",\"name\":\"Yuting Su\"},{\"authorId\":\"48693981\",\"name\":\"J. Nie\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.1109/TMM.2019.2941820\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"aff890f20d28a13b9fb89d192fad35d92381c410\",\"title\":\"Multi-Level Policy and Reward-Based Deep Reinforcement Learning Framework for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/aff890f20d28a13b9fb89d192fad35d92381c410\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151430668\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s11042-019-08021-1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1ba03c16bf25d33efc0d977ab51392e1d9b5a0fb\",\"title\":\"Survey of deep learning and architectures for visual captioning\\u2014transitioning between media and natural languages\",\"url\":\"https://www.semanticscholar.org/paper/1ba03c16bf25d33efc0d977ab51392e1d9b5a0fb\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150197175\",\"name\":\"L. Zhou\"},{\"authorId\":\"49890476\",\"name\":\"Yuejie Zhang\"},{\"authorId\":\"49296155\",\"name\":\"Y. Jiang\"},{\"authorId\":\"145326655\",\"name\":\"Tao Zhang\"},{\"authorId\":\"145631869\",\"name\":\"W. Fan\"}],\"doi\":\"10.1109/TIP.2019.2928144\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"95db18799c539c82379585d25af66fd968ff000c\",\"title\":\"Re-Caption: Saliency-Enhanced Image Captioning Through Two-Phase Learning\",\"url\":\"https://www.semanticscholar.org/paper/95db18799c539c82379585d25af66fd968ff000c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2000125058\",\"name\":\"Feicheng Huang\"},{\"authorId\":\"49969428\",\"name\":\"Z. Li\"},{\"authorId\":\"1856671082\",\"name\":\"Shengjia Chen\"},{\"authorId\":\"104269832\",\"name\":\"Canlong Zhang\"},{\"authorId\":\"1998838209\",\"name\":\"Huifang Ma\"}],\"doi\":\"10.1145/3340531.3411948\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"3428bac9141f6db961fc4665db1cbc9a196152da\",\"title\":\"Image Captioning with Internal and External Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/3428bac9141f6db961fc4665db1cbc9a196152da\",\"venue\":\"CIKM\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4247049\",\"name\":\"Jingyu Liu\"},{\"authorId\":\"39685680\",\"name\":\"Wei Wang\"},{\"authorId\":\"144143335\",\"name\":\"L. Wang\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/TIP.2020.2979010\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2d8e70022d5ee5cfd5a51f8d8bdba876ff6bda5f\",\"title\":\"Attribute-Guided Attention for Referring Expression Generation and Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/2d8e70022d5ee5cfd5a51f8d8bdba876ff6bda5f\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1611.08002\",\"authors\":[{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"2750075\",\"name\":\"Y. Pu\"},{\"authorId\":\"143690259\",\"name\":\"K. Tran\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"}],\"doi\":\"10.1109/CVPR.2017.127\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"778ce81457383bd5e3fdb11b145ded202ebb4970\",\"title\":\"Semantic Compositional Networks for Visual Captioning\",\"url\":\"https://www.semanticscholar.org/paper/778ce81457383bd5e3fdb11b145ded202ebb4970\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1703.06233\",\"authors\":[{\"authorId\":\"36508529\",\"name\":\"Arun Mallya\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1109/ICCV.2017.57\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"afc7d76c94c9b73aa28f4aa42407b21aa0572a1b\",\"title\":\"Recurrent Models for Situation Recognition\",\"url\":\"https://www.semanticscholar.org/paper/afc7d76c94c9b73aa28f4aa42407b21aa0572a1b\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2642638\",\"name\":\"F. Chen\"},{\"authorId\":\"145592290\",\"name\":\"R. Ji\"},{\"authorId\":\"34739384\",\"name\":\"Jinsong Su\"},{\"authorId\":\"47096329\",\"name\":\"Yongjian Wu\"},{\"authorId\":\"10609538\",\"name\":\"Y. Wu\"}],\"doi\":\"10.1145/3123266.3123275\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"159d16cdc48135632c2d5790e5baaf8d0631f510\",\"title\":\"StructCap: Structured Semantic Embedding for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/159d16cdc48135632c2d5790e5baaf8d0631f510\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50244843\",\"name\":\"E. Barsoum\"}],\"doi\":\"10.7916/d8-sq89-mm29\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d8d9ab14c06bbbe084232517c8a67581d16d4ef0\",\"title\":\"Human Motion Anticipation and Recognition from RGB-D\",\"url\":\"https://www.semanticscholar.org/paper/d8d9ab14c06bbbe084232517c8a67581d16d4ef0\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2301765\",\"name\":\"Tsung-Wei Ke\"},{\"authorId\":\"3172276\",\"name\":\"Che-Wei Lin\"},{\"authorId\":\"1805102\",\"name\":\"Tyng-Luh Liu\"},{\"authorId\":\"14489533\",\"name\":\"D. Geiger\"}],\"doi\":\"10.1007/978-3-319-54190-7_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d1df74a5047e953766fa07dec356bba285c605a1\",\"title\":\"Variational Convolutional Networks for Human-Centric Annotations\",\"url\":\"https://www.semanticscholar.org/paper/d1df74a5047e953766fa07dec356bba285c605a1\",\"venue\":\"ACCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11611009\",\"name\":\"Chun-ye Li\"},{\"authorId\":\"78507285\",\"name\":\"Zhiping Zhou\"},{\"authorId\":\"41052788\",\"name\":\"W. Zhang\"}],\"doi\":\"10.1007/s11042-019-08165-0\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0a59a5ed672dda9f45187bdb7727922e21f24fd9\",\"title\":\"An image retrieval method based on semantic matching with multiple positional representations\",\"url\":\"https://www.semanticscholar.org/paper/0a59a5ed672dda9f45187bdb7727922e21f24fd9\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":\"2012.15378\",\"authors\":[{\"authorId\":\"47223178\",\"name\":\"E. Barsoum\"},{\"authorId\":\"1719062\",\"name\":\"J. Kender\"},{\"authorId\":\"1691128\",\"name\":\"Zicheng Liu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f8f5efc7deba7d9cf8c51779875063679ecceabe\",\"title\":\"3D Human motion anticipation and classification\",\"url\":\"https://www.semanticscholar.org/paper/f8f5efc7deba7d9cf8c51779875063679ecceabe\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2881137\",\"name\":\"Junhwi Choi\"},{\"authorId\":\"40405891\",\"name\":\"Seonghan Ryu\"},{\"authorId\":\"1723357\",\"name\":\"H. Yu\"},{\"authorId\":\"1735513\",\"name\":\"G. Lee\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"faba465d55ec43b97fb16fd8973d8646914964fd\",\"title\":\"Guided Sequence Generation using Trie-based Dictionary for ASR Error Correction\",\"url\":\"https://www.semanticscholar.org/paper/faba465d55ec43b97fb16fd8973d8646914964fd\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39772032\",\"name\":\"C. Liu\"},{\"authorId\":\"143823065\",\"name\":\"F. Sun\"},{\"authorId\":\"39506391\",\"name\":\"B. Zhang\"}],\"doi\":\"10.26599/BSA.2018.9050004\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"27a02257a76a0f05d70fcc69102981fc067401c7\",\"title\":\"Brain-inspired Multimodal Learning Based on Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/27a02257a76a0f05d70fcc69102981fc067401c7\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1804472\",\"name\":\"H. Chen\"},{\"authorId\":\"38329336\",\"name\":\"G. Ding\"},{\"authorId\":\"1818920\",\"name\":\"Zijia Lin\"},{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"}],\"doi\":\"10.24963/ijcai.2018/84\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b4ae889c38444939ae4312ab38bf7036f6df739f\",\"title\":\"Show, Observe and Tell: Attribute-driven Attention Model for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/b4ae889c38444939ae4312ab38bf7036f6df739f\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152924581\",\"name\":\"Jicheng Wang\"},{\"authorId\":\"51288875\",\"name\":\"Y. Zhou\"},{\"authorId\":\"1438588470\",\"name\":\"Zhenzhen Hu\"},{\"authorId\":\"47957556\",\"name\":\"X. Zhang\"},{\"authorId\":\"31048669\",\"name\":\"M. Wang\"}],\"doi\":\"10.1007/s11042-019-08439-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0c48de74a40736498d6443f84ecdddc08275359f\",\"title\":\"Sequential image encoding for vision-to-language problems\",\"url\":\"https://www.semanticscholar.org/paper/0c48de74a40736498d6443f84ecdddc08275359f\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40564040\",\"name\":\"J. Wu\"},{\"authorId\":\"37403439\",\"name\":\"H. Hu\"},{\"authorId\":\"40468514\",\"name\":\"Liang Yang\"}],\"doi\":\"10.1145/3336495\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"715fe60a8615d283c70d12db13857d8948baebca\",\"title\":\"Pseudo-3D Attention Transfer Network with Content-aware Strategy for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/715fe60a8615d283c70d12db13857d8948baebca\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144603000\",\"name\":\"Xinwei He\"},{\"authorId\":\"2276155\",\"name\":\"Baoguang Shi\"},{\"authorId\":\"145905113\",\"name\":\"X. Bai\"},{\"authorId\":\"39943835\",\"name\":\"Gui-Song Xia\"},{\"authorId\":\"145274329\",\"name\":\"Zhaoxiang Zhang\"},{\"authorId\":\"2872774\",\"name\":\"W. Dong\"}],\"doi\":\"10.1016/J.PATREC.2017.10.018\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"390d0bb977b7473b8b76d045875c767d743de943\",\"title\":\"Image Caption Generation with Part of Speech Guidance\",\"url\":\"https://www.semanticscholar.org/paper/390d0bb977b7473b8b76d045875c767d743de943\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151487400\",\"name\":\"Chu-yi Li\"},{\"authorId\":\"9319341\",\"name\":\"Wei-yu Yu\"}],\"doi\":\"10.1117/12.2514651\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ddbc1542476237b6ace7b871e34269e790d35bad\",\"title\":\"Spatial-temporal attention in Bi-LSTM networks based on multiple features for video captioning\",\"url\":\"https://www.semanticscholar.org/paper/ddbc1542476237b6ace7b871e34269e790d35bad\",\"venue\":\"Other Conferences\",\"year\":2018},{\"arxivId\":\"1911.10132\",\"authors\":[{\"authorId\":\"151430668\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s11042-020-09865-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c8f8ea39c64cf08792cd49c6ad04e85e3b90c88f\",\"title\":\"CRUR: Coupled-Recurrent Unit for Unification, Conceptualization and Context Capture for Language Representation - A Generalization of Bi Directional LSTM\",\"url\":\"https://www.semanticscholar.org/paper/c8f8ea39c64cf08792cd49c6ad04e85e3b90c88f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8772234\",\"name\":\"Hyeryun Park\"},{\"authorId\":\"113066066\",\"name\":\"Kyungmo Kim\"},{\"authorId\":\"72062486\",\"name\":\"J. Yoon\"},{\"authorId\":\"31171717\",\"name\":\"Seongkeun Park\"},{\"authorId\":\"153439158\",\"name\":\"Jinwook Choi\"}],\"doi\":\"10.18653/v1/2020.acl-srw.14\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3b85f64b0a7c8eabd11476fa870b14b4ec696166\",\"title\":\"Feature Difference Makes Sense: A medical image captioning model exploiting feature difference and tag information\",\"url\":\"https://www.semanticscholar.org/paper/3b85f64b0a7c8eabd11476fa870b14b4ec696166\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"1707.06342\",\"authors\":[{\"authorId\":\"2119576\",\"name\":\"Jian-Hao Luo\"},{\"authorId\":\"1808816\",\"name\":\"Jianxin Wu\"},{\"authorId\":\"8131625\",\"name\":\"W. Lin\"}],\"doi\":\"10.1109/ICCV.2017.541\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"049fd80f52c0b1fa4d532945d95a24734b62bdf3\",\"title\":\"ThiNet: A Filter Level Pruning Method for Deep Neural Network Compression\",\"url\":\"https://www.semanticscholar.org/paper/049fd80f52c0b1fa4d532945d95a24734b62bdf3\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1723672\",\"name\":\"X. Zhang\"},{\"authorId\":\"2548483\",\"name\":\"Shengfeng He\"},{\"authorId\":\"1688375\",\"name\":\"Xinhang Song\"},{\"authorId\":\"145402398\",\"name\":\"Pengxu Wei\"},{\"authorId\":\"1696610\",\"name\":\"S. Jiang\"},{\"authorId\":\"1694936\",\"name\":\"Q. Ye\"},{\"authorId\":\"24350293\",\"name\":\"J. Jiao\"},{\"authorId\":\"1726262\",\"name\":\"R. Lau\"}],\"doi\":\"10.1109/ICME.2017.8019525\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e4b5bc8ee9632d7ff2f23e92295189dad9522864\",\"title\":\"Keyword-driven image captioning via Context-dependent Bilateral LSTM\",\"url\":\"https://www.semanticscholar.org/paper/e4b5bc8ee9632d7ff2f23e92295189dad9522864\",\"venue\":\"2017 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3186804\",\"name\":\"Xinxin Zhu\"},{\"authorId\":\"1761970\",\"name\":\"L. Li\"},{\"authorId\":null,\"name\":\"Jing Liu\"},{\"authorId\":\"46948270\",\"name\":\"Ziyi Li\"},{\"authorId\":\"7475375\",\"name\":\"H. Peng\"},{\"authorId\":\"3712008\",\"name\":\"X. Niu\"}],\"doi\":\"10.1016/j.neucom.2018.08.069\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"299c4aebcc81dd311f5632f3eec5f8a3bd17a226\",\"title\":\"Image captioning with triple-attention and stack parallel LSTM\",\"url\":\"https://www.semanticscholar.org/paper/299c4aebcc81dd311f5632f3eec5f8a3bd17a226\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2099537\",\"name\":\"Seungryong Kim\"},{\"authorId\":\"144442279\",\"name\":\"K. Sohn\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f21e41712ae60560021942c5696c5f309585407e\",\"title\":\"Tri-modal Recurrent Attention Networks for Emotion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f21e41712ae60560021942c5696c5f309585407e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9734988\",\"name\":\"Yuecong Xu\"},{\"authorId\":\"2562263\",\"name\":\"Jianfei Yang\"},{\"authorId\":\"144067957\",\"name\":\"K. Mao\"}],\"doi\":\"10.1016/J.NEUCOM.2019.05.027\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fd9a6ff5f908a6e8e785eb0a1432a5c9da2c2192\",\"title\":\"Semantic-filtered Soft-Split-Aware video captioning with audio-augmented feature\",\"url\":\"https://www.semanticscholar.org/paper/fd9a6ff5f908a6e8e785eb0a1432a5c9da2c2192\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144478646\",\"name\":\"Z. Guo\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"47158869\",\"name\":\"Xing Xu\"},{\"authorId\":\"145496509\",\"name\":\"Jie Shao\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1145/2964284.2967242\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"90c4a6c6f790dbcef9a29c9a755458be09e319b6\",\"title\":\"Attention-based LSTM with Semantic Consistency for Videos Captioning\",\"url\":\"https://www.semanticscholar.org/paper/90c4a6c6f790dbcef9a29c9a755458be09e319b6\",\"venue\":\"ACM Multimedia\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"dd7062e6f84750688fa96143209efc801e91f9bd\",\"title\":\"Visual Understanding through Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/dd7062e6f84750688fa96143209efc801e91f9bd\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49528055\",\"name\":\"Hanzhang Wang\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"3187665\",\"name\":\"Kaisheng Xu\"}],\"doi\":\"10.1016/j.neucom.2020.03.087\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f1c830d89069401945c430c6ddccc3ea4b3bd924\",\"title\":\"Evolutionary recurrent neural network for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/f1c830d89069401945c430c6ddccc3ea4b3bd924\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47672526\",\"name\":\"Shiwei Wang\"},{\"authorId\":\"2410125\",\"name\":\"Long Lan\"},{\"authorId\":\"46447554\",\"name\":\"Xiaodong Zhang\"},{\"authorId\":\"48593034\",\"name\":\"Guohua Dong\"},{\"authorId\":\"145254061\",\"name\":\"Z. Luo\"}],\"doi\":\"10.1109/ACCESS.2019.2917979\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c5a759bbf042fe8852f23567cf14daf3d9f180bc\",\"title\":\"Cascade Semantic Fusion for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/c5a759bbf042fe8852f23567cf14daf3d9f180bc\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Shuang Peng\"},{\"authorId\":\"31385650\",\"name\":\"H. Chen\"},{\"authorId\":\"144369496\",\"name\":\"Chun Du\"},{\"authorId\":\"46276037\",\"name\":\"Jun Yu Li\"},{\"authorId\":\"47838875\",\"name\":\"N. Jing\"}],\"doi\":\"10.1109/ACCESS.2018.2877687\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7acead6998a8a229902bfc4aeb3424b2fe9f82fe\",\"title\":\"Onboard Observation Task Planning for an Autonomous Earth Observation Satellite Using Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/7acead6998a8a229902bfc4aeb3424b2fe9f82fe\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144751998\",\"name\":\"C. He\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1007/s11063-018-9807-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8ea4f967ed643d12d74cb1cddbb9b1849fa3e892\",\"title\":\"Image Captioning with Text-Based Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/8ea4f967ed643d12d74cb1cddbb9b1849fa3e892\",\"venue\":\"Neural Processing Letters\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145293956\",\"name\":\"Zhihao Zhu\"},{\"authorId\":\"14598300\",\"name\":\"Zhan Xue\"},{\"authorId\":\"33762094\",\"name\":\"Zejian Yuan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4eb2d13871582ae4d1d744ff1f7945e12880693f\",\"title\":\"Think and Tell: Preview Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/4eb2d13871582ae4d1d744ff1f7945e12880693f\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2250564\",\"name\":\"Leiquan Wang\"},{\"authorId\":\"15862607\",\"name\":\"Xiaoliang Chu\"},{\"authorId\":\"1954076\",\"name\":\"W. Zhang\"},{\"authorId\":\"19261873\",\"name\":\"Yiwei Wei\"},{\"authorId\":\"2037988\",\"name\":\"Weichen Sun\"},{\"authorId\":\"32324177\",\"name\":\"C. Wu\"}],\"doi\":\"10.3390/s18020646\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e4b9c14951cea6259dd9d522586ba2c5bb1fbcce\",\"title\":\"Social Image Captioning: Exploring Visual Attention and User Attention\",\"url\":\"https://www.semanticscholar.org/paper/e4b9c14951cea6259dd9d522586ba2c5bb1fbcce\",\"venue\":\"Sensors\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143677598\",\"name\":\"Ran Tao\"},{\"authorId\":\"2304222\",\"name\":\"Efstratios Gavves\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"970e0a18fe46aeb94647be19842d2f800147b95e\",\"title\":\"UvA-DARE ( Digital Academic Repository ) Tracking by Natural Language Specification\",\"url\":\"https://www.semanticscholar.org/paper/970e0a18fe46aeb94647be19842d2f800147b95e\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2900840\",\"name\":\"Z. Cheng\"},{\"authorId\":\"1813326\",\"name\":\"Y. Zhou\"}],\"doi\":\"10.1109/SMC.2018.00356\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fc403f2b235cf2fa365b7d5ffd84facdfbc0b8ce\",\"title\":\"Finger-Worn Device Based Hand Gesture Recognition Using Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/fc403f2b235cf2fa365b7d5ffd84facdfbc0b8ce\",\"venue\":\"2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47666284\",\"name\":\"H. Chen\"},{\"authorId\":\"49723481\",\"name\":\"Huan Zhang\"},{\"authorId\":\"153191489\",\"name\":\"P. Chen\"},{\"authorId\":\"2882166\",\"name\":\"Jinfeng Yi\"},{\"authorId\":\"1793529\",\"name\":\"C. Hsieh\"}],\"doi\":\"10.18653/v1/P18-1241\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"77685c77a1fa39890006fe13f43738aac49a2c51\",\"title\":\"Attacking Visual Language Grounding with Adversarial Examples: A Case Study on Neural Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/77685c77a1fa39890006fe13f43738aac49a2c51\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47591102\",\"name\":\"F. Chen\"},{\"authorId\":\"152566316\",\"name\":\"Songxian Xie\"},{\"authorId\":\"48570095\",\"name\":\"Xinyi Li\"},{\"authorId\":\"98482203\",\"name\":\"S. Li\"},{\"authorId\":\"1762106\",\"name\":\"Jintao Tang\"},{\"authorId\":\"1749687\",\"name\":\"Ting Wang\"}],\"doi\":\"10.1109/ICMEW.2019.00083\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"beaee074a9548022527c2a5a45a64861df7784ea\",\"title\":\"What Topics Do Images Say: A Neural Image Captioning Model with Topic Representation\",\"url\":\"https://www.semanticscholar.org/paper/beaee074a9548022527c2a5a45a64861df7784ea\",\"venue\":\"2019 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143780023\",\"name\":\"Zhong Ji\"},{\"authorId\":\"103571514\",\"name\":\"Erlu He\"},{\"authorId\":\"49528408\",\"name\":\"H. Wang\"},{\"authorId\":\"1700859\",\"name\":\"Aiping Yang\"}],\"doi\":\"10.1016/J.PATREC.2019.01.010\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"be0b96235fc070f1c2847ba3a858c558f60e243a\",\"title\":\"Image-attribute reciprocally guided attention network for pedestrian attribute recognition\",\"url\":\"https://www.semanticscholar.org/paper/be0b96235fc070f1c2847ba3a858c558f60e243a\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2643775\",\"name\":\"Zhongyu Liu\"},{\"authorId\":\"153489843\",\"name\":\"T. Chen\"},{\"authorId\":\"3091544\",\"name\":\"Enjie Ding\"},{\"authorId\":\"46398350\",\"name\":\"Y. Liu\"},{\"authorId\":\"145909567\",\"name\":\"Wanli Yu\"}],\"doi\":\"10.1109/ACCESS.2020.3010872\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d6d66e02be2972957c2579cdc4dd46b5b0a5369d\",\"title\":\"Attention-Based Convolutional LSTM for Describing Video\",\"url\":\"https://www.semanticscholar.org/paper/d6d66e02be2972957c2579cdc4dd46b5b0a5369d\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152506137\",\"name\":\"F. Zhu\"},{\"authorId\":\"152539938\",\"name\":\"J. Xie\"},{\"authorId\":\"144145644\",\"name\":\"Yi Fang\"}],\"doi\":\"10.1007/978-3-319-46478-7_19\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8436989f7e93aefd34fac2aa6cfdf6deaa4b4eb6\",\"title\":\"Heat Diffusion Long-Short Term Memory Learning for 3D Shape Analysis\",\"url\":\"https://www.semanticscholar.org/paper/8436989f7e93aefd34fac2aa6cfdf6deaa4b4eb6\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3187665\",\"name\":\"Kaisheng Xu\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"8275214\",\"name\":\"P. Tang\"}],\"doi\":\"10.1109/ICME.2017.8019408\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2bb66ba1ef18110b422a8a7a2ce0e6400181b952\",\"title\":\"Image captioning with deep LSTM based on sequential residual\",\"url\":\"https://www.semanticscholar.org/paper/2bb66ba1ef18110b422a8a7a2ce0e6400181b952\",\"venue\":\"2017 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2017},{\"arxivId\":\"1901.07878\",\"authors\":[{\"authorId\":\"145045115\",\"name\":\"C. Otto\"},{\"authorId\":\"65987408\",\"name\":\"Sebastian Holzki\"},{\"authorId\":\"1738703\",\"name\":\"R. Ewerth\"}],\"doi\":\"10.1007/978-3-030-15712-8_46\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d2b23c7ad4d5bc263855dbb0237c9eef4bfd689f\",\"title\":\"\\\"Is this an example image?\\\" - Predicting the Relative Abstractness Level of Image and Text\",\"url\":\"https://www.semanticscholar.org/paper/d2b23c7ad4d5bc263855dbb0237c9eef4bfd689f\",\"venue\":\"ECIR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144081629\",\"name\":\"Mario G\\u00f3mez Mart\\u00ednez\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"faa8314259e9de1af8e841c265b0251531b32e04\",\"title\":\"Deep learning for image captioning: an encoder-decoder architecture with soft attention\",\"url\":\"https://www.semanticscholar.org/paper/faa8314259e9de1af8e841c265b0251531b32e04\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2375133\",\"name\":\"Xiaoyu Duan\"},{\"authorId\":\"1944376232\",\"name\":\"Shi Ying\"},{\"authorId\":\"50435842\",\"name\":\"Hailong Cheng\"},{\"authorId\":\"46421795\",\"name\":\"Wanli Yuan\"},{\"authorId\":\"152544077\",\"name\":\"Xiang Yin\"}],\"doi\":\"10.1016/j.is.2020.101618\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7bbd316f8bf74c7d4c10b554e3ab133f6af2e9e3\",\"title\":\"OILog: An online incremental log keyword extraction approach based on MDP-LSTM neural network\",\"url\":\"https://www.semanticscholar.org/paper/7bbd316f8bf74c7d4c10b554e3ab133f6af2e9e3\",\"venue\":\"Inf. Syst.\",\"year\":2021},{\"arxivId\":\"1907.09358\",\"authors\":[{\"authorId\":\"3219864\",\"name\":\"Aditya Mogadala\"},{\"authorId\":\"151119369\",\"name\":\"M. Kalimuthu\"},{\"authorId\":\"2561225\",\"name\":\"D. Klakow\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f8a48678094adbe421d61d0045361bfc635a2900\",\"title\":\"Trends in Integration of Vision and Language Research: A Survey of Tasks, Datasets, and Methods\",\"url\":\"https://www.semanticscholar.org/paper/f8a48678094adbe421d61d0045361bfc635a2900\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32730921\",\"name\":\"J. Wang\"},{\"authorId\":\"1795646\",\"name\":\"Z. Cao\"},{\"authorId\":\"144209660\",\"name\":\"Yang Xiao\"},{\"authorId\":\"4634604\",\"name\":\"Xinyuan Qi\"}],\"doi\":\"10.1117/12.2284665\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"aca34f9dfdd471e64c0cb7aaa88a2cdf64df66ad\",\"title\":\"Supervised guiding long-short term memory for image caption generation based on object classes\",\"url\":\"https://www.semanticscholar.org/paper/aca34f9dfdd471e64c0cb7aaa88a2cdf64df66ad\",\"venue\":\"International Symposium on Multispectral Image Processing and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"103382547\",\"name\":\"Junzhong Ji\"},{\"authorId\":\"49770078\",\"name\":\"C. Xu\"},{\"authorId\":\"46447188\",\"name\":\"X. Zhang\"},{\"authorId\":\"2692910\",\"name\":\"Boyue Wang\"},{\"authorId\":\"1688375\",\"name\":\"Xinhang Song\"}],\"doi\":\"10.1109/TIP.2020.3004729\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"63632ca4c1a6c16c9b6358624134880c3b23df90\",\"title\":\"Spatio-Temporal Memory Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/63632ca4c1a6c16c9b6358624134880c3b23df90\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yue Wang\"},{\"authorId\":\"46700331\",\"name\":\"J. Liu\"},{\"authorId\":\"1680068\",\"name\":\"X. Wang\"}],\"doi\":\"10.1145/3126686.3126714\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b5bfe824fc49fe78b538ac15f21c4cd6a9d44347\",\"title\":\"Image Caption with Synchronous Cross-Attention\",\"url\":\"https://www.semanticscholar.org/paper/b5bfe824fc49fe78b538ac15f21c4cd6a9d44347\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"104150443\",\"name\":\"Zeqin Huang\"},{\"authorId\":\"9118491\",\"name\":\"Zhongzhi Shi\"}],\"doi\":\"10.1007/978-3-030-46931-3_29\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f08ac1aa8bfc804414b1e5a2bb98203337368807\",\"title\":\"Image Caption Combined with GAN Training Method\",\"url\":\"https://www.semanticscholar.org/paper/f08ac1aa8bfc804414b1e5a2bb98203337368807\",\"venue\":\"Intelligent Information Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40564040\",\"name\":\"J. Wu\"},{\"authorId\":\"145030934\",\"name\":\"H. Hu\"}],\"doi\":\"10.1049/EL.2017.3159\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c499a1738be0915df2fa1f97c1f8671da1630bee\",\"title\":\"Cascade recurrent neural network for image caption generation\",\"url\":\"https://www.semanticscholar.org/paper/c499a1738be0915df2fa1f97c1f8671da1630bee\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1711.05557\",\"authors\":[{\"authorId\":\"143692915\",\"name\":\"Ying Hua Tan\"},{\"authorId\":\"2863960\",\"name\":\"Chee Seng Chan\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e70af721dbf04ab8aacc138d75c808588612289b\",\"title\":\"Phrase-based Image Captioning with Hierarchical LSTM Model\",\"url\":\"https://www.semanticscholar.org/paper/e70af721dbf04ab8aacc138d75c808588612289b\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47672151\",\"name\":\"Ning Xu\"},{\"authorId\":\"153152064\",\"name\":\"A. Liu\"},{\"authorId\":\"144536249\",\"name\":\"W. Nie\"},{\"authorId\":\"2788104\",\"name\":\"Yuting Su\"}],\"doi\":\"10.1007/s00530-018-0598-5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f386d25bfbb0399fd6c8116add5faa66ffcfa467\",\"title\":\"Multi-guiding long short-term memory for video captioning\",\"url\":\"https://www.semanticscholar.org/paper/f386d25bfbb0399fd6c8116add5faa66ffcfa467\",\"venue\":\"Multimedia Systems\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1735878\",\"name\":\"D. Zhao\"},{\"authorId\":\"144481850\",\"name\":\"Zhi Chang\"},{\"authorId\":\"50530237\",\"name\":\"Shutao Guo\"}],\"doi\":\"10.1016/j.neucom.2018.11.004\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5612a5adaf8152b85010bf57c322d2fabef0fd40\",\"title\":\"A multimodal fusion approach for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/5612a5adaf8152b85010bf57c322d2fabef0fd40\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"1807.08820\",\"authors\":[{\"authorId\":\"2325993\",\"name\":\"Yanbo Xu\"},{\"authorId\":\"3233864\",\"name\":\"S. Biswal\"},{\"authorId\":\"7164228\",\"name\":\"S. Deshpande\"},{\"authorId\":\"5525835\",\"name\":\"K. Maher\"},{\"authorId\":\"1738536\",\"name\":\"Jimeng Sun\"}],\"doi\":\"10.1145/3219819.3220051\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"3c3c4459da169b486628413258f2d79cdcb36fff\",\"title\":\"RAIM: Recurrent Attentive and Intensive Model of Multimodal Patient Monitoring Data\",\"url\":\"https://www.semanticscholar.org/paper/3c3c4459da169b486628413258f2d79cdcb36fff\",\"venue\":\"KDD\",\"year\":2018},{\"arxivId\":\"2001.09545\",\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"66a2eb540af6f47db177599bc793ab0c6a6aa47e\",\"title\":\"aiTPR: Attribute Interaction-Tensor Product Representation for Image Caption\",\"url\":\"https://www.semanticscholar.org/paper/66a2eb540af6f47db177599bc793ab0c6a6aa47e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39772032\",\"name\":\"C. Liu\"},{\"authorId\":\"1697065\",\"name\":\"C. Wang\"},{\"authorId\":\"40203750\",\"name\":\"F. Sun\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1145/2964284.2973831\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"47bf35a79a79e5155afc7573c5de2b690504fb94\",\"title\":\"Image2Text: A Multimodal Image Captioner\",\"url\":\"https://www.semanticscholar.org/paper/47bf35a79a79e5155afc7573c5de2b690504fb94\",\"venue\":\"ACM Multimedia\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2786437\",\"name\":\"Linghui Li\"},{\"authorId\":\"144044848\",\"name\":\"Sheng Tang\"},{\"authorId\":\"2031845\",\"name\":\"Junbo Guo\"},{\"authorId\":null,\"name\":\"Rui Wang\"},{\"authorId\":\"144241178\",\"name\":\"B. Lyu\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.1109/BigMM.2018.8499066\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9a830ef990527adef14fed8d05ef5df5b9c87d4c\",\"title\":\"Image Captioning Based on Adaptive Balancing Loss\",\"url\":\"https://www.semanticscholar.org/paper/9a830ef990527adef14fed8d05ef5df5b9c87d4c\",\"venue\":\"2018 IEEE Fourth International Conference on Multimedia Big Data (BigMM)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11474124\",\"name\":\"Sanjukta Mishra\"},{\"authorId\":\"3094150\",\"name\":\"M. Banerjee\"}],\"doi\":\"10.1007/978-981-15-2930-6_1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ee22142fb6788e2bb3b695e73df5b3bc36eb20ff\",\"title\":\"Automatic Caption Generation of Retinal Diseases with Self-trained RNN Merge Model\",\"url\":\"https://www.semanticscholar.org/paper/ee22142fb6788e2bb3b695e73df5b3bc36eb20ff\",\"venue\":\"ACSS\",\"year\":2020},{\"arxivId\":\"1506.01144\",\"authors\":[{\"authorId\":\"34902783\",\"name\":\"Qi Wu\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2016.29\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"00fe3d95d0fd5f1433d81405bee772c4fe9af9c6\",\"title\":\"What Value Do Explicit High Level Concepts Have in Vision to Language Problems?\",\"url\":\"https://www.semanticscholar.org/paper/00fe3d95d0fd5f1433d81405bee772c4fe9af9c6\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31394336\",\"name\":\"D. Dong\"},{\"authorId\":\"47056526\",\"name\":\"X. Li\"},{\"authorId\":\"7447984\",\"name\":\"Fuqiang Sun\"}],\"doi\":\"10.1109/PHM.2017.8079264\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e1be2ae3aea73167e6f96bfe0505fe77571c19f4\",\"title\":\"Life prediction of jet engines based on LSTM-recurrent neural networks\",\"url\":\"https://www.semanticscholar.org/paper/e1be2ae3aea73167e6f96bfe0505fe77571c19f4\",\"venue\":\"2017 Prognostics and System Health Management Conference (PHM-Harbin)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36595248\",\"name\":\"Fang Fang\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"8275214\",\"name\":\"P. Tang\"}],\"doi\":\"10.1109/ICIP.2018.8451558\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c5f6ed9efc222fe2773135ffb4e5c567d98e64ea\",\"title\":\"Image Captioning with Word Level Attention\",\"url\":\"https://www.semanticscholar.org/paper/c5f6ed9efc222fe2773135ffb4e5c567d98e64ea\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2932516\",\"name\":\"J. Zhang\"},{\"authorId\":\"1853471\",\"name\":\"K. Mei\"},{\"authorId\":\"1626610869\",\"name\":\"Yu Zheng\"},{\"authorId\":\"1692580\",\"name\":\"Jianping Fan\"}],\"doi\":\"10.1109/TMM.2020.2976552\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"27d838ae5a89cd54ef1cb6599484c794bd544ad9\",\"title\":\"Integrating Part of Speech Guidance for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/27d838ae5a89cd54ef1cb6599484c794bd544ad9\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1601207488\",\"name\":\"Jiyoung Lee\"},{\"authorId\":\"2352565\",\"name\":\"Sunok Kim\"},{\"authorId\":\"2099537\",\"name\":\"Seungryong Kim\"},{\"authorId\":\"144442279\",\"name\":\"K. Sohn\"}],\"doi\":\"10.1109/TIP.2020.2996086\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c9f020f72e75afb0150fbc6a29a537bdef427b02\",\"title\":\"Multi-Modal Recurrent Attention Networks for Facial Expression Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c9f020f72e75afb0150fbc6a29a537bdef427b02\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49478695\",\"name\":\"Teng Jiang\"},{\"authorId\":\"2598444\",\"name\":\"Chengjun Zhang\"},{\"authorId\":\"7607492\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1145/3319921.3319934\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1da9da475a471eacdb47a7f71d81cc3517188054\",\"title\":\"Reconstructing Attention with Dynamic Regularization\",\"url\":\"https://www.semanticscholar.org/paper/1da9da475a471eacdb47a7f71d81cc3517188054\",\"venue\":\"ICIAI 2019\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49776272\",\"name\":\"Pengfei Cao\"},{\"authorId\":\"47087612\",\"name\":\"Z. Yang\"},{\"authorId\":\"144526347\",\"name\":\"L. Sun\"},{\"authorId\":\"145629787\",\"name\":\"Y. Liang\"},{\"authorId\":\"1717198\",\"name\":\"M. Yang\"},{\"authorId\":\"144479376\",\"name\":\"Renchu Guan\"}],\"doi\":\"10.1007/s11063-018-09973-5\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"16efc1a4c7cdf8bc6d49cc326542e1fe1c88456b\",\"title\":\"Image Captioning with Bidirectional Semantic Attention-Based Guiding of Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/16efc1a4c7cdf8bc6d49cc326542e1fe1c88456b\",\"venue\":\"Neural Processing Letters\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98419684\",\"name\":\"Phil Kinghorn\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9549e8e59f5ce436cc4d81ddb859b3295d131c5b\",\"title\":\"Deep learning-based regional image caption generation with refined descriptions\",\"url\":\"https://www.semanticscholar.org/paper/9549e8e59f5ce436cc4d81ddb859b3295d131c5b\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152599891\",\"name\":\"Himanshu Sharma\"},{\"authorId\":\"1685484260\",\"name\":\"Manmohan Agrahari\"},{\"authorId\":\"49551081\",\"name\":\"S. K. Singh\"},{\"authorId\":\"1685691379\",\"name\":\"Mohd Firoj\"},{\"authorId\":\"145391619\",\"name\":\"R. K. Mishra\"}],\"doi\":\"10.1109/PARC49193.2020.236619\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fc50a1620b0210c9e9a21b6f62d3338010187032\",\"title\":\"Image Captioning: A Comprehensive Survey\",\"url\":\"https://www.semanticscholar.org/paper/fc50a1620b0210c9e9a21b6f62d3338010187032\",\"venue\":\"2020 International Conference on Power Electronics & IoT Applications in Renewable Energy and its Control (PARC)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40235164\",\"name\":\"J. Wu\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"},{\"authorId\":\"144084568\",\"name\":\"Yi Wu\"}],\"doi\":\"10.1145/3271485\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"744d79cfe0b38b2e674c7425dea67492d4f14807\",\"title\":\"Image Captioning via Semantic Guidance Attention and Consensus Selection Strategy\",\"url\":\"https://www.semanticscholar.org/paper/744d79cfe0b38b2e674c7425dea67492d4f14807\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2018},{\"arxivId\":\"1909.05693\",\"authors\":[{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"101377061\",\"name\":\"Zizhou Jia\"},{\"authorId\":\"144600412\",\"name\":\"H. Chen\"},{\"authorId\":\"2091623\",\"name\":\"L. Li\"},{\"authorId\":\"38329336\",\"name\":\"G. Ding\"},{\"authorId\":\"1732330\",\"name\":\"K. Keutzer\"}],\"doi\":\"10.1145/3343031.3351062\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"12c258108ab59ef0189a6deb47222a99269da212\",\"title\":\"PDANet: Polarity-consistent Deep Attention Network for Fine-grained Visual Emotion Regression\",\"url\":\"https://www.semanticscholar.org/paper/12c258108ab59ef0189a6deb47222a99269da212\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40469481\",\"name\":\"T. Nogueira\"},{\"authorId\":\"32535425\",\"name\":\"C. Vinhal\"},{\"authorId\":\"1491425913\",\"name\":\"G\\u00e9lson da Cruz J\\u00fanior\"},{\"authorId\":\"2569769\",\"name\":\"Matheus Rudolfo Diedrich Ullmann\"}],\"doi\":\"10.1007/s11042-020-09539-5\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"48f17b2b08aebd16e711f5c7ca9e773fe6639dc3\",\"title\":\"Reference-based model using multimodal gated recurrent units for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/48f17b2b08aebd16e711f5c7ca9e773fe6639dc3\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36595248\",\"name\":\"Fang Fang\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"50581334\",\"name\":\"Y. Chen\"},{\"authorId\":\"8275214\",\"name\":\"P. Tang\"}],\"doi\":\"10.1007/s11042-018-6228-6\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c580b0a8dc655a8831ddbb7954bb929b1f236ebc\",\"title\":\"Looking deeper and transferring attention for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/c580b0a8dc655a8831ddbb7954bb929b1f236ebc\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47672526\",\"name\":\"Shiwei Wang\"},{\"authorId\":\"2410125\",\"name\":\"Long Lan\"},{\"authorId\":\"49470127\",\"name\":\"X. Zhang\"},{\"authorId\":\"48593034\",\"name\":\"Guohua Dong\"},{\"authorId\":\"1406222945\",\"name\":\"Zhigang Luo\"}],\"doi\":\"10.1007/s11042-019-08209-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"311ee1284e6bdf035f8c3a1a20d00c5841b2e341\",\"title\":\"Object-aware semantics of attention for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/311ee1284e6bdf035f8c3a1a20d00c5841b2e341\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1804472\",\"name\":\"H. Chen\"},{\"authorId\":\"38329336\",\"name\":\"G. Ding\"},{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"60af58a2435fe758fe9a172f2009efbb89584f58\",\"title\":\"Temporal-Difference Learning With Sampling Baseline for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/60af58a2435fe758fe9a172f2009efbb89584f58\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1708.09666\",\"authors\":[{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"49252656\",\"name\":\"Jia Chen\"},{\"authorId\":\"1721329\",\"name\":\"Q. Jin\"}],\"doi\":\"10.1145/3078971.3079000\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d953d9767070bdb1f4f1af9e2a923dff047353cf\",\"title\":\"Generating Video Descriptions with Topic Guidance\",\"url\":\"https://www.semanticscholar.org/paper/d953d9767070bdb1f4f1af9e2a923dff047353cf\",\"venue\":\"ICMR\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144546798\",\"name\":\"Y. Han\"},{\"authorId\":\"144400646\",\"name\":\"J. He\"},{\"authorId\":\"35137026\",\"name\":\"Qiwen Dong\"}],\"doi\":\"10.1145/3292448.3292455\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"03c2948ed2591c35b92325485a79120e5ec1d9ac\",\"title\":\"CSSSketch2Code: An Automatic Method to Generate Web Pages with CSS Style\",\"url\":\"https://www.semanticscholar.org/paper/03c2948ed2591c35b92325485a79120e5ec1d9ac\",\"venue\":\"ICAAI 2018\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3238568\",\"name\":\"M. Liu\"},{\"authorId\":\"1485768948\",\"name\":\"Lingjun Li\"},{\"authorId\":\"146896370\",\"name\":\"H. Hu\"},{\"authorId\":\"15880069\",\"name\":\"W. Guan\"},{\"authorId\":\"153307124\",\"name\":\"J. Tian\"}],\"doi\":\"10.1016/j.ipm.2019.102178\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e4ba3a265763677dfb68567aa6b62cd5fe4a633b\",\"title\":\"Image caption generation with dual attention mechanism\",\"url\":\"https://www.semanticscholar.org/paper/e4ba3a265763677dfb68567aa6b62cd5fe4a633b\",\"venue\":\"Inf. Process. Manag.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144603000\",\"name\":\"Xinwei He\"},{\"authorId\":\"144757965\",\"name\":\"Y. Yang\"},{\"authorId\":\"2276155\",\"name\":\"Baoguang Shi\"},{\"authorId\":\"145905113\",\"name\":\"X. Bai\"}],\"doi\":\"10.1016/j.neucom.2018.02.106\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a24f013cbae0f349c54aaf958dca944d561a6efd\",\"title\":\"VD-SAN: Visual-Densely Semantic Attention Network for Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/a24f013cbae0f349c54aaf958dca944d561a6efd\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"1901.01939\",\"authors\":[{\"authorId\":\"8449394\",\"name\":\"A. Torfi\"},{\"authorId\":\"7664662\",\"name\":\"Rouzbeh A. Shirvani\"},{\"authorId\":\"30319988\",\"name\":\"Sobhan Soleymani\"},{\"authorId\":\"8147588\",\"name\":\"N. Nasrabadi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ad0ba8d57b2e09d091bfec7e48d717898cb25de0\",\"title\":\"GASL: Guided Attention for Sparsity Learning in Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/ad0ba8d57b2e09d091bfec7e48d717898cb25de0\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8859232\",\"name\":\"Xiaoci Zhang\"},{\"authorId\":\"38572972\",\"name\":\"N. Gu\"},{\"authorId\":\"145688358\",\"name\":\"Hong Ye\"},{\"authorId\":\"2840902\",\"name\":\"Chuanwen Lin\"}],\"doi\":\"10.1117/1.JEI.27.4.043056\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"39e94e064536daa0ed0d7e479c9886f14e234823\",\"title\":\"Vehicle license plate detection and recognition using deep neural networks and generative adversarial networks\",\"url\":\"https://www.semanticscholar.org/paper/39e94e064536daa0ed0d7e479c9886f14e234823\",\"venue\":\"J. Electronic Imaging\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s42979-020-00238-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3f732495721356944027051bb14100436a5dbdf5\",\"title\":\"AACR: Feature Fusion Effects of Algebraic Amalgamation Composed Representation on (De)Compositional Network for Caption Generation for Images\",\"url\":\"https://www.semanticscholar.org/paper/3f732495721356944027051bb14100436a5dbdf5\",\"venue\":\"SN Comput. Sci.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145414742\",\"name\":\"Kun Fu\"},{\"authorId\":\"2512850\",\"name\":\"Junqi Jin\"},{\"authorId\":\"2153397\",\"name\":\"Runpeng Cui\"},{\"authorId\":\"39543696\",\"name\":\"Fei Sha\"},{\"authorId\":\"14966740\",\"name\":\"Changshui Zhang\"}],\"doi\":\"10.1109/TPAMI.2016.2642953\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"afb353801ce723951f0d8f9ed4b5ff9b41615601\",\"title\":\"Aligning Where to See and What to Tell: Image Captioning with Region-Based Attention and Scene-Specific Contexts\",\"url\":\"https://www.semanticscholar.org/paper/afb353801ce723951f0d8f9ed4b5ff9b41615601\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144063214\",\"name\":\"M. Z. Hossain\"},{\"authorId\":\"19324907\",\"name\":\"F. Sohel\"},{\"authorId\":\"96363850\",\"name\":\"Mohd Fairuz Shiratuddin\"},{\"authorId\":\"47028380\",\"name\":\"Hamid Laga\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"}],\"doi\":\"10.1007/978-3-030-36802-9_13\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"53234e0927d63bb85121bea44f9a60edf0849a8e\",\"title\":\"Attention-Based Image Captioning Using DenseNet Features\",\"url\":\"https://www.semanticscholar.org/paper/53234e0927d63bb85121bea44f9a60edf0849a8e\",\"venue\":\"ICONIP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1804472\",\"name\":\"H. Chen\"},{\"authorId\":\"38329336\",\"name\":\"G. Ding\"},{\"authorId\":\"1818920\",\"name\":\"Zijia Lin\"},{\"authorId\":\"34811036\",\"name\":\"Yuchen Guo\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"}],\"doi\":\"10.1007/978-3-030-00563-4_16\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"18d99d29834ddd8c70878504998ca9f63f7b3ce1\",\"title\":\"Attend to Knowledge: Memory-Enhanced Attention Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/18d99d29834ddd8c70878504998ca9f63f7b3ce1\",\"venue\":\"BICS\",\"year\":2018},{\"arxivId\":\"1611.05594\",\"authors\":[{\"authorId\":\"143891667\",\"name\":\"Long Chen\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1406012647\",\"name\":\"Jun Xiao\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":\"104757141\",\"name\":\"Jian Shao\"},{\"authorId\":\"40366581\",\"name\":\"Wei Liu\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1109/CVPR.2017.667\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"88513e738a95840de05a62f0e43d30a67b3c542e\",\"title\":\"SCA-CNN: Spatial and Channel-Wise Attention in Convolutional Networks for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/88513e738a95840de05a62f0e43d30a67b3c542e\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48064309\",\"name\":\"L. Yang\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"},{\"authorId\":\"150311018\",\"name\":\"Songlong Xing\"},{\"authorId\":\"150344317\",\"name\":\"Xinlong Lu\"}],\"doi\":\"10.1145/3386725\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1546133a67bfab09c64a9e2875266b1286ccab55\",\"title\":\"Constrained LSTM and Residual Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/1546133a67bfab09c64a9e2875266b1286ccab55\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47908786\",\"name\":\"Y. Liu\"},{\"authorId\":\"1687503\",\"name\":\"Yanming Guo\"},{\"authorId\":\"1731570\",\"name\":\"M. Lew\"}],\"doi\":\"10.1007/978-3-319-51811-4_34\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"66156cb48fe184ea98be1c394f70cef78f63b1ae\",\"title\":\"What Convnets Make for Image Captioning?\",\"url\":\"https://www.semanticscholar.org/paper/66156cb48fe184ea98be1c394f70cef78f63b1ae\",\"venue\":\"MMM\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"}],\"doi\":\"10.1109/CVPR.2017.108\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"561ed7e47524fb3218e6a38f41cd877a9c33d3b9\",\"title\":\"StyleNet: Generating Attractive Visual Captions with Styles\",\"url\":\"https://www.semanticscholar.org/paper/561ed7e47524fb3218e6a38f41cd877a9c33d3b9\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1901.08942\",\"authors\":[{\"authorId\":\"143959713\",\"name\":\"Yimin Zhou\"},{\"authorId\":\"3156408\",\"name\":\"Y. Sun\"},{\"authorId\":\"145513516\",\"name\":\"Vasant G Honavar\"}],\"doi\":\"10.1109/WACV.2019.00036\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f4c45108cb41051010d8a5175b8da23eb246c967\",\"title\":\"Improving Image Captioning by Leveraging Knowledge Graphs\",\"url\":\"https://www.semanticscholar.org/paper/f4c45108cb41051010d8a5175b8da23eb246c967\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67010907\",\"name\":\"Martina Toshevska\"},{\"authorId\":\"67275493\",\"name\":\"Frosina Stojanovska\"},{\"authorId\":\"2269444\",\"name\":\"Eftim Zdravevski\"},{\"authorId\":\"1769456\",\"name\":\"Petre Lameski\"},{\"authorId\":\"144293427\",\"name\":\"S. Gievska\"}],\"doi\":\"10.15439/2020F57\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a8becc75e050e9ea52a1e4bb4faf9c1e39e5d599\",\"title\":\"Exploration into Deep Learning Text Generation Architectures for Dense Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/a8becc75e050e9ea52a1e4bb4faf9c1e39e5d599\",\"venue\":\"2020 15th Conference on Computer Science and Information Systems (FedCSIS)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1576152870\",\"name\":\"Xiaopeng Gong\"},{\"authorId\":\"1752239\",\"name\":\"Xiabi Liu\"},{\"authorId\":\"152998528\",\"name\":\"Yushuo Li\"},{\"authorId\":\"1471524979\",\"name\":\"Huiyu Li\"}],\"doi\":\"10.1016/j.imavis.2020.103973\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e87977613880444a029137a11ca04675a4cacb48\",\"title\":\"A novel co-attention computation block for deep learning based image co-segmentation\",\"url\":\"https://www.semanticscholar.org/paper/e87977613880444a029137a11ca04675a4cacb48\",\"venue\":\"Image Vis. Comput.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2037486210\",\"name\":\"Qiaoqiao Yang\"},{\"authorId\":\"1410201319\",\"name\":\"Guangxing Wang\"},{\"authorId\":\"1695975266\",\"name\":\"Xiaoyu Zhang\"},{\"authorId\":\"2037477833\",\"name\":\"Christos Grecos\"},{\"authorId\":\"143823414\",\"name\":\"Peng Ren\"}],\"doi\":\"10.2112/SI102-018.1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"556edd10f961c30fc523f291fe657db56a297850\",\"title\":\"Coastal Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/556edd10f961c30fc523f291fe657db56a297850\",\"venue\":\"Journal of Coastal Research\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2893664\",\"name\":\"Zeynep Akata\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"40894329\",\"name\":\"Stephan Alaniz\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1007/978-3-319-98131-4_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"86de19e783d717c5db77f96f707613c27bde2915\",\"title\":\"Generating Post-Hoc Rationales of Deep Visual Classification Decisions\",\"url\":\"https://www.semanticscholar.org/paper/86de19e783d717c5db77f96f707613c27bde2915\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1912.01881\",\"authors\":[{\"authorId\":\"1443435125\",\"name\":\"Zhengcong Fei\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"03158341c61b8bfedc9ccd503610ab150678a7c1\",\"title\":\"Better Understanding Hierarchical Visual Relationship for Image Caption\",\"url\":\"https://www.semanticscholar.org/paper/03158341c61b8bfedc9ccd503610ab150678a7c1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2786437\",\"name\":\"Linghui Li\"},{\"authorId\":\"46321465\",\"name\":\"Sheng Tang\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"},{\"authorId\":\"4303531\",\"name\":\"Lixi Deng\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/TMM.2017.2751140\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2e0f1c89c4e099b14c4d77bd406be9f7b78d6f6d\",\"title\":\"GLA: Global\\u2013Local Attention for Image Description\",\"url\":\"https://www.semanticscholar.org/paper/2e0f1c89c4e099b14c4d77bd406be9f7b78d6f6d\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144063214\",\"name\":\"M. Z. Hossain\"},{\"authorId\":\"19324907\",\"name\":\"F. Sohel\"},{\"authorId\":\"96363850\",\"name\":\"Mohd Fairuz Shiratuddin\"},{\"authorId\":\"48540238\",\"name\":\"Hamid Laga\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"}],\"doi\":\"10.1109/DICTA47822.2019.8946003\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"098833985221f9f30d547dadf24ae7b0f1433ef5\",\"title\":\"Bi-SAN-CAP: Bi-Directional Self-Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/098833985221f9f30d547dadf24ae7b0f1433ef5\",\"venue\":\"2019 Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152356310\",\"name\":\"Danyang Cao\"},{\"authorId\":\"152223852\",\"name\":\"Menggui Zhu\"},{\"authorId\":\"145735014\",\"name\":\"L. Gao\"}],\"doi\":\"10.1007/s11042-019-08116-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3e19260676bbc8185830528773d54b83ba3f12a2\",\"title\":\"An image caption method based on object detection\",\"url\":\"https://www.semanticscholar.org/paper/3e19260676bbc8185830528773d54b83ba3f12a2\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":\"2010.12267\",\"authors\":[{\"authorId\":\"1519970315\",\"name\":\"Xinsheng Wang\"},{\"authorId\":\"1514891263\",\"name\":\"Siyuan Feng\"},{\"authorId\":\"2237811\",\"name\":\"Jihua Zhu\"},{\"authorId\":\"1399115926\",\"name\":\"M. Hasegawa-Johnson\"},{\"authorId\":\"144951859\",\"name\":\"O. Scharenborg\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d7b2a37fac581795101120989c0ff76147938a4a\",\"title\":\"Show and Speak: Directly Synthesize Spoken Description of Images\",\"url\":\"https://www.semanticscholar.org/paper/d7b2a37fac581795101120989c0ff76147938a4a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46740305\",\"name\":\"Chunlei Wu\"},{\"authorId\":\"19261873\",\"name\":\"Yiwei Wei\"},{\"authorId\":\"15862607\",\"name\":\"Xiaoliang Chu\"},{\"authorId\":\"152343380\",\"name\":\"Fei Su\"},{\"authorId\":\"2250564\",\"name\":\"Leiquan Wang\"}],\"doi\":\"10.1016/j.image.2018.06.002\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f20d5a6f10c269582bd00fd4733bb0066faee302\",\"title\":\"Modeling visual and word-conditional semantic attention for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/f20d5a6f10c269582bd00fd4733bb0066faee302\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2018},{\"arxivId\":\"1709.01424\",\"authors\":[{\"authorId\":\"2084534\",\"name\":\"Maedeh Aghaei\"},{\"authorId\":\"2837527\",\"name\":\"Mariella Dimiccoli\"},{\"authorId\":\"1399086207\",\"name\":\"C. Canton-Ferrer\"},{\"authorId\":\"143601910\",\"name\":\"P. Radeva\"}],\"doi\":\"10.1016/j.cviu.2018.05.001\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ee8466a8bda15534cb862b420a8a51bb333cf06e\",\"title\":\"Towards social pattern characterization in egocentric photo-streams\",\"url\":\"https://www.semanticscholar.org/paper/ee8466a8bda15534cb862b420a8a51bb333cf06e\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153730333\",\"name\":\"V. Kumar\"},{\"authorId\":\"1703799\",\"name\":\"S. Joshi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"269ed5ba525519502123b58472e069d77c5bda14\",\"title\":\"Non-sentential Question Resolution using Sequence to Sequence Learning\",\"url\":\"https://www.semanticscholar.org/paper/269ed5ba525519502123b58472e069d77c5bda14\",\"venue\":\"COLING\",\"year\":2016},{\"arxivId\":\"1706.02430\",\"authors\":[{\"authorId\":\"143932857\",\"name\":\"Zhongliang Yang\"},{\"authorId\":\"34853917\",\"name\":\"Y. Zhang\"},{\"authorId\":\"19283055\",\"name\":\"S. Rehman\"},{\"authorId\":\"1731776\",\"name\":\"Y. Huang\"}],\"doi\":\"10.1007/978-3-319-71589-6_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e8fa2e242369dcf50ab5cd1745b29bfc51aadf2a\",\"title\":\"Image Captioning with Object Detection and Localization\",\"url\":\"https://www.semanticscholar.org/paper/e8fa2e242369dcf50ab5cd1745b29bfc51aadf2a\",\"venue\":\"ICIG\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3158899\",\"name\":\"Mariam Bouchakwa\"},{\"authorId\":\"2135034\",\"name\":\"Yassine Ayadi\"},{\"authorId\":\"1784204\",\"name\":\"I. Amous\"}],\"doi\":\"10.1007/s11042-020-08862-1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"445df9ebc8c43c39faeaa58518383f980fdd0da9\",\"title\":\"A review on visual content-based and users\\u2019 tags-based image annotation: methods and techniques\",\"url\":\"https://www.semanticscholar.org/paper/445df9ebc8c43c39faeaa58518383f980fdd0da9\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"1711.09561\",\"authors\":[{\"authorId\":\"47223178\",\"name\":\"E. Barsoum\"},{\"authorId\":\"6134973\",\"name\":\"John Kender\"},{\"authorId\":\"1691128\",\"name\":\"Zicheng Liu\"}],\"doi\":\"10.1109/CVPRW.2018.00191\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d488ceb4ea85d4d31a933a16b0abd0af042d5b98\",\"title\":\"HP-GAN: Probabilistic 3D Human Motion Prediction via GAN\",\"url\":\"https://www.semanticscholar.org/paper/d488ceb4ea85d4d31a933a16b0abd0af042d5b98\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49285626\",\"name\":\"An-An Liu\"},{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":\"3026404\",\"name\":\"Yongkang Wong\"},{\"authorId\":\"47786844\",\"name\":\"J. Li\"},{\"authorId\":\"2788104\",\"name\":\"Yuting Su\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":\"10.1016/j.cviu.2017.04.013\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"96eb165fbc83dd0abbaf65eaa75e020e289e4a66\",\"title\":\"Hierarchical & multimodal video captioning: Discovering and transferring multimodal knowledge for vision to language\",\"url\":\"https://www.semanticscholar.org/paper/96eb165fbc83dd0abbaf65eaa75e020e289e4a66\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40893753\",\"name\":\"A. Dilawari\"},{\"authorId\":\"35528948\",\"name\":\"M. A. Khan\"},{\"authorId\":\"32824146\",\"name\":\"Ammarah Farooq\"},{\"authorId\":\"46198155\",\"name\":\"Z. Rehman\"},{\"authorId\":\"143929828\",\"name\":\"S. Rho\"},{\"authorId\":\"3330588\",\"name\":\"I. Mehmood\"}],\"doi\":\"10.1109/ACCESS.2018.2814075\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7544aead4c1c68e21a775fc8c62c19fb5bc8171c\",\"title\":\"Natural Language Description of Video Streams Using Task-Specific Feature Encoding\",\"url\":\"https://www.semanticscholar.org/paper/7544aead4c1c68e21a775fc8c62c19fb5bc8171c\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40468514\",\"name\":\"Liang Yang\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1007/s11063-019-10045-5\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"f15f92647a02e526c02c1b61bf8bcc5d6b206e99\",\"title\":\"Adaptive Syncretic Attention for Constrained Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/f15f92647a02e526c02c1b61bf8bcc5d6b206e99\",\"venue\":\"Neural Processing Letters\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37670557\",\"name\":\"Xiangyang Li\"},{\"authorId\":\"1696610\",\"name\":\"S. Jiang\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"65885b53d54e52b8bbf31b1714be740eeb544c7f\",\"title\":\"Region Features ... ... Input Image Contextual Object Features ... ... ROI pooling C o n v Conv 5 _ 3 feature map Object Detection Region Proposal Network s Proposals Object Context Encoding\",\"url\":\"https://www.semanticscholar.org/paper/65885b53d54e52b8bbf31b1714be740eeb544c7f\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1912.06365\",\"authors\":[{\"authorId\":\"1443435125\",\"name\":\"Zhengcong Fei\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"38e48d6b39ce94ddc2a0bf20320598739187bfef\",\"title\":\"Fast Image Caption Generation with Position Alignment\",\"url\":\"https://www.semanticscholar.org/paper/38e48d6b39ce94ddc2a0bf20320598739187bfef\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8275214\",\"name\":\"P. Tang\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"1687386\",\"name\":\"S. Kwong\"}],\"doi\":\"10.1016/j.neucom.2018.05.086\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6723a565d4d7bc221fff7160bebfe54d16a40607\",\"title\":\"Deep sequential fusion LSTM network for image description\",\"url\":\"https://www.semanticscholar.org/paper/6723a565d4d7bc221fff7160bebfe54d16a40607\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49672743\",\"name\":\"C. Li\"},{\"authorId\":\"50763392\",\"name\":\"J. Chen\"},{\"authorId\":\"47718901\",\"name\":\"Weitao Wan\"},{\"authorId\":\"2641581\",\"name\":\"Tianpeng Li\"}],\"doi\":\"10.1007/978-3-319-71607-7_54\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"edc7f610c6dadc2e8c854c0fd9de320457ae942c\",\"title\":\"Combining Object-Based Attention and Attributes for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/edc7f610c6dadc2e8c854c0fd9de320457ae942c\",\"venue\":\"ICIG\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jian Yang\"},{\"authorId\":\"2018112\",\"name\":\"ZuQiang Meng\"}],\"doi\":\"10.1007/978-3-030-00828-4_36\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7b41ae2a6f7282aa00fa828e3a1e6e6bfc97bbdb\",\"title\":\"Image Semantic Description Based on Deep Learning with Multi-attention Mechanisms\",\"url\":\"https://www.semanticscholar.org/paper/7b41ae2a6f7282aa00fa828e3a1e6e6bfc97bbdb\",\"venue\":\"Intelligent Information Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1643954281\",\"name\":\"Noopur Ballal\"},{\"authorId\":\"39734694\",\"name\":\"S. K. Saritha\"}],\"doi\":\"10.1007/978-981-15-2071-6_16\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"35ddd3b2d7115dde8b3c514348329ebf157fe6bc\",\"title\":\"A Study of Deep Learning in Text Analytics\",\"url\":\"https://www.semanticscholar.org/paper/35ddd3b2d7115dde8b3c514348329ebf157fe6bc\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1705.09406\",\"authors\":[{\"authorId\":\"11138090\",\"name\":\"Tadas Baltru\\u0161aitis\"},{\"authorId\":\"118242121\",\"name\":\"Chaitanya Ahuja\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.1109/TPAMI.2018.2798607\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6bc4b1376ec2812b6d752c4f6bc8d8fd0512db91\",\"title\":\"Multimodal Machine Learning: A Survey and Taxonomy\",\"url\":\"https://www.semanticscholar.org/paper/6bc4b1376ec2812b6d752c4f6bc8d8fd0512db91\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":\"1603.08507\",\"authors\":[{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"2893664\",\"name\":\"Zeynep Akata\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1007/978-3-319-46493-0_1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ecf551d532d0e9cfb252a1bea04d14db620bc488\",\"title\":\"Generating Visual Explanations\",\"url\":\"https://www.semanticscholar.org/paper/ecf551d532d0e9cfb252a1bea04d14db620bc488\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"2012.01295\",\"authors\":[{\"authorId\":\"1768759403\",\"name\":\"Jing Su\"},{\"authorId\":\"2268783\",\"name\":\"Chenghua Lin\"},{\"authorId\":\"1510708415\",\"name\":\"Mian Zhou\"},{\"authorId\":\"49892954\",\"name\":\"Qingyun Dai\"},{\"authorId\":\"13036580\",\"name\":\"Haoyu Lv\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"91c21f11bdcf89ae18b7fc805c114fa8f27f72ef\",\"title\":\"Generating Descriptions for Sequential Images with Local-Object Attention and Global Semantic Context Modelling\",\"url\":\"https://www.semanticscholar.org/paper/91c21f11bdcf89ae18b7fc805c114fa8f27f72ef\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72211602\",\"name\":\"Kai Rannenberg\"}],\"doi\":\"10.1007/978-3-030-46931-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d37509fc390147f2ab8e3746c3abb208b3cfc36f\",\"title\":\"Intelligent Information Processing X: 11th IFIP TC 12 International Conference, IIP 2020, Hangzhou, China, July 3\\u20136, 2020, Proceedings\",\"url\":\"https://www.semanticscholar.org/paper/d37509fc390147f2ab8e3746c3abb208b3cfc36f\",\"venue\":\"Intelligent Information Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47767554\",\"name\":\"L. Wu\"},{\"authorId\":\"40444400\",\"name\":\"M. Xu\"},{\"authorId\":\"1783122\",\"name\":\"J. Wang\"},{\"authorId\":\"144242192\",\"name\":\"Stuart Perry\"}],\"doi\":\"10.1109/TMM.2019.2931815\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5b8b83bbb8ea54873be904ff77b1764267b3bd33\",\"title\":\"Recall What You See Continually Using GridLSTM in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/5b8b83bbb8ea54873be904ff77b1764267b3bd33\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11219408\",\"name\":\"Yuxuan Ding\"},{\"authorId\":\"46314444\",\"name\":\"W. Wang\"},{\"authorId\":\"151118825\",\"name\":\"Mengmeng Jiang\"},{\"authorId\":\"48446599\",\"name\":\"H. Liu\"},{\"authorId\":\"30631999\",\"name\":\"Donghu Deng\"},{\"authorId\":\"145673165\",\"name\":\"Wei Wei\"},{\"authorId\":\"2094026\",\"name\":\"Chunna Tian\"}],\"doi\":\"10.1007/978-3-030-31726-3_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6b1c6af412cc94e5cc5dcc11663b9828307aa21e\",\"title\":\"Jointing Cross-Modality Retrieval to Reweight Attributes for Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/6b1c6af412cc94e5cc5dcc11663b9828307aa21e\",\"venue\":\"PRCV\",\"year\":2019},{\"arxivId\":\"1704.03899\",\"authors\":[{\"authorId\":\"145888238\",\"name\":\"Zhou Ren\"},{\"authorId\":\"145779951\",\"name\":\"X. Wang\"},{\"authorId\":\"145002061\",\"name\":\"N. Zhang\"},{\"authorId\":\"2936952\",\"name\":\"Xutao Lv\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"}],\"doi\":\"10.1109/CVPR.2017.128\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c689f73f8ea65c6e81c628f2b37feae09b29e46b\",\"title\":\"Deep Reinforcement Learning-Based Image Captioning with Embedding Reward\",\"url\":\"https://www.semanticscholar.org/paper/c689f73f8ea65c6e81c628f2b37feae09b29e46b\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40663500\",\"name\":\"J. Chen\"},{\"authorId\":\"1848462\",\"name\":\"Yarong Han\"},{\"authorId\":\"144530696\",\"name\":\"Li Wan\"},{\"authorId\":\"144025048\",\"name\":\"Xing Zhou\"},{\"authorId\":\"144975798\",\"name\":\"Min Deng\"}],\"doi\":\"10.1080/01431161.2019.1594439\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"baf0c489e3f307187d5f20f10b4e24db37cd1cd1\",\"title\":\"Geospatial relation captioning for high-spatial-resolution images by using an attention-based neural network\",\"url\":\"https://www.semanticscholar.org/paper/baf0c489e3f307187d5f20f10b4e24db37cd1cd1\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40362315\",\"name\":\"J. Wang\"},{\"authorId\":\"1866977\",\"name\":\"Yiping Duan\"},{\"authorId\":\"144978572\",\"name\":\"X. Tao\"},{\"authorId\":\"47789939\",\"name\":\"J. Lu\"}],\"doi\":\"10.1109/ICC40277.2020.9149264\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3a5a6c759925570ab178c45340d34174fc8760f3\",\"title\":\"Local-to-Global Semantic Supervised Learning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/3a5a6c759925570ab178c45340d34174fc8760f3\",\"venue\":\"ICC 2020 - 2020 IEEE International Conference on Communications (ICC)\",\"year\":2020},{\"arxivId\":\"1606.04621\",\"authors\":[{\"authorId\":\"2677364\",\"name\":\"Luowei Zhou\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"},{\"authorId\":\"31717541\",\"name\":\"Parker A. Koch\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a861313608ef58ed09ab7c35a589ae22088ff2e9\",\"title\":\"Image Caption Generation with Text-Conditional Semantic Attention\",\"url\":\"https://www.semanticscholar.org/paper/a861313608ef58ed09ab7c35a589ae22088ff2e9\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92057141\",\"name\":\"H. Wei\"},{\"authorId\":\"49969428\",\"name\":\"Z. Li\"},{\"authorId\":\"104269832\",\"name\":\"Canlong Zhang\"},{\"authorId\":\"144137447\",\"name\":\"Tao Zhou\"},{\"authorId\":\"1391051492\",\"name\":\"Y. Quan\"}],\"doi\":\"10.1109/IJCNN.2019.8852118\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f76cf186f93a0f5b3f57a8d0a1545e5b626e664e\",\"title\":\"Image Captioning Based On Sentence-Level And Word-Level Attention\",\"url\":\"https://www.semanticscholar.org/paper/f76cf186f93a0f5b3f57a8d0a1545e5b626e664e\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46458416\",\"name\":\"L. Liu\"},{\"authorId\":\"2094026\",\"name\":\"Chunna Tian\"},{\"authorId\":\"48263872\",\"name\":\"Ruiguo Zhang\"},{\"authorId\":\"1490736109\",\"name\":\"Yuxuan Ding\"}],\"doi\":\"10.1117/12.2557584\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0d11973ef9567133ae8035dfbd4e96c87ca36505\",\"title\":\"Generating description with multi-feature and saliency maps of image\",\"url\":\"https://www.semanticscholar.org/paper/0d11973ef9567133ae8035dfbd4e96c87ca36505\",\"venue\":\"International Conference on Graphic and Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1591146157\",\"name\":\"Yixiao Zhang\"},{\"authorId\":\"40406046\",\"name\":\"Ziyu Wang\"},{\"authorId\":\"150084152\",\"name\":\"Dingsu Wang\"},{\"authorId\":\"38746431\",\"name\":\"G. Xia\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2022ea7ad4b00a307559ae0be1d0ae2237ad7466\",\"title\":\"BUTTER: A Representation Learning Framework for Bi-directional Music-Sentence Retrieval and Generation\",\"url\":\"https://www.semanticscholar.org/paper/2022ea7ad4b00a307559ae0be1d0ae2237ad7466\",\"venue\":\"NLP4MUSA\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92187979\",\"name\":\"C. Xu\"},{\"authorId\":\"103382547\",\"name\":\"Junzhong Ji\"},{\"authorId\":\"16003095\",\"name\":\"Meng-long Zhang\"},{\"authorId\":\"49470161\",\"name\":\"X. Zhang\"}],\"doi\":\"10.1109/ICUSAI47366.2019.9124779\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"72364b3cd61221a99fb6be65e34a10c53db531cd\",\"title\":\"Attention-gated LSTM for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/72364b3cd61221a99fb6be65e34a10c53db531cd\",\"venue\":\"2019 IEEE International Conference on Unmanned Systems and Artificial Intelligence (ICUSAI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39006765\",\"name\":\"J. Wu\"},{\"authorId\":\"152566311\",\"name\":\"Si-ya Xie\"},{\"authorId\":\"5935907\",\"name\":\"Xin-bao Shi\"},{\"authorId\":\"94257262\",\"name\":\"Y. Chen\"}],\"doi\":\"10.1007/S11801-017-7185-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9823c25796a364d70e31059c44305f007a2dbc8a\",\"title\":\"Global-local feature attention network with reranking strategy for image caption generation\",\"url\":\"https://www.semanticscholar.org/paper/9823c25796a364d70e31059c44305f007a2dbc8a\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46583706\",\"name\":\"J. Wang\"},{\"authorId\":\"145200778\",\"name\":\"Wei Wang\"},{\"authorId\":\"123865558\",\"name\":\"Liang Wang\"},{\"authorId\":\"50857536\",\"name\":\"Z. Wang\"},{\"authorId\":\"145855523\",\"name\":\"D. Feng\"},{\"authorId\":\"145808910\",\"name\":\"Tieniu Tan\"}],\"doi\":\"10.1016/j.patcog.2019.107075\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"70b03dfb947ca136e3476c9f49b8f6b044d0c1d9\",\"title\":\"Learning visual relationship and context-aware attention for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/70b03dfb947ca136e3476c9f49b8f6b044d0c1d9\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":\"1612.09542\",\"authors\":[{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"47300698\",\"name\":\"Hao Tan\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/CVPR.2017.375\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a5b64709c677c131ec8b7846d3493df53987fa6f\",\"title\":\"A Joint Speaker-Listener-Reinforcer Model for Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/a5b64709c677c131ec8b7846d3493df53987fa6f\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40622539\",\"name\":\"Dong-Jin Kim\"},{\"authorId\":\"2283756\",\"name\":\"Donggeun Yoo\"},{\"authorId\":\"7825960\",\"name\":\"B. Sim\"},{\"authorId\":\"2398271\",\"name\":\"In-So Kweon\"}],\"doi\":\"10.1109/URAI.2016.7625747\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fc72f40a3d55db85929fff99110384d05dc2c7ab\",\"title\":\"Sentence learning on deep convolutional networks for image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/fc72f40a3d55db85929fff99110384d05dc2c7ab\",\"venue\":\"2016 13th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34153289\",\"name\":\"Anqi Wang\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"},{\"authorId\":\"40468514\",\"name\":\"Liang Yang\"}],\"doi\":\"10.1145/3226037\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"f164313e63d5c6d0a5f4b55fd0ffcc25c436bc14\",\"title\":\"Image Captioning with Affective Guiding and Selective Attention\",\"url\":\"https://www.semanticscholar.org/paper/f164313e63d5c6d0a5f4b55fd0ffcc25c436bc14\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2059218\",\"name\":\"Ankit Khare\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"01fe0c5f0d033141a29f4958f15520798022bbe7\",\"title\":\"ULTRA-CONTEXT: MAXIMIZING THE CONTEXT FOR BETTER IMAGE CAPTION GENERATION\",\"url\":\"https://www.semanticscholar.org/paper/01fe0c5f0d033141a29f4958f15520798022bbe7\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1803.05526\",\"authors\":[{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"},{\"authorId\":\"2708940\",\"name\":\"Shafiq R. Joty\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"}],\"doi\":\"10.1007/978-3-030-01246-5_31\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"05544876b7bc58b59b9ec5a8ee09e3ce9b4791ce\",\"title\":\"Unpaired Image Captioning by Language Pivoting\",\"url\":\"https://www.semanticscholar.org/paper/05544876b7bc58b59b9ec5a8ee09e3ce9b4791ce\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145511765\",\"name\":\"Tong Wu\"},{\"authorId\":\"38338059\",\"name\":\"T. Ku\"},{\"authorId\":\"153504695\",\"name\":\"Hao Zhang\"}],\"doi\":\"10.1117/12.2552711\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b37b3cdcd6d839aaee661324c9d4a5411de20a11\",\"title\":\"Research for image caption based on global attention mechanism\",\"url\":\"https://www.semanticscholar.org/paper/b37b3cdcd6d839aaee661324c9d4a5411de20a11\",\"venue\":\"Target Recognition and Artificial Intelligence Summit Forum\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153730333\",\"name\":\"V. Kumar\"},{\"authorId\":\"1703799\",\"name\":\"S. Joshi\"}],\"doi\":\"10.1145/3077136.3080801\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f27be01ce79e086c02547137524db0a428239ff7\",\"title\":\"Incomplete Follow-up Question Resolution using Retrieval based Sequence to Sequence Learning\",\"url\":\"https://www.semanticscholar.org/paper/f27be01ce79e086c02547137524db0a428239ff7\",\"venue\":\"SIGIR\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153274639\",\"name\":\"Sangpil Kim\"},{\"authorId\":\"1379494960\",\"name\":\"Hyung-gun Chi\"},{\"authorId\":\"145460915\",\"name\":\"Xiaolin Hu\"},{\"authorId\":\"151485038\",\"name\":\"Qi-Xing Huang\"},{\"authorId\":\"122609496\",\"name\":\"Karthik\"},{\"authorId\":\"98298417\",\"name\":\"Ramani\"}],\"doi\":\"10.1007/978-3-030-58523-5_11\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a382840b58f918613fb9e415457b9c233849e289\",\"title\":\"A Large-Scale Annotated Mechanical Components Benchmark for Classification and Retrieval Tasks with Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/a382840b58f918613fb9e415457b9c233849e289\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"70998064\",\"name\":\"De-xin Zhao\"},{\"authorId\":\"144481842\",\"name\":\"Zhi Chang\"},{\"authorId\":\"50530237\",\"name\":\"Shutao Guo\"}],\"doi\":\"10.1016/j.neucom.2019.09.055\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cb6e072913c1708e50fe2690cb103c2b7c0346f8\",\"title\":\"Cross-scale fusion detection with global attribute for dense captioning\",\"url\":\"https://www.semanticscholar.org/paper/cb6e072913c1708e50fe2690cb103c2b7c0346f8\",\"venue\":\"Neurocomputing\",\"year\":2020}],\"corpusId\":7502269,\"doi\":\"10.1109/ICCV.2015.277\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":15,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"c3640aae13e344ad70a926510221dada626a44de\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1784914\",\"name\":\"A. Lavie\"},{\"authorId\":\"3766304\",\"name\":\"Abhaya Agarwal\"}],\"doi\":\"10.3115/1626355.1626389\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"34d7a07c493ca6336c92156806a2947e115caadc\",\"title\":\"METEOR: An Automatic Metric for MT Evaluation with High Levels of Correlation with Human Judgments\",\"url\":\"https://www.semanticscholar.org/paper/34d7a07c493ca6336c92156806a2947e115caadc\",\"venue\":\"WMT@ACL\",\"year\":2007},{\"arxivId\":\"1409.1259\",\"authors\":[{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"3158246\",\"name\":\"B. V. Merrienboer\"},{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":\"10.3115/v1/W14-4012\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"1eb09fecd75eb27825dce4f964b97f4f5cc399d7\",\"title\":\"On the Properties of Neural Machine Translation: Encoder-Decoder Approaches\",\"url\":\"https://www.semanticscholar.org/paper/1eb09fecd75eb27825dce4f964b97f4f5cc399d7\",\"venue\":\"SSST@EMNLP\",\"year\":2014},{\"arxivId\":\"1406.1078\",\"authors\":[{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"3158246\",\"name\":\"B. V. Merrienboer\"},{\"authorId\":\"1854385\",\"name\":\"\\u00c7aglar G\\u00fcl\\u00e7ehre\"},{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"2076086\",\"name\":\"Fethi Bougares\"},{\"authorId\":\"144518416\",\"name\":\"Holger Schwenk\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":\"10.3115/v1/D14-1179\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0b544dfe355a5070b60986319a3f51fb45d1348e\",\"title\":\"Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/0b544dfe355a5070b60986319a3f51fb45d1348e\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144747622\",\"name\":\"R. Mason\"},{\"authorId\":\"1749837\",\"name\":\"Eugene Charniak\"}],\"doi\":\"10.3115/v1/P14-2097\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"88e652a681ffa132d0438b0d0c322766dc8eac91\",\"title\":\"Nonparametric Method for Data-driven Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/88e652a681ffa132d0438b0d0c322766dc8eac91\",\"venue\":\"ACL\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"145704247\",\"name\":\"J. Martens\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e0e5dd8b206806372b3e20b9a2fbdbd0cf9ce1de\",\"title\":\"Generating Text with Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/e0e5dd8b206806372b3e20b9a2fbdbd0cf9ce1de\",\"venue\":\"ICML\",\"year\":2011},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fad611e35b3731740b4d8b754241e77add5a70b9\",\"title\":\"Multimodal Neural Language Models\",\"url\":\"https://www.semanticscholar.org/paper/fad611e35b3731740b4d8b754241e77add5a70b9\",\"venue\":\"ICML\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3323275\",\"name\":\"Kishore Papineni\"},{\"authorId\":\"1781292\",\"name\":\"S. Roukos\"},{\"authorId\":\"144582029\",\"name\":\"T. Ward\"},{\"authorId\":\"2587983\",\"name\":\"Wei-Jing Zhu\"}],\"doi\":\"10.3115/1073083.1073135\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d7da009f457917aa381619facfa5ffae9329a6e9\",\"title\":\"Bleu: a Method for Automatic Evaluation of Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/d7da009f457917aa381619facfa5ffae9329a6e9\",\"venue\":\"ACL\",\"year\":2002},{\"arxivId\":\"1503.04069\",\"authors\":[{\"authorId\":\"3035541\",\"name\":\"Klaus Greff\"},{\"authorId\":\"2100612\",\"name\":\"R. Srivastava\"},{\"authorId\":\"2865775\",\"name\":\"J. Koutn\\u00edk\"},{\"authorId\":\"71009239\",\"name\":\"Bastiaan Steunebrink\"},{\"authorId\":\"48974230\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1109/tnnls.2016.2582924\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a7976c2bacfbb194ddbe7fd10c2e50a545cf4081\",\"title\":\"LSTM: A Search Space Odyssey\",\"url\":\"https://www.semanticscholar.org/paper/a7976c2bacfbb194ddbe7fd10c2e50a545cf4081\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2017},{\"arxivId\":\"1409.4842\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"46641766\",\"name\":\"W. Liu\"},{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"},{\"authorId\":\"48840704\",\"name\":\"Scott Reed\"},{\"authorId\":\"1838674\",\"name\":\"Dragomir Anguelov\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"39863668\",\"name\":\"Andrew Rabinovich\"}],\"doi\":\"10.1109/CVPR.2015.7298594\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"title\":\"Going deeper with convolutions\",\"url\":\"https://www.semanticscholar.org/paper/e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1211.3711\",\"authors\":[{\"authorId\":\"1753223\",\"name\":\"A. Graves\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7b4f3d0e4e2486a8d5d3f8e00549cf9a117bf88f\",\"title\":\"Sequence Transduction with Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/7b4f3d0e4e2486a8d5d3f8e00549cf9a117bf88f\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1109/CVPR.2015.7298856\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"a72b8bbd039989db39769da836cdb287737deb92\",\"title\":\"Mind's eye: A recurrent visual representation for image caption generation\",\"url\":\"https://www.semanticscholar.org/paper/a72b8bbd039989db39769da836cdb287737deb92\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1162/neco.1997.9.8.1735\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"title\":\"Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"venue\":\"Neural Computation\",\"year\":1997},{\"arxivId\":\"1411.5726\",\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2015.7299087\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"258986132bf17755fe8263e42429fe73218c1534\",\"title\":\"CIDEr: Consensus-based image description evaluation\",\"url\":\"https://www.semanticscholar.org/paper/258986132bf17755fe8263e42429fe73218c1534\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1412.2306\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/TPAMI.2016.2598339\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"title\":\"Deep Visual-Semantic Alignments for Generating Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"1756655\",\"name\":\"C. L. Teo\"},{\"authorId\":\"1722360\",\"name\":\"Hal Daum\\u00e9\"},{\"authorId\":\"1697493\",\"name\":\"Y. Aloimonos\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"76a1dca3a9c2b0229c1b12c95752dcf40dc95a11\",\"title\":\"Corpus-Guided Sentence Generation of Natural Images\",\"url\":\"https://www.semanticscholar.org/paper/76a1dca3a9c2b0229c1b12c95752dcf40dc95a11\",\"venue\":\"EMNLP\",\"year\":2011},{\"arxivId\":\"1409.3215\",\"authors\":[{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"cea967b59209c6be22829699f05b8b1ac4dc092d\",\"title\":\"Sequence to Sequence Learning with Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/cea967b59209c6be22829699f05b8b1ac4dc092d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1308.0850\",\"authors\":[{\"authorId\":\"1753223\",\"name\":\"A. Graves\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"89b1f4740ae37fd04f6ac007577bdd34621f0861\",\"title\":\"Generating Sequences With Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/89b1f4740ae37fd04f6ac007577bdd34621f0861\",\"venue\":\"ArXiv\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1888731\",\"name\":\"M. Hejrati\"},{\"authorId\":\"21160985\",\"name\":\"M. Sadeghi\"},{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"3125805\",\"name\":\"Cyrus Rashtchian\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"144016256\",\"name\":\"D. Forsyth\"}],\"doi\":\"10.1007/978-3-642-15561-1_2\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"eaaed23a2d94feb2f1c3ff22a25777c7a78f3141\",\"title\":\"Every Picture Tells a Story: Generating Sentences from Images\",\"url\":\"https://www.semanticscholar.org/paper/eaaed23a2d94feb2f1c3ff22a25777c7a78f3141\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2170746\",\"name\":\"M. Hodosh\"},{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"}],\"doi\":\"10.1613/jair.3994\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9814df8bd00ba999c4d1e305a7e9bca579dc7c75\",\"title\":\"Framing Image Description as a Ranking Task: Data, Models and Evaluation Metrics (Extended Abstract)\",\"url\":\"https://www.semanticscholar.org/paper/9814df8bd00ba999c4d1e305a7e9bca579dc7c75\",\"venue\":\"IJCAI\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50675395\",\"name\":\"H. Hotelling\"}],\"doi\":\"10.1007/978-1-4612-4380-9_14\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"45db76270416a42517a21c63a77e9c4260fa979a\",\"title\":\"Relations Between Two Sets of Variates\",\"url\":\"https://www.semanticscholar.org/paper/45db76270416a42517a21c63a77e9c4260fa979a\",\"venue\":\"\",\"year\":1936},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"34176020\",\"name\":\"Jesse Dodge\"},{\"authorId\":\"46479604\",\"name\":\"Amit Goyal\"},{\"authorId\":\"1721910\",\"name\":\"Kota Yamaguchi\"},{\"authorId\":\"1714215\",\"name\":\"K. Stratos\"},{\"authorId\":\"1682965\",\"name\":\"Xufeng Han\"},{\"authorId\":\"40614240\",\"name\":\"A. Mensch\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1722360\",\"name\":\"Hal Daum\\u00e9\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"355de7460120ddc1150d9ce3756f9848983f7ff4\",\"title\":\"Midge: Generating Image Descriptions From Computer Vision Detections\",\"url\":\"https://www.semanticscholar.org/paper/355de7460120ddc1150d9ce3756f9848983f7ff4\",\"venue\":\"EACL\",\"year\":2012},{\"arxivId\":\"1411.4952\",\"authors\":[{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3346186\",\"name\":\"Forrest N. Iandola\"},{\"authorId\":\"2100612\",\"name\":\"R. Srivastava\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"144189092\",\"name\":\"John C. Platt\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"}],\"doi\":\"10.1109/CVPR.2015.7298754\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"title\":\"From captions to visual concepts and back\",\"url\":\"https://www.semanticscholar.org/paper/15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"145297531\",\"name\":\"A. Lai\"},{\"authorId\":\"2170746\",\"name\":\"M. Hodosh\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"}],\"doi\":\"10.1162/tacl_a_00166\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"44040913380206991b1991daf1192942e038fe31\",\"title\":\"From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions\",\"url\":\"https://www.semanticscholar.org/paper/44040913380206991b1991daf1192942e038fe31\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145592791\",\"name\":\"P. Kuznetsova\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"9002c8d2c2210387dd0c694c151c4ab1dde42b4b\",\"title\":\"Generalizing Image Captions for Image-Text Parallel Corpus\",\"url\":\"https://www.semanticscholar.org/paper/9002c8d2c2210387dd0c694c151c4ab1dde42b4b\",\"venue\":\"ACL\",\"year\":2013},{\"arxivId\":\"1409.0473\",\"authors\":[{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"title\":\"Neural Machine Translation by Jointly Learning to Align and Translate\",\"url\":\"https://www.semanticscholar.org/paper/fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1212.4522\",\"authors\":[{\"authorId\":\"5115386\",\"name\":\"Yunchao Gong\"},{\"authorId\":\"2259786\",\"name\":\"Q. Ke\"},{\"authorId\":\"2090818\",\"name\":\"M. Isard\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1007/s11263-013-0658-4\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"7fceccc7a1046caa4936b14eeacb71ccf4d6be10\",\"title\":\"A Multi-View Embedding Space for Modeling Internet Images, Tags, and Their Semantics\",\"url\":\"https://www.semanticscholar.org/paper/7fceccc7a1046caa4936b14eeacb71ccf4d6be10\",\"venue\":\"International Journal of Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"R. Mason\"},{\"authorId\":null,\"name\":\"E. Charniak\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Nonparametric method for datadriven image captioning\",\"url\":\"\",\"venue\":\"ACL,\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145564333\",\"name\":\"G. Kulkarni\"},{\"authorId\":\"3128210\",\"name\":\"Visruth Premraj\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"2985883\",\"name\":\"Sagnik Dhar\"},{\"authorId\":\"50341924\",\"name\":\"Siming Li\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/TPAMI.2012.162\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5cb6700d94c6118ee13f4f4fecac99f111189812\",\"title\":\"BabyTalk: Understanding and Generating Simple Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/5cb6700d94c6118ee13f4f4fecac99f111189812\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145592791\",\"name\":\"P. Kuznetsova\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":\"10.1162/tacl_a_00188\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"59927ded86ab4f7253fc32efb351e5a13e746ead\",\"title\":\"TreeTalk: Composition and Compression of Trees for Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/59927ded86ab4f7253fc32efb351e5a13e746ead\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2157958\",\"name\":\"Michael J. Denkowski\"},{\"authorId\":\"1784914\",\"name\":\"A. Lavie\"}],\"doi\":\"10.3115/v1/W14-3348\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"26adb749fc5d80502a6d889966e50b31391560d3\",\"title\":\"Meteor Universal: Language Specific Translation Evaluation for Any Target Language\",\"url\":\"https://www.semanticscholar.org/paper/26adb749fc5d80502a6d889966e50b31391560d3\",\"venue\":\"WMT@ACL\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21308992\",\"name\":\"Steven Bird\"},{\"authorId\":\"145606490\",\"name\":\"E. Klein\"},{\"authorId\":\"3213150\",\"name\":\"E. Loper\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7a65f23d990231d461418067c808b09d84c19b2c\",\"title\":\"Natural Language Processing with Python\",\"url\":\"https://www.semanticscholar.org/paper/7a65f23d990231d461418067c808b09d84c19b2c\",\"venue\":\"\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"T. Tieleman\"},{\"authorId\":null,\"name\":\"G. Hinton\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Leccture 6.5 - rmsprop\",\"url\":\"\",\"venue\":\"Technical Report MSU-CSE-00-2,\",\"year\":2000},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"K Greff\"},{\"authorId\":null,\"name\":\"R K Srivastava\"},{\"authorId\":null,\"name\":\"J Koutn\\u00edk\"},{\"authorId\":null,\"name\":\"B R Steunebrink\"},{\"authorId\":null,\"name\":\"J Schmidhuber\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"LSTM: A search space odyssey. CoRR, abs/1503\",\"url\":\"\",\"venue\":\"LSTM: A search space odyssey. CoRR, abs/1503\",\"year\":2015},{\"arxivId\":\"1412.6632\",\"authors\":[{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"40579682\",\"name\":\"J. Wang\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745\",\"title\":\"Deep Captioning with Multimodal Recurrent Neural Networks (m-RNN)\",\"url\":\"https://www.semanticscholar.org/paper/54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1406.5679\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2319608\",\"name\":\"Armand Joulin\"},{\"authorId\":\"153196308\",\"name\":\"F. Li\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7f1b111f0bb703b0bd97aba505728a9b0d9b2a54\",\"title\":\"Deep Fragment Embeddings for Bidirectional Image Sentence Mapping\",\"url\":\"https://www.semanticscholar.org/paper/7f1b111f0bb703b0bd97aba505728a9b0d9b2a54\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145592791\",\"name\":\"P. Kuznetsova\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"2a0d0f6c5a69b264710df0230696f47c5918e2f2\",\"title\":\"Collective Generation of Natural Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/2a0d0f6c5a69b264710df0230696f47c5918e2f2\",\"venue\":\"ACL\",\"year\":2012},{\"arxivId\":\"1412.4564\",\"authors\":[{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"3257286\",\"name\":\"Karel Lenc\"}],\"doi\":\"10.1145/2733373.2807412\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0bde8d9367d1004c7396dd69cb27ed97dc2f8d77\",\"title\":\"MatConvNet: Convolutional Neural Networks for MATLAB\",\"url\":\"https://www.semanticscholar.org/paper/0bde8d9367d1004c7396dd69cb27ed97dc2f8d77\",\"venue\":\"ACM Multimedia\",\"year\":2015}],\"title\":\"Guiding the Long-Short Term Memory Model for Image Caption Generation\",\"topics\":[{\"topic\":\"Beam search\",\"topicId\":\"215017\",\"url\":\"https://www.semanticscholar.org/topic/215017\"},{\"topic\":\"Long short-term memory\",\"topicId\":\"117199\",\"url\":\"https://www.semanticscholar.org/topic/117199\"},{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"}],\"url\":\"https://www.semanticscholar.org/paper/c3640aae13e344ad70a926510221dada626a44de\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015}\n"