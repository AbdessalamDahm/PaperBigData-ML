"{\"abstract\":\"We propose the task of free-form and open-ended Visual Question Answering (VQA). Given an image and a natural language question about the image, the task is to provide an accurate natural language answer. Mirroring real-world scenarios, such as helping the visually impaired, both the questions and answers are open-ended. Visual questions selectively target different areas of an image, including background details and underlying context. As a result, a system that succeeds at VQA typically needs a more detailed understanding of the image and complex reasoning than a system producing generic image captions. Moreover, VQA is amenable to automatic evaluation, since many open-ended answers contain only a few words or a closed set of answers that can be provided in a multiple-choice format. We provide a dataset containing ~0.25M images, ~0.76M questions, and ~10M answers (www.visualqa.org), and discuss the information it provides. Numerous baselines for VQA are provided and compared with human performance.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\",\"url\":\"https://www.semanticscholar.org/author/1963421\"},{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\",\"url\":\"https://www.semanticscholar.org/author/2801949\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\",\"url\":\"https://www.semanticscholar.org/author/8553015\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\",\"url\":\"https://www.semanticscholar.org/author/49501003\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\",\"url\":\"https://www.semanticscholar.org/author/51472503\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\",\"url\":\"https://www.semanticscholar.org/author/1699161\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\",\"url\":\"https://www.semanticscholar.org/author/153432684\"}],\"citationVelocity\":47,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"}],\"doi\":\"10.1109/MSP.2017.2741510\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c5b803c2fee9bbf6d9132f633de70332b5e80a4d\",\"title\":\"Deep Learning for Image-to-Text Generation: A Technical Overview\",\"url\":\"https://www.semanticscholar.org/paper/c5b803c2fee9bbf6d9132f633de70332b5e80a4d\",\"venue\":\"IEEE Signal Processing Magazine\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390026947\",\"name\":\"Komal Sharan\"},{\"authorId\":\"2116290\",\"name\":\"Ashwinkumar Ganesan\"},{\"authorId\":\"143979239\",\"name\":\"T. Oates\"}],\"doi\":\"10.1007/978-3-030-33720-9_17\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aa08784c797cde8a003dc11643f257fc9cc91c09\",\"title\":\"Improving Visual Reasoning with Attention Alignment\",\"url\":\"https://www.semanticscholar.org/paper/aa08784c797cde8a003dc11643f257fc9cc91c09\",\"venue\":\"ISVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2973718\",\"name\":\"L. Kodra\"},{\"authorId\":\"50879442\",\"name\":\"E. Me\\u00e7e\"}],\"doi\":\"10.1007/978-3-319-75928-9_52\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"51280870657c72400b5de46ba56ee18b9891ab40\",\"title\":\"Multimodal Attention Agents in Visual Conversation\",\"url\":\"https://www.semanticscholar.org/paper/51280870657c72400b5de46ba56ee18b9891ab40\",\"venue\":\"EIDWT\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2301765\",\"name\":\"Tsung-Wei Ke\"},{\"authorId\":\"3172276\",\"name\":\"Che-Wei Lin\"},{\"authorId\":\"1805102\",\"name\":\"Tyng-Luh Liu\"},{\"authorId\":\"14489533\",\"name\":\"D. Geiger\"}],\"doi\":\"10.1007/978-3-319-54190-7_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d1df74a5047e953766fa07dec356bba285c605a1\",\"title\":\"Variational Convolutional Networks for Human-Centric Annotations\",\"url\":\"https://www.semanticscholar.org/paper/d1df74a5047e953766fa07dec356bba285c605a1\",\"venue\":\"ACCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"940c90eb474cb2670559e03965b97a67eabd7a73\",\"title\":\"CODRAW: COLLABORATIVE DRAWING\",\"url\":\"https://www.semanticscholar.org/paper/940c90eb474cb2670559e03965b97a67eabd7a73\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49116303\",\"name\":\"Yue Qiu\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"},{\"authorId\":\"144410256\",\"name\":\"Ryota Suzuki\"},{\"authorId\":\"35206224\",\"name\":\"K. Iwata\"}],\"doi\":\"10.1007/978-3-030-50334-5_26\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ee2dc587ff68e353fc47e0b2ad25e402fe87c57f\",\"title\":\"Multi-view Visual Question Answering Dataset for Real Environment Applications\",\"url\":\"https://www.semanticscholar.org/paper/ee2dc587ff68e353fc47e0b2ad25e402fe87c57f\",\"venue\":\"HCI\",\"year\":2020},{\"arxivId\":\"1905.11532\",\"authors\":[{\"authorId\":\"7591930\",\"name\":\"Vardaan Pahuja\"},{\"authorId\":\"145016608\",\"name\":\"J. Fu\"},{\"authorId\":\"144631588\",\"name\":\"A. Chandar\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"}],\"doi\":\"10.18653/v1/D19-6401\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"857b81e7c21cb878781d90ddcaa72ced83cb177c\",\"title\":\"Structure Learning for Neural Module Networks\",\"url\":\"https://www.semanticscholar.org/paper/857b81e7c21cb878781d90ddcaa72ced83cb177c\",\"venue\":\"LANTERN@EMNLP-IJCNLP\",\"year\":2019},{\"arxivId\":\"1806.00857\",\"authors\":[{\"authorId\":\"35748708\",\"name\":\"Gabriel Grand\"},{\"authorId\":\"31408089\",\"name\":\"Aron Szanto\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2a9135976912d4169a4490c641561ed0867a306c\",\"title\":\"On the Flip Side: Identifying Counterexamples in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2a9135976912d4169a4490c641561ed0867a306c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33396604\",\"name\":\"N. Sankaran\"},{\"authorId\":\"33754562\",\"name\":\"D. Mohan\"},{\"authorId\":\"1800513\",\"name\":\"S. Setlur\"},{\"authorId\":\"51023269\",\"name\":\"V. Govindaraju\"},{\"authorId\":\"83368994\",\"name\":\"D. Fedorishin\"}],\"doi\":\"10.1109/FG.2019.8756519\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c270ea47fc3aa68121855d7e2cdecafc12955a2\",\"title\":\"Representation Learning Through Cross-Modality Supervision\",\"url\":\"https://www.semanticscholar.org/paper/1c270ea47fc3aa68121855d7e2cdecafc12955a2\",\"venue\":\"2019 14th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2019)\",\"year\":2019},{\"arxivId\":\"1805.09701\",\"authors\":[{\"authorId\":\"2887562\",\"name\":\"Pan Lu\"},{\"authorId\":\"50688017\",\"name\":\"L. Ji\"},{\"authorId\":null,\"name\":\"Wei Zhang\"},{\"authorId\":\"29943965\",\"name\":\"Nan Duan\"},{\"authorId\":\"143849609\",\"name\":\"M. Zhou\"},{\"authorId\":\"2447408\",\"name\":\"Jianyong Wang\"}],\"doi\":\"10.1145/3219819.3220036\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d2de5d94461d66e6b97e6825ae0fea3d6d925382\",\"title\":\"R-VQA: Learning Visual Relation Facts with Semantic Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d2de5d94461d66e6b97e6825ae0fea3d6d925382\",\"venue\":\"KDD\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47987162\",\"name\":\"Hao Wu\"},{\"authorId\":\"13589371\",\"name\":\"Jiayuan Mao\"},{\"authorId\":\"51437593\",\"name\":\"Y. Zhang\"},{\"authorId\":\"144898150\",\"name\":\"Yuning Jiang\"},{\"authorId\":\"46255707\",\"name\":\"Lei Li\"},{\"authorId\":\"143872729\",\"name\":\"Weiwei Sun\"},{\"authorId\":\"1712167\",\"name\":\"W. Ma\"}],\"doi\":\"10.1109/CVPR.2019.00677\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"08a302f0bb8dc360ae3a0a20fa7b7555920380d4\",\"title\":\"Unified Visual-Semantic Embeddings: Bridging Vision and Language With Structured Meaning Representations\",\"url\":\"https://www.semanticscholar.org/paper/08a302f0bb8dc360ae3a0a20fa7b7555920380d4\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1806.08409\",\"authors\":[{\"authorId\":\"1765212\",\"name\":\"C. Hori\"},{\"authorId\":\"2809915\",\"name\":\"H. AlAmri\"},{\"authorId\":null,\"name\":\"Jue Wang\"},{\"authorId\":\"1816785\",\"name\":\"G. Wichern\"},{\"authorId\":\"145443186\",\"name\":\"T. Hori\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"},{\"authorId\":\"51002409\",\"name\":\"Vincent Cartillier\"},{\"authorId\":\"143826364\",\"name\":\"Raphael Gontijo Lopes\"},{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"21472040\",\"name\":\"Irfan Essa\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/ICASSP.2019.8682583\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"85c22ce1a62973a4b64bbcde26748893d61d01e4\",\"title\":\"End-to-end Audio Visual Scene-aware Dialog Using Multimodal Attention-based Video Features\",\"url\":\"https://www.semanticscholar.org/paper/85c22ce1a62973a4b64bbcde26748893d61d01e4\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":\"1908.06306\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"1382193868\",\"name\":\"Mayank Lunayach\"},{\"authorId\":\"152264213\",\"name\":\"Shivansh Patel\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":\"10.1109/ICCV.2019.00754\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5c1d1d341f7d29ae078940fad184b7b182fa0cd1\",\"title\":\"U-CAM: Visual Explanation Using Uncertainty Based Class Activation Maps\",\"url\":\"https://www.semanticscholar.org/paper/5c1d1d341f7d29ae078940fad184b7b182fa0cd1\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66073991\",\"name\":\"Edoardo Alati\"},{\"authorId\":\"65770249\",\"name\":\"L. Mauro\"},{\"authorId\":\"2368860\",\"name\":\"Valsamis Ntouskos\"},{\"authorId\":\"1695016\",\"name\":\"F. Pirri\"}],\"doi\":\"10.1007/978-3-030-29516-5_60\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"422910cd883a39a42e40d6630997c95cb1864d44\",\"title\":\"Anticipating Next Goal for Robot Plan Prediction\",\"url\":\"https://www.semanticscholar.org/paper/422910cd883a39a42e40d6630997c95cb1864d44\",\"venue\":\"IntelliSys\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47837986\",\"name\":\"An Yan\"},{\"authorId\":\"47120131\",\"name\":\"X. Wang\"},{\"authorId\":\"2093485\",\"name\":\"Jiangtao Feng\"},{\"authorId\":null,\"name\":\"Lei Li\"},{\"authorId\":\"1682479\",\"name\":\"William Yang Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a88e77a9574bcb20021d0dd4a4b8d729d85696f2\",\"title\":\"Beyond Monolingual Vision-Language Navigation\",\"url\":\"https://www.semanticscholar.org/paper/a88e77a9574bcb20021d0dd4a4b8d729d85696f2\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6485607\",\"name\":\"Jongchan Park\"},{\"authorId\":\"49108458\",\"name\":\"Min-Hyun Kim\"},{\"authorId\":\"38563282\",\"name\":\"S. Choi\"},{\"authorId\":\"98758720\",\"name\":\"I. Kweon\"},{\"authorId\":\"2854596\",\"name\":\"Dong-Geol Choi\"}],\"doi\":\"10.23919/ELINFOCOM.2019.8706354\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1180af5d6e64c1ba6bcebaff84b8ac346eb7512e\",\"title\":\"Fraud Detection with Multi-Modal Attention and Correspondence Learning\",\"url\":\"https://www.semanticscholar.org/paper/1180af5d6e64c1ba6bcebaff84b8ac346eb7512e\",\"venue\":\"2019 International Conference on Electronics, Information, and Communication (ICEIC)\",\"year\":2019},{\"arxivId\":\"1812.11737\",\"authors\":[{\"authorId\":\"3449429\",\"name\":\"Alexander Kuhnle\"},{\"authorId\":\"2812333\",\"name\":\"Ann A. Copestake\"}],\"doi\":\"10.18653/v1/W19-4806\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3f45e8e9c56e4fc3f132072ee4867a89f927687d\",\"title\":\"The meaning of \\\"most\\\" for visual question answering models\",\"url\":\"https://www.semanticscholar.org/paper/3f45e8e9c56e4fc3f132072ee4867a89f927687d\",\"venue\":\"ACL 2019\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"13460802\",\"name\":\"Yaning Tan\"},{\"authorId\":\"2169519\",\"name\":\"Xinyan Yang\"},{\"authorId\":\"50336438\",\"name\":\"Tianyi Feng\"},{\"authorId\":\"49659000\",\"name\":\"Xin Xiang\"},{\"authorId\":\"46583513\",\"name\":\"Jianbiao Wang\"},{\"authorId\":\"46269770\",\"name\":\"Long Ye\"}],\"doi\":\"10.1109/icis46139.2019.8940339\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"49671a30b401d47e4949df17630bf6eb5e191068\",\"title\":\"M2-VISD:A Visual Intelligence Evaluation Dataset Based on Virtual Scene*\",\"url\":\"https://www.semanticscholar.org/paper/49671a30b401d47e4949df17630bf6eb5e191068\",\"venue\":\"2019 IEEE/ACIS 18th International Conference on Computer and Information Science (ICIS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1899992\",\"name\":\"Avi Singh\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3965d73c9d7c97cdb391bfd86a15bfd3534cbd32\",\"title\":\"Deep Learning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/3965d73c9d7c97cdb391bfd86a15bfd3534cbd32\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1620218253\",\"name\":\"Sruthy Manmadhan\"},{\"authorId\":\"30588803\",\"name\":\"Binsu C. Kovoor\"}],\"doi\":\"10.1007/978-981-15-5788-0_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c51bfb53b85ef2e19d6ae61ca7be9c0ed3ae63d8\",\"title\":\"Optimal Image Feature Ranking and Fusion for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/c51bfb53b85ef2e19d6ae61ca7be9c0ed3ae63d8\",\"venue\":\"FICTA\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738318751\",\"name\":\"Sinan Tan\"},{\"authorId\":\"3449051\",\"name\":\"Weilai Xiang\"},{\"authorId\":\"2641547\",\"name\":\"H. Liu\"},{\"authorId\":\"1960245583\",\"name\":\"Di Guo\"},{\"authorId\":\"143823065\",\"name\":\"F. Sun\"}],\"doi\":\"10.1007/978-3-030-58601-0_39\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5ed523871586b0f883e4ec890155075b96291a13\",\"title\":\"Multi-agent Embodied Question Answering in Interactive Environments\",\"url\":\"https://www.semanticscholar.org/paper/5ed523871586b0f883e4ec890155075b96291a13\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2003.03716\",\"authors\":[{\"authorId\":null,\"name\":\"Yu-Siang Wang\"},{\"authorId\":\"1947473\",\"name\":\"Yen-Ling Kuo\"},{\"authorId\":\"143912599\",\"name\":\"B. Katz\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3ed1e969bef77692e1f1941c5b7450f83d6b6b22\",\"title\":\"Investigating the Decoders of Maximum Likelihood Sequence Models: A Look-ahead Approach\",\"url\":\"https://www.semanticscholar.org/paper/3ed1e969bef77692e1f1941c5b7450f83d6b6b22\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143808231\",\"name\":\"Nikita Kitaev\"},{\"authorId\":\"38666915\",\"name\":\"D. Klein\"}],\"doi\":\"10.18653/v1/D17-1015\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f03b9b0895f5fb3351bbf3db4b1139af85650543\",\"title\":\"Where is Misty? Interpreting Spatial Descriptors by Modeling Regions in Space\",\"url\":\"https://www.semanticscholar.org/paper/f03b9b0895f5fb3351bbf3db4b1139af85650543\",\"venue\":\"EMNLP\",\"year\":2017},{\"arxivId\":\"1907.09748\",\"authors\":[{\"authorId\":null,\"name\":\"Yaxiong Wang\"},{\"authorId\":\"143727909\",\"name\":\"H. Yang\"},{\"authorId\":\"6468417\",\"name\":\"Xueming Qian\"},{\"authorId\":\"152309770\",\"name\":\"Lin Ma\"},{\"authorId\":\"97486095\",\"name\":\"J. Lu\"},{\"authorId\":\"49730271\",\"name\":\"Biao Li\"},{\"authorId\":\"51952911\",\"name\":\"Xin Fan\"}],\"doi\":\"10.24963/ijcai.2019/526\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"48a7873681c6aa88b9e0e22a25c2a8245eaeb45f\",\"title\":\"Position Focused Attention Network for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/48a7873681c6aa88b9e0e22a25c2a8245eaeb45f\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"1905.04016\",\"authors\":[{\"authorId\":\"48615144\",\"name\":\"Yan Xu\"},{\"authorId\":\"143905981\",\"name\":\"Baoyuan Wu\"},{\"authorId\":\"144618699\",\"name\":\"F. Shen\"},{\"authorId\":\"49411511\",\"name\":\"Yanbo Fan\"},{\"authorId\":\"49891118\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"},{\"authorId\":\"144416719\",\"name\":\"W. Liu\"}],\"doi\":\"10.1109/CVPR.2019.00426\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aacdfd9fd9bf59afdc6612678440581f229d270e\",\"title\":\"Exact Adversarial Attack to Image Captioning via Structured Output Learning With Latent Variables\",\"url\":\"https://www.semanticscholar.org/paper/aacdfd9fd9bf59afdc6612678440581f229d270e\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32928116\",\"name\":\"Amir Rosenfeld\"},{\"authorId\":\"36000196\",\"name\":\"M. Solbach\"},{\"authorId\":\"1727853\",\"name\":\"John K. Tsotsos\"}],\"doi\":\"10.1007/978-3-030-20887-5_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2152673f9e478a19bdb519adf4ca8685e5429f34\",\"title\":\"Totally Looks Like - How Humans Compare, Compared to Machines\",\"url\":\"https://www.semanticscholar.org/paper/2152673f9e478a19bdb519adf4ca8685e5429f34\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48731103\",\"name\":\"Hideki Nakayama\"},{\"authorId\":\"1888638\",\"name\":\"Akihiro Tamura\"},{\"authorId\":\"49584970\",\"name\":\"T. Ninomiya\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4174087859fb7e99e6f24cd7ae765e3b3011a4f9\",\"title\":\"A Visually-Grounded Parallel Corpus with Phrase-to-Region Linking\",\"url\":\"https://www.semanticscholar.org/paper/4174087859fb7e99e6f24cd7ae765e3b3011a4f9\",\"venue\":\"LREC\",\"year\":2020},{\"arxivId\":\"1906.04464\",\"authors\":[{\"authorId\":\"3144952\",\"name\":\"Sibei Yang\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"66616425\",\"name\":\"Yizhou Yu\"}],\"doi\":\"10.1109/tpami.2020.2973983\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"14204fd579ad2802490a8f4a781392ca7ba19c80\",\"title\":\"Relationship-Embedded Representation Learning for Grounding Referring Expressions.\",\"url\":\"https://www.semanticscholar.org/paper/14204fd579ad2802490a8f4a781392ca7ba19c80\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145458333\",\"name\":\"Adel Saleh\"},{\"authorId\":\"46717559\",\"name\":\"Mohamed Abdel-Nasser\"},{\"authorId\":\"2372326\",\"name\":\"Md. Mostafa Kamal Sarker\"},{\"authorId\":\"144687691\",\"name\":\"V. K. Singh\"},{\"authorId\":\"48067440\",\"name\":\"S. Abdulwahab\"},{\"authorId\":\"34379031\",\"name\":\"N. Saffari\"},{\"authorId\":\"145356986\",\"name\":\"M. A. Garcia\"},{\"authorId\":\"143844336\",\"name\":\"D. Puig\"}],\"doi\":\"10.1109/ITCE.2018.8316596\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cfbfdcf64b6b8b91460c5567efbffa9f68592bea\",\"title\":\"Deep visual embedding for image classification\",\"url\":\"https://www.semanticscholar.org/paper/cfbfdcf64b6b8b91460c5567efbffa9f68592bea\",\"venue\":\"2018 International Conference on Innovative Trends in Computer Engineering (ITCE)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151411658\",\"name\":\"Xutao Qu\"},{\"authorId\":\"2127844\",\"name\":\"Dongye Zhuang\"},{\"authorId\":\"152962135\",\"name\":\"Haibin Xie\"}],\"doi\":\"10.1007/978-3-030-27532-7_27\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"02a582e88eff56adc643b4d5404ae78a06524470\",\"title\":\"Semantic Situation Extraction from Satellite Image Based on Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/02a582e88eff56adc643b4d5404ae78a06524470\",\"venue\":\"ICIRA\",\"year\":2019},{\"arxivId\":\"1609.05258\",\"authors\":[{\"authorId\":\"40548044\",\"name\":\"J. Leitner\"},{\"authorId\":\"3469182\",\"name\":\"Adam W. Tow\"},{\"authorId\":\"1771913\",\"name\":\"Niko S\\u00fcnderhauf\"},{\"authorId\":\"1389568206\",\"name\":\"Jake E. Dean\"},{\"authorId\":\"2140658\",\"name\":\"Joseph W. Durham\"},{\"authorId\":\"31426852\",\"name\":\"M. Cooper\"},{\"authorId\":\"2860822\",\"name\":\"M. Eich\"},{\"authorId\":\"51276092\",\"name\":\"Christopher Lehnert\"},{\"authorId\":\"1389919063\",\"name\":\"Ruben Mangels\"},{\"authorId\":\"1763662\",\"name\":\"C. McCool\"},{\"authorId\":\"51879631\",\"name\":\"Peter T. Kujala\"},{\"authorId\":\"36251217\",\"name\":\"Lachlan Nicholson\"},{\"authorId\":\"103102820\",\"name\":\"T. Pham\"},{\"authorId\":\"34978092\",\"name\":\"James Sergeant\"},{\"authorId\":\"144029904\",\"name\":\"L. Wu\"},{\"authorId\":\"2896212\",\"name\":\"Fangyi Zhang\"},{\"authorId\":\"1803115\",\"name\":\"B. Upcroft\"},{\"authorId\":\"1714296\",\"name\":\"P. Corke\"}],\"doi\":\"10.1109/ICRA.2017.7989545\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"912b41ff2e8782e42236f275b6b96281b02eea70\",\"title\":\"The ACRV picking benchmark: A robotic shelf picking benchmark to foster reproducible research\",\"url\":\"https://www.semanticscholar.org/paper/912b41ff2e8782e42236f275b6b96281b02eea70\",\"venue\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145098620\",\"name\":\"M. Ortiz\"},{\"authorId\":\"1683950\",\"name\":\"L. M. Bergasa\"},{\"authorId\":\"144347549\",\"name\":\"R. Arroyo\"},{\"authorId\":\"115023578\",\"name\":\"Sergio \\u00c1lvarez\"},{\"authorId\":\"153051245\",\"name\":\"Aitor Aller\"}],\"doi\":\"10.1007/978-3-030-62579-5_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"60c389da22f6a0ec3467e029842c7c5baf0893d4\",\"title\":\"Towards Fine-Tuning of VQA Models in Public Datasets\",\"url\":\"https://www.semanticscholar.org/paper/60c389da22f6a0ec3467e029842c7c5baf0893d4\",\"venue\":\"WAF\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7499906\",\"name\":\"Xiaomeng Song\"},{\"authorId\":\"46571755\",\"name\":\"Yucheng Shi\"},{\"authorId\":\"46772058\",\"name\":\"X. Chen\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"}],\"doi\":\"10.1145/3240508.3240563\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b08c35f8e529f47a3fdc4f0713ffe77d94c57d87\",\"title\":\"Explore Multi-Step Reasoning in Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b08c35f8e529f47a3fdc4f0713ffe77d94c57d87\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1903.12314\",\"authors\":[{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"145215470\",\"name\":\"Yu Cheng\"},{\"authorId\":\"38079056\",\"name\":\"Jingjing Liu\"}],\"doi\":\"10.1109/ICCV.2019.01041\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d379ba96b8f400b23b2cd72c428af67e578959ea\",\"title\":\"Relation-Aware Graph Attention Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d379ba96b8f400b23b2cd72c428af67e578959ea\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1912.05783\",\"authors\":[{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"153559313\",\"name\":\"H. D. Vries\"},{\"authorId\":\"11030219\",\"name\":\"Timothy J. O'Donnell\"},{\"authorId\":\"37824171\",\"name\":\"Shikhar Murty\"},{\"authorId\":\"1390035743\",\"name\":\"Philippe Beaudoin\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"80deaca65c2c155bd15718eeecff584841eb25b0\",\"title\":\"CLOSURE: Assessing Systematic Generalization of CLEVR Models\",\"url\":\"https://www.semanticscholar.org/paper/80deaca65c2c155bd15718eeecff584841eb25b0\",\"venue\":\"ViGIL@NeurIPS\",\"year\":2019},{\"arxivId\":\"1705.00464\",\"authors\":[{\"authorId\":\"9586147\",\"name\":\"Ted Zhang\"},{\"authorId\":\"1778526\",\"name\":\"Dengxin Dai\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"},{\"authorId\":\"145446752\",\"name\":\"Marie-Francine Moens\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6dc3b8a5fdceaea4b32df8552cbb5a22ef83c197\",\"title\":\"Speech-Based Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/6dc3b8a5fdceaea4b32df8552cbb5a22ef83c197\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121944615\",\"name\":\"Stefan Lee\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3bfd34f04cd1afe1bacf783552bc8004eb50ab1b\",\"title\":\"Data-driven computer vision for science and the humanities\",\"url\":\"https://www.semanticscholar.org/paper/3bfd34f04cd1afe1bacf783552bc8004eb50ab1b\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51021338\",\"name\":\"Nelson Ruwa\"},{\"authorId\":\"3069077\",\"name\":\"Q. Mao\"},{\"authorId\":\"2054737\",\"name\":\"Liangjun Wang\"},{\"authorId\":\"38978232\",\"name\":\"J. Gou\"},{\"authorId\":\"144964053\",\"name\":\"M. Dong\"}],\"doi\":\"10.1016/j.neucom.2018.11.049\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e3e4954e40f33b503f7fe220be90917124a09c43\",\"title\":\"Mood-aware visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/e3e4954e40f33b503f7fe220be90917124a09c43\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50005563\",\"name\":\"G. Christie\"},{\"authorId\":\"2440772\",\"name\":\"Ankit P Laddha\"},{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"1942176\",\"name\":\"K. Kochersberger\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1016/j.cviu.2017.09.001\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2dbca69f6e50c058a44243abfaf669097a02c879\",\"title\":\"Resolving vision and language ambiguities together: Joint segmentation & prepositional attachment resolution in captioned scenes\",\"url\":\"https://www.semanticscholar.org/paper/2dbca69f6e50c058a44243abfaf669097a02c879\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1711219\",\"name\":\"Juzheng Li\"},{\"authorId\":\"144904238\",\"name\":\"H. Su\"},{\"authorId\":\"145254043\",\"name\":\"J. Zhu\"},{\"authorId\":\"47672848\",\"name\":\"Siyu Wang\"},{\"authorId\":\"145803573\",\"name\":\"B. Zhang\"}],\"doi\":\"10.1109/CVPR.2018.00385\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f783d93b983841804a9633a37dfbc624bf5d9bfb\",\"title\":\"Textbook Question Answering Under Instructor Guidance with Memory Networks\",\"url\":\"https://www.semanticscholar.org/paper/f783d93b983841804a9633a37dfbc624bf5d9bfb\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144149597\",\"name\":\"Tianshu Yu\"},{\"authorId\":\"2180892\",\"name\":\"Yikang Li\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"}],\"doi\":\"10.1007/978-3-030-58607-2_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b9ff84d2d45ec704d5680119d0ea0faa01f016be\",\"title\":\"RhyRNN: Rhythmic RNN for Recognizing Events in Long and Complex Videos\",\"url\":\"https://www.semanticscholar.org/paper/b9ff84d2d45ec704d5680119d0ea0faa01f016be\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1804310231\",\"name\":\"Anu Shrestha\"},{\"authorId\":\"1599424042\",\"name\":\"Francesca Spezzano\"},{\"authorId\":\"146973068\",\"name\":\"Indhumathi Gurunathan\"}],\"doi\":\"10.1007/978-3-030-61841-4_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5ac7556b587c0ea1184b2fe5107cb1a42198e9e9\",\"title\":\"Multi-modal Analysis of Misleading Political News\",\"url\":\"https://www.semanticscholar.org/paper/5ac7556b587c0ea1184b2fe5107cb1a42198e9e9\",\"venue\":\"MISDOOM\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":\"49336556\",\"name\":\"Wenjie Wang\"},{\"authorId\":\"48043335\",\"name\":\"R. Hong\"},{\"authorId\":\"152808542\",\"name\":\"Meng Wang\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1145/3343031.3350923\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f7b13eff8ecec771e91a814b598fa33a24980f03\",\"title\":\"Multimodal Dialog System: Generating Responses via Adaptive Decoders\",\"url\":\"https://www.semanticscholar.org/paper/f7b13eff8ecec771e91a814b598fa33a24980f03\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48044229\",\"name\":\"F. Qi\"},{\"authorId\":\"2059713\",\"name\":\"Xiaoshan Yang\"},{\"authorId\":\"145194969\",\"name\":\"C. Xu\"}],\"doi\":\"10.1145/3240508.3240633\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dae315b084b9164ac68da26aaa73de877f73f75c\",\"title\":\"A Unified Framework for Multimodal Domain Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/dae315b084b9164ac68da26aaa73de877f73f75c\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390626344\",\"name\":\"Zhiyuan Liu\"},{\"authorId\":\"2427350\",\"name\":\"Yankai Lin\"},{\"authorId\":\"1753344\",\"name\":\"M. Sun\"}],\"doi\":\"10.1007/978-981-15-5573-2_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7cd0c93b77bd2cf085c02c7a98118b6b43592110\",\"title\":\"Cross-Modal Representation\",\"url\":\"https://www.semanticscholar.org/paper/7cd0c93b77bd2cf085c02c7a98118b6b43592110\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9515493\",\"name\":\"Liangfu Cao\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"47158869\",\"name\":\"Xing Xu\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1007/978-3-319-68155-9_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"47d76f7c19c53a83704fa8c91d88add93c5654d1\",\"title\":\"Jointly Learning Attentions with Semantic Cross-Modal Correlation for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/47d76f7c19c53a83704fa8c91d88add93c5654d1\",\"venue\":\"ADC\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66119300\",\"name\":\"Shuangjia Zheng\"},{\"authorId\":null,\"name\":\"Yongjian Li\"},{\"authorId\":\"98498212\",\"name\":\"Sheng Chen\"},{\"authorId\":\"152327955\",\"name\":\"J. Xu\"},{\"authorId\":\"46286259\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1038/s42256-020-0152-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"10a6d56b10e8945b98f7ac17f234475e64736cb4\",\"title\":\"Predicting drug\\u2013protein interaction using quasi-visual question answering system\",\"url\":\"https://www.semanticscholar.org/paper/10a6d56b10e8945b98f7ac17f234475e64736cb4\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1905.12794\",\"authors\":[{\"authorId\":\"121433787\",\"name\":\"Xiaoxiao Guo\"},{\"authorId\":\"47987329\",\"name\":\"H. Wu\"},{\"authorId\":\"2926307\",\"name\":\"Yupeng Gao\"},{\"authorId\":\"2071376\",\"name\":\"Steven J. Rennie\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f472b819ce521337c01e4ebf91714f93413d9997\",\"title\":\"Fashion IQ: A New Dataset towards Retrieving Images by Natural Language Feedback\",\"url\":\"https://www.semanticscholar.org/paper/f472b819ce521337c01e4ebf91714f93413d9997\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145089978\",\"name\":\"D. Damen\"},{\"authorId\":\"28798386\",\"name\":\"H. Doughty\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"12387007\",\"name\":\"Evangelos Kazakos\"},{\"authorId\":\"3420479\",\"name\":\"D. Moltisanti\"},{\"authorId\":\"47077615\",\"name\":\"J. Munro\"},{\"authorId\":\"2682004\",\"name\":\"T. Perrett\"},{\"authorId\":\"50065546\",\"name\":\"W. Price\"},{\"authorId\":\"145032628\",\"name\":\"Michael Wray\"}],\"doi\":\"10.1007/978-3-030-01225-0_44\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"443b1a20b30f09a2e4d6c47a8a9412a668f615fd\",\"title\":\"Scaling Egocentric Vision: The Dataset\",\"url\":\"https://www.semanticscholar.org/paper/443b1a20b30f09a2e4d6c47a8a9412a668f615fd\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152902853\",\"name\":\"Vedant Singh\"},{\"authorId\":\"144833581\",\"name\":\"V. Doshi\"},{\"authorId\":\"66507017\",\"name\":\"Mitali Dave\"},{\"authorId\":\"144301613\",\"name\":\"A. Desai\"},{\"authorId\":\"1729588200\",\"name\":\"Smith Agrawal\"},{\"authorId\":\"144791188\",\"name\":\"J. Shah\"},{\"authorId\":\"9272713\",\"name\":\"P. Kanani\"}],\"doi\":\"10.1007/978-981-15-4451-4_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e5730053fd973426028fa3b47a55be9d7fd2938d\",\"title\":\"Answering Questions in Natural Language About Images Using Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/e5730053fd973426028fa3b47a55be9d7fd2938d\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27743961\",\"name\":\"Dimitris Gkoumas\"},{\"authorId\":\"41219390\",\"name\":\"Qiuchi Li\"},{\"authorId\":\"1784800\",\"name\":\"C. Lioma\"},{\"authorId\":\"47111898\",\"name\":\"Yijun Yu\"},{\"authorId\":\"51002652\",\"name\":\"Da-wei Song\"},{\"authorId\":\"51002652\",\"name\":\"Da-wei Song\"}],\"doi\":\"10.1016/J.INFFUS.2020.09.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b3b960ceed80dc0b5bf749ae6e152abefef52f52\",\"title\":\"What makes the difference? An empirical comparison of fusion strategies for multimodal language analysis\",\"url\":\"https://www.semanticscholar.org/paper/b3b960ceed80dc0b5bf749ae6e152abefef52f52\",\"venue\":\"Inf. Fusion\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11611009\",\"name\":\"Chun-ye Li\"},{\"authorId\":\"8756547\",\"name\":\"Liya Kong\"},{\"authorId\":\"153043900\",\"name\":\"Zhi-Ping Zhou\"}],\"doi\":\"10.1016/j.jvcir.2020.102956\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"32a9b74561ee7c7b2d9663248b515168676d9321\",\"title\":\"Improved-StoryGAN for sequential images visualization\",\"url\":\"https://www.semanticscholar.org/paper/32a9b74561ee7c7b2d9663248b515168676d9321\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145746152\",\"name\":\"S. K. Kolluru\"},{\"authorId\":\"71008717\",\"name\":\"Shreyans Shrimal\"},{\"authorId\":\"72376932\",\"name\":\"S. Krishnaswamy\"}],\"doi\":\"10.1007/978-981-10-6418-0_11\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"125172e566293a80869a7b4ed6c5f6c7d7b85568\",\"title\":\"CognitiveCam: A Visual Question Answering Application\",\"url\":\"https://www.semanticscholar.org/paper/125172e566293a80869a7b4ed6c5f6c7d7b85568\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1812.03928\",\"authors\":[{\"authorId\":\"49889702\",\"name\":\"Y. Zhang\"},{\"authorId\":\"3724810\",\"name\":\"J. Hare\"},{\"authorId\":\"1398417301\",\"name\":\"A. Pr\\u00fcgel-Bennett\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"8083cfb0e76358ab54f92eedbe13ed6a874a48e5\",\"title\":\"Learning Representations of Sets through Optimized Permutations\",\"url\":\"https://www.semanticscholar.org/paper/8083cfb0e76358ab54f92eedbe13ed6a874a48e5\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1902.05715\",\"authors\":[{\"authorId\":\"1703558\",\"name\":\"S. Ghosh\"},{\"authorId\":\"69919463\",\"name\":\"Giedrius Burachas\"},{\"authorId\":\"20686092\",\"name\":\"Arijit Ray\"},{\"authorId\":\"6052800\",\"name\":\"Avi Ziskind\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ea0ea5e0ccfb2ccaaba2c9757f4ab5ac875965cc\",\"title\":\"Generating Natural Language Explanations for Visual Question Answering using Scene Graphs and Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/ea0ea5e0ccfb2ccaaba2c9757f4ab5ac875965cc\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1710.01202\",\"authors\":[{\"authorId\":\"15732649\",\"name\":\"F. Yan\"},{\"authorId\":\"1712041\",\"name\":\"K. Mikolajczyk\"},{\"authorId\":\"47091894\",\"name\":\"J. Kittler\"}],\"doi\":\"10.1109/ICPR.2018.8545582\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0e85b9c05d6f6d190f7c0434e3356a8bfb97bdec\",\"title\":\"Person Re-Identification with Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/0e85b9c05d6f6d190f7c0434e3356a8bfb97bdec\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":\"1605.02697\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":\"10.1007/s11263-017-1038-2\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f7ddf708442dad7ed2978658b101c797c7c10220\",\"title\":\"Ask Your Neurons: A Deep Learning Approach to Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f7ddf708442dad7ed2978658b101c797c7c10220\",\"venue\":\"International Journal of Computer Vision\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144638992\",\"name\":\"Xinzhe Han\"},{\"authorId\":\"47672591\",\"name\":\"Shuhui Wang\"},{\"authorId\":\"145422145\",\"name\":\"Chi Su\"},{\"authorId\":\"153645460\",\"name\":\"W. Zhang\"},{\"authorId\":\"153159021\",\"name\":\"Qingming Huang\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1007/978-3-030-58545-7_32\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2a315d4e5db42ae5d45f7c1702998b41ac26babe\",\"title\":\"Interpretable Visual Reasoning via Probabilistic Formulation Under Natural Supervision\",\"url\":\"https://www.semanticscholar.org/paper/2a315d4e5db42ae5d45f7c1702998b41ac26babe\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151496750\",\"name\":\"Surgan Jandial\"},{\"authorId\":\"9551558\",\"name\":\"Ayush Chopra\"},{\"authorId\":\"10357841\",\"name\":\"Pinkesh Badjatiya\"},{\"authorId\":\"1946040746\",\"name\":\"Pranit Chawla\"},{\"authorId\":\"39230373\",\"name\":\"Mausoom Sarkar\"},{\"authorId\":\"1557631185\",\"name\":\"Balaji Krishnamurthy\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"dcf55ad1e7b3b59c72159a51806cee543fbd6574\",\"title\":\"TRACE: Transform Aggregate and Compose Visiolinguistic Representations for Image Search with Text Feedback\",\"url\":\"https://www.semanticscholar.org/paper/dcf55ad1e7b3b59c72159a51806cee543fbd6574\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1606.03556\",\"authors\":[{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"37825612\",\"name\":\"Harsh Agrawal\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1016/j.cviu.2017.10.001\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"58cb0c24c936b8a14ca7b2d56ba80de733c545b3\",\"title\":\"Human Attention in Visual Question Answering: Do Humans and Deep Networks look at the same regions?\",\"url\":\"https://www.semanticscholar.org/paper/58cb0c24c936b8a14ca7b2d56ba80de733c545b3\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30793303\",\"name\":\"Amirhoshang Hoseinpour Dehkordi\"},{\"authorId\":\"153235768\",\"name\":\"M. Alizadeh\"},{\"authorId\":\"2005221955\",\"name\":\"Ali Movaghar\"}],\"doi\":\"10.36227/techrxiv.12928544.v1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b678835c5de86ebe2031da902957aead8de931aa\",\"title\":\"Linear Temporal Public Announcement Logic: a new perspective for reasoning the knowledge of multi-classifiers\",\"url\":\"https://www.semanticscholar.org/paper/b678835c5de86ebe2031da902957aead8de931aa\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51126032\",\"name\":\"Zhuoqian Yang\"},{\"authorId\":\"119883573\",\"name\":\"J. Yu\"},{\"authorId\":\"119883554\",\"name\":\"J. Yu\"},{\"authorId\":null,\"name\":\"Zengchang Qin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"490a9ee7c995140136d2c5054081c08429ebc171\",\"title\":\"Scene Graph Reasoning with Prior Visual Relationship for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/490a9ee7c995140136d2c5054081c08429ebc171\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1906.05797\",\"authors\":[{\"authorId\":\"20128275\",\"name\":\"J. Straub\"},{\"authorId\":\"2761402\",\"name\":\"T. Whelan\"},{\"authorId\":\"2562254\",\"name\":\"Lingni Ma\"},{\"authorId\":\"1519046041\",\"name\":\"Yufan Chen\"},{\"authorId\":\"8405939\",\"name\":\"Erik Wijmans\"},{\"authorId\":\"46818829\",\"name\":\"S. Green\"},{\"authorId\":\"152219059\",\"name\":\"J. Engel\"},{\"authorId\":\"1397877487\",\"name\":\"Raul Mur-Artal\"},{\"authorId\":\"4547952\",\"name\":\"C. Ren\"},{\"authorId\":\"4353520\",\"name\":\"S. Verma\"},{\"authorId\":\"1412348616\",\"name\":\"Anton Clarkson\"},{\"authorId\":\"7890648\",\"name\":\"Mingfei Yan\"},{\"authorId\":\"1419438664\",\"name\":\"Brian Budge\"},{\"authorId\":\"113548407\",\"name\":\"Yajie Yan\"},{\"authorId\":\"3365823\",\"name\":\"Xiaqing Pan\"},{\"authorId\":\"1411072569\",\"name\":\"June Yon\"},{\"authorId\":\"1416072084\",\"name\":\"Yuyang Zou\"},{\"authorId\":\"153626423\",\"name\":\"K. Leon\"},{\"authorId\":\"1410895983\",\"name\":\"Nigel Carter\"},{\"authorId\":\"2446207\",\"name\":\"Jesus Briales\"},{\"authorId\":\"8412769\",\"name\":\"Tyler Gillingham\"},{\"authorId\":\"144578041\",\"name\":\"Elias Mueggler\"},{\"authorId\":\"1416771217\",\"name\":\"Luis Pesqueira\"},{\"authorId\":\"2295141\",\"name\":\"M. Savva\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"1419436752\",\"name\":\"Hauke M. Strasdat\"},{\"authorId\":\"1769365\",\"name\":\"R. D. Nardi\"},{\"authorId\":\"1689293\",\"name\":\"M. Goesele\"},{\"authorId\":\"3289186\",\"name\":\"S. Lovegrove\"},{\"authorId\":\"50366818\",\"name\":\"Richard A. Newcombe\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"60f511eef446120fe59563ee976f948d5e3f9064\",\"title\":\"The Replica Dataset: A Digital Replica of Indoor Spaces\",\"url\":\"https://www.semanticscholar.org/paper/60f511eef446120fe59563ee976f948d5e3f9064\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1585810093\",\"name\":\"Laetitia Teodorescu\"},{\"authorId\":\"1380228856\",\"name\":\"Katja Hofmann\"},{\"authorId\":\"1720664\",\"name\":\"Pierre-Yves Oudeyer\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bd90945c45f7f7445655ddf53110c45f97202804\",\"title\":\"SpatialSim: Recognizing Spatial Configurations of Objects with Graph Neural Networks.\",\"url\":\"https://www.semanticscholar.org/paper/bd90945c45f7f7445655ddf53110c45f97202804\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3196632\",\"name\":\"Q. Tian\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a337d41731a28ba1f43e1ca6515ef38a59f0c134\",\"title\":\"Towards Supporting Visual Question and Answering Applications\",\"url\":\"https://www.semanticscholar.org/paper/a337d41731a28ba1f43e1ca6515ef38a59f0c134\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1765212\",\"name\":\"C. Hori\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"},{\"authorId\":\"144179578\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a212be7ec1ff75ecfee52c7c49c73d7244a87eb7\",\"title\":\"Video Scene-Aware Dialog Track in DSTC 7\",\"url\":\"https://www.semanticscholar.org/paper/a212be7ec1ff75ecfee52c7c49c73d7244a87eb7\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1908.09317\",\"authors\":[{\"authorId\":\"3422200\",\"name\":\"I. Laina\"},{\"authorId\":\"49359942\",\"name\":\"C. Rupprecht\"},{\"authorId\":\"145587209\",\"name\":\"N. Navab\"}],\"doi\":\"10.1109/ICCV.2019.00751\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a4ff2a0b65b7dfdecee8d2e4bc0c5f7e1fee03be\",\"title\":\"Towards Unsupervised Image Captioning With Shared Multimodal Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/a4ff2a0b65b7dfdecee8d2e4bc0c5f7e1fee03be\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22651219\",\"name\":\"Ko Endo\"},{\"authorId\":\"96853476\",\"name\":\"Masaki Aono\"},{\"authorId\":\"143662759\",\"name\":\"Eric Nichols\"},{\"authorId\":\"1747395\",\"name\":\"Kotaro Funakoshi\"}],\"doi\":\"10.24963/ijcai.2017/558\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8b9db19d0d3e2a7d740be811810a043a04d6226a\",\"title\":\"An Attention-based Regression Model for Grounding Textual Phrases in Images\",\"url\":\"https://www.semanticscholar.org/paper/8b9db19d0d3e2a7d740be811810a043a04d6226a\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1581441035\",\"name\":\"Afrae Bghiel\"},{\"authorId\":\"1581444871\",\"name\":\"Yousra Dahdouh\"},{\"authorId\":\"51162320\",\"name\":\"Imane Allaouzi\"},{\"authorId\":\"143678432\",\"name\":\"M. Ahmed\"},{\"authorId\":\"47708727\",\"name\":\"A. Boudhir\"}],\"doi\":\"10.1007/978-3-030-37629-1_35\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1ba86d31844d9a1bb1c26928f555025508e7f963\",\"title\":\"Visual Question Answering System for Identifying Medical Images Attributes\",\"url\":\"https://www.semanticscholar.org/paper/1ba86d31844d9a1bb1c26928f555025508e7f963\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1907.10500\",\"authors\":[{\"authorId\":\"15028494\",\"name\":\"Yen-Wei Chang\"},{\"authorId\":\"1749122\",\"name\":\"Wen-Hsiao Peng\"}],\"doi\":\"10.1109/ICME.2019.00096\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8819217e05d1c7ef8efc62989c04235df6750fb5\",\"title\":\"Learning Goal-Oriented Visual Dialog Agents: Imitating and Surpassing Analytic Experts\",\"url\":\"https://www.semanticscholar.org/paper/8819217e05d1c7ef8efc62989c04235df6750fb5\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":\"1911.11702\",\"authors\":[{\"authorId\":\"1410334693\",\"name\":\"Miguel Fabian Romero-Rond\\u00f3n\"},{\"authorId\":\"1750472\",\"name\":\"L. Sassatelli\"},{\"authorId\":\"1398078454\",\"name\":\"R. Aparicio-Pardo\"},{\"authorId\":\"150103589\",\"name\":\"F. Precioso\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fbc949df3b994709a806ddb2a3d4ce5414657cd0\",\"title\":\"Revisiting Deep Architectures for Head Motion Prediction in 360\\u00b0 Videos\",\"url\":\"https://www.semanticscholar.org/paper/fbc949df3b994709a806ddb2a3d4ce5414657cd0\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145019838\",\"name\":\"F. A. O. Santos\"},{\"authorId\":\"2948325\",\"name\":\"C. Zanchettin\"},{\"authorId\":\"145254176\",\"name\":\"L. Matos\"},{\"authorId\":\"1701346\",\"name\":\"P. Novais\"}],\"doi\":\"10.1007/978-3-030-29859-3_27\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b03f363c8405b7a00e00749d9fbfdc8a3d69cbc7\",\"title\":\"Active Image Data Augmentation\",\"url\":\"https://www.semanticscholar.org/paper/b03f363c8405b7a00e00749d9fbfdc8a3d69cbc7\",\"venue\":\"HAIS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"31081539\",\"name\":\"Pengpeng Zeng\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"6820648\",\"name\":\"Xianglong Liu\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1145/3240508.3240687\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"97add9744ae63c5e7af9d9861ecc18a2734d3f0c\",\"title\":\"Examine before You Answer: Multi-task Learning with Adaptive-attentions for Multiple-choice VQA\",\"url\":\"https://www.semanticscholar.org/paper/97add9744ae63c5e7af9d9861ecc18a2734d3f0c\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12271314\",\"name\":\"Chenwei Tang\"},{\"authorId\":\"2053666\",\"name\":\"J. Lv\"},{\"authorId\":\"47558162\",\"name\":\"Y. Chen\"},{\"authorId\":\"34809813\",\"name\":\"J. Guo\"}],\"doi\":\"10.1007/S00500-018-3051-Y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e4d99da5e3523ac174cc554441bf293b8c39bba3\",\"title\":\"An angle-based method for measuring the semantic similarity between visual and textual features\",\"url\":\"https://www.semanticscholar.org/paper/e4d99da5e3523ac174cc554441bf293b8c39bba3\",\"venue\":\"Soft Comput.\",\"year\":2019},{\"arxivId\":\"1810.03649\",\"authors\":[{\"authorId\":\"31448527\",\"name\":\"S. Ramakrishnan\"},{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"45ec1446f42c0a7c7fe74319118335c76e0f7b19\",\"title\":\"Overcoming Language Priors in Visual Question Answering with Adversarial Regularization\",\"url\":\"https://www.semanticscholar.org/paper/45ec1446f42c0a7c7fe74319118335c76e0f7b19\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1577606322\",\"name\":\"Shrey Nahar\"},{\"authorId\":\"1576127863\",\"name\":\"S. Naik\"},{\"authorId\":\"15488883\",\"name\":\"Niti H Shah\"},{\"authorId\":\"49485385\",\"name\":\"Saumya Shah\"},{\"authorId\":\"9079986\",\"name\":\"Lakshmi Kurup\"}],\"doi\":\"10.1007/978-3-030-38445-6_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1bac534a3a2672297db2a76a4491b275e464bdbd\",\"title\":\"Automated Question Generation and Answer Verification Using Visual Data\",\"url\":\"https://www.semanticscholar.org/paper/1bac534a3a2672297db2a76a4491b275e464bdbd\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39939127\",\"name\":\"Yingying Zhang\"},{\"authorId\":\"144737162\",\"name\":\"Q. Fang\"},{\"authorId\":\"2070687\",\"name\":\"S. Qian\"},{\"authorId\":\"48258806\",\"name\":\"C. Xu\"}],\"doi\":\"10.1145/3384675\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8c0cd8717efb8d394bd73369766b034b70c96e86\",\"title\":\"Knowledge-aware Attentive Wasserstein Adversarial Dialogue Response Generation\",\"url\":\"https://www.semanticscholar.org/paper/8c0cd8717efb8d394bd73369766b034b70c96e86\",\"venue\":\"ACM Trans. Intell. Syst. Technol.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22063226\",\"name\":\"Q. Zhang\"},{\"authorId\":\"39092098\",\"name\":\"Y. Wu\"},{\"authorId\":\"144838173\",\"name\":\"Hao Zhang\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1016/j.cviu.2018.09.008\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ddef816dc6f0131afcbde1350133377fdd20e305\",\"title\":\"Mining deep And-Or object structures via cost-sensitive question-answer-based active annotations\",\"url\":\"https://www.semanticscholar.org/paper/ddef816dc6f0131afcbde1350133377fdd20e305\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8799308\",\"name\":\"U. Nadeem\"},{\"authorId\":\"2210661\",\"name\":\"S. Shah\"},{\"authorId\":\"2470423\",\"name\":\"Ferdous Sohel\"},{\"authorId\":\"2444665\",\"name\":\"R. Togneri\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"}],\"doi\":\"10.1007/978-3-030-11479-4_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e549a9049bbbcb1a9e854de2f05fdfae4fb0da7d\",\"title\":\"Deep Learning for Scene Understanding\",\"url\":\"https://www.semanticscholar.org/paper/e549a9049bbbcb1a9e854de2f05fdfae4fb0da7d\",\"venue\":\"Handbook of Deep Learning Applications\",\"year\":2019},{\"arxivId\":\"1708.02043\",\"authors\":[{\"authorId\":\"32227979\",\"name\":\"M. Tanti\"},{\"authorId\":\"1700894\",\"name\":\"Albert Gatt\"},{\"authorId\":\"2370774\",\"name\":\"K. Camilleri\"}],\"doi\":\"10.18653/v1/W17-3506\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d22f972448a2336677ae6ff2877fae010c7dfa2\",\"title\":\"What is the Role of Recurrent Neural Networks (RNNs) in an Image Caption Generator?\",\"url\":\"https://www.semanticscholar.org/paper/3d22f972448a2336677ae6ff2877fae010c7dfa2\",\"venue\":\"INLG\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3393294\",\"name\":\"Ilija Ilievski\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":\"10.1145/3126686.3126695\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c315a0109b67cda1f55dee7967f570f0579a8ee8\",\"title\":\"Generative Attention Model with Adversarial Self-learning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/c315a0109b67cda1f55dee7967f570f0579a8ee8\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10321974\",\"name\":\"Chunyi Yue\"},{\"authorId\":\"49221827\",\"name\":\"H. Cao\"},{\"authorId\":\"50033756\",\"name\":\"Kun Xiong\"},{\"authorId\":\"2339882\",\"name\":\"Anqi Cui\"},{\"authorId\":\"10303486\",\"name\":\"Haocheng Qin\"},{\"authorId\":\"35834541\",\"name\":\"Ming Li\"}],\"doi\":\"10.1016/j.eswa.2017.03.006\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"350de5ce7ae6430f0ade28dc0d8c009e875834f1\",\"title\":\"Enhanced question understanding with dynamic memory networks for textual question answering\",\"url\":\"https://www.semanticscholar.org/paper/350de5ce7ae6430f0ade28dc0d8c009e875834f1\",\"venue\":\"Expert Syst. Appl.\",\"year\":2017},{\"arxivId\":\"1606.01847\",\"authors\":[{\"authorId\":\"50599725\",\"name\":\"A. Fukui\"},{\"authorId\":\"3422202\",\"name\":\"Dong Huk Park\"},{\"authorId\":\"3422876\",\"name\":\"Daylen Yang\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.18653/v1/D16-1044\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"fddc15480d086629b960be5bff96232f967f2252\",\"title\":\"Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/fddc15480d086629b960be5bff96232f967f2252\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1711219\",\"name\":\"Juzheng Li\"},{\"authorId\":\"144904238\",\"name\":\"H. Su\"},{\"authorId\":\"145254043\",\"name\":\"J. Zhu\"},{\"authorId\":\"49846744\",\"name\":\"Bo Zhang\"}],\"doi\":\"10.1109/ICME.2018.8486468\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c1655b32a30165f7863ece52c54270662a28be0e\",\"title\":\"Essay-Anchor Attentive Multi-Modal Bilinear Pooling for Textbook Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/c1655b32a30165f7863ece52c54270662a28be0e\",\"venue\":\"2018 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3430787\",\"name\":\"Sanbi Luo\"},{\"authorId\":\"144977051\",\"name\":\"S. Liu\"},{\"authorId\":\"2710247\",\"name\":\"Jizhong Han\"},{\"authorId\":\"145791297\",\"name\":\"T. Guo\"}],\"doi\":\"10.1007/978-3-030-00764-5_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c8b4afc0c6b7cfce28376a228b93844f75dba189\",\"title\":\"Multimodal Fusion for Traditional Chinese Painting Generation\",\"url\":\"https://www.semanticscholar.org/paper/c8b4afc0c6b7cfce28376a228b93844f75dba189\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":\"1908.06327\",\"authors\":[{\"authorId\":\"38727845\",\"name\":\"A. Burns\"},{\"authorId\":\"73441526\",\"name\":\"R. Tan\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"},{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"}],\"doi\":\"10.1109/ICCV.2019.00757\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"71634edd80ce000b3d1e462137fcfa8c2b377943\",\"title\":\"Language Features Matter: Effective Language Representations for Vision-Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/71634edd80ce000b3d1e462137fcfa8c2b377943\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1786202\",\"name\":\"H. Bunt\"},{\"authorId\":\"144090767\",\"name\":\"V. Petukhova\"},{\"authorId\":\"3228958\",\"name\":\"A. Malchanau\"},{\"authorId\":\"5730733\",\"name\":\"A. Fang\"},{\"authorId\":\"3448970\",\"name\":\"K. Wijnhoven\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e9841511964dba894a0e658d27ac9b94512ddbf4\",\"title\":\"Proceedings 12th Joint ACL-ISO Workshop on Interoperable Semantic Annotation (ISA-12)\",\"url\":\"https://www.semanticscholar.org/paper/e9841511964dba894a0e658d27ac9b94512ddbf4\",\"venue\":\"ACL 2016\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47002278\",\"name\":\"Yikuan Li\"},{\"authorId\":\"51464971\",\"name\":\"Hanyin Wang\"},{\"authorId\":\"1830568527\",\"name\":\"Yuan Luo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ff554f6228cf1f939a0e9e44ada06ef9cd28be15\",\"title\":\"A Comparison of Pre-trained Vision-and-Language Models for Multimodal Representation Learning across Medical Images and Reports\",\"url\":\"https://www.semanticscholar.org/paper/ff554f6228cf1f939a0e9e44ada06ef9cd28be15\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1908.08191\",\"authors\":[{\"authorId\":\"152923110\",\"name\":\"Kuan-Yen Lin\"},{\"authorId\":\"23608432\",\"name\":\"Chao-Chun Hsu\"},{\"authorId\":\"1725643\",\"name\":\"Yun-Nung (Vivian) Chen\"},{\"authorId\":\"1746959\",\"name\":\"Lun-Wei Ku\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ee1add32f430fb6e9f82958dc431b635174ee9bd\",\"title\":\"Entropy-Enhanced Multimodal Attention Model for Scene-Aware Dialogue Generation\",\"url\":\"https://www.semanticscholar.org/paper/ee1add32f430fb6e9f82958dc431b635174ee9bd\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48925229\",\"name\":\"Byung-Ju Kim\"},{\"authorId\":\"100498018\",\"name\":\"\\uae40\\ubcd1\\uc8fc\"}],\"doi\":\"10.1049/EL.2017.1881\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b86686436608b4083bbca19e6e71e2f780ff3ef7\",\"title\":\"Question aware prediction with candidate answer recommendation for visual question answering = \\ud6c4\\ubcf4 \\ub2f5\\ubcc0 \\uc608\\uce21\\uc744 \\ud1b5\\ud55c \\uc601\\uc0c1 \\uae30\\ubc18 \\uc9c8\\uc758\\uc751\\ub2f5\\uc5d0 \\ub300\\ud55c \\uc5f0\\uad6c\",\"url\":\"https://www.semanticscholar.org/paper/b86686436608b4083bbca19e6e71e2f780ff3ef7\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46961137\",\"name\":\"Chen Cui\"},{\"authorId\":\"49336556\",\"name\":\"Wenjie Wang\"},{\"authorId\":\"33977299\",\"name\":\"X. Song\"},{\"authorId\":\"1730108\",\"name\":\"Minlie Huang\"},{\"authorId\":\"40620796\",\"name\":\"Xin-Shun Xu\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"}],\"doi\":\"10.1145/3331184.3331226\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e92a32c45ccc0c933553d6f28b3551f0293bcd20\",\"title\":\"User Attention-guided Multimodal Dialog Systems\",\"url\":\"https://www.semanticscholar.org/paper/e92a32c45ccc0c933553d6f28b3551f0293bcd20\",\"venue\":\"SIGIR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32208823\",\"name\":\"S. H. Kumar\"},{\"authorId\":\"3442103\",\"name\":\"Eda Okur\"},{\"authorId\":\"38531701\",\"name\":\"S. Sahay\"},{\"authorId\":\"4240351\",\"name\":\"Jonathan Huang\"},{\"authorId\":\"1896095\",\"name\":\"L. Nachman\"}],\"doi\":\"10.1016/j.csl.2020.101102\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a00a2b6eb505a172a36de81dc803a9d45597bc8a\",\"title\":\"Investigating topics, audio representations and attention for multimodal scene-aware dialog\",\"url\":\"https://www.semanticscholar.org/paper/a00a2b6eb505a172a36de81dc803a9d45597bc8a\",\"venue\":\"Comput. Speech Lang.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8937909\",\"name\":\"Nazneen Rajani\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"}],\"doi\":\"10.1007/978-3-319-98131-4_7\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a9d2c96cead937e53e614abb9fd051574a55c77a\",\"title\":\"Ensembling Visual Explanations\",\"url\":\"https://www.semanticscholar.org/paper/a9d2c96cead937e53e614abb9fd051574a55c77a\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36300013\",\"name\":\"Y. Rao\"},{\"authorId\":\"3607957\",\"name\":\"Haoran Xie\"},{\"authorId\":\"48032513\",\"name\":\"X. Liu\"},{\"authorId\":\"145726530\",\"name\":\"Q. Li\"},{\"authorId\":\"1773235\",\"name\":\"Fu Lee Wang\"},{\"authorId\":\"39756936\",\"name\":\"T. Wong\"}],\"doi\":\"10.3233/JIFS-169094\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9f306cb9fcaf19ae60305a83ed6e109015ba6ea1\",\"title\":\"User authority ranking models for community question answering\",\"url\":\"https://www.semanticscholar.org/paper/9f306cb9fcaf19ae60305a83ed6e109015ba6ea1\",\"venue\":\"J. Intell. Fuzzy Syst.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50317425\",\"name\":\"Abhishek Das\"},{\"authorId\":\"37825612\",\"name\":\"Harsh Agrawal\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.18653/v1/D16-1092\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"00158a3a5f00bce40d9e0711d78cd9a6b099c21b\",\"title\":\"Human Attention in Visual Question Answering: Do Humans and Deep Networks look at the same regions?\",\"url\":\"https://www.semanticscholar.org/paper/00158a3a5f00bce40d9e0711d78cd9a6b099c21b\",\"venue\":\"EMNLP 2016\",\"year\":2016},{\"arxivId\":\"1806.05645\",\"authors\":[{\"authorId\":\"2112133\",\"name\":\"H. T. Vu\"},{\"authorId\":\"5975291\",\"name\":\"C. Greco\"},{\"authorId\":\"145095497\",\"name\":\"A. Erofeeva\"},{\"authorId\":\"51030589\",\"name\":\"Somayeh Jafaritazehjan\"},{\"authorId\":\"50816019\",\"name\":\"Guido Linders\"},{\"authorId\":\"32227979\",\"name\":\"M. Tanti\"},{\"authorId\":\"50829868\",\"name\":\"A. Testoni\"},{\"authorId\":\"145040726\",\"name\":\"R. Bernardi\"},{\"authorId\":\"1700894\",\"name\":\"Albert Gatt\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1235dd37312cb20aced0e97d953f6379d8a0c7d4\",\"title\":\"Grounded Textual Entailment\",\"url\":\"https://www.semanticscholar.org/paper/1235dd37312cb20aced0e97d953f6379d8a0c7d4\",\"venue\":\"COLING\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2681569\",\"name\":\"Haoqi Fan\"},{\"authorId\":\"27329137\",\"name\":\"Jiatong Zhou\"}],\"doi\":\"10.1109/CVPR.2018.00118\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"135c71101af5d030f8cf470c454e7b655d699920\",\"title\":\"Stacked Latent Attention for Multimodal Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/135c71101af5d030f8cf470c454e7b655d699920\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1902.07864\",\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"1606411716\",\"name\":\"Karan Desai\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"cef77310f326bd30b172459dbecaedf228fc7b23\",\"title\":\"Probabilistic Neural-symbolic Models for Interpretable Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/cef77310f326bd30b172459dbecaedf228fc7b23\",\"venue\":\"ICML\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8004535\",\"name\":\"Chaojun Han\"},{\"authorId\":\"144618699\",\"name\":\"F. Shen\"},{\"authorId\":\"46457827\",\"name\":\"Li Liu\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1145/3240508.3240611\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f51d9d34635ad9f6310d767869710e78fc4174bf\",\"title\":\"Visual Spatial Attention Network for Relationship Detection\",\"url\":\"https://www.semanticscholar.org/paper/f51d9d34635ad9f6310d767869710e78fc4174bf\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2490430\",\"name\":\"Carina Silberer\"},{\"authorId\":\"1823362\",\"name\":\"J. Uijlings\"},{\"authorId\":\"1747893\",\"name\":\"Mirella Lapata\"}],\"doi\":\"10.1017/S1351324918000104\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a69f7e80bae350dd51518424abd2d63b73cb6ee6\",\"title\":\"Understanding visual scenes\",\"url\":\"https://www.semanticscholar.org/paper/a69f7e80bae350dd51518424abd2d63b73cb6ee6\",\"venue\":\"Nat. Lang. Eng.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47740650\",\"name\":\"Jian Jhen Chen\"},{\"authorId\":\"145496509\",\"name\":\"Jie Shao\"},{\"authorId\":\"144618699\",\"name\":\"F. Shen\"},{\"authorId\":\"2838253\",\"name\":\"C. He\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1145/3132847.3132922\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3085671f6232aac4492ad861d09334b8f3a7e2a7\",\"title\":\"Movie Fill in the Blank with Adaptive Temporal Attention and Description Update\",\"url\":\"https://www.semanticscholar.org/paper/3085671f6232aac4492ad861d09334b8f3a7e2a7\",\"venue\":\"CIKM\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23865980\",\"name\":\"R. Gupta\"},{\"authorId\":\"1753738514\",\"name\":\"Parikshit Hooda\"},{\"authorId\":\"1753737639\",\"name\":\"Sanjeev\"},{\"authorId\":\"1753738106\",\"name\":\"Nikhil Kumar Chikkara\"}],\"doi\":\"10.1109/ICICCS48265.2020.9121068\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6788a018647840cfac2c9af608c5a1a7903d8778\",\"title\":\"Natural Language Processing based Visual Question Answering Efficient: an EfficientDet Approach\",\"url\":\"https://www.semanticscholar.org/paper/6788a018647840cfac2c9af608c5a1a7903d8778\",\"venue\":\"2020 4th International Conference on Intelligent Computing and Control Systems (ICICCS)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1753569332\",\"name\":\"Yan Qu\"},{\"authorId\":\"1774956\",\"name\":\"W. Deng\"},{\"authorId\":\"23224233\",\"name\":\"Jiani Hu\"}],\"doi\":\"10.1007/978-3-030-60636-7_21\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"36b4dfe2a5ff0bf190c8e252111da8e5330685c2\",\"title\":\"H-AT: Hybrid Attention Transfer for Knowledge Distillation\",\"url\":\"https://www.semanticscholar.org/paper/36b4dfe2a5ff0bf190c8e252111da8e5330685c2\",\"venue\":\"PRCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47817913\",\"name\":\"L. Chen\"},{\"authorId\":\"1397287686\",\"name\":\"Yifan Zhuo\"},{\"authorId\":\"48607932\",\"name\":\"Yingjie Wu\"},{\"authorId\":null,\"name\":\"Yilei Wang\"},{\"authorId\":\"1678585\",\"name\":\"Xianghan Zheng\"}],\"doi\":\"10.1007/978-3-030-31723-2_56\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bae56e688485148c1519ff8458ea2ba6b7fab3f2\",\"title\":\"Multi-modal Feature Fusion Based on Variational Autoencoder for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/bae56e688485148c1519ff8458ea2ba6b7fab3f2\",\"venue\":\"PRCV\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2671023\",\"name\":\"Yusuf Osmanlioglu\"},{\"authorId\":\"1740078\",\"name\":\"A. Shokoufandeh\"}],\"doi\":\"10.1007/978-3-319-59259-6_7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ccb7aa994d949da40a6a6720f93079d57b22b8fd\",\"title\":\"On Automatic Question Answering Using Efficient Primal-Dual Models\",\"url\":\"https://www.semanticscholar.org/paper/ccb7aa994d949da40a6a6720f93079d57b22b8fd\",\"venue\":\"MPRSS\",\"year\":2016},{\"arxivId\":\"2004.03755\",\"authors\":[{\"authorId\":\"27549522\",\"name\":\"Goonmeet Bajaj\"},{\"authorId\":\"153100367\",\"name\":\"B. Bandyopadhyay\"},{\"authorId\":\"144545992\",\"name\":\"D. Schmidt\"},{\"authorId\":\"8394636\",\"name\":\"Pranav Maneriker\"},{\"authorId\":\"32264523\",\"name\":\"Christopher W. Myers\"},{\"authorId\":\"143724543\",\"name\":\"S. Parthasarathy\"}],\"doi\":\"10.1109/CVPRW50498.2020.00201\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e52a0d9b41a2c94eb4da9037b5ce530930e9914c\",\"title\":\"Understanding Knowledge Gaps in Visual Question Answering: Implications for Gap Identification and Testing\",\"url\":\"https://www.semanticscholar.org/paper/e52a0d9b41a2c94eb4da9037b5ce530930e9914c\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2625271\",\"name\":\"Mengfei Li\"},{\"authorId\":\"143628183\",\"name\":\"Li Gu\"},{\"authorId\":\"144602988\",\"name\":\"Yi Ji\"},{\"authorId\":\"6681872\",\"name\":\"Chunping Liu\"}],\"doi\":\"10.1007/978-3-030-00764-5_69\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"87f208c3716a80f5251d35196b8ac5c42fa791ea\",\"title\":\"Text-Guided Dual-Branch Attention Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/87f208c3716a80f5251d35196b8ac5c42fa791ea\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145422343\",\"name\":\"Dalu Guo\"},{\"authorId\":\"93374657\",\"name\":\"C. Xu\"},{\"authorId\":\"1490934465\",\"name\":\"Dacheng Tao\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"22fa5a7f3f00737c1912cbd6b2cac248a7e734a4\",\"title\":\"Bilinear Graph Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/22fa5a7f3f00737c1912cbd6b2cac248a7e734a4\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1912.05396\",\"authors\":[{\"authorId\":\"1454226662\",\"name\":\"Aiham Taleb\"},{\"authorId\":\"38206541\",\"name\":\"C. Lippert\"},{\"authorId\":\"35660331\",\"name\":\"T. Klein\"},{\"authorId\":\"1848946\",\"name\":\"Moin Nabi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b94a3bfe8ca48855e4b4c6bcab5b051197052d9e\",\"title\":\"Multimodal Self-Supervised Learning for Medical Image Analysis\",\"url\":\"https://www.semanticscholar.org/paper/b94a3bfe8ca48855e4b4c6bcab5b051197052d9e\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1830444313\",\"name\":\"Bozhi Wang\"},{\"authorId\":\"48537695\",\"name\":\"Teng Fei\"},{\"authorId\":\"50050246\",\"name\":\"Yuhao Kang\"},{\"authorId\":\"8392935\",\"name\":\"M. Li\"},{\"authorId\":\"31486023\",\"name\":\"Qingyun Du\"},{\"authorId\":\"145175025\",\"name\":\"M. Han\"},{\"authorId\":\"48101087\",\"name\":\"N. Dong\"}],\"doi\":\"10.1371/journal.pone.0236347\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8899616d7efa44ab6161efb0ccb6e30071e99b1e\",\"title\":\"Understanding the spatial dimension of natural language by measuring the spatial semantic similarity of words through a scalable geospatial context window\",\"url\":\"https://www.semanticscholar.org/paper/8899616d7efa44ab6161efb0ccb6e30071e99b1e\",\"venue\":\"PloS one\",\"year\":2020},{\"arxivId\":\"1904.04357\",\"authors\":[{\"authorId\":\"2047692\",\"name\":\"Chenyou Fan\"},{\"authorId\":\"49469577\",\"name\":\"X. Zhang\"},{\"authorId\":\"50202300\",\"name\":\"Shu Zhang\"},{\"authorId\":\"46314996\",\"name\":\"Wensheng Wang\"},{\"authorId\":null,\"name\":\"Chi Zhang\"},{\"authorId\":\"46675463\",\"name\":\"Heng Huang\"}],\"doi\":\"10.1109/CVPR.2019.00210\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5c5d99eff1377e141be293336a14ffddb323c364\",\"title\":\"Heterogeneous Memory Enhanced Multimodal Attention Model for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/5c5d99eff1377e141be293336a14ffddb323c364\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"1764508\",\"name\":\"Z. Zhang\"},{\"authorId\":\"2440041\",\"name\":\"X. Jiang\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"}],\"doi\":\"10.1109/TIP.2019.2902106\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"65bd828c05cac7eabe791e10d4d3c0f2da2b798c\",\"title\":\"Multi-Turn Video Question Answering via Hierarchical Attention Context Reinforced Networks\",\"url\":\"https://www.semanticscholar.org/paper/65bd828c05cac7eabe791e10d4d3c0f2da2b798c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"1711.09528\",\"authors\":[{\"authorId\":\"2238575\",\"name\":\"Daesik Kim\"},{\"authorId\":\"2347316\",\"name\":\"Young Joon Yoo\"},{\"authorId\":\"47965071\",\"name\":\"Jeesoo Kim\"},{\"authorId\":\"1949021\",\"name\":\"Sangkuk Lee\"},{\"authorId\":\"3160425\",\"name\":\"N. Kwak\"}],\"doi\":\"10.1109/CVPR.2018.00438\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b969ae8270f113477347de9778880ff91d75ed72\",\"title\":\"Dynamic Graph Generation Network: Generating Relational Knowledge from Diagrams\",\"url\":\"https://www.semanticscholar.org/paper/b969ae8270f113477347de9778880ff91d75ed72\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1606.01455\",\"authors\":[{\"authorId\":\"2684967\",\"name\":\"J. Kim\"},{\"authorId\":\"3226948\",\"name\":\"Sang-Woo Lee\"},{\"authorId\":\"3422869\",\"name\":\"Dong-Hyun Kwak\"},{\"authorId\":\"2939188\",\"name\":\"Min-Oh Heo\"},{\"authorId\":\"2947441\",\"name\":\"J. Kim\"},{\"authorId\":\"2577039\",\"name\":\"Jung-Woo Ha\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1afb710a5b35a2352a6495e4bf6eef66808daf1b\",\"title\":\"Multimodal Residual Learning for Visual QA\",\"url\":\"https://www.semanticscholar.org/paper/1afb710a5b35a2352a6495e4bf6eef66808daf1b\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"2009.13862\",\"authors\":[{\"authorId\":\"50232214\",\"name\":\"Wenjia Xu\"},{\"authorId\":\"51175635\",\"name\":\"Jiuniu Wang\"},{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"3287827\",\"name\":\"Guangluan Xu\"},{\"authorId\":\"7413451\",\"name\":\"Daoyu Lin\"},{\"authorId\":\"1379498558\",\"name\":\"Wei Dai\"},{\"authorId\":\"48607717\",\"name\":\"Y. Wu\"}],\"doi\":\"10.1109/JSTSP.2020.2987729\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7c056c388f4deb0ff87932eb6e7789b23eb22d22\",\"title\":\"Where is the Model Looking At? \\u2013 Concentrate and Explain the Network Attention\",\"url\":\"https://www.semanticscholar.org/paper/7c056c388f4deb0ff87932eb6e7789b23eb22d22\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152553572\",\"name\":\"Huan Shao\"},{\"authorId\":\"1965723\",\"name\":\"Y. Xu\"},{\"authorId\":\"144602988\",\"name\":\"Yi Ji\"},{\"authorId\":\"7788280\",\"name\":\"J. Yang\"},{\"authorId\":\"47535378\",\"name\":\"Chunping Liu\"}],\"doi\":\"10.1007/978-3-030-36802-9_24\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f21cba46085eba47b299fbff283515284bed7189\",\"title\":\"Intra-Modality Feature Interaction Using Self-attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f21cba46085eba47b299fbff283515284bed7189\",\"venue\":\"ICONIP\",\"year\":2019},{\"arxivId\":\"1704.08243\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a3d071d2a5c11329aa324b2cae6b7b6ca7800213\",\"title\":\"C-VQA: A Compositional Split of the Visual Question Answering (VQA) v1.0 Dataset\",\"url\":\"https://www.semanticscholar.org/paper/a3d071d2a5c11329aa324b2cae6b7b6ca7800213\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51151974\",\"name\":\"Prakruthi Prabhakar\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b56b001dff2e13f8b6488a9473163fff31f2953f\",\"title\":\"Question Relevance in VisualQuestion Answering\",\"url\":\"https://www.semanticscholar.org/paper/b56b001dff2e13f8b6488a9473163fff31f2953f\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"89093987\",\"name\":\"Shane Storks\"},{\"authorId\":\"3193409\",\"name\":\"Qiaozi Gao\"},{\"authorId\":\"1707259\",\"name\":\"J. Y. Chai\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e7c75b16563d07069505cd07dd6466d86f6958f9\",\"title\":\"Recent Advances in Natural Language Inference: A Survey of Benchmarks, Resources, and Approaches\",\"url\":\"https://www.semanticscholar.org/paper/e7c75b16563d07069505cd07dd6466d86f6958f9\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39630849\",\"name\":\"Kenki Nakamura\"},{\"authorId\":\"48939802\",\"name\":\"Q. Ma\"}],\"doi\":\"10.1007/978-3-030-27615-7_33\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"137dcdad7c5553e0c21e371d97e06338c5149aa0\",\"title\":\"Context-Aware GANs for Image Generation from Multimodal Queries\",\"url\":\"https://www.semanticscholar.org/paper/137dcdad7c5553e0c21e371d97e06338c5149aa0\",\"venue\":\"DEXA\",\"year\":2019},{\"arxivId\":\"1904.12584\",\"authors\":[{\"authorId\":\"13589371\",\"name\":\"Jiayuan Mao\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"143967473\",\"name\":\"P. Kohli\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ec9b27d019fefadb5e97c8174ac889e831f483d7\",\"title\":\"The Neuro-Symbolic Concept Learner: Interpreting Scenes Words and Sentences from Natural Supervision\",\"url\":\"https://www.semanticscholar.org/paper/ec9b27d019fefadb5e97c8174ac889e831f483d7\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738202556\",\"name\":\"Ting-Hao Kenneth Huang\"},{\"authorId\":\"2034063\",\"name\":\"F. Ferraro\"},{\"authorId\":\"2400138\",\"name\":\"N. Mostafazadeh\"},{\"authorId\":\"1806773\",\"name\":\"I. Misra\"},{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"39172707\",\"name\":\"J. Devlin\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"50045602\",\"name\":\"Xiaodong He\"},{\"authorId\":\"143967473\",\"name\":\"P. Kohli\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"1738701211\",\"name\":\"C. Lawrence Zitnick\"},{\"authorId\":\"144179578\",\"name\":\"D. Parikh\"},{\"authorId\":\"1909300\",\"name\":\"Lucy Vanderwende\"},{\"authorId\":\"1947267\",\"name\":\"Michel Galley\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"}],\"doi\":\"10.18653/v1/N16-1147\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ba7694798333d4670722bb703b7922a0df9a7e7b\",\"title\":\"Visual Storytelling\",\"url\":\"https://www.semanticscholar.org/paper/ba7694798333d4670722bb703b7922a0df9a7e7b\",\"venue\":\"NAACL 2016\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"20632291\",\"name\":\"Shiliang Sun\"},{\"authorId\":\"145307050\",\"name\":\"Liang Mao\"},{\"authorId\":\"66550933\",\"name\":\"Ziang Dong\"},{\"authorId\":\"4382815\",\"name\":\"Lidan Wu\"}],\"doi\":\"10.1007/978-981-13-3029-2_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"173a286cfb01a605641c8a7c1c110d648b404459\",\"title\":\"Multiview Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/173a286cfb01a605641c8a7c1c110d648b404459\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1805.05492\",\"authors\":[{\"authorId\":\"2235894\",\"name\":\"Pramod Kaushik Mudrakarta\"},{\"authorId\":\"40511120\",\"name\":\"Ankur Taly\"},{\"authorId\":\"30740726\",\"name\":\"M. Sundararajan\"},{\"authorId\":\"1696833\",\"name\":\"K. Dhamdhere\"}],\"doi\":\"10.18653/v1/P18-1176\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4a9831e5fec549edee454709048a51997ef60fb7\",\"title\":\"Did the Model Understand the Question?\",\"url\":\"https://www.semanticscholar.org/paper/4a9831e5fec549edee454709048a51997ef60fb7\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":\"1710.09867\",\"authors\":[{\"authorId\":\"145783676\",\"name\":\"Felix Hill\"},{\"authorId\":\"2910877\",\"name\":\"K. Hermann\"},{\"authorId\":\"1685771\",\"name\":\"P. Blunsom\"},{\"authorId\":\"144523372\",\"name\":\"Stephen Clark\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2cf481f3dcbcfca2e533c4334d31aa50f7ad3d39\",\"title\":\"Understanding Grounded Language Learning Agents\",\"url\":\"https://www.semanticscholar.org/paper/2cf481f3dcbcfca2e533c4334d31aa50f7ad3d39\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"89813962\",\"name\":\"Shivangi Modi\"},{\"authorId\":\"153279050\",\"name\":\"Dhatri Pandya\"}],\"doi\":\"10.1109/ICCMC.2019.8819803\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c99654c738cf9a426fac40251e277282a8ee86a7\",\"title\":\"VQAR: Review on Information Retrieval Techniques based on Computer Vision and Natural Language Processing\",\"url\":\"https://www.semanticscholar.org/paper/c99654c738cf9a426fac40251e277282a8ee86a7\",\"venue\":\"2019 3rd International Conference on Computing Methodologies and Communication (ICCMC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144608002\",\"name\":\"Gerard de Melo\"},{\"authorId\":\"1721168\",\"name\":\"Niket Tandon\"}],\"doi\":\"10.1145/2903513.2903517\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"968ab65077c4be1c1071120052b2e4b4f3d3c59a\",\"title\":\"\\\"Seeing is believing: the quest for multimodal knowledge\\\" by Gerard de Melo and Niket Tandon, with Martin Vesely as coordinator\",\"url\":\"https://www.semanticscholar.org/paper/968ab65077c4be1c1071120052b2e4b4f3d3c59a\",\"venue\":\"LINK\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1398777358\",\"name\":\"J. Hern\\u00e1ndez-Orallo\"}],\"doi\":\"10.1017/9781316594179\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c3c7dbf270efdab161a780d638be4631365e578\",\"title\":\"The Measure of All Minds: Evaluating Natural and Artificial Intelligence\",\"url\":\"https://www.semanticscholar.org/paper/1c3c7dbf270efdab161a780d638be4631365e578\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1812.03402\",\"authors\":[{\"authorId\":\"2434622\",\"name\":\"Z. Seymour\"},{\"authorId\":\"39707211\",\"name\":\"Karan Sikka\"},{\"authorId\":\"35260743\",\"name\":\"Han-Pang Chiu\"},{\"authorId\":\"1789477\",\"name\":\"S. Samarasekera\"},{\"authorId\":\"153411819\",\"name\":\"R. Kumar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"da5062a8b794445445058c00d6879d17c7510494\",\"title\":\"Semantically-Aware Attentive Neural Embeddings for Image-based Visual Localization\",\"url\":\"https://www.semanticscholar.org/paper/da5062a8b794445445058c00d6879d17c7510494\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1811.02307\",\"authors\":[{\"authorId\":\"2018561\",\"name\":\"Vasili Ramanishka\"},{\"authorId\":\"47559205\",\"name\":\"Y. Chen\"},{\"authorId\":\"32639375\",\"name\":\"Teruhisa Misu\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/CVPR.2018.00803\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7b5bd8535e49747b752c5eb8c0d80cd45a30078b\",\"title\":\"Toward Driving Scene Understanding: A Dataset for Learning Driver Behavior and Causal Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/7b5bd8535e49747b752c5eb8c0d80cd45a30078b\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1604.02125\",\"authors\":[{\"authorId\":\"50005563\",\"name\":\"G. Christie\"},{\"authorId\":\"48222562\",\"name\":\"A. Laddha\"},{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"98391857\",\"name\":\"K. Kochersberger\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.18653/v1/D16-1156\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"26eb2c900814707ae962184ad4173e754247a80a\",\"title\":\"Resolving Language and Vision Ambiguities Together: Joint Segmentation & Prepositional Attachment Resolution in Captioned Scenes\",\"url\":\"https://www.semanticscholar.org/paper/26eb2c900814707ae962184ad4173e754247a80a\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":\"1907.03609\",\"authors\":[{\"authorId\":\"2520427\",\"name\":\"Yulei Niu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1776220\",\"name\":\"Zhiwu Lu\"},{\"authorId\":\"70351911\",\"name\":\"Shih-Fu Chang\"}],\"doi\":\"10.1109/TPAMI.2019.2926266\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"df9c0a59bdbd54be299ca63b60773eed62e2c611\",\"title\":\"Variational Context: Exploiting Visual and Textual Context for Grounding Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/df9c0a59bdbd54be299ca63b60773eed62e2c611\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2021},{\"arxivId\":\"1802.05766\",\"authors\":[{\"authorId\":\"49889702\",\"name\":\"Y. Zhang\"},{\"authorId\":\"3724810\",\"name\":\"J. Hare\"},{\"authorId\":\"1398417301\",\"name\":\"A. Pr\\u00fcgel-Bennett\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"30a3eee5e9302108416f6234d739373dde68d373\",\"title\":\"Learning to Count Objects in Natural Images for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/30a3eee5e9302108416f6234d739373dde68d373\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3174935\",\"name\":\"Wenshan Wang\"},{\"authorId\":\"1470685911\",\"name\":\"Pengfei Liu\"},{\"authorId\":\"117785369\",\"name\":\"Su Yang\"},{\"authorId\":\"1954076\",\"name\":\"W. Zhang\"}],\"doi\":\"10.1016/j.neucom.2019.10.103\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ae1deb2efe99eea114fcde95ccd92a29af232c5a\",\"title\":\"Dynamic interaction networks for image-text multimodal learning\",\"url\":\"https://www.semanticscholar.org/paper/ae1deb2efe99eea114fcde95ccd92a29af232c5a\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46827428\",\"name\":\"Kaveh Hassani\"}],\"doi\":\"10.20381/RUOR-20445\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"67fcb23ea23eda15c540937ac9b02ba975e837c3\",\"title\":\"Commonsense Knowledge for 3D Modeling: A Machine Learning Approach\",\"url\":\"https://www.semanticscholar.org/paper/67fcb23ea23eda15c540937ac9b02ba975e837c3\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144582538\",\"name\":\"Vasu Sharma\"},{\"authorId\":\"49761595\",\"name\":\"A. Kalra\"},{\"authorId\":\"3374607\",\"name\":\"Vaibhav\"},{\"authorId\":\"1764061\",\"name\":\"Sumedha Chaudhary\"},{\"authorId\":\"22267101\",\"name\":\"L. Patel\"},{\"authorId\":\"69948163\",\"name\":\"Louis-Phillippe Morency\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e975bbb6cbd8216cfb920e0a1861079d0ac3535c\",\"title\":\"Attend and Attack : Attention Guided Adversarial Attacks on Visual Question Answering Models\",\"url\":\"https://www.semanticscholar.org/paper/e975bbb6cbd8216cfb920e0a1861079d0ac3535c\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51021338\",\"name\":\"Nelson Ruwa\"},{\"authorId\":\"151423308\",\"name\":\"Qirong Mao\"},{\"authorId\":\"3309006\",\"name\":\"Heping Song\"},{\"authorId\":\"153719921\",\"name\":\"H. Jia\"},{\"authorId\":\"1384379379\",\"name\":\"Ming Dong\"}],\"doi\":\"10.1016/j.cviu.2019.102829\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9572e232d33aba1b765ef90924d8662707cc2a01\",\"title\":\"Triple attention network for sentimental visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/9572e232d33aba1b765ef90924d8662707cc2a01\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2019},{\"arxivId\":\"1505.04870\",\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2133220\",\"name\":\"C. Cervantes\"},{\"authorId\":\"145507543\",\"name\":\"Juan C. Caicedo\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1007/s11263-016-0965-7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0612745dbd292fc0a548a16d39cd73e127faedde\",\"title\":\"Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models\",\"url\":\"https://www.semanticscholar.org/paper/0612745dbd292fc0a548a16d39cd73e127faedde\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1606.07356\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.18653/v1/D16-1203\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8e759195eb4b4f0f480a8a2cf1c629bfd881d4e5\",\"title\":\"Analyzing the Behavior of Visual Question Answering Models\",\"url\":\"https://www.semanticscholar.org/paper/8e759195eb4b4f0f480a8a2cf1c629bfd881d4e5\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1784897\",\"name\":\"Incheol Kim\"}],\"doi\":\"10.1155/2020/8567271\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a3900d795a4914f0e8c346397c3dff4038d41591\",\"title\":\"Visual Experience-Based Question Answering with Complex Multimodal Environments\",\"url\":\"https://www.semanticscholar.org/paper/a3900d795a4914f0e8c346397c3dff4038d41591\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1601.01705\",\"authors\":[{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"38666915\",\"name\":\"D. Klein\"}],\"doi\":\"10.18653/v1/N16-1181\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"75ddc7ee15be14013a3462c01b38b0548486fbcb\",\"title\":\"Learning to Compose Neural Networks for Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/75ddc7ee15be14013a3462c01b38b0548486fbcb\",\"venue\":\"HLT-NAACL\",\"year\":2016},{\"arxivId\":\"2007.15780\",\"authors\":[{\"authorId\":\"3360992\",\"name\":\"Cristina Garbacea\"},{\"authorId\":\"1743469\",\"name\":\"Q. Mei\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"64da659c0687762359226b4cf455520c78acd165\",\"title\":\"Neural Language Generation: Formulation, Methods, and Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/64da659c0687762359226b4cf455520c78acd165\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1706.06706\",\"authors\":[{\"authorId\":\"145659406\",\"name\":\"Yang Shi\"},{\"authorId\":\"2426872\",\"name\":\"Tommaso Furlanello\"},{\"authorId\":\"2047844\",\"name\":\"Anima Anandkumar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2953fa360c79f2c77bbc53c8154f49136333bfa6\",\"title\":\"Compact Tensor Pooling for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2953fa360c79f2c77bbc53c8154f49136333bfa6\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1906.03561\",\"authors\":[{\"authorId\":\"48929163\",\"name\":\"Daqing Liu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"152808542\",\"name\":\"Meng Wang\"},{\"authorId\":\"32222907\",\"name\":\"Qianru Sun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d84db9d0d21b0eae8cad741d16a74e7880c711c\",\"title\":\"Joint Visual Grounding with Language Scene Graphs\",\"url\":\"https://www.semanticscholar.org/paper/3d84db9d0d21b0eae8cad741d16a74e7880c711c\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1803.02324\",\"authors\":[{\"authorId\":\"40895369\",\"name\":\"Suchin Gururangan\"},{\"authorId\":\"2705113\",\"name\":\"Swabha Swayamdipta\"},{\"authorId\":\"39455775\",\"name\":\"Omer Levy\"},{\"authorId\":\"4671928\",\"name\":\"Roy Schwartz\"},{\"authorId\":\"3644767\",\"name\":\"Samuel R. Bowman\"},{\"authorId\":\"144365875\",\"name\":\"Noah A. Smith\"}],\"doi\":\"10.18653/v1/N18-2017\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2997b26ffb8c291ce478bd8a6e47979d5a55c466\",\"title\":\"Annotation Artifacts in Natural Language Inference Data\",\"url\":\"https://www.semanticscholar.org/paper/2997b26ffb8c291ce478bd8a6e47979d5a55c466\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40538912\",\"name\":\"Wei Zhang\"},{\"authorId\":\"46314731\",\"name\":\"W. Wang\"},{\"authorId\":null,\"name\":\"Jun Wang\"},{\"authorId\":\"145203884\",\"name\":\"H. Zha\"}],\"doi\":\"10.1145/3178876.3186026\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"43bb4b073f7b2b9b626c7f3263cc61932271ab74\",\"title\":\"User-guided Hierarchical Attention Network for Multi-modal Social Image Popularity Prediction\",\"url\":\"https://www.semanticscholar.org/paper/43bb4b073f7b2b9b626c7f3263cc61932271ab74\",\"venue\":\"WWW\",\"year\":2018},{\"arxivId\":\"2007.12146\",\"authors\":[{\"authorId\":\"66536530\",\"name\":\"Yash Kant\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"1606382599\",\"name\":\"Peter Anderson\"},{\"authorId\":\"5153264\",\"name\":\"A. Schwing\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"37825612\",\"name\":\"Harsh Agrawal\"}],\"doi\":\"10.1007/978-3-030-58545-7_41\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f92dc7d9a61f7b8b5b7cb58f3895541e266ce057\",\"title\":\"Spatially Aware Multimodal Transformers for TextVQA\",\"url\":\"https://www.semanticscholar.org/paper/f92dc7d9a61f7b8b5b7cb58f3895541e266ce057\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2008.01766\",\"authors\":[{\"authorId\":\"2373318\",\"name\":\"B. Lake\"},{\"authorId\":\"33696979\",\"name\":\"G. Murphy\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"19f4404f640f850521cc97bc75ddbe8f482fc85e\",\"title\":\"Word meaning in minds and machines\",\"url\":\"https://www.semanticscholar.org/paper/19f4404f640f850521cc97bc75ddbe8f482fc85e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2692127\",\"name\":\"Mourad Sarrouti\"},{\"authorId\":\"2205800\",\"name\":\"Asma Ben Abacha\"},{\"authorId\":\"1398175407\",\"name\":\"Dina Demner-Fushman\"}],\"doi\":\"10.18653/v1/2020.alvr-1.3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d77a71c94e688d92a3fa10fb7f7feda2c306b9dc\",\"title\":\"Visual Question Generation from Radiology Images\",\"url\":\"https://www.semanticscholar.org/paper/d77a71c94e688d92a3fa10fb7f7feda2c306b9dc\",\"venue\":\"ALVR\",\"year\":2020},{\"arxivId\":\"2002.04672\",\"authors\":[{\"authorId\":\"40857101\",\"name\":\"Yuewei Yang\"},{\"authorId\":\"144130492\",\"name\":\"Kevin J Liang\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3a8acb61589352819b96e0642d5dcb2c78bac03b\",\"title\":\"Object Detection as a Positive-Unlabeled Problem\",\"url\":\"https://www.semanticscholar.org/paper/3a8acb61589352819b96e0642d5dcb2c78bac03b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1907.00661\",\"authors\":[{\"authorId\":\"32185652\",\"name\":\"Yusuke Yamaura\"},{\"authorId\":\"150246288\",\"name\":\"Nobuya Kanemaki\"},{\"authorId\":\"3184895\",\"name\":\"Yukihiro Tsuboshita\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"75952cb7d5945d001d0758a994eb8017ddca3733\",\"title\":\"The Resale Price Prediction of Secondhand Jewelry Items Using a Multi-modal Deep Model with Iterative Co-Attention\",\"url\":\"https://www.semanticscholar.org/paper/75952cb7d5945d001d0758a994eb8017ddca3733\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2673176\",\"name\":\"M. Alizadeh\"},{\"authorId\":\"66658845\",\"name\":\"B. D. Eugenio\"}],\"doi\":\"10.1142/S1793351X20400085\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eca1e3a8ecfd39026d3f7de4717ad0429d406602\",\"title\":\"Incorporating Verb Semantic Information in Visual Question Answering Through Multitask Learning Paradigm\",\"url\":\"https://www.semanticscholar.org/paper/eca1e3a8ecfd39026d3f7de4717ad0429d406602\",\"venue\":\"Int. J. Semantic Comput.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9139235\",\"name\":\"S. Singh\"}],\"doi\":\"10.18653/v1/P18-3005\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8fdfd4c5039cf7d70470a2a3ac52bfd229bcd4e2\",\"title\":\"Pushing the Limits of Radiology with Joint Modeling of Visual and Textual Information\",\"url\":\"https://www.semanticscholar.org/paper/8fdfd4c5039cf7d70470a2a3ac52bfd229bcd4e2\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49597404\",\"name\":\"Z. Fang\"},{\"authorId\":\"7187373\",\"name\":\"J. Liu\"},{\"authorId\":null,\"name\":\"Qu Tang\"},{\"authorId\":\"49112842\",\"name\":\"Y. Li\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1007/978-3-030-20887-5_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8463ff93a6725017bd1875eeb7ae4d0f0e7df568\",\"title\":\"Answer Distillation for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8463ff93a6725017bd1875eeb7ae4d0f0e7df568\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"1910.03230\",\"authors\":[{\"authorId\":\"2928777\",\"name\":\"Wenhu Chen\"},{\"authorId\":\"153731335\",\"name\":\"Zhe Gan\"},{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"153655416\",\"name\":\"Yu Cheng\"},{\"authorId\":\"152876475\",\"name\":\"William W. J. Wang\"},{\"authorId\":\"32556571\",\"name\":\"J. Liu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d0bbae624efbfeee01bd38185c6d754c08417de7\",\"title\":\"Meta Module Network for Compositional Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/d0bbae624efbfeee01bd38185c6d754c08417de7\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1807.03950\",\"authors\":[{\"authorId\":\"51135358\",\"name\":\"Deepthi Karkada\"},{\"authorId\":\"2175808\",\"name\":\"Ramesh R. Manuvinakurike\"},{\"authorId\":\"3194430\",\"name\":\"Kallirroi Georgila\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"947f4e616862d1f8d6c49a980417de7bc03e08ed\",\"title\":\"Towards Understanding End-of-trip Instructions in a Taxi Ride Scenario\",\"url\":\"https://www.semanticscholar.org/paper/947f4e616862d1f8d6c49a980417de7bc03e08ed\",\"venue\":\"ACL 2018\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3199565\",\"name\":\"A. Zador\"}],\"doi\":\"10.1038/s41467-019-11786-6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"32abbcb3aa75ac34a92624dc779a9f7a82ee981c\",\"title\":\"A critique of pure learning and what artificial neural networks can learn from animal brains\",\"url\":\"https://www.semanticscholar.org/paper/32abbcb3aa75ac34a92624dc779a9f7a82ee981c\",\"venue\":\"Nature Communications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9610143\",\"name\":\"Zhihao Fan\"},{\"authorId\":\"2712533\",\"name\":\"Zhongyu Wei\"},{\"authorId\":\"50695111\",\"name\":\"Siyuan Wang\"},{\"authorId\":\"1790227\",\"name\":\"X. Huang\"}],\"doi\":\"10.18653/v1/P19-1652\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aaf5e3afd61d0df6c483ca32faf8e7a9198b1557\",\"title\":\"Bridging by Word: Image Grounded Vocabulary Construction for Visual Captioning\",\"url\":\"https://www.semanticscholar.org/paper/aaf5e3afd61d0df6c483ca32faf8e7a9198b1557\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1398421283\",\"name\":\"U. Markowska-Kaczmar\"},{\"authorId\":\"153318273\",\"name\":\"H. Kwasnicka\"}],\"doi\":\"10.1007/978-3-319-73891-8_7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0302fed107f5bee6cc4ea4a48eb1dfb26554ef83\",\"title\":\"Deep Learning\\u2014A New Era in Bridging the Semantic Gap\",\"url\":\"https://www.semanticscholar.org/paper/0302fed107f5bee6cc4ea4a48eb1dfb26554ef83\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1908.04011\",\"authors\":[{\"authorId\":\"134814700\",\"name\":\"T. Wang\"},{\"authorId\":\"1390532590\",\"name\":\"Xing Xu\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":\"1718099\",\"name\":\"A. Hanjalic\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"}],\"doi\":\"10.1145/3343031.3350875\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b4e1be8dd4d303e8e8ffe4343b2200d7952d16c4\",\"title\":\"Matching Images and Text with Multi-modal Tensor Fusion and Re-ranking\",\"url\":\"https://www.semanticscholar.org/paper/b4e1be8dd4d303e8e8ffe4343b2200d7952d16c4\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2635321\",\"name\":\"Josiah Wang\"},{\"authorId\":\"1954884\",\"name\":\"A. Gilbert\"},{\"authorId\":\"2463875\",\"name\":\"B. Thomee\"},{\"authorId\":\"41206897\",\"name\":\"M. Villegas\"}],\"doi\":\"10.1007/978-3-030-22948-1_11\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f475b7e0df4b64b5438f8527a736d2967e87eb36\",\"title\":\"Automatic Image Annotation at ImageCLEF\",\"url\":\"https://www.semanticscholar.org/paper/f475b7e0df4b64b5438f8527a736d2967e87eb36\",\"venue\":\"Information Retrieval Evaluation in a Changing World\",\"year\":2019},{\"arxivId\":\"1511.02251\",\"authors\":[{\"authorId\":\"2319608\",\"name\":\"Armand Joulin\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"},{\"authorId\":\"14258597\",\"name\":\"A. Jabri\"},{\"authorId\":\"1800919\",\"name\":\"Nicolas Vasilache\"}],\"doi\":\"10.1007/978-3-319-46478-7_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8c30968d96e0c601adaa74db8907fa6ad73bae31\",\"title\":\"Learning Visual Features from Large Weakly Supervised Data\",\"url\":\"https://www.semanticscholar.org/paper/8c30968d96e0c601adaa74db8907fa6ad73bae31\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1806.06765\",\"authors\":[{\"authorId\":\"35005710\",\"name\":\"Jason Jo\"},{\"authorId\":\"47324418\",\"name\":\"V. Verma\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"cb475fe9ad25e78414ffbf2c7598b5f1f8979c6e\",\"title\":\"Modularity Matters: Learning Invariant Relational Reasoning Tasks\",\"url\":\"https://www.semanticscholar.org/paper/cb475fe9ad25e78414ffbf2c7598b5f1f8979c6e\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2006.12442\",\"authors\":[{\"authorId\":\"144745718\",\"name\":\"Stephen Roller\"},{\"authorId\":\"2656573\",\"name\":\"Y.-Lan Boureau\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"},{\"authorId\":\"1713934\",\"name\":\"Antoine Bordes\"},{\"authorId\":\"31461304\",\"name\":\"Emily Dinan\"},{\"authorId\":\"4861083\",\"name\":\"A. Fan\"},{\"authorId\":\"2121780\",\"name\":\"D. Gunning\"},{\"authorId\":\"3092435\",\"name\":\"Da Ju\"},{\"authorId\":\"6649233\",\"name\":\"Margaret Li\"},{\"authorId\":\"1753626755\",\"name\":\"Spencer Poff\"},{\"authorId\":\"1422035486\",\"name\":\"Pratik Ringshia\"},{\"authorId\":\"35752280\",\"name\":\"Kurt Shuster\"},{\"authorId\":\"51324296\",\"name\":\"Eric Michael Smith\"},{\"authorId\":\"3149531\",\"name\":\"Arthur Szlam\"},{\"authorId\":\"39219656\",\"name\":\"Jack Urbanek\"},{\"authorId\":\"49160304\",\"name\":\"M. Williamson\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ebf79630966e36761f2275990075384fdcb8d3a7\",\"title\":\"Open-Domain Conversational Agents: Current Progress, Open Problems, and Future Directions\",\"url\":\"https://www.semanticscholar.org/paper/ebf79630966e36761f2275990075384fdcb8d3a7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144468064\",\"name\":\"A. Vieira\"},{\"authorId\":\"144719255\",\"name\":\"B. Ribeiro\"}],\"doi\":\"10.1007/978-1-4842-3453-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4e880a6f35844ffb16bbb1baedcc75ffac8dafaa\",\"title\":\"Introduction to Deep Learning Business Applications for Developers\",\"url\":\"https://www.semanticscholar.org/paper/4e880a6f35844ffb16bbb1baedcc75ffac8dafaa\",\"venue\":\"Apress\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46958543\",\"name\":\"T. Wang\"},{\"authorId\":\"49298611\",\"name\":\"J. Li\"},{\"authorId\":\"153501119\",\"name\":\"Zhaoning Kong\"},{\"authorId\":\"46333170\",\"name\":\"Liu Xin\"},{\"authorId\":\"2103629\",\"name\":\"H. Snoussi\"},{\"authorId\":\"2199558\",\"name\":\"H. Lv\"}],\"doi\":\"10.1016/j.jmsy.2020.07.011\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"13ce2e837c067f759d0596037e7bdeec80397553\",\"title\":\"Digital twin improved via visual question answering for vision-language interactive mode in human\\u2013machine collaboration\",\"url\":\"https://www.semanticscholar.org/paper/13ce2e837c067f759d0596037e7bdeec80397553\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1907.02985\",\"authors\":[{\"authorId\":\"67344892\",\"name\":\"Federico Landi\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"40186452\",\"name\":\"M. Corsini\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"64d1b545f586d930cbe67402e853ab26a8f6e18d\",\"title\":\"Embodied Vision-and-Language Navigation with Dynamic Convolutional Filters\",\"url\":\"https://www.semanticscholar.org/paper/64d1b545f586d930cbe67402e853ab26a8f6e18d\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2378902\",\"name\":\"Yen-Chun Chen\"},{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1877430\",\"name\":\"A. E. Kholy\"},{\"authorId\":\"83147159\",\"name\":\"Faisal Ahmed\"},{\"authorId\":\"153731335\",\"name\":\"Zhe Gan\"},{\"authorId\":\"153655416\",\"name\":\"Yu Cheng\"},{\"authorId\":\"32556571\",\"name\":\"J. Liu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"33c10383189c118465f8b40e8dba9213f57fa570\",\"title\":\"UNITER: Learning UNiversal Image-TExt Representations\",\"url\":\"https://www.semanticscholar.org/paper/33c10383189c118465f8b40e8dba9213f57fa570\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30888760\",\"name\":\"Jason L. Granstedt\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fc43f7dec09482552987d75c9964d758ad5e5158\",\"title\":\"Data Augmentation with Seq2Seq Models\",\"url\":\"https://www.semanticscholar.org/paper/fc43f7dec09482552987d75c9964d758ad5e5158\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1505.01121\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":\"10.1109/ICCV.2015.9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bd7bd1d2945a58cdcc1797ba9698b8810fe68f60\",\"title\":\"Ask Your Neurons: A Neural-Based Approach to Answering Questions about Images\",\"url\":\"https://www.semanticscholar.org/paper/bd7bd1d2945a58cdcc1797ba9698b8810fe68f60\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4300473\",\"name\":\"M. Yokota\"},{\"authorId\":\"48731103\",\"name\":\"Hideki Nakayama\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f88a0f44ff7ec5fe0facf0facac0a094c7bd6cb8\",\"title\":\"Augmenting Image Question Answering Dataset by Exploiting Image Captions\",\"url\":\"https://www.semanticscholar.org/paper/f88a0f44ff7ec5fe0facf0facac0a094c7bd6cb8\",\"venue\":\"LREC\",\"year\":2018},{\"arxivId\":\"1809.06213\",\"authors\":[{\"authorId\":\"144801562\",\"name\":\"Zhen Cui\"},{\"authorId\":\"48258938\",\"name\":\"Chunyan Xu\"},{\"authorId\":\"40608983\",\"name\":\"W. Zheng\"},{\"authorId\":null,\"name\":\"Jian Yang\"}],\"doi\":\"10.1145/3240508.3240668\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4edeaa65210966cc89890ac4c19ec447f000dba2\",\"title\":\"Context-Dependent Diffusion Network for Visual Relationship Detection\",\"url\":\"https://www.semanticscholar.org/paper/4edeaa65210966cc89890ac4c19ec447f000dba2\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2973718\",\"name\":\"L. Kodra\"},{\"authorId\":\"50879442\",\"name\":\"E. Me\\u00e7e\"}],\"doi\":\"10.1007/978-3-030-01174-1_60\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c2777a8ca7447764e51a4b2498a7a6157f76da37\",\"title\":\"Multimodal Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/c2777a8ca7447764e51a4b2498a7a6157f76da37\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50629736\",\"name\":\"H. Braun\"},{\"authorId\":\"143655174\",\"name\":\"P. Turaga\"},{\"authorId\":\"144924839\",\"name\":\"Andreas Spanias\"},{\"authorId\":\"32777195\",\"name\":\"Sameeksha Katoch\"},{\"authorId\":\"152843624\",\"name\":\"Suren Jayasuriya\"},{\"authorId\":\"1755611\",\"name\":\"C. Tepedelenlio\\u011flu\"}],\"doi\":\"10.2200/S00914ED2V01Y201904SPR017\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"083d175b33fee8e159a1bd4a3f2ea32259a424df\",\"title\":\"Reconstruction-Free Compressive Vision for Surveillance Applications\",\"url\":\"https://www.semanticscholar.org/paper/083d175b33fee8e159a1bd4a3f2ea32259a424df\",\"venue\":\"Reconstruction-Free Compressive Vision for Surveillance Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3074923\",\"name\":\"Alexandros Iosifidis\"},{\"authorId\":\"1737071\",\"name\":\"A. Tefas\"},{\"authorId\":\"144064571\",\"name\":\"I. Pitas\"},{\"authorId\":\"9219875\",\"name\":\"M. Gabbouj\"}],\"doi\":\"10.1016/j.image.2017.10.004\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e828a00f51116e0ffcb118db0a29122758f1a2ef\",\"title\":\"Big Media Data Analysis\",\"url\":\"https://www.semanticscholar.org/paper/e828a00f51116e0ffcb118db0a29122758f1a2ef\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2017},{\"arxivId\":\"1905.04877\",\"authors\":[{\"authorId\":\"30921555\",\"name\":\"Yangyang Guo\"},{\"authorId\":\"13167100\",\"name\":\"Zhiyong Cheng\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":\"35435925\",\"name\":\"Y. Liu\"},{\"authorId\":\"49417788\",\"name\":\"Yinglong Wang\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":\"10.1145/3331184.3331186\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d00fe8d117a3849d3085d4301d91c56b775ee8b1\",\"title\":\"Quantifying and Alleviating the Language Prior Problem in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d00fe8d117a3849d3085d4301d91c56b775ee8b1\",\"venue\":\"SIGIR\",\"year\":2019},{\"arxivId\":\"2002.06800\",\"authors\":[{\"authorId\":\"9208016\",\"name\":\"Aakansha Mishra\"},{\"authorId\":\"47583423\",\"name\":\"A. Anand\"},{\"authorId\":\"46401518\",\"name\":\"Prithwijit Guha\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206913\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"212c2d71f9f404bcbb3cfe8bc35e5e1ea25076c5\",\"title\":\"CQ-VQA: Visual Question Answering on Categorized Questions\",\"url\":\"https://www.semanticscholar.org/paper/212c2d71f9f404bcbb3cfe8bc35e5e1ea25076c5\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":\"1908.01224\",\"authors\":[{\"authorId\":\"51880324\",\"name\":\"Daniel Omeiza\"},{\"authorId\":\"40205485\",\"name\":\"S. Speakman\"},{\"authorId\":\"3674007\",\"name\":\"C. Cintas\"},{\"authorId\":\"3217172\",\"name\":\"K. Weldemariam\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d7cb9361d671ac6edaadaef4273c190e8913d86a\",\"title\":\"Smooth Grad-CAM++: An Enhanced Inference Level Visualization Technique for Deep Convolutional Neural Network Models\",\"url\":\"https://www.semanticscholar.org/paper/d7cb9361d671ac6edaadaef4273c190e8913d86a\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1902.03570\",\"authors\":[{\"authorId\":\"24508084\",\"name\":\"Deshraj Yadav\"},{\"authorId\":\"145461380\",\"name\":\"Rishabh Jain\"},{\"authorId\":\"37825612\",\"name\":\"Harsh Agrawal\"},{\"authorId\":\"40424000\",\"name\":\"Prithvijit Chattopadhyay\"},{\"authorId\":\"2781522\",\"name\":\"T. Singh\"},{\"authorId\":\"49148034\",\"name\":\"Akash Jain\"},{\"authorId\":\"8518719\",\"name\":\"S. Singh\"},{\"authorId\":\"121944615\",\"name\":\"Stefan Lee\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0d96ac48e92b6b42737276a319f48d9d27080fce\",\"title\":\"EvalAI: Towards Better Evaluation Systems for AI Agents\",\"url\":\"https://www.semanticscholar.org/paper/0d96ac48e92b6b42737276a319f48d9d27080fce\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10405058\",\"name\":\"Chenfei Wu\"},{\"authorId\":\"46700331\",\"name\":\"J. Liu\"},{\"authorId\":\"38542466\",\"name\":\"X. Wang\"},{\"authorId\":\"143672034\",\"name\":\"X. Dong\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"184002001b3b514f432e538f872aebce3c7db060\",\"title\":\"Chain of Reasoning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/184002001b3b514f432e538f872aebce3c7db060\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39105519\",\"name\":\"Matthew Ricci\"},{\"authorId\":\"7535126\",\"name\":\"R\\u00e9mi Cad\\u00e8ne\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"}],\"doi\":\"10.1016/j.cobeha.2020.08.008\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"519af509d69d15fede74f64bef8a7833d47fdd28\",\"title\":\"Same-different conceptualization: a machine vision perspective\",\"url\":\"https://www.semanticscholar.org/paper/519af509d69d15fede74f64bef8a7833d47fdd28\",\"venue\":\"Current Opinion in Behavioral Sciences\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41020222\",\"name\":\"Tsu-Jui Fu\"},{\"authorId\":\"35392319\",\"name\":\"Shao-Heng Tai\"},{\"authorId\":\"1803730\",\"name\":\"Hwann-Tzong Chen\"}],\"doi\":\"10.1109/WACV.2019.00173\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b0e6921c84263c5c961cd286e3145ca5eda352e0\",\"title\":\"Attentive and Adversarial Learning for Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/b0e6921c84263c5c961cd286e3145ca5eda352e0\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":\"1501.02741\",\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"49712326\",\"name\":\"M. Cheng\"},{\"authorId\":\"40175280\",\"name\":\"Huaizu Jiang\"},{\"authorId\":\"97483166\",\"name\":\"J. Li\"}],\"doi\":\"10.1109/TIP.2015.2487833\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a1260c42b86dcbe123ccc038857cd3b14e146032\",\"title\":\"Salient Object Detection: A Benchmark\",\"url\":\"https://www.semanticscholar.org/paper/a1260c42b86dcbe123ccc038857cd3b14e146032\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1620218253\",\"name\":\"Sruthy Manmadhan\"},{\"authorId\":\"30588803\",\"name\":\"Binsu C. Kovoor\"}],\"doi\":\"10.1007/s10462-020-09832-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"667b88984df0c5c11ac07899ffb5509185abdf57\",\"title\":\"Visual question answering: a state-of-the-art review\",\"url\":\"https://www.semanticscholar.org/paper/667b88984df0c5c11ac07899ffb5509185abdf57\",\"venue\":\"Artificial Intelligence Review\",\"year\":2020},{\"arxivId\":\"2004.04312\",\"authors\":[{\"authorId\":\"38727845\",\"name\":\"A. Burns\"},{\"authorId\":\"31494849\",\"name\":\"D. Kim\"},{\"authorId\":\"2129412\",\"name\":\"D. Wijaya\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"}],\"doi\":\"10.1007/978-3-030-58548-8_12\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b8e9b6ecb592269836bcdc46d0d0d001e883c9ee\",\"title\":\"Learning to Scale Multilingual Representations for Vision-Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/b8e9b6ecb592269836bcdc46d0d0d001e883c9ee\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2005.00619\",\"authors\":[{\"authorId\":\"1387994137\",\"name\":\"Gabriel Ilharco\"},{\"authorId\":\"2545335\",\"name\":\"Rowan Zellers\"},{\"authorId\":\"47465174\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"2548384\",\"name\":\"Hannaneh Hajishirzi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf45a40d129e02079ba482d3b1bc742a1f6ef36b\",\"title\":\"Probing Contextual Language Models for Common Ground with Visual Representations\",\"url\":\"https://www.semanticscholar.org/paper/cf45a40d129e02079ba482d3b1bc742a1f6ef36b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21267284\",\"name\":\"Sabin Kafle\"},{\"authorId\":\"40273954\",\"name\":\"Nisansa de Silva\"},{\"authorId\":\"1721158\",\"name\":\"D. Dou\"}],\"doi\":\"10.1007/s10796-020-10035-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0bd275907158a21c58d1a54b4f94c0e6b0307113\",\"title\":\"An Overview of Utilizing Knowledge Bases in Neural Networks for Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0bd275907158a21c58d1a54b4f94c0e6b0307113\",\"venue\":\"Inf. Syst. Frontiers\",\"year\":2020}],\"corpusId\":58727669,\"doi\":\"10.1109/ICCV.2015.279\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":21,\"is_open_access\":true,\"is_publisher_licensed\":false,\"paperId\":\"784da2a7b53a16d2243f747e14946cc5e3476af0\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"144332826\",\"name\":\"Chen Kong\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":\"10.1109/CVPR.2014.455\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"13549b4e6fffbb7932b7a83a8eb6be27e6a60eca\",\"title\":\"What Are You Talking About? Text-to-Image Coreference\",\"url\":\"https://www.semanticscholar.org/paper/13549b4e6fffbb7932b7a83a8eb6be27e6a60eca\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38087946\",\"name\":\"Anthony Fader\"},{\"authorId\":\"1982950\",\"name\":\"Luke Zettlemoyer\"},{\"authorId\":\"1741101\",\"name\":\"Oren Etzioni\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c0be2ac2f45681f1852fc1d298af5dceb85834f4\",\"title\":\"Paraphrase-Driven Learning for Open Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/c0be2ac2f45681f1852fc1d298af5dceb85834f4\",\"venue\":\"ACL\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"69576034\",\"name\":\"\\u6589\\u85e4 \\u5eb7\\u5df1\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"130abd596735a6adffb55a0a6a47bc285ddb365e\",\"title\":\"Douglas B. Lenat and R. V. Guha : Building Large Knowledge-Based Systems, Representation and Inference in the Cyc Project, Addison-Wesley (1990).\",\"url\":\"https://www.semanticscholar.org/paper/130abd596735a6adffb55a0a6a47bc285ddb365e\",\"venue\":\"\",\"year\":1990},{\"arxivId\":\"1410.1090\",\"authors\":[{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"40579682\",\"name\":\"J. Wang\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"82fdca623c65b6acf6b06bdeed48b2a9ebdb80a9\",\"title\":\"Explain Images with Multimodal Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/82fdca623c65b6acf6b06bdeed48b2a9ebdb80a9\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3198867\",\"name\":\"H. Liu\"},{\"authorId\":\"40139814\",\"name\":\"Push Singh\"}],\"doi\":\"10.1023/B:BTTJ.0000047600.45421.6D\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b3fea597033a46d5ae282464a8f16d6715187e70\",\"title\":\"ConceptNet \\u2014 A Practical Commonsense Reasoning Tool-Kit\",\"url\":\"https://www.semanticscholar.org/paper/b3fea597033a46d5ae282464a8f16d6715187e70\",\"venue\":\"\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4366352\",\"name\":\"Glen Coppersmith\"},{\"authorId\":\"48354136\",\"name\":\"E. Kelly\"}],\"doi\":\"10.3115/v1/W14-3103\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d8e8f7311d52871d86baf7571b87107e23ac99f3\",\"title\":\"Dynamic Wordclouds and Vennclouds for Exploratory Data Analysis\",\"url\":\"https://www.semanticscholar.org/paper/d8e8f7311d52871d86baf7571b87107e23ac99f3\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"144369161\",\"name\":\"Wei Qiu\"},{\"authorId\":\"144889265\",\"name\":\"Ivan Titov\"},{\"authorId\":\"1727272\",\"name\":\"Stefan Thater\"},{\"authorId\":\"1717560\",\"name\":\"Manfred Pinkal\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1109/ICCV.2013.61\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e8cd37fbd8bd5e690eef5861cf92af8e002d4533\",\"title\":\"Translating Video Content to Natural Language Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/e8cd37fbd8bd5e690eef5861cf92af8e002d4533\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3259253\",\"name\":\"Kristina Toutanova\"},{\"authorId\":\"38666915\",\"name\":\"D. Klein\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"},{\"authorId\":\"1740765\",\"name\":\"Y. Singer\"}],\"doi\":\"10.3115/1073445.1073478\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb42a490cf4f186d3383c92963817d100afd81e2\",\"title\":\"Feature-Rich Part-of-Speech Tagging with a Cyclic Dependency Network\",\"url\":\"https://www.semanticscholar.org/paper/eb42a490cf4f186d3383c92963817d100afd81e2\",\"venue\":\"HLT-NAACL\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143818235\",\"name\":\"A. Carlson\"},{\"authorId\":\"31779043\",\"name\":\"J. Betteridge\"},{\"authorId\":\"16411658\",\"name\":\"Bryan Kisiel\"},{\"authorId\":\"1717452\",\"name\":\"B. Settles\"},{\"authorId\":\"1842532\",\"name\":\"Estevam R. Hruschka\"},{\"authorId\":\"40975594\",\"name\":\"Tom Michael Mitchell\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f7312b8568d63bbbb239583ed282f46cdc40978d\",\"title\":\"Toward an Architecture for Never-Ending Language Learning\",\"url\":\"https://www.semanticscholar.org/paper/f7312b8568d63bbbb239583ed282f46cdc40978d\",\"venue\":\"AAAI\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1007/978-3-319-10593-2_27\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d3ab56d83a616dba391a3373037aceb662bcda9d\",\"title\":\"Zero-Shot Learning via Visual Abstraction\",\"url\":\"https://www.semanticscholar.org/paper/d3ab56d83a616dba391a3373037aceb662bcda9d\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"97711484\",\"name\":\"Xiao Lin\"},{\"authorId\":\"32519394\",\"name\":\"Tanmay Batra\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/ICCV.2015.292\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0b888196dda951287dddb60bd44798aab16d6fca\",\"title\":\"Learning Common Sense through Visual Abstraction\",\"url\":\"https://www.semanticscholar.org/paper/0b888196dda951287dddb60bd44798aab16d6fca\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1505.01121\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":\"10.1109/ICCV.2015.9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bd7bd1d2945a58cdcc1797ba9698b8810fe68f60\",\"title\":\"Ask Your Neurons: A Neural-Based Approach to Answering Questions about Images\",\"url\":\"https://www.semanticscholar.org/paper/bd7bd1d2945a58cdcc1797ba9698b8810fe68f60\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1310.4546\",\"authors\":[{\"authorId\":null,\"name\":\"Tomas Mikolov\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"38644044\",\"name\":\"Kai Chen\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"87f40e6f3022adbc1f1905e3e506abad05a9964f\",\"title\":\"Distributed Representations of Words and Phrases and their Compositionality\",\"url\":\"https://www.semanticscholar.org/paper/87f40e6f3022adbc1f1905e3e506abad05a9964f\",\"venue\":\"NIPS\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"143694777\",\"name\":\"Frank Keller\"}],\"doi\":\"10.3115/v1/P14-2074\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"52f86811b57034ba5c0478b37cab101d9a84024a\",\"title\":\"Comparing Automatic Evaluation Measures for Image Description\",\"url\":\"https://www.semanticscholar.org/paper/52f86811b57034ba5c0478b37cab101d9a84024a\",\"venue\":\"ACL\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"1781242\",\"name\":\"Abhinav Shrivastava\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1109/ICCV.2013.178\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"53e4ab9730e983242a3409c7bf1af945041a6563\",\"title\":\"NEIL: Extracting Visual Knowledge from Web Data\",\"url\":\"https://www.semanticscholar.org/paper/53e4ab9730e983242a3409c7bf1af945041a6563\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":\"1504.00325\",\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"title\":\"Microsoft COCO Captions: Data Collection and Evaluation Server\",\"url\":\"https://www.semanticscholar.org/paper/696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"1789347\",\"name\":\"Kees van Deemter\"},{\"authorId\":\"144568312\",\"name\":\"Ehud Reiter\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c40e743d12ae387cf844bdfd2e8a2c7c11add28a\",\"title\":\"Generating Expressions that Refer to Visible Objects\",\"url\":\"https://www.semanticscholar.org/paper/c40e743d12ae387cf844bdfd2e8a2c7c11add28a\",\"venue\":\"HLT-NAACL\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1888731\",\"name\":\"M. Hejrati\"},{\"authorId\":\"21160985\",\"name\":\"M. Sadeghi\"},{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"3125805\",\"name\":\"Cyrus Rashtchian\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"144016256\",\"name\":\"D. Forsyth\"}],\"doi\":\"10.1007/978-3-642-15561-1_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eaaed23a2d94feb2f1c3ff22a25777c7a78f3141\",\"title\":\"Every Picture Tells a Story: Generating Sentences from Images\",\"url\":\"https://www.semanticscholar.org/paper/eaaed23a2d94feb2f1c3ff22a25777c7a78f3141\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":\"1411.5726\",\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2015.7299087\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"258986132bf17755fe8263e42429fe73218c1534\",\"title\":\"CIDEr: Consensus-based image description evaluation\",\"url\":\"https://www.semanticscholar.org/paper/258986132bf17755fe8263e42429fe73218c1534\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3253737\",\"name\":\"F. Sadeghi\"},{\"authorId\":\"2038685\",\"name\":\"S. Divvala\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"}],\"doi\":\"10.1109/CVPR.2015.7298752\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"495015d21c26eac9a6bd64c836ee3370283641ec\",\"title\":\"VisKE: Visual knowledge extraction and question answering by visual verification of relation phrases\",\"url\":\"https://www.semanticscholar.org/paper/495015d21c26eac9a6bd64c836ee3370283641ec\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"3006928\",\"name\":\"N. Krishnamoorthy\"},{\"authorId\":\"3163967\",\"name\":\"Girish Malkarnenkar\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/ICCV.2013.337\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d6a7a563640bf53953c4fda0997e4db176488510\",\"title\":\"YouTube2Text: Recognizing and Describing Arbitrary Activities Using Semantic Hierarchies and Zero-Shot Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d6a7a563640bf53953c4fda0997e4db176488510\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3006072\",\"name\":\"Sahar Kazemzadeh\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"32215032\",\"name\":\"Mark Matten\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.3115/v1/D14-1086\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"92c141447f51b6732242376164ff961e464731c8\",\"title\":\"ReferItGame: Referring to Objects in Photographs of Natural Scenes\",\"url\":\"https://www.semanticscholar.org/paper/92c141447f51b6732242376164ff961e464731c8\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":\"1502.05698\",\"authors\":[{\"authorId\":\"145183709\",\"name\":\"J. Weston\"},{\"authorId\":\"1713934\",\"name\":\"Antoine Bordes\"},{\"authorId\":\"3295092\",\"name\":\"S. Chopra\"},{\"authorId\":null,\"name\":\"Tomas Mikolov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"abb33d75dc297993fcc3fb75e0f4498f413eb4f6\",\"title\":\"Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks\",\"url\":\"https://www.semanticscholar.org/paper/abb33d75dc297993fcc3fb75e0f4498f413eb4f6\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":\"1410.0210\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ac64fb7e6d2ddf236332ec9f371fe85d308c114d\",\"title\":\"A Multi-World Approach to Question Answering about Real-World Scenes based on Uncertain Input\",\"url\":\"https://www.semanticscholar.org/paper/ac64fb7e6d2ddf236332ec9f371fe85d308c114d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32375492\",\"name\":\"Jia Deng\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2011.5995516\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f8b5dee83543369488aff195564f6b90c6f9db49\",\"title\":\"Hierarchical semantic indexing for large scale image retrieval\",\"url\":\"https://www.semanticscholar.org/paper/f8b5dee83543369488aff195564f6b90c6f9db49\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"144568312\",\"name\":\"Ehud Reiter\"},{\"authorId\":\"1789347\",\"name\":\"Kees van Deemter\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"92704fd7a9dec32ddbea30516262cb7eaa7ee72e\",\"title\":\"Typicality and Object Reference\",\"url\":\"https://www.semanticscholar.org/paper/92704fd7a9dec32ddbea30516262cb7eaa7ee72e\",\"venue\":\"CogSci\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1109/CVPR.2015.7298856\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a72b8bbd039989db39769da836cdb287737deb92\",\"title\":\"Mind's eye: A recurrent visual representation for image caption generation\",\"url\":\"https://www.semanticscholar.org/paper/a72b8bbd039989db39769da836cdb287737deb92\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2170746\",\"name\":\"M. Hodosh\"},{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"}],\"doi\":\"10.1613/jair.3994\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9814df8bd00ba999c4d1e305a7e9bca579dc7c75\",\"title\":\"Framing Image Description as a Ranking Task: Data, Models and Evaluation Metrics (Extended Abstract)\",\"url\":\"https://www.semanticscholar.org/paper/9814df8bd00ba999c4d1e305a7e9bca579dc7c75\",\"venue\":\"IJCAI\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2015.7298932\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"title\":\"Deep visual-semantic alignments for generating image descriptions\",\"url\":\"https://www.semanticscholar.org/paper/ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"venue\":\"CVPR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38087946\",\"name\":\"Anthony Fader\"},{\"authorId\":\"1982950\",\"name\":\"Luke Zettlemoyer\"},{\"authorId\":\"1741101\",\"name\":\"Oren Etzioni\"}],\"doi\":\"10.1145/2623330.2623677\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f86ec155cce6259e5230aaad3b762343757feb1d\",\"title\":\"Open question answering over curated and extracted knowledge bases\",\"url\":\"https://www.semanticscholar.org/paper/f86ec155cce6259e5230aaad3b762343757feb1d\",\"venue\":\"KDD\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145714602\",\"name\":\"E. Wilde\"}],\"doi\":\"10.1109/SCC.2007.135\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1879caf0debda3e10c49780669422f12e54af000\",\"title\":\"What are you talking about?\",\"url\":\"https://www.semanticscholar.org/paper/1879caf0debda3e10c49780669422f12e54af000\",\"venue\":\"IEEE International Conference on Services Computing (SCC 2007)\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"34176020\",\"name\":\"Jesse Dodge\"},{\"authorId\":\"46479604\",\"name\":\"Amit Goyal\"},{\"authorId\":\"1721910\",\"name\":\"Kota Yamaguchi\"},{\"authorId\":\"1714215\",\"name\":\"K. Stratos\"},{\"authorId\":\"1682965\",\"name\":\"Xufeng Han\"},{\"authorId\":\"40614240\",\"name\":\"A. Mensch\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1722360\",\"name\":\"Hal Daum\\u00e9\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"355de7460120ddc1150d9ce3756f9848983f7ff4\",\"title\":\"Midge: Generating Image Descriptions From Computer Vision Detections\",\"url\":\"https://www.semanticscholar.org/paper/355de7460120ddc1150d9ce3756f9848983f7ff4\",\"venue\":\"EACL\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1742448\",\"name\":\"K. Bollacker\"},{\"authorId\":\"144572178\",\"name\":\"C. Evans\"},{\"authorId\":\"2990264\",\"name\":\"Praveen Paritosh\"},{\"authorId\":\"1399112633\",\"name\":\"Tim Sturge\"},{\"authorId\":\"37715132\",\"name\":\"J. Taylor\"}],\"doi\":\"10.1145/1376616.1376746\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1976c9eeccc7115d18a04f1e7fb5145db6b96002\",\"title\":\"Freebase: a collaboratively created graph database for structuring human knowledge\",\"url\":\"https://www.semanticscholar.org/paper/1976c9eeccc7115d18a04f1e7fb5145db6b96002\",\"venue\":\"SIGMOD Conference\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1909300\",\"name\":\"Lucy Vanderwende\"}],\"doi\":\"10.1109/ICCV.2013.211\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c39f56c3c21c3972c362f8e752be57a50c41f4f\",\"title\":\"Learning the Visual Interpretation of Sentences\",\"url\":\"https://www.semanticscholar.org/paper/6c39f56c3c21c3972c362f8e752be57a50c41f4f\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"2155311\",\"name\":\"Eunbyung Park\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/ICCV.2015.283\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ced9f7178f8032d3408fcba493c02eb48e8a8636\",\"title\":\"Visual Madlibs: Fill in the Blank Description Generation and Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ced9f7178f8032d3408fcba493c02eb48e8a8636\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1308.6628\",\"authors\":[{\"authorId\":\"40341553\",\"name\":\"K. Tu\"},{\"authorId\":\"143764552\",\"name\":\"M. Meng\"},{\"authorId\":\"2649483\",\"name\":\"M. Lee\"},{\"authorId\":\"2194804\",\"name\":\"T. E. Choe\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/MMUL.2014.29\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2935d8071583e46c5a895730c65d2bd213757c07\",\"title\":\"Joint Video and Text Parsing for Understanding Events and Answering Queries\",\"url\":\"https://www.semanticscholar.org/paper/2935d8071583e46c5a895730c65d2bd213757c07\",\"venue\":\"IEEE MultiMedia\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144422314\",\"name\":\"M. Richardson\"},{\"authorId\":\"2676309\",\"name\":\"C. Burges\"},{\"authorId\":\"1859813\",\"name\":\"Erin Renshaw\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"564257469fa44cdb57e4272f85253efb9acfd69d\",\"title\":\"MCTest: A Challenge Dataset for the Open-Domain Machine Comprehension of Text\",\"url\":\"https://www.semanticscholar.org/paper/564257469fa44cdb57e4272f85253efb9acfd69d\",\"venue\":\"EMNLP\",\"year\":2013},{\"arxivId\":\"1408.5093\",\"authors\":[{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"1782282\",\"name\":\"Evan Shelhamer\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"3049736\",\"name\":\"S. Karayev\"},{\"authorId\":\"144361581\",\"name\":\"J. Long\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1145/2647868.2654889\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6bdb186ec4726e00a8051119636d4df3b94043b5\",\"title\":\"Caffe: Convolutional Architecture for Fast Feature Embedding\",\"url\":\"https://www.semanticscholar.org/paper/6bdb186ec4726e00a8051119636d4df3b94043b5\",\"venue\":\"ACM Multimedia\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2013.387\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"051830b0ea58d1568f19ec3297e301d9789c9a76\",\"title\":\"Bringing Semantics into Focus Using Visual Abstraction\",\"url\":\"https://www.semanticscholar.org/paper/051830b0ea58d1568f19ec3297e301d9789c9a76\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1511.05099\",\"authors\":[{\"authorId\":\"40409467\",\"name\":\"P. Zhang\"},{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2016.542\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5fa973b8d284145bf0ced9acf2913a74674260f6\",\"title\":\"Yin and Yang: Balancing and Answering Binary Visual Questions\",\"url\":\"https://www.semanticscholar.org/paper/5fa973b8d284145bf0ced9acf2913a74674260f6\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1505.02074\",\"authors\":[{\"authorId\":\"2540599\",\"name\":\"Mengye Ren\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"62a956d7600b10ca455076cd56e604dfd106072a\",\"title\":\"Exploring Models and Data for Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/62a956d7600b10ca455076cd56e604dfd106072a\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1411.4952\",\"authors\":[{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3346186\",\"name\":\"Forrest N. Iandola\"},{\"authorId\":\"2100612\",\"name\":\"R. Srivastava\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"144189092\",\"name\":\"John C. Platt\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"}],\"doi\":\"10.1109/CVPR.2015.7298754\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"title\":\"From captions to visual concepts and back\",\"url\":\"https://www.semanticscholar.org/paper/15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/TPAMI.2014.2366143\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f8403bf4e3060487cbc8acceb1fb256a4f1cfc76\",\"title\":\"Adopting Abstract Images for Semantic Scene Understanding\",\"url\":\"https://www.semanticscholar.org/paper/f8403bf4e3060487cbc8acceb1fb256a4f1cfc76\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2016},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1505.05612\",\"authors\":[{\"authorId\":\"2345388\",\"name\":\"Haoyuan Gao\"},{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":null,\"name\":\"Jie Zhou\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":null,\"name\":\"Lei Wang\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2fcd5cff2b4743ea640c4af68bf4143f4a2cccb1\",\"title\":\"Are You Talking to a Machine? Dataset and Methods for Multilingual Image Question\",\"url\":\"https://www.semanticscholar.org/paper/2fcd5cff2b4743ea640c4af68bf4143f4a2cccb1\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145564333\",\"name\":\"G. Kulkarni\"},{\"authorId\":\"3128210\",\"name\":\"Visruth Premraj\"},{\"authorId\":\"2985883\",\"name\":\"Sagnik Dhar\"},{\"authorId\":\"50341924\",\"name\":\"Siming Li\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/CVPR.2011.5995466\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"169b847e69c35cfd475eb4dcc561a24de11762ca\",\"title\":\"Baby talk: Understanding and generating simple image descriptions\",\"url\":\"https://www.semanticscholar.org/paper/169b847e69c35cfd475eb4dcc561a24de11762ca\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1744846\",\"name\":\"Jeffrey P. Bigham\"},{\"authorId\":\"1712587\",\"name\":\"C. Jayant\"},{\"authorId\":\"1737220\",\"name\":\"H. Ji\"},{\"authorId\":\"48155668\",\"name\":\"G. Little\"},{\"authorId\":\"153472666\",\"name\":\"A. Miller\"},{\"authorId\":\"34205614\",\"name\":\"R. Miller\"},{\"authorId\":\"1715819\",\"name\":\"Aubrey Tatarowicz\"},{\"authorId\":\"37929982\",\"name\":\"B. White\"},{\"authorId\":\"144289340\",\"name\":\"Samuel White\"},{\"authorId\":\"1704158\",\"name\":\"T. Yeh\"}],\"doi\":\"10.1145/1805986.1806020\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e0c668d1da866617ccfeee910d13eb14fa340bea\",\"title\":\"VizWiz: nearly real-time answers to visual questions\",\"url\":\"https://www.semanticscholar.org/paper/e0c668d1da866617ccfeee910d13eb14fa340bea\",\"venue\":\"W4A\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1707642\",\"name\":\"D. Geman\"},{\"authorId\":\"3194361\",\"name\":\"S. Geman\"},{\"authorId\":\"9588317\",\"name\":\"Neil Hallonquist\"},{\"authorId\":\"1721284\",\"name\":\"L. Younes\"}],\"doi\":\"10.1073/pnas.1422953112\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"050da5d159fb0dd96143948e1cffeb3dec814673\",\"title\":\"Visual Turing test for computer vision systems\",\"url\":\"https://www.semanticscholar.org/paper/050da5d159fb0dd96143948e1cffeb3dec814673\",\"venue\":\"Proceedings of the National Academy of Sciences\",\"year\":2015},{\"arxivId\":\"1502.06108\",\"authors\":[{\"authorId\":\"9136919\",\"name\":\"X. Lin\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2015.7298917\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e0cff50a6ce27a8cb2b26ca586dea8a0b7cd67bd\",\"title\":\"Don't just listen, use your imagination: Leveraging visual common sense for non-visual tasks\",\"url\":\"https://www.semanticscholar.org/paper/e0cff50a6ce27a8cb2b26ca586dea8a0b7cd67bd\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1744846\",\"name\":\"Jeffrey P. Bigham\"},{\"authorId\":\"1712587\",\"name\":\"C. Jayant\"},{\"authorId\":\"1737220\",\"name\":\"H. Ji\"},{\"authorId\":\"48155668\",\"name\":\"G. Little\"},{\"authorId\":\"144360239\",\"name\":\"A. Miller\"},{\"authorId\":\"34205614\",\"name\":\"R. Miller\"},{\"authorId\":\"2925245\",\"name\":\"R. Miller\"},{\"authorId\":\"1715819\",\"name\":\"Aubrey Tatarowicz\"},{\"authorId\":\"37929982\",\"name\":\"B. White\"},{\"authorId\":\"144289340\",\"name\":\"Samuel White\"},{\"authorId\":\"1704158\",\"name\":\"T. Yeh\"}],\"doi\":\"10.1145/1866029.1866080\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a960ea40fe7b32a1ee702a84f64ec1de5c3e7fe\",\"title\":\"VizWiz: nearly real-time answers to visual questions\",\"url\":\"https://www.semanticscholar.org/paper/8a960ea40fe7b32a1ee702a84f64ec1de5c3e7fe\",\"venue\":\"UIST '10\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1704635\",\"name\":\"D. Lenat\"},{\"authorId\":\"145615125\",\"name\":\"R. Guha\"}],\"doi\":\"10.1016/0004-3702(93)90093-q\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cd4ba23c89b5b4eecd9b542e79dbdc195de65f6d\",\"title\":\"Building Large Knowledge-Based Systems: Representation and Inference in the Cyc Project\",\"url\":\"https://www.semanticscholar.org/paper/cd4ba23c89b5b4eecd9b542e79dbdc195de65f6d\",\"venue\":\"\",\"year\":1990},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34066479\",\"name\":\"Vignesh Ramanathan\"},{\"authorId\":\"2319608\",\"name\":\"Armand Joulin\"},{\"authorId\":\"40085065\",\"name\":\"Percy Liang\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/978-3-319-10590-1_7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a0a083c7bb23db507a40a736953b1cca5a33b16d\",\"title\":\"Linking People in Videos with \\\"Their\\\" Names Using Coreference Resolution\",\"url\":\"https://www.semanticscholar.org/paper/a0a083c7bb23db507a40a736953b1cca5a33b16d\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1411.2539\",\"authors\":[{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2e36ea91a3c8fbff92be2989325531b4002e2afc\",\"title\":\"Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models\",\"url\":\"https://www.semanticscholar.org/paper/2e36ea91a3c8fbff92be2989325531b4002e2afc\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":\"1506.06726\",\"authors\":[{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"2214033\",\"name\":\"Y. Zhu\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6e795c6e9916174ae12349f5dc3f516570c17ce8\",\"title\":\"Skip-Thought Vectors\",\"url\":\"https://www.semanticscholar.org/paper/6e795c6e9916174ae12349f5dc3f516570c17ce8\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145402198\",\"name\":\"Jonathan Gordon\"},{\"authorId\":\"7536576\",\"name\":\"Benjamin Van Durme\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"46e123a8ba5d4277b935c97529d48f2e678a9b45\",\"title\":\"Reporting Bias and Knowledge Extraction\",\"url\":\"https://www.semanticscholar.org/paper/46e123a8ba5d4277b935c97529d48f2e678a9b45\",\"venue\":\"\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/CVPR.2015.7298878\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5838af587938e74b5758414c384dcf16dd6e1d1e\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/5838af587938e74b5758414c384dcf16dd6e1d1e\",\"venue\":\"CVPR\",\"year\":2015}],\"title\":\"VQA: Visual Question Answering\",\"topics\":[{\"topic\":\"Question answering\",\"topicId\":\"18817\",\"url\":\"https://www.semanticscholar.org/topic/18817\"},{\"topic\":\"Natural language\",\"topicId\":\"1911\",\"url\":\"https://www.semanticscholar.org/topic/1911\"},{\"topic\":\"Nonlinear gameplay\",\"topicId\":\"62171\",\"url\":\"https://www.semanticscholar.org/topic/62171\"},{\"topic\":\"Google Questions and Answers\",\"topicId\":\"2898125\",\"url\":\"https://www.semanticscholar.org/topic/2898125\"},{\"topic\":\"Human reliability\",\"topicId\":\"193661\",\"url\":\"https://www.semanticscholar.org/topic/193661\"},{\"topic\":\"Disk mirroring\",\"topicId\":\"492762\",\"url\":\"https://www.semanticscholar.org/topic/492762\"}],\"url\":\"https://www.semanticscholar.org/paper/784da2a7b53a16d2243f747e14946cc5e3476af0\",\"venue\":\"ICCV\",\"year\":2015}\n"