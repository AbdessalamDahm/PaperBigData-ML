"{\"abstract\":\"In this paper, we introduce a new dataset consisting of 360,001 focused natural language descriptions for 10,738 images. This dataset, the Visual Madlibs dataset, is collected using automatically produced fill-in-the-blank templates designed to gather targeted descriptions about: people and objects, their appearances, activities, and interactions, as well as inferences about the general scene or its broader context. We provide several analyses of the Visual Madlibs dataset and demonstrate its applicability to two new description generation tasks: focused description generation, and multiple-choice question-answering for images. Experiments using joint-embedding and deep learning methods show promising results on these tasks.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\",\"url\":\"https://www.semanticscholar.org/author/1714982\"},{\"authorId\":\"2155311\",\"name\":\"Eunbyung Park\",\"url\":\"https://www.semanticscholar.org/author/2155311\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\",\"url\":\"https://www.semanticscholar.org/author/39668247\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\",\"url\":\"https://www.semanticscholar.org/author/1685538\"}],\"citationVelocity\":21,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"35330701\",\"name\":\"K. Takanashi\"},{\"authorId\":\"71687093\",\"name\":\"T. Kawahara\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"88452dc70b263442c5da454fa801e80200a4d948\",\"title\":\"18th Annual Meeting of the Special Interest Group on Discourse and Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/88452dc70b263442c5da454fa801e80200a4d948\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"103567595\",\"name\":\"Shayan Hassantabar\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"880760777e3671593ba50b7a17b0d30b655fc86d\",\"title\":\"Visual Question Answering : Datasets , Methods , Challenges and Oppurtunities\",\"url\":\"https://www.semanticscholar.org/paper/880760777e3671593ba50b7a17b0d30b655fc86d\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1576818877\",\"name\":\"Kento Terao\"},{\"authorId\":\"134811419\",\"name\":\"Toru Tamaki\"},{\"authorId\":\"1688940\",\"name\":\"B. Raytchev\"},{\"authorId\":\"1686272\",\"name\":\"K. Kaneda\"},{\"authorId\":\"144404414\",\"name\":\"S. Satoh\"}],\"doi\":\"10.1109/ACCESS.2020.3022063\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c7583d58aec662313bd5b0082b656d9f44956dc3\",\"title\":\"An Entropy Clustering Approach for Assessing Visual Question Difficulty\",\"url\":\"https://www.semanticscholar.org/paper/c7583d58aec662313bd5b0082b656d9f44956dc3\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1604.04808\",\"authors\":[{\"authorId\":\"36508529\",\"name\":\"Arun Mallya\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1007/978-3-319-46448-0_25\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"de984e920b38b07421a1c17fb10e0c6677a4f5fb\",\"title\":\"Learning Models for Actions and Person-Object Interactions with Transfer to Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/de984e920b38b07421a1c17fb10e0c6677a4f5fb\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1912.01452\",\"authors\":[{\"authorId\":\"50535497\",\"name\":\"Jiahong Huang\"},{\"authorId\":\"9951160\",\"name\":\"Modar Alfadly\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"1717056\",\"name\":\"M. Worring\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"01aa5668a618fbb376b6ab6608defc074ed355ac\",\"title\":\"Assessing the Robustness of Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/01aa5668a618fbb376b6ab6608defc074ed355ac\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50005563\",\"name\":\"G. Christie\"},{\"authorId\":\"2440772\",\"name\":\"Ankit P Laddha\"},{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"1942176\",\"name\":\"K. Kochersberger\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1016/j.cviu.2017.09.001\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2dbca69f6e50c058a44243abfaf669097a02c879\",\"title\":\"Resolving vision and language ambiguities together: Joint segmentation & prepositional attachment resolution in captioned scenes\",\"url\":\"https://www.semanticscholar.org/paper/2dbca69f6e50c058a44243abfaf669097a02c879\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":\"1705.03865\",\"authors\":[{\"authorId\":\"50178628\",\"name\":\"Akshay Kumar Gupta\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"637648198f9e91654ce27eaaa40512f2dc870fc1\",\"title\":\"Survey of Visual Question Answering: Datasets and Techniques\",\"url\":\"https://www.semanticscholar.org/paper/637648198f9e91654ce27eaaa40512f2dc870fc1\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1612.09542\",\"authors\":[{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"47300698\",\"name\":\"Hao Tan\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/CVPR.2017.375\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a5b64709c677c131ec8b7846d3493df53987fa6f\",\"title\":\"A Joint Speaker-Listener-Reinforcer Model for Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/a5b64709c677c131ec8b7846d3493df53987fa6f\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145808756\",\"name\":\"Xuanyi Dong\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"145865760\",\"name\":\"D. Zhang\"},{\"authorId\":null,\"name\":\"Yi Yang\"},{\"authorId\":\"39918420\",\"name\":\"F. Wu\"}],\"doi\":\"10.1145/3240508.3240527\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"81b3cfd55ca84802cdcc971410e633ed40e04980\",\"title\":\"Fast Parameter Adaptation for Few-shot Image Captioning and Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/81b3cfd55ca84802cdcc971410e633ed40e04980\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1905.13648\",\"authors\":[{\"authorId\":\"35570245\",\"name\":\"Ali Furkan Biten\"},{\"authorId\":\"134682605\",\"name\":\"Ruben Tito\"},{\"authorId\":\"51238351\",\"name\":\"Andr\\u00e9s Mafla\"},{\"authorId\":\"51231577\",\"name\":\"Llu\\u00eds G\\u00f3mez\"},{\"authorId\":\"143823474\",\"name\":\"M. Rusi\\u00f1ol\"},{\"authorId\":\"2864362\",\"name\":\"Ernest Valveny\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"},{\"authorId\":\"1694974\",\"name\":\"Dimosthenis Karatzas\"}],\"doi\":\"10.1109/ICCV.2019.00439\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0033346700dc450ac22c9b704eab0e906d868662\",\"title\":\"Scene Text Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0033346700dc450ac22c9b704eab0e906d868662\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1620218253\",\"name\":\"Sruthy Manmadhan\"},{\"authorId\":\"30588803\",\"name\":\"Binsu C. Kovoor\"}],\"doi\":\"10.1007/978-981-15-5788-0_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c51bfb53b85ef2e19d6ae61ca7be9c0ed3ae63d8\",\"title\":\"Optimal Image Feature Ranking and Fusion for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/c51bfb53b85ef2e19d6ae61ca7be9c0ed3ae63d8\",\"venue\":\"FICTA\",\"year\":2020},{\"arxivId\":\"1901.09107\",\"authors\":[{\"authorId\":\"2809915\",\"name\":\"H. AlAmri\"},{\"authorId\":\"51002409\",\"name\":\"Vincent Cartillier\"},{\"authorId\":\"50317425\",\"name\":\"Abhishek Das\"},{\"authorId\":null,\"name\":\"Jue Wang\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"153149395\",\"name\":\"P. Anderson\"},{\"authorId\":\"21472040\",\"name\":\"Irfan Essa\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"},{\"authorId\":\"1765212\",\"name\":\"C. Hori\"}],\"doi\":\"10.1109/CVPR.2019.00774\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"044c56af7005c2013ce24c7199af716319378d7f\",\"title\":\"Audio Visual Scene-Aware Dialog\",\"url\":\"https://www.semanticscholar.org/paper/044c56af7005c2013ce24c7199af716319378d7f\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"112858943\",\"name\":\"Z. Liu\"},{\"authorId\":\"2427350\",\"name\":\"Yankai Lin\"},{\"authorId\":\"1753344\",\"name\":\"M. Sun\"}],\"doi\":\"10.1007/978-981-15-5573-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2f1107ea6b9b4147a808e9ae27757e214685e90a\",\"title\":\"Representation Learning for Natural Language Processing\",\"url\":\"https://www.semanticscholar.org/paper/2f1107ea6b9b4147a808e9ae27757e214685e90a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51021338\",\"name\":\"Nelson Ruwa\"},{\"authorId\":\"151423308\",\"name\":\"Qirong Mao\"},{\"authorId\":\"3309006\",\"name\":\"Heping Song\"},{\"authorId\":\"153719921\",\"name\":\"H. Jia\"},{\"authorId\":\"1384379379\",\"name\":\"Ming Dong\"}],\"doi\":\"10.1016/j.cviu.2019.102829\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9572e232d33aba1b765ef90924d8662707cc2a01\",\"title\":\"Triple attention network for sentimental visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/9572e232d33aba1b765ef90924d8662707cc2a01\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2019},{\"arxivId\":\"2004.12238\",\"authors\":[{\"authorId\":\"1424748326\",\"name\":\"A. Kumar\"},{\"authorId\":\"9214782\",\"name\":\"Trisha Mittal\"},{\"authorId\":\"1699159\",\"name\":\"D. Manocha\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"43d992c17b53e75e46a29c9866ac1c0966bd5bf4\",\"title\":\"MCQA: Multimodal Co-attention Based Network for Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/43d992c17b53e75e46a29c9866ac1c0966bd5bf4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144897421\",\"name\":\"Rachel N. Simons\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"62cd6ac2eaadf030eac67d9ec33554daee05e178\",\"title\":\"\\\"I Hope This Is Helpful\\\": Understanding Crowdworkers\\u2019 Challenges and Motivations for an Image Description Task\",\"url\":\"https://www.semanticscholar.org/paper/62cd6ac2eaadf030eac67d9ec33554daee05e178\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1606.05433\",\"authors\":[{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"121177698\",\"name\":\"A. Dick\"},{\"authorId\":\"133678193\",\"name\":\"A. van den Hengel\"}],\"doi\":\"10.1109/TPAMI.2017.2754246\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b60630911d7746fba06de7c34abe98c9a61c6bcc\",\"title\":\"FVQA: Fact-Based Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b60630911d7746fba06de7c34abe98c9a61c6bcc\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51021338\",\"name\":\"Nelson Ruwa\"},{\"authorId\":\"3069077\",\"name\":\"Q. Mao\"},{\"authorId\":\"2054737\",\"name\":\"Liangjun Wang\"},{\"authorId\":\"38978232\",\"name\":\"J. Gou\"},{\"authorId\":\"144964053\",\"name\":\"M. Dong\"}],\"doi\":\"10.1016/j.neucom.2018.11.049\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e3e4954e40f33b503f7fe220be90917124a09c43\",\"title\":\"Mood-aware visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/e3e4954e40f33b503f7fe220be90917124a09c43\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"940c90eb474cb2670559e03965b97a67eabd7a73\",\"title\":\"CODRAW: COLLABORATIVE DRAWING\",\"url\":\"https://www.semanticscholar.org/paper/940c90eb474cb2670559e03965b97a67eabd7a73\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"89855289\",\"name\":\"K. Basu\"},{\"authorId\":\"19317347\",\"name\":\"Farhad Shakerin\"},{\"authorId\":\"7525172\",\"name\":\"G. Gupta\"}],\"doi\":\"10.1007/978-3-030-39197-3_4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4bce0e394c2bfdcbfbe5910a7740a653af3284d6\",\"title\":\"AQuA: ASP-Based Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/4bce0e394c2bfdcbfbe5910a7740a653af3284d6\",\"venue\":\"PADL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"86912250\",\"name\":\"Peixi Xiong\"},{\"authorId\":\"145074713\",\"name\":\"Ying Wu\"}],\"doi\":\"10.1109/cvpr42600.2020.01008\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ed212b4c747d35e284e8874c38cd0b855cd98f66\",\"title\":\"TA-Student VQA: Multi-Agents Training by Self-Questioning\",\"url\":\"https://www.semanticscholar.org/paper/ed212b4c747d35e284e8874c38cd0b855cd98f66\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"},{\"authorId\":\"4418074\",\"name\":\"Minjoon Seo\"},{\"authorId\":\"34846449\",\"name\":\"D. Schwenk\"},{\"authorId\":\"119675494\",\"name\":\"Jonghyun Choi\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"2548384\",\"name\":\"Hannaneh Hajishirzi\"}],\"doi\":\"10.1109/CVPR.2017.571\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c071a1ad68310fed7f0876b6f01cb7b135043bc3\",\"title\":\"Are You Smarter Than a Sixth Grader? Textbook Question Answering for Multimodal Machine Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/c071a1ad68310fed7f0876b6f01cb7b135043bc3\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1707.05691\",\"authors\":[{\"authorId\":\"1399909799\",\"name\":\"Xintong Han\"},{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"1392470243\",\"name\":\"Larry S. Davis\"}],\"doi\":\"10.1145/3123266.3123394\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1686a73010fadf9c78b2d617a74d8e981fd7a290\",\"title\":\"Learning Fashion Compatibility with Bidirectional LSTMs\",\"url\":\"https://www.semanticscholar.org/paper/1686a73010fadf9c78b2d617a74d8e981fd7a290\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145037543\",\"name\":\"Q. Sun\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"974cadd15684c96618d04f845794cec5568a86a6\",\"title\":\"Greedy Inference Algorithms for Structured and Neural Models\",\"url\":\"https://www.semanticscholar.org/paper/974cadd15684c96618d04f845794cec5568a86a6\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49597404\",\"name\":\"Z. Fang\"},{\"authorId\":null,\"name\":\"Jing Liu\"},{\"authorId\":\"49544292\",\"name\":\"Xueliang Liu\"},{\"authorId\":null,\"name\":\"Qu Tang\"},{\"authorId\":\"50025104\",\"name\":\"Yonghong Li\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1145/3282469\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2c74311cc5e18a120bebf331b0dd85c72426380d\",\"title\":\"BTDP: Toward Sparse Fusion with Block Term Decomposition Pooling for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2c74311cc5e18a120bebf331b0dd85c72426380d\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153188145\",\"name\":\"J. Kim\"},{\"authorId\":\"143808231\",\"name\":\"Nikita Kitaev\"},{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"},{\"authorId\":\"39402399\",\"name\":\"Yuandong Tian\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"144179578\",\"name\":\"D. Parikh\"}],\"doi\":\"10.18653/v1/P19-1651\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"58641a3a4b4653b5d63e57dc6dfe3935b866d78f\",\"title\":\"CoDraw: Collaborative Drawing as a Testbed for Grounded Goal-driven Communication\",\"url\":\"https://www.semanticscholar.org/paper/58641a3a4b4653b5d63e57dc6dfe3935b866d78f\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37774552\",\"name\":\"Tomer Ullman\"},{\"authorId\":\"1409262931\",\"name\":\"Santiago Alonso-Diaz\"},{\"authorId\":\"5078954\",\"name\":\"Stephen Ferrigno\"},{\"authorId\":\"32876847\",\"name\":\"Sarina Zahid\"},{\"authorId\":\"144584048\",\"name\":\"Celeste Kidd\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"69070d7d1d770264ef0cf38615984fa91ef4bf68\",\"title\":\"Weight matters: The role of physical weight in non-physical language across age and culture\",\"url\":\"https://www.semanticscholar.org/paper/69070d7d1d770264ef0cf38615984fa91ef4bf68\",\"venue\":\"CogSci\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9305072\",\"name\":\"Jifei Song\"},{\"authorId\":\"1705408\",\"name\":\"Yi-Zhe Song\"},{\"authorId\":\"1965319\",\"name\":\"Tony Xiang\"},{\"authorId\":\"1697755\",\"name\":\"Timothy M. Hospedales\"}],\"doi\":\"10.5244/C.31.45\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c52f30ef7fbef659994dc195bcce16fa85bd6f41\",\"title\":\"Fine-Grained Image Retrieval: the Text/Sketch Input Dilemma\",\"url\":\"https://www.semanticscholar.org/paper/c52f30ef7fbef659994dc195bcce16fa85bd6f41\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":\"1809.00812\",\"authors\":[{\"authorId\":\"40387200\",\"name\":\"S. Yagcioglu\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"},{\"authorId\":\"1398643531\",\"name\":\"N. Ikizler-Cinbis\"}],\"doi\":\"10.18653/v1/D18-1166\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c581686edbd7227e9eb4a0841cce16728ca27369\",\"title\":\"RecipeQA: A Challenge Dataset for Multimodal Comprehension of Cooking Recipes\",\"url\":\"https://www.semanticscholar.org/paper/c581686edbd7227e9eb4a0841cce16728ca27369\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"1705.08759\",\"authors\":[{\"authorId\":\"144207643\",\"name\":\"Q. Sun\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1109/CVPR.2017.763\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1cee733ee31e245dac4655a870fd9226163a52b5\",\"title\":\"Bidirectional Beam Search: Forward-Backward Inference in Neural Sequence Models for Fill-in-the-Blank Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/1cee733ee31e245dac4655a870fd9226163a52b5\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1708.02760\",\"authors\":[{\"authorId\":\"47002704\",\"name\":\"Y. Li\"},{\"authorId\":\"145544640\",\"name\":\"C. Huang\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"}],\"doi\":\"10.1109/ICCV.2017.370\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"acb1ffd5ba92b0c450ec63f36f4f67a972fc35ed\",\"title\":\"Learning to Disambiguate by Asking Discriminative Questions\",\"url\":\"https://www.semanticscholar.org/paper/acb1ffd5ba92b0c450ec63f36f4f67a972fc35ed\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1607.02769\",\"authors\":[{\"authorId\":\"3433384\",\"name\":\"Gitit Kehat\"},{\"authorId\":\"1707726\",\"name\":\"J. Pustejovsky\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b6ecc8d34ebc8895378abe2b8f35e3a0691f5d26\",\"title\":\"Annotation Methodologies for Vision and Language Dataset Creation\",\"url\":\"https://www.semanticscholar.org/paper/b6ecc8d34ebc8895378abe2b8f35e3a0691f5d26\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2087226\",\"name\":\"T. Tommasi\"},{\"authorId\":\"36508529\",\"name\":\"Arun Mallya\"},{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1007/s11263-018-1096-0\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6f8ea6c3d195b92a92005f993aa98b98b069d10d\",\"title\":\"Combining Multiple Cues for Visual Madlibs Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/6f8ea6c3d195b92a92005f993aa98b98b069d10d\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018},{\"arxivId\":\"1604.02125\",\"authors\":[{\"authorId\":\"50005563\",\"name\":\"G. Christie\"},{\"authorId\":\"48222562\",\"name\":\"A. Laddha\"},{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"98391857\",\"name\":\"K. Kochersberger\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.18653/v1/D16-1156\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"26eb2c900814707ae962184ad4173e754247a80a\",\"title\":\"Resolving Language and Vision Ambiguities Together: Joint Segmentation & Prepositional Attachment Resolution in Captioned Scenes\",\"url\":\"https://www.semanticscholar.org/paper/26eb2c900814707ae962184ad4173e754247a80a\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":\"1705.01253\",\"authors\":[{\"authorId\":\"2511637\",\"name\":\"Hongyang Xue\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"}],\"doi\":\"10.1016/j.neucom.2018.06.069\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"783e48629dfbb44697b15a3bc0cb2aa3eea490eb\",\"title\":\"The Forgettable-Watcher Model for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/783e48629dfbb44697b15a3bc0cb2aa3eea490eb\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":\"1704.07129\",\"authors\":[{\"authorId\":\"2921001\",\"name\":\"Spandana Gella\"},{\"authorId\":\"143694777\",\"name\":\"Frank Keller\"}],\"doi\":\"10.18653/v1/P17-2011\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"766330b56c01c946d257cb3bef5234ac29bc7f69\",\"title\":\"An Analysis of Action Recognition Datasets for Language and Vision Tasks\",\"url\":\"https://www.semanticscholar.org/paper/766330b56c01c946d257cb3bef5234ac29bc7f69\",\"venue\":\"ACL\",\"year\":2017},{\"arxivId\":\"1906.00067\",\"authors\":[{\"authorId\":\"35789996\",\"name\":\"Kenneth Marino\"},{\"authorId\":\"143887493\",\"name\":\"M. Rastegari\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"3012475\",\"name\":\"R. Mottaghi\"}],\"doi\":\"10.1109/CVPR.2019.00331\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"28ad018c39d1578bea84e7cedf94459e3dbe1e70\",\"title\":\"OK-VQA: A Visual Question Answering Benchmark Requiring External Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/28ad018c39d1578bea84e7cedf94459e3dbe1e70\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1805.06549\",\"authors\":[{\"authorId\":\"3238408\",\"name\":\"P. Madhyastha\"},{\"authorId\":\"2635321\",\"name\":\"Josiah Wang\"},{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"}],\"doi\":\"10.18653/v1/N18-2069\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8629c779581a0f46452bc4ca45b571bfbd3cd063\",\"title\":\"Defoiling Foiled Image Captions\",\"url\":\"https://www.semanticscholar.org/paper/8629c779581a0f46452bc4ca45b571bfbd3cd063\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":\"1909.01860\",\"authors\":[{\"authorId\":\"66275275\",\"name\":\"Yash Srivastava\"},{\"authorId\":\"152967610\",\"name\":\"Vaishnav Murali\"},{\"authorId\":\"34992579\",\"name\":\"S. Dubey\"},{\"authorId\":\"34356161\",\"name\":\"Snehasis Mukherjee\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b0ddbc14499fbc4b03ad92eb7f9a9b26b1eeb39e\",\"title\":\"Visual Question Answering using Deep Learning: A Survey and Performance Analysis\",\"url\":\"https://www.semanticscholar.org/paper/b0ddbc14499fbc4b03ad92eb7f9a9b26b1eeb39e\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2010.14095\",\"authors\":[{\"authorId\":\"25263842\",\"name\":\"Aisha Urooj Khan\"},{\"authorId\":\"144839067\",\"name\":\"Amir Mazaheri\"},{\"authorId\":\"1700665\",\"name\":\"N. Lobo\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.417\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bf8a0cda4f26c889d1b6d16fe070fa3d907a8686\",\"title\":\"MMFT-BERT: Multimodal Fusion Transformer with BERT Encodings for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/bf8a0cda4f26c889d1b6d16fe070fa3d907a8686\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Tarfah Alrashid\"},{\"authorId\":\"2635321\",\"name\":\"Josiah Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"70327c8228b508388f96bd70d7dbdf3943c8437e\",\"title\":\"Annotating and Recognising Visually Descriptive Language\",\"url\":\"https://www.semanticscholar.org/paper/70327c8228b508388f96bd70d7dbdf3943c8437e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1904.03000\",\"authors\":[{\"authorId\":\"7229001\",\"name\":\"Johann Sawatzky\"},{\"authorId\":\"1889486\",\"name\":\"Yaser Souri\"},{\"authorId\":\"144306299\",\"name\":\"C. Grund\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1109/CVPR.2019.00779\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e7b36024652d99cdf1f75a1daa891729ef0aa0cb\",\"title\":\"What Object Should I Use? - Task Driven Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/e7b36024652d99cdf1f75a1daa891729ef0aa0cb\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1612.07833\",\"authors\":[{\"authorId\":\"145534769\",\"name\":\"N. Ding\"},{\"authorId\":\"7685850\",\"name\":\"Sebastian Goodman\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6edb41364802b0fdd1e3e98d644fe78b1ecbbe45\",\"title\":\"Understanding Image and Text Simultaneously: a Dual Vision-Language Machine Comprehension Task\",\"url\":\"https://www.semanticscholar.org/paper/6edb41364802b0fdd1e3e98d644fe78b1ecbbe45\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1612.09161\",\"authors\":[{\"authorId\":\"145476835\",\"name\":\"Ang Li\"},{\"authorId\":\"14258597\",\"name\":\"A. Jabri\"},{\"authorId\":\"2319608\",\"name\":\"Armand Joulin\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"}],\"doi\":\"10.1109/ICCV.2017.449\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8938988d82c6eb18e47deb5e69220652446c60bd\",\"title\":\"Learning Visual N-Grams from Web Data\",\"url\":\"https://www.semanticscholar.org/paper/8938988d82c6eb18e47deb5e69220652446c60bd\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1801.09718\",\"authors\":[{\"authorId\":\"35358246\",\"name\":\"Mikyas T. Desta\"},{\"authorId\":\"2230576\",\"name\":\"Larry Chen\"},{\"authorId\":\"2725083\",\"name\":\"T. Kornuta\"}],\"doi\":\"10.1109/WACV.2018.00201\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"23d6bb8edcd86f8439072f932f414329b393473b\",\"title\":\"Object-Based Reasoning in VQA\",\"url\":\"https://www.semanticscholar.org/paper/23d6bb8edcd86f8439072f932f414329b393473b\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":\"1711.06666\",\"authors\":[{\"authorId\":\"9085797\",\"name\":\"Keren Ye\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":\"10.1007/978-3-030-01267-0_51\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e1be2c16060974f66e5366872ebbee21325075e8\",\"title\":\"ADVISE: Symbolism and External Knowledge for Decoding Advertisements\",\"url\":\"https://www.semanticscholar.org/paper/e1be2c16060974f66e5366872ebbee21325075e8\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1604.02748\",\"authors\":[{\"authorId\":\"66508219\",\"name\":\"Y. Li\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"48749954\",\"name\":\"L. Cao\"},{\"authorId\":\"1739099\",\"name\":\"J. Tetreault\"},{\"authorId\":\"39420932\",\"name\":\"L. Goldberg\"},{\"authorId\":\"144633617\",\"name\":\"A. Jaimes\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2016.502\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"05f3f8f6f97db00bafa2efd2ac9aac570603c0c6\",\"title\":\"TGIF: A New Dataset and Benchmark on Animated GIF Description\",\"url\":\"https://www.semanticscholar.org/paper/05f3f8f6f97db00bafa2efd2ac9aac570603c0c6\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2310836\",\"name\":\"Bashar Talafha\"},{\"authorId\":\"1398466553\",\"name\":\"Mahmoud Al-Ayyoub\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4cefd47f3327b6d30bf99e61651b18319c4ee829\",\"title\":\"JUST at VQA-Med: A VGG-Seq2Seq Model\",\"url\":\"https://www.semanticscholar.org/paper/4cefd47f3327b6d30bf99e61651b18319c4ee829\",\"venue\":\"CLEF\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22225752\",\"name\":\"F. Brad\"}],\"doi\":\"10.1109/ICCVW.2019.00560\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f3ede2a4244f7485270d5e155de8cb14d1f88bc2\",\"title\":\"Scene Graph Contextualization in Visual Commonsense Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/f3ede2a4244f7485270d5e155de8cb14d1f88bc2\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1806.01873\",\"authors\":[{\"authorId\":\"1915796\",\"name\":\"Junwei Liang\"},{\"authorId\":\"39978626\",\"name\":\"Lu Jiang\"},{\"authorId\":\"48749954\",\"name\":\"L. Cao\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1109/TPAMI.2018.2890628\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aee265f6a19f9774c65d296cf9ec0e169365dda5\",\"title\":\"Focal Visual-Text Attention for Memex Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/aee265f6a19f9774c65d296cf9ec0e169365dda5\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1620218253\",\"name\":\"Sruthy Manmadhan\"},{\"authorId\":\"30588803\",\"name\":\"Binsu C. Kovoor\"}],\"doi\":\"10.1007/s10462-020-09832-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"667b88984df0c5c11ac07899ffb5509185abdf57\",\"title\":\"Visual question answering: a state-of-the-art review\",\"url\":\"https://www.semanticscholar.org/paper/667b88984df0c5c11ac07899ffb5509185abdf57\",\"venue\":\"Artificial Intelligence Review\",\"year\":2020},{\"arxivId\":\"1505.00468\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-016-0966-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"title\":\"VQA: Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1511.02251\",\"authors\":[{\"authorId\":\"2319608\",\"name\":\"Armand Joulin\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"},{\"authorId\":\"14258597\",\"name\":\"A. Jabri\"},{\"authorId\":\"1800919\",\"name\":\"Nicolas Vasilache\"}],\"doi\":\"10.1007/978-3-319-46478-7_5\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8c30968d96e0c601adaa74db8907fa6ad73bae31\",\"title\":\"Learning Visual Features from Large Weakly Supervised Data\",\"url\":\"https://www.semanticscholar.org/paper/8c30968d96e0c601adaa74db8907fa6ad73bae31\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1803.07616\",\"authors\":[{\"authorId\":\"40895941\",\"name\":\"Ronan Riochet\"},{\"authorId\":\"40901792\",\"name\":\"Mario Ynocente Castro\"},{\"authorId\":\"37831451\",\"name\":\"M. Bernard\"},{\"authorId\":\"1977806\",\"name\":\"A. Lerer\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"3158706\",\"name\":\"V\\u00e9ronique Izard\"},{\"authorId\":\"2202008\",\"name\":\"Emmanuel Dupoux\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"705ab4cd13ea26247fd537150708ee352e06b863\",\"title\":\"IntPhys: A Framework and Benchmark for Visual Intuitive Physics Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/705ab4cd13ea26247fd537150708ee352e06b863\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1704.00260\",\"authors\":[{\"authorId\":\"1911972\",\"name\":\"Tanmay Gupta\"},{\"authorId\":\"143953573\",\"name\":\"K. Shih\"},{\"authorId\":\"37415643\",\"name\":\"S. Singh\"},{\"authorId\":\"2433269\",\"name\":\"Derek Hoiem\"}],\"doi\":\"10.1109/ICCV.2017.452\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d1a73b5516b59fa28f7630da78ed18fb547d777c\",\"title\":\"Aligned Image-Word Representations Improve Inductive Transfer Across Vision-Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/d1a73b5516b59fa28f7630da78ed18fb547d777c\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"2001.08730\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"1490642986\",\"name\":\"Shivansh Pate\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":\"10.1109/WACV45572.2020.9093295\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a487065408c44d387aa1cf7836cd58405f945983\",\"title\":\"Robust Explanations for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a487065408c44d387aa1cf7836cd58405f945983\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40387200\",\"name\":\"S. Yagcioglu\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"},{\"authorId\":\"144738250\",\"name\":\"E. Erdem\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"79cba2b3d3b4289c19e324b0e833c3abeab0325e\",\"title\":\"2 RecipeQA Dataset The Recipe Question Answering ( RecipeQA ) dataset is a challenging multimodal dataset\",\"url\":\"https://www.semanticscholar.org/paper/79cba2b3d3b4289c19e324b0e833c3abeab0325e\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1704.07121\",\"authors\":[{\"authorId\":\"38784892\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"}],\"doi\":\"10.18653/v1/N18-1040\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3374dfe0419cf452d2a60cdd750bdeb6e7433e59\",\"title\":\"Being Negative but Constructively: Lessons Learnt from Creating Better Visual Question Answering Datasets\",\"url\":\"https://www.semanticscholar.org/paper/3374dfe0419cf452d2a60cdd750bdeb6e7433e59\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"42afa9a0166eeb45cb2e9b37e0a8eec482f78fe0\",\"title\":\"Visual Question Answering and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/42afa9a0166eeb45cb2e9b37e0a8eec482f78fe0\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1810.09630\",\"authors\":[{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"345a222fef6f5c1415056319ae7e87a369940d3f\",\"title\":\"A Neural Compositional Paradigm for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/345a222fef6f5c1415056319ae7e87a369940d3f\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"9390267\",\"name\":\"Qifan Yang\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"},{\"authorId\":\"3945955\",\"name\":\"X. He\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.24963/ijcai.2017/492\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a05e84f77e1dacaa1c59ba0d92919bdcfe4debbb\",\"title\":\"Video Question Answering via Hierarchical Spatio-Temporal Attention Networks\",\"url\":\"https://www.semanticscholar.org/paper/a05e84f77e1dacaa1c59ba0d92919bdcfe4debbb\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":\"1809.04344\",\"authors\":[{\"authorId\":\"51228129\",\"name\":\"Shailza Jolly\"},{\"authorId\":\"3422247\",\"name\":\"Sandro Pezzelle\"},{\"authorId\":\"35660331\",\"name\":\"T. Klein\"},{\"authorId\":\"145279674\",\"name\":\"A. Dengel\"},{\"authorId\":\"1848946\",\"name\":\"Moin Nabi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"610e0bee525a6573932e077f091505f54a5c4ede\",\"title\":\"The Wisdom of MaSSeS: Majority, Subjectivity, and Semantic Similarity in the Evaluation of VQA\",\"url\":\"https://www.semanticscholar.org/paper/610e0bee525a6573932e077f091505f54a5c4ede\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2028946\",\"name\":\"D. Gurari\"},{\"authorId\":\"50444302\",\"name\":\"Q. Li\"},{\"authorId\":\"47532530\",\"name\":\"Chi Lin\"},{\"authorId\":\"46317592\",\"name\":\"Y. Zhao\"},{\"authorId\":\"2582404\",\"name\":\"Anhong Guo\"},{\"authorId\":\"46500210\",\"name\":\"Abigale Stangl\"},{\"authorId\":\"1744846\",\"name\":\"Jeffrey P. Bigham\"}],\"doi\":\"10.1109/CVPR.2019.00103\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8dba803240e2cf00d143d4b0a82b95933b5883eb\",\"title\":\"VizWiz-Priv: A Dataset for Recognizing the Presence and Purpose of Private Visual Information in Images Taken by Blind People\",\"url\":\"https://www.semanticscholar.org/paper/8dba803240e2cf00d143d4b0a82b95933b5883eb\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2004.05595\",\"authors\":[{\"authorId\":\"1576818877\",\"name\":\"Kento Terao\"},{\"authorId\":\"47668008\",\"name\":\"T. Tamaki\"},{\"authorId\":\"1688940\",\"name\":\"B. Raytchev\"},{\"authorId\":\"1686272\",\"name\":\"K. Kaneda\"},{\"authorId\":\"49969107\",\"name\":\"S. Satoh\"}],\"doi\":\"10.1109/ACCESS.2020.3022063\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"217d80b1425c24996dafbe539a1e976a1e790ac0\",\"title\":\"Which visual questions are difficult to answer? Analysis with Entropy of Answer Distributions\",\"url\":\"https://www.semanticscholar.org/paper/217d80b1425c24996dafbe539a1e976a1e790ac0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1909.02218\",\"authors\":[{\"authorId\":\"2511637\",\"name\":\"Hongyang Xue\"},{\"authorId\":\"2061528\",\"name\":\"Wenqing Chu\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"}],\"doi\":\"10.1109/TIP.2018.2859820\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"96f0908cc138aceb2d5e0180c440e5adc711d855\",\"title\":\"A Better Way to Attend: Attention With Trees for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/96f0908cc138aceb2d5e0180c440e5adc711d855\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3449429\",\"name\":\"Alexander Kuhnle\"}],\"doi\":\"10.17863/CAM.49177\",\"intent\":[\"methodology\",\"result\"],\"isInfluential\":false,\"paperId\":\"c04262cb3f76ff769af32afad05263bd47ebef18\",\"title\":\"Evaluating visually grounded language capabilities using microworlds\",\"url\":\"https://www.semanticscholar.org/paper/c04262cb3f76ff769af32afad05263bd47ebef18\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144897421\",\"name\":\"Rachel N. Simons\"},{\"authorId\":\"2028946\",\"name\":\"D. Gurari\"},{\"authorId\":\"3079031\",\"name\":\"Kenneth R. Fleischmann\"}],\"doi\":\"10.1145/3415176\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f2d4b8de7f9ed9a1a0b403e9f1ad9365b599c5ad\",\"title\":\"\\\"I Hope This Is Helpful\\\"\",\"url\":\"https://www.semanticscholar.org/paper/f2d4b8de7f9ed9a1a0b403e9f1ad9365b599c5ad\",\"venue\":\"Proc. ACM Hum. Comput. Interact.\",\"year\":2020},{\"arxivId\":\"1605.02697\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":\"10.1007/s11263-017-1038-2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f7ddf708442dad7ed2978658b101c797c7c10220\",\"title\":\"Ask Your Neurons: A Deep Learning Approach to Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f7ddf708442dad7ed2978658b101c797c7c10220\",\"venue\":\"International Journal of Computer Vision\",\"year\":2017},{\"arxivId\":\"2001.03339\",\"authors\":[{\"authorId\":\"6937593\",\"name\":\"Shih-Han Chou\"},{\"authorId\":\"150336480\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"2268189\",\"name\":\"Wei-Sheng Lai\"},{\"authorId\":\"30885811\",\"name\":\"Min Sun\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"8d27640ce75557156de13fb827b64446ef9cc0e4\",\"title\":\"Visual Question Answering on 360{\\\\deg} Images.\",\"url\":\"https://www.semanticscholar.org/paper/8d27640ce75557156de13fb827b64446ef9cc0e4\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1907.13280\",\"authors\":[{\"authorId\":\"2531558\",\"name\":\"G. Chao\"},{\"authorId\":\"2188497\",\"name\":\"Abhinav Rastogi\"},{\"authorId\":\"3014143\",\"name\":\"Semih Yavuz\"},{\"authorId\":\"152325757\",\"name\":\"D. Hakkani-T\\u00fcr\"},{\"authorId\":\"47740493\",\"name\":\"Jindong Chen\"},{\"authorId\":\"5347612\",\"name\":\"I. Lane\"}],\"doi\":\"10.18653/v1/W19-5926\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fb5af7b7d5ebf9e8ff4164233a73b8fe4fe737a3\",\"title\":\"Learning Question-Guided Video Representation for Multi-Turn Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/fb5af7b7d5ebf9e8ff4164233a73b8fe4fe737a3\",\"venue\":\"ViGIL@NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2511637\",\"name\":\"Hongyang Xue\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"}],\"doi\":\"10.1109/TIP.2017.2746267\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1b94c49c119c7490d2df6a2dd093e5ddd8bfba14\",\"title\":\"Unifying the Video and Question Attentions for Open-Ended Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1b94c49c119c7490d2df6a2dd093e5ddd8bfba14\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":\"1601.03896\",\"authors\":[{\"authorId\":\"145040726\",\"name\":\"R. Bernardi\"},{\"authorId\":\"2588033\",\"name\":\"Ruken Cakici\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"},{\"authorId\":\"1398643531\",\"name\":\"N. Ikizler-Cinbis\"},{\"authorId\":\"1393020635\",\"name\":\"F. Keller\"},{\"authorId\":\"35347012\",\"name\":\"A. Muscat\"},{\"authorId\":\"2022124\",\"name\":\"Barbara Plank\"}],\"doi\":\"10.24963/ijcai.2017/704\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6e9aebe54f76d85c6df7e80faa761ef0aec3d54c\",\"title\":\"Automatic Description Generation from Images: A Survey of Models, Datasets, and Evaluation Measures (Extended Abstract)\",\"url\":\"https://www.semanticscholar.org/paper/6e9aebe54f76d85c6df7e80faa761ef0aec3d54c\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":\"1704.04497\",\"authors\":[{\"authorId\":\"2338742\",\"name\":\"Y. Jang\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"49170458\",\"name\":\"Youngjin Kim\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1109/CVPR.2017.149\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b2f521c02c6ed3080c5fe123e938cdf4555e6fd2\",\"title\":\"TGIF-QA: Toward Spatio-Temporal Reasoning in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b2f521c02c6ed3080c5fe123e938cdf4555e6fd2\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145040726\",\"name\":\"R. Bernardi\"},{\"authorId\":\"2588033\",\"name\":\"Ruken Cakici\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"},{\"authorId\":\"1398643531\",\"name\":\"N. Ikizler-Cinbis\"},{\"authorId\":\"1393020635\",\"name\":\"F. Keller\"},{\"authorId\":\"35347012\",\"name\":\"A. Muscat\"},{\"authorId\":\"2022124\",\"name\":\"Barbara Plank\"}],\"doi\":\"10.1613/jair.4900\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c162d791b63682d928c09578bd38c3dd61f78c8c\",\"title\":\"Automatic Description Generation from Images: A Survey of Models, Datasets, and Evaluation Measures\",\"url\":\"https://www.semanticscholar.org/paper/c162d791b63682d928c09578bd38c3dd61f78c8c\",\"venue\":\"J. Artif. Intell. Res.\",\"year\":2016},{\"arxivId\":\"1606.08390\",\"authors\":[{\"authorId\":\"14258597\",\"name\":\"A. Jabri\"},{\"authorId\":\"2319608\",\"name\":\"Armand Joulin\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"}],\"doi\":\"10.1007/978-3-319-46484-8_44\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3c1bbd2672c11a796f1e6e6aa787257498ec8bec\",\"title\":\"Revisiting Visual Question Answering Baselines\",\"url\":\"https://www.semanticscholar.org/paper/3c1bbd2672c11a796f1e6e6aa787257498ec8bec\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1712.05558\",\"authors\":[{\"authorId\":\"2684967\",\"name\":\"J. Kim\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"},{\"authorId\":\"39402399\",\"name\":\"Yuandong Tian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b68773df340498768e88487abe8f7fbac5fcb52d\",\"title\":\"CoDraw: Visual Dialog for Collaborative Drawing\",\"url\":\"https://www.semanticscholar.org/paper/b68773df340498768e88487abe8f7fbac5fcb52d\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41052836\",\"name\":\"Anya Belz\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"}],\"doi\":\"10.1017/S1351324918000086\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d740802aa22dbc187fe5df39108ba493b34d2839\",\"title\":\"From image to language and back again\",\"url\":\"https://www.semanticscholar.org/paper/d740802aa22dbc187fe5df39108ba493b34d2839\",\"venue\":\"Nat. Lang. Eng.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3422247\",\"name\":\"Sandro Pezzelle\"},{\"authorId\":\"152741757\",\"name\":\"C. Greco\"},{\"authorId\":\"32113652\",\"name\":\"G. Gandolfi\"},{\"authorId\":\"2008208159\",\"name\":\"Eleonora Gualdoni\"},{\"authorId\":\"145040726\",\"name\":\"R. Bernardi\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.248\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"caba4881b921c43f4562ed6b6aa8f07b971a6fa2\",\"title\":\"Be Different to Be Better! A Benchmark to Leverage the Complementarity of Language and Vision\",\"url\":\"https://www.semanticscholar.org/paper/caba4881b921c43f4562ed6b6aa8f07b971a6fa2\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"7595427\",\"name\":\"Tejas Khot\"},{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1007/s11263-018-1116-0\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7e232313a59d735ef7c8a9f4cc7bc980a29deb5e\",\"title\":\"Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7e232313a59d735ef7c8a9f4cc7bc980a29deb5e\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018},{\"arxivId\":\"1701.02870\",\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1732280\",\"name\":\"Gal Chechik\"}],\"doi\":\"10.1109/CVPR.2017.120\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e782437503f2a24fd1a836a434da395bf15c88c2\",\"title\":\"Context-Aware Captions from Context-Agnostic Supervision\",\"url\":\"https://www.semanticscholar.org/paper/e782437503f2a24fd1a836a434da395bf15c88c2\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2338742\",\"name\":\"Y. Jang\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"32821535\",\"name\":\"C. D. Kim\"},{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"49170458\",\"name\":\"Youngjin Kim\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1007/s11263-019-01189-x\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1e1bd132613866c176a8fc780cb1b9f9aa43feeb\",\"title\":\"Video Question Answering with Spatio-Temporal Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/1e1bd132613866c176a8fc780cb1b9f9aa43feeb\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"1904.02794\",\"authors\":[{\"authorId\":\"47309247\",\"name\":\"Manoj Acharya\"},{\"authorId\":\"93155387\",\"name\":\"Karan Jariwala\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.18653/v1/N19-1194\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f17f7590a6b4488921f046112bc8fdb82d513914\",\"title\":\"VQD: Visual Query Detection in Natural Scenes\",\"url\":\"https://www.semanticscholar.org/paper/f17f7590a6b4488921f046112bc8fdb82d513914\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":\"1711.10185\",\"authors\":[{\"authorId\":\"2179435\",\"name\":\"G. Montone\"},{\"authorId\":\"1398984373\",\"name\":\"J. O'Regan\"},{\"authorId\":\"1814884\",\"name\":\"A. V. Terekhov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"004dc8de3a6832c8d4764144570dc122b5265ec5\",\"title\":\"Hyper-dimensional computing for a visual question-answering system that is trainable end-to-end\",\"url\":\"https://www.semanticscholar.org/paper/004dc8de3a6832c8d4764144570dc122b5265ec5\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1904.11574\",\"authors\":[{\"authorId\":\"46665218\",\"name\":\"Jie Lei\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/2020.acl-main.730\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb1b368ca847846774ee41af6da906ab77013313\",\"title\":\"TVQA+: Spatio-Temporal Grounding for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/eb1b368ca847846774ee41af6da906ab77013313\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"1611.02145\",\"authors\":[{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"},{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1561/0600000073\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"84c95a8db377c25d4280f188e9477569ab57281b\",\"title\":\"Crowdsourcing in Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/84c95a8db377c25d4280f188e9477569ab57281b\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2862582\",\"name\":\"Peratham Wiriyathammabhum\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"1759899\",\"name\":\"C. Ferm\\u00fcller\"},{\"authorId\":\"1697493\",\"name\":\"Y. Aloimonos\"}],\"doi\":\"10.1145/3009906\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6e60536c847ac25dba4c1c071e0355e5537fe061\",\"title\":\"Computer Vision and Natural Language Processing\",\"url\":\"https://www.semanticscholar.org/paper/6e60536c847ac25dba4c1c071e0355e5537fe061\",\"venue\":\"ACM Comput. Surv.\",\"year\":2017},{\"arxivId\":\"2001.08779\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"50975843\",\"name\":\"Vinod K. Kurmi\"},{\"authorId\":null,\"name\":\"Sandeep Kumar\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":\"10.1109/WACV45572.2020.9093293\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8e4720942ff8b02d2822aea5d024628139551723\",\"title\":\"Deep Bayesian Network for Visual Question Generation\",\"url\":\"https://www.semanticscholar.org/paper/8e4720942ff8b02d2822aea5d024628139551723\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1510.08973\",\"authors\":[{\"authorId\":\"3253737\",\"name\":\"F. Sadeghi\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8eac065bece185d4b16ce2f885da0e56d4d3474d\",\"title\":\"Visalogy: Answering Visual Analogy Questions\",\"url\":\"https://www.semanticscholar.org/paper/8eac065bece185d4b16ce2f885da0e56d4d3474d\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1809.01124\",\"authors\":[{\"authorId\":\"153137839\",\"name\":\"M. Narasimhan\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1007/978-3-030-01237-3_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d88eb94d7054d2668b1a8dfa311721f37ae1f059\",\"title\":\"Straight to the Facts: Learning Knowledge Base Retrieval for Factual Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d88eb94d7054d2668b1a8dfa311721f37ae1f059\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1603.07141\",\"authors\":[{\"authorId\":\"1780343\",\"name\":\"Arnau Ramisa\"},{\"authorId\":\"144535340\",\"name\":\"Fei Yan\"},{\"authorId\":\"1397181875\",\"name\":\"F. Moreno-Noguer\"},{\"authorId\":\"1712041\",\"name\":\"K. Mikolajczyk\"}],\"doi\":\"10.1109/TPAMI.2017.2721945\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"82d9b588eabeb6bf4baa945d5c71b3bf89dd1e69\",\"title\":\"BreakingNews: Article Annotation by Image and Text Processing\",\"url\":\"https://www.semanticscholar.org/paper/82d9b588eabeb6bf4baa945d5c71b3bf89dd1e69\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2588850\",\"name\":\"Nabil Hossain\"},{\"authorId\":\"143688670\",\"name\":\"J. Krumm\"},{\"authorId\":\"1909300\",\"name\":\"Lucy Vanderwende\"},{\"authorId\":\"145479841\",\"name\":\"E. Horvitz\"},{\"authorId\":\"1690271\",\"name\":\"Henry A. Kautz\"}],\"doi\":\"10.18653/v1/D17-1067\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ea05486f4c7069937b904af0f049a547f779b769\",\"title\":\"Filling the Blanks (hint: plural noun) for Mad Libs Humor\",\"url\":\"https://www.semanticscholar.org/paper/ea05486f4c7069937b904af0f049a547f779b769\",\"venue\":\"EMNLP\",\"year\":2017},{\"arxivId\":\"1911.03977\",\"authors\":[{\"authorId\":\"145282222\",\"name\":\"C. Zhang\"},{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"144718783\",\"name\":\"Li Deng\"}],\"doi\":\"10.1109/JSTSP.2020.2987728\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"415efb7b4d9d1e5b64dbaf3fe4229ad462acce71\",\"title\":\"Multimodal Intelligence: Representation Learning, Information Fusion, and Applications\",\"url\":\"https://www.semanticscholar.org/paper/415efb7b4d9d1e5b64dbaf3fe4229ad462acce71\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390626344\",\"name\":\"Zhiyuan Liu\"},{\"authorId\":\"2427350\",\"name\":\"Yankai Lin\"},{\"authorId\":\"1753344\",\"name\":\"M. Sun\"}],\"doi\":\"10.1007/978-981-15-5573-2_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7cd0c93b77bd2cf085c02c7a98118b6b43592110\",\"title\":\"Cross-Modal Representation\",\"url\":\"https://www.semanticscholar.org/paper/7cd0c93b77bd2cf085c02c7a98118b6b43592110\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1809.03707\",\"authors\":[{\"authorId\":\"51929143\",\"name\":\"M. Wagner\"},{\"authorId\":\"7005920\",\"name\":\"H. Basevi\"},{\"authorId\":\"38314306\",\"name\":\"Rakshith Shetty\"},{\"authorId\":\"39956342\",\"name\":\"Wenbin Li\"},{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"},{\"authorId\":\"1732672\",\"name\":\"A. Leonardis\"}],\"doi\":\"10.1007/978-3-030-11009-3_32\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"918f122b385c5de709d076063527e850c2666c78\",\"title\":\"Answering Visual What-If Questions: From Actions to Predicted Scene Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/918f122b385c5de709d076063527e850c2666c78\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"1612.00837\",\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"7595427\",\"name\":\"Tejas Khot\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2017.670\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"title\":\"Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48985840\",\"name\":\"Tianyi Hao\"},{\"authorId\":\"2349295\",\"name\":\"Longbo Huang\"}],\"doi\":\"10.24963/ijcai.2018/527\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"913a677f5c8ed1d5b0bfc72985e5247f387379de\",\"title\":\"A Social Interaction Activity based Time-Varying User Vectorization Method for Online Social Networks\",\"url\":\"https://www.semanticscholar.org/paper/913a677f5c8ed1d5b0bfc72985e5247f387379de\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/ICCV.2015.279\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"784da2a7b53a16d2243f747e14946cc5e3476af0\",\"title\":\"VQA: Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/784da2a7b53a16d2243f747e14946cc5e3476af0\",\"venue\":\"ICCV\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6937593\",\"name\":\"Shih-Han Chou\"},{\"authorId\":\"150336480\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"38784892\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"30885811\",\"name\":\"Min Sun\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/WACV45572.2020.9093452\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"0e0c5d868d84908bb7a26c27c1aedea43fdc493d\",\"title\":\"Visual Question Answering on 360\\u00b0 Images\",\"url\":\"https://www.semanticscholar.org/paper/0e0c5d868d84908bb7a26c27c1aedea43fdc493d\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1806.00186\",\"authors\":[{\"authorId\":\"50978260\",\"name\":\"Nayyer Aafaq\"},{\"authorId\":\"1746166\",\"name\":\"Syed Zulqarnain Gilani\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"46332747\",\"name\":\"A. Mian\"}],\"doi\":\"10.1145/3355390\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"665a5673d33a90a1b71c0d5b1be127a76af43be7\",\"title\":\"Video Description\",\"url\":\"https://www.semanticscholar.org/paper/665a5673d33a90a1b71c0d5b1be127a76af43be7\",\"venue\":\"ACM Comput. Surv.\",\"year\":2020}],\"corpusId\":7142199,\"doi\":\"10.1109/ICCV.2015.283\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":7,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"ced9f7178f8032d3408fcba493c02eb48e8a8636\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"145297531\",\"name\":\"A. Lai\"},{\"authorId\":\"2170746\",\"name\":\"M. Hodosh\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"}],\"doi\":\"10.1162/tacl_a_00166\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"44040913380206991b1991daf1192942e038fe31\",\"title\":\"From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions\",\"url\":\"https://www.semanticscholar.org/paper/44040913380206991b1991daf1192942e038fe31\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2014},{\"arxivId\":\"1411.2539\",\"authors\":[{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2e36ea91a3c8fbff92be2989325531b4002e2afc\",\"title\":\"Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models\",\"url\":\"https://www.semanticscholar.org/paper/2e36ea91a3c8fbff92be2989325531b4002e2afc\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1707642\",\"name\":\"D. Geman\"},{\"authorId\":\"3194361\",\"name\":\"S. Geman\"},{\"authorId\":\"9588317\",\"name\":\"Neil Hallonquist\"},{\"authorId\":\"1721284\",\"name\":\"L. Younes\"}],\"doi\":\"10.1073/pnas.1422953112\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"050da5d159fb0dd96143948e1cffeb3dec814673\",\"title\":\"Visual Turing test for computer vision systems\",\"url\":\"https://www.semanticscholar.org/paper/050da5d159fb0dd96143948e1cffeb3dec814673\",\"venue\":\"Proceedings of the National Academy of Sciences\",\"year\":2015},{\"arxivId\":\"1406.3676\",\"authors\":[{\"authorId\":\"1713934\",\"name\":\"Antoine Bordes\"},{\"authorId\":\"3295092\",\"name\":\"S. Chopra\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":\"10.3115/v1/D14-1067\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"33261d252218007147a71e40f8367ed152fa2fe0\",\"title\":\"Question Answering with Subgraph Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/33261d252218007147a71e40f8367ed152fa2fe0\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"145564333\",\"name\":\"G. Kulkarni\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8e080b98efbe65c02a116439205ca2344b9f7cd4\",\"title\":\"Im2Text: Describing Images Using 1 Million Captioned Photographs\",\"url\":\"https://www.semanticscholar.org/paper/8e080b98efbe65c02a116439205ca2344b9f7cd4\",\"venue\":\"NIPS\",\"year\":2011},{\"arxivId\":\"1411.4952\",\"authors\":[{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3346186\",\"name\":\"Forrest N. Iandola\"},{\"authorId\":\"2100612\",\"name\":\"R. Srivastava\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"144189092\",\"name\":\"John C. Platt\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"}],\"doi\":\"10.1109/CVPR.2015.7298754\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"title\":\"From captions to visual concepts and back\",\"url\":\"https://www.semanticscholar.org/paper/15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1410.0210\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ac64fb7e6d2ddf236332ec9f371fe85d308c114d\",\"title\":\"A Multi-World Approach to Question Answering about Real-World Scenes based on Uncertain Input\",\"url\":\"https://www.semanticscholar.org/paper/ac64fb7e6d2ddf236332ec9f371fe85d308c114d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144747622\",\"name\":\"R. Mason\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"47cf8f38981564571f4d6a394e580abd2fd4ea43\",\"title\":\"Domain-Independent Captioning of Domain-Specific Images\",\"url\":\"https://www.semanticscholar.org/paper/47cf8f38981564571f4d6a394e580abd2fd4ea43\",\"venue\":\"HLT-NAACL\",\"year\":2013},{\"arxivId\":\"1103.0398\",\"authors\":[{\"authorId\":\"2939803\",\"name\":\"Ronan Collobert\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"},{\"authorId\":\"52184096\",\"name\":\"L. Bottou\"},{\"authorId\":\"21432929\",\"name\":\"Michael Karlen\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"},{\"authorId\":\"46283650\",\"name\":\"P. Kuksa\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bc1022b031dc6c7019696492e8116598097a8c12\",\"title\":\"Natural Language Processing (Almost) from Scratch\",\"url\":\"https://www.semanticscholar.org/paper/bc1022b031dc6c7019696492e8116598097a8c12\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2011},{\"arxivId\":\"1503.08895\",\"authors\":[{\"authorId\":\"2265067\",\"name\":\"Sainbayar Sukhbaatar\"},{\"authorId\":\"3149531\",\"name\":\"Arthur Szlam\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a583af2696030bcf5f556edc74573fbee902be0b\",\"title\":\"Weakly Supervised Memory Networks\",\"url\":\"https://www.semanticscholar.org/paper/a583af2696030bcf5f556edc74573fbee902be0b\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"V. Ordonez\"},{\"authorId\":null,\"name\":\"G. Kulkarni\"},{\"authorId\":null,\"name\":\"L. T.\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Berg . Im 2 text : Describing images using 1 million captioned photographs\",\"url\":\"\",\"venue\":\"\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":\"1411.5726\",\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2015.7299087\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"258986132bf17755fe8263e42429fe73218c1534\",\"title\":\"CIDEr: Consensus-based image description evaluation\",\"url\":\"https://www.semanticscholar.org/paper/258986132bf17755fe8263e42429fe73218c1534\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145564333\",\"name\":\"G. Kulkarni\"},{\"authorId\":\"3128210\",\"name\":\"Visruth Premraj\"},{\"authorId\":\"2985883\",\"name\":\"Sagnik Dhar\"},{\"authorId\":\"50341924\",\"name\":\"Siming Li\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6e6f47c4b2109e7824cd475336c3676faf9b113e\",\"title\":\"Baby Talk : Understanding and Generating Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/6e6f47c4b2109e7824cd475336c3676faf9b113e\",\"venue\":\"\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"2677488\",\"name\":\"\\u00c0gata Lapedriza\"},{\"authorId\":\"40599257\",\"name\":\"J. Xiao\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9667f8264745b626c6173b1310e2ff0298b09cfc\",\"title\":\"Learning Deep Features for Scene Recognition using Places Database\",\"url\":\"https://www.semanticscholar.org/paper/9667f8264745b626c6173b1310e2ff0298b09cfc\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"34176020\",\"name\":\"Jesse Dodge\"},{\"authorId\":\"46479604\",\"name\":\"Amit Goyal\"},{\"authorId\":\"1721910\",\"name\":\"Kota Yamaguchi\"},{\"authorId\":\"1714215\",\"name\":\"K. Stratos\"},{\"authorId\":\"1682965\",\"name\":\"Xufeng Han\"},{\"authorId\":\"40614240\",\"name\":\"A. Mensch\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1722360\",\"name\":\"Hal Daum\\u00e9\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"355de7460120ddc1150d9ce3756f9848983f7ff4\",\"title\":\"Midge: Generating Image Descriptions From Computer Vision Detections\",\"url\":\"https://www.semanticscholar.org/paper/355de7460120ddc1150d9ce3756f9848983f7ff4\",\"venue\":\"EACL\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1888731\",\"name\":\"M. Hejrati\"},{\"authorId\":\"21160985\",\"name\":\"M. Sadeghi\"},{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"3125805\",\"name\":\"Cyrus Rashtchian\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"144016256\",\"name\":\"D. Forsyth\"}],\"doi\":\"10.1007/978-3-642-15561-1_2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eaaed23a2d94feb2f1c3ff22a25777c7a78f3141\",\"title\":\"Every Picture Tells a Story: Generating Sentences from Images\",\"url\":\"https://www.semanticscholar.org/paper/eaaed23a2d94feb2f1c3ff22a25777c7a78f3141\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":\"1212.4522\",\"authors\":[{\"authorId\":\"5115386\",\"name\":\"Yunchao Gong\"},{\"authorId\":\"2259786\",\"name\":\"Q. Ke\"},{\"authorId\":\"2090818\",\"name\":\"M. Isard\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1007/s11263-013-0658-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7fceccc7a1046caa4936b14eeacb71ccf4d6be10\",\"title\":\"A Multi-View Embedding Space for Modeling Internet Images, Tags, and Their Semantics\",\"url\":\"https://www.semanticscholar.org/paper/7fceccc7a1046caa4936b14eeacb71ccf4d6be10\",\"venue\":\"International Journal of Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1722360\",\"name\":\"Hal Daum\\u00e9\"},{\"authorId\":\"34176020\",\"name\":\"Jesse Dodge\"},{\"authorId\":\"46479604\",\"name\":\"Amit Goyal\"},{\"authorId\":\"1682965\",\"name\":\"Xufeng Han\"},{\"authorId\":\"40614240\",\"name\":\"A. Mensch\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"2212748\",\"name\":\"Aneesh Sood\"},{\"authorId\":\"1714215\",\"name\":\"K. Stratos\"},{\"authorId\":\"1721910\",\"name\":\"Kota Yamaguchi\"}],\"doi\":\"10.1109/CVPR.2012.6248100\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5ce04063ecf83a6584813e1a09fb3d81642e5790\",\"title\":\"Understanding and predicting importance in images\",\"url\":\"https://www.semanticscholar.org/paper/5ce04063ecf83a6584813e1a09fb3d81642e5790\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"1756655\",\"name\":\"C. L. Teo\"},{\"authorId\":\"1722360\",\"name\":\"Hal Daum\\u00e9\"},{\"authorId\":\"1697493\",\"name\":\"Y. Aloimonos\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"76a1dca3a9c2b0229c1b12c95752dcf40dc95a11\",\"title\":\"Corpus-Guided Sentence Generation of Natural Images\",\"url\":\"https://www.semanticscholar.org/paper/76a1dca3a9c2b0229c1b12c95752dcf40dc95a11\",\"venue\":\"EMNLP\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"P. O. Lebret Remi\"},{\"authorId\":null,\"name\":\"Pinheiro\"},{\"authorId\":null,\"name\":\"R. Collobert\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Phrase-based captioning\",\"url\":\"\",\"venue\":\"In ICML,\",\"year\":2015},{\"arxivId\":\"1301.3781\",\"authors\":[{\"authorId\":null,\"name\":\"Tomas Mikolov\"},{\"authorId\":\"38644044\",\"name\":\"Kai Chen\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"330da625c15427c6e42ccfa3b747fb29e5835bf0\",\"title\":\"Efficient Estimation of Word Representations in Vector Space\",\"url\":\"https://www.semanticscholar.org/paper/330da625c15427c6e42ccfa3b747fb29e5835bf0\",\"venue\":\"ICLR\",\"year\":2013},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1311.2524\",\"authors\":[{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"153652146\",\"name\":\"J. Malik\"}],\"doi\":\"10.1109/CVPR.2014.81\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2f4df08d9072fc2ac181b7fced6a245315ce05c8\",\"title\":\"Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/2f4df08d9072fc2ac181b7fced6a245315ce05c8\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2015.7298932\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"title\":\"Deep visual-semantic alignments for generating image descriptions\",\"url\":\"https://www.semanticscholar.org/paper/ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"venue\":\"CVPR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2241127\",\"name\":\"Marie-Catherine de Marneffe\"},{\"authorId\":\"3257930\",\"name\":\"Bill MacCartney\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3cc228402f31ca749112197720b9ef6af0c16790\",\"title\":\"Generating Typed Dependency Parses from Phrase Structure Parses\",\"url\":\"https://www.semanticscholar.org/paper/3cc228402f31ca749112197720b9ef6af0c16790\",\"venue\":\"LREC\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1109/CVPR.2015.7298856\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a72b8bbd039989db39769da836cdb287737deb92\",\"title\":\"Mind's eye: A recurrent visual representation for image caption generation\",\"url\":\"https://www.semanticscholar.org/paper/a72b8bbd039989db39769da836cdb287737deb92\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3125805\",\"name\":\"Cyrus Rashtchian\"},{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"2170746\",\"name\":\"M. Hodosh\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"bf60322f83714523e2d7c1d39983151fe9db7146\",\"title\":\"Collecting Image Annotations Using Amazon's Mechanical Turk\",\"url\":\"https://www.semanticscholar.org/paper/bf60322f83714523e2d7c1d39983151fe9db7146\",\"venue\":\"Mturk@HLT-NAACL\",\"year\":2010},{\"arxivId\":\"1404.4326\",\"authors\":[{\"authorId\":\"1713934\",\"name\":\"Antoine Bordes\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"},{\"authorId\":\"1746841\",\"name\":\"Nicolas Usunier\"}],\"doi\":\"10.1007/978-3-662-44848-9_11\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a584211768d49f80192f13b8ed2fda9c058dec34\",\"title\":\"Open Question Answering with Weakly Supervised Embedding Models\",\"url\":\"https://www.semanticscholar.org/paper/a584211768d49f80192f13b8ed2fda9c058dec34\",\"venue\":\"ECML/PKDD\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145970060\",\"name\":\"A. Aker\"},{\"authorId\":\"1718590\",\"name\":\"R. Gaizauskas\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e8dbc756ea246f599250c09e3efd9bba9909a842\",\"title\":\"Generating Image Descriptions Using Dependency Relational Patterns\",\"url\":\"https://www.semanticscholar.org/paper/e8dbc756ea246f599250c09e3efd9bba9909a842\",\"venue\":\"ACL\",\"year\":2010},{\"arxivId\":\"1502.06108\",\"authors\":[{\"authorId\":\"9136919\",\"name\":\"X. Lin\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2015.7298917\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e0cff50a6ce27a8cb2b26ca586dea8a0b7cd67bd\",\"title\":\"Don't just listen, use your imagination: Leveraging visual common sense for non-visual tasks\",\"url\":\"https://www.semanticscholar.org/paper/e0cff50a6ce27a8cb2b26ca586dea8a0b7cd67bd\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145592791\",\"name\":\"P. Kuznetsova\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2a0d0f6c5a69b264710df0230696f47c5918e2f2\",\"title\":\"Collective Generation of Natural Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/2a0d0f6c5a69b264710df0230696f47c5918e2f2\",\"venue\":\"ACL\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145564333\",\"name\":\"G. Kulkarni\"},{\"authorId\":\"3128210\",\"name\":\"Visruth Premraj\"},{\"authorId\":\"2985883\",\"name\":\"Sagnik Dhar\"},{\"authorId\":\"50341924\",\"name\":\"Siming Li\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/CVPR.2011.5995466\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"169b847e69c35cfd475eb4dcc561a24de11762ca\",\"title\":\"Baby talk: Understanding and generating simple image descriptions\",\"url\":\"https://www.semanticscholar.org/paper/169b847e69c35cfd475eb4dcc561a24de11762ca\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50536468\",\"name\":\"Danqi Chen\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.3115/v1/D14-1082\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a14045a751f5d8ed387c8630a86a3a2861b90643\",\"title\":\"A Fast and Accurate Dependency Parser using Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/a14045a751f5d8ed387c8630a86a3a2861b90643\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"P O Lebret Remi\"},{\"authorId\":null,\"name\":\"Pinheiro\"},{\"authorId\":null,\"name\":\"R Collobert\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Phrase-based captioning\",\"url\":\"\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52014393\",\"name\":\"Ut Austin\"},{\"authorId\":\"123312980\",\"name\":\"Austin\"},{\"authorId\":\"102704114\",\"name\":\"UMass Lowell\"},{\"authorId\":\"102898595\",\"name\":\"Lowell\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"43795b7bac3d921c4e579964b54187bdbf6c6330\",\"title\":\"Translating Videos to Natural Language Using Deep Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/43795b7bac3d921c4e579964b54187bdbf6c6330\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1717629\",\"name\":\"Yansong Feng\"},{\"authorId\":\"1747893\",\"name\":\"Mirella Lapata\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"60be767a255fd13f73ed4e64d9901b30cf6081e8\",\"title\":\"Topic Models for Image Annotation and Text Illustration\",\"url\":\"https://www.semanticscholar.org/paper/60be767a255fd13f73ed4e64d9901b30cf6081e8\",\"venue\":\"HLT-NAACL\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3006928\",\"name\":\"N. Krishnamoorthy\"},{\"authorId\":\"3163967\",\"name\":\"Girish Malkarnenkar\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3b9f8101c61b415f946625b69f69fc9e3d0d6fc4\",\"title\":\"Generating Natural-Language Video Descriptions Using Text-Mined Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/3b9f8101c61b415f946625b69f69fc9e3d0d6fc4\",\"venue\":\"AAAI\",\"year\":2013}],\"title\":\"Visual Madlibs: Fill in the Blank Description Generation and Question Answering\",\"topics\":[{\"topic\":\"Question answering\",\"topicId\":\"18817\",\"url\":\"https://www.semanticscholar.org/topic/18817\"},{\"topic\":\"Natural language\",\"topicId\":\"1911\",\"url\":\"https://www.semanticscholar.org/topic/1911\"},{\"topic\":\"Microsoft Research\",\"topicId\":\"73897\",\"url\":\"https://www.semanticscholar.org/topic/73897\"},{\"topic\":\"Deep learning\",\"topicId\":\"2762\",\"url\":\"https://www.semanticscholar.org/topic/2762\"},{\"topic\":\"Interaction\",\"topicId\":\"72\",\"url\":\"https://www.semanticscholar.org/topic/72\"},{\"topic\":\"IBM Notes\",\"topicId\":\"82564\",\"url\":\"https://www.semanticscholar.org/topic/82564\"}],\"url\":\"https://www.semanticscholar.org/paper/ced9f7178f8032d3408fcba493c02eb48e8a8636\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015}\n"