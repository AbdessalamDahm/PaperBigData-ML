"{\"abstract\":\"In the past decades, hundreds of saliency models have been proposed for fixation prediction, along with dozens of evaluation metrics. However, existing metrics, which are often heuristically designed, may draw conflict conclusions in comparing saliency models. As a consequence, it becomes somehow confusing on the selection of metrics in comparing new models with state-of-the-arts. To address this problem, we propose a data-driven metric for comprehensive evaluation of saliency models. Instead of heuristically designing such a metric, we first conduct extensive subjective tests to find how saliency maps are assessed by the human-being. Based on the user data collected in the tests, nine representative evaluation metrics are directly compared by quantizing their performances in assessing saliency maps. Moreover, we propose to learn a data-driven metric by using Convolutional Neural Network. Compared with existing metrics, experimental results show that the data-driven metric performs the most consistently with the human-being in evaluating saliency maps as well as saliency models.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"145519708\",\"name\":\"J. Li\",\"url\":\"https://www.semanticscholar.org/author/145519708\"},{\"authorId\":\"2749565\",\"name\":\"Changqun Xia\",\"url\":\"https://www.semanticscholar.org/author/2749565\"},{\"authorId\":\"2839196\",\"name\":\"Yafei Song\",\"url\":\"https://www.semanticscholar.org/author/2839196\"},{\"authorId\":\"145021810\",\"name\":\"Shu Fang\",\"url\":\"https://www.semanticscholar.org/author/145021810\"},{\"authorId\":\"33610144\",\"name\":\"X. Chen\",\"url\":\"https://www.semanticscholar.org/author/33610144\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":\"1710.10755\",\"authors\":[{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"3383051\",\"name\":\"Yuhang Song\"},{\"authorId\":\"49606288\",\"name\":\"Jianyi Wang\"},{\"authorId\":\"27647516\",\"name\":\"Minglang Qiao\"},{\"authorId\":\"27661057\",\"name\":\"Liangyu Huo\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"}],\"doi\":\"10.1109/TPAMI.2018.2858783\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"27bf4a794a535994e43c2eb41b81b6795bcddfd0\",\"title\":\"Predicting Head Movement in Panoramic Video: A Deep Reinforcement Learning Approach\",\"url\":\"https://www.semanticscholar.org/paper/27bf4a794a535994e43c2eb41b81b6795bcddfd0\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3383051\",\"name\":\"Yuhang Song\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"27647516\",\"name\":\"Minglang Qiao\"},{\"authorId\":\"49606288\",\"name\":\"Jianyi Wang\"},{\"authorId\":\"27661057\",\"name\":\"Liangyu Huo\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6c67a441e1ebaa3773bb7734a7eb1690236f81a6\",\"title\":\"Modeling Attention in Panoramic Video: A Deep Reinforcement Learning Approach\",\"url\":\"https://www.semanticscholar.org/paper/6c67a441e1ebaa3773bb7734a7eb1690236f81a6\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33719665\",\"name\":\"Saulo A. F. Oliveira\"},{\"authorId\":\"9376074\",\"name\":\"S. S. Alves\"},{\"authorId\":\"40665068\",\"name\":\"J. P. Gomes\"},{\"authorId\":\"2269331\",\"name\":\"A. R. Neto\"}],\"doi\":\"10.1016/j.cviu.2017.11.011\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"781d28eaeb8d514ac015d0516a9340ba84ac0f40\",\"title\":\"A bi-directional evaluation-based approach for image retargeting quality assessment\",\"url\":\"https://www.semanticscholar.org/paper/781d28eaeb8d514ac015d0516a9340ba84ac0f40\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"40144368\",\"name\":\"Chen Li\"},{\"authorId\":\"1737311\",\"name\":\"Yufan Liu\"},{\"authorId\":\"144325130\",\"name\":\"X. Deng\"},{\"authorId\":\"2892103\",\"name\":\"Jiaxin Lu\"}],\"doi\":\"10.1109/ICME.2017.8019351\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"93942f3533eafff75b4ca66e0de360df4e86bcab\",\"title\":\"A subjective visual quality assessment method of panoramic videos\",\"url\":\"https://www.semanticscholar.org/paper/93942f3533eafff75b4ca66e0de360df4e86bcab\",\"venue\":\"2017 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2637872\",\"name\":\"Y. Niu\"},{\"authorId\":\"73708454\",\"name\":\"J. Chen\"},{\"authorId\":\"145672212\",\"name\":\"Xiao Ke\"},{\"authorId\":\"47740854\",\"name\":\"J. Chen\"}],\"doi\":\"10.1109/ACCESS.2019.2897404\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e81e1edf77c00e11976d0026b3966c62cf4978c6\",\"title\":\"Stereoscopic Image Saliency Detection Optimization: A Multi-Cue-Driven Approach\",\"url\":\"https://www.semanticscholar.org/paper/e81e1edf77c00e11976d0026b3966c62cf4978c6\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1967201\",\"name\":\"Kui Fu\"},{\"authorId\":null,\"name\":\"Jia Li\"},{\"authorId\":\"121194391\",\"name\":\"Hongze Shen\"},{\"authorId\":\"144051792\",\"name\":\"Yonghong Tian\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"737ca6dd41d8bc4f3ce06161bc2e3050a37b050a\",\"title\":\"How Drones Look: Crowdsourced Knowledge Transfer for Aerial Video Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/737ca6dd41d8bc4f3ce06161bc2e3050a37b050a\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1904.04449\",\"authors\":[{\"authorId\":\"1967201\",\"name\":\"Kui Fu\"},{\"authorId\":null,\"name\":\"Jia Li\"},{\"authorId\":\"2839196\",\"name\":\"Yafei Song\"},{\"authorId\":\"39076047\",\"name\":\"Y. Zhang\"},{\"authorId\":\"39646508\",\"name\":\"Shiming Ge\"},{\"authorId\":\"144051792\",\"name\":\"Yonghong Tian\"}],\"doi\":\"10.1609/AAAI.V34I07.6710\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1b995069e1930fd9a2d87fb35fc4d9b3632cb82d\",\"title\":\"Ultrafast Video Attention Prediction with Coupled Knowledge Distillation\",\"url\":\"https://www.semanticscholar.org/paper/1b995069e1930fd9a2d87fb35fc4d9b3632cb82d\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33719665\",\"name\":\"Saulo A. F. Oliveira\"},{\"authorId\":\"2269331\",\"name\":\"A. R. Neto\"},{\"authorId\":\"144227442\",\"name\":\"J. Gomes\"}],\"doi\":\"10.1109/BRACIS.2016.077\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4be46e79aa958b2fde0948488084c48cb8a9b6c6\",\"title\":\"Towards Fixation Prediction: A Nonparametric Estimation-Based Approach through Key-Points\",\"url\":\"https://www.semanticscholar.org/paper/4be46e79aa958b2fde0948488084c48cb8a9b6c6\",\"venue\":\"2016 5th Brazilian Conference on Intelligent Systems (BRACIS)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2190047\",\"name\":\"G. Leifman\"},{\"authorId\":\"2401277\",\"name\":\"Elizabeth Shtrom\"},{\"authorId\":\"3226509\",\"name\":\"A. Tal\"}],\"doi\":\"10.1109/CVPR.2012.6247703\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"65dc75918d6476051604a96a138216ea04e2026d\",\"title\":\"Surface Regions of Interest for Viewpoint Selection\",\"url\":\"https://www.semanticscholar.org/paper/65dc75918d6476051604a96a138216ea04e2026d\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2016},{\"arxivId\":\"1806.10257\",\"authors\":[{\"authorId\":\"2749565\",\"name\":\"Changqun Xia\"},{\"authorId\":\"46275685\",\"name\":\"Jia Li\"},{\"authorId\":\"5349760\",\"name\":\"Jinming Su\"},{\"authorId\":\"3177797\",\"name\":\"Ali Borji\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c5d08cf523115ec8a3c656f1435291d0fb0cfa73\",\"title\":\"Learning a Saliency Evaluation Metric Using Crowdsourced Perceptual Judgments\",\"url\":\"https://www.semanticscholar.org/paper/c5d08cf523115ec8a3c656f1435291d0fb0cfa73\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"145076397\",\"name\":\"Yun Ren\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"},{\"authorId\":\"8189996\",\"name\":\"Jingxian Liu\"},{\"authorId\":\"144978572\",\"name\":\"X. Tao\"}],\"doi\":\"10.1109/TMM.2017.2767784\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5ecacb98ac7e2ad9d28f6bc20d7bb449b888afe9\",\"title\":\"Saliency Detection in Face Videos: A Data-Driven Approach\",\"url\":\"https://www.semanticscholar.org/paper/5ecacb98ac7e2ad9d28f6bc20d7bb449b888afe9\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33101489\",\"name\":\"Arindam Bhakta\"},{\"authorId\":\"1923642\",\"name\":\"C. Hollitt\"},{\"authorId\":\"2309030\",\"name\":\"W. Browne\"},{\"authorId\":\"40073871\",\"name\":\"M. Frean\"}],\"doi\":\"10.1007/S10514-018-9752-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"45616a381365a349f0044ef05a2c87b2159afa04\",\"title\":\"Utility function generated saccade strategies for robot active vision: a probabilistic approach\",\"url\":\"https://www.semanticscholar.org/paper/45616a381365a349f0044ef05a2c87b2159afa04\",\"venue\":\"Auton. Robots\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33101489\",\"name\":\"Arindam Bhakta\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"40de29a2815ce13c123043915010c59f6ba6b08d\",\"title\":\"Epistemic guidance of visual attention for robotic agents in dynamic visual scenes\",\"url\":\"https://www.semanticscholar.org/paper/40de29a2815ce13c123043915010c59f6ba6b08d\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743773\",\"name\":\"Mai Xu\"},{\"authorId\":\"39923487\",\"name\":\"Chen Li\"},{\"authorId\":\"1754571\",\"name\":\"Zulin Wang\"},{\"authorId\":\"1724811\",\"name\":\"Zhenzhong Chen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5814f82c6d65071e1b28875258a48ea3905206fa\",\"title\":\"Visual Quality Assessment of Panoramic Video\",\"url\":\"https://www.semanticscholar.org/paper/5814f82c6d65071e1b28875258a48ea3905206fa\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"119923978\",\"name\":\"Yufan Liu\"},{\"authorId\":\"145143111\",\"name\":\"R. Hu\"},{\"authorId\":\"143684018\",\"name\":\"F. He\"}],\"doi\":\"10.1109/TIP.2018.2837106\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9f1a854d574d0bd14786c41247db272be6062581\",\"title\":\"Find Who to Look at: Turning From Action to Saliency\",\"url\":\"https://www.semanticscholar.org/paper/9f1a854d574d0bd14786c41247db272be6062581\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":\"1904.00767\",\"authors\":[{\"authorId\":\"1807405\",\"name\":\"S. Chen\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1007/978-3-030-01252-6_5\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"5cab3ce511ec8345d16a28c00094a2800b3919ce\",\"title\":\"Boosted Attention: Leveraging Human Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/5cab3ce511ec8345d16a28c00094a2800b3919ce\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3376641\",\"name\":\"A. Nuthmann\"},{\"authorId\":\"1917767\",\"name\":\"W. Einh\\u00e4user\"},{\"authorId\":\"46510545\",\"name\":\"Immo Schuetz\"}],\"doi\":\"10.3389/fnhum.2017.00491\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e1c2d5aeb31709e9ffd5ffe0b259805f38d16ae5\",\"title\":\"How Well Can Saliency Models Predict Fixation Selection in Scenes Beyond Central Bias? A New Approach to Model Evaluation Using Generalized Linear Mixed Models\",\"url\":\"https://www.semanticscholar.org/paper/e1c2d5aeb31709e9ffd5ffe0b259805f38d16ae5\",\"venue\":\"Front. Hum. Neurosci.\",\"year\":2017},{\"arxivId\":\"1709.06342\",\"authors\":[{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"46651223\",\"name\":\"C. Li\"},{\"authorId\":\"48354614\",\"name\":\"Zhenzhong Chen\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"},{\"authorId\":\"2694633\",\"name\":\"Zhenyu Guan\"}],\"doi\":\"10.1109/TCSVT.2018.2886277\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a55f87fed6cf14896a7494e893180dc71a7d55c6\",\"title\":\"Assessing Visual Quality of Omnidirectional Videos\",\"url\":\"https://www.semanticscholar.org/paper/a55f87fed6cf14896a7494e893180dc71a7d55c6\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":\"2012.05567\",\"authors\":[{\"authorId\":\"9660848\",\"name\":\"Wencan Zhang\"},{\"authorId\":\"2837527\",\"name\":\"Mariella Dimiccoli\"},{\"authorId\":\"1995703\",\"name\":\"B. Lim\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4c46271e99f7f38ce335ca45136de7e71603006e\",\"title\":\"Debiased-CAM for bias-agnostic faithful visual explanations of deep convolutional networks\",\"url\":\"https://www.semanticscholar.org/paper/4c46271e99f7f38ce335ca45136de7e71603006e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1811.10004\",\"authors\":[{\"authorId\":\"21319564\",\"name\":\"J. Li\"},{\"authorId\":\"2966504\",\"name\":\"Daowei Li\"},{\"authorId\":\"1967201\",\"name\":\"Kui Fu\"},{\"authorId\":\"1690940\",\"name\":\"L. Xu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6d17074e5b6a6b2e92141560479ad4ab5eb66af5\",\"title\":\"Visual Attention on the Sun: What Do Existing Models Actually Predict?\",\"url\":\"https://www.semanticscholar.org/paper/6d17074e5b6a6b2e92141560479ad4ab5eb66af5\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1604.03605\",\"authors\":[{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"},{\"authorId\":\"152627906\",\"name\":\"T. Judd\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"}],\"doi\":\"10.1109/TPAMI.2018.2815601\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"bfdf3431ff5182b585b3b0c11fa8cbfc13a6bde4\",\"title\":\"What Do Different Evaluation Metrics Tell Us About Saliency Models?\",\"url\":\"https://www.semanticscholar.org/paper/bfdf3431ff5182b585b3b0c11fa8cbfc13a6bde4\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145076397\",\"name\":\"Yun Ren\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"79439415\",\"name\":\"Haoyu Dong\"},{\"authorId\":\"2560900\",\"name\":\"Shengxi Li\"}],\"doi\":\"10.1109/CVPRW.2017.208\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f7d81091f909f718425eb428336ff72de5f3ad0e\",\"title\":\"Learning Dynamic GMM for Attention Distribution on Single-Face Videos\",\"url\":\"https://www.semanticscholar.org/paper/f7d81091f909f718425eb428336ff72de5f3ad0e\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":\"1904.04992\",\"authors\":[{\"authorId\":null,\"name\":\"Jia Li\"},{\"authorId\":\"1967201\",\"name\":\"Kui Fu\"},{\"authorId\":\"152836873\",\"name\":\"Shengwei Zhao\"},{\"authorId\":\"39646508\",\"name\":\"Shiming Ge\"}],\"doi\":\"10.1109/TIP.2019.2946102\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3f76324a4a26ff3d9097642676878aa7b1122581\",\"title\":\"Spatiotemporal Knowledge Distillation for Efficient Estimation of Aerial Video Saliency\",\"url\":\"https://www.semanticscholar.org/paper/3f76324a4a26ff3d9097642676878aa7b1122581\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1811.05625\",\"authors\":[{\"authorId\":\"1967201\",\"name\":\"Kui Fu\"},{\"authorId\":\"9073063\",\"name\":\"Jiugang Li\"},{\"authorId\":\"2803144\",\"name\":\"Y. Zhang\"},{\"authorId\":\"121194391\",\"name\":\"Hongze Shen\"},{\"authorId\":\"144051792\",\"name\":\"Yonghong Tian\"}],\"doi\":\"10.1109/TIP.2020.2998977\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fd2b919b6abb91657aa9104dfc2e7c18c114cbae\",\"title\":\"Model-Guided Multi-Path Knowledge Aggregation for Aerial Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/fd2b919b6abb91657aa9104dfc2e7c18c114cbae\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1737311\",\"name\":\"Yufan Liu\"},{\"authorId\":null,\"name\":\"Songyang Zhang\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"33913193\",\"name\":\"Xuming He\"}],\"doi\":\"10.1109/CVPR.2017.343\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5c3318d66f78c2ed8cbbdd1791e5a70ba2f64ead\",\"title\":\"Predicting Salient Face in Multiple-Face Videos\",\"url\":\"https://www.semanticscholar.org/paper/5c3318d66f78c2ed8cbbdd1791e5a70ba2f64ead\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1910.10859\",\"authors\":[{\"authorId\":\"49046587\",\"name\":\"Chunlei Liu\"},{\"authorId\":\"144778389\",\"name\":\"W. Ding\"},{\"authorId\":\"19171514\",\"name\":\"J. Yang\"},{\"authorId\":\"1727204\",\"name\":\"Vittorio Murino\"},{\"authorId\":\"46242227\",\"name\":\"B. Zhang\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"},{\"authorId\":\"1822413\",\"name\":\"Guodong Guo\"}],\"doi\":\"10.1109/TIP.2019.2940477\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0f8c3b653ff510e6f04a0195fa6aac91923bbffc\",\"title\":\"Aggregation Signature for Small Object Tracking\",\"url\":\"https://www.semanticscholar.org/paper/0f8c3b653ff510e6f04a0195fa6aac91923bbffc\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020}],\"corpusId\":11232964,\"doi\":\"10.1109/ICCV.2015.30\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":3,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"3e32b6325e6aa267a5f0cde1edd45c5a72ed3de6\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"W. Hou\"},{\"authorId\":null,\"name\":\"X. Gao\"},{\"authorId\":null,\"name\":\"D. Tao\"},{\"authorId\":null,\"name\":\"X. Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Visual saliency detection using information\",\"url\":\"\",\"venue\":\"divergence. PR,\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"D. Sihite A. Borji\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Itti . Stateoftheart in visual attention modeling\",\"url\":\"\",\"venue\":\"IEEE TPAMI\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7326223\",\"name\":\"L. Itti\"},{\"authorId\":\"144902513\",\"name\":\"P. Baldi\"}],\"doi\":\"10.1016/j.visres.2008.09.007\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aebd8bab5cff769fed204dba35112e364a47e504\",\"title\":\"Bayesian surprise attracts human attention\",\"url\":\"https://www.semanticscholar.org/paper/aebd8bab5cff769fed204dba35112e364a47e504\",\"venue\":\"Vision Research\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2608733\",\"name\":\"Stas Goferman\"},{\"authorId\":\"1398327241\",\"name\":\"L. Zelnik-Manor\"},{\"authorId\":\"49653522\",\"name\":\"A. Tal\"}],\"doi\":\"10.1109/TPAMI.2011.272\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fbe18b90b9e3031bfb7044226882cfc763e0a1ee\",\"title\":\"Context-Aware Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/fbe18b90b9e3031bfb7044226882cfc763e0a1ee\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1109/CVPR.2012.6247711\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5e3d92c27e2fbb407243a6279dfafe9260a3732d\",\"title\":\"Exploiting local and global patch rarities for saliency detection\",\"url\":\"https://www.semanticscholar.org/paper/5e3d92c27e2fbb407243a6279dfafe9260a3732d\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39810944\",\"name\":\"Jonathan Harel\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"}],\"doi\":\"10.7551/mitpress/7503.003.0073\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f412bb31ec9ef8bbef70eefc7ffd04420c1365d9\",\"title\":\"Graph-Based Visual Saliency\",\"url\":\"https://www.semanticscholar.org/paper/f412bb31ec9ef8bbef70eefc7ffd04420c1365d9\",\"venue\":\"NIPS\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1422133239\",\"name\":\"A. Garcia-Diaz\"},{\"authorId\":\"1760977\",\"name\":\"V. Lebor\\u00e1n\"},{\"authorId\":\"1390040513\",\"name\":\"X. R. Fdez-Vidal\"},{\"authorId\":\"1768258\",\"name\":\"X. Pardo\"}],\"doi\":\"10.1167/12.6.17\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9c40387012b5b86f82a8329d078f4f01ec90d512\",\"title\":\"On the relationship between optical variability, visual saliency, and eye fixations: a computational approach.\",\"url\":\"https://www.semanticscholar.org/paper/9c40387012b5b86f82a8329d078f4f01ec90d512\",\"venue\":\"Journal of vision\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1771189\",\"name\":\"S. Lu\"},{\"authorId\":\"1694051\",\"name\":\"Cheston Tan\"},{\"authorId\":\"6516914\",\"name\":\"J. Lim\"}],\"doi\":\"10.1109/TPAMI.2013.158\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ea11a1716ade7922f765ba4c70a15b9f7a75bc2b\",\"title\":\"Robust and Efficient Saliency Modeling from Image Co-Occurrence Histograms\",\"url\":\"https://www.semanticscholar.org/paper/ea11a1716ade7922f765ba4c70a15b9f7a75bc2b\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Garcia-Diaz\"},{\"authorId\":null,\"name\":\"V. Leborn\"},{\"authorId\":null,\"name\":\"X. R. Fdez-Vidal\"},{\"authorId\":null,\"name\":\"X. M. Pardo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"On the relationship between optical variability, visual saliency, and eye fixations: A computational approach. JOV\",\"url\":\"\",\"venue\":\"\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30372076\",\"name\":\"A. Russell\"},{\"authorId\":\"8149071\",\"name\":\"Stefan Mihalas\"},{\"authorId\":\"3220527\",\"name\":\"Rudiger Heydt\"},{\"authorId\":\"3271571\",\"name\":\"E. Niebur\"},{\"authorId\":\"1398026219\",\"name\":\"R. Etienne-Cummings\"}],\"doi\":\"10.1016/j.visres.2013.10.005\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"76b14353fcc158686114091aa481281d99c3bdae\",\"title\":\"A model of proto-object based saliency\",\"url\":\"https://www.semanticscholar.org/paper/76b14353fcc158686114091aa481281d99c3bdae\",\"venue\":\"Vision Research\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3084719\",\"name\":\"Xiaodi Hou\"},{\"authorId\":\"39810944\",\"name\":\"Jonathan Harel\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"}],\"doi\":\"10.1109/TPAMI.2011.146\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"48c2b8a35ce9468b84ac032af70cf2b100f5c1fc\",\"title\":\"Image Signature: Highlighting Sparse Salient Regions\",\"url\":\"https://www.semanticscholar.org/paper/48c2b8a35ce9468b84ac032af70cf2b100f5c1fc\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1941997\",\"name\":\"Chenlei Guo\"},{\"authorId\":\"144818403\",\"name\":\"Qi Ma\"},{\"authorId\":\"29906646\",\"name\":\"L. Zhang\"}],\"doi\":\"10.1109/CVPR.2008.4587715\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"16f4cfd4cbf504a151827b5a94df5deafd4930ac\",\"title\":\"Spatio-temporal Saliency detection using phase spectrum of quaternion fourier transform\",\"url\":\"https://www.semanticscholar.org/paper/16f4cfd4cbf504a151827b5a94df5deafd4930ac\",\"venue\":\"2008 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1109/TPAMI.2012.89\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"aa57b9bdb0736cbb38abf0a9d12047212c2a2425\",\"title\":\"State-of-the-Art in Visual Attention Modeling\",\"url\":\"https://www.semanticscholar.org/paper/aa57b9bdb0736cbb38abf0a9d12047212c2a2425\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"2037692\",\"name\":\"Dicky N. Sihite\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1109/TIP.2012.2210727\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c0b60d02b2d59123f6b336fe2e287bdb02a2a776\",\"title\":\"Quantitative Analysis of Human-Model Agreement in Visual Saliency Modeling: A Comparative Study\",\"url\":\"https://www.semanticscholar.org/paper/c0b60d02b2d59123f6b336fe2e287bdb02a2a776\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Z Bylinskii\"},{\"authorId\":null,\"name\":\"T Judd\"},{\"authorId\":null,\"name\":\"F Durand\"},{\"authorId\":null,\"name\":\"A Oliva\"},{\"authorId\":null,\"name\":\"A Torralba\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Mit saliency benchmark\",\"url\":\"\",\"venue\":\"Mit saliency benchmark\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2602925\",\"name\":\"Boris Schauerte\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"}],\"doi\":\"10.1007/978-3-642-33709-3_9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5a0d596ef86c7563c0907c052273113f51006479\",\"title\":\"Quaternion-Based Spectral Saliency Detection for Eye Fixation Prediction\",\"url\":\"https://www.semanticscholar.org/paper/5a0d596ef86c7563c0907c052273113f51006479\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1701293\",\"name\":\"J. Zhang\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"}],\"doi\":\"10.1109/ICCV.2013.26\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"75ee5cd7712b6ad13d64c3b4de24aa592a869fc1\",\"title\":\"Saliency Detection: A Boolean Map Approach\",\"url\":\"https://www.semanticscholar.org/paper/75ee5cd7712b6ad13d64c3b4de24aa592a869fc1\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2989773\",\"name\":\"Nicolas Riche\"},{\"authorId\":\"2896417\",\"name\":\"Matthieu Duvinage\"},{\"authorId\":\"1681157\",\"name\":\"M. Mancas\"},{\"authorId\":\"50276543\",\"name\":\"B. Gosselin\"},{\"authorId\":\"49164810\",\"name\":\"T. Dutoit\"}],\"doi\":\"10.1109/ICCV.2013.147\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"79c761353fe46544a758b284813dfa2908664db2\",\"title\":\"Saliency and Human Fixations: State-of-the-Art and Study of Comparison Metrics\",\"url\":\"https://www.semanticscholar.org/paper/79c761353fe46544a758b284813dfa2908664db2\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46275685\",\"name\":\"J. Li\"},{\"authorId\":\"145481070\",\"name\":\"D. Xu\"},{\"authorId\":\"48385803\",\"name\":\"W. Gao\"}],\"doi\":\"10.1109/TIP.2011.2179665\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"523cb3f5a357e9702777b019e5052788360509ce\",\"title\":\"Removing Label Ambiguity in Learning-Based Visual Saliency Estimation\",\"url\":\"https://www.semanticscholar.org/paper/523cb3f5a357e9702777b019e5052788360509ce\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3350185\",\"name\":\"C. Lang\"},{\"authorId\":\"1990768\",\"name\":\"Guangcan Liu\"},{\"authorId\":\"1740321\",\"name\":\"Jian Yu\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"}],\"doi\":\"10.1109/TIP.2011.2169274\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2d3ab8986c5cdc8d21923101ee30cae5ccbf0f35\",\"title\":\"Saliency Detection by Multitask Sparsity Pursuit\",\"url\":\"https://www.semanticscholar.org/paper/2d3ab8986c5cdc8d21923101ee30cae5ccbf0f35\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2937115\",\"name\":\"Weilong Hou\"},{\"authorId\":\"10699750\",\"name\":\"X. Gao\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"},{\"authorId\":\"1720243\",\"name\":\"X. Li\"}],\"doi\":\"10.1016/j.patcog.2013.03.008\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0668fae7d0d2f696ebcf4bf5c89cf0eaf261da45\",\"title\":\"Visual saliency detection using information divergence\",\"url\":\"https://www.semanticscholar.org/paper/0668fae7d0d2f696ebcf4bf5c89cf0eaf261da45\",\"venue\":\"Pattern Recognit.\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"C. Koch J. Harel\"},{\"authorId\":null,\"name\":\"P. Perona\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Graph - based visual salien\",\"url\":\"\",\"venue\":\"In NIPS\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145519708\",\"name\":\"J. Li\"},{\"authorId\":\"40161651\",\"name\":\"Yonghong Tian\"},{\"authorId\":\"34097174\",\"name\":\"Tiejun Huang\"},{\"authorId\":\"48385803\",\"name\":\"W. Gao\"}],\"doi\":\"10.1007/s11263-010-0354-6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d1ca0711576a4d6e1145502821f3dca8e3ce69bd\",\"title\":\"Probabilistic Multi-Task Learning for Visual Saliency Estimation in Video\",\"url\":\"https://www.semanticscholar.org/paper/d1ca0711576a4d6e1145502821f3dca8e3ce69bd\",\"venue\":\"International Journal of Computer Vision\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144410381\",\"name\":\"R. Margolin\"},{\"authorId\":\"1398327241\",\"name\":\"L. Zelnik-Manor\"},{\"authorId\":\"49653522\",\"name\":\"A. Tal\"}],\"doi\":\"10.1109/CVPR.2014.39\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eaaa16fe11bf17b6df58dfbd346a5b8cbfabd596\",\"title\":\"How to Evaluate Foreground Maps\",\"url\":\"https://www.semanticscholar.org/paper/eaaa16fe11bf17b6df58dfbd346a5b8cbfabd596\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3084719\",\"name\":\"Xiaodi Hou\"},{\"authorId\":\"5381034\",\"name\":\"L. Zhang\"}],\"doi\":\"10.1109/CVPR.2007.383267\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9ce3c18eb4fa86fd19bce46227be39895de4e4ab\",\"title\":\"Saliency Detection: A Spectral Residual Approach\",\"url\":\"https://www.semanticscholar.org/paper/9ce3c18eb4fa86fd19bce46227be39895de4e4ab\",\"venue\":\"2007 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7326223\",\"name\":\"L. Itti\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"},{\"authorId\":\"3271571\",\"name\":\"E. Niebur\"}],\"doi\":\"10.1109/34.730558\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4816f0b6f0d05da3901441bfa5cc7be044b4da8b\",\"title\":\"A Model of Saliency-Based Visual Attention for Rapid Scene Analysis\",\"url\":\"https://www.semanticscholar.org/paper/4816f0b6f0d05da3901441bfa5cc7be044b4da8b\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"143852685\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"2037692\",\"name\":\"Dicky N. Sihite\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1109/ICCV.2013.118\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"05375a7489f0a84d47a316bacb4d86e8a7bda0df\",\"title\":\"Analysis of Scores, Datasets, and Models in Visual Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/05375a7489f0a84d47a316bacb4d86e8a7bda0df\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2989773\",\"name\":\"Nicolas Riche\"},{\"authorId\":\"1681157\",\"name\":\"M. Mancas\"},{\"authorId\":\"2896417\",\"name\":\"Matthieu Duvinage\"},{\"authorId\":\"3028207\",\"name\":\"Makiese Mibulumukini\"},{\"authorId\":\"50276543\",\"name\":\"B. Gosselin\"},{\"authorId\":\"49164810\",\"name\":\"T. Dutoit\"}],\"doi\":\"10.1016/j.image.2013.03.009\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"83ec029e1a7b41669f8254b24c070050d9d01d75\",\"title\":\"RARE2012: A multi-scale rarity-based saliency detection with its comparative statistical analysis\",\"url\":\"https://www.semanticscholar.org/paper/83ec029e1a7b41669f8254b24c070050d9d01d75\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145519708\",\"name\":\"J. Li\"},{\"authorId\":\"40161651\",\"name\":\"Yonghong Tian\"},{\"authorId\":\"34097174\",\"name\":\"Tiejun Huang\"}],\"doi\":\"10.1007/s11263-013-0678-0\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5e535e4da529b6bd952f42fcdce5068cc0f54c19\",\"title\":\"Visual Saliency with Statistical Priors\",\"url\":\"https://www.semanticscholar.org/paper/5e535e4da529b6bd952f42fcdce5068cc0f54c19\",\"venue\":\"International Journal of Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"R Margolin\"},{\"authorId\":null,\"name\":\"L Zelnik-Manor\"},{\"authorId\":null,\"name\":\"A Tal\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"How to evaluate foreground maps? In CVPR\",\"url\":\"\",\"venue\":\"How to evaluate foreground maps? In CVPR\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47059693\",\"name\":\"L. Zhang\"},{\"authorId\":\"49488601\",\"name\":\"M. Tong\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"},{\"authorId\":\"2207531\",\"name\":\"Honghao Shan\"},{\"authorId\":\"48524582\",\"name\":\"G. Cottrell\"}],\"doi\":\"10.1167/8.7.32\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e80c48441351fc1d928524710b4500a0de8315bb\",\"title\":\"SUN: A Bayesian framework for saliency using natural statistics.\",\"url\":\"https://www.semanticscholar.org/paper/e80c48441351fc1d928524710b4500a0de8315bb\",\"venue\":\"Journal of vision\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":\"10.1109/CVPR.2012.6247706\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5817841d769baa45122ba0bf38af8cab3aeb5dd4\",\"title\":\"Boosting bottom-up and top-down visual features for saliency estimation\",\"url\":\"https://www.semanticscholar.org/paper/5817841d769baa45122ba0bf38af8cab3aeb5dd4\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Figure 10. The ranking lists of 23 models obtained by using the data-driven metric learned from user data\",\"url\":\"\",\"venue\":\"Figure 10. The ranking lists of 23 models obtained by using the data-driven metric learned from user data\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145557639\",\"name\":\"V. Nair\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a538b05ebb01a40323997629e171c91aa28b8e2f\",\"title\":\"Rectified Linear Units Improve Restricted Boltzmann Machines\",\"url\":\"https://www.semanticscholar.org/paper/a538b05ebb01a40323997629e171c91aa28b8e2f\",\"venue\":\"ICML\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2866780\",\"name\":\"Neil D. B. Bruce\"},{\"authorId\":\"1727853\",\"name\":\"John K. Tsotsos\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4f847b4ddc105d73bc78f3e7220e6c1f71a7dfb6\",\"title\":\"Saliency Based on Information Maximization\",\"url\":\"https://www.semanticscholar.org/paper/4f847b4ddc105d73bc78f3e7220e6c1f71a7dfb6\",\"venue\":\"NIPS\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143775672\",\"name\":\"Tilke Judd\"},{\"authorId\":\"1865091\",\"name\":\"Krista A. Ehinger\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/ICCV.2009.5459462\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c7614898de1cfee1a3a1c564f52c1e67879c29b3\",\"title\":\"Learning to predict where humans look\",\"url\":\"https://www.semanticscholar.org/paper/c7614898de1cfee1a3a1c564f52c1e67879c29b3\",\"venue\":\"2009 IEEE 12th International Conference on Computer Vision\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143615083\",\"name\":\"R. J. Peters\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"25aa2092e0e24401c66a3c4088166ac710cfbff5\",\"title\":\"Congruence between model and human attention reveals unique signatures of critical visual events\",\"url\":\"https://www.semanticscholar.org/paper/25aa2092e0e24401c66a3c4088166ac710cfbff5\",\"venue\":\"NIPS\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3084719\",\"name\":\"Xiaodi Hou\"},{\"authorId\":\"5381034\",\"name\":\"L. Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4e7ec75337766f2b649bb9f99c6887ee0f1674a6\",\"title\":\"Dynamic visual attention: searching for coding length increments\",\"url\":\"https://www.semanticscholar.org/paper/4e7ec75337766f2b649bb9f99c6887ee0f1674a6\",\"venue\":\"NIPS\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2514095\",\"name\":\"M. Emami\"},{\"authorId\":\"1826586\",\"name\":\"L. L. Hoberock\"}],\"doi\":\"10.1016/j.imavis.2013.08.004\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"417c797158ae20b324597c3612731edfd11757ea\",\"title\":\"Selection of a best metric and evaluation of bottom-up visual saliency models\",\"url\":\"https://www.semanticscholar.org/paper/417c797158ae20b324597c3612731edfd11757ea\",\"venue\":\"Image Vis. Comput.\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26734366\",\"name\":\"N. Murray\"},{\"authorId\":\"144465192\",\"name\":\"M. Vanrell\"},{\"authorId\":\"2556319\",\"name\":\"X. Otazu\"},{\"authorId\":\"145983916\",\"name\":\"C. P\\u00e1rraga\"}],\"doi\":\"10.1109/CVPR.2011.5995506\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"42f80d9186370cb9d21d7b244051e0b08dd51372\",\"title\":\"Saliency estimation using a non-parametric low-level vision model\",\"url\":\"https://www.semanticscholar.org/paper/42f80d9186370cb9d21d7b244051e0b08dd51372\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":\"1605.01999\",\"authors\":[{\"authorId\":\"1701502\",\"name\":\"Jian Li\"},{\"authorId\":\"3631473\",\"name\":\"M. Levine\"},{\"authorId\":\"2888872\",\"name\":\"X. An\"},{\"authorId\":\"145813731\",\"name\":\"X. Xu\"},{\"authorId\":\"3302754\",\"name\":\"Hangen He\"}],\"doi\":\"10.1109/TPAMI.2012.147\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"0c760f678c99b4a7eacc4b0ef7a42d4e6c734983\",\"title\":\"Visual Saliency Based on Scale-Space Analysis in the Frequency Domain\",\"url\":\"https://www.semanticscholar.org/paper/0c760f678c99b4a7eacc4b0ef7a42d4e6c734983\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"}],\"doi\":\"10.1167/13.4.11\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9896b03aeb17e06181c1842773fec4b742d7c51f\",\"title\":\"Visual saliency estimation by nonlinearly integrating features using region covariances.\",\"url\":\"https://www.semanticscholar.org/paper/9896b03aeb17e06181c1842773fec4b742d7c51f\",\"venue\":\"Journal of vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144388361\",\"name\":\"C. Li\"},{\"authorId\":\"3280033\",\"name\":\"J. Xue\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"},{\"authorId\":\"2498428\",\"name\":\"X. Lan\"},{\"authorId\":\"41170833\",\"name\":\"Zhiqiang Tian\"}],\"doi\":\"10.3390/s130303409\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"439d08507295d5d00d806de190c31126f499a701\",\"title\":\"Spatio-Temporal Saliency Perception via Hypercomplex Frequency Spectral Contrast\",\"url\":\"https://www.semanticscholar.org/paper/439d08507295d5d00d806de190c31126f499a701\",\"venue\":\"Sensors\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47521917\",\"name\":\"Q. Zhao\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"}],\"doi\":\"10.1167/12.6.22\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a020ea916bb8fa9cbc4cb7da4c22e7f35d81f3f3\",\"title\":\"Learning visual saliency by combining feature maps in a nonlinear manner using AdaBoost.\",\"url\":\"https://www.semanticscholar.org/paper/a020ea916bb8fa9cbc4cb7da4c22e7f35d81f3f3\",\"venue\":\"Journal of vision\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47824598\",\"name\":\"W. Wang\"},{\"authorId\":\"1717863\",\"name\":\"Yizhou Wang\"},{\"authorId\":\"1689702\",\"name\":\"Q. Huang\"},{\"authorId\":\"48385803\",\"name\":\"W. Gao\"}],\"doi\":\"10.1109/CVPR.2010.5539927\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e2b4206d7c58047e0351242df3dcf2c83dd9d8fa\",\"title\":\"Measuring visual saliency by Site Entropy Rate\",\"url\":\"https://www.semanticscholar.org/paper/e2b4206d7c58047e0351242df3dcf2c83dd9d8fa\",\"venue\":\"2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Borji\"},{\"authorId\":null,\"name\":\"L.\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Itti . Stateoftheart in visual attention modeling\",\"url\":\"\",\"venue\":\"IEEE TPAMI\",\"year\":2013}],\"title\":\"A Data-Driven Metric for Comprehensive Evaluation of Saliency Models\",\"topics\":[{\"topic\":\"Convolutional neural network\",\"topicId\":\"29860\",\"url\":\"https://www.semanticscholar.org/topic/29860\"},{\"topic\":\"Map\",\"topicId\":\"2392\",\"url\":\"https://www.semanticscholar.org/topic/2392\"},{\"topic\":\"Heuristic\",\"topicId\":\"4146\",\"url\":\"https://www.semanticscholar.org/topic/4146\"},{\"topic\":\"Performance\",\"topicId\":\"3097\",\"url\":\"https://www.semanticscholar.org/topic/3097\"}],\"url\":\"https://www.semanticscholar.org/paper/3e32b6325e6aa267a5f0cde1edd45c5a72ed3de6\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015}\n"