"{\"abstract\":\"We address a question answering task on real-world images that is set up as a Visual Turing Test. By combining latest advances in image representation and natural language processing, we propose Neural-Image-QA, an end-to-end formulation to this problem for which all parts are trained jointly. In contrast to previous efforts, we are facing a multi-modal problem where the language output (answer) is conditioned on visual and natural language input (image and question). Our approach Neural-Image-QA doubles the performance of the previous best approach on this problem. We provide additional insights into the problem by analyzing how much information is contained only in the language part for which we provide a new human baseline. To study human consensus, which is related to the ambiguities inherent in this challenging task, we propose two novel metrics and collect additional answers which extends the original DAQUAR dataset to DAQUAR-Consensus.\",\"arxivId\":\"1505.01121\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\",\"url\":\"https://www.semanticscholar.org/author/145478807\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\",\"url\":\"https://www.semanticscholar.org/author/34849128\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\",\"url\":\"https://www.semanticscholar.org/author/1739548\"}],\"citationVelocity\":90,\"citations\":[{\"arxivId\":\"1705.00601\",\"authors\":[{\"authorId\":\"3158336\",\"name\":\"Aroma Mahendru\"},{\"authorId\":\"39351028\",\"name\":\"Viraj Prabhu\"},{\"authorId\":\"2884573\",\"name\":\"Akrit Mohapatra\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"}],\"doi\":\"10.18653/v1/D17-1097\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1d82e7736268917cc3d87a2ee0896b03e02a5ff6\",\"title\":\"The Promise of Premise: Harnessing Question Premises in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1d82e7736268917cc3d87a2ee0896b03e02a5ff6\",\"venue\":\"EMNLP\",\"year\":2017},{\"arxivId\":\"1712.01329\",\"authors\":[{\"authorId\":\"32652024\",\"name\":\"Mircea Mironenco\"},{\"authorId\":\"1867140\",\"name\":\"D. Kianfar\"},{\"authorId\":\"145560715\",\"name\":\"Ke Tran\"},{\"authorId\":\"1713134\",\"name\":\"E. Kanoulas\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"03f98bfb129028b80ce98686c573830671ee1e3d\",\"title\":\"Examining Cooperation in Visual Dialog Models\",\"url\":\"https://www.semanticscholar.org/paper/03f98bfb129028b80ce98686c573830671ee1e3d\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3158336\",\"name\":\"Aroma Mahendru\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e973243bf6d4b8bd56f210ba490a26e7946c5b1f\",\"title\":\"Role of Premises in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e973243bf6d4b8bd56f210ba490a26e7946c5b1f\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150337817\",\"name\":\"Weike Jin\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"48515305\",\"name\":\"Yimeng Li\"},{\"authorId\":\"49298718\",\"name\":\"Jie Li\"},{\"authorId\":\"145974112\",\"name\":\"Jun Xiao\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1145/3321505\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"99b722fc4e168eddea69521f26c77e31e56fc9f4\",\"title\":\"Video Question Answering via Knowledge-based Progressive Spatial-Temporal Attention Network\",\"url\":\"https://www.semanticscholar.org/paper/99b722fc4e168eddea69521f26c77e31e56fc9f4\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":\"1801.01967\",\"authors\":[{\"authorId\":\"144839067\",\"name\":\"Amir Mazaheri\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1007/978-3-030-01261-8_10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ab84d00079d0a29e44bdc4c83037dc76b0fbef05\",\"title\":\"Visual Text Correction\",\"url\":\"https://www.semanticscholar.org/paper/ab84d00079d0a29e44bdc4c83037dc76b0fbef05\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1511.02570\",\"authors\":[{\"authorId\":\"71984337\",\"name\":\"Peng Wang\"},{\"authorId\":\"49018095\",\"name\":\"Qi Wu\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.24963/ijcai.2017/179\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0b0a1cd432413978e4ef3d0418ebf3bb07af6c7a\",\"title\":\"Explicit Knowledge-based Reasoning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0b0a1cd432413978e4ef3d0418ebf3bb07af6c7a\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":\"1901.06595\",\"authors\":[{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"1806773\",\"name\":\"I. Misra\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"}],\"doi\":\"10.1109/ICCVW.2019.00237\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5a97e9a253a60814f76dab86e8a4ec65fc86e261\",\"title\":\"Evaluating Text-to-Image Matching using Binary Image Selection (BISON)\",\"url\":\"https://www.semanticscholar.org/paper/5a97e9a253a60814f76dab86e8a4ec65fc86e261\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50822528\",\"name\":\"Wenbin Su\"},{\"authorId\":\"9456123\",\"name\":\"Zhufeng Lei\"}],\"doi\":\"10.1177/1687814019894433\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f2ca5e9c49136aa840462bd2eb298750136f1411\",\"title\":\"Mold-level prediction based on long short-term memory model and multi-mode decomposition with mutual information entropy\",\"url\":\"https://www.semanticscholar.org/paper/f2ca5e9c49136aa840462bd2eb298750136f1411\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48520182\",\"name\":\"Xiaoshan Yang\"},{\"authorId\":\"145194969\",\"name\":\"C. Xu\"}],\"doi\":\"10.1145/3313873\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1a756ae8457454120ee2e067d4936d801f56ed62\",\"title\":\"Image Captioning by Asking Questions\",\"url\":\"https://www.semanticscholar.org/paper/1a756ae8457454120ee2e067d4936d801f56ed62\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":\"1805.08389\",\"authors\":[{\"authorId\":\"35585536\",\"name\":\"Jialin Wu\"},{\"authorId\":\"32193161\",\"name\":\"Zeyuan Hu\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"91956c41190231eefd2186f21b79d1ca1495a68e\",\"title\":\"Joint Image Captioning and Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/91956c41190231eefd2186f21b79d1ca1495a68e\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"14320047\",\"name\":\"C. Patil\"},{\"authorId\":\"34326205\",\"name\":\"Manasi S. Patwardhan\"}],\"doi\":\"10.1145/3383465\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"9e081431cfbab4d5c8823efa2620ca0accfa124e\",\"title\":\"Visual Question Generation\",\"url\":\"https://www.semanticscholar.org/paper/9e081431cfbab4d5c8823efa2620ca0accfa124e\",\"venue\":\"ACM Comput. Surv.\",\"year\":2020},{\"arxivId\":\"1511.05960\",\"authors\":[{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"36650957\",\"name\":\"Jiang Wang\"},{\"authorId\":\"34192119\",\"name\":\"Liang-Chieh Chen\"},{\"authorId\":\"2345388\",\"name\":\"Haoyuan Gao\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b196bc11ad516c8e6ff96f83acfc443fd7161730\",\"title\":\"ABC-CNN: An Attention Based Convolutional Neural Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b196bc11ad516c8e6ff96f83acfc443fd7161730\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1803.11185\",\"authors\":[{\"authorId\":\"28919105\",\"name\":\"Raymond A. Yeh\"},{\"authorId\":\"1834451\",\"name\":\"M. Do\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1109/CVPR.2018.00641\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"021b08b823700f8053afc54356e8d0ce57a3df71\",\"title\":\"Unsupervised Textual Grounding: Linking Words to Image Concepts\",\"url\":\"https://www.semanticscholar.org/paper/021b08b823700f8053afc54356e8d0ce57a3df71\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1601.03896\",\"authors\":[{\"authorId\":\"145040726\",\"name\":\"R. Bernardi\"},{\"authorId\":\"2588033\",\"name\":\"Ruken Cakici\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"},{\"authorId\":\"1398643531\",\"name\":\"N. Ikizler-Cinbis\"},{\"authorId\":\"1393020635\",\"name\":\"F. Keller\"},{\"authorId\":\"35347012\",\"name\":\"A. Muscat\"},{\"authorId\":\"2022124\",\"name\":\"Barbara Plank\"}],\"doi\":\"10.24963/ijcai.2017/704\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6e9aebe54f76d85c6df7e80faa761ef0aec3d54c\",\"title\":\"Automatic Description Generation from Images: A Survey of Models, Datasets, and Evaluation Measures (Extended Abstract)\",\"url\":\"https://www.semanticscholar.org/paper/6e9aebe54f76d85c6df7e80faa761ef0aec3d54c\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":\"1906.02890\",\"authors\":[{\"authorId\":\"8815141\",\"name\":\"Haoyue Shi\"},{\"authorId\":\"13589371\",\"name\":\"Jiayuan Mao\"},{\"authorId\":\"1700980\",\"name\":\"Kevin Gimpel\"},{\"authorId\":\"2924113\",\"name\":\"Karen Livescu\"}],\"doi\":\"10.18653/v1/P19-1180\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"708f8c0eb5032edd6f31663a27febbb0529cbcf3\",\"title\":\"Visually Grounded Neural Syntax Acquisition\",\"url\":\"https://www.semanticscholar.org/paper/708f8c0eb5032edd6f31663a27febbb0529cbcf3\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1612.06530\",\"authors\":[{\"authorId\":\"144738967\",\"name\":\"S. Zhang\"},{\"authorId\":\"14564042\",\"name\":\"Lizhen Qu\"},{\"authorId\":\"2941564\",\"name\":\"Shaodi You\"},{\"authorId\":\"2881049\",\"name\":\"Zhenglu Yang\"},{\"authorId\":\"8214269\",\"name\":\"Jiawan Zhang\"}],\"doi\":\"10.24963/ijcai.2017/592\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b0f61fa2ae931eb001214b60c6391966ddb41123\",\"title\":\"Automatic Generation of Grounded Visual Questions\",\"url\":\"https://www.semanticscholar.org/paper/b0f61fa2ae931eb001214b60c6391966ddb41123\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":\"1804.00105\",\"authors\":[{\"authorId\":\"2826839\",\"name\":\"Qingxing Cao\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"46708223\",\"name\":\"B. Li\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"1737218\",\"name\":\"L. Lin\"}],\"doi\":\"10.1109/CVPR.2018.00757\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eff328e0ecfb9a7a2d6664ee38aa32a61c7b9f42\",\"title\":\"Visual Question Reasoning on General Dependency Tree\",\"url\":\"https://www.semanticscholar.org/paper/eff328e0ecfb9a7a2d6664ee38aa32a61c7b9f42\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1811.00538\",\"authors\":[{\"authorId\":\"153137839\",\"name\":\"M. Narasimhan\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"ad08da5951437c117551a63c2f8b943bee2029ce\",\"title\":\"Out of the Box: Reasoning with Graph Convolution Nets for Factual Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ad08da5951437c117551a63c2f8b943bee2029ce\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1505.02074\",\"authors\":[{\"authorId\":\"2540599\",\"name\":\"Mengye Ren\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"62a956d7600b10ca455076cd56e604dfd106072a\",\"title\":\"Exploring Models and Data for Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/62a956d7600b10ca455076cd56e604dfd106072a\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1512.03460\",\"authors\":[{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"47001807\",\"name\":\"Y. Li\"},{\"authorId\":\"1759899\",\"name\":\"C. Ferm\\u00fcller\"},{\"authorId\":\"1697493\",\"name\":\"Y. Aloimonos\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"8172a3812e6a451eaac7d4b3e1102e5942279c26\",\"title\":\"Neural Self Talk: Image Understanding via Continuous Questioning and Answering\",\"url\":\"https://www.semanticscholar.org/paper/8172a3812e6a451eaac7d4b3e1102e5942279c26\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"17765450\",\"name\":\"Aahitagni Mukherjee\"},{\"authorId\":\"2615954\",\"name\":\"Shubham Agrawal\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"4a9f1335cde49473a8aec4f57c5cd65b101c9af9\",\"title\":\"Visual Question Answering using Deep Learning Project proposal for CS 671 A : Natural Language Processing\",\"url\":\"https://www.semanticscholar.org/paper/4a9f1335cde49473a8aec4f57c5cd65b101c9af9\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Haoyue Shi\"},{\"authorId\":\"13589371\",\"name\":\"Jiayuan Mao\"},{\"authorId\":\"15727192\",\"name\":\"Tete Xiao\"},{\"authorId\":\"144898150\",\"name\":\"Yuning Jiang\"},{\"authorId\":\"144716314\",\"name\":\"J. Sun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"75409785b6b6e7fee81489cc5db731c1718dbd3e\",\"title\":\"GRU Encoder Word Embeddings Fusing with MLP Predicted Word : Vase\",\"url\":\"https://www.semanticscholar.org/paper/75409785b6b6e7fee81489cc5db731c1718dbd3e\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1707.05612\",\"authors\":[{\"authorId\":\"2978170\",\"name\":\"Fartash Faghri\"},{\"authorId\":\"1793739\",\"name\":\"David J. Fleet\"},{\"authorId\":\"51131802\",\"name\":\"J. Kiros\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"faa093a53b83f0e9c35a0bfbcacee0a16f8eb6d1\",\"title\":\"VSE++: Improved Visual-Semantic Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/faa093a53b83f0e9c35a0bfbcacee0a16f8eb6d1\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"102993876\",\"name\":\"X. Tang\"},{\"authorId\":\"40156219\",\"name\":\"P. Wang\"},{\"authorId\":\"10440006\",\"name\":\"Qiuyang Liu\"},{\"authorId\":\"144812977\",\"name\":\"W. Wang\"},{\"authorId\":\"47179764\",\"name\":\"J. Han\"}],\"doi\":\"10.1109/HPCC/SmartCity/DSS.2019.00334\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"44ea486d6d9d33ea654ba880404c99086e603d7d\",\"title\":\"Nanily: A QoS-Aware Scheduling for DNN Inference Workload in Clouds\",\"url\":\"https://www.semanticscholar.org/paper/44ea486d6d9d33ea654ba880404c99086e603d7d\",\"venue\":\"2019 IEEE 21st International Conference on High Performance Computing and Communications; IEEE 17th International Conference on Smart City; IEEE 5th International Conference on Data Science and Systems (HPCC/SmartCity/DSS)\",\"year\":2019},{\"arxivId\":\"1906.02467\",\"authors\":[{\"authorId\":\"48567197\",\"name\":\"Zhou Yu\"},{\"authorId\":\"50854337\",\"name\":\"D. Xu\"},{\"authorId\":\"1720236\",\"name\":\"J. Yu\"},{\"authorId\":\"144478231\",\"name\":\"T. Yu\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1609/aaai.v33i01.33019127\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"4f2c1af57c056102806a184517313804f66e7447\",\"title\":\"ActivityNet-QA: A Dataset for Understanding Complex Web Videos via Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/4f2c1af57c056102806a184517313804f66e7447\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1505.00468\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-016-0966-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"title\":\"VQA: Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1704.04497\",\"authors\":[{\"authorId\":\"2338742\",\"name\":\"Y. Jang\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"49170458\",\"name\":\"Youngjin Kim\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1109/CVPR.2017.149\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b2f521c02c6ed3080c5fe123e938cdf4555e6fd2\",\"title\":\"TGIF-QA: Toward Spatio-Temporal Reasoning in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b2f521c02c6ed3080c5fe123e938cdf4555e6fd2\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48570713\",\"name\":\"L. Zhang\"},{\"authorId\":\"1798982\",\"name\":\"Bingpeng Ma\"},{\"authorId\":\"46439250\",\"name\":\"Guorong Li\"},{\"authorId\":\"1689702\",\"name\":\"Q. Huang\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1145/3123266.3123317\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"20e24a40dc855fa69aa3d85b4bfdcfb8c9dadb74\",\"title\":\"Multi-Networks Joint Learning for Large-Scale Cross-Modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/20e24a40dc855fa69aa3d85b4bfdcfb8c9dadb74\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47905503\",\"name\":\"Yuyu Wang\"},{\"authorId\":\"1918691\",\"name\":\"Chunjuan Bo\"},{\"authorId\":\"143987328\",\"name\":\"Dong Wang\"},{\"authorId\":\"50695608\",\"name\":\"S. Wang\"},{\"authorId\":\"4955826\",\"name\":\"Yunwei Qi\"},{\"authorId\":\"1790976\",\"name\":\"H. Lu\"}],\"doi\":\"10.1109/ICASSP.2019.8682456\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"611e705fdaf8564e27b9e798aaf6424dc8ed046c\",\"title\":\"Language Person Search with Mutually Connected Classification Loss\",\"url\":\"https://www.semanticscholar.org/paper/611e705fdaf8564e27b9e798aaf6424dc8ed046c\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40791626\",\"name\":\"Reham Abobeah\"},{\"authorId\":\"1864588\",\"name\":\"Marwan Torki\"},{\"authorId\":\"39781659\",\"name\":\"A. Shoukry\"},{\"authorId\":\"1788294\",\"name\":\"J. Katto\"}],\"doi\":\"10.5220/0007524505830589\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fd6ca05440395195c3092c0717d58f4410143fb0\",\"title\":\"Bi-Directional Attention Flow for Video Alignment\",\"url\":\"https://www.semanticscholar.org/paper/fd6ca05440395195c3092c0717d58f4410143fb0\",\"venue\":\"VISIGRAPP\",\"year\":2019},{\"arxivId\":\"1806.06371\",\"authors\":[{\"authorId\":\"2752573\",\"name\":\"Lisa Beinborn\"},{\"authorId\":\"25080314\",\"name\":\"Teresa Botschen\"},{\"authorId\":\"1730400\",\"name\":\"Iryna Gurevych\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1b3587363d37dd197b6adbcfa79d49b5486f27d8\",\"title\":\"Multimodal Grounding for Language Processing\",\"url\":\"https://www.semanticscholar.org/paper/1b3587363d37dd197b6adbcfa79d49b5486f27d8\",\"venue\":\"COLING\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1796706\",\"name\":\"Daojian Zeng\"},{\"authorId\":\"1400347434\",\"name\":\"Guanhong Zhou\"},{\"authorId\":\"9491882\",\"name\":\"J. Wang\"}],\"doi\":\"10.1109/ICECIE47765.2019.8974765\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"01163764edf888ded242e992845badaaf6c6ec6e\",\"title\":\"Residual Self-Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/01163764edf888ded242e992845badaaf6c6ec6e\",\"venue\":\"2019 1st International Conference on Electrical, Control and Instrumentation Engineering (ICECIE)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3144952\",\"name\":\"Sibei Yang\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"66616425\",\"name\":\"Yizhou Yu\"}],\"doi\":\"10.1109/CVPR.2019.00427\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1db245d9d2873ed433774f55b74e5b0274a71bd8\",\"title\":\"Cross-Modal Relationship Inference for Grounding Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/1db245d9d2873ed433774f55b74e5b0274a71bd8\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1610.01076\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"484c465e13720fff383c7fb6fc49719a817fb0f7\",\"title\":\"Tutorial on Answering Questions about Images with Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/484c465e13720fff383c7fb6fc49719a817fb0f7\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0b2c543e0c47454c4512569175094e6cb6ae02a9\",\"title\":\"The VizWiz Grand Challenge : A Large Visual Question Answering Dataset from Blind People Anonymous CVPR submission\",\"url\":\"https://www.semanticscholar.org/paper/0b2c543e0c47454c4512569175094e6cb6ae02a9\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47909637\",\"name\":\"Yun Liu\"},{\"authorId\":\"1679013\",\"name\":\"X. Zhang\"},{\"authorId\":\"1939569\",\"name\":\"Feiran Huang\"},{\"authorId\":\"1707275\",\"name\":\"Zhoujun Li\"}],\"doi\":\"10.1145/3269206.3271765\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c67d62592ff24a25764e489a8a68672d40f50da7\",\"title\":\"Adversarial Learning of Answer-Related Representation for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/c67d62592ff24a25764e489a8a68672d40f50da7\",\"venue\":\"CIKM\",\"year\":2018},{\"arxivId\":\"1912.09551\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6cfc0933cbc5c4d59cb9a951ea51bae41e150ccc\",\"title\":\"Deep Exemplar Networks for VQA and VQG\",\"url\":\"https://www.semanticscholar.org/paper/6cfc0933cbc5c4d59cb9a951ea51bae41e150ccc\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1698736245\",\"name\":\"Akshra Gupta\"},{\"authorId\":\"1699602385\",\"name\":\"Manas Garg\"},{\"authorId\":\"1699601985\",\"name\":\"Shrikant Deshmane\"},{\"authorId\":\"2826791\",\"name\":\"P. Singh\"},{\"authorId\":\"1699596049\",\"name\":\"Basant Agarwal\"}],\"doi\":\"10.1109/ICETCE48199.2020.9091754\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"97c41345d523ba97d84507b2550888084a988134\",\"title\":\"Object-based classification for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/97c41345d523ba97d84507b2550888084a988134\",\"venue\":\"2020 3rd International Conference on Emerging Technologies in Computer Engineering: Machine Learning and Internet of Things (ICETCE)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2973718\",\"name\":\"L. Kodra\"}],\"doi\":\"10.5121/IJAIA.2017.8206\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e33d8103bb5c1811fe19cc76bb1259b0ed137961\",\"title\":\"A Review on Neural Network Question Answering Systems\",\"url\":\"https://www.semanticscholar.org/paper/e33d8103bb5c1811fe19cc76bb1259b0ed137961\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150337817\",\"name\":\"Weike Jin\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"67144160\",\"name\":\"Mao Gu\"},{\"authorId\":\"97583812\",\"name\":\"J. Yu\"},{\"authorId\":\"1384523745\",\"name\":\"Jun Xiao\"},{\"authorId\":\"2125211\",\"name\":\"Yueting Zhuang\"}],\"doi\":\"10.1145/3343031.3351065\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7a162f189c9c553438b83a8a8ec7de4a6fa59069\",\"title\":\"Multi-interaction Network with Object Relation for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7a162f189c9c553438b83a8a8ec7de4a6fa59069\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1604.00466\",\"authors\":[{\"authorId\":\"1712479\",\"name\":\"Mohamed Elhoseiny\"},{\"authorId\":\"145823372\",\"name\":\"S. Cohen\"},{\"authorId\":\"145907577\",\"name\":\"W. Chang\"},{\"authorId\":\"31844147\",\"name\":\"Brian L. Price\"},{\"authorId\":\"145159523\",\"name\":\"A. Elgammal\"}],\"doi\":\"10.18653/v1/W16-3201\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e4c0c0b0795f5de0306c775ae1b10659b9ab80bb\",\"title\":\"Automatic Annotation of Structured Facts in Images\",\"url\":\"https://www.semanticscholar.org/paper/e4c0c0b0795f5de0306c775ae1b10659b9ab80bb\",\"venue\":\"VL@ACL\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"44c0f72c0d6604482d9bd9607b30d831c7cde82c\",\"title\":\"Learning from Language\",\"url\":\"https://www.semanticscholar.org/paper/44c0f72c0d6604482d9bd9607b30d831c7cde82c\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2012.03678\",\"authors\":[{\"authorId\":\"2935458\",\"name\":\"Alkesh Patel\"},{\"authorId\":\"71027035\",\"name\":\"Akanksha Bindal\"},{\"authorId\":\"3365389\",\"name\":\"Hadas Kotek\"},{\"authorId\":\"32192159\",\"name\":\"C. Klein\"},{\"authorId\":\"31868842\",\"name\":\"J. Williams\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1aae51526f8a9d27cc973d98223a909af0e82cd7\",\"title\":\"Generating Natural Questions from Images for Multimodal Assistants\",\"url\":\"https://www.semanticscholar.org/paper/1aae51526f8a9d27cc973d98223a909af0e82cd7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47220354\",\"name\":\"Pingping Huang\"},{\"authorId\":\"47513298\",\"name\":\"J. Huang\"},{\"authorId\":\"46791647\",\"name\":\"Y. Guo\"},{\"authorId\":\"49605671\",\"name\":\"M. Qiao\"},{\"authorId\":\"143756111\",\"name\":\"Y. Zhu\"}],\"doi\":\"10.18653/v1/P19-1349\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"144f4d5dcd0b13935ff0d0890c2ec37aa40039b1\",\"title\":\"Multi-grained Attention with Object-level Grounding for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/144f4d5dcd0b13935ff0d0890c2ec37aa40039b1\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1511.06973\",\"authors\":[{\"authorId\":\"34902783\",\"name\":\"Qi Wu\"},{\"authorId\":\"48319305\",\"name\":\"P. Wang\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2016.500\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"20dbdf02497aa84510970d0f5e8b599073bca1bc\",\"title\":\"Ask Me Anything: Free-Form Visual Question Answering Based on Knowledge from External Sources\",\"url\":\"https://www.semanticscholar.org/paper/20dbdf02497aa84510970d0f5e8b599073bca1bc\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1803.10906\",\"authors\":[{\"authorId\":\"3029956\",\"name\":\"J. Gao\"},{\"authorId\":\"40899706\",\"name\":\"Runzhou Ge\"},{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/CVPR.2018.00688\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f45c3a83e5c6276c6655c5df5833ab6b75e17bdf\",\"title\":\"Motion-Appearance Co-memory Networks for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f45c3a83e5c6276c6655c5df5833ab6b75e17bdf\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1811.04595\",\"authors\":[{\"authorId\":\"1754818\",\"name\":\"Anran Wang\"},{\"authorId\":\"26336902\",\"name\":\"Anh Tuan Luu\"},{\"authorId\":\"2121484\",\"name\":\"Chuan-Sheng Foo\"},{\"authorId\":\"7296648\",\"name\":\"Hongyuan Zhu\"},{\"authorId\":\"144447820\",\"name\":\"Yi Tay\"},{\"authorId\":\"1802086\",\"name\":\"V. Chandrasekhar\"}],\"doi\":\"10.1109/TIP.2019.2931534\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"09acc6d00f710c8307ffa118a7dc77a00c692b74\",\"title\":\"Holistic Multi-Modal Memory Network for Movie Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/09acc6d00f710c8307ffa118a7dc77a00c692b74\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2973718\",\"name\":\"L. Kodra\"},{\"authorId\":\"50879442\",\"name\":\"E. Me\\u00e7e\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f22058a3003cee6b17c6c25c8a635a653e78614c\",\"title\":\"Multimodal Attention in Recurrent Neural Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f22058a3003cee6b17c6c25c8a635a653e78614c\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1806.10348\",\"authors\":[{\"authorId\":\"8815141\",\"name\":\"Haoyue Shi\"},{\"authorId\":\"13589371\",\"name\":\"Jiayuan Mao\"},{\"authorId\":\"15727192\",\"name\":\"Tete Xiao\"},{\"authorId\":\"1691963\",\"name\":\"Yuning Jiang\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3e16de062b9cdeecfcbda0de022f1fc4e741a2e6\",\"title\":\"Learning Visually-Grounded Semantics from Contrastive Adversarial Samples\",\"url\":\"https://www.semanticscholar.org/paper/3e16de062b9cdeecfcbda0de022f1fc4e741a2e6\",\"venue\":\"COLING\",\"year\":2018},{\"arxivId\":\"1810.11735\",\"authors\":[{\"authorId\":\"32251567\",\"name\":\"Shikib Mehri\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a82034bd78ee09117baa35ab23b9d600a7509167\",\"title\":\"Middle-Out Decoding\",\"url\":\"https://www.semanticscholar.org/paper/a82034bd78ee09117baa35ab23b9d600a7509167\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1808.04446\",\"authors\":[{\"authorId\":\"3367628\",\"name\":\"Florian Strub\"},{\"authorId\":\"34675041\",\"name\":\"Mathieu Seurin\"},{\"authorId\":\"3439053\",\"name\":\"Ethan Perez\"},{\"authorId\":\"153559313\",\"name\":\"H. D. Vries\"},{\"authorId\":\"143716734\",\"name\":\"J. Mary\"},{\"authorId\":\"34682317\",\"name\":\"P. Preux\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1721354\",\"name\":\"Olivier Pietquin\"}],\"doi\":\"10.1007/978-3-030-01228-1_48\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0654e75bfea7af13e021a22a21422b36270c08b7\",\"title\":\"Visual Reasoning with Multi-hop Feature Modulation\",\"url\":\"https://www.semanticscholar.org/paper/0654e75bfea7af13e021a22a21422b36270c08b7\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1603.08754\",\"authors\":[{\"authorId\":\"2893664\",\"name\":\"Zeynep Akata\"},{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1109/CVPR.2016.14\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"244ae156ba2aaa91b2fa443c8ceb74ee13c6c6fa\",\"title\":\"Multi-cue Zero-Shot Learning with Strong Supervision\",\"url\":\"https://www.semanticscholar.org/paper/244ae156ba2aaa91b2fa443c8ceb74ee13c6c6fa\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2973718\",\"name\":\"L. Kodra\"},{\"authorId\":\"50879442\",\"name\":\"E. Me\\u00e7e\"}],\"doi\":\"10.1007/978-3-030-01174-1_60\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c2777a8ca7447764e51a4b2498a7a6157f76da37\",\"title\":\"Multimodal Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/c2777a8ca7447764e51a4b2498a7a6157f76da37\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1606.05433\",\"authors\":[{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"121177698\",\"name\":\"A. Dick\"},{\"authorId\":\"133678193\",\"name\":\"A. van den Hengel\"}],\"doi\":\"10.1109/TPAMI.2017.2754246\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b60630911d7746fba06de7c34abe98c9a61c6bcc\",\"title\":\"FVQA: Fact-Based Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b60630911d7746fba06de7c34abe98c9a61c6bcc\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":\"1608.03410\",\"authors\":[{\"authorId\":\"2087226\",\"name\":\"T. Tommasi\"},{\"authorId\":\"36508529\",\"name\":\"Arun Mallya\"},{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.5244/C.30.77\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"95f0125e6dda6c0028e09e814a7aaae5ef4922a4\",\"title\":\"Solving VIsual Madlibs with Multiple Cues\",\"url\":\"https://www.semanticscholar.org/paper/95f0125e6dda6c0028e09e814a7aaae5ef4922a4\",\"venue\":\"BMVC\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2346355\",\"name\":\"Ashish Bora\"},{\"authorId\":\"50292393\",\"name\":\"A. Sinha\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ddbfea5302fcb5cbc2ca4c498a592ddb063b9eff\",\"title\":\"L OW SUPERVISION VISUAL LEARNING THROUGH COOPERATIVE AGENTS\",\"url\":\"https://www.semanticscholar.org/paper/ddbfea5302fcb5cbc2ca4c498a592ddb063b9eff\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"133678193\",\"name\":\"A. van den Hengel\"}],\"doi\":\"10.1109/MSP.2017.2739826\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"141c9f6817331a6f3cccf82ebda5c8fd66c88b98\",\"title\":\"Visual Question Answering: A Tutorial\",\"url\":\"https://www.semanticscholar.org/paper/141c9f6817331a6f3cccf82ebda5c8fd66c88b98\",\"venue\":\"IEEE Signal Processing Magazine\",\"year\":2017},{\"arxivId\":\"1901.04870\",\"authors\":[{\"authorId\":\"9947690\",\"name\":\"Pongsate Tangseng\"},{\"authorId\":\"1718872\",\"name\":\"Takayuki Okatani\"}],\"doi\":\"10.1109/WACV45572.2020.9093367\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"432c680158205214ef086c8ee98ac9e530c41aa8\",\"title\":\"Toward Explainable Fashion Recommendation\",\"url\":\"https://www.semanticscholar.org/paper/432c680158205214ef086c8ee98ac9e530c41aa8\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"100768233\",\"name\":\"Daniel Dorda\"},{\"authorId\":\"1557273753\",\"name\":\"Moin Nabi\"}],\"doi\":\"10.1109/ICCVW.2019.00219\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ade6a89428219a38c69fa869efd0d2f24e9a8172\",\"title\":\"SynthRel0: Towards a Diagnostic Dataset for Relational Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/ade6a89428219a38c69fa869efd0d2f24e9a8172\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1804.09412\",\"authors\":[{\"authorId\":\"49292319\",\"name\":\"Bo Wang\"},{\"authorId\":\"3429960\",\"name\":\"Youjiang Xu\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"48043335\",\"name\":\"R. Hong\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e5c7798293f8325bbe8d92b185c99a7c7662e330\",\"title\":\"Movie Question Answering: Remembering the Textual Cues for Layered Visual Contents\",\"url\":\"https://www.semanticscholar.org/paper/e5c7798293f8325bbe8d92b185c99a7c7662e330\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1859204\",\"name\":\"Seyed Amin Khatami\"},{\"authorId\":\"9011967\",\"name\":\"Parham M. Kebria\"},{\"authorId\":\"51295354\",\"name\":\"Seyed Mohammad Jafar Jalali\"},{\"authorId\":\"145434108\",\"name\":\"A. Khosravi\"},{\"authorId\":\"2118338\",\"name\":\"A. Nazari\"},{\"authorId\":\"1443781526\",\"name\":\"Marjan Shamszadeh\"},{\"authorId\":\"1410115152\",\"name\":\"Thanh Nguyen\"},{\"authorId\":\"1743136\",\"name\":\"S. Nahavandi\"}],\"doi\":\"10.1109/SMC.2019.8914557\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1840a4d18f77039bb177c9f40911f043273eceaa\",\"title\":\"A GA-Based Pruning Fully Connected Network for Tuned Connections in Deep Networks\",\"url\":\"https://www.semanticscholar.org/paper/1840a4d18f77039bb177c9f40911f043273eceaa\",\"venue\":\"2019 IEEE International Conference on Systems, Man and Cybernetics (SMC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1581441035\",\"name\":\"Afrae Bghiel\"},{\"authorId\":\"1581444871\",\"name\":\"Yousra Dahdouh\"},{\"authorId\":\"51162320\",\"name\":\"Imane Allaouzi\"},{\"authorId\":\"143678432\",\"name\":\"M. Ahmed\"},{\"authorId\":\"47708727\",\"name\":\"A. Boudhir\"}],\"doi\":\"10.1007/978-3-030-37629-1_35\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1ba86d31844d9a1bb1c26928f555025508e7f963\",\"title\":\"Visual Question Answering System for Identifying Medical Images Attributes\",\"url\":\"https://www.semanticscholar.org/paper/1ba86d31844d9a1bb1c26928f555025508e7f963\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145327287\",\"name\":\"Y. Jing\"},{\"authorId\":\"46583706\",\"name\":\"J. Wang\"},{\"authorId\":\"41173169\",\"name\":\"W. Wang\"},{\"authorId\":\"97846606\",\"name\":\"L. Wang\"},{\"authorId\":\"145808910\",\"name\":\"Tieniu Tan\"}],\"doi\":\"10.1016/j.patcog.2020.107544\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"264e4e8a0c876774053e85ec8c9f8ceb6e29e311\",\"title\":\"Relational graph neural network for situation recognition\",\"url\":\"https://www.semanticscholar.org/paper/264e4e8a0c876774053e85ec8c9f8ceb6e29e311\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1412530617\",\"name\":\"Aisha Al-Sadi\"},{\"authorId\":\"1409942322\",\"name\":\"Hana' Al-Theiabat\"},{\"authorId\":\"1398466553\",\"name\":\"Mahmoud Al-Ayyoub\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5c01315f0840d8bead978cd9a9cb4c21f0400805\",\"title\":\"The Inception Team at VQA-Med 2020: Pretrained VGG with Data Augmentation for Medical VQA and VQG\",\"url\":\"https://www.semanticscholar.org/paper/5c01315f0840d8bead978cd9a9cb4c21f0400805\",\"venue\":\"CLEF\",\"year\":2020},{\"arxivId\":\"1612.05386\",\"authors\":[{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2017.416\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7d52fa1a9021d3596930ad2d5121e9d125113ab2\",\"title\":\"The VQA-Machine: Learning How to Use Existing Vision Algorithms to Answer New Questions\",\"url\":\"https://www.semanticscholar.org/paper/7d52fa1a9021d3596930ad2d5121e9d125113ab2\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1704.02516\",\"authors\":[{\"authorId\":\"21810992\",\"name\":\"Santhosh K. Ramakrishnan\"},{\"authorId\":\"2311107\",\"name\":\"Ambar Pal\"},{\"authorId\":\"144054467\",\"name\":\"G. Sharma\"},{\"authorId\":\"50853059\",\"name\":\"Anurag Mittal\"}],\"doi\":\"10.1109/CVPR.2017.773\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"6e77e651f44a11c7c3a459c7dfcdfabba0fb6891\",\"title\":\"An Empirical Evaluation of Visual Question Answering for Novel Objects\",\"url\":\"https://www.semanticscholar.org/paper/6e77e651f44a11c7c3a459c7dfcdfabba0fb6891\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9515493\",\"name\":\"Liangfu Cao\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"47158869\",\"name\":\"Xing Xu\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1007/978-3-319-68155-9_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"47d76f7c19c53a83704fa8c91d88add93c5654d1\",\"title\":\"Jointly Learning Attentions with Semantic Cross-Modal Correlation for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/47d76f7c19c53a83704fa8c91d88add93c5654d1\",\"venue\":\"ADC\",\"year\":2017},{\"arxivId\":\"1811.02234\",\"authors\":[{\"authorId\":\"7808048\",\"name\":\"M. Bucher\"},{\"authorId\":\"1924996\",\"name\":\"S. Herbin\"},{\"authorId\":\"82117876\",\"name\":\"F. Jurie\"}],\"doi\":\"10.1007/978-3-030-20890-5_44\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ca4eb45862a7153e6264bc96a400508d94c9d7ef\",\"title\":\"Semantic bottleneck for computer vision tasks\",\"url\":\"https://www.semanticscholar.org/paper/ca4eb45862a7153e6264bc96a400508d94c9d7ef\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"1610.02391\",\"authors\":[{\"authorId\":\"35100058\",\"name\":\"R. R. Selvaraju\"},{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"144354133\",\"name\":\"Michael Cogswell\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-019-01228-7\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e7eef2ac4136ec93bd306d2c9c353a13729a4553\",\"title\":\"Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization\",\"url\":\"https://www.semanticscholar.org/paper/e7eef2ac4136ec93bd306d2c9c353a13729a4553\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"1910.09134\",\"authors\":[{\"authorId\":\"2674321\",\"name\":\"Jiaying Lu\"},{\"authorId\":\"153031206\",\"name\":\"Xin Ye\"},{\"authorId\":\"71048893\",\"name\":\"Yi Ren\"},{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"58f78833c64750122ad21f79f2f53db37141237d\",\"title\":\"Good, Better, Best: Textual Distractors Generation for Multi-Choice VQA via Policy Gradient\",\"url\":\"https://www.semanticscholar.org/paper/58f78833c64750122ad21f79f2f53db37141237d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3368782\",\"name\":\"Yuetan Lin\"},{\"authorId\":\"7372283\",\"name\":\"Zhangyang Pang\"},{\"authorId\":\"1691826\",\"name\":\"Y. Li\"},{\"authorId\":\"144199812\",\"name\":\"D. Wang\"}],\"doi\":\"10.1109/ICIP.2016.7532764\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"940c42892bc5b012be2b2ac7421ccb15005781e6\",\"title\":\"Simple and effective visual question answering in a single modality\",\"url\":\"https://www.semanticscholar.org/paper/940c42892bc5b012be2b2ac7421ccb15005781e6\",\"venue\":\"2016 IEEE International Conference on Image Processing (ICIP)\",\"year\":2016},{\"arxivId\":\"1708.01471\",\"authors\":[{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"},{\"authorId\":\"50812077\",\"name\":\"J. Yu\"},{\"authorId\":\"144147221\",\"name\":\"Jianping Fan\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/ICCV.2017.202\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8e9ad6f8b2bc97f0412fa0cc243ac6975864534a\",\"title\":\"Multi-modal Factorized Bilinear Pooling with Co-attention Learning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8e9ad6f8b2bc97f0412fa0cc243ac6975864534a\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1703.06246\",\"authors\":[{\"authorId\":\"3194022\",\"name\":\"Bohan Zhuang\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f95f45b8e4d99175f8c68bb539231d82846d5f0b\",\"title\":\"Towards Context-aware Interaction Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f95f45b8e4d99175f8c68bb539231d82846d5f0b\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1996209\",\"name\":\"Davide Modolo\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2e27849ee6e7663410ca965e1ef4ab67ea6b3dca\",\"title\":\"Advances in detecting object classes and their semantic parts\",\"url\":\"https://www.semanticscholar.org/paper/2e27849ee6e7663410ca965e1ef4ab67ea6b3dca\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"16149902\",\"name\":\"Janani Ramaswamy\"},{\"authorId\":\"144009889\",\"name\":\"Sukhendu Das\"}],\"doi\":\"10.1109/WACV45572.2020.9093616\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c911d81bddb48490a02258e79379b6428246ddc2\",\"title\":\"See the Sound, Hear the Pixels\",\"url\":\"https://www.semanticscholar.org/paper/c911d81bddb48490a02258e79379b6428246ddc2\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2227139\",\"name\":\"J. Keller\"},{\"authorId\":\"98579522\",\"name\":\"D. Liu\"},{\"authorId\":\"144330013\",\"name\":\"D. Fogel\"}],\"doi\":\"10.1007/978-3-030-14596-5_7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a92fa27f5342aee919d54e9e8bce5125aa4fcc1c\",\"title\":\"Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/a92fa27f5342aee919d54e9e8bce5125aa4fcc1c\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1912.01452\",\"authors\":[{\"authorId\":\"50535497\",\"name\":\"Jiahong Huang\"},{\"authorId\":\"9951160\",\"name\":\"Modar Alfadly\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"1717056\",\"name\":\"M. Worring\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"01aa5668a618fbb376b6ab6608defc074ed355ac\",\"title\":\"Assessing the Robustness of Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/01aa5668a618fbb376b6ab6608defc074ed355ac\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1611.05118\",\"authors\":[{\"authorId\":\"2136562\",\"name\":\"Mohit Iyyer\"},{\"authorId\":\"1977256\",\"name\":\"V. Manjunatha\"},{\"authorId\":\"2220994\",\"name\":\"A. Guha\"},{\"authorId\":\"2065005\",\"name\":\"Yogarshi Vyas\"},{\"authorId\":\"1409929082\",\"name\":\"Jordan L. Boyd-Graber\"},{\"authorId\":\"145432949\",\"name\":\"Hal Daum'e\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/CVPR.2017.686\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bf63276c90a803fe0d069ce0a3a4a8236e756363\",\"title\":\"The Amazing Mysteries of the Gutter: Drawing Inferences Between Panels in Comic Book Narratives\",\"url\":\"https://www.semanticscholar.org/paper/bf63276c90a803fe0d069ce0a3a4a8236e756363\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40269075\",\"name\":\"R. Burt\"},{\"authorId\":\"20600120\",\"name\":\"Mihael Cudic\"},{\"authorId\":\"143961030\",\"name\":\"J. Pr\\u00edncipe\"}],\"doi\":\"10.1109/IJCNN.2017.7965954\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"72a2b7e46c51cd65810c9b511996a1776405eec8\",\"title\":\"Fusing attention with visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/72a2b7e46c51cd65810c9b511996a1776405eec8\",\"venue\":\"2017 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2017},{\"arxivId\":\"1703.09684\",\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1109/ICCV.2017.217\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"915b5b12f9bdebc321e970ecd713458c3479d70e\",\"title\":\"An Analysis of Visual Question Answering Algorithms\",\"url\":\"https://www.semanticscholar.org/paper/915b5b12f9bdebc321e970ecd713458c3479d70e\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"2006.09073\",\"authors\":[{\"authorId\":\"49659134\",\"name\":\"Zihao Zhu\"},{\"authorId\":\"119883573\",\"name\":\"J. Yu\"},{\"authorId\":\"46394401\",\"name\":\"Yujing Wang\"},{\"authorId\":\"15087270\",\"name\":\"Yajing Sun\"},{\"authorId\":\"1581498565\",\"name\":\"Yue Hu\"},{\"authorId\":\"1509240145\",\"name\":\"Qi Wu\"}],\"doi\":\"10.24963/ijcai.2020/153\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6b13065b4050800e30bb74e010b8aaba3355525d\",\"title\":\"Mucko: Multi-Layer Cross-Modal Knowledge Reasoning for Fact-based Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/6b13065b4050800e30bb74e010b8aaba3355525d\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":\"1804.01452\",\"authors\":[{\"authorId\":\"30507748\",\"name\":\"David Harwath\"},{\"authorId\":\"39257069\",\"name\":\"A. Recasens\"},{\"authorId\":\"35399640\",\"name\":\"D\\u00eddac Sur\\u00eds\"},{\"authorId\":\"2213197\",\"name\":\"Galen Chuang\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"}],\"doi\":\"10.1007/978-3-030-01231-1_40\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7dcaf1ef07a593a987f3b529c2ad1e977c0c7196\",\"title\":\"Jointly Discovering Visual Objects and Spoken Words from Raw Sensory Input\",\"url\":\"https://www.semanticscholar.org/paper/7dcaf1ef07a593a987f3b529c2ad1e977c0c7196\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1711.06666\",\"authors\":[{\"authorId\":\"9085797\",\"name\":\"Keren Ye\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":\"10.1007/978-3-030-01267-0_51\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e1be2c16060974f66e5366872ebbee21325075e8\",\"title\":\"ADVISE: Symbolism and External Knowledge for Decoding Advertisements\",\"url\":\"https://www.semanticscholar.org/paper/e1be2c16060974f66e5366872ebbee21325075e8\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1803.11544\",\"authors\":[{\"authorId\":\"49359942\",\"name\":\"C. Rupprecht\"},{\"authorId\":\"3422200\",\"name\":\"I. Laina\"},{\"authorId\":\"145587210\",\"name\":\"Nassir Navab\"},{\"authorId\":\"1678633\",\"name\":\"Gregory Hager\"},{\"authorId\":\"2266326\",\"name\":\"Federico Tombari\"}],\"doi\":\"10.1109/CVPR.2018.00892\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a334442b493501bb60a53dc3e689fc569965ad81\",\"title\":\"Guide Me: Interacting with Deep Networks\",\"url\":\"https://www.semanticscholar.org/paper/a334442b493501bb60a53dc3e689fc569965ad81\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1705.01359\",\"authors\":[{\"authorId\":\"145543514\",\"name\":\"Ravi Shekhar\"},{\"authorId\":\"3422247\",\"name\":\"Sandro Pezzelle\"},{\"authorId\":\"13597291\",\"name\":\"Yauhen Klimovich\"},{\"authorId\":\"3352951\",\"name\":\"Aur\\u00e9lie Herbelot\"},{\"authorId\":\"1848946\",\"name\":\"Moin Nabi\"},{\"authorId\":\"1716310\",\"name\":\"E. Sangineto\"},{\"authorId\":\"145040726\",\"name\":\"R. Bernardi\"}],\"doi\":\"10.18653/v1/P17-1024\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c86ce9fc2bd5aea98869cf1f31d03e05e7ec672c\",\"title\":\"FOIL it! Find One mismatch between Image and Language caption\",\"url\":\"https://www.semanticscholar.org/paper/c86ce9fc2bd5aea98869cf1f31d03e05e7ec672c\",\"venue\":\"ACL\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145344058\",\"name\":\"Tianyuan Yu\"},{\"authorId\":\"144769215\",\"name\":\"L. Bai\"},{\"authorId\":\"1805712\",\"name\":\"Jinlin Guo\"},{\"authorId\":\"40176711\",\"name\":\"Z. Yang\"},{\"authorId\":\"2248082\",\"name\":\"Yuxiang Xie\"}],\"doi\":\"10.1007/978-3-319-51814-5_12\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"928ea01af67dcbb416879f016cad69cd81bf9f4c\",\"title\":\"Deep Convolutional Neural Network for Bidirectional Image-Sentence Mapping\",\"url\":\"https://www.semanticscholar.org/paper/928ea01af67dcbb416879f016cad69cd81bf9f4c\",\"venue\":\"MMM\",\"year\":2017},{\"arxivId\":\"1708.03619\",\"authors\":[{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"},{\"authorId\":\"50812077\",\"name\":\"J. Yu\"},{\"authorId\":\"24071345\",\"name\":\"Chenchao Xiang\"},{\"authorId\":\"144147221\",\"name\":\"Jianping Fan\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/TNNLS.2018.2817340\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0c0f41d3162e76500d4639557ff4463bd246e395\",\"title\":\"Beyond Bilinear: Generalized Multimodal Factorized High-Order Pooling for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0c0f41d3162e76500d4639557ff4463bd246e395\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2018},{\"arxivId\":\"1705.09406\",\"authors\":[{\"authorId\":\"11138090\",\"name\":\"Tadas Baltru\\u0161aitis\"},{\"authorId\":\"118242121\",\"name\":\"Chaitanya Ahuja\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.1109/TPAMI.2018.2798607\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6bc4b1376ec2812b6d752c4f6bc8d8fd0512db91\",\"title\":\"Multimodal Machine Learning: A Survey and Taxonomy\",\"url\":\"https://www.semanticscholar.org/paper/6bc4b1376ec2812b6d752c4f6bc8d8fd0512db91\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":\"1702.06700\",\"authors\":[{\"authorId\":\"3368782\",\"name\":\"Yuetan Lin\"},{\"authorId\":\"7372283\",\"name\":\"Zhangyang Pang\"},{\"authorId\":\"144199812\",\"name\":\"D. Wang\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2385007824daaf9eac9476fccb1501b7ac166ceb\",\"title\":\"Task-driven Visual Saliency and Attention-based Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2385007824daaf9eac9476fccb1501b7ac166ceb\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47908786\",\"name\":\"Y. Liu\"},{\"authorId\":\"1687503\",\"name\":\"Yanming Guo\"},{\"authorId\":\"143866184\",\"name\":\"E. Bakker\"},{\"authorId\":\"1731570\",\"name\":\"M. Lew\"}],\"doi\":\"10.1109/ICCV.2017.442\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"90208e8cbda1f39f3d06e41d97898408b13192a7\",\"title\":\"Learning a Recurrent Residual Fusion Network for Multimodal Matching\",\"url\":\"https://www.semanticscholar.org/paper/90208e8cbda1f39f3d06e41d97898408b13192a7\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39685222\",\"name\":\"Lijun Chen\"},{\"authorId\":\"8194130\",\"name\":\"Qinyu Li\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"1696966\",\"name\":\"Y. Long\"}],\"doi\":\"10.1109/BigComp.2018.00087\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8cbee37fdc2353e93494a687ceddfdce2ad71e85\",\"title\":\"Static Correlative Filter Based Convolutional Neural Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8cbee37fdc2353e93494a687ceddfdce2ad71e85\",\"venue\":\"2018 IEEE International Conference on Big Data and Smart Computing (BigComp)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3103159\",\"name\":\"M. I. H. Chowdhury\"},{\"authorId\":\"145025159\",\"name\":\"K. Nguyen\"},{\"authorId\":\"1729760\",\"name\":\"S. Sridharan\"},{\"authorId\":\"3140440\",\"name\":\"C. Fookes\"}],\"doi\":\"10.1109/ICIP.2018.8451103\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"62504a1faaff417b275c6c68835ed024136a9eef\",\"title\":\"Hierarchical Relational Attention for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/62504a1faaff417b275c6c68835ed024136a9eef\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":\"1812.01776\",\"authors\":[{\"authorId\":\"50564124\",\"name\":\"D. Crankshaw\"},{\"authorId\":\"34741544\",\"name\":\"Gur-Eyal Sela\"},{\"authorId\":\"52145600\",\"name\":\"Corey Zumar\"},{\"authorId\":\"145272357\",\"name\":\"Xiangxi Mo\"},{\"authorId\":\"144307989\",\"name\":\"J. Gonzalez\"},{\"authorId\":\"1716557\",\"name\":\"I. Stoica\"},{\"authorId\":\"144312193\",\"name\":\"Alexey Tumanov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3873f819da0a78d95f75049c0e715ba48aad3021\",\"title\":\"InferLine: ML Prediction Pipeline Provisioning and Management for Tight Latency Objectives\",\"url\":\"https://www.semanticscholar.org/paper/3873f819da0a78d95f75049c0e715ba48aad3021\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"86912250\",\"name\":\"Peixi Xiong\"},{\"authorId\":\"145074713\",\"name\":\"Ying Wu\"}],\"doi\":\"10.1109/cvpr42600.2020.01008\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"ed212b4c747d35e284e8874c38cd0b855cd98f66\",\"title\":\"TA-Student VQA: Multi-Agents Training by Self-Questioning\",\"url\":\"https://www.semanticscholar.org/paper/ed212b4c747d35e284e8874c38cd0b855cd98f66\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2706269\",\"name\":\"Chengxiang Yin\"},{\"authorId\":\"152949437\",\"name\":\"Jian Tang\"},{\"authorId\":\"48559420\",\"name\":\"Zhiyuan Xu\"},{\"authorId\":null,\"name\":\"Yanzhi Wang\"}],\"doi\":\"10.1109/TNNLS.2019.2938015\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d796ff29f8798c418d5374a6632231f02233dbba\",\"title\":\"Memory Augmented Deep Recurrent Neural Network for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d796ff29f8798c418d5374a6632231f02233dbba\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1519063133\",\"name\":\"Jianing Zhang\"},{\"authorId\":\"2035523498\",\"name\":\"Zhaochang Wu\"},{\"authorId\":null,\"name\":\"Huajie Zhang\"},{\"authorId\":\"47558930\",\"name\":\"Yunfang Chen\"}],\"doi\":\"10.1088/1742-6596/1624/2/022022\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2d9c51318eab259d038495fd7f76321971bb104f\",\"title\":\"Visual Question Answering Based on Question Attention Model\",\"url\":\"https://www.semanticscholar.org/paper/2d9c51318eab259d038495fd7f76321971bb104f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2712862\",\"name\":\"D. Zhang\"},{\"authorId\":\"145690873\",\"name\":\"R. Cao\"},{\"authorId\":\"1765710\",\"name\":\"Sai Wu\"}],\"doi\":\"10.1016/J.INFFUS.2019.03.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"91118408f8192c2addade2a0401a32c3bbd47818\",\"title\":\"Information fusion in visual question answering: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/91118408f8192c2addade2a0401a32c3bbd47818\",\"venue\":\"Inf. Fusion\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2087226\",\"name\":\"T. Tommasi\"},{\"authorId\":\"36508529\",\"name\":\"Arun Mallya\"},{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1007/s11263-018-1096-0\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6f8ea6c3d195b92a92005f993aa98b98b069d10d\",\"title\":\"Combining Multiple Cues for Visual Madlibs Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/6f8ea6c3d195b92a92005f993aa98b98b069d10d\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018},{\"arxivId\":\"1511.05676\",\"authors\":[{\"authorId\":\"3335651\",\"name\":\"Aiwen Jiang\"},{\"authorId\":\"7572514\",\"name\":\"Fang Wang\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"},{\"authorId\":\"47001807\",\"name\":\"Y. Li\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3d1382fa43c31e594ed2d84dda9984b1db047b0e\",\"title\":\"Compositional Memory for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/3d1382fa43c31e594ed2d84dda9984b1db047b0e\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1608.08974\",\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"2884573\",\"name\":\"Akrit Mohapatra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f8645f298cc67a7ab751488f3945dc1beaffe8da\",\"title\":\"Towards Transparent AI Systems: Interpreting Visual Question Answering Models\",\"url\":\"https://www.semanticscholar.org/paper/f8645f298cc67a7ab751488f3945dc1beaffe8da\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1821267\",\"name\":\"A. Gordo\"},{\"authorId\":\"2295553\",\"name\":\"Diane Larlus\"}],\"doi\":\"10.1109/CVPR.2017.560\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cb3e81b912f24e66d91509e8ab41d09b522a397a\",\"title\":\"Beyond Instance-Level Image Retrieval: Leveraging Captions to Learn a Global Visual Representation for Semantic Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/cb3e81b912f24e66d91509e8ab41d09b522a397a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1708.01336\",\"authors\":[{\"authorId\":\"144811744\",\"name\":\"L. Jiang\"},{\"authorId\":\"1915796\",\"name\":\"Junwei Liang\"},{\"authorId\":\"48749954\",\"name\":\"L. Cao\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"3256430\",\"name\":\"Sachin Farfade\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ceac30061d8f7985987448f4712c49eeb98efad2\",\"title\":\"MemexQA: Visual Memex Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ceac30061d8f7985987448f4712c49eeb98efad2\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"39efe4ac24f9f1a9b68e210b84a3432505cfcac2\",\"title\":\"Story Understanding through Semantic Analysis and Automatic Alignment of Text and Video\",\"url\":\"https://www.semanticscholar.org/paper/39efe4ac24f9f1a9b68e210b84a3432505cfcac2\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48447789\",\"name\":\"Jens Nevens\"},{\"authorId\":\"150266649\",\"name\":\"Paul Van Eecke\"},{\"authorId\":\"2972424\",\"name\":\"Katrien Beuls\"}],\"doi\":\"10.1515/lingvan-2018-0070\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f388721a2b76e18f5515e599509d4504729f847e\",\"title\":\"Computational construction grammar for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/f388721a2b76e18f5515e599509d4504729f847e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1805.08969\",\"authors\":[{\"authorId\":\"47871644\",\"name\":\"Pei Guo\"},{\"authorId\":\"24884535\",\"name\":\"C. Anderson\"},{\"authorId\":\"46199465\",\"name\":\"Kolten Pearson\"},{\"authorId\":\"49791682\",\"name\":\"Ryan Farrell\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4a223fc8cd3e7ca19255ff31a3494fedb09c7bfd\",\"title\":\"Neural Network Interpretation via Fine Grained Textual Summarization\",\"url\":\"https://www.semanticscholar.org/paper/4a223fc8cd3e7ca19255ff31a3494fedb09c7bfd\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2037988\",\"name\":\"Weichen Sun\"},{\"authorId\":\"144310030\",\"name\":\"F. Su\"}],\"doi\":\"10.1016/j.imavis.2016.11.012\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"93ed1a1e9619c0f8a581df2cabf26e4bd1c404fc\",\"title\":\"A novel companion objective function for regularization of deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/93ed1a1e9619c0f8a581df2cabf26e4bd1c404fc\",\"venue\":\"Image Vis. Comput.\",\"year\":2017},{\"arxivId\":\"1511.07067\",\"authors\":[{\"authorId\":\"2150275\",\"name\":\"S. Kottur\"},{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"144915495\",\"name\":\"Jos\\u00e9 M. F. Moura\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2016.539\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"06599d41a3256245aa0cb2e9e56b29459c2e2c69\",\"title\":\"VisualWord2Vec (Vis-W2V): Learning Visually Grounded Word Embeddings Using Abstract Scenes\",\"url\":\"https://www.semanticscholar.org/paper/06599d41a3256245aa0cb2e9e56b29459c2e2c69\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145264918\",\"name\":\"Jing Zhu\"},{\"authorId\":\"144826941\",\"name\":\"J. Rizzo\"},{\"authorId\":\"144145642\",\"name\":\"Y. Fang\"}],\"doi\":\"10.1016/j.patrec.2017.09.041\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"34b5a50b02909e5b9bf2cb82b14cbd22929a852e\",\"title\":\"Learning domain-invariant feature for robust depth-image-based 3D shape retrieval\",\"url\":\"https://www.semanticscholar.org/paper/34b5a50b02909e5b9bf2cb82b14cbd22929a852e\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1914578421\",\"name\":\"Sabarish Gopalakrishnan\"},{\"authorId\":\"1921418752\",\"name\":\"Premkumar Udaiyar\"},{\"authorId\":\"3424086\",\"name\":\"S. Sah\"},{\"authorId\":\"1404315481\",\"name\":\"Raymond Ptucha\"}],\"doi\":\"10.1109/AIPR47015.2019.9174583\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c29d8cc9a6dcf55c4b624d607f61301a29d68861\",\"title\":\"Multi Stage Common Vector Space for Multimodal Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/c29d8cc9a6dcf55c4b624d607f61301a29d68861\",\"venue\":\"2019 IEEE Applied Imagery Pattern Recognition Workshop (AIPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47739808\",\"name\":\"Junkun Chen\"},{\"authorId\":\"1767521\",\"name\":\"Xipeng Qiu\"},{\"authorId\":\"144118452\",\"name\":\"Pengfei Liu\"},{\"authorId\":\"144052385\",\"name\":\"X. Huang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3468740e4a9fc72a269f4f0ca8470ccd60925f92\",\"title\":\"2019 Formatting Instructions for Authors Using LaTeX\",\"url\":\"https://www.semanticscholar.org/paper/3468740e4a9fc72a269f4f0ca8470ccd60925f92\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49229373\",\"name\":\"N. Liu\"},{\"authorId\":\"1728316\",\"name\":\"K. Wang\"},{\"authorId\":\"50562622\",\"name\":\"X. Jin\"},{\"authorId\":\"1721208\",\"name\":\"Boyang Gao\"},{\"authorId\":\"1718878\",\"name\":\"E. Dellandr\\u00e9a\"},{\"authorId\":\"47818198\",\"name\":\"L. Chen\"}],\"doi\":\"10.1371/journal.pone.0183018\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3a60d4d4706cbd3e630a5ba551b6db6a907d139e\",\"title\":\"Visual affective classification by combining visual and text features\",\"url\":\"https://www.semanticscholar.org/paper/3a60d4d4706cbd3e630a5ba551b6db6a907d139e\",\"venue\":\"PloS one\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2670451\",\"name\":\"E. Kapetanios\"},{\"authorId\":\"145314602\",\"name\":\"Saad A. Alshahrani\"},{\"authorId\":\"90125171\",\"name\":\"Anastasia Angelopoulou\"},{\"authorId\":\"144219177\",\"name\":\"M. Baldwin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"083846768be3d043a8ccb81bf4372f695789eda9\",\"title\":\"1 What do we learn from word associations ? Evaluating 2 machine learning algorithms for the extraction of 3 contextual word meaning in natural language 4 processing 5\",\"url\":\"https://www.semanticscholar.org/paper/083846768be3d043a8ccb81bf4372f695789eda9\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1806.04860\",\"authors\":[{\"authorId\":\"47008023\",\"name\":\"Z. Su\"},{\"authorId\":\"144469723\",\"name\":\"C. Zhu\"},{\"authorId\":\"3431029\",\"name\":\"Y. Dong\"},{\"authorId\":\"1751449\",\"name\":\"Dongqi Cai\"},{\"authorId\":\"6060281\",\"name\":\"Y. Chen\"},{\"authorId\":\"46277052\",\"name\":\"J. Li\"}],\"doi\":\"10.1109/CVPR.2018.00807\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"33f08157b959070ba802afbb135f4336c5a426fd\",\"title\":\"Learning Visual Knowledge Memory Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/33f08157b959070ba802afbb135f4336c5a426fd\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1803.11186\",\"authors\":[{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1109/CVPR.2018.00603\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"36bb1983dceb84f33d9adcf4ef032c9b0aeed1e4\",\"title\":\"Two Can Play This Game: Visual Dialog with Discriminative Question Generation and Answering\",\"url\":\"https://www.semanticscholar.org/paper/36bb1983dceb84f33d9adcf4ef032c9b0aeed1e4\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145446752\",\"name\":\"Marie-Francine Moens\"}],\"doi\":\"10.3233/AAC-170025\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"19629ea1f85cf59adc189169b6b5b534c7e3125c\",\"title\":\"Argumentation mining: How can a machine acquire common sense and world knowledge?\",\"url\":\"https://www.semanticscholar.org/paper/19629ea1f85cf59adc189169b6b5b534c7e3125c\",\"venue\":\"Argument Comput.\",\"year\":2018},{\"arxivId\":\"1911.03977\",\"authors\":[{\"authorId\":\"145282222\",\"name\":\"C. Zhang\"},{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"144718783\",\"name\":\"Li Deng\"}],\"doi\":\"10.1109/JSTSP.2020.2987728\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"415efb7b4d9d1e5b64dbaf3fe4229ad462acce71\",\"title\":\"Multimodal Intelligence: Representation Learning, Information Fusion, and Applications\",\"url\":\"https://www.semanticscholar.org/paper/415efb7b4d9d1e5b64dbaf3fe4229ad462acce71\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020},{\"arxivId\":\"1706.02337\",\"authors\":[{\"authorId\":\"47009032\",\"name\":\"Xiaowei Yang\"},{\"authorId\":\"8020964\",\"name\":\"Ersin Yumer\"},{\"authorId\":\"2934421\",\"name\":\"Paul Asente\"},{\"authorId\":\"1389971134\",\"name\":\"Mike Kraley\"},{\"authorId\":\"1852261\",\"name\":\"D. Kifer\"},{\"authorId\":\"145157784\",\"name\":\"C. Lee Giles\"}],\"doi\":\"10.1109/CVPR.2017.462\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9baae0bdc2884bcf0aa4063914b87d60952cb678\",\"title\":\"Learning to Extract Semantic Structure from Documents Using Multimodal Fully Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/9baae0bdc2884bcf0aa4063914b87d60952cb678\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2223252\",\"name\":\"Y. Zhou\"},{\"authorId\":\"145592290\",\"name\":\"R. Ji\"},{\"authorId\":\"34739384\",\"name\":\"Jinsong Su\"},{\"authorId\":\"47096329\",\"name\":\"Yongjian Wu\"},{\"authorId\":\"10609538\",\"name\":\"Y. Wu\"}],\"doi\":\"10.1145/3123266.3123335\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b44999bb2e23cf8ca0a413a2d006cc9800794650\",\"title\":\"More Than An Answer: Neural Pivot Network for Visual Qestion Answering\",\"url\":\"https://www.semanticscholar.org/paper/b44999bb2e23cf8ca0a413a2d006cc9800794650\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11611009\",\"name\":\"Chun-ye Li\"},{\"authorId\":\"153043900\",\"name\":\"Zhi-Ping Zhou\"}],\"doi\":\"10.1145/3366194.3366252\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a1b51243d3612e18dd804b727d78b24fc6fb6dc3\",\"title\":\"Visual Question Answering with Dynamic Parameter Prediction using Functional Hashing\",\"url\":\"https://www.semanticscholar.org/paper/a1b51243d3612e18dd804b727d78b24fc6fb6dc3\",\"venue\":\"RICAI 2019\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"1776014\",\"name\":\"Ce Zhang\"},{\"authorId\":\"1803218\",\"name\":\"Christopher R\\u00e9\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"131125a5aadb48ec3eceb404cedbff713c401feb\",\"title\":\"Building a Large-scale Multimodal Knowledge Base System for Answering Visual Queries\",\"url\":\"https://www.semanticscholar.org/paper/131125a5aadb48ec3eceb404cedbff713c401feb\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"38666915\",\"name\":\"D. Klein\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0ac8f1a3c679b90d22c1f840cdc8d61ffef750ac\",\"title\":\"Deep Compositional Question Answering with Neural Module Networks\",\"url\":\"https://www.semanticscholar.org/paper/0ac8f1a3c679b90d22c1f840cdc8d61ffef750ac\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f55deed4fa5d6d806790610dad9cf7505c1adde8\",\"title\":\"Goal Driven Detection in Natural Scenes Anonymous\",\"url\":\"https://www.semanticscholar.org/paper/f55deed4fa5d6d806790610dad9cf7505c1adde8\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2028946\",\"name\":\"D. Gurari\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1145/3025453.3025781\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"25936a0b60af41d0679afcfc0c23ffed91ab3243\",\"title\":\"CrowdVerge: Predicting If People Will Agree on the Answer to a Visual Question\",\"url\":\"https://www.semanticscholar.org/paper/25936a0b60af41d0679afcfc0c23ffed91ab3243\",\"venue\":\"CHI\",\"year\":2017},{\"arxivId\":\"1606.03647\",\"authors\":[{\"authorId\":\"2018393\",\"name\":\"Hyeonwoo Noh\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b58e08741fb9803fa2a870eee139137d3bade332\",\"title\":\"Training Recurrent Answering Units with Joint Loss Minimization for VQA\",\"url\":\"https://www.semanticscholar.org/paper/b58e08741fb9803fa2a870eee139137d3bade332\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50564124\",\"name\":\"D. Crankshaw\"},{\"authorId\":\"34741544\",\"name\":\"Gur-Eyal Sela\"},{\"authorId\":\"145272357\",\"name\":\"Xiangxi Mo\"},{\"authorId\":\"52145600\",\"name\":\"Corey Zumar\"},{\"authorId\":\"1484048577\",\"name\":\"I. Stoica\"},{\"authorId\":\"49988044\",\"name\":\"Joseph E. Gonzalez\"},{\"authorId\":\"144312193\",\"name\":\"Alexey Tumanov\"}],\"doi\":\"10.1145/3419111.3421285\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7bb359b734643ebd8b1180128a1ad30b7c80a7d7\",\"title\":\"InferLine: latency-aware provisioning and scaling for prediction serving pipelines\",\"url\":\"https://www.semanticscholar.org/paper/7bb359b734643ebd8b1180128a1ad30b7c80a7d7\",\"venue\":\"SoCC\",\"year\":2020},{\"arxivId\":\"1712.03316\",\"authors\":[{\"authorId\":\"152462964\",\"name\":\"Daniel Gordon\"},{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"},{\"authorId\":\"143887493\",\"name\":\"M. Rastegari\"},{\"authorId\":\"40497777\",\"name\":\"Joseph Redmon\"},{\"authorId\":\"145197953\",\"name\":\"D. Fox\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"}],\"doi\":\"10.1109/CVPR.2018.00430\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b0cd469a06fb2eae3a5cc0c860aa592f71b13f6d\",\"title\":\"IQA: Visual Question Answering in Interactive Environments\",\"url\":\"https://www.semanticscholar.org/paper/b0cd469a06fb2eae3a5cc0c860aa592f71b13f6d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39744108\",\"name\":\"S. Aditya\"},{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"1760291\",\"name\":\"Chitta Baral\"},{\"authorId\":\"1697493\",\"name\":\"Y. Aloimonos\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7535a97bcb06b78531f95b7443671a2c0d319476\",\"title\":\"Combining Knowledge and Reasoning through Probabilistic Soft Logic for Image Puzzle Solving\",\"url\":\"https://www.semanticscholar.org/paper/7535a97bcb06b78531f95b7443671a2c0d319476\",\"venue\":\"UAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1915796\",\"name\":\"Junwei Liang\"},{\"authorId\":\"39978626\",\"name\":\"Lu Jiang\"},{\"authorId\":\"48749954\",\"name\":\"L. Cao\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1109/CVPR.2018.00642\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"72c16ae6969eda304f76af139e000e4cec34d564\",\"title\":\"Focal Visual-Text Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/72c16ae6969eda304f76af139e000e4cec34d564\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4942547\",\"name\":\"Zongjian Zhang\"},{\"authorId\":\"145698633\",\"name\":\"Q. Wu\"},{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"145093625\",\"name\":\"F. Chen\"}],\"doi\":\"10.1109/WACV.2018.00190\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6107d5107e7e0d94a3f0f43b642c4cfd1cba3b79\",\"title\":\"Fine-Grained and Semantic-Guided Visual Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6107d5107e7e0d94a3f0f43b642c4cfd1cba3b79\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":\"1611.05594\",\"authors\":[{\"authorId\":\"143891667\",\"name\":\"Long Chen\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1406012647\",\"name\":\"Jun Xiao\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":\"104757141\",\"name\":\"Jian Shao\"},{\"authorId\":\"40366581\",\"name\":\"Wei Liu\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1109/CVPR.2017.667\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"88513e738a95840de05a62f0e43d30a67b3c542e\",\"title\":\"SCA-CNN: Spatial and Channel-Wise Attention in Convolutional Networks for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/88513e738a95840de05a62f0e43d30a67b3c542e\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3449429\",\"name\":\"Alexander Kuhnle\"}],\"doi\":\"10.17863/CAM.49177\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c04262cb3f76ff769af32afad05263bd47ebef18\",\"title\":\"Evaluating visually grounded language capabilities using microworlds\",\"url\":\"https://www.semanticscholar.org/paper/c04262cb3f76ff769af32afad05263bd47ebef18\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1904.00623\",\"authors\":[{\"authorId\":\"15353659\",\"name\":\"Yu-Jung Heo\"},{\"authorId\":\"2943489\",\"name\":\"Kyoung-Woon On\"},{\"authorId\":\"7236400\",\"name\":\"S. Choi\"},{\"authorId\":\"70262116\",\"name\":\"Jaeseo Lim\"},{\"authorId\":\"7951400\",\"name\":\"J. Kim\"},{\"authorId\":\"89496405\",\"name\":\"Jeh-Kwang Ryu\"},{\"authorId\":\"39171461\",\"name\":\"B. Bae\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b27b6df500b4fc50092f22727a90111b2010a588\",\"title\":\"Constructing Hierarchical Q&A Datasets for Video Story Understanding\",\"url\":\"https://www.semanticscholar.org/paper/b27b6df500b4fc50092f22727a90111b2010a588\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1612.07833\",\"authors\":[{\"authorId\":\"145534769\",\"name\":\"N. Ding\"},{\"authorId\":\"7685850\",\"name\":\"Sebastian Goodman\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6edb41364802b0fdd1e3e98d644fe78b1ecbbe45\",\"title\":\"Understanding Image and Text Simultaneously: a Dual Vision-Language Machine Comprehension Task\",\"url\":\"https://www.semanticscholar.org/paper/6edb41364802b0fdd1e3e98d644fe78b1ecbbe45\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1705.02445\",\"authors\":[{\"authorId\":\"144442429\",\"name\":\"J. Martinez\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"},{\"authorId\":\"143881914\",\"name\":\"J. Romero\"}],\"doi\":\"10.1109/CVPR.2017.497\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7f065002afcb90240a41f05f138269c5675b9805\",\"title\":\"On Human Motion Prediction Using Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/7f065002afcb90240a41f05f138269c5675b9805\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1901.03788\",\"authors\":[{\"authorId\":\"144570826\",\"name\":\"Q. Yin\"},{\"authorId\":\"143627655\",\"name\":\"Guan Luo\"},{\"authorId\":\"145667261\",\"name\":\"Xiaodong Zhu\"},{\"authorId\":\"144281199\",\"name\":\"Q. Hu\"},{\"authorId\":\"143958958\",\"name\":\"O. Wu\"}],\"doi\":\"10.1007/978-3-030-16145-3_1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"117850e2109dcf916daa8fb1c8c3e459af505c4d\",\"title\":\"Semi-interactive Attention Network for Answer Understanding in Reverse-QA\",\"url\":\"https://www.semanticscholar.org/paper/117850e2109dcf916daa8fb1c8c3e459af505c4d\",\"venue\":\"PAKDD\",\"year\":2019},{\"arxivId\":\"1511.05234\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1007/978-3-319-46478-7_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1cf6bc0866226c1f8e282463adc8b75d92fba9bb\",\"title\":\"Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1cf6bc0866226c1f8e282463adc8b75d92fba9bb\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"2011.03322\",\"authors\":[{\"authorId\":\"2345018\",\"name\":\"Shen Gao\"},{\"authorId\":\"46772896\",\"name\":\"Xiuying Chen\"},{\"authorId\":\"87109212\",\"name\":\"Li Liu\"},{\"authorId\":\"9072379\",\"name\":\"Dongyan Zhao\"},{\"authorId\":\"1845885740\",\"name\":\"Rui Yan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"336cad600d15832243f4228b351c638630d64cb7\",\"title\":\"Learning to Respond with Your Favorite Stickers: A Framework of Unifying Multi-Modality and User Preference in Multi-Turn Dialog\",\"url\":\"https://www.semanticscholar.org/paper/336cad600d15832243f4228b351c638630d64cb7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1471721735\",\"name\":\"Umair Ahmad Khan\"},{\"authorId\":\"1409307726\",\"name\":\"Miguel \\u00c1. Mart\\u00ednez-Del-Amor\"},{\"authorId\":\"49912813\",\"name\":\"Saleh M. Altowaijri\"},{\"authorId\":\"144396106\",\"name\":\"A. Ahmed\"},{\"authorId\":\"3233695\",\"name\":\"A. Rahman\"},{\"authorId\":\"2234879\",\"name\":\"Najm Us Sama\"},{\"authorId\":\"48043100\",\"name\":\"K. Haseeb\"},{\"authorId\":\"50421651\",\"name\":\"Naveed Islam\"}],\"doi\":\"10.1109/ACCESS.2019.2963535\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5ffabdc4909395baa486fd56153b98911647e205\",\"title\":\"Movie Tags Prediction and Segmentation Using Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/5ffabdc4909395baa486fd56153b98911647e205\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41036094\",\"name\":\"C. Deng\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"8277017\",\"name\":\"Q. Wu\"},{\"authorId\":\"2348236\",\"name\":\"Fuyuan Hu\"},{\"authorId\":\"12358136\",\"name\":\"Fan Lyu\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"}],\"doi\":\"10.1109/CVPR.2018.00808\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"8d1c8dd0559642a3bdd5c7234d2ce4611e911e23\",\"title\":\"Visual Grounding via Accumulated Attention\",\"url\":\"https://www.semanticscholar.org/paper/8d1c8dd0559642a3bdd5c7234d2ce4611e911e23\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4247049\",\"name\":\"Jingyu Liu\"},{\"authorId\":\"39685680\",\"name\":\"Wei Wang\"},{\"authorId\":\"144143335\",\"name\":\"L. Wang\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/TIP.2020.2979010\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2d8e70022d5ee5cfd5a51f8d8bdba876ff6bda5f\",\"title\":\"Attribute-Guided Attention for Referring Expression Generation and Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/2d8e70022d5ee5cfd5a51f8d8bdba876ff6bda5f\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1576818877\",\"name\":\"Kento Terao\"},{\"authorId\":\"134811419\",\"name\":\"Toru Tamaki\"},{\"authorId\":\"1688940\",\"name\":\"B. Raytchev\"},{\"authorId\":\"1686272\",\"name\":\"K. Kaneda\"},{\"authorId\":\"144404414\",\"name\":\"S. Satoh\"}],\"doi\":\"10.1109/ACCESS.2020.3022063\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c7583d58aec662313bd5b0082b656d9f44956dc3\",\"title\":\"An Entropy Clustering Approach for Assessing Visual Question Difficulty\",\"url\":\"https://www.semanticscholar.org/paper/c7583d58aec662313bd5b0082b656d9f44956dc3\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1611.05546\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a8224266b8ab1483f6548307ab96227147f34da\",\"title\":\"Zero-Shot Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8a8224266b8ab1483f6548307ab96227147f34da\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"2884573\",\"name\":\"Akrit Mohapatra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"72cebd7d046080899703ed3cd96e3019a9f60f13\",\"title\":\"Interpreting Visual Question Answering Models\",\"url\":\"https://www.semanticscholar.org/paper/72cebd7d046080899703ed3cd96e3019a9f60f13\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6051714\",\"name\":\"G. Li\"},{\"authorId\":\"144904238\",\"name\":\"H. Su\"},{\"authorId\":\"145583986\",\"name\":\"Wenwu Zhu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"db6ad1e242c31c2fbd514cd71df904a8f96fba5f\",\"title\":\"Preserved Knowledge Embedding Question : Why does the person have an umbrella ? Answer : It is raining . Knowledge Incorporated Open-Domain VQA Candidate Knowledge Retrieval Dynamic Memory Network Memory Updating Attention Machanisim Query\",\"url\":\"https://www.semanticscholar.org/paper/db6ad1e242c31c2fbd514cd71df904a8f96fba5f\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1903.06994\",\"authors\":[{\"authorId\":\"86912250\",\"name\":\"Peixi Xiong\"},{\"authorId\":\"7573997\",\"name\":\"Huayi Zhan\"},{\"authorId\":null,\"name\":\"Xin Wang\"},{\"authorId\":\"67250414\",\"name\":\"B. Sinha\"},{\"authorId\":\"50118130\",\"name\":\"Y. Wu\"}],\"doi\":\"10.1109/CVPR.2019.00855\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6d9e326ff03bbaf6426bfb3a9331d49a24dc4e4c\",\"title\":\"Visual Query Answering by Entity-Attribute Graph Matching and Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/6d9e326ff03bbaf6426bfb3a9331d49a24dc4e4c\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4942547\",\"name\":\"Zongjian Zhang\"},{\"authorId\":\"144066903\",\"name\":\"Q. Wu\"},{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"145093625\",\"name\":\"F. Chen\"}],\"doi\":\"10.1109/TMM.2018.2888822\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2bc7959cf6bf0ae64f1a83f5fce1ac8cb2256ed3\",\"title\":\"High-Quality Image Captioning With Fine-Grained and Semantic-Guided Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/2bc7959cf6bf0ae64f1a83f5fce1ac8cb2256ed3\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145066124\",\"name\":\"Bin Guo\"},{\"authorId\":\"46506266\",\"name\":\"Haiying Wang\"},{\"authorId\":\"151260226\",\"name\":\"Yasan Ding\"},{\"authorId\":\"117889029\",\"name\":\"Shaoyang Hao\"},{\"authorId\":\"79953570\",\"name\":\"Yueqi Sun\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"891082eb8ec9796d9e6041a93c2dfcf1654daf76\",\"title\":\"1 c-TextGen : Conditional Text Generation for Harmonious Human-Machine Interaction\",\"url\":\"https://www.semanticscholar.org/paper/891082eb8ec9796d9e6041a93c2dfcf1654daf76\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145279549\",\"name\":\"Xiao Lin\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c822419edde10e21d4d0bb381d97c5f774dcfd19\",\"title\":\"Leveraging Multimodal Perspectives to Learn Common Sense for Vision and Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/c822419edde10e21d4d0bb381d97c5f774dcfd19\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1801.09041\",\"authors\":[{\"authorId\":\"48933900\",\"name\":\"Q. Li\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"2846025\",\"name\":\"D. Yu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.18653/v1/D18-1164\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dd2f8bb5fa881797fad0448547e307a18bf897da\",\"title\":\"Tell-and-Answer: Towards Explainable Visual Question Answering using Attributes and Captions\",\"url\":\"https://www.semanticscholar.org/paper/dd2f8bb5fa881797fad0448547e307a18bf897da\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"1711.07373\",\"authors\":[{\"authorId\":\"3422202\",\"name\":\"Dong Huk Park\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"2893664\",\"name\":\"Zeynep Akata\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dc07e7bf1cf25aab2c39c85ab03bf085bbca31b5\",\"title\":\"Attentive Explanations: Justifying Decisions and Pointing to the Evidence\",\"url\":\"https://www.semanticscholar.org/paper/dc07e7bf1cf25aab2c39c85ab03bf085bbca31b5\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1939569\",\"name\":\"Feiran Huang\"},{\"authorId\":\"1679013\",\"name\":\"X. Zhang\"},{\"authorId\":\"1707275\",\"name\":\"Zhoujun Li\"},{\"authorId\":\"144493052\",\"name\":\"Z. Zhao\"},{\"authorId\":\"2577617\",\"name\":\"Yueying He\"}],\"doi\":\"10.1016/j.knosys.2018.07.020\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"31c86b5fa148a8c8a0bf812721d0c6859de45200\",\"title\":\"From content to links: Social image embedding with deep multimodal model\",\"url\":\"https://www.semanticscholar.org/paper/31c86b5fa148a8c8a0bf812721d0c6859de45200\",\"venue\":\"Knowl. Based Syst.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49163024\",\"name\":\"Shuang Bai\"},{\"authorId\":\"3380543\",\"name\":\"S. An\"}],\"doi\":\"10.1016/j.neucom.2018.05.080\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fe66fc9e3d9a52497119bab89ac54fc8b5f8859a\",\"title\":\"A survey on automatic image caption generation\",\"url\":\"https://www.semanticscholar.org/paper/fe66fc9e3d9a52497119bab89ac54fc8b5f8859a\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":\"1511.02799\",\"authors\":[{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"38666915\",\"name\":\"D. Klein\"}],\"doi\":\"10.1109/CVPR.2016.12\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"21c99706bb26e9012bfb4d8d48009a3d45af59b2\",\"title\":\"Neural Module Networks\",\"url\":\"https://www.semanticscholar.org/paper/21c99706bb26e9012bfb4d8d48009a3d45af59b2\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1803.08896\",\"authors\":[{\"authorId\":\"39744108\",\"name\":\"S. Aditya\"},{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"1760291\",\"name\":\"Chitta Baral\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"0c41d7cfadcdaa5a66694bd57fa5eaf807043ef9\",\"title\":\"Explicit Reasoning over End-to-End Neural Architectures for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0c41d7cfadcdaa5a66694bd57fa5eaf807043ef9\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"118144862\",\"name\":\"Fidel Indalecio Mamani Maquera\"},{\"authorId\":\"114700029\",\"name\":\"E. C. Gutierrez\"},{\"authorId\":\"3427444\",\"name\":\"Alfredo Paz Valderrama\"}],\"doi\":\"10.18687/laccei2019.1.1.178\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5f5e0e56bf8a75c6b2a774daf7df807fbf737a2c\",\"title\":\"Performance Evaluation of Recurrent Neural Network on Large-Scale Translated Dataset for Question Generation in NLP for Educational Purposes\",\"url\":\"https://www.semanticscholar.org/paper/5f5e0e56bf8a75c6b2a774daf7df807fbf737a2c\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144774112\",\"name\":\"F. Liu\"},{\"authorId\":\"145406421\",\"name\":\"T. Xiang\"},{\"authorId\":\"1697755\",\"name\":\"Timothy M. Hospedales\"},{\"authorId\":\"2345507\",\"name\":\"Wankou Yang\"},{\"authorId\":\"145928755\",\"name\":\"C. Sun\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"57417c4a523d93801c8901d6f3c3740eaa65c9ae\",\"title\":\"Inverse Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/57417c4a523d93801c8901d6f3c3740eaa65c9ae\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1809.01810\",\"authors\":[{\"authorId\":\"2826839\",\"name\":\"Qingxing Cao\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"46708631\",\"name\":\"Bailin Li\"},{\"authorId\":\"1737218\",\"name\":\"L. Lin\"}],\"doi\":\"10.1109/tpami.2019.2943456\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"97b93509f6c3c33dd3665d05b1878e36d58a1efb\",\"title\":\"Interpretable Visual Question Answering by Reasoning on Dependency Trees\",\"url\":\"https://www.semanticscholar.org/paper/97b93509f6c3c33dd3665d05b1878e36d58a1efb\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1472939182\",\"name\":\"Sayedshayan Hashemi Hosseinabad\"},{\"authorId\":\"2179339\",\"name\":\"M. Safayani\"},{\"authorId\":\"145238808\",\"name\":\"A. Mirzaei\"}],\"doi\":\"10.1007/s00371-019-01786-4\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c1072c09f843ba976803ea14b8bf2c4e932ac56d\",\"title\":\"Multiple answers to a question: a new approach for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/c1072c09f843ba976803ea14b8bf2c4e932ac56d\",\"venue\":\"The Visual Computer\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9610143\",\"name\":\"Zhihao Fan\"},{\"authorId\":\"2712533\",\"name\":\"Zhongyu Wei\"},{\"authorId\":\"50695111\",\"name\":\"Siyuan Wang\"},{\"authorId\":\"1790227\",\"name\":\"X. Huang\"}],\"doi\":\"10.18653/v1/P19-1652\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"aaf5e3afd61d0df6c483ca32faf8e7a9198b1557\",\"title\":\"Bridging by Word: Image Grounded Vocabulary Construction for Visual Captioning\",\"url\":\"https://www.semanticscholar.org/paper/aaf5e3afd61d0df6c483ca32faf8e7a9198b1557\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1723657\",\"name\":\"M. Wang\"},{\"authorId\":\"145246199\",\"name\":\"Zhen Zhong\"},{\"authorId\":\"3302605\",\"name\":\"Wanlin Gao\"}],\"doi\":\"10.1145/3207677.3277968\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c073d119d82879946ca8a70eff541ad263f310d6\",\"title\":\"Development and Challenges of Phenotypic Characterization in Modal Animals\",\"url\":\"https://www.semanticscholar.org/paper/c073d119d82879946ca8a70eff541ad263f310d6\",\"venue\":\"CSAE '18\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9377628\",\"name\":\"S. Sehgal\"},{\"authorId\":\"47231598\",\"name\":\"J. Sharma\"},{\"authorId\":\"1961030572\",\"name\":\"Natasha Chaudhary\"}],\"doi\":\"10.1109/ICRITO48877.2020.9197977\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"787415b2e7d11dfc895e78221cb044085620d830\",\"title\":\"Generating Image Captions based on Deep Learning and Natural language Processing\",\"url\":\"https://www.semanticscholar.org/paper/787415b2e7d11dfc895e78221cb044085620d830\",\"venue\":\"2020 8th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2420608\",\"name\":\"Difei Gao\"},{\"authorId\":\"3373117\",\"name\":\"R. Wang\"},{\"authorId\":\"145455919\",\"name\":\"S. Shan\"},{\"authorId\":\"1710220\",\"name\":\"X. Chen\"}],\"doi\":\"10.5244/C.31.131\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d814981606fe5954148e45c737f1debe7b5b36c4\",\"title\":\"Visual Textbook Network: Watch Carefully before Answering Visual Questions\",\"url\":\"https://www.semanticscholar.org/paper/d814981606fe5954148e45c737f1debe7b5b36c4\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":\"1809.04344\",\"authors\":[{\"authorId\":\"51228129\",\"name\":\"Shailza Jolly\"},{\"authorId\":\"3422247\",\"name\":\"Sandro Pezzelle\"},{\"authorId\":\"35660331\",\"name\":\"T. Klein\"},{\"authorId\":\"145279674\",\"name\":\"A. Dengel\"},{\"authorId\":\"1848946\",\"name\":\"Moin Nabi\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"610e0bee525a6573932e077f091505f54a5c4ede\",\"title\":\"The Wisdom of MaSSeS: Majority, Subjectivity, and Semantic Similarity in the Evaluation of VQA\",\"url\":\"https://www.semanticscholar.org/paper/610e0bee525a6573932e077f091505f54a5c4ede\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d7221695df4de3f34d5e4a877b71c14bc88760d2\",\"title\":\"Proposal Incorporating Structural Bias into Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/d7221695df4de3f34d5e4a877b71c14bc88760d2\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144905355\",\"name\":\"Chao Ma\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"121177698\",\"name\":\"A. Dick\"},{\"authorId\":\"1715610\",\"name\":\"Qi Wu\"},{\"authorId\":\"3775903\",\"name\":\"J. Wang\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"},{\"authorId\":\"145950894\",\"name\":\"I. Reid\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"0297f25af287b2db87876be3d85f0e0d26bb6c87\",\"title\":\"Answering with Memory-Augmented Networks\",\"url\":\"https://www.semanticscholar.org/paper/0297f25af287b2db87876be3d85f0e0d26bb6c87\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2003.10065\",\"authors\":[{\"authorId\":\"2826839\",\"name\":\"Qingxing Cao\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"3170394\",\"name\":\"Keze Wang\"},{\"authorId\":\"49478124\",\"name\":\"L. Lin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e4e90d80721fc24ac40f4711f8692aba08dc14e0\",\"title\":\"Linguistically Driven Graph Capsule Network for Visual Question Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/e4e90d80721fc24ac40f4711f8692aba08dc14e0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1906.00067\",\"authors\":[{\"authorId\":\"35789996\",\"name\":\"Kenneth Marino\"},{\"authorId\":\"143887493\",\"name\":\"M. Rastegari\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"3012475\",\"name\":\"R. Mottaghi\"}],\"doi\":\"10.1109/CVPR.2019.00331\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"28ad018c39d1578bea84e7cedf94459e3dbe1e70\",\"title\":\"OK-VQA: A Visual Question Answering Benchmark Requiring External Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/28ad018c39d1578bea84e7cedf94459e3dbe1e70\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1511.04891\",\"authors\":[{\"authorId\":\"1712479\",\"name\":\"Mohamed Elhoseiny\"},{\"authorId\":\"145823372\",\"name\":\"S. Cohen\"},{\"authorId\":\"145907577\",\"name\":\"W. Chang\"},{\"authorId\":\"31844147\",\"name\":\"Brian L. Price\"},{\"authorId\":\"145159523\",\"name\":\"A. Elgammal\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c1aead75afc2fe709b80d6416488ccd157a2a079\",\"title\":\"Sherlock: Scalable Fact Learning in Images\",\"url\":\"https://www.semanticscholar.org/paper/c1aead75afc2fe709b80d6416488ccd157a2a079\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50005563\",\"name\":\"G. Christie\"},{\"authorId\":\"2440772\",\"name\":\"Ankit P Laddha\"},{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"1942176\",\"name\":\"K. Kochersberger\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1016/j.cviu.2017.09.001\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2dbca69f6e50c058a44243abfaf669097a02c879\",\"title\":\"Resolving vision and language ambiguities together: Joint segmentation & prepositional attachment resolution in captioned scenes\",\"url\":\"https://www.semanticscholar.org/paper/2dbca69f6e50c058a44243abfaf669097a02c879\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51021338\",\"name\":\"Nelson Ruwa\"},{\"authorId\":\"151423308\",\"name\":\"Qirong Mao\"},{\"authorId\":\"3309006\",\"name\":\"Heping Song\"},{\"authorId\":\"153719921\",\"name\":\"H. Jia\"},{\"authorId\":\"1384379379\",\"name\":\"Ming Dong\"}],\"doi\":\"10.1016/j.cviu.2019.102829\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9572e232d33aba1b765ef90924d8662707cc2a01\",\"title\":\"Triple attention network for sentimental visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/9572e232d33aba1b765ef90924d8662707cc2a01\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2019},{\"arxivId\":\"1902.09818\",\"authors\":[{\"authorId\":\"49724488\",\"name\":\"H. Zhang\"},{\"authorId\":\"1703558\",\"name\":\"S. Ghosh\"},{\"authorId\":\"46819684\",\"name\":\"Larry Heck\"},{\"authorId\":\"145109280\",\"name\":\"S. Walsh\"},{\"authorId\":\"49051223\",\"name\":\"Junting Zhang\"},{\"authorId\":\"38791445\",\"name\":\"J. Zhang\"},{\"authorId\":\"9363144\",\"name\":\"C.-C. Jay Kuo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cb08a5d1ae9985ae3867780094c9a5e7074817d8\",\"title\":\"Generative Visual Dialogue System via Adaptive Reasoning and Weighted Likelihood Estimation\",\"url\":\"https://www.semanticscholar.org/paper/cb08a5d1ae9985ae3867780094c9a5e7074817d8\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1806.01873\",\"authors\":[{\"authorId\":\"1915796\",\"name\":\"Junwei Liang\"},{\"authorId\":\"39978626\",\"name\":\"Lu Jiang\"},{\"authorId\":\"48749954\",\"name\":\"L. Cao\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1109/TPAMI.2018.2890628\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aee265f6a19f9774c65d296cf9ec0e169365dda5\",\"title\":\"Focal Visual-Text Attention for Memex Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/aee265f6a19f9774c65d296cf9ec0e169365dda5\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":\"1604.03249\",\"authors\":[{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.1007/978-3-319-50077-5_12\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ffd73d1956163a4160ec2c96b3ab256f79fc92e8\",\"title\":\"Attributes as Semantic Units between Natural Language and Visual Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ffd73d1956163a4160ec2c96b3ab256f79fc92e8\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"},{\"authorId\":\"4418074\",\"name\":\"Minjoon Seo\"},{\"authorId\":\"34846449\",\"name\":\"D. Schwenk\"},{\"authorId\":\"119675494\",\"name\":\"Jonghyun Choi\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"2548384\",\"name\":\"Hannaneh Hajishirzi\"}],\"doi\":\"10.1109/CVPR.2017.571\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c071a1ad68310fed7f0876b6f01cb7b135043bc3\",\"title\":\"Are You Smarter Than a Sixth Grader? Textbook Question Answering for Multimodal Machine Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/c071a1ad68310fed7f0876b6f01cb7b135043bc3\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1603.02814\",\"authors\":[{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"121177698\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/TPAMI.2017.2708709\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"6acd385b2742f65359efb99543ebfb9a0d1b850f\",\"title\":\"Image Captioning and Visual Question Answering Based on Attributes and External Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/6acd385b2742f65359efb99543ebfb9a0d1b850f\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2674321\",\"name\":\"Jiaying Lu\"},{\"authorId\":\"50183959\",\"name\":\"Xin Ye\"},{\"authorId\":\"71048893\",\"name\":\"Yi Ren\"},{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c7343bc435970ef0ea4dde0c621835446de119a3\",\"title\":\"Good, Better, Best: Multi-Choice VQA with Textual Distractors Generation via Policy Gradient\",\"url\":\"https://www.semanticscholar.org/paper/c7343bc435970ef0ea4dde0c621835446de119a3\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51021265\",\"name\":\"T. Yu\"},{\"authorId\":\"97583812\",\"name\":\"J. Yu\"},{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/TIP.2019.2940677\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ef33aedbab68b0771f6dd7ca8ec2492f12d7ea51\",\"title\":\"Compositional Attention Networks With Two-Stream Fusion for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ef33aedbab68b0771f6dd7ca8ec2492f12d7ea51\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1906.09844\",\"authors\":[{\"authorId\":\"2052119\",\"name\":\"Zhaoquan Yuan\"},{\"authorId\":\"47393013\",\"name\":\"Siyuan Sun\"},{\"authorId\":\"2055900\",\"name\":\"Lixin Duan\"},{\"authorId\":\"116155759\",\"name\":\"Xiao Wu\"},{\"authorId\":\"48258806\",\"name\":\"Changsheng Xu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b5b0228f4955add9bdf0edbf66e0d3df6f38a993\",\"title\":\"Adversarial Multimodal Network for Movie Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b5b0228f4955add9bdf0edbf66e0d3df6f38a993\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1109/CVPR.2016.538\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ebe5081b8a24b4740db929b6eae75f28f8edbc58\",\"title\":\"Answer-Type Prediction for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ebe5081b8a24b4740db929b6eae75f28f8edbc58\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152309767\",\"name\":\"L. Ma\"},{\"authorId\":\"119897463\",\"name\":\"Wenhao Jiang\"},{\"authorId\":\"2750647\",\"name\":\"Zequn Jie\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"40143631\",\"name\":\"W. Liu\"}],\"doi\":\"10.1109/TCSVT.2019.2916167\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4f15a43aba873c83f688fe3fd0d11eedb2398a23\",\"title\":\"Matching Image and Sentence With Multi-Faceted Representations\",\"url\":\"https://www.semanticscholar.org/paper/4f15a43aba873c83f688fe3fd0d11eedb2398a23\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"2010.16010\",\"authors\":[{\"authorId\":\"1390575046\",\"name\":\"Yangyang Guo\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":\"46504200\",\"name\":\"Zhiyong Cheng\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9b9e35875ad771961ad2d35f7b9cd645b96afd04\",\"title\":\"Loss-rescaling VQA: Revisiting Language Prior Problem from a Class-imbalance View\",\"url\":\"https://www.semanticscholar.org/paper/9b9e35875ad771961ad2d35f7b9cd645b96afd04\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3194022\",\"name\":\"Bohan Zhuang\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"}],\"doi\":\"10.1109/ICCV.2017.71\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"222c0f085c3510eee3196fb9b3fdc52d3c488cd8\",\"title\":\"Towards Context-Aware Interaction Recognition for Visual Relationship Detection\",\"url\":\"https://www.semanticscholar.org/paper/222c0f085c3510eee3196fb9b3fdc52d3c488cd8\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31747675\",\"name\":\"Sue Han Lee\"},{\"authorId\":\"2863960\",\"name\":\"Chee Seng Chan\"},{\"authorId\":\"1711669\",\"name\":\"Paolo Remagnino\"}],\"doi\":\"10.1109/TIP.2018.2836321\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"976647b32fd7e1a5c8ee4a11792155903bb34e43\",\"title\":\"Multi-Organ Plant Classification Based on Convolutional and Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/976647b32fd7e1a5c8ee4a11792155903bb34e43\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47158869\",\"name\":\"Xing Xu\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"143663452\",\"name\":\"Huimin Lu\"},{\"authorId\":\"144780837\",\"name\":\"Li He\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":\"144618699\",\"name\":\"F. Shen\"}],\"doi\":\"10.1109/ICME.2018.8486475\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d353b30b9ca3124fad08e3bdc8167dfe994efb34\",\"title\":\"Dual Learning for Visual Question Generation\",\"url\":\"https://www.semanticscholar.org/paper/d353b30b9ca3124fad08e3bdc8167dfe994efb34\",\"venue\":\"2018 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2018},{\"arxivId\":\"1808.00300\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"2786693\",\"name\":\"C. Doersch\"},{\"authorId\":\"35030998\",\"name\":\"A. Santoro\"},{\"authorId\":\"2019153\",\"name\":\"P. Battaglia\"}],\"doi\":\"10.1007/978-3-030-01231-1_1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"afe3a0d463e2f099305c745ddbf943844583795d\",\"title\":\"Learning Visual Question Answering by Bootstrapping Hard Attention\",\"url\":\"https://www.semanticscholar.org/paper/afe3a0d463e2f099305c745ddbf943844583795d\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50565167\",\"name\":\"K. Barnard\"}],\"doi\":\"10.2200/S00705ED1V01Y201602COV007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c4e69a89a9e322ca78ed3f1140e74aee5ab844f1\",\"title\":\"Computational Methods for Integrating Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/c4e69a89a9e322ca78ed3f1140e74aee5ab844f1\",\"venue\":\"Computational Methods for Integrating Vision and Language\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36300013\",\"name\":\"Y. Rao\"},{\"authorId\":\"3607957\",\"name\":\"Haoran Xie\"},{\"authorId\":\"48032513\",\"name\":\"X. Liu\"},{\"authorId\":\"145726530\",\"name\":\"Q. Li\"},{\"authorId\":\"1773235\",\"name\":\"Fu Lee Wang\"},{\"authorId\":\"39756936\",\"name\":\"T. Wong\"}],\"doi\":\"10.3233/JIFS-169094\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9f306cb9fcaf19ae60305a83ed6e109015ba6ea1\",\"title\":\"User authority ranking models for community question answering\",\"url\":\"https://www.semanticscholar.org/paper/9f306cb9fcaf19ae60305a83ed6e109015ba6ea1\",\"venue\":\"J. Intell. Fuzzy Syst.\",\"year\":2016},{\"arxivId\":\"1703.06585\",\"authors\":[{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"2150275\",\"name\":\"S. Kottur\"},{\"authorId\":\"51283515\",\"name\":\"Jos\\u00e9 M. F. Moura\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1109/ICCV.2017.321\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"c18df1edc0a45891806d44896a8f666944e93d01\",\"title\":\"Learning Cooperative Visual Dialog Agents with Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/c18df1edc0a45891806d44896a8f666944e93d01\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23978705\",\"name\":\"J. Y. Koh\"},{\"authorId\":\"1699054\",\"name\":\"W. Samek\"},{\"authorId\":\"145034054\",\"name\":\"K. M\\u00fcller\"},{\"authorId\":\"49345823\",\"name\":\"Alexander Binder\"}],\"doi\":\"10.1007/978-3-319-66709-6_13\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e214a8c2d7ec04755aa41380091419fc2bbb094f\",\"title\":\"Object Boundary Detection and Classification with Image-Level Labels\",\"url\":\"https://www.semanticscholar.org/paper/e214a8c2d7ec04755aa41380091419fc2bbb094f\",\"venue\":\"GCPR\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32482521\",\"name\":\"P. Zhang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"00432309c1125d3b99d27c686f8da28ead6f7cf8\",\"title\":\"Towards Interpretable Vision Systems\",\"url\":\"https://www.semanticscholar.org/paper/00432309c1125d3b99d27c686f8da28ead6f7cf8\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"146162422\",\"name\":\"Akshit Pradhan\"},{\"authorId\":\"48533729\",\"name\":\"P. Shukla\"},{\"authorId\":\"151172996\",\"name\":\"Pallavi Patra\"},{\"authorId\":\"2975781\",\"name\":\"R. Pathak\"},{\"authorId\":\"48652239\",\"name\":\"Ajay Jena\"}],\"doi\":\"10.1007/978-981-13-8581-0_1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7ffba0f09bbbe6d396ffaba8f6a13b0ea12e54b8\",\"title\":\"Enhancing Interaction with Social Networking Sites for Visually Impaired People by Using Textual and Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7ffba0f09bbbe6d396ffaba8f6a13b0ea12e54b8\",\"venue\":\"CICBA\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49597404\",\"name\":\"Z. Fang\"},{\"authorId\":\"46700426\",\"name\":\"J. Liu\"},{\"authorId\":\"47003032\",\"name\":\"Y. Li\"},{\"authorId\":\"80526284\",\"name\":\"Yanyuan Qiao\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1016/J.PATCOG.2019.01.038\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aa31126aa9dc7665bf236a51c6de31c4bf6c59ad\",\"title\":\"Improving visual question answering using dropout and enhanced question encoder\",\"url\":\"https://www.semanticscholar.org/paper/aa31126aa9dc7665bf236a51c6de31c4bf6c59ad\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":\"1604.04279\",\"authors\":[{\"authorId\":\"34280810\",\"name\":\"Gunnar A. Sigurdsson\"},{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1007/978-3-319-46454-1_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3583f39138f3e70fab0754ed4e5578a91fb08a20\",\"title\":\"Learning Visual Storylines with Skipping Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/3583f39138f3e70fab0754ed4e5578a91fb08a20\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1711.06794\",\"authors\":[{\"authorId\":\"2887562\",\"name\":\"Pan Lu\"},{\"authorId\":\"49404547\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"40538912\",\"name\":\"Wei Zhang\"},{\"authorId\":\"2447408\",\"name\":\"Jianyong Wang\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9a6268d2bc1221ea154097feadea0c58f234d02f\",\"title\":\"Co-attending Free-form Regions and Detections with Multi-modal Multiplicative Feature Embedding for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/9a6268d2bc1221ea154097feadea0c58f234d02f\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1703.08120\",\"authors\":[{\"authorId\":\"2321160\",\"name\":\"Abhijit Sharang\"},{\"authorId\":\"143756813\",\"name\":\"Eric Lau\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2c0c611ebc538662023c7e5e51654a47e8063c2e\",\"title\":\"Recurrent and Contextual Models for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2c0c611ebc538662023c7e5e51654a47e8063c2e\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1712.00733\",\"authors\":[{\"authorId\":\"6051714\",\"name\":\"G. Li\"},{\"authorId\":\"144904238\",\"name\":\"H. Su\"},{\"authorId\":\"145583986\",\"name\":\"Wenwu Zhu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"23ed7f18100717ba814b2859196e10c5d4fed216\",\"title\":\"Incorporating External Knowledge to Answer Open-Domain Visual Questions with Dynamic Memory Networks\",\"url\":\"https://www.semanticscholar.org/paper/23ed7f18100717ba814b2859196e10c5d4fed216\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1803.10862\",\"authors\":[{\"authorId\":\"1399026483\",\"name\":\"Javier Ruiz-del-Solar\"},{\"authorId\":\"2926000\",\"name\":\"P. Loncomilla\"},{\"authorId\":\"41067913\",\"name\":\"N. Soto\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"59c23afa9e53f97a28da3abbecb3d1eb8d05985b\",\"title\":\"A Survey on Deep Learning Methods for Robot Vision\",\"url\":\"https://www.semanticscholar.org/paper/59c23afa9e53f97a28da3abbecb3d1eb8d05985b\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1810.12118\",\"authors\":[{\"authorId\":\"46431006\",\"name\":\"H. Zhao\"},{\"authorId\":\"1688665\",\"name\":\"J. Liu\"}],\"doi\":\"10.1109/IJCNN.2018.8489756\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9c97db1924f57ed84f6b79e4b375a2720de2d04f\",\"title\":\"Finding Answers from the Word of God: Domain Adaptation for Neural Networks in Biblical Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/9c97db1924f57ed84f6b79e4b375a2720de2d04f\",\"venue\":\"2018 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2625271\",\"name\":\"Mengfei Li\"},{\"authorId\":\"143628183\",\"name\":\"Li Gu\"},{\"authorId\":\"144602988\",\"name\":\"Yi Ji\"},{\"authorId\":\"6681872\",\"name\":\"Chunping Liu\"}],\"doi\":\"10.1007/978-3-030-00764-5_69\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"87f208c3716a80f5251d35196b8ac5c42fa791ea\",\"title\":\"Text-Guided Dual-Branch Attention Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/87f208c3716a80f5251d35196b8ac5c42fa791ea\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52145600\",\"name\":\"Corey Zumar\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"96f94d89dfbc5ba1de98bc00392eea23b9d1aa7b\",\"title\":\"Sample Queries Latency SLO Offline Online Live Queries Preds . PICL Expression Model Profiles Pipeline Config Budget $ Physical Execution Engine Queue\",\"url\":\"https://www.semanticscholar.org/paper/96f94d89dfbc5ba1de98bc00392eea23b9d1aa7b\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48881927\",\"name\":\"R. Li\"},{\"authorId\":\"1729056\",\"name\":\"J. Jia\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"269546925f0fd457b31c13c2870343b0aed761dc\",\"title\":\"Visual Question Answering with Question Representation Update (QRU)\",\"url\":\"https://www.semanticscholar.org/paper/269546925f0fd457b31c13c2870343b0aed761dc\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"2002.05104\",\"authors\":[{\"authorId\":\"1396871443\",\"name\":\"Camila Kolling\"},{\"authorId\":\"8599825\",\"name\":\"Jonatas Wehrmann\"},{\"authorId\":\"1380051745\",\"name\":\"Rodrigo C. Barros\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206679\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e4bd198ec47697ed1442af0babd35b88451fd205\",\"title\":\"Component Analysis for Visual Question Answering Architectures\",\"url\":\"https://www.semanticscholar.org/paper/e4bd198ec47697ed1442af0babd35b88451fd205\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":\"1709.07192\",\"authors\":[{\"authorId\":\"2180892\",\"name\":\"Yikang Li\"},{\"authorId\":\"46429989\",\"name\":\"N. Duan\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"47353404\",\"name\":\"X. Chu\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"}],\"doi\":\"10.1109/CVPR.2018.00640\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"47aff6477f05ec32fc163e1943fe9464a8379552\",\"title\":\"Visual Question Generation as Dual Task of Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/47aff6477f05ec32fc163e1943fe9464a8379552\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1708.02711\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2018.00444\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b14a60a1c3e6bb45baddd754a1cfe83ffc1bbb81\",\"title\":\"Tips and Tricks for Visual Question Answering: Learnings from the 2017 Challenge\",\"url\":\"https://www.semanticscholar.org/paper/b14a60a1c3e6bb45baddd754a1cfe83ffc1bbb81\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47908786\",\"name\":\"Y. Liu\"},{\"authorId\":\"46457827\",\"name\":\"Li Liu\"},{\"authorId\":\"1687503\",\"name\":\"Yanming Guo\"},{\"authorId\":\"1731570\",\"name\":\"M. Lew\"}],\"doi\":\"10.1016/j.patcog.2018.07.001\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"96e05dd7f08df72f57b22ebf67a7bd5b5b797989\",\"title\":\"Learning visual and textual representations for multimodal matching and classification\",\"url\":\"https://www.semanticscholar.org/paper/96e05dd7f08df72f57b22ebf67a7bd5b5b797989\",\"venue\":\"Pattern Recognit.\",\"year\":2018},{\"arxivId\":\"1708.02531\",\"authors\":[{\"authorId\":\"144820063\",\"name\":\"Yuming Shen\"},{\"authorId\":\"40241836\",\"name\":\"L. Liu\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"}],\"doi\":\"10.1109/ICCV.2017.441\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f632790471b2bed7ba7c28b12cda9360ec586a63\",\"title\":\"Deep Binaries: Encoding Semantic-Rich Cues for Efficient Textual-Visual Cross Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/f632790471b2bed7ba7c28b12cda9360ec586a63\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1704.04224\",\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1109/ICCV.2017.440\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c00deb3774bcadf8f5e64ab48f483f06be56bc1\",\"title\":\"Spatial Memory for Context Reasoning in Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/2c00deb3774bcadf8f5e64ab48f483f06be56bc1\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3368782\",\"name\":\"Yuetan Lin\"},{\"authorId\":\"7372283\",\"name\":\"Zhangyang Pang\"},{\"authorId\":\"144199812\",\"name\":\"D. Wang\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.24963/ijcai.2018/586\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f15ad07b9f6686bc72c45bf781c91f8eeb035899\",\"title\":\"Feature Enhancement in Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f15ad07b9f6686bc72c45bf781c91f8eeb035899\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6578200\",\"name\":\"Shiling Jiang\"},{\"authorId\":\"1405875318\",\"name\":\"Ming Ma\"},{\"authorId\":\"46584793\",\"name\":\"J. Wang\"},{\"authorId\":\"2607232\",\"name\":\"Jiayu Liang\"},{\"authorId\":\"3386073\",\"name\":\"Kunliang Liu\"},{\"authorId\":\"46676502\",\"name\":\"Y. Sun\"},{\"authorId\":\"3417894\",\"name\":\"W. Deng\"},{\"authorId\":\"148123516\",\"name\":\"Siyu Ren\"},{\"authorId\":\"151470674\",\"name\":\"Guanghao Jin\"}],\"doi\":\"10.1007/978-3-030-31654-9_40\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"87045ac2a065b14a3f6608ac9147fa81b89aa4fb\",\"title\":\"Semantic Reanalysis of Scene Words in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/87045ac2a065b14a3f6608ac9147fa81b89aa4fb\",\"venue\":\"PRCV\",\"year\":2019},{\"arxivId\":\"1511.05099\",\"authors\":[{\"authorId\":\"40409467\",\"name\":\"P. Zhang\"},{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2016.542\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5fa973b8d284145bf0ced9acf2913a74674260f6\",\"title\":\"Yin and Yang: Balancing and Answering Binary Visual Questions\",\"url\":\"https://www.semanticscholar.org/paper/5fa973b8d284145bf0ced9acf2913a74674260f6\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145283199\",\"name\":\"M. Baroni\"}],\"doi\":\"10.1111/lnc3.12170\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f5473f9b4bafb63782049725bf7f3f8ee92f6e85\",\"title\":\"Grounding Distributional Semantics in the Visual World\",\"url\":\"https://www.semanticscholar.org/paper/f5473f9b4bafb63782049725bf7f3f8ee92f6e85\",\"venue\":\"Lang. Linguistics Compass\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"2351434\",\"name\":\"Zhongwen Xu\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1007/s11263-017-1033-7\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"828ac57f755db989e2886042a85278ae4823297c\",\"title\":\"Uncovering the Temporal Context for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/828ac57f755db989e2886042a85278ae4823297c\",\"venue\":\"International Journal of Computer Vision\",\"year\":2017},{\"arxivId\":\"1511.04670\",\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"2351434\",\"name\":\"Zhongwen Xu\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9ed7d774684a1770445c1c53e276011a8364b9e2\",\"title\":\"Uncovering Temporal Context for Video Question and Answering\",\"url\":\"https://www.semanticscholar.org/paper/9ed7d774684a1770445c1c53e276011a8364b9e2\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1506.00333\",\"authors\":[{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"11955007\",\"name\":\"Z. Lu\"},{\"authorId\":\"49404233\",\"name\":\"Hang Li\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"98bd5dd1740f585bf25320ba504e2c1ae57f2e5f\",\"title\":\"Learning to Answer Questions from Image Using Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/98bd5dd1740f585bf25320ba504e2c1ae57f2e5f\",\"venue\":\"AAAI\",\"year\":2016},{\"arxivId\":\"1703.09902\",\"authors\":[{\"authorId\":\"1700894\",\"name\":\"Albert Gatt\"},{\"authorId\":\"145210073\",\"name\":\"E. Krahmer\"}],\"doi\":\"10.1613/jair.5477\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d13bb317e87f3f6da10da11059ebf4350b754814\",\"title\":\"Survey of the State of the Art in Natural Language Generation: Core tasks, applications and evaluation\",\"url\":\"https://www.semanticscholar.org/paper/d13bb317e87f3f6da10da11059ebf4350b754814\",\"venue\":\"J. Artif. Intell. Res.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Leonard B\\u00e4rmann\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"8b818a642c13a643ceed0a71575263e9732cc3ac\",\"title\":\"Multimodal goal-oriented dialog using Encoder-Decoder-Networks\",\"url\":\"https://www.semanticscholar.org/paper/8b818a642c13a643ceed0a71575263e9732cc3ac\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143957784\",\"name\":\"M. Iqbal\"},{\"authorId\":\"119339025\",\"name\":\"H. Chowdhury\"},{\"authorId\":\"145025159\",\"name\":\"K. Nguyen\"},{\"authorId\":\"3140440\",\"name\":\"C. Fookes\"},{\"authorId\":\"1729760\",\"name\":\"S. Sridharan\"}],\"doi\":\"10.36227/techrxiv.12731948\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"182cff43865499c081c2ea9c441605ae6670ad5e\",\"title\":\"VISUAL QUESTION ANSWERING THROUGH ADVERSARIAL LEARNING OF MULTI-MODAL REPRESENTATION\",\"url\":\"https://www.semanticscholar.org/paper/182cff43865499c081c2ea9c441605ae6670ad5e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1604.01485\",\"authors\":[{\"authorId\":\"3393294\",\"name\":\"Ilija Ilievski\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"7214daf035ab005b3d1e739750dd597b4f4513fa\",\"title\":\"A Focused Dynamic Attention Model for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7214daf035ab005b3d1e739750dd597b4f4513fa\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1707.06436\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":null,\"name\":\"Yun He\"},{\"authorId\":\"9935341\",\"name\":\"S. Ueta\"},{\"authorId\":\"5014206\",\"name\":\"T. Suzuki\"},{\"authorId\":\"49897653\",\"name\":\"K. Abe\"},{\"authorId\":\"2554424\",\"name\":\"Asako Kanezaki\"},{\"authorId\":\"49133490\",\"name\":\"Shinichiro Morita\"},{\"authorId\":\"22219521\",\"name\":\"Toshiyuki Yabe\"},{\"authorId\":\"50544018\",\"name\":\"Yoshihiro Kanehara\"},{\"authorId\":\"22174281\",\"name\":\"Hiroya Yatsuyanagi\"},{\"authorId\":\"1692565\",\"name\":\"S. Maruyama\"},{\"authorId\":\"10756539\",\"name\":\"Ryousuke Takasawa\"},{\"authorId\":\"3217653\",\"name\":\"Masataka Fuchida\"},{\"authorId\":\"2642022\",\"name\":\"Y. Miyashita\"},{\"authorId\":\"34935749\",\"name\":\"Kazushige Okayasu\"},{\"authorId\":\"20505300\",\"name\":\"Yuta Matsuzaki\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"title\":\"cvpaper.challenge in 2016: Futuristic Computer Vision through 1, 600 Papers Survey\",\"url\":\"https://www.semanticscholar.org/paper/8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1812.01776\",\"authors\":[{\"authorId\":\"50564124\",\"name\":\"D. Crankshaw\"},{\"authorId\":\"34741544\",\"name\":\"Gur-Eyal Sela\"},{\"authorId\":\"52145600\",\"name\":\"Corey Zumar\"},{\"authorId\":\"145272357\",\"name\":\"Xiangxi Mo\"},{\"authorId\":\"49988044\",\"name\":\"Joseph E. Gonzalez\"},{\"authorId\":\"144467753\",\"name\":\"I. Stoica\"},{\"authorId\":\"144312193\",\"name\":\"Alexey Tumanov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"352461d8c8eb2a963cfab6d0c7069af6f3543f10\",\"title\":\"InferLine: ML Inference Pipeline Composition Framework\",\"url\":\"https://www.semanticscholar.org/paper/352461d8c8eb2a963cfab6d0c7069af6f3543f10\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1608.02717\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"117034854\",\"name\":\"Ashkan Mokarian\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":\"10.5244/C.30.111\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e0c7c81571ff97881277bc37a218d885ec64beb1\",\"title\":\"Mean Box Pooling: A Rich Image Representation and Output Embedding for the Visual Madlibs Task\",\"url\":\"https://www.semanticscholar.org/paper/e0c7c81571ff97881277bc37a218d885ec64beb1\",\"venue\":\"BMVC\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40461528\",\"name\":\"Y. Liu\"},{\"authorId\":\"1687503\",\"name\":\"Yanming Guo\"},{\"authorId\":\"46458102\",\"name\":\"L. Liu\"},{\"authorId\":\"143866184\",\"name\":\"E. Bakker\"},{\"authorId\":\"1731570\",\"name\":\"M. Lew\"}],\"doi\":\"10.1016/J.PATCOG.2019.05.008\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d1c6fb3a0b46ecfaa0b23b6a10ecd07b2cd4ab28\",\"title\":\"CycleMatch: A cycle-consistent embedding network for image-text matching\",\"url\":\"https://www.semanticscholar.org/paper/d1c6fb3a0b46ecfaa0b23b6a10ecd07b2cd4ab28\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":\"2009.12770\",\"authors\":[{\"authorId\":\"1865719481\",\"name\":\"Deepak Gupta\"},{\"authorId\":\"1492191087\",\"name\":\"Swati Suman\"},{\"authorId\":\"152800923\",\"name\":\"A. Ekbal\"}],\"doi\":\"10.1016/J.ESWA.2020.113993\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9fe3eeafbe022de014aeb54d0b55502e2a2e46fe\",\"title\":\"Hierarchical Deep Multi-modal Network for Medical Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/9fe3eeafbe022de014aeb54d0b55502e2a2e46fe\",\"venue\":\"Expert Syst. Appl.\",\"year\":2021},{\"arxivId\":\"1809.01816\",\"authors\":[{\"authorId\":\"2150275\",\"name\":\"S. Kottur\"},{\"authorId\":\"144915495\",\"name\":\"Jos\\u00e9 M. F. Moura\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.1007/978-3-030-01267-0_10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"782bc02684de81f98c92475957501801bf91e023\",\"title\":\"Visual Coreference Resolution in Visual Dialog using Neural Module Networks\",\"url\":\"https://www.semanticscholar.org/paper/782bc02684de81f98c92475957501801bf91e023\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1908.04342\",\"authors\":[{\"authorId\":\"23364558\",\"name\":\"Nilavra Bhattacharya\"},{\"authorId\":\"48933740\",\"name\":\"Q. Li\"},{\"authorId\":\"2028946\",\"name\":\"D. Gurari\"}],\"doi\":\"10.1109/ICCV.2019.00437\",\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"4cae43b28757e0c37a05156ed063dcc3bb652809\",\"title\":\"Why Does a Visual Question Have Different Answers?\",\"url\":\"https://www.semanticscholar.org/paper/4cae43b28757e0c37a05156ed063dcc3bb652809\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1611.05896\",\"authors\":[{\"authorId\":\"39744108\",\"name\":\"S. Aditya\"},{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"1760291\",\"name\":\"Chitta Baral\"},{\"authorId\":\"1697493\",\"name\":\"Y. Aloimonos\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"55f2626b7250b3b24dd0d2bab3ef3c3bbd9b3758\",\"title\":\"Answering Image Riddles using Vision and Reasoning through Probabilistic Soft Logic\",\"url\":\"https://www.semanticscholar.org/paper/55f2626b7250b3b24dd0d2bab3ef3c3bbd9b3758\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35100058\",\"name\":\"R. R. Selvaraju\"},{\"authorId\":\"144354133\",\"name\":\"Michael Cogswell\"},{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1109/ICCV.2017.74\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"24120b948f39834e7860271992464eb4a575501b\",\"title\":\"Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization\",\"url\":\"https://www.semanticscholar.org/paper/24120b948f39834e7860271992464eb4a575501b\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1803.06936\",\"authors\":[{\"authorId\":\"144238414\",\"name\":\"Feng Liu\"},{\"authorId\":\"145406421\",\"name\":\"T. Xiang\"},{\"authorId\":\"1697755\",\"name\":\"Timothy M. Hospedales\"},{\"authorId\":\"2345507\",\"name\":\"Wankou Yang\"},{\"authorId\":\"145928755\",\"name\":\"C. Sun\"}],\"doi\":\"10.1109/TPAMI.2018.2880185\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8927117cba0d82d59a35f099b47acb291c6567e3\",\"title\":\"Inverse Visual Question Answering: A New Benchmark and VQA Diagnosis Tool\",\"url\":\"https://www.semanticscholar.org/paper/8927117cba0d82d59a35f099b47acb291c6567e3\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"dd7062e6f84750688fa96143209efc801e91f9bd\",\"title\":\"Visual Understanding through Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/dd7062e6f84750688fa96143209efc801e91f9bd\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1511.02283\",\"authors\":[{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"1808244\",\"name\":\"J. Huang\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"3317152\",\"name\":\"Oana-Maria Camburu\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":\"10.1109/CVPR.2016.9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e65142010431ffc089b272a1174214e00693e503\",\"title\":\"Generation and Comprehension of Unambiguous Object Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/e65142010431ffc089b272a1174214e00693e503\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2846025\",\"name\":\"D. Yu\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"40434674\",\"name\":\"X. Tian\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1145/3316767\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b0ce44270916fd6e254fd9e75dd77ee1cf9f212a\",\"title\":\"Multi-source Multi-level Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b0ce44270916fd6e254fd9e75dd77ee1cf9f212a\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51052405\",\"name\":\"H. Liu\"},{\"authorId\":\"32986779\",\"name\":\"Shengrong Gong\"},{\"authorId\":\"144602988\",\"name\":\"Yi Ji\"},{\"authorId\":\"7788280\",\"name\":\"J. Yang\"},{\"authorId\":\"50356714\",\"name\":\"Tengfei Xing\"},{\"authorId\":\"47535378\",\"name\":\"Chunping Liu\"}],\"doi\":\"10.2991/CMSA-18.2018.80\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"483828a82b26db7761a3a47fadc971b561b53615\",\"title\":\"Multimodal Cross-guided Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/483828a82b26db7761a3a47fadc971b561b53615\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1908.11310\",\"authors\":[{\"authorId\":\"19444389\",\"name\":\"Koustav Ghosal\"},{\"authorId\":\"36809068\",\"name\":\"Aakanksha Rana\"},{\"authorId\":\"118065745\",\"name\":\"A. Smolic\"}],\"doi\":\"10.1109/ICCVW.2019.00556\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5d204156022f65e34706d4211e05bcb578940939\",\"title\":\"Aesthetic Image Captioning From Weakly-Labelled Photographs\",\"url\":\"https://www.semanticscholar.org/paper/5d204156022f65e34706d4211e05bcb578940939\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1947259\",\"name\":\"Ionut-Teodor Sorodoc\"},{\"authorId\":\"3422247\",\"name\":\"Sandro Pezzelle\"},{\"authorId\":\"3352951\",\"name\":\"Aur\\u00e9lie Herbelot\"},{\"authorId\":\"2837527\",\"name\":\"Mariella Dimiccoli\"}],\"doi\":\"10.1017/S1351324918000128\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4e7533da3833a1e89c14f6c7d948c44331d9f815\",\"title\":\"Learning quantification from images: A structured neural architecture\",\"url\":\"https://www.semanticscholar.org/paper/4e7533da3833a1e89c14f6c7d948c44331d9f815\",\"venue\":\"Nat. Lang. Eng.\",\"year\":2018},{\"arxivId\":\"1912.07538\",\"authors\":[{\"authorId\":\"48189355\",\"name\":\"V. Agarwal\"},{\"authorId\":\"38314306\",\"name\":\"Rakshith Shetty\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":\"10.1109/cvpr42600.2020.00971\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d9cf8fc0bca131be5aeba5fb64a7393f53cb7e60\",\"title\":\"Towards Causal VQA: Revealing and Reducing Spurious Correlations by Invariant and Covariant Semantic Editing\",\"url\":\"https://www.semanticscholar.org/paper/d9cf8fc0bca131be5aeba5fb64a7393f53cb7e60\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1007/s11042-020-09251-4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"af92381f95f28701396abeecaf715383b26ca354\",\"title\":\"A unified cycle-consistent neural model for text and image retrieval\",\"url\":\"https://www.semanticscholar.org/paper/af92381f95f28701396abeecaf715383b26ca354\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"1602.07332\",\"authors\":[{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"50499889\",\"name\":\"O. Groth\"},{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"1382195702\",\"name\":\"Kenji Hata\"},{\"authorId\":\"40591424\",\"name\":\"J. Kravitz\"},{\"authorId\":\"6000646\",\"name\":\"Stephanie Chen\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"1388344504\",\"name\":\"David A. Shamma\"},{\"authorId\":\"1379506718\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-016-0981-7\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"title\":\"Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations\",\"url\":\"https://www.semanticscholar.org/paper/afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":\"1707.04968\",\"authors\":[{\"authorId\":\"144905344\",\"name\":\"Chifeng Ma\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2018.00729\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"3bb4f2013d99eaf2afc182fa482bd0f2d63f2d82\",\"title\":\"Visual Question Answering with Memory-Augmented Networks\",\"url\":\"https://www.semanticscholar.org/paper/3bb4f2013d99eaf2afc182fa482bd0f2d63f2d82\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1899992\",\"name\":\"Avi Singh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"3965d73c9d7c97cdb391bfd86a15bfd3534cbd32\",\"title\":\"Deep Learning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/3965d73c9d7c97cdb391bfd86a15bfd3534cbd32\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1809.00681\",\"authors\":[{\"authorId\":\"2479187\",\"name\":\"Moitreya Chatterjee\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1007/978-3-030-01216-8_45\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a27973d90c1427369cb10aa0202d671f0422e21e\",\"title\":\"Diverse and Coherent Paragraph Generation from Images\",\"url\":\"https://www.semanticscholar.org/paper/a27973d90c1427369cb10aa0202d671f0422e21e\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1809.08697\",\"authors\":[{\"authorId\":\"37619618\",\"name\":\"Khyathi Raghavi Chandu\"},{\"authorId\":\"51007384\",\"name\":\"Mary Arpita Pyreddy\"},{\"authorId\":\"40895015\",\"name\":\"Matthieu Felix\"},{\"authorId\":\"50745535\",\"name\":\"Narendra Nath Joshi\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"ad5950257e053b08657ea298f7b89ba358b8bfcf\",\"title\":\"Textually Enriched Neural Module Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ad5950257e053b08657ea298f7b89ba358b8bfcf\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"145743311\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"287c5be2610e1c61798851feb32b88c424acfbf9\",\"title\":\"Hierarchical Co-Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/287c5be2610e1c61798851feb32b88c424acfbf9\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"25080314\",\"name\":\"Teresa Botschen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"478193a30c5e1daf01fb2f380852040fd6f49081\",\"title\":\"Uni- and Multimodal and Structured Representations for Modeling Frame Semantics\",\"url\":\"https://www.semanticscholar.org/paper/478193a30c5e1daf01fb2f380852040fd6f49081\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"9515493\",\"name\":\"Liangfu Cao\"},{\"authorId\":\"48669907\",\"name\":\"X. Xu\"},{\"authorId\":\"145496508\",\"name\":\"J. Shao\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"}],\"doi\":\"10.1016/J.NEUCOM.2018.11.102\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"be63949be4151ed73503b3eb218aa9175233661b\",\"title\":\"Question-Led object attention for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/be63949be4151ed73503b3eb218aa9175233661b\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"2007.02833\",\"authors\":[{\"authorId\":\"31926869\",\"name\":\"A. Pollard\"},{\"authorId\":\"2113093\",\"name\":\"J. Shapiro\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"07d07329c896d5a4d975313b02e52726d7cbbfb3\",\"title\":\"Eliminating Catastrophic Interference with Biased Competition\",\"url\":\"https://www.semanticscholar.org/paper/07d07329c896d5a4d975313b02e52726d7cbbfb3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.11603\",\"authors\":[{\"authorId\":\"50219425\",\"name\":\"Zhonghao Wang\"},{\"authorId\":\"50753116\",\"name\":\"M. Yu\"},{\"authorId\":\"1557365681\",\"name\":\"Kai Wang\"},{\"authorId\":\"46590281\",\"name\":\"Jinjun Xiong\"},{\"authorId\":\"143668320\",\"name\":\"W. Hwu\"},{\"authorId\":\"1404424091\",\"name\":\"M. Hasegawa-Johnson\"},{\"authorId\":\"1733082596\",\"name\":\"Humphrey Shi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ceb7dad11d16c21c2743e8b418bee5260d90102d\",\"title\":\"Interpretable Visual Reasoning via Induced Symbolic Space\",\"url\":\"https://www.semanticscholar.org/paper/ceb7dad11d16c21c2743e8b418bee5260d90102d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.11014\",\"authors\":[{\"authorId\":\"35789996\",\"name\":\"Kenneth Marino\"},{\"authorId\":\"1606041624\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1726095131\",\"name\":\"Abhinav Gupta\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1a9015e511ec3da873f6114eeb542905a92d7d62\",\"title\":\"KRISP: Integrating Implicit and Symbolic Knowledge for Open-Domain Knowledge-Based VQA\",\"url\":\"https://www.semanticscholar.org/paper/1a9015e511ec3da873f6114eeb542905a92d7d62\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2003.01200\",\"authors\":[{\"authorId\":\"8449394\",\"name\":\"A. Torfi\"},{\"authorId\":\"7664662\",\"name\":\"Rouzbeh A. Shirvani\"},{\"authorId\":\"2180949\",\"name\":\"Yaser Keneshloo\"},{\"authorId\":\"1518270914\",\"name\":\"Nader Tavvaf\"},{\"authorId\":\"1705950\",\"name\":\"E. Fox\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d426fc815357d4dc0313d989cd3e2963787fc9e3\",\"title\":\"Natural Language Processing Advancements By Deep Learning: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/d426fc815357d4dc0313d989cd3e2963787fc9e3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1703.06492\",\"authors\":[{\"authorId\":\"2973866\",\"name\":\"J. Huang\"},{\"authorId\":\"9951160\",\"name\":\"Modar Alfadly\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"533fd756cdc4bad2994f921950b7822c6a0fd0c5\",\"title\":\"VQABQ: Visual Question Answering by Basic Questions\",\"url\":\"https://www.semanticscholar.org/paper/533fd756cdc4bad2994f921950b7822c6a0fd0c5\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1611.06949\",\"authors\":[{\"authorId\":\"2889075\",\"name\":\"L. Yang\"},{\"authorId\":\"3355264\",\"name\":\"Kevin D. Tang\"},{\"authorId\":\"1706007\",\"name\":\"Jianchao Yang\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"}],\"doi\":\"10.1109/CVPR.2017.214\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"21fa67345e49642b8ebb22a59c4b2799a56e996f\",\"title\":\"Dense Captioning with Joint Inference and Visual Context\",\"url\":\"https://www.semanticscholar.org/paper/21fa67345e49642b8ebb22a59c4b2799a56e996f\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7574699\",\"name\":\"Handong Zhao\"},{\"authorId\":\"33421444\",\"name\":\"Quanfu Fan\"},{\"authorId\":\"1891570\",\"name\":\"Dan Gutfreund\"},{\"authorId\":\"145692782\",\"name\":\"Yun Fu\"}],\"doi\":\"10.1109/WACV.2018.00205\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"03c820f35afdc38dd05e4c663d2877e2602bcde0\",\"title\":\"Semantically Guided Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/03c820f35afdc38dd05e4c663d2877e2602bcde0\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152392281\",\"name\":\"Yassine Mrabet\"},{\"authorId\":\"1398175407\",\"name\":\"Dina Demner-Fushman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"52b248b1fe0e099eee04f734e3abc7bb5a7902df\",\"title\":\"On Agreements in Visual Understanding\",\"url\":\"https://www.semanticscholar.org/paper/52b248b1fe0e099eee04f734e3abc7bb5a7902df\",\"venue\":\"ViGIL@NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2351434\",\"name\":\"Zhongwen Xu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"6bd7ff039ff38f4bb41f7a4b9a1f370ef02eed80\",\"title\":\"Large-scale video analysis and understanding\",\"url\":\"https://www.semanticscholar.org/paper/6bd7ff039ff38f4bb41f7a4b9a1f370ef02eed80\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1574421683\",\"name\":\"Xi Zhu\"},{\"authorId\":\"1855978\",\"name\":\"Zhendong Mao\"},{\"authorId\":\"8157255\",\"name\":\"Zhineng Chen\"},{\"authorId\":\"40282454\",\"name\":\"Y. Li\"},{\"authorId\":\"50218711\",\"name\":\"Z. Wang\"},{\"authorId\":\"15696552\",\"name\":\"Bin Wang\"}],\"doi\":\"10.1007/s11042-020-08790-0\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"49c9921b5df66b421b5e6432d84a8eb699c6443b\",\"title\":\"Object-difference drived graph convolutional networks for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/49c9921b5df66b421b5e6432d84a8eb699c6443b\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"1709.06308\",\"authors\":[{\"authorId\":\"6002624\",\"name\":\"Tingting Qiao\"},{\"authorId\":\"40240283\",\"name\":\"J. Dong\"},{\"authorId\":\"7471918\",\"name\":\"Duanqing Xu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3fafe70edc7067015ca2d49aef2773c22a71647d\",\"title\":\"Exploring Human-like Attention Supervision in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/3fafe70edc7067015ca2d49aef2773c22a71647d\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1715610\",\"name\":\"Qi Wu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"},{\"authorId\":\"3775903\",\"name\":\"J. Wang\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"55a7286f014cc6b51a3f50b1e6bc8acc8166f231\",\"title\":\"Image Captioning and Visual Question Answering Based on Attributes and Their Related External Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/55a7286f014cc6b51a3f50b1e6bc8acc8166f231\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49268056\",\"name\":\"J. Hu\"},{\"authorId\":\"2287686\",\"name\":\"Xiangbo Shu\"}],\"doi\":\"10.1145/3339363.3339389\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f8e21836e80d6641886a5a0a1f66fc7e54f6db76\",\"title\":\"Semantic BI-Embedded GRU for Fill-in-the-Blank Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f8e21836e80d6641886a5a0a1f66fc7e54f6db76\",\"venue\":\"CSSE 2019\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"25184078\",\"name\":\"M. Chevalier\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1b23981c8466e9a3b98f43b503d0dec0ac464bfa\",\"title\":\"R\\u00e9solution variable et information privil\\u00e9gi\\u00e9e pour la reconnaissance d'images. (Varying resolution and privileged information for image recognition)\",\"url\":\"https://www.semanticscholar.org/paper/1b23981c8466e9a3b98f43b503d0dec0ac464bfa\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1708.02760\",\"authors\":[{\"authorId\":\"47002704\",\"name\":\"Y. Li\"},{\"authorId\":\"145544640\",\"name\":\"C. Huang\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"}],\"doi\":\"10.1109/ICCV.2017.370\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"acb1ffd5ba92b0c450ec63f36f4f67a972fc35ed\",\"title\":\"Learning to Disambiguate by Asking Discriminative Questions\",\"url\":\"https://www.semanticscholar.org/paper/acb1ffd5ba92b0c450ec63f36f4f67a972fc35ed\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1804.02516\",\"authors\":[{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3448af861bf5d44ce7ab6b25002504815212252e\",\"title\":\"Learning a Text-Video Embedding from Incomplete and Heterogeneous Data\",\"url\":\"https://www.semanticscholar.org/paper/3448af861bf5d44ce7ab6b25002504815212252e\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1610.01465\",\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1016/j.cviu.2017.06.005\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6d92ce1c4f7f0ccfe068e663903e4dd614a15ede\",\"title\":\"Visual question answering: Datasets, algorithms, and future challenges\",\"url\":\"https://www.semanticscholar.org/paper/6d92ce1c4f7f0ccfe068e663903e4dd614a15ede\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":\"1604.03505\",\"authors\":[{\"authorId\":\"40424000\",\"name\":\"Prithvijit Chattopadhyay\"},{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"1388516470\",\"name\":\"Ramprasaath R. Selvaraju\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2017.471\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e39ea61d4751fa3447041ad0706e32e88be15e9d\",\"title\":\"Counting Everyday Objects in Everyday Scenes\",\"url\":\"https://www.semanticscholar.org/paper/e39ea61d4751fa3447041ad0706e32e88be15e9d\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1704.03493\",\"authors\":[{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"3095572\",\"name\":\"Ziyu Zhang\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1109/CVPR.2017.575\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"390cac0a7e2f90c8efb12a1a9ff850ef386e5db6\",\"title\":\"Creativity: Generating Diverse Questions Using Variational Autoencoders\",\"url\":\"https://www.semanticscholar.org/paper/390cac0a7e2f90c8efb12a1a9ff850ef386e5db6\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1511.03416\",\"authors\":[{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"50499889\",\"name\":\"O. Groth\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2016.540\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"def584565d05d6a8ba94de6621adab9e301d375d\",\"title\":\"Visual7W: Grounded Question Answering in Images\",\"url\":\"https://www.semanticscholar.org/paper/def584565d05d6a8ba94de6621adab9e301d375d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2835963\",\"name\":\"A. Razavian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"656a59954de3c9fcf82ffcef926af6ade2f3fdb5\",\"title\":\"Convolutional Network Representation for Visual Recognition\",\"url\":\"https://www.semanticscholar.org/paper/656a59954de3c9fcf82ffcef926af6ade2f3fdb5\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7808048\",\"name\":\"M. Bucher\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d423f37185a2210d5e47f24d4792e68d0088cd52\",\"title\":\"Apprentissage et exploitation de repr\\u00e9sentations s\\u00e9mantiques pour la classification et la recherche d'images. (Learning and exploiting semantic representations for image classification and retrieval)\",\"url\":\"https://www.semanticscholar.org/paper/d423f37185a2210d5e47f24d4792e68d0088cd52\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143852685\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"38314306\",\"name\":\"Rakshith Shetty\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"1708642\",\"name\":\"J. Laaksonen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"204184e8a54c42bac589c19c3fa0c5d3d2c6009b\",\"title\":\"Can Saliency Information Benefit Image Captioning Models?\",\"url\":\"https://www.semanticscholar.org/paper/204184e8a54c42bac589c19c3fa0c5d3d2c6009b\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1711.04323\",\"authors\":[{\"authorId\":\"38211837\",\"name\":\"Idan Schwartz\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"1918412\",\"name\":\"T. Hazan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"799537fa855caf53a6a3a7cf20301a81e90da127\",\"title\":\"High-Order Attention Models for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/799537fa855caf53a6a3a7cf20301a81e90da127\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1809.02765\",\"authors\":[{\"authorId\":\"51152129\",\"name\":\"Ruixuan Luo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4e614e344ecbb36770d45fc14d3b5152b653aa97\",\"title\":\"Exploration on Grounded Word Embedding: Matching Words and Images with Image-Enhanced Skip-Gram Model\",\"url\":\"https://www.semanticscholar.org/paper/4e614e344ecbb36770d45fc14d3b5152b653aa97\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1904.08607\",\"authors\":[{\"authorId\":\"2447631\",\"name\":\"Junyeong Kim\"},{\"authorId\":\"103278467\",\"name\":\"Minuk Ma\"},{\"authorId\":\"4604969\",\"name\":\"Kyungsu Kim\"},{\"authorId\":\"2561991\",\"name\":\"S. Kim\"},{\"authorId\":\"145954697\",\"name\":\"C. Yoo\"}],\"doi\":\"10.1109/CVPR.2019.00853\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b621afeef5888f8f71fd6ca97a62daa0d0cb6d69\",\"title\":\"Progressive Attention Memory Network for Movie Story Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b621afeef5888f8f71fd6ca97a62daa0d0cb6d69\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144288475\",\"name\":\"Yufei Feng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d037e105412a7edc93e97c4ea0abd209ec23795e\",\"title\":\"Learning Capsule Networks with Images and Text\",\"url\":\"https://www.semanticscholar.org/paper/d037e105412a7edc93e97c4ea0abd209ec23795e\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7361508\",\"name\":\"Zhiqiang Wan\"},{\"authorId\":\"144996615\",\"name\":\"Haibo He\"}],\"doi\":\"10.1109/TBDATA.2018.2884486\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8524d0447d84c6b2dc41e4bca81e0daf6b1b67ac\",\"title\":\"AnswerNet: Learning to Answer Questions\",\"url\":\"https://www.semanticscholar.org/paper/8524d0447d84c6b2dc41e4bca81e0daf6b1b67ac\",\"venue\":\"IEEE Transactions on Big Data\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11448948\",\"name\":\"C. Han\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e80958437389b7aaa3cfb96ceba647827cafe32e\",\"title\":\"Visual Concept-Metaconcept Learning\",\"url\":\"https://www.semanticscholar.org/paper/e80958437389b7aaa3cfb96ceba647827cafe32e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1805.02997\",\"authors\":[{\"authorId\":null,\"name\":\"Yi Yu\"},{\"authorId\":\"1764527\",\"name\":\"S. Tang\"},{\"authorId\":\"1712839\",\"name\":\"K. Aizawa\"},{\"authorId\":\"1705519\",\"name\":\"A. Aizawa\"}],\"doi\":\"10.1109/TNNLS.2018.2856253\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c2e9728db91c96665a7fb7a0e0f4a7bc37399b1e\",\"title\":\"Category-Based Deep CCA for Fine-Grained Venue Discovery From Multimodal Data\",\"url\":\"https://www.semanticscholar.org/paper/c2e9728db91c96665a7fb7a0e0f4a7bc37399b1e\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2019},{\"arxivId\":\"1709.04625\",\"authors\":[{\"authorId\":\"2973866\",\"name\":\"J. Huang\"},{\"authorId\":\"9951160\",\"name\":\"Modar Alfadly\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"28853de59af8560dca5ff83f68f5af1cec0493d9\",\"title\":\"Robustness Analysis of Visual QA Models by Basic Questions\",\"url\":\"https://www.semanticscholar.org/paper/28853de59af8560dca5ff83f68f5af1cec0493d9\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50974488\",\"name\":\"Mingrui Lao\"},{\"authorId\":\"49813983\",\"name\":\"Yanming Guo\"},{\"authorId\":\"49528566\",\"name\":\"Hui Wang\"},{\"authorId\":\"35742440\",\"name\":\"X. Zhang\"}],\"doi\":\"10.1109/ACCESS.2018.2844789\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2609626519d8fa0ccc53bce49a3a21b928deeca6\",\"title\":\"Cross-Modal Multistep Fusion Network With Co-Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2609626519d8fa0ccc53bce49a3a21b928deeca6\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22228139\",\"name\":\"Yunan Ye\"},{\"authorId\":\"101266543\",\"name\":\"Shifeng Zhang\"},{\"authorId\":\"48515305\",\"name\":\"Yimeng Li\"},{\"authorId\":\"152519410\",\"name\":\"Xufeng Qian\"},{\"authorId\":\"1774936\",\"name\":\"Siliang Tang\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"},{\"authorId\":\"153269968\",\"name\":\"Jun Xiao\"}],\"doi\":\"10.1016/j.ipm.2020.102265\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"32589847320c3c783e6eaf512e7723b8d5f5fb0a\",\"title\":\"Video question answering via grounded cross-attention network learning\",\"url\":\"https://www.semanticscholar.org/paper/32589847320c3c783e6eaf512e7723b8d5f5fb0a\",\"venue\":\"Inf. Process. Manag.\",\"year\":2020},{\"arxivId\":\"1704.03899\",\"authors\":[{\"authorId\":\"145888238\",\"name\":\"Zhou Ren\"},{\"authorId\":\"145779951\",\"name\":\"X. Wang\"},{\"authorId\":\"145002061\",\"name\":\"N. Zhang\"},{\"authorId\":\"2936952\",\"name\":\"Xutao Lv\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"}],\"doi\":\"10.1109/CVPR.2017.128\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c689f73f8ea65c6e81c628f2b37feae09b29e46b\",\"title\":\"Deep Reinforcement Learning-Based Image Captioning with Embedding Reward\",\"url\":\"https://www.semanticscholar.org/paper/c689f73f8ea65c6e81c628f2b37feae09b29e46b\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71222785\",\"name\":\"Yun Liu\"},{\"authorId\":\"46447759\",\"name\":\"X. Zhang\"},{\"authorId\":\"1939569\",\"name\":\"Feiran Huang\"},{\"authorId\":\"2548662\",\"name\":\"X. Tang\"},{\"authorId\":\"1707275\",\"name\":\"Zhoujun Li\"}],\"doi\":\"10.1016/J.ASOC.2019.105584\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a78477728a184a80cdfcfb97d5023f37961c3b6a\",\"title\":\"Visual question answering via Attention-based syntactic structure tree-LSTM\",\"url\":\"https://www.semanticscholar.org/paper/a78477728a184a80cdfcfb97d5023f37961c3b6a\",\"venue\":\"Appl. Soft Comput.\",\"year\":2019},{\"arxivId\":\"1611.01603\",\"authors\":[{\"authorId\":\"4418074\",\"name\":\"Minjoon Seo\"},{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"2548384\",\"name\":\"Hannaneh Hajishirzi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3a7b63b50c64f4ec3358477790e84cbd6be2a0b4\",\"title\":\"Bidirectional Attention Flow for Machine Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/3a7b63b50c64f4ec3358477790e84cbd6be2a0b4\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1611.04021\",\"authors\":[{\"authorId\":\"32970572\",\"name\":\"Kuo-Hao Zeng\"},{\"authorId\":\"3451456\",\"name\":\"Tseng-Hung Chen\"},{\"authorId\":\"8551209\",\"name\":\"Ching-Yao Chuang\"},{\"authorId\":\"1826179\",\"name\":\"Yuan-Hong Liao\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1da2431a799f68888b7e035fe49fe47a4735b71b\",\"title\":\"Leveraging Video Descriptions to Learn Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1da2431a799f68888b7e035fe49fe47a4735b71b\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":\"1911.09655\",\"authors\":[{\"authorId\":\"1822214\",\"name\":\"Haytham M. Fayek\"},{\"authorId\":\"31039758\",\"name\":\"J. Johnson\"}],\"doi\":\"10.1109/TASLP.2020.3010650\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bfa437129daef8533708924c395c3fd0c5c3bf81\",\"title\":\"Temporal Reasoning via Audio Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/bfa437129daef8533708924c395c3fd0c5c3bf81\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2136562\",\"name\":\"Mohit Iyyer\"}],\"doi\":\"10.13016/M2930NW6W\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"126be977c03d732fbef2381565a41b957d41a2cc\",\"title\":\"Discourse-Level Language Understanding with Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/126be977c03d732fbef2381565a41b957d41a2cc\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"2004.05595\",\"authors\":[{\"authorId\":\"1576818877\",\"name\":\"Kento Terao\"},{\"authorId\":\"47668008\",\"name\":\"T. Tamaki\"},{\"authorId\":\"1688940\",\"name\":\"B. Raytchev\"},{\"authorId\":\"1686272\",\"name\":\"K. Kaneda\"},{\"authorId\":\"49969107\",\"name\":\"S. Satoh\"}],\"doi\":\"10.1109/ACCESS.2020.3022063\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"217d80b1425c24996dafbe539a1e976a1e790ac0\",\"title\":\"Which visual questions are difficult to answer? Analysis with Entropy of Answer Distributions\",\"url\":\"https://www.semanticscholar.org/paper/217d80b1425c24996dafbe539a1e976a1e790ac0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.05406\",\"authors\":[{\"authorId\":\"4631835\",\"name\":\"Mingzhe Li\"},{\"authorId\":\"46772896\",\"name\":\"Xiuying Chen\"},{\"authorId\":\"47357425\",\"name\":\"S. Gao\"},{\"authorId\":\"51177175\",\"name\":\"Zhangming Chan\"},{\"authorId\":\"144060462\",\"name\":\"Dongyan Zhao\"},{\"authorId\":\"1845885740\",\"name\":\"Rui Yan\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.752\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3ed35a45f0d912afe37b915a30e2b254b946e10d\",\"title\":\"VMSMO: Learning to Generate Multimodal Summary for Video-based News Articles\",\"url\":\"https://www.semanticscholar.org/paper/3ed35a45f0d912afe37b915a30e2b254b946e10d\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2002.06800\",\"authors\":[{\"authorId\":\"9208016\",\"name\":\"Aakansha Mishra\"},{\"authorId\":\"47583423\",\"name\":\"A. Anand\"},{\"authorId\":\"46401518\",\"name\":\"Prithwijit Guha\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206913\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"212c2d71f9f404bcbb3cfe8bc35e5e1ea25076c5\",\"title\":\"CQ-VQA: Visual Question Answering on Categorized Questions\",\"url\":\"https://www.semanticscholar.org/paper/212c2d71f9f404bcbb3cfe8bc35e5e1ea25076c5\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40295709\",\"name\":\"F. Liu\"},{\"authorId\":null,\"name\":\"Jing Liu\"},{\"authorId\":\"48386951\",\"name\":\"Xinxin Zhu\"},{\"authorId\":\"120313754\",\"name\":\"Richang Hong\"},{\"authorId\":\"1699900\",\"name\":\"H. Lu\"}],\"doi\":\"10.1145/3394171.3413649\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"063235546b312ee4cb5cc67578b6e879461c6d83\",\"title\":\"Dual Hierarchical Temporal Convolutional Network with QA-Aware Dynamic Normalization for Video Story Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/063235546b312ee4cb5cc67578b6e879461c6d83\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1910.14671\",\"authors\":[{\"authorId\":\"9852531\",\"name\":\"J. Lin\"},{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1743587c272c36dbda0adc50496bf7f34b8148f1\",\"title\":\"TAB-VCR: Tags and Attributes based Visual Commonsense Reasoning Baselines\",\"url\":\"https://www.semanticscholar.org/paper/1743587c272c36dbda0adc50496bf7f34b8148f1\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"74295098\",\"name\":\"M. Rishita\"},{\"authorId\":\"107786137\",\"name\":\"Tanvir Ahmed Harris\"}],\"doi\":\"10.1109/ICNEWS.2018.8903980\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f42d09f11171e91922cd58a14e125d0bc11f566d\",\"title\":\"Dog Breed Classifier using Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/f42d09f11171e91922cd58a14e125d0bc11f566d\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48669970\",\"name\":\"X. Xu\"},{\"authorId\":\"2727656\",\"name\":\"X. Chen\"},{\"authorId\":null,\"name\":\"Chang Liu\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"143711382\",\"name\":\"D. Song\"}],\"doi\":\"10.1109/CVPR.2018.00520\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2fa9b32ebc329d57fa2e3fabb9e12382f019f47a\",\"title\":\"Fooling Vision and Language Models Despite Localization and Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/2fa9b32ebc329d57fa2e3fabb9e12382f019f47a\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"31081539\",\"name\":\"Pengpeng Zeng\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.24963/ijcai.2018/126\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b18d7ce3e7514fdae89ff410e2e122382c3d10a9\",\"title\":\"From Pixels to Objects: Cubic Visual Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b18d7ce3e7514fdae89ff410e2e122382c3d10a9\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2123865\",\"name\":\"F. Tung\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"}],\"doi\":\"10.1109/CVPR.2018.00821\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"289b69ac9bc6b859ab05671f02b0a4f82280e88f\",\"title\":\"CLIP-Q: Deep Network Compression Learning by In-parallel Pruning-Quantization\",\"url\":\"https://www.semanticscholar.org/paper/289b69ac9bc6b859ab05671f02b0a4f82280e88f\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51021338\",\"name\":\"Nelson Ruwa\"},{\"authorId\":\"3069077\",\"name\":\"Q. Mao\"},{\"authorId\":\"79927338\",\"name\":\"L. Wang\"},{\"authorId\":\"37233332\",\"name\":\"J. Gou\"}],\"doi\":\"10.1016/J.NEUCOM.2019.06.046\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1b6ce7e65130431eecf98db2e6c162893bbe5127\",\"title\":\"Affective question answering on video\",\"url\":\"https://www.semanticscholar.org/paper/1b6ce7e65130431eecf98db2e6c162893bbe5127\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"1708.02709\",\"authors\":[{\"authorId\":\"70632151\",\"name\":\"Tom Young\"},{\"authorId\":\"8223433\",\"name\":\"Devamanyu Hazarika\"},{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"49943757\",\"name\":\"E. Cambria\"}],\"doi\":\"10.1109/MCI.2018.2840738\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ce2d5b5856bb6c9ab5c2390eb8b180c75a162055\",\"title\":\"Recent Trends in Deep Learning Based Natural Language Processing [Review Article]\",\"url\":\"https://www.semanticscholar.org/paper/ce2d5b5856bb6c9ab5c2390eb8b180c75a162055\",\"venue\":\"IEEE Computational Intelligence Magazine\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1717592\",\"name\":\"W. Zhang\"},{\"authorId\":\"1792246\",\"name\":\"C. Zhang\"},{\"authorId\":\"3114205\",\"name\":\"P. Liu\"},{\"authorId\":\"2035942\",\"name\":\"Zhiqiang Zhan\"},{\"authorId\":\"34985964\",\"name\":\"Xiaofeng Qiu\"}],\"doi\":\"10.1109/BIGCOM.2017.17\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a3f24a03b9b55327704fba3aed182323137113c2\",\"title\":\"Two-Step Joint Attention Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a3f24a03b9b55327704fba3aed182323137113c2\",\"venue\":\"2017 3rd International Conference on Big Data Computing and Communications (BIGCOM)\",\"year\":2017},{\"arxivId\":\"1904.05880\",\"authors\":[{\"authorId\":\"38211837\",\"name\":\"Idan Schwartz\"},{\"authorId\":\"1885974\",\"name\":\"Seunghak Yu\"},{\"authorId\":\"1918412\",\"name\":\"T. Hazan\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1109/CVPR.2019.00214\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ecce0a7b0f9b2bfbc6ca2c99805bddd53178ac35\",\"title\":\"Factor Graph Attention\",\"url\":\"https://www.semanticscholar.org/paper/ecce0a7b0f9b2bfbc6ca2c99805bddd53178ac35\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1511.05756\",\"authors\":[{\"authorId\":\"2018393\",\"name\":\"Hyeonwoo Noh\"},{\"authorId\":\"14454974\",\"name\":\"P. H. Seo\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":\"10.1109/CVPR.2016.11\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"385c18cc4024a3b3206c508c512e037b9c00b8f3\",\"title\":\"Image Question Answering Using Convolutional Neural Network with Dynamic Parameter Prediction\",\"url\":\"https://www.semanticscholar.org/paper/385c18cc4024a3b3206c508c512e037b9c00b8f3\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31696860\",\"name\":\"Shurong Sheng\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"145446752\",\"name\":\"Marie-Francine Moens\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10be82098017fc2d60b0572cea8032afabad5d1a\",\"title\":\"A Dataset for Multimodal Question Answering in the Cultural Heritage Domain\",\"url\":\"https://www.semanticscholar.org/paper/10be82098017fc2d60b0572cea8032afabad5d1a\",\"venue\":\"LT4DH@COLING\",\"year\":2016},{\"arxivId\":\"1709.08693\",\"authors\":[{\"authorId\":\"48670486\",\"name\":\"X. Xu\"},{\"authorId\":\"2727656\",\"name\":\"X. Chen\"},{\"authorId\":\"28969396\",\"name\":\"C. Liu\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"143711382\",\"name\":\"D. Song\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dda1822872942f658b89e7e1c1ffe08c35e7b290\",\"title\":\"Can you fool AI with adversarial examples on a visual Turing test?\",\"url\":\"https://www.semanticscholar.org/paper/dda1822872942f658b89e7e1c1ffe08c35e7b290\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9330502\",\"name\":\"Navneet Sinha\"},{\"authorId\":\"1841118\",\"name\":\"Ifeoma Nwogu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"20289282fedfd60d9d4a7153f460f5c8e0a502b8\",\"title\":\"Goal Driven Detection in Natural Scenes\",\"url\":\"https://www.semanticscholar.org/paper/20289282fedfd60d9d4a7153f460f5c8e0a502b8\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1707.00683\",\"authors\":[{\"authorId\":\"153559313\",\"name\":\"H. D. Vries\"},{\"authorId\":\"3367628\",\"name\":\"Florian Strub\"},{\"authorId\":\"143716734\",\"name\":\"J. Mary\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1721354\",\"name\":\"Olivier Pietquin\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"feeb3a2aa35a02e06546d05d94bac9a2123fc0c8\",\"title\":\"Modulating early visual processing by language\",\"url\":\"https://www.semanticscholar.org/paper/feeb3a2aa35a02e06546d05d94bac9a2123fc0c8\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1705.03633\",\"authors\":[{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"73710317\",\"name\":\"B. Hariharan\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"},{\"authorId\":\"50196944\",\"name\":\"Judy Hoffman\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/ICCV.2017.325\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2e17cf6a339fd071ad222062f868e882ef4120a4\",\"title\":\"Inferring and Executing Programs for Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/2e17cf6a339fd071ad222062f868e882ef4120a4\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1511.07394\",\"authors\":[{\"authorId\":\"143953573\",\"name\":\"K. Shih\"},{\"authorId\":\"37415643\",\"name\":\"S. Singh\"},{\"authorId\":\"2433269\",\"name\":\"Derek Hoiem\"}],\"doi\":\"10.1109/CVPR.2016.499\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"175e9bb50cc062c6c1742a5d90c8dfe31d2e4e22\",\"title\":\"Where to Look: Focus Regions for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/175e9bb50cc062c6c1742a5d90c8dfe31d2e4e22\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1601.06615\",\"authors\":[{\"authorId\":\"2822290\",\"name\":\"Suraj Srinivas\"},{\"authorId\":\"1730952\",\"name\":\"Ravi Kiran Sarvadevabhatla\"},{\"authorId\":\"2217000\",\"name\":\"Konda Reddy Mopuri\"},{\"authorId\":\"40390520\",\"name\":\"N. Prabhu\"},{\"authorId\":\"1784761\",\"name\":\"S. Kruthiventi\"},{\"authorId\":\"144682140\",\"name\":\"R. Venkatesh Babu\"}],\"doi\":\"10.3389/frobt.2015.00036\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"412b3ef02c85087e5f1721176114672c722b17a4\",\"title\":\"A Taxonomy of Deep Convolutional Neural Nets for Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/412b3ef02c85087e5f1721176114672c722b17a4\",\"venue\":\"Front. Robot. AI\",\"year\":2016},{\"arxivId\":\"2003.04679\",\"authors\":[{\"authorId\":\"2345018\",\"name\":\"Shen Gao\"},{\"authorId\":\"46772896\",\"name\":\"Xiuying Chen\"},{\"authorId\":\"73100429\",\"name\":\"Chang Liu\"},{\"authorId\":\"144073922\",\"name\":\"Li Liu\"},{\"authorId\":\"144060462\",\"name\":\"Dongyan Zhao\"},{\"authorId\":\"1399646334\",\"name\":\"Rui Yan\"}],\"doi\":\"10.1145/3366423.3380191\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3ab771b7431f5d3dce4372a18555f4216528ace7\",\"title\":\"Learning to Respond with Stickers: A Framework of Unifying Multi-Modality in Multi-Turn Dialog\",\"url\":\"https://www.semanticscholar.org/paper/3ab771b7431f5d3dce4372a18555f4216528ace7\",\"venue\":\"WWW\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144663763\",\"name\":\"Q. Wu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"bc2856e70ad3c8fe439dec6cc6a2e03d6e090fb7\",\"title\":\"What value high level concepts in vision to language problems\",\"url\":\"https://www.semanticscholar.org/paper/bc2856e70ad3c8fe439dec6cc6a2e03d6e090fb7\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3149518\",\"name\":\"Volkan Cirik\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"},{\"authorId\":\"1694075\",\"name\":\"E. Hovy\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"720e06688e1038026070253891037652f5d0d9f5\",\"title\":\"Chess Q & A : Question Answering on Chess Games\",\"url\":\"https://www.semanticscholar.org/paper/720e06688e1038026070253891037652f5d0d9f5\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39744108\",\"name\":\"S. Aditya\"},{\"authorId\":\"1760291\",\"name\":\"Chitta Baral\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"63856e83b69ac15e1252c1c3d89114dcf806fbcc\",\"title\":\"DeepIU : An Architecture for Image Understanding\",\"url\":\"https://www.semanticscholar.org/paper/63856e83b69ac15e1252c1c3d89114dcf806fbcc\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1704.03944\",\"authors\":[{\"authorId\":\"145489055\",\"name\":\"Y. Zhang\"},{\"authorId\":\"27257564\",\"name\":\"Luyao Yuan\"},{\"authorId\":\"1857914\",\"name\":\"Yijie Guo\"},{\"authorId\":\"1755497\",\"name\":\"Zhiyuan He\"},{\"authorId\":\"38648777\",\"name\":\"Ian Huang\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"}],\"doi\":\"10.1109/CVPR.2017.122\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e60416112ce2a4a5ca7826f1636206f80dbd390b\",\"title\":\"Discriminative Bimodal Networks for Visual Localization and Detection with Natural Language Queries\",\"url\":\"https://www.semanticscholar.org/paper/e60416112ce2a4a5ca7826f1636206f80dbd390b\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1510.08973\",\"authors\":[{\"authorId\":\"3253737\",\"name\":\"F. Sadeghi\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8eac065bece185d4b16ce2f885da0e56d4d3474d\",\"title\":\"Visalogy: Answering Visual Analogy Questions\",\"url\":\"https://www.semanticscholar.org/paper/8eac065bece185d4b16ce2f885da0e56d4d3474d\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1609.08124\",\"authors\":[{\"authorId\":\"1730844\",\"name\":\"Atousa Torabi\"},{\"authorId\":\"1721168\",\"name\":\"Niket Tandon\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2068f66a10254d457cdb5fab74b0128b24bfdb65\",\"title\":\"Learning Language-Visual Embedding for Movie Understanding with Natural-Language\",\"url\":\"https://www.semanticscholar.org/paper/2068f66a10254d457cdb5fab74b0128b24bfdb65\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"2007.01780\",\"authors\":[{\"authorId\":\"31926869\",\"name\":\"A. Pollard\"},{\"authorId\":\"2113093\",\"name\":\"J. Shapiro\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b1b8ffe938f706a9416c319a34793a2389866773\",\"title\":\"Visual Question Answering as a Multi-Task Problem\",\"url\":\"https://www.semanticscholar.org/paper/b1b8ffe938f706a9416c319a34793a2389866773\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1805.11730\",\"authors\":[{\"authorId\":\"2584898\",\"name\":\"K. Liu\"},{\"authorId\":\"3076945\",\"name\":\"Yanen Li\"},{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":\"145603129\",\"name\":\"P. Natarajan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3829607559475bbf15c66850810a497eac1a26e1\",\"title\":\"Learn to Combine Modalities in Multimodal Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/3829607559475bbf15c66850810a497eac1a26e1\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1904.05876\",\"authors\":[{\"authorId\":\"38211837\",\"name\":\"Idan Schwartz\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"1918412\",\"name\":\"T. Hazan\"}],\"doi\":\"10.1109/CVPR.2019.01283\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf072e469d82e71f0515f32b686fb084f4f31714\",\"title\":\"A Simple Baseline for Audio-Visual Scene-Aware Dialog\",\"url\":\"https://www.semanticscholar.org/paper/cf072e469d82e71f0515f32b686fb084f4f31714\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1710.10675\",\"authors\":[{\"authorId\":\"1808172\",\"name\":\"D. Kumar\"},{\"authorId\":\"144639556\",\"name\":\"Graham W. Taylor\"},{\"authorId\":\"144821966\",\"name\":\"A. Wong\"}],\"doi\":\"10.1109/ACCESS.2019.2893635\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4f73e8d36980f9be1903f3358a727fdd13e3b76b\",\"title\":\"Discovery Radiomics With CLEAR-DR: Interpretable Computer Aided Diagnosis of Diabetic Retinopathy\",\"url\":\"https://www.semanticscholar.org/paper/4f73e8d36980f9be1903f3358a727fdd13e3b76b\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Xin He\"},{\"authorId\":\"2667724\",\"name\":\"D. Zeng\"}],\"doi\":\"10.1109/ISPACS.2017.8266567\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f5a00153cb49c2f66b072832adf053ebabf50850\",\"title\":\"Real-time pedestrian warning system on highway using deep learning methods\",\"url\":\"https://www.semanticscholar.org/paper/f5a00153cb49c2f66b072832adf053ebabf50850\",\"venue\":\"2017 International Symposium on Intelligent Signal Processing and Communication Systems (ISPACS)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"2150275\",\"name\":\"S. Kottur\"},{\"authorId\":\"39855500\",\"name\":\"K. Gupta\"},{\"authorId\":\"1899992\",\"name\":\"Avi Singh\"},{\"authorId\":\"24508084\",\"name\":\"Deshraj Yadav\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"144915495\",\"name\":\"Jos\\u00e9 M. F. Moura\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1109/TPAMI.2018.2828437\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4c16428a0bae507d2a1785860f07168a807d8e59\",\"title\":\"Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/4c16428a0bae507d2a1785860f07168a807d8e59\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"42afa9a0166eeb45cb2e9b37e0a8eec482f78fe0\",\"title\":\"Visual Question Answering and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/42afa9a0166eeb45cb2e9b37e0a8eec482f78fe0\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145040726\",\"name\":\"R. Bernardi\"},{\"authorId\":\"2588033\",\"name\":\"Ruken Cakici\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"},{\"authorId\":\"1398643531\",\"name\":\"N. Ikizler-Cinbis\"},{\"authorId\":\"1393020635\",\"name\":\"F. Keller\"},{\"authorId\":\"35347012\",\"name\":\"A. Muscat\"},{\"authorId\":\"2022124\",\"name\":\"Barbara Plank\"}],\"doi\":\"10.1613/jair.4900\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c162d791b63682d928c09578bd38c3dd61f78c8c\",\"title\":\"Automatic Description Generation from Images: A Survey of Models, Datasets, and Evaluation Measures\",\"url\":\"https://www.semanticscholar.org/paper/c162d791b63682d928c09578bd38c3dd61f78c8c\",\"venue\":\"J. Artif. Intell. Res.\",\"year\":2016},{\"arxivId\":\"1606.08390\",\"authors\":[{\"authorId\":\"14258597\",\"name\":\"A. Jabri\"},{\"authorId\":\"2319608\",\"name\":\"Armand Joulin\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"}],\"doi\":\"10.1007/978-3-319-46484-8_44\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3c1bbd2672c11a796f1e6e6aa787257498ec8bec\",\"title\":\"Revisiting Visual Question Answering Baselines\",\"url\":\"https://www.semanticscholar.org/paper/3c1bbd2672c11a796f1e6e6aa787257498ec8bec\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1909.03409\",\"authors\":[{\"authorId\":\"145066132\",\"name\":\"Bin Guo\"},{\"authorId\":null,\"name\":\"Hao Wang\"},{\"authorId\":\"151260226\",\"name\":\"Y. Ding\"},{\"authorId\":\"117889029\",\"name\":\"Shaoyang Hao\"},{\"authorId\":\"79953570\",\"name\":\"Y. Sun\"},{\"authorId\":\"2256618\",\"name\":\"Z. Yu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"4cd7ce0d1ad83b2afbc2468d5d43ff8de0d9ae28\",\"title\":\"c-TextGen: Conditional Text Generation for Harmonious Human-Machine Interaction\",\"url\":\"https://www.semanticscholar.org/paper/4cd7ce0d1ad83b2afbc2468d5d43ff8de0d9ae28\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1906.03327\",\"authors\":[{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"35838466\",\"name\":\"D. Zhukov\"},{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"}],\"doi\":\"10.1109/ICCV.2019.00272\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9311779489e597315488749ee6c386bfa3f3512e\",\"title\":\"HowTo100M: Learning a Text-Video Embedding by Watching Hundred Million Narrated Video Clips\",\"url\":\"https://www.semanticscholar.org/paper/9311779489e597315488749ee6c386bfa3f3512e\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1911.07528\",\"authors\":[{\"authorId\":\"50504111\",\"name\":\"Mo Zhou\"},{\"authorId\":\"1786361\",\"name\":\"Zhenxing Niu\"},{\"authorId\":\"153755094\",\"name\":\"L. Wang\"},{\"authorId\":\"2687716\",\"name\":\"Zhanning Gao\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"49195402\",\"name\":\"Gang Hua\"}],\"doi\":\"10.1609/AAAI.V34I07.7006\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"640dec44287ddf237da06ae863ae7669a1737281\",\"title\":\"Ladder Loss for Coherent Visual-Semantic Embedding\",\"url\":\"https://www.semanticscholar.org/paper/640dec44287ddf237da06ae863ae7669a1737281\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2707832\",\"name\":\"Geonmo Gu\"},{\"authorId\":\"49899378\",\"name\":\"S. T. Kim\"},{\"authorId\":\"7251290\",\"name\":\"Yong Man Ro\"}],\"doi\":\"10.1109/ICME.2017.8019540\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cb8f1f77a8b19d99dfe0c7b50dae3978cf646aa9\",\"title\":\"Adaptive attention fusion network for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/cb8f1f77a8b19d99dfe0c7b50dae3978cf646aa9\",\"venue\":\"2017 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2017},{\"arxivId\":\"2002.01464\",\"authors\":[{\"authorId\":\"11448948\",\"name\":\"C. Han\"},{\"authorId\":\"13589371\",\"name\":\"Jiayuan Mao\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"114497499\",\"name\":\"Josh Tenenbaum\"},{\"authorId\":\"119837545\",\"name\":\"J. Wu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"26b14e8693c4f8da04c545e0f01236449d505b3d\",\"title\":\"Visual Concept-Metaconcept Learning\",\"url\":\"https://www.semanticscholar.org/paper/26b14e8693c4f8da04c545e0f01236449d505b3d\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"1806773\",\"name\":\"I. Misra\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fc8df4ad35282ccf19261e02de87d8e35c956537\",\"title\":\"Binary Image Selection (BISON): Interpretable Evaluation of Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/fc8df4ad35282ccf19261e02de87d8e35c956537\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51021338\",\"name\":\"Nelson Ruwa\"},{\"authorId\":\"3069077\",\"name\":\"Q. Mao\"},{\"authorId\":\"2054737\",\"name\":\"L. Wang\"},{\"authorId\":\"144964053\",\"name\":\"M. Dong\"}],\"doi\":\"10.1109/MIPR.2018.00038\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"883800c16fd5250d43a195dfa8b4eeca0b7f7e0b\",\"title\":\"Affective Visual Question Answering Network\",\"url\":\"https://www.semanticscholar.org/paper/883800c16fd5250d43a195dfa8b4eeca0b7f7e0b\",\"venue\":\"2018 IEEE Conference on Multimedia Information Processing and Retrieval (MIPR)\",\"year\":2018},{\"arxivId\":\"1904.08324\",\"authors\":[{\"authorId\":\"66599917\",\"name\":\"Yanze Wu\"},{\"authorId\":\"145268319\",\"name\":\"Q. Sun\"},{\"authorId\":\"3493380\",\"name\":\"Jianqi Ma\"},{\"authorId\":\"49729707\",\"name\":\"B. Li\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"145589539\",\"name\":\"Y. Peng\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"914c3045b4e140a93eace23eded09317072d3f42\",\"title\":\"Question Guided Modular Routing Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/914c3045b4e140a93eace23eded09317072d3f42\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"20600120\",\"name\":\"Mihael Cudic\"},{\"authorId\":\"40269075\",\"name\":\"R. Burt\"},{\"authorId\":\"145805087\",\"name\":\"Eder Santana\"},{\"authorId\":\"143961030\",\"name\":\"J. Pr\\u00edncipe\"}],\"doi\":\"10.1016/j.neucom.2018.02.065\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d7d0325e3a012cae26b3d0861e878d60e97d0035\",\"title\":\"A flexible testing environment for visual question answering with performance evaluation\",\"url\":\"https://www.semanticscholar.org/paper/d7d0325e3a012cae26b3d0861e878d60e97d0035\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144839067\",\"name\":\"Amir Mazaheri\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"fa2030f41aa0b54965420eb7836c7c32a91b087b\",\"title\":\"Video Content Understanding Using Text\",\"url\":\"https://www.semanticscholar.org/paper/fa2030f41aa0b54965420eb7836c7c32a91b087b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3814221\",\"name\":\"Vasileios Lioutas\"},{\"authorId\":\"3200630\",\"name\":\"N. Passalis\"},{\"authorId\":\"1737071\",\"name\":\"A. Tefas\"}],\"doi\":\"10.1016/j.patrec.2018.04.031\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"17984591f8b6fba05d950458220b0450f8753b84\",\"title\":\"Explicit ensemble attention learning for improving visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/17984591f8b6fba05d950458220b0450f8753b84\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2018},{\"arxivId\":\"1704.02923\",\"authors\":[{\"authorId\":\"1947259\",\"name\":\"Ionut-Teodor Sorodoc\"},{\"authorId\":\"3422247\",\"name\":\"Sandro Pezzelle\"},{\"authorId\":\"3352951\",\"name\":\"Aur\\u00e9lie Herbelot\"},{\"authorId\":\"2837527\",\"name\":\"Mariella Dimiccoli\"},{\"authorId\":\"145040726\",\"name\":\"Raffaella Bernardi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"49af582b8e96cd69986ff21223e3fa331081d7d5\",\"title\":\"Pay Attention to Those Sets! Learning Quantification from Images\",\"url\":\"https://www.semanticscholar.org/paper/49af582b8e96cd69986ff21223e3fa331081d7d5\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1704.04133\",\"authors\":[{\"authorId\":\"145005176\",\"name\":\"D. Kumar\"},{\"authorId\":\"144821966\",\"name\":\"A. Wong\"},{\"authorId\":\"144639556\",\"name\":\"Graham W. Taylor\"}],\"doi\":\"10.1109/CVPRW.2017.215\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"508335142583e140fb12738fa9db98724deefd6c\",\"title\":\"Explaining the Unexplained: A CLass-Enhanced Attentive Response (CLEAR) Approach to Understanding Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/508335142583e140fb12738fa9db98724deefd6c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10405058\",\"name\":\"Chenfei Wu\"},{\"authorId\":\"46700331\",\"name\":\"J. Liu\"},{\"authorId\":\"1680068\",\"name\":\"X. Wang\"},{\"authorId\":\"143672034\",\"name\":\"X. Dong\"}],\"doi\":\"10.1145/3240508.3240513\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"34c9753893fe4713568542e7d96dc9a9e6545ec8\",\"title\":\"Object-Difference Attention: A Simple Relational Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/34c9753893fe4713568542e7d96dc9a9e6545ec8\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67310661\",\"name\":\"Monica Haurilet\"},{\"authorId\":\"1390024605\",\"name\":\"Ziad Al-Halah\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"}],\"doi\":\"10.1007/978-3-030-11018-5_9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8173e63aa2db962b9807bdbab66538afb3caf929\",\"title\":\"MoQA - A Multi-modal Question Answering Architecture\",\"url\":\"https://www.semanticscholar.org/paper/8173e63aa2db962b9807bdbab66538afb3caf929\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"89813962\",\"name\":\"Shivangi Modi\"},{\"authorId\":\"153279050\",\"name\":\"Dhatri Pandya\"}],\"doi\":\"10.1109/ICCMC.2019.8819803\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c99654c738cf9a426fac40251e277282a8ee86a7\",\"title\":\"VQAR: Review on Information Retrieval Techniques based on Computer Vision and Natural Language Processing\",\"url\":\"https://www.semanticscholar.org/paper/c99654c738cf9a426fac40251e277282a8ee86a7\",\"venue\":\"2019 3rd International Conference on Computing Methodologies and Communication (ICCMC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"113739988\",\"name\":\"Chi Han\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a595980784df7bee12ed248e727929af417713d0\",\"title\":\"Visual Concept-Metaconcept Learning\",\"url\":\"https://www.semanticscholar.org/paper/a595980784df7bee12ed248e727929af417713d0\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1606.07046\",\"authors\":[{\"authorId\":\"2517825\",\"name\":\"J. Krishnamurthy\"},{\"authorId\":\"3385516\",\"name\":\"Oyvind Tafjord\"},{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"}],\"doi\":\"10.18653/v1/D16-1016\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9940e8b05c808a8dc5a688fa860bcf40ef3b59d3\",\"title\":\"Semantic Parsing to Probabilistic Programs for Situated Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/9940e8b05c808a8dc5a688fa860bcf40ef3b59d3\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1409222519\",\"name\":\"U. A. Khan\"},{\"authorId\":\"150244890\",\"name\":\"N. Ejaz\"},{\"authorId\":\"1401947265\",\"name\":\"M. A. Mart\\u00ednez-del-Amor\"},{\"authorId\":\"2366822\",\"name\":\"H. Sparenberg\"}],\"doi\":\"10.1109/AVSS.2017.8078459\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4b8f805e18c205916285c4a8ca5f233cb8952cc8\",\"title\":\"Movies tags extraction using deep learning\",\"url\":\"https://www.semanticscholar.org/paper/4b8f805e18c205916285c4a8ca5f233cb8952cc8\",\"venue\":\"2017 14th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)\",\"year\":2017},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e464187b1cee23117a0b1b1b86a479bee011d991\",\"title\":\"Project on Visual Commonsense Reasoning Anonymous ACL submission\",\"url\":\"https://www.semanticscholar.org/paper/e464187b1cee23117a0b1b1b86a479bee011d991\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144582538\",\"name\":\"Vasu Sharma\"},{\"authorId\":\"34711141\",\"name\":\"Ankita Bishnu\"},{\"authorId\":\"22267101\",\"name\":\"L. Patel\"}],\"doi\":\"10.18653/v1/P17-3008\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e8691980eeb827b10cdfb4cc402b3f43f020bc6a\",\"title\":\"Segmentation Guided Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e8691980eeb827b10cdfb4cc402b3f43f020bc6a\",\"venue\":\"ACL\",\"year\":2017},{\"arxivId\":\"1605.02697\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":\"10.1007/s11263-017-1038-2\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f7ddf708442dad7ed2978658b101c797c7c10220\",\"title\":\"Ask Your Neurons: A Deep Learning Approach to Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f7ddf708442dad7ed2978658b101c797c7c10220\",\"venue\":\"International Journal of Computer Vision\",\"year\":2017},{\"arxivId\":\"1905.04877\",\"authors\":[{\"authorId\":\"30921555\",\"name\":\"Yangyang Guo\"},{\"authorId\":\"13167100\",\"name\":\"Zhiyong Cheng\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":\"35435925\",\"name\":\"Y. Liu\"},{\"authorId\":\"49417788\",\"name\":\"Yinglong Wang\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":\"10.1145/3331184.3331186\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d00fe8d117a3849d3085d4301d91c56b775ee8b1\",\"title\":\"Quantifying and Alleviating the Language Prior Problem in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d00fe8d117a3849d3085d4301d91c56b775ee8b1\",\"venue\":\"SIGIR\",\"year\":2019},{\"arxivId\":\"1604.02125\",\"authors\":[{\"authorId\":\"50005563\",\"name\":\"G. Christie\"},{\"authorId\":\"48222562\",\"name\":\"A. Laddha\"},{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"98391857\",\"name\":\"K. Kochersberger\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.18653/v1/D16-1156\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"26eb2c900814707ae962184ad4173e754247a80a\",\"title\":\"Resolving Language and Vision Ambiguities Together: Joint Segmentation & Prepositional Attachment Resolution in Captioned Scenes\",\"url\":\"https://www.semanticscholar.org/paper/26eb2c900814707ae962184ad4173e754247a80a\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":\"1611.08669\",\"authors\":[{\"authorId\":\"145497716\",\"name\":\"A. Das\"},{\"authorId\":\"2150275\",\"name\":\"S. Kottur\"},{\"authorId\":\"39855500\",\"name\":\"K. Gupta\"},{\"authorId\":\"1899992\",\"name\":\"Avi Singh\"},{\"authorId\":\"24508084\",\"name\":\"Deshraj Yadav\"},{\"authorId\":\"144915495\",\"name\":\"Jos\\u00e9 M. F. Moura\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1109/CVPR.2017.121\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2231f44be9a8472a46d8e8a628b4e52b9a8f44e0\",\"title\":\"Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/2231f44be9a8472a46d8e8a628b4e52b9a8f44e0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47740650\",\"name\":\"Jian Jhen Chen\"},{\"authorId\":\"145496509\",\"name\":\"Jie Shao\"},{\"authorId\":\"144618699\",\"name\":\"F. Shen\"},{\"authorId\":\"2838253\",\"name\":\"C. He\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1145/3132847.3132922\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3085671f6232aac4492ad861d09334b8f3a7e2a7\",\"title\":\"Movie Fill in the Blank with Adaptive Temporal Attention and Description Update\",\"url\":\"https://www.semanticscholar.org/paper/3085671f6232aac4492ad861d09334b8f3a7e2a7\",\"venue\":\"CIKM\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2082604\",\"name\":\"F. Xing\"},{\"authorId\":\"1877955\",\"name\":\"Yuanpu Xie\"},{\"authorId\":\"143729223\",\"name\":\"H. Su\"},{\"authorId\":\"48697256\",\"name\":\"F. Liu\"},{\"authorId\":\"40248915\",\"name\":\"L. Yang\"}],\"doi\":\"10.1109/TNNLS.2017.2766168\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"08dc94471605308669c8d3d8284ba94fcc93e345\",\"title\":\"Deep Learning in Microscopy Image Analysis: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/08dc94471605308669c8d3d8284ba94fcc93e345\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2018},{\"arxivId\":\"1607.05910\",\"authors\":[{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1016/j.cviu.2017.05.001\",\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"88c307c51594c6d802080a0780d0d654e2e2891f\",\"title\":\"Visual question answering: A survey of methods and datasets\",\"url\":\"https://www.semanticscholar.org/paper/88c307c51594c6d802080a0780d0d654e2e2891f\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150337817\",\"name\":\"Weike Jin\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"67144160\",\"name\":\"Mao Gu\"},{\"authorId\":\"9919436\",\"name\":\"J. Yu\"},{\"authorId\":\"145974111\",\"name\":\"Jun Xiao\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1145/3331184.3331240\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f8954b3f74373e953b4449efca71e5ec6be46fb6\",\"title\":\"Video Dialog via Multi-Grained Convolutional Self-Attention Context Networks\",\"url\":\"https://www.semanticscholar.org/paper/f8954b3f74373e953b4449efca71e5ec6be46fb6\",\"venue\":\"SIGIR\",\"year\":2019},{\"arxivId\":\"1506.01144\",\"authors\":[{\"authorId\":\"34902783\",\"name\":\"Qi Wu\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2016.29\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"00fe3d95d0fd5f1433d81405bee772c4fe9af9c6\",\"title\":\"What Value Do Explicit High Level Concepts Have in Vision to Language Problems?\",\"url\":\"https://www.semanticscholar.org/paper/00fe3d95d0fd5f1433d81405bee772c4fe9af9c6\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"113739988\",\"name\":\"Chi Han\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"fe9354c9c50eca88b125ac067da5b865ce715d57\",\"title\":\"Visual Concept-Metaconcept Learning\",\"url\":\"https://www.semanticscholar.org/paper/fe9354c9c50eca88b125ac067da5b865ce715d57\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c1693e1defad1cc8ec36b061add2afcd564013ff\",\"title\":\"Advancing Multi-Modal Deep Learning: Towards Language-Grounded Visual Understanding\",\"url\":\"https://www.semanticscholar.org/paper/c1693e1defad1cc8ec36b061add2afcd564013ff\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1711.01732\",\"authors\":[{\"authorId\":\"9136919\",\"name\":\"X. Lin\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"52b72e34bc281b44a7d4edc990dcb781c89afc28\",\"title\":\"Active Learning for Visual Question Answering: An Empirical Study\",\"url\":\"https://www.semanticscholar.org/paper/52b72e34bc281b44a7d4edc990dcb781c89afc28\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"116780600\",\"name\":\"S. Semenova\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"089254dfb8fb0fbfac55696d1f9eba02e4079e97\",\"title\":\"Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/089254dfb8fb0fbfac55696d1f9eba02e4079e97\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2123865\",\"name\":\"F. Tung\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"}],\"doi\":\"10.1109/TPAMI.2018.2886192\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"610d0b290f0f1c22b03f220d6ba332627a5f6f3e\",\"title\":\"Deep Neural Network Compression by In-Parallel Pruning-Quantization\",\"url\":\"https://www.semanticscholar.org/paper/610d0b290f0f1c22b03f220d6ba332627a5f6f3e\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12153206\",\"name\":\"Shengyan Liu\"},{\"authorId\":\"151257983\",\"name\":\"Xiaozhi Ou\"},{\"authorId\":\"90628610\",\"name\":\"Jiao Che\"},{\"authorId\":\"47155070\",\"name\":\"Xiaobing Zhou\"},{\"authorId\":\"2025671\",\"name\":\"Haiyan Ding\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"deb8fac1239d88df5e1ffd6bff52a767a1007628\",\"title\":\"An Xception-GRU Model for Visual Question Answering in the Medical Domain\",\"url\":\"https://www.semanticscholar.org/paper/deb8fac1239d88df5e1ffd6bff52a767a1007628\",\"venue\":\"CLEF\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145446752\",\"name\":\"Marie-Francine Moens\"},{\"authorId\":\"2861393\",\"name\":\"K. Pastra\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"}],\"doi\":\"10.1109/MMUL.2018.023121160\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"37bc08f554333225c85d00261123aec934cbd682\",\"title\":\"Vision and Language Integration Meets Multimedia Fusion\",\"url\":\"https://www.semanticscholar.org/paper/37bc08f554333225c85d00261123aec934cbd682\",\"venue\":\"IEEE Multim.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3814221\",\"name\":\"Vasileios Lioutas\"},{\"authorId\":\"3200630\",\"name\":\"N. Passalis\"},{\"authorId\":\"1737071\",\"name\":\"A. Tefas\"}],\"doi\":\"10.1109/ISCAS.2018.8351158\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"36cdb5d188398fd5d84fcc0b8959edee69a54f58\",\"title\":\"Visual Question Answering using Explicit Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/36cdb5d188398fd5d84fcc0b8959edee69a54f58\",\"venue\":\"2018 IEEE International Symposium on Circuits and Systems (ISCAS)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2338742\",\"name\":\"Y. Jang\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"32821535\",\"name\":\"C. D. Kim\"},{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"49170458\",\"name\":\"Youngjin Kim\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1007/s11263-019-01189-x\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1e1bd132613866c176a8fc780cb1b9f9aa43feeb\",\"title\":\"Video Question Answering with Spatio-Temporal Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/1e1bd132613866c176a8fc780cb1b9f9aa43feeb\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"1606.00061\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"145743311\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b\",\"title\":\"Hierarchical Question-Image Co-Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2978170\",\"name\":\"Fartash Faghri\"},{\"authorId\":\"1793739\",\"name\":\"David J. Fleet\"},{\"authorId\":\"51131802\",\"name\":\"J. Kiros\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f7ab6c52be9351ac3f6cf8fe6ad5efba1c1595e8\",\"title\":\"VSE++: Improving Visual-Semantic Embeddings with Hard Negatives\",\"url\":\"https://www.semanticscholar.org/paper/f7ab6c52be9351ac3f6cf8fe6ad5efba1c1595e8\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67144160\",\"name\":\"Mao Gu\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"150337817\",\"name\":\"Weike Jin\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"},{\"authorId\":\"144894837\",\"name\":\"F. Wu\"}],\"doi\":\"10.1109/TCSVT.2019.2957309\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1c0acaec480993efb5f882cea44879545dd5687c\",\"title\":\"Video Dialog via Multi-Grained Convolutional Self-Attention Context Multi-Modal Networks\",\"url\":\"https://www.semanticscholar.org/paper/1c0acaec480993efb5f882cea44879545dd5687c\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9852531\",\"name\":\"J. Lin\"},{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eefddfa610243968135726f9fddf4f69696863ed\",\"title\":\"TAB-VCR: Tags and Attributes based VCR Baselines\",\"url\":\"https://www.semanticscholar.org/paper/eefddfa610243968135726f9fddf4f69696863ed\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1735739\",\"name\":\"Weifeng Zhang\"},{\"authorId\":\"119883573\",\"name\":\"J. Yu\"},{\"authorId\":\"47864783\",\"name\":\"H. Hu\"},{\"authorId\":\"144645443\",\"name\":\"H. Hu\"},{\"authorId\":\"70565757\",\"name\":\"Zengchang Qin\"}],\"doi\":\"10.1016/J.INFFUS.2019.08.009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"04afa0417dc2a4555c15243a69e6a54ce44ecf63\",\"title\":\"Multimodal feature fusion by relational reasoning and attention for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/04afa0417dc2a4555c15243a69e6a54ce44ecf63\",\"venue\":\"Inf. Fusion\",\"year\":2020},{\"arxivId\":\"1906.04464\",\"authors\":[{\"authorId\":\"3144952\",\"name\":\"Sibei Yang\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"66616425\",\"name\":\"Yizhou Yu\"}],\"doi\":\"10.1109/tpami.2020.2973983\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"14204fd579ad2802490a8f4a781392ca7ba19c80\",\"title\":\"Relationship-Embedded Representation Learning for Grounding Referring Expressions.\",\"url\":\"https://www.semanticscholar.org/paper/14204fd579ad2802490a8f4a781392ca7ba19c80\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30507748\",\"name\":\"David Harwath\"},{\"authorId\":\"39257069\",\"name\":\"A. Recasens\"},{\"authorId\":\"35399640\",\"name\":\"D\\u00eddac Sur\\u00eds\"},{\"authorId\":\"2213197\",\"name\":\"Galen Chuang\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145898103\",\"name\":\"J. Glass\"}],\"doi\":\"10.1007/s11263-019-01205-0\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"45070dd423a47f237d2c0bc7930579ecc4e4ad0a\",\"title\":\"Jointly Discovering Visual Objects and Spoken Words from Raw Sensory Input\",\"url\":\"https://www.semanticscholar.org/paper/45070dd423a47f237d2c0bc7930579ecc4e4ad0a\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39720629\",\"name\":\"Alessandro Bay\"}],\"doi\":\"10.6092/polito/porto/2677460\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e260a9f00180a720e848d8a2f28e7d4cba93e453\",\"title\":\"Recurrent neural networks: methods and applications to non-linear predictions\",\"url\":\"https://www.semanticscholar.org/paper/e260a9f00180a720e848d8a2f28e7d4cba93e453\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1782578\",\"name\":\"Chun-Ju Yang\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"2028946\",\"name\":\"D. Gurari\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"91c184e7fb0c7cce5319b8db85c1488b3861976f\",\"title\":\"Visual Question Answer Diversity\",\"url\":\"https://www.semanticscholar.org/paper/91c184e7fb0c7cce5319b8db85c1488b3861976f\",\"venue\":\"HCOMP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35458817\",\"name\":\"Sudan Jha\"},{\"authorId\":\"143699471\",\"name\":\"Anirban Dey\"},{\"authorId\":\"145835018\",\"name\":\"R. Kumar\"},{\"authorId\":\"2245174\",\"name\":\"Vijender Kumar Solanki\"}],\"doi\":\"10.9781/IJIMAI.2018.08.004\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a47093ac41db735b837e6b9e8f3cccdfc46e20f3\",\"title\":\"A Novel Approach on Visual Question Answering by Parameter Prediction using Faster Region Based Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/a47093ac41db735b837e6b9e8f3cccdfc46e20f3\",\"venue\":\"Int. J. Interact. Multim. Artif. Intell.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1423736637\",\"name\":\"Middi Venkata Sai Rishita\"},{\"authorId\":\"1423731552\",\"name\":\"Tanvir Ahmed Harris\"}],\"doi\":\"10.1109/ICNEWS.2018.8903980\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"646cbbda3a56af50defe9b325017058273000d36\",\"title\":\"Dog Breed Classifier using Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/646cbbda3a56af50defe9b325017058273000d36\",\"venue\":\"2018 International Conference on Networking, Embedded and Wireless Systems (ICNEWS)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"81974870\",\"name\":\"Kristijan Jankoski\"},{\"authorId\":\"144293427\",\"name\":\"Sonja Gievska\"}],\"doi\":\"10.1007/978-3-030-00825-3_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a7a83ed04e54e494ccb6384e7dbaf7ca26e42072\",\"title\":\"Evaluation of Multiple Approaches for Visual Question Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/a7a83ed04e54e494ccb6384e7dbaf7ca26e42072\",\"venue\":\"ICT Innovations\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"31081539\",\"name\":\"Pengpeng Zeng\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"6820648\",\"name\":\"Xianglong Liu\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1145/3240508.3240687\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"97add9744ae63c5e7af9d9861ecc18a2734d3f0c\",\"title\":\"Examine before You Answer: Multi-task Learning with Adaptive-attentions for Multiple-choice VQA\",\"url\":\"https://www.semanticscholar.org/paper/97add9744ae63c5e7af9d9861ecc18a2734d3f0c\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1471721735\",\"name\":\"Umair Ahmad Khan\"}],\"doi\":\"10.4018/978-1-7998-2803-7.ch014\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"acf669807487bc78cc5f6c0afa815889a9c7d080\",\"title\":\"Semantic Analysis of Videos for Tags Prediction and Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/acf669807487bc78cc5f6c0afa815889a9c7d080\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1612.06890\",\"authors\":[{\"authorId\":\"153365679\",\"name\":\"J. Johnson\"},{\"authorId\":\"73710317\",\"name\":\"B. Hariharan\"},{\"authorId\":\"35341401\",\"name\":\"Laurens van der Maaten\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/CVPR.2017.215\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"03eb382e04cca8cca743f7799070869954f1402a\",\"title\":\"CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/03eb382e04cca8cca743f7799070869954f1402a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51021338\",\"name\":\"Nelson Ruwa\"},{\"authorId\":\"3069077\",\"name\":\"Q. Mao\"},{\"authorId\":\"2054737\",\"name\":\"Liangjun Wang\"},{\"authorId\":\"38978232\",\"name\":\"J. Gou\"},{\"authorId\":\"144964053\",\"name\":\"M. Dong\"}],\"doi\":\"10.1016/j.neucom.2018.11.049\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e3e4954e40f33b503f7fe220be90917124a09c43\",\"title\":\"Mood-aware visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/e3e4954e40f33b503f7fe220be90917124a09c43\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"1912.03098\",\"authors\":[{\"authorId\":\"1403171438\",\"name\":\"J. Pont-Tuset\"},{\"authorId\":\"1823362\",\"name\":\"J. Uijlings\"},{\"authorId\":\"2059199\",\"name\":\"Soravit Changpinyo\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"},{\"authorId\":\"143865718\",\"name\":\"V. Ferrari\"}],\"doi\":\"10.1007/978-3-030-58558-7_38\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"439369de9514e41e0f03fed552d8f6e5aebf51b2\",\"title\":\"Connecting Vision and Language with Localized Narratives\",\"url\":\"https://www.semanticscholar.org/paper/439369de9514e41e0f03fed552d8f6e5aebf51b2\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1709.07871\",\"authors\":[{\"authorId\":\"3439053\",\"name\":\"Ethan Perez\"},{\"authorId\":\"3367628\",\"name\":\"Florian Strub\"},{\"authorId\":\"153559313\",\"name\":\"H. D. Vries\"},{\"authorId\":\"3074927\",\"name\":\"Vincent Dumoulin\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7cfa5c97164129ce3630511f639040d28db1d4b7\",\"title\":\"FiLM: Visual Reasoning with a General Conditioning Layer\",\"url\":\"https://www.semanticscholar.org/paper/7cfa5c97164129ce3630511f639040d28db1d4b7\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1802.08129\",\"authors\":[{\"authorId\":\"3422202\",\"name\":\"Dong Huk Park\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"2893664\",\"name\":\"Zeynep Akata\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.1109/CVPR.2018.00915\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ef153ece43ee50f8208f6197f0eaf3d324e4475b\",\"title\":\"Multimodal Explanations: Justifying Decisions and Pointing to the Evidence\",\"url\":\"https://www.semanticscholar.org/paper/ef153ece43ee50f8208f6197f0eaf3d324e4475b\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145664204\",\"name\":\"G. Antipov\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"61825a32a8cb28045ef4769e35a9fea6a372a1a1\",\"title\":\"Deep learning for semantic description of visual human traits. (Apprentissage profond pour la description s\\u00e9mantique des traits visuels humains)\",\"url\":\"https://www.semanticscholar.org/paper/61825a32a8cb28045ef4769e35a9fea6a372a1a1\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"7595427\",\"name\":\"Tejas Khot\"},{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1007/s11263-018-1116-0\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"7e232313a59d735ef7c8a9f4cc7bc980a29deb5e\",\"title\":\"Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7e232313a59d735ef7c8a9f4cc7bc980a29deb5e\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2862582\",\"name\":\"Peratham Wiriyathammabhum\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"1759899\",\"name\":\"C. Ferm\\u00fcller\"},{\"authorId\":\"1697493\",\"name\":\"Y. Aloimonos\"}],\"doi\":\"10.1145/3009906\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6e60536c847ac25dba4c1c071e0355e5537fe061\",\"title\":\"Computer Vision and Natural Language Processing\",\"url\":\"https://www.semanticscholar.org/paper/6e60536c847ac25dba4c1c071e0355e5537fe061\",\"venue\":\"ACM Comput. Surv.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39744108\",\"name\":\"S. Aditya\"},{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"1760291\",\"name\":\"Chitta Baral\"},{\"authorId\":\"1697493\",\"name\":\"Y. Aloimonos\"},{\"authorId\":\"1759899\",\"name\":\"C. Ferm\\u00fcller\"}],\"doi\":\"10.1016/j.cviu.2017.12.004\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e1e2e32f29cf7d23881e98dfe018d9049bdb070d\",\"title\":\"Image Understanding using vision and reasoning through Scene Description Graph\",\"url\":\"https://www.semanticscholar.org/paper/e1e2e32f29cf7d23881e98dfe018d9049bdb070d\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3033617\",\"name\":\"Qiaoyun Wang\"},{\"authorId\":\"36766903\",\"name\":\"H. Huang\"}],\"doi\":\"10.23919/CHICC.2017.8028007\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b3beadd2ffc101a8ce9f999c13c5db3211af32d1\",\"title\":\"Learning of recurrent convolutional neural networks with applications in pattern recognition\",\"url\":\"https://www.semanticscholar.org/paper/b3beadd2ffc101a8ce9f999c13c5db3211af32d1\",\"venue\":\"2017 36th Chinese Control Conference (CCC)\",\"year\":2017},{\"arxivId\":\"1706.01554\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"145721096\",\"name\":\"A. Kannan\"},{\"authorId\":\"145743311\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8cdd241b474bf7b0632162403ac2a3c4799252ad\",\"title\":\"Best of Both Worlds: Transferring Knowledge from Discriminative Learning to a Generative Visual Dialog Model\",\"url\":\"https://www.semanticscholar.org/paper/8cdd241b474bf7b0632162403ac2a3c4799252ad\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1702.05729\",\"authors\":[{\"authorId\":\"2944920\",\"name\":\"Shaomeng Li\"},{\"authorId\":null,\"name\":\"Tong Xiao\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"1380096226\",\"name\":\"Dayu Yue\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1109/CVPR.2017.551\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"28870e4de79d5086864a9f2c6df632b606ac3347\",\"title\":\"Person Search with Natural Language Description\",\"url\":\"https://www.semanticscholar.org/paper/28870e4de79d5086864a9f2c6df632b606ac3347\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1804.05018\",\"authors\":[{\"authorId\":\"3422247\",\"name\":\"Sandro Pezzelle\"},{\"authorId\":\"50322207\",\"name\":\"Ionut-Teodor Sorodoc\"},{\"authorId\":\"145040726\",\"name\":\"R. Bernardi\"}],\"doi\":\"10.18653/v1/N18-1039\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ce386ab4511f38a7671576a9cd32e5557853180e\",\"title\":\"Comparatives, Quantifiers, Proportions: A Multi-Task Model for the Learning of Quantities from Vision\",\"url\":\"https://www.semanticscholar.org/paper/ce386ab4511f38a7671576a9cd32e5557853180e\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":\"1704.07434\",\"authors\":[{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"38314306\",\"name\":\"Rakshith Shetty\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"1708642\",\"name\":\"Jorma T. Laaksonen\"}],\"doi\":\"10.1109/ICCV.2017.272\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e4a11cc697c94fdda9eedbac7d83a865646bd4cc\",\"title\":\"Paying Attention to Descriptions Generated by Image Captioning Models\",\"url\":\"https://www.semanticscholar.org/paper/e4a11cc697c94fdda9eedbac7d83a865646bd4cc\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743434\",\"name\":\"W. Cheng\"},{\"authorId\":\"49867037\",\"name\":\"Y. Huang\"},{\"authorId\":\"49681016\",\"name\":\"L. Wang\"}],\"doi\":\"10.1109/ICPR.2018.8546015\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6fa1076a98a15cec083fb474f238237f1b3a341a\",\"title\":\"Towards Unconstrained Pointing Problem of Visual Question Answering: A Retrieval-based Method\",\"url\":\"https://www.semanticscholar.org/paper/6fa1076a98a15cec083fb474f238237f1b3a341a\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"2214033\",\"name\":\"Y. Zhu\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e03b932fa6c87b8a698c86b4b4963bf6e4b45933\",\"title\":\"Matrix ? Why does Cypher betray Morpheus ? How does the movie end ?\",\"url\":\"https://www.semanticscholar.org/paper/e03b932fa6c87b8a698c86b4b4963bf6e4b45933\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143957784\",\"name\":\"M. Iqbal\"},{\"authorId\":\"119339025\",\"name\":\"H. Chowdhury\"},{\"authorId\":\"145025159\",\"name\":\"K. Nguyen\"},{\"authorId\":\"3140440\",\"name\":\"C. Fookes\"},{\"authorId\":\"1729760\",\"name\":\"S. Sridharan\"}],\"doi\":\"10.36227/techrxiv.12731945\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"08dc9a1be26e6f87d26b69286bbc82686a4f5c90\",\"title\":\"VIDEO QUESTION ANSWERING FOR SURVEILLANCE\",\"url\":\"https://www.semanticscholar.org/paper/08dc9a1be26e6f87d26b69286bbc82686a4f5c90\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1712479\",\"name\":\"Mohamed Elhoseiny\"}],\"doi\":\"10.7282/T3QC05T7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"630bff5280f7195e999532c21c9efb13c7f937be\",\"title\":\"Language guided visual perception\",\"url\":\"https://www.semanticscholar.org/paper/630bff5280f7195e999532c21c9efb13c7f937be\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1511.02274\",\"authors\":[{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"46234526\",\"name\":\"Alex Smola\"}],\"doi\":\"10.1109/CVPR.2016.10\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2c1890864c1c2b750f48316dc8b650ba4772adc5\",\"title\":\"Stacked Attention Networks for Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2c1890864c1c2b750f48316dc8b650ba4772adc5\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39888194\",\"name\":\"Kashif Shah\"},{\"authorId\":\"2635321\",\"name\":\"Josiah Wang\"},{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"}],\"doi\":\"10.18653/v1/W16-2363\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7b8cf3f63fa57f84a0bb23a39267a593e2eded06\",\"title\":\"SHEF-Multimodal: Grounding Machine Translation on Images\",\"url\":\"https://www.semanticscholar.org/paper/7b8cf3f63fa57f84a0bb23a39267a593e2eded06\",\"venue\":\"WMT\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3236503\",\"name\":\"Li-Chi Huang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5438445786db9f6181d9fabfc758663518ba28fd\",\"title\":\"Compressive Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/5438445786db9f6181d9fabfc758663518ba28fd\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1709.07992\",\"authors\":[{\"authorId\":\"14454974\",\"name\":\"P. H. Seo\"},{\"authorId\":\"20812150\",\"name\":\"Andreas M. Lehrmann\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ad8c0489d908d6bb4b48eb56c8c92b8f545216f5\",\"title\":\"Visual Reference Resolution using Attention Memory for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/ad8c0489d908d6bb4b48eb56c8c92b8f545216f5\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145478715\",\"name\":\"I. Chowdhury\"},{\"authorId\":\"145025159\",\"name\":\"K. Nguyen\"},{\"authorId\":\"3140440\",\"name\":\"C. Fookes\"},{\"authorId\":\"1729760\",\"name\":\"S. Sridharan\"}],\"doi\":\"10.1109/ICIP.2017.8296600\",\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"4cb2d5ea093d52a9dbb5141bde20cbea576efa24\",\"title\":\"A cascaded long short-term memory (LSTM) driven generic visual question answering (VQA)\",\"url\":\"https://www.semanticscholar.org/paper/4cb2d5ea093d52a9dbb5141bde20cbea576efa24\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8004535\",\"name\":\"Chaojun Han\"},{\"authorId\":\"144618699\",\"name\":\"F. Shen\"},{\"authorId\":\"46457827\",\"name\":\"Li Liu\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1145/3240508.3240611\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f51d9d34635ad9f6310d767869710e78fc4174bf\",\"title\":\"Visual Spatial Attention Network for Relationship Detection\",\"url\":\"https://www.semanticscholar.org/paper/f51d9d34635ad9f6310d767869710e78fc4174bf\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30143534\",\"name\":\"Jiayu Shang\"},{\"authorId\":\"48830858\",\"name\":\"S. J. Li\"},{\"authorId\":\"134902036\",\"name\":\"Zhikui Duan\"},{\"authorId\":\"49024867\",\"name\":\"Junwei Huang\"}],\"doi\":\"10.1117/12.2302484\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9bade063424b08b0e270dc3761b054a7596bd1c3\",\"title\":\"Visual question answering using hierarchical dynamic memory networks\",\"url\":\"https://www.semanticscholar.org/paper/9bade063424b08b0e270dc3761b054a7596bd1c3\",\"venue\":\"International Conference on Graphic and Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23364558\",\"name\":\"Nilavra Bhattacharya\"},{\"authorId\":\"101489041\",\"name\":\"Q. Li\"},{\"authorId\":\"2028946\",\"name\":\"D. Gurari\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"6a9293145a9a3a7ca42b18a437e0bce67a359127\",\"title\":\"Reason Label Description Issues with the Question-Image ( QI ) pair Low Quality\",\"url\":\"https://www.semanticscholar.org/paper/6a9293145a9a3a7ca42b18a437e0bce67a359127\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"},{\"authorId\":\"143655174\",\"name\":\"P. Turaga\"},{\"authorId\":\"40222634\",\"name\":\"K. Kulkarni\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"22a47c94c49e721e0afbf70ab10200403a1d2cf7\",\"title\":\"Compressive Visual Question Answering by Li-chi Huang A Thesis Presented in Partial Fulfillment of the Requirements for the Degree Master of Science Approved August 2017 by the Graduate Supervisory Committee: Pavan Turaga, Chair\",\"url\":\"https://www.semanticscholar.org/paper/22a47c94c49e721e0afbf70ab10200403a1d2cf7\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1412806873\",\"name\":\"Mandar Bhalerao\"},{\"authorId\":\"1491238382\",\"name\":\"Shlok Gujar\"},{\"authorId\":\"144555055\",\"name\":\"A. Bhave\"},{\"authorId\":\"2702152\",\"name\":\"Anant V. Nimkar\"}],\"doi\":\"10.1109/IBSSC47189.2019.8973090\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0fd778bd56bfda44297c72633b2ef2988d10bc76\",\"title\":\"Visual Question Answering Using Video Clips\",\"url\":\"https://www.semanticscholar.org/paper/0fd778bd56bfda44297c72633b2ef2988d10bc76\",\"venue\":\"2019 IEEE Bombay Section Signature Conference (IBSSC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143750989\",\"name\":\"F. Gao\"},{\"authorId\":\"49982480\",\"name\":\"Yuanyuan Ge\"},{\"authorId\":\"47909272\",\"name\":\"Y. Liu\"}],\"doi\":\"10.1007/s11042-018-5868-x\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"ffcfe47a28929135c2e8905d36f7f8732d217d5d\",\"title\":\"Remember and forget: video and text fusion for video question answering\",\"url\":\"https://www.semanticscholar.org/paper/ffcfe47a28929135c2e8905d36f7f8732d217d5d\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":\"1505.05612\",\"authors\":[{\"authorId\":\"2345388\",\"name\":\"Haoyuan Gao\"},{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":null,\"name\":\"Jie Zhou\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":null,\"name\":\"Lei Wang\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2fcd5cff2b4743ea640c4af68bf4143f4a2cccb1\",\"title\":\"Are You Talking to a Machine? Dataset and Methods for Multilingual Image Question\",\"url\":\"https://www.semanticscholar.org/paper/2fcd5cff2b4743ea640c4af68bf4143f4a2cccb1\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1603.01417\",\"authors\":[{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"3375440\",\"name\":\"Stephen Merity\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f96898d15a1bf1fa8925b1280d0e07a7a8e72194\",\"title\":\"Dynamic Memory Networks for Visual and Textual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f96898d15a1bf1fa8925b1280d0e07a7a8e72194\",\"venue\":\"ICML\",\"year\":2016},{\"arxivId\":\"1907.09358\",\"authors\":[{\"authorId\":\"3219864\",\"name\":\"Aditya Mogadala\"},{\"authorId\":\"151119369\",\"name\":\"M. Kalimuthu\"},{\"authorId\":\"2561225\",\"name\":\"D. Klakow\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f8a48678094adbe421d61d0045361bfc635a2900\",\"title\":\"Trends in Integration of Vision and Language Research: A Survey of Tasks, Datasets, and Methods\",\"url\":\"https://www.semanticscholar.org/paper/f8a48678094adbe421d61d0045361bfc635a2900\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1904.09317\",\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"153677280\",\"name\":\"Robik Shrestha\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.3389/frai.2019.00028\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"78f36f2acb0c88cfe74572933cb52c9cc75a1d50\",\"title\":\"Challenges and Prospects in Vision and Language Research\",\"url\":\"https://www.semanticscholar.org/paper/78f36f2acb0c88cfe74572933cb52c9cc75a1d50\",\"venue\":\"Front. Artif. Intell.\",\"year\":2019},{\"arxivId\":\"1612.00837\",\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"7595427\",\"name\":\"Tejas Khot\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2017.670\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"title\":\"Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738318751\",\"name\":\"Sinan Tan\"},{\"authorId\":\"3449051\",\"name\":\"Weilai Xiang\"},{\"authorId\":\"2641547\",\"name\":\"H. Liu\"},{\"authorId\":\"1960245583\",\"name\":\"Di Guo\"},{\"authorId\":\"143823065\",\"name\":\"F. Sun\"}],\"doi\":\"10.1007/978-3-030-58601-0_39\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5ed523871586b0f883e4ec890155075b96291a13\",\"title\":\"Multi-agent Embodied Question Answering in Interactive Environments\",\"url\":\"https://www.semanticscholar.org/paper/5ed523871586b0f883e4ec890155075b96291a13\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1576015194\",\"name\":\"Juan K. Leonard\"}],\"doi\":\"10.15354/si.19.re117\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"973ea120a084f56915f0370433c68b5bb2486a06\",\"title\":\"Image Classification and Object Detection Algorithm Based on Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/973ea120a084f56915f0370433c68b5bb2486a06\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1905.13540\",\"authors\":[{\"authorId\":\"2447631\",\"name\":\"Junyeong Kim\"},{\"authorId\":\"103278467\",\"name\":\"Minuk Ma\"},{\"authorId\":\"3549056\",\"name\":\"K. Kim\"},{\"authorId\":\"72108920\",\"name\":\"S. Kim\"},{\"authorId\":\"145954697\",\"name\":\"C. Yoo\"}],\"doi\":\"10.1109/IJCNN.2019.8852087\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1165b090e5ec6a9311ecba5be4f6aac0a1a4586b\",\"title\":\"Gaining Extra Supervision via Multi-task learning for Multi-Modal Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1165b090e5ec6a9311ecba5be4f6aac0a1a4586b\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":\"1707.03067\",\"authors\":[{\"authorId\":\"1996796\",\"name\":\"Zaeem Hussain\"},{\"authorId\":\"2365530\",\"name\":\"Mingda Zhang\"},{\"authorId\":\"3186356\",\"name\":\"X. Zhang\"},{\"authorId\":\"9085797\",\"name\":\"Keren Ye\"},{\"authorId\":\"67100504\",\"name\":\"C. Thomas\"},{\"authorId\":\"6004292\",\"name\":\"Zuha Agha\"},{\"authorId\":\"34493995\",\"name\":\"Nathan Ong\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":\"10.1109/CVPR.2017.123\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d173f80797b0e7984d2faf1bd609252a3b365f20\",\"title\":\"Automatic Understanding of Image and Video Advertisements\",\"url\":\"https://www.semanticscholar.org/paper/d173f80797b0e7984d2faf1bd609252a3b365f20\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1606.01455\",\"authors\":[{\"authorId\":\"2684967\",\"name\":\"J. Kim\"},{\"authorId\":\"3226948\",\"name\":\"Sang-Woo Lee\"},{\"authorId\":\"3422869\",\"name\":\"Dong-Hyun Kwak\"},{\"authorId\":\"2939188\",\"name\":\"Min-Oh Heo\"},{\"authorId\":\"2947441\",\"name\":\"J. Kim\"},{\"authorId\":\"2577039\",\"name\":\"Jung-Woo Ha\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1afb710a5b35a2352a6495e4bf6eef66808daf1b\",\"title\":\"Multimodal Residual Learning for Visual QA\",\"url\":\"https://www.semanticscholar.org/paper/1afb710a5b35a2352a6495e4bf6eef66808daf1b\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143663410\",\"name\":\"F. Zhu\"},{\"authorId\":\"3305169\",\"name\":\"Zhicheng Yan\"},{\"authorId\":\"145383433\",\"name\":\"J. Bu\"},{\"authorId\":\"1841911\",\"name\":\"Y. Yu\"}],\"doi\":\"10.1109/TIP.2017.2703099\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f5251bae9b5a3fec2a7ba4b7c000e0185d25e4c6\",\"title\":\"Exemplar-Based Image and Video Stylization Using Fully Convolutional Semantic Features\",\"url\":\"https://www.semanticscholar.org/paper/f5251bae9b5a3fec2a7ba4b7c000e0185d25e4c6\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":\"1601.01705\",\"authors\":[{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"38666915\",\"name\":\"D. Klein\"}],\"doi\":\"10.18653/v1/N16-1181\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"75ddc7ee15be14013a3462c01b38b0548486fbcb\",\"title\":\"Learning to Compose Neural Networks for Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/75ddc7ee15be14013a3462c01b38b0548486fbcb\",\"venue\":\"HLT-NAACL\",\"year\":2016},{\"arxivId\":\"1809.01124\",\"authors\":[{\"authorId\":\"153137839\",\"name\":\"M. Narasimhan\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1007/978-3-030-01237-3_28\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d88eb94d7054d2668b1a8dfa311721f37ae1f059\",\"title\":\"Straight to the Facts: Learning Knowledge Base Retrieval for Factual Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d88eb94d7054d2668b1a8dfa311721f37ae1f059\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1608.08188\",\"authors\":[{\"authorId\":\"2028946\",\"name\":\"D. Gurari\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":null,\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"ceca60c4bf1a5c4e5893ae6685e7a9f80ca47f27\",\"title\":\"Visual Question: Predicting If a Crowd Will Agree on the Answer\",\"url\":\"https://www.semanticscholar.org/paper/ceca60c4bf1a5c4e5893ae6685e7a9f80ca47f27\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2846025\",\"name\":\"D. Yu\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/CVPR.2017.446\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d740d0a960368633ed32fc84877b8391993acdca\",\"title\":\"Multi-level Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d740d0a960368633ed32fc84877b8391993acdca\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1804.07669\",\"authors\":[{\"authorId\":\"39326148\",\"name\":\"Yanwei Cui\"},{\"authorId\":\"41020107\",\"name\":\"Rogatien Tobossi\"},{\"authorId\":\"41020181\",\"name\":\"Olivia Vigouroux\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4935d8b156056ebbaad20b0d5b7513c51b09ef63\",\"title\":\"Modelling customer online behaviours with neural networks: applications to conversion prediction and advertising retargeting\",\"url\":\"https://www.semanticscholar.org/paper/4935d8b156056ebbaad20b0d5b7513c51b09ef63\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1704.04689\",\"authors\":[{\"authorId\":\"144839067\",\"name\":\"Amir Mazaheri\"},{\"authorId\":\"119745921\",\"name\":\"Dong Zhang\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/ICCV.2017.157\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ad2339c48ad4ffdd6100310dcbb1fb78e72fac98\",\"title\":\"Video Fill In the Blank Using LR/RL LSTMs with Spatial-Temporal Attentions\",\"url\":\"https://www.semanticscholar.org/paper/ad2339c48ad4ffdd6100310dcbb1fb78e72fac98\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1606.09187\",\"authors\":[{\"authorId\":\"23978705\",\"name\":\"Jing Yu Koh\"},{\"authorId\":\"1699054\",\"name\":\"Wojciech Samek\"},{\"authorId\":\"145034054\",\"name\":\"Klaus-Robert M\\u00fcller\"},{\"authorId\":\"49345823\",\"name\":\"Alexander Binder\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1a07de23d6fe1f716d2e163779a0f1607905b1d8\",\"title\":\"Zero Shot Learning for Semantic Boundary Detection - How Far Can We Get?\",\"url\":\"https://www.semanticscholar.org/paper/1a07de23d6fe1f716d2e163779a0f1607905b1d8\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2110665\",\"name\":\"A. Padmakumar\"},{\"authorId\":\"10978611\",\"name\":\"Akanksha Saran\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"aa5fbe092f8a4dcb43c31ab93af0290900b4f0e2\",\"title\":\"Visual Question Answering using Natural Language Object Retrieval and Saliency Cues\",\"url\":\"https://www.semanticscholar.org/paper/aa5fbe092f8a4dcb43c31ab93af0290900b4f0e2\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50974488\",\"name\":\"Mingrui Lao\"},{\"authorId\":\"49813983\",\"name\":\"Yanming Guo\"},{\"authorId\":\"49528152\",\"name\":\"H. Wang\"},{\"authorId\":\"49468999\",\"name\":\"Xin Zhang\"}],\"doi\":\"10.1109/ACCESS.2018.2873570\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"161876ad06d5a349ccde4b4db3d3759ef43268a8\",\"title\":\"Multimodal Local Perception Bilinear Pooling for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/161876ad06d5a349ccde4b4db3d3759ef43268a8\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31784482\",\"name\":\"S. Alshahrani\"},{\"authorId\":\"2670451\",\"name\":\"E. Kapetanios\"}],\"doi\":\"10.1007/978-3-319-41754-7_33\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"66a70fbd0802ecfe66815888378460ea17cba5aa\",\"title\":\"Are Deep Learning Approaches Suitable for Natural Language Processing?\",\"url\":\"https://www.semanticscholar.org/paper/66a70fbd0802ecfe66815888378460ea17cba5aa\",\"venue\":\"NLDB\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Kushal Kafle\"},{\"authorId\":\"153677280\",\"name\":\"Robik Shrestha\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e3bb5773205477ae4711524a9d4ae739bee40349\",\"title\":\"Visual semantic role labeling requires recognizing activities and semantic context in images\",\"url\":\"https://www.semanticscholar.org/paper/e3bb5773205477ae4711524a9d4ae739bee40349\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48289232\",\"name\":\"Mohit Bajaj\"}],\"doi\":\"10.14288/1.0380482\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ef8832a4cc4d1838763df8dc7580e14706547f5a\",\"title\":\"Graph-based language grounding\",\"url\":\"https://www.semanticscholar.org/paper/ef8832a4cc4d1838763df8dc7580e14706547f5a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1909.11874\",\"authors\":[{\"authorId\":\"52220768\",\"name\":\"T. Do\"},{\"authorId\":\"3354627\",\"name\":\"Thanh-Toan Do\"},{\"authorId\":\"134083550\",\"name\":\"Huy Tran\"},{\"authorId\":\"1387964524\",\"name\":\"Erman Tjiputra\"},{\"authorId\":\"20135953\",\"name\":\"Q. D. Tran\"}],\"doi\":\"10.1109/ICCV.2019.00048\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"27cb0b42e0573c4891ae2ca444776dee57bfe2ac\",\"title\":\"Compact Trilinear Interaction for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/27cb0b42e0573c4891ae2ca444776dee57bfe2ac\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2200cb5e584288f1cef8f83d5a746d2df86e322f\",\"title\":\"NIPS 2018 Competition Track Day 1\",\"url\":\"https://www.semanticscholar.org/paper/2200cb5e584288f1cef8f83d5a746d2df86e322f\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"04a82bb033a713ae88f2e3e2306822272c30ddd9\",\"title\":\"Video representation learning with deep neural networks\",\"url\":\"https://www.semanticscholar.org/paper/04a82bb033a713ae88f2e3e2306822272c30ddd9\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47817913\",\"name\":\"L. Chen\"},{\"authorId\":\"1397287686\",\"name\":\"Yifan Zhuo\"},{\"authorId\":\"48607932\",\"name\":\"Yingjie Wu\"},{\"authorId\":null,\"name\":\"Yilei Wang\"},{\"authorId\":\"1678585\",\"name\":\"Xianghan Zheng\"}],\"doi\":\"10.1007/978-3-030-31723-2_56\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bae56e688485148c1519ff8458ea2ba6b7fab3f2\",\"title\":\"Multi-modal Feature Fusion Based on Variational Autoencoder for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/bae56e688485148c1519ff8458ea2ba6b7fab3f2\",\"venue\":\"PRCV\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47897687\",\"name\":\"H. Tan\"},{\"authorId\":\"2129212\",\"name\":\"M. Leong\"},{\"authorId\":\"1786343\",\"name\":\"Q. Xu\"},{\"authorId\":\"35718875\",\"name\":\"L. Li\"},{\"authorId\":\"2998031\",\"name\":\"F. Fang\"},{\"authorId\":\"2000269838\",\"name\":\"Yi Cheng\"},{\"authorId\":\"152765071\",\"name\":\"N. Gauthier\"},{\"authorId\":\"2000311149\",\"name\":\"Ying Sun\"},{\"authorId\":\"9183286\",\"name\":\"Joo-Hwee Lim\"}],\"doi\":\"10.1109/ICIP40778.2020.9190659\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cf4d01d0c5dc4d351a96162a5387e56bc95e58ff\",\"title\":\"Task-Oriented Multi-Modal Question Answering For Collaborative Applications\",\"url\":\"https://www.semanticscholar.org/paper/cf4d01d0c5dc4d351a96162a5387e56bc95e58ff\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144820063\",\"name\":\"Yuming Shen\"},{\"authorId\":\"50856669\",\"name\":\"L. Zhang\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"}],\"doi\":\"10.1109/ICRA.2017.7989160\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cfea594615bfa443cb517fab14180354da8a3897\",\"title\":\"Semi-supervised vision-language mapping via variational learning\",\"url\":\"https://www.semanticscholar.org/paper/cfea594615bfa443cb517fab14180354da8a3897\",\"venue\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2017},{\"arxivId\":\"1512.02902\",\"authors\":[{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"2214033\",\"name\":\"Y. Zhu\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":\"10.1109/CVPR.2016.501\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1bdd75a37f7c601f01e9d31c2551fa9f2067ffd7\",\"title\":\"MovieQA: Understanding Stories in Movies through Question-Answering\",\"url\":\"https://www.semanticscholar.org/paper/1bdd75a37f7c601f01e9d31c2551fa9f2067ffd7\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1703.07939\",\"authors\":[{\"authorId\":\"50557601\",\"name\":\"Chenxi Liu\"},{\"authorId\":\"145527707\",\"name\":\"Zhe L. Lin\"},{\"authorId\":\"1720987\",\"name\":\"X. Shen\"},{\"authorId\":\"1768964\",\"name\":\"Jimei Yang\"},{\"authorId\":\"145574672\",\"name\":\"Xin Lu\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.1109/ICCV.2017.143\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d69edb02e935b782b90175cb691f6ab5f4bd64f\",\"title\":\"Recurrent Multimodal Interaction for Referring Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/3d69edb02e935b782b90175cb691f6ab5f4bd64f\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41052836\",\"name\":\"Anya Belz\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"}],\"doi\":\"10.1017/S1351324918000086\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d740802aa22dbc187fe5df39108ba493b34d2839\",\"title\":\"From image to language and back again\",\"url\":\"https://www.semanticscholar.org/paper/d740802aa22dbc187fe5df39108ba493b34d2839\",\"venue\":\"Nat. Lang. Eng.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50829868\",\"name\":\"A. Testoni\"},{\"authorId\":\"3422247\",\"name\":\"Sandro Pezzelle\"},{\"authorId\":\"145040726\",\"name\":\"R. Bernardi\"}],\"doi\":\"10.18653/v1/W19-2912\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f4036759404c6fa54a040b69bcfd4996083cb3aa\",\"title\":\"Quantifiers in a Multimodal World: Hallucinating Vision with Language and Sound\",\"url\":\"https://www.semanticscholar.org/paper/f4036759404c6fa54a040b69bcfd4996083cb3aa\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6eeff23d6e0127cfbbd0374a83341173a418ba7f\",\"title\":\"Dual Attention Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/6eeff23d6e0127cfbbd0374a83341173a418ba7f\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46174228\",\"name\":\"Sidra Shabir\"},{\"authorId\":\"49854677\",\"name\":\"Syed Yasser Arafat\"}],\"doi\":\"10.1109/ICPESG.2018.8384519\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4bc176200ff718ea0a0650145d3d263b0b7dfb39\",\"title\":\"An image conveys a message: A brief survey on image description generation\",\"url\":\"https://www.semanticscholar.org/paper/4bc176200ff718ea0a0650145d3d263b0b7dfb39\",\"venue\":\"2018 1st International Conference on Power, Energy and Smart Grid (ICPESG)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49780999\",\"name\":\"Y. Zhu\"},{\"authorId\":\"82741945\",\"name\":\"Y. Zhu\"},{\"authorId\":\"1711560\",\"name\":\"D. Metaxas\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5d5f6ca40afd27fd49c72930a87abd8b9fc4c0b1\",\"title\":\"TOWARDS ACTIVE AND INTERACTIVE VISUAL LEARNING\",\"url\":\"https://www.semanticscholar.org/paper/5d5f6ca40afd27fd49c72930a87abd8b9fc4c0b1\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yu Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d7484d9e753ccc529018f8c01027bfef304dc1b9\",\"title\":\"An Interpretable (Conversational) VQA model using Attention based Weighted Contextual Features\",\"url\":\"https://www.semanticscholar.org/paper/d7484d9e753ccc529018f8c01027bfef304dc1b9\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Pan Lu\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"2236084\",\"name\":\"Weitong Zhang\"},{\"authorId\":\"2447408\",\"name\":\"Jianyong Wang\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7835f6e76e810445a38f76892c5dc58ee17efddb\",\"title\":\"Question : What is on the plate ? S of tm ax Linear Tanh ResNet Faster-RCNN GRU Linear Tanh\",\"url\":\"https://www.semanticscholar.org/paper/7835f6e76e810445a38f76892c5dc58ee17efddb\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e8d37d9522d57df506a6eda88953bd97c009ea29\",\"title\":\"Characterizing how Visual Question Answering models scale with the world\",\"url\":\"https://www.semanticscholar.org/paper/e8d37d9522d57df506a6eda88953bd97c009ea29\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"46172451\",\"name\":\"B. Wang\"},{\"authorId\":\"2248826\",\"name\":\"R. Hong\"},{\"authorId\":\"32996440\",\"name\":\"F. Wu\"}],\"doi\":\"10.1109/TCSVT.2019.2897604\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cb2f25b32344888d644dc3a3e729275a8abee07a\",\"title\":\"Movie Question Answering via Textual Memory and Plot Graph\",\"url\":\"https://www.semanticscholar.org/paper/cb2f25b32344888d644dc3a3e729275a8abee07a\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47260649\",\"name\":\"Imran Sheikh\"},{\"authorId\":\"1791335\",\"name\":\"Rupayan Chakraborty\"},{\"authorId\":\"1809276\",\"name\":\"Sunil Kumar Kopparapu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c7f8ccccda67a44503b4c4e0611f38451a334cc2\",\"title\":\"Audio-Visual Fusion for Sentiment Classification using Cross-Modal Autoencoder\",\"url\":\"https://www.semanticscholar.org/paper/c7f8ccccda67a44503b4c4e0611f38451a334cc2\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49528055\",\"name\":\"Hanzhang Wang\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"3187665\",\"name\":\"Kaisheng Xu\"}],\"doi\":\"10.1109/CVPR.2018.00521\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"7fdac774e51e0aa8f9921e857067801d73a8d2d0\",\"title\":\"Categorizing Concepts with Basic Level for Vision-to-Language\",\"url\":\"https://www.semanticscholar.org/paper/7fdac774e51e0aa8f9921e857067801d73a8d2d0\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"35198686\",\"name\":\"Joseph J. Lim\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2017.651\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"173a38768848cfe57a6b20b5ae019ce613e58781\",\"title\":\"Knowledge Acquisition for Visual Question Answering via Iterative Querying\",\"url\":\"https://www.semanticscholar.org/paper/173a38768848cfe57a6b20b5ae019ce613e58781\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2221434\",\"name\":\"R. Hasan\"},{\"authorId\":\"145548902\",\"name\":\"Eman T. Hassan\"},{\"authorId\":\"2356044\",\"name\":\"Y. Li\"},{\"authorId\":\"1786759\",\"name\":\"Kelly Caine\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"},{\"authorId\":\"39179135\",\"name\":\"R. Hoyle\"},{\"authorId\":\"145728136\",\"name\":\"Apu Kapadia\"}],\"doi\":\"10.1145/3173574.3173621\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7f55f878eeb9bd1f2827aa9a1f68a3601de9eb17\",\"title\":\"Viewer Experience of Obscuring Scene Elements in Photos to Enhance Privacy\",\"url\":\"https://www.semanticscholar.org/paper/7f55f878eeb9bd1f2827aa9a1f68a3601de9eb17\",\"venue\":\"CHI\",\"year\":2018},{\"arxivId\":\"1707.06830\",\"authors\":[{\"authorId\":\"145784776\",\"name\":\"R. Sharma\"},{\"authorId\":\"1720741\",\"name\":\"T. Guha\"},{\"authorId\":\"144054467\",\"name\":\"G. Sharma\"}],\"doi\":\"10.1109/WACV.2018.00058\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a5531b5626c1ee3b6f9aed281a98338439d06d12\",\"title\":\"Multichannel Attention Network for Analyzing Visual Behavior in Public Speaking\",\"url\":\"https://www.semanticscholar.org/paper/a5531b5626c1ee3b6f9aed281a98338439d06d12\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":\"1710.03370\",\"authors\":[{\"authorId\":\"144238414\",\"name\":\"Feng Liu\"},{\"authorId\":\"145406421\",\"name\":\"T. Xiang\"},{\"authorId\":\"1697755\",\"name\":\"Timothy M. Hospedales\"},{\"authorId\":\"2345507\",\"name\":\"Wankou Yang\"},{\"authorId\":\"145928755\",\"name\":\"C. Sun\"}],\"doi\":\"10.1109/CVPR.2018.00898\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8a565aa547e2bdf278ad3d1fce1f1da8e70c38a1\",\"title\":\"iVQA: Inverse Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8a565aa547e2bdf278ad3d1fce1f1da8e70c38a1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1801.01582\",\"authors\":[{\"authorId\":\"2326243\",\"name\":\"Arun Balajee Vasudevan\"},{\"authorId\":\"1778526\",\"name\":\"Dengxin Dai\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2018.00434\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7a82d83f818cdc4ac714e468446bc2499ff9caa7\",\"title\":\"Object Referring in Videos with Language and Human Gaze\",\"url\":\"https://www.semanticscholar.org/paper/7a82d83f818cdc4ac714e468446bc2499ff9caa7\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1904.04166\",\"authors\":[{\"authorId\":\"1887625\",\"name\":\"Yuehua Wu\"},{\"authorId\":\"39978626\",\"name\":\"Lu Jiang\"},{\"authorId\":\"143699996\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1109/TIP.2020.2967584\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"866908141e1db5d6b278984072303a0e14423bcc\",\"title\":\"Revisiting EmbodiedQA: A Simple Baseline and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/866908141e1db5d6b278984072303a0e14423bcc\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40791626\",\"name\":\"Reham Abobeah\"},{\"authorId\":\"39781659\",\"name\":\"A. Shoukry\"},{\"authorId\":\"1788294\",\"name\":\"J. Katto\"}],\"doi\":\"10.1109/ACCESS.2020.2967750\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"15c795b754f44f5f1c8664a5adb18e01e33eb8e5\",\"title\":\"Video Alignment Using Bi-Directional Attention Flow in a Multi-Stage Learning Model\",\"url\":\"https://www.semanticscholar.org/paper/15c795b754f44f5f1c8664a5adb18e01e33eb8e5\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1912.01119\",\"authors\":[{\"authorId\":\"97634546\",\"name\":\"Khaled Jedoui\"},{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e23a129f49fcd52258c14da28311cce3190d271f\",\"title\":\"Deep Bayesian Active Learning for Multiple Correct Outputs\",\"url\":\"https://www.semanticscholar.org/paper/e23a129f49fcd52258c14da28311cce3190d271f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2484223\",\"name\":\"Yuan-Ting Hu\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1145/3103535.3103541\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5a0bacb6246e40a3595a90a6c55ccf9573322312\",\"title\":\"An Elevator Pitch on Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/5a0bacb6246e40a3595a90a6c55ccf9573322312\",\"venue\":\"GETMBL\",\"year\":2017},{\"arxivId\":\"1711.06232\",\"authors\":[{\"authorId\":\"2973866\",\"name\":\"J. Huang\"},{\"authorId\":\"3409955\",\"name\":\"C. D. Dao\"},{\"authorId\":\"9951160\",\"name\":\"Modar Alfadly\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1609/aaai.v33i01.33018449\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a26d01dc2b9a4e435c015914690354f67a9b6a08\",\"title\":\"A Novel Framework for Robustness Analysis of Visual QA Models\",\"url\":\"https://www.semanticscholar.org/paper/a26d01dc2b9a4e435c015914690354f67a9b6a08\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1804.00298\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":\"10.1109/CVPR.2018.00801\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6ef1d2076f50940683e326b97cbf0d9e5d630116\",\"title\":\"Differential Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/6ef1d2076f50940683e326b97cbf0d9e5d630116\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1605.01379\",\"authors\":[{\"authorId\":\"9136919\",\"name\":\"X. Lin\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1007/978-3-319-46475-6_17\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c94217efec8773ef947df2772f92df8c5726f855\",\"title\":\"Leveraging Visual Question Answering for Image-Caption Ranking\",\"url\":\"https://www.semanticscholar.org/paper/c94217efec8773ef947df2772f92df8c5726f855\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2822290\",\"name\":\"Suraj Srinivas\"},{\"authorId\":\"1730952\",\"name\":\"Ravi Kiran Sarvadevabhatla\"},{\"authorId\":\"2217000\",\"name\":\"Konda Reddy Mopuri\"},{\"authorId\":\"40390520\",\"name\":\"N. Prabhu\"},{\"authorId\":\"1784761\",\"name\":\"S. Kruthiventi\"},{\"authorId\":\"144682140\",\"name\":\"R. Venkatesh Babu\"}],\"doi\":\"10.1016/B978-0-12-810408-8.00003-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"783cd91797aad234b1558099689e794b48694092\",\"title\":\"An Introduction to Deep Convolutional Neural Nets for Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/783cd91797aad234b1558099689e794b48694092\",\"venue\":\"Deep Learning for Medical Image Analysis\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/ICCV.2015.279\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"784da2a7b53a16d2243f747e14946cc5e3476af0\",\"title\":\"VQA: Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/784da2a7b53a16d2243f747e14946cc5e3476af0\",\"venue\":\"ICCV\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2593979\",\"name\":\"Kyung-Min Kim\"},{\"authorId\":\"46182785\",\"name\":\"Chang-Jun Nan\"},{\"authorId\":\"2577039\",\"name\":\"Jung-Woo Ha\"},{\"authorId\":\"15353659\",\"name\":\"Yu-Jung Heo\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"6448e25b8767febcd2933eadb3ffc70eb0dffb64\",\"title\":\"Pororobot: A Deep Learning Robot That Plays Video Q&A Games\",\"url\":\"https://www.semanticscholar.org/paper/6448e25b8767febcd2933eadb3ffc70eb0dffb64\",\"venue\":\"AAAI Fall Symposia\",\"year\":2015}],\"corpusId\":738850,\"doi\":\"10.1109/ICCV.2015.9\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":49,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"bd7bd1d2945a58cdcc1797ba9698b8810fe68f60\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1750652\",\"name\":\"Jonathan Berant\"},{\"authorId\":\"145419642\",\"name\":\"Percy Liang\"}],\"doi\":\"10.3115/v1/P14-1133\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d1d42c9435b419ac928ebf7bcf4c86a460d6ef4\",\"title\":\"Semantic Parsing via Paraphrasing\",\"url\":\"https://www.semanticscholar.org/paper/3d1d42c9435b419ac928ebf7bcf4c86a460d6ef4\",\"venue\":\"ACL\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"S. Guadarrama\"},{\"authorId\":null,\"name\":\"M. Rohrbach\"},{\"authorId\":null,\"name\":\"K. Saenko\"},{\"authorId\":null,\"name\":\"T. Darrell\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Examples of questions and answers - failure cases . representations using rnn encoder - decoder for statistical machine translation\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1707642\",\"name\":\"D. Geman\"},{\"authorId\":\"3194361\",\"name\":\"S. Geman\"},{\"authorId\":\"9588317\",\"name\":\"Neil Hallonquist\"},{\"authorId\":\"1721284\",\"name\":\"L. Younes\"}],\"doi\":\"10.1073/pnas.1422953112\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"050da5d159fb0dd96143948e1cffeb3dec814673\",\"title\":\"Visual Turing test for computer vision systems\",\"url\":\"https://www.semanticscholar.org/paper/050da5d159fb0dd96143948e1cffeb3dec814673\",\"venue\":\"Proceedings of the National Academy of Sciences\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"K Cho\"},{\"authorId\":null,\"name\":\"B Van Merrienboer\"},{\"authorId\":null,\"name\":\"C Gulcehre\"},{\"authorId\":null,\"name\":\"F Bougares\"},{\"authorId\":null,\"name\":\"H Schwenk\"},{\"authorId\":null,\"name\":\"D Bahdanau\"},{\"authorId\":null,\"name\":\"Y Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Learning phrase\",\"url\":\"\",\"venue\":\"Learning phrase\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1162/neco.1997.9.8.1735\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"title\":\"Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"venue\":\"Neural Computation\",\"year\":1997},{\"arxivId\":\"1410.0210\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"ac64fb7e6d2ddf236332ec9f371fe85d308c114d\",\"title\":\"A Multi-World Approach to Question Answering about Real-World Scenes based on Uncertain Input\",\"url\":\"https://www.semanticscholar.org/paper/ac64fb7e6d2ddf236332ec9f371fe85d308c114d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1506.00278\",\"authors\":[{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"2155311\",\"name\":\"Eunbyung Park\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a58a582b95a07932cb248f1b739e4ad739ead6b9\",\"title\":\"Visual Madlibs: Fill in the blank Image Generation and Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a58a582b95a07932cb248f1b739e4ad739ead6b9\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2517825\",\"name\":\"J. Krishnamurthy\"},{\"authorId\":\"2836353\",\"name\":\"T. Kollar\"}],\"doi\":\"10.1162/tacl_a_00220\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c45fd881bcc20bc1a754ee4b446d99aaff1d3dd5\",\"title\":\"Jointly Learning to Parse and Perceive: Connecting Natural Language to the Physical World\",\"url\":\"https://www.semanticscholar.org/paper/c45fd881bcc20bc1a754ee4b446d99aaff1d3dd5\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"P. Liang\"},{\"authorId\":null,\"name\":\"M. I. Jordan\"},{\"authorId\":null,\"name\":\"D. Klein\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Learning dependencybased compositional semantics\",\"url\":\"\",\"venue\":\"Computational Linguistics\",\"year\":2013},{\"arxivId\":\"1410.4615\",\"authors\":[{\"authorId\":\"2563432\",\"name\":\"W. Zaremba\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0d0b3ff23fbf1ec7a0dfebd923a3ef224306491a\",\"title\":\"Learning to Execute\",\"url\":\"https://www.semanticscholar.org/paper/0d0b3ff23fbf1ec7a0dfebd923a3ef224306491a\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1648075979\",\"name\":\"B. A. R. Kernfach\"},{\"authorId\":\"1648268257\",\"name\":\"Nur IM Sommersemester\"},{\"authorId\":\"1648268256\",\"name\":\"\\u00dcbersicht Franz\\u00f6sisch\"},{\"authorId\":\"1648134774\",\"name\":\"\\u00dcbersicht Italienisch\"}],\"doi\":\"10.1515/9783111697888-004\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fff1b293b45d06c8462021aa6c90c81e743e131b\",\"title\":\"B\",\"url\":\"https://www.semanticscholar.org/paper/fff1b293b45d06c8462021aa6c90c81e743e131b\",\"venue\":\"Edinburgh Medical and Surgical Journal\",\"year\":1824},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145670761\",\"name\":\"J. Cohen\"}],\"doi\":\"10.1177/001316446002000104\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9e463eefadbcd336c69270a299666e4104d50159\",\"title\":\"A Coefficient of Agreement for Nominal Scales\",\"url\":\"https://www.semanticscholar.org/paper/9e463eefadbcd336c69270a299666e4104d50159\",\"venue\":\"\",\"year\":1960},{\"arxivId\":\"1109.6841\",\"authors\":[{\"authorId\":\"145419642\",\"name\":\"Percy Liang\"},{\"authorId\":\"1694621\",\"name\":\"Michael I. Jordan\"},{\"authorId\":\"38666915\",\"name\":\"D. Klein\"}],\"doi\":\"10.1162/COLI_a_00127\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3ecd3e00bbbfd94446c3adc9c6878de27e250f7c\",\"title\":\"Learning Dependency-Based Compositional Semantics\",\"url\":\"https://www.semanticscholar.org/paper/3ecd3e00bbbfd94446c3adc9c6878de27e250f7c\",\"venue\":\"Computational Linguistics\",\"year\":2013},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1909300\",\"name\":\"Lucy Vanderwende\"}],\"doi\":\"10.1109/ICCV.2013.211\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6c39f56c3c21c3972c362f8e752be57a50c41f4f\",\"title\":\"Learning the Visual Interpretation of Sentences\",\"url\":\"https://www.semanticscholar.org/paper/6c39f56c3c21c3972c362f8e752be57a50c41f4f\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":\"1502.05698\",\"authors\":[{\"authorId\":\"145183709\",\"name\":\"J. Weston\"},{\"authorId\":\"1713934\",\"name\":\"Antoine Bordes\"},{\"authorId\":\"3295092\",\"name\":\"S. Chopra\"},{\"authorId\":null,\"name\":\"Tomas Mikolov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"abb33d75dc297993fcc3fb75e0f4498f413eb4f6\",\"title\":\"Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks\",\"url\":\"https://www.semanticscholar.org/paper/abb33d75dc297993fcc3fb75e0f4498f413eb4f6\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1412.2306\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/TPAMI.2016.2598339\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"title\":\"Deep Visual-Semantic Alignments for Generating Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":\"cmp-lg/9406033\",\"authors\":[{\"authorId\":\"2459057\",\"name\":\"Z. Wu\"},{\"authorId\":\"145755155\",\"name\":\"Martha Palmer\"}],\"doi\":\"10.3115/981732.981751\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"0e3e3c3d8ae5cb7c4636870d69967c197484d3bb\",\"title\":\"Verb Semantics and Lexical Selection\",\"url\":\"https://www.semanticscholar.org/paper/0e3e3c3d8ae5cb7c4636870d69967c197484d3bb\",\"venue\":\"ACL\",\"year\":1994},{\"arxivId\":\"1505.00487\",\"authors\":[{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/ICCV.2015.515\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e58a110fa1e4ddf247d5c614d117d64bfbe135c4\",\"title\":\"Sequence to Sequence -- Video to Text\",\"url\":\"https://www.semanticscholar.org/paper/e58a110fa1e4ddf247d5c614d117d64bfbe135c4\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2136562\",\"name\":\"Mohit Iyyer\"},{\"authorId\":\"1409929082\",\"name\":\"Jordan L. Boyd-Graber\"},{\"authorId\":\"3357514\",\"name\":\"Leonardo Claudino\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"1722360\",\"name\":\"Hal Daum\\u00e9\"}],\"doi\":\"10.3115/v1/D14-1070\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"af44f5db5b4396e1670cda07eff5ad84145ba843\",\"title\":\"A Neural Network for Factoid Question Answering over Paragraphs\",\"url\":\"https://www.semanticscholar.org/paper/af44f5db5b4396e1670cda07eff5ad84145ba843\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1409.3215\",\"authors\":[{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cea967b59209c6be22829699f05b8b1ac4dc092d\",\"title\":\"Sequence to Sequence Learning with Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/cea967b59209c6be22829699f05b8b1ac4dc092d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2286640\",\"name\":\"N. Silberman\"},{\"authorId\":\"2433269\",\"name\":\"Derek Hoiem\"},{\"authorId\":\"143967473\",\"name\":\"P. Kohli\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":\"10.1007/978-3-642-33715-4_54\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c1994ba5946456fc70948c549daf62363f13fa2d\",\"title\":\"Indoor Segmentation and Support Inference from RGBD Images\",\"url\":\"https://www.semanticscholar.org/paper/c1994ba5946456fc70948c549daf62363f13fa2d\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144332826\",\"name\":\"Chen Kong\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":\"10.1109/CVPR.2014.455\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"13549b4e6fffbb7932b7a83a8eb6be27e6a60eca\",\"title\":\"What Are You Talking About? Text-to-Image Coreference\",\"url\":\"https://www.semanticscholar.org/paper/13549b4e6fffbb7932b7a83a8eb6be27e6a60eca\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1406.1078\",\"authors\":[{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"3158246\",\"name\":\"B. V. Merrienboer\"},{\"authorId\":\"1854385\",\"name\":\"\\u00c7aglar G\\u00fcl\\u00e7ehre\"},{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"2076086\",\"name\":\"Fethi Bougares\"},{\"authorId\":\"144518416\",\"name\":\"Holger Schwenk\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":\"10.3115/v1/D14-1179\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0b544dfe355a5070b60986319a3f51fb45d1348e\",\"title\":\"Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/0b544dfe355a5070b60986319a3f51fb45d1348e\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2540599\",\"name\":\"Mengye Ren\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"df4f851e3c37017822a683b1356c6c390b5b5487\",\"title\":\"Image Question Answering: A Visual Semantic Embedding Model and a New Dataset\",\"url\":\"https://www.semanticscholar.org/paper/df4f851e3c37017822a683b1356c6c390b5b5487\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1408.5093\",\"authors\":[{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"1782282\",\"name\":\"Evan Shelhamer\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"3049736\",\"name\":\"S. Karayev\"},{\"authorId\":\"144361581\",\"name\":\"J. Long\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1145/2647868.2654889\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"6bdb186ec4726e00a8051119636d4df3b94043b5\",\"title\":\"Caffe: Convolutional Architecture for Fast Feature Embedding\",\"url\":\"https://www.semanticscholar.org/paper/6bdb186ec4726e00a8051119636d4df3b94043b5\",\"venue\":\"ACM Multimedia\",\"year\":2014},{\"arxivId\":\"1206.6423\",\"authors\":[{\"authorId\":\"2674440\",\"name\":\"Cynthia Matuszek\"},{\"authorId\":\"143883142\",\"name\":\"Nicholas FitzGerald\"},{\"authorId\":\"1982950\",\"name\":\"Luke Zettlemoyer\"},{\"authorId\":\"144651486\",\"name\":\"L. Bo\"},{\"authorId\":\"145197953\",\"name\":\"D. Fox\"}],\"doi\":\"10.13016/M2EHU6-1M90\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"58bd0afc8a1b98e16a67ebda436e60c6f6410f56\",\"title\":\"A Joint Model of Language and Perception for Grounded Attribute Learning\",\"url\":\"https://www.semanticscholar.org/paper/58bd0afc8a1b98e16a67ebda436e60c6f6410f56\",\"venue\":\"ICML\",\"year\":2012},{\"arxivId\":\"1409.4842\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"46641766\",\"name\":\"W. Liu\"},{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"},{\"authorId\":\"48840704\",\"name\":\"Scott Reed\"},{\"authorId\":\"1838674\",\"name\":\"Dragomir Anguelov\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"39863668\",\"name\":\"Andrew Rabinovich\"}],\"doi\":\"10.1109/CVPR.2015.7298594\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"title\":\"Going deeper with convolutions\",\"url\":\"https://www.semanticscholar.org/paper/e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1506.00333\",\"authors\":[{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"11955007\",\"name\":\"Z. Lu\"},{\"authorId\":\"49404233\",\"name\":\"Hang Li\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"98bd5dd1740f585bf25320ba504e2c1ae57f2e5f\",\"title\":\"Learning to Answer Questions from Image Using Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/98bd5dd1740f585bf25320ba504e2c1ae57f2e5f\",\"venue\":\"AAAI\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1735300\",\"name\":\"S. Haykin\"},{\"authorId\":\"35299277\",\"name\":\"B. Kosko\"}],\"doi\":\"10.1109/9780470544976.CH9\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f42b865e20e61a954239f421b42007236e671f19\",\"title\":\"GradientBased Learning Applied to Document Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f42b865e20e61a954239f421b42007236e671f19\",\"venue\":\"\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"},{\"authorId\":\"52184096\",\"name\":\"L. Bottou\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"1721248\",\"name\":\"P. Haffner\"}],\"doi\":\"10.1109/5.726791\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"162d958ff885f1462aeda91cd72582323fd6a1f4\",\"title\":\"Gradient-based learning applied to document recognition\",\"url\":\"https://www.semanticscholar.org/paper/162d958ff885f1462aeda91cd72582323fd6a1f4\",\"venue\":\"\",\"year\":1998},{\"arxivId\":\"1410.3916\",\"authors\":[{\"authorId\":\"145183709\",\"name\":\"J. Weston\"},{\"authorId\":\"3295092\",\"name\":\"S. Chopra\"},{\"authorId\":\"1713934\",\"name\":\"Antoine Bordes\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"71ae756c75ac89e2d731c9c79649562b5768ff39\",\"title\":\"Memory Networks\",\"url\":\"https://www.semanticscholar.org/paper/71ae756c75ac89e2d731c9c79649562b5768ff39\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1406.5679\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2319608\",\"name\":\"Armand Joulin\"},{\"authorId\":\"153196308\",\"name\":\"F. Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7f1b111f0bb703b0bd97aba505728a9b0d9b2a54\",\"title\":\"Deep Fragment Embeddings for Bidirectional Image Sentence Mapping\",\"url\":\"https://www.semanticscholar.org/paper/7f1b111f0bb703b0bd97aba505728a9b0d9b2a54\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1409.0575\",\"authors\":[{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"71309570\",\"name\":\"H. Su\"},{\"authorId\":\"2285165\",\"name\":\"J. Krause\"},{\"authorId\":\"145031342\",\"name\":\"S. Satheesh\"},{\"authorId\":\"145423516\",\"name\":\"S. Ma\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-015-0816-y\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"title\":\"ImageNet Large Scale Visual Recognition Challenge\",\"url\":\"https://www.semanticscholar.org/paper/e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6734096\",\"name\":\"J. Fleiss\"},{\"authorId\":\"145670758\",\"name\":\"J. Cohen\"}],\"doi\":\"10.1177/001316447303300309\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"85ecca58c8b4d40a4bf53c1c45b1b8e410468aea\",\"title\":\"The Equivalence of Weighted Kappa and the Intraclass Correlation Coefficient as Measures of Reliability\",\"url\":\"https://www.semanticscholar.org/paper/85ecca58c8b4d40a4bf53c1c45b1b8e410468aea\",\"venue\":\"\",\"year\":1973},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"P Liang\"},{\"authorId\":null,\"name\":\"M I Jordan\"},{\"authorId\":null,\"name\":\"D Klein\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Learning dependencybased compositional semantics. Computational Linguistics\",\"url\":\"\",\"venue\":\"Learning dependencybased compositional semantics. Computational Linguistics\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52014393\",\"name\":\"Ut Austin\"},{\"authorId\":\"123312980\",\"name\":\"Austin\"},{\"authorId\":\"102704114\",\"name\":\"UMass Lowell\"},{\"authorId\":\"102898595\",\"name\":\"Lowell\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"43795b7bac3d921c4e579964b54187bdbf6c6330\",\"title\":\"Translating Videos to Natural Language Using Deep Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/43795b7bac3d921c4e579964b54187bdbf6c6330\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"M. Malinowski\"},{\"authorId\":null,\"name\":\"M. Rohrbach\"},{\"authorId\":null,\"name\":\"M. Fritz\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"ICCV'15, Oral, to appear)\",\"url\":\"\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1505.05612\",\"authors\":[{\"authorId\":\"2345388\",\"name\":\"Haoyuan Gao\"},{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":null,\"name\":\"Jie Zhou\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":null,\"name\":\"Lei Wang\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2fcd5cff2b4743ea640c4af68bf4143f4a2cccb1\",\"title\":\"Are You Talking to a Machine? Dataset and Methods for Multilingual Image Question\",\"url\":\"https://www.semanticscholar.org/paper/2fcd5cff2b4743ea640c4af68bf4143f4a2cccb1\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1410.8027\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3d29e1c4f1c2b079cf6b5dd458fa6cee246955f9\",\"title\":\"Towards a Visual Turing Challenge\",\"url\":\"https://www.semanticscholar.org/paper/3d29e1c4f1c2b079cf6b5dd458fa6cee246955f9\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/ICCV.2015.279\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"784da2a7b53a16d2243f747e14946cc5e3476af0\",\"title\":\"VQA: Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/784da2a7b53a16d2243f747e14946cc5e3476af0\",\"venue\":\"ICCV\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3115592\",\"name\":\"Ndapandula Nakashole\"},{\"authorId\":\"2685013\",\"name\":\"Tomasz Tylenda\"},{\"authorId\":\"1751591\",\"name\":\"G. Weikum\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6629785cb5c9c96921f97e7a8c56dbe63f80d9ef\",\"title\":\"Fine-grained Semantic Typing of Emerging Entities\",\"url\":\"https://www.semanticscholar.org/paper/6629785cb5c9c96921f97e7a8c56dbe63f80d9ef\",\"venue\":\"ACL\",\"year\":2013}],\"title\":\"Ask Your Neurons: A Neural-Based Approach to Answering Questions about Images\",\"topics\":[{\"topic\":\"Question answering\",\"topicId\":\"18817\",\"url\":\"https://www.semanticscholar.org/topic/18817\"},{\"topic\":\"Natural language processing\",\"topicId\":\"1914\",\"url\":\"https://www.semanticscholar.org/topic/1914\"},{\"topic\":\"Visual Turing Test\",\"topicId\":\"727819\",\"url\":\"https://www.semanticscholar.org/topic/727819\"},{\"topic\":\"Baseline (configuration management)\",\"topicId\":\"3403\",\"url\":\"https://www.semanticscholar.org/topic/3403\"},{\"topic\":\"Commonsense knowledge (artificial intelligence)\",\"topicId\":\"326287\",\"url\":\"https://www.semanticscholar.org/topic/326287\"},{\"topic\":\"End-to-end principle\",\"topicId\":\"299633\",\"url\":\"https://www.semanticscholar.org/topic/299633\"},{\"topic\":\"Parsing\",\"topicId\":\"1910\",\"url\":\"https://www.semanticscholar.org/topic/1910\"},{\"topic\":\"Modal logic\",\"topicId\":\"61528\",\"url\":\"https://www.semanticscholar.org/topic/61528\"},{\"topic\":\"Period-doubling bifurcation\",\"topicId\":\"550140\",\"url\":\"https://www.semanticscholar.org/topic/550140\"}],\"url\":\"https://www.semanticscholar.org/paper/bd7bd1d2945a58cdcc1797ba9698b8810fe68f60\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015}\n"