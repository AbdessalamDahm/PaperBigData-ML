"{\"abstract\":\"This paper presents a novel feature learning method for visual speech recognition using Deep Boltzmann Machines (DBM). Unlike all existing visual feature extraction techniques which solely extracts features from video sequences, our method is able to explore both acoustic information and visual information to learn a better visual feature representation in the training stage. During the test stage, instead of using both audio and visual signals, only the videos are used for generating the missing audio feature, and both the given visual and given audio features are used to obtain a joint representation. We carried out our experiments on a large scale audio-visual data corpus, and experimental results show that our proposed techniques outperforms the performance of the hadncrafted features and features learned by other commonly used deep learning techniques.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"144213476\",\"name\":\"Chao Sui\",\"url\":\"https://www.semanticscholar.org/author/144213476\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\",\"url\":\"https://www.semanticscholar.org/author/1698675\"},{\"authorId\":\"2444665\",\"name\":\"R. Togneri\",\"url\":\"https://www.semanticscholar.org/author/2444665\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":\"1807.05162\",\"authors\":[{\"authorId\":\"3144580\",\"name\":\"Brendan Shillingford\"},{\"authorId\":\"3365565\",\"name\":\"Yannis M. Assael\"},{\"authorId\":\"3243579\",\"name\":\"M. W. Hoffman\"},{\"authorId\":\"145757542\",\"name\":\"T. Paine\"},{\"authorId\":\"49304262\",\"name\":\"C. Hughes\"},{\"authorId\":\"39309000\",\"name\":\"Utsav Prabhu\"},{\"authorId\":\"39977619\",\"name\":\"H. Liao\"},{\"authorId\":\"2670103\",\"name\":\"H. Sak\"},{\"authorId\":\"2251957\",\"name\":\"K. Rao\"},{\"authorId\":\"51121518\",\"name\":\"Lorrayne Bennett\"},{\"authorId\":\"51116420\",\"name\":\"Marie Mulville\"},{\"authorId\":\"48303781\",\"name\":\"Ben Coppin\"},{\"authorId\":\"153774873\",\"name\":\"B. Laurie\"},{\"authorId\":\"33666044\",\"name\":\"A. Senior\"},{\"authorId\":\"1737568\",\"name\":\"N. D. Freitas\"}],\"doi\":\"10.21437/interspeech.2019-1669\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e5befd105f7bbd373208522d5b85682116b59c38\",\"title\":\"Large-Scale Visual Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e5befd105f7bbd373208522d5b85682116b59c38\",\"venue\":\"INTERSPEECH\",\"year\":2019},{\"arxivId\":\"1701.05847\",\"authors\":[{\"authorId\":\"2403354\",\"name\":\"S. Petridis\"},{\"authorId\":\"8798628\",\"name\":\"Z. Li\"},{\"authorId\":\"145387780\",\"name\":\"M. Pantic\"}],\"doi\":\"10.1109/ICASSP.2017.7952625\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f1e214cf61b9f6be6a67ebe129e6d34584e783d4\",\"title\":\"End-to-end visual speech recognition with LSTMS\",\"url\":\"https://www.semanticscholar.org/paper/f1e214cf61b9f6be6a67ebe129e6d34584e783d4\",\"venue\":\"2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2017},{\"arxivId\":\"1807.00619\",\"authors\":[{\"authorId\":\"50793081\",\"name\":\"Y. Kumar\"},{\"authorId\":\"46469663\",\"name\":\"Mayank Aggarwal\"},{\"authorId\":\"51118910\",\"name\":\"Pratham Nawal\"},{\"authorId\":\"1700567\",\"name\":\"Shin'ichi Satoh\"},{\"authorId\":\"1753278\",\"name\":\"R. Shah\"},{\"authorId\":\"144809527\",\"name\":\"Roger Zimmermann\"}],\"doi\":\"10.1145/3240508.3241911\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b978e6034842395b3e9202cec26a257594da8f76\",\"title\":\"Harnessing AI for Speech Reconstruction using Multi-view Silent Video Feed\",\"url\":\"https://www.semanticscholar.org/paper/b978e6034842395b3e9202cec26a257594da8f76\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1710.07161\",\"authors\":[{\"authorId\":\"26207251\",\"name\":\"M. Zimmermann\"},{\"authorId\":\"1399030182\",\"name\":\"Mostafa Mehdipour-Ghazi\"},{\"authorId\":\"3025777\",\"name\":\"H. K. Ekenel\"},{\"authorId\":\"7195318\",\"name\":\"J-P. Thiran\"}],\"doi\":\"10.1007/978-3-319-54427-4_20\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"513d3fe5c88ee442871ea95d2f2a444f85e7dad6\",\"title\":\"Visual Speech Recognition Using PCA Networks and LSTMs in a Tandem GMM-HMM System\",\"url\":\"https://www.semanticscholar.org/paper/513d3fe5c88ee442871ea95d2f2a444f85e7dad6\",\"venue\":\"ACCV Workshops\",\"year\":2016},{\"arxivId\":\"1906.04691\",\"authors\":[{\"authorId\":\"48271262\",\"name\":\"Taewan Kim\"},{\"authorId\":\"34724702\",\"name\":\"Joydeep Ghosh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"43c5257502b0460ad44bf744c263b5b9120d29e6\",\"title\":\"On Single Source Robustness in Deep Fusion Models\",\"url\":\"https://www.semanticscholar.org/paper/43c5257502b0460ad44bf744c263b5b9120d29e6\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1710.07168\",\"authors\":[{\"authorId\":\"26207251\",\"name\":\"M. Zimmermann\"},{\"authorId\":\"1399030182\",\"name\":\"Mostafa Mehdipour-Ghazi\"},{\"authorId\":\"3025777\",\"name\":\"H. K. Ekenel\"},{\"authorId\":\"7195318\",\"name\":\"J-P. Thiran\"}],\"doi\":\"10.21437/AVSP.2017-10\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2d8e88fec1ffd18675f241f4df55a8846fe237f7\",\"title\":\"Combining Multiple Views for Visual Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2d8e88fec1ffd18675f241f4df55a8846fe237f7\",\"venue\":\"AVSP\",\"year\":2017},{\"arxivId\":\"2012.10852\",\"authors\":[{\"authorId\":\"40121503\",\"name\":\"Sindhu B. Hegde\"},{\"authorId\":\"1380234931\",\"name\":\"K. Prajwal\"},{\"authorId\":\"41052499\",\"name\":\"R. Mukhopadhyay\"},{\"authorId\":\"1744135\",\"name\":\"Vinay Namboodiri\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c2ca56c7bf6fae7096d35806412a1820a2a1712e\",\"title\":\"Visual Speech Enhancement Without A Real Visual Stream\",\"url\":\"https://www.semanticscholar.org/paper/c2ca56c7bf6fae7096d35806412a1820a2a1712e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50793081\",\"name\":\"Y. Kumar\"},{\"authorId\":\"46469663\",\"name\":\"Mayank Aggarwal\"},{\"authorId\":\"51118910\",\"name\":\"Pratham Nawal\"},{\"authorId\":\"1700567\",\"name\":\"Shin'ichi Satoh\"},{\"authorId\":\"1753278\",\"name\":\"R. Shah\"},{\"authorId\":\"144809527\",\"name\":\"Roger Zimmermann\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7115db883183510122e2485dd9063d31a25dabdb\",\"title\":\"Speech Reconstitution using Multi-view Silent Videos\",\"url\":\"https://www.semanticscholar.org/paper/7115db883183510122e2485dd9063d31a25dabdb\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1704.08035\",\"authors\":[{\"authorId\":\"1410464604\",\"name\":\"A. Fernandez-Lopez\"},{\"authorId\":\"2012978\",\"name\":\"F. Sukno\"}],\"doi\":\"10.5220/0006102100520063\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"eb55a66008808ef169121ba60cd60f4308373908\",\"title\":\"Automatic Viseme Vocabulary Construction to Enhance Continuous Lip-reading\",\"url\":\"https://www.semanticscholar.org/paper/eb55a66008808ef169121ba60cd60f4308373908\",\"venue\":\"VISIGRAPP\",\"year\":2017},{\"arxivId\":\"1704.08028\",\"authors\":[{\"authorId\":\"1410464604\",\"name\":\"A. Fernandez-Lopez\"},{\"authorId\":\"145796289\",\"name\":\"Oriol Mart\\u00ednez\"},{\"authorId\":\"2012978\",\"name\":\"F. Sukno\"}],\"doi\":\"10.1109/FG.2017.34\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2f5d7ff5eb22042e91ab5208795415a9c91ccb3b\",\"title\":\"Towards Estimating the Upper Bound of Visual-Speech Recognition: The Visual Lip-Reading Feasibility Database\",\"url\":\"https://www.semanticscholar.org/paper/2f5d7ff5eb22042e91ab5208795415a9c91ccb3b\",\"venue\":\"2017 12th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2017)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51241930\",\"name\":\"Xinmei Zhong\"},{\"authorId\":\"9370398\",\"name\":\"Yunzhong Dai\"},{\"authorId\":\"50436835\",\"name\":\"Yong Dai\"},{\"authorId\":\"145246518\",\"name\":\"T. Jin\"}],\"doi\":\"10.1007/s10772-018-9516-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"96b7250c81f4f619ff750a09745f049a73f4c0cc\",\"title\":\"Study on processing of wavelet speech denoising in speech recognition system\",\"url\":\"https://www.semanticscholar.org/paper/96b7250c81f4f619ff750a09745f049a73f4c0cc\",\"venue\":\"Int. J. Speech Technol.\",\"year\":2018},{\"arxivId\":\"1611.01599\",\"authors\":[{\"authorId\":\"3365565\",\"name\":\"Yannis M. Assael\"},{\"authorId\":\"3144580\",\"name\":\"Brendan Shillingford\"},{\"authorId\":\"1766767\",\"name\":\"S. Whiteson\"},{\"authorId\":\"1737568\",\"name\":\"N. D. Freitas\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"291c0e453503a704c0fd932a067ca054cc7edad6\",\"title\":\"LipNet: End-to-End Sentence-level Lipreading\",\"url\":\"https://www.semanticscholar.org/paper/291c0e453503a704c0fd932a067ca054cc7edad6\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145213644\",\"name\":\"M. R. Alam\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"2444665\",\"name\":\"R. Togneri\"},{\"authorId\":\"2470423\",\"name\":\"Ferdous Sohel\"}],\"doi\":\"10.1109/TMM.2016.2615524\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ebd10f51f3a190fd1ca06f1bacfe0092f7d28f50\",\"title\":\"A Joint Deep Boltzmann Machine (jDBM) Model for Person Identification Using Mobile Phone Data\",\"url\":\"https://www.semanticscholar.org/paper/ebd10f51f3a190fd1ca06f1bacfe0092f7d28f50\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144213476\",\"name\":\"Chao Sui\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"2444665\",\"name\":\"R. Togneri\"}],\"doi\":\"10.1016/j.patrec.2017.03.021\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1a367f9c330411614397220564516484aa71d11c\",\"title\":\"Deep feature learning for dummies: A simple auto-encoder training method using Particle Swarm Optimisation\",\"url\":\"https://www.semanticscholar.org/paper/1a367f9c330411614397220564516484aa71d11c\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2027003826\",\"name\":\"Mingfeng Hao\"},{\"authorId\":\"26957200\",\"name\":\"Mutallip Mamut\"},{\"authorId\":\"2027003608\",\"name\":\"Nurbiya Yadikar\"},{\"authorId\":\"2119595\",\"name\":\"A. Aysa\"},{\"authorId\":\"1869945\",\"name\":\"K. Ubul\"}],\"doi\":\"10.1109/ACCESS.2020.3036865\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"3014cc7546ad2c35d47fd6627233d92d7ae40a85\",\"title\":\"A Survey of Research on Lipreading Technology\",\"url\":\"https://www.semanticscholar.org/paper/3014cc7546ad2c35d47fd6627233d92d7ae40a85\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1704.03152\",\"authors\":[{\"authorId\":\"3042242\",\"name\":\"X. Yang\"},{\"authorId\":\"40327196\",\"name\":\"Palghat Ramesh\"},{\"authorId\":\"1776163\",\"name\":\"Radha Chitta\"},{\"authorId\":\"2234121\",\"name\":\"S. Madhvanath\"},{\"authorId\":\"2164140\",\"name\":\"E. Bernal\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2017.538\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"01f4e52ead817b83d65478d03f6a9d7e9074d889\",\"title\":\"Deep Multimodal Representation Learning from Temporal Data\",\"url\":\"https://www.semanticscholar.org/paper/01f4e52ead817b83d65478d03f6a9d7e9074d889\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410464604\",\"name\":\"A. Fernandez-Lopez\"},{\"authorId\":\"2012978\",\"name\":\"F. Sukno\"}],\"doi\":\"10.1016/j.imavis.2018.07.002\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"938717d66533d900abac7451e15c1f322e78db81\",\"title\":\"Survey on automatic lip-reading in the era of deep learning\",\"url\":\"https://www.semanticscholar.org/paper/938717d66533d900abac7451e15c1f322e78db81\",\"venue\":\"Image Vis. Comput.\",\"year\":2018},{\"arxivId\":\"1905.03968\",\"authors\":[{\"authorId\":\"144339857\",\"name\":\"Nilay Shrivastava\"},{\"authorId\":\"51004100\",\"name\":\"Astitwa Saxena\"},{\"authorId\":\"50793081\",\"name\":\"Y. Kumar\"},{\"authorId\":\"2052549\",\"name\":\"Preeti Kaur\"},{\"authorId\":\"1753278\",\"name\":\"R. Shah\"},{\"authorId\":\"2712224\",\"name\":\"Debanjan Mahata\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f0d5606c0e77ce7a85dadf79a238f4938e29da72\",\"title\":\"MobiVSR: A Visual Speech Recognition Solution for Mobile Devices\",\"url\":\"https://www.semanticscholar.org/paper/f0d5606c0e77ce7a85dadf79a238f4938e29da72\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3034487\",\"name\":\"K. Thangthai\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a9f19c1fbf50f3a54d6227383c8b43b2d7fce75c\",\"title\":\"Computer lipreading via hybrid deep neural network hidden Markov models\",\"url\":\"https://www.semanticscholar.org/paper/a9f19c1fbf50f3a54d6227383c8b43b2d7fce75c\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26609465\",\"name\":\"S. Khan\"},{\"authorId\":\"47893834\",\"name\":\"K. Ullah\"}],\"doi\":\"10.1109/ICIEECT.2017.7916563\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0af5e51c47c5fc867329748d98b0d62f4d547879\",\"title\":\"Visual acuity test for isolated words using speech recognition\",\"url\":\"https://www.semanticscholar.org/paper/0af5e51c47c5fc867329748d98b0d62f4d547879\",\"venue\":\"2017 International Conference on Innovations in Electrical Engineering and Computational Technologies (ICIEECT)\",\"year\":2017},{\"arxivId\":\"1903.09616\",\"authors\":[{\"authorId\":\"7885067\",\"name\":\"Xinshuo Weng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"27dd4c88b990f54f8b2c6039b98fa1de72d27150\",\"title\":\"On the Importance of Video Action Recognition for Visual Lipreading\",\"url\":\"https://www.semanticscholar.org/paper/27dd4c88b990f54f8b2c6039b98fa1de72d27150\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2006.08599\",\"authors\":[{\"authorId\":\"66016321\",\"name\":\"Dhruva Sahrawat\"},{\"authorId\":\"50793081\",\"name\":\"Y. Kumar\"},{\"authorId\":\"1452341751\",\"name\":\"Shashwat Aggarwal\"},{\"authorId\":\"144221742\",\"name\":\"Yifang Yin\"},{\"authorId\":\"1753278\",\"name\":\"R. Shah\"},{\"authorId\":\"153015119\",\"name\":\"R. Zimmermann\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7ab8502508a2eee7025c632b5373dcc48ef042be\",\"title\":\"\\\"Notic My Speech\\\" - Blending Speech Patterns With Multimedia\",\"url\":\"https://www.semanticscholar.org/paper/7ab8502508a2eee7025c632b5373dcc48ef042be\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1905.02540\",\"authors\":[{\"authorId\":\"7885067\",\"name\":\"Xinshuo Weng\"},{\"authorId\":\"144040368\",\"name\":\"K. Kitani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"607048b431cea997ae9dd01f029a73c502d0273f\",\"title\":\"Learning Spatio-Temporal Features with Two-Stream Deep 3D CNNs for Lipreading\",\"url\":\"https://www.semanticscholar.org/paper/607048b431cea997ae9dd01f029a73c502d0273f\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410464604\",\"name\":\"A. Fernandez-Lopez\"},{\"authorId\":\"2012978\",\"name\":\"F. Sukno\"}],\"doi\":\"10.1007/978-3-030-12209-6_15\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"06dd16799c5b939226aee9315340a6547bee4205\",\"title\":\"Optimizing Phoneme-to-Viseme Mapping for Continuous Lip-Reading in Spanish\",\"url\":\"https://www.semanticscholar.org/paper/06dd16799c5b939226aee9315340a6547bee4205\",\"venue\":\"VISIGRAPP\",\"year\":2017},{\"arxivId\":\"1706.10197\",\"authors\":[{\"authorId\":\"3091647\",\"name\":\"Zibo Meng\"},{\"authorId\":\"49107074\",\"name\":\"Shizhong Han\"},{\"authorId\":\"47478870\",\"name\":\"Ping Liu\"},{\"authorId\":\"145371875\",\"name\":\"Yan Tong\"}],\"doi\":\"10.1109/TCYB.2018.2840090\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bc4dc3f1e2dd7ad9b2fc08284d612e7f6d6df9c7\",\"title\":\"Improving Speech Related Facial Action Unit Recognition by Audiovisual Information Fusion\",\"url\":\"https://www.semanticscholar.org/paper/bc4dc3f1e2dd7ad9b2fc08284d612e7f6d6df9c7\",\"venue\":\"IEEE Transactions on Cybernetics\",\"year\":2019},{\"arxivId\":\"1904.01954\",\"authors\":[{\"authorId\":\"2403354\",\"name\":\"S. Petridis\"},{\"authorId\":\"2563750\",\"name\":\"Yujiang Wang\"},{\"authorId\":\"144933397\",\"name\":\"Pingchuan Ma\"},{\"authorId\":\"8798628\",\"name\":\"Z. Li\"},{\"authorId\":\"145387780\",\"name\":\"M. Pantic\"}],\"doi\":\"10.1016/j.patrec.2020.01.022\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4c785dcf80ae0f8d5fab1960ef2afc6cefcebd8a\",\"title\":\"End-to-End Visual Speech Recognition for Small-Scale Datasets\",\"url\":\"https://www.semanticscholar.org/paper/4c785dcf80ae0f8d5fab1960ef2afc6cefcebd8a\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3091647\",\"name\":\"Zibo Meng\"},{\"authorId\":\"49107074\",\"name\":\"Shizhong Han\"},{\"authorId\":\"83359287\",\"name\":\"M. Chen\"},{\"authorId\":\"145371875\",\"name\":\"Yan Tong\"}],\"doi\":\"10.4018/IJMDEM.2016010104\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"798ed4c9f8d24fef57c0f944738216bacdd6d7b4\",\"title\":\"Audiovisual Facial Action Unit Recognition using Feature Level Fusion\",\"url\":\"https://www.semanticscholar.org/paper/798ed4c9f8d24fef57c0f944738216bacdd6d7b4\",\"venue\":\"Int. J. Multim. Data Eng. Manag.\",\"year\":2016}],\"corpusId\":14503362,\"doi\":\"10.1109/ICCV.2015.26\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":3,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"ad036ad46fc14212d6b9ffdb1a823c4a9e89195b\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"2653504\",\"name\":\"Y. Pei\"},{\"authorId\":\"143617697\",\"name\":\"Tae-Kyun Kim\"},{\"authorId\":\"1687248\",\"name\":\"H. Zha\"}],\"doi\":\"10.1109/ICCV.2013.23\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7d2c61faa5350bce08725d2a301f393499feb734\",\"title\":\"Unsupervised Random Forest Manifold Alignment for Lipreading\",\"url\":\"https://www.semanticscholar.org/paper/7d2c61faa5350bce08725d2a301f393499feb734\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1798550\",\"name\":\"Timothy J. Hazen\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"3079356\",\"name\":\"C. La\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"}],\"doi\":\"10.1145/1027933.1027972\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8365df47be3313e86be96d0f8f96d070c2d51128\",\"title\":\"A segment-based audio-visual speech recognizer: data collection, development, and initial experiments\",\"url\":\"https://www.semanticscholar.org/paper/8365df47be3313e86be96d0f8f96d070c2d51128\",\"venue\":\"ICMI '04\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144213476\",\"name\":\"Chao Sui\"},{\"authorId\":\"2444665\",\"name\":\"R. Togneri\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"}],\"doi\":\"10.1109/ICASSP.2015.7178224\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"917a5aba3232e66bfbfc4e162d98fccde77d8e47\",\"title\":\"Extracting deep bottleneck features for visual speech recognition\",\"url\":\"https://www.semanticscholar.org/paper/917a5aba3232e66bfbfc4e162d98fccde77d8e47\",\"venue\":\"2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"104117062\",\"name\":\"Ziheng Zhou\"},{\"authorId\":\"83433495\",\"name\":\"G. Zhao\"},{\"authorId\":\"46761465\",\"name\":\"Xiaopeng Hong\"},{\"authorId\":\"145962204\",\"name\":\"M. Pietik\\u00e4inen\"}],\"doi\":\"10.1016/j.imavis.2014.06.004\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"4c842fbd4c032dd4d931eb6ff1eaa2a13450b7af\",\"title\":\"A review of recent advances in visual speech decoding\",\"url\":\"https://www.semanticscholar.org/paper/4c842fbd4c032dd4d931eb6ff1eaa2a13450b7af\",\"venue\":\"Image Vis. Comput.\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1757287\",\"name\":\"G. Zhao\"},{\"authorId\":\"144302675\",\"name\":\"M. Barnard\"},{\"authorId\":\"145962204\",\"name\":\"M. Pietik\\u00e4inen\"}],\"doi\":\"10.1109/TMM.2009.2030637\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8c4a6a915a7fbb9af5beeff55bf7d8cef18bf93a\",\"title\":\"Lipreading With Local Spatiotemporal Descriptors\",\"url\":\"https://www.semanticscholar.org/paper/8c4a6a915a7fbb9af5beeff55bf7d8cef18bf93a\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"85021c84383d18a7a4434d76dc8135fc6bdc0aa6\",\"title\":\"Deep Boltzmann Machines\",\"url\":\"https://www.semanticscholar.org/paper/85021c84383d18a7a4434d76dc8135fc6bdc0aa6\",\"venue\":\"AISTATS\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144580027\",\"name\":\"Dong Yu\"},{\"authorId\":\"1727524\",\"name\":\"Michael L. Seltzer\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"008e9e2d3908c964d5b1c408c478215709dbea10\",\"title\":\"Improved Bottleneck Features Using Pretrained Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/008e9e2d3908c964d5b1c408c478215709dbea10\",\"venue\":\"INTERSPEECH\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"S. Gurbuz\"},{\"authorId\":null,\"name\":\"Z. Tufekci\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Multimodal deep learning Learning sequential patterns for lipreading\",\"url\":\"\",\"venue\":\"\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40427010\",\"name\":\"M. Wagner\"},{\"authorId\":\"144216770\",\"name\":\"D. Tran\"},{\"authorId\":\"2444665\",\"name\":\"R. Togneri\"},{\"authorId\":\"7296521\",\"name\":\"P. Rose\"},{\"authorId\":\"144871539\",\"name\":\"D. Powers\"},{\"authorId\":\"2281712\",\"name\":\"M. Onslow\"},{\"authorId\":\"31781363\",\"name\":\"D. Loakes\"},{\"authorId\":\"145111765\",\"name\":\"T. Lewis\"},{\"authorId\":\"1747304\",\"name\":\"T. Kuratate\"},{\"authorId\":\"2125840\",\"name\":\"Y. Kinoshita\"},{\"authorId\":\"46817222\",\"name\":\"N. Kemp\"},{\"authorId\":\"4639863\",\"name\":\"S. Ishihara\"},{\"authorId\":\"152579413\",\"name\":\"J. Ingram\"},{\"authorId\":\"34351592\",\"name\":\"J. Hajek\"},{\"authorId\":\"2807319\",\"name\":\"D. Grayden\"},{\"authorId\":\"1717204\",\"name\":\"R. Goecke\"},{\"authorId\":\"48017861\",\"name\":\"J. Fletcher\"},{\"authorId\":\"2672421\",\"name\":\"D. Estival\"},{\"authorId\":\"145815422\",\"name\":\"J. Epps\"},{\"authorId\":\"144301565\",\"name\":\"R. Dale\"},{\"authorId\":\"143789092\",\"name\":\"A. Cutler\"},{\"authorId\":\"49582788\",\"name\":\"F. Cox\"},{\"authorId\":\"2263677\",\"name\":\"G. Chetty\"},{\"authorId\":\"1891272\",\"name\":\"S. Cassidy\"},{\"authorId\":\"145564710\",\"name\":\"Andrew Butcher\"},{\"authorId\":\"50218399\",\"name\":\"Denis K Burnham\"},{\"authorId\":\"21308992\",\"name\":\"Steven Bird\"},{\"authorId\":\"1834311\",\"name\":\"C. Best\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"2811464\",\"name\":\"Joanne Arciuli\"},{\"authorId\":\"9279985\",\"name\":\"E. Ambikairajah\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8062aa4a6f1b1618ba8ee6cd4a9a8c7d084aca1c\",\"title\":\"The Big Australian Speech Corpus (The Big ASC)\",\"url\":\"https://www.semanticscholar.org/paper/8062aa4a6f1b1618ba8ee6cd4a9a8c7d084aca1c\",\"venue\":\"\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1731948\",\"name\":\"P. Viola\"},{\"authorId\":\"145319478\",\"name\":\"Michael J. Jones\"}],\"doi\":\"10.1109/ICCV.2001.937709\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b09ec0b350f8352bce46a2f5bf7ae97c83a7b9ca\",\"title\":\"Robust real-time face detection\",\"url\":\"https://www.semanticscholar.org/paper/b09ec0b350f8352bce46a2f5bf7ae97c83a7b9ca\",\"venue\":\"Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145259603\",\"name\":\"S. Young\"},{\"authorId\":\"1713807\",\"name\":\"Gunnar Evermann\"},{\"authorId\":\"38296926\",\"name\":\"M. Gales\"},{\"authorId\":\"2171861\",\"name\":\"Thomas Hain\"},{\"authorId\":\"145796302\",\"name\":\"D. Kershaw\"},{\"authorId\":\"1938928\",\"name\":\"G. L. Moore\"},{\"authorId\":\"144687429\",\"name\":\"J. Odell\"},{\"authorId\":\"2965187\",\"name\":\"D. Ollason\"},{\"authorId\":\"47652202\",\"name\":\"D. Povey\"},{\"authorId\":\"69425965\",\"name\":\"Valtchev\"},{\"authorId\":\"52590933\",\"name\":\"Philip C. Woodland\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"135328a4e2a33e17949b495ccd5fbdc87b2a7e3d\",\"title\":\"The HTK book version 3.4\",\"url\":\"https://www.semanticscholar.org/paper/135328a4e2a33e17949b495ccd5fbdc87b2a7e3d\",\"venue\":\"\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"S. J. Young\"},{\"authorId\":null,\"name\":\"G. Evermann\"},{\"authorId\":null,\"name\":\"M. Gales\"},{\"authorId\":null,\"name\":\"D. Kershaw\"},{\"authorId\":null,\"name\":\"G. Moore\"},{\"authorId\":null,\"name\":\"J. Odell\"},{\"authorId\":null,\"name\":\"D. Ollason\"},{\"authorId\":null,\"name\":\"D. Povey\"},{\"authorId\":null,\"name\":\"V. Valtchev\"},{\"authorId\":null,\"name\":\"P. Woodland\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"The HTK book version\",\"url\":\"\",\"venue\":\"\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145823936\",\"name\":\"Amr Bakry\"},{\"authorId\":\"145159523\",\"name\":\"A. Elgammal\"}],\"doi\":\"10.1109/CVPR.2013.94\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a226c1252385e36abb0ac38117fd8dd7f37dbfac\",\"title\":\"MKPLS: Manifold Kernel Partial Least Squares for Lipreading and Speaker Identification\",\"url\":\"https://www.semanticscholar.org/paper/a226c1252385e36abb0ac38117fd8dd7f37dbfac\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"G Potamianos\"},{\"authorId\":null,\"name\":\"C Neti\"},{\"authorId\":null,\"name\":\"J Luettin\"},{\"authorId\":null,\"name\":\"I Matthews\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Audiovisual automatic speech recognition: An overview. Issues in visual and audio-visual speech processing\",\"url\":\"\",\"venue\":\"Audiovisual automatic speech recognition: An overview. Issues in visual and audio-visual speech processing\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1711695\",\"name\":\"I. Matthews\"},{\"authorId\":\"7205190\",\"name\":\"T. Cootes\"},{\"authorId\":\"144427091\",\"name\":\"J. Bangham\"},{\"authorId\":\"35132323\",\"name\":\"S. Cox\"},{\"authorId\":\"144439756\",\"name\":\"R. Harvey\"}],\"doi\":\"10.1109/34.982900\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f78867834f7f6797ca6396f98edb10aad2a864fb\",\"title\":\"Extraction of Visual Features for Lipreading\",\"url\":\"https://www.semanticscholar.org/paper/f78867834f7f6797ca6396f98edb10aad2a864fb\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"H Peng\"},{\"authorId\":null,\"name\":\"F Long\"},{\"authorId\":null,\"name\":\"C Ding\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Feature selection based on mutual information criteria of max-dependency, maxrelevance , and min-redundancy. Pattern Analysis and Machine Intelligence\",\"url\":\"\",\"venue\":\"IEEE Transactions on\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2020608\",\"name\":\"J. Ngiam\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"4738460\",\"name\":\"Mingyu Kim\"},{\"authorId\":\"145578392\",\"name\":\"Juhan Nam\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"},{\"authorId\":\"34699434\",\"name\":\"A. Ng\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"80e9e3fc3670482c1fee16b2542061b779f47c4f\",\"title\":\"Multimodal Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/80e9e3fc3670482c1fee16b2542061b779f47c4f\",\"venue\":\"ICML\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"G Zhao\"},{\"authorId\":null,\"name\":\"M Barnard\"},{\"authorId\":null,\"name\":\"M Pietikainen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Lipreading with local spatiotemporal descriptors. Multimedia\",\"url\":\"\",\"venue\":\"IEEE Transactions on\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143894891\",\"name\":\"E. Ong\"},{\"authorId\":\"145398628\",\"name\":\"R. Bowden\"}],\"doi\":\"10.5244/C.25.55\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"42093b4c11762a67d25e45f791d2a7dee17c04b1\",\"title\":\"Learning Sequential Patterns for Lipreading\",\"url\":\"https://www.semanticscholar.org/paper/42093b4c11762a67d25e45f791d2a7dee17c04b1\",\"venue\":\"BMVC\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34849838\",\"name\":\"Ziheng Zhou\"},{\"authorId\":\"1757287\",\"name\":\"G. Zhao\"},{\"authorId\":\"145962204\",\"name\":\"M. Pietik\\u00e4inen\"}],\"doi\":\"10.1109/CVPR.2011.5995345\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"56b506a95cb63afd1e359babe1fdf3f0138ff7a4\",\"title\":\"Towards a practical lipreading system\",\"url\":\"https://www.semanticscholar.org/paper/56b506a95cb63afd1e359babe1fdf3f0138ff7a4\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34969191\",\"name\":\"P. Scanlon\"},{\"authorId\":\"145708716\",\"name\":\"R. Reilly\"}],\"doi\":\"10.1109/MMSP.2001.962802\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"64b6007b5b87ac0d6dbb83ed3307aaec1cb1f5f6\",\"title\":\"Feature analysis for automatic speechreading\",\"url\":\"https://www.semanticscholar.org/paper/64b6007b5b87ac0d6dbb83ed3307aaec1cb1f5f6\",\"venue\":\"2001 IEEE Fourth Workshop on Multimedia Signal Processing (Cat. No.01TH8564)\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1c46943103bd7b7a2c7be86859995a4144d1938b\",\"title\":\"Visualizing Data using t-SNE\",\"url\":\"https://www.semanticscholar.org/paper/1c46943103bd7b7a2c7be86859995a4144d1938b\",\"venue\":\"\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2401865\",\"name\":\"Jonas Gehring\"},{\"authorId\":\"37467623\",\"name\":\"Y. Miao\"},{\"authorId\":\"1740721\",\"name\":\"F. Metze\"},{\"authorId\":\"1724972\",\"name\":\"Alexander H. Waibel\"}],\"doi\":\"10.1109/ICASSP.2013.6638284\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c5ee8c30bba238fbcb31456b10ebb2cdb8d1a35\",\"title\":\"Extracting deep bottleneck features using stacked auto-encoders\",\"url\":\"https://www.semanticscholar.org/paper/2c5ee8c30bba238fbcb31456b10ebb2cdb8d1a35\",\"venue\":\"2013 IEEE International Conference on Acoustics, Speech and Signal Processing\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"2444665\",\"name\":\"R. Togneri\"}],\"doi\":\"10.1007/978-1-4939-1456-2_6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"490facf1b0e3a400234e7590345935d1ef1cf226\",\"title\":\"Deep Dynamic Models for Learning Hidden Representations of Speech Features\",\"url\":\"https://www.semanticscholar.org/paper/490facf1b0e3a400234e7590345935d1ef1cf226\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2422388\",\"name\":\"Jingyong Su\"},{\"authorId\":\"143868576\",\"name\":\"A. Srivastava\"},{\"authorId\":\"27398350\",\"name\":\"F. Souza\"},{\"authorId\":\"145306925\",\"name\":\"Sudeep Sarkar\"}],\"doi\":\"10.1109/CVPR.2014.86\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"32033cf3e84b0ffd5700da470e08fa54f40ab2d0\",\"title\":\"Rate-Invariant Analysis of Trajectories on Riemannian Manifolds with Application in Visual Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/32033cf3e84b0ffd5700da470e08fa54f40ab2d0\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1757287\",\"name\":\"G. Zhao\"},{\"authorId\":\"48345000\",\"name\":\"T. Ahonen\"},{\"authorId\":\"145564537\",\"name\":\"Jiri Matas\"},{\"authorId\":\"145962204\",\"name\":\"M. Pietik\\u00e4inen\"}],\"doi\":\"10.1109/TIP.2011.2175739\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d1414c971c9a3e3e4273910159e9471dc78d272b\",\"title\":\"Rotation-Invariant Image and Video Description With Local Binary Pattern Features\",\"url\":\"https://www.semanticscholar.org/paper/d1414c971c9a3e3e4273910159e9471dc78d272b\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1788454\",\"name\":\"Mihai Gurban\"},{\"authorId\":\"1710257\",\"name\":\"J. Thiran\"}],\"doi\":\"10.1109/TSP.2009.2026513\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"48c6b1d7fd3d9b5e170481c255aaab8bd66d40ab\",\"title\":\"Information Theoretic Feature Extraction for Audio-Visual Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/48c6b1d7fd3d9b5e170481c255aaab8bd66d40ab\",\"venue\":\"IEEE Transactions on Signal Processing\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3255983\",\"name\":\"V. Mnih\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0ea90fac0958d84bcf4a2875c2b169478358b480\",\"title\":\"CUDAMat: a CUDA-based matrix class for Python\",\"url\":\"https://www.semanticscholar.org/paper/0ea90fac0958d84bcf4a2875c2b169478358b480\",\"venue\":\"\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49025046\",\"name\":\"Jing Huang\"},{\"authorId\":\"144707379\",\"name\":\"Brian Kingsbury\"}],\"doi\":\"10.1109/ICASSP.2013.6639140\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3a039e33733ed88fecc5b353e0d7ab26817e122d\",\"title\":\"Audio-visual deep learning for noise robust speech recognition\",\"url\":\"https://www.semanticscholar.org/paper/3a039e33733ed88fecc5b353e0d7ab26817e122d\",\"venue\":\"2013 IEEE International Conference on Acoustics, Speech and Signal Processing\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10787756\",\"name\":\"M. Sulaiman\"},{\"authorId\":\"2808327\",\"name\":\"J. Labadin\"}],\"doi\":\"10.1109/CITA.2015.7349827\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0c91d5305ad34814b631d4a642bb0535a2e066ea\",\"title\":\"Feature selection based on mutual information\",\"url\":\"https://www.semanticscholar.org/paper/0c91d5305ad34814b631d4a642bb0535a2e066ea\",\"venue\":\"2015 9th International Conference on IT in Asia (CITA)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2173900\",\"name\":\"K. Messer\"},{\"authorId\":\"145564537\",\"name\":\"Jiri Matas\"},{\"authorId\":\"47091894\",\"name\":\"J. Kittler\"},{\"authorId\":\"1678373\",\"name\":\"J. Luettin\"},{\"authorId\":\"2488626\",\"name\":\"G. Ma\\u00eetre\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b62628ac06bbac998a3ab825324a41a11bc3a988\",\"title\":\"XM2VTSDB: The Extended M2VTS Database\",\"url\":\"https://www.semanticscholar.org/paper/b62628ac06bbac998a3ab825324a41a11bc3a988\",\"venue\":\"\",\"year\":1999},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"144580027\",\"name\":\"Dong Yu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6e07128ca05c16ad295e320a05eda4c738047212\",\"title\":\"Foundations and Trends in Signal Processing: DEEP LEARNING - Methods and Applications\",\"url\":\"https://www.semanticscholar.org/paper/6e07128ca05c16ad295e320a05eda4c738047212\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34849838\",\"name\":\"Ziheng Zhou\"},{\"authorId\":\"46761465\",\"name\":\"Xiaopeng Hong\"},{\"authorId\":\"1757287\",\"name\":\"G. Zhao\"},{\"authorId\":\"145962204\",\"name\":\"M. Pietik\\u00e4inen\"}],\"doi\":\"10.1109/TPAMI.2013.173\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a8bbbf3ff7757e2c963997ab07229518b04a1db6\",\"title\":\"A Compact Representation of Visual Speech Data Using Latent Variables\",\"url\":\"https://www.semanticscholar.org/paper/a8bbbf3ff7757e2c963997ab07229518b04a1db6\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1688852\",\"name\":\"G. Potamianos\"},{\"authorId\":\"2264160\",\"name\":\"C. Neti\"},{\"authorId\":\"1678373\",\"name\":\"J. Luettin\"},{\"authorId\":\"1711695\",\"name\":\"I. Matthews\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"afb50fe3d6490ad5cd0b624ac72e569fbf33f619\",\"title\":\"Audio-Visual Automatic Speech Recognition: An Overview\",\"url\":\"https://www.semanticscholar.org/paper/afb50fe3d6490ad5cd0b624ac72e569fbf33f619\",\"venue\":\"\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5726c7b40fcc454b77d989656c085520bf6c15fa\",\"title\":\"Multimodal learning with deep Boltzmann machines\",\"url\":\"https://www.semanticscholar.org/paper/5726c7b40fcc454b77d989656c085520bf6c15fa\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145270321\",\"name\":\"E. B. Patterson\"},{\"authorId\":\"3097743\",\"name\":\"S. Gurbuz\"},{\"authorId\":\"3351861\",\"name\":\"Z. Tufekci\"},{\"authorId\":\"33978317\",\"name\":\"J.N. Gowdy\"}],\"doi\":\"10.1109/ICASSP.2002.5745028\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dd70cd5c716b7c484f4a9833cf61453e1e70d387\",\"title\":\"CUAVE: A new audio-visual database for multimodal human-computer interface research\",\"url\":\"https://www.semanticscholar.org/paper/dd70cd5c716b7c484f4a9833cf61453e1e70d387\",\"venue\":\"2002 IEEE International Conference on Acoustics, Speech, and Signal Processing\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"S J Young\"},{\"authorId\":null,\"name\":\"G Evermann\"},{\"authorId\":null,\"name\":\"M Gales\"},{\"authorId\":null,\"name\":\"D Kershaw\"},{\"authorId\":null,\"name\":\"G Moore\"},{\"authorId\":null,\"name\":\"J Odell\"},{\"authorId\":null,\"name\":\"D Ollason\"},{\"authorId\":null,\"name\":\"D Povey\"},{\"authorId\":null,\"name\":\"V Valtchev\"},{\"authorId\":null,\"name\":\"P Woodland\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"The HTK book version 3\",\"url\":\"\",\"venue\":\"The HTK book version 3\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":\"10.1126/SCIENCE.1127647\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"46eb79e5eec8a4e2b2f5652b66441e8a4c921c3e\",\"title\":\"Reducing the Dimensionality of Data with Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/46eb79e5eec8a4e2b2f5652b66441e8a4c921c3e\",\"venue\":\"Science\",\"year\":2006}],\"title\":\"Listening with Your Eyes: Towards a Practical Visual Speech Recognition System Using Deep Boltzmann Machines\",\"topics\":[{\"topic\":\"Speech recognition\",\"topicId\":\"2869\",\"url\":\"https://www.semanticscholar.org/topic/2869\"},{\"topic\":\"Feature extraction\",\"topicId\":\"4259\",\"url\":\"https://www.semanticscholar.org/topic/4259\"},{\"topic\":\"Feature learning\",\"topicId\":\"20551\",\"url\":\"https://www.semanticscholar.org/topic/20551\"},{\"topic\":\"Deep learning\",\"topicId\":\"2762\",\"url\":\"https://www.semanticscholar.org/topic/2762\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Dbm\",\"topicId\":\"570179\",\"url\":\"https://www.semanticscholar.org/topic/570179\"},{\"topic\":\"Acoustic cryptanalysis\",\"topicId\":\"1017215\",\"url\":\"https://www.semanticscholar.org/topic/1017215\"}],\"url\":\"https://www.semanticscholar.org/paper/ad036ad46fc14212d6b9ffdb1a823c4a9e89195b\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015}\n"