"{\"abstract\":\"Learning how to interact with objects is an important step towards embodied visual intelligence, but existing techniques suffer from heavy supervision or sensing requirements. We propose an approach to learn human-object interaction \\\"hotspots\\\" directly from video. Rather than treat affordances as a manually supervised semantic segmentation task, our approach learns about interactions by watching videos of real human behavior and anticipating afforded actions. Given a novel image or video, our model infers a spatial hotspot map indicating where an object would be manipulated in a potential interaction even if the object is currently at rest. Through results with both first and third person video, we show the value of grounding affordances in real human-object interactions. Not only are our weakly supervised hotspots competitive with strongly supervised affordance methods, but they can also anticipate object interaction for novel object categories. Project page: http://vision.cs.utexas.edu/projects/interaction-hotspots/\",\"arxivId\":\"1812.04558\",\"authors\":[{\"authorId\":\"38661780\",\"name\":\"Tushar Nagarajan\",\"url\":\"https://www.semanticscholar.org/author/38661780\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\",\"url\":\"https://www.semanticscholar.org/author/2322150\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\",\"url\":\"https://www.semanticscholar.org/author/1794409\"}],\"citationVelocity\":8,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"47842115\",\"name\":\"M. Liu\"},{\"authorId\":\"39578749\",\"name\":\"Siyu Tang\"},{\"authorId\":\"47002162\",\"name\":\"Y. Li\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c94aa2bff74824bb8c3adbd5c697d890d0e73620\",\"title\":\"Forecasting Human Object Interaction: Joint Prediction of Motor Attention and Egocentric Activity\",\"url\":\"https://www.semanticscholar.org/paper/c94aa2bff74824bb8c3adbd5c697d890d0e73620\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2004.08644\",\"authors\":[{\"authorId\":\"3418004\",\"name\":\"Spyridon Thermos\"},{\"authorId\":\"1747572\",\"name\":\"P. Daras\"},{\"authorId\":\"1423737852\",\"name\":\"Gerasimos Potamianos\"}],\"doi\":\"10.1109/ICASSP40776.2020.9054167\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8fd3cb7b995b66312bb42220eadde30d0ae130cd\",\"title\":\"A Deep Learning Approach to Object Affordance Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/8fd3cb7b995b66312bb42220eadde30d0ae130cd\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"2010.05654\",\"authors\":[{\"authorId\":\"39714216\",\"name\":\"F. Ragusa\"},{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"2444519\",\"name\":\"S. Livatino\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a58a0732664b97b471b795df5812f98f24840490\",\"title\":\"The MECCANO Dataset: Understanding Human-Object Interactions from Egocentric Videos in an Industrial-like Domain\",\"url\":\"https://www.semanticscholar.org/paper/a58a0732664b97b471b795df5812f98f24840490\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35412344\",\"name\":\"Suchen Wang\"},{\"authorId\":\"2258221\",\"name\":\"Kim-Hui Yap\"},{\"authorId\":\"48837492\",\"name\":\"J. Yuan\"},{\"authorId\":\"30915941\",\"name\":\"Y. Tan\"}],\"doi\":\"10.1109/cvpr42600.2020.01167\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"393a25ea49ca01204ee4d0910a786b9614fab478\",\"title\":\"Discovering Human Interactions With Novel Objects via Zero-Shot Learning\",\"url\":\"https://www.semanticscholar.org/paper/393a25ea49ca01204ee4d0910a786b9614fab478\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2006.06669\",\"authors\":[{\"authorId\":\"48158956\",\"name\":\"Dandan Shan\"},{\"authorId\":\"20290060\",\"name\":\"J. Geng\"},{\"authorId\":\"38826848\",\"name\":\"Michelle Shu\"},{\"authorId\":\"1786435\",\"name\":\"David F. Fouhey\"}],\"doi\":\"10.1109/cvpr42600.2020.00989\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b539b61fbeb3a8514fd82069b35884a4fcac4985\",\"title\":\"Understanding Human Hands in Contact at Internet Scale\",\"url\":\"https://www.semanticscholar.org/paper/b539b61fbeb3a8514fd82069b35884a4fcac4985\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24378300\",\"name\":\"Adam Allevato\"},{\"authorId\":\"32775309\",\"name\":\"Elaine Schaertl Short\"},{\"authorId\":\"46423508\",\"name\":\"M. Pryor\"},{\"authorId\":\"1682788\",\"name\":\"A. Thomaz\"}],\"doi\":\"10.15607/rss.2020.xvi.037\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7694275203cfb569589f85d81bc0931074b06774\",\"title\":\"Learning Labeled Robot Affordance Models Using Simulations and Crowdsourcing\",\"url\":\"https://www.semanticscholar.org/paper/7694275203cfb569589f85d81bc0931074b06774\",\"venue\":\"RSS 2020\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51126291\",\"name\":\"Priyanka Mandikal\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"66d6f22f1df3113ff93a8d08c0aa2f199cb4b777\",\"title\":\"Dexterous Robotic Grasping with Object-Centric Visual Affordances\",\"url\":\"https://www.semanticscholar.org/paper/66d6f22f1df3113ff93a8d08c0aa2f199cb4b777\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153652147\",\"name\":\"Jagannath Malik\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9ffc9a0da2a9877ab793b9d0f2f3a9eafd67cc29\",\"title\":\"Test-Time Training for Improved Object Affordance Prediction\",\"url\":\"https://www.semanticscholar.org/paper/9ffc9a0da2a9877ab793b9d0f2f3a9eafd67cc29\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2001.04583\",\"authors\":[{\"authorId\":\"38661780\",\"name\":\"Tushar Nagarajan\"},{\"authorId\":\"48513679\",\"name\":\"Yanghao Li\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR42600.2020.00024\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7d8f6dd70e8c15105e52b5ac4666db7085689939\",\"title\":\"Ego-Topo: Environment Affordances From Egocentric Video\",\"url\":\"https://www.semanticscholar.org/paper/7d8f6dd70e8c15105e52b5ac4666db7085689939\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2008.09241\",\"authors\":[{\"authorId\":\"38661780\",\"name\":\"Tushar Nagarajan\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"7f7f381fe77d1b6b21e10a9c7136a99eb111893e\",\"title\":\"Learning Affordance Landscapes forInteraction Exploration in 3D Environments\",\"url\":\"https://www.semanticscholar.org/paper/7f7f381fe77d1b6b21e10a9c7136a99eb111893e\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2011.13341\",\"authors\":[{\"authorId\":\"1720749879\",\"name\":\"Miao Liu\"},{\"authorId\":\"2812134\",\"name\":\"D. Yang\"},{\"authorId\":\"2655217\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1813796\",\"name\":\"Zhaopeng Cui\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"},{\"authorId\":\"1831081930\",\"name\":\"Siyu Tang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7d1bfeb5084e0a275602fc67fa0ac60269c1719e\",\"title\":\"4D Human Body Capture from Egocentric Video via 3D Scene Grounding\",\"url\":\"https://www.semanticscholar.org/paper/7d1bfeb5084e0a275602fc67fa0ac60269c1719e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.09856\",\"authors\":[{\"authorId\":\"47060433\",\"name\":\"Zhe Cao\"},{\"authorId\":\"30407997\",\"name\":\"Ilija Radosavovic\"},{\"authorId\":\"20615377\",\"name\":\"A. Kanazawa\"},{\"authorId\":\"153652147\",\"name\":\"J. Malik\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"217b100fbee9a50e49583498f46a07f9e3d33016\",\"title\":\"Reconstructing Hand-Object Interactions in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/217b100fbee9a50e49583498f46a07f9e3d33016\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2007.04515\",\"authors\":[{\"authorId\":\"3234247\",\"name\":\"Senthil Purushwalkam\"},{\"authorId\":\"1391076188\",\"name\":\"Tian Ye\"},{\"authorId\":\"47924870\",\"name\":\"Saurabh Gupta\"},{\"authorId\":null,\"name\":\"Abhinav Gupta\"}],\"doi\":\"10.1007/978-3-030-58574-7_16\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9e3a6c70799ee375e4b6035f59236677439c41a5\",\"title\":\"Aligning Videos in Space and Time\",\"url\":\"https://www.semanticscholar.org/paper/9e3a6c70799ee375e4b6035f59236677439c41a5\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1901.10673\",\"authors\":[{\"authorId\":\"2677378\",\"name\":\"Martin Hjelm\"},{\"authorId\":\"2484138\",\"name\":\"C. Ek\"},{\"authorId\":\"40143841\",\"name\":\"R. Detry\"},{\"authorId\":\"1731490\",\"name\":\"D. Kragic\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a6ed433eeaea37ff86e31e012d345dbd31eb2356\",\"title\":\"Invariant Feature Mappings for Generalizing Affordance Understanding Using Regularized Metric Learning\",\"url\":\"https://www.semanticscholar.org/paper/a6ed433eeaea37ff86e31e012d345dbd31eb2356\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1911.10967\",\"authors\":[{\"authorId\":\"1720749879\",\"name\":\"Miao Liu\"},{\"authorId\":\"39578749\",\"name\":\"Siyu Tang\"},{\"authorId\":\"47002659\",\"name\":\"Yanchao Li\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1007/978-3-030-58452-8_41\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"994481d46df92709b61614f5e756e40df4117622\",\"title\":\"Forecasting Human-Object Interaction: Joint Prediction of Motor Attention and Actions in First Person Video\",\"url\":\"https://www.semanticscholar.org/paper/994481d46df92709b61614f5e756e40df4117622\",\"venue\":\"ECCV\",\"year\":2020}],\"corpusId\":54560811,\"doi\":\"10.1109/ICCV.2019.00878\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":3,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"316a16485bf9ad67a6a07888f8e0d24604d96b76\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"H. S. Koppula\"},{\"authorId\":null,\"name\":\"A. Saxena\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Physically grounded spatiotemporal object affordances\",\"url\":\"\",\"venue\":\"ECCV,\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1723948\",\"name\":\"H. Koppula\"},{\"authorId\":\"1681995\",\"name\":\"A. Saxena\"}],\"doi\":\"10.1007/978-3-319-10578-9_54\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"63fe52f7d454f8af57dfe9bc88ac1689595dbbbe\",\"title\":\"Physically Grounded Spatio-temporal Object Affordances\",\"url\":\"https://www.semanticscholar.org/paper/63fe52f7d454f8af57dfe9bc88ac1689595dbbbe\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1704.04749\",\"authors\":[{\"authorId\":\"145882852\",\"name\":\"David Novotn\\u00fd\"},{\"authorId\":\"2295553\",\"name\":\"Diane Larlus\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":\"10.1109/CVPR.2017.306\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4f617bcec8d970453a0b809c7ca78cf716f6eff9\",\"title\":\"AnchorNet: A Weakly Supervised Network to Learn Geometry-Sensitive Features for Semantic Matching\",\"url\":\"https://www.semanticscholar.org/paper/4f617bcec8d970453a0b809c7ca78cf716f6eff9\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7229001\",\"name\":\"Johann Sawatzky\"},{\"authorId\":\"1716023\",\"name\":\"A. Srikantha\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1109/CVPR.2017.552\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e427c8d3c1b616d319c8b5f233e725d4ebfd9768\",\"title\":\"Weakly Supervised Affordance Detection\",\"url\":\"https://www.semanticscholar.org/paper/e427c8d3c1b616d319c8b5f233e725d4ebfd9768\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30457331\",\"name\":\"J. Gibson\"}],\"doi\":\"10.4324/9781315740218\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1054b9480d759485cc4573f16b4537c698ba26d2\",\"title\":\"The Ecological Approach to Visual Perception: Classic Edition\",\"url\":\"https://www.semanticscholar.org/paper/1054b9480d759485cc4573f16b4537c698ba26d2\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145213709\",\"name\":\"Kuan Fang\"},{\"authorId\":\"2015467\",\"name\":\"Te-Lin Wu\"},{\"authorId\":\"143993197\",\"name\":\"D. Yang\"},{\"authorId\":\"1702137\",\"name\":\"S. Savarese\"},{\"authorId\":\"35198686\",\"name\":\"Joseph J. Lim\"}],\"doi\":\"10.1109/CVPR.2018.00228\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4c0d3055decc8a6433918920127512e0fcbc06f0\",\"title\":\"Demo2Vec: Reasoning Object Affordances from Online Videos\",\"url\":\"https://www.semanticscholar.org/paper/4c0d3055decc8a6433918920127512e0fcbc06f0\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1704.05831\",\"authors\":[{\"authorId\":\"144543406\",\"name\":\"R. Villegas\"},{\"authorId\":\"1768964\",\"name\":\"Jimei Yang\"},{\"authorId\":\"8299168\",\"name\":\"Y. Zou\"},{\"authorId\":\"2459821\",\"name\":\"Sungryull Sohn\"},{\"authorId\":\"10668384\",\"name\":\"Xunyu Lin\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f230cacc511b17b491bf3d90015bbbf85b9ef6af\",\"title\":\"Learning to Generate Long-term Future via Hierarchical Prediction\",\"url\":\"https://www.semanticscholar.org/paper/f230cacc511b17b491bf3d90015bbbf85b9ef6af\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":\"1708.00284\",\"authors\":[{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"87068304\",\"name\":\"L. Lee\"},{\"authorId\":\"143716171\",\"name\":\"Wei Dai\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":\"10.1109/ICCV.2017.194\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb911796464b1e01e98c2b3d007a4ef9310272e2\",\"title\":\"Dual Motion GAN for Future-Flow Embedded Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/eb911796464b1e01e98c2b3d007a4ef9310272e2\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"2949240\",\"name\":\"Scott Satkin\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1109/CVPR.2011.5995448\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0e700356dae7a0a54c91567801c8c5f09bdd8c05\",\"title\":\"From 3D scene geometry to human workspace\",\"url\":\"https://www.semanticscholar.org/paper/0e700356dae7a0a54c91567801c8c5f09bdd8c05\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":\"1803.09125\",\"authors\":[{\"authorId\":\"48355461\",\"name\":\"Yifei Huang\"},{\"authorId\":\"3172280\",\"name\":\"Minjie Cai\"},{\"authorId\":\"46947776\",\"name\":\"Zhenqiang Li\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1007/978-3-030-01225-0_46\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"7e236d33dce5d30348aeb494e491a13468133b4e\",\"title\":\"Predicting Gaze in Egocentric Video by Learning Task-dependent Attention Transition\",\"url\":\"https://www.semanticscholar.org/paper/7e236d33dce5d30348aeb494e491a13468133b4e\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2367683\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":\"10.1109/CVPR.2012.6248010\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9e81caf9dd31b893ebbee3970c312619b7eac7bf\",\"title\":\"Detecting activities of daily living in first-person camera views\",\"url\":\"https://www.semanticscholar.org/paper/9e81caf9dd31b893ebbee3970c312619b7eac7bf\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":\"1904.05250\",\"authors\":[{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1742452\",\"name\":\"S. Battiato\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":\"10.1016/j.jvcir.2017.10.004\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b67282a73c79438095799de916bf44ae55f1d310\",\"title\":\"Next-active-object prediction from egocentric videos\",\"url\":\"https://www.semanticscholar.org/paper/b67282a73c79438095799de916bf44ae55f1d310\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743399\",\"name\":\"Claudio Castellini\"},{\"authorId\":\"2087226\",\"name\":\"T. Tommasi\"},{\"authorId\":\"2600472\",\"name\":\"Nicoletta Noceti\"},{\"authorId\":\"1712692\",\"name\":\"F. Odone\"},{\"authorId\":\"3033284\",\"name\":\"B. Caputo\"}],\"doi\":\"10.1109/TAMD.2011.2106782\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5586dc017702769c8fcc30bf04500dbb19d87570\",\"title\":\"Using Object Affordances to Improve Object Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5586dc017702769c8fcc30bf04500dbb19d87570\",\"venue\":\"IEEE Transactions on Autonomous Mental Development\",\"year\":2011},{\"arxivId\":\"1804.03080\",\"authors\":[{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1109/CVPR.2017.359\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"603c216e83324ca2f7b63c0e6c5b45a845932531\",\"title\":\"Binge Watching: Scaling Affordance Learning from Sitcoms\",\"url\":\"https://www.semanticscholar.org/paper/603c216e83324ca2f7b63c0e6c5b45a845932531\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71799216\",\"name\":\"J. Kilner\"},{\"authorId\":\"49847212\",\"name\":\"A. Neal\"},{\"authorId\":\"2214204\",\"name\":\"N. Weiskopf\"},{\"authorId\":\"1737497\",\"name\":\"Karl J. Friston\"},{\"authorId\":\"145366142\",\"name\":\"C. Frith\"}],\"doi\":\"10.1523/JNEUROSCI.2668-09.2009\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8e60c17cfca71cc72d623140b7388c8dc45ea02d\",\"title\":\"Evidence of Mirror Neurons in Human Inferior Frontal Gyrus\",\"url\":\"https://www.semanticscholar.org/paper/8e60c17cfca71cc72d623140b7388c8dc45ea02d\",\"venue\":\"The Journal of Neuroscience\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1704879\",\"name\":\"H. Kjellstr\\u00f6m\"},{\"authorId\":\"143881914\",\"name\":\"J. Romero\"},{\"authorId\":\"1731490\",\"name\":\"D. Kragic\"}],\"doi\":\"10.1016/j.cviu.2010.08.002\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e60545a2db405c900d86b3c72068cb2e44fa252d\",\"title\":\"Visual object-action recognition: Inferring object affordances from human demonstration\",\"url\":\"https://www.semanticscholar.org/paper/e60545a2db405c900d86b3c72068cb2e44fa252d\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2011},{\"arxivId\":\"1609.02612\",\"authors\":[{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"2367683\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.13016/M26GIH-TNYZ\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ee091ccf24c4f053c5c3dfbefe4a7975ed3447c1\",\"title\":\"Generating Videos with Scene Dynamics\",\"url\":\"https://www.semanticscholar.org/paper/ee091ccf24c4f053c5c3dfbefe4a7975ed3447c1\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1511.05440\",\"authors\":[{\"authorId\":\"143949035\",\"name\":\"Micha\\u00ebl Mathieu\"},{\"authorId\":\"2341378\",\"name\":\"C. Couprie\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"17fa1c2a24ba8f731c8b21f1244463bc4b465681\",\"title\":\"Deep multi-scale video prediction beyond mean square error\",\"url\":\"https://www.semanticscholar.org/paper/17fa1c2a24ba8f731c8b21f1244463bc4b465681\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":\"1707.02850\",\"authors\":[{\"authorId\":\"7229001\",\"name\":\"Johann Sawatzky\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1109/ICCVW.2017.164\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2298e44d71c34eff9c9e3406b0de574d60f79dd2\",\"title\":\"Adaptive Binarization for Weakly Supervised Affordance Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/2298e44d71c34eff9c9e3406b0de574d60f79dd2\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":\"1604.03605\",\"authors\":[{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"},{\"authorId\":\"152627906\",\"name\":\"T. Judd\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"}],\"doi\":\"10.1109/TPAMI.2018.2815601\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bfdf3431ff5182b585b3b0c11fa8cbfc13a6bde4\",\"title\":\"What Do Different Evaluation Metrics Tell Us About Saliency Models?\",\"url\":\"https://www.semanticscholar.org/paper/bfdf3431ff5182b585b3b0c11fa8cbfc13a6bde4\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":\"1604.04842\",\"authors\":[{\"authorId\":\"3197570\",\"name\":\"Chao-Yeh Chen\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1007/s11263-016-0958-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5d0584075807741798055af1b6711475babc4315\",\"title\":\"Subjects and Their Objects: Localizing Interactees for a Person-Centric View of Importance\",\"url\":\"https://www.semanticscholar.org/paper/5d0584075807741798055af1b6711475babc4315\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":\"1705.00053\",\"authors\":[{\"authorId\":\"143928130\",\"name\":\"J. Walker\"},{\"authorId\":\"35789996\",\"name\":\"Kenneth Marino\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1109/ICCV.2017.361\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3df8cc0384814c3fb05c44e494ced947a7d43f36\",\"title\":\"The Pose Knows: Video Forecasting by Generating Pose Futures\",\"url\":\"https://www.semanticscholar.org/paper/3df8cc0384814c3fb05c44e494ced947a7d43f36\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1412.6806\",\"authors\":[{\"authorId\":\"2060551\",\"name\":\"Jost Tobias Springenberg\"},{\"authorId\":\"2841331\",\"name\":\"A. Dosovitskiy\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"},{\"authorId\":\"3137672\",\"name\":\"Martin A. Riedmiller\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f84a81f431b18a78bd97f59ed4b9d8eda390970\",\"title\":\"Striving for Simplicity: The All Convolutional Net\",\"url\":\"https://www.semanticscholar.org/paper/0f84a81f431b18a78bd97f59ed4b9d8eda390970\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1607.02586\",\"authors\":[{\"authorId\":\"3222730\",\"name\":\"Tianfan Xue\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"18555073\",\"name\":\"K. Bouman\"},{\"authorId\":\"36668046\",\"name\":\"B. Freeman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"397e9b56e46d3cc34af1525493e597facb104570\",\"title\":\"Visual Dynamics: Probabilistic Future Frame Synthesis via Cross Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/397e9b56e46d3cc34af1525493e597facb104570\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145089978\",\"name\":\"D. Damen\"},{\"authorId\":\"3067867\",\"name\":\"T. Leelasawassuk\"},{\"authorId\":\"2356868\",\"name\":\"Osian Haines\"},{\"authorId\":\"3336943\",\"name\":\"A. Calway\"},{\"authorId\":\"1398236231\",\"name\":\"W. Mayol-Cuevas\"}],\"doi\":\"10.5244/C.28.30\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6d37a63088d0f296b3dc5f587944cd3c65d1e52e\",\"title\":\"You-Do, I-Learn: Discovering Task Relevant Objects and their Modes of Interaction from Multi-User Egocentric Video\",\"url\":\"https://www.semanticscholar.org/paper/6d37a63088d0f296b3dc5f587944cd3c65d1e52e\",\"venue\":\"BMVC\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38916673\",\"name\":\"B. Yao\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2010.5540234\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"50499aa9af9b4be0f5ef3ffbdd24299f3c402586\",\"title\":\"Grouplet: A structured image representation for recognizing human and object interactions\",\"url\":\"https://www.semanticscholar.org/paper/50499aa9af9b4be0f5ef3ffbdd24299f3c402586\",\"venue\":\"2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition\",\"year\":2010},{\"arxivId\":\"1210.1207\",\"authors\":[{\"authorId\":\"1723948\",\"name\":\"H. Koppula\"},{\"authorId\":\"1996326\",\"name\":\"Rudhir Gupta\"},{\"authorId\":\"1681995\",\"name\":\"A. Saxena\"}],\"doi\":\"10.1177/0278364913478446\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e45cd7ec5fb4a4d6c51e0a56feb7feba69e6066f\",\"title\":\"Learning human activities and object affordances from RGB-D videos\",\"url\":\"https://www.semanticscholar.org/paper/e45cd7ec5fb4a4d6c51e0a56feb7feba69e6066f\",\"venue\":\"Int. J. Robotics Res.\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145767346\",\"name\":\"Tucker Hermans\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"},{\"authorId\":\"1688328\",\"name\":\"A. Bobick\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5502dfe47ac26e60e0fb25fc0f810cae6f5173c0\",\"title\":\"Affordance Prediction via Learned Object Attributes\",\"url\":\"https://www.semanticscholar.org/paper/5502dfe47ac26e60e0fb25fc0f810cae6f5173c0\",\"venue\":\"\",\"year\":2011},{\"arxivId\":\"1712.07576\",\"authors\":[{\"authorId\":\"8551209\",\"name\":\"Ching-Yao Chuang\"},{\"authorId\":\"22133106\",\"name\":\"Jiaman Li\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":\"10.1109/CVPR.2018.00108\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cfa58662750d752ed96184c9fde90150ec89d234\",\"title\":\"Learning to Act Properly: Predicting and Explaining Affordances from Images\",\"url\":\"https://www.semanticscholar.org/paper/cfa58662750d752ed96184c9fde90150ec89d234\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1610.00696\",\"authors\":[{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":\"10.1109/ICRA.2017.7989324\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8f92b4ea04758df2acfb49bd46a4cde923c3ddcb\",\"title\":\"Deep visual foresight for planning robot motion\",\"url\":\"https://www.semanticscholar.org/paper/8f92b4ea04758df2acfb49bd46a4cde923c3ddcb\",\"venue\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/TPAMI.2009.83\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3a8da6accff92f915c1b8ac26d8176308c425b61\",\"title\":\"Observing Human-Object Interactions: Using Spatial and Functional Compatibility for Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3a8da6accff92f915c1b8ac26d8176308c425b61\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2009},{\"arxivId\":\"1512.04150\",\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"2677488\",\"name\":\"\\u00c0gata Lapedriza\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/CVPR.2016.319\",\"intent\":[\"methodology\",\"result\"],\"isInfluential\":false,\"paperId\":\"31f9eb39d840821979e5df9f34a6e92dd9c879f2\",\"title\":\"Learning Deep Features for Discriminative Localization\",\"url\":\"https://www.semanticscholar.org/paper/31f9eb39d840821979e5df9f34a6e92dd9c879f2\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1704.02787\",\"authors\":[{\"authorId\":\"3418004\",\"name\":\"Spyridon Thermos\"},{\"authorId\":\"33961149\",\"name\":\"G. Papadopoulos\"},{\"authorId\":\"1747572\",\"name\":\"P. Daras\"},{\"authorId\":\"1688852\",\"name\":\"G. Potamianos\"}],\"doi\":\"10.1109/CVPR.2017.13\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a5ee92784bd38aee592cbd566844f3ac42f4f325\",\"title\":\"Deep Affordance-Grounded Sensorimotor Object Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a5ee92784bd38aee592cbd566844f3ac42f4f325\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145062693\",\"name\":\"Anh Nguyen\"},{\"authorId\":\"1704541\",\"name\":\"Dimitrios Kanoulas\"},{\"authorId\":\"1745158\",\"name\":\"D. Caldwell\"},{\"authorId\":\"145887349\",\"name\":\"N. Tsagarakis\"}],\"doi\":\"10.1109/IROS.2016.7759429\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"98738590fa191b9bb6aae2618e8e33cea39100b9\",\"title\":\"Detecting object affordances with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/98738590fa191b9bb6aae2618e8e33cea39100b9\",\"venue\":\"2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145551629\",\"name\":\"H. Grabner\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2011.5995327\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"1e56890e7300090691d770270ccb2ce96ab0cac9\",\"title\":\"What makes a chair a chair?\",\"url\":\"https://www.semanticscholar.org/paper/1e56890e7300090691d770270ccb2ce96ab0cac9\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":\"1804.02748\",\"authors\":[{\"authorId\":\"145089978\",\"name\":\"D. Damen\"},{\"authorId\":\"28798386\",\"name\":\"H. Doughty\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"12387007\",\"name\":\"Evangelos Kazakos\"},{\"authorId\":\"3420479\",\"name\":\"D. Moltisanti\"},{\"authorId\":\"47077615\",\"name\":\"J. Munro\"},{\"authorId\":\"2682004\",\"name\":\"T. Perrett\"},{\"authorId\":\"50065546\",\"name\":\"W. Price\"},{\"authorId\":\"145032628\",\"name\":\"Michael Wray\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"fc50c9392fd23b6c88915177c6ae904a498aacea\",\"title\":\"Scaling Egocentric Vision: The EPIC-KITCHENS Dataset\",\"url\":\"https://www.semanticscholar.org/paper/fc50c9392fd23b6c88915177c6ae904a498aacea\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1605.01679\",\"authors\":[{\"authorId\":\"1974383\",\"name\":\"Nicholas Rhinehart\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"}],\"doi\":\"10.1109/CVPR.2016.69\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8f38d907b60602c79a3368e96e54cd5c14cdd84f\",\"title\":\"Learning Action Maps of Large Environments via First-Person Vision\",\"url\":\"https://www.semanticscholar.org/paper/8f38d907b60602c79a3368e96e54cd5c14cdd84f\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145149308\",\"name\":\"A. Roy\"},{\"authorId\":\"143856428\",\"name\":\"S. Todorovic\"}],\"doi\":\"10.1007/978-3-319-46493-0_12\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"bb6f922cc6f94beacc93aead7af53e9bcb9fe3b4\",\"title\":\"A Multi-scale CNN for Affordance Segmentation in RGB Images\",\"url\":\"https://www.semanticscholar.org/paper/bb6f922cc6f94beacc93aead7af53e9bcb9fe3b4\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1808.07784\",\"authors\":[{\"authorId\":\"144348441\",\"name\":\"Dinesh Jayaraman\"},{\"authorId\":\"27535721\",\"name\":\"Frederik Ebert\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"973e116b2b2949fdb8c533a8d84ddd811c0920cf\",\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"url\":\"https://www.semanticscholar.org/paper/973e116b2b2949fdb8c533a8d84ddd811c0920cf\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2672448\",\"name\":\"Yixin Zhu\"},{\"authorId\":\"2956458\",\"name\":\"Chenfanfu Jiang\"},{\"authorId\":\"1757665\",\"name\":\"Y. Zhao\"},{\"authorId\":\"1750924\",\"name\":\"Demetri Terzopoulos\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/CVPR.2016.415\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b1642dd229794902704a6234662e5071b1684ff2\",\"title\":\"Inferring Forces and Learning Human Utilities from Videos\",\"url\":\"https://www.semanticscholar.org/paper/b1642dd229794902704a6234662e5071b1684ff2\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49588480\",\"name\":\"A. Myers\"},{\"authorId\":\"1756655\",\"name\":\"C. L. Teo\"},{\"authorId\":\"1759899\",\"name\":\"C. Ferm\\u00fcller\"},{\"authorId\":\"1697493\",\"name\":\"Y. Aloimonos\"}],\"doi\":\"10.1109/ICRA.2015.7139369\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0458cec30079a53a2b7726a14f5dd826b9b39bfd\",\"title\":\"Affordance detection of tool parts from geometric features\",\"url\":\"https://www.semanticscholar.org/paper/0458cec30079a53a2b7726a14f5dd826b9b39bfd\",\"venue\":\"2015 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145062693\",\"name\":\"Anh Nguyen\"},{\"authorId\":\"1704541\",\"name\":\"Dimitrios Kanoulas\"},{\"authorId\":\"1745158\",\"name\":\"D. Caldwell\"},{\"authorId\":\"145887349\",\"name\":\"N. Tsagarakis\"}],\"doi\":\"10.1109/IROS.2017.8206484\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c375868e395bbfe1a56267f7604a9039cc07729e\",\"title\":\"Object-based affordances detection with Convolutional Neural Networks and dense Conditional Random Fields\",\"url\":\"https://www.semanticscholar.org/paper/c375868e395bbfe1a56267f7604a9039cc07729e\",\"venue\":\"2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2017},{\"arxivId\":\"1610.01563\",\"authors\":[{\"authorId\":\"2997408\",\"name\":\"Matthias K\\u00fcmmerer\"},{\"authorId\":\"49737748\",\"name\":\"Thomas S. A. Wallis\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d160d375a7c187dfe10c110e9e733f36accb87e6\",\"title\":\"DeepGaze II: Reading fixations from deep features trained on object recognition\",\"url\":\"https://www.semanticscholar.org/paper/d160d375a7c187dfe10c110e9e733f36accb87e6\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1701.01081\",\"authors\":[{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"},{\"authorId\":\"1399086207\",\"name\":\"C. Canton-Ferrer\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"},{\"authorId\":\"147166602\",\"name\":\"J. Torres\"},{\"authorId\":\"2470219\",\"name\":\"E. Sayrol\"},{\"authorId\":\"3100480\",\"name\":\"Xavier Giro-i-Nieto\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"258fad95e709b6d0572ae6cc99efbbb14d32bdf2\",\"title\":\"SalGAN: Visual Saliency Prediction with Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/258fad95e709b6d0572ae6cc99efbbb14d32bdf2\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/CVPR.2017.319\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d2892f82a89bfc81f9924adb8bd070fe007adf7\",\"title\":\"Generating the Future with Adversarial Transformers\",\"url\":\"https://www.semanticscholar.org/paper/6d2892f82a89bfc81f9924adb8bd070fe007adf7\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/CVPR.2007.383331\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f2363f4d5027b10954e1b3124a31218cd9199bab\",\"title\":\"Objects in Action: An Approach for Combining Action Understanding and Object Perception\",\"url\":\"https://www.semanticscholar.org/paper/f2363f4d5027b10954e1b3124a31218cd9199bab\",\"venue\":\"2007 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2007},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1502.04681\",\"authors\":[{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"2711409\",\"name\":\"Elman Mansimov\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"title\":\"Unsupervised Learning of Video Representations using LSTMs\",\"url\":\"https://www.semanticscholar.org/paper/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1723948\",\"name\":\"H. Koppula\"},{\"authorId\":\"1681995\",\"name\":\"A. Saxena\"}],\"doi\":\"10.15607/RSS.2013.IX.006\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e6907faab99d8304e9dc5baf05d5e5aca28737a1\",\"title\":\"Anticipating Human Activities using Object Affordances for Reactive Robotic Response\",\"url\":\"https://www.semanticscholar.org/paper/e6907faab99d8304e9dc5baf05d5e5aca28737a1\",\"venue\":\"Robotics: Science and Systems\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1162/neco.1997.9.8.1735\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"title\":\"Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"venue\":\"Neural Computation\",\"year\":1997},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"}],\"doi\":\"10.1007/978-3-319-10584-0_32\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fdfedec1341bdd2f0df6cc6f987d867f7173191c\",\"title\":\"Action-Reaction: Forecasting the Dynamics of Human Interaction\",\"url\":\"https://www.semanticscholar.org/paper/fdfedec1341bdd2f0df6cc6f987d867f7173191c\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1786435\",\"name\":\"David F. Fouhey\"},{\"authorId\":\"1792719\",\"name\":\"Vincent Delaitre\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"}],\"doi\":\"10.1007/s11263-014-0710-z\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf6adca17eb4b9d26de29f10f2be20bcf8e522ee\",\"title\":\"People Watching: Human Actions as a Cue for Single View Geometry\",\"url\":\"https://www.semanticscholar.org/paper/cf6adca17eb4b9d26de29f10f2be20bcf8e522ee\",\"venue\":\"International Journal of Computer Vision\",\"year\":2014},{\"arxivId\":\"1702.02738\",\"authors\":[{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1388317459\",\"name\":\"S. Lacoste-Julien\"}],\"doi\":\"10.1109/ICCV.2017.234\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"993f0793ca7217e03afbd29346d03c01109acc49\",\"title\":\"Joint Discovery of Object States and Manipulation Actions\",\"url\":\"https://www.semanticscholar.org/paper/993f0793ca7217e03afbd29346d03c01109acc49\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1709.07326\",\"authors\":[{\"authorId\":\"3354627\",\"name\":\"Thanh-Toan Do\"},{\"authorId\":null,\"name\":\"Anh Nguyen\"},{\"authorId\":\"93622602\",\"name\":\"Ian Reid\"},{\"authorId\":\"1745158\",\"name\":\"D. Caldwell\"},{\"authorId\":\"145887349\",\"name\":\"N. Tsagarakis\"}],\"doi\":\"10.1109/ICRA.2018.8460902\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5d3b74d0702bbdca96f326d2d0ba96349f5c42a6\",\"title\":\"AffordanceNet: An End-to-End Deep Learning Approach for Object Affordance Detection\",\"url\":\"https://www.semanticscholar.org/paper/5d3b74d0702bbdca96f326d2d0ba96349f5c42a6\",\"venue\":\"2018 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2018},{\"arxivId\":\"1511.07122\",\"authors\":[{\"authorId\":\"1807197\",\"name\":\"F. Yu\"},{\"authorId\":\"145231047\",\"name\":\"V. Koltun\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7f5fc84819c0cf94b771fe15141f65b123f7b8ec\",\"title\":\"Multi-Scale Context Aggregation by Dilated Convolutions\",\"url\":\"https://www.semanticscholar.org/paper/7f5fc84819c0cf94b771fe15141f65b123f7b8ec\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144489175\",\"name\":\"Y. Zhou\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"48043335\",\"name\":\"R. Hong\"},{\"authorId\":\"1795291\",\"name\":\"X. Yang\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/CVPR.2016.210\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7de1d463fef3c63cb228f5b4a6a72e62f66630e6\",\"title\":\"Cascaded Interactional Targeting Network for Egocentric Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/7de1d463fef3c63cb228f5b4a6a72e62f66630e6\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1504.08023\",\"authors\":[{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"2367683\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0fb3b63090f95af97723efe565893eb25ea9188c\",\"title\":\"Anticipating the future by watching unlabeled video\",\"url\":\"https://www.semanticscholar.org/paper/0fb3b63090f95af97723efe565893eb25ea9188c\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144421225\",\"name\":\"M. Stark\"},{\"authorId\":\"153143236\",\"name\":\"P. Lies\"},{\"authorId\":\"1682587\",\"name\":\"M. Zillich\"},{\"authorId\":\"1688492\",\"name\":\"J. Wyatt\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1007/978-3-540-79547-6_42\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5fd84b516af5c06102e7c58a4e48a580417293e9\",\"title\":\"Functional Object Class Detection Based on Learned Affordance Cues\",\"url\":\"https://www.semanticscholar.org/paper/5fd84b516af5c06102e7c58a4e48a580417293e9\",\"venue\":\"ICVS\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2672448\",\"name\":\"Yixin Zhu\"},{\"authorId\":\"1757665\",\"name\":\"Y. Zhao\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/CVPR.2015.7298903\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3de78c766cfceaceca7ee3932304d2478f98107b\",\"title\":\"Understanding tools: Task-oriented object modeling, learning and recognition\",\"url\":\"https://www.semanticscholar.org/paper/3de78c766cfceaceca7ee3932304d2478f98107b\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Kuan Fang\"},{\"authorId\":null,\"name\":\"Te-Lin Wu\"},{\"authorId\":null,\"name\":\"Daniel Yang\"},{\"authorId\":null,\"name\":\"Silvio Savarese\"},{\"authorId\":null,\"name\":\"Joseph J Lim\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Demo 2 vec : Reasoning object affordances from online videos Unsuper - vised learning for physical interaction through video prediction\",\"url\":\"\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38916673\",\"name\":\"B. Yao\"},{\"authorId\":\"2262500\",\"name\":\"Jiayuan Ma\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/ICCV.2013.312\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"22f2f77120cd28e9b2516179239380adef46b1be\",\"title\":\"Discovering Object Functionality\",\"url\":\"https://www.semanticscholar.org/paper/22f2f77120cd28e9b2516179239380adef46b1be\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":\"1412.6604\",\"authors\":[{\"authorId\":\"1706809\",\"name\":\"Marc'Aurelio Ranzato\"},{\"authorId\":\"3149531\",\"name\":\"Arthur Szlam\"},{\"authorId\":\"143627859\",\"name\":\"Joan Bruna\"},{\"authorId\":\"143949035\",\"name\":\"Micha\\u00ebl Mathieu\"},{\"authorId\":\"2939803\",\"name\":\"Ronan Collobert\"},{\"authorId\":\"3295092\",\"name\":\"S. Chopra\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"355f98e4827a1b6ad3f29d07ea2bcf9ad078295c\",\"title\":\"Video (language) modeling: a baseline for generative models of natural videos\",\"url\":\"https://www.semanticscholar.org/paper/355f98e4827a1b6ad3f29d07ea2bcf9ad078295c\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1974383\",\"name\":\"Nicholas Rhinehart\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"}],\"doi\":\"10.1109/TPAMI.2018.2873794\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"008085275d5c1b7f0cc2631c9eae3d015ed244ca\",\"title\":\"First-Person Activity Forecasting from Video with Online Inverse Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/008085275d5c1b7f0cc2631c9eae3d015ed244ca\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":\"1609.01064\",\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/ICPR.2016.7900174\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"57e143c96a41ba81d9d59120a1cd0dc04905d3f1\",\"title\":\"A deep multi-level network for saliency prediction\",\"url\":\"https://www.semanticscholar.org/paper/57e143c96a41ba81d9d59120a1cd0dc04905d3f1\",\"venue\":\"2016 23rd International Conference on Pattern Recognition (ICPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144872229\",\"name\":\"P. Hanrahan\"}],\"doi\":\"10.1145/2661229.2661230\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1817e2285bfa850d01d92b65b0fd2e1525c727c9\",\"title\":\"SceneGrok: inferring action maps in 3D environments\",\"url\":\"https://www.semanticscholar.org/paper/1817e2285bfa850d01d92b65b0fd2e1525c727c9\",\"venue\":\"ACM Trans. Graph.\",\"year\":2014},{\"arxivId\":\"1710.05268\",\"authors\":[{\"authorId\":\"27535721\",\"name\":\"Frederik Ebert\"},{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"},{\"authorId\":\"49250083\",\"name\":\"Alex X. Lee\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cf18287e79b1fd73cd333fc914bb24c00a537f4c\",\"title\":\"Self-Supervised Visual Planning with Temporal Skip Connections\",\"url\":\"https://www.semanticscholar.org/paper/cf18287e79b1fd73cd333fc914bb24c00a537f4c\",\"venue\":\"CoRL\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1792719\",\"name\":\"Vincent Delaitre\"},{\"authorId\":\"1786435\",\"name\":\"David F. Fouhey\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1007/978-3-642-33783-3_21\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b85674090c2d15ce3221c6d0c4c8a6d8f7e77e4d\",\"title\":\"Scene Semantics from Long-Term Observation of People\",\"url\":\"https://www.semanticscholar.org/paper/b85674090c2d15ce3221c6d0c4c8a6d8f7e77e4d\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":\"1605.07157\",\"authors\":[{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f110cfdbe9ded7a384bcf5c0d56e536bd275a7eb\",\"title\":\"Unsupervised Learning for Physical Interaction through Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/f110cfdbe9ded7a384bcf5c0d56e536bd275a7eb\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1507.08750\",\"authors\":[{\"authorId\":\"2894414\",\"name\":\"Junhyuk Oh\"},{\"authorId\":\"1955964\",\"name\":\"Xiaoxiao Guo\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"},{\"authorId\":\"46328485\",\"name\":\"R. L. Lewis\"},{\"authorId\":\"1699868\",\"name\":\"Satinder Singh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e4257bc131c36504a04382290cbc27ca8bb27813\",\"title\":\"Action-Conditional Video Prediction using Deep Networks in Atari Games\",\"url\":\"https://www.semanticscholar.org/paper/e4257bc131c36504a04382290cbc27ca8bb27813\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1807.06775\",\"authors\":[{\"authorId\":\"145867132\",\"name\":\"Mohammed Hassanin\"},{\"authorId\":\"144812766\",\"name\":\"Salman Khan\"},{\"authorId\":\"2312383\",\"name\":\"M. Tahtali\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"81d327ec41c67728b15438bca86d10b72de1d88f\",\"title\":\"Visual Affordance and Function Understanding: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/81d327ec41c67728b15438bca86d10b72de1d88f\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35100058\",\"name\":\"R. R. Selvaraju\"},{\"authorId\":\"144354133\",\"name\":\"Michael Cogswell\"},{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1109/ICCV.2017.74\",\"intent\":[\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"24120b948f39834e7860271992464eb4a575501b\",\"title\":\"Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization\",\"url\":\"https://www.semanticscholar.org/paper/24120b948f39834e7860271992464eb4a575501b\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017}],\"title\":\"Grounded Human-Object Interaction Hotspots From Video\",\"topics\":[{\"topic\":\"Java HotSpot Virtual Machine\",\"topicId\":\"778543\",\"url\":\"https://www.semanticscholar.org/topic/778543\"},{\"topic\":\"Interaction\",\"topicId\":\"72\",\"url\":\"https://www.semanticscholar.org/topic/72\"},{\"topic\":\"Social affordance\",\"topicId\":\"2246751\",\"url\":\"https://www.semanticscholar.org/topic/2246751\"},{\"topic\":\"Requirement\",\"topicId\":\"136\",\"url\":\"https://www.semanticscholar.org/topic/136\"},{\"topic\":\"Virtual camera system\",\"topicId\":\"493894\",\"url\":\"https://www.semanticscholar.org/topic/493894\"},{\"topic\":\"Supervised learning\",\"topicId\":\"8357\",\"url\":\"https://www.semanticscholar.org/topic/8357\"}],\"url\":\"https://www.semanticscholar.org/paper/316a16485bf9ad67a6a07888f8e0d24604d96b76\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019}\n"