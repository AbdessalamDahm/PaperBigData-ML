"{\"abstract\":\"Free-form video inpainting is a very challenging task that could be widely used for video editing such as text removal. Existing patch-based methods could not handle non-repetitive structures such as faces, while directly applying image-based inpainting models to videos will result in temporal inconsistency (see this https://www.youtube.com/watch?v=BuTYfo4bO2I&list=PLnEeMdoBDCISRm0EZYFcQuaJ5ITUaaEIb&index=1). In this paper, we introduce a deep learning based free-form video inpainting model, with proposed 3D gated convolutions to tackle the uncertainty of free-form masks and a novel Temporal PatchGAN loss to enhance temporal consistency. In addition, we collect videos and design a free-form mask generation algorithm to build the free-form video inpainting (FVI) dataset for training and evaluation of video inpainting models. We demonstrate the benefits of these components and experiments on both the FaceForensics and our FVI dataset suggest that our method is superior to existing ones. Related source code, full-resolution result videos and the FVI dataset could be found on Github: https://github.com/amjltc295/Free-Form-Video-Inpainting\",\"arxivId\":\"1904.10247\",\"authors\":[{\"authorId\":\"48133807\",\"name\":\"Y. Chang\",\"url\":\"https://www.semanticscholar.org/author/48133807\"},{\"authorId\":\"143822897\",\"name\":\"Zhe Yu Liu\",\"url\":\"https://www.semanticscholar.org/author/143822897\"},{\"authorId\":\"3403825\",\"name\":\"Kuan-Ying Lee\",\"url\":\"https://www.semanticscholar.org/author/3403825\"},{\"authorId\":\"31871157\",\"name\":\"Winston Hsu\",\"url\":\"https://www.semanticscholar.org/author/31871157\"}],\"citationVelocity\":10,\"citations\":[{\"arxivId\":\"2007.10247\",\"authors\":[{\"authorId\":\"5764695\",\"name\":\"Y. Zeng\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"41079034\",\"name\":\"Hong-Yang Chao\"}],\"doi\":\"10.1007/978-3-030-58517-4_31\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f7f89feee68b6856c0a980a5888b42d18231be07\",\"title\":\"Learning Joint Spatial-Temporal Transformations for Video Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/f7f89feee68b6856c0a980a5888b42d18231be07\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2484223\",\"name\":\"Yuan-Ting Hu\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2482072\",\"name\":\"Nicolas Ballas\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1007/978-3-030-58583-9_3\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e4ae2e88c470975209769abe12c895dcf0b534d5\",\"title\":\"Proposal-Based Video Completion\",\"url\":\"https://www.semanticscholar.org/paper/e4ae2e88c470975209769abe12c895dcf0b534d5\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3406363\",\"name\":\"Michal U\\u0159i\\u010d\\u00e1\\u0159\"},{\"authorId\":\"69039029\",\"name\":\"J. Uli\\u010dn\\u00fd\"},{\"authorId\":\"66443522\",\"name\":\"Ganesh Sistu\"},{\"authorId\":\"38656643\",\"name\":\"H. Rashed\"},{\"authorId\":\"2088180\",\"name\":\"P. Kr\\u00edzek\"},{\"authorId\":\"2687885\",\"name\":\"D. Hurych\"},{\"authorId\":\"40995651\",\"name\":\"Anton\\u00edn Vobeck\\u00fd\"},{\"authorId\":\"2601522\",\"name\":\"S. Yogamani\"}],\"doi\":\"10.1109/ICCVW.2019.00526\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fdbb1d4fb265f5a32f9d81917ba1a37911808871\",\"title\":\"Desoiling Dataset: Restoring Soiled Areas on Automotive Fisheye Cameras\",\"url\":\"https://www.semanticscholar.org/paper/fdbb1d4fb265f5a32f9d81917ba1a37911808871\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1907.01131\",\"authors\":[{\"authorId\":\"48133807\",\"name\":\"Y. Chang\"},{\"authorId\":\"47781274\",\"name\":\"Z. Liu\"},{\"authorId\":\"3403825\",\"name\":\"Kuan-Ying Lee\"},{\"authorId\":\"31871157\",\"name\":\"Winston Hsu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"fe59654dd44dfe5f216587ccbc089c5a0ec1461a\",\"title\":\"Learnable Gated Temporal Shift Module for Free-form Video Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/fe59654dd44dfe5f216587ccbc089c5a0ec1461a\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2885713\",\"name\":\"Nianyi Wang\"},{\"authorId\":\"11230276\",\"name\":\"Weilan Wang\"},{\"authorId\":\"50105467\",\"name\":\"Wenjin Hu\"},{\"authorId\":\"144408124\",\"name\":\"A. Fenster\"},{\"authorId\":\"47320097\",\"name\":\"Shuo Li\"}],\"doi\":\"10.1007/978-3-030-60633-6_12\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ef25f8627f28428b03ba0a3023cac758d6ada12f\",\"title\":\"Damage Sensitive and Original Restoration Driven Thanka Mural Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/ef25f8627f28428b03ba0a3023cac758d6ada12f\",\"venue\":\"PRCV\",\"year\":2020},{\"arxivId\":\"2003.10685\",\"authors\":[{\"authorId\":\"143931954\",\"name\":\"M. Shi\"},{\"authorId\":\"49050067\",\"name\":\"Jiaqi Zhang\"},{\"authorId\":\"2999411\",\"name\":\"Shu-Yu Chen\"},{\"authorId\":\"51190170\",\"name\":\"Lin Gao\"},{\"authorId\":\"144891983\",\"name\":\"Yu-Kun Lai\"},{\"authorId\":\"3326435\",\"name\":\"Fang-Lue Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"525d226b9b14fe056e30c8f3261ece7b7eff11f9\",\"title\":\"Deep Line Art Video Colorization with a Few References\",\"url\":\"https://www.semanticscholar.org/paper/525d226b9b14fe056e30c8f3261ece7b7eff11f9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.06476\",\"authors\":[{\"authorId\":\"48133807\",\"name\":\"Y. Chang\"},{\"authorId\":\"3403825\",\"name\":\"Kuan-Ying Lee\"},{\"authorId\":\"145017741\",\"name\":\"Po-Yu Wu\"},{\"authorId\":\"1706104\",\"name\":\"Hung-yi Lee\"},{\"authorId\":\"31871157\",\"name\":\"Winston Hsu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"cc067fbc52333475b1b320de158b9fb219b916fb\",\"title\":\"Deep Long Audio Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/cc067fbc52333475b1b320de158b9fb219b916fb\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3250505\",\"name\":\"Avisek Lahiri\"},{\"authorId\":\"7284555\",\"name\":\"A. Jain\"},{\"authorId\":\"52585867\",\"name\":\"Sanskar Agrawal\"},{\"authorId\":\"144240261\",\"name\":\"P. Mitra\"},{\"authorId\":\"1758797\",\"name\":\"P. Biswas\"}],\"doi\":\"10.1109/CVPR42600.2020.01371\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"55c86c15dd41cbb23f657de01a8a867ce1b7383b\",\"title\":\"Prior Guided GAN Based Semantic Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/55c86c15dd41cbb23f657de01a8a867ce1b7383b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2007.12391\",\"authors\":[{\"authorId\":\"1756108\",\"name\":\"N. Anantrasirichai\"},{\"authorId\":\"2073462\",\"name\":\"D. Bull\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3670d55a696dea9234660149b490e22fb5c2a3a5\",\"title\":\"Artificial Intelligence in the Creative Industries: A Review\",\"url\":\"https://www.semanticscholar.org/paper/3670d55a696dea9234660149b490e22fb5c2a3a5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.05721\",\"authors\":[{\"authorId\":\"100895685\",\"name\":\"Ang Li\"},{\"authorId\":\"145382022\",\"name\":\"Shanshan Zhao\"},{\"authorId\":\"9576855\",\"name\":\"Xingjun Ma\"},{\"authorId\":\"50175298\",\"name\":\"M. Gong\"},{\"authorId\":\"145663352\",\"name\":\"Jianzhong Qi\"},{\"authorId\":\"143758471\",\"name\":\"Rui Zhang\"},{\"authorId\":\"1490934465\",\"name\":\"Dacheng Tao\"},{\"authorId\":\"50278164\",\"name\":\"R. Kotagiri\"}],\"doi\":\"10.1007/978-3-030-58548-8_42\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e198f21b3d052a809d3198ace4de78be32ee843c\",\"title\":\"Short-Term and Long-Term Context Aggregation Network for Video Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/e198f21b3d052a809d3198ace4de78be32ee843c\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49681078\",\"name\":\"L. Wang\"},{\"authorId\":\"3073831\",\"name\":\"Wanchun Chen\"},{\"authorId\":\"1642917405\",\"name\":\"Wenjia Yang\"},{\"authorId\":\"38819886\",\"name\":\"Fangming Bi\"},{\"authorId\":\"1696615\",\"name\":\"F. Yu\"}],\"doi\":\"10.1109/ACCESS.2020.2982224\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cb03cff85876b3719fc9843f5bcf77f38dfa4f4a\",\"title\":\"A State-of-the-Art Review on Image Synthesis With Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/cb03cff85876b3719fc9843f5bcf77f38dfa4f4a\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1911.12588\",\"authors\":[{\"authorId\":\"24282778\",\"name\":\"R. Zhang\"},{\"authorId\":\"39848690\",\"name\":\"Wei Li\"},{\"authorId\":\"49161455\",\"name\":\"P. Wang\"},{\"authorId\":\"51226237\",\"name\":\"Chenye Guan\"},{\"authorId\":\"145791861\",\"name\":\"J. Fang\"},{\"authorId\":null,\"name\":\"Yuhang Song\"},{\"authorId\":\"34331831\",\"name\":\"J. Yu\"},{\"authorId\":\"1748939\",\"name\":\"B. Chen\"},{\"authorId\":\"152261442\",\"name\":\"Wei-wei Xu\"},{\"authorId\":\"38958903\",\"name\":\"Ruigang Yang\"}],\"doi\":\"10.1609/AAAI.V34I07.6982\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a736563e276d74f425222d7bcf7d3641c5cf999b\",\"title\":\"AutoRemover: Automatic Object Removal for Autonomous Driving Videos\",\"url\":\"https://www.semanticscholar.org/paper/a736563e276d74f425222d7bcf7d3641c5cf999b\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24028009\",\"name\":\"Dahun Kim\"},{\"authorId\":\"2262209\",\"name\":\"S. Woo\"},{\"authorId\":\"1576788264\",\"name\":\"Joon-Young Lee\"},{\"authorId\":\"145017149\",\"name\":\"In So Kweon\"}],\"doi\":\"10.1109/TPAMI.2019.2958083\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ab6d2e28f51012b1968b8b460624178d1cf47a5f\",\"title\":\"Recurrent Temporal Aggregation Framework for Deep Video Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/ab6d2e28f51012b1968b8b460624178d1cf47a5f\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":\"2003.07042\",\"authors\":[{\"authorId\":\"1563206364\",\"name\":\"Kaito Imai\"},{\"authorId\":\"2515755\",\"name\":\"T. Miyata\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"960bf5da404f0c689e41a9a841211786aa568221\",\"title\":\"Gated Texture CNN for Efficient and Configurable Image Denoising\",\"url\":\"https://www.semanticscholar.org/paper/960bf5da404f0c689e41a9a841211786aa568221\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.00652\",\"authors\":[{\"authorId\":\"52184822\",\"name\":\"Mucong Ding\"},{\"authorId\":\"3806712\",\"name\":\"C. Daskalakis\"},{\"authorId\":\"34389431\",\"name\":\"S. Feizi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f8e25bd936041b8a4761b958f11515128f55c147\",\"title\":\"When Do Local Discriminators Work? On Subadditivity of Probability Divergences\",\"url\":\"https://www.semanticscholar.org/paper/f8e25bd936041b8a4761b958f11515128f55c147\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47246298\",\"name\":\"Ruixin Liu\"},{\"authorId\":\"151270908\",\"name\":\"Zhenyu Weng\"},{\"authorId\":\"46758870\",\"name\":\"Y. Zhu\"},{\"authorId\":\"103717726\",\"name\":\"Bairong Li\"}],\"doi\":\"10.24963/ijcai.2020/129\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0db83dbdb6825596860ea08cc2ad090410cd335b\",\"title\":\"Temporal Adaptive Alignment Network for Deep Video Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/0db83dbdb6825596860ea08cc2ad090410cd335b\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":\"2009.01835\",\"authors\":[{\"authorId\":\"49281242\",\"name\":\"C. Gao\"},{\"authorId\":\"1873347743\",\"name\":\"Ayush Saraf\"},{\"authorId\":\"50535349\",\"name\":\"J. Huang\"},{\"authorId\":\"2891193\",\"name\":\"Johannes Kopf\"}],\"doi\":\"10.1007/978-3-030-58610-2_42\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"fed1bccd50dd8df173a1c53e50967eae3668b623\",\"title\":\"Flow-edge Guided Video Completion\",\"url\":\"https://www.semanticscholar.org/paper/fed1bccd50dd8df173a1c53e50967eae3668b623\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2003.05383\",\"authors\":[{\"authorId\":\"49417759\",\"name\":\"Y. Lin\"},{\"authorId\":\"46270526\",\"name\":\"Z. Liu\"},{\"authorId\":\"152829351\",\"name\":\"Y. Chen\"},{\"authorId\":null,\"name\":\"Yu-Siang Wang\"},{\"authorId\":\"49923155\",\"name\":\"Hsin-Ying Lee\"},{\"authorId\":\"47558437\",\"name\":\"Yirong Chen\"},{\"authorId\":\"48133807\",\"name\":\"Y. Chang\"},{\"authorId\":\"1716836\",\"name\":\"W. Hsu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"95a309ad99b3a94ee38bfebf40c7af0635687e3d\",\"title\":\"xCos: An Explainable Cosine Metric for Face Verification Task\",\"url\":\"https://www.semanticscholar.org/paper/95a309ad99b3a94ee38bfebf40c7af0635687e3d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48133807\",\"name\":\"Y. Chang\"},{\"authorId\":\"143822897\",\"name\":\"Zhe Yu Liu\"},{\"authorId\":\"3403825\",\"name\":\"Kuan-Ying Lee\"},{\"authorId\":\"1716836\",\"name\":\"W. Hsu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0bd7b15c7ae060eb029490d5b18617977eb28812\",\"title\":\"Learnable Gated Temporal Shift Module for Deep Video Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/0bd7b15c7ae060eb029490d5b18617977eb28812\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2002.04433\",\"authors\":[{\"authorId\":\"40326718\",\"name\":\"Hossein Javidnia\"},{\"authorId\":\"1491819441\",\"name\":\"Franccois Piti'e\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ae806b54bf2e9872607ddbd03727f613ded7c588\",\"title\":\"Background Matting\",\"url\":\"https://www.semanticscholar.org/paper/ae806b54bf2e9872607ddbd03727f613ded7c588\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":128358680,\"doi\":\"10.1109/ICCV.2019.00916\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":3,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"e8705ab4b9626c1ab6442483731fe0371f2234b6\",\"references\":[{\"arxivId\":\"1801.09392\",\"authors\":[{\"authorId\":\"35277013\",\"name\":\"Zhaoyi Yan\"},{\"authorId\":\"21515518\",\"name\":\"X. Li\"},{\"authorId\":\"47628982\",\"name\":\"Mu Li\"},{\"authorId\":\"1724520\",\"name\":\"W. Zuo\"},{\"authorId\":\"145455919\",\"name\":\"S. Shan\"}],\"doi\":\"10.1007/978-3-030-01264-9_1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"904decf94f5495d1488e2bf22e3ed4df500ce4d5\",\"title\":\"Shift-Net: Image Inpainting via Deep Feature Rearrangement\",\"url\":\"https://www.semanticscholar.org/paper/904decf94f5495d1488e2bf22e3ed4df500ce4d5\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1907.01131\",\"authors\":[{\"authorId\":\"48133807\",\"name\":\"Y. Chang\"},{\"authorId\":\"47781274\",\"name\":\"Z. Liu\"},{\"authorId\":\"3403825\",\"name\":\"Kuan-Ying Lee\"},{\"authorId\":\"31871157\",\"name\":\"Winston Hsu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fe59654dd44dfe5f216587ccbc089c5a0ec1461a\",\"title\":\"Learnable Gated Temporal Shift Module for Free-form Video Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/fe59654dd44dfe5f216587ccbc089c5a0ec1461a\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"1503.05528\",\"authors\":[{\"authorId\":\"1902919\",\"name\":\"A. Newson\"},{\"authorId\":\"1713633\",\"name\":\"Andr\\u00e9s Almansa\"},{\"authorId\":\"3284350\",\"name\":\"M. Fradet\"},{\"authorId\":\"1796594\",\"name\":\"Y. Gousseau\"},{\"authorId\":\"144565371\",\"name\":\"P. P\\u00e9rez\"}],\"doi\":\"10.1137/140954933\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a57afd150ab309f868c9030cddfc0fd896f67308\",\"title\":\"Video Inpainting of Complex Scenes\",\"url\":\"https://www.semanticscholar.org/paper/a57afd150ab309f868c9030cddfc0fd896f67308\",\"venue\":\"SIAM J. Imaging Sci.\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"123371831\",\"name\":\"\\u00c0gata Lapedriza\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/TPAMI.2017.2723009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f986968735459e789890f24b6b277b0920a9725d\",\"title\":\"Places: A 10 Million Image Database for Scene Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f986968735459e789890f24b6b277b0920a9725d\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":\"1702.00824\",\"authors\":[{\"authorId\":\"2892780\",\"name\":\"E. Real\"},{\"authorId\":\"1789737\",\"name\":\"Jonathon Shlens\"},{\"authorId\":\"49436220\",\"name\":\"S. Mazzocchi\"},{\"authorId\":\"144680010\",\"name\":\"Xin Pan\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"}],\"doi\":\"10.1109/CVPR.2017.789\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"991544f9333296a7d9e5b9751bca932bb68f54e1\",\"title\":\"YouTube-BoundingBoxes: A Large High-Precision Human-Annotated Data Set for Object Detection in Video\",\"url\":\"https://www.semanticscholar.org/paper/991544f9333296a7d9e5b9751bca932bb68f54e1\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1508.06576\",\"authors\":[{\"authorId\":\"1891828\",\"name\":\"Leon A. Gatys\"},{\"authorId\":\"1746183\",\"name\":\"Alexander S. Ecker\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":\"10.1167/16.12.326\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f37e90c0bd5c4a9619ccfb763c45cb2d84abd3e6\",\"title\":\"A Neural Algorithm of Artistic Style\",\"url\":\"https://www.semanticscholar.org/paper/f37e90c0bd5c4a9619ccfb763c45cb2d84abd3e6\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1811.08383\",\"authors\":[{\"authorId\":\"46698300\",\"name\":\"Ji Lin\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"143840275\",\"name\":\"Song Han\"}],\"doi\":\"10.1109/ICCV.2019.00718\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4bbfd46721c145852e443ae4aad35148b814bf91\",\"title\":\"TSM: Temporal Shift Module for Efficient Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/4bbfd46721c145852e443ae4aad35148b814bf91\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Marcelo Bertalmio\"},{\"authorId\":null,\"name\":\"Guillermo Sapiro\"},{\"authorId\":null,\"name\":\"Vincent Caselles\"},{\"authorId\":null,\"name\":\"Coloma Ballester\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Image inpainting. In Proceedings of the 27th annual conference on Computer graphics and interactive techniques, pages 417\\u2013424\",\"url\":\"\",\"venue\":\"ACM Press/Addison- Wesley Publishing Co.,\",\"year\":2000},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30991253\",\"name\":\"M. Bertalm\\u00edo\"},{\"authorId\":\"1699339\",\"name\":\"G. Sapiro\"},{\"authorId\":\"8004695\",\"name\":\"V. Caselles\"},{\"authorId\":\"34688079\",\"name\":\"C. Ballester\"}],\"doi\":\"10.1145/344779.344972\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4dbe992c46e664d8c4b9c6359dac6e775b9c5b5c\",\"title\":\"Image inpainting\",\"url\":\"https://www.semanticscholar.org/paper/4dbe992c46e664d8c4b9c6359dac6e775b9c5b5c\",\"venue\":\"SIGGRAPH '00\",\"year\":2000},{\"arxivId\":\"1808.06601\",\"authors\":[{\"authorId\":\"2195314\",\"name\":\"T. Wang\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"47062069\",\"name\":\"Guilin Liu\"},{\"authorId\":\"29955511\",\"name\":\"A. Tao\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"},{\"authorId\":\"2301680\",\"name\":\"Bryan Catanzaro\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c5b55f410365bb889c25a9f0354f2b86ec61c4f0\",\"title\":\"Video-to-Video Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/c5b55f410365bb889c25a9f0354f2b86ec61c4f0\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2861627\",\"name\":\"Iddo Drori\"},{\"authorId\":\"1388323541\",\"name\":\"D. Cohen-Or\"},{\"authorId\":\"47620675\",\"name\":\"Y. Yeshurun\"}],\"doi\":\"10.1145/1201775.882267\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6eb28cb2368c5196cb6cc5a144cb3e4593c96db5\",\"title\":\"Fragment-based image completion\",\"url\":\"https://www.semanticscholar.org/paper/6eb28cb2368c5196cb6cc5a144cb3e4593c96db5\",\"venue\":\"SIGGRAPH '03\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743988\",\"name\":\"Yonatan Wexler\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"144611617\",\"name\":\"M. Irani\"}],\"doi\":\"10.1109/TPAMI.2007.60\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3ace907ea90aed1fb4287b78b19a9f65a462d247\",\"title\":\"Space-Time Completion of Video\",\"url\":\"https://www.semanticscholar.org/paper/3ace907ea90aed1fb4287b78b19a9f65a462d247\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2007},{\"arxivId\":\"1604.07379\",\"authors\":[{\"authorId\":\"38236002\",\"name\":\"Deepak Pathak\"},{\"authorId\":\"2562966\",\"name\":\"Philipp Kr\\u00e4henb\\u00fchl\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1109/CVPR.2016.278\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7d0effebfa4bed19b6ba41f3af5b7e5b6890de87\",\"title\":\"Context Encoders: Feature Learning by Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/7d0effebfa4bed19b6ba41f3af5b7e5b6890de87\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2496412\",\"name\":\"Connelly Barnes\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"38824925\",\"name\":\"A. Finkelstein\"},{\"authorId\":\"1976171\",\"name\":\"D. Goldman\"}],\"doi\":\"10.1145/1576246.1531330\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"744293fb92aa3dde3a5001885cf61eb7165eb95b\",\"title\":\"PatchMatch: a randomized correspondence algorithm for structural image editing\",\"url\":\"https://www.semanticscholar.org/paper/744293fb92aa3dde3a5001885cf61eb7165eb95b\",\"venue\":\"ACM Trans. Graph.\",\"year\":2009},{\"arxivId\":\"1803.09179\",\"authors\":[{\"authorId\":\"48971535\",\"name\":\"A. R\\u00f6ssler\"},{\"authorId\":\"34188567\",\"name\":\"D. Cozzolino\"},{\"authorId\":\"1730255\",\"name\":\"L. Verdoliva\"},{\"authorId\":\"145062425\",\"name\":\"C. Riess\"},{\"authorId\":\"34105638\",\"name\":\"Justus Thies\"},{\"authorId\":\"2209612\",\"name\":\"M. Nie\\u00dfner\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b82058b4bf630d33e129ab097b8cacf6cc3d4556\",\"title\":\"FaceForensics: A Large-scale Video Dataset for Forgery Detection in Human Faces\",\"url\":\"https://www.semanticscholar.org/paper/b82058b4bf630d33e129ab097b8cacf6cc3d4556\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1904.06726\",\"authors\":[{\"authorId\":\"48133807\",\"name\":\"Y. Chang\"},{\"authorId\":\"143822897\",\"name\":\"Zhe Yu Liu\"},{\"authorId\":\"1716836\",\"name\":\"W. Hsu\"}],\"doi\":\"10.1109/CVPRW.2019.00229\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"62c6c2efdc2de134a94e78e9a350db74b80ccd00\",\"title\":\"VORNet: Spatio-Temporally Consistent Video Inpainting for Object Removal\",\"url\":\"https://www.semanticscholar.org/paper/62c6c2efdc2de134a94e78e9a350db74b80ccd00\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":\"1809.00461\",\"authors\":[{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":\"2889075\",\"name\":\"L. Yang\"},{\"authorId\":\"7888497\",\"name\":\"Yuchen Fan\"},{\"authorId\":\"47988297\",\"name\":\"Jianchao Yang\"},{\"authorId\":\"84426766\",\"name\":\"Dingcheng Yue\"},{\"authorId\":\"21160992\",\"name\":\"Yuchen Liang\"},{\"authorId\":\"31844147\",\"name\":\"Brian L. Price\"},{\"authorId\":\"145823372\",\"name\":\"S. Cohen\"},{\"authorId\":\"1739208\",\"name\":\"T. Huang\"}],\"doi\":\"10.1007/978-3-030-01228-1_36\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f054fdd7a36b569eae7627cf12a4d81322dea022\",\"title\":\"YouTube-VOS: Sequence-to-Sequence Video Object Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/f054fdd7a36b569eae7627cf12a4d81322dea022\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1801.03924\",\"authors\":[{\"authorId\":\"2844849\",\"name\":\"Richard Zhang\"},{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"39231399\",\"name\":\"O. Wang\"}],\"doi\":\"10.1109/CVPR.2018.00068\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c468bbde6a22d961829e1970e6ad5795e05418d1\",\"title\":\"The Unreasonable Effectiveness of Deep Features as a Perceptual Metric\",\"url\":\"https://www.semanticscholar.org/paper/c468bbde6a22d961829e1970e6ad5795e05418d1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1806.08482\",\"authors\":[{\"authorId\":\"47074942\",\"name\":\"Chuan Wang\"},{\"authorId\":\"3119608\",\"name\":\"Haibin Huang\"},{\"authorId\":\"1763245\",\"name\":\"Xiaoguang Han\"},{\"authorId\":\"48094509\",\"name\":\"J. Wang\"}],\"doi\":\"10.1609/AAAI.V33I01.33015232\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1f8c851b73ccb36a88bea0392d1ace84a79f3d97\",\"title\":\"Video Inpainting by Jointly Learning Temporal Structure and Spatial Details\",\"url\":\"https://www.semanticscholar.org/paper/1f8c851b73ccb36a88bea0392d1ace84a79f3d97\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1706.08500\",\"authors\":[{\"authorId\":\"2445103\",\"name\":\"Martin Heusel\"},{\"authorId\":\"19219270\",\"name\":\"Hubert Ramsauer\"},{\"authorId\":\"2465270\",\"name\":\"Thomas Unterthiner\"},{\"authorId\":\"37082831\",\"name\":\"Bernhard Nessler\"},{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"231af7dc01a166cac3b5b01ca05778238f796e41\",\"title\":\"GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium\",\"url\":\"https://www.semanticscholar.org/paper/231af7dc01a166cac3b5b01ca05778238f796e41\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Dahun Kim\"},{\"authorId\":null,\"name\":\"Sanghyun Woo\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Joon-Young Lee, and In So Kweon. Deep video inpainting\",\"url\":\"\",\"venue\":\"Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2019},{\"arxivId\":\"1802.05957\",\"authors\":[{\"authorId\":\"3213400\",\"name\":\"Takeru Miyato\"},{\"authorId\":\"1984831\",\"name\":\"T. Kataoka\"},{\"authorId\":\"2877296\",\"name\":\"Masanori Koyama\"},{\"authorId\":\"51462146\",\"name\":\"Y. Yoshida\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"84de7d27e2f6160f634a483e8548c499a2cda7fa\",\"title\":\"Spectral Normalization for Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/84de7d27e2f6160f634a483e8548c499a2cda7fa\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1949594\",\"name\":\"R. Bornard\"},{\"authorId\":\"3162327\",\"name\":\"Emmanuelle Lecan\"},{\"authorId\":\"3020710\",\"name\":\"L. Laborelli\"},{\"authorId\":\"2069039\",\"name\":\"J. Chenot\"}],\"doi\":\"10.1145/641007.641084\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7f2b36610d14d25142a5664e8a1ca6e1425c14dc\",\"title\":\"Missing data correction in still images and image sequences\",\"url\":\"https://www.semanticscholar.org/paper/7f2b36610d14d25142a5664e8a1ca6e1425c14dc\",\"venue\":\"MULTIMEDIA '02\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3068086\",\"name\":\"Jia-Bin Huang\"},{\"authorId\":\"1738740\",\"name\":\"S. B. Kang\"},{\"authorId\":\"145237406\",\"name\":\"N. Ahuja\"},{\"authorId\":\"6867165\",\"name\":\"J. Kopf\"}],\"doi\":\"10.1145/2980179.2982398\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"cdb9a964d2b08cc7578eae031600bfa75e7e8c0c\",\"title\":\"Temporally coherent completion of dynamic video\",\"url\":\"https://www.semanticscholar.org/paper/cdb9a964d2b08cc7578eae031600bfa75e7e8c0c\",\"venue\":\"ACM Trans. Graph.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39990338\",\"name\":\"S. Iizuka\"},{\"authorId\":\"1398077025\",\"name\":\"Edgar Simo-Serra\"},{\"authorId\":\"66193516\",\"name\":\"H. Ishikawa\"}],\"doi\":\"10.1145/3072959.3073659\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d21ebaab3f715dc7178966ff146711882e6a6fee\",\"title\":\"Globally and locally consistent image completion\",\"url\":\"https://www.semanticscholar.org/paper/d21ebaab3f715dc7178966ff146711882e6a6fee\",\"venue\":\"ACM Trans. Graph.\",\"year\":2017},{\"arxivId\":\"1609.04802\",\"authors\":[{\"authorId\":\"1779917\",\"name\":\"C. Ledig\"},{\"authorId\":\"2073063\",\"name\":\"L. Theis\"},{\"authorId\":\"3108066\",\"name\":\"Ferenc Husz\\u00e1r\"},{\"authorId\":\"79382929\",\"name\":\"J. Caballero\"},{\"authorId\":\"83015038\",\"name\":\"Andrew Aitken\"},{\"authorId\":\"41203992\",\"name\":\"Alykhan Tejani\"},{\"authorId\":\"1853456\",\"name\":\"J. Totz\"},{\"authorId\":\"34627233\",\"name\":\"Zehan Wang\"},{\"authorId\":\"152554375\",\"name\":\"W. Shi\"}],\"doi\":\"10.1109/CVPR.2017.19\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"df0c54fe61f0ffb9f0e36a17c2038d9a1964cba3\",\"title\":\"Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network\",\"url\":\"https://www.semanticscholar.org/paper/df0c54fe61f0ffb9f0e36a17c2038d9a1964cba3\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1705.07750\",\"authors\":[{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2017.502\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"title\":\"Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset\",\"url\":\"https://www.semanticscholar.org/paper/b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1804.07723\",\"authors\":[{\"authorId\":\"2457939\",\"name\":\"Guilin Liu\"},{\"authorId\":\"3291967\",\"name\":\"F. Reda\"},{\"authorId\":\"143953573\",\"name\":\"K. Shih\"},{\"authorId\":\"2195314\",\"name\":\"T. Wang\"},{\"authorId\":\"29955511\",\"name\":\"A. Tao\"},{\"authorId\":\"2301680\",\"name\":\"Bryan Catanzaro\"}],\"doi\":\"10.1007/978-3-030-01252-6_6\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2a417a16473e2bcb1c98cd7814bc106760925e60\",\"title\":\"Image Inpainting for Irregular Holes Using Partial Convolutions\",\"url\":\"https://www.semanticscholar.org/paper/2a417a16473e2bcb1c98cd7814bc106760925e60\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1901.00212\",\"authors\":[{\"authorId\":\"40894045\",\"name\":\"Kamyar Nazeri\"},{\"authorId\":\"144653206\",\"name\":\"Eric Ng\"},{\"authorId\":\"39468379\",\"name\":\"T. Joseph\"},{\"authorId\":\"1812218\",\"name\":\"Faisal Z. Qureshi\"},{\"authorId\":\"40155218\",\"name\":\"Mehran Ebrahimi\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f6284d750cf12669ca3bc12a1b485545af776239\",\"title\":\"EdgeConnect: Generative Image Inpainting with Adversarial Edge Learning\",\"url\":\"https://www.semanticscholar.org/paper/f6284d750cf12669ca3bc12a1b485545af776239\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1403025868\",\"name\":\"Jean Pouget-Abadie\"},{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"144738865\",\"name\":\"Bing Xu\"},{\"authorId\":\"1393680089\",\"name\":\"David Warde-Farley\"},{\"authorId\":\"1955694\",\"name\":\"Sherjil Ozair\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"title\":\"Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1609.08675\",\"authors\":[{\"authorId\":\"1389570466\",\"name\":\"Sami Abu-El-Haija\"},{\"authorId\":\"144317839\",\"name\":\"Nisarg Kothari\"},{\"authorId\":\"2119006\",\"name\":\"Joonseok Lee\"},{\"authorId\":\"1820908\",\"name\":\"A. Natsev\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"2758088\",\"name\":\"B. Varadarajan\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c9a1e8e1ba2913ef0bdf1c5eaaa1ac0a79be3716\",\"title\":\"YouTube-8M: A Large-Scale Video Classification Benchmark\",\"url\":\"https://www.semanticscholar.org/paper/c9a1e8e1ba2913ef0bdf1c5eaaa1ac0a79be3716\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ting-Chun Wang\"},{\"authorId\":null,\"name\":\"Ming-Yu Liu\"},{\"authorId\":null,\"name\":\"Jun-Yan Zhu\"},{\"authorId\":null,\"name\":\"Guilin Liu\"},{\"authorId\":null,\"name\":\"Andrew Tao\"},{\"authorId\":null,\"name\":\"Jan Kautz\"},{\"authorId\":null,\"name\":\"Bryan Catanzaro\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Video-tovideo synthesis\",\"url\":\"\",\"venue\":\"arXiv preprint arXiv:1808.06601,\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145603921\",\"name\":\"Miguel Granados\"},{\"authorId\":\"1854493\",\"name\":\"J. Tompkin\"},{\"authorId\":\"1808255\",\"name\":\"K. Kim\"},{\"authorId\":\"1763640\",\"name\":\"O. Grau\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"}],\"doi\":\"10.1111/j.1467-8659.2012.03000.x\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b09ea83a2c84150477ca85a6a0da0920ce64ef32\",\"title\":\"How Not to Be Seen \\u2014 Object Removal from Videos of Crowded Scenes\",\"url\":\"https://www.semanticscholar.org/paper/b09ea83a2c84150477ca85a6a0da0920ce64ef32\",\"venue\":\"Comput. Graph. Forum\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yonatan Wexler\"},{\"authorId\":null,\"name\":\"Eli Shechtman\"},{\"authorId\":null,\"name\":\"Michal Irani\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Spacetime completion of video\",\"url\":\"\",\"venue\":\"IEEE Transactions on Pattern Analysis & Machine Intelligence,\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Christian Ledig\"},{\"authorId\":null,\"name\":\"Lucas Theis\"},{\"authorId\":null,\"name\":\"Ferenc Husz\\u00e1r\"},{\"authorId\":null,\"name\":\"Jose Caballero\"},{\"authorId\":null,\"name\":\"Andrew Cunningham\"},{\"authorId\":null,\"name\":\"Alejandro Acosta\"},{\"authorId\":null,\"name\":\"Andrew Aitken\"},{\"authorId\":null,\"name\":\"Alykhan Tejani\"},{\"authorId\":null,\"name\":\"Johannes Totz\"},{\"authorId\":null,\"name\":\"Zehan Wang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Photorealistic single image super-resolution using a generative adversarial network\",\"url\":\"\",\"venue\":\"In Proceedings of the IEEE conference on computer vision and pattern recognition,\",\"year\":2017},{\"arxivId\":\"1801.07892\",\"authors\":[{\"authorId\":\"46380478\",\"name\":\"J. Yu\"},{\"authorId\":\"145527707\",\"name\":\"Zhe L. Lin\"},{\"authorId\":\"1768964\",\"name\":\"Jimei Yang\"},{\"authorId\":\"1720987\",\"name\":\"X. Shen\"},{\"authorId\":\"145574672\",\"name\":\"Xin Lu\"},{\"authorId\":\"1739208\",\"name\":\"T. Huang\"}],\"doi\":\"10.1109/CVPR.2018.00577\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6b0bbf3e7df725cc3b781d2648e41782cb3d8539\",\"title\":\"Generative Image Inpainting with Contextual Attention\",\"url\":\"https://www.semanticscholar.org/paper/6b0bbf3e7df725cc3b781d2648e41782cb3d8539\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1905.01639\",\"authors\":[{\"authorId\":\"24028009\",\"name\":\"Dahun Kim\"},{\"authorId\":\"2262209\",\"name\":\"S. Woo\"},{\"authorId\":\"1926578\",\"name\":\"Joon-Young Lee\"},{\"authorId\":\"98758720\",\"name\":\"I. Kweon\"}],\"doi\":\"10.1109/CVPR.2019.00594\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5f0c8b5be40518b0ce7876ab152c2b9696ef713e\",\"title\":\"Deep Video Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/5f0c8b5be40518b0ce7876ab152c2b9696ef713e\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2369548\",\"name\":\"Junyuan Xie\"},{\"authorId\":\"2230211\",\"name\":\"Linli Xu\"},{\"authorId\":\"144378760\",\"name\":\"E. Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a2017ec2c60d542af5e9993176ba68f89529dbce\",\"title\":\"Image Denoising and Inpainting with Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/a2017ec2c60d542af5e9993176ba68f89529dbce\",\"venue\":\"NIPS\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1694119\",\"name\":\"M. Bertalm\\u00edo\"},{\"authorId\":\"144722242\",\"name\":\"A. Bertozzi\"},{\"authorId\":\"1699339\",\"name\":\"G. Sapiro\"}],\"doi\":\"10.1109/CVPR.2001.990497\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"95498890efa965658d77c118eaec935622634fc0\",\"title\":\"Navier-stokes, fluid dynamics, and image and video inpainting\",\"url\":\"https://www.semanticscholar.org/paper/95498890efa965658d77c118eaec935622634fc0\",\"venue\":\"Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001\",\"year\":2001},{\"arxivId\":\"1806.03589\",\"authors\":[{\"authorId\":\"46380478\",\"name\":\"J. Yu\"},{\"authorId\":\"145527707\",\"name\":\"Zhe L. Lin\"},{\"authorId\":\"1768964\",\"name\":\"Jimei Yang\"},{\"authorId\":\"1720987\",\"name\":\"X. Shen\"},{\"authorId\":\"145574672\",\"name\":\"Xin Lu\"},{\"authorId\":\"1739208\",\"name\":\"T. Huang\"}],\"doi\":\"10.1109/ICCV.2019.00457\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a997f1ecd85e1467d11252741d188fac8db22722\",\"title\":\"Free-Form Image Inpainting With Gated Convolution\",\"url\":\"https://www.semanticscholar.org/paper/a997f1ecd85e1467d11252741d188fac8db22722\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1409.0575\",\"authors\":[{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"71309570\",\"name\":\"H. Su\"},{\"authorId\":\"2285165\",\"name\":\"J. Krause\"},{\"authorId\":\"145031342\",\"name\":\"S. Satheesh\"},{\"authorId\":\"145423516\",\"name\":\"S. Ma\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-015-0816-y\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"title\":\"ImageNet Large Scale Visual Recognition Challenge\",\"url\":\"https://www.semanticscholar.org/paper/e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Marcelo Bertalmio\"},{\"authorId\":null,\"name\":\"Guillermo Sapiro\"},{\"authorId\":null,\"name\":\"Vincent Caselles\"},{\"authorId\":null,\"name\":\"Coloma Ballester\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Image inpainting. In Proceedings of the 27th annual conference on Computer graphics and interactive techniques, pages 417\\u2013424\",\"url\":\"\",\"venue\":\"ACM Press/Addison- Wesley Publishing Co.,\",\"year\":2000},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46698300\",\"name\":\"Ji Lin\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"143840277\",\"name\":\"Song Han\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5925a25dfe107c49c636eccb8f9fd1aeef7b438c\",\"title\":\"Temporal Shift Module for Efficient Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/5925a25dfe107c49c636eccb8f9fd1aeef7b438c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1603.08155\",\"authors\":[{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"3304525\",\"name\":\"Alexandre Alahi\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/978-3-319-46475-6_43\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9fa3720371e78d04973ce9752781bc337480b68f\",\"title\":\"Perceptual Losses for Real-Time Style Transfer and Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/9fa3720371e78d04973ce9752781bc337480b68f\",\"venue\":\"ECCV\",\"year\":2016}],\"title\":\"Free-Form Video Inpainting With 3D Gated Convolution and Temporal PatchGAN\",\"topics\":[{\"topic\":\"Inpainting\",\"topicId\":\"146260\",\"url\":\"https://www.semanticscholar.org/topic/146260\"},{\"topic\":\"Convolution\",\"topicId\":\"571\",\"url\":\"https://www.semanticscholar.org/topic/571\"},{\"topic\":\"Supercomputer\",\"topicId\":\"9282\",\"url\":\"https://www.semanticscholar.org/topic/9282\"},{\"topic\":\"Mask data preparation\",\"topicId\":\"257141\",\"url\":\"https://www.semanticscholar.org/topic/257141\"},{\"topic\":\"Nvidia DGX-1\",\"topicId\":\"2516702\",\"url\":\"https://www.semanticscholar.org/topic/2516702\"},{\"topic\":\"Clone tool\",\"topicId\":\"466225\",\"url\":\"https://www.semanticscholar.org/topic/466225\"},{\"topic\":\"Interpolation\",\"topicId\":\"1131\",\"url\":\"https://www.semanticscholar.org/topic/1131\"},{\"topic\":\"National Center for High-Performance Computing\",\"topicId\":\"398008\",\"url\":\"https://www.semanticscholar.org/topic/398008\"},{\"topic\":\"Algorithm\",\"topicId\":\"305\",\"url\":\"https://www.semanticscholar.org/topic/305\"},{\"topic\":\"Super-resolution imaging\",\"topicId\":\"127408\",\"url\":\"https://www.semanticscholar.org/topic/127408\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Hypertext Transfer Protocol\",\"topicId\":\"28225\",\"url\":\"https://www.semanticscholar.org/topic/28225\"},{\"topic\":\"Video\",\"topicId\":\"120294\",\"url\":\"https://www.semanticscholar.org/topic/120294\"}],\"url\":\"https://www.semanticscholar.org/paper/e8705ab4b9626c1ab6442483731fe0371f2234b6\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019}\n"