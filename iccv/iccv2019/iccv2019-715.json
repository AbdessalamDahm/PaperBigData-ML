"{\"abstract\":\"Humans are able to localize objects in the environment using both visual and auditory cues, integrating information from multiple modalities into a common reference frame. We introduce a system that can leverage unlabeled audiovisual data to learn to localize objects (moving vehicles) in a visual reference frame, purely using stereo sound at inference time. Since it is labor-intensive to manually annotate the correspondences between audio and object bounding boxes, we achieve this goal by using the co-occurrence of visual and audio streams in unlabeled videos as a form of self-supervision, without resorting to the collection of ground truth annotations. In particular, we propose a framework that consists of a vision ``teacher'' network and a stereo-sound ``student'' network. During training, knowledge embodied in a well-established visual vehicle detection model is transferred to the audio domain using unlabeled videos as a bridge. At test time, the stereo-sound student network can work independently to perform object localization using just stereo audio and camera meta-data, without any visual input. Experimental results on a newly collected Auditory Vehicles Tracking dataset verify that our proposed approach outperforms several baseline approaches. We also demonstrate that our cross-modal auditory localization approach can assist in the visual localization of moving vehicles under poor lighting conditions.\",\"arxivId\":\"1910.11760\",\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\",\"url\":\"https://www.semanticscholar.org/author/144158271\"},{\"authorId\":\"51333271\",\"name\":\"H. Zhao\",\"url\":\"https://www.semanticscholar.org/author/51333271\"},{\"authorId\":\"4965440\",\"name\":\"Peihao Chen\",\"url\":\"https://www.semanticscholar.org/author/4965440\"},{\"authorId\":\"66305116\",\"name\":\"D. Cox\",\"url\":\"https://www.semanticscholar.org/author/66305116\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\",\"url\":\"https://www.semanticscholar.org/author/143805212\"}],\"citationVelocity\":19,\"citations\":[{\"arxivId\":\"2011.07949\",\"authors\":[{\"authorId\":\"4965440\",\"name\":\"Peihao Chen\"},{\"authorId\":\"145592817\",\"name\":\"D. Huang\"},{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"46550737\",\"name\":\"Xiang Long\"},{\"authorId\":\"147992804\",\"name\":\"Runhao Zeng\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2336388131b3cb41eb44e927aeac10a1dabbedad\",\"title\":\"RSPNet: Relative Speed Perception for Unsupervised Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/2336388131b3cb41eb44e927aeac10a1dabbedad\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.09199\",\"authors\":[{\"authorId\":\"41020711\",\"name\":\"Andrew Rouditchenko\"},{\"authorId\":\"1394839535\",\"name\":\"Angie Boggust\"},{\"authorId\":\"30507748\",\"name\":\"David Harwath\"},{\"authorId\":\"47669634\",\"name\":\"Dhiraj Joshi\"},{\"authorId\":\"70913918\",\"name\":\"S. Thomas\"},{\"authorId\":\"3104038\",\"name\":\"Kartik Audhkhasi\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"144707379\",\"name\":\"Brian Kingsbury\"},{\"authorId\":\"1774515\",\"name\":\"M. Picheny\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"},{\"authorId\":\"152450847\",\"name\":\"J. Glass\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1141ac4a1443ae7b44266a84a7f042f38759ac47\",\"title\":\"AVLnet: Learning Audio-Visual Language Representations from Instructional Videos\",\"url\":\"https://www.semanticscholar.org/paper/1141ac4a1443ae7b44266a84a7f042f38759ac47\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2623871\",\"name\":\"Xinchen Liu\"},{\"authorId\":\"1820419411\",\"name\":\"Wu Liu\"},{\"authorId\":\"12009927\",\"name\":\"J. Zheng\"},{\"authorId\":\"3863922\",\"name\":\"C. Yan\"},{\"authorId\":\"1490772804\",\"name\":\"Tao Mei\"}],\"doi\":\"10.1145/3394171.3413578\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"af456f624e20605b464b3332d8e07e7eaddbcdce\",\"title\":\"Beyond the Parts: Learning Multi-view Cross-part Correlation for Vehicle Re-identification\",\"url\":\"https://www.semanticscholar.org/paper/af456f624e20605b464b3332d8e07e7eaddbcdce\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1912.11684\",\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"1591133899\",\"name\":\"Yiwei Zhang\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"}],\"doi\":\"10.1109/ICRA40945.2020.9197008\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3a24996f14c194cd125fd69b5af32037d5abee1a\",\"title\":\"Look, Listen, and Act: Towards Audio-Visual Embodied Navigation\",\"url\":\"https://www.semanticscholar.org/paper/3a24996f14c194cd125fd69b5af32037d5abee1a\",\"venue\":\"2020 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49794497\",\"name\":\"X. Chen\"},{\"authorId\":\"1820419411\",\"name\":\"Wu Liu\"},{\"authorId\":\"2623871\",\"name\":\"Xinchen Liu\"},{\"authorId\":\"121310224\",\"name\":\"Yongdong Zhang\"},{\"authorId\":\"153040576\",\"name\":\"T. Mei\"}],\"doi\":\"10.1145/3394171.3414455\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"40504fc640ed94f279ce31920c5aa9641588a750\",\"title\":\"A Cross-modality and Progressive Person Search System\",\"url\":\"https://www.semanticscholar.org/paper/40504fc640ed94f279ce31920c5aa9641588a750\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2008.00820\",\"authors\":[{\"authorId\":\"4965440\",\"name\":\"Peihao Chen\"},{\"authorId\":\"29969244\",\"name\":\"Y. Zhang\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"},{\"authorId\":\"4506893\",\"name\":\"Hongdong Xiao\"},{\"authorId\":\"145592817\",\"name\":\"D. Huang\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"}],\"doi\":\"10.1109/TIP.2020.3009820\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d0ed8a26aa689992bd0e870df9e428987ea2a4e2\",\"title\":\"Generating Visually Aligned Sound From Videos\",\"url\":\"https://www.semanticscholar.org/paper/d0ed8a26aa689992bd0e870df9e428987ea2a4e2\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"2012.15470\",\"authors\":[{\"authorId\":null,\"name\":\"Senthil Purushwalkam\"},{\"authorId\":null,\"name\":\"Sebastian Vicenc Amengual Gari\"},{\"authorId\":null,\"name\":\"Vamsi Krishna Ithapu\"},{\"authorId\":null,\"name\":\"Carl Schissler\"},{\"authorId\":\"153812886\",\"name\":\"P. Robinson\"},{\"authorId\":\"1726095131\",\"name\":\"Abhinav Gupta\"},{\"authorId\":null,\"name\":\"Kristen Grauman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f6f3c6927b15b035e501727fe5c4e6459f09f9a8\",\"title\":\"Audio-Visual Floorplan Reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/f6f3c6927b15b035e501727fe5c4e6459f09f9a8\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2005.08449\",\"authors\":[{\"authorId\":\"153211990\",\"name\":\"Di Hu\"},{\"authorId\":\"48568841\",\"name\":\"Xuhong Li\"},{\"authorId\":\"35041003\",\"name\":\"Lichao Mou\"},{\"authorId\":\"36352940\",\"name\":\"P. Jin\"},{\"authorId\":\"144230587\",\"name\":\"D. Chen\"},{\"authorId\":\"104530500\",\"name\":\"L. Jing\"},{\"authorId\":\"1761972\",\"name\":\"X. Zhu\"},{\"authorId\":\"1721158\",\"name\":\"D. Dou\"}],\"doi\":\"10.1007/978-3-030-58586-0_5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7fabb1ef96d2840834cfaf384408309bafc588d5\",\"title\":\"Cross-Task Transfer for Geotagged Audiovisual Aerial Scene Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7fabb1ef96d2840834cfaf384408309bafc588d5\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.13976\",\"authors\":[{\"authorId\":\"51298994\",\"name\":\"Yoshiki Masuyama\"},{\"authorId\":\"2730311\",\"name\":\"Yoshiaki Bando\"},{\"authorId\":\"1968008\",\"name\":\"K. Yatabe\"},{\"authorId\":\"1936377\",\"name\":\"Yoko Sasaki\"},{\"authorId\":\"120942871\",\"name\":\"M. Onishi\"},{\"authorId\":\"47735058\",\"name\":\"Y. Oikawa\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0a10b7c9c881924d843445b258eba7209e9d0d8d\",\"title\":\"Self-supervised Neural Audio-Visual Sound Source Localization via Probabilistic Spatial Modeling\",\"url\":\"https://www.semanticscholar.org/paper/0a10b7c9c881924d843445b258eba7209e9d0d8d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49507095\",\"name\":\"Haoming Xu\"},{\"authorId\":\"147992804\",\"name\":\"Runhao Zeng\"},{\"authorId\":\"1443732549\",\"name\":\"Qingyao Wu\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"}],\"doi\":\"10.1145/3394171.3413581\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1d0ffb0a8c69ec211f91bda8f5e9f2ed5d5b42bf\",\"title\":\"Cross-Modal Relation-Aware Networks for Audio-Visual Event Localization\",\"url\":\"https://www.semanticscholar.org/paper/1d0ffb0a8c69ec211f91bda8f5e9f2ed5d5b42bf\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30691613\",\"name\":\"X. Wang\"},{\"authorId\":\"1686917\",\"name\":\"Wu Liu\"},{\"authorId\":\"153426241\",\"name\":\"J. Chen\"},{\"authorId\":\"1519969356\",\"name\":\"Xiaobo Wang\"},{\"authorId\":\"7590116\",\"name\":\"C. Yan\"},{\"authorId\":\"153040576\",\"name\":\"T. Mei\"}],\"doi\":\"10.1145/3380549\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"410d362eaa55c93b6772d1158b1522e6d6846e22\",\"title\":\"Listen, Look, and Find the One\",\"url\":\"https://www.semanticscholar.org/paper/410d362eaa55c93b6772d1158b1522e6d6846e22\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4965440\",\"name\":\"Peihao Chen\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"34413657\",\"name\":\"G. Shen\"},{\"authorId\":\"51026885\",\"name\":\"W. Huang\"},{\"authorId\":\"147992804\",\"name\":\"Runhao Zeng\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"}],\"doi\":\"10.1109/TMM.2019.2959977\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"320d212dd25dfdec58ac6d9f60198eb893d3744e\",\"title\":\"Relation Attention for Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/320d212dd25dfdec58ac6d9f60198eb893d3744e\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"2003.13960\",\"authors\":[{\"authorId\":\"49370795\",\"name\":\"Dongdong Wang\"},{\"authorId\":\"1527095795\",\"name\":\"Yandong Li\"},{\"authorId\":\"49681507\",\"name\":\"Liqiang Wang\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"}],\"doi\":\"10.1109/cvpr42600.2020.00157\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d5a93c7ef56137e500f3615840d4bb1d4b4fd25d\",\"title\":\"Neural Networks Are More Productive Teachers Than Human Raters: Active Mixup for Data-Efficient Knowledge Distillation From a Blackbox Model\",\"url\":\"https://www.semanticscholar.org/paper/d5a93c7ef56137e500f3615840d4bb1d4b4fd25d\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2004.05937\",\"authors\":[{\"authorId\":null,\"name\":\"Lin Wang\"},{\"authorId\":\"51182421\",\"name\":\"Kuk-Jin Yoon\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2528a82dd2266600d4ee2b54165556a984de94d4\",\"title\":\"Knowledge Distillation and Student-Teacher Learning for Visual Intelligence: A Review and New Outlooks\",\"url\":\"https://www.semanticscholar.org/paper/2528a82dd2266600d4ee2b54165556a984de94d4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.13729\",\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144220896\",\"name\":\"Xiaoyu Chen\"},{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5f978b3829acad6ac8b3372d2fa8d38a45b96d3d\",\"title\":\"Noisy Agents: Self-supervised Exploration by Predicting Auditory Events\",\"url\":\"https://www.semanticscholar.org/paper/5f978b3829acad6ac8b3372d2fa8d38a45b96d3d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.09105\",\"authors\":[{\"authorId\":\"145592817\",\"name\":\"D. Huang\"},{\"authorId\":\"4965440\",\"name\":\"Peihao Chen\"},{\"authorId\":\"147992804\",\"name\":\"Runhao Zeng\"},{\"authorId\":\"150270181\",\"name\":\"Qing Du\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"}],\"doi\":\"10.1609/AAAI.V34I07.6737\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"982192e82f17876bf3f8703fbd90ba7e8e3a6e5c\",\"title\":\"Location-Aware Graph Convolutional Networks for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/982192e82f17876bf3f8703fbd90ba7e8e3a6e5c\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2007.10984\",\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"145592817\",\"name\":\"D. Huang\"},{\"authorId\":\"4965440\",\"name\":\"Peihao Chen\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1007/978-3-030-58621-8_44\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"43971a0a2593f660427e016032b983b52f8dd8eb\",\"title\":\"Foley Music: Learning to Generate Music from Videos\",\"url\":\"https://www.semanticscholar.org/paper/43971a0a2593f660427e016032b983b52f8dd8eb\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2326243\",\"name\":\"Arun Balajee Vasudevan\"},{\"authorId\":\"1778526\",\"name\":\"Dengxin Dai\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.3929/ETHZ-B-000431943\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4867095c19f6c5827943cc74335b370d4bfcab29\",\"title\":\"Semantic Object Prediction and Spatial Sound Super-Resolution with Binaural Sounds\",\"url\":\"https://www.semanticscholar.org/paper/4867095c19f6c5827943cc74335b370d4bfcab29\",\"venue\":\"ECCV 2020\",\"year\":2020},{\"arxivId\":\"2004.09476\",\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"145592817\",\"name\":\"D. Huang\"},{\"authorId\":\"47940821\",\"name\":\"Hang Zhao\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/CVPR42600.2020.01049\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b643a7186c08db9f13d7204f6e5e739f97902e71\",\"title\":\"Music Gesture for Visual Sound Separation\",\"url\":\"https://www.semanticscholar.org/paper/b643a7186c08db9f13d7204f6e5e739f97902e71\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143905569\",\"name\":\"Nian Liu\"},{\"authorId\":\"40456843\",\"name\":\"N. Zhang\"},{\"authorId\":\"122200133\",\"name\":\"J. Han\"}],\"doi\":\"10.1109/cvpr42600.2020.01377\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f237473bba70ec13737dbd4ef8f0f67c3cb5c3ff\",\"title\":\"Learning Selective Self-Mutual Attention for RGB-D Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/f237473bba70ec13737dbd4ef8f0f67c3cb5c3ff\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2010.05466\",\"authors\":[{\"authorId\":\"153211990\",\"name\":\"Di Hu\"},{\"authorId\":\"47519958\",\"name\":\"Rui Qian\"},{\"authorId\":\"46332801\",\"name\":\"Minyue Jiang\"},{\"authorId\":\"5424083\",\"name\":\"X. Tan\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"},{\"authorId\":\"12081764\",\"name\":\"E. Ding\"},{\"authorId\":\"8131625\",\"name\":\"W. Lin\"},{\"authorId\":\"1721158\",\"name\":\"D. Dou\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e96b7de5f6366aa1a8b4377d97c3f2464ab198ca\",\"title\":\"Discriminative Sounding Objects Localization via Self-supervised Audiovisual Matching\",\"url\":\"https://www.semanticscholar.org/paper/e96b7de5f6366aa1a8b4377d97c3f2464ab198ca\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2003.04210\",\"authors\":[{\"authorId\":\"2326243\",\"name\":\"Arun Balajee Vasudevan\"},{\"authorId\":\"1778526\",\"name\":\"Dengxin Dai\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-030-58548-8_37\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4d981cc84ee972104eb6d95a2421a42db8a0cf57\",\"title\":\"Semantic Object Prediction and Spatial Sound Super-Resolution with Binaural Sounds\",\"url\":\"https://www.semanticscholar.org/paper/4d981cc84ee972104eb6d95a2421a42db8a0cf57\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1906.06618\",\"authors\":[{\"authorId\":\"2679796\",\"name\":\"Y. Xu\"},{\"authorId\":\"3331304\",\"name\":\"Aljosa Osep\"},{\"authorId\":\"8422060\",\"name\":\"Yutong Ban\"},{\"authorId\":\"116320678\",\"name\":\"Radu Horaud\"},{\"authorId\":\"1388407684\",\"name\":\"L. Leal-Taix\\u00e9\"},{\"authorId\":\"1382657362\",\"name\":\"Xavier Alameda-Pineda\"}],\"doi\":\"10.1109/CVPR42600.2020.00682\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3f3b88dd9856f00d02ac69505d4f940775e28ec8\",\"title\":\"How to Train Your Deep Multi-Object Tracker\",\"url\":\"https://www.semanticscholar.org/paper/3f3b88dd9856f00d02ac69505d4f940775e28ec8\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2006.06175\",\"authors\":[{\"authorId\":\"2806097\",\"name\":\"Karren D. Yang\"},{\"authorId\":\"145160921\",\"name\":\"Bryan C. Russell\"},{\"authorId\":\"1786276\",\"name\":\"Justin Salamon\"}],\"doi\":\"10.1109/cvpr42600.2020.00995\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7555e7a02b23886f1c17049999e4fc66b30c8bf3\",\"title\":\"Telling Left From Right: Learning Spatial Correspondence of Sight and Sound\",\"url\":\"https://www.semanticscholar.org/paper/7555e7a02b23886f1c17049999e4fc66b30c8bf3\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1912.04487\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":\"10.1109/cvpr42600.2020.01047\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c4128ba8deeb67e731cf52fb98addcfddd487e55\",\"title\":\"Listen to Look: Action Recognition by Previewing Audio\",\"url\":\"https://www.semanticscholar.org/paper/c4128ba8deeb67e731cf52fb98addcfddd487e55\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2003.11539\",\"authors\":[{\"authorId\":\"2476765\",\"name\":\"Yonglong Tian\"},{\"authorId\":null,\"name\":\"Yue Wang\"},{\"authorId\":\"1707347\",\"name\":\"Dilip Krishnan\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"},{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"}],\"doi\":\"10.1007/978-3-030-58568-6_16\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"80455126562cfe6a483e02b3446a3f30b8e9f229\",\"title\":\"Rethinking Few-Shot Image Classification: a Good Embedding Is All You Need?\",\"url\":\"https://www.semanticscholar.org/paper/80455126562cfe6a483e02b3446a3f30b8e9f229\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2006.05071\",\"authors\":[{\"authorId\":\"3028886\",\"name\":\"M. Mirbagheri\"},{\"authorId\":\"21149653\",\"name\":\"Bardia Doosti\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"68ff89c34440b192aa1e909c8c7635f6edd9c346\",\"title\":\"C-SL: Contrastive Sound Localization with Inertial-Acoustic Sensors\",\"url\":\"https://www.semanticscholar.org/paper/68ff89c34440b192aa1e909c8c7635f6edd9c346\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.07097\",\"authors\":[{\"authorId\":\"153211990\",\"name\":\"Di Hu\"},{\"authorId\":\"35041003\",\"name\":\"Lichao Mou\"},{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"46930271\",\"name\":\"Junyu Gao\"},{\"authorId\":\"51151222\",\"name\":\"Yuansheng Hua\"},{\"authorId\":\"1721158\",\"name\":\"D. Dou\"},{\"authorId\":\"40049070\",\"name\":\"X. Zhu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bd0438b43d63605356bf5bcfedb8bd1e99803cdc\",\"title\":\"Ambient Sound Helps: Audiovisual Crowd Counting in Extreme Conditions\",\"url\":\"https://www.semanticscholar.org/paper/bd0438b43d63605356bf5bcfedb8bd1e99803cdc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.06355\",\"authors\":[{\"authorId\":\"47519958\",\"name\":\"Rui Qian\"},{\"authorId\":\"1500378795\",\"name\":\"Di Hu\"},{\"authorId\":\"2451839\",\"name\":\"H. Dinkel\"},{\"authorId\":\"3000684\",\"name\":\"Mengyue Wu\"},{\"authorId\":null,\"name\":\"Ning Xu\"},{\"authorId\":\"8131625\",\"name\":\"W. Lin\"}],\"doi\":\"10.1007/978-3-030-58565-5_18\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"53eb4c778e7c2aec2f4c5d2681321b18c06decca\",\"title\":\"Multiple Sound Sources Localization from Coarse to Fine\",\"url\":\"https://www.semanticscholar.org/paper/53eb4c778e7c2aec2f4c5d2681321b18c06decca\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2006.11476\",\"authors\":[{\"authorId\":\"1390925224\",\"name\":\"Y. Yao\"},{\"authorId\":\"49046944\",\"name\":\"C. Liu\"},{\"authorId\":\"152504322\",\"name\":\"Dezhao Luo\"},{\"authorId\":\"9113781\",\"name\":\"Yin-qing Zhou\"},{\"authorId\":\"12605536\",\"name\":\"Qixiang Ye\"}],\"doi\":\"10.1109/cvpr42600.2020.00658\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"15e8b0a6366e29c7093ecf844eb40d03d8004abb\",\"title\":\"Video Playback Rate Perception for Self-Supervised Spatio-Temporal Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/15e8b0a6366e29c7093ecf844eb40d03d8004abb\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Xiao Wang\"},{\"authorId\":null,\"name\":\"Jun Chen\"},{\"authorId\":\"93321210\",\"name\":\"Z. Wang\"},{\"authorId\":\"1677190126\",\"name\":\"Wu Liu\"},{\"authorId\":\"144404414\",\"name\":\"S. Satoh\"},{\"authorId\":\"143869239\",\"name\":\"Chao Liang\"},{\"authorId\":\"46246806\",\"name\":\"Chia-Wen Lin\"}],\"doi\":\"10.24963/ijcai.2020/71\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"747fd725785a427824c0a223237f8893b3923f34\",\"title\":\"When Pedestrian Detection Meets Nighttime Surveillance: A New Benchmark\",\"url\":\"https://www.semanticscholar.org/paper/747fd725785a427824c0a223237f8893b3923f34\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":\"2008.04237\",\"authors\":[{\"authorId\":\"2285516\",\"name\":\"Triantafyllos Afouras\"},{\"authorId\":\"144956994\",\"name\":\"Andrew Owens\"},{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/978-3-030-58523-5_13\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0eb79a085e014f129b063199a38fe9945355c137\",\"title\":\"Self-Supervised Learning of Audio-Visual Objects from Video\",\"url\":\"https://www.semanticscholar.org/paper/0eb79a085e014f129b063199a38fe9945355c137\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.09162\",\"authors\":[{\"authorId\":\"1527095795\",\"name\":\"Yandong Li\"},{\"authorId\":\"144942207\",\"name\":\"Di Huang\"},{\"authorId\":\"36690046\",\"name\":\"Danfeng Qin\"},{\"authorId\":\"1390771606\",\"name\":\"Liqiang Wang\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"}],\"doi\":\"10.1007/978-3-030-58526-6_35\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d4e43035f83bc9a37f118edf037b27dcb5293288\",\"title\":\"Improving Object Detection with Selective Self-supervised Self-training\",\"url\":\"https://www.semanticscholar.org/paper/d4e43035f83bc9a37f118edf037b27dcb5293288\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7299839\",\"name\":\"Huadong Tan\"},{\"authorId\":\"89136398\",\"name\":\"Guang Wu\"},{\"authorId\":\"152226296\",\"name\":\"Pengcheng Zhao\"},{\"authorId\":\"47558599\",\"name\":\"Yan-Xiang Chen\"}],\"doi\":\"10.1109/ICASSP40776.2020.9052918\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8fd8e6b8ebe89bd7500d2639fcf42f52e3e771fa\",\"title\":\"Spectrogram Analysis Via Self-Attention for Realizing Cross-Model Visual-Audio Generation\",\"url\":\"https://www.semanticscholar.org/paper/8fd8e6b8ebe89bd7500d2639fcf42f52e3e771fa\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"16149902\",\"name\":\"Janani Ramaswamy\"},{\"authorId\":\"144009889\",\"name\":\"Sukhendu Das\"}],\"doi\":\"10.1109/WACV45572.2020.9093616\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"c911d81bddb48490a02258e79379b6428246ddc2\",\"title\":\"See the Sound, Hear the Pixels\",\"url\":\"https://www.semanticscholar.org/paper/c911d81bddb48490a02258e79379b6428246ddc2\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"2007.09902\",\"authors\":[{\"authorId\":\"145798292\",\"name\":\"Hang Zhou\"},{\"authorId\":\"48670507\",\"name\":\"Xudong Xu\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"},{\"authorId\":\"3243969\",\"name\":\"Z. Liu\"}],\"doi\":\"10.1007/978-3-030-58610-2_4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"73aa926dad010a3f1bb89faa31241f97a89cc461\",\"title\":\"Sep-Stereo: Visually Guided Stereophonic Audio Generation by Associating Source Separation\",\"url\":\"https://www.semanticscholar.org/paper/73aa926dad010a3f1bb89faa31241f97a89cc461\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.04954\",\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"40256075\",\"name\":\"Jeremy I Schwartz\"},{\"authorId\":\"1753624613\",\"name\":\"Seth Alter\"},{\"authorId\":\"8551292\",\"name\":\"Martin Schrimpf\"},{\"authorId\":\"50690309\",\"name\":\"James Traer\"},{\"authorId\":\"145584238\",\"name\":\"J\\u00falian Let\\u00edcia de Freitas\"},{\"authorId\":\"2898540\",\"name\":\"J. Kubilius\"},{\"authorId\":\"150894502\",\"name\":\"Abhishek Bhandwaldar\"},{\"authorId\":\"49101800\",\"name\":\"N. Haber\"},{\"authorId\":\"27023509\",\"name\":\"M. Sano\"},{\"authorId\":\"1802442393\",\"name\":\"Kuno Kim\"},{\"authorId\":\"50844928\",\"name\":\"Elias Wang\"},{\"authorId\":\"2440995\",\"name\":\"Damian Mrowca\"},{\"authorId\":\"1802680741\",\"name\":\"Michael Lingelbach\"},{\"authorId\":\"1381602121\",\"name\":\"Aidan Curtis\"},{\"authorId\":\"19247947\",\"name\":\"Kevin T. Feigelis\"},{\"authorId\":\"29737051\",\"name\":\"Daniel M. Bear\"},{\"authorId\":\"1891570\",\"name\":\"Dan Gutfreund\"},{\"authorId\":\"145082769\",\"name\":\"David Cox\"},{\"authorId\":\"34409560\",\"name\":\"James J. DiCarlo\"},{\"authorId\":\"2324658\",\"name\":\"J. McDermott\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"},{\"authorId\":\"6772751\",\"name\":\"Daniel L. K. Yamins\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fdd1ff22c3a35d9d7426ef6e6fd9a4775317f5a6\",\"title\":\"ThreeDWorld: A Platform for Interactive Multi-Modal Physical Simulation\",\"url\":\"https://www.semanticscholar.org/paper/fdd1ff22c3a35d9d7426ef6e6fd9a4775317f5a6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.01616\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"153246625\",\"name\":\"Chang\\u2019an Chen\"},{\"authorId\":\"9187007\",\"name\":\"Z. Al-Halah\"},{\"authorId\":\"2368282\",\"name\":\"Carl Schissler\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1007/978-3-030-58545-7_38\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"33006edd74d92453903df5a53fa25539047c1850\",\"title\":\"VisualEchoes: Spatial Image Representation Learning through Echolocation\",\"url\":\"https://www.semanticscholar.org/paper/33006edd74d92453903df5a53fa25539047c1850\",\"venue\":\"ECCV\",\"year\":2020}],\"corpusId\":204885193,\"doi\":\"10.1109/ICCV.2019.00715\",\"fieldsOfStudy\":[\"Computer Science\",\"Engineering\"],\"influentialCitationCount\":2,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"05c846b122dc64b6900c09b9210912615a3febb6\",\"references\":[{\"arxivId\":\"1809.10961\",\"authors\":[{\"authorId\":\"8422060\",\"name\":\"Yutong Ban\"},{\"authorId\":\"1382657362\",\"name\":\"Xavier Alameda-Pineda\"},{\"authorId\":\"1780746\",\"name\":\"Laurent Girin\"},{\"authorId\":\"1794229\",\"name\":\"R. Horaud\"}],\"doi\":\"10.1109/TPAMI.2019.2953020\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d1263c5b58a2591eb3c1e35eebd78f3caf0a3716\",\"title\":\"Variational Bayesian Inference for Audio-Visual Tracking of Multiple Speakers\",\"url\":\"https://www.semanticscholar.org/paper/d1263c5b58a2591eb3c1e35eebd78f3caf0a3716\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J. Redmon\"},{\"authorId\":null,\"name\":\"A. Farhadi\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"YOLO9000: Better\",\"url\":\"\",\"venue\":\"faster, stronger. In CVPR, pages 6517\\u20136525\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"R. Stiefelhagen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Varia - tional bayesian inference for audio - visual tracking of multiple speakers Harmony in motion\",\"url\":\"\",\"venue\":\"\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31496901\",\"name\":\"John W. Fisher III\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"},{\"authorId\":\"1731948\",\"name\":\"P. Viola\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"15674778d14d7f2bf90c323924e8153d5f10fb60\",\"title\":\"Learning Joint Statistical Models for Audio-Visual Fusion and Segregation\",\"url\":\"https://www.semanticscholar.org/paper/15674778d14d7f2bf90c323924e8153d5f10fb60\",\"venue\":\"NIPS\",\"year\":2000},{\"arxivId\":\"1803.03849\",\"authors\":[{\"authorId\":\"40895287\",\"name\":\"Arda Senocak\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"3053231\",\"name\":\"J. Kim\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"2398271\",\"name\":\"In-So Kweon\"}],\"doi\":\"10.1109/CVPR.2018.00458\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b91d738cd1f5d550c5b27f328e55308a0a73b2d2\",\"title\":\"Learning to Localize Sound Source in Visual Scenes\",\"url\":\"https://www.semanticscholar.org/paper/b91d738cd1f5d550c5b27f328e55308a0a73b2d2\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"R. Arandjelovic\"},{\"authorId\":null,\"name\":\"A. Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Look\",\"url\":\"\",\"venue\":\"listen and learn. In 2017 IEEE International Conference on Computer Vision (ICCV), pages 609\\u2013617\",\"year\":2017},{\"arxivId\":\"1706.00932\",\"authors\":[{\"authorId\":\"3152281\",\"name\":\"Y. Aytar\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"52ed3b634c302af93ee2e70b7c28e4b2128a5947\",\"title\":\"See, Hear, and Read: Deep Aligned Representations\",\"url\":\"https://www.semanticscholar.org/paper/52ed3b634c302af93ee2e70b7c28e4b2128a5947\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1809.10936\",\"authors\":[{\"authorId\":\"50079006\",\"name\":\"Xiaofei Li\"},{\"authorId\":\"8422060\",\"name\":\"Yutong Ban\"},{\"authorId\":\"1780746\",\"name\":\"Laurent Girin\"},{\"authorId\":\"1382657362\",\"name\":\"Xavier Alameda-Pineda\"},{\"authorId\":\"1794229\",\"name\":\"R. Horaud\"}],\"doi\":\"10.1109/JSTSP.2019.2903472\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"edea0eecdb3af425eb98d35f58468005f80bf057\",\"title\":\"Online Localization and Tracking of Multiple Moving Speakers in Reverberant Environments\",\"url\":\"https://www.semanticscholar.org/paper/edea0eecdb3af425eb98d35f58468005f80bf057\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"W.-C. Ma\"},{\"authorId\":null,\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"A . A . Winder . II . Sonar system technology\",\"url\":\"\",\"venue\":\"IEEE Transactions on Sonics and Ultrasonics\",\"year\":1975},{\"arxivId\":\"1607.07295\",\"authors\":[{\"authorId\":\"3436589\",\"name\":\"L. Castrej\\u00f3n\"},{\"authorId\":\"3152281\",\"name\":\"Y. Aytar\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"2367683\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/CVPR.2016.321\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7e64992091458256f438fbe1bd44fffcc197b76c\",\"title\":\"Learning Aligned Cross-Modal Representations from Weakly Aligned Data\",\"url\":\"https://www.semanticscholar.org/paper/7e64992091458256f438fbe1bd44fffcc197b76c\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A A Winder\"},{\"authorId\":null,\"name\":\"Ii\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Sonar system technology\",\"url\":\"\",\"venue\":\"IEEE Transactions on Sonics and Ultrasonics\",\"year\":1975},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1701229\",\"name\":\"Keni Bernardin\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"}],\"doi\":\"10.1155/2008/246309\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2258e01865367018ed6f4262c880df85b94959f8\",\"title\":\"Evaluating Multiple Object Tracking Performance: The CLEAR MOT Metrics\",\"url\":\"https://www.semanticscholar.org/paper/2258e01865367018ed6f4262c880df85b94959f8\",\"venue\":\"EURASIP J. Image Video Process.\",\"year\":2008},{\"arxivId\":\"1610.09001\",\"authors\":[{\"authorId\":\"3152281\",\"name\":\"Y. Aytar\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7ab8d3af6f78f9c9f64a2f2d38471401ad0988a9\",\"title\":\"SoundNet: Learning Sound Representations from Unlabeled Video\",\"url\":\"https://www.semanticscholar.org/paper/7ab8d3af6f78f9c9f64a2f2d38471401ad0988a9\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1804.01665\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1007/978-3-030-01219-9_3\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5c9ca16cb2337fd5948c7af28c29c156981250e8\",\"title\":\"Learning to Separate Object Sounds by Watching Unlabeled Video\",\"url\":\"https://www.semanticscholar.org/paper/5c9ca16cb2337fd5948c7af28c29c156981250e8\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1810.06553\",\"authors\":[{\"authorId\":\"31571033\",\"name\":\"A. Salvador\"},{\"authorId\":\"32856859\",\"name\":\"Nicholas Hynes\"},{\"authorId\":\"3152281\",\"name\":\"Y. Aytar\"},{\"authorId\":\"145686708\",\"name\":\"J. Mar\\u00edn\"},{\"authorId\":\"1727159\",\"name\":\"Ferda Ofli\"},{\"authorId\":\"1684687\",\"name\":\"Ingmar Weber\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/CVPR.2017.327\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d7170e3641ba7452987bfd299ef4c6e20dd8105c\",\"title\":\"Learning Cross-Modal Embeddings for Cooking Recipes and Food Images\",\"url\":\"https://www.semanticscholar.org/paper/d7170e3641ba7452987bfd299ef4c6e20dd8105c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1904.05979\",\"authors\":[{\"authorId\":\"144077750\",\"name\":\"Hang Zhao\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"2650832\",\"name\":\"W. Ma\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/ICCV.2019.00182\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c880de441a41c351955ad0bf8f712eeee500ac67\",\"title\":\"The Sound of Motions\",\"url\":\"https://www.semanticscholar.org/paper/c880de441a41c351955ad0bf8f712eeee500ac67\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3016044\",\"name\":\"M. Brandstein\"},{\"authorId\":\"2287631\",\"name\":\"D. Ward\"}],\"doi\":\"10.1007/978-3-662-04619-7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c05cedb393a5ae9e53e80537a28cda06decd5540\",\"title\":\"Microphone Arrays - Signal Processing Techniques and Applications\",\"url\":\"https://www.semanticscholar.org/paper/c05cedb393a5ae9e53e80537a28cda06decd5540\",\"venue\":\"Microphone Arrays\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1784851\",\"name\":\"T. Sainath\"},{\"authorId\":\"39571582\",\"name\":\"Ron J. Weiss\"},{\"authorId\":\"12812321\",\"name\":\"K. Wilson\"},{\"authorId\":\"143771569\",\"name\":\"Bo Li\"},{\"authorId\":\"1989278\",\"name\":\"A. Narayanan\"},{\"authorId\":\"3032614\",\"name\":\"Ehsan Variani\"},{\"authorId\":\"1771090\",\"name\":\"M. Bacchiani\"},{\"authorId\":\"1697494\",\"name\":\"I. Shafran\"},{\"authorId\":\"33666044\",\"name\":\"A. Senior\"},{\"authorId\":\"3015639\",\"name\":\"K. K. Chin\"},{\"authorId\":\"36079662\",\"name\":\"A. Misra\"},{\"authorId\":\"14073033\",\"name\":\"Chanwoo Kim\"}],\"doi\":\"10.1109/TASLP.2017.2672401\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0a5361855f02412eab7a920a09d86c513b5d5e86\",\"title\":\"Multichannel Signal Processing With Deep Neural Networks for Automatic Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/0a5361855f02412eab7a920a09d86c513b5d5e86\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J. Redmon\"},{\"authorId\":null,\"name\":\"S. Divvala\"},{\"authorId\":null,\"name\":\"R. Girshick\"},{\"authorId\":null,\"name\":\"A. Farhadi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"You only look once: Unified\",\"url\":\"\",\"venue\":\"real-time object detection. In CVPR, pages 779\\u2013788\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145183926\",\"name\":\"Aditya Nugraha\"},{\"authorId\":\"47515529\",\"name\":\"A. Liutkus\"},{\"authorId\":\"1692147\",\"name\":\"E. Vincent\"}],\"doi\":\"10.1109/TASLP.2016.2580946\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6b03d309551991d3a905ff7a7f4501aa2864b99f\",\"title\":\"Multichannel Audio Source Separation With Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6b03d309551991d3a905ff7a7f4501aa2864b99f\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2992579\",\"name\":\"Hamid Izadinia\"},{\"authorId\":\"2658133\",\"name\":\"Imran Saleemi\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/TMM.2012.2228476\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e3118de593eee760242be45ceac0ae77d0831d31\",\"title\":\"Multimodal Analysis for Identification and Segmentation of Moving-Sounding Objects\",\"url\":\"https://www.semanticscholar.org/paper/e3118de593eee760242be45ceac0ae77d0831d31\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2013},{\"arxivId\":\"1506.02640\",\"authors\":[{\"authorId\":\"40497777\",\"name\":\"Joseph Redmon\"},{\"authorId\":\"2038685\",\"name\":\"S. Divvala\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"47465174\",\"name\":\"Ali Farhadi\"}],\"doi\":\"10.1109/CVPR.2016.91\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f8e79ac0ea341056ef20f2616628b3e964764cfd\",\"title\":\"You Only Look Once: Unified, Real-Time Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/f8e79ac0ea341056ef20f2616628b3e964764cfd\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1804.03641\",\"authors\":[{\"authorId\":\"144956994\",\"name\":\"Andrew Owens\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1007/978-3-030-01231-1_39\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"171f8f1090ef0533ff470ed5a4d31ecfefcc74be\",\"title\":\"Audio-Visual Scene Analysis with Self-Supervised Multisensory Features\",\"url\":\"https://www.semanticscholar.org/paper/171f8f1090ef0533ff470ed5a4d31ecfefcc74be\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"},{\"authorId\":\"144119773\",\"name\":\"Kun Liu\"},{\"authorId\":\"144914140\",\"name\":\"H. Su\"},{\"authorId\":\"1744254\",\"name\":\"L. Guibas\"}],\"doi\":\"10.1109/CVPR.2018.00586\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"10befbb6c3f6183fe143830ac1479b7dcf119bae\",\"title\":\"Geometry Guided Convolutional Neural Networks for Self-Supervised Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/10befbb6c3f6183fe143830ac1479b7dcf119bae\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1809.02587\",\"authors\":[{\"authorId\":\"31692099\",\"name\":\"Pedro Morgado\"},{\"authorId\":\"1699559\",\"name\":\"N. Vasconcelos\"},{\"authorId\":\"153298725\",\"name\":\"Timothy R. Langlois\"},{\"authorId\":\"39231399\",\"name\":\"O. Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"029490920cd736e91d6c57f3cfb850adddcf2725\",\"title\":\"Self-Supervised Generation of Spatial Audio for 360 Video\",\"url\":\"https://www.semanticscholar.org/paper/029490920cd736e91d6c57f3cfb850adddcf2725\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7136913\",\"name\":\"J. Leonard\"},{\"authorId\":\"1398671969\",\"name\":\"H. Durrant-Whyte\"}],\"doi\":\"10.1007/978-1-4615-3652-9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"065b638b3548c58ed18361c25bcef1d13b670f8c\",\"title\":\"Directed Sonar Sensing for Mobile Robot Navigation\",\"url\":\"https://www.semanticscholar.org/paper/065b638b3548c58ed18361c25bcef1d13b670f8c\",\"venue\":\"\",\"year\":1992},{\"arxivId\":\"1808.05561\",\"authors\":[{\"authorId\":\"7641268\",\"name\":\"Samuel Albanie\"},{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1145/3240508.3240578\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"540831094fd9b80469c8dacb9320b7e342b50e03\",\"title\":\"Emotion Recognition in Speech using Cross-Modal Transfer in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/540831094fd9b80469c8dacb9320b7e342b50e03\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2387467\",\"name\":\"J. Hershey\"},{\"authorId\":\"1741200\",\"name\":\"J. Movellan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"00d1bb817691bb0566bc55fde01d12339625aa1c\",\"title\":\"Audio Vision: Using Audio-Visual Synchrony to Locate Sounds\",\"url\":\"https://www.semanticscholar.org/paper/00d1bb817691bb0566bc55fde01d12339625aa1c\",\"venue\":\"NIPS\",\"year\":1999},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2744069\",\"name\":\"Zohar Barzelay\"},{\"authorId\":\"2159538\",\"name\":\"Y. Schechner\"}],\"doi\":\"10.1109/CVPR.2007.383344\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e309dfbae9d123f85223d398d4a400abee3ef393\",\"title\":\"Harmony in Motion\",\"url\":\"https://www.semanticscholar.org/paper/e309dfbae9d123f85223d398d4a400abee3ef393\",\"venue\":\"2007 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1692923940\",\"name\":\"revis\\u00e3o da literatura\"},{\"authorId\":\"1692923938\",\"name\":\"O. P. D. Envelhecimento\"},{\"authorId\":\"1692926814\",\"name\":\"Segundo Robert\"}],\"doi\":\"10.1080/14753820.2019.1662973\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"01b4ef84188428acdea3e62d82abb12a59e5b69d\",\"title\":\"II\",\"url\":\"https://www.semanticscholar.org/paper/01b4ef84188428acdea3e62d82abb12a59e5b69d\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"95941127\",\"name\":\"Y. Li\"},{\"authorId\":\"48908475\",\"name\":\"C. Huang\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/cvprw.2009.5206735\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5981e6479c3fd4e31644db35d236bfb84ae46514\",\"title\":\"Learning to associate: HybridBoosted multi-target tracker for crowded scene\",\"url\":\"https://www.semanticscholar.org/paper/5981e6479c3fd4e31644db35d236bfb84ae46514\",\"venue\":\"2009 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2009},{\"arxivId\":\"1503.02531\",\"authors\":[{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"0c908739fbff75f03469d13d4a1a07de3414ee19\",\"title\":\"Distilling the Knowledge in a Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/0c908739fbff75f03469d13d4a1a07de3414ee19\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1312.6184\",\"authors\":[{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"145727186\",\"name\":\"R. Caruana\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d770060812fb646b3846a7d398a3066145b5e3c8\",\"title\":\"Do Deep Nets Really Need to be Deep?\",\"url\":\"https://www.semanticscholar.org/paper/d770060812fb646b3846a7d398a3066145b5e3c8\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1705.08168\",\"authors\":[{\"authorId\":\"2299479\",\"name\":\"R. Arandjelovi\\u0107\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/ICCV.2017.73\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9b5f696f73c1264ccb8e97d3b738a2342ecd6bee\",\"title\":\"Look, Listen and Learn\",\"url\":\"https://www.semanticscholar.org/paper/9b5f696f73c1264ccb8e97d3b738a2342ecd6bee\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1608.07017\",\"authors\":[{\"authorId\":\"144956994\",\"name\":\"Andrew Owens\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"2324658\",\"name\":\"J. McDermott\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1007/978-3-319-46448-0_48\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"93a87dfa72f22fba14ef243a62c7d0a6906dfed7\",\"title\":\"Ambient Sound Provides Supervision for Visual Learning\",\"url\":\"https://www.semanticscholar.org/paper/93a87dfa72f22fba14ef243a62c7d0a6906dfed7\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1712.06651\",\"authors\":[{\"authorId\":\"2299479\",\"name\":\"R. Arandjelovi\\u0107\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/978-3-030-01246-5_27\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dfc504536e8434eb008680343abb77010965169e\",\"title\":\"Objects that Sound\",\"url\":\"https://www.semanticscholar.org/paper/dfc504536e8434eb008680343abb77010965169e\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144775037\",\"name\":\"A. Winder\"}],\"doi\":\"10.1109/T-SU.1975.30813\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"53628fe0e080e389c9988931e6642c03684ee351\",\"title\":\"II. Sonar System Technology\",\"url\":\"https://www.semanticscholar.org/paper/53628fe0e080e389c9988931e6642c03684ee351\",\"venue\":\"IEEE Transactions on Sonics and Ultrasonics\",\"year\":1975},{\"arxivId\":\"1301.3666\",\"authors\":[{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"2012435\",\"name\":\"M. Ganjoo\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"},{\"authorId\":\"34699434\",\"name\":\"A. Ng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"755e9f43ce398ae8737366720c5f82685b0c253e\",\"title\":\"Zero-Shot Learning Through Cross-Modal Transfer\",\"url\":\"https://www.semanticscholar.org/paper/755e9f43ce398ae8737366720c5f82685b0c253e\",\"venue\":\"NIPS\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8592850\",\"name\":\"Santani Teng\"},{\"authorId\":\"13026676\",\"name\":\"Verena R. Sommer\"},{\"authorId\":\"8152383\",\"name\":\"D. Pantazis\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"}],\"doi\":\"10.1523/ENEURO.0007-17.2017\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"96a1e828f10e85a409430bc0bf519068ef6cb81d\",\"title\":\"Hearing Scenes: A Neuromagnetic Signature of Auditory Source and Reverberant Space Separation\",\"url\":\"https://www.semanticscholar.org/paper/96a1e828f10e85a409430bc0bf519068ef6cb81d\",\"venue\":\"eNeuro\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"2976163\",\"name\":\"Kuiyuan Yang\"},{\"authorId\":null,\"name\":\"Yi Yang\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2016.106\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"26201e1b76f276187e31c7db84eab0bfcda01102\",\"title\":\"You Lead, We Exceed: Labor-Free Video Concept Learning by Jointly Exploiting Web Videos and Images\",\"url\":\"https://www.semanticscholar.org/paper/26201e1b76f276187e31c7db84eab0bfcda01102\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5886094\",\"name\":\"P. Cochat\"},{\"authorId\":\"13267685\",\"name\":\"L. Vaucoret\"},{\"authorId\":\"31455512\",\"name\":\"J. Sarles\"}],\"doi\":\"10.1016/j.arcped.2012.01.013\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"10d85561e4aafc516d10064f30dff05b41f70afe\",\"title\":\"[Et al].\",\"url\":\"https://www.semanticscholar.org/paper/10d85561e4aafc516d10064f30dff05b41f70afe\",\"venue\":\"Archives de pediatrie : organe officiel de la Societe francaise de pediatrie\",\"year\":2012},{\"arxivId\":\"1804.03160\",\"authors\":[{\"authorId\":\"144077750\",\"name\":\"Hang Zhao\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"41020711\",\"name\":\"Andrew Rouditchenko\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"2324658\",\"name\":\"J. McDermott\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1007/978-3-030-01246-5_35\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"fe018f22600d07cbd0452a070e03708886470015\",\"title\":\"The Sound of Pixels\",\"url\":\"https://www.semanticscholar.org/paper/fe018f22600d07cbd0452a070e03708886470015\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1507.00448\",\"authors\":[{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"50196944\",\"name\":\"Judy Hoffman\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/CVPR.2016.309\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"53d1e022961e241164ecb6ec58378d7033a280f8\",\"title\":\"Cross Modal Distillation for Supervision Transfer\",\"url\":\"https://www.semanticscholar.org/paper/53d1e022961e241164ecb6ec58378d7033a280f8\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1612.08242\",\"authors\":[{\"authorId\":\"40497777\",\"name\":\"Joseph Redmon\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"}],\"doi\":\"10.1109/CVPR.2017.690\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7d39d69b23424446f0400ef603b2e3e22d0309d6\",\"title\":\"YOLO9000: Better, Faster, Stronger\",\"url\":\"https://www.semanticscholar.org/paper/7d39d69b23424446f0400ef603b2e3e22d0309d6\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1804.03619\",\"authors\":[{\"authorId\":\"2077454\",\"name\":\"A. Ephrat\"},{\"authorId\":\"2138834\",\"name\":\"Inbar Mosseri\"},{\"authorId\":\"49618488\",\"name\":\"Oran Lang\"},{\"authorId\":\"2112779\",\"name\":\"Tali Dekel\"},{\"authorId\":\"118291142\",\"name\":\"K. Wilson\"},{\"authorId\":\"1639722387\",\"name\":\"Avinatan Hassidim\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"},{\"authorId\":\"144544291\",\"name\":\"Michael Rubinstein\"}],\"doi\":\"10.1145/3197517.3201357\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1b6add50e6be8d4f21e38cca9a154321cad3a4e0\",\"title\":\"Looking to listen at the cocktail party\",\"url\":\"https://www.semanticscholar.org/paper/1b6add50e6be8d4f21e38cca9a154321cad3a4e0\",\"venue\":\"ACM Trans. Graph.\",\"year\":2018},{\"arxivId\":\"1904.09013\",\"authors\":[{\"authorId\":\"41020711\",\"name\":\"Andrew Rouditchenko\"},{\"authorId\":\"144077750\",\"name\":\"Hang Zhao\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"2324658\",\"name\":\"J. McDermott\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/ICASSP.2019.8682467\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c4a44cd4c6bdd7fe85a1227c5041827ba828e0de\",\"title\":\"Self-supervised Audio-visual Co-segmentation\",\"url\":\"https://www.semanticscholar.org/paper/c4a44cd4c6bdd7fe85a1227c5041827ba828e0de\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Y. Aytar\"},{\"authorId\":null,\"name\":\"C. Vondrick\"},{\"authorId\":null,\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"See\",\"url\":\"\",\"venue\":\"hear, and read: Deep aligned representations. arXiv preprint arXiv:1706.00932\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"C. Gan\"},{\"authorId\":null,\"name\":\"T. Yao\"},{\"authorId\":null,\"name\":\"K. Yang\"},{\"authorId\":null,\"name\":\"Y. Yang\"},{\"authorId\":null,\"name\":\"T. Mei\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"You lead\",\"url\":\"\",\"venue\":\"we exceed: Labor-free video concept learning by jointly exploiting web videos and images. In CVPR, pages 923\\u2013932\",\"year\":2016}],\"title\":\"Self-Supervised Moving Vehicle Tracking With Stereo Sound\",\"topics\":[{\"topic\":\"Vehicle tracking system\",\"topicId\":\"150510\",\"url\":\"https://www.semanticscholar.org/topic/150510\"},{\"topic\":\"Reference frame (video)\",\"topicId\":\"60937\",\"url\":\"https://www.semanticscholar.org/topic/60937\"},{\"topic\":\"Ground truth\",\"topicId\":\"33313\",\"url\":\"https://www.semanticscholar.org/topic/33313\"},{\"topic\":\"Humans\",\"topicId\":\"732\",\"url\":\"https://www.semanticscholar.org/topic/732\"},{\"topic\":\"Algorithm\",\"topicId\":\"305\",\"url\":\"https://www.semanticscholar.org/topic/305\"},{\"topic\":\"Object detection\",\"topicId\":\"14349\",\"url\":\"https://www.semanticscholar.org/topic/14349\"},{\"topic\":\"Video tracking\",\"topicId\":\"14340\",\"url\":\"https://www.semanticscholar.org/topic/14340\"},{\"topic\":\"Video clip\",\"topicId\":\"30493\",\"url\":\"https://www.semanticscholar.org/topic/30493\"},{\"topic\":\"Baseline (configuration management)\",\"topicId\":\"3403\",\"url\":\"https://www.semanticscholar.org/topic/3403\"},{\"topic\":\"Modality (human\\u2013computer interaction)\",\"topicId\":\"462\",\"url\":\"https://www.semanticscholar.org/topic/462\"},{\"topic\":\"Modal logic\",\"topicId\":\"61528\",\"url\":\"https://www.semanticscholar.org/topic/61528\"},{\"topic\":\"Auditory processing disorder\",\"topicId\":\"394106\",\"url\":\"https://www.semanticscholar.org/topic/394106\"}],\"url\":\"https://www.semanticscholar.org/paper/05c846b122dc64b6900c09b9210912615a3febb6\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019}\n"