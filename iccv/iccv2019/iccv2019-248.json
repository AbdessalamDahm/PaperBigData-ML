"{\"abstract\":\"TASED-Net is a 3D fully-convolutional network architecture for video saliency detection. It consists of two building blocks: first, the encoder network extracts low-resolution spatiotemporal features from an input clip of several consecutive frames, and then the following prediction network decodes the encoded features spatially while aggregating all the temporal information. As a result, a single prediction map is produced from an input clip of multiple frames. Frame-wise saliency maps can be predicted by applying TASED-Net in a sliding-window fashion to a video. The proposed approach assumes that the saliency map of any frame can be predicted by considering a limited number of past frames. The results of our extensive experiments on video saliency detection validate this assumption and demonstrate that our fully-convolutional model with temporal aggregation method is effective. TASED-Net significantly outperforms previous state-of-the-art approaches on all three major large-scale datasets of video saliency detection: DHF1K, Hollywood2, and UCFSports. After analyzing the results qualitatively, we observe that our model is especially better at attending to salient moving objects.\",\"arxivId\":\"1908.05786\",\"authors\":[{\"authorId\":\"41018180\",\"name\":\"Kyle Min\",\"url\":\"https://www.semanticscholar.org/author/41018180\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\",\"url\":\"https://www.semanticscholar.org/author/3587688\"}],\"citationVelocity\":8,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"119923978\",\"name\":\"Yufan Liu\"},{\"authorId\":\"27647516\",\"name\":\"Minglang Qiao\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"1996319848\",\"name\":\"Bing Li\"},{\"authorId\":\"48594951\",\"name\":\"Weiming Hu\"},{\"authorId\":\"51004202\",\"name\":\"A. Borji\"}],\"doi\":\"10.1007/978-3-030-58565-5_25\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2e4da9223bbaea0dd7d4ed44f3cc0a7d1e7a3b17\",\"title\":\"Learning to Predict Salient Faces: A Novel Visual-Audio Saliency Model\",\"url\":\"https://www.semanticscholar.org/paper/2e4da9223bbaea0dd7d4ed44f3cc0a7d1e7a3b17\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2001.03063\",\"authors\":[{\"authorId\":\"3200442\",\"name\":\"A. Tsiami\"},{\"authorId\":\"2539459\",\"name\":\"Petros Koutras\"},{\"authorId\":\"1750686\",\"name\":\"P. Maragos\"}],\"doi\":\"10.1109/cvpr42600.2020.00482\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e296a1f529d9caa125e8c6a56cac61423e04b41b\",\"title\":\"STAViS: Spatio-Temporal AudioVisual Saliency Network\",\"url\":\"https://www.semanticscholar.org/paper/e296a1f529d9caa125e8c6a56cac61423e04b41b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2012.06170\",\"authors\":[{\"authorId\":\"151444035\",\"name\":\"Samyak Jain\"},{\"authorId\":\"34935738\",\"name\":\"Pradeep Yarlagadda\"},{\"authorId\":\"48236457\",\"name\":\"R. Subramanian\"},{\"authorId\":\"145091336\",\"name\":\"V. Gandhi\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"40a7f20cf6a05a481146bd7f18ba747d17700ebd\",\"title\":\"AViNet: Diving Deep into Audio-Visual Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/40a7f20cf6a05a481146bd7f18ba747d17700ebd\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1973281228\",\"name\":\"Ofir Dvir\"},{\"authorId\":\"49122049\",\"name\":\"P. Wolfson\"},{\"authorId\":\"90309075\",\"name\":\"L. Lovat\"},{\"authorId\":\"3140713\",\"name\":\"Robert Moskovitch\"}],\"doi\":\"10.1007/978-3-030-59137-3_36\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"111faff9bbbd180fdf4372ec940c7e46dfa7a094\",\"title\":\"Falls Prediction in Care Homes Using Mobile App Data Collection\",\"url\":\"https://www.semanticscholar.org/paper/111faff9bbbd180fdf4372ec940c7e46dfa7a094\",\"venue\":\"AIME\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150188542\",\"name\":\"Lai Jiang\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"15661018\",\"name\":\"Shanyi Zhang\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":\"10.1016/j.patcog.2020.107234\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"947b42503e78f29fd64ab864a76721dae8cad26e\",\"title\":\"DeepCT: A novel deep complex-valued network with learnable transform for video saliency prediction\",\"url\":\"https://www.semanticscholar.org/paper/947b42503e78f29fd64ab864a76721dae8cad26e\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30024940\",\"name\":\"Qiudan Zhang\"},{\"authorId\":\"72541446\",\"name\":\"Xu Wang\"},{\"authorId\":null,\"name\":\"Shiqi Wang\"},{\"authorId\":\"1390477390\",\"name\":\"Zhenhao Sun\"},{\"authorId\":\"1687386\",\"name\":\"S. Kwong\"},{\"authorId\":\"145931655\",\"name\":\"Jianmin Jiang\"}],\"doi\":\"10.1109/TIP.2020.2985531\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"917666c6ff2993f75dd77009ca41e69c81369707\",\"title\":\"Learning to Explore Saliency for Stereoscopic Videos Via Component-Based Interaction\",\"url\":\"https://www.semanticscholar.org/paper/917666c6ff2993f75dd77009ca41e69c81369707\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3404054\",\"name\":\"Y. Zhu\"},{\"authorId\":\"152867067\",\"name\":\"Dandan Zhu\"},{\"authorId\":\"46286370\",\"name\":\"Yiwei Yang\"},{\"authorId\":\"19269060\",\"name\":\"Huiyu Duan\"},{\"authorId\":\"2222210\",\"name\":\"Qiangqiang Zhou\"},{\"authorId\":\"2246414\",\"name\":\"Xiongkuo Min\"},{\"authorId\":\"66102996\",\"name\":\"Jian-Tao Zhou\"},{\"authorId\":\"144826391\",\"name\":\"Guangtao Zhai\"},{\"authorId\":\"50031361\",\"name\":\"X. Yang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"6eed131900c8ed2412acf7eecc70f472eb3b9b2b\",\"title\":\"A Saliency Dataset of Head and Eye Movements for Augmented Reality\",\"url\":\"https://www.semanticscholar.org/paper/6eed131900c8ed2412acf7eecc70f472eb3b9b2b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2010.01220\",\"authors\":[{\"authorId\":\"1986291097\",\"name\":\"Giovanni Bellitto\"},{\"authorId\":\"1985894550\",\"name\":\"Federica Proietto Salanitri\"},{\"authorId\":\"1409705906\",\"name\":\"S. Palazzo\"},{\"authorId\":\"50528328\",\"name\":\"F. Rundo\"},{\"authorId\":\"35906202\",\"name\":\"D. Giordano\"},{\"authorId\":\"2441118\",\"name\":\"C. Spampinato\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"36081963c58871adc8706e2cfcbf94872a42c5ae\",\"title\":\"Video Saliency Detection with Domain Adaptation using Hierarchical Gradient Reversal Layers\",\"url\":\"https://www.semanticscholar.org/paper/36081963c58871adc8706e2cfcbf94872a42c5ae\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.10600\",\"authors\":[{\"authorId\":\"1582477446\",\"name\":\"Yasser Abdelaziz Dahou Djilali\"},{\"authorId\":\"2028199013\",\"name\":\"Marouane Tliba\"},{\"authorId\":\"123746715\",\"name\":\"K. McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"39ebe1ff6f4087119fa9c70ff981f31b60613452\",\"title\":\"ATSal: An Attention Based Architecture for Saliency Prediction in 360 Videos\",\"url\":\"https://www.semanticscholar.org/paper/39ebe1ff6f4087119fa9c70ff981f31b60613452\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.05477\",\"authors\":[{\"authorId\":\"1430747783\",\"name\":\"Richard Droste\"},{\"authorId\":\"2840852\",\"name\":\"Jianbo Jiao\"},{\"authorId\":\"144870105\",\"name\":\"J. Noble\"}],\"doi\":\"10.1007/978-3-030-58558-7_25\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b01cb5c42ba693c84967bfd2ec94e420586164cc\",\"title\":\"Unified Image and Video Saliency Modeling\",\"url\":\"https://www.semanticscholar.org/paper/b01cb5c42ba693c84967bfd2ec94e420586164cc\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2001.00292\",\"authors\":[{\"authorId\":\"29874425\",\"name\":\"Jyun-Ruei Chen\"},{\"authorId\":\"2163097\",\"name\":\"Huihui Song\"},{\"authorId\":\"11735382\",\"name\":\"K. Zhang\"},{\"authorId\":\"35954057\",\"name\":\"Bo Liu\"},{\"authorId\":\"143960771\",\"name\":\"Qingshan Liu\"}],\"doi\":\"10.1016/j.patcog.2020.107615\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"866cedefb15e4a4a3f1b1cf3b9bd844654eb6af1\",\"title\":\"Video Saliency Prediction Using Enhanced Spatiotemporal Alignment Network\",\"url\":\"https://www.semanticscholar.org/paper/866cedefb15e4a4a3f1b1cf3b9bd844654eb6af1\",\"venue\":\"Pattern Recognit.\",\"year\":2021},{\"arxivId\":\"1911.08877\",\"authors\":[{\"authorId\":\"144719528\",\"name\":\"Lei Ding\"},{\"authorId\":\"145462888\",\"name\":\"Hao Tang\"},{\"authorId\":\"1698844\",\"name\":\"L. Bruzzone\"}],\"doi\":\"10.1109/TGRS.2020.2994150\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"005aacffcd3521e86f0ce4007ad2bd1de9189a62\",\"title\":\"Improving Semantic Segmentation of Aerial Images Using Patch-based Attention\",\"url\":\"https://www.semanticscholar.org/paper/005aacffcd3521e86f0ce4007ad2bd1de9189a62\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1753015\",\"name\":\"M. Michalowski\"},{\"authorId\":\"3140713\",\"name\":\"Robert Moskovitch\"},{\"authorId\":\"145960032\",\"name\":\"R. Goebel\"},{\"authorId\":\"144865865\",\"name\":\"Y. Tanaka\"}],\"doi\":\"10.1007/978-3-030-59137-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"70df3355dff10a9109d6450171208f1854d912aa\",\"title\":\"Artificial Intelligence in Medicine: 18th International Conference on Artificial Intelligence in Medicine, AIME 2020, Minneapolis, MN, USA, August 25\\u201328, 2020, Proceedings\",\"url\":\"https://www.semanticscholar.org/paper/70df3355dff10a9109d6450171208f1854d912aa\",\"venue\":\"AIME\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50528328\",\"name\":\"F. Rundo\"},{\"authorId\":\"1742452\",\"name\":\"S. Battiato\"},{\"authorId\":\"94403184\",\"name\":\"Francesca Trenta\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"3048fb2305606ee2fd5e452aaedf4ef6fb07e8ce\",\"title\":\"Innovative Saliency based Deep Driving Scene Understanding System for Automatic Safety Assessment in Next-Generation Cars\",\"url\":\"https://www.semanticscholar.org/paper/3048fb2305606ee2fd5e452aaedf4ef6fb07e8ce\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2083603\",\"name\":\"Tianfei Zhou\"},{\"authorId\":\"47785924\",\"name\":\"Jianwu Li\"},{\"authorId\":\"9437193\",\"name\":\"Shunzhou Wang\"},{\"authorId\":\"47599902\",\"name\":\"R. Tao\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"}],\"doi\":\"10.1109/TIP.2020.3013162\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a633a8537a0e5d0ac28ea3dec36caae5777d9ce7\",\"title\":\"MATNet: Motion-Attentive Transition Network for Zero-Shot Video Object Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/a633a8537a0e5d0ac28ea3dec36caae5777d9ce7\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1630843908\",\"name\":\"Inam Ullah\"},{\"authorId\":\"1783889\",\"name\":\"M. Jian\"},{\"authorId\":\"1630822963\",\"name\":\"Sumaira Hussain\"},{\"authorId\":\"47093250\",\"name\":\"J. Guo\"},{\"authorId\":\"48002941\",\"name\":\"H. Yu\"},{\"authorId\":\"50142726\",\"name\":\"X. Wang\"},{\"authorId\":\"102446355\",\"name\":\"Y. Yin\"}],\"doi\":\"10.1007/s11042-020-08849-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"24012fe3970da6c1a3ef7918ce7f40346a0b714c\",\"title\":\"A brief survey of visual saliency detection\",\"url\":\"https://www.semanticscholar.org/paper/24012fe3970da6c1a3ef7918ce7f40346a0b714c\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2007931\",\"name\":\"Kao Zhang\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"},{\"authorId\":\"1792817\",\"name\":\"S. Liu\"}],\"doi\":\"10.1109/TIP.2020.3036749\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"51b23ce1f48d769a31a4a4f4982fbfe5d4de41f4\",\"title\":\"A Spatial-Temporal Recurrent Neural Network for Video Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/51b23ce1f48d769a31a4a4f4982fbfe5d4de41f4\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2021},{\"arxivId\":\"1912.05971\",\"authors\":[{\"authorId\":\"3404054\",\"name\":\"Y. Zhu\"},{\"authorId\":\"2246414\",\"name\":\"Xiongkuo Min\"},{\"authorId\":\"152867067\",\"name\":\"Dandan Zhu\"},{\"authorId\":\"1474358241\",\"name\":\"Ke Gu\"},{\"authorId\":\"66102996\",\"name\":\"Jian-Tao Zhou\"},{\"authorId\":\"144826391\",\"name\":\"Guangtao Zhai\"},{\"authorId\":\"15469693\",\"name\":\"Xiaokang Yang\"},{\"authorId\":\"153645488\",\"name\":\"W. Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0bd5d09cbe11ff6afa763529dd7bebde89dbe1f4\",\"title\":\"Toward Better Understanding of Saliency Prediction in Augmented 360 Degree Videos\",\"url\":\"https://www.semanticscholar.org/paper/0bd5d09cbe11ff6afa763529dd7bebde89dbe1f4\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1910.02793\",\"authors\":[{\"authorId\":\"144487556\",\"name\":\"Madan Ravi Ganesh\"},{\"authorId\":\"24337238\",\"name\":\"Eric Hofesmann\"},{\"authorId\":\"46184233\",\"name\":\"N. Louis\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4dfaa337fb4cc3d7f755c258f192edc774f601fc\",\"title\":\"ViP: Video Platform for PyTorch\",\"url\":\"https://www.semanticscholar.org/paper/4dfaa337fb4cc3d7f755c258f192edc774f601fc\",\"venue\":\"ArXiv\",\"year\":2019}],\"corpusId\":201058496,\"doi\":\"10.1109/ICCV.2019.00248\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":9,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"5b93aaf71e4c18d304ab9b3e77598cb0423d0952\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"144361581\",\"name\":\"J. Long\"},{\"authorId\":\"1782282\",\"name\":\"Evan Shelhamer\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/CVPR.2015.7298965\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9201bf6f8222c2335913002e13fbac640fc0f4ec\",\"title\":\"Fully convolutional networks for semantic segmentation\",\"url\":\"https://www.semanticscholar.org/paper/9201bf6f8222c2335913002e13fbac640fc0f4ec\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1511.00561\",\"authors\":[{\"authorId\":\"2442177\",\"name\":\"Vijay Badrinarayanan\"},{\"authorId\":\"47645184\",\"name\":\"Alex Kendall\"},{\"authorId\":\"1745672\",\"name\":\"R. Cipolla\"}],\"doi\":\"10.1109/TPAMI.2016.2644615\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b0c065cd43aa7280e766b5dcbcc7e26abce59330\",\"title\":\"SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/b0c065cd43aa7280e766b5dcbcc7e26abce59330\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jonathan Harel\"},{\"authorId\":null,\"name\":\"Christof Koch\"},{\"authorId\":null,\"name\":\"Pietro Perona\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Graphbased visual saliency\",\"url\":\"\",\"venue\":\"In Advances in neural information processing systems,\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50814507\",\"name\":\"Cagdas Bak\"},{\"authorId\":\"3044594\",\"name\":\"Aysun Kocak\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"}],\"doi\":\"10.1109/TMM.2017.2777665\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1ebd1083ad9e10ed2feded8319c5d472bf9f420b\",\"title\":\"Spatio-Temporal Saliency Networks for Dynamic Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/1ebd1083ad9e10ed2feded8319c5d472bf9f420b\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3502855\",\"name\":\"M. Marszalek\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/CVPR.2009.5206557\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c26906b6dab02083ffd01fd27d9087597999bc0e\",\"title\":\"Actions in context\",\"url\":\"https://www.semanticscholar.org/paper/c26906b6dab02083ffd01fd27d9087597999bc0e\",\"venue\":\"CVPR\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144645142\",\"name\":\"M. Jiang\"},{\"authorId\":\"1961257\",\"name\":\"Shengsheng Huang\"},{\"authorId\":\"2104164\",\"name\":\"Juanyong Duan\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1109/CVPR.2015.7298710\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c71db5d3546e22227662ee0f0ce586495ef18899\",\"title\":\"SALICON: Saliency in Context\",\"url\":\"https://www.semanticscholar.org/paper/c71db5d3546e22227662ee0f0ce586495ef18899\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1709.06316\",\"authors\":[{\"authorId\":\"47420847\",\"name\":\"Lai Jiang\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"}],\"doi\":\"10.1007/978-3-030-01264-9_37\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"fb0942800a4bc36881785d1bd878b5e8c95d9fe4\",\"title\":\"Predicting Video Saliency with Object-to-Motion CNN and Two-layer Convolutional LSTM\",\"url\":\"https://www.semanticscholar.org/paper/fb0942800a4bc36881785d1bd878b5e8c95d9fe4\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"91447021\",\"name\":\"H. Mueller\"},{\"authorId\":\"145698573\",\"name\":\"J. Maxwell\"}],\"doi\":\"10.1037//0096-1523.20.2.397\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7f8ccbf18d7b14bb6e1895346e1efa92f5c76ef4\",\"title\":\"Perceptual integration of motion and form information: is the movement filter involved in form discrimination?\",\"url\":\"https://www.semanticscholar.org/paper/7f8ccbf18d7b14bb6e1895346e1efa92f5c76ef4\",\"venue\":\"Journal of experimental psychology. Human perception and performance\",\"year\":1994},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"}],\"doi\":\"10.1007/978-3-319-09396-3_9\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a3f78cc944ac189632f25925ba807a0e0678c4d5\",\"title\":\"Action Recognition in Realistic Sports Videos\",\"url\":\"https://www.semanticscholar.org/paper/a3f78cc944ac189632f25925ba807a0e0678c4d5\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"134861178\",\"name\":\"Wei Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPRW.2009.5206848\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d2c733e34d48784a37d717fe43d9e93277a8c53e\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/d2c733e34d48784a37d717fe43d9e93277a8c53e\",\"venue\":\"2009 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2009},{\"arxivId\":\"1604.03605\",\"authors\":[{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"},{\"authorId\":\"152627906\",\"name\":\"T. Judd\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"}],\"doi\":\"10.1109/TPAMI.2018.2815601\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bfdf3431ff5182b585b3b0c11fa8cbfc13a6bde4\",\"title\":\"What Do Different Evaluation Metrics Tell Us About Saliency Models?\",\"url\":\"https://www.semanticscholar.org/paper/bfdf3431ff5182b585b3b0c11fa8cbfc13a6bde4\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1801.07424\",\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"143929120\",\"name\":\"F. Guo\"},{\"authorId\":\"37535930\",\"name\":\"Ming-Ming Cheng\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":\"10.1109/CVPR.2018.00514\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fdf8c9c4c30c6005c2f0e92ce9db3de5ab8b5d29\",\"title\":\"Revisiting Video Saliency: A Large-Scale Benchmark and a New Model\",\"url\":\"https://www.semanticscholar.org/paper/fdf8c9c4c30c6005c2f0e92ce9db3de5ab8b5d29\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1685004\",\"name\":\"H. Hadizadeh\"},{\"authorId\":\"1730101\",\"name\":\"I. Bajic\"}],\"doi\":\"10.1109/TIP.2013.2282897\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"edf3d2f5ad0473698fcdb5dad712734ef1365524\",\"title\":\"Saliency-Aware Video Compression\",\"url\":\"https://www.semanticscholar.org/paper/edf3d2f5ad0473698fcdb5dad712734ef1365524\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"148372530\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"147183308\",\"name\":\"Jianbing Shen\"}],\"doi\":\"10.1109/TIP.2017.2787612\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"82ea489619d8e69ac0d49d07bb85e3b523d1c842\",\"title\":\"Deep Visual Attention Prediction.\",\"url\":\"https://www.semanticscholar.org/paper/82ea489619d8e69ac0d49d07bb85e3b523d1c842\",\"venue\":\"IEEE transactions on image processing : a publication of the IEEE Signal Processing Society\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144247007\",\"name\":\"X. Huang\"},{\"authorId\":\"3329744\",\"name\":\"Chengyao Shen\"},{\"authorId\":\"2343486\",\"name\":\"X. Boix\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1109/ICCV.2015.38\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1281e443d2cf1c1dd71ed3b7b0376d408d0958af\",\"title\":\"SALICON: Reducing the Semantic Gap in Saliency Prediction by Adapting Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/1281e443d2cf1c1dd71ed3b7b0376d408d0958af\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144375727\",\"name\":\"R. Desimone\"},{\"authorId\":\"47479075\",\"name\":\"J. Duncan\"}],\"doi\":\"10.1146/ANNUREV.NE.18.030195.001205\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5d2ef51c912df93d31314d6827a98bc474374105\",\"title\":\"Neural mechanisms of selective visual attention.\",\"url\":\"https://www.semanticscholar.org/paper/5d2ef51c912df93d31314d6827a98bc474374105\",\"venue\":\"Annual review of neuroscience\",\"year\":1995},{\"arxivId\":\"1711.07971\",\"authors\":[{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"}],\"doi\":\"10.1109/CVPR.2018.00813\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8899094797e82c5c185a0893896320ef77f60e64\",\"title\":\"Non-local Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/8899094797e82c5c185a0893896320ef77f60e64\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123135459\",\"name\":\"Mikel D. Rodriguez\"},{\"authorId\":\"144643948\",\"name\":\"Javed Ahmed\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/CVPR.2008.4587727\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1c2629d53fd73ee42fb9a67b4d656688ef6a005f\",\"title\":\"Action MACH a spatio-temporal Maximum Average Correlation Height filter for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/1c2629d53fd73ee42fb9a67b4d656688ef6a005f\",\"venue\":\"2008 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2008},{\"arxivId\":\"1701.01081\",\"authors\":[{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"},{\"authorId\":\"1399086207\",\"name\":\"C. Canton-Ferrer\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"},{\"authorId\":\"147166602\",\"name\":\"J. Torres\"},{\"authorId\":\"2470219\",\"name\":\"E. Sayrol\"},{\"authorId\":\"3100480\",\"name\":\"Xavier Giro-i-Nieto\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"258fad95e709b6d0572ae6cc99efbbb14d32bdf2\",\"title\":\"SalGAN: Visual Saliency Prediction with Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/258fad95e709b6d0572ae6cc99efbbb14d32bdf2\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1921500\",\"name\":\"Y. Tong\"},{\"authorId\":\"1795667\",\"name\":\"F. A. Cheikh\"},{\"authorId\":\"2770986\",\"name\":\"Fahad Fazal Elahi Guraya\"},{\"authorId\":\"1971616\",\"name\":\"H. Konik\"},{\"authorId\":\"1704567\",\"name\":\"A. Tr\\u00e9meau\"}],\"doi\":\"10.1007/s12559-010-9094-8\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c96ae7f50a449cf632702e1ceb86fb1a314ec5a4\",\"title\":\"A Spatiotemporal Saliency Model for Video Surveillance\",\"url\":\"https://www.semanticscholar.org/paper/c96ae7f50a449cf632702e1ceb86fb1a314ec5a4\",\"venue\":\"Cognitive Computation\",\"year\":2010},{\"arxivId\":\"1409.4842\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"46641766\",\"name\":\"W. Liu\"},{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"},{\"authorId\":\"48840704\",\"name\":\"Scott Reed\"},{\"authorId\":\"1838674\",\"name\":\"Dragomir Anguelov\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"39863668\",\"name\":\"Andrew Rabinovich\"}],\"doi\":\"10.1109/CVPR.2015.7298594\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"title\":\"Going deeper with convolutions\",\"url\":\"https://www.semanticscholar.org/paper/e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1502.03167\",\"authors\":[{\"authorId\":\"144147316\",\"name\":\"S. Ioffe\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4d376d6978dad0374edfa6709c9556b42d3594d3\",\"title\":\"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\",\"url\":\"https://www.semanticscholar.org/paper/4d376d6978dad0374edfa6709c9556b42d3594d3\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72436419\",\"name\":\"\\ud55c\\ubcf4\\ud615\"},{\"authorId\":\"70063817\",\"name\":\"\\ud64d\\uc2b9\\ud6c8\"},{\"authorId\":\"66219957\",\"name\":\"\\ub178\\ud604\\uc6b0\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"da574437bde83aaa879f6285cf0a2676c85219bf\",\"title\":\"Learning Deconvolution Network for Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/da574437bde83aaa879f6285cf0a2676c85219bf\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1506.02640\",\"authors\":[{\"authorId\":\"40497777\",\"name\":\"Joseph Redmon\"},{\"authorId\":\"2038685\",\"name\":\"S. Divvala\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"47465174\",\"name\":\"Ali Farhadi\"}],\"doi\":\"10.1109/CVPR.2016.91\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f8e79ac0ea341056ef20f2616628b3e964764cfd\",\"title\":\"You Only Look Once: Unified, Real-Time Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/f8e79ac0ea341056ef20f2616628b3e964764cfd\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1941997\",\"name\":\"Chenlei Guo\"},{\"authorId\":\"29906646\",\"name\":\"L. Zhang\"}],\"doi\":\"10.1109/TIP.2009.2030969\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"01825573781674bcf85d0f5d2ec456842f75ad3c\",\"title\":\"A Novel Multiresolution Spatiotemporal Saliency Detection Model and Its Applications in Image and Video Compression\",\"url\":\"https://www.semanticscholar.org/paper/01825573781674bcf85d0f5d2ec456842f75ad3c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2770986\",\"name\":\"Fahad Fazal Elahi Guraya\"},{\"authorId\":\"1795667\",\"name\":\"F. A. Cheikh\"},{\"authorId\":\"1704567\",\"name\":\"A. Tr\\u00e9meau\"},{\"authorId\":\"1921500\",\"name\":\"Y. Tong\"},{\"authorId\":\"1971616\",\"name\":\"H. Konik\"}],\"doi\":\"10.1109/DCABES.2010.160\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eaabafd9b6816cae950c603b0f5789b75e626df9\",\"title\":\"Predictive Saliency Maps for Surveillance Videos\",\"url\":\"https://www.semanticscholar.org/paper/eaabafd9b6816cae950c603b0f5789b75e626df9\",\"venue\":\"2010 Ninth International Symposium on Distributed Computing and Applications to Business, Engineering and Science\",\"year\":2010},{\"arxivId\":\"1606.00915\",\"authors\":[{\"authorId\":\"34192119\",\"name\":\"Liang-Chieh Chen\"},{\"authorId\":\"2776496\",\"name\":\"G. Papandreou\"},{\"authorId\":\"2010660\",\"name\":\"I. Kokkinos\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.1109/TPAMI.2017.2699184\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cab372bc3824780cce20d9dd1c22d4df39ed081a\",\"title\":\"DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs\",\"url\":\"https://www.semanticscholar.org/paper/cab372bc3824780cce20d9dd1c22d4df39ed081a\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145557639\",\"name\":\"V. Nair\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a538b05ebb01a40323997629e171c91aa28b8e2f\",\"title\":\"Rectified Linear Units Improve Restricted Boltzmann Machines\",\"url\":\"https://www.semanticscholar.org/paper/a538b05ebb01a40323997629e171c91aa28b8e2f\",\"venue\":\"ICML\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34646933\",\"name\":\"T. V. Nguyen\"},{\"authorId\":\"1775497\",\"name\":\"Mengdi Xu\"},{\"authorId\":\"36264491\",\"name\":\"Guangyu Gao\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"}],\"doi\":\"10.1145/2502081.2502128\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"04f74bf0d88ca566cd75804e3e48fc36c22c47f4\",\"title\":\"Static saliency vs. dynamic saliency: a comparative study\",\"url\":\"https://www.semanticscholar.org/paper/04f74bf0d88ca566cd75804e3e48fc36c22c47f4\",\"venue\":\"MM '13\",\"year\":2013},{\"arxivId\":\"1705.06950\",\"authors\":[{\"authorId\":\"21028601\",\"name\":\"W. Kay\"},{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"11809518\",\"name\":\"Brian Zhang\"},{\"authorId\":\"38961760\",\"name\":\"Chloe Hillier\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"143740871\",\"name\":\"F. Viola\"},{\"authorId\":\"143897708\",\"name\":\"T. Green\"},{\"authorId\":\"2830305\",\"name\":\"T. Back\"},{\"authorId\":\"1820908\",\"name\":\"A. Natsev\"},{\"authorId\":\"2573615\",\"name\":\"Mustafa Suleyman\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6\",\"title\":\"The Kinetics Human Action Video Dataset\",\"url\":\"https://www.semanticscholar.org/paper/86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48799969\",\"name\":\"Matthew D. Zeiler\"},{\"authorId\":\"144639556\",\"name\":\"Graham W. Taylor\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":\"10.1109/ICCV.2011.6126474\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d743430cb2329caa5d446c17fc9ec07f5e916ab0\",\"title\":\"Adaptive deconvolutional networks for mid and high level feature learning\",\"url\":\"https://www.semanticscholar.org/paper/d743430cb2329caa5d446c17fc9ec07f5e916ab0\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":\"1312.7570\",\"authors\":[{\"authorId\":\"37710702\",\"name\":\"Stefan Mathe\"},{\"authorId\":\"1781120\",\"name\":\"C. Sminchisescu\"}],\"doi\":\"10.1109/TPAMI.2014.2366154\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e254d0e670ce8217e74aaf1421c72e63e62929e3\",\"title\":\"Actions in the Eye: Dynamic Gaze Datasets and Learnt Saliency Models for Visual Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e254d0e670ce8217e74aaf1421c72e63e62929e3\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37169448\",\"name\":\"T. Moore\"},{\"authorId\":\"46596581\",\"name\":\"Marc Zirnsak\"}],\"doi\":\"10.1146/annurev-psych-122414-033400\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"395bfed326500e9f86d0a41f099691f0990de34d\",\"title\":\"Neural Mechanisms of Selective Visual Attention.\",\"url\":\"https://www.semanticscholar.org/paper/395bfed326500e9f86d0a41f099691f0990de34d\",\"venue\":\"Annual review of psychology\",\"year\":2017},{\"arxivId\":\"1711.09577\",\"authors\":[{\"authorId\":\"2199251\",\"name\":\"K. Hara\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"}],\"doi\":\"10.1109/CVPR.2018.00685\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d716435f0cb0cac56237f74b1ced940aabce6a2b\",\"title\":\"Can Spatiotemporal 3D CNNs Retrace the History of 2D CNNs and ImageNet?\",\"url\":\"https://www.semanticscholar.org/paper/d716435f0cb0cac56237f74b1ced940aabce6a2b\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1802.02611\",\"authors\":[{\"authorId\":\"34192119\",\"name\":\"Liang-Chieh Chen\"},{\"authorId\":\"2214033\",\"name\":\"Y. Zhu\"},{\"authorId\":\"2776496\",\"name\":\"G. Papandreou\"},{\"authorId\":\"3302320\",\"name\":\"Florian Schroff\"},{\"authorId\":\"2595180\",\"name\":\"H. Adam\"}],\"doi\":\"10.1007/978-3-030-01234-2_49\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9217e28b2273eb3b26e4e9b7b498b4661e6e09f5\",\"title\":\"Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/9217e28b2273eb3b26e4e9b7b498b4661e6e09f5\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1505.04597\",\"authors\":[{\"authorId\":\"1737326\",\"name\":\"O. Ronneberger\"},{\"authorId\":\"152702479\",\"name\":\"P. Fischer\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1007/978-3-319-24574-4_28\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6364fdaa0a0eccd823a779fcdd489173f938e91a\",\"title\":\"U-Net: Convolutional Networks for Biomedical Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/6364fdaa0a0eccd823a779fcdd489173f938e91a\",\"venue\":\"MICCAI\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1162/neco.1997.9.8.1735\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"title\":\"Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"venue\":\"Neural Computation\",\"year\":1997},{\"arxivId\":\"1504.06852\",\"authors\":[{\"authorId\":\"1382344214\",\"name\":\"A. Dosovitskiy\"},{\"authorId\":\"152702479\",\"name\":\"P. Fischer\"},{\"authorId\":\"48105320\",\"name\":\"Eddy Ilg\"},{\"authorId\":\"2880264\",\"name\":\"Philip H\\u00e4usser\"},{\"authorId\":\"3322806\",\"name\":\"Caner Hazirbas\"},{\"authorId\":\"2943639\",\"name\":\"V. Golkov\"},{\"authorId\":\"1715782\",\"name\":\"P. V. D. Smagt\"},{\"authorId\":\"153685345\",\"name\":\"D. Cremers\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1109/ICCV.2015.316\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c2fb5b39428818d7ec8cc78e152e19c21b7db568\",\"title\":\"FlowNet: Learning Optical Flow with Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/c2fb5b39428818d7ec8cc78e152e19c21b7db568\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/ICCV.2015.510\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"title\":\"Learning Spatiotemporal Features with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1603.08199\",\"authors\":[{\"authorId\":\"1809420\",\"name\":\"Loris Bazzani\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f3158ce4e1c9e908e7d06533d711d84205c973b9\",\"title\":\"Recurrent Mixture Density Network for Spatiotemporal Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/f3158ce4e1c9e908e7d06533d711d84205c973b9\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1705.07750\",\"authors\":[{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2017.502\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"title\":\"Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset\",\"url\":\"https://www.semanticscholar.org/paper/b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1603.00845\",\"authors\":[{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"},{\"authorId\":\"2470219\",\"name\":\"E. Sayrol\"},{\"authorId\":\"3100480\",\"name\":\"Xavier Giro-i-Nieto\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"}],\"doi\":\"10.1109/CVPR.2016.71\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9528e2e8c20517ab916f803c0371abb4f0ed488b\",\"title\":\"Shallow and Deep Convolutional Networks for Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/9528e2e8c20517ab916f803c0371abb4f0ed488b\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1712.04851\",\"authors\":[{\"authorId\":\"1817030\",\"name\":\"Saining Xie\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"1808244\",\"name\":\"J. Huang\"},{\"authorId\":\"144035504\",\"name\":\"Zhuowen Tu\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":\"10.1007/978-3-030-01267-0_19\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"815aa52cfc02961d82415f080384594639a21984\",\"title\":\"Rethinking Spatiotemporal Feature Learning: Speed-Accuracy Trade-offs in Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/815aa52cfc02961d82415f080384594639a21984\",\"venue\":\"ECCV\",\"year\":2018}],\"title\":\"TASED-Net: Temporally-Aggregating Spatial Encoder-Decoder Network for Video Saliency Detection\",\"topics\":[{\"topic\":\"Encoder\",\"topicId\":\"16744\",\"url\":\"https://www.semanticscholar.org/topic/16744\"},{\"topic\":\"Network architecture\",\"topicId\":\"58473\",\"url\":\"https://www.semanticscholar.org/topic/58473\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Map\",\"topicId\":\"2392\",\"url\":\"https://www.semanticscholar.org/topic/2392\"}],\"url\":\"https://www.semanticscholar.org/paper/5b93aaf71e4c18d304ab9b3e77598cb0423d0952\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019}\n"