"{\"abstract\":\"Attention mechanisms are widely used in current encoder/decoder frameworks of image captioning, where a weighted average on encoded vectors is generated at each time step to guide the caption decoding process. However, the decoder has little idea of whether or how well the attended vector and the given attention query are related, which could make the decoder give misled results. In this paper, we propose an Attention on Attention (AoA) module, which extends the conventional attention mechanisms to determine the relevance between attention results and queries. AoA first generates an information vector and an attention gate using the attention result and the current context, then adds another attention by applying element-wise multiplication to them and finally obtains the attended information, the expected useful knowledge. We apply AoA to both the encoder and the decoder of our image captioning model, which we name as AoA Network (AoANet). Experiments show that AoANet outperforms all previously published methods and achieves a new state-of-the-art performance of 129.8 CIDEr-D score on MS COCO Karpathy offline test split and 129.6 CIDEr-D (C40) score on the official online testing server. Code is available at https://github.com/husthuaan/AoANet.\",\"arxivId\":\"1908.06954\",\"authors\":[{\"authorId\":\"48544896\",\"name\":\"Lun Huang\",\"url\":\"https://www.semanticscholar.org/author/48544896\"},{\"authorId\":\"46315174\",\"name\":\"Wenmin Wang\",\"url\":\"https://www.semanticscholar.org/author/46315174\"},{\"authorId\":\"40445654\",\"name\":\"J. Chen\",\"url\":\"https://www.semanticscholar.org/author/40445654\"},{\"authorId\":\"144539992\",\"name\":\"Xiao-Yong Wei\",\"url\":\"https://www.semanticscholar.org/author/144539992\"}],\"citationVelocity\":40,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"},{\"authorId\":\"1796216614\",\"name\":\"Siyu Huang\"},{\"authorId\":\"40518823\",\"name\":\"Haoyi Xiong\"},{\"authorId\":\"7824051\",\"name\":\"Xingjian Li\"},{\"authorId\":\"1721158\",\"name\":\"D. Dou\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"652885a326e1b5b978f4abeeb88e5fe518733f7e\",\"title\":\"Neighbours Matter: Image Captioning with Similar Images\",\"url\":\"https://www.semanticscholar.org/paper/652885a326e1b5b978f4abeeb88e5fe518733f7e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2008.02448\",\"authors\":[{\"authorId\":\"51912474\",\"name\":\"Xiaoye Qu\"},{\"authorId\":\"1855095179\",\"name\":\"Pengwei Tang\"},{\"authorId\":\"3008849\",\"name\":\"Zhikang Zhou\"},{\"authorId\":\"5524736\",\"name\":\"Y. Cheng\"},{\"authorId\":\"40240283\",\"name\":\"J. Dong\"},{\"authorId\":\"145232778\",\"name\":\"Pan Zhou\"}],\"doi\":\"10.1145/3394171.3414053\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a4d78df0b175e3cbf811e652184f6b1e9d11caca\",\"title\":\"Fine-grained Iterative Attention Network for Temporal Language Localization in Videos\",\"url\":\"https://www.semanticscholar.org/paper/a4d78df0b175e3cbf811e652184f6b1e9d11caca\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2004.05828\",\"authors\":[{\"authorId\":\"1387898803\",\"name\":\"Ziqing Ma\"},{\"authorId\":\"48641863\",\"name\":\"Shuming Liu\"},{\"authorId\":\"84056987\",\"name\":\"Guancheng Guo\"},{\"authorId\":\"8769191\",\"name\":\"Xipeng Yu\"}],\"doi\":\"10.1109/lgrs.2020.3030839\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"efe49a78e474ec07454f05d86e8ff977e14606f0\",\"title\":\"Hybrid Attention Networks for Flow and Pressure Forecasting in Water Distribution Systems\",\"url\":\"https://www.semanticscholar.org/paper/efe49a78e474ec07454f05d86e8ff977e14606f0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49251978\",\"name\":\"J. Chen\"},{\"authorId\":\"41079034\",\"name\":\"Hong-Yang Chao\"}],\"doi\":\"10.1145/3394171.3416291\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"598ad06c164043c45c952dbde37e0c75991e66aa\",\"title\":\"VideoTRM: Pre-training for Video Captioning Challenge 2020\",\"url\":\"https://www.semanticscholar.org/paper/598ad06c164043c45c952dbde37e0c75991e66aa\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2003.03107\",\"authors\":[{\"authorId\":\"32095408\",\"name\":\"Fawaz Sammani\"},{\"authorId\":\"1411260673\",\"name\":\"Luke Melas-Kyriazi\"}],\"doi\":\"10.1109/cvpr42600.2020.00486\",\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"e9419436682726232e1b37a04c53bba919b12025\",\"title\":\"Show, Edit and Tell: A Framework for Editing Image Captions\",\"url\":\"https://www.semanticscholar.org/paper/e9419436682726232e1b37a04c53bba919b12025\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2003.14080\",\"authors\":[{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"1490772804\",\"name\":\"Tao Mei\"}],\"doi\":\"10.1109/cvpr42600.2020.01098\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4adfa7b83342b77c830f2b0f6fc1b784c21e7ed0\",\"title\":\"X-Linear Attention Networks for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/4adfa7b83342b77c830f2b0f6fc1b784c21e7ed0\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2012.09742\",\"authors\":[{\"authorId\":\"48386951\",\"name\":\"Xinxin Zhu\"},{\"authorId\":\"49336560\",\"name\":\"Weining Wang\"},{\"authorId\":\"26982950\",\"name\":\"Longteng Guo\"},{\"authorId\":null,\"name\":\"Jing Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb3f19de52d330ded5b3eebb79b89876648f67cb\",\"title\":\"AutoCaption: Image Captioning with Neural Architecture Search\",\"url\":\"https://www.semanticscholar.org/paper/eb3f19de52d330ded5b3eebb79b89876648f67cb\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2012.04638\",\"authors\":[{\"authorId\":\"21518096\",\"name\":\"Zhengyuan Yang\"},{\"authorId\":\"38534822\",\"name\":\"Y. Lu\"},{\"authorId\":\"46583994\",\"name\":\"Jianfeng Wang\"},{\"authorId\":\"1629039205\",\"name\":\"Xi Yin\"},{\"authorId\":\"1882479\",\"name\":\"D. Flor\\u00eancio\"},{\"authorId\":\"30602591\",\"name\":\"Lijuan Wang\"},{\"authorId\":\"1706673\",\"name\":\"C. Zhang\"},{\"authorId\":\"145637095\",\"name\":\"Lei Zhang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8deceb13cb3afcfbaab06a2c655f1935445635fe\",\"title\":\"TAP: Text-Aware Pre-training for Text-VQA and Text-Caption\",\"url\":\"https://www.semanticscholar.org/paper/8deceb13cb3afcfbaab06a2c655f1935445635fe\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.13122\",\"authors\":[{\"authorId\":\"48394426\",\"name\":\"Naeha Sharif\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"40366581\",\"name\":\"Wei Liu\"},{\"authorId\":\"14752125\",\"name\":\"Syed Afaq Ali Shah\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5318abd4f12a5b25c2847e9c66713951341af504\",\"title\":\"SubICap: Towards Subword-informed Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/5318abd4f12a5b25c2847e9c66713951341af504\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1931096\",\"name\":\"A. Behera\"},{\"authorId\":\"70249755\",\"name\":\"Zachary Wharton\"},{\"authorId\":\"32349358\",\"name\":\"Pradeep Ruwan Padmasiri Galbokka Hewage\"},{\"authorId\":\"40578964\",\"name\":\"S. Kumar\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d4b060b16329c6e44cc78b0e293f8c7ba3ca5a01\",\"title\":\"Rotation Axis Focused Attention Network (RAFA-Net) for Estimating Head Pose\",\"url\":\"https://www.semanticscholar.org/paper/d4b060b16329c6e44cc78b0e293f8c7ba3ca5a01\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143696833\",\"name\":\"Wenjie Cai\"},{\"authorId\":\"47362438\",\"name\":\"Q. Liu\"}],\"doi\":\"10.1016/j.neucom.2020.06.112\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c218331cf31c32c46eb660c1b2ce3e506c99b3b0\",\"title\":\"Image captioning with semantic-enhanced features and extremely hard negative examples\",\"url\":\"https://www.semanticscholar.org/paper/c218331cf31c32c46eb660c1b2ce3e506c99b3b0\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"39290858e39fb6e2a7d8b9685cbb854fa7da222f\",\"title\":\"Combining NLP and Computer Vision to Help Blind People\",\"url\":\"https://www.semanticscholar.org/paper/39290858e39fb6e2a7d8b9685cbb854fa7da222f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2012.06946\",\"authors\":[{\"authorId\":\"46583603\",\"name\":\"J. Wang\"},{\"authorId\":\"50049779\",\"name\":\"X. Hu\"},{\"authorId\":\"9325940\",\"name\":\"Pengchuan Zhang\"},{\"authorId\":\"47058148\",\"name\":\"Xiujun Li\"},{\"authorId\":\"29957038\",\"name\":\"Longguang Wang\"},{\"authorId\":\"1720539\",\"name\":\"L. Zhang\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"1691128\",\"name\":\"Zicheng Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"41171e9024d0082c2a57f4887bac93131669b881\",\"title\":\"MiniVLM: A Smaller and Faster Vision-Language Model\",\"url\":\"https://www.semanticscholar.org/paper/41171e9024d0082c2a57f4887bac93131669b881\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2009.03949\",\"authors\":[{\"authorId\":\"1699605396\",\"name\":\"Zeyu Wang\"},{\"authorId\":\"114200472\",\"name\":\"Berthy Feng\"},{\"authorId\":\"144958935\",\"name\":\"Karthik Narasimhan\"},{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"}],\"doi\":\"10.1007/978-3-030-58571-6_37\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"81be56a5783552d5b32463b392ff0499dd86a5ab\",\"title\":\"Towards Unique and Informative Captioning of Images\",\"url\":\"https://www.semanticscholar.org/paper/81be56a5783552d5b32463b392ff0499dd86a5ab\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2011.02164\",\"authors\":[{\"authorId\":\"49172303\",\"name\":\"T. Rahman\"},{\"authorId\":\"6937593\",\"name\":\"Shih-Han Chou\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"1387254703\",\"name\":\"Giuseppe Carenini\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"e1cf7e279abc4301729c24cb7f888b2df42f7644\",\"title\":\"An Improved Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e1cf7e279abc4301729c24cb7f888b2df42f7644\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47210449\",\"name\":\"W. Xu\"},{\"authorId\":\"1605316613\",\"name\":\"Jing He\"},{\"authorId\":\"48085005\",\"name\":\"Yanfeng Shu\"},{\"authorId\":\"1738774176\",\"name\":\"Hui Zheng\"}],\"doi\":\"10.5772/intechopen.93512\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2f4881253e6428bb48a108e09edf3b53fa6071e1\",\"title\":\"Advances in Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/2f4881253e6428bb48a108e09edf3b53fa6071e1\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2007.09580\",\"authors\":[{\"authorId\":\"41036094\",\"name\":\"C. Deng\"},{\"authorId\":\"46649124\",\"name\":\"Ning Ding\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"},{\"authorId\":\"1509240145\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1007/978-3-030-58601-0_42\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2320f853059c29ce7e70409fa559074d727da5a2\",\"title\":\"Length-Controllable Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/2320f853059c29ce7e70409fa559074d727da5a2\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2038515405\",\"name\":\"Yazid Bounab\"},{\"authorId\":\"1471224685\",\"name\":\"Mourad Oussalah\"},{\"authorId\":\"2038543683\",\"name\":\"Ahlam Ferdenache\"}],\"doi\":\"10.1109/IPTA50016.2020.9286602\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"12246cc5d29c1d8d7177d7a6e820fe3038ccd1d5\",\"title\":\"Reconciling Image Captioning and User\\u2019s Comments for Urban Tourism\",\"url\":\"https://www.semanticscholar.org/paper/12246cc5d29c1d8d7177d7a6e820fe3038ccd1d5\",\"venue\":\"2020 Tenth International Conference on Image Processing Theory, Tools and Applications (IPTA)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1954481\",\"name\":\"D. Huynh\"},{\"authorId\":\"47126776\",\"name\":\"E. Elhamifar\"}],\"doi\":\"10.1109/cvpr42600.2020.00454\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ed0e117152196693a42fd845740ca08ae1d5ef8a\",\"title\":\"Fine-Grained Generalized Zero-Shot Learning via Dense Attribute-Based Attention\",\"url\":\"https://www.semanticscholar.org/paper/ed0e117152196693a42fd845740ca08ae1d5ef8a\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2004.06165\",\"authors\":[{\"authorId\":\"47058148\",\"name\":\"Xiujun Li\"},{\"authorId\":\"1629039205\",\"name\":\"Xi Yin\"},{\"authorId\":\"1978606\",\"name\":\"C. Li\"},{\"authorId\":\"50049779\",\"name\":\"X. Hu\"},{\"authorId\":\"9325940\",\"name\":\"Pengchuan Zhang\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"},{\"authorId\":\"29957038\",\"name\":\"Longguang Wang\"},{\"authorId\":\"35431603\",\"name\":\"H. Hu\"},{\"authorId\":\"145307652\",\"name\":\"Li Dong\"},{\"authorId\":\"49807919\",\"name\":\"Furu Wei\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":\"10.1007/978-3-030-58577-8_8\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"818e5cbc337e4e1b98e65a2d7c2d6d2a0318cd57\",\"title\":\"Oscar: Object-Semantics Aligned Pre-training for Vision-Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/818e5cbc337e4e1b98e65a2d7c2d6d2a0318cd57\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2010.12267\",\"authors\":[{\"authorId\":\"1519970315\",\"name\":\"Xinsheng Wang\"},{\"authorId\":\"1514891263\",\"name\":\"Siyuan Feng\"},{\"authorId\":\"2237811\",\"name\":\"Jihua Zhu\"},{\"authorId\":\"1399115926\",\"name\":\"M. Hasegawa-Johnson\"},{\"authorId\":\"144951859\",\"name\":\"O. Scharenborg\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d7b2a37fac581795101120989c0ff76147938a4a\",\"title\":\"Show and Speak: Directly Synthesize Spoken Description of Images\",\"url\":\"https://www.semanticscholar.org/paper/d7b2a37fac581795101120989c0ff76147938a4a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.06877\",\"authors\":[{\"authorId\":\"51175635\",\"name\":\"Jiuniu Wang\"},{\"authorId\":\"50232214\",\"name\":\"Wenjia Xu\"},{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":\"10.1007/978-3-030-58452-8_22\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e38274d1d544af5fad2cb814d62a028e2ff7437b\",\"title\":\"Compare and Reweight: Distinctive Image Captioning Using Similar Images Sets\",\"url\":\"https://www.semanticscholar.org/paper/e38274d1d544af5fad2cb814d62a028e2ff7437b\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2009.05175\",\"authors\":[{\"authorId\":\"37619618\",\"name\":\"Khyathi Raghavi Chandu\"},{\"authorId\":\"153513927\",\"name\":\"P. Sharma\"},{\"authorId\":\"2059199\",\"name\":\"Soravit Changpinyo\"},{\"authorId\":\"87784755\",\"name\":\"A. Thapliyal\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9d325b31c8ccffea52c25e8586bdb9d4dde26151\",\"title\":\"Weakly Supervised Content Selection for Improved Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9d325b31c8ccffea52c25e8586bdb9d4dde26151\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"144255105\",\"name\":\"M. Stefanini\"},{\"authorId\":\"92326466\",\"name\":\"L. Baraldi\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/cvpr42600.2020.01059\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3c5882ba83265093f2625fcebaf41bcdae4548a1\",\"title\":\"Meshed-Memory Transformer for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/3c5882ba83265093f2625fcebaf41bcdae4548a1\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2011.00966\",\"authors\":[{\"authorId\":\"32370882\",\"name\":\"Shweta Mahajan\"},{\"authorId\":\"49863405\",\"name\":\"S. Roth\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7d805e35f17dab7382748130a2ca1bda629cdceb\",\"title\":\"Diverse Image Captioning with Context-Object Split Latent Spaces\",\"url\":\"https://www.semanticscholar.org/paper/7d805e35f17dab7382748130a2ca1bda629cdceb\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2012.07061\",\"authors\":[{\"authorId\":\"9665187\",\"name\":\"Jiayi Ji\"},{\"authorId\":\"46491945\",\"name\":\"Yunpeng Luo\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"2642638\",\"name\":\"F. Chen\"},{\"authorId\":\"1993645531\",\"name\":\"Gen Luo\"},{\"authorId\":\"47096329\",\"name\":\"Yongjian Wu\"},{\"authorId\":\"40366236\",\"name\":\"Yue Gao\"},{\"authorId\":\"1572139630\",\"name\":\"Rongrong Ji\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7217b5d8d0fb753532026cc36b0aaa056960c6f8\",\"title\":\"Improving Image Captioning by Leveraging Intra- and Inter-layer Global Representation in Transformer Network\",\"url\":\"https://www.semanticscholar.org/paper/7217b5d8d0fb753532026cc36b0aaa056960c6f8\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2012.03662\",\"authors\":[{\"authorId\":\"50218156\",\"name\":\"Zhaokai Wang\"},{\"authorId\":\"7760591\",\"name\":\"Renda Bao\"},{\"authorId\":\"1720738301\",\"name\":\"Qi Wu\"},{\"authorId\":\"101219260\",\"name\":\"Si Liu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b1fe7a16266cf2316f436688e0df6c6350c885ef\",\"title\":\"Confidence-aware Non-repetitive Multimodal Transformers for TextCaps\",\"url\":\"https://www.semanticscholar.org/paper/b1fe7a16266cf2316f436688e0df6c6350c885ef\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"115665360\",\"name\":\"Abdelrahman Abdallah\"},{\"authorId\":\"144535484\",\"name\":\"M. Hamada\"},{\"authorId\":\"3253700\",\"name\":\"D. Nurseitov\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b7d12cfb9892423d454726d1f3d22fdfcf38faa7\",\"title\":\"Attention-based Fully Gated Conventional Recurrent Neural Network for Russian Handwritten Text\",\"url\":\"https://www.semanticscholar.org/paper/b7d12cfb9892423d454726d1f3d22fdfcf38faa7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144813679\",\"name\":\"L. Hao\"},{\"authorId\":\"48557329\",\"name\":\"L. Hou\"},{\"authorId\":\"9254183\",\"name\":\"Y. Song\"},{\"authorId\":\"144392311\",\"name\":\"Ke Lu\"},{\"authorId\":\"143670111\",\"name\":\"J. Xue\"}],\"doi\":\"10.1145/3372278.3390712\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8631b8c4d14b42767deaeae0cad13d331d505e26\",\"title\":\"A Lightweight Gated Global Module for Global Context Modeling in Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/8631b8c4d14b42767deaeae0cad13d331d505e26\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":\"2012.05545\",\"authors\":[{\"authorId\":\"67333377\",\"name\":\"Zeliang Song\"},{\"authorId\":\"1727617\",\"name\":\"Xiaofei Zhou\"},{\"authorId\":\"1855978\",\"name\":\"Zhendong Mao\"},{\"authorId\":\"2573626\",\"name\":\"Jianlong Tan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"6f237f4ce10001a9b6cb47fae5333fa5ddb7e2d3\",\"title\":\"Image Captioning with Context-Aware Auxiliary Guidance\",\"url\":\"https://www.semanticscholar.org/paper/6f237f4ce10001a9b6cb47fae5333fa5ddb7e2d3\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2003.12462\",\"authors\":[{\"authorId\":\"144656873\",\"name\":\"O. Sidorov\"},{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"50286460\",\"name\":\"Amanpreet Singh\"}],\"doi\":\"10.1007/978-3-030-58536-5_44\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7442eaaf453e63195cdee037f8e23830b4004027\",\"title\":\"TextCaps: a Dataset for Image Captioning with Reading Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/7442eaaf453e63195cdee037f8e23830b4004027\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2001.01037\",\"authors\":[{\"authorId\":\"46969089\",\"name\":\"J. Sun\"},{\"authorId\":\"3633358\",\"name\":\"S. Lapuschkin\"},{\"authorId\":\"1699054\",\"name\":\"W. Samek\"},{\"authorId\":\"49345823\",\"name\":\"Alexander Binder\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"82e836be97e706dca7029ce6a0553b4890726593\",\"title\":\"Understanding Image Captioning Models beyond Visualizing Attention\",\"url\":\"https://www.semanticscholar.org/paper/82e836be97e706dca7029ce6a0553b4890726593\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.14405\",\"authors\":[{\"authorId\":\"2458059\",\"name\":\"Y. Huang\"},{\"authorId\":\"47739902\",\"name\":\"J. Chen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6caaf71d18f093aebd0cffdcf246b86400092ab5\",\"title\":\"Teacher-Critical Training Strategies for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6caaf71d18f093aebd0cffdcf246b86400092ab5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1443435125\",\"name\":\"Zhengcong Fei\"}],\"doi\":\"10.1145/3394171.3413901\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0bcec12a99cfcd649ea36d6b7215d025bad12974\",\"title\":\"Iterative Back Modification for Faster Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0bcec12a99cfcd649ea36d6b7215d025bad12974\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1998926555\",\"name\":\"Chenxi Yuan\"},{\"authorId\":\"2027167977\",\"name\":\"Yang Bai\"},{\"authorId\":\"144204924\",\"name\":\"C. Yuan\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"68c11851ace525b233f05b985f8acf887d03d379\",\"title\":\"Bridge the Gap: High-level Semantic Planning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/68c11851ace525b233f05b985f8acf887d03d379\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":\"2004.05343\",\"authors\":[{\"authorId\":\"1400414483\",\"name\":\"Maitreya Suin\"},{\"authorId\":\"8107818\",\"name\":\"K. Purohit\"},{\"authorId\":\"143891066\",\"name\":\"A. Rajagopalan\"}],\"doi\":\"10.1109/cvpr42600.2020.00366\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f488d9f0d90b5983e1430806ef1cb1edea4e58fe\",\"title\":\"Spatially-Attentive Patch-Hierarchical Network for Adaptive Motion Deblurring\",\"url\":\"https://www.semanticscholar.org/paper/f488d9f0d90b5983e1430806ef1cb1edea4e58fe\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2003.08897\",\"authors\":[{\"authorId\":\"26982950\",\"name\":\"Longteng Guo\"},{\"authorId\":null,\"name\":\"Jing Liu\"},{\"authorId\":\"48386951\",\"name\":\"Xinxin Zhu\"},{\"authorId\":\"49051904\",\"name\":\"P. Yao\"},{\"authorId\":\"116829059\",\"name\":\"Shi-chen Lu\"},{\"authorId\":\"1699900\",\"name\":\"H. Lu\"}],\"doi\":\"10.1109/cvpr42600.2020.01034\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"833560cd68a3e3d1be1bc650756dd6c679798551\",\"title\":\"Normalized and Geometry-Aware Self-Attention Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/833560cd68a3e3d1be1bc650756dd6c679798551\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1909.11059\",\"authors\":[{\"authorId\":\"48206987\",\"name\":\"L. Zhou\"},{\"authorId\":\"2542427\",\"name\":\"H. Palangi\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"},{\"authorId\":\"35431603\",\"name\":\"H. Hu\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":\"10.1609/AAAI.V34I07.7005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"088ef8f1bdd733673672a055017ee3dd0e70f2cf\",\"title\":\"Unified Vision-Language Pre-Training for Image Captioning and VQA\",\"url\":\"https://www.semanticscholar.org/paper/088ef8f1bdd733673672a055017ee3dd0e70f2cf\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152924571\",\"name\":\"Jing Wang\"},{\"authorId\":\"145113946\",\"name\":\"J. Tang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1145/3394171.3413753\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"021d50ba5ae1c66e9175428f546976798126dd9f\",\"title\":\"Multimodal Attention with Image Text Spatial Relationship for OCR-Based Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/021d50ba5ae1c66e9175428f546976798126dd9f\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2008.05231\",\"authors\":[{\"authorId\":\"67213349\",\"name\":\"N. Messina\"},{\"authorId\":\"144514869\",\"name\":\"G. Amato\"},{\"authorId\":\"1699411\",\"name\":\"Andrea Esuli\"},{\"authorId\":\"1846129\",\"name\":\"F. Falchi\"},{\"authorId\":\"2209975\",\"name\":\"C. Gennaro\"},{\"authorId\":\"1405499517\",\"name\":\"St\\u00e9phane Marchand-Maillet\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"52011033fb859c38bbcc82c311667feb38994ae3\",\"title\":\"Fine-grained Visual Textual Alignment for Cross-Modal Retrieval using Transformer Encoders\",\"url\":\"https://www.semanticscholar.org/paper/52011033fb859c38bbcc82c311667feb38994ae3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.03923\",\"authors\":[{\"authorId\":\"1410097225\",\"name\":\"X. Yang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"50490213\",\"name\":\"Jianfei Cai\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1e420efcd3fbace6f219c812a78d33cb64e25445\",\"title\":\"Deconfounded Image Captioning: A Causal Retrospect\",\"url\":\"https://www.semanticscholar.org/paper/1e420efcd3fbace6f219c812a78d33cb64e25445\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2001.11782\",\"authors\":[{\"authorId\":\"152584142\",\"name\":\"Zhengxiong Jia\"},{\"authorId\":\"9931285\",\"name\":\"Xirong Li\"}],\"doi\":\"10.1145/3372278.3390697\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"87c7ec86e37178720686eba4d00ea53b2aca93d7\",\"title\":\"iCap: Interactive Image Captioning with Predictive Text\",\"url\":\"https://www.semanticscholar.org/paper/87c7ec86e37178720686eba4d00ea53b2aca93d7\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":\"2011.04264\",\"authors\":[{\"authorId\":\"32763968\",\"name\":\"A. Fisch\"},{\"authorId\":\"2544107\",\"name\":\"Kenton Lee\"},{\"authorId\":\"1744179\",\"name\":\"Ming-Wei Chang\"},{\"authorId\":\"144797264\",\"name\":\"J. Clark\"},{\"authorId\":\"1741283\",\"name\":\"R. Barzilay\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8ca71f61139c69131ab200368a30a3dc72fa6785\",\"title\":\"CapWAP: Captioning with a Purpose\",\"url\":\"https://www.semanticscholar.org/paper/8ca71f61139c69131ab200368a30a3dc72fa6785\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144469308\",\"name\":\"Jian Wang\"},{\"authorId\":\"145534714\",\"name\":\"Jie Feng\"}],\"doi\":\"10.1109/ACCESS.2020.3018546\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"123361e4769f2f8a17742197aa52cc676a4caa9a\",\"title\":\"Hybrid Attention Distribution and Factorized Embedding Matrix in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/123361e4769f2f8a17742197aa52cc676a4caa9a\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144613170\",\"name\":\"S. Cao\"},{\"authorId\":\"2896701\",\"name\":\"G. An\"},{\"authorId\":\"4464686\",\"name\":\"ZhenXing Zheng\"},{\"authorId\":\"2383779\",\"name\":\"Qiu-Qi Ruan\"}],\"doi\":\"10.1016/j.neucom.2020.08.019\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f235982f603a740dcee9cff7c5de234878f80a3f\",\"title\":\"Interactions Guided Generative Adversarial Network for unsupervised image captioning\",\"url\":\"https://www.semanticscholar.org/paper/f235982f603a740dcee9cff7c5de234878f80a3f\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"2008.08012\",\"authors\":[{\"authorId\":\"9748140\",\"name\":\"K. Gouthaman\"},{\"authorId\":\"3265714\",\"name\":\"A. Nambiar\"},{\"authorId\":\"1882516497\",\"name\":\"Kancheti Sai Srinivas\"},{\"authorId\":\"50853059\",\"name\":\"Anurag Mittal\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b46ce08535c728cc690852a7c63a9bb211ff25ab\",\"title\":\"Linguistically-aware Attention for Reducing the Semantic-Gap in Vision-Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/b46ce08535c728cc690852a7c63a9bb211ff25ab\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50580169\",\"name\":\"Y. Chen\"},{\"authorId\":\"144784813\",\"name\":\"S. Gong\"},{\"authorId\":\"1809420\",\"name\":\"Loris Bazzani\"}],\"doi\":\"10.1109/CVPR42600.2020.00307\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"78f69364531794550130389342b7bc0ff785b7e9\",\"title\":\"Image Search With Text Feedback by Visiolinguistic Attention Learning\",\"url\":\"https://www.semanticscholar.org/paper/78f69364531794550130389342b7bc0ff785b7e9\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1931096\",\"name\":\"A. Behera\"},{\"authorId\":\"70249755\",\"name\":\"Zachary Wharton\"},{\"authorId\":\"152891407\",\"name\":\"Y. Liu\"},{\"authorId\":\"1522002795\",\"name\":\"Morteza Ghahremani\"},{\"authorId\":\"40578964\",\"name\":\"S. Kumar\"},{\"authorId\":\"2004428132\",\"name\":\"Nikolaos Bessis\"}],\"doi\":\"10.1109/taffc.2020.3031841\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d48d644758dd74fae7265bd0db13d73f98bf3b7a\",\"title\":\"Regional Attention Network (RAN) for Head Pose and Fine-grained Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d48d644758dd74fae7265bd0db13d73f98bf3b7a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2004.00390\",\"authors\":[{\"authorId\":\"51288875\",\"name\":\"Y. Zhou\"},{\"authorId\":\"5332711\",\"name\":\"Meng Wang\"},{\"authorId\":\"48929163\",\"name\":\"Daqing Liu\"},{\"authorId\":\"49941674\",\"name\":\"Zhenzhen Hu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"}],\"doi\":\"10.1109/cvpr42600.2020.00483\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c936e70cc1de52c5ad0ed5ec7a219bd25a46902c\",\"title\":\"More Grounded Image Captioning by Distilling Image-Text Matching Model\",\"url\":\"https://www.semanticscholar.org/paper/c936e70cc1de52c5ad0ed5ec7a219bd25a46902c\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1813602\",\"name\":\"Jee-Young Sun\"},{\"authorId\":\"30993544\",\"name\":\"Seung-Won Jung\"},{\"authorId\":\"7021627\",\"name\":\"Sung-Jea Ko\"}],\"doi\":\"10.1109/ACCESS.2020.3001679\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1486e26d5d4add35ce2e7b40a420f342d2964cbb\",\"title\":\"Lightweight Prediction and Boundary Attention-Based Semantic Segmentation for Road Scene Understanding\",\"url\":\"https://www.semanticscholar.org/paper/1486e26d5d4add35ce2e7b40a420f342d2964cbb\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1909.09060\",\"authors\":[{\"authorId\":\"48544896\",\"name\":\"Lun Huang\"},{\"authorId\":\"1788029\",\"name\":\"W. Wang\"},{\"authorId\":\"49289638\",\"name\":\"Y. Xia\"},{\"authorId\":\"40445654\",\"name\":\"J. Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"312799645adfafb886f156708a7a36f2db459c62\",\"title\":\"Adaptively Aligned Image Captioning via Adaptive Attention Time\",\"url\":\"https://www.semanticscholar.org/paper/312799645adfafb886f156708a7a36f2db459c62\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"2002.08565\",\"authors\":[{\"authorId\":\"2028946\",\"name\":\"D. Gurari\"},{\"authorId\":\"150353841\",\"name\":\"Yinan Zhao\"},{\"authorId\":\"1409765557\",\"name\":\"Meng Zhang\"},{\"authorId\":\"23364558\",\"name\":\"Nilavra Bhattacharya\"}],\"doi\":\"10.1007/978-3-030-58520-4_25\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"c936d878003254cdab662a966cecd29e8be652d0\",\"title\":\"Captioning Images Taken by People Who Are Blind\",\"url\":\"https://www.semanticscholar.org/paper/c936d878003254cdab662a966cecd29e8be652d0\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2009.13682\",\"authors\":[{\"authorId\":\"50049779\",\"name\":\"X. Hu\"},{\"authorId\":\"1629039205\",\"name\":\"Xi Yin\"},{\"authorId\":\"51188307\",\"name\":\"Kevin Lin\"},{\"authorId\":\"29957038\",\"name\":\"Longguang Wang\"},{\"authorId\":\"1720539\",\"name\":\"L. Zhang\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"1691128\",\"name\":\"Zicheng Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f147279c9d1edddda57f1f21f23b3b58998bad74\",\"title\":\"VIVO: Surpassing Human Performance in Novel Object Captioning with Visual Vocabulary Pre-Training\",\"url\":\"https://www.semanticscholar.org/paper/f147279c9d1edddda57f1f21f23b3b58998bad74\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144041168\",\"name\":\"N. Wang\"},{\"authorId\":\"51043014\",\"name\":\"Sihan Ma\"},{\"authorId\":\"1492114642\",\"name\":\"Jingyuan Li\"},{\"authorId\":\"2760404\",\"name\":\"Yipeng Zhang\"},{\"authorId\":null,\"name\":\"Lefei Zhang\"}],\"doi\":\"10.1016/j.patcog.2020.107448\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3fb37054b15fe1ebf276dc6d52ecf4fe82a8ecb2\",\"title\":\"Multistage attention network for image inpainting\",\"url\":\"https://www.semanticscholar.org/paper/3fb37054b15fe1ebf276dc6d52ecf4fe82a8ecb2\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":\"2012.04925\",\"authors\":[{\"authorId\":\"30894109\",\"name\":\"A. Chen\"},{\"authorId\":\"49444758\",\"name\":\"Xinyi Huang\"},{\"authorId\":\"15385188\",\"name\":\"Hailan Lin\"},{\"authorId\":\"9931285\",\"name\":\"Xirong Li\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f4079b8d38e085386609b82b6bf8ab43d1fab13e\",\"title\":\"Towards Annotation-Free Evaluation of Cross-Lingual Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/f4079b8d38e085386609b82b6bf8ab43d1fab13e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92091076\",\"name\":\"F. Yu\"},{\"authorId\":\"102401998\",\"name\":\"H. Wang\"},{\"authorId\":\"1744930\",\"name\":\"T. Ren\"},{\"authorId\":\"145113946\",\"name\":\"J. Tang\"},{\"authorId\":\"39914710\",\"name\":\"Gangshan Wu\"}],\"doi\":\"10.1145/3394171.3413566\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f2a0485dca57fd054b1577f9bbda61f40fe0924c\",\"title\":\"Visual Relation of Interest Detection\",\"url\":\"https://www.semanticscholar.org/paper/f2a0485dca57fd054b1577f9bbda61f40fe0924c\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"37184350\",\"name\":\"J. Xu\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"1490772804\",\"name\":\"Tao Mei\"},{\"authorId\":\"50763020\",\"name\":\"Jingwen Chen\"},{\"authorId\":\"41079034\",\"name\":\"Hong-Yang Chao\"},{\"authorId\":\"2458059\",\"name\":\"Y. Huang\"},{\"authorId\":\"1394465427\",\"name\":\"Qiuyu Cai\"}],\"doi\":\"10.1145/3394171.3416290\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"93aed487e9b9f51bf05803ef69c92599001358ac\",\"title\":\"XlanV Model with Adaptively Multi-Modality Feature Fusing for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/93aed487e9b9f51bf05803ef69c92599001358ac\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2010.08708\",\"authors\":[{\"authorId\":\"2728646\",\"name\":\"Hantao Huang\"},{\"authorId\":\"145421604\",\"name\":\"T. Han\"},{\"authorId\":\"72549949\",\"name\":\"Wei Han\"},{\"authorId\":\"48986588\",\"name\":\"D. Yap\"},{\"authorId\":\"32312400\",\"name\":\"C. Chiang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"91550d1490caa39f723d3efb5d1b78b6f8b7c6cf\",\"title\":\"Answer-checking in Context: A Multi-modal FullyAttention Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/91550d1490caa39f723d3efb5d1b78b6f8b7c6cf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144101175\",\"name\":\"Zhou Lei\"},{\"authorId\":\"1831825\",\"name\":\"Congcong Zhou\"},{\"authorId\":\"35155467\",\"name\":\"Shengbo Chen\"},{\"authorId\":\"1722738282\",\"name\":\"Yiyong Huang\"},{\"authorId\":\"1726027121\",\"name\":\"Xianrui Liu\"}],\"doi\":\"10.1109/ACCESS.2020.3024639\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e85fdae1b5e297f1d8925c9bd5cd7e243a305116\",\"title\":\"A Sparse Transformer-Based Approach for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/e85fdae1b5e297f1d8925c9bd5cd7e243a305116\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2004.02435\",\"authors\":[{\"authorId\":\"2416001\",\"name\":\"Shashank Bujimalla\"},{\"authorId\":\"2536658\",\"name\":\"Mahesh Subedar\"},{\"authorId\":\"1798616\",\"name\":\"O. Tickoo\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"81e7e74d0f5f200e575df1908a1b0a5f0500906b\",\"title\":\"B-SCST: Bayesian Self-Critical Sequence Training for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/81e7e74d0f5f200e575df1908a1b0a5f0500906b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.12204\",\"authors\":[{\"authorId\":\"134814700\",\"name\":\"T. Wang\"},{\"authorId\":\"50560698\",\"name\":\"Jianqiang Huang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"32222907\",\"name\":\"Qianru Sun\"}],\"doi\":\"10.1109/cvpr42600.2020.01077\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d9d0197c6d9304d6bc179ac21370c49a33fc2388\",\"title\":\"Visual Commonsense R-CNN\",\"url\":\"https://www.semanticscholar.org/paper/d9d0197c6d9304d6bc179ac21370c49a33fc2388\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2006.13611\",\"authors\":[{\"authorId\":\"49319111\",\"name\":\"Dan Guo\"},{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"47382681\",\"name\":\"Peipei Song\"},{\"authorId\":\"152808542\",\"name\":\"Meng Wang\"}],\"doi\":\"10.24963/ijcai.2020/128\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9c3f13969af79ce26d584935e8e39a4423a9d63f\",\"title\":\"Recurrent Relational Memory Network for Unsupervised Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9c3f13969af79ce26d584935e8e39a4423a9d63f\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":\"2005.08081\",\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"19169659\",\"name\":\"Xuancheng Ren\"},{\"authorId\":\"1390788836\",\"name\":\"Guangxiang Zhao\"},{\"authorId\":\"2511091\",\"name\":\"X. Sun\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4ba3190eb0dca6344e43c3eced1788324c169388\",\"title\":\"Layer-Wise Cross-View Decoding for Sequence-to-Sequence Learning\",\"url\":\"https://www.semanticscholar.org/paper/4ba3190eb0dca6344e43c3eced1788324c169388\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.11696\",\"authors\":[{\"authorId\":\"1839363\",\"name\":\"Pierre L. Dognin\"},{\"authorId\":\"2576373\",\"name\":\"I. Melnyk\"},{\"authorId\":\"2211263\",\"name\":\"Youssef Mroueh\"},{\"authorId\":\"8350409\",\"name\":\"I. Padhi\"},{\"authorId\":\"2535094\",\"name\":\"Mattia Rigotti\"},{\"authorId\":\"153598395\",\"name\":\"J. Ross\"},{\"authorId\":\"1999174380\",\"name\":\"Yair Schiff\"},{\"authorId\":\"49832828\",\"name\":\"R. A. Young\"},{\"authorId\":\"2679155\",\"name\":\"Brian M. Belgodere\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5d4b265d7f80b185c618fb230ea14dcf909beed7\",\"title\":\"Image Captioning as an Assistive Technology: Lessons Learned from VizWiz 2020 Challenge\",\"url\":\"https://www.semanticscholar.org/paper/5d4b265d7f80b185c618fb230ea14dcf909beed7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52150251\",\"name\":\"A. Goel\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"103192742\",\"name\":\"T. Nguyen\"},{\"authorId\":\"2518212\",\"name\":\"Hakan Bilen\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"3d807fed82f61bc48aea76f191d2e19e2fc38f5d\",\"title\":\"Learning to Caption Images with Two-Stream Attention and Sentence Auto-Encoder\",\"url\":\"https://www.semanticscholar.org/paper/3d807fed82f61bc48aea76f191d2e19e2fc38f5d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9665187\",\"name\":\"Jiayi Ji\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"2223252\",\"name\":\"Y. Zhou\"},{\"authorId\":\"1572139630\",\"name\":\"Rongrong Ji\"},{\"authorId\":\"2642638\",\"name\":\"F. Chen\"},{\"authorId\":\"46700604\",\"name\":\"J. Liu\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1145/3394171.3414009\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f480dadb895975a3921f5fcd03fdbf4085f8e9b\",\"title\":\"Attacking Image Captioning Towards Accuracy-Preserving Target Words Removal\",\"url\":\"https://www.semanticscholar.org/paper/0f480dadb895975a3921f5fcd03fdbf4085f8e9b\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1753617513\",\"name\":\"Tan Wang\"},{\"authorId\":\"50535545\",\"name\":\"Jianqiang Huang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"32222907\",\"name\":\"Qianru Sun\"}],\"doi\":\"10.1109/CVPRW50498.2020.00197\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"ff0236a4f4687b61155416eae8864bd9da234509\",\"title\":\"Visual Commonsense Representation Learning via Causal Inference\",\"url\":\"https://www.semanticscholar.org/paper/ff0236a4f4687b61155416eae8864bd9da234509\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"2011.00927\",\"authors\":[{\"authorId\":\"2000125058\",\"name\":\"Feicheng Huang\"},{\"authorId\":\"144111674\",\"name\":\"Zhixin Li\"},{\"authorId\":\"92057141\",\"name\":\"H. Wei\"},{\"authorId\":\"104269832\",\"name\":\"Canlong Zhang\"},{\"authorId\":\"1998838209\",\"name\":\"Huifang Ma\"}],\"doi\":\"10.1007/s10994-020-05919-y\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"899b365ce70207f1fd456e982583841d9e4701bf\",\"title\":\"Boost Image Captioning with Knowledge Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/899b365ce70207f1fd456e982583841d9e4701bf\",\"venue\":\"Mach. Learn.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49418270\",\"name\":\"Yong Wang\"},{\"authorId\":\"1485232293\",\"name\":\"Wenkai Zhang\"},{\"authorId\":\"47362549\",\"name\":\"Qing Liu\"},{\"authorId\":\"9708577\",\"name\":\"Zhengyuan Zhang\"},{\"authorId\":\"11732382\",\"name\":\"X. Gao\"},{\"authorId\":\"9758599\",\"name\":\"Xi-an Sun\"}],\"doi\":\"10.1145/3394171.3413877\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a05a96d5d9bac88d7c8b34be2e57f58f17a6e53d\",\"title\":\"Improving Intra- and Inter-Modality Visual Relation for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/a05a96d5d9bac88d7c8b34be2e57f58f17a6e53d\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2011.01385\",\"authors\":[{\"authorId\":\"3280656\",\"name\":\"Litao Yu\"},{\"authorId\":\"123275544\",\"name\":\"Jian Zhang\"},{\"authorId\":\"47506551\",\"name\":\"Qiang Wu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b0aa35ac0caf5230cdd1c5022b246e2381f87aac\",\"title\":\"Dual Attention on Pyramid Feature Maps for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/b0aa35ac0caf5230cdd1c5022b246e2381f87aac\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1912.08226\",\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"144255105\",\"name\":\"M. Stefanini\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"261570379fd841b426a4c51e8004f2cf9f1df771\",\"title\":\"M2: Meshed-Memory Transformer for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/261570379fd841b426a4c51e8004f2cf9f1df771\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"144746444\",\"name\":\"H. Bischof\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"},{\"authorId\":\"40454588\",\"name\":\"J. Frahm\"}],\"doi\":\"10.1007/978-3-030-58577-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"08a578d7f7f3d0edf46470e33f92e2335d19b70b\",\"title\":\"Computer Vision \\u2013 ECCV 2020: 16th European Conference, Glasgow, UK, August 23\\u201328, 2020, Proceedings, Part XXX\",\"url\":\"https://www.semanticscholar.org/paper/08a578d7f7f3d0edf46470e33f92e2335d19b70b\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2003.12511\",\"authors\":[{\"authorId\":\"3428457\",\"name\":\"Tai-Yin Chiu\"},{\"authorId\":\"31812669\",\"name\":\"Y. Zhao\"},{\"authorId\":\"2028946\",\"name\":\"D. Gurari\"}],\"doi\":\"10.1109/cvpr42600.2020.00370\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"795435da0de2cb9772e8ebec9a4242de7e677b30\",\"title\":\"Assessing Image Quality Issues for Real-World Problems\",\"url\":\"https://www.semanticscholar.org/paper/795435da0de2cb9772e8ebec9a4242de7e677b30\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2004.14231\",\"authors\":[{\"authorId\":\"47287647\",\"name\":\"Sen He\"},{\"authorId\":\"3157379\",\"name\":\"Wentong Liao\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"143672748\",\"name\":\"M. Yang\"},{\"authorId\":\"1779035\",\"name\":\"B. Rosenhahn\"},{\"authorId\":\"3251678\",\"name\":\"N. Pugeault\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"657cce51f80e272373ab4fc0dabf5dc8b30c0070\",\"title\":\"Image Captioning through Image Transformer\",\"url\":\"https://www.semanticscholar.org/paper/657cce51f80e272373ab4fc0dabf5dc8b30c0070\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.01473\",\"authors\":[{\"authorId\":\"10007273\",\"name\":\"Qiaolin Xia\"},{\"authorId\":\"15086992\",\"name\":\"H. Huang\"},{\"authorId\":\"46429989\",\"name\":\"N. Duan\"},{\"authorId\":\"144934143\",\"name\":\"Dongdong Zhang\"},{\"authorId\":\"144906579\",\"name\":\"Lei Ji\"},{\"authorId\":\"49575302\",\"name\":\"Zhifang Sui\"},{\"authorId\":\"144530394\",\"name\":\"Edward Cui\"},{\"authorId\":\"1490606819\",\"name\":\"Taroon Bharti\"},{\"authorId\":null,\"name\":\"Xin Liu\"},{\"authorId\":\"92660691\",\"name\":\"M. Zhou\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1d0d9550ecd2bece6a34fe1ffd12fb7504e7aaa0\",\"title\":\"XGPT: Cross-modal Generative Pre-Training for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/1d0d9550ecd2bece6a34fe1ffd12fb7504e7aaa0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.08899\",\"authors\":[{\"authorId\":\"2533559\",\"name\":\"Dhomas Hatta Fudholi\"},{\"authorId\":\"88823036\",\"name\":\"Yurio Windiatmoko\"},{\"authorId\":\"104526200\",\"name\":\"Nurdi Afrianto\"},{\"authorId\":\"1392876189\",\"name\":\"P. Susanto\"},{\"authorId\":\"80939610\",\"name\":\"Magfirah Suyuti\"},{\"authorId\":\"30726945\",\"name\":\"A. Hidayatullah\"},{\"authorId\":\"2938889\",\"name\":\"R. Rahmadi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2291e4f1eb85ec2415aee119c5ca67d8bb64b30f\",\"title\":\"Image Captioning with Attention for Smart Local Tourism using EfficientNet\",\"url\":\"https://www.semanticscholar.org/paper/2291e4f1eb85ec2415aee119c5ca67d8bb64b30f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1488653711\",\"name\":\"Yanzhi Yi\"},{\"authorId\":\"1486063321\",\"name\":\"Hangyu Deng\"},{\"authorId\":\"153147804\",\"name\":\"Jinglu Hu\"}],\"doi\":\"10.18653/v1/2020.acl-main.93\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0b4d5b7cef06b66182db80803f783d077e3637b6\",\"title\":\"Improving Image Captioning Evaluation by Considering Inter References Variance\",\"url\":\"https://www.semanticscholar.org/paper/0b4d5b7cef06b66182db80803f783d077e3637b6\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"1911.10082\",\"authors\":[{\"authorId\":\"52150251\",\"name\":\"A. Goel\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"103192742\",\"name\":\"T. Nguyen\"},{\"authorId\":\"2518212\",\"name\":\"Hakan Bilen\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"e4dcd3fa308b263cee8c7581e2d695dc15c2f51f\",\"title\":\"Injecting Prior Knowledge into Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/e4dcd3fa308b263cee8c7581e2d695dc15c2f51f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2008.05373\",\"authors\":[{\"authorId\":\"115665360\",\"name\":\"Abdelrahman Abdallah\"},{\"authorId\":\"144535484\",\"name\":\"M. Hamada\"},{\"authorId\":\"3253700\",\"name\":\"D. Nurseitov\"}],\"doi\":\"10.3390/jimaging6120141\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c1efbca18181cebf398506ed9cdf686ded5b293b\",\"title\":\"Attention-based Fully Gated CNN-BGRU for Russian Handwritten Text\",\"url\":\"https://www.semanticscholar.org/paper/c1efbca18181cebf398506ed9cdf686ded5b293b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32763968\",\"name\":\"A. Fisch\"},{\"authorId\":\"2544107\",\"name\":\"Kenton Lee\"},{\"authorId\":\"1744179\",\"name\":\"Ming-Wei Chang\"},{\"authorId\":\"144797264\",\"name\":\"J. Clark\"},{\"authorId\":\"1741283\",\"name\":\"R. Barzilay\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.705\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b01bc15919f72929d36fc0443395e97b632c81b8\",\"title\":\"CapWAP: Image Captioning with a Purpose\",\"url\":\"https://www.semanticscholar.org/paper/b01bc15919f72929d36fc0443395e97b632c81b8\",\"venue\":\"EMNLP\",\"year\":2020}],\"corpusId\":201070367,\"doi\":\"10.1109/ICCV.2019.00473\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":26,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"4c163d4942117179d3e97182e1b280027d7d60a9\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"2653462\",\"name\":\"Ronald A. Rensink\"}],\"doi\":\"10.1080/135062800394667\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"00e64fb34f407f5939612481ebc93a44d571c9c7\",\"title\":\"The Dynamic Representation of Scenes\",\"url\":\"https://www.semanticscholar.org/paper/00e64fb34f407f5939612481ebc93a44d571c9c7\",\"venue\":\"\",\"year\":2000},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"}],\"doi\":\"10.1109/CVPR.2017.108\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"561ed7e47524fb3218e6a38f41cd877a9c33d3b9\",\"title\":\"StyleNet: Generating Attractive Visual Captions with Styles\",\"url\":\"https://www.semanticscholar.org/paper/561ed7e47524fb3218e6a38f41cd877a9c33d3b9\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1809.07041\",\"authors\":[{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1007/978-3-030-01264-9_42\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0000fcfd467a19cf0e59169c2f07d730a0f3a8b9\",\"title\":\"Exploring Visual Relationship for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0000fcfd467a19cf0e59169c2f07d730a0f3a8b9\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12094097\",\"name\":\"Pratik P. Rane\"},{\"authorId\":\"118145941\",\"name\":\"A. Sargar\"},{\"authorId\":\"47039181\",\"name\":\"Faiza Shaikh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f77a604410d88307ec5c6331c8b6133272fbaa10\",\"title\":\"Self-Critical Sequence Training for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/f77a604410d88307ec5c6331c8b6133272fbaa10\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1812.02378\",\"authors\":[{\"authorId\":\"47008946\",\"name\":\"X. Yang\"},{\"authorId\":\"10817432\",\"name\":\"Kaihua Tang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"}],\"doi\":\"10.1109/CVPR.2019.01094\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f6feb1af1809dfd872d868dfcc13021cc42f496c\",\"title\":\"Auto-Encoding Scene Graphs for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/f6feb1af1809dfd872d868dfcc13021cc42f496c\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1705.06676\",\"authors\":[{\"authorId\":\"1405301761\",\"name\":\"Hedi Ben-younes\"},{\"authorId\":\"7535126\",\"name\":\"R\\u00e9mi Cad\\u00e8ne\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"},{\"authorId\":\"1728523\",\"name\":\"N. Thome\"}],\"doi\":\"10.1109/ICCV.2017.285\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fe466e84fa2e838adc3c37ee327cd68004ae08fe\",\"title\":\"MUTAN: Multimodal Tucker Fusion for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/fe466e84fa2e838adc3c37ee327cd68004ae08fe\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"34176020\",\"name\":\"Jesse Dodge\"},{\"authorId\":\"46479604\",\"name\":\"Amit Goyal\"},{\"authorId\":\"1721910\",\"name\":\"Kota Yamaguchi\"},{\"authorId\":\"1714215\",\"name\":\"K. Stratos\"},{\"authorId\":\"1682965\",\"name\":\"Xufeng Han\"},{\"authorId\":\"40614240\",\"name\":\"A. Mensch\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1722360\",\"name\":\"Hal Daum\\u00e9\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"355de7460120ddc1150d9ce3756f9848983f7ff4\",\"title\":\"Midge: Generating Image Descriptions From Computer Vision Detections\",\"url\":\"https://www.semanticscholar.org/paper/355de7460120ddc1150d9ce3756f9848983f7ff4\",\"venue\":\"EACL\",\"year\":2012},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1707.07998\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"31790073\",\"name\":\"C. Buehler\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":\"10.1109/CVPR.2018.00636\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"title\":\"Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1812.05252\",\"authors\":[{\"authorId\":\"144579865\",\"name\":\"P. Gao\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"30156979\",\"name\":\"Haoxuan You\"},{\"authorId\":\"50676465\",\"name\":\"Zhengkai Jiang\"},{\"authorId\":\"2887562\",\"name\":\"Pan Lu\"},{\"authorId\":\"49212307\",\"name\":\"Steven C. H. Hoi\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"}],\"doi\":\"10.1109/CVPR.2019.00680\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e9b13731027418ed38103d1dfc8a70f6881bc684\",\"title\":\"Dynamic Fusion With Intra- and Inter-Modality Attention Flow for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e9b13731027418ed38103d1dfc8a70f6881bc684\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3141511\",\"name\":\"S. Banerjee\"},{\"authorId\":\"1784914\",\"name\":\"A. Lavie\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0cd18e4400ff75b2f8b58d60ddb9b0bc12f489e7\",\"title\":\"METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments\",\"url\":\"https://www.semanticscholar.org/paper/0cd18e4400ff75b2f8b58d60ddb9b0bc12f489e7\",\"venue\":\"IEEvaluation@ACL\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47713710\",\"name\":\"Benjamin Z. Yao\"},{\"authorId\":\"47008378\",\"name\":\"Xiong Yang\"},{\"authorId\":\"1737218\",\"name\":\"L. Lin\"},{\"authorId\":\"2649483\",\"name\":\"M. Lee\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/JPROC.2010.2050411\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"05e074abddd3fe987b9bebd46f6cf4bf8465c37e\",\"title\":\"I2T: Image Parsing to Text Description\",\"url\":\"https://www.semanticscholar.org/paper/05e074abddd3fe987b9bebd46f6cf4bf8465c37e\",\"venue\":\"Proceedings of the IEEE\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jin Hwa Kim\"},{\"authorId\":null,\"name\":\"Kyoung Woon On\"},{\"authorId\":null,\"name\":\"Jeonghee Kim\"},{\"authorId\":null,\"name\":\"Jung Woo Ha\"},{\"authorId\":null,\"name\":\"Byoung Tak Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Hadamard product for low-rank bilinear pooling\",\"url\":\"\",\"venue\":\"In ICLR,\",\"year\":2017},{\"arxivId\":\"1411.5726\",\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2015.7299087\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"258986132bf17755fe8263e42429fe73218c1534\",\"title\":\"CIDEr: Consensus-based image description evaluation\",\"url\":\"https://www.semanticscholar.org/paper/258986132bf17755fe8263e42429fe73218c1534\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1711.11575\",\"authors\":[{\"authorId\":\"1805197\",\"name\":\"H. Hu\"},{\"authorId\":\"30107062\",\"name\":\"Jiayuan Gu\"},{\"authorId\":null,\"name\":\"Zheng Zhang\"},{\"authorId\":\"3304536\",\"name\":\"Jifeng Dai\"},{\"authorId\":\"1732264\",\"name\":\"Y. Wei\"}],\"doi\":\"10.1109/CVPR.2018.00378\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6a0aaefce8a27a8727d896fa444ba27558b2d381\",\"title\":\"Relation Networks for Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/6a0aaefce8a27a8727d896fa444ba27558b2d381\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1511.02274\",\"authors\":[{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"46234526\",\"name\":\"Alex Smola\"}],\"doi\":\"10.1109/CVPR.2016.10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c1890864c1c2b750f48316dc8b650ba4772adc5\",\"title\":\"Stacked Attention Networks for Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2c1890864c1c2b750f48316dc8b650ba4772adc5\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2010.5540112\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6eb3a15108dfdec25b46522ed94b866aeb156de9\",\"title\":\"Connecting modalities: Semi-supervised segmentation and annotation of images using unaligned text corpora\",\"url\":\"https://www.semanticscholar.org/paper/6eb3a15108dfdec25b46522ed94b866aeb156de9\",\"venue\":\"2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144930597\",\"name\":\"Fang Wan\"},{\"authorId\":\"145402398\",\"name\":\"Pengxu Wei\"},{\"authorId\":\"1747832\",\"name\":\"Zhenjun Han\"},{\"authorId\":\"24350293\",\"name\":\"J. Jiao\"},{\"authorId\":\"1694936\",\"name\":\"Q. Ye\"}],\"doi\":\"10.1109/TPAMI.2019.2898858\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d9c2f9064914162c912ff108bf5c9bac13fc3597\",\"title\":\"Min-Entropy Latent Model for Weakly Supervised Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/d9c2f9064914162c912ff108bf5c9bac13fc3597\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":\"1612.08083\",\"authors\":[{\"authorId\":\"2921469\",\"name\":\"Yann Dauphin\"},{\"authorId\":\"144270981\",\"name\":\"Angela Fan\"},{\"authorId\":\"2325985\",\"name\":\"M. Auli\"},{\"authorId\":\"2529182\",\"name\":\"David Grangier\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"88caa4a0253a8b0076176745ebc072864eab66e1\",\"title\":\"Language Modeling with Gated Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/88caa4a0253a8b0076176745ebc072864eab66e1\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"1756655\",\"name\":\"C. L. Teo\"},{\"authorId\":\"1722360\",\"name\":\"Hal Daum\\u00e9\"},{\"authorId\":\"1697493\",\"name\":\"Y. Aloimonos\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"76a1dca3a9c2b0229c1b12c95752dcf40dc95a11\",\"title\":\"Corpus-Guided Sentence Generation of Natural Images\",\"url\":\"https://www.semanticscholar.org/paper/76a1dca3a9c2b0229c1b12c95752dcf40dc95a11\",\"venue\":\"EMNLP\",\"year\":2011},{\"arxivId\":\"1607.08822\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1007/978-3-319-46454-1_24\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1c54acd7d9ed8017acdc5674c9b7faac738fd651\",\"title\":\"SPICE: Semantic Propositional Image Caption Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/1c54acd7d9ed8017acdc5674c9b7faac738fd651\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145971173\",\"name\":\"J. Xu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/CVPR.2016.571\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b8e2e9f3ba008e28257195ec69a00e07f260131d\",\"title\":\"MSR-VTT: A Large Video Description Dataset for Bridging Video and Language\",\"url\":\"https://www.semanticscholar.org/paper/b8e2e9f3ba008e28257195ec69a00e07f260131d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1602.07332\",\"authors\":[{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"50499889\",\"name\":\"O. Groth\"},{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"1382195702\",\"name\":\"Kenji Hata\"},{\"authorId\":\"40591424\",\"name\":\"J. Kravitz\"},{\"authorId\":\"6000646\",\"name\":\"Stephanie Chen\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"1388344504\",\"name\":\"David A. Shamma\"},{\"authorId\":\"1379506718\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-016-0981-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"title\":\"Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations\",\"url\":\"https://www.semanticscholar.org/paper/afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1723344\",\"name\":\"M. Corbetta\"},{\"authorId\":\"39269549\",\"name\":\"G. Shulman\"}],\"doi\":\"10.1038/nrn755\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"53e66b6934516a9859573f4866f81f04bce977ae\",\"title\":\"Control of goal-directed and stimulus-driven attention in the brain\",\"url\":\"https://www.semanticscholar.org/paper/53e66b6934516a9859573f4866f81f04bce977ae\",\"venue\":\"Nature Reviews Neuroscience\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1781574\",\"name\":\"Chin-Yew Lin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"60b05f32c32519a809f21642ef1eb3eaf3848008\",\"title\":\"ROUGE: A Package for Automatic Evaluation of Summaries\",\"url\":\"https://www.semanticscholar.org/paper/60b05f32c32519a809f21642ef1eb3eaf3848008\",\"venue\":\"ACL 2004\",\"year\":2004},{\"arxivId\":\"1611.05594\",\"authors\":[{\"authorId\":\"143891667\",\"name\":\"Long Chen\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1406012647\",\"name\":\"Jun Xiao\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":\"104757141\",\"name\":\"Jian Shao\"},{\"authorId\":\"40366581\",\"name\":\"Wei Liu\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1109/CVPR.2017.667\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"88513e738a95840de05a62f0e43d30a67b3c542e\",\"title\":\"SCA-CNN: Spatial and Channel-Wise Attention in Convolutional Networks for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/88513e738a95840de05a62f0e43d30a67b3c542e\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2846025\",\"name\":\"D. Yu\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/CVPR.2017.446\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d740d0a960368633ed32fc84877b8391993acdca\",\"title\":\"Multi-level Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d740d0a960368633ed32fc84877b8391993acdca\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1711.07971\",\"authors\":[{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"}],\"doi\":\"10.1109/CVPR.2018.00813\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8899094797e82c5c185a0893896320ef77f60e64\",\"title\":\"Non-local Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/8899094797e82c5c185a0893896320ef77f60e64\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1406.1078\",\"authors\":[{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"3158246\",\"name\":\"B. V. Merrienboer\"},{\"authorId\":\"1854385\",\"name\":\"\\u00c7aglar G\\u00fcl\\u00e7ehre\"},{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"2076086\",\"name\":\"Fethi Bougares\"},{\"authorId\":\"144518416\",\"name\":\"Holger Schwenk\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":\"10.3115/v1/D14-1179\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0b544dfe355a5070b60986319a3f51fb45d1348e\",\"title\":\"Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/0b544dfe355a5070b60986319a3f51fb45d1348e\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":\"1706.03762\",\"authors\":[{\"authorId\":\"40348417\",\"name\":\"Ashish Vaswani\"},{\"authorId\":\"1846258\",\"name\":\"Noam Shazeer\"},{\"authorId\":\"3877127\",\"name\":\"Niki Parmar\"},{\"authorId\":\"39328010\",\"name\":\"Jakob Uszkoreit\"},{\"authorId\":\"145024664\",\"name\":\"Llion Jones\"},{\"authorId\":\"19177000\",\"name\":\"Aidan N. Gomez\"},{\"authorId\":\"40527594\",\"name\":\"L. Kaiser\"},{\"authorId\":\"3443442\",\"name\":\"Illia Polosukhin\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"204e3073870fae3d05bcbc2f6a8e263d9b72e776\",\"title\":\"Attention is All you Need\",\"url\":\"https://www.semanticscholar.org/paper/204e3073870fae3d05bcbc2f6a8e263d9b72e776\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1411.4952\",\"authors\":[{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3346186\",\"name\":\"Forrest N. Iandola\"},{\"authorId\":\"2100612\",\"name\":\"R. Srivastava\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"144189092\",\"name\":\"John C. Platt\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"}],\"doi\":\"10.1109/CVPR.2015.7298754\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"title\":\"From captions to visual concepts and back\",\"url\":\"https://www.semanticscholar.org/paper/15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1506.03099\",\"authors\":[{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"3111912\",\"name\":\"Navdeep Jaitly\"},{\"authorId\":\"1846258\",\"name\":\"Noam Shazeer\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"df137487e20ba7c6e1e2b9a1e749f2a578b5ad99\",\"title\":\"Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/df137487e20ba7c6e1e2b9a1e749f2a578b5ad99\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1807.09986\",\"authors\":[{\"authorId\":\"2093119\",\"name\":\"W. Jiang\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"38144094\",\"name\":\"T. Zhang\"}],\"doi\":\"10.1007/978-3-030-01216-8_31\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"04cd9168dcf1a0d2cf01db95a1af53d0900bc346\",\"title\":\"Recurrent Fusion Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/04cd9168dcf1a0d2cf01db95a1af53d0900bc346\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1612.01887\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":\"10.1109/CVPR.2017.345\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9f4d7d622d1f7319cc511bfef661cd973e881a4c\",\"title\":\"Knowing When to Look: Adaptive Attention via a Visual Sentinel for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9f4d7d622d1f7319cc511bfef661cd973e881a4c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2015.7298932\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"title\":\"Deep visual-semantic alignments for generating image descriptions\",\"url\":\"https://www.semanticscholar.org/paper/ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"venue\":\"CVPR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"134861178\",\"name\":\"Wei Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPRW.2009.5206848\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d2c733e34d48784a37d717fe43d9e93277a8c53e\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/d2c733e34d48784a37d717fe43d9e93277a8c53e\",\"venue\":\"2009 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2009},{\"arxivId\":\"1904.05647\",\"authors\":[{\"authorId\":\"144930597\",\"name\":\"Fang Wan\"},{\"authorId\":null,\"name\":\"Chang Liu\"},{\"authorId\":\"48614994\",\"name\":\"W. Ke\"},{\"authorId\":\"7807689\",\"name\":\"Xiangyang Ji\"},{\"authorId\":\"24350293\",\"name\":\"J. Jiao\"},{\"authorId\":\"1694936\",\"name\":\"Q. Ye\"}],\"doi\":\"10.1109/CVPR.2019.00230\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"425fc8829ff30c4795776a92076b6d6ba8714f51\",\"title\":\"C-MIL: Continuation Multiple Instance Learning for Weakly Supervised Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/425fc8829ff30c4795776a92076b6d6ba8714f51\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1803.01457\",\"authors\":[{\"authorId\":\"40702813\",\"name\":\"Yangyu Chen\"},{\"authorId\":\"2538306\",\"name\":\"S. Wang\"},{\"authorId\":\"47527850\",\"name\":\"W. Zhang\"},{\"authorId\":\"1689702\",\"name\":\"Q. Huang\"}],\"doi\":\"10.1007/978-3-030-01261-8_22\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d5ff7a4580fbfdecc1d912746eee36980f29278b\",\"title\":\"Less Is More: Picking Informative Frames for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/d5ff7a4580fbfdecc1d912746eee36980f29278b\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47087291\",\"name\":\"Z. Yang\"},{\"authorId\":\"30556331\",\"name\":\"Y. Yuan\"},{\"authorId\":\"9287688\",\"name\":\"Yuexin Wu\"},{\"authorId\":\"50056360\",\"name\":\"William W. Cohen\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"61d2dda8d96a10a714636475c7589bd149bda053\",\"title\":\"Review Networks for Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/61d2dda8d96a10a714636475c7589bd149bda053\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1611.08002\",\"authors\":[{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"2750075\",\"name\":\"Y. Pu\"},{\"authorId\":\"143690259\",\"name\":\"K. Tran\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"}],\"doi\":\"10.1109/CVPR.2017.127\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"778ce81457383bd5e3fdb11b145ded202ebb4970\",\"title\":\"Semantic Compositional Networks for Visual Captioning\",\"url\":\"https://www.semanticscholar.org/paper/778ce81457383bd5e3fdb11b145ded202ebb4970\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145564333\",\"name\":\"G. Kulkarni\"},{\"authorId\":\"3128210\",\"name\":\"Visruth Premraj\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"2985883\",\"name\":\"Sagnik Dhar\"},{\"authorId\":\"50341924\",\"name\":\"Siming Li\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/TPAMI.2012.162\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5cb6700d94c6118ee13f4f4fecac99f111189812\",\"title\":\"BabyTalk: Understanding and Generating Simple Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/5cb6700d94c6118ee13f4f4fecac99f111189812\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2013},{\"arxivId\":\"1511.06062\",\"authors\":[{\"authorId\":\"145644823\",\"name\":\"Y. Gao\"},{\"authorId\":\"3258919\",\"name\":\"Oscar Beijbom\"},{\"authorId\":null,\"name\":\"Ning Zhang\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/CVPR.2016.41\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"327dc2fd203a7049f3409479ab68e5e2a83cd352\",\"title\":\"Compact Bilinear Pooling\",\"url\":\"https://www.semanticscholar.org/paper/327dc2fd203a7049f3409479ab68e5e2a83cd352\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1606.01847\",\"authors\":[{\"authorId\":\"50599725\",\"name\":\"A. Fukui\"},{\"authorId\":\"3422202\",\"name\":\"Dong Huk Park\"},{\"authorId\":\"3422876\",\"name\":\"Daylen Yang\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.18653/v1/D16-1044\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fddc15480d086629b960be5bff96232f967f2252\",\"title\":\"Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/fddc15480d086629b960be5bff96232f967f2252\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3323275\",\"name\":\"Kishore Papineni\"},{\"authorId\":\"1781292\",\"name\":\"S. Roukos\"},{\"authorId\":\"144582029\",\"name\":\"T. Ward\"},{\"authorId\":\"2587983\",\"name\":\"Wei-Jing Zhu\"}],\"doi\":\"10.3115/1073083.1073135\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d7da009f457917aa381619facfa5ffae9329a6e9\",\"title\":\"Bleu: a Method for Automatic Evaluation of Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/d7da009f457917aa381619facfa5ffae9329a6e9\",\"venue\":\"ACL\",\"year\":2002},{\"arxivId\":\"1506.01497\",\"authors\":[{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"144716314\",\"name\":\"J. Sun\"}],\"doi\":\"10.1109/TPAMI.2016.2577031\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"title\":\"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\",\"url\":\"https://www.semanticscholar.org/paper/424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2015},{\"arxivId\":\"1611.01646\",\"authors\":[{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/ICCV.2017.524\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5785466bc14529e94e54baa4ed051f7037f3b1d3\",\"title\":\"Boosting Image Captioning with Attributes\",\"url\":\"https://www.semanticscholar.org/paper/5785466bc14529e94e54baa4ed051f7037f3b1d3\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017}],\"title\":\"Attention on Attention for Image Captioning\",\"topics\":[{\"topic\":\"Encoder\",\"topicId\":\"16744\",\"url\":\"https://www.semanticscholar.org/topic/16744\"},{\"topic\":\"Relevance\",\"topicId\":\"503\",\"url\":\"https://www.semanticscholar.org/topic/503\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Online and offline\",\"topicId\":\"12094\",\"url\":\"https://www.semanticscholar.org/topic/12094\"},{\"topic\":\"Server (computing)\",\"topicId\":\"6042\",\"url\":\"https://www.semanticscholar.org/topic/6042\"}],\"url\":\"https://www.semanticscholar.org/paper/4c163d4942117179d3e97182e1b280027d7d60a9\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019}\n"