"{\"abstract\":\"While image synthesis achieves tremendous breakthroughs (e.g., generating realistic faces), video generation is less explored and harder to control, which limits its applications in the real world. For instance, video editing requires temporal coherence across multiple clips and thus poses both start and end constraints within a video sequence. We introduce point-to-point video generation that controls the generation process with two control points: the targeted start- and end-frames. The task is challenging since the model not only generates a smooth transition of frames but also plans ahead to ensure that the generated end-frame conforms to the targeted end-frame for videos of various lengths. We propose to maximize the modified variational lower bound of conditional data likelihood under a skip-frame training strategy. Our model can generate end-frame-consistent sequences without loss of quality and diversity. We evaluate our method through extensive experiments on Stochastic Moving MNIST, Weizmann Action, Human3.6M, and BAIR Robot Pushing under a series of scenarios. The qualitative results showcase the effectiveness and merits of point-to-point generation.\",\"arxivId\":\"1904.02912\",\"authors\":[{\"authorId\":\"40897201\",\"name\":\"Tsun-Hsuan Wang\",\"url\":\"https://www.semanticscholar.org/author/40897201\"},{\"authorId\":\"94288126\",\"name\":\"Y. Cheng\",\"url\":\"https://www.semanticscholar.org/author/94288126\"},{\"authorId\":\"49044307\",\"name\":\"Chieh Hubert Lin\",\"url\":\"https://www.semanticscholar.org/author/49044307\"},{\"authorId\":\"1803730\",\"name\":\"Hwann-Tzong Chen\",\"url\":\"https://www.semanticscholar.org/author/1803730\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\",\"url\":\"https://www.semanticscholar.org/author/145718481\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":\"1812.01874\",\"authors\":[{\"authorId\":\"5437547\",\"name\":\"Qiyang Hu\"},{\"authorId\":\"1822120361\",\"name\":\"Adrian Walchli\"},{\"authorId\":\"21529935\",\"name\":\"Tiziano Portenier\"},{\"authorId\":\"1796846\",\"name\":\"Matthias Zwicker\"},{\"authorId\":\"144707901\",\"name\":\"P. Favaro\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6bb74e29321772ea815f88769d31a902a2c3e996\",\"title\":\"Learning to Take Directions One Step at a Time\",\"url\":\"https://www.semanticscholar.org/paper/6bb74e29321772ea815f88769d31a902a2c3e996\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10755743\",\"name\":\"Takayuki Nakatsuka\"},{\"authorId\":\"2844427\",\"name\":\"M. Hamanaka\"},{\"authorId\":\"1490867805\",\"name\":\"Shigeo Morishima\"}],\"doi\":\"10.5220/0008876600270035\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c1de74772253f4b9ebb4ea86b1602fa1445786f\",\"title\":\"Audio-guided Video Interpolation via Human Pose Features\",\"url\":\"https://www.semanticscholar.org/paper/6c1de74772253f4b9ebb4ea86b1602fa1445786f\",\"venue\":\"VISIGRAPP\",\"year\":2020},{\"arxivId\":\"2007.08397\",\"authors\":[{\"authorId\":\"94288126\",\"name\":\"Y. Cheng\"},{\"authorId\":\"49923155\",\"name\":\"Hsin-Ying Lee\"},{\"authorId\":\"30885811\",\"name\":\"Min Sun\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1007/978-3-030-58571-6_10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c4e84b1cbf81a6c89c1f0cc9ed2496ea5102fa56\",\"title\":\"Controllable Image Synthesis via SegVAE\",\"url\":\"https://www.semanticscholar.org/paper/c4e84b1cbf81a6c89c1f0cc9ed2496ea5102fa56\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2012.03796\",\"authors\":[{\"authorId\":\"9222620\",\"name\":\"J. S. Yoon\"},{\"authorId\":\"46458089\",\"name\":\"Lingjie Liu\"},{\"authorId\":\"3407706\",\"name\":\"Vladislav Golyanik\"},{\"authorId\":\"3434185\",\"name\":\"K. Sarkar\"},{\"authorId\":\"1806522\",\"name\":\"H. Park\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c89ae90f158a55c6a8faf363111d316f7ece99af\",\"title\":\"Pose-Guided Human Animation from a Single Image in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/c89ae90f158a55c6a8faf363111d316f7ece99af\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.09565\",\"authors\":[{\"authorId\":\"2274692\",\"name\":\"Abhishek Aich\"},{\"authorId\":\"150015249\",\"name\":\"Akash Gupta\"},{\"authorId\":\"1819152\",\"name\":\"R. Panda\"},{\"authorId\":\"12212948\",\"name\":\"Rakib Hyder\"},{\"authorId\":\"27996204\",\"name\":\"M. Asif\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":\"10.1109/cvpr42600.2020.00613\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6a55aad6a51662da2d1e454a41878935a86a5d4a\",\"title\":\"Non-Adversarial Video Synthesis with Learned Priors\",\"url\":\"https://www.semanticscholar.org/paper/6a55aad6a51662da2d1e454a41878935a86a5d4a\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2006.13205\",\"authors\":[{\"authorId\":\"31719101\",\"name\":\"Karl Pertsch\"},{\"authorId\":\"40900227\",\"name\":\"Oleh Rybkin\"},{\"authorId\":\"27535721\",\"name\":\"Frederik Ebert\"},{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"},{\"authorId\":\"144348441\",\"name\":\"Dinesh Jayaraman\"},{\"authorId\":\"152198491\",\"name\":\"Sergey Levine\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8dd3ec3ca1b7400d998e747356d07763a7ac1fb0\",\"title\":\"Long-Horizon Visual Planning with Goal-Conditioned Hierarchical Predictors\",\"url\":\"https://www.semanticscholar.org/paper/8dd3ec3ca1b7400d998e747356d07763a7ac1fb0\",\"venue\":\"NeurIPS\",\"year\":2020}],\"corpusId\":102351432,\"doi\":\"10.1109/ICCV.2019.01059\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"cb0a151cf8740c66b461ff809e086b91f14bd23b\",\"references\":[{\"arxivId\":\"1605.09673\",\"authors\":[{\"authorId\":\"40347509\",\"name\":\"Xu Jia\"},{\"authorId\":\"3384995\",\"name\":\"Bert De Brabandere\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aba48504f4f9563eafa44e0cfb22e1345d767c80\",\"title\":\"Dynamic Filter Networks\",\"url\":\"https://www.semanticscholar.org/paper/aba48504f4f9563eafa44e0cfb22e1345d767c80\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1706.08033\",\"authors\":[{\"authorId\":\"144543406\",\"name\":\"R. Villegas\"},{\"authorId\":\"1768964\",\"name\":\"Jimei Yang\"},{\"authorId\":\"2241528\",\"name\":\"Seunghoon Hong\"},{\"authorId\":\"10668384\",\"name\":\"Xunyu Lin\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b8375ff50b8a6f1a10dd809129a18df96888ac8b\",\"title\":\"Decomposing Motion and Content for Natural Video Sequence Prediction\",\"url\":\"https://www.semanticscholar.org/paper/b8375ff50b8a6f1a10dd809129a18df96888ac8b\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1804.01622\",\"authors\":[{\"authorId\":\"153365679\",\"name\":\"J. Johnson\"},{\"authorId\":\"25445698\",\"name\":\"Agrim Gupta\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2018.00133\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"46b5d408d950287637dd21ce04772d9b2bacfd14\",\"title\":\"Image Generation from Scene Graphs\",\"url\":\"https://www.semanticscholar.org/paper/46b5d408d950287637dd21ce04772d9b2bacfd14\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2273228\",\"name\":\"Catalin Ionescu\"},{\"authorId\":\"2781306\",\"name\":\"Dragos Papava\"},{\"authorId\":\"2185203\",\"name\":\"V. Olaru\"},{\"authorId\":\"1781120\",\"name\":\"C. Sminchisescu\"}],\"doi\":\"10.1109/TPAMI.2013.248\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"bac377d3a051899dbe0d7249ed5d3d0b22d57310\",\"title\":\"Human3.6M: Large Scale Datasets and Predictive Methods for 3D Human Sensing in Natural Environments\",\"url\":\"https://www.semanticscholar.org/paper/bac377d3a051899dbe0d7249ed5d3d0b22d57310\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2014},{\"arxivId\":\"1609.03552\",\"authors\":[{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"2562966\",\"name\":\"Philipp Kr\\u00e4henb\\u00fchl\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1007/978-3-319-46454-1_36\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fc7822f56dd255a872326b9536a0821bbf0277dd\",\"title\":\"Generative Visual Manipulation on the Natural Image Manifold\",\"url\":\"https://www.semanticscholar.org/paper/fc7822f56dd255a872326b9536a0821bbf0277dd\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1808.06882\",\"authors\":[{\"authorId\":\"8792285\",\"name\":\"Olivia Wiles\"},{\"authorId\":\"32445716\",\"name\":\"A. Koepke\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e5fbffd3449a2bfe0acb4ec339a19f5b88fff783\",\"title\":\"Self-supervised learning of a facial attribute embedding from video\",\"url\":\"https://www.semanticscholar.org/paper/e5fbffd3449a2bfe0acb4ec339a19f5b88fff783\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":\"1609.02612\",\"authors\":[{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"2367683\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.13016/M26GIH-TNYZ\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ee091ccf24c4f053c5c3dfbefe4a7975ed3447c1\",\"title\":\"Generating Videos with Scene Dynamics\",\"url\":\"https://www.semanticscholar.org/paper/ee091ccf24c4f053c5c3dfbefe4a7975ed3447c1\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19235216\",\"name\":\"Zekun Hao\"},{\"authorId\":\"47932904\",\"name\":\"Xun Huang\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"}],\"doi\":\"10.1109/CVPR.2018.00819\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d629ee73070e7c693ae6924aa52df129a127b33\",\"title\":\"Controllable Video Generation with Sparse Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/9d629ee73070e7c693ae6924aa52df129a127b33\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1702.02463\",\"authors\":[{\"authorId\":\"3243969\",\"name\":\"Z. Liu\"},{\"authorId\":\"28919105\",\"name\":\"Raymond A. Yeh\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"36966089\",\"name\":\"Y. Liu\"},{\"authorId\":\"1696487\",\"name\":\"A. Agarwala\"}],\"doi\":\"10.1109/ICCV.2017.478\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8970e9caed1fca960ead644e6453a1a7321a7e6d\",\"title\":\"Video Frame Synthesis Using Deep Voxel Flow\",\"url\":\"https://www.semanticscholar.org/paper/8970e9caed1fca960ead644e6453a1a7321a7e6d\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1810.01325\",\"authors\":[{\"authorId\":\"51466944\",\"name\":\"Sandra Aigner\"},{\"authorId\":\"119567230\",\"name\":\"Marco Korner\"}],\"doi\":\"10.5194/isprs-archives-xlii-2-w16-3-2019\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b6cad0b0ffd5d7b5ec1db60173c194ae2a9ec947\",\"title\":\"FutureGAN: Anticipating the Future Frames of Video Sequences using Spatio-Temporal 3d Convolutions in Progressively Growing GANs\",\"url\":\"https://www.semanticscholar.org/paper/b6cad0b0ffd5d7b5ec1db60173c194ae2a9ec947\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1511.05440\",\"authors\":[{\"authorId\":\"143949035\",\"name\":\"Micha\\u00ebl Mathieu\"},{\"authorId\":\"2341378\",\"name\":\"C. Couprie\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"17fa1c2a24ba8f731c8b21f1244463bc4b465681\",\"title\":\"Deep multi-scale video prediction beyond mean square error\",\"url\":\"https://www.semanticscholar.org/paper/17fa1c2a24ba8f731c8b21f1244463bc4b465681\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":\"1808.07784\",\"authors\":[{\"authorId\":\"144348441\",\"name\":\"Dinesh Jayaraman\"},{\"authorId\":\"27535721\",\"name\":\"Frederik Ebert\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"973e116b2b2949fdb8c533a8d84ddd811c0920cf\",\"title\":\"Time-Agnostic Prediction: Predicting Predictable Video Frames\",\"url\":\"https://www.semanticscholar.org/paper/973e116b2b2949fdb8c533a8d84ddd811c0920cf\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1412.6604\",\"authors\":[{\"authorId\":\"1706809\",\"name\":\"Marc'Aurelio Ranzato\"},{\"authorId\":\"3149531\",\"name\":\"Arthur Szlam\"},{\"authorId\":\"143627859\",\"name\":\"Joan Bruna\"},{\"authorId\":\"143949035\",\"name\":\"Micha\\u00ebl Mathieu\"},{\"authorId\":\"2939803\",\"name\":\"Ronan Collobert\"},{\"authorId\":\"3295092\",\"name\":\"S. Chopra\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"355f98e4827a1b6ad3f29d07ea2bcf9ad078295c\",\"title\":\"Video (language) modeling: a baseline for generative models of natural videos\",\"url\":\"https://www.semanticscholar.org/paper/355f98e4827a1b6ad3f29d07ea2bcf9ad078295c\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":\"1512.00570\",\"authors\":[{\"authorId\":\"3084614\",\"name\":\"Xinchen Yan\"},{\"authorId\":\"1768964\",\"name\":\"Jimei Yang\"},{\"authorId\":\"1729571\",\"name\":\"Kihyuk Sohn\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"}],\"doi\":\"10.1007/978-3-319-46493-0_47\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2d0363a3ebda56d91d704d5ff5458a527775b609\",\"title\":\"Attribute2Image: Conditional Image Generation from Visual Attributes\",\"url\":\"https://www.semanticscholar.org/paper/2d0363a3ebda56d91d704d5ff5458a527775b609\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1802.07687\",\"authors\":[{\"authorId\":\"40081727\",\"name\":\"Emily L. Denton\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"de3b9eb697feed3d097e3f671afe395f48c1ab76\",\"title\":\"Stochastic Video Generation with a Learned Prior\",\"url\":\"https://www.semanticscholar.org/paper/de3b9eb697feed3d097e3f671afe395f48c1ab76\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3089071\",\"name\":\"Lena Gorelick\"},{\"authorId\":\"50170517\",\"name\":\"M. Blank\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"144611617\",\"name\":\"M. Irani\"},{\"authorId\":\"1760994\",\"name\":\"R. Basri\"}],\"doi\":\"10.1109/TPAMI.2007.70711\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"45a7c9deb52e0326618a6220716fe8f45d5dca7d\",\"title\":\"Actions as Space-Time Shapes\",\"url\":\"https://www.semanticscholar.org/paper/45a7c9deb52e0326618a6220716fe8f45d5dca7d\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2007},{\"arxivId\":\"1705.10915\",\"authors\":[{\"authorId\":\"40081727\",\"name\":\"Emily L. Denton\"},{\"authorId\":\"3468723\",\"name\":\"Vighnesh Birodkar\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1a8d3ad2b400bcebc9f17b309901ca5ef2e95315\",\"title\":\"Unsupervised Learning of Disentangled Representations from Video\",\"url\":\"https://www.semanticscholar.org/paper/1a8d3ad2b400bcebc9f17b309901ca5ef2e95315\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1708.05980\",\"authors\":[{\"authorId\":\"8268761\",\"name\":\"T. Marwah\"},{\"authorId\":\"47351893\",\"name\":\"G. Mittal\"},{\"authorId\":\"1699429\",\"name\":\"V. Balasubramanian\"}],\"doi\":\"10.1109/ICCV.2017.159\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1491b98d8e9ccca13bec883f94d935d2dff24053\",\"title\":\"Attentive Semantic Video Generation Using Captions\",\"url\":\"https://www.semanticscholar.org/paper/1491b98d8e9ccca13bec883f94d935d2dff24053\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1710.11252\",\"authors\":[{\"authorId\":\"3365707\",\"name\":\"M. Babaeizadeh\"},{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"143775101\",\"name\":\"R. Campbell\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"59d86da5c5936e7a236678bf5eaaa7753c226fb1\",\"title\":\"Stochastic Variational Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/59d86da5c5936e7a236678bf5eaaa7753c226fb1\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Simon Niklaus\"},{\"authorId\":null,\"name\":\"Long Mai\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Gross , and Christopher Schroers . Phasenet for video frame interpolation\",\"url\":\"\",\"venue\":\"Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":null},{\"arxivId\":\"1804.00884\",\"authors\":[{\"authorId\":\"50113176\",\"name\":\"S. Meyer\"},{\"authorId\":\"1763523\",\"name\":\"Abdelaziz Djelouah\"},{\"authorId\":\"46936952\",\"name\":\"Brian McWilliams\"},{\"authorId\":\"1388791172\",\"name\":\"Alexander Sorkine-Hornung\"},{\"authorId\":\"144877478\",\"name\":\"M. Gross\"},{\"authorId\":\"2604867\",\"name\":\"Christopher Schroers\"}],\"doi\":\"10.1109/CVPR.2018.00059\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b934bdaaaed7af7269a368a8c93c87c293f876f8\",\"title\":\"PhaseNet for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/b934bdaaaed7af7269a368a8c93c87c293f876f8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Pieter Abbeel\"},{\"authorId\":null,\"name\":\"Chelsea Finn\"},{\"authorId\":null,\"name\":\"Xiaodan Liang\"},{\"authorId\":null,\"name\":\"Lisa Lee\"},{\"authorId\":null,\"name\":\"Wei Dai\"},{\"authorId\":null,\"name\":\"Eric P Xing\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Kingma and Max Welling . Auto - encoding variational bayes\",\"url\":\"\",\"venue\":\"Proceedings of the International Conference on Learning Representations\",\"year\":2014},{\"arxivId\":\"1708.00284\",\"authors\":[{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"87068304\",\"name\":\"L. Lee\"},{\"authorId\":\"143716171\",\"name\":\"Wei Dai\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":\"10.1109/ICCV.2017.194\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"eb911796464b1e01e98c2b3d007a4ef9310272e2\",\"title\":\"Dual Motion GAN for Future-Flow Embedded Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/eb911796464b1e01e98c2b3d007a4ef9310272e2\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1803.08085\",\"authors\":[{\"authorId\":\"50775044\",\"name\":\"Jiawei He\"},{\"authorId\":\"20812150\",\"name\":\"Andreas M. Lehrmann\"},{\"authorId\":\"145170722\",\"name\":\"Joseph Marino\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":\"10.1007/978-3-030-01228-1_28\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f53044c0a9cec1af142b8b0e9f5ddf389fe7b6a6\",\"title\":\"Probabilistic Video Generation using Holistic Attribute Control\",\"url\":\"https://www.semanticscholar.org/paper/f53044c0a9cec1af142b8b0e9f5ddf389fe7b6a6\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1812.01874\",\"authors\":[{\"authorId\":\"5437547\",\"name\":\"Qiyang Hu\"},{\"authorId\":\"1822120361\",\"name\":\"Adrian Walchli\"},{\"authorId\":\"21529935\",\"name\":\"Tiziano Portenier\"},{\"authorId\":\"1796846\",\"name\":\"Matthias Zwicker\"},{\"authorId\":\"144707901\",\"name\":\"P. Favaro\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6bb74e29321772ea815f88769d31a902a2c3e996\",\"title\":\"Learning to Take Directions One Step at a Time\",\"url\":\"https://www.semanticscholar.org/paper/6bb74e29321772ea815f88769d31a902a2c3e996\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1808.04545\",\"authors\":[{\"authorId\":\"3084614\",\"name\":\"Xinchen Yan\"},{\"authorId\":\"51114494\",\"name\":\"Akash Rastogi\"},{\"authorId\":\"144543406\",\"name\":\"R. Villegas\"},{\"authorId\":\"2454127\",\"name\":\"Kalyan Sunkavalli\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"1733732\",\"name\":\"Sunil Hadap\"},{\"authorId\":\"8020964\",\"name\":\"Ersin Yumer\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"}],\"doi\":\"10.1007/978-3-030-01228-1_17\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2ce852f1e9b6d8d97787127d43dcbec1cdeeda09\",\"title\":\"MT-VAE: Learning Motion Transformations to Generate Multimodal Human Dynamics\",\"url\":\"https://www.semanticscholar.org/paper/2ce852f1e9b6d8d97787127d43dcbec1cdeeda09\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1502.04681\",\"authors\":[{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"2711409\",\"name\":\"Elman Mansimov\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"title\":\"Unsupervised Learning of Video Representations using LSTMs\",\"url\":\"https://www.semanticscholar.org/paper/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1729571\",\"name\":\"Kihyuk Sohn\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"},{\"authorId\":\"3084614\",\"name\":\"Xinchen Yan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"3f25e17eb717e5894e0404ea634451332f85d287\",\"title\":\"Learning Structured Output Representation using Deep Conditional Generative Models\",\"url\":\"https://www.semanticscholar.org/paper/3f25e17eb717e5894e0404ea634451332f85d287\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1607.02586\",\"authors\":[{\"authorId\":\"3222730\",\"name\":\"Tianfan Xue\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"18555073\",\"name\":\"K. Bouman\"},{\"authorId\":\"36668046\",\"name\":\"B. Freeman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"397e9b56e46d3cc34af1525493e597facb104570\",\"title\":\"Visual Dynamics: Probabilistic Future Frame Synthesis via Cross Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/397e9b56e46d3cc34af1525493e597facb104570\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1711.10485\",\"authors\":[{\"authorId\":\"39866461\",\"name\":\"T. Xu\"},{\"authorId\":\"9325940\",\"name\":\"Pengchuan Zhang\"},{\"authorId\":\"1788124\",\"name\":\"Qiuyuan Huang\"},{\"authorId\":\"48213346\",\"name\":\"Han Zhang\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"143713756\",\"name\":\"Xiaolei Huang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"}],\"doi\":\"10.1109/CVPR.2018.00143\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8b35c00edfa4edfd7a99d816e671023d2c000d55\",\"title\":\"AttnGAN: Fine-Grained Text to Image Generation with Attentional Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/8b35c00edfa4edfd7a99d816e671023d2c000d55\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1312.6114\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"1678311\",\"name\":\"M. Welling\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"5f5dc5b9a2ba710937e2c413b37b053cd673df02\",\"title\":\"Auto-Encoding Variational Bayes\",\"url\":\"https://www.semanticscholar.org/paper/5f5dc5b9a2ba710937e2c413b37b053cd673df02\",\"venue\":\"ICLR\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5437547\",\"name\":\"Qiyang Hu\"},{\"authorId\":\"52148417\",\"name\":\"Adrian Waelchli\"},{\"authorId\":\"21529935\",\"name\":\"Tiziano Portenier\"},{\"authorId\":\"1796846\",\"name\":\"Matthias Zwicker\"},{\"authorId\":\"145646305\",\"name\":\"P. Favaro\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"949ec7afb546060a8c8929462b2eb7bdb468f30a\",\"title\":\"Video Synthesis from a Single Image and Motion Stroke\",\"url\":\"https://www.semanticscholar.org/paper/949ec7afb546060a8c8929462b2eb7bdb468f30a\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/CVPR.2017.319\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d2892f82a89bfc81f9924adb8bd070fe007adf7\",\"title\":\"Generating the Future with Adversarial Transformers\",\"url\":\"https://www.semanticscholar.org/paper/6d2892f82a89bfc81f9924adb8bd070fe007adf7\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51466944\",\"name\":\"Sandra Aigner\"},{\"authorId\":\"2388085\",\"name\":\"M. K\\u00f6rner\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0fc9b202107bafa4b755c913c904d8ab046b8113\",\"title\":\"FutureGAN: Anticipating the Future Frames of Video Sequences using Spatio-Temporal 3d Convolutions in Progressively Growing Autoencoder GANs\",\"url\":\"https://www.semanticscholar.org/paper/0fc9b202107bafa4b755c913c904d8ab046b8113\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Frederik Ebert\"},{\"authorId\":null,\"name\":\"Chelsea Finn\"},{\"authorId\":null,\"name\":\"Alex Lee\"},{\"authorId\":null,\"name\":\"Sergey Levine\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Denton and Vighnesh Birodkar . Unsupervised learning of disentangled representations from video\",\"url\":\"\",\"venue\":\"Ad - vances in Neural Information Processing Systems\",\"year\":null},{\"arxivId\":\"1511.06380\",\"authors\":[{\"authorId\":\"2023002\",\"name\":\"William Lotter\"},{\"authorId\":\"1852992\",\"name\":\"G. Kreiman\"},{\"authorId\":\"2042941\",\"name\":\"D. Cox\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b7d5d7e2e0b4af3ff8a7b1f7ee59281eca6e47e6\",\"title\":\"Unsupervised Learning of Visual Structure using Predictive Generative Networks\",\"url\":\"https://www.semanticscholar.org/paper/b7d5d7e2e0b4af3ff8a7b1f7ee59281eca6e47e6\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1712.00080\",\"authors\":[{\"authorId\":\"40175280\",\"name\":\"Huaizu Jiang\"},{\"authorId\":\"3232265\",\"name\":\"Deqing Sun\"},{\"authorId\":\"2745026\",\"name\":\"V. Jampani\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"1389846455\",\"name\":\"E. Learned-Miller\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":\"10.1109/CVPR.2018.00938\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"baa1ae74fbf7ed6204f2f6364d51375ff81aabc1\",\"title\":\"Super SloMo: High Quality Estimation of Multiple Intermediate Frames for Video Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/baa1ae74fbf7ed6204f2f6364d51375ff81aabc1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1804.01523\",\"authors\":[{\"authorId\":\"49250083\",\"name\":\"Alex X. Lee\"},{\"authorId\":\"2844849\",\"name\":\"Richard Zhang\"},{\"authorId\":\"27535721\",\"name\":\"Frederik Ebert\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"},{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9f67271a1edea3bf80c64c2d54e2a0a57612a567\",\"title\":\"Stochastic Adversarial Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/9f67271a1edea3bf80c64c2d54e2a0a57612a567\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1710.00421\",\"authors\":[{\"authorId\":\"2664705\",\"name\":\"Y. Li\"},{\"authorId\":\"2984407\",\"name\":\"Martin Renqiang Min\"},{\"authorId\":\"19178763\",\"name\":\"Dinghan Shen\"},{\"authorId\":\"144752689\",\"name\":\"David Edwin Carlson\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3a2bbf1f895a1850da3bb6d92b4ffbe61b68145d\",\"title\":\"Video Generation From Text\",\"url\":\"https://www.semanticscholar.org/paper/3a2bbf1f895a1850da3bb6d92b4ffbe61b68145d\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1806.04166\",\"authors\":[{\"authorId\":\"7164257\",\"name\":\"Jun-Ting Hsieh\"},{\"authorId\":\"51033208\",\"name\":\"B. Liu\"},{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1d38ee16ed990689c3a85160dbc20e22b72afb6d\",\"title\":\"Learning to Decompose and Disentangle Representations for Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/1d38ee16ed990689c3a85160dbc20e22b72afb6d\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1705.00053\",\"authors\":[{\"authorId\":\"143928130\",\"name\":\"J. Walker\"},{\"authorId\":\"35789996\",\"name\":\"Kenneth Marino\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1109/ICCV.2017.361\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3df8cc0384814c3fb05c44e494ced947a7d43f36\",\"title\":\"The Pose Knows: Video Forecasting by Generating Pose Futures\",\"url\":\"https://www.semanticscholar.org/paper/3df8cc0384814c3fb05c44e494ced947a7d43f36\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1901.09024\",\"authors\":[{\"authorId\":\"35573122\",\"name\":\"Dingdong Yang\"},{\"authorId\":\"2241528\",\"name\":\"Seunghoon Hong\"},{\"authorId\":\"2338742\",\"name\":\"Y. Jang\"},{\"authorId\":\"30940066\",\"name\":\"T. Zhao\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cc8a7a229151d17b1088d059fc471da2cea718c3\",\"title\":\"Diversity-Sensitive Conditional Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/cc8a7a229151d17b1088d059fc471da2cea718c3\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1710.05268\",\"authors\":[{\"authorId\":\"27535721\",\"name\":\"Frederik Ebert\"},{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"},{\"authorId\":\"49250083\",\"name\":\"Alex X. Lee\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"cf18287e79b1fd73cd333fc914bb24c00a537f4c\",\"title\":\"Self-Supervised Visual Planning with Temporal Skip Connections\",\"url\":\"https://www.semanticscholar.org/paper/cf18287e79b1fd73cd333fc914bb24c00a537f4c\",\"venue\":\"CoRL\",\"year\":2017},{\"arxivId\":\"1511.06434\",\"authors\":[{\"authorId\":\"38909097\",\"name\":\"A. Radford\"},{\"authorId\":\"2096458\",\"name\":\"Luke Metz\"},{\"authorId\":\"2127604\",\"name\":\"Soumith Chintala\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8388f1be26329fa45e5807e968a641ce170ea078\",\"title\":\"Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/8388f1be26329fa45e5807e968a641ce170ea078\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"D. Yang\"},{\"authorId\":null,\"name\":\"S. Hong\"},{\"authorId\":null,\"name\":\"Y. Jang\"},{\"authorId\":null,\"name\":\"T. Zhao\"},{\"authorId\":null,\"name\":\"H. Lee\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Diversitysensitive conditional generative adversarial networks\",\"url\":\"\",\"venue\":\"Proceedings of the International Conference on Learning Representations,\",\"year\":2019},{\"arxivId\":\"1707.04993\",\"authors\":[{\"authorId\":\"145582202\",\"name\":\"S. Tulyakov\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":\"144434220\",\"name\":\"X. Yang\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":\"10.1109/CVPR.2018.00165\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e76edb86f270c3a77ed9f5a1e1b305461f36f96f\",\"title\":\"MoCoGAN: Decomposing Motion and Content for Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/e76edb86f270c3a77ed9f5a1e1b305461f36f96f\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1611.06624\",\"authors\":[{\"authorId\":\"144648787\",\"name\":\"M. Saito\"},{\"authorId\":\"8252749\",\"name\":\"E. Matsumoto\"},{\"authorId\":\"3083107\",\"name\":\"Shunta Saito\"}],\"doi\":\"10.1109/ICCV.2017.308\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"062c41dad67bb68fefd9ff0c5c4d296e796004dc\",\"title\":\"Temporal Generative Adversarial Nets with Singular Value Clipping\",\"url\":\"https://www.semanticscholar.org/paper/062c41dad67bb68fefd9ff0c5c4d296e796004dc\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1703.07514\",\"authors\":[{\"authorId\":\"39644974\",\"name\":\"Simon Niklaus\"},{\"authorId\":\"2712573\",\"name\":\"Long Mai\"},{\"authorId\":\"40513795\",\"name\":\"Feng Liu\"}],\"doi\":\"10.1109/CVPR.2017.244\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"841832fae29497f20ed795604ce76358ed7e51c3\",\"title\":\"Video Frame Interpolation via Adaptive Convolution\",\"url\":\"https://www.semanticscholar.org/paper/841832fae29497f20ed795604ce76358ed7e51c3\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1708.01692\",\"authors\":[{\"authorId\":\"39644974\",\"name\":\"Simon Niklaus\"},{\"authorId\":\"2712573\",\"name\":\"Long Mai\"},{\"authorId\":\"40513795\",\"name\":\"Feng Liu\"}],\"doi\":\"10.1109/ICCV.2017.37\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ed74b9390eda908060fa3501b8f20a836ec98d63\",\"title\":\"Video Frame Interpolation via Adaptive Separable Convolution\",\"url\":\"https://www.semanticscholar.org/paper/ed74b9390eda908060fa3501b8f20a836ec98d63\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1403025868\",\"name\":\"Jean Pouget-Abadie\"},{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"144738865\",\"name\":\"Bing Xu\"},{\"authorId\":\"1393680089\",\"name\":\"David Warde-Farley\"},{\"authorId\":\"1955694\",\"name\":\"Sherjil Ozair\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"title\":\"Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1705.02082\",\"authors\":[{\"authorId\":\"1705557\",\"name\":\"K. Fragkiadaki\"},{\"authorId\":\"1808244\",\"name\":\"J. Huang\"},{\"authorId\":\"122113652\",\"name\":\"Alexander Amir Alemi\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"2262946\",\"name\":\"S. Ricco\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a68163dca89433f1ebd3f81ac58a482dd90174b3\",\"title\":\"Motion Prediction Under Multimodality with Conditional Stochastic Networks\",\"url\":\"https://www.semanticscholar.org/paper/a68163dca89433f1ebd3f81ac58a482dd90174b3\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1605.07157\",\"authors\":[{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f110cfdbe9ded7a384bcf5c0d56e536bd275a7eb\",\"title\":\"Unsupervised Learning for Physical Interaction through Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/f110cfdbe9ded7a384bcf5c0d56e536bd275a7eb\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1812.01261\",\"authors\":[{\"authorId\":\"48333400\",\"name\":\"S. Yamamoto\"},{\"authorId\":\"1399435786\",\"name\":\"Antonio Tejero-de-Pablos\"},{\"authorId\":\"3250559\",\"name\":\"Y. Ushiku\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e8de3d97d14344d13d15701eea8d6a27c696e27a\",\"title\":\"Conditional Video Generation Using Action-Appearance Captions\",\"url\":\"https://www.semanticscholar.org/paper/e8de3d97d14344d13d15701eea8d6a27c696e27a\",\"venue\":\"ArXiv\",\"year\":2018}],\"title\":\"Point-to-Point Video Generation\",\"topics\":[{\"topic\":\"Coherence (physics)\",\"topicId\":\"921\",\"url\":\"https://www.semanticscholar.org/topic/921\"},{\"topic\":\"Point-to-Point Protocol\",\"topicId\":\"3845\",\"url\":\"https://www.semanticscholar.org/topic/3845\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"MNIST database\",\"topicId\":\"211771\",\"url\":\"https://www.semanticscholar.org/topic/211771\"},{\"topic\":\"Frame (physical object)\",\"topicId\":\"4537\",\"url\":\"https://www.semanticscholar.org/topic/4537\"},{\"topic\":\"Calculus of variations\",\"topicId\":\"34187\",\"url\":\"https://www.semanticscholar.org/topic/34187\"},{\"topic\":\"Fibre Channel point-to-point\",\"topicId\":\"9582008\",\"url\":\"https://www.semanticscholar.org/topic/9582008\"},{\"topic\":\"videocassette\",\"topicId\":\"20721\",\"url\":\"https://www.semanticscholar.org/topic/20721\"},{\"topic\":\"Face\",\"topicId\":\"10302\",\"url\":\"https://www.semanticscholar.org/topic/10302\"}],\"url\":\"https://www.semanticscholar.org/paper/cb0a151cf8740c66b461ff809e086b91f14bd23b\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019}\n"