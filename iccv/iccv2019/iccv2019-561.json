"{\"abstract\":\"Temporal reasoning is an important aspect of video analysis. 3D CNN shows good performance by exploring spatial-temporal features jointly in an unconstrained way, but it also increases the computational cost a lot. Previous works try to reduce the complexity by decoupling the spatial and temporal filters. In this paper, we propose a novel decomposition method that decomposes the feature channels into spatial and temporal groups in parallel. This decomposition can make two groups focus on static and dynamic cues separately. We call this grouped spatial-temporal aggregation (GST). This decomposition is more parameter-efficient and enables us to quantitatively analyze the contributions of spatial and temporal features in different layers. We verify our model on several action recognition tasks that require temporal reasoning and show its effectiveness.\",\"arxivId\":\"1909.13130\",\"authors\":[{\"authorId\":\"153918891\",\"name\":\"Chenxu Luo\",\"url\":\"https://www.semanticscholar.org/author/153918891\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\",\"url\":\"https://www.semanticscholar.org/author/145081362\"}],\"citationVelocity\":15,\"citations\":[{\"arxivId\":\"2006.16367\",\"authors\":[{\"authorId\":\"1901361\",\"name\":\"Pramit Saha\"},{\"authorId\":\"46398931\",\"name\":\"Y. Liu\"},{\"authorId\":\"2160324\",\"name\":\"B. Gick\"},{\"authorId\":\"23111666\",\"name\":\"S. Fels\"}],\"doi\":\"10.1007/978-3-030-59716-0_45\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"11809d6c31e471fb45569c5f40f3f4e7566ee3ce\",\"title\":\"Ultra2Speech - A Deep Learning Framework for Formant Frequency Estimation and Tracking from Ultrasound Tongue Images\",\"url\":\"https://www.semanticscholar.org/paper/11809d6c31e471fb45569c5f40f3f4e7566ee3ce\",\"venue\":\"MICCAI\",\"year\":2020},{\"arxivId\":\"2007.11365\",\"authors\":[{\"authorId\":\"39440469\",\"name\":\"Sudhakar Kumawat\"},{\"authorId\":\"145879750\",\"name\":\"Manisha Verma\"},{\"authorId\":\"1789677\",\"name\":\"Yuta Nakashima\"},{\"authorId\":\"145853779\",\"name\":\"S. Raman\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4914a205aa1ddeaae3c86a449c69703c89484f54\",\"title\":\"Depthwise Spatio-Temporal STFT Convolutional Neural Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4914a205aa1ddeaae3c86a449c69703c89484f54\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.02113\",\"authors\":[{\"authorId\":\"47892681\",\"name\":\"Haoxin Li\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"},{\"authorId\":\"1401057385\",\"name\":\"Yu Tao\"},{\"authorId\":\"37403439\",\"name\":\"H. Hu\"},{\"authorId\":\"153224231\",\"name\":\"Jianhuang Lai\"}],\"doi\":\"10.1109/CVPR42600.2020.00060\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5c02af517dff2ff0d34dee04535731b7d252bbbb\",\"title\":\"Adaptive Interaction Modeling via Graph Operations Search\",\"url\":\"https://www.semanticscholar.org/paper/5c02af517dff2ff0d34dee04535731b7d252bbbb\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2004228925\",\"name\":\"Jinhao Duan\"},{\"authorId\":\"40463478\",\"name\":\"H. Xu\"},{\"authorId\":\"48030229\",\"name\":\"Xiaozhu Lin\"},{\"authorId\":\"2004346653\",\"name\":\"Shangchao Zhu\"},{\"authorId\":\"115394762\",\"name\":\"Y. Du\"}],\"doi\":\"10.1016/j.imavis.2020.103988\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"68e1892f95de0a982571c0c5df1c12c42364ee11\",\"title\":\"Multi-semantic long-range dependencies capturing for efficient video representation learning\",\"url\":\"https://www.semanticscholar.org/paper/68e1892f95de0a982571c0c5df1c12c42364ee11\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2010.06647\",\"authors\":[{\"authorId\":\"153634296\",\"name\":\"Matthew Hutchinson\"},{\"authorId\":\"74882299\",\"name\":\"Vijay Gadepally\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"65955a106905afb90a2a2fa74e48c6d6d597892f\",\"title\":\"Video Action Understanding: A Tutorial\",\"url\":\"https://www.semanticscholar.org/paper/65955a106905afb90a2a2fa74e48c6d6d597892f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491240780\",\"name\":\"Z. Shi\"},{\"authorId\":\"144962375\",\"name\":\"Cheng Guan\"},{\"authorId\":\"1491233401\",\"name\":\"Liangjie Cao\"},{\"authorId\":\"1632356255\",\"name\":\"Qianqian Li\"},{\"authorId\":\"1993660232\",\"name\":\"Ju Liang\"},{\"authorId\":\"29344734\",\"name\":\"Zhaorui Gu\"},{\"authorId\":\"2336297\",\"name\":\"Haiyong Zheng\"},{\"authorId\":\"1470709309\",\"name\":\"Bing Zheng\"}],\"doi\":\"10.1007/978-3-030-58539-6_23\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c826e169f505f6fda0872d0a3e1e156e15b5111e\",\"title\":\"CoTeRe-Net: Discovering Collaborative Ternary Relations in Videos\",\"url\":\"https://www.semanticscholar.org/paper/c826e169f505f6fda0872d0a3e1e156e15b5111e\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2010.11757\",\"authors\":[{\"authorId\":\"48239920\",\"name\":\"Chun-Fu Chen\"},{\"authorId\":\"1819152\",\"name\":\"R. Panda\"},{\"authorId\":\"40544169\",\"name\":\"K. Ramakrishnan\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"38060482\",\"name\":\"J. M. Cohn\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"33421444\",\"name\":\"Quanfu Fan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f5c2623a44660ad9fe6cd46710fec6e812a3375a\",\"title\":\"Deep Analysis of CNN-based Spatio-temporal Representations for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f5c2623a44660ad9fe6cd46710fec6e812a3375a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.12619\",\"authors\":[{\"authorId\":\"147084112\",\"name\":\"Jack Humphreys\"},{\"authorId\":\"48354826\",\"name\":\"Z. Chen\"},{\"authorId\":\"145047838\",\"name\":\"Dacheng Tao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e88bff50c417703239e0a832fddb267196ab5a99\",\"title\":\"Recent Progress in Appearance-based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e88bff50c417703239e0a832fddb267196ab5a99\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.06977\",\"authors\":[{\"authorId\":\"47203405\",\"name\":\"Wenhao Wu\"},{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"6873935\",\"name\":\"T. Lin\"},{\"authorId\":\"1998948807\",\"name\":\"F. Li\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"12081764\",\"name\":\"E. Ding\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a6e71b58ea6668dd3872e0c9e6cdd258b4582e2a\",\"title\":\"MVFNet: Multi-View Fusion Network for Efficient Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a6e71b58ea6668dd3872e0c9e6cdd258b4582e2a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2002.03152\",\"authors\":[{\"authorId\":\"47968272\",\"name\":\"Li-Yu Daisy Liu\"},{\"authorId\":\"1491094850\",\"name\":\"Tao Wang\"},{\"authorId\":\"49723003\",\"name\":\"J. Liu\"},{\"authorId\":\"50463545\",\"name\":\"Yang Guan\"},{\"authorId\":\"9963055\",\"name\":\"Qi Bu\"},{\"authorId\":\"49576139\",\"name\":\"Longfei Yang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9f0320cd101ed6426a4330ecb395015c266e976c\",\"title\":\"CTM: Collaborative Temporal Modeling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9f0320cd101ed6426a4330ecb395015c266e976c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144838223\",\"name\":\"Wei Li\"},{\"authorId\":\"66350669\",\"name\":\"Y. Huang\"},{\"authorId\":\"1721716\",\"name\":\"J. Peng\"}],\"doi\":\"10.1007/978-3-030-63830-6_52\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3b1b056b835a34c7616039ba8b8d52c8359b2484\",\"title\":\"Video-Interfaced Human Motion Capture Data Retrieval Based on the Normalized Motion Energy Image Representation\",\"url\":\"https://www.semanticscholar.org/paper/3b1b056b835a34c7616039ba8b8d52c8359b2484\",\"venue\":\"ICONIP\",\"year\":2020},{\"arxivId\":\"2012.10071\",\"authors\":[{\"authorId\":\"48170161\",\"name\":\"L. Wang\"},{\"authorId\":\"9445458\",\"name\":\"Zhan Tong\"},{\"authorId\":\"1511715446\",\"name\":\"Bin Ji\"},{\"authorId\":\"39914710\",\"name\":\"Gangshan Wu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"839a009d4d530483cb9b365012ffc7d76cd88b85\",\"title\":\"TDN: Temporal Difference Networks for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/839a009d4d530483cb9b365012ffc7d76cd88b85\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2000153057\",\"name\":\"Zhikang Qiu\"},{\"authorId\":null,\"name\":\"Xu Zhao\"},{\"authorId\":\"49941675\",\"name\":\"Zhilan Hu\"}],\"doi\":\"10.1109/ICIP40778.2020.9190997\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"593fa71e5cad2afcc4b105c45d5ee4eae101bf54\",\"title\":\"Efficient Temporal-Spatial Feature Grouping For Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/593fa71e5cad2afcc4b105c45d5ee4eae101bf54\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"2007.07626\",\"authors\":[{\"authorId\":\"28969692\",\"name\":\"Junwu Weng\"},{\"authorId\":\"9393671\",\"name\":\"Donghao Luo\"},{\"authorId\":null,\"name\":\"Yabiao Wang\"},{\"authorId\":\"144970872\",\"name\":\"Ying Tai\"},{\"authorId\":\"1978245\",\"name\":\"Chengjie Wang\"},{\"authorId\":\"49298244\",\"name\":\"Jilin Li\"},{\"authorId\":\"1835006\",\"name\":\"Feiyue Huang\"},{\"authorId\":\"3307580\",\"name\":\"Xudong Jiang\"},{\"authorId\":\"48837492\",\"name\":\"J. Yuan\"}],\"doi\":\"10.1007/978-3-030-58571-6_22\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cfb71e0cce6487b6a1cf2dd0cd3755d1d78e908e\",\"title\":\"Temporal Distinct Representation Learning for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cfb71e0cce6487b6a1cf2dd0cd3755d1d78e908e\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2009.08427\",\"authors\":[{\"authorId\":\"51011850\",\"name\":\"Iulia Duta\"},{\"authorId\":\"50986865\",\"name\":\"A. Nicolicioiu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"343f14319d5e34c37eeb86dea88fa82f56715679\",\"title\":\"Dynamic Regions Graph Neural Networks for Spatio-Temporal Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/343f14319d5e34c37eeb86dea88fa82f56715679\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2802283\",\"name\":\"H. Liu\"},{\"authorId\":\"153108488\",\"name\":\"Bin Ren\"},{\"authorId\":\"47842072\",\"name\":\"M. Liu\"},{\"authorId\":\"2705961\",\"name\":\"R. Ding\"}],\"doi\":\"10.1109/ICIP40778.2020.9190958\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"93011a4d810eacfc4ff3202d3c38e78706ff3341\",\"title\":\"Grouped Temporal Enhancement Module for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/93011a4d810eacfc4ff3202d3c38e78706ff3341\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"2005.06803\",\"authors\":[{\"authorId\":\"46270766\",\"name\":\"Zhaoyang Liu\"},{\"authorId\":\"29461006\",\"name\":\"L. Wang\"},{\"authorId\":\"3096434\",\"name\":\"W. Wu\"},{\"authorId\":\"7350503\",\"name\":\"Chen Qian\"},{\"authorId\":\"144720251\",\"name\":\"Tong Lu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3ac6ad718bbdeda6b5b00b61983f8b520d8a6bcb\",\"title\":\"TAM: Temporal Adaptive Module for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3ac6ad718bbdeda6b5b00b61983f8b520d8a6bcb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1912.00381\",\"authors\":[{\"authorId\":\"1756362\",\"name\":\"Swathikiran Sudhakaran\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"}],\"doi\":\"10.1109/cvpr42600.2020.00118\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"57cee868188127305f966a178ca22025b397d911\",\"title\":\"Gate-Shift Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/57cee868188127305f966a178ca22025b397d911\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2004.04730\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"}],\"doi\":\"10.1109/cvpr42600.2020.00028\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"908cca0abefc35acc38033603714fbb1bcadc49d\",\"title\":\"X3D: Expanding Architectures for Efficient Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/908cca0abefc35acc38033603714fbb1bcadc49d\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2003.12798\",\"authors\":[{\"authorId\":\"2156559\",\"name\":\"Qihang Yu\"},{\"authorId\":\"48513320\",\"name\":\"Yingwei Li\"},{\"authorId\":\"10407760\",\"name\":\"Jieru Mei\"},{\"authorId\":\"7743268\",\"name\":\"Yuyin Zhou\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3743c3c7c30d700f37bcd00048af007137517a18\",\"title\":\"CAKES: Channel-wise Automatic KErnel Shrinking for Efficient 3D Network\",\"url\":\"https://www.semanticscholar.org/paper/3743c3c7c30d700f37bcd00048af007137517a18\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.05769\",\"authors\":[{\"authorId\":\"48093158\",\"name\":\"Jinpeng Wang\"},{\"authorId\":\"151470972\",\"name\":\"Yuting Gao\"},{\"authorId\":\"104106360\",\"name\":\"Ke Li\"},{\"authorId\":\"46396519\",\"name\":\"Yiqi Lin\"},{\"authorId\":\"38624848\",\"name\":\"A. J. Ma\"},{\"authorId\":\"143900241\",\"name\":\"Xing Sun\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"01637f04eac8523b6c4887d419bd718f65860982\",\"title\":\"Removing the Background by Adding the Background: Towards Background Robust Self-supervised Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/01637f04eac8523b6c4887d419bd718f65860982\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49372683\",\"name\":\"Niamul Quader\"},{\"authorId\":\"150152476\",\"name\":\"Juwei Lu\"},{\"authorId\":\"144287598\",\"name\":\"Peng Dai\"},{\"authorId\":\"122009001\",\"name\":\"Wei Li\"}],\"doi\":\"10.1007/978-3-030-58577-8_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"080039e68707b483e5c3c27f38660acc1e51ddde\",\"title\":\"Towards Efficient Coarse-to-Fine Networks for Action and Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/080039e68707b483e5c3c27f38660acc1e51ddde\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152142657\",\"name\":\"Y. Tian\"},{\"authorId\":\"1825799769\",\"name\":\"Guangzhao Zhai\"},{\"authorId\":\"97709070\",\"name\":\"Z. Gao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"5768e26731fb55edced4193596f6a470d0029ce6\",\"title\":\"Video-ception Network: Towards Multi-Scale Efficient Asymmetric Spatial-Temporal Interactions\",\"url\":\"https://www.semanticscholar.org/paper/5768e26731fb55edced4193596f6a470d0029ce6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1994488088\",\"name\":\"Lianyu Hu\"},{\"authorId\":\"152150149\",\"name\":\"Lin Feng\"},{\"authorId\":\"8602618\",\"name\":\"Shenglan Liu\"}],\"doi\":\"10.1145/3422844.3423052\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"661a89fbbe1fadc94c145af3a6a1ddb79c7d99a1\",\"title\":\"HFNet: A Novel Model for Human Focused Sports Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/661a89fbbe1fadc94c145af3a6a1ddb79c7d99a1\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491240780\",\"name\":\"Z. Shi\"},{\"authorId\":\"1491233401\",\"name\":\"Liangjie Cao\"},{\"authorId\":\"153747406\",\"name\":\"Cheng Guan\"},{\"authorId\":\"1993660232\",\"name\":\"Ju Liang\"},{\"authorId\":\"48934241\",\"name\":\"Qianqian Li\"},{\"authorId\":\"29344734\",\"name\":\"Zhaorui Gu\"},{\"authorId\":\"2336297\",\"name\":\"Haiyong Zheng\"},{\"authorId\":\"49721778\",\"name\":\"Bing Zheng\"}],\"doi\":\"10.1145/3394171.3413646\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c0d5f622f775d02e90b715b80485dbcab250e7bd\",\"title\":\"Multi-Group Multi-Attention: Towards Discriminative Spatiotemporal Representation\",\"url\":\"https://www.semanticscholar.org/paper/c0d5f622f775d02e90b715b80485dbcab250e7bd\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2006.00626\",\"authors\":[{\"authorId\":\"47002659\",\"name\":\"Yanchao Li\"},{\"authorId\":\"1720749879\",\"name\":\"Miao Liu\"},{\"authorId\":\"50779871\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a48cde936f7dea115cbda99a08e12dbdf45d13fb\",\"title\":\"In the Eye of the Beholder: Gaze and Actions in First Person Video\",\"url\":\"https://www.semanticscholar.org/paper/a48cde936f7dea115cbda99a08e12dbdf45d13fb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.12384\",\"authors\":[{\"authorId\":\"9385903\",\"name\":\"S. Zhu\"},{\"authorId\":\"1390892946\",\"name\":\"Taojiannan Yang\"},{\"authorId\":\"1422036273\",\"name\":\"Mat'ias Mendieta\"},{\"authorId\":\"143916976\",\"name\":\"Chen Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ba1dda6494709cac7c48c95c81afff7a087f2031\",\"title\":\"A3D: Adaptive 3D Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ba1dda6494709cac7c48c95c81afff7a087f2031\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1906.03349\",\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"}],\"doi\":\"10.1109/cvpr42600.2020.00043\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"45a924794b2c6501b671cf4249c6ac4fa1671597\",\"title\":\"Video Modeling With Correlation Networks\",\"url\":\"https://www.semanticscholar.org/paper/45a924794b2c6501b671cf4249c6ac4fa1671597\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2007.11460\",\"authors\":[{\"authorId\":\"152142657\",\"name\":\"Y. Tian\"},{\"authorId\":\"144826391\",\"name\":\"Guangtao Zhai\"},{\"authorId\":\"97709070\",\"name\":\"Z. Gao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"d11a695680f0fd0004e1b8b74a0e2f29e7002246\",\"title\":\"Perceptron Synthesis Network: Rethinking the Action Scale Variances in Videos\",\"url\":\"https://www.semanticscholar.org/paper/d11a695680f0fd0004e1b8b74a0e2f29e7002246\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1912.00998\",\"authors\":[{\"authorId\":\"100880679\",\"name\":\"Chao-Yuan Wu\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"51506875\",\"name\":\"Philipp Krahenbuhl\"}],\"doi\":\"10.1109/cvpr42600.2020.00023\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b8cc28e11900e4d191651ae7234b4dbd129b1007\",\"title\":\"A Multigrid Method for Efficiently Training Video Models\",\"url\":\"https://www.semanticscholar.org/paper/b8cc28e11900e4d191651ae7234b4dbd129b1007\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020}],\"corpusId\":203593466,\"doi\":\"10.1109/ICCV.2019.00561\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":6,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"8b8fe4727c8094b17e61886e69a602f8d0403091\",\"references\":[{\"arxivId\":\"1704.00389\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1007/978-3-030-20893-6_23\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"47195627755d88121af2513646ac41eec8645fb7\",\"title\":\"Hidden Two-Stream Convolutional Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/47195627755d88121af2513646ac41eec8645fb7\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"1212.0402\",\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"title\":\"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\",\"url\":\"https://www.semanticscholar.org/paper/da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":\"1807.11794\",\"authors\":[{\"authorId\":\"1756362\",\"name\":\"Swathikiran Sudhakaran\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"75fac714ccc1b616048c9bb6ca918c58317c56a1\",\"title\":\"Attention is All We Need: Nailing Down Object-centric Attention for Egocentric Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/75fac714ccc1b616048c9bb6ca918c58317c56a1\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":\"1604.01753\",\"authors\":[{\"authorId\":\"34280810\",\"name\":\"Gunnar A. Sigurdsson\"},{\"authorId\":\"2668759\",\"name\":\"G. Varol\"},{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1007/978-3-319-46448-0_31\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"21334d1aac5422da88780f8e24e181bfa15ef0e1\",\"title\":\"Hollywood in Homes: Crowdsourcing Data Collection for Activity Understanding\",\"url\":\"https://www.semanticscholar.org/paper/21334d1aac5422da88780f8e24e181bfa15ef0e1\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1804.09235\",\"authors\":[{\"authorId\":\"2454800\",\"name\":\"F. Mahdisoltani\"},{\"authorId\":\"40586522\",\"name\":\"Guillaume Berger\"},{\"authorId\":\"3462264\",\"name\":\"Waseem Gharbieh\"},{\"authorId\":\"143673251\",\"name\":\"D. Fleet\"},{\"authorId\":\"1710604\",\"name\":\"R. Memisevic\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"26106bcf799c66d719e0cdde6d9fbd3f7eb55e13\",\"title\":\"ON THE EFFECTIVENESS OF TASK GRANULARITY FOR TRANSFER LEARNING\",\"url\":\"https://www.semanticscholar.org/paper/26106bcf799c66d719e0cdde6d9fbd3f7eb55e13\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1406.2199\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"title\":\"Two-Stream Convolutional Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/ICCV.2015.510\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"title\":\"Learning Spatiotemporal Features with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1711.07971\",\"authors\":[{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"}],\"doi\":\"10.1109/CVPR.2018.00813\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"8899094797e82c5c185a0893896320ef77f60e64\",\"title\":\"Non-local Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/8899094797e82c5c185a0893896320ef77f60e64\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1806.01810\",\"authors\":[{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1007/978-3-030-01228-1_25\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d7cbf2d3ea63d97b699cc04af98fea521459ee75\",\"title\":\"Videos as Space-Time Region Graphs\",\"url\":\"https://www.semanticscholar.org/paper/d7cbf2d3ea63d97b699cc04af98fea521459ee75\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1804.09066\",\"authors\":[{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"145264990\",\"name\":\"K. Singh\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1007/978-3-030-01216-8_43\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aa63893b34f523973d0692dc74ff22512daac322\",\"title\":\"ECO: Efficient Convolutional Network for Online Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/aa63893b34f523973d0692dc74ff22512daac322\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1711.11248\",\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"4439383\",\"name\":\"Jamie Ray\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/CVPR.2018.00675\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"89c3050522a0bb9820c32dc7444e003ef0d3e2e4\",\"title\":\"A Closer Look at Spatiotemporal Convolutions for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/89c3050522a0bb9820c32dc7444e003ef0d3e2e4\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1705.07750\",\"authors\":[{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2017.502\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"title\":\"Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset\",\"url\":\"https://www.semanticscholar.org/paper/b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1812.05038\",\"authors\":[{\"authorId\":\"2978413\",\"name\":\"Chao-Yuan Wu\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"2681569\",\"name\":\"Haoqi Fan\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2562966\",\"name\":\"Philipp Kr\\u00e4henb\\u00fchl\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/CVPR.2019.00037\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"45cb2cbae5c0b4cc52e524cc191a2f8db674ed42\",\"title\":\"Long-Term Feature Banks for Detailed Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/45cb2cbae5c0b4cc52e524cc191a2f8db674ed42\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1811.08383\",\"authors\":[{\"authorId\":\"46698300\",\"name\":\"Ji Lin\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"143840275\",\"name\":\"Song Han\"}],\"doi\":\"10.1109/ICCV.2019.00718\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4bbfd46721c145852e443ae4aad35148b814bf91\",\"title\":\"TSM: Temporal Shift Module for Efficient Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/4bbfd46721c145852e443ae4aad35148b814bf91\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2013.441\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d721f4d64b8e722222c876f0a0f226ed49476347\",\"title\":\"Action Recognition with Improved Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/d721f4d64b8e722222c876f0a0f226ed49476347\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":\"1611.05431\",\"authors\":[{\"authorId\":\"1817030\",\"name\":\"Saining Xie\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"144035504\",\"name\":\"Zhuowen Tu\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"}],\"doi\":\"10.1109/CVPR.2017.634\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f6e0856b4a9199fa968ac00da612a9407b5cb85c\",\"title\":\"Aggregated Residual Transformations for Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/f6e0856b4a9199fa968ac00da612a9407b5cb85c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1812.04172\",\"authors\":[{\"authorId\":\"3313330\",\"name\":\"Gedas Bertasius\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"46865129\",\"name\":\"J. Shi\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e412efc9baecddac274639c0a5140aa28446792c\",\"title\":\"Learning Discriminative Motion Features Through Detection\",\"url\":\"https://www.semanticscholar.org/paper/e412efc9baecddac274639c0a5140aa28446792c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1806.06157\",\"authors\":[{\"authorId\":\"9943923\",\"name\":\"Fabien Baradel\"},{\"authorId\":\"2759569\",\"name\":\"N. Neverova\"},{\"authorId\":\"144899680\",\"name\":\"C. Wolf\"},{\"authorId\":\"1723242\",\"name\":\"J. Mille\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"}],\"doi\":\"10.1007/978-3-030-01261-8_7\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"49615e80bac044b92d2edec8b053965e846486f2\",\"title\":\"Object Level Visual Reasoning in Videos\",\"url\":\"https://www.semanticscholar.org/paper/49615e80bac044b92d2edec8b053965e846486f2\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1711.11152\",\"authors\":[{\"authorId\":\"47392986\",\"name\":\"S. Sun\"},{\"authorId\":\"1874900\",\"name\":\"Zhanghui Kuang\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"84200540\",\"name\":\"Lu Sheng\"},{\"authorId\":\"1726357\",\"name\":\"Wayne Zhang\"}],\"doi\":\"10.1109/CVPR.2018.00151\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"42517e072406ea6f8d2c579d98ee3f9918a8a1d3\",\"title\":\"Optical Flow Guided Feature: A Fast and Robust Motion Representation for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/42517e072406ea6f8d2c579d98ee3f9918a8a1d3\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1712.02310\",\"authors\":[{\"authorId\":\"1786435\",\"name\":\"David F. Fouhey\"},{\"authorId\":\"7987770\",\"name\":\"Weicheng Kuo\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/CVPR.2018.00524\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"729fb92afe3cf7faaae1b079f7c7a2cd39c01dad\",\"title\":\"From Lifestyle Vlogs to Everyday Interactions\",\"url\":\"https://www.semanticscholar.org/paper/729fb92afe3cf7faaae1b079f7c7a2cd39c01dad\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1812.03982\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"2681569\",\"name\":\"Haoqi Fan\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"}],\"doi\":\"10.1109/ICCV.2019.00630\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8b47b9c3c35b2b2a78bff7822605b3040f87d699\",\"title\":\"SlowFast Networks for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b47b9c3c35b2b2a78bff7822605b3040f87d699\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1510.00562\",\"authors\":[{\"authorId\":\"41191188\",\"name\":\"Lin Sun\"},{\"authorId\":\"2370507\",\"name\":\"K. Jia\"},{\"authorId\":\"1739816\",\"name\":\"D. Yeung\"},{\"authorId\":\"2131088\",\"name\":\"B. Shi\"}],\"doi\":\"10.1109/ICCV.2015.522\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"95561aec9f00cdf5346e627574e1a022eda3e4f5\",\"title\":\"Human Action Recognition Using Factorized Spatio-Temporal Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/95561aec9f00cdf5346e627574e1a022eda3e4f5\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1711.08496\",\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"50112310\",\"name\":\"Alex Andonian\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1007/978-3-030-01246-5_49\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8ad12d3ee186403b856639b58d7797aa4b89a6c7\",\"title\":\"Temporal Relational Reasoning in Videos\",\"url\":\"https://www.semanticscholar.org/paper/8ad12d3ee186403b856639b58d7797aa4b89a6c7\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1804.00413\",\"authors\":[{\"authorId\":\"2548303\",\"name\":\"Lijie Fan\"},{\"authorId\":\"2978255\",\"name\":\"Wen-bing Huang\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"2490652\",\"name\":\"S. Ermon\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"},{\"authorId\":\"1768190\",\"name\":\"J. Huang\"}],\"doi\":\"10.1109/CVPR.2018.00630\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"259dcd1afe22e569132ccc41697ac368504c4dd1\",\"title\":\"End-to-End Learning of Motion Representation for Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/259dcd1afe22e569132ccc41697ac368504c4dd1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1707.01083\",\"authors\":[{\"authorId\":\"50875121\",\"name\":\"X. Zhang\"},{\"authorId\":\"47155568\",\"name\":\"X. Zhou\"},{\"authorId\":\"3287035\",\"name\":\"Mengxiao Lin\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/CVPR.2018.00716\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9da734397acd7ff7c557960c62fb1b400b27bd89\",\"title\":\"ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices\",\"url\":\"https://www.semanticscholar.org/paper/9da734397acd7ff7c557960c62fb1b400b27bd89\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1706.04261\",\"authors\":[{\"authorId\":\"38962424\",\"name\":\"Raghav Goyal\"},{\"authorId\":\"3127597\",\"name\":\"S. Kahou\"},{\"authorId\":\"1748421\",\"name\":\"Vincent Michalski\"},{\"authorId\":\"7654960\",\"name\":\"Joanna Materzynska\"},{\"authorId\":\"12929417\",\"name\":\"S. Westphal\"},{\"authorId\":\"2233986\",\"name\":\"Heuna Kim\"},{\"authorId\":\"7241984\",\"name\":\"V. Haenel\"},{\"authorId\":\"47544625\",\"name\":\"Ingo Fr\\u00fcnd\"},{\"authorId\":\"19265538\",\"name\":\"Peter Yianilos\"},{\"authorId\":\"1414405239\",\"name\":\"Moritz Mueller-Freitag\"},{\"authorId\":\"143931146\",\"name\":\"F. Hoppe\"},{\"authorId\":\"2020614\",\"name\":\"Christian Thurau\"},{\"authorId\":\"2443288\",\"name\":\"I. Bax\"},{\"authorId\":\"1710604\",\"name\":\"R. Memisevic\"}],\"doi\":\"10.1109/ICCV.2017.622\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b68811a9b5cafe4795a11c1048541750068b7ad0\",\"title\":\"The \\u201cSomething Something\\u201d Video Database for Learning and Evaluating Visual Common Sense\",\"url\":\"https://www.semanticscholar.org/paper/b68811a9b5cafe4795a11c1048541750068b7ad0\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1711.10305\",\"authors\":[{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/ICCV.2017.590\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"024d037d46ae933c7e12fd16af61953c7161773a\",\"title\":\"Learning Spatio-Temporal Representation with Pseudo-3D Residual Networks\",\"url\":\"https://www.semanticscholar.org/paper/024d037d46ae933c7e12fd16af61953c7161773a\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46698300\",\"name\":\"Ji Lin\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"143840277\",\"name\":\"Song Han\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5925a25dfe107c49c636eccb8f9fd1aeef7b438c\",\"title\":\"Temporal Shift Module for Efficient Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/5925a25dfe107c49c636eccb8f9fd1aeef7b438c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1608.00859\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-319-46484-8_2\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"title\":\"Temporal Segment Networks: Towards Good Practices for Deep Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1807.10037\",\"authors\":[{\"authorId\":\"2647624\",\"name\":\"Myunggi Lee\"},{\"authorId\":\"51151436\",\"name\":\"Seungeui Lee\"},{\"authorId\":\"9044475\",\"name\":\"Sung Joon Son\"},{\"authorId\":\"51136389\",\"name\":\"G. Park\"},{\"authorId\":\"3160425\",\"name\":\"N. Kwak\"}],\"doi\":\"10.1007/978-3-030-01249-6_24\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"10a1dcbe52547146fa4735274e8c89ae01e70a55\",\"title\":\"Motion Feature Network: Fixed Motion Filter for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/10a1dcbe52547146fa4735274e8c89ae01e70a55\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1712.04851\",\"authors\":[{\"authorId\":\"1817030\",\"name\":\"Saining Xie\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"1808244\",\"name\":\"J. Huang\"},{\"authorId\":\"144035504\",\"name\":\"Zhuowen Tu\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":\"10.1007/978-3-030-01267-0_19\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"815aa52cfc02961d82415f080384594639a21984\",\"title\":\"Rethinking Spatiotemporal Feature Learning: Speed-Accuracy Trade-offs in Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/815aa52cfc02961d82415f080384594639a21984\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1804.02748\",\"authors\":[{\"authorId\":\"145089978\",\"name\":\"D. Damen\"},{\"authorId\":\"28798386\",\"name\":\"H. Doughty\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"12387007\",\"name\":\"Evangelos Kazakos\"},{\"authorId\":\"3420479\",\"name\":\"D. Moltisanti\"},{\"authorId\":\"47077615\",\"name\":\"J. Munro\"},{\"authorId\":\"2682004\",\"name\":\"T. Perrett\"},{\"authorId\":\"50065546\",\"name\":\"W. Price\"},{\"authorId\":\"145032628\",\"name\":\"Michael Wray\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fc50c9392fd23b6c88915177c6ae904a498aacea\",\"title\":\"Scaling Egocentric Vision: The EPIC-KITCHENS Dataset\",\"url\":\"https://www.semanticscholar.org/paper/fc50c9392fd23b6c88915177c6ae904a498aacea\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"46331912\",\"name\":\"M. Liu\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1007/978-3-030-01228-1_38\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"fa1723b216b1f41b085b62b450b7b0bd9f2fd281\",\"title\":\"In the Eye of Beholder: Joint Learning of Gaze and Actions in First Person Video\",\"url\":\"https://www.semanticscholar.org/paper/fa1723b216b1f41b085b62b450b7b0bd9f2fd281\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1409.0575\",\"authors\":[{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"71309570\",\"name\":\"H. Su\"},{\"authorId\":\"2285165\",\"name\":\"J. Krause\"},{\"authorId\":\"145031342\",\"name\":\"S. Satheesh\"},{\"authorId\":\"145423516\",\"name\":\"S. Ma\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-015-0816-y\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"title\":\"ImageNet Large Scale Visual Recognition Challenge\",\"url\":\"https://www.semanticscholar.org/paper/e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"152821938\",\"name\":\"Sanketh Shetty\"},{\"authorId\":\"120906511\",\"name\":\"T. Leung\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2014.223\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"title\":\"Large-Scale Video Classification with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yingwei Li\"},{\"authorId\":\"47001807\",\"name\":\"Y. Li\"},{\"authorId\":\"1699559\",\"name\":\"N. Vasconcelos\"}],\"doi\":\"10.1007/978-3-030-01231-1_32\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"74c19438c78a136677a7cb9004c53684a4ae56ff\",\"title\":\"RESOUND: Towards Action Recognition Without Representation Bias\",\"url\":\"https://www.semanticscholar.org/paper/74c19438c78a136677a7cb9004c53684a4ae56ff\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1711.09577\",\"authors\":[{\"authorId\":\"2199251\",\"name\":\"K. Hara\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"}],\"doi\":\"10.1109/CVPR.2018.00685\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d716435f0cb0cac56237f74b1ced940aabce6a2b\",\"title\":\"Can Spatiotemporal 3D CNNs Retrace the History of 2D CNNs and ImageNet?\",\"url\":\"https://www.semanticscholar.org/paper/d716435f0cb0cac56237f74b1ced940aabce6a2b\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018}],\"title\":\"Grouped Spatial-Temporal Aggregation for Efficient Action Recognition\",\"topics\":[{\"topic\":\"Video content analysis\",\"topicId\":\"98626\",\"url\":\"https://www.semanticscholar.org/topic/98626\"},{\"topic\":\"Computational complexity theory\",\"topicId\":\"1133\",\"url\":\"https://www.semanticscholar.org/topic/1133\"},{\"topic\":\"Coupling (computer programming)\",\"topicId\":\"20694\",\"url\":\"https://www.semanticscholar.org/topic/20694\"},{\"topic\":\"Computation\",\"topicId\":\"339\",\"url\":\"https://www.semanticscholar.org/topic/339\"}],\"url\":\"https://www.semanticscholar.org/paper/8b8fe4727c8094b17e61886e69a602f8d0403091\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019}\n"