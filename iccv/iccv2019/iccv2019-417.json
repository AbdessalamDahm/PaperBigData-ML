"{\"abstract\":\"Passive and convenient depth estimation from single-shot image is still an open problem. Existing depth from defocus methods require multiple input images or special hardware customization. Recent deep monocular depth estimation is also limited to an image with sufficient contextual information. In this work, we propose a novel method which realizes a single-shot deep depth measurement based on physical depth cue using only an off-the-shelf camera and lens. When a defocused image is taken by a camera, it contains various types of aberrations corresponding to distances from the image sensor and positions in the image plane. We call these minute and complexly compound aberrations as Aberration Map (A-Map) and we found that A-Map can be utilized as reliable physical depth cue. Additionally, our deep network named A-Map Analysis Network (AMA-Net) is also proposed, which can effectively learn and estimate depth via A-Map. To evaluate validity and robustness of our approach, we have conducted extensive experiments using both real outdoor scenes and simulated images. The qualitative result shows the accuracy and availability of the method in comparison with a state-of-the-art deep context-based method.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"69980800\",\"name\":\"Masako Kashiwagi\",\"url\":\"https://www.semanticscholar.org/author/69980800\"},{\"authorId\":\"9227770\",\"name\":\"N. Mishima\",\"url\":\"https://www.semanticscholar.org/author/9227770\"},{\"authorId\":\"1742108\",\"name\":\"Tatsuo Kozakaya\",\"url\":\"https://www.semanticscholar.org/author/1742108\"},{\"authorId\":\"1915982\",\"name\":\"S. Hiura\",\"url\":\"https://www.semanticscholar.org/author/1915982\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"2041272769\",\"name\":\"Kazuki Murayama\"},{\"authorId\":\"145758871\",\"name\":\"Kenji Kanai\"},{\"authorId\":\"153168747\",\"name\":\"M. Takeuchi\"},{\"authorId\":\"1788294\",\"name\":\"J. Katto\"}],\"doi\":\"10.1109/GCCE50665.2020.9291915\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f4311217ebd97650b47ea89c623d6d56e9a8f0f2\",\"title\":\"Deep Pedestrian Distance Estimation from Single-shot Image\",\"url\":\"https://www.semanticscholar.org/paper/f4311217ebd97650b47ea89c623d6d56e9a8f0f2\",\"venue\":\"2020 IEEE 9th Global Conference on Consumer Electronics (GCCE)\",\"year\":2020},{\"arxivId\":\"2011.11831\",\"authors\":[{\"authorId\":\"1470838102\",\"name\":\"Basile Van Hoorick\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eac7a3f19eae28681a98be261180b4b9c78050fa\",\"title\":\"Dissecting Image Crops\",\"url\":\"https://www.semanticscholar.org/paper/eac7a3f19eae28681a98be261180b4b9c78050fa\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":208001358,\"doi\":\"10.1109/ICCV.2019.00417\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":1,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"2cf22f2f7a456e4123fc1cb352443230504ce79d\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"38534744\",\"name\":\"A. Chakrabarti\"},{\"authorId\":\"1713451\",\"name\":\"Todd E. Zickler\"}],\"doi\":\"10.1007/978-3-642-33715-4_47\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"800db05f9a090883c79626142a98acd2875835c0\",\"title\":\"Depth and Deblurring from a Spectrally-Varying Depth-of-Field\",\"url\":\"https://www.semanticscholar.org/paper/800db05f9a090883c79626142a98acd2875835c0\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1799420\",\"name\":\"Y. Bando\"},{\"authorId\":\"1733344\",\"name\":\"B. Chen\"},{\"authorId\":\"1696605\",\"name\":\"T. Nishita\"}],\"doi\":\"10.1145/1457515.1409087\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"260b647283d02cbe5e4e07401dc685a1663a6c5b\",\"title\":\"Extracting depth and matte using a color-filtered aperture\",\"url\":\"https://www.semanticscholar.org/paper/260b647283d02cbe5e4e07401dc685a1663a6c5b\",\"venue\":\"ACM Trans. Graph.\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1704988\",\"name\":\"S. Kim\"},{\"authorId\":\"1721199\",\"name\":\"E. Lee\"},{\"authorId\":\"144449603\",\"name\":\"M. Hayes\"},{\"authorId\":\"144155678\",\"name\":\"Joonki Paik\"}],\"doi\":\"10.1109/TIP.2012.2202671\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a273a4e316792a18cb9452c5dffbbf8db7c5c156\",\"title\":\"Multifocusing and Depth Estimation Using a Color Shift Model-Based Computational Camera\",\"url\":\"https://www.semanticscholar.org/paper/a273a4e316792a18cb9452c5dffbbf8db7c5c156\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2012},{\"arxivId\":\"1805.03096\",\"authors\":[{\"authorId\":\"2598904\",\"name\":\"Christian Bailer\"},{\"authorId\":\"41016138\",\"name\":\"Tewodros Habtegebrial\"},{\"authorId\":\"13640633\",\"name\":\"K. Varanasi\"},{\"authorId\":\"143749919\",\"name\":\"D. Stricker\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d7bcd62e1eb60468394034e92d11450580dbfd3\",\"title\":\"Fast Feature Extraction with CNNs with Pooling Layers\",\"url\":\"https://www.semanticscholar.org/paper/4d7bcd62e1eb60468394034e92d11450580dbfd3\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1804.00607\",\"authors\":[{\"authorId\":\"8763474\",\"name\":\"Z. Li\"},{\"authorId\":\"1830653\",\"name\":\"Noah Snavely\"}],\"doi\":\"10.1109/CVPR.2018.00218\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3395de3126d9b6b9d75f0d85d8c4ebab8ff84686\",\"title\":\"MegaDepth: Learning Single-View Depth Prediction from Internet Photos\",\"url\":\"https://www.semanticscholar.org/paper/3395de3126d9b6b9d75f0d85d8c4ebab8ff84686\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1708.04896\",\"authors\":[{\"authorId\":\"145798096\",\"name\":\"Z. Zhong\"},{\"authorId\":\"144802394\",\"name\":\"L. Zheng\"},{\"authorId\":\"3374337\",\"name\":\"Guoliang Kang\"},{\"authorId\":\"8086812\",\"name\":\"Shaozi Li\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1609/AAAI.V34I07.7000\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2788a2461ed0067e2f7aaa63c449a24a237ec341\",\"title\":\"Random Erasing Data Augmentation\",\"url\":\"https://www.semanticscholar.org/paper/2788a2461ed0067e2f7aaa63c449a24a237ec341\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1510.05970\",\"authors\":[{\"authorId\":\"3105120\",\"name\":\"J. Zbontar\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ad3e7515c61ccdc2c36887e7d4929c78904881db\",\"title\":\"Stereo Matching by Training a Convolutional Neural Network to Compare Image Patches\",\"url\":\"https://www.semanticscholar.org/paper/ad3e7515c61ccdc2c36887e7d4929c78904881db\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2586236\",\"name\":\"Yusuke Moriuchi\"},{\"authorId\":\"46565495\",\"name\":\"T. Sasaki\"},{\"authorId\":\"9227770\",\"name\":\"N. Mishima\"},{\"authorId\":\"145817726\",\"name\":\"T. Mita\"}],\"doi\":\"10.1002/SDTP.11639\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7d622d032d6a63e0b93c190529d6e7700bf86bd8\",\"title\":\"23\\u20104: Invited Paper: Depth from Asymmetric Defocus using Color\\u2010Filtered Aperture\",\"url\":\"https://www.semanticscholar.org/paper/7d622d032d6a63e0b93c190529d6e7700bf86bd8\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50610018\",\"name\":\"J. Garcia\"},{\"authorId\":\"145926051\",\"name\":\"J. M. S\\u00e1nchez\"},{\"authorId\":\"3122871\",\"name\":\"Xavier Orriols\"},{\"authorId\":\"1692494\",\"name\":\"Xavier Binefa\"}],\"doi\":\"10.1109/ICPR.2000.905499\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4223921b8d203c923eded78e8c8c4b482f5b6ae1\",\"title\":\"Chromatic aberration and depth extraction\",\"url\":\"https://www.semanticscholar.org/paper/4223921b8d203c923eded78e8c8c4b482f5b6ae1\",\"venue\":\"Proceedings 15th International Conference on Pattern Recognition. ICPR-2000\",\"year\":2000},{\"arxivId\":\"1703.04309\",\"authors\":[{\"authorId\":\"47645184\",\"name\":\"Alex Kendall\"},{\"authorId\":\"9746545\",\"name\":\"H. Martirosyan\"},{\"authorId\":\"5762869\",\"name\":\"S. Dasgupta\"},{\"authorId\":\"144165781\",\"name\":\"Peter Henry\"}],\"doi\":\"10.1109/ICCV.2017.17\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0ba19bb88c856b880d198f4b6e9dcf8144657df8\",\"title\":\"End-to-End Learning of Geometry and Context for Deep Stereo Regression\",\"url\":\"https://www.semanticscholar.org/paper/0ba19bb88c856b880d198f4b6e9dcf8144657df8\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1398077025\",\"name\":\"Edgar Simo-Serra\"},{\"authorId\":\"1995333\",\"name\":\"Eduard Trulls\"},{\"authorId\":\"145689677\",\"name\":\"L. Ferraz\"},{\"authorId\":\"2010660\",\"name\":\"I. Kokkinos\"},{\"authorId\":\"153918727\",\"name\":\"P. Fua\"},{\"authorId\":\"1397181875\",\"name\":\"F. Moreno-Noguer\"}],\"doi\":\"10.1109/ICCV.2015.22\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3f12f001fdabf293e273e960c7756cb379c50b66\",\"title\":\"Discriminative Learning of Deep Convolutional Feature Point Descriptors\",\"url\":\"https://www.semanticscholar.org/paper/3f12f001fdabf293e273e960c7756cb379c50b66\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2490410\",\"name\":\"Amir Atapour-Abarghouei\"},{\"authorId\":\"1803808\",\"name\":\"T. Breckon\"}],\"doi\":\"10.1109/CVPR.2018.00296\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"21547e038b383fb9d2ca14eb9978b1d4d8e6b178\",\"title\":\"Real-Time Monocular Depth Estimation Using Synthetic Data with Domain Adaptation via Image Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/21547e038b383fb9d2ca14eb9978b1d4d8e6b178\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152451400\",\"name\":\"H. Hirschmuller\"}],\"doi\":\"10.1109/CVPR.2005.56\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c38fe172d1c96650ee918b4d731e341859504bb7\",\"title\":\"Accurate and efficient stereo processing by semi-global matching and mutual information\",\"url\":\"https://www.semanticscholar.org/paper/c38fe172d1c96650ee918b4d731e341859504bb7\",\"venue\":\"2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)\",\"year\":2005},{\"arxivId\":\"1805.08318\",\"authors\":[{\"authorId\":\"48213346\",\"name\":\"Han Zhang\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1711560\",\"name\":\"D. Metaxas\"},{\"authorId\":\"2624088\",\"name\":\"Augustus Odena\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a8f3dc53e321fbb2565f5925def4365b9f68d1af\",\"title\":\"Self-Attention Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/a8f3dc53e321fbb2565f5925def4365b9f68d1af\",\"venue\":\"ICML\",\"year\":2019},{\"arxivId\":\"1504.03641\",\"authors\":[{\"authorId\":\"2134433\",\"name\":\"Sergey Zagoruyko\"},{\"authorId\":\"2505902\",\"name\":\"Nikos Komodakis\"}],\"doi\":\"10.1109/CVPR.2015.7299064\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"adcf9bdac7f05ba2bc003256a6794974aa571e0c\",\"title\":\"Learning to compare image patches via convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/adcf9bdac7f05ba2bc003256a6794974aa571e0c\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1609.06647\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"48818137\",\"name\":\"Samy Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/TPAMI.2016.2587640\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"62f74d3aaf9e86633e4d88b04a6d04ca93e8b81e\",\"title\":\"Show and Tell: Lessons Learned from the 2015 MSCOCO Image Captioning Challenge\",\"url\":\"https://www.semanticscholar.org/paper/62f74d3aaf9e86633e4d88b04a6d04ca93e8b81e\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":\"1802.07042\",\"authors\":[{\"authorId\":\"83015253\",\"name\":\"Alex Hern\\u00e1ndez-Garc\\u00eda\"},{\"authorId\":\"144027562\",\"name\":\"P. K\\u00f6nig\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"23c311d56190604f8aed18a36bdbdded702bc5bb\",\"title\":\"Do deep nets really need weight decay and dropout?\",\"url\":\"https://www.semanticscholar.org/paper/23c311d56190604f8aed18a36bdbdded702bc5bb\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40593092\",\"name\":\"M. Martinello\"},{\"authorId\":\"1885618\",\"name\":\"A. Wajs\"},{\"authorId\":\"2894672\",\"name\":\"S. Quan\"},{\"authorId\":\"49923024\",\"name\":\"H. Lee\"},{\"authorId\":\"2859880\",\"name\":\"Chien Lim\"},{\"authorId\":\"32656688\",\"name\":\"T. Woo\"},{\"authorId\":\"5955672\",\"name\":\"W. Lee\"},{\"authorId\":\"4563225\",\"name\":\"S. Kim\"},{\"authorId\":\"1717931\",\"name\":\"D. Lee\"}],\"doi\":\"10.1109/ICCPHOT.2015.7168366\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"7d99ed290d62913ddd3a6565b04277edbe61e3c1\",\"title\":\"Dual Aperture Photography: Image and Depth from a Mobile Camera\",\"url\":\"https://www.semanticscholar.org/paper/7d99ed290d62913ddd3a6565b04277edbe61e3c1\",\"venue\":\"2015 IEEE International Conference on Computational Photography (ICCP)\",\"year\":2015},{\"arxivId\":\"1803.08669\",\"authors\":[{\"authorId\":\"2936466\",\"name\":\"Jia-Ren Chang\"},{\"authorId\":\"4769561\",\"name\":\"Y. Chen\"}],\"doi\":\"10.1109/CVPR.2018.00567\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"316b1b9d96149e7bb3d9d6afc0295881c6123cc8\",\"title\":\"Pyramid Stereo Matching Network\",\"url\":\"https://www.semanticscholar.org/paper/316b1b9d96149e7bb3d9d6afc0295881c6123cc8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49756115\",\"name\":\"W. Luo\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"}],\"doi\":\"10.1109/CVPR.2016.614\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e517a34dbacfba588e6480f110e4c27665686819\",\"title\":\"Efficient Deep Learning for Stereo Matching\",\"url\":\"https://www.semanticscholar.org/paper/e517a34dbacfba588e6480f110e4c27665686819\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1809.01567\",\"authors\":[{\"authorId\":\"144918254\",\"name\":\"Marcela Carvalho\"},{\"authorId\":\"1730023\",\"name\":\"B. L. Saux\"},{\"authorId\":\"1397299055\",\"name\":\"P. Trouv\\u00e9-Peloux\"},{\"authorId\":\"1395121035\",\"name\":\"A. Almansa\"},{\"authorId\":\"1776378\",\"name\":\"F. Champagnat\"}],\"doi\":\"10.1007/978-3-030-11009-3_18\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4e69dc3d70cbedfb24d421094ffde79f3ac8b1b5\",\"title\":\"Deep Depth from Defocus: how can defocus blur improve 3D estimation using dense neural networks?\",\"url\":\"https://www.semanticscholar.org/paper/4e69dc3d70cbedfb24d421094ffde79f3ac8b1b5\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46404734\",\"name\":\"P. Trouv\\u00e9\"},{\"authorId\":\"1776378\",\"name\":\"F. Champagnat\"},{\"authorId\":\"122919210\",\"name\":\"G. Le Besnerais\"},{\"authorId\":\"145280801\",\"name\":\"J. Sabater\"},{\"authorId\":\"13693132\",\"name\":\"T. Avignon\"},{\"authorId\":\"1701780\",\"name\":\"J. Idier\"}],\"doi\":\"10.1364/AO.52.007152\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"80d0851d1e73c21b6a92ac16e49c8e93f2d33fe0\",\"title\":\"Passive depth estimation using chromatic aberration and a depth from defocus approach.\",\"url\":\"https://www.semanticscholar.org/paper/80d0851d1e73c21b6a92ac16e49c8e93f2d33fe0\",\"venue\":\"Applied optics\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"},{\"authorId\":\"52184096\",\"name\":\"L. Bottou\"},{\"authorId\":\"34782608\",\"name\":\"G. Orr\"},{\"authorId\":\"145034054\",\"name\":\"K. M\\u00fcller\"}],\"doi\":\"10.1007/978-3-642-35289-8_3\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b87274e6d9aa4e6ba5148898aa92941617d2b6ed\",\"title\":\"Efficient BackProp\",\"url\":\"https://www.semanticscholar.org/paper/b87274e6d9aa4e6ba5148898aa92941617d2b6ed\",\"venue\":\"Neural Networks: Tricks of the Trade\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2512563\",\"name\":\"M. Subbarao\"},{\"authorId\":\"29810298\",\"name\":\"Gopal Surya\"}],\"doi\":\"10.1007/BF02028349\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"771290ffeb20e5860772edd0ab71068fd22e0446\",\"title\":\"Depth from defocus: A spatial domain approach\",\"url\":\"https://www.semanticscholar.org/paper/771290ffeb20e5860772edd0ab71068fd22e0446\",\"venue\":\"International Journal of Computer Vision\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2598904\",\"name\":\"Christian Bailer\"},{\"authorId\":\"13640633\",\"name\":\"K. Varanasi\"},{\"authorId\":\"143749919\",\"name\":\"D. Stricker\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"da11e38895b1ba0034dc59a629b949f33f092275\",\"title\":\"CNN based Patch Matching for Optical Flow with Thresholded Hinge Loss\",\"url\":\"https://www.semanticscholar.org/paper/da11e38895b1ba0034dc59a629b949f33f092275\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144432351\",\"name\":\"Vladimir Paramonov\"},{\"authorId\":\"102946784\",\"name\":\"I. Panchenko\"},{\"authorId\":\"3420204\",\"name\":\"V. Bucha\"},{\"authorId\":\"7810793\",\"name\":\"Andrey Drogolyub\"},{\"authorId\":\"2134433\",\"name\":\"Sergey Zagoruyko\"}],\"doi\":\"10.1109/CVPRW.2016.118\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"5ac9ebd40ee4ed33a4340e50c81270d5b581b443\",\"title\":\"Depth Camera Based on Color-Coded Aperture\",\"url\":\"https://www.semanticscholar.org/paper/5ac9ebd40ee4ed33a4340e50c81270d5b581b443\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2321890\",\"name\":\"S. Lee\"},{\"authorId\":\"32013177\",\"name\":\"N. Kim\"},{\"authorId\":\"1901466\",\"name\":\"Kyungwon Jung\"},{\"authorId\":\"144449603\",\"name\":\"M. Hayes\"},{\"authorId\":\"144155678\",\"name\":\"Joonki Paik\"}],\"doi\":\"10.1109/ICASSP.2013.6638054\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5a0d2bbf421fadf679e5c5c0fccc5b222e05591c\",\"title\":\"Single image-based depth estimation using dual off-axis color filtered aperture camera\",\"url\":\"https://www.semanticscholar.org/paper/5a0d2bbf421fadf679e5c5c0fccc5b222e05591c\",\"venue\":\"2013 IEEE International Conference on Acoustics, Speech and Signal Processing\",\"year\":2013},{\"arxivId\":\"1702.02706\",\"authors\":[{\"authorId\":\"9538411\",\"name\":\"Yevhen Kuznietsov\"},{\"authorId\":\"1683956\",\"name\":\"J. St\\u00fcckler\"},{\"authorId\":\"1789756\",\"name\":\"B. Leibe\"}],\"doi\":\"10.1109/CVPR.2017.238\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6088a5af7198e763f9d6a9a5e78f45302228a3ff\",\"title\":\"Semi-Supervised Deep Learning for Monocular Depth Map Prediction\",\"url\":\"https://www.semanticscholar.org/paper/6088a5af7198e763f9d6a9a5e78f45302228a3ff\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":\"1809.06839\",\"authors\":[{\"authorId\":\"144338534\",\"name\":\"Alexander V. Buslaev\"},{\"authorId\":\"51450943\",\"name\":\"A. Parinov\"},{\"authorId\":\"79692603\",\"name\":\"Eugene Khvedchenya\"},{\"authorId\":\"19231037\",\"name\":\"V. Iglovikov\"},{\"authorId\":\"32985843\",\"name\":\"A. Kalinin\"}],\"doi\":\"10.3390/info11020125\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"17555c227941654bc19d613742e2508f209c6d86\",\"title\":\"Albumentations: fast and flexible image augmentations\",\"url\":\"https://www.semanticscholar.org/paper/17555c227941654bc19d613742e2508f209c6d86\",\"venue\":\"Inf.\",\"year\":2020}],\"title\":\"Deep Depth From Aberration Map\",\"topics\":[{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Image sensor\",\"topicId\":\"33586\",\"url\":\"https://www.semanticscholar.org/topic/33586\"},{\"topic\":\"Image plane\",\"topicId\":\"23349\",\"url\":\"https://www.semanticscholar.org/topic/23349\"},{\"topic\":\"Simulation\",\"topicId\":\"194\",\"url\":\"https://www.semanticscholar.org/topic/194\"},{\"topic\":\"Map analysis\",\"topicId\":\"2051450\",\"url\":\"https://www.semanticscholar.org/topic/2051450\"}],\"url\":\"https://www.semanticscholar.org/paper/2cf22f2f7a456e4123fc1cb352443230504ce79d\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019}\n"