"{\"abstract\":\"Traditional techniques for emotion recognition have focused on the facial expression analysis only, thus providing limited ability to encode context that comprehensively represents the emotional responses. We present deep networks for context-aware emotion recognition, called CAER-Net, that exploit not only human facial expression but also context information in a joint and boosting manner. The key idea is to hide human faces in a visual scene and seek other contexts based on an attention mechanism. Our networks consist of two sub-networks, including two-stream encoding networks to separately extract the features of face and context regions, and adaptive fusion networks to fuse such features in an adaptive fashion. We also introduce a novel benchmark for context-aware emotion recognition, called CAER, that is appropriate than existing benchmarks both qualitatively and quantitatively. On several benchmarks, CAER-Net proves the effect of context for emotion recognition. Our dataset is available at http://caer-dataset.github.io.\",\"arxivId\":\"1908.05913\",\"authors\":[{\"authorId\":\"82536700\",\"name\":\"J. Lee\",\"url\":\"https://www.semanticscholar.org/author/82536700\"},{\"authorId\":\"2099537\",\"name\":\"Seungryong Kim\",\"url\":\"https://www.semanticscholar.org/author/2099537\"},{\"authorId\":\"2352565\",\"name\":\"Sunok Kim\",\"url\":\"https://www.semanticscholar.org/author/2352565\"},{\"authorId\":\"102769741\",\"name\":\"Jung-In. Park\",\"url\":\"https://www.semanticscholar.org/author/102769741\"},{\"authorId\":\"144442279\",\"name\":\"K. Sohn\",\"url\":\"https://www.semanticscholar.org/author/144442279\"}],\"citationVelocity\":8,\"citations\":[{\"arxivId\":\"2008.05924\",\"authors\":[{\"authorId\":\"1387822126\",\"name\":\"Xingxun Jiang\"},{\"authorId\":\"48115912\",\"name\":\"Yuan Zong\"},{\"authorId\":\"153811981\",\"name\":\"Wenming Zheng\"},{\"authorId\":\"2397257\",\"name\":\"Chuangao Tang\"},{\"authorId\":\"1382744618\",\"name\":\"Wanchuang Xia\"},{\"authorId\":\"102517285\",\"name\":\"Cheng Lu\"},{\"authorId\":\"1390977843\",\"name\":\"Jiateng Liu\"}],\"doi\":\"10.1145/3394171.3413620\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"061d69640ba6b544bbdfa8fa4637fa867fb42d2d\",\"title\":\"DFEW: A Large-Scale Database for Recognizing Dynamic Facial Expressions in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/061d69640ba6b544bbdfa8fa4637fa867fb42d2d\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ahmed Shehab Khan\"},{\"authorId\":null,\"name\":\"Zhiyuan Li\"},{\"authorId\":null,\"name\":\"Jie Cai\"},{\"authorId\":null,\"name\":\"Yan Tong\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"170f403ca462bf88513197f8e499e31dd7701d1a\",\"title\":\"Regional Attention Networks with Context-aware Fusion for Group Emotion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/170f403ca462bf88513197f8e499e31dd7701d1a\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Abdulaziz Salamah Aljaloud\"},{\"authorId\":\"1430785963\",\"name\":\"Habib Ullah\"},{\"authorId\":\"8635893\",\"name\":\"A. Alanazi\"}],\"doi\":\"10.14569/ijacsa.2020.0110137\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7522679b432649785f1355a7013d448b837a08c2\",\"title\":\"Facial Emotion Recognition using Neighborhood Features\",\"url\":\"https://www.semanticscholar.org/paper/7522679b432649785f1355a7013d448b837a08c2\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1400408486\",\"name\":\"Garima Sharma\"},{\"authorId\":\"1735697\",\"name\":\"Abhinav Dhall\"}],\"doi\":\"10.1007/978-3-030-51870-7_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f5aabd468e2b8738a7487774d31e90e62b05f726\",\"title\":\"A Survey on Automatic Multimodal Emotion Recognition in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/f5aabd468e2b8738a7487774d31e90e62b05f726\",\"venue\":\"\",\"year\":2021},{\"arxivId\":\"1912.06874\",\"authors\":[{\"authorId\":\"3352747\",\"name\":\"Tanmay Randhavane\"},{\"authorId\":\"50227009\",\"name\":\"Uttaran Bhattacharya\"},{\"authorId\":\"80905955\",\"name\":\"Kyra Kapsaskis\"},{\"authorId\":\"152193420\",\"name\":\"Kurt Gray\"},{\"authorId\":\"2979367\",\"name\":\"Aniket Bera\"},{\"authorId\":\"1699159\",\"name\":\"D. Manocha\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c70b41782edbdb84a454ab61043cf3c134ce12e\",\"title\":\"The Liar's Walk: Detecting Deception with Gait and Gesture\",\"url\":\"https://www.semanticscholar.org/paper/2c70b41782edbdb84a454ab61043cf3c134ce12e\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9448859\",\"name\":\"Gede Putra Kusuma\"},{\"authorId\":\"144604503\",\"name\":\"J. Jonathan\"},{\"authorId\":\"65723871\",\"name\":\"Andreas Pangestu Lim\"}],\"doi\":\"10.25046/aj050638\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c757822db022ee2ecec052743f22453d4a89feef\",\"title\":\"Emotion Recognition on FER-2013 Face Images Using Fine-Tuned VGG-16\",\"url\":\"https://www.semanticscholar.org/paper/c757822db022ee2ecec052743f22453d4a89feef\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1911.08708\",\"authors\":[{\"authorId\":\"50227009\",\"name\":\"Uttaran Bhattacharya\"},{\"authorId\":\"1385119825\",\"name\":\"Christian Roncal\"},{\"authorId\":\"9214782\",\"name\":\"Trisha Mittal\"},{\"authorId\":\"30144577\",\"name\":\"Rohan Chandra\"},{\"authorId\":\"2979367\",\"name\":\"Aniket Bera\"},{\"authorId\":\"1699159\",\"name\":\"D. Manocha\"}],\"doi\":\"10.1007/978-3-030-58607-2_9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3a718341f5db00071de408a4bd52e92541052e13\",\"title\":\"Take an Emotion Walk: Perceiving Emotions from Gaits Using Hierarchical Attention Pooling and Affective Mapping\",\"url\":\"https://www.semanticscholar.org/paper/3a718341f5db00071de408a4bd52e92541052e13\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51123172\",\"name\":\"Darshana Priyasad\"},{\"authorId\":\"34735743\",\"name\":\"T. Fernando\"},{\"authorId\":\"1980700\",\"name\":\"Simon Denman\"},{\"authorId\":\"1729760\",\"name\":\"S. Sridharan\"},{\"authorId\":\"3140440\",\"name\":\"C. Fookes\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"48d5edd8d705f5c51f01a1d958de375cca8b06f5\",\"title\":\"Memory Based Attentive Fusion\",\"url\":\"https://www.semanticscholar.org/paper/48d5edd8d705f5c51f01a1d958de375cca8b06f5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26339425\",\"name\":\"Valentin Vielzeuf\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0501b8a99270a20c7536ed2f6df6569413810f6d\",\"title\":\"Apprentissage neuronal profond pour l'analyse de contenus multimodaux et temporels. (Deep learning for multimodal and temporal contents analysis)\",\"url\":\"https://www.semanticscholar.org/paper/0501b8a99270a20c7536ed2f6df6569413810f6d\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2007.08076\",\"authors\":[{\"authorId\":\"51123172\",\"name\":\"Darshana Priyasad\"},{\"authorId\":\"34735743\",\"name\":\"T. Fernando\"},{\"authorId\":\"1980700\",\"name\":\"Simon Denman\"},{\"authorId\":\"1729760\",\"name\":\"S. Sridharan\"},{\"authorId\":\"3140440\",\"name\":\"C. Fookes\"}],\"doi\":\"10.1016/j.inffus.2020.10.005\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"08189ce7ec387a47b490113a4040dec6f65a254e\",\"title\":\"Memory based fusion for multi-modal deep learning.\",\"url\":\"https://www.semanticscholar.org/paper/08189ce7ec387a47b490113a4040dec6f65a254e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2010.16396\",\"authors\":[{\"authorId\":\"30192180\",\"name\":\"P. P. Filntisis\"},{\"authorId\":\"1726020695\",\"name\":\"Nikos Efthymiou\"},{\"authorId\":\"1423737852\",\"name\":\"Gerasimos Potamianos\"},{\"authorId\":\"1750686\",\"name\":\"P. Maragos\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"11ef3bf92bbe71eb42ba4c575345e8853e0b29eb\",\"title\":\"Emotion Understanding in Videos Through Body, Context, and Visual-Semantic Embedding Loss\",\"url\":\"https://www.semanticscholar.org/paper/11ef3bf92bbe71eb42ba4c575345e8853e0b29eb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35144077\",\"name\":\"A. Yadav\"},{\"authorId\":\"47731526\",\"name\":\"D. Vishwakarma\"}],\"doi\":\"10.1007/s00530-020-00656-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"764a6412c9ed41a06092bc6a908d25201029f0da\",\"title\":\"A deep learning architecture of RA-DLNet for visual sentiment analysis\",\"url\":\"https://www.semanticscholar.org/paper/764a6412c9ed41a06092bc6a908d25201029f0da\",\"venue\":\"Multimedia Systems\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46983280\",\"name\":\"A. H. Farzaneh\"},{\"authorId\":\"144244342\",\"name\":\"Xiaojun Qi\"}],\"doi\":\"10.1109/CVPRW50498.2020.00211\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8bb51fd8681fb982fa3518a643fc7cfdf4bd352b\",\"title\":\"Discriminant Distribution-Agnostic Loss for Facial Expression Recognition in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/8bb51fd8681fb982fa3518a643fc7cfdf4bd352b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"2002.03399\",\"authors\":[{\"authorId\":\"17126804\",\"name\":\"F. Kuhnke\"},{\"authorId\":\"89274230\",\"name\":\"Lars Rumberg\"},{\"authorId\":\"123027238\",\"name\":\"J. Ostermann\"}],\"doi\":\"10.1109/FG47880.2020.00056\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b9d0935cd0017ab0705d783b985891abed6412f1\",\"title\":\"Two-Stream Aural-Visual Affect Analysis in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/b9d0935cd0017ab0705d783b985891abed6412f1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.02661\",\"authors\":[{\"authorId\":\"97621522\",\"name\":\"A. Shirian\"},{\"authorId\":\"48197292\",\"name\":\"S. Tripathi\"},{\"authorId\":\"1720741\",\"name\":\"T. Guha\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"981dc21c883f283e5104da294aa70e9042aa3af3\",\"title\":\"Learnable Graph Inception Network for Emotion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/981dc21c883f283e5104da294aa70e9042aa3af3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.06692\",\"authors\":[{\"authorId\":\"9214782\",\"name\":\"Trisha Mittal\"},{\"authorId\":\"6325349\",\"name\":\"P. Guhan\"},{\"authorId\":\"50227009\",\"name\":\"Uttaran Bhattacharya\"},{\"authorId\":\"30144577\",\"name\":\"Rohan Chandra\"},{\"authorId\":\"2979367\",\"name\":\"Aniket Bera\"},{\"authorId\":\"1699159\",\"name\":\"D. Manocha\"}],\"doi\":\"10.1109/cvpr42600.2020.01424\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d19bc4735cdb26935dbf50d2ac6d6b82fcc20302\",\"title\":\"EmotiCon: Context-Aware Multimodal Emotion Recognition Using Frege\\u2019s Principle\",\"url\":\"https://www.semanticscholar.org/paper/d19bc4735cdb26935dbf50d2ac6d6b82fcc20302\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32265398\",\"name\":\"M. Spezialetti\"},{\"authorId\":\"1808995\",\"name\":\"G. Placidi\"},{\"authorId\":\"145546380\",\"name\":\"S. Rossi\"}],\"doi\":\"10.3389/frobt.2020.532279\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"13b7d0127b399b36c230bf22a0881122a6731903\",\"title\":\"Emotion Recognition for Human-Robot Interaction: Recent Advances and Future Perspectives\",\"url\":\"https://www.semanticscholar.org/paper/13b7d0127b399b36c230bf22a0881122a6731903\",\"venue\":\"Frontiers in Robotics and AI\",\"year\":2020}],\"corpusId\":201058721,\"doi\":\"10.1109/ICCV.2019.01024\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":2,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"7f7618f2f315cb06b65925b4d497da30448c4f4d\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"144598072\",\"name\":\"D. King\"}],\"doi\":\"10.1145/1577069.1755843\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2ea6a93199c9227fa0c1c7de13725f918c9be3a4\",\"title\":\"Dlib-ml: A Machine Learning Toolkit\",\"url\":\"https://www.semanticscholar.org/paper/2ea6a93199c9227fa0c1c7de13725f918c9be3a4\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"152821938\",\"name\":\"Sanketh Shetty\"},{\"authorId\":\"120906511\",\"name\":\"T. Leung\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2014.223\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"title\":\"Large-Scale Video Classification with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1713496\",\"name\":\"P. Lucey\"},{\"authorId\":\"1737918\",\"name\":\"J. Cohn\"},{\"authorId\":\"1733113\",\"name\":\"T. Kanade\"},{\"authorId\":\"2398245\",\"name\":\"Jason M. Saragih\"},{\"authorId\":\"2059653\",\"name\":\"Z. Ambadar\"},{\"authorId\":\"1711695\",\"name\":\"I. Matthews\"}],\"doi\":\"10.1109/CVPRW.2010.5543262\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7dcdfe89a36e4e54d33362c164e09709a19bef7f\",\"title\":\"The Extended Cohn-Kanade Dataset (CK+): A complete dataset for action unit and emotion-specified expression\",\"url\":\"https://www.semanticscholar.org/paper/7dcdfe89a36e4e54d33362c164e09709a19bef7f\",\"venue\":\"2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition - Workshops\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143607713\",\"name\":\"C. Lisetti\"},{\"authorId\":\"2107729\",\"name\":\"Fatma Nasoz\"},{\"authorId\":\"1750842\",\"name\":\"C. LeRouge\"},{\"authorId\":\"1781389\",\"name\":\"Onur Ozyer\"},{\"authorId\":\"2592521\",\"name\":\"Kaye Alvarez\"}],\"doi\":\"10.1016/S1071-5819(03)00051-X\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d59ff756ebbcabce3a5f4d09ae7151c673090329\",\"title\":\"Developing multimodal intelligent affective interfaces for tele-home health care\",\"url\":\"https://www.semanticscholar.org/paper/d59ff756ebbcabce3a5f4d09ae7151c673090329\",\"venue\":\"Int. J. Hum. Comput. Stud.\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1413851634\",\"name\":\"C. F. Benitez-Quiroz\"},{\"authorId\":\"8038057\",\"name\":\"R. Srinivasan\"},{\"authorId\":\"145358414\",\"name\":\"A. Mart\\u00ednez\"}],\"doi\":\"10.1109/CVPR.2016.600\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"cbf4a4bbfadf0c8321da579075f14b997b1354ad\",\"title\":\"EmotioNet: An Accurate, Real-Time Algorithm for the Automatic Annotation of a Million Facial Expressions in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/cbf4a4bbfadf0c8321da579075f14b997b1354ad\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1686193\",\"name\":\"Georgios N. Yannakakis\"},{\"authorId\":\"1810053\",\"name\":\"J. Togelius\"}],\"doi\":\"10.1109/ACII.2015.7344619\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ff36175113a2d1cfeba4fdb78871a6f4b3ef29d0\",\"title\":\"Experience-Driven Procedural Content Generation\",\"url\":\"https://www.semanticscholar.org/paper/ff36175113a2d1cfeba4fdb78871a6f4b3ef29d0\",\"venue\":\"IEEE Transactions on Affective Computing\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47003426\",\"name\":\"Y. Li\"},{\"authorId\":\"3050780\",\"name\":\"Jiabei Zeng\"},{\"authorId\":\"145455919\",\"name\":\"S. Shan\"},{\"authorId\":\"1710220\",\"name\":\"X. Chen\"}],\"doi\":\"10.1109/TIP.2018.2886767\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b5bb7e12a15b57b4d307e742da127a74596d0c7c\",\"title\":\"Occlusion Aware Facial Expression Recognition Using CNN With Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/b5bb7e12a15b57b4d307e742da127a74596d0c7c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"1512.04150\",\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"2677488\",\"name\":\"\\u00c0gata Lapedriza\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/CVPR.2016.319\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"31f9eb39d840821979e5df9f34a6e92dd9c879f2\",\"title\":\"Learning Deep Features for Discriminative Localization\",\"url\":\"https://www.semanticscholar.org/paper/31f9eb39d840821979e5df9f34a6e92dd9c879f2\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2308430\",\"name\":\"Stefanos Eleftheriadis\"},{\"authorId\":\"143776835\",\"name\":\"Ognjen Rudovic\"},{\"authorId\":\"145387780\",\"name\":\"M. Pantic\"}],\"doi\":\"10.1109/TIP.2014.2375634\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5e9ec3b8daa95d45138e30c07321e386590f8ec7\",\"title\":\"Discriminative Shared Gaussian Processes for Multiview and View-Invariant Facial Expression Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5e9ec3b8daa95d45138e30c07321e386590f8ec7\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2352565\",\"name\":\"Sunok Kim\"},{\"authorId\":\"2065130\",\"name\":\"D. Min\"},{\"authorId\":\"2099537\",\"name\":\"Seungryong Kim\"},{\"authorId\":\"144442279\",\"name\":\"K. Sohn\"}],\"doi\":\"10.1109/TIP.2018.2878325\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eccaa4dd0b9807299a0d5490a391bb000bf9e5ec\",\"title\":\"Unified Confidence Estimation Networks for Robust Stereo Matching\",\"url\":\"https://www.semanticscholar.org/paper/eccaa4dd0b9807299a0d5490a391bb000bf9e5ec\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2870739\",\"name\":\"A. Kleinsmith\"},{\"authorId\":\"1398541310\",\"name\":\"N. Bianchi-Berthouze\"}],\"doi\":\"10.1007/978-3-540-74889-2_5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4fb23e81384005dac2120e35dbc9677ed5df92bc\",\"title\":\"Recognizing Affective Dimensions from Body Posture\",\"url\":\"https://www.semanticscholar.org/paper/4fb23e81384005dac2120e35dbc9677ed5df92bc\",\"venue\":\"ACII\",\"year\":2007},{\"arxivId\":\"1605.03639\",\"authors\":[{\"authorId\":\"2314025\",\"name\":\"A. Mollahosseini\"},{\"authorId\":\"3408037\",\"name\":\"B. Hassani\"},{\"authorId\":\"40418914\",\"name\":\"Michelle J. Salvador\"},{\"authorId\":\"3407846\",\"name\":\"Hojjat Abdollahi\"},{\"authorId\":\"143942598\",\"name\":\"D. Chan\"},{\"authorId\":\"145531712\",\"name\":\"M. Mahoor\"}],\"doi\":\"10.1109/CVPRW.2016.188\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4bc4cd82a96c50e11114e07579160cb501ae3c66\",\"title\":\"Facial Expression Recognition from World Wild Web\",\"url\":\"https://www.semanticscholar.org/paper/4bc4cd82a96c50e11114e07579160cb501ae3c66\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144881481\",\"name\":\"E. Aminoff\"},{\"authorId\":\"3003181\",\"name\":\"Kestutis Kveraga\"},{\"authorId\":\"2741887\",\"name\":\"M. Bar\"}],\"doi\":\"10.1016/j.tics.2013.06.009\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8020a2f3f619d2e9dd79eceb6bff2c7304f95c03\",\"title\":\"The role of the parahippocampal cortex in cognition\",\"url\":\"https://www.semanticscholar.org/paper/8020a2f3f619d2e9dd79eceb6bff2c7304f95c03\",\"venue\":\"Trends in Cognitive Sciences\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1383996606\",\"name\":\"Sidney K. D'Mello\"},{\"authorId\":\"1719389\",\"name\":\"Rosalind W. Picard\"},{\"authorId\":\"1769251\",\"name\":\"A. Graesser\"}],\"doi\":\"10.1109/MIS.2007.79\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"80df5a02e896b3b5507df0a1077c32d29e2c9853\",\"title\":\"Toward an Affect-Sensitive AutoTutor\",\"url\":\"https://www.semanticscholar.org/paper/80df5a02e896b3b5507df0a1077c32d29e2c9853\",\"venue\":\"IEEE Intelligent Systems\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3407277\",\"name\":\"Adam Paszke\"},{\"authorId\":\"39793298\",\"name\":\"S. Gross\"},{\"authorId\":\"2127604\",\"name\":\"Soumith Chintala\"},{\"authorId\":\"114250963\",\"name\":\"G. Chanan\"},{\"authorId\":\"50064334\",\"name\":\"E. Yang\"},{\"authorId\":\"81505016\",\"name\":\"Zachary Devito\"},{\"authorId\":\"3370429\",\"name\":\"Zeming Lin\"},{\"authorId\":\"3050846\",\"name\":\"Alban Desmaison\"},{\"authorId\":\"3029482\",\"name\":\"L. Antiga\"},{\"authorId\":\"1977806\",\"name\":\"A. Lerer\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b36a5bb1707bb9c70025294b3a310138aae8327a\",\"title\":\"Automatic differentiation in PyTorch\",\"url\":\"https://www.semanticscholar.org/paper/b36a5bb1707bb9c70025294b3a310138aae8327a\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144366829\",\"name\":\"Jiyoung Lee\"},{\"authorId\":\"2352565\",\"name\":\"Sunok Kim\"},{\"authorId\":\"2099537\",\"name\":\"Seungryong Kim\"},{\"authorId\":\"144442279\",\"name\":\"K. Sohn\"}],\"doi\":\"10.1109/ICASSP.2018.8461920\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0b25a29376261ace8a327150a5bb208c8ab0e6a5\",\"title\":\"Spatiotemporal Attention Based Deep Neural Networks for Emotion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/0b25a29376261ace8a327150a5bb208c8ab0e6a5\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":\"1708.03985\",\"authors\":[{\"authorId\":\"2314025\",\"name\":\"A. Mollahosseini\"},{\"authorId\":\"9706655\",\"name\":\"B. Hasani\"},{\"authorId\":\"145531712\",\"name\":\"M. Mahoor\"}],\"doi\":\"10.1109/TAFFC.2017.2740923\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4b149a326e38b9237077d794a0d5f5b4865efacf\",\"title\":\"AffectNet: A Database for Facial Expression, Valence, and Arousal Computing in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/4b149a326e38b9237077d794a0d5f5b4865efacf\",\"venue\":\"IEEE Transactions on Affective Computing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1735697\",\"name\":\"Abhinav Dhall\"},{\"authorId\":\"1717204\",\"name\":\"R. Goecke\"},{\"authorId\":\"1820249\",\"name\":\"S. Lucey\"},{\"authorId\":\"27011207\",\"name\":\"T. Gedeon\"}],\"doi\":\"10.1109/MMUL.2012.26\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"1336839e7bd3d072a2c699e613312a852a6586ae\",\"title\":\"Collecting Large, Richly Annotated Facial-Expression Databases from Movies\",\"url\":\"https://www.semanticscholar.org/paper/1336839e7bd3d072a2c699e613312a852a6586ae\",\"venue\":\"IEEE MultiMedia\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145387780\",\"name\":\"M. Pantic\"},{\"authorId\":\"1795528\",\"name\":\"M. Valstar\"},{\"authorId\":\"2503276\",\"name\":\"R. Rademaker\"},{\"authorId\":\"153828376\",\"name\":\"L. Maat\"}],\"doi\":\"10.1109/ICME.2005.1521424\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2a75f34663a60ab1b04a0049ed1d14335129e908\",\"title\":\"Web-based database for facial expression analysis\",\"url\":\"https://www.semanticscholar.org/paper/2a75f34663a60ab1b04a0049ed1d14335129e908\",\"venue\":\"2005 IEEE International Conference on Multimedia and Expo\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ali Mollahosseini\"},{\"authorId\":null,\"name\":\"Behzad Hasani\"},{\"authorId\":null,\"name\":\"Michelle J Salvador\"},{\"authorId\":null,\"name\":\"Hojjat Abdollahi\"},{\"authorId\":null,\"name\":\"David Chan\"},{\"authorId\":null,\"name\":\"Mohammad H Mahoor\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Facial expression recognition from world wild\",\"url\":\"\",\"venue\":\"web. In: CVPR Work.,\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1735697\",\"name\":\"Abhinav Dhall\"},{\"authorId\":\"1717204\",\"name\":\"R. Goecke\"},{\"authorId\":\"1820249\",\"name\":\"S. Lucey\"},{\"authorId\":\"27011207\",\"name\":\"T. Gedeon\"}],\"doi\":\"10.1109/ICCVW.2011.6130508\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"34a3d9d30e00550ab6a4f5ae5a8ecc0d1c3132c1\",\"title\":\"Static facial expression analysis in tough conditions: Data, evaluation protocol and benchmark\",\"url\":\"https://www.semanticscholar.org/paper/34a3d9d30e00550ab6a4f5ae5a8ecc0d1c3132c1\",\"venue\":\"2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops)\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1731779\",\"name\":\"L. Barrett\"},{\"authorId\":\"5935785\",\"name\":\"B. Mesquita\"},{\"authorId\":\"39456045\",\"name\":\"M. Gendron\"}],\"doi\":\"10.1177/0963721411422522\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"48e71c7d49d8d95ffde8363be7be0ff7c30dca8d\",\"title\":\"Context in Emotion Perception\",\"url\":\"https://www.semanticscholar.org/paper/48e71c7d49d8d95ffde8363be7be0ff7c30dca8d\",\"venue\":\"\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1752913\",\"name\":\"Mihalis A. Nicolaou\"},{\"authorId\":\"1781916\",\"name\":\"H. Gunes\"},{\"authorId\":\"145387780\",\"name\":\"M. Pantic\"}],\"doi\":\"10.1109/T-AFFC.2011.9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b34c6081aac87d4d9f659c8f342c05ce7b835bba\",\"title\":\"Continuous Prediction of Spontaneous Affect from Multiple Cues and Modalities in Valence-Arousal Space\",\"url\":\"https://www.semanticscholar.org/paper/b34c6081aac87d4d9f659c8f342c05ce7b835bba\",\"venue\":\"IEEE Transactions on Affective Computing\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145219961\",\"name\":\"P. Hu\"},{\"authorId\":\"1751449\",\"name\":\"Dongqi Cai\"},{\"authorId\":\"7489274\",\"name\":\"Shandong Wang\"},{\"authorId\":\"2021251\",\"name\":\"A. Yao\"},{\"authorId\":\"6060281\",\"name\":\"Y. Chen\"}],\"doi\":\"10.1145/3136755.3143009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5a5c85cf5c21a3559fbdf7da2263c7da860ea193\",\"title\":\"Learning supervised scoring ensemble for emotion recognition in the wild\",\"url\":\"https://www.semanticscholar.org/paper/5a5c85cf5c21a3559fbdf7da2263c7da860ea193\",\"venue\":\"ICMI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2870739\",\"name\":\"A. Kleinsmith\"},{\"authorId\":\"1398541310\",\"name\":\"N. Bianchi-Berthouze\"},{\"authorId\":\"143903462\",\"name\":\"A. Steed\"}],\"doi\":\"10.1109/TSMCB.2010.2103557\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c6e3c927978d546519d79c1db81618d783fdd63c\",\"title\":\"Automatic Recognition of Non-Acted Affective Postures\",\"url\":\"https://www.semanticscholar.org/paper/c6e3c927978d546519d79c1db81618d783fdd63c\",\"venue\":\"IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)\",\"year\":2011},{\"arxivId\":\"1709.07200\",\"authors\":[{\"authorId\":\"26339425\",\"name\":\"Valentin Vielzeuf\"},{\"authorId\":\"2642628\",\"name\":\"S. Pateux\"},{\"authorId\":\"82117876\",\"name\":\"F. Jurie\"}],\"doi\":\"10.1145/3136755.3143011\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"99f2972cf3e895c0c1847c9929818920383ae0ff\",\"title\":\"Temporal multimodal fusion for video emotion classification in the wild\",\"url\":\"https://www.semanticscholar.org/paper/99f2972cf3e895c0c1847c9929818920383ae0ff\",\"venue\":\"ICMI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145815850\",\"name\":\"Jie Hu\"},{\"authorId\":\"152148573\",\"name\":\"L. Shen\"},{\"authorId\":\"7641268\",\"name\":\"Samuel Albanie\"},{\"authorId\":\"152274574\",\"name\":\"Gang Sun\"},{\"authorId\":\"145344139\",\"name\":\"Enhua Wu\"}],\"doi\":\"10.1109/TPAMI.2019.2913372\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"df67d46e78aae0d2fccfb6212d101a342259c01b\",\"title\":\"Squeeze-and-Excitation Networks\",\"url\":\"https://www.semanticscholar.org/paper/df67d46e78aae0d2fccfb6212d101a342259c01b\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1735697\",\"name\":\"Abhinav Dhall\"},{\"authorId\":\"1717204\",\"name\":\"R. Goecke\"},{\"authorId\":\"50391500\",\"name\":\"Jyoti Joshi\"},{\"authorId\":\"145803385\",\"name\":\"J. Hoey\"},{\"authorId\":\"27011207\",\"name\":\"T. Gedeon\"}],\"doi\":\"10.1145/2993148.2997638\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d781b943bff6a3b62a79e2c8daf7f4d4d6431ad\",\"title\":\"EmotiW 2016: video and group-level emotion recognition challenges\",\"url\":\"https://www.semanticscholar.org/paper/0d781b943bff6a3b62a79e2c8daf7f4d4d6431ad\",\"venue\":\"ICMI\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10795229\",\"name\":\"Caifeng Shan\"},{\"authorId\":\"144784813\",\"name\":\"S. Gong\"},{\"authorId\":\"2803283\",\"name\":\"P. McOwan\"}],\"doi\":\"10.1016/j.imavis.2008.08.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bd8d579715d58405dfd5a77f32920aafe018fce4\",\"title\":\"Facial expression recognition based on Local Binary Patterns: A comprehensive study\",\"url\":\"https://www.semanticscholar.org/paper/bd8d579715d58405dfd5a77f32920aafe018fce4\",\"venue\":\"Image Vis. Comput.\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"47680287\",\"name\":\"W. Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2009.5206848\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1b47265245e8db53a553049dcb27ed3e495fd625\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/1b47265245e8db53a553049dcb27ed3e495fd625\",\"venue\":\"CVPR 2009\",\"year\":2009},{\"arxivId\":\"1807.06521\",\"authors\":[{\"authorId\":\"2262209\",\"name\":\"S. Woo\"},{\"authorId\":\"6485607\",\"name\":\"Jongchan Park\"},{\"authorId\":\"1926578\",\"name\":\"Joon-Young Lee\"},{\"authorId\":\"2398271\",\"name\":\"In-So Kweon\"}],\"doi\":\"10.1007/978-3-030-01234-2_1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"de95601d9e3b20ec51aa33e1f27b1880d2c44ef2\",\"title\":\"CBAM: Convolutional Block Attention Module\",\"url\":\"https://www.semanticscholar.org/paper/de95601d9e3b20ec51aa33e1f27b1880d2c44ef2\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35587961\",\"name\":\"Yingruo Fan\"},{\"authorId\":\"145669829\",\"name\":\"Jacqueline C. K. Lam\"},{\"authorId\":\"144354165\",\"name\":\"V. Li\"}],\"doi\":\"10.1145/3242969.3264978\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2cf91c09d648d37c9833d9763721fe07213ae985\",\"title\":\"Video-based Emotion Recognition Using Deeply-Supervised Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/2cf91c09d648d37c9833d9763721fe07213ae985\",\"venue\":\"ICMI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1735697\",\"name\":\"Abhinav Dhall\"},{\"authorId\":\"1717204\",\"name\":\"R. Goecke\"},{\"authorId\":\"1820249\",\"name\":\"S. Lucey\"},{\"authorId\":\"27011207\",\"name\":\"T. Gedeon\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"223ec77652c268b98c298327d42aacea8f3ce23f\",\"title\":\"TR-CS-1102 Acted Facial Expressions In The Wild Database\",\"url\":\"https://www.semanticscholar.org/paper/223ec77652c268b98c298327d42aacea8f3ce23f\",\"venue\":\"\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/ICCV.2015.510\",\"intent\":[\"methodology\",\"result\"],\"isInfluential\":false,\"paperId\":\"d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"title\":\"Learning Spatiotemporal Features with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1604.05766\",\"authors\":[{\"authorId\":\"50339742\",\"name\":\"Krishna Kumar Singh\"},{\"authorId\":\"2299381\",\"name\":\"Fanyi Xiao\"},{\"authorId\":\"144756076\",\"name\":\"Y. Lee\"}],\"doi\":\"10.1109/CVPR.2016.386\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fae2e29e534e1e20d6ff1c59a9eeb855686181e3\",\"title\":\"Track and Transfer: Watching Videos to Simulate Strong Human Supervision for Weakly-Supervised Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/fae2e29e534e1e20d6ff1c59a9eeb855686181e3\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1511.04119\",\"authors\":[{\"authorId\":\"145478041\",\"name\":\"Shikhar Sharma\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7b8810ad8ef9ddd024583f95a51559e6c1b8c754\",\"title\":\"Action Recognition using Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/7b8810ad8ef9ddd024583f95a51559e6c1b8c754\",\"venue\":\"NIPS 2015\",\"year\":2015},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49730034\",\"name\":\"B. Li\"},{\"authorId\":\"2214855\",\"name\":\"Weihua Xiong\"},{\"authorId\":\"40506509\",\"name\":\"W. Hu\"},{\"authorId\":\"2228341\",\"name\":\"Xinmiao Ding\"}],\"doi\":\"10.1145/2393347.2396296\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d4f2e1f24c726bdd3ff2456097ba6e3db9023f7\",\"title\":\"Context-aware affective images classification based on bilayer sparse representation\",\"url\":\"https://www.semanticscholar.org/paper/3d4f2e1f24c726bdd3ff2456097ba6e3db9023f7\",\"venue\":\"ACM Multimedia\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24320514\",\"name\":\"Ronak Kosti\"},{\"authorId\":\"2974008\",\"name\":\"Jose M. Alvarez\"},{\"authorId\":\"39257069\",\"name\":\"A. Recasens\"},{\"authorId\":\"2677488\",\"name\":\"\\u00c0gata Lapedriza\"}],\"doi\":\"10.1109/CVPR.2017.212\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"382e9f1ed5e3e0e7dd5b1f27cdd14e4202044f9b\",\"title\":\"Emotion Recognition in Context\",\"url\":\"https://www.semanticscholar.org/paper/382e9f1ed5e3e0e7dd5b1f27cdd14e4202044f9b\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3125761\",\"name\":\"Jean Kossaifi\"},{\"authorId\":\"2610880\",\"name\":\"Georgios Tzimiropoulos\"},{\"authorId\":\"143856428\",\"name\":\"S. Todorovic\"},{\"authorId\":\"145387780\",\"name\":\"M. Pantic\"}],\"doi\":\"10.1016/j.imavis.2017.02.001\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2624d84503bc2f8e190e061c5480b6aa4d89277a\",\"title\":\"AFEW-VA database for valence and arousal estimation in-the-wild\",\"url\":\"https://www.semanticscholar.org/paper/2624d84503bc2f8e190e061c5480b6aa4d89277a\",\"venue\":\"Image Vis. Comput.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1145/2964284.2967196\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"357a65432aecd0565df9dc9b8e013dd46d8d184b\",\"title\":\"Emotion in Context: Deep Semantic Feature Fusion for Video Emotion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/357a65432aecd0565df9dc9b8e013dd46d8d184b\",\"venue\":\"ACM Multimedia\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50827772\",\"name\":\"G. Patterson\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"}],\"doi\":\"10.1007/978-3-319-46466-4_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8db052e5eea17c28d8a98b9d5a5e7c32bee2655c\",\"title\":\"COCO Attributes: Attributes for People, Animals, and Objects\",\"url\":\"https://www.semanticscholar.org/paper/8db052e5eea17c28d8a98b9d5a5e7c32bee2655c\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Sanghyun Woo\"},{\"authorId\":null,\"name\":\"Jongchan Park\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Joon-Young Lee, and In So Kweon. Cbam: Convolutional block attention module\",\"url\":\"\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21451088\",\"name\":\"P. Ekman\"},{\"authorId\":\"37652085\",\"name\":\"W. Friesen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1566cf20e2ba91ca8857c30083419bf7c127094b\",\"title\":\"Facial action coding system: a technique for the measurement of facial movement\",\"url\":\"https://www.semanticscholar.org/paper/1566cf20e2ba91ca8857c30083419bf7c127094b\",\"venue\":\"\",\"year\":1978},{\"arxivId\":\"1610.02391\",\"authors\":[{\"authorId\":\"35100058\",\"name\":\"R. R. Selvaraju\"},{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"144354133\",\"name\":\"Michael Cogswell\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-019-01228-7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e7eef2ac4136ec93bd306d2c9c353a13729a4553\",\"title\":\"Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization\",\"url\":\"https://www.semanticscholar.org/paper/e7eef2ac4136ec93bd306d2c9c353a13729a4553\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"1307.0414\",\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"153921980\",\"name\":\"Pierre Luc Carrier\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"3033919\",\"name\":\"Benjamin Hamner\"},{\"authorId\":\"3155742\",\"name\":\"William Cukierski\"},{\"authorId\":\"34312504\",\"name\":\"Y. Tang\"},{\"authorId\":\"40294315\",\"name\":\"D. Thaler\"},{\"authorId\":\"152496349\",\"name\":\"Dong-Hyun Lee\"},{\"authorId\":\"34872128\",\"name\":\"Yingbo Zhou\"},{\"authorId\":\"1764124\",\"name\":\"Chetan Ramaiah\"},{\"authorId\":\"39825530\",\"name\":\"Fangxiang Feng\"},{\"authorId\":\"2462591\",\"name\":\"Ruifan Li\"},{\"authorId\":\"38542466\",\"name\":\"X. Wang\"},{\"authorId\":\"19998730\",\"name\":\"Dimitris Athanasakis\"},{\"authorId\":\"1404459229\",\"name\":\"J. Shawe-Taylor\"},{\"authorId\":\"2449832\",\"name\":\"Maxim Milakov\"},{\"authorId\":\"70373009\",\"name\":\"John Park\"},{\"authorId\":\"1817759\",\"name\":\"Radu Tudor Ionescu\"},{\"authorId\":\"49006356\",\"name\":\"M. Popescu\"},{\"authorId\":\"2599036\",\"name\":\"C. Grozea\"},{\"authorId\":\"32837403\",\"name\":\"J. Bergstra\"},{\"authorId\":\"46577093\",\"name\":\"Jingjing Xie\"},{\"authorId\":\"1743912\",\"name\":\"Lukasz Romaszko\"},{\"authorId\":\"144738865\",\"name\":\"Bing Xu\"},{\"authorId\":\"100522306\",\"name\":\"Chuang Zhang\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":\"10.1016/j.neunet.2014.09.005\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"db8c3cfaae04a14c1209d62953029b6fa53e23c7\",\"title\":\"Challenges in representation learning: A report on three machine learning contests\",\"url\":\"https://www.semanticscholar.org/paper/db8c3cfaae04a14c1209d62953029b6fa53e23c7\",\"venue\":\"Neural Networks\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34575578\",\"name\":\"Y. Fan\"},{\"authorId\":\"3090848\",\"name\":\"Xiangju Lu\"},{\"authorId\":\"144760436\",\"name\":\"Dian Li\"},{\"authorId\":\"2816557\",\"name\":\"Yuanliu Liu\"}],\"doi\":\"10.1145/2993148.2997632\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"92527ace7f75188b5ec209ff7d59f431343075e4\",\"title\":\"Video-based emotion recognition using CNN-RNN and C3D hybrid networks\",\"url\":\"https://www.semanticscholar.org/paper/92527ace7f75188b5ec209ff7d59f431343075e4\",\"venue\":\"ICMI\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144243333\",\"name\":\"Lin Zhong\"},{\"authorId\":\"50383828\",\"name\":\"Qingshan Liu\"},{\"authorId\":\"145512282\",\"name\":\"Peng Yang\"},{\"authorId\":\"40107085\",\"name\":\"Bo Liu\"},{\"authorId\":\"1768190\",\"name\":\"J. Huang\"},{\"authorId\":\"1711560\",\"name\":\"D. Metaxas\"}],\"doi\":\"10.1109/CVPR.2012.6247974\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d785fcf71cb22f9c33473cba35f075c1f0f06ffc\",\"title\":\"Learning active facial patches for expression analysis\",\"url\":\"https://www.semanticscholar.org/paper/d785fcf71cb22f9c33473cba35f075c1f0f06ffc\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39433609\",\"name\":\"Shan Li\"},{\"authorId\":\"1774956\",\"name\":\"W. Deng\"},{\"authorId\":\"8491162\",\"name\":\"J. Du\"}],\"doi\":\"10.1109/CVPR.2017.277\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d57982dc55dbed3d0f89589e319dc2d2bd598532\",\"title\":\"Reliable Crowdsourcing and Deep Locality-Preserving Learning for Expression Recognition in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/d57982dc55dbed3d0f89589e319dc2d2bd598532\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3c3633d08316fe527b7836b4038359538088fa8e\",\"title\":\"Visual Sentiment Analysis by Attending on Local Image Regions\",\"url\":\"https://www.semanticscholar.org/paper/3c3633d08316fe527b7836b4038359538088fa8e\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1755872\",\"name\":\"Jufeng Yang\"},{\"authorId\":\"22631231\",\"name\":\"Dongyu She\"},{\"authorId\":\"7827503\",\"name\":\"Y. Lai\"},{\"authorId\":\"1734823\",\"name\":\"Paul L. Rosin\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/CVPR.2018.00791\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5ec456cea7c6831eba87cebf9e2fa873b5aee4d2\",\"title\":\"Weakly Supervised Coupled Networks for Visual Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/5ec456cea7c6831eba87cebf9e2fa873b5aee4d2\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"2229862\",\"name\":\"Baohan Xu\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e9ab17d68a35f35e026c025904d053a653b7c02e\",\"title\":\"Predicting Emotions in User-Generated Videos\",\"url\":\"https://www.semanticscholar.org/paper/e9ab17d68a35f35e026c025904d053a653b7c02e\",\"venue\":\"AAAI\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144810819\",\"name\":\"K. Schindler\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"3213354\",\"name\":\"B. Gelder\"}],\"doi\":\"10.1016/j.neunet.2008.05.003\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ec2c8ca6e8bc6762a586d6addc46c95574a76e8a\",\"title\":\"Recognizing emotions expressed by body pose: A biologically inspired neural model\",\"url\":\"https://www.semanticscholar.org/paper/ec2c8ca6e8bc6762a586d6addc46c95574a76e8a\",\"venue\":\"Neural Networks\",\"year\":2008},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016}],\"title\":\"Context-Aware Emotion Recognition Networks\",\"topics\":[{\"topic\":\"Emotion recognition\",\"topicId\":\"68560\",\"url\":\"https://www.semanticscholar.org/topic/68560\"},{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"},{\"topic\":\"ENCODE\",\"topicId\":\"365717\",\"url\":\"https://www.semanticscholar.org/topic/365717\"}],\"url\":\"https://www.semanticscholar.org/paper/7f7618f2f315cb06b65925b4d497da30448c4f4d\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019}\n"