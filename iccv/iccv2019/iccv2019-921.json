"{\"abstract\":\"Font selection is one of the most important steps in a design workflow. Traditional methods rely on ordered lists which require significant domain knowledge and are often difficult to use even for trained professionals. In this paper, we address the problem of large-scale tag-based font retrieval which aims to bring semantics to the font selection process and enable people without expert knowledge to use fonts effectively. We collect a large-scale font tagging dataset of high-quality professional fonts. The dataset contains nearly 20,000 fonts, 2,000 tags, and hundreds of thousands of font-tag relations. We propose a novel generative feature learning algorithm that leverages the unique characteristics of fonts. The key idea is that font images are synthetic and can therefore be controlled by the learning algorithm. We design an integrated rendering and learning process so that the visual feature from one image can be used to reconstruct another image with different text. The resulting feature captures important font design details while is robust to nuisance factors such as text. We propose a novel attention mechanism to re-weight the visual feature for joint visual-text modeling. We combine the feature and the attention mechanism in a novel recognition-retrieval model. Experimental results show that our method significantly outperforms the state-of-the-art for the important problem of large-scale tag-based font retrieval.\",\"arxivId\":\"1909.02072\",\"authors\":[{\"authorId\":\"7934161\",\"name\":\"T. Chen\",\"url\":\"https://www.semanticscholar.org/author/7934161\"},{\"authorId\":\"50218411\",\"name\":\"Z. Wang\",\"url\":\"https://www.semanticscholar.org/author/50218411\"},{\"authorId\":\"145857599\",\"name\":\"N. Xu\",\"url\":\"https://www.semanticscholar.org/author/145857599\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\",\"url\":\"https://www.semanticscholar.org/author/41151701\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\",\"url\":\"https://www.semanticscholar.org/author/33642939\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"9580843\",\"name\":\"Tugba Kulahcioglu\"},{\"authorId\":\"144608002\",\"name\":\"Gerard de Melo\"}],\"doi\":\"10.1145/3394171.3413534\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fd3d67e702a97385e9997614edd6834462b15926\",\"title\":\"Fonts Like This but Happier: A New Way to Discover Fonts\",\"url\":\"https://www.semanticscholar.org/paper/fd3d67e702a97385e9997614edd6834462b15926\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2005.07865\",\"authors\":[{\"authorId\":null,\"name\":\"Yizhi Wang\"},{\"authorId\":\"48146797\",\"name\":\"Yue Gao\"},{\"authorId\":\"2620336\",\"name\":\"Zhouhui Lian\"}],\"doi\":\"10.1145/3386569.3392456\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7071e5947d55902082fe8248027ed61c00d5064e\",\"title\":\"Attribute2Font: Creating Fonts You Want From Attributes\",\"url\":\"https://www.semanticscholar.org/paper/7071e5947d55902082fe8248027ed61c00d5064e\",\"venue\":\"ACM Trans. Graph.\",\"year\":2020}],\"corpusId\":202541141,\"doi\":\"10.1109/ICCV.2019.00921\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":1,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"22d07f5eb536877aafbad9d790b56c51bb1c4a42\",\"references\":[{\"arxivId\":\"1803.08024\",\"authors\":[{\"authorId\":\"1863953\",\"name\":\"Kuang-Huei Lee\"},{\"authorId\":\"1683647\",\"name\":\"X. Chen\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\"},{\"authorId\":\"35431603\",\"name\":\"H. Hu\"},{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"}],\"doi\":\"10.1007/978-3-030-01225-0_13\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"45dd2a3cd7c27f2e9509b023d702408f5ac11c9d\",\"title\":\"Stacked Cross Attention for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/45dd2a3cd7c27f2e9509b023d702408f5ac11c9d\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1411.1784\",\"authors\":[{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"2217144\",\"name\":\"Simon Osindero\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"353ecf7b66b3e9ff5e9f41145a147e899a2eea5c\",\"title\":\"Conditional Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/353ecf7b66b3e9ff5e9f41145a147e899a2eea5c\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30296838\",\"name\":\"Bokun Wang\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":\"47158869\",\"name\":\"Xing Xu\"},{\"authorId\":\"1718099\",\"name\":\"A. Hanjalic\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1145/3123266.3123326\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"61060bea27a3410260988540b627ccc5ba131822\",\"title\":\"Adversarial Cross-Modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/61060bea27a3410260988540b627ccc5ba131822\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":\"1703.04394\",\"authors\":[{\"authorId\":\"3370667\",\"name\":\"Yongqin Xian\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"2893664\",\"name\":\"Zeynep Akata\"}],\"doi\":\"10.1109/CVPR.2017.328\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"89e88ab5b7ba7557573ad773a0a077484bee3759\",\"title\":\"Zero-Shot Learning \\u2014 The Good, the Bad and the Ugly\",\"url\":\"https://www.semanticscholar.org/paper/89e88ab5b7ba7557573ad773a0a077484bee3759\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143776763\",\"name\":\"L. Tran\"},{\"authorId\":\"2399004\",\"name\":\"Xi Yin\"},{\"authorId\":\"1759169\",\"name\":\"X. Liu\"}],\"doi\":\"10.1109/CVPR.2017.141\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b5ca8d4f259f35c1f3edfd9f108ce29881e478b0\",\"title\":\"Disentangled Representation Learning GAN for Pose-Invariant Face Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b5ca8d4f259f35c1f3edfd9f108ce29881e478b0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403433976\",\"name\":\"P. O'Donovan\"},{\"authorId\":\"2569322\",\"name\":\"Janis Libeks\"},{\"authorId\":\"46260271\",\"name\":\"A. Agarwala\"},{\"authorId\":\"1747779\",\"name\":\"Aaron Hertzmann\"}],\"doi\":\"10.1145/2601097.2601110\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f7a1f2c6f5d2fe442488a365904c69766ab2cce8\",\"title\":\"Exploratory font selection using crowdsourced attributes\",\"url\":\"https://www.semanticscholar.org/paper/f7a1f2c6f5d2fe442488a365904c69766ab2cce8\",\"venue\":\"ACM Trans. Graph.\",\"year\":2014},{\"arxivId\":\"1511.02274\",\"authors\":[{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"46234526\",\"name\":\"Alex Smola\"}],\"doi\":\"10.1109/CVPR.2016.10\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c1890864c1c2b750f48316dc8b650ba4772adc5\",\"title\":\"Stacked Attention Networks for Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2c1890864c1c2b750f48316dc8b650ba4772adc5\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1703.10593\",\"authors\":[{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"145599603\",\"name\":\"T. Park\"},{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1109/ICCV.2017.244\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c43d954cf8133e6254499f3d68e45218067e4941\",\"title\":\"Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/c43d954cf8133e6254499f3d68e45218067e4941\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Hannes Nickisch\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Hinton . Imagenet classification with deep convolutional neural networks\",\"url\":\"\",\"venue\":\"Advances in neural information processing systems\",\"year\":2012},{\"arxivId\":\"1301.3666\",\"authors\":[{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"2012435\",\"name\":\"M. Ganjoo\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"},{\"authorId\":\"34699434\",\"name\":\"A. Ng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"755e9f43ce398ae8737366720c5f82685b0c253e\",\"title\":\"Zero-Shot Learning Through Cross-Modal Transfer\",\"url\":\"https://www.semanticscholar.org/paper/755e9f43ce398ae8737366720c5f82685b0c253e\",\"venue\":\"NIPS\",\"year\":2013},{\"arxivId\":\"1612.01887\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":\"10.1109/CVPR.2017.345\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9f4d7d622d1f7319cc511bfef661cd973e881a4c\",\"title\":\"Knowing When to Look: Adaptive Attention via a Visual Sentinel for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9f4d7d622d1f7319cc511bfef661cd973e881a4c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3163684\",\"name\":\"Abdel Wahab Zramdini\"},{\"authorId\":\"1680326\",\"name\":\"R. Ingold\"}],\"doi\":\"10.1109/34.709616\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2097d07a289e65c4d676a502756726b75f24af80\",\"title\":\"Optical Font Recognition Using Typographical Features\",\"url\":\"https://www.semanticscholar.org/paper/2097d07a289e65c4d676a502756726b75f24af80\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":1998},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46179714\",\"name\":\"Y. Liu\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"1808473\",\"name\":\"I. Wassell\"}],\"doi\":\"10.1109/CVPR.2018.00394\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2025392b7ebe267fbe13cb9fcd022ded8f7d1972\",\"title\":\"Multi-task Adversarial Network for Disentangled Feature Learning\",\"url\":\"https://www.semanticscholar.org/paper/2025392b7ebe267fbe13cb9fcd022ded8f7d1972\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1711.06025\",\"authors\":[{\"authorId\":\"40497013\",\"name\":\"Flood Sung\"},{\"authorId\":\"2653152\",\"name\":\"Yongxin Yang\"},{\"authorId\":\"52423203\",\"name\":\"L. Zhang\"},{\"authorId\":\"145406421\",\"name\":\"T. Xiang\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"},{\"authorId\":\"1697755\",\"name\":\"Timothy M. Hospedales\"}],\"doi\":\"10.1109/CVPR.2018.00131\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"bfe284e4338e62f0a61bb33398353efd687f206f\",\"title\":\"Learning to Compare: Relation Network for Few-Shot Learning\",\"url\":\"https://www.semanticscholar.org/paper/bfe284e4338e62f0a61bb33398353efd687f206f\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1787591\",\"name\":\"Christoph H. Lampert\"},{\"authorId\":\"1748758\",\"name\":\"H. Nickisch\"},{\"authorId\":\"1734990\",\"name\":\"S. Harmeling\"}],\"doi\":\"10.1109/CVPRW.2009.5206594\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0566bf06a0368b518b8b474166f7b1dfef3f9283\",\"title\":\"Learning to detect unseen object classes by between-class attribute transfer\",\"url\":\"https://www.semanticscholar.org/paper/0566bf06a0368b518b8b474166f7b1dfef3f9283\",\"venue\":\"2009 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2009},{\"arxivId\":\"1708.01988\",\"authors\":[{\"authorId\":\"2944920\",\"name\":\"Shaomeng Li\"},{\"authorId\":null,\"name\":\"Tong Xiao\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"47718789\",\"name\":\"Wei Yang\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1109/ICCV.2017.209\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f222282574666658dc0408176805cbe21348477d\",\"title\":\"Identity-Aware Textual-Visual Matching with Latent Co-attention\",\"url\":\"https://www.semanticscholar.org/paper/f222282574666658dc0408176805cbe21348477d\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3056361\",\"name\":\"J. Friedman\"}],\"doi\":\"10.1214/AOS/1013203451\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1679beddda3a183714d380e944fe6bf586c083cd\",\"title\":\"Greedy function approximation: A gradient boosting machine.\",\"url\":\"https://www.semanticscholar.org/paper/1679beddda3a183714d380e944fe6bf586c083cd\",\"venue\":\"\",\"year\":2001},{\"arxivId\":\"1702.05729\",\"authors\":[{\"authorId\":\"2944920\",\"name\":\"Shaomeng Li\"},{\"authorId\":null,\"name\":\"Tong Xiao\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"1380096226\",\"name\":\"Dayu Yue\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1109/CVPR.2017.551\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"28870e4de79d5086864a9f2c6df632b606ac3347\",\"title\":\"Person Search with Natural Language Description\",\"url\":\"https://www.semanticscholar.org/paper/28870e4de79d5086864a9f2c6df632b606ac3347\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1711.09347\",\"authors\":[{\"authorId\":null,\"name\":\"Xi Zhang\"},{\"authorId\":\"2356867\",\"name\":\"Hanjiang Lai\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":\"10.1007/978-3-030-01267-0_36\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3bc2f0c63de7aa6d13b891e3924a35eb46c81c77\",\"title\":\"Attention-Aware Deep Adversarial Hashing for Cross-Modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/3bc2f0c63de7aa6d13b891e3924a35eb46c81c77\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"123371831\",\"name\":\"\\u00c0gata Lapedriza\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/TPAMI.2017.2723009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f986968735459e789890f24b6b277b0920a9725d\",\"title\":\"Places: A 10 Million Image Database for Scene Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f986968735459e789890f24b6b277b0920a9725d\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1403025868\",\"name\":\"Jean Pouget-Abadie\"},{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"144738865\",\"name\":\"Bing Xu\"},{\"authorId\":\"1393680089\",\"name\":\"David Warde-Farley\"},{\"authorId\":\"1955694\",\"name\":\"Sherjil Ozair\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"title\":\"Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1611.07004\",\"authors\":[{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"1822702\",\"name\":\"Tinghui Zhou\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1109/CVPR.2017.632\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8acbe90d5b852dadea7810345451a99608ee54c7\",\"title\":\"Image-to-Image Translation with Conditional Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/8acbe90d5b852dadea7810345451a99608ee54c7\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1802.06454\",\"authors\":[{\"authorId\":\"145798572\",\"name\":\"S. Ma\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"1735257\",\"name\":\"C. Chen\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2018.00593\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"247d40bed85d09e752f60e5183f14b02e100360b\",\"title\":\"DA-GAN: Instance-Level Image Translation by Deep Attention Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/247d40bed85d09e752f60e5183f14b02e100360b\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1707.07998\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"31790073\",\"name\":\"C. Buehler\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":\"10.1109/CVPR.2018.00636\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"title\":\"Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1606.01455\",\"authors\":[{\"authorId\":\"2684967\",\"name\":\"J. Kim\"},{\"authorId\":\"3226948\",\"name\":\"Sang-Woo Lee\"},{\"authorId\":\"3422869\",\"name\":\"Dong-Hyun Kwak\"},{\"authorId\":\"2939188\",\"name\":\"Min-Oh Heo\"},{\"authorId\":\"2947441\",\"name\":\"J. Kim\"},{\"authorId\":\"2577039\",\"name\":\"Jung-Woo Ha\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1afb710a5b35a2352a6495e4bf6eef66808daf1b\",\"title\":\"Multimodal Residual Learning for Visual QA\",\"url\":\"https://www.semanticscholar.org/paper/1afb710a5b35a2352a6495e4bf6eef66808daf1b\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1507.03196\",\"authors\":[{\"authorId\":\"2969311\",\"name\":\"Zhangyang Wang\"},{\"authorId\":\"1706007\",\"name\":\"Jianchao Yang\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"1696487\",\"name\":\"A. Agarwala\"},{\"authorId\":\"145561604\",\"name\":\"Jonathan Brandt\"},{\"authorId\":\"1739208\",\"name\":\"T. Huang\"}],\"doi\":\"10.1145/2733373.2806219\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7620ad01e6bff1b4e10abb843af855e56fbd4800\",\"title\":\"DeepFont: Identify Your Font from An Image\",\"url\":\"https://www.semanticscholar.org/paper/7620ad01e6bff1b4e10abb843af855e56fbd4800\",\"venue\":\"ACM Multimedia\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2279670\",\"name\":\"Andrea Frome\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"1789737\",\"name\":\"Jonathon Shlens\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"},{\"authorId\":\"1706809\",\"name\":\"Marc'Aurelio Ranzato\"},{\"authorId\":null,\"name\":\"Tomas Mikolov\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4aa4069693bee00d1b0759ca3df35e59284e9845\",\"title\":\"DeViSE: A Deep Visual-Semantic Embedding Model\",\"url\":\"https://www.semanticscholar.org/paper/4aa4069693bee00d1b0759ca3df35e59284e9845\",\"venue\":\"NIPS\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2367820\",\"name\":\"C. Wah\"},{\"authorId\":\"3251767\",\"name\":\"S. Branson\"},{\"authorId\":\"2930640\",\"name\":\"P. Welinder\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c069629a51f6c1c301eb20ed77bc6b586c24ce32\",\"title\":\"The Caltech-UCSD Birds-200-2011 Dataset\",\"url\":\"https://www.semanticscholar.org/paper/c069629a51f6c1c301eb20ed77bc6b586c24ce32\",\"venue\":\"\",\"year\":2011},{\"arxivId\":\"1711.06420\",\"authors\":[{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"2708940\",\"name\":\"Shafiq R. Joty\"},{\"authorId\":\"39298199\",\"name\":\"Li Niu\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"}],\"doi\":\"10.1109/CVPR.2018.00750\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"724b253a55e86ad230ba05c7eb78f249e09258d9\",\"title\":\"Look, Imagine and Match: Improving Textual-Visual Cross-Modal Retrieval with Generative Models\",\"url\":\"https://www.semanticscholar.org/paper/724b253a55e86ad230ba05c7eb78f249e09258d9\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48270268\",\"name\":\"Yong Zhu\"},{\"authorId\":\"143874948\",\"name\":\"T. Tan\"},{\"authorId\":\"40013375\",\"name\":\"Y. Wang\"}],\"doi\":\"10.1109/34.954608\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"20db17b2ffdf0baf0b3d0cfa1405946e140fb378\",\"title\":\"Font Recognition Based on Global Texture Analysis\",\"url\":\"https://www.semanticscholar.org/paper/20db17b2ffdf0baf0b3d0cfa1405946e140fb378\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2001},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1605.05395\",\"authors\":[{\"authorId\":\"48840704\",\"name\":\"Scott Reed\"},{\"authorId\":\"2893664\",\"name\":\"Zeynep Akata\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1109/CVPR.2016.13\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"90368e1751b34f22492ed18cc3b1ab19ae546afa\",\"title\":\"Learning Deep Representations of Fine-Grained Visual Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/90368e1751b34f22492ed18cc3b1ab19ae546afa\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1711.06454\",\"authors\":[{\"authorId\":\"22796119\",\"name\":\"Y. Zhang\"},{\"authorId\":\"2280849\",\"name\":\"Wenbin Cai\"},{\"authorId\":\"153533574\",\"name\":\"Ya Zhang\"}],\"doi\":\"10.1109/CVPR.2018.00881\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1b0ea9b19edaf99aff5e411020387a70c79867c8\",\"title\":\"Separating Style and Content for Generalized Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/1b0ea9b19edaf99aff5e411020387a70c79867c8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1712.00516\",\"authors\":[{\"authorId\":\"2300366\",\"name\":\"Samaneh Azadi\"},{\"authorId\":\"145002004\",\"name\":\"Matthew Fisher\"},{\"authorId\":\"3082383\",\"name\":\"Vladimir G. Kim\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/CVPR.2018.00789\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8faddb00bb5b99013ec359475ba7787ff7e05229\",\"title\":\"Multi-content GAN for Few-Shot Font Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/8faddb00bb5b99013ec359475ba7787ff7e05229\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1603.03925\",\"authors\":[{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2016.503\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"bf55591e09b58ea9ce8d66110d6d3000ee804bdd\",\"title\":\"Image Captioning with Semantic Attention\",\"url\":\"https://www.semanticscholar.org/paper/bf55591e09b58ea9ce8d66110d6d3000ee804bdd\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46879353\",\"name\":\"G. Chen\"},{\"authorId\":\"1706007\",\"name\":\"Jianchao Yang\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"145561604\",\"name\":\"Jonathan Brandt\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"1696487\",\"name\":\"A. Agarwala\"},{\"authorId\":\"3244463\",\"name\":\"Tony X. Han\"}],\"doi\":\"10.1109/CVPR.2014.460\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b6b428c697bc7346da8ca8fcdd59513e0266d4a4\",\"title\":\"Large-Scale Visual Font Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b6b428c697bc7346da8ca8fcdd59513e0266d4a4\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"},{\"authorId\":\"31790073\",\"name\":\"C. Buehler\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"46878216\",\"name\":\"M. Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a79b694bd4ef51207787da1948ed473903b751ef\",\"title\":\"Bottom-Up and Top-Down Attention for Image Captioning and VQA\",\"url\":\"https://www.semanticscholar.org/paper/a79b694bd4ef51207787da1948ed473903b751ef\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1711.05535\",\"authors\":[{\"authorId\":\"7435343\",\"name\":\"Zhedong Zheng\"},{\"authorId\":\"144802394\",\"name\":\"L. Zheng\"},{\"authorId\":\"145908163\",\"name\":\"Michael Garrett\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"},{\"authorId\":\"1744468\",\"name\":\"Y. Shen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"40a943746d3a6156f9ca477e437263c7841118ac\",\"title\":\"Dual-Path Convolutional Image-Text Embedding\",\"url\":\"https://www.semanticscholar.org/paper/40a943746d3a6156f9ca477e437263c7841118ac\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1611.05088\",\"authors\":[{\"authorId\":\"50081790\",\"name\":\"L. Zhang\"},{\"authorId\":\"145406420\",\"name\":\"Tao Xiang\"},{\"authorId\":\"144784813\",\"name\":\"S. Gong\"}],\"doi\":\"10.1109/CVPR.2017.321\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c4f67bb310ef9b5dca6623d3aa890182d9e828e7\",\"title\":\"Learning a Deep Embedding Model for Zero-Shot Learning\",\"url\":\"https://www.semanticscholar.org/paper/c4f67bb310ef9b5dca6623d3aa890182d9e828e7\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1681842\",\"name\":\"Y. Liu\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"1808473\",\"name\":\"I. Wassell\"}],\"doi\":\"10.1007/978-3-030-01228-1_27\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"493a7272d8b04f4e06344f4b4058d2b99fc0ebef\",\"title\":\"Synthetically Supervised Feature Learning for Scene Text Recognition\",\"url\":\"https://www.semanticscholar.org/paper/493a7272d8b04f4e06344f4b4058d2b99fc0ebef\",\"venue\":\"ECCV\",\"year\":2018}],\"title\":\"Large-Scale Tag-Based Font Retrieval With Generative Feature Learning\",\"topics\":[{\"topic\":\"Feature learning\",\"topicId\":\"20551\",\"url\":\"https://www.semanticscholar.org/topic/20551\"},{\"topic\":\"Algorithm\",\"topicId\":\"305\",\"url\":\"https://www.semanticscholar.org/topic/305\"},{\"topic\":\"Synthetic data\",\"topicId\":\"16840\",\"url\":\"https://www.semanticscholar.org/topic/16840\"},{\"topic\":\"Nuisance variable\",\"topicId\":\"445123\",\"url\":\"https://www.semanticscholar.org/topic/445123\"}],\"url\":\"https://www.semanticscholar.org/paper/22d07f5eb536877aafbad9d790b56c51bb1c4a42\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019}\n"