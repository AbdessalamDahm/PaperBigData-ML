"{\"abstract\":\"We address the problem of grounding free-form textual phrases by using weak supervision from image-caption pairs. We propose a novel end-to-end model that uses caption-to-image retrieval as a downstream task to guide the process of phrase localization. Our method, as a first step, infers the latent correspondences between regions-of-interest (RoIs) and phrases in the caption and creates a discriminative image representation using these matched RoIs. In the subsequent step, this learned representation is aligned with the caption. Our key contribution lies in building this \\\"caption-conditioned\\\" image encoding, which tightly couples both the tasks and allows the weak supervision to effectively guide visual grounding. We provide extensive empirical and qualitative analysis to investigate the different components of our proposed model and compare it with competitive baselines. For phrase localization, we report an improvement of 4.9% and 1.3% (absolute) over the prior state-of-the-art on the VisualGenome and Flickr30k Entities datasets. We also report results that are at par with the state-of-the-art on the downstream caption-to-image retrieval task on COCO and Flickr30k datasets.\",\"arxivId\":\"1903.11649\",\"authors\":[{\"authorId\":\"19200118\",\"name\":\"Samyak Datta\",\"url\":\"https://www.semanticscholar.org/author/19200118\"},{\"authorId\":\"39707211\",\"name\":\"Karan Sikka\",\"url\":\"https://www.semanticscholar.org/author/39707211\"},{\"authorId\":\"145149308\",\"name\":\"A. Roy\",\"url\":\"https://www.semanticscholar.org/author/145149308\"},{\"authorId\":\"40480894\",\"name\":\"Karuna Ahuja\",\"url\":\"https://www.semanticscholar.org/author/40480894\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\",\"url\":\"https://www.semanticscholar.org/author/153432684\"},{\"authorId\":\"1696401\",\"name\":\"Ajay Divakaran\",\"url\":\"https://www.semanticscholar.org/author/1696401\"}],\"citationVelocity\":8,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"98531843\",\"name\":\"Tianyu Yu\"},{\"authorId\":\"151475424\",\"name\":\"Tianrui Hui\"},{\"authorId\":\"30972874\",\"name\":\"Z. Yu\"},{\"authorId\":\"47303356\",\"name\":\"Yue Liao\"},{\"authorId\":\"1977587202\",\"name\":\"Sansi Yu\"},{\"authorId\":\"1977074324\",\"name\":\"Faxi Zhang\"},{\"authorId\":\"153318526\",\"name\":\"Si Liu\"}],\"doi\":\"10.1145/3394171.3413846\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"136de72fdb9498b20fbb438afb6567aa03cfa6a1\",\"title\":\"Cross-Modal Omni Interaction Modeling for Phrase Grounding\",\"url\":\"https://www.semanticscholar.org/paper/136de72fdb9498b20fbb438afb6567aa03cfa6a1\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1905.07075\",\"authors\":[{\"authorId\":\"39707211\",\"name\":\"Karan Sikka\"},{\"authorId\":\"123813779\",\"name\":\"Lucas Van Bramer\"},{\"authorId\":\"1696401\",\"name\":\"Ajay Divakaran\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"418003534843f0fdda7dfb1d41c35bef683b1dad\",\"title\":\"Deep Unified Multimodal Embeddings for Understanding both Content and Users in Social Media Networks\",\"url\":\"https://www.semanticscholar.org/paper/418003534843f0fdda7dfb1d41c35bef683b1dad\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2009.06066\",\"authors\":[{\"authorId\":\"24661938\",\"name\":\"N. Rufus\"},{\"authorId\":\"30900327\",\"name\":\"U. Nair\"},{\"authorId\":\"145211574\",\"name\":\"K. Krishna\"},{\"authorId\":\"145091336\",\"name\":\"V. Gandhi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f6887b5680d0041f3bea85bb85a2d9f77dd41067\",\"title\":\"Cosine meets Softmax: A tough-to-beat baseline for visual grounding\",\"url\":\"https://www.semanticscholar.org/paper/f6887b5680d0041f3bea85bb85a2d9f77dd41067\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"79647482\",\"name\":\"Letitia Parcalabescu\"},{\"authorId\":\"143876555\",\"name\":\"A. Frank\"}],\"doi\":\"10.1109/CVPRW50498.2020.00489\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c18dcb2b99cb50ff8dc485fee41cd3c39a5e2089\",\"title\":\"Exploring Phrase Grounding without Training: Contextualisation and Extension to Text-Based Image Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/c18dcb2b99cb50ff8dc485fee41cd3c39a5e2089\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"1904.07826\",\"authors\":[{\"authorId\":\"2689239\",\"name\":\"Jack Hessel\"},{\"authorId\":\"145810617\",\"name\":\"Lillian Lee\"},{\"authorId\":\"38917723\",\"name\":\"D. Mimno\"}],\"doi\":\"10.18653/v1/D19-1210\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"76d97b53c661bfca4fe8f4ce253c13a45645a44b\",\"title\":\"Unsupervised Discovery of Multimodal Links in Multi-Image, Multi-Sentence Documents\",\"url\":\"https://www.semanticscholar.org/paper/76d97b53c661bfca4fe8f4ce253c13a45645a44b\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49785011\",\"name\":\"L. Yuan\"},{\"authorId\":\"1556928554\",\"name\":\"Violet Xiang\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"},{\"authorId\":\"2836466\",\"name\":\"L. Smith\"}],\"doi\":\"10.1016/j.cognition.2020.104243\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ec60e7735a7206dd26ab6484301c082bbeba6a27\",\"title\":\"Learning the generative principles of a symbol system from limited examples\",\"url\":\"https://www.semanticscholar.org/paper/ec60e7735a7206dd26ab6484301c082bbeba6a27\",\"venue\":\"Cognition\",\"year\":2020},{\"arxivId\":\"2011.10678\",\"authors\":[{\"authorId\":\"2778637\",\"name\":\"Alireza Zareian\"},{\"authorId\":\"2722334\",\"name\":\"Kevin Dela Rosa\"},{\"authorId\":\"1811433\",\"name\":\"D. Hu\"},{\"authorId\":\"72197815\",\"name\":\"Shih-Fu Chang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"497d765b1eccbc9e99a37592a1860744559695db\",\"title\":\"Open-Vocabulary Object Detection Using Captions\",\"url\":\"https://www.semanticscholar.org/paper/497d765b1eccbc9e99a37592a1860744559695db\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.09920\",\"authors\":[{\"authorId\":\"1911972\",\"name\":\"Tanmay Gupta\"},{\"authorId\":\"3214848\",\"name\":\"Arash Vahdat\"},{\"authorId\":\"1732280\",\"name\":\"Gal Chechik\"},{\"authorId\":\"47008546\",\"name\":\"Xiaodong Yang\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"},{\"authorId\":\"2433269\",\"name\":\"Derek Hoiem\"}],\"doi\":\"10.1007/978-3-030-58580-8_44\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"14e6c84fd88badeaa969c27d4cdada764877afff\",\"title\":\"Contrastive Learning for Weakly Supervised Phrase Grounding\",\"url\":\"https://www.semanticscholar.org/paper/14e6c84fd88badeaa969c27d4cdada764877afff\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2004.00390\",\"authors\":[{\"authorId\":\"51288875\",\"name\":\"Y. Zhou\"},{\"authorId\":\"5332711\",\"name\":\"Meng Wang\"},{\"authorId\":\"48929163\",\"name\":\"Daqing Liu\"},{\"authorId\":\"49941674\",\"name\":\"Zhenzhen Hu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"}],\"doi\":\"10.1109/cvpr42600.2020.00483\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c936e70cc1de52c5ad0ed5ec7a219bd25a46902c\",\"title\":\"More Grounded Image Captioning by Distilling Image-Text Matching Model\",\"url\":\"https://www.semanticscholar.org/paper/c936e70cc1de52c5ad0ed5ec7a219bd25a46902c\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2008.05231\",\"authors\":[{\"authorId\":\"67213349\",\"name\":\"N. Messina\"},{\"authorId\":\"144514869\",\"name\":\"G. Amato\"},{\"authorId\":\"1699411\",\"name\":\"Andrea Esuli\"},{\"authorId\":\"1846129\",\"name\":\"F. Falchi\"},{\"authorId\":\"2209975\",\"name\":\"C. Gennaro\"},{\"authorId\":\"1405499517\",\"name\":\"St\\u00e9phane Marchand-Maillet\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"52011033fb859c38bbcc82c311667feb38994ae3\",\"title\":\"Fine-grained Visual Textual Alignment for Cross-Modal Retrieval using Transformer Encoders\",\"url\":\"https://www.semanticscholar.org/paper/52011033fb859c38bbcc82c311667feb38994ae3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.06597\",\"authors\":[{\"authorId\":\"47773127\",\"name\":\"S. Yuan\"},{\"authorId\":\"1423652601\",\"name\":\"Ke Bai\"},{\"authorId\":\"50811121\",\"name\":\"Liqun Chen\"},{\"authorId\":\"48378494\",\"name\":\"Yizhe Zhang\"},{\"authorId\":\"46387857\",\"name\":\"Chenyang Tao\"},{\"authorId\":\"1978606\",\"name\":\"C. Li\"},{\"authorId\":\"1807489212\",\"name\":\"Guoyin Wang\"},{\"authorId\":\"51030446\",\"name\":\"R. Henao\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1af06d2c4a129f9335159db8bb1455414705bed1\",\"title\":\"Weakly supervised cross-domain alignment with optimal transport\",\"url\":\"https://www.semanticscholar.org/paper/1af06d2c4a129f9335159db8bb1455414705bed1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48251796\",\"name\":\"Chenyun Wu\"},{\"authorId\":\"145527698\",\"name\":\"Zhe Lin\"},{\"authorId\":\"153500661\",\"name\":\"S. Cohen\"},{\"authorId\":\"145262461\",\"name\":\"Trung Bui\"},{\"authorId\":\"35208858\",\"name\":\"Subhransu Maji\"}],\"doi\":\"10.1109/CVPR42600.2020.01023\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a1ebc58f6c055eac8555d9850cb849a38c22c67d\",\"title\":\"PhraseCut: Language-Based Image Segmentation in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/a1ebc58f6c055eac8555d9850cb849a38c22c67d\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32562635\",\"name\":\"Liunian Harold Li\"},{\"authorId\":\"2064210\",\"name\":\"Mark Yatskar\"},{\"authorId\":\"144508458\",\"name\":\"Da Yin\"},{\"authorId\":\"1793529\",\"name\":\"C. Hsieh\"},{\"authorId\":\"101751639\",\"name\":\"Kai-Wei Chang\"}],\"doi\":\"10.18653/v1/2020.acl-main.469\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"cdcdc7ab1f5b6e86146b5c0224cba7d8cd35142c\",\"title\":\"What Does BERT with Vision Look At?\",\"url\":\"https://www.semanticscholar.org/paper/cdcdc7ab1f5b6e86146b5c0224cba7d8cd35142c\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"2009.05695\",\"authors\":[{\"authorId\":\"47733442\",\"name\":\"Niluthpol Chowdhury Mithun\"},{\"authorId\":\"39707211\",\"name\":\"Karan Sikka\"},{\"authorId\":\"35260743\",\"name\":\"Han-Pang Chiu\"},{\"authorId\":\"1789477\",\"name\":\"S. Samarasekera\"},{\"authorId\":\"1557362763\",\"name\":\"Rakesh Kumar\"}],\"doi\":\"10.1145/3394171.3413647\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"596fd6b55ca8e85b410e41360abd46f9f5373ee1\",\"title\":\"RGB2LIDAR: Towards Solving Large-Scale Cross-Modal Visual Localization\",\"url\":\"https://www.semanticscholar.org/paper/596fd6b55ca8e85b410e41360abd46f9f5373ee1\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1912.08830\",\"authors\":[{\"authorId\":\"73286206\",\"name\":\"Dave Zhenyu Chen\"},{\"authorId\":\"3317599\",\"name\":\"A. X. Chang\"},{\"authorId\":\"2209612\",\"name\":\"M. Nie\\u00dfner\"}],\"doi\":\"10.1007/978-3-030-58565-5_13\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"82b6033697e2a2a6018577bc3dac239b40a0a242\",\"title\":\"ScanRefer: 3D Object Localization in RGB-D Scans using Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/82b6033697e2a2a6018577bc3dac239b40a0a242\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2010.05379\",\"authors\":[{\"authorId\":\"27866536\",\"name\":\"Q. Wang\"},{\"authorId\":\"1725438390\",\"name\":\"H. Tan\"},{\"authorId\":\"2191455\",\"name\":\"Sheng Shen\"},{\"authorId\":\"1717098\",\"name\":\"M. W. Mahoney\"},{\"authorId\":\"9088433\",\"name\":\"Zhewei Yao\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.159\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f68429e4cb119d3ac6cfbc9be7476609878fd2fa\",\"title\":\"MAF: Multimodal Alignment Framework for Weakly-Supervised Phrase Grounding\",\"url\":\"https://www.semanticscholar.org/paper/f68429e4cb119d3ac6cfbc9be7476609878fd2fa\",\"venue\":\"EMNLP\",\"year\":2020}],\"corpusId\":85543204,\"doi\":\"10.1109/ICCV.2019.00269\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":1,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"a89cd9056c0fb037d659215b121686ff3b454fd5\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2015.7298932\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"title\":\"Deep visual-semantic alignments for generating image descriptions\",\"url\":\"https://www.semanticscholar.org/paper/ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"venue\":\"CVPR\",\"year\":2015},{\"arxivId\":\"1103.0398\",\"authors\":[{\"authorId\":\"2939803\",\"name\":\"Ronan Collobert\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"},{\"authorId\":\"52184096\",\"name\":\"L. Bottou\"},{\"authorId\":\"21432929\",\"name\":\"Michael Karlen\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"},{\"authorId\":\"46283650\",\"name\":\"P. Kuksa\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bc1022b031dc6c7019696492e8116598097a8c12\",\"title\":\"Natural Language Processing (Almost) from Scratch\",\"url\":\"https://www.semanticscholar.org/paper/bc1022b031dc6c7019696492e8116598097a8c12\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2011},{\"arxivId\":\"1705.01371\",\"authors\":[{\"authorId\":\"2299381\",\"name\":\"Fanyi Xiao\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"144756076\",\"name\":\"Y. Lee\"}],\"doi\":\"10.1109/CVPR.2017.558\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9405a9180139f23f4dd9d90aa4e86944b35b8c88\",\"title\":\"Weakly-Supervised Visual Grounding of Phrases with Linguistic Structures\",\"url\":\"https://www.semanticscholar.org/paper/9405a9180139f23f4dd9d90aa4e86944b35b8c88\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1505.05192\",\"authors\":[{\"authorId\":\"2786693\",\"name\":\"C. Doersch\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1109/ICCV.2015.167\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"fc1b1c9364c58ec406f494dd944b609a6a038ba6\",\"title\":\"Unsupervised Visual Representation Learning by Context Prediction\",\"url\":\"https://www.semanticscholar.org/paper/fc1b1c9364c58ec406f494dd944b609a6a038ba6\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1611.05588\",\"authors\":[{\"authorId\":\"49867037\",\"name\":\"Y. Huang\"},{\"authorId\":null,\"name\":\"Wei Wang\"},{\"authorId\":null,\"name\":\"Liang Wang\"}],\"doi\":\"10.1109/CVPR.2017.767\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e1b6735f6ecb09e1d83b0aa9d2cde42993ee2eb0\",\"title\":\"Instance-Aware Image and Sentence Matching with Selective Multimodal LSTM\",\"url\":\"https://www.semanticscholar.org/paper/e1b6735f6ecb09e1d83b0aa9d2cde42993ee2eb0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Peter Anderson\"},{\"authorId\":null,\"name\":\"Xiaodong He\"},{\"authorId\":null,\"name\":\"Chris Buehler\"},{\"authorId\":null,\"name\":\"Damien Teney\"},{\"authorId\":null,\"name\":\"Mark Johnson\"},{\"authorId\":null,\"name\":\"Stephen Gould\"},{\"authorId\":null,\"name\":\"Lei Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Bottomup and top-down attention for image captioning and visual question answering\",\"url\":\"\",\"venue\":\"In Conference on Computer Vision and Pattern Recognition,\",\"year\":2018},{\"arxivId\":\"1608.07973\",\"authors\":[{\"authorId\":\"3451681\",\"name\":\"Aviv Eisenschtat\"},{\"authorId\":\"145128145\",\"name\":\"Lior Wolf\"}],\"doi\":\"10.1109/CVPR.2017.201\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2616e0fbce43362a338acedcbb5cd80db7bbb7e5\",\"title\":\"Linking Image and Text with 2-Way Nets\",\"url\":\"https://www.semanticscholar.org/paper/2616e0fbce43362a338acedcbb5cd80db7bbb7e5\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1803.03879\",\"authors\":[{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"3029956\",\"name\":\"J. Gao\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/CVPR.2018.00425\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0f66f124bcfa4c3d9d0e54af0c1103f1219c1c8c\",\"title\":\"Knowledge Aided Consistency for Weakly Supervised Phrase Grounding\",\"url\":\"https://www.semanticscholar.org/paper/0f66f124bcfa4c3d9d0e54af0c1103f1219c1c8c\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1511.03745\",\"authors\":[{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1007/978-3-319-46448-0_49\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"14c2321851fb5ae580a19726dd2753a525d6ad76\",\"title\":\"Grounding of Textual Phrases in Images by Reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/14c2321851fb5ae580a19726dd2753a525d6ad76\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1804.04340\",\"authors\":[{\"authorId\":\"2068427\",\"name\":\"Ankan Bansal\"},{\"authorId\":\"39707211\",\"name\":\"Karan Sikka\"},{\"authorId\":\"144054467\",\"name\":\"G. Sharma\"},{\"authorId\":\"9215658\",\"name\":\"R. Chellappa\"},{\"authorId\":\"1696401\",\"name\":\"Ajay Divakaran\"}],\"doi\":\"10.1007/978-3-030-01246-5_24\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"32bc9334ad0edaec29540320b9f00c9a7aab81f8\",\"title\":\"Zero-Shot Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/32bc9334ad0edaec29540320b9f00c9a7aab81f8\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Andrea Frome\"},{\"authorId\":null,\"name\":\"Greg S Corrado\"},{\"authorId\":null,\"name\":\"Jon Shlens\"},{\"authorId\":null,\"name\":\"Samy Bengio\"},{\"authorId\":null,\"name\":\"Jeff Dean\"},{\"authorId\":null,\"name\":\"Tomas Mikolov\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Devise: A deep visualsemantic embedding model\",\"url\":\"\",\"venue\":\"In Neural Information Processing Systems,\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144030870\",\"name\":\"Jieping Ye\"},{\"authorId\":\"144093726\",\"name\":\"Zheng Zhao\"},{\"authorId\":\"38746648\",\"name\":\"Huan Liu\"}],\"doi\":\"10.1109/CVPR.2007.383103\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"50ce3f8744c219871fbdcab1342d49d589f2626b\",\"title\":\"Adaptive Distance Metric Learning for Clustering\",\"url\":\"https://www.semanticscholar.org/paper/50ce3f8744c219871fbdcab1342d49d589f2626b\",\"venue\":\"2007 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2007},{\"arxivId\":\"1502.02367\",\"authors\":[{\"authorId\":\"8270717\",\"name\":\"J. Chung\"},{\"authorId\":\"1854385\",\"name\":\"\\u00c7aglar G\\u00fcl\\u00e7ehre\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d14c7e5f5cace4c925abc74c88baa474e9f31a28\",\"title\":\"Gated Feedback Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/d14c7e5f5cace4c925abc74c88baa474e9f31a28\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1803.08024\",\"authors\":[{\"authorId\":\"1863953\",\"name\":\"Kuang-Huei Lee\"},{\"authorId\":\"1683647\",\"name\":\"X. Chen\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\"},{\"authorId\":\"35431603\",\"name\":\"H. Hu\"},{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"}],\"doi\":\"10.1007/978-3-030-01225-0_13\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"45dd2a3cd7c27f2e9509b023d702408f5ac11c9d\",\"title\":\"Stacked Cross Attention for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/45dd2a3cd7c27f2e9509b023d702408f5ac11c9d\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1704.03470\",\"authors\":[{\"authorId\":\"145602574\",\"name\":\"L. Wang\"},{\"authorId\":\"48513361\",\"name\":\"Y. Li\"},{\"authorId\":\"19353632\",\"name\":\"J. Huang\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1109/TPAMI.2018.2797921\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f865268b81eeb29d94775f22c6bc24dcc5e1b2e9\",\"title\":\"Learning Two-Branch Neural Networks for Image-Text Matching Tasks\",\"url\":\"https://www.semanticscholar.org/paper/f865268b81eeb29d94775f22c6bc24dcc5e1b2e9\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":\"1603.05027\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1007/978-3-319-46493-0_38\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"77f0a39b8e02686fd85b01971f8feb7f60971f80\",\"title\":\"Identity Mappings in Deep Residual Networks\",\"url\":\"https://www.semanticscholar.org/paper/77f0a39b8e02686fd85b01971f8feb7f60971f80\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2518212\",\"name\":\"Hakan Bilen\"},{\"authorId\":\"3048367\",\"name\":\"M. Pedersoli\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e533c6488b42b099f320a9921ba26dcde7e97e4f\",\"title\":\"Weakly Supervised Object Detection with Posterior Regularization\",\"url\":\"https://www.semanticscholar.org/paper/e533c6488b42b099f320a9921ba26dcde7e97e4f\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2279670\",\"name\":\"Andrea Frome\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"1789737\",\"name\":\"Jonathon Shlens\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"},{\"authorId\":\"1706809\",\"name\":\"Marc'Aurelio Ranzato\"},{\"authorId\":null,\"name\":\"Tomas Mikolov\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4aa4069693bee00d1b0759ca3df35e59284e9845\",\"title\":\"DeViSE: A Deep Visual-Semantic Embedding Model\",\"url\":\"https://www.semanticscholar.org/paper/4aa4069693bee00d1b0759ca3df35e59284e9845\",\"venue\":\"NIPS\",\"year\":2013},{\"arxivId\":\"1805.10547\",\"authors\":[{\"authorId\":\"3149518\",\"name\":\"Volkan Cirik\"},{\"authorId\":\"1400419309\",\"name\":\"Taylor Berg-Kirkpatrick\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b658b8a9fbe1d35cdf1942e5c1bdc546a4c39029\",\"title\":\"Using Syntax to Ground Referring Expressions in Natural Images\",\"url\":\"https://www.semanticscholar.org/paper/b658b8a9fbe1d35cdf1942e5c1bdc546a4c39029\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1412.6632\",\"authors\":[{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"40579682\",\"name\":\"J. Wang\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745\",\"title\":\"Deep Captioning with Multimodal Recurrent Neural Networks (m-RNN)\",\"url\":\"https://www.semanticscholar.org/paper/54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1503.00949\",\"authors\":[{\"authorId\":\"1939006\",\"name\":\"Ramazan Gokberk Cinbis\"},{\"authorId\":\"34602236\",\"name\":\"Jakob Verbeek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/TPAMI.2016.2535231\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"05e71b05ed2c4766ed4a080cb0411be7291b717b\",\"title\":\"Weakly Supervised Object Localization with Multi-Fold Multiple Instance Learning\",\"url\":\"https://www.semanticscholar.org/paper/05e71b05ed2c4766ed4a080cb0411be7291b717b\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Kaiming He\"},{\"authorId\":null,\"name\":\"Georgia Gkioxari\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Piotr Doll\\u00e1r, and Ross Girshick. Mask r-cnn\",\"url\":\"\",\"venue\":\"International Conference on Computer Vision\",\"year\":2017},{\"arxivId\":\"1504.06063\",\"authors\":[{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"11955007\",\"name\":\"Z. Lu\"},{\"authorId\":\"50812138\",\"name\":\"L. Shang\"},{\"authorId\":\"49404233\",\"name\":\"Hang Li\"}],\"doi\":\"10.1109/ICCV.2015.301\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"153d6feb7149e063b33e8ee437b74e4a2def8057\",\"title\":\"Multimodal Convolutional Neural Networks for Matching Image and Sentence\",\"url\":\"https://www.semanticscholar.org/paper/153d6feb7149e063b33e8ee437b74e4a2def8057\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2978170\",\"name\":\"Fartash Faghri\"},{\"authorId\":\"1793739\",\"name\":\"David J. Fleet\"},{\"authorId\":\"51131802\",\"name\":\"J. Kiros\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f7ab6c52be9351ac3f6cf8fe6ad5efba1c1595e8\",\"title\":\"VSE++: Improving Visual-Semantic Embeddings with Hard Negatives\",\"url\":\"https://www.semanticscholar.org/paper/f7ab6c52be9351ac3f6cf8fe6ad5efba1c1595e8\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":\"1707.07998\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"31790073\",\"name\":\"C. Buehler\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":\"10.1109/CVPR.2018.00636\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"title\":\"Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1806773\",\"name\":\"I. Misra\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1007/978-3-319-46448-0_32\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"6d4e3616d0b27957c4107ae877dc0dd4504b69ab\",\"title\":\"Shuffle and Learn: Unsupervised Learning Using Temporal Order Verification\",\"url\":\"https://www.semanticscholar.org/paper/6d4e3616d0b27957c4107ae877dc0dd4504b69ab\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"145297531\",\"name\":\"A. Lai\"},{\"authorId\":\"2170746\",\"name\":\"M. Hodosh\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"}],\"doi\":\"10.1162/tacl_a_00166\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"44040913380206991b1991daf1192942e038fe31\",\"title\":\"From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions\",\"url\":\"https://www.semanticscholar.org/paper/44040913380206991b1991daf1192942e038fe31\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2014},{\"arxivId\":\"1811.11683\",\"authors\":[{\"authorId\":\"145559125\",\"name\":\"H. Akbari\"},{\"authorId\":\"35862299\",\"name\":\"S. Karaman\"},{\"authorId\":\"1754397\",\"name\":\"Surabhi Bhargava\"},{\"authorId\":\"143852868\",\"name\":\"B. Chen\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1109/CVPR.2019.01276\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b4702bad26563a4e1d03b33c0af0b29b095438bc\",\"title\":\"Multi-Level Multimodal Common Semantic Space for Image-Phrase Grounding\",\"url\":\"https://www.semanticscholar.org/paper/b4702bad26563a4e1d03b33c0af0b29b095438bc\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1804.01720\",\"authors\":[{\"authorId\":\"35376394\",\"name\":\"Martin Engilberge\"},{\"authorId\":\"39255836\",\"name\":\"Louis Chevallier\"},{\"authorId\":\"144565371\",\"name\":\"P. P\\u00e9rez\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"}],\"doi\":\"10.1109/CVPR.2018.00419\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9645e8b4829c04879a642d8dd6b3cdf5cf264afb\",\"title\":\"Finding Beans in Burgers: Deep Semantic-Visual Embedding with Localization\",\"url\":\"https://www.semanticscholar.org/paper/9645e8b4829c04879a642d8dd6b3cdf5cf264afb\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1612.00593\",\"authors\":[{\"authorId\":\"144329939\",\"name\":\"C. R. Qi\"},{\"authorId\":\"144914140\",\"name\":\"H. Su\"},{\"authorId\":\"2216377\",\"name\":\"Kaichun Mo\"},{\"authorId\":\"1744254\",\"name\":\"L. Guibas\"}],\"doi\":\"10.1109/CVPR.2017.16\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d997beefc0922d97202789d2ac307c55c2c52fba\",\"title\":\"PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/d997beefc0922d97202789d2ac307c55c2c52fba\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1602.07332\",\"authors\":[{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"50499889\",\"name\":\"O. Groth\"},{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"1382195702\",\"name\":\"Kenji Hata\"},{\"authorId\":\"40591424\",\"name\":\"J. Kravitz\"},{\"authorId\":\"6000646\",\"name\":\"Stephanie Chen\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"1388344504\",\"name\":\"David A. Shamma\"},{\"authorId\":\"1379506718\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-016-0981-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"title\":\"Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations\",\"url\":\"https://www.semanticscholar.org/paper/afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":\"1703.06870\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2082991\",\"name\":\"Georgia Gkioxari\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/ICCV.2017.322\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ea99a5535388196d0d44be5b4d7dd02029a43bb2\",\"title\":\"Mask R-CNN\",\"url\":\"https://www.semanticscholar.org/paper/ea99a5535388196d0d44be5b4d7dd02029a43bb2\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1807.01448\",\"authors\":[{\"authorId\":\"40480894\",\"name\":\"Karuna Ahuja\"},{\"authorId\":\"39707211\",\"name\":\"Karan Sikka\"},{\"authorId\":\"145149308\",\"name\":\"A. Roy\"},{\"authorId\":\"1696401\",\"name\":\"Ajay Divakaran\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ce407c2899ac955fa67dc7f6ba3a7f07ecd18855\",\"title\":\"Understanding Visual Ads by Aligning Symbols and Objects using Co-Attention\",\"url\":\"https://www.semanticscholar.org/paper/ce407c2899ac955fa67dc7f6ba3a7f07ecd18855\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1511.03416\",\"authors\":[{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"50499889\",\"name\":\"O. Groth\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2016.540\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"def584565d05d6a8ba94de6621adab9e301d375d\",\"title\":\"Visual7W: Grounded Question Answering in Images\",\"url\":\"https://www.semanticscholar.org/paper/def584565d05d6a8ba94de6621adab9e301d375d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1706.08502\",\"authors\":[{\"authorId\":\"2150275\",\"name\":\"S. Kottur\"},{\"authorId\":\"144915495\",\"name\":\"Jos\\u00e9 M. F. Moura\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.18653/v1/D17-1321\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"2caa021d85d4878d3369000e0068f617576d6cca\",\"title\":\"Natural Language Does Not Emerge 'Naturally' in Multi-Agent Dialog\",\"url\":\"https://www.semanticscholar.org/paper/2caa021d85d4878d3369000e0068f617576d6cca\",\"venue\":\"EMNLP\",\"year\":2017},{\"arxivId\":\"1506.01497\",\"authors\":[{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"144716314\",\"name\":\"J. Sun\"}],\"doi\":\"10.1109/TPAMI.2016.2577031\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"title\":\"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\",\"url\":\"https://www.semanticscholar.org/paper/424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1701293\",\"name\":\"J. Zhang\"},{\"authorId\":\"145527707\",\"name\":\"Zhe L. Lin\"},{\"authorId\":\"145561604\",\"name\":\"Jonathan Brandt\"},{\"authorId\":\"1720987\",\"name\":\"X. Shen\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"}],\"doi\":\"10.1007/978-3-319-46493-0_33\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"26d43ae0e7a8d523d48d2fe8a9e1b6e308913cf5\",\"title\":\"Top-Down Neural Attention by Excitation Backprop\",\"url\":\"https://www.semanticscholar.org/paper/26d43ae0e7a8d523d48d2fe8a9e1b6e308913cf5\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1511.02283\",\"authors\":[{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"1808244\",\"name\":\"J. Huang\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"3317152\",\"name\":\"Oana-Maria Camburu\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":\"10.1109/CVPR.2016.9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e65142010431ffc089b272a1174214e00693e503\",\"title\":\"Generation and Comprehension of Unambiguous Object Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/e65142010431ffc089b272a1174214e00693e503\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144329939\",\"name\":\"C. R. Qi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8d62db434a5fec66c85153a8109509ff786dd29a\",\"title\":\"Deep Learning on Point Sets for 3 D Classification and Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/8d62db434a5fec66c85153a8109509ff786dd29a\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34346779\",\"name\":\"Weixin Li\"},{\"authorId\":\"1699559\",\"name\":\"N. Vasconcelos\"}],\"doi\":\"10.1109/CVPR.2015.7299056\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"2cf5ff18580c6073e555cf34793d71a63b40d406\",\"title\":\"Multiple instance learning for soft bags via top instances\",\"url\":\"https://www.semanticscholar.org/paper/2cf5ff18580c6073e555cf34793d71a63b40d406\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1411.2539\",\"authors\":[{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2e36ea91a3c8fbff92be2989325531b4002e2afc\",\"title\":\"Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models\",\"url\":\"https://www.semanticscholar.org/paper/2e36ea91a3c8fbff92be2989325531b4002e2afc\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":\"1505.04870\",\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2133220\",\"name\":\"C. Cervantes\"},{\"authorId\":\"145507543\",\"name\":\"Juan C. Caicedo\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1007/s11263-016-0965-7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0612745dbd292fc0a548a16d39cd73e127faedde\",\"title\":\"Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models\",\"url\":\"https://www.semanticscholar.org/paper/0612745dbd292fc0a548a16d39cd73e127faedde\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1611.00471\",\"authors\":[{\"authorId\":\"34758272\",\"name\":\"H. Nam\"},{\"authorId\":\"2577039\",\"name\":\"Jung-Woo Ha\"},{\"authorId\":\"2947441\",\"name\":\"J. Kim\"}],\"doi\":\"10.1109/CVPR.2017.232\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f651593fa6c83d717fc961482696a53b6fca5ab5\",\"title\":\"Dual Attention Networks for Multimodal Reasoning and Matching\",\"url\":\"https://www.semanticscholar.org/paper/f651593fa6c83d717fc961482696a53b6fca5ab5\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Manzil Zaheer\"},{\"authorId\":null,\"name\":\"Satwik Kottur Ruslan\"},{\"authorId\":null,\"name\":\"R Salakhutdinov\"},{\"authorId\":null,\"name\":\"Alexander J Smola\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Siamak Ravanbakhsh, Barnabas Poczos\",\"url\":\"\",\"venue\":\"Neural Information Processing Systems\",\"year\":2017},{\"arxivId\":\"1411.4952\",\"authors\":[{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3346186\",\"name\":\"Forrest N. Iandola\"},{\"authorId\":\"2100612\",\"name\":\"R. Srivastava\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"144189092\",\"name\":\"John C. Platt\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"}],\"doi\":\"10.1109/CVPR.2015.7298754\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"title\":\"From captions to visual concepts and back\",\"url\":\"https://www.semanticscholar.org/paper/15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1707.05612\",\"authors\":[{\"authorId\":\"2978170\",\"name\":\"Fartash Faghri\"},{\"authorId\":\"1793739\",\"name\":\"David J. Fleet\"},{\"authorId\":\"51131802\",\"name\":\"J. Kiros\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"faa093a53b83f0e9c35a0bfbcacee0a16f8eb6d1\",\"title\":\"VSE++: Improved Visual-Semantic Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/faa093a53b83f0e9c35a0bfbcacee0a16f8eb6d1\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1703.06114\",\"authors\":[{\"authorId\":\"1771307\",\"name\":\"M. Zaheer\"},{\"authorId\":\"2150275\",\"name\":\"S. Kottur\"},{\"authorId\":\"2111187\",\"name\":\"Siamak Ravanbakhsh\"},{\"authorId\":\"1719347\",\"name\":\"B. P\\u00f3czos\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"46234526\",\"name\":\"Alex Smola\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a456265138c088a894301c0433dae938705a9bec\",\"title\":\"Deep Sets\",\"url\":\"https://www.semanticscholar.org/paper/a456265138c088a894301c0433dae938705a9bec\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5886094\",\"name\":\"P. Cochat\"},{\"authorId\":\"13267685\",\"name\":\"L. Vaucoret\"},{\"authorId\":\"31455512\",\"name\":\"J. Sarles\"}],\"doi\":\"10.1016/j.arcped.2012.01.013\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"10d85561e4aafc516d10064f30dff05b41f70afe\",\"title\":\"[Et al].\",\"url\":\"https://www.semanticscholar.org/paper/10d85561e4aafc516d10064f30dff05b41f70afe\",\"venue\":\"Archives de pediatrie : organe officiel de la Societe francaise de pediatrie\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1786361\",\"name\":\"Zhenxing Niu\"},{\"authorId\":\"144426057\",\"name\":\"M. Zhou\"},{\"authorId\":\"9173291\",\"name\":\"L. Wang\"},{\"authorId\":\"10699750\",\"name\":\"X. Gao\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\"}],\"doi\":\"10.1109/ICCV.2017.208\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ad5dc94b28bee087a34f52114c52bd09d2acd8cb\",\"title\":\"Hierarchical Multimodal LSTM for Dense Visual-Semantic Embedding\",\"url\":\"https://www.semanticscholar.org/paper/ad5dc94b28bee087a34f52114c52bd09d2acd8cb\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1511.06361\",\"authors\":[{\"authorId\":\"2210865\",\"name\":\"Ivan Vendrov\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"46b8cbcdff87b842c2c1d4a003c831f845096ba7\",\"title\":\"Order-Embeddings of Images and Language\",\"url\":\"https://www.semanticscholar.org/paper/46b8cbcdff87b842c2c1d4a003c831f845096ba7\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":\"1406.5679\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2319608\",\"name\":\"Armand Joulin\"},{\"authorId\":\"153196308\",\"name\":\"F. Li\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7f1b111f0bb703b0bd97aba505728a9b0d9b2a54\",\"title\":\"Deep Fragment Embeddings for Bidirectional Image Sentence Mapping\",\"url\":\"https://www.semanticscholar.org/paper/7f1b111f0bb703b0bd97aba505728a9b0d9b2a54\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Charles R Qi\"},{\"authorId\":null,\"name\":\"Hao Su\"},{\"authorId\":null,\"name\":\"Kaichun Mo\"},{\"authorId\":null,\"name\":\"Leonidas J Guibas\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Juan C Caicedo , Julia Hockenmaier , and Svetlana Lazebnik . Flickr 30 k entities : Collecting region - to - phrase correspondences for richer image - to - sentence models\",\"url\":\"\",\"venue\":\"\",\"year\":null}],\"title\":\"Align2Ground: Weakly Supervised Phrase Grounding Guided by Image-Caption Alignment\",\"topics\":[{\"topic\":\"Caption\",\"topicId\":\"785579\",\"url\":\"https://www.semanticscholar.org/topic/785579\"},{\"topic\":\"Image retrieval\",\"topicId\":\"21846\",\"url\":\"https://www.semanticscholar.org/topic/21846\"},{\"topic\":\"Downstream (software development)\",\"topicId\":\"10055\",\"url\":\"https://www.semanticscholar.org/topic/10055\"},{\"topic\":\"Phrases\",\"topicId\":\"14658\",\"url\":\"https://www.semanticscholar.org/topic/14658\"},{\"topic\":\"End-to-end principle\",\"topicId\":\"299633\",\"url\":\"https://www.semanticscholar.org/topic/299633\"},{\"topic\":\"Condition number\",\"topicId\":\"5434\",\"url\":\"https://www.semanticscholar.org/topic/5434\"},{\"topic\":\"Alignment\",\"topicId\":\"80376\",\"url\":\"https://www.semanticscholar.org/topic/80376\"},{\"topic\":\"Silo (dataset)\",\"topicId\":\"130506\",\"url\":\"https://www.semanticscholar.org/topic/130506\"}],\"url\":\"https://www.semanticscholar.org/paper/a89cd9056c0fb037d659215b121686ff3b454fd5\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019}\n"