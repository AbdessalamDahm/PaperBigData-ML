"{\"abstract\":\"Multi-modality perception is essential to develop interactive intelligence. In this work, we consider a new task of visual information-infused audio inpainting, i.e., synthesizing missing audio segments that correspond to their accompanying videos. We identify two key aspects for a successful inpainter: (1) It is desirable to operate on spectrograms instead of raw audios. Recent advances in deep semantic image inpainting could be leveraged to go beyond the limitations of traditional audio inpainting. (2) To synthesize visually indicated audio, a visual-audio joint feature space needs to be learned with synchronization of audio and video. To facilitate a large-scale study, we collect a new multi-modality instrument-playing dataset called MUSIC-Extra-Solo (MUSICES) by enriching MUSIC dataset. Extensive experiments demonstrate that our framework is capable of inpainting realistic and varying audio segments with or without visual contexts. More importantly, our synthesized audio segments are coherent with their video counterparts, showing the effectiveness of our proposed Vision-Infused Audio Inpainter (VIAI).\",\"arxivId\":\"1910.10997\",\"authors\":[{\"authorId\":\"145798292\",\"name\":\"Hang Zhou\",\"url\":\"https://www.semanticscholar.org/author/145798292\"},{\"authorId\":\"3243969\",\"name\":\"Z. Liu\",\"url\":\"https://www.semanticscholar.org/author/3243969\"},{\"authorId\":\"50487517\",\"name\":\"Xudong Xu\",\"url\":\"https://www.semanticscholar.org/author/50487517\"},{\"authorId\":\"47571885\",\"name\":\"Ping Luo\",\"url\":\"https://www.semanticscholar.org/author/47571885\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\",\"url\":\"https://www.semanticscholar.org/author/48631549\"}],\"citationVelocity\":6,\"citations\":[{\"arxivId\":\"2003.08124\",\"authors\":[{\"authorId\":\"145798292\",\"name\":\"Hang Zhou\"},{\"authorId\":\"2337079\",\"name\":\"Jihao Liu\"},{\"authorId\":\"3243969\",\"name\":\"Z. Liu\"},{\"authorId\":\"119924269\",\"name\":\"Y. Liu\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"}],\"doi\":\"10.1109/cvpr42600.2020.00595\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5e868741bc96920a7eddb2f2bed3cc22f9c2fffc\",\"title\":\"Rotate-and-Render: Unsupervised Photorealistic Face Rotation From Single-View Images\",\"url\":\"https://www.semanticscholar.org/paper/5e868741bc96920a7eddb2f2bed3cc22f9c2fffc\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2005.08209\",\"authors\":[{\"authorId\":\"1380234931\",\"name\":\"K. Prajwal\"},{\"authorId\":\"41052499\",\"name\":\"R. Mukhopadhyay\"},{\"authorId\":\"1744135\",\"name\":\"Vinay Namboodiri\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"}],\"doi\":\"10.1109/cvpr42600.2020.01381\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ba684a9966995e5a8c6efef46aeb57bd387ff51f\",\"title\":\"Learning Individual Speaking Styles for Accurate Lip to Speech Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/ba684a9966995e5a8c6efef46aeb57bd387ff51f\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2008.03546\",\"authors\":[{\"authorId\":\"1657277123\",\"name\":\"J. Xia\"},{\"authorId\":\"36290866\",\"name\":\"Anyi Rao\"},{\"authorId\":\"39360892\",\"name\":\"Q. Huang\"},{\"authorId\":\"150196512\",\"name\":\"Linning Xu\"},{\"authorId\":\"49320456\",\"name\":\"Jiangtao Wen\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1007/978-3-030-58610-2_11\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e71db960a43bf26d9de3515652f04579952ab6ff\",\"title\":\"Online Multi-modal Person Search in Videos\",\"url\":\"https://www.semanticscholar.org/paper/e71db960a43bf26d9de3515652f04579952ab6ff\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.12130\",\"authors\":[{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"2479187\",\"name\":\"Moitreya Chatterjee\"},{\"authorId\":\"145237406\",\"name\":\"N. Ahuja\"}],\"doi\":\"10.1007/978-3-030-58583-9_42\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"02f3ced09497c5db59985b2a5db9d3d0aebe5074\",\"title\":\"Sound2Sight: Generating Visual Dynamics from Sound and Context\",\"url\":\"https://www.semanticscholar.org/paper/02f3ced09497c5db59985b2a5db9d3d0aebe5074\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1912.04487\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":\"10.1109/cvpr42600.2020.01047\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c4128ba8deeb67e731cf52fb98addcfddd487e55\",\"title\":\"Listen to Look: Action Recognition by Previewing Audio\",\"url\":\"https://www.semanticscholar.org/paper/c4128ba8deeb67e731cf52fb98addcfddd487e55\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2007.09902\",\"authors\":[{\"authorId\":\"145798292\",\"name\":\"Hang Zhou\"},{\"authorId\":\"48670507\",\"name\":\"Xudong Xu\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"},{\"authorId\":\"3243969\",\"name\":\"Z. Liu\"}],\"doi\":\"10.1007/978-3-030-58610-2_4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"73aa926dad010a3f1bb89faa31241f97a89cc461\",\"title\":\"Sep-Stereo: Visually Guided Stereophonic Audio Generation by Associating Source Separation\",\"url\":\"https://www.semanticscholar.org/paper/73aa926dad010a3f1bb89faa31241f97a89cc461\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.10984\",\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"145592817\",\"name\":\"D. Huang\"},{\"authorId\":\"4965440\",\"name\":\"Peihao Chen\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1007/978-3-030-58621-8_44\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"43971a0a2593f660427e016032b983b52f8dd8eb\",\"title\":\"Foley Music: Learning to Generate Music from Videos\",\"url\":\"https://www.semanticscholar.org/paper/43971a0a2593f660427e016032b983b52f8dd8eb\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2006.07931\",\"authors\":[{\"authorId\":\"134192555\",\"name\":\"J. F. Montesinos\"},{\"authorId\":\"9936815\",\"name\":\"Olga Slizovskaia\"},{\"authorId\":\"1916387\",\"name\":\"G. Haro\"}],\"doi\":\"10.1109/MMSP48831.2020.9287124\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5b36193e42615bf1ec6202f22be6bfc5ed86d444\",\"title\":\"Solos: A Dataset for Audio-Visual Music Analysis\",\"url\":\"https://www.semanticscholar.org/paper/5b36193e42615bf1ec6202f22be6bfc5ed86d444\",\"venue\":\"2020 IEEE 22nd International Workshop on Multimedia Signal Processing (MMSP)\",\"year\":2020},{\"arxivId\":\"2005.05032\",\"authors\":[{\"authorId\":\"51941517\",\"name\":\"Andr\\u00e9s Marafioti\"},{\"authorId\":\"2005106\",\"name\":\"P. Majdak\"},{\"authorId\":\"2617861\",\"name\":\"Nicki Holighaus\"},{\"authorId\":\"2210804\",\"name\":\"Nathanael Perraudin\"}],\"doi\":\"10.1109/JSTSP.2020.3037506\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1f76a0725d66f72a29e39a0facfcd433fd320abe\",\"title\":\"GACELA - A generative adversarial context encoder for long audio inpainting\",\"url\":\"https://www.semanticscholar.org/paper/1f76a0725d66f72a29e39a0facfcd433fd320abe\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.07794\",\"authors\":[{\"authorId\":\"2152322\",\"name\":\"M. M. Mohamed\"},{\"authorId\":\"1703004919\",\"name\":\"Mina A. Nessiem\"},{\"authorId\":\"123939577\",\"name\":\"B. Schuller\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"925fcf3c9e0f2dc2046c0092613e8d801e60d0b0\",\"title\":\"On Deep Speech Packet Loss Concealment: A Mini-Survey\",\"url\":\"https://www.semanticscholar.org/paper/925fcf3c9e0f2dc2046c0092613e8d801e60d0b0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.04556\",\"authors\":[{\"authorId\":\"80442851\",\"name\":\"Giovanni Morrone\"},{\"authorId\":\"9686806\",\"name\":\"Daniel Michelsanti\"},{\"authorId\":\"9168278\",\"name\":\"Zheng-Hua Tan\"},{\"authorId\":\"145416680\",\"name\":\"J. Jensen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"21dd49732f9f2dea1311c27b81b57a0ff2492731\",\"title\":\"Audio-Visual Speech Inpainting with Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/21dd49732f9f2dea1311c27b81b57a0ff2492731\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.10558\",\"authors\":[{\"authorId\":\"34777509\",\"name\":\"Yapeng Tian\"},{\"authorId\":\"40580714\",\"name\":\"Dingzeyu Li\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":\"10.1007/978-3-030-58580-8_26\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3867340091c920dc5f8ba462197fa5bc924a98c4\",\"title\":\"Unified Multisensory Perception: Weakly-Supervised Audio-Visual Video Parsing\",\"url\":\"https://www.semanticscholar.org/paper/3867340091c920dc5f8ba462197fa5bc924a98c4\",\"venue\":\"ECCV\",\"year\":2020}],\"corpusId\":204851938,\"doi\":\"10.1109/ICCV.2019.00037\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":1,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"82feef7ae3b3d5ea16ce8bfdf9a01d9aadb4b7be\",\"references\":[{\"arxivId\":\"1712.01393\",\"authors\":[{\"authorId\":\"49455017\",\"name\":\"Yipin Zhou\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"145262461\",\"name\":\"Trung Bui\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/CVPR.2018.00374\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f2d126e02401ec9f3c131eac423620529996df2f\",\"title\":\"Visual to Sound: Generating Natural Sound for Videos in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/f2d126e02401ec9f3c131eac423620529996df2f\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1702.07825\",\"authors\":[{\"authorId\":\"2676352\",\"name\":\"Sercan \\u00d6. Arik\"},{\"authorId\":\"35977287\",\"name\":\"M. Chrzanowski\"},{\"authorId\":\"144638694\",\"name\":\"A. Coates\"},{\"authorId\":\"2040049\",\"name\":\"G. Diamos\"},{\"authorId\":\"9544702\",\"name\":\"Andrew Gibiansky\"},{\"authorId\":\"1729563\",\"name\":\"Yongguo Kang\"},{\"authorId\":\"2745494\",\"name\":\"X. Li\"},{\"authorId\":\"152617830\",\"name\":\"J. Miller\"},{\"authorId\":\"145175379\",\"name\":\"Andrew Ng\"},{\"authorId\":\"34042420\",\"name\":\"Jonathan Raiman\"},{\"authorId\":\"2264597\",\"name\":\"S. Sengupta\"},{\"authorId\":\"1911755\",\"name\":\"M. Shoeybi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"63880b57b95de8afd73036e55b9c4bccb7a528b9\",\"title\":\"Deep Voice: Real-time Neural Text-to-Speech\",\"url\":\"https://www.semanticscholar.org/paper/63880b57b95de8afd73036e55b9c4bccb7a528b9\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":\"1701.00495\",\"authors\":[{\"authorId\":\"2077454\",\"name\":\"A. Ephrat\"},{\"authorId\":\"144406261\",\"name\":\"Shmuel Peleg\"}],\"doi\":\"10.1109/ICASSP.2017.7953127\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5c87c275ddde2e0b75264fe9dad7b130db410601\",\"title\":\"Vid2speech: Speech reconstruction from silent video\",\"url\":\"https://www.semanticscholar.org/paper/5c87c275ddde2e0b75264fe9dad7b130db410601\",\"venue\":\"2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1388822676\",\"name\":\"Andr eacute Marafioti\"},{\"authorId\":\"2617861\",\"name\":\"Nicki Holighaus\"},{\"authorId\":\"2005106\",\"name\":\"P. Majdak\"},{\"authorId\":\"1387973384\",\"name\":\"Nathana euml Perraudin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"46ecd6599afe7d1bc1703a70947d5983a8b8912e\",\"title\":\"Audio Inpainting of Music by Means of Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/46ecd6599afe7d1bc1703a70947d5983a8b8912e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33412853\",\"name\":\"R. Huber\"},{\"authorId\":\"1941498\",\"name\":\"B. Kollmeier\"}],\"doi\":\"10.1109/TASL.2006.883259\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cb9abaf9d9b40fe95cf416c4ca041575c53c52ec\",\"title\":\"PEMO-Q&#8212;A New Method for Objective Audio Quality Assessment Using a Model of Auditory Perception\",\"url\":\"https://www.semanticscholar.org/paper/cb9abaf9d9b40fe95cf416c4ca041575c53c52ec\",\"venue\":\"IEEE Transactions on Audio, Speech, and Language Processing\",\"year\":2006},{\"arxivId\":\"1704.01279\",\"authors\":[{\"authorId\":\"9695761\",\"name\":\"J. Engel\"},{\"authorId\":\"47267576\",\"name\":\"Cinjon Resnick\"},{\"authorId\":\"152606360\",\"name\":\"A. Roberts\"},{\"authorId\":\"48373216\",\"name\":\"S. Dieleman\"},{\"authorId\":\"144739074\",\"name\":\"Mohammad Norouzi\"},{\"authorId\":\"153329923\",\"name\":\"Douglas Eck\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"97c01b6cef7d7d88ec7eda488bfdc46fd601e76a\",\"title\":\"Neural Audio Synthesis of Musical Notes with WaveNet Autoencoders\",\"url\":\"https://www.semanticscholar.org/paper/97c01b6cef7d7d88ec7eda488bfdc46fd601e76a\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":\"1807.07860\",\"authors\":[{\"authorId\":\"145798292\",\"name\":\"Hang Zhou\"},{\"authorId\":\"40457380\",\"name\":\"Y. Liu\"},{\"authorId\":\"3243969\",\"name\":\"Z. Liu\"},{\"authorId\":\"47571885\",\"name\":\"Ping Luo\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1609/aaai.v33i01.33019299\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1816f98e2a4dd54690c2689cf529699d8843e847\",\"title\":\"Talking Face Generation by Adversarially Disentangled Audio-Visual Representation\",\"url\":\"https://www.semanticscholar.org/paper/1816f98e2a4dd54690c2689cf529699d8843e847\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1610.09001\",\"authors\":[{\"authorId\":\"3152281\",\"name\":\"Y. Aytar\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7ab8d3af6f78f9c9f64a2f2d38471401ad0988a9\",\"title\":\"SoundNet: Learning Sound Representations from Unlabeled Video\",\"url\":\"https://www.semanticscholar.org/paper/7ab8d3af6f78f9c9f64a2f2d38471401ad0988a9\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1804.03619\",\"authors\":[{\"authorId\":\"2077454\",\"name\":\"A. Ephrat\"},{\"authorId\":\"2138834\",\"name\":\"Inbar Mosseri\"},{\"authorId\":\"49618488\",\"name\":\"Oran Lang\"},{\"authorId\":\"2112779\",\"name\":\"Tali Dekel\"},{\"authorId\":\"118291142\",\"name\":\"K. Wilson\"},{\"authorId\":\"1639722387\",\"name\":\"Avinatan Hassidim\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"},{\"authorId\":\"144544291\",\"name\":\"Michael Rubinstein\"}],\"doi\":\"10.1145/3197517.3201357\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1b6add50e6be8d4f21e38cca9a154321cad3a4e0\",\"title\":\"Looking to listen at the cocktail party\",\"url\":\"https://www.semanticscholar.org/paper/1b6add50e6be8d4f21e38cca9a154321cad3a4e0\",\"venue\":\"ACM Trans. Graph.\",\"year\":2018},{\"arxivId\":\"1801.07892\",\"authors\":[{\"authorId\":\"46380478\",\"name\":\"J. Yu\"},{\"authorId\":\"145527707\",\"name\":\"Zhe L. Lin\"},{\"authorId\":\"1768964\",\"name\":\"Jimei Yang\"},{\"authorId\":\"1720987\",\"name\":\"X. Shen\"},{\"authorId\":\"145574672\",\"name\":\"Xin Lu\"},{\"authorId\":\"1739208\",\"name\":\"T. Huang\"}],\"doi\":\"10.1109/CVPR.2018.00577\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6b0bbf3e7df725cc3b781d2648e41782cb3d8539\",\"title\":\"Generative Image Inpainting with Contextual Attention\",\"url\":\"https://www.semanticscholar.org/paper/6b0bbf3e7df725cc3b781d2648e41782cb3d8539\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1904.05979\",\"authors\":[{\"authorId\":\"144077750\",\"name\":\"Hang Zhao\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"2650832\",\"name\":\"W. Ma\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/ICCV.2019.00182\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c880de441a41c351955ad0bf8f712eeee500ac67\",\"title\":\"The Sound of Motions\",\"url\":\"https://www.semanticscholar.org/paper/c880de441a41c351955ad0bf8f712eeee500ac67\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1711.08102\",\"authors\":[{\"authorId\":\"8598253\",\"name\":\"Wang-Li Hao\"},{\"authorId\":\"145274329\",\"name\":\"Zhaoxiang Zhang\"},{\"authorId\":\"32561502\",\"name\":\"H. Guan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e834460d2cec8c24d7ade9364f68d2debcf994e4\",\"title\":\"CMCGAN: A Uniform Framework for Cross-Modal Visual-Audio Mutual Generation\",\"url\":\"https://www.semanticscholar.org/paper/e834460d2cec8c24d7ade9364f68d2debcf994e4\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3443095\",\"name\":\"Bruno Korbar\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c97774191be232678a45d343a25fcc0c96c065e7\",\"title\":\"Co-Training of Audio and Video Representations from Self-Supervised Temporal Synchronization\",\"url\":\"https://www.semanticscholar.org/paper/c97774191be232678a45d343a25fcc0c96c065e7\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40363518\",\"name\":\"Nathana\\u00ebl Perraudin\"},{\"authorId\":\"2617861\",\"name\":\"Nicki Holighaus\"},{\"authorId\":\"2005106\",\"name\":\"P. Majdak\"},{\"authorId\":\"1820822\",\"name\":\"P. Bal\\u00e1zs\"}],\"doi\":\"10.1109/TASLP.2018.2809864\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fc7c3ba7b17eb679054a575bfec8b2cea39c1b57\",\"title\":\"Inpainting of Long Audio Segments With Similarity Graphs\",\"url\":\"https://www.semanticscholar.org/paper/fc7c3ba7b17eb679054a575bfec8b2cea39c1b57\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2018},{\"arxivId\":\"1611.05358\",\"authors\":[{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"},{\"authorId\":\"33666044\",\"name\":\"A. Senior\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2017.367\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bed6d0097df1e9ac82f789f6da268cdb3dd65bc3\",\"title\":\"Lip Reading Sentences in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/bed6d0097df1e9ac82f789f6da268cdb3dd65bc3\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1711.10433\",\"authors\":[{\"authorId\":\"3422336\",\"name\":\"A. Oord\"},{\"authorId\":\"3422141\",\"name\":\"Y. Li\"},{\"authorId\":\"7309979\",\"name\":\"I. Babuschkin\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"},{\"authorId\":\"47568983\",\"name\":\"George van den Driessche\"},{\"authorId\":\"49860549\",\"name\":\"Edward Lockhart\"},{\"authorId\":\"38712164\",\"name\":\"Luis C. Cobo\"},{\"authorId\":\"3205302\",\"name\":\"Florian Stimberg\"},{\"authorId\":\"2670752\",\"name\":\"Norman Casagrande\"},{\"authorId\":\"2401609\",\"name\":\"Dominik Grewe\"},{\"authorId\":\"30155667\",\"name\":\"Seb Noury\"},{\"authorId\":\"48373216\",\"name\":\"S. Dieleman\"},{\"authorId\":\"152585800\",\"name\":\"E. Elsen\"},{\"authorId\":\"2583391\",\"name\":\"Nal Kalchbrenner\"},{\"authorId\":\"1691713\",\"name\":\"H. Zen\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"143776287\",\"name\":\"Helen King\"},{\"authorId\":\"123738153\",\"name\":\"Tom Walters\"},{\"authorId\":\"143813532\",\"name\":\"D. Belov\"},{\"authorId\":\"48987704\",\"name\":\"Demis Hassabis\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f6cbf83e1ce3b099d656d2346b261d5ef7f2b62e\",\"title\":\"Parallel WaveNet: Fast High-Fidelity Speech Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/f6cbf83e1ce3b099d656d2346b261d5ef7f2b62e\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":\"1804.01665\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1007/978-3-030-01219-9_3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5c9ca16cb2337fd5948c7af28c29c156981250e8\",\"title\":\"Learning to Separate Object Sounds by Watching Unlabeled Video\",\"url\":\"https://www.semanticscholar.org/paper/5c9ca16cb2337fd5948c7af28c29c156981250e8\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2715710\",\"name\":\"Kai Siedenburg\"},{\"authorId\":\"29292560\",\"name\":\"M. Kowalski\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"954b24978e6b13baf5177ee0d3cc08e2c88f8dda\",\"title\":\"Audio Inpainting with Social Sparsity\",\"url\":\"https://www.semanticscholar.org/paper/954b24978e6b13baf5177ee0d3cc08e2c88f8dda\",\"venue\":\"\",\"year\":2013},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jiahui Yu\"},{\"authorId\":null,\"name\":\"Zhe Lin\"},{\"authorId\":null,\"name\":\"Jimei Yang\"},{\"authorId\":null,\"name\":\"Xiaohui Shen\"},{\"authorId\":null,\"name\":\"Xin Lu\"},{\"authorId\":null,\"name\":\"Thomas S Huang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"mantic image inpainting with deep generative models\",\"url\":\"\",\"venue\":\"Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/978-3-319-54184-6_6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"74f1c93dd3a8c3f9fa59fadef9a744234b2977eb\",\"title\":\"Lip Reading in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/74f1c93dd3a8c3f9fa59fadef9a744234b2977eb\",\"venue\":\"ACCV\",\"year\":2016},{\"arxivId\":\"1611.07004\",\"authors\":[{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"1822702\",\"name\":\"Tinghui Zhou\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1109/CVPR.2017.632\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8acbe90d5b852dadea7810345451a99608ee54c7\",\"title\":\"Image-to-Image Translation with Conditional Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/8acbe90d5b852dadea7810345451a99608ee54c7\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1801.09392\",\"authors\":[{\"authorId\":\"35277013\",\"name\":\"Zhaoyi Yan\"},{\"authorId\":\"21515518\",\"name\":\"X. Li\"},{\"authorId\":\"47628982\",\"name\":\"Mu Li\"},{\"authorId\":\"1724520\",\"name\":\"W. Zuo\"},{\"authorId\":\"145455919\",\"name\":\"S. Shan\"}],\"doi\":\"10.1007/978-3-030-01264-9_1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"904decf94f5495d1488e2bf22e3ed4df500ce4d5\",\"title\":\"Shift-Net: Image Inpainting via Deep Feature Rearrangement\",\"url\":\"https://www.semanticscholar.org/paper/904decf94f5495d1488e2bf22e3ed4df500ce4d5\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1713941\",\"name\":\"Christopher Zach\"},{\"authorId\":\"1730097\",\"name\":\"T. Pock\"},{\"authorId\":\"144746444\",\"name\":\"H. Bischof\"}],\"doi\":\"10.1007/978-3-540-74936-3_22\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f6bbe9afab5fd61f36de5461e9e6a30ca462c7c\",\"title\":\"A Duality Based Approach for Realtime TV-L1 Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/0f6bbe9afab5fd61f36de5461e9e6a30ca462c7c\",\"venue\":\"DAGM-Symposium\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2754098\",\"name\":\"Y. Ai\"},{\"authorId\":\"51289691\",\"name\":\"Hong-Chuan Wu\"},{\"authorId\":\"1749989\",\"name\":\"Z. Ling\"}],\"doi\":\"10.1109/ICASSP.2018.8461878\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"545cddcb4d525b193eb8ca142f15ebfca6eecbad\",\"title\":\"Samplernn-Based Neural Vocoder for Statistical Parametric Speech Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/545cddcb4d525b193eb8ca142f15ebfca6eecbad\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":\"1803.10404\",\"authors\":[{\"authorId\":\"1753356\",\"name\":\"Lele Chen\"},{\"authorId\":\"48458657\",\"name\":\"Zhiheng Li\"},{\"authorId\":\"4053196\",\"name\":\"Ross K. Maddox\"},{\"authorId\":\"3270912\",\"name\":\"Z. Duan\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":\"10.1007/978-3-030-01234-2_32\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d7e12f93339dc9a97cc325a4a3e9a13bdffb4988\",\"title\":\"Lip Movements Generation at a Glance\",\"url\":\"https://www.semanticscholar.org/paper/d7e12f93339dc9a97cc325a4a3e9a13bdffb4988\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1705.08168\",\"authors\":[{\"authorId\":\"2299479\",\"name\":\"R. Arandjelovi\\u0107\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/ICCV.2017.73\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9b5f696f73c1264ccb8e97d3b738a2342ecd6bee\",\"title\":\"Look, Listen and Learn\",\"url\":\"https://www.semanticscholar.org/paper/9b5f696f73c1264ccb8e97d3b738a2342ecd6bee\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1705.08947\",\"authors\":[{\"authorId\":\"9544702\",\"name\":\"Andrew Gibiansky\"},{\"authorId\":\"2676352\",\"name\":\"Sercan \\u00d6. Arik\"},{\"authorId\":\"2040049\",\"name\":\"G. Diamos\"},{\"authorId\":\"152617830\",\"name\":\"J. Miller\"},{\"authorId\":\"12240560\",\"name\":\"Kainan Peng\"},{\"authorId\":\"34337724\",\"name\":\"W. Ping\"},{\"authorId\":\"34042420\",\"name\":\"Jonathan Raiman\"},{\"authorId\":\"2389316\",\"name\":\"Yanqi Zhou\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5a5bcfda3b753f8266b9ba27d34fc86b6d374a1b\",\"title\":\"Deep Voice 2: Multi-Speaker Neural Text-to-Speech\",\"url\":\"https://www.semanticscholar.org/paper/5a5bcfda3b753f8266b9ba27d34fc86b6d374a1b\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1607.07539\",\"authors\":[{\"authorId\":\"28919105\",\"name\":\"Raymond A. Yeh\"},{\"authorId\":\"1696291\",\"name\":\"Chen Chen\"},{\"authorId\":\"33494814\",\"name\":\"Teck-Yian Lim\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"1399115926\",\"name\":\"M. Hasegawa-Johnson\"},{\"authorId\":\"1834451\",\"name\":\"M. Do\"}],\"doi\":\"10.1109/CVPR.2017.728\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a3bf4d403a39ed33f0fa8cf78dc906d6130595f\",\"title\":\"Semantic Image Inpainting with Deep Generative Models\",\"url\":\"https://www.semanticscholar.org/paper/8a3bf4d403a39ed33f0fa8cf78dc906d6130595f\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1512.08512\",\"authors\":[{\"authorId\":\"144956994\",\"name\":\"Andrew Owens\"},{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"2324658\",\"name\":\"J. McDermott\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145358192\",\"name\":\"E. Adelson\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"}],\"doi\":\"10.1109/CVPR.2016.264\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ac640c2d0f33fb3ab49f37b26982948fc31e3191\",\"title\":\"Visually Indicated Sounds\",\"url\":\"https://www.semanticscholar.org/paper/ac640c2d0f33fb3ab49f37b26982948fc31e3191\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1702.02463\",\"authors\":[{\"authorId\":\"3243969\",\"name\":\"Z. Liu\"},{\"authorId\":\"28919105\",\"name\":\"Raymond A. Yeh\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"36966089\",\"name\":\"Y. Liu\"},{\"authorId\":\"1696487\",\"name\":\"A. Agarwala\"}],\"doi\":\"10.1109/ICCV.2017.478\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8970e9caed1fca960ead644e6453a1a7321a7e6d\",\"title\":\"Video Frame Synthesis Using Deep Voxel Flow\",\"url\":\"https://www.semanticscholar.org/paper/8970e9caed1fca960ead644e6453a1a7321a7e6d\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3243969\",\"name\":\"Z. Liu\"},{\"authorId\":\"89139426\",\"name\":\"Zhongqi Miao\"},{\"authorId\":\"14214933\",\"name\":\"Xingang Pan\"},{\"authorId\":\"31818765\",\"name\":\"Xiaohang Zhan\"},{\"authorId\":\"2251428\",\"name\":\"S. Yu\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"19147b0847bc4381be75df008fc06c5283282c01\",\"title\":\"Compound Domain Adaptation in an Open World\",\"url\":\"https://www.semanticscholar.org/paper/19147b0847bc4381be75df008fc06c5283282c01\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1810.08771\",\"authors\":[{\"authorId\":\"46393411\",\"name\":\"Yi Wang\"},{\"authorId\":\"37983219\",\"name\":\"X. Tao\"},{\"authorId\":\"50844674\",\"name\":\"Xiaojuan Qi\"},{\"authorId\":\"2029246\",\"name\":\"Xiaoyong Shen\"},{\"authorId\":\"1729056\",\"name\":\"J. Jia\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2d7ee90e4f2826e403f3f306c40d4c2998e01c0a\",\"title\":\"Image Inpainting via Generative Multi-column Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/2d7ee90e4f2826e403f3f306c40d4c2998e01c0a\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1938478\",\"name\":\"Yuval Bahat\"},{\"authorId\":\"2159538\",\"name\":\"Y. Schechner\"},{\"authorId\":\"1753908\",\"name\":\"Michael Elad\"}],\"doi\":\"10.1016/j.sigpro.2014.11.023\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cee2c84177654a2c16a95a95c79b8c3c266a4be3\",\"title\":\"Self-content-based audio inpainting\",\"url\":\"https://www.semanticscholar.org/paper/cee2c84177654a2c16a95a95c79b8c3c266a4be3\",\"venue\":\"Signal Process.\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1806590\",\"name\":\"G. Chantas\"},{\"authorId\":\"1698652\",\"name\":\"S. Nikolopoulos\"},{\"authorId\":\"1715604\",\"name\":\"Y. Kompatsiaris\"}],\"doi\":\"10.1109/ICCE.2018.8326160\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"60413cc5ef5fd3b89b2c3ca10f0dae57dbfa8db6\",\"title\":\"Sparse audio inpainting with variational Bayesian inference\",\"url\":\"https://www.semanticscholar.org/paper/60413cc5ef5fd3b89b2c3ca10f0dae57dbfa8db6\",\"venue\":\"2018 IEEE International Conference on Consumer Electronics (ICCE)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1403025868\",\"name\":\"Jean Pouget-Abadie\"},{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"144738865\",\"name\":\"Bing Xu\"},{\"authorId\":\"1393680089\",\"name\":\"David Warde-Farley\"},{\"authorId\":\"1955694\",\"name\":\"Sherjil Ozair\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"title\":\"Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41210105\",\"name\":\"Zhou Wang\"},{\"authorId\":\"144492850\",\"name\":\"A. Bovik\"},{\"authorId\":\"120732976\",\"name\":\"H.R. Sheikh\"},{\"authorId\":\"122128303\",\"name\":\"E.P. Simoncelli\"}],\"doi\":\"10.1109/TIP.2003.819861\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"eae2e0fa72e898c289365c0af16daf57a7a6cf40\",\"title\":\"Image quality assessment: from error visibility to structural similarity\",\"url\":\"https://www.semanticscholar.org/paper/eae2e0fa72e898c289365c0af16daf57a7a6cf40\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2004},{\"arxivId\":\"1604.07379\",\"authors\":[{\"authorId\":\"38236002\",\"name\":\"Deepak Pathak\"},{\"authorId\":\"2562966\",\"name\":\"Philipp Kr\\u00e4henb\\u00fchl\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1109/CVPR.2016.278\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7d0effebfa4bed19b6ba41f3af5b7e5b6890de87\",\"title\":\"Context Encoders: Feature Learning by Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/7d0effebfa4bed19b6ba41f3af5b7e5b6890de87\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1609.03499\",\"authors\":[{\"authorId\":\"3422336\",\"name\":\"A. Oord\"},{\"authorId\":\"48373216\",\"name\":\"S. Dieleman\"},{\"authorId\":\"1691713\",\"name\":\"H. Zen\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"2583391\",\"name\":\"Nal Kalchbrenner\"},{\"authorId\":\"33666044\",\"name\":\"A. Senior\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"df0402517a7338ae28bc54acaac400de6b456a46\",\"title\":\"WaveNet: A Generative Model for Raw Audio\",\"url\":\"https://www.semanticscholar.org/paper/df0402517a7338ae28bc54acaac400de6b456a46\",\"venue\":\"SSW\",\"year\":2016},{\"arxivId\":\"1804.03641\",\"authors\":[{\"authorId\":\"144956994\",\"name\":\"Andrew Owens\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1007/978-3-030-01231-1_39\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"171f8f1090ef0533ff470ed5a4d31ecfefcc74be\",\"title\":\"Audio-Visual Scene Analysis with Self-Supervised Multisensory Features\",\"url\":\"https://www.semanticscholar.org/paper/171f8f1090ef0533ff470ed5a4d31ecfefcc74be\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1729059\",\"name\":\"Valentin Emiya\"},{\"authorId\":\"1692147\",\"name\":\"E. Vincent\"},{\"authorId\":\"2925595\",\"name\":\"Niklas Harlander\"},{\"authorId\":\"1708316\",\"name\":\"V. Hohmann\"}],\"doi\":\"10.1109/TASL.2011.2109381\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1a72a7155d50f9b2e0e3c78244de2eb6b940d331\",\"title\":\"Subjective and Objective Quality Assessment of Audio Source Separation\",\"url\":\"https://www.semanticscholar.org/paper/1a72a7155d50f9b2e0e3c78244de2eb6b940d331\",\"venue\":\"IEEE Transactions on Audio, Speech, and Language Processing\",\"year\":2011},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1704.08292\",\"authors\":[{\"authorId\":\"1753356\",\"name\":\"Lele Chen\"},{\"authorId\":\"4037274\",\"name\":\"Sudhanshu Srivastava\"},{\"authorId\":\"3270912\",\"name\":\"Z. Duan\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":\"10.1145/3126686.3126723\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"27e8965cc9c166e9afee46e611039f0ce8263e51\",\"title\":\"Deep Cross-Modal Audio-Visual Generation\",\"url\":\"https://www.semanticscholar.org/paper/27e8965cc9c166e9afee46e611039f0ce8263e51\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/978-3-319-54427-4_19\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"87defac1045bfa9af0162cd248d193e9be6eb25b\",\"title\":\"Out of Time: Automated Lip Sync in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/87defac1045bfa9af0162cd248d193e9be6eb25b\",\"venue\":\"ACCV Workshops\",\"year\":2016},{\"arxivId\":\"1908.11602\",\"authors\":[{\"authorId\":\"50487517\",\"name\":\"Xudong Xu\"},{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/ICCV.2019.00097\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b7a5f074e06cf8d71e26fb5d25b86b4164a5bb54\",\"title\":\"Recursive Visual Sound Separation Using Minus-Plus Net\",\"url\":\"https://www.semanticscholar.org/paper/b7a5f074e06cf8d71e26fb5d25b86b4164a5bb54\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1804.03160\",\"authors\":[{\"authorId\":\"144077750\",\"name\":\"Hang Zhao\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"41020711\",\"name\":\"Andrew Rouditchenko\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"2324658\",\"name\":\"J. McDermott\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1007/978-3-030-01246-5_35\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fe018f22600d07cbd0452a070e03708886470015\",\"title\":\"The Sound of Pixels\",\"url\":\"https://www.semanticscholar.org/paper/fe018f22600d07cbd0452a070e03708886470015\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1612.07837\",\"authors\":[{\"authorId\":\"34719201\",\"name\":\"Soroush Mehri\"},{\"authorId\":\"145411463\",\"name\":\"K. Kumar\"},{\"authorId\":\"2708454\",\"name\":\"Ishaan Gulrajani\"},{\"authorId\":\"39458024\",\"name\":\"Rithesh Kumar\"},{\"authorId\":\"145342039\",\"name\":\"Shubham Jain\"},{\"authorId\":\"143778281\",\"name\":\"J. Sotelo\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e221e2c2ca8bd74a7b818406c8a2a342760e7d65\",\"title\":\"SampleRNN: An Unconditional End-to-End Neural Audio Generation Model\",\"url\":\"https://www.semanticscholar.org/paper/e221e2c2ca8bd74a7b818406c8a2a342760e7d65\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5610015\",\"name\":\"I. Toumi\"},{\"authorId\":\"1729059\",\"name\":\"Valentin Emiya\"}],\"doi\":\"10.1109/ICASSP.2018.8462187\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb2245a0c138ec72da146629b220d6e7899f27fe\",\"title\":\"Sparse Non-Local Similarity Modeling for Audio Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/eb2245a0c138ec72da146629b220d6e7899f27fe\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":\"1809.02587\",\"authors\":[{\"authorId\":\"31692099\",\"name\":\"Pedro Morgado\"},{\"authorId\":\"1699559\",\"name\":\"N. Vasconcelos\"},{\"authorId\":\"153298725\",\"name\":\"Timothy R. Langlois\"},{\"authorId\":\"39231399\",\"name\":\"O. Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"029490920cd736e91d6c57f3cfb850adddcf2725\",\"title\":\"Self-Supervised Generation of Spatial Audio for 360 Video\",\"url\":\"https://www.semanticscholar.org/paper/029490920cd736e91d6c57f3cfb850adddcf2725\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39990338\",\"name\":\"S. Iizuka\"},{\"authorId\":\"1398077025\",\"name\":\"Edgar Simo-Serra\"},{\"authorId\":\"66193516\",\"name\":\"H. Ishikawa\"}],\"doi\":\"10.1145/3072959.3073659\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d21ebaab3f715dc7178966ff146711882e6a6fee\",\"title\":\"Globally and locally consistent image completion\",\"url\":\"https://www.semanticscholar.org/paper/d21ebaab3f715dc7178966ff146711882e6a6fee\",\"venue\":\"ACM Trans. Graph.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Kai Siedenburg\"},{\"authorId\":null,\"name\":\"Monika D\\u00f6rfler\"},{\"authorId\":null,\"name\":\"Matthieu Kowalski\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Audio inpainting with social sparsity. SPARS (Signal Processing with Adaptive Sparse Structured Representations)\",\"url\":\"\",\"venue\":\"\",\"year\":2013},{\"arxivId\":\"1705.02966\",\"authors\":[{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"},{\"authorId\":\"2727313\",\"name\":\"A. Jamaludin\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.5244/C.31.109\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a8632cf6c1ef4319966564328d187876d3bef363\",\"title\":\"You said that?\",\"url\":\"https://www.semanticscholar.org/paper/a8632cf6c1ef4319966564328d187876d3bef363\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":\"1712.06651\",\"authors\":[{\"authorId\":\"2299479\",\"name\":\"R. Arandjelovi\\u0107\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/978-3-030-01246-5_27\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dfc504536e8434eb008680343abb77010965169e\",\"title\":\"Objects that Sound\",\"url\":\"https://www.semanticscholar.org/paper/dfc504536e8434eb008680343abb77010965169e\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1909.03403\",\"authors\":[{\"authorId\":\"3243969\",\"name\":\"Z. Liu\"},{\"authorId\":\"89139426\",\"name\":\"Zhongqi Miao\"},{\"authorId\":\"14214933\",\"name\":\"Xingang Pan\"},{\"authorId\":\"31818765\",\"name\":\"Xiaohang Zhan\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"2251428\",\"name\":\"S. Yu\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"}],\"doi\":\"10.1109/cvpr42600.2020.01242\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"81ae743681a8c237267512df64b3e656d047632b\",\"title\":\"Open Compound Domain Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/81ae743681a8c237267512df64b3e656d047632b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1710.07654\",\"authors\":[{\"authorId\":\"34337724\",\"name\":\"W. Ping\"},{\"authorId\":\"12240560\",\"name\":\"Kainan Peng\"},{\"authorId\":\"9544702\",\"name\":\"Andrew Gibiansky\"},{\"authorId\":\"2676352\",\"name\":\"Sercan \\u00d6. Arik\"},{\"authorId\":\"33850592\",\"name\":\"A. Kannan\"},{\"authorId\":\"46617804\",\"name\":\"Sharan Narang\"},{\"authorId\":\"34042420\",\"name\":\"Jonathan Raiman\"},{\"authorId\":\"144909221\",\"name\":\"J. Miller\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"852120feb37d2dc136d1c6916b52b9baabfc2e11\",\"title\":\"Deep Voice 3: 2000-Speaker Neural Text-to-Speech\",\"url\":\"https://www.semanticscholar.org/paper/852120feb37d2dc136d1c6916b52b9baabfc2e11\",\"venue\":\"ICLR 2018\",\"year\":2017},{\"arxivId\":\"1712.05884\",\"authors\":[{\"authorId\":\"143724108\",\"name\":\"Jonathan Shen\"},{\"authorId\":\"34320634\",\"name\":\"R. Pang\"},{\"authorId\":\"39571582\",\"name\":\"Ron J. Weiss\"},{\"authorId\":\"46503039\",\"name\":\"M. Schuster\"},{\"authorId\":\"3111912\",\"name\":\"Navdeep Jaitly\"},{\"authorId\":\"1867996\",\"name\":\"Z. Yang\"},{\"authorId\":\"2545358\",\"name\":\"Z. Chen\"},{\"authorId\":\"36562659\",\"name\":\"Yu Zhang\"},{\"authorId\":null,\"name\":\"Yuxuan Wang\"},{\"authorId\":\"1380248814\",\"name\":\"R. Skerry-Ryan\"},{\"authorId\":\"2278009\",\"name\":\"R. A. Saurous\"},{\"authorId\":\"2259013\",\"name\":\"Yannis Agiomyrgiannakis\"},{\"authorId\":\"1780996\",\"name\":\"Y. Wu\"}],\"doi\":\"10.1109/ICASSP.2018.8461368\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1a2599e467e855f845dcbf9282f8bdbd97b85708\",\"title\":\"Natural TTS Synthesis by Conditioning Wavenet on MEL Spectrogram Predictions\",\"url\":\"https://www.semanticscholar.org/paper/1a2599e467e855f845dcbf9282f8bdbd97b85708\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":\"1803.03849\",\"authors\":[{\"authorId\":\"40895287\",\"name\":\"Arda Senocak\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"3053231\",\"name\":\"J. Kim\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"2398271\",\"name\":\"In-So Kweon\"}],\"doi\":\"10.1109/CVPR.2018.00458\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b91d738cd1f5d550c5b27f328e55308a0a73b2d2\",\"title\":\"Learning to Localize Sound Source in Visual Scenes\",\"url\":\"https://www.semanticscholar.org/paper/b91d738cd1f5d550c5b27f328e55308a0a73b2d2\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Kai Siedenburg\"},{\"authorId\":null,\"name\":\"Monika D\\u00f6rfler\"},{\"authorId\":null,\"name\":\"Matthieu Kowalski\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Audio inpainting with social sparsity. SPARS (Signal Pro-  cessing with Adaptive Sparse Structured Representations)\",\"url\":\"\",\"venue\":\"\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39243222\",\"name\":\"A. Adler\"},{\"authorId\":\"1729059\",\"name\":\"Valentin Emiya\"},{\"authorId\":\"2045027\",\"name\":\"M. Jafari\"},{\"authorId\":\"1753908\",\"name\":\"Michael Elad\"},{\"authorId\":\"1731535\",\"name\":\"R. Gribonval\"},{\"authorId\":\"1804703\",\"name\":\"Mark D. Plumbley\"}],\"doi\":\"10.1109/TASL.2011.2168211\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"11718b2e6e92b66cc65f2920423322c6930893c2\",\"title\":\"Audio Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/11718b2e6e92b66cc65f2920423322c6930893c2\",\"venue\":\"IEEE Transactions on Audio, Speech, and Language Processing\",\"year\":2012}],\"title\":\"Vision-Infused Deep Audio Inpainting\",\"topics\":[{\"topic\":\"Inpainting\",\"topicId\":\"146260\",\"url\":\"https://www.semanticscholar.org/topic/146260\"},{\"topic\":\"Spectrogram\",\"topicId\":\"107230\",\"url\":\"https://www.semanticscholar.org/topic/107230\"},{\"topic\":\"Modality (human\\u2013computer interaction)\",\"topicId\":\"462\",\"url\":\"https://www.semanticscholar.org/topic/462\"},{\"topic\":\"Feature vector\",\"topicId\":\"4255\",\"url\":\"https://www.semanticscholar.org/topic/4255\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Coherence (physics)\",\"topicId\":\"921\",\"url\":\"https://www.semanticscholar.org/topic/921\"},{\"topic\":\"Solo\",\"topicId\":\"163281\",\"url\":\"https://www.semanticscholar.org/topic/163281\"}],\"url\":\"https://www.semanticscholar.org/paper/82feef7ae3b3d5ea16ce8bfdf9a01d9aadb4b7be\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019}\n"