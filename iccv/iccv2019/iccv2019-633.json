"{\"abstract\":\"While many action recognition datasets consist of collections of brief, trimmed videos each containing a relevant action, videos in the real-world (e.g., on YouTube) exhibit very different properties: they are often several minutes long, where brief relevant clips are often interleaved with segments of extended duration containing little change. Applying densely an action recognition system to every temporal clip within such videos is prohibitively expensive. Furthermore, as we show in our experiments, this results in suboptimal recognition accuracy as informative predictions from relevant clips are outnumbered by meaningless classification outputs over long uninformative sections of the video. In this paper we introduce a lightweight ``clip-sampling'' model that can efficiently identify the most salient temporal clips within a long video. We demonstrate that the computational cost of action recognition on untrimmed videos can be dramatically reduced by invoking recognition only on these most salient clips. Furthermore, we show that this yields significant gains in recognition accuracy compared to analysis of all clips or randomly selected clips. On Sports1M, our clip sampling scheme elevates the accuracy of an already state-of-the-art action classifier by 7% and reduces by more than 15 times its computational cost.\",\"arxivId\":\"1904.04289\",\"authors\":[{\"authorId\":\"3443095\",\"name\":\"Bruno Korbar\",\"url\":\"https://www.semanticscholar.org/author/3443095\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\",\"url\":\"https://www.semanticscholar.org/author/1687325\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\",\"url\":\"https://www.semanticscholar.org/author/1732879\"}],\"citationVelocity\":16,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"32346302\",\"name\":\"F. Wang\"},{\"authorId\":\"1423415979\",\"name\":\"Guorui Wang\"},{\"authorId\":\"100975725\",\"name\":\"Yunwen Huang\"},{\"authorId\":\"49276987\",\"name\":\"Hao Chu\"}],\"doi\":\"10.1109/ACCESS.2019.2953113\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"65d934938c27585e144660ae7c293d297dddf64b\",\"title\":\"SAST: Learning Semantic Action-Aware Spatial-Temporal Features for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/65d934938c27585e144660ae7c293d297dddf64b\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"97514733\",\"name\":\"Jin-woo Choi\"},{\"authorId\":\"2515597\",\"name\":\"Gaurav Sharma\"},{\"authorId\":\"1790643\",\"name\":\"S. Schulter\"},{\"authorId\":\"50535349\",\"name\":\"J. Huang\"}],\"doi\":\"10.1007/978-3-030-58610-2_40\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"19d574a2238ad11142de1d6f2713315880b2d218\",\"title\":\"Shuffle and Attend: Video Domain Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/19d574a2238ad11142de1d6f2713315880b2d218\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143688987\",\"name\":\"X. Yan\"},{\"authorId\":\"46461307\",\"name\":\"S. Z. Gilani\"},{\"authorId\":\"3446916\",\"name\":\"Mingtao Feng\"},{\"authorId\":\"2121454\",\"name\":\"Libao Zhang\"},{\"authorId\":\"9493788\",\"name\":\"Han-lin Qin\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"}],\"doi\":\"10.3390/s20236941\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"61de5563ca445cab30b9d4ae2a7112b730c269ce\",\"title\":\"Self-Supervised Learning to Detect Key Frames in Videos\",\"url\":\"https://www.semanticscholar.org/paper/61de5563ca445cab30b9d4ae2a7112b730c269ce\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"2009.10311\",\"authors\":[{\"authorId\":\"1900412935\",\"name\":\"Alon Halevy\"},{\"authorId\":\"1958793545\",\"name\":\"Cristian Canton Ferrer\"},{\"authorId\":\"46389865\",\"name\":\"Hao Ma\"},{\"authorId\":\"2730288\",\"name\":\"U. Ozertem\"},{\"authorId\":\"1990190\",\"name\":\"P. Pantel\"},{\"authorId\":\"2073055\",\"name\":\"Marzieh Saeidi\"},{\"authorId\":\"152493117\",\"name\":\"F. Silvestri\"},{\"authorId\":\"1389924486\",\"name\":\"Ves Stoyanov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"67678935a4cf559762f28e2bfcaa400865e27b84\",\"title\":\"Preserving Integrity in Online Social Networks\",\"url\":\"https://www.semanticscholar.org/paper/67678935a4cf559762f28e2bfcaa400865e27b84\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.06977\",\"authors\":[{\"authorId\":\"47203405\",\"name\":\"Wenhao Wu\"},{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"6873935\",\"name\":\"T. Lin\"},{\"authorId\":\"1998948807\",\"name\":\"F. Li\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"12081764\",\"name\":\"E. Ding\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a6e71b58ea6668dd3872e0c9e6cdd258b4582e2a\",\"title\":\"MVFNet: Multi-View Fusion Network for Efficient Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a6e71b58ea6668dd3872e0c9e6cdd258b4582e2a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2004.01808\",\"authors\":[{\"authorId\":\"13142264\",\"name\":\"Noureldien Hussein\"},{\"authorId\":\"143798882\",\"name\":\"Mihir Jain\"},{\"authorId\":\"2954103\",\"name\":\"B. E. Bejnordi\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"24fd7077532323fffec0aab2bea3d1db4159ffc1\",\"title\":\"TimeGate: Conditional Gating of Segments in Long-range Activities\",\"url\":\"https://www.semanticscholar.org/paper/24fd7077532323fffec0aab2bea3d1db4159ffc1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.08041\",\"authors\":[{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"50557221\",\"name\":\"Chunhui Liu\"},{\"authorId\":\"2521776\",\"name\":\"B. Shuai\"},{\"authorId\":\"1805946041\",\"name\":\"Yi Zhu\"},{\"authorId\":\"48444479\",\"name\":\"Hao Chen\"},{\"authorId\":\"2397422\",\"name\":\"Joseph Tighe\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f0d55ca0b8f1639372e88479516a573e2bf2250b\",\"title\":\"NUTA: Non-uniform Temporal Aggregation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f0d55ca0b8f1639372e88479516a573e2bf2250b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1912.04487\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":\"10.1109/cvpr42600.2020.01047\",\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"c4128ba8deeb67e731cf52fb98addcfddd487e55\",\"title\":\"Listen to Look: Action Recognition by Previewing Audio\",\"url\":\"https://www.semanticscholar.org/paper/c4128ba8deeb67e731cf52fb98addcfddd487e55\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49350890\",\"name\":\"Kwang-Yon Kim\"},{\"authorId\":\"2499044\",\"name\":\"Yeong Jun Koh\"},{\"authorId\":\"96521675\",\"name\":\"Chang-Su Kim\"}],\"doi\":\"10.1109/ACCESS.2020.3003751\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cee7fa07f5eb672d700220c0c89eb19cbda284b5\",\"title\":\"Instance-Level Future Motion Estimation in a Single Image Based on Ordinal Regression and Semi-Supervised Domain Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/cee7fa07f5eb672d700220c0c89eb19cbda284b5\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2011.12384\",\"authors\":[{\"authorId\":\"9385903\",\"name\":\"S. Zhu\"},{\"authorId\":\"1390892946\",\"name\":\"Taojiannan Yang\"},{\"authorId\":\"1422036273\",\"name\":\"Mat'ias Mendieta\"},{\"authorId\":\"143916976\",\"name\":\"Chen Chen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ba1dda6494709cac7c48c95c81afff7a087f2031\",\"title\":\"A3D: Adaptive 3D Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ba1dda6494709cac7c48c95c81afff7a087f2031\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.15560\",\"authors\":[{\"authorId\":\"1391155455\",\"name\":\"Yin-Dong Zheng\"},{\"authorId\":\"46270766\",\"name\":\"Zhaoyang Liu\"},{\"authorId\":\"144720251\",\"name\":\"Tong Lu\"},{\"authorId\":\"29461006\",\"name\":\"L. Wang\"}],\"doi\":\"10.1109/TIP.2020.3007826\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3ee328e73acc9be44d874756dab4c13c65a835c0\",\"title\":\"Dynamic Sampling Networks for Efficient Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/3ee328e73acc9be44d874756dab4c13c65a835c0\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"2011.12619\",\"authors\":[{\"authorId\":\"147084112\",\"name\":\"Jack Humphreys\"},{\"authorId\":\"48354826\",\"name\":\"Z. Chen\"},{\"authorId\":\"145047838\",\"name\":\"Dacheng Tao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e88bff50c417703239e0a832fddb267196ab5a99\",\"title\":\"Recent Progress in Appearance-based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e88bff50c417703239e0a832fddb267196ab5a99\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.08164\",\"authors\":[{\"authorId\":\"47287725\",\"name\":\"Anshul B. Shah\"},{\"authorId\":\"2850880\",\"name\":\"Shlok Kumar Mishra\"},{\"authorId\":\"2068427\",\"name\":\"Ankan Bansal\"},{\"authorId\":\"1391201966\",\"name\":\"Jun-Cheng Chen\"},{\"authorId\":\"69416958\",\"name\":\"Ramalingam Chellappa\"},{\"authorId\":\"51453757\",\"name\":\"Abhinav Shrivastava\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5ac51a6eb28656c670c36a6460be0e458b2e562f\",\"title\":\"Pose And Joint-Aware Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5ac51a6eb28656c670c36a6460be0e458b2e562f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.11479\",\"authors\":[{\"authorId\":\"19198894\",\"name\":\"Humam Alwassel\"},{\"authorId\":\"22314218\",\"name\":\"Silvio Giancola\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5388388db25f0d40ef6612333a0279373f8dddcf\",\"title\":\"TSP: Temporally-Sensitive Pretraining of Video Encoders for Localization Tasks\",\"url\":\"https://www.semanticscholar.org/paper/5388388db25f0d40ef6612333a0279373f8dddcf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.08247\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":\"10.1016/j.patrec.2020.11.012\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9c9ee02e3394adde596c35d1966566b2d971f426\",\"title\":\"Learn to cycle: Time-consistent feature discovery for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/9c9ee02e3394adde596c35d1966566b2d971f426\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"1403581832\",\"name\":\"Laura Sevilla-Lara\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"11445222\",\"name\":\"H. Wang\"}],\"doi\":\"10.1609/AAAI.V34I07.7012\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d718baf9187fa5851a9389e5e250d47ba1210e0e\",\"title\":\"FASTER Recurrent Networks for Efficient Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/d718baf9187fa5851a9389e5e250d47ba1210e0e\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2011.07915\",\"authors\":[{\"authorId\":\"52532366\",\"name\":\"Sanqing Qu\"},{\"authorId\":\"143930563\",\"name\":\"G. Chen\"},{\"authorId\":\"144742695\",\"name\":\"D. Xu\"},{\"authorId\":\"1491152801\",\"name\":\"Jinhu Dong\"},{\"authorId\":\"143611184\",\"name\":\"Fan Lu\"},{\"authorId\":\"152948808\",\"name\":\"A. Knoll\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a098650e4fb78a8b2c9cf22b28faa93f291e20d5\",\"title\":\"LAP-Net: Adaptive Features Sampling via Learning Action Progression for Online Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/a098650e4fb78a8b2c9cf22b28faa93f291e20d5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.06567\",\"authors\":[{\"authorId\":\"1805946041\",\"name\":\"Yi Zhu\"},{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"49046944\",\"name\":\"C. Liu\"},{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"22539483\",\"name\":\"Chongruo Wu\"},{\"authorId\":\"152781163\",\"name\":\"Z. Zhang\"},{\"authorId\":\"2397422\",\"name\":\"Joseph Tighe\"},{\"authorId\":\"1758550\",\"name\":\"R. Manmatha\"},{\"authorId\":\"49140510\",\"name\":\"M. Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ee12f02830a5e1f7cadd3623dfed495cf099bc82\",\"title\":\"A Comprehensive Study of Deep Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ee12f02830a5e1f7cadd3623dfed495cf099bc82\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1912.01601\",\"authors\":[{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"92020e4a2ed14a5f3fd421bcf1111dd2403a237a\",\"title\":\"LiteEval: A Coarse-to-Fine Framework for Resource Efficient Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/92020e4a2ed14a5f3fd421bcf1111dd2403a237a\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46264507\",\"name\":\"Zhipeng Fan\"},{\"authorId\":\"40588062\",\"name\":\"Jun Liu\"},{\"authorId\":null,\"name\":\"Yao Wang\"}],\"doi\":\"10.1007/978-3-030-58548-8_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"21c3901de3093533adf6973a329808ca7750b98e\",\"title\":\"Adaptive Computationally Efficient Network for Monocular 3D Hand Pose Estimation\",\"url\":\"https://www.semanticscholar.org/paper/21c3901de3093533adf6973a329808ca7750b98e\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2001.08740\",\"authors\":[{\"authorId\":\"2299381\",\"name\":\"Fanyi Xiao\"},{\"authorId\":\"144756076\",\"name\":\"Y. Lee\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"153652147\",\"name\":\"J. Malik\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"80685dc522d30b18f3feb97d6c977f71fa746325\",\"title\":\"Audiovisual SlowFast Networks for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/80685dc522d30b18f3feb97d6c977f71fa746325\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1912.00998\",\"authors\":[{\"authorId\":\"100880679\",\"name\":\"Chao-Yuan Wu\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"51506875\",\"name\":\"Philipp Krahenbuhl\"}],\"doi\":\"10.1109/cvpr42600.2020.00023\",\"intent\":[\"methodology\",\"result\"],\"isInfluential\":false,\"paperId\":\"b8cc28e11900e4d191651ae7234b4dbd129b1007\",\"title\":\"A Multigrid Method for Efficiently Training Video Models\",\"url\":\"https://www.semanticscholar.org/paper/b8cc28e11900e4d191651ae7234b4dbd129b1007\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2011.05227\",\"authors\":[{\"authorId\":\"2008155399\",\"name\":\"Th'eo Ayral\"},{\"authorId\":\"3048367\",\"name\":\"M. Pedersoli\"},{\"authorId\":\"3477862\",\"name\":\"S. Bacon\"},{\"authorId\":\"52194462\",\"name\":\"\\u00c9ric Granger\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9080a9f5464b37572202e4a4061997428993fe50\",\"title\":\"Temporal Stochastic Softmax for 3D CNNs: An Application in Facial Expression Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9080a9f5464b37572202e4a4061997428993fe50\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.15796\",\"authors\":[{\"authorId\":\"1470673136\",\"name\":\"Yue Meng\"},{\"authorId\":\"47532522\",\"name\":\"Chung-Ching Lin\"},{\"authorId\":\"1819152\",\"name\":\"R. Panda\"},{\"authorId\":\"1706272\",\"name\":\"P. Sattigeri\"},{\"authorId\":\"2428823\",\"name\":\"Leonid Karlinsky\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"}],\"doi\":\"10.1007/978-3-030-58571-6_6\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"11bf57d8a652de8e2ea436ff6a2707c95fa5197a\",\"title\":\"AR-Net: Adaptive Frame Resolution for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/11bf57d8a652de8e2ea436ff6a2707c95fa5197a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2012.10671\",\"authors\":[{\"authorId\":\"152957752\",\"name\":\"Shreyank N Gowda\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1403581832\",\"name\":\"Laura Sevilla-Lara\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7c062be0a5ba96b5d0cd606d2eeacd768845a116\",\"title\":\"SMART Frame Selection for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7c062be0a5ba96b5d0cd606d2eeacd768845a116\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1905.00561\",\"authors\":[{\"authorId\":\"2028234\",\"name\":\"Deepti Ghadiyaram\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"11529694\",\"name\":\"Xueting Yan\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"144542135\",\"name\":\"D. Mahajan\"}],\"doi\":\"10.1109/CVPR.2019.01232\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4cbaea4c21e15312ef2aeb9529a39baa48bbb522\",\"title\":\"Large-Scale Weakly-Supervised Pre-Training for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4cbaea4c21e15312ef2aeb9529a39baa48bbb522\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2004.04730\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"}],\"doi\":\"10.1109/cvpr42600.2020.00028\",\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"908cca0abefc35acc38033603714fbb1bcadc49d\",\"title\":\"X3D: Expanding Architectures for Efficient Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/908cca0abefc35acc38033603714fbb1bcadc49d\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2011.08652\",\"authors\":[{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"2025664854\",\"name\":\"Emad Bahrami Rad\"},{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"2199924\",\"name\":\"M. Noroozi\"},{\"authorId\":\"46408185\",\"name\":\"E. Adeli\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"80ddd8e76480aa92aa071d33c624af7195b0b762\",\"title\":\"3D CNNs with Adaptive Temporal Feature Resolutions\",\"url\":\"https://www.semanticscholar.org/paper/80ddd8e76480aa92aa071d33c624af7195b0b762\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.10850\",\"authors\":[{\"authorId\":\"40951853\",\"name\":\"Manyuan Zhang\"},{\"authorId\":\"12920342\",\"name\":\"Guanglu Song\"},{\"authorId\":\"145798292\",\"name\":\"Hang Zhou\"},{\"authorId\":\"30752055\",\"name\":\"Y. Liu\"}],\"doi\":\"10.1007/978-3-030-58607-2_1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a1027f7c27273c8c0aac30bbd31da87a0fa342db\",\"title\":\"Discriminability Distillation in Group Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/a1027f7c27273c8c0aac30bbd31da87a0fa342db\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2003.04298\",\"authors\":[{\"authorId\":\"1379929116\",\"name\":\"Mandela Patrick\"},{\"authorId\":\"47792365\",\"name\":\"Y. Asano\"},{\"authorId\":\"145891577\",\"name\":\"Ruth Fong\"},{\"authorId\":\"143848064\",\"name\":\"Jo\\u00e3o F. Henriques\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8ddbaa34c574124a91fa3bc217e232e17668e84c\",\"title\":\"Multi-modal Self-Supervision from Generalized Data Transformations\",\"url\":\"https://www.semanticscholar.org/paper/8ddbaa34c574124a91fa3bc217e232e17668e84c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.10558\",\"authors\":[{\"authorId\":\"34777509\",\"name\":\"Yapeng Tian\"},{\"authorId\":\"40580714\",\"name\":\"Dingzeyu Li\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":\"10.1007/978-3-030-58580-8_26\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3867340091c920dc5f8ba462197fa5bc924a98c4\",\"title\":\"Unified Multisensory Perception: Weakly-Supervised Audio-Visual Video Parsing\",\"url\":\"https://www.semanticscholar.org/paper/3867340091c920dc5f8ba462197fa5bc924a98c4\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2001.06232\",\"authors\":[{\"authorId\":\"1471708751\",\"name\":\"M. Malinowski\"},{\"authorId\":\"1782475\",\"name\":\"G. Swirszcz\"},{\"authorId\":\"153062108\",\"name\":\"J. Carreira\"},{\"authorId\":\"1756112\",\"name\":\"Viorica Patraucean\"}],\"doi\":\"10.1109/cvpr42600.2020.01185\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"21f96afef802b3e00edd9bb8c4b71fc3f0cc43df\",\"title\":\"Sideways: Depth-Parallel Training of Video Models\",\"url\":\"https://www.semanticscholar.org/paper/21f96afef802b3e00edd9bb8c4b71fc3f0cc43df\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2012.14950\",\"authors\":[{\"authorId\":\"26959701\",\"name\":\"Hengduo Li\"},{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":null,\"name\":\"Abhinav Shrivastava\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f434d65e76041d3417715791e052255f924d4efc\",\"title\":\"2D or not 2D? Adaptive 3D Convolution Selection for Efficient Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f434d65e76041d3417715791e052255f924d4efc\",\"venue\":\"\",\"year\":2020}],\"corpusId\":104292215,\"doi\":\"10.1109/ICCV.2019.00633\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":7,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"2aed352cdd78010f72eaf618d52a4793fab32cea\",\"references\":[{\"arxivId\":\"1705.07750\",\"authors\":[{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2017.502\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"title\":\"Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset\",\"url\":\"https://www.semanticscholar.org/paper/b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1109/CVPR.2016.211\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bac994dda1385cd709e08e24170c711d8c573676\",\"title\":\"Fast Temporal Activity Proposals for Efficient Detection of Human Actions in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/bac994dda1385cd709e08e24170c711d8c573676\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1804.03641\",\"authors\":[{\"authorId\":\"144956994\",\"name\":\"Andrew Owens\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1007/978-3-030-01231-1_39\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"171f8f1090ef0533ff470ed5a4d31ecfefcc74be\",\"title\":\"Audio-Visual Scene Analysis with Self-Supervised Multisensory Features\",\"url\":\"https://www.semanticscholar.org/paper/171f8f1090ef0533ff470ed5a4d31ecfefcc74be\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1703.07814\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"40521893\",\"name\":\"Abir Das\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/ICCV.2017.617\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7f8324dda6261ec293e9705c13a0e96b9ab63474\",\"title\":\"R-C3D: Region Convolutional 3D Network for Temporal Activity Detection\",\"url\":\"https://www.semanticscholar.org/paper/7f8324dda6261ec293e9705c13a0e96b9ab63474\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1608.07017\",\"authors\":[{\"authorId\":\"144956994\",\"name\":\"Andrew Owens\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"2324658\",\"name\":\"J. McDermott\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1007/978-3-319-46448-0_48\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"93a87dfa72f22fba14ef243a62c7d0a6906dfed7\",\"title\":\"Ambient Sound Provides Supervision for Visual Learning\",\"url\":\"https://www.semanticscholar.org/paper/93a87dfa72f22fba14ef243a62c7d0a6906dfed7\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1608.00859\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-319-46484-8_2\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"title\":\"Temporal Segment Networks: Towards Good Practices for Deep Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1804.03160\",\"authors\":[{\"authorId\":\"144077750\",\"name\":\"Hang Zhao\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"41020711\",\"name\":\"Andrew Rouditchenko\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"2324658\",\"name\":\"J. McDermott\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1007/978-3-030-01246-5_35\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fe018f22600d07cbd0452a070e03708886470015\",\"title\":\"The Sound of Pixels\",\"url\":\"https://www.semanticscholar.org/paper/fe018f22600d07cbd0452a070e03708886470015\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1704.02895\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"145160921\",\"name\":\"Bryan C. Russell\"}],\"doi\":\"10.1109/CVPR.2017.337\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"63213d080a43660ac59ea12e3c35e6953f6d7ce8\",\"title\":\"ActionVLAD: Learning Spatio-Temporal Aggregation for Action Classification\",\"url\":\"https://www.semanticscholar.org/paper/63213d080a43660ac59ea12e3c35e6953f6d7ce8\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1812.03982\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"2681569\",\"name\":\"Haoqi Fan\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"}],\"doi\":\"10.1109/ICCV.2019.00630\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"8b47b9c3c35b2b2a78bff7822605b3040f87d699\",\"title\":\"SlowFast Networks for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b47b9c3c35b2b2a78bff7822605b3040f87d699\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1707.06750\",\"authors\":[{\"authorId\":\"6873935\",\"name\":\"T. Lin\"},{\"authorId\":\"1758267\",\"name\":\"X. Zhao\"},{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"af3bdb1739826b1a6ada23b9fb18eaa241a444e3\",\"title\":\"Temporal Convolution Based Action Proposal: Submission to ActivityNet 2017\",\"url\":\"https://www.semanticscholar.org/paper/af3bdb1739826b1a6ada23b9fb18eaa241a444e3\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1811.12432\",\"authors\":[{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"7437104\",\"name\":\"Chih-Yao Ma\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/CVPR.2019.00137\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0a98ef88bae12639d8770e5680564b8f9a188bec\",\"title\":\"AdaFrame: Adaptive Frame Selection for Fast Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/0a98ef88bae12639d8770e5680564b8f9a188bec\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1804.01665\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1007/978-3-030-01219-9_3\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"5c9ca16cb2337fd5948c7af28c29c156981250e8\",\"title\":\"Learning to Separate Object Sounds by Watching Unlabeled Video\",\"url\":\"https://www.semanticscholar.org/paper/5c9ca16cb2337fd5948c7af28c29c156981250e8\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1711.07971\",\"authors\":[{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"}],\"doi\":\"10.1109/CVPR.2018.00813\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"8899094797e82c5c185a0893896320ef77f60e64\",\"title\":\"Non-local Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/8899094797e82c5c185a0893896320ef77f60e64\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/ICCV.2015.510\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"title\":\"Learning Spatiotemporal Features with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1711.08496\",\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"50112310\",\"name\":\"Alex Andonian\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1007/978-3-030-01246-5_49\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8ad12d3ee186403b856639b58d7797aa4b89a6c7\",\"title\":\"Temporal Relational Reasoning in Videos\",\"url\":\"https://www.semanticscholar.org/paper/8ad12d3ee186403b856639b58d7797aa4b89a6c7\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3116662\",\"name\":\"J. Gemmeke\"},{\"authorId\":\"1745455\",\"name\":\"D. Ellis\"},{\"authorId\":\"36794621\",\"name\":\"Dylan Freedman\"},{\"authorId\":\"35996413\",\"name\":\"A. Jansen\"},{\"authorId\":\"39965499\",\"name\":\"W. Lawrence\"},{\"authorId\":\"1974225\",\"name\":\"R. C. Moore\"},{\"authorId\":\"2114994\",\"name\":\"M. Plakal\"},{\"authorId\":\"39687627\",\"name\":\"M. Ritter\"}],\"doi\":\"10.1109/ICASSP.2017.7952261\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5ba2218b708ca64ab556e39d5997202e012717d5\",\"title\":\"Audio Set: An ontology and human-labeled dataset for audio events\",\"url\":\"https://www.semanticscholar.org/paper/5ba2218b708ca64ab556e39d5997202e012717d5\",\"venue\":\"2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2435677\",\"name\":\"Michele Merler\"},{\"authorId\":\"2798372\",\"name\":\"Khoi-Nguyen C. Mac\"},{\"authorId\":\"5113463\",\"name\":\"D. Joshi\"},{\"authorId\":\"143880942\",\"name\":\"Q. Nguyen\"},{\"authorId\":\"7641415\",\"name\":\"Stephen Hammer\"},{\"authorId\":\"143836309\",\"name\":\"J. Kent\"},{\"authorId\":\"46590281\",\"name\":\"Jinjun Xiong\"},{\"authorId\":\"1834451\",\"name\":\"M. Do\"},{\"authorId\":null,\"name\":\"John R. Smith\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"}],\"doi\":\"10.1109/TMM.2018.2876046\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2f96cff446b72222d67665d3412b5889ccb10fba\",\"title\":\"Automatic Curation of Sports Highlights Using Multimodal Excitement Features\",\"url\":\"https://www.semanticscholar.org/paper/2f96cff446b72222d67665d3412b5889ccb10fba\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"},{\"authorId\":\"2704179\",\"name\":\"Dongang Wang\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1109/CVPR.2016.119\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"317eaf94573857bec786bbf030605ccdb0fd624d\",\"title\":\"Temporal Action Localization in Untrimmed Videos via Multi-stage CNNs\",\"url\":\"https://www.semanticscholar.org/paper/317eaf94573857bec786bbf030605ccdb0fd624d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1604.04494\",\"authors\":[{\"authorId\":\"2668759\",\"name\":\"G. Varol\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/TPAMI.2017.2712608\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"47e3ef70f2539386bcef604097fa9235246c6d53\",\"title\":\"Long-Term Temporal Convolutions for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/47e3ef70f2539386bcef604097fa9235246c6d53\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":\"1611.02155\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5f4d2f6ad967f7c9369c04e75cda08f12cb8afbd\",\"title\":\"Spatiotemporal Residual Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5f4d2f6ad967f7c9369c04e75cda08f12cb8afbd\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19198894\",\"name\":\"Humam Alwassel\"},{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1007/978-3-030-01240-3_16\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"78c4086c392d03e206d2a25be55768cd58ce3462\",\"title\":\"Action Search: Spotting Actions in Videos and Its Application to Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/78c4086c392d03e206d2a25be55768cd58ce3462\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1511.06984\",\"authors\":[{\"authorId\":\"34149749\",\"name\":\"Serena Yeung\"},{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2016.293\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1bbde7946951d770628cf6b6bcd66c63e4fabb4c\",\"title\":\"End-to-End Learning of Action Detection from Frame Glimpses in Videos\",\"url\":\"https://www.semanticscholar.org/paper/1bbde7946951d770628cf6b6bcd66c63e4fabb4c\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1706.06905\",\"authors\":[{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1238d0c296c1263afa958ccc1bff3d65e6430be3\",\"title\":\"Learnable pooling with Context Gating for video classification\",\"url\":\"https://www.semanticscholar.org/paper/1238d0c296c1263afa958ccc1bff3d65e6430be3\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2319574\",\"name\":\"D. Potapov\"},{\"authorId\":\"3271933\",\"name\":\"M. Douze\"},{\"authorId\":\"1753355\",\"name\":\"Z. Harchaoui\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1007/978-3-319-10599-4_35\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"558a7e14c7dfe3f65bd5a8ff7b4e59b635306a72\",\"title\":\"Category-Specific Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/558a7e14c7dfe3f65bd5a8ff7b4e59b635306a72\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1807.00230\",\"authors\":[{\"authorId\":\"3443095\",\"name\":\"Bruno Korbar\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"2e057a9b195f0ea2d1c5a1e88ff9606f9b67ef8b\",\"title\":\"Cooperative Learning of Audio and Video Models from Self-Supervised Synchronization\",\"url\":\"https://www.semanticscholar.org/paper/2e057a9b195f0ea2d1c5a1e88ff9606f9b67ef8b\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1712.00636\",\"authors\":[{\"authorId\":\"2978413\",\"name\":\"Chao-Yuan Wu\"},{\"authorId\":\"1771307\",\"name\":\"M. Zaheer\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"1758550\",\"name\":\"R. Manmatha\"},{\"authorId\":\"46234526\",\"name\":\"Alex Smola\"},{\"authorId\":\"2562966\",\"name\":\"Philipp Kr\\u00e4henb\\u00fchl\"}],\"doi\":\"10.1109/CVPR.2018.00631\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9d98a956aadaff727e495b14b7c532d40ea49e16\",\"title\":\"Compressed Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9d98a956aadaff727e495b14b7c532d40ea49e16\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"152821938\",\"name\":\"Sanketh Shetty\"},{\"authorId\":\"120906511\",\"name\":\"T. Leung\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2014.223\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"title\":\"Large-Scale Video Classification with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1503.08909\",\"authors\":[{\"authorId\":\"2340579\",\"name\":\"J. Ng\"},{\"authorId\":\"3308897\",\"name\":\"Matthew J. Hausknecht\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"49519592\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"3089272\",\"name\":\"Rajat Monga\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"}],\"doi\":\"10.1109/CVPR.2015.7299101\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5418b2a482720e013d487a385c26fae0f017c6a6\",\"title\":\"Beyond short snippets: Deep networks for video classification\",\"url\":\"https://www.semanticscholar.org/paper/5418b2a482720e013d487a385c26fae0f017c6a6\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1604.07669\",\"authors\":[{\"authorId\":\"3047890\",\"name\":\"Bowen Zhang\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"}],\"doi\":\"10.1109/CVPR.2016.297\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d4cf68fad61cd7dc9061670ba3864a7fdf87d4c\",\"title\":\"Real-Time Action Recognition with Enhanced Motion Vector CNNs\",\"url\":\"https://www.semanticscholar.org/paper/3d4cf68fad61cd7dc9061670ba3864a7fdf87d4c\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2367683\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":\"10.1109/CVPR.2014.85\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7c0f1b49fd8a5b2ca8116e613a5da10babe5e564\",\"title\":\"Parsing Videos of Actions with Segmental Grammars\",\"url\":\"https://www.semanticscholar.org/paper/7c0f1b49fd8a5b2ca8116e613a5da10babe5e564\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1904.02811\",\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"}],\"doi\":\"10.1109/ICCV.2019.00565\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f4852f5385d60e8870e30db5c65392d120e58574\",\"title\":\"Video Classification With Channel-Separated Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/f4852f5385d60e8870e30db5c65392d120e58574\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1705.08168\",\"authors\":[{\"authorId\":\"2299479\",\"name\":\"R. Arandjelovi\\u0107\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/ICCV.2017.73\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"9b5f696f73c1264ccb8e97d3b738a2342ecd6bee\",\"title\":\"Look, Listen and Learn\",\"url\":\"https://www.semanticscholar.org/paper/9b5f696f73c1264ccb8e97d3b738a2342ecd6bee\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"A. Andonian Zhou\"},{\"authorId\":null,\"name\":\"A. Oliva\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"poral relational reasoning in videos\",\"url\":\"\",\"venue\":\"Computer Vision - ECCV 2018 - 15 th European Conference , Munich , Germany , September 8 - 14 , 2018 , Proceedings , Part I , pages 587 \\u2013 604\",\"year\":null},{\"arxivId\":\"1707.05357\",\"authors\":[{\"authorId\":\"35223379\",\"name\":\"Sumit Shekhar\"},{\"authorId\":\"22234092\",\"name\":\"Dhruv Singal\"},{\"authorId\":\"20400898\",\"name\":\"Harvineet Singh\"},{\"authorId\":\"3419748\",\"name\":\"Manav Kedia\"},{\"authorId\":\"37722215\",\"name\":\"Akhil Shetty\"}],\"doi\":\"10.1109/ICCVW.2017.321\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"21efd287c95b045d929761cbd7c35d331398df21\",\"title\":\"Show and Recall: Learning What Makes Videos Memorable\",\"url\":\"https://www.semanticscholar.org/paper/21efd287c95b045d929761cbd7c35d331398df21\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":\"1409.0575\",\"authors\":[{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"71309570\",\"name\":\"H. Su\"},{\"authorId\":\"2285165\",\"name\":\"J. Krause\"},{\"authorId\":\"145031342\",\"name\":\"S. Satheesh\"},{\"authorId\":\"145423516\",\"name\":\"S. Ma\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-015-0816-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"title\":\"ImageNet Large Scale Visual Recognition Challenge\",\"url\":\"https://www.semanticscholar.org/paper/e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8983218\",\"name\":\"S. Buch\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"2263748\",\"name\":\"Chuanqi Shen\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/CVPR.2017.675\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"352b190acfe19406baee53a169a8732f9b2764d4\",\"title\":\"SST: Single-Stream Temporal Action Proposals\",\"url\":\"https://www.semanticscholar.org/paper/352b190acfe19406baee53a169a8732f9b2764d4\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1007/s11263-015-0859-0\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"16eaa26a84468b27e559215db01c53286808ec2a\",\"title\":\"MoFAP: A Multi-level Representation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/16eaa26a84468b27e559215db01c53286808ec2a\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":\"1605.08110\",\"authors\":[{\"authorId\":\"47968942\",\"name\":\"K. Zhang\"},{\"authorId\":\"38784892\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1007/978-3-319-46478-7_47\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1dbc12e54ceb70f2022f956aa0a46e2706e99962\",\"title\":\"Video Summarization with Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/1dbc12e54ceb70f2022f956aa0a46e2706e99962\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2695601\",\"name\":\"Vadim Kantorov\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"}],\"doi\":\"10.1109/CVPR.2014.332\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"482f7471c708f371cbd7658aa4a48187dc830e17\",\"title\":\"Efficient Feature Extraction, Encoding, and Classification for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/482f7471c708f371cbd7658aa4a48187dc830e17\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1812.05038\",\"authors\":[{\"authorId\":\"2978413\",\"name\":\"Chao-Yuan Wu\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"2681569\",\"name\":\"Haoqi Fan\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2562966\",\"name\":\"Philipp Kr\\u00e4henb\\u00fchl\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/CVPR.2019.00037\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"45cb2cbae5c0b4cc52e524cc191a2f8db674ed42\",\"title\":\"Long-Term Feature Banks for Detailed Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/45cb2cbae5c0b4cc52e524cc191a2f8db674ed42\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1712.06651\",\"authors\":[{\"authorId\":\"2299479\",\"name\":\"R. Arandjelovi\\u0107\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/978-3-030-01246-5_27\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dfc504536e8434eb008680343abb77010965169e\",\"title\":\"Objects that Sound\",\"url\":\"https://www.semanticscholar.org/paper/dfc504536e8434eb008680343abb77010965169e\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"},{\"authorId\":\"38784892\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"25da1b119ba1e0bb602be6ce8492d1e33dbac9ff\",\"title\":\"Diverse Sequential Subset Selection for Supervised Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/25da1b119ba1e0bb602be6ce8492d1e33dbac9ff\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48094509\",\"name\":\"J. Wang\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"}],\"doi\":\"10.1007/978-3-030-01225-0_42\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8c7a962e1076949d8395e8de6aaae026f673b184\",\"title\":\"Learning Discriminative Video Representations Using Adversarial Perturbations\",\"url\":\"https://www.semanticscholar.org/paper/8c7a962e1076949d8395e8de6aaae026f673b184\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1703.01515\",\"authors\":[{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"},{\"authorId\":\"144983134\",\"name\":\"J. Chan\"},{\"authorId\":\"2778637\",\"name\":\"Alireza Zareian\"},{\"authorId\":\"1789840\",\"name\":\"K. Miyazawa\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1109/CVPR.2017.155\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bd3a96a94a9ca7fa62f1aec6e868ca03a56c08b9\",\"title\":\"CDC: Convolutional-De-Convolutional Networks for Precise Temporal Action Localization in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/bd3a96a94a9ca7fa62f1aec6e868ca03a56c08b9\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1512.00795\",\"authors\":[{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1109/CVPR.2016.291\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8d093efcfadda3ac7de7b0e1ca7d9aa2005c2ec3\",\"title\":\"Actions ~ Transformations\",\"url\":\"https://www.semanticscholar.org/paper/8d093efcfadda3ac7de7b0e1ca7d9aa2005c2ec3\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1603.03369\",\"authors\":[{\"authorId\":\"47968942\",\"name\":\"K. Zhang\"},{\"authorId\":\"38784892\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2016.120\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e3db6c8086082acd55f6c95070ad309ecb834517\",\"title\":\"Summary Transfer: Exemplar-Based Subset Selection for Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/e3db6c8086082acd55f6c95070ad309ecb834517\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31745469\",\"name\":\"Y. Zhao\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"119770705\",\"name\":\"L. Wang\"},{\"authorId\":\"152247501\",\"name\":\"Zhirong Wu\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1007/s11263-019-01211-2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9c643f3d4d7d52ab9b64911bb085438ca096275a\",\"title\":\"Temporal Action Detection with Structured Segment Networks\",\"url\":\"https://www.semanticscholar.org/paper/9c643f3d4d7d52ab9b64911bb085438ca096275a\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143798882\",\"name\":\"Mihir Jain\"},{\"authorId\":\"1738975\",\"name\":\"J. C. V. Gemert\"},{\"authorId\":\"1681054\",\"name\":\"H. J\\u00e9gou\"},{\"authorId\":\"1716733\",\"name\":\"P. Bouthemy\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1109/CVPR.2014.100\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"377ad65969b98823dc5f28815d8a01b74fc1b79a\",\"title\":\"Action Localization with Tubelets from Motion\",\"url\":\"https://www.semanticscholar.org/paper/377ad65969b98823dc5f28815d8a01b74fc1b79a\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1007/978-3-319-46487-9_47\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c24bbbc5139eb2f8c5d0579174dbeae5cbaedbfc\",\"title\":\"DAPs: Deep Action Proposals for Action Understanding\",\"url\":\"https://www.semanticscholar.org/paper/c24bbbc5139eb2f8c5d0579174dbeae5cbaedbfc\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3446334\",\"name\":\"Hehe Fan\"},{\"authorId\":\"2351434\",\"name\":\"Zhongwen Xu\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"7590116\",\"name\":\"C. Yan\"},{\"authorId\":\"38263913\",\"name\":\"J. Ge\"},{\"authorId\":null,\"name\":\"Yi Yang\"}],\"doi\":\"10.24963/ijcai.2018/98\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3da5de9c29e007ff2bca0cc9152bcf4dd83fe7a0\",\"title\":\"Watching a Small Portion could be as Good as Watching All: Towards Efficient Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/3da5de9c29e007ff2bca0cc9152bcf4dd83fe7a0\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":\"1711.11248\",\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"4439383\",\"name\":\"Jamie Ray\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/CVPR.2018.00675\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"89c3050522a0bb9820c32dc7444e003ef0d3e2e4\",\"title\":\"A Closer Look at Spatiotemporal Convolutions for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/89c3050522a0bb9820c32dc7444e003ef0d3e2e4\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/978-3-319-54427-4_19\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"87defac1045bfa9af0162cd248d193e9be6eb25b\",\"title\":\"Out of Time: Automated Lip Sync in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/87defac1045bfa9af0162cd248d193e9be6eb25b\",\"venue\":\"ACCV Workshops\",\"year\":2016},{\"arxivId\":\"1707.01083\",\"authors\":[{\"authorId\":\"50875121\",\"name\":\"X. Zhang\"},{\"authorId\":\"47155568\",\"name\":\"X. Zhou\"},{\"authorId\":\"3287035\",\"name\":\"Mengxiao Lin\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/CVPR.2018.00716\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9da734397acd7ff7c557960c62fb1b400b27bd89\",\"title\":\"ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices\",\"url\":\"https://www.semanticscholar.org/paper/9da734397acd7ff7c557960c62fb1b400b27bd89\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1406.2199\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"title\":\"Two-Stream Convolutional Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3037160\",\"name\":\"Michael Gygli\"},{\"authorId\":\"145551629\",\"name\":\"H. Grabner\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2015.7298928\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cfcb9bcc1e8b4d3451578398aeb37f0fa5614632\",\"title\":\"Video summarization by learning submodular mixtures of objectives\",\"url\":\"https://www.semanticscholar.org/paper/cfcb9bcc1e8b4d3451578398aeb37f0fa5614632\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2435677\",\"name\":\"Michele Merler\"},{\"authorId\":\"5113463\",\"name\":\"D. Joshi\"},{\"authorId\":\"2798372\",\"name\":\"Khoi-Nguyen C. Mac\"},{\"authorId\":\"143880942\",\"name\":\"Q. Nguyen\"},{\"authorId\":\"7641415\",\"name\":\"Stephen Hammer\"},{\"authorId\":\"143836309\",\"name\":\"J. Kent\"},{\"authorId\":\"46590281\",\"name\":\"Jinjun Xiong\"},{\"authorId\":\"1834451\",\"name\":\"M. Do\"},{\"authorId\":null,\"name\":\"John R. Smith\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d6d203c51db833c0c3d122fc213c053fdfceeb42\",\"title\":\"The Excitement of Sports: Automatic Highlights Using Audio/Visual Cues\",\"url\":\"https://www.semanticscholar.org/paper/d6d203c51db833c0c3d122fc213c053fdfceeb42\",\"venue\":\"CVPR Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Du Tran\"},{\"authorId\":null,\"name\":\"Heng Wang\"},{\"authorId\":null,\"name\":\"Lorenzo Torresani\"},{\"authorId\":null,\"name\":\"Matt Feiszli\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Classification with channel-separated convolutional net-  works\",\"url\":\"\",\"venue\":\"In IEEE International Conference on Computer Vision,\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1799820\",\"name\":\"Adrien Gaidon\"},{\"authorId\":\"1753355\",\"name\":\"Z. Harchaoui\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/TPAMI.2013.65\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"404352f5c18d4aca97f0cb660a31bf5d0df3fe0c\",\"title\":\"Temporal Localization of Actions with Actoms\",\"url\":\"https://www.semanticscholar.org/paper/404352f5c18d4aca97f0cb660a31bf5d0df3fe0c\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":\"1705.06950\",\"authors\":[{\"authorId\":\"21028601\",\"name\":\"W. Kay\"},{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"11809518\",\"name\":\"Brian Zhang\"},{\"authorId\":\"38961760\",\"name\":\"Chloe Hillier\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"143740871\",\"name\":\"F. Viola\"},{\"authorId\":\"143897708\",\"name\":\"T. Green\"},{\"authorId\":\"2830305\",\"name\":\"T. Back\"},{\"authorId\":\"1820908\",\"name\":\"A. Natsev\"},{\"authorId\":\"2573615\",\"name\":\"Mustafa Suleyman\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6\",\"title\":\"The Kinetics Human Action Video Dataset\",\"url\":\"https://www.semanticscholar.org/paper/86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1610.09001\",\"authors\":[{\"authorId\":\"3152281\",\"name\":\"Y. Aytar\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7ab8d3af6f78f9c9f64a2f2d38471401ad0988a9\",\"title\":\"SoundNet: Learning Sound Representations from Unlabeled Video\",\"url\":\"https://www.semanticscholar.org/paper/7ab8d3af6f78f9c9f64a2f2d38471401ad0988a9\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1806.02964\",\"authors\":[{\"authorId\":\"6873935\",\"name\":\"T. Lin\"},{\"authorId\":\"1758267\",\"name\":\"X. Zhao\"},{\"authorId\":\"13099867\",\"name\":\"Haisheng Su\"},{\"authorId\":\"3004751\",\"name\":\"Chongjing Wang\"},{\"authorId\":\"2909406\",\"name\":\"Ming Yang\"}],\"doi\":\"10.1007/978-3-030-01225-0_1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"49e2b4db35a408e91353578764be9085ac1210da\",\"title\":\"BSN: Boundary Sensitive Network for Temporal Action Proposal Generation\",\"url\":\"https://www.semanticscholar.org/paper/49e2b4db35a408e91353578764be9085ac1210da\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3112334\",\"name\":\"Behrooz Mahasseni\"},{\"authorId\":\"47772841\",\"name\":\"Michael Lam\"},{\"authorId\":\"143856428\",\"name\":\"S. Todorovic\"}],\"doi\":\"10.1109/CVPR.2017.318\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"620fe6c786d15efca7f553ad70f295e2b693b391\",\"title\":\"Unsupervised Video Summarization with Adversarial LSTM Networks\",\"url\":\"https://www.semanticscholar.org/paper/620fe6c786d15efca7f553ad70f295e2b693b391\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1703.06189\",\"authors\":[{\"authorId\":\"3029956\",\"name\":\"J. Gao\"},{\"authorId\":\"3469030\",\"name\":\"Zhenheng Yang\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/ICCV.2017.392\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f94841ec597dcf6d1c23e7f40ba35e121f6a81c1\",\"title\":\"TURN TAP: Temporal Unit Regression Network for Temporal Action Proposals\",\"url\":\"https://www.semanticscholar.org/paper/f94841ec597dcf6d1c23e7f40ba35e121f6a81c1\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017}],\"title\":\"SCSampler: Sampling Salient Clips From Video for Efficient Action Recognition\",\"topics\":[{\"topic\":\"Sampling (signal processing)\",\"topicId\":\"7839\",\"url\":\"https://www.semanticscholar.org/topic/7839\"},{\"topic\":\"Algorithmic efficiency\",\"topicId\":\"19973\",\"url\":\"https://www.semanticscholar.org/topic/19973\"},{\"topic\":\"Computation\",\"topicId\":\"339\",\"url\":\"https://www.semanticscholar.org/topic/339\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Information\",\"topicId\":\"185548\",\"url\":\"https://www.semanticscholar.org/topic/185548\"},{\"topic\":\"Randomness\",\"topicId\":\"726\",\"url\":\"https://www.semanticscholar.org/topic/726\"},{\"topic\":\"Greater Than\",\"topicId\":\"344\",\"url\":\"https://www.semanticscholar.org/topic/344\"},{\"topic\":\"Collections (publication)\",\"topicId\":\"23835\",\"url\":\"https://www.semanticscholar.org/topic/23835\"},{\"topic\":\"videocassette\",\"topicId\":\"20721\",\"url\":\"https://www.semanticscholar.org/topic/20721\"},{\"topic\":\"Sampling - Surgical action\",\"topicId\":\"2142\",\"url\":\"https://www.semanticscholar.org/topic/2142\"}],\"url\":\"https://www.semanticscholar.org/paper/2aed352cdd78010f72eaf618d52a4793fab32cea\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019}\n"