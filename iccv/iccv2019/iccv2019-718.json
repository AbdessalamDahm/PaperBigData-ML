"{\"abstract\":\"The explosive growth in video streaming gives rise to challenges on performing video understanding at high accuracy and low computation cost. Conventional 2D CNNs are computationally cheap but cannot capture temporal relationships; 3D CNN based methods can achieve good performance but are computationally intensive, making it expensive to deploy. In this paper, we propose a generic and effective Temporal Shift Module (TSM) that enjoys both high efficiency and high performance. Specifically, it can achieve the performance of 3D CNN but maintain 2D CNN\\u2019s complexity. TSM shifts part of the channels along the temporal dimension; thus facilitate information exchanged among neighboring frames. It can be inserted into 2D CNNs to achieve temporal modeling at zero computation and zero parameters. We also extended TSM to online setting, which enables real-time low-latency online video recognition and video object detection. TSM is accurate and efficient: it ranks the first place on the Something-Something leaderboard upon publication; on Jetson Nano and Galaxy Note8, it achieves a low latency of 13ms and 35ms for online video recognition. The code is available at: https://github. com/mit-han-lab/temporal-shift-module.\",\"arxivId\":\"1811.08383\",\"authors\":[{\"authorId\":\"46698300\",\"name\":\"Ji Lin\",\"url\":\"https://www.semanticscholar.org/author/46698300\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\",\"url\":\"https://www.semanticscholar.org/author/144158271\"},{\"authorId\":\"143840275\",\"name\":\"Song Han\",\"url\":\"https://www.semanticscholar.org/author/143840275\"}],\"citationVelocity\":96,\"citations\":[{\"arxivId\":\"1910.00932\",\"authors\":[{\"authorId\":\"93318099\",\"name\":\"J. Lin\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"143840270\",\"name\":\"S. Han\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9739f39feacca0550eff8ac42a92445efdce31c8\",\"title\":\"Training Kinetics in 15 Minutes: Large-scale Distributed Training on Videos\",\"url\":\"https://www.semanticscholar.org/paper/9739f39feacca0550eff8ac42a92445efdce31c8\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2465856\",\"name\":\"Yen-Chia Hsu\"},{\"authorId\":\"40324443\",\"name\":\"Ting-Hao Huang\"},{\"authorId\":\"2998709\",\"name\":\"Ting-yao Hu\"},{\"authorId\":\"6336229\",\"name\":\"P. Dille\"},{\"authorId\":\"1693980281\",\"name\":\"Sean Prendi\"},{\"authorId\":\"12628113\",\"name\":\"R. Hoffman\"},{\"authorId\":\"1693976434\",\"name\":\"Anastasia Tsuhlares\"},{\"authorId\":\"144669295\",\"name\":\"R. Sargent\"},{\"authorId\":\"84502304\",\"name\":\"Illah Nourbakhsh\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2ffeb6a9d4cad479b61ed72807d42eb9ea29d811\",\"title\":\"RISE Video Dataset: Recognizing Industrial Smoke Emissions\",\"url\":\"https://www.semanticscholar.org/paper/2ffeb6a9d4cad479b61ed72807d42eb9ea29d811\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.06866\",\"authors\":[{\"authorId\":\"150348841\",\"name\":\"Yuchi Ishikawa\"},{\"authorId\":\"1381411615\",\"name\":\"Seito Kasai\"},{\"authorId\":\"10664005\",\"name\":\"Y. Aoki\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4fed0235614df46fa0c53e05b71e9939b53a1bdf\",\"title\":\"Alleviating Over-segmentation Errors by Detecting Action Boundaries\",\"url\":\"https://www.semanticscholar.org/paper/4fed0235614df46fa0c53e05b71e9939b53a1bdf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yikai Wang\"},{\"authorId\":\"2323566\",\"name\":\"Fu-Chun Sun\"},{\"authorId\":\"145871213\",\"name\":\"M. Lu\"},{\"authorId\":\"1405606408\",\"name\":\"Anbang Yao\"}],\"doi\":\"10.1145/3394171.3413621\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ad6ab45aff7d6a390a070fc3c1149db05771f26f\",\"title\":\"Learning Deep Multimodal Feature Representation with Asymmetric Multi-layer Fusion\",\"url\":\"https://www.semanticscholar.org/paper/ad6ab45aff7d6a390a070fc3c1149db05771f26f\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2005.02113\",\"authors\":[{\"authorId\":\"47892681\",\"name\":\"Haoxin Li\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"},{\"authorId\":\"1401057385\",\"name\":\"Yu Tao\"},{\"authorId\":\"37403439\",\"name\":\"H. Hu\"},{\"authorId\":\"153224231\",\"name\":\"Jianhuang Lai\"}],\"doi\":\"10.1109/CVPR42600.2020.00060\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5c02af517dff2ff0d34dee04535731b7d252bbbb\",\"title\":\"Adaptive Interaction Modeling via Graph Operations Search\",\"url\":\"https://www.semanticscholar.org/paper/5c02af517dff2ff0d34dee04535731b7d252bbbb\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2001.05661\",\"authors\":[{\"authorId\":\"143657833\",\"name\":\"Li Tao\"},{\"authorId\":\"1524733293\",\"name\":\"Xueting Wang\"},{\"authorId\":\"145572095\",\"name\":\"T. Yamasaki\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"18726788e8a74aed4420745fc420dddd3950e1c6\",\"title\":\"Rethinking Motion Representation: Residual Frames with 3D ConvNets for Better Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/18726788e8a74aed4420745fc420dddd3950e1c6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121520308\",\"name\":\"J. Wilson\"},{\"authorId\":\"143953664\",\"name\":\"M. Lin\"}],\"doi\":\"10.1109/ICRA40945.2020.9197528\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ad1a80255027836b71137f3a05bf631ba0ee1821\",\"title\":\"AVOT: Audio-Visual Object Tracking of Multiple Objects for Robotics\",\"url\":\"https://www.semanticscholar.org/paper/ad1a80255027836b71137f3a05bf631ba0ee1821\",\"venue\":\"2020 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2020},{\"arxivId\":\"2009.14661\",\"authors\":[{\"authorId\":\"1500399016\",\"name\":\"Tong Yu\"},{\"authorId\":\"2655297\",\"name\":\"Nicolas Padoy\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c386b73f74c2e7f91217bb65504d8725e17b81e\",\"title\":\"Encode the Unseen: Predictive Video Hashing for Scalable Mid-Stream Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/2c386b73f74c2e7f91217bb65504d8725e17b81e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1596808016\",\"name\":\"Xiaohan Wang\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"50118837\",\"name\":\"Y. Wu\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1109/tpami.2020.3015894\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7401d3895e1cb78c34fa25db12409fdff56b1661\",\"title\":\"Symbiotic Attention for Egocentric Action Recognition with Object-centric Alignment.\",\"url\":\"https://www.semanticscholar.org/paper/7401d3895e1cb78c34fa25db12409fdff56b1661\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"2007.09033\",\"authors\":[{\"authorId\":\"16323128\",\"name\":\"Guoxi Huang\"},{\"authorId\":\"1707271\",\"name\":\"Adrian G. Bors\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"215182fe19015d315cae9cd2c39e3a576b7193bf\",\"title\":\"Region-based Non-local Operation for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/215182fe19015d315cae9cd2c39e3a576b7193bf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.08510\",\"authors\":[{\"authorId\":\"144234446\",\"name\":\"Bo He\"},{\"authorId\":\"50031265\",\"name\":\"Xitong Yang\"},{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"48444479\",\"name\":\"Hao Chen\"},{\"authorId\":\"38760573\",\"name\":\"Ser-Nam Lim\"},{\"authorId\":\"51453757\",\"name\":\"Abhinav Shrivastava\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b77967866434f46c41f25baf7149d9b027b600b3\",\"title\":\"GTA: Global Temporal Attention for Video Action Understanding\",\"url\":\"https://www.semanticscholar.org/paper/b77967866434f46c41f25baf7149d9b027b600b3\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2007.09883\",\"authors\":[{\"authorId\":\"13099867\",\"name\":\"Haisheng Su\"},{\"authorId\":\"153285206\",\"name\":\"J. Feng\"},{\"authorId\":\"46798949\",\"name\":\"H. Shao\"},{\"authorId\":\"1768672172\",\"name\":\"Zhenyu Jiang\"},{\"authorId\":\"40951853\",\"name\":\"Manyuan Zhang\"},{\"authorId\":\"145717875\",\"name\":\"Wei Wu\"},{\"authorId\":\"30752055\",\"name\":\"Y. Liu\"},{\"authorId\":\"119885708\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3e7b4c49ad5754e9d7e9019684a777ae66ee5eed\",\"title\":\"Complementary Boundary Generator with Scale-Invariant Relation Modeling for Temporal Action Localization: Submission to ActivityNet Challenge 2020\",\"url\":\"https://www.semanticscholar.org/paper/3e7b4c49ad5754e9d7e9019684a777ae66ee5eed\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31790681\",\"name\":\"Shuya Ding\"},{\"authorId\":\"48354826\",\"name\":\"Z. Chen\"},{\"authorId\":\"1750918854\",\"name\":\"Tianyue Zheng\"},{\"authorId\":\"34309103\",\"name\":\"Jun Luo\"}],\"doi\":\"10.1145/3384419.3430735\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cc75fb803a1c594935219dd5458f5f712d16bde3\",\"title\":\"RF-net: a unified meta-learning framework for RF-enabled one-shot human activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/cc75fb803a1c594935219dd5458f5f712d16bde3\",\"venue\":\"SenSys\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49372683\",\"name\":\"Niamul Quader\"},{\"authorId\":\"150152476\",\"name\":\"Juwei Lu\"},{\"authorId\":\"144287598\",\"name\":\"Peng Dai\"},{\"authorId\":\"122009001\",\"name\":\"Wei Li\"}],\"doi\":\"10.1007/978-3-030-58577-8_3\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"080039e68707b483e5c3c27f38660acc1e51ddde\",\"title\":\"Towards Efficient Coarse-to-Fine Networks for Action and Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/080039e68707b483e5c3c27f38660acc1e51ddde\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2004.07711\",\"authors\":[{\"authorId\":\"1637242169\",\"name\":\"Guglielmo Camporese\"},{\"authorId\":\"29776698\",\"name\":\"Pasquale Coscia\"},{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"},{\"authorId\":\"1795847\",\"name\":\"Lamberto Ballan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dc24772bf84d9ff92166d8f228284c4079619ed0\",\"title\":\"Knowledge Distillation for Action Anticipation via Label Smoothing\",\"url\":\"https://www.semanticscholar.org/paper/dc24772bf84d9ff92166d8f228284c4079619ed0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1485630780\",\"name\":\"Yanbin Hao\"},{\"authorId\":\"145063759\",\"name\":\"Hao Zhang\"},{\"authorId\":\"143977389\",\"name\":\"C. Ngo\"},{\"authorId\":\"48874063\",\"name\":\"Q. Liu\"},{\"authorId\":\"144635784\",\"name\":\"X. Hu\"}],\"doi\":\"10.1145/3394171.3413595\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1e29826ff34cc39f04d23784ad8ec6649717e1ce\",\"title\":\"Compact Bilinear Augmented Query Structured Attention for Sport Highlights Classification\",\"url\":\"https://www.semanticscholar.org/paper/1e29826ff34cc39f04d23784ad8ec6649717e1ce\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1912.03613\",\"authors\":[{\"authorId\":\"2542995\",\"name\":\"T. Kim\"},{\"authorId\":\"143954557\",\"name\":\"J. Jones\"},{\"authorId\":\"51207689\",\"name\":\"Michael Peven\"},{\"authorId\":\"9381483\",\"name\":\"Zihao Xiao\"},{\"authorId\":\"144878724\",\"name\":\"J. Bai\"},{\"authorId\":\"48379752\",\"name\":\"Yufu Zhang\"},{\"authorId\":\"3256056\",\"name\":\"Weichao Qiu\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"},{\"authorId\":\"1678633\",\"name\":\"Gregory Hager\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f888f518c79e52debe6646c68049d87d0b0555cd\",\"title\":\"DASZL: Dynamic Action Signatures for Zero-shot Learning\",\"url\":\"https://www.semanticscholar.org/paper/f888f518c79e52debe6646c68049d87d0b0555cd\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123266340\",\"name\":\"Chuanhe Liu\"},{\"authorId\":\"87034557\",\"name\":\"W. Jiang\"},{\"authorId\":\"47447148\",\"name\":\"Minghao Wang\"},{\"authorId\":\"2342818\",\"name\":\"T. Tang\"}],\"doi\":\"10.1145/3382507.3417968\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"264d38fb71ccc85c91a7f89680e62d86da4dc807\",\"title\":\"Group Level Audio-Video Emotion Recognition Using Hybrid Networks\",\"url\":\"https://www.semanticscholar.org/paper/264d38fb71ccc85c91a7f89680e62d86da4dc807\",\"venue\":\"ICMI\",\"year\":2020},{\"arxivId\":\"2007.12887\",\"authors\":[{\"authorId\":\"26415158\",\"name\":\"Xinqi Zhu\"},{\"authorId\":\"153250308\",\"name\":\"C. Xu\"},{\"authorId\":\"102853050\",\"name\":\"L. Hui\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/ICCV.2019.00359\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7303ce1fe8f54f45e4558eb81368bda9dfe2793f\",\"title\":\"Approximated Bilinear Modules for Temporal Modeling\",\"url\":\"https://www.semanticscholar.org/paper/7303ce1fe8f54f45e4558eb81368bda9dfe2793f\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2498892\",\"name\":\"Pengxiang Wu\"},{\"authorId\":\"1814286\",\"name\":\"Siheng Chen\"},{\"authorId\":\"1711560\",\"name\":\"Dimitris N. Metaxas\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6234435197b5325b0b9caf2f5336c2e41e93a268\",\"title\":\"MotionNet: Joint Perception and Motion Prediction for Autonomous Driving Based on Birda\\u0302\\u2022Z\\u030cs Eye View Maps /Author=Wu, Pengxiang; Chen, Siheng /CreationDate=June 9, 2020 /Subject=Artificial Intelligence, Computer Vision, Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/6234435197b5325b0b9caf2f5336c2e41e93a268\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1657264680\",\"name\":\"Cece Jin\"},{\"authorId\":\"1500522440\",\"name\":\"T. Zhang\"},{\"authorId\":\"33559754\",\"name\":\"Weijie Kong\"},{\"authorId\":\"50289966\",\"name\":\"Thomas H. Li\"},{\"authorId\":\"46439321\",\"name\":\"Ge Li\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053319\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eda43d4c38d7af6cf1dac123fcdd8b8a411e0e1a\",\"title\":\"Regression Before Classification for Temporal Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/eda43d4c38d7af6cf1dac123fcdd8b8a411e0e1a\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48093549\",\"name\":\"Jinpeng Wang\"},{\"authorId\":\"29995014\",\"name\":\"Shiren Li\"},{\"authorId\":\"30646831\",\"name\":\"Zhi-kui Duan\"},{\"authorId\":\"48803999\",\"name\":\"Z. Yuan\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053794\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a021daf17351415827420456377f77f6a146fd56\",\"title\":\"Rethinking Temporal-Related Sample for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a021daf17351415827420456377f77f6a146fd56\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"2009.08427\",\"authors\":[{\"authorId\":\"51011850\",\"name\":\"Iulia Duta\"},{\"authorId\":\"50986865\",\"name\":\"A. Nicolicioiu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"343f14319d5e34c37eeb86dea88fa82f56715679\",\"title\":\"Dynamic Regions Graph Neural Networks for Spatio-Temporal Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/343f14319d5e34c37eeb86dea88fa82f56715679\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46578437\",\"name\":\"K. Liu\"},{\"authorId\":\"13384075\",\"name\":\"Minzhi Zhu\"},{\"authorId\":\"2513605\",\"name\":\"Huiyuan Fu\"},{\"authorId\":\"40013029\",\"name\":\"Hua-Dong Ma\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1145/3394171.3416298\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"eaf34194a0e86fc5ed29a258594fa580b828e997\",\"title\":\"Enhancing Anomaly Detection in Surveillance Videos with Transfer Learning from Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eaf34194a0e86fc5ed29a258594fa580b828e997\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2004.04981\",\"authors\":[{\"authorId\":\"1491233177\",\"name\":\"Yizhou Zhou\"},{\"authorId\":\"6485172\",\"name\":\"Xiaoyan Sun\"},{\"authorId\":\"2820418\",\"name\":\"Chong Luo\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"}],\"doi\":\"10.1109/cvpr42600.2020.00985\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e7ca185e3a4515471c2b9a411da9f264d55ea563\",\"title\":\"Spatiotemporal Fusion in 3D CNNs: A Probabilistic View\",\"url\":\"https://www.semanticscholar.org/paper/e7ca185e3a4515471c2b9a411da9f264d55ea563\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2005.08637\",\"authors\":[{\"authorId\":\"2831859\",\"name\":\"Xiang-jun Peng\"},{\"authorId\":\"12318262\",\"name\":\"Z. Huang\"},{\"authorId\":\"2511091\",\"name\":\"X. Sun\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7921c4258abf3f44208d86220a35b9cd228d21da\",\"title\":\"Building BROOK: A Multi-modal and Facial Video Database for Human-Vehicle Interaction Research\",\"url\":\"https://www.semanticscholar.org/paper/7921c4258abf3f44208d86220a35b9cd228d21da\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1811.08362\",\"authors\":[{\"authorId\":\"91060830\",\"name\":\"Zhiyu Yao\"},{\"authorId\":null,\"name\":\"Yunbo Wang\"},{\"authorId\":\"35776445\",\"name\":\"Mingsheng Long\"},{\"authorId\":\"1519286448\",\"name\":\"J. Wang\"},{\"authorId\":\"144019071\",\"name\":\"Philip S. Yu\"},{\"authorId\":\"153552276\",\"name\":\"J. Sun\"}],\"doi\":\"10.1109/ICME46284.2020.9102724\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"371ab565b512a5ef9133831c8b7b04fb5b1905c4\",\"title\":\"Multi-Task Learning of Generalizable Representations for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/371ab565b512a5ef9133831c8b7b04fb5b1905c4\",\"venue\":\"2020 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2020},{\"arxivId\":\"2004.03548\",\"authors\":[{\"authorId\":\"49984891\",\"name\":\"Ceyuan Yang\"},{\"authorId\":\"121983635\",\"name\":\"Yinghao Xu\"},{\"authorId\":\"46865320\",\"name\":\"Jianping Shi\"},{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"}],\"doi\":\"10.1109/cvpr42600.2020.00067\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"10db26c80238d70ca51d8a5293d893b6f1dedc8b\",\"title\":\"Temporal Pyramid Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/10db26c80238d70ca51d8a5293d893b6f1dedc8b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2011.11479\",\"authors\":[{\"authorId\":\"19198894\",\"name\":\"Humam Alwassel\"},{\"authorId\":\"22314218\",\"name\":\"Silvio Giancola\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5388388db25f0d40ef6612333a0279373f8dddcf\",\"title\":\"TSP: Temporally-Sensitive Pretraining of Video Encoders for Localization Tasks\",\"url\":\"https://www.semanticscholar.org/paper/5388388db25f0d40ef6612333a0279373f8dddcf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1912.09930\",\"authors\":[{\"authorId\":\"7654960\",\"name\":\"Joanna Materzynska\"},{\"authorId\":\"15727192\",\"name\":\"Tete Xiao\"},{\"authorId\":\"46796686\",\"name\":\"Roei Herzig\"},{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"39635018\",\"name\":\"Xiaolong Wang\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/cvpr42600.2020.00113\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"af06120e7883ff969746ab473bfe09e642a90fc3\",\"title\":\"Something-Else: Compositional Action Recognition With Spatial-Temporal Interaction Networks\",\"url\":\"https://www.semanticscholar.org/paper/af06120e7883ff969746ab473bfe09e642a90fc3\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2006.13256\",\"authors\":[{\"authorId\":\"1677780022\",\"name\":\"Dima Damen\"},{\"authorId\":\"28798386\",\"name\":\"H. Doughty\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"},{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"48842721\",\"name\":\"Evangelos Kazakos\"},{\"authorId\":\"153155867\",\"name\":\"Jian Ma\"},{\"authorId\":\"3420479\",\"name\":\"D. Moltisanti\"},{\"authorId\":\"47077615\",\"name\":\"J. Munro\"},{\"authorId\":\"2682004\",\"name\":\"T. Perrett\"},{\"authorId\":\"50065546\",\"name\":\"W. Price\"},{\"authorId\":\"145032628\",\"name\":\"Michael Wray\"}],\"doi\":\"10.5523/bris.2g1n6qdydwa9u22shpxqzp0t8m\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c1a80daadab9c3bc3fdf183c669070ba7a3fd37\",\"title\":\"Rescaling Egocentric Vision\",\"url\":\"https://www.semanticscholar.org/paper/6c1a80daadab9c3bc3fdf183c669070ba7a3fd37\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.05689\",\"authors\":[{\"authorId\":\"1845885740\",\"name\":\"Rui Yan\"},{\"authorId\":\"3041937\",\"name\":\"Lingxi Xie\"},{\"authorId\":\"2287686\",\"name\":\"Xiangbo Shu\"},{\"authorId\":\"8053308\",\"name\":\"J. Tang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f40225f23d46fd15d35b1529427f2f6055c737d4\",\"title\":\"Interactive Fusion of Multi-level Features for Compositional Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f40225f23d46fd15d35b1529427f2f6055c737d4\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2012.06977\",\"authors\":[{\"authorId\":\"47203405\",\"name\":\"Wenhao Wu\"},{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"6873935\",\"name\":\"T. Lin\"},{\"authorId\":\"1998948807\",\"name\":\"F. Li\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"12081764\",\"name\":\"E. Ding\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6e71b58ea6668dd3872e0c9e6cdd258b4582e2a\",\"title\":\"MVFNet: Multi-View Fusion Network for Efficient Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a6e71b58ea6668dd3872e0c9e6cdd258b4582e2a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2002.03152\",\"authors\":[{\"authorId\":\"47968272\",\"name\":\"Li-Yu Daisy Liu\"},{\"authorId\":\"1491094850\",\"name\":\"Tao Wang\"},{\"authorId\":\"49723003\",\"name\":\"J. Liu\"},{\"authorId\":\"50463545\",\"name\":\"Yang Guan\"},{\"authorId\":\"9963055\",\"name\":\"Qi Bu\"},{\"authorId\":\"49576139\",\"name\":\"Longfei Yang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9f0320cd101ed6426a4330ecb395015c266e976c\",\"title\":\"CTM: Collaborative Temporal Modeling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9f0320cd101ed6426a4330ecb395015c266e976c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.10830\",\"authors\":[{\"authorId\":\"97375393\",\"name\":\"Mengmeng Xu\"},{\"authorId\":\"1397974082\",\"name\":\"Juan-Manuel Perez-Rua\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"145944235\",\"name\":\"B. Mart\\u00ednez\"},{\"authorId\":\"2171228\",\"name\":\"Xiatian Zhu\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"145406420\",\"name\":\"Tao Xiang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cdc28eb98cd4e5fa28811f4ea6dbe7c64d5fcffe\",\"title\":\"Boundary-sensitive Pre-training for Temporal Localization in Videos\",\"url\":\"https://www.semanticscholar.org/paper/cdc28eb98cd4e5fa28811f4ea6dbe7c64d5fcffe\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1908.09442\",\"authors\":[{\"authorId\":\"47057388\",\"name\":\"X. Li\"},{\"authorId\":\"6873935\",\"name\":\"T. Lin\"},{\"authorId\":\"153201747\",\"name\":\"Xiao Liu\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"1724520\",\"name\":\"W. Zuo\"},{\"authorId\":\"46651287\",\"name\":\"C. Li\"},{\"authorId\":\"46550771\",\"name\":\"X. Long\"},{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"32379958\",\"name\":\"Fu Li\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"}],\"doi\":\"10.1145/3394171.3413860\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"317e0392d2a830df88dd093df01ef4d2943e5c96\",\"title\":\"Deep Concept-wise Temporal Convolutional Networks for Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/317e0392d2a830df88dd093df01ef4d2943e5c96\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1908.09995\",\"authors\":[{\"authorId\":\"2659862\",\"name\":\"J. Zhang\"},{\"authorId\":\"38083193\",\"name\":\"F. Shen\"},{\"authorId\":\"1390532590\",\"name\":\"Xing Xu\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1109/TIP.2020.2985219\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f3b9458522b828c39b1a7d7a9ffa15eae0789bfc\",\"title\":\"Temporal Reasoning Graph for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f3b9458522b828c39b1a7d7a9ffa15eae0789bfc\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"2008.01232\",\"authors\":[{\"authorId\":\"1395788009\",\"name\":\"M. E. Kalfaoglu\"},{\"authorId\":\"1699609\",\"name\":\"Sinan Kalkan\"},{\"authorId\":\"1751998\",\"name\":\"Aydin Alatan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"dce965db955113b3710c9977dc5f68f3bfd85c4b\",\"title\":\"Late Temporal Modeling in 3D CNN Architectures with BERT for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/dce965db955113b3710c9977dc5f68f3bfd85c4b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3275727\",\"name\":\"Linxi (Jim) Fan\"},{\"authorId\":\"8983218\",\"name\":\"S. Buch\"},{\"authorId\":\"96374437\",\"name\":\"Guanzhi Wang\"},{\"authorId\":\"2013547017\",\"name\":\"Ryan Cao\"},{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/978-3-030-58529-7_30\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3ab0c5006bb157b801ec592951a1da2c8af9d158\",\"title\":\"RubiksNet: Learnable 3D-Shift for Efficient Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3ab0c5006bb157b801ec592951a1da2c8af9d158\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"144746444\",\"name\":\"H. Bischof\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"},{\"authorId\":\"40454588\",\"name\":\"J. Frahm\"}],\"doi\":\"10.1007/978-3-030-58539-6\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"72eb837c0d113dcdd51e57958e58d48e1759ea0f\",\"title\":\"Computer Vision \\u2013 ECCV 2020: 16th European Conference, Glasgow, UK, August 23\\u201328, 2020, Proceedings, Part VI\",\"url\":\"https://www.semanticscholar.org/paper/72eb837c0d113dcdd51e57958e58d48e1759ea0f\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2008.05721\",\"authors\":[{\"authorId\":\"48271129\",\"name\":\"T. Kim\"},{\"authorId\":\"98080420\",\"name\":\"H. Lee\"},{\"authorId\":\"1387831061\",\"name\":\"MyeongAh Cho\"},{\"authorId\":\"48411936\",\"name\":\"H. Lee\"},{\"authorId\":\"80069330\",\"name\":\"Dong Heon Cho\"},{\"authorId\":\"39847092\",\"name\":\"Sangyoun Lee\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"24b300420bd814e48b59a3419a22d706da6c4191\",\"title\":\"Learning Temporally Invariant and Localizable Features via Data Augmentation for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/24b300420bd814e48b59a3419a22d706da6c4191\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1527097295\",\"name\":\"Yue Li\"},{\"authorId\":\"31399226\",\"name\":\"Wenrui Ding\"},{\"authorId\":\"2563751\",\"name\":\"Y. Zhu\"},{\"authorId\":\"46843692\",\"name\":\"Yuanjun Huang\"},{\"authorId\":\"9325297\",\"name\":\"Yalong Jiang\"},{\"authorId\":\"46242227\",\"name\":\"B. Zhang\"}],\"doi\":\"10.1109/ICIP40778.2020.9191306\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a3f7e4074a356474113cdb6cb4c7ca7cb3e097d5\",\"title\":\"Cam-Net: Compressed Attentive Multi-Granularity Network For Dynamic Scene Classification\",\"url\":\"https://www.semanticscholar.org/paper/a3f7e4074a356474113cdb6cb4c7ca7cb3e097d5\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"2012.00317\",\"authors\":[{\"authorId\":\"3445691\",\"name\":\"Youngwan Lee\"},{\"authorId\":\"2645625\",\"name\":\"H. Kim\"},{\"authorId\":\"35323281\",\"name\":\"Kimin Yun\"},{\"authorId\":\"3035146\",\"name\":\"Jinyoung Moon\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"87b2f4542659801ab5b4baddbd88b2a7d1296726\",\"title\":\"Diverse Temporal Aggregation and Depthwise Spatiotemporal Factorization for Efficient Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/87b2f4542659801ab5b4baddbd88b2a7d1296726\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.11040\",\"authors\":[{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"2521776\",\"name\":\"B. Shuai\"},{\"authorId\":\"2397422\",\"name\":\"Joseph Tighe\"}],\"doi\":\"10.1007/978-3-030-58539-6_17\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c40990d00633b63caf78082f8570a55e2ec5abbb\",\"title\":\"Directional Temporal Modeling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c40990d00633b63caf78082f8570a55e2ec5abbb\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1911.11319\",\"authors\":[{\"authorId\":\"1384480816\",\"name\":\"Pingchuan Ma\"},{\"authorId\":\"120026268\",\"name\":\"Yao Zhou\"},{\"authorId\":null,\"name\":\"Yu Lu\"},{\"authorId\":\"1726357\",\"name\":\"Wayne Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3b5829a65c4eb19ec8922a1575c6900d5f94046f\",\"title\":\"Learning Efficient Video Representation with Video Shuffle Networks\",\"url\":\"https://www.semanticscholar.org/paper/3b5829a65c4eb19ec8922a1575c6900d5f94046f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2006.03790\",\"authors\":[{\"authorId\":\"97713266\",\"name\":\"X. Liu\"},{\"authorId\":\"71908954\",\"name\":\"J. Fromm\"},{\"authorId\":\"1701358\",\"name\":\"S. Patel\"},{\"authorId\":\"1381192475\",\"name\":\"Daniel McDuff\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"70e01f8de3cc71023f57c23cde7c37d3408a7858\",\"title\":\"Multi-Task Temporal Shift Attention Networks for On-Device Contactless Vitals Measurement\",\"url\":\"https://www.semanticscholar.org/paper/70e01f8de3cc71023f57c23cde7c37d3408a7858\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2007.10321\",\"authors\":[{\"authorId\":\"50031265\",\"name\":\"Xitong Yang\"},{\"authorId\":\"40058797\",\"name\":\"Xiaodong Yang\"},{\"authorId\":\"2391885\",\"name\":\"Sifei Liu\"},{\"authorId\":\"3232265\",\"name\":\"Deqing Sun\"},{\"authorId\":\"152296574\",\"name\":\"L. Davis\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1cedd24562c1e95415b246a1a0e9912d8de6f0f7\",\"title\":\"Hierarchical Contrastive Motion Learning for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1cedd24562c1e95415b246a1a0e9912d8de6f0f7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.06567\",\"authors\":[{\"authorId\":\"1805946041\",\"name\":\"Yi Zhu\"},{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"49046944\",\"name\":\"C. Liu\"},{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"22539483\",\"name\":\"Chongruo Wu\"},{\"authorId\":\"152781163\",\"name\":\"Z. Zhang\"},{\"authorId\":\"2397422\",\"name\":\"Joseph Tighe\"},{\"authorId\":\"1758550\",\"name\":\"R. Manmatha\"},{\"authorId\":\"49140510\",\"name\":\"M. Li\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ee12f02830a5e1f7cadd3623dfed495cf099bc82\",\"title\":\"A Comprehensive Study of Deep Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ee12f02830a5e1f7cadd3623dfed495cf099bc82\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491240780\",\"name\":\"Z. Shi\"},{\"authorId\":\"1491233401\",\"name\":\"Liangjie Cao\"},{\"authorId\":\"153747406\",\"name\":\"Cheng Guan\"},{\"authorId\":\"1993660232\",\"name\":\"Ju Liang\"},{\"authorId\":\"48934241\",\"name\":\"Qianqian Li\"},{\"authorId\":\"29344734\",\"name\":\"Zhaorui Gu\"},{\"authorId\":\"2336297\",\"name\":\"Haiyong Zheng\"},{\"authorId\":\"49721778\",\"name\":\"Bing Zheng\"}],\"doi\":\"10.1145/3394171.3413646\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c0d5f622f775d02e90b715b80485dbcab250e7bd\",\"title\":\"Multi-Group Multi-Attention: Towards Discriminative Spatiotemporal Representation\",\"url\":\"https://www.semanticscholar.org/paper/c0d5f622f775d02e90b715b80485dbcab250e7bd\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2004.04730\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"}],\"doi\":\"10.1109/cvpr42600.2020.00028\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"908cca0abefc35acc38033603714fbb1bcadc49d\",\"title\":\"X3D: Expanding Architectures for Efficient Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/908cca0abefc35acc38033603714fbb1bcadc49d\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2005.01969\",\"authors\":[{\"authorId\":\"47988339\",\"name\":\"Jiancheng Yang\"},{\"authorId\":null,\"name\":\"Yi He\"},{\"authorId\":\"97620448\",\"name\":\"Xiaoyang. Huang\"},{\"authorId\":\"47882735\",\"name\":\"Jingwei Xu\"},{\"authorId\":\"7928963\",\"name\":\"Xiaodan Ye\"},{\"authorId\":\"14211284\",\"name\":\"Guangyu Tao\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"}],\"doi\":\"10.1007/978-3-030-59719-1_55\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3f3a8cf6c173af24d98f7d94bc9f18ed53fc9c50\",\"title\":\"AlignShift: Bridging the Gap of Imaging Thickness in 3D Anisotropic Volumes\",\"url\":\"https://www.semanticscholar.org/paper/3f3a8cf6c173af24d98f7d94bc9f18ed53fc9c50\",\"venue\":\"MICCAI\",\"year\":2020},{\"arxivId\":\"2011.07949\",\"authors\":[{\"authorId\":\"4965440\",\"name\":\"Peihao Chen\"},{\"authorId\":\"145592817\",\"name\":\"D. Huang\"},{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"46550737\",\"name\":\"Xiang Long\"},{\"authorId\":\"147992804\",\"name\":\"Runhao Zeng\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2336388131b3cb41eb44e927aeac10a1dabbedad\",\"title\":\"RSPNet: Relative Speed Perception for Unsupervised Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/2336388131b3cb41eb44e927aeac10a1dabbedad\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.06902\",\"authors\":[{\"authorId\":\"13099867\",\"name\":\"Haisheng Su\"},{\"authorId\":\"1768759403\",\"name\":\"Jing Su\"},{\"authorId\":\"1605763279\",\"name\":\"Dongliang Wang\"},{\"authorId\":\"35893447\",\"name\":\"W. Gan\"},{\"authorId\":\"145717875\",\"name\":\"Wei Wu\"},{\"authorId\":\"47446949\",\"name\":\"M. Wang\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\"},{\"authorId\":\"145858545\",\"name\":\"Y. Qiao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"882a973e02bfe9717f4ad70fe9fb327a515b16ca\",\"title\":\"Collaborative Distillation in the Parameter and Spectrum Domains for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/882a973e02bfe9717f4ad70fe9fb327a515b16ca\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.04567\",\"authors\":[{\"authorId\":\"71222753\",\"name\":\"Yongchao Liu\"},{\"authorId\":\"152804142\",\"name\":\"Yue Jin\"},{\"authorId\":\"50581390\",\"name\":\"Y. Chen\"},{\"authorId\":\"1400841106\",\"name\":\"Teng Teng\"},{\"authorId\":\"113375900\",\"name\":\"Hang Ou\"},{\"authorId\":\"1395873384\",\"name\":\"Rui Zhao\"},{\"authorId\":\"1611287648\",\"name\":\"Yao Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"21066f476b04b602b40e73f494b577f7eb660e75\",\"title\":\"Woodpecker-DL: Accelerating Deep Neural Networks via Hardware-Aware Multifaceted Optimizations\",\"url\":\"https://www.semanticscholar.org/paper/21066f476b04b602b40e73f494b577f7eb660e75\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1910.05577\",\"authors\":[{\"authorId\":\"1821514\",\"name\":\"Xu-Dong Lin\"},{\"authorId\":\"152309767\",\"name\":\"L. Ma\"},{\"authorId\":\"1743698\",\"name\":\"Wenyu Liu\"},{\"authorId\":\"72197815\",\"name\":\"Shih-Fu Chang\"}],\"doi\":\"10.1007/978-3-030-58523-5_41\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"119b1526842c105ef9a5b187c13045eb580220e7\",\"title\":\"Context-Gated Convolution\",\"url\":\"https://www.semanticscholar.org/paper/119b1526842c105ef9a5b187c13045eb580220e7\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.15796\",\"authors\":[{\"authorId\":\"1470673136\",\"name\":\"Yue Meng\"},{\"authorId\":\"47532522\",\"name\":\"Chung-Ching Lin\"},{\"authorId\":\"1819152\",\"name\":\"R. Panda\"},{\"authorId\":\"1706272\",\"name\":\"P. Sattigeri\"},{\"authorId\":\"2428823\",\"name\":\"Leonid Karlinsky\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"}],\"doi\":\"10.1007/978-3-030-58571-6_6\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"11bf57d8a652de8e2ea436ff6a2707c95fa5197a\",\"title\":\"AR-Net: Adaptive Frame Resolution for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/11bf57d8a652de8e2ea436ff6a2707c95fa5197a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1750931828\",\"name\":\"Ke Cheng\"},{\"authorId\":\"40382978\",\"name\":\"Yifan Zhang\"},{\"authorId\":\"48535072\",\"name\":\"X. He\"},{\"authorId\":\"26390637\",\"name\":\"Wei-Han Chen\"},{\"authorId\":\"48265260\",\"name\":\"Jian Cheng\"},{\"authorId\":\"1699900\",\"name\":\"H. Lu\"}],\"doi\":\"10.1109/cvpr42600.2020.00026\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1d41090ba8e597380e7353b6b1f42d6a7d9f83b4\",\"title\":\"Skeleton-Based Action Recognition With Shift Graph Convolutional Network\",\"url\":\"https://www.semanticscholar.org/paper/1d41090ba8e597380e7353b6b1f42d6a7d9f83b4\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2010.01773\",\"authors\":[{\"authorId\":\"49544149\",\"name\":\"Xiao-hua Liu\"},{\"authorId\":\"1732910\",\"name\":\"Ziheng Jiang\"},{\"authorId\":\"71908954\",\"name\":\"J. Fromm\"},{\"authorId\":\"9551276\",\"name\":\"Xuhai Xu\"},{\"authorId\":\"1701358\",\"name\":\"S. Patel\"},{\"authorId\":\"1381192475\",\"name\":\"Daniel McDuff\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"62ba8fb6faaf31333ee953a4db123fc3f687abca\",\"title\":\"MetaPhys: Unsupervised Few-Shot Adaptation for Non-Contact Physiological Measurement\",\"url\":\"https://www.semanticscholar.org/paper/62ba8fb6faaf31333ee953a4db123fc3f687abca\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1908.00867\",\"authors\":[{\"authorId\":\"50065546\",\"name\":\"W. Price\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"dc4b5fd4cf40b765abefb42bca6db1d845e0caa0\",\"title\":\"An Evaluation of Action Recognition Models on EPIC-Kitchens\",\"url\":\"https://www.semanticscholar.org/paper/dc4b5fd4cf40b765abefb42bca6db1d845e0caa0\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1519284973\",\"name\":\"Jingyao Wang\"},{\"authorId\":\"9454704\",\"name\":\"J. Chen\"},{\"authorId\":\"1486416799\",\"name\":\"Yuanyuan Qiao\"},{\"authorId\":\"1485134953\",\"name\":\"Junyan Zhou\"},{\"authorId\":null,\"name\":\"Yongtian Wang\"}],\"doi\":\"10.1109/ISMAR-Adjunct.2019.00-26\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"afb5ae43f6709de7d27f6ca2623d946acfde113f\",\"title\":\"Online Gesture Recognition Algorithm Applied to HUD Based Smart Driving System\",\"url\":\"https://www.semanticscholar.org/paper/afb5ae43f6709de7d27f6ca2623d946acfde113f\",\"venue\":\"2019 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3005372\",\"name\":\"Abdourrahmane M. Atto\"},{\"authorId\":\"144373800\",\"name\":\"A. Benoit\"},{\"authorId\":\"47858467\",\"name\":\"P. Lambert\"}],\"doi\":\"10.1016/j.patcog.2020.107353\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d767c20bd91fc785b170e271a15508f56ee92fc4\",\"title\":\"Timed-image based deep learning for action recognition in video sequences\",\"url\":\"https://www.semanticscholar.org/paper/d767c20bd91fc785b170e271a15508f56ee92fc4\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"120071612\",\"name\":\"E. Prytkova\"},{\"authorId\":\"98895189\",\"name\":\"S. Vannuccini\"}],\"doi\":\"10.2139/ssrn.3536389\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d135e98d23206ddcb5b4274c23e626f85b254678\",\"title\":\"On the Basis of Brain: Neural-Network-Inspired Change in General Purpose Chips\",\"url\":\"https://www.semanticscholar.org/paper/d135e98d23206ddcb5b4274c23e626f85b254678\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2003.13042\",\"authors\":[{\"authorId\":\"31463937\",\"name\":\"Haodong Duan\"},{\"authorId\":\"152621421\",\"name\":\"Yue Zhao\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"49663328\",\"name\":\"Wentao Liu\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1007/978-3-030-58555-6_40\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d6f7e18d551743889cd87dc3e0b4a75b8791ea95\",\"title\":\"Omni-sourced Webly-supervised Learning for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d6f7e18d551743889cd87dc3e0b4a75b8791ea95\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1912.04487\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":\"10.1109/cvpr42600.2020.01047\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c4128ba8deeb67e731cf52fb98addcfddd487e55\",\"title\":\"Listen to Look: Action Recognition by Previewing Audio\",\"url\":\"https://www.semanticscholar.org/paper/c4128ba8deeb67e731cf52fb98addcfddd487e55\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2008.02454\",\"authors\":[{\"authorId\":\"3469024\",\"name\":\"Yash Bhalgat\"},{\"authorId\":\"48378494\",\"name\":\"Yizhe Zhang\"},{\"authorId\":\"46697809\",\"name\":\"J. Lin\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6e2a44d64dd9ffe1e4f60a8d0728b3edfe33076\",\"title\":\"Structured Convolutions for Efficient Neural Network Design\",\"url\":\"https://www.semanticscholar.org/paper/a6e2a44d64dd9ffe1e4f60a8d0728b3edfe33076\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31595791\",\"name\":\"J. Li\"},{\"authorId\":\"6820648\",\"name\":\"Xianglong Liu\"},{\"authorId\":\"150341144\",\"name\":\"Wenxuan Zhang\"},{\"authorId\":\"47473953\",\"name\":\"Mingyuan Zhang\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":\"10.1109/TMM.2020.2965434\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2ea173f972d39b8631e9ac8fe59a947c70ba31e3\",\"title\":\"Spatio-Temporal Attention Networks for Action Recognition and Detection\",\"url\":\"https://www.semanticscholar.org/paper/2ea173f972d39b8631e9ac8fe59a947c70ba31e3\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"2001.06769\",\"authors\":[{\"authorId\":\"151080964\",\"name\":\"Kaiyu Shan\"},{\"authorId\":null,\"name\":\"Yongtao Wang\"},{\"authorId\":\"5744018\",\"name\":\"Z. Wang\"},{\"authorId\":\"47715977\",\"name\":\"Ting-Ting Liang\"},{\"authorId\":null,\"name\":\"Zhi Tang\"},{\"authorId\":\"50581109\",\"name\":\"Y. Chen\"},{\"authorId\":\"1920864\",\"name\":\"Yangyan Li\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0c09d3844807f4cbed18f5ff5d5df34a89365d07\",\"title\":\"MixTConv: Mixed Temporal Convolutional Kernels for Efficient Action Recogntion\",\"url\":\"https://www.semanticscholar.org/paper/0c09d3844807f4cbed18f5ff5d5df34a89365d07\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.06317\",\"authors\":[{\"authorId\":\"3458134\",\"name\":\"Gyeongsik Moon\"},{\"authorId\":\"30557120\",\"name\":\"Heeseung Kwon\"},{\"authorId\":\"2135837\",\"name\":\"Kyoung Mu Lee\"},{\"authorId\":\"72643925\",\"name\":\"Minsu Cho\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8230c73193abe9f42306a311d75557a902e785f6\",\"title\":\"IntegralAction: Pose-driven Feature Integration for Robust Human Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/8230c73193abe9f42306a311d75557a902e785f6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6798639\",\"name\":\"Jinyang Guo\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"1510477221\",\"name\":\"Dong Xu\"}],\"doi\":\"10.1109/cvpr42600.2020.00158\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ffbcd6379e865f150d2f1d2c7074d5d1e482e547\",\"title\":\"Multi-Dimensional Pruning: A Unified Framework for Model Compression\",\"url\":\"https://www.semanticscholar.org/paper/ffbcd6379e865f150d2f1d2c7074d5d1e482e547\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2011.12004\",\"authors\":[{\"authorId\":\"2028357556\",\"name\":\"Racha Friji\"},{\"authorId\":\"2641251\",\"name\":\"H. Drira\"},{\"authorId\":\"2446036\",\"name\":\"F. Chaieb\"},{\"authorId\":\"145766926\",\"name\":\"S. Kurtek\"},{\"authorId\":\"2028357554\",\"name\":\"Hamza Kchok\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2ae03c97b1a6bfa3546646ab654c5bf652c0f12c\",\"title\":\"KShapeNet: Riemannian network on Kendall shape space for Skeleton based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2ae03c97b1a6bfa3546646ab654c5bf652c0f12c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.12384\",\"authors\":[{\"authorId\":\"9385903\",\"name\":\"S. Zhu\"},{\"authorId\":\"1390892946\",\"name\":\"Taojiannan Yang\"},{\"authorId\":\"1422036273\",\"name\":\"Mat'ias Mendieta\"},{\"authorId\":\"143916976\",\"name\":\"Chen Chen\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ba1dda6494709cac7c48c95c81afff7a087f2031\",\"title\":\"A3D: Adaptive 3D Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ba1dda6494709cac7c48c95c81afff7a087f2031\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153652147\",\"name\":\"Jagannath Malik\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9ffc9a0da2a9877ab793b9d0f2f3a9eafd67cc29\",\"title\":\"Test-Time Training for Improved Object Affordance Prediction\",\"url\":\"https://www.semanticscholar.org/paper/9ffc9a0da2a9877ab793b9d0f2f3a9eafd67cc29\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1741412659\",\"name\":\"Zhijian Liu\"},{\"authorId\":\"1390573666\",\"name\":\"Zhanghao Wu\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"20515689\",\"name\":\"Ligeng Zhu\"},{\"authorId\":\"143840277\",\"name\":\"Song Han\"}],\"doi\":\"10.1007/978-3-030-58621-8_34\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7b1707391bf47ed5a99fe3626be6b4514c317745\",\"title\":\"DataMix: Efficient Privacy-Preserving Edge-Cloud Inference\",\"url\":\"https://www.semanticscholar.org/paper/7b1707391bf47ed5a99fe3626be6b4514c317745\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2010.05099\",\"authors\":[{\"authorId\":\"3451382\",\"name\":\"T. Tanay\"},{\"authorId\":\"49361819\",\"name\":\"A. Sootla\"},{\"authorId\":\"48098273\",\"name\":\"M. Maggioni\"},{\"authorId\":\"144679302\",\"name\":\"P. Dokania\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"},{\"authorId\":\"1732672\",\"name\":\"A. Leonardis\"},{\"authorId\":\"1729399584\",\"name\":\"Gregory Slabaugh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"495f76d685ae95965aa69f56fbbfbff3307f8978\",\"title\":\"Diagnosing and Preventing Instabilities in Recurrent Video Processing\",\"url\":\"https://www.semanticscholar.org/paper/495f76d685ae95965aa69f56fbbfbff3307f8978\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.00210\",\"authors\":[{\"authorId\":\"46399266\",\"name\":\"Yang Liu\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"49478124\",\"name\":\"L. Lin\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c1c3bde4639433102c6873a083e8875e8a7f375c\",\"title\":\"Semantics-aware Adaptive Knowledge Distillation for Sensor-to-Vision Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c1c3bde4639433102c6873a083e8875e8a7f375c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.06647\",\"authors\":[{\"authorId\":\"153634296\",\"name\":\"Matthew Hutchinson\"},{\"authorId\":\"74882299\",\"name\":\"Vijay Gadepally\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"65955a106905afb90a2a2fa74e48c6d6d597892f\",\"title\":\"Video Action Understanding: A Tutorial\",\"url\":\"https://www.semanticscholar.org/paper/65955a106905afb90a2a2fa74e48c6d6d597892f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.02543\",\"authors\":[{\"authorId\":\"30621486\",\"name\":\"Stepan Alekseevich Komkov\"},{\"authorId\":\"2007675511\",\"name\":\"Maksim Dzabraev\"},{\"authorId\":\"1380315305\",\"name\":\"Aleksandr Petiushko\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0e0be00a9dac71413ebfca60ea6b40a5d73c5877\",\"title\":\"Mutual Modality Learning for Video Action Classification\",\"url\":\"https://www.semanticscholar.org/paper/0e0be00a9dac71413ebfca60ea6b40a5d73c5877\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.02190\",\"authors\":[{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":\"10.1109/TPAMI.2020.2992889\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"07cf6c4c1714a0cd88e5c1566aac9df40e111db7\",\"title\":\"Rolling-Unrolling LSTMs for Action Anticipation from First-Person Video\",\"url\":\"https://www.semanticscholar.org/paper/07cf6c4c1714a0cd88e5c1566aac9df40e111db7\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"2011.12619\",\"authors\":[{\"authorId\":\"147084112\",\"name\":\"Jack Humphreys\"},{\"authorId\":\"48354826\",\"name\":\"Z. Chen\"},{\"authorId\":\"145047838\",\"name\":\"Dacheng Tao\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e88bff50c417703239e0a832fddb267196ab5a99\",\"title\":\"Recent Progress in Appearance-based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e88bff50c417703239e0a832fddb267196ab5a99\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.01398\",\"authors\":[{\"authorId\":\"48513712\",\"name\":\"Y. Li\"},{\"authorId\":\"102880425\",\"name\":\"Bin Ji\"},{\"authorId\":\"48203223\",\"name\":\"Xintian Shi\"},{\"authorId\":\"98697812\",\"name\":\"J. Zhang\"},{\"authorId\":\"48418655\",\"name\":\"Bin Kang\"},{\"authorId\":\"48170350\",\"name\":\"Limin Wang\"}],\"doi\":\"10.1109/cvpr42600.2020.00099\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1ebeb84e2b8e1182a2b4821c906200ecc49ae187\",\"title\":\"TEA: Temporal Excitation and Aggregation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1ebeb84e2b8e1182a2b4821c906200ecc49ae187\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47876379\",\"name\":\"J. Wu\"},{\"authorId\":\"1846644339\",\"name\":\"Yingying Li\"},{\"authorId\":\"47528427\",\"name\":\"W. Zhang\"},{\"authorId\":\"145831603\",\"name\":\"Yi Wu\"},{\"authorId\":\"145681035\",\"name\":\"Xiao Tan\"},{\"authorId\":\"2316745\",\"name\":\"H. Zhang\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"},{\"authorId\":\"32914175\",\"name\":\"Errui Ding\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"}],\"doi\":\"10.1145/3394171.3416279\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"7ae5893a65394d45498aa4c0eeca587bbe772201\",\"title\":\"Modularized Framework with Category-Sensitive Abnormal Filter for City Anomaly Detection\",\"url\":\"https://www.semanticscholar.org/paper/7ae5893a65394d45498aa4c0eeca587bbe772201\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2012.05672\",\"authors\":[{\"authorId\":\"3041463\",\"name\":\"Josh Abramson\"},{\"authorId\":\"37968006\",\"name\":\"Arun Ahuja\"},{\"authorId\":\"104251960\",\"name\":\"A. Brussee\"},{\"authorId\":\"32561676\",\"name\":\"F. Carnevale\"},{\"authorId\":\"147433059\",\"name\":\"M. Cassin\"},{\"authorId\":\"40591844\",\"name\":\"S. Clark\"},{\"authorId\":\"145585375\",\"name\":\"Andrew Dudzik\"},{\"authorId\":\"1737522\",\"name\":\"P. Georgiev\"},{\"authorId\":\"40895205\",\"name\":\"Aurelia Guy\"},{\"authorId\":\"3367786\",\"name\":\"T. Harley\"},{\"authorId\":\"145783676\",\"name\":\"Felix Hill\"},{\"authorId\":\"1572095637\",\"name\":\"Alden Hung\"},{\"authorId\":\"40947466\",\"name\":\"Zachary Kenton\"},{\"authorId\":\"47522978\",\"name\":\"J. Landon\"},{\"authorId\":\"2542999\",\"name\":\"T. Lillicrap\"},{\"authorId\":\"3422828\",\"name\":\"K. Mathewson\"},{\"authorId\":\"50654556\",\"name\":\"Alistair Muldal\"},{\"authorId\":\"35030998\",\"name\":\"A. Santoro\"},{\"authorId\":\"2417003\",\"name\":\"Nikolay Savinov\"},{\"authorId\":\"144711236\",\"name\":\"Vikrant Varma\"},{\"authorId\":\"1388843622\",\"name\":\"Greg Wayne\"},{\"authorId\":\"1571809179\",\"name\":\"N. Wong\"},{\"authorId\":\"1500528300\",\"name\":\"Chen Yan\"},{\"authorId\":\"152186738\",\"name\":\"Rui Zhu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fa7f381612c506d024f803930ae6f93474cc048e\",\"title\":\"Imitating Interactive Intelligence\",\"url\":\"https://www.semanticscholar.org/paper/fa7f381612c506d024f803930ae6f93474cc048e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1908.08926\",\"authors\":[{\"authorId\":\"3130257\",\"name\":\"B. Wu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0067c6b323449be5b31891c6123c0b9c3ad0f525\",\"title\":\"Efficient Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/0067c6b323449be5b31891c6123c0b9c3ad0f525\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2009.13087\",\"authors\":[{\"authorId\":\"3173493\",\"name\":\"Y. Li\"},{\"authorId\":\"2050979\",\"name\":\"Zhichao Lu\"},{\"authorId\":\"3182065\",\"name\":\"Xuehan Xiong\"},{\"authorId\":\"4240351\",\"name\":\"Jonathan Huang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c8bf6f41d6df5c6cdc6249aecfa1aab027f0c8e0\",\"title\":\"PERF-Net: Pose Empowered RGB-Flow Net\",\"url\":\"https://www.semanticscholar.org/paper/c8bf6f41d6df5c6cdc6249aecfa1aab027f0c8e0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.04863\",\"authors\":[{\"authorId\":\"2160469\",\"name\":\"Y. Cao\"},{\"authorId\":\"1394232864\",\"name\":\"Qingfei Tang\"},{\"authorId\":\"50084994\",\"name\":\"X. Lu\"},{\"authorId\":\"1825677658\",\"name\":\"Fan Li\"},{\"authorId\":\"103151133\",\"name\":\"Jin-de Cao\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"56c41a9f797cf1a23beb93b7571359fbc061397d\",\"title\":\"STCNet: Spatio-Temporal Cross Network for Industrial Smoke Detection\",\"url\":\"https://www.semanticscholar.org/paper/56c41a9f797cf1a23beb93b7571359fbc061397d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1912.06992\",\"authors\":[{\"authorId\":\"2547290\",\"name\":\"Jingwei Ji\"},{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/cvpr42600.2020.01025\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d1242ba8fdb994b82a0575dc92f30f7b26a75707\",\"title\":\"Action Genome: Actions As Compositions of Spatio-Temporal Scene Graphs\",\"url\":\"https://www.semanticscholar.org/paper/d1242ba8fdb994b82a0575dc92f30f7b26a75707\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2003.12798\",\"authors\":[{\"authorId\":\"2156559\",\"name\":\"Qihang Yu\"},{\"authorId\":\"48513320\",\"name\":\"Yingwei Li\"},{\"authorId\":\"10407760\",\"name\":\"Jieru Mei\"},{\"authorId\":\"7743268\",\"name\":\"Yuyin Zhou\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"3743c3c7c30d700f37bcd00048af007137517a18\",\"title\":\"CAKES: Channel-wise Automatic KErnel Shrinking for Efficient 3D Network\",\"url\":\"https://www.semanticscholar.org/paper/3743c3c7c30d700f37bcd00048af007137517a18\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.05342\",\"authors\":[{\"authorId\":\"145580092\",\"name\":\"Pierre-Etienne Martin\"},{\"authorId\":\"1401651727\",\"name\":\"J. Benois-Pineau\"},{\"authorId\":\"1639895183\",\"name\":\"Renaud P\\u00e9teri\"},{\"authorId\":\"1639983772\",\"name\":\"Julien Morlier\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4c6b7bc12da85925efeb297cadf0a47c6c6ec7ea\",\"title\":\"3D attention mechanism for fine-grained classification of table tennis strokes using a Twin Spatio-Temporal Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/4c6b7bc12da85925efeb297cadf0a47c6c6ec7ea\",\"venue\":\"\",\"year\":2021},{\"arxivId\":\"2003.05837\",\"authors\":[{\"authorId\":\"40951853\",\"name\":\"Manyuan Zhang\"},{\"authorId\":\"46798949\",\"name\":\"H. Shao\"},{\"authorId\":\"12920342\",\"name\":\"Guanglu Song\"},{\"authorId\":\"119924269\",\"name\":\"Y. Liu\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5a700417579a1fbde76baba60595bc00c909606c\",\"title\":\"Top-1 Solution of Multi-Moments in Time Challenge 2019\",\"url\":\"https://www.semanticscholar.org/paper/5a700417579a1fbde76baba60595bc00c909606c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34678431\",\"name\":\"F. Sener\"},{\"authorId\":\"1734802895\",\"name\":\"Dipika Singhania\"},{\"authorId\":\"144031869\",\"name\":\"A. Yao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e77735f1131cdb42db5a03093e4d15ebce34d473\",\"title\":\"Temporal Aggregate Representations for Long Term Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/e77735f1131cdb42db5a03093e4d15ebce34d473\",\"venue\":\"ECCV 2020\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2222058\",\"name\":\"M. Charkhabi\"},{\"authorId\":\"1471692973\",\"name\":\"Nivedita Rahurkar\"}],\"doi\":\"10.1117/12.2550596\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"91806627b3773ca26929e96d7ba2197523c22b16\",\"title\":\"Efficient training and inference in highly temporal activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/91806627b3773ca26929e96d7ba2197523c22b16\",\"venue\":\"Other Conferences\",\"year\":2019},{\"arxivId\":\"2002.03342\",\"authors\":[{\"authorId\":\"47203405\",\"name\":\"Wenhao Wu\"},{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"145681032\",\"name\":\"Xiao Tan\"},{\"authorId\":\"2869725\",\"name\":\"Shifeng Chen\"},{\"authorId\":null,\"name\":\"Yi Yang\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"}],\"doi\":\"10.1109/CVPRW50498.2020.00346\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"de79226c40767073dea787327637c8415b1bc60a\",\"title\":\"Dynamic Inference: A New Approach Toward Efficient Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/de79226c40767073dea787327637c8415b1bc60a\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"2008.09037\",\"authors\":[{\"authorId\":\"153634296\",\"name\":\"Matthew Hutchinson\"},{\"authorId\":\"2331418\",\"name\":\"S. Samsi\"},{\"authorId\":\"3302251\",\"name\":\"W. Arcand\"},{\"authorId\":\"2159806\",\"name\":\"David Bestor\"},{\"authorId\":\"34001612\",\"name\":\"Bill Bergeron\"},{\"authorId\":\"2098646\",\"name\":\"C. Byun\"},{\"authorId\":\"1850501832\",\"name\":\"Micheal Houle\"},{\"authorId\":\"145238688\",\"name\":\"M. Hubbell\"},{\"authorId\":\"145319478\",\"name\":\"Michael J. Jones\"},{\"authorId\":\"3257323\",\"name\":\"J. Kepner\"},{\"authorId\":\"1983355\",\"name\":\"A. Kirby\"},{\"authorId\":\"1684116\",\"name\":\"P. Michaleas\"},{\"authorId\":\"3385550\",\"name\":\"Lauren Milechin\"},{\"authorId\":\"143913450\",\"name\":\"J. Mullen\"},{\"authorId\":\"2417672\",\"name\":\"A. Prout\"},{\"authorId\":\"144557576\",\"name\":\"A. Rosa\"},{\"authorId\":\"2097629\",\"name\":\"Albert Reuther\"},{\"authorId\":\"145378881\",\"name\":\"C. Yee\"},{\"authorId\":\"74882299\",\"name\":\"Vijay Gadepally\"}],\"doi\":\"10.1109/HPEC43674.2020.9286249\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b3aef63e62e673e852048a24bea1040d3f8b23c1\",\"title\":\"Accuracy and Performance Comparison of Video Action Recognition Approaches\",\"url\":\"https://www.semanticscholar.org/paper/b3aef63e62e673e852048a24bea1040d3f8b23c1\",\"venue\":\"2020 IEEE High Performance Extreme Computing Conference (HPEC)\",\"year\":2020},{\"arxivId\":\"2008.11378\",\"authors\":[{\"authorId\":\"153420733\",\"name\":\"Haozhi Cao\"},{\"authorId\":\"9734988\",\"name\":\"Yuecong Xu\"},{\"authorId\":\"2562263\",\"name\":\"Jianfei Yang\"},{\"authorId\":\"120974533\",\"name\":\"Kezhi Mao\"},{\"authorId\":\"2037059\",\"name\":\"Jian-Xiong Yin\"},{\"authorId\":\"144308998\",\"name\":\"S. See\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"c16a94fe31835a67a8cf5e2d4d1076e0037844a9\",\"title\":\"Effective Action Recognition with Embedded Key Point Shifts\",\"url\":\"https://www.semanticscholar.org/paper/c16a94fe31835a67a8cf5e2d4d1076e0037844a9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1912.00998\",\"authors\":[{\"authorId\":\"100880679\",\"name\":\"Chao-Yuan Wu\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"51506875\",\"name\":\"Philipp Krahenbuhl\"}],\"doi\":\"10.1109/cvpr42600.2020.00023\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b8cc28e11900e4d191651ae7234b4dbd129b1007\",\"title\":\"A Multigrid Method for Efficiently Training Video Models\",\"url\":\"https://www.semanticscholar.org/paper/b8cc28e11900e4d191651ae7234b4dbd129b1007\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"2148510\",\"name\":\"A. Angelova\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"38df033adc8b89ad02a638db823be439260113bd\",\"title\":\"Tiny Video Networks: Architecture Search for Efficient Video Models\",\"url\":\"https://www.semanticscholar.org/paper/38df033adc8b89ad02a638db823be439260113bd\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1912.10405\",\"authors\":[{\"authorId\":\"52170427\",\"name\":\"Boxiao Pan\"},{\"authorId\":\"3451430\",\"name\":\"Zhangjie Cao\"},{\"authorId\":\"46408185\",\"name\":\"E. Adeli\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1609/AAAI.V34I07.6854\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"94536d1a30f83bd0327b3a7e9f3ed1a66a9a3cdc\",\"title\":\"Adversarial Cross-Domain Action Recognition with Co-Attention\",\"url\":\"https://www.semanticscholar.org/paper/94536d1a30f83bd0327b3a7e9f3ed1a66a9a3cdc\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2004.06704\",\"authors\":[{\"authorId\":\"27575517\",\"name\":\"Dian Shao\"},{\"authorId\":\"145454812\",\"name\":\"Yue Zhao\"},{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/cvpr42600.2020.00269\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f5c35edc9cf622c7dd7e19ce6fbd5d563557de5b\",\"title\":\"FineGym: A Hierarchical Video Dataset for Fine-Grained Action Understanding\",\"url\":\"https://www.semanticscholar.org/paper/f5c35edc9cf622c7dd7e19ce6fbd5d563557de5b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2003.06754\",\"authors\":[{\"authorId\":\"2498892\",\"name\":\"Pengxiang Wu\"},{\"authorId\":\"145552439\",\"name\":\"Siheng Chen\"},{\"authorId\":\"1711560\",\"name\":\"D. Metaxas\"}],\"doi\":\"10.1109/cvpr42600.2020.01140\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5e84232f179034b039bfc4d1dae3c91c1a50bfa2\",\"title\":\"MotionNet: Joint Perception and Motion Prediction for Autonomous Driving Based on Bird\\u2019s Eye View Maps\",\"url\":\"https://www.semanticscholar.org/paper/5e84232f179034b039bfc4d1dae3c91c1a50bfa2\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143672737\",\"name\":\"A. Mu\\u00f1oz\"},{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"49965376\",\"name\":\"Max Argus\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1233d892716e3c8efab5a72bef14c8a4bdf668d4\",\"title\":\"Multi-Variate Temporal GAN for Large Scale Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/1233d892716e3c8efab5a72bef14c8a4bdf668d4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.08247\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":\"10.1016/j.patrec.2020.11.012\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9c9ee02e3394adde596c35d1966566b2d971f426\",\"title\":\"Learn to cycle: Time-consistent feature discovery for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/9c9ee02e3394adde596c35d1966566b2d971f426\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.09470\",\"authors\":[{\"authorId\":\"1399646334\",\"name\":\"Rui Yan\"},{\"authorId\":\"3041937\",\"name\":\"Lingxi Xie\"},{\"authorId\":\"8053308\",\"name\":\"J. Tang\"},{\"authorId\":\"2287686\",\"name\":\"Xiangbo Shu\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1007/978-3-030-58598-3_13\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"314f0cdcca7cdab68c92821c149786a876c116bb\",\"title\":\"Social Adaptive Module for Weakly-supervised Group Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/314f0cdcca7cdab68c92821c149786a876c116bb\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47077615\",\"name\":\"J. Munro\"},{\"authorId\":\"1677780022\",\"name\":\"Dima Damen\"}],\"doi\":\"10.1109/cvpr42600.2020.00020\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"646a256e30cd244b668660c32b529ff31a874a78\",\"title\":\"Multi-Modal Domain Adaptation for Fine-Grained Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/646a256e30cd244b668660c32b529ff31a874a78\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Loc Trinh\"},{\"authorId\":null,\"name\":\"Michael Tsang\"},{\"authorId\":null,\"name\":\"Sirisha Rambhatla\"},{\"authorId\":null,\"name\":\"Yan Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"41cbea36c8107d6ed4f3b89bd641e292d0096a24\",\"title\":\"Interpretable and Trustworthy Deepfake Detection via Dynamic Prototypes\",\"url\":\"https://www.semanticscholar.org/paper/41cbea36c8107d6ed4f3b89bd641e292d0096a24\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"2007.11431\",\"authors\":[{\"authorId\":\"14002400\",\"name\":\"Taihong Xiao\"},{\"authorId\":\"46685413\",\"name\":\"J. Yuan\"},{\"authorId\":\"3232265\",\"name\":\"Deqing Sun\"},{\"authorId\":\"2230525\",\"name\":\"Qifei Wang\"},{\"authorId\":\"1485105851\",\"name\":\"Xinyu Zhang\"},{\"authorId\":\"49343490\",\"name\":\"Kehan Xu\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1007/978-3-030-58545-7_28\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bd1b9aac9b0a4fd9b653c6215a9d38e8d37b7130\",\"title\":\"Learnable Cost Volume Using the Cayley Representation\",\"url\":\"https://www.semanticscholar.org/paper/bd1b9aac9b0a4fd9b653c6215a9d38e8d37b7130\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2004346846\",\"name\":\"Jialin Gao\"},{\"authorId\":\"6873935\",\"name\":\"T. Lin\"},{\"authorId\":\"46550737\",\"name\":\"Xiang Long\"},{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"145987553\",\"name\":\"F. Li\"},{\"authorId\":\"3223020\",\"name\":\"Xin Li\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"},{\"authorId\":\"12081764\",\"name\":\"E. Ding\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b0b58740e78ca06cc8c2963720e1657d012d9922\",\"title\":\"Multi-modal fusion network based on relation-aware pyramid network for temporal action localization\",\"url\":\"https://www.semanticscholar.org/paper/b0b58740e78ca06cc8c2963720e1657d012d9922\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1992699237\",\"name\":\"Zhenbang Li\"},{\"authorId\":\"145805403\",\"name\":\"Q. Wang\"},{\"authorId\":\"46930055\",\"name\":\"J. Gao\"},{\"authorId\":null,\"name\":\"Bing Li\"},{\"authorId\":\"121926309\",\"name\":\"Weiming Hu\"}],\"doi\":\"10.1109/ICIP40778.2020.9191165\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"cb76c3d1b1f40b1377f36bf8f30779fd546c442b\",\"title\":\"End-to-End Temporal Feature Aggregation for Siamese Trackers\",\"url\":\"https://www.semanticscholar.org/paper/cb76c3d1b1f40b1377f36bf8f30779fd546c442b\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"2008.04999\",\"authors\":[{\"authorId\":\"13930770\",\"name\":\"Faegheh Sardari\"},{\"authorId\":\"2657085\",\"name\":\"A. Paiement\"},{\"authorId\":\"1751117\",\"name\":\"S. Hannuna\"},{\"authorId\":\"1728108\",\"name\":\"M. Mirmehdi\"}],\"doi\":\"10.3390/s20185258\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eddbf3b7783f528a3413dbe96a58da1690d7f156\",\"title\":\"VI-Net\\u2014View-Invariant Quality of Human Movement Assessment\",\"url\":\"https://www.semanticscholar.org/paper/eddbf3b7783f528a3413dbe96a58da1690d7f156\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"1911.04140\",\"authors\":[{\"authorId\":\"1381281389\",\"name\":\"Prashant Pandey\"},{\"authorId\":\"1411010600\",\"name\":\"P. PrathoshA.\"},{\"authorId\":\"49085157\",\"name\":\"Manu Kohli\"},{\"authorId\":\"49017407\",\"name\":\"J. Pritchard\"}],\"doi\":\"10.1609/aaai.v34i01.5383\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bfefcb0901b173f0da0d4db3948d749ab9734198\",\"title\":\"Guided weak supervision for action recognition with scarce data to assess skills of children with autism\",\"url\":\"https://www.semanticscholar.org/paper/bfefcb0901b173f0da0d4db3948d749ab9734198\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1912.00381\",\"authors\":[{\"authorId\":\"1756362\",\"name\":\"Swathikiran Sudhakaran\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"}],\"doi\":\"10.1109/cvpr42600.2020.00118\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"57cee868188127305f966a178ca22025b397d911\",\"title\":\"Gate-Shift Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/57cee868188127305f966a178ca22025b397d911\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2006.15327\",\"authors\":[{\"authorId\":\"48319922\",\"name\":\"A. Bar\"},{\"authorId\":\"46796686\",\"name\":\"Roei Herzig\"},{\"authorId\":\"122024152\",\"name\":\"Xiaolong Wang\"},{\"authorId\":\"1732280\",\"name\":\"Gal Chechik\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"1786843\",\"name\":\"A. Globerson\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cdc4ae0adcff94e9ea4591f25b81f88c93cb4fbe\",\"title\":\"Compositional Video Synthesis with Action Graphs\",\"url\":\"https://www.semanticscholar.org/paper/cdc4ae0adcff94e9ea4591f25b81f88c93cb4fbe\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"93318099\",\"name\":\"J. Lin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"27ff341652fff45d545f68c6e00b0b07627dccc1\",\"title\":\"Training Kinetics in 15 Minutes: Large-scale Distributed Training on Videos\",\"url\":\"https://www.semanticscholar.org/paper/27ff341652fff45d545f68c6e00b0b07627dccc1\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92533069\",\"name\":\"L. Chi\"},{\"authorId\":\"2704823\",\"name\":\"Ze-Huan Yuan\"},{\"authorId\":\"145353089\",\"name\":\"Y. Mu\"},{\"authorId\":\"1697065\",\"name\":\"C. Wang\"}],\"doi\":\"10.1109/cvpr42600.2020.01182\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6dcb726b4e1afa5fa6f8684081f19508e61b45c0\",\"title\":\"Non-Local Neural Networks With Grouped Bilinear Attentional Transforms\",\"url\":\"https://www.semanticscholar.org/paper/6dcb726b4e1afa5fa6f8684081f19508e61b45c0\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46276307\",\"name\":\"Jianwei Li\"},{\"authorId\":\"143836554\",\"name\":\"Hainan Cui\"},{\"authorId\":\"1878916102\",\"name\":\"Tianxiao Guo\"},{\"authorId\":\"1877155774\",\"name\":\"Qingrui Hu\"},{\"authorId\":\"8034759\",\"name\":\"Y. Shen\"}],\"doi\":\"10.1109/ICMEW46912.2020.9106049\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"95920910eb5ca01a28b0d3fbb90cfb3e025a4382\",\"title\":\"Efficient Fitness Action Analysis Based on Spatio-Temporal Feature Encoding\",\"url\":\"https://www.semanticscholar.org/paper/95920910eb5ca01a28b0d3fbb90cfb3e025a4382\",\"venue\":\"2020 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2020},{\"arxivId\":\"2012.09434\",\"authors\":[{\"authorId\":\"48031771\",\"name\":\"X. Liu\"},{\"authorId\":\"72285615\",\"name\":\"Yao Hu\"},{\"authorId\":\"98807701\",\"name\":\"Song Bai\"},{\"authorId\":\"1430778662\",\"name\":\"Fei Ding\"},{\"authorId\":\"145905113\",\"name\":\"X. Bai\"},{\"authorId\":\"2038266421\",\"name\":\"Philip H.S. Torr Huazhong University of Science\"},{\"authorId\":\"103081934\",\"name\":\"Technology\"},{\"authorId\":\"2038266423\",\"name\":\"Alibaba Group\"},{\"authorId\":\"51909023\",\"name\":\"U. O. Oxford\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"db1b0d0e70f29b0018d1a9462d98dd39559f3e4a\",\"title\":\"Multi-shot Temporal Event Localization: a Benchmark\",\"url\":\"https://www.semanticscholar.org/paper/db1b0d0e70f29b0018d1a9462d98dd39559f3e4a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49372683\",\"name\":\"Niamul Quader\"},{\"authorId\":\"102542533\",\"name\":\"M. M. I. Bhuiyan\"},{\"authorId\":\"150152476\",\"name\":\"Juwei Lu\"},{\"authorId\":\"144287598\",\"name\":\"Peng Dai\"},{\"authorId\":\"122009001\",\"name\":\"Wei Li\"}],\"doi\":\"10.1007/978-3-030-58577-8_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dd6b78e4b9c50f9783a5d6f4eed09216ece3c508\",\"title\":\"Weight Excitation: Built-in Attention Mechanisms in Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/dd6b78e4b9c50f9783a5d6f4eed09216ece3c508\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1911.09435\",\"authors\":[{\"authorId\":\"46270766\",\"name\":\"Zhaoyang Liu\"},{\"authorId\":\"9393671\",\"name\":\"Donghao Luo\"},{\"authorId\":null,\"name\":\"Yabiao Wang\"},{\"authorId\":\"29461006\",\"name\":\"L. Wang\"},{\"authorId\":\"144970872\",\"name\":\"Ying Tai\"},{\"authorId\":\"1978245\",\"name\":\"Chengjie Wang\"},{\"authorId\":\"49298244\",\"name\":\"Jilin Li\"},{\"authorId\":\"1835006\",\"name\":\"Feiyue Huang\"},{\"authorId\":\"144720251\",\"name\":\"Tong Lu\"}],\"doi\":\"10.1609/AAAI.V34I07.6836\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"fa3473f1f5d4f19ec6d561e2700a4d88dad4ccf8\",\"title\":\"TEINet: Towards an Efficient Architecture for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fa3473f1f5d4f19ec6d561e2700a4d88dad4ccf8\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491240780\",\"name\":\"Z. Shi\"},{\"authorId\":\"144962375\",\"name\":\"Cheng Guan\"},{\"authorId\":\"1491233401\",\"name\":\"Liangjie Cao\"},{\"authorId\":\"1632356255\",\"name\":\"Qianqian Li\"},{\"authorId\":\"1993660232\",\"name\":\"Ju Liang\"},{\"authorId\":\"29344734\",\"name\":\"Zhaorui Gu\"},{\"authorId\":\"2336297\",\"name\":\"Haiyong Zheng\"},{\"authorId\":\"1470709309\",\"name\":\"Bing Zheng\"}],\"doi\":\"10.1007/978-3-030-58539-6_23\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c826e169f505f6fda0872d0a3e1e156e15b5111e\",\"title\":\"CoTeRe-Net: Discovering Collaborative Ternary Relations in Videos\",\"url\":\"https://www.semanticscholar.org/paper/c826e169f505f6fda0872d0a3e1e156e15b5111e\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1680553699\",\"name\":\"Kuntai Du\"},{\"authorId\":\"11005710\",\"name\":\"Ahsan Pervaiz\"},{\"authorId\":\"152162547\",\"name\":\"Xin Yuan\"},{\"authorId\":\"2841893\",\"name\":\"Aakanksha Chowdhery\"},{\"authorId\":\"1581986665\",\"name\":\"Qizheng Zhang\"},{\"authorId\":\"152495735\",\"name\":\"Henry Hoffmann\"},{\"authorId\":\"1727978\",\"name\":\"J. Jiang\"}],\"doi\":\"10.1145/3387514.3405887\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"0523c90754956535f5daa3069d7a26ac7ca0df78\",\"title\":\"Server-Driven Video Streaming for Deep Learning Inference\",\"url\":\"https://www.semanticscholar.org/paper/0523c90754956535f5daa3069d7a26ac7ca0df78\",\"venue\":\"SIGCOMM\",\"year\":2020},{\"arxivId\":\"2011.03949\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d7728ed8dd12e0ad64514ae9ec5d0bdf0576dadc\",\"title\":\"Right on Time: Multi-Temporal Convolutions for Human Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/d7728ed8dd12e0ad64514ae9ec5d0bdf0576dadc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":null,\"name\":\"Gedas Bertasius\"},{\"authorId\":null,\"name\":\"Tae-Hyun Oh\"},{\"authorId\":null,\"name\":\"Abhinav Gupta\"},{\"authorId\":null,\"name\":\"Minh Hoai\"},{\"authorId\":null,\"name\":\"Lorenzo Torresani\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"86a9e09459c5a4e436706d0b89f951d780e80a71\",\"title\":\"Supervoxel Attention Graphs for Long-Range Video Modeling\",\"url\":\"https://www.semanticscholar.org/paper/86a9e09459c5a4e436706d0b89f951d780e80a71\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"2003.08042\",\"authors\":[{\"authorId\":\"66562585\",\"name\":\"Xu Li\"},{\"authorId\":\"46584062\",\"name\":\"Junling Wang\"},{\"authorId\":\"152309767\",\"name\":\"L. Ma\"},{\"authorId\":\"3397429\",\"name\":\"K. Zhang\"},{\"authorId\":\"1568961008\",\"name\":\"Fengzong Lian\"},{\"authorId\":\"2705857\",\"name\":\"Zhanhui Kang\"},{\"authorId\":\"71563118\",\"name\":\"Jinjun Wang\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"786a010cb738fe28bb44fcff790966a380c9da56\",\"title\":\"STH: Spatio-Temporal Hybrid Convolution for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/786a010cb738fe28bb44fcff790966a380c9da56\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.10260\",\"authors\":[{\"authorId\":\"29936554\",\"name\":\"Madhawa Vidanapathirana\"},{\"authorId\":\"7351931\",\"name\":\"Supriya Pandhre\"},{\"authorId\":\"1752600856\",\"name\":\"Sonia Raychaudhuri\"},{\"authorId\":\"30060974\",\"name\":\"Anjali Khurana\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9fdc58ef2b1cbd4f7be32fab19cda112e8674d78\",\"title\":\"Video Moment Localization using Object Evidence and Reverse Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9fdc58ef2b1cbd4f7be32fab19cda112e8674d78\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.06149\",\"authors\":[{\"authorId\":\"2283619\",\"name\":\"Peisen Zhao\"},{\"authorId\":\"3041937\",\"name\":\"Lingxi Xie\"},{\"authorId\":\"49890039\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/tmm.2020.3025665\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6c1fc76cc67ad82df1f7695b4d9e0b7536a70732\",\"title\":\"Universal-to-Specific Framework for Complex Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6c1fc76cc67ad82df1f7695b4d9e0b7536a70732\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1905.12462\",\"authors\":[{\"authorId\":\"1756362\",\"name\":\"Swathikiran Sudhakaran\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"adec3b5b4ebccbdacdcd0c805f7c73501852b3cd\",\"title\":\"Hierarchical Feature Aggregation Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/adec3b5b4ebccbdacdcd0c805f7c73501852b3cd\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2004.05054\",\"authors\":[{\"authorId\":\"51000619\",\"name\":\"Evgeny Izutov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f4436c77e4232d36d95f95989d2e5ae2fa0b0514\",\"title\":\"ASL Recognition with Metric-Learning based Lightweight Network\",\"url\":\"https://www.semanticscholar.org/paper/f4436c77e4232d36d95f95989d2e5ae2fa0b0514\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.00826\",\"authors\":[{\"authorId\":null,\"name\":\"Zihao Wang\"},{\"authorId\":\"5739094\",\"name\":\"Chen Lin\"},{\"authorId\":\"1999541581\",\"name\":\"Lu Sheng\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\"},{\"authorId\":\"1388486428\",\"name\":\"Jing Shao\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"316931202b0d02d37672a976f43bb1ed479c6877\",\"title\":\"PV-NAS: Practical Neural Architecture Search for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/316931202b0d02d37672a976f43bb1ed479c6877\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.10071\",\"authors\":[{\"authorId\":\"48170161\",\"name\":\"L. Wang\"},{\"authorId\":\"9445458\",\"name\":\"Zhan Tong\"},{\"authorId\":\"1511715446\",\"name\":\"Bin Ji\"},{\"authorId\":\"39914710\",\"name\":\"Gangshan Wu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"839a009d4d530483cb9b365012ffc7d76cd88b85\",\"title\":\"TDN: Temporal Difference Networks for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/839a009d4d530483cb9b365012ffc7d76cd88b85\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143995146\",\"name\":\"Hao Huang\"},{\"authorId\":\"48206987\",\"name\":\"L. Zhou\"},{\"authorId\":\"90638604\",\"name\":\"W. Zhang\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3341898f570384ce310445d6f3f0b6c598831a61\",\"title\":\"Dynamic Graph Modules for Modeling Object-Object Interactions in Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3341898f570384ce310445d6f3f0b6c598831a61\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"1912.03613\",\"authors\":[{\"authorId\":\"143954557\",\"name\":\"J. Jones\"},{\"authorId\":\"2542995\",\"name\":\"T. Kim\"},{\"authorId\":\"51207689\",\"name\":\"Michael Peven\"},{\"authorId\":\"9381483\",\"name\":\"Zihao Xiao\"},{\"authorId\":\"144878724\",\"name\":\"J. Bai\"},{\"authorId\":\"48379752\",\"name\":\"Yufu Zhang\"},{\"authorId\":\"3256056\",\"name\":\"Weichao Qiu\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"},{\"authorId\":\"1678633\",\"name\":\"Gregory Hager\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3aa1c9750ccf9da321db7b893776c060a1d0a7b3\",\"title\":\"DAZSL: Dynamic Attributes for Zero-Shot Learning\",\"url\":\"https://www.semanticscholar.org/paper/3aa1c9750ccf9da321db7b893776c060a1d0a7b3\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2000124994\",\"name\":\"Mo Sun\"},{\"authorId\":\"81752599\",\"name\":\"J. Li\"},{\"authorId\":\"151503256\",\"name\":\"Hui Feng\"},{\"authorId\":\"2000123285\",\"name\":\"Wei Gou\"},{\"authorId\":\"153784017\",\"name\":\"Haifeng Shen\"},{\"authorId\":\"152226504\",\"name\":\"J. Tang\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"},{\"authorId\":\"2778556\",\"name\":\"Jie-ping Ye\"}],\"doi\":\"10.1145/3382507.3417971\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d0afe00d375df35342afd0723689aa9570c28863\",\"title\":\"Multi-modal Fusion Using Spatio-temporal and Static Features for Group Emotion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d0afe00d375df35342afd0723689aa9570c28863\",\"venue\":\"ICMI\",\"year\":2020},{\"arxivId\":\"2010.09982\",\"authors\":[{\"authorId\":\"1993669388\",\"name\":\"Yuqian Fu\"},{\"authorId\":\"31267246\",\"name\":\"L. Zhang\"},{\"authorId\":\"1993529318\",\"name\":\"Junke Wang\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1145/3394171.3413502\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8abe9a4d432cc4c43a11f9336cd105d1be30ae92\",\"title\":\"Depth Guided Adaptive Meta-Fusion Network for Few-shot Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8abe9a4d432cc4c43a11f9336cd105d1be30ae92\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1772198\",\"name\":\"X. Wu\"},{\"authorId\":\"3307319\",\"name\":\"Qing-Ge Ji\"}],\"doi\":\"10.1145/3426826.3426836\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"64469e496132f3e25cdc5bfcfb3b7069c5e15ac4\",\"title\":\"Split and Attentive-Aggregated Learnable Shift Module for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/64469e496132f3e25cdc5bfcfb3b7069c5e15ac4\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2003.07637\",\"authors\":[{\"authorId\":\"49724493\",\"name\":\"H. Zhang\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1007/978-3-030-58565-5_15\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"180d7e45e5fc84138039f738830950dd9b7d0e06\",\"title\":\"Motion-Excited Sampler: Video Adversarial Attack with Sparked Prior\",\"url\":\"https://www.semanticscholar.org/paper/180d7e45e5fc84138039f738830950dd9b7d0e06\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d2925b1a75c72728d2d90157c1d1057cbc5da8b9\",\"title\":\"Structured Procedural Knowledge Extraction from Cooking Videos\",\"url\":\"https://www.semanticscholar.org/paper/d2925b1a75c72728d2d90157c1d1057cbc5da8b9\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1909.13130\",\"authors\":[{\"authorId\":\"153918891\",\"name\":\"Chenxu Luo\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.1109/ICCV.2019.00561\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8b8fe4727c8094b17e61886e69a602f8d0403091\",\"title\":\"Grouped Spatial-Temporal Aggregation for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b8fe4727c8094b17e61886e69a602f8d0403091\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"97375393\",\"name\":\"Mengmeng Xu\"},{\"authorId\":null,\"name\":\"Chen Zhao\"},{\"authorId\":\"4042496\",\"name\":\"M. Ramazanova\"},{\"authorId\":\"144723836\",\"name\":\"D. Rojas\"},{\"authorId\":\"1872964\",\"name\":\"Ali K. Thabet\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"41076692\",\"name\":\"King Abdullah\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"0d8c7303d3961bef10584df2839290686e63e05d\",\"title\":\"Improve Baseline for Temporal Action Detection: HACS Challenge 2020 Solution of IVUL-KAUST team\",\"url\":\"https://www.semanticscholar.org/paper/0d8c7303d3961bef10584df2839290686e63e05d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2002.05907\",\"authors\":[{\"authorId\":\"153108483\",\"name\":\"Bin Ren\"},{\"authorId\":\"47842072\",\"name\":\"M. Liu\"},{\"authorId\":\"2705961\",\"name\":\"R. Ding\"},{\"authorId\":\"10114692\",\"name\":\"Hong Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0a8196cd5905812dbdfb87096bcb7d2433ede93e\",\"title\":\"A Survey on 3D Skeleton-Based Action Recognition Using Learning Method\",\"url\":\"https://www.semanticscholar.org/paper/0a8196cd5905812dbdfb87096bcb7d2433ede93e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1909.04743\",\"authors\":[{\"authorId\":\"15727192\",\"name\":\"Tete Xiao\"},{\"authorId\":\"33421444\",\"name\":\"Quanfu Fan\"},{\"authorId\":\"1891570\",\"name\":\"Dan Gutfreund\"},{\"authorId\":\"95743023\",\"name\":\"Mathew Monfort\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"}],\"doi\":\"10.1109/ICCV.2019.00402\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"98b6d3f69e37e6bf33ea270ac28773d86e778c34\",\"title\":\"Reasoning About Human-Object Interactions Through Dual Attention Networks\",\"url\":\"https://www.semanticscholar.org/paper/98b6d3f69e37e6bf33ea270ac28773d86e778c34\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2005.06803\",\"authors\":[{\"authorId\":\"46270766\",\"name\":\"Zhaoyang Liu\"},{\"authorId\":\"29461006\",\"name\":\"L. Wang\"},{\"authorId\":\"3096434\",\"name\":\"W. Wu\"},{\"authorId\":\"7350503\",\"name\":\"Chen Qian\"},{\"authorId\":\"144720251\",\"name\":\"Tong Lu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3ac6ad718bbdeda6b5b00b61983f8b520d8a6bcb\",\"title\":\"TAM: Temporal Adaptive Module for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3ac6ad718bbdeda6b5b00b61983f8b520d8a6bcb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2004228925\",\"name\":\"Jinhao Duan\"},{\"authorId\":\"40463478\",\"name\":\"H. Xu\"},{\"authorId\":\"48030229\",\"name\":\"Xiaozhu Lin\"},{\"authorId\":\"2004346653\",\"name\":\"Shangchao Zhu\"},{\"authorId\":\"115394762\",\"name\":\"Y. Du\"}],\"doi\":\"10.1016/j.imavis.2020.103988\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"68e1892f95de0a982571c0c5df1c12c42364ee11\",\"title\":\"Multi-semantic long-range dependencies capturing for efficient video representation learning\",\"url\":\"https://www.semanticscholar.org/paper/68e1892f95de0a982571c0c5df1c12c42364ee11\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1904.02811\",\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"}],\"doi\":\"10.1109/ICCV.2019.00565\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f4852f5385d60e8870e30db5c65392d120e58574\",\"title\":\"Video Classification With Channel-Separated Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/f4852f5385d60e8870e30db5c65392d120e58574\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2012.02109\",\"authors\":[{\"authorId\":\"2542995\",\"name\":\"T. Kim\"},{\"authorId\":\"1678633\",\"name\":\"Gregory Hager\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"72b19a0125ddda2752cfcf8c5758a13c52275665\",\"title\":\"SAFCAR: Structured Attention Fusion for Compositional Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/72b19a0125ddda2752cfcf8c5758a13c52275665\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1906.11415\",\"authors\":[{\"authorId\":\"48865984\",\"name\":\"Kaidi Cao\"},{\"authorId\":\"2547290\",\"name\":\"Jingwei Ji\"},{\"authorId\":\"3451430\",\"name\":\"Zhangjie Cao\"},{\"authorId\":\"4251916\",\"name\":\"C. Chang\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/cvpr42600.2020.01063\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ede7829b3f057a874c513919d19307e2b60ead23\",\"title\":\"Few-Shot Video Classification via Temporal Alignment\",\"url\":\"https://www.semanticscholar.org/paper/ede7829b3f057a874c513919d19307e2b60ead23\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1908.02486\",\"authors\":[{\"authorId\":\"51128181\",\"name\":\"Boyuan Jiang\"},{\"authorId\":\"47446949\",\"name\":\"M. Wang\"},{\"authorId\":\"35893447\",\"name\":\"W. Gan\"},{\"authorId\":\"145717890\",\"name\":\"W. Wu\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\"}],\"doi\":\"10.1109/ICCV.2019.00209\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b812b20192ffac37b03bde0261934a2a8c7fdf47\",\"title\":\"STM: SpatioTemporal and Motion Encoding for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b812b20192ffac37b03bde0261934a2a8c7fdf47\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2006.14582\",\"authors\":[{\"authorId\":\"50079897\",\"name\":\"X. Li\"},{\"authorId\":null,\"name\":\"Yali Wang\"},{\"authorId\":\"1491073267\",\"name\":\"Zhipeng Zhou\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1109/cvpr42600.2020.00117\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"da9b802ea051ffb7ef2de0d8d1003944a60bf44c\",\"title\":\"SmallBigNet: Integrating Core and Contextual Views for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/da9b802ea051ffb7ef2de0d8d1003944a60bf44c\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2006.16228\",\"authors\":[{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"39257069\",\"name\":\"A. Recasens\"},{\"authorId\":\"145721402\",\"name\":\"Ros\\u00e1lia G. Schneider\"},{\"authorId\":\"2299479\",\"name\":\"R. Arandjelovi\\u0107\"},{\"authorId\":\"16092809\",\"name\":\"Jason Ramapuram\"},{\"authorId\":\"3364908\",\"name\":\"J. Fauw\"},{\"authorId\":\"1466466597\",\"name\":\"Lucas Smaira\"},{\"authorId\":\"48373216\",\"name\":\"S. Dieleman\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4174f03c7d8d9add62ae4ecd0ec90efba680b7ae\",\"title\":\"Self-Supervised MultiModal Versatile Networks\",\"url\":\"https://www.semanticscholar.org/paper/4174f03c7d8d9add62ae4ecd0ec90efba680b7ae\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2012.08041\",\"authors\":[{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"50557221\",\"name\":\"Chunhui Liu\"},{\"authorId\":\"2521776\",\"name\":\"B. Shuai\"},{\"authorId\":\"1805946041\",\"name\":\"Yi Zhu\"},{\"authorId\":\"48444479\",\"name\":\"Hao Chen\"},{\"authorId\":\"2397422\",\"name\":\"Joseph Tighe\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f0d55ca0b8f1639372e88479516a573e2bf2250b\",\"title\":\"NUTA: Non-uniform Temporal Aggregation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f0d55ca0b8f1639372e88479516a573e2bf2250b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2008.03462\",\"authors\":[{\"authorId\":\"145586191\",\"name\":\"Can Zhang\"},{\"authorId\":\"26981150\",\"name\":\"Yue-Xian Zou\"},{\"authorId\":\"143930563\",\"name\":\"G. Chen\"},{\"authorId\":\"48204311\",\"name\":\"L. Gan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"60840dce8073545641198c297796902fa390c719\",\"title\":\"PAN: Towards Fast Action Recognition via Learning Persistence of Appearance\",\"url\":\"https://www.semanticscholar.org/paper/60840dce8073545641198c297796902fa390c719\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2007.11365\",\"authors\":[{\"authorId\":\"39440469\",\"name\":\"Sudhakar Kumawat\"},{\"authorId\":\"145879750\",\"name\":\"Manisha Verma\"},{\"authorId\":\"1789677\",\"name\":\"Yuta Nakashima\"},{\"authorId\":\"145853779\",\"name\":\"S. Raman\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4914a205aa1ddeaae3c86a449c69703c89484f54\",\"title\":\"Depthwise Spatio-Temporal STFT Convolutional Neural Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4914a205aa1ddeaae3c86a449c69703c89484f54\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.05133\",\"authors\":[{\"authorId\":\"46522476\",\"name\":\"Xiaoli Liu\"},{\"authorId\":\"72002635\",\"name\":\"Jianqin Yin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"abe5568862f396d18f0a4892e8e06d9a86e6206d\",\"title\":\"SDMTL: Semi-Decoupled Multi-grained Trajectory Learning for 3D human motion prediction\",\"url\":\"https://www.semanticscholar.org/paper/abe5568862f396d18f0a4892e8e06d9a86e6206d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144406781\",\"name\":\"Lijun He\"},{\"authorId\":\"2035803194\",\"name\":\"Shuai Wen\"},{\"authorId\":\"2199437\",\"name\":\"L. Wang\"},{\"authorId\":\"1825677658\",\"name\":\"Fan Li\"}],\"doi\":\"10.1007/s10489-020-01933-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb68cda0fdd2e9fec857ff8016b3a74912ceb57e\",\"title\":\"Vehicle theft recognition from surveillance video based on spatiotemporal attention\",\"url\":\"https://www.semanticscholar.org/paper/eb68cda0fdd2e9fec857ff8016b3a74912ceb57e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2007.09933\",\"authors\":[{\"authorId\":\"30557120\",\"name\":\"Heeseung Kwon\"},{\"authorId\":\"16142867\",\"name\":\"Manjin Kim\"},{\"authorId\":\"2483916\",\"name\":\"Suha Kwak\"},{\"authorId\":\"72643925\",\"name\":\"Minsu Cho\"}],\"doi\":\"10.1007/978-3-030-58517-4_21\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b5be8a78db1631159500e7cee249729820e355b2\",\"title\":\"MotionSqueeze: Neural Motion Feature Learning for Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/b5be8a78db1631159500e7cee249729820e355b2\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2006.15473\",\"authors\":[{\"authorId\":\"4962557\",\"name\":\"L. Trinh\"},{\"authorId\":\"49130616\",\"name\":\"M. Tsang\"},{\"authorId\":\"2267664\",\"name\":\"Sirisha Rambhatla\"},{\"authorId\":\"49422024\",\"name\":\"Y. Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f797892f9270eca7fd63dc9681cfbfe398baf378\",\"title\":\"Interpretable Deepfake Detection via Dynamic Prototypes\",\"url\":\"https://www.semanticscholar.org/paper/f797892f9270eca7fd63dc9681cfbfe398baf378\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.00830\",\"authors\":[{\"authorId\":\"34678431\",\"name\":\"F. Sener\"},{\"authorId\":\"1734802895\",\"name\":\"Dipika Singhania\"},{\"authorId\":\"1803321310\",\"name\":\"Angela Yao\"}],\"doi\":\"10.1007/978-3-030-58517-4_10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c8f191fa7b5c51af0810b0996a0ef25b4db4d9a\",\"title\":\"Temporal Aggregate Representations for Long-Range Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/6c8f191fa7b5c51af0810b0996a0ef25b4db4d9a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152390773\",\"name\":\"B. Jiang\"},{\"authorId\":\"46696524\",\"name\":\"Lei Zhou\"},{\"authorId\":\"152644243\",\"name\":\"L. Lin\"},{\"authorId\":\"36557488\",\"name\":\"B. Xu\"},{\"authorId\":\"4074288\",\"name\":\"Jiahong Yu\"},{\"authorId\":\"70538826\",\"name\":\"Xu-ping Zheng\"},{\"authorId\":\"119685358\",\"name\":\"K. Wu\"}],\"doi\":\"10.1109/ICIP.2019.8803838\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2283ea00819c199394589af4710e47b36789c297\",\"title\":\"A Real-Time Multi-Label Classification System for Short Videos\",\"url\":\"https://www.semanticscholar.org/paper/2283ea00819c199394589af4710e47b36789c297\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"1912.03716\",\"authors\":[{\"authorId\":\"91060830\",\"name\":\"Zhiyu Yao\"},{\"authorId\":null,\"name\":\"Yunbo Wang\"},{\"authorId\":\"93640403\",\"name\":\"Xingqiang Du\"},{\"authorId\":\"35776445\",\"name\":\"Mingsheng Long\"},{\"authorId\":\"46583978\",\"name\":\"J. Wang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2df80c3db4550da81854e05a24e658bacec564a2\",\"title\":\"Adversarial Pyramid Network for Video Domain Generalization\",\"url\":\"https://www.semanticscholar.org/paper/2df80c3db4550da81854e05a24e658bacec564a2\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2000153057\",\"name\":\"Zhikang Qiu\"},{\"authorId\":null,\"name\":\"Xu Zhao\"},{\"authorId\":\"49941675\",\"name\":\"Zhilan Hu\"}],\"doi\":\"10.1109/ICIP40778.2020.9190997\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"593fa71e5cad2afcc4b105c45d5ee4eae101bf54\",\"title\":\"Efficient Temporal-Spatial Feature Grouping For Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/593fa71e5cad2afcc4b105c45d5ee4eae101bf54\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48133807\",\"name\":\"Y. Chang\"},{\"authorId\":\"143822897\",\"name\":\"Zhe Yu Liu\"},{\"authorId\":\"3403825\",\"name\":\"Kuan-Ying Lee\"},{\"authorId\":\"1716836\",\"name\":\"W. Hsu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0bd7b15c7ae060eb029490d5b18617977eb28812\",\"title\":\"Learnable Gated Temporal Shift Module for Deep Video Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/0bd7b15c7ae060eb029490d5b18617977eb28812\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1912.08860\",\"authors\":[{\"authorId\":\"26432578\",\"name\":\"Emmanuel Kahembwe\"},{\"authorId\":\"47172195\",\"name\":\"S. Ramamoorthy\"}],\"doi\":\"10.1016/j.neunet.2020.09.016\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1f313226533edea306c4de79df945cc5a90d153c\",\"title\":\"Lower Dimensional Kernels for Video Discriminators\",\"url\":\"https://www.semanticscholar.org/paper/1f313226533edea306c4de79df945cc5a90d153c\",\"venue\":\"Neural Networks\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152142657\",\"name\":\"Y. Tian\"},{\"authorId\":\"1825799769\",\"name\":\"Guangzhao Zhai\"},{\"authorId\":\"97709070\",\"name\":\"Z. Gao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"5768e26731fb55edced4193596f6a470d0029ce6\",\"title\":\"Video-ception Network: Towards Multi-Scale Efficient Asymmetric Spatial-Temporal Interactions\",\"url\":\"https://www.semanticscholar.org/paper/5768e26731fb55edced4193596f6a470d0029ce6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.11757\",\"authors\":[{\"authorId\":\"48239920\",\"name\":\"Chun-Fu Chen\"},{\"authorId\":\"1819152\",\"name\":\"R. Panda\"},{\"authorId\":\"40544169\",\"name\":\"K. Ramakrishnan\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"38060482\",\"name\":\"J. M. Cohn\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"33421444\",\"name\":\"Quanfu Fan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f5c2623a44660ad9fe6cd46710fec6e812a3375a\",\"title\":\"Deep Analysis of CNN-based Spatio-temporal Representations for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f5c2623a44660ad9fe6cd46710fec6e812a3375a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390626541\",\"name\":\"Ziming Liu\"},{\"authorId\":\"2041335607\",\"name\":\"Jinyang Li\"},{\"authorId\":\"47296615\",\"name\":\"Guangyu Gao\"},{\"authorId\":\"2041264362\",\"name\":\"Alex K. Qin\"}],\"doi\":\"10.1109/ACCESS.2020.3043386\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"16df18da2ab27ef1affeefe62ab842ce0f9d8520\",\"title\":\"Temporal Memory Network Towards Real-Time Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/16df18da2ab27ef1affeefe62ab842ce0f9d8520\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2005.06111\",\"authors\":[{\"authorId\":\"2465856\",\"name\":\"Yen-Chia Hsu\"},{\"authorId\":\"144188081\",\"name\":\"Ting-Hao Kenneth Huang\"},{\"authorId\":\"2998709\",\"name\":\"Ting-yao Hu\"},{\"authorId\":\"6336229\",\"name\":\"P. Dille\"},{\"authorId\":\"1693980281\",\"name\":\"Sean Prendi\"},{\"authorId\":\"12628113\",\"name\":\"R. Hoffman\"},{\"authorId\":\"1693976434\",\"name\":\"Anastasia Tsuhlares\"},{\"authorId\":\"144669295\",\"name\":\"R. Sargent\"},{\"authorId\":\"84502304\",\"name\":\"Illah Nourbakhsh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fe9d1eca471ff7298e0f0aacd605873e25c15d9e\",\"title\":\"Project RISE: Recognizing Industrial Smoke Emissions\",\"url\":\"https://www.semanticscholar.org/paper/fe9d1eca471ff7298e0f0aacd605873e25c15d9e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1903.10520\",\"authors\":[{\"authorId\":\"2383133\",\"name\":\"Siyuan Qiao\"},{\"authorId\":\"46506170\",\"name\":\"Huiyu Wang\"},{\"authorId\":\"50557601\",\"name\":\"Chenxi Liu\"},{\"authorId\":\"144084228\",\"name\":\"Wei Shen\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"caa2704320e3742bc611c30092acd7a7eb87d5d4\",\"title\":\"Weight Standardization\",\"url\":\"https://www.semanticscholar.org/paper/caa2704320e3742bc611c30092acd7a7eb87d5d4\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2001.09691\",\"authors\":[{\"authorId\":\"47077615\",\"name\":\"J. Munro\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.1109/ICCVW.2019.00461\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"10cf610ca725cdf459f6a4fa68999066b586b93a\",\"title\":\"Multi-Modal Domain Adaptation for Fine-Grained Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/10cf610ca725cdf459f6a4fa68999066b586b93a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"2009.11050\",\"authors\":[{\"authorId\":\"121149599\",\"name\":\"A. Sabater\"},{\"authorId\":\"1408203017\",\"name\":\"L. Montesano\"},{\"authorId\":\"1991008\",\"name\":\"A. C. Murillo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d5ffd40a83c10a04d9d1cd0fd77db19e58188237\",\"title\":\"Robust and efficient post-processing for video object detection\",\"url\":\"https://www.semanticscholar.org/paper/d5ffd40a83c10a04d9d1cd0fd77db19e58188237\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.09216\",\"authors\":[{\"authorId\":\"30857985\",\"name\":\"Nishant Bhattacharya\"},{\"authorId\":\"2000307852\",\"name\":\"Suresh Sundaram\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"06adf1a80e110f4c78c31f072824726aeeed1a1a\",\"title\":\"CGAP2: Context and gap aware predictive pose framework for early detection of gestures\",\"url\":\"https://www.semanticscholar.org/paper/06adf1a80e110f4c78c31f072824726aeeed1a1a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.08652\",\"authors\":[{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"2025664854\",\"name\":\"Emad Bahrami Rad\"},{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"2199924\",\"name\":\"M. Noroozi\"},{\"authorId\":\"46408185\",\"name\":\"E. Adeli\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"80ddd8e76480aa92aa071d33c624af7195b0b762\",\"title\":\"3D CNNs with Adaptive Temporal Feature Resolutions\",\"url\":\"https://www.semanticscholar.org/paper/80ddd8e76480aa92aa071d33c624af7195b0b762\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1912.04430\",\"authors\":[{\"authorId\":\"3121735\",\"name\":\"Paritosh Parmar\"},{\"authorId\":\"49059658\",\"name\":\"B. Morris.\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7aef63bbe103760e78f359223e35562cdaed16c1\",\"title\":\"HalluciNet-ing Spatiotemporal Representations Using 2D-CNN\",\"url\":\"https://www.semanticscholar.org/paper/7aef63bbe103760e78f359223e35562cdaed16c1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34608005\",\"name\":\"L. Chen\"},{\"authorId\":\"144207288\",\"name\":\"R. Liu\"},{\"authorId\":\"153450634\",\"name\":\"Dongsheng Zhou\"},{\"authorId\":\"50031413\",\"name\":\"X. Yang\"},{\"authorId\":\"47835286\",\"name\":\"Qing-fang Zhang\"}],\"doi\":\"10.1186/s42492-020-00045-x\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"115880905156feef7d751840b7f59c72987b17a8\",\"title\":\"Fused behavior recognition model based on attention mechanism\",\"url\":\"https://www.semanticscholar.org/paper/115880905156feef7d751840b7f59c72987b17a8\",\"venue\":\"Vis. Comput. Ind. Biomed. Art\",\"year\":2020},{\"arxivId\":\"2007.01883\",\"authors\":[{\"authorId\":\"1397974082\",\"name\":\"Juan-Manuel Perez-Rua\"},{\"authorId\":\"3098817\",\"name\":\"Antoine Toisoul\"},{\"authorId\":\"145944235\",\"name\":\"B. Mart\\u00ednez\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"48571183\",\"name\":\"Liyong Zhang\"},{\"authorId\":\"2171228\",\"name\":\"Xiatian Zhu\"},{\"authorId\":\"145406420\",\"name\":\"Tao Xiang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"dbdf7284a37d6bc9c68e3fe17596850b9cd6a1bb\",\"title\":\"Egocentric Action Recognition by Video Attention and Temporal Context\",\"url\":\"https://www.semanticscholar.org/paper/dbdf7284a37d6bc9c68e3fe17596850b9cd6a1bb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30679763\",\"name\":\"Xuezhe Li\"},{\"authorId\":\"153109159\",\"name\":\"L. Wen\"},{\"authorId\":\"71563118\",\"name\":\"Jinjun Wang\"},{\"authorId\":\"2020817\",\"name\":\"Ming Zeng\"}],\"doi\":\"10.1109/ICAICA50127.2020.9182498\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5b679ccceefd9605661115e6e2391ad3c9076168\",\"title\":\"Spatio-temporal Collaborative Convolution for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5b679ccceefd9605661115e6e2391ad3c9076168\",\"venue\":\"2020 IEEE International Conference on Artificial Intelligence and Computer Applications (ICAICA)\",\"year\":2020},{\"arxivId\":\"2011.12372\",\"authors\":[{\"authorId\":\"50065546\",\"name\":\"W. Price\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f6378d6130b82f083882db4c0bf2065b6a3e59b8\",\"title\":\"Play Fair: Frame Attributions in Video Models\",\"url\":\"https://www.semanticscholar.org/paper/f6378d6130b82f083882db4c0bf2065b6a3e59b8\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1912.04070\",\"authors\":[{\"authorId\":\"82657029\",\"name\":\"G. Varol\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d9cd1ffcd91ef7e51b7a6bb4e65a3fada4e11244\",\"title\":\"Synthetic Humans for Action Recognition from Unseen Viewpoints\",\"url\":\"https://www.semanticscholar.org/paper/d9cd1ffcd91ef7e51b7a6bb4e65a3fada4e11244\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1994488088\",\"name\":\"Lianyu Hu\"},{\"authorId\":\"152150149\",\"name\":\"Lin Feng\"},{\"authorId\":\"8602618\",\"name\":\"Shenglan Liu\"}],\"doi\":\"10.1145/3422844.3423052\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"661a89fbbe1fadc94c145af3a6a1ddb79c7d99a1\",\"title\":\"HFNet: A Novel Model for Human Focused Sports Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/661a89fbbe1fadc94c145af3a6a1ddb79c7d99a1\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1647005624\",\"name\":\"Xuejian Rong\"},{\"authorId\":\"65754626\",\"name\":\"D. Demandolx\"},{\"authorId\":\"40353974\",\"name\":\"K. Matzen\"},{\"authorId\":\"38084876\",\"name\":\"Priyam Chatterjee\"},{\"authorId\":\"35484757\",\"name\":\"Yingli Tian\"}],\"doi\":\"10.1007/978-3-030-58601-0_15\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bf584ec11c9fb822c1d133f1f98efe0b74260ce2\",\"title\":\"Burst Denoising via Temporally Shifted Wavelet Transforms\",\"url\":\"https://www.semanticscholar.org/paper/bf584ec11c9fb822c1d133f1f98efe0b74260ce2\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2009.05224\",\"authors\":[{\"authorId\":\"3795834\",\"name\":\"J. Chung\"},{\"authorId\":\"1940024152\",\"name\":\"C. Wuu\"},{\"authorId\":\"1940708423\",\"name\":\"Hsuan-ru Yang\"},{\"authorId\":\"5068280\",\"name\":\"Yu-Wing Tai\"},{\"authorId\":\"2088295\",\"name\":\"C. Tang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d5635ee061af4321d5de2076d4834a4f96012551\",\"title\":\"HAA500: Human-Centric Atomic Action Dataset with Curated Videos\",\"url\":\"https://www.semanticscholar.org/paper/d5635ee061af4321d5de2076d4834a4f96012551\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.07358\",\"authors\":[{\"authorId\":\"2283619\",\"name\":\"Peisen Zhao\"},{\"authorId\":\"3041937\",\"name\":\"Lingxi Xie\"},{\"authorId\":\"2899544\",\"name\":\"C. Ju\"},{\"authorId\":\"49890039\",\"name\":\"Y. Zhang\"},{\"authorId\":null,\"name\":\"Yanfeng Wang\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1007/978-3-030-58598-3_32\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"44e8ddac792f35105dd4db176345515f531a0b71\",\"title\":\"Bottom-Up Temporal Action Localization with Mutual Regularization\",\"url\":\"https://www.semanticscholar.org/paper/44e8ddac792f35105dd4db176345515f531a0b71\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2005.00706\",\"authors\":[{\"authorId\":\"40027632\",\"name\":\"F. F. Xu\"},{\"authorId\":\"144906579\",\"name\":\"Lei Ji\"},{\"authorId\":\"119700639\",\"name\":\"Botian Shi\"},{\"authorId\":\"3109653\",\"name\":\"Junyi Du\"},{\"authorId\":\"1700325\",\"name\":\"Graham Neubig\"},{\"authorId\":\"3312309\",\"name\":\"Yonatan Bisk\"},{\"authorId\":\"46429989\",\"name\":\"N. Duan\"}],\"doi\":\"10.18653/v1/2020.nlpbt-1.4\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"358d7d6333d3edd530e37efd8004cb9da8cfd5d4\",\"title\":\"A Benchmark for Structured Procedural Knowledge Extraction from Cooking Videos\",\"url\":\"https://www.semanticscholar.org/paper/358d7d6333d3edd530e37efd8004cb9da8cfd5d4\",\"venue\":\"NLPBT\",\"year\":2020},{\"arxivId\":\"2010.05654\",\"authors\":[{\"authorId\":\"39714216\",\"name\":\"F. Ragusa\"},{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"2444519\",\"name\":\"S. Livatino\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a58a0732664b97b471b795df5812f98f24840490\",\"title\":\"The MECCANO Dataset: Understanding Human-Object Interactions from Egocentric Videos in an Industrial-like Domain\",\"url\":\"https://www.semanticscholar.org/paper/a58a0732664b97b471b795df5812f98f24840490\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.02426\",\"authors\":[{\"authorId\":\"1879292723\",\"name\":\"Junwei Liang\"},{\"authorId\":\"48749954\",\"name\":\"L. Cao\"},{\"authorId\":\"3182065\",\"name\":\"Xuehan Xiong\"},{\"authorId\":\"2029317446\",\"name\":\"Ting Yu\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e84c8a5b818d6c121083550bae9bda257a4df60f\",\"title\":\"Spatial-Temporal Alignment Network for Action Recognition and Detection\",\"url\":\"https://www.semanticscholar.org/paper/e84c8a5b818d6c121083550bae9bda257a4df60f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.07626\",\"authors\":[{\"authorId\":\"28969692\",\"name\":\"Junwu Weng\"},{\"authorId\":\"9393671\",\"name\":\"Donghao Luo\"},{\"authorId\":null,\"name\":\"Yabiao Wang\"},{\"authorId\":\"144970872\",\"name\":\"Ying Tai\"},{\"authorId\":\"1978245\",\"name\":\"Chengjie Wang\"},{\"authorId\":\"49298244\",\"name\":\"Jilin Li\"},{\"authorId\":\"1835006\",\"name\":\"Feiyue Huang\"},{\"authorId\":\"3307580\",\"name\":\"Xudong Jiang\"},{\"authorId\":\"48837492\",\"name\":\"J. Yuan\"}],\"doi\":\"10.1007/978-3-030-58571-6_22\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"cfb71e0cce6487b6a1cf2dd0cd3755d1d78e908e\",\"title\":\"Temporal Distinct Representation Learning for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cfb71e0cce6487b6a1cf2dd0cd3755d1d78e908e\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1906.07052\",\"authors\":[{\"authorId\":\"31415725\",\"name\":\"Chen-Lin Zhang\"},{\"authorId\":\"49543907\",\"name\":\"Xin-Xin Liu\"},{\"authorId\":\"49388002\",\"name\":\"Jianxin Wu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ed2fd4d36340c61e4af9ff6fbf33c336c45458f1\",\"title\":\"Towards Real-Time Action Recognition on Mobile Devices Using Deep Models\",\"url\":\"https://www.semanticscholar.org/paper/ed2fd4d36340c61e4af9ff6fbf33c336c45458f1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2004.01278\",\"authors\":[{\"authorId\":\"1397974082\",\"name\":\"Juan-Manuel Perez-Rua\"},{\"authorId\":\"145944235\",\"name\":\"B. Mart\\u00ednez\"},{\"authorId\":\"2171228\",\"name\":\"Xiatian Zhu\"},{\"authorId\":\"3098817\",\"name\":\"Antoine Toisoul\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"145406420\",\"name\":\"Tao Xiang\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8fcc3c2e525307f7a694979500dcca09d0f3a830\",\"title\":\"Knowing What, Where and When to Look: Efficient Video Action Modeling with Attention\",\"url\":\"https://www.semanticscholar.org/paper/8fcc3c2e525307f7a694979500dcca09d0f3a830\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.13017\",\"authors\":[{\"authorId\":\"143657833\",\"name\":\"Li Tao\"},{\"authorId\":\"1524733293\",\"name\":\"Xueting Wang\"},{\"authorId\":\"145572095\",\"name\":\"T. Yamasaki\"}],\"doi\":\"10.1109/ICIP40778.2020.9191133\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3cfee833437b81b89bb272dd4f5a501b61f2c0d1\",\"title\":\"Motion Representation Using Residual Frames with 3D CNN\",\"url\":\"https://www.semanticscholar.org/paper/3cfee833437b81b89bb272dd4f5a501b61f2c0d1\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"2008.10428\",\"authors\":[{\"authorId\":\"1400188907\",\"name\":\"Hezhen Hu\"},{\"authorId\":\"51476742\",\"name\":\"Wengang Zhou\"},{\"authorId\":\"2653622\",\"name\":\"Junfu Pu\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"cc338010de2bfba5dcf52d61bbb0ea3fe5495cea\",\"title\":\"Global-local Enhancement Network for NMFs-aware Sign Language Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cc338010de2bfba5dcf52d61bbb0ea3fe5495cea\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.10247\",\"authors\":[{\"authorId\":\"5764695\",\"name\":\"Y. Zeng\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"41079034\",\"name\":\"Hong-Yang Chao\"}],\"doi\":\"10.1007/978-3-030-58517-4_31\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f7f89feee68b6856c0a980a5888b42d18231be07\",\"title\":\"Learning Joint Spatial-Temporal Transformations for Video Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/f7f89feee68b6856c0a980a5888b42d18231be07\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1912.00869\",\"authors\":[{\"authorId\":\"33421444\",\"name\":\"Quanfu Fan\"},{\"authorId\":\"48239920\",\"name\":\"Chun-Fu Chen\"},{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"134455051\",\"name\":\"Marco Pistoia\"},{\"authorId\":\"66305116\",\"name\":\"D. Cox\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9c77ffc223e47388155a6e3bf58ae294f51f9ccb\",\"title\":\"More Is Less: Learning Efficient Video Representations by Big-Little Network and Depthwise Temporal Aggregation\",\"url\":\"https://www.semanticscholar.org/paper/9c77ffc223e47388155a6e3bf58ae294f51f9ccb\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151472652\",\"name\":\"Yuqi Huo\"},{\"authorId\":\"101246507\",\"name\":\"Xiaoli Xu\"},{\"authorId\":\"46215480\",\"name\":\"Yao Lu\"},{\"authorId\":\"2520427\",\"name\":\"Yulei Niu\"},{\"authorId\":\"48876151\",\"name\":\"Mingyu Ding\"},{\"authorId\":\"1776220\",\"name\":\"Zhiwu Lu\"},{\"authorId\":\"145406420\",\"name\":\"Tao Xiang\"},{\"authorId\":\"153693432\",\"name\":\"Jirong Wen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"89fafbe91b31d43dc3314ffabffa79a5f5ad746f\",\"title\":\"Lightweight Action Recognition in Compressed Videos\",\"url\":\"https://www.semanticscholar.org/paper/89fafbe91b31d43dc3314ffabffa79a5f5ad746f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1485630780\",\"name\":\"Yanbin Hao\"},{\"authorId\":\"100468488\",\"name\":\"Z. Liu\"},{\"authorId\":\"145063759\",\"name\":\"Hao Zhang\"},{\"authorId\":\"46511118\",\"name\":\"Bin Zhu\"},{\"authorId\":\"1742506579\",\"name\":\"J. Chen\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"143977389\",\"name\":\"C. Ngo\"}],\"doi\":\"10.1145/3394171.3416276\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"c0b8cb284b37718375ff9f134f5c61b8fa098243\",\"title\":\"Person-level Action Recognition in Complex Events via TSD-TSM Networks\",\"url\":\"https://www.semanticscholar.org/paper/c0b8cb284b37718375ff9f134f5c61b8fa098243\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1904.10247\",\"authors\":[{\"authorId\":\"48133807\",\"name\":\"Y. Chang\"},{\"authorId\":\"143822897\",\"name\":\"Zhe Yu Liu\"},{\"authorId\":\"3403825\",\"name\":\"Kuan-Ying Lee\"},{\"authorId\":\"31871157\",\"name\":\"Winston Hsu\"}],\"doi\":\"10.1109/ICCV.2019.00916\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e8705ab4b9626c1ab6442483731fe0371f2234b6\",\"title\":\"Free-Form Video Inpainting With 3D Gated Convolution and Temporal PatchGAN\",\"url\":\"https://www.semanticscholar.org/paper/e8705ab4b9626c1ab6442483731fe0371f2234b6\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2009.07420\",\"authors\":[{\"authorId\":\"3671120\",\"name\":\"Yanyi Zhang\"},{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"144555425\",\"name\":\"I. Marsic\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d951f225ab2d64af36e9c44a658ac79c2afde7f3\",\"title\":\"Multi-Label Activity Recognition using Activity-specific Features\",\"url\":\"https://www.semanticscholar.org/paper/d951f225ab2d64af36e9c44a658ac79c2afde7f3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.14950\",\"authors\":[{\"authorId\":\"26959701\",\"name\":\"Hengduo Li\"},{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":null,\"name\":\"Abhinav Shrivastava\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f434d65e76041d3417715791e052255f924d4efc\",\"title\":\"2D or not 2D? Adaptive 3D Convolution Selection for Efficient Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f434d65e76041d3417715791e052255f924d4efc\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2004.01823\",\"authors\":[{\"authorId\":\"143672737\",\"name\":\"A. Mu\\u00f1oz\"},{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"49965376\",\"name\":\"Max Argus\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"31ce95cc12c4e58fd5d7051d9797589859d5dda1\",\"title\":\"Temporal Shift GAN for Large Scale Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/31ce95cc12c4e58fd5d7051d9797589859d5dda1\",\"venue\":\"\",\"year\":2020}],\"corpusId\":85542740,\"doi\":\"10.1109/ICCV.2019.00718\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":60,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"4bbfd46721c145852e443ae4aad35148b814bf91\",\"references\":[{\"arxivId\":\"1611.01578\",\"authors\":[{\"authorId\":\"2368067\",\"name\":\"Barret Zoph\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"67d968c7450878190e45ac7886746de867bf673d\",\"title\":\"Neural Architecture Search with Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/67d968c7450878190e45ac7886746de867bf673d\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1510.00562\",\"authors\":[{\"authorId\":\"41191188\",\"name\":\"Lin Sun\"},{\"authorId\":\"2370507\",\"name\":\"K. Jia\"},{\"authorId\":\"1739816\",\"name\":\"D. Yeung\"},{\"authorId\":\"2131088\",\"name\":\"B. Shi\"}],\"doi\":\"10.1109/ICCV.2015.522\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"95561aec9f00cdf5346e627574e1a022eda3e4f5\",\"title\":\"Human Action Recognition Using Factorized Spatio-Temporal Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/95561aec9f00cdf5346e627574e1a022eda3e4f5\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1212.0402\",\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"title\":\"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\",\"url\":\"https://www.semanticscholar.org/paper/da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Andrew G Howard\"},{\"authorId\":null,\"name\":\"Menglong Zhu\"},{\"authorId\":null,\"name\":\"Bo Chen\"},{\"authorId\":null,\"name\":\"Dmitry Kalenichenko\"},{\"authorId\":null,\"name\":\"Weijun Wang\"},{\"authorId\":null,\"name\":\"Tobias Weyand\"},{\"authorId\":null,\"name\":\"Hartwig Adam\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and J\\u00fcrgen Schmidhuber . Long short - term memory\",\"url\":\"\",\"venue\":\"Neural computation\",\"year\":1997},{\"arxivId\":\"1406.2199\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"title\":\"Two-Stream Convolutional Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1711.08141\",\"authors\":[{\"authorId\":\"3130257\",\"name\":\"B. Wu\"},{\"authorId\":\"144546548\",\"name\":\"Alvin Wan\"},{\"authorId\":\"27577617\",\"name\":\"Xiangyu Yue\"},{\"authorId\":\"32294544\",\"name\":\"P. Jin\"},{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"30096597\",\"name\":\"Noah Golmant\"},{\"authorId\":\"3647010\",\"name\":\"A. Gholaminejad\"},{\"authorId\":\"49988044\",\"name\":\"Joseph E. Gonzalez\"},{\"authorId\":\"1732330\",\"name\":\"K. Keutzer\"}],\"doi\":\"10.1109/CVPR.2018.00951\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"70c810ba62c5ee40d611e134b2ac2ca61c4de16b\",\"title\":\"Shift: A Zero FLOP, Zero Parameter Alternative to Spatial Convolutions\",\"url\":\"https://www.semanticscholar.org/paper/70c810ba62c5ee40d611e134b2ac2ca61c4de16b\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1809.08458\",\"authors\":[{\"authorId\":\"9280313\",\"name\":\"Huasong Zhong\"},{\"authorId\":\"9137409\",\"name\":\"Xianggen Liu\"},{\"authorId\":\"39838894\",\"name\":\"Yihui He\"},{\"authorId\":\"7777496\",\"name\":\"Yuchun Ma\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"36da6d76342545135d5d575e6d0847e18550b377\",\"title\":\"Shift-based Primitives for Efficient Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/36da6d76342545135d5d575e6d0847e18550b377\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1612.01064\",\"authors\":[{\"authorId\":\"7883636\",\"name\":\"Chenzhuo Zhu\"},{\"authorId\":\"143840277\",\"name\":\"Song Han\"},{\"authorId\":\"3123774\",\"name\":\"Huizi Mao\"},{\"authorId\":\"80724002\",\"name\":\"W. Dally\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d418295cd3027c43eccc5592ae5b8303ba8192be\",\"title\":\"Trained Ternary Quantization\",\"url\":\"https://www.semanticscholar.org/paper/d418295cd3027c43eccc5592ae5b8303ba8192be\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1409.0575\",\"authors\":[{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"71309570\",\"name\":\"H. Su\"},{\"authorId\":\"2285165\",\"name\":\"J. Krause\"},{\"authorId\":\"145031342\",\"name\":\"S. Satheesh\"},{\"authorId\":\"145423516\",\"name\":\"S. Ma\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-015-0816-y\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"title\":\"ImageNet Large Scale Visual Recognition Challenge\",\"url\":\"https://www.semanticscholar.org/paper/e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":\"1806.01810\",\"authors\":[{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1007/978-3-030-01228-1_25\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d7cbf2d3ea63d97b699cc04af98fea521459ee75\",\"title\":\"Videos as Space-Time Region Graphs\",\"url\":\"https://www.semanticscholar.org/paper/d7cbf2d3ea63d97b699cc04af98fea521459ee75\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1511.04119\",\"authors\":[{\"authorId\":\"145478041\",\"name\":\"Shikhar Sharma\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7b8810ad8ef9ddd024583f95a51559e6c1b8c754\",\"title\":\"Action Recognition using Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/7b8810ad8ef9ddd024583f95a51559e6c1b8c754\",\"venue\":\"NIPS 2015\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yi Li\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Squeezenet : Alexnet - level accuracy with 50 x fewer parameters and \\u00a1 0 . 5 mb model size Batch normalization : Accelerating deep network training by reducing internal co - variate shift\",\"url\":\"\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Bolei Zhou\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"poral relational reasoning in videos\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1711.09125\",\"authors\":[{\"authorId\":\"119770705\",\"name\":\"L. Wang\"},{\"authorId\":\"48625175\",\"name\":\"W. Li\"},{\"authorId\":\"145344553\",\"name\":\"W. Li\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2018.00155\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e6b534d8838f92461a478a3e737b73e08db94748\",\"title\":\"Appearance-and-Relation Networks for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/e6b534d8838f92461a478a3e737b73e08db94748\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1704.04861\",\"authors\":[{\"authorId\":\"144727050\",\"name\":\"A. Howard\"},{\"authorId\":\"2717876\",\"name\":\"Menglong Zhu\"},{\"authorId\":null,\"name\":\"Bo Chen\"},{\"authorId\":\"2741985\",\"name\":\"D. Kalenichenko\"},{\"authorId\":\"47825047\",\"name\":\"W. Wang\"},{\"authorId\":\"47447630\",\"name\":\"Tobias Weyand\"},{\"authorId\":\"2612392\",\"name\":\"M. Andreetto\"},{\"authorId\":\"2595180\",\"name\":\"H. Adam\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3647d6d0f151dc05626449ee09cc7bce55be497e\",\"title\":\"MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications\",\"url\":\"https://www.semanticscholar.org/paper/3647d6d0f151dc05626449ee09cc7bce55be497e\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1502.03167\",\"authors\":[{\"authorId\":\"144147316\",\"name\":\"S. Ioffe\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d376d6978dad0374edfa6709c9556b42d3594d3\",\"title\":\"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\",\"url\":\"https://www.semanticscholar.org/paper/4d376d6978dad0374edfa6709c9556b42d3594d3\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1711.09550\",\"authors\":[{\"authorId\":\"144858226\",\"name\":\"Xiang Long\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144608002\",\"name\":\"Gerard de Melo\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"48033101\",\"name\":\"Xiao Liu\"},{\"authorId\":\"35247507\",\"name\":\"Shilei Wen\"}],\"doi\":\"10.1109/CVPR.2018.00817\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5406fd98aa22bc2a0c1a8bc2a58ca3eb7a91155d\",\"title\":\"Attention Clusters: Purely Attention Based Local Feature Integration for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/5406fd98aa22bc2a0c1a8bc2a58ca3eb7a91155d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1705.06950\",\"authors\":[{\"authorId\":\"21028601\",\"name\":\"W. Kay\"},{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"11809518\",\"name\":\"Brian Zhang\"},{\"authorId\":\"38961760\",\"name\":\"Chloe Hillier\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"143740871\",\"name\":\"F. Viola\"},{\"authorId\":\"143897708\",\"name\":\"T. Green\"},{\"authorId\":\"2830305\",\"name\":\"T. Back\"},{\"authorId\":\"1820908\",\"name\":\"A. Natsev\"},{\"authorId\":\"2573615\",\"name\":\"Mustafa Suleyman\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6\",\"title\":\"The Kinetics Human Action Video Dataset\",\"url\":\"https://www.semanticscholar.org/paper/86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1410.0759\",\"authors\":[{\"authorId\":\"3003738\",\"name\":\"Sharan Chetlur\"},{\"authorId\":\"2266717\",\"name\":\"C. Woolley\"},{\"authorId\":\"2101730\",\"name\":\"Philippe Vandermersch\"},{\"authorId\":\"145678733\",\"name\":\"J. Cohen\"},{\"authorId\":\"145927488\",\"name\":\"John Tran\"},{\"authorId\":\"2301680\",\"name\":\"Bryan Catanzaro\"},{\"authorId\":\"1782282\",\"name\":\"Evan Shelhamer\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"31c36d445367ba204244bb74893c5654e31c3869\",\"title\":\"cuDNN: Efficient Primitives for Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/31c36d445367ba204244bb74893c5654e31c3869\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"152821938\",\"name\":\"Sanketh Shetty\"},{\"authorId\":\"120906511\",\"name\":\"T. Leung\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2014.223\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"title\":\"Large-Scale Video Classification with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Hildegard Kuehne\"},{\"authorId\":null,\"name\":\"Hueihan Jhuang\"},{\"authorId\":null,\"name\":\"Est\\u0131\\u0301baliz Garrote\"},{\"authorId\":null,\"name\":\"Tomaso Poggio\"},{\"authorId\":null,\"name\":\"Thomas Serre\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Hmdb: a large video 7090 database for human motion recognition\",\"url\":\"\",\"venue\":\"In Computer Vision (ICCV),\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3407277\",\"name\":\"Adam Paszke\"},{\"authorId\":\"39793298\",\"name\":\"S. Gross\"},{\"authorId\":\"2127604\",\"name\":\"Soumith Chintala\"},{\"authorId\":\"114250963\",\"name\":\"G. Chanan\"},{\"authorId\":\"50064334\",\"name\":\"E. Yang\"},{\"authorId\":\"81505016\",\"name\":\"Zachary Devito\"},{\"authorId\":\"3370429\",\"name\":\"Zeming Lin\"},{\"authorId\":\"3050846\",\"name\":\"Alban Desmaison\"},{\"authorId\":\"3029482\",\"name\":\"L. Antiga\"},{\"authorId\":\"1977806\",\"name\":\"A. Lerer\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b36a5bb1707bb9c70025294b3a310138aae8327a\",\"title\":\"Automatic differentiation in PyTorch\",\"url\":\"https://www.semanticscholar.org/paper/b36a5bb1707bb9c70025294b3a310138aae8327a\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1807.11626\",\"authors\":[{\"authorId\":\"2554604\",\"name\":\"M. Tan\"},{\"authorId\":null,\"name\":\"Bo Chen\"},{\"authorId\":\"34320634\",\"name\":\"R. Pang\"},{\"authorId\":\"38062095\",\"name\":\"V. Vasudevan\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"}],\"doi\":\"10.1109/CVPR.2019.00293\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"693c97ecedb0a84539b7162c95e89fa3cd84ca73\",\"title\":\"MnasNet: Platform-Aware Neural Architecture Search for Mobile\",\"url\":\"https://www.semanticscholar.org/paper/693c97ecedb0a84539b7162c95e89fa3cd84ca73\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1506.02626\",\"authors\":[{\"authorId\":\"143840277\",\"name\":\"Song Han\"},{\"authorId\":\"47325862\",\"name\":\"J. Pool\"},{\"authorId\":\"145927488\",\"name\":\"John Tran\"},{\"authorId\":\"80724002\",\"name\":\"W. Dally\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1ff9a37d766e3a4f39757f5e1b235a42dacf18ff\",\"title\":\"Learning both Weights and Connections for Efficient Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/1ff9a37d766e3a4f39757f5e1b235a42dacf18ff\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1510.00149\",\"authors\":[{\"authorId\":\"143840277\",\"name\":\"Song Han\"},{\"authorId\":\"3123774\",\"name\":\"Huizi Mao\"},{\"authorId\":\"80724002\",\"name\":\"W. Dally\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"642d0f49b7826adcf986616f4af77e736229990f\",\"title\":\"Deep Compression: Compressing Deep Neural Network with Pruning, Trained Quantization and Huffman Coding\",\"url\":\"https://www.semanticscholar.org/paper/642d0f49b7826adcf986616f4af77e736229990f\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"2976163\",\"name\":\"Kuiyuan Yang\"},{\"authorId\":null,\"name\":\"Yi Yang\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2016.106\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"26201e1b76f276187e31c7db84eab0bfcda01102\",\"title\":\"You Lead, We Exceed: Labor-Free Video Concept Learning by Jointly Exploiting Web Videos and Images\",\"url\":\"https://www.semanticscholar.org/paper/26201e1b76f276187e31c7db84eab0bfcda01102\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1611.02155\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5f4d2f6ad967f7c9369c04e75cda08f12cb8afbd\",\"title\":\"Spatiotemporal Residual Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5f4d2f6ad967f7c9369c04e75cda08f12cb8afbd\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1707.07012\",\"authors\":[{\"authorId\":\"2368067\",\"name\":\"Barret Zoph\"},{\"authorId\":\"1695525\",\"name\":\"V. Vasudevan\"},{\"authorId\":\"1789737\",\"name\":\"Jonathon Shlens\"},{\"authorId\":\"1397917613\",\"name\":\"Quoc V. Le\"}],\"doi\":\"10.1109/CVPR.2018.00907\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d0611891b9e8a7c5731146097b6f201578f47b2f\",\"title\":\"Learning Transferable Architectures for Scalable Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d0611891b9e8a7c5731146097b6f201578f47b2f\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1807.10037\",\"authors\":[{\"authorId\":\"2647624\",\"name\":\"Myunggi Lee\"},{\"authorId\":\"51151436\",\"name\":\"Seungeui Lee\"},{\"authorId\":\"9044475\",\"name\":\"Sung Joon Son\"},{\"authorId\":\"51136389\",\"name\":\"G. Park\"},{\"authorId\":\"3160425\",\"name\":\"N. Kwak\"}],\"doi\":\"10.1007/978-3-030-01249-6_24\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10a1dcbe52547146fa4735274e8c89ae01e70a55\",\"title\":\"Motion Feature Network: Fixed Motion Filter for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/10a1dcbe52547146fa4735274e8c89ae01e70a55\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1707.01083\",\"authors\":[{\"authorId\":\"50875121\",\"name\":\"X. Zhang\"},{\"authorId\":\"47155568\",\"name\":\"X. Zhou\"},{\"authorId\":\"3287035\",\"name\":\"Mengxiao Lin\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/CVPR.2018.00716\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9da734397acd7ff7c557960c62fb1b400b27bd89\",\"title\":\"ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices\",\"url\":\"https://www.semanticscholar.org/paper/9da734397acd7ff7c557960c62fb1b400b27bd89\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"48246959\",\"name\":\"Naiyan Wang\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"},{\"authorId\":\"1739816\",\"name\":\"D. Yeung\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1109/CVPR.2015.7298872\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3de050d1707524512eeab99780df3cbdee09670c\",\"title\":\"DevNet: A Deep Event Network for multimedia event detection and evidence recounting\",\"url\":\"https://www.semanticscholar.org/paper/3de050d1707524512eeab99780df3cbdee09670c\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1713941\",\"name\":\"Christopher Zach\"},{\"authorId\":\"1730097\",\"name\":\"T. Pock\"},{\"authorId\":\"144746444\",\"name\":\"H. Bischof\"}],\"doi\":\"10.1007/978-3-540-74936-3_22\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f6bbe9afab5fd61f36de5461e9e6a30ca462c7c\",\"title\":\"A Duality Based Approach for Realtime TV-L1 Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/0f6bbe9afab5fd61f36de5461e9e6a30ca462c7c\",\"venue\":\"DAGM-Symposium\",\"year\":2007},{\"arxivId\":\"1608.00859\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-319-46484-8_2\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"title\":\"Temporal Segment Networks: Towards Good Practices for Deep Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1712.04851\",\"authors\":[{\"authorId\":\"1817030\",\"name\":\"Saining Xie\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"1808244\",\"name\":\"J. Huang\"},{\"authorId\":\"144035504\",\"name\":\"Zhuowen Tu\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":\"10.1007/978-3-030-01267-0_19\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"815aa52cfc02961d82415f080384594639a21984\",\"title\":\"Rethinking Spatiotemporal Feature Learning: Speed-Accuracy Trade-offs in Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/815aa52cfc02961d82415f080384594639a21984\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1706.04261\",\"authors\":[{\"authorId\":\"38962424\",\"name\":\"Raghav Goyal\"},{\"authorId\":\"3127597\",\"name\":\"S. Kahou\"},{\"authorId\":\"1748421\",\"name\":\"Vincent Michalski\"},{\"authorId\":\"7654960\",\"name\":\"Joanna Materzynska\"},{\"authorId\":\"12929417\",\"name\":\"S. Westphal\"},{\"authorId\":\"2233986\",\"name\":\"Heuna Kim\"},{\"authorId\":\"7241984\",\"name\":\"V. Haenel\"},{\"authorId\":\"47544625\",\"name\":\"Ingo Fr\\u00fcnd\"},{\"authorId\":\"19265538\",\"name\":\"Peter Yianilos\"},{\"authorId\":\"1414405239\",\"name\":\"Moritz Mueller-Freitag\"},{\"authorId\":\"143931146\",\"name\":\"F. Hoppe\"},{\"authorId\":\"2020614\",\"name\":\"Christian Thurau\"},{\"authorId\":\"2443288\",\"name\":\"I. Bax\"},{\"authorId\":\"1710604\",\"name\":\"R. Memisevic\"}],\"doi\":\"10.1109/ICCV.2017.622\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b68811a9b5cafe4795a11c1048541750068b7ad0\",\"title\":\"The \\u201cSomething Something\\u201d Video Database for Learning and Evaluating Visual Common Sense\",\"url\":\"https://www.semanticscholar.org/paper/b68811a9b5cafe4795a11c1048541750068b7ad0\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1162/neco.1997.9.8.1735\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"title\":\"Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"venue\":\"Neural Computation\",\"year\":1997},{\"arxivId\":\"1607.01794\",\"authors\":[{\"authorId\":\"3245057\",\"name\":\"Zhenyang Li\"},{\"authorId\":\"32781361\",\"name\":\"Kirill Gavrilyuk\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"143798882\",\"name\":\"Mihir Jain\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1016/j.cviu.2017.10.011\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"86031f555c128b82a1ac0db89ff4faeae16a1802\",\"title\":\"VideoLSTM convolves, attends and flows for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/86031f555c128b82a1ac0db89ff4faeae16a1802\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2018},{\"arxivId\":\"1604.01753\",\"authors\":[{\"authorId\":\"34280810\",\"name\":\"Gunnar A. Sigurdsson\"},{\"authorId\":\"2668759\",\"name\":\"G. Varol\"},{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1007/978-3-319-46448-0_31\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"21334d1aac5422da88780f8e24e181bfa15ef0e1\",\"title\":\"Hollywood in Homes: Crowdsourcing Data Collection for Activity Understanding\",\"url\":\"https://www.semanticscholar.org/paper/21334d1aac5422da88780f8e24e181bfa15ef0e1\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1802.04799\",\"authors\":[{\"authorId\":\"1913774\",\"name\":\"T. Chen\"},{\"authorId\":\"47108160\",\"name\":\"T. Moreau\"},{\"authorId\":\"1732910\",\"name\":\"Ziheng Jiang\"},{\"authorId\":\"11455132\",\"name\":\"Lianmin Zheng\"},{\"authorId\":\"2621619\",\"name\":\"Eddie Q. Yan\"},{\"authorId\":\"3050154\",\"name\":\"Haichen Shen\"},{\"authorId\":\"37270394\",\"name\":\"Meghan Cowan\"},{\"authorId\":\"2185540\",\"name\":\"Leyuan Wang\"},{\"authorId\":\"49994783\",\"name\":\"Yuwei Hu\"},{\"authorId\":\"1717411\",\"name\":\"L. Ceze\"},{\"authorId\":\"1730156\",\"name\":\"Carlos Guestrin\"},{\"authorId\":\"144695691\",\"name\":\"A. Krishnamurthy\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"df013a17ab84d5403361da4538a04d574f58be83\",\"title\":\"TVM: An Automated End-to-End Optimizing Compiler for Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/df013a17ab84d5403361da4538a04d574f58be83\",\"venue\":\"OSDI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46698300\",\"name\":\"Ji Lin\"},{\"authorId\":\"39358728\",\"name\":\"Yongming Rao\"},{\"authorId\":\"1697700\",\"name\":\"Jiwen Lu\"},{\"authorId\":\"49640256\",\"name\":\"J. Zhou\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"88cd4209db62a34d9cba0b9cbe9d45d1e57d21e5\",\"title\":\"Runtime Neural Pruning\",\"url\":\"https://www.semanticscholar.org/paper/88cd4209db62a34d9cba0b9cbe9d45d1e57d21e5\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1712.00559\",\"authors\":[{\"authorId\":\"50557601\",\"name\":\"Chenxi Liu\"},{\"authorId\":\"2368067\",\"name\":\"Barret Zoph\"},{\"authorId\":\"1789737\",\"name\":\"Jonathon Shlens\"},{\"authorId\":\"145221796\",\"name\":\"W. Hua\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"},{\"authorId\":\"4240351\",\"name\":\"Jonathan Huang\"},{\"authorId\":\"145601650\",\"name\":\"K. Murphy\"}],\"doi\":\"10.1007/978-3-030-01246-5_2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5f79398057bf0bbda9ff50067bc1f2950c2a2266\",\"title\":\"Progressive Neural Architecture Search\",\"url\":\"https://www.semanticscholar.org/paper/5f79398057bf0bbda9ff50067bc1f2950c2a2266\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/ICCV.2015.510\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"title\":\"Learning Spatiotemporal Features with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1704.02895\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"145160921\",\"name\":\"Bryan C. Russell\"}],\"doi\":\"10.1109/CVPR.2017.337\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"63213d080a43660ac59ea12e3c35e6953f6d7ce8\",\"title\":\"ActionVLAD: Learning Spatio-Temporal Aggregation for Action Classification\",\"url\":\"https://www.semanticscholar.org/paper/63213d080a43660ac59ea12e3c35e6953f6d7ce8\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1604.06573\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2016.213\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9d9aced120e530484609164c836da64548693484\",\"title\":\"Convolutional Two-Stream Network Fusion for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9d9aced120e530484609164c836da64548693484\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1503.08909\",\"authors\":[{\"authorId\":\"2340579\",\"name\":\"J. Ng\"},{\"authorId\":\"3308897\",\"name\":\"Matthew J. Hausknecht\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"49519592\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"3089272\",\"name\":\"Rajat Monga\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"}],\"doi\":\"10.1109/CVPR.2015.7299101\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5418b2a482720e013d487a385c26fae0f017c6a6\",\"title\":\"Beyond short snippets: Deep networks for video classification\",\"url\":\"https://www.semanticscholar.org/paper/5418b2a482720e013d487a385c26fae0f017c6a6\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1711.08496\",\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"50112310\",\"name\":\"Alex Andonian\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1007/978-3-030-01246-5_49\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8ad12d3ee186403b856639b58d7797aa4b89a6c7\",\"title\":\"Temporal Relational Reasoning in Videos\",\"url\":\"https://www.semanticscholar.org/paper/8ad12d3ee186403b856639b58d7797aa4b89a6c7\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1812.00332\",\"authors\":[{\"authorId\":\"145834074\",\"name\":\"Han Cai\"},{\"authorId\":\"20515689\",\"name\":\"Ligeng Zhu\"},{\"authorId\":\"143840277\",\"name\":\"Song Han\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dc8b789446416383bfafe9b1c504c4a2b17e68d1\",\"title\":\"ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware\",\"url\":\"https://www.semanticscholar.org/paper/dc8b789446416383bfafe9b1c504c4a2b17e68d1\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23214073\",\"name\":\"Kuan Wang\"},{\"authorId\":\"47781592\",\"name\":\"Zhijian Liu\"},{\"authorId\":\"49417466\",\"name\":\"Yujun Lin\"},{\"authorId\":\"46698300\",\"name\":\"Ji Lin\"},{\"authorId\":\"143840277\",\"name\":\"Song Han\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"df71a17df5350b0dbf8e5e084ae56a65cee9aaf8\",\"title\":\"HAQ: Hardware-Aware Automated Quantization\",\"url\":\"https://www.semanticscholar.org/paper/df71a17df5350b0dbf8e5e084ae56a65cee9aaf8\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1602.07360\",\"authors\":[{\"authorId\":\"3346186\",\"name\":\"Forrest N. Iandola\"},{\"authorId\":\"2318023\",\"name\":\"Matthew W. Moskewicz\"},{\"authorId\":\"2059241\",\"name\":\"K. Ashraf\"},{\"authorId\":\"143840277\",\"name\":\"Song Han\"},{\"authorId\":\"80724002\",\"name\":\"W. Dally\"},{\"authorId\":\"1732330\",\"name\":\"K. Keutzer\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"969fbdcd0717bec06228053788c2ff78bbb4daac\",\"title\":\"SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <1MB model size\",\"url\":\"https://www.semanticscholar.org/paper/969fbdcd0717bec06228053788c2ff78bbb4daac\",\"venue\":\"CVPR 2017\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Andonian Zhou\"},{\"authorId\":null,\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Temporal relational reasoning in videos Trained ternary quantization\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1811.08886\",\"authors\":[{\"authorId\":\"23214073\",\"name\":\"Kuan Wang\"},{\"authorId\":\"47781592\",\"name\":\"Zhijian Liu\"},{\"authorId\":\"49417466\",\"name\":\"Yujun Lin\"},{\"authorId\":\"46698300\",\"name\":\"Ji Lin\"},{\"authorId\":\"143840270\",\"name\":\"S. Han\"}],\"doi\":\"10.1109/CVPR.2019.00881\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"54c4642d017830e1faddbb49f0377228d2b01493\",\"title\":\"HAQ: Hardware-Aware Automated Quantization With Mixed Precision\",\"url\":\"https://www.semanticscholar.org/paper/54c4642d017830e1faddbb49f0377228d2b01493\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1705.07750\",\"authors\":[{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2017.502\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"title\":\"Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset\",\"url\":\"https://www.semanticscholar.org/paper/b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1611.05431\",\"authors\":[{\"authorId\":\"1817030\",\"name\":\"Saining Xie\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"144035504\",\"name\":\"Zhuowen Tu\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"}],\"doi\":\"10.1109/CVPR.2017.634\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f6e0856b4a9199fa968ac00da612a9407b5cb85c\",\"title\":\"Aggregated Residual Transformations for Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/f6e0856b4a9199fa968ac00da612a9407b5cb85c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1801.04381\",\"authors\":[{\"authorId\":\"144882893\",\"name\":\"Mark Sandler\"},{\"authorId\":\"144727050\",\"name\":\"A. Howard\"},{\"authorId\":\"2717876\",\"name\":\"Menglong Zhu\"},{\"authorId\":\"3422677\",\"name\":\"A. Zhmoginov\"},{\"authorId\":\"34192119\",\"name\":\"Liang-Chieh Chen\"}],\"doi\":\"10.1109/CVPR.2018.00474\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4\",\"title\":\"MobileNetV2: Inverted Residuals and Linear Bottlenecks\",\"url\":\"https://www.semanticscholar.org/paper/dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1409.4842\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"46641766\",\"name\":\"W. Liu\"},{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"},{\"authorId\":\"48840704\",\"name\":\"Scott Reed\"},{\"authorId\":\"1838674\",\"name\":\"Dragomir Anguelov\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"39863668\",\"name\":\"Andrew Rabinovich\"}],\"doi\":\"10.1109/CVPR.2015.7298594\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"title\":\"Going deeper with convolutions\",\"url\":\"https://www.semanticscholar.org/paper/e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1804.09066\",\"authors\":[{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"145264990\",\"name\":\"K. Singh\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1007/978-3-030-01216-8_43\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"aa63893b34f523973d0692dc74ff22512daac322\",\"title\":\"ECO: Efficient Convolutional Network for Online Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/aa63893b34f523973d0692dc74ff22512daac322\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1711.07971\",\"authors\":[{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"}],\"doi\":\"10.1109/CVPR.2018.00813\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8899094797e82c5c185a0893896320ef77f60e64\",\"title\":\"Non-local Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/8899094797e82c5c185a0893896320ef77f60e64\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2518212\",\"name\":\"Hakan Bilen\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1109/CVPR.2016.331\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5aae6f1aedb3e78a05bc430a1d8b86cac33c5184\",\"title\":\"Dynamic Image Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5aae6f1aedb3e78a05bc430a1d8b86cac33c5184\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1506.01497\",\"authors\":[{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"144716314\",\"name\":\"J. Sun\"}],\"doi\":\"10.1109/TPAMI.2016.2577031\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"title\":\"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\",\"url\":\"https://www.semanticscholar.org/paper/424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"2055900\",\"name\":\"Lixin Duan\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"}],\"doi\":\"10.1007/978-3-319-46487-9_52\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c5498b3cc5ac12ac5209ec3c8c751e87b59e9c31\",\"title\":\"Webly-Supervised Video Recognition by Mutually Voting for Relevant Web Images and Web Video Frames\",\"url\":\"https://www.semanticscholar.org/paper/c5498b3cc5ac12ac5209ec3c8c751e87b59e9c31\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1802.03494\",\"authors\":[{\"authorId\":\"39838894\",\"name\":\"Yihui He\"},{\"authorId\":\"46698300\",\"name\":\"Ji Lin\"},{\"authorId\":\"47781592\",\"name\":\"Zhijian Liu\"},{\"authorId\":\"35446689\",\"name\":\"Hanrui Wang\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"143840277\",\"name\":\"Song Han\"}],\"doi\":\"10.1007/978-3-030-01234-2_48\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1717255b6aea01fe956cef998abbc3c399b5d7cf\",\"title\":\"AMC: AutoML for Model Compression and Acceleration on Mobile Devices\",\"url\":\"https://www.semanticscholar.org/paper/1717255b6aea01fe956cef998abbc3c399b5d7cf\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1711.10305\",\"authors\":[{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/ICCV.2017.590\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"024d037d46ae933c7e12fd16af61953c7161773a\",\"title\":\"Learning Spatio-Temporal Representation with Pseudo-3D Residual Networks\",\"url\":\"https://www.semanticscholar.org/paper/024d037d46ae933c7e12fd16af61953c7161773a\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1711.11248\",\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"4439383\",\"name\":\"Jamie Ray\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/CVPR.2018.00675\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"89c3050522a0bb9820c32dc7444e003ef0d3e2e4\",\"title\":\"A Closer Look at Spatiotemporal Convolutions for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/89c3050522a0bb9820c32dc7444e003ef0d3e2e4\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"119268487\",\"name\":\"Hueihan Jhuang\"},{\"authorId\":\"1930964\",\"name\":\"E. Garrote\"},{\"authorId\":\"145031878\",\"name\":\"T. Poggio\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"}],\"doi\":\"10.1109/ICCV.2011.6126543\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8b3b8848a311c501e704c45c6d50430ab7068956\",\"title\":\"HMDB: A large video database for human motion recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b3b8848a311c501e704c45c6d50430ab7068956\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":\"1502.04681\",\"authors\":[{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"2711409\",\"name\":\"Elman Mansimov\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"title\":\"Unsupervised Learning of Video Representations using LSTMs\",\"url\":\"https://www.semanticscholar.org/paper/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1703.10025\",\"authors\":[{\"authorId\":\"2578924\",\"name\":\"X. Zhu\"},{\"authorId\":null,\"name\":\"Yujie Wang\"},{\"authorId\":\"3304536\",\"name\":\"Jifeng Dai\"},{\"authorId\":\"145347147\",\"name\":\"Lu Yuan\"},{\"authorId\":\"1732264\",\"name\":\"Y. Wei\"}],\"doi\":\"10.1109/ICCV.2017.52\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0246f6754c38324a837c0ebd1b51976f413f80ad\",\"title\":\"Flow-Guided Feature Aggregation for Video Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/0246f6754c38324a837c0ebd1b51976f413f80ad\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1605.06409\",\"authors\":[{\"authorId\":\"3304536\",\"name\":\"Jifeng Dai\"},{\"authorId\":\"47001807\",\"name\":\"Y. Li\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b724c3f7ff395235b62537203ddeb710f0eb27bb\",\"title\":\"R-FCN: Object Detection via Region-based Fully Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/b724c3f7ff395235b62537203ddeb710f0eb27bb\",\"venue\":\"NIPS\",\"year\":2016}],\"title\":\"TSM: Temporal Shift Module for Efficient Video Understanding\",\"topics\":[{\"topic\":\"Streaming media\",\"topicId\":\"1357\",\"url\":\"https://www.semanticscholar.org/topic/1357\"},{\"topic\":\"IBM Spectrum Protect (Tivoli Storage Manager)\",\"topicId\":\"662121\",\"url\":\"https://www.semanticscholar.org/topic/662121\"},{\"topic\":\"Video clip\",\"topicId\":\"30493\",\"url\":\"https://www.semanticscholar.org/topic/30493\"},{\"topic\":\"Computation\",\"topicId\":\"339\",\"url\":\"https://www.semanticscholar.org/topic/339\"},{\"topic\":\"Object detection\",\"topicId\":\"14349\",\"url\":\"https://www.semanticscholar.org/topic/14349\"},{\"topic\":\"Han unification\",\"topicId\":\"233807\",\"url\":\"https://www.semanticscholar.org/topic/233807\"},{\"topic\":\"Shadow mapping\",\"topicId\":\"349453\",\"url\":\"https://www.semanticscholar.org/topic/349453\"},{\"topic\":\"Internet backbone\",\"topicId\":\"15478\",\"url\":\"https://www.semanticscholar.org/topic/15478\"},{\"topic\":\"Real-time clock\",\"topicId\":\"121831\",\"url\":\"https://www.semanticscholar.org/topic/121831\"},{\"topic\":\"GNU nano\",\"topicId\":\"67424\",\"url\":\"https://www.semanticscholar.org/topic/67424\"}],\"url\":\"https://www.semanticscholar.org/paper/4bbfd46721c145852e443ae4aad35148b814bf91\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019}\n"