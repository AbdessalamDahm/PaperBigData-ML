"{\"abstract\":\"Learning how objects sound from video is challenging, since they often heavily overlap in a single audio channel. Current methods for visually-guided audio source separation sidestep the issue by training with artificially mixed video clips, but this puts unwieldy restrictions on training data collection and may even prevent learning the properties of \\\"true\\\" mixed sounds. We introduce a co-separation training paradigm that permits learning object-level sounds from unlabeled multi-source videos. Our novel training objective requires that the deep neural network's separated audio for similar-looking objects be consistently identifiable, while simultaneously reproducing accurate video-level audio tracks for each source training pair. Our approach disentangles sounds in realistic test videos, even in cases where an object was not observed individually during training. We obtain state-of-the-art results on visually-guided audio source separation and audio denoising for the MUSIC, AudioSet, and AV-Bench datasets.\",\"arxivId\":\"1904.07750\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\",\"url\":\"https://www.semanticscholar.org/author/3387849\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\",\"url\":\"https://www.semanticscholar.org/author/1794409\"}],\"citationVelocity\":20,\"citations\":[{\"arxivId\":\"2010.11904\",\"authors\":[{\"authorId\":\"27671219\",\"name\":\"Yun-Ning Hung\"},{\"authorId\":\"1816785\",\"name\":\"G. Wichern\"},{\"authorId\":\"9332945\",\"name\":\"Jonathan Le Roux\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"046265fca2871c91212be3cddb2c049b6073602e\",\"title\":\"Transcription Is All You Need: Learning to Separate Musical Mixtures with Score as Supervision\",\"url\":\"https://www.semanticscholar.org/paper/046265fca2871c91212be3cddb2c049b6073602e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.04210\",\"authors\":[{\"authorId\":\"2326243\",\"name\":\"Arun Balajee Vasudevan\"},{\"authorId\":\"1778526\",\"name\":\"Dengxin Dai\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-030-58548-8_37\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4d981cc84ee972104eb6d95a2421a42db8a0cf57\",\"title\":\"Semantic Object Prediction and Spatial Sound Super-Resolution with Binaural Sounds\",\"url\":\"https://www.semanticscholar.org/paper/4d981cc84ee972104eb6d95a2421a42db8a0cf57\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.10558\",\"authors\":[{\"authorId\":\"34777509\",\"name\":\"Yapeng Tian\"},{\"authorId\":\"40580714\",\"name\":\"Dingzeyu Li\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":\"10.1007/978-3-030-58580-8_26\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3867340091c920dc5f8ba462197fa5bc924a98c4\",\"title\":\"Unified Multisensory Perception: Weakly-Supervised Audio-Visual Video Parsing\",\"url\":\"https://www.semanticscholar.org/paper/3867340091c920dc5f8ba462197fa5bc924a98c4\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.05722\",\"authors\":[{\"authorId\":\"31836044\",\"name\":\"Takashi Oya\"},{\"authorId\":\"34279376\",\"name\":\"Shohei Iwase\"},{\"authorId\":\"41015901\",\"name\":\"R. Natsume\"},{\"authorId\":\"21583404\",\"name\":\"Takahiro Itazuri\"},{\"authorId\":\"3117231\",\"name\":\"Shugo Yamaguchi\"},{\"authorId\":\"1490867805\",\"name\":\"Shigeo Morishima\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"476d71a4cfd1529c4705636041add568853d74b1\",\"title\":\"Do We Need Sound for Sound Source Localization?\",\"url\":\"https://www.semanticscholar.org/paper/476d71a4cfd1529c4705636041add568853d74b1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.09476\",\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"145592817\",\"name\":\"D. Huang\"},{\"authorId\":\"47940821\",\"name\":\"Hang Zhao\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/CVPR42600.2020.01049\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b643a7186c08db9f13d7204f6e5e739f97902e71\",\"title\":\"Music Gesture for Visual Sound Separation\",\"url\":\"https://www.semanticscholar.org/paper/b643a7186c08db9f13d7204f6e5e739f97902e71\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2249568\",\"name\":\"S. Wisdom\"},{\"authorId\":\"18139933\",\"name\":\"Efthymios Tzinis\"},{\"authorId\":\"153441094\",\"name\":\"H. Erdogan\"},{\"authorId\":\"39571582\",\"name\":\"Ron J. Weiss\"},{\"authorId\":\"49210463\",\"name\":\"K. Wilson\"},{\"authorId\":\"2387467\",\"name\":\"J. Hershey\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"18779118a36942df135e401dc0d713b080be8782\",\"title\":\"Unsupervised Sound Separation Using Mixtures of Mixtures\",\"url\":\"https://www.semanticscholar.org/paper/18779118a36942df135e401dc0d713b080be8782\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2249568\",\"name\":\"S. Wisdom\"},{\"authorId\":\"18139933\",\"name\":\"Efthymios Tzinis\"},{\"authorId\":\"153441094\",\"name\":\"H. Erdogan\"},{\"authorId\":\"39571582\",\"name\":\"Ron J. Weiss\"},{\"authorId\":\"144514812\",\"name\":\"K. Wilson\"},{\"authorId\":\"2387467\",\"name\":\"J. Hershey\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"09f69b7b10de042698382c5ec74fe4dad0b386ab\",\"title\":\"Unsupervised Speech Separation Using Mixtures of Mixtures\",\"url\":\"https://www.semanticscholar.org/paper/09f69b7b10de042698382c5ec74fe4dad0b386ab\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9077277\",\"name\":\"Fatemeh Pishdadian\"},{\"authorId\":\"1816785\",\"name\":\"G. Wichern\"},{\"authorId\":\"9332945\",\"name\":\"Jonathan Le Roux\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053055\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0d586138abb80eba2144a1f2528d0d081ed9bbe6\",\"title\":\"Learning to Separate Sounds from Weakly Labeled Scenes\",\"url\":\"https://www.semanticscholar.org/paper/0d586138abb80eba2144a1f2528d0d081ed9bbe6\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"2011.01143\",\"authors\":[{\"authorId\":\"18139933\",\"name\":\"Efthymios Tzinis\"},{\"authorId\":\"34654283\",\"name\":\"Scott T. Wisdom\"},{\"authorId\":\"35996413\",\"name\":\"A. Jansen\"},{\"authorId\":\"50781940\",\"name\":\"Shawn Hershey\"},{\"authorId\":\"2211633\",\"name\":\"Tal Remez\"},{\"authorId\":\"1745455\",\"name\":\"D. Ellis\"},{\"authorId\":\"2387467\",\"name\":\"J. Hershey\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"8cc141d242387dc9b64124e97896097ddfd6bcf2\",\"title\":\"Into the Wild with AudioScope: Unsupervised Audio-Visual Separation of On-Screen Sounds\",\"url\":\"https://www.semanticscholar.org/paper/8cc141d242387dc9b64124e97896097ddfd6bcf2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"16149902\",\"name\":\"Janani Ramaswamy\"},{\"authorId\":\"144009889\",\"name\":\"Sukhendu Das\"}],\"doi\":\"10.1109/WACV45572.2020.9093616\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c911d81bddb48490a02258e79379b6428246ddc2\",\"title\":\"See the Sound, Hear the Pixels\",\"url\":\"https://www.semanticscholar.org/paper/c911d81bddb48490a02258e79379b6428246ddc2\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34777509\",\"name\":\"Yapeng Tian\"},{\"authorId\":\"1500378795\",\"name\":\"Di Hu\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"95a1979a34f2c93a184b77a19cb0a3818befd198\",\"title\":\"Co-Learn Sounding Object Visual Grounding and Visually Indicated Sound Separation in A Cycle\",\"url\":\"https://www.semanticscholar.org/paper/95a1979a34f2c93a184b77a19cb0a3818befd198\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2001.09414\",\"authors\":[{\"authorId\":\"153211990\",\"name\":\"Di Hu\"},{\"authorId\":\"98358780\",\"name\":\"Z. Wang\"},{\"authorId\":\"40518823\",\"name\":\"Haoyi Xiong\"},{\"authorId\":\"113144757\",\"name\":\"D. Wang\"},{\"authorId\":\"144962210\",\"name\":\"F. Nie\"},{\"authorId\":\"1721158\",\"name\":\"D. Dou\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"04b6568cb7f30c399157e94c30b44c59c00e251d\",\"title\":\"Curriculum Audiovisual Learning\",\"url\":\"https://www.semanticscholar.org/paper/04b6568cb7f30c399157e94c30b44c59c00e251d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.01616\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"153246625\",\"name\":\"Chang\\u2019an Chen\"},{\"authorId\":\"9187007\",\"name\":\"Z. Al-Halah\"},{\"authorId\":\"2368282\",\"name\":\"Carl Schissler\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1007/978-3-030-58545-7_38\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"33006edd74d92453903df5a53fa25539047c1850\",\"title\":\"VisualEchoes: Spatial Image Representation Learning through Echolocation\",\"url\":\"https://www.semanticscholar.org/paper/33006edd74d92453903df5a53fa25539047c1850\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.06355\",\"authors\":[{\"authorId\":\"47519958\",\"name\":\"Rui Qian\"},{\"authorId\":\"1500378795\",\"name\":\"Di Hu\"},{\"authorId\":\"2451839\",\"name\":\"H. Dinkel\"},{\"authorId\":\"3000684\",\"name\":\"Mengyue Wu\"},{\"authorId\":null,\"name\":\"Ning Xu\"},{\"authorId\":\"8131625\",\"name\":\"W. Lin\"}],\"doi\":\"10.1007/978-3-030-58565-5_18\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"53eb4c778e7c2aec2f4c5d2681321b18c06decca\",\"title\":\"Multiple Sound Sources Localization from Coarse to Fine\",\"url\":\"https://www.semanticscholar.org/paper/53eb4c778e7c2aec2f4c5d2681321b18c06decca\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1912.04487\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":\"10.1109/cvpr42600.2020.01047\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c4128ba8deeb67e731cf52fb98addcfddd487e55\",\"title\":\"Listen to Look: Action Recognition by Previewing Audio\",\"url\":\"https://www.semanticscholar.org/paper/c4128ba8deeb67e731cf52fb98addcfddd487e55\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153201597\",\"name\":\"Xinzhu Liu\"},{\"authorId\":\"46522240\",\"name\":\"X. Liu\"},{\"authorId\":\"66147945\",\"name\":\"Di Guo\"},{\"authorId\":\"31833173\",\"name\":\"H. Liu\"},{\"authorId\":\"38784685\",\"name\":\"Fu-chun Sun\"},{\"authorId\":\"50206854\",\"name\":\"H. Min\"}],\"doi\":\"10.1109/ICRA40945.2020.9197566\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"150904f599ee0771e319c162c71d90f3e29a879c\",\"title\":\"Self-Supervised Learning for Alignment of Objects and Sound\",\"url\":\"https://www.semanticscholar.org/paper/150904f599ee0771e319c162c71d90f3e29a879c\",\"venue\":\"2020 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2020},{\"arxivId\":\"2006.12701\",\"authors\":[{\"authorId\":\"2249568\",\"name\":\"S. Wisdom\"},{\"authorId\":\"18139933\",\"name\":\"Efthymios Tzinis\"},{\"authorId\":\"153441094\",\"name\":\"H. Erdogan\"},{\"authorId\":\"39571582\",\"name\":\"Ron J. Weiss\"},{\"authorId\":\"49210463\",\"name\":\"K. Wilson\"},{\"authorId\":\"2387467\",\"name\":\"J. Hershey\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c4ee93b3efeefee042102ca01738c4e9c5378ab2\",\"title\":\"Unsupervised Sound Separation Using Mixture Invariant Training\",\"url\":\"https://www.semanticscholar.org/paper/c4ee93b3efeefee042102ca01738c4e9c5378ab2\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145194507\",\"name\":\"S. Kasaei\"},{\"authorId\":\"1568855068\",\"name\":\"J. Melsen\"},{\"authorId\":\"80009585\",\"name\":\"F. V. Beers\"},{\"authorId\":\"1568979708\",\"name\":\"Christiaan Steenkist\"},{\"authorId\":\"147265747\",\"name\":\"K. Von\\u010dina\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f05023f7afe019c3a2b00f56d45a9e857c9437ea\",\"title\":\"The State of Service Robots: Current Bottlenecks in Object Perception and Manipulation\",\"url\":\"https://www.semanticscholar.org/paper/f05023f7afe019c3a2b00f56d45a9e857c9437ea\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"153246625\",\"name\":\"Chang\\u2019an Chen\"},{\"authorId\":\"1390024605\",\"name\":\"Ziad Al-Halah\"},{\"authorId\":\"2368282\",\"name\":\"Carl Schissler\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3e8b99d59e3f077bf1391140bd58a78341b3148a\",\"title\":\"VisualEchoes: Spatial Image Representation Learning through Echolocation (Supplementary Materials)\",\"url\":\"https://www.semanticscholar.org/paper/3e8b99d59e3f077bf1391140bd58a78341b3148a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2008.06581\",\"authors\":[{\"authorId\":\"1826395\",\"name\":\"Bin Duan\"},{\"authorId\":\"1491092462\",\"name\":\"Hao Tang\"},{\"authorId\":\"91913011\",\"name\":\"Wei Wang\"},{\"authorId\":\"153364719\",\"name\":\"Ziliang Zong\"},{\"authorId\":\"47124958\",\"name\":\"Guowei Yang\"},{\"authorId\":null,\"name\":\"Yan Yan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"17cf9e1a487ef8141192d6ec7d568c9823b34ac4\",\"title\":\"Audio-Visual Event Localization via Recursive Fusion by Joint Co-Attention\",\"url\":\"https://www.semanticscholar.org/paper/17cf9e1a487ef8141192d6ec7d568c9823b34ac4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.09199\",\"authors\":[{\"authorId\":\"41020711\",\"name\":\"Andrew Rouditchenko\"},{\"authorId\":\"1394839535\",\"name\":\"Angie Boggust\"},{\"authorId\":\"30507748\",\"name\":\"David Harwath\"},{\"authorId\":\"47669634\",\"name\":\"Dhiraj Joshi\"},{\"authorId\":\"70913918\",\"name\":\"S. Thomas\"},{\"authorId\":\"3104038\",\"name\":\"Kartik Audhkhasi\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"144707379\",\"name\":\"Brian Kingsbury\"},{\"authorId\":\"1774515\",\"name\":\"M. Picheny\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"},{\"authorId\":\"152450847\",\"name\":\"J. Glass\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1141ac4a1443ae7b44266a84a7f042f38759ac47\",\"title\":\"AVLnet: Learning Audio-Visual Language Representations from Instructional Videos\",\"url\":\"https://www.semanticscholar.org/paper/1141ac4a1443ae7b44266a84a7f042f38759ac47\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.04237\",\"authors\":[{\"authorId\":\"2285516\",\"name\":\"Triantafyllos Afouras\"},{\"authorId\":\"144956994\",\"name\":\"Andrew Owens\"},{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/978-3-030-58523-5_13\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0eb79a085e014f129b063199a38fe9945355c137\",\"title\":\"Self-Supervised Learning of Audio-Visual Objects from Video\",\"url\":\"https://www.semanticscholar.org/paper/0eb79a085e014f129b063199a38fe9945355c137\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1912.11474\",\"authors\":[{\"authorId\":\"153246625\",\"name\":\"Chang\\u2019an Chen\"},{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"2368282\",\"name\":\"Carl Schissler\"},{\"authorId\":\"80532894\",\"name\":\"S. V. A. Gar\\u00ed\"},{\"authorId\":\"1390024605\",\"name\":\"Ziad Al-Halah\"},{\"authorId\":\"2736958\",\"name\":\"Vamsi K. Ithapu\"},{\"authorId\":\"153812886\",\"name\":\"P. Robinson\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1007/978-3-030-58539-6_2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c47ef056ac57e83405f9ee63c32c6a185011d187\",\"title\":\"SoundSpaces: Audio-Visual Navigation in 3D Environments\",\"url\":\"https://www.semanticscholar.org/paper/c47ef056ac57e83405f9ee63c32c6a185011d187\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2006.03028\",\"authors\":[{\"authorId\":\"8301799\",\"name\":\"Lingyu Zhu\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"4024fb95ebf35d0edd25123b604d26e832b61a6b\",\"title\":\"Visually Guided Sound Source Separation using Cascaded Opponent Filter Network\",\"url\":\"https://www.semanticscholar.org/paper/4024fb95ebf35d0edd25123b604d26e832b61a6b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.01819\",\"authors\":[{\"authorId\":\"143698653\",\"name\":\"P. Morgado\"},{\"authorId\":\"3184077\",\"name\":\"Y. Li\"},{\"authorId\":\"1699559\",\"name\":\"N. Vasconcelos\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eeb33ad2ede9944918724978bcbfb08b4c8c50a8\",\"title\":\"Learning Representations from Audio-Visual Spatial Alignment\",\"url\":\"https://www.semanticscholar.org/paper/eeb33ad2ede9944918724978bcbfb08b4c8c50a8\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2004.03873\",\"authors\":[{\"authorId\":\"9936815\",\"name\":\"Olga Slizovskaia\"},{\"authorId\":\"1916387\",\"name\":\"G. Haro\"},{\"authorId\":\"145217215\",\"name\":\"E. G\\u00f3mez\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"fc6767792c34f509b053523b5327b2b88f1d6521\",\"title\":\"Conditioned Source Separation for Music Instrument Performances\",\"url\":\"https://www.semanticscholar.org/paper/fc6767792c34f509b053523b5327b2b88f1d6521\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.07931\",\"authors\":[{\"authorId\":\"134192555\",\"name\":\"J. F. Montesinos\"},{\"authorId\":\"9936815\",\"name\":\"Olga Slizovskaia\"},{\"authorId\":\"1916387\",\"name\":\"G. Haro\"}],\"doi\":\"10.1109/MMSP48831.2020.9287124\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5b36193e42615bf1ec6202f22be6bfc5ed86d444\",\"title\":\"Solos: A Dataset for Audio-Visual Music Analysis\",\"url\":\"https://www.semanticscholar.org/paper/5b36193e42615bf1ec6202f22be6bfc5ed86d444\",\"venue\":\"2020 IEEE 22nd International Workshop on Multimedia Signal Processing (MMSP)\",\"year\":2020},{\"arxivId\":\"2007.09902\",\"authors\":[{\"authorId\":\"145798292\",\"name\":\"Hang Zhou\"},{\"authorId\":\"48670507\",\"name\":\"Xudong Xu\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"},{\"authorId\":\"3243969\",\"name\":\"Z. Liu\"}],\"doi\":\"10.1007/978-3-030-58610-2_4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"73aa926dad010a3f1bb89faa31241f97a89cc461\",\"title\":\"Sep-Stereo: Visually Guided Stereophonic Audio Generation by Associating Source Separation\",\"url\":\"https://www.semanticscholar.org/paper/73aa926dad010a3f1bb89faa31241f97a89cc461\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2009.09805\",\"authors\":[{\"authorId\":\"1491401265\",\"name\":\"Shuang Ma\"},{\"authorId\":\"46490565\",\"name\":\"Zhaoyang Zeng\"},{\"authorId\":\"1381192475\",\"name\":\"Daniel McDuff\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7df5dd31f2ce600a4be589dff4d6a758be262324\",\"title\":\"Learning Audio-Visual Representations with Active Contrastive Coding\",\"url\":\"https://www.semanticscholar.org/paper/7df5dd31f2ce600a4be589dff4d6a758be262324\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.02182\",\"authors\":[{\"authorId\":\"9077277\",\"name\":\"Fatemeh Pishdadian\"},{\"authorId\":\"1816785\",\"name\":\"G. Wichern\"},{\"authorId\":\"9332945\",\"name\":\"Jonathan Le Roux\"}],\"doi\":\"10.1109/TASLP.2020.3013105\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"69834ce107eb9ba771aada9fcf848130f9b1c35a\",\"title\":\"Finding Strength in Weakness: Learning to Separate Sounds With Weak Supervision\",\"url\":\"https://www.semanticscholar.org/paper/69834ce107eb9ba771aada9fcf848130f9b1c35a\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2020},{\"arxivId\":\"2006.06175\",\"authors\":[{\"authorId\":\"2806097\",\"name\":\"Karren D. Yang\"},{\"authorId\":\"145160921\",\"name\":\"Bryan C. Russell\"},{\"authorId\":\"1786276\",\"name\":\"Justin Salamon\"}],\"doi\":\"10.1109/cvpr42600.2020.00995\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7555e7a02b23886f1c17049999e4fc66b30c8bf3\",\"title\":\"Telling Left From Right: Learning Spatial Correspondence of Sight and Sound\",\"url\":\"https://www.semanticscholar.org/paper/7555e7a02b23886f1c17049999e4fc66b30c8bf3\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2326243\",\"name\":\"Arun Balajee Vasudevan\"},{\"authorId\":\"1778526\",\"name\":\"Dengxin Dai\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.3929/ETHZ-B-000431943\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4867095c19f6c5827943cc74335b370d4bfcab29\",\"title\":\"Semantic Object Prediction and Spatial Sound Super-Resolution with Binaural Sounds\",\"url\":\"https://www.semanticscholar.org/paper/4867095c19f6c5827943cc74335b370d4bfcab29\",\"venue\":\"ECCV 2020\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47519958\",\"name\":\"Rui Qian\"},{\"authorId\":\"153211990\",\"name\":\"Di Hu\"},{\"authorId\":\"2451839\",\"name\":\"H. Dinkel\"},{\"authorId\":\"3000684\",\"name\":\"Mengyue Wu\"},{\"authorId\":\"145857587\",\"name\":\"Ning Xu\"},{\"authorId\":\"8131625\",\"name\":\"W. Lin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8f430dbeb164ef96dedfd83bf2583684fab2faa5\",\"title\":\"A Two-Stage Framework for Multiple Sound-Source Localization\",\"url\":\"https://www.semanticscholar.org/paper/8f430dbeb164ef96dedfd83bf2583684fab2faa5\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2012.11583\",\"authors\":[{\"authorId\":\"153246625\",\"name\":\"Chang\\u2019an Chen\"},{\"authorId\":\"9187007\",\"name\":\"Z. Al-Halah\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1941a6e2d4fd61b63d1df518a40cb47cab19c0e6\",\"title\":\"Semantic Audio-Visual Navigation\",\"url\":\"https://www.semanticscholar.org/paper/1941a6e2d4fd61b63d1df518a40cb47cab19c0e6\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2003.04298\",\"authors\":[{\"authorId\":\"1379929116\",\"name\":\"Mandela Patrick\"},{\"authorId\":\"47792365\",\"name\":\"Y. Asano\"},{\"authorId\":\"145891577\",\"name\":\"Ruth Fong\"},{\"authorId\":\"143848064\",\"name\":\"Jo\\u00e3o F. Henriques\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8ddbaa34c574124a91fa3bc217e232e17668e84c\",\"title\":\"Multi-modal Self-Supervision from Generalized Data Transformations\",\"url\":\"https://www.semanticscholar.org/paper/8ddbaa34c574124a91fa3bc217e232e17668e84c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.07984\",\"authors\":[{\"authorId\":\"8301799\",\"name\":\"Lingyu Zhu\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7b2cf1d0538f3ad0d5fae1af4d97571b9291eabc\",\"title\":\"Separating Sounds from a Single Image\",\"url\":\"https://www.semanticscholar.org/paper/7b2cf1d0538f3ad0d5fae1af4d97571b9291eabc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.05466\",\"authors\":[{\"authorId\":\"153211990\",\"name\":\"Di Hu\"},{\"authorId\":\"47519958\",\"name\":\"Rui Qian\"},{\"authorId\":\"46332801\",\"name\":\"Minyue Jiang\"},{\"authorId\":\"5424083\",\"name\":\"X. Tan\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"},{\"authorId\":\"12081764\",\"name\":\"E. Ding\"},{\"authorId\":\"8131625\",\"name\":\"W. Lin\"},{\"authorId\":\"1721158\",\"name\":\"D. Dou\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e96b7de5f6366aa1a8b4377d97c3f2464ab198ca\",\"title\":\"Discriminative Sounding Objects Localization via Self-supervised Audiovisual Matching\",\"url\":\"https://www.semanticscholar.org/paper/e96b7de5f6366aa1a8b4377d97c3f2464ab198ca\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153246625\",\"name\":\"Chang\\u2019an Chen\"},{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"2368282\",\"name\":\"Carl Schissler\"},{\"authorId\":\"80532894\",\"name\":\"S. V. A. Gar\\u00ed\"},{\"authorId\":\"1390024605\",\"name\":\"Ziad Al-Halah\"},{\"authorId\":\"2736958\",\"name\":\"Vamsi K. Ithapu\"},{\"authorId\":\"153812886\",\"name\":\"P. Robinson\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6090aa8ef7989101e3f18c44a84e3f5a80e905a5\",\"title\":\"Audio-Visual Embodied Navigation\",\"url\":\"https://www.semanticscholar.org/paper/6090aa8ef7989101e3f18c44a84e3f5a80e905a5\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2008.09586\",\"authors\":[{\"authorId\":\"9686806\",\"name\":\"Daniel Michelsanti\"},{\"authorId\":\"71668001\",\"name\":\"Zheng-Hua Tan\"},{\"authorId\":\"47180604\",\"name\":\"Shixiong Zhang\"},{\"authorId\":\"121983569\",\"name\":\"Yanchen Xu\"},{\"authorId\":\"143872259\",\"name\":\"M. Yu\"},{\"authorId\":null,\"name\":\"Dong Yu\"},{\"authorId\":\"145416680\",\"name\":\"J. Jensen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e1859067487893f6580e934e9ee3408a2fa8b7e1\",\"title\":\"An Overview of Deep-Learning-Based Audio-Visual Speech Enhancement and Separation\",\"url\":\"https://www.semanticscholar.org/paper/e1859067487893f6580e934e9ee3408a2fa8b7e1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.08151\",\"authors\":[{\"authorId\":\"145194507\",\"name\":\"S. Kasaei\"},{\"authorId\":\"1568855068\",\"name\":\"J. Melsen\"},{\"authorId\":\"80009585\",\"name\":\"F. V. Beers\"},{\"authorId\":\"1568979708\",\"name\":\"Christiaan Steenkist\"},{\"authorId\":\"147265747\",\"name\":\"K. Von\\u010dina\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f6ea4bbc2d1fcac322e64a190c5ae990d9a9f682\",\"title\":\"The State of Lifelong Learning in Service Robots: Current Bottlenecks in Object Perception and Manipulation\",\"url\":\"https://www.semanticscholar.org/paper/f6ea4bbc2d1fcac322e64a190c5ae990d9a9f682\",\"venue\":\"\",\"year\":2020}],\"corpusId\":119182143,\"doi\":\"10.1109/ICCV.2019.00398\",\"fieldsOfStudy\":[\"Computer Science\",\"Engineering\"],\"influentialCitationCount\":10,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"7a88fa82b2032b8234a2005c26de8fbb096aa27a\",\"references\":[{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Bryan lucas band -acoustic guitar and cello wedding ceremony music\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1804.03641\",\"authors\":[{\"authorId\":\"144956994\",\"name\":\"Andrew Owens\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1007/978-3-030-01231-1_39\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"171f8f1090ef0533ff470ed5a4d31ecfefcc74be\",\"title\":\"Audio-Visual Scene Analysis with Self-Supervised Multisensory Features\",\"url\":\"https://www.semanticscholar.org/paper/171f8f1090ef0533ff470ed5a4d31ecfefcc74be\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1804.03619\",\"authors\":[{\"authorId\":\"2077454\",\"name\":\"A. Ephrat\"},{\"authorId\":\"2138834\",\"name\":\"Inbar Mosseri\"},{\"authorId\":\"49618488\",\"name\":\"Oran Lang\"},{\"authorId\":\"2112779\",\"name\":\"Tali Dekel\"},{\"authorId\":\"118291142\",\"name\":\"K. Wilson\"},{\"authorId\":\"1639722387\",\"name\":\"Avinatan Hassidim\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"},{\"authorId\":\"144544291\",\"name\":\"Michael Rubinstein\"}],\"doi\":\"10.1145/3197517.3201357\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1b6add50e6be8d4f21e38cca9a154321cad3a4e0\",\"title\":\"Looking to listen at the cocktail party\",\"url\":\"https://www.semanticscholar.org/paper/1b6add50e6be8d4f21e38cca9a154321cad3a4e0\",\"venue\":\"ACM Trans. Graph.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jort F Gemmeke\"},{\"authorId\":null,\"name\":\"Daniel PW Ellis\"},{\"authorId\":null,\"name\":\"Dylan Freedman\"},{\"authorId\":null,\"name\":\"Aren Jansen\"},{\"authorId\":null,\"name\":\"Wade Lawrence\"},{\"authorId\":null,\"name\":\"R Channing Moore\"},{\"authorId\":null,\"name\":\"Manoj Plakal\"},{\"authorId\":null,\"name\":\"Marvin Ritter\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and Kristen Grauman . 2 . 5 d visual sound\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1809.02587\",\"authors\":[{\"authorId\":\"31692099\",\"name\":\"Pedro Morgado\"},{\"authorId\":\"1699559\",\"name\":\"N. Vasconcelos\"},{\"authorId\":\"153298725\",\"name\":\"Timothy R. Langlois\"},{\"authorId\":\"39231399\",\"name\":\"O. Wang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"029490920cd736e91d6c57f3cfb850adddcf2725\",\"title\":\"Self-Supervised Generation of Spatial Audio for 360 Video\",\"url\":\"https://www.semanticscholar.org/paper/029490920cd736e91d6c57f3cfb850adddcf2725\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Lele Chen\"},{\"authorId\":null,\"name\":\"Sudhanshu Srivastava\"},{\"authorId\":null,\"name\":\"Zhiyao Duan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Objects that sound Harmony in motion\",\"url\":\"\",\"venue\":\"\",\"year\":2007},{\"arxivId\":\"1904.05979\",\"authors\":[{\"authorId\":\"144077750\",\"name\":\"Hang Zhao\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"2650832\",\"name\":\"W. Ma\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/ICCV.2019.00182\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c880de441a41c351955ad0bf8f712eeee500ac67\",\"title\":\"The Sound of Motions\",\"url\":\"https://www.semanticscholar.org/paper/c880de441a41c351955ad0bf8f712eeee500ac67\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1102.4110\",\"authors\":[{\"authorId\":\"1688762\",\"name\":\"E. Lock\"},{\"authorId\":\"3590526\",\"name\":\"K. Hoadley\"},{\"authorId\":\"143780031\",\"name\":\"J. S. Marron\"},{\"authorId\":\"1794435\",\"name\":\"A. Nobel\"}],\"doi\":\"10.1214/12-AOAS597\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"736bc4c904845ac3bece9f6db10d0d4d36298d3f\",\"title\":\"JOINT AND INDIVIDUAL VARIATION EXPLAINED (JIVE) FOR INTEGRATED ANALYSIS OF MULTIPLE DATA TYPES.\",\"url\":\"https://www.semanticscholar.org/paper/736bc4c904845ac3bece9f6db10d0d4d36298d3f\",\"venue\":\"The annals of applied statistics\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31496901\",\"name\":\"John W. Fisher III\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"},{\"authorId\":\"1731948\",\"name\":\"P. Viola\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"15674778d14d7f2bf90c323924e8153d5f10fb60\",\"title\":\"Learning Joint Statistical Models for Audio-Visual Fusion and Segregation\",\"url\":\"https://www.semanticscholar.org/paper/15674778d14d7f2bf90c323924e8153d5f10fb60\",\"venue\":\"NIPS\",\"year\":2000},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2402716\",\"name\":\"Colin Raffel\"},{\"authorId\":\"3215419\",\"name\":\"B. McFee\"},{\"authorId\":\"3268101\",\"name\":\"Eric J. Humphrey\"},{\"authorId\":\"1786276\",\"name\":\"Justin Salamon\"},{\"authorId\":\"1899151\",\"name\":\"O. Nieto\"},{\"authorId\":\"1702877\",\"name\":\"Dawen Liang\"},{\"authorId\":\"1745455\",\"name\":\"D. Ellis\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6d37fbd2fccaef3ecdf75d34a7aee18ab9519a6f\",\"title\":\"MIR_EVAL: A Transparent Implementation of Common MIR Metrics\",\"url\":\"https://www.semanticscholar.org/paper/6d37fbd2fccaef3ecdf75d34a7aee18ab9519a6f\",\"venue\":\"ISMIR\",\"year\":2014},{\"arxivId\":\"1712.06651\",\"authors\":[{\"authorId\":\"2299479\",\"name\":\"R. Arandjelovi\\u0107\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/978-3-030-01246-5_27\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dfc504536e8434eb008680343abb77010965169e\",\"title\":\"Objects that Sound\",\"url\":\"https://www.semanticscholar.org/paper/dfc504536e8434eb008680343abb77010965169e\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33284306\",\"name\":\"Rajesh Jaiswal\"},{\"authorId\":\"48561289\",\"name\":\"D. Fitzgerald\"},{\"authorId\":\"34972619\",\"name\":\"D. Barry\"},{\"authorId\":\"143715575\",\"name\":\"E. Coyle\"},{\"authorId\":\"8850109\",\"name\":\"S. Rickard\"}],\"doi\":\"10.1109/ICASSP.2011.5946386\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1f26cfc5573ea723c2c6adc261d3f0e82d7ddaa1\",\"title\":\"Clustering NMF basis functions using Shifted NMF for monaural sound source separation\",\"url\":\"https://www.semanticscholar.org/paper/1f26cfc5573ea723c2c6adc261d3f0e82d7ddaa1\",\"venue\":\"2011 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48190580\",\"name\":\"D. Griffin\"},{\"authorId\":\"49719219\",\"name\":\"J. Lim\"}],\"doi\":\"10.1109/TASSP.1984.1164317\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"83179cfc937dfd62513282854e357c7f38fecda8\",\"title\":\"Signal estimation from modified short-time Fourier transform\",\"url\":\"https://www.semanticscholar.org/paper/83179cfc937dfd62513282854e357c7f38fecda8\",\"venue\":\"\",\"year\":1984},{\"arxivId\":\"1506.01497\",\"authors\":[{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"144716314\",\"name\":\"J. Sun\"}],\"doi\":\"10.1109/TPAMI.2016.2577031\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"title\":\"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\",\"url\":\"https://www.semanticscholar.org/paper/424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"144077750\",\"name\":\"Hang Zhao\"},{\"authorId\":\"143872936\",\"name\":\"Xavier Puig\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"3081640\",\"name\":\"Adela Barriuso\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/CVPR.2017.544\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2a5667702b0f1ff77dde8fb3e2e10d4e05e8de9d\",\"title\":\"Scene Parsing through ADE20K Dataset\",\"url\":\"https://www.semanticscholar.org/paper/2a5667702b0f1ff77dde8fb3e2e10d4e05e8de9d\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41192047\",\"name\":\"D. Ellis\"}],\"doi\":\"10.7916/D84J0N13\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1fee153d9ee59a1048656acf31814a651fe18be5\",\"title\":\"Prediction-driven computational auditory scene analysis\",\"url\":\"https://www.semanticscholar.org/paper/1fee153d9ee59a1048656acf31814a651fe18be5\",\"venue\":\"\",\"year\":1996},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1684454\",\"name\":\"T. Virtanen\"}],\"doi\":\"10.1109/TASL.2006.885253\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"fe27cac60301c52397c1ce150abd7706afa007cd\",\"title\":\"Monaural Sound Source Separation by Nonnegative Matrix Factorization With Temporal Continuity and Sparseness Criteria\",\"url\":\"https://www.semanticscholar.org/paper/fe27cac60301c52397c1ce150abd7706afa007cd\",\"venue\":\"IEEE Transactions on Audio, Speech, and Language Processing\",\"year\":2007},{\"arxivId\":\"1505.04597\",\"authors\":[{\"authorId\":\"1737326\",\"name\":\"O. Ronneberger\"},{\"authorId\":\"152702479\",\"name\":\"P. Fischer\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1007/978-3-319-24574-4_28\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6364fdaa0a0eccd823a779fcdd489173f938e91a\",\"title\":\"U-Net: Convolutional Networks for Biomedical Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/6364fdaa0a0eccd823a779fcdd489173f938e91a\",\"venue\":\"MICCAI\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27485318\",\"name\":\"Aviv Gabbay\"},{\"authorId\":\"153677544\",\"name\":\"Asaph Shamir\"},{\"authorId\":\"144406261\",\"name\":\"Shmuel Peleg\"}],\"doi\":\"10.21437/Interspeech.2018-1955\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f997d69d78af086dec4462e4319c6d241f42c0c1\",\"title\":\"Visual Speech Enhancement\",\"url\":\"https://www.semanticscholar.org/paper/f997d69d78af086dec4462e4319c6d241f42c0c1\",\"venue\":\"INTERSPEECH\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2387467\",\"name\":\"J. Hershey\"},{\"authorId\":\"1741200\",\"name\":\"J. Movellan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"00d1bb817691bb0566bc55fde01d12339625aa1c\",\"title\":\"Audio Vision: Using Audio-Visual Synchrony to Locate Sounds\",\"url\":\"https://www.semanticscholar.org/paper/00d1bb817691bb0566bc55fde01d12339625aa1c\",\"venue\":\"NIPS\",\"year\":1999},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1718742\",\"name\":\"P. Smaragdis\"},{\"authorId\":\"1734296\",\"name\":\"M. Casey\"},{\"authorId\":\"70773882\",\"name\":\"Northampton Square\"},{\"authorId\":\"1452780437\",\"name\":\"Subspace Projections\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d7b47411373a3af57bf7b00ae52cc5443f8b9704\",\"title\":\"AUDIO/VISUAL INDEPENDENT COMPONENTS\",\"url\":\"https://www.semanticscholar.org/paper/d7b47411373a3af57bf7b00ae52cc5443f8b9704\",\"venue\":\"\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2058409\",\"name\":\"Volker Gnann\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"56456a595bb6d2dea5bfbed0a429f0e53c5a7512\",\"title\":\"SOURCE-FILTER BASED CLUSTERING FOR MONAURAL BLIND SOURCE SEPARATION\",\"url\":\"https://www.semanticscholar.org/paper/56456a595bb6d2dea5bfbed0a429f0e53c5a7512\",\"venue\":\"\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3116662\",\"name\":\"J. Gemmeke\"},{\"authorId\":\"1745455\",\"name\":\"D. Ellis\"},{\"authorId\":\"36794621\",\"name\":\"Dylan Freedman\"},{\"authorId\":\"35996413\",\"name\":\"A. Jansen\"},{\"authorId\":\"39965499\",\"name\":\"W. Lawrence\"},{\"authorId\":\"1974225\",\"name\":\"R. C. Moore\"},{\"authorId\":\"2114994\",\"name\":\"M. Plakal\"},{\"authorId\":\"39687627\",\"name\":\"M. Ritter\"}],\"doi\":\"10.1109/ICASSP.2017.7952261\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5ba2218b708ca64ab556e39d5997202e012717d5\",\"title\":\"Audio Set: An ontology and human-labeled dataset for audio events\",\"url\":\"https://www.semanticscholar.org/paper/5ba2218b708ca64ab556e39d5997202e012717d5\",\"venue\":\"2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2017},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40217426\",\"name\":\"S. Parekh\"},{\"authorId\":\"1807587\",\"name\":\"S. Essid\"},{\"authorId\":\"2889451\",\"name\":\"A. Ozerov\"},{\"authorId\":\"1756744\",\"name\":\"Ngoc Q. K. Duong\"},{\"authorId\":\"144565371\",\"name\":\"P. P\\u00e9rez\"},{\"authorId\":\"145793390\",\"name\":\"G. Richard\"}],\"doi\":\"10.1109/ICASSP.2017.7951787\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"77b5aa4f00a8525893ce3aeb9eea9934a8694b84\",\"title\":\"Motion informed audio source separation\",\"url\":\"https://www.semanticscholar.org/paper/77b5aa4f00a8525893ce3aeb9eea9934a8694b84\",\"venue\":\"2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48841289\",\"name\":\"Satoshi Innami\"},{\"authorId\":\"1760422\",\"name\":\"H. Kasai\"}],\"doi\":\"10.1016/j.camwa.2012.03.077\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ac28c4baa1d50acf1c7587701256177c9eb12fa6\",\"title\":\"NMF-based environmental sound source separation using time-variant gain features\",\"url\":\"https://www.semanticscholar.org/paper/ac28c4baa1d50acf1c7587701256177c9eb12fa6\",\"venue\":\"Comput. Math. Appl.\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47820818\",\"name\":\"J. Pu\"},{\"authorId\":\"1780393\",\"name\":\"Yannis Panagakis\"},{\"authorId\":\"2403354\",\"name\":\"S. Petridis\"},{\"authorId\":\"145387780\",\"name\":\"M. Pantic\"}],\"doi\":\"10.1109/ICASSP.2017.7952687\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0d7d609d978eabf9df940687b8b94ef104d1ef3c\",\"title\":\"Audio-visual object localization and separation using low-rank and sparsity\",\"url\":\"https://www.semanticscholar.org/paper/0d7d609d978eabf9df940687b8b94ef104d1ef3c\",\"venue\":\"2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"122315677\",\"name\":\"P. Huang\"},{\"authorId\":\"33752120\",\"name\":\"Minje Kim\"},{\"authorId\":\"1399115926\",\"name\":\"M. Hasegawa-Johnson\"},{\"authorId\":\"1718742\",\"name\":\"P. Smaragdis\"}],\"doi\":\"10.1109/ICASSP.2014.6853860\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ca7f25ac119e2d706e51a63f6178f1547a863bcc\",\"title\":\"Deep learning for monaural speech separation\",\"url\":\"https://www.semanticscholar.org/paper/ca7f25ac119e2d706e51a63f6178f1547a863bcc\",\"venue\":\"2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2014},{\"arxivId\":\"1512.08512\",\"authors\":[{\"authorId\":\"144956994\",\"name\":\"Andrew Owens\"},{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"2324658\",\"name\":\"J. McDermott\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145358192\",\"name\":\"E. Adelson\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"}],\"doi\":\"10.1109/CVPR.2016.264\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ac640c2d0f33fb3ab49f37b26982948fc31e3191\",\"title\":\"Visually Indicated Sounds\",\"url\":\"https://www.semanticscholar.org/paper/ac640c2d0f33fb3ab49f37b26982948fc31e3191\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1508.04306\",\"authors\":[{\"authorId\":\"2387467\",\"name\":\"J. Hershey\"},{\"authorId\":\"49865106\",\"name\":\"Z. Chen\"},{\"authorId\":\"9332945\",\"name\":\"Jonathan Le Roux\"},{\"authorId\":\"1746678\",\"name\":\"Shinji Watanabe\"}],\"doi\":\"10.1109/ICASSP.2016.7471631\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"3332dc72fbe3907e45e8a500c6a1202ad5092c0f\",\"title\":\"Deep clustering: Discriminative embeddings for segmentation and separation\",\"url\":\"https://www.semanticscholar.org/paper/3332dc72fbe3907e45e8a500c6a1202ad5092c0f\",\"venue\":\"2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2016},{\"arxivId\":\"1804.04121\",\"authors\":[{\"authorId\":\"2285516\",\"name\":\"Triantafyllos Afouras\"},{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.21437/Interspeech.2018-1400\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e3cac1f3fa0ca9ba41f1cb0fbbd28a0f320903e3\",\"title\":\"The Conversation: Deep Audio-Visual Speech Enhancement\",\"url\":\"https://www.semanticscholar.org/paper/e3cac1f3fa0ca9ba41f1cb0fbbd28a0f320903e3\",\"venue\":\"INTERSPEECH\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1c46943103bd7b7a2c7be86859995a4144d1938b\",\"title\":\"Visualizing Data using t-SNE\",\"url\":\"https://www.semanticscholar.org/paper/1c46943103bd7b7a2c7be86859995a4144d1938b\",\"venue\":\"\",\"year\":2008},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Shape of my heart violin and guitar wedding ceremony sydney manly q station\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1607.00325\",\"authors\":[{\"authorId\":\"144580027\",\"name\":\"Dong Yu\"},{\"authorId\":\"3437492\",\"name\":\"Morten Kolb\\u00e6k\"},{\"authorId\":\"71668001\",\"name\":\"Zheng-Hua Tan\"},{\"authorId\":\"145416680\",\"name\":\"J. Jensen\"}],\"doi\":\"10.1109/ICASSP.2017.7952154\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d4f62ffbf7c51a5ad01b89c6889c649bf48baac8\",\"title\":\"Permutation invariant training of deep models for speaker-independent multi-talker speech separation\",\"url\":\"https://www.semanticscholar.org/paper/d4f62ffbf7c51a5ad01b89c6889c649bf48baac8\",\"venue\":\"2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2017},{\"arxivId\":\"1704.08292\",\"authors\":[{\"authorId\":\"1753356\",\"name\":\"Lele Chen\"},{\"authorId\":\"4037274\",\"name\":\"Sudhanshu Srivastava\"},{\"authorId\":\"3270912\",\"name\":\"Z. Duan\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":\"10.1145/3126686.3126723\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"27e8965cc9c166e9afee46e611039f0ce8263e51\",\"title\":\"Deep Cross-Modal Audio-Visual Generation\",\"url\":\"https://www.semanticscholar.org/paper/27e8965cc9c166e9afee46e611039f0ce8263e51\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2211891\",\"name\":\"Einat Kidron\"},{\"authorId\":\"2159538\",\"name\":\"Y. Schechner\"},{\"authorId\":\"1753908\",\"name\":\"Michael Elad\"}],\"doi\":\"10.1109/CVPR.2005.274\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"91bfc3de8bfa6b9e7ccd685f53db8304a0c114ad\",\"title\":\"Pixels that sound\",\"url\":\"https://www.semanticscholar.org/paper/91bfc3de8bfa6b9e7ccd685f53db8304a0c114ad\",\"venue\":\"2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)\",\"year\":2005},{\"arxivId\":\"1504.04658\",\"authors\":[{\"authorId\":\"34979897\",\"name\":\"Andrew J. R. Simpson\"},{\"authorId\":\"35581798\",\"name\":\"G. Roma\"},{\"authorId\":\"1804703\",\"name\":\"Mark D. Plumbley\"}],\"doi\":\"10.1007/978-3-319-22482-4_50\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8a54a76f7c2b95bd2514b461253e239f8f1ea427\",\"title\":\"Deep Karaoke: Extracting Vocals from Musical Mixtures Using a Convolutional Deep Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/8a54a76f7c2b95bd2514b461253e239f8f1ea427\",\"venue\":\"LVA/ICA\",\"year\":2015},{\"arxivId\":\"1803.03849\",\"authors\":[{\"authorId\":\"40895287\",\"name\":\"Arda Senocak\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"3053231\",\"name\":\"J. Kim\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"2398271\",\"name\":\"In-So Kweon\"}],\"doi\":\"10.1109/CVPR.2018.00458\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b91d738cd1f5d550c5b27f328e55308a0a73b2d2\",\"title\":\"Learning to Localize Sound Source in Visual Scenes\",\"url\":\"https://www.semanticscholar.org/paper/b91d738cd1f5d550c5b27f328e55308a0a73b2d2\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48190580\",\"name\":\"D. Griffin\"},{\"authorId\":\"49719219\",\"name\":\"J. Lim\"}],\"doi\":\"10.1109/ICASSP.1983.1172092\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"14bc876fae55faf5669beb01667a4f3bd324a4f1\",\"title\":\"Signal estimation from modified short-time Fourier transform\",\"url\":\"https://www.semanticscholar.org/paper/14bc876fae55faf5669beb01667a4f3bd324a4f1\",\"venue\":\"ICASSP\",\"year\":1983},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jort F Gemmeke\"},{\"authorId\":null,\"name\":\"Daniel PW Ellis\"},{\"authorId\":null,\"name\":\"Dylan Freedman\"},{\"authorId\":null,\"name\":\"Aren Jansen\"},{\"authorId\":null,\"name\":\"Wade Lawrence\"},{\"authorId\":null,\"name\":\"R Channing Moore\"},{\"authorId\":null,\"name\":\"Manoj Plakal\"},{\"authorId\":null,\"name\":\"Marvin Ritter\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and Kristen Grauman . 2 . 5 d visual sound\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1708.07524\",\"authors\":[{\"authorId\":\"46348681\",\"name\":\"D. Wang\"},{\"authorId\":\"49252693\",\"name\":\"J. Chen\"}],\"doi\":\"10.1109/TASLP.2018.2842159\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ae523e2f137fa2a4f5a6cbcc443ba63db2642a96\",\"title\":\"Supervised Speech Separation Based on Deep Learning: An Overview\",\"url\":\"https://www.semanticscholar.org/paper/ae523e2f137fa2a4f5a6cbcc443ba63db2642a96\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ivan Krasin\"},{\"authorId\":null,\"name\":\"Tom Duerig\"},{\"authorId\":null,\"name\":\"Neil Alldrin\"},{\"authorId\":null,\"name\":\"Vittorio Ferrari\"},{\"authorId\":null,\"name\":\"Sami Abu-El-Haija\"},{\"authorId\":null,\"name\":\"Alina Kuznetsova\"},{\"authorId\":null,\"name\":\"Hassan Rom\"},{\"authorId\":null,\"name\":\"Jasper Uijlings\"},{\"authorId\":null,\"name\":\"Stefan Popov\"},{\"authorId\":null,\"name\":\"Shahab Kamali\"},{\"authorId\":null,\"name\":\"Matteo Malloci\"},{\"authorId\":null,\"name\":\"Jordi Pont-Tuset\"},{\"authorId\":null,\"name\":\"Andreas Veit\"},{\"authorId\":null,\"name\":\"Serge Belongie\"},{\"authorId\":null,\"name\":\"Victor Gomes\"},{\"authorId\":null,\"name\":\"Abhinav Gupta\"},{\"authorId\":null,\"name\":\"Chen Sun\"},{\"authorId\":null,\"name\":\"Gal Chechik\"},{\"authorId\":null,\"name\":\"David Cai\"},{\"authorId\":null,\"name\":\"Zheyun Feng\"},{\"authorId\":null,\"name\":\"Dhyanesh Narayanan\"},{\"authorId\":null,\"name\":\"Kevin Murphy\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Openimages: A public dataset for large-scale multi-label and multi-class image classification\",\"url\":\"\",\"venue\":\"Dataset available from https://storage.googleapis.com/openimages/web/index.html,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1823362\",\"name\":\"J. Uijlings\"},{\"authorId\":\"1756979\",\"name\":\"K. V. D. Sande\"},{\"authorId\":\"1620219267\",\"name\":\"Theo Gevers\"},{\"authorId\":\"144638781\",\"name\":\"A. Smeulders\"}],\"doi\":\"10.1007/s11263-013-0620-5\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"38b6540ddd5beebffd05047c78183f7575559fb2\",\"title\":\"Selective Search for Object Recognition\",\"url\":\"https://www.semanticscholar.org/paper/38b6540ddd5beebffd05047c78183f7575559fb2\",\"venue\":\"International Journal of Computer Vision\",\"year\":2013},{\"arxivId\":\"1502.04149\",\"authors\":[{\"authorId\":\"122315677\",\"name\":\"P. Huang\"},{\"authorId\":\"33752120\",\"name\":\"Minje Kim\"},{\"authorId\":\"1399115926\",\"name\":\"M. Hasegawa-Johnson\"},{\"authorId\":\"1718742\",\"name\":\"P. Smaragdis\"}],\"doi\":\"10.1109/TASLP.2015.2468583\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"4c5562bcc6e2fb58cd69952a3b74c88626ce5185\",\"title\":\"Joint Optimization of Masks and Deep Recurrent Neural Networks for Monaural Source Separation\",\"url\":\"https://www.semanticscholar.org/paper/4c5562bcc6e2fb58cd69952a3b74c88626ce5185\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2015},{\"arxivId\":\"1712.01393\",\"authors\":[{\"authorId\":\"49455017\",\"name\":\"Yipin Zhou\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"145262461\",\"name\":\"Trung Bui\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/CVPR.2018.00374\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f2d126e02401ec9f3c131eac423620529996df2f\",\"title\":\"Visual to Sound: Generating Natural Sound for Videos in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/f2d126e02401ec9f3c131eac423620529996df2f\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7491017\",\"name\":\"F. Sedighin\"},{\"authorId\":\"30954170\",\"name\":\"M. Babaie-Zadeh\"},{\"authorId\":\"1744054\",\"name\":\"B. Rivet\"},{\"authorId\":\"1696508\",\"name\":\"C. Jutten\"}],\"doi\":\"10.1109/EUSIPCO.2016.7760220\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3dff0935de38fef7c0e591434bd4ca29a6db8047\",\"title\":\"Two multimodal approaches for single microphone source separation\",\"url\":\"https://www.semanticscholar.org/paper/3dff0935de38fef7c0e591434bd4ca29a6db8047\",\"venue\":\"2016 24th European Signal Processing Conference (EUSIPCO)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1678553621\",\"name\":\"Martin P. Catherwood\"}],\"doi\":\"10.1515/9783111576855-016\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"725cd02f9ab4e5e4f7db6ef0d2ff5b13819a6fc1\",\"title\":\"K\",\"url\":\"https://www.semanticscholar.org/paper/725cd02f9ab4e5e4f7db6ef0d2ff5b13819a6fc1\",\"venue\":\"Edinburgh Medical and Surgical Journal\",\"year\":1824},{\"arxivId\":\"1803.08842\",\"authors\":[{\"authorId\":\"34777509\",\"name\":\"Yapeng Tian\"},{\"authorId\":\"145458657\",\"name\":\"Jing Shi\"},{\"authorId\":\"2868721\",\"name\":\"Bochen Li\"},{\"authorId\":\"3270912\",\"name\":\"Z. Duan\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":\"10.1007/978-3-030-01216-8_16\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a5e58ef7c11515847967019fbe01fa033d9bdd88\",\"title\":\"Audio-Visual Event Localization in Unconstrained Videos\",\"url\":\"https://www.semanticscholar.org/paper/a5e58ef7c11515847967019fbe01fa033d9bdd88\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1756036\",\"name\":\"C. Rother\"},{\"authorId\":\"1801025\",\"name\":\"Tom Minka\"},{\"authorId\":\"145162067\",\"name\":\"A. Blake\"},{\"authorId\":\"144653005\",\"name\":\"V. Kolmogorov\"}],\"doi\":\"10.1109/CVPR.2006.91\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2fbfd6a9daa73756196ec663d65019a7a9b58600\",\"title\":\"Cosegmentation of Image Pairs by Histogram Matching - Incorporating a Global Constraint into MRFs\",\"url\":\"https://www.semanticscholar.org/paper/2fbfd6a9daa73756196ec663d65019a7a9b58600\",\"venue\":\"2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2744069\",\"name\":\"Zohar Barzelay\"},{\"authorId\":\"2159538\",\"name\":\"Y. Schechner\"}],\"doi\":\"10.1109/CVPR.2007.383344\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e309dfbae9d123f85223d398d4a400abee3ef393\",\"title\":\"Harmony in Motion\",\"url\":\"https://www.semanticscholar.org/paper/e309dfbae9d123f85223d398d4a400abee3ef393\",\"venue\":\"2007 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2007},{\"arxivId\":\"1804.01665\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1007/978-3-030-01219-9_3\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5c9ca16cb2337fd5948c7af28c29c156981250e8\",\"title\":\"Learning to Separate Object Sounds by Watching Unlabeled Video\",\"url\":\"https://www.semanticscholar.org/paper/5c9ca16cb2337fd5948c7af28c29c156981250e8\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1684454\",\"name\":\"T. Virtanen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6962d54c05023a36834c5b34c8e7573de6390223\",\"title\":\"Sound Source Separation Using Sparse Coding with Temporal Continuity Objective\",\"url\":\"https://www.semanticscholar.org/paper/6962d54c05023a36834c5b34c8e7573de6390223\",\"venue\":\"ICMC\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Xin Guo\"},{\"authorId\":\"2504395\",\"name\":\"S. Uhlich\"},{\"authorId\":\"2744777\",\"name\":\"Yuki Mitsufuji\"}],\"doi\":\"10.1109/ICASSP.2015.7177972\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7006ea78532fd20ca56f31c9c33892fd2cc1f60f\",\"title\":\"NMF-based blind source separation using a linear predictive coding error clustering criterion\",\"url\":\"https://www.semanticscholar.org/paper/7006ea78532fd20ca56f31c9c33892fd2cc1f60f\",\"venue\":\"2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1981204\",\"name\":\"C. F\\u00e9votte\"},{\"authorId\":\"1764984\",\"name\":\"N. Bertin\"},{\"authorId\":\"1873560\",\"name\":\"Jean-Louis Durrieu\"}],\"doi\":\"10.1162/neco.2008.04-08-771\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"34e86b693642b41e60e41f7a53bd9821764bda7c\",\"title\":\"Nonnegative Matrix Factorization with the Itakura-Saito Divergence: With Application to Music Analysis\",\"url\":\"https://www.semanticscholar.org/paper/34e86b693642b41e60e41f7a53bd9821764bda7c\",\"venue\":\"Neural Computation\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1791548\",\"name\":\"A. Hyv\\u00e4rinen\"},{\"authorId\":\"1726997\",\"name\":\"E. Oja\"}],\"doi\":\"10.1016/S0893-6080(00)00026-5\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"577d19a115f9ef6f002483fcf88adbb3b5479556\",\"title\":\"Independent component analysis: algorithms and applications\",\"url\":\"https://www.semanticscholar.org/paper/577d19a115f9ef6f002483fcf88adbb3b5479556\",\"venue\":\"Neural Networks\",\"year\":2000},{\"arxivId\":\"1711.00048\",\"authors\":[{\"authorId\":\"39914594\",\"name\":\"D. Stoller\"},{\"authorId\":\"2766157\",\"name\":\"S. Ewert\"},{\"authorId\":\"145039466\",\"name\":\"S. Dixon\"}],\"doi\":\"10.1109/ICASSP.2018.8461722\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"58750d2dcb7e97383c1faefa2d664a82a02236c9\",\"title\":\"Adversarial Semi-Supervised Audio Source Separation Applied to Singing Voice Extraction\",\"url\":\"https://www.semanticscholar.org/paper/58750d2dcb7e97383c1faefa2d664a82a02236c9\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":\"1812.04204\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2019.00041\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b809837560cf11937ee857338eb1a7ccd2abc7b2\",\"title\":\"2.5D Visual Sound\",\"url\":\"https://www.semanticscholar.org/paper/b809837560cf11937ee857338eb1a7ccd2abc7b2\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2868721\",\"name\":\"Bochen Li\"},{\"authorId\":\"27361710\",\"name\":\"K. Dinesh\"},{\"authorId\":\"3270912\",\"name\":\"Z. Duan\"},{\"authorId\":\"145621177\",\"name\":\"Gaurav Sharma\"}],\"doi\":\"10.1109/ICASSP.2017.7952688\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5545c07fb82934cbe2918ef5ae8550a01efa25ab\",\"title\":\"See and listen: Score-informed association of sound tracks to players in chamber music performance videos\",\"url\":\"https://www.semanticscholar.org/paper/5545c07fb82934cbe2918ef5ae8550a01efa25ab\",\"venue\":\"2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2017},{\"arxivId\":\"1804.03160\",\"authors\":[{\"authorId\":\"144077750\",\"name\":\"Hang Zhao\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"41020711\",\"name\":\"Andrew Rouditchenko\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"2324658\",\"name\":\"J. McDermott\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1007/978-3-030-01246-5_35\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"fe018f22600d07cbd0452a070e03708886470015\",\"title\":\"The Sound of Pixels\",\"url\":\"https://www.semanticscholar.org/paper/fe018f22600d07cbd0452a070e03708886470015\",\"venue\":\"ECCV\",\"year\":2018}],\"title\":\"Co-Separating Sounds of Visual Objects\",\"topics\":[{\"topic\":\"Visual Objects\",\"topicId\":\"242884\",\"url\":\"https://www.semanticscholar.org/topic/242884\"},{\"topic\":\"Deep learning\",\"topicId\":\"2762\",\"url\":\"https://www.semanticscholar.org/topic/2762\"},{\"topic\":\"Source separation\",\"topicId\":\"39125\",\"url\":\"https://www.semanticscholar.org/topic/39125\"},{\"topic\":\"Video clip\",\"topicId\":\"30493\",\"url\":\"https://www.semanticscholar.org/topic/30493\"},{\"topic\":\"Noise reduction\",\"topicId\":\"18968\",\"url\":\"https://www.semanticscholar.org/topic/18968\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"},{\"topic\":\"Multi-source\",\"topicId\":\"137787\",\"url\":\"https://www.semanticscholar.org/topic/137787\"},{\"topic\":\"Programming paradigm\",\"topicId\":\"29522\",\"url\":\"https://www.semanticscholar.org/topic/29522\"},{\"topic\":\"Hypertext Transfer Protocol\",\"topicId\":\"28225\",\"url\":\"https://www.semanticscholar.org/topic/28225\"},{\"topic\":\"AV-TEST\",\"topicId\":\"1024862\",\"url\":\"https://www.semanticscholar.org/topic/1024862\"}],\"url\":\"https://www.semanticscholar.org/paper/7a88fa82b2032b8234a2005c26de8fbb096aa27a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019}\n"