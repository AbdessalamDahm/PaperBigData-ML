"{\"abstract\":\"In this paper, we present a thorough evaluation of the efficacy of knowledge distillation and its dependence on student and teacher architectures. Starting with the observation that more accurate teachers often don\\u2019t make good teachers, we attempt to tease apart the factors that affect knowledge distillation performance. We find crucially that larger models do not often make better teachers. We show that this is a consequence of mismatched capacity, and that small students are unable to mimic large teachers. We find typical ways of circumventing this (such as performing a sequence of knowledge distillation steps) to be ineffective. Finally, we show that this effect can be mitigated by stopping the teacher\\u2019s training early. Our results generalize across datasets and models.\",\"arxivId\":\"1910.01348\",\"authors\":[{\"authorId\":\"39878282\",\"name\":\"J. H. Cho\",\"url\":\"https://www.semanticscholar.org/author/39878282\"},{\"authorId\":\"73710317\",\"name\":\"B. Hariharan\",\"url\":\"https://www.semanticscholar.org/author/73710317\"}],\"citationVelocity\":25,\"citations\":[{\"arxivId\":\"2010.15054\",\"authors\":[{\"authorId\":\"1435907961\",\"name\":\"Geondo Park\"},{\"authorId\":\"2004057395\",\"name\":\"June Yang\"},{\"authorId\":\"35788904\",\"name\":\"Sung Ju Hwang\"},{\"authorId\":\"1720494\",\"name\":\"E. Yang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0e0d8d356bc9d47dcd5cececaf23453fdbed7067\",\"title\":\"Attribution Preservation in Network Compression for Reliable Network Interpretation\",\"url\":\"https://www.semanticscholar.org/paper/0e0d8d356bc9d47dcd5cececaf23453fdbed7067\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2010.04812\",\"authors\":[{\"authorId\":\"145924070\",\"name\":\"Xiang Deng\"},{\"authorId\":\"104383701\",\"name\":\"Zhongfei\"},{\"authorId\":\"1399959843\",\"name\":\"Zhang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a3a022bf41423650d6b749ea37afcd52171d400e\",\"title\":\"Local Region Knowledge Distillation\",\"url\":\"https://www.semanticscholar.org/paper/a3a022bf41423650d6b749ea37afcd52171d400e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2012.04193\",\"authors\":[{\"authorId\":\"34650131\",\"name\":\"Pengfei Chen\"},{\"authorId\":\"39690058\",\"name\":\"J. Ye\"},{\"authorId\":\"2653181\",\"name\":\"Guangyong Chen\"},{\"authorId\":\"1601191498\",\"name\":\"Jingwei Zhao\"},{\"authorId\":\"72434829\",\"name\":\"P. Heng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1fbff5f28ac4851011a0c86f72c1c6126a984c07\",\"title\":\"Robustness of Accuracy Metric and its Inspirations in Learning with Noisy Labels\",\"url\":\"https://www.semanticscholar.org/paper/1fbff5f28ac4851011a0c86f72c1c6126a984c07\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1909.04286\",\"authors\":[{\"authorId\":\"92076186\",\"name\":\"S. Minami\"},{\"authorId\":\"134790239\",\"name\":\"Tsubasa Hirakawa\"},{\"authorId\":\"1687819\",\"name\":\"T. Yamashita\"},{\"authorId\":\"1687968\",\"name\":\"H. Fujiyoshi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a90e67295b0bff83b1ffc6f49fe759e07ac2d076\",\"title\":\"Knowledge Transfer Graph for Deep Collaborative Learning\",\"url\":\"https://www.semanticscholar.org/paper/a90e67295b0bff83b1ffc6f49fe759e07ac2d076\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2010.10090\",\"authors\":[{\"authorId\":\"1999769883\",\"name\":\"Guangda Ji\"},{\"authorId\":\"1703952\",\"name\":\"Zhanxing Zhu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"607e2974515819f856477f58583d607641d14a68\",\"title\":\"Knowledge Distillation in Wide Neural Networks: Risk Bound, Data Efficiency and Imperfect Teacher\",\"url\":\"https://www.semanticscholar.org/paper/607e2974515819f856477f58583d607641d14a68\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11251672\",\"name\":\"Ding-Wen Zhang\"},{\"authorId\":\"103370371\",\"name\":\"G. Huang\"},{\"authorId\":\"153441722\",\"name\":\"Q. Zhang\"},{\"authorId\":\"144762952\",\"name\":\"J. Han\"},{\"authorId\":\"122200133\",\"name\":\"J. Han\"},{\"authorId\":\"66616425\",\"name\":\"Yizhou Yu\"}],\"doi\":\"10.1016/j.patcog.2020.107562\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7621b70c0d4523a4c9f399f69359fa2184cbc590\",\"title\":\"Cross-modality deep feature learning for brain tumor segmentation\",\"url\":\"https://www.semanticscholar.org/paper/7621b70c0d4523a4c9f399f69359fa2184cbc590\",\"venue\":\"Pattern Recognit.\",\"year\":2021},{\"arxivId\":\"2006.03810\",\"authors\":[{\"authorId\":\"121490889\",\"name\":\"Deepan Das\"},{\"authorId\":\"1436024527\",\"name\":\"Haley Massa\"},{\"authorId\":\"1738774570\",\"name\":\"Abhimanyu Kulkarni\"},{\"authorId\":\"145071799\",\"name\":\"Theodoros Rekatsinas\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"04be154a14b9b3ffdd96b03b19d5f937512ce437\",\"title\":\"An Empirical Analysis of the Impact of Data Augmentation on Knowledge Distillation\",\"url\":\"https://www.semanticscholar.org/paper/04be154a14b9b3ffdd96b03b19d5f937512ce437\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.04108\",\"authors\":[{\"authorId\":\"29892729\",\"name\":\"Matteo Dunnhofer\"},{\"authorId\":\"1736750\",\"name\":\"N. Martinel\"},{\"authorId\":\"1708507\",\"name\":\"C. Micheloni\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"bd4f219ce6bc5c22f9da71959d5192cf0b0141fe\",\"title\":\"Tracking-by-Trackers with a Distilled and Reinforced Model\",\"url\":\"https://www.semanticscholar.org/paper/bd4f219ce6bc5c22f9da71959d5192cf0b0141fe\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51929926\",\"name\":\"F. Geiger\"},{\"authorId\":\"8551292\",\"name\":\"Martin Schrimpf\"},{\"authorId\":\"39035833\",\"name\":\"Tiago Marques\"},{\"authorId\":\"34409560\",\"name\":\"James J. DiCarlo\"}],\"doi\":\"10.1101/2020.06.08.140111\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"19d68db5346c837bb428160619356e36045b351c\",\"title\":\"Wiring Up Vision: Minimizing Supervised Synaptic Updates Needed to Produce a Primate Ventral Stream\",\"url\":\"https://www.semanticscholar.org/paper/19d68db5346c837bb428160619356e36045b351c\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2004.14928\",\"authors\":[{\"authorId\":\"40928701\",\"name\":\"Christos Baziotis\"},{\"authorId\":\"2259100\",\"name\":\"B. Haddow\"},{\"authorId\":\"2539211\",\"name\":\"Alexandra Birch\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.615\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb978b0eada04be0762081167aa4b0310a52dd9d\",\"title\":\"Language Model Prior for Low-Resource Neural Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/eb978b0eada04be0762081167aa4b0310a52dd9d\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50081570\",\"name\":\"Linfeng Zhang\"},{\"authorId\":\"93180269\",\"name\":\"Yukang Shi\"},{\"authorId\":\"69868912\",\"name\":\"Z. Shi\"},{\"authorId\":\"8503165\",\"name\":\"Kaisheng Ma\"},{\"authorId\":\"3183763\",\"name\":\"Chenglong Bao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aae38a2c51b4aa79b43d712e0d8a91ce4ad55bf4\",\"title\":\"Task-Oriented Feature Distillation\",\"url\":\"https://www.semanticscholar.org/paper/aae38a2c51b4aa79b43d712e0d8a91ce4ad55bf4\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"70171830\",\"name\":\"D. Kothandaraman\"},{\"authorId\":\"3265714\",\"name\":\"A. Nambiar\"},{\"authorId\":\"50853059\",\"name\":\"Anurag Mittal\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb33dbf54085d7a9025cad93c422e7f3e5f3a34c\",\"title\":\"Unsupervised Domain Adaptive Knowledge Distillation for Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/eb33dbf54085d7a9025cad93c422e7f3e5f3a34c\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2002.11794\",\"authors\":[{\"authorId\":\"2276422\",\"name\":\"Zhuohan Li\"},{\"authorId\":\"145217343\",\"name\":\"Eric Wallace\"},{\"authorId\":\"2191455\",\"name\":\"Sheng Shen\"},{\"authorId\":\"48085802\",\"name\":\"Kevin Lin\"},{\"authorId\":\"1732330\",\"name\":\"K. Keutzer\"},{\"authorId\":\"38666915\",\"name\":\"D. Klein\"},{\"authorId\":\"144307989\",\"name\":\"J. Gonzalez\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2356781b8a98bf94e6fc73798c6cb65ac35e5f97\",\"title\":\"Train Large, Then Compress: Rethinking Model Size for Efficient Training and Inference of Transformers\",\"url\":\"https://www.semanticscholar.org/paper/2356781b8a98bf94e6fc73798c6cb65ac35e5f97\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":\"2009.05226\",\"authors\":[{\"authorId\":\"46584414\",\"name\":\"Jiyue Wang\"},{\"authorId\":\"1805951175\",\"name\":\"Pei Zhang\"},{\"authorId\":\"40795754\",\"name\":\"Wenfeng Pang\"},{\"authorId\":\"40116871\",\"name\":\"Jie Li\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"bb56f0b1f66ad7b7428e574e93330ee9eb8d1c89\",\"title\":\"Extending Label Smoothing Regularization with Self-Knowledge Distillation\",\"url\":\"https://www.semanticscholar.org/paper/bb56f0b1f66ad7b7428e574e93330ee9eb8d1c89\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.14284\",\"authors\":[{\"authorId\":\"2915023\",\"name\":\"Rasool Fakoor\"},{\"authorId\":\"153430733\",\"name\":\"Jonas Mueller\"},{\"authorId\":\"47110437\",\"name\":\"Nick Erickson\"},{\"authorId\":\"152283255\",\"name\":\"Pratik Chaudhari\"},{\"authorId\":\"46234526\",\"name\":\"Alex Smola\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"3d856d797356ab32be936e74a7eed39766bfc0d3\",\"title\":\"Fast, Accurate, and Simple Models for Tabular Data via Augmented Distillation\",\"url\":\"https://www.semanticscholar.org/paper/3d856d797356ab32be936e74a7eed39766bfc0d3\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2006.01683\",\"authors\":[{\"authorId\":\"1733346578\",\"name\":\"Zaida Zhou\"},{\"authorId\":\"1693981493\",\"name\":\"Chaoran Zhuge\"},{\"authorId\":\"15063129\",\"name\":\"Xinwei Guan\"},{\"authorId\":null,\"name\":\"Wen Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"17579a1dd85acd25b17deea827459ba826408a26\",\"title\":\"Channel Distillation: Channel-Wise Attention for Knowledge Distillation\",\"url\":\"https://www.semanticscholar.org/paper/17579a1dd85acd25b17deea827459ba826408a26\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.12094\",\"authors\":[{\"authorId\":\"67215934\",\"name\":\"Benlin Liu\"},{\"authorId\":\"39358728\",\"name\":\"Yongming Rao\"},{\"authorId\":\"100475213\",\"name\":\"Jiwen Lu\"},{\"authorId\":\"144535460\",\"name\":\"J. Zhou\"},{\"authorId\":\"3310983\",\"name\":\"C. Hsieh\"}],\"doi\":\"10.1007/978-3-030-58568-6_41\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"6e0c4191f8f245cad3a30797cffd5c3e64ed26a7\",\"title\":\"MetaDistiller: Network Self-Boosting via Meta-Learned Top-Down Distillation\",\"url\":\"https://www.semanticscholar.org/paper/6e0c4191f8f245cad3a30797cffd5c3e64ed26a7\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2004.12311\",\"authors\":[{\"authorId\":\"145242715\",\"name\":\"Hao Cheng\"},{\"authorId\":\"14788211\",\"name\":\"Fanxu Meng\"},{\"authorId\":\"36844147\",\"name\":\"K. Li\"},{\"authorId\":\"1657464379\",\"name\":\"Huixiang Luo\"},{\"authorId\":\"143911582\",\"name\":\"Guangming Lu\"},{\"authorId\":\"49932595\",\"name\":\"X. Guo\"},{\"authorId\":\"50187838\",\"name\":\"Feiyue Huang\"},{\"authorId\":\"143900241\",\"name\":\"Xing Sun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e7dfe797f2de0b1864f04422d83ef49149500231\",\"title\":\"DGD: Densifying the Knowledge of Neural Networks with Filter Grafting and Knowledge Distillation\",\"url\":\"https://www.semanticscholar.org/paper/e7dfe797f2de0b1864f04422d83ef49149500231\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2744759\",\"name\":\"Han-Jia Ye\"},{\"authorId\":\"50345057\",\"name\":\"Su Lu\"},{\"authorId\":\"1721819\",\"name\":\"D. Zhan\"}],\"doi\":\"10.1109/cvpr42600.2020.01241\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"227729510da9acd404e9e70811bc61cb1bc059f7\",\"title\":\"Distilling Cross-Task Knowledge via Relationship Matching\",\"url\":\"https://www.semanticscholar.org/paper/227729510da9acd404e9e70811bc61cb1bc059f7\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2003.04289\",\"authors\":[{\"authorId\":\"2744249\",\"name\":\"J. Yang\"},{\"authorId\":\"145944235\",\"name\":\"B. Mart\\u00ednez\"},{\"authorId\":\"145245424\",\"name\":\"Adrian Bulat\"},{\"authorId\":\"2610880\",\"name\":\"Georgios Tzimiropoulos\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3913afb4d9747dcbf27e75e75dcf4c48e6da00b2\",\"title\":\"Knowledge distillation via adaptive instance normalization\",\"url\":\"https://www.semanticscholar.org/paper/3913afb4d9747dcbf27e75e75dcf4c48e6da00b2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.08007\",\"authors\":[{\"authorId\":\"70171830\",\"name\":\"D. Kothandaraman\"},{\"authorId\":\"3265714\",\"name\":\"A. Nambiar\"},{\"authorId\":\"50853059\",\"name\":\"Anurag Mittal\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e32728e7809dab95d0f614f6fc9ef68a8c43393a\",\"title\":\"Domain Adaptive Knowledge Distillation for Driving Scene Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/e32728e7809dab95d0f614f6fc9ef68a8c43393a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.11066\",\"authors\":[{\"authorId\":\"145689527\",\"name\":\"Abhinav Goel\"},{\"authorId\":\"145910992\",\"name\":\"Caleb Tung\"},{\"authorId\":\"1781255\",\"name\":\"Yung-Hsiang Lu\"},{\"authorId\":\"145078593\",\"name\":\"G. K. Thiruvathukal\"}],\"doi\":\"10.1109/WF-IoT48130.2020.9221198\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0ac0c18fdb61577b5e67c5eb23cf8e1113dac0ba\",\"title\":\"A Survey of Methods for Low-Power Deep Learning and Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/0ac0c18fdb61577b5e67c5eb23cf8e1113dac0ba\",\"venue\":\"2020 IEEE 6th World Forum on Internet of Things (WF-IoT)\",\"year\":2020},{\"arxivId\":\"2010.07485\",\"authors\":[{\"authorId\":\"50115396\",\"name\":\"Jian-Xin Guo\"},{\"authorId\":\"2456739\",\"name\":\"Minghao Chen\"},{\"authorId\":\"46972595\",\"name\":\"Yao Hu\"},{\"authorId\":\"1500736585\",\"name\":\"Chen Zhu\"},{\"authorId\":\"3945955\",\"name\":\"X. He\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"}],\"doi\":null,\"intent\":[\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"9cbeb8595713c5f52b10e7837df545b5da0937f4\",\"title\":\"Spherical Knowledge Distillation\",\"url\":\"https://www.semanticscholar.org/paper/9cbeb8595713c5f52b10e7837df545b5da0937f4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.04719\",\"authors\":[{\"authorId\":\"50079136\",\"name\":\"Xuewei Li\"},{\"authorId\":\"47319889\",\"name\":\"Songyuan Li\"},{\"authorId\":\"22273493\",\"name\":\"Omar El Farouk Bourahla\"},{\"authorId\":\"121856937\",\"name\":\"X. Li\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"673b939b4b56daea45d97ecdeef725a34b3fead1\",\"title\":\"ResKD: Residual-Guided Knowledge Distillation\",\"url\":\"https://www.semanticscholar.org/paper/673b939b4b56daea45d97ecdeef725a34b3fead1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1840081210\",\"name\":\"Taehyeon Kim\"},{\"authorId\":\"46299565\",\"name\":\"Jaehoon Oh\"},{\"authorId\":\"2032192304\",\"name\":\"Nakyil Kim\"},{\"authorId\":\"2503579\",\"name\":\"S. Cho\"},{\"authorId\":\"2539390\",\"name\":\"Seyoung Yun\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d16f24d6f13307a56a9ea90415678549dc7631ab\",\"title\":\"Understanding Knowledge Distillation\",\"url\":\"https://www.semanticscholar.org/paper/d16f24d6f13307a56a9ea90415678549dc7631ab\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2011.09158\",\"authors\":[{\"authorId\":\"2283619\",\"name\":\"Peisen Zhao\"},{\"authorId\":\"97773539\",\"name\":\"Jiajie Wang\"},{\"authorId\":\"3041937\",\"name\":\"Lingxi Xie\"},{\"authorId\":\"98049755\",\"name\":\"Y. Zhang\"},{\"authorId\":null,\"name\":\"Yanfeng Wang\"},{\"authorId\":\"1471647358\",\"name\":\"Qi Tian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"42b6d63416f46e9ac2bcdda9a7065f4682f18e93\",\"title\":\"Privileged Knowledge Distillation for Online Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/42b6d63416f46e9ac2bcdda9a7065f4682f18e93\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145480158\",\"name\":\"Danilo Pereira\"},{\"authorId\":\"34822887\",\"name\":\"F. A. O. Santos\"},{\"authorId\":\"145254176\",\"name\":\"L. Matos\"},{\"authorId\":\"145302989\",\"name\":\"P. Novais\"},{\"authorId\":\"2948325\",\"name\":\"C. Zanchettin\"},{\"authorId\":\"1746612\",\"name\":\"T. Ludermir\"}],\"doi\":\"10.1007/978-3-030-62365-4_20\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7461e45276db845d40dcf8301e69dffd9fbe851a\",\"title\":\"On Analysing Similarity Knowledge Transfer by Ensembles\",\"url\":\"https://www.semanticscholar.org/paper/7461e45276db845d40dcf8301e69dffd9fbe851a\",\"venue\":\"IDEAL\",\"year\":2020},{\"arxivId\":\"2006.03669\",\"authors\":[{\"authorId\":\"152342307\",\"name\":\"J. O. Neill\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"adbf76b63ec20225e069c1f2f21b32ce1e86d8f5\",\"title\":\"An Overview of Neural Network Compression\",\"url\":\"https://www.semanticscholar.org/paper/adbf76b63ec20225e069c1f2f21b32ce1e86d8f5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.13960\",\"authors\":[{\"authorId\":\"49370795\",\"name\":\"Dongdong Wang\"},{\"authorId\":\"1527095795\",\"name\":\"Yandong Li\"},{\"authorId\":\"49681507\",\"name\":\"Liqiang Wang\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"}],\"doi\":\"10.1109/cvpr42600.2020.00157\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d5a93c7ef56137e500f3615840d4bb1d4b4fd25d\",\"title\":\"Neural Networks Are More Productive Teachers Than Human Raters: Active Mixup for Data-Efficient Knowledge Distillation From a Blackbox Model\",\"url\":\"https://www.semanticscholar.org/paper/d5a93c7ef56137e500f3615840d4bb1d4b4fd25d\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1789397\",\"name\":\"D. Ienco\"},{\"authorId\":\"148390087\",\"name\":\"Yawogan Jean Eudes Gbodjo\"},{\"authorId\":\"144836023\",\"name\":\"R. Gaetano\"},{\"authorId\":\"2125780\",\"name\":\"Roberto Interdonato\"}],\"doi\":\"10.5194/isprs-annals-v-2-2020-997-2020\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d1c6355fd5d22dcdab60d87a9e2dc45ca78c6e85\",\"title\":\"GENERALIZED KNOWLEDGE DISTILLATION FOR MULTI-SENSOR REMOTE SENSING CLASSIFICATION: AN APPLICATION TO LAND COVER MAPPING\",\"url\":\"https://www.semanticscholar.org/paper/d1c6355fd5d22dcdab60d87a9e2dc45ca78c6e85\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2006.11487\",\"authors\":[{\"authorId\":\"144864525\",\"name\":\"D. H. Le\"},{\"authorId\":\"1753622419\",\"name\":\"Vo Trung Nhan\"},{\"authorId\":\"1738622\",\"name\":\"Nam Thoai\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a6b499136aa70dfad66fca5efaaaead5c616d59b\",\"title\":\"Paying more attention to snapshots of Iterative Pruning: Improving Model Compression via Ensemble Distillation\",\"url\":\"https://www.semanticscholar.org/paper/a6b499136aa70dfad66fca5efaaaead5c616d59b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52224165\",\"name\":\"Fadi Boutros\"},{\"authorId\":\"2265721\",\"name\":\"Naser Damer\"},{\"authorId\":\"1944448620\",\"name\":\"Meiling Fang\"},{\"authorId\":\"34711412\",\"name\":\"K. Raja\"},{\"authorId\":\"2178720\",\"name\":\"Florian Kirchbuchner\"},{\"authorId\":\"145307900\",\"name\":\"Arjan Kuijper\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ca07c89353f89936a901b5659945fb0d7c4c9712\",\"title\":\"Compact Models for Periocular Verification Through Knowledge Distillation\",\"url\":\"https://www.semanticscholar.org/paper/ca07c89353f89936a901b5659945fb0d7c4c9712\",\"venue\":\"2020 International Conference of the Biometrics Special Interest Group (BIOSIG)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29892729\",\"name\":\"Matteo Dunnhofer\"},{\"authorId\":\"1736750\",\"name\":\"N. Martinel\"},{\"authorId\":\"1708507\",\"name\":\"C. Micheloni\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"37b52eb928c6197cc0d840d27d1f3a1c8cccdb34\",\"title\":\"A Distilled Model for Tracking and Tracker Fusion\",\"url\":\"https://www.semanticscholar.org/paper/37b52eb928c6197cc0d840d27d1f3a1c8cccdb34\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.08825\",\"authors\":[{\"authorId\":\"1557388434\",\"name\":\"Wonchul Son\"},{\"authorId\":\"107598106\",\"name\":\"Jaemin Na\"},{\"authorId\":\"34600044\",\"name\":\"Wonjun Hwang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7fb39400e066b9adf1a75e8142fc64a6661f17d9\",\"title\":\"Densely Guided Knowledge Distillation using Multiple Teacher Assistants\",\"url\":\"https://www.semanticscholar.org/paper/7fb39400e066b9adf1a75e8142fc64a6661f17d9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.05065\",\"authors\":[{\"authorId\":\"1491240545\",\"name\":\"Zhilu Zhang\"},{\"authorId\":\"2369409\",\"name\":\"M. Sabuncu\"}],\"doi\":null,\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"2bdfc6d8f6d03b38b80b8aa4112088323b6b552f\",\"title\":\"Self-Distillation as Instance-Specific Label Smoothing\",\"url\":\"https://www.semanticscholar.org/paper/2bdfc6d8f6d03b38b80b8aa4112088323b6b552f\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2010.04812\",\"authors\":[{\"authorId\":\"145924070\",\"name\":\"Xiang Deng\"},{\"authorId\":\"9338907\",\"name\":\"Z. Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8536befb9e0109058f67267ecf0ae610e7c75090\",\"title\":\"Locally Linear Region Knowledge Distillation\",\"url\":\"https://www.semanticscholar.org/paper/8536befb9e0109058f67267ecf0ae610e7c75090\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"SION VIA\"},{\"authorId\":null,\"name\":\"ENSEMBLE DISTILLATION\"},{\"authorId\":\"144864525\",\"name\":\"Duong Hoang Le\"},{\"authorId\":\"1753622419\",\"name\":\"Vo Trung Nhan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e6466feb728069311b172273d512485a0edd3ce7\",\"title\":\"ITERATIVE PRUNING: IMPROVING MODEL COMPRES-\",\"url\":\"https://www.semanticscholar.org/paper/e6466feb728069311b172273d512485a0edd3ce7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2012.12877\",\"authors\":[{\"authorId\":\"146941532\",\"name\":\"Hugo Touvron\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"},{\"authorId\":\"3271933\",\"name\":\"M. Douze\"},{\"authorId\":\"1403239967\",\"name\":\"F. Massa\"},{\"authorId\":\"3469062\",\"name\":\"Alexandre Sablayrolles\"},{\"authorId\":\"1681054\",\"name\":\"H. J\\u00e9gou\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8c13be599a8aef4f7ffb467e03fde65e855a366c\",\"title\":\"Training data-efficient image transformers&distillation through attention\",\"url\":\"https://www.semanticscholar.org/paper/8c13be599a8aef4f7ffb467e03fde65e855a366c\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2004.05937\",\"authors\":[{\"authorId\":null,\"name\":\"Lin Wang\"},{\"authorId\":\"51182421\",\"name\":\"Kuk-Jin Yoon\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2528a82dd2266600d4ee2b54165556a984de94d4\",\"title\":\"Knowledge Distillation and Student-Teacher Learning for Visual Intelligence: A Review and New Outlooks\",\"url\":\"https://www.semanticscholar.org/paper/2528a82dd2266600d4ee2b54165556a984de94d4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.14435\",\"authors\":[{\"authorId\":\"143715689\",\"name\":\"Xiang Hao\"},{\"authorId\":\"31871922\",\"name\":\"Shi-Xue Wen\"},{\"authorId\":\"80644791\",\"name\":\"Xiangdong Su\"},{\"authorId\":\"49420738\",\"name\":\"Y. Liu\"},{\"authorId\":\"1807620\",\"name\":\"Guanglai Gao\"},{\"authorId\":\"50079006\",\"name\":\"Xiaofei Li\"}],\"doi\":\"10.21437/Interspeech.2020-1539\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6b417238aee5c1af70f4f7e1db63f692276fcfa5\",\"title\":\"Sub-band Knowledge Distillation Framework for Speech Enhancement\",\"url\":\"https://www.semanticscholar.org/paper/6b417238aee5c1af70f4f7e1db63f692276fcfa5\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":\"2011.14779\",\"authors\":[{\"authorId\":\"2029496490\",\"name\":\"Jean-Baptiste Truong\"},{\"authorId\":\"153742303\",\"name\":\"Pratyush Maini\"},{\"authorId\":\"2329545\",\"name\":\"Robert J. Walls\"},{\"authorId\":\"1967156\",\"name\":\"Nicolas Papernot\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"287e82b08cc5b8c8aae03825b466fcb73860b0c4\",\"title\":\"Data-Free Model Extraction\",\"url\":\"https://www.semanticscholar.org/paper/287e82b08cc5b8c8aae03825b466fcb73860b0c4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.16589\",\"authors\":[{\"authorId\":\"1739130318\",\"name\":\"Nandan Kumar Jha\"},{\"authorId\":\"143805025\",\"name\":\"Rajat Saini\"},{\"authorId\":\"32001938\",\"name\":\"Sparsh Mittal\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1de777c50096a63502d27a934bbb9a9d10c11284\",\"title\":\"On the Demystification of Knowledge Distillation: A Residual Network Perspective\",\"url\":\"https://www.semanticscholar.org/paper/1de777c50096a63502d27a934bbb9a9d10c11284\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.07485\",\"authors\":[{\"authorId\":\"2018337565\",\"name\":\"Jia Guo\"},{\"authorId\":\"1520489466\",\"name\":\"Minghao Chen\"},{\"authorId\":\"46972595\",\"name\":\"Yao Hu\"},{\"authorId\":\"1500736585\",\"name\":\"Chen Zhu\"},{\"authorId\":\"50045633\",\"name\":\"X. He\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b7cc617934531088554898d0a9a46d2988db58aa\",\"title\":\"Reducing the Teacher-Student Gap via Spherical Knowledge Disitllation.\",\"url\":\"https://www.semanticscholar.org/paper/b7cc617934531088554898d0a9a46d2988db58aa\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2008.01458\",\"authors\":[{\"authorId\":\"144128023\",\"name\":\"Youcai Zhang\"},{\"authorId\":\"1591111265\",\"name\":\"Zhonghao Lan\"},{\"authorId\":\"3373150\",\"name\":\"Yuchen Dai\"},{\"authorId\":\"1853188487\",\"name\":\"Fangao Zeng\"},{\"authorId\":\"1753497434\",\"name\":\"Yan Bai\"},{\"authorId\":\"14071917\",\"name\":\"J. Chang\"},{\"authorId\":\"1732264\",\"name\":\"Y. Wei\"}],\"doi\":\"10.1007/978-3-030-58529-7_39\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d14eedd992081c5011d43747b80535629f68372\",\"title\":\"Prime-Aware Adaptive Distillation\",\"url\":\"https://www.semanticscholar.org/paper/9d14eedd992081c5011d43747b80535629f68372\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150068084\",\"name\":\"Changyong Yu\"},{\"authorId\":\"48535604\",\"name\":\"Xin He\"},{\"authorId\":\"1471705521\",\"name\":\"Haitao Ma\"},{\"authorId\":\"1471706404\",\"name\":\"Xin Qi\"},{\"authorId\":\"1471677780\",\"name\":\"Jiarui Lu\"},{\"authorId\":\"47827883\",\"name\":\"Yuhai Zhao\"}],\"doi\":\"10.1109/ACCESS.2019.2960315\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"1f8dae7c84f46aeaf6cc98b8b18a1011ad6e9cc8\",\"title\":\"S-DenseNet: A DenseNet Compression Model Based on Convolution Grouping Strategy Using Skyline Method\",\"url\":\"https://www.semanticscholar.org/paper/1f8dae7c84f46aeaf6cc98b8b18a1011ad6e9cc8\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1912.01540\",\"authors\":[{\"authorId\":\"3451474\",\"name\":\"Himalaya Jain\"},{\"authorId\":\"2475428\",\"name\":\"Spyros Gidaris\"},{\"authorId\":\"2505902\",\"name\":\"Nikos Komodakis\"},{\"authorId\":\"1398301486\",\"name\":\"P. P\\u00e9rez\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"}],\"doi\":\"10.1007/978-3-030-58589-1_11\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7c1400a8998b28d0ff1220f2fdcf4c2380244b83\",\"title\":\"QUEST: Quantized embedding space for transferring knowledge\",\"url\":\"https://www.semanticscholar.org/paper/7c1400a8998b28d0ff1220f2fdcf4c2380244b83\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2009.04120\",\"authors\":[{\"authorId\":\"35869519\",\"name\":\"Seonguk Park\"},{\"authorId\":\"1713608836\",\"name\":\"Kiyoon Yoo\"},{\"authorId\":\"71494716\",\"name\":\"Nojun Kwak\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f84b959e714d958b94e5314759b29759a0bc7a6d\",\"title\":\"On the Orthogonality of Knowledge Distillation with Other Techniques: From an Ensemble Perspective\",\"url\":\"https://www.semanticscholar.org/paper/f84b959e714d958b94e5314759b29759a0bc7a6d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.03944\",\"authors\":[{\"authorId\":\"1557388434\",\"name\":\"Wonchul Son\"},{\"authorId\":\"2304259\",\"name\":\"Youngbin Kim\"},{\"authorId\":\"145523834\",\"name\":\"W. Song\"},{\"authorId\":\"2198635\",\"name\":\"Youngsu Moon\"},{\"authorId\":\"34600044\",\"name\":\"Wonjun Hwang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f40777ad655a9ac1fc88b53675d01ff33f41bc6d\",\"title\":\"Pacemaker: Intermediate Teacher Knowledge Distillation For On-The-Fly Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/f40777ad655a9ac1fc88b53675d01ff33f41bc6d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.01189\",\"authors\":[{\"authorId\":\"19295627\",\"name\":\"Laetitia Shao\"},{\"authorId\":\"2740527\",\"name\":\"Elad Eban\"},{\"authorId\":\"1405595195\",\"name\":\"Yair Movshovitz-Attias\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"67af264656fbd50f46cd23fca0380f2966490f56\",\"title\":\"Neighbourhood Distillation: On the benefits of non end-to-end distillation\",\"url\":\"https://www.semanticscholar.org/paper/67af264656fbd50f46cd23fca0380f2966490f56\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.05525\",\"authors\":[{\"authorId\":\"37233332\",\"name\":\"J. Gou\"},{\"authorId\":\"2425630\",\"name\":\"B. Yu\"},{\"authorId\":\"144555237\",\"name\":\"S. Maybank\"},{\"authorId\":\"145047838\",\"name\":\"Dacheng Tao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"1728cb805a9573b59330890ba9723e73d6c3c974\",\"title\":\"Knowledge Distillation: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/1728cb805a9573b59330890ba9723e73d6c3c974\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.07524\",\"authors\":[{\"authorId\":\"49627087\",\"name\":\"Wonkyung Lee\"},{\"authorId\":\"26973831\",\"name\":\"Junghyup Lee\"},{\"authorId\":null,\"name\":\"Dohyung Kim\"},{\"authorId\":\"38723538\",\"name\":\"Bumsub Ham\"}],\"doi\":\"10.1007/978-3-030-58586-0_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c0d12b9f44ae769e26d60248fe65f945900a8399\",\"title\":\"Learning with Privileged Information for Efficient Image Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/c0d12b9f44ae769e26d60248fe65f945900a8399\",\"venue\":\"ECCV\",\"year\":2020}],\"corpusId\":203642130,\"doi\":\"10.1109/ICCV.2019.00489\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":7,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"8de7f044a673d1f5e3b454d0663811f91aa9811a\",\"references\":[{\"arxivId\":\"1606.07947\",\"authors\":[{\"authorId\":\"38367242\",\"name\":\"Yoon Kim\"},{\"authorId\":\"2531268\",\"name\":\"Alexander M. Rush\"}],\"doi\":\"10.18653/v1/D16-1139\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"57a10537978600fd33dcdd48922c791609a4851a\",\"title\":\"Sequence-Level Knowledge Distillation\",\"url\":\"https://www.semanticscholar.org/paper/57a10537978600fd33dcdd48922c791609a4851a\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":\"1612.03928\",\"authors\":[{\"authorId\":\"2134433\",\"name\":\"Sergey Zagoruyko\"},{\"authorId\":\"2505902\",\"name\":\"Nikos Komodakis\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f7b032a4df721d4ed2bab97f6acd33d62477b7a5\",\"title\":\"Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer\",\"url\":\"https://www.semanticscholar.org/paper/f7b032a4df721d4ed2bab97f6acd33d62477b7a5\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1703.01780\",\"authors\":[{\"authorId\":\"9942966\",\"name\":\"Antti Tarvainen\"},{\"authorId\":\"2132516\",\"name\":\"H. Valpola\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"1342c1e1684620c019972e2679d5131f1e8a4a13\",\"title\":\"Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results\",\"url\":\"https://www.semanticscholar.org/paper/1342c1e1684620c019972e2679d5131f1e8a4a13\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1711.06798\",\"authors\":[{\"authorId\":\"152894252\",\"name\":\"A. Gordon\"},{\"authorId\":\"2740527\",\"name\":\"Elad Eban\"},{\"authorId\":\"7624658\",\"name\":\"Ofir Nachum\"},{\"authorId\":\"145779964\",\"name\":\"B. Chen\"},{\"authorId\":\"1950815\",\"name\":\"Tien-Ju Yang\"},{\"authorId\":\"1387328701\",\"name\":\"Edward Choi\"}],\"doi\":\"10.1109/CVPR.2018.00171\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e60f693cb12132c7fffc34dc141bcc3c9dfd4961\",\"title\":\"MorphNet: Fast & Simple Resource-Constrained Structure Learning of Deep Networks\",\"url\":\"https://www.semanticscholar.org/paper/e60f693cb12132c7fffc34dc141bcc3c9dfd4961\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Gao Huang\"},{\"authorId\":null,\"name\":\"Zhuang Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Laurens van der Maaten, and Kilian Q Weinberger. Densely connected convolutional networks\",\"url\":\"\",\"venue\":\"CVPR\",\"year\":2017},{\"arxivId\":\"1706.00384\",\"authors\":[{\"authorId\":\"46868596\",\"name\":\"Y. Zhang\"},{\"authorId\":\"145406421\",\"name\":\"T. Xiang\"},{\"authorId\":\"1697755\",\"name\":\"Timothy M. Hospedales\"},{\"authorId\":\"1790976\",\"name\":\"H. Lu\"}],\"doi\":\"10.1109/CVPR.2018.00454\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f06a12928307e17b1aff2b9f4a6c11791f19b6a7\",\"title\":\"Deep Mutual Learning\",\"url\":\"https://www.semanticscholar.org/paper/f06a12928307e17b1aff2b9f4a6c11791f19b6a7\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1510.00149\",\"authors\":[{\"authorId\":\"143840277\",\"name\":\"Song Han\"},{\"authorId\":\"3123774\",\"name\":\"Huizi Mao\"},{\"authorId\":\"80724002\",\"name\":\"W. Dally\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"642d0f49b7826adcf986616f4af77e736229990f\",\"title\":\"Deep Compression: Compressing Deep Neural Network with Pruning, Trained Quantization and Huffman Coding\",\"url\":\"https://www.semanticscholar.org/paper/642d0f49b7826adcf986616f4af77e736229990f\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2591217\",\"name\":\"Cristian Bucila\"},{\"authorId\":\"145727186\",\"name\":\"R. Caruana\"},{\"authorId\":\"1399048849\",\"name\":\"Alexandru Niculescu-Mizil\"}],\"doi\":\"10.1145/1150402.1150464\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"30c9bb327b7f2b9f1d1e5b69b9d0c97b410948d9\",\"title\":\"Model compression\",\"url\":\"https://www.semanticscholar.org/paper/30c9bb327b7f2b9f1d1e5b69b9d0c97b410948d9\",\"venue\":\"KDD '06\",\"year\":2006},{\"arxivId\":\"1805.04770\",\"authors\":[{\"authorId\":\"2426872\",\"name\":\"T. Furlanello\"},{\"authorId\":\"32219137\",\"name\":\"Zachary Chase Lipton\"},{\"authorId\":\"143902495\",\"name\":\"Michael Tschannen\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"},{\"authorId\":\"2047844\",\"name\":\"Anima Anandkumar\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2444be7584d1f5a7e2aa9f65078de09154f14ea1\",\"title\":\"Born Again Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/2444be7584d1f5a7e2aa9f65078de09154f14ea1\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":\"1707.01219\",\"authors\":[{\"authorId\":\"5198321\",\"name\":\"Z. Huang\"},{\"authorId\":\"48246959\",\"name\":\"Naiyan Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"971fc689ff73e412306057177ee203d0b8f64fd1\",\"title\":\"Like What You Like: Knowledge Distill via Neuron Selectivity Transfer\",\"url\":\"https://www.semanticscholar.org/paper/971fc689ff73e412306057177ee203d0b8f64fd1\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yoon Kim\"},{\"authorId\":null,\"name\":\"M. Alexander\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Rush . Sequence - level knowledge distillation\",\"url\":\"\",\"venue\":\"Densely connected convolutional networks . In CVPR\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Cristian Bucilu\\u01ce\"},{\"authorId\":null,\"name\":\"Rich Caruana\"},{\"authorId\":null,\"name\":\"Alexandru Niculescu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Mizil. Model compression\",\"url\":\"\",\"venue\":\"In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining,\",\"year\":2006},{\"arxivId\":\"1703.09580\",\"authors\":[{\"authorId\":\"3310425\",\"name\":\"M. Mahsereci\"},{\"authorId\":\"8604693\",\"name\":\"Lukas Balles\"},{\"authorId\":\"3266545\",\"name\":\"Christoph Lassner\"},{\"authorId\":\"2517795\",\"name\":\"Philipp Hennig\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fa990915583dd4ba94139c08827d0d0e3c7a3ac8\",\"title\":\"Early Stopping without a Validation Set\",\"url\":\"https://www.semanticscholar.org/paper/fa990915583dd4ba94139c08827d0d0e3c7a3ac8\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1806.04606\",\"authors\":[{\"authorId\":\"143866730\",\"name\":\"X. Lan\"},{\"authorId\":\"2171228\",\"name\":\"Xiatian Zhu\"},{\"authorId\":\"144784813\",\"name\":\"S. Gong\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c864e3785a9aecf25296781c272980eaed78e51a\",\"title\":\"Knowledge Distillation by On-the-Fly Native Ensemble\",\"url\":\"https://www.semanticscholar.org/paper/c864e3785a9aecf25296781c272980eaed78e51a\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1711.05852\",\"authors\":[{\"authorId\":\"35769149\",\"name\":\"A. Mishra\"},{\"authorId\":\"33027790\",\"name\":\"Debbie Marr\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf8c44a703350ebc5df46a861c76db9f0e49457b\",\"title\":\"Apprentice: Using Knowledge Distillation Techniques To Improve Low-Precision Network Accuracy\",\"url\":\"https://www.semanticscholar.org/paper/cf8c44a703350ebc5df46a861c76db9f0e49457b\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1804.00644\",\"authors\":[{\"authorId\":\"8783768\",\"name\":\"Zhong Meng\"},{\"authorId\":\"145364697\",\"name\":\"J. Li\"},{\"authorId\":\"1777280\",\"name\":\"Y. Gong\"},{\"authorId\":\"143604406\",\"name\":\"B. Juang\"}],\"doi\":\"10.1109/ICASSP.2018.8461682\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"22fdf5a50e40135ad04a2377e6c892fffe1dd642\",\"title\":\"Adversarial Teacher-Student Learning for Unsupervised Domain Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/22fdf5a50e40135ad04a2377e6c892fffe1dd642\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":\"1507.00448\",\"authors\":[{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"50196944\",\"name\":\"Judy Hoffman\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/CVPR.2016.309\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"53d1e022961e241164ecb6ec58378d7033a280f8\",\"title\":\"Cross Modal Distillation for Supervision Transfer\",\"url\":\"https://www.semanticscholar.org/paper/53d1e022961e241164ecb6ec58378d7033a280f8\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1512.06473\",\"authors\":[{\"authorId\":\"143706247\",\"name\":\"J. Wu\"},{\"authorId\":\"3259574\",\"name\":\"C. Leng\"},{\"authorId\":\"3152755\",\"name\":\"Yuhang Wang\"},{\"authorId\":\"2571792\",\"name\":\"Q. Hu\"},{\"authorId\":\"143949499\",\"name\":\"J. Cheng\"}],\"doi\":\"10.1109/CVPR.2016.521\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d3cb9bad655197b52932978dd8186b36c512bf92\",\"title\":\"Quantized Convolutional Neural Networks for Mobile Devices\",\"url\":\"https://www.semanticscholar.org/paper/d3cb9bad655197b52932978dd8186b36c512bf92\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1312.6184\",\"authors\":[{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"145727186\",\"name\":\"R. Caruana\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d770060812fb646b3846a7d398a3066145b5e3c8\",\"title\":\"Do Deep Nets Really Need to be Deep?\",\"url\":\"https://www.semanticscholar.org/paper/d770060812fb646b3846a7d398a3066145b5e3c8\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1706.04599\",\"authors\":[{\"authorId\":\"144993411\",\"name\":\"Chuan Guo\"},{\"authorId\":\"10804137\",\"name\":\"Geoff Pleiss\"},{\"authorId\":\"35760122\",\"name\":\"Yu Sun\"},{\"authorId\":\"7446832\",\"name\":\"Kilian Q. Weinberger\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d65ce2b8300541414bfe51d03906fca72e93523c\",\"title\":\"On Calibration of Modern Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/d65ce2b8300541414bfe51d03906fca72e93523c\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Cristian Bucilu\\u01ce\"},{\"authorId\":null,\"name\":\"Rich Caruana\"},{\"authorId\":null,\"name\":\"Alexandru Niculescu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Mizil. Model compression\",\"url\":\"\",\"venue\":\"In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining,\",\"year\":2006},{\"arxivId\":\"1503.02531\",\"authors\":[{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0c908739fbff75f03469d13d4a1a07de3414ee19\",\"title\":\"Distilling the Knowledge in a Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/0c908739fbff75f03469d13d4a1a07de3414ee19\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"I. Guyon\"},{\"authorId\":null,\"name\":\"S. Vishwanathan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Michael Tschan - nen , Laurent Itti , and Anima Anandkumar . Born again neural networks\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Zhuang Liu\"},{\"authorId\":null,\"name\":\"Yoon Kim\"},{\"authorId\":null,\"name\":\"M. Alexander\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Rush . Sequence - level knowledge distillation\",\"url\":\"\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1605.07146\",\"authors\":[{\"authorId\":\"2134433\",\"name\":\"Sergey Zagoruyko\"},{\"authorId\":\"2505902\",\"name\":\"Nikos Komodakis\"}],\"doi\":\"10.5244/C.30.87\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1c4e9156ca07705531e45960b7a919dc473abb51\",\"title\":\"Wide Residual Networks\",\"url\":\"https://www.semanticscholar.org/paper/1c4e9156ca07705531e45960b7a919dc473abb51\",\"venue\":\"BMVC\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145727186\",\"name\":\"R. Caruana\"},{\"authorId\":\"145840115\",\"name\":\"S. Lawrence\"},{\"authorId\":\"145157784\",\"name\":\"C. Lee Giles\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"072d756c8b17a78018298e67ff29e6d3a4fe5770\",\"title\":\"Overfitting in Neural Nets: Backpropagation, Conjugate Gradient, and Early Stopping\",\"url\":\"https://www.semanticscholar.org/paper/072d756c8b17a78018298e67ff29e6d3a4fe5770\",\"venue\":\"NIPS\",\"year\":2000},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2527420\",\"name\":\"Yevgen Chebotar\"},{\"authorId\":\"40418206\",\"name\":\"Austin Waters\"}],\"doi\":\"10.21437/Interspeech.2016-1190\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c78c3b2593b808ed7af498bba48768dd607f8787\",\"title\":\"Distilling Knowledge from Ensembles of Neural Networks for Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c78c3b2593b808ed7af498bba48768dd607f8787\",\"venue\":\"INTERSPEECH\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3249661\",\"name\":\"Junho Yim\"},{\"authorId\":\"50001046\",\"name\":\"Donggyu Joo\"},{\"authorId\":\"28960350\",\"name\":\"Jihoon Bae\"},{\"authorId\":\"1769295\",\"name\":\"Junmo Kim\"}],\"doi\":\"10.1109/CVPR.2017.754\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0410659b6a311b281d10e0e44abce9b1c06be462\",\"title\":\"A Gift from Knowledge Distillation: Fast Optimization, Network Minimization and Transfer Learning\",\"url\":\"https://www.semanticscholar.org/paper/0410659b6a311b281d10e0e44abce9b1c06be462\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1805.05551\",\"authors\":[{\"authorId\":\"8100330\",\"name\":\"Chenglin Yang\"},{\"authorId\":\"3041937\",\"name\":\"Lingxi Xie\"},{\"authorId\":\"2383133\",\"name\":\"Siyuan Qiao\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a0fe39e7008f25d2084fae0bc5c5cb53b0b9caa4\",\"title\":\"Knowledge Distillation in Generations: More Tolerant Teachers Educate Better Students\",\"url\":\"https://www.semanticscholar.org/paper/a0fe39e7008f25d2084fae0bc5c5cb53b0b9caa4\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1608.06993\",\"authors\":[{\"authorId\":\"143983679\",\"name\":\"Gao Huang\"},{\"authorId\":null,\"name\":\"Zhuang Liu\"},{\"authorId\":\"7446832\",\"name\":\"Kilian Q. Weinberger\"}],\"doi\":\"10.1109/CVPR.2017.243\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5694e46284460a648fe29117cbc55f6c9be3fa3c\",\"title\":\"Densely Connected Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/5694e46284460a648fe29117cbc55f6c9be3fa3c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1727550\",\"name\":\"G. Chen\"},{\"authorId\":\"17132791\",\"name\":\"W. Choi\"},{\"authorId\":\"143880075\",\"name\":\"X. Yu\"},{\"authorId\":\"3244463\",\"name\":\"Tony X. Han\"},{\"authorId\":\"2099305\",\"name\":\"Manmohan Chandraker\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"16161051ee13dd3d836a39a280df822bf6442c84\",\"title\":\"Learning Efficient Object Detection Models with Knowledge Distillation\",\"url\":\"https://www.semanticscholar.org/paper/16161051ee13dd3d836a39a280df822bf6442c84\",\"venue\":\"NIPS\",\"year\":2017}],\"title\":\"On the Efficacy of Knowledge Distillation\",\"topics\":[{\"topic\":\"ImageNet\",\"topicId\":\"256302\",\"url\":\"https://www.semanticscholar.org/topic/256302\"}],\"url\":\"https://www.semanticscholar.org/paper/8de7f044a673d1f5e3b454d0663811f91aa9811a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019}\n"