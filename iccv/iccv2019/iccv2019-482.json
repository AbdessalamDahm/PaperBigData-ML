"{\"abstract\":\"Neural networks have been proven to be vulnerable to a variety of adversarial attacks. From a safety perspective, highly sparse adversarial attacks are particularly dangerous. On the other hand the pixelwise perturbations of sparse attacks are typically large and thus can be potentially detected. We propose a new black-box technique to craft adversarial examples aiming at minimizing $l_0$-distance to the original image. Extensive experiments show that our attack is better or competitive to the state of the art. Moreover, we can integrate additional bounds on the componentwise perturbation. Allowing pixels to change only in region of high variation and avoiding changes along axis-aligned edges makes our adversarial examples almost non-perceivable. Moreover, we adapt the Projected Gradient Descent attack to the $l_0$-norm integrating componentwise constraints. This allows us to do adversarial training to enhance the robustness of classifiers against sparse and imperceivable adversarial manipulations.\",\"arxivId\":\"1909.05040\",\"authors\":[{\"authorId\":\"39171784\",\"name\":\"F. Croce\",\"url\":\"https://www.semanticscholar.org/author/39171784\"},{\"authorId\":\"37388290\",\"name\":\"M. Hein\",\"url\":\"https://www.semanticscholar.org/author/37388290\"}],\"citationVelocity\":17,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"ING BEYOND\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fac8d2bd19f3a82f92a344d758007cff499b7725\",\"title\":\"CONFIDENCE-CALIBRATED ADVERSARIAL TRAINING and Detection: MORE ROBUST MODELS GENERALIZ-\",\"url\":\"https://www.semanticscholar.org/paper/fac8d2bd19f3a82f92a344d758007cff499b7725\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2004.13002\",\"authors\":[{\"authorId\":\"32007078\",\"name\":\"A. Ghosh\"},{\"authorId\":\"70040213\",\"name\":\"Sankha Subhra Mullick\"},{\"authorId\":\"2165464\",\"name\":\"S. Datta\"},{\"authorId\":\"71658519\",\"name\":\"Swagatam Das\"},{\"authorId\":\"1768588\",\"name\":\"R. Mallipeddi\"},{\"authorId\":\"145222883\",\"name\":\"A. Das\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1429eec87dc5d019834854d2448b8edddddcfe96\",\"title\":\"One Sparse Perturbation to Fool them All, almost Always!\",\"url\":\"https://www.semanticscholar.org/paper/1429eec87dc5d019834854d2448b8edddddcfe96\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.09922\",\"authors\":[{\"authorId\":\"143808176\",\"name\":\"Tao Bai\"},{\"authorId\":\"3619009\",\"name\":\"J. Chen\"},{\"authorId\":\"1390572170\",\"name\":\"Jun Zhao\"},{\"authorId\":\"1766554\",\"name\":\"B. Wen\"},{\"authorId\":\"3307580\",\"name\":\"Xudong Jiang\"},{\"authorId\":\"1711097\",\"name\":\"A. Kot\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f5f7c87661c40b991073def0ab36b1da05a5d244\",\"title\":\"Feature Distillation With Guided Adversarial Contrastive Learning\",\"url\":\"https://www.semanticscholar.org/paper/f5f7c87661c40b991073def0ab36b1da05a5d244\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145177088\",\"name\":\"David Stutz\"},{\"authorId\":\"37388290\",\"name\":\"M. Hein\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"02beef8baeb674c764071cd60da86c4a03f1fa78\",\"title\":\"CONFIDENCE-CALIBRATED ADVERSARIAL TRAINING\",\"url\":\"https://www.semanticscholar.org/paper/02beef8baeb674c764071cd60da86c4a03f1fa78\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2011.11957\",\"authors\":[{\"authorId\":\"1560221518\",\"name\":\"Yingpeng Deng\"},{\"authorId\":\"47209857\",\"name\":\"Lina Karam\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bbe9f46fad17f4c06c56c8da7afbdcb6f642c980\",\"title\":\"Towards Imperceptible Universal Attacks on Texture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/bbe9f46fad17f4c06c56c8da7afbdcb6f642c980\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.12834\",\"authors\":[{\"authorId\":\"39171784\",\"name\":\"F. Croce\"},{\"authorId\":\"47669224\",\"name\":\"Maksym Andriushchenko\"},{\"authorId\":\"150249517\",\"name\":\"N. D. Singh\"},{\"authorId\":\"2874440\",\"name\":\"Nicolas Flammarion\"},{\"authorId\":\"37388290\",\"name\":\"M. Hein\"}],\"doi\":null,\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"5b5a677bf371a4f357bb739bc954d376b41b0c9a\",\"title\":\"Sparse-RS: a versatile framework for query-efficient sparse black-box adversarial attacks\",\"url\":\"https://www.semanticscholar.org/paper/5b5a677bf371a4f357bb739bc954d376b41b0c9a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49411511\",\"name\":\"Yanbo Fan\"},{\"authorId\":\"143905981\",\"name\":\"Baoyuan Wu\"},{\"authorId\":\"150321316\",\"name\":\"T. Li\"},{\"authorId\":\"71848250\",\"name\":\"Yong Zhang\"},{\"authorId\":\"150218408\",\"name\":\"Mingyang Li\"},{\"authorId\":\"1911510\",\"name\":\"Z. Li\"},{\"authorId\":\"3001727\",\"name\":\"Yujiu Yang\"}],\"doi\":\"10.1007/978-3-030-58542-6_3\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"0004e150d93d52624a2caf7a9d37e2be9d4dae3f\",\"title\":\"Sparse Adversarial Attack via Perturbation Factorization\",\"url\":\"https://www.semanticscholar.org/paper/0004e150d93d52624a2caf7a9d37e2be9d4dae3f\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144321761\",\"name\":\"J. Ding\"},{\"authorId\":\"72417719\",\"name\":\"Zhiwu Xu\"}],\"doi\":\"10.1007/978-3-030-60248-2_27\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2251804599995217cb594bed2f2d37e41802f9a6\",\"title\":\"Adversarial Attacks on Deep Learning Models of Computer Vision: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/2251804599995217cb594bed2f2d37e41802f9a6\",\"venue\":\"ICA3PP\",\"year\":2020},{\"arxivId\":\"1812.02737\",\"authors\":[{\"authorId\":\"145607083\",\"name\":\"B. Luo\"},{\"authorId\":\"114684906\",\"name\":\"Min Li\"},{\"authorId\":\"50023961\",\"name\":\"Y. Li\"},{\"authorId\":\"144239164\",\"name\":\"Q. Xu\"}],\"doi\":\"10.1145/3386263.3407601\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"724a82ca338a564c808eda5c606157c56b89be1a\",\"title\":\"On Configurable Defense against Adversarial Example Attacks\",\"url\":\"https://www.semanticscholar.org/paper/724a82ca338a564c808eda5c606157c56b89be1a\",\"venue\":\"ACM Great Lakes Symposium on VLSI\",\"year\":2020},{\"arxivId\":\"2007.01855\",\"authors\":[{\"authorId\":\"145735687\",\"name\":\"Ehsan Kazemi\"},{\"authorId\":\"40900821\",\"name\":\"T. Kerdreux\"},{\"authorId\":\"1390771606\",\"name\":\"Liqiang Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"59e6200bf81fc7765c83b2809d49f99f4e66d3b4\",\"title\":\"Trace-Norm Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/59e6200bf81fc7765c83b2809d49f99f4e66d3b4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145177088\",\"name\":\"David Stutz\"},{\"authorId\":\"2916636\",\"name\":\"N. Chandramoorthy\"},{\"authorId\":\"37388290\",\"name\":\"M. Hein\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a1db46169a8c6ab333ae36d1223c70cc7a1490b3\",\"title\":\"On Mitigating Random and Adversarial Bit Errors\",\"url\":\"https://www.semanticscholar.org/paper/a1db46169a8c6ab333ae36d1223c70cc7a1490b3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.09670\",\"authors\":[{\"authorId\":\"39171784\",\"name\":\"F. Croce\"},{\"authorId\":\"47669224\",\"name\":\"Maksym Andriushchenko\"},{\"authorId\":\"3482535\",\"name\":\"V. Sehwag\"},{\"authorId\":\"2874440\",\"name\":\"Nicolas Flammarion\"},{\"authorId\":\"1864002076\",\"name\":\"Mung Chiang\"},{\"authorId\":\"143615341\",\"name\":\"P. Mittal\"},{\"authorId\":\"37388290\",\"name\":\"M. Hein\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4efc60e1b342f0164db5425076b1bc6196ea8bb5\",\"title\":\"RobustBench: a standardized adversarial robustness benchmark\",\"url\":\"https://www.semanticscholar.org/paper/4efc60e1b342f0164db5425076b1bc6196ea8bb5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.01223\",\"authors\":[{\"authorId\":\"121977751\",\"name\":\"Z. Cong\"},{\"authorId\":\"2074100\",\"name\":\"Lingyang Chu\"},{\"authorId\":\"46286326\",\"name\":\"Y. Yang\"},{\"authorId\":\"1768729587\",\"name\":\"Jian Pei\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4c7a664eaf0793733732ea52d02f3e7d5f4ecd4b\",\"title\":\"Comprehensible Counterfactual Interpretation on Kolmogorov-Smirnov Test\",\"url\":\"https://www.semanticscholar.org/paper/4c7a664eaf0793733732ea52d02f3e7d5f4ecd4b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.12066\",\"authors\":[{\"authorId\":\"46454693\",\"name\":\"Jaeyeon Kim\"},{\"authorId\":\"143807806\",\"name\":\"Binh-Son Hua\"},{\"authorId\":\"1779016\",\"name\":\"D. Nguyen\"},{\"authorId\":\"153147030\",\"name\":\"Sai-Kit Yeung\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"be440591c46630cc18190c2539c07697cbb9b54b\",\"title\":\"Minimal Adversarial Examples for Deep Learning on 3D Point Clouds\",\"url\":\"https://www.semanticscholar.org/paper/be440591c46630cc18190c2539c07697cbb9b54b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.05254\",\"authors\":[{\"authorId\":null,\"name\":\"Yongwei Wang\"},{\"authorId\":\"112912334\",\"name\":\"Mingquan Feng\"},{\"authorId\":\"1484815819\",\"name\":\"R. Ward\"},{\"authorId\":\"38106845\",\"name\":\"Z. Wang\"},{\"authorId\":\"49680751\",\"name\":\"Lanjun Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a17b0280066ae8b632194f7ff44d98028ff60b7d\",\"title\":\"Perception Improvement for Free: Exploring Imperceptible Black-box Adversarial Attacks on Image Classification\",\"url\":\"https://www.semanticscholar.org/paper/a17b0280066ae8b632194f7ff44d98028ff60b7d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.11207\",\"authors\":[{\"authorId\":\"2277275\",\"name\":\"Zhengyu Zhao\"},{\"authorId\":\"1500377626\",\"name\":\"Zhuoran Liu\"},{\"authorId\":\"104810482\",\"name\":\"M. Larson\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"20fa5e2f87864bc4a3bd47386b5635d070bd3ed1\",\"title\":\"On Success and Simplicity: A Second Look at Transferable Targeted Attacks\",\"url\":\"https://www.semanticscholar.org/paper/20fa5e2f87864bc4a3bd47386b5635d070bd3ed1\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2004.04919\",\"authors\":[{\"authorId\":\"1381203703\",\"name\":\"R\\u00e9mi Bernhard\"},{\"authorId\":\"3070099\",\"name\":\"Pierre-Alain Mo\\u00ebllic\"},{\"authorId\":\"2416333\",\"name\":\"J. Dutertre\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"107b033432097b954172c4020a2b694045940ee9\",\"title\":\"Luring of Adversarial Perturbations\",\"url\":\"https://www.semanticscholar.org/paper/107b033432097b954172c4020a2b694045940ee9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.13773\",\"authors\":[{\"authorId\":\"5620602\",\"name\":\"Xiaoyi Dong\"},{\"authorId\":\"47514207\",\"name\":\"Dongdong Chen\"},{\"authorId\":\"9324504\",\"name\":\"Jian-min Bao\"},{\"authorId\":\"1986859645\",\"name\":\"Chuan Qin\"},{\"authorId\":\"145347147\",\"name\":\"Lu Yuan\"},{\"authorId\":\"47528018\",\"name\":\"Weiming Zhang\"},{\"authorId\":\"49191981\",\"name\":\"N. Yu\"},{\"authorId\":\"144230587\",\"name\":\"D. Chen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a7d037abb7285740c58f578ef201eb6bcf18a58\",\"title\":\"GreedyFool: Distortion-Aware Sparse Adversarial Attack\",\"url\":\"https://www.semanticscholar.org/paper/8a7d037abb7285740c58f578ef201eb6bcf18a58\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"1910.06259\",\"authors\":[{\"authorId\":\"145177088\",\"name\":\"David Stutz\"},{\"authorId\":\"37388290\",\"name\":\"M. Hein\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"604dc3c7ad3736e58d7fd8a5839f8d8ba63e63b6\",\"title\":\"Confidence-Calibrated Adversarial Training: Generalizing to Unseen Attacks\",\"url\":\"https://www.semanticscholar.org/paper/604dc3c7ad3736e58d7fd8a5839f8d8ba63e63b6\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":\"2012.15183\",\"authors\":[{\"authorId\":null,\"name\":\"Krishna Kanth Nakka\"},{\"authorId\":null,\"name\":\"Mathieu Salzmann\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d3853a6f2f40e80759140115439180ddd5f70b17\",\"title\":\"Temporally-Transferable Perturbations: Efficient, One-Shot Adversarial Attacks for Online Visual Object Trackers\",\"url\":\"https://www.semanticscholar.org/paper/d3853a6f2f40e80759140115439180ddd5f70b17\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1912.00049\",\"authors\":[{\"authorId\":\"47669224\",\"name\":\"Maksym Andriushchenko\"},{\"authorId\":\"39171784\",\"name\":\"F. Croce\"},{\"authorId\":\"2874440\",\"name\":\"Nicolas Flammarion\"},{\"authorId\":\"37388290\",\"name\":\"M. Hein\"}],\"doi\":\"10.1007/978-3-030-58592-1_29\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8b523ab6093dd513800f1368bfc9bae8a5aabc82\",\"title\":\"Square Attack: a query-efficient black-box adversarial attack via random search\",\"url\":\"https://www.semanticscholar.org/paper/8b523ab6093dd513800f1368bfc9bae8a5aabc82\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2005.02313\",\"authors\":[{\"authorId\":\"40897453\",\"name\":\"Sukrut Rao\"},{\"authorId\":\"145177088\",\"name\":\"David Stutz\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5b7d8bee7f666326925f0933ca5a52b16ba1ff8f\",\"title\":\"Adversarial Training against Location-Optimized Adversarial Patches\",\"url\":\"https://www.semanticscholar.org/paper/5b7d8bee7f666326925f0933ca5a52b16ba1ff8f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.02466\",\"authors\":[{\"authorId\":\"2277275\",\"name\":\"Zhengyu Zhao\"},{\"authorId\":\"2214021\",\"name\":\"Z. Liu\"},{\"authorId\":\"104810482\",\"name\":\"M. Larson\"}],\"doi\":\"10.1109/CVPR42600.2020.00112\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"da531ecc2cd1b6078f91b6ed19ac30d45f9a6af9\",\"title\":\"Towards Large Yet Imperceptible Adversarial Image Perturbations With Perceptual Color Distance\",\"url\":\"https://www.semanticscholar.org/paper/da531ecc2cd1b6078f91b6ed19ac30d45f9a6af9\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3256307\",\"name\":\"M. A. A. K. Jalwana\"},{\"authorId\":\"47398812\",\"name\":\"N. Akhtar\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"}],\"doi\":\"10.1109/cvpr42600.2020.00956\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fb128a1da39e6bdd2a284e18bcdb3f6aafa6f078\",\"title\":\"Attack to Explain Deep Representation\",\"url\":\"https://www.semanticscholar.org/paper/fb128a1da39e6bdd2a284e18bcdb3f6aafa6f078\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2011.06690\",\"authors\":[{\"authorId\":\"2277275\",\"name\":\"Zhengyu Zhao\"},{\"authorId\":\"1500377626\",\"name\":\"Zhuoran Liu\"},{\"authorId\":\"104810482\",\"name\":\"M. Larson\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9bbd3a6940f998adba08099ea913921f9bcac64a\",\"title\":\"Adversarial Robustness Against Image Color Transformation within Parametric Filter Space\",\"url\":\"https://www.semanticscholar.org/paper/9bbd3a6940f998adba08099ea913921f9bcac64a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.10282\",\"authors\":[{\"authorId\":\"3048822\",\"name\":\"Jinyin Chen\"},{\"authorId\":\"72682891\",\"name\":\"Zhen Wang\"},{\"authorId\":\"151500086\",\"name\":\"Haibin Zheng\"},{\"authorId\":\"1384523745\",\"name\":\"Jun Xiao\"},{\"authorId\":\"6485049\",\"name\":\"Zhaoyan Ming\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3eb6164895c9b1cc69413e24172eb8bd53ec2c36\",\"title\":\"ROBY: Evaluating the Robustness of a Deep Model by its Decision Boundaries\",\"url\":\"https://www.semanticscholar.org/paper/3eb6164895c9b1cc69413e24172eb8bd53ec2c36\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2010.07038\",\"authors\":[{\"authorId\":\"119016463\",\"name\":\"David Higgins\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"98fd3987f0089f1e66c2e882d62672cec2d0be04\",\"title\":\"On Regulating AI in Medical Products (OnRAMP).\",\"url\":\"https://www.semanticscholar.org/paper/98fd3987f0089f1e66c2e882d62672cec2d0be04\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2002.01008\",\"authors\":[{\"authorId\":\"2277275\",\"name\":\"Zhengyu Zhao\"},{\"authorId\":\"1500377626\",\"name\":\"Zhuoran Liu\"},{\"authorId\":\"104810482\",\"name\":\"M. Larson\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"56787bb2c773ee8f72f036cba054a6cd268571c4\",\"title\":\"Adversarial Color Enhancement: Generating Unrestricted Adversarial Images by Optimizing a Color Filter\",\"url\":\"https://www.semanticscholar.org/paper/56787bb2c773ee8f72f036cba054a6cd268571c4\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2007.08473\",\"authors\":[{\"authorId\":\"52215534\",\"name\":\"Julian Bitterwolf\"},{\"authorId\":\"38150565\",\"name\":\"Alexander Meinke\"},{\"authorId\":\"37388290\",\"name\":\"M. Hein\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0930f7234a861c34050685070e117c295ebb184a\",\"title\":\"Certifiably Adversarially Robust Detection of Out-of-Distribution Data\",\"url\":\"https://www.semanticscholar.org/paper/0930f7234a861c34050685070e117c295ebb184a\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2002.11293\",\"authors\":[{\"authorId\":\"50504111\",\"name\":\"Mo Zhou\"},{\"authorId\":\"1786361\",\"name\":\"Zhenxing Niu\"},{\"authorId\":\"153755094\",\"name\":\"L. Wang\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"144988570\",\"name\":\"Gang Hua\"}],\"doi\":\"10.1007/978-3-030-58568-6_46\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5384baacb44417974c87db5bc0d2754467b01c7b\",\"title\":\"Adversarial Ranking Attack and Defense\",\"url\":\"https://www.semanticscholar.org/paper/5384baacb44417974c87db5bc0d2754467b01c7b\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52215534\",\"name\":\"Julian Bitterwolf\"},{\"authorId\":\"38150565\",\"name\":\"Alexander Meinke\"},{\"authorId\":\"37388290\",\"name\":\"M. Hein\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b5158c943eda1ba11ea7efe0c09980325ddbb3d2\",\"title\":\"Provable Worst Case Guarantees for the Detection of Out-of-Distribution Data\",\"url\":\"https://www.semanticscholar.org/paper/b5158c943eda1ba11ea7efe0c09980325ddbb3d2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.03843\",\"authors\":[{\"authorId\":\"103655196\",\"name\":\"S. Kumano\"},{\"authorId\":\"7756290\",\"name\":\"H. Kera\"},{\"authorId\":\"145572097\",\"name\":\"T. Yamasaki\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"52f7a1d0f7e81bd52eaf065219c7c03426bb68c1\",\"title\":\"Sparse Fooling Images: Fooling Machine Perception through Unrecognizable Images\",\"url\":\"https://www.semanticscholar.org/paper/52f7a1d0f7e81bd52eaf065219c7c03426bb68c1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.14856\",\"authors\":[{\"authorId\":\"3256307\",\"name\":\"M. A. A. K. Jalwana\"},{\"authorId\":\"47398812\",\"name\":\"N. Akhtar\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"}],\"doi\":\"10.1109/ACCESS.2020.3005961\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"df703f9143e1ac5e3cd26a89e4ea8d6c398a7379\",\"title\":\"Orthogonal Deep Models as Defense Against Black-Box Attacks\",\"url\":\"https://www.semanticscholar.org/paper/df703f9143e1ac5e3cd26a89e4ea8d6c398a7379\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2006.13977\",\"authors\":[{\"authorId\":\"145177088\",\"name\":\"David Stutz\"},{\"authorId\":\"2916636\",\"name\":\"N. Chandramoorthy\"},{\"authorId\":\"37388290\",\"name\":\"M. Hein\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"cf4d01f6db964cf9101702a32ca8db1b9b2b06d0\",\"title\":\"Bit Error Robustness for Energy-Efficient DNN Accelerators\",\"url\":\"https://www.semanticscholar.org/paper/cf4d01f6db964cf9101702a32ca8db1b9b2b06d0\",\"venue\":\"\",\"year\":2020}],\"corpusId\":202558502,\"doi\":\"10.1109/ICCV.2019.00482\",\"fieldsOfStudy\":[\"Computer Science\",\"Mathematics\"],\"influentialCitationCount\":4,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"e8c46dade1aaedce96ecd03178379b5921a90306\",\"references\":[{\"arxivId\":\"1707.04131\",\"authors\":[{\"authorId\":\"19237612\",\"name\":\"Jonas Rauber\"},{\"authorId\":\"40634590\",\"name\":\"W. Brendel\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8023b835934e8c2ccfe068d59d6c319bb8a1c293\",\"title\":\"Foolbox v0.8.0: A Python toolbox to benchmark the robustness of machine learning models\",\"url\":\"https://www.semanticscholar.org/paper/8023b835934e8c2ccfe068d59d6c319bb8a1c293\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1804.08598\",\"authors\":[{\"authorId\":\"34562927\",\"name\":\"Andrew Ilyas\"},{\"authorId\":\"39468283\",\"name\":\"L. Engstrom\"},{\"authorId\":\"38939786\",\"name\":\"Anish Athalye\"},{\"authorId\":\"32815692\",\"name\":\"Jessy Lin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b3f83e8416010e9c3a705a0b6390d268e5ddf5c0\",\"title\":\"Black-box Adversarial Attacks with Limited Queries and Information\",\"url\":\"https://www.semanticscholar.org/paper/b3f83e8416010e9c3a705a0b6390d268e5ddf5c0\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10754103\",\"name\":\"A. Bhagoji\"},{\"authorId\":\"145551594\",\"name\":\"Warren He\"},{\"authorId\":\"143771567\",\"name\":\"Bo Li\"},{\"authorId\":\"143711382\",\"name\":\"D. Song\"}],\"doi\":\"10.1007/978-3-030-01258-8_10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9e6671270fa329fab2f9e837d3da65f3e0fb905b\",\"title\":\"Practical Black-Box Attacks on Deep Neural Networks Using Efficient Query Mechanisms\",\"url\":\"https://www.semanticscholar.org/paper/9e6671270fa329fab2f9e837d3da65f3e0fb905b\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3021654\",\"name\":\"Daniel Lowd\"},{\"authorId\":\"50004012\",\"name\":\"Christopher Meek\"}],\"doi\":\"10.1145/1081870.1081950\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"165e4c6467eeae8974739a731045bdff07d906fc\",\"title\":\"Adversarial learning\",\"url\":\"https://www.semanticscholar.org/paper/165e4c6467eeae8974739a731045bdff07d906fc\",\"venue\":\"KDD '05\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Li-Jia Li\"},{\"authorId\":null,\"name\":\"Kehui Li\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\", Mausam , Sumit K . Sanghai , and Deepak Verma . Adversarial classification\",\"url\":\"\",\"venue\":\"\",\"year\":2004},{\"arxivId\":\"1801.04693\",\"authors\":[{\"authorId\":\"145607083\",\"name\":\"B. Luo\"},{\"authorId\":\"2146767\",\"name\":\"Y. Liu\"},{\"authorId\":\"2337781\",\"name\":\"Lingxiao Wei\"},{\"authorId\":\"144239164\",\"name\":\"Q. Xu\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"516afc7d5a427f0b53ca459fe2624a1aae2ee00d\",\"title\":\"Towards Imperceptible and Robust Adversarial Example Attacks against Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/516afc7d5a427f0b53ca459fe2624a1aae2ee00d\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"134861178\",\"name\":\"Wei Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPRW.2009.5206848\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d2c733e34d48784a37d717fe43d9e93277a8c53e\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/d2c733e34d48784a37d717fe43d9e93277a8c53e\",\"venue\":\"2009 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2009},{\"arxivId\":\"1706.06083\",\"authors\":[{\"authorId\":\"143826246\",\"name\":\"A. Madry\"},{\"authorId\":\"17775913\",\"name\":\"Aleksandar Makelov\"},{\"authorId\":\"33404869\",\"name\":\"L. Schmidt\"},{\"authorId\":\"2754804\",\"name\":\"D. Tsipras\"},{\"authorId\":\"2869958\",\"name\":\"Adrian Vladu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"7aa38b85fa8cba64d6a4010543f6695dbf5f1386\",\"title\":\"Towards Deep Learning Models Resistant to Adversarial Attacks\",\"url\":\"https://www.semanticscholar.org/paper/7aa38b85fa8cba64d6a4010543f6695dbf5f1386\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1825256\",\"name\":\"Kevin Eykholt\"},{\"authorId\":\"22229139\",\"name\":\"Ivan Evtimov\"},{\"authorId\":\"35064352\",\"name\":\"E. Fernandes\"},{\"authorId\":\"143771567\",\"name\":\"Bo Li\"},{\"authorId\":\"145416145\",\"name\":\"A. Rahmati\"},{\"authorId\":\"2723309\",\"name\":\"Chaowei Xiao\"},{\"authorId\":\"49428285\",\"name\":\"Atul Prakash\"},{\"authorId\":\"1769675\",\"name\":\"T. Kohno\"},{\"authorId\":\"143711382\",\"name\":\"D. Song\"}],\"doi\":\"10.1109/CVPR.2018.00175\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f0c5991dbb130fa6b5de011cf7a04f6ed815ef68\",\"title\":\"Robust Physical-World Attacks on Deep Learning Visual Classification\",\"url\":\"https://www.semanticscholar.org/paper/f0c5991dbb130fa6b5de011cf7a04f6ed815ef68\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1811.11493\",\"authors\":[{\"authorId\":\"145342730\",\"name\":\"F. Croce\"},{\"authorId\":\"143610806\",\"name\":\"M. Hein\"}],\"doi\":\"10.1007/978-3-030-12939-2_16\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"12b6a7eb4014338fba3edef956be32775d271c78\",\"title\":\"A randomized gradient-free attack on ReLU networks\",\"url\":\"https://www.semanticscholar.org/paper/12b6a7eb4014338fba3edef956be32775d271c78\",\"venue\":\"GCPR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Nicolas Papernot\"},{\"authorId\":null,\"name\":\"Fartash Faghri\"},{\"authorId\":null,\"name\":\"Nicholas Carlini\"},{\"authorId\":null,\"name\":\"Ian Goodfellow\"},{\"authorId\":null,\"name\":\"Reuben Feinman\"},{\"authorId\":null,\"name\":\"Alexey Kurakin\"},{\"authorId\":null,\"name\":\"Cihang Xie\"},{\"authorId\":null,\"name\":\"Yash Sharma\"},{\"authorId\":null,\"name\":\"Tom Brown\"},{\"authorId\":null,\"name\":\"Aurko Roy\"},{\"authorId\":null,\"name\":\"Alexander Matyasko\"},{\"authorId\":null,\"name\":\"Vahid Behzadan\"},{\"authorId\":null,\"name\":\"Karen Hambardzumyan\"},{\"authorId\":null,\"name\":\"Zhishuai Zhang\"},{\"authorId\":null,\"name\":\"Yi-Lin Juang\"},{\"authorId\":null,\"name\":\"Zhi Li\"},{\"authorId\":null,\"name\":\"Ryan Sheatsley\"},{\"authorId\":null,\"name\":\"Abhibhav Garg\"},{\"authorId\":null,\"name\":\"Jonathan Uesato\"},{\"authorId\":null,\"name\":\"Willi Gierke\"},{\"authorId\":null,\"name\":\"Yinpeng Dong\"},{\"authorId\":null,\"name\":\"David Berthelot\"},{\"authorId\":null,\"name\":\"Paul Hendricks\"},{\"authorId\":null,\"name\":\"Jonas Rauber\"},{\"authorId\":null,\"name\":\"Rujun Long\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"cleverhans v2.0.0: an adversarial machine learning\",\"url\":\"\",\"venue\":\"library. preprint,\",\"year\":2017},{\"arxivId\":\"1805.12152\",\"authors\":[{\"authorId\":\"2754804\",\"name\":\"D. Tsipras\"},{\"authorId\":\"2852106\",\"name\":\"Shibani Santurkar\"},{\"authorId\":\"39468283\",\"name\":\"L. Engstrom\"},{\"authorId\":\"152866449\",\"name\":\"A. Turner\"},{\"authorId\":\"143826246\",\"name\":\"A. Madry\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1b9c6022598085dd892f360122c0fa4c630b3f18\",\"title\":\"Robustness May Be at Odds with Accuracy\",\"url\":\"https://www.semanticscholar.org/paper/1b9c6022598085dd892f360122c0fa4c630b3f18\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1708.03999\",\"authors\":[{\"authorId\":\"153191489\",\"name\":\"P. Chen\"},{\"authorId\":\"49723481\",\"name\":\"Huan Zhang\"},{\"authorId\":\"49738125\",\"name\":\"Yash Sharma\"},{\"authorId\":\"2882166\",\"name\":\"Jinfeng Yi\"},{\"authorId\":\"1793529\",\"name\":\"C. Hsieh\"}],\"doi\":\"10.1145/3128572.3140448\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9ab7319dbe80549ba80e3320d0546d741a7a5791\",\"title\":\"ZOO: Zeroth Order Optimization Based Black-box Attacks to Deep Neural Networks without Training Substitute Models\",\"url\":\"https://www.semanticscholar.org/paper/9ab7319dbe80549ba80e3320d0546d741a7a5791\",\"venue\":\"AISec@CCS\",\"year\":2017},{\"arxivId\":\"1611.02770\",\"authors\":[{\"authorId\":\"1887192\",\"name\":\"Y. Liu\"},{\"authorId\":\"2727656\",\"name\":\"X. Chen\"},{\"authorId\":null,\"name\":\"Chang Liu\"},{\"authorId\":\"143711382\",\"name\":\"D. Song\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"99e5a8c10cf92749d4a7c2949691c3a6046e499a\",\"title\":\"Delving into Transferable Adversarial Examples and Black-box Attacks\",\"url\":\"https://www.semanticscholar.org/paper/99e5a8c10cf92749d4a7c2949691c3a6046e499a\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1412.6572\",\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1789737\",\"name\":\"Jonathon Shlens\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bee044c8e8903fb67523c1f8c105ab4718600cdb\",\"title\":\"Explaining and Harnessing Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/bee044c8e8903fb67523c1f8c105ab4718600cdb\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1708.06131\",\"authors\":[{\"authorId\":\"1684175\",\"name\":\"B. Biggio\"},{\"authorId\":\"2338858\",\"name\":\"I. Corona\"},{\"authorId\":\"3248803\",\"name\":\"Davide Maiorca\"},{\"authorId\":\"39743720\",\"name\":\"B. Nelson\"},{\"authorId\":\"2118348\",\"name\":\"Nedim Srndic\"},{\"authorId\":\"1754215\",\"name\":\"P. Laskov\"},{\"authorId\":\"1779484\",\"name\":\"G. Giacinto\"},{\"authorId\":\"1710171\",\"name\":\"F. Roli\"}],\"doi\":\"10.1007/978-3-642-40994-3_25\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"033c08ca48aaed2d5ab0a17d668d410538678ed8\",\"title\":\"Evasion Attacks against Machine Learning at Test Time\",\"url\":\"https://www.semanticscholar.org/paper/033c08ca48aaed2d5ab0a17d668d410538678ed8\",\"venue\":\"ECML/PKDD\",\"year\":2013},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19237612\",\"name\":\"Jonas Rauber\"},{\"authorId\":\"40634590\",\"name\":\"W. Brendel\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"59d9318f07331ec15e54fe2a4218bc4a5c247a38\",\"title\":\"Foolbox: A Python toolbox to benchmark the robustness of machine learning models\",\"url\":\"https://www.semanticscholar.org/paper/59d9318f07331ec15e54fe2a4218bc4a5c247a38\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1705.07263\",\"authors\":[{\"authorId\":\"39907737\",\"name\":\"N. Carlini\"},{\"authorId\":\"40429990\",\"name\":\"D. Wagner\"}],\"doi\":\"10.1145/3128572.3140444\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"99cb08c76c120599abd1d1637e32aaf577f38d39\",\"title\":\"Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods\",\"url\":\"https://www.semanticscholar.org/paper/99cb08c76c120599abd1d1637e32aaf577f38d39\",\"venue\":\"AISec@CCS\",\"year\":2017},{\"arxivId\":\"1312.6199\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"2563432\",\"name\":\"W. Zaremba\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"143627859\",\"name\":\"Joan Bruna\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d891dc72cbd40ffaeefdc79f2e7afe1e530a23ad\",\"title\":\"Intriguing properties of neural networks\",\"url\":\"https://www.semanticscholar.org/paper/d891dc72cbd40ffaeefdc79f2e7afe1e530a23ad\",\"venue\":\"ICLR\",\"year\":2014},{\"arxivId\":\"1710.08864\",\"authors\":[{\"authorId\":\"1730754\",\"name\":\"Jiawei Su\"},{\"authorId\":\"145197293\",\"name\":\"Danilo Vasconcellos Vargas\"},{\"authorId\":\"145106127\",\"name\":\"K. Sakurai\"}],\"doi\":\"10.1109/TEVC.2019.2890858\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6f835ca6e12245a835ab6074bc6ec2c3c60b85a\",\"title\":\"One Pixel Attack for Fooling Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/a6f835ca6e12245a835ab6074bc6ec2c3c60b85a\",\"venue\":\"IEEE Transactions on Evolutionary Computation\",\"year\":2019},{\"arxivId\":\"1711.09115\",\"authors\":[{\"authorId\":\"30017654\",\"name\":\"Can Kanbak\"},{\"authorId\":\"1403182206\",\"name\":\"Seyed-Mohsen Moosavi-Dezfooli\"},{\"authorId\":\"48036489\",\"name\":\"P. Frossard\"}],\"doi\":\"10.1109/CVPR.2018.00467\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"47eb8d7ea4f7c209040ddd82e264edf3945df6cb\",\"title\":\"Geometric Robustness of Deep Networks: Analysis and Improvement\",\"url\":\"https://www.semanticscholar.org/paper/47eb8d7ea4f7c209040ddd82e264edf3945df6cb\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1608.04644\",\"authors\":[{\"authorId\":\"2483738\",\"name\":\"Nicholas Carlini\"},{\"authorId\":\"145394689\",\"name\":\"D. Wagner\"}],\"doi\":\"10.1109/SP.2017.49\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"df40ce107a71b770c9d0354b78fdd8989da80d2f\",\"title\":\"Towards Evaluating the Robustness of Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/df40ce107a71b770c9d0354b78fdd8989da80d2f\",\"venue\":\"2017 IEEE Symposium on Security and Privacy (SP)\",\"year\":2017},{\"arxivId\":\"1511.07528\",\"authors\":[{\"authorId\":\"1967156\",\"name\":\"Nicolas Papernot\"},{\"authorId\":\"144061974\",\"name\":\"P. McDaniel\"},{\"authorId\":\"1680133\",\"name\":\"S. Jha\"},{\"authorId\":\"2623167\",\"name\":\"Matt Fredrikson\"},{\"authorId\":\"144643812\",\"name\":\"Z. Y. Celik\"},{\"authorId\":\"144231976\",\"name\":\"A. Swami\"}],\"doi\":\"10.1109/EuroSP.2016.36\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"819167ace2f0caae7745d2f25a803979be5fbfae\",\"title\":\"The Limitations of Deep Learning in Adversarial Settings\",\"url\":\"https://www.semanticscholar.org/paper/819167ace2f0caae7745d2f25a803979be5fbfae\",\"venue\":\"2016 IEEE European Symposium on Security and Privacy (EuroS&P)\",\"year\":2016},{\"arxivId\":\"1511.04599\",\"authors\":[{\"authorId\":\"1403182206\",\"name\":\"Seyed-Mohsen Moosavi-Dezfooli\"},{\"authorId\":\"33054064\",\"name\":\"Alhussein Fawzi\"},{\"authorId\":\"48036489\",\"name\":\"P. Frossard\"}],\"doi\":\"10.1109/CVPR.2016.282\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35\",\"title\":\"DeepFool: A Simple and Accurate Method to Fool Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Nilesh N. Dalvi\"},{\"authorId\":null,\"name\":\"Pedro M. Domingos\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\", Mausam , Sumit K . Sanghai , and Deepak Verma . Adversarial classification\",\"url\":\"\",\"venue\":\"In GCPR\",\"year\":2004},{\"arxivId\":\"1802.00420\",\"authors\":[{\"authorId\":\"38939786\",\"name\":\"Anish Athalye\"},{\"authorId\":\"2483738\",\"name\":\"Nicholas Carlini\"},{\"authorId\":\"145394689\",\"name\":\"D. Wagner\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"651adaa058f821a890f2c5d1053d69eb481a8352\",\"title\":\"Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/651adaa058f821a890f2c5d1053d69eb481a8352\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1923209\",\"name\":\"Nilesh N. Dalvi\"},{\"authorId\":\"1740213\",\"name\":\"Pedro M. Domingos\"},{\"authorId\":\"2674444\",\"name\":\"Mausam\"},{\"authorId\":\"2411435\",\"name\":\"Sumit K. Sanghai\"},{\"authorId\":\"144130626\",\"name\":\"D. Verma\"}],\"doi\":\"10.1145/1014052.1014066\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d94f56e7ef07b6e785b830e41da30c257b9a6ece\",\"title\":\"Adversarial classification\",\"url\":\"https://www.semanticscholar.org/paper/d94f56e7ef07b6e785b830e41da30c257b9a6ece\",\"venue\":\"KDD '04\",\"year\":2004},{\"arxivId\":\"1801.02612\",\"authors\":[{\"authorId\":\"2723309\",\"name\":\"Chaowei Xiao\"},{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"143771567\",\"name\":\"Bo Li\"},{\"authorId\":\"145551594\",\"name\":\"Warren He\"},{\"authorId\":\"39037167\",\"name\":\"M. Liu\"},{\"authorId\":\"143711382\",\"name\":\"D. Song\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d3c071dbbb4520ed5875f7e064a9da87240534db\",\"title\":\"Spatially Transformed Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/d3c071dbbb4520ed5875f7e064a9da87240534db\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1811.02248\",\"authors\":[{\"authorId\":\"2618576\",\"name\":\"A. Modas\"},{\"authorId\":\"1403182206\",\"name\":\"Seyed-Mohsen Moosavi-Dezfooli\"},{\"authorId\":\"48036489\",\"name\":\"P. Frossard\"}],\"doi\":\"10.1109/CVPR.2019.00930\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8bf18d546ae7aea144663136c5704049953ce4e2\",\"title\":\"SparseFool: A Few Pixels Make a Big Difference\",\"url\":\"https://www.semanticscholar.org/paper/8bf18d546ae7aea144663136c5704049953ce4e2\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1312.4400\",\"authors\":[{\"authorId\":\"143953684\",\"name\":\"M. Lin\"},{\"authorId\":\"35370244\",\"name\":\"Q. Chen\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5e83ab70d0cbc003471e87ec306d27d9c80ecb16\",\"title\":\"Network In Network\",\"url\":\"https://www.semanticscholar.org/paper/5e83ab70d0cbc003471e87ec306d27d9c80ecb16\",\"venue\":\"ICLR\",\"year\":2014},{\"arxivId\":\"1612.06299\",\"authors\":[{\"authorId\":\"2701535\",\"name\":\"Nina Narodytska\"},{\"authorId\":\"7993151\",\"name\":\"S. Kasiviswanathan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2a76bf5895759af6a561d81a0e2960cd00f1167e\",\"title\":\"Simple Black-Box Adversarial Perturbations for Deep Networks\",\"url\":\"https://www.semanticscholar.org/paper/2a76bf5895759af6a561d81a0e2960cd00f1167e\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Huichen Lihuichen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4535ecaf37ffc80ef4fe05561c034880388343d0\",\"title\":\"Decision-Based Adversarial Attacks : Reliable Attacks Against Black-box Machine Learning Models\",\"url\":\"https://www.semanticscholar.org/paper/4535ecaf37ffc80ef4fe05561c034880388343d0\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1805.09190\",\"authors\":[{\"authorId\":\"36873987\",\"name\":\"Lukas Schott\"},{\"authorId\":\"19237612\",\"name\":\"Jonas Rauber\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"},{\"authorId\":\"40634590\",\"name\":\"W. Brendel\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fd7789de401811fd8692466b8d49230e7184655f\",\"title\":\"Towards the first adversarially robust neural network model on MNIST\",\"url\":\"https://www.semanticscholar.org/paper/fd7789de401811fd8692466b8d49230e7184655f\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1607.02533\",\"authors\":[{\"authorId\":\"145714153\",\"name\":\"A. Kurakin\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"}],\"doi\":\"10.1201/9781351251389-8\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b544ca32b66b4c9c69bcfa00d63ee4b799d8ab6b\",\"title\":\"Adversarial examples in the physical world\",\"url\":\"https://www.semanticscholar.org/paper/b544ca32b66b4c9c69bcfa00d63ee4b799d8ab6b\",\"venue\":\"ICLR\",\"year\":2017}],\"title\":\"Sparse and Imperceivable Adversarial Attacks\",\"topics\":[{\"topic\":\"Sparse matrix\",\"topicId\":\"126\",\"url\":\"https://www.semanticscholar.org/topic/126\"},{\"topic\":\"Adversary (cryptography)\",\"topicId\":\"5369\",\"url\":\"https://www.semanticscholar.org/topic/5369\"},{\"topic\":\"Gradient descent\",\"topicId\":\"24880\",\"url\":\"https://www.semanticscholar.org/topic/24880\"},{\"topic\":\"Pixel\",\"topicId\":\"4254\",\"url\":\"https://www.semanticscholar.org/topic/4254\"},{\"topic\":\"Black box\",\"topicId\":\"16977\",\"url\":\"https://www.semanticscholar.org/topic/16977\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Apache Axis\",\"topicId\":\"24270\",\"url\":\"https://www.semanticscholar.org/topic/24270\"},{\"topic\":\"Perturbation function\",\"topicId\":\"775052\",\"url\":\"https://www.semanticscholar.org/topic/775052\"},{\"topic\":\"Neural Networks\",\"topicId\":\"99954\",\"url\":\"https://www.semanticscholar.org/topic/99954\"}],\"url\":\"https://www.semanticscholar.org/paper/e8c46dade1aaedce96ecd03178379b5921a90306\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019}\n"