"{\"abstract\":\"We present a new large-scale multilingual video description dataset, VATEX, which contains over 41,250 videos and 825,000 captions in both English and Chinese. Among the captions, there are over 206,000 English-Chinese parallel translation pairs. Compared to the widely-used MSR-VTT dataset, \\\\vatex is multilingual, larger, linguistically complex, and more diverse in terms of both video and natural language descriptions. We also introduce two tasks for video-and-language research based on \\\\vatex: (1) Multilingual Video Captioning, aimed at describing a video in various languages with a compact unified captioning model, and (2) Video-guided Machine Translation, to translate a source language description into the target language using the video information as additional spatiotemporal context. Extensive experiments on the \\\\vatex dataset show that, first, the unified multilingual model can not only produce both English and Chinese descriptions for a video more efficiently, but also offer improved performance over the monolingual models. Furthermore, we demonstrate that the spatiotemporal video context can be effectively utilized to align source and target languages and thus assist machine translation. In the end, we discuss the potentials of using \\\\vatex for other video-and-language research.\",\"arxivId\":\"1904.03493\",\"authors\":[{\"authorId\":\"48631993\",\"name\":\"Xin Eric Wang\",\"url\":\"https://www.semanticscholar.org/author/48631993\"},{\"authorId\":\"46365930\",\"name\":\"Jiawei Wu\",\"url\":\"https://www.semanticscholar.org/author/46365930\"},{\"authorId\":\"47739808\",\"name\":\"Junkun Chen\",\"url\":\"https://www.semanticscholar.org/author/47739808\"},{\"authorId\":\"46255707\",\"name\":\"Lei Li\",\"url\":\"https://www.semanticscholar.org/author/46255707\"},{\"authorId\":\"1706938\",\"name\":\"Y. Wang\",\"url\":\"https://www.semanticscholar.org/author/1706938\"},{\"authorId\":\"1682479\",\"name\":\"William Yang Wang\",\"url\":\"https://www.semanticscholar.org/author/1682479\"}],\"citationVelocity\":24,\"citations\":[{\"arxivId\":\"2012.04925\",\"authors\":[{\"authorId\":\"30894109\",\"name\":\"A. Chen\"},{\"authorId\":\"49444758\",\"name\":\"Xinyi Huang\"},{\"authorId\":\"15385188\",\"name\":\"Hailan Lin\"},{\"authorId\":\"9931285\",\"name\":\"Xirong Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"f4079b8d38e085386609b82b6bf8ab43d1fab13e\",\"title\":\"Towards Annotation-Free Evaluation of Cross-Lingual Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/f4079b8d38e085386609b82b6bf8ab43d1fab13e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2006.04058\",\"authors\":[{\"authorId\":\"48775710\",\"name\":\"Alok Singh\"},{\"authorId\":\"2305086\",\"name\":\"Thoudam Doren Singh\"},{\"authorId\":\"1722399\",\"name\":\"Sivaji Bandyopadhyay\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"098317f445d4753188658ebd3a72c272d10132cd\",\"title\":\"NITS-VC System for VATEX Video Captioning Challenge 2020\",\"url\":\"https://www.semanticscholar.org/paper/098317f445d4753188658ebd3a72c272d10132cd\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.07098\",\"authors\":[{\"authorId\":\"28282293\",\"name\":\"Begum Citamak\"},{\"authorId\":\"10791325\",\"name\":\"Ozan Caglayan\"},{\"authorId\":\"51214846\",\"name\":\"Menekse Kuyu\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"},{\"authorId\":\"152827782\",\"name\":\"Aykut Erdem\"},{\"authorId\":\"144695472\",\"name\":\"P. Madhyastha\"},{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c2557b1a45412e1100d40ec1fe4073c3b00921f6\",\"title\":\"MSVD-Turkish: A Comprehensive Multimodal Dataset for Integrated Vision and Language Research in Turkish\",\"url\":\"https://www.semanticscholar.org/paper/c2557b1a45412e1100d40ec1fe4073c3b00921f6\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2012.00366\",\"authors\":[{\"authorId\":\"9610143\",\"name\":\"Zhihao Fan\"},{\"authorId\":\"2171182\",\"name\":\"Yeyun Gong\"},{\"authorId\":\"2712533\",\"name\":\"Zhongyu Wei\"},{\"authorId\":\"50695377\",\"name\":\"Siyuan Wang\"},{\"authorId\":\"121240634\",\"name\":\"Yameng Huang\"},{\"authorId\":\"49097406\",\"name\":\"Jian Jiao\"},{\"authorId\":\"144052385\",\"name\":\"X. Huang\"},{\"authorId\":\"46429989\",\"name\":\"N. Duan\"},{\"authorId\":\"2027657172\",\"name\":\"Ruofei Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"023b508aca0e776f6face93548fedb8921cf35ab\",\"title\":\"An Enhanced Knowledge Injection Model for Commonsense Generation\",\"url\":\"https://www.semanticscholar.org/paper/023b508aca0e776f6face93548fedb8921cf35ab\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":\"2010.03644\",\"authors\":[{\"authorId\":\"51439692\",\"name\":\"Wanrong Zhu\"},{\"authorId\":\"47120131\",\"name\":\"X. Wang\"},{\"authorId\":\"145382418\",\"name\":\"P. Narayana\"},{\"authorId\":\"113477341\",\"name\":\"Kazoo Sone\"},{\"authorId\":\"40632403\",\"name\":\"S. Basu\"},{\"authorId\":\"1682479\",\"name\":\"William Yang Wang\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.708\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1e1b42c2dccb19d9ac441a3c0e62d2d21e3bd198\",\"title\":\"Towards Understanding Sample Variance in Visually Grounded Language Generation: Evaluations and Observations\",\"url\":\"https://www.semanticscholar.org/paper/1e1b42c2dccb19d9ac441a3c0e62d2d21e3bd198\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"1911.03705\",\"authors\":[{\"authorId\":\"51583409\",\"name\":\"Bill Yuchen Lin\"},{\"authorId\":\"153150499\",\"name\":\"Ming Shen\"},{\"authorId\":\"97953933\",\"name\":\"Y. Xing\"},{\"authorId\":\"144032123\",\"name\":\"P. Zhou\"},{\"authorId\":\"145201126\",\"name\":\"X. Ren\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"727c9d3846ebd80a9138d0e6c9e995d9afc1d312\",\"title\":\"CommonGen: A Constrained Text Generation Dataset Towards Generative Commonsense Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/727c9d3846ebd80a9138d0e6c9e995d9afc1d312\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2010.02824\",\"authors\":[{\"authorId\":\"1379929116\",\"name\":\"Mandela Patrick\"},{\"authorId\":\"2319973\",\"name\":\"Po-Yao Huang\"},{\"authorId\":\"144721617\",\"name\":\"Y. Asano\"},{\"authorId\":\"2048745\",\"name\":\"F. Metze\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"},{\"authorId\":\"145414740\",\"name\":\"J. Henriques\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"78bc767ebd02c0cc690fdb334c37bf64cfaf0115\",\"title\":\"Support-set bottlenecks for video-text representation learning\",\"url\":\"https://www.semanticscholar.org/paper/78bc767ebd02c0cc690fdb334c37bf64cfaf0115\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1910.05752\",\"authors\":[{\"authorId\":\"36811682\",\"name\":\"Z. Zhang\"},{\"authorId\":\"37198550\",\"name\":\"Yaya Shi\"},{\"authorId\":\"1387518609\",\"name\":\"Jiutong Wei\"},{\"authorId\":null,\"name\":\"Chunfeng Yuan\"},{\"authorId\":\"122094546\",\"name\":\"B. Li\"},{\"authorId\":\"40506509\",\"name\":\"W. Hu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"9dab1068a6e9f4696ea3687baf04f9098107c1f7\",\"title\":\"VATEX Captioning Challenge 2019: Multi-modal Information Fusion and Multi-stage Training Strategy for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9dab1068a6e9f4696ea3687baf04f9098107c1f7\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40280182\",\"name\":\"Yuqing Song\"},{\"authorId\":\"50976845\",\"name\":\"Yida Zhao\"},{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1de16ce45d9dbfa315f44136923b90b4d37ff0f0\",\"title\":\"RUC_AIM3 at TRECVID 2019: Video to Text\",\"url\":\"https://www.semanticscholar.org/paper/1de16ce45d9dbfa315f44136923b90b4d37ff0f0\",\"venue\":\"TRECVID\",\"year\":2019},{\"arxivId\":\"2008.06880\",\"authors\":[{\"authorId\":\"1739188006\",\"name\":\"Sheng-Yu Zhang\"},{\"authorId\":\"3856602\",\"name\":\"Ziqi Tan\"},{\"authorId\":\"144644708\",\"name\":\"Jin Yu\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"33870528\",\"name\":\"Kun Kuang\"},{\"authorId\":null,\"name\":\"Jie Liu\"},{\"authorId\":\"1726030259\",\"name\":\"Jingren Zhou\"},{\"authorId\":\"1712223662\",\"name\":\"Hongxia Yang\"},{\"authorId\":\"144894837\",\"name\":\"F. Wu\"}],\"doi\":\"10.1145/3394171.3413880\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"72ca5f49b67f0e57e1f213323ff5d884e91ee824\",\"title\":\"Poet: Product-oriented Video Captioner for E-commerce\",\"url\":\"https://www.semanticscholar.org/paper/72ca5f49b67f0e57e1f213323ff5d884e91ee824\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2005.00683\",\"authors\":[{\"authorId\":\"51583409\",\"name\":\"Bill Yuchen Lin\"},{\"authorId\":\"145213015\",\"name\":\"S. Lee\"},{\"authorId\":\"1885282\",\"name\":\"Rahul Khanna\"},{\"authorId\":\"1384550891\",\"name\":\"X. Ren\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.557\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"848f8e921fd3d84b7d6354cdfdcc8bc2aa6ecd51\",\"title\":\"Birds have four legs?! NumerSense: Probing Numerical Commonsense Knowledge of Pre-trained Language Models\",\"url\":\"https://www.semanticscholar.org/paper/848f8e921fd3d84b7d6354cdfdcc8bc2aa6ecd51\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"1910.06737\",\"authors\":[{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"50976845\",\"name\":\"Yida Zhao\"},{\"authorId\":\"40280182\",\"name\":\"Yuqing Song\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"},{\"authorId\":\"34902783\",\"name\":\"Qi Wu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ac87d8ef6da4be7d7822053355c0528c58d8ddf5\",\"title\":\"Integrating Temporal and Spatial Attentions for VATEX Video Captioning Challenge 2019\",\"url\":\"https://www.semanticscholar.org/paper/ac87d8ef6da4be7d7822053355c0528c58d8ddf5\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1910.11301\",\"authors\":[{\"authorId\":\"47837986\",\"name\":\"An Yan\"},{\"authorId\":\"72541452\",\"name\":\"X. Wang\"},{\"authorId\":\"2093485\",\"name\":\"Jiangtao Feng\"},{\"authorId\":null,\"name\":\"Lei Li\"},{\"authorId\":\"1682479\",\"name\":\"William Yang Wang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2a273479d5ede7a27cf144a18cfbf0542b92fa12\",\"title\":\"Cross-Lingual Vision-Language Navigation\",\"url\":\"https://www.semanticscholar.org/paper/2a273479d5ede7a27cf144a18cfbf0542b92fa12\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2002.11566\",\"authors\":[{\"authorId\":\"36811682\",\"name\":\"Z. Zhang\"},{\"authorId\":\"37198550\",\"name\":\"Yaya Shi\"},{\"authorId\":null,\"name\":\"Chunfeng Yuan\"},{\"authorId\":null,\"name\":\"Bing Li\"},{\"authorId\":\"39397292\",\"name\":\"Peijin Wang\"},{\"authorId\":\"48594951\",\"name\":\"Weiming Hu\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"}],\"doi\":\"10.1109/cvpr42600.2020.01329\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f1dd557a8839733a5ee06d19989a265e61f603c1\",\"title\":\"Object Relational Graph With Teacher-Recommended Learning for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/f1dd557a8839733a5ee06d19989a265e61f603c1\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"70026472\",\"name\":\"T. Yu\"},{\"authorId\":\"6470580\",\"name\":\"Y. Yang\"},{\"authorId\":\"47002715\",\"name\":\"Y. Li\"},{\"authorId\":\"49794949\",\"name\":\"Xiaodong Chen\"},{\"authorId\":\"1893044063\",\"name\":\"Mingming Sun\"},{\"authorId\":\"144785135\",\"name\":\"P. Li\"}],\"doi\":\"10.1145/3394486.3403297\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"8a1d603b0860ca5a27a2813be1e0a0d1277fa44a\",\"title\":\"Combo-Attention Network for Baidu Video Advertising\",\"url\":\"https://www.semanticscholar.org/paper/8a1d603b0860ca5a27a2813be1e0a0d1277fa44a\",\"venue\":\"KDD\",\"year\":2020},{\"arxivId\":\"2005.05402\",\"authors\":[{\"authorId\":\"46665218\",\"name\":\"Jie Lei\"},{\"authorId\":\"145602574\",\"name\":\"L. Wang\"},{\"authorId\":\"1752875\",\"name\":\"Y. Shen\"},{\"authorId\":\"144580027\",\"name\":\"Dong Yu\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"143977266\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/2020.acl-main.233\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"70557ea6b65846fc30729ceed224acd4ac64ca5d\",\"title\":\"MART: Memory-Augmented Recurrent Transformer for Coherent Video Paragraph Captioning\",\"url\":\"https://www.semanticscholar.org/paper/70557ea6b65846fc30729ceed224acd4ac64ca5d\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"2003.08897\",\"authors\":[{\"authorId\":\"26982950\",\"name\":\"Longteng Guo\"},{\"authorId\":null,\"name\":\"Jing Liu\"},{\"authorId\":\"48386951\",\"name\":\"Xinxin Zhu\"},{\"authorId\":\"49051904\",\"name\":\"P. Yao\"},{\"authorId\":\"116829059\",\"name\":\"Shi-chen Lu\"},{\"authorId\":\"1699900\",\"name\":\"H. Lu\"}],\"doi\":\"10.1109/cvpr42600.2020.01034\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"833560cd68a3e3d1be1bc650756dd6c679798551\",\"title\":\"Normalized and Geometry-Aware Self-Attention Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/833560cd68a3e3d1be1bc650756dd6c679798551\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1387548078\",\"name\":\"K. Lin\"},{\"authorId\":\"1738276592\",\"name\":\"Zhuoxin Gan\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.98\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3263b941d0a77bbd2040612ec774ef063ef64c48\",\"title\":\"Semi-Supervised Learning for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/3263b941d0a77bbd2040612ec774ef063ef64c48\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2005.00200\",\"authors\":[{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"2378902\",\"name\":\"Yen-Chun Chen\"},{\"authorId\":\"1664725279\",\"name\":\"Yu Cheng\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1520007550\",\"name\":\"Jingjing Liu\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.161\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6961065a16f6c3db4879cfad5875d11ce75e6b2f\",\"title\":\"HERO: Hierarchical Encoder for Video+Language Omni-representation Pre-training\",\"url\":\"https://www.semanticscholar.org/paper/6961065a16f6c3db4879cfad5875d11ce75e6b2f\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"1910.11102\",\"authors\":[{\"authorId\":\"48386951\",\"name\":\"Xinxin Zhu\"},{\"authorId\":\"26982950\",\"name\":\"Longteng Guo\"},{\"authorId\":\"1923156\",\"name\":\"Peng Yao\"},{\"authorId\":\"1749850\",\"name\":\"Jing Liu\"},{\"authorId\":\"116829059\",\"name\":\"Shichen Lu\"},{\"authorId\":\"2125223\",\"name\":\"Zheng Gen Yu\"},{\"authorId\":\"46641690\",\"name\":\"Wei Liu\"},{\"authorId\":\"46386029\",\"name\":\"Hanqing Lu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1ae6fc431791e0daa8bfb3b195acdba4535cf07c\",\"title\":\"Multi-View Features and Hybrid Reward Strategies for Vatex Video Captioning Challenge 2019\",\"url\":\"https://www.semanticscholar.org/paper/1ae6fc431791e0daa8bfb3b195acdba4535cf07c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2010.13588\",\"authors\":[{\"authorId\":\"10791325\",\"name\":\"Ozan Caglayan\"},{\"authorId\":\"144695472\",\"name\":\"P. Madhyastha\"},{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2e4ca3d95ffb83870661dd66deee143e782f0706\",\"title\":\"Curious Case of Language Generation Evaluation Metrics: A Cautionary Tale\",\"url\":\"https://www.semanticscholar.org/paper/2e4ca3d95ffb83870661dd66deee143e782f0706\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":\"2011.11071\",\"authors\":[{\"authorId\":\"2028596941\",\"name\":\"Andreea-Maria Oncescu\"},{\"authorId\":\"143848064\",\"name\":\"Jo\\u00e3o F. Henriques\"},{\"authorId\":\"1614034792\",\"name\":\"Yang Liu\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"},{\"authorId\":\"7641268\",\"name\":\"Samuel Albanie\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6ee5d4a6ead378df9949daad5cf245c01563a3fa\",\"title\":\"QuerYD: A video dataset with high-quality textual and audio narrations\",\"url\":\"https://www.semanticscholar.org/paper/6ee5d4a6ead378df9949daad5cf245c01563a3fa\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1907.09358\",\"authors\":[{\"authorId\":\"3219864\",\"name\":\"Aditya Mogadala\"},{\"authorId\":\"151119369\",\"name\":\"M. Kalimuthu\"},{\"authorId\":\"2561225\",\"name\":\"D. Klakow\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f8a48678094adbe421d61d0045361bfc635a2900\",\"title\":\"Trends in Integration of Vision and Language Research: A Survey of Tasks, Datasets, and Methods\",\"url\":\"https://www.semanticscholar.org/paper/f8a48678094adbe421d61d0045361bfc635a2900\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1911.03854\",\"authors\":[{\"authorId\":\"30347964\",\"name\":\"Kai Nakamura\"},{\"authorId\":\"49285370\",\"name\":\"Sharon Levy\"},{\"authorId\":\"1682479\",\"name\":\"William Yang Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"76de89ca66f898e8211acba7392ef2d4a7e14125\",\"title\":\"r/Fakeddit: A New Multimodal Benchmark Dataset for Fine-grained Fake News Detection\",\"url\":\"https://www.semanticscholar.org/paper/76de89ca66f898e8211acba7392ef2d4a7e14125\",\"venue\":\"LREC\",\"year\":2020},{\"arxivId\":\"2001.09099\",\"authors\":[{\"authorId\":\"46665218\",\"name\":\"Jie Lei\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"143977266\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.1007/978-3-030-58589-1_27\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"37dd9c725cb800fd5f336a5227f02c160b8723cb\",\"title\":\"TVR: A Large-Scale Dataset for Video-Subtitle Moment Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/37dd9c725cb800fd5f336a5227f02c160b8723cb\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1911.03705\",\"authors\":[{\"authorId\":\"51583409\",\"name\":\"Bill Yuchen Lin\"},{\"authorId\":\"143977316\",\"name\":\"M. Shen\"},{\"authorId\":\"150341221\",\"name\":\"Wangchunshu Zhou\"},{\"authorId\":\"1557324013\",\"name\":\"Pei Zhou\"},{\"authorId\":\"1857797\",\"name\":\"Chandra Bhagavatula\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"},{\"authorId\":\"1384550891\",\"name\":\"X. Ren\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.165\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"fc366c5a6e6aaf3fe718be09d9b6fb8924f1a7bf\",\"title\":\"CommonGen: A Constrained Text Generation Challenge for Generative Commonsense Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/fc366c5a6e6aaf3fe718be09d9b6fb8924f1a7bf\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2003.00392\",\"authors\":[{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"50976845\",\"name\":\"Yida Zhao\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"},{\"authorId\":\"49018095\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1109/cvpr42600.2020.01065\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"0b78e14dfc2050878e8c817e4782c0c81ee7f5dd\",\"title\":\"Fine-Grained Video-Text Retrieval With Hierarchical Graph Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/0b78e14dfc2050878e8c817e4782c0c81ee7f5dd\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2008.09791\",\"authors\":[{\"authorId\":\"46979645\",\"name\":\"J. Park\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"}],\"doi\":\"10.1007/978-3-030-58589-1_22\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"21a1b6f4f56c1fb6d844c5a1d971c59ab9cf81f7\",\"title\":\"Identity-Aware Multi-Sentence Video Description\",\"url\":\"https://www.semanticscholar.org/paper/21a1b6f4f56c1fb6d844c5a1d971c59ab9cf81f7\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2010.07999\",\"authors\":[{\"authorId\":\"46665218\",\"name\":\"Jie Lei\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"143977266\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.706\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9f2a7a912624d850cf9e0587263b4fcd88d44f18\",\"title\":\"What is More Likely to Happen Next? Video-and-Language Future Event Prediction\",\"url\":\"https://www.semanticscholar.org/paper/9f2a7a912624d850cf9e0587263b4fcd88d44f18\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2004.10151\",\"authors\":[{\"authorId\":\"3312309\",\"name\":\"Yonatan Bisk\"},{\"authorId\":\"14487640\",\"name\":\"Ari Holtzman\"},{\"authorId\":\"2665873\",\"name\":\"Jesse Thomason\"},{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"50730674\",\"name\":\"Joyce Chai\"},{\"authorId\":\"1412841514\",\"name\":\"M. Lapata\"},{\"authorId\":\"2672644\",\"name\":\"A. Lazaridou\"},{\"authorId\":\"143823227\",\"name\":\"Jonathan May\"},{\"authorId\":\"17109242\",\"name\":\"Aleksandr Nisnevich\"},{\"authorId\":\"30017846\",\"name\":\"Nicolas Pinto\"},{\"authorId\":\"153160559\",\"name\":\"Joseph P. Turian\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.703\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"bb6c2a64ecb6e4c9f3f5720d53cca76a2c37505d\",\"title\":\"Experience Grounds Language\",\"url\":\"https://www.semanticscholar.org/paper/bb6c2a64ecb6e4c9f3f5720d53cca76a2c37505d\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"1910.07482\",\"authors\":[{\"authorId\":\"10791325\",\"name\":\"Ozan Caglayan\"},{\"authorId\":\"151480727\",\"name\":\"Zixiu Wu\"},{\"authorId\":\"144695472\",\"name\":\"P. Madhyastha\"},{\"authorId\":\"2635321\",\"name\":\"Josiah Wang\"},{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"37f371fe04f3dc38df7f27f43277ba15d3637890\",\"title\":\"Imperial College London Submission to VATEX Video Captioning Task\",\"url\":\"https://www.semanticscholar.org/paper/37f371fe04f3dc38df7f27f43277ba15d3637890\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2011.14752\",\"authors\":[{\"authorId\":\"47264639\",\"name\":\"Ashutosh Kumar Singh\"},{\"authorId\":\"2305086\",\"name\":\"Thoudam Doren Singh\"},{\"authorId\":\"1722399\",\"name\":\"Sivaji Bandyopadhyay\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"baf5478fbf0a2f0ca2af287a35f3f5469afcd936\",\"title\":\"A Comprehensive Review on Recent Methods and Challenges of Video Description\",\"url\":\"https://www.semanticscholar.org/paper/baf5478fbf0a2f0ca2af287a35f3f5469afcd936\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.11618\",\"authors\":[{\"authorId\":\"48211835\",\"name\":\"J. Liu\"},{\"authorId\":\"2928777\",\"name\":\"Wenhu Chen\"},{\"authorId\":\"5524736\",\"name\":\"Y. Cheng\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"35729970\",\"name\":\"Yiming Yang\"},{\"authorId\":\"46700348\",\"name\":\"Jing-jing Liu\"}],\"doi\":\"10.1109/cvpr42600.2020.01091\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"704ec27b8399df574a96da338c428a923509385e\",\"title\":\"Violin: A Large-Scale Dataset for Video-and-Language Inference\",\"url\":\"https://www.semanticscholar.org/paper/704ec27b8399df574a96da338c428a923509385e\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2006.03315\",\"authors\":[{\"authorId\":\"1387548078\",\"name\":\"K. Lin\"},{\"authorId\":\"1738276592\",\"name\":\"Zhuoxin Gan\"},{\"authorId\":\"46659782\",\"name\":\"L. Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aea0c2fdcb618d3b0fdea17a5fc5b068b80a0ec3\",\"title\":\"Multi-modal Feature Fusion with Feature Attention for VATEX Captioning Challenge 2020\",\"url\":\"https://www.semanticscholar.org/paper/aea0c2fdcb618d3b0fdea17a5fc5b068b80a0ec3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.04305\",\"authors\":[{\"authorId\":\"1918424\",\"name\":\"Jiacheng Chen\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"1491232360\",\"name\":\"Hao Wu\"},{\"authorId\":\"1691963\",\"name\":\"Yuning Jiang\"},{\"authorId\":\"1906061249\",\"name\":\"Changhu Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a27f4af07d73baccda94b5d2a2535b7dfdb58019\",\"title\":\"Learning the Best Pooling Strategy for Visual Semantic Embedding\",\"url\":\"https://www.semanticscholar.org/paper/a27f4af07d73baccda94b5d2a2535b7dfdb58019\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47860328\",\"name\":\"Shagun Uppal\"},{\"authorId\":\"73368394\",\"name\":\"Sarthak Bhagat\"},{\"authorId\":\"8223433\",\"name\":\"Devamanyu Hazarika\"},{\"authorId\":\"1999177921\",\"name\":\"Navonil Majumdar\"},{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"153015119\",\"name\":\"R. Zimmermann\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"0f23b548ff7b3517f028164a30c8bf186f11a1a6\",\"title\":\"Emerging Trends of Multimodal Research in Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/0f23b548ff7b3517f028164a30c8bf186f11a1a6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.05381\",\"authors\":[{\"authorId\":\"40240283\",\"name\":\"J. Dong\"},{\"authorId\":\"9931285\",\"name\":\"Xirong Li\"},{\"authorId\":\"46200183\",\"name\":\"Chaoxi Xu\"},{\"authorId\":\"145789906\",\"name\":\"G. Yang\"},{\"authorId\":\"48632140\",\"name\":\"Xun Wang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"be749fb4719cfc56d689ab11a27a9a6f8fd76570\",\"title\":\"Hybrid Space Learning for Language-based Video Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/be749fb4719cfc56d689ab11a27a9a6f8fd76570\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.12798\",\"authors\":[{\"authorId\":\"3461272\",\"name\":\"Umut Sulubacak\"},{\"authorId\":\"10791325\",\"name\":\"Ozan Caglayan\"},{\"authorId\":\"1438306994\",\"name\":\"Stig-Arne Gronroos\"},{\"authorId\":\"8769200\",\"name\":\"Aku Rouhe\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"},{\"authorId\":\"113391779\",\"name\":\"Jorg Tiedemann\"}],\"doi\":\"10.1007/s10590-020-09250-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a6f62d2365aa63f5d9c90893ab8aaa25551276fe\",\"title\":\"Multimodal machine translation through visuals and speech\",\"url\":\"https://www.semanticscholar.org/paper/a6f62d2365aa63f5d9c90893ab8aaa25551276fe\",\"venue\":\"Machine Translation\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47837986\",\"name\":\"An Yan\"},{\"authorId\":\"47120131\",\"name\":\"X. Wang\"},{\"authorId\":\"2093485\",\"name\":\"Jiangtao Feng\"},{\"authorId\":null,\"name\":\"Lei Li\"},{\"authorId\":\"1682479\",\"name\":\"William Yang Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a88e77a9574bcb20021d0dd4a4b8d729d85696f2\",\"title\":\"Beyond Monolingual Vision-Language Navigation\",\"url\":\"https://www.semanticscholar.org/paper/a88e77a9574bcb20021d0dd4a4b8d729d85696f2\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Bill Yuchen Lin\"},{\"authorId\":\"143977316\",\"name\":\"M. Shen\"},{\"authorId\":\"145303641\",\"name\":\"Yu Xing\"},{\"authorId\":\"1557324013\",\"name\":\"Pei Zhou\"},{\"authorId\":\"145201124\",\"name\":\"Xiang Ren\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8b7cb2e9d884427ef50b564d97d3fd403953afa6\",\"title\":\"COMMONGEN: Towards Generative Commonsense Reasoning via A Constrained Text Generation Challenge\",\"url\":\"https://www.semanticscholar.org/paper/8b7cb2e9d884427ef50b564d97d3fd403953afa6\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30347964\",\"name\":\"Kai Nakamura\"},{\"authorId\":\"2006062225\",\"name\":\"Sharon Levy\"},{\"authorId\":\"1682479\",\"name\":\"William Yang Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eec79e8640b64961a402658cc32c539a9230b3ff\",\"title\":\"Fakeddit: A New Multimodal Benchmark Dataset for Fine-grained Fake News Detection.\",\"url\":\"https://www.semanticscholar.org/paper/eec79e8640b64961a402658cc32c539a9230b3ff\",\"venue\":\"LREC 2020\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150358371\",\"name\":\"Zhiyong Wu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4ef4417e61687aee0196573d0c29422bc9ac225f\",\"title\":\"DeepFuse: HKU\\u2019s Multimodal Machine Translation System for VMT\\u201920\",\"url\":\"https://www.semanticscholar.org/paper/4ef4417e61687aee0196573d0c29422bc9ac225f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40607664\",\"name\":\"Yuqing Song\"},{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c71934550456ef3f92edc6b7e98d6b2d9c519382\",\"title\":\"Team RUC AI\\u00b7M Technical Report at VMT Challenge 2020: Enhancing Neural Machine Translation with Multimodal Rewards\",\"url\":\"https://www.semanticscholar.org/paper/c71934550456ef3f92edc6b7e98d6b2d9c519382\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2006.12799\",\"authors\":[{\"authorId\":\"89530758\",\"name\":\"Tosho Hirasawa\"},{\"authorId\":\"3005221\",\"name\":\"Zhishen Yang\"},{\"authorId\":\"2936411\",\"name\":\"Mamoru Komachi\"},{\"authorId\":\"102837708\",\"name\":\"N. Okazaki\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3eee1fd014ee6ce7563633bb4a088d73cada82ce\",\"title\":\"Keyframe Segmentation and Positional Encoding for Video-guided Machine Translation Challenge 2020\",\"url\":\"https://www.semanticscholar.org/paper/3eee1fd014ee6ce7563633bb4a088d73cada82ce\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.11760\",\"authors\":[{\"authorId\":\"24040986\",\"name\":\"Gabriel Huang\"},{\"authorId\":\"1560385163\",\"name\":\"Bo Pang\"},{\"authorId\":\"2062703\",\"name\":\"Z. Zhu\"},{\"authorId\":\"66193113\",\"name\":\"C. Rivera\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2bacd2f2a70d756f108ad889b6bcddc79cc1ce51\",\"title\":\"Multimodal Pretraining for Dense Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/2bacd2f2a70d756f108ad889b6bcddc79cc1ce51\",\"venue\":\"AACL/IJCNLP\",\"year\":2020},{\"arxivId\":\"2008.06376\",\"authors\":[{\"authorId\":\"1879340740\",\"name\":\"Jason Armitage\"},{\"authorId\":\"1720805321\",\"name\":\"Endri Kacupaj\"},{\"authorId\":\"1811161657\",\"name\":\"Golsa Tahmasebzadeh\"},{\"authorId\":\"50533974\",\"name\":\"Swati\"},{\"authorId\":\"2298633\",\"name\":\"M. Maleshkova\"},{\"authorId\":\"1738703\",\"name\":\"R. Ewerth\"},{\"authorId\":\"71564931\",\"name\":\"J. Lehmann\"}],\"doi\":\"10.1145/3340531.3412783\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4329ceeac964cd2d061d4e151c505905636f76fa\",\"title\":\"MLM: A Benchmark Dataset for Multitask Learning with Multiple Languages and Modalities\",\"url\":\"https://www.semanticscholar.org/paper/4329ceeac964cd2d061d4e151c505905636f76fa\",\"venue\":\"CIKM\",\"year\":2020},{\"arxivId\":\"2003.05078\",\"authors\":[{\"authorId\":\"34280810\",\"name\":\"Gunnar A. Sigurdsson\"},{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"3208081\",\"name\":\"A. Nematzadeh\"},{\"authorId\":\"1466466597\",\"name\":\"Lucas Smaira\"},{\"authorId\":\"1471708751\",\"name\":\"M. Malinowski\"},{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"1685771\",\"name\":\"P. Blunsom\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/cvpr42600.2020.01086\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a1f1d17a350d30d55de52b15c9fe7fea4ba6ff13\",\"title\":\"Visual Grounding in Video for Unsupervised Word Translation\",\"url\":\"https://www.semanticscholar.org/paper/a1f1d17a350d30d55de52b15c9fe7fea4ba6ff13\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020}],\"corpusId\":102352148,\"doi\":\"10.1109/ICCV.2019.00468\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":13,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"28b74bb7c8b08cceb2430ec2d54dfa0f3225d796\",\"references\":[{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Multilingual Video Captioning 4. Video-guided Machine Translation 5. Examples\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40201738\",\"name\":\"G. Youmans\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"391b075718ceebd4bc4808c82430ad0459b609ed\",\"title\":\"Measuring Lexical Style and Competence: The Type-Token Vocabulary Curve\",\"url\":\"https://www.semanticscholar.org/paper/391b075718ceebd4bc4808c82430ad0459b609ed\",\"venue\":\"\",\"year\":1990},{\"arxivId\":\"1409.0473\",\"authors\":[{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"title\":\"Neural Machine Translation by Jointly Learning to Align and Translate\",\"url\":\"https://www.semanticscholar.org/paper/fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1504.00325\",\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"title\":\"Microsoft COCO Captions: Data Collection and Evaluation Server\",\"url\":\"https://www.semanticscholar.org/paper/696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"119268487\",\"name\":\"Hueihan Jhuang\"},{\"authorId\":\"1930964\",\"name\":\"E. Garrote\"},{\"authorId\":\"145031878\",\"name\":\"T. Poggio\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"}],\"doi\":\"10.1109/ICCV.2011.6126543\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8b3b8848a311c501e704c45c6d50430ab7068956\",\"title\":\"HMDB: A large video database for human motion recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b3b8848a311c501e704c45c6d50430ab7068956\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":\"1806.00186\",\"authors\":[{\"authorId\":\"50978260\",\"name\":\"Nayyer Aafaq\"},{\"authorId\":\"1746166\",\"name\":\"Syed Zulqarnain Gilani\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"46332747\",\"name\":\"A. Mian\"}],\"doi\":\"10.1145/3355390\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"665a5673d33a90a1b71c0d5b1be127a76af43be7\",\"title\":\"Video Description\",\"url\":\"https://www.semanticscholar.org/paper/665a5673d33a90a1b71c0d5b1be127a76af43be7\",\"venue\":\"ACM Comput. Surv.\",\"year\":2020},{\"arxivId\":\"1710.07177\",\"authors\":[{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"37922370\",\"name\":\"S. Frank\"},{\"authorId\":\"2934336\",\"name\":\"Lo\\u00efc Barrault\"},{\"authorId\":\"2076086\",\"name\":\"Fethi Bougares\"},{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"}],\"doi\":\"10.18653/v1/W17-4718\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ee5b4fc5fafa7e883d751557b5c7863503cd92d2\",\"title\":\"Findings of the Second Shared Task on Multimodal Machine Translation and Multilingual Image Description\",\"url\":\"https://www.semanticscholar.org/paper/ee5b4fc5fafa7e883d751557b5c7863503cd92d2\",\"venue\":\"WMT\",\"year\":2017},{\"arxivId\":\"1411.5726\",\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2015.7299087\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"258986132bf17755fe8263e42429fe73218c1534\",\"title\":\"CIDEr: Consensus-based image description evaluation\",\"url\":\"https://www.semanticscholar.org/paper/258986132bf17755fe8263e42429fe73218c1534\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1403.6173\",\"authors\":[{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"113090874\",\"name\":\"W. Qiu\"},{\"authorId\":\"33985877\",\"name\":\"Annemarie Friedrich\"},{\"authorId\":\"1717560\",\"name\":\"Manfred Pinkal\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1007/978-3-319-11752-2_15\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"889e723cd6d581e120ee6776b231fdf69707ab50\",\"title\":\"Coherent Multi-sentence Video Description with Variable Level of Detail\",\"url\":\"https://www.semanticscholar.org/paper/889e723cd6d581e120ee6776b231fdf69707ab50\",\"venue\":\"GCPR\",\"year\":2014},{\"arxivId\":\"1605.03705\",\"authors\":[{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1730844\",\"name\":\"Atousa Torabi\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1721168\",\"name\":\"Niket Tandon\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1007/s11263-016-0987-1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"154c22ca5eef149aedc8a986fa684ca1fd14e7dc\",\"title\":\"Movie Description\",\"url\":\"https://www.semanticscholar.org/paper/154c22ca5eef149aedc8a986fa684ca1fd14e7dc\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1505.00468\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-016-0966-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"title\":\"VQA: Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1409.3215\",\"authors\":[{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cea967b59209c6be22829699f05b8b1ac4dc092d\",\"title\":\"Sequence to Sequence Learning with Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/cea967b59209c6be22829699f05b8b1ac4dc092d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1606.02276\",\"authors\":[{\"authorId\":\"143958923\",\"name\":\"Nikolaos Pappas\"},{\"authorId\":\"2109913\",\"name\":\"Miriam Redi\"},{\"authorId\":\"7179616\",\"name\":\"Mercan Topkara\"},{\"authorId\":\"2447185\",\"name\":\"B. Jou\"},{\"authorId\":\"2012673\",\"name\":\"H. Liu\"},{\"authorId\":\"143726651\",\"name\":\"Tao Chen\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1145/2911996.2912016\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"60a4a20c3bb019a1b2b23e701f9b35c8e0d7fdd6\",\"title\":\"Multilingual Visual Sentiment Concept Matching\",\"url\":\"https://www.semanticscholar.org/paper/60a4a20c3bb019a1b2b23e701f9b35c8e0d7fdd6\",\"venue\":\"ICMR\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1162/neco.1997.9.8.1735\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"title\":\"Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"venue\":\"Neural Computation\",\"year\":1997},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2921001\",\"name\":\"Spandana Gella\"},{\"authorId\":\"35084211\",\"name\":\"M. Lewis\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.18653/v1/D18-1117\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"b5647cbbfdc7d1ee91a8ec264b200b66afd7b8b2\",\"title\":\"A Dataset for Telling the Stories of Social Media Videos\",\"url\":\"https://www.semanticscholar.org/paper/b5647cbbfdc7d1ee91a8ec264b200b66afd7b8b2\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2063374\",\"name\":\"Houda Bouamor\"},{\"authorId\":\"1898561\",\"name\":\"Hanan Alshikhabobakr\"},{\"authorId\":\"1809988\",\"name\":\"B. Mohit\"},{\"authorId\":\"1723120\",\"name\":\"Kemal Oflazer\"}],\"doi\":\"10.3115/v1/D14-1026\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1d8338548190d06963806faa6a4eb81bb09f7b0c\",\"title\":\"A Human Judgement Corpus and a Metric for Arabic MT Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/1d8338548190d06963806faa6a4eb81bb09f7b0c\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jo\\u00e3o Carreira\"},{\"authorId\":null,\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Quo vadis, action recognition?\",\"url\":\"\",\"venue\":\"a new model and the kinetics dataset. Proceedings of the 30th IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1605.00459\",\"authors\":[{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"143873430\",\"name\":\"S. Frank\"},{\"authorId\":\"3540477\",\"name\":\"K. Sima'an\"},{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"}],\"doi\":\"10.18653/v1/W16-3210\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bc9db6117d0026bc5b11eeba2303d2bddc96c306\",\"title\":\"Multi30K: Multilingual English-German Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/bc9db6117d0026bc5b11eeba2303d2bddc96c306\",\"venue\":\"VL@ACL\",\"year\":2016},{\"arxivId\":\"1812.08658\",\"authors\":[{\"authorId\":\"37825612\",\"name\":\"Harsh Agrawal\"},{\"authorId\":\"1606411716\",\"name\":\"Karan Desai\"},{\"authorId\":\"46395829\",\"name\":\"Yufei Wang\"},{\"authorId\":\"1606041624\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"145461380\",\"name\":\"Rishabh Jain\"},{\"authorId\":\"1607624548\",\"name\":\"Mark Johnson\"},{\"authorId\":\"1606364265\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"1606363958\",\"name\":\"Devi Parikh\"},{\"authorId\":\"1607486000\",\"name\":\"Stefan Lee\"},{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"}],\"doi\":\"10.1109/ICCV.2019.00904\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8b55402ffee2734bfc7d5d7595500916e1ef04e8\",\"title\":\"nocaps: novel object captioning at scale\",\"url\":\"https://www.semanticscholar.org/paper/8b55402ffee2734bfc7d5d7595500916e1ef04e8\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3238408\",\"name\":\"P. Madhyastha\"},{\"authorId\":\"2635321\",\"name\":\"Josiah Wang\"},{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"}],\"doi\":\"10.18653/v1/W17-4752\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"08f6b52317b34b60aa65f38b83e3d72deffa0473\",\"title\":\"Sheffield MultiMT: Using Object Posterior Predictions for Multimodal Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/08f6b52317b34b60aa65f38b83e3d72deffa0473\",\"venue\":\"WMT\",\"year\":2017},{\"arxivId\":\"1705.06950\",\"authors\":[{\"authorId\":\"21028601\",\"name\":\"W. Kay\"},{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"11809518\",\"name\":\"Brian Zhang\"},{\"authorId\":\"38961760\",\"name\":\"Chloe Hillier\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"143740871\",\"name\":\"F. Viola\"},{\"authorId\":\"143897708\",\"name\":\"T. Green\"},{\"authorId\":\"2830305\",\"name\":\"T. Back\"},{\"authorId\":\"1820908\",\"name\":\"A. Natsev\"},{\"authorId\":\"2573615\",\"name\":\"Mustafa Suleyman\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6\",\"title\":\"The Kinetics Human Action Video Dataset\",\"url\":\"https://www.semanticscholar.org/paper/86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1811.00347\",\"authors\":[{\"authorId\":\"40489004\",\"name\":\"R. Sanabria\"},{\"authorId\":\"10791325\",\"name\":\"Ozan Caglayan\"},{\"authorId\":\"26400211\",\"name\":\"Shruti Palaskar\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"2934336\",\"name\":\"Lo\\u00efc Barrault\"},{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"},{\"authorId\":\"1740721\",\"name\":\"F. Metze\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f56cb5dc32b5b280546998418fda7769d0858629\",\"title\":\"How2: A Large-scale Dataset for Multimodal Language Understanding\",\"url\":\"https://www.semanticscholar.org/paper/f56cb5dc32b5b280546998418fda7769d0858629\",\"venue\":\"NIPS 2018\",\"year\":2018},{\"arxivId\":\"1503.01070\",\"authors\":[{\"authorId\":\"1730844\",\"name\":\"Atousa Torabi\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b1ddb2994e49a6a4f45e878c1cda7562b03177e6\",\"title\":\"Using Descriptive Video Services to Create a Large Data Source for Video Annotation Research\",\"url\":\"https://www.semanticscholar.org/paper/b1ddb2994e49a6a4f45e878c1cda7562b03177e6\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3323275\",\"name\":\"Kishore Papineni\"},{\"authorId\":\"1781292\",\"name\":\"S. Roukos\"},{\"authorId\":\"144582029\",\"name\":\"T. Ward\"},{\"authorId\":\"2587983\",\"name\":\"Wei-Jing Zhu\"}],\"doi\":\"10.3115/1073083.1073135\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d7da009f457917aa381619facfa5ffae9329a6e9\",\"title\":\"Bleu: a Method for Automatic Evaluation of Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/d7da009f457917aa381619facfa5ffae9329a6e9\",\"venue\":\"ACL\",\"year\":2002},{\"arxivId\":\"1903.08678\",\"authors\":[{\"authorId\":\"10791325\",\"name\":\"Ozan Caglayan\"},{\"authorId\":\"144695472\",\"name\":\"P. Madhyastha\"},{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"},{\"authorId\":\"2934336\",\"name\":\"Lo\\u00efc Barrault\"}],\"doi\":\"10.18653/v1/N19-1422\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4f30434e86a54a214c56e76106f801a1ad740b1f\",\"title\":\"Probing the Need for Visual Context in Multimodal Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/4f30434e86a54a214c56e76106f801a1ad740b1f\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":\"1608.07068\",\"authors\":[{\"authorId\":\"32970572\",\"name\":\"Kuo-Hao Zeng\"},{\"authorId\":\"3451456\",\"name\":\"Tseng-Hung Chen\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":\"10.1007/978-3-319-46475-6_38\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"65ba5f3927633293112cf1bbdf6641d4d15638cc\",\"title\":\"Title Generation for User Generated Videos\",\"url\":\"https://www.semanticscholar.org/paper/65ba5f3927633293112cf1bbdf6641d4d15638cc\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1781574\",\"name\":\"Chin-Yew Lin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"60b05f32c32519a809f21642ef1eb3eaf3848008\",\"title\":\"ROUGE: A Package for Automatic Evaluation of Summaries\",\"url\":\"https://www.semanticscholar.org/paper/60b05f32c32519a809f21642ef1eb3eaf3848008\",\"venue\":\"ACL 2004\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/CVPR.2015.7298698\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0a28efacb92d16e6e0dd4d87b5aca91b28be8853\",\"title\":\"ActivityNet: A large-scale video benchmark for human activity understanding\",\"url\":\"https://www.semanticscholar.org/paper/0a28efacb92d16e6e0dd4d87b5aca91b28be8853\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49775163\",\"name\":\"Ruihua Zhang\"}],\"doi\":\"10.5040/9781472593719\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"72a6ae7b3d5177cf92e4e7a1a293a53afb35b080\",\"title\":\"Sadness Expressions in English and Chinese: Corpus Linguistic Contrastive Semantic Analysis\",\"url\":\"https://www.semanticscholar.org/paper/72a6ae7b3d5177cf92e4e7a1a293a53afb35b080\",\"venue\":\"\",\"year\":2014},{\"arxivId\":\"1805.08661\",\"authors\":[{\"authorId\":\"9931285\",\"name\":\"Xirong Li\"},{\"authorId\":\"46200183\",\"name\":\"Chaoxi Xu\"},{\"authorId\":\"26832002\",\"name\":\"X. Wang\"},{\"authorId\":\"2896042\",\"name\":\"Weiyu Lan\"},{\"authorId\":\"152584142\",\"name\":\"Zhengxiong Jia\"},{\"authorId\":\"145789911\",\"name\":\"Gang Yang\"},{\"authorId\":\"1706347\",\"name\":\"Jieping Xu\"}],\"doi\":\"10.1109/TMM.2019.2896494\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b795675a6228abb68f8ed1b8abaf8630309fd764\",\"title\":\"COCO-CN for Cross-Lingual Image Tagging, Captioning, and Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/b795675a6228abb68f8ed1b8abaf8630309fd764\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144956443\",\"name\":\"F. Xia\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7c7c19e89a17cec76e949ebdee92aab5ab46aca1\",\"title\":\"The Part-Of-Speech Tagging Guidelines for the Penn Chinese Treebank (3.0)\",\"url\":\"https://www.semanticscholar.org/paper/7c7c19e89a17cec76e949ebdee92aab5ab46aca1\",\"venue\":\"\",\"year\":2000},{\"arxivId\":\"1604.02748\",\"authors\":[{\"authorId\":\"66508219\",\"name\":\"Y. Li\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"48749954\",\"name\":\"L. Cao\"},{\"authorId\":\"1739099\",\"name\":\"J. Tetreault\"},{\"authorId\":\"39420932\",\"name\":\"L. Goldberg\"},{\"authorId\":\"144633617\",\"name\":\"A. Jaimes\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2016.502\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"05f3f8f6f97db00bafa2efd2ac9aac570603c0c6\",\"title\":\"TGIF: A New Dataset and Benchmark on Animated GIF Description\",\"url\":\"https://www.semanticscholar.org/paper/05f3f8f6f97db00bafa2efd2ac9aac570603c0c6\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1609.03976\",\"authors\":[{\"authorId\":\"10791325\",\"name\":\"Ozan Caglayan\"},{\"authorId\":\"2934336\",\"name\":\"Lo\\u00efc Barrault\"},{\"authorId\":\"2076086\",\"name\":\"Fethi Bougares\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7876f448942e2658c3911c42b32ced10f85a4800\",\"title\":\"Multimodal Attention for Neural Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/7876f448942e2658c3911c42b32ced10f85a4800\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144927151\",\"name\":\"Mike Schuster\"},{\"authorId\":\"48099761\",\"name\":\"K. Paliwal\"}],\"doi\":\"10.1109/78.650093\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"e23c34414e66118ecd9b08cf0cd4d016f59b0b85\",\"title\":\"Bidirectional recurrent neural networks\",\"url\":\"https://www.semanticscholar.org/paper/e23c34414e66118ecd9b08cf0cd4d016f59b0b85\",\"venue\":\"IEEE Trans. Signal Process.\",\"year\":1997},{\"arxivId\":\"1703.09788\",\"authors\":[{\"authorId\":\"2677364\",\"name\":\"Luowei Zhou\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e10a5e0baf2aa87d804795af071808a9377cc80a\",\"title\":\"Towards Automatic Learning of Procedures From Web Instructional Videos\",\"url\":\"https://www.semanticscholar.org/paper/e10a5e0baf2aa87d804795af071808a9377cc80a\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153642390\",\"name\":\"David L. Chen\"},{\"authorId\":\"83415753\",\"name\":\"W. Dolan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"554a31ce91189cf6022ac677413ef2f8b9b40ca7\",\"title\":\"Collecting Highly Parallel Data for Paraphrase Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/554a31ce91189cf6022ac677413ef2f8b9b40ca7\",\"venue\":\"ACL 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1906895\",\"name\":\"M. Andriluka\"},{\"authorId\":\"2299109\",\"name\":\"L. Pishchulin\"},{\"authorId\":\"2871555\",\"name\":\"P. Gehler\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1109/CVPR.2014.471\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"da8d53f9a85b40a695585aa461286e373c6b74d4\",\"title\":\"2D Human Pose Estimation: New Benchmark and State of the Art Analysis\",\"url\":\"https://www.semanticscholar.org/paper/da8d53f9a85b40a695585aa461286e373c6b74d4\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2363529\",\"name\":\"Pradipto Das\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"},{\"authorId\":\"38972663\",\"name\":\"Richard F. Doell\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1109/CVPR.2013.340\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a23ab0fb7d9e9961e92d704ed71e3dbc15c0d908\",\"title\":\"A Thousand Frames in Just a Few Words: Lingual Description of Videos through Latent Topics and Sparse Object Stitching\",\"url\":\"https://www.semanticscholar.org/paper/a23ab0fb7d9e9961e92d704ed71e3dbc15c0d908\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":\"1804.05448\",\"authors\":[{\"authorId\":null,\"name\":\"Xin Wang\"},{\"authorId\":\"1706938\",\"name\":\"Y. Wang\"},{\"authorId\":\"1682479\",\"name\":\"William Yang Wang\"}],\"doi\":\"10.18653/v1/N18-2125\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2714a3932b9d096b7bb285f6ec415cb047eafe09\",\"title\":\"Watch, Listen, and Describe: Globally and Locally Aligned Cross-Modal Attentions for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/2714a3932b9d096b7bb285f6ec415cb047eafe09\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1604.01753\",\"authors\":[{\"authorId\":\"34280810\",\"name\":\"Gunnar A. Sigurdsson\"},{\"authorId\":\"2668759\",\"name\":\"G. Varol\"},{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1007/978-3-319-46448-0_31\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"21334d1aac5422da88780f8e24e181bfa15ef0e1\",\"title\":\"Hollywood in Homes: Crowdsourcing Data Collection for Activity Understanding\",\"url\":\"https://www.semanticscholar.org/paper/21334d1aac5422da88780f8e24e181bfa15ef0e1\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1705.00754\",\"authors\":[{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"1382195702\",\"name\":\"Kenji Hata\"},{\"authorId\":\"3260219\",\"name\":\"F. Ren\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/ICCV.2017.83\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"96dd1fc39a368d23291816d57763bc6eb4f7b8d6\",\"title\":\"Dense-Captioning Events in Videos\",\"url\":\"https://www.semanticscholar.org/paper/96dd1fc39a368d23291816d57763bc6eb4f7b8d6\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1708.02300\",\"authors\":[{\"authorId\":\"10721120\",\"name\":\"Ramakanth Pasunuru\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/D17-1103\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"53bed2d3d75c4320ad5af4a85e31bf92e3c704ef\",\"title\":\"Reinforced Video Captioning with Entailment Rewards\",\"url\":\"https://www.semanticscholar.org/paper/53bed2d3d75c4320ad5af4a85e31bf92e3c704ef\",\"venue\":\"EMNLP\",\"year\":2017},{\"arxivId\":\"1212.0402\",\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"title\":\"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\",\"url\":\"https://www.semanticscholar.org/paper/da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":\"1812.00087\",\"authors\":[{\"authorId\":\"145979995\",\"name\":\"D. Zhang\"},{\"authorId\":\"3386593\",\"name\":\"X. Dai\"},{\"authorId\":\"48631993\",\"name\":\"Xin Eric Wang\"},{\"authorId\":\"1706938\",\"name\":\"Y. Wang\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/CVPR.2019.00134\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"613f59279586bd53aed57bc133246a4eb3c38977\",\"title\":\"MAN: Moment Alignment Network for Natural Language Moment Retrieval via Iterative Graph Adjustment\",\"url\":\"https://www.semanticscholar.org/paper/613f59279586bd53aed57bc133246a4eb3c38977\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1705.07750\",\"authors\":[{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2017.502\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"title\":\"Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset\",\"url\":\"https://www.semanticscholar.org/paper/b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1505.05612\",\"authors\":[{\"authorId\":\"2345388\",\"name\":\"Haoyuan Gao\"},{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":null,\"name\":\"Jie Zhou\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":null,\"name\":\"Lei Wang\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2fcd5cff2b4743ea640c4af68bf4143f4a2cccb1\",\"title\":\"Are You Talking to a Machine? Dataset and Methods for Multilingual Image Question\",\"url\":\"https://www.semanticscholar.org/paper/2fcd5cff2b4743ea640c4af68bf4143f4a2cccb1\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1708.01641\",\"authors\":[{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"39231399\",\"name\":\"O. Wang\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"145160921\",\"name\":\"Bryan C. Russell\"}],\"doi\":\"10.1109/ICCV.2017.618\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ee909ad489244016cf301bb7d7d8eeea423dbf35\",\"title\":\"Localizing Moments in Video with Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/ee909ad489244016cf301bb7d7d8eeea423dbf35\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1704.06567\",\"authors\":[{\"authorId\":\"3448602\",\"name\":\"Jind\\u0159ich Libovick\\u00fd\"},{\"authorId\":\"46407634\",\"name\":\"Jind\\u0159ich Helcl\"}],\"doi\":\"10.18653/v1/P17-2031\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e7dc0d6669d411849010a32ee75b49cf4c853f55\",\"title\":\"Attention Strategies for Multi-Source Sequence-to-Sequence Learning\",\"url\":\"https://www.semanticscholar.org/paper/e7dc0d6669d411849010a32ee75b49cf4c853f55\",\"venue\":\"ACL\",\"year\":2017},{\"arxivId\":\"1706.06275\",\"authors\":[{\"authorId\":\"3727644\",\"name\":\"Satoshi Tsutsui\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"93168a3dc214447cd938c35e635bea8af4400b12\",\"title\":\"Using Artificial Tokens to Control Languages for Multilingual Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/93168a3dc214447cd938c35e635bea8af4400b12\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1711.11135\",\"authors\":[{\"authorId\":\"48631993\",\"name\":\"Xin Eric Wang\"},{\"authorId\":\"2928777\",\"name\":\"Wenhu Chen\"},{\"authorId\":\"46365930\",\"name\":\"Jiawei Wu\"},{\"authorId\":\"1706938\",\"name\":\"Y. Wang\"},{\"authorId\":\"1682479\",\"name\":\"William Yang Wang\"}],\"doi\":\"10.1109/CVPR.2018.00443\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"74b284a66e75b65f5970d05bac000fe91243ee49\",\"title\":\"Video Captioning via Hierarchical Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/74b284a66e75b65f5970d05bac000fe91243ee49\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"},{\"authorId\":\"143873430\",\"name\":\"S. Frank\"},{\"authorId\":\"3540477\",\"name\":\"K. Sima'an\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"}],\"doi\":\"10.18653/v1/W16-2346\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"95d3001ed7782fecea29bdb41e598aa5b41a615b\",\"title\":\"A Shared Task on Multimodal Machine Translation and Crosslingual Image Description\",\"url\":\"https://www.semanticscholar.org/paper/95d3001ed7782fecea29bdb41e598aa5b41a615b\",\"venue\":\"WMT\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2157958\",\"name\":\"Michael J. Denkowski\"},{\"authorId\":\"1784914\",\"name\":\"A. Lavie\"}],\"doi\":\"10.3115/v1/W14-3348\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"26adb749fc5d80502a6d889966e50b31391560d3\",\"title\":\"Meteor Universal: Language Specific Translation Evaluation for Any Target Language\",\"url\":\"https://www.semanticscholar.org/paper/26adb749fc5d80502a6d889966e50b31391560d3\",\"venue\":\"WMT@ACL\",\"year\":2014},{\"arxivId\":\"1707.04481\",\"authors\":[{\"authorId\":\"10791325\",\"name\":\"Ozan Caglayan\"},{\"authorId\":\"3202143\",\"name\":\"Walid Aransa\"},{\"authorId\":\"19192985\",\"name\":\"Adrien Bardet\"},{\"authorId\":\"1389738351\",\"name\":\"M. Garc\\u00eda-Mart\\u00ednez\"},{\"authorId\":\"2076086\",\"name\":\"Fethi Bougares\"},{\"authorId\":\"1389738309\",\"name\":\"Loic Barrault\"},{\"authorId\":\"37077230\",\"name\":\"Marc Masana\"},{\"authorId\":\"153206483\",\"name\":\"L. Herranz\"},{\"authorId\":\"2820687\",\"name\":\"Joost van de Weijer\"}],\"doi\":\"10.18653/v1/W17-4746\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0674ed3be0714a0c21967c35320860caf82e55ef\",\"title\":\"LIUM-CVC Submissions for WMT17 Multimodal Translation Task\",\"url\":\"https://www.semanticscholar.org/paper/0674ed3be0714a0c21967c35320860caf82e55ef\",\"venue\":\"WMT\",\"year\":2017},{\"arxivId\":\"1808.10802\",\"authors\":[{\"authorId\":\"1902558\",\"name\":\"S. Gr\\u00f6nroos\"},{\"authorId\":\"2086066\",\"name\":\"B. Huet\"},{\"authorId\":\"1719346\",\"name\":\"M. Kurimo\"},{\"authorId\":\"1708642\",\"name\":\"Jorma T. Laaksonen\"},{\"authorId\":\"1686820\",\"name\":\"B. M\\u00e9rialdo\"},{\"authorId\":\"144270183\",\"name\":\"Phu Pham\"},{\"authorId\":\"1766204\",\"name\":\"M. Sj\\u00f6berg\"},{\"authorId\":\"3461272\",\"name\":\"Umut Sulubacak\"},{\"authorId\":\"143675545\",\"name\":\"J. Tiedemann\"},{\"authorId\":\"1684267\",\"name\":\"Rapha\\u00ebl Troncy\"},{\"authorId\":\"145398168\",\"name\":\"R. V\\u00e1zquez\"}],\"doi\":\"10.18653/v1/W18-6439\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"95172875245af1865c341465c284450537c44f9e\",\"title\":\"The MeMAD Submission to the WMT18 Multimodal Translation Task\",\"url\":\"https://www.semanticscholar.org/paper/95172875245af1865c341465c284450537c44f9e\",\"venue\":\"WMT\",\"year\":2018},{\"arxivId\":\"1501.02530\",\"authors\":[{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1721168\",\"name\":\"Niket Tandon\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1109/CVPR.2015.7298940\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a5ea0da7b93452bec54b5034706f2255bfb5a8f3\",\"title\":\"A dataset for Movie Description\",\"url\":\"https://www.semanticscholar.org/paper/a5ea0da7b93452bec54b5034706f2255bfb5a8f3\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2934336\",\"name\":\"Lo\\u00efc Barrault\"},{\"authorId\":\"2076086\",\"name\":\"Fethi Bougares\"},{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"},{\"authorId\":\"1908331\",\"name\":\"Chiraag Lala\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"37922370\",\"name\":\"S. Frank\"}],\"doi\":\"10.18653/v1/W18-6402\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b37fc91f2fbfad3ae70827e7259997c383e041ff\",\"title\":\"Findings of the Third Shared Task on Multimodal Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/b37fc91f2fbfad3ae70827e7259997c383e041ff\",\"venue\":\"WMT\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2034351\",\"name\":\"W. Zaghouani\"},{\"authorId\":\"1696645\",\"name\":\"Nizar Habash\"},{\"authorId\":\"40010893\",\"name\":\"O. Obeid\"},{\"authorId\":\"1809988\",\"name\":\"B. Mohit\"},{\"authorId\":\"2063374\",\"name\":\"Houda Bouamor\"},{\"authorId\":\"1723120\",\"name\":\"Kemal Oflazer\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8c3bca26ce8a88ffb7bc590b3d164f02c23c9668\",\"title\":\"Building an Arabic Machine Translation Post-Edited Corpus: Guidelines and Annotation\",\"url\":\"https://www.semanticscholar.org/paper/8c3bca26ce8a88ffb7bc590b3d164f02c23c9668\",\"venue\":\"LREC\",\"year\":2016},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1508.04025\",\"authors\":[{\"authorId\":\"1821711\",\"name\":\"Thang Luong\"},{\"authorId\":\"143950636\",\"name\":\"Hieu Pham\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.18653/v1/D15-1166\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"93499a7c7f699b6630a86fad964536f9423bb6d0\",\"title\":\"Effective Approaches to Attention-based Neural Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/93499a7c7f699b6630a86fad964536f9423bb6d0\",\"venue\":\"EMNLP\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"144332826\",\"name\":\"Chen Kong\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"}],\"doi\":\"10.1109/CVPR.2014.340\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7afd833f484c8032e7fdc5f53188d2ebb0fb9934\",\"title\":\"Visual Semantic Search: Retrieving Videos via Complex Textual Queries\",\"url\":\"https://www.semanticscholar.org/paper/7afd833f484c8032e7fdc5f53188d2ebb0fb9934\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1710.02718\",\"authors\":[{\"authorId\":\"1847848\",\"name\":\"M. Ma\"},{\"authorId\":\"2429519\",\"name\":\"D. Li\"},{\"authorId\":\"145341916\",\"name\":\"Kai Zhao\"},{\"authorId\":\"144768480\",\"name\":\"Liang Huang\"}],\"doi\":\"10.18653/v1/W17-4751\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b9baca7746a7771de360f24a1c345fea59335cbd\",\"title\":\"OSU Multimodal Machine Translation System Report\",\"url\":\"https://www.semanticscholar.org/paper/b9baca7746a7771de360f24a1c345fea59335cbd\",\"venue\":\"WMT\",\"year\":2017},{\"arxivId\":\"1701.06521\",\"authors\":[{\"authorId\":\"3068677\",\"name\":\"Iacer Calixto\"},{\"authorId\":\"1688015\",\"name\":\"Qun Liu\"}],\"doi\":\"10.18653/v1/D17-1105\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"380fb2b79a53f884e7d81057fd519237550e988f\",\"title\":\"Incorporating Global Visual Features into Attention-based Neural Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/380fb2b79a53f884e7d81057fd519237550e988f\",\"venue\":\"EMNLP\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2319973\",\"name\":\"Po-Yao Huang\"},{\"authorId\":\"2155134\",\"name\":\"Frederick Liu\"},{\"authorId\":\"2500744\",\"name\":\"Sz-Rung Shiang\"},{\"authorId\":\"143904954\",\"name\":\"Jean Oh\"},{\"authorId\":\"1745899\",\"name\":\"Chris Dyer\"}],\"doi\":\"10.18653/v1/W16-2360\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0a84161fb44da4c04a0b93423e344a03bca77ed5\",\"title\":\"Attention-based Multimodal Neural Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/0a84161fb44da4c04a0b93423e344a03bca77ed5\",\"venue\":\"WMT\",\"year\":2016},{\"arxivId\":\"1708.04390\",\"authors\":[{\"authorId\":\"2896042\",\"name\":\"Weiyu Lan\"},{\"authorId\":\"9931285\",\"name\":\"Xirong Li\"},{\"authorId\":\"40240283\",\"name\":\"J. Dong\"}],\"doi\":\"10.1145/3123266.3123366\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"39f3f9d22a072d0ccf423aa31bacbb4071ac0644\",\"title\":\"Fluency-Guided Cross-Lingual Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/39f3f9d22a072d0ccf423aa31bacbb4071ac0644\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Kuo-Hao Zeng\"},{\"authorId\":null,\"name\":\"Tseng-Hung Chen\"},{\"authorId\":null,\"name\":\"Juan Carlos Niebles\"},{\"authorId\":null,\"name\":\"Min Sun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Generation for user generated videos\",\"url\":\"\",\"venue\":\"In Proceedings of the 2016 European conference on computer vision (ECCV),\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145971173\",\"name\":\"J. Xu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/CVPR.2016.571\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b8e2e9f3ba008e28257195ec69a00e07f260131d\",\"title\":\"MSR-VTT: A Large Video Description Dataset for Bridging Video and Language\",\"url\":\"https://www.semanticscholar.org/paper/b8e2e9f3ba008e28257195ec69a00e07f260131d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2485529\",\"name\":\"Michaela Regneri\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"24138684\",\"name\":\"Dominikus Wetzel\"},{\"authorId\":\"1727272\",\"name\":\"Stefan Thater\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"1717560\",\"name\":\"Manfred Pinkal\"}],\"doi\":\"10.1162/tacl_a_00207\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"21b3007f967d39e1346bc91e0fc8b3f16121300c\",\"title\":\"Grounding Action Descriptions in Videos\",\"url\":\"https://www.semanticscholar.org/paper/21b3007f967d39e1346bc91e0fc8b3f16121300c\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3037066\",\"name\":\"N. Shimizu\"},{\"authorId\":\"48873415\",\"name\":\"Na Rong\"},{\"authorId\":\"145414551\",\"name\":\"Takashi Miyazaki\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"98025d3d44e9379736adb1228919272ded9298ae\",\"title\":\"Visual Question Answering Dataset for Bilingual Image Understanding: A Study of Cross-Lingual Transfer Using Attention Maps\",\"url\":\"https://www.semanticscholar.org/paper/98025d3d44e9379736adb1228919272ded9298ae\",\"venue\":\"COLING\",\"year\":2018},{\"arxivId\":\"1512.00795\",\"authors\":[{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1109/CVPR.2016.291\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8d093efcfadda3ac7de7b0e1ca7d9aa2005c2ec3\",\"title\":\"Actions ~ Transformations\",\"url\":\"https://www.semanticscholar.org/paper/8d093efcfadda3ac7de7b0e1ca7d9aa2005c2ec3\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1505.00487\",\"authors\":[{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/ICCV.2015.515\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e58a110fa1e4ddf247d5c614d117d64bfbe135c4\",\"title\":\"Sequence to Sequence -- Video to Text\",\"url\":\"https://www.semanticscholar.org/paper/e58a110fa1e4ddf247d5c614d117d64bfbe135c4\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1505.04870\",\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2133220\",\"name\":\"C. Cervantes\"},{\"authorId\":\"145507543\",\"name\":\"Juan C. Caicedo\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1007/s11263-016-0965-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0612745dbd292fc0a548a16d39cd73e127faedde\",\"title\":\"Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models\",\"url\":\"https://www.semanticscholar.org/paper/0612745dbd292fc0a548a16d39cd73e127faedde\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"V Peter\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Gehler , and Bernt Schiele . 2 d human pose estimation : New benchmark and state of the art analysis\",\"url\":\"\",\"venue\":\"Proceedings of the 27 th IEEE Conference on Computer Vision and Pattern Recognition ( CVPR )\",\"year\":2014},{\"arxivId\":\"1506.03099\",\"authors\":[{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"3111912\",\"name\":\"Navdeep Jaitly\"},{\"authorId\":\"1846258\",\"name\":\"Noam Shazeer\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"df137487e20ba7c6e1e2b9a1e749f2a578b5ad99\",\"title\":\"Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/df137487e20ba7c6e1e2b9a1e749f2a578b5ad99\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1811.02765\",\"authors\":[{\"authorId\":\"48631993\",\"name\":\"Xin Eric Wang\"},{\"authorId\":\"46365930\",\"name\":\"Jiawei Wu\"},{\"authorId\":\"145979995\",\"name\":\"D. Zhang\"},{\"authorId\":\"1758652\",\"name\":\"Yu Su\"},{\"authorId\":\"1682479\",\"name\":\"William Yang Wang\"}],\"doi\":\"10.1609/aaai.v33i01.33018965\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aeb1fe15261f0ee10a27d1753fb301b7a044933a\",\"title\":\"Learning to Compose Topic-Aware Mixture of Experts for Zero-Shot Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/aeb1fe15261f0ee10a27d1753fb301b7a044933a\",\"venue\":\"AAAI\",\"year\":2019}],\"title\":\"VaTeX: A Large-Scale, High-Quality Multilingual Dataset for Video-and-Language Research\",\"topics\":[{\"topic\":\"Machine translation\",\"topicId\":\"34995\",\"url\":\"https://www.semanticscholar.org/topic/34995\"},{\"topic\":\"Natural language\",\"topicId\":\"1911\",\"url\":\"https://www.semanticscholar.org/topic/1911\"},{\"topic\":\"Audio description\",\"topicId\":\"1289167\",\"url\":\"https://www.semanticscholar.org/topic/1289167\"},{\"topic\":\"Compiler\",\"topicId\":\"13817\",\"url\":\"https://www.semanticscholar.org/topic/13817\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Align (company)\",\"topicId\":\"439709\",\"url\":\"https://www.semanticscholar.org/topic/439709\"}],\"url\":\"https://www.semanticscholar.org/paper/28b74bb7c8b08cceb2430ec2d54dfa0f3225d796\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019}\n"