"{\"abstract\":\"Line art colorization is expensive and challenging to automate. A GAN approach is proposed, called Tag2Pix, of line art colorization which takes as input a grayscale line art and color tag information and produces a quality colored image. First, we present the Tag2Pix line art colorization dataset. A generator network is proposed which consists of convolutional layers to transform the input line art, a pre-trained semantic extraction network, and an encoder for input color information. The discriminator is based on an auxiliary classifier GAN to classify the tag information as well as genuineness. In addition, we propose a novel network structure called SECat, which makes the generator properly colorize even small features such as eyes, and also suggest a novel two-step training method where the generator and discriminator first learn the notion of object and shape and then, based on the learned notion, learn colorization, such as where and how to place which color. We present both quantitative and qualitative evaluations which prove the effectiveness of the proposed method.\",\"arxivId\":\"1908.05840\",\"authors\":[{\"authorId\":\"48206594\",\"name\":\"Hyunsu Kim\",\"url\":\"https://www.semanticscholar.org/author/48206594\"},{\"authorId\":\"1387991988\",\"name\":\"Ho Young Jhoo\",\"url\":\"https://www.semanticscholar.org/author/1387991988\"},{\"authorId\":\"2292315\",\"name\":\"Eunhyeok Park\",\"url\":\"https://www.semanticscholar.org/author/2292315\"},{\"authorId\":\"143750427\",\"name\":\"Sungjoo Yoo\",\"url\":\"https://www.semanticscholar.org/author/143750427\"}],\"citationVelocity\":8,\"citations\":[{\"arxivId\":\"2003.10685\",\"authors\":[{\"authorId\":\"143931954\",\"name\":\"M. Shi\"},{\"authorId\":\"49050067\",\"name\":\"Jiaqi Zhang\"},{\"authorId\":\"2999411\",\"name\":\"Shu-Yu Chen\"},{\"authorId\":\"51190170\",\"name\":\"Lin Gao\"},{\"authorId\":\"144891983\",\"name\":\"Yu-Kun Lai\"},{\"authorId\":\"3326435\",\"name\":\"Fang-Lue Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"525d226b9b14fe056e30c8f3261ece7b7eff11f9\",\"title\":\"Deep Line Art Video Colorization with a Few References\",\"url\":\"https://www.semanticscholar.org/paper/525d226b9b14fe056e30c8f3261ece7b7eff11f9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1507489686\",\"name\":\"Tram-Tran Nguyen-Quynh\"},{\"authorId\":\"2355626\",\"name\":\"Soohyung Kim\"},{\"authorId\":\"26149670\",\"name\":\"Nhu-Tai Do\"}],\"doi\":\"10.1109/ACCESS.2020.3040737\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2da450ea9b694c8e2deab88480417551346fceda\",\"title\":\"Image Colorization Using the Global Scene-Context Style and Pixel-Wise Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/2da450ea9b694c8e2deab88480417551346fceda\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2002.11812\",\"authors\":[{\"authorId\":\"9339911\",\"name\":\"Qingyuan Zheng\"},{\"authorId\":\"2158180\",\"name\":\"Zhuoru Li\"},{\"authorId\":\"1720867\",\"name\":\"Adam W. Bargteil\"}],\"doi\":\"10.1109/CVPR42600.2020.00746\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e21bf68bd69630c80d54c295c4b206aba2279eec\",\"title\":\"Learning to Shadow Hand-Drawn Sketches\",\"url\":\"https://www.semanticscholar.org/paper/e21bf68bd69630c80d54c295c4b206aba2279eec\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35612436\",\"name\":\"Koki Tsubota\"},{\"authorId\":\"11682769\",\"name\":\"Daiki Ikami\"},{\"authorId\":\"65832005\",\"name\":\"K. Aizawa\"}],\"doi\":\"10.1109/ISM46123.2019.00046\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a406e516915640b0844174acdadbc8b5603a1443\",\"title\":\"Synthesis of Screentone Patterns of Manga Characters\",\"url\":\"https://www.semanticscholar.org/paper/a406e516915640b0844174acdadbc8b5603a1443\",\"venue\":\"2019 IEEE International Symposium on Multimedia (ISM)\",\"year\":2019},{\"arxivId\":\"1912.01865\",\"authors\":[{\"authorId\":\"30187096\",\"name\":\"Yunjey Choi\"},{\"authorId\":\"2847986\",\"name\":\"Youngjung Uh\"},{\"authorId\":\"36343408\",\"name\":\"J. Yoo\"},{\"authorId\":\"2577039\",\"name\":\"Jung-Woo Ha\"}],\"doi\":\"10.1109/cvpr42600.2020.00821\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1045aee009c2a66e1330ac4ccfd22ec27665eebe\",\"title\":\"StarGAN v2: Diverse Image Synthesis for Multiple Domains\",\"url\":\"https://www.semanticscholar.org/paper/1045aee009c2a66e1330ac4ccfd22ec27665eebe\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2011.11377\",\"authors\":[{\"authorId\":\"103425198\",\"name\":\"Yuzhi Zhao\"},{\"authorId\":\"144582405\",\"name\":\"L. Po\"},{\"authorId\":\"88939293\",\"name\":\"Kwok-Wai Cheung\"},{\"authorId\":\"87960633\",\"name\":\"Wing-Yin Yu\"},{\"authorId\":\"6260845\",\"name\":\"Yasar Abbas Ur Rehman\"}],\"doi\":\"10.1109/TCSVT.2020.3037688\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb14bbf2c6d85569bcb66023dbea5a4cc4033659\",\"title\":\"SCGAN: Saliency Map-guided Colorization with Generative Adversarial Network\",\"url\":\"https://www.semanticscholar.org/paper/eb14bbf2c6d85569bcb66023dbea5a4cc4033659\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.06822\",\"authors\":[{\"authorId\":\"1379932763\",\"name\":\"Raghav Brahmadesam Venkataramaiyer\"},{\"authorId\":\"144000519\",\"name\":\"A. Joshi\"},{\"authorId\":\"2024769493\",\"name\":\"Saisha Narang\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"27dbd7475fa44365a9f3ade38f77eb222d9af5d9\",\"title\":\"SHAD3S: A model to Sketch, Shade and Shadow\",\"url\":\"https://www.semanticscholar.org/paper/27dbd7475fa44365a9f3ade38f77eb222d9af5d9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.05207\",\"authors\":[{\"authorId\":\"48174707\",\"name\":\"J. Lee\"},{\"authorId\":\"1438202579\",\"name\":\"Eungyeup Kim\"},{\"authorId\":\"46357976\",\"name\":\"Yunsung Lee\"},{\"authorId\":\"51999226\",\"name\":\"Dong-Jun Kim\"},{\"authorId\":\"14071669\",\"name\":\"Jaehyuk Chang\"},{\"authorId\":\"1795455\",\"name\":\"J. Choo\"}],\"doi\":\"10.1109/CVPR42600.2020.00584\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8c5aa40f3e7a804f1a6a644792deef9f8d810b83\",\"title\":\"Reference-Based Sketch Image Colorization Using Augmented-Self Reference and Dense Semantic Correspondence\",\"url\":\"https://www.semanticscholar.org/paper/8c5aa40f3e7a804f1a6a644792deef9f8d810b83\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2008.10774\",\"authors\":[{\"authorId\":\"49053414\",\"name\":\"S. Anwar\"},{\"authorId\":\"35801552\",\"name\":\"Muhammad Tahir\"},{\"authorId\":\"1608939378\",\"name\":\"Chongyi Li\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"},{\"authorId\":\"2358803\",\"name\":\"F. Khan\"},{\"authorId\":\"1950134\",\"name\":\"Abdul Wahab Muzaffar\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4da589d5400e8abf219d1c6d3157e9f2e56b86b5\",\"title\":\"Image Colorization: A Survey and Dataset\",\"url\":\"https://www.semanticscholar.org/paper/4da589d5400e8abf219d1c6d3157e9f2e56b86b5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.13611\",\"authors\":[{\"authorId\":\"9293325\",\"name\":\"M. Cai\"},{\"authorId\":\"9184786\",\"name\":\"H. Zhang\"},{\"authorId\":\"48186233\",\"name\":\"Huijuan Huang\"},{\"authorId\":\"34973011\",\"name\":\"Qichuan Geng\"},{\"authorId\":\"143983679\",\"name\":\"Gao Huang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4c0167a67292bf05e7d65f4fa2808f703a8a97d3\",\"title\":\"Frequency Domain Image Translation: More Photo-realistic, Better Identity-preserving\",\"url\":\"https://www.semanticscholar.org/paper/4c0167a67292bf05e7d65f4fa2808f703a8a97d3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145313141\",\"name\":\"Zhang Qian\"},{\"authorId\":\"1410131659\",\"name\":\"Wang Bo\"},{\"authorId\":\"152611046\",\"name\":\"W. Wei\"},{\"authorId\":\"144428674\",\"name\":\"L. Hai\"},{\"authorId\":\"144548758\",\"name\":\"L. Hui\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a1b4d574e2eb4309fa4369b1ceb772cd664cdbbf\",\"title\":\"Line Art Correlation Matching Network for Automatic Animation Colorization\",\"url\":\"https://www.semanticscholar.org/paper/a1b4d574e2eb4309fa4369b1ceb772cd664cdbbf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38957626\",\"name\":\"K. Akita\"},{\"authorId\":\"1877308882\",\"name\":\"Y. Morimoto\"},{\"authorId\":\"2832418\",\"name\":\"R. Tsuruno\"}],\"doi\":\"10.1111/cgf.14171\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ad8adbd99d50320789c06b5a6495b06b449efff0\",\"title\":\"Colorization of Line Drawings with Empty Pupils\",\"url\":\"https://www.semanticscholar.org/paper/ad8adbd99d50320789c06b5a6495b06b449efff0\",\"venue\":\"Comput. Graph. Forum\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2206122\",\"name\":\"Wenyuan Tao\"},{\"authorId\":\"50089974\",\"name\":\"H. Jiang\"},{\"authorId\":\"143844301\",\"name\":\"Q. Sun\"},{\"authorId\":\"50496117\",\"name\":\"Mu Zhang\"},{\"authorId\":\"98205005\",\"name\":\"K. Chen\"},{\"authorId\":\"1381741200\",\"name\":\"Marius Erdt\"}],\"doi\":\"10.1109/CW49994.2020.00013\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bd50d18ccba0a4123c15efdf41ee65f6ef558176\",\"title\":\"ArchGANs: stylized colorization prototyping for architectural line drawing\",\"url\":\"https://www.semanticscholar.org/paper/bd50d18ccba0a4123c15efdf41ee65f6ef558176\",\"venue\":\"2020 International Conference on Cyberworlds (CW)\",\"year\":2020},{\"arxivId\":\"2009.07557\",\"authors\":[{\"authorId\":\"35687142\",\"name\":\"Daichi Horita\"},{\"authorId\":\"46363837\",\"name\":\"K. Aizawa\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"62322d8a99260effc08fb4160b9e021d447fe8ff\",\"title\":\"SLGAN: Style- and Latent-guided Generative Adversarial Network for Desirable Makeup Transfer and Removal\",\"url\":\"https://www.semanticscholar.org/paper/62322d8a99260effc08fb4160b9e021d447fe8ff\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.00809\",\"authors\":[{\"authorId\":\"1387976657\",\"name\":\"Konstantin Sofiiuk\"},{\"authorId\":\"108531946\",\"name\":\"Polina Popenova\"},{\"authorId\":\"144608239\",\"name\":\"Anton Konushin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a2e311480f51439c6da27dbac82a3f43a718958a\",\"title\":\"Foreground-aware Semantic Representations for Image Harmonization\",\"url\":\"https://www.semanticscholar.org/paper/a2e311480f51439c6da27dbac82a3f43a718958a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.06718\",\"authors\":[{\"authorId\":\"145313141\",\"name\":\"Zhang Qian\"},{\"authorId\":\"1410131710\",\"name\":\"Wang Bo\"},{\"authorId\":\"152611046\",\"name\":\"W. Wei\"},{\"authorId\":\"144428674\",\"name\":\"L. Hai\"},{\"authorId\":\"144548758\",\"name\":\"L. Hui\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ab4afd91d3ce18fde1c24cfab8f95c48d9c8b45e\",\"title\":\"Line Art Correlation Matching Feature Transfer Network for Automatic Animation Colorization.\",\"url\":\"https://www.semanticscholar.org/paper/ab4afd91d3ce18fde1c24cfab8f95c48d9c8b45e\",\"venue\":\"\",\"year\":2020}],\"corpusId\":201058639,\"doi\":\"10.1109/ICCV.2019.00915\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":1,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"d57622db429112152ee726bbee80ddd567c342bc\",\"references\":[{\"arxivId\":\"1703.08966\",\"authors\":[{\"authorId\":\"1398077025\",\"name\":\"Edgar Simo-Serra\"},{\"authorId\":\"150298109\",\"name\":\"Satoshi Iizuka\"},{\"authorId\":\"66193516\",\"name\":\"H. Ishikawa\"}],\"doi\":\"10.1145/3132703\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"17f3f14c5e57462087b7cb6fee51567ade481e37\",\"title\":\"Mastering Sketching\",\"url\":\"https://www.semanticscholar.org/paper/17f3f14c5e57462087b7cb6fee51567ade481e37\",\"venue\":\"ACM Trans. Graph.\",\"year\":2018},{\"arxivId\":\"1707.06873\",\"authors\":[{\"authorId\":\"143626361\",\"name\":\"H. Dong\"},{\"authorId\":\"50443471\",\"name\":\"Simiao Yu\"},{\"authorId\":\"49762880\",\"name\":\"Chao Wu\"},{\"authorId\":\"3194920\",\"name\":\"Y. Guo\"}],\"doi\":\"10.1109/ICCV.2017.608\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5bb0e32d1e4d24e8e9f952d918c3d865c606d194\",\"title\":\"Semantic Image Synthesis via Adversarial Learning\",\"url\":\"https://www.semanticscholar.org/paper/5bb0e32d1e4d24e8e9f952d918c3d865c606d194\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1729041\",\"name\":\"J. Canny\"}],\"doi\":\"10.1109/TPAMI.1986.4767851\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fcf9fc4e23b45345c2404ce7d6cb0fc9dea2c9ec\",\"title\":\"A Computational Approach to Edge Detection\",\"url\":\"https://www.semanticscholar.org/paper/fcf9fc4e23b45345c2404ce7d6cb0fc9dea2c9ec\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":1986},{\"arxivId\":\"1706.03319\",\"authors\":[{\"authorId\":\"17744884\",\"name\":\"Lvmin Zhang\"},{\"authorId\":\"119035710\",\"name\":\"Yi Ji\"},{\"authorId\":\"145122731\",\"name\":\"Xin Lin\"}],\"doi\":\"10.1109/ACPR.2017.61\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d634ec5eed78f6411ea774cc99b068c539a44a6a\",\"title\":\"Style Transfer for Anime Sketches with Enhanced Residual U-net and Auxiliary Classifier GAN\",\"url\":\"https://www.semanticscholar.org/paper/d634ec5eed78f6411ea774cc99b068c539a44a6a\",\"venue\":\"2017 4th IAPR Asian Conference on Pattern Recognition (ACPR)\",\"year\":2017},{\"arxivId\":\"1711.06288\",\"authors\":[{\"authorId\":\"3111284\",\"name\":\"J. Chen\"},{\"authorId\":\"1752875\",\"name\":\"Y. Shen\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"1726477\",\"name\":\"J. Liu\"},{\"authorId\":\"1729368\",\"name\":\"X. Liu\"}],\"doi\":\"10.1109/CVPR.2018.00909\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d852da3f126ba2faca380064675a7af3805ec7cb\",\"title\":\"Language-Based Image Editing with Recurrent Attentive Models\",\"url\":\"https://www.semanticscholar.org/paper/d852da3f126ba2faca380064675a7af3805ec7cb\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1512.00567\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"144147316\",\"name\":\"S. Ioffe\"},{\"authorId\":\"103590098\",\"name\":\"Jon Shlens\"},{\"authorId\":\"3282833\",\"name\":\"Z. Wojna\"}],\"doi\":\"10.1109/CVPR.2016.308\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"23ffaa0fe06eae05817f527a47ac3291077f9e58\",\"title\":\"Rethinking the Inception Architecture for Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/23ffaa0fe06eae05817f527a47ac3291077f9e58\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Anonymous\"},{\"authorId\":null,\"name\":\"Danbooru community\"},{\"authorId\":null,\"name\":\"Gwern Branwen\"},{\"authorId\":null,\"name\":\"Aaron Gokaslan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Danbooru2017: A large-scale crowdsourced and tagged anime illustration dataset\",\"url\":\"\",\"venue\":\"https: //www.gwern.net/Danbooru2017,\",\"year\":2018},{\"arxivId\":\"1804.04128\",\"authors\":[{\"authorId\":\"41019737\",\"name\":\"Hyojin Bahng\"},{\"authorId\":\"41020567\",\"name\":\"Seungjoo Yoo\"},{\"authorId\":\"41021457\",\"name\":\"W. Cho\"},{\"authorId\":\"145966306\",\"name\":\"D. Park\"},{\"authorId\":\"121808924\",\"name\":\"Ziming Wu\"},{\"authorId\":\"3230330\",\"name\":\"Xiaojuan Ma\"},{\"authorId\":\"1795455\",\"name\":\"J. Choo\"}],\"doi\":\"10.1007/978-3-030-01258-8_27\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a5e53ff13cead01b1f73354bc31112abe8f27a75\",\"title\":\"Coloring with Words: Guiding Image Colorization Through Text-Based Palette Generation\",\"url\":\"https://www.semanticscholar.org/paper/a5e53ff13cead01b1f73354bc31112abe8f27a75\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1706.06759\",\"authors\":[{\"authorId\":\"3005586\",\"name\":\"Chie Furusawa\"},{\"authorId\":\"19252487\",\"name\":\"Kazuyuki Hiroshiba\"},{\"authorId\":\"32635753\",\"name\":\"K. Ogaki\"},{\"authorId\":\"18041930\",\"name\":\"Yuri Odagiri\"}],\"doi\":\"10.1145/3145749.3149430\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cb099882a728914aeee7f2b2a2f80cd8be758d08\",\"title\":\"Comicolorization: semi-automatic manga colorization\",\"url\":\"https://www.semanticscholar.org/paper/cb099882a728914aeee7f2b2a2f80cd8be758d08\",\"venue\":\"SIGGRAPH Asia Technical Briefs\",\"year\":2017},{\"arxivId\":\"1611.07004\",\"authors\":[{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"1822702\",\"name\":\"Tinghui Zhou\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1109/CVPR.2017.632\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8acbe90d5b852dadea7810345451a99608ee54c7\",\"title\":\"Image-to-Image Translation with Conditional Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/8acbe90d5b852dadea7810345451a99608ee54c7\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1505.04597\",\"authors\":[{\"authorId\":\"1737326\",\"name\":\"O. Ronneberger\"},{\"authorId\":\"152702479\",\"name\":\"P. Fischer\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1007/978-3-319-24574-4_28\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6364fdaa0a0eccd823a779fcdd489173f938e91a\",\"title\":\"U-Net: Convolutional Networks for Biomedical Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/6364fdaa0a0eccd823a779fcdd489173f938e91a\",\"venue\":\"MICCAI\",\"year\":2015},{\"arxivId\":\"1609.05158\",\"authors\":[{\"authorId\":\"2700496\",\"name\":\"W. Shi\"},{\"authorId\":\"145372820\",\"name\":\"J. Caballero\"},{\"authorId\":\"3108066\",\"name\":\"Ferenc Husz\\u00e1r\"},{\"authorId\":\"1853456\",\"name\":\"J. Totz\"},{\"authorId\":\"49931957\",\"name\":\"A. Aitken\"},{\"authorId\":\"50784424\",\"name\":\"R. Bishop\"},{\"authorId\":\"1717710\",\"name\":\"D. Rueckert\"},{\"authorId\":\"34627233\",\"name\":\"Zehan Wang\"}],\"doi\":\"10.1109/CVPR.2016.207\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"03a5b2aac53443e6078f0f63b35d4f95d6d54c5d\",\"title\":\"Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/03a5b2aac53443e6078f0f63b35d4f95d6d54c5d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1708.05509\",\"authors\":[{\"authorId\":\"2126155\",\"name\":\"Yanghua Jin\"},{\"authorId\":\"3393542\",\"name\":\"Jiakai Zhang\"},{\"authorId\":\"3700393\",\"name\":\"Minjun Li\"},{\"authorId\":\"48391641\",\"name\":\"Y. Tian\"},{\"authorId\":\"9339744\",\"name\":\"Huachun Zhu\"},{\"authorId\":\"9151252\",\"name\":\"Z. Fang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2759179c786f5eec95b4552910e2cace1899890e\",\"title\":\"Towards the Automatic Anime Characters Creation with Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/2759179c786f5eec95b4552910e2cace1899890e\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1804.06026\",\"authors\":[{\"authorId\":\"1977256\",\"name\":\"V. Manjunatha\"},{\"authorId\":\"2136562\",\"name\":\"Mohit Iyyer\"},{\"authorId\":\"1389036863\",\"name\":\"Jordan L. Boyd-Graber\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.18653/v1/N18-2120\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5ee96dd7e3395d8a53d6d3ceb62593477a4e0fe1\",\"title\":\"Learning to Color from Language\",\"url\":\"https://www.semanticscholar.org/paper/5ee96dd7e3395d8a53d6d3ceb62593477a4e0fe1\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144648787\",\"name\":\"M. Saito\"},{\"authorId\":\"46461083\",\"name\":\"Y. Matsui\"}],\"doi\":\"10.1145/2820903.2820907\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d32e360f6e88caeb0df031af7ad6d907b432ca1b\",\"title\":\"Illustration2Vec: a semantic vector representation of illustrations\",\"url\":\"https://www.semanticscholar.org/paper/d32e360f6e88caeb0df031af7ad6d907b432ca1b\",\"venue\":\"SIGGRAPH Asia Technical Briefs\",\"year\":2015},{\"arxivId\":\"1706.08500\",\"authors\":[{\"authorId\":\"2445103\",\"name\":\"Martin Heusel\"},{\"authorId\":\"19219270\",\"name\":\"Hubert Ramsauer\"},{\"authorId\":\"2465270\",\"name\":\"Thomas Unterthiner\"},{\"authorId\":\"37082831\",\"name\":\"Bernhard Nessler\"},{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"231af7dc01a166cac3b5b01ca05778238f796e41\",\"title\":\"GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium\",\"url\":\"https://www.semanticscholar.org/paper/231af7dc01a166cac3b5b01ca05778238f796e41\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1398077025\",\"name\":\"Edgar Simo-Serra\"},{\"authorId\":\"150298109\",\"name\":\"Satoshi Iizuka\"},{\"authorId\":\"2967000\",\"name\":\"K. Sasaki\"},{\"authorId\":\"66193516\",\"name\":\"H. Ishikawa\"}],\"doi\":\"10.1145/2897824.2925972\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"96cbfd42c4222c30161ac511e595bc85ed5a9487\",\"title\":\"Learning to simplify\",\"url\":\"https://www.semanticscholar.org/paper/96cbfd42c4222c30161ac511e595bc85ed5a9487\",\"venue\":\"ACM Trans. Graph.\",\"year\":2016},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"17744884\",\"name\":\"Lvmin Zhang\"},{\"authorId\":\"2294563\",\"name\":\"Chengze Li\"},{\"authorId\":\"1720633\",\"name\":\"T. Wong\"},{\"authorId\":\"144602988\",\"name\":\"Yi Ji\"},{\"authorId\":\"6681872\",\"name\":\"Chunping Liu\"}],\"doi\":\"10.1145/3272127.3275090\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"7d01e5c4ab3e4ddeadcda107d946a705c70ac4c8\",\"title\":\"Two-stage sketch colorization\",\"url\":\"https://www.semanticscholar.org/paper/7d01e5c4ab3e4ddeadcda107d946a705c70ac4c8\",\"venue\":\"ACM Trans. Graph.\",\"year\":2018},{\"arxivId\":\"1810.11919\",\"authors\":[{\"authorId\":\"7532506\",\"name\":\"Seonghyeon Nam\"},{\"authorId\":\"49170402\",\"name\":\"Yunji Kim\"},{\"authorId\":\"1754380\",\"name\":\"S. Kim\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c3c713fd66a9aff42b82894142c87adcf44084bd\",\"title\":\"Text-Adaptive Generative Adversarial Networks: Manipulating Images with Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/c3c713fd66a9aff42b82894142c87adcf44084bd\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1611.05431\",\"authors\":[{\"authorId\":\"1817030\",\"name\":\"Saining Xie\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"144035504\",\"name\":\"Zhuowen Tu\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"}],\"doi\":\"10.1109/CVPR.2017.634\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f6e0856b4a9199fa968ac00da612a9407b5cb85c\",\"title\":\"Aggregated Residual Transformations for Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/f6e0856b4a9199fa968ac00da612a9407b5cb85c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150298109\",\"name\":\"Satoshi Iizuka\"},{\"authorId\":\"1398077025\",\"name\":\"Edgar Simo-Serra\"},{\"authorId\":\"66193516\",\"name\":\"H. Ishikawa\"}],\"doi\":\"10.1145/2897824.2925974\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ec3453b0892ed8bf0531ffb5370c0159597eec11\",\"title\":\"Let there be color!\",\"url\":\"https://www.semanticscholar.org/paper/ec3453b0892ed8bf0531ffb5370c0159597eec11\",\"venue\":\"ACM Trans. Graph.\",\"year\":2016},{\"arxivId\":\"1612.00835\",\"authors\":[{\"authorId\":\"3430745\",\"name\":\"Patsorn Sangkloy\"},{\"authorId\":\"2054975\",\"name\":\"Jingwan Lu\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"1807197\",\"name\":\"F. Yu\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"}],\"doi\":\"10.1109/CVPR.2017.723\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4cf8e4dd94bf9f08d1d1c370ef05c0c0865c2858\",\"title\":\"Scribbler: Controlling Deep Image Synthesis with Sketch and Color\",\"url\":\"https://www.semanticscholar.org/paper/4cf8e4dd94bf9f08d1d1c370ef05c0c0865c2858\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1610.09585\",\"authors\":[{\"authorId\":\"2624088\",\"name\":\"Augustus Odena\"},{\"authorId\":\"37232298\",\"name\":\"Christopher Olah\"},{\"authorId\":\"1789737\",\"name\":\"Jonathon Shlens\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"ecc0edd450ae7e52f65ddf61405b30ad6dbabdd7\",\"title\":\"Conditional Image Synthesis with Auxiliary Classifier GANs\",\"url\":\"https://www.semanticscholar.org/paper/ecc0edd450ae7e52f65ddf61405b30ad6dbabdd7\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Varun Manjunatha\"},{\"authorId\":null,\"name\":\"Mohit Iyyer\"},{\"authorId\":null,\"name\":\"Jordan Boyd-Graber\"},{\"authorId\":null,\"name\":\"Larry Davis\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Learning to color from language. North American Chapter of the Association for Computational Linguistics (NAACL), 2018\",\"url\":\"\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1705.02999\",\"authors\":[{\"authorId\":\"2844849\",\"name\":\"Richard Zhang\"},{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"3468192\",\"name\":\"Xinyang Geng\"},{\"authorId\":\"145800141\",\"name\":\"A. Lin\"},{\"authorId\":\"10909315\",\"name\":\"Tianhe Yu\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1145/3072959.3073703\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b16b401ba4817bb42ef1ed5720da1709c56519ad\",\"title\":\"Real-time user-guided image colorization with learned deep priors\",\"url\":\"https://www.semanticscholar.org/paper/b16b401ba4817bb42ef1ed5720da1709c56519ad\",\"venue\":\"ACM Trans. Graph.\",\"year\":2017},{\"arxivId\":\"1709.01507\",\"authors\":[{\"authorId\":\"145815850\",\"name\":\"Jie Hu\"},{\"authorId\":\"152148573\",\"name\":\"L. Shen\"},{\"authorId\":\"152274574\",\"name\":\"Gang Sun\"}],\"doi\":\"10.1109/CVPR.2018.00745\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fb37561499573109fc2cebb6a7b08f44917267dd\",\"title\":\"Squeeze-and-Excitation Networks\",\"url\":\"https://www.semanticscholar.org/paper/fb37561499573109fc2cebb6a7b08f44917267dd\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1703.06868\",\"authors\":[{\"authorId\":\"144247007\",\"name\":\"X. Huang\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"}],\"doi\":\"10.1109/ICCV.2017.167\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"be0ef77fb0345c5851bb5d297f3ed84ae3c581ee\",\"title\":\"Arbitrary Style Transfer in Real-Time with Adaptive Instance Normalization\",\"url\":\"https://www.semanticscholar.org/paper/be0ef77fb0345c5851bb5d297f3ed84ae3c581ee\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1706.06918\",\"authors\":[{\"authorId\":\"19187505\",\"name\":\"Paulina Hensman\"},{\"authorId\":\"1712839\",\"name\":\"K. Aizawa\"}],\"doi\":\"10.1109/ICDAR.2017.295\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cb50d3080ab198741aa7ee87d285b984ea289100\",\"title\":\"cGAN-Based Manga Colorization Using a Single Training Image\",\"url\":\"https://www.semanticscholar.org/paper/cb50d3080ab198741aa7ee87d285b984ea289100\",\"venue\":\"2017 14th IAPR International Conference on Document Analysis and Recognition (ICDAR)\",\"year\":2017},{\"arxivId\":\"1808.03240\",\"authors\":[{\"authorId\":\"51214466\",\"name\":\"Yuanzheng Ci\"},{\"authorId\":\"7832311\",\"name\":\"Xinzhu Ma\"},{\"authorId\":\"1776856\",\"name\":\"Z. Wang\"},{\"authorId\":\"2579920\",\"name\":\"Haojie Li\"},{\"authorId\":\"145865683\",\"name\":\"Zhongxuan Luo\"}],\"doi\":\"10.1145/3240508.3240661\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6850306dfe557dc5eea689bb778f9033a203f3b3\",\"title\":\"User-Guided Deep Anime Line Art Colorization with Conditional Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/6850306dfe557dc5eea689bb778f9033a203f3b3\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1812.04948\",\"authors\":[{\"authorId\":\"2976930\",\"name\":\"Tero Karras\"},{\"authorId\":\"36436218\",\"name\":\"S. Laine\"},{\"authorId\":\"1761103\",\"name\":\"Timo Aila\"}],\"doi\":\"10.1109/CVPR.2019.00453\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ceb2ebef0b41e31c1a21b28c2734123900c005e2\",\"title\":\"A Style-Based Generator Architecture for Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/ceb2ebef0b41e31c1a21b28c2734123900c005e2\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1403025868\",\"name\":\"Jean Pouget-Abadie\"},{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"144738865\",\"name\":\"Bing Xu\"},{\"authorId\":\"1393680089\",\"name\":\"David Warde-Farley\"},{\"authorId\":\"1955694\",\"name\":\"Sherjil Ozair\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"title\":\"Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2168852\",\"name\":\"H. Winnem\\u00f6ller\"},{\"authorId\":\"1927808\",\"name\":\"J. E. Kyprianidis\"},{\"authorId\":\"2737807\",\"name\":\"S. Olsen\"}],\"doi\":\"10.1016/j.cag.2012.03.004\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b5062bbbee3ed3df984649a00872ac145e8c8aa3\",\"title\":\"XDoG: An eXtended difference-of-Gaussians compendium including advanced image stylization\",\"url\":\"https://www.semanticscholar.org/paper/b5062bbbee3ed3df984649a00872ac145e8c8aa3\",\"venue\":\"Comput. Graph.\",\"year\":2012},{\"arxivId\":\"1612.03242\",\"authors\":[{\"authorId\":\"120811666\",\"name\":\"Han Zhang\"},{\"authorId\":\"145017761\",\"name\":\"Tao Xu\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"}],\"doi\":\"10.1109/ICCV.2017.629\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ea67d2d5f2a7d5760ec6b67ea93d11dd5affa921\",\"title\":\"StackGAN: Text to Photo-Realistic Image Synthesis with Stacked Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/ea67d2d5f2a7d5760ec6b67ea93d11dd5affa921\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yanghua Jin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Make.girls.moe\",\"url\":\"\",\"venue\":\"\",\"year\":2017}],\"title\":\"Tag2Pix: Line Art Colorization Using Text Tag With SECat and Changing Loss\",\"topics\":[{\"topic\":\"Discriminator\",\"topicId\":\"41710\",\"url\":\"https://www.semanticscholar.org/topic/41710\"},{\"topic\":\"Grayscale\",\"topicId\":\"18096\",\"url\":\"https://www.semanticscholar.org/topic/18096\"},{\"topic\":\"Teaching method\",\"topicId\":\"73414\",\"url\":\"https://www.semanticscholar.org/topic/73414\"},{\"topic\":\"Encoder\",\"topicId\":\"16744\",\"url\":\"https://www.semanticscholar.org/topic/16744\"}],\"url\":\"https://www.semanticscholar.org/paper/d57622db429112152ee726bbee80ddd567c342bc\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019}\n"