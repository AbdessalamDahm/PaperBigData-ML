"{\"abstract\":\"Video captioning is a challenging task that involves not only visual perception but also syntax representation learning. Recent progress in video captioning has been achieved through visual perception, but syntax representation learning is still under-explored. We propose a novel video captioning approach that takes into account both visual perception and syntax representation learning to generate accurate descriptions of videos. Specifically, we use sentence templates composed of Part-of-Speech (POS) tags to represent the syntax structure of captions, and accordingly, syntax representation learning is performed by directly inferring POS tags from videos. The visual perception is implemented by a mixture model which translates visual cues into lexical words that are conditional on the learned syntactic structure of sentences. Thus, a video captioning task consists of two sub-tasks: video POS tagging and visual cue translation, which are jointly modeled and trained in an end-to-end fashion. Evaluations on three public benchmark datasets demonstrate that our proposed method achieves substantially better performance than the state-of-the-art methods, which validates the superiority of joint modeling of syntax representation learning and visual perception for video captioning.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"47286885\",\"name\":\"Jingyi Hou\",\"url\":\"https://www.semanticscholar.org/author/47286885\"},{\"authorId\":\"47149737\",\"name\":\"X. Wu\",\"url\":\"https://www.semanticscholar.org/author/47149737\"},{\"authorId\":\"29367810\",\"name\":\"Wentian Zhao\",\"url\":\"https://www.semanticscholar.org/author/29367810\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\",\"url\":\"https://www.semanticscholar.org/author/33642939\"},{\"authorId\":\"7415267\",\"name\":\"Y. Jia\",\"url\":\"https://www.semanticscholar.org/author/7415267\"}],\"citationVelocity\":6,\"citations\":[{\"arxivId\":\"2007.02375\",\"authors\":[{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"5891694\",\"name\":\"J. Luo\"},{\"authorId\":\"37184350\",\"name\":\"J. Xu\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"1490772804\",\"name\":\"Tao Mei\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ad9d41b29f7b7b35278f466dc2eafedaf7f57db1\",\"title\":\"Auto-captions on GIF: A Large-scale Video-sentence Dataset for Vision-language Pre-training\",\"url\":\"https://www.semanticscholar.org/paper/ad9d41b29f7b7b35278f466dc2eafedaf7f57db1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.09049\",\"authors\":[{\"authorId\":\"1810689822\",\"name\":\"Ganchao Tan\"},{\"authorId\":\"48929163\",\"name\":\"Daqing Liu\"},{\"authorId\":\"152808542\",\"name\":\"Meng Wang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"}],\"doi\":\"10.24963/ijcai.2020/104\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a7e8aeca681e6409aa73ab0f70ff9e6fb891d071\",\"title\":\"Learning to Discretely Compose Reasoning Module Networks for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/a7e8aeca681e6409aa73ab0f70ff9e6fb891d071\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":\"2003.13942\",\"authors\":[{\"authorId\":\"52170427\",\"name\":\"Boxiao Pan\"},{\"authorId\":\"30017683\",\"name\":\"Haoye Cai\"},{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"144015229\",\"name\":\"Kuan-Hui Lee\"},{\"authorId\":\"1799820\",\"name\":\"Adrien Gaidon\"},{\"authorId\":\"46408185\",\"name\":\"E. Adeli\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/cvpr42600.2020.01088\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a444d32f30d38fb0cb811fa1a9b601511244fb5b\",\"title\":\"Spatio-Temporal Graph for Video Captioning With Knowledge Distillation\",\"url\":\"https://www.semanticscholar.org/paper/a444d32f30d38fb0cb811fa1a9b601511244fb5b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2011.09530\",\"authors\":[{\"authorId\":\"153769937\",\"name\":\"H. Akbari\"},{\"authorId\":\"2542427\",\"name\":\"H. Palangi\"},{\"authorId\":\"120157163\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"1845230025\",\"name\":\"Sudha Rao\"},{\"authorId\":\"1709797\",\"name\":\"A. \\u00c7elikyilmaz\"},{\"authorId\":\"37409035\",\"name\":\"R. Fernandez\"},{\"authorId\":\"1748557\",\"name\":\"P. Smolensky\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"72197815\",\"name\":\"Shih-Fu Chang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c2b4d96db34bd472e84c9234838cc4e808eb1ba9\",\"title\":\"Neuro-Symbolic Representations for Video Captioning: A Case for Leveraging Inductive Biases for Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/c2b4d96db34bd472e84c9234838cc4e808eb1ba9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.11566\",\"authors\":[{\"authorId\":\"36811682\",\"name\":\"Z. Zhang\"},{\"authorId\":\"37198550\",\"name\":\"Yaya Shi\"},{\"authorId\":null,\"name\":\"Chunfeng Yuan\"},{\"authorId\":null,\"name\":\"Bing Li\"},{\"authorId\":\"39397292\",\"name\":\"Peijin Wang\"},{\"authorId\":\"48594951\",\"name\":\"Weiming Hu\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"}],\"doi\":\"10.1109/cvpr42600.2020.01329\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f1dd557a8839733a5ee06d19989a265e61f603c1\",\"title\":\"Object Relational Graph With Teacher-Recommended Learning for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/f1dd557a8839733a5ee06d19989a265e61f603c1\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2010.02824\",\"authors\":[{\"authorId\":\"1379929116\",\"name\":\"Mandela Patrick\"},{\"authorId\":\"2319973\",\"name\":\"Po-Yao Huang\"},{\"authorId\":\"144721617\",\"name\":\"Y. Asano\"},{\"authorId\":\"2048745\",\"name\":\"F. Metze\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"},{\"authorId\":\"145414740\",\"name\":\"J. Henriques\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"78bc767ebd02c0cc690fdb334c37bf64cfaf0115\",\"title\":\"Support-set bottlenecks for video-text representation learning\",\"url\":\"https://www.semanticscholar.org/paper/78bc767ebd02c0cc690fdb334c37bf64cfaf0115\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1909.00121\",\"authors\":[{\"authorId\":\"49178142\",\"name\":\"H. Chen\"},{\"authorId\":\"145468578\",\"name\":\"Ke Lin\"},{\"authorId\":\"1772128\",\"name\":\"A. Maye\"},{\"authorId\":\"47786863\",\"name\":\"J. Li\"},{\"authorId\":\"145460910\",\"name\":\"Xiaolin Hu\"}],\"doi\":\"10.3389/frobt.2020.475767\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"304f94dbe2ed228309e86298766ad24d9b6c6747\",\"title\":\"A Semantics-Assisted Video Captioning Model Trained With Scheduled Sampling\",\"url\":\"https://www.semanticscholar.org/paper/304f94dbe2ed228309e86298766ad24d9b6c6747\",\"venue\":\"Frontiers in Robotics and AI\",\"year\":2020},{\"arxivId\":\"2008.09791\",\"authors\":[{\"authorId\":\"46979645\",\"name\":\"J. Park\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"}],\"doi\":\"10.1007/978-3-030-58589-1_22\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"21a1b6f4f56c1fb6d844c5a1d971c59ab9cf81f7\",\"title\":\"Identity-Aware Multi-Sentence Video Description\",\"url\":\"https://www.semanticscholar.org/paper/21a1b6f4f56c1fb6d844c5a1d971c59ab9cf81f7\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1387548078\",\"name\":\"K. Lin\"},{\"authorId\":\"1738276592\",\"name\":\"Zhuoxin Gan\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.98\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3263b941d0a77bbd2040612ec774ef063ef64c48\",\"title\":\"Semi-Supervised Learning for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/3263b941d0a77bbd2040612ec774ef063ef64c48\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47860328\",\"name\":\"Shagun Uppal\"},{\"authorId\":\"73368394\",\"name\":\"Sarthak Bhagat\"},{\"authorId\":\"8223433\",\"name\":\"Devamanyu Hazarika\"},{\"authorId\":\"1999177921\",\"name\":\"Navonil Majumdar\"},{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"153015119\",\"name\":\"R. Zimmermann\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f23b548ff7b3517f028164a30c8bf186f11a1a6\",\"title\":\"Emerging Trends of Multimodal Research in Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/0f23b548ff7b3517f028164a30c8bf186f11a1a6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.11479\",\"authors\":[{\"authorId\":\"19198894\",\"name\":\"Humam Alwassel\"},{\"authorId\":\"22314218\",\"name\":\"Silvio Giancola\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5388388db25f0d40ef6612333a0279373f8dddcf\",\"title\":\"TSP: Temporally-Sensitive Pretraining of Video Encoders for Localization Tasks\",\"url\":\"https://www.semanticscholar.org/paper/5388388db25f0d40ef6612333a0279373f8dddcf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.08883\",\"authors\":[{\"authorId\":\"1500530481\",\"name\":\"Haoran Wang\"},{\"authorId\":\"72095125\",\"name\":\"Y. Zhang\"},{\"authorId\":\"21148831\",\"name\":\"Zhong Ji\"},{\"authorId\":\"48278149\",\"name\":\"Y. Pang\"},{\"authorId\":\"152309767\",\"name\":\"L. Ma\"}],\"doi\":\"10.1007/978-3-030-58586-0_2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fe573437cbd4069556348ad28dfeae2df46e22a0\",\"title\":\"Consensus-Aware Visual-Semantic Embedding for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/fe573437cbd4069556348ad28dfeae2df46e22a0\",\"venue\":\"ECCV\",\"year\":2020}],\"corpusId\":204955545,\"doi\":\"10.1109/ICCV.2019.00901\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":2,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"ce40cd5214d556e9b8ca8ca401597321cb29b8d6\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"144369161\",\"name\":\"Wei Qiu\"},{\"authorId\":\"144889265\",\"name\":\"Ivan Titov\"},{\"authorId\":\"1727272\",\"name\":\"Stefan Thater\"},{\"authorId\":\"1717560\",\"name\":\"Manfred Pinkal\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1109/ICCV.2013.61\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e8cd37fbd8bd5e690eef5861cf92af8e002d4533\",\"title\":\"Translating Video Content to Natural Language Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/e8cd37fbd8bd5e690eef5861cf92af8e002d4533\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"3006928\",\"name\":\"N. Krishnamoorthy\"},{\"authorId\":\"3163967\",\"name\":\"Girish Malkarnenkar\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/ICCV.2013.337\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d6a7a563640bf53953c4fda0997e4db176488510\",\"title\":\"YouTube2Text: Recognizing and Describing Arbitrary Activities Using Semantic Hierarchies and Zero-Shot Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d6a7a563640bf53953c4fda0997e4db176488510\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":\"1805.12589\",\"authors\":[{\"authorId\":\"31121723\",\"name\":\"A. Deshpande\"},{\"authorId\":\"29956361\",\"name\":\"Jyoti Aneja\"},{\"authorId\":\"39709900\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"144016256\",\"name\":\"D. Forsyth\"}],\"doi\":\"10.1109/CVPR.2019.01095\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e7fe886600399448f3282c8da8fd98ab7e50eae3\",\"title\":\"Fast, Diverse and Accurate Image Captioning Guided by Part-Of-Speech\",\"url\":\"https://www.semanticscholar.org/paper/e7fe886600399448f3282c8da8fd98ab7e50eae3\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1611.08002\",\"authors\":[{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"2750075\",\"name\":\"Y. Pu\"},{\"authorId\":\"143690259\",\"name\":\"K. Tran\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"}],\"doi\":\"10.1109/CVPR.2017.127\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"778ce81457383bd5e3fdb11b145ded202ebb4970\",\"title\":\"Semantic Compositional Networks for Visual Captioning\",\"url\":\"https://www.semanticscholar.org/paper/778ce81457383bd5e3fdb11b145ded202ebb4970\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1711.03953\",\"authors\":[{\"authorId\":\"47087291\",\"name\":\"Z. Yang\"},{\"authorId\":\"3422912\",\"name\":\"Zihang Dai\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"50056360\",\"name\":\"William W. Cohen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ef9ddbc35676ce8ffc2a8067044473727839dbac\",\"title\":\"Breaking the Softmax Bottleneck: A High-Rank RNN Language Model\",\"url\":\"https://www.semanticscholar.org/paper/ef9ddbc35676ce8ffc2a8067044473727839dbac\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"144478646\",\"name\":\"Z. Guo\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"47158869\",\"name\":\"Xing Xu\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1109/TMM.2017.2729019\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"51b2c1e750b1d3b893072829d012f2352d6bd373\",\"title\":\"Video Captioning With Attention-Based LSTM and Semantic Consistency\",\"url\":\"https://www.semanticscholar.org/paper/51b2c1e750b1d3b893072829d012f2352d6bd373\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2017},{\"arxivId\":\"1502.08029\",\"authors\":[{\"authorId\":\"145095579\",\"name\":\"L. Yao\"},{\"authorId\":\"1730844\",\"name\":\"Atousa Torabi\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"2482072\",\"name\":\"Nicolas Ballas\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":\"10.1109/ICCV.2015.512\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5f425b7abf2ed3172ed060df85bb1885860a297e\",\"title\":\"Describing Videos by Exploiting Temporal Structure\",\"url\":\"https://www.semanticscholar.org/paper/5f425b7abf2ed3172ed060df85bb1885860a297e\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Nianwen Xue\"},{\"authorId\":null,\"name\":\"Evan Steven Bird\"},{\"authorId\":null,\"name\":\"Edward Klein\"},{\"authorId\":null,\"name\":\"Loper\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Natural Language Processing with Python. o'reilly media\",\"url\":\"\",\"venue\":\"Natural Language Engineering\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1389724108\",\"name\":\"Chris Callison-Burch\"},{\"authorId\":\"2057788\",\"name\":\"M. Osborne\"},{\"authorId\":\"1755162\",\"name\":\"Philipp Koehn\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0a1f4cc5e1d7ccdce98c65545bbcccc23a6c16e7\",\"title\":\"Re-evaluation the Role of Bleu in Machine Translation Research\",\"url\":\"https://www.semanticscholar.org/paper/0a1f4cc5e1d7ccdce98c65545bbcccc23a6c16e7\",\"venue\":\"EACL\",\"year\":2006},{\"arxivId\":\"1904.03870\",\"authors\":[{\"authorId\":\"8511875\",\"name\":\"Jonghwan Mun\"},{\"authorId\":\"2889075\",\"name\":\"L. Yang\"},{\"authorId\":\"145888238\",\"name\":\"Zhou Ren\"},{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":\"10.1109/CVPR.2019.00675\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c5a757427132fda0c66e18a0d059eca8e2472d13\",\"title\":\"Streamlined Dense Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/c5a757427132fda0c66e18a0d059eca8e2472d13\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1510.07712\",\"authors\":[{\"authorId\":\"2910174\",\"name\":\"Haonan Yu\"},{\"authorId\":\"40579682\",\"name\":\"J. Wang\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"}],\"doi\":\"10.1109/CVPR.2016.496\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f678a0041f2c6f931168010e7418c500c3f14cdb\",\"title\":\"Video Paragraph Captioning Using Hierarchical Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/f678a0041f2c6f931168010e7418c500c3f14cdb\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1162/neco.1997.9.8.1735\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"title\":\"Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"venue\":\"Neural Computation\",\"year\":1997},{\"arxivId\":\"1505.00853\",\"authors\":[{\"authorId\":\"48310008\",\"name\":\"B. Xu\"},{\"authorId\":\"48246959\",\"name\":\"Naiyan Wang\"},{\"authorId\":\"1913774\",\"name\":\"T. Chen\"},{\"authorId\":null,\"name\":\"Mu Li\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"adf3b591281688b7e71b254ab931b2aa39b4b59f\",\"title\":\"Empirical Evaluation of Rectified Activations in Convolutional Network\",\"url\":\"https://www.semanticscholar.org/paper/adf3b591281688b7e71b254ab931b2aa39b4b59f\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1803.01457\",\"authors\":[{\"authorId\":\"40702813\",\"name\":\"Yangyu Chen\"},{\"authorId\":\"2538306\",\"name\":\"S. Wang\"},{\"authorId\":\"47527850\",\"name\":\"W. Zhang\"},{\"authorId\":\"1689702\",\"name\":\"Q. Huang\"}],\"doi\":\"10.1007/978-3-030-01261-8_22\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d5ff7a4580fbfdecc1d912746eee36980f29278b\",\"title\":\"Less Is More: Picking Informative Frames for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/d5ff7a4580fbfdecc1d912746eee36980f29278b\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145564333\",\"name\":\"G. Kulkarni\"},{\"authorId\":\"3128210\",\"name\":\"Visruth Premraj\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"2985883\",\"name\":\"Sagnik Dhar\"},{\"authorId\":\"50341924\",\"name\":\"Siming Li\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/TPAMI.2012.162\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5cb6700d94c6118ee13f4f4fecac99f111189812\",\"title\":\"BabyTalk: Understanding and Generating Simple Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/5cb6700d94c6118ee13f4f4fecac99f111189812\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2013},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2157958\",\"name\":\"Michael J. Denkowski\"},{\"authorId\":\"1784914\",\"name\":\"A. Lavie\"}],\"doi\":\"10.3115/v1/W14-3348\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"26adb749fc5d80502a6d889966e50b31391560d3\",\"title\":\"Meteor Universal: Language Specific Translation Evaluation for Any Target Language\",\"url\":\"https://www.semanticscholar.org/paper/26adb749fc5d80502a6d889966e50b31391560d3\",\"venue\":\"WMT@ACL\",\"year\":2014},{\"arxivId\":\"1411.5726\",\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2015.7299087\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"258986132bf17755fe8263e42429fe73218c1534\",\"title\":\"CIDEr: Consensus-based image description evaluation\",\"url\":\"https://www.semanticscholar.org/paper/258986132bf17755fe8263e42429fe73218c1534\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1611.07675\",\"authors\":[{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2017.111\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0d3b5ffff118326fea73341a86a7c29423eb95f0\",\"title\":\"Video Captioning with Transferred Semantic Attributes\",\"url\":\"https://www.semanticscholar.org/paper/0d3b5ffff118326fea73341a86a7c29423eb95f0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jimmy Lei\"},{\"authorId\":null,\"name\":\"Ryan Ba\"},{\"authorId\":null,\"name\":\"Geoffrey E Kiros\"},{\"authorId\":null,\"name\":\"Hinton\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Layer normalization. CoRR\",\"url\":\"\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1511.03476\",\"authors\":[{\"authorId\":\"1991108\",\"name\":\"P. Pan\"},{\"authorId\":\"2351434\",\"name\":\"Zhongwen Xu\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"},{\"authorId\":\"144894849\",\"name\":\"Fei Wu\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1109/CVPR.2016.117\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e9a66904559011d48245bba01e55f72246927e77\",\"title\":\"Hierarchical Recurrent Neural Encoder for Video Representation with Application to Captioning\",\"url\":\"https://www.semanticscholar.org/paper/e9a66904559011d48245bba01e55f72246927e77\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1504.00325\",\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"title\":\"Microsoft COCO Captions: Data Collection and Evaluation Server\",\"url\":\"https://www.semanticscholar.org/paper/696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3006928\",\"name\":\"N. Krishnamoorthy\"},{\"authorId\":\"3163967\",\"name\":\"Girish Malkarnenkar\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3b9f8101c61b415f946625b69f69fc9e3d0d6fc4\",\"title\":\"Generating Natural-Language Video Descriptions Using Text-Mined Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/3b9f8101c61b415f946625b69f69fc9e3d0d6fc4\",\"venue\":\"AAAI\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49693392\",\"name\":\"A. Kojima\"},{\"authorId\":\"46526487\",\"name\":\"Takeshi Tamura\"},{\"authorId\":\"145950023\",\"name\":\"K. Fukunaga\"}],\"doi\":\"10.1023/A:1020346032608\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d53a97a3dd7760b193c0d9a5293b60feff239059\",\"title\":\"Natural Language Description of Human Activities from Video Images Based on Concept Hierarchy of Actions\",\"url\":\"https://www.semanticscholar.org/paper/d53a97a3dd7760b193c0d9a5293b60feff239059\",\"venue\":\"International Journal of Computer Vision\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52014393\",\"name\":\"Ut Austin\"},{\"authorId\":\"123312980\",\"name\":\"Austin\"},{\"authorId\":\"102704114\",\"name\":\"UMass Lowell\"},{\"authorId\":\"102898595\",\"name\":\"Lowell\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"43795b7bac3d921c4e579964b54187bdbf6c6330\",\"title\":\"Translating Videos to Natural Language Using Deep Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/43795b7bac3d921c4e579964b54187bdbf6c6330\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1705.00754\",\"authors\":[{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"1382195702\",\"name\":\"Kenji Hata\"},{\"authorId\":\"3260219\",\"name\":\"F. Ren\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/ICCV.2017.83\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"96dd1fc39a368d23291816d57763bc6eb4f7b8d6\",\"title\":\"Dense-Captioning Events in Videos\",\"url\":\"https://www.semanticscholar.org/paper/96dd1fc39a368d23291816d57763bc6eb4f7b8d6\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/ICCV.2015.510\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"title\":\"Learning Spatiotemporal Features with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Subhashini Venugopalan\"},{\"authorId\":null,\"name\":\"Huijuan Xu\"},{\"authorId\":null,\"name\":\"Jeff Donahue\"},{\"authorId\":null,\"name\":\"Marcus Rohrbach\"},{\"authorId\":null,\"name\":\"J Raymond\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Mooney , and Kate Saenko . Translating videos to natural language using deep recurrent neural networks\",\"url\":\"\",\"venue\":\"In NAACL - HLT\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3407277\",\"name\":\"Adam Paszke\"},{\"authorId\":\"39793298\",\"name\":\"S. Gross\"},{\"authorId\":\"2127604\",\"name\":\"Soumith Chintala\"},{\"authorId\":\"114250963\",\"name\":\"G. Chanan\"},{\"authorId\":\"50064334\",\"name\":\"E. Yang\"},{\"authorId\":\"81505016\",\"name\":\"Zachary Devito\"},{\"authorId\":\"3370429\",\"name\":\"Zeming Lin\"},{\"authorId\":\"3050846\",\"name\":\"Alban Desmaison\"},{\"authorId\":\"3029482\",\"name\":\"L. Antiga\"},{\"authorId\":\"1977806\",\"name\":\"A. Lerer\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b36a5bb1707bb9c70025294b3a310138aae8327a\",\"title\":\"Automatic differentiation in PyTorch\",\"url\":\"https://www.semanticscholar.org/paper/b36a5bb1707bb9c70025294b3a310138aae8327a\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ajmal Mian\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Spatio - temporal dynamics and semantic attribute enriched visual encoding for video caption Schwing . Convolutional image captioning\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144603000\",\"name\":\"Xinwei He\"},{\"authorId\":\"2276155\",\"name\":\"Baoguang Shi\"},{\"authorId\":\"145905113\",\"name\":\"X. Bai\"},{\"authorId\":\"39943835\",\"name\":\"Gui-Song Xia\"},{\"authorId\":\"145274329\",\"name\":\"Zhaoxiang Zhang\"},{\"authorId\":\"2872774\",\"name\":\"W. Dong\"}],\"doi\":\"10.1016/J.PATREC.2017.10.018\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"390d0bb977b7473b8b76d045875c767d743de943\",\"title\":\"Image Caption Generation with Part of Speech Guidance\",\"url\":\"https://www.semanticscholar.org/paper/390d0bb977b7473b8b76d045875c767d743de943\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Kaiming He\"},{\"authorId\":null,\"name\":\"Xiangyu Zhang\"},{\"authorId\":null,\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Mooney , Trevor Darrell , and Kate Saenko . Youtube 2 text : Recognizing and describing arbitrary activities using semantic hierarchies and zero - shot recognition\",\"url\":\"\",\"venue\":\"In ICCV\",\"year\":2013},{\"arxivId\":\"1711.11135\",\"authors\":[{\"authorId\":\"48631993\",\"name\":\"Xin Eric Wang\"},{\"authorId\":\"2928777\",\"name\":\"Wenhu Chen\"},{\"authorId\":\"46365930\",\"name\":\"Jiawei Wu\"},{\"authorId\":\"1706938\",\"name\":\"Y. Wang\"},{\"authorId\":\"1682479\",\"name\":\"William Yang Wang\"}],\"doi\":\"10.1109/CVPR.2018.00443\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"74b284a66e75b65f5970d05bac000fe91243ee49\",\"title\":\"Video Captioning via Hierarchical Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/74b284a66e75b65f5970d05bac000fe91243ee49\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Nianwen Xue. Steven\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"bird, evan klein and edward loper\",\"url\":\"\",\"venue\":\"Natural Language Processing with Python. o\\u2019reilly media,\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1781574\",\"name\":\"Chin-Yew Lin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"60b05f32c32519a809f21642ef1eb3eaf3848008\",\"title\":\"ROUGE: A Package for Automatic Evaluation of Summaries\",\"url\":\"https://www.semanticscholar.org/paper/60b05f32c32519a809f21642ef1eb3eaf3848008\",\"venue\":\"ACL 2004\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145971173\",\"name\":\"J. Xu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/CVPR.2016.571\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b8e2e9f3ba008e28257195ec69a00e07f260131d\",\"title\":\"MSR-VTT: A Large Video Description Dataset for Bridging Video and Language\",\"url\":\"https://www.semanticscholar.org/paper/b8e2e9f3ba008e28257195ec69a00e07f260131d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1805.10829\",\"authors\":[{\"authorId\":\"29820421\",\"name\":\"Sekitoshi Kanai\"},{\"authorId\":\"144841089\",\"name\":\"Y. Fujiwara\"},{\"authorId\":\"144901814\",\"name\":\"Y. Yamanaka\"},{\"authorId\":\"2452040\",\"name\":\"S. Adachi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7b9256b9fc59404b4cfe8c60b3943f4e38360122\",\"title\":\"Sigsoftmax: Reanalysis of the Softmax Bottleneck\",\"url\":\"https://www.semanticscholar.org/paper/7b9256b9fc59404b4cfe8c60b3943f4e38360122\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1711.09151\",\"authors\":[{\"authorId\":\"29956361\",\"name\":\"Jyoti Aneja\"},{\"authorId\":\"113001756\",\"name\":\"A. Deshpande\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1109/CVPR.2018.00583\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"9fb5e3db385588f671b11cfc8bf18efb90ee7b19\",\"title\":\"Convolutional Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9fb5e3db385588f671b11cfc8bf18efb90ee7b19\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1505.00487\",\"authors\":[{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/ICCV.2015.515\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e58a110fa1e4ddf247d5c614d117d64bfbe135c4\",\"title\":\"Sequence to Sequence -- Video to Text\",\"url\":\"https://www.semanticscholar.org/paper/e58a110fa1e4ddf247d5c614d117d64bfbe135c4\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1804.03803\",\"authors\":[{\"authorId\":\"1887625\",\"name\":\"Yuehua Wu\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"39978626\",\"name\":\"Lu Jiang\"},{\"authorId\":null,\"name\":\"Yi Yang\"}],\"doi\":\"10.1145/3240508.3240640\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d64f52b94977b71976327eeb3db702b246ee39ce\",\"title\":\"Decoupled Novel Object Captioner\",\"url\":\"https://www.semanticscholar.org/paper/d64f52b94977b71976327eeb3db702b246ee39ce\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1804.08274\",\"authors\":[{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"47636228\",\"name\":\"H. Chao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2018.00782\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"19d7f83c3d7147f0eed1e1471438066eb4fe51fb\",\"title\":\"Jointly Localizing and Describing Events for Dense Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/19d7f83c3d7147f0eed1e1471438066eb4fe51fb\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Kaiming He\"},{\"authorId\":null,\"name\":\"Xiangyu Zhang\"},{\"authorId\":null,\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Mooney , Trevor Darrell , and Kate Saenko . Youtube 2 text : Recognizing and describing arbitrary activities using semantic hierarchies and zero - shot recognition\",\"url\":\"\",\"venue\":\"In ICCV\",\"year\":2013},{\"arxivId\":\"1803.11438\",\"authors\":[{\"authorId\":\"40892631\",\"name\":\"Bairui Wang\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"37378985\",\"name\":\"Wei Zhang\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"}],\"doi\":\"10.1109/CVPR.2018.00795\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ba7405516e1408f0ee6e0d0a8c6d511ce33c0551\",\"title\":\"Reconstruction Network for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/ba7405516e1408f0ee6e0d0a8c6d511ce33c0551\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1602.07261\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"144147316\",\"name\":\"S. Ioffe\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"122113652\",\"name\":\"Alexander Amir Alemi\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b5c26ab8767d046cb6e32d959fdf726aee89bb62\",\"title\":\"Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning\",\"url\":\"https://www.semanticscholar.org/paper/b5c26ab8767d046cb6e32d959fdf726aee89bb62\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36924412\",\"name\":\"Jes\\u00fas Gim\\u00e9nez\"},{\"authorId\":\"3049328\",\"name\":\"Llu\\u00eds M\\u00e0rquez i Villodre\"}],\"doi\":\"10.3115/1626355.1626393\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c365683ce624f3fc79450ec9232893f85ca31080\",\"title\":\"Linguistic Features for Automatic Evaluation of Heterogenous MT Systems\",\"url\":\"https://www.semanticscholar.org/paper/c365683ce624f3fc79450ec9232893f85ca31080\",\"venue\":\"WMT@ACL\",\"year\":2007},{\"arxivId\":\"1902.10322\",\"authors\":[{\"authorId\":\"50978260\",\"name\":\"Nayyer Aafaq\"},{\"authorId\":\"47398812\",\"name\":\"N. Akhtar\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"1746166\",\"name\":\"Syed Zulqarnain Gilani\"},{\"authorId\":\"46332747\",\"name\":\"A. Mian\"}],\"doi\":\"10.1109/CVPR.2019.01277\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"20888a7aebaf77a306c0886f165bd0d468db806d\",\"title\":\"Spatio-Temporal Dynamics and Semantic Attribute Enriched Visual Encoding for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/20888a7aebaf77a306c0886f165bd0d468db806d\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1611.09312\",\"authors\":[{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"153925540\",\"name\":\"C. Grana\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/CVPR.2017.339\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"726b1ade8b3d0023f0b4a9f86b7c2c3004885e37\",\"title\":\"Hierarchical Boundary-Aware Neural Encoder for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/726b1ade8b3d0023f0b4a9f86b7c2c3004885e37\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46583706\",\"name\":\"J. Wang\"},{\"authorId\":\"145200778\",\"name\":\"Wei Wang\"},{\"authorId\":\"49867037\",\"name\":\"Y. Huang\"},{\"authorId\":\"40476140\",\"name\":\"Liang Wang\"},{\"authorId\":\"143874948\",\"name\":\"T. Tan\"}],\"doi\":\"10.1109/CVPR.2018.00784\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b910a6f687a4e56062dc326786cee297bd60e8c1\",\"title\":\"M3: Multimodal Memory Modelling for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/b910a6f687a4e56062dc326786cee297bd60e8c1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1702849\",\"name\":\"N. Xue\"}],\"doi\":\"10.1017/S1351324910000306\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f1942199cd90eae9a91ec2beb33935e61927a210\",\"title\":\"Steven Bird, Evan Klein and Edward Loper. Natural Language Processing with Python. O'Reilly Media, Inc 2009. ISBN: 978-0-596-51649-9\",\"url\":\"https://www.semanticscholar.org/paper/f1942199cd90eae9a91ec2beb33935e61927a210\",\"venue\":\"Nat. Lang. Eng.\",\"year\":2011},{\"arxivId\":\"1803.09845\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"94908120\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2018.00754\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3bf09b2e2639add154a9fe6ff98cc373d3e90e4e\",\"title\":\"Neural Baby Talk\",\"url\":\"https://www.semanticscholar.org/paper/3bf09b2e2639add154a9fe6ff98cc373d3e90e4e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3323275\",\"name\":\"Kishore Papineni\"},{\"authorId\":\"1781292\",\"name\":\"S. Roukos\"},{\"authorId\":\"144582029\",\"name\":\"T. Ward\"},{\"authorId\":\"2587983\",\"name\":\"Wei-Jing Zhu\"}],\"doi\":\"10.3115/1073083.1073135\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d7da009f457917aa381619facfa5ffae9329a6e9\",\"title\":\"Bleu: a Method for Automatic Evaluation of Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/d7da009f457917aa381619facfa5ffae9329a6e9\",\"venue\":\"ACL\",\"year\":2002},{\"arxivId\":\"1308.0850\",\"authors\":[{\"authorId\":\"1753223\",\"name\":\"A. Graves\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"89b1f4740ae37fd04f6ac007577bdd34621f0861\",\"title\":\"Generating Sequences With Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/89b1f4740ae37fd04f6ac007577bdd34621f0861\",\"venue\":\"ArXiv\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153642390\",\"name\":\"David L. Chen\"},{\"authorId\":\"83415753\",\"name\":\"W. Dolan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"554a31ce91189cf6022ac677413ef2f8b9b40ca7\",\"title\":\"Collecting Highly Parallel Data for Paraphrase Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/554a31ce91189cf6022ac677413ef2f8b9b40ca7\",\"venue\":\"ACL 2011\",\"year\":2011}],\"title\":\"Joint Syntax Representation Learning and Visual Cue Translation for Video Captioning\",\"topics\":[{\"topic\":\"Feature learning\",\"topicId\":\"20551\",\"url\":\"https://www.semanticscholar.org/topic/20551\"},{\"topic\":\"Mixture model\",\"topicId\":\"3712\",\"url\":\"https://www.semanticscholar.org/topic/3712\"},{\"topic\":\"Video\",\"topicId\":\"120294\",\"url\":\"https://www.semanticscholar.org/topic/120294\"},{\"topic\":\"Part-of-speech tagging\",\"topicId\":\"82770\",\"url\":\"https://www.semanticscholar.org/topic/82770\"},{\"topic\":\"Brown Corpus\",\"topicId\":\"304872\",\"url\":\"https://www.semanticscholar.org/topic/304872\"},{\"topic\":\"Machine learning\",\"topicId\":\"168\",\"url\":\"https://www.semanticscholar.org/topic/168\"},{\"topic\":\"End-to-end principle\",\"topicId\":\"299633\",\"url\":\"https://www.semanticscholar.org/topic/299633\"},{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"},{\"topic\":\"Natural language\",\"topicId\":\"1911\",\"url\":\"https://www.semanticscholar.org/topic/1911\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"}],\"url\":\"https://www.semanticscholar.org/paper/ce40cd5214d556e9b8ca8ca401597321cb29b8d6\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019}\n"