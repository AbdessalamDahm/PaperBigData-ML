"{\"abstract\":\"Deep generative models have led to significant advances in cross-modal generation such as text-to-image synthesis. Training these models typically requires paired data with direct correspondence between modalities. We introduce the novel problem of translating instances from one modality to another without paired data by leveraging an intermediate modality shared by the two other modalities. To demonstrate this, we take the problem of translating images to speech. In this case, one could leverage disjoint datasets with one shared modality, e.g., image-text pairs and text-speech pairs, with text as the shared modality. We call this problem ``skip-modal generation'' because the shared modality is skipped during the generation process. We propose a multimodal information bottleneck approach that learns the correspondence between modalities from unpaired data (image and speech) by leveraging the shared modality (text). We address fundamental challenges of skip-modal generation: 1) learning multimodal representations using a single model, 2) bridging the domain gap between two unrelated datasets, and 3) learning the correspondence between modalities from unpaired data. We show qualitative results on image-to-speech synthesis; this is the first time such results have been reported in the literature. We also show that our approach improves performance on traditional cross-modal generation, suggesting that it improves data efficiency in solving individual tasks.\",\"arxivId\":\"1908.07094\",\"authors\":[{\"authorId\":\"145798572\",\"name\":\"S. Ma\",\"url\":\"https://www.semanticscholar.org/author/145798572\"},{\"authorId\":\"1801452\",\"name\":\"D. McDuff\",\"url\":\"https://www.semanticscholar.org/author/1801452\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\",\"url\":\"https://www.semanticscholar.org/author/2317183\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":\"2006.16228\",\"authors\":[{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"39257069\",\"name\":\"A. Recasens\"},{\"authorId\":\"145721402\",\"name\":\"Ros\\u00e1lia G. Schneider\"},{\"authorId\":\"2299479\",\"name\":\"R. Arandjelovi\\u0107\"},{\"authorId\":\"16092809\",\"name\":\"Jason Ramapuram\"},{\"authorId\":\"3364908\",\"name\":\"J. Fauw\"},{\"authorId\":\"1466466597\",\"name\":\"Lucas Smaira\"},{\"authorId\":\"48373216\",\"name\":\"S. Dieleman\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4174f03c7d8d9add62ae4ecd0ec90efba680b7ae\",\"title\":\"Self-Supervised MultiModal Versatile Networks\",\"url\":\"https://www.semanticscholar.org/paper/4174f03c7d8d9add62ae4ecd0ec90efba680b7ae\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2012.15454\",\"authors\":[{\"authorId\":null,\"name\":\"Wei-Ning Hsu\"},{\"authorId\":null,\"name\":\"David Harwath\"},{\"authorId\":null,\"name\":\"Christopher Song\"},{\"authorId\":\"152450847\",\"name\":\"J. Glass\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5df12460d9a742b08f82e8b79cb102a8be5dd9b4\",\"title\":\"Text-Free Image-to-Speech Synthesis Using Learned Segmental Units\",\"url\":\"https://www.semanticscholar.org/paper/5df12460d9a742b08f82e8b79cb102a8be5dd9b4\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2006.04641\",\"authors\":[{\"authorId\":\"1389050462\",\"name\":\"Zoe Piran\"},{\"authorId\":\"1777660\",\"name\":\"Naftali Tishby\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7420a4a01ec844432db034f959c6823a72e12b68\",\"title\":\"The Dual Information Bottleneck\",\"url\":\"https://www.semanticscholar.org/paper/7420a4a01ec844432db034f959c6823a72e12b68\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":201103719,\"doi\":\"10.1109/ICCV.2019.00769\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"e1e1feac96004866052787115ea08a4dcdd888b9\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1977452\",\"name\":\"P. Pietrini\"},{\"authorId\":\"2944424\",\"name\":\"M. Furey\"},{\"authorId\":\"3136019\",\"name\":\"E. Ricciardi\"},{\"authorId\":\"1982106\",\"name\":\"M. I. Gobbini\"},{\"authorId\":\"122265017\",\"name\":\"W-H Wu\"},{\"authorId\":\"152659842\",\"name\":\"L. Cohen\"},{\"authorId\":\"1927285\",\"name\":\"M. Guazzelli\"},{\"authorId\":\"2327323\",\"name\":\"J. Haxby\"}],\"doi\":\"10.1073/PNAS.0400707101\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"05bd005b171e9196dc63e4ca177e05261b9eceb8\",\"title\":\"Beyond sensory images: Object-based representation in the human ventral pathway.\",\"url\":\"https://www.semanticscholar.org/paper/05bd005b171e9196dc63e4ca177e05261b9eceb8\",\"venue\":\"Proceedings of the National Academy of Sciences of the United States of America\",\"year\":2004},{\"arxivId\":\"1802.06984\",\"authors\":[{\"authorId\":\"3436681\",\"name\":\"Eliya Nachmani\"},{\"authorId\":\"33964593\",\"name\":\"A. Polyak\"},{\"authorId\":\"2188620\",\"name\":\"Yaniv Taigman\"},{\"authorId\":\"145128145\",\"name\":\"Lior Wolf\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7386e389b07718ee0b132364b82a458aeeaeb15c\",\"title\":\"Fitting New Speakers Based on a Short Untranscribed Sample\",\"url\":\"https://www.semanticscholar.org/paper/7386e389b07718ee0b132364b82a458aeeaeb15c\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":\"1608.06993\",\"authors\":[{\"authorId\":\"143983679\",\"name\":\"Gao Huang\"},{\"authorId\":null,\"name\":\"Zhuang Liu\"},{\"authorId\":\"7446832\",\"name\":\"Kilian Q. Weinberger\"}],\"doi\":\"10.1109/CVPR.2017.243\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5694e46284460a648fe29117cbc55f6c9be3fa3c\",\"title\":\"Densely Connected Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/5694e46284460a648fe29117cbc55f6c9be3fa3c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1409.7495\",\"authors\":[{\"authorId\":\"2825246\",\"name\":\"Yaroslav Ganin\"},{\"authorId\":\"1740145\",\"name\":\"V. Lempitsky\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2530cfc7764bda1330c48c0c8e2cd0e0c671d7e1\",\"title\":\"Unsupervised Domain Adaptation by Backpropagation\",\"url\":\"https://www.semanticscholar.org/paper/2530cfc7764bda1330c48c0c8e2cd0e0c671d7e1\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1603.03925\",\"authors\":[{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2016.503\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"bf55591e09b58ea9ce8d66110d6d3000ee804bdd\",\"title\":\"Image Captioning with Semantic Attention\",\"url\":\"https://www.semanticscholar.org/paper/bf55591e09b58ea9ce8d66110d6d3000ee804bdd\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1805.07030\",\"authors\":[{\"authorId\":\"3175685\",\"name\":\"A. Mathews\"},{\"authorId\":\"33650938\",\"name\":\"Lexing Xie\"},{\"authorId\":\"33913193\",\"name\":\"Xuming He\"}],\"doi\":\"10.1109/CVPR.2018.00896\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"beeebd2af0d8f130dcf234231de4569d584cb7fd\",\"title\":\"SemStyle: Learning to Generate Stylised Image Captions Using Unaligned Text\",\"url\":\"https://www.semanticscholar.org/paper/beeebd2af0d8f130dcf234231de4569d584cb7fd\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"144580027\",\"name\":\"Dong Yu\"},{\"authorId\":\"35188630\",\"name\":\"G. Dahl\"},{\"authorId\":\"40360972\",\"name\":\"Abdel-rahman Mohamed\"},{\"authorId\":\"3111912\",\"name\":\"Navdeep Jaitly\"},{\"authorId\":\"33666044\",\"name\":\"A. Senior\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"14902530\",\"name\":\"P. Nguyen\"},{\"authorId\":\"98801017\",\"name\":\"Tara Sainath\"},{\"authorId\":\"144707379\",\"name\":\"Brian Kingsbury\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e33cbb25a8c7390aec6a398e36381f4f7770c283\",\"title\":\"Deep Neural Networks for Acoustic Modeling in Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e33cbb25a8c7390aec6a398e36381f4f7770c283\",\"venue\":\"\",\"year\":2012},{\"arxivId\":\"1611.07004\",\"authors\":[{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"1822702\",\"name\":\"Tinghui Zhou\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1109/CVPR.2017.632\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8acbe90d5b852dadea7810345451a99608ee54c7\",\"title\":\"Image-to-Image Translation with Conditional Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/8acbe90d5b852dadea7810345451a99608ee54c7\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1703.10135\",\"authors\":[{\"authorId\":null,\"name\":\"Yuxuan Wang\"},{\"authorId\":\"1380248814\",\"name\":\"R. Skerry-Ryan\"},{\"authorId\":\"39741369\",\"name\":\"Daisy Stanton\"},{\"authorId\":\"1780996\",\"name\":\"Y. Wu\"},{\"authorId\":\"39571582\",\"name\":\"Ron J. Weiss\"},{\"authorId\":\"3111912\",\"name\":\"Navdeep Jaitly\"},{\"authorId\":\"1867996\",\"name\":\"Z. Yang\"},{\"authorId\":\"152130121\",\"name\":\"Y. Xiao\"},{\"authorId\":\"2545358\",\"name\":\"Z. Chen\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"},{\"authorId\":\"2259013\",\"name\":\"Yannis Agiomyrgiannakis\"},{\"authorId\":\"49343861\",\"name\":\"R. Clark\"},{\"authorId\":\"2278009\",\"name\":\"R. A. Saurous\"}],\"doi\":\"10.21437/INTERSPEECH.2017-1452\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a072c2a400f62f720b68dc54a662fb1ae115bf06\",\"title\":\"Tacotron: Towards End-to-End Speech Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/a072c2a400f62f720b68dc54a662fb1ae115bf06\",\"venue\":\"INTERSPEECH\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143778281\",\"name\":\"J. Sotelo\"},{\"authorId\":\"34719201\",\"name\":\"Soroush Mehri\"},{\"authorId\":\"145411463\",\"name\":\"K. Kumar\"},{\"authorId\":\"144660120\",\"name\":\"J. F. Santos\"},{\"authorId\":\"2182706\",\"name\":\"Kyle Kastner\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9203d6c076bffe87336f2ea91f5851436c02dbe6\",\"title\":\"Char2Wav: End-to-End Speech Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/9203d6c076bffe87336f2ea91f5851436c02dbe6\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1803.09017\",\"authors\":[{\"authorId\":null,\"name\":\"Yuxuan Wang\"},{\"authorId\":\"39741369\",\"name\":\"Daisy Stanton\"},{\"authorId\":\"145954570\",\"name\":\"Yu Zhang\"},{\"authorId\":\"1380248814\",\"name\":\"R. Skerry-Ryan\"},{\"authorId\":\"5697774\",\"name\":\"Eric Battenberg\"},{\"authorId\":\"30418264\",\"name\":\"Joel Shor\"},{\"authorId\":\"152130121\",\"name\":\"Y. Xiao\"},{\"authorId\":\"153311281\",\"name\":\"F. Ren\"},{\"authorId\":\"1691944\",\"name\":\"Ye Jia\"},{\"authorId\":\"2278009\",\"name\":\"R. A. Saurous\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1db4d7cf784e53f62ffe414bbde2cdcd770e579f\",\"title\":\"Style Tokens: Unsupervised Style Modeling, Control and Transfer in End-to-End Speech Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/1db4d7cf784e53f62ffe414bbde2cdcd770e579f\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1605.05396\",\"authors\":[{\"authorId\":\"144828948\",\"name\":\"S. Reed\"},{\"authorId\":\"2893664\",\"name\":\"Zeynep Akata\"},{\"authorId\":\"3084614\",\"name\":\"Xinchen Yan\"},{\"authorId\":\"2876316\",\"name\":\"L. Logeswaran\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c7f040a150abf21dbcefe1f22e0f98fa184f41a\",\"title\":\"Generative Adversarial Text to Image Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/6c7f040a150abf21dbcefe1f22e0f98fa184f41a\",\"venue\":\"ICML\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48190580\",\"name\":\"D. Griffin\"},{\"authorId\":\"49719219\",\"name\":\"J. Lim\"}],\"doi\":\"10.1109/TASSP.1984.1164317\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"83179cfc937dfd62513282854e357c7f38fecda8\",\"title\":\"Signal estimation from modified short-time Fourier transform\",\"url\":\"https://www.semanticscholar.org/paper/83179cfc937dfd62513282854e357c7f38fecda8\",\"venue\":\"\",\"year\":1984},{\"arxivId\":\"1602.07332\",\"authors\":[{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"50499889\",\"name\":\"O. Groth\"},{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"1382195702\",\"name\":\"Kenji Hata\"},{\"authorId\":\"40591424\",\"name\":\"J. Kravitz\"},{\"authorId\":\"6000646\",\"name\":\"Stephanie Chen\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"1388344504\",\"name\":\"David A. Shamma\"},{\"authorId\":\"1379506718\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-016-0981-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"title\":\"Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations\",\"url\":\"https://www.semanticscholar.org/paper/afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":\"1712.01769\",\"authors\":[{\"authorId\":\"145039780\",\"name\":\"Chung-Cheng Chiu\"},{\"authorId\":\"1784851\",\"name\":\"T. Sainath\"},{\"authorId\":\"1780996\",\"name\":\"Y. Wu\"},{\"authorId\":\"2557391\",\"name\":\"Rohit Prabhavalkar\"},{\"authorId\":\"40133958\",\"name\":\"Patrick Nguyen\"},{\"authorId\":\"2545358\",\"name\":\"Z. Chen\"},{\"authorId\":\"31801501\",\"name\":\"A. Kannan\"},{\"authorId\":\"39571582\",\"name\":\"Ron J. Weiss\"},{\"authorId\":\"2251957\",\"name\":\"K. Rao\"},{\"authorId\":\"1398413062\",\"name\":\"Katya Gonina\"},{\"authorId\":\"3111912\",\"name\":\"Navdeep Jaitly\"},{\"authorId\":\"143771569\",\"name\":\"Bo Li\"},{\"authorId\":\"2292403\",\"name\":\"J. Chorowski\"},{\"authorId\":\"1771090\",\"name\":\"M. Bacchiani\"}],\"doi\":\"10.1109/ICASSP.2018.8462105\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c6b61535f1544835cca3851ceb34222ebc5b4377\",\"title\":\"State-of-the-Art Speech Recognition with Sequence-to-Sequence Models\",\"url\":\"https://www.semanticscholar.org/paper/c6b61535f1544835cca3851ceb34222ebc5b4377\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":\"1410.3916\",\"authors\":[{\"authorId\":\"145183709\",\"name\":\"J. Weston\"},{\"authorId\":\"3295092\",\"name\":\"S. Chopra\"},{\"authorId\":\"1713934\",\"name\":\"Antoine Bordes\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"71ae756c75ac89e2d731c9c79649562b5768ff39\",\"title\":\"Memory Networks\",\"url\":\"https://www.semanticscholar.org/paper/71ae756c75ac89e2d731c9c79649562b5768ff39\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1712.07101\",\"authors\":[{\"authorId\":\"34872128\",\"name\":\"Yingbo Zhou\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":\"10.1109/ICASSP.2018.8462361\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"527dc08f670981d22bfeb831d9e249d25a449380\",\"title\":\"Improving End-to-End Speech Recognition with Policy Learning\",\"url\":\"https://www.semanticscholar.org/paper/527dc08f670981d22bfeb831d9e249d25a449380\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1511.05440\",\"authors\":[{\"authorId\":\"143949035\",\"name\":\"Micha\\u00ebl Mathieu\"},{\"authorId\":\"2341378\",\"name\":\"C. Couprie\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"17fa1c2a24ba8f731c8b21f1244463bc4b465681\",\"title\":\"Deep multi-scale video prediction beyond mean square error\",\"url\":\"https://www.semanticscholar.org/paper/17fa1c2a24ba8f731c8b21f1244463bc4b465681\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2188620\",\"name\":\"Yaniv Taigman\"},{\"authorId\":\"145128145\",\"name\":\"Lior Wolf\"},{\"authorId\":\"33964593\",\"name\":\"A. Polyak\"},{\"authorId\":\"3436681\",\"name\":\"Eliya Nachmani\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7e8f697f19c5d7d95f859e1ad6bcc219a902f52b\",\"title\":\"VoiceLoop: Voice Fitting and Synthesis via a Phonological Loop\",\"url\":\"https://www.semanticscholar.org/paper/7e8f697f19c5d7d95f859e1ad6bcc219a902f52b\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1506.01497\",\"authors\":[{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"144716314\",\"name\":\"J. Sun\"}],\"doi\":\"10.1109/TPAMI.2016.2577031\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"title\":\"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\",\"url\":\"https://www.semanticscholar.org/paper/424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2015},{\"arxivId\":\"1712.01393\",\"authors\":[{\"authorId\":\"49455017\",\"name\":\"Yipin Zhou\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"145262461\",\"name\":\"Trung Bui\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/CVPR.2018.00374\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f2d126e02401ec9f3c131eac423620529996df2f\",\"title\":\"Visual to Sound: Generating Natural Sound for Videos in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/f2d126e02401ec9f3c131eac423620529996df2f\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1706.03762\",\"authors\":[{\"authorId\":\"40348417\",\"name\":\"Ashish Vaswani\"},{\"authorId\":\"1846258\",\"name\":\"Noam Shazeer\"},{\"authorId\":\"3877127\",\"name\":\"Niki Parmar\"},{\"authorId\":\"39328010\",\"name\":\"Jakob Uszkoreit\"},{\"authorId\":\"145024664\",\"name\":\"Llion Jones\"},{\"authorId\":\"19177000\",\"name\":\"Aidan N. Gomez\"},{\"authorId\":\"40527594\",\"name\":\"L. Kaiser\"},{\"authorId\":\"3443442\",\"name\":\"Illia Polosukhin\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"204e3073870fae3d05bcbc2f6a8e263d9b72e776\",\"title\":\"Attention is All you Need\",\"url\":\"https://www.semanticscholar.org/paper/204e3073870fae3d05bcbc2f6a8e263d9b72e776\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1702.07825\",\"authors\":[{\"authorId\":\"2676352\",\"name\":\"Sercan \\u00d6. Arik\"},{\"authorId\":\"35977287\",\"name\":\"M. Chrzanowski\"},{\"authorId\":\"144638694\",\"name\":\"A. Coates\"},{\"authorId\":\"2040049\",\"name\":\"G. Diamos\"},{\"authorId\":\"9544702\",\"name\":\"Andrew Gibiansky\"},{\"authorId\":\"1729563\",\"name\":\"Yongguo Kang\"},{\"authorId\":\"2745494\",\"name\":\"X. Li\"},{\"authorId\":\"152617830\",\"name\":\"J. Miller\"},{\"authorId\":\"145175379\",\"name\":\"Andrew Ng\"},{\"authorId\":\"34042420\",\"name\":\"Jonathan Raiman\"},{\"authorId\":\"2264597\",\"name\":\"S. Sengupta\"},{\"authorId\":\"1911755\",\"name\":\"M. Shoeybi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"63880b57b95de8afd73036e55b9c4bccb7a528b9\",\"title\":\"Deep Voice: Real-time Neural Text-to-Speech\",\"url\":\"https://www.semanticscholar.org/paper/63880b57b95de8afd73036e55b9c4bccb7a528b9\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":\"1807.09986\",\"authors\":[{\"authorId\":\"2093119\",\"name\":\"W. Jiang\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"38144094\",\"name\":\"T. Zhang\"}],\"doi\":\"10.1007/978-3-030-01216-8_31\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"04cd9168dcf1a0d2cf01db95a1af53d0900bc346\",\"title\":\"Recurrent Fusion Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/04cd9168dcf1a0d2cf01db95a1af53d0900bc346\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1712.09444\",\"authors\":[{\"authorId\":\"1680679\",\"name\":\"Vitaliy Liptchinsky\"},{\"authorId\":\"2282478\",\"name\":\"Gabriel Synnaeve\"},{\"authorId\":\"2939803\",\"name\":\"Ronan Collobert\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"da8c898dfe4804ed60833ee0d019969a8c588a46\",\"title\":\"Letter-Based Speech Recognition with Gated ConvNets\",\"url\":\"https://www.semanticscholar.org/paper/da8c898dfe4804ed60833ee0d019969a8c588a46\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1312.6114\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"1678311\",\"name\":\"M. Welling\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5f5dc5b9a2ba710937e2c413b37b053cd673df02\",\"title\":\"Auto-Encoding Variational Bayes\",\"url\":\"https://www.semanticscholar.org/paper/5f5dc5b9a2ba710937e2c413b37b053cd673df02\",\"venue\":\"ICLR\",\"year\":2014},{\"arxivId\":\"1707.07998\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"31790073\",\"name\":\"C. Buehler\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":\"10.1109/CVPR.2018.00636\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"title\":\"Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1504.00325\",\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"title\":\"Microsoft COCO Captions: Data Collection and Evaluation Server\",\"url\":\"https://www.semanticscholar.org/paper/696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1403025868\",\"name\":\"Jean Pouget-Abadie\"},{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"144738865\",\"name\":\"Bing Xu\"},{\"authorId\":\"1393680089\",\"name\":\"David Warde-Farley\"},{\"authorId\":\"1955694\",\"name\":\"Sherjil Ozair\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"title\":\"Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145798572\",\"name\":\"S. Ma\"},{\"authorId\":\"1801452\",\"name\":\"D. McDuff\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c978ee204c0f6ab6e1a8c635a93d16612927e24b\",\"title\":\"Neural TTS Stylization with Adversarial and Collaborative Games\",\"url\":\"https://www.semanticscholar.org/paper/c978ee204c0f6ab6e1a8c635a93d16612927e24b\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1703.10593\",\"authors\":[{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"145599603\",\"name\":\"T. Park\"},{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1109/ICCV.2017.244\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c43d954cf8133e6254499f3d68e45218067e4941\",\"title\":\"Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/c43d954cf8133e6254499f3d68e45218067e4941\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"physics/0004057\",\"authors\":[{\"authorId\":\"1777660\",\"name\":\"Naftali Tishby\"},{\"authorId\":\"145366908\",\"name\":\"Fernando C Pereira\"},{\"authorId\":\"1762240\",\"name\":\"W. Bialek\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"c76c62c5ab6c076a80f925d277ef04dd36f6bf9c\",\"title\":\"The information bottleneck method\",\"url\":\"https://www.semanticscholar.org/paper/c76c62c5ab6c076a80f925d277ef04dd36f6bf9c\",\"venue\":\"ArXiv\",\"year\":2000},{\"arxivId\":\"1711.11586\",\"authors\":[{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"2844849\",\"name\":\"Richard Zhang\"},{\"authorId\":\"38236002\",\"name\":\"Deepak Pathak\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"},{\"authorId\":\"39231399\",\"name\":\"O. Wang\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d6eda0c16d226976506396653d14044c185eaf3e\",\"title\":\"Toward Multimodal Image-to-Image Translation\",\"url\":\"https://www.semanticscholar.org/paper/d6eda0c16d226976506396653d14044c185eaf3e\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1704.06485\",\"authors\":[{\"authorId\":\"47465525\",\"name\":\"Cesc Chunseong Park\"},{\"authorId\":\"3231991\",\"name\":\"Byeongchang Kim\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1109/CVPR.2017.681\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d842c2fb5a0c54f15bc4e45c7c93bdb8b0c44de\",\"title\":\"Attend to You: Personalized Image Captioning with Context Sequence Memory Networks\",\"url\":\"https://www.semanticscholar.org/paper/9d842c2fb5a0c54f15bc4e45c7c93bdb8b0c44de\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1612.03242\",\"authors\":[{\"authorId\":\"120811666\",\"name\":\"Han Zhang\"},{\"authorId\":\"145017761\",\"name\":\"Tao Xu\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"}],\"doi\":\"10.1109/ICCV.2017.629\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ea67d2d5f2a7d5760ec6b67ea93d11dd5affa921\",\"title\":\"StackGAN: Text to Photo-Realistic Image Synthesis with Stacked Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/ea67d2d5f2a7d5760ec6b67ea93d11dd5affa921\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1802.06454\",\"authors\":[{\"authorId\":\"145798572\",\"name\":\"S. Ma\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"1735257\",\"name\":\"C. Chen\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2018.00593\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"247d40bed85d09e752f60e5183f14b02e100360b\",\"title\":\"DA-GAN: Instance-Level Image Translation by Deep Attention Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/247d40bed85d09e752f60e5183f14b02e100360b\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1512.02595\",\"authors\":[{\"authorId\":\"2698777\",\"name\":\"Dario Amodei\"},{\"authorId\":\"39436202\",\"name\":\"S. Ananthanarayanan\"},{\"authorId\":\"2432216\",\"name\":\"Rishita Anubhai\"},{\"authorId\":\"47236125\",\"name\":\"J. Bai\"},{\"authorId\":\"5697774\",\"name\":\"Eric Battenberg\"},{\"authorId\":\"145353944\",\"name\":\"C. Case\"},{\"authorId\":\"48991386\",\"name\":\"J. Casper\"},{\"authorId\":\"2301680\",\"name\":\"Bryan Catanzaro\"},{\"authorId\":\"47740218\",\"name\":\"Jingdong Chen\"},{\"authorId\":\"35977287\",\"name\":\"M. Chrzanowski\"},{\"authorId\":\"144638694\",\"name\":\"A. Coates\"},{\"authorId\":\"2322582\",\"name\":\"Greg Diamos\"},{\"authorId\":\"152585800\",\"name\":\"E. Elsen\"},{\"authorId\":\"9695761\",\"name\":\"J. Engel\"},{\"authorId\":\"3275727\",\"name\":\"Linxi (Jim) Fan\"},{\"authorId\":\"2910729\",\"name\":\"Christopher Fougner\"},{\"authorId\":\"2893056\",\"name\":\"Awni Y. Hannun\"},{\"authorId\":\"34601942\",\"name\":\"Billy Jun\"},{\"authorId\":\"3041255\",\"name\":\"Tony Han\"},{\"authorId\":\"3081566\",\"name\":\"P. LeGresley\"},{\"authorId\":\"1898780\",\"name\":\"Xiangang Li\"},{\"authorId\":\"113530808\",\"name\":\"Libby Lin\"},{\"authorId\":\"46617804\",\"name\":\"Sharan Narang\"},{\"authorId\":\"34699434\",\"name\":\"A. Ng\"},{\"authorId\":\"1955694\",\"name\":\"Sherjil Ozair\"},{\"authorId\":\"3168041\",\"name\":\"Ryan Prenger\"},{\"authorId\":\"144416975\",\"name\":\"S. Qian\"},{\"authorId\":\"34042420\",\"name\":\"Jonathan Raiman\"},{\"authorId\":\"145031342\",\"name\":\"S. Satheesh\"},{\"authorId\":\"2100685\",\"name\":\"David Seetapun\"},{\"authorId\":\"2264597\",\"name\":\"S. Sengupta\"},{\"authorId\":\"8401284\",\"name\":\"Anuroop Sriram\"},{\"authorId\":\"47074522\",\"name\":\"C. Wang\"},{\"authorId\":\"46393411\",\"name\":\"Yi Wang\"},{\"authorId\":\"50219267\",\"name\":\"Zhiqian Wang\"},{\"authorId\":\"144912001\",\"name\":\"B. Xiao\"},{\"authorId\":\"143669548\",\"name\":\"Y. Xie\"},{\"authorId\":\"1755465\",\"name\":\"Dani Yogatama\"},{\"authorId\":\"145141776\",\"name\":\"Jun Zhan\"},{\"authorId\":\"2042558\",\"name\":\"Zhenyao Zhu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8ff840a40d3f1557c55c19d4d636da77103168ce\",\"title\":\"Deep Speech 2 : End-to-End Speech Recognition in English and Mandarin\",\"url\":\"https://www.semanticscholar.org/paper/8ff840a40d3f1557c55c19d4d636da77103168ce\",\"venue\":\"ICML\",\"year\":2016},{\"arxivId\":\"1406.1078\",\"authors\":[{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"3158246\",\"name\":\"B. V. Merrienboer\"},{\"authorId\":\"1854385\",\"name\":\"\\u00c7aglar G\\u00fcl\\u00e7ehre\"},{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"2076086\",\"name\":\"Fethi Bougares\"},{\"authorId\":\"144518416\",\"name\":\"Holger Schwenk\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":\"10.3115/v1/D14-1179\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0b544dfe355a5070b60986319a3f51fb45d1348e\",\"title\":\"Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/0b544dfe355a5070b60986319a3f51fb45d1348e\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":\"1711.10485\",\"authors\":[{\"authorId\":\"39866461\",\"name\":\"T. Xu\"},{\"authorId\":\"9325940\",\"name\":\"Pengchuan Zhang\"},{\"authorId\":\"1788124\",\"name\":\"Qiuyuan Huang\"},{\"authorId\":\"48213346\",\"name\":\"Han Zhang\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"143713756\",\"name\":\"Xiaolei Huang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"}],\"doi\":\"10.1109/CVPR.2018.00143\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8b35c00edfa4edfd7a99d816e671023d2c000d55\",\"title\":\"AttnGAN: Fine-Grained Text to Image Generation with Attentional Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/8b35c00edfa4edfd7a99d816e671023d2c000d55\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1712.05884\",\"authors\":[{\"authorId\":\"143724108\",\"name\":\"Jonathan Shen\"},{\"authorId\":\"34320634\",\"name\":\"R. Pang\"},{\"authorId\":\"39571582\",\"name\":\"Ron J. Weiss\"},{\"authorId\":\"46503039\",\"name\":\"M. Schuster\"},{\"authorId\":\"3111912\",\"name\":\"Navdeep Jaitly\"},{\"authorId\":\"1867996\",\"name\":\"Z. Yang\"},{\"authorId\":\"2545358\",\"name\":\"Z. Chen\"},{\"authorId\":\"36562659\",\"name\":\"Yu Zhang\"},{\"authorId\":null,\"name\":\"Yuxuan Wang\"},{\"authorId\":\"1380248814\",\"name\":\"R. Skerry-Ryan\"},{\"authorId\":\"2278009\",\"name\":\"R. A. Saurous\"},{\"authorId\":\"2259013\",\"name\":\"Yannis Agiomyrgiannakis\"},{\"authorId\":\"1780996\",\"name\":\"Y. Wu\"}],\"doi\":\"10.1109/ICASSP.2018.8461368\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1a2599e467e855f845dcbf9282f8bdbd97b85708\",\"title\":\"Natural TTS Synthesis by Conditioning Wavenet on MEL Spectrogram Predictions\",\"url\":\"https://www.semanticscholar.org/paper/1a2599e467e855f845dcbf9282f8bdbd97b85708\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2150714\",\"name\":\"Vassil Panayotov\"},{\"authorId\":\"2335354\",\"name\":\"Guoguo Chen\"},{\"authorId\":\"1792214\",\"name\":\"D. Povey\"},{\"authorId\":\"2803071\",\"name\":\"S. Khudanpur\"}],\"doi\":\"10.1109/ICASSP.2015.7178964\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"34038d9424ce602d7ac917a4e582d977725d4393\",\"title\":\"Librispeech: An ASR corpus based on public domain audio books\",\"url\":\"https://www.semanticscholar.org/paper/34038d9424ce602d7ac917a4e582d977725d4393\",\"venue\":\"2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Chung-Cheng Chiu\"},{\"authorId\":null,\"name\":\"Yonghui Wu\"},{\"authorId\":null,\"name\":\"Zhifeng Chen\"},{\"authorId\":null,\"name\":\"Anjuli Kannan\"},{\"authorId\":null,\"name\":\"Ron J. Weiss\"},{\"authorId\":null,\"name\":\"Navdeep Jaitly\"},{\"authorId\":null,\"name\":\"Jan Chorowski\"},{\"authorId\":null,\"name\":\"Michiel Bacchiani\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Bottom - up and top - down attention for image captioning and visual question answering Deep voice : Real - time neural text - to - speech One - sided unsupervised domain mapping\",\"url\":\"\",\"venue\":\"In NIPS\",\"year\":2017},{\"arxivId\":\"1609.03499\",\"authors\":[{\"authorId\":\"3422336\",\"name\":\"A. Oord\"},{\"authorId\":\"48373216\",\"name\":\"S. Dieleman\"},{\"authorId\":\"1691713\",\"name\":\"H. Zen\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"2583391\",\"name\":\"Nal Kalchbrenner\"},{\"authorId\":\"33666044\",\"name\":\"A. Senior\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"df0402517a7338ae28bc54acaac400de6b456a46\",\"title\":\"WaveNet: A Generative Model for Raw Audio\",\"url\":\"https://www.semanticscholar.org/paper/df0402517a7338ae28bc54acaac400de6b456a46\",\"venue\":\"SSW\",\"year\":2016},{\"arxivId\":\"1409.4842\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"46641766\",\"name\":\"W. Liu\"},{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"},{\"authorId\":\"48840704\",\"name\":\"Scott Reed\"},{\"authorId\":\"1838674\",\"name\":\"Dragomir Anguelov\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"39863668\",\"name\":\"Andrew Rabinovich\"}],\"doi\":\"10.1109/CVPR.2015.7298594\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"title\":\"Going deeper with convolutions\",\"url\":\"https://www.semanticscholar.org/paper/e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1705.08947\",\"authors\":[{\"authorId\":\"9544702\",\"name\":\"Andrew Gibiansky\"},{\"authorId\":\"2676352\",\"name\":\"Sercan \\u00d6. Arik\"},{\"authorId\":\"2040049\",\"name\":\"G. Diamos\"},{\"authorId\":\"152617830\",\"name\":\"J. Miller\"},{\"authorId\":\"12240560\",\"name\":\"Kainan Peng\"},{\"authorId\":\"34337724\",\"name\":\"W. Ping\"},{\"authorId\":\"34042420\",\"name\":\"Jonathan Raiman\"},{\"authorId\":\"2389316\",\"name\":\"Yanqi Zhou\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5a5bcfda3b753f8266b9ba27d34fc86b6d374a1b\",\"title\":\"Deep Voice 2: Multi-Speaker Neural Text-to-Speech\",\"url\":\"https://www.semanticscholar.org/paper/5a5bcfda3b753f8266b9ba27d34fc86b6d374a1b\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48241196\",\"name\":\"M. H. Giard\"},{\"authorId\":\"48154893\",\"name\":\"F. P\\u00e9ronnet\"}],\"doi\":\"10.1162/089892999563544\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"73769fb5e911026c62be01a674385b9accaa1bf3\",\"title\":\"Auditory-Visual Integration during Multimodal Object Recognition in Humans: A Behavioral and Electrophysiological Study\",\"url\":\"https://www.semanticscholar.org/paper/73769fb5e911026c62be01a674385b9accaa1bf3\",\"venue\":\"Journal of Cognitive Neuroscience\",\"year\":1999},{\"arxivId\":\"1706.00826\",\"authors\":[{\"authorId\":\"19310335\",\"name\":\"Sagie Benaim\"},{\"authorId\":\"145128145\",\"name\":\"Lior Wolf\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fd4537b92ab9fa7c653e9e5b9c4f815914a498c0\",\"title\":\"One-Sided Unsupervised Domain Mapping\",\"url\":\"https://www.semanticscholar.org/paper/fd4537b92ab9fa7c653e9e5b9c4f815914a498c0\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1412.7449\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"40527594\",\"name\":\"L. Kaiser\"},{\"authorId\":\"145096103\",\"name\":\"T. Koo\"},{\"authorId\":\"1754497\",\"name\":\"Slav Petrov\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"47570e7f63e296f224a0e7f9a0d08b0de3cbaf40\",\"title\":\"Grammar as a Foreign Language\",\"url\":\"https://www.semanticscholar.org/paper/47570e7f63e296f224a0e7f9a0d08b0de3cbaf40\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1711.09020\",\"authors\":[{\"authorId\":\"30187096\",\"name\":\"Yunjey Choi\"},{\"authorId\":\"8486223\",\"name\":\"Min-Je Choi\"},{\"authorId\":\"30184861\",\"name\":\"Munyoung Kim\"},{\"authorId\":\"2577039\",\"name\":\"Jung-Woo Ha\"},{\"authorId\":\"6098375\",\"name\":\"S. Kim\"},{\"authorId\":\"1795455\",\"name\":\"J. Choo\"}],\"doi\":\"10.1109/CVPR.2018.00916\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"302207c149bdf7beb6e46e4d4afbd2fa9ac02c64\",\"title\":\"StarGAN: Unified Generative Adversarial Networks for Multi-domain Image-to-Image Translation\",\"url\":\"https://www.semanticscholar.org/paper/302207c149bdf7beb6e46e4d4afbd2fa9ac02c64\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"134861178\",\"name\":\"Wei Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPRW.2009.5206848\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d2c733e34d48784a37d717fe43d9e93277a8c53e\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/d2c733e34d48784a37d717fe43d9e93277a8c53e\",\"venue\":\"2009 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2009},{\"arxivId\":\"1703.05192\",\"authors\":[{\"authorId\":\"2509132\",\"name\":\"Taeksoo Kim\"},{\"authorId\":\"9959922\",\"name\":\"Moonsu Cha\"},{\"authorId\":\"39280603\",\"name\":\"H. Kim\"},{\"authorId\":\"3088401\",\"name\":\"J. Lee\"},{\"authorId\":\"3968500\",\"name\":\"Jiwon Kim\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7778b2b6ee67df2a0a06fe82e79acfdf714c7399\",\"title\":\"Learning to Discover Cross-Domain Relations with Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/7778b2b6ee67df2a0a06fe82e79acfdf714c7399\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":\"1710.07654\",\"authors\":[{\"authorId\":\"34337724\",\"name\":\"W. Ping\"},{\"authorId\":\"12240560\",\"name\":\"Kainan Peng\"},{\"authorId\":\"9544702\",\"name\":\"Andrew Gibiansky\"},{\"authorId\":\"2676352\",\"name\":\"Sercan \\u00d6. Arik\"},{\"authorId\":\"33850592\",\"name\":\"A. Kannan\"},{\"authorId\":\"46617804\",\"name\":\"Sharan Narang\"},{\"authorId\":\"34042420\",\"name\":\"Jonathan Raiman\"},{\"authorId\":\"144909221\",\"name\":\"J. Miller\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"852120feb37d2dc136d1c6916b52b9baabfc2e11\",\"title\":\"Deep Voice 3: 2000-Speaker Neural Text-to-Speech\",\"url\":\"https://www.semanticscholar.org/paper/852120feb37d2dc136d1c6916b52b9baabfc2e11\",\"venue\":\"ICLR 2018\",\"year\":2017},{\"arxivId\":\"1611.02200\",\"authors\":[{\"authorId\":\"2188620\",\"name\":\"Yaniv Taigman\"},{\"authorId\":\"33964593\",\"name\":\"A. Polyak\"},{\"authorId\":\"145128145\",\"name\":\"Lior Wolf\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"04bd2907111855b9fde9413bb25b9788a4c03f26\",\"title\":\"Unsupervised Cross-Domain Image Generation\",\"url\":\"https://www.semanticscholar.org/paper/04bd2907111855b9fde9413bb25b9788a4c03f26\",\"venue\":\"ICLR\",\"year\":2017}],\"title\":\"Unpaired Image-to-Speech Synthesis With Multimodal Information Bottleneck\",\"topics\":[{\"topic\":\"Speech synthesis\",\"topicId\":\"12604\",\"url\":\"https://www.semanticscholar.org/topic/12604\"},{\"topic\":\"Modal logic\",\"topicId\":\"61528\",\"url\":\"https://www.semanticscholar.org/topic/61528\"},{\"topic\":\"Modality (human\\u2013computer interaction)\",\"topicId\":\"462\",\"url\":\"https://www.semanticscholar.org/topic/462\"},{\"topic\":\"Multimodal interaction\",\"topicId\":\"42592\",\"url\":\"https://www.semanticscholar.org/topic/42592\"},{\"topic\":\"Rendering (computer graphics)\",\"topicId\":\"15667\",\"url\":\"https://www.semanticscholar.org/topic/15667\"},{\"topic\":\"Bridging (networking)\",\"topicId\":\"46048\",\"url\":\"https://www.semanticscholar.org/topic/46048\"}],\"url\":\"https://www.semanticscholar.org/paper/e1e1feac96004866052787115ea08a4dcdd888b9\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019}\n"