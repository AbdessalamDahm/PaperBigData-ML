"{\"abstract\":\"Shouldn't language and vision features be treated equally in vision-language (VL) tasks? Many VL approaches treat the language component as an afterthought, using simple language models that are either built upon fixed word embeddings trained on text-only data or are learned from scratch. We conclude that language features deserve more attention, which has been informed by experiments which compare different word embeddings, language models, and embedding augmentation steps on five common VL tasks: image-sentence retrieval, image captioning, visual question answering, phrase grounding, and text-to-clip retrieval. Our experiments provide some striking results; an average embedding language model outperforms a LSTM on retrieval-style tasks; state-of-the-art representations such as BERT perform relatively poorly on vision-language tasks. From this comprehensive set of experiments we can propose a set of best practices for incorporating the language component of vision-language tasks. To further elevate language features, we also show that knowledge in vision-language problems can be transferred across tasks to gain performance with multi-task training. This multi-task training is applied to a new Graph Oriented Vision-Language Embedding (GrOVLE), which we adapt from Word2Vec using WordNet and an original visual-language graph built from Visual Genome, providing a ready-to-use vision-language embedding: http://ai.bu.edu/grovle.\",\"arxivId\":\"1908.06327\",\"authors\":[{\"authorId\":\"38727845\",\"name\":\"A. Burns\",\"url\":\"https://www.semanticscholar.org/author/38727845\"},{\"authorId\":\"73441526\",\"name\":\"R. Tan\",\"url\":\"https://www.semanticscholar.org/author/73441526\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\",\"url\":\"https://www.semanticscholar.org/author/2903226\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\",\"url\":\"https://www.semanticscholar.org/author/1749590\"},{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\",\"url\":\"https://www.semanticscholar.org/author/2856622\"}],\"citationVelocity\":6,\"citations\":[{\"arxivId\":\"2002.05104\",\"authors\":[{\"authorId\":\"1396871443\",\"name\":\"Camila Kolling\"},{\"authorId\":\"8599825\",\"name\":\"Jonatas Wehrmann\"},{\"authorId\":\"1380051745\",\"name\":\"Rodrigo C. Barros\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206679\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e4bd198ec47697ed1442af0babd35b88451fd205\",\"title\":\"Component Analysis for Visual Question Answering Architectures\",\"url\":\"https://www.semanticscholar.org/paper/e4bd198ec47697ed1442af0babd35b88451fd205\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":\"2005.08399\",\"authors\":[{\"authorId\":\"3044372\",\"name\":\"M. Bastan\"},{\"authorId\":\"1780343\",\"name\":\"Arnau Ramisa\"},{\"authorId\":\"1413035003\",\"name\":\"Mehmet Tek\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"808aeca77cd7d0bba12a201377abf5e862962da0\",\"title\":\"T-VSE: Transformer-Based Visual Semantic Embedding\",\"url\":\"https://www.semanticscholar.org/paper/808aeca77cd7d0bba12a201377abf5e862962da0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1912.02048\",\"authors\":[{\"authorId\":\"79576706\",\"name\":\"Q. Feng\"},{\"authorId\":\"1852308\",\"name\":\"Vitaly Ablavsky\"},{\"authorId\":\"2132890\",\"name\":\"Qinxun Bai\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"494be1259cfe27f1fa16383395dd7059e220b4e5\",\"title\":\"Robust Visual Object Tracking with Natural Language Region Proposal Network\",\"url\":\"https://www.semanticscholar.org/paper/494be1259cfe27f1fa16383395dd7059e220b4e5\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2006.10598\",\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"2134146\",\"name\":\"Nikoli Dryden\"},{\"authorId\":\"1752594045\",\"name\":\"Julius Frost\"},{\"authorId\":\"1713648\",\"name\":\"Torsten Hoefler\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"235de6164e754400f82b77fb33be84fc43c79078\",\"title\":\"Shapeshifter Networks: Decoupling Layers from Parameters for Scalable and Effective Deep Learning.\",\"url\":\"https://www.semanticscholar.org/paper/235de6164e754400f82b77fb33be84fc43c79078\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2007.10639\",\"authors\":[{\"authorId\":\"151352107\",\"name\":\"Valentin Gabeur\"},{\"authorId\":\"1491624845\",\"name\":\"Chen Sun\"},{\"authorId\":\"72492981\",\"name\":\"Alahari Karteek\"},{\"authorId\":\"153433844\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1007/978-3-030-58548-8_13\",\"intent\":[\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"6871f6c5437a747fae75a19962f418d234ce2dc1\",\"title\":\"Multi-modal Transformer for Video Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/6871f6c5437a747fae75a19962f418d234ce2dc1\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121433901\",\"name\":\"Xiaoqian Guo\"},{\"authorId\":\"50080038\",\"name\":\"Xiangyang Li\"},{\"authorId\":\"1696610\",\"name\":\"S. Jiang\"}],\"doi\":\"10.1145/3394171.3413567\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1870b836377d41de6280f6291089d66ee8cf8e61\",\"title\":\"Expressional Region Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/1870b836377d41de6280f6291089d66ee8cf8e61\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1909.03493\",\"authors\":[{\"authorId\":\"31494849\",\"name\":\"D. Kim\"},{\"authorId\":\"2652444\",\"name\":\"K. Saito\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"},{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"}],\"doi\":\"10.1609/AAAI.V34I07.6785\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"77802591c3f5b3f654bb5b68ad62ed056769320f\",\"title\":\"MULE: Multimodal Universal Language Embedding\",\"url\":\"https://www.semanticscholar.org/paper/77802591c3f5b3f654bb5b68ad62ed056769320f\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1811.07212\",\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"143953573\",\"name\":\"K. Shih\"},{\"authorId\":\"121704643\",\"name\":\"Yichen Li\"},{\"authorId\":\"145031845\",\"name\":\"Ke Xu\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/TPAMI.2020.3029008\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"0e0fbead3da9e16b03894b63efc6816fa3ef6d0e\",\"title\":\"Revisiting Image-Language Networks for Open-ended Phrase Detection.\",\"url\":\"https://www.semanticscholar.org/paper/0e0fbead3da9e16b03894b63efc6816fa3ef6d0e\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"2011.13406\",\"authors\":[{\"authorId\":\"153188991\",\"name\":\"Spencer Whitehead\"},{\"authorId\":\"97671685\",\"name\":\"H. Wu\"},{\"authorId\":\"51135899\",\"name\":\"Yi Ren Fung\"},{\"authorId\":\"153172090\",\"name\":\"Huai-zhong Ji\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1904c5389a70a905019d5429f09bc7f669bdc898\",\"title\":\"Learning from Lexical Perturbations for Consistent Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1904c5389a70a905019d5429f09bc7f669bdc898\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.09634\",\"authors\":[{\"authorId\":\"1624475253\",\"name\":\"Yujie Zhong\"},{\"authorId\":\"11246861\",\"name\":\"Linhai Xie\"},{\"authorId\":\"1421686725\",\"name\":\"Sen Wang\"},{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"},{\"authorId\":\"2666898\",\"name\":\"Yishu Miao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f416cdb1cd51a73fdb7f8f4194308798ae57033c\",\"title\":\"Watch and Learn: Mapping Language and Noisy Real-world Videos with Self-supervision\",\"url\":\"https://www.semanticscholar.org/paper/f416cdb1cd51a73fdb7f8f4194308798ae57033c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"2134146\",\"name\":\"Nikoli Dryden\"},{\"authorId\":\"1752594045\",\"name\":\"Julius Frost\"},{\"authorId\":\"1713648\",\"name\":\"Torsten Hoefler\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e2457396ebdf83f7f81a048863f4a0aa38bfb39f\",\"title\":\"Shapeshifter Networks: Cross-layer Parameter Sharing for Scalable and Effective Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/e2457396ebdf83f7f81a048863f4a0aa38bfb39f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.04312\",\"authors\":[{\"authorId\":\"38727845\",\"name\":\"A. Burns\"},{\"authorId\":\"31494849\",\"name\":\"D. Kim\"},{\"authorId\":\"2129412\",\"name\":\"D. Wijaya\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"}],\"doi\":\"10.1007/978-3-030-58548-8_12\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b8e9b6ecb592269836bcdc46d0d0d001e883c9ee\",\"title\":\"Learning to Scale Multilingual Representations for Vision-Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/b8e9b6ecb592269836bcdc46d0d0d001e883c9ee\",\"venue\":\"ECCV\",\"year\":2020}],\"corpusId\":201070522,\"doi\":\"10.1109/ICCV.2019.00757\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":2,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"71634edd80ce000b3d1e462137fcfa8c2b377943\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Bryan A. Plummer\"},{\"authorId\":null,\"name\":\"Liwei Wang\"},{\"authorId\":null,\"name\":\"Chris M. Cervantes\"},{\"authorId\":null,\"name\":\"Juan C. Caicedo\"},{\"authorId\":null,\"name\":\"Julia Hockenmaier\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\", and Svetlana Lazebnik . Flickr 30 K Entities : Collecting region - to - phrase correspondences for richer image - to - sentence models\",\"url\":\"\",\"venue\":\"In ICCV\",\"year\":2017},{\"arxivId\":\"1411.4952\",\"authors\":[{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3346186\",\"name\":\"Forrest N. Iandola\"},{\"authorId\":\"2100612\",\"name\":\"R. Srivastava\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"144189092\",\"name\":\"John C. Platt\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"}],\"doi\":\"10.1109/CVPR.2015.7298754\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"title\":\"From captions to visual concepts and back\",\"url\":\"https://www.semanticscholar.org/paper/15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1711.05769\",\"authors\":[{\"authorId\":\"36508529\",\"name\":\"Arun Mallya\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1109/CVPR.2018.00810\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"47bc048efb90e7b8bae5c1fcc979a78b65763fe9\",\"title\":\"PackNet: Adding Multiple Tasks to a Single Network by Iterative Pruning\",\"url\":\"https://www.semanticscholar.org/paper/47bc048efb90e7b8bae5c1fcc979a78b65763fe9\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Bryan A. Plummer\"},{\"authorId\":null,\"name\":\"Liwei Wang\"},{\"authorId\":null,\"name\":\"Chris M. Cervantes\"},{\"authorId\":null,\"name\":\"Juan C. Caicedo\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\", Julia Hockenmaier , and Svetlana Lazebnik . Flickr 30 K Entities : Collecting region - to - phrase correspondences for richer image - to - sentence models\",\"url\":\"\",\"venue\":\"IJCV\",\"year\":null},{\"arxivId\":\"1707.07998\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"31790073\",\"name\":\"C. Buehler\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":\"10.1109/CVPR.2018.00636\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"title\":\"Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1810.04805\",\"authors\":[{\"authorId\":\"39172707\",\"name\":\"J. Devlin\"},{\"authorId\":\"1744179\",\"name\":\"Ming-Wei Chang\"},{\"authorId\":\"2544107\",\"name\":\"Kenton Lee\"},{\"authorId\":\"3259253\",\"name\":\"Kristina Toutanova\"}],\"doi\":\"10.18653/v1/N19-1423\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"df2b0e26d0599ce3e70df8a9da02e51594e0e992\",\"title\":\"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\",\"url\":\"https://www.semanticscholar.org/paper/df2b0e26d0599ce3e70df8a9da02e51594e0e992\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":\"1511.05099\",\"authors\":[{\"authorId\":\"40409467\",\"name\":\"P. Zhang\"},{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2016.542\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5fa973b8d284145bf0ced9acf2913a74674260f6\",\"title\":\"Yin and Yang: Balancing and Answering Binary Visual Questions\",\"url\":\"https://www.semanticscholar.org/paper/5fa973b8d284145bf0ced9acf2913a74674260f6\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1506.00278\",\"authors\":[{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"2155311\",\"name\":\"Eunbyung Park\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a58a582b95a07932cb248f1b739e4ad739ead6b9\",\"title\":\"Visual Madlibs: Fill in the blank Image Generation and Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a58a582b95a07932cb248f1b739e4ad739ead6b9\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144096985\",\"name\":\"G. Miller\"}],\"doi\":\"10.1145/219717.219748\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"68c03788224000794d5491ab459be0b2a2c38677\",\"title\":\"WordNet: a lexical database for English\",\"url\":\"https://www.semanticscholar.org/paper/68c03788224000794d5491ab459be0b2a2c38677\",\"venue\":\"CACM\",\"year\":1995},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Tsung-Yi Lin\"},{\"authorId\":null,\"name\":\"Michael Maire\"},{\"authorId\":null,\"name\":\"James Hays\"},{\"authorId\":null,\"name\":\"Pietro Perona\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Common objects in context\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Tomas Mikolov\"},{\"authorId\":\"144105277\",\"name\":\"Wen-tau Yih\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c4fd9c86b2b41df51a6fe212406dda81b1997fd4\",\"title\":\"Linguistic Regularities in Continuous Space Word Representations\",\"url\":\"https://www.semanticscholar.org/paper/c4fd9c86b2b41df51a6fe212406dda81b1997fd4\",\"venue\":\"HLT-NAACL\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743722\",\"name\":\"Douwe Kiela\"},{\"authorId\":\"52184096\",\"name\":\"L. Bottou\"}],\"doi\":\"10.3115/v1/D14-1005\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f28bd36d233dba56e23df22e79b1e432d4bdc66b\",\"title\":\"Learning Image Embeddings using Convolutional Neural Networks for Improved Multi-Modal Semantics\",\"url\":\"https://www.semanticscholar.org/paper/f28bd36d233dba56e23df22e79b1e432d4bdc66b\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":\"1712.02036\",\"authors\":[{\"authorId\":\"144368930\",\"name\":\"Yan Huang\"},{\"authorId\":\"34902783\",\"name\":\"Qi Wu\"},{\"authorId\":\"144143336\",\"name\":\"Liang Wang\"}],\"doi\":\"10.1109/CVPR.2018.00645\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f322eef6a4c965910e03f6997b1bc2acd413e273\",\"title\":\"Learning Semantic Concepts and Order for Image and Sentence Matching\",\"url\":\"https://www.semanticscholar.org/paper/f322eef6a4c965910e03f6997b1bc2acd413e273\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1604.03540\",\"authors\":[{\"authorId\":\"1781242\",\"name\":\"Abhinav Shrivastava\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/CVPR.2016.89\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"63333669bcf694aba2e1928f6060ab1d6a5161fe\",\"title\":\"Training Region-Based Object Detectors with Online Hard Example Mining\",\"url\":\"https://www.semanticscholar.org/paper/63333669bcf694aba2e1928f6060ab1d6a5161fe\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1512.03958\",\"authors\":[{\"authorId\":\"3004979\",\"name\":\"G. Lev\"},{\"authorId\":\"2251827\",\"name\":\"Gil Sadeh\"},{\"authorId\":\"145969200\",\"name\":\"B. Klein\"},{\"authorId\":\"145128145\",\"name\":\"Lior Wolf\"}],\"doi\":\"10.1007/978-3-319-46466-4_50\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"04b8a1d2498a7c8bd90a5465a02b2e8e178177c5\",\"title\":\"RNN Fisher Vectors for Action Recognition and Image Annotation\",\"url\":\"https://www.semanticscholar.org/paper/04b8a1d2498a7c8bd90a5465a02b2e8e178177c5\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1708.01676\",\"authors\":[{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"3407447\",\"name\":\"Rama Kovvuri\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/ICCV.2017.95\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ff4b351dccb970f13a345adf0647ffe8c2021f1f\",\"title\":\"Query-Guided Regression Network with Context Policy for Phrase Grounding\",\"url\":\"https://www.semanticscholar.org/paper/ff4b351dccb970f13a345adf0647ffe8c2021f1f\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2433617\",\"name\":\"Mingzhe Wang\"},{\"authorId\":\"144886349\",\"name\":\"Mahmoud Azab\"},{\"authorId\":\"31686229\",\"name\":\"Noriyuki Kojima\"},{\"authorId\":\"145557251\",\"name\":\"R. Mihalcea\"},{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"}],\"doi\":\"10.1007/978-3-319-46484-8_42\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3dd4f855d0c794060a8a2fabe0639f4a4e792b45\",\"title\":\"Structured Matching for Phrase Localization\",\"url\":\"https://www.semanticscholar.org/paper/3dd4f855d0c794060a8a2fabe0639f4a4e792b45\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1511.03745\",\"authors\":[{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1007/978-3-319-46448-0_49\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"14c2321851fb5ae580a19726dd2753a525d6ad76\",\"title\":\"Grounding of Textual Phrases in Images by Reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/14c2321851fb5ae580a19726dd2753a525d6ad76\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1803.08024\",\"authors\":[{\"authorId\":\"1863953\",\"name\":\"Kuang-Huei Lee\"},{\"authorId\":\"1683647\",\"name\":\"X. Chen\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\"},{\"authorId\":\"35431603\",\"name\":\"H. Hu\"},{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"}],\"doi\":\"10.1007/978-3-030-01225-0_13\",\"intent\":[\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"45dd2a3cd7c27f2e9509b023d702408f5ac11c9d\",\"title\":\"Stacked Cross Attention for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/45dd2a3cd7c27f2e9509b023d702408f5ac11c9d\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144332826\",\"name\":\"Chen Kong\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":\"10.1109/CVPR.2014.455\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"13549b4e6fffbb7932b7a83a8eb6be27e6a60eca\",\"title\":\"What Are You Talking About? Text-to-Image Coreference\",\"url\":\"https://www.semanticscholar.org/paper/13549b4e6fffbb7932b7a83a8eb6be27e6a60eca\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1511.04164\",\"authors\":[{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"3286703\",\"name\":\"Huazhe Xu\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/CVPR.2016.493\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d696a1923288e6c15422660de9553f6fdb6a4fae\",\"title\":\"Natural Language Object Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/d696a1923288e6c15422660de9553f6fdb6a4fae\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"E. Matthew\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Peters , Mark Neumann , Mohit Iyyer , Matt Gardner , Christopher Clark , Kenton Lee , and Luke Zettlemoyer . Deep contextualized word representations\",\"url\":\"\",\"venue\":\"In NAACL\",\"year\":2018},{\"arxivId\":\"1704.03470\",\"authors\":[{\"authorId\":\"145602574\",\"name\":\"L. Wang\"},{\"authorId\":\"48513361\",\"name\":\"Y. Li\"},{\"authorId\":\"19353632\",\"name\":\"J. Huang\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1109/TPAMI.2018.2797921\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f865268b81eeb29d94775f22c6bc24dcc5e1b2e9\",\"title\":\"Learning Two-Branch Neural Networks for Image-Text Matching Tasks\",\"url\":\"https://www.semanticscholar.org/paper/f865268b81eeb29d94775f22c6bc24dcc5e1b2e9\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":\"1711.09509\",\"authors\":[{\"authorId\":\"3401864\",\"name\":\"Ryota Hinami\"},{\"authorId\":\"1700567\",\"name\":\"Shin'ichi Satoh\"}],\"doi\":\"10.18653/v1/D18-1281\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ca24289cefdee010a4700a6dd2ffac2a0cf05d09\",\"title\":\"Discriminative Learning of Open-Vocabulary Object Retrieval and Localization by Negative Phrase Augmentation\",\"url\":\"https://www.semanticscholar.org/paper/ca24289cefdee010a4700a6dd2ffac2a0cf05d09\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"143953573\",\"name\":\"K. Shih\"},{\"authorId\":\"1798489\",\"name\":\"Yichen Li\"},{\"authorId\":\"144968844\",\"name\":\"K. Xu\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"155dbe88e444b18ad1fd78dc9b655eb9b9d7fd43\",\"title\":\"Open-vocabulary Phrase Detection\",\"url\":\"https://www.semanticscholar.org/paper/155dbe88e444b18ad1fd78dc9b655eb9b9d7fd43\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1505.00487\",\"authors\":[{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/ICCV.2015.515\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e58a110fa1e4ddf247d5c614d117d64bfbe135c4\",\"title\":\"Sequence to Sequence -- Video to Text\",\"url\":\"https://www.semanticscholar.org/paper/e58a110fa1e4ddf247d5c614d117d64bfbe135c4\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Tsung-Yi Lin\"},{\"authorId\":null,\"name\":\"Michael Maire\"},{\"authorId\":null,\"name\":\"James Hays\"},{\"authorId\":null,\"name\":\"Pietro Perona\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Common objects in context\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36595248\",\"name\":\"Fang Fang\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"8275214\",\"name\":\"P. Tang\"}],\"doi\":\"10.1109/ICIP.2018.8451558\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c5f6ed9efc222fe2773135ffb4e5c567d98e64ea\",\"title\":\"Image Captioning with Word Level Attention\",\"url\":\"https://www.semanticscholar.org/paper/c5f6ed9efc222fe2773135ffb4e5c567d98e64ea\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":\"1606.01847\",\"authors\":[{\"authorId\":\"50599725\",\"name\":\"A. Fukui\"},{\"authorId\":\"3422202\",\"name\":\"Dong Huk Park\"},{\"authorId\":\"3422876\",\"name\":\"Daylen Yang\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.18653/v1/D16-1044\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"fddc15480d086629b960be5bff96232f967f2252\",\"title\":\"Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/fddc15480d086629b960be5bff96232f967f2252\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":\"1608.03410\",\"authors\":[{\"authorId\":\"2087226\",\"name\":\"T. Tommasi\"},{\"authorId\":\"36508529\",\"name\":\"Arun Mallya\"},{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.5244/C.30.77\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"95f0125e6dda6c0028e09e814a7aaae5ef4922a4\",\"title\":\"Solving VIsual Madlibs with Multiple Cues\",\"url\":\"https://www.semanticscholar.org/paper/95f0125e6dda6c0028e09e814a7aaae5ef4922a4\",\"venue\":\"BMVC\",\"year\":2016},{\"arxivId\":\"1411.7399\",\"authors\":[{\"authorId\":\"145969200\",\"name\":\"B. Klein\"},{\"authorId\":\"3004979\",\"name\":\"G. Lev\"},{\"authorId\":\"2251827\",\"name\":\"Gil Sadeh\"},{\"authorId\":\"145128145\",\"name\":\"Lior Wolf\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4898e0c5bb8d93443f2f168c31e3f1827c9129de\",\"title\":\"Fisher Vectors Derived from Hybrid Gaussian-Laplacian Mixture Models for Image Annotation\",\"url\":\"https://www.semanticscholar.org/paper/4898e0c5bb8d93443f2f168c31e3f1827c9129de\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":\"1804.05113\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"145905328\",\"name\":\"Kun He\"},{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1609/AAAI.V33I01.33019062\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"83b2a55aecd5f917dbedbc0c5ef3ff3b61013958\",\"title\":\"Multilevel Language and Vision Integration for Text-to-Clip Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/83b2a55aecd5f917dbedbc0c5ef3ff3b61013958\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"145297531\",\"name\":\"A. Lai\"},{\"authorId\":\"2170746\",\"name\":\"M. Hodosh\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"}],\"doi\":\"10.1162/tacl_a_00166\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"44040913380206991b1991daf1192942e038fe31\",\"title\":\"From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions\",\"url\":\"https://www.semanticscholar.org/paper/44040913380206991b1991daf1192942e038fe31\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ranjay Krishna\"},{\"authorId\":null,\"name\":\"Kenji Hata\"},{\"authorId\":null,\"name\":\"Frederic Ren\"},{\"authorId\":null,\"name\":\"Li Fei-Fei\"},{\"authorId\":null,\"name\":\"Juan Carlos Niebles\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\", and Devi Parikh . Visual word 2 vec ( vis - w 2 v ) : Learning visually grounded word embeddings using abstract scenes\",\"url\":\"\",\"venue\":\"In CVPR\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47740660\",\"name\":\"Jingyuan Chen\"},{\"authorId\":\"3179887\",\"name\":\"Xinpeng Chen\"},{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"2750647\",\"name\":\"Zequn Jie\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.18653/v1/D18-1015\",\"intent\":[\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"452aca244ef62a533d8b46a54c6212fe9fa3ce9a\",\"title\":\"Temporally Grounding Natural Sentence in Video\",\"url\":\"https://www.semanticscholar.org/paper/452aca244ef62a533d8b46a54c6212fe9fa3ce9a\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46868596\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1790976\",\"name\":\"H. Lu\"}],\"doi\":\"10.1007/978-3-030-01246-5_42\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1a86eb42952412ee02e3f6da06f874f1946eff6b\",\"title\":\"Deep Cross-Modal Projection Learning for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/1a86eb42952412ee02e3f6da06f874f1946eff6b\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3006072\",\"name\":\"Sahar Kazemzadeh\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"32215032\",\"name\":\"Mark Matten\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.3115/v1/D14-1086\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"92c141447f51b6732242376164ff961e464731c8\",\"title\":\"ReferItGame: Referring to Objects in Photographs of Natural Scenes\",\"url\":\"https://www.semanticscholar.org/paper/92c141447f51b6732242376164ff961e464731c8\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":\"1705.02364\",\"authors\":[{\"authorId\":\"2480903\",\"name\":\"Alexis Conneau\"},{\"authorId\":\"1743722\",\"name\":\"Douwe Kiela\"},{\"authorId\":\"144518416\",\"name\":\"Holger Schwenk\"},{\"authorId\":\"2934336\",\"name\":\"Lo\\u00efc Barrault\"},{\"authorId\":\"1713934\",\"name\":\"Antoine Bordes\"}],\"doi\":\"10.18653/v1/D17-1070\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ee7b883e35d754ae4f71c21bb71f9f03e4ffbb2c\",\"title\":\"Supervised Learning of Universal Sentence Representations from Natural Language Inference Data\",\"url\":\"https://www.semanticscholar.org/paper/ee7b883e35d754ae4f71c21bb71f9f03e4ffbb2c\",\"venue\":\"EMNLP\",\"year\":2017},{\"arxivId\":\"1706.03762\",\"authors\":[{\"authorId\":\"40348417\",\"name\":\"Ashish Vaswani\"},{\"authorId\":\"1846258\",\"name\":\"Noam Shazeer\"},{\"authorId\":\"3877127\",\"name\":\"Niki Parmar\"},{\"authorId\":\"39328010\",\"name\":\"Jakob Uszkoreit\"},{\"authorId\":\"145024664\",\"name\":\"Llion Jones\"},{\"authorId\":\"19177000\",\"name\":\"Aidan N. Gomez\"},{\"authorId\":\"40527594\",\"name\":\"L. Kaiser\"},{\"authorId\":\"3443442\",\"name\":\"Illia Polosukhin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"204e3073870fae3d05bcbc2f6a8e263d9b72e776\",\"title\":\"Attention is All you Need\",\"url\":\"https://www.semanticscholar.org/paper/204e3073870fae3d05bcbc2f6a8e263d9b72e776\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1506.01497\",\"authors\":[{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"144716314\",\"name\":\"J. Sun\"}],\"doi\":\"10.1109/TPAMI.2016.2577031\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"title\":\"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\",\"url\":\"https://www.semanticscholar.org/paper/424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2015},{\"arxivId\":\"1612.00837\",\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"7595427\",\"name\":\"Tejas Khot\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2017.670\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"title\":\"Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/ICCV.2015.279\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"784da2a7b53a16d2243f747e14946cc5e3476af0\",\"title\":\"VQA: Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/784da2a7b53a16d2243f747e14946cc5e3476af0\",\"venue\":\"ICCV\",\"year\":2015},{\"arxivId\":\"1802.05365\",\"authors\":[{\"authorId\":\"39139825\",\"name\":\"Matthew E. Peters\"},{\"authorId\":\"50043859\",\"name\":\"Mark Neumann\"},{\"authorId\":\"2136562\",\"name\":\"Mohit Iyyer\"},{\"authorId\":\"40642935\",\"name\":\"Matt Gardner\"},{\"authorId\":\"143997772\",\"name\":\"Christopher Clark\"},{\"authorId\":\"2544107\",\"name\":\"Kenton Lee\"},{\"authorId\":\"1982950\",\"name\":\"Luke Zettlemoyer\"}],\"doi\":\"10.18653/v1/N18-1202\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3febb2bed8865945e7fddc99efd791887bb7e14f\",\"title\":\"Deep contextualized word representations\",\"url\":\"https://www.semanticscholar.org/paper/3febb2bed8865945e7fddc99efd791887bb7e14f\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143845796\",\"name\":\"Jeffrey Pennington\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.3115/v1/D14-1162\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"title\":\"Glove: Global Vectors for Word Representation\",\"url\":\"https://www.semanticscholar.org/paper/f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Manaal Faruqui\"},{\"authorId\":null,\"name\":\"Jesse Dodge\"},{\"authorId\":null,\"name\":\"Sujay Kumar Jauhar\"},{\"authorId\":null,\"name\":\"Chris Dyer\"},{\"authorId\":null,\"name\":\"Eduard Hovy\"},{\"authorId\":null,\"name\":\"Noah A. Smith\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Retrofitting Word Vectors to Semantic Lexicons\",\"url\":\"\",\"venue\":\"NAACL 2015\",\"year\":2015},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1705.00754\",\"authors\":[{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"1382195702\",\"name\":\"Kenji Hata\"},{\"authorId\":\"3260219\",\"name\":\"F. Ren\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/ICCV.2017.83\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"96dd1fc39a368d23291816d57763bc6eb4f7b8d6\",\"title\":\"Dense-Captioning Events in Videos\",\"url\":\"https://www.semanticscholar.org/paper/96dd1fc39a368d23291816d57763bc6eb4f7b8d6\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1704.05526\",\"authors\":[{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/ICCV.2017.93\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a396a6febdacb84340d139096455e67049ac1e22\",\"title\":\"Learning to Reason: End-to-End Module Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a396a6febdacb84340d139096455e67049ac1e22\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51033208\",\"name\":\"B. Liu\"},{\"authorId\":\"34149749\",\"name\":\"Serena Yeung\"},{\"authorId\":\"34613203\",\"name\":\"Edward Chou\"},{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1007/978-3-030-01219-9_34\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"73d1b35cd28befe845fcb60a3fed67c9fb7793ad\",\"title\":\"Temporal Modular Networks for Retrieving Complex Compositional Activities in Videos\",\"url\":\"https://www.semanticscholar.org/paper/73d1b35cd28befe845fcb60a3fed67c9fb7793ad\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1708.01641\",\"authors\":[{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"39231399\",\"name\":\"O. Wang\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"145160921\",\"name\":\"Bryan C. Russell\"}],\"doi\":\"10.1109/ICCV.2017.618\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"ee909ad489244016cf301bb7d7d8eeea423dbf35\",\"title\":\"Localizing Moments in Video with Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/ee909ad489244016cf301bb7d7d8eeea423dbf35\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1602.07332\",\"authors\":[{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"50499889\",\"name\":\"O. Groth\"},{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"1382195702\",\"name\":\"Kenji Hata\"},{\"authorId\":\"40591424\",\"name\":\"J. Kravitz\"},{\"authorId\":\"6000646\",\"name\":\"Stephanie Chen\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"1388344504\",\"name\":\"David A. Shamma\"},{\"authorId\":\"1379506718\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-016-0981-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"title\":\"Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations\",\"url\":\"https://www.semanticscholar.org/paper/afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":\"1805.07932\",\"authors\":[{\"authorId\":\"2684967\",\"name\":\"J. Kim\"},{\"authorId\":\"29818400\",\"name\":\"Jaehyun Jun\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a5d10341717c0519cf63151b496a6d2ed67aa05f\",\"title\":\"Bilinear Attention Networks\",\"url\":\"https://www.semanticscholar.org/paper/a5d10341717c0519cf63151b496a6d2ed67aa05f\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1803.11439\",\"authors\":[{\"authorId\":\"3179887\",\"name\":\"Xinpeng Chen\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"2093119\",\"name\":\"W. Jiang\"},{\"authorId\":\"144188763\",\"name\":\"Jian Yao\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"}],\"doi\":\"10.1109/CVPR.2018.00834\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"85e2b2c35b916b1ee4926c155065d01b21c80c60\",\"title\":\"Regularizing RNNs for Caption Generation by Reconstructing the Past with the Present\",\"url\":\"https://www.semanticscholar.org/paper/85e2b2c35b916b1ee4926c155065d01b21c80c60\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Bryan A. Plummer\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\", Paige Kordas , M . Hadi Kiapour , Shuai Zheng , Robinson Piramuthu , and Svetlana Lazebnik . Conditional image - text embedding networks\",\"url\":\"\",\"venue\":\"In ECCV\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2133220\",\"name\":\"C. Cervantes\"},{\"authorId\":\"145507543\",\"name\":\"Juan C. Caicedo\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1109/ICCV.2015.303\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"11c9c31dff70de92ada9160c78ff8bb46b2912d6\",\"title\":\"Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models\",\"url\":\"https://www.semanticscholar.org/paper/11c9c31dff70de92ada9160c78ff8bb46b2912d6\",\"venue\":\"ICCV\",\"year\":2015},{\"arxivId\":\"1606.00061\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"145743311\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b\",\"title\":\"Hierarchical Question-Image Co-Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1611.06641\",\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"36508529\",\"name\":\"Arun Mallya\"},{\"authorId\":\"6648406\",\"name\":\"Christopher M. Cervantes\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1109/ICCV.2017.213\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d061fbed640a4a06dfea2c2fbe9ec05061d775ce\",\"title\":\"Phrase Localization and Visual Relationship Detection with Comprehensive Image-Language Cues\",\"url\":\"https://www.semanticscholar.org/paper/d061fbed640a4a06dfea2c2fbe9ec05061d775ce\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1511.07067\",\"authors\":[{\"authorId\":\"2150275\",\"name\":\"S. Kottur\"},{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"144915495\",\"name\":\"Jos\\u00e9 M. F. Moura\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2016.539\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"06599d41a3256245aa0cb2e9e56b29459c2e2c69\",\"title\":\"VisualWord2Vec (Vis-W2V): Learning Visually Grounded Word Embeddings Using Abstract Scenes\",\"url\":\"https://www.semanticscholar.org/paper/06599d41a3256245aa0cb2e9e56b29459c2e2c69\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Akira Fukui\"},{\"authorId\":null,\"name\":\"Dong Huk Park\"},{\"authorId\":null,\"name\":\"Daylen Yang\"},{\"authorId\":null,\"name\":\"Anna Rohrbach\"},{\"authorId\":null,\"name\":\"Trevor Darrell\"},{\"authorId\":null,\"name\":\"Marcus Rohrbach\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\", Chris Dyer , Eduard Hovy , and Noah A . Smith . Retrofitting word vectors to semantic lexicons\",\"url\":\"\",\"venue\":\"In NAACL\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Mark Johnson\"},{\"authorId\":null,\"name\":\"Stephen Gould\"},{\"authorId\":null,\"name\":\"Lei Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Bottom - up and top - down attention for image captioning and visual question answering A neural probabilistic language model\",\"url\":\"\",\"venue\":\"\",\"year\":2003},{\"arxivId\":\"1511.06361\",\"authors\":[{\"authorId\":\"2210865\",\"name\":\"Ivan Vendrov\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"46b8cbcdff87b842c2c1d4a003c831f845096ba7\",\"title\":\"Order-Embeddings of Images and Language\",\"url\":\"https://www.semanticscholar.org/paper/46b8cbcdff87b842c2c1d4a003c831f845096ba7\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2482533\",\"name\":\"Mo Yu\"},{\"authorId\":\"1782853\",\"name\":\"Mark Dredze\"}],\"doi\":\"10.3115/v1/P14-2089\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c8dfdb6bc17094fc1c35757a0020dea8d813b7b6\",\"title\":\"Improving Lexical Embeddings with Semantic Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/c8dfdb6bc17094fc1c35757a0020dea8d813b7b6\",\"venue\":\"ACL\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"134861178\",\"name\":\"Wei Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPRW.2009.5206848\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d2c733e34d48784a37d717fe43d9e93277a8c53e\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/d2c733e34d48784a37d717fe43d9e93277a8c53e\",\"venue\":\"2009 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2009},{\"arxivId\":\"1711.08389\",\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"8440041\",\"name\":\"Paige Kordas\"},{\"authorId\":\"1772294\",\"name\":\"M. Kiapour\"},{\"authorId\":\"144147900\",\"name\":\"Shuai Zheng\"},{\"authorId\":\"3221010\",\"name\":\"Robinson Piramuthu\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1007/978-3-030-01258-8_16\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e5bfebd3774c44580463cda8e611487ae3639cd7\",\"title\":\"Conditional Image-Text Embedding Networks\",\"url\":\"https://www.semanticscholar.org/paper/e5bfebd3774c44580463cda8e611487ae3639cd7\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1703.07814\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"40521893\",\"name\":\"Abir Das\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/ICCV.2017.617\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7f8324dda6261ec293e9705c13a0e96b9ab63474\",\"title\":\"R-C3D: Region Convolutional 3D Network for Temporal Activity Detection\",\"url\":\"https://www.semanticscholar.org/paper/7f8324dda6261ec293e9705c13a0e96b9ab63474\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"36037226\",\"name\":\"R. Ducharme\"},{\"authorId\":\"120247189\",\"name\":\"Pascal Vincent\"},{\"authorId\":\"1909943744\",\"name\":\"Christian Janvin\"}],\"doi\":\"10.1162/153244303322533223\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c2b28f9354f667cd5bd07afc0471d8334430da7\",\"title\":\"A Neural Probabilistic Language Model\",\"url\":\"https://www.semanticscholar.org/paper/6c2b28f9354f667cd5bd07afc0471d8334430da7\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2978170\",\"name\":\"Fartash Faghri\"},{\"authorId\":\"1793739\",\"name\":\"David J. Fleet\"},{\"authorId\":\"51131802\",\"name\":\"J. Kiros\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f7ab6c52be9351ac3f6cf8fe6ad5efba1c1595e8\",\"title\":\"VSE++: Improving Visual-Semantic Embeddings with Hard Negatives\",\"url\":\"https://www.semanticscholar.org/paper/f7ab6c52be9351ac3f6cf8fe6ad5efba1c1595e8\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2426894\",\"name\":\"Michael Grubinger\"},{\"authorId\":\"1704149\",\"name\":\"P. Clough\"},{\"authorId\":\"1679402\",\"name\":\"H. M\\u00fcller\"},{\"authorId\":\"1879646\",\"name\":\"Thomas Deselaers\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"381929a8187010f6db940a23d78731c8e694c56c\",\"title\":\"The IAPR TC-12 Benchmark: A New Evaluation Resource for Visual Information Systems\",\"url\":\"https://www.semanticscholar.org/paper/381929a8187010f6db940a23d78731c8e694c56c\",\"venue\":\"\",\"year\":2006},{\"arxivId\":\"1607.04606\",\"authors\":[{\"authorId\":\"2329288\",\"name\":\"P. Bojanowski\"},{\"authorId\":\"3024698\",\"name\":\"E. Grave\"},{\"authorId\":\"2319608\",\"name\":\"Armand Joulin\"},{\"authorId\":null,\"name\":\"Tomas Mikolov\"}],\"doi\":\"10.1162/tacl_a_00051\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e2dba792360873aef125572812f3673b1a85d850\",\"title\":\"Enriching Word Vectors with Subword Information\",\"url\":\"https://www.semanticscholar.org/paper/e2dba792360873aef125572812f3673b1a85d850\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Bryan A. Plummer\"},{\"authorId\":null,\"name\":\"Kevin J. Shih\"},{\"authorId\":null,\"name\":\"Yichen Li\"},{\"authorId\":null,\"name\":\"Ke Xu\"},{\"authorId\":null,\"name\":\"Svetlana Lazebnik\"},{\"authorId\":null,\"name\":\"Stan Sclaroff\"},{\"authorId\":null,\"name\":\"Kate Saenko\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Revisiting image-language embeddings for open-ended phrase detection\",\"url\":\"\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1611.00471\",\"authors\":[{\"authorId\":\"34758272\",\"name\":\"H. Nam\"},{\"authorId\":\"2577039\",\"name\":\"Jung-Woo Ha\"},{\"authorId\":\"2947441\",\"name\":\"J. Kim\"}],\"doi\":\"10.1109/CVPR.2017.232\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f651593fa6c83d717fc961482696a53b6fca5ab5\",\"title\":\"Dual Attention Networks for Multimodal Reasoning and Matching\",\"url\":\"https://www.semanticscholar.org/paper/f651593fa6c83d717fc961482696a53b6fca5ab5\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Daylen Yang\"},{\"authorId\":null,\"name\":\"Anna Rohrbach\"},{\"authorId\":null,\"name\":\"Trevor Darrell\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Jauhar , Chris Dyer , Eduard Hovy , and Noah A . Smith . Retrofitting word vectors to semantic lexicons\",\"url\":\"\",\"venue\":\"In NAACL\",\"year\":2015},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1501.02598\",\"authors\":[{\"authorId\":\"2672644\",\"name\":\"A. Lazaridou\"},{\"authorId\":\"2702980\",\"name\":\"N. Pham\"},{\"authorId\":\"145283199\",\"name\":\"M. Baroni\"}],\"doi\":\"10.3115/v1/N15-1016\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dfa8790b6463cbd8e50d746e03e4c161e1920cf1\",\"title\":\"Combining Language and Vision with a Multimodal Skip-gram Model\",\"url\":\"https://www.semanticscholar.org/paper/dfa8790b6463cbd8e50d746e03e4c161e1920cf1\",\"venue\":\"HLT-NAACL\",\"year\":2015}],\"title\":\"Language Features Matter: Effective Language Representations for Vision-Language Tasks\",\"topics\":[{\"topic\":\"Language model\",\"topicId\":\"26812\",\"url\":\"https://www.semanticscholar.org/topic/26812\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Question answering\",\"topicId\":\"18817\",\"url\":\"https://www.semanticscholar.org/topic/18817\"},{\"topic\":\"Word embedding\",\"topicId\":\"286696\",\"url\":\"https://www.semanticscholar.org/topic/286696\"},{\"topic\":\"Best practice\",\"topicId\":\"8774\",\"url\":\"https://www.semanticscholar.org/topic/8774\"},{\"topic\":\"Computer multitasking\",\"topicId\":\"6968\",\"url\":\"https://www.semanticscholar.org/topic/6968\"},{\"topic\":\"Long short-term memory\",\"topicId\":\"117199\",\"url\":\"https://www.semanticscholar.org/topic/117199\"},{\"topic\":\"WordNet\",\"topicId\":\"95603\",\"url\":\"https://www.semanticscholar.org/topic/95603\"},{\"topic\":\"Text-based user interface\",\"topicId\":\"328633\",\"url\":\"https://www.semanticscholar.org/topic/328633\"}],\"url\":\"https://www.semanticscholar.org/paper/71634edd80ce000b3d1e462137fcfa8c2b377943\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019}\n"