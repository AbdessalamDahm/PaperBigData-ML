"{\"abstract\":\"In this work, we present a novel dataset consisting of eye movements and verbal descriptions recorded synchronously over images. Using this data, we study the differences in human attention during free-viewing and image captioning tasks. We look into the relationship between human atten- tion and language constructs during perception and sen- tence articulation. We also analyse attention deployment mechanisms in the top-down soft attention approach that is argued to mimic human attention in captioning tasks, and investigate whether visual saliency can help image caption- ing. Our study reveals that (1) human attention behaviour differs in free-viewing and image description tasks. Hu- mans tend to fixate on a greater variety of regions under the latter task, (2) there is a strong relationship between de- scribed objects and attended objects (97% of the described objects are being attended), (3) a convolutional neural net- work as feature encoder accounts for human-attended re- gions during image captioning to a great extent (around 78%), (4) soft-attention mechanism differs from human at- tention, both spatially and temporally, and there is low correlation between caption scores and attention consis- tency scores. These indicate a large gap between humans and machines in regards to top-down attention, and (5) by integrating the soft attention model with image saliency, we can significantly improve the model\\u2019s performance on Flickr30k and MSCOCO benchmarks. The dataset can be found at: https://github.com/SenHe/ Human-Attention-in-Image-Captioning.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"47287647\",\"name\":\"Sen He\",\"url\":\"https://www.semanticscholar.org/author/47287647\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\",\"url\":\"https://www.semanticscholar.org/author/2319672\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\",\"url\":\"https://www.semanticscholar.org/author/3177797\"},{\"authorId\":\"3251678\",\"name\":\"N. Pugeault\",\"url\":\"https://www.semanticscholar.org/author/3251678\"}],\"citationVelocity\":5,\"citations\":[{\"arxivId\":\"2007.14419\",\"authors\":[{\"authorId\":\"94011352\",\"name\":\"S. Chen\"},{\"authorId\":\"1405907659\",\"name\":\"Ming Jiang\"},{\"authorId\":\"7788087\",\"name\":\"J. Yang\"},{\"authorId\":\"153386875\",\"name\":\"Q. Zhao\"}],\"doi\":\"10.1007/978-3-030-58452-8_6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"96150d2fdbb72e11882ad06b346d6e0d2e819d51\",\"title\":\"AiR: Attention with Reasoning Capability\",\"url\":\"https://www.semanticscholar.org/paper/96150d2fdbb72e11882ad06b346d6e0d2e819d51\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.08760\",\"authors\":[{\"authorId\":\"47824882\",\"name\":\"W. Wang\"},{\"authorId\":\"3373117\",\"name\":\"R. Wang\"},{\"authorId\":\"144481158\",\"name\":\"S. Shan\"},{\"authorId\":\"1710220\",\"name\":\"X. Chen\"}],\"doi\":\"10.1007/978-3-030-58601-0_14\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c450ead5da6783d93e20e718f27f4475b16c7dc9\",\"title\":\"Sketching Image Gist: Human-Mimetic Hierarchical Scene Graph Generation\",\"url\":\"https://www.semanticscholar.org/paper/c450ead5da6783d93e20e718f27f4475b16c7dc9\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2004.02877\",\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6709fbca948e6b2bbdff4d52433de7992e44f5bf\",\"title\":\"Empirical Upper Bound, Error Diagnosis and Invariance Analysis of Modern Object Detectors\",\"url\":\"https://www.semanticscholar.org/paper/6709fbca948e6b2bbdff4d52433de7992e44f5bf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.15942\",\"authors\":[{\"authorId\":\"2657185\",\"name\":\"Ruohan Zhang\"},{\"authorId\":\"1720831208\",\"name\":\"Bo Liu\"},{\"authorId\":\"1778450\",\"name\":\"Y. Zhu\"},{\"authorId\":\"1807482896\",\"name\":\"Sihang Guo\"},{\"authorId\":\"2848854\",\"name\":\"M. Hayhoe\"},{\"authorId\":\"1691804\",\"name\":\"D. Ballard\"},{\"authorId\":\"144848112\",\"name\":\"P. Stone\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0af86c8fe633e71aeb38561165609bc14d699290\",\"title\":\"Human versus Machine Attention in Deep Reinforcement Learning Tasks\",\"url\":\"https://www.semanticscholar.org/paper/0af86c8fe633e71aeb38561165609bc14d699290\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47011474\",\"name\":\"Kun Xiong\"},{\"authorId\":\"1807459832\",\"name\":\"Liu Jiang\"},{\"authorId\":\"39056715\",\"name\":\"Xuan Dang\"},{\"authorId\":\"50248791\",\"name\":\"G. Wang\"},{\"authorId\":\"1830569732\",\"name\":\"Wenwen Ye\"},{\"authorId\":\"1489386471\",\"name\":\"Zheng Qin\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206953\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dafb451fc3a51032c825eea6cc2037911089d47c\",\"title\":\"Towards Personalized Aesthetic Image Caption\",\"url\":\"https://www.semanticscholar.org/paper/dafb451fc3a51032c825eea6cc2037911089d47c\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"47957770\",\"name\":\"Xuying Zhang\"},{\"authorId\":\"40626740\",\"name\":\"Liujuan Cao\"},{\"authorId\":\"47096329\",\"name\":\"Yongjian Wu\"},{\"authorId\":\"1835006\",\"name\":\"Feiyue Huang\"},{\"authorId\":\"1572139630\",\"name\":\"Rongrong Ji\"}],\"doi\":\"10.1145/3394171.3414008\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c19f8380410181249fdca70ec14f6b5f38ae0846\",\"title\":\"Exploring Language Prior for Mode-Sensitive Visual Attention Modeling\",\"url\":\"https://www.semanticscholar.org/paper/c19f8380410181249fdca70ec14f6b5f38ae0846\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2011.04592\",\"authors\":[{\"authorId\":\"41071249\",\"name\":\"Ece Takmaz\"},{\"authorId\":\"3422247\",\"name\":\"Sandro Pezzelle\"},{\"authorId\":\"2752573\",\"name\":\"Lisa Beinborn\"},{\"authorId\":\"144151273\",\"name\":\"R. Fern\\u00e1ndez\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.377\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"306ec4956aa2bb4e29a0b5c8b52d1c0e6007a32b\",\"title\":\"Generating Image Descriptions via Sequential Cross-Modal Alignment Guided by Human Gaze\",\"url\":\"https://www.semanticscholar.org/paper/306ec4956aa2bb4e29a0b5c8b52d1c0e6007a32b\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2657185\",\"name\":\"Ruohan Zhang\"},{\"authorId\":\"10978611\",\"name\":\"Akanksha Saran\"},{\"authorId\":\"73548014\",\"name\":\"Bo Liu\"},{\"authorId\":\"46759203\",\"name\":\"Y. Zhu\"},{\"authorId\":\"1807482896\",\"name\":\"Sihang Guo\"},{\"authorId\":\"2791038\",\"name\":\"S. Niekum\"},{\"authorId\":\"1691804\",\"name\":\"D. Ballard\"},{\"authorId\":\"2848854\",\"name\":\"M. Hayhoe\"}],\"doi\":\"10.24963/ijcai.2020/689\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"97a06ab02b44a696619c21de32d6ec0dcfc876eb\",\"title\":\"Human Gaze Assisted Artificial Intelligence: A Review\",\"url\":\"https://www.semanticscholar.org/paper/97a06ab02b44a696619c21de32d6ec0dcfc876eb\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2615648\",\"name\":\"Xudong Hong\"},{\"authorId\":\"38314306\",\"name\":\"Rakshith Shetty\"},{\"authorId\":\"153786091\",\"name\":\"Asad Sayeed\"},{\"authorId\":\"52406707\",\"name\":\"Khushboo Mehra\"},{\"authorId\":\"2869436\",\"name\":\"V. Demberg\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.18653/v1/2020.conll-1.34\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8504fe99ba36088b36623441eb468adae67a9b51\",\"title\":\"Diverse and Relevant Visual Storytelling with Scene Graph Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/8504fe99ba36088b36623441eb468adae67a9b51\",\"venue\":\"CoNLL\",\"year\":2020},{\"arxivId\":\"2008.02918\",\"authors\":[{\"authorId\":\"1864097171\",\"name\":\"Xubin Zhong\"},{\"authorId\":\"144116132\",\"name\":\"Changxing Ding\"},{\"authorId\":\"50123957\",\"name\":\"Xian Qu\"},{\"authorId\":\"145047838\",\"name\":\"Dacheng Tao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"84dc734a134a2a87d36b189aed6f5b2b9e1c5264\",\"title\":\"Polysemy Deciphering Network for Robust Human-Object Interaction Detection\",\"url\":\"https://www.semanticscholar.org/paper/84dc734a134a2a87d36b189aed6f5b2b9e1c5264\",\"venue\":\"ECCV 2020\",\"year\":2020}],\"corpusId\":199441964,\"doi\":\"10.1109/ICCV.2019.00862\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":1,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"e4a91b8c1259e7744784d922f250dd77ea951e9f\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"2037692\",\"name\":\"Dicky N. Sihite\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1109/TIP.2012.2210727\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c0b60d02b2d59123f6b336fe2e287bdb02a2a776\",\"title\":\"Quantitative Analysis of Human-Model Agreement in Visual Saliency Modeling: A Comparative Study\",\"url\":\"https://www.semanticscholar.org/paper/c0b60d02b2d59123f6b336fe2e287bdb02a2a776\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2013},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145624227\",\"name\":\"C. Koch\"},{\"authorId\":\"1743045\",\"name\":\"S. Ullman\"}],\"doi\":\"10.1007/978-94-009-3833-5_5\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0ce672e6ef09e9ab4c43f1eb75443dc7a5cb38c6\",\"title\":\"Shifts in selective visual attention: towards the underlying neural circuitry.\",\"url\":\"https://www.semanticscholar.org/paper/0ce672e6ef09e9ab4c43f1eb75443dc7a5cb38c6\",\"venue\":\"Human neurobiology\",\"year\":1985},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7326223\",\"name\":\"L. Itti\"},{\"authorId\":\"1795076\",\"name\":\"M. Arbib\"}],\"doi\":\"10.1017/CBO9780511541599.010\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1fbfffc42b13294cbf767db2354ec8d4635a6916\",\"title\":\"Action to Language via the Mirror Neuron System: Attention and the minimal subscene\",\"url\":\"https://www.semanticscholar.org/paper/1fbfffc42b13294cbf767db2354ec8d4635a6916\",\"venue\":\"\",\"year\":2006},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1511.07122\",\"authors\":[{\"authorId\":\"1807197\",\"name\":\"F. Yu\"},{\"authorId\":\"145231047\",\"name\":\"V. Koltun\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7f5fc84819c0cf94b771fe15141f65b123f7b8ec\",\"title\":\"Multi-Scale Context Aggregation by Dilated Convolutions\",\"url\":\"https://www.semanticscholar.org/paper/7f5fc84819c0cf94b771fe15141f65b123f7b8ec\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":\"1506.02025\",\"authors\":[{\"authorId\":\"3093886\",\"name\":\"Max Jaderberg\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fe87ea16d5eb1c7509da9a0314bbf4c7b0676506\",\"title\":\"Spatial Transformer Networks\",\"url\":\"https://www.semanticscholar.org/paper/fe87ea16d5eb1c7509da9a0314bbf4c7b0676506\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1701.01081\",\"authors\":[{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"},{\"authorId\":\"1399086207\",\"name\":\"C. Canton-Ferrer\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"},{\"authorId\":\"147166602\",\"name\":\"J. Torres\"},{\"authorId\":\"2470219\",\"name\":\"E. Sayrol\"},{\"authorId\":\"3100480\",\"name\":\"Xavier Giro-i-Nieto\"}],\"doi\":null,\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"258fad95e709b6d0572ae6cc99efbbb14d32bdf2\",\"title\":\"SalGAN: Visual Saliency Prediction with Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/258fad95e709b6d0572ae6cc99efbbb14d32bdf2\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3017358\",\"name\":\"Y. Wang\"},{\"authorId\":\"30820560\",\"name\":\"B. Wang\"},{\"authorId\":\"4417713\",\"name\":\"Xiaofeng Wu\"},{\"authorId\":\"29906646\",\"name\":\"L. Zhang\"}],\"doi\":\"10.1007/s10339-016-0781-6\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"30b52c789adfad9123dbcf571053a1d71c3beb5d\",\"title\":\"Scanpath estimation based on foveated image saliency\",\"url\":\"https://www.semanticscholar.org/paper/30b52c789adfad9123dbcf571053a1d71c3beb5d\",\"venue\":\"Cognitive Processing\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"},{\"authorId\":\"1760868\",\"name\":\"M. Surdeanu\"},{\"authorId\":\"144661918\",\"name\":\"John Bauer\"},{\"authorId\":\"2784228\",\"name\":\"Jenny Rose Finkel\"},{\"authorId\":\"2105138\",\"name\":\"Steven Bethard\"},{\"authorId\":\"2240597\",\"name\":\"D. McClosky\"}],\"doi\":\"10.3115/v1/P14-5010\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2f5102ec3f70d0dea98c957cc2cab4d15d83a2da\",\"title\":\"The Stanford CoreNLP Natural Language Processing Toolkit\",\"url\":\"https://www.semanticscholar.org/paper/2f5102ec3f70d0dea98c957cc2cab4d15d83a2da\",\"venue\":\"ACL\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144645142\",\"name\":\"M. Jiang\"},{\"authorId\":\"1961257\",\"name\":\"Shengsheng Huang\"},{\"authorId\":\"2104164\",\"name\":\"Juanyong Duan\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1109/CVPR.2015.7298710\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c71db5d3546e22227662ee0f0ce586495ef18899\",\"title\":\"SALICON: Saliency in Context\",\"url\":\"https://www.semanticscholar.org/paper/c71db5d3546e22227662ee0f0ce586495ef18899\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2015.7298932\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"title\":\"Deep visual-semantic alignments for generating image descriptions\",\"url\":\"https://www.semanticscholar.org/paper/ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"venue\":\"CVPR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1403025868\",\"name\":\"Jean Pouget-Abadie\"},{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"144738865\",\"name\":\"Bing Xu\"},{\"authorId\":\"1393680089\",\"name\":\"David Warde-Farley\"},{\"authorId\":\"1955694\",\"name\":\"Sherjil Ozair\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"title\":\"Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Meinard M\\u00fcller\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Dynamic time warping. Information retrieval for music and motion, pages\",\"url\":\"\",\"venue\":\"\",\"year\":2007},{\"arxivId\":\"1409.4842\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"46641766\",\"name\":\"W. Liu\"},{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"},{\"authorId\":\"48840704\",\"name\":\"Scott Reed\"},{\"authorId\":\"1838674\",\"name\":\"Dragomir Anguelov\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"39863668\",\"name\":\"Andrew Rabinovich\"}],\"doi\":\"10.1109/CVPR.2015.7298594\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"title\":\"Going deeper with convolutions\",\"url\":\"https://www.semanticscholar.org/paper/e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1412.2306\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/TPAMI.2016.2598339\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"title\":\"Deep Visual-Semantic Alignments for Generating Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1781574\",\"name\":\"Chin-Yew Lin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"60b05f32c32519a809f21642ef1eb3eaf3848008\",\"title\":\"ROUGE: A Package for Automatic Evaluation of Summaries\",\"url\":\"https://www.semanticscholar.org/paper/60b05f32c32519a809f21642ef1eb3eaf3848008\",\"venue\":\"ACL 2004\",\"year\":2004},{\"arxivId\":\"1411.5726\",\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2015.7299087\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"258986132bf17755fe8263e42429fe73218c1534\",\"title\":\"CIDEr: Consensus-based image description evaluation\",\"url\":\"https://www.semanticscholar.org/paper/258986132bf17755fe8263e42429fe73218c1534\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1411.3041\",\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1bf155d1473baf90e584b3e022a0c30e1fa1ca05\",\"title\":\"Collecting Image Description Datasets using Crowdsourcing\",\"url\":\"https://www.semanticscholar.org/paper/1bf155d1473baf90e584b3e022a0c30e1fa1ca05\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2459642\",\"name\":\"P. Vaidyanathan\"},{\"authorId\":\"1401154472\",\"name\":\"Emily Tucker Prud'hommeaux\"},{\"authorId\":\"2899726\",\"name\":\"J. Pelz\"},{\"authorId\":\"144648940\",\"name\":\"Cecilia Ovesdotter Alm\"}],\"doi\":\"10.18653/v1/P18-2022\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8fdbebb4972ecf12f1b736bd4fb0cf0223e8217e\",\"title\":\"SNAG: Spoken Narratives and Gaze Dataset\",\"url\":\"https://www.semanticscholar.org/paper/8fdbebb4972ecf12f1b736bd4fb0cf0223e8217e\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":\"1704.07434\",\"authors\":[{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"38314306\",\"name\":\"Rakshith Shetty\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"1708642\",\"name\":\"Jorma T. Laaksonen\"}],\"doi\":\"10.1109/ICCV.2017.272\",\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"e4a11cc697c94fdda9eedbac7d83a865646bd4cc\",\"title\":\"Paying Attention to Descriptions Generated by Image Captioning Models\",\"url\":\"https://www.semanticscholar.org/paper/e4a11cc697c94fdda9eedbac7d83a865646bd4cc\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1162/neco.1997.9.8.1735\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"title\":\"Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"venue\":\"Neural Computation\",\"year\":1997},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2997408\",\"name\":\"Matthias K\\u00fcmmerer\"},{\"authorId\":\"49737748\",\"name\":\"Thomas S. A. Wallis\"},{\"authorId\":\"1891828\",\"name\":\"Leon A. Gatys\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":\"10.1109/ICCV.2017.513\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"53d77b463ec744491ab68ed49f5d2152cbbcbf9d\",\"title\":\"Understanding Low- and High-Level Contributions to Fixation Prediction\",\"url\":\"https://www.semanticscholar.org/paper/53d77b463ec744491ab68ed49f5d2152cbbcbf9d\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1611.05594\",\"authors\":[{\"authorId\":\"143891667\",\"name\":\"Long Chen\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1406012647\",\"name\":\"Jun Xiao\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":\"104757141\",\"name\":\"Jian Shao\"},{\"authorId\":\"40366581\",\"name\":\"Wei Liu\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1109/CVPR.2017.667\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"88513e738a95840de05a62f0e43d30a67b3c542e\",\"title\":\"SCA-CNN: Spatial and Channel-Wise Attention in Convolutional Networks for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/88513e738a95840de05a62f0e43d30a67b3c542e\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1795076\",\"name\":\"M. Arbib\"}],\"doi\":\"10.1017/CBO9780511541599\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b45faf555489ab5d2a0a8c396f7353210583676a\",\"title\":\"Action to language via the mirror neuron system\",\"url\":\"https://www.semanticscholar.org/paper/b45faf555489ab5d2a0a8c396f7353210583676a\",\"venue\":\"\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3323275\",\"name\":\"Kishore Papineni\"},{\"authorId\":\"1781292\",\"name\":\"S. Roukos\"},{\"authorId\":\"144582029\",\"name\":\"T. Ward\"},{\"authorId\":\"2587983\",\"name\":\"Wei-Jing Zhu\"}],\"doi\":\"10.3115/1073083.1073135\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d7da009f457917aa381619facfa5ffae9329a6e9\",\"title\":\"Bleu: a Method for Automatic Evaluation of Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/d7da009f457917aa381619facfa5ffae9329a6e9\",\"venue\":\"ACL\",\"year\":2002},{\"arxivId\":\"1606.03556\",\"authors\":[{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"37825612\",\"name\":\"Harsh Agrawal\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1016/j.cviu.2017.10.001\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"58cb0c24c936b8a14ca7b2d56ba80de733c545b3\",\"title\":\"Human Attention in Visual Question Answering: Do Humans and Deep Networks look at the same regions?\",\"url\":\"https://www.semanticscholar.org/paper/58cb0c24c936b8a14ca7b2d56ba80de733c545b3\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Max Jaderberg\"},{\"authorId\":null,\"name\":\"Karen Simonyan\"},{\"authorId\":null,\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Spatial transformer networks. In Advances in neural information processing\",\"url\":\"\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2157958\",\"name\":\"Michael J. Denkowski\"},{\"authorId\":\"1784914\",\"name\":\"A. Lavie\"}],\"doi\":\"10.3115/v1/W14-3348\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"26adb749fc5d80502a6d889966e50b31391560d3\",\"title\":\"Meteor Universal: Language Specific Translation Evaluation for Any Target Language\",\"url\":\"https://www.semanticscholar.org/paper/26adb749fc5d80502a6d889966e50b31391560d3\",\"venue\":\"WMT@ACL\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144171250\",\"name\":\"M. Tanenhaus\"},{\"authorId\":\"1403814853\",\"name\":\"M. Spivey-Knowlton\"},{\"authorId\":\"2323416\",\"name\":\"K. M. Eberhard\"},{\"authorId\":\"39290981\",\"name\":\"J. Sedivy\"}],\"doi\":\"10.1126/SCIENCE.7777863\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"765491c9cfc746275000297fc0ae919b5c4440e0\",\"title\":\"Integration of visual and linguistic information in spoken language comprehension.\",\"url\":\"https://www.semanticscholar.org/paper/765491c9cfc746275000297fc0ae919b5c4440e0\",\"venue\":\"Science\",\"year\":1995},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"145297531\",\"name\":\"A. Lai\"},{\"authorId\":\"2170746\",\"name\":\"M. Hodosh\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"}],\"doi\":\"10.1162/tacl_a_00166\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"44040913380206991b1991daf1192942e038fe31\",\"title\":\"From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions\",\"url\":\"https://www.semanticscholar.org/paper/44040913380206991b1991daf1192942e038fe31\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2014},{\"arxivId\":\"1604.03605\",\"authors\":[{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"},{\"authorId\":\"152627906\",\"name\":\"T. Judd\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"}],\"doi\":\"10.1109/TPAMI.2018.2815601\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"bfdf3431ff5182b585b3b0c11fa8cbfc13a6bde4\",\"title\":\"What Do Different Evaluation Metrics Tell Us About Saliency Models?\",\"url\":\"https://www.semanticscholar.org/paper/bfdf3431ff5182b585b3b0c11fa8cbfc13a6bde4\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1109/TPAMI.2012.89\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aa57b9bdb0736cbb38abf0a9d12047212c2a2425\",\"title\":\"State-of-the-Art in Visual Attention Modeling\",\"url\":\"https://www.semanticscholar.org/paper/aa57b9bdb0736cbb38abf0a9d12047212c2a2425\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":\"1612.01887\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":\"10.1109/CVPR.2017.345\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"9f4d7d622d1f7319cc511bfef661cd973e881a4c\",\"title\":\"Knowing When to Look: Adaptive Attention via a Visual Sentinel for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9f4d7d622d1f7319cc511bfef661cd973e881a4c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33230676\",\"name\":\"Kiwon Yun\"},{\"authorId\":null,\"name\":\"Yifan Peng\"},{\"authorId\":\"145654220\",\"name\":\"D. Samaras\"},{\"authorId\":\"1696991\",\"name\":\"G. Zelinsky\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/CVPR.2013.101\",\"intent\":[\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"ad2c0ae801c9e8adece483e74725e12a8544d440\",\"title\":\"Studying Relationships between Human Gaze, Description, and Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/ad2c0ae801c9e8adece483e74725e12a8544d440\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":\"1904.00767\",\"authors\":[{\"authorId\":\"1807405\",\"name\":\"S. Chen\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1007/978-3-030-01252-6_5\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5cab3ce511ec8345d16a28c00094a2800b3919ce\",\"title\":\"Boosted Attention: Leveraging Human Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/5cab3ce511ec8345d16a28c00094a2800b3919ce\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1810.03716\",\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4df34e0194faa27078832cb5078a2af6c9d0ea9b\",\"title\":\"Saliency Prediction in the Deep Learning Era: An Empirical Investigation\",\"url\":\"https://www.semanticscholar.org/paper/4df34e0194faa27078832cb5078a2af6c9d0ea9b\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/CVPRW.2018.00250\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cc5b8c711f4d6d42fff939f19d8828545cc801c1\",\"title\":\"SAM: Pushing the Limits of Saliency Prediction Models\",\"url\":\"https://www.semanticscholar.org/paper/cc5b8c711f4d6d42fff939f19d8828545cc801c1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3192572\",\"name\":\"Emiel van Miltenburg\"},{\"authorId\":\"2828538\",\"name\":\"\\u00c1kos K\\u00e1d\\u00e1r\"},{\"authorId\":\"2045556\",\"name\":\"R. Koolen\"},{\"authorId\":\"145210073\",\"name\":\"E. Krahmer\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"14bfde3b760bc09d4c93f81dc029429fca734c48\",\"title\":\"DIDEC: The Dutch Image Description and Eye-tracking Corpus\",\"url\":\"https://www.semanticscholar.org/paper/14bfde3b760bc09d4c93f81dc029429fca734c48\",\"venue\":\"COLING\",\"year\":2018},{\"arxivId\":\"1903.02501\",\"authors\":[{\"authorId\":\"47287647\",\"name\":\"Sen He\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"145071344\",\"name\":\"Yang Mi\"},{\"authorId\":\"3251678\",\"name\":\"N. Pugeault\"}],\"doi\":\"10.1109/CVPR.2019.01045\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"38410376deedfdfc32e53b7369b9ea2297fa521f\",\"title\":\"Understanding and Visualizing Deep Visual Saliency Models\",\"url\":\"https://www.semanticscholar.org/paper/38410376deedfdfc32e53b7369b9ea2297fa521f\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"13819131\",\"name\":\"M. M\\u00fcller\"}],\"doi\":\"10.1007/978-3-540-74048-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9695b92f08d563ec053d4c89927836d9c8f01d26\",\"title\":\"Information retrieval for music and motion\",\"url\":\"https://www.semanticscholar.org/paper/9695b92f08d563ec053d4c89927836d9c8f01d26\",\"venue\":\"\",\"year\":2007}],\"title\":\"Human Attention in Image Captioning: Dataset and Analysis\",\"topics\":[{\"topic\":\"Convolutional neural network\",\"topicId\":\"29860\",\"url\":\"https://www.semanticscholar.org/topic/29860\"},{\"topic\":\"Top-down and bottom-up design\",\"topicId\":\"96387\",\"url\":\"https://www.semanticscholar.org/topic/96387\"},{\"topic\":\"Humans\",\"topicId\":\"732\",\"url\":\"https://www.semanticscholar.org/topic/732\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"},{\"topic\":\"Biconnected component\",\"topicId\":\"334045\",\"url\":\"https://www.semanticscholar.org/topic/334045\"},{\"topic\":\"Encoder\",\"topicId\":\"16744\",\"url\":\"https://www.semanticscholar.org/topic/16744\"},{\"topic\":\"Software deployment\",\"topicId\":\"328066\",\"url\":\"https://www.semanticscholar.org/topic/328066\"}],\"url\":\"https://www.semanticscholar.org/paper/e4a91b8c1259e7744784d922f250dd77ea951e9f\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019}\n"