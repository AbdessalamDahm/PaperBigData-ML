"{\"abstract\":\"Image captioning models have achieved impressive results on datasets containing limited visual concepts and large amounts of paired image-caption training data. However, if these models are to ever function in the wild, a much larger variety of visual concepts must be learned, ideally from less supervision. To encourage the development of image captioning models that can learn visual concepts from alternative data sources, such as object detection datasets, we present the first large-scale benchmark for this task. Dubbed \\u2018nocaps\\u2019, for novel object captioning at scale, our benchmark consists of 166,100 human-generated captions describing 15,100 images from the Open Images validation and test sets. The associated training data consists of COCO image-caption pairs, plus Open Images image-level labels and object bounding boxes. Since Open Images contains many more classes than COCO, nearly 400 object classes seen in test images have no or very few associated training captions (hence, nocaps). We extend existing novel object captioning models to establish strong baselines for this benchmark and provide analysis to guide future work.\",\"arxivId\":\"1812.08658\",\"authors\":[{\"authorId\":\"37825612\",\"name\":\"Harsh Agrawal\",\"url\":\"https://www.semanticscholar.org/author/37825612\"},{\"authorId\":\"1606411716\",\"name\":\"Karan Desai\",\"url\":\"https://www.semanticscholar.org/author/1606411716\"},{\"authorId\":\"46395829\",\"name\":\"Yufei Wang\",\"url\":\"https://www.semanticscholar.org/author/46395829\"},{\"authorId\":\"1606041624\",\"name\":\"Xinlei Chen\",\"url\":\"https://www.semanticscholar.org/author/1606041624\"},{\"authorId\":\"145461380\",\"name\":\"Rishabh Jain\",\"url\":\"https://www.semanticscholar.org/author/145461380\"},{\"authorId\":\"1607624548\",\"name\":\"Mark Johnson\",\"url\":\"https://www.semanticscholar.org/author/1607624548\"},{\"authorId\":\"1606364265\",\"name\":\"Dhruv Batra\",\"url\":\"https://www.semanticscholar.org/author/1606364265\"},{\"authorId\":\"1606363958\",\"name\":\"Devi Parikh\",\"url\":\"https://www.semanticscholar.org/author/1606363958\"},{\"authorId\":\"1607486000\",\"name\":\"Stefan Lee\",\"url\":\"https://www.semanticscholar.org/author/1607486000\"},{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\",\"url\":\"https://www.semanticscholar.org/author/6965856\"}],\"citationVelocity\":12,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Eli Pugh\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2864ea38ac22ebeddd8044c09a5a750ac2c7f36a\",\"title\":\"A Meta Learning Approach to Novel Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/2864ea38ac22ebeddd8044c09a5a750ac2c7f36a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48394426\",\"name\":\"Naeha Sharif\"},{\"authorId\":\"8799308\",\"name\":\"U. Nadeem\"},{\"authorId\":\"14752125\",\"name\":\"Syed Afaq Ali Shah\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"1980026040\",\"name\":\"Wei Liu\"}],\"doi\":\"10.1007/978-3-030-49724-8_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8885ae1cbdac1d27443167689ed872dfe46c9e3f\",\"title\":\"Vision to Language: Methods, Metrics and Datasets\",\"url\":\"https://www.semanticscholar.org/paper/8885ae1cbdac1d27443167689ed872dfe46c9e3f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2006.02174\",\"authors\":[{\"authorId\":\"3444866\",\"name\":\"Alessandro Suglia\"},{\"authorId\":\"2621022\",\"name\":\"Ioannis Konstas\"},{\"authorId\":\"34742006\",\"name\":\"Andrea Vanzo\"},{\"authorId\":\"2972920\",\"name\":\"E. Bastianelli\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"143873430\",\"name\":\"S. Frank\"},{\"authorId\":\"1782798\",\"name\":\"Oliver Lemon\"}],\"doi\":\"10.18653/V1/2020.ACL-MAIN.682\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fc78991050e355477f9d0ba51a241947e8bc9b9d\",\"title\":\"CompGuessWhat?!: A Multi-task Evaluation Framework for Grounded Language Learning\",\"url\":\"https://www.semanticscholar.org/paper/fc78991050e355477f9d0ba51a241947e8bc9b9d\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144897421\",\"name\":\"Rachel N. Simons\"},{\"authorId\":\"2028946\",\"name\":\"D. Gurari\"},{\"authorId\":\"3079031\",\"name\":\"Kenneth R. Fleischmann\"}],\"doi\":\"10.1145/3415176\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f2d4b8de7f9ed9a1a0b403e9f1ad9365b599c5ad\",\"title\":\"\\\"I Hope This Is Helpful\\\"\",\"url\":\"https://www.semanticscholar.org/paper/f2d4b8de7f9ed9a1a0b403e9f1ad9365b599c5ad\",\"venue\":\"Proc. ACM Hum. Comput. Interact.\",\"year\":2020},{\"arxivId\":\"2003.00387\",\"authors\":[{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"},{\"authorId\":\"1490938689\",\"name\":\"Peng Wang\"},{\"authorId\":\"49018095\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1109/cvpr42600.2020.00998\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b4916e339caef2d2a98e633e1f0b2144e2b0c9e2\",\"title\":\"Say As You Wish: Fine-Grained Control of Image Caption Generation With Abstract Scene Graphs\",\"url\":\"https://www.semanticscholar.org/paper/b4916e339caef2d2a98e633e1f0b2144e2b0c9e2\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1912.08226\",\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"144255105\",\"name\":\"M. Stefanini\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"261570379fd841b426a4c51e8004f2cf9f1df771\",\"title\":\"M2: Meshed-Memory Transformer for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/261570379fd841b426a4c51e8004f2cf9f1df771\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1904.03493\",\"authors\":[{\"authorId\":\"48631993\",\"name\":\"Xin Eric Wang\"},{\"authorId\":\"46365930\",\"name\":\"Jiawei Wu\"},{\"authorId\":\"47739808\",\"name\":\"Junkun Chen\"},{\"authorId\":\"46255707\",\"name\":\"Lei Li\"},{\"authorId\":\"1706938\",\"name\":\"Y. Wang\"},{\"authorId\":\"1682479\",\"name\":\"William Yang Wang\"}],\"doi\":\"10.1109/ICCV.2019.00468\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"28b74bb7c8b08cceb2430ec2d54dfa0f3225d796\",\"title\":\"VaTeX: A Large-Scale, High-Quality Multilingual Dataset for Video-and-Language Research\",\"url\":\"https://www.semanticscholar.org/paper/28b74bb7c8b08cceb2430ec2d54dfa0f3225d796\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2009.13682\",\"authors\":[{\"authorId\":\"50049779\",\"name\":\"X. Hu\"},{\"authorId\":\"1629039205\",\"name\":\"Xi Yin\"},{\"authorId\":\"51188307\",\"name\":\"Kevin Lin\"},{\"authorId\":\"29957038\",\"name\":\"Longguang Wang\"},{\"authorId\":\"1720539\",\"name\":\"L. Zhang\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"1691128\",\"name\":\"Zicheng Liu\"}],\"doi\":null,\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f147279c9d1edddda57f1f21f23b3b58998bad74\",\"title\":\"VIVO: Surpassing Human Performance in Novel Object Captioning with Visual Vocabulary Pre-Training\",\"url\":\"https://www.semanticscholar.org/paper/f147279c9d1edddda57f1f21f23b3b58998bad74\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.12058\",\"authors\":[{\"authorId\":\"4055152\",\"name\":\"Sarah Pratt\"},{\"authorId\":\"2064210\",\"name\":\"Mark Yatskar\"},{\"authorId\":\"20745881\",\"name\":\"Luca Weihs\"},{\"authorId\":\"47465174\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"}],\"doi\":\"10.1007/978-3-030-58548-8_19\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fc261c0efb5f9ce82581932d1440630b861fb85f\",\"title\":\"Grounded Situation Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fc261c0efb5f9ce82581932d1440630b861fb85f\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2003.11743\",\"authors\":[{\"authorId\":\"1491233100\",\"name\":\"Pranav Agarwal\"},{\"authorId\":\"145086911\",\"name\":\"A. Betancourt\"},{\"authorId\":\"1594025086\",\"name\":\"V. Panagiotou\"},{\"authorId\":\"2251072\",\"name\":\"N. Rodr\\u00edguez\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b430a5384c82beb6102106fbea0a134425a08c23\",\"title\":\"Egoshots, an ego-vision life-logging dataset and semantic fidelity metric to evaluate diversity in image captioning models\",\"url\":\"https://www.semanticscholar.org/paper/b430a5384c82beb6102106fbea0a134425a08c23\",\"venue\":\"ICLR 2020\",\"year\":2020},{\"arxivId\":\"2002.08565\",\"authors\":[{\"authorId\":\"2028946\",\"name\":\"D. Gurari\"},{\"authorId\":\"150353841\",\"name\":\"Yinan Zhao\"},{\"authorId\":\"1409765557\",\"name\":\"Meng Zhang\"},{\"authorId\":\"23364558\",\"name\":\"Nilavra Bhattacharya\"}],\"doi\":\"10.1007/978-3-030-58520-4_25\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c936d878003254cdab662a966cecd29e8be652d0\",\"title\":\"Captioning Images Taken by People Who Are Blind\",\"url\":\"https://www.semanticscholar.org/paper/c936d878003254cdab662a966cecd29e8be652d0\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2003.12462\",\"authors\":[{\"authorId\":\"144656873\",\"name\":\"O. Sidorov\"},{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"50286460\",\"name\":\"Amanpreet Singh\"}],\"doi\":\"10.1007/978-3-030-58536-5_44\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7442eaaf453e63195cdee037f8e23830b4004027\",\"title\":\"TextCaps: a Dataset for Image Captioning with Reading Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/7442eaaf453e63195cdee037f8e23830b4004027\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1909.04402\",\"authors\":[{\"authorId\":\"1387994359\",\"name\":\"Mitja Nikolaus\"},{\"authorId\":\"30671790\",\"name\":\"M. Abdou\"},{\"authorId\":\"48024953\",\"name\":\"Matthew Lamm\"},{\"authorId\":\"19509693\",\"name\":\"Rahul Aralikatte\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"}],\"doi\":\"10.18653/v1/K19-1009\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"11557ee241f6b5dc0a8c62bb8014c0111bbe45ba\",\"title\":\"Compositional Generalization in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/11557ee241f6b5dc0a8c62bb8014c0111bbe45ba\",\"venue\":\"CoNLL\",\"year\":2019},{\"arxivId\":\"2011.00966\",\"authors\":[{\"authorId\":\"32370882\",\"name\":\"Shweta Mahajan\"},{\"authorId\":\"49863405\",\"name\":\"S. Roth\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7d805e35f17dab7382748130a2ca1bda629cdceb\",\"title\":\"Diverse Image Captioning with Context-Object Split Latent Spaces\",\"url\":\"https://www.semanticscholar.org/paper/7d805e35f17dab7382748130a2ca1bda629cdceb\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2234342\",\"name\":\"L. Hendricks\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"dd7062e6f84750688fa96143209efc801e91f9bd\",\"title\":\"Visual Understanding through Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/dd7062e6f84750688fa96143209efc801e91f9bd\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1906.05518\",\"authors\":[{\"authorId\":\"1721364\",\"name\":\"Sina Zarrie\\u00df\"},{\"authorId\":\"1817455\",\"name\":\"David Schlangen\"}],\"doi\":\"10.18653/v1/P19-1063\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d4e26768300d94850418de10484067707fec34ec\",\"title\":\"Know What You Don't Know: Modeling a Pragmatic Speaker that Refers to Objects of Unknown Categories\",\"url\":\"https://www.semanticscholar.org/paper/d4e26768300d94850418de10484067707fec34ec\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"144255105\",\"name\":\"M. Stefanini\"},{\"authorId\":\"92326466\",\"name\":\"L. Baraldi\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/cvpr42600.2020.01059\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3c5882ba83265093f2625fcebaf41bcdae4548a1\",\"title\":\"Meshed-Memory Transformer for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/3c5882ba83265093f2625fcebaf41bcdae4548a1\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2001.01037\",\"authors\":[{\"authorId\":\"46969089\",\"name\":\"J. Sun\"},{\"authorId\":\"3633358\",\"name\":\"S. Lapuschkin\"},{\"authorId\":\"1699054\",\"name\":\"W. Samek\"},{\"authorId\":\"49345823\",\"name\":\"Alexander Binder\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"82e836be97e706dca7029ce6a0553b4890726593\",\"title\":\"Understanding Image Captioning Models beyond Visualizing Attention\",\"url\":\"https://www.semanticscholar.org/paper/82e836be97e706dca7029ce6a0553b4890726593\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1908.02265\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"65a9c7b0800c86a196bc14e7621ff895cc6ab287\",\"title\":\"ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/65a9c7b0800c86a196bc14e7621ff895cc6ab287\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2101328\",\"name\":\"Xue-Jing Liu\"},{\"authorId\":\"50703807\",\"name\":\"L. Li\"},{\"authorId\":\"47672591\",\"name\":\"Shuhui Wang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"2797676\",\"name\":\"Dechao Meng\"},{\"authorId\":\"153159021\",\"name\":\"Qingming Huang\"}],\"doi\":\"10.1145/3394171.3413677\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0767d8241f959f42e2e747cf17813c78cacc79e1\",\"title\":\"Transferrable Referring Expression Grounding with Concept Transfer and Context Inheritance\",\"url\":\"https://www.semanticscholar.org/paper/0767d8241f959f42e2e747cf17813c78cacc79e1\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ming Jiang\"},{\"authorId\":null,\"name\":\"Qi Zhao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3977c0056755c2911811509ac38e0cef532004b0\",\"title\":\"Self-Distillation for Few-Shot Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/3977c0056755c2911811509ac38e0cef532004b0\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1907.09358\",\"authors\":[{\"authorId\":\"3219864\",\"name\":\"Aditya Mogadala\"},{\"authorId\":\"151119369\",\"name\":\"M. Kalimuthu\"},{\"authorId\":\"2561225\",\"name\":\"D. Klakow\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f8a48678094adbe421d61d0045361bfc635a2900\",\"title\":\"Trends in Integration of Vision and Language Research: A Survey of Tasks, Datasets, and Methods\",\"url\":\"https://www.semanticscholar.org/paper/f8a48678094adbe421d61d0045361bfc635a2900\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22199114\",\"name\":\"Panos Achlioptas\"},{\"authorId\":\"30628940\",\"name\":\"Ahmed Abdelreheem\"},{\"authorId\":\"66562670\",\"name\":\"F. Xia\"},{\"authorId\":\"1712479\",\"name\":\"Mohamed Elhoseiny\"},{\"authorId\":\"1744254\",\"name\":\"L. Guibas\"}],\"doi\":\"10.1007/978-3-030-58452-8_25\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"53794499a3830c3ebb365ecc57f0e8c8a20a682d\",\"title\":\"ReferIt3D: Neural Listeners for Fine-Grained 3D Object Identification in Real-World Scenes\",\"url\":\"https://www.semanticscholar.org/paper/53794499a3830c3ebb365ecc57f0e8c8a20a682d\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2003.03305\",\"authors\":[{\"authorId\":\"40912088\",\"name\":\"M. Tanaka\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"22d733f5d5a995469dc916102f1806253645ae60\",\"title\":\"Captioning Images with Novel Objects via Online Vocabulary Expansion\",\"url\":\"https://www.semanticscholar.org/paper/22d733f5d5a995469dc916102f1806253645ae60\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"144255105\",\"name\":\"M. Stefanini\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"bcec2fc7db5df44eee4e84cd15bf6aa537d524c0\",\"title\":\"Meshed-Memory Transformer for Image Captioning Supplementary Material\",\"url\":\"https://www.semanticscholar.org/paper/bcec2fc7db5df44eee4e84cd15bf6aa537d524c0\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2004.06165\",\"authors\":[{\"authorId\":\"47058148\",\"name\":\"Xiujun Li\"},{\"authorId\":\"1629039205\",\"name\":\"Xi Yin\"},{\"authorId\":\"1978606\",\"name\":\"C. Li\"},{\"authorId\":\"50049779\",\"name\":\"X. Hu\"},{\"authorId\":\"9325940\",\"name\":\"Pengchuan Zhang\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"},{\"authorId\":\"29957038\",\"name\":\"Longguang Wang\"},{\"authorId\":\"35431603\",\"name\":\"H. Hu\"},{\"authorId\":\"145307652\",\"name\":\"Li Dong\"},{\"authorId\":\"49807919\",\"name\":\"Furu Wei\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":\"10.1007/978-3-030-58577-8_8\",\"intent\":[\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"818e5cbc337e4e1b98e65a2d7c2d6d2a0318cd57\",\"title\":\"Oscar: Object-Semantics Aligned Pre-training for Vision-Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/818e5cbc337e4e1b98e65a2d7c2d6d2a0318cd57\",\"venue\":\"ECCV\",\"year\":2020}],\"corpusId\":56517630,\"doi\":\"10.1109/ICCV.2019.00904\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":6,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"8b55402ffee2734bfc7d5d7595500916e1ef04e8\",\"references\":[{\"arxivId\":\"1603.09016\",\"authors\":[{\"authorId\":\"143690259\",\"name\":\"K. Tran\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/CVPRW.2016.61\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"18f1143c64e6557c933b206fb8b2a7bd1f389afd\",\"title\":\"Rich Image Captioning in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/18f1143c64e6557c933b206fb8b2a7bd1f389afd\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2016},{\"arxivId\":\"1708.02750\",\"authors\":[{\"authorId\":\"1749373\",\"name\":\"Dim P. Papadopoulos\"},{\"authorId\":\"1823362\",\"name\":\"J. Uijlings\"},{\"authorId\":\"143694777\",\"name\":\"Frank Keller\"},{\"authorId\":\"143865718\",\"name\":\"V. Ferrari\"}],\"doi\":\"10.1109/ICCV.2017.528\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"469bf173e05a8a17170bbb317502b1e6002ebdc1\",\"title\":\"Extreme Clicking for Efficient Object Annotation\",\"url\":\"https://www.semanticscholar.org/paper/469bf173e05a8a17170bbb317502b1e6002ebdc1\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1612.00576\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.18653/v1/D17-1098\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"086fa2fe3ee2a5b805aeaf9fbfe59ee8157dad5c\",\"title\":\"Guided Open Vocabulary Image Captioning with Constrained Beam Search\",\"url\":\"https://www.semanticscholar.org/paper/086fa2fe3ee2a5b805aeaf9fbfe59ee8157dad5c\",\"venue\":\"EMNLP\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Oriol Vinyals\"},{\"authorId\":null,\"name\":\"Alexander Toshev\"},{\"authorId\":null,\"name\":\"Samy Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Mooney , Trevor Darrell , and Kate Saenko . Captioning Images with Diverse Objects\",\"url\":\"\",\"venue\":\"In CVPR\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1784914\",\"name\":\"A. Lavie\"},{\"authorId\":\"3766304\",\"name\":\"Abhaya Agarwal\"}],\"doi\":\"10.3115/1626355.1626389\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"34d7a07c493ca6336c92156806a2947e115caadc\",\"title\":\"METEOR: An Automatic Metric for MT Evaluation with High Levels of Correlation with Human Judgments\",\"url\":\"https://www.semanticscholar.org/paper/34d7a07c493ca6336c92156806a2947e115caadc\",\"venue\":\"WMT@ACL\",\"year\":2007},{\"arxivId\":\"1611.10012\",\"authors\":[{\"authorId\":\"4240351\",\"name\":\"Jonathan Huang\"},{\"authorId\":\"40303375\",\"name\":\"V. Rathod\"},{\"authorId\":\"145546535\",\"name\":\"Chen Sun\"},{\"authorId\":\"2717876\",\"name\":\"Menglong Zhu\"},{\"authorId\":\"34786378\",\"name\":\"A. Balan\"},{\"authorId\":\"50706340\",\"name\":\"Alireza Fathi\"},{\"authorId\":\"33091759\",\"name\":\"Ian S. Fischer\"},{\"authorId\":\"3282833\",\"name\":\"Z. Wojna\"},{\"authorId\":\"49992891\",\"name\":\"Y. Song\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"145601650\",\"name\":\"K. Murphy\"}],\"doi\":\"10.1109/CVPR.2017.351\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a312a573ef81793d56401e932ef6c9498791a3d1\",\"title\":\"Speed/Accuracy Trade-Offs for Modern Convolutional Object Detectors\",\"url\":\"https://www.semanticscholar.org/paper/a312a573ef81793d56401e932ef6c9498791a3d1\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1c46943103bd7b7a2c7be86859995a4144d1938b\",\"title\":\"Visualizing Data using t-SNE\",\"url\":\"https://www.semanticscholar.org/paper/1c46943103bd7b7a2c7be86859995a4144d1938b\",\"venue\":\"\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47087291\",\"name\":\"Z. Yang\"},{\"authorId\":\"30556331\",\"name\":\"Y. Yuan\"},{\"authorId\":\"9287688\",\"name\":\"Yuexin Wu\"},{\"authorId\":\"50056360\",\"name\":\"William W. Cohen\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"61d2dda8d96a10a714636475c7589bd149bda053\",\"title\":\"Review Networks for Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/61d2dda8d96a10a714636475c7589bd149bda053\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3323275\",\"name\":\"Kishore Papineni\"},{\"authorId\":\"1781292\",\"name\":\"S. Roukos\"},{\"authorId\":\"144582029\",\"name\":\"T. Ward\"},{\"authorId\":\"2587983\",\"name\":\"Wei-Jing Zhu\"}],\"doi\":\"10.3115/1073083.1073135\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d7da009f457917aa381619facfa5ffae9329a6e9\",\"title\":\"Bleu: a Method for Automatic Evaluation of Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/d7da009f457917aa381619facfa5ffae9329a6e9\",\"venue\":\"ACL\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"I. Krasin\"},{\"authorId\":null,\"name\":\"T. Duerig\"},{\"authorId\":null,\"name\":\"N. Alldrin\"},{\"authorId\":null,\"name\":\"V. Ferrari\"},{\"authorId\":null,\"name\":\"S. Abu-El-Haija\"},{\"authorId\":null,\"name\":\"A. Kuznetsova\"},{\"authorId\":null,\"name\":\"H. Rom\"},{\"authorId\":null,\"name\":\"J. Uijlings\"},{\"authorId\":null,\"name\":\"S. Popov\"},{\"authorId\":null,\"name\":\"A. Veit\"},{\"authorId\":null,\"name\":\"S. Belongie\"},{\"authorId\":null,\"name\":\"V. Gomes\"},{\"authorId\":null,\"name\":\"A. Gupta\"},{\"authorId\":null,\"name\":\"C. Sun\"},{\"authorId\":null,\"name\":\"G. Chechik\"},{\"authorId\":null,\"name\":\"D. Cai\"},{\"authorId\":null,\"name\":\"Z. Feng\"},{\"authorId\":null,\"name\":\"D. Narayanan\"},{\"authorId\":null,\"name\":\"K. Murphy\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Openimages: A public dataset for large-scale multi-label and multi-class image classification\",\"url\":\"\",\"venue\":\"Dataset available from https://github.com/openimages,\",\"year\":2017},{\"arxivId\":\"1806.06004\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ceabd7ff28ce2d501511da998252aeb938adc98b\",\"title\":\"Partially-Supervised Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/ceabd7ff28ce2d501511da998252aeb938adc98b\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1607.08822\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1007/978-3-319-46454-1_24\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1c54acd7d9ed8017acdc5674c9b7faac738fd651\",\"title\":\"SPICE: Semantic Propositional Image Caption Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/1c54acd7d9ed8017acdc5674c9b7faac738fd651\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"145297531\",\"name\":\"A. Lai\"},{\"authorId\":\"2170746\",\"name\":\"M. Hodosh\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"}],\"doi\":\"10.1162/tacl_a_00166\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"44040913380206991b1991daf1192942e038fe31\",\"title\":\"From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions\",\"url\":\"https://www.semanticscholar.org/paper/44040913380206991b1991daf1192942e038fe31\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2014},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1702.05374\",\"authors\":[{\"authorId\":\"1808423\",\"name\":\"G. Csurka\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"330dda431e0343a96f9d630a0b4ee526bd93ad11\",\"title\":\"Domain Adaptation for Visual Applications: A Comprehensive Survey\",\"url\":\"https://www.semanticscholar.org/paper/330dda431e0343a96f9d630a0b4ee526bd93ad11\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2170746\",\"name\":\"M. Hodosh\"},{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"}],\"doi\":\"10.1613/jair.3994\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9814df8bd00ba999c4d1e305a7e9bca579dc7c75\",\"title\":\"Framing Image Description as a Ranking Task: Data, Models and Evaluation Metrics (Extended Abstract)\",\"url\":\"https://www.semanticscholar.org/paper/9814df8bd00ba999c4d1e305a7e9bca579dc7c75\",\"venue\":\"IJCAI\",\"year\":2013},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1611.05431\",\"authors\":[{\"authorId\":\"1817030\",\"name\":\"Saining Xie\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"144035504\",\"name\":\"Zhuowen Tu\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"}],\"doi\":\"10.1109/CVPR.2017.634\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f6e0856b4a9199fa968ac00da612a9407b5cb85c\",\"title\":\"Aggregated Residual Transformations for Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/f6e0856b4a9199fa968ac00da612a9407b5cb85c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1611.08321\",\"authors\":[{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"2560579\",\"name\":\"J. Xu\"},{\"authorId\":\"39554931\",\"name\":\"Yushi Jing\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cc18cb42289fd570a06896b5543b085ebabee57b\",\"title\":\"Training and Evaluating Multimodal Word Embeddings with Large-scale Web Annotated Images\",\"url\":\"https://www.semanticscholar.org/paper/cc18cb42289fd570a06896b5543b085ebabee57b\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1602.08405\",\"authors\":[{\"authorId\":\"1749373\",\"name\":\"Dim P. Papadopoulos\"},{\"authorId\":\"1823362\",\"name\":\"J. Uijlings\"},{\"authorId\":\"143694777\",\"name\":\"Frank Keller\"},{\"authorId\":\"143865718\",\"name\":\"V. Ferrari\"}],\"doi\":\"10.1109/CVPR.2016.99\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5f48e89e49b1a414f6029a41933c2aa6008d12de\",\"title\":\"We Don\\u2019t Need No Bounding-Boxes: Training Object Class Detectors Using Only Human Verification\",\"url\":\"https://www.semanticscholar.org/paper/5f48e89e49b1a414f6029a41933c2aa6008d12de\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ivan Krasin\"},{\"authorId\":null,\"name\":\"Tom Duerig\"},{\"authorId\":null,\"name\":\"Neil Alldrin\"},{\"authorId\":null,\"name\":\"Vittorio Ferrari\"},{\"authorId\":null,\"name\":\"Sami Abu-El-Haija\"},{\"authorId\":null,\"name\":\"Alina Kuznetsova\"},{\"authorId\":null,\"name\":\"Hassan Rom\"},{\"authorId\":null,\"name\":\"Jasper Uijlings\"},{\"authorId\":null,\"name\":\"Stefan Popov\"},{\"authorId\":null,\"name\":\"Andreas Veit\"},{\"authorId\":null,\"name\":\"Serge Belongie\"},{\"authorId\":null,\"name\":\"Victor Gomes\"},{\"authorId\":null,\"name\":\"Abhinav Gupta\"},{\"authorId\":null,\"name\":\"Chen Sun\"},{\"authorId\":null,\"name\":\"Gal Chechik\"},{\"authorId\":null,\"name\":\"David Cai\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Zheyun Feng, Dhyanesh Narayanan, and Kevin Murphy. Openimages: A public dataset for large-scale multilabel and multi-class image classification\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2015.7298932\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"title\":\"Deep visual-semantic alignments for generating image descriptions\",\"url\":\"https://www.semanticscholar.org/paper/ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"venue\":\"CVPR\",\"year\":2015},{\"arxivId\":\"1612.00563\",\"authors\":[{\"authorId\":\"2071376\",\"name\":\"Steven J. Rennie\"},{\"authorId\":\"2293163\",\"name\":\"E. Marcheret\"},{\"authorId\":\"2211263\",\"name\":\"Youssef Mroueh\"},{\"authorId\":\"39320489\",\"name\":\"J. Ross\"},{\"authorId\":\"1782589\",\"name\":\"V. Goel\"}],\"doi\":\"10.1109/CVPR.2017.131\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6c8353697cdbb98dfba4f493875778c4286d3e3a\",\"title\":\"Self-Critical Sequence Training for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6c8353697cdbb98dfba4f493875778c4286d3e3a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47130333\",\"name\":\"Siqi Liu\"},{\"authorId\":\"39815369\",\"name\":\"Z. Zhu\"},{\"authorId\":\"145361612\",\"name\":\"N. Ye\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":\"10.1109/ICCV.2017.100\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"163a474747fd63ab62ae586711fa5e5a2ac91bd8\",\"title\":\"Improved Image Captioning via Policy Gradient optimization of SPIDEr\",\"url\":\"https://www.semanticscholar.org/paper/163a474747fd63ab62ae586711fa5e5a2ac91bd8\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"R. Girshick\"},{\"authorId\":null,\"name\":\"I. Radosavovic\"},{\"authorId\":null,\"name\":\"G. Gkioxari\"},{\"authorId\":null,\"name\":\"P. Doll\\u00e1r\"},{\"authorId\":null,\"name\":\"K. He\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Detectron.\\u201d https://github.com/ facebookresearch/detectron, 2018\",\"url\":\"\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35043531\",\"name\":\"A. Dempster\"},{\"authorId\":\"7890796\",\"name\":\"N. Laird\"},{\"authorId\":\"2235217\",\"name\":\"D. Rubin\"}],\"doi\":\"10.1111/J.2517-6161.1977.TB01600.X\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d36efb9ad91e00faa334b549ce989bfae7e2907a\",\"title\":\"Maximum likelihood from incomplete data via the EM - algorithm plus discussions on the paper\",\"url\":\"https://www.semanticscholar.org/paper/d36efb9ad91e00faa334b549ce989bfae7e2907a\",\"venue\":\"\",\"year\":1977},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1781574\",\"name\":\"Chin-Yew Lin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"60b05f32c32519a809f21642ef1eb3eaf3848008\",\"title\":\"ROUGE: A Package for Automatic Evaluation of Summaries\",\"url\":\"https://www.semanticscholar.org/paper/60b05f32c32519a809f21642ef1eb3eaf3848008\",\"venue\":\"ACL 2004\",\"year\":2004},{\"arxivId\":\"1511.05284\",\"authors\":[{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/CVPR.2016.8\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e516d22697bad6d0f7956b0e8bfa93d6eb0b2f17\",\"title\":\"Deep Compositional Captioning: Describing Novel Object Categories without Paired Training Data\",\"url\":\"https://www.semanticscholar.org/paper/e516d22697bad6d0f7956b0e8bfa93d6eb0b2f17\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1806.00451\",\"authors\":[{\"authorId\":\"9229182\",\"name\":\"B. Recht\"},{\"authorId\":\"40458654\",\"name\":\"Rebecca Roelofs\"},{\"authorId\":\"33404869\",\"name\":\"L. Schmidt\"},{\"authorId\":\"34961417\",\"name\":\"V. Shankar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f445493badf53febbaeab340a4fca98d9e4ab7f7\",\"title\":\"Do CIFAR-10 Classifiers Generalize to CIFAR-10?\",\"url\":\"https://www.semanticscholar.org/paper/f445493badf53febbaeab340a4fca98d9e4ab7f7\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1411.4952\",\"authors\":[{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3346186\",\"name\":\"Forrest N. Iandola\"},{\"authorId\":\"2100612\",\"name\":\"R. Srivastava\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"144189092\",\"name\":\"John C. Platt\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"}],\"doi\":\"10.1109/CVPR.2015.7298754\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"title\":\"From captions to visual concepts and back\",\"url\":\"https://www.semanticscholar.org/paper/15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1805.04787\",\"authors\":[{\"authorId\":\"2265599\",\"name\":\"Luheng He\"},{\"authorId\":\"2544107\",\"name\":\"Kenton Lee\"},{\"authorId\":\"39455775\",\"name\":\"Omer Levy\"},{\"authorId\":\"1982950\",\"name\":\"Luke Zettlemoyer\"}],\"doi\":\"10.18653/v1/p18-2058\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7442a18a55f257a68f21d0cbb8b1395f8915a452\",\"title\":\"Jointly Predicting Predicates and Arguments in Neural Semantic Role Labeling\",\"url\":\"https://www.semanticscholar.org/paper/7442a18a55f257a68f21d0cbb8b1395f8915a452\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52184096\",\"name\":\"L. Bottou\"}],\"doi\":\"10.1007/978-3-7908-2604-3_16\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fbc6562814e08e416e28a268ce7beeaa3d0708c8\",\"title\":\"Large-Scale Machine Learning with Stochastic Gradient Descent\",\"url\":\"https://www.semanticscholar.org/paper/fbc6562814e08e416e28a268ce7beeaa3d0708c8\",\"venue\":\"COMPSTAT\",\"year\":2010},{\"arxivId\":\"1606.07770\",\"authors\":[{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/CVPR.2017.130\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b9aa3bafa9e8e21bb92908ae23b468fa248239b3\",\"title\":\"Captioning Images with Diverse Objects\",\"url\":\"https://www.semanticscholar.org/paper/b9aa3bafa9e8e21bb92908ae23b468fa248239b3\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143845796\",\"name\":\"Jeffrey Pennington\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.3115/v1/D14-1162\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"title\":\"Glove: Global Vectors for Word Representation\",\"url\":\"https://www.semanticscholar.org/paper/f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39455775\",\"name\":\"Omer Levy\"},{\"authorId\":\"2089067\",\"name\":\"Y. Goldberg\"}],\"doi\":\"10.3115/v1/P14-2050\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0183b3e9d84c15c7048e6c2149ed86257ccdc6cb\",\"title\":\"Dependency-Based Word Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/0183b3e9d84c15c7048e6c2149ed86257ccdc6cb\",\"venue\":\"ACL\",\"year\":2014},{\"arxivId\":\"1804.07461\",\"authors\":[{\"authorId\":\"144906624\",\"name\":\"Alex Wang\"},{\"authorId\":\"50286460\",\"name\":\"Amanpreet Singh\"},{\"authorId\":\"38614754\",\"name\":\"Julian Michael\"},{\"authorId\":\"145783676\",\"name\":\"Felix Hill\"},{\"authorId\":\"39455775\",\"name\":\"Omer Levy\"},{\"authorId\":\"3644767\",\"name\":\"Samuel R. Bowman\"}],\"doi\":\"10.18653/v1/W18-5446\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"93b8da28d006415866bf48f9a6e06b5242129195\",\"title\":\"GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding\",\"url\":\"https://www.semanticscholar.org/paper/93b8da28d006415866bf48f9a6e06b5242129195\",\"venue\":\"BlackboxNLP@EMNLP\",\"year\":2018},{\"arxivId\":\"1707.07998\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"31790073\",\"name\":\"C. Buehler\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":\"10.1109/CVPR.2018.00636\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"title\":\"Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1708.05271\",\"authors\":[{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2017.559\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"10480a42957a8e08e4c543185e135d7c254583a5\",\"title\":\"Incorporating Copying Mechanism in Image Captioning for Learning Novel Objects\",\"url\":\"https://www.semanticscholar.org/paper/10480a42957a8e08e4c543185e135d7c254583a5\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"145564333\",\"name\":\"G. Kulkarni\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8e080b98efbe65c02a116439205ca2344b9f7cd4\",\"title\":\"Im2Text: Describing Images Using 1 Million Captioned Photographs\",\"url\":\"https://www.semanticscholar.org/paper/8e080b98efbe65c02a116439205ca2344b9f7cd4\",\"venue\":\"NIPS\",\"year\":2011},{\"arxivId\":\"1809.00778\",\"authors\":[{\"authorId\":\"2859858\",\"name\":\"Takuya Akiba\"},{\"authorId\":\"33347316\",\"name\":\"Tommi Kerola\"},{\"authorId\":\"24000488\",\"name\":\"Yusuke Niitani\"},{\"authorId\":\"47529618\",\"name\":\"T. Ogawa\"},{\"authorId\":\"2019759\",\"name\":\"Shotaro Sano\"},{\"authorId\":\"49549590\",\"name\":\"S. Suzuki\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c34217591c4b7bf2f5d0d71e1d524073f411d6a9\",\"title\":\"PFDet: 2nd Place Solution to Open Images Challenge 2018 Object Detection Track\",\"url\":\"https://www.semanticscholar.org/paper/c34217591c4b7bf2f5d0d71e1d524073f411d6a9\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1803.09845\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"94908120\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2018.00754\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3bf09b2e2639add154a9fe6ff98cc373d3e90e4e\",\"title\":\"Neural Baby Talk\",\"url\":\"https://www.semanticscholar.org/paper/3bf09b2e2639add154a9fe6ff98cc373d3e90e4e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1802.05365\",\"authors\":[{\"authorId\":\"39139825\",\"name\":\"Matthew E. Peters\"},{\"authorId\":\"50043859\",\"name\":\"Mark Neumann\"},{\"authorId\":\"2136562\",\"name\":\"Mohit Iyyer\"},{\"authorId\":\"40642935\",\"name\":\"Matt Gardner\"},{\"authorId\":\"143997772\",\"name\":\"Christopher Clark\"},{\"authorId\":\"2544107\",\"name\":\"Kenton Lee\"},{\"authorId\":\"1982950\",\"name\":\"Luke Zettlemoyer\"}],\"doi\":\"10.18653/v1/N18-1202\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3febb2bed8865945e7fddc99efd791887bb7e14f\",\"title\":\"Deep contextualized word representations\",\"url\":\"https://www.semanticscholar.org/paper/3febb2bed8865945e7fddc99efd791887bb7e14f\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":\"1411.2539\",\"authors\":[{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2e36ea91a3c8fbff92be2989325531b4002e2afc\",\"title\":\"Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models\",\"url\":\"https://www.semanticscholar.org/paper/2e36ea91a3c8fbff92be2989325531b4002e2afc\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":\"1902.03570\",\"authors\":[{\"authorId\":\"24508084\",\"name\":\"Deshraj Yadav\"},{\"authorId\":\"145461380\",\"name\":\"Rishabh Jain\"},{\"authorId\":\"37825612\",\"name\":\"Harsh Agrawal\"},{\"authorId\":\"40424000\",\"name\":\"Prithvijit Chattopadhyay\"},{\"authorId\":\"2781522\",\"name\":\"T. Singh\"},{\"authorId\":\"49148034\",\"name\":\"Akash Jain\"},{\"authorId\":\"8518719\",\"name\":\"S. Singh\"},{\"authorId\":\"121944615\",\"name\":\"Stefan Lee\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"0d96ac48e92b6b42737276a319f48d9d27080fce\",\"title\":\"EvalAI: Towards Better Evaluation Systems for AI Agents\",\"url\":\"https://www.semanticscholar.org/paper/0d96ac48e92b6b42737276a319f48d9d27080fce\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1804.03803\",\"authors\":[{\"authorId\":\"1887625\",\"name\":\"Yuehua Wu\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"39978626\",\"name\":\"Lu Jiang\"},{\"authorId\":null,\"name\":\"Yi Yang\"}],\"doi\":\"10.1145/3240508.3240640\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d64f52b94977b71976327eeb3db702b246ee39ce\",\"title\":\"Decoupled Novel Object Captioner\",\"url\":\"https://www.semanticscholar.org/paper/d64f52b94977b71976327eeb3db702b246ee39ce\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1506.01497\",\"authors\":[{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"144716314\",\"name\":\"J. Sun\"}],\"doi\":\"10.1109/TPAMI.2016.2577031\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"title\":\"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\",\"url\":\"https://www.semanticscholar.org/paper/424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2015},{\"arxivId\":\"1411.5726\",\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2015.7299087\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"258986132bf17755fe8263e42429fe73218c1534\",\"title\":\"CIDEr: Consensus-based image description evaluation\",\"url\":\"https://www.semanticscholar.org/paper/258986132bf17755fe8263e42429fe73218c1534\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1602.07332\",\"authors\":[{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"50499889\",\"name\":\"O. Groth\"},{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"1382195702\",\"name\":\"Kenji Hata\"},{\"authorId\":\"40591424\",\"name\":\"J. Kravitz\"},{\"authorId\":\"6000646\",\"name\":\"Stephanie Chen\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"1388344504\",\"name\":\"David A. Shamma\"},{\"authorId\":\"1379506718\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-016-0981-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"title\":\"Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations\",\"url\":\"https://www.semanticscholar.org/paper/afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Alex Wang\"},{\"authorId\":null,\"name\":\"Amanpreet Singh\"},{\"authorId\":null,\"name\":\"Julian Michael\"},{\"authorId\":null,\"name\":\"Felix Hill\"},{\"authorId\":null,\"name\":\"Omer Levy\"},{\"authorId\":null,\"name\":\"R Samuel\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Bowman . GLUE : A multitask benchmark and analysis platform for natural language understanding\",\"url\":\"\",\"venue\":\"Show and tell : A neural image caption generator . In CVPR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"134861178\",\"name\":\"Wei Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPRW.2009.5206848\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d2c733e34d48784a37d717fe43d9e93277a8c53e\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/d2c733e34d48784a37d717fe43d9e93277a8c53e\",\"venue\":\"2009 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145564333\",\"name\":\"G. Kulkarni\"},{\"authorId\":\"3128210\",\"name\":\"Visruth Premraj\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"2985883\",\"name\":\"Sagnik Dhar\"},{\"authorId\":\"50341924\",\"name\":\"Siming Li\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/TPAMI.2012.162\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5cb6700d94c6118ee13f4f4fecac99f111189812\",\"title\":\"BabyTalk: Understanding and Generating Simple Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/5cb6700d94c6118ee13f4f4fecac99f111189812\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48267618\",\"name\":\"Piyush Sharma\"},{\"authorId\":\"145534769\",\"name\":\"N. Ding\"},{\"authorId\":\"7685850\",\"name\":\"Sebastian Goodman\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"}],\"doi\":\"10.18653/v1/P18-1238\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b4df354db88a70183a64dbc9e56cf14e7669a6c0\",\"title\":\"Conceptual Captions: A Cleaned, Hypernymed, Image Alt-text Dataset For Automatic Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/b4df354db88a70183a64dbc9e56cf14e7669a6c0\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":\"1504.00325\",\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"title\":\"Microsoft COCO Captions: Data Collection and Evaluation Server\",\"url\":\"https://www.semanticscholar.org/paper/696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1612.01887\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":\"10.1109/CVPR.2017.345\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9f4d7d622d1f7319cc511bfef661cd973e881a4c\",\"title\":\"Knowing When to Look: Adaptive Attention via a Visual Sentinel for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9f4d7d622d1f7319cc511bfef661cd973e881a4c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ivan Krasin\"},{\"authorId\":null,\"name\":\"Tom Duerig\"},{\"authorId\":null,\"name\":\"Neil Alldrin\"},{\"authorId\":null,\"name\":\"Vittorio Ferrari\"},{\"authorId\":null,\"name\":\"Sami Abu-El-Haija\"},{\"authorId\":null,\"name\":\"Alina Kuznetsova\"},{\"authorId\":null,\"name\":\"Hassan Rom\"},{\"authorId\":null,\"name\":\"Jasper Uijlings\"},{\"authorId\":null,\"name\":\"Stefan Popov\"},{\"authorId\":null,\"name\":\"Andreas Veit\"},{\"authorId\":null,\"name\":\"Serge Belongie\"},{\"authorId\":null,\"name\":\"Victor Gomes\"},{\"authorId\":null,\"name\":\"Abhinav Gupta\"},{\"authorId\":null,\"name\":\"Chen Sun\"},{\"authorId\":null,\"name\":\"Gal Chechik\"},{\"authorId\":null,\"name\":\"David Cai\"},{\"authorId\":null,\"name\":\"Zheyun Feng\"},{\"authorId\":null,\"name\":\"Dhyanesh Narayanan\"},{\"authorId\":null,\"name\":\"Kevin Murphy\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Openimages: A public dataset for large-scale multilabel and multi-class image classification\",\"url\":\"\",\"venue\":\"Dataset available from https://github.com/openimages,\",\"year\":2017},{\"arxivId\":\"1409.0575\",\"authors\":[{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"71309570\",\"name\":\"H. Su\"},{\"authorId\":\"2285165\",\"name\":\"J. Krause\"},{\"authorId\":\"145031342\",\"name\":\"S. Satheesh\"},{\"authorId\":\"145423516\",\"name\":\"S. Ma\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-015-0816-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"title\":\"ImageNet Large Scale Visual Recognition Challenge\",\"url\":\"https://www.semanticscholar.org/paper/e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"P. Anderson\"},{\"authorId\":null,\"name\":\"S. Gould\"},{\"authorId\":null,\"name\":\"M. Johnson\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Partiallysupervised image captioning\",\"url\":\"\",\"venue\":\"NIPS, 2018. 1, 2, 8\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Z Yang\"},{\"authorId\":null,\"name\":\"Y Yuan\"},{\"authorId\":null,\"name\":\"Y Wu\"},{\"authorId\":null,\"name\":\"R Salakhutdinov\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Cohen. Review networks for caption generation\",\"url\":\"\",\"venue\":\"NIPS\",\"year\":2016}],\"title\":\"nocaps: novel object captioning at scale\",\"topics\":[{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"},{\"topic\":\"Object detection\",\"topicId\":\"14349\",\"url\":\"https://www.semanticscholar.org/topic/14349\"},{\"topic\":\"Baseline (configuration management)\",\"topicId\":\"3403\",\"url\":\"https://www.semanticscholar.org/topic/3403\"}],\"url\":\"https://www.semanticscholar.org/paper/8b55402ffee2734bfc7d5d7595500916e1ef04e8\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019}\n"