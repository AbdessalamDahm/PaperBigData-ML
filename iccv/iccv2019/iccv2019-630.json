"{\"abstract\":\"We present SlowFast networks for video recognition. Our model involves (i) a Slow pathway, operating at low frame rate, to capture spatial semantics, and (ii) a Fast pathway, operating at high frame rate, to capture motion at fine temporal resolution. The Fast pathway can be made very lightweight by reducing its channel capacity, yet can learn useful temporal information for video recognition. Our models achieve strong performance for both action classification and detection in video, and large improvements are pin-pointed as contributions by our SlowFast concept. We report state-of-the-art accuracy on major video recognition benchmarks, Kinetics, Charades and AVA. Code has been made available at: https://github.com/facebookresearch/SlowFast.\",\"arxivId\":\"1812.03982\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\",\"url\":\"https://www.semanticscholar.org/author/2322150\"},{\"authorId\":\"2681569\",\"name\":\"Haoqi Fan\",\"url\":\"https://www.semanticscholar.org/author/2681569\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\",\"url\":\"https://www.semanticscholar.org/author/143751119\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\",\"url\":\"https://www.semanticscholar.org/author/39353098\"}],\"citationVelocity\":117,\"citations\":[{\"arxivId\":\"2003.14266\",\"authors\":[{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1109/cvpr42600.2020.00058\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e1e3a36644d71bf1e8a09ad943c7a1bbb65ae73e\",\"title\":\"SCT: Set Constrained Temporal Transformer for Set Supervised Action Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/e1e3a36644d71bf1e8a09ad943c7a1bbb65ae73e\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3145312\",\"name\":\"Chungkuk Yoo\"},{\"authorId\":\"146272390\",\"name\":\"B. Kang\"},{\"authorId\":\"1801812\",\"name\":\"Minsik Cho\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"15a4dce41f61f20ac4b817c2c5b0b928aed6dde9\",\"title\":\"SNOW: Subscribing to Knowledge via Channel Pooling for Transfer & Lifelong Learning of Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/15a4dce41f61f20ac4b817c2c5b0b928aed6dde9\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"2006.09116\",\"authors\":[{\"authorId\":\"30733670\",\"name\":\"S. Chen\"},{\"authorId\":\"1720856277\",\"name\":\"Junting Pan\"},{\"authorId\":\"12920342\",\"name\":\"Guanglu Song\"},{\"authorId\":\"40951853\",\"name\":\"Manyuan Zhang\"},{\"authorId\":\"46798949\",\"name\":\"H. Shao\"},{\"authorId\":\"1967781\",\"name\":\"Ziyi Lin\"},{\"authorId\":\"1388486428\",\"name\":\"Jing Shao\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"30752055\",\"name\":\"Y. Liu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb8eca609bdd9dc37968a48b5e74ba30d0ecff12\",\"title\":\"1st place solution for AVA-Kinetics Crossover in AcitivityNet Challenge 2020\",\"url\":\"https://www.semanticscholar.org/paper/eb8eca609bdd9dc37968a48b5e74ba30d0ecff12\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.07626\",\"authors\":[{\"authorId\":\"28969692\",\"name\":\"Junwu Weng\"},{\"authorId\":\"9393671\",\"name\":\"Donghao Luo\"},{\"authorId\":null,\"name\":\"Yabiao Wang\"},{\"authorId\":\"144970872\",\"name\":\"Ying Tai\"},{\"authorId\":\"1978245\",\"name\":\"Chengjie Wang\"},{\"authorId\":\"49298244\",\"name\":\"Jilin Li\"},{\"authorId\":\"1835006\",\"name\":\"Feiyue Huang\"},{\"authorId\":\"3307580\",\"name\":\"Xudong Jiang\"},{\"authorId\":\"48837492\",\"name\":\"J. Yuan\"}],\"doi\":\"10.1007/978-3-030-58571-6_22\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"cfb71e0cce6487b6a1cf2dd0cd3755d1d78e908e\",\"title\":\"Temporal Distinct Representation Learning for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cfb71e0cce6487b6a1cf2dd0cd3755d1d78e908e\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2011.13322\",\"authors\":[{\"authorId\":\"1845783022\",\"name\":\"Zhen Huang\"},{\"authorId\":\"94123138\",\"name\":\"X. Shen\"},{\"authorId\":\"40434674\",\"name\":\"X. Tian\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"},{\"authorId\":\"50535670\",\"name\":\"Jian-qiang Huang\"},{\"authorId\":\"143863242\",\"name\":\"Xiansheng Hua\"}],\"doi\":\"10.1145/3394171.3413666\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"71918fb33871497f7c4722246e63e8beaaf588fa\",\"title\":\"Spatio-Temporal Inception Graph Convolutional Networks for Skeleton-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/71918fb33871497f7c4722246e63e8beaaf588fa\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49597328\",\"name\":\"J. Xia\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aaa5e03a926af11472a6c47dcbfe3941a0f2004b\",\"title\":\"Weakly Supervised EM Process For Temporal Localization Within Video\",\"url\":\"https://www.semanticscholar.org/paper/aaa5e03a926af11472a6c47dcbfe3941a0f2004b\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"fe2dba4d494e5a3c68eba14cc09a808de00f3f57\",\"title\":\"Supplementary Material: X3D: Expanding Architectures for Efficient Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fe2dba4d494e5a3c68eba14cc09a808de00f3f57\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1577678641\",\"name\":\"Ganesh Samarth\"},{\"authorId\":\"1974345797\",\"name\":\"Sheetal Ojha\"},{\"authorId\":\"96566998\",\"name\":\"N. Pareek\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5624963548a28f00a3aef20dca3bdbfe3d394d9d\",\"title\":\"Knowledge Fusion Transformers for Video Action Classification\",\"url\":\"https://www.semanticscholar.org/paper/5624963548a28f00a3aef20dca3bdbfe3d394d9d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2010.03016\",\"authors\":[{\"authorId\":\"1490732820\",\"name\":\"Bowen Zhang\"},{\"authorId\":\"48444479\",\"name\":\"Hao Chen\"},{\"authorId\":\"152808542\",\"name\":\"Meng Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a2101cacd22060882e1ec6e787774e6b04f531e0\",\"title\":\"Online Action Detection in Streaming Videos with Time Buffers\",\"url\":\"https://www.semanticscholar.org/paper/a2101cacd22060882e1ec6e787774e6b04f531e0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.03462\",\"authors\":[{\"authorId\":\"145586191\",\"name\":\"Can Zhang\"},{\"authorId\":\"26981150\",\"name\":\"Yue-Xian Zou\"},{\"authorId\":\"143930563\",\"name\":\"G. Chen\"},{\"authorId\":\"48204311\",\"name\":\"L. Gan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"60840dce8073545641198c297796902fa390c719\",\"title\":\"PAN: Towards Fast Action Recognition via Learning Persistence of Appearance\",\"url\":\"https://www.semanticscholar.org/paper/60840dce8073545641198c297796902fa390c719\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2002.00367\",\"authors\":[{\"authorId\":\"152509251\",\"name\":\"Joonatan M\\u00e4ntt\\u00e4ri\"},{\"authorId\":\"67200092\",\"name\":\"S. Broom\\u00e9\"},{\"authorId\":\"3248522\",\"name\":\"John Folkesson\"},{\"authorId\":\"1704879\",\"name\":\"H. Kjellstr\\u00f6m\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ab78636736e978b814af4ecbe42d116bbfbbac1f\",\"title\":\"Interpreting video features: a comparison of 3D convolutional networks and convolutional LSTM networks\",\"url\":\"https://www.semanticscholar.org/paper/ab78636736e978b814af4ecbe42d116bbfbbac1f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1912.00381\",\"authors\":[{\"authorId\":\"1756362\",\"name\":\"Swathikiran Sudhakaran\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"}],\"doi\":\"10.1109/cvpr42600.2020.00118\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"57cee868188127305f966a178ca22025b397d911\",\"title\":\"Gate-Shift Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/57cee868188127305f966a178ca22025b397d911\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2003.01455\",\"authors\":[{\"authorId\":\"27629992\",\"name\":\"B. Brattoli\"},{\"authorId\":\"40580686\",\"name\":\"Joe Tighe\"},{\"authorId\":\"2096007\",\"name\":\"Fedor Zhdanov\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"3180200\",\"name\":\"Krzysztof Chalupka\"}],\"doi\":\"10.1109/CVPR42600.2020.00467\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c58c4c6ce9ae60dce8b2f6a02c06d086d7c2e545\",\"title\":\"Rethinking Zero-Shot Video Classification: End-to-End Training for Realistic Applications\",\"url\":\"https://www.semanticscholar.org/paper/c58c4c6ce9ae60dce8b2f6a02c06d086d7c2e545\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2004.14487\",\"authors\":[{\"authorId\":\"94314731\",\"name\":\"Matthew Purri\"},{\"authorId\":\"1710772\",\"name\":\"K. Dana\"}],\"doi\":\"10.1007/978-3-030-58583-9_1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dd5f4a7a3f619cb64428dc1a8a128019c8d4f512\",\"title\":\"Teaching Cameras to Feel: Estimating Tactile Physical Properties of Surfaces From Images\",\"url\":\"https://www.semanticscholar.org/paper/dd5f4a7a3f619cb64428dc1a8a128019c8d4f512\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49527668\",\"name\":\"Haonan Wang\"},{\"authorId\":\"95163406\",\"name\":\"Y. Mei\"},{\"authorId\":\"95339157\",\"name\":\"J. Lin\"},{\"authorId\":\"2539310\",\"name\":\"Z. Wang\"}],\"doi\":\"10.1109/SiPS50750.2020.9195240\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0612a6a61f26dc9d8cd50dfa9c6f83e268e2ae58\",\"title\":\"Temporal Residual Feature Learning for Efficient 3D Convolutional Neural Network on Action Recognition Task\",\"url\":\"https://www.semanticscholar.org/paper/0612a6a61f26dc9d8cd50dfa9c6f83e268e2ae58\",\"venue\":\"2020 IEEE Workshop on Signal Processing Systems (SiPS)\",\"year\":2020},{\"arxivId\":\"2011.08652\",\"authors\":[{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"2025664854\",\"name\":\"Emad Bahrami Rad\"},{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"2199924\",\"name\":\"M. Noroozi\"},{\"authorId\":\"46408185\",\"name\":\"E. Adeli\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"80ddd8e76480aa92aa071d33c624af7195b0b762\",\"title\":\"3D CNNs with Adaptive Temporal Feature Resolutions\",\"url\":\"https://www.semanticscholar.org/paper/80ddd8e76480aa92aa071d33c624af7195b0b762\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1904.11492\",\"authors\":[{\"authorId\":\"1696087\",\"name\":\"Yue Cao\"},{\"authorId\":\"7169566\",\"name\":\"J. Xu\"},{\"authorId\":\"145676588\",\"name\":\"Stephen Lin\"},{\"authorId\":\"2480483\",\"name\":\"Fangyun Wei\"},{\"authorId\":\"1805197\",\"name\":\"H. Hu\"}],\"doi\":\"10.1109/ICCVW.2019.00246\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"66143960c0325c70329a3869cc8052f0416b87aa\",\"title\":\"GCNet: Non-Local Networks Meet Squeeze-Excitation Networks and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/66143960c0325c70329a3869cc8052f0416b87aa\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"2010.07524\",\"authors\":[{\"authorId\":\"1387831061\",\"name\":\"MyeongAh Cho\"},{\"authorId\":\"48271129\",\"name\":\"T. Kim\"},{\"authorId\":\"39847092\",\"name\":\"Sangyoun Lee\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"616e4fa9ac89ef99f073aabfcdb4cc05e4407520\",\"title\":\"Unsupervised Video Anomaly Detection via Flow-based Generative Modeling on Appearance and Motion Latent Features\",\"url\":\"https://www.semanticscholar.org/paper/616e4fa9ac89ef99f073aabfcdb4cc05e4407520\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2845745\",\"name\":\"Sovan Biswas\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1f2bd6effe8666d2843f66bcaae9724f7c453290\",\"title\":\"Discovering Multi-Label Actor-Action Association in a Weakly Supervised Setting\",\"url\":\"https://www.semanticscholar.org/paper/1f2bd6effe8666d2843f66bcaae9724f7c453290\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51265752\",\"name\":\"Alexandros Koumparoulis\"},{\"authorId\":\"1423737852\",\"name\":\"Gerasimos Potamianos\"},{\"authorId\":\"70913918\",\"name\":\"S. Thomas\"},{\"authorId\":\"150092714\",\"name\":\"Edmilson da Silva Morais\"}],\"doi\":\"10.21437/interspeech.2020-3003\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"821ebc91199f1d08f21f67c3ef56aa733c529201\",\"title\":\"Resource-Adaptive Deep Learning for Visual Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/821ebc91199f1d08f21f67c3ef56aa733c529201\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":\"2008.04999\",\"authors\":[{\"authorId\":\"13930770\",\"name\":\"Faegheh Sardari\"},{\"authorId\":\"2657085\",\"name\":\"A. Paiement\"},{\"authorId\":\"1751117\",\"name\":\"S. Hannuna\"},{\"authorId\":\"1728108\",\"name\":\"M. Mirmehdi\"}],\"doi\":\"10.3390/s20185258\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eddbf3b7783f528a3413dbe96a58da1690d7f156\",\"title\":\"VI-Net\\u2014View-Invariant Quality of Human Movement Assessment\",\"url\":\"https://www.semanticscholar.org/paper/eddbf3b7783f528a3413dbe96a58da1690d7f156\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"2007.06866\",\"authors\":[{\"authorId\":\"150348841\",\"name\":\"Yuchi Ishikawa\"},{\"authorId\":\"1381411615\",\"name\":\"Seito Kasai\"},{\"authorId\":\"10664005\",\"name\":\"Y. Aoki\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4fed0235614df46fa0c53e05b71e9939b53a1bdf\",\"title\":\"Alleviating Over-segmentation Errors by Detecting Action Boundaries\",\"url\":\"https://www.semanticscholar.org/paper/4fed0235614df46fa0c53e05b71e9939b53a1bdf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50202365\",\"name\":\"S. Zhang\"},{\"authorId\":\"153098982\",\"name\":\"Sheng Guo\"},{\"authorId\":\"49015548\",\"name\":\"Weilin Huang\"},{\"authorId\":\"1915350\",\"name\":\"M. Scott\"},{\"authorId\":\"29461006\",\"name\":\"L. Wang\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"60d95b4ed4f6e9ac38441d130d3969597ce4d626\",\"title\":\"V4D: 4D Covolutional Neural Networks for Video-level Representations Learning\",\"url\":\"https://www.semanticscholar.org/paper/60d95b4ed4f6e9ac38441d130d3969597ce4d626\",\"venue\":\"ICLR 2020\",\"year\":2020},{\"arxivId\":\"2007.06317\",\"authors\":[{\"authorId\":\"3458134\",\"name\":\"Gyeongsik Moon\"},{\"authorId\":\"30557120\",\"name\":\"Heeseung Kwon\"},{\"authorId\":\"2135837\",\"name\":\"Kyoung Mu Lee\"},{\"authorId\":\"72643925\",\"name\":\"Minsu Cho\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"8230c73193abe9f42306a311d75557a902e785f6\",\"title\":\"IntegralAction: Pose-driven Feature Integration for Robust Human Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/8230c73193abe9f42306a311d75557a902e785f6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491240780\",\"name\":\"Z. Shi\"},{\"authorId\":\"144962375\",\"name\":\"Cheng Guan\"},{\"authorId\":\"1491233401\",\"name\":\"Liangjie Cao\"},{\"authorId\":\"1632356255\",\"name\":\"Qianqian Li\"},{\"authorId\":\"1993660232\",\"name\":\"Ju Liang\"},{\"authorId\":\"29344734\",\"name\":\"Zhaorui Gu\"},{\"authorId\":\"2336297\",\"name\":\"Haiyong Zheng\"},{\"authorId\":\"1470709309\",\"name\":\"Bing Zheng\"}],\"doi\":\"10.1007/978-3-030-58539-6_23\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c826e169f505f6fda0872d0a3e1e156e15b5111e\",\"title\":\"CoTeRe-Net: Discovering Collaborative Ternary Relations in Videos\",\"url\":\"https://www.semanticscholar.org/paper/c826e169f505f6fda0872d0a3e1e156e15b5111e\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2012.06977\",\"authors\":[{\"authorId\":\"47203405\",\"name\":\"Wenhao Wu\"},{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"6873935\",\"name\":\"T. Lin\"},{\"authorId\":\"1998948807\",\"name\":\"F. Li\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"12081764\",\"name\":\"E. Ding\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a6e71b58ea6668dd3872e0c9e6cdd258b4582e2a\",\"title\":\"MVFNet: Multi-View Fusion Network for Efficient Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a6e71b58ea6668dd3872e0c9e6cdd258b4582e2a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2002.12177\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"2148510\",\"name\":\"A. Angelova\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1109/cvpr42600.2020.00021\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3cb1b739f32641938485b714a186fb705d0b0215\",\"title\":\"Evolving Losses for Unsupervised Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/3cb1b739f32641938485b714a186fb705d0b0215\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2003.13942\",\"authors\":[{\"authorId\":\"52170427\",\"name\":\"Boxiao Pan\"},{\"authorId\":\"30017683\",\"name\":\"Haoye Cai\"},{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"144015229\",\"name\":\"Kuan-Hui Lee\"},{\"authorId\":\"1799820\",\"name\":\"Adrien Gaidon\"},{\"authorId\":\"46408185\",\"name\":\"E. Adeli\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/cvpr42600.2020.01088\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a444d32f30d38fb0cb811fa1a9b601511244fb5b\",\"title\":\"Spatio-Temporal Graph for Video Captioning With Knowledge Distillation\",\"url\":\"https://www.semanticscholar.org/paper/a444d32f30d38fb0cb811fa1a9b601511244fb5b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1912.03612\",\"authors\":[{\"authorId\":\"3178508\",\"name\":\"Songyang Zhang\"},{\"authorId\":\"2484788\",\"name\":\"Houwen Peng\"},{\"authorId\":\"46554630\",\"name\":\"L. Yang\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bebbd6a2e786fa5a33dd4bbd27310e116411188e\",\"title\":\"Learning Sparse 2D Temporal Adjacent Networks for Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/bebbd6a2e786fa5a33dd4bbd27310e116411188e\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1789352\",\"name\":\"Jelena Tesic\"},{\"authorId\":\"34959049\",\"name\":\"D. Tamir\"},{\"authorId\":\"3424281\",\"name\":\"Shai Neumann\"},{\"authorId\":\"1719172\",\"name\":\"N. Rishe\"},{\"authorId\":\"115146359\",\"name\":\"A. Kandel\"}],\"doi\":\"10.1007/978-3-030-50439-7_30\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"17f50a52fd4b30f6c22b6be9d33c078a534d5dac\",\"title\":\"Computing with Words in Maritime Piracy and Attack Detection Systems\",\"url\":\"https://www.semanticscholar.org/paper/17f50a52fd4b30f6c22b6be9d33c078a534d5dac\",\"venue\":\"HCI\",\"year\":2020},{\"arxivId\":\"1901.09615\",\"authors\":[{\"authorId\":\"41022447\",\"name\":\"Okan K\\u00f6p\\u00fckl\\u00fc\"},{\"authorId\":\"3281049\",\"name\":\"M. Babaee\"},{\"authorId\":\"32790011\",\"name\":\"Stefan H\\u00f6rmann\"},{\"authorId\":\"145512909\",\"name\":\"G. Rigoll\"}],\"doi\":\"10.1109/ICIP.2019.8802998\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9ad51a022dda0f043f2fc505b0b648e36e646166\",\"title\":\"Convolutional Neural Networks with Layer Reuse\",\"url\":\"https://www.semanticscholar.org/paper/9ad51a022dda0f043f2fc505b0b648e36e646166\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"2011.07787\",\"authors\":[{\"authorId\":\"81226618\",\"name\":\"Jinmiao Cai\"},{\"authorId\":\"2855391\",\"name\":\"N. Jiang\"},{\"authorId\":\"50016941\",\"name\":\"Xiao-Guang Han\"},{\"authorId\":\"49104090\",\"name\":\"Kui Jia\"},{\"authorId\":\"1715148\",\"name\":\"Jiangbo Lu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c2664de9388332008077c54278c4f59025dc0bab\",\"title\":\"JOLO-GCN: Mining Joint-Centered Light-Weight Information for Skeleton-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c2664de9388332008077c54278c4f59025dc0bab\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.00212\",\"authors\":[{\"authorId\":\"1560385163\",\"name\":\"Bo Pang\"},{\"authorId\":\"15376265\",\"name\":\"Kaiwen Zha\"},{\"authorId\":\"50732737\",\"name\":\"Hanwen Cao\"},{\"authorId\":\"152949394\",\"name\":\"J. Tang\"},{\"authorId\":\"50753313\",\"name\":\"Minghui Yu\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"}],\"doi\":\"10.1038/s42256-020-0168-3\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"86cc65a2b78f5ad9205faf0dba26b5f04d11126c\",\"title\":\"Complex sequential understanding through the awareness of spatial and temporal concepts\",\"url\":\"https://www.semanticscholar.org/paper/86cc65a2b78f5ad9205faf0dba26b5f04d11126c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"97514733\",\"name\":\"Jin-woo Choi\"},{\"authorId\":\"2515597\",\"name\":\"Gaurav Sharma\"},{\"authorId\":\"1790643\",\"name\":\"S. Schulter\"},{\"authorId\":\"50535349\",\"name\":\"J. Huang\"}],\"doi\":\"10.1007/978-3-030-58610-2_40\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"19d574a2238ad11142de1d6f2713315880b2d218\",\"title\":\"Shuffle and Attend: Video Domain Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/19d574a2238ad11142de1d6f2713315880b2d218\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144809605\",\"name\":\"Xiaolong Liu\"},{\"authorId\":\"9177510\",\"name\":\"Y. Sun\"},{\"authorId\":\"2034194541\",\"name\":\"Jianghu Lu\"},{\"authorId\":\"2034240637\",\"name\":\"Cong Yao\"},{\"authorId\":\"47943518\",\"name\":\"Y. Zhou\"}],\"doi\":\"10.1109/LSP.2020.3037796\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0f7ee124e37bc0e4102f2f1e113b68a1cefee978\",\"title\":\"Self-Similarity Action Proposal\",\"url\":\"https://www.semanticscholar.org/paper/0f7ee124e37bc0e4102f2f1e113b68a1cefee978\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2020},{\"arxivId\":\"2008.03548\",\"authors\":[{\"authorId\":\"36290866\",\"name\":\"Anyi Rao\"},{\"authorId\":\"1557390077\",\"name\":\"Jiaze Wang\"},{\"authorId\":\"150196512\",\"name\":\"Linning Xu\"},{\"authorId\":\"80180784\",\"name\":\"Xuekun Jiang\"},{\"authorId\":\"39360892\",\"name\":\"Q. Huang\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1007/978-3-030-58621-8_2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"49b2d6f498bde324151cc5d0f8a9bba70540efbd\",\"title\":\"A Unified Framework for Shot Type Classification Based on Subject Centric Lens\",\"url\":\"https://www.semanticscholar.org/paper/49b2d6f498bde324151cc5d0f8a9bba70540efbd\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2006.00626\",\"authors\":[{\"authorId\":\"47002659\",\"name\":\"Yanchao Li\"},{\"authorId\":\"1720749879\",\"name\":\"Miao Liu\"},{\"authorId\":\"50779871\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a48cde936f7dea115cbda99a08e12dbdf45d13fb\",\"title\":\"In the Eye of the Beholder: Gaze and Actions in First Person Video\",\"url\":\"https://www.semanticscholar.org/paper/a48cde936f7dea115cbda99a08e12dbdf45d13fb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.07520\",\"authors\":[{\"authorId\":\"1750375688\",\"name\":\"Zhiwu Qing\"},{\"authorId\":\"1726109879\",\"name\":\"Xiang Wang\"},{\"authorId\":\"1749375503\",\"name\":\"Yongpeng Sang\"},{\"authorId\":\"40115662\",\"name\":\"Changxin Gao\"},{\"authorId\":\"50202110\",\"name\":\"Shiwei Zhang\"},{\"authorId\":\"1707161\",\"name\":\"N. Sang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7e6ee2de875529f7af5419b66266c4664cffdd84\",\"title\":\"Temporal Fusion Network for Temporal Action Localization: Submission to ActivityNet Challenge 2020 (Task E)\",\"url\":\"https://www.semanticscholar.org/paper/7e6ee2de875529f7af5419b66266c4664cffdd84\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50202365\",\"name\":\"Shiwen Zhang\"},{\"authorId\":\"49015548\",\"name\":\"Weilin Huang\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a19185b1cbb6588682318bb9ce649a611e889162\",\"title\":\"VIDEO-LEVEL REPRESENTATION LEARNING\",\"url\":\"https://www.semanticscholar.org/paper/a19185b1cbb6588682318bb9ce649a611e889162\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48093549\",\"name\":\"Jinpeng Wang\"},{\"authorId\":\"29995014\",\"name\":\"Shiren Li\"},{\"authorId\":\"30646831\",\"name\":\"Zhi-kui Duan\"},{\"authorId\":\"48803999\",\"name\":\"Z. Yuan\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053794\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a021daf17351415827420456377f77f6a146fd56\",\"title\":\"Rethinking Temporal-Related Sample for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a021daf17351415827420456377f77f6a146fd56\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"2011.10670\",\"authors\":[{\"authorId\":\"1915796\",\"name\":\"Junwei Liang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"05b7a66632946e838599681339aa7575f7a6e80b\",\"title\":\"Joint Analysis and Prediction of Human Actions and Paths in Video\",\"url\":\"https://www.semanticscholar.org/paper/05b7a66632946e838599681339aa7575f7a6e80b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49372683\",\"name\":\"Niamul Quader\"},{\"authorId\":\"150152476\",\"name\":\"Juwei Lu\"},{\"authorId\":\"144287598\",\"name\":\"Peng Dai\"},{\"authorId\":\"122009001\",\"name\":\"Wei Li\"}],\"doi\":\"10.1007/978-3-030-58577-8_3\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"080039e68707b483e5c3c27f38660acc1e51ddde\",\"title\":\"Towards Efficient Coarse-to-Fine Networks for Action and Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/080039e68707b483e5c3c27f38660acc1e51ddde\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2006.06668\",\"authors\":[{\"authorId\":\"38279784\",\"name\":\"Minghao Yin\"},{\"authorId\":\"32532300\",\"name\":\"Zhuliang Yao\"},{\"authorId\":null,\"name\":\"Yue Cao\"},{\"authorId\":\"1723549\",\"name\":\"X. Li\"},{\"authorId\":\"1852415\",\"name\":\"Zheng Zhang\"},{\"authorId\":\"48639986\",\"name\":\"Stephen Lin\"},{\"authorId\":\"100541102\",\"name\":\"H. Hu\"}],\"doi\":\"10.1007/978-3-030-58555-6_12\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"93586a3caf5c3428045399abbc5e1b096b59d623\",\"title\":\"Disentangled Non-Local Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/93586a3caf5c3428045399abbc5e1b096b59d623\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1527097295\",\"name\":\"Yue Li\"},{\"authorId\":\"31399226\",\"name\":\"Wenrui Ding\"},{\"authorId\":\"2563751\",\"name\":\"Y. Zhu\"},{\"authorId\":\"46843692\",\"name\":\"Yuanjun Huang\"},{\"authorId\":\"9325297\",\"name\":\"Yalong Jiang\"},{\"authorId\":\"46242227\",\"name\":\"B. Zhang\"}],\"doi\":\"10.1109/ICIP40778.2020.9191306\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a3f7e4074a356474113cdb6cb4c7ca7cb3e097d5\",\"title\":\"Cam-Net: Compressed Attentive Multi-Granularity Network For Dynamic Scene Classification\",\"url\":\"https://www.semanticscholar.org/paper/a3f7e4074a356474113cdb6cb4c7ca7cb3e097d5\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"2012.02109\",\"authors\":[{\"authorId\":\"2542995\",\"name\":\"T. Kim\"},{\"authorId\":\"1678633\",\"name\":\"Gregory Hager\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"72b19a0125ddda2752cfcf8c5758a13c52275665\",\"title\":\"SAFCAR: Structured Attention Fusion for Compositional Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/72b19a0125ddda2752cfcf8c5758a13c52275665\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.13375\",\"authors\":[{\"authorId\":null,\"name\":\"Yue Cao\"},{\"authorId\":\"1690418794\",\"name\":\"Jiarui Xu\"},{\"authorId\":\"48639986\",\"name\":\"Stephen Lin\"},{\"authorId\":\"2480483\",\"name\":\"Fangyun Wei\"},{\"authorId\":\"1825704806\",\"name\":\"Han Hu\"}],\"doi\":\"10.1109/TPAMI.2020.3047209\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e1da715b8ae4436c5224e9b573309a3b72c7a53c\",\"title\":\"Global Context Networks.\",\"url\":\"https://www.semanticscholar.org/paper/e1da715b8ae4436c5224e9b573309a3b72c7a53c\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"2003.05093\",\"authors\":[{\"authorId\":\"153451676\",\"name\":\"Wonjik Kim\"},{\"authorId\":\"1390503932\",\"name\":\"M. Tanaka\"},{\"authorId\":\"1742442\",\"name\":\"M. Okutomi\"},{\"authorId\":\"1936377\",\"name\":\"Yoko Sasaki\"}],\"doi\":\"10.1109/ACCESS.2020.2993299\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d3014275abea425f715ed7dc1b226ed808b7a39c\",\"title\":\"Learning-Based Human Segmentation and Velocity Estimation Using Automatic Labeled LiDAR Sequence for Training\",\"url\":\"https://www.semanticscholar.org/paper/d3014275abea425f715ed7dc1b226ed808b7a39c\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2003.00197\",\"authors\":[{\"authorId\":\"29724362\",\"name\":\"Longlong Jing\"},{\"authorId\":\"1807477\",\"name\":\"T. Parag\"},{\"authorId\":\"152247556\",\"name\":\"Zhe Wu\"},{\"authorId\":\"8193125\",\"name\":\"Y. Tian\"},{\"authorId\":\"3254319\",\"name\":\"Hongcheng Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"637b413488ef5b72a3f04089ea3e3c635caab9ee\",\"title\":\"VideoSSL: Semi-Supervised Learning for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/637b413488ef5b72a3f04089ea3e3c635caab9ee\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41022447\",\"name\":\"Okan K\\u00f6p\\u00fckl\\u00fc\"},{\"authorId\":\"1862703\",\"name\":\"N. Kose\"},{\"authorId\":\"66999822\",\"name\":\"Ahmet Gunduz\"},{\"authorId\":\"46343645\",\"name\":\"G. Rigoll\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d712fdf54d2d4c56afdc89e779208113b6edeafb\",\"title\":\"Resource Efficient 3 D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/d712fdf54d2d4c56afdc89e779208113b6edeafb\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2006.03315\",\"authors\":[{\"authorId\":\"1387548078\",\"name\":\"K. Lin\"},{\"authorId\":\"1738276592\",\"name\":\"Zhuoxin Gan\"},{\"authorId\":\"46659782\",\"name\":\"L. Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"aea0c2fdcb618d3b0fdea17a5fc5b068b80a0ec3\",\"title\":\"Multi-modal Feature Fusion with Feature Attention for VATEX Captioning Challenge 2020\",\"url\":\"https://www.semanticscholar.org/paper/aea0c2fdcb618d3b0fdea17a5fc5b068b80a0ec3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.07665\",\"authors\":[{\"authorId\":\"35299091\",\"name\":\"Yansong Tang\"},{\"authorId\":\"1749325163\",\"name\":\"Zanlin Ni\"},{\"authorId\":\"2415109\",\"name\":\"Jiahuan Zhou\"},{\"authorId\":\"2118333\",\"name\":\"Danyang Zhang\"},{\"authorId\":\"1697700\",\"name\":\"Jiwen Lu\"},{\"authorId\":\"115957649\",\"name\":\"Y. Wu\"},{\"authorId\":\"49178343\",\"name\":\"Jie Zhou\"}],\"doi\":\"10.1109/cvpr42600.2020.00986\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d47e67c04e884cc83fff781ee9157f07acc0a558\",\"title\":\"Uncertainty-Aware Score Distribution Learning for Action Quality Assessment\",\"url\":\"https://www.semanticscholar.org/paper/d47e67c04e884cc83fff781ee9157f07acc0a558\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f2184a094fcd7838278a7afcf8188ddf6e1e1806\",\"title\":\"Appendix for Towards Streaming Perception\",\"url\":\"https://www.semanticscholar.org/paper/f2184a094fcd7838278a7afcf8188ddf6e1e1806\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2001.04627\",\"authors\":[{\"authorId\":\"38403207\",\"name\":\"L. Wang\"},{\"authorId\":\"2155775\",\"name\":\"Piotr Koniusz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8e35dc0f90a721d819f74633c8d0d7e4c5a7973e\",\"title\":\"Hallucinating Statistical Moment and Subspace Descriptors from Object and Saliency Detectors for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8e35dc0f90a721d819f74633c8d0d7e4c5a7973e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.15831\",\"authors\":[{\"authorId\":\"51310352\",\"name\":\"Philipp V. Rouast\"},{\"authorId\":\"65980152\",\"name\":\"H. Heydarian\"},{\"authorId\":\"24235135\",\"name\":\"M. Adam\"},{\"authorId\":\"35164715\",\"name\":\"M. Rollo\"}],\"doi\":\"10.1109/ACCESS.2020.3026965\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f851a707b673857f7e1e571072894d6893156421\",\"title\":\"OREBA: A Dataset for Objectively Recognizing Eating Behavior and Associated Intake\",\"url\":\"https://www.semanticscholar.org/paper/f851a707b673857f7e1e571072894d6893156421\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2004.04981\",\"authors\":[{\"authorId\":\"1491233177\",\"name\":\"Yizhou Zhou\"},{\"authorId\":\"6485172\",\"name\":\"Xiaoyan Sun\"},{\"authorId\":\"2820418\",\"name\":\"Chong Luo\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"}],\"doi\":\"10.1109/cvpr42600.2020.00985\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e7ca185e3a4515471c2b9a411da9f264d55ea563\",\"title\":\"Spatiotemporal Fusion in 3D CNNs: A Probabilistic View\",\"url\":\"https://www.semanticscholar.org/paper/e7ca185e3a4515471c2b9a411da9f264d55ea563\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2005.09183\",\"authors\":[{\"authorId\":\"1381411615\",\"name\":\"Seito Kasai\"},{\"authorId\":\"150348841\",\"name\":\"Yuchi Ishikawa\"},{\"authorId\":\"40495154\",\"name\":\"M. Hayashi\"},{\"authorId\":\"10664005\",\"name\":\"Y. Aoki\"},{\"authorId\":\"2199251\",\"name\":\"K. Hara\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"}],\"doi\":\"10.1109/ICIP40778.2020.9190820\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"63a5b2f09fd2b217fa5a3792b84a78397fc10be4\",\"title\":\"Retrieving and Highlighting Action with Spatiotemporal Reference\",\"url\":\"https://www.semanticscholar.org/paper/63a5b2f09fd2b217fa5a3792b84a78397fc10be4\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"2003.07637\",\"authors\":[{\"authorId\":\"49724493\",\"name\":\"H. Zhang\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1007/978-3-030-58565-5_15\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"180d7e45e5fc84138039f738830950dd9b7d0e06\",\"title\":\"Motion-Excited Sampler: Video Adversarial Attack with Sparked Prior\",\"url\":\"https://www.semanticscholar.org/paper/180d7e45e5fc84138039f738830950dd9b7d0e06\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2002.07362\",\"authors\":[{\"authorId\":\"31494849\",\"name\":\"D. Kim\"},{\"authorId\":\"143928528\",\"name\":\"Tian Lan\"},{\"authorId\":\"2992272\",\"name\":\"Chuhang Zou\"},{\"authorId\":\"123673109\",\"name\":\"Ning Xu\"},{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"},{\"authorId\":\"2242934\",\"name\":\"J. Eledath\"},{\"authorId\":\"3463966\",\"name\":\"G. Medioni\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"17be5c35b3ba02f8cc04313558a8d981b6242cc7\",\"title\":\"MILA: Multi-Task Learning from Videos via Efficient Inter-Frame Local Attention\",\"url\":\"https://www.semanticscholar.org/paper/17be5c35b3ba02f8cc04313558a8d981b6242cc7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19177140\",\"name\":\"S. Das\"},{\"authorId\":\"145745355\",\"name\":\"Rui Dai\"},{\"authorId\":\"34561667\",\"name\":\"Michal Koperski\"},{\"authorId\":\"10392396\",\"name\":\"Luca Minciullo\"},{\"authorId\":\"2645224\",\"name\":\"Lorenzo Garattoni\"},{\"authorId\":\"69929964\",\"name\":\"F. Br\\u00e9mond\"},{\"authorId\":\"2647267\",\"name\":\"G. Francesca\"}],\"doi\":\"10.1109/ICCV.2019.00092\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c17f395738bc3494974283ba9460c516a948f7ef\",\"title\":\"Toyota Smarthome: Real-World Activities of Daily Living\",\"url\":\"https://www.semanticscholar.org/paper/c17f395738bc3494974283ba9460c516a948f7ef\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2006.09220\",\"authors\":[{\"authorId\":\"41022481\",\"name\":\"Yazan Abu Farha\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1109/CVPR.2019.00369\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b4673e744d0ded47fe6df3b6314f79a41359578b\",\"title\":\"MS-TCN: Multi-Stage Temporal Convolutional Network for Action Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/b4673e744d0ded47fe6df3b6314f79a41359578b\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1908.01449\",\"authors\":[{\"authorId\":\"2177037\",\"name\":\"Andrew Kae\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"}],\"doi\":\"10.1109/WACV45572.2020.9093645\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e776cc129ed89303af6f2075ccfcea596243ff5d\",\"title\":\"Image to Video Domain Adaptation Using Web Supervision\",\"url\":\"https://www.semanticscholar.org/paper/e776cc129ed89303af6f2075ccfcea596243ff5d\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"2003.04852\",\"authors\":[{\"authorId\":\"3286107\",\"name\":\"X. Wang\"},{\"authorId\":\"1884134\",\"name\":\"Xiya Zhang\"},{\"authorId\":\"51280237\",\"name\":\"Yinheng Zhu\"},{\"authorId\":\"34811036\",\"name\":\"Yuchen Guo\"},{\"authorId\":\"2536159\",\"name\":\"Xiaoyun Yuan\"},{\"authorId\":\"83620577\",\"name\":\"Liuyu Xiang\"},{\"authorId\":\"96309455\",\"name\":\"Z. Wang\"},{\"authorId\":\"38329336\",\"name\":\"G. Ding\"},{\"authorId\":\"1741299\",\"name\":\"D. Brady\"},{\"authorId\":\"48382219\",\"name\":\"Qiong-hai Dai\"},{\"authorId\":\"47547866\",\"name\":\"Lu Fang\"}],\"doi\":\"10.1109/cvpr42600.2020.00333\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bf9a30ee3ef6320780c6980f21f3c3ea43fc2c62\",\"title\":\"PANDA: A Gigapixel-Level Human-Centric Video Dataset\",\"url\":\"https://www.semanticscholar.org/paper/bf9a30ee3ef6320780c6980f21f3c3ea43fc2c62\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2011.02543\",\"authors\":[{\"authorId\":\"30621486\",\"name\":\"Stepan Alekseevich Komkov\"},{\"authorId\":\"2007675511\",\"name\":\"Maksim Dzabraev\"},{\"authorId\":\"1380315305\",\"name\":\"Aleksandr Petiushko\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0e0be00a9dac71413ebfca60ea6b40a5d73c5877\",\"title\":\"Mutual Modality Learning for Video Action Classification\",\"url\":\"https://www.semanticscholar.org/paper/0e0be00a9dac71413ebfca60ea6b40a5d73c5877\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.03548\",\"authors\":[{\"authorId\":\"49984891\",\"name\":\"Ceyuan Yang\"},{\"authorId\":\"121983635\",\"name\":\"Yinghao Xu\"},{\"authorId\":\"46865320\",\"name\":\"Jianping Shi\"},{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"}],\"doi\":\"10.1109/cvpr42600.2020.00067\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"10db26c80238d70ca51d8a5293d893b6f1dedc8b\",\"title\":\"Temporal Pyramid Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/10db26c80238d70ca51d8a5293d893b6f1dedc8b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2010.05654\",\"authors\":[{\"authorId\":\"39714216\",\"name\":\"F. Ragusa\"},{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"2444519\",\"name\":\"S. Livatino\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a58a0732664b97b471b795df5812f98f24840490\",\"title\":\"The MECCANO Dataset: Understanding Human-Object Interactions from Egocentric Videos in an Industrial-like Domain\",\"url\":\"https://www.semanticscholar.org/paper/a58a0732664b97b471b795df5812f98f24840490\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.13017\",\"authors\":[{\"authorId\":\"143657833\",\"name\":\"Li Tao\"},{\"authorId\":\"1524733293\",\"name\":\"Xueting Wang\"},{\"authorId\":\"145572095\",\"name\":\"T. Yamasaki\"}],\"doi\":\"10.1109/ICIP40778.2020.9191133\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3cfee833437b81b89bb272dd4f5a501b61f2c0d1\",\"title\":\"Motion Representation Using Residual Frames with 3D CNN\",\"url\":\"https://www.semanticscholar.org/paper/3cfee833437b81b89bb272dd4f5a501b61f2c0d1\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50341802\",\"name\":\"S. Li\"},{\"authorId\":\"87046280\",\"name\":\"H. Yang\"},{\"authorId\":\"1560347965\",\"name\":\"Jun Sun\"}],\"doi\":\"10.1109/ICIP40778.2020.9191071\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a4b39edaf6ca123705d2f77cba77753154a0a64\",\"title\":\"Multilevel Interaction Reasoning For Complex Event Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8a4b39edaf6ca123705d2f77cba77753154a0a64\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"2005.10420\",\"authors\":[{\"authorId\":\"31378310\",\"name\":\"Mengtian Li\"},{\"authorId\":null,\"name\":\"Yu-Xiong Wang\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":\"10.1007/978-3-030-58536-5_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8527d3fe2a36e9d2d7a5dea641e1ef96fe0086d5\",\"title\":\"Towards Streaming Perception\",\"url\":\"https://www.semanticscholar.org/paper/8527d3fe2a36e9d2d7a5dea641e1ef96fe0086d5\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49597328\",\"name\":\"J. Xia\"},{\"authorId\":\"48624966\",\"name\":\"Wei Li\"},{\"authorId\":\"15316116\",\"name\":\"J. Shao\"},{\"authorId\":\"51305314\",\"name\":\"Zehuan Yuan\"},{\"authorId\":\"46741143\",\"name\":\"Jiajun Tang\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"},{\"authorId\":\"1697065\",\"name\":\"C. Wang\"},{\"authorId\":null,\"name\":\"ByteDance AI Lab\"},{\"authorId\":\"46197004\",\"name\":\"S. Tong\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ec00a57820335f136efe96eada551fddb83cde08\",\"title\":\"Multiple Attempts for AVA-Kinetics challenge 2020\",\"url\":\"https://www.semanticscholar.org/paper/ec00a57820335f136efe96eada551fddb83cde08\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7ae93062fdaa6054a2a44bf7b0352c5a5bf97eba\",\"title\":\"3 Dataset Construction and Task Description\",\"url\":\"https://www.semanticscholar.org/paper/7ae93062fdaa6054a2a44bf7b0352c5a5bf97eba\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1907.10837\",\"authors\":[{\"authorId\":\"2447769\",\"name\":\"Chunfei Ma\"},{\"authorId\":\"32407457\",\"name\":\"Joonhyang Choi\"},{\"authorId\":\"150936578\",\"name\":\"Byeongwon Lee\"},{\"authorId\":\"3246975\",\"name\":\"Seungji Yang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a3cb1fff165f191cf2a7d3be2b9efb7cb26e3ea8\",\"title\":\"Submission to ActivityNet Challenge 2019: Task B Spatio-temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/a3cb1fff165f191cf2a7d3be2b9efb7cb26e3ea8\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2012.09434\",\"authors\":[{\"authorId\":\"48031771\",\"name\":\"X. Liu\"},{\"authorId\":\"72285615\",\"name\":\"Yao Hu\"},{\"authorId\":\"98807701\",\"name\":\"Song Bai\"},{\"authorId\":\"1430778662\",\"name\":\"Fei Ding\"},{\"authorId\":\"145905113\",\"name\":\"X. Bai\"},{\"authorId\":\"2038266421\",\"name\":\"Philip H.S. Torr Huazhong University of Science\"},{\"authorId\":\"103081934\",\"name\":\"Technology\"},{\"authorId\":\"2038266423\",\"name\":\"Alibaba Group\"},{\"authorId\":\"51909023\",\"name\":\"U. O. Oxford\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"db1b0d0e70f29b0018d1a9462d98dd39559f3e4a\",\"title\":\"Multi-shot Temporal Event Localization: a Benchmark\",\"url\":\"https://www.semanticscholar.org/paper/db1b0d0e70f29b0018d1a9462d98dd39559f3e4a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2002.07442\",\"authors\":[{\"authorId\":\"50202365\",\"name\":\"S. Zhang\"},{\"authorId\":\"153098982\",\"name\":\"Sheng Guo\"},{\"authorId\":\"49015548\",\"name\":\"Weilin Huang\"},{\"authorId\":\"1915350\",\"name\":\"M. Scott\"},{\"authorId\":\"29461006\",\"name\":\"L. Wang\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"df2f2591054080d069e563cb9ca4e0592bc6df08\",\"title\":\"V4D: 4D Convolutional Neural Networks for Video-level Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/df2f2591054080d069e563cb9ca4e0592bc6df08\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"2012.05689\",\"authors\":[{\"authorId\":\"1845885740\",\"name\":\"Rui Yan\"},{\"authorId\":\"3041937\",\"name\":\"Lingxi Xie\"},{\"authorId\":\"2287686\",\"name\":\"Xiangbo Shu\"},{\"authorId\":\"8053308\",\"name\":\"J. Tang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f40225f23d46fd15d35b1529427f2f6055c737d4\",\"title\":\"Interactive Fusion of Multi-level Features for Compositional Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f40225f23d46fd15d35b1529427f2f6055c737d4\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2034347747\",\"name\":\"Chang Liu\"},{\"authorId\":\"153690115\",\"name\":\"Yulin Yang\"},{\"authorId\":\"2034348002\",\"name\":\"Xingyan Liu\"},{\"authorId\":\"51310276\",\"name\":\"Linpu Fang\"},{\"authorId\":\"40497356\",\"name\":\"Wenxiong Kang\"}],\"doi\":\"10.1109/TIFS.2020.3036218\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4a93f6df11436e0f5df09d79c814930430104b75\",\"title\":\"Dynamic-Hand-Gesture Authentication Dataset and Benchmark\",\"url\":\"https://www.semanticscholar.org/paper/4a93f6df11436e0f5df09d79c814930430104b75\",\"venue\":\"IEEE Transactions on Information Forensics and Security\",\"year\":2021},{\"arxivId\":\"2002.07471\",\"authors\":[{\"authorId\":\"50202365\",\"name\":\"S. Zhang\"},{\"authorId\":\"153098982\",\"name\":\"Sheng Guo\"},{\"authorId\":\"29461006\",\"name\":\"L. Wang\"},{\"authorId\":\"49015548\",\"name\":\"Weilin Huang\"},{\"authorId\":\"1915350\",\"name\":\"M. Scott\"}],\"doi\":\"10.1609/AAAI.V34I07.6983\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"65e170ba65e94ea7310367fc5540fbb9629010b5\",\"title\":\"Knowledge Integration Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/65e170ba65e94ea7310367fc5540fbb9629010b5\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1387989010\",\"name\":\"Fida Mohammad Thoker\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b7f3c20652907d4aae0c773f265d5cb833d5d767\",\"title\":\"Feature-Supervised Action Modality Transfer\",\"url\":\"https://www.semanticscholar.org/paper/b7f3c20652907d4aae0c773f265d5cb833d5d767\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2007.15796\",\"authors\":[{\"authorId\":\"1470673136\",\"name\":\"Yue Meng\"},{\"authorId\":\"47532522\",\"name\":\"Chung-Ching Lin\"},{\"authorId\":\"1819152\",\"name\":\"R. Panda\"},{\"authorId\":\"1706272\",\"name\":\"P. Sattigeri\"},{\"authorId\":\"2428823\",\"name\":\"Leonid Karlinsky\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"}],\"doi\":\"10.1007/978-3-030-58571-6_6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"11bf57d8a652de8e2ea436ff6a2707c95fa5197a\",\"title\":\"AR-Net: Adaptive Frame Resolution for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/11bf57d8a652de8e2ea436ff6a2707c95fa5197a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2010.11757\",\"authors\":[{\"authorId\":\"48239920\",\"name\":\"Chun-Fu Chen\"},{\"authorId\":\"1819152\",\"name\":\"R. Panda\"},{\"authorId\":\"40544169\",\"name\":\"K. Ramakrishnan\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"38060482\",\"name\":\"J. M. Cohn\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"33421444\",\"name\":\"Quanfu Fan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f5c2623a44660ad9fe6cd46710fec6e812a3375a\",\"title\":\"Deep Analysis of CNN-based Spatio-temporal Representations for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f5c2623a44660ad9fe6cd46710fec6e812a3375a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.08951\",\"authors\":[{\"authorId\":\"40627107\",\"name\":\"Y. Obinata\"},{\"authorId\":\"120056181\",\"name\":\"Takuma Yamamoto\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"37669f13ac47c69f5ff33de4e8673f4a377bf229\",\"title\":\"Temporal Extension Module for Skeleton-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/37669f13ac47c69f5ff33de4e8673f4a377bf229\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.07967\",\"authors\":[{\"authorId\":\"144810262\",\"name\":\"H. M. Nguyen\"},{\"authorId\":\"3388392\",\"name\":\"T. Miyazaki\"},{\"authorId\":\"2137463\",\"name\":\"Y. Sugaya\"},{\"authorId\":\"1740235\",\"name\":\"S. Omachi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"20b15ddf9efe511961321355bcb4a62c3a29a9ef\",\"title\":\"Multiple Visual-Semantic Embedding for Video Retrieval from Query Sentence\",\"url\":\"https://www.semanticscholar.org/paper/20b15ddf9efe511961321355bcb4a62c3a29a9ef\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46598954\",\"name\":\"Dan Li\"},{\"authorId\":\"1656176919\",\"name\":\"Kaifeng Zhang\"},{\"authorId\":\"40388829\",\"name\":\"Z. Li\"},{\"authorId\":\"97042247\",\"name\":\"Y. Chen\"}],\"doi\":\"10.3390/s20082381\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a3d3f0d1546018493cfa3a7c502a420e260a791f\",\"title\":\"A Spatiotemporal Convolutional Network for Multi-Behavior Recognition of Pigs\",\"url\":\"https://www.semanticscholar.org/paper/a3d3f0d1546018493cfa3a7c502a420e260a791f\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"1907.01847\",\"authors\":[{\"authorId\":\"73383712\",\"name\":\"W. Li\"},{\"authorId\":\"51305314\",\"name\":\"Zehuan Yuan\"},{\"authorId\":\"20412557\",\"name\":\"Dashan Guo\"},{\"authorId\":\"144585903\",\"name\":\"L. Huang\"},{\"authorId\":\"1706164\",\"name\":\"X. Fang\"},{\"authorId\":\"1697065\",\"name\":\"C. Wang\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c33e9aaec527dfeb733fc10c1d2bda417f546b37\",\"title\":\"Deformable Tube Network for Action Detection in Videos\",\"url\":\"https://www.semanticscholar.org/paper/c33e9aaec527dfeb733fc10c1d2bda417f546b37\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2004.03259\",\"authors\":[{\"authorId\":\"144861502\",\"name\":\"Lei Shi\"},{\"authorId\":\"48380079\",\"name\":\"Yi-Fan Zhang\"},{\"authorId\":\"48265260\",\"name\":\"Jian Cheng\"},{\"authorId\":\"1699900\",\"name\":\"H. Lu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"74f78f64e5d72f18a1679a5c7bc4269e237e53f7\",\"title\":\"SC4D: A Sparse 4D Convolutional Network for Skeleton-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/74f78f64e5d72f18a1679a5c7bc4269e237e53f7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1912.09930\",\"authors\":[{\"authorId\":\"7654960\",\"name\":\"Joanna Materzynska\"},{\"authorId\":\"15727192\",\"name\":\"Tete Xiao\"},{\"authorId\":\"46796686\",\"name\":\"Roei Herzig\"},{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"39635018\",\"name\":\"Xiaolong Wang\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/cvpr42600.2020.00113\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"af06120e7883ff969746ab473bfe09e642a90fc3\",\"title\":\"Something-Else: Compositional Action Recognition With Spatial-Temporal Interaction Networks\",\"url\":\"https://www.semanticscholar.org/paper/af06120e7883ff969746ab473bfe09e642a90fc3\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2012.09890\",\"authors\":[{\"authorId\":\"50997909\",\"name\":\"Amirhossein Dadashzadeh\"},{\"authorId\":\"2271983\",\"name\":\"A. Whone\"},{\"authorId\":\"2836006\",\"name\":\"M. Rolinski\"},{\"authorId\":\"1728108\",\"name\":\"M. Mirmehdi\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ad0f49996ccd867a19e2a4964746bf5b981db3b9\",\"title\":\"Exploring Motion Boundaries in an End-to-End Network for Vision-based Parkinson's Severity Assessment\",\"url\":\"https://www.semanticscholar.org/paper/ad0f49996ccd867a19e2a4964746bf5b981db3b9\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2012.11866\",\"authors\":[{\"authorId\":\"2595189\",\"name\":\"Zehua Sun\"},{\"authorId\":\"120809631\",\"name\":\"Jiwang Liu\"},{\"authorId\":\"143969578\",\"name\":\"Qiuhong Ke\"},{\"authorId\":\"1877377\",\"name\":\"H. Rahmani\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"816236bf3219363bfe4b847363e137b1fe6712e7\",\"title\":\"Human Action Recognition from Various Data Modalities: A Review\",\"url\":\"https://www.semanticscholar.org/paper/816236bf3219363bfe4b847363e137b1fe6712e7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Wei Li\"},{\"authorId\":\"2704823\",\"name\":\"Ze-Huan Yuan\"},{\"authorId\":\"144891856\",\"name\":\"An Zhao\"},{\"authorId\":\"15316116\",\"name\":\"J. Shao\"},{\"authorId\":\"1697065\",\"name\":\"C. Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"49b619ae667ad62917a5a08e3c2714b2415dd12f\",\"title\":\"ByteDance AI Lab AVA Challenge 2019 Technical Report\",\"url\":\"https://www.semanticscholar.org/paper/49b619ae667ad62917a5a08e3c2714b2415dd12f\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2008.03996\",\"authors\":[{\"authorId\":\"1471684559\",\"name\":\"Haoyu Chen\"},{\"authorId\":\"8706479\",\"name\":\"Z. Yu\"},{\"authorId\":null,\"name\":\"Xin Liu\"},{\"authorId\":\"1382648588\",\"name\":\"Wei Peng\"},{\"authorId\":\"66966514\",\"name\":\"Yoon Lee\"},{\"authorId\":\"83433495\",\"name\":\"G. Zhao\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6c9d32b48ad0c668e496b7c04c6f49dd87d5c5f5\",\"title\":\"2nd Place Scheme on Action Recognition Track of ECCV 2020 VIPriors Challenges: An Efficient Optical Flow Stream Guided Framework\",\"url\":\"https://www.semanticscholar.org/paper/6c9d32b48ad0c668e496b7c04c6f49dd87d5c5f5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1904.04289\",\"authors\":[{\"authorId\":\"3443095\",\"name\":\"Bruno Korbar\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":\"10.1109/ICCV.2019.00633\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2aed352cdd78010f72eaf618d52a4793fab32cea\",\"title\":\"SCSampler: Sampling Salient Clips From Video for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2aed352cdd78010f72eaf618d52a4793fab32cea\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2010.15336\",\"authors\":[{\"authorId\":\"144850780\",\"name\":\"Haoyuan Zhang\"},{\"authorId\":\"3292845\",\"name\":\"Y. Hou\"},{\"authorId\":\"8120382\",\"name\":\"P. Wang\"},{\"authorId\":\"151502410\",\"name\":\"Zihui Guo\"},{\"authorId\":\"1752792230\",\"name\":\"Wanqing Li\"}],\"doi\":\"10.1016/j.jvcir.2020.102942\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7997b15e6b91fba0f7af6596e12a303ff7de8223\",\"title\":\"SAR-NAS: Skeleton-based Action Recognition via Neural Architecture Searching\",\"url\":\"https://www.semanticscholar.org/paper/7997b15e6b91fba0f7af6596e12a303ff7de8223\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2020},{\"arxivId\":\"1912.04430\",\"authors\":[{\"authorId\":\"3121735\",\"name\":\"Paritosh Parmar\"},{\"authorId\":\"49059658\",\"name\":\"B. Morris.\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7aef63bbe103760e78f359223e35562cdaed16c1\",\"title\":\"HalluciNet-ing Spatiotemporal Representations Using 2D-CNN\",\"url\":\"https://www.semanticscholar.org/paper/7aef63bbe103760e78f359223e35562cdaed16c1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2006.05683\",\"authors\":[{\"authorId\":\"1560385163\",\"name\":\"Bo Pang\"},{\"authorId\":\"48513370\",\"name\":\"Yizhuo Li\"},{\"authorId\":\"48380079\",\"name\":\"Yi-Fan Zhang\"},{\"authorId\":\"2692368\",\"name\":\"Muchen Li\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"}],\"doi\":\"10.1109/cvpr42600.2020.00634\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d92827d0c62ce499e199caadb83e5ba457bc8869\",\"title\":\"TubeTK: Adopting Tubes to Track Multi-Object in a One-Step Training Model\",\"url\":\"https://www.semanticscholar.org/paper/d92827d0c62ce499e199caadb83e5ba457bc8869\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2007.10703\",\"authors\":[{\"authorId\":\"31638576\",\"name\":\"A. Arnab\"},{\"authorId\":\"1491624845\",\"name\":\"Chen Sun\"},{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"153433844\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1007/978-3-030-58607-2_44\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7d9660f127a880ec9757aedc90509524d744c15a\",\"title\":\"Uncertainty-Aware Weakly Supervised Action Detection from Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/7d9660f127a880ec9757aedc90509524d744c15a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e6435837116d2d08d4f873e2b556c29a4d20812d\",\"title\":\"Holistic Large Scale Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/e6435837116d2d08d4f873e2b556c29a4d20812d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1907.09658\",\"authors\":[{\"authorId\":\"145338228\",\"name\":\"Fan Yang\"},{\"authorId\":\"1783949\",\"name\":\"Sakriani Sakti\"},{\"authorId\":\"145175309\",\"name\":\"Y. Wu\"},{\"authorId\":\"145223960\",\"name\":\"S. Nakamura\"}],\"doi\":\"10.1145/3338533.3366569\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a94e1b573836ab358845fea8faf93b15671fdc69\",\"title\":\"Make Skeleton-based Action Recognition Model Smaller, Faster and Better\",\"url\":\"https://www.semanticscholar.org/paper/a94e1b573836ab358845fea8faf93b15671fdc69\",\"venue\":\"MMAsia\",\"year\":2019},{\"arxivId\":\"2010.14742\",\"authors\":[{\"authorId\":\"51115810\",\"name\":\"Hochul Hwang\"},{\"authorId\":\"1831882\",\"name\":\"C. Jang\"},{\"authorId\":\"51311609\",\"name\":\"Geonwoo Park\"},{\"authorId\":\"1679356768\",\"name\":\"Junghyun Cho\"},{\"authorId\":\"49596689\",\"name\":\"Ig-Jae Kim\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"06e3b496911e8f13e4fb54b61a636465d9cf1c99\",\"title\":\"ElderSim: A Synthetic Data Generation Platform for Human Action Recognition in Eldercare Applications\",\"url\":\"https://www.semanticscholar.org/paper/06e3b496911e8f13e4fb54b61a636465d9cf1c99\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151474893\",\"name\":\"Maryam Koohzadi\"},{\"authorId\":\"48315995\",\"name\":\"Nasrollah Moghadam Charkari\"}],\"doi\":\"10.1007/s11063-020-10248-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"397d3252caa29d233ab97cf7213f398c17c28409\",\"title\":\"A Context Based Deep Temporal Embedding Network in Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/397d3252caa29d233ab97cf7213f398c17c28409\",\"venue\":\"Neural Processing Letters\",\"year\":2020},{\"arxivId\":\"2007.10321\",\"authors\":[{\"authorId\":\"50031265\",\"name\":\"Xitong Yang\"},{\"authorId\":\"40058797\",\"name\":\"Xiaodong Yang\"},{\"authorId\":\"2391885\",\"name\":\"Sifei Liu\"},{\"authorId\":\"3232265\",\"name\":\"Deqing Sun\"},{\"authorId\":\"152296574\",\"name\":\"L. Davis\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1cedd24562c1e95415b246a1a0e9912d8de6f0f7\",\"title\":\"Hierarchical Contrastive Motion Learning for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1cedd24562c1e95415b246a1a0e9912d8de6f0f7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144149597\",\"name\":\"Tianshu Yu\"},{\"authorId\":\"2180892\",\"name\":\"Yikang Li\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"}],\"doi\":\"10.1007/978-3-030-58607-2_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b9ff84d2d45ec704d5680119d0ea0faa01f016be\",\"title\":\"RhyRNN: Rhythmic RNN for Recognizing Events in Long and Complex Videos\",\"url\":\"https://www.semanticscholar.org/paper/b9ff84d2d45ec704d5680119d0ea0faa01f016be\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1910.13888\",\"authors\":[{\"authorId\":\"3040310\",\"name\":\"Y. Jiang\"},{\"authorId\":\"1389284356\",\"name\":\"Kaixu Cui\"},{\"authorId\":\"144690387\",\"name\":\"B. Peng\"},{\"authorId\":\"48258796\",\"name\":\"C. Xu\"}],\"doi\":\"10.1109/ICCVW.2019.00195\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"126d93fb45ee6e4d9af314981e8430aa5b2f24c1\",\"title\":\"Comprehensive Video Understanding: Video Summarization with Content-Based Video Recommender Design\",\"url\":\"https://www.semanticscholar.org/paper/126d93fb45ee6e4d9af314981e8430aa5b2f24c1\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1904.05049\",\"authors\":[{\"authorId\":\"1713312\",\"name\":\"Y. Chen\"},{\"authorId\":\"2681569\",\"name\":\"Haoqi Fan\"},{\"authorId\":\"48310008\",\"name\":\"B. Xu\"},{\"authorId\":\"3305169\",\"name\":\"Zhicheng Yan\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":\"10.1109/ICCV.2019.00353\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0d9eb72ea89bb7bf5720a7b2c2f3f77c26fc67a6\",\"title\":\"Drop an Octave: Reducing Spatial Redundancy in Convolutional Neural Networks With Octave Convolution\",\"url\":\"https://www.semanticscholar.org/paper/0d9eb72ea89bb7bf5720a7b2c2f3f77c26fc67a6\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2008.10428\",\"authors\":[{\"authorId\":\"1400188907\",\"name\":\"Hezhen Hu\"},{\"authorId\":\"51476742\",\"name\":\"Wengang Zhou\"},{\"authorId\":\"2653622\",\"name\":\"Junfu Pu\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"cc338010de2bfba5dcf52d61bbb0ea3fe5495cea\",\"title\":\"Global-local Enhancement Network for NMFs-aware Sign Language Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cc338010de2bfba5dcf52d61bbb0ea3fe5495cea\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1811.07519\",\"authors\":[{\"authorId\":\"143993120\",\"name\":\"K. Hu\"},{\"authorId\":\"1681921\",\"name\":\"B. Raj\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"41ab8c0c47dd8fce41dbe904ab78ed1a7320dfd6\",\"title\":\"Higher-order Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/41ab8c0c47dd8fce41dbe904ab78ed1a7320dfd6\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2010.11289\",\"authors\":[{\"authorId\":\"23183886\",\"name\":\"W. Kratsch\"},{\"authorId\":\"1499270024\",\"name\":\"Fabian K\\u00f6nig\"},{\"authorId\":\"2711584\",\"name\":\"M. R\\u00f6glinger\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0c6e7a812524c295dfa7385b3cfd5225c526459b\",\"title\":\"Shedding Light on Blind Spots: Developing a Reference Architecture to Leverage Video Data for Process Mining\",\"url\":\"https://www.semanticscholar.org/paper/0c6e7a812524c295dfa7385b3cfd5225c526459b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.02632\",\"authors\":[{\"authorId\":\"52025559\",\"name\":\"Mahsa Ehsanpour\"},{\"authorId\":\"3447236\",\"name\":\"A. Abedin\"},{\"authorId\":\"19170799\",\"name\":\"F. Saleh\"},{\"authorId\":\"31635758\",\"name\":\"Javen Shi\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"},{\"authorId\":\"1387977754\",\"name\":\"Hamid Rezatofighi\"}],\"doi\":\"10.1007/978-3-030-58545-7_11\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"81287e31f3e659aaedb5dce0646ba2b86377b282\",\"title\":\"Joint Learning of Social Groups, Individuals Action and Sub-group Activities in Videos\",\"url\":\"https://www.semanticscholar.org/paper/81287e31f3e659aaedb5dce0646ba2b86377b282\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2011.12026\",\"authors\":[{\"authorId\":\"51118864\",\"name\":\"I. Skorokhodov\"},{\"authorId\":\"1466518477\",\"name\":\"S. Ignatyev\"},{\"authorId\":\"1712479\",\"name\":\"Mohamed Elhoseiny\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"25f52a76678a636179384363745123cd54ac6aa8\",\"title\":\"Adversarial Generation of Continuous Images\",\"url\":\"https://www.semanticscholar.org/paper/25f52a76678a636179384363745123cd54ac6aa8\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2489020\",\"name\":\"Brian Geuther\"},{\"authorId\":\"1995462965\",\"name\":\"Asaf Pe'er\"},{\"authorId\":\"145818206\",\"name\":\"Hao He\"},{\"authorId\":\"71586239\",\"name\":\"G. Sabnis\"},{\"authorId\":\"2264830\",\"name\":\"V. Philip\"},{\"authorId\":\"49533156\",\"name\":\"V. Kumar\"}],\"doi\":\"10.1101/2020.10.08.331017\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b63e43d368935fb8657fa0bd800d03b1229485eb\",\"title\":\"Action detection using a neural network elucidates the genetics of mouse grooming behavior\",\"url\":\"https://www.semanticscholar.org/paper/b63e43d368935fb8657fa0bd800d03b1229485eb\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"91999133\",\"name\":\"Ji-Hwan Kim\"},{\"authorId\":\"3247148\",\"name\":\"Jae-Pil Heo\"}],\"doi\":\"10.1109/ACCESS.2019.2946898\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f1db07ce91065594751cd51d31f086bc02d42968\",\"title\":\"Learning Coarse and Fine Features for Precise Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/f1db07ce91065594751cd51d31f086bc02d42968\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"2007.05515\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0e599d703e358d6e554da859cff116553053d0fa\",\"title\":\"AViD Dataset: Anonymized Videos from Diverse Countries\",\"url\":\"https://www.semanticscholar.org/paper/0e599d703e358d6e554da859cff116553053d0fa\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2006.08247\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":\"10.1016/j.patrec.2020.11.012\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9c9ee02e3394adde596c35d1966566b2d971f426\",\"title\":\"Learn to cycle: Time-consistent feature discovery for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/9c9ee02e3394adde596c35d1966566b2d971f426\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1772198\",\"name\":\"X. Wu\"},{\"authorId\":\"3307319\",\"name\":\"Qing-Ge Ji\"}],\"doi\":\"10.1145/3426826.3426836\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"64469e496132f3e25cdc5bfcfb3b7069c5e15ac4\",\"title\":\"Split and Attentive-Aggregated Learnable Shift Module for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/64469e496132f3e25cdc5bfcfb3b7069c5e15ac4\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46276307\",\"name\":\"Jianwei Li\"},{\"authorId\":\"143836554\",\"name\":\"Hainan Cui\"},{\"authorId\":\"1878916102\",\"name\":\"Tianxiao Guo\"},{\"authorId\":\"1877155774\",\"name\":\"Qingrui Hu\"},{\"authorId\":\"8034759\",\"name\":\"Y. Shen\"}],\"doi\":\"10.1109/ICMEW46912.2020.9106049\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"95920910eb5ca01a28b0d3fbb90cfb3e025a4382\",\"title\":\"Efficient Fitness Action Analysis Based on Spatio-Temporal Feature Encoding\",\"url\":\"https://www.semanticscholar.org/paper/95920910eb5ca01a28b0d3fbb90cfb3e025a4382\",\"venue\":\"2020 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2020},{\"arxivId\":\"1912.01601\",\"authors\":[{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"92020e4a2ed14a5f3fd421bcf1111dd2403a237a\",\"title\":\"LiteEval: A Coarse-to-Fine Framework for Resource Efficient Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/92020e4a2ed14a5f3fd421bcf1111dd2403a237a\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"2012.08510\",\"authors\":[{\"authorId\":\"144234446\",\"name\":\"Bo He\"},{\"authorId\":\"50031265\",\"name\":\"Xitong Yang\"},{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"48444479\",\"name\":\"Hao Chen\"},{\"authorId\":\"38760573\",\"name\":\"Ser-Nam Lim\"},{\"authorId\":\"51453757\",\"name\":\"Abhinav Shrivastava\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b77967866434f46c41f25baf7149d9b027b600b3\",\"title\":\"GTA: Global Temporal Attention for Video Action Understanding\",\"url\":\"https://www.semanticscholar.org/paper/b77967866434f46c41f25baf7149d9b027b600b3\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1912.06992\",\"authors\":[{\"authorId\":\"2547290\",\"name\":\"Jingwei Ji\"},{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/cvpr42600.2020.01025\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d1242ba8fdb994b82a0575dc92f30f7b26a75707\",\"title\":\"Action Genome: Actions As Compositions of Spatio-Temporal Scene Graphs\",\"url\":\"https://www.semanticscholar.org/paper/d1242ba8fdb994b82a0575dc92f30f7b26a75707\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1912.04316\",\"authors\":[{\"authorId\":\"34656387\",\"name\":\"Matteo Tomei\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2175529\",\"name\":\"Simone Calderara\"},{\"authorId\":\"102613292\",\"name\":\"Simone Bronzin\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ad16dbe1a5c3b192de961a1f1c3fedeba8bf2783\",\"title\":\"STAGE: Spatio-Temporal Attention on Graph Entities for Video Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/ad16dbe1a5c3b192de961a1f1c3fedeba8bf2783\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1980785576\",\"name\":\"Shiho Yagasaki\"},{\"authorId\":\"2962962\",\"name\":\"Norihiro Koizumi\"},{\"authorId\":\"1980672730\",\"name\":\"Yu Nishiyama\"},{\"authorId\":\"1980870641\",\"name\":\"Ryosuke Kondo\"},{\"authorId\":\"51227226\",\"name\":\"Tsubasa Imaizumi\"},{\"authorId\":\"1980775183\",\"name\":\"Naoki Matsumoto\"},{\"authorId\":\"47413317\",\"name\":\"M. Ogawa\"},{\"authorId\":\"31538246\",\"name\":\"K. Numata\"}],\"doi\":\"10.1007/s11548-020-02265-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5ee463707a5e0633d47431c281b908fcbb81117e\",\"title\":\"Estimating 3-dimensional liver motion using deep learning and 2-dimensional ultrasound images\",\"url\":\"https://www.semanticscholar.org/paper/5ee463707a5e0633d47431c281b908fcbb81117e\",\"venue\":\"International Journal of Computer Assisted Radiology and Surgery\",\"year\":2020},{\"arxivId\":\"2006.14582\",\"authors\":[{\"authorId\":\"50079897\",\"name\":\"X. Li\"},{\"authorId\":null,\"name\":\"Yali Wang\"},{\"authorId\":\"1491073267\",\"name\":\"Zhipeng Zhou\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1109/cvpr42600.2020.00117\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"da9b802ea051ffb7ef2de0d8d1003944a60bf44c\",\"title\":\"SmallBigNet: Integrating Core and Contextual Views for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/da9b802ea051ffb7ef2de0d8d1003944a60bf44c\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2012.03457\",\"authors\":[{\"authorId\":\"2151587\",\"name\":\"Sangdoo Yun\"},{\"authorId\":\"2390510\",\"name\":\"Seong Joon Oh\"},{\"authorId\":\"3086596\",\"name\":\"Byeongho Heo\"},{\"authorId\":\"2086576\",\"name\":\"Dongyoon Han\"},{\"authorId\":\"52289773\",\"name\":\"Jinhyung Kim\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0f6830373b3a2758baf5efa50f4ca9ac17b1a377\",\"title\":\"VideoMix: Rethinking Data Augmentation for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/0f6830373b3a2758baf5efa50f4ca9ac17b1a377\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.07420\",\"authors\":[{\"authorId\":\"3671120\",\"name\":\"Yanyi Zhang\"},{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"144555425\",\"name\":\"I. Marsic\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d951f225ab2d64af36e9c44a658ac79c2afde7f3\",\"title\":\"Multi-Label Activity Recognition using Activity-specific Features\",\"url\":\"https://www.semanticscholar.org/paper/d951f225ab2d64af36e9c44a658ac79c2afde7f3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.12384\",\"authors\":[{\"authorId\":\"9385903\",\"name\":\"S. Zhu\"},{\"authorId\":\"1390892946\",\"name\":\"Taojiannan Yang\"},{\"authorId\":\"1422036273\",\"name\":\"Mat'ias Mendieta\"},{\"authorId\":\"143916976\",\"name\":\"Chen Chen\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ba1dda6494709cac7c48c95c81afff7a087f2031\",\"title\":\"A3D: Adaptive 3D Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ba1dda6494709cac7c48c95c81afff7a087f2031\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Loc Trinh\"},{\"authorId\":null,\"name\":\"Michael Tsang\"},{\"authorId\":null,\"name\":\"Sirisha Rambhatla\"},{\"authorId\":null,\"name\":\"Yan Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"41cbea36c8107d6ed4f3b89bd641e292d0096a24\",\"title\":\"Interpretable and Trustworthy Deepfake Detection via Dynamic Prototypes\",\"url\":\"https://www.semanticscholar.org/paper/41cbea36c8107d6ed4f3b89bd641e292d0096a24\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31494849\",\"name\":\"D. Kim\"},{\"authorId\":\"143928528\",\"name\":\"Tian Lan\"},{\"authorId\":\"2992272\",\"name\":\"Chuhang Zou\"},{\"authorId\":null,\"name\":\"Ning Xu\"},{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"},{\"authorId\":\"2242934\",\"name\":\"J. Eledath\"},{\"authorId\":\"3463966\",\"name\":\"G. Medioni\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"95d195beafa410ecddf314da3ab215258d3e5e39\",\"title\":\"Multi-Task Learning from Videos via Efficient Inter-Frame Attention\",\"url\":\"https://www.semanticscholar.org/paper/95d195beafa410ecddf314da3ab215258d3e5e39\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.01278\",\"authors\":[{\"authorId\":\"1397974082\",\"name\":\"Juan-Manuel Perez-Rua\"},{\"authorId\":\"145944235\",\"name\":\"B. Mart\\u00ednez\"},{\"authorId\":\"2171228\",\"name\":\"Xiatian Zhu\"},{\"authorId\":\"3098817\",\"name\":\"Antoine Toisoul\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"145406420\",\"name\":\"Tao Xiang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8fcc3c2e525307f7a694979500dcca09d0f3a830\",\"title\":\"Knowing What, Where and When to Look: Efficient Video Action Modeling with Attention\",\"url\":\"https://www.semanticscholar.org/paper/8fcc3c2e525307f7a694979500dcca09d0f3a830\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2000124994\",\"name\":\"Mo Sun\"},{\"authorId\":\"81752599\",\"name\":\"J. Li\"},{\"authorId\":\"151503256\",\"name\":\"Hui Feng\"},{\"authorId\":\"2000123285\",\"name\":\"Wei Gou\"},{\"authorId\":\"153784017\",\"name\":\"Haifeng Shen\"},{\"authorId\":\"152226504\",\"name\":\"J. Tang\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"},{\"authorId\":\"2778556\",\"name\":\"Jie-ping Ye\"}],\"doi\":\"10.1145/3382507.3417971\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d0afe00d375df35342afd0723689aa9570c28863\",\"title\":\"Multi-modal Fusion Using Spatio-temporal and Static Features for Group Emotion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d0afe00d375df35342afd0723689aa9570c28863\",\"venue\":\"ICMI\",\"year\":2020},{\"arxivId\":\"1911.09243\",\"authors\":[{\"authorId\":null,\"name\":\"Ya Wang\"},{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"145724892\",\"name\":\"Fu Li\"},{\"authorId\":\"46550737\",\"name\":\"Xiang Long\"},{\"authorId\":\"47230289\",\"name\":\"Zhichao Zhou\"},{\"authorId\":\"1685259\",\"name\":\"Jinwen Ma\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"}],\"doi\":\"10.1609/AAAI.V34I07.6909\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"8cc97fff3292f13cfc73721dc4ae26d8f970692f\",\"title\":\"Multi-Label Classification with Label Graph Superimposing\",\"url\":\"https://www.semanticscholar.org/paper/8cc97fff3292f13cfc73721dc4ae26d8f970692f\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2802283\",\"name\":\"H. Liu\"},{\"authorId\":\"153108488\",\"name\":\"Bin Ren\"},{\"authorId\":\"47842072\",\"name\":\"M. Liu\"},{\"authorId\":\"2705961\",\"name\":\"R. Ding\"}],\"doi\":\"10.1109/ICIP40778.2020.9190958\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"93011a4d810eacfc4ff3202d3c38e78706ff3341\",\"title\":\"Grouped Temporal Enhancement Module for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/93011a4d810eacfc4ff3202d3c38e78706ff3341\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"1912.04070\",\"authors\":[{\"authorId\":\"82657029\",\"name\":\"G. Varol\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d9cd1ffcd91ef7e51b7a6bb4e65a3fada4e11244\",\"title\":\"Synthetic Humans for Action Recognition from Unseen Viewpoints\",\"url\":\"https://www.semanticscholar.org/paper/d9cd1ffcd91ef7e51b7a6bb4e65a3fada4e11244\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1485630780\",\"name\":\"Yanbin Hao\"},{\"authorId\":\"145063759\",\"name\":\"Hao Zhang\"},{\"authorId\":\"143977389\",\"name\":\"C. Ngo\"},{\"authorId\":\"48874063\",\"name\":\"Q. Liu\"},{\"authorId\":\"144635784\",\"name\":\"X. Hu\"}],\"doi\":\"10.1145/3394171.3413595\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"1e29826ff34cc39f04d23784ad8ec6649717e1ce\",\"title\":\"Compact Bilinear Augmented Query Structured Attention for Sport Highlights Classification\",\"url\":\"https://www.semanticscholar.org/paper/1e29826ff34cc39f04d23784ad8ec6649717e1ce\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1904.03116\",\"authors\":[{\"authorId\":\"1889486\",\"name\":\"Yaser Souri\"},{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c0450f376334b8c4bd57d34a35ab060ddc3595ee\",\"title\":\"Weakly Supervised Action Segmentation Using Mutual Consistency\",\"url\":\"https://www.semanticscholar.org/paper/c0450f376334b8c4bd57d34a35ab060ddc3595ee\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1904.08916\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1109/CVPRW.2019.00298\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"077346a4336f2c1d8cb1f5edb42c6d4bcbedb850\",\"title\":\"Early Detection of Injuries in MLB Pitchers from Video\",\"url\":\"https://www.semanticscholar.org/paper/077346a4336f2c1d8cb1f5edb42c6d4bcbedb850\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7634810\",\"name\":\"Weiyao Wang\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"}],\"doi\":\"10.1109/CVPR42600.2020.01271\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f6caf91f731fab861ef420f680cf691f12f70134\",\"title\":\"What Makes Training Multi-Modal Classification Networks Hard?\",\"url\":\"https://www.semanticscholar.org/paper/f6caf91f731fab861ef420f680cf691f12f70134\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2008.05721\",\"authors\":[{\"authorId\":\"48271129\",\"name\":\"T. Kim\"},{\"authorId\":\"98080420\",\"name\":\"H. Lee\"},{\"authorId\":\"1387831061\",\"name\":\"MyeongAh Cho\"},{\"authorId\":\"48411936\",\"name\":\"H. Lee\"},{\"authorId\":\"80069330\",\"name\":\"Dong Heon Cho\"},{\"authorId\":\"39847092\",\"name\":\"Sangyoun Lee\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"24b300420bd814e48b59a3419a22d706da6c4191\",\"title\":\"Learning Temporally Invariant and Localizable Features via Data Augmentation for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/24b300420bd814e48b59a3419a22d706da6c4191\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.07248\",\"authors\":[{\"authorId\":\"1560385163\",\"name\":\"Bo Pang\"},{\"authorId\":\"1527112562\",\"name\":\"Yizhuo Li\"},{\"authorId\":\"49299169\",\"name\":\"J. Li\"},{\"authorId\":\"1807805250\",\"name\":\"Muchen Li\"},{\"authorId\":\"50732737\",\"name\":\"Hanwen Cao\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"965571810fcb79fdaaed7329ff57b3720508a241\",\"title\":\"TDAF: Top-Down Attention Framework for Vision Tasks\",\"url\":\"https://www.semanticscholar.org/paper/965571810fcb79fdaaed7329ff57b3720508a241\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2007.09883\",\"authors\":[{\"authorId\":\"13099867\",\"name\":\"Haisheng Su\"},{\"authorId\":\"153285206\",\"name\":\"J. Feng\"},{\"authorId\":\"46798949\",\"name\":\"H. Shao\"},{\"authorId\":\"1768672172\",\"name\":\"Zhenyu Jiang\"},{\"authorId\":\"40951853\",\"name\":\"Manyuan Zhang\"},{\"authorId\":\"145717875\",\"name\":\"Wei Wu\"},{\"authorId\":\"30752055\",\"name\":\"Y. Liu\"},{\"authorId\":\"119885708\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3e7b4c49ad5754e9d7e9019684a777ae66ee5eed\",\"title\":\"Complementary Boundary Generator with Scale-Invariant Relation Modeling for Temporal Action Localization: Submission to ActivityNet Challenge 2020\",\"url\":\"https://www.semanticscholar.org/paper/3e7b4c49ad5754e9d7e9019684a777ae66ee5eed\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.11040\",\"authors\":[{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"2521776\",\"name\":\"B. Shuai\"},{\"authorId\":\"2397422\",\"name\":\"Joseph Tighe\"}],\"doi\":\"10.1007/978-3-030-58539-6_17\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c40990d00633b63caf78082f8570a55e2ec5abbb\",\"title\":\"Directional Temporal Modeling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c40990d00633b63caf78082f8570a55e2ec5abbb\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.15781\",\"authors\":[{\"authorId\":\"26663607\",\"name\":\"Baoxiong Jia\"},{\"authorId\":\"49069534\",\"name\":\"Yixin Chen\"},{\"authorId\":\"51442394\",\"name\":\"Siyuan Huang\"},{\"authorId\":\"2672448\",\"name\":\"Yixin Zhu\"},{\"authorId\":\"12554898\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1007/978-3-030-58574-7_46\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cd6b1063f234836a1dcdc7f8a39c10c4d8fdbbbe\",\"title\":\"LEMMA: A Multi-view Dataset for Learning Multi-agent Multi-task Activities\",\"url\":\"https://www.semanticscholar.org/paper/cd6b1063f234836a1dcdc7f8a39c10c4d8fdbbbe\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410131672\",\"name\":\"Yang Mi\"},{\"authorId\":\"2244863\",\"name\":\"X. Zhang\"},{\"authorId\":\"48459086\",\"name\":\"Zhongguo Li\"},{\"authorId\":\"40696794\",\"name\":\"Song Wang\"}],\"doi\":\"10.1109/TIP.2020.2989864\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e099ed2b5389322c71cf693c59decbf08bb4c2d6\",\"title\":\"Dual-Branch Network With a Subtle Motion Detector for Microaction Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/e099ed2b5389322c71cf693c59decbf08bb4c2d6\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993592720\",\"name\":\"Zhaobo Qi\"},{\"authorId\":\"47672591\",\"name\":\"Shuhui Wang\"},{\"authorId\":\"145422145\",\"name\":\"Chi Su\"},{\"authorId\":\"153142919\",\"name\":\"Li Su\"},{\"authorId\":\"153159021\",\"name\":\"Qingming Huang\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1145/3394171.3413954\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1d71c6ecb0d7ca618665e6402e84c2f5d39b761f\",\"title\":\"Towards More Explainability: Concept Knowledge Mining Network for Event Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1d71c6ecb0d7ca618665e6402e84c2f5d39b761f\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2010.10008\",\"authors\":[{\"authorId\":\"1993649162\",\"name\":\"Shuning Chang\"},{\"authorId\":\"50854772\",\"name\":\"Li Yuan\"},{\"authorId\":\"35785179\",\"name\":\"Xuecheng Nie\"},{\"authorId\":\"1993645769\",\"name\":\"Z. Huang\"},{\"authorId\":\"1864078340\",\"name\":\"Yichen Zhou\"},{\"authorId\":\"1994343285\",\"name\":\"Yu-Peng Chen\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"}],\"doi\":\"10.1145/3394171.3416299\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1f5eb13d8b3e86e49664329b6a23462cfb02437c\",\"title\":\"Towards Accurate Human Pose Estimation in Videos of Crowded Scenes\",\"url\":\"https://www.semanticscholar.org/paper/1f5eb13d8b3e86e49664329b6a23462cfb02437c\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1908.07625\",\"authors\":[{\"authorId\":\"145944235\",\"name\":\"B. Mart\\u00ednez\"},{\"authorId\":\"1996209\",\"name\":\"Davide Modolo\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"2397422\",\"name\":\"Joseph Tighe\"}],\"doi\":\"10.1109/ICCV.2019.00558\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d5a8fbb37f564b397071e016fb39e4c6a612cc83\",\"title\":\"Action Recognition With Spatial-Temporal Discriminative Filter Banks\",\"url\":\"https://www.semanticscholar.org/paper/d5a8fbb37f564b397071e016fb39e4c6a612cc83\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1904.02422\",\"authors\":[{\"authorId\":\"41022447\",\"name\":\"Okan K\\u00f6p\\u00fckl\\u00fc\"},{\"authorId\":\"1862703\",\"name\":\"N. Kose\"},{\"authorId\":\"66999822\",\"name\":\"Ahmet Gunduz\"},{\"authorId\":\"145512909\",\"name\":\"G. Rigoll\"}],\"doi\":\"10.1109/ICCVW.2019.00240\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b4f307750b6e192239dff6f80f203dcf9e05cb5d\",\"title\":\"Resource Efficient 3D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/b4f307750b6e192239dff6f80f203dcf9e05cb5d\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1909.08611\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"51463388\",\"name\":\"G. Kapidis\"},{\"authorId\":\"2358813\",\"name\":\"Grigorios Kalliatakis\"},{\"authorId\":\"49018286\",\"name\":\"C. Chrysoulas\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"},{\"authorId\":\"1739867\",\"name\":\"R. Veltkamp\"}],\"doi\":\"10.1109/ICCVW.2019.00524\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"aaf75022b71fb0346b476ba1b8ad7ec9633d2f58\",\"title\":\"Class Feature Pyramids for Video Explanation\",\"url\":\"https://www.semanticscholar.org/paper/aaf75022b71fb0346b476ba1b8ad7ec9633d2f58\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1908.04519\",\"authors\":[{\"authorId\":\"97765655\",\"name\":\"J. Xia\"},{\"authorId\":\"46741143\",\"name\":\"Jiajun Tang\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a82614927db94b233415975ab98f92e9468e6492\",\"title\":\"Three Branches: Detecting Actions With Richer Features\",\"url\":\"https://www.semanticscholar.org/paper/a82614927db94b233415975ab98f92e9468e6492\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52289773\",\"name\":\"Jinhyung Kim\"},{\"authorId\":\"33532407\",\"name\":\"S. Cha\"},{\"authorId\":\"1405197098\",\"name\":\"Dongyoon Wee\"},{\"authorId\":\"40656963\",\"name\":\"Soonmin Bae\"},{\"authorId\":\"1769295\",\"name\":\"Junmo Kim\"}],\"doi\":\"10.1109/cvpr42600.2020.01212\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"96c0ba91d650c571d20961f1fae0560f8962afa5\",\"title\":\"Regularization on Spatio-Temporally Smoothed Feature for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/96c0ba91d650c571d20961f1fae0560f8962afa5\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2151048\",\"name\":\"Taiki Miyanishi\"},{\"authorId\":\"34772057\",\"name\":\"Takuya Maekawa\"},{\"authorId\":\"1716788\",\"name\":\"M. Kawanabe\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b3fc587b83d8c6a28b2bc4f9a1f8770f42fb5658\",\"title\":\"Two-Stream Spatiotemporal Compositional Attention Network for VideoQA\",\"url\":\"https://www.semanticscholar.org/paper/b3fc587b83d8c6a28b2bc4f9a1f8770f42fb5658\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1904.12993\",\"authors\":[{\"authorId\":\"49890205\",\"name\":\"Yubo Zhang\"},{\"authorId\":\"2931554\",\"name\":\"P. Tokmakov\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"55f70b16f087ec9b11168c67f3f3ff4e61baa0e5\",\"title\":\"A Study on Action Detection in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/55f70b16f087ec9b11168c67f3f3ff4e61baa0e5\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2007.04515\",\"authors\":[{\"authorId\":\"3234247\",\"name\":\"Senthil Purushwalkam\"},{\"authorId\":\"1391076188\",\"name\":\"Tian Ye\"},{\"authorId\":\"47924870\",\"name\":\"Saurabh Gupta\"},{\"authorId\":null,\"name\":\"Abhinav Gupta\"}],\"doi\":\"10.1007/978-3-030-58574-7_16\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9e3a6c70799ee375e4b6035f59236677439c41a5\",\"title\":\"Aligning Videos in Space and Time\",\"url\":\"https://www.semanticscholar.org/paper/9e3a6c70799ee375e4b6035f59236677439c41a5\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2006.14613\",\"authors\":[{\"authorId\":\"14258597\",\"name\":\"A. Jabri\"},{\"authorId\":\"144956994\",\"name\":\"Andrew Owens\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c78b00f2abbf7523a860e717f767b0bb8f860143\",\"title\":\"Space-Time Correspondence as a Contrastive Random Walk\",\"url\":\"https://www.semanticscholar.org/paper/c78b00f2abbf7523a860e717f767b0bb8f860143\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2007.03056\",\"authors\":[{\"authorId\":\"19177140\",\"name\":\"S. Das\"},{\"authorId\":\"18139992\",\"name\":\"Saurav Sharma\"},{\"authorId\":\"145745355\",\"name\":\"Rui Dai\"},{\"authorId\":\"69929964\",\"name\":\"F. Br\\u00e9mond\"},{\"authorId\":\"49796048\",\"name\":\"M. Thonnat\"}],\"doi\":\"10.1007/978-3-030-58545-7_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"de51038f9f9e94fa9fdb54c5c3e911f918e87ba9\",\"title\":\"VPN: Learning Video-Pose Embedding for Activities of Daily Living\",\"url\":\"https://www.semanticscholar.org/paper/de51038f9f9e94fa9fdb54c5c3e911f918e87ba9\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1908.01341\",\"authors\":[{\"authorId\":\"47087136\",\"name\":\"Zhaoyang Yang\"},{\"authorId\":\"113515522\",\"name\":\"Zhenmei Shi\"},{\"authorId\":\"2029246\",\"name\":\"Xiaoyong Shen\"},{\"authorId\":\"5068280\",\"name\":\"Yu-Wing Tai\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bd712a873ae4eefb6c623c8e605e42c5a0173e3e\",\"title\":\"SF-Net: Structured Feature Network for Continuous Sign Language Recognition\",\"url\":\"https://www.semanticscholar.org/paper/bd712a873ae4eefb6c623c8e605e42c5a0173e3e\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49120765\",\"name\":\"R. Singh\"},{\"authorId\":\"1387052806\",\"name\":\"Ankur Sonawane\"},{\"authorId\":\"33188415\",\"name\":\"R. Srivastava\"}],\"doi\":\"10.1007/s00530-019-00635-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"45a7a721cfe3f179c5bf86ae08340b1f38fdde48\",\"title\":\"Recent evolution of modern datasets for human activity recognition: a deep survey\",\"url\":\"https://www.semanticscholar.org/paper/45a7a721cfe3f179c5bf86ae08340b1f38fdde48\",\"venue\":\"Multimedia Systems\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46578437\",\"name\":\"K. Liu\"},{\"authorId\":\"13384075\",\"name\":\"Minzhi Zhu\"},{\"authorId\":\"2513605\",\"name\":\"Huiyuan Fu\"},{\"authorId\":\"40013029\",\"name\":\"Hua-Dong Ma\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1145/3394171.3416298\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"eaf34194a0e86fc5ed29a258594fa580b828e997\",\"title\":\"Enhancing Anomaly Detection in Surveillance Videos with Transfer Learning from Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eaf34194a0e86fc5ed29a258594fa580b828e997\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2012.08512\",\"authors\":[{\"authorId\":\"2655351\",\"name\":\"Tarun Kalluri\"},{\"authorId\":\"2004879394\",\"name\":\"Deepak Pathak\"},{\"authorId\":\"1491032137\",\"name\":\"M. Chandraker\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5ca230da787b25643150c8b2df474e2d6d8ec7c9\",\"title\":\"FLAVR: Flow-Agnostic Video Representations for Fast Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/5ca230da787b25643150c8b2df474e2d6d8ec7c9\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2003.08275\",\"authors\":[{\"authorId\":\"13142264\",\"name\":\"Noureldien Hussein\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"144638781\",\"name\":\"A. Smeulders\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2975022cb314045d1471c407454bcdf8b7cb5fef\",\"title\":\"PIC: Permutation Invariant Convolution for Recognizing Long-range Activities\",\"url\":\"https://www.semanticscholar.org/paper/2975022cb314045d1471c407454bcdf8b7cb5fef\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.00826\",\"authors\":[{\"authorId\":null,\"name\":\"Zihao Wang\"},{\"authorId\":\"5739094\",\"name\":\"Chen Lin\"},{\"authorId\":\"1999541581\",\"name\":\"Lu Sheng\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\"},{\"authorId\":\"1388486428\",\"name\":\"Jing Shao\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"316931202b0d02d37672a976f43bb1ed479c6877\",\"title\":\"PV-NAS: Practical Neural Architecture Search for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/316931202b0d02d37672a976f43bb1ed479c6877\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.09435\",\"authors\":[{\"authorId\":\"46270766\",\"name\":\"Zhaoyang Liu\"},{\"authorId\":\"9393671\",\"name\":\"Donghao Luo\"},{\"authorId\":null,\"name\":\"Yabiao Wang\"},{\"authorId\":\"29461006\",\"name\":\"L. Wang\"},{\"authorId\":\"144970872\",\"name\":\"Ying Tai\"},{\"authorId\":\"1978245\",\"name\":\"Chengjie Wang\"},{\"authorId\":\"49298244\",\"name\":\"Jilin Li\"},{\"authorId\":\"1835006\",\"name\":\"Feiyue Huang\"},{\"authorId\":\"144720251\",\"name\":\"Tong Lu\"}],\"doi\":\"10.1609/AAAI.V34I07.6836\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fa3473f1f5d4f19ec6d561e2700a4d88dad4ccf8\",\"title\":\"TEINet: Towards an Efficient Architecture for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fa3473f1f5d4f19ec6d561e2700a4d88dad4ccf8\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1906.03349\",\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"}],\"doi\":\"10.1109/cvpr42600.2020.00043\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"45a924794b2c6501b671cf4249c6ac4fa1671597\",\"title\":\"Video Modeling With Correlation Networks\",\"url\":\"https://www.semanticscholar.org/paper/45a924794b2c6501b671cf4249c6ac4fa1671597\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1905.09979\",\"authors\":[{\"authorId\":\"1391217276\",\"name\":\"Hanhan Li\"},{\"authorId\":\"2340579\",\"name\":\"J. Ng\"},{\"authorId\":\"1820908\",\"name\":\"A. Natsev\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3d8d08ef343035352064fc42c8e7f9531046e597\",\"title\":\"EnsembleNet: End-to-End Optimization of Multi-headed Models\",\"url\":\"https://www.semanticscholar.org/paper/3d8d08ef343035352064fc42c8e7f9531046e597\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1510708346\",\"name\":\"Jianbang Qin\"},{\"authorId\":\"1510665624\",\"name\":\"S. Hu\"},{\"authorId\":\"153301546\",\"name\":\"W. Guo\"}],\"doi\":\"10.1117/12.2559286\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"80f0280a05f10f0d95ceb0bc4c435315acfef5bb\",\"title\":\"Global evaluate-and-rescale network: an efficient model for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/80f0280a05f10f0d95ceb0bc4c435315acfef5bb\",\"venue\":\"International Conference on Machine Vision\",\"year\":2020},{\"arxivId\":\"2009.13782\",\"authors\":[{\"authorId\":\"1577678641\",\"name\":\"Ganesh Samarth\"},{\"authorId\":\"1974345797\",\"name\":\"Sheetal Ojha\"},{\"authorId\":\"96566998\",\"name\":\"N. Pareek\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"29df95ddda4e52ada0564458fe6f438f462b5651\",\"title\":\"Knowledge Fusion Transformers for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/29df95ddda4e52ada0564458fe6f438f462b5651\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12808196\",\"name\":\"I. Naeh\"},{\"authorId\":\"1491911042\",\"name\":\"Roi Pony\"},{\"authorId\":\"1712535\",\"name\":\"Shie Mannor\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf1e40e4628b00ffba63190b1866c41f07e755e5\",\"title\":\"Patternless Adversarial Attacks on Video Recognition Networks\",\"url\":\"https://www.semanticscholar.org/paper/cf1e40e4628b00ffba63190b1866c41f07e755e5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1994488088\",\"name\":\"Lianyu Hu\"},{\"authorId\":\"152150149\",\"name\":\"Lin Feng\"},{\"authorId\":\"8602618\",\"name\":\"Shenglan Liu\"}],\"doi\":\"10.1145/3422844.3423052\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"661a89fbbe1fadc94c145af3a6a1ddb79c7d99a1\",\"title\":\"HFNet: A Novel Model for Human Focused Sports Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/661a89fbbe1fadc94c145af3a6a1ddb79c7d99a1\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49326834\",\"name\":\"Q. Zuo\"},{\"authorId\":\"11857395\",\"name\":\"Lian Zou\"},{\"authorId\":\"73313375\",\"name\":\"Cien Fan\"},{\"authorId\":\"1657188730\",\"name\":\"Dongqian Li\"},{\"authorId\":\"143891653\",\"name\":\"Hao Jiang\"},{\"authorId\":\"47909275\",\"name\":\"Yifeng Liu\"}],\"doi\":\"10.3390/s20247149\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3c29f728df66434210f115cba745d6ec63a772e3\",\"title\":\"Whole and Part Adaptive Fusion Graph Convolutional Networks for Skeleton-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3c29f728df66434210f115cba745d6ec63a772e3\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"2011.12619\",\"authors\":[{\"authorId\":\"147084112\",\"name\":\"Jack Humphreys\"},{\"authorId\":\"48354826\",\"name\":\"Z. Chen\"},{\"authorId\":\"145047838\",\"name\":\"Dacheng Tao\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e88bff50c417703239e0a832fddb267196ab5a99\",\"title\":\"Recent Progress in Appearance-based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e88bff50c417703239e0a832fddb267196ab5a99\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2001.09691\",\"authors\":[{\"authorId\":\"47077615\",\"name\":\"J. Munro\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.1109/ICCVW.2019.00461\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10cf610ca725cdf459f6a4fa68999066b586b93a\",\"title\":\"Multi-Modal Domain Adaptation for Fine-Grained Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/10cf610ca725cdf459f6a4fa68999066b586b93a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"2008.02129\",\"authors\":[{\"authorId\":\"48093158\",\"name\":\"Jinpeng Wang\"},{\"authorId\":\"46396519\",\"name\":\"Yiqi Lin\"},{\"authorId\":\"38624848\",\"name\":\"A. J. Ma\"},{\"authorId\":\"1768574\",\"name\":\"P. Yuen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a4bf06da8592a52d5bc7a52c5fa8d0dca45b9bce\",\"title\":\"Self-supervised Temporal Discriminative Learning for Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/a4bf06da8592a52d5bc7a52c5fa8d0dca45b9bce\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1878475584\",\"name\":\"Xin Gao\"},{\"authorId\":\"1878338267\",\"name\":\"Xusheng Liu\"},{\"authorId\":\"1879512992\",\"name\":\"Taotao Yang\"},{\"authorId\":\"34604525\",\"name\":\"G. Deng\"},{\"authorId\":\"1878360893\",\"name\":\"Hao Peng\"},{\"authorId\":\"1877628045\",\"name\":\"Qiaosong Zhang\"},{\"authorId\":\"97584815\",\"name\":\"H. Li\"},{\"authorId\":\"1879297772\",\"name\":\"Junhui Liu\"}],\"doi\":\"10.1109/ICMEW46912.2020.9106051\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"31e55bc719db796d8022b2c9b1e9285812fb0da8\",\"title\":\"Automatic Key Moment Extraction and Highlights Generation Based on Comprehensive Soccer Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/31e55bc719db796d8022b2c9b1e9285812fb0da8\",\"venue\":\"2020 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"69893872\",\"name\":\"Yuri Yudhaswana Joefrie\"},{\"authorId\":\"96853476\",\"name\":\"Masaki Aono\"}],\"doi\":\"10.1109/ACCESS.2020.3025931\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0ef9affa9c633e1c2713cef266f246c4a0a23821\",\"title\":\"Multi-Label Multi-Class Action Recognition With Deep Spatio-Temporal Layers Based on Temporal Gaussian Mixtures\",\"url\":\"https://www.semanticscholar.org/paper/0ef9affa9c633e1c2713cef266f246c4a0a23821\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7ad2e71a521179599d133f07287a9a36d4019254\",\"title\":\"Learning De-biased Representations with Biased Representations\\u2013 Appendix \\u2013\",\"url\":\"https://www.semanticscholar.org/paper/7ad2e71a521179599d133f07287a9a36d4019254\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2008.11254\",\"authors\":[{\"authorId\":\"49901923\",\"name\":\"Tingting Xie\"},{\"authorId\":\"1694090\",\"name\":\"Christos Tzelepis\"},{\"authorId\":\"50058816\",\"name\":\"I. Patras\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ec7b5f36e8a129521bf46f958cd366aa50a5a46d\",\"title\":\"Temporal Action Localization with Variance-Aware Networks\",\"url\":\"https://www.semanticscholar.org/paper/ec7b5f36e8a129521bf46f958cd366aa50a5a46d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.03044\",\"authors\":[{\"authorId\":\"145545664\",\"name\":\"Y. Yao\"},{\"authorId\":\"47120072\",\"name\":\"Xizi Wang\"},{\"authorId\":\"143847408\",\"name\":\"Mingze Xu\"},{\"authorId\":\"41066643\",\"name\":\"Zelin Pu\"},{\"authorId\":\"153499091\",\"name\":\"E. Atkins\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"9a8be994e7069236d94e30c4c7b481988effc106\",\"title\":\"When, Where, and What? A New Dataset for Anomaly Detection in Driving Videos\",\"url\":\"https://www.semanticscholar.org/paper/9a8be994e7069236d94e30c4c7b481988effc106\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.09355\",\"authors\":[{\"authorId\":\"1486610630\",\"name\":\"Yuyang Qian\"},{\"authorId\":\"1381112251\",\"name\":\"Guojun Yin\"},{\"authorId\":\"84200540\",\"name\":\"Lu Sheng\"},{\"authorId\":\"1500377913\",\"name\":\"Zixuan Chen\"},{\"authorId\":\"1388486428\",\"name\":\"Jing Shao\"}],\"doi\":\"10.1007/978-3-030-58610-2_6\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"63440cd6dad2a3b9241d6b2729f3857f3cadb14e\",\"title\":\"Thinking in Frequency: Face Forgery Detection by Mining Frequency-aware Clues\",\"url\":\"https://www.semanticscholar.org/paper/63440cd6dad2a3b9241d6b2729f3857f3cadb14e\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2006.05091\",\"authors\":[{\"authorId\":\"9734988\",\"name\":\"Yuecong Xu\"},{\"authorId\":\"153420733\",\"name\":\"Haozhi Cao\"},{\"authorId\":\"2562263\",\"name\":\"Jianfei Yang\"},{\"authorId\":\"120974533\",\"name\":\"Kezhi Mao\"},{\"authorId\":\"2037059\",\"name\":\"Jian-Xiong Yin\"},{\"authorId\":\"144308998\",\"name\":\"S. See\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f252cf230c32847099908e4eda9a37c3086fcb8a\",\"title\":\"PNL: Efficient Long-Range Dependencies Extraction with Pyramid Non-Local Module for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f252cf230c32847099908e4eda9a37c3086fcb8a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.05757\",\"authors\":[{\"authorId\":\"48093158\",\"name\":\"Jinpeng Wang\"},{\"authorId\":\"151470972\",\"name\":\"Yuting Gao\"},{\"authorId\":\"104106360\",\"name\":\"Ke Li\"},{\"authorId\":\"2046022\",\"name\":\"X. Jiang\"},{\"authorId\":\"152978186\",\"name\":\"Xiao-wei Guo\"},{\"authorId\":\"1572139630\",\"name\":\"Rongrong Ji\"},{\"authorId\":\"143900241\",\"name\":\"Xing Sun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cfff32dd150ee568384d60708622e2a3917fd6cf\",\"title\":\"Enhancing Unsupervised Video Representation Learning by Decoupling the Scene and the Motion\",\"url\":\"https://www.semanticscholar.org/paper/cfff32dd150ee568384d60708622e2a3917fd6cf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35199438\",\"name\":\"Joshua Gleason\"},{\"authorId\":\"47454520\",\"name\":\"S. Schwarcz\"},{\"authorId\":\"1492122369\",\"name\":\"R. Ranjan\"},{\"authorId\":\"145586343\",\"name\":\"Carlos D. Castillo\"},{\"authorId\":\"1391201966\",\"name\":\"Jun-Cheng Chen\"},{\"authorId\":\"69416958\",\"name\":\"Ramalingam Chellappa\"}],\"doi\":\"10.1109/WACVW50321.2020.9096912\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"789cf1e1e4018b629973f7b4ba8864b71f501518\",\"title\":\"Activity Detection in Untrimmed Videos Using Chunk-based Classifiers\",\"url\":\"https://www.semanticscholar.org/paper/789cf1e1e4018b629973f7b4ba8864b71f501518\",\"venue\":\"2020 IEEE Winter Applications of Computer Vision Workshops (WACVW)\",\"year\":2020},{\"arxivId\":\"2008.07728\",\"authors\":[{\"authorId\":\"46554630\",\"name\":\"L. Yang\"},{\"authorId\":\"39901030\",\"name\":\"Dingwen Zhang\"},{\"authorId\":null,\"name\":\"Tao Zhao\"},{\"authorId\":\"122200133\",\"name\":\"J. Han\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1c065821de73b6bb87a2a2376134ac9c28008486\",\"title\":\"Equivalent Classification Mapping for Weakly Supervised Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/1c065821de73b6bb87a2a2376134ac9c28008486\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.05596\",\"authors\":[{\"authorId\":\"50112310\",\"name\":\"Alex Andonian\"},{\"authorId\":\"1482544048\",\"name\":\"Camilo Fosco\"},{\"authorId\":\"95743023\",\"name\":\"Mathew Monfort\"},{\"authorId\":\"123872529\",\"name\":\"Allen Lee\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"}],\"doi\":\"10.1007/978-3-030-58523-5_2\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"33c723f096c3fd156e32295325afc2e6081afac4\",\"title\":\"We Have So Much In Common: Modeling Semantic Relational Set Abstractions in Videos\",\"url\":\"https://www.semanticscholar.org/paper/33c723f096c3fd156e32295325afc2e6081afac4\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2004.04730\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"}],\"doi\":\"10.1109/cvpr42600.2020.00028\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"908cca0abefc35acc38033603714fbb1bcadc49d\",\"title\":\"X3D: Expanding Architectures for Efficient Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/908cca0abefc35acc38033603714fbb1bcadc49d\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2006.00830\",\"authors\":[{\"authorId\":\"34678431\",\"name\":\"F. Sener\"},{\"authorId\":\"1734802895\",\"name\":\"Dipika Singhania\"},{\"authorId\":\"1803321310\",\"name\":\"Angela Yao\"}],\"doi\":\"10.1007/978-3-030-58517-4_10\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6c8f191fa7b5c51af0810b0996a0ef25b4db4d9a\",\"title\":\"Temporal Aggregate Representations for Long-Range Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/6c8f191fa7b5c51af0810b0996a0ef25b4db4d9a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.03263\",\"authors\":[{\"authorId\":\"93242167\",\"name\":\"Lei Shi\"},{\"authorId\":\"48380079\",\"name\":\"Yi-Fan Zhang\"},{\"authorId\":\"48265260\",\"name\":\"Jian Cheng\"},{\"authorId\":\"1699900\",\"name\":\"H. Lu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"df131f9d1fa5570192a5a3c040fe42ebe4bdfe5f\",\"title\":\"Decoupled Spatial-Temporal Attention Network for Skeleton-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/df131f9d1fa5570192a5a3c040fe42ebe4bdfe5f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.15244\",\"authors\":[{\"authorId\":\"1841089935\",\"name\":\"Mahdi Davoodikakhki\"},{\"authorId\":\"153505292\",\"name\":\"KangKang Yin\"}],\"doi\":\"10.1007/978-3-030-64556-4_23\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0359520036f33beea638b979d515c170420ac37b\",\"title\":\"Hierarchical Action Classification with Network Pruning\",\"url\":\"https://www.semanticscholar.org/paper/0359520036f33beea638b979d515c170420ac37b\",\"venue\":\"ISVC\",\"year\":2020},{\"arxivId\":\"2009.09818\",\"authors\":[{\"authorId\":\"145098776\",\"name\":\"Umar Asif\"},{\"authorId\":\"2363364\",\"name\":\"D. Mehta\"},{\"authorId\":\"2103918\",\"name\":\"Stefan von Cavallar\"},{\"authorId\":\"2328282\",\"name\":\"J. Tang\"},{\"authorId\":\"40639323\",\"name\":\"S. Harrer\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f64c5330704d9d0909044fb653313c23e4a02ef\",\"title\":\"DeepActsNet: Spatial and Motion features from Face, Hands, and Body Combined with Convolutional and Graph Networks for Improved Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/0f64c5330704d9d0909044fb653313c23e4a02ef\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145350413\",\"name\":\"Zijian Kang\"},{\"authorId\":\"48169980\",\"name\":\"L. Wang\"},{\"authorId\":\"9071789\",\"name\":\"Z. Liu\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"}],\"doi\":\"10.1007/978-3-030-19823-7_15\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d3ce1869ac6627e79643ac64a8ae7b2358cbe58a\",\"title\":\"Extracting Action Sensitive Features to Facilitate Weakly-Supervised Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/d3ce1869ac6627e79643ac64a8ae7b2358cbe58a\",\"venue\":\"AIAI\",\"year\":2019},{\"arxivId\":\"1909.10695\",\"authors\":[{\"authorId\":\"51310352\",\"name\":\"Philipp V. Rouast\"},{\"authorId\":\"24235135\",\"name\":\"M. Adam\"}],\"doi\":\"10.1109/JBHI.2019.2942845\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"61b86a3b0c3dd290d2a6a67a335e4473ff69f92b\",\"title\":\"Learning Deep Representations for Video-Based Intake Gesture Detection\",\"url\":\"https://www.semanticscholar.org/paper/61b86a3b0c3dd290d2a6a67a335e4473ff69f92b\",\"venue\":\"IEEE Journal of Biomedical and Health Informatics\",\"year\":2020},{\"arxivId\":\"1905.13388\",\"authors\":[{\"authorId\":\"46506975\",\"name\":\"Haonan Wang\"},{\"authorId\":\"145394369\",\"name\":\"J. Lin\"},{\"authorId\":\"2539310\",\"name\":\"Z. Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"56563001d7a177bdd4ddf332a2a9cdad858ee3a7\",\"title\":\"Design Light-weight 3D Convolutional Networks for Video Recognition Temporal Residual, Fully Separable Block, and Fast Algorithm\",\"url\":\"https://www.semanticscholar.org/paper/56563001d7a177bdd4ddf332a2a9cdad858ee3a7\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153023158\",\"name\":\"Z. Zhao\"},{\"authorId\":\"49901469\",\"name\":\"G. Chen\"},{\"authorId\":\"49750905\",\"name\":\"Chong Chen\"},{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"51470719\",\"name\":\"Xuanlu Xiang\"},{\"authorId\":\"49339105\",\"name\":\"Yanyun Zhao\"},{\"authorId\":\"152343380\",\"name\":\"Fei Su\"}],\"doi\":\"10.1109/ICCVW.2019.00234\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9a841017d4da8382841d1216ebeed8605bfaafaf\",\"title\":\"Instance-Based Video Search via Multi-Task Retrieval and Re-Ranking\",\"url\":\"https://www.semanticscholar.org/paper/9a841017d4da8382841d1216ebeed8605bfaafaf\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1910.08250\",\"authors\":[{\"authorId\":\"2724075\",\"name\":\"Yiping Tang\"},{\"authorId\":\"51431831\",\"name\":\"Chuang Niu\"},{\"authorId\":\"35182090\",\"name\":\"Minghao Dong\"},{\"authorId\":\"10648494\",\"name\":\"Shenghan Ren\"},{\"authorId\":\"145157018\",\"name\":\"J. Liang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6bfb4ef35fd5e9820e23e130aff6c09aa2c6b75c\",\"title\":\"AFO-TAD: Anchor-free One-Stage Detector for Temporal Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/6bfb4ef35fd5e9820e23e130aff6c09aa2c6b75c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27494261\",\"name\":\"Daniel F. S. Santos\"},{\"authorId\":\"32376689\",\"name\":\"R. Pires\"},{\"authorId\":\"1381521917\",\"name\":\"D. Colombo\"},{\"authorId\":\"2029362801\",\"name\":\"Jo\\u00e3o P. Pap\"}],\"doi\":\"10.1109/SIBGRAPI51738.2020.00023\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4fa54a18ea5c98bfcc402f295efc846a91adaf9f\",\"title\":\"Scene Change Detection Using Multiscale Cascade Residual Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/4fa54a18ea5c98bfcc402f295efc846a91adaf9f\",\"venue\":\"2020 33rd SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)\",\"year\":2020},{\"arxivId\":\"2012.05342\",\"authors\":[{\"authorId\":\"145580092\",\"name\":\"Pierre-Etienne Martin\"},{\"authorId\":\"1401651727\",\"name\":\"J. Benois-Pineau\"},{\"authorId\":\"1639895183\",\"name\":\"Renaud P\\u00e9teri\"},{\"authorId\":\"1639983772\",\"name\":\"Julien Morlier\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4c6b7bc12da85925efeb297cadf0a47c6c6ec7ea\",\"title\":\"3D attention mechanism for fine-grained classification of table tennis strokes using a Twin Spatio-Temporal Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/4c6b7bc12da85925efeb297cadf0a47c6c6ec7ea\",\"venue\":\"\",\"year\":2021},{\"arxivId\":\"1910.02806\",\"authors\":[{\"authorId\":\"41019737\",\"name\":\"Hyojin Bahng\"},{\"authorId\":\"2647582\",\"name\":\"Sanghyuk Chun\"},{\"authorId\":\"2151587\",\"name\":\"Sangdoo Yun\"},{\"authorId\":\"1795455\",\"name\":\"J. Choo\"},{\"authorId\":\"2390510\",\"name\":\"Seong Joon Oh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f4f3f946498e8af471596f89dde2168f87cc9861\",\"title\":\"Learning De-biased Representations with Biased Representations\",\"url\":\"https://www.semanticscholar.org/paper/f4f3f946498e8af471596f89dde2168f87cc9861\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":\"2008.03800\",\"authors\":[{\"authorId\":\"47519958\",\"name\":\"Rui Qian\"},{\"authorId\":\"1486442460\",\"name\":\"Tianjian Meng\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"3154495\",\"name\":\"H. Wang\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"1387716705\",\"name\":\"Yin Cui\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1f3a9a431dc5bf813455ac89df5c0a4e747bc553\",\"title\":\"Spatiotemporal Contrastive Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/1f3a9a431dc5bf813455ac89df5c0a4e747bc553\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2007.13278\",\"authors\":[{\"authorId\":\"40482726\",\"name\":\"R. Devon Hjelm\"},{\"authorId\":\"143902541\",\"name\":\"Philip Bachman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"04ea5fe569cd48c588b7fe420965016ed4ddd312\",\"title\":\"Representation Learning with Video Deep InfoMax\",\"url\":\"https://www.semanticscholar.org/paper/04ea5fe569cd48c588b7fe420965016ed4ddd312\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1912.04487\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":\"10.1109/cvpr42600.2020.01047\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c4128ba8deeb67e731cf52fb98addcfddd487e55\",\"title\":\"Listen to Look: Action Recognition by Previewing Audio\",\"url\":\"https://www.semanticscholar.org/paper/c4128ba8deeb67e731cf52fb98addcfddd487e55\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2007.11365\",\"authors\":[{\"authorId\":\"39440469\",\"name\":\"Sudhakar Kumawat\"},{\"authorId\":\"145879750\",\"name\":\"Manisha Verma\"},{\"authorId\":\"1789677\",\"name\":\"Yuta Nakashima\"},{\"authorId\":\"145853779\",\"name\":\"S. Raman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4914a205aa1ddeaae3c86a449c69703c89484f54\",\"title\":\"Depthwise Spatio-Temporal STFT Convolutional Neural Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4914a205aa1ddeaae3c86a449c69703c89484f54\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.08042\",\"authors\":[{\"authorId\":\"66562585\",\"name\":\"Xu Li\"},{\"authorId\":\"46584062\",\"name\":\"Junling Wang\"},{\"authorId\":\"152309767\",\"name\":\"L. Ma\"},{\"authorId\":\"3397429\",\"name\":\"K. Zhang\"},{\"authorId\":\"1568961008\",\"name\":\"Fengzong Lian\"},{\"authorId\":\"2705857\",\"name\":\"Zhanhui Kang\"},{\"authorId\":\"71563118\",\"name\":\"Jinjun Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"786a010cb738fe28bb44fcff790966a380c9da56\",\"title\":\"STH: Spatio-Temporal Hybrid Convolution for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/786a010cb738fe28bb44fcff790966a380c9da56\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144125487\",\"name\":\"Hefei Ling\"},{\"authorId\":\"51066371\",\"name\":\"Yuli Chen\"},{\"authorId\":\"1722881\",\"name\":\"Jiazhong Chen\"},{\"authorId\":\"47767769\",\"name\":\"Lei Wu\"},{\"authorId\":\"1753219181\",\"name\":\"Yuxuan Shi\"},{\"authorId\":\"144401327\",\"name\":\"Jing Deng\"}],\"doi\":\"10.1007/s11042-020-09137-5\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"08a34d85465a3ee611d8bc48ae3083f578f6833d\",\"title\":\"XwiseNet: action recognition with Xwise separable convolutions\",\"url\":\"https://www.semanticscholar.org/paper/08a34d85465a3ee611d8bc48ae3083f578f6833d\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"2005.00214\",\"authors\":[{\"authorId\":\"145476833\",\"name\":\"Ang Li\"},{\"authorId\":\"1683048870\",\"name\":\"Meghana Thotakuri\"},{\"authorId\":\"144711958\",\"name\":\"D. Ross\"},{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"98379559\",\"name\":\"Alexander Vostrikov\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d84e7557bdcf540484ba305e1a06ad2d18ab2c38\",\"title\":\"The AVA-Kinetics Localized Human Actions Video Dataset\",\"url\":\"https://www.semanticscholar.org/paper/d84e7557bdcf540484ba305e1a06ad2d18ab2c38\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.14501\",\"authors\":[{\"authorId\":\"40949052\",\"name\":\"Aashaka Shah\"},{\"authorId\":\"100880679\",\"name\":\"Chao-Yuan Wu\"},{\"authorId\":\"145583247\",\"name\":\"J. Mohan\"},{\"authorId\":\"2002462\",\"name\":\"Vijay Chidambaram\"},{\"authorId\":\"51506875\",\"name\":\"Philipp Krahenbuhl\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b5697ed0c72b318d291545871fbd3a7a6e59e3cf\",\"title\":\"Memory Optimization for Deep Networks\",\"url\":\"https://www.semanticscholar.org/paper/b5697ed0c72b318d291545871fbd3a7a6e59e3cf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31378310\",\"name\":\"Mengtian Li\"},{\"authorId\":null,\"name\":\"Yu-Xiong Wang\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b35fb87d2b4b5ccc4d9a7cf4ef4b73672ce2f4e0\",\"title\":\"Towards Streaming Image Understanding\",\"url\":\"https://www.semanticscholar.org/paper/b35fb87d2b4b5ccc4d9a7cf4ef4b73672ce2f4e0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9230423\",\"name\":\"Guangyi Chen\"},{\"authorId\":\"39358728\",\"name\":\"Yongming Rao\"},{\"authorId\":\"100475213\",\"name\":\"Jiwen Lu\"},{\"authorId\":\"49178343\",\"name\":\"Jie Zhou\"}],\"doi\":\"10.1007/978-3-030-58598-3_39\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4e479987696bcb229cb4779b896187bc0d3497e2\",\"title\":\"Temporal Coherence or Temporal Motion: Which Is More Critical for Video-Based Person Re-identification?\",\"url\":\"https://www.semanticscholar.org/paper/4e479987696bcb229cb4779b896187bc0d3497e2\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5998740\",\"name\":\"T. Wang\"},{\"authorId\":\"145906066\",\"name\":\"Yang Chen\"},{\"authorId\":\"47896919\",\"name\":\"Hongqiang Lv\"},{\"authorId\":\"1680217\",\"name\":\"Jing Teng\"},{\"authorId\":\"2103629\",\"name\":\"H. Snoussi\"},{\"authorId\":\"152412578\",\"name\":\"Fei Tao\"}],\"doi\":\"10.1109/TII.2020.2997032\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c33b896f43e41d3cf04fc8ad53f88de985666107\",\"title\":\"Online Detection of Action Start via Soft Computing for Smart City\",\"url\":\"https://www.semanticscholar.org/paper/c33b896f43e41d3cf04fc8ad53f88de985666107\",\"venue\":\"IEEE Transactions on Industrial Informatics\",\"year\":2021},{\"arxivId\":\"2002.05907\",\"authors\":[{\"authorId\":\"153108483\",\"name\":\"Bin Ren\"},{\"authorId\":\"47842072\",\"name\":\"M. Liu\"},{\"authorId\":\"2705961\",\"name\":\"R. Ding\"},{\"authorId\":\"10114692\",\"name\":\"Hong Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0a8196cd5905812dbdfb87096bcb7d2433ede93e\",\"title\":\"A Survey on 3D Skeleton-Based Action Recognition Using Learning Method\",\"url\":\"https://www.semanticscholar.org/paper/0a8196cd5905812dbdfb87096bcb7d2433ede93e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1918589313\",\"name\":\"Lingfeng Li\"},{\"authorId\":\"40010600\",\"name\":\"Richard A. Paris\"},{\"authorId\":\"1922323687\",\"name\":\"Conner Pinson\"},{\"authorId\":null,\"name\":\"Yan Wang\"},{\"authorId\":\"3010164\",\"name\":\"Joseph Coco\"},{\"authorId\":\"1922029122\",\"name\":\"Jamison Heard\"},{\"authorId\":\"153936924\",\"name\":\"J. A. Adams\"},{\"authorId\":\"3025858\",\"name\":\"D. Fabbri\"},{\"authorId\":\"143941893\",\"name\":\"B. Bodenheimer\"}],\"doi\":\"10.1109/EMBC44109.2020.9175575\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0ebb650bd269143962e6d1824989a02277c481ba\",\"title\":\"Emergency Clinical Procedure Detection With Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/0ebb650bd269143962e6d1824989a02277c481ba\",\"venue\":\"2020 42nd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2000153057\",\"name\":\"Zhikang Qiu\"},{\"authorId\":null,\"name\":\"Xu Zhao\"},{\"authorId\":\"49941675\",\"name\":\"Zhilan Hu\"}],\"doi\":\"10.1109/ICIP40778.2020.9190997\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"593fa71e5cad2afcc4b105c45d5ee4eae101bf54\",\"title\":\"Efficient Temporal-Spatial Feature Grouping For Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/593fa71e5cad2afcc4b105c45d5ee4eae101bf54\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"2006.13256\",\"authors\":[{\"authorId\":\"1677780022\",\"name\":\"Dima Damen\"},{\"authorId\":\"28798386\",\"name\":\"H. Doughty\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"},{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"48842721\",\"name\":\"Evangelos Kazakos\"},{\"authorId\":\"153155867\",\"name\":\"Jian Ma\"},{\"authorId\":\"3420479\",\"name\":\"D. Moltisanti\"},{\"authorId\":\"47077615\",\"name\":\"J. Munro\"},{\"authorId\":\"2682004\",\"name\":\"T. Perrett\"},{\"authorId\":\"50065546\",\"name\":\"W. Price\"},{\"authorId\":\"145032628\",\"name\":\"Michael Wray\"}],\"doi\":\"10.5523/bris.2g1n6qdydwa9u22shpxqzp0t8m\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6c1a80daadab9c3bc3fdf183c669070ba7a3fd37\",\"title\":\"Rescaling Egocentric Vision\",\"url\":\"https://www.semanticscholar.org/paper/6c1a80daadab9c3bc3fdf183c669070ba7a3fd37\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.00649\",\"authors\":[{\"authorId\":\"48444479\",\"name\":\"Hao Chen\"},{\"authorId\":\"51453757\",\"name\":\"Abhinav Shrivastava\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1755381c55d8e52e3a72b3f065a5380874597af1\",\"title\":\"Group Ensemble: Learning an Ensemble of ConvNets in a single ConvNet\",\"url\":\"https://www.semanticscholar.org/paper/1755381c55d8e52e3a72b3f065a5380874597af1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.00200\",\"authors\":[{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"2378902\",\"name\":\"Yen-Chun Chen\"},{\"authorId\":\"1664725279\",\"name\":\"Yu Cheng\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1520007550\",\"name\":\"Jingjing Liu\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.161\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6961065a16f6c3db4879cfad5875d11ce75e6b2f\",\"title\":\"HERO: Hierarchical Encoder for Video+Language Omni-representation Pre-training\",\"url\":\"https://www.semanticscholar.org/paper/6961065a16f6c3db4879cfad5875d11ce75e6b2f\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2006.15473\",\"authors\":[{\"authorId\":\"4962557\",\"name\":\"L. Trinh\"},{\"authorId\":\"49130616\",\"name\":\"M. Tsang\"},{\"authorId\":\"2267664\",\"name\":\"Sirisha Rambhatla\"},{\"authorId\":\"49422024\",\"name\":\"Y. Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f797892f9270eca7fd63dc9681cfbfe398baf378\",\"title\":\"Interpretable Deepfake Detection via Dynamic Prototypes\",\"url\":\"https://www.semanticscholar.org/paper/f797892f9270eca7fd63dc9681cfbfe398baf378\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.14950\",\"authors\":[{\"authorId\":\"26959701\",\"name\":\"Hengduo Li\"},{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":null,\"name\":\"Abhinav Shrivastava\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f434d65e76041d3417715791e052255f924d4efc\",\"title\":\"2D or not 2D? Adaptive 3D Convolution Selection for Efficient Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f434d65e76041d3417715791e052255f924d4efc\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":null,\"name\":\"Gedas Bertasius\"},{\"authorId\":null,\"name\":\"Tae-Hyun Oh\"},{\"authorId\":null,\"name\":\"Abhinav Gupta\"},{\"authorId\":null,\"name\":\"Minh Hoai\"},{\"authorId\":null,\"name\":\"Lorenzo Torresani\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"86a9e09459c5a4e436706d0b89f951d780e80a71\",\"title\":\"Supervoxel Attention Graphs for Long-Range Video Modeling\",\"url\":\"https://www.semanticscholar.org/paper/86a9e09459c5a4e436706d0b89f951d780e80a71\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"2008.01232\",\"authors\":[{\"authorId\":\"1395788009\",\"name\":\"M. E. Kalfaoglu\"},{\"authorId\":\"1699609\",\"name\":\"Sinan Kalkan\"},{\"authorId\":\"1751998\",\"name\":\"Aydin Alatan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"dce965db955113b3710c9977dc5f68f3bfd85c4b\",\"title\":\"Late Temporal Modeling in 3D CNN Architectures with BERT for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/dce965db955113b3710c9977dc5f68f3bfd85c4b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.02711\",\"authors\":[{\"authorId\":\"152504322\",\"name\":\"Dezhao Luo\"},{\"authorId\":\"153841261\",\"name\":\"Bo Fang\"},{\"authorId\":\"9113781\",\"name\":\"Yin-qing Zhou\"},{\"authorId\":\"2803189\",\"name\":\"Yucan Zhou\"},{\"authorId\":\"11000953\",\"name\":\"D. Wu\"},{\"authorId\":\"1956868\",\"name\":\"Weiping Wang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ec47ea8667ec60f21ead4e4bd9e286ef28e484f3\",\"title\":\"Exploring Relations in Untrimmed Videos for Self-Supervised Learning\",\"url\":\"https://www.semanticscholar.org/paper/ec47ea8667ec60f21ead4e4bd9e286ef28e484f3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.05614\",\"authors\":[{\"authorId\":\"34280810\",\"name\":\"Gunnar A. Sigurdsson\"},{\"authorId\":null,\"name\":\"Abhinav Gupta\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"72492981\",\"name\":\"Alahari Karteek\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"594163df647890f47e6ab0b0b426363f7175c9a0\",\"title\":\"Beyond the Camera: Neural Networks in World Coordinates\",\"url\":\"https://www.semanticscholar.org/paper/594163df647890f47e6ab0b0b426363f7175c9a0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.09709\",\"authors\":[{\"authorId\":\"22237490\",\"name\":\"Tengda Han\"},{\"authorId\":\"10096695\",\"name\":\"Weidi Xie\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"88f440120730e21b07bbd188b2a04787a3208861\",\"title\":\"Self-supervised Co-training for Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/88f440120730e21b07bbd188b2a04787a3208861\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2004228925\",\"name\":\"Jinhao Duan\"},{\"authorId\":\"40463478\",\"name\":\"H. Xu\"},{\"authorId\":\"48030229\",\"name\":\"Xiaozhu Lin\"},{\"authorId\":\"2004346653\",\"name\":\"Shangchao Zhu\"},{\"authorId\":\"115394762\",\"name\":\"Y. Du\"}],\"doi\":\"10.1016/j.imavis.2020.103988\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"68e1892f95de0a982571c0c5df1c12c42364ee11\",\"title\":\"Multi-semantic long-range dependencies capturing for efficient video representation learning\",\"url\":\"https://www.semanticscholar.org/paper/68e1892f95de0a982571c0c5df1c12c42364ee11\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40951853\",\"name\":\"Manyuan Zhang\"},{\"authorId\":\"46798949\",\"name\":\"H. Shao\"},{\"authorId\":\"12920342\",\"name\":\"Guanglu Song\"},{\"authorId\":\"119924269\",\"name\":\"Y. Liu\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8703832cf993aa86b6c6eb48c1d7f76cbacfcb7a\",\"title\":\"Team Efficient Multi-Moments in Time Challenge 2019 Technical Report\",\"url\":\"https://www.semanticscholar.org/paper/8703832cf993aa86b6c6eb48c1d7f76cbacfcb7a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2006.07526\",\"authors\":[{\"authorId\":\"1726109879\",\"name\":\"Xiang Wang\"},{\"authorId\":\"1749563254\",\"name\":\"Baiteng Ma\"},{\"authorId\":\"1750375688\",\"name\":\"Zhiwu Qing\"},{\"authorId\":\"1749375503\",\"name\":\"Yongpeng Sang\"},{\"authorId\":\"40115662\",\"name\":\"Changxin Gao\"},{\"authorId\":\"50202110\",\"name\":\"Shiwei Zhang\"},{\"authorId\":\"1707161\",\"name\":\"N. Sang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"306b6a6bf831b204e8b4f63ba9717504b1d17f7f\",\"title\":\"CBR-Net: Cascade Boundary Refinement Network for Action Detection: Submission to ActivityNet Challenge 2020 (Task 1)\",\"url\":\"https://www.semanticscholar.org/paper/306b6a6bf831b204e8b4f63ba9717504b1d17f7f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1912.04465\",\"authors\":[{\"authorId\":\"50262695\",\"name\":\"Y. Jiang\"},{\"authorId\":\"1389284356\",\"name\":\"Kaixu Cui\"},{\"authorId\":\"1500377539\",\"name\":\"Leilei Chen\"},{\"authorId\":\"152745066\",\"name\":\"Can-jin Wang\"},{\"authorId\":\"48258796\",\"name\":\"C. Xu\"}],\"doi\":\"10.1145/3422844.3423051\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"189895b7f56f39d9e4ae5edf85eda866dd0412ff\",\"title\":\"SoccerDB: A Large-Scale Database for Comprehensive Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/189895b7f56f39d9e4ae5edf85eda866dd0412ff\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144406781\",\"name\":\"Lijun He\"},{\"authorId\":\"2035803194\",\"name\":\"Shuai Wen\"},{\"authorId\":\"2199437\",\"name\":\"L. Wang\"},{\"authorId\":\"1825677658\",\"name\":\"Fan Li\"}],\"doi\":\"10.1007/s10489-020-01933-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb68cda0fdd2e9fec857ff8016b3a74912ceb57e\",\"title\":\"Vehicle theft recognition from surveillance video based on spatiotemporal attention\",\"url\":\"https://www.semanticscholar.org/paper/eb68cda0fdd2e9fec857ff8016b3a74912ceb57e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993592720\",\"name\":\"Zhaobo Qi\"},{\"authorId\":\"47672591\",\"name\":\"Shuhui Wang\"},{\"authorId\":\"145422145\",\"name\":\"Chi Su\"},{\"authorId\":\"153142919\",\"name\":\"Li Su\"},{\"authorId\":\"46246550\",\"name\":\"W. Zhang\"},{\"authorId\":\"153159021\",\"name\":\"Qingming Huang\"}],\"doi\":\"10.1145/3394171.3413618\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1f26caf22fd05659802db690c7e6c9db289be340\",\"title\":\"Modeling Temporal Concept Receptive Field Dynamically for Untrimmed Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/1f26caf22fd05659802db690c7e6c9db289be340\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2007.09861\",\"authors\":[{\"authorId\":\"9096071\",\"name\":\"Jianchao Wu\"},{\"authorId\":\"1874900\",\"name\":\"Zhanghui Kuang\"},{\"authorId\":\"48170161\",\"name\":\"L. Wang\"},{\"authorId\":\"1726357\",\"name\":\"Wayne Zhang\"},{\"authorId\":\"39914710\",\"name\":\"Gangshan Wu\"}],\"doi\":\"10.1007/978-3-030-58595-2_27\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"cf0bc1e97049ece897db97ba605594a89df50c34\",\"title\":\"Context-Aware RCNN: A Baseline for Action Detection in Videos\",\"url\":\"https://www.semanticscholar.org/paper/cf0bc1e97049ece897db97ba605594a89df50c34\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2010051\",\"name\":\"D. Schmorrow\"},{\"authorId\":\"47963528\",\"name\":\"Cali Fidopiastis\"},{\"authorId\":\"145960032\",\"name\":\"R. Goebel\"},{\"authorId\":\"144865865\",\"name\":\"Y. Tanaka\"}],\"doi\":\"10.1007/978-3-030-50439-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0c6a4525a6e75bb9bfa9fb117de1ca4893981412\",\"title\":\"Augmented Cognition. Human Cognition and Behavior: 14th International Conference, AC 2020, Held as Part of the 22nd HCI International Conference, HCII 2020, Copenhagen, Denmark, July 19\\u201324, 2020, Proceedings, Part II\",\"url\":\"https://www.semanticscholar.org/paper/0c6a4525a6e75bb9bfa9fb117de1ca4893981412\",\"venue\":\"HCI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"144746444\",\"name\":\"H. Bischof\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"},{\"authorId\":\"40454588\",\"name\":\"J. Frahm\"}],\"doi\":\"10.1007/978-3-030-58539-6\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"72eb837c0d113dcdd51e57958e58d48e1759ea0f\",\"title\":\"Computer Vision \\u2013 ECCV 2020: 16th European Conference, Glasgow, UK, August 23\\u201328, 2020, Proceedings, Part VI\",\"url\":\"https://www.semanticscholar.org/paper/72eb837c0d113dcdd51e57958e58d48e1759ea0f\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2008.08072\",\"authors\":[{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"},{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"3462309\",\"name\":\"Juhana Kangaspunta\"},{\"authorId\":\"2148510\",\"name\":\"A. Angelova\"}],\"doi\":\"10.1007/978-3-030-58565-5_39\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a156594c076a8f0e073e5656ae8e3311212d2422\",\"title\":\"AssembleNet++: Assembling Modality Representations via Attention Connections\",\"url\":\"https://www.semanticscholar.org/paper/a156594c076a8f0e073e5656ae8e3311212d2422\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2006.15489\",\"authors\":[{\"authorId\":\"49984891\",\"name\":\"Ceyuan Yang\"},{\"authorId\":\"121983635\",\"name\":\"Yinghao Xu\"},{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3cb65b26e407e7464223e9568010965fe73ae61f\",\"title\":\"Video Representation Learning with Visual Tempo Consistency\",\"url\":\"https://www.semanticscholar.org/paper/3cb65b26e407e7464223e9568010965fe73ae61f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1906.07052\",\"authors\":[{\"authorId\":\"31415725\",\"name\":\"Chen-Lin Zhang\"},{\"authorId\":\"49543907\",\"name\":\"Xin-Xin Liu\"},{\"authorId\":\"49388002\",\"name\":\"Jianxin Wu\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ed2fd4d36340c61e4af9ff6fbf33c336c45458f1\",\"title\":\"Towards Real-Time Action Recognition on Mobile Devices Using Deep Models\",\"url\":\"https://www.semanticscholar.org/paper/ed2fd4d36340c61e4af9ff6fbf33c336c45458f1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1909.09422\",\"authors\":[{\"authorId\":\"50065546\",\"name\":\"W. Price\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.1109/ICCVW.2019.00173\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3c0cf56b33fdca7529ec5bc308060e307c9ae1bc\",\"title\":\"Retro-Actions: Learning 'Close' by Time-Reversing 'Open' Videos\",\"url\":\"https://www.semanticscholar.org/paper/3c0cf56b33fdca7529ec5bc308060e307c9ae1bc\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"2011.09530\",\"authors\":[{\"authorId\":\"153769937\",\"name\":\"H. Akbari\"},{\"authorId\":\"2542427\",\"name\":\"H. Palangi\"},{\"authorId\":\"120157163\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"1845230025\",\"name\":\"Sudha Rao\"},{\"authorId\":\"1709797\",\"name\":\"A. \\u00c7elikyilmaz\"},{\"authorId\":\"37409035\",\"name\":\"R. Fernandez\"},{\"authorId\":\"1748557\",\"name\":\"P. Smolensky\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"72197815\",\"name\":\"Shih-Fu Chang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c2b4d96db34bd472e84c9234838cc4e808eb1ba9\",\"title\":\"Neuro-Symbolic Representations for Video Captioning: A Case for Leveraging Inductive Biases for Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/c2b4d96db34bd472e84c9234838cc4e808eb1ba9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.02426\",\"authors\":[{\"authorId\":\"1879292723\",\"name\":\"Junwei Liang\"},{\"authorId\":\"48749954\",\"name\":\"L. Cao\"},{\"authorId\":\"3182065\",\"name\":\"Xuehan Xiong\"},{\"authorId\":\"2029317446\",\"name\":\"Ting Yu\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e84c8a5b818d6c121083550bae9bda257a4df60f\",\"title\":\"Spatial-Temporal Alignment Network for Action Recognition and Detection\",\"url\":\"https://www.semanticscholar.org/paper/e84c8a5b818d6c121083550bae9bda257a4df60f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151472652\",\"name\":\"Yuqi Huo\"},{\"authorId\":\"101246507\",\"name\":\"Xiaoli Xu\"},{\"authorId\":\"46215480\",\"name\":\"Yao Lu\"},{\"authorId\":\"2520427\",\"name\":\"Yulei Niu\"},{\"authorId\":\"48876151\",\"name\":\"Mingyu Ding\"},{\"authorId\":\"1776220\",\"name\":\"Zhiwu Lu\"},{\"authorId\":\"145406420\",\"name\":\"Tao Xiang\"},{\"authorId\":\"153693432\",\"name\":\"Jirong Wen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"89fafbe91b31d43dc3314ffabffa79a5f5ad746f\",\"title\":\"Lightweight Action Recognition in Compressed Videos\",\"url\":\"https://www.semanticscholar.org/paper/89fafbe91b31d43dc3314ffabffa79a5f5ad746f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46324934\",\"name\":\"Qi-jun Zhang\"},{\"authorId\":\"47277292\",\"name\":\"S. Fu\"},{\"authorId\":\"48109180\",\"name\":\"Dan Li\"}],\"doi\":\"10.1109/WSAI49636.2020.9143282\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7d431177d56f24cc7792db89b18878a0f3683fe7\",\"title\":\"Nonlinear Activation in Deep Residual Networks\",\"url\":\"https://www.semanticscholar.org/paper/7d431177d56f24cc7792db89b18878a0f3683fe7\",\"venue\":\"2020 2nd World Symposium on Artificial Intelligence (WSAI)\",\"year\":2020},{\"arxivId\":\"2004.04851\",\"authors\":[{\"authorId\":\"2068427\",\"name\":\"Ankan Bansal\"},{\"authorId\":\"3403576\",\"name\":\"Sai Saketh Rambhatla\"},{\"authorId\":\"51453757\",\"name\":\"Abhinav Shrivastava\"},{\"authorId\":\"9215658\",\"name\":\"R. Chellappa\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"61c9cb51312aa890a3ad1f3a4f53ae048ecaa216\",\"title\":\"Spatial Priming for Detecting Human-Object Interactions\",\"url\":\"https://www.semanticscholar.org/paper/61c9cb51312aa890a3ad1f3a4f53ae048ecaa216\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.14585\",\"authors\":[{\"authorId\":\"66946727\",\"name\":\"Jaehui Hwang\"},{\"authorId\":\"3098768\",\"name\":\"Junhyuk Kim\"},{\"authorId\":\"1704860\",\"name\":\"J. Choi\"},{\"authorId\":\"11623715\",\"name\":\"J. Lee\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"60a4fc6dc28ab47f517c53fb7440995a0a932505\",\"title\":\"Just One Moment: Inconspicuous One Frame Attack on Deep Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/60a4fc6dc28ab47f517c53fb7440995a0a932505\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32346302\",\"name\":\"F. Wang\"},{\"authorId\":\"1423415979\",\"name\":\"Guorui Wang\"},{\"authorId\":\"100975725\",\"name\":\"Yunwen Huang\"},{\"authorId\":\"49276987\",\"name\":\"Hao Chu\"}],\"doi\":\"10.1109/ACCESS.2019.2953113\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"65d934938c27585e144660ae7c293d297dddf64b\",\"title\":\"SAST: Learning Semantic Action-Aware Spatial-Temporal Features for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/65d934938c27585e144660ae7c293d297dddf64b\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145496509\",\"name\":\"Jie Shao\"},{\"authorId\":\"143993120\",\"name\":\"K. Hu\"},{\"authorId\":\"3393850\",\"name\":\"Yixin Bao\"},{\"authorId\":\"11320042\",\"name\":\"Yining Lin\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5b3fd234bd072706af99100edba037b13d5a0069\",\"title\":\"High Order Neural Networks for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/5b3fd234bd072706af99100edba037b13d5a0069\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2001.08740\",\"authors\":[{\"authorId\":\"2299381\",\"name\":\"Fanyi Xiao\"},{\"authorId\":\"144756076\",\"name\":\"Y. Lee\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"153652147\",\"name\":\"J. Malik\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"80685dc522d30b18f3feb97d6c977f71fa746325\",\"title\":\"Audiovisual SlowFast Networks for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/80685dc522d30b18f3feb97d6c977f71fa746325\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71039664\",\"name\":\"Hiroaki Ishioka\"},{\"authorId\":\"7885067\",\"name\":\"Xinshuo Weng\"},{\"authorId\":\"48087997\",\"name\":\"Y. Man\"},{\"authorId\":\"1665822545\",\"name\":\"Kris Kitani\"}],\"doi\":\"10.22260/isarc2020/0092\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"b116e130b3fa9ee7c007f02c3d19ed35180aec8d\",\"title\":\"Single Camera Worker Detection, Tracking and Action Recognition in Construction Site\",\"url\":\"https://www.semanticscholar.org/paper/b116e130b3fa9ee7c007f02c3d19ed35180aec8d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2010.07217\",\"authors\":[{\"authorId\":\"2595119\",\"name\":\"X. Yang\"},{\"authorId\":\"1728108\",\"name\":\"M. Mirmehdi\"},{\"authorId\":\"1717278\",\"name\":\"T. Burghardt\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"af44b51ac01b2599961107a7a76a5892601c5f7c\",\"title\":\"Back to the Future: Cycle Encoding Prediction for Self-supervised Contrastive Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/af44b51ac01b2599961107a7a76a5892601c5f7c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"82301441\",\"name\":\"Liang Yang\"},{\"authorId\":\"2000361118\",\"name\":\"Jingjie Zeng\"},{\"authorId\":\"48298668\",\"name\":\"T. Peng\"},{\"authorId\":\"145364885\",\"name\":\"X. Luo\"},{\"authorId\":\"2833549\",\"name\":\"J. Zhang\"},{\"authorId\":\"9244357\",\"name\":\"Hongfei Lin\"}],\"doi\":\"10.1145/3382507.3418893\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c8180436328fc6aa91dfb9025368d2cb7a2ad783\",\"title\":\"Leniency to those who confess?: Predicting the Legal Judgement via Multi-Modal Analysis\",\"url\":\"https://www.semanticscholar.org/paper/c8180436328fc6aa91dfb9025368d2cb7a2ad783\",\"venue\":\"ICMI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92709220\",\"name\":\"Yao-Sen Chen\"},{\"authorId\":\"1455126232\",\"name\":\"Bing Guo\"},{\"authorId\":\"143736944\",\"name\":\"Yan Shen\"},{\"authorId\":\"115438571\",\"name\":\"W. Wang\"},{\"authorId\":\"1836290988\",\"name\":\"Xinhua Suo\"},{\"authorId\":\"1409738616\",\"name\":\"Zhang Zhen\"}],\"doi\":\"10.1007/s11760-020-01758-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0e47005fae57dfc1e4e3f3abcbd61a8d2cc9aead\",\"title\":\"Using efficient group pseudo-3D network to learn spatio-temporal features\",\"url\":\"https://www.semanticscholar.org/paper/0e47005fae57dfc1e4e3f3abcbd61a8d2cc9aead\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1905.11954\",\"authors\":[{\"authorId\":\"2117357\",\"name\":\"Chengxu Zhuang\"},{\"authorId\":\"50112310\",\"name\":\"Alex Andonian\"},{\"authorId\":\"40657572\",\"name\":\"D. Yamins\"}],\"doi\":\"10.1109/CVPR42600.2020.00958\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"02cd7e1a888fedd25337a4598f332c5203091e71\",\"title\":\"Unsupervised Learning From Video With Deep Neural Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/02cd7e1a888fedd25337a4598f332c5203091e71\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2002.05123\",\"authors\":[{\"authorId\":\"1491911042\",\"name\":\"Roi Pony\"},{\"authorId\":\"12808196\",\"name\":\"I. Naeh\"},{\"authorId\":\"1712535\",\"name\":\"Shie Mannor\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ef4549c94e1ee3e2a132c63bde4c2de51396febc\",\"title\":\"Over-the-Air Adversarial Flickering Attacks against Video Recognition Networks.\",\"url\":\"https://www.semanticscholar.org/paper/ef4549c94e1ee3e2a132c63bde4c2de51396febc\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2003.13594\",\"authors\":[{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"1491624845\",\"name\":\"Chen Sun\"},{\"authorId\":\"152567560\",\"name\":\"D. Ross\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/cvpr42600.2020.01033\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ee3ba7ebf3a0116d17857c53fe10d98ae3a586d9\",\"title\":\"Speech2Action: Cross-Modal Supervision for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ee3ba7ebf3a0116d17857c53fe10d98ae3a586d9\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3458261\",\"name\":\"Quanle Liu\"},{\"authorId\":\"1961065\",\"name\":\"Xiangjiu Che\"},{\"authorId\":\"3079649\",\"name\":\"Mei Bie\"}],\"doi\":\"10.1109/ACCESS.2019.2923651\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c93fea9dba471ad0b42ba7b217cbe5ee1bc74a26\",\"title\":\"R-STAN: Residual Spatial-Temporal Attention Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c93fea9dba471ad0b42ba7b217cbe5ee1bc74a26\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"2003.02692\",\"authors\":[{\"authorId\":\"12888106\",\"name\":\"H. Cho\"},{\"authorId\":\"40152520\",\"name\":\"Tae-Hoon Kim\"},{\"authorId\":\"145917158\",\"name\":\"H. J. Chang\"},{\"authorId\":\"34600044\",\"name\":\"Wonjun Hwang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"90e185b5011a11fba9dea8db9136e4048b3728ec\",\"title\":\"Self-Supervised Spatio-Temporal Representation Learning Using Variable Playback Speed Prediction\",\"url\":\"https://www.semanticscholar.org/paper/90e185b5011a11fba9dea8db9136e4048b3728ec\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46276482\",\"name\":\"J. Li\"},{\"authorId\":\"145708711\",\"name\":\"Ping Wei\"},{\"authorId\":\"1978363545\",\"name\":\"Yongchi Zhang\"},{\"authorId\":\"153873673\",\"name\":\"N. Zheng\"}],\"doi\":\"10.1145/3394171.3413641\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"05444a5a49f717dc199957b66e9c472219171f88\",\"title\":\"A Slow-I-Fast-P Architecture for Compressed Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/05444a5a49f717dc199957b66e9c472219171f88\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2007.12034\",\"authors\":[{\"authorId\":\"1809218238\",\"name\":\"Xiaofang Wang\"},{\"authorId\":\"3182065\",\"name\":\"Xuehan Xiong\"},{\"authorId\":\"7679232\",\"name\":\"M. Neumann\"},{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"},{\"authorId\":\"2148510\",\"name\":\"A. Angelova\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"},{\"authorId\":\"145221796\",\"name\":\"W. Hua\"}],\"doi\":\"10.1007/978-3-030-58598-3_27\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"858a9f482e2dc1cebf7a116a740ddd0cf1f13506\",\"title\":\"AttentionNAS: Spatiotemporal Attention Cell Search for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/858a9f482e2dc1cebf7a116a740ddd0cf1f13506\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2011.07557\",\"authors\":[{\"authorId\":\"80007827\",\"name\":\"Dalu Feng\"},{\"authorId\":\"7389074\",\"name\":\"S. Yang\"},{\"authorId\":\"144481158\",\"name\":\"S. Shan\"},{\"authorId\":\"51069511\",\"name\":\"X. Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9bd00f2545b89e538a524bf2330ba32d39d9bfcd\",\"title\":\"Learn an Effective Lip Reading Model without Pains\",\"url\":\"https://www.semanticscholar.org/paper/9bd00f2545b89e538a524bf2330ba32d39d9bfcd\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.10071\",\"authors\":[{\"authorId\":\"48170161\",\"name\":\"L. Wang\"},{\"authorId\":\"9445458\",\"name\":\"Zhan Tong\"},{\"authorId\":\"1511715446\",\"name\":\"Bin Ji\"},{\"authorId\":\"39914710\",\"name\":\"Gangshan Wu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"839a009d4d530483cb9b365012ffc7d76cd88b85\",\"title\":\"TDN: Temporal Difference Networks for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/839a009d4d530483cb9b365012ffc7d76cd88b85\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2006.16228\",\"authors\":[{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"39257069\",\"name\":\"A. Recasens\"},{\"authorId\":\"145721402\",\"name\":\"Ros\\u00e1lia G. Schneider\"},{\"authorId\":\"2299479\",\"name\":\"R. Arandjelovi\\u0107\"},{\"authorId\":\"16092809\",\"name\":\"Jason Ramapuram\"},{\"authorId\":\"3364908\",\"name\":\"J. Fauw\"},{\"authorId\":\"1466466597\",\"name\":\"Lucas Smaira\"},{\"authorId\":\"48373216\",\"name\":\"S. Dieleman\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4174f03c7d8d9add62ae4ecd0ec90efba680b7ae\",\"title\":\"Self-Supervised MultiModal Versatile Networks\",\"url\":\"https://www.semanticscholar.org/paper/4174f03c7d8d9add62ae4ecd0ec90efba680b7ae\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"114270355\",\"name\":\"Ziqiao Weng\"},{\"authorId\":\"1691016\",\"name\":\"J. Meng\"},{\"authorId\":\"37457254\",\"name\":\"Zhaohua Ding\"},{\"authorId\":\"145078769\",\"name\":\"J. Yuan\"}],\"doi\":\"10.1109/icme46284.2020.9102776\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5e81dacc7762a0bff0507e8c0a7d7e06583436f8\",\"title\":\"S3F: A Multi-View Slow-Fast Network For Alzheimer\\u2019s Disease Diagnosis\",\"url\":\"https://www.semanticscholar.org/paper/5e81dacc7762a0bff0507e8c0a7d7e06583436f8\",\"venue\":\"2020 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2020},{\"arxivId\":\"2010.08365\",\"authors\":[{\"authorId\":\"50854772\",\"name\":\"Li Yuan\"},{\"authorId\":\"1864078340\",\"name\":\"Yichen Zhou\"},{\"authorId\":\"1993649162\",\"name\":\"Shuning Chang\"},{\"authorId\":\"1993645769\",\"name\":\"Z. Huang\"},{\"authorId\":\"1994343285\",\"name\":\"Yu-Peng Chen\"},{\"authorId\":\"35785179\",\"name\":\"Xuecheng Nie\"},{\"authorId\":\"72259333\",\"name\":\"Tao Wang\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"}],\"doi\":\"10.1145/3394171.3416301\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c42683144f583035bef46257ca34ae2d71498ef3\",\"title\":\"Toward Accurate Person-level Action Recognition in Videos of Crowed Scenes\",\"url\":\"https://www.semanticscholar.org/paper/c42683144f583035bef46257ca34ae2d71498ef3\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2012.06567\",\"authors\":[{\"authorId\":\"1805946041\",\"name\":\"Yi Zhu\"},{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"49046944\",\"name\":\"C. Liu\"},{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"22539483\",\"name\":\"Chongruo Wu\"},{\"authorId\":\"152781163\",\"name\":\"Z. Zhang\"},{\"authorId\":\"2397422\",\"name\":\"Joseph Tighe\"},{\"authorId\":\"1758550\",\"name\":\"R. Manmatha\"},{\"authorId\":\"49140510\",\"name\":\"M. Li\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ee12f02830a5e1f7cadd3623dfed495cf099bc82\",\"title\":\"A Comprehensive Study of Deep Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ee12f02830a5e1f7cadd3623dfed495cf099bc82\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2011.13046\",\"authors\":[{\"authorId\":\"48442730\",\"name\":\"Y. Bai\"},{\"authorId\":\"145350991\",\"name\":\"Haoqi Fan\"},{\"authorId\":\"1806773\",\"name\":\"I. Misra\"},{\"authorId\":\"145595812\",\"name\":\"G. Venkatesh\"},{\"authorId\":\"2946371\",\"name\":\"Yongyi Lu\"},{\"authorId\":\"7743268\",\"name\":\"Yuyin Zhou\"},{\"authorId\":\"2156559\",\"name\":\"Qihang Yu\"},{\"authorId\":\"50105587\",\"name\":\"Vikas Chandra\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c8993a95dac7a0bf86fb96ee30cf653a57755783\",\"title\":\"Can Temporal Information Help with Contrastive Self-Supervised Learning?\",\"url\":\"https://www.semanticscholar.org/paper/c8993a95dac7a0bf86fb96ee30cf653a57755783\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2001.05661\",\"authors\":[{\"authorId\":\"143657833\",\"name\":\"Li Tao\"},{\"authorId\":\"1524733293\",\"name\":\"Xueting Wang\"},{\"authorId\":\"145572095\",\"name\":\"T. Yamasaki\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"18726788e8a74aed4420745fc420dddd3950e1c6\",\"title\":\"Rethinking Motion Representation: Residual Frames with 3D ConvNets for Better Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/18726788e8a74aed4420745fc420dddd3950e1c6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31474464\",\"name\":\"Wei Hong Chin\"},{\"authorId\":\"2141400\",\"name\":\"Nuo Wi Noel Tay\"},{\"authorId\":\"145350352\",\"name\":\"N. Kubota\"},{\"authorId\":\"117831028\",\"name\":\"Chu Kiong Loo\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206637\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1ff99740e33d92be0d18866661184e41085583ba\",\"title\":\"A Lightweight Neural-Net with Assistive Mobile Robot for Human Fall Detection System\",\"url\":\"https://www.semanticscholar.org/paper/1ff99740e33d92be0d18866661184e41085583ba\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":\"2003.13042\",\"authors\":[{\"authorId\":\"31463937\",\"name\":\"Haodong Duan\"},{\"authorId\":\"152621421\",\"name\":\"Yue Zhao\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"49663328\",\"name\":\"Wentao Liu\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1007/978-3-030-58555-6_40\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d6f7e18d551743889cd87dc3e0b4a75b8791ea95\",\"title\":\"Omni-sourced Webly-supervised Learning for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d6f7e18d551743889cd87dc3e0b4a75b8791ea95\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1912.00998\",\"authors\":[{\"authorId\":\"100880679\",\"name\":\"Chao-Yuan Wu\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"51506875\",\"name\":\"Philipp Krahenbuhl\"}],\"doi\":\"10.1109/cvpr42600.2020.00023\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b8cc28e11900e4d191651ae7234b4dbd129b1007\",\"title\":\"A Multigrid Method for Efficiently Training Video Models\",\"url\":\"https://www.semanticscholar.org/paper/b8cc28e11900e4d191651ae7234b4dbd129b1007\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12808196\",\"name\":\"I. Naeh\"},{\"authorId\":\"1491911042\",\"name\":\"Roi Pony\"},{\"authorId\":\"1712535\",\"name\":\"Shie Mannor\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f26706daac5f920925871c1554da4db6f72702c6\",\"title\":\"Flickering Adversarial Attacks against Video Recognition Networks\",\"url\":\"https://www.semanticscholar.org/paper/f26706daac5f920925871c1554da4db6f72702c6\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46723906\",\"name\":\"J. Fei\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"c9a88970d666904848a2bef1b180fbde0d8a2db9\",\"title\":\"Temporal Action Recognition for Tutorial Videos\",\"url\":\"https://www.semanticscholar.org/paper/c9a88970d666904848a2bef1b180fbde0d8a2db9\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2012.04124\",\"authors\":[{\"authorId\":\"40176903\",\"name\":\"Sangho Lee\"},{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"},{\"authorId\":\"6555176\",\"name\":\"Thomas Breuel\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"3655a6344ffb57838fd7f7acce651f36d3a9d526\",\"title\":\"Parameter Efficient Multimodal Transformers for Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/3655a6344ffb57838fd7f7acce651f36d3a9d526\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47149750\",\"name\":\"Xinhui Wu\"},{\"authorId\":\"1719370\",\"name\":\"Shiqi Yu\"},{\"authorId\":\"145501833\",\"name\":\"Y. Huang\"}],\"doi\":\"10.1007/978-3-030-31456-9_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f65891ab12ca77b6eddcd63df9e36776f115eec2\",\"title\":\"Multiscale Temporal Network for Video-Based Gait Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f65891ab12ca77b6eddcd63df9e36776f115eec2\",\"venue\":\"CCBR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46276931\",\"name\":\"Jiaojiao Li\"},{\"authorId\":\"1379683358\",\"name\":\"Ruxing Cui\"},{\"authorId\":\"2485552\",\"name\":\"B. Li\"},{\"authorId\":\"7771261\",\"name\":\"Y. Li\"},{\"authorId\":\"1745727\",\"name\":\"S. Mei\"},{\"authorId\":\"144486980\",\"name\":\"Q. Du\"}],\"doi\":\"10.1109/IGARSS.2019.8898352\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f9373941be7391b744ee1ed03576ac5fa46aeccf\",\"title\":\"Dual 1D-2D Spatial-Spectral CNN for Hyperspectral Image Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/f9373941be7391b744ee1ed03576ac5fa46aeccf\",\"venue\":\"IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium\",\"year\":2019},{\"arxivId\":\"1909.13130\",\"authors\":[{\"authorId\":\"153918891\",\"name\":\"Chenxu Luo\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.1109/ICCV.2019.00561\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8b8fe4727c8094b17e61886e69a602f8d0403091\",\"title\":\"Grouped Spatial-Temporal Aggregation for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b8fe4727c8094b17e61886e69a602f8d0403091\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"144746444\",\"name\":\"H. Bischof\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"},{\"authorId\":\"40454588\",\"name\":\"J. Frahm\"}],\"doi\":\"10.1007/978-3-030-58577-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"08a578d7f7f3d0edf46470e33f92e2335d19b70b\",\"title\":\"Computer Vision \\u2013 ECCV 2020: 16th European Conference, Glasgow, UK, August 23\\u201328, 2020, Proceedings, Part XXX\",\"url\":\"https://www.semanticscholar.org/paper/08a578d7f7f3d0edf46470e33f92e2335d19b70b\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1912.00869\",\"authors\":[{\"authorId\":\"33421444\",\"name\":\"Quanfu Fan\"},{\"authorId\":\"48239920\",\"name\":\"Chun-Fu Chen\"},{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"134455051\",\"name\":\"Marco Pistoia\"},{\"authorId\":\"66305116\",\"name\":\"D. Cox\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9c77ffc223e47388155a6e3bf58ae294f51f9ccb\",\"title\":\"More Is Less: Learning Efficient Video Representations by Big-Little Network and Depthwise Temporal Aggregation\",\"url\":\"https://www.semanticscholar.org/paper/9c77ffc223e47388155a6e3bf58ae294f51f9ccb\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3281413\",\"name\":\"Diangang Li\"},{\"authorId\":\"49722335\",\"name\":\"Jianquan Liu\"},{\"authorId\":\"1382175791\",\"name\":\"Shoji Nishimura\"},{\"authorId\":\"1993699405\",\"name\":\"Yuka Hayashi\"},{\"authorId\":\"144042991\",\"name\":\"Jun Suzuki\"},{\"authorId\":\"144768792\",\"name\":\"Y. Gong\"}],\"doi\":\"10.1145/3394171.3413801\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2587144054982adc9b4c5adef760f45bf3be0a26\",\"title\":\"Multi-Person Action Recognition in Microwave Sensors\",\"url\":\"https://www.semanticscholar.org/paper/2587144054982adc9b4c5adef760f45bf3be0a26\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2007.00394\",\"authors\":[{\"authorId\":\"1410307807\",\"name\":\"Yizhak Ben-Shabat\"},{\"authorId\":\"1490933487\",\"name\":\"Xin Yu\"},{\"authorId\":\"9120887\",\"name\":\"F. Saleh\"},{\"authorId\":\"145185576\",\"name\":\"Dylan Campbell\"},{\"authorId\":\"145112187\",\"name\":\"Cristian Rodriguez-Opazo\"},{\"authorId\":\"71200893\",\"name\":\"H. Li\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"947b868aa1c38940df280ebeb8077d4e729fb988\",\"title\":\"The IKEA ASM Dataset: Understanding People Assembling Furniture through Actions, Objects and Pose\",\"url\":\"https://www.semanticscholar.org/paper/947b868aa1c38940df280ebeb8077d4e729fb988\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8277405\",\"name\":\"Brian Dolhansky\"},{\"authorId\":\"1749686057\",\"name\":\"Joanna Bitton\"},{\"authorId\":\"1417654107\",\"name\":\"Ben Pflaum\"},{\"authorId\":\"119590112\",\"name\":\"Jikuo Lu\"},{\"authorId\":\"1410913697\",\"name\":\"Russ Howes\"},{\"authorId\":\"51202149\",\"name\":\"Menglin Wang\"},{\"authorId\":\"1399086207\",\"name\":\"C. Canton-Ferrer\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1af36c1a0fafa4aed6ad7937a32b962982e2654b\",\"title\":\"The DeepFake Detection Challenge Dataset\",\"url\":\"https://www.semanticscholar.org/paper/1af36c1a0fafa4aed6ad7937a32b962982e2654b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.14285\",\"authors\":[{\"authorId\":\"151473559\",\"name\":\"Liam Hiley\"},{\"authorId\":\"1762890\",\"name\":\"A. Preece\"},{\"authorId\":\"2256975\",\"name\":\"Y. Hicks\"},{\"authorId\":\"144387904\",\"name\":\"S. Chakraborty\"},{\"authorId\":\"1804334\",\"name\":\"Prudhvi Gurram\"},{\"authorId\":\"151479420\",\"name\":\"Richard Tomsett\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ab170d55c661bf7cf5868ca82b67a3d6fed758d2\",\"title\":\"Explaining Motion Relevance for Activity Recognition in Video Deep Learning Models\",\"url\":\"https://www.semanticscholar.org/paper/ab170d55c661bf7cf5868ca82b67a3d6fed758d2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"81781019\",\"name\":\"Minho Shim\"},{\"authorId\":\"28033903\",\"name\":\"Hsuan-I Ho\"},{\"authorId\":\"52289773\",\"name\":\"Jinhyung Kim\"},{\"authorId\":\"1405197098\",\"name\":\"Dongyoon Wee\"}],\"doi\":\"10.1007/978-3-030-58568-6_20\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9f8c337087bfb7498ec3d6990b9df44ce7ff876d\",\"title\":\"READ: Reciprocal Attention Discriminator for Image-to-Video Re-identification\",\"url\":\"https://www.semanticscholar.org/paper/9f8c337087bfb7498ec3d6990b9df44ce7ff876d\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2006.15657\",\"authors\":[{\"authorId\":\"32486555\",\"name\":\"D. Epstein\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9a6dd28c5449ddcad7b079c0dca6ea6a518c3eb0\",\"title\":\"Video Representations of Goals Emerge from Watching Failure\",\"url\":\"https://www.semanticscholar.org/paper/9a6dd28c5449ddcad7b079c0dca6ea6a518c3eb0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1912.06640\",\"authors\":[{\"authorId\":\"52023459\",\"name\":\"Steven Schwarcz\"},{\"authorId\":\"104382958\",\"name\":\"P. Xu\"},{\"authorId\":\"1401079497\",\"name\":\"David B. D'Ambrosio\"},{\"authorId\":\"3462309\",\"name\":\"Juhana Kangaspunta\"},{\"authorId\":\"2148510\",\"name\":\"A. Angelova\"},{\"authorId\":\"2574014\",\"name\":\"H. Phan\"},{\"authorId\":\"3111912\",\"name\":\"Navdeep Jaitly\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6e7a36fb58596cefc089de92696fc6f5cfc7259c\",\"title\":\"SPIN: A High Speed, High Resolution Vision Dataset for Tracking and Action Recognition in Ping Pong\",\"url\":\"https://www.semanticscholar.org/paper/6e7a36fb58596cefc089de92696fc6f5cfc7259c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34041171\",\"name\":\"Akshaya Ramaswamy\"},{\"authorId\":\"3339923\",\"name\":\"K. Seemakurthy\"},{\"authorId\":\"49294154\",\"name\":\"J. Gubbi\"},{\"authorId\":\"21432550\",\"name\":\"B. Purushothaman\"}],\"doi\":\"10.1109/CVPRW50498.2020.00390\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"001ab97faa6b224b52aac252a003e223325e70a2\",\"title\":\"Spatio-temporal action detection and localization using a hierarchical LSTM\",\"url\":\"https://www.semanticscholar.org/paper/001ab97faa6b224b52aac252a003e223325e70a2\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"2008.05861\",\"authors\":[{\"authorId\":\"46584859\",\"name\":\"Jiangliu Wang\"},{\"authorId\":\"2840852\",\"name\":\"Jianbo Jiao\"},{\"authorId\":\"47908910\",\"name\":\"Y. Liu\"}],\"doi\":\"10.1007/978-3-030-58520-4_30\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"78ad3beec8cc6c331dfe491291c213214e798f45\",\"title\":\"Self-supervised Video Representation Learning by Pace Prediction\",\"url\":\"https://www.semanticscholar.org/paper/78ad3beec8cc6c331dfe491291c213214e798f45\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47077615\",\"name\":\"J. Munro\"},{\"authorId\":\"1677780022\",\"name\":\"Dima Damen\"}],\"doi\":\"10.1109/cvpr42600.2020.00020\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"646a256e30cd244b668660c32b529ff31a874a78\",\"title\":\"Multi-Modal Domain Adaptation for Fine-Grained Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/646a256e30cd244b668660c32b529ff31a874a78\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2001.06499\",\"authors\":[{\"authorId\":\"46798949\",\"name\":\"H. Shao\"},{\"authorId\":\"152230789\",\"name\":\"Shengju Qian\"},{\"authorId\":\"119924269\",\"name\":\"Y. Liu\"}],\"doi\":\"10.1609/AAAI.V34I07.6872\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a573c125e85d1230626c8f3cf6193354f753958d\",\"title\":\"Temporal Interlacing Network\",\"url\":\"https://www.semanticscholar.org/paper/a573c125e85d1230626c8f3cf6193354f753958d\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8433849\",\"name\":\"Mengshi Qi\"},{\"authorId\":\"144411970\",\"name\":\"J. Qin\"},{\"authorId\":\"34798935\",\"name\":\"Xiantong Zhen\"},{\"authorId\":\"144942207\",\"name\":\"Di Huang\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1145/3394171.3416269\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"27df4822497b090811c3576f17245feaee40d2ff\",\"title\":\"Few-Shot Ensemble Learning for Video Classification with SlowFast Memory Networks\",\"url\":\"https://www.semanticscholar.org/paper/27df4822497b090811c3576f17245feaee40d2ff\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1911.11319\",\"authors\":[{\"authorId\":\"1384480816\",\"name\":\"Pingchuan Ma\"},{\"authorId\":\"120026268\",\"name\":\"Yao Zhou\"},{\"authorId\":null,\"name\":\"Yu Lu\"},{\"authorId\":\"1726357\",\"name\":\"Wayne Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3b5829a65c4eb19ec8922a1575c6900d5f94046f\",\"title\":\"Learning Efficient Video Representation with Video Shuffle Networks\",\"url\":\"https://www.semanticscholar.org/paper/3b5829a65c4eb19ec8922a1575c6900d5f94046f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2010.09982\",\"authors\":[{\"authorId\":\"1993669388\",\"name\":\"Yuqian Fu\"},{\"authorId\":\"31267246\",\"name\":\"L. Zhang\"},{\"authorId\":\"1993529318\",\"name\":\"Junke Wang\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1145/3394171.3413502\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8abe9a4d432cc4c43a11f9336cd105d1be30ae92\",\"title\":\"Depth Guided Adaptive Meta-Fusion Network for Few-shot Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8abe9a4d432cc4c43a11f9336cd105d1be30ae92\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Xiantan Zhu\"},{\"authorId\":\"48391877\",\"name\":\"Xuan Tao\"},{\"authorId\":\"82592949\",\"name\":\"Lu Shi\"},{\"authorId\":\"1390642027\",\"name\":\"Shaoqi Chen\"},{\"authorId\":\"1490704328\",\"name\":\"Rui Yin\"},{\"authorId\":\"144529492\",\"name\":\"L. Ding\"},{\"authorId\":\"40627107\",\"name\":\"Y. Obinata\"},{\"authorId\":\"1636418717\",\"name\":\"Takuma Yamamoto\"},{\"authorId\":\"8132840\",\"name\":\"Zhi-ming Tan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"976e86c12aebe392c04322852402a1e17b5a70e2\",\"title\":\"Multi-scale Spatiotemporal Features for Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/976e86c12aebe392c04322852402a1e17b5a70e2\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"116998585\",\"name\":\"Petr Byvshev\"},{\"authorId\":\"40892875\",\"name\":\"Pascal Mettes\"},{\"authorId\":\"144755236\",\"name\":\"Y. Xiao\"}],\"doi\":\"10.1145/3372278.3390675\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3b7340a8490b8de31bb4106b37e957f3db476bef\",\"title\":\"Heterogeneous Non-Local Fusion for Multimodal Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3b7340a8490b8de31bb4106b37e957f3db476bef\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":\"2005.06803\",\"authors\":[{\"authorId\":\"46270766\",\"name\":\"Zhaoyang Liu\"},{\"authorId\":\"29461006\",\"name\":\"L. Wang\"},{\"authorId\":\"3096434\",\"name\":\"W. Wu\"},{\"authorId\":\"7350503\",\"name\":\"Chen Qian\"},{\"authorId\":\"144720251\",\"name\":\"Tong Lu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"3ac6ad718bbdeda6b5b00b61983f8b520d8a6bcb\",\"title\":\"TAM: Temporal Adaptive Module for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3ac6ad718bbdeda6b5b00b61983f8b520d8a6bcb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.06647\",\"authors\":[{\"authorId\":\"153634296\",\"name\":\"Matthew Hutchinson\"},{\"authorId\":\"74882299\",\"name\":\"Vijay Gadepally\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"65955a106905afb90a2a2fa74e48c6d6d597892f\",\"title\":\"Video Action Understanding: A Tutorial\",\"url\":\"https://www.semanticscholar.org/paper/65955a106905afb90a2a2fa74e48c6d6d597892f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.03184\",\"authors\":[{\"authorId\":\"2455191\",\"name\":\"Omid Mohamad Nezami\"},{\"authorId\":\"22205368\",\"name\":\"Akshay Chaturvedi\"},{\"authorId\":\"143899054\",\"name\":\"Mark Dras\"},{\"authorId\":\"48421321\",\"name\":\"U. Garain\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cf2f8c8686cff2643270ed2d61f12d4661cbb75a\",\"title\":\"Pick-Object-Attack: Type-Specific Adversarial Attack for Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/cf2f8c8686cff2643270ed2d61f12d4661cbb75a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2001.05691\",\"authors\":[{\"authorId\":\"122460701\",\"name\":\"Tianhao Li\"},{\"authorId\":\"119770705\",\"name\":\"L. Wang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2783c13471060300e62a1eed458d9d2888b5b5be\",\"title\":\"Learning Spatiotemporal Features via Video and Text Pair Discrimination\",\"url\":\"https://www.semanticscholar.org/paper/2783c13471060300e62a1eed458d9d2888b5b5be\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1904.12043\",\"authors\":[{\"authorId\":\"49955730\",\"name\":\"Haibin Lin\"},{\"authorId\":\"144978189\",\"name\":\"Hang Zhang\"},{\"authorId\":\"50032176\",\"name\":\"Yifei Ma\"},{\"authorId\":\"145633170\",\"name\":\"Tong He\"},{\"authorId\":\"48805322\",\"name\":\"Zhi Zhang\"},{\"authorId\":\"40881843\",\"name\":\"Sheng Zha\"},{\"authorId\":null,\"name\":\"Mu Li\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"64957205022593d904070a399a8d5675a08ffaf4\",\"title\":\"Dynamic Mini-batch SGD for Elastic Distributed Training: Learning in the Limbo of Resources\",\"url\":\"https://www.semanticscholar.org/paper/64957205022593d904070a399a8d5675a08ffaf4\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1904.02811\",\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"}],\"doi\":\"10.1109/ICCV.2019.00565\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f4852f5385d60e8870e30db5c65392d120e58574\",\"title\":\"Video Classification With Channel-Separated Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/f4852f5385d60e8870e30db5c65392d120e58574\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1909.04656\",\"authors\":[{\"authorId\":\"22237490\",\"name\":\"Tengda Han\"},{\"authorId\":\"10096695\",\"name\":\"Weidi Xie\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/ICCVW.2019.00186\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0174d263d3a77bf03fce831a9a5ce2678e1959f0\",\"title\":\"Video Representation Learning by Dense Predictive Coding\",\"url\":\"https://www.semanticscholar.org/paper/0174d263d3a77bf03fce831a9a5ce2678e1959f0\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"2011.10889\",\"authors\":[{\"authorId\":\"39707211\",\"name\":\"Karan Sikka\"},{\"authorId\":\"2745451\",\"name\":\"Jihua Huang\"},{\"authorId\":\"1418955362\",\"name\":\"Andrew Silberfarb\"},{\"authorId\":\"1379647463\",\"name\":\"Prateeth Nayak\"},{\"authorId\":\"2028573203\",\"name\":\"Luke Rohrer\"},{\"authorId\":\"4643090\",\"name\":\"Pritish Sahu\"},{\"authorId\":\"1860536\",\"name\":\"J. Byrnes\"},{\"authorId\":\"47977519\",\"name\":\"A. Divakaran\"},{\"authorId\":\"34915378\",\"name\":\"R. Rohwer\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eab2f4ea850b319f2a0fc57ec36810907c3c677d\",\"title\":\"Zero-Shot Learning with Knowledge Enhanced Visual Semantic Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/eab2f4ea850b319f2a0fc57ec36810907c3c677d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.14139\",\"authors\":[{\"authorId\":\"1976656211\",\"name\":\"\\u00c7agri G\\u00f6k\\u00e7e\"},{\"authorId\":\"32852728\",\"name\":\"Ogulcan \\u00d6zdemir\"},{\"authorId\":\"1944885\",\"name\":\"A. Kindiroglu\"},{\"authorId\":\"1694599\",\"name\":\"L. Akarun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"591a11dedfb9190ec66b3cd45c67cee824187a6d\",\"title\":\"Score-level Multi Cue Fusion for Sign Language Recognition\",\"url\":\"https://www.semanticscholar.org/paper/591a11dedfb9190ec66b3cd45c67cee824187a6d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.11378\",\"authors\":[{\"authorId\":\"153420733\",\"name\":\"Haozhi Cao\"},{\"authorId\":\"9734988\",\"name\":\"Yuecong Xu\"},{\"authorId\":\"2562263\",\"name\":\"Jianfei Yang\"},{\"authorId\":\"120974533\",\"name\":\"Kezhi Mao\"},{\"authorId\":\"2037059\",\"name\":\"Jian-Xiong Yin\"},{\"authorId\":\"144308998\",\"name\":\"S. See\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c16a94fe31835a67a8cf5e2d4d1076e0037844a9\",\"title\":\"Effective Action Recognition with Embedded Key Point Shifts\",\"url\":\"https://www.semanticscholar.org/paper/c16a94fe31835a67a8cf5e2d4d1076e0037844a9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.10903\",\"authors\":[{\"authorId\":\"2862582\",\"name\":\"Peratham Wiriyathammabhum\"}],\"doi\":\"10.1007/978-3-030-63820-7_63\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"09da26797d509cc5e193512589e205c088f4b1f4\",\"title\":\"SpotFast Networks with Memory Augmented Lateral Transformers for Lipreading\",\"url\":\"https://www.semanticscholar.org/paper/09da26797d509cc5e193512589e205c088f4b1f4\",\"venue\":\"ICONIP\",\"year\":2020},{\"arxivId\":\"2003.04298\",\"authors\":[{\"authorId\":\"1379929116\",\"name\":\"Mandela Patrick\"},{\"authorId\":\"47792365\",\"name\":\"Y. Asano\"},{\"authorId\":\"145891577\",\"name\":\"Ruth Fong\"},{\"authorId\":\"143848064\",\"name\":\"Jo\\u00e3o F. Henriques\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8ddbaa34c574124a91fa3bc217e232e17668e84c\",\"title\":\"Multi-modal Self-Supervision from Generalized Data Transformations\",\"url\":\"https://www.semanticscholar.org/paper/8ddbaa34c574124a91fa3bc217e232e17668e84c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Gao Peng\"},{\"authorId\":null,\"name\":\"Bo Pang\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d2bf569fbf3e407f4b60567a94d45880d35c2a3d\",\"title\":\"Efficient 3D Video Engine Using Frame Redundancy\",\"url\":\"https://www.semanticscholar.org/paper/d2bf569fbf3e407f4b60567a94d45880d35c2a3d\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1908.02486\",\"authors\":[{\"authorId\":\"51128181\",\"name\":\"Boyuan Jiang\"},{\"authorId\":\"47446949\",\"name\":\"M. Wang\"},{\"authorId\":\"35893447\",\"name\":\"W. Gan\"},{\"authorId\":\"145717890\",\"name\":\"W. Wu\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\"}],\"doi\":\"10.1109/ICCV.2019.00209\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b812b20192ffac37b03bde0261934a2a8c7fdf47\",\"title\":\"STM: SpatioTemporal and Motion Encoding for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b812b20192ffac37b03bde0261934a2a8c7fdf47\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2006.07609\",\"authors\":[{\"authorId\":\"1390626541\",\"name\":\"Ziming Liu\"},{\"authorId\":\"47296615\",\"name\":\"Guangyu Gao\"},{\"authorId\":\"1380212680\",\"name\":\"A. K. Qin\"},{\"authorId\":\"46276184\",\"name\":\"Jinyang Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ddc5b5371bc1bc1ab283818034f3dcb3756cff69\",\"title\":\"DTG-Net: Differentiated Teachers Guided Self-Supervised Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ddc5b5371bc1bc1ab283818034f3dcb3756cff69\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"69893872\",\"name\":\"Yuri Yudhaswana Joefrie\"},{\"authorId\":\"96853476\",\"name\":\"Masaki Aono\"}],\"doi\":\"10.1109/ICAICTA.2019.8904245\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6ccba260ccaa7fb9a649497e80aefa737756b3b0\",\"title\":\"Action Recognition by Composite Deep Learning Architecture I3D-DenseLSTM\",\"url\":\"https://www.semanticscholar.org/paper/6ccba260ccaa7fb9a649497e80aefa737756b3b0\",\"venue\":\"2019 International Conference of Advanced Informatics: Concepts, Theory and Applications (ICAICTA)\",\"year\":2019},{\"arxivId\":\"2008.11588\",\"authors\":[{\"authorId\":\"1411464794\",\"name\":\"Alejandro L\\u00f3pez-Cifuentes\"},{\"authorId\":\"1404022411\",\"name\":\"Marcos Escudero-Vi\\u00f1olo\"},{\"authorId\":\"143785525\",\"name\":\"J. Besc\\u00f3s\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8ed2291a39d8274bc5f09f3a7af1259ce84ff19d\",\"title\":\"A Prospective Study on Sequence-Driven Temporal Sampling and Ego-Motion Compensation for Action Recognition in the EPIC-Kitchens Dataset\",\"url\":\"https://www.semanticscholar.org/paper/8ed2291a39d8274bc5f09f3a7af1259ce84ff19d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.05837\",\"authors\":[{\"authorId\":\"40951853\",\"name\":\"Manyuan Zhang\"},{\"authorId\":\"46798949\",\"name\":\"H. Shao\"},{\"authorId\":\"12920342\",\"name\":\"Guanglu Song\"},{\"authorId\":\"119924269\",\"name\":\"Y. Liu\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5a700417579a1fbde76baba60595bc00c909606c\",\"title\":\"Top-1 Solution of Multi-Moments in Time Challenge 2019\",\"url\":\"https://www.semanticscholar.org/paper/5a700417579a1fbde76baba60595bc00c909606c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.05687\",\"authors\":[{\"authorId\":\"119997084\",\"name\":\"Xuhua Huang\"},{\"authorId\":\"1690418794\",\"name\":\"Jiarui Xu\"},{\"authorId\":\"5068280\",\"name\":\"Yu-Wing Tai\"},{\"authorId\":\"2088295\",\"name\":\"C. Tang\"}],\"doi\":\"10.1109/cvpr42600.2020.00890\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6404aaba4d243b519b7c65a4e52cb9ffb886f042\",\"title\":\"Fast Video Object Segmentation With Temporal Aggregation Network and Dynamic Template Matching\",\"url\":\"https://www.semanticscholar.org/paper/6404aaba4d243b519b7c65a4e52cb9ffb886f042\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3040310\",\"name\":\"Y. Jiang\"},{\"authorId\":\"1389284356\",\"name\":\"Kaixu Cui\"},{\"authorId\":\"47818608\",\"name\":\"Leilei Chen\"},{\"authorId\":\"152745066\",\"name\":\"Can-jin Wang\"},{\"authorId\":null,\"name\":\"Chen Wang\"},{\"authorId\":\"1732904\",\"name\":\"Haijing Liu\"},{\"authorId\":\"48258796\",\"name\":\"C. Xu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"0d9448f6fa289b86b1c448882907332a0ce49376\",\"title\":\"Comprehensive Soccer Video Understanding: Towards Human-comparable Video Understanding System in Constrained Environment\",\"url\":\"https://www.semanticscholar.org/paper/0d9448f6fa289b86b1c448882907332a0ce49376\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1912.07249\",\"authors\":[{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"3321919\",\"name\":\"Gr\\u00e9gory Rogez\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8dce5b1cc382f4a341f7ea43c6329c9e8acd202d\",\"title\":\"Mimetics: Towards Understanding Human Actions Out of Context\",\"url\":\"https://www.semanticscholar.org/paper/8dce5b1cc382f4a341f7ea43c6329c9e8acd202d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1904.11451\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"145878079\",\"name\":\"Vivek Sharma\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"1576263143\",\"name\":\"Jurgen Gall\"},{\"authorId\":\"49157259\",\"name\":\"R. Stiefelhagen\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-030-58558-7_35\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c2fe9e87e31e6fdb2b7bae5f9cc3c2d2612d13a\",\"title\":\"Large Scale Holistic Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/1c2fe9e87e31e6fdb2b7bae5f9cc3c2d2612d13a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2009.14661\",\"authors\":[{\"authorId\":\"1500399016\",\"name\":\"Tong Yu\"},{\"authorId\":\"2655297\",\"name\":\"Nicolas Padoy\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c386b73f74c2e7f91217bb65504d8725e17b81e\",\"title\":\"Encode the Unseen: Predictive Video Hashing for Scalable Mid-Stream Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/2c386b73f74c2e7f91217bb65504d8725e17b81e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.11833\",\"authors\":[{\"authorId\":\"7582228\",\"name\":\"Francisco J Luongo\"},{\"authorId\":\"1572018514\",\"name\":\"Ryan Hakim\"},{\"authorId\":\"50004324\",\"name\":\"J. Nguyen\"},{\"authorId\":\"2047844\",\"name\":\"Anima Anandkumar\"},{\"authorId\":\"1739831\",\"name\":\"A. Hung\"}],\"doi\":\"10.1016/j.surg.2020.08.016\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6ac3a69722b1d261fc50c8b4de046d0f501caf74\",\"title\":\"Deep learning-based computer vision to recognize and classify suturing gestures in robot-assisted surgery\",\"url\":\"https://www.semanticscholar.org/paper/6ac3a69722b1d261fc50c8b4de046d0f501caf74\",\"venue\":\"Surgery\",\"year\":2020},{\"arxivId\":\"2008.09412\",\"authors\":[{\"authorId\":\"8706479\",\"name\":\"Z. Yu\"},{\"authorId\":\"73819368\",\"name\":\"Benjia Zhou\"},{\"authorId\":\"1785406293\",\"name\":\"Jun Wan\"},{\"authorId\":\"8120382\",\"name\":\"P. Wang\"},{\"authorId\":\"1471684559\",\"name\":\"Haoyu Chen\"},{\"authorId\":null,\"name\":\"Xin Liu\"},{\"authorId\":\"34679741\",\"name\":\"S. Li\"},{\"authorId\":\"83433495\",\"name\":\"G. Zhao\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d2fec7fd0d928788491651ef66e795c5d7b73d0b\",\"title\":\"Searching Multi-Rate and Multi-Modal Temporal Enhanced Networks for Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d2fec7fd0d928788491651ef66e795c5d7b73d0b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.11479\",\"authors\":[{\"authorId\":\"19198894\",\"name\":\"Humam Alwassel\"},{\"authorId\":\"22314218\",\"name\":\"Silvio Giancola\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5388388db25f0d40ef6612333a0279373f8dddcf\",\"title\":\"TSP: Temporally-Sensitive Pretraining of Video Encoders for Localization Tasks\",\"url\":\"https://www.semanticscholar.org/paper/5388388db25f0d40ef6612333a0279373f8dddcf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.12372\",\"authors\":[{\"authorId\":\"50065546\",\"name\":\"W. Price\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f6378d6130b82f083882db4c0bf2065b6a3e59b8\",\"title\":\"Play Fair: Frame Attributions in Video Models\",\"url\":\"https://www.semanticscholar.org/paper/f6378d6130b82f083882db4c0bf2065b6a3e59b8\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34678431\",\"name\":\"F. Sener\"},{\"authorId\":\"1734802895\",\"name\":\"Dipika Singhania\"},{\"authorId\":\"144031869\",\"name\":\"A. Yao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e77735f1131cdb42db5a03093e4d15ebce34d473\",\"title\":\"Temporal Aggregate Representations for Long Term Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/e77735f1131cdb42db5a03093e4d15ebce34d473\",\"venue\":\"ECCV 2020\",\"year\":2020},{\"arxivId\":\"2004.11475\",\"authors\":[{\"authorId\":\"9247631\",\"name\":\"M. N. Rizve\"},{\"authorId\":\"2935412\",\"name\":\"U. Demir\"},{\"authorId\":\"82021814\",\"name\":\"Praveen Tirupattur\"},{\"authorId\":\"1564031469\",\"name\":\"A. J. Rana\"},{\"authorId\":\"7839191\",\"name\":\"K. Duarte\"},{\"authorId\":\"27058669\",\"name\":\"I. Dave\"},{\"authorId\":\"2116440\",\"name\":\"Y. Rawat\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"beb5336d3babd2307887fd7ac7db5d946160f8a1\",\"title\":\"Gabriella: An Online System for Real-Time Activity Detection in Untrimmed Security Videos\",\"url\":\"https://www.semanticscholar.org/paper/beb5336d3babd2307887fd7ac7db5d946160f8a1\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2011.13202\",\"authors\":[{\"authorId\":\"2029244883\",\"name\":\"Soroosh Poorgholi\"},{\"authorId\":\"50311569\",\"name\":\"O. Kayhan\"},{\"authorId\":\"1738975\",\"name\":\"J. C. V. Gemert\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5960bbc43b3fddde32a9f57f8821f7f978343de4\",\"title\":\"t-EVA: Time-Efficient t-SNE Video Annotation\",\"url\":\"https://www.semanticscholar.org/paper/5960bbc43b3fddde32a9f57f8821f7f978343de4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.01148\",\"authors\":[{\"authorId\":\"2804902\",\"name\":\"M. M. Islam\"},{\"authorId\":\"32229358\",\"name\":\"Tariq Iqbal\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ab3f612125a13410373c33600abd3fccdf79ce31\",\"title\":\"HAMLET: A Hierarchical Multimodal Attention-based Human Activity Recognition Algorithm\",\"url\":\"https://www.semanticscholar.org/paper/ab3f612125a13410373c33600abd3fccdf79ce31\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.10937\",\"authors\":[{\"authorId\":\"39360892\",\"name\":\"Q. Huang\"},{\"authorId\":\"145984817\",\"name\":\"Yu Xiong\"},{\"authorId\":\"36290866\",\"name\":\"Anyi Rao\"},{\"authorId\":\"1557390077\",\"name\":\"Jiaze Wang\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1007/978-3-030-58548-8_41\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"0732df185bdfcb9c908ec30bb441252593f58875\",\"title\":\"MovieNet: A Holistic Dataset for Movie Understanding\",\"url\":\"https://www.semanticscholar.org/paper/0732df185bdfcb9c908ec30bb441252593f58875\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2008.08360\",\"authors\":[{\"authorId\":\"71563120\",\"name\":\"Junyan Wang\"},{\"authorId\":null,\"name\":\"Yang Bai\"},{\"authorId\":\"144325904\",\"name\":\"Yang Long\"},{\"authorId\":\"48188132\",\"name\":\"Bing-zhang Hu\"},{\"authorId\":\"94418819\",\"name\":\"Zhenhua Chai\"},{\"authorId\":\"1585407535\",\"name\":\"Yu Guan\"},{\"authorId\":\"49141839\",\"name\":\"Xiaolin Wei\"}],\"doi\":\"10.1145/3394171.3414064\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"66981f61c10395a8661585c48f5d3f445dbeaea8\",\"title\":\"Query Twice: Dual Mixture Attention Meta Learning for Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/66981f61c10395a8661585c48f5d3f445dbeaea8\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152142657\",\"name\":\"Y. Tian\"},{\"authorId\":\"1825799769\",\"name\":\"Guangzhao Zhai\"},{\"authorId\":\"97709070\",\"name\":\"Z. Gao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5768e26731fb55edced4193596f6a470d0029ce6\",\"title\":\"Video-ception Network: Towards Multi-Scale Efficient Asymmetric Spatial-Temporal Interactions\",\"url\":\"https://www.semanticscholar.org/paper/5768e26731fb55edced4193596f6a470d0029ce6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.06809\",\"authors\":[{\"authorId\":\"9435157\",\"name\":\"Ehsan Asali\"},{\"authorId\":\"1646641382\",\"name\":\"Farzan Shenavarmasouleh\"},{\"authorId\":\"3261667\",\"name\":\"F. Mohammadi\"},{\"authorId\":\"153046351\",\"name\":\"P. Suresh\"},{\"authorId\":\"1712033\",\"name\":\"H. Arabnia\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8eda77ac0d52cd89a49e03081832765fccd8a228\",\"title\":\"DeepMSRF: A novel Deep Multimodal Speaker Recognition framework with Feature selection\",\"url\":\"https://www.semanticscholar.org/paper/8eda77ac0d52cd89a49e03081832765fccd8a228\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"88470948\",\"name\":\"Y. Kim\"},{\"authorId\":\"2487892\",\"name\":\"Sungeun Hong\"},{\"authorId\":\"3160154\",\"name\":\"Donghyeon Cho\"},{\"authorId\":\"121416659\",\"name\":\"H. Park\"},{\"authorId\":\"9352814\",\"name\":\"Priyadarshini Panda\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7170952d0d6ded78708be7aca86e630089dcdb88\",\"title\":\"Domain Adaptation without Source Data\",\"url\":\"https://www.semanticscholar.org/paper/7170952d0d6ded78708be7aca86e630089dcdb88\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.05224\",\"authors\":[{\"authorId\":\"3795834\",\"name\":\"J. Chung\"},{\"authorId\":\"1940024152\",\"name\":\"C. Wuu\"},{\"authorId\":\"1940708423\",\"name\":\"Hsuan-ru Yang\"},{\"authorId\":\"5068280\",\"name\":\"Yu-Wing Tai\"},{\"authorId\":\"2088295\",\"name\":\"C. Tang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d5635ee061af4321d5de2076d4834a4f96012551\",\"title\":\"HAA500: Human-Centric Atomic Action Dataset with Curated Videos\",\"url\":\"https://www.semanticscholar.org/paper/d5635ee061af4321d5de2076d4834a4f96012551\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.06193\",\"authors\":[{\"authorId\":\"1725438390\",\"name\":\"H. Tan\"},{\"authorId\":\"39336044\",\"name\":\"Ran Cheng\"},{\"authorId\":\"5405672\",\"name\":\"Shihua Huang\"},{\"authorId\":\"144778510\",\"name\":\"Cheng He\"},{\"authorId\":\"2154788\",\"name\":\"Changxiao Qiu\"},{\"authorId\":null,\"name\":\"Fan Yang\"},{\"authorId\":\"144389940\",\"name\":\"Ping Luo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"13dc820268c4f846fde3113f82f59930b5615c58\",\"title\":\"RelativeNAS: Relative Neural Architecture Search via Slow-Fast Learning\",\"url\":\"https://www.semanticscholar.org/paper/13dc820268c4f846fde3113f82f59930b5615c58\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.11783\",\"authors\":[{\"authorId\":\"3307885\",\"name\":\"Taesup Kim\"},{\"authorId\":\"87586093\",\"name\":\"S. Kim\"},{\"authorId\":\"1865800402\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fab4598dc40ee5840196dd2c85e62f1238f11a48\",\"title\":\"Visual Concept Reasoning Networks\",\"url\":\"https://www.semanticscholar.org/paper/fab4598dc40ee5840196dd2c85e62f1238f11a48\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.04755\",\"authors\":[{\"authorId\":\"3370667\",\"name\":\"Yongqin Xian\"},{\"authorId\":\"3443095\",\"name\":\"Bruno Korbar\"},{\"authorId\":\"3271933\",\"name\":\"M. Douze\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"2893664\",\"name\":\"Zeynep Akata\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f5f35c39f9e5979a97cd5d4affe40b7cd3f6dd45\",\"title\":\"Generalized Many-Way Few-Shot Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/f5f35c39f9e5979a97cd5d4affe40b7cd3f6dd45\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.07485\",\"authors\":[{\"authorId\":\"152949394\",\"name\":\"J. Tang\"},{\"authorId\":\"49597328\",\"name\":\"J. Xia\"},{\"authorId\":\"13812767\",\"name\":\"Xinzhi Mu\"},{\"authorId\":\"1560385163\",\"name\":\"Bo Pang\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"}],\"doi\":\"10.1007/978-3-030-58555-6_5\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e820578147cac31a6748c3f6ef2eeaccac066b41\",\"title\":\"Asynchronous Interaction Aggregation for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/e820578147cac31a6748c3f6ef2eeaccac066b41\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2006.07397\",\"authors\":[{\"authorId\":\"8277405\",\"name\":\"Brian Dolhansky\"},{\"authorId\":\"1749686057\",\"name\":\"Joanna Bitton\"},{\"authorId\":\"1417654107\",\"name\":\"Ben Pflaum\"},{\"authorId\":\"119590112\",\"name\":\"Jikuo Lu\"},{\"authorId\":\"1410913697\",\"name\":\"Russ Howes\"},{\"authorId\":\"51202149\",\"name\":\"Menglin Wang\"},{\"authorId\":\"1958793545\",\"name\":\"Cristian Canton Ferrer\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9790f95dc3ba6ecc516d8aca6f5cdff5dfcd5f35\",\"title\":\"The DeepFake Detection Challenge (DFDC) Dataset.\",\"url\":\"https://www.semanticscholar.org/paper/9790f95dc3ba6ecc516d8aca6f5cdff5dfcd5f35\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2005.10229\",\"authors\":[{\"authorId\":\"27575517\",\"name\":\"Dian Shao\"},{\"authorId\":\"145454812\",\"name\":\"Yue Zhao\"},{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/cvpr42600.2020.00081\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c09af0b1bdbd5d532b0d5d2ba2a2a12b29ba4f19\",\"title\":\"Intra- and Inter-Action Understanding via Temporal Action Parsing\",\"url\":\"https://www.semanticscholar.org/paper/c09af0b1bdbd5d532b0d5d2ba2a2a12b29ba4f19\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2002.02918\",\"authors\":[{\"authorId\":\"47968272\",\"name\":\"Li-Yu Daisy Liu\"},{\"authorId\":\"3143130\",\"name\":\"Dongyang Cai\"},{\"authorId\":\"49723003\",\"name\":\"J. Liu\"},{\"authorId\":\"145534763\",\"name\":\"N. Ding\"},{\"authorId\":\"1491094850\",\"name\":\"Tao Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aff765ae3c6be6c83c731ae1289facaa87dbb6b0\",\"title\":\"iqiyi Submission to ActivityNet Challenge 2019 Kinetics-700 challenge: Hierarchical Group-wise Attention\",\"url\":\"https://www.semanticscholar.org/paper/aff765ae3c6be6c83c731ae1289facaa87dbb6b0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2006270114\",\"name\":\"Michael Dorkenwald\"},{\"authorId\":\"21408156\",\"name\":\"U. B\\u00fcchler\"},{\"authorId\":\"1796707\",\"name\":\"B. Ommer\"}],\"doi\":\"10.1109/cvpr42600.2020.00828\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7f919769924e603833b96682f0fe0ebf4d7f2a1f\",\"title\":\"Unsupervised Magnification of Posture Deviations Across Subjects\",\"url\":\"https://www.semanticscholar.org/paper/7f919769924e603833b96682f0fe0ebf4d7f2a1f\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3145312\",\"name\":\"Chungkuk Yoo\"},{\"authorId\":\"146272390\",\"name\":\"B. Kang\"},{\"authorId\":\"1801812\",\"name\":\"Minsik Cho\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2176b5c088e454ae99eef7605d27c733466c2626\",\"title\":\"CONVOLUTIONAL NEURAL NETWORKS\",\"url\":\"https://www.semanticscholar.org/paper/2176b5c088e454ae99eef7605d27c733466c2626\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1905.13209\",\"authors\":[{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"},{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"2554604\",\"name\":\"M. Tan\"},{\"authorId\":\"145426908\",\"name\":\"A. Angelova\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a7afd4fdc9388b94ae5ff6aee062f8c5a9270ec1\",\"title\":\"AssembleNet: Searching for Multi-Stream Neural Connectivity in Video Architectures\",\"url\":\"https://www.semanticscholar.org/paper/a7afd4fdc9388b94ae5ff6aee062f8c5a9270ec1\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35199438\",\"name\":\"Joshua Gleason\"},{\"authorId\":\"145586343\",\"name\":\"Carlos D. Castillo\"},{\"authorId\":\"69416958\",\"name\":\"Ramalingam Chellappa\"}],\"doi\":\"10.1109/WACVW50321.2020.9096937\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b39d9873e95553406923f0bbd492ba70f6db7d83\",\"title\":\"Real-time Detection of Activities in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/b39d9873e95553406923f0bbd492ba70f6db7d83\",\"venue\":\"2020 IEEE Winter Applications of Computer Vision Workshops (WACVW)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46276931\",\"name\":\"Jiaojiao Li\"},{\"authorId\":\"1379683358\",\"name\":\"Ruxing Cui\"},{\"authorId\":\"46708584\",\"name\":\"B. Li\"},{\"authorId\":\"38785260\",\"name\":\"R. Song\"},{\"authorId\":\"7771261\",\"name\":\"Y. Li\"},{\"authorId\":\"144486974\",\"name\":\"Q. Du\"}],\"doi\":\"10.3390/rs11232859\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a56dc1a3cc8710db614de223c88197e76f7937f3\",\"title\":\"Hyperspectral Image Super-Resolution with 1D-2D Attentional Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/a56dc1a3cc8710db614de223c88197e76f7937f3\",\"venue\":\"Remote. Sens.\",\"year\":2019},{\"arxivId\":\"1903.05359\",\"authors\":[{\"authorId\":\"145883335\",\"name\":\"J. Long\"},{\"authorId\":\"46912588\",\"name\":\"W. Sun\"},{\"authorId\":\"1754077\",\"name\":\"Zhan Yang\"},{\"authorId\":\"78371785\",\"name\":\"Osolo Ian Raymond\"},{\"authorId\":\"49729707\",\"name\":\"B. Li\"}],\"doi\":\"10.3390/info10060203\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c6228558a333e6cfeb57c181010bf454459bf4c8\",\"title\":\"Dual Residual Network for Accurate Human Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c6228558a333e6cfeb57c181010bf454459bf4c8\",\"venue\":\"Inf.\",\"year\":2019},{\"arxivId\":\"2009.14639\",\"authors\":[{\"authorId\":\"1976000468\",\"name\":\"Okan Kopuklu\"},{\"authorId\":\"114991183\",\"name\":\"Stefan Hormann\"},{\"authorId\":\"32240536\",\"name\":\"Fabian Herzog\"},{\"authorId\":\"2277308\",\"name\":\"Hakan Cevikalp\"},{\"authorId\":\"46343645\",\"name\":\"G. Rigoll\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d197d0ab852c20122ffb1833fb29199ca77ce9bb\",\"title\":\"Dissected 3D CNNs: Temporal Skip Connections for Efficient Online Video Processing\",\"url\":\"https://www.semanticscholar.org/paper/d197d0ab852c20122ffb1833fb29199ca77ce9bb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30679763\",\"name\":\"Xuezhe Li\"},{\"authorId\":\"153109159\",\"name\":\"L. Wen\"},{\"authorId\":\"71563118\",\"name\":\"Jinjun Wang\"},{\"authorId\":\"2020817\",\"name\":\"Ming Zeng\"}],\"doi\":\"10.1109/ICAICA50127.2020.9182498\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5b679ccceefd9605661115e6e2391ad3c9076168\",\"title\":\"Spatio-temporal Collaborative Convolution for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5b679ccceefd9605661115e6e2391ad3c9076168\",\"venue\":\"2020 IEEE International Conference on Artificial Intelligence and Computer Applications (ICAICA)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92533069\",\"name\":\"L. Chi\"},{\"authorId\":\"2704823\",\"name\":\"Ze-Huan Yuan\"},{\"authorId\":\"145353089\",\"name\":\"Y. Mu\"},{\"authorId\":\"1697065\",\"name\":\"C. Wang\"}],\"doi\":\"10.1109/cvpr42600.2020.01182\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6dcb726b4e1afa5fa6f8684081f19508e61b45c0\",\"title\":\"Non-Local Neural Networks With Grouped Bilinear Attentional Transforms\",\"url\":\"https://www.semanticscholar.org/paper/6dcb726b4e1afa5fa6f8684081f19508e61b45c0\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2004.07514\",\"authors\":[{\"authorId\":\"8511875\",\"name\":\"Jonghwan Mun\"},{\"authorId\":\"72643925\",\"name\":\"Minsu Cho\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":\"10.1109/CVPR42600.2020.01082\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7e3d5b20e5df692deb80d9e100e4f34c1a8f8031\",\"title\":\"Local-Global Video-Text Interactions for Temporal Grounding\",\"url\":\"https://www.semanticscholar.org/paper/7e3d5b20e5df692deb80d9e100e4f34c1a8f8031\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2004.01398\",\"authors\":[{\"authorId\":\"48513712\",\"name\":\"Y. Li\"},{\"authorId\":\"102880425\",\"name\":\"Bin Ji\"},{\"authorId\":\"48203223\",\"name\":\"Xintian Shi\"},{\"authorId\":\"98697812\",\"name\":\"J. Zhang\"},{\"authorId\":\"48418655\",\"name\":\"Bin Kang\"},{\"authorId\":\"48170350\",\"name\":\"Limin Wang\"}],\"doi\":\"10.1109/cvpr42600.2020.00099\",\"intent\":[\"result\"],\"isInfluential\":true,\"paperId\":\"1ebeb84e2b8e1182a2b4821c906200ecc49ae187\",\"title\":\"TEA: Temporal Excitation and Aggregation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1ebeb84e2b8e1182a2b4821c906200ecc49ae187\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2006.11476\",\"authors\":[{\"authorId\":\"1390925224\",\"name\":\"Y. Yao\"},{\"authorId\":\"49046944\",\"name\":\"C. Liu\"},{\"authorId\":\"152504322\",\"name\":\"Dezhao Luo\"},{\"authorId\":\"9113781\",\"name\":\"Yin-qing Zhou\"},{\"authorId\":\"12605536\",\"name\":\"Qixiang Ye\"}],\"doi\":\"10.1109/cvpr42600.2020.00658\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"15e8b0a6366e29c7093ecf844eb40d03d8004abb\",\"title\":\"Video Playback Rate Perception for Self-Supervised Spatio-Temporal Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/15e8b0a6366e29c7093ecf844eb40d03d8004abb\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145944235\",\"name\":\"B. Mart\\u00ednez\"},{\"authorId\":\"1996209\",\"name\":\"Davide Modolo\"},{\"authorId\":null,\"name\":\"Yuanjun Xiong\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d9266a16e9213b7406968578b5f7a8dde2c15f43\",\"title\":\"Dribbling Basketball Shooting Basketball Dribbling Basketball Shooting Basketball Baking Cookies Peeling Potatos Baking Cookies Peeling Potatos Smoking Eating BurgerSmoking Eating\",\"url\":\"https://www.semanticscholar.org/paper/d9266a16e9213b7406968578b5f7a8dde2c15f43\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2008.13759\",\"authors\":[{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"67968b5b59b08ea1dd8a1266b422ee38e3ca8ad5\",\"title\":\"Online Spatiotemporal Action Detection and Prediction via Causal Representations\",\"url\":\"https://www.semanticscholar.org/paper/67968b5b59b08ea1dd8a1266b422ee38e3ca8ad5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121339452\",\"name\":\"Y. Tian\"},{\"authorId\":\"1810382\",\"name\":\"Zhaohui Che\"},{\"authorId\":\"116279011\",\"name\":\"Wenbo Bao\"},{\"authorId\":\"1509899757\",\"name\":\"Guangtao Zhai\"},{\"authorId\":\"97709070\",\"name\":\"Z. Gao\"}],\"doi\":\"10.1007/978-3-030-58568-6_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"27568c821ab008facaa57dc4f99217a294e196c4\",\"title\":\"Self-supervised Motion Representation via Scattering Local Motion Cues\",\"url\":\"https://www.semanticscholar.org/paper/27568c821ab008facaa57dc4f99217a294e196c4\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2006.07976\",\"authors\":[{\"authorId\":\"1720856277\",\"name\":\"Junting Pan\"},{\"authorId\":\"30733670\",\"name\":\"S. Chen\"},{\"authorId\":\"73423138\",\"name\":\"Zheng Shou\"},{\"authorId\":\"1388486428\",\"name\":\"Jing Shao\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f46458babf6ec837ff829e54c110d1c71f0945eb\",\"title\":\"Actor-Context-Actor Relation Network for Spatio-Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/f46458babf6ec837ff829e54c110d1c71f0945eb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1564031469\",\"name\":\"Aayush Jung Rana\"},{\"authorId\":\"82021814\",\"name\":\"Praveen Tirupattur\"},{\"authorId\":\"9247631\",\"name\":\"M. N. Rizve\"},{\"authorId\":\"7839191\",\"name\":\"K. Duarte\"},{\"authorId\":\"2935412\",\"name\":\"U. Demir\"},{\"authorId\":\"2116440\",\"name\":\"Y. Rawat\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d4b8626336566f34c7e1d17ddf7b144636812c18\",\"title\":\"An Online System for Real-Time Activity Detection in Untrimmed Surveillance Videos\",\"url\":\"https://www.semanticscholar.org/paper/d4b8626336566f34c7e1d17ddf7b144636812c18\",\"venue\":\"TRECVID\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390925314\",\"name\":\"Yue Yao\"},{\"authorId\":\"49981081\",\"name\":\"T. Wang\"},{\"authorId\":\"150121597\",\"name\":\"Heming Du\"},{\"authorId\":\"144436089\",\"name\":\"L. Zheng\"},{\"authorId\":\"27011207\",\"name\":\"T. Gedeon\"}],\"doi\":\"10.1145/3340555.3356101\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d2fb5712d639658310c28785f74e6f7f8cf65630\",\"title\":\"Spotting Visual Keywords from Temporal Sliding Windows\",\"url\":\"https://www.semanticscholar.org/paper/d2fb5712d639658310c28785f74e6f7f8cf65630\",\"venue\":\"ICMI\",\"year\":2019},{\"arxivId\":\"2006.15560\",\"authors\":[{\"authorId\":\"1391155455\",\"name\":\"Yin-Dong Zheng\"},{\"authorId\":\"46270766\",\"name\":\"Zhaoyang Liu\"},{\"authorId\":\"144720251\",\"name\":\"Tong Lu\"},{\"authorId\":\"29461006\",\"name\":\"L. Wang\"}],\"doi\":\"10.1109/TIP.2020.3007826\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3ee328e73acc9be44d874756dab4c13c65a835c0\",\"title\":\"Dynamic Sampling Networks for Efficient Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/3ee328e73acc9be44d874756dab4c13c65a835c0\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"2009.13087\",\"authors\":[{\"authorId\":\"3173493\",\"name\":\"Y. Li\"},{\"authorId\":\"2050979\",\"name\":\"Zhichao Lu\"},{\"authorId\":\"3182065\",\"name\":\"Xuehan Xiong\"},{\"authorId\":\"4240351\",\"name\":\"Jonathan Huang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c8bf6f41d6df5c6cdc6249aecfa1aab027f0c8e0\",\"title\":\"PERF-Net: Pose Empowered RGB-Flow Net\",\"url\":\"https://www.semanticscholar.org/paper/c8bf6f41d6df5c6cdc6249aecfa1aab027f0c8e0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.08041\",\"authors\":[{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"50557221\",\"name\":\"Chunhui Liu\"},{\"authorId\":\"2521776\",\"name\":\"B. Shuai\"},{\"authorId\":\"1805946041\",\"name\":\"Yi Zhu\"},{\"authorId\":\"48444479\",\"name\":\"Hao Chen\"},{\"authorId\":\"2397422\",\"name\":\"Joseph Tighe\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f0d55ca0b8f1639372e88479516a573e2bf2250b\",\"title\":\"NUTA: Non-uniform Temporal Aggregation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f0d55ca0b8f1639372e88479516a573e2bf2250b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2002.02651\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"},{\"authorId\":\"1739867\",\"name\":\"R. Veltkamp\"}],\"doi\":\"10.3390/app10186241\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c30d284bcba14754bbc020c7cf2688e2f831e97e\",\"title\":\"Learning Class Regularized Features for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c30d284bcba14754bbc020c7cf2688e2f831e97e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.09033\",\"authors\":[{\"authorId\":\"16323128\",\"name\":\"Guoxi Huang\"},{\"authorId\":\"1707271\",\"name\":\"Adrian G. Bors\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"215182fe19015d315cae9cd2c39e3a576b7193bf\",\"title\":\"Region-based Non-local Operation for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/215182fe19015d315cae9cd2c39e3a576b7193bf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.03949\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d7728ed8dd12e0ad64514ae9ec5d0bdf0576dadc\",\"title\":\"Right on Time: Multi-Temporal Convolutions for Human Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/d7728ed8dd12e0ad64514ae9ec5d0bdf0576dadc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.00317\",\"authors\":[{\"authorId\":\"3445691\",\"name\":\"Youngwan Lee\"},{\"authorId\":\"2645625\",\"name\":\"H. Kim\"},{\"authorId\":\"35323281\",\"name\":\"Kimin Yun\"},{\"authorId\":\"3035146\",\"name\":\"Jinyoung Moon\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"87b2f4542659801ab5b4baddbd88b2a7d1296726\",\"title\":\"Diverse Temporal Aggregation and Depthwise Spatiotemporal Factorization for Efficient Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/87b2f4542659801ab5b4baddbd88b2a7d1296726\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390626541\",\"name\":\"Ziming Liu\"},{\"authorId\":\"2041335607\",\"name\":\"Jinyang Li\"},{\"authorId\":\"47296615\",\"name\":\"Guangyu Gao\"},{\"authorId\":\"2041264362\",\"name\":\"Alex K. Qin\"}],\"doi\":\"10.1109/ACCESS.2020.3043386\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"16df18da2ab27ef1affeefe62ab842ce0f9d8520\",\"title\":\"Temporal Memory Network Towards Real-Time Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/16df18da2ab27ef1affeefe62ab842ce0f9d8520\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2008.10850\",\"authors\":[{\"authorId\":\"40951853\",\"name\":\"Manyuan Zhang\"},{\"authorId\":\"12920342\",\"name\":\"Guanglu Song\"},{\"authorId\":\"145798292\",\"name\":\"Hang Zhou\"},{\"authorId\":\"30752055\",\"name\":\"Y. Liu\"}],\"doi\":\"10.1007/978-3-030-58607-2_1\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a1027f7c27273c8c0aac30bbd31da87a0fa342db\",\"title\":\"Discriminability Distillation in Group Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/a1027f7c27273c8c0aac30bbd31da87a0fa342db\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2003.06845\",\"authors\":[{\"authorId\":\"1410309633\",\"name\":\"Fan Ma\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"},{\"authorId\":\"2815926\",\"name\":\"Shengxin Zha\"},{\"authorId\":\"38896301\",\"name\":\"G. Kundu\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"},{\"authorId\":\"73423138\",\"name\":\"Zheng Shou\"}],\"doi\":\"10.1007/978-3-030-58548-8_25\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"84d710727a9a5775ab4691a969f52bc3062325e2\",\"title\":\"SF-Net: Single-Frame Supervision for Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/84d710727a9a5775ab4691a969f52bc3062325e2\",\"venue\":\"ECCV\",\"year\":2020}],\"corpusId\":54463801,\"doi\":\"10.1109/ICCV.2019.00630\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":100,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"8b47b9c3c35b2b2a78bff7822605b3040f87d699\",\"references\":[{\"arxivId\":\"1705.06950\",\"authors\":[{\"authorId\":\"21028601\",\"name\":\"W. Kay\"},{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"11809518\",\"name\":\"Brian Zhang\"},{\"authorId\":\"38961760\",\"name\":\"Chloe Hillier\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"143740871\",\"name\":\"F. Viola\"},{\"authorId\":\"143897708\",\"name\":\"T. Green\"},{\"authorId\":\"2830305\",\"name\":\"T. Back\"},{\"authorId\":\"1820908\",\"name\":\"A. Natsev\"},{\"authorId\":\"2573615\",\"name\":\"Mustafa Suleyman\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6\",\"title\":\"The Kinetics Human Action Video Dataset\",\"url\":\"https://www.semanticscholar.org/paper/86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3558981\",\"name\":\"A. Derrington\"},{\"authorId\":\"4433870\",\"name\":\"P. Lennie\"}],\"doi\":\"10.1113/jphysiol.1984.sp015498\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"aa5056a68334da843a8e0194d9ce779a5f2eefb9\",\"title\":\"Spatial and temporal contrast sensitivities of neurones in lateral geniculate nucleus of macaque.\",\"url\":\"https://www.semanticscholar.org/paper/aa5056a68334da843a8e0194d9ce779a5f2eefb9\",\"venue\":\"The Journal of physiology\",\"year\":1984},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ross Girshick\"},{\"authorId\":null,\"name\":\"Ilija Radosavovic\"},{\"authorId\":null,\"name\":\"Georgia Gkioxari\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Piotr Doll\\u00e1r, and Kaiming He\",\"url\":\"\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40505180\",\"name\":\"M. Livingstone\"},{\"authorId\":\"2334226\",\"name\":\"D. Hubel\"}],\"doi\":\"10.1126/SCIENCE.3283936\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"cce9ff2a9df6d171e35c3532cae28f7e230e95bd\",\"title\":\"Segregation of form, color, movement, and depth: anatomy, physiology, and perception.\",\"url\":\"https://www.semanticscholar.org/paper/cce9ff2a9df6d171e35c3532cae28f7e230e95bd\",\"venue\":\"Science\",\"year\":1988},{\"arxivId\":\"1604.06573\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2016.213\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9d9aced120e530484609164c836da64548693484\",\"title\":\"Convolutional Two-Stream Network Fusion for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9d9aced120e530484609164c836da64548693484\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Will Kay\"},{\"authorId\":null,\"name\":\"Joao Carreira\"},{\"authorId\":null,\"name\":\"Karen Simonyan\"},{\"authorId\":null,\"name\":\"Brian Zhang\"},{\"authorId\":null,\"name\":\"Chloe Hillier\"},{\"authorId\":null,\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":null,\"name\":\"Fabio Viola\"},{\"authorId\":null,\"name\":\"Tim Green\"},{\"authorId\":null,\"name\":\"Trevor Back\"},{\"authorId\":null,\"name\":\"Paul Natsev\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"The kinetics human action video\",\"url\":\"\",\"venue\":\"dataset. arXiv:1705.06950,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"R. Girshick\"},{\"authorId\":null,\"name\":\"I. Radosavovic\"},{\"authorId\":null,\"name\":\"G. Gkioxari\"},{\"authorId\":null,\"name\":\"P. Doll\\u00e1r\"},{\"authorId\":null,\"name\":\"K. He\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Detectron. https://github.com/ facebookresearch/detectron, 2018\",\"url\":\"\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1612.03144\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1790580\",\"name\":\"Bharath Hariharan\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"}],\"doi\":\"10.1109/CVPR.2017.106\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b9b4e05faa194e5022edd9eb9dd07e3d675c2b36\",\"title\":\"Feature Pyramid Networks for Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/b9b4e05faa194e5022edd9eb9dd07e3d675c2b36\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1611.05431\",\"authors\":[{\"authorId\":\"1817030\",\"name\":\"Saining Xie\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"144035504\",\"name\":\"Zhuowen Tu\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"}],\"doi\":\"10.1109/CVPR.2017.634\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f6e0856b4a9199fa968ac00da612a9407b5cb85c\",\"title\":\"Aggregated Residual Transformations for Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/f6e0856b4a9199fa968ac00da612a9407b5cb85c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1502.03167\",\"authors\":[{\"authorId\":\"144147316\",\"name\":\"S. Ioffe\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d376d6978dad0374edfa6709c9556b42d3594d3\",\"title\":\"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\",\"url\":\"https://www.semanticscholar.org/paper/4d376d6978dad0374edfa6709c9556b42d3594d3\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1705.07750\",\"authors\":[{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2017.502\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"title\":\"Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset\",\"url\":\"https://www.semanticscholar.org/paper/b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1207.0580\",\"authors\":[{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"},{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1366de5bb112746a555e9c0cd00de3ad8628aea8\",\"title\":\"Improving neural networks by preventing co-adaptation of feature detectors\",\"url\":\"https://www.semanticscholar.org/paper/1366de5bb112746a555e9c0cd00de3ad8628aea8\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":\"1502.01852\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/ICCV.2015.123\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d6f2f611da110b5b5061731be3fc4c7f45d8ee23\",\"title\":\"Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification\",\"url\":\"https://www.semanticscholar.org/paper/d6f2f611da110b5b5061731be3fc4c7f45d8ee23\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Kaiming He\"},{\"authorId\":null,\"name\":\"Georgia Gkioxari\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Piotr Doll\\u00e1r, and Ross Girshick. Mask R-CNN\",\"url\":\"\",\"venue\":\"Proc. ICCV\",\"year\":2017},{\"arxivId\":\"1807.10066\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"2786693\",\"name\":\"C. Doersch\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6fb3940ddd658e549a111870f10ca77ba3c4cf37\",\"title\":\"A Better Baseline for AVA\",\"url\":\"https://www.semanticscholar.org/paper/6fb3940ddd658e549a111870f10ca77ba3c4cf37\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1703.06870\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2082991\",\"name\":\"Georgia Gkioxari\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/ICCV.2017.322\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ea99a5535388196d0d44be5b4d7dd02029a43bb2\",\"title\":\"Mask R-CNN\",\"url\":\"https://www.semanticscholar.org/paper/ea99a5535388196d0d44be5b4d7dd02029a43bb2\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2605935\",\"name\":\"D. Felleman\"},{\"authorId\":\"7549580\",\"name\":\"D. V. Van Essen\"}],\"doi\":\"10.1093/CERCOR/1.1.1\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c66b40e54fcb1d748aa04d82f497f24ac22d6129\",\"title\":\"Distributed hierarchical processing in the primate cerebral cortex.\",\"url\":\"https://www.semanticscholar.org/paper/c66b40e54fcb1d748aa04d82f497f24ac22d6129\",\"venue\":\"Cerebral cortex\",\"year\":1991},{\"arxivId\":\"1808.01340\",\"authors\":[{\"authorId\":\"153062108\",\"name\":\"J. Carreira\"},{\"authorId\":\"51210148\",\"name\":\"Eric Noland\"},{\"authorId\":\"1409990820\",\"name\":\"Andras Banki-Horvath\"},{\"authorId\":\"38961760\",\"name\":\"Chloe Hillier\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"62dccab9ab715f33761a5315746ed02e48eed2a0\",\"title\":\"A Short Note about Kinetics-600\",\"url\":\"https://www.semanticscholar.org/paper/62dccab9ab715f33761a5315746ed02e48eed2a0\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144639556\",\"name\":\"Graham W. Taylor\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"},{\"authorId\":\"2428034\",\"name\":\"C. Bregler\"}],\"doi\":\"10.1007/978-3-642-15567-3_11\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4d476b96be73fccc61f2076befbf5a468caa4180\",\"title\":\"Convolutional Learning of Spatio-temporal Features\",\"url\":\"https://www.semanticscholar.org/paper/4d476b96be73fccc61f2076befbf5a468caa4180\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":\"1604.01753\",\"authors\":[{\"authorId\":\"34280810\",\"name\":\"Gunnar A. Sigurdsson\"},{\"authorId\":\"2668759\",\"name\":\"G. Varol\"},{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1007/978-3-319-46448-0_31\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"21334d1aac5422da88780f8e24e181bfa15ef0e1\",\"title\":\"Hollywood in Homes: Crowdsourcing Data Collection for Activity Understanding\",\"url\":\"https://www.semanticscholar.org/paper/21334d1aac5422da88780f8e24e181bfa15ef0e1\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48950628\",\"name\":\"N. Dalal\"},{\"authorId\":\"1756114\",\"name\":\"B. Triggs\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1007/11744047_33\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"44f3ac3277c2eb6e5599739eb875888c46e21d4c\",\"title\":\"Human Detection Using Oriented Histograms of Flow and Appearance\",\"url\":\"https://www.semanticscholar.org/paper/44f3ac3277c2eb6e5599739eb875888c46e21d4c\",\"venue\":\"ECCV\",\"year\":2006},{\"arxivId\":\"1712.00636\",\"authors\":[{\"authorId\":\"2978413\",\"name\":\"Chao-Yuan Wu\"},{\"authorId\":\"1771307\",\"name\":\"M. Zaheer\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"1758550\",\"name\":\"R. Manmatha\"},{\"authorId\":\"46234526\",\"name\":\"Alex Smola\"},{\"authorId\":\"2562966\",\"name\":\"Philipp Kr\\u00e4henb\\u00fchl\"}],\"doi\":\"10.1109/CVPR.2018.00631\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9d98a956aadaff727e495b14b7c532d40ea49e16\",\"title\":\"Compressed Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9d98a956aadaff727e495b14b7c532d40ea49e16\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1711.08496\",\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"50112310\",\"name\":\"Alex Andonian\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1007/978-3-030-01246-5_49\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8ad12d3ee186403b856639b58d7797aa4b89a6c7\",\"title\":\"Temporal Relational Reasoning in Videos\",\"url\":\"https://www.semanticscholar.org/paper/8ad12d3ee186403b856639b58d7797aa4b89a6c7\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1608.03983\",\"authors\":[{\"authorId\":\"1678656\",\"name\":\"I. Loshchilov\"},{\"authorId\":\"144661829\",\"name\":\"F. Hutter\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b022f2a277a4bf5f42382e86e4380b96340b9e86\",\"title\":\"SGDR: Stochastic Gradient Descent with Warm Restarts\",\"url\":\"https://www.semanticscholar.org/paper/b022f2a277a4bf5f42382e86e4380b96340b9e86\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1711.07971\",\"authors\":[{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"}],\"doi\":\"10.1109/CVPR.2018.00813\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8899094797e82c5c185a0893896320ef77f60e64\",\"title\":\"Non-local Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/8899094797e82c5c185a0893896320ef77f60e64\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1504.08083\",\"authors\":[{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/ICCV.2015.169\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7ffdbc358b63378f07311e883dddacc9faeeaf4b\",\"title\":\"Fast R-CNN\",\"url\":\"https://www.semanticscholar.org/paper/7ffdbc358b63378f07311e883dddacc9faeeaf4b\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1817030\",\"name\":\"Saining Xie\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"1808244\",\"name\":\"J. Huang\"},{\"authorId\":\"144035504\",\"name\":\"Zhuowen Tu\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4fa0d73b8ba114578744c2ebaf610d2ca9694f45\",\"title\":\"Rethinking Spatiotemporal Feature Learning For Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/4fa0d73b8ba114578744c2ebaf610d2ca9694f45\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1812.05038\",\"authors\":[{\"authorId\":\"2978413\",\"name\":\"Chao-Yuan Wu\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"2681569\",\"name\":\"Haoqi Fan\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2562966\",\"name\":\"Philipp Kr\\u00e4henb\\u00fchl\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/CVPR.2019.00037\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"45cb2cbae5c0b4cc52e524cc191a2f8db674ed42\",\"title\":\"Long-Term Feature Banks for Detailed Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/45cb2cbae5c0b4cc52e524cc191a2f8db674ed42\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1808.03766\",\"authors\":[{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"},{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"19198894\",\"name\":\"Humam Alwassel\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"8983218\",\"name\":\"S. Buch\"},{\"authorId\":\"3409955\",\"name\":\"C. D. Dao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5468c96e3846da23c26b59c28c313506bffbf7ce\",\"title\":\"The ActivityNet Large-Scale Activity Recognition Challenge 2018 Summary\",\"url\":\"https://www.semanticscholar.org/paper/5468c96e3846da23c26b59c28c313506bffbf7ce\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1762649\",\"name\":\"V. Rabaud\"},{\"authorId\":\"48524582\",\"name\":\"G. Cottrell\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"}],\"doi\":\"10.1109/VSPETS.2005.1570899\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9f1707caad72573633c2307fa26ec093e8f4bb03\",\"title\":\"Behavior recognition via sparse spatio-temporal features\",\"url\":\"https://www.semanticscholar.org/paper/9f1707caad72573633c2307fa26ec093e8f4bb03\",\"venue\":\"2005 IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance\",\"year\":2005},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"C Feichtenhofer\"},{\"authorId\":null,\"name\":\"H Fan\"},{\"authorId\":null,\"name\":\"J Malik\"},{\"authorId\":null,\"name\":\"K He\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"SlowFast networks for video recognition in ActivityNet challenge\",\"url\":\"\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":null,\"name\":\"Haoqi Fan\"},{\"authorId\":null,\"name\":\"Jitendra Malik\"},{\"authorId\":null,\"name\":\"Kaiming He\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"SlowFast networks for video recognition in ActivityNet challenge 2019\",\"url\":\"\",\"venue\":\"http://static.googleusercontent.com/ media/research.google.com/en//ava/2019/ fair_slowfast.pdf,\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/ICCV.2015.510\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"title\":\"Learning Spatiotemporal Features with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"134861178\",\"name\":\"Wei Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPRW.2009.5206848\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d2c733e34d48784a37d717fe43d9e93277a8c53e\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/d2c733e34d48784a37d717fe43d9e93277a8c53e\",\"venue\":\"2009 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2009},{\"arxivId\":\"1711.11248\",\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"4439383\",\"name\":\"Jamie Ray\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/CVPR.2018.00675\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"89c3050522a0bb9820c32dc7444e003ef0d3e2e4\",\"title\":\"A Closer Look at Spatiotemporal Convolutions for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/89c3050522a0bb9820c32dc7444e003ef0d3e2e4\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2880368\",\"name\":\"D. Essen\"},{\"authorId\":\"40373111\",\"name\":\"J. Gallant\"}],\"doi\":\"10.1016/0896-6273(94)90455-3\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e9ef2375669916e4084fe61982e4a208765d3a6a\",\"title\":\"Neural mechanisms of form and motion processing in the primate visual system\",\"url\":\"https://www.semanticscholar.org/paper/e9ef2375669916e4084fe61982e4a208765d3a6a\",\"venue\":\"Neuron\",\"year\":1994},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"C. Feichtenhofer\"},{\"authorId\":null,\"name\":\"H. Fan\"},{\"authorId\":null,\"name\":\"J. Malik\"},{\"authorId\":null,\"name\":\"K. He\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"SlowFast networks for video recognition\",\"url\":\"\",\"venue\":\"arXiv preprint arXiv:1812.03982,\",\"year\":2018},{\"arxivId\":\"1806.07754\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"2713759\",\"name\":\"M. M. Arzani\"},{\"authorId\":\"9456273\",\"name\":\"Rahman Yousefzadeh\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-030-01225-0_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"85fb0d6cc991cf49ebc4f506b5edd44214979f65\",\"title\":\"Spatio-Temporal Channel Correlation Networks for Action Classification\",\"url\":\"https://www.semanticscholar.org/paper/85fb0d6cc991cf49ebc4f506b5edd44214979f65\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Limin Wang\"},{\"authorId\":null,\"name\":\"Wei Li\"},{\"authorId\":null,\"name\":\"Wen Li\"},{\"authorId\":null,\"name\":\"Luc Van Gool\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Appearanceand-relation networks for video classification\",\"url\":\"\",\"venue\":\"In Proc. CVPR,\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"3502855\",\"name\":\"M. Marszalek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"3261451\",\"name\":\"Benjamin Rozenfeld\"}],\"doi\":\"10.1109/CVPR.2008.4587756\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f86767732f76f478d5845f2e59f99ba106e9265\",\"title\":\"Learning realistic human actions from movies\",\"url\":\"https://www.semanticscholar.org/paper/0f86767732f76f478d5845f2e59f99ba106e9265\",\"venue\":\"2008 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2539961\",\"name\":\"J. Huang\"},{\"authorId\":\"117481816\",\"name\":\"D. Mumford\"}],\"doi\":\"10.1109/CVPR.1999.786990\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c9001ca7266f67de55733477eeb48988481d7204\",\"title\":\"Statistics of natural images and models\",\"url\":\"https://www.semanticscholar.org/paper/c9001ca7266f67de55733477eeb48988481d7204\",\"venue\":\"Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149)\",\"year\":1999},{\"arxivId\":\"1705.08421\",\"authors\":[{\"authorId\":\"39599498\",\"name\":\"C. Gu\"},{\"authorId\":\"94567368\",\"name\":\"C. Sun\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"2997956\",\"name\":\"C. Pantofaru\"},{\"authorId\":\"144711958\",\"name\":\"D. Ross\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"1758054\",\"name\":\"Y. Li\"},{\"authorId\":\"2262946\",\"name\":\"S. Ricco\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"153652146\",\"name\":\"J. Malik\"}],\"doi\":\"10.1109/CVPR.2018.00633\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"54c7c3909c7e1e827befdbe8d2595a3b196ba1b8\",\"title\":\"AVA: A Video Dataset of Spatio-Temporally Localized Atomic Visual Actions\",\"url\":\"https://www.semanticscholar.org/paper/54c7c3909c7e1e827befdbe8d2595a3b196ba1b8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1706.02677\",\"authors\":[{\"authorId\":\"47316088\",\"name\":\"Priya Goyal\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"34837514\",\"name\":\"P. Noordhuis\"},{\"authorId\":\"39033676\",\"name\":\"L. Wesolowski\"},{\"authorId\":\"1717990\",\"name\":\"Aapo Kyrola\"},{\"authorId\":\"3609856\",\"name\":\"Andrew Tulloch\"},{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0d57ba12a6d958e178d83be4c84513f7e42b24e5\",\"title\":\"Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour\",\"url\":\"https://www.semanticscholar.org/paper/0d57ba12a6d958e178d83be4c84513f7e42b24e5\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1804.09066\",\"authors\":[{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"145264990\",\"name\":\"K. Singh\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1007/978-3-030-01216-8_43\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aa63893b34f523973d0692dc74ff22512daac322\",\"title\":\"ECO: Efficient Convolutional Network for Online Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/aa63893b34f523973d0692dc74ff22512daac322\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Bolei Zhou\"},{\"authorId\":null,\"name\":\"Alex Andonian\"},{\"authorId\":null,\"name\":\"Aude Oliva\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Compressed video action recognition Aggregated residual transformations for deep neural networks\",\"url\":\"\",\"venue\":\"Proc . CVPR\",\"year\":null},{\"arxivId\":\"1711.09125\",\"authors\":[{\"authorId\":\"119770705\",\"name\":\"L. Wang\"},{\"authorId\":\"48625175\",\"name\":\"W. Li\"},{\"authorId\":\"145344553\",\"name\":\"W. Li\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2018.00155\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e6b534d8838f92461a478a3e737b73e08db94748\",\"title\":\"Appearance-and-Relation Networks for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/e6b534d8838f92461a478a3e737b73e08db94748\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2013.441\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d721f4d64b8e722222c876f0a0f226ed49476347\",\"title\":\"Action Recognition with Improved Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/d721f4d64b8e722222c876f0a0f226ed49476347\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":\"1806.01810\",\"authors\":[{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1007/978-3-030-01228-1_25\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d7cbf2d3ea63d97b699cc04af98fea521459ee75\",\"title\":\"Videos as Space-Time Region Graphs\",\"url\":\"https://www.semanticscholar.org/paper/d7cbf2d3ea63d97b699cc04af98fea521459ee75\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1807.10982\",\"authors\":[{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"1781242\",\"name\":\"Abhinav Shrivastava\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1007/978-3-030-01252-6_20\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6b325af08a63bc8f94c39ae1c12509dce23d755c\",\"title\":\"Actor-Centric Relation Network\",\"url\":\"https://www.semanticscholar.org/paper/6b325af08a63bc8f94c39ae1c12509dce23d755c\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1711.10305\",\"authors\":[{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/ICCV.2017.590\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"024d037d46ae933c7e12fd16af61953c7161773a\",\"title\":\"Learning Spatio-Temporal Representation with Pseudo-3D Residual Networks\",\"url\":\"https://www.semanticscholar.org/paper/024d037d46ae933c7e12fd16af61953c7161773a\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"D. H. Hubel\"},{\"authorId\":null,\"name\":\"T. N. Wrisel\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Receptive fields and functional architecture in two non-striate visual areas of the cat\",\"url\":\"\",\"venue\":\"J. Neurophysiol,\",\"year\":1965},{\"arxivId\":\"1612.06371\",\"authors\":[{\"authorId\":\"34280810\",\"name\":\"Gunnar A. Sigurdsson\"},{\"authorId\":\"2038685\",\"name\":\"S. Divvala\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1109/CVPR.2017.599\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e61c8ec6e26df76c8f0a174740f86510a786c93b\",\"title\":\"Asynchronous Temporal Fields for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e61c8ec6e26df76c8f0a174740f86510a786c93b\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1406.2199\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"title\":\"Two-Stream Convolutional Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144538257\",\"name\":\"Y. Weiss\"},{\"authorId\":\"1689350\",\"name\":\"Eero P. Simoncelli\"},{\"authorId\":\"145358192\",\"name\":\"E. Adelson\"}],\"doi\":\"10.1038/nn0602-858\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4eda0e4608d35b62fb34a162d1de238caaed8faa\",\"title\":\"Motion illusions as optimal percepts\",\"url\":\"https://www.semanticscholar.org/paper/4eda0e4608d35b62fb34a162d1de238caaed8faa\",\"venue\":\"Nature Neuroscience\",\"year\":2002},{\"arxivId\":\"1907.06987\",\"authors\":[{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"51210148\",\"name\":\"Eric Noland\"},{\"authorId\":\"38961760\",\"name\":\"Chloe Hillier\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"84c0528cb2aa4bdacad989b5b43441161dd4ecda\",\"title\":\"A Short Note on the Kinetics-700 Human Action Dataset\",\"url\":\"https://www.semanticscholar.org/paper/84c0528cb2aa4bdacad989b5b43441161dd4ecda\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1806.10319\",\"authors\":[{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"50984378\",\"name\":\"F. Li\"},{\"authorId\":\"2273005\",\"name\":\"Qijie Zhao\"},{\"authorId\":\"144858226\",\"name\":\"Xiang Long\"},{\"authorId\":\"145413801\",\"name\":\"Y. Fu\"},{\"authorId\":\"35247507\",\"name\":\"Shilei Wen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10370545ea747c6adec26142dbfc499681876570\",\"title\":\"Exploiting Spatial-Temporal Modelling and Multi-Modal Fusion for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/10370545ea747c6adec26142dbfc499681876570\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145358192\",\"name\":\"E. Adelson\"},{\"authorId\":\"116003860\",\"name\":\"J. Bergen\"}],\"doi\":\"10.1364/JOSAA.2.000284\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"33ce6c2f2d5128be710fb3ddd8f1117758b9b4a9\",\"title\":\"Spatiotemporal energy models for the perception of motion.\",\"url\":\"https://www.semanticscholar.org/paper/33ce6c2f2d5128be710fb3ddd8f1117758b9b4a9\",\"venue\":\"Journal of the Optical Society of America. A, Optics and image science\",\"year\":1985},{\"arxivId\":\"1608.00859\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-319-46484-8_2\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"title\":\"Temporal Segment Networks: Towards Good Practices for Deep Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Daniel L Ruderman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"The statistics of natural images. Network: computation\",\"url\":\"\",\"venue\":\"in neural systems,\",\"year\":1994},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":\"1604.04494\",\"authors\":[{\"authorId\":\"2668759\",\"name\":\"G. Varol\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/TPAMI.2017.2712608\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"47e3ef70f2539386bcef604097fa9235246c6d53\",\"title\":\"Long-Term Temporal Convolutions for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/47e3ef70f2539386bcef604097fa9235246c6d53\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":\"1611.02155\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5f4d2f6ad967f7c9369c04e75cda08f12cb8afbd\",\"title\":\"Spatiotemporal Residual Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5f4d2f6ad967f7c9369c04e75cda08f12cb8afbd\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2909350\",\"name\":\"Alexander Kl\\u00e4ser\"},{\"authorId\":\"3502855\",\"name\":\"M. Marszalek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.5244/C.22.99\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"56e95f8efb7dbbc0b1820eaf365edc6f3b3f6719\",\"title\":\"A Spatio-Temporal Descriptor Based on 3D-Gradients\",\"url\":\"https://www.semanticscholar.org/paper/56e95f8efb7dbbc0b1820eaf365edc6f3b3f6719\",\"venue\":\"BMVC\",\"year\":2008},{\"arxivId\":\"1409.4842\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"46641766\",\"name\":\"W. Liu\"},{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"},{\"authorId\":\"48840704\",\"name\":\"Scott Reed\"},{\"authorId\":\"1838674\",\"name\":\"Dragomir Anguelov\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"39863668\",\"name\":\"Andrew Rabinovich\"}],\"doi\":\"10.1109/CVPR.2015.7298594\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"title\":\"Going deeper with convolutions\",\"url\":\"https://www.semanticscholar.org/paper/e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1506.01497\",\"authors\":[{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"144716314\",\"name\":\"J. Sun\"}],\"doi\":\"10.1109/TPAMI.2016.2577031\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"title\":\"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\",\"url\":\"https://www.semanticscholar.org/paper/424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1829021\",\"name\":\"D. Ruderman\"}],\"doi\":\"10.1088/0954-898X_5_4_006\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"13206b6ba3711a14a56cf1599ecb08c16f49061e\",\"title\":\"The statistics of natural images\",\"url\":\"https://www.semanticscholar.org/paper/13206b6ba3711a14a56cf1599ecb08c16f49061e\",\"venue\":\"\",\"year\":1994},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46401013\",\"name\":\"Jian-wen Jiang\"},{\"authorId\":\"153843000\",\"name\":\"Y. Cao\"},{\"authorId\":\"80834369\",\"name\":\"L. Song\"},{\"authorId\":\"50202110\",\"name\":\"Shiwei Zhang\"},{\"authorId\":\"51487081\",\"name\":\"Yunkai Li\"},{\"authorId\":\"70397730\",\"name\":\"Ziyao Xu\"},{\"authorId\":\"47506758\",\"name\":\"Q. Wu\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":null,\"name\":\"Chi Zhang\"},{\"authorId\":\"145844907\",\"name\":\"Gang Yu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4f968688dcdd8980399265de1996a00a62034913\",\"title\":\"Human Centric Spatio-Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/4f968688dcdd8980399265de1996a00a62034913\",\"venue\":\"\",\"year\":2018}],\"title\":\"SlowFast Networks for Video Recognition\",\"topics\":[{\"topic\":\"Gene regulatory network\",\"topicId\":\"22947\",\"url\":\"https://www.semanticscholar.org/topic/22947\"},{\"topic\":\"Channel capacity\",\"topicId\":\"3303\",\"url\":\"https://www.semanticscholar.org/topic/3303\"},{\"topic\":\"AVA Radio Company\",\"topicId\":\"3596393\",\"url\":\"https://www.semanticscholar.org/topic/3596393\"},{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"},{\"topic\":\"Kinesiology\",\"topicId\":\"113188\",\"url\":\"https://www.semanticscholar.org/topic/113188\"}],\"url\":\"https://www.semanticscholar.org/paper/8b47b9c3c35b2b2a78bff7822605b3040f87d699\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019}\n"