"{\"abstract\":\"Egocentric action anticipation consists in understanding which objects the camera wearer will interact with in the near future and which actions they will perform. We tackle the problem proposing an architecture able to anticipate actions at multiple temporal scales using two LSTMs to 1) summarize the past, and 2) formulate predictions about the future. The input video is processed considering three complimentary modalities: appearance (RGB), motion (optical flow) and objects (object-based features). Modality-specific predictions are fused using a novel Modality ATTention (MATT) mechanism which learns to weigh modalities in an adaptive fashion. Extensive evaluations on two large-scale benchmark datasets show that our method outperforms prior art by up to +7% on the challenging EPIC-Kitchens dataset including more than 2500 actions, and generalizes to EGTEA Gaze+. Our approach is also shown to generalize to the tasks of early action recognition and action recognition. Our method is ranked first in the public leaderboard of the EPIC-Kitchens egocentric action anticipation challenge 2019. Please see the project web page for code and additional details: http://iplab.dmi.unict.it/rulstm.\",\"arxivId\":\"1905.09035\",\"authors\":[{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\",\"url\":\"https://www.semanticscholar.org/author/1792681\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\",\"url\":\"https://www.semanticscholar.org/author/1729739\"}],\"citationVelocity\":12,\"citations\":[{\"arxivId\":\"2004.03548\",\"authors\":[{\"authorId\":\"49984891\",\"name\":\"Ceyuan Yang\"},{\"authorId\":\"121983635\",\"name\":\"Yinghao Xu\"},{\"authorId\":\"46865320\",\"name\":\"Jianping Shi\"},{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"}],\"doi\":\"10.1109/cvpr42600.2020.00067\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"10db26c80238d70ca51d8a5293d893b6f1dedc8b\",\"title\":\"Temporal Pyramid Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/10db26c80238d70ca51d8a5293d893b6f1dedc8b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2009.01142\",\"authors\":[{\"authorId\":\"41022481\",\"name\":\"Yazan Abu Farha\"},{\"authorId\":\"143969578\",\"name\":\"Qiuhong Ke\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d39c1a6ba3083510d9f697458a6bfdca1be27340\",\"title\":\"Long-Term Anticipation of Activities with Cycle Consistency\",\"url\":\"https://www.semanticscholar.org/paper/d39c1a6ba3083510d9f697458a6bfdca1be27340\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1909.06761\",\"authors\":[{\"authorId\":\"51463388\",\"name\":\"G. Kapidis\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"},{\"authorId\":\"8297919\",\"name\":\"E. V. Dam\"},{\"authorId\":\"144882447\",\"name\":\"L. Noldus\"},{\"authorId\":\"47329105\",\"name\":\"Remco C. Veltkamp\"}],\"doi\":\"10.1109/ICCVW.2019.00540\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8cca4d9e7831cad9d7b4e9693a1be9b6eaea8805\",\"title\":\"Multitask Learning to Improve Egocentric Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8cca4d9e7831cad9d7b4e9693a1be9b6eaea8805\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"2003.03530\",\"authors\":[{\"authorId\":\"2719454\",\"name\":\"W. Wang\"},{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":\"150352016\",\"name\":\"Yanzhou Su\"},{\"authorId\":\"144941515\",\"name\":\"Y. Qiao\"},{\"authorId\":\"48265260\",\"name\":\"Jian Cheng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2de59074948bca0c0a4919bba03229477f65e821\",\"title\":\"TTPP: Temporal Transformer with Progressive Prediction for Efficient Action Anticipation\",\"url\":\"https://www.semanticscholar.org/paper/2de59074948bca0c0a4919bba03229477f65e821\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34678431\",\"name\":\"F. Sener\"},{\"authorId\":\"1734802895\",\"name\":\"Dipika Singhania\"},{\"authorId\":\"144031869\",\"name\":\"A. Yao\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e77735f1131cdb42db5a03093e4d15ebce34d473\",\"title\":\"Temporal Aggregate Representations for Long Term Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/e77735f1131cdb42db5a03093e4d15ebce34d473\",\"venue\":\"ECCV 2020\",\"year\":2020},{\"arxivId\":\"2004.07711\",\"authors\":[{\"authorId\":\"1637242169\",\"name\":\"Guglielmo Camporese\"},{\"authorId\":\"29776698\",\"name\":\"Pasquale Coscia\"},{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"},{\"authorId\":\"1795847\",\"name\":\"Lamberto Ballan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"dc24772bf84d9ff92166d8f228284c4079619ed0\",\"title\":\"Knowledge Distillation for Action Anticipation via Label Smoothing\",\"url\":\"https://www.semanticscholar.org/paper/dc24772bf84d9ff92166d8f228284c4079619ed0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2001.04583\",\"authors\":[{\"authorId\":\"38661780\",\"name\":\"Tushar Nagarajan\"},{\"authorId\":\"48513679\",\"name\":\"Yanghao Li\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR42600.2020.00024\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7d8f6dd70e8c15105e52b5ac4666db7085689939\",\"title\":\"Ego-Topo: Environment Affordances From Egocentric Video\",\"url\":\"https://www.semanticscholar.org/paper/7d8f6dd70e8c15105e52b5ac4666db7085689939\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47842115\",\"name\":\"M. Liu\"},{\"authorId\":\"39578749\",\"name\":\"Siyu Tang\"},{\"authorId\":\"47002162\",\"name\":\"Y. Li\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c94aa2bff74824bb8c3adbd5c697d890d0e73620\",\"title\":\"Forecasting Human Object Interaction: Joint Prediction of Motor Attention and Egocentric Activity\",\"url\":\"https://www.semanticscholar.org/paper/c94aa2bff74824bb8c3adbd5c697d890d0e73620\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1596808016\",\"name\":\"Xiaohan Wang\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"50118837\",\"name\":\"Y. Wu\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1109/tpami.2020.3015894\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7401d3895e1cb78c34fa25db12409fdff56b1661\",\"title\":\"Symbiotic Attention for Egocentric Action Recognition with Object-centric Alignment.\",\"url\":\"https://www.semanticscholar.org/paper/7401d3895e1cb78c34fa25db12409fdff56b1661\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"2006.03201\",\"authors\":[{\"authorId\":\"51230038\",\"name\":\"Eadom Dessalene\"},{\"authorId\":\"2739186\",\"name\":\"Michael Maynord\"},{\"authorId\":\"39685196\",\"name\":\"Chinmaya Devaraj\"},{\"authorId\":\"1759899\",\"name\":\"C. Ferm\\u00fcller\"},{\"authorId\":\"1697493\",\"name\":\"Y. Aloimonos\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"50f9b0fb3448435f569e702aacc02bac4298d314\",\"title\":\"Egocentric Object Manipulation Graphs\",\"url\":\"https://www.semanticscholar.org/paper/50f9b0fb3448435f569e702aacc02bac4298d314\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.00626\",\"authors\":[{\"authorId\":\"47002659\",\"name\":\"Yanchao Li\"},{\"authorId\":\"1720749879\",\"name\":\"Miao Liu\"},{\"authorId\":\"50779871\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a48cde936f7dea115cbda99a08e12dbdf45d13fb\",\"title\":\"In the Eye of the Beholder: Gaze and Actions in First Person Video\",\"url\":\"https://www.semanticscholar.org/paper/a48cde936f7dea115cbda99a08e12dbdf45d13fb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.06123\",\"authors\":[{\"authorId\":\"35315206\",\"name\":\"Haziq Razali\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"254cce9a431a12f62f4939c0b972637b37e7f9ab\",\"title\":\"A Log-likelihood Regularized KL Divergence for Video Prediction with A 3D Convolutional Variational Recurrent Network\",\"url\":\"https://www.semanticscholar.org/paper/254cce9a431a12f62f4939c0b972637b37e7f9ab\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2006.00830\",\"authors\":[{\"authorId\":\"34678431\",\"name\":\"F. Sener\"},{\"authorId\":\"1734802895\",\"name\":\"Dipika Singhania\"},{\"authorId\":\"1803321310\",\"name\":\"Angela Yao\"}],\"doi\":\"10.1007/978-3-030-58517-4_10\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6c8f191fa7b5c51af0810b0996a0ef25b4db4d9a\",\"title\":\"Temporal Aggregate Representations for Long-Range Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/6c8f191fa7b5c51af0810b0996a0ef25b4db4d9a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145222076\",\"name\":\"Tianyu Zhang\"},{\"authorId\":\"2366119\",\"name\":\"Weiqing Min\"},{\"authorId\":\"27730334\",\"name\":\"Ying Zhu\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"},{\"authorId\":\"1696610\",\"name\":\"S. Jiang\"}],\"doi\":\"10.1145/3394171.3413964\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"10066d89b96b8baac518c994f23278b817994a12\",\"title\":\"An Egocentric Action Anticipation Framework via Fusing Intuition and Analysis\",\"url\":\"https://www.semanticscholar.org/paper/10066d89b96b8baac518c994f23278b817994a12\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1907.01172\",\"authors\":[{\"authorId\":\"4251916\",\"name\":\"C. Chang\"},{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"2068265\",\"name\":\"Danfei Xu\"},{\"authorId\":\"3419364\",\"name\":\"E. Adeli\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1007/978-3-030-58621-8_20\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"71992656ff50c56adcbe6e99fca7eecac446d70a\",\"title\":\"Procedure Planning in Instructional Videos\",\"url\":\"https://www.semanticscholar.org/paper/71992656ff50c56adcbe6e99fca7eecac446d70a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2010.06647\",\"authors\":[{\"authorId\":\"153634296\",\"name\":\"Matthew Hutchinson\"},{\"authorId\":\"74882299\",\"name\":\"Vijay Gadepally\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"65955a106905afb90a2a2fa74e48c6d6d597892f\",\"title\":\"Video Action Understanding: A Tutorial\",\"url\":\"https://www.semanticscholar.org/paper/65955a106905afb90a2a2fa74e48c6d6d597892f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Iuliia Kotseruba\"},{\"authorId\":null,\"name\":\"Amir Rasouli\"},{\"authorId\":null,\"name\":\"John K. Tsotsos\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6eed01d812c9355f2ee0f5737f8718b3ecbb17f9\",\"title\":\"Benchmark for Evaluating Pedestrian Action Prediction\",\"url\":\"https://www.semanticscholar.org/paper/6eed01d812c9355f2ee0f5737f8718b3ecbb17f9\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"2011.13341\",\"authors\":[{\"authorId\":\"1720749879\",\"name\":\"Miao Liu\"},{\"authorId\":\"2812134\",\"name\":\"D. Yang\"},{\"authorId\":\"2655217\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1813796\",\"name\":\"Zhaopeng Cui\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"},{\"authorId\":\"1831081930\",\"name\":\"Siyu Tang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7d1bfeb5084e0a275602fc67fa0ac60269c1719e\",\"title\":\"4D Human Body Capture from Egocentric Video via 3D Scene Grounding\",\"url\":\"https://www.semanticscholar.org/paper/7d1bfeb5084e0a275602fc67fa0ac60269c1719e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50118603\",\"name\":\"Y. Wu\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"144652817\",\"name\":\"Xiaohan Wang\"},{\"authorId\":\"7179962\",\"name\":\"Yan-qi Yang\"},{\"authorId\":\"144894837\",\"name\":\"F. Wu\"}],\"doi\":\"10.1109/TIP.2020.3040521\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"acfa6fcd7343c14e3f150c0541cc94e672cf1a73\",\"title\":\"Learning to Anticipate Egocentric Actions by Imagination\",\"url\":\"https://www.semanticscholar.org/paper/acfa6fcd7343c14e3f150c0541cc94e672cf1a73\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2021},{\"arxivId\":\"1911.10967\",\"authors\":[{\"authorId\":\"1720749879\",\"name\":\"Miao Liu\"},{\"authorId\":\"39578749\",\"name\":\"Siyu Tang\"},{\"authorId\":\"47002659\",\"name\":\"Yanchao Li\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1007/978-3-030-58452-8_41\",\"intent\":[\"result\"],\"isInfluential\":true,\"paperId\":\"994481d46df92709b61614f5e756e40df4117622\",\"title\":\"Forecasting Human-Object Interaction: Joint Prediction of Motor Attention and Actions in First Person Video\",\"url\":\"https://www.semanticscholar.org/paper/994481d46df92709b61614f5e756e40df4117622\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2001.07501\",\"authors\":[{\"authorId\":\"2719454\",\"name\":\"W. Wang\"},{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"48265260\",\"name\":\"Jian Cheng\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6b06383710f5dff3028db31d1497914d65888194\",\"title\":\"A Comprehensive Study on Temporal Modeling for Online Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/6b06383710f5dff3028db31d1497914d65888194\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72541556\",\"name\":\"X. Wang\"},{\"authorId\":\"41051809\",\"name\":\"Alireza Haji Fathaliyan\"},{\"authorId\":\"145577652\",\"name\":\"V. Santos\"}],\"doi\":\"10.3389/fnbot.2020.567571\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"467bc21ba8935685a98794fa15bc83638ec9626b\",\"title\":\"Toward Shared Autonomy Control Schemes for Human-Robot Systems: Action Primitive Recognition Using Eye Gaze Features\",\"url\":\"https://www.semanticscholar.org/paper/467bc21ba8935685a98794fa15bc83638ec9626b\",\"venue\":\"Frontiers in Neurorobotics\",\"year\":2020},{\"arxivId\":\"2006.13256\",\"authors\":[{\"authorId\":\"1677780022\",\"name\":\"Dima Damen\"},{\"authorId\":\"28798386\",\"name\":\"H. Doughty\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"},{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"48842721\",\"name\":\"Evangelos Kazakos\"},{\"authorId\":\"153155867\",\"name\":\"Jian Ma\"},{\"authorId\":\"3420479\",\"name\":\"D. Moltisanti\"},{\"authorId\":\"47077615\",\"name\":\"J. Munro\"},{\"authorId\":\"2682004\",\"name\":\"T. Perrett\"},{\"authorId\":\"50065546\",\"name\":\"W. Price\"},{\"authorId\":\"145032628\",\"name\":\"Michael Wray\"}],\"doi\":\"10.5523/bris.2g1n6qdydwa9u22shpxqzp0t8m\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6c1a80daadab9c3bc3fdf183c669070ba7a3fd37\",\"title\":\"Rescaling Egocentric Vision\",\"url\":\"https://www.semanticscholar.org/paper/6c1a80daadab9c3bc3fdf183c669070ba7a3fd37\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.00095\",\"authors\":[{\"authorId\":\"26902477\",\"name\":\"Amir Rasouli\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"9f28b8965e0e1dab3c38ea6c95a6a3ad60d83785\",\"title\":\"Deep Learning for Vision-based Prediction: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/9f28b8965e0e1dab3c38ea6c95a6a3ad60d83785\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2001.08740\",\"authors\":[{\"authorId\":\"2299381\",\"name\":\"Fanyi Xiao\"},{\"authorId\":\"144756076\",\"name\":\"Y. Lee\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"153652147\",\"name\":\"J. Malik\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"80685dc522d30b18f3feb97d6c977f71fa746325\",\"title\":\"Audiovisual SlowFast Networks for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/80685dc522d30b18f3feb97d6c977f71fa746325\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.13922\",\"authors\":[{\"authorId\":\"1612421029\",\"name\":\"Yicong Hong\"},{\"authorId\":\"1509240145\",\"name\":\"Qi Wu\"},{\"authorId\":\"35653798\",\"name\":\"Yuankai Qi\"},{\"authorId\":\"145112187\",\"name\":\"Cristian Rodriguez-Opazo\"},{\"authorId\":\"47873182\",\"name\":\"S. Gould\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d16bce335338372c1927f69d4b1f667a330b59d2\",\"title\":\"A Recurrent Vision-and-Language BERT for Navigation\",\"url\":\"https://www.semanticscholar.org/paper/d16bce335338372c1927f69d4b1f667a330b59d2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1912.00381\",\"authors\":[{\"authorId\":\"1756362\",\"name\":\"Swathikiran Sudhakaran\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"}],\"doi\":\"10.1109/cvpr42600.2020.00118\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"57cee868188127305f966a178ca22025b397d911\",\"title\":\"Gate-Shift Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/57cee868188127305f966a178ca22025b397d911\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020}],\"corpusId\":162168703,\"doi\":\"10.1109/ICCV.2019.00635\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":6,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"792829f263a523eedf1a8748ec23d25cf664c2b4\",\"references\":[{\"arxivId\":\"1504.08083\",\"authors\":[{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/ICCV.2015.169\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7ffdbc358b63378f07311e883dddacc9faeeaf4b\",\"title\":\"Fast R-CNN\",\"url\":\"https://www.semanticscholar.org/paper/7ffdbc358b63378f07311e883dddacc9faeeaf4b\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47683829\",\"name\":\"A. Fathi\"},{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1007/978-3-642-33718-5_23\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"985e1f2dc17db0d590de883cbf1e30535169cb1a\",\"title\":\"Learning to Recognize Daily Actions Using Gaze\",\"url\":\"https://www.semanticscholar.org/paper/985e1f2dc17db0d590de883cbf1e30535169cb1a\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1806522\",\"name\":\"H. Park\"},{\"authorId\":\"2351486\",\"name\":\"Jyh-Jing Hwang\"},{\"authorId\":\"39294088\",\"name\":\"Yedong Niu\"},{\"authorId\":\"46865129\",\"name\":\"J. Shi\"}],\"doi\":\"10.1109/CVPR.2016.508\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6abc95865cade4cd81eddaf1979f70115dc7bf37\",\"title\":\"Egocentric Future Localization\",\"url\":\"https://www.semanticscholar.org/paper/6abc95865cade4cd81eddaf1979f70115dc7bf37\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2909350\",\"name\":\"Alexander Kl\\u00e4ser\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"1689269\",\"name\":\"C. Liu\"}],\"doi\":\"10.1007/s11263-012-0594-8\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bbe0819a47a9f3f11dd34bb3ab44a997ef111088\",\"title\":\"Dense Trajectories and Motion Boundary Descriptors for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/bbe0819a47a9f3f11dd34bb3ab44a997ef111088\",\"venue\":\"International Journal of Computer Vision\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1382424098\",\"name\":\"\\u0422\\u0430\\u0440\\u0430\\u0441\\u0430 \\u0428\\u0435\\u0432\\u0447\\u0435\\u043d\\u043a\\u0430\"},{\"authorId\":\"1397452703\",\"name\":\"\\u0412\\u0430\\u0441\\u0438\\u043b\\u044f \\u041a\\u0430\\u0440\\u0430\\u0437\\u0456\\u043d\\u0430\"},{\"authorId\":\"1397452698\",\"name\":\"\\u041e\\u043b\\u0435\\u043a\\u0441\\u0430\\u043d\\u0434\\u0440\\u0430 \\u0411\\u043e\\u0433\\u043e\\u043c\\u043e\\u043b\\u044c\\u0446\\u044f\"}],\"doi\":\"10.1093/clinchem/60.1.283\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dedb1eaf13642fec867f4333ed4353f60aa2c38b\",\"title\":\"Quo vadis?\",\"url\":\"https://www.semanticscholar.org/paper/dedb1eaf13642fec867f4333ed4353f60aa2c38b\",\"venue\":\"Clinical chemistry\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2876810\",\"name\":\"Bilge Soran\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1809809\",\"name\":\"L. Shapiro\"}],\"doi\":\"10.1109/ICCV.2015.530\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f8ae17c3ef3754967b62f4a4bc34cfc2f6d93719\",\"title\":\"Generating Notifications for Missing Actions: Don't Forget to Turn the Lights Off!\",\"url\":\"https://www.semanticscholar.org/paper/f8ae17c3ef3754967b62f4a4bc34cfc2f6d93719\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2418491\",\"name\":\"M. Zhang\"},{\"authorId\":\"21007367\",\"name\":\"K. T. Ma\"},{\"authorId\":\"153239355\",\"name\":\"J. H. Lim\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":\"10.1109/CVPR.2017.377\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f95e349489aa48fc57494aab101d58c496cc35f5\",\"title\":\"Deep Future Gaze: Gaze Anticipation on Egocentric Videos Using Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/f95e349489aa48fc57494aab101d58c496cc35f5\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1698158\",\"name\":\"Minh Hoai Nguyen\"},{\"authorId\":\"143867160\",\"name\":\"F. Torre\"}],\"doi\":\"10.1007/s11263-013-0683-3\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b72756c4d4237a857e1a764c876e82a82edd128c\",\"title\":\"Max-Margin Early Event Detectors\",\"url\":\"https://www.semanticscholar.org/paper/b72756c4d4237a857e1a764c876e82a82edd128c\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49455017\",\"name\":\"Yipin Zhou\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/ICCV.2015.511\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d12c567768b401f8d7f1ad532a2b23320ca29b49\",\"title\":\"Temporal Perception and Prediction in Ego-Centric Video\",\"url\":\"https://www.semanticscholar.org/paper/d12c567768b401f8d7f1ad532a2b23320ca29b49\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66063679\",\"name\":\"Elsevier Sdol\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"79ea477048cb4c3116d0b001df5485069e8edcca\",\"title\":\"Journal of Visual Communication and Image Representation\",\"url\":\"https://www.semanticscholar.org/paper/79ea477048cb4c3116d0b001df5485069e8edcca\",\"venue\":\"\",\"year\":2009},{\"arxivId\":\"1904.05250\",\"authors\":[{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1742452\",\"name\":\"S. Battiato\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":\"10.1016/j.jvcir.2017.10.004\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b67282a73c79438095799de916bf44ae55f1d310\",\"title\":\"Next-active-object prediction from egocentric videos\",\"url\":\"https://www.semanticscholar.org/paper/b67282a73c79438095799de916bf44ae55f1d310\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1742452\",\"name\":\"S. Battiato\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":\"10.1007/978-3-030-11021-5_24\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9d09701ea8c5809086fca2919400ff7f5b80ae30\",\"title\":\"Leveraging Uncertainty to Rethink Loss Functions and Evaluation Measures for Egocentric Action Anticipation\",\"url\":\"https://www.semanticscholar.org/paper/9d09701ea8c5809086fca2919400ff7f5b80ae30\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"1502.03167\",\"authors\":[{\"authorId\":\"144147316\",\"name\":\"S. Ioffe\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"4d376d6978dad0374edfa6709c9556b42d3594d3\",\"title\":\"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\",\"url\":\"https://www.semanticscholar.org/paper/4d376d6978dad0374edfa6709c9556b42d3594d3\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1612.07796\",\"authors\":[{\"authorId\":\"1974383\",\"name\":\"Nicholas Rhinehart\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"}],\"doi\":\"10.1109/ICCV.2017.399\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3f3610711c9000106b56b8d1d5941c49ee3a5f54\",\"title\":\"First-Person Activity Forecasting with Online Inverse Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/3f3610711c9000106b56b8d1d5941c49ee3a5f54\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1406.2199\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"title\":\"Two-Stream Convolutional Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/ICCV.2015.510\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"title\":\"Learning Spatiotemporal Features with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"R. Girshick\"},{\"authorId\":null,\"name\":\"I. Radosavovic\"},{\"authorId\":null,\"name\":\"G. Gkioxari\"},{\"authorId\":null,\"name\":\"P. Doll\\u00e1r\"},{\"authorId\":null,\"name\":\"K. He\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Detectron\",\"url\":\"\",\"venue\":\"https://github.com/ facebookresearch/detectron,\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"1843583\",\"name\":\"Zhefan Ye\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1109/CVPR.2015.7298625\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"08b1a3f8c6dc175b1e45818024def4ba311b21e6\",\"title\":\"Delving into egocentric actions\",\"url\":\"https://www.semanticscholar.org/paper/08b1a3f8c6dc175b1e45818024def4ba311b21e6\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"3205375\",\"name\":\"T. Lindeberg\"}],\"doi\":\"10.1109/ICCV.2003.1238378\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f90d79809325d2b78e35a79ecb372407f81b3993\",\"title\":\"Space-time interest points\",\"url\":\"https://www.semanticscholar.org/paper/f90d79809325d2b78e35a79ecb372407f81b3993\",\"venue\":\"Proceedings Ninth IEEE International Conference on Computer Vision\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144149886\",\"name\":\"Yu Cao\"},{\"authorId\":\"2089428\",\"name\":\"D. P. Barrett\"},{\"authorId\":\"21570451\",\"name\":\"A. Barbu\"},{\"authorId\":\"38052303\",\"name\":\"S. Narayanaswamy\"},{\"authorId\":\"2910174\",\"name\":\"Haonan Yu\"},{\"authorId\":\"38414598\",\"name\":\"A. Michaux\"},{\"authorId\":\"2933674\",\"name\":\"Yuewei Lin\"},{\"authorId\":\"1779136\",\"name\":\"S. Dickinson\"},{\"authorId\":\"1737754\",\"name\":\"J. Siskind\"},{\"authorId\":\"30102584\",\"name\":\"S. Wang\"}],\"doi\":\"10.1109/CVPR.2013.343\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"352cd022699c0b338f8951d94bd034642cfe5290\",\"title\":\"Recognize Human Activities from Partially Observed Videos\",\"url\":\"https://www.semanticscholar.org/paper/352cd022699c0b338f8951d94bd034642cfe5290\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"}],\"doi\":\"10.1007/978-3-319-10584-0_32\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fdfedec1341bdd2f0df6cc6f987d867f7173191c\",\"title\":\"Action-Reaction: Forecasting the Dynamics of Human Interaction\",\"url\":\"https://www.semanticscholar.org/paper/fdfedec1341bdd2f0df6cc6f987d867f7173191c\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1604.02115\",\"authors\":[{\"authorId\":\"48039353\",\"name\":\"Suriya Singh\"},{\"authorId\":\"145676235\",\"name\":\"C. Arora\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"}],\"doi\":\"10.1016/j.patcog.2016.07.031\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"45b6562ffd8df53de69e39c91b1f28abece412d9\",\"title\":\"Trajectory aligned features for first person action recognition\",\"url\":\"https://www.semanticscholar.org/paper/45b6562ffd8df53de69e39c91b1f28abece412d9\",\"venue\":\"Pattern Recognit.\",\"year\":2017},{\"arxivId\":\"1412.6505\",\"authors\":[{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"},{\"authorId\":\"1904850\",\"name\":\"B. Rothrock\"},{\"authorId\":\"1782162\",\"name\":\"L. Matthies\"}],\"doi\":\"10.1109/CVPR.2015.7298691\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0229829e9a1eed5769a2b5eccddcaa7cd9460b92\",\"title\":\"Pooled motion features for first-person videos\",\"url\":\"https://www.semanticscholar.org/paper/0229829e9a1eed5769a2b5eccddcaa7cd9460b92\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"},{\"authorId\":\"1753269\",\"name\":\"Brian D. Ziebart\"},{\"authorId\":\"1756566\",\"name\":\"J. Bagnell\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1007/978-3-642-33765-9_15\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0d8a5addbd17d2c7c8043d8877234675da19938a\",\"title\":\"Activity Forecasting\",\"url\":\"https://www.semanticscholar.org/paper/0d8a5addbd17d2c7c8043d8877234675da19938a\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":\"1604.06506\",\"authors\":[{\"authorId\":\"2287343\",\"name\":\"Roeland De Geest\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"3060081\",\"name\":\"A. Ghodrati\"},{\"authorId\":\"3245057\",\"name\":\"Zhenyang Li\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"}],\"doi\":\"10.1007/978-3-319-46454-1_17\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"574ab231627eadc1056162c38d0895f372121250\",\"title\":\"Online Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/574ab231627eadc1056162c38d0895f372121250\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8047613\",\"name\":\"Tahmida Mahmud\"},{\"authorId\":\"26559284\",\"name\":\"M. Hasan\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":\"10.1109/ICCV.2017.616\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"25403c52a7c3092866773b0e765ab55841d3cb67\",\"title\":\"Joint Prediction of Activity Labels and Starting Times in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/25403c52a7c3092866773b0e765ab55841d3cb67\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1726066\",\"name\":\"Ashesh Jain\"},{\"authorId\":\"1723948\",\"name\":\"H. Koppula\"},{\"authorId\":\"3282281\",\"name\":\"B. Raghavan\"},{\"authorId\":\"2645837\",\"name\":\"Shane Soh\"},{\"authorId\":\"1681995\",\"name\":\"A. Saxena\"}],\"doi\":\"10.1109/ICCV.2015.364\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"186336fb15a47ebdc6f0730d0cf4f56c58c5b906\",\"title\":\"Car that Knows Before You Do: Anticipating Maneuvers via Learning Temporal Driving Models\",\"url\":\"https://www.semanticscholar.org/paper/186336fb15a47ebdc6f0730d0cf4f56c58c5b906\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47683829\",\"name\":\"A. Fathi\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1109/ICCV.2011.6126269\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"bfc71c97f21b354ddfe69d17115e52db4fd4dce8\",\"title\":\"Understanding egocentric activities\",\"url\":\"https://www.semanticscholar.org/paper/bfc71c97f21b354ddfe69d17115e52db4fd4dce8\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"46331912\",\"name\":\"M. Liu\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1007/978-3-030-01228-1_38\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fa1723b216b1f41b085b62b450b7b0bd9f2fd281\",\"title\":\"In the Eye of Beholder: Joint Learning of Gaze and Actions in First Person Video\",\"url\":\"https://www.semanticscholar.org/paper/fa1723b216b1f41b085b62b450b7b0bd9f2fd281\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1807.11794\",\"authors\":[{\"authorId\":\"1756362\",\"name\":\"Swathikiran Sudhakaran\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"75fac714ccc1b616048c9bb6ca918c58317c56a1\",\"title\":\"Attention is All We Need: Nailing Down Object-centric Attention for Egocentric Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/75fac714ccc1b616048c9bb6ca918c58317c56a1\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2986395\",\"name\":\"Panna Felsen\"},{\"authorId\":\"33932184\",\"name\":\"Pulkit Agrawal\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/ICCV.2017.362\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"22e189a813529a8f43ad76b318207d9a4b6de71a\",\"title\":\"What will Happen Next? Forecasting Player Moves in Sports Videos\",\"url\":\"https://www.semanticscholar.org/paper/22e189a813529a8f43ad76b318207d9a4b6de71a\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1705.07328\",\"authors\":[{\"authorId\":\"2047692\",\"name\":\"Chenyou Fan\"},{\"authorId\":\"46664397\",\"name\":\"Jangwon Lee\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3a8f40af25b5b4a23639f18f9daefd39757a4f67\",\"title\":\"Forecasting Hand and Object Locations in Future Frames\",\"url\":\"https://www.semanticscholar.org/paper/3a8f40af25b5b4a23639f18f9daefd39757a4f67\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1708.05827\",\"authors\":[{\"authorId\":\"32970572\",\"name\":\"Kuo-Hao Zeng\"},{\"authorId\":\"41187419\",\"name\":\"Bokui (William) Shen\"},{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/ICCV.2017.326\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9c5cbbdaa76e10106c4ea12a17826bec88e5efc3\",\"title\":\"Visual Forecasting by Imitating Dynamics in Natural Sequences\",\"url\":\"https://www.semanticscholar.org/paper/9c5cbbdaa76e10106c4ea12a17826bec88e5efc3\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1705.07750\",\"authors\":[{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2017.502\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"title\":\"Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset\",\"url\":\"https://www.semanticscholar.org/paper/b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1711.08496\",\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"50112310\",\"name\":\"Alex Andonian\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1007/978-3-030-01246-5_49\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8ad12d3ee186403b856639b58d7797aa4b89a6c7\",\"title\":\"Temporal Relational Reasoning in Videos\",\"url\":\"https://www.semanticscholar.org/paper/8ad12d3ee186403b856639b58d7797aa4b89a6c7\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2398457\",\"name\":\"Ekaterina H. Spriggs\"},{\"authorId\":\"143867160\",\"name\":\"F. Torre\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1109/CVPRW.2009.5204354\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1aaf8e1e8164e8968f693a100fee4343580b1d61\",\"title\":\"Temporal segmentation and activity classification from first-person sensing\",\"url\":\"https://www.semanticscholar.org/paper/1aaf8e1e8164e8968f693a100fee4343580b1d61\",\"venue\":\"2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops\",\"year\":2009},{\"arxivId\":\"1605.03688\",\"authors\":[{\"authorId\":\"2238622\",\"name\":\"Minghuang Ma\"},{\"authorId\":\"2681569\",\"name\":\"Haoqi Fan\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"}],\"doi\":\"10.1109/CVPR.2016.209\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"444eba373d46c9f7d58cad74989ec9109b0d5219\",\"title\":\"Going Deeper into First-Person Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/444eba373d46c9f7d58cad74989ec9109b0d5219\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":\"10.1109/CVPR.2017.787\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"265cd694e8886a7f8413dd334662f269c6ac2bfc\",\"title\":\"Spatiotemporal Multiplier Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/265cd694e8886a7f8413dd334662f269c6ac2bfc\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1723948\",\"name\":\"H. Koppula\"},{\"authorId\":\"1681995\",\"name\":\"A. Saxena\"}],\"doi\":\"10.1109/TPAMI.2015.2430335\",\"intent\":[\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"50a00d4fa9bf2e7bff37bc944ac48b403f5eb097\",\"title\":\"Anticipating Human Activities Using Object Affordances for Reactive Robotic Response\",\"url\":\"https://www.semanticscholar.org/paper/50a00d4fa9bf2e7bff37bc944ac48b403f5eb097\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2287343\",\"name\":\"Roeland De Geest\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"}],\"doi\":\"10.1109/WACV.2018.00173\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f38813f1c9dac44dcb992ebe51c5ede66fd0f491\",\"title\":\"Modeling Temporal Structure with LSTM for Online Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/f38813f1c9dac44dcb992ebe51c5ede66fd0f491\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"2367683\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/CVPR.2016.18\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"932ac3707e1ed84ab67526692a1ef8f064f24ab5\",\"title\":\"Anticipating Visual Representations from Unlabeled Video\",\"url\":\"https://www.semanticscholar.org/paper/932ac3707e1ed84ab67526692a1ef8f064f24ab5\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1703.07023\",\"authors\":[{\"authorId\":\"3462343\",\"name\":\"M. Akbarian\"},{\"authorId\":\"35441838\",\"name\":\"Fatemehsadat Saleh\"},{\"authorId\":\"2862871\",\"name\":\"M. Salzmann\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"47773335\",\"name\":\"L. Petersson\"},{\"authorId\":\"145007997\",\"name\":\"L. Andersson\"}],\"doi\":\"10.1109/ICCV.2017.39\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"72c48390aebacc70c0e7d3b90e8199b139bfad9b\",\"title\":\"Encouraging LSTMs to Anticipate Actions Very Early\",\"url\":\"https://www.semanticscholar.org/paper/72c48390aebacc70c0e7d3b90e8199b139bfad9b\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1811.10698\",\"authors\":[{\"authorId\":\"1756362\",\"name\":\"Swathikiran Sudhakaran\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"}],\"doi\":\"10.1109/CVPR.2019.01019\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ed78a2671ef61c031759c01434678c282f23faec\",\"title\":\"LSTA: Long Short-Term Attention for Egocentric Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ed78a2671ef61c031759c01434678c282f23faec\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1707.04818\",\"authors\":[{\"authorId\":\"3029956\",\"name\":\"J. Gao\"},{\"authorId\":\"3469030\",\"name\":\"Zhenheng Yang\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.5244/C.31.92\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7ace4330a28ef74f489e581b62cfe21cc9bbc986\",\"title\":\"RED: Reinforced Encoder-Decoder Networks for Action Anticipation\",\"url\":\"https://www.semanticscholar.org/paper/7ace4330a28ef74f489e581b62cfe21cc9bbc986\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48039353\",\"name\":\"Suriya Singh\"},{\"authorId\":\"145676233\",\"name\":\"Chetan Arora\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"}],\"doi\":\"10.1109/CVPR.2016.287\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"28efff48583dfbcf8e6e552f5720278db1ae0fe3\",\"title\":\"First Person Action Recognition Using Deep Learned Descriptors\",\"url\":\"https://www.semanticscholar.org/paper/28efff48583dfbcf8e6e552f5720278db1ae0fe3\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1707.05733\",\"authors\":[{\"authorId\":\"7264115\",\"name\":\"Oier Mees\"},{\"authorId\":\"12428576\",\"name\":\"A. Eitel\"},{\"authorId\":\"1725973\",\"name\":\"W. Burgard\"}],\"doi\":\"10.1109/IROS.2016.7759048\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c2da6d47cd69a3820d00488da9b321f0f6f179b2\",\"title\":\"Choosing smartly: Adaptive multimodal fusion for object detection in changing environments\",\"url\":\"https://www.semanticscholar.org/paper/c2da6d47cd69a3820d00488da9b321f0f6f179b2\",\"venue\":\"2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2016},{\"arxivId\":\"1608.00859\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-319-46484-8_2\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"title\":\"Temporal Segment Networks: Towards Good Practices for Deep Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2863531\",\"name\":\"Shugao Ma\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"}],\"doi\":\"10.1109/CVPR.2016.214\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e578bd130eb2a2fdc573ec3f7d80f2186cb221fe\",\"title\":\"Learning Activity Progression in LSTMs for Activity Detection and Early Detection\",\"url\":\"https://www.semanticscholar.org/paper/e578bd130eb2a2fdc573ec3f7d80f2186cb221fe\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"G. Toderici A. Karpathy\"},{\"authorId\":null,\"name\":\"S. Shetty\"},{\"authorId\":null,\"name\":\"T. Leung\"},{\"authorId\":null,\"name\":\"R. Sukthankar\"},{\"authorId\":null,\"name\":\"L. Fei-Fei\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Recurrent neural networks for driver activity anticipation via sensory - fusion architecture First - person vision\",\"url\":\"\",\"venue\":\"Proceedings of the IEEE\",\"year\":null},{\"arxivId\":\"1604.06573\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2016.213\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d9aced120e530484609164c836da64548693484\",\"title\":\"Convolutional Two-Stream Network Fusion for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9d9aced120e530484609164c836da64548693484\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1409.0473\",\"authors\":[{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"title\":\"Neural Machine Translation by Jointly Learning to Align and Translate\",\"url\":\"https://www.semanticscholar.org/paper/fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"152821938\",\"name\":\"Sanketh Shetty\"},{\"authorId\":\"120906511\",\"name\":\"T. Leung\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2014.223\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"title\":\"Large-Scale Video Classification with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1109/ICCV.2011.6126349\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"76be79c45335db6d08efcde7843ae298765d4d63\",\"title\":\"Human activity prediction: Early recognition of ongoing activities from streaming videos\",\"url\":\"https://www.semanticscholar.org/paper/76be79c45335db6d08efcde7843ae298765d4d63\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2367683\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":\"10.1109/CVPR.2012.6248010\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9e81caf9dd31b893ebbee3970c312619b7eac7bf\",\"title\":\"Detecting activities of daily living in first-person camera views\",\"url\":\"https://www.semanticscholar.org/paper/9e81caf9dd31b893ebbee3970c312619b7eac7bf\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145252513\",\"name\":\"Dong Huang\"},{\"authorId\":\"2583890\",\"name\":\"Shitong Yao\"},{\"authorId\":\"46393411\",\"name\":\"Yi Wang\"},{\"authorId\":\"143867160\",\"name\":\"F. Torre\"}],\"doi\":\"10.1007/978-3-319-10578-9_27\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"16572c545384174f8136d761d2b0866e968120a8\",\"title\":\"Sequential Max-Margin Event Detectors\",\"url\":\"https://www.semanticscholar.org/paper/16572c545384174f8136d761d2b0866e968120a8\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9619757\",\"name\":\"Syed Zahir Bokhari\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"}],\"doi\":\"10.1007/978-3-319-54193-8_22\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4a82bc51c70e96c9c053a66100afb628d794ce13\",\"title\":\"Long-Term Activity Forecasting Using First-Person Vision\",\"url\":\"https://www.semanticscholar.org/paper/4a82bc51c70e96c9c053a66100afb628d794ce13\",\"venue\":\"ACCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"3502855\",\"name\":\"M. Marszalek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"3261451\",\"name\":\"Benjamin Rozenfeld\"}],\"doi\":\"10.1109/CVPR.2008.4587756\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0f86767732f76f478d5845f2e59f99ba106e9265\",\"title\":\"Learning realistic human actions from movies\",\"url\":\"https://www.semanticscholar.org/paper/0f86767732f76f478d5845f2e59f99ba106e9265\",\"venue\":\"2008 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Fathi\"},{\"authorId\":null,\"name\":\"A. Farhadi\"},{\"authorId\":null,\"name\":\"J. M. Rehg\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Understanding ego- Figure 10\",\"url\":\"\",\"venue\":\"Success action anticipation example qualitative results (best seen on screen). Figure 11. Failure action anticipation example qualitative results (best seen on screen). centric activities. In International Conference on Computer Vision, pages 407\\u2013414,\",\"year\":2011},{\"arxivId\":\"1804.00892\",\"authors\":[{\"authorId\":\"41022481\",\"name\":\"Yazan Abu Farha\"},{\"authorId\":\"32774629\",\"name\":\"A. Richard\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1109/CVPR.2018.00560\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"33b1843afc8b76314c9fbe11ca11c23fa0966c08\",\"title\":\"When will you do what? - Anticipating Temporal Occurrences of Activities\",\"url\":\"https://www.semanticscholar.org/paper/33b1843afc8b76314c9fbe11ca11c23fa0966c08\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1509.05016\",\"authors\":[{\"authorId\":\"1726066\",\"name\":\"Ashesh Jain\"},{\"authorId\":\"1899992\",\"name\":\"Avi Singh\"},{\"authorId\":\"1723948\",\"name\":\"H. Koppula\"},{\"authorId\":\"2645837\",\"name\":\"Shane Soh\"},{\"authorId\":\"1681995\",\"name\":\"A. Saxena\"}],\"doi\":\"10.1109/ICRA.2016.7487478\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7c71edddbad617f0b6fb6a0ad043440663703127\",\"title\":\"Recurrent Neural Networks for driver activity anticipation via sensory-fusion architecture\",\"url\":\"https://www.semanticscholar.org/paper/7c71edddbad617f0b6fb6a0ad043440663703127\",\"venue\":\"2016 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2016},{\"arxivId\":\"1807.04445\",\"authors\":[{\"authorId\":\"48754312\",\"name\":\"Pengfei Zhang\"},{\"authorId\":\"3280033\",\"name\":\"J. Xue\"},{\"authorId\":\"40093162\",\"name\":\"Cuiling Lan\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"},{\"authorId\":\"2687716\",\"name\":\"Zhanning Gao\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"}],\"doi\":\"10.1007/978-3-030-01240-3_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"04791b727d0b0820d110288546fa5d3fb5528a63\",\"title\":\"Adding Attentiveness to the Neurons in Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/04791b727d0b0820d110288546fa5d3fb5528a63\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2013.441\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d721f4d64b8e722222c876f0a0f226ed49476347\",\"title\":\"Action Recognition with Improved Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/d721f4d64b8e722222c876f0a0f226ed49476347\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":\"1705.01781\",\"authors\":[{\"authorId\":\"41172759\",\"name\":\"Federico Becattini\"},{\"authorId\":\"1789269\",\"name\":\"Tiberio Uricchio\"},{\"authorId\":\"1795847\",\"name\":\"Lamberto Ballan\"},{\"authorId\":\"2831602\",\"name\":\"Lorenzo Seidenari\"},{\"authorId\":\"8196487\",\"name\":\"A. D. Bimbo\"}],\"doi\":\"10.1145/3402447\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dc974c31201b6da32f48ef81ae5a9042512705fe\",\"title\":\"Am I Done? Predicting Action Progress in Videos\",\"url\":\"https://www.semanticscholar.org/paper/dc974c31201b6da32f48ef81ae5a9042512705fe\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1713941\",\"name\":\"Christopher Zach\"},{\"authorId\":\"1730097\",\"name\":\"T. Pock\"},{\"authorId\":\"144746444\",\"name\":\"H. Bischof\"}],\"doi\":\"10.1007/978-3-540-74936-3_22\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f6bbe9afab5fd61f36de5461e9e6a30ca462c7c\",\"title\":\"A Duality Based Approach for Realtime TV-L1 Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/0f6bbe9afab5fd61f36de5461e9e6a30ca462c7c\",\"venue\":\"DAGM-Symposium\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50339742\",\"name\":\"Krishna Kumar Singh\"},{\"authorId\":\"2789576\",\"name\":\"K. Fatahalian\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1109/WACV.2016.7477717\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7034b9a498b14cdb3362f65560a00b4fbee85df6\",\"title\":\"KrishnaCam: Using a longitudinal, single-person, egocentric dataset for scene understanding tasks\",\"url\":\"https://www.semanticscholar.org/paper/7034b9a498b14cdb3362f65560a00b4fbee85df6\",\"venue\":\"2016 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143928529\",\"name\":\"Tian Lan\"},{\"authorId\":\"2708745\",\"name\":\"Tsung-Chuan Chen\"},{\"authorId\":\"1702137\",\"name\":\"S. Savarese\"}],\"doi\":\"10.1007/978-3-319-10578-9_45\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e2edc655b678da8fac7db70c3389070eba8727c5\",\"title\":\"A Hierarchical Representation for Future Action Prediction\",\"url\":\"https://www.semanticscholar.org/paper/e2edc655b678da8fac7db70c3389070eba8727c5\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3407277\",\"name\":\"Adam Paszke\"},{\"authorId\":\"39793298\",\"name\":\"S. Gross\"},{\"authorId\":\"2127604\",\"name\":\"Soumith Chintala\"},{\"authorId\":\"114250963\",\"name\":\"G. Chanan\"},{\"authorId\":\"50064334\",\"name\":\"E. Yang\"},{\"authorId\":\"81505016\",\"name\":\"Zachary Devito\"},{\"authorId\":\"3370429\",\"name\":\"Zeming Lin\"},{\"authorId\":\"3050846\",\"name\":\"Alban Desmaison\"},{\"authorId\":\"3029482\",\"name\":\"L. Antiga\"},{\"authorId\":\"1977806\",\"name\":\"A. Lerer\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b36a5bb1707bb9c70025294b3a310138aae8327a\",\"title\":\"Automatic differentiation in PyTorch\",\"url\":\"https://www.semanticscholar.org/paper/b36a5bb1707bb9c70025294b3a310138aae8327a\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1733113\",\"name\":\"T. Kanade\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1109/JPROC.2012.2200554\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ac520a1addd2d5e64aa6379072b013729e856df4\",\"title\":\"First-Person Vision\",\"url\":\"https://www.semanticscholar.org/paper/ac520a1addd2d5e64aa6379072b013729e856df4\",\"venue\":\"Proceedings of the IEEE\",\"year\":2012},{\"arxivId\":\"1804.02748\",\"authors\":[{\"authorId\":\"145089978\",\"name\":\"D. Damen\"},{\"authorId\":\"28798386\",\"name\":\"H. Doughty\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"12387007\",\"name\":\"Evangelos Kazakos\"},{\"authorId\":\"3420479\",\"name\":\"D. Moltisanti\"},{\"authorId\":\"47077615\",\"name\":\"J. Munro\"},{\"authorId\":\"2682004\",\"name\":\"T. Perrett\"},{\"authorId\":\"50065546\",\"name\":\"W. Price\"},{\"authorId\":\"145032628\",\"name\":\"Michael Wray\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"fc50c9392fd23b6c88915177c6ae904a498aacea\",\"title\":\"Scaling Egocentric Vision: The EPIC-KITCHENS Dataset\",\"url\":\"https://www.semanticscholar.org/paper/fc50c9392fd23b6c88915177c6ae904a498aacea\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"},{\"authorId\":\"34459632\",\"name\":\"Thomas J. Fuchs\"},{\"authorId\":\"47839689\",\"name\":\"L. Xia\"},{\"authorId\":\"1705627\",\"name\":\"J. Aggarwal\"},{\"authorId\":\"1782162\",\"name\":\"L. Matthies\"}],\"doi\":\"10.1145/2696454.2696462\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3d7670e2a55b5a9fae609eed08777da71e0b92ee\",\"title\":\"Robot-Centric Activity Prediction from First-Person Videos: What Will They Do to Me?\",\"url\":\"https://www.semanticscholar.org/paper/3d7670e2a55b5a9fae609eed08777da71e0b92ee\",\"venue\":\"2015 10th ACM/IEEE International Conference on Human-Robot Interaction (HRI)\",\"year\":2015}],\"title\":\"What Would You Expect? Anticipating Egocentric Actions With Rolling-Unrolling LSTMs and Modality Attention\",\"topics\":[{\"topic\":\"Expect\",\"topicId\":\"1572873\",\"url\":\"https://www.semanticscholar.org/topic/1572873\"},{\"topic\":\"Optical flow\",\"topicId\":\"26430\",\"url\":\"https://www.semanticscholar.org/topic/26430\"},{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"},{\"topic\":\"Object-based language\",\"topicId\":\"156657\",\"url\":\"https://www.semanticscholar.org/topic/156657\"},{\"topic\":\"Physical object\",\"topicId\":\"253313\",\"url\":\"https://www.semanticscholar.org/topic/253313\"},{\"topic\":\"Attention deficit hyperactivity disorder\",\"topicId\":\"3786\",\"url\":\"https://www.semanticscholar.org/topic/3786\"},{\"topic\":\"Evaluation\",\"topicId\":\"46123\",\"url\":\"https://www.semanticscholar.org/topic/46123\"},{\"topic\":\"Rolling hash\",\"topicId\":\"1710692\",\"url\":\"https://www.semanticscholar.org/topic/1710692\"},{\"topic\":\"Silo (dataset)\",\"topicId\":\"130506\",\"url\":\"https://www.semanticscholar.org/topic/130506\"},{\"topic\":\"Regulatory Submission\",\"topicId\":\"200632\",\"url\":\"https://www.semanticscholar.org/topic/200632\"}],\"url\":\"https://www.semanticscholar.org/paper/792829f263a523eedf1a8748ec23d25cf664c2b4\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019}\n"