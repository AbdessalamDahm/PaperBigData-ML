"{\"abstract\":\"We present a method to analyze daily activities, such as meal preparation, using video from an egocentric camera. Our method performs inference about activities, actions, hands, and objects. Daily activities are a challenging domain for activity recognition which are well-suited to an egocentric approach. In contrast to previous activity recognition methods, our approach does not require pre-trained detectors for objects and hands. Instead we demonstrate the ability to learn a hierarchical model of an activity by exploiting the consistent appearance of objects, hands, and actions that results from the egocentric context. We show that joint modeling of activities, actions, and objects leads to superior performance in comparison to the case where they are considered independently. We introduce a novel representation of actions based on object-hand interactions and experimentally demonstrate the superior performance of our representation in comparison to standard activity representations such as bag of words.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"47683829\",\"name\":\"A. Fathi\",\"url\":\"https://www.semanticscholar.org/author/47683829\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\",\"url\":\"https://www.semanticscholar.org/author/143787583\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\",\"url\":\"https://www.semanticscholar.org/author/144177248\"}],\"citationVelocity\":40,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"2021805\",\"name\":\"V. Buso\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8add9c8bad1f479f81f9cfaaf7b0e210fc3d929c\",\"title\":\"Perceptual object of interest recognition : application to the interpretation of instrumental activities of daily living for dementia studies. (Reconnaissance perceptuelle des objets d'Int\\u00e9r\\u00eat : application \\u00e0 l'interpre'tation des activite's instrumentales de la vie quotidienne pour les \\u00e9tudes de de\",\"url\":\"https://www.semanticscholar.org/paper/8add9c8bad1f479f81f9cfaaf7b0e210fc3d929c\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1684052\",\"name\":\"G. Quellec\"},{\"authorId\":\"1727789\",\"name\":\"M. Lamard\"},{\"authorId\":\"1974436\",\"name\":\"B. Cochener\"},{\"authorId\":\"1721126\",\"name\":\"G. Cazuguel\"}],\"doi\":\"10.1109/TMI.2014.2340473\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5b39e103b979286bb921260c6c2ae861776fe49c\",\"title\":\"Real-Time Segmentation and Recognition of Surgical Tasks in Cataract Surgery Videos\",\"url\":\"https://www.semanticscholar.org/paper/5b39e103b979286bb921260c6c2ae861776fe49c\",\"venue\":\"IEEE Transactions on Medical Imaging\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1899753\",\"name\":\"Ryo Yonetani\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1109/CVPR.2016.288\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"16461bc1f06c781b5357cb1157248d28dc3672a0\",\"title\":\"Recognizing Micro-Actions and Reactions from Paired Egocentric Videos\",\"url\":\"https://www.semanticscholar.org/paper/16461bc1f06c781b5357cb1157248d28dc3672a0\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"},{\"authorId\":\"1742452\",\"name\":\"S. Battiato\"}],\"doi\":\"10.1109/THMS.2016.2612002\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"58e8c736cb0f1034c819a95a0b6260cc6ed474af\",\"title\":\"Recognizing Personal Locations From Egocentric Videos\",\"url\":\"https://www.semanticscholar.org/paper/58e8c736cb0f1034c819a95a0b6260cc6ed474af\",\"venue\":\"IEEE Transactions on Human-Machine Systems\",\"year\":2017},{\"arxivId\":\"1812.00312\",\"authors\":[{\"authorId\":\"50857765\",\"name\":\"Jayant Sharma\"},{\"authorId\":\"9737003\",\"name\":\"Zixing Wang\"},{\"authorId\":\"1732945\",\"name\":\"Alberto Speranzon\"},{\"authorId\":\"3100301\",\"name\":\"Vijay Venkataraman\"},{\"authorId\":\"1806522\",\"name\":\"Hyun Soo Park\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fccfd318e56b5c5ea6ffb93f422b40eade39661e\",\"title\":\"ECO: Egocentric Cognitive Mapping\",\"url\":\"https://www.semanticscholar.org/paper/fccfd318e56b5c5ea6ffb93f422b40eade39661e\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41051809\",\"name\":\"Alireza Haji Fathaliyan\"},{\"authorId\":\"145779951\",\"name\":\"X. Wang\"},{\"authorId\":\"145577651\",\"name\":\"V. J. Santos\"}],\"doi\":\"10.3389/frobt.2018.00025\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ea5088b97026812cf742343eb182b37e872524ac\",\"title\":\"Exploiting Three-Dimensional Gaze Tracking for Action Recognition During Bimanual Manipulation to Enhance Human\\u2013Robot Collaboration\",\"url\":\"https://www.semanticscholar.org/paper/ea5088b97026812cf742343eb182b37e872524ac\",\"venue\":\"Front. Robot. AI\",\"year\":2018},{\"arxivId\":\"2006.00626\",\"authors\":[{\"authorId\":\"47002659\",\"name\":\"Yanchao Li\"},{\"authorId\":\"1720749879\",\"name\":\"Miao Liu\"},{\"authorId\":\"50779871\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a48cde936f7dea115cbda99a08e12dbdf45d13fb\",\"title\":\"In the Eye of the Beholder: Gaze and Actions in First Person Video\",\"url\":\"https://www.semanticscholar.org/paper/a48cde936f7dea115cbda99a08e12dbdf45d13fb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"2485529\",\"name\":\"Michaela Regneri\"},{\"authorId\":\"1906895\",\"name\":\"M. Andriluka\"},{\"authorId\":\"40404576\",\"name\":\"S. Amin\"},{\"authorId\":\"1717560\",\"name\":\"Manfred Pinkal\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1007/978-3-642-33718-5_11\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8623fe8b087cedcaac276e313f8fed6f0dfccc33\",\"title\":\"Script Data for Attribute-Based Recognition of Composite Activities\",\"url\":\"https://www.semanticscholar.org/paper/8623fe8b087cedcaac276e313f8fed6f0dfccc33\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":\"1507.06120\",\"authors\":[{\"authorId\":\"38950290\",\"name\":\"Marc Bola\\u00f1os\"},{\"authorId\":\"2837527\",\"name\":\"Mariella Dimiccoli\"},{\"authorId\":\"143601910\",\"name\":\"P. Radeva\"}],\"doi\":\"10.1109/THMS.2016.2616296\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1d4c2dd3996cb3d87da6c35d72572637d3175ea5\",\"title\":\"Toward Storytelling From Visual Lifelogging: An Overview\",\"url\":\"https://www.semanticscholar.org/paper/1d4c2dd3996cb3d87da6c35d72572637d3175ea5\",\"venue\":\"IEEE Transactions on Human-Machine Systems\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1681842\",\"name\":\"Y. Liu\"},{\"authorId\":\"145708707\",\"name\":\"P. Wei\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/ICCV.2017.318\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"414c85e333a24456a3bb5b194d97e95e69175dea\",\"title\":\"Jointly Recognizing Object Fluents and Tasks in Egocentric Videos\",\"url\":\"https://www.semanticscholar.org/paper/414c85e333a24456a3bb5b194d97e95e69175dea\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143874453\",\"name\":\"Evonne Ng\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"2480239\",\"name\":\"Donglai Xiang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"918b67624d6f579567b7a191d01375339dd9298f\",\"title\":\"You 2 Me : Inferring Body Pose in Egocentric Video via First and Second Person Interactions by Evonne\",\"url\":\"https://www.semanticscholar.org/paper/918b67624d6f579567b7a191d01375339dd9298f\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153398746\",\"name\":\"I. Chakraborty\"},{\"authorId\":\"1783585\",\"name\":\"A. Elgammal\"},{\"authorId\":\"1945606\",\"name\":\"R. Burd\"}],\"doi\":\"10.1109/FG.2013.6553758\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d34e438f8d308e493cc6b51f6600ba2f3e77f92e\",\"title\":\"Video based activity recognition in trauma resuscitation\",\"url\":\"https://www.semanticscholar.org/paper/d34e438f8d308e493cc6b51f6600ba2f3e77f92e\",\"venue\":\"2013 10th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG)\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"103837492\",\"name\":\"Sergio R. Cruz\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":\"10.1007/978-3-030-30645-8_11\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"35b228c5c3f7ab81d1319fd70467b5d385e8ba49\",\"title\":\"Hand Detection Using Zoomed Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/35b228c5c3f7ab81d1319fd70467b5d385e8ba49\",\"venue\":\"ICIAP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32361885\",\"name\":\"H. Le\"},{\"authorId\":\"1787300\",\"name\":\"Sarah Clinch\"},{\"authorId\":\"2175489\",\"name\":\"C. Sas\"},{\"authorId\":\"1726630\",\"name\":\"Tilman Dingler\"},{\"authorId\":\"1801804\",\"name\":\"N. Henze\"},{\"authorId\":\"144396244\",\"name\":\"N. Davies\"}],\"doi\":\"10.1145/2858036.2858413\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6f2d5b6feb47f87b618185140d3ffd3490f56953\",\"title\":\"Impact of Video Summary Viewing on Episodic Memory Recall: Design Guidelines for Video Summarizations\",\"url\":\"https://www.semanticscholar.org/paper/6f2d5b6feb47f87b618185140d3ffd3490f56953\",\"venue\":\"CHI\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3313330\",\"name\":\"Gedas Bertasius\"},{\"authorId\":\"2251428\",\"name\":\"S. Yu\"},{\"authorId\":\"46865129\",\"name\":\"J. Shi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d91632867822fc95a00348aeca3a3ea7844ab35a\",\"title\":\"Exploiting Visual-Spatial First-Person Co-Occurrence for Action-Object Detection without Labels\",\"url\":\"https://www.semanticscholar.org/paper/d91632867822fc95a00348aeca3a3ea7844ab35a\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1711.11217\",\"authors\":[{\"authorId\":\"31485927\",\"name\":\"T. Yagi\"},{\"authorId\":\"11379939\",\"name\":\"Karttikeya Mangalam\"},{\"authorId\":\"1899753\",\"name\":\"Ryo Yonetani\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1109/CVPR.2018.00792\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0d1b8ac91ca95f5234d58602078aa13753f3c73b\",\"title\":\"Future Person Localization in First-Person Videos\",\"url\":\"https://www.semanticscholar.org/paper/0d1b8ac91ca95f5234d58602078aa13753f3c73b\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1507.02558\",\"authors\":[{\"authorId\":\"2964199\",\"name\":\"I. Gori\"},{\"authorId\":\"1705627\",\"name\":\"J. Aggarwal\"},{\"authorId\":\"1782162\",\"name\":\"L. Matthies\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1109/LRA.2016.2525002\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f612b31be7dc3f6e269fc1c0fba8e960642f037a\",\"title\":\"Multitype Activity Recognition in Robot-Centric Scenarios\",\"url\":\"https://www.semanticscholar.org/paper/f612b31be7dc3f6e269fc1c0fba8e960642f037a\",\"venue\":\"IEEE Robotics and Automation Letters\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1931096\",\"name\":\"A. Behera\"},{\"authorId\":\"145030629\",\"name\":\"Matthew Chapman\"},{\"authorId\":\"1703235\",\"name\":\"A. Cohn\"},{\"authorId\":\"1967104\",\"name\":\"David C. Hogg\"}],\"doi\":\"10.5220/0004655100220030\",\"intent\":[\"methodology\",\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"186498c4ac00f5db50c7ac45443015c569fb00a4\",\"title\":\"Egocentric activity recognition using Histograms of Oriented Pairwise Relations\",\"url\":\"https://www.semanticscholar.org/paper/186498c4ac00f5db50c7ac45443015c569fb00a4\",\"venue\":\"2014 International Conference on Computer Vision Theory and Applications (VISAPP)\",\"year\":2014},{\"arxivId\":\"2008.06046\",\"authors\":[{\"authorId\":\"72802941\",\"name\":\"C. Rockwell\"},{\"authorId\":\"1786435\",\"name\":\"David F. Fouhey\"}],\"doi\":\"10.1007/978-3-030-58520-4_31\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"77cc755f4d2a953a9c630f6900a2cfd696408d2d\",\"title\":\"Full-Body Awareness from Partial Observations\",\"url\":\"https://www.semanticscholar.org/paper/77cc755f4d2a953a9c630f6900a2cfd696408d2d\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1995028\",\"name\":\"K. Suma\"},{\"authorId\":\"71879392\",\"name\":\"G. Aditya\"},{\"authorId\":\"34356161\",\"name\":\"Snehasis Mukherjee\"}],\"doi\":\"10.1145/3293353.3293362\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dc5e3095ce86de685418fb7ca2062eab21214801\",\"title\":\"Activity Recognition in Egocentric Videos Using Bag of Key Action Units\",\"url\":\"https://www.semanticscholar.org/paper/dc5e3095ce86de685418fb7ca2062eab21214801\",\"venue\":\"ICVGIP\",\"year\":2018},{\"arxivId\":\"1904.05349\",\"authors\":[{\"authorId\":\"39307390\",\"name\":\"Bugra Tekin\"},{\"authorId\":\"2988774\",\"name\":\"Federica Bogo\"},{\"authorId\":\"1742208\",\"name\":\"M. Pollefeys\"}],\"doi\":\"10.1109/CVPR.2019.00464\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5b94a0ecfb144423ca7c5275a31d0d16f99c84d1\",\"title\":\"H+O: Unified Egocentric Recognition of 3D Hand-Object Poses and Interactions\",\"url\":\"https://www.semanticscholar.org/paper/5b94a0ecfb144423ca7c5275a31d0d16f99c84d1\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50398746\",\"name\":\"B. Xiong\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1007/978-3-319-24702-1_4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4a4b20a36846a5f5aed427a483a5a64c6870c145\",\"title\":\"Intentional Photos from an Unintentional Photographer: Detecting Snap Points in Egocentric Video with a Web Photo Prior\",\"url\":\"https://www.semanticscholar.org/paper/4a4b20a36846a5f5aed427a483a5a64c6870c145\",\"venue\":\"Mobile Cloud Visual Media Computing\",\"year\":2015},{\"arxivId\":\"2003.12352\",\"authors\":[{\"authorId\":\"1410197220\",\"name\":\"Ester Gonz\\u00e1lez-Sosa\"},{\"authorId\":\"143944667\",\"name\":\"P. P\\u00e9rez\"},{\"authorId\":\"1708502\",\"name\":\"R. Tolosana\"},{\"authorId\":\"3419528\",\"name\":\"Redouane Kachach\"},{\"authorId\":\"2345461\",\"name\":\"Alvaro Villegas\"}],\"doi\":\"10.1109/ACCESS.2020.3013016\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"da5666f1f2c7b78f1d56c1d7a7b26638655ec343\",\"title\":\"Enhanced Self-Perception in Mixed Reality: Egocentric Arm Segmentation and Database With Automatic Labeling\",\"url\":\"https://www.semanticscholar.org/paper/da5666f1f2c7b78f1d56c1d7a7b26638655ec343\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3391951\",\"name\":\"Ambuj Mehrish\"},{\"authorId\":\"2237008\",\"name\":\"P. Singh\"},{\"authorId\":\"152177405\",\"name\":\"Puneet Jain\"},{\"authorId\":\"1707477\",\"name\":\"A. V. Subramanyam\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":\"10.1109/TCSVT.2019.2929561\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"14bf1db075c29d4181a9c62a5afd12de0428f73d\",\"title\":\"Egocentric Analysis of Dash-Cam Videos for Vehicle Forensics\",\"url\":\"https://www.semanticscholar.org/paper/14bf1db075c29d4181a9c62a5afd12de0428f73d\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144756076\",\"name\":\"Y. Lee\"},{\"authorId\":\"34724702\",\"name\":\"Joydeep Ghosh\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2012.6247820\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"616a23ebf79e35033c84797993943013c5dde5a0\",\"title\":\"Discovering important people and objects for egocentric video summarization\",\"url\":\"https://www.semanticscholar.org/paper/616a23ebf79e35033c84797993943013c5dde5a0\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3207859\",\"name\":\"M. Z. Hameed\"},{\"authorId\":\"1403754530\",\"name\":\"Guillermo Garcia-Hernando\"}],\"doi\":\"10.1109/MVA.2015.7153236\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"43db479e992d865aec4181a5dc58eb5cdde27ee4\",\"title\":\"Novel spatio-temporal features for fingertip writing recognition in egocentric viewpoint\",\"url\":\"https://www.semanticscholar.org/paper/43db479e992d865aec4181a5dc58eb5cdde27ee4\",\"venue\":\"2015 14th IAPR International Conference on Machine Vision Applications (MVA)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47376654\",\"name\":\"Bo Xiong\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":\"10.1109/ICCV.2015.514\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cd1e7af7cc6d2dcac839848dd9efdbed87141df0\",\"title\":\"Storyline Representation of Egocentric Videos with an Applications to Story-Based Search\",\"url\":\"https://www.semanticscholar.org/paper/cd1e7af7cc6d2dcac839848dd9efdbed87141df0\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1910.06693\",\"authors\":[{\"authorId\":\"1901010\",\"name\":\"A. Cartas\"},{\"authorId\":\"145114663\",\"name\":\"J. Luque\"},{\"authorId\":\"143601910\",\"name\":\"P. Radeva\"},{\"authorId\":\"1380262503\",\"name\":\"C. Segura\"},{\"authorId\":\"2837527\",\"name\":\"Mariella Dimiccoli\"}],\"doi\":\"10.1109/ICCVW.2019.00548\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d1cf1ce95af190223519c1c9705251c15557afe4\",\"title\":\"Seeing and Hearing Egocentric Actions: How Much Can We Learn?\",\"url\":\"https://www.semanticscholar.org/paper/d1cf1ce95af190223519c1c9705251c15557afe4\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699609\",\"name\":\"Sinan Kalkan\"},{\"authorId\":\"2910193\",\"name\":\"Ahmet Iscen\"},{\"authorId\":null,\"name\":\"\\u00d6ZET YARDIMCI\"},{\"authorId\":null,\"name\":\"TEKNOLOJ\\u0130 S\\u0130STEMLER\\u0130NDE\"},{\"authorId\":null,\"name\":\"AKT\\u0130V\\u0130TE ANAL\\u0130Z\\u0130\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"406b64a2ede2b94d67d0e360058baac27fb6be2f\",\"title\":\"ACTIVITY ANALYSIS FOR ASSISTIVE SYSTEMS\",\"url\":\"https://www.semanticscholar.org/paper/406b64a2ede2b94d67d0e360058baac27fb6be2f\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35299091\",\"name\":\"Yansong Tang\"},{\"authorId\":\"145987219\",\"name\":\"Y. Tian\"},{\"authorId\":\"1697700\",\"name\":\"Jiwen Lu\"},{\"authorId\":\"144698893\",\"name\":\"J. Feng\"},{\"authorId\":\"49640256\",\"name\":\"J. Zhou\"}],\"doi\":\"10.1109/ICIP.2017.8296915\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8fb68bb0b02a16f3e55fc210d3342aeef4226e1f\",\"title\":\"Action recognition in RGB-D egocentric videos\",\"url\":\"https://www.semanticscholar.org/paper/8fb68bb0b02a16f3e55fc210d3342aeef4226e1f\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1742452\",\"name\":\"S. Battiato\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":\"10.1109/ICCVW.2017.280\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2e9cc64376ce44c6ef848a13aaab26e3878b9ec7\",\"title\":\"How Shall We Evaluate Egocentric Action Recognition?\",\"url\":\"https://www.semanticscholar.org/paper/2e9cc64376ce44c6ef848a13aaab26e3878b9ec7\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"2798750\",\"name\":\"Sven Bambach\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"},{\"authorId\":\"3207623\",\"name\":\"John M. Franchak\"},{\"authorId\":\"102595883\",\"name\":\"Chen Yu\"}],\"doi\":\"10.1109/CVPRW.2014.86\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"133b0d480a8fac7c7e0c7511b5bdb0dc7d387d42\",\"title\":\"This Hand Is My Hand: A Probabilistic Approach to Hand Disambiguation in Egocentric Video\",\"url\":\"https://www.semanticscholar.org/paper/133b0d480a8fac7c7e0c7511b5bdb0dc7d387d42\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition Workshops\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1688695\",\"name\":\"Volkmar Frinken\"},{\"authorId\":\"1962609\",\"name\":\"Yutaro Iwakiri\"},{\"authorId\":\"144293357\",\"name\":\"R. Ishida\"},{\"authorId\":\"2408609\",\"name\":\"Kensho Fujisaki\"},{\"authorId\":\"1809705\",\"name\":\"S. Uchida\"}],\"doi\":\"10.1109/ICPR.2014.512\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"071777bc168e9940bb04b207d3b061bbd5a0c01a\",\"title\":\"Improving Point of View Scene Recognition by Considering Textual Data\",\"url\":\"https://www.semanticscholar.org/paper/071777bc168e9940bb04b207d3b061bbd5a0c01a\",\"venue\":\"2014 22nd International Conference on Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1398693138\",\"name\":\"I. Gonz\\u00e1lez-D\\u00edaz\"},{\"authorId\":\"2393280\",\"name\":\"H. Boujut\"},{\"authorId\":\"2021805\",\"name\":\"V. Buso\"},{\"authorId\":\"1401651727\",\"name\":\"J. Benois-Pineau\"},{\"authorId\":\"1746076\",\"name\":\"Jean-Philippe Domenger\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e39470ed927dd6e08e8f33632ac43c3954c18e12\",\"title\":\"Saliency-based object recognition in video\",\"url\":\"https://www.semanticscholar.org/paper/e39470ed927dd6e08e8f33632ac43c3954c18e12\",\"venue\":\"\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47683829\",\"name\":\"A. Fathi\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1109/CVPR.2013.333\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"42f55af5a0c774d5140df601b39167f94062ad6a\",\"title\":\"Modeling Actions through State Changes\",\"url\":\"https://www.semanticscholar.org/paper/42f55af5a0c774d5140df601b39167f94062ad6a\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"147250363\",\"name\":\"K. P. Sanal Kumar\"},{\"authorId\":\"145711908\",\"name\":\"R. Bhavani\"}],\"doi\":\"10.1007/s10586-017-1131-x\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"62cf98ce9c28dad430810a59a527df50cebb65fd\",\"title\":\"Human activity recognition in egocentric video using PNN, SVM, kNN and SVM+kNN classifiers\",\"url\":\"https://www.semanticscholar.org/paper/62cf98ce9c28dad430810a59a527df50cebb65fd\",\"venue\":\"Cluster Computing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"2238622\",\"name\":\"Minghuang Ma\"},{\"authorId\":\"2650832\",\"name\":\"W. Ma\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"}],\"doi\":\"10.1109/CVPR.2015.7298666\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d3669356313e2afff6ab80181ff5cdf4885bd61d\",\"title\":\"How do we use our hands? Discovering a diverse set of common grasps\",\"url\":\"https://www.semanticscholar.org/paper/d3669356313e2afff6ab80181ff5cdf4885bd61d\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1709.01630\",\"authors\":[{\"authorId\":\"3313330\",\"name\":\"Gedas Bertasius\"},{\"authorId\":\"46865173\",\"name\":\"Jianbo Shi\"}],\"doi\":\"10.1109/ICCVW.2017.278\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5eb200cc606ec9290acdf4679fa4315c1bbe725d\",\"title\":\"Using Cross-Model EgoSupervision to Learn Cooperative Basketball Intention\",\"url\":\"https://www.semanticscholar.org/paper/5eb200cc606ec9290acdf4679fa4315c1bbe725d\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153823664\",\"name\":\"K. Nakamura\"},{\"authorId\":\"34149749\",\"name\":\"Serena Yeung\"},{\"authorId\":\"3304525\",\"name\":\"Alexandre Alahi\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2017.721\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"36e093e2c6142017e61c37200e915fd08d2456a1\",\"title\":\"Jointly Learning Energy Expenditures and Activities Using Egocentric Multimodal Signals\",\"url\":\"https://www.semanticscholar.org/paper/36e093e2c6142017e61c37200e915fd08d2456a1\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2235516\",\"name\":\"K. Matsuo\"},{\"authorId\":\"50295846\",\"name\":\"K. Yamada\"},{\"authorId\":\"50269200\",\"name\":\"S. Ueno\"},{\"authorId\":\"144889095\",\"name\":\"S. Naito\"}],\"doi\":\"10.1109/CVPRW.2014.87\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c75d5a3be94eb106000aae7049c89adc369c6e67\",\"title\":\"An Attention-Based Activity Recognition for Egocentric Video\",\"url\":\"https://www.semanticscholar.org/paper/c75d5a3be94eb106000aae7049c89adc369c6e67\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition Workshops\",\"year\":2014},{\"arxivId\":\"1612.08153\",\"authors\":[{\"authorId\":\"2599451\",\"name\":\"Shervin Ardeshir\"},{\"authorId\":\"8348054\",\"name\":\"Sandesh Sharma\"},{\"authorId\":\"8262483\",\"name\":\"Ali Broji\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6355f7fd956466e8e9f09b297e6cdd155d66740e\",\"title\":\"EgoReID: Cross-view Self-Identification and Human Re-identification in Egocentric and Surveillance Videos\",\"url\":\"https://www.semanticscholar.org/paper/6355f7fd956466e8e9f09b297e6cdd155d66740e\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"103837492\",\"name\":\"Sergio R. Cruz\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":\"10.1109/DICTA.2018.8615781\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"736be0fd88402e4170131e236807ee55b34bf977\",\"title\":\"Hand Detection using Deformable Part Models on an Egocentric Perspective\",\"url\":\"https://www.semanticscholar.org/paper/736be0fd88402e4170131e236807ee55b34bf977\",\"venue\":\"2018 Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"78461875\",\"name\":\"Maedeh Aghaei\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"61da412f446a99dc0eefd3e72753b4101a3b4e5d\",\"title\":\"Social signal processing from egocentric photo-streams\",\"url\":\"https://www.semanticscholar.org/paper/61da412f446a99dc0eefd3e72753b4101a3b4e5d\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145086911\",\"name\":\"A. Betancourt\"},{\"authorId\":\"2322579\",\"name\":\"Pietro Morerio\"},{\"authorId\":\"1689330\",\"name\":\"L. Marcenaro\"},{\"authorId\":\"145741020\",\"name\":\"E. Barakova\"},{\"authorId\":\"1736974\",\"name\":\"M. Rauterberg\"},{\"authorId\":\"9587913\",\"name\":\"C. Regazzoni\"}],\"doi\":\"10.1109/ICMEW.2015.7169784\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"91b76a3a1d3679b771f60592c81468021ec77fe0\",\"title\":\"Towards a unified framework for hand-based methods in First Person Vision\",\"url\":\"https://www.semanticscholar.org/paper/91b76a3a1d3679b771f60592c81468021ec77fe0\",\"venue\":\"2015 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2015},{\"arxivId\":\"1502.06648\",\"authors\":[{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"2485529\",\"name\":\"Michaela Regneri\"},{\"authorId\":\"40404576\",\"name\":\"S. Amin\"},{\"authorId\":\"1906895\",\"name\":\"M. Andriluka\"},{\"authorId\":\"1717560\",\"name\":\"Manfred Pinkal\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1007/s11263-015-0851-8\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"0138ef03aa5cf7bf7d0ce70b3f98876af022ffcd\",\"title\":\"Recognizing Fine-Grained and Composite Activities Using Hand-Centric Features and Script Data\",\"url\":\"https://www.semanticscholar.org/paper/0138ef03aa5cf7bf7d0ce70b3f98876af022ffcd\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145892975\",\"name\":\"S. Stein\"},{\"authorId\":\"6435894\",\"name\":\"S. Mckenna\"}],\"doi\":\"10.1016/j.cviu.2016.08.012\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fe9d96587c1d7e994fe8ad21e1ef1074c00c4a5c\",\"title\":\"Recognising complex activities with histograms of relative tracklets\",\"url\":\"https://www.semanticscholar.org/paper/fe9d96587c1d7e994fe8ad21e1ef1074c00c4a5c\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1830653\",\"name\":\"Noah Snavely\"},{\"authorId\":\"93575366\",\"name\":\"D. Huttenlocher\"},{\"authorId\":\"1717736\",\"name\":\"P. Fua\"}],\"doi\":\"10.1007/978-3-642-33718-5\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"df264c3e472b1d2be3bf3f28da88fb25e81e0cfa\",\"title\":\"Computer Vision \\u2013 ECCV 2012\",\"url\":\"https://www.semanticscholar.org/paper/df264c3e472b1d2be3bf3f28da88fb25e81e0cfa\",\"venue\":\"Lecture Notes in Computer Science\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33371794\",\"name\":\"Mouna Selmi\"},{\"authorId\":\"1398821307\",\"name\":\"Mounim A. El-Yacoubi\"}],\"doi\":\"10.1007/978-3-319-41267-2_76\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5137bfca521a890dc8597626b750146bdbded2aa\",\"title\":\"Multimodal Sequential Modeling and Recognition of Human Activities\",\"url\":\"https://www.semanticscholar.org/paper/5137bfca521a890dc8597626b750146bdbded2aa\",\"venue\":\"ICCHP\",\"year\":2016},{\"arxivId\":\"1611.05335\",\"authors\":[{\"authorId\":\"3313330\",\"name\":\"Gedas Bertasius\"},{\"authorId\":\"1806522\",\"name\":\"H. Park\"},{\"authorId\":\"2251428\",\"name\":\"S. Yu\"},{\"authorId\":\"46865129\",\"name\":\"J. Shi\"}],\"doi\":\"10.1109/ICCV.2017.216\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b5ebfb763053d3a66e6a4f36ed443dc4ab5ac877\",\"title\":\"Unsupervised Learning of Important Objects from First-Person Videos\",\"url\":\"https://www.semanticscholar.org/paper/b5ebfb763053d3a66e6a4f36ed443dc4ab5ac877\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1603.04908\",\"authors\":[{\"authorId\":\"3313330\",\"name\":\"Gedas Bertasius\"},{\"authorId\":\"1806522\",\"name\":\"H. Park\"},{\"authorId\":\"2251428\",\"name\":\"S. Yu\"},{\"authorId\":\"46865129\",\"name\":\"J. Shi\"}],\"doi\":\"10.15607/RSS.2017.XIII.012\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6021af236342c11c44f681d2aa21b0b46756236a\",\"title\":\"First Person Action-Object Detection with EgoNet\",\"url\":\"https://www.semanticscholar.org/paper/6021af236342c11c44f681d2aa21b0b46756236a\",\"venue\":\"Robotics: Science and Systems\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144207290\",\"name\":\"Rui Liu\"},{\"authorId\":\"47957301\",\"name\":\"X. Zhang\"}],\"doi\":\"10.1109/TAMD.2015.2504919\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3ff9d587893d510f5ecc62ce8c2db3bd0eced1f8\",\"title\":\"Understanding Human Behaviors with an Object Functional Role Perspective for Robotics\",\"url\":\"https://www.semanticscholar.org/paper/3ff9d587893d510f5ecc62ce8c2db3bd0eced1f8\",\"venue\":\"IEEE Transactions on Cognitive and Developmental Systems\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47528018\",\"name\":\"Weiming Zhang\"},{\"authorId\":\"11833179\",\"name\":\"Y. Huang\"},{\"authorId\":\"50239804\",\"name\":\"Wanting Yu\"},{\"authorId\":\"2059713\",\"name\":\"Xiaoshan Yang\"},{\"authorId\":\"115438571\",\"name\":\"W. Wang\"},{\"authorId\":\"152958348\",\"name\":\"J. Sang\"}],\"doi\":\"10.1145/3338533.3366592\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"3ffa55458f24787542860c8224cd97249836576c\",\"title\":\"Multimodal Attribute and Feature Embedding for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3ffa55458f24787542860c8224cd97249836576c\",\"venue\":\"MMAsia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153398746\",\"name\":\"I. Chakraborty\"},{\"authorId\":\"145697708\",\"name\":\"H. Cheng\"},{\"authorId\":\"2805147\",\"name\":\"O. Javed\"}],\"doi\":\"10.1145/2660505.2660506\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c645a804e2655e41e0686567db6c99b1406ea10b\",\"title\":\"Entity centric Feature Pooling for Complex Event Detection\",\"url\":\"https://www.semanticscholar.org/paper/c645a804e2655e41e0686567db6c99b1406ea10b\",\"venue\":\"HuEvent '14\",\"year\":2014},{\"arxivId\":\"2011.01519\",\"authors\":[{\"authorId\":\"3358340\",\"name\":\"Denis Tom\\u00e8\"},{\"authorId\":\"1914886\",\"name\":\"Thiemo Alldieck\"},{\"authorId\":\"151353735\",\"name\":\"Patrick Peluse\"},{\"authorId\":\"1403428213\",\"name\":\"Gerard Pons-Moll\"},{\"authorId\":\"3377447\",\"name\":\"L. Agapito\"},{\"authorId\":\"2863682\",\"name\":\"H. Badino\"},{\"authorId\":\"143867160\",\"name\":\"F. Torre\"}],\"doi\":\"10.1109/TPAMI.2020.3029700\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8d77d035a5cdccbd96e2779cdcf69c05808559d2\",\"title\":\"SelfPose: 3D Egocentric Pose Estimation from a Headset Mounted Camera\",\"url\":\"https://www.semanticscholar.org/paper/8d77d035a5cdccbd96e2779cdcf69c05808559d2\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"1803.01413\",\"authors\":[{\"authorId\":\"3313330\",\"name\":\"Gedas Bertasius\"},{\"authorId\":\"3490541\",\"name\":\"Aaron Chan\"},{\"authorId\":\"46865129\",\"name\":\"J. Shi\"}],\"doi\":\"10.1109/CVPR.2018.00617\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8bfa0c14c2ae48c1ee6b145008137e4d69688416\",\"title\":\"Egocentric Basketball Motion Planning from a Single First-Person Image\",\"url\":\"https://www.semanticscholar.org/paper/8bfa0c14c2ae48c1ee6b145008137e4d69688416\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40645942\",\"name\":\"Juan Sebastian Olier\"},{\"authorId\":\"9587913\",\"name\":\"C. Regazzoni\"},{\"authorId\":\"1689330\",\"name\":\"L. Marcenaro\"},{\"authorId\":\"1736974\",\"name\":\"M. Rauterberg\"}],\"doi\":\"10.1007/978-3-319-19258-1_39\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"89dcf3d6f42f1a2fcdb0c81982ac1ea9e4ce2339\",\"title\":\"Convolutional Neural Networks for Detecting and Mapping Crowds in First Person Vision Applications\",\"url\":\"https://www.semanticscholar.org/paper/89dcf3d6f42f1a2fcdb0c81982ac1ea9e4ce2339\",\"venue\":\"IWANN\",\"year\":2015},{\"arxivId\":\"1606.02031\",\"authors\":[{\"authorId\":\"145194973\",\"name\":\"C. Xu\"},{\"authorId\":\"2722143\",\"name\":\"L. Govindarajan\"},{\"authorId\":\"145874477\",\"name\":\"Li Cheng\"}],\"doi\":\"10.1016/j.patcog.2017.08.009\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3597dce344b088f913689abde927a59a0bedde48\",\"title\":\"Hand action detection from ego-centric depth sequences with error-correcting Hough transform\",\"url\":\"https://www.semanticscholar.org/paper/3597dce344b088f913689abde927a59a0bedde48\",\"venue\":\"Pattern Recognit.\",\"year\":2017},{\"arxivId\":\"1509.02094\",\"authors\":[{\"authorId\":\"1806522\",\"name\":\"H. Park\"},{\"authorId\":\"39294088\",\"name\":\"Yedong Niu\"},{\"authorId\":\"46865129\",\"name\":\"J. Shi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"37a4199e63312f7901af853998951883e52ab062\",\"title\":\"Future Localization from an Egocentric Depth Image\",\"url\":\"https://www.semanticscholar.org/paper/37a4199e63312f7901af853998951883e52ab062\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35429700\",\"name\":\"Panagiotis Giannakeris\"},{\"authorId\":\"2735095\",\"name\":\"Konstantinos Avgerinakis\"},{\"authorId\":\"3019137\",\"name\":\"S. Vrochidis\"},{\"authorId\":\"1715604\",\"name\":\"Y. Kompatsiaris\"}],\"doi\":\"10.1109/CBMI.2018.8516553\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"16b75e833ddde952708c2a1756231ab88aa48b8e\",\"title\":\"Activity Recognition from Wearable Cameras\",\"url\":\"https://www.semanticscholar.org/paper/16b75e833ddde952708c2a1756231ab88aa48b8e\",\"venue\":\"2018 International Conference on Content-Based Multimedia Indexing (CBMI)\",\"year\":2018},{\"arxivId\":\"1612.07796\",\"authors\":[{\"authorId\":\"1974383\",\"name\":\"Nicholas Rhinehart\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"}],\"doi\":\"10.1109/ICCV.2017.399\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3f3610711c9000106b56b8d1d5941c49ee3a5f54\",\"title\":\"First-Person Activity Forecasting with Online Inverse Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/3f3610711c9000106b56b8d1d5941c49ee3a5f54\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3321919\",\"name\":\"Gr\\u00e9gory Rogez\"},{\"authorId\":\"3150023\",\"name\":\"J. Supancic\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":\"10.1109/CVPR.2015.7299061\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b639cf6a3b418544870b565d491f2c967d641ae2\",\"title\":\"First-person pose recognition using egocentric workspaces\",\"url\":\"https://www.semanticscholar.org/paper/b639cf6a3b418544870b565d491f2c967d641ae2\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2514236\",\"name\":\"Peng-Ju Hsieh\"},{\"authorId\":\"1760870\",\"name\":\"Y. Lin\"},{\"authorId\":\"1805910\",\"name\":\"Yu-Hsiu Chen\"},{\"authorId\":\"1716836\",\"name\":\"W. Hsu\"}],\"doi\":\"10.1109/ICME.2016.7552937\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"782fcec5bd6dc7bec3d54db3b614ada0ab2764b3\",\"title\":\"Egocentric activity recognition by leveraging multiple mid-level representations\",\"url\":\"https://www.semanticscholar.org/paper/782fcec5bd6dc7bec3d54db3b614ada0ab2764b3\",\"venue\":\"2016 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48046803\",\"name\":\"Bharat Lal Bhatnagar\"},{\"authorId\":\"48039353\",\"name\":\"Suriya Singh\"},{\"authorId\":\"145676235\",\"name\":\"C. Arora\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"}],\"doi\":\"10.24963/ijcai.2017/200\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"dcf17cc3b4f8519a6789c1ea086689bcbc1d6f11\",\"title\":\"Unsupervised Learning of Deep Feature Representation for Clustering Egocentric Actions\",\"url\":\"https://www.semanticscholar.org/paper/dcf17cc3b4f8519a6789c1ea086689bcbc1d6f11\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48039353\",\"name\":\"Suriya Singh\"},{\"authorId\":\"145676233\",\"name\":\"Chetan Arora\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d20efdf05444a9d7509b85f6d5cd59359b1062f2\",\"title\":\"First Person Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d20efdf05444a9d7509b85f6d5cd59359b1062f2\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39307390\",\"name\":\"Bugra Tekin\"},{\"authorId\":\"2988774\",\"name\":\"Federica Bogo\"},{\"authorId\":\"88550057\",\"name\":\"Marc Pollefeys\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d39d3de091a3fe65e42a5034e49ce44ee0397a69\",\"title\":\"Unified Egocentric Recognition of 3 D Hand-Object Poses and Interactions\",\"url\":\"https://www.semanticscholar.org/paper/d39d3de091a3fe65e42a5034e49ce44ee0397a69\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47002659\",\"name\":\"Yanchao Li\"},{\"authorId\":\"1843583\",\"name\":\"Zhefan Ye\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"66d5842b7392bed57f473f8179dc04735412fb42\",\"title\":\"Motion , Object and Egocentric Cues\",\"url\":\"https://www.semanticscholar.org/paper/66d5842b7392bed57f473f8179dc04735412fb42\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1409.1484\",\"authors\":[{\"authorId\":\"145086911\",\"name\":\"A. Betancourt\"},{\"authorId\":\"2322579\",\"name\":\"Pietro Morerio\"},{\"authorId\":\"9587913\",\"name\":\"C. Regazzoni\"},{\"authorId\":\"1736974\",\"name\":\"M. Rauterberg\"}],\"doi\":\"10.1109/TCSVT.2015.2409731\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d317bf369e62fca415d54b091d9025b9e0e63181\",\"title\":\"The Evolution of First Person Vision Methods: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/d317bf369e62fca415d54b091d9025b9e0e63181\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2015},{\"arxivId\":\"1904.05250\",\"authors\":[{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1742452\",\"name\":\"S. Battiato\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":\"10.1016/j.jvcir.2017.10.004\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b67282a73c79438095799de916bf44ae55f1d310\",\"title\":\"Next-active-object prediction from egocentric videos\",\"url\":\"https://www.semanticscholar.org/paper/b67282a73c79438095799de916bf44ae55f1d310\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2017},{\"arxivId\":\"2005.02190\",\"authors\":[{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":\"10.1109/TPAMI.2020.2992889\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"07cf6c4c1714a0cd88e5c1566aac9df40e111db7\",\"title\":\"Rolling-Unrolling LSTMs for Action Anticipation from First-Person Video\",\"url\":\"https://www.semanticscholar.org/paper/07cf6c4c1714a0cd88e5c1566aac9df40e111db7\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1806522\",\"name\":\"H. Park\"},{\"authorId\":\"2351486\",\"name\":\"Jyh-Jing Hwang\"},{\"authorId\":\"39294088\",\"name\":\"Yedong Niu\"},{\"authorId\":\"46865129\",\"name\":\"J. Shi\"}],\"doi\":\"10.1109/CVPR.2016.508\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6abc95865cade4cd81eddaf1979f70115dc7bf37\",\"title\":\"Egocentric Future Localization\",\"url\":\"https://www.semanticscholar.org/paper/6abc95865cade4cd81eddaf1979f70115dc7bf37\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145086911\",\"name\":\"A. Betancourt\"},{\"authorId\":\"2322579\",\"name\":\"Pietro Morerio\"},{\"authorId\":\"9587913\",\"name\":\"C. Regazzoni\"},{\"authorId\":\"1736974\",\"name\":\"M. Rauterberg\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"990bf0171deae7f788f4867c155a276fca5c891a\",\"title\":\"An Overview of First Person Vision and Egocentric Video Analysis for Personal Mobile Wearable Devices\",\"url\":\"https://www.semanticscholar.org/paper/990bf0171deae7f788f4867c155a276fca5c891a\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2842099\",\"name\":\"Floraine Berthouzoz\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"dfff942a84d9126d2aebbc59be3834311e83ffc0\",\"title\":\"Teaching People and Machines to Enhance Images\",\"url\":\"https://www.semanticscholar.org/paper/dfff942a84d9126d2aebbc59be3834311e83ffc0\",\"venue\":\"\",\"year\":2013},{\"arxivId\":\"1612.05836\",\"authors\":[{\"authorId\":\"2599451\",\"name\":\"Shervin Ardeshir\"},{\"authorId\":\"50528026\",\"name\":\"Krishna Regmi\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1a74c9affc7209343026f8cd47d9b35fd818253c\",\"title\":\"EgoTransfer: Transferring Motion Across Egocentric and Exocentric Domains using Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/1a74c9affc7209343026f8cd47d9b35fd818253c\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1904.09062\",\"authors\":[{\"authorId\":\"50689299\",\"name\":\"Honglin Chen\"},{\"authorId\":\"144057957\",\"name\":\"H. Li\"},{\"authorId\":\"49077856\",\"name\":\"Alexander Song\"},{\"authorId\":\"33702926\",\"name\":\"M. Haberland\"},{\"authorId\":\"103541502\",\"name\":\"Osman Akar\"},{\"authorId\":\"144097866\",\"name\":\"Adam Dhillon\"},{\"authorId\":\"41033318\",\"name\":\"Tiankuang Zhou\"},{\"authorId\":\"144722242\",\"name\":\"A. Bertozzi\"},{\"authorId\":\"1970636\",\"name\":\"P. Brantingham\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f0dbdf9665f1d810f3d6a8fa3092c7307920d874\",\"title\":\"Semi-Supervised First-Person Activity Recognition in Body-Worn Video\",\"url\":\"https://www.semanticscholar.org/paper/f0dbdf9665f1d810f3d6a8fa3092c7307920d874\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1607.06986\",\"authors\":[{\"authorId\":\"2599451\",\"name\":\"Shervin Ardeshir\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":\"10.1007/978-3-319-46454-1_16\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f4f3b7fd4d77cd7d315971f1803d9f68e1109aa5\",\"title\":\"Ego2Top: Matching Viewers in Egocentric and Top-View Videos\",\"url\":\"https://www.semanticscholar.org/paper/f4f3b7fd4d77cd7d315971f1803d9f68e1109aa5\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"096a518224a4cdfd5d2ddd2ce5405b72b028be26\",\"title\":\"SKILL MEASUREMENT VIA EGOCENTRIC VISION IN WETLAB\",\"url\":\"https://www.semanticscholar.org/paper/096a518224a4cdfd5d2ddd2ce5405b72b028be26\",\"venue\":\"\",\"year\":2013},{\"arxivId\":\"1809.07408\",\"authors\":[{\"authorId\":\"145545664\",\"name\":\"Y. Yao\"},{\"authorId\":\"143847408\",\"name\":\"Mingze Xu\"},{\"authorId\":\"37435569\",\"name\":\"Chiho Choi\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"},{\"authorId\":\"144729148\",\"name\":\"E. Atkins\"},{\"authorId\":\"2086607\",\"name\":\"B. Dariush\"}],\"doi\":\"10.1109/ICRA.2019.8794474\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"497db84d084c34cf2db8883f95000953deeeddcc\",\"title\":\"Egocentric Vision-based Future Vehicle Localization for Intelligent Driving Assistance Systems\",\"url\":\"https://www.semanticscholar.org/paper/497db84d084c34cf2db8883f95000953deeeddcc\",\"venue\":\"2019 International Conference on Robotics and Automation (ICRA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1696389\",\"name\":\"G. Meditskos\"},{\"authorId\":\"2647162\",\"name\":\"Pierre-Marie Plans\"},{\"authorId\":\"1727843\",\"name\":\"T. Stavropoulos\"},{\"authorId\":\"1381345946\",\"name\":\"J. Benois-Pineau\"},{\"authorId\":\"2021805\",\"name\":\"V. Buso\"},{\"authorId\":\"1715604\",\"name\":\"Y. Kompatsiaris\"}],\"doi\":\"10.1016/j.jvcir.2018.01.009\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c04c541e4f64204945b197b5ec2512752a5edc24\",\"title\":\"Multi-modal activity recognition from egocentric vision, semantic enrichment and lifelogging applications for the care of dementia\",\"url\":\"https://www.semanticscholar.org/paper/c04c541e4f64204945b197b5ec2512752a5edc24\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2018},{\"arxivId\":\"1812.01233\",\"authors\":[{\"authorId\":\"46796686\",\"name\":\"Roei Herzig\"},{\"authorId\":\"34490455\",\"name\":\"Elad Levi\"},{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"2041489\",\"name\":\"E. Brosh\"},{\"authorId\":\"1786843\",\"name\":\"A. Globerson\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"09dc45f036781ccfc51cdc7a6f2057aba8b5ff10\",\"title\":\"Classifying Collisions with Spatio-Temporal Action Graph Networks\",\"url\":\"https://www.semanticscholar.org/paper/09dc45f036781ccfc51cdc7a6f2057aba8b5ff10\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123624286\",\"name\":\"N. Vo\"},{\"authorId\":\"1688328\",\"name\":\"A. Bobick\"}],\"doi\":\"10.1109/CVPR.2014.338\",\"intent\":[\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"18032d9c62b9e5f2af1a2c86ba483a393eb73a44\",\"title\":\"From Stochastic Grammar to Bayes Network: Probabilistic Parsing of Complex Activity\",\"url\":\"https://www.semanticscholar.org/paper/18032d9c62b9e5f2af1a2c86ba483a393eb73a44\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144180678\",\"name\":\"Minlong Lu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"972b1d8842df8ad06c50a33782af1cfdc9ffd411\",\"title\":\"Action analysis and control strategy for rat robot automatic navigation\",\"url\":\"https://www.semanticscholar.org/paper/972b1d8842df8ad06c50a33782af1cfdc9ffd411\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151430672\",\"name\":\"Khalid El Ansaoui\"},{\"authorId\":\"102880570\",\"name\":\"Youness Chawki\"},{\"authorId\":\"151441479\",\"name\":\"Mohammed Ouhda\"}],\"doi\":\"10.1007/978-3-030-23672-4_21\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3d4ceaa1b392509591c384822cd789a263101107\",\"title\":\"Towards a Rich and Dynamic Human Digital Memory in Egocentric Dataset\",\"url\":\"https://www.semanticscholar.org/paper/3d4ceaa1b392509591c384822cd789a263101107\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1803.10827\",\"authors\":[{\"authorId\":\"2883417\",\"name\":\"Kiana Ehsani\"},{\"authorId\":\"2456400\",\"name\":\"Hessam Bagherinezhad\"},{\"authorId\":\"40497777\",\"name\":\"Joseph Redmon\"},{\"authorId\":\"3012475\",\"name\":\"R. Mottaghi\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"}],\"doi\":\"10.1109/CVPR.2018.00426\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a63b8429ebeef316a65a94b021ef9a214c705f83\",\"title\":\"Who Let the Dogs Out? Modeling Dog Behavior from Visual Data\",\"url\":\"https://www.semanticscholar.org/paper/a63b8429ebeef316a65a94b021ef9a214c705f83\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"65804627\",\"name\":\"Khalid El Asnaoui\"},{\"authorId\":\"143601910\",\"name\":\"P. Radeva\"}],\"doi\":\"10.1515/jisys-2017-0364\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0363d6b6820070c475f6d8608e4594c7af9ca736\",\"title\":\"Automatically Assess Day Similarity Using Visual Lifelogs\",\"url\":\"https://www.semanticscholar.org/paper/0363d6b6820070c475f6d8608e4594c7af9ca736\",\"venue\":\"J. Intell. Syst.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145731841\",\"name\":\"P. Lei\"},{\"authorId\":\"143856428\",\"name\":\"S. Todorovic\"}],\"doi\":\"10.1109/CVPR.2018.00705\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4bfcedc30c05b68ba109b9ae71db42f1f1985770\",\"title\":\"Temporal Deformable Residual Networks for Action Segmentation in Videos\",\"url\":\"https://www.semanticscholar.org/paper/4bfcedc30c05b68ba109b9ae71db42f1f1985770\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34876449\",\"name\":\"E. Aksoy\"},{\"authorId\":\"2218815\",\"name\":\"Mohamad Javad Aein\"},{\"authorId\":\"1953638\",\"name\":\"M. Tamosiunaite\"},{\"authorId\":\"1714016\",\"name\":\"F. W\\u00f6rg\\u00f6tter\"}],\"doi\":\"10.1109/IROS.2015.7353773\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9a7b470d810234d337fcd0ed72091cebc945195e\",\"title\":\"Semantic parsing of human manipulation activities using on-line learned models for robot imitation\",\"url\":\"https://www.semanticscholar.org/paper/9a7b470d810234d337fcd0ed72091cebc945195e\",\"venue\":\"2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1901010\",\"name\":\"A. Cartas\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6d572e5851306d7d420a619469c8f449943f5880\",\"title\":\"Modeling Long-Term Interactions to Enhance Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6d572e5851306d7d420a619469c8f449943f5880\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2876810\",\"name\":\"Bilge Soran\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1809809\",\"name\":\"L. Shapiro\"}],\"doi\":\"10.1007/978-3-319-16814-2_12\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c2371629ad7bcde46e62859b2e812f6e5fc64cf\",\"title\":\"Action Recognition in the Presence of One Egocentric and Multiple Static Cameras\",\"url\":\"https://www.semanticscholar.org/paper/2c2371629ad7bcde46e62859b2e812f6e5fc64cf\",\"venue\":\"ACCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"},{\"authorId\":\"1782162\",\"name\":\"L. Matthies\"}],\"doi\":\"10.1117/12.2229531\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"55cd7f8b46eab20bd7e8f905e3c83397b11e6759\",\"title\":\"Video-based convolutional neural networks for activity recognition from robot-centric videos\",\"url\":\"https://www.semanticscholar.org/paper/55cd7f8b46eab20bd7e8f905e3c83397b11e6759\",\"venue\":\"SPIE Defense + Security\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143804966\",\"name\":\"F. Mart\\u00ednez\"},{\"authorId\":\"1723498\",\"name\":\"E. Pissaloux\"},{\"authorId\":\"2274030\",\"name\":\"A. Carbone\"}],\"doi\":\"10.3233/ICA-160520\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"21784c23be425824cf39e483f6813ad4e73c301e\",\"title\":\"Towards activity recognition from eye-movements using contextual temporal learning\",\"url\":\"https://www.semanticscholar.org/paper/21784c23be425824cf39e483f6813ad4e73c301e\",\"venue\":\"Integr. Comput. Aided Eng.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1795530\",\"name\":\"Y. Iwashita\"},{\"authorId\":\"48946640\",\"name\":\"Asamichi Takamine\"},{\"authorId\":\"1801213\",\"name\":\"R. Kurazume\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1109/ICPR.2014.739\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"51bc98791fdb5262d319ff8257bae11d3cf7fd1b\",\"title\":\"First-Person Animal Activity Recognition from Egocentric Videos\",\"url\":\"https://www.semanticscholar.org/paper/51bc98791fdb5262d319ff8257bae11d3cf7fd1b\",\"venue\":\"2014 22nd International Conference on Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47839689\",\"name\":\"L. Xia\"},{\"authorId\":\"2964199\",\"name\":\"I. Gori\"},{\"authorId\":\"1705627\",\"name\":\"J. Aggarwal\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1109/WACV.2015.54\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cdec872a07a2ad5b3d43eaf95c960b88728aeba5\",\"title\":\"Robot-centric Activity Recognition from First-Person RGB-D Videos\",\"url\":\"https://www.semanticscholar.org/paper/cdec872a07a2ad5b3d43eaf95c960b88728aeba5\",\"venue\":\"2015 IEEE Winter Conference on Applications of Computer Vision\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"1843583\",\"name\":\"Zhefan Ye\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1109/CVPR.2015.7298625\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"08b1a3f8c6dc175b1e45818024def4ba311b21e6\",\"title\":\"Delving into egocentric actions\",\"url\":\"https://www.semanticscholar.org/paper/08b1a3f8c6dc175b1e45818024def4ba311b21e6\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2527741\",\"name\":\"Sibo Song\"},{\"authorId\":\"1802086\",\"name\":\"V. Chandrasekhar\"},{\"authorId\":\"1709001\",\"name\":\"B. Mandal\"},{\"authorId\":\"35718875\",\"name\":\"L. Li\"},{\"authorId\":\"6516914\",\"name\":\"J. Lim\"},{\"authorId\":\"34094551\",\"name\":\"G. S. Babu\"},{\"authorId\":\"2307813\",\"name\":\"P. P. San\"},{\"authorId\":\"143770929\",\"name\":\"N. Cheung\"}],\"doi\":\"10.1109/CVPRW.2016.54\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6a9168bd32550e06f2cd23105f82f6735fb2edf4\",\"title\":\"Multimodal Multi-Stream Deep Learning for Egocentric Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6a9168bd32550e06f2cd23105f82f6735fb2edf4\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2016},{\"arxivId\":\"1709.06495\",\"authors\":[{\"authorId\":\"1756362\",\"name\":\"Swathikiran Sudhakaran\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"}],\"doi\":\"10.1109/ICCVW.2017.276\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5155499812dafee92316bdbca5937f0e134514f3\",\"title\":\"Convolutional Long Short-Term Memory Networks for Recognizing First Person Interactions\",\"url\":\"https://www.semanticscholar.org/paper/5155499812dafee92316bdbca5937f0e134514f3\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":\"1704.04097\",\"authors\":[{\"authorId\":\"1901010\",\"name\":\"A. Cartas\"},{\"authorId\":\"144952180\",\"name\":\"J. Mar\\u00edn\"},{\"authorId\":\"143601910\",\"name\":\"P. Radeva\"},{\"authorId\":\"2837527\",\"name\":\"Mariella Dimiccoli\"}],\"doi\":\"10.1007/978-3-319-58838-4_10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"73a4b994c9f521153881e1c02e47086afa978566\",\"title\":\"Recognizing Activities of Daily Living from Egocentric Images\",\"url\":\"https://www.semanticscholar.org/paper/73a4b994c9f521153881e1c02e47086afa978566\",\"venue\":\"IbPRIA\",\"year\":2017},{\"arxivId\":\"1812.00104\",\"authors\":[{\"authorId\":\"46419391\",\"name\":\"M. Elfeki\"},{\"authorId\":\"50528026\",\"name\":\"Krishna Regmi\"},{\"authorId\":\"2599451\",\"name\":\"Shervin Ardeshir\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a1c8fd832fe393034fad096f3296493ef6f807ad\",\"title\":\"From Third Person to First Person: Dataset and Baselines for Synthesis and Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/a1c8fd832fe393034fad096f3296493ef6f807ad\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152401495\",\"name\":\"K. P. Sanal Kumar\"},{\"authorId\":\"121123258\",\"name\":\"R. Bhavani\"},{\"authorId\":\"152245799\",\"name\":\"M. Rajaguru\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"dff6cae1ac3e522cb2f7441c74153a6731b6a6a7\",\"title\":\"Egocentric Activity Recognition Using Bag of Visual Words\",\"url\":\"https://www.semanticscholar.org/paper/dff6cae1ac3e522cb2f7441c74153a6731b6a6a7\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2256574\",\"name\":\"K. Inoue\"},{\"authorId\":\"147558190\",\"name\":\"Misa Ono\"},{\"authorId\":\"2593208\",\"name\":\"M. Yoshioka\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2567ab620a9baef594a6b6a1753f0e2c96a8d3a5\",\"title\":\"Hand Detection in Egocentric Video and Investigation Towards Fine-grained Cooking Activities Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2567ab620a9baef594a6b6a1753f0e2c96a8d3a5\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35429700\",\"name\":\"Panagiotis Giannakeris\"},{\"authorId\":\"2733886\",\"name\":\"Panagiotis C. Petrantonakis\"},{\"authorId\":\"2735095\",\"name\":\"Konstantinos Avgerinakis\"},{\"authorId\":\"1381295446\",\"name\":\"S. Vrochidis\"},{\"authorId\":\"119661806\",\"name\":\"I. Kompatsiaris\"}],\"doi\":\"10.1007/S11042-020-09902-6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"44c0abc3ac54c69ba68362708c2a5c06b088287b\",\"title\":\"First-person activity recognition from micro-action representations using convolutional neural networks and object flow histograms\",\"url\":\"https://www.semanticscholar.org/paper/44c0abc3ac54c69ba68362708c2a5c06b088287b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1455919396\",\"name\":\"Mingming Zhang\"},{\"authorId\":\"145732825\",\"name\":\"Xiaoqiang Yan\"},{\"authorId\":\"28962067\",\"name\":\"Shizhe Hu\"},{\"authorId\":\"2382085\",\"name\":\"Y. Ye\"}],\"doi\":\"10.1016/j.asoc.2020.106425\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5db83557ea61418bd14a6d5e662577fe10d254af\",\"title\":\"An Information Maximization Multi-task Clustering Method for egocentric temporal segmentation\",\"url\":\"https://www.semanticscholar.org/paper/5db83557ea61418bd14a6d5e662577fe10d254af\",\"venue\":\"Appl. Soft Comput.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403754530\",\"name\":\"Guillermo Garcia-Hernando\"},{\"authorId\":\"145917158\",\"name\":\"H. J. Chang\"},{\"authorId\":\"144540522\",\"name\":\"I. Serrano\"},{\"authorId\":\"1397942042\",\"name\":\"O. D\\u00e9niz-Su\\u00e1rez\"},{\"authorId\":\"1700968\",\"name\":\"Tae-Kyun Kim\"}],\"doi\":\"10.1109/WACV.2016.7477709\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f613aa581546ffb37561fe87dffd484d6daecbf0\",\"title\":\"Transition Hough forest for trajectory-based action recognition\",\"url\":\"https://www.semanticscholar.org/paper/f613aa581546ffb37561fe87dffd484d6daecbf0\",\"venue\":\"2016 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2016},{\"arxivId\":\"1605.03688\",\"authors\":[{\"authorId\":\"2238622\",\"name\":\"Minghuang Ma\"},{\"authorId\":\"2681569\",\"name\":\"Haoqi Fan\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"}],\"doi\":\"10.1109/CVPR.2016.209\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"444eba373d46c9f7d58cad74989ec9109b0d5219\",\"title\":\"Going Deeper into First-Person Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/444eba373d46c9f7d58cad74989ec9109b0d5219\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2876810\",\"name\":\"Bilge Soran\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e227058f661d9dd644753c4f81c02b8e46ec89b1\",\"title\":\"Action Recognition and Prediction with Applications to Medical Diagnosis and Daily Living\",\"url\":\"https://www.semanticscholar.org/paper/e227058f661d9dd644753c4f81c02b8e46ec89b1\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1704.00098\",\"authors\":[{\"authorId\":\"145022261\",\"name\":\"Shan Su\"},{\"authorId\":\"46865129\",\"name\":\"J. Shi\"},{\"authorId\":\"1806522\",\"name\":\"H. Park\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"603dee8661aa9bf0d7af6c61fe5fa2e85227f166\",\"title\":\"Customizing First Person Image Through Desired Actions\",\"url\":\"https://www.semanticscholar.org/paper/603dee8661aa9bf0d7af6c61fe5fa2e85227f166\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"},{\"authorId\":\"34459632\",\"name\":\"Thomas J. Fuchs\"},{\"authorId\":\"47839689\",\"name\":\"L. Xia\"},{\"authorId\":\"1705627\",\"name\":\"J. Aggarwal\"},{\"authorId\":\"1782162\",\"name\":\"L. Matthies\"}],\"doi\":\"10.1145/2696454.2696462\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d7670e2a55b5a9fae609eed08777da71e0b92ee\",\"title\":\"Robot-Centric Activity Prediction from First-Person Videos: What Will They Do to Me?\",\"url\":\"https://www.semanticscholar.org/paper/3d7670e2a55b5a9fae609eed08777da71e0b92ee\",\"venue\":\"2015 10th ACM/IEEE International Conference on Human-Robot Interaction (HRI)\",\"year\":2015},{\"arxivId\":\"1510.01576\",\"authors\":[{\"authorId\":\"118242229\",\"name\":\"D. Castro\"},{\"authorId\":\"2935619\",\"name\":\"Steven Hickson\"},{\"authorId\":\"3115428\",\"name\":\"Vinay Bettadapura\"},{\"authorId\":\"39642711\",\"name\":\"E. Thomaz\"},{\"authorId\":\"9267108\",\"name\":\"Gregory D. Abowd\"},{\"authorId\":\"1723059\",\"name\":\"H. Christensen\"},{\"authorId\":\"21472040\",\"name\":\"Irfan Essa\"}],\"doi\":\"10.1145/2802083.2808398\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0d23260f8cb9d0ef5f1e0e9f43e9ebd1131f0e71\",\"title\":\"Predicting daily activities from egocentric images using deep learning\",\"url\":\"https://www.semanticscholar.org/paper/0d23260f8cb9d0ef5f1e0e9f43e9ebd1131f0e71\",\"venue\":\"SEMWEB\",\"year\":2015},{\"arxivId\":\"1909.09269\",\"authors\":[{\"authorId\":\"9284940\",\"name\":\"Harshala Gammulle\"},{\"authorId\":\"1980700\",\"name\":\"Simon Denman\"},{\"authorId\":\"1729760\",\"name\":\"S. Sridharan\"},{\"authorId\":\"3140440\",\"name\":\"C. Fookes\"}],\"doi\":\"10.1016/j.patcog.2019.107039\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e593d38f35d340e8da0cf62a29a180dbe42e8047\",\"title\":\"Fine-grained Action Segmentation using the Semi-Supervised Action GAN\",\"url\":\"https://www.semanticscholar.org/paper/e593d38f35d340e8da0cf62a29a180dbe42e8047\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1596808016\",\"name\":\"Xiaohan Wang\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"50118837\",\"name\":\"Y. Wu\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1109/tpami.2020.3015894\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7401d3895e1cb78c34fa25db12409fdff56b1661\",\"title\":\"Symbiotic Attention for Egocentric Action Recognition with Object-centric Alignment.\",\"url\":\"https://www.semanticscholar.org/paper/7401d3895e1cb78c34fa25db12409fdff56b1661\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"1504.07469\",\"authors\":[{\"authorId\":\"2926663\",\"name\":\"Yair Poleg\"},{\"authorId\":\"2077454\",\"name\":\"A. Ephrat\"},{\"authorId\":\"144406261\",\"name\":\"Shmuel Peleg\"},{\"authorId\":\"145676235\",\"name\":\"C. Arora\"}],\"doi\":\"10.1109/WACV.2016.7477708\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6f2b075d527e7d3b29219e5955f294f539c4764f\",\"title\":\"Compact CNN for indexing egocentric videos\",\"url\":\"https://www.semanticscholar.org/paper/6f2b075d527e7d3b29219e5955f294f539c4764f\",\"venue\":\"2016 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35299091\",\"name\":\"Yansong Tang\"},{\"authorId\":\"50218246\",\"name\":\"Z. Wang\"},{\"authorId\":\"1697700\",\"name\":\"Jiwen Lu\"},{\"authorId\":\"144698893\",\"name\":\"J. Feng\"},{\"authorId\":\"49640256\",\"name\":\"J. Zhou\"}],\"doi\":\"10.1109/TCSVT.2018.2875441\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a90a56267b66c060b235339a0080a00585fdeb41\",\"title\":\"Multi-Stream Deep Neural Networks for RGB-D Egocentric Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a90a56267b66c060b235339a0080a00585fdeb41\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":\"1701.04743\",\"authors\":[{\"authorId\":\"2280086\",\"name\":\"Suvam Patra\"},{\"authorId\":\"49871207\",\"name\":\"Himanshu Aggarwal\"},{\"authorId\":\"49583376\",\"name\":\"Himani Arora\"},{\"authorId\":\"2226388\",\"name\":\"S. Banerjee\"},{\"authorId\":\"145676232\",\"name\":\"Chetan Arora\"}],\"doi\":\"10.1109/WACV.2017.57\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a55504c724d8d8bee0893f5469e6b8685dbeb1c1\",\"title\":\"Computing Egomotion with Local Loop Closures for Egocentric Videos\",\"url\":\"https://www.semanticscholar.org/paper/a55504c724d8d8bee0893f5469e6b8685dbeb1c1\",\"venue\":\"2017 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47211446\",\"name\":\"W. Yamazaki\"},{\"authorId\":null,\"name\":\"Ming Ding\"},{\"authorId\":\"21825576\",\"name\":\"J. Takamatsu\"},{\"authorId\":\"144496879\",\"name\":\"T. Ogasawara\"}],\"doi\":\"10.1109/ROBIO.2017.8324409\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a0c0edaf77ae7be9f78d1571b4aa3130dfbea0e1\",\"title\":\"Hand pose estimation and motion recognition using egocentric RGB-D video\",\"url\":\"https://www.semanticscholar.org/paper/a0c0edaf77ae7be9f78d1571b4aa3130dfbea0e1\",\"venue\":\"2017 IEEE International Conference on Robotics and Biomimetics (ROBIO)\",\"year\":2017},{\"arxivId\":\"1710.04112\",\"authors\":[{\"authorId\":\"1901010\",\"name\":\"A. Cartas\"},{\"authorId\":\"144952180\",\"name\":\"J. Mar\\u00edn\"},{\"authorId\":\"143601910\",\"name\":\"P. Radeva\"},{\"authorId\":\"2837527\",\"name\":\"Mariella Dimiccoli\"}],\"doi\":\"10.1007/s10044-018-0708-1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"726493da25879c1579941e9cbcd5e9a15c7665d1\",\"title\":\"Recognizing Daily Activities from Egocentric Photo-Streams\",\"url\":\"https://www.semanticscholar.org/paper/726493da25879c1579941e9cbcd5e9a15c7665d1\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1812.09570\",\"authors\":[{\"authorId\":\"1808039\",\"name\":\"Emrah Basaran\"},{\"authorId\":\"10428247\",\"name\":\"Yonatan Tariku Tesfaye\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c8ca231a21c28c57d15ace1d9057879046a7f08c\",\"title\":\"EgoReID: Person re-identification in Egocentric Videos Acquired by Mobile Devices with First-Person Point-of-View\",\"url\":\"https://www.semanticscholar.org/paper/c8ca231a21c28c57d15ace1d9057879046a7f08c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51243449\",\"name\":\"Atanas Poibrenski\"},{\"authorId\":\"1798357\",\"name\":\"M. Klusch\"},{\"authorId\":\"1596870919\",\"name\":\"Igor Vozniak\"},{\"authorId\":\"143851843\",\"name\":\"C. M\\u00fcller\"}],\"doi\":\"10.1145/3341105.3373877\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6a6af33e8117079372b60ba65dc15a4738105162\",\"title\":\"M2P3: multimodal multi-pedestrian path prediction by self-driving cars with egocentric vision\",\"url\":\"https://www.semanticscholar.org/paper/6a6af33e8117079372b60ba65dc15a4738105162\",\"venue\":\"SAC\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1733113\",\"name\":\"T. Kanade\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1109/JPROC.2012.2200554\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ac520a1addd2d5e64aa6379072b013729e856df4\",\"title\":\"First-Person Vision\",\"url\":\"https://www.semanticscholar.org/paper/ac520a1addd2d5e64aa6379072b013729e856df4\",\"venue\":\"Proceedings of the IEEE\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145865884\",\"name\":\"T. McCandless\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.5244/C.27.30\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e6aa058aa564efbaaed8ea4e5a164574a69f3034\",\"title\":\"Object-Centric Spatio-Temporal Pyramids for Egocentric Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e6aa058aa564efbaaed8ea4e5a164574a69f3034\",\"venue\":\"BMVC\",\"year\":2013},{\"arxivId\":\"1603.09200\",\"authors\":[{\"authorId\":\"145086911\",\"name\":\"A. Betancourt\"},{\"authorId\":\"2251072\",\"name\":\"N. Rodr\\u00edguez\"},{\"authorId\":\"145741020\",\"name\":\"E. Barakova\"},{\"authorId\":\"1689330\",\"name\":\"L. Marcenaro\"},{\"authorId\":\"1736974\",\"name\":\"M. Rauterberg\"},{\"authorId\":\"9587913\",\"name\":\"C. Regazzoni\"}],\"doi\":\"10.1016/j.pmcj.2017.03.016\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"adc8fe239c33585ec6ab0e55c1e3e3248d0523d5\",\"title\":\"Unsupervised understanding of location and illumination changes in egocentric videos\",\"url\":\"https://www.semanticscholar.org/paper/adc8fe239c33585ec6ab0e55c1e3e3248d0523d5\",\"venue\":\"Pervasive Mob. Comput.\",\"year\":2017},{\"arxivId\":\"2011.13341\",\"authors\":[{\"authorId\":\"1720749879\",\"name\":\"Miao Liu\"},{\"authorId\":\"2812134\",\"name\":\"D. Yang\"},{\"authorId\":\"2655217\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1813796\",\"name\":\"Zhaopeng Cui\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"},{\"authorId\":\"1831081930\",\"name\":\"Siyu Tang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7d1bfeb5084e0a275602fc67fa0ac60269c1719e\",\"title\":\"4D Human Body Capture from Egocentric Video via 3D Scene Grounding\",\"url\":\"https://www.semanticscholar.org/paper/7d1bfeb5084e0a275602fc67fa0ac60269c1719e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"14545508\",\"name\":\"Mohamad Baydoun\"},{\"authorId\":\"145086911\",\"name\":\"A. Betancourt\"},{\"authorId\":\"2322579\",\"name\":\"Pietro Morerio\"},{\"authorId\":\"1689330\",\"name\":\"L. Marcenaro\"},{\"authorId\":\"1736974\",\"name\":\"M. Rauterberg\"},{\"authorId\":\"9587913\",\"name\":\"C. Regazzoni\"}],\"doi\":\"10.1109/ICASSP.2017.7952481\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"93ce46e183e159b79ff239bad7be0c9b5c4a58d6\",\"title\":\"Hand pose recognition in First Person Vision through graph spectral analysis\",\"url\":\"https://www.semanticscholar.org/paper/93ce46e183e159b79ff239bad7be0c9b5c4a58d6\",\"venue\":\"2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145892975\",\"name\":\"S. Stein\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"cbf14c7b515fa30b1da1f19e1610582dc7b2932f\",\"title\":\"Multi-modal recognition of manipulation activities through visual accelerometer tracking, relational histograms, and user-adaptation\",\"url\":\"https://www.semanticscholar.org/paper/cbf14c7b515fa30b1da1f19e1610582dc7b2932f\",\"venue\":\"\",\"year\":2014},{\"arxivId\":\"1905.09402\",\"authors\":[{\"authorId\":\"1985999\",\"name\":\"Hyungik Oh\"},{\"authorId\":\"144938740\",\"name\":\"Ramesh C. Jain\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2fe8c3e8de67e9c0bb4df124449f99a6dd83b9da\",\"title\":\"Detecting Events of Daily Living Using Multimodal Data\",\"url\":\"https://www.semanticscholar.org/paper/2fe8c3e8de67e9c0bb4df124449f99a6dd83b9da\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1604.02115\",\"authors\":[{\"authorId\":\"48039353\",\"name\":\"Suriya Singh\"},{\"authorId\":\"145676235\",\"name\":\"C. Arora\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"}],\"doi\":\"10.1016/j.patcog.2016.07.031\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"45b6562ffd8df53de69e39c91b1f28abece412d9\",\"title\":\"Trajectory aligned features for first person action recognition\",\"url\":\"https://www.semanticscholar.org/paper/45b6562ffd8df53de69e39c91b1f28abece412d9\",\"venue\":\"Pattern Recognit.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"},{\"authorId\":\"1742452\",\"name\":\"S. Battiato\"}],\"doi\":\"10.1007/978-3-319-46604-0_34\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9c0e70c97f065ad10d2a24963439d3892183ac99\",\"title\":\"Temporal Segmentation of Egocentric Videos to Highlight Personal Locations of Interest\",\"url\":\"https://www.semanticscholar.org/paper/9c0e70c97f065ad10d2a24963439d3892183ac99\",\"venue\":\"ECCV Workshops\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"46331912\",\"name\":\"M. Liu\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1007/978-3-030-01228-1_38\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fa1723b216b1f41b085b62b450b7b0bd9f2fd281\",\"title\":\"In the Eye of Beholder: Joint Learning of Gaze and Actions in First Person Video\",\"url\":\"https://www.semanticscholar.org/paper/fa1723b216b1f41b085b62b450b7b0bd9f2fd281\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39872583\",\"name\":\"M. Wang\"},{\"authorId\":\"2206888\",\"name\":\"Changzhi Luo\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"143625300\",\"name\":\"J. Yuan\"},{\"authorId\":\"49606802\",\"name\":\"Jianfeng Wang\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"}],\"doi\":\"10.1109/TCSVT.2017.2716819\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5b300b85e10aa312dfe31d8064d86f764d0aaa68\",\"title\":\"First-Person Daily Activity Recognition With Manipulated Object Proposals and Non-Linear Feature Fusion\",\"url\":\"https://www.semanticscholar.org/paper/5b300b85e10aa312dfe31d8064d86f764d0aaa68\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152401495\",\"name\":\"K. Kumar\"},{\"authorId\":\"145711908\",\"name\":\"R. Bhavani\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"efa2b259407b5b9171dd085061d05b72b6309eb0\",\"title\":\"Egocentric Activity Recognition Using HOG , HOF , MBH and Combined features\",\"url\":\"https://www.semanticscholar.org/paper/efa2b259407b5b9171dd085061d05b72b6309eb0\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1805.07253\",\"authors\":[{\"authorId\":\"3110004\",\"name\":\"Anjith George\"},{\"authorId\":\"2680543\",\"name\":\"A. Routray\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"acce6cd8b8a3f5ee010df757a82514060f9ff98f\",\"title\":\"Recognition of Activities from Eye Gaze and Egocentric Video\",\"url\":\"https://www.semanticscholar.org/paper/acce6cd8b8a3f5ee010df757a82514060f9ff98f\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"103837492\",\"name\":\"Sergio R. Cruz\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":\"10.1016/J.IMAVIS.2019.06.002\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e42e00f2dda54365073d5d6345d81bd1012ea879\",\"title\":\"Is that my hand? An egocentric dataset for hand disambiguation\",\"url\":\"https://www.semanticscholar.org/paper/e42e00f2dda54365073d5d6345d81bd1012ea879\",\"venue\":\"Image Vis. Comput.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3194727\",\"name\":\"Andreas Bulling\"},{\"authorId\":\"143973307\",\"name\":\"K. Kunze\"}],\"doi\":\"10.1145/2912886\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c5e4b98fe444342d9c21fc670d9086e847971f06\",\"title\":\"Eyewear computers for human-computer interaction\",\"url\":\"https://www.semanticscholar.org/paper/c5e4b98fe444342d9c21fc670d9086e847971f06\",\"venue\":\"Interactions\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34575696\",\"name\":\"Keita Higuchi\"},{\"authorId\":\"1899753\",\"name\":\"Ryo Yonetani\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1145/3132818.3132831\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1fdac02fd55308be6580ba289134a91376906b1f\",\"title\":\"Egoscanning: quickly scanning first-person videos with egocentric elastic timelines\",\"url\":\"https://www.semanticscholar.org/paper/1fdac02fd55308be6580ba289134a91376906b1f\",\"venue\":\"SIGGRAPH ASIA Emerging Technologies\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40536205\",\"name\":\"M. Rodriguez\"},{\"authorId\":\"31341930\",\"name\":\"C. Orrite\"},{\"authorId\":\"144426554\",\"name\":\"C. Medrano\"}],\"doi\":\"10.1007/s10044-020-00942-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2b2dd881b42406a41845e83a2aa1db8efe8b5aff\",\"title\":\"Space-time flexible kernel for recognizing activities from wearable cameras\",\"url\":\"https://www.semanticscholar.org/paper/2b2dd881b42406a41845e83a2aa1db8efe8b5aff\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2504093\",\"name\":\"G. Bleser\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"},{\"authorId\":\"1931096\",\"name\":\"A. Behera\"},{\"authorId\":\"2486923\",\"name\":\"G. Hendeby\"},{\"authorId\":\"40481151\",\"name\":\"K. Mura\"},{\"authorId\":\"2525788\",\"name\":\"Markus Miezal\"},{\"authorId\":\"1679011\",\"name\":\"A. Gee\"},{\"authorId\":\"40311604\",\"name\":\"N. Petersen\"},{\"authorId\":\"5080244\",\"name\":\"Gustavo Ma\\u00e7\\u00e3es\"},{\"authorId\":\"47171176\",\"name\":\"Hugo Domingues\"},{\"authorId\":\"2351851\",\"name\":\"Dominic Gorecky\"},{\"authorId\":\"153876935\",\"name\":\"Lu\\u00eds Almeida\"},{\"authorId\":\"1398236231\",\"name\":\"W. Mayol-Cuevas\"},{\"authorId\":\"3336943\",\"name\":\"A. Calway\"},{\"authorId\":\"1703235\",\"name\":\"A. Cohn\"},{\"authorId\":\"1967104\",\"name\":\"David C. Hogg\"},{\"authorId\":\"1807169\",\"name\":\"D. Stricker\"},{\"authorId\":\"1772497\",\"name\":\"Gianluca Bontempi\"}],\"doi\":\"10.1371/journal.pone.0127769\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9b1489bb657497d8792d0197c269456a582a2bb6\",\"title\":\"Cognitive Learning, Monitoring and Assistance of Industrial Workflows Using Egocentric Sensor Networks\",\"url\":\"https://www.semanticscholar.org/paper/9b1489bb657497d8792d0197c269456a582a2bb6\",\"venue\":\"PloS one\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145086911\",\"name\":\"A. Betancourt\"},{\"authorId\":\"2322579\",\"name\":\"Pietro Morerio\"},{\"authorId\":\"145741020\",\"name\":\"E. Barakova\"},{\"authorId\":\"1689330\",\"name\":\"L. Marcenaro\"},{\"authorId\":\"1736974\",\"name\":\"M. Rauterberg\"},{\"authorId\":\"9587913\",\"name\":\"C. Regazzoni\"}],\"doi\":\"10.1007/978-3-319-23192-1_23\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c160bcbc8f0517a97e46042c84343bf3f0477478\",\"title\":\"A Dynamic Approach and a New Dataset for Hand-detection in First Person Vision\",\"url\":\"https://www.semanticscholar.org/paper/c160bcbc8f0517a97e46042c84343bf3f0477478\",\"venue\":\"CAIP\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2452552\",\"name\":\"S. Alletto\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1145/2964284.2967266\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"603ca92bb35fc5d604d12f979aa144c923687526\",\"title\":\"Motion Segmentation using Visual and Bio-mechanical Features\",\"url\":\"https://www.semanticscholar.org/paper/603ca92bb35fc5d604d12f979aa144c923687526\",\"venue\":\"ACM Multimedia\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"},{\"authorId\":\"1782162\",\"name\":\"L. Matthies\"}],\"doi\":\"10.1109/CVPR.2013.352\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aa4dd3eec733045c7d5f43535f201a12f71ef5f5\",\"title\":\"First-Person Activity Recognition: What Are They Doing to Me?\",\"url\":\"https://www.semanticscholar.org/paper/aa4dd3eec733045c7d5f43535f201a12f71ef5f5\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3090606\",\"name\":\"Y. Lin\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\"},{\"authorId\":\"1706145\",\"name\":\"Philippos Mordohai\"}],\"doi\":\"10.1007/978-3-319-16199-0_52\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"05e2ff695976c60403c87d07189f6030f55045e8\",\"title\":\"Egocentric Object Recognition Leveraging the 3D Shape of the Grasping Hand\",\"url\":\"https://www.semanticscholar.org/paper/05e2ff695976c60403c87d07189f6030f55045e8\",\"venue\":\"ECCV Workshops\",\"year\":2014},{\"arxivId\":\"2006.09220\",\"authors\":[{\"authorId\":\"41022481\",\"name\":\"Yazan Abu Farha\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1109/CVPR.2019.00369\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b4673e744d0ded47fe6df3b6314f79a41359578b\",\"title\":\"MS-TCN: Multi-Stage Temporal Convolutional Network for Action Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/b4673e744d0ded47fe6df3b6314f79a41359578b\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2876810\",\"name\":\"Bilge Soran\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1809809\",\"name\":\"L. Shapiro\"}],\"doi\":\"10.1109/ICCV.2015.530\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f8ae17c3ef3754967b62f4a4bc34cfc2f6d93719\",\"title\":\"Generating Notifications for Missing Actions: Don't Forget to Turn the Lights Off!\",\"url\":\"https://www.semanticscholar.org/paper/f8ae17c3ef3754967b62f4a4bc34cfc2f6d93719\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1603.07763\",\"authors\":[{\"authorId\":\"143891657\",\"name\":\"H. Jiang\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2017.373\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9e1f07016fb532800fcaccab03582cb16234b888\",\"title\":\"Seeing Invisible Poses: Estimating 3D Body Pose from Egocentric Video\",\"url\":\"https://www.semanticscholar.org/paper/9e1f07016fb532800fcaccab03582cb16234b888\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48039353\",\"name\":\"Suriya Singh\"},{\"authorId\":\"145676233\",\"name\":\"Chetan Arora\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"}],\"doi\":\"10.1109/CVPR.2016.287\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"28efff48583dfbcf8e6e552f5720278db1ae0fe3\",\"title\":\"First Person Action Recognition Using Deep Learned Descriptors\",\"url\":\"https://www.semanticscholar.org/paper/28efff48583dfbcf8e6e552f5720278db1ae0fe3\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3463027\",\"name\":\"Jen-An Yang\"},{\"authorId\":\"49010693\",\"name\":\"C. Lee\"},{\"authorId\":\"3320157\",\"name\":\"Shao-Wen Yang\"},{\"authorId\":\"144396576\",\"name\":\"V. Somayazulu\"},{\"authorId\":\"1748602\",\"name\":\"Y. Chen\"},{\"authorId\":\"1733505\",\"name\":\"S. Chien\"}],\"doi\":\"10.1109/ICMEW.2016.7574681\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1e8fd77d4717e9cb6079e10771dd2ed772098cb3\",\"title\":\"Wearable social camera: Egocentric video summarization for social interaction\",\"url\":\"https://www.semanticscholar.org/paper/1e8fd77d4717e9cb6079e10771dd2ed772098cb3\",\"venue\":\"2016 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2016},{\"arxivId\":\"1803.05959\",\"authors\":[{\"authorId\":\"2470018\",\"name\":\"WeiPeng Xu\"},{\"authorId\":\"49926328\",\"name\":\"A. Chatterjee\"},{\"authorId\":\"1699058\",\"name\":\"M. Zollh\\u00f6fer\"},{\"authorId\":\"2933543\",\"name\":\"H. Rhodin\"},{\"authorId\":\"153918727\",\"name\":\"P. Fua\"},{\"authorId\":\"145361968\",\"name\":\"H. Seidel\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"}],\"doi\":\"10.1109/TVCG.2019.2898650\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c3b4f711f415d5559e0626543c5413e4f6ec71c6\",\"title\":\"Mo2Cap2: Real-time Mobile 3D Motion Capture with a Cap-mounted Fisheye Camera\",\"url\":\"https://www.semanticscholar.org/paper/c3b4f711f415d5559e0626543c5413e4f6ec71c6\",\"venue\":\"IEEE Transactions on Visualization and Computer Graphics\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1793739\",\"name\":\"David J. Fleet\"},{\"authorId\":\"1758039\",\"name\":\"T. Pajdla\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"}],\"doi\":\"10.1007/978-3-319-10602-1\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"18101bfc08381ddea8fd944a3300dc8cffe34e63\",\"title\":\"Computer Vision \\u2013 ECCV 2014\",\"url\":\"https://www.semanticscholar.org/paper/18101bfc08381ddea8fd944a3300dc8cffe34e63\",\"venue\":\"Lecture Notes in Computer Science\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1974383\",\"name\":\"Nicholas Rhinehart\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"}],\"doi\":\"10.1109/TPAMI.2018.2873794\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"008085275d5c1b7f0cc2631c9eae3d015ed244ca\",\"title\":\"First-Person Activity Forecasting from Video with Online Inverse Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/008085275d5c1b7f0cc2631c9eae3d015ed244ca\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150185312\",\"name\":\"Longfei Chen\"},{\"authorId\":\"24265259\",\"name\":\"Y. Nakamura\"},{\"authorId\":\"1942816\",\"name\":\"K. Kondo\"},{\"authorId\":\"1398236231\",\"name\":\"W. Mayol-Cuevas\"}],\"doi\":\"10.1587/TRANSINF.2018EDP7146\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e255819a13d32c106e9a31f12644da0efb0ef369\",\"title\":\"Hotspot Modeling of Hand-Machine Interaction Experiences from a Head-Mounted RGB-D Camera\",\"url\":\"https://www.semanticscholar.org/paper/e255819a13d32c106e9a31f12644da0efb0ef369\",\"venue\":\"IEICE Trans. Inf. Syst.\",\"year\":2019},{\"arxivId\":\"1907.04325\",\"authors\":[{\"authorId\":\"3110004\",\"name\":\"Anjith George\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"57e3e58fc4307559021da37ba0cf02bf860a5933\",\"title\":\"Image based Eye Gaze Tracking and its Applications\",\"url\":\"https://www.semanticscholar.org/paper/57e3e58fc4307559021da37ba0cf02bf860a5933\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145732825\",\"name\":\"Xiaoqiang Yan\"},{\"authorId\":\"2382085\",\"name\":\"Y. Ye\"},{\"authorId\":\"2467033\",\"name\":\"Zhengzheng Lou\"}],\"doi\":\"10.1016/j.knosys.2015.03.028\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ea7229432eb0c918ed5965157d67c804b9277c40\",\"title\":\"Unsupervised video categorization based on multivariate information bottleneck method\",\"url\":\"https://www.semanticscholar.org/paper/ea7229432eb0c918ed5965157d67c804b9277c40\",\"venue\":\"Knowl. Based Syst.\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47683829\",\"name\":\"A. Fathi\"},{\"authorId\":\"1788773\",\"name\":\"J. Hodgins\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1109/CVPR.2012.6247805\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"014e1186209e4f942f3b5ba29b6b039c8e99ad88\",\"title\":\"Social interactions: A first-person perspective\",\"url\":\"https://www.semanticscholar.org/paper/014e1186209e4f942f3b5ba29b6b039c8e99ad88\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":\"1509.00651\",\"authors\":[{\"authorId\":\"2206888\",\"name\":\"Changzhi Luo\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"143625300\",\"name\":\"J. Yuan\"},{\"authorId\":\"38504661\",\"name\":\"J. Wang\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"},{\"authorId\":\"47446553\",\"name\":\"M. Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"3dfe949687a422b6b022a36ad46700450966f5fc\",\"title\":\"Manipulated Object Proposal: A Discriminative Object Extraction and Feature Fusion Framework for First-Person Daily Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3dfe949687a422b6b022a36ad46700450966f5fc\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1602.02995\",\"authors\":[{\"authorId\":\"98658818\",\"name\":\"C. Lea\"},{\"authorId\":\"3207112\",\"name\":\"A. Reiter\"},{\"authorId\":\"144020730\",\"name\":\"R. Vidal\"},{\"authorId\":\"1678633\",\"name\":\"Gregory Hager\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"0258749b418db624de697ea934b4f1425c961066\",\"title\":\"Segmental Spatio-Temporal CNNs for Fine-grained Action Segmentation and Classification\",\"url\":\"https://www.semanticscholar.org/paper/0258749b418db624de697ea934b4f1425c961066\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50339742\",\"name\":\"Krishna Kumar Singh\"},{\"authorId\":\"2789576\",\"name\":\"K. Fatahalian\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1109/WACV.2016.7477717\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7034b9a498b14cdb3362f65560a00b4fbee85df6\",\"title\":\"KrishnaCam: Using a longitudinal, single-person, egocentric dataset for scene understanding tasks\",\"url\":\"https://www.semanticscholar.org/paper/7034b9a498b14cdb3362f65560a00b4fbee85df6\",\"venue\":\"2016 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1974383\",\"name\":\"Nicholas Rhinehart\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4a250bf0e10e23de16200cb33d5977d09848c80a\",\"title\":\"Online Semantic Activity Forecasting with DARKO\",\"url\":\"https://www.semanticscholar.org/paper/4a250bf0e10e23de16200cb33d5977d09848c80a\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48333718\",\"name\":\"Pascal Fallavollita\"}],\"doi\":\"10.5772/INTECHOPEN.68775\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5e04fd403a62c7c6d00d3d8ee4a69b9cd9170a48\",\"title\":\"Innovative Technologies for Medical Education\",\"url\":\"https://www.semanticscholar.org/paper/5e04fd403a62c7c6d00d3d8ee4a69b9cd9170a48\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2164140\",\"name\":\"E. Bernal\"},{\"authorId\":\"3042242\",\"name\":\"X. Yang\"},{\"authorId\":\"144326109\",\"name\":\"Q. Li\"},{\"authorId\":\"143775793\",\"name\":\"J. Kumar\"},{\"authorId\":\"49488800\",\"name\":\"Sriganesh Madhvanath\"},{\"authorId\":\"40327196\",\"name\":\"Palghat Ramesh\"},{\"authorId\":\"145652623\",\"name\":\"R. Bala\"}],\"doi\":\"10.1109/TMM.2017.2726187\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"30bb55d3ef6905cfeedc12aa0dc70ccbf85c8293\",\"title\":\"Deep Temporal Multimodal Fusion for Medical Procedure Monitoring Using Wearable Sensors\",\"url\":\"https://www.semanticscholar.org/paper/30bb55d3ef6905cfeedc12aa0dc70ccbf85c8293\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":\"1807.00612\",\"authors\":[{\"authorId\":\"3172278\",\"name\":\"Mehmet Ali Arabaci\"},{\"authorId\":\"11255888\",\"name\":\"F. \\u00d6zkan\"},{\"authorId\":\"3299076\",\"name\":\"Elif Surer\"},{\"authorId\":\"1784515\",\"name\":\"P. Jancovic\"},{\"authorId\":\"1787799\",\"name\":\"Alptekin Temizel\"}],\"doi\":\"10.1007/s11042-020-08789-7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"77181ce3e55e25da06d0ac584c3ceef313bdde3f\",\"title\":\"Multi-modal egocentric activity recognition using multi-kernel learning\",\"url\":\"https://www.semanticscholar.org/paper/77181ce3e55e25da06d0ac584c3ceef313bdde3f\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2599451\",\"name\":\"Shervin Ardeshir\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":\"10.1016/j.cviu.2018.05.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a38a87330e434dedaadccc3add90f95c8c48a080\",\"title\":\"An exocentric look at egocentric actions and vice versa\",\"url\":\"https://www.semanticscholar.org/paper/a38a87330e434dedaadccc3add90f95c8c48a080\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3214992\",\"name\":\"A. Ortis\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"},{\"authorId\":\"1402723660\",\"name\":\"V. D'Amico\"},{\"authorId\":\"2279929\",\"name\":\"Luca Addesso\"},{\"authorId\":\"32359383\",\"name\":\"Giovanni Torrisi\"},{\"authorId\":\"1742452\",\"name\":\"S. Battiato\"}],\"doi\":\"10.1145/2983576.2983578\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5648cdde44dc5d28eedfcd7c4512731d7e4f96f9\",\"title\":\"Organizing Egocentric Videos for Daily Living Monitoring\",\"url\":\"https://www.semanticscholar.org/paper/5648cdde44dc5d28eedfcd7c4512731d7e4f96f9\",\"venue\":\"LTA@MM\",\"year\":2016},{\"arxivId\":\"2002.03137\",\"authors\":[{\"authorId\":\"144652817\",\"name\":\"Xiaohan Wang\"},{\"authorId\":\"47096706\",\"name\":\"Y. Wu\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":null,\"name\":\"Yi Yang\"}],\"doi\":\"10.1609/AAAI.V34I07.6907\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4bca2665f80765d25e71796c928dd20963e0b26e\",\"title\":\"Symbiotic Attention with Privileged Information for Egocentric Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4bca2665f80765d25e71796c928dd20963e0b26e\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143616798\",\"name\":\"Zheng Lu\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2013.350\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"996e8c706cc8e726963d3bbc4e761fc2ab68d396\",\"title\":\"Story-Driven Summarization for Egocentric Video\",\"url\":\"https://www.semanticscholar.org/paper/996e8c706cc8e726963d3bbc4e761fc2ab68d396\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":\"2011.12102\",\"authors\":[{\"authorId\":\"1773047\",\"name\":\"Qing Gao\"},{\"authorId\":\"3356854\",\"name\":\"Ming-Tao Pei\"},{\"authorId\":\"2187859\",\"name\":\"H. Shen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c195c6aa7269a7d4b64d24b079e3fd61d97f6e9c\",\"title\":\"Do You Live a Healthy Life? Analyzing Lifestyle by Visual Life Logging\",\"url\":\"https://www.semanticscholar.org/paper/c195c6aa7269a7d4b64d24b079e3fd61d97f6e9c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"73770487\",\"name\":\"A. M. Choudhury\"},{\"authorId\":\"144894381\",\"name\":\"A. S. Saif\"},{\"authorId\":\"144593525\",\"name\":\"Mashiour Rahman\"}],\"doi\":\"10.1145/3377049.3377055\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3ee8755594bfa1f5b44787769c92aaee44bfcc3d\",\"title\":\"Toddler Sensory-Motor Development for Object Manipulation by Analyzing Hand-Pose\",\"url\":\"https://www.semanticscholar.org/paper/3ee8755594bfa1f5b44787769c92aaee44bfcc3d\",\"venue\":\"ICCA\",\"year\":2020},{\"arxivId\":\"1608.08334\",\"authors\":[{\"authorId\":\"2599451\",\"name\":\"Shervin Ardeshir\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":\"10.1109/TPAMI.2018.2832121\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f00c1fcf43e0ff2de19ffe5b209b1fe85acb4d50\",\"title\":\"Egocentric Meets Top-View\",\"url\":\"https://www.semanticscholar.org/paper/f00c1fcf43e0ff2de19ffe5b209b1fe85acb4d50\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48183487\",\"name\":\"S. Samiei\"},{\"authorId\":\"134598664\",\"name\":\"Pejman Rasti\"},{\"authorId\":\"145631453\",\"name\":\"P. Richard\"},{\"authorId\":\"3395751\",\"name\":\"G. Galopin\"},{\"authorId\":\"153766356\",\"name\":\"D. Rousseau\"}],\"doi\":\"10.3390/s20154173\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c2195df91a37dc03f682ecb12ebaa5db7f77fc54\",\"title\":\"Toward Joint Acquisition-Annotation of Images with Egocentric Devices for a Lower-Cost Machine Learning Application to Apple Detection\",\"url\":\"https://www.semanticscholar.org/paper/c2195df91a37dc03f682ecb12ebaa5db7f77fc54\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2367683\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":\"10.1109/CVPR.2012.6248010\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9e81caf9dd31b893ebbee3970c312619b7eac7bf\",\"title\":\"Detecting activities of daily living in first-person camera views\",\"url\":\"https://www.semanticscholar.org/paper/9e81caf9dd31b893ebbee3970c312619b7eac7bf\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"82256529\",\"name\":\"Irwandi Hipiny\"},{\"authorId\":\"1398236231\",\"name\":\"W. Mayol-Cuevas\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d19d5c1bf21573c937165ffed0d73e57cbc03dc1\",\"title\":\"Recognising Egocentric Activities from Gaze Regions with Multiple-Voting Bag of Words\",\"url\":\"https://www.semanticscholar.org/paper/d19d5c1bf21573c937165ffed0d73e57cbc03dc1\",\"venue\":\"\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49455017\",\"name\":\"Yipin Zhou\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/ICCV.2015.511\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d12c567768b401f8d7f1ad532a2b23320ca29b49\",\"title\":\"Temporal Perception and Prediction in Ego-Centric Video\",\"url\":\"https://www.semanticscholar.org/paper/d12c567768b401f8d7f1ad532a2b23320ca29b49\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47971190\",\"name\":\"Yan Yan\"},{\"authorId\":\"40811261\",\"name\":\"E. Ricci\"},{\"authorId\":\"3056447\",\"name\":\"G. Liu\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":\"10.1109/TIP.2015.2438540\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"37880d711782fc0358a1d5914b6d63dee2734e50\",\"title\":\"Egocentric Daily Activity Recognition via Multitask Clustering\",\"url\":\"https://www.semanticscholar.org/paper/37880d711782fc0358a1d5914b6d63dee2734e50\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32591784\",\"name\":\"T. Nguyen\"},{\"authorId\":\"3085605\",\"name\":\"Jean-Christophe Nebel\"},{\"authorId\":\"1404190954\",\"name\":\"Francisco Fl\\u00f3rez-Revuelta\"}],\"doi\":\"10.3390/s16010072\",\"intent\":[\"methodology\",\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"5a48999cf31b26191e2db60d80794163d5f8c43d\",\"title\":\"Recognition of Activities of Daily Living with Egocentric Vision: A Review\",\"url\":\"https://www.semanticscholar.org/paper/5a48999cf31b26191e2db60d80794163d5f8c43d\",\"venue\":\"Sensors\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3435194\",\"name\":\"El Asnaoui Khalid\"},{\"authorId\":\"143601910\",\"name\":\"P. Radeva\"},{\"authorId\":\"15370656\",\"name\":\"Aksasse Brahim\"},{\"authorId\":\"15249320\",\"name\":\"Ouanan Mohammed\"}],\"doi\":\"10.1109/ISACV.2017.8054946\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6f69a49d454c7da51d184992d776bed87ae0a0b3\",\"title\":\"Using content-based image retrieval to automatically assess day similarity in visual lifelogs\",\"url\":\"https://www.semanticscholar.org/paper/6f69a49d454c7da51d184992d776bed87ae0a0b3\",\"venue\":\"2017 Intelligent Systems and Computer Vision (ISCV)\",\"year\":2017},{\"arxivId\":\"1906.04913\",\"authors\":[{\"authorId\":\"86955149\",\"name\":\"Wei Wang\"},{\"authorId\":\"9945144\",\"name\":\"Kaicheng Yu\"},{\"authorId\":\"2375521\",\"name\":\"Joachim Hugonot\"},{\"authorId\":\"1717736\",\"name\":\"P. Fua\"},{\"authorId\":\"2862871\",\"name\":\"M. Salzmann\"}],\"doi\":\"10.1109/ICCV.2019.00223\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"5f356ae976e756b74c762ad4734e5f73f674c1d5\",\"title\":\"Recurrent U-Net for Resource-Constrained Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/5f356ae976e756b74c762ad4734e5f73f674c1d5\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144752314\",\"name\":\"Bo Xiong\"}],\"doi\":\"10.26153/TSW/5847\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4b64bcb39e979cf6eaeb7739af468b0a08e6250d\",\"title\":\"Learning to compose photos and videos from passive cameras\",\"url\":\"https://www.semanticscholar.org/paper/4b64bcb39e979cf6eaeb7739af468b0a08e6250d\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1904.06250\",\"authors\":[{\"authorId\":\"47625239\",\"name\":\"Jiaqi Guan\"},{\"authorId\":\"145412874\",\"name\":\"Ye Yuan\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"},{\"authorId\":\"1974383\",\"name\":\"Nicholas Rhinehart\"}],\"doi\":\"10.1109/cvpr42600.2020.00025\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1e81711be35d918d1bc5c987f25e0eaa9cfb7170\",\"title\":\"Generative Hybrid Representations for Activity Forecasting With No-Regret Learning\",\"url\":\"https://www.semanticscholar.org/paper/1e81711be35d918d1bc5c987f25e0eaa9cfb7170\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1904.09882\",\"authors\":[{\"authorId\":\"143874453\",\"name\":\"Evonne Ng\"},{\"authorId\":\"2480239\",\"name\":\"Donglai Xiang\"},{\"authorId\":\"7996087\",\"name\":\"Hanbyul Joo\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/cvpr42600.2020.00991\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fe87da6f364417d87ecaf525e563851718ffdb07\",\"title\":\"You2Me: Inferring Body Pose in Egocentric Video via First and Second Person Interactions\",\"url\":\"https://www.semanticscholar.org/paper/fe87da6f364417d87ecaf525e563851718ffdb07\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1604.00906\",\"authors\":[{\"authorId\":\"39523296\",\"name\":\"Yu-Chuan Su\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1007/978-3-319-46454-1_28\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2a0957d2238a8dca24aa4a276c3370fad671c104\",\"title\":\"Detecting Engagement in Egocentric Video\",\"url\":\"https://www.semanticscholar.org/paper/2a0957d2238a8dca24aa4a276c3370fad671c104\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144061516\",\"name\":\"L. Tao\"},{\"authorId\":\"1753336\",\"name\":\"L. Zappella\"},{\"authorId\":\"1678633\",\"name\":\"Gregory Hager\"},{\"authorId\":\"144020730\",\"name\":\"R. Vidal\"}],\"doi\":\"10.1007/978-3-642-40760-4_43\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4ab382d0a97b4a193b844d982218d23ed91e640f\",\"title\":\"Surgical Gesture Segmentation and Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4ab382d0a97b4a193b844d982218d23ed91e640f\",\"venue\":\"MICCAI\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"3105474\",\"name\":\"Vignesh R. Paramathayalan\"},{\"authorId\":\"47775167\",\"name\":\"Teng Li\"},{\"authorId\":\"1742248\",\"name\":\"P. Moulin\"}],\"doi\":\"10.1007/s11263-016-0891-8\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4e7951a083bdac5c5d62c221de93181398240234\",\"title\":\"Multiple Granularity Modeling: A Coarse-to-Fine Framework for Fine-grained Action Analysis\",\"url\":\"https://www.semanticscholar.org/paper/4e7951a083bdac5c5d62c221de93181398240234\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"97514733\",\"name\":\"Jin-woo Choi\"},{\"authorId\":\"144054466\",\"name\":\"G. Sharma\"},{\"authorId\":\"1491032137\",\"name\":\"M. Chandraker\"},{\"authorId\":\"50535349\",\"name\":\"J. Huang\"}],\"doi\":\"10.1109/WACV45572.2020.9093511\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6f73e8d3b567b763898342567c332ff821b5f60e\",\"title\":\"Unsupervised and Semi-Supervised Domain Adaptation for Action Recognition from Drones\",\"url\":\"https://www.semanticscholar.org/paper/6f73e8d3b567b763898342567c332ff821b5f60e\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"},{\"authorId\":\"1782162\",\"name\":\"L. Matthies\"}],\"doi\":\"10.1007/s11263-015-0847-4\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"080e81f425dc129c4e4022568e2a23674ca41307\",\"title\":\"First-Person Activity Recognition: Feature, Temporal Structure, and Prediction\",\"url\":\"https://www.semanticscholar.org/paper/080e81f425dc129c4e4022568e2a23674ca41307\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"97362676\",\"name\":\"Katrin Wolf\"},{\"authorId\":\"1976179\",\"name\":\"Yomna Abdelrahman\"},{\"authorId\":\"144795818\",\"name\":\"D. Schmid\"},{\"authorId\":\"1726630\",\"name\":\"Tilman Dingler\"},{\"authorId\":\"145823907\",\"name\":\"A. Schmidt\"}],\"doi\":\"10.1145/2836041.2836065\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0db172c388ccad095bf3763575d35bb84c8f2091\",\"title\":\"Effects of camera position and media type on lifelogging images\",\"url\":\"https://www.semanticscholar.org/paper/0db172c388ccad095bf3763575d35bb84c8f2091\",\"venue\":\"MUM\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152401495\",\"name\":\"K. Kumar\"},{\"authorId\":\"145711908\",\"name\":\"R. Bhavani\"}],\"doi\":\"10.1145/2980258.2980433\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2a5dc32ba784ff30c73011414bfb679fbc203069\",\"title\":\"Analysis of SVM and kNN Classifiers For Egocentric Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2a5dc32ba784ff30c73011414bfb679fbc203069\",\"venue\":\"ICIA\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2926663\",\"name\":\"Yair Poleg\"},{\"authorId\":\"145676235\",\"name\":\"C. Arora\"},{\"authorId\":\"144406261\",\"name\":\"Shmuel Peleg\"}],\"doi\":\"10.1109/CVPR.2014.325\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"579c88f5fd1b1e2e84c7659b6ed589aeee06035f\",\"title\":\"Temporal Segmentation of Egocentric Videos\",\"url\":\"https://www.semanticscholar.org/paper/579c88f5fd1b1e2e84c7659b6ed589aeee06035f\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1807.08254\",\"authors\":[{\"authorId\":\"3172280\",\"name\":\"Minjie Cai\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9c1b526dc9adba029809e45693f758c2af913f60\",\"title\":\"Understanding hand-object manipulation by modeling the contextual relationship between actions, grasp types and object attributes\",\"url\":\"https://www.semanticscholar.org/paper/9c1b526dc9adba029809e45693f758c2af913f60\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1512.01881\",\"authors\":[{\"authorId\":\"36549981\",\"name\":\"Cheng-Sheng Chan\"},{\"authorId\":\"50357993\",\"name\":\"Shou-Zhong Chen\"},{\"authorId\":\"1717126\",\"name\":\"Pei-Xuan Xie\"},{\"authorId\":\"145982994\",\"name\":\"Chiung-Chih Chang\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e5a4649a57d4e8b1ba06c0aaa8b7297efa7dced9\",\"title\":\"Recognition from Hand Cameras\",\"url\":\"https://www.semanticscholar.org/paper/e5a4649a57d4e8b1ba06c0aaa8b7297efa7dced9\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145482661\",\"name\":\"C. L. Franca\"},{\"authorId\":\"1732364\",\"name\":\"R. Herv\\u00e1s\"},{\"authorId\":\"35581361\",\"name\":\"Esperanza Johnson\"}],\"doi\":\"10.3390/s18051665\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"36cd55cdb1b032c8f29e011ed0637923afc46d3f\",\"title\":\"Strategies to Improve Activity Recognition Based on Skeletal Tracking: Applying Restrictions Regarding Body Parts and Similarity Boundaries \\u2020\",\"url\":\"https://www.semanticscholar.org/paper/36cd55cdb1b032c8f29e011ed0637923afc46d3f\",\"venue\":\"Sensors\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3347447\",\"name\":\"Sanath Narayan\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"},{\"authorId\":\"81053474\",\"name\":\"K. Ramakrishnan\"}],\"doi\":\"10.1109/CVPRW.2014.82\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cc7ddb6aa5eec694d8d4abfbe16fa295577dfbbf\",\"title\":\"Action and Interaction Recognition in First-Person Videos\",\"url\":\"https://www.semanticscholar.org/paper/cc7ddb6aa5eec694d8d4abfbe16fa295577dfbbf\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition Workshops\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3172280\",\"name\":\"Minjie Cai\"},{\"authorId\":\"145053996\",\"name\":\"Feng Lu\"},{\"authorId\":\"35350470\",\"name\":\"Yue Gao\"}],\"doi\":\"10.1109/TCYB.2018.2806381\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2565c9ea9edf4275cba0679c3ef6a8f3bea8aa52\",\"title\":\"Desktop Action Recognition From First-Person Point-of-View\",\"url\":\"https://www.semanticscholar.org/paper/2565c9ea9edf4275cba0679c3ef6a8f3bea8aa52\",\"venue\":\"IEEE Transactions on Cybernetics\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144180678\",\"name\":\"M. Lu\"},{\"authorId\":\"1689656\",\"name\":\"Z. Li\"},{\"authorId\":\"7135663\",\"name\":\"Y. Wang\"},{\"authorId\":\"144563871\",\"name\":\"Gang Pan\"}],\"doi\":\"10.1109/TIP.2019.2901707\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"355f769cc896ff3ea302423587c9a1b7c2301c4e\",\"title\":\"Deep Attention Network for Egocentric Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/355f769cc896ff3ea302423587c9a1b7c2301c4e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1843583\",\"name\":\"Zhefan Ye\"},{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"47909637\",\"name\":\"Yun Liu\"},{\"authorId\":\"39936376\",\"name\":\"C. Bridges\"},{\"authorId\":\"2244531\",\"name\":\"Agata Rozga\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1109/FG.2015.7163095\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d385f4a1c7153b061b414ef361e72c0a5da7b0b7\",\"title\":\"Detecting bids for eye contact using a wearable camera\",\"url\":\"https://www.semanticscholar.org/paper/d385f4a1c7153b061b414ef361e72c0a5da7b0b7\",\"venue\":\"2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143775793\",\"name\":\"J. Kumar\"},{\"authorId\":\"144326109\",\"name\":\"Q. Li\"},{\"authorId\":\"2164893\",\"name\":\"Survi Kyal\"},{\"authorId\":\"2164140\",\"name\":\"E. Bernal\"},{\"authorId\":\"145652623\",\"name\":\"R. Bala\"}],\"doi\":\"10.1109/CVPRW.2015.7301344\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"3ca4ce8ab704b44701bf7ef8dda01c8dbb226fac\",\"title\":\"On-the-fly hand detection training with application in egocentric action recognition\",\"url\":\"https://www.semanticscholar.org/paper/3ca4ce8ab704b44701bf7ef8dda01c8dbb226fac\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2015},{\"arxivId\":\"1511.02682\",\"authors\":[{\"authorId\":\"3313330\",\"name\":\"Gedas Bertasius\"},{\"authorId\":\"1806522\",\"name\":\"H. Park\"},{\"authorId\":\"46865129\",\"name\":\"J. Shi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b0cb39acf4ae6cbd324f76be3d41b3d1da635c4c\",\"title\":\"Exploiting Egocentric Object Prior for 3D Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/b0cb39acf4ae6cbd324f76be3d41b3d1da635c4c\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1412.0065\",\"authors\":[{\"authorId\":\"3321919\",\"name\":\"Gr\\u00e9gory Rogez\"},{\"authorId\":\"48780952\",\"name\":\"Maryam Khademi\"},{\"authorId\":\"3150023\",\"name\":\"J. Supancic\"},{\"authorId\":\"145794862\",\"name\":\"J. M. M. Montiel\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":\"10.1007/978-3-319-16178-5_25\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d42aedd347f927a6bce28d0fa509c6d2132c11f\",\"title\":\"3D Hand Pose Detection in Egocentric RGB-D Images\",\"url\":\"https://www.semanticscholar.org/paper/3d42aedd347f927a6bce28d0fa509c6d2132c11f\",\"venue\":\"ECCV Workshops\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47842115\",\"name\":\"M. Liu\"},{\"authorId\":\"39578749\",\"name\":\"Siyu Tang\"},{\"authorId\":\"47002162\",\"name\":\"Y. Li\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c94aa2bff74824bb8c3adbd5c697d890d0e73620\",\"title\":\"Forecasting Human Object Interaction: Joint Prediction of Motor Attention and Egocentric Activity\",\"url\":\"https://www.semanticscholar.org/paper/c94aa2bff74824bb8c3adbd5c697d890d0e73620\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1809.00928\",\"authors\":[{\"authorId\":\"48006417\",\"name\":\"J. Likitlersuang\"},{\"authorId\":\"20678404\",\"name\":\"E. Sumitro\"},{\"authorId\":\"152612745\",\"name\":\"Tianshi Cao\"},{\"authorId\":\"83053815\",\"name\":\"R. J. Vis\\u00e9e\"},{\"authorId\":\"1398618517\",\"name\":\"S. Kalsi-Ryan\"},{\"authorId\":\"1870273\",\"name\":\"J. Zariffa\"}],\"doi\":\"10.1186/s12984-019-0557-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"33c041ae279668c4be232882684e4d854ee11031\",\"title\":\"Egocentric video: a new tool for capturing hand use of individuals with spinal cord injury at home\",\"url\":\"https://www.semanticscholar.org/paper/33c041ae279668c4be232882684e4d854ee11031\",\"venue\":\"Journal of NeuroEngineering and Rehabilitation\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3195828\",\"name\":\"L. Rybok\"}],\"doi\":\"10.5445/ir/1000073778\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1ae22453b5ee4c55fca2c7ce2f56d2ba049d7e1c\",\"title\":\"Unsupervised object candidate discovery for activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/1ae22453b5ee4c55fca2c7ce2f56d2ba049d7e1c\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3172280\",\"name\":\"Minjie Cai\"},{\"authorId\":\"1388864077\",\"name\":\"Feng Lu\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1109/cvpr42600.2020.01440\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5347a9a8bcdcbe9427628872e70f184036589046\",\"title\":\"Generalizing Hand Segmentation in Egocentric Videos With Uncertainty-Guided Model Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/5347a9a8bcdcbe9427628872e70f184036589046\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1412.0060\",\"authors\":[{\"authorId\":\"3321919\",\"name\":\"Gr\\u00e9gory Rogez\"},{\"authorId\":\"3150023\",\"name\":\"J. Supancic\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c7e3b8b408844693596a5e4da9a4328019a1a067\",\"title\":\"Egocentric Pose Recognition in Four Lines of Code\",\"url\":\"https://www.semanticscholar.org/paper/c7e3b8b408844693596a5e4da9a4328019a1a067\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"47683829\",\"name\":\"A. Fathi\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1109/ICCV.2013.399\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cd6f8f20f549bd9d6711c1c7e89c3350ed48f8c1\",\"title\":\"Learning to Predict Gaze in Egocentric Video\",\"url\":\"https://www.semanticscholar.org/paper/cd6f8f20f549bd9d6711c1c7e89c3350ed48f8c1\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152401495\",\"name\":\"K. Kumar\"},{\"authorId\":\"145711906\",\"name\":\"R. Bhavani\"}],\"doi\":\"10.1007/s11042-018-6034-1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d730fbbdfcea9fa74b59e9a324cf450cd2411fc\",\"title\":\"Human activity recognition in egocentric video using HOG, GiST and color features\",\"url\":\"https://www.semanticscholar.org/paper/4d730fbbdfcea9fa74b59e9a324cf450cd2411fc\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":\"1707.05564\",\"authors\":[{\"authorId\":\"2280086\",\"name\":\"Suvam Patra\"},{\"authorId\":\"22192364\",\"name\":\"Kartikeya Gupta\"},{\"authorId\":\"25732952\",\"name\":\"F. Ahmad\"},{\"authorId\":\"145676235\",\"name\":\"C. Arora\"},{\"authorId\":\"2226388\",\"name\":\"S. Banerjee\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"57d55ecd850ce02e95e7f8a0b942a0debaf63a1f\",\"title\":\"Batch based Monocular SLAM for Egocentric Videos\",\"url\":\"https://www.semanticscholar.org/paper/57d55ecd850ce02e95e7f8a0b942a0debaf63a1f\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1912.10867\",\"authors\":[{\"authorId\":\"39612426\",\"name\":\"A. Bandini\"},{\"authorId\":\"1870273\",\"name\":\"J. Zariffa\"}],\"doi\":\"10.1109/TPAMI.2020.2986648\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ee84cebd99eca11eaf826a803feeb804634536dc\",\"title\":\"Analysis of the hands in egocentric vision: A survey\",\"url\":\"https://www.semanticscholar.org/paper/ee84cebd99eca11eaf826a803feeb804634536dc\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72541556\",\"name\":\"X. Wang\"},{\"authorId\":\"41051809\",\"name\":\"Alireza Haji Fathaliyan\"},{\"authorId\":\"145577652\",\"name\":\"V. Santos\"}],\"doi\":\"10.3389/fnbot.2020.567571\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"467bc21ba8935685a98794fa15bc83638ec9626b\",\"title\":\"Toward Shared Autonomy Control Schemes for Human-Robot Systems: Action Primitive Recognition Using Eye Gaze Features\",\"url\":\"https://www.semanticscholar.org/paper/467bc21ba8935685a98794fa15bc83638ec9626b\",\"venue\":\"Frontiers in Neurorobotics\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2910193\",\"name\":\"Ahmet Iscen\"},{\"authorId\":\"1696365\",\"name\":\"Y. Wang\"},{\"authorId\":\"2446509\",\"name\":\"P. D. Sahin\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1007/978-3-319-16220-1_1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d42e4523c835ec7340fed705631e04f745e73be9\",\"title\":\"Snippet Based Trajectory Statistics Histograms for Assistive Technologies\",\"url\":\"https://www.semanticscholar.org/paper/d42e4523c835ec7340fed705631e04f745e73be9\",\"venue\":\"ECCV Workshops\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98658818\",\"name\":\"C. Lea\"},{\"authorId\":\"3207112\",\"name\":\"A. Reiter\"},{\"authorId\":\"144020730\",\"name\":\"R. Vidal\"},{\"authorId\":\"1678633\",\"name\":\"Gregory Hager\"}],\"doi\":\"10.1007/978-3-319-46487-9_3\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"a900a0b5319d84e212943b63265050c05b51652b\",\"title\":\"Segmental Spatiotemporal CNNs for Fine-Grained Action Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/a900a0b5319d84e212943b63265050c05b51652b\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1907.10045\",\"authors\":[{\"authorId\":\"3358340\",\"name\":\"Denis Tom\\u00e8\"},{\"authorId\":\"151353735\",\"name\":\"Patrick Peluse\"},{\"authorId\":\"3377447\",\"name\":\"L. Agapito\"},{\"authorId\":\"2863682\",\"name\":\"H. Badino\"}],\"doi\":\"10.1109/ICCV.2019.00782\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f54f2db3e1c8e79f073840a7fd4f320fb3d0589c\",\"title\":\"xR-EgoPose: Egocentric 3D Human Pose From an HMD Camera\",\"url\":\"https://www.semanticscholar.org/paper/f54f2db3e1c8e79f073840a7fd4f320fb3d0589c\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34280810\",\"name\":\"Gunnar A. Sigurdsson\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"72492981\",\"name\":\"Alahari Karteek\"}],\"doi\":\"10.1109/CVPR.2018.00772\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3586c182a3450f6eea4d64d69217383bae77e6c1\",\"title\":\"Actor and Observer: Joint Modeling of First and Third-Person Videos\",\"url\":\"https://www.semanticscholar.org/paper/3586c182a3450f6eea4d64d69217383bae77e6c1\",\"venue\":\"CVPR\",\"year\":2018},{\"arxivId\":\"1907.01481\",\"authors\":[{\"authorId\":\"150296901\",\"name\":\"Shreyas Hampali\"},{\"authorId\":\"144536317\",\"name\":\"M. Rad\"},{\"authorId\":\"2650133\",\"name\":\"Markus Oberweger\"},{\"authorId\":\"144447227\",\"name\":\"Vincent Lepetit\"}],\"doi\":\"10.1109/cvpr42600.2020.00326\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5b2c6bf5ca7f54a1d32c02fe7a1fe28b274c6ba3\",\"title\":\"HOnnotate: A Method for 3D Annotation of Hand and Object Poses\",\"url\":\"https://www.semanticscholar.org/paper/5b2c6bf5ca7f54a1d32c02fe7a1fe28b274c6ba3\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1901.01874\",\"authors\":[{\"authorId\":\"48355461\",\"name\":\"Yifei Huang\"},{\"authorId\":\"46947776\",\"name\":\"Zhenqiang Li\"},{\"authorId\":\"3172280\",\"name\":\"Minjie Cai\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1109/TIP.2020.3007841\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"78d95b989b807f28ef624318e3cb583ca1d73a3e\",\"title\":\"Mutual Context Network for Jointly Estimating Egocentric Gaze and Action\",\"url\":\"https://www.semanticscholar.org/paper/78d95b989b807f28ef624318e3cb583ca1d73a3e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3150023\",\"name\":\"J. Supancic\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"828b73e8a4d539eeae82601b5f5a4392818c6430\",\"title\":\"Long-Term Tracking by Decision Making\",\"url\":\"https://www.semanticscholar.org/paper/828b73e8a4d539eeae82601b5f5a4392818c6430\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.22028/D291-26562\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ab1719f573a6c121d7d7da5053fe5f12de0182e7\",\"title\":\"Combining visual recognition and computational linguistics : linguistic knowledge for visual recognition and natural language descriptions of visual content\",\"url\":\"https://www.semanticscholar.org/paper/ab1719f573a6c121d7d7da5053fe5f12de0182e7\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145504574\",\"name\":\"R. Templeman\"},{\"authorId\":\"145728136\",\"name\":\"Apu Kapadia\"},{\"authorId\":\"39179135\",\"name\":\"R. Hoyle\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"}],\"doi\":\"10.1145/2638728.2641708\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1d9700247570a40e7ba28cdc38de723bf6a2842a\",\"title\":\"Reactive security: responding to visual stimuli from wearable cameras\",\"url\":\"https://www.semanticscholar.org/paper/1d9700247570a40e7ba28cdc38de723bf6a2842a\",\"venue\":\"UbiComp Adjunct\",\"year\":2014},{\"arxivId\":\"1812.01738\",\"authors\":[{\"authorId\":\"144779803\",\"name\":\"Y. Yao\"},{\"authorId\":\"1806522\",\"name\":\"H. Park\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4f71709f08a451fceaaeaf6b3c814d137c8941e1\",\"title\":\"Multiview Cross-supervision for Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/4f71709f08a451fceaaeaf6b3c814d137c8941e1\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1909.06761\",\"authors\":[{\"authorId\":\"51463388\",\"name\":\"G. Kapidis\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"},{\"authorId\":\"8297919\",\"name\":\"E. V. Dam\"},{\"authorId\":\"144882447\",\"name\":\"L. Noldus\"},{\"authorId\":\"47329105\",\"name\":\"Remco C. Veltkamp\"}],\"doi\":\"10.1109/ICCVW.2019.00540\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8cca4d9e7831cad9d7b4e9693a1be9b6eaea8805\",\"title\":\"Multitask Learning to Improve Egocentric Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8cca4d9e7831cad9d7b4e9693a1be9b6eaea8805\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1803.03317\",\"authors\":[{\"authorId\":\"25263842\",\"name\":\"Aisha Urooj Khan\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":\"10.1109/CVPR.2018.00495\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c1d285c54b18834d4458c30669c24efae0fa7e9c\",\"title\":\"Analysis of Hand Segmentation in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/c1d285c54b18834d4458c30669c24efae0fa7e9c\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3053828\",\"name\":\"T. Ishihara\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"},{\"authorId\":\"2650832\",\"name\":\"W. Ma\"},{\"authorId\":\"3086992\",\"name\":\"H. Takagi\"},{\"authorId\":\"1851536\",\"name\":\"C. Asakawa\"}],\"doi\":\"10.1109/ICIP.2015.7351020\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7a0b4c7e1bb53a1753ef9156c8a7ad560a337a83\",\"title\":\"Recognizing hand-object interactions in wearable camera videos\",\"url\":\"https://www.semanticscholar.org/paper/7a0b4c7e1bb53a1753ef9156c8a7ad560a337a83\",\"venue\":\"2015 IEEE International Conference on Image Processing (ICIP)\",\"year\":2015},{\"arxivId\":\"1703.09026\",\"authors\":[{\"authorId\":\"3420479\",\"name\":\"D. Moltisanti\"},{\"authorId\":\"145032628\",\"name\":\"Michael Wray\"},{\"authorId\":\"1398236231\",\"name\":\"W. Mayol-Cuevas\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.1109/iccv.2017.314\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b02b4fb293eae3a2d87df98a132b3d701f44a579\",\"title\":\"Trespassing the Boundaries: Labeling Temporal Bounds for Object Interactions in Egocentric Video\",\"url\":\"https://www.semanticscholar.org/paper/b02b4fb293eae3a2d87df98a132b3d701f44a579\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1608.08242\",\"authors\":[{\"authorId\":\"98658818\",\"name\":\"C. Lea\"},{\"authorId\":\"144020730\",\"name\":\"R. Vidal\"},{\"authorId\":\"3207112\",\"name\":\"A. Reiter\"},{\"authorId\":\"1678633\",\"name\":\"Gregory Hager\"}],\"doi\":\"10.1007/978-3-319-49409-8_7\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6903ea1adc08200dfe2df5a54896c4c76a0088d1\",\"title\":\"Temporal Convolutional Networks: A Unified Approach to Action Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/6903ea1adc08200dfe2df5a54896c4c76a0088d1\",\"venue\":\"ECCV Workshops\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8311413\",\"name\":\"Vinodh Buddubariki\"},{\"authorId\":\"8392068\",\"name\":\"Sunitha Gowd Tulluri\"},{\"authorId\":\"34356161\",\"name\":\"Snehasis Mukherjee\"}],\"doi\":\"10.1145/3009977.3010011\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7de79a149568048db336d92dba9ea5ca54145628\",\"title\":\"Event recognition in egocentric videos using a novel trajectory based feature\",\"url\":\"https://www.semanticscholar.org/paper/7de79a149568048db336d92dba9ea5ca54145628\",\"venue\":\"ICVGIP '16\",\"year\":2016},{\"arxivId\":\"1707.06436\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":null,\"name\":\"Yun He\"},{\"authorId\":\"9935341\",\"name\":\"S. Ueta\"},{\"authorId\":\"5014206\",\"name\":\"T. Suzuki\"},{\"authorId\":\"49897653\",\"name\":\"K. Abe\"},{\"authorId\":\"2554424\",\"name\":\"Asako Kanezaki\"},{\"authorId\":\"49133490\",\"name\":\"Shinichiro Morita\"},{\"authorId\":\"22219521\",\"name\":\"Toshiyuki Yabe\"},{\"authorId\":\"50544018\",\"name\":\"Yoshihiro Kanehara\"},{\"authorId\":\"22174281\",\"name\":\"Hiroya Yatsuyanagi\"},{\"authorId\":\"1692565\",\"name\":\"S. Maruyama\"},{\"authorId\":\"10756539\",\"name\":\"Ryousuke Takasawa\"},{\"authorId\":\"3217653\",\"name\":\"Masataka Fuchida\"},{\"authorId\":\"2642022\",\"name\":\"Y. Miyashita\"},{\"authorId\":\"34935749\",\"name\":\"Kazushige Okayasu\"},{\"authorId\":\"20505300\",\"name\":\"Yuta Matsuzaki\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"title\":\"cvpaper.challenge in 2016: Futuristic Computer Vision through 1, 600 Papers Survey\",\"url\":\"https://www.semanticscholar.org/paper/8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46796686\",\"name\":\"Roei Herzig\"},{\"authorId\":\"34490455\",\"name\":\"Elad Levi\"},{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"153585940\",\"name\":\"Hang Gao\"},{\"authorId\":\"2041489\",\"name\":\"E. Brosh\"},{\"authorId\":\"17279245\",\"name\":\"X. Wang\"},{\"authorId\":\"1786843\",\"name\":\"A. Globerson\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/ICCVW.2019.00288\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3be602c7c3812397a29c64e544981a362de80f27\",\"title\":\"Spatio-Temporal Action Graph Networks\",\"url\":\"https://www.semanticscholar.org/paper/3be602c7c3812397a29c64e544981a362de80f27\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1804.09627\",\"authors\":[{\"authorId\":\"34280810\",\"name\":\"Gunnar A. Sigurdsson\"},{\"authorId\":null,\"name\":\"Abhinav Gupta\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"47465174\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"72492981\",\"name\":\"Alahari Karteek\"}],\"doi\":\"10.1145/3265987.3265995\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e5bce81f9f0a4b962ae39205be9985bc5128fce9\",\"title\":\"Actor and Observer: Joint Modeling of First and Third-Person Videos\",\"url\":\"https://www.semanticscholar.org/paper/e5bce81f9f0a4b962ae39205be9985bc5128fce9\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1806522\",\"name\":\"H. Park\"},{\"authorId\":\"46865129\",\"name\":\"J. Shi\"}],\"doi\":\"10.1109/TPAMI.2018.2883327\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3c56e90cc0a9baa3582931313e313784ecc6e507\",\"title\":\"Force from Motion: Decoding Control Force of Activity in a First-Person Video\",\"url\":\"https://www.semanticscholar.org/paper/3c56e90cc0a9baa3582931313e313784ecc6e507\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72608846\",\"name\":\"Mohammad Moghimi Najafabadi\"}],\"doi\":\"10.7298/X4F47M34\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d66f0f69b73ae5faf10021fc59e4f9bcbeaf7cc3\",\"title\":\"Analyzing life-logging image sequences\",\"url\":\"https://www.semanticscholar.org/paper/d66f0f69b73ae5faf10021fc59e4f9bcbeaf7cc3\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1406.5309\",\"authors\":[{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"},{\"authorId\":\"34459632\",\"name\":\"Thomas J. Fuchs\"},{\"authorId\":\"47839689\",\"name\":\"L. Xia\"},{\"authorId\":\"1705627\",\"name\":\"J. Aggarwal\"},{\"authorId\":\"1782162\",\"name\":\"L. Matthies\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f103739051977cb08ec7d45b90b80e1d50560c40\",\"title\":\"Early Recognition of Human Activities from First-Person Videos Using Onset Representations\",\"url\":\"https://www.semanticscholar.org/paper/f103739051977cb08ec7d45b90b80e1d50560c40\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":\"2012.07508\",\"authors\":[{\"authorId\":\"113144757\",\"name\":\"D. Wang\"},{\"authorId\":\"153211990\",\"name\":\"Di Hu\"},{\"authorId\":\"7824051\",\"name\":\"Xingjian Li\"},{\"authorId\":\"1721158\",\"name\":\"D. Dou\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b20ccb5e53bcc5e76d05d173149d3926bec952fd\",\"title\":\"Temporal Relational Modeling with Self-Supervision for Action Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/b20ccb5e53bcc5e76d05d173149d3926bec952fd\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40408041\",\"name\":\"K. Ozcan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"3169f6e77b4892755cf4750b7d24622fc2619cdc\",\"title\":\"Computer Vision Algorithms for Mobile Camera Applications\",\"url\":\"https://www.semanticscholar.org/paper/3169f6e77b4892755cf4750b7d24622fc2619cdc\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1701.00142\",\"authors\":[{\"authorId\":\"2933543\",\"name\":\"H. Rhodin\"},{\"authorId\":\"1819028\",\"name\":\"C. Richardt\"},{\"authorId\":\"1863006\",\"name\":\"D. Casas\"},{\"authorId\":\"3205238\",\"name\":\"Eldar Insafutdinov\"},{\"authorId\":\"32776367\",\"name\":\"Mohammad Shafiei\"},{\"authorId\":\"145156858\",\"name\":\"H. Seidel\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"}],\"doi\":\"10.1145/2980179.2980235\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ec2d6d3bfa6a342c215c4f1ee1ae22a5c4ca82ae\",\"title\":\"EgoCap: egocentric marker-less motion capture with two fisheye cameras\",\"url\":\"https://www.semanticscholar.org/paper/ec2d6d3bfa6a342c215c4f1ee1ae22a5c4ca82ae\",\"venue\":\"ACM Trans. Graph.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48355651\",\"name\":\"Yifei Huang\"},{\"authorId\":\"1751242\",\"name\":\"Yusuke Sugano\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1109/cvpr42600.2020.01404\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2aeb56eee55d26fa845c7872b996c3d92bc45abd\",\"title\":\"Improving Action Segmentation via Graph-Based Temporal Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/2aeb56eee55d26fa845c7872b996c3d92bc45abd\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1802086\",\"name\":\"V. Chandrasekhar\"},{\"authorId\":\"1694051\",\"name\":\"Cheston Tan\"},{\"authorId\":\"145977119\",\"name\":\"Wu Min\"},{\"authorId\":\"35718875\",\"name\":\"L. Li\"},{\"authorId\":\"22476943\",\"name\":\"X. Li\"},{\"authorId\":\"6516914\",\"name\":\"J. Lim\"}],\"doi\":\"10.1109/ICPR.2014.454\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"998e0af2906fb6e2930930cddc4a47199fd00c04\",\"title\":\"Incremental Graph Clustering for Efficient Retrieval from Streaming Egocentric Video Data\",\"url\":\"https://www.semanticscholar.org/paper/998e0af2906fb6e2930930cddc4a47199fd00c04\",\"venue\":\"2014 22nd International Conference on Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"119858851\",\"name\":\"J. Xu\"},{\"authorId\":\"144324490\",\"name\":\"Lopamudra Mukherjee\"},{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"40450406\",\"name\":\"J. Warner\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"},{\"authorId\":\"144711711\",\"name\":\"V. Singh\"}],\"doi\":\"10.1109/CVPR.2015.7298836\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2aacb2a897dfddd49bb162d87ca80863ca8ef1c2\",\"title\":\"Gaze-enabled egocentric video summarization via constrained submodular maximization\",\"url\":\"https://www.semanticscholar.org/paper/2aacb2a897dfddd49bb162d87ca80863ca8ef1c2\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2813082\",\"name\":\"J. Lee\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1109/IROS.2017.8205953\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e0e8a3b6c6f1521d222ebf71bfa53f9f8dd75312\",\"title\":\"Learning robot activities from first-person human videos using convolutional future regression\",\"url\":\"https://www.semanticscholar.org/paper/e0e8a3b6c6f1521d222ebf71bfa53f9f8dd75312\",\"venue\":\"2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1760870\",\"name\":\"Y. Lin\"},{\"authorId\":\"2852035\",\"name\":\"V. Morariu\"},{\"authorId\":\"1716836\",\"name\":\"W. Hsu\"}],\"doi\":\"10.1109/ICCVW.2015.65\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"806d9616e10020f069e604c4c828ae992b694c7d\",\"title\":\"Summarizing While Recording: Context-Based Highlight Detection for Egocentric Videos\",\"url\":\"https://www.semanticscholar.org/paper/806d9616e10020f069e604c4c828ae992b694c7d\",\"venue\":\"2015 IEEE International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144652817\",\"name\":\"Xiaohan Wang\"},{\"authorId\":\"2448536\",\"name\":\"F. M. Eliott\"},{\"authorId\":\"32682119\",\"name\":\"James Ainooson\"},{\"authorId\":\"37000424\",\"name\":\"J. Palmer\"},{\"authorId\":\"2333314\",\"name\":\"M. Kunda\"}],\"doi\":\"10.1109/ICCVW.2017.279\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"678a01184a2841842d4718ad050365982b957fba\",\"title\":\"An Object is Worth Six Thousand Pictures: The Egocentric, Manual, Multi-image (EMMI) Dataset\",\"url\":\"https://www.semanticscholar.org/paper/678a01184a2841842d4718ad050365982b957fba\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121944615\",\"name\":\"Stefan Lee\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3bfd34f04cd1afe1bacf783552bc8004eb50ab1b\",\"title\":\"Data-driven computer vision for science and the humanities\",\"url\":\"https://www.semanticscholar.org/paper/3bfd34f04cd1afe1bacf783552bc8004eb50ab1b\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150296901\",\"name\":\"Shreyas Hampali\"},{\"authorId\":\"2650133\",\"name\":\"Markus Oberweger\"},{\"authorId\":\"144536317\",\"name\":\"M. Rad\"},{\"authorId\":\"144447227\",\"name\":\"Vincent Lepetit\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"18f649b8652703dd3053f798eae9e4b1fd44cd2f\",\"title\":\"HO-3D: A Multi-User, Multi-Object Dataset for Joint 3D Hand-Object Pose Estimation\",\"url\":\"https://www.semanticscholar.org/paper/18f649b8652703dd3053f798eae9e4b1fd44cd2f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4947266e0caa3d8be726b98f5be08217748a6e20\",\"title\":\"Input Mask Encoder z Decoder Reconstructed Mask a ) VAE Input Mask Action CNN b ) Action CNN Predicted Action Probability Fixed Action\",\"url\":\"https://www.semanticscholar.org/paper/4947266e0caa3d8be726b98f5be08217748a6e20\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41051074\",\"name\":\"Kai Toyama\"},{\"authorId\":\"1717358\",\"name\":\"Y. Sumi\"}],\"doi\":\"10.1007/978-3-319-90740-6_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"261973e1fe559be74531f4a922750c9f7ed5825c\",\"title\":\"Quick Browsing of Shared Experience Videos Based on Conversational Field Detection\",\"url\":\"https://www.semanticscholar.org/paper/261973e1fe559be74531f4a922750c9f7ed5825c\",\"venue\":\"MobiCASE\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1167/14.3.29\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"639722c2c23e8c8033b715d039e1f14d79cb970e\",\"title\":\"Defending Yarbus: eye movements reveal observers' task.\",\"url\":\"https://www.semanticscholar.org/paper/639722c2c23e8c8033b715d039e1f14d79cb970e\",\"venue\":\"Journal of vision\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2452223\",\"name\":\"Kazuto Nakashima\"},{\"authorId\":\"1429832993\",\"name\":\"Julien Girard-Satabin\"},{\"authorId\":\"1795530\",\"name\":\"Y. Iwashita\"},{\"authorId\":\"1801213\",\"name\":\"R. Kurazume\"}],\"doi\":\"10.1109/SII.2016.7844021\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b632e7d58fe22bbc96742533d848fd4294f5a6ab\",\"title\":\"Automatic houseware registration system for informationally-structured environment\",\"url\":\"https://www.semanticscholar.org/paper/b632e7d58fe22bbc96742533d848fd4294f5a6ab\",\"venue\":\"2016 IEEE/SICE International Symposium on System Integration (SII)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145558934\",\"name\":\"S. Mann\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"},{\"authorId\":\"144756076\",\"name\":\"Y. Lee\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"},{\"authorId\":\"47683829\",\"name\":\"A. Fathi\"}],\"doi\":\"10.1109/CVPRW.2014.133\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3a192e0391c357124cd2ec2287b1706f523ecdfd\",\"title\":\"An Introduction to the 3rd Workshop on Egocentric (First-Person) Vision\",\"url\":\"https://www.semanticscholar.org/paper/3a192e0391c357124cd2ec2287b1706f523ecdfd\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition Workshops\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39956342\",\"name\":\"Wenbin Li\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":\"10.1109/WACV.2016.7477586\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"65355cbb581a219bd7461d48b3afd115263ea760\",\"title\":\"Recognition of ongoing complex activities by sequence prediction over a hierarchical label space\",\"url\":\"https://www.semanticscholar.org/paper/65355cbb581a219bd7461d48b3afd115263ea760\",\"venue\":\"2016 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50398746\",\"name\":\"B. Xiong\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1007/978-3-319-10602-1_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aea8047ec01c18fd3f279e9e7e55822cbd4b4d46\",\"title\":\"Detecting Snap Points in Egocentric Video with a Web Photo Prior\",\"url\":\"https://www.semanticscholar.org/paper/aea8047ec01c18fd3f279e9e7e55822cbd4b4d46\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48333718\",\"name\":\"Pascal Fallavollita\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"94e2b2d898d7faf1c67f53d1003634b475ba069e\",\"title\":\"Chapter 2 Innovative Technologies for Medical Education\",\"url\":\"https://www.semanticscholar.org/paper/94e2b2d898d7faf1c67f53d1003634b475ba069e\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1843583\",\"name\":\"Zhefan Ye\"},{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"47683829\",\"name\":\"A. Fathi\"},{\"authorId\":\"15317660\",\"name\":\"Yi Han\"},{\"authorId\":\"2244531\",\"name\":\"Agata Rozga\"},{\"authorId\":\"9267108\",\"name\":\"Gregory D. Abowd\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1145/2370216.2370368\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"48359777b66b64c464fa69bc31ac132d2c586a25\",\"title\":\"Detecting eye contact using wearable eye-tracking glasses\",\"url\":\"https://www.semanticscholar.org/paper/48359777b66b64c464fa69bc31ac132d2c586a25\",\"venue\":\"UbiComp '12\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3214992\",\"name\":\"A. Ortis\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"},{\"authorId\":\"1402723660\",\"name\":\"V. D'Amico\"},{\"authorId\":\"2279929\",\"name\":\"Luca Addesso\"},{\"authorId\":\"32359383\",\"name\":\"Giovanni Torrisi\"},{\"authorId\":\"1742452\",\"name\":\"S. Battiato\"}],\"doi\":\"10.1016/j.patcog.2017.07.010\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b906508989bfdb128e53b69b75cc9e878cb61465\",\"title\":\"Organizing egocentric videos of daily living activities\",\"url\":\"https://www.semanticscholar.org/paper/b906508989bfdb128e53b69b75cc9e878cb61465\",\"venue\":\"Pattern Recognit.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48006417\",\"name\":\"J. Likitlersuang\"},{\"authorId\":\"1870273\",\"name\":\"J. Zariffa\"}],\"doi\":\"10.1109/JBHI.2016.2636748\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bbd14ce214501cf0b9e342500201d0622284eac3\",\"title\":\"Interaction Detection in Egocentric Video: Toward a Novel Outcome Measure for Upper Extremity Function\",\"url\":\"https://www.semanticscholar.org/paper/bbd14ce214501cf0b9e342500201d0622284eac3\",\"venue\":\"IEEE Journal of Biomedical and Health Informatics\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2798750\",\"name\":\"Sven Bambach\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"af4d99f5bc0ef4525708904e36ee9751957f089b\",\"title\":\"Tracking Hands of Interacting People in Egocentric Video\",\"url\":\"https://www.semanticscholar.org/paper/af4d99f5bc0ef4525708904e36ee9751957f089b\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34575696\",\"name\":\"Keita Higuchi\"},{\"authorId\":\"1899753\",\"name\":\"Ryo Yonetani\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1145/3025453.3025821\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"835680aa3c770a2360e62e467d82760936e52431\",\"title\":\"EgoScanning: Quickly Scanning First-Person Videos with Egocentric Elastic Timelines\",\"url\":\"https://www.semanticscholar.org/paper/835680aa3c770a2360e62e467d82760936e52431\",\"venue\":\"CHI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1901010\",\"name\":\"A. Cartas\"},{\"authorId\":\"143601910\",\"name\":\"P. Radeva\"},{\"authorId\":\"2837527\",\"name\":\"Mariella Dimiccoli\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"08825ffe4dc4f673eb86de43f9a708c85cdf9947\",\"title\":\"Contextually Driven First-person Action Recognition From Videos\",\"url\":\"https://www.semanticscholar.org/paper/08825ffe4dc4f673eb86de43f9a708c85cdf9947\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1742452\",\"name\":\"S. Battiato\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":\"10.1016/j.jvcir.2018.01.019\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"79bb40158293d747ebfd76445f927bb5c09f9cb8\",\"title\":\"Personal-location-based temporal segmentation of egocentric videos for lifelogging applications\",\"url\":\"https://www.semanticscholar.org/paper/79bb40158293d747ebfd76445f927bb5c09f9cb8\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9764377\",\"name\":\"Xuanhan Wang\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"34798935\",\"name\":\"Xiantong Zhen\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1016/j.neucom.2017.08.063\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c5e8046c5393847439232c94846b7556ad201ba4\",\"title\":\"Deep appearance and motion learning for egocentric activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/c5e8046c5393847439232c94846b7556ad201ba4\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"103678890\",\"name\":\"Humaira A. Ghafoor\"},{\"authorId\":\"144865166\",\"name\":\"A. Javed\"},{\"authorId\":\"2809162\",\"name\":\"Aun Irtaza\"},{\"authorId\":\"51260966\",\"name\":\"H. Dawood\"},{\"authorId\":\"145337997\",\"name\":\"H. Dawood\"},{\"authorId\":\"2823041\",\"name\":\"Ameen Banjar\"}],\"doi\":\"10.1155/2018/7586417\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"87da2e37fb6464e3664aa27625cf5e25ece8fe6f\",\"title\":\"Egocentric Video Summarization Based on People Interaction Using Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/87da2e37fb6464e3664aa27625cf5e25ece8fe6f\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1607.06264\",\"authors\":[{\"authorId\":\"145086911\",\"name\":\"A. Betancourt\"},{\"authorId\":\"2322579\",\"name\":\"Pietro Morerio\"},{\"authorId\":\"145741020\",\"name\":\"E. Barakova\"},{\"authorId\":\"1689330\",\"name\":\"L. Marcenaro\"},{\"authorId\":\"1736974\",\"name\":\"M. Rauterberg\"},{\"authorId\":\"9587913\",\"name\":\"C. Regazzoni\"}],\"doi\":\"10.1016/j.cviu.2016.09.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0fb34be57900fe202baeacb00e8dcfa53f0bb58f\",\"title\":\"Left/right hand segmentation in egocentric videos\",\"url\":\"https://www.semanticscholar.org/paper/0fb34be57900fe202baeacb00e8dcfa53f0bb58f\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1901010\",\"name\":\"A. Cartas\"},{\"authorId\":\"144952180\",\"name\":\"J. Mar\\u00edn\"},{\"authorId\":\"143601910\",\"name\":\"P. Radeva\"},{\"authorId\":\"2837527\",\"name\":\"Mariella Dimiccoli\"}],\"doi\":\"10.1007/s10044-018-0708-1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a625b55cf8914d6f275478773b84f58ad8ffdd85\",\"title\":\"Batch-based activity recognition from egocentric photo-streams revisited\",\"url\":\"https://www.semanticscholar.org/paper/a625b55cf8914d6f275478773b84f58ad8ffdd85\",\"venue\":\"Pattern Analysis and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49370704\",\"name\":\"Dong Wang\"},{\"authorId\":\"153197501\",\"name\":\"Yuan Yuan\"},{\"authorId\":\"50621207\",\"name\":\"Q. Wang\"}],\"doi\":\"10.1016/j.neucom.2020.03.066\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a84ef229e2349fcd59e7f235acf9e697b31462ff\",\"title\":\"Gated forward refinement network for action segmentation\",\"url\":\"https://www.semanticscholar.org/paper/a84ef229e2349fcd59e7f235acf9e697b31462ff\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1974383\",\"name\":\"Nicholas Rhinehart\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"6dbe18855b85bc6f218c53993cf289e2607518b1\",\"title\":\"Learning Policies to Forecast Agent Behavior with Visual Data\",\"url\":\"https://www.semanticscholar.org/paper/6dbe18855b85bc6f218c53993cf289e2607518b1\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123624286\",\"name\":\"N. Vo\"},{\"authorId\":\"1688328\",\"name\":\"A. Bobick\"}],\"doi\":\"10.1016/j.cviu.2015.07.006\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"43fa3e986b4f3df3c0ebbe4dcf7d451e9018efcc\",\"title\":\"Sequential Interval Network for parsing complex structured activity\",\"url\":\"https://www.semanticscholar.org/paper/43fa3e986b4f3df3c0ebbe4dcf7d451e9018efcc\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2016},{\"arxivId\":\"1610.05693\",\"authors\":[{\"authorId\":\"34876449\",\"name\":\"E. Aksoy\"},{\"authorId\":\"9738883\",\"name\":\"Adil Orhan\"},{\"authorId\":\"1714016\",\"name\":\"F. W\\u00f6rg\\u00f6tter\"}],\"doi\":\"10.1007/s11263-016-0956-8\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"fe56243209f577223e673d3275191c76bebdb3cd\",\"title\":\"Semantic Decomposition and Recognition of Long and Complex Manipulation Action Sequences\",\"url\":\"https://www.semanticscholar.org/paper/fe56243209f577223e673d3275191c76bebdb3cd\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145482661\",\"name\":\"C. L. Franca\"},{\"authorId\":\"1732364\",\"name\":\"R. Herv\\u00e1s\"},{\"authorId\":\"35581361\",\"name\":\"Esperanza Johnson\"},{\"authorId\":\"143923637\",\"name\":\"J. Bravo\"}],\"doi\":\"10.1007/978-3-319-48746-5_55\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"316c2ed4b8c6b9683ae31a9166913d317f14f2f7\",\"title\":\"Findings About Selecting Body Parts to Analyze Human Activities Through Skeletal Tracking Joint Oriented Devices\",\"url\":\"https://www.semanticscholar.org/paper/316c2ed4b8c6b9683ae31a9166913d317f14f2f7\",\"venue\":\"UCAmI\",\"year\":2016},{\"arxivId\":\"1703.01040\",\"authors\":[{\"authorId\":\"2813082\",\"name\":\"J. Lee\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1109/CVPRW.2017.63\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b6c95b567701f38fe3d87bbd56e3da9ad5ee35ca\",\"title\":\"Learning Robot Activities from First-Person Human Videos Using Convolutional Future Regression\",\"url\":\"https://www.semanticscholar.org/paper/b6c95b567701f38fe3d87bbd56e3da9ad5ee35ca\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144489175\",\"name\":\"Y. Zhou\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"48043335\",\"name\":\"R. Hong\"},{\"authorId\":\"1795291\",\"name\":\"X. Yang\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/CVPR.2016.210\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7de1d463fef3c63cb228f5b4a6a72e62f66630e6\",\"title\":\"Cascaded Interactional Targeting Network for Egocentric Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/7de1d463fef3c63cb228f5b4a6a72e62f66630e6\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1605.01679\",\"authors\":[{\"authorId\":\"1974383\",\"name\":\"Nicholas Rhinehart\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"}],\"doi\":\"10.1109/CVPR.2016.69\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8f38d907b60602c79a3368e96e54cd5c14cdd84f\",\"title\":\"Learning Action Maps of Large Environments via First-Person Vision\",\"url\":\"https://www.semanticscholar.org/paper/8f38d907b60602c79a3368e96e54cd5c14cdd84f\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1611.05267\",\"authors\":[{\"authorId\":\"98658818\",\"name\":\"C. Lea\"},{\"authorId\":\"49447925\",\"name\":\"M. Flynn\"},{\"authorId\":\"144020730\",\"name\":\"R. Vidal\"},{\"authorId\":\"3207112\",\"name\":\"A. Reiter\"},{\"authorId\":\"1678633\",\"name\":\"Gregory Hager\"}],\"doi\":\"10.1109/CVPR.2017.113\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"210f258524deabc3d08cbbea4e4ca5c2a98f4846\",\"title\":\"Temporal Convolutional Networks for Action Segmentation and Detection\",\"url\":\"https://www.semanticscholar.org/paper/210f258524deabc3d08cbbea4e4ca5c2a98f4846\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145052333\",\"name\":\"Kang Zheng\"},{\"authorId\":\"2933674\",\"name\":\"Yuewei Lin\"},{\"authorId\":\"1746008\",\"name\":\"Youjie Zhou\"},{\"authorId\":\"2968009\",\"name\":\"D. Salvi\"},{\"authorId\":\"49537566\",\"name\":\"Xiaochuan Fan\"},{\"authorId\":\"145889317\",\"name\":\"Dazhou Guo\"},{\"authorId\":\"3091647\",\"name\":\"Zibo Meng\"},{\"authorId\":\"30102584\",\"name\":\"S. Wang\"}],\"doi\":\"10.1007/978-3-319-16178-5_51\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bf726ec891e9ecd3ec99eec82757b21083aa354a\",\"title\":\"Video-Based Action Detection Using Multiple Wearable Cameras\",\"url\":\"https://www.semanticscholar.org/paper/bf726ec891e9ecd3ec99eec82757b21083aa354a\",\"venue\":\"ECCV Workshops\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3056447\",\"name\":\"G. Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0888b6904ef12bc7a3c59fa59c4051d5002de80f\",\"title\":\"Learning with Shared Information for Image and Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/0888b6904ef12bc7a3c59fa59c4051d5002de80f\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2599451\",\"name\":\"Shervin Ardeshir\"},{\"authorId\":\"3177797\",\"name\":\"Ali Borji\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a1099173f9df4173f8f68ecd00ce780ac9ef2df4\",\"title\":\"Egocentric Meets Surveillance\",\"url\":\"https://www.semanticscholar.org/paper/a1099173f9df4173f8f68ecd00ce780ac9ef2df4\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1603.09439\",\"authors\":[{\"authorId\":\"1879100\",\"name\":\"P. Nguyen\"},{\"authorId\":\"3321919\",\"name\":\"Gr\\u00e9gory Rogez\"},{\"authorId\":\"143800213\",\"name\":\"Charless C. Fowlkes\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f631f754afc9a82fa7a5e5a70eac37376c7379ef\",\"title\":\"The Open World of Micro-Videos\",\"url\":\"https://www.semanticscholar.org/paper/f631f754afc9a82fa7a5e5a70eac37376c7379ef\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1907.09382\",\"authors\":[{\"authorId\":\"145254119\",\"name\":\"Huseyin Coskun\"},{\"authorId\":\"48151137\",\"name\":\"Z. Zia\"},{\"authorId\":\"39307390\",\"name\":\"Bugra Tekin\"},{\"authorId\":\"2988774\",\"name\":\"Federica Bogo\"},{\"authorId\":\"145587209\",\"name\":\"N. Navab\"},{\"authorId\":\"2266326\",\"name\":\"Federico Tombari\"},{\"authorId\":\"1733393\",\"name\":\"H. Sawhney\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"18cb8c24fae3186487b14fdb28b1b2617057198f\",\"title\":\"Domain-Specific Priors and Meta Learning for Low-shot First-Person Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/18cb8c24fae3186487b14fdb28b1b2617057198f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1733564\",\"name\":\"K. Kurzhals\"},{\"authorId\":\"46253823\",\"name\":\"Nils Rodrigues\"},{\"authorId\":\"46206249\",\"name\":\"Maurice Koch\"},{\"authorId\":\"144949648\",\"name\":\"Michael Stoll\"},{\"authorId\":\"144031005\",\"name\":\"A. Bruhn\"},{\"authorId\":\"3194727\",\"name\":\"Andreas Bulling\"},{\"authorId\":\"69863469\",\"name\":\"D. Weiskopf\"}],\"doi\":\"10.1145/3379155.3391326\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8b165ca2a5ab92de87d4df5a315438025becbaf2\",\"title\":\"Visual Analytics and Annotation of Pervasive Eye Tracking Video\",\"url\":\"https://www.semanticscholar.org/paper/8b165ca2a5ab92de87d4df5a315438025becbaf2\",\"venue\":\"ETRA\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48946640\",\"name\":\"Asamichi Takamine\"},{\"authorId\":\"1795530\",\"name\":\"Y. Iwashita\"},{\"authorId\":\"1801213\",\"name\":\"R. Kurazume\"}],\"doi\":\"10.1109/SII.2015.7405050\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"30b7d284c29e49a55797041dffd26d8cfe3ad9ca\",\"title\":\"First-person activity recognition with C3D features from optical flow images\",\"url\":\"https://www.semanticscholar.org/paper/30b7d284c29e49a55797041dffd26d8cfe3ad9ca\",\"venue\":\"2015 IEEE/SICE International Symposium on System Integration (SII)\",\"year\":2015},{\"arxivId\":\"1601.04406\",\"authors\":[{\"authorId\":\"3115428\",\"name\":\"Vinay Bettadapura\"},{\"authorId\":\"118242229\",\"name\":\"D. Castro\"},{\"authorId\":\"21472040\",\"name\":\"Irfan Essa\"}],\"doi\":\"10.1109/WACV.2016.7477707\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d830ac06ef23298106461a2f6dd97c404c4fbb13\",\"title\":\"Discovering picturesque highlights from egocentric vacation videos\",\"url\":\"https://www.semanticscholar.org/paper/d830ac06ef23298106461a2f6dd97c404c4fbb13\",\"venue\":\"2016 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2303172\",\"name\":\"Peng Lei\"},{\"authorId\":\"143856428\",\"name\":\"S. Todorovic\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b9306e90facafc2001e6f01f209ddbb0694d61fb\",\"title\":\"AN ABSTRACT OF THE DISSERTATION OF\",\"url\":\"https://www.semanticscholar.org/paper/b9306e90facafc2001e6f01f209ddbb0694d61fb\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1931096\",\"name\":\"A. Behera\"},{\"authorId\":\"1967104\",\"name\":\"David C. Hogg\"},{\"authorId\":\"1703235\",\"name\":\"A. Cohn\"}],\"doi\":\"10.1007/978-3-642-37431-9_40\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eccd9b24f6faeee672b28f83cf5b849f6746e7c7\",\"title\":\"Egocentric Activity Monitoring and Recovery\",\"url\":\"https://www.semanticscholar.org/paper/eccd9b24f6faeee672b28f83cf5b849f6746e7c7\",\"venue\":\"ACCV\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50750258\",\"name\":\"T. Okawara\"},{\"authorId\":\"80809027\",\"name\":\"M. Yoshida\"},{\"authorId\":\"145800886\",\"name\":\"H. Nagahara\"},{\"authorId\":\"1715071\",\"name\":\"Y. Yagi\"}],\"doi\":\"10.1109/ICCP48838.2020.9105176\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"90ccdae5898712d2cb59d52f6aad0aeb64066eb6\",\"title\":\"Action Recognition from a Single Coded Image\",\"url\":\"https://www.semanticscholar.org/paper/90ccdae5898712d2cb59d52f6aad0aeb64066eb6\",\"venue\":\"2020 IEEE International Conference on Computational Photography (ICCP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2964199\",\"name\":\"I. Gori\"},{\"authorId\":\"1705627\",\"name\":\"J. Aggarwal\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"114d6a2503847a72afeb38e79243ad10abc7e123\",\"title\":\"Building Unified Human Descriptors For Multi-Type Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/114d6a2503847a72afeb38e79243ad10abc7e123\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2628886\",\"name\":\"Tao Zhuo\"},{\"authorId\":\"48754075\",\"name\":\"P. Zhang\"},{\"authorId\":\"2497558\",\"name\":\"K. Chen\"},{\"authorId\":\"1801395\",\"name\":\"Y. Zhang\"}],\"doi\":\"10.1109/ACII.2015.7344674\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cb40e7b35dc623953b9289ff2ffb4c6af2536a4d\",\"title\":\"Superframe segmentation based on content-motion correspondence for social video summarization\",\"url\":\"https://www.semanticscholar.org/paper/cb40e7b35dc623953b9289ff2ffb4c6af2536a4d\",\"venue\":\"2015 International Conference on Affective Computing and Intelligent Interaction (ACII)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1806522\",\"name\":\"H. Park\"},{\"authorId\":\"2351486\",\"name\":\"Jyh-Jing Hwang\"},{\"authorId\":\"46865129\",\"name\":\"J. Shi\"}],\"doi\":\"10.1109/CVPR.2016.416\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3c5b3c90f951ca0f4b4e3a0ac3dd6aacae4adf72\",\"title\":\"Force from Motion: Decoding Physical Sensation in a First Person Video\",\"url\":\"https://www.semanticscholar.org/paper/3c5b3c90f951ca0f4b4e3a0ac3dd6aacae4adf72\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144243028\",\"name\":\"Mohammad Moghimi\"},{\"authorId\":\"144461750\",\"name\":\"J. Kerr\"},{\"authorId\":\"145106646\",\"name\":\"E. Johnson\"},{\"authorId\":\"144568199\",\"name\":\"S. Godbole\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"}],\"doi\":\"10.1007/978-3-319-14442-9_42\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"65601451bf636e4655007b0fc535b32eca980cc8\",\"title\":\"Discriminative Regions: A Substrate for Analyzing Life-Logging Image Sequences\",\"url\":\"https://www.semanticscholar.org/paper/65601451bf636e4655007b0fc535b32eca980cc8\",\"venue\":\"MMM\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32361885\",\"name\":\"H. Le\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e0f5414255ed0df14f17085a1ff3216429a5923c\",\"title\":\"Development and Evaluation of Automatic Video Recaps from Lifelog Data Huy Viet\",\"url\":\"https://www.semanticscholar.org/paper/e0f5414255ed0df14f17085a1ff3216429a5923c\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2452223\",\"name\":\"Kazuto Nakashima\"},{\"authorId\":\"1795530\",\"name\":\"Y. Iwashita\"},{\"authorId\":\"48946640\",\"name\":\"Asamichi Takamine\"},{\"authorId\":\"1801213\",\"name\":\"R. Kurazume\"}],\"doi\":\"10.1299/JSMERMD.2016.2P2-03A4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fa537bfb5171dbe16f5e97099fdd9eb945aafa0b\",\"title\":\"Automatic Houseware Registration System using Egocentric Vision and Faster R-CNN for Informationally-Structured Environment\",\"url\":\"https://www.semanticscholar.org/paper/fa537bfb5171dbe16f5e97099fdd9eb945aafa0b\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150965117\",\"name\":\"Daniel Alejandro Castro Chin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b24c218e8545bdbe58d3a614aee6c9063dd40d62\",\"title\":\"Understanding The Motion of A Human State In Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/b24c218e8545bdbe58d3a614aee6c9063dd40d62\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1905.09035\",\"authors\":[{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":\"10.1109/ICCV.2019.00635\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"792829f263a523eedf1a8748ec23d25cf664c2b4\",\"title\":\"What Would You Expect? Anticipating Egocentric Actions With Rolling-Unrolling LSTMs and Modality Attention\",\"url\":\"https://www.semanticscholar.org/paper/792829f263a523eedf1a8748ec23d25cf664c2b4\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31197849\",\"name\":\"Shaohua Wan\"},{\"authorId\":\"1705627\",\"name\":\"J. Aggarwal\"}],\"doi\":\"10.1109/CVPRW.2015.7301346\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"043f2a41b1183e60200274c7af756607c9c1d347\",\"title\":\"Mining discriminative states of hands and objects to recognize egocentric actions with a wearable RGBD camera\",\"url\":\"https://www.semanticscholar.org/paper/043f2a41b1183e60200274c7af756607c9c1d347\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1931096\",\"name\":\"A. Behera\"},{\"authorId\":\"1703235\",\"name\":\"A. Cohn\"},{\"authorId\":\"1967104\",\"name\":\"David C. Hogg\"}],\"doi\":\"10.5244/C.28.100\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1af9e75429c85b7442579fe679c8333c6316f269\",\"title\":\"Real-time Activity Recognition by Discerning Qualitative Relationships Between Randomly Chosen Visual Features\",\"url\":\"https://www.semanticscholar.org/paper/1af9e75429c85b7442579fe679c8333c6316f269\",\"venue\":\"BMVC\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1893497\",\"name\":\"Z. Li\"},{\"authorId\":\"3472767\",\"name\":\"Chiwun Au\"},{\"authorId\":\"144644332\",\"name\":\"Y. Kakiuchi\"},{\"authorId\":\"1683608\",\"name\":\"K. Okada\"},{\"authorId\":\"1749935\",\"name\":\"M. Inaba\"}],\"doi\":\"10.1109/HUMANOIDS.2016.7803273\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"51a128eb0d72f318e9d3617ceff64539dfeaa608\",\"title\":\"What am i doing? Robotic self-action recognition\",\"url\":\"https://www.semanticscholar.org/paper/51a128eb0d72f318e9d3617ceff64539dfeaa608\",\"venue\":\"2016 IEEE-RAS 16th International Conference on Humanoid Robots (Humanoids)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47683829\",\"name\":\"A. Fathi\"},{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1007/978-3-642-33718-5_23\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"985e1f2dc17db0d590de883cbf1e30535169cb1a\",\"title\":\"Learning to Recognize Daily Actions Using Gaze\",\"url\":\"https://www.semanticscholar.org/paper/985e1f2dc17db0d590de883cbf1e30535169cb1a\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144756076\",\"name\":\"Y. Lee\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb716dd3dbd0f04e6d89f1703b9975cad62ffb09\",\"title\":\"Visual object category discovery in images and videos\",\"url\":\"https://www.semanticscholar.org/paper/eb716dd3dbd0f04e6d89f1703b9975cad62ffb09\",\"venue\":\"\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39956342\",\"name\":\"Wenbin Li\"}],\"doi\":\"10.22028/D291-27156\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"993023a4859f9889f30fa2625790ccfa4dd4b1b3\",\"title\":\"From perception over anticipation to manipulation\",\"url\":\"https://www.semanticscholar.org/paper/993023a4859f9889f30fa2625790ccfa4dd4b1b3\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2933543\",\"name\":\"H. Rhodin\"}],\"doi\":\"10.22028/D291-26685\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"62c9590d6a37a24e6ce7805a4b1fe20c8e502c5e\",\"title\":\"From motion capture to interactive virtual worlds: towards unconstrained motion-capture algorithms for real-time performance-driven character animation\",\"url\":\"https://www.semanticscholar.org/paper/62c9590d6a37a24e6ce7805a4b1fe20c8e502c5e\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36549981\",\"name\":\"Cheng-Sheng Chan\"},{\"authorId\":\"50357993\",\"name\":\"Shou-Zhong Chen\"},{\"authorId\":\"1717126\",\"name\":\"Pei-Xuan Xie\"},{\"authorId\":\"145982994\",\"name\":\"Chiung-Chih Chang\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":\"10.1007/978-3-319-46493-0_31\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a985a3e0fb59493356b488ae9aa7cd1c71ee1c7c\",\"title\":\"Recognition from Hand Cameras: A Revisit with Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/a985a3e0fb59493356b488ae9aa7cd1c71ee1c7c\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40413015\",\"name\":\"M. Cornacchia\"},{\"authorId\":\"40408041\",\"name\":\"K. Ozcan\"},{\"authorId\":\"47833440\",\"name\":\"Yu Zheng\"},{\"authorId\":\"1714074\",\"name\":\"Senem Velipasalar\"}],\"doi\":\"10.1109/JSEN.2016.2628346\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"46c73ac90c8107e9580950eef9df6834edccd183\",\"title\":\"A Survey on Activity Detection and Classification Using Wearable Sensors\",\"url\":\"https://www.semanticscholar.org/paper/46c73ac90c8107e9580950eef9df6834edccd183\",\"venue\":\"IEEE Sensors Journal\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34876449\",\"name\":\"E. Aksoy\"},{\"authorId\":\"1953638\",\"name\":\"M. Tamosiunaite\"},{\"authorId\":\"1714016\",\"name\":\"F. W\\u00f6rg\\u00f6tter\"}],\"doi\":\"10.1016/j.robot.2014.11.003\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6ca27ae9ec8b689a43f597a240dd8ad55c50c601\",\"title\":\"Model-free incremental learning of the semantics of manipulation actions\",\"url\":\"https://www.semanticscholar.org/paper/6ca27ae9ec8b689a43f597a240dd8ad55c50c601\",\"venue\":\"Robotics Auton. Syst.\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1398693138\",\"name\":\"I. Gonz\\u00e1lez-D\\u00edaz\"},{\"authorId\":\"2021805\",\"name\":\"V. Buso\"},{\"authorId\":\"1406426904\",\"name\":\"J. Benois-Pineau\"},{\"authorId\":\"2505447\",\"name\":\"Guillaume Bourmaud\"},{\"authorId\":\"50374225\",\"name\":\"Gaelle Usseglio\"},{\"authorId\":\"1697287\",\"name\":\"R. M\\u00e9gret\"},{\"authorId\":\"2930352\",\"name\":\"Yann Ga\\u00ebstel\"},{\"authorId\":\"144328013\",\"name\":\"J. Dartigues\"}],\"doi\":\"10.1007/978-3-319-17963-6_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"33390d9f83cffe7a0a45ec30007735feddacfb54\",\"title\":\"Recognition of Instrumental Activities of Daily Living in Egocentric Video for Activity Monitoring of Patients with Dementia\",\"url\":\"https://www.semanticscholar.org/paper/33390d9f83cffe7a0a45ec30007735feddacfb54\",\"venue\":\"Health Monitoring and Personalized Feedback using Multimedia Data\",\"year\":2015},{\"arxivId\":\"1501.02825\",\"authors\":[{\"authorId\":\"2798750\",\"name\":\"Sven Bambach\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d61f2ab043473032653d461f32efd7c5a0cbe1a1\",\"title\":\"A Survey on Recent Advances of Computer Vision Algorithms for Egocentric Video\",\"url\":\"https://www.semanticscholar.org/paper/d61f2ab043473032653d461f32efd7c5a0cbe1a1\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1708.07889\",\"authors\":[{\"authorId\":\"1901010\",\"name\":\"A. Cartas\"},{\"authorId\":\"2837527\",\"name\":\"Mariella Dimiccoli\"},{\"authorId\":\"143601910\",\"name\":\"P. Radeva\"}],\"doi\":\"10.1109/ICCVW.2017.277\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d1e388269ea8ce7074f804f79e158038f629a0df\",\"title\":\"Batch-Based Activity Recognition from Egocentric Photo-Streams\",\"url\":\"https://www.semanticscholar.org/paper/d1e388269ea8ce7074f804f79e158038f629a0df\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1398693138\",\"name\":\"I. Gonz\\u00e1lez-D\\u00edaz\"},{\"authorId\":\"2021805\",\"name\":\"V. Buso\"},{\"authorId\":\"1381345946\",\"name\":\"J. Benois-Pineau\"},{\"authorId\":\"2505447\",\"name\":\"Guillaume Bourmaud\"},{\"authorId\":\"1697287\",\"name\":\"R. M\\u00e9gret\"}],\"doi\":\"10.1145/2505323.2505328\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d5d6bddb53be18021510f7a706fa623c4cc7b854\",\"title\":\"Modeling instrumental activities of daily living in egocentric vision as sequences of active objects and context for alzheimer disease research\",\"url\":\"https://www.semanticscholar.org/paper/d5d6bddb53be18021510f7a706fa623c4cc7b854\",\"venue\":\"MIIRH '13\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2798750\",\"name\":\"Sven Bambach\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"},{\"authorId\":\"102595883\",\"name\":\"Chen Yu\"}],\"doi\":\"10.1109/ICCV.2015.226\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7ef40f47e6f20c87391dd77b6e8c081709e1b8bd\",\"title\":\"Lending A Hand: Detecting Hands and Recognizing Activities in Complex Egocentric Interactions\",\"url\":\"https://www.semanticscholar.org/paper/7ef40f47e6f20c87391dd77b6e8c081709e1b8bd\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2798750\",\"name\":\"Sven Bambach\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"de2e8127105a37ff1f59be13a010ab0d3f4fa650\",\"title\":\"Analyzing hands with first-person computer vision\",\"url\":\"https://www.semanticscholar.org/paper/de2e8127105a37ff1f59be13a010ab0d3f4fa650\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10978611\",\"name\":\"Akanksha Saran\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"}],\"doi\":\"10.1109/IROS.2015.7354088\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aa570b7b24f30d0d2f347ad1d8496b0d5e53987f\",\"title\":\"Hand parsing for fine-grained recognition of human grasps in monocular images\",\"url\":\"https://www.semanticscholar.org/paper/aa570b7b24f30d0d2f347ad1d8496b0d5e53987f\",\"venue\":\"2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11380127\",\"name\":\"Khalid El Asnaoui\"},{\"authorId\":\"35176541\",\"name\":\"A. Hamid\"},{\"authorId\":\"15370656\",\"name\":\"Aksasse Brahim\"},{\"authorId\":\"15249320\",\"name\":\"Ouanan Mohammed\"}],\"doi\":\"10.1109/WITS.2017.7934659\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ff59ad8cea158ef1c2ef15e43517e8fa33df97b1\",\"title\":\"A survey of activity recognition in egocentric lifelogging datasets\",\"url\":\"https://www.semanticscholar.org/paper/ff59ad8cea158ef1c2ef15e43517e8fa33df97b1\",\"venue\":\"2017 International Conference on Wireless Technologies, Embedded and Intelligent Systems (WITS)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1742452\",\"name\":\"S. Battiato\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":\"10.1007/978-3-030-11021-5_24\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d09701ea8c5809086fca2919400ff7f5b80ae30\",\"title\":\"Leveraging Uncertainty to Rethink Loss Functions and Evaluation Measures for Egocentric Action Anticipation\",\"url\":\"https://www.semanticscholar.org/paper/9d09701ea8c5809086fca2919400ff7f5b80ae30\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"1807.11794\",\"authors\":[{\"authorId\":\"1756362\",\"name\":\"Swathikiran Sudhakaran\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"75fac714ccc1b616048c9bb6ca918c58317c56a1\",\"title\":\"Attention is All We Need: Nailing Down Object-centric Attention for Egocentric Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/75fac714ccc1b616048c9bb6ca918c58317c56a1\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9362227\",\"name\":\"Sagar Verma\"},{\"authorId\":\"145676232\",\"name\":\"Chetan Arora\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"72379808573cc333f63a3c774457d1770aca052d\",\"title\":\"Action recognition in egocentric videos\",\"url\":\"https://www.semanticscholar.org/paper/72379808573cc333f63a3c774457d1770aca052d\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2983554\",\"name\":\"G. Somasundaram\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"1827707\",\"name\":\"V. Morellas\"},{\"authorId\":\"1696163\",\"name\":\"N. Papanikolopoulos\"}],\"doi\":\"10.1016/j.cviu.2014.01.002\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c4dab4376d3ae0ddd76a1097820b9f10a8cda26\",\"title\":\"Action recognition using global spatio-temporal features derived from sparse representations\",\"url\":\"https://www.semanticscholar.org/paper/6c4dab4376d3ae0ddd76a1097820b9f10a8cda26\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2151048\",\"name\":\"Taiki Miyanishi\"},{\"authorId\":\"8425523\",\"name\":\"J. Hirayama\"},{\"authorId\":\"1959174\",\"name\":\"Quan Kong\"},{\"authorId\":\"34772057\",\"name\":\"Takuya Maekawa\"},{\"authorId\":\"2626787\",\"name\":\"H. Moriya\"},{\"authorId\":\"32398693\",\"name\":\"T. Suyama\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5db27cef14ebdf53149a5072650b302fce2c0eed\",\"title\":\"Egocentric Video Search via Physical Interactions\",\"url\":\"https://www.semanticscholar.org/paper/5db27cef14ebdf53149a5072650b302fce2c0eed\",\"venue\":\"AAAI\",\"year\":2016},{\"arxivId\":\"2008.08452\",\"authors\":[{\"authorId\":\"50841913\",\"name\":\"Asif Shahriyar Sushmit\"},{\"authorId\":\"10458138\",\"name\":\"P. Ghosh\"},{\"authorId\":\"1885311407\",\"name\":\"Md.Abrar Istiak\"},{\"authorId\":\"1742267771\",\"name\":\"Nayeeb Rashid\"},{\"authorId\":\"1742267920\",\"name\":\"Ahsan Habib Akash\"},{\"authorId\":\"144782474\",\"name\":\"T. Hasan\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d4953e2a564f68bc7eccd8d1af12da3c2c5bbf7c\",\"title\":\"SegCodeNet: Color-Coded Segmentation Masks for Activity Detection from Wearable Cameras\",\"url\":\"https://www.semanticscholar.org/paper/d4953e2a564f68bc7eccd8d1af12da3c2c5bbf7c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1909.09283\",\"authors\":[{\"authorId\":\"9284940\",\"name\":\"Harshala Gammulle\"},{\"authorId\":\"34735743\",\"name\":\"T. Fernando\"},{\"authorId\":\"1980700\",\"name\":\"Simon Denman\"},{\"authorId\":\"1729760\",\"name\":\"S. Sridharan\"},{\"authorId\":\"3140440\",\"name\":\"C. Fookes\"}],\"doi\":\"10.1109/WACV.2019.00027\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ced33344402d74f69367caa163e94918f307ab78\",\"title\":\"Coupled Generative Adversarial Network for Continuous Fine-Grained Action Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/ced33344402d74f69367caa163e94918f307ab78\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":\"1905.00742\",\"authors\":[{\"authorId\":\"51463388\",\"name\":\"G. Kapidis\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"},{\"authorId\":\"8297919\",\"name\":\"E. V. Dam\"},{\"authorId\":\"144882446\",\"name\":\"L. Noldus\"},{\"authorId\":\"1739867\",\"name\":\"R. Veltkamp\"}],\"doi\":\"10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00185\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fe9083f8d8a4d3c0a00b2c1caf3bf8a14d5c332e\",\"title\":\"Egocentric Hand Track and Object-Based Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fe9083f8d8a4d3c0a00b2c1caf3bf8a14d5c332e\",\"venue\":\"2019 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"122150713\",\"name\":\"Shuichi Urabe\"},{\"authorId\":\"2256574\",\"name\":\"K. Inoue\"},{\"authorId\":\"2593208\",\"name\":\"M. Yoshioka\"}],\"doi\":\"10.1145/3230519.3230584\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"43eda7a5b5c3ba144dcfb92303442f3100cb05dc\",\"title\":\"Cooking activities recognition in egocentric videos using combining 2DCNN and 3DCNN\",\"url\":\"https://www.semanticscholar.org/paper/43eda7a5b5c3ba144dcfb92303442f3100cb05dc\",\"venue\":\"CEA@IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1726630\",\"name\":\"Tilman Dingler\"},{\"authorId\":\"3097204\",\"name\":\"Passant El Agroudy\"},{\"authorId\":\"144334297\",\"name\":\"Gerd Matheis\"},{\"authorId\":\"145823914\",\"name\":\"A. Schmidt\"}],\"doi\":\"10.1145/2875194.2875224\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"293f69166e5b8088967f5e0b26a1fc9f23b4c4bb\",\"title\":\"Reading-based Screenshot Summaries for Supporting Awareness of Desktop Activities\",\"url\":\"https://www.semanticscholar.org/paper/293f69166e5b8088967f5e0b26a1fc9f23b4c4bb\",\"venue\":\"AH\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2021805\",\"name\":\"V. Buso\"},{\"authorId\":\"1405890081\",\"name\":\"Louise Hopper\"},{\"authorId\":\"1381345946\",\"name\":\"J. Benois-Pineau\"},{\"authorId\":\"2647162\",\"name\":\"Pierre-Marie Plans\"},{\"authorId\":\"1697287\",\"name\":\"R. M\\u00e9gret\"}],\"doi\":\"10.1109/ICMEW.2015.7169861\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"311d7f0145a758cc6f8dc6f36368fce0a49bde1f\",\"title\":\"Recognition of Activities of Daily Living in natural \\u201cat home\\u201d scenario for assessment of Alzheimer's disease patients\",\"url\":\"https://www.semanticscholar.org/paper/311d7f0145a758cc6f8dc6f36368fce0a49bde1f\",\"venue\":\"2015 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2015},{\"arxivId\":\"1911.10967\",\"authors\":[{\"authorId\":\"1720749879\",\"name\":\"Miao Liu\"},{\"authorId\":\"39578749\",\"name\":\"Siyu Tang\"},{\"authorId\":\"47002659\",\"name\":\"Yanchao Li\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1007/978-3-030-58452-8_41\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"994481d46df92709b61614f5e756e40df4117622\",\"title\":\"Forecasting Human-Object Interaction: Joint Prediction of Motor Attention and Actions in First Person Video\",\"url\":\"https://www.semanticscholar.org/paper/994481d46df92709b61614f5e756e40df4117622\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1811.10914\",\"authors\":[{\"authorId\":\"40231554\",\"name\":\"W. Wang\"},{\"authorId\":\"9945144\",\"name\":\"Kaicheng Yu\"},{\"authorId\":\"2375521\",\"name\":\"Joachim Hugonot\"},{\"authorId\":\"1717736\",\"name\":\"P. Fua\"},{\"authorId\":\"2862871\",\"name\":\"M. Salzmann\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"86e6335c498afc0a01d7369ae3ca8b3b8cf64232\",\"title\":\"Beyond One Glance: Gated Recurrent Architecture for Hand Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/86e6335c498afc0a01d7369ae3ca8b3b8cf64232\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"},{\"authorId\":\"9267108\",\"name\":\"Gregory D. Abowd\"},{\"authorId\":\"2244531\",\"name\":\"Agata Rozga\"},{\"authorId\":\"144519605\",\"name\":\"M. Romero\"},{\"authorId\":\"1793320\",\"name\":\"M. Clements\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"},{\"authorId\":\"21472040\",\"name\":\"Irfan Essa\"},{\"authorId\":\"3069929\",\"name\":\"O. Ousley\"},{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"48809882\",\"name\":\"Chanho Kim\"},{\"authorId\":\"36120353\",\"name\":\"H. Rao\"},{\"authorId\":\"31642491\",\"name\":\"Jonathan C. Kim\"},{\"authorId\":\"1711610\",\"name\":\"L. Presti\"},{\"authorId\":\"1701293\",\"name\":\"J. Zhang\"},{\"authorId\":\"2391334\",\"name\":\"Denis Lantsman\"},{\"authorId\":\"50604693\",\"name\":\"J. Bidwell\"},{\"authorId\":\"1843583\",\"name\":\"Zhefan Ye\"}],\"doi\":\"10.1109/CVPR.2013.438\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4b9b4011fd367a3b36444fb79d3f25f2323bd8e4\",\"title\":\"Decoding Children's Social Behavior\",\"url\":\"https://www.semanticscholar.org/paper/4b9b4011fd367a3b36444fb79d3f25f2323bd8e4\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":\"1601.06603\",\"authors\":[{\"authorId\":\"2527741\",\"name\":\"Sibo Song\"},{\"authorId\":\"143770929\",\"name\":\"N. Cheung\"},{\"authorId\":\"1802086\",\"name\":\"V. Chandrasekhar\"},{\"authorId\":\"1709001\",\"name\":\"B. Mandal\"},{\"authorId\":\"144462791\",\"name\":\"Jie Lin\"}],\"doi\":\"10.1109/ICASSP.2016.7472171\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3b108767448ad05274f4e95b47f7b060e56d00ad\",\"title\":\"Egocentric activity recognition with multimodal fisher vector\",\"url\":\"https://www.semanticscholar.org/paper/3b108767448ad05274f4e95b47f7b060e56d00ad\",\"venue\":\"2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2599451\",\"name\":\"Shervin Ardeshir\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"72fa069d1ff70730493b1b814c78b498df3e1030\",\"title\":\"Ego 2 Top : Matching Viewers in Egocentric and Top-view Cameras\",\"url\":\"https://www.semanticscholar.org/paper/72fa069d1ff70730493b1b814c78b498df3e1030\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3172280\",\"name\":\"Minjie Cai\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.15607/RSS.2016.XII.034\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9904979ba8b5fdc338efa14a59034c3974444bbd\",\"title\":\"Understanding Hand-Object Manipulation with Grasp Types and Object Attributes\",\"url\":\"https://www.semanticscholar.org/paper/9904979ba8b5fdc338efa14a59034c3974444bbd\",\"venue\":\"Robotics: Science and Systems\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1931096\",\"name\":\"A. Behera\"},{\"authorId\":\"49682370\",\"name\":\"Alexander Keidel\"},{\"authorId\":\"73650373\",\"name\":\"Bappaditya Debnath\"}],\"doi\":\"10.1007/978-3-030-12939-2_21\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"64abe70f02579fafc8b23b99700d625f1ca440a4\",\"title\":\"Context-driven Multi-stream LSTM (M-LSTM) for Recognizing Fine-Grained Activity of Drivers\",\"url\":\"https://www.semanticscholar.org/paper/64abe70f02579fafc8b23b99700d625f1ca440a4\",\"venue\":\"GCPR\",\"year\":2018},{\"arxivId\":\"1905.13586\",\"authors\":[{\"authorId\":\"47892681\",\"name\":\"Haoxin Li\"},{\"authorId\":\"50204657\",\"name\":\"Yijun Cai\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"}],\"doi\":\"10.1109/CVPR.2019.00812\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"303aa6cb7a182d5437c86d07aff4fb9fdabc744e\",\"title\":\"Deep Dual Relation Modeling for Egocentric Interaction Recognition\",\"url\":\"https://www.semanticscholar.org/paper/303aa6cb7a182d5437c86d07aff4fb9fdabc744e\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1710.07477\",\"authors\":[{\"authorId\":\"27555915\",\"name\":\"Tz-Ying Wu\"},{\"authorId\":\"16261770\",\"name\":\"Ting-An Chien\"},{\"authorId\":\"36549981\",\"name\":\"Cheng-Sheng Chan\"},{\"authorId\":\"27538483\",\"name\":\"Chan-Wei Hu\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":\"10.1109/ICCV.2017.15\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"604575bf821ad655e195a78d53badb0a636ffa0f\",\"title\":\"Anticipating Daily Intention Using On-wrist Motion Triggered Sensing\",\"url\":\"https://www.semanticscholar.org/paper/604575bf821ad655e195a78d53badb0a636ffa0f\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2886032\",\"name\":\"Agata Mosinska\"}],\"doi\":\"10.5075/epfl-thesis-9301\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d7bc08f07ad9264327805d77b821f676a5884624\",\"title\":\"Learning Approach to Delineation of Curvilinear Structures in 2D and 3D Images\",\"url\":\"https://www.semanticscholar.org/paper/d7bc08f07ad9264327805d77b821f676a5884624\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1901010\",\"name\":\"A. Cartas\"},{\"authorId\":\"143601910\",\"name\":\"P. Radeva\"},{\"authorId\":\"2837527\",\"name\":\"Mariella Dimiccoli\"}],\"doi\":\"10.1109/ACCESS.2020.2990333\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b516f02c6fc6f923100f377b6aaa4ca3e515331d\",\"title\":\"Activities of Daily Living Monitoring via a Wearable Camera: Toward Real-World Applications\",\"url\":\"https://www.semanticscholar.org/paper/b516f02c6fc6f923100f377b6aaa4ca3e515331d\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1999236\",\"name\":\"H. Chang\"},{\"authorId\":\"1403754530\",\"name\":\"Guillermo Garcia-Hernando\"},{\"authorId\":\"40245930\",\"name\":\"Danhang Tang\"},{\"authorId\":\"143617697\",\"name\":\"Tae-Kyun Kim\"}],\"doi\":\"10.1016/j.cviu.2016.01.010\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"46f2ea77b15922239cad3c151705f59050bebc4a\",\"title\":\"Spatio-Temporal Hough Forest for efficient detection-localisation-recognition of fingerwriting in egocentric camera\",\"url\":\"https://www.semanticscholar.org/paper/46f2ea77b15922239cad3c151705f59050bebc4a\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1808039\",\"name\":\"Emrah Basaran\"},{\"authorId\":\"10428247\",\"name\":\"Yonatan Tariku Tesfaye\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1c838b9f37d1b4633e2addfbca2e51df0e24b0e3\",\"title\":\"Person Re-identification in Videos Acquired by Mobile Devices with First-Person Point-of-View\",\"url\":\"https://www.semanticscholar.org/paper/1c838b9f37d1b4633e2addfbca2e51df0e24b0e3\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1704.02463\",\"authors\":[{\"authorId\":\"1403754530\",\"name\":\"Guillermo Garcia-Hernando\"},{\"authorId\":\"3325819\",\"name\":\"Shanxin Yuan\"},{\"authorId\":\"2637535\",\"name\":\"Seungryul Baek\"},{\"authorId\":\"1700968\",\"name\":\"Tae-Kyun Kim\"}],\"doi\":\"10.1109/CVPR.2018.00050\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e85327e43f8b7e052a52ff9ee6b845cc0bee990d\",\"title\":\"First-Person Hand Action Benchmark with RGB-D Videos and 3D Hand Pose Annotations\",\"url\":\"https://www.semanticscholar.org/paper/e85327e43f8b7e052a52ff9ee6b845cc0bee990d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"117491978\",\"name\":\"Mario Rodr\\u00edguez\"},{\"authorId\":\"1398367150\",\"name\":\"C. Orrite-Uru\\u00f1uela\"},{\"authorId\":\"144426554\",\"name\":\"C. Medrano\"}],\"doi\":\"10.1007/978-3-319-58838-4_56\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"57e2adbe2e69f5ad9011028165949af42214b3e5\",\"title\":\"Space-Time Flexible Kernel for Recognizing Activities from Wearable Cameras\",\"url\":\"https://www.semanticscholar.org/paper/57e2adbe2e69f5ad9011028165949af42214b3e5\",\"venue\":\"IbPRIA\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143804966\",\"name\":\"F. Mart\\u00ednez\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"093a8ad2732b1a8a88069cacde7828e70d4bb7ed\",\"title\":\"Tout est dans le regard : reconnaissance visuelle du comportement humain en vue subjective. (It's all in your eyes : first-person gaze estimation and analysis for understanding human behavior)\",\"url\":\"https://www.semanticscholar.org/paper/093a8ad2732b1a8a88069cacde7828e70d4bb7ed\",\"venue\":\"\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67001588\",\"name\":\"K. Vinay Chandrasekhar\"},{\"authorId\":\"49631929\",\"name\":\"M. Imtiaz\"},{\"authorId\":\"49553330\",\"name\":\"E. Sazonov\"}],\"doi\":\"10.1109/ICSENS.2018.8630305\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7ae418410acb7c8b11a7f7ecb9a2bcf288d754b2\",\"title\":\"Motion-Adaptive Image Capture in a Body-Worn Wearable Sensor\",\"url\":\"https://www.semanticscholar.org/paper/7ae418410acb7c8b11a7f7ecb9a2bcf288d754b2\",\"venue\":\"2018 IEEE SENSORS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2568376\",\"name\":\"Abhimanyu Sahu\"},{\"authorId\":\"1384438931\",\"name\":\"Rajit Bhattacharya\"},{\"authorId\":\"1397164455\",\"name\":\"Pallabh Bhura\"},{\"authorId\":\"40272229\",\"name\":\"A. S. Chowdhury\"}],\"doi\":\"10.1007/978-981-32-9291-8_31\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3702830eeb1bc771a3a9b0133c407b1fe8afb4d3\",\"title\":\"Action Recognition from Egocentric Videos Using Random Walks\",\"url\":\"https://www.semanticscholar.org/paper/3702830eeb1bc771a3a9b0133c407b1fe8afb4d3\",\"venue\":\"CVIP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31197849\",\"name\":\"Shaohua Wan\"},{\"authorId\":\"1705627\",\"name\":\"J. Aggarwal\"}],\"doi\":\"10.1109/CVPRW.2015.7301302\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"264a2b946fae4af23c646cc08fc56947b5be82cf\",\"title\":\"Robust object recognition in RGB-D egocentric videos based on Sparse Affine Hull Kernel\",\"url\":\"https://www.semanticscholar.org/paper/264a2b946fae4af23c646cc08fc56947b5be82cf\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"80519596\",\"name\":\"A. Betancourt\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"eef4ac6942c76651d204116a221994baa5808ec8\",\"title\":\"EgoHands : a unified framework for hand-based methods in first person vision videos\",\"url\":\"https://www.semanticscholar.org/paper/eef4ac6942c76651d204116a221994baa5808ec8\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1505.04803\",\"authors\":[{\"authorId\":\"144756076\",\"name\":\"Y. Lee\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1007/s11263-014-0794-5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ec3d9f304f173362007f5c2e3c6c616d24b85c9f\",\"title\":\"Predicting Important Objects for Egocentric Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/ec3d9f304f173362007f5c2e3c6c616d24b85c9f\",\"venue\":\"International Journal of Computer Vision\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51463388\",\"name\":\"G. Kapidis\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"},{\"authorId\":\"8297919\",\"name\":\"E. V. Dam\"},{\"authorId\":\"144882447\",\"name\":\"L. Noldus\"},{\"authorId\":\"47329105\",\"name\":\"Remco C. Veltkamp\"}],\"doi\":\"10.1007/978-3-030-25590-9_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2def8f26aabc1a5fd646aa4a9f17ab47e241e529\",\"title\":\"Object Detection-Based Location and Activity Classification from Egocentric Videos: A Systematic Analysis\",\"url\":\"https://www.semanticscholar.org/paper/2def8f26aabc1a5fd646aa4a9f17ab47e241e529\",\"venue\":\"\",\"year\":2020}],\"corpusId\":378809,\"doi\":\"10.1109/ICCV.2011.6126269\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":35,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"bfc71c97f21b354ddfe69d17115e52db4fd4dce8\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1808816\",\"name\":\"Jianxin Wu\"},{\"authorId\":\"1754526\",\"name\":\"A. Osuntogun\"},{\"authorId\":\"144075899\",\"name\":\"T. Choudhury\"},{\"authorId\":\"3041721\",\"name\":\"M. Philipose\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1109/ICCV.2007.4408865\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d7e13004dcc904591ade1f471b09a86870da0b69\",\"title\":\"A Scalable Approach to Activity Recognition based on Object Use\",\"url\":\"https://www.semanticscholar.org/paper/d7e13004dcc904591ade1f471b09a86870da0b69\",\"venue\":\"2007 IEEE 11th International Conference on Computer Vision\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38916673\",\"name\":\"B. Yao\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2010.5540235\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"927432c50d920e647260c67506859d7845c7f729\",\"title\":\"Modeling mutual context of object and human pose in human-object interaction activities\",\"url\":\"https://www.semanticscholar.org/paper/927432c50d920e647260c67506859d7845c7f729\",\"venue\":\"2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46426476\",\"name\":\"X. Ren\"},{\"authorId\":\"39599498\",\"name\":\"C. Gu\"}],\"doi\":\"10.1109/CVPR.2010.5540074\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"04b16a1a19ee2128c663326b1e87a2d8ec368450\",\"title\":\"Figure-ground segmentation improves handled object recognition in egocentric video\",\"url\":\"https://www.semanticscholar.org/paper/04b16a1a19ee2128c663326b1e87a2d8ec368450\",\"venue\":\"2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/ICCV.2007.4408872\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ef4209ed288ef38fecdfae2409bce78633386c10\",\"title\":\"What, where and who? Classifying events by scene and object recognition\",\"url\":\"https://www.semanticscholar.org/paper/ef4209ed288ef38fecdfae2409bce78633386c10\",\"venue\":\"2007 IEEE 11th International Conference on Computer Vision\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2097256\",\"name\":\"Xiao-Li Meng\"},{\"authorId\":\"2235217\",\"name\":\"D. Rubin\"}],\"doi\":\"10.1093/BIOMET/80.2.267\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"721b25ffad2623a8d1e8044882f66e0dbe678f1d\",\"title\":\"Maximum likelihood estimation via the ECM algorithm: A general framework\",\"url\":\"https://www.semanticscholar.org/paper/721b25ffad2623a8d1e8044882f66e0dbe678f1d\",\"venue\":\"\",\"year\":1993},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Fathi\"},{\"authorId\":null,\"name\":\"X. Ren\"},{\"authorId\":null,\"name\":\"M.\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Rehg . Learning to recog \\u00ad nize objects in egocentric activities\",\"url\":\"\",\"venue\":\"\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2712738\",\"name\":\"C. Sch\\u00fcldt\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"3033284\",\"name\":\"B. Caputo\"}],\"doi\":\"10.1109/icpr.2004.1334462\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b480f6a3750b4cebaf1db205692c8321d45926a2\",\"title\":\"Recognizing human actions: a local SVM approach\",\"url\":\"https://www.semanticscholar.org/paper/b480f6a3750b4cebaf1db205692c8321d45926a2\",\"venue\":\"Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004.\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Gupta\"},{\"authorId\":null,\"name\":\"A. Kembhavi\"},{\"authorId\":null,\"name\":\"L. S. Davis\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Observ\\u00ad ing human-object interactions: using spatial and func\\u00ad tional compatibility for recognition\",\"url\":\"\",\"venue\":\"PAMI,\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1749650\",\"name\":\"B. Frey\"},{\"authorId\":\"2888023\",\"name\":\"D. Dueck\"}],\"doi\":\"10.1126/SCIENCE.1136800\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ca839260a9e13f21fff53b7227d6d363cf3d4735\",\"title\":\"Clustering by Passing Messages Between Data Points\",\"url\":\"https://www.semanticscholar.org/paper/ca839260a9e13f21fff53b7227d6d363cf3d4735\",\"venue\":\"Science\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. A. Efros\"},{\"authorId\":null,\"name\":\"A. C. Berg\"},{\"authorId\":null,\"name\":\"G. Mori\"},{\"authorId\":null,\"name\":\"1. Malik\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Rec\\u00ad ognizing action at a distance\",\"url\":\"\",\"venue\":\"In ICCV,\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35238678\",\"name\":\"D. Lowe\"}],\"doi\":\"10.1023/B:VISI.0000029664.99615.94\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8c04f169203f9e55056a6f7f956695babe622a38\",\"title\":\"Distinctive Image Features from Scale-Invariant Keypoints\",\"url\":\"https://www.semanticscholar.org/paper/8c04f169203f9e55056a6f7f956695babe622a38\",\"venue\":\"International Journal of Computer Vision\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"R Mann\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"A. 1 epson, and 1. M. Siskind. Computational perception of scene dynamics\",\"url\":\"\",\"venue\":\"ECCV\",\"year\":1996},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3502855\",\"name\":\"M. Marszalek\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/CVPR.2009.5206557\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c26906b6dab02083ffd01fd27d9087597999bc0e\",\"title\":\"Actions in context\",\"url\":\"https://www.semanticscholar.org/paper/c26906b6dab02083ffd01fd27d9087597999bc0e\",\"venue\":\"CVPR\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1688328\",\"name\":\"A. Bobick\"},{\"authorId\":\"32511979\",\"name\":\"Y. Ivanov\"}],\"doi\":\"10.1109/CVPR.1998.698609\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a5fa324fea88e4caae6eb8a72361f567e32c9cc\",\"title\":\"Action recognition using probabilistic parsing\",\"url\":\"https://www.semanticscholar.org/paper/8a5fa324fea88e4caae6eb8a72361f567e32c9cc\",\"venue\":\"Proceedings. 1998 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.98CB36231)\",\"year\":1998},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738894\",\"name\":\"T. Starner\"},{\"authorId\":\"145002914\",\"name\":\"Joshua Weaver\"},{\"authorId\":\"144994682\",\"name\":\"A. Pentland\"}],\"doi\":\"10.1109/34.735811\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ccd238120e1eb620f4bcf235dc549619560f2857\",\"title\":\"Real-Time American Sign Language Recognition Using Desk and Wearable Computer Based Video\",\"url\":\"https://www.semanticscholar.org/paper/ccd238120e1eb620f4bcf235dc549619560f2857\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":1998},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"L. 1. Li\"},{\"authorId\":null,\"name\":\"L. Fei-Fei\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"What, where and who? classi\\u00ad fying event by scene and object recognition\",\"url\":\"\",\"venue\":\"In CVPR,\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"}],\"doi\":\"10.1007/s11263-005-1838-7\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d2fb2fa53021b2776da0fb8b53c54820ed3982cc\",\"title\":\"On Space-Time Interest Points\",\"url\":\"https://www.semanticscholar.org/paper/d2fb2fa53021b2776da0fb8b53c54820ed3982cc\",\"venue\":\"International Journal of Computer Vision\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687322\",\"name\":\"O. Aghazadeh\"},{\"authorId\":\"50626295\",\"name\":\"J. Sullivan\"},{\"authorId\":\"144719278\",\"name\":\"S. Carlsson\"}],\"doi\":\"10.1109/CVPR.2011.5995731\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"53dff6a36e9537a9d2547d471004d83e29cb8e19\",\"title\":\"Novelty detection from an ego-centric perspective\",\"url\":\"https://www.semanticscholar.org/paper/53dff6a36e9537a9d2547d471004d83e29cb8e19\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Bobick and 1. Davis. The recognition of hu\\u00ad man movement using temporal templates\",\"url\":\"\",\"venue\":\"Bobick and 1. Davis. The recognition of hu\\u00ad man movement using temporal templates\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47683829\",\"name\":\"A. Fathi\"},{\"authorId\":\"1745410\",\"name\":\"Maria-Florina Balcan\"},{\"authorId\":\"46426476\",\"name\":\"X. Ren\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.5244/C.25.78\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8480635ef58029a78b4a5e3b45fdd7cade52c11b\",\"title\":\"Combining Self Training and Active Learning for Video Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/8480635ef58029a78b4a5e3b45fdd7cade52c11b\",\"venue\":\"BMVC\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/TPAMI.2009.83\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"3a8da6accff92f915c1b8ac26d8176308c425b61\",\"title\":\"Observing Human-Object Interactions: Using Spatial and Functional Compatibility for Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3a8da6accff92f915c1b8ac26d8176308c425b61\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145844737\",\"name\":\"James F. Allen\"}],\"doi\":\"10.1016/0004-3702(84)90008-0\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d36afe59ad1b706e020f55b54740bc9cddf25dcd\",\"title\":\"Towards a General Theory of Action and Time\",\"url\":\"https://www.semanticscholar.org/paper/d36afe59ad1b706e020f55b54740bc9cddf25dcd\",\"venue\":\"Artif. Intell.\",\"year\":1984},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2398457\",\"name\":\"Ekaterina H. Spriggs\"},{\"authorId\":\"143867160\",\"name\":\"F. Torre\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1109/CVPRW.2009.5204354\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1aaf8e1e8164e8968f693a100fee4343580b1d61\",\"title\":\"Temporal segmentation and activity classification from first-person sensing\",\"url\":\"https://www.semanticscholar.org/paper/1aaf8e1e8164e8968f693a100fee4343580b1d61\",\"venue\":\"2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A Fathi\"},{\"authorId\":null,\"name\":\"Mf Ba1can\"},{\"authorId\":null,\"name\":\"X Ren\"},{\"authorId\":null,\"name\":\"M Rehg\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Com\\u00ad bining self training and active learning for video seg\\u00ad mentation\",\"url\":\"\",\"venue\":\"BMVC\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1680188\",\"name\":\"T. Joachims\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"74b1a9e50f18af8a7b9f8dd38f40e0466ad7a8e8\",\"title\":\"Transductive Inference for Text Classification using Support Vector Machines\",\"url\":\"https://www.semanticscholar.org/paper/74b1a9e50f18af8a7b9f8dd38f40e0466ad7a8e8\",\"venue\":\"ICML\",\"year\":1999},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"2577358\",\"name\":\"P. Srinivasan\"},{\"authorId\":\"46865129\",\"name\":\"J. Shi\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/CVPR.2009.5206492\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f3743f425faf5cae6fb1e55a864e8361027fff6c\",\"title\":\"Understanding videos, constructing plots learning a visually grounded storyline model from annotated videos\",\"url\":\"https://www.semanticscholar.org/paper/f3743f425faf5cae6fb1e55a864e8361027fff6c\",\"venue\":\"CVPR\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143655174\",\"name\":\"P. Turaga\"},{\"authorId\":\"9215658\",\"name\":\"R. Chellappa\"},{\"authorId\":\"1728462\",\"name\":\"V. Subrahmanian\"},{\"authorId\":\"2493008\",\"name\":\"O. Udrea\"}],\"doi\":\"10.1109/TCSVT.2008.2005594\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fbf1c51548ffc9b9e538befcd71529365af23d15\",\"title\":\"Machine Recognition of Human Activities: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/fbf1c51548ffc9b9e538befcd71529365af23d15\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1716301\",\"name\":\"R. Schapire\"},{\"authorId\":\"1740765\",\"name\":\"Y. Singer\"}],\"doi\":\"10.1145/279943.279960\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"14e53403a0055dbe5faaf9f1f3be96ca0e692a4d\",\"title\":\"Improved Boosting Algorithms using Confidence-Rated Predictions\",\"url\":\"https://www.semanticscholar.org/paper/14e53403a0055dbe5faaf9f1f3be96ca0e692a4d\",\"venue\":\"COLT\",\"year\":1998},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49230687\",\"name\":\"W. Yang\"},{\"authorId\":\"46396571\",\"name\":\"Y. Wang\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"}],\"doi\":\"10.1109/CVPR.2010.5539879\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c93fcbc5512a4634a557f420bcfad4caa313c470\",\"title\":\"Recognizing human actions from still images with latent poses\",\"url\":\"https://www.semanticscholar.org/paper/c93fcbc5512a4634a557f420bcfad4caa313c470\",\"venue\":\"2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3063676\",\"name\":\"Michalis Raptis\"},{\"authorId\":\"1715959\",\"name\":\"Stefano Soatto\"}],\"doi\":\"10.1007/978-3-642-15549-9_42\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eeaba0abdc26a89d8b9e3750db344c45d3460e7c\",\"title\":\"Tracklet Descriptors for Action Modeling and Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/eeaba0abdc26a89d8b9e3750db344c45d3460e7c\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48275599\",\"name\":\"R. Mann\"},{\"authorId\":\"1723930\",\"name\":\"A. Jepson\"},{\"authorId\":\"1737754\",\"name\":\"J. Siskind\"}],\"doi\":\"10.1007/3-540-61123-1_167\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"10a3f14faf79ec12d04f834abf8fea63a891232c\",\"title\":\"Computational Perception of Scene Dynamics\",\"url\":\"https://www.semanticscholar.org/paper/10a3f14faf79ec12d04f834abf8fea63a891232c\",\"venue\":\"ECCV\",\"year\":1996},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1739581\",\"name\":\"J. Lafferty\"},{\"authorId\":\"143753639\",\"name\":\"A. McCallum\"},{\"authorId\":\"152115316\",\"name\":\"F. Pereira\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f4ba954b0412773d047dc41231c733de0c1f4926\",\"title\":\"Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data\",\"url\":\"https://www.semanticscholar.org/paper/f4ba954b0412773d047dc41231c733de0c1f4926\",\"venue\":\"ICML\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"3254319\",\"name\":\"Hongcheng Wang\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"263442bab9faba9ad84c8a1dfb6ca9a0947bd4d4\",\"title\":\"Unsupervised Learning of Human Action Categories\",\"url\":\"https://www.semanticscholar.org/paper/263442bab9faba9ad84c8a1dfb6ca9a0947bd4d4\",\"venue\":\"\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"},{\"authorId\":\"1705627\",\"name\":\"J. Aggarwal\"}],\"doi\":\"10.1109/CVPR.2007.383487\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b1029d008f3b8b8ca6d6028eb922dc911e9558df\",\"title\":\"Hierarchical Recognition of Human Activities Interacting with Objects\",\"url\":\"https://www.semanticscholar.org/paper/b1029d008f3b8b8ca6d6028eb922dc911e9558df\",\"venue\":\"2007 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"3502855\",\"name\":\"M. Marszalek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"3261451\",\"name\":\"Benjamin Rozenfeld\"}],\"doi\":\"10.1109/CVPR.2008.4587756\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0f86767732f76f478d5845f2e59f99ba106e9265\",\"title\":\"Learning realistic human actions from movies\",\"url\":\"https://www.semanticscholar.org/paper/0f86767732f76f478d5845f2e59f99ba106e9265\",\"venue\":\"2008 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"3254319\",\"name\":\"Hongcheng Wang\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.5244/C.20.127\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e25d2a9aa691e63657fef30f5850799d757f69e6\",\"title\":\"Unsupervised Learning of Human Action Categories Using Spatial-Temporal Words\",\"url\":\"https://www.semanticscholar.org/paper/e25d2a9aa691e63657fef30f5850799d757f69e6\",\"venue\":\"BMVC\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32713089\",\"name\":\"D. Moore\"},{\"authorId\":\"21472040\",\"name\":\"Irfan Essa\"},{\"authorId\":\"144449603\",\"name\":\"M. Hayes\"}],\"doi\":\"10.1109/ICCV.1999.791201\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f090df944fceaf52cda458ed6116802cd36ca08e\",\"title\":\"Exploiting human actions and object context for recognition tasks\",\"url\":\"https://www.semanticscholar.org/paper/f090df944fceaf52cda458ed6116802cd36ca08e\",\"venue\":\"Proceedings of the Seventh IEEE International Conference on Computer Vision\",\"year\":1999},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47683829\",\"name\":\"A. Fathi\"},{\"authorId\":\"46426476\",\"name\":\"X. Ren\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1109/CVPR.2011.5995444\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"bc900a187b6f0115417f4b7dfd2cf44c62875bf8\",\"title\":\"Learning to recognize objects in egocentric activities\",\"url\":\"https://www.semanticscholar.org/paper/bc900a187b6f0115417f4b7dfd2cf44c62875bf8\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/ICCV.2003.1238420\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"804d86dd7ab3498266922244e73a88c1add5a6ab\",\"title\":\"Recognizing action at a distance\",\"url\":\"https://www.semanticscholar.org/paper/804d86dd7ab3498266922244e73a88c1add5a6ab\",\"venue\":\"Proceedings Ninth IEEE International Conference on Computer Vision\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40344698\",\"name\":\"R. Messing\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"},{\"authorId\":\"1690271\",\"name\":\"Henry A. Kautz\"}],\"doi\":\"10.1109/ICCV.2009.5459154\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"14528cfb9f2f049cefa1c6bfef17b1f18110eac1\",\"title\":\"Activity recognition using the velocity histories of tracked keypoints\",\"url\":\"https://www.semanticscholar.org/paper/14528cfb9f2f049cefa1c6bfef17b1f18110eac1\",\"venue\":\"2009 IEEE 12th International Conference on Computer Vision\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1700569\",\"name\":\"T. Moeslund\"},{\"authorId\":\"144046599\",\"name\":\"A. Hilton\"},{\"authorId\":\"48378203\",\"name\":\"V. Kr\\u00fcger\"}],\"doi\":\"10.1016/j.cviu.2006.08.002\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c4e16d64b77d133b7382440a08091d64008dd923\",\"title\":\"A survey of advances in vision-based human motion capture and analysis\",\"url\":\"https://www.semanticscholar.org/paper/c4e16d64b77d133b7382440a08091d64008dd923\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1688328\",\"name\":\"A. Bobick\"},{\"authorId\":\"144429686\",\"name\":\"J. Davis\"}],\"doi\":\"10.1109/34.910878\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"886431a362bfdbcc6dd518f844eb374950b9de86\",\"title\":\"The Recognition of Human Movement Using Temporal Templates\",\"url\":\"https://www.semanticscholar.org/paper/886431a362bfdbcc6dd518f844eb374950b9de86\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144040368\",\"name\":\"K. Kitani\"},{\"authorId\":\"1943600\",\"name\":\"T. Okabe\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"},{\"authorId\":\"143993575\",\"name\":\"A. Sugimoto\"}],\"doi\":\"10.1109/CVPR.2011.5995406\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8848d1abd31873594fc372e0022789f153112174\",\"title\":\"Fast unsupervised ego-action learning for first-person sports videos\",\"url\":\"https://www.semanticscholar.org/paper/8848d1abd31873594fc372e0022789f153112174\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1644050191\",\"name\":\"G. LoweDavid\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"4cab9c4b571761203ed4c3a4c5a07dd615f57a91\",\"title\":\"Distinctive Image Features from Scale-Invariant Keypoints\",\"url\":\"https://www.semanticscholar.org/paper/4cab9c4b571761203ed4c3a4c5a07dd615f57a91\",\"venue\":\"\",\"year\":2004}],\"title\":\"Understanding egocentric activities\",\"topics\":[{\"topic\":\"Activity recognition\",\"topicId\":\"46497\",\"url\":\"https://www.semanticscholar.org/topic/46497\"},{\"topic\":\"Bag-of-words model\",\"topicId\":\"66224\",\"url\":\"https://www.semanticscholar.org/topic/66224\"},{\"topic\":\"Function model\",\"topicId\":\"2715\",\"url\":\"https://www.semanticscholar.org/topic/2715\"},{\"topic\":\"Categorization\",\"topicId\":\"8505\",\"url\":\"https://www.semanticscholar.org/topic/8505\"},{\"topic\":\"Hierarchical database model\",\"topicId\":\"110806\",\"url\":\"https://www.semanticscholar.org/topic/110806\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Interaction\",\"topicId\":\"72\",\"url\":\"https://www.semanticscholar.org/topic/72\"},{\"topic\":\"Refinement (computing)\",\"topicId\":\"5410\",\"url\":\"https://www.semanticscholar.org/topic/5410\"},{\"topic\":\"Top-down and bottom-up design\",\"topicId\":\"96387\",\"url\":\"https://www.semanticscholar.org/topic/96387\"},{\"topic\":\"Sensor\",\"topicId\":\"1117\",\"url\":\"https://www.semanticscholar.org/topic/1117\"},{\"topic\":\"Bottom-up parsing\",\"topicId\":\"682974\",\"url\":\"https://www.semanticscholar.org/topic/682974\"},{\"topic\":\"Software propagation\",\"topicId\":\"2021211\",\"url\":\"https://www.semanticscholar.org/topic/2021211\"}],\"url\":\"https://www.semanticscholar.org/paper/bfc71c97f21b354ddfe69d17115e52db4fd4dce8\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011}\n"