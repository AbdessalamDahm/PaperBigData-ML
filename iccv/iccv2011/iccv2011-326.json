"{\"abstract\":\"With nearly one billion online videos viewed everyday, an emerging new frontier in computer vision research is recognition and search in video. While much effort has been devoted to the collection and annotation of large scalable static image datasets containing thousands of image categories, human action datasets lag far behind. Current action recognition databases contain on the order of ten different action categories collected under fairly controlled conditions. State-of-the-art performance on these datasets is now near ceiling and thus there is a need for the design and creation of new benchmarks. To address this issue we collected the largest action video database to-date with 51 action categories, which in total contain around 7,000 manually annotated clips extracted from a variety of sources ranging from digitized movies to YouTube. We use this database to evaluate the performance of two representative computer vision systems for action recognition and explore the robustness of these methods under various conditions such as camera motion, viewpoint, video quality and occlusion.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\",\"url\":\"https://www.semanticscholar.org/author/123446103\"},{\"authorId\":\"119268487\",\"name\":\"Hueihan Jhuang\",\"url\":\"https://www.semanticscholar.org/author/119268487\"},{\"authorId\":\"1930964\",\"name\":\"E. Garrote\",\"url\":\"https://www.semanticscholar.org/author/1930964\"},{\"authorId\":\"145031878\",\"name\":\"T. Poggio\",\"url\":\"https://www.semanticscholar.org/author/145031878\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\",\"url\":\"https://www.semanticscholar.org/author/1981539\"}],\"citationVelocity\":366,\"citations\":[{\"arxivId\":\"1907.10915\",\"authors\":[{\"authorId\":\"2470198\",\"name\":\"Jiaolong Xu\"},{\"authorId\":\"145033241\",\"name\":\"L. Xiao\"},{\"authorId\":\"144187725\",\"name\":\"Antonio M. L\\u00f3pez\"}],\"doi\":\"10.1109/ACCESS.2019.2949697\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cafcee20d282a346e923965cfad8d689f4c6c92a\",\"title\":\"Self-Supervised Domain Adaptation for Computer Vision Tasks\",\"url\":\"https://www.semanticscholar.org/paper/cafcee20d282a346e923965cfad8d689f4c6c92a\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"2148510\",\"name\":\"A. Angelova\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"38df033adc8b89ad02a638db823be439260113bd\",\"title\":\"Tiny Video Networks: Architecture Search for Efficient Video Models\",\"url\":\"https://www.semanticscholar.org/paper/38df033adc8b89ad02a638db823be439260113bd\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121247048\",\"name\":\"Mauricio Perez\"},{\"authorId\":\"145438759\",\"name\":\"S. Avila\"},{\"authorId\":\"133845545\",\"name\":\"D. Moreira\"},{\"authorId\":\"144573251\",\"name\":\"D. Moraes\"},{\"authorId\":\"3095283\",\"name\":\"Vanessa Testoni\"},{\"authorId\":\"145487017\",\"name\":\"E. Valle\"},{\"authorId\":\"1689508\",\"name\":\"S. Goldenstein\"},{\"authorId\":\"145603848\",\"name\":\"Anderson Rocha\"}],\"doi\":\"10.1016/j.neucom.2016.12.017\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fcda7a74c5b8e6533f72e4483440ba4286f16a85\",\"title\":\"Video pornography detection through deep learning techniques and motion information\",\"url\":\"https://www.semanticscholar.org/paper/fcda7a74c5b8e6533f72e4483440ba4286f16a85\",\"venue\":\"Neurocomputing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39796129\",\"name\":\"Hayden Faulkner\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"}],\"doi\":\"10.1109/DICTA.2017.8227494\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4ee94572ae1d9c090fe81baa7236c7efbe1ca5b4\",\"title\":\"TenniSet: A Dataset for Dense Fine-Grained Event Recognition, Localisation and Description\",\"url\":\"https://www.semanticscholar.org/paper/4ee94572ae1d9c090fe81baa7236c7efbe1ca5b4\",\"venue\":\"2017 International Conference on Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2017},{\"arxivId\":\"1512.00795\",\"authors\":[{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1109/CVPR.2016.291\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8d093efcfadda3ac7de7b0e1ca7d9aa2005c2ec3\",\"title\":\"Actions ~ Transformations\",\"url\":\"https://www.semanticscholar.org/paper/8d093efcfadda3ac7de7b0e1ca7d9aa2005c2ec3\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3260425\",\"name\":\"Shijian Huang\"},{\"authorId\":\"2852884\",\"name\":\"Junyong Ye\"},{\"authorId\":\"2366005\",\"name\":\"T. Wang\"},{\"authorId\":\"48931975\",\"name\":\"L. Jiang\"},{\"authorId\":\"2764253\",\"name\":\"Changyuan Xing\"},{\"authorId\":null,\"name\":\"Yang Li\"}],\"doi\":\"10.1587/TRANSINF.2015EDL8148\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0fbd645d4c55bdeb6b48bdc2620b3a5bd58dae66\",\"title\":\"Learning a Similarity Constrained Discriminative Kernel Dictionary from Concatenated Low-Rank Features for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/0fbd645d4c55bdeb6b48bdc2620b3a5bd58dae66\",\"venue\":\"IEICE Trans. Inf. Syst.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143798882\",\"name\":\"Mihir Jain\"},{\"authorId\":\"1681054\",\"name\":\"H. J\\u00e9gou\"},{\"authorId\":\"1716733\",\"name\":\"P. Bouthemy\"}],\"doi\":\"10.1109/CVPR.2013.330\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9a4bff7e93a2d2d50495d873890cf52f868d3b66\",\"title\":\"Better Exploiting Motion for Better Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9a4bff7e93a2d2d50495d873890cf52f868d3b66\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":\"1812.01717\",\"authors\":[{\"authorId\":\"2465270\",\"name\":\"Thomas Unterthiner\"},{\"authorId\":\"3440930\",\"name\":\"Sjoerd van Steenkiste\"},{\"authorId\":\"2006889\",\"name\":\"Karol Kurach\"},{\"authorId\":\"52153018\",\"name\":\"Rapha\\u00ebl Marinier\"},{\"authorId\":\"144859281\",\"name\":\"M. Michalski\"},{\"authorId\":\"1802148\",\"name\":\"S. Gelly\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b59233aab8364186603967bc12d88af48cc0992d\",\"title\":\"Towards Accurate Generative Models of Video: A New Metric & Challenges\",\"url\":\"https://www.semanticscholar.org/paper/b59233aab8364186603967bc12d88af48cc0992d\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2011.10834\",\"authors\":[{\"authorId\":\"1944615571\",\"name\":\"A. Almeida\"},{\"authorId\":\"145334240\",\"name\":\"J. P. D. Villiers\"},{\"authorId\":\"145515736\",\"name\":\"A. D. Freitas\"},{\"authorId\":\"1944660087\",\"name\":\"M. Velayudan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c1d17ac263557f5306e620b431354cc84df14be0\",\"title\":\"Exploring the multimodal information from video content using deep learning features of appearance, audio and action for video recommendation\",\"url\":\"https://www.semanticscholar.org/paper/c1d17ac263557f5306e620b431354cc84df14be0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1803305\",\"name\":\"W. Li\"},{\"authorId\":\"3026404\",\"name\":\"Yongkang Wong\"},{\"authorId\":\"143602033\",\"name\":\"Anan Liu\"},{\"authorId\":null,\"name\":\"Yang Li\"},{\"authorId\":\"2788104\",\"name\":\"Yuting Su\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"1056347fc5e8cd86c875a2747b5f84fd570ba232\",\"title\":\"Multi-Camera Action Dataset (MCAD): A Dataset for Studying Non-overlapped Cross-Camera Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1056347fc5e8cd86c875a2747b5f84fd570ba232\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2837968\",\"name\":\"K. Wang\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"977b24ed0e8f71711287544b42021d0a13c97b41\",\"title\":\"Classifying NBA Offensive Plays Using Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/977b24ed0e8f71711287544b42021d0a13c97b41\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9267486\",\"name\":\"Si Miao\"},{\"authorId\":\"1724825\",\"name\":\"Haoyu Xu\"},{\"authorId\":\"2005462\",\"name\":\"Zhenqi Han\"},{\"authorId\":\"35884242\",\"name\":\"Y. Zhu\"}],\"doi\":\"10.1109/ACCESS.2019.2921220\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"729b76715c5665643058045de178a0b91262dfdb\",\"title\":\"Recognizing Facial Expressions Using a Shallow Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/729b76715c5665643058045de178a0b91262dfdb\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153580352\",\"name\":\"Ionut Cosmin Duta\"},{\"authorId\":\"1796198\",\"name\":\"B. Ionescu\"},{\"authorId\":\"1712839\",\"name\":\"K. Aizawa\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":\"10.1007/978-3-319-51811-4_30\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"be5276e9744c4445fe5b12b785650e8f173f56ff\",\"title\":\"Spatio-Temporal VLAD Encoding for Human Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/be5276e9744c4445fe5b12b785650e8f173f56ff\",\"venue\":\"MMM\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46818097\",\"name\":\"K. Lakshmi\"},{\"authorId\":\"40608152\",\"name\":\"Mihir Solanki\"},{\"authorId\":\"52437324\",\"name\":\"J. Swaroop\"},{\"authorId\":\"1658903368\",\"name\":\"A. Bhargav\"}],\"doi\":\"10.14569/ijacsa.2020.0110321\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"3265028963540d10c7ce582f0a06ae46c622a8c7\",\"title\":\"Video Genre Classification using Convolutional Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/3265028963540d10c7ce582f0a06ae46c622a8c7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40596452\",\"name\":\"Leyla Tarhan\"},{\"authorId\":\"1742525744\",\"name\":\"Talia Konkle\"}],\"doi\":\"10.1038/s41467-020-16846-w\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a4c0f4a01ac6315c7b4920895c44df1176c72ac6\",\"title\":\"Sociality and interaction envelope organize visual action representations\",\"url\":\"https://www.semanticscholar.org/paper/a4c0f4a01ac6315c7b4920895c44df1176c72ac6\",\"venue\":\"Nature Communications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143954557\",\"name\":\"J. Jones\"},{\"authorId\":\"1678633\",\"name\":\"Gregory Hager\"},{\"authorId\":\"2803071\",\"name\":\"S. Khudanpur\"}],\"doi\":\"10.1109/WACV.2019.00051\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ecf6fc2c42d83ca7fe18fdb6dd8c9b8770f9baca\",\"title\":\"Toward Computer Vision Systems That Understand Real-World Assembly Processes\",\"url\":\"https://www.semanticscholar.org/paper/ecf6fc2c42d83ca7fe18fdb6dd8c9b8770f9baca\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":\"1912.00308\",\"authors\":[{\"authorId\":\"121310313\",\"name\":\"Yiyi Zhang\"},{\"authorId\":\"1716055\",\"name\":\"Li Niu\"},{\"authorId\":\"13944031\",\"name\":\"Ziqi Pan\"},{\"authorId\":\"1438947172\",\"name\":\"Meichao Luo\"},{\"authorId\":\"49051251\",\"name\":\"Jianfu Zhang\"},{\"authorId\":\"2476347\",\"name\":\"Dawei Cheng\"},{\"authorId\":\"48571700\",\"name\":\"L. Zhang\"}],\"doi\":\"10.1609/AAAI.V34I07.6990\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"223eba328e72650eda1cc85817f4d396cc116eb4\",\"title\":\"Exploiting Motion Information from Unlabeled Videos for Static Image Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/223eba328e72650eda1cc85817f4d396cc116eb4\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3211859\",\"name\":\"Biyun Sheng\"},{\"authorId\":\"31595791\",\"name\":\"J. Li\"},{\"authorId\":\"10225694\",\"name\":\"F. Xiao\"},{\"authorId\":\"2914175\",\"name\":\"Wan-kou Yang\"}],\"doi\":\"10.1016/j.neucom.2020.02.096\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9682c70b844cb35eb602d165933d83a369c986c2\",\"title\":\"Multilayer deep features with multiple kernel learning for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/9682c70b844cb35eb602d165933d83a369c986c2\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144082568\",\"name\":\"Liangliang Wang\"},{\"authorId\":\"39975036\",\"name\":\"R. Li\"},{\"authorId\":\"40630660\",\"name\":\"Y. Fang\"}],\"doi\":\"10.1007/s00138-017-0848-0\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d8c9bad8d07ae4196027dfb8343b9d9aefb130ff\",\"title\":\"Power difference template for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/d8c9bad8d07ae4196027dfb8343b9d9aefb130ff\",\"venue\":\"Machine Vision and Applications\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49854896\",\"name\":\"M. Fang\"},{\"authorId\":\"47055440\",\"name\":\"X. Bai\"},{\"authorId\":\"113734234\",\"name\":\"J. Zhao\"},{\"authorId\":\"119704789\",\"name\":\"F. Yang\"},{\"authorId\":\"144042438\",\"name\":\"C. Hung\"},{\"authorId\":\"122050993\",\"name\":\"Shuhua Liu\"}],\"doi\":\"10.1007/s00530-020-00683-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"340ef80d63c6514598839e29e6f24ffb9dc22212\",\"title\":\"Integrating Gaussian mixture model and dilated residual network for action recognition in videos\",\"url\":\"https://www.semanticscholar.org/paper/340ef80d63c6514598839e29e6f24ffb9dc22212\",\"venue\":\"Multimedia Systems\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41127426\",\"name\":\"Jiaying Liu\"},{\"authorId\":\"3384254\",\"name\":\"Sijie Song\"},{\"authorId\":\"48093650\",\"name\":\"Chunhui Liu\"},{\"authorId\":\"48513679\",\"name\":\"Yanghao Li\"},{\"authorId\":\"9956463\",\"name\":\"Yueyu Hu\"}],\"doi\":\"10.1145/3365212\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"76f6ca119c719cd9f9362a160fb15af2b895095f\",\"title\":\"A Benchmark Dataset and Comparison Study for Multi-modal Human Action Analytics\",\"url\":\"https://www.semanticscholar.org/paper/76f6ca119c719cd9f9362a160fb15af2b895095f\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1978582908\",\"name\":\"Divina Govender\"},{\"authorId\":\"66491832\",\"name\":\"Jules-Raymond Tapamo\"}],\"doi\":\"10.3390/s20216380\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"85be850607b8d65c9b22082c7a20b06b11f6c2a6\",\"title\":\"Spatio-Temporal Scale Coded Bag-of-Words\",\"url\":\"https://www.semanticscholar.org/paper/85be850607b8d65c9b22082c7a20b06b11f6c2a6\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31474374\",\"name\":\"P. Bilinski\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8110ecbd519a6391daa90f342d1245b0e865a3fc\",\"title\":\"Human action recognition in videos\",\"url\":\"https://www.semanticscholar.org/paper/8110ecbd519a6391daa90f342d1245b0e865a3fc\",\"venue\":\"\",\"year\":2014},{\"arxivId\":\"1909.01954\",\"authors\":[{\"authorId\":\"20772402\",\"name\":\"B. Gatto\"},{\"authorId\":\"2657966\",\"name\":\"E. M. D. Santos\"},{\"authorId\":\"1808179\",\"name\":\"Alessandro Lameiras Koerich\"},{\"authorId\":\"1770128\",\"name\":\"K. Fukui\"},{\"authorId\":\"144996736\",\"name\":\"Waldir S. S. Junior\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"bc8395a520a79ffe636dd3fb2d03889529baa211\",\"title\":\"Tensor Analysis with n-Mode Generalized Difference Subspace\",\"url\":\"https://www.semanticscholar.org/paper/bc8395a520a79ffe636dd3fb2d03889529baa211\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1906.05910\",\"authors\":[{\"authorId\":\"46659935\",\"name\":\"Lei Wang\"},{\"authorId\":\"2155775\",\"name\":\"Piotr Koniusz\"},{\"authorId\":\"144199437\",\"name\":\"D. Huynh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f9a9965c013be1269c05a96857c78ad8c87ee517\",\"title\":\"Hallucinating Bag-of-Words and Fisher Vector IDT terms for CNN-based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f9a9965c013be1269c05a96857c78ad8c87ee517\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145201177\",\"name\":\"J. T. Balint\"},{\"authorId\":\"1855748\",\"name\":\"J. Allbeck\"}],\"doi\":\"10.1002/cav.1759\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2184ecd156cf91eaac5a38d6ea512e43945b1a83\",\"title\":\"ALET: Agents Learning their Environment through Text\",\"url\":\"https://www.semanticscholar.org/paper/2184ecd156cf91eaac5a38d6ea512e43945b1a83\",\"venue\":\"Comput. Animat. Virtual Worlds\",\"year\":2017},{\"arxivId\":\"2009.10580\",\"authors\":[{\"authorId\":\"47577022\",\"name\":\"Nannan Li\"},{\"authorId\":\"143749868\",\"name\":\"Yu Pan\"},{\"authorId\":\"47557528\",\"name\":\"Yaran Chen\"},{\"authorId\":\"83352946\",\"name\":\"Zixiang Ding\"},{\"authorId\":\"1699234\",\"name\":\"D. Zhao\"},{\"authorId\":\"1683510\",\"name\":\"Zenglin Xu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"4b4ddc2b9de508c651769dd2b2b4c47bc082633f\",\"title\":\"Heuristic Rank Selection with Progressively Searching Tensor Ring Network\",\"url\":\"https://www.semanticscholar.org/paper/4b4ddc2b9de508c651769dd2b2b4c47bc082633f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145380510\",\"name\":\"L. Rossetto\"},{\"authorId\":\"2155883\",\"name\":\"Ivan Giangreco\"},{\"authorId\":\"34588610\",\"name\":\"S. Heller\"},{\"authorId\":\"2926040\",\"name\":\"C. Tanase\"},{\"authorId\":\"145717652\",\"name\":\"H. Schuldt\"},{\"authorId\":\"144436412\",\"name\":\"S. Dupont\"},{\"authorId\":\"3272087\",\"name\":\"Omar Seddati\"},{\"authorId\":\"143765782\",\"name\":\"T. M. Sezgin\"},{\"authorId\":\"3337793\",\"name\":\"Ozan Can Altiok\"},{\"authorId\":\"2870361\",\"name\":\"Y. Sahillioglu\"}],\"doi\":\"10.1007/978-3-319-27674-8_36\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"465d5bb11912005f0a4f0569c6524981df18a7de\",\"title\":\"IMOTION - Searching for Video Sequences Using Multi-Shot Sketch Queries\",\"url\":\"https://www.semanticscholar.org/paper/465d5bb11912005f0a4f0569c6524981df18a7de\",\"venue\":\"MMM\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48093158\",\"name\":\"Jinpeng Wang\"},{\"authorId\":\"145517136\",\"name\":\"A. Ma\"}],\"doi\":\"10.1007/978-3-030-34120-6_7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9ad5dce0e3d9663a5d0c4044c927776e4bcef2e2\",\"title\":\"Spatial-Temporal Bottom-Up Top-Down Attention Model for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9ad5dce0e3d9663a5d0c4044c927776e4bcef2e2\",\"venue\":\"ICIG\",\"year\":2019},{\"arxivId\":\"1502.01540\",\"authors\":[{\"authorId\":\"1390531672\",\"name\":\"Xun Xu\"},{\"authorId\":\"79456794\",\"name\":\"Timothy M. Hospedales\"},{\"authorId\":\"144784813\",\"name\":\"S. Gong\"}],\"doi\":\"10.1109/ICIP.2015.7350760\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3ca2e45db5c88d830c3e31134feacd793c09ee2f\",\"title\":\"Semantic embedding space for zero-shot action recognition\",\"url\":\"https://www.semanticscholar.org/paper/3ca2e45db5c88d830c3e31134feacd793c09ee2f\",\"venue\":\"2015 IEEE International Conference on Image Processing (ICIP)\",\"year\":2015},{\"arxivId\":\"1605.08125\",\"authors\":[{\"authorId\":\"3195774\",\"name\":\"Waqas Sultani\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1016/j.cviu.2017.05.005\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"18be19ca3c8e006bf63293ac2dad4a06c5fbf7f7\",\"title\":\"Automatic action annotation in weakly labeled videos\",\"url\":\"https://www.semanticscholar.org/paper/18be19ca3c8e006bf63293ac2dad4a06c5fbf7f7\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"1803711\",\"name\":\"H. Idrees\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/CVPR.2016.290\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"68bd9fa880a368b82782f617deefbde9552cac28\",\"title\":\"Predicting the Where and What of Actors and Actions through Online Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/68bd9fa880a368b82782f617deefbde9552cac28\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1706.00699\",\"authors\":[{\"authorId\":\"32774629\",\"name\":\"Alexander Richard\"},{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7577a1ddf9195513a5c976887ad806d1386bb1e9\",\"title\":\"Temporal Action Labeling using Action Sets\",\"url\":\"https://www.semanticscholar.org/paper/7577a1ddf9195513a5c976887ad806d1386bb1e9\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34646933\",\"name\":\"T. V. Nguyen\"},{\"authorId\":\"3421228\",\"name\":\"Bilal Mirza\"}],\"doi\":\"10.1016/j.neucom.2017.04.007\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2bf29868e856621a59dad8adb2c66e21348612ef\",\"title\":\"Dual-layer kernel extreme learning machine for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/2bf29868e856621a59dad8adb2c66e21348612ef\",\"venue\":\"Neurocomputing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49794918\",\"name\":\"Xin Chen\"},{\"authorId\":\"145369053\",\"name\":\"J. Weng\"},{\"authorId\":null,\"name\":\"Wei Lu\"},{\"authorId\":null,\"name\":\"Jiaming Xu\"},{\"authorId\":\"81346503\",\"name\":\"Jiasi Weng\"}],\"doi\":\"10.1109/TNNLS.2017.2740318\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"782a05fbe30269ff8ab427109f5c4d0a577e5284\",\"title\":\"Deep Manifold Learning Combined With Convolutional Neural Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/782a05fbe30269ff8ab427109f5c4d0a577e5284\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29724362\",\"name\":\"Longlong Jing\"},{\"authorId\":\"3105254\",\"name\":\"Yuancheng Ye\"},{\"authorId\":\"38101706\",\"name\":\"Xiaodong Yang\"},{\"authorId\":\"35484757\",\"name\":\"Yingli Tian\"}],\"doi\":\"10.1109/ICIP.2017.8296599\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d4985dde77a09674fa3264decc1a809da206fbae\",\"title\":\"3D convolutional neural network with multi-model framework for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/d4985dde77a09674fa3264decc1a809da206fbae\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"79755154\",\"name\":\"Hongje Seong\"},{\"authorId\":\"2246939\",\"name\":\"Junhyuk Hyun\"},{\"authorId\":\"70400973\",\"name\":\"Euntai Kim\"}],\"doi\":\"10.1109/ICCVW.2019.00194\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0be0313db9a4fd54a2e3a4f427772498a1419db8\",\"title\":\"Video Multitask Transformer Network\",\"url\":\"https://www.semanticscholar.org/paper/0be0313db9a4fd54a2e3a4f427772498a1419db8\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"28933059\",\"name\":\"Jiangchuan Wei\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"50130622\",\"name\":\"Yun Yi\"},{\"authorId\":\"8194130\",\"name\":\"Qinyu Li\"},{\"authorId\":\"8312366\",\"name\":\"De-Shuang Huang\"}],\"doi\":\"10.1109/ICIP.2019.8802979\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6c4e7471cd845223b852efe09e5985544332b22a\",\"title\":\"P3D-CTN: Pseudo-3D Convolutional Tube Network for Spatio-Temporal Action Detection in Videos\",\"url\":\"https://www.semanticscholar.org/paper/6c4e7471cd845223b852efe09e5985544332b22a\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390421338\",\"name\":\"Sheng Yu\"},{\"authorId\":\"1400233791\",\"name\":\"Li Xie\"},{\"authorId\":\"152644954\",\"name\":\"Lin Liu\"},{\"authorId\":\"9340242\",\"name\":\"Daoxun Xia\"}],\"doi\":\"10.1109/ACCESS.2019.2962284\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"179a116f3fb59dac65c974f94ad92e21eaf011a1\",\"title\":\"Learning Long-Term Temporal Features With Deep Neural Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/179a116f3fb59dac65c974f94ad92e21eaf011a1\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"DA COMPUTA\\u00c7\\u00c3O\"},{\"authorId\":\"3052490\",\"name\":\"M. Vieira\"},{\"authorId\":\"3387755\",\"name\":\"S. Villela\"},{\"authorId\":null,\"name\":\"Hemerson Aparecido da Costa\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"838871719b323c2b457c769cdf66d68f06df9523\",\"title\":\"Data Augmentation of Visual Rhythms using Symmetric Extension for Deep Learning Video Based Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/838871719b323c2b457c769cdf66d68f06df9523\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36794849\",\"name\":\"L. Zhang\"},{\"authorId\":\"49981283\",\"name\":\"T. Wang\"},{\"authorId\":\"34798935\",\"name\":\"Xiantong Zhen\"}],\"doi\":\"10.1109/ICIP.2013.6738497\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3d3fcaf91c767ac9a9ee39d8f02709f645272663\",\"title\":\"Recognizing actions via sparse coding on structure projection\",\"url\":\"https://www.semanticscholar.org/paper/3d3fcaf91c767ac9a9ee39d8f02709f645272663\",\"venue\":\"2013 IEEE International Conference on Image Processing\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23278631\",\"name\":\"Guangle Yao\"},{\"authorId\":\"144673774\",\"name\":\"T. Lei\"},{\"authorId\":\"23227806\",\"name\":\"Jiandan Zhong\"},{\"authorId\":\"143657565\",\"name\":\"P. Jiang\"}],\"doi\":\"10.1007/s10489-018-1347-3\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"57bb032953f09168953f1cc03102b9269eeee7f5\",\"title\":\"Learning multi-temporal-scale deep information for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/57bb032953f09168953f1cc03102b9269eeee7f5\",\"venue\":\"Applied Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3174233\",\"name\":\"H. Boyraz\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a27cac500a0cd082be151a52703eabd818f92514\",\"title\":\"Human Action Localization And Recognition In Unconstrained Videos\",\"url\":\"https://www.semanticscholar.org/paper/a27cac500a0cd082be151a52703eabd818f92514\",\"venue\":\"\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3381029\",\"name\":\"J. Wang\"},{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1016/j.cviu.2019.102898\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"62af68e20481f9f98509bfed69ef1300a8e9485e\",\"title\":\"Cascade multi-head attention networks for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/62af68e20481f9f98509bfed69ef1300a8e9485e\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3150525\",\"name\":\"E. Chen\"},{\"authorId\":\"144981720\",\"name\":\"Xue Bai\"},{\"authorId\":\"145735014\",\"name\":\"L. Gao\"},{\"authorId\":\"74806144\",\"name\":\"H. Tinega\"},{\"authorId\":\"1761058\",\"name\":\"Y. Ding\"}],\"doi\":\"10.1109/ACCESS.2019.2910604\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"41bfc72e40cb5878e1f6e54f450abb69345f8a99\",\"title\":\"A Spatiotemporal Heterogeneous Two-Stream Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/41bfc72e40cb5878e1f6e54f450abb69345f8a99\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2983562\",\"name\":\"Huafeng Chen\"},{\"authorId\":\"47740566\",\"name\":\"J. Chen\"},{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"144328091\",\"name\":\"R. Hu\"}],\"doi\":\"10.1109/ICIP.2017.8296441\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c0f67e850176bb778b6c048d81c3d7e4d8c41003\",\"title\":\"Action recognition with gradient boundary convolutional network\",\"url\":\"https://www.semanticscholar.org/paper/c0f67e850176bb778b6c048d81c3d7e4d8c41003\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40415139\",\"name\":\"Neelay Pandit\"},{\"authorId\":\"40005980\",\"name\":\"S. Abdelhak\"}],\"doi\":\"10.1145/3126686.3126775\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"2c648da4d3b0fb7f175111ddad58ba912b37d9c6\",\"title\":\"Evolution of Trajectories: A Novel Representation for Deep Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c648da4d3b0fb7f175111ddad58ba912b37d9c6\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39974958\",\"name\":\"T. Yu\"},{\"authorId\":\"46181112\",\"name\":\"Chaoxu Guo\"},{\"authorId\":\"46660013\",\"name\":\"L. Wang\"},{\"authorId\":\"1909131\",\"name\":\"Huxiang Gu\"},{\"authorId\":\"1683738\",\"name\":\"S. Xiang\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.1016/j.patrec.2018.07.034\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"403f756f9f18948994e7a650ccb0be359d695530\",\"title\":\"Joint spatial-temporal attention for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/403f756f9f18948994e7a650ccb0be359d695530\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2018},{\"arxivId\":\"1502.04132\",\"authors\":[{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"2314980\",\"name\":\"X. Li\"},{\"authorId\":\"144247571\",\"name\":\"Ming Lin\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"db2517d518ae7c48fc2ad79f1839bd5d464411a0\",\"title\":\"Long-short Term Motion Feature for Action Classification and Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/db2517d518ae7c48fc2ad79f1839bd5d464411a0\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"15187304\",\"name\":\"Chien-Fang Chiu\"},{\"authorId\":\"1726411\",\"name\":\"Chien-Hao Kuo\"},{\"authorId\":\"145456212\",\"name\":\"P. Chang\"}],\"doi\":\"10.23919/APSIPA.2018.8659703\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"369e25b87bff71e350e995a890ab69965c20e488\",\"title\":\"Smoking Action Recognition Based on Spatial-Temporal Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/369e25b87bff71e350e995a890ab69965c20e488\",\"venue\":\"2018 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9229148\",\"name\":\"Y. Han\"},{\"authorId\":\"48754075\",\"name\":\"P. Zhang\"},{\"authorId\":\"2628886\",\"name\":\"Tao Zhuo\"},{\"authorId\":\"1730584\",\"name\":\"W. Huang\"},{\"authorId\":\"1801395\",\"name\":\"Y. Zhang\"}],\"doi\":\"10.1109/CVPRW.2017.162\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"34c8de02a5064e27760d33b861b7e47161592e65\",\"title\":\"Video Action Recognition Based on Deeper Convolution Networks with Pair-Wise Frame Motion Concatenation\",\"url\":\"https://www.semanticscholar.org/paper/34c8de02a5064e27760d33b861b7e47161592e65\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1823362\",\"name\":\"J. Uijlings\"},{\"authorId\":\"153580352\",\"name\":\"Ionut Cosmin Duta\"},{\"authorId\":\"1716310\",\"name\":\"E. Sangineto\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":\"10.1007/s13735-014-0069-5\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"aa5e24ac5ea78fb9ee4f39143a5c0b74e9eced98\",\"title\":\"Video classification with Densely extracted HOG/HOF/MBH features: an evaluation of the accuracy/computational efficiency trade-off\",\"url\":\"https://www.semanticscholar.org/paper/aa5e24ac5ea78fb9ee4f39143a5c0b74e9eced98\",\"venue\":\"International Journal of Multimedia Information Retrieval\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47508738\",\"name\":\"Shuangshuang Guo\"},{\"authorId\":\"2343895\",\"name\":\"Laiyun Qing\"},{\"authorId\":\"145235303\",\"name\":\"Jun Miao\"},{\"authorId\":\"7667827\",\"name\":\"L. Duan\"}],\"doi\":\"10.1109/BigMM.2018.8499470\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ee15b67b606ff49cd17467b062c11441e3b2dd70\",\"title\":\"Deep Residual Feature Learning for Action Prediction\",\"url\":\"https://www.semanticscholar.org/paper/ee15b67b606ff49cd17467b062c11441e3b2dd70\",\"venue\":\"2018 IEEE Fourth International Conference on Multimedia Big Data (BigMM)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145015817\",\"name\":\"Gang Yu\"},{\"authorId\":\"144890540\",\"name\":\"Ting Li\"}],\"doi\":\"10.1007/978-3-319-68345-4_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ea7da6a7d05095c21b283db13498fc30476cd60b\",\"title\":\"Recognition of Human Continuous Action with 3D CNN\",\"url\":\"https://www.semanticscholar.org/paper/ea7da6a7d05095c21b283db13498fc30476cd60b\",\"venue\":\"ICVS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50504401\",\"name\":\"Wei Chen\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"144418348\",\"name\":\"R. Xu\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1109/CVPR.2014.101\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6226f4040fce4e636c75b9fd3abd42c4f32639dd\",\"title\":\"Actionness Ranking with Lattice Conditional Ordinal Random Fields\",\"url\":\"https://www.semanticscholar.org/paper/6226f4040fce4e636c75b9fd3abd42c4f32639dd\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1904.03493\",\"authors\":[{\"authorId\":\"48631993\",\"name\":\"Xin Eric Wang\"},{\"authorId\":\"46365930\",\"name\":\"Jiawei Wu\"},{\"authorId\":\"47739808\",\"name\":\"Junkun Chen\"},{\"authorId\":\"46255707\",\"name\":\"Lei Li\"},{\"authorId\":\"1706938\",\"name\":\"Y. Wang\"},{\"authorId\":\"1682479\",\"name\":\"William Yang Wang\"}],\"doi\":\"10.1109/ICCV.2019.00468\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"28b74bb7c8b08cceb2430ec2d54dfa0f3225d796\",\"title\":\"VaTeX: A Large-Scale, High-Quality Multilingual Dataset for Video-and-Language Research\",\"url\":\"https://www.semanticscholar.org/paper/28b74bb7c8b08cceb2430ec2d54dfa0f3225d796\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1471106222\",\"name\":\"Huan Liu\"},{\"authorId\":\"2082966\",\"name\":\"L. Yao\"},{\"authorId\":\"50320297\",\"name\":\"Qinghua Zheng\"},{\"authorId\":\"3326677\",\"name\":\"Minnan Luo\"},{\"authorId\":\"151501346\",\"name\":\"H. Zhao\"},{\"authorId\":\"120292094\",\"name\":\"Yanzhang Lyu\"}],\"doi\":\"10.1016/j.ins.2020.01.025\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c5e9e16c9874f4baa58137d26c6f6fa79c3df4ce\",\"title\":\"Dual-stream generative adversarial networks for distributionally robust zero-shot learning\",\"url\":\"https://www.semanticscholar.org/paper/c5e9e16c9874f4baa58137d26c6f6fa79c3df4ce\",\"venue\":\"Inf. Sci.\",\"year\":2020},{\"arxivId\":\"2003.07064\",\"authors\":[{\"authorId\":\"50311569\",\"name\":\"O. Kayhan\"},{\"authorId\":\"1738975\",\"name\":\"J. C. V. Gemert\"}],\"doi\":\"10.1109/cvpr42600.2020.01428\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e00b35920a38cfc3fc58c72d70f5518b0a397a8d\",\"title\":\"On Translation Invariance in CNNs: Convolutional Layers can Exploit Absolute Spatial Location\",\"url\":\"https://www.semanticscholar.org/paper/e00b35920a38cfc3fc58c72d70f5518b0a397a8d\",\"venue\":\"CVPR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2089428\",\"name\":\"D. P. Barrett\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"eec326ea0a1a1044b011c2b454fe8b7ce1240a30\",\"title\":\"Learning in vision and robotics\",\"url\":\"https://www.semanticscholar.org/paper/eec326ea0a1a1044b011c2b454fe8b7ce1240a30\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144214889\",\"name\":\"C. Cuevas\"},{\"authorId\":\"32389068\",\"name\":\"E. Y\\u00e1\\u00f1ez\"},{\"authorId\":\"145728918\",\"name\":\"N. Garc\\u00eda\"}],\"doi\":\"10.1016/j.cviu.2016.08.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"81eba2ed7c200ccc1ab0f5e5e0ed9ebe10c394ee\",\"title\":\"Labeled dataset for integral evaluation of moving object detection algorithms: LASIESTA\",\"url\":\"https://www.semanticscholar.org/paper/81eba2ed7c200ccc1ab0f5e5e0ed9ebe10c394ee\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491240780\",\"name\":\"Z. Shi\"},{\"authorId\":\"144962375\",\"name\":\"Cheng Guan\"},{\"authorId\":\"1491233401\",\"name\":\"Liangjie Cao\"},{\"authorId\":\"1632356255\",\"name\":\"Qianqian Li\"},{\"authorId\":\"1993660232\",\"name\":\"Ju Liang\"},{\"authorId\":\"29344734\",\"name\":\"Zhaorui Gu\"},{\"authorId\":\"2336297\",\"name\":\"Haiyong Zheng\"},{\"authorId\":\"1470709309\",\"name\":\"Bing Zheng\"}],\"doi\":\"10.1007/978-3-030-58539-6_23\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"c826e169f505f6fda0872d0a3e1e156e15b5111e\",\"title\":\"CoTeRe-Net: Discovering Collaborative Ternary Relations in Videos\",\"url\":\"https://www.semanticscholar.org/paper/c826e169f505f6fda0872d0a3e1e156e15b5111e\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1778780\",\"name\":\"S. Lo\"},{\"authorId\":\"1733691\",\"name\":\"A. Tsoi\"}],\"doi\":\"10.1007/978-3-319-16628-5_7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"612f2a2f29935ae114d91f5f2ef47a3eb886dab1\",\"title\":\"Motion Boundary Trajectory for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/612f2a2f29935ae114d91f5f2ef47a3eb886dab1\",\"venue\":\"ACCV Workshops\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3211859\",\"name\":\"Biyun Sheng\"},{\"authorId\":\"46276037\",\"name\":\"Jun Yu Li\"},{\"authorId\":\"146761298\",\"name\":\"Fu Xiaoc\"},{\"authorId\":\"144326109\",\"name\":\"Q. Li\"},{\"authorId\":\"2345507\",\"name\":\"Wankou Yang\"},{\"authorId\":\"7181955\",\"name\":\"J. Han\"}],\"doi\":\"10.1109/TCSVT.2019.2918591\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"14d4bba4afc9ecb54f57d9b629bd09c04d292623\",\"title\":\"Discriminative Multi-View Subspace Feature Learning for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/14d4bba4afc9ecb54f57d9b629bd09c04d292623\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"2047692\",\"name\":\"Chenyou Fan\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"aa299218f9b7cda78c440117f12f193c3c4a86cb\",\"title\":\"Learning Latent Sub-events in Activity Videos Using Temporal Attention Filters\",\"url\":\"https://www.semanticscholar.org/paper/aa299218f9b7cda78c440117f12f193c3c4a86cb\",\"venue\":\"AAAI 2017\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3195774\",\"name\":\"Waqas Sultani\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"081a05d88f0442915c1402548fc82e48ee8133a2\",\"title\":\"Weakly Labeled Action Recognition and Detection\",\"url\":\"https://www.semanticscholar.org/paper/081a05d88f0442915c1402548fc82e48ee8133a2\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3439788\",\"name\":\"Ashwan Abdulmunem\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f96f1afd07706941e96126d25577d9e1bf1fd1bb\",\"title\":\"Human action recognition using saliency-based global and local features\",\"url\":\"https://www.semanticscholar.org/paper/f96f1afd07706941e96126d25577d9e1bf1fd1bb\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1606.05355\",\"authors\":[{\"authorId\":\"144474750\",\"name\":\"Subhabrata Bhattacharya\"},{\"authorId\":\"3362425\",\"name\":\"N. Souly\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"5265be9c7b8b22f4e06a01736bbedf171caee74e\",\"title\":\"Covariance of Motion and Appearance Featuresfor Spatio Temporal Recognition Tasks\",\"url\":\"https://www.semanticscholar.org/paper/5265be9c7b8b22f4e06a01736bbedf171caee74e\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2035597\",\"name\":\"Novanto Yudistira\"},{\"authorId\":\"145375983\",\"name\":\"Takio Kurita\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"6e297f10a02580dfc74595ff8d7db34020002ec4\",\"title\":\"Correlation Net : spatio temporal multimodal deep learning\",\"url\":\"https://www.semanticscholar.org/paper/6e297f10a02580dfc74595ff8d7db34020002ec4\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143612376\",\"name\":\"Simon Fraser\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3b2a2357b12cf0a5c99c8bc06ef7b46e40dd888e\",\"title\":\"Learning Person Trajectory Representations for Team Activity Analysis\",\"url\":\"https://www.semanticscholar.org/paper/3b2a2357b12cf0a5c99c8bc06ef7b46e40dd888e\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145458333\",\"name\":\"Adel Saleh\"},{\"authorId\":\"35257513\",\"name\":\"Miguel \\u00c1ngel Garc\\u00eda\"},{\"authorId\":\"2961376\",\"name\":\"Farhan Akram\"},{\"authorId\":\"46717559\",\"name\":\"Mohamed Abdel-Nasser\"},{\"authorId\":\"143844336\",\"name\":\"D. Puig\"}],\"doi\":\"10.5220/0005781001800185\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2f733287c85788d0d9f89cf8d4d36aa691675249\",\"title\":\"Exploiting the Kinematic of the Trajectories of the Local Descriptors to Improve Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2f733287c85788d0d9f89cf8d4d36aa691675249\",\"venue\":\"VISIGRAPP\",\"year\":2016},{\"arxivId\":\"1808.07712\",\"authors\":[{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":null,\"name\":\"Suman Saha\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":\"10.1007/978-3-030-11015-4_11\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7ffcf3435b1e7a984836bac25800481fb5140d97\",\"title\":\"Predicting Action Tubes\",\"url\":\"https://www.semanticscholar.org/paper/7ffcf3435b1e7a984836bac25800481fb5140d97\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51268431\",\"name\":\"Xinshu Qiao\"},{\"authorId\":\"9764225\",\"name\":\"Chuanwei Zhou\"},{\"authorId\":\"48258938\",\"name\":\"Chunyan Xu\"},{\"authorId\":\"144801562\",\"name\":\"Zhen Cui\"},{\"authorId\":null,\"name\":\"Jian Yang\"}],\"doi\":\"10.1109/ICIP.2018.8451548\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"53da7e4e193b334ce3891a55c61593a9fe479e19\",\"title\":\"Action Recognition with Spatial-Temporal Representation Analysis Across Grassmannian Manifold and Euclidean Space\",\"url\":\"https://www.semanticscholar.org/paper/53da7e4e193b334ce3891a55c61593a9fe479e19\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":\"1511.04808\",\"authors\":[{\"authorId\":\"1730228\",\"name\":\"M. Liu\"},{\"authorId\":\"3373117\",\"name\":\"R. Wang\"},{\"authorId\":\"145455919\",\"name\":\"S. Shan\"},{\"authorId\":\"1710220\",\"name\":\"X. Chen\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d02f04f7f94ef0f0a7eaa1a54ee1c4099dd98861\",\"title\":\"Learning Mid-level Words on Riemannian Manifold for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d02f04f7f94ef0f0a7eaa1a54ee1c4099dd98861\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403633669\",\"name\":\"Jordi Bautista-Ballester\"},{\"authorId\":\"1403633671\",\"name\":\"J. Verg\\u00e9s-Llah\\u00ed\"},{\"authorId\":\"143844336\",\"name\":\"D. Puig\"}],\"doi\":\"10.1117/12.2228527\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2c03e5daa78989c443fb54f1ba8a61b9f36fd02e\",\"title\":\"Weighting video information into a multikernel SVM for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03e5daa78989c443fb54f1ba8a61b9f36fd02e\",\"venue\":\"International Conference on Machine Vision\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47538976\",\"name\":\"Jing Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d209c2de71eba17c00902792c200992484080453\",\"title\":\"Transfer Learning for Cross-domain Visual Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d209c2de71eba17c00902792c200992484080453\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151480047\",\"name\":\"Chamath Abeysinghe\"},{\"authorId\":\"1396258325\",\"name\":\"Thejan Wijesinghe\"},{\"authorId\":\"1396258323\",\"name\":\"Chanuka Wijayakoon\"},{\"authorId\":\"1396258319\",\"name\":\"Lahiru Jayathilake\"}],\"doi\":\"10.1109/MERCon.2019.8818859\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f2a2b6db3fc686ae8780e36aa7f1c6b3c0158272\",\"title\":\"Video Colorization Dataset and Benchmark\",\"url\":\"https://www.semanticscholar.org/paper/f2a2b6db3fc686ae8780e36aa7f1c6b3c0158272\",\"venue\":\"2019 Moratuwa Engineering Research Conference (MERCon)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3193566\",\"name\":\"Yongbo Bo\"},{\"authorId\":\"19244094\",\"name\":\"Yangdi Lu\"},{\"authorId\":\"145850224\",\"name\":\"Wenbo He\"}],\"doi\":\"10.1109/WACV45572.2020.9093481\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5ced7f13f2c616f770c126eba68626a4830205de\",\"title\":\"Few-Shot Learning of Video Action Recognition Only Based on Video Contents\",\"url\":\"https://www.semanticscholar.org/paper/5ced7f13f2c616f770c126eba68626a4830205de\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30861335\",\"name\":\"Festus Osayamwen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"37434b7caa7878aacf9787f5d0f960d2dfdd3c98\",\"title\":\"Feature regularization and learning for human activity recognition.\",\"url\":\"https://www.semanticscholar.org/paper/37434b7caa7878aacf9787f5d0f960d2dfdd3c98\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32222907\",\"name\":\"Qianru Sun\"},{\"authorId\":\"33185308\",\"name\":\"Hong-Cheu Liu\"},{\"authorId\":\"1847145\",\"name\":\"Liqian Ma\"},{\"authorId\":\"51049314\",\"name\":\"Tianwei Zhang\"}],\"doi\":\"10.1016/j.neucom.2015.09.074\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"30e1b88351c30e61b961ecd4cb25185cc1f1fb26\",\"title\":\"A novel hierarchical Bag-of-Words model for compact action representation\",\"url\":\"https://www.semanticscholar.org/paper/30e1b88351c30e61b961ecd4cb25185cc1f1fb26\",\"venue\":\"Neurocomputing\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49865142\",\"name\":\"P. Zhou\"},{\"authorId\":\"31355406\",\"name\":\"Qing-hai Ding\"},{\"authorId\":\"47030228\",\"name\":\"H. Luo\"},{\"authorId\":\"30983656\",\"name\":\"X. Hou\"}],\"doi\":\"10.1088/1742-6596/844/1/012044\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8cd55e3a6c3b73ac76e5552625d3cf3ccf1d9ced\",\"title\":\"Violent Interaction Detection in Video Based on Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/8cd55e3a6c3b73ac76e5552625d3cf3ccf1d9ced\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2086802\",\"name\":\"J. Cai\"},{\"authorId\":\"2435677\",\"name\":\"Michele Merler\"},{\"authorId\":\"1767897\",\"name\":\"Sharath Pankanti\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1145/2671188.2749320\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3e0377af0087b9b836bf6d95bc1c7085dfde4897\",\"title\":\"Heterogeneous Semantic Level Features Fusion for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3e0377af0087b9b836bf6d95bc1c7085dfde4897\",\"venue\":\"ICMR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145546921\",\"name\":\"J. Qin\"},{\"authorId\":\"40241836\",\"name\":\"L. Liu\"},{\"authorId\":\"9452165\",\"name\":\"Mengyang Yu\"},{\"authorId\":\"40013375\",\"name\":\"Y. Wang\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"}],\"doi\":\"10.1016/j.cviu.2016.09.009\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"971ce497bb3bc6e5310de2c4eabce8b5a2a36478\",\"title\":\"Fast action retrieval from videos via feature disaggregation\",\"url\":\"https://www.semanticscholar.org/paper/971ce497bb3bc6e5310de2c4eabce8b5a2a36478\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":\"1701.04925\",\"authors\":[{\"authorId\":\"2256817\",\"name\":\"Fahimeh Rezazadegan\"},{\"authorId\":\"34686772\",\"name\":\"S. Shirazi\"},{\"authorId\":\"1803115\",\"name\":\"B. Upcroft\"},{\"authorId\":\"1809144\",\"name\":\"Michael Milford\"}],\"doi\":\"10.1109/ICRA.2017.7989361\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"48cad609886bec3fdcc4417343e3e1dfb117bdd2\",\"title\":\"Action recognition: From static datasets to moving robots\",\"url\":\"https://www.semanticscholar.org/paper/48cad609886bec3fdcc4417343e3e1dfb117bdd2\",\"venue\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3432961\",\"name\":\"Wukui Yang\"},{\"authorId\":\"145468103\",\"name\":\"S. Gao\"},{\"authorId\":\"38836749\",\"name\":\"Wenran Liu\"},{\"authorId\":\"7807689\",\"name\":\"Xiangyang Ji\"}],\"doi\":\"10.1109/MMSP.2018.8547088\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c4761b47c3f259559740c90bd42ed8442249499d\",\"title\":\"3-Stream Convolutional Networks for Video Action Recognition with Hybrid Motion Field\",\"url\":\"https://www.semanticscholar.org/paper/c4761b47c3f259559740c90bd42ed8442249499d\",\"venue\":\"2018 IEEE 20th International Workshop on Multimedia Signal Processing (MMSP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48094509\",\"name\":\"J. Wang\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"}],\"doi\":\"10.1007/978-3-030-01225-0_42\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"8c7a962e1076949d8395e8de6aaae026f673b184\",\"title\":\"Learning Discriminative Video Representations Using Adversarial Perturbations\",\"url\":\"https://www.semanticscholar.org/paper/8c7a962e1076949d8395e8de6aaae026f673b184\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1502.07209\",\"authors\":[{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"49606697\",\"name\":\"J. Wang\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1109/TPAMI.2017.2670560\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1a0a01c78b746f44575f0c4f297e1621eb212dde\",\"title\":\"Exploiting Feature and Class Relationships in Video Categorization with Regularized Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/1a0a01c78b746f44575f0c4f297e1621eb212dde\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40465774\",\"name\":\"Z. Gao\"},{\"authorId\":\"2028829514\",\"name\":\"Leming Guo\"},{\"authorId\":\"15880069\",\"name\":\"W. Guan\"},{\"authorId\":\"143602033\",\"name\":\"Anan Liu\"},{\"authorId\":\"1744930\",\"name\":\"T. Ren\"},{\"authorId\":\"1788427\",\"name\":\"Shengyong Chen\"}],\"doi\":\"10.1109/TIP.2020.3038372\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"6648479157216bee1f31ef9718fcb64eeafa6843\",\"title\":\"A Pairwise Attentive Adversarial Spatiotemporal Network for Cross-Domain Few-Shot Action Recognition-R2\",\"url\":\"https://www.semanticscholar.org/paper/6648479157216bee1f31ef9718fcb64eeafa6843\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"73244535\",\"name\":\"M. Rodr\\u00edguez\"},{\"authorId\":\"1398367150\",\"name\":\"C. Orrite-Uru\\u00f1uela\"},{\"authorId\":\"144426554\",\"name\":\"C. Medrano\"},{\"authorId\":\"143920053\",\"name\":\"D. Makris\"}],\"doi\":\"10.1016/j.imavis.2015.12.006\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"59eef6a94d36aa1069a85260931237e3adb05daf\",\"title\":\"A Time Flexible Kernel framework for video-based activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/59eef6a94d36aa1069a85260931237e3adb05daf\",\"venue\":\"Image Vis. Comput.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2340579\",\"name\":\"J. Ng\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/WACV.2018.00176\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c1227659878e867a01888eef472dd96b679adb6\",\"title\":\"Temporal Difference Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6c1227659878e867a01888eef472dd96b679adb6\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12100407\",\"name\":\"S. Rahman\"},{\"authorId\":\"143937986\",\"name\":\"John See\"}],\"doi\":\"10.1109/ICASSP.2016.7471996\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d8057da3dd1da37a96c70bdc98cfc6edb68ba75f\",\"title\":\"Spatio-temporal mid-level feature bank for action recognition in low quality video\",\"url\":\"https://www.semanticscholar.org/paper/d8057da3dd1da37a96c70bdc98cfc6edb68ba75f\",\"venue\":\"2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3076130\",\"name\":\"Keyang Cheng\"},{\"authorId\":\"1845915519\",\"name\":\"Eric Kasangu Lubamba\"},{\"authorId\":\"92581630\",\"name\":\"Q. Liu\"}],\"doi\":\"10.1109/ACCESS.2020.3008848\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5c7c4556126f7219886cd28e4f33c85586f24955\",\"title\":\"Action Prediction Based on Partial Video Observation via Context and Temporal Sequential Network With Deformable Convolution\",\"url\":\"https://www.semanticscholar.org/paper/5c7c4556126f7219886cd28e4f33c85586f24955\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31856162\",\"name\":\"Gulraiz Khan\"},{\"authorId\":null,\"name\":\"Muhammad Usman Ghani\"},{\"authorId\":\"51303053\",\"name\":\"Aiman Siddiqi\"},{\"authorId\":\"35390217\",\"name\":\"Zahoor-ur-Rehman\"},{\"authorId\":\"5686109\",\"name\":\"Sanghyun Seo\"},{\"authorId\":\"1777998\",\"name\":\"S. Baik\"},{\"authorId\":\"3330588\",\"name\":\"I. Mehmood\"}],\"doi\":\"10.1007/s11042-018-6286-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e59df13cde71ac301fc3fac4268267a7ba7dea3b\",\"title\":\"Egocentric visual scene description based on human-object interaction and deep spatial relations among objects\",\"url\":\"https://www.semanticscholar.org/paper/e59df13cde71ac301fc3fac4268267a7ba7dea3b\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2283107\",\"name\":\"Debaditya Roy\"},{\"authorId\":\"144987703\",\"name\":\"M. Srinivas\"},{\"authorId\":\"34358756\",\"name\":\"C. K. Mohan\"}],\"doi\":\"10.1016/j.patcog.2016.03.011\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0710ff88f9b2de9c0235787442825fb935a39a22\",\"title\":\"Sparsity-inducing dictionaries for effective action classification\",\"url\":\"https://www.semanticscholar.org/paper/0710ff88f9b2de9c0235787442825fb935a39a22\",\"venue\":\"Pattern Recognit.\",\"year\":2016},{\"arxivId\":\"2001.03905\",\"authors\":[{\"authorId\":\"2849892\",\"name\":\"Hongguang Zhang\"},{\"authorId\":\"48459110\",\"name\":\"Li Zhang\"},{\"authorId\":\"50844674\",\"name\":\"Xiaojuan Qi\"},{\"authorId\":\"40124570\",\"name\":\"Hongdong Li\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"},{\"authorId\":\"2155775\",\"name\":\"Piotr Koniusz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"96e12142f49e5c66b7e4a7fbaeeae0a7ab176484\",\"title\":\"Few-shot Action Recognition via Improved Attention with Self-supervision\",\"url\":\"https://www.semanticscholar.org/paper/96e12142f49e5c66b7e4a7fbaeeae0a7ab176484\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49120765\",\"name\":\"R. Singh\"},{\"authorId\":\"1387052806\",\"name\":\"Ankur Sonawane\"},{\"authorId\":\"33188415\",\"name\":\"R. Srivastava\"}],\"doi\":\"10.1007/s00530-019-00635-7\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"45a7a721cfe3f179c5bf86ae08340b1f38fdde48\",\"title\":\"Recent evolution of modern datasets for human activity recognition: a deep survey\",\"url\":\"https://www.semanticscholar.org/paper/45a7a721cfe3f179c5bf86ae08340b1f38fdde48\",\"venue\":\"Multimedia Systems\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.22028/D291-26562\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ab1719f573a6c121d7d7da5053fe5f12de0182e7\",\"title\":\"Combining visual recognition and computational linguistics : linguistic knowledge for visual recognition and natural language descriptions of visual content\",\"url\":\"https://www.semanticscholar.org/paper/ab1719f573a6c121d7d7da5053fe5f12de0182e7\",\"venue\":\"\",\"year\":2014},{\"arxivId\":\"2006.05675\",\"authors\":[{\"authorId\":\"2557642\",\"name\":\"HyeokHyen Kwon\"},{\"authorId\":\"49101030\",\"name\":\"C. Tong\"},{\"authorId\":\"1396120509\",\"name\":\"Harish Haresamudram\"},{\"authorId\":\"152673873\",\"name\":\"Yan Gao\"},{\"authorId\":\"9267108\",\"name\":\"Gregory D. Abowd\"},{\"authorId\":\"144948031\",\"name\":\"N. Lane\"},{\"authorId\":\"2191750\",\"name\":\"T. Pl\\u00f6tz\"}],\"doi\":\"10.1145/3411841\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"30847bf643b810a4bc536fe8ce3630704e10f971\",\"title\":\"IMUTube: Automatic extraction of virtual on-body accelerometry from video for human activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/30847bf643b810a4bc536fe8ce3630704e10f971\",\"venue\":\"Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3530540\",\"name\":\"Yunbo Wang\"},{\"authorId\":\"91060830\",\"name\":\"Zhiyu Yao\"},{\"authorId\":\"7296530\",\"name\":\"Hongyu Zhu\"},{\"authorId\":\"35776445\",\"name\":\"Mingsheng Long\"},{\"authorId\":\"1751179\",\"name\":\"J. Wang\"},{\"authorId\":\"144019071\",\"name\":\"Philip S. Yu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"10f7551bb9f6fa992660e70cb2896b8d5bdcc406\",\"title\":\"Reversing Two-Stream Networks with Decoding Discrepancy Penalty for Robust Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/10f7551bb9f6fa992660e70cb2896b8d5bdcc406\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3438978\",\"name\":\"Geoffrey Vaquette\"},{\"authorId\":\"19258632\",\"name\":\"A. Orcesi\"},{\"authorId\":\"1885717\",\"name\":\"L. Lucat\"},{\"authorId\":\"1787641\",\"name\":\"C. Achard\"}],\"doi\":\"10.1109/FG.2017.67\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"35c3dead77e705132762006e588984ef36ee3604\",\"title\":\"The DAily Home LIfe Activity Dataset: A High Semantic Activity Dataset for Online Recognition\",\"url\":\"https://www.semanticscholar.org/paper/35c3dead77e705132762006e588984ef36ee3604\",\"venue\":\"2017 12th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2017)\",\"year\":2017},{\"arxivId\":\"1804.01373\",\"authors\":[{\"authorId\":\"3179887\",\"name\":\"Xinpeng Chen\"},{\"authorId\":\"47740660\",\"name\":\"Jingyuan Chen\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"144188763\",\"name\":\"Jian Yao\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"},{\"authorId\":\"38144094\",\"name\":\"T. Zhang\"}],\"doi\":\"10.1145/3184558.3186584\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8ba45c4f82b0328dfdf5dc93dfd88e3d9ac76bad\",\"title\":\"Fine-grained Video Attractiveness Prediction Using Multimodal Deep Learning on a Large Real-world Dataset\",\"url\":\"https://www.semanticscholar.org/paper/8ba45c4f82b0328dfdf5dc93dfd88e3d9ac76bad\",\"venue\":\"WWW\",\"year\":2018},{\"arxivId\":\"2010.08164\",\"authors\":[{\"authorId\":\"47287725\",\"name\":\"Anshul B. Shah\"},{\"authorId\":\"2850880\",\"name\":\"Shlok Kumar Mishra\"},{\"authorId\":\"2068427\",\"name\":\"Ankan Bansal\"},{\"authorId\":\"1391201966\",\"name\":\"Jun-Cheng Chen\"},{\"authorId\":\"69416958\",\"name\":\"Ramalingam Chellappa\"},{\"authorId\":\"51453757\",\"name\":\"Abhinav Shrivastava\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"5ac51a6eb28656c670c36a6460be0e458b2e562f\",\"title\":\"Pose And Joint-Aware Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5ac51a6eb28656c670c36a6460be0e458b2e562f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1808.01340\",\"authors\":[{\"authorId\":\"153062108\",\"name\":\"J. Carreira\"},{\"authorId\":\"51210148\",\"name\":\"Eric Noland\"},{\"authorId\":\"1409990820\",\"name\":\"Andras Banki-Horvath\"},{\"authorId\":\"38961760\",\"name\":\"Chloe Hillier\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"62dccab9ab715f33761a5315746ed02e48eed2a0\",\"title\":\"A Short Note about Kinetics-600\",\"url\":\"https://www.semanticscholar.org/paper/62dccab9ab715f33761a5315746ed02e48eed2a0\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1908.03180\",\"authors\":[{\"authorId\":\"1399431057\",\"name\":\"Paola Cascante-Bonilla\"},{\"authorId\":\"1416539256\",\"name\":\"Kalpathy Sitaraman\"},{\"authorId\":\"31143971\",\"name\":\"Mengjia Luo\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e8dc97a4d489bab50abdef6f8c616694f9c68d9f\",\"title\":\"Moviescope: Large-scale Analysis of Movies using Multiple Modalities\",\"url\":\"https://www.semanticscholar.org/paper/e8dc97a4d489bab50abdef6f8c616694f9c68d9f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2863531\",\"name\":\"Shugao Ma\"},{\"authorId\":\"1701293\",\"name\":\"J. Zhang\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"},{\"authorId\":\"1398643531\",\"name\":\"N. Ikizler-Cinbis\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":\"10.1007/s11263-016-0980-8\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a03a2154f9aaff21c190634c888ed6d4f8d52150\",\"title\":\"Space-Time Tree Ensemble for Action Recognition and Localization\",\"url\":\"https://www.semanticscholar.org/paper/a03a2154f9aaff21c190634c888ed6d4f8d52150\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":\"2002.02651\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"},{\"authorId\":\"1739867\",\"name\":\"R. Veltkamp\"}],\"doi\":\"10.3390/app10186241\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"c30d284bcba14754bbc020c7cf2688e2f831e97e\",\"title\":\"Learning Class Regularized Features for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c30d284bcba14754bbc020c7cf2688e2f831e97e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3374519\",\"name\":\"H. Lee\"},{\"authorId\":\"144248119\",\"name\":\"Minju Jung\"},{\"authorId\":\"1780524\",\"name\":\"J. Tani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"2a468ac6399a82ccad9bbfa7133264dae9f14584\",\"title\":\"Characteristics of Visual Categorization of Long-Concatenated and Object-Directed Human Actions by a Multiple Spatio-Temporal Scales Recurrent Neural Network Model\",\"url\":\"https://www.semanticscholar.org/paper/2a468ac6399a82ccad9bbfa7133264dae9f14584\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9649314\",\"name\":\"Sheeraz Arif\"},{\"authorId\":\"1414105614\",\"name\":\"Tehseen Ul-Hassan\"},{\"authorId\":\"14858604\",\"name\":\"F. Hussain\"},{\"authorId\":\"152924726\",\"name\":\"Jing Wang\"},{\"authorId\":\"144506603\",\"name\":\"Zesong Fei\"}],\"doi\":\"10.1080/1206212X.2018.1486001\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7c7c22b79447d6c2e17162c582ba8a824ec5060e\",\"title\":\"Video representation by dense trajectories motion map applied to human activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/7c7c22b79447d6c2e17162c582ba8a824ec5060e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35654996\",\"name\":\"B. Pan\"},{\"authorId\":\"2282025\",\"name\":\"Jiankai Sun\"},{\"authorId\":\"35992009\",\"name\":\"Wuwei Lin\"},{\"authorId\":\"48170350\",\"name\":\"Limin Wang\"},{\"authorId\":\"8131625\",\"name\":\"W. Lin\"}],\"doi\":\"10.1109/CVPRW.2019.00059\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3e9285552fc3c1402a09e3d29ee09c130cf2d419\",\"title\":\"Cross-Stream Selective Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3e9285552fc3c1402a09e3d29ee09c130cf2d419\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":\"1810.00207\",\"authors\":[{\"authorId\":\"7868449\",\"name\":\"Yongyi Tang\"},{\"authorId\":\"46447561\",\"name\":\"X. Zhang\"},{\"authorId\":null,\"name\":\"Jingwen Wang\"},{\"authorId\":\"39650418\",\"name\":\"S. Chen\"},{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1007/978-3-030-11018-5_20\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"507f398b79e94a1ebde61c0a854c3954e7bb3d33\",\"title\":\"Non-local NetVLAD Encoding for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/507f398b79e94a1ebde61c0a854c3954e7bb3d33\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4464686\",\"name\":\"ZhenXing Zheng\"},{\"authorId\":\"2896701\",\"name\":\"G. An\"},{\"authorId\":\"144953181\",\"name\":\"D. Wu\"},{\"authorId\":\"144695333\",\"name\":\"Q. Ruan\"}],\"doi\":\"10.1016/J.NEUCOM.2019.05.058\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"67d3ec7b1070405575974e449cfdc495b43f7b21\",\"title\":\"Spatial-temporal pyramid based Convolutional Neural Network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/67d3ec7b1070405575974e449cfdc495b43f7b21\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1773194\",\"name\":\"Fei Pan\"},{\"authorId\":\"1720424\",\"name\":\"Y. Guo\"},{\"authorId\":\"151485208\",\"name\":\"Z. Yan\"},{\"authorId\":\"50115448\",\"name\":\"Jie Guo\"}],\"doi\":\"10.1109/ICME.2019.00283\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"85427b81ea2d3b0aea44fe82f6520507e7241c2f\",\"title\":\"Temporal Segment Convolutional Kernel Networks for Sequence Modeling of Videos\",\"url\":\"https://www.semanticscholar.org/paper/85427b81ea2d3b0aea44fe82f6520507e7241c2f\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48354916\",\"name\":\"Ze Chen\"},{\"authorId\":\"37514286\",\"name\":\"H. Lu\"}],\"doi\":\"10.1145/3297097.3297107\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"f9fff8a34942053fd93760c8c84a40849b9db734\",\"title\":\"Recurrent Spatiotemporal Feature Learning for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f9fff8a34942053fd93760c8c84a40849b9db734\",\"venue\":\"ICRAI 2018\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2934295\",\"name\":\"R. Luca\"},{\"authorId\":\"2337557\",\"name\":\"S. Bejinariu\"},{\"authorId\":\"2244684\",\"name\":\"F. Rotaru\"}],\"doi\":\"10.1109/EHB47216.2019.8969975\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"600e4da74c59dfb8acd46bc361fbbd83b77f2ba6\",\"title\":\"Tree-Based Classifiers on Human Locomotion Statistical Parameters\",\"url\":\"https://www.semanticscholar.org/paper/600e4da74c59dfb8acd46bc361fbbd83b77f2ba6\",\"venue\":\"2019 E-Health and Bioengineering Conference (EHB)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4464686\",\"name\":\"ZhenXing Zheng\"},{\"authorId\":\"2896701\",\"name\":\"G. An\"},{\"authorId\":\"144695333\",\"name\":\"Q. Ruan\"}],\"doi\":\"10.1109/ICSP.2018.8652359\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"494f3f390442c622fd47d3c75316c3f9737bfa97\",\"title\":\"Temporal Pyramid Pooling Based Relation Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/494f3f390442c622fd47d3c75316c3f9737bfa97\",\"venue\":\"2018 14th IEEE International Conference on Signal Processing (ICSP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47286885\",\"name\":\"Jingyi Hou\"},{\"authorId\":\"2125709\",\"name\":\"Xinxiao Wu\"},{\"authorId\":\"51036717\",\"name\":\"J. Chen\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"},{\"authorId\":\"7415267\",\"name\":\"Y. Jia\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f72405e74c3c4f962c4821bf5f34b9106009801c\",\"title\":\"Unsupervised Deep Learning of Mid-Level Video Representation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f72405e74c3c4f962c4821bf5f34b9106009801c\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34798935\",\"name\":\"Xiantong Zhen\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"}],\"doi\":\"10.1016/j.patrec.2012.10.021\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"88a7ad0138bff6201266d7b3455a0b8c69612897\",\"title\":\"A local descriptor based on Laplacian pyramid coding for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/88a7ad0138bff6201266d7b3455a0b8c69612897\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152506137\",\"name\":\"F. Zhu\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"}],\"doi\":\"10.5244/C.27.52\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"be9bf0307468813a478e3655a927c013fa520952\",\"title\":\"Enhancing Action Recognition by Cross-Domain Dictionary Learning\",\"url\":\"https://www.semanticscholar.org/paper/be9bf0307468813a478e3655a927c013fa520952\",\"venue\":\"BMVC\",\"year\":2013},{\"arxivId\":\"1711.09550\",\"authors\":[{\"authorId\":\"144858226\",\"name\":\"Xiang Long\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144608002\",\"name\":\"Gerard de Melo\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"48033101\",\"name\":\"Xiao Liu\"},{\"authorId\":\"35247507\",\"name\":\"Shilei Wen\"}],\"doi\":\"10.1109/CVPR.2018.00817\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"5406fd98aa22bc2a0c1a8bc2a58ca3eb7a91155d\",\"title\":\"Attention Clusters: Purely Attention Based Local Feature Integration for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/5406fd98aa22bc2a0c1a8bc2a58ca3eb7a91155d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40404576\",\"name\":\"S. Amin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b4e8abb2a5220732002e1086fb4a214122213fea\",\"title\":\"Multi-view Part-based Models for 3D Human Pose Estimation in Real-World Scenes\",\"url\":\"https://www.semanticscholar.org/paper/b4e8abb2a5220732002e1086fb4a214122213fea\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"51043468\",\"name\":\"Maksim Bolonkin\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7ba0bf9323c2d79300f1a433ff8b4fe0a00ad889\",\"title\":\"VideoMCC: a New Benchmark for Video Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/7ba0bf9323c2d79300f1a433ff8b4fe0a00ad889\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5808321\",\"name\":\"Meng-Chieh Wu\"},{\"authorId\":\"145888908\",\"name\":\"Ching-Te Chiu\"}],\"doi\":\"10.1016/j.sysarc.2019.101695\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"25da842e3efcdd96b98e1276a59e6073d9c0b970\",\"title\":\"Multi-teacher knowledge distillation for compressed video action recognition based on deep learning\",\"url\":\"https://www.semanticscholar.org/paper/25da842e3efcdd96b98e1276a59e6073d9c0b970\",\"venue\":\"J. Syst. Archit.\",\"year\":2020},{\"arxivId\":\"1905.04430\",\"authors\":[{\"authorId\":\"119352476\",\"name\":\"M. M. K. Moghaddam\"},{\"authorId\":\"8088602\",\"name\":\"Ehsan Abbasnejad\"},{\"authorId\":\"31635758\",\"name\":\"Javen Shi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c6e889406f3f85dcb33e90eba2a6dfffbb3c51a1\",\"title\":\"Follow the Attention: Combining Partial Pose and Object Motion for Fine-Grained Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/c6e889406f3f85dcb33e90eba2a6dfffbb3c51a1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1909.04656\",\"authors\":[{\"authorId\":\"22237490\",\"name\":\"Tengda Han\"},{\"authorId\":\"10096695\",\"name\":\"Weidi Xie\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/ICCVW.2019.00186\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0174d263d3a77bf03fce831a9a5ce2678e1959f0\",\"title\":\"Video Representation Learning by Dense Predictive Coding\",\"url\":\"https://www.semanticscholar.org/paper/0174d263d3a77bf03fce831a9a5ce2678e1959f0\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46930271\",\"name\":\"Junyu Gao\"},{\"authorId\":\"48258806\",\"name\":\"C. Xu\"}],\"doi\":\"10.1109/TMM.2020.2969787\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9548b20d7347ae098e03a73eef98f42d0db3775b\",\"title\":\"CI-GNN: Building a Category-Instance Graph for Zero-Shot Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/9548b20d7347ae098e03a73eef98f42d0db3775b\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"2010.11757\",\"authors\":[{\"authorId\":\"48239920\",\"name\":\"Chun-Fu Chen\"},{\"authorId\":\"1819152\",\"name\":\"R. Panda\"},{\"authorId\":\"40544169\",\"name\":\"K. Ramakrishnan\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"38060482\",\"name\":\"J. M. Cohn\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"33421444\",\"name\":\"Quanfu Fan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f5c2623a44660ad9fe6cd46710fec6e812a3375a\",\"title\":\"Deep Analysis of CNN-based Spatio-temporal Representations for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f5c2623a44660ad9fe6cd46710fec6e812a3375a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2001.06232\",\"authors\":[{\"authorId\":\"1471708751\",\"name\":\"M. Malinowski\"},{\"authorId\":\"1782475\",\"name\":\"G. Swirszcz\"},{\"authorId\":\"153062108\",\"name\":\"J. Carreira\"},{\"authorId\":\"1756112\",\"name\":\"Viorica Patraucean\"}],\"doi\":\"10.1109/cvpr42600.2020.01185\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"21f96afef802b3e00edd9bb8c4b71fc3f0cc43df\",\"title\":\"Sideways: Depth-Parallel Training of Video Models\",\"url\":\"https://www.semanticscholar.org/paper/21f96afef802b3e00edd9bb8c4b71fc3f0cc43df\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2003.13594\",\"authors\":[{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"1491624845\",\"name\":\"Chen Sun\"},{\"authorId\":\"152567560\",\"name\":\"D. Ross\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/cvpr42600.2020.01033\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ee3ba7ebf3a0116d17857c53fe10d98ae3a586d9\",\"title\":\"Speech2Action: Cross-Modal Supervision for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ee3ba7ebf3a0116d17857c53fe10d98ae3a586d9\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"143740449\",\"name\":\"Q. Peng\"},{\"authorId\":\"2689287\",\"name\":\"X. Qi\"}],\"doi\":\"10.5244/C.27.59\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"591de9e7dc0e0610290c704977437c1dc8df2c3a\",\"title\":\"Exploring Motion Boundary based Sampling and Spatial-Temporal Context Descriptors for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/591de9e7dc0e0610290c704977437c1dc8df2c3a\",\"venue\":\"BMVC\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"2985266\",\"name\":\"Zhuowei Cai\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1007/978-3-319-16178-5_36\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"896f4d87257abd0f628c1ffbbfdac38c86a56f50\",\"title\":\"Action and Gesture Temporal Spotting with Super Vector Representation\",\"url\":\"https://www.semanticscholar.org/paper/896f4d87257abd0f628c1ffbbfdac38c86a56f50\",\"venue\":\"ECCV Workshops\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993663564\",\"name\":\"Mingyao Hong\"},{\"authorId\":\"46439250\",\"name\":\"Guorong Li\"},{\"authorId\":\"3175853\",\"name\":\"Xinfeng Zhang\"},{\"authorId\":\"153159021\",\"name\":\"Qingming Huang\"}],\"doi\":\"10.1145/3394171.3413517\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2009d525afc02cdc60270669ec760d222ef5bd32\",\"title\":\"Generalized Zero-Shot Video Classification via Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/2009d525afc02cdc60270669ec760d222ef5bd32\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1711.07430\",\"authors\":[{\"authorId\":\"8131625\",\"name\":\"W. Lin\"},{\"authorId\":\"145071344\",\"name\":\"Yang Mi\"},{\"authorId\":\"49388002\",\"name\":\"J. Wu\"},{\"authorId\":\"144392311\",\"name\":\"Ke Lu\"},{\"authorId\":\"144045763\",\"name\":\"Hongkai Xiong\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4f22d424292594c164a5f72846ac2cbfe94cd69f\",\"title\":\"Action Recognition with Coarse-to-Fine Deep Feature Integration and Asynchronous Fusion\",\"url\":\"https://www.semanticscholar.org/paper/4f22d424292594c164a5f72846ac2cbfe94cd69f\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3050512\",\"name\":\"Eman Mohammadi\"},{\"authorId\":\"145742710\",\"name\":\"Q. Wu\"},{\"authorId\":\"2864059\",\"name\":\"Y. Yang\"},{\"authorId\":\"145278886\",\"name\":\"M. Saif\"}],\"doi\":\"10.1109/ICIP.2017.8296589\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4f24e2afe83cb21201a2bd4c061b4a9d7d0692fc\",\"title\":\"Effect of wavelet and hybrid classification on action recognition\",\"url\":\"https://www.semanticscholar.org/paper/4f24e2afe83cb21201a2bd4c061b4a9d7d0692fc\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3458261\",\"name\":\"Quanle Liu\"},{\"authorId\":\"1961065\",\"name\":\"Xiangjiu Che\"},{\"authorId\":\"3079649\",\"name\":\"Mei Bie\"}],\"doi\":\"10.1109/ACCESS.2019.2923651\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"c93fea9dba471ad0b42ba7b217cbe5ee1bc74a26\",\"title\":\"R-STAN: Residual Spatial-Temporal Attention Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c93fea9dba471ad0b42ba7b217cbe5ee1bc74a26\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49102847\",\"name\":\"Feifei Chen\"},{\"authorId\":\"1707161\",\"name\":\"N. Sang\"},{\"authorId\":\"40115662\",\"name\":\"Changxin Gao\"},{\"authorId\":\"2445342\",\"name\":\"Xiaoqin Kuang\"}],\"doi\":\"10.1109/ICIP.2014.7025304\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3f251cead9541da058988c9aa591cdaebe5415f8\",\"title\":\"Discovering distinctive action parts for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/3f251cead9541da058988c9aa591cdaebe5415f8\",\"venue\":\"2014 IEEE International Conference on Image Processing (ICIP)\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"- ING\"},{\"authorId\":\"69354043\",\"name\":\"Ang\"},{\"authorId\":null,\"name\":\"- IDA\"},{\"authorId\":\"102770090\",\"name\":\"Ussain\"},{\"authorId\":null,\"name\":\"- ESONG\"},{\"authorId\":\"115925168\",\"name\":\"Ei\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fab04dfcb35a29a46504d2ad3acbc642c602c7e8\",\"title\":\"Trajectory-based 3D Convolutional Descriptors for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/fab04dfcb35a29a46504d2ad3acbc642c602c7e8\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50986865\",\"name\":\"Andrei Liviu Nicolicioiu\"},{\"authorId\":\"51011850\",\"name\":\"Iulia Duta\"},{\"authorId\":\"1749627\",\"name\":\"Marius Leordeanu\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"69309c61e336a32df3569248765e06abd2f35077\",\"title\":\"Recurrent Space-time Graphs for Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/69309c61e336a32df3569248765e06abd2f35077\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49528654\",\"name\":\"Huiling Wang\"},{\"authorId\":\"2785022\",\"name\":\"T. Raiko\"},{\"authorId\":\"1688468\",\"name\":\"L. Lensu\"},{\"authorId\":\"46958572\",\"name\":\"T. Wang\"},{\"authorId\":\"1703769\",\"name\":\"J. Karhunen\"}],\"doi\":\"10.1007/978-3-030-20893-6\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8f0c1d7dd99ea904da834204da1fc7ce94314d49\",\"title\":\"Computer Vision \\u2013 ACCV 2018\",\"url\":\"https://www.semanticscholar.org/paper/8f0c1d7dd99ea904da834204da1fc7ce94314d49\",\"venue\":\"Lecture Notes in Computer Science\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33998511\",\"name\":\"Aaron Chadha\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"02bd4c1b8adcd3478441f83972dceb2757ef409e\",\"title\":\"From pixels to spikes : efficient multimodal learning in the presence of domain shift\",\"url\":\"https://www.semanticscholar.org/paper/02bd4c1b8adcd3478441f83972dceb2757ef409e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9649314\",\"name\":\"Sheeraz Arif\"},{\"authorId\":\"122309007\",\"name\":\"Wangjing Wangjing\"}],\"doi\":\"10.1109/icvrv.2017.00111\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"704bc08b1d808e5c187f51fb5127edaa244006ba\",\"title\":\"3-Dimensional Convolution Based Iterative Model for Efficient Motion Map Generation for Representing Video Discriminative Information\",\"url\":\"https://www.semanticscholar.org/paper/704bc08b1d808e5c187f51fb5127edaa244006ba\",\"venue\":\"2017 International Conference on Virtual Reality and Visualization (ICVRV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145254044\",\"name\":\"Jun Zhu\"},{\"authorId\":\"2450889\",\"name\":\"B. Wang\"},{\"authorId\":\"1795291\",\"name\":\"X. Yang\"},{\"authorId\":\"31064779\",\"name\":\"W. Zhang\"},{\"authorId\":\"144035504\",\"name\":\"Zhuowen Tu\"}],\"doi\":\"10.1109/ICCV.2013.442\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"21e8f3344170a8f133b69308c178518df8a27274\",\"title\":\"Action Recognition with Actons\",\"url\":\"https://www.semanticscholar.org/paper/21e8f3344170a8f133b69308c178518df8a27274\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2439487\",\"name\":\"Y. Wang\"},{\"authorId\":\"2450889\",\"name\":\"B. Wang\"},{\"authorId\":\"1841911\",\"name\":\"Y. Yu\"},{\"authorId\":\"144954808\",\"name\":\"Q. Dai\"},{\"authorId\":\"144035504\",\"name\":\"Zhuowen Tu\"}],\"doi\":\"10.1007/978-3-319-16814-2_17\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3ae50c46aa8c7db077cfea8d4947e40081deeac2\",\"title\":\"Action-Gons: Action Recognition with a Discriminative Dictionary of Structured Elements with Varying Granularity\",\"url\":\"https://www.semanticscholar.org/paper/3ae50c46aa8c7db077cfea8d4947e40081deeac2\",\"venue\":\"ACCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3330305\",\"name\":\"Z. Qin\"},{\"authorId\":\"144222395\",\"name\":\"K. Ren\"},{\"authorId\":\"144478228\",\"name\":\"T. Yu\"},{\"authorId\":\"145369053\",\"name\":\"J. Weng\"}],\"doi\":\"10.1109/TMM.2016.2535729\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"56df929ee3a2bec1c45d8ab22cc4be9fb817ae7e\",\"title\":\"DPcode: Privacy-Preserving Frequent Visual Patterns Publication on Cloud\",\"url\":\"https://www.semanticscholar.org/paper/56df929ee3a2bec1c45d8ab22cc4be9fb817ae7e\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2016},{\"arxivId\":\"1909.10236\",\"authors\":[{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"1591131960\",\"name\":\"Yiheng Zhang\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0194898fea5464fe016d0ca202458a26485bf932\",\"title\":\"Scheduled Differentiable Architecture Search for Visual Recognition\",\"url\":\"https://www.semanticscholar.org/paper/0194898fea5464fe016d0ca202458a26485bf932\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32486555\",\"name\":\"D. Epstein\"},{\"authorId\":\"8786274\",\"name\":\"Boyuan Chen\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cc6b00a4f43370644f410330ed6d065f7fa38d5b\",\"title\":\"ops Predicting Unintentional Action in Video\",\"url\":\"https://www.semanticscholar.org/paper/cc6b00a4f43370644f410330ed6d065f7fa38d5b\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"94173091\",\"name\":\"Y. Wan\"},{\"authorId\":\"7822579\",\"name\":\"Zujun Yu\"},{\"authorId\":null,\"name\":\"Yao Wang\"},{\"authorId\":\"50079335\",\"name\":\"Xingxin Li\"}],\"doi\":\"10.1109/ACCESS.2020.2993227\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ba85b9d5f7f31690e9981a04916ef5baccf71e73\",\"title\":\"Action Recognition Based on Two-Stream Convolutional Networks With Long-Short-Term Spatiotemporal Features\",\"url\":\"https://www.semanticscholar.org/paper/ba85b9d5f7f31690e9981a04916ef5baccf71e73\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1405.7545\",\"authors\":[{\"authorId\":\"145466505\",\"name\":\"M. Sapienza\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3e3f305dac4fbb813e60ac778d6929012b4b745a\",\"title\":\"Feature sampling and partitioning for visual vocabulary generation on large action classification datasets\",\"url\":\"https://www.semanticscholar.org/paper/3e3f305dac4fbb813e60ac778d6929012b4b745a\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40241836\",\"name\":\"L. Liu\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"},{\"authorId\":\"144767226\",\"name\":\"P. Rockett\"}],\"doi\":\"10.1016/j.patcog.2012.10.004\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"926b99cbea04fb213c9984b10acf2235a3949ebb\",\"title\":\"Boosted key-frame selection and correlated pyramidal motion-feature representation for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/926b99cbea04fb213c9984b10acf2235a3949ebb\",\"venue\":\"Pattern Recognit.\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40349048\",\"name\":\"Y. Wang\"},{\"authorId\":\"1718829\",\"name\":\"J. Kato\"}],\"doi\":\"10.1109/ICIP.2015.7350903\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f7ec8168b1987f84ead200900a378ca57a6612eb\",\"title\":\"Action recognition with approximate sparse coding\",\"url\":\"https://www.semanticscholar.org/paper/f7ec8168b1987f84ead200900a378ca57a6612eb\",\"venue\":\"2015 IEEE International Conference on Image Processing (ICIP)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47608957\",\"name\":\"F. A. Rahman\"},{\"authorId\":\"66412577\",\"name\":\"A. Hussain\"},{\"authorId\":\"35562357\",\"name\":\"W. M. W. Zaki\"},{\"authorId\":\"2105877\",\"name\":\"H. Zaman\"},{\"authorId\":\"34334962\",\"name\":\"N. Tahir\"}],\"doi\":\"10.1155/2013/598708\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f71af3f98672caa005814b1a21e50657a200bab6\",\"title\":\"Enhancement of Background Subtraction Techniques Using a Second Derivative in Gradient Direction Filter\",\"url\":\"https://www.semanticscholar.org/paper/f71af3f98672caa005814b1a21e50657a200bab6\",\"venue\":\"J. Electr. Comput. Eng.\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39599054\",\"name\":\"B. Sengupta\"},{\"authorId\":\"72399895\",\"name\":\"Yu Qian\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"368ce0bb4d4e8e11001857c367d51658fcb225a2\",\"title\":\"Multi-kernel learning of deep convolutional features for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/368ce0bb4d4e8e11001857c367d51658fcb225a2\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1804.05879\",\"authors\":[{\"authorId\":\"24337238\",\"name\":\"E. Hofesmann\"},{\"authorId\":\"144487556\",\"name\":\"Madan Ravi Ganesh\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"548f656802735674c269da389afe662d73af661a\",\"title\":\"M-PACT: An Open Source Platform for Repeatable Activity Classification Research\",\"url\":\"https://www.semanticscholar.org/paper/548f656802735674c269da389afe662d73af661a\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1705.00053\",\"authors\":[{\"authorId\":\"143928130\",\"name\":\"J. Walker\"},{\"authorId\":\"35789996\",\"name\":\"Kenneth Marino\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1109/ICCV.2017.361\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3df8cc0384814c3fb05c44e494ced947a7d43f36\",\"title\":\"The Pose Knows: Video Forecasting by Generating Pose Futures\",\"url\":\"https://www.semanticscholar.org/paper/3df8cc0384814c3fb05c44e494ced947a7d43f36\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1808.09892\",\"authors\":[{\"authorId\":\"1756362\",\"name\":\"Swathikiran Sudhakaran\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"}],\"doi\":\"10.1007/978-3-030-03840-3_28\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b1d2001e877bb36c8ccc97bee62d9824a3b8874d\",\"title\":\"Top-down Attention Recurrent VLAD Encoding for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/b1d2001e877bb36c8ccc97bee62d9824a3b8874d\",\"venue\":\"AI*IA\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2374364\",\"name\":\"Yusuke Mukuta\"},{\"authorId\":\"3250559\",\"name\":\"Y. Ushiku\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.1109/ICCVW.2017.127\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6d31e9a28e85c63f1744f01a2d88364551e0a988\",\"title\":\"Spatial-Temporal Weighted Pyramid Using Spatial Orthogonal Pooling\",\"url\":\"https://www.semanticscholar.org/paper/6d31e9a28e85c63f1744f01a2d88364551e0a988\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"},{\"authorId\":\"1904850\",\"name\":\"B. Rothrock\"},{\"authorId\":\"47517530\",\"name\":\"C. Fleming\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2deed841cfde51ce3b4e90880894efbbfdc18f18\",\"title\":\"Privacy-Preserving Egocentric Activity Recognition from Extreme Low Resolution\",\"url\":\"https://www.semanticscholar.org/paper/2deed841cfde51ce3b4e90880894efbbfdc18f18\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1607.06416\",\"authors\":[{\"authorId\":null,\"name\":\"Yilin Wang\"},{\"authorId\":\"2893721\",\"name\":\"Suhang Wang\"},{\"authorId\":\"1736632\",\"name\":\"Jiliang Tang\"},{\"authorId\":\"1401255262\",\"name\":\"N. O'Hare\"},{\"authorId\":\"120586587\",\"name\":\"Y. Chang\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9f499948121abb47b31ca904030243e924585d5f\",\"title\":\"Hierarchical Attention Network for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/9f499948121abb47b31ca904030243e924585d5f\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1609.08675\",\"authors\":[{\"authorId\":\"1389570466\",\"name\":\"Sami Abu-El-Haija\"},{\"authorId\":\"144317839\",\"name\":\"Nisarg Kothari\"},{\"authorId\":\"2119006\",\"name\":\"Joonseok Lee\"},{\"authorId\":\"1820908\",\"name\":\"A. Natsev\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"2758088\",\"name\":\"B. Varadarajan\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c9a1e8e1ba2913ef0bdf1c5eaaa1ac0a79be3716\",\"title\":\"YouTube-8M: A Large-Scale Video Classification Benchmark\",\"url\":\"https://www.semanticscholar.org/paper/c9a1e8e1ba2913ef0bdf1c5eaaa1ac0a79be3716\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49551061\",\"name\":\"Shubham Singh\"},{\"authorId\":\"40339392\",\"name\":\"R. Kaushal\"},{\"authorId\":\"3170352\",\"name\":\"A. Buduru\"},{\"authorId\":\"1734731\",\"name\":\"P. Kumaraguru\"}],\"doi\":\"10.1145/3297280.3297487\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6a9bfb8ea06d011900d7facc93ee77e5733b8870\",\"title\":\"KidsGUARD: fine grained approach for child unsafe video representation and detection\",\"url\":\"https://www.semanticscholar.org/paper/6a9bfb8ea06d011900d7facc93ee77e5733b8870\",\"venue\":\"SAC\",\"year\":2019},{\"arxivId\":\"1608.07876\",\"authors\":[{\"authorId\":null,\"name\":\"Yun He\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"}],\"doi\":\"10.1007/978-3-319-49409-8_2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"04e96c69176030cf8d7c82d86c345b7f4bcf6a24\",\"title\":\"Human Action Recognition Without Human\",\"url\":\"https://www.semanticscholar.org/paper/04e96c69176030cf8d7c82d86c345b7f4bcf6a24\",\"venue\":\"ECCV Workshops\",\"year\":2016},{\"arxivId\":\"2007.06149\",\"authors\":[{\"authorId\":\"2283619\",\"name\":\"Peisen Zhao\"},{\"authorId\":\"3041937\",\"name\":\"Lingxi Xie\"},{\"authorId\":\"49890039\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/tmm.2020.3025665\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6c1fc76cc67ad82df1f7695b4d9e0b7536a70732\",\"title\":\"Universal-to-Specific Framework for Complex Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6c1fc76cc67ad82df1f7695b4d9e0b7536a70732\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.00843\",\"authors\":[{\"authorId\":\"47061966\",\"name\":\"M. Potter\"},{\"authorId\":\"1785364061\",\"name\":\"Henry Gridley\"},{\"authorId\":\"1785339126\",\"name\":\"Noah Lichtenstein\"},{\"authorId\":\"47128606\",\"name\":\"Kevin Hines\"},{\"authorId\":\"50004462\",\"name\":\"John Nguyen\"},{\"authorId\":\"151494580\",\"name\":\"Jacob Walsh\"}],\"doi\":\"10.1109/MLSP49062.2020.9231894\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"216e819a500c2d5ba2dfc993ddf4c161d72d34bb\",\"title\":\"Low-Light Environment Neural Surveillance\",\"url\":\"https://www.semanticscholar.org/paper/216e819a500c2d5ba2dfc993ddf4c161d72d34bb\",\"venue\":\"2020 IEEE 30th International Workshop on Machine Learning for Signal Processing (MLSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"18080084\",\"name\":\"Qingya Huang\"},{\"authorId\":\"145107805\",\"name\":\"S. Sun\"},{\"authorId\":\"47939010\",\"name\":\"Feng Wang\"}],\"doi\":\"10.1109/ICASSP.2017.7952460\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"67ba3524e135c1375c74fe53ebb03684754aae56\",\"title\":\"A compact pairwise trajectory representation for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/67ba3524e135c1375c74fe53ebb03684754aae56\",\"venue\":\"2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2017},{\"arxivId\":\"1711.11152\",\"authors\":[{\"authorId\":\"47392986\",\"name\":\"S. Sun\"},{\"authorId\":\"1874900\",\"name\":\"Zhanghui Kuang\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"84200540\",\"name\":\"Lu Sheng\"},{\"authorId\":\"1726357\",\"name\":\"Wayne Zhang\"}],\"doi\":\"10.1109/CVPR.2018.00151\",\"intent\":[\"methodology\",\"result\"],\"isInfluential\":false,\"paperId\":\"42517e072406ea6f8d2c579d98ee3f9918a8a1d3\",\"title\":\"Optical Flow Guided Feature: A Fast and Robust Motion Representation for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/42517e072406ea6f8d2c579d98ee3f9918a8a1d3\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1806.08251\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8f27df2d4fb7dd7ed5587640dcbe4dc1eb37acfb\",\"title\":\"Unseen Action Recognition with Multimodal Learning\",\"url\":\"https://www.semanticscholar.org/paper/8f27df2d4fb7dd7ed5587640dcbe4dc1eb37acfb\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121209369\",\"name\":\"J. Cai\"},{\"authorId\":\"50779096\",\"name\":\"J. Hu\"}],\"doi\":\"10.1007/s00371-019-01733-3\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"324054c22c974b24bff452cd0144df07665fa00e\",\"title\":\"3D RANs: 3D Residual Attention Networks for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/324054c22c974b24bff452cd0144df07665fa00e\",\"venue\":\"The Visual Computer\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2199251\",\"name\":\"K. Hara\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"}],\"doi\":\"10.1109/ICPR.2018.8546325\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d45f7abeca184533ee0f0670c4946bcd34edda81\",\"title\":\"Towards Good Practice for Action Recognition with Spatiotemporal 3D Convolutions\",\"url\":\"https://www.semanticscholar.org/paper/d45f7abeca184533ee0f0670c4946bcd34edda81\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51263546\",\"name\":\"Ujjal Kr Dutta\"},{\"authorId\":\"1685874\",\"name\":\"C. Sekhar\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053418\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a1f7190f49f0fff4139b65bf382b73e8fdf2e88d\",\"title\":\"A Geometric Approach for Unsupervised Similarity Learning\",\"url\":\"https://www.semanticscholar.org/paper/a1f7190f49f0fff4139b65bf382b73e8fdf2e88d\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"1805.06374\",\"authors\":[{\"authorId\":\"8133623\",\"name\":\"Wanjia Liu\"},{\"authorId\":\"31385532\",\"name\":\"Huaijin Chen\"},{\"authorId\":\"46186660\",\"name\":\"R. Goel\"},{\"authorId\":\"35633657\",\"name\":\"Yuzhong Huang\"},{\"authorId\":\"145280967\",\"name\":\"A. Veeraraghavan\"},{\"authorId\":\"46463998\",\"name\":\"Ankit B. Patel\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a0c37f07710184597befaa7e6cf2f0893ff440e9\",\"title\":\"Fast Retinomorphic Event Stream for Video Recognition and Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/a0c37f07710184597befaa7e6cf2f0893ff440e9\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2008.08452\",\"authors\":[{\"authorId\":\"50841913\",\"name\":\"Asif Shahriyar Sushmit\"},{\"authorId\":\"10458138\",\"name\":\"P. Ghosh\"},{\"authorId\":\"1885311407\",\"name\":\"Md.Abrar Istiak\"},{\"authorId\":\"1742267771\",\"name\":\"Nayeeb Rashid\"},{\"authorId\":\"1742267920\",\"name\":\"Ahsan Habib Akash\"},{\"authorId\":\"144782474\",\"name\":\"T. Hasan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d4953e2a564f68bc7eccd8d1af12da3c2c5bbf7c\",\"title\":\"SegCodeNet: Color-Coded Segmentation Masks for Activity Detection from Wearable Cameras\",\"url\":\"https://www.semanticscholar.org/paper/d4953e2a564f68bc7eccd8d1af12da3c2c5bbf7c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1811.09795\",\"authors\":[{\"authorId\":\"24028009\",\"name\":\"Dahun Kim\"},{\"authorId\":\"3160154\",\"name\":\"Donghyeon Cho\"},{\"authorId\":\"2398271\",\"name\":\"In-So Kweon\"}],\"doi\":\"10.1609/aaai.v33i01.33018545\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b3dbd24407f6e58f6b7bc461fd21782062f0f361\",\"title\":\"Self-Supervised Video Representation Learning with Space-Time Cubic Puzzles\",\"url\":\"https://www.semanticscholar.org/paper/b3dbd24407f6e58f6b7bc461fd21782062f0f361\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9173291\",\"name\":\"L. Wang\"},{\"authorId\":\"14800230\",\"name\":\"J. Zang\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"1786361\",\"name\":\"Zhenxing Niu\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"}],\"doi\":\"10.3390/s18071979\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2588acc7a730d864f84d4e1a050070ff873b03d5\",\"title\":\"Action Recognition by an Attention-Aware Temporal Weighted Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/2588acc7a730d864f84d4e1a050070ff873b03d5\",\"venue\":\"Sensors\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145783730\",\"name\":\"X. Xiao\"},{\"authorId\":\"144742694\",\"name\":\"D. Xu\"},{\"authorId\":\"145524181\",\"name\":\"W. Wan\"}],\"doi\":\"10.1109/ICALIP.2016.7846652\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"861a51e66553979535df2b41971150453ab26372\",\"title\":\"Overview: Video recognition from handcrafted method to deep learning method\",\"url\":\"https://www.semanticscholar.org/paper/861a51e66553979535df2b41971150453ab26372\",\"venue\":\"2016 International Conference on Audio, Language and Image Processing (ICALIP)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40590308\",\"name\":\"Chen Chen\"},{\"authorId\":\"50382172\",\"name\":\"Ray Surette\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":\"10.1057/s41284-020-00230-w\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"50a723e3a8904b0c858169def416365b99e9f2b7\",\"title\":\"Automated monitoring for security camera networks: promise from computer vision labs\",\"url\":\"https://www.semanticscholar.org/paper/50a723e3a8904b0c858169def416365b99e9f2b7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1612.00738\",\"authors\":[{\"authorId\":\"2518212\",\"name\":\"Hakan Bilen\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":\"10.1109/TPAMI.2017.2769085\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"2fe8c43aa9427582906c684afadebbc6a86fa036\",\"title\":\"Action Recognition with Dynamic Image Networks\",\"url\":\"https://www.semanticscholar.org/paper/2fe8c43aa9427582906c684afadebbc6a86fa036\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":\"2008.10534\",\"authors\":[{\"authorId\":\"2715566\",\"name\":\"K. Lai\"},{\"authorId\":\"1728290\",\"name\":\"S. Yanushkevich\"}],\"doi\":\"10.1109/SMC42975.2020.9283273\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d11d845f92cdbe63eb96a1d648e85abaa8a3f5d2\",\"title\":\"Decision Support for Video-based Detection of Flu Symptoms\",\"url\":\"https://www.semanticscholar.org/paper/d11d845f92cdbe63eb96a1d648e85abaa8a3f5d2\",\"venue\":\"2020 IEEE International Conference on Systems, Man, and Cybernetics (SMC)\",\"year\":2020},{\"arxivId\":\"1808.07507\",\"authors\":[{\"authorId\":\"2308598\",\"name\":\"U. Ahsan\"},{\"authorId\":\"37714701\",\"name\":\"R. Madhok\"},{\"authorId\":\"21472040\",\"name\":\"Irfan Essa\"}],\"doi\":\"10.1109/WACV.2019.00025\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ecbfdcbc09146c87fca594b9dcdf55f9c3504ce3\",\"title\":\"Video Jigsaw: Unsupervised Learning of Spatiotemporal Context for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ecbfdcbc09146c87fca594b9dcdf55f9c3504ce3\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":\"1901.00484\",\"authors\":[{\"authorId\":\"29132542\",\"name\":\"Meera Hahn\"},{\"authorId\":\"49915485\",\"name\":\"Andrew Silva\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"797243368d6ccde3b70bab9e1265f4e1d4e1cc43\",\"title\":\"Action2Vec: A Crossmodal Embedding Approach to Action Learning\",\"url\":\"https://www.semanticscholar.org/paper/797243368d6ccde3b70bab9e1265f4e1d4e1cc43\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49681148\",\"name\":\"L. Wang\"},{\"authorId\":\"3034546\",\"name\":\"Lianzheng Ge\"},{\"authorId\":\"39975036\",\"name\":\"R. Li\"},{\"authorId\":\"40630660\",\"name\":\"Y. Fang\"}],\"doi\":\"10.1016/j.patrec.2017.04.004\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e378d5258615b542484fb519f2ca28b0ab1f1394\",\"title\":\"Three-stream CNNs for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/e378d5258615b542484fb519f2ca28b0ab1f1394\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48620041\",\"name\":\"Yun Yi\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"}],\"doi\":\"10.1007/s00371-016-1345-6\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"047fa38a3c991e8b83b8a59a4610b3128a91df08\",\"title\":\"Motion keypoint trajectory and covariance descriptor for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/047fa38a3c991e8b83b8a59a4610b3128a91df08\",\"venue\":\"The Visual Computer\",\"year\":2016},{\"arxivId\":\"1707.06923\",\"authors\":[{\"authorId\":\"39599054\",\"name\":\"B. Sengupta\"},{\"authorId\":\"50059673\",\"name\":\"Yu Qian\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2227f978f084ebb18cb594c0cfaf124b0df6bf95\",\"title\":\"Pillar Networks for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/2227f978f084ebb18cb594c0cfaf124b0df6bf95\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46331912\",\"name\":\"M. Liu\"},{\"authorId\":\"89507637\",\"name\":\"X. Chen\"},{\"authorId\":\"144781413\",\"name\":\"Y. Zhang\"},{\"authorId\":\"48513361\",\"name\":\"Y. Li\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"dc7de1c65a52db271016313980ae577d19aace24\",\"title\":\"Paying More Attention to Motion: Attention Distillation for Learning Video Representations\",\"url\":\"https://www.semanticscholar.org/paper/dc7de1c65a52db271016313980ae577d19aace24\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2010.09709\",\"authors\":[{\"authorId\":\"22237490\",\"name\":\"Tengda Han\"},{\"authorId\":\"10096695\",\"name\":\"Weidi Xie\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"88f440120730e21b07bbd188b2a04787a3208861\",\"title\":\"Self-supervised Co-training for Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/88f440120730e21b07bbd188b2a04787a3208861\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1579340152\",\"name\":\"Dylan Siegler\"},{\"authorId\":\"1576087725\",\"name\":\"Reed Chen\"},{\"authorId\":\"1579213855\",\"name\":\"Michael Fasko\"},{\"authorId\":\"2409366\",\"name\":\"Shunkun Yang\"},{\"authorId\":\"9160831\",\"name\":\"X. Luo\"},{\"authorId\":\"144101028\",\"name\":\"W. Zhao\"}],\"doi\":\"10.1007/978-981-15-1925-3_25\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"de2bde4449c6e0c4687bedc3d2d383e9157a7d2a\",\"title\":\"Semi-automated Development of a Dataset for Baseball Pitch Type Recognition\",\"url\":\"https://www.semanticscholar.org/paper/de2bde4449c6e0c4687bedc3d2d383e9157a7d2a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144800948\",\"name\":\"A. Papadakis\"},{\"authorId\":\"50231158\",\"name\":\"Eirini Mathe\"},{\"authorId\":\"51031275\",\"name\":\"Ioannis Vernikos\"},{\"authorId\":\"123038798\",\"name\":\"Apostolos Maniatis\"},{\"authorId\":\"144116678\",\"name\":\"E. Spyrou\"},{\"authorId\":\"1684455\",\"name\":\"Phivos Mylonas\"}],\"doi\":\"10.1007/978-3-030-20257-6_44\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2165bab67da78a2e99ff89d2a121a6273eb0d350\",\"title\":\"Recognizing Human Actions Using 3D Skeletal Information and CNNs\",\"url\":\"https://www.semanticscholar.org/paper/2165bab67da78a2e99ff89d2a121a6273eb0d350\",\"venue\":\"EANN\",\"year\":2019},{\"arxivId\":\"1607.06408\",\"authors\":[{\"authorId\":\"145742543\",\"name\":\"W. Li\"},{\"authorId\":\"3026404\",\"name\":\"Yongkang Wong\"},{\"authorId\":\"143602033\",\"name\":\"Anan Liu\"},{\"authorId\":null,\"name\":\"Yang Li\"},{\"authorId\":\"2788104\",\"name\":\"Yuting Su\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":\"10.1109/WACV.2017.28\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"38c901a58244be9a2644d486f9a1284dc0edbf8a\",\"title\":\"Multi-Camera Action Dataset for Cross-Camera Action Recognition Benchmarking\",\"url\":\"https://www.semanticscholar.org/paper/38c901a58244be9a2644d486f9a1284dc0edbf8a\",\"venue\":\"2017 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12457708\",\"name\":\"Zhipeng Wei\"},{\"authorId\":\"1742506579\",\"name\":\"J. Chen\"},{\"authorId\":\"2769710\",\"name\":\"Xingxing Wei\"},{\"authorId\":\"108526754\",\"name\":\"Linxi Jiang\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"},{\"authorId\":\"40242610\",\"name\":\"F. Zhou\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1609/AAAI.V34I07.6918\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7b490ba0965fa45445eca4715f46166c76e88988\",\"title\":\"Heuristic Black-Box Adversarial Attacks on Video Recognition Models\",\"url\":\"https://www.semanticscholar.org/paper/7b490ba0965fa45445eca4715f46166c76e88988\",\"venue\":\"AAAI 2020\",\"year\":2019},{\"arxivId\":\"1701.05432\",\"authors\":[{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"2155775\",\"name\":\"Piotr Koniusz\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1109/WACV.2017.22\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6ccf2c5212d793fc44d11f31bbdab7a26ef48f1c\",\"title\":\"Higher-Order Pooling of CNN Features via Kernel Linearization for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6ccf2c5212d793fc44d11f31bbdab7a26ef48f1c\",\"venue\":\"2017 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144082425\",\"name\":\"L. Shao\"},{\"authorId\":\"152506137\",\"name\":\"F. Zhu\"},{\"authorId\":\"1720243\",\"name\":\"X. Li\"}],\"doi\":\"10.1109/TNNLS.2014.2330900\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ae20c630759847cd88655631d0041b0be127fd0c\",\"title\":\"Transfer Learning for Visual Categorization: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/ae20c630759847cd88655631d0041b0be127fd0c\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"},{\"authorId\":\"145466505\",\"name\":\"M. Sapienza\"}],\"doi\":\"10.1109/TPAMI.2013.181\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"13ae07ab03611cb6ebd4ddade4e8c53f1daf454a\",\"title\":\"Learning Pullback HMM Distances\",\"url\":\"https://www.semanticscholar.org/paper/13ae07ab03611cb6ebd4ddade4e8c53f1daf454a\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144717607\",\"name\":\"Jun-Wei Hsieh\"},{\"authorId\":\"3044214\",\"name\":\"Jiun-Cheng Cheng\"},{\"authorId\":\"2544169\",\"name\":\"L. Chen\"},{\"authorId\":\"33689898\",\"name\":\"Chi-Hung Chuang\"},{\"authorId\":\"3214542\",\"name\":\"Duan-Yu Chen\"}],\"doi\":\"10.1016/j.jvcir.2014.05.009\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"14a843aab238c2650d4b5c6d559944ef4356dcd7\",\"title\":\"Handheld object detection and its related event analysis using ratio histogram and mixture of HMMs\",\"url\":\"https://www.semanticscholar.org/paper/14a843aab238c2650d4b5c6d559944ef4356dcd7\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2014},{\"arxivId\":\"2011.11261\",\"authors\":[{\"authorId\":\"47295036\",\"name\":\"Zehua Zhang\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"93d198d99ef16868d381bc63e9e6f8c6ef3f7a07\",\"title\":\"Hierarchically Decoupled Spatial-Temporal Contrast for Self-supervised Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/93d198d99ef16868d381bc63e9e6f8c6ef3f7a07\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.07637\",\"authors\":[{\"authorId\":\"49724493\",\"name\":\"H. Zhang\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1007/978-3-030-58565-5_15\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"180d7e45e5fc84138039f738830950dd9b7d0e06\",\"title\":\"Motion-Excited Sampler: Video Adversarial Attack with Sparked Prior\",\"url\":\"https://www.semanticscholar.org/paper/180d7e45e5fc84138039f738830950dd9b7d0e06\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2012.12334\",\"authors\":[{\"authorId\":\"152998393\",\"name\":\"Yunqiang Li\"},{\"authorId\":\"21225169\",\"name\":\"J. V. Gemert\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"48f33710063f1cdf74abe298245e4cd3834800c9\",\"title\":\"Deep Unsupervised Image Hashing by Maximizing Bit Entropy\",\"url\":\"https://www.semanticscholar.org/paper/48f33710063f1cdf74abe298245e4cd3834800c9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"84670846\",\"name\":\"M. K. Reddy\"},{\"authorId\":\"4454238\",\"name\":\"S. Arora\"},{\"authorId\":\"144682140\",\"name\":\"R. Venkatesh Babu\"}],\"doi\":\"10.1109/NCVPRIPG.2013.6776268\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3687bbcf018d6c074852071f2558924967746929\",\"title\":\"Spatio-temporal feature based VLAD for efficient video retrieval\",\"url\":\"https://www.semanticscholar.org/paper/3687bbcf018d6c074852071f2558924967746929\",\"venue\":\"2013 Fourth National Conference on Computer Vision, Pattern Recognition, Image Processing and Graphics (NCVPRIPG)\",\"year\":2013},{\"arxivId\":\"1801.04134\",\"authors\":[{\"authorId\":\"35309584\",\"name\":\"Jonas Rothfuss\"},{\"authorId\":\"145839029\",\"name\":\"F. Ferreira\"},{\"authorId\":\"34876449\",\"name\":\"E. Aksoy\"},{\"authorId\":\"46432716\",\"name\":\"Y. Zhou\"},{\"authorId\":\"1722677\",\"name\":\"T. Asfour\"}],\"doi\":\"10.1109/LRA.2018.2860057\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"970a8f1655ab329cba5fe26edf543e62fe354376\",\"title\":\"Deep Episodic Memory: Encoding, Recalling, and Predicting Episodic Experiences for Robot Action Execution\",\"url\":\"https://www.semanticscholar.org/paper/970a8f1655ab329cba5fe26edf543e62fe354376\",\"venue\":\"IEEE Robotics and Automation Letters\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"47775167\",\"name\":\"Teng Li\"},{\"authorId\":\"1795291\",\"name\":\"X. Yang\"}],\"doi\":\"10.1109/TNNLS.2017.2731775\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e4d7b8eb0a8e6d2bb5b90b027c1bf32bad320ba5\",\"title\":\"Learning Semantic-Aligned Action Representation\",\"url\":\"https://www.semanticscholar.org/paper/e4d7b8eb0a8e6d2bb5b90b027c1bf32bad320ba5\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2018},{\"arxivId\":\"1212.0402\",\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"title\":\"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\",\"url\":\"https://www.semanticscholar.org/paper/da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3258842\",\"name\":\"J. Wang\"},{\"authorId\":\"1788029\",\"name\":\"W. Wang\"},{\"authorId\":\"48385803\",\"name\":\"W. Gao\"}],\"doi\":\"10.1109/TMM.2018.2855081\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d3aba33ac0025d067bc3ed80d2d73ee883a1c2b1\",\"title\":\"Multiscale Deep Alternative Neural Network for Large-Scale Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/d3aba33ac0025d067bc3ed80d2d73ee883a1c2b1\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":\"1708.02862\",\"authors\":[{\"authorId\":\"50135099\",\"name\":\"W. Li\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"144838223\",\"name\":\"Wei Li\"},{\"authorId\":\"2794259\",\"name\":\"Eirikur Agustsson\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5de5848dc3fc35e40420ffec70a407e4770e3a8d\",\"title\":\"WebVision Database: Visual Learning and Understanding from Web Data\",\"url\":\"https://www.semanticscholar.org/paper/5de5848dc3fc35e40420ffec70a407e4770e3a8d\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1711.10143\",\"authors\":[{\"authorId\":\"47916686\",\"name\":\"Kenji Matsui\"},{\"authorId\":\"134811419\",\"name\":\"Toru Tamaki\"},{\"authorId\":\"30171131\",\"name\":\"Gwladys Auffret\"},{\"authorId\":\"1688940\",\"name\":\"Bisser Raytchev\"},{\"authorId\":\"1686272\",\"name\":\"Kazufumi Kaneda\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"714cd75fe3557b4cbce4b7d5335d06af0fa99689\",\"title\":\"Revisiting hand-crafted feature for action recognition: a set of improved dense trajectories\",\"url\":\"https://www.semanticscholar.org/paper/714cd75fe3557b4cbce4b7d5335d06af0fa99689\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3355010\",\"name\":\"Greg Casta\\u00f1\\u00f3n\"},{\"authorId\":\"2962929\",\"name\":\"Nathan Shnidman\"},{\"authorId\":\"50780334\",\"name\":\"Tim Anderson\"},{\"authorId\":\"152187759\",\"name\":\"Jeffrey Byrne\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aeea6a28ff7290e9e7d9188df569ad75e79788bc\",\"title\":\"Dataset Paper Videos Hours Classes Description Charades Hollywood in Homes : Crowdsourcing Data Collection for Activity Understanding 9848\",\"url\":\"https://www.semanticscholar.org/paper/aeea6a28ff7290e9e7d9188df569ad75e79788bc\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yi Zhu\"},{\"authorId\":\"144325904\",\"name\":\"Yang Long\"},{\"authorId\":\"48953082\",\"name\":\"Y. Guan\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"},{\"authorId\":\"40799321\",\"name\":\"L. Shao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b2cca16e8477f677b4a4c3f1ab572f7fc425ee99\",\"title\":\"ActivityNet Kernelised Representation Generalised Multiple Instance Learning Deep Features NMF with JSD Transfer Joint Matching Actions in Unknown Datasets Word 2 Vec New Concepts Deep Network Matching 1 2 3\",\"url\":\"https://www.semanticscholar.org/paper/b2cca16e8477f677b4a4c3f1ab572f7fc425ee99\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2335888\",\"name\":\"J. Liu\"},{\"authorId\":\"47903936\",\"name\":\"Yali Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"164b0e2a03a5a402f66c497e6c327edf20f8827b\",\"title\":\"Sparse Deep Transfer Learning for Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/164b0e2a03a5a402f66c497e6c327edf20f8827b\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72434202\",\"name\":\"Zixian Cai\"},{\"authorId\":\"143685465\",\"name\":\"S. Gould\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"71b9c46f223dc0d48113f6da1415dc35b2f73eab\",\"title\":\"Activity Recognition in Videos with Segmented Streams\",\"url\":\"https://www.semanticscholar.org/paper/71b9c46f223dc0d48113f6da1415dc35b2f73eab\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24037352\",\"name\":\"N. V. K. Medathati\"},{\"authorId\":\"144718494\",\"name\":\"H. Neumann\"},{\"authorId\":\"34956840\",\"name\":\"Guillaume S. Masson\"},{\"authorId\":\"2796589\",\"name\":\"P. Kornprobst\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"dd9ff1c7a1f569439c80abe9cd857fa61dc315fb\",\"title\":\"Bio-Inspired Computer Vision: Setting the Basis for a New Departure\",\"url\":\"https://www.semanticscholar.org/paper/dd9ff1c7a1f569439c80abe9cd857fa61dc315fb\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143798882\",\"name\":\"Mihir Jain\"},{\"authorId\":\"1738975\",\"name\":\"J. C. V. Gemert\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1109/CVPR.2015.7298599\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"90d44ce126b1ca7107f555db4d546d0e1843d075\",\"title\":\"What do 15,000 object categories tell us about classifying and localizing actions?\",\"url\":\"https://www.semanticscholar.org/paper/90d44ce126b1ca7107f555db4d546d0e1843d075\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2274625\",\"name\":\"Do Hang Nga\"},{\"authorId\":\"1681659\",\"name\":\"K. Yanai\"}],\"doi\":\"10.1007/978-3-319-04114-8_32\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"63a2e2155193dc2da9764ae7380cdbd044ff2b94\",\"title\":\"A Dense SURF and Triangulation Based Spatio-temporal Feature for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/63a2e2155193dc2da9764ae7380cdbd044ff2b94\",\"venue\":\"MMM\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9433002\",\"name\":\"M. Saremi\"},{\"authorId\":\"1914793\",\"name\":\"F. Yaghmaee\"}],\"doi\":\"10.1007/s11042-019-08483-3\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8f95beff2d62ff8aaa9c6143dc4b9443653acc1f\",\"title\":\"Efficient encoding of video descriptor distribution for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/8f95beff2d62ff8aaa9c6143dc4b9443653acc1f\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390049805\",\"name\":\"J. Fern\\u00e1ndez-Ram\\u00edrez\"},{\"authorId\":\"1390049809\",\"name\":\"A. \\u00c1lvarez-Meza\"},{\"authorId\":\"1390049857\",\"name\":\"\\u00c1. Orozco-Gutierrez\"},{\"authorId\":\"46325308\",\"name\":\"J. Correa\"}],\"doi\":\"10.1007/978-3-030-33723-0_4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0c13d989c7dbd3af4547e52bb04e95356ed54879\",\"title\":\"Infinite Gaussian Fisher Vector to Support Video-Based Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/0c13d989c7dbd3af4547e52bb04e95356ed54879\",\"venue\":\"ISVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49865403\",\"name\":\"Zhiyu Chen\"},{\"authorId\":\"1668787617\",\"name\":\"Yangwei Gu\"},{\"authorId\":\"50542782\",\"name\":\"Chunhua Deng\"},{\"authorId\":\"34611435\",\"name\":\"Ziqi Zhu\"}],\"doi\":\"10.1109/SPAC49953.2019.237869\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"747cd60482560cc92a254eccc516cf8f230845d8\",\"title\":\"Adaptive Temporal Segmentation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/747cd60482560cc92a254eccc516cf8f230845d8\",\"venue\":\"2019 International Conference on Security, Pattern Analysis, and Cybernetics (SPAC)\",\"year\":2019},{\"arxivId\":\"1806.05666\",\"authors\":[{\"authorId\":\"1952002\",\"name\":\"A. Ranjan\"},{\"authorId\":\"143881914\",\"name\":\"J. Romero\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"07d6238d8f8edbfe0fd2887fa0a7939735f21e13\",\"title\":\"Learning Human Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/07d6238d8f8edbfe0fd2887fa0a7939735f21e13\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1742445396\",\"name\":\"Lin Wang\"},{\"authorId\":\"8417088\",\"name\":\"Xingfu Wang\"},{\"authorId\":\"3132704\",\"name\":\"Ammar Hawbani\"},{\"authorId\":\"38131633\",\"name\":\"Y. Xiong\"},{\"authorId\":\"89013155\",\"name\":\"Xu Zhang\"}],\"doi\":\"10.1109/ACCESS.2020.3012154\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"54d296dab7a1fd42ad30ed52d266c9faf1c63fab\",\"title\":\"Convolution Encoders for End-to-End Action Tracking With Space-Time Cubic Kernels\",\"url\":\"https://www.semanticscholar.org/paper/54d296dab7a1fd42ad30ed52d266c9faf1c63fab\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72547325\",\"name\":\"Bassel S. Chawky\"},{\"authorId\":\"2805974\",\"name\":\"A. S. Elons\"},{\"authorId\":\"114287783\",\"name\":\"A. Ali\"},{\"authorId\":\"2382767\",\"name\":\"H. A. Shedeed\"}],\"doi\":\"10.1007/978-3-319-63754-9_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"88d70d8cf4557e032bc359d2c2a15b06686612ea\",\"title\":\"A Study of Action Recognition Problems: Dataset and Architectures Perspectives\",\"url\":\"https://www.semanticscholar.org/paper/88d70d8cf4557e032bc359d2c2a15b06686612ea\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1705.03634\",\"authors\":[{\"authorId\":\"8852912\",\"name\":\"S. Li\"},{\"authorId\":\"1858702\",\"name\":\"A. Yilmaz\"},{\"authorId\":\"2869867\",\"name\":\"Changlin Xiao\"},{\"authorId\":\"46382547\",\"name\":\"H. Li\"}],\"doi\":\"10.1007/978-3-319-71607-7_15\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"c001d7d3a543f789f1395dce148915baacf50925\",\"title\":\"4D ISIP: 4D Implicit Surface Interest Point Detection\",\"url\":\"https://www.semanticscholar.org/paper/c001d7d3a543f789f1395dce148915baacf50925\",\"venue\":\"ICIG\",\"year\":2017},{\"arxivId\":\"1810.01455\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1109/CVPR.2019.01018\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"7d8be0302b754c903d96fd056c20207ad90ab4e6\",\"title\":\"Representation Flow for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7d8be0302b754c903d96fd056c20207ad90ab4e6\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143611428\",\"name\":\"Z. Tu\"},{\"authorId\":\"144561905\",\"name\":\"W. Xie\"},{\"authorId\":\"1681843\",\"name\":\"J. Dauwels\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1109/tcsvt.2018.2830102\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"e1d5a04b0ff209aed0f254f39401e235ef56bd09\",\"title\":\"Semantic Cues Enhanced Multimodality Multistream CNN for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e1d5a04b0ff209aed0f254f39401e235ef56bd09\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40451577\",\"name\":\"W. Wang\"},{\"authorId\":\"3113725\",\"name\":\"V. Zheng\"},{\"authorId\":\"9380191\",\"name\":\"H. Yu\"},{\"authorId\":\"1679209\",\"name\":\"C. Miao\"}],\"doi\":\"10.1145/3293318\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dafa29f1f0534448d205365796d68873a0068c6b\",\"title\":\"A Survey of Zero-Shot Learning\",\"url\":\"https://www.semanticscholar.org/paper/dafa29f1f0534448d205365796d68873a0068c6b\",\"venue\":\"ACM Trans. Intell. Syst. Technol.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2948199\",\"name\":\"Eyrun Eyjolfsdottir\"}],\"doi\":\"10.7907/SD8H-YB17.\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"5d2bb032f9721990ed08921fb660bb76e48e608d\",\"title\":\"Detecting Actions of Fruit Flies\",\"url\":\"https://www.semanticscholar.org/paper/5d2bb032f9721990ed08921fb660bb76e48e608d\",\"venue\":\"\",\"year\":2014},{\"arxivId\":\"1912.10269\",\"authors\":[{\"authorId\":\"152360483\",\"name\":\"Nan Wang\"},{\"authorId\":\"49454885\",\"name\":\"Y. Zhou\"},{\"authorId\":\"14481685\",\"name\":\"Fenglei Han\"},{\"authorId\":\"47297723\",\"name\":\"H. Zhu\"},{\"authorId\":\"1470449889\",\"name\":\"Yaojing Zheng\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ad8fbe003c65c15429ffa1a81fbd311f9bbae777\",\"title\":\"UWGAN: Underwater GAN for Real-world Underwater Color Restoration and Dehazing\",\"url\":\"https://www.semanticscholar.org/paper/ad8fbe003c65c15429ffa1a81fbd311f9bbae777\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8125221\",\"name\":\"H. Maia\"},{\"authorId\":\"66088742\",\"name\":\"Darwin Ttito Concha\"},{\"authorId\":\"1398585275\",\"name\":\"H. Pedrini\"},{\"authorId\":\"66275285\",\"name\":\"Hemerson Tacon\"},{\"authorId\":\"51519347\",\"name\":\"A. Brito\"},{\"authorId\":\"67244903\",\"name\":\"H. Chaves\"},{\"authorId\":\"3052490\",\"name\":\"M. Vieira\"},{\"authorId\":\"3387755\",\"name\":\"S. Villela\"}],\"doi\":\"10.1007/978-981-15-1816-4_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0c426717bed63d0afdfb16dd98c8cba915f52853\",\"title\":\"Action Recognition in Videos Using Multi-stream Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/0c426717bed63d0afdfb16dd98c8cba915f52853\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144289594\",\"name\":\"C. Caetano\"},{\"authorId\":\"143793197\",\"name\":\"V. H. Melo\"},{\"authorId\":\"144103389\",\"name\":\"F. Br\\u00e9mond\"},{\"authorId\":\"6141311\",\"name\":\"J. A. D. Santos\"},{\"authorId\":\"9385043\",\"name\":\"W. Schwartz\"}],\"doi\":\"10.1016/J.JVCIR.2019.102596\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c3c201c48d14e0e7135d4558590a4ad3f7bc864c\",\"title\":\"Magnitude-Orientation Stream network and depth information applied to activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/c3c201c48d14e0e7135d4558590a4ad3f7bc864c\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":\"1911.09449\",\"authors\":[{\"authorId\":\"108526754\",\"name\":\"Linxi Jiang\"},{\"authorId\":\"9576855\",\"name\":\"Xingjun Ma\"},{\"authorId\":\"39650418\",\"name\":\"S. Chen\"},{\"authorId\":\"145148600\",\"name\":\"J. Bailey\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1145/3343031.3351088\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6be44364db3a46ab5fcf8172910650b210cc5c39\",\"title\":\"Black-box Adversarial Attacks on Video Recognition Models\",\"url\":\"https://www.semanticscholar.org/paper/6be44364db3a46ab5fcf8172910650b210cc5c39\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26940993\",\"name\":\"Djamila Romaissa Beddiar\"},{\"authorId\":\"2079007\",\"name\":\"B. Nini\"},{\"authorId\":\"1887141250\",\"name\":\"Mohammad Sabokrou\"},{\"authorId\":\"144979251\",\"name\":\"A. Hadid\"}],\"doi\":\"10.1007/s11042-020-09004-3\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"46995f6b266a40c10bc05b046654a4be8bf2220c\",\"title\":\"Vision-based human activity recognition: a survey\",\"url\":\"https://www.semanticscholar.org/paper/46995f6b266a40c10bc05b046654a4be8bf2220c\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36899698\",\"name\":\"Rizwan Ahmed Chaudhry\"},{\"authorId\":\"144020730\",\"name\":\"R. Vidal\"}],\"doi\":\"10.1109/CDC.2013.6760735\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"fdddd687ef3bf3cee40cd1b9b94d0013dd235df5\",\"title\":\"Initial-state invariant Binet-Cauchy kernels for the comparison of Linear Dynamical Systems\",\"url\":\"https://www.semanticscholar.org/paper/fdddd687ef3bf3cee40cd1b9b94d0013dd235df5\",\"venue\":\"52nd IEEE Conference on Decision and Control\",\"year\":2013},{\"arxivId\":\"2007.11365\",\"authors\":[{\"authorId\":\"39440469\",\"name\":\"Sudhakar Kumawat\"},{\"authorId\":\"145879750\",\"name\":\"Manisha Verma\"},{\"authorId\":\"1789677\",\"name\":\"Yuta Nakashima\"},{\"authorId\":\"145853779\",\"name\":\"S. Raman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"4914a205aa1ddeaae3c86a449c69703c89484f54\",\"title\":\"Depthwise Spatio-Temporal STFT Convolutional Neural Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4914a205aa1ddeaae3c86a449c69703c89484f54\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/s11263-019-01225-w\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"43cbabdac51091773d1b003d76adaf8426d17b24\",\"title\":\"Deep Insights into Convolutional Networks for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/43cbabdac51091773d1b003d76adaf8426d17b24\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46758783\",\"name\":\"Jiawei Yan\"},{\"authorId\":\"8556451\",\"name\":\"F. Angelini\"},{\"authorId\":\"144403678\",\"name\":\"S. Naqvi\"}],\"doi\":\"10.1109/ICASSP40776.2020.9054456\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"39e4c98a180c115684fce2caf3f86a0bf804c06a\",\"title\":\"Image Segmentation Based Privacy-Preserving Human Action Recognition for Anomaly Detection\",\"url\":\"https://www.semanticscholar.org/paper/39e4c98a180c115684fce2caf3f86a0bf804c06a\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47319654\",\"name\":\"S. Li\"},{\"authorId\":\"1741668\",\"name\":\"Zhicheng Zhao\"},{\"authorId\":\"152343380\",\"name\":\"Fei Su\"}],\"doi\":\"10.1109/VCIP47243.2019.8965878\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eced654a4b8467a6b52194af8e4d83bcbe1730cb\",\"title\":\"A Spatio-temporal Hybrid Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eced654a4b8467a6b52194af8e4d83bcbe1730cb\",\"venue\":\"2019 IEEE Visual Communications and Image Processing (VCIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1669712931\",\"name\":\"Arpan Gupta\"},{\"authorId\":\"3247309\",\"name\":\"Sakthi Balan Muthiah\"}],\"doi\":\"10.1016/j.imavis.2020.103944\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"22f92789daadfb944e33f7f76ca13553765eabb3\",\"title\":\"Viewpoint constrained and unconstrained Cricket stroke localization from untrimmed videos\",\"url\":\"https://www.semanticscholar.org/paper/22f92789daadfb944e33f7f76ca13553765eabb3\",\"venue\":\"Image Vis. Comput.\",\"year\":2020},{\"arxivId\":\"2004.06130\",\"authors\":[{\"authorId\":\"19310335\",\"name\":\"Sagie Benaim\"},{\"authorId\":\"2077454\",\"name\":\"A. Ephrat\"},{\"authorId\":\"49618488\",\"name\":\"Oran Lang\"},{\"authorId\":\"2138834\",\"name\":\"Inbar Mosseri\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"},{\"authorId\":\"3829997\",\"name\":\"M. Rubinstein\"},{\"authorId\":\"144611617\",\"name\":\"M. Irani\"},{\"authorId\":\"2112779\",\"name\":\"Tali Dekel\"}],\"doi\":\"10.1109/cvpr42600.2020.00994\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"1708ca69799e5ae2614cc61f79ff164fd6d6baa4\",\"title\":\"SpeedNet: Learning the Speediness in Videos\",\"url\":\"https://www.semanticscholar.org/paper/1708ca69799e5ae2614cc61f79ff164fd6d6baa4\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145096334\",\"name\":\"K. Reddy\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1007/s00138-012-0450-4\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"c7eee57d8a8c057ab1f599105d16d0e8489a61e0\",\"title\":\"Recognizing 50 human action categories of web videos\",\"url\":\"https://www.semanticscholar.org/paper/c7eee57d8a8c057ab1f599105d16d0e8489a61e0\",\"venue\":\"Machine Vision and Applications\",\"year\":2012},{\"arxivId\":\"1607.02556\",\"authors\":[{\"authorId\":\"35585536\",\"name\":\"Jialin Wu\"},{\"authorId\":\"29644358\",\"name\":\"Gu Wang\"},{\"authorId\":\"3432961\",\"name\":\"Wukui Yang\"},{\"authorId\":\"7807689\",\"name\":\"Xiangyang Ji\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"2288696b6558b7397bdebe3aed77bedec7b9c0a9\",\"title\":\"Action Recognition with Joint Attention on Multi-Level Deep Features\",\"url\":\"https://www.semanticscholar.org/paper/2288696b6558b7397bdebe3aed77bedec7b9c0a9\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"2009.13782\",\"authors\":[{\"authorId\":\"1577678641\",\"name\":\"Ganesh Samarth\"},{\"authorId\":\"1974345797\",\"name\":\"Sheetal Ojha\"},{\"authorId\":\"96566998\",\"name\":\"N. Pareek\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"29df95ddda4e52ada0564458fe6f438f462b5651\",\"title\":\"Knowledge Fusion Transformers for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/29df95ddda4e52ada0564458fe6f438f462b5651\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2353872\",\"name\":\"Shahzad Cheema\"},{\"authorId\":\"2914349\",\"name\":\"Abdalrahman Eweiwi\"},{\"authorId\":\"1692283\",\"name\":\"C. Bauckhage\"}],\"doi\":\"10.1016/j.patrec.2013.09.024\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a9d0d3dbf5ae84115a20f8659921c32b202ca86a\",\"title\":\"Human activity recognition by separating style and content\",\"url\":\"https://www.semanticscholar.org/paper/a9d0d3dbf5ae84115a20f8659921c32b202ca86a\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50444365\",\"name\":\"Qiming Li\"},{\"authorId\":\"145544640\",\"name\":\"C. Huang\"},{\"authorId\":\"50977643\",\"name\":\"Z. Yao\"},{\"authorId\":\"9407393\",\"name\":\"Y. Chen\"},{\"authorId\":\"8452947\",\"name\":\"L. Ma\"}],\"doi\":\"10.1002/rcs.1931\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"82ca7933208c142a67ff5d4e259c546b5c8a9450\",\"title\":\"Continuous dynamic gesture spotting algorithm based on Dempster\\u2013Shafer Theory in the augmented reality human computer interaction\",\"url\":\"https://www.semanticscholar.org/paper/82ca7933208c142a67ff5d4e259c546b5c8a9450\",\"venue\":\"The international journal of medical robotics + computer assisted surgery : MRCAS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46528640\",\"name\":\"H. T. Binh\"},{\"authorId\":\"9283769\",\"name\":\"Ma Thi Chau\"},{\"authorId\":\"143993575\",\"name\":\"A. Sugimoto\"},{\"authorId\":\"9349062\",\"name\":\"B. Duy\"}],\"doi\":\"10.1109/ICCCE.2018.8539313\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3901f177642912be3fd132807a1e7d16796d1011\",\"title\":\"Selecting active frames for action recognition with vote fusion method\",\"url\":\"https://www.semanticscholar.org/paper/3901f177642912be3fd132807a1e7d16796d1011\",\"venue\":\"2018 7th International Conference on Computer and Communication Engineering (ICCCE)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47508738\",\"name\":\"Shuangshuang Guo\"},{\"authorId\":\"2343895\",\"name\":\"Laiyun Qing\"},{\"authorId\":\"47430935\",\"name\":\"Jun Miao\"},{\"authorId\":\"7667827\",\"name\":\"L. Duan\"}],\"doi\":\"10.1007/s11042-019-7675-4\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b04b5503532a69428841548e32c1847f4cd24021\",\"title\":\"Action prediction via deep residual feature learning and weighted loss\",\"url\":\"https://www.semanticscholar.org/paper/b04b5503532a69428841548e32c1847f4cd24021\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":\"1711.04161\",\"authors\":[{\"authorId\":\"1696573\",\"name\":\"Jiagang Zhu\"},{\"authorId\":\"9276071\",\"name\":\"Wei Zou\"},{\"authorId\":\"40031201\",\"name\":\"Z. Zhu\"},{\"authorId\":\"12791587\",\"name\":\"Lin Li\"}],\"doi\":\"10.1109/ICPR.2018.8545710\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"8c501a89092252a9f62f76a6f439916efe626251\",\"title\":\"End-to-end Video-level Representation Learning for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8c501a89092252a9f62f76a6f439916efe626251\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":\"2011.13367\",\"authors\":[{\"authorId\":\"32590713\",\"name\":\"A. Deli\\u00e8ge\"},{\"authorId\":\"51006998\",\"name\":\"A. Cioppa\"},{\"authorId\":\"22314218\",\"name\":\"Silvio Giancola\"},{\"authorId\":\"1752865048\",\"name\":\"M. J. Seikavandi\"},{\"authorId\":\"9714545\",\"name\":\"J. V. Dueholm\"},{\"authorId\":\"1803459\",\"name\":\"Kamal Nasrollahi\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"1700569\",\"name\":\"T. Moeslund\"},{\"authorId\":\"46541168\",\"name\":\"Marc Van Droogenbroeck\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"16282981d35e696afc70724b6cc6a186a404fe92\",\"title\":\"SoccerNet-v2 : A Dataset and Benchmarks for Holistic Understanding of Broadcast Soccer Videos\",\"url\":\"https://www.semanticscholar.org/paper/16282981d35e696afc70724b6cc6a186a404fe92\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yang Li\"},{\"authorId\":\"2852884\",\"name\":\"Junyong Ye\"},{\"authorId\":\"2366005\",\"name\":\"T. Wang\"},{\"authorId\":\"3260425\",\"name\":\"Shijian Huang\"}],\"doi\":\"10.1007/s00371-014-1020-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"489e626949d70fbb43ab76da12c05cbc07dc81c6\",\"title\":\"Augmenting bag-of-words: a robust contextual representation of spatiotemporal interest points for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/489e626949d70fbb43ab76da12c05cbc07dc81c6\",\"venue\":\"The Visual Computer\",\"year\":2014},{\"arxivId\":\"1708.09268\",\"authors\":[{\"authorId\":\"144603946\",\"name\":\"A. Tran\"},{\"authorId\":\"6835136\",\"name\":\"L. Cheong\"}],\"doi\":\"10.1109/ICCVW.2017.368\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cdbfc8786f9ef0c1331f180398857347d29f901b\",\"title\":\"Two-Stream Flow-Guided Convolutional Attention Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cdbfc8786f9ef0c1331f180398857347d29f901b\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1007/s11263-015-0859-0\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"16eaa26a84468b27e559215db01c53286808ec2a\",\"title\":\"MoFAP: A Multi-level Representation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/16eaa26a84468b27e559215db01c53286808ec2a\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1756362\",\"name\":\"Swathikiran Sudhakaran\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"}],\"doi\":\"10.3233/IA-190021\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6faa95812c73f297eb7f1a8b191b72a8ba0ae763\",\"title\":\"Top-down attention recurrent VLAD encoding for action recognition in videos\",\"url\":\"https://www.semanticscholar.org/paper/6faa95812c73f297eb7f1a8b191b72a8ba0ae763\",\"venue\":\"Intelligenza Artificiale\",\"year\":2019},{\"arxivId\":\"1811.08362\",\"authors\":[{\"authorId\":\"91060830\",\"name\":\"Zhiyu Yao\"},{\"authorId\":null,\"name\":\"Yunbo Wang\"},{\"authorId\":\"35776445\",\"name\":\"Mingsheng Long\"},{\"authorId\":\"1519286448\",\"name\":\"J. Wang\"},{\"authorId\":\"144019071\",\"name\":\"Philip S. Yu\"},{\"authorId\":\"153552276\",\"name\":\"J. Sun\"}],\"doi\":\"10.1109/ICME46284.2020.9102724\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"371ab565b512a5ef9133831c8b7b04fb5b1905c4\",\"title\":\"Multi-Task Learning of Generalizable Representations for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/371ab565b512a5ef9133831c8b7b04fb5b1905c4\",\"venue\":\"2020 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2020},{\"arxivId\":\"1405.4506\",\"authors\":[{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"39527134\",\"name\":\"X. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1016/j.cviu.2016.03.013\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"facbedfe90956c720f70aab14767b5e25dcc6478\",\"title\":\"Bag of visual words and fusion methods for action recognition: Comprehensive study and good practice\",\"url\":\"https://www.semanticscholar.org/paper/facbedfe90956c720f70aab14767b5e25dcc6478\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2726914\",\"name\":\"Shuren Zhou\"},{\"authorId\":\"49435489\",\"name\":\"X. Zeng\"}],\"doi\":\"10.1007/978-981-15-8083-3_27\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5b40980a4a9cc4535e8578b22e09487ad2ca8206\",\"title\":\"Spatial-Temporal Co-attention Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5b40980a4a9cc4535e8578b22e09487ad2ca8206\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1506.03607\",\"authors\":[{\"authorId\":\"1902524\",\"name\":\"Guilhem Ch\\u00e9ron\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2015.368\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c4697681079de557cc04e209762b1a4c1eaae709\",\"title\":\"P-CNN: Pose-Based CNN Features for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c4697681079de557cc04e209762b1a4c1eaae709\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3105254\",\"name\":\"Yuancheng Ye\"},{\"authorId\":\"38101706\",\"name\":\"Xiaodong Yang\"},{\"authorId\":\"35484757\",\"name\":\"Yingli Tian\"}],\"doi\":\"10.1145/2671188.2749339\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"738c187d55745aac18d5fb5f6cc9e3568cd2d217\",\"title\":\"Exploring Pooling Strategies based on Idiosyncrasies of Spatio-Temporal Interest Points\",\"url\":\"https://www.semanticscholar.org/paper/738c187d55745aac18d5fb5f6cc9e3568cd2d217\",\"venue\":\"ICMR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143642520\",\"name\":\"Shoou-I Yu\"},{\"authorId\":\"39978626\",\"name\":\"Lu Jiang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1145/2647868.2654997\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"bfcdffb2fbfba3cc009535f4e3bc719f3e3502b6\",\"title\":\"Instructional Videos for Unsupervised Harvesting and Learning of Action Examples\",\"url\":\"https://www.semanticscholar.org/paper/bfcdffb2fbfba3cc009535f4e3bc719f3e3502b6\",\"venue\":\"ACM Multimedia\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49024484\",\"name\":\"J. Huang\"},{\"authorId\":\"47577022\",\"name\":\"Nannan Li\"},{\"authorId\":\"50289966\",\"name\":\"Thomas H. Li\"},{\"authorId\":\"1390631689\",\"name\":\"Shan Liu\"},{\"authorId\":\"46439321\",\"name\":\"Ge Li\"}],\"doi\":\"10.1109/TCSVT.2019.2923712\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"71780727bad491d006a97ee365c08ea616b707c3\",\"title\":\"Spatial\\u2013Temporal Context-Aware Online Action Detection and Prediction\",\"url\":\"https://www.semanticscholar.org/paper/71780727bad491d006a97ee365c08ea616b707c3\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1733863\",\"name\":\"Ziqiang Li\"},{\"authorId\":\"31248326\",\"name\":\"Y. Ge\"},{\"authorId\":\"153285206\",\"name\":\"J. Feng\"},{\"authorId\":\"47719677\",\"name\":\"Xiaolei Qin\"},{\"authorId\":\"1878213307\",\"name\":\"Jiaruo Yu\"},{\"authorId\":\"145429878\",\"name\":\"Hui Yu\"}],\"doi\":\"10.1109/icme46284.2020.9102727\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"998ff770cc593fa2d7a0ba1029cd78bf5d4c1ca0\",\"title\":\"Deep Selective Feature Learning for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/998ff770cc593fa2d7a0ba1029cd78bf5d4c1ca0\",\"venue\":\"2020 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40893753\",\"name\":\"A. Dilawari\"},{\"authorId\":\"2193802\",\"name\":\"M. U. Khan\"},{\"authorId\":\"46198155\",\"name\":\"Z. Rehman\"},{\"authorId\":\"51138110\",\"name\":\"Khalid Mahmood Awan\"},{\"authorId\":\"118667615\",\"name\":\"I. Mehmood\"},{\"authorId\":\"1680455\",\"name\":\"Seungmin Rho\"}],\"doi\":\"10.1007/S00034-019-01143-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c1edfe91c1cb3a8c237e78dbc86683d4e11f9aac\",\"title\":\"Toward Generating Human-Centered Video Annotations\",\"url\":\"https://www.semanticscholar.org/paper/c1edfe91c1cb3a8c237e78dbc86683d4e11f9aac\",\"venue\":\"Circuits Syst. Signal Process.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31586818\",\"name\":\"H. G. Chen\"},{\"authorId\":\"8133623\",\"name\":\"Wanjia Liu\"},{\"authorId\":\"46186660\",\"name\":\"R. Goel\"},{\"authorId\":\"2492444\",\"name\":\"Rhonald C. Lua\"},{\"authorId\":\"47732006\",\"name\":\"S. Mittal\"},{\"authorId\":\"35633657\",\"name\":\"Yuzhong Huang\"},{\"authorId\":\"145280967\",\"name\":\"A. Veeraraghavan\"},{\"authorId\":\"46463998\",\"name\":\"Ankit B. Patel\"}],\"doi\":\"10.1109/TCI.2019.2948755\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7377982e58702e0f44beff2c00ab2d32825cf557\",\"title\":\"Fast Retinomorphic Event-Driven Representations for Video Gameplay and Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7377982e58702e0f44beff2c00ab2d32825cf557\",\"venue\":\"IEEE Transactions on Computational Imaging\",\"year\":2020},{\"arxivId\":\"2011.13046\",\"authors\":[{\"authorId\":\"48442730\",\"name\":\"Y. Bai\"},{\"authorId\":\"145350991\",\"name\":\"Haoqi Fan\"},{\"authorId\":\"1806773\",\"name\":\"I. Misra\"},{\"authorId\":\"145595812\",\"name\":\"G. Venkatesh\"},{\"authorId\":\"2946371\",\"name\":\"Yongyi Lu\"},{\"authorId\":\"7743268\",\"name\":\"Yuyin Zhou\"},{\"authorId\":\"2156559\",\"name\":\"Qihang Yu\"},{\"authorId\":\"50105587\",\"name\":\"Vikas Chandra\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"c8993a95dac7a0bf86fb96ee30cf653a57755783\",\"title\":\"Can Temporal Information Help with Contrastive Self-Supervised Learning?\",\"url\":\"https://www.semanticscholar.org/paper/c8993a95dac7a0bf86fb96ee30cf653a57755783\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.06037\",\"authors\":[{\"authorId\":\"1581475970\",\"name\":\"Nadine Behrmann\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"},{\"authorId\":\"2199924\",\"name\":\"M. Noroozi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"11cd3fc5561dd372f8fd03dd1c4d23d93f2e746e\",\"title\":\"Unsupervised Video Representation Learning by Bidirectional Feature Prediction\",\"url\":\"https://www.semanticscholar.org/paper/11cd3fc5561dd372f8fd03dd1c4d23d93f2e746e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3047890\",\"name\":\"Bowen Zhang\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"}],\"doi\":\"10.1109/TIP.2018.2791180\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e720ef927bb03b4cd821a1d65a2b18d46748e2dc\",\"title\":\"Real-Time Action Recognition With Deeply Transferred Motion Vector CNNs\",\"url\":\"https://www.semanticscholar.org/paper/e720ef927bb03b4cd821a1d65a2b18d46748e2dc\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39901030\",\"name\":\"Dingwen Zhang\"},{\"authorId\":\"50469612\",\"name\":\"Guangyu Guo\"},{\"authorId\":null,\"name\":\"Dong Huang\"},{\"authorId\":\"145877494\",\"name\":\"J. Han\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"87e3a8c0429a2d8c4349f9b55fce4ff2c8540deb\",\"title\":\"presented a deep 3 D convolutional architecture that models the flow estimation problem as a \\u201c Voxel 2 Voxel \\u201d prediction problem\",\"url\":\"https://www.semanticscholar.org/paper/87e3a8c0429a2d8c4349f9b55fce4ff2c8540deb\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145380510\",\"name\":\"L. Rossetto\"},{\"authorId\":\"2155883\",\"name\":\"Ivan Giangreco\"},{\"authorId\":\"145717652\",\"name\":\"H. Schuldt\"},{\"authorId\":\"144436412\",\"name\":\"S. Dupont\"},{\"authorId\":\"3272087\",\"name\":\"Omar Seddati\"},{\"authorId\":\"143765782\",\"name\":\"T. M. Sezgin\"},{\"authorId\":\"2870361\",\"name\":\"Y. Sahillioglu\"}],\"doi\":\"10.1007/978-3-319-14442-9_24\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6e8cb25baa04a541f0c12d959d814da63f864147\",\"title\":\"IMOTION - A Content-Based Video Retrieval Engine\",\"url\":\"https://www.semanticscholar.org/paper/6e8cb25baa04a541f0c12d959d814da63f864147\",\"venue\":\"MMM\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145732825\",\"name\":\"Xiaoqiang Yan\"},{\"authorId\":\"28962067\",\"name\":\"Shizhe Hu\"},{\"authorId\":\"2382085\",\"name\":\"Y. Ye\"}],\"doi\":\"10.1109/CVPR.2017.431\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"38e4b15b7417d4511a6b1c50307f33d7a7edbfbd\",\"title\":\"Multi-task Clustering of Human Actions by Sharing Information\",\"url\":\"https://www.semanticscholar.org/paper/38e4b15b7417d4511a6b1c50307f33d7a7edbfbd\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1904.08634\",\"authors\":[{\"authorId\":\"2682004\",\"name\":\"T. Perrett\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.1109/CVPR.2019.00804\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1aea7d20edfd40b0907249270a80842382d93964\",\"title\":\"DDLSTM: Dual-Domain LSTM for Cross-Dataset Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1aea7d20edfd40b0907249270a80842382d93964\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2007.05515\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0e599d703e358d6e554da859cff116553053d0fa\",\"title\":\"AViD Dataset: Anonymized Videos from Diverse Countries\",\"url\":\"https://www.semanticscholar.org/paper/0e599d703e358d6e554da859cff116553053d0fa\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39635018\",\"name\":\"Xiaolong Wang\"}],\"doi\":\"10.1184/R1/9823919\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"dcd6c05a5ef1e6d9247f3eb0bff91ac0c3d7ac01\",\"title\":\"Learning and Reasoning with Visual Correspondence in Time\",\"url\":\"https://www.semanticscholar.org/paper/dcd6c05a5ef1e6d9247f3eb0bff91ac0c3d7ac01\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2992579\",\"name\":\"Hamid Izadinia\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1007/978-3-642-33765-9_31\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"40493e58880b5bc51e38d2831f0a4e6c1b01bde8\",\"title\":\"Recognizing Complex Events Using Large Margin Joint Low-Level Event Model\",\"url\":\"https://www.semanticscholar.org/paper/40493e58880b5bc51e38d2831f0a4e6c1b01bde8\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":\"1607.08665\",\"authors\":[{\"authorId\":\"2739544\",\"name\":\"Shreyansh Daftry\"},{\"authorId\":\"3308210\",\"name\":\"Sam Zeng\"},{\"authorId\":\"1756566\",\"name\":\"J. Bagnell\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1109/IROS.2016.7759279\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0726a45eb129eed88915aa5a86df2af16a09bcc1\",\"title\":\"Introspective perception: Learning to predict failures in vision systems\",\"url\":\"https://www.semanticscholar.org/paper/0726a45eb129eed88915aa5a86df2af16a09bcc1\",\"venue\":\"2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145188375\",\"name\":\"Tingting Yao\"},{\"authorId\":\"50857536\",\"name\":\"Z. Wang\"},{\"authorId\":\"144918654\",\"name\":\"Z. Xie\"},{\"authorId\":null,\"name\":\"Jun Gao\"},{\"authorId\":\"145855523\",\"name\":\"D. Feng\"}],\"doi\":\"10.1016/j.patcog.2016.11.012\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b4faeafa47346ca08eac97a77ec424405105fb86\",\"title\":\"Learning universal multiview dictionary for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/b4faeafa47346ca08eac97a77ec424405105fb86\",\"venue\":\"Pattern Recognit.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9012538\",\"name\":\"Salah Alghyaline\"},{\"authorId\":\"144717607\",\"name\":\"Jun-Wei Hsieh\"},{\"authorId\":\"33689898\",\"name\":\"Chi-Hung Chuang\"}],\"doi\":\"10.1109/SMC.2017.8122640\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f19bf8b5c1860cd81b5339804d5db9e791085aa7\",\"title\":\"Video action classification using symmelets and deep learning\",\"url\":\"https://www.semanticscholar.org/paper/f19bf8b5c1860cd81b5339804d5db9e791085aa7\",\"venue\":\"2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403633669\",\"name\":\"Jordi Bautista-Ballester\"},{\"authorId\":\"1403633671\",\"name\":\"J. Verg\\u00e9s-Llah\\u00ed\"},{\"authorId\":\"143844336\",\"name\":\"D. Puig\"}],\"doi\":\"10.5220/0005669002990307\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d278ef6dea241cd89709db2335f53485f7b2325a\",\"title\":\"Combining Contextual and Modal Action Information into a Weighted Multikernel SVM for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d278ef6dea241cd89709db2335f53485f7b2325a\",\"venue\":\"VISIGRAPP\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2749438\",\"name\":\"Shriman Narayan Tiwari\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"176b5b8533def338272551736e7c5ec386ea3b91\",\"title\":\"Deep features for multimodal emotion classification\",\"url\":\"https://www.semanticscholar.org/paper/176b5b8533def338272551736e7c5ec386ea3b91\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47599321\",\"name\":\"Qian Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6ac568fa4e641c4a5b9f5ada98fb1eafe7b4d157\",\"title\":\"Zero-shot visual recognition via latent embedding learning\",\"url\":\"https://www.semanticscholar.org/paper/6ac568fa4e641c4a5b9f5ada98fb1eafe7b4d157\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1450625257\",\"name\":\"Cvpr\"},{\"authorId\":\"66987745\",\"name\":\"Paper Id\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4d512c2cd40bb99170ad8d66aa7c6d3d71af1a79\",\"title\":\"Learning Fisher star models for action recognition in space-time videos\",\"url\":\"https://www.semanticscholar.org/paper/4d512c2cd40bb99170ad8d66aa7c6d3d71af1a79\",\"venue\":\"\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35005950\",\"name\":\"Ethem F. Can\"},{\"authorId\":\"1758550\",\"name\":\"R. Manmatha\"}],\"doi\":\"10.1109/CVPRW.2013.44\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"32b1a465e4128e4c05bec891b0a01fd6ca62e21b\",\"title\":\"Formulating Action Recognition as a Ranking Problem\",\"url\":\"https://www.semanticscholar.org/paper/32b1a465e4128e4c05bec891b0a01fd6ca62e21b\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition Workshops\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"UWGAN UNDERWATER GAN\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"97724d7df8c92cdb5d41e26e634c36067859f6c0\",\"title\":\"UWGAN : UNDERWATER GAN FOR REAL-WORLD UNDERWATER COLOR RESTORATION AND DEHAZING\",\"url\":\"https://www.semanticscholar.org/paper/97724d7df8c92cdb5d41e26e634c36067859f6c0\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2269886\",\"name\":\"Jianguang Zhang\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"145054089\",\"name\":\"J. Jiang\"},{\"authorId\":\"52178352\",\"name\":\"Zhongrun Zhou\"},{\"authorId\":\"145595597\",\"name\":\"D. An\"},{\"authorId\":\"9184261\",\"name\":\"JieJing Liu\"},{\"authorId\":\"4582402\",\"name\":\"Zhifei Song\"}],\"doi\":\"10.1186/s13640-019-0428-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b541acb7f6fb87fda4cd5a1915c7632579995314\",\"title\":\"A feature selection framework for video semantic recognition via integrated cross-media analysis and embedded learning\",\"url\":\"https://www.semanticscholar.org/paper/b541acb7f6fb87fda4cd5a1915c7632579995314\",\"venue\":\"EURASIP J. Image Video Process.\",\"year\":2019},{\"arxivId\":\"1805.06749\",\"authors\":[{\"authorId\":\"10007321\",\"name\":\"Farnoosh Heidarivincheh\"},{\"authorId\":\"1728108\",\"name\":\"M. Mirmehdi\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"89d7aa10ad97251089d0204916f784f137f3a1ec\",\"title\":\"Action Completion: A Temporal Model for Moment Detection\",\"url\":\"https://www.semanticscholar.org/paper/89d7aa10ad97251089d0204916f784f137f3a1ec\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144284282\",\"name\":\"W. Sun\"},{\"authorId\":null,\"name\":\"Chunfeng Yuan\"},{\"authorId\":\"48319476\",\"name\":\"P. Wang\"},{\"authorId\":\"145071104\",\"name\":\"Shuang Yang\"},{\"authorId\":\"40506509\",\"name\":\"W. Hu\"},{\"authorId\":\"40286498\",\"name\":\"Zhaoquan Cai\"}],\"doi\":\"10.1007/978-3-319-59259-6_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"32761827b8ee0e9edf31df4f3c7f242070191313\",\"title\":\"Hierarchical Bayesian Multiple Kernel Learning Based Feature Fusion for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/32761827b8ee0e9edf31df4f3c7f242070191313\",\"venue\":\"MPRSS\",\"year\":2016},{\"arxivId\":\"1805.04026\",\"authors\":[{\"authorId\":\"145032628\",\"name\":\"Michael Wray\"},{\"authorId\":\"3420479\",\"name\":\"D. Moltisanti\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f2abaa1476fe1f00358f3eaa77dde2f348f58982\",\"title\":\"Towards an Unequivocal Representation of Actions\",\"url\":\"https://www.semanticscholar.org/paper/f2abaa1476fe1f00358f3eaa77dde2f348f58982\",\"venue\":\"CVPR Workshops\",\"year\":2018},{\"arxivId\":\"1908.10136\",\"authors\":[{\"authorId\":\"2659862\",\"name\":\"J. Zhang\"},{\"authorId\":\"38083193\",\"name\":\"F. Shen\"},{\"authorId\":\"1390532590\",\"name\":\"Xing Xu\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":null,\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f0446862cbdf61974e039a85d349d7f7864f42c1\",\"title\":\"Cooperative Cross-Stream Network for Discriminative Action Representation\",\"url\":\"https://www.semanticscholar.org/paper/f0446862cbdf61974e039a85d349d7f7864f42c1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9433002\",\"name\":\"M. Saremi\"},{\"authorId\":\"1914793\",\"name\":\"F. Yaghmaee\"}],\"doi\":\"10.1007/s13735-019-00182-x\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"db337468c459fc100780e396c39750fb5aebf05e\",\"title\":\"Probabilistic selection of frames for early action recognition in videos\",\"url\":\"https://www.semanticscholar.org/paper/db337468c459fc100780e396c39750fb5aebf05e\",\"venue\":\"International Journal of Multimedia Information Retrieval\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9742265\",\"name\":\"O. C. Kwon\"},{\"authorId\":\"2447631\",\"name\":\"Junyeong Kim\"},{\"authorId\":\"145954697\",\"name\":\"C. Yoo\"}],\"doi\":\"10.1109/ICIP.2018.8451493\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ac9ee00414034f340b1c612ef23bbc9ed6d653e0\",\"title\":\"Action Recognition: First-and Second-Order 3D Feature in Bi-Directional Attention Network\",\"url\":\"https://www.semanticscholar.org/paper/ac9ee00414034f340b1c612ef23bbc9ed6d653e0\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145489794\",\"name\":\"K. Huang\"},{\"authorId\":\"145458349\",\"name\":\"Z. Qin\"},{\"authorId\":\"2168639\",\"name\":\"Kaiping Xu\"},{\"authorId\":\"19204816\",\"name\":\"Shuxiong Ye\"},{\"authorId\":\"1886528\",\"name\":\"Guolong Wang\"}],\"doi\":\"10.1007/978-3-319-77383-4_14\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c48f20b4fba0b629cab97e330c8c4a3423dc5d00\",\"title\":\"Multi-modality Fusion Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c48f20b4fba0b629cab97e330c8c4a3423dc5d00\",\"venue\":\"PCM\",\"year\":2017},{\"arxivId\":\"1711.11248\",\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"4439383\",\"name\":\"Jamie Ray\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/CVPR.2018.00675\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"89c3050522a0bb9820c32dc7444e003ef0d3e2e4\",\"title\":\"A Closer Look at Spatiotemporal Convolutions for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/89c3050522a0bb9820c32dc7444e003ef0d3e2e4\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144796322\",\"name\":\"F. P\\u00e1ez\"},{\"authorId\":\"1939861\",\"name\":\"J. Vanegas\"},{\"authorId\":\"144637758\",\"name\":\"F. Gonzalez\"}],\"doi\":\"10.1109/STSIVA.2013.6644926\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"92d6037136aac58f6c619e3069bd38e623983884\",\"title\":\"An evaluation of NMF algorithm on human action video retrieval\",\"url\":\"https://www.semanticscholar.org/paper/92d6037136aac58f6c619e3069bd38e623983884\",\"venue\":\"Symposium of Signals, Images and Artificial Vision - 2013: STSIVA - 2013\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1931096\",\"name\":\"A. Behera\"},{\"authorId\":\"145030629\",\"name\":\"Matthew Chapman\"},{\"authorId\":\"1703235\",\"name\":\"A. Cohn\"},{\"authorId\":\"1967104\",\"name\":\"David C. Hogg\"}],\"doi\":\"10.5220/0004655100220030\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"186498c4ac00f5db50c7ac45443015c569fb00a4\",\"title\":\"Egocentric activity recognition using Histograms of Oriented Pairwise Relations\",\"url\":\"https://www.semanticscholar.org/paper/186498c4ac00f5db50c7ac45443015c569fb00a4\",\"venue\":\"2014 International Conference on Computer Vision Theory and Applications (VISAPP)\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66589187\",\"name\":\"Hanjian Song\"},{\"authorId\":\"50167971\",\"name\":\"L. Tian\"},{\"authorId\":\"49673312\",\"name\":\"Chen Li\"}],\"doi\":\"10.1109/ISM.2018.00036\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2a69959449e8ba64b6f75b6a794075018ad01f57\",\"title\":\"3D Convolutional Network Based Foreground Feature Fusion\",\"url\":\"https://www.semanticscholar.org/paper/2a69959449e8ba64b6f75b6a794075018ad01f57\",\"venue\":\"2018 IEEE International Symposium on Multimedia (ISM)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3043492\",\"name\":\"M. Kulbacki\"},{\"authorId\":\"2554241\",\"name\":\"J. Segen\"},{\"authorId\":\"3379311\",\"name\":\"Slawomir Wojciechowski\"},{\"authorId\":\"2722816\",\"name\":\"Kamil Wereszczynski\"},{\"authorId\":\"2171503\",\"name\":\"J. Nowacki\"},{\"authorId\":\"15528306\",\"name\":\"A. Drabik\"},{\"authorId\":\"40308408\",\"name\":\"K. Wojciechowski\"}],\"doi\":\"10.1007/978-3-319-75420-8_47\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"febbb6088e4fbc587dddab9737cd1d4aae146f61\",\"title\":\"Intelligent Video Monitoring System with the Functionality of Online Recognition of People's Behavior and Interactions Between People\",\"url\":\"https://www.semanticscholar.org/paper/febbb6088e4fbc587dddab9737cd1d4aae146f61\",\"venue\":\"ACIIDS\",\"year\":2018},{\"arxivId\":\"1602.01921\",\"authors\":[{\"authorId\":\"3374519\",\"name\":\"H. Lee\"},{\"authorId\":\"144248119\",\"name\":\"Minju Jung\"},{\"authorId\":\"1780524\",\"name\":\"J. Tani\"}],\"doi\":\"10.1109/tcds.2017.2768422\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2002456c4789e763c2c37f1dd159025e7253f9d7\",\"title\":\"Recognition of Visually Perceived Compositional Human Actions by Multiple Spatio-Temporal Scales Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/2002456c4789e763c2c37f1dd159025e7253f9d7\",\"venue\":\"IEEE Transactions on Cognitive and Developmental Systems\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7200696\",\"name\":\"K. Sagayam\"},{\"authorId\":\"144950163\",\"name\":\"D. J. Hemanth\"}],\"doi\":\"10.1016/j.compind.2018.03.035\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"493a304fad752fd491674dacfeb1d5562546e8a9\",\"title\":\"ABC algorithm based optimization of 1-D hidden Markov model for hand gesture recognition applications\",\"url\":\"https://www.semanticscholar.org/paper/493a304fad752fd491674dacfeb1d5562546e8a9\",\"venue\":\"Comput. Ind.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3136303\",\"name\":\"G. Cong\"},{\"authorId\":\"2972684\",\"name\":\"G. Domeniconi\"},{\"authorId\":\"47377263\",\"name\":\"Joshua Shapiro\"},{\"authorId\":\"34765265\",\"name\":\"C. Yang\"},{\"authorId\":\"144969569\",\"name\":\"B. Chen\"}],\"doi\":\"10.1109/WACV.2019.00013\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"dcdf68e007737ebae40e27239b3340b236337f03\",\"title\":\"Video Action Recognition With an Additional End-to-End Trained Temporal Stream\",\"url\":\"https://www.semanticscholar.org/paper/dcdf68e007737ebae40e27239b3340b236337f03\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":\"1511.04458\",\"authors\":[{\"authorId\":\"1735328\",\"name\":\"X. Xu\"},{\"authorId\":\"1697755\",\"name\":\"Timothy M. Hospedales\"},{\"authorId\":\"144784813\",\"name\":\"S. Gong\"}],\"doi\":\"10.1007/s11263-016-0983-5\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"a30203598d758af7112afa0c5e6f85ef726daec1\",\"title\":\"Transductive Zero-Shot Action Recognition by Word-Vector Embedding\",\"url\":\"https://www.semanticscholar.org/paper/a30203598d758af7112afa0c5e6f85ef726daec1\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145052381\",\"name\":\"A. Gupta\"}],\"doi\":\"10.14288/1.0305862\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9e0a864793a45be2a105a252322453abbb5e1148\",\"title\":\"Using unlabeled 3D motion examples for human activity understanding\",\"url\":\"https://www.semanticscholar.org/paper/9e0a864793a45be2a105a252322453abbb5e1148\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2256817\",\"name\":\"Fahimeh Rezazadegan\"},{\"authorId\":\"34686772\",\"name\":\"S. Shirazi\"},{\"authorId\":\"1771913\",\"name\":\"Niko S\\u00fcnderhauf\"},{\"authorId\":\"1809144\",\"name\":\"Michael Milford\"},{\"authorId\":\"1803115\",\"name\":\"B. Upcroft\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"30b103d59f8460d80bb9eac0aa09aaa56c98494f\",\"title\":\"Enhancing human action recognition with region proposals\",\"url\":\"https://www.semanticscholar.org/paper/30b103d59f8460d80bb9eac0aa09aaa56c98494f\",\"venue\":\"ICRA 2015\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"3237649\",\"name\":\"P. Stanitsas\"},{\"authorId\":\"1686714\",\"name\":\"M. Harandi\"},{\"authorId\":\"1827707\",\"name\":\"V. Morellas\"},{\"authorId\":\"38797009\",\"name\":\"N. Papanikolopoulos\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"9795ea84babb4989ea722e274e70d6c89bbce520\",\"title\":\"Learning Discriminative \\u03b1\\u03b2-Divergences for Positive Definite Matrices 1\",\"url\":\"https://www.semanticscholar.org/paper/9795ea84babb4989ea722e274e70d6c89bbce520\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"2008.13426\",\"authors\":[{\"authorId\":\"46584859\",\"name\":\"Jiangliu Wang\"},{\"authorId\":\"2840852\",\"name\":\"Jianbo Jiao\"},{\"authorId\":\"2780029\",\"name\":\"Linchao Bao\"},{\"authorId\":\"2548483\",\"name\":\"Shengfeng He\"},{\"authorId\":\"1654091065\",\"name\":\"Wei Liu\"},{\"authorId\":\"47908910\",\"name\":\"Y. Liu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b38e482488359da26a25ed9ef5341cd38a2b6562\",\"title\":\"Self-supervised Video Representation Learning by Uncovering Spatio-temporal Statistics\",\"url\":\"https://www.semanticscholar.org/paper/b38e482488359da26a25ed9ef5341cd38a2b6562\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"65989274\",\"name\":\"Abinta Mehmood Mir\"},{\"authorId\":\"1697680\",\"name\":\"M. Yousaf\"},{\"authorId\":\"51260966\",\"name\":\"H. Dawood\"}],\"doi\":\"10.1117/1.JEI.27.6.063016\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"04dc67d43e45f5236c675d06fffe75d3589c676a\",\"title\":\"Criminal action recognition using spatiotemporal human motion acceleration descriptor\",\"url\":\"https://www.semanticscholar.org/paper/04dc67d43e45f5236c675d06fffe75d3589c676a\",\"venue\":\"J. Electronic Imaging\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145733600\",\"name\":\"Song Cao\"},{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/WACV.2016.7477583\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"15ef449ac443c494ceeea8a9c425043f4079522e\",\"title\":\"Abstraction hierarchy and self annotation update for fine grained activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/15ef449ac443c494ceeea8a9c425043f4079522e\",\"venue\":\"2016 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"104150223\",\"name\":\"K. Yang\"},{\"authorId\":\"47196642\",\"name\":\"Z. Wang\"},{\"authorId\":\"7944784\",\"name\":\"H. Dai\"},{\"authorId\":\"15785036\",\"name\":\"Tianlong Shen\"},{\"authorId\":\"48957961\",\"name\":\"P. Qiao\"},{\"authorId\":\"143767586\",\"name\":\"Xin Niu\"},{\"authorId\":\"47911285\",\"name\":\"J. Jiang\"},{\"authorId\":\"144032853\",\"name\":\"Dong-sheng Li\"},{\"authorId\":\"1791001\",\"name\":\"Y. Dou\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053394\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"651bbfced764c3e8039adf8598def1bd1d69506d\",\"title\":\"Attentional Fused Temporal Transformation Network for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/651bbfced764c3e8039adf8598def1bd1d69506d\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"2012.02426\",\"authors\":[{\"authorId\":\"1879292723\",\"name\":\"Junwei Liang\"},{\"authorId\":\"48749954\",\"name\":\"L. Cao\"},{\"authorId\":\"3182065\",\"name\":\"Xuehan Xiong\"},{\"authorId\":\"2029317446\",\"name\":\"Ting Yu\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e84c8a5b818d6c121083550bae9bda257a4df60f\",\"title\":\"Spatial-Temporal Alignment Network for Action Recognition and Detection\",\"url\":\"https://www.semanticscholar.org/paper/e84c8a5b818d6c121083550bae9bda257a4df60f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144876830\",\"name\":\"Q. Tian\"},{\"authorId\":\"1699104\",\"name\":\"T. Arbel\"},{\"authorId\":\"47125588\",\"name\":\"James J. Clark\"}],\"doi\":\"10.1109/ICPR.2016.7899761\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"bdd203bcd3c41c336c5635fb026a78279d75b4be\",\"title\":\"Shannon information based adaptive sampling for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/bdd203bcd3c41c336c5635fb026a78279d75b4be\",\"venue\":\"2016 23rd International Conference on Pattern Recognition (ICPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2410694\",\"name\":\"Jos\\u00e9 M. Chaquet\"},{\"authorId\":\"32044957\",\"name\":\"E. Carmona\"},{\"authorId\":\"1397896370\",\"name\":\"A. Fern\\u00e1ndez-Caballero\"}],\"doi\":\"10.1016/j.cviu.2013.01.013\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ca17025fe9519b0eec7738995902be2992040a87\",\"title\":\"A survey of video datasets for human action and activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/ca17025fe9519b0eec7738995902be2992040a87\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2646978\",\"name\":\"Zengmin Xu\"},{\"authorId\":\"144328091\",\"name\":\"R. Hu\"},{\"authorId\":\"38373223\",\"name\":\"J. Chen\"},{\"authorId\":\"2983562\",\"name\":\"Huafeng Chen\"},{\"authorId\":\"46382329\",\"name\":\"Hongyang Li\"}],\"doi\":\"10.1007/978-3-319-27671-7_16\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"49d5ad8ac7aa0ed2f63733a719a44602b5c52636\",\"title\":\"Global Contrast Based Salient Region Boundary Sampling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/49d5ad8ac7aa0ed2f63733a719a44602b5c52636\",\"venue\":\"MMM\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"18947121\",\"name\":\"Muhammad Attique Khan\"},{\"authorId\":\"1405301558\",\"name\":\"Kashif Javed\"},{\"authorId\":\"46883468\",\"name\":\"S. Khan\"},{\"authorId\":\"48592042\",\"name\":\"T. Saba\"},{\"authorId\":\"49244454\",\"name\":\"U. Habib\"},{\"authorId\":\"1850112\",\"name\":\"J. Khan\"},{\"authorId\":\"2332795\",\"name\":\"Aaqif Afzaal Abbasi\"}],\"doi\":\"10.1007/s11042-020-08806-9\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"faa84a405a5ce2b7b0eaa7bd90d329894cbb3be4\",\"title\":\"Human action recognition using fusion of multiview and deep features: an application to video surveillance\",\"url\":\"https://www.semanticscholar.org/paper/faa84a405a5ce2b7b0eaa7bd90d329894cbb3be4\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"2003.03030\",\"authors\":[{\"authorId\":\"50623801\",\"name\":\"Shihao Zhao\"},{\"authorId\":\"9576855\",\"name\":\"Xingjun Ma\"},{\"authorId\":\"145014256\",\"name\":\"Xiang Zheng\"},{\"authorId\":\"145148600\",\"name\":\"J. Bailey\"},{\"authorId\":\"40663515\",\"name\":\"J. Chen\"},{\"authorId\":\"152163873\",\"name\":\"Yugang Jiang\"}],\"doi\":\"10.1109/cvpr42600.2020.01445\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"803f9bf6ab893073c514492a220747aa3d5fbf64\",\"title\":\"Clean-Label Backdoor Attacks on Video Recognition Models\",\"url\":\"https://www.semanticscholar.org/paper/803f9bf6ab893073c514492a220747aa3d5fbf64\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2505740\",\"name\":\"Dennis Ludl\"},{\"authorId\":\"7932331\",\"name\":\"T. Gulde\"},{\"authorId\":\"2174606\",\"name\":\"Crist\\u00f3bal Curio\"}],\"doi\":\"10.1109/TITS.2020.2988504\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5eb8531ef3e5bb2606b2f8aa70664ef70db78f00\",\"title\":\"Enhancing Data-Driven Algorithms for Human Pose Estimation and Action Recognition Through Simulation\",\"url\":\"https://www.semanticscholar.org/paper/5eb8531ef3e5bb2606b2f8aa70664ef70db78f00\",\"venue\":\"IEEE Transactions on Intelligent Transportation Systems\",\"year\":2020},{\"arxivId\":\"1808.03998\",\"authors\":[{\"authorId\":\"1803711\",\"name\":\"H. Idrees\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"},{\"authorId\":\"50382172\",\"name\":\"Ray Surette\"}],\"doi\":\"10.1108/PIJPSM-11-2016-0158\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5e694d6a242827bc2603a3ac76a4a6de0c832fab\",\"title\":\"Enhancing camera surveillance using computer vision: a research note\",\"url\":\"https://www.semanticscholar.org/paper/5e694d6a242827bc2603a3ac76a4a6de0c832fab\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7675e7d657b3dfe25022ad918a09b588ea0d2e30\",\"title\":\"Motion in action : optical flow estimation and action localization in videos. (Le mouvement en action : estimation du flot optique et localisation d'actions dans les vid\\u00e9os)\",\"url\":\"https://www.semanticscholar.org/paper/7675e7d657b3dfe25022ad918a09b588ea0d2e30\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51290120\",\"name\":\"Siddharth Roheda\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"c22b67958821328c4dd831a7b61e64e534c2d9b4\",\"title\":\"Multi-Modal Sensor Fusion: A Principled Approach to Optimality.\",\"url\":\"https://www.semanticscholar.org/paper/c22b67958821328c4dd831a7b61e64e534c2d9b4\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2007.06292\",\"authors\":[{\"authorId\":\"1486074318\",\"name\":\"Piyush Yadav\"},{\"authorId\":\"1811412083\",\"name\":\"Dhaval Salwala\"},{\"authorId\":\"49976545\",\"name\":\"Edward Curry\"}],\"doi\":\"10.1142/s1793351x20500051\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"c026a584425ab976693c4287ef0bf6a74e2fe75c\",\"title\":\"Knowledge Graph Driven Approach to Represent Video Streams for Spatiotemporal Event Pattern Matching in Complex Event Processing\",\"url\":\"https://www.semanticscholar.org/paper/c026a584425ab976693c4287ef0bf6a74e2fe75c\",\"venue\":\"Int. J. Semantic Comput.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"90724813\",\"name\":\"Y. Cheng\"},{\"authorId\":\"71300641\",\"name\":\"G. Li\"},{\"authorId\":\"1873081\",\"name\":\"N. Wong\"},{\"authorId\":\"50688512\",\"name\":\"Haibao Chen\"},{\"authorId\":\"37629830\",\"name\":\"H. Yu\"}],\"doi\":\"10.1145/3381805\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ac1961d8096e171b840c1cb8d5f7b299bcdf9d2f\",\"title\":\"DEEPEYE: A Deeply Tensor-Compressed Neural Network for Video Comprehension on Terminal Devices\",\"url\":\"https://www.semanticscholar.org/paper/ac1961d8096e171b840c1cb8d5f7b299bcdf9d2f\",\"venue\":\"ACM Trans. Embed. Comput. Syst.\",\"year\":2020},{\"arxivId\":\"1908.00867\",\"authors\":[{\"authorId\":\"50065546\",\"name\":\"W. Price\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dc4b5fd4cf40b765abefb42bca6db1d845e0caa0\",\"title\":\"An Evaluation of Action Recognition Models on EPIC-Kitchens\",\"url\":\"https://www.semanticscholar.org/paper/dc4b5fd4cf40b765abefb42bca6db1d845e0caa0\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48114960\",\"name\":\"Ali Mohammad Nickfarjam\"},{\"authorId\":\"1402318194\",\"name\":\"H. Ebrahimpour-Komleh\"}],\"doi\":\"10.1007/s11042-018-7076-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cf0f92513a4c7000c7e54ff7f4edb9cab0b06629\",\"title\":\"Multi-input 1-dimensional deep belief network: action and activity recognition as case study\",\"url\":\"https://www.semanticscholar.org/paper/cf0f92513a4c7000c7e54ff7f4edb9cab0b06629\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":\"1801.08100\",\"authors\":[{\"authorId\":\"1403813423\",\"name\":\"Carolina Redondo-Cabrera\"},{\"authorId\":\"1402973336\",\"name\":\"R. L\\u00f3pez-Sastre\"}],\"doi\":\"10.1016/j.cviu.2018.08.003\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6855ed66c8a8643aa287078a130308e4a045d288\",\"title\":\"Unsupervised learning from videos using temporal coherency deep networks\",\"url\":\"https://www.semanticscholar.org/paper/6855ed66c8a8643aa287078a130308e4a045d288\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29326440\",\"name\":\"A. Roy\"}],\"doi\":\"10.15167/ROY-ABHINABA_PHD2019-02-21\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c0c43e113d7ae99e763ea09dac97ba115d9e54bb\",\"title\":\"Data Driven Approaches for Image & Video Understanding: from Traditional to Zero-shot Supervised Learning\",\"url\":\"https://www.semanticscholar.org/paper/c0c43e113d7ae99e763ea09dac97ba115d9e54bb\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1811.10636\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"145426908\",\"name\":\"A. Angelova\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1109/ICCV.2019.00188\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"793ba81fa3bc728e9e35e0f82a8c4286d61d3aff\",\"title\":\"Evolving Space-Time Neural Architectures for Videos\",\"url\":\"https://www.semanticscholar.org/paper/793ba81fa3bc728e9e35e0f82a8c4286d61d3aff\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"},{\"authorId\":\"1930068\",\"name\":\"Shao-Hang Hsieh\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1109/CVPR.2015.7298839\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0b1616a59df96d9e2fa2dd3b2e1fd7bed7719913\",\"title\":\"Can humans fly? Action understanding with multiple classes of actors\",\"url\":\"https://www.semanticscholar.org/paper/0b1616a59df96d9e2fa2dd3b2e1fd7bed7719913\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1888678\",\"name\":\"Miao Xin\"},{\"authorId\":\"46702644\",\"name\":\"H. Zhang\"},{\"authorId\":\"2512046\",\"name\":\"Helong Wang\"},{\"authorId\":\"145070659\",\"name\":\"M. Sun\"},{\"authorId\":\"144437722\",\"name\":\"D. Yuan\"}],\"doi\":\"10.1016/j.neucom.2015.09.112\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5aff9c4118b15c7fa8d9afdc1527bb608c667bd2\",\"title\":\"ARCH: Adaptive recurrent-convolutional hybrid networks for long-term action recognition\",\"url\":\"https://www.semanticscholar.org/paper/5aff9c4118b15c7fa8d9afdc1527bb608c667bd2\",\"venue\":\"Neurocomputing\",\"year\":2016},{\"arxivId\":\"1607.03827\",\"authors\":[{\"authorId\":\"3407285\",\"name\":\"Matthias Plappert\"},{\"authorId\":\"2545377\",\"name\":\"Christian Mandery\"},{\"authorId\":\"1722677\",\"name\":\"T. Asfour\"}],\"doi\":\"10.1089/big.2016.0028\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e738d166c72513feaede2e19b4e713fd410cfce8\",\"title\":\"The KIT Motion-Language Dataset\",\"url\":\"https://www.semanticscholar.org/paper/e738d166c72513feaede2e19b4e713fd410cfce8\",\"venue\":\"Big Data\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51247926\",\"name\":\"Ksenia Bittner\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2927aa7953121221aace875280c4742963e83248\",\"title\":\"Building information extraction and refinement from VHR satellite imagery using deep learning techniques\",\"url\":\"https://www.semanticscholar.org/paper/2927aa7953121221aace875280c4742963e83248\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2012.05438\",\"authors\":[{\"authorId\":\"1846789641\",\"name\":\"Maxat Alibayev\"},{\"authorId\":\"7818698\",\"name\":\"D. Paulius\"},{\"authorId\":\"143971676\",\"name\":\"Y. Sun\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"48fb5a24f32dd72b6f94c4cb079345ea5aeee9b7\",\"title\":\"Developing Motion Code Embedding for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/48fb5a24f32dd72b6f94c4cb079345ea5aeee9b7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1409955695\",\"name\":\"B. Chen\"},{\"authorId\":null,\"name\":\"Ahmed Ali-Eldin\"},{\"authorId\":null,\"name\":\"Prashant Shenoy\"},{\"authorId\":null,\"name\":\"Klara Nahrstedt\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4ee14c3b350a79b8be52edee96b412768d47f7d8\",\"title\":\"Real-time Spatio-Temporal Action Localization in 360 Videos\",\"url\":\"https://www.semanticscholar.org/paper/4ee14c3b350a79b8be52edee96b412768d47f7d8\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2031813950\",\"name\":\"Kent Wu\"},{\"authorId\":\"2031839518\",\"name\":\"Suzy He\"},{\"authorId\":\"3247498\",\"name\":\"G. Fernie\"},{\"authorId\":\"2702612\",\"name\":\"Atena Roshan Fekr\"}],\"doi\":\"10.3390/s20236883\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d4001fe6d384d2bc8ac1447021d34b07310c27f7\",\"title\":\"Deep Neural Network for Slip Detection on Ice Surface\",\"url\":\"https://www.semanticscholar.org/paper/d4001fe6d384d2bc8ac1447021d34b07310c27f7\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"2007.09933\",\"authors\":[{\"authorId\":\"30557120\",\"name\":\"Heeseung Kwon\"},{\"authorId\":\"16142867\",\"name\":\"Manjin Kim\"},{\"authorId\":\"2483916\",\"name\":\"Suha Kwak\"},{\"authorId\":\"72643925\",\"name\":\"Minsu Cho\"}],\"doi\":\"10.1007/978-3-030-58517-4_21\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b5be8a78db1631159500e7cee249729820e355b2\",\"title\":\"MotionSqueeze: Neural Motion Feature Learning for Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/b5be8a78db1631159500e7cee249729820e355b2\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31245648\",\"name\":\"M. Baba\"},{\"authorId\":\"3339145\",\"name\":\"V. Gui\"},{\"authorId\":\"1403664270\",\"name\":\"C. Cernazanu-Glavan\"},{\"authorId\":\"3204022\",\"name\":\"D. Pescaru\"}],\"doi\":\"10.3390/s19071676\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e8beb7bb8d4e27adcbf95052d695328d71863e79\",\"title\":\"A Sensor Network Approach for Violence Detection in Smart Cities Using Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/e8beb7bb8d4e27adcbf95052d695328d71863e79\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"80558539\",\"name\":\"Yanhua Yang\"},{\"authorId\":\"2059283\",\"name\":\"Ruishan Liu\"},{\"authorId\":\"145102437\",\"name\":\"Cheng Deng\"},{\"authorId\":\"10699750\",\"name\":\"X. Gao\"}],\"doi\":\"10.1016/j.sigpro.2015.10.035\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"26916e0a03d920be83ad77a3c26bcfe3c0b6c244\",\"title\":\"Multi-task human action recognition via exploring super-category\",\"url\":\"https://www.semanticscholar.org/paper/26916e0a03d920be83ad77a3c26bcfe3c0b6c244\",\"venue\":\"Signal Process.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144289594\",\"name\":\"C. Caetano\"},{\"authorId\":\"6141311\",\"name\":\"J. A. D. Santos\"},{\"authorId\":\"9385043\",\"name\":\"W. Schwartz\"}],\"doi\":\"10.5220/0006615803010308\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"856b27626f9e5daab00c965109da5f687198e75d\",\"title\":\"Statistical Measures from Co-occurrence of Codewords for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/856b27626f9e5daab00c965109da5f687198e75d\",\"venue\":\"VISIGRAPP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9649314\",\"name\":\"Sheeraz Arif\"},{\"authorId\":\"49605422\",\"name\":\"Jing Wang\"},{\"authorId\":\"4869835\",\"name\":\"T. Hassan\"},{\"authorId\":\"144506604\",\"name\":\"Z. Fei\"}],\"doi\":\"10.3390/fi11020042\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"74aafcf3d7ddfdc0d099269e2335b64bc83f7f2b\",\"title\":\"3D-CNN-Based Fused Feature Maps with LSTM Applied to Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/74aafcf3d7ddfdc0d099269e2335b64bc83f7f2b\",\"venue\":\"Future Internet\",\"year\":2019},{\"arxivId\":\"1807.00230\",\"authors\":[{\"authorId\":\"3443095\",\"name\":\"Bruno Korbar\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2e057a9b195f0ea2d1c5a1e88ff9606f9b67ef8b\",\"title\":\"Cooperative Learning of Audio and Video Models from Self-Supervised Synchronization\",\"url\":\"https://www.semanticscholar.org/paper/2e057a9b195f0ea2d1c5a1e88ff9606f9b67ef8b\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Hao Wang\"},{\"authorId\":\"143730442\",\"name\":\"Yanhua Yang\"},{\"authorId\":\"3444345\",\"name\":\"Erkun Yang\"},{\"authorId\":\"145102437\",\"name\":\"Cheng Deng\"}],\"doi\":\"10.1007/s11042-017-4514-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e2faaebd17d10e2919bd69492787e7565546a63f\",\"title\":\"Exploring hybrid spatio-temporal convolutional networks for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/e2faaebd17d10e2919bd69492787e7565546a63f\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1706701\",\"name\":\"Changyu Liu\"},{\"authorId\":\"145281143\",\"name\":\"B. Lu\"},{\"authorId\":\"1780591\",\"name\":\"H. Li\"}],\"doi\":\"10.1155/2014/219732\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4e5dc3b397484326a4348ccceb88acf309960e86\",\"title\":\"Secure Access Control and Large Scale Robust Representation for Online Multimedia Event Detection\",\"url\":\"https://www.semanticscholar.org/paper/4e5dc3b397484326a4348ccceb88acf309960e86\",\"venue\":\"TheScientificWorldJournal\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2689633\",\"name\":\"Andrew Jaegle\"},{\"authorId\":\"144045396\",\"name\":\"S. Phillips\"},{\"authorId\":\"7975935\",\"name\":\"Daphne Ippolito\"},{\"authorId\":\"1751586\",\"name\":\"Kostas Daniilidis\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"869ef3835e5da24b4597a757948f1c0e19fa546d\",\"title\":\"Understanding image motion with group representations\",\"url\":\"https://www.semanticscholar.org/paper/869ef3835e5da24b4597a757948f1c0e19fa546d\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1411.6232\",\"authors\":[{\"authorId\":\"144950946\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1109/TNNLS.2016.2582746\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5906c81ad5ee9b2604f41224f30c59937aeb00e1\",\"title\":\"Semisupervised Feature Analysis by Mining Correlations Among Multiple Tasks\",\"url\":\"https://www.semanticscholar.org/paper/5906c81ad5ee9b2604f41224f30c59937aeb00e1\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2017},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1511.09319\",\"authors\":[{\"authorId\":\"2059950\",\"name\":\"Luca Del Pero\"},{\"authorId\":\"2262946\",\"name\":\"S. Ricco\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"143865718\",\"name\":\"V. Ferrari\"}],\"doi\":\"10.1007/s11263-016-0939-9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9e8bbf9ac3a114831fda40b0775cff44e6b0aed7\",\"title\":\"Behavior Discovery and Alignment of Articulated Object Classes from Unstructured Video\",\"url\":\"https://www.semanticscholar.org/paper/9e8bbf9ac3a114831fda40b0775cff44e6b0aed7\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":\"1706.07525\",\"authors\":[{\"authorId\":\"3151995\",\"name\":\"Hemanth Venkateswara\"},{\"authorId\":\"2929090\",\"name\":\"Prasanth Lade\"},{\"authorId\":\"144030870\",\"name\":\"Jieping Ye\"},{\"authorId\":\"1743991\",\"name\":\"S. Panchanathan\"}],\"doi\":\"10.1145/2733373.2806334\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"998911a52d0bc6d1d294c92373023df90da338ea\",\"title\":\"Coupled Support Vector Machines for Supervised Domain Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/998911a52d0bc6d1d294c92373023df90da338ea\",\"venue\":\"ACM Multimedia\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"82702431\",\"name\":\"Xiongli Chai\"},{\"authorId\":\"143749716\",\"name\":\"Feng Shao\"}],\"doi\":\"10.1016/j.ijleo.2020.165887\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c3bd832b5d4f1af0038a1a93dcac8d4e39f0115f\",\"title\":\"Blind quality assessment of omnidirectional videos using spatio-temporal convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/c3bd832b5d4f1af0038a1a93dcac8d4e39f0115f\",\"venue\":\"\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1915129\",\"name\":\"Tomasz Boinski\"},{\"authorId\":\"31611204\",\"name\":\"J. Szymanski\"}],\"doi\":\"10.1007/978-3-030-47679-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2d84127958efd69527b7a045679fd7d7540864f8\",\"title\":\"Computer Information Systems and Industrial Management: 19th International Conference, CISIM 2020, Bialystok, Poland, October 16\\u201318, 2020, Proceedings\",\"url\":\"https://www.semanticscholar.org/paper/2d84127958efd69527b7a045679fd7d7540864f8\",\"venue\":\"CISIM\",\"year\":2020},{\"arxivId\":\"2011.12619\",\"authors\":[{\"authorId\":\"147084112\",\"name\":\"Jack Humphreys\"},{\"authorId\":\"48354826\",\"name\":\"Z. Chen\"},{\"authorId\":\"145047838\",\"name\":\"Dacheng Tao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e88bff50c417703239e0a832fddb267196ab5a99\",\"title\":\"Recent Progress in Appearance-based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e88bff50c417703239e0a832fddb267196ab5a99\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2244863\",\"name\":\"X. Zhang\"},{\"authorId\":\"1715708\",\"name\":\"Yaping Huang\"},{\"authorId\":\"2035596033\",\"name\":\"Yang Mi\"},{\"authorId\":\"80996783\",\"name\":\"Yanting Pei\"},{\"authorId\":\"2196589\",\"name\":\"Qi Zou\"},{\"authorId\":\"40696794\",\"name\":\"Song Wang\"}],\"doi\":\"10.1007/s10489-020-01905-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ffd6d8c2f114895c3506b8326a0fdb6b8728e901\",\"title\":\"Video sketch: A middle-level representation for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/ffd6d8c2f114895c3506b8326a0fdb6b8728e901\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3287750\",\"name\":\"Tan Yu\"},{\"authorId\":\"71530731\",\"name\":\"J. Meng\"},{\"authorId\":\"49479171\",\"name\":\"Chen Fang\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"48837492\",\"name\":\"J. Yuan\"}],\"doi\":\"10.1007/s11263-020-01326-x\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"291fe2de592e1f827e44c5226b9decfa45c3f28e\",\"title\":\"Product Quantization Network for Fast Visual Search\",\"url\":\"https://www.semanticscholar.org/paper/291fe2de592e1f827e44c5226b9decfa45c3f28e\",\"venue\":\"International Journal of Computer Vision\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144057634\",\"name\":\"A. Mishra\"},{\"authorId\":\"4243661\",\"name\":\"Anubha Pandey\"},{\"authorId\":\"1726726\",\"name\":\"H. Murthy\"}],\"doi\":\"10.1016/j.neucom.2020.01.078\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"72a270fb8f6d4f3653539a4905e7a5d29632f81f\",\"title\":\"Zero-shot learning for action recognition using synthesized features\",\"url\":\"https://www.semanticscholar.org/paper/72a270fb8f6d4f3653539a4905e7a5d29632f81f\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144350339\",\"name\":\"Chirag I. Patel\"},{\"authorId\":\"2042647646\",\"name\":\"Dileep Labana\"},{\"authorId\":\"47706103\",\"name\":\"S. Pandya\"},{\"authorId\":\"3438822\",\"name\":\"Kirit Modi\"},{\"authorId\":\"3424424\",\"name\":\"H. Ghayvat\"},{\"authorId\":\"1622021877\",\"name\":\"Muhammad Awais\"}],\"doi\":\"10.3390/s20247299\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3fa0ad0a0e3779516e5a9cb74fc40b872448b232\",\"title\":\"Histogram of Oriented Gradient-Based Fusion of Features for Human Action Recognition in Action Video Sequences\",\"url\":\"https://www.semanticscholar.org/paper/3fa0ad0a0e3779516e5a9cb74fc40b872448b232\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":\"2876552\",\"name\":\"Changqing Zou\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"143740449\",\"name\":\"Q. Peng\"}],\"doi\":\"10.1007/978-3-319-10602-1_38\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"34f2f2dbaca68eb05426b51620673e71b69e1b37\",\"title\":\"Action Recognition with Stacked Fisher Vectors\",\"url\":\"https://www.semanticscholar.org/paper/34f2f2dbaca68eb05426b51620673e71b69e1b37\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145952624\",\"name\":\"A. Ara\\u00fajo\"},{\"authorId\":\"50544593\",\"name\":\"J. Chaves\"},{\"authorId\":\"12600623\",\"name\":\"D. Chen\"},{\"authorId\":\"2746423\",\"name\":\"R. Angst\"},{\"authorId\":\"1739786\",\"name\":\"B. Girod\"}],\"doi\":\"10.1145/2713168.2713197\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"07f0b638b2109c19d18e89c5bc74ded73cb2117f\",\"title\":\"Stanford I2V: a news video dataset for query-by-image experiments\",\"url\":\"https://www.semanticscholar.org/paper/07f0b638b2109c19d18e89c5bc74ded73cb2117f\",\"venue\":\"MMSys\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3260425\",\"name\":\"Shijian Huang\"},{\"authorId\":\"2852884\",\"name\":\"Junyong Ye\"},{\"authorId\":\"46958452\",\"name\":\"TongQing Wang\"},{\"authorId\":\"144740190\",\"name\":\"L. Jiang\"},{\"authorId\":\"3728865\",\"name\":\"X. Wu\"},{\"authorId\":\"31735819\",\"name\":\"Y. Li\"}],\"doi\":\"10.1007/S13369-015-1635-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c0d283688b611b9547b4bb9f28cb88e708e0bde6\",\"title\":\"Extracting Refined Low-Rank Features of Robust PCA for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c0d283688b611b9547b4bb9f28cb88e708e0bde6\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"2012.11866\",\"authors\":[{\"authorId\":\"2595189\",\"name\":\"Zehua Sun\"},{\"authorId\":\"120809631\",\"name\":\"Jiwang Liu\"},{\"authorId\":\"143969578\",\"name\":\"Qiuhong Ke\"},{\"authorId\":\"1877377\",\"name\":\"H. Rahmani\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"816236bf3219363bfe4b847363e137b1fe6712e7\",\"title\":\"Human Action Recognition from Various Data Modalities: A Review\",\"url\":\"https://www.semanticscholar.org/paper/816236bf3219363bfe4b847363e137b1fe6712e7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3280656\",\"name\":\"Litao Yu\"}],\"doi\":\"10.14264/uql.2016.574\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2534d1147b89fe687092310ef77eefff41d9507f\",\"title\":\"Effective multimedia event analysis in large-scale videos\",\"url\":\"https://www.semanticscholar.org/paper/2534d1147b89fe687092310ef77eefff41d9507f\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51046192\",\"name\":\"Yixiong Zou\"},{\"authorId\":\"38179026\",\"name\":\"Y. Shi\"},{\"authorId\":\"5765799\",\"name\":\"Yaowei Wang\"},{\"authorId\":\"143672707\",\"name\":\"Y. Shu\"},{\"authorId\":\"3330973\",\"name\":\"Qingsheng Yuan\"},{\"authorId\":\"40161651\",\"name\":\"Yonghong Tian\"}],\"doi\":\"10.1109/ICME.2018.8486447\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"9d530c341b3eda84c0b0a2c3149232daf16056f4\",\"title\":\"Hierarchical Temporal Memory Enhanced One-Shot Distance Learning for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9d530c341b3eda84c0b0a2c3149232daf16056f4\",\"venue\":\"2018 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1566489065\",\"name\":\"Yukun Huang\"},{\"authorId\":\"2425471\",\"name\":\"Yongcai Guo\"},{\"authorId\":\"153686290\",\"name\":\"C. Gao\"}],\"doi\":\"10.1109/ACCESS.2020.2978223\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dd59c68dc58e350b51288d2b6ee6d5ea52ad9f84\",\"title\":\"Efficient Parallel Inflated 3D Convolution Architecture for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/dd59c68dc58e350b51288d2b6ee6d5ea52ad9f84\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1908.00347\",\"authors\":[{\"authorId\":\"1557282756\",\"name\":\"Li Yuan\"},{\"authorId\":\"72259333\",\"name\":\"Tao Wang\"},{\"authorId\":\"21458018\",\"name\":\"Xiaopeng Zhang\"},{\"authorId\":\"40983412\",\"name\":\"F. Tay\"},{\"authorId\":\"2750647\",\"name\":\"Zequn Jie\"},{\"authorId\":\"40584023\",\"name\":\"Wei Liu\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6c28f774aa1d085df5ae08d105a5b74fcd3de6dc\",\"title\":\"Central Similarity Hashing for Efficient Image and Video Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/6c28f774aa1d085df5ae08d105a5b74fcd3de6dc\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3056962\",\"name\":\"Shujon Naha\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"98191fa24f7ebcb4715c1e6a30198bfc6e56ab4e\",\"title\":\"Zero-shot Learning for Visual Recognition Problems\",\"url\":\"https://www.semanticscholar.org/paper/98191fa24f7ebcb4715c1e6a30198bfc6e56ab4e\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Roshan Rane\"},{\"authorId\":\"150333998\",\"name\":\"Vageesh Saxena\"},{\"authorId\":\"150096315\",\"name\":\"Edit Sz\\u00fcgyi\"},{\"authorId\":\"35280884\",\"name\":\"Andr\\u00e9 Ofner\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e78232f23508b879c6c5ae372030487ed071ca1f\",\"title\":\"Video Action Classification Using Deep Predictive Coding Networks\",\"url\":\"https://www.semanticscholar.org/paper/e78232f23508b879c6c5ae372030487ed071ca1f\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1722052\",\"name\":\"Thomas Mensink\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"deac0e8c340c63f3a9434f88f20349321b161a74\",\"title\":\"UvA-DARE ( Digital Academic Repository ) Objects 2 action : Classifying and localizing actions without\",\"url\":\"https://www.semanticscholar.org/paper/deac0e8c340c63f3a9434f88f20349321b161a74\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Teng Zhang\"},{\"authorId\":\"2499431\",\"name\":\"Liangchen Liu\"},{\"authorId\":\"2331880\",\"name\":\"A. Wiliem\"},{\"authorId\":\"144367279\",\"name\":\"B. Lovell\"}],\"doi\":\"10.1109/WACV.2016.7477710\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"16b8339211c737dcdf7edb9d8537df8deb3f08b9\",\"title\":\"Is alice chasing or being chased?: Determining subject and object of activities in videos\",\"url\":\"https://www.semanticscholar.org/paper/16b8339211c737dcdf7edb9d8537df8deb3f08b9\",\"venue\":\"2016 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143798882\",\"name\":\"Mihir Jain\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"14fa7093c03909760099a0f97a3c53c086fed2ef\",\"title\":\"Enhanced image and video representation for visual recognition\",\"url\":\"https://www.semanticscholar.org/paper/14fa7093c03909760099a0f97a3c53c086fed2ef\",\"venue\":\"\",\"year\":2014},{\"arxivId\":\"1511.04048\",\"authors\":[{\"authorId\":\"3012475\",\"name\":\"R. Mottaghi\"},{\"authorId\":\"2456400\",\"name\":\"Hessam Bagherinezhad\"},{\"authorId\":\"143887493\",\"name\":\"M. Rastegari\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"}],\"doi\":\"10.1109/CVPR.2016.383\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4aae4d3300179d180966ea9c116159469f69eb2d\",\"title\":\"Newtonian Image Understanding: Unfolding the Dynamics of Objects in Static Images\",\"url\":\"https://www.semanticscholar.org/paper/4aae4d3300179d180966ea9c116159469f69eb2d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yingying Wang\"},{\"authorId\":\"50135244\",\"name\":\"Wenjia Li\"},{\"authorId\":\"143677598\",\"name\":\"R. Tao\"}],\"doi\":\"10.1109/LSP.2019.2940111\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ab9b40a95e4b2328cb681de4413ba918a978ecff\",\"title\":\"Multi-Branch Spatial-Temporal Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ab9b40a95e4b2328cb681de4413ba918a978ecff\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2019},{\"arxivId\":\"2009.03281\",\"authors\":[{\"authorId\":\"118331199\",\"name\":\"Amgad Ahmed\"},{\"authorId\":\"66382400\",\"name\":\"Suhong Kim\"},{\"authorId\":\"1854465\",\"name\":\"M. Elgharib\"},{\"authorId\":\"144262128\",\"name\":\"Mohamed Hefeeda\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"610f4d97da504f5beb469d3939681d70676ca64f\",\"title\":\"User-assisted Video Reflection Removal\",\"url\":\"https://www.semanticscholar.org/paper/610f4d97da504f5beb469d3939681d70676ca64f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1904697\",\"name\":\"Zhenbing Liu\"},{\"authorId\":\"1796258521\",\"name\":\"Zeya Li\"},{\"authorId\":\"49908315\",\"name\":\"Ruili Wang\"},{\"authorId\":\"51251812\",\"name\":\"Ming Zong\"},{\"authorId\":\"29790429\",\"name\":\"Wanting Ji\"}],\"doi\":\"10.1007/s00521-020-05144-7\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"575448ab04aef0856a73d8eba3a75a5321e0506d\",\"title\":\"Spatiotemporal saliency-based multi-stream networks with attention-aware LSTM for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/575448ab04aef0856a73d8eba3a75a5321e0506d\",\"venue\":\"Neural Computing and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1941827\",\"name\":\"I. Rodomagoulakis\"},{\"authorId\":\"3493540\",\"name\":\"N. Kardaris\"},{\"authorId\":\"1738119\",\"name\":\"Vassilis Pitsikalis\"},{\"authorId\":\"145702264\",\"name\":\"E. Mavroudi\"},{\"authorId\":\"2243473\",\"name\":\"Athanasios Katsamanis\"},{\"authorId\":\"3200442\",\"name\":\"A. Tsiami\"},{\"authorId\":\"1750686\",\"name\":\"P. Maragos\"}],\"doi\":\"10.1109/ICASSP.2016.7472168\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7a70cc84bb3422381e3f5e3ffdfcbd4af0566b5c\",\"title\":\"Multimodal human action recognition in assistive human-robot interaction\",\"url\":\"https://www.semanticscholar.org/paper/7a70cc84bb3422381e3f5e3ffdfcbd4af0566b5c\",\"venue\":\"2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48333400\",\"name\":\"S. Yamamoto\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.1145/2964284.2967287\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b54fe193b6faf228e5ffc4b88818d6aa234b5bb9\",\"title\":\"Video Generation Using 3D Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/b54fe193b6faf228e5ffc4b88818d6aa234b5bb9\",\"venue\":\"ACM Multimedia\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31933147\",\"name\":\"F. Romano\"},{\"authorId\":\"40555175\",\"name\":\"G. Nava\"},{\"authorId\":\"2222420\",\"name\":\"M. Azad\"},{\"authorId\":\"5106646\",\"name\":\"Jernej \\u010camernik\"},{\"authorId\":\"8458022\",\"name\":\"Stefano Dafarra\"},{\"authorId\":\"3470995\",\"name\":\"Oriane Dermy\"},{\"authorId\":\"49897080\",\"name\":\"Claudia Latella\"},{\"authorId\":\"47424488\",\"name\":\"M. Lazzaroni\"},{\"authorId\":\"34816416\",\"name\":\"R. Lober\"},{\"authorId\":\"31153432\",\"name\":\"M. Lorenzini\"},{\"authorId\":\"2202742\",\"name\":\"Daniele Pucci\"},{\"authorId\":\"3211142\",\"name\":\"Olivier Sigaud\"},{\"authorId\":\"2255650\",\"name\":\"Silvio Traversaro\"},{\"authorId\":\"49499963\",\"name\":\"J. Babi\\u010d\"},{\"authorId\":\"1763452\",\"name\":\"S. Ivaldi\"},{\"authorId\":\"1687582\",\"name\":\"Michael N. Mistry\"},{\"authorId\":\"48192535\",\"name\":\"V. Padois\"},{\"authorId\":\"1692768\",\"name\":\"F. Nori\"}],\"doi\":\"10.1109/LRA.2017.2768126\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2198a7d745a2185e05ef6a946e216a68065e1865\",\"title\":\"The CoDyCo Project Achievements and Beyond: Toward Human Aware Whole-Body Controllers for Physical Human Robot Interaction\",\"url\":\"https://www.semanticscholar.org/paper/2198a7d745a2185e05ef6a946e216a68065e1865\",\"venue\":\"IEEE Robotics and Automation Letters\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"95906612\",\"name\":\"D. Purwanto\"},{\"authorId\":\"150282005\",\"name\":\"Rizard Renanda Adhi Pramono\"},{\"authorId\":\"30477181\",\"name\":\"Yie-Tarng Chen\"},{\"authorId\":\"122315920\",\"name\":\"Wen-Hsien Fang\"}],\"doi\":\"10.1109/ICCVW.2019.00125\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2a160c956afc22ad837e61f865eb80169bd12259\",\"title\":\"Extreme Low Resolution Action Recognition with Spatial-Temporal Multi-Head Self-Attention and Knowledge Distillation\",\"url\":\"https://www.semanticscholar.org/paper/2a160c956afc22ad837e61f865eb80169bd12259\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145075206\",\"name\":\"M. Huang\"},{\"authorId\":\"1900810\",\"name\":\"Guo-Rong Cai\"},{\"authorId\":\"2196194\",\"name\":\"H. Zhang\"},{\"authorId\":\"1686715\",\"name\":\"S. Yu\"},{\"authorId\":\"41135049\",\"name\":\"Dong-Ying Gong\"},{\"authorId\":\"38187621\",\"name\":\"D. Cao\"},{\"authorId\":\"8086812\",\"name\":\"Shaozi Li\"},{\"authorId\":\"8143876\",\"name\":\"Songzhi Su\"}],\"doi\":\"10.1016/j.neucom.2018.02.056\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9577c5d16a95e7e9d0d7cbae01dccdc8ab076c6a\",\"title\":\"Discriminative parts learning for 3D human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/9577c5d16a95e7e9d0d7cbae01dccdc8ab076c6a\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":\"1806.08251\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1109/WACV45572.2020.9093612\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"dbbcf8af70db7533f76e8e55f108fcc6af6e0c0e\",\"title\":\"Learning Multimodal Representations for Unseen Activities\",\"url\":\"https://www.semanticscholar.org/paper/dbbcf8af70db7533f76e8e55f108fcc6af6e0c0e\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51001584\",\"name\":\"Hyung-min Lee\"},{\"authorId\":\"153481384\",\"name\":\"Il-Koo Kim\"}],\"doi\":\"10.1109/IJCNN.2019.8851892\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b89d030332f7ff66ef270160dfc93e6b3122f34b\",\"title\":\"Generating Natural Video Descriptions using Semantic Gate\",\"url\":\"https://www.semanticscholar.org/paper/b89d030332f7ff66ef270160dfc93e6b3122f34b\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2145942\",\"name\":\"Allah Bux Sargano\"},{\"authorId\":\"4509077\",\"name\":\"Xiaowei Gu\"},{\"authorId\":\"1719855\",\"name\":\"P. Angelov\"},{\"authorId\":\"152734957\",\"name\":\"Zulfiqar Habib\"}],\"doi\":\"10.1007/s11042-020-09381-9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8973f6d988c7868d8d78ea3f13dc0604ac356e65\",\"title\":\"Human action recognition using deep rule-based classifier\",\"url\":\"https://www.semanticscholar.org/paper/8973f6d988c7868d8d78ea3f13dc0604ac356e65\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40547902\",\"name\":\"L. M. Dang\"},{\"authorId\":\"114915097\",\"name\":\"Kyungbok Min\"},{\"authorId\":\"1878085541\",\"name\":\"Hanxiang Wang\"},{\"authorId\":\"27648067\",\"name\":\"Md. Jalil Piran\"},{\"authorId\":\"115465984\",\"name\":\"Cheol Hee Lee\"},{\"authorId\":\"73078584\",\"name\":\"Hyeonjoon Moon\"}],\"doi\":\"10.1016/j.patcog.2020.107561\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5b6936905a1fcef9af31bdab49ec99581c03fd83\",\"title\":\"Sensor-based and vision-based human activity recognition: A comprehensive survey\",\"url\":\"https://www.semanticscholar.org/paper/5b6936905a1fcef9af31bdab49ec99581c03fd83\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2320984\",\"name\":\"Junwei Jin\"},{\"authorId\":\"47003203\",\"name\":\"Y. Li\"},{\"authorId\":null,\"name\":\"Lijun Sun\"},{\"authorId\":\"8694336\",\"name\":\"Jianyu Miao\"},{\"authorId\":\"1491249454\",\"name\":\"C. Chen\"}],\"doi\":\"10.1109/ACCESS.2020.2989452\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1f698dcbb72a77ca4f46413ef2eef01a2685d645\",\"title\":\"A New Local Knowledge-Based Collaborative Representation for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1f698dcbb72a77ca4f46413ef2eef01a2685d645\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1608.00859\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-319-46484-8_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"title\":\"Temporal Segment Networks: Towards Good Practices for Deep Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"31493847\",\"name\":\"A. H. Karami\"},{\"authorId\":\"2713759\",\"name\":\"M. M. Arzani\"},{\"authorId\":\"9456273\",\"name\":\"Rahman Yousefzadeh\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"92679c8cff92442f39de3405c21c8028162fe56a\",\"title\":\"Temporal 3D ConvNets Using Temporal Transition Layer\",\"url\":\"https://www.semanticscholar.org/paper/92679c8cff92442f39de3405c21c8028162fe56a\",\"venue\":\"CVPR Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2482072\",\"name\":\"Nicolas Ballas\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"34692532\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"11127101\",\"name\":\"Betrand Delezoide\"},{\"authorId\":\"113805643\",\"name\":\"Francoise Pr\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1058c578b0d8b1326bbd1b9059a6d73b39c2bba5\",\"title\":\"Space-Time Robust Video Representation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1058c578b0d8b1326bbd1b9059a6d73b39c2bba5\",\"venue\":\"\",\"year\":2013},{\"arxivId\":\"1707.04555\",\"authors\":[{\"authorId\":\"50984378\",\"name\":\"F. Li\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"48033101\",\"name\":\"Xiao Liu\"},{\"authorId\":\"38812373\",\"name\":\"Yunlong Bian\"},{\"authorId\":\"144858226\",\"name\":\"Xiang Long\"},{\"authorId\":\"48515099\",\"name\":\"Y. Li\"},{\"authorId\":\"46948074\",\"name\":\"Zhichao Li\"},{\"authorId\":null,\"name\":\"Jie Zhou\"},{\"authorId\":\"35247507\",\"name\":\"Shilei Wen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"90bec6f106f6d8d60cd939d594568bfc0f1393d9\",\"title\":\"Temporal Modeling Approaches for Large-scale Youtube-8M Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/90bec6f106f6d8d60cd939d594568bfc0f1393d9\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3367041\",\"name\":\"Himanshu Buckchash\"},{\"authorId\":\"1796442\",\"name\":\"B. Raman\"}],\"doi\":\"10.1007/978-3-030-34869-4_16\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0739a0b547ad3b50289b012d4e34bf44e577541f\",\"title\":\"Sustained Self-Supervised Pretraining for Temporal Order Verification\",\"url\":\"https://www.semanticscholar.org/paper/0739a0b547ad3b50289b012d4e34bf44e577541f\",\"venue\":\"PReMI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145987219\",\"name\":\"Y. Tian\"},{\"authorId\":\"144695333\",\"name\":\"Q. Ruan\"},{\"authorId\":\"2896701\",\"name\":\"G. An\"}],\"doi\":\"10.1109/ICSP.2018.8652306\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0e50cbd929432ed22b7d81165f177e3135951d77\",\"title\":\"Zero-shot Action Recognition via Empirical Maximum Mean Discrepancy\",\"url\":\"https://www.semanticscholar.org/paper/0e50cbd929432ed22b7d81165f177e3135951d77\",\"venue\":\"2018 14th IEEE International Conference on Signal Processing (ICSP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2845745\",\"name\":\"Sovan Biswas\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"be21cd7fae28f04871ae69e5167fb676ee17a08a\",\"title\":\"Motion Based Event Analysis\",\"url\":\"https://www.semanticscholar.org/paper/be21cd7fae28f04871ae69e5167fb676ee17a08a\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144082425\",\"name\":\"L. Shao\"},{\"authorId\":\"34798935\",\"name\":\"Xiantong Zhen\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"},{\"authorId\":\"1720243\",\"name\":\"X. Li\"}],\"doi\":\"10.1109/TCYB.2013.2273174\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b60a6c16399cc0e5ce2d7b117807854891042de4\",\"title\":\"Spatio-Temporal Laplacian Pyramid Coding for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b60a6c16399cc0e5ce2d7b117807854891042de4\",\"venue\":\"IEEE Transactions on Cybernetics\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36794849\",\"name\":\"L. Zhang\"},{\"authorId\":\"46749270\",\"name\":\"Yangyang Feng\"},{\"authorId\":\"1718376\",\"name\":\"Jiqing Han\"},{\"authorId\":\"34798935\",\"name\":\"Xiantong Zhen\"}],\"doi\":\"10.1109/ICASSP.2016.7471897\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5738bb6ad67849ab142397e88fb377be824c2391\",\"title\":\"Realistic human action recognition: When deep learning meets VLAD\",\"url\":\"https://www.semanticscholar.org/paper/5738bb6ad67849ab142397e88fb377be824c2391\",\"venue\":\"2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50006507\",\"name\":\"Yanli Ji\"},{\"authorId\":\"49338773\",\"name\":\"Y. Zhan\"},{\"authorId\":\"27718163\",\"name\":\"Y. Yang\"},{\"authorId\":\"1410252832\",\"name\":\"Xing Xu\"},{\"authorId\":\"38083193\",\"name\":\"F. Shen\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1109/TIP.2019.2952088\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ac2b6006886e6693ce85a5c935abceef90ae3b89\",\"title\":\"A Context Knowledge Map Guided Coarse-to-Fine Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ac2b6006886e6693ce85a5c935abceef90ae3b89\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36475565\",\"name\":\"Yang Cai\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"},{\"authorId\":\"1679880\",\"name\":\"H. Wactlar\"}],\"doi\":\"10.1145/2505323.2505334\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"493dfe59cf77cf6a95f8f33e3e48af0d3bba3d24\",\"title\":\"A cognitive assistive system for monitoring the use of home medical devices\",\"url\":\"https://www.semanticscholar.org/paper/493dfe59cf77cf6a95f8f33e3e48af0d3bba3d24\",\"venue\":\"MIIRH '13\",\"year\":2013},{\"arxivId\":\"1412.1194\",\"authors\":[{\"authorId\":\"145327729\",\"name\":\"Feng Shi\"},{\"authorId\":\"2035718\",\"name\":\"R. Lagani\\u00e8re\"},{\"authorId\":\"1745632\",\"name\":\"E. Petriu\"}],\"doi\":\"10.1109/WACV.2015.152\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8458edb8b74003a50de006eb99982f0b30e09245\",\"title\":\"Gradient Boundary Histograms for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8458edb8b74003a50de006eb99982f0b30e09245\",\"venue\":\"2015 IEEE Winter Conference on Applications of Computer Vision\",\"year\":2015},{\"arxivId\":\"1802.02522\",\"authors\":[{\"authorId\":\"26902477\",\"name\":\"Amir Rasouli\"},{\"authorId\":\"1727853\",\"name\":\"John K. Tsotsos\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6270914cf5f60627a1332bcc3f5951c9eea3be0\",\"title\":\"Joint Attention in Driver-Pedestrian Interaction: from Theory to Practice\",\"url\":\"https://www.semanticscholar.org/paper/a6270914cf5f60627a1332bcc3f5951c9eea3be0\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1509.01074\",\"authors\":[{\"authorId\":\"40360970\",\"name\":\"A. Mohamed\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c37a971f7a57f7345fdc479fa329d9b425ee02be\",\"title\":\"A Novice Guide towards Human Motion Analysis and Understanding\",\"url\":\"https://www.semanticscholar.org/paper/c37a971f7a57f7345fdc479fa329d9b425ee02be\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"2012.05342\",\"authors\":[{\"authorId\":\"145580092\",\"name\":\"Pierre-Etienne Martin\"},{\"authorId\":\"1401651727\",\"name\":\"J. Benois-Pineau\"},{\"authorId\":\"1639895183\",\"name\":\"Renaud P\\u00e9teri\"},{\"authorId\":\"1639983772\",\"name\":\"Julien Morlier\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4c6b7bc12da85925efeb297cadf0a47c6c6ec7ea\",\"title\":\"3D attention mechanism for fine-grained classification of table tennis strokes using a Twin Spatio-Temporal Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/4c6b7bc12da85925efeb297cadf0a47c6c6ec7ea\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1504.00983\",\"authors\":[{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"152821938\",\"name\":\"Sanketh Shetty\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1145/2733373.2806226\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3634b4dd263c0f330245c086ce646c9bb748cd6b\",\"title\":\"Temporal Localization of Fine-Grained Actions in Videos by Domain Transfer from Web Images\",\"url\":\"https://www.semanticscholar.org/paper/3634b4dd263c0f330245c086ce646c9bb748cd6b\",\"venue\":\"ACM Multimedia\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144907434\",\"name\":\"T. Kobayashi\"}],\"doi\":\"10.1007/s00138-016-0780-8\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a38ed94dff916a872c340823afd54b3b39ace7ef\",\"title\":\"Discriminative local binary pattern\",\"url\":\"https://www.semanticscholar.org/paper/a38ed94dff916a872c340823afd54b3b39ace7ef\",\"venue\":\"Machine Vision and Applications\",\"year\":2016},{\"arxivId\":\"1609.05420\",\"authors\":[{\"authorId\":\"3234247\",\"name\":\"Senthil Purushwalkam\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a69099ad60804816d1c2d884d4844105b0480082\",\"title\":\"Pose from Action: Unsupervised Learning of Pose Features based on Motion\",\"url\":\"https://www.semanticscholar.org/paper/a69099ad60804816d1c2d884d4844105b0480082\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1804.04326\",\"authors\":[{\"authorId\":\"31678456\",\"name\":\"Y. Yoshikawa\"},{\"authorId\":\"2996464\",\"name\":\"Jiaqing Lin\"},{\"authorId\":\"39702069\",\"name\":\"A. Takeuchi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d3f5a1848b0028d8ab51d0b0673732cad2e3c8c9\",\"title\":\"STAIR Actions: A Video Dataset of Everyday Home Actions\",\"url\":\"https://www.semanticscholar.org/paper/d3f5a1848b0028d8ab51d0b0673732cad2e3c8c9\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1694599\",\"name\":\"L. Akarun\"},{\"authorId\":\"1793947\",\"name\":\"Y. Akg\\u00fcl\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"80135ed7e34ac1dcc7f858f880edc699a920bf53\",\"title\":\"EFFICIENT ACTION AND EVENT RECOGNITION IN VIDEOS USING EXTREME LEARNING MACHINES\",\"url\":\"https://www.semanticscholar.org/paper/80135ed7e34ac1dcc7f858f880edc699a920bf53\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49340052\",\"name\":\"L. Belhadj\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a5dfcee6042427dfaf445bb3452eccae4cfc4b42\",\"title\":\"Reconnaissance des actions humaines : m\\u00e9thode bas\\u00e9e sur la r\\u00e9duction de dimensionnalit\\u00e9 par MDS spatio-temporelle\",\"url\":\"https://www.semanticscholar.org/paper/a5dfcee6042427dfaf445bb3452eccae4cfc4b42\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37433719\",\"name\":\"Arthur Truong\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"17af83bf55d5a805bf634b8a8b2fd5b03fa090d9\",\"title\":\"Analyse du contenu expressif des gestes corporels\",\"url\":\"https://www.semanticscholar.org/paper/17af83bf55d5a805bf634b8a8b2fd5b03fa090d9\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2121584\",\"name\":\"Wangjiang Zhu\"},{\"authorId\":\"145815850\",\"name\":\"Jie Hu\"},{\"authorId\":\"143847421\",\"name\":\"Gang Sun\"},{\"authorId\":\"47300766\",\"name\":\"X. Cao\"},{\"authorId\":\"143970608\",\"name\":\"Y. Qiao\"}],\"doi\":\"10.1109/CVPR.2016.219\",\"intent\":[\"methodology\",\"result\"],\"isInfluential\":false,\"paperId\":\"4c822785c29ceaf67a0de9c699716c94fefbd37d\",\"title\":\"A Key Volume Mining Deep Framework for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4c822785c29ceaf67a0de9c699716c94fefbd37d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"93318099\",\"name\":\"J. Lin\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1dc7454bacae9a949db38b8306bd7c4df855fa1c\",\"title\":\"TSM: Temporal Shift Module for Efficient Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/1dc7454bacae9a949db38b8306bd7c4df855fa1c\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3114252\",\"name\":\"O. Sener\"}],\"doi\":\"10.7298/X47942ND\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cffebdf88e406c27b892857d1520cb2d7ccda573\",\"title\":\"Learning from large-scale visual data for robots\",\"url\":\"https://www.semanticscholar.org/paper/cffebdf88e406c27b892857d1520cb2d7ccda573\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Zheyuan Liu\"},{\"authorId\":\"9642011\",\"name\":\"Xiaoteng Zhang\"},{\"authorId\":\"33055674\",\"name\":\"L. Song\"},{\"authorId\":\"2261516\",\"name\":\"Zhengyan Ding\"},{\"authorId\":\"1730199\",\"name\":\"Huixian Duan\"}],\"doi\":\"10.1007/s10586-017-1309-2\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"3a67e45b7bd7d5113e1f3fc4a02d8db9579e321a\",\"title\":\"More efficient and effective tricks for deep action recognition\",\"url\":\"https://www.semanticscholar.org/paper/3a67e45b7bd7d5113e1f3fc4a02d8db9579e321a\",\"venue\":\"Cluster Computing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34539976\",\"name\":\"S. Santos\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"},{\"authorId\":\"23962586\",\"name\":\"J. Almeida\"}],\"doi\":\"10.1109/SIBGRAPI.2019.00012\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"41c21f12f6896c458004f26b1fd704f4058aaac1\",\"title\":\"CV-C3D: Action Recognition on Compressed Videos with Convolutional 3D Networks\",\"url\":\"https://www.semanticscholar.org/paper/41c21f12f6896c458004f26b1fd704f4058aaac1\",\"venue\":\"2019 32nd SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Sai Shashidhar Nagabandi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"bc3f9edf329b1db74fbe2b66b74d159be6f3b9ec\",\"title\":\"Self-Supervised Video Representation Learning by Recurrent Networks and Frame Order Prediction\",\"url\":\"https://www.semanticscholar.org/paper/bc3f9edf329b1db74fbe2b66b74d159be6f3b9ec\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144397879\",\"name\":\"S. N. Gowda\"}],\"doi\":\"10.1109/CVPRW.2017.203\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c9df46ca568e4feda02cbe7fe87f7184d3daa773\",\"title\":\"Human Activity Recognition Using Combinatorial Deep Belief Networks\",\"url\":\"https://www.semanticscholar.org/paper/c9df46ca568e4feda02cbe7fe87f7184d3daa773\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144543350\",\"name\":\"P. Dong\"},{\"authorId\":\"38158055\",\"name\":\"J. Li\"},{\"authorId\":\"1964397\",\"name\":\"J. Dong\"},{\"authorId\":\"145953636\",\"name\":\"L. Qi\"}],\"doi\":\"10.1117/12.2302485\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d852602cd18cf3859f92cf2178346e8c9860f7f1\",\"title\":\"Multi-dimension feature fusion for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/d852602cd18cf3859f92cf2178346e8c9860f7f1\",\"venue\":\"International Conference on Graphic and Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1799216\",\"name\":\"Jeong-Jik Seo\"},{\"authorId\":\"2645625\",\"name\":\"H. Kim\"},{\"authorId\":\"7627712\",\"name\":\"W. D. Neve\"},{\"authorId\":\"7251290\",\"name\":\"Yong Man Ro\"}],\"doi\":\"10.1016/j.imavis.2016.06.002\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e6c491fb6a57c9a7c2d71522a1a066be2e681c84\",\"title\":\"Effective and efficient human action recognition using dynamic frame skipping and trajectory rejection\",\"url\":\"https://www.semanticscholar.org/paper/e6c491fb6a57c9a7c2d71522a1a066be2e681c84\",\"venue\":\"Image Vis. Comput.\",\"year\":2017},{\"arxivId\":\"1911.11206\",\"authors\":[{\"authorId\":\"32486555\",\"name\":\"D. Epstein\"},{\"authorId\":\"8786274\",\"name\":\"Boyuan Chen\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"}],\"doi\":\"10.1109/cvpr42600.2020.00100\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2324d55ec54b9a12c4ac5353c51bcfa8440f7b6a\",\"title\":\"Oops! Predicting Unintentional Action in Video\",\"url\":\"https://www.semanticscholar.org/paper/2324d55ec54b9a12c4ac5353c51bcfa8440f7b6a\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1911.10751\",\"authors\":[{\"authorId\":\"46399266\",\"name\":\"Yang Liu\"},{\"authorId\":\"46950892\",\"name\":\"Zhao-yang Lu\"},{\"authorId\":\"46276828\",\"name\":\"J. Li\"},{\"authorId\":\"144954285\",\"name\":\"T. Yang\"},{\"authorId\":\"144299910\",\"name\":\"C. Yao\"}],\"doi\":\"10.1109/TIP.2019.2957930\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7cfd5817802102b0326243c95ebfe1c8e14427cd\",\"title\":\"Deep Image-to-Video Adaptation and Fusion Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7cfd5817802102b0326243c95ebfe1c8e14427cd\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144149597\",\"name\":\"Tianshu Yu\"},{\"authorId\":\"2180892\",\"name\":\"Yikang Li\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"}],\"doi\":\"10.1007/978-3-030-58607-2_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b9ff84d2d45ec704d5680119d0ea0faa01f016be\",\"title\":\"RhyRNN: Rhythmic RNN for Recognizing Events in Long and Complex Videos\",\"url\":\"https://www.semanticscholar.org/paper/b9ff84d2d45ec704d5680119d0ea0faa01f016be\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145014138\",\"name\":\"L. Qi\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"},{\"authorId\":\"50080046\",\"name\":\"X. Li\"}],\"doi\":\"10.1145/3271553.3271563\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"08410196627dfd16371d781a64e98573c54d07a4\",\"title\":\"Action Recognition by Jointly Using Video Proposal and Trajectory\",\"url\":\"https://www.semanticscholar.org/paper/08410196627dfd16371d781a64e98573c54d07a4\",\"venue\":\"ICVISP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1952002\",\"name\":\"A. Ranjan\"}],\"doi\":\"10.15496/PUBLIKATION-4524\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c3d7ebfa0199d7d49f4ca95b80fa136aafb43b88\",\"title\":\"Towards Geometric Understanding of Motion\",\"url\":\"https://www.semanticscholar.org/paper/c3d7ebfa0199d7d49f4ca95b80fa136aafb43b88\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50728221\",\"name\":\"Sahere Rahimi\"},{\"authorId\":\"2488201\",\"name\":\"A. Aghagolzadeh\"},{\"authorId\":\"46373568\",\"name\":\"M. Ezoji\"}],\"doi\":\"10.1016/j.eswa.2019.112927\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c001c621a0ce9e02c79dd79a5328af2fcbdcfd39\",\"title\":\"Human action recognition using double discriminative sparsity preserving projections and discriminant ridge-based classifier based on the GDWL-l1 graph\",\"url\":\"https://www.semanticscholar.org/paper/c001c621a0ce9e02c79dd79a5328af2fcbdcfd39\",\"venue\":\"Expert Syst. Appl.\",\"year\":2020},{\"arxivId\":\"1911.06644\",\"authors\":[{\"authorId\":\"41022447\",\"name\":\"Okan K\\u00f6p\\u00fckl\\u00fc\"},{\"authorId\":\"50652944\",\"name\":\"Xiangyu Wei\"},{\"authorId\":\"46343645\",\"name\":\"G. Rigoll\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"143059e7d17fd17c961a538ea98fadcf2667d5ca\",\"title\":\"You Only Watch Once: A Unified CNN Architecture for Real-Time Spatiotemporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/143059e7d17fd17c961a538ea98fadcf2667d5ca\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1912.07249\",\"authors\":[{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"3321919\",\"name\":\"Gr\\u00e9gory Rogez\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8dce5b1cc382f4a341f7ea43c6329c9e8acd202d\",\"title\":\"Mimetics: Towards Understanding Human Actions Out of Context\",\"url\":\"https://www.semanticscholar.org/paper/8dce5b1cc382f4a341f7ea43c6329c9e8acd202d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2006.00212\",\"authors\":[{\"authorId\":\"1560385163\",\"name\":\"Bo Pang\"},{\"authorId\":\"15376265\",\"name\":\"Kaiwen Zha\"},{\"authorId\":\"50732737\",\"name\":\"Hanwen Cao\"},{\"authorId\":\"152949394\",\"name\":\"J. Tang\"},{\"authorId\":\"50753313\",\"name\":\"Minghui Yu\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"}],\"doi\":\"10.1038/s42256-020-0168-3\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"86cc65a2b78f5ad9205faf0dba26b5f04d11126c\",\"title\":\"Complex sequential understanding through the awareness of spatial and temporal concepts\",\"url\":\"https://www.semanticscholar.org/paper/86cc65a2b78f5ad9205faf0dba26b5f04d11126c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1912.06606\",\"authors\":[{\"authorId\":\"1466503743\",\"name\":\"X. Ren\"},{\"authorId\":null,\"name\":\"Haoran Li\"},{\"authorId\":\"48783196\",\"name\":\"Zijian Huang\"},{\"authorId\":\"143832240\",\"name\":\"Qifeng Chen\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3803023eb13d986b8776d5856df70e801efd74da\",\"title\":\"Music-oriented Dance Video Synthesis with Pose Perceptual Loss\",\"url\":\"https://www.semanticscholar.org/paper/3803023eb13d986b8776d5856df70e801efd74da\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145397376\",\"name\":\"K. Naik\"},{\"authorId\":\"2000251565\",\"name\":\"A. Soni\"}],\"doi\":\"10.4018/978-1-7998-2795-5.ch001\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0cd0e438ca645078358ff7f434466ccdd88cd268\",\"title\":\"Video Classification Using 3D Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/0cd0e438ca645078358ff7f434466ccdd88cd268\",\"venue\":\"\",\"year\":2021},{\"arxivId\":\"2010.07217\",\"authors\":[{\"authorId\":\"2595119\",\"name\":\"X. Yang\"},{\"authorId\":\"1728108\",\"name\":\"M. Mirmehdi\"},{\"authorId\":\"1717278\",\"name\":\"T. Burghardt\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"af44b51ac01b2599961107a7a76a5892601c5f7c\",\"title\":\"Back to the Future: Cycle Encoding Prediction for Self-supervised Contrastive Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/af44b51ac01b2599961107a7a76a5892601c5f7c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31595791\",\"name\":\"J. Li\"},{\"authorId\":\"6820648\",\"name\":\"Xianglong Liu\"},{\"authorId\":\"150341144\",\"name\":\"Wenxuan Zhang\"},{\"authorId\":\"47473953\",\"name\":\"Mingyuan Zhang\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":\"10.1109/TMM.2020.2965434\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2ea173f972d39b8631e9ac8fe59a947c70ba31e3\",\"title\":\"Spatio-Temporal Attention Networks for Action Recognition and Detection\",\"url\":\"https://www.semanticscholar.org/paper/2ea173f972d39b8631e9ac8fe59a947c70ba31e3\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"1602.00224\",\"authors\":[{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1016/j.patcog.2019.03.002\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2cdde47c27a8ecd391cbb6b2dea64b73282c7491\",\"title\":\"Order-aware Convolutional Pooling for Video Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2cdde47c27a8ecd391cbb6b2dea64b73282c7491\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39974958\",\"name\":\"T. Yu\"},{\"authorId\":\"46181112\",\"name\":\"Chaoxu Guo\"},{\"authorId\":\"40585252\",\"name\":\"L. Wang\"},{\"authorId\":\"1683738\",\"name\":\"S. Xiang\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.1109/LSP.2018.2843295\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0f2ddd35090bf4220c97f0bf1d87f76121c15963\",\"title\":\"Self-Paced AutoEncoder\",\"url\":\"https://www.semanticscholar.org/paper/0f2ddd35090bf4220c97f0bf1d87f76121c15963\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9712088\",\"name\":\"Van-Huy Pham\"},{\"authorId\":\"2109561\",\"name\":\"Le-My Ha\"},{\"authorId\":\"145334834\",\"name\":\"V. Hoang\"}],\"doi\":\"10.1007/978-3-319-54472-4_57\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"20ca94df6a9a16b8a93adb9b2a3dcee62c9aa27e\",\"title\":\"Boosting Discriminative Models for Activity Detection Using Local Feature Descriptors\",\"url\":\"https://www.semanticscholar.org/paper/20ca94df6a9a16b8a93adb9b2a3dcee62c9aa27e\",\"venue\":\"ACIIDS\",\"year\":2017},{\"arxivId\":\"1806.00631\",\"authors\":[{\"authorId\":\"2896701\",\"name\":\"G. An\"},{\"authorId\":\"145957093\",\"name\":\"Wen Zhou\"},{\"authorId\":\"47095962\",\"name\":\"Yuxuan Wu\"},{\"authorId\":\"4464686\",\"name\":\"ZhenXing Zheng\"},{\"authorId\":\"46398737\",\"name\":\"Yongwen Liu\"}],\"doi\":\"10.1109/ICSP.2018.8652287\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"da092dad9a978f420bff4fb7731d5453ebed1d5e\",\"title\":\"Squeeze-and-Excitation on Spatial and Temporal Deep Feature Space for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/da092dad9a978f420bff4fb7731d5453ebed1d5e\",\"venue\":\"2018 14th IEEE International Conference on Signal Processing (ICSP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153580352\",\"name\":\"Ionut Cosmin Duta\"},{\"authorId\":\"1796198\",\"name\":\"B. Ionescu\"},{\"authorId\":\"1712839\",\"name\":\"K. Aizawa\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":\"10.1109/CVPR.2017.341\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e3ce4c3e1279e3dc0c14ff3bb2920aced9e62638\",\"title\":\"Spatio-Temporal Vector of Locally Max Pooled Features for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/e3ce4c3e1279e3dc0c14ff3bb2920aced9e62638\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50019641\",\"name\":\"Ekaterina Taralova\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"92d5e00f3f6b6fc18603dd309d3a7609190c3540\",\"title\":\"Feature Quantization and Pooling for Videos\",\"url\":\"https://www.semanticscholar.org/paper/92d5e00f3f6b6fc18603dd309d3a7609190c3540\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2082991\",\"name\":\"Georgia Gkioxari\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1eb4ea011a3122dc7ef3447e10c1dad5b69b0642\",\"title\":\"Contextual Visual Recognition from Images and Videos\",\"url\":\"https://www.semanticscholar.org/paper/1eb4ea011a3122dc7ef3447e10c1dad5b69b0642\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40760781\",\"name\":\"Zheming Zuo\"},{\"authorId\":\"34975328\",\"name\":\"D. Organisciak\"},{\"authorId\":\"2840036\",\"name\":\"Hubert P. H. Shum\"},{\"authorId\":\"1706028\",\"name\":\"L. Yang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c7713be03c08e62d9a5c2f3be937a69c7ac4441e\",\"title\":\"Saliency-Informed Spatio-Temporal Vector of Locally Aggregated Descriptors and Fisher Vectors for Visual Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c7713be03c08e62d9a5c2f3be937a69c7ac4441e\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46698300\",\"name\":\"Ji Lin\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"143840277\",\"name\":\"Song Han\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5925a25dfe107c49c636eccb8f9fd1aeef7b438c\",\"title\":\"Temporal Shift Module for Efficient Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/5925a25dfe107c49c636eccb8f9fd1aeef7b438c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143622778\",\"name\":\"K. Xu\"},{\"authorId\":\"1888867\",\"name\":\"X. Jiang\"},{\"authorId\":\"3307728\",\"name\":\"T. Sun\"}],\"doi\":\"10.1109/TCSVT.2017.2665359\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f8b0fb855e2ddbf490d3160c408a0cbe16c5ee9f\",\"title\":\"Two-Stream Dictionary Learning Architecture for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f8b0fb855e2ddbf490d3160c408a0cbe16c5ee9f\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2017},{\"arxivId\":\"1811.11387\",\"authors\":[{\"authorId\":\"29724362\",\"name\":\"Longlong Jing\"},{\"authorId\":\"40058797\",\"name\":\"Xiaodong Yang\"},{\"authorId\":\"1800425\",\"name\":\"Jingen Liu\"},{\"authorId\":\"8193125\",\"name\":\"Y. Tian\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f7fa3b8ed5f3f75ace4fe8447ccd9abfbb19e621\",\"title\":\"Self-Supervised Spatiotemporal Feature Learning via Video Rotation Prediction.\",\"url\":\"https://www.semanticscholar.org/paper/f7fa3b8ed5f3f75ace4fe8447ccd9abfbb19e621\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50993183\",\"name\":\"Haochen Zhang\"},{\"authorId\":\"1718355\",\"name\":\"Dong Liu\"},{\"authorId\":\"2352456\",\"name\":\"Z. Xiong\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"39e04aa60e7e7824f26988fc9df3b42143bc8222\",\"title\":\"Two-Stream Oriented Video Super-Resolution for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/39e04aa60e7e7824f26988fc9df3b42143bc8222\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40566477\",\"name\":\"H. Yang\"},{\"authorId\":null,\"name\":\"Chunfeng Yuan\"},{\"authorId\":\"1757173\",\"name\":\"Junliang Xing\"},{\"authorId\":\"40506509\",\"name\":\"W. Hu\"}],\"doi\":\"10.1109/ICIP.2017.8296302\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"0e424b458f4fe94fc74daffda79d6366d8d005e0\",\"title\":\"SCNN: Sequential convolutional neural network for human action recognition in videos\",\"url\":\"https://www.semanticscholar.org/paper/0e424b458f4fe94fc74daffda79d6366d8d005e0\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":\"1708.00999\",\"authors\":[{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"},{\"authorId\":\"2902291\",\"name\":\"Kiyoon Kim\"},{\"authorId\":\"3014315\",\"name\":\"H. Yang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"50cd6a89c31d49e134127aa7dccb6a9c218a5f52\",\"title\":\"Extreme Low Resolution Activity Recognition with Multi-Siamese Embedding Learning\",\"url\":\"https://www.semanticscholar.org/paper/50cd6a89c31d49e134127aa7dccb6a9c218a5f52\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152823345\",\"name\":\"M. Sol\\u00e8r\"},{\"authorId\":\"31798873\",\"name\":\"J. Bazin\"},{\"authorId\":\"47520207\",\"name\":\"O. Wang\"},{\"authorId\":\"153243248\",\"name\":\"A. Krause\"},{\"authorId\":\"1388791172\",\"name\":\"Alexander Sorkine-Hornung\"}],\"doi\":\"10.1007/978-3-319-48881-3_59\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"333aa36e80f1a7fa29cf069d81d4d2e12679bc67\",\"title\":\"Suggesting Sounds for Images from Video Collections\",\"url\":\"https://www.semanticscholar.org/paper/333aa36e80f1a7fa29cf069d81d4d2e12679bc67\",\"venue\":\"ECCV Workshops\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143798882\",\"name\":\"Mihir Jain\"},{\"authorId\":\"1681054\",\"name\":\"H. J\\u00e9gou\"},{\"authorId\":\"1716733\",\"name\":\"P. Bouthemy\"}],\"doi\":\"10.3389/fict.2015.00028\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0b61fde7e70a5329473b6bd1eee784aef6870721\",\"title\":\"Improved Motion Description for Action Classification\",\"url\":\"https://www.semanticscholar.org/paper/0b61fde7e70a5329473b6bd1eee784aef6870721\",\"venue\":\"Front. ICT\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9024867\",\"name\":\"Jongkwang Hong\"},{\"authorId\":\"70374238\",\"name\":\"Bora Cho\"},{\"authorId\":\"49058762\",\"name\":\"Yongwon Hong\"},{\"authorId\":\"144036125\",\"name\":\"H. Byun\"}],\"doi\":\"10.3390/s19061382\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"17d77c03c2b552f2046e8c4674db64a3ef9b915b\",\"title\":\"Contextual Action Cues from Camera Sensor for Multi-Stream Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/17d77c03c2b552f2046e8c4674db64a3ef9b915b\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1899753\",\"name\":\"Ryo Yonetani\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1109/CVPR.2016.288\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"16461bc1f06c781b5357cb1157248d28dc3672a0\",\"title\":\"Recognizing Micro-Actions and Reactions from Paired Egocentric Videos\",\"url\":\"https://www.semanticscholar.org/paper/16461bc1f06c781b5357cb1157248d28dc3672a0\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21643049\",\"name\":\"S. Wilson\"},{\"authorId\":\"34358756\",\"name\":\"C. K. Mohan\"}],\"doi\":\"10.1109/TMM.2017.2716835\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c59b13adfb853c7a6355f2538176f8279604ab07\",\"title\":\"An Information Bottleneck Approach to Optimize the Dictionary of Visual Data\",\"url\":\"https://www.semanticscholar.org/paper/c59b13adfb853c7a6355f2538176f8279604ab07\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2014145\",\"name\":\"Mohammad Tavakolian\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"46606565\",\"name\":\"A. Hadid\"}],\"doi\":\"10.1109/ICCV.2019.00811\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"acd1e0773799658a4481693220f38157f204f9bf\",\"title\":\"AWSD: Adaptive Weighted Spatiotemporal Distillation for Video Representation\",\"url\":\"https://www.semanticscholar.org/paper/acd1e0773799658a4481693220f38157f204f9bf\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34834493\",\"name\":\"Carolina Pacheco\"},{\"authorId\":\"145702263\",\"name\":\"E. Mavroudi\"},{\"authorId\":\"1491796980\",\"name\":\"Elena Kokkoni\"},{\"authorId\":\"1748908\",\"name\":\"H. Tanner\"},{\"authorId\":\"144187890\",\"name\":\"R. Vidal\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"630351ebae61fce9d37baaeaf7e57797276d1fbf\",\"title\":\"A Detection-based Approach to Multiview Action Classification in Infants\",\"url\":\"https://www.semanticscholar.org/paper/630351ebae61fce9d37baaeaf7e57797276d1fbf\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"},{\"authorId\":\"1742688\",\"name\":\"H. Escalante\"},{\"authorId\":\"46176857\",\"name\":\"X. Bar\\u00f3\"},{\"authorId\":\"46987321\",\"name\":\"I. Guyon\"},{\"authorId\":\"50161696\",\"name\":\"M. Madadi\"},{\"authorId\":\"145121526\",\"name\":\"J. Wan\"},{\"authorId\":\"145956252\",\"name\":\"S. Ayache\"},{\"authorId\":\"2706315\",\"name\":\"Ya\\u011fmur G\\u00fc\\u00e7l\\u00fct\\u00fcrk\"},{\"authorId\":\"3038211\",\"name\":\"Umut G\\u00fc\\u00e7l\\u00fc\"}],\"doi\":\"10.1109/tpami.2020.2971291\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"10a6083339b6a5655446b49095607bc7a8914fc6\",\"title\":\"Guest Editorial: Image and Video Inpainting and Denoising\",\"url\":\"https://www.semanticscholar.org/paper/10a6083339b6a5655446b49095607bc7a8914fc6\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2020},{\"arxivId\":\"2004.01808\",\"authors\":[{\"authorId\":\"13142264\",\"name\":\"Noureldien Hussein\"},{\"authorId\":\"143798882\",\"name\":\"Mihir Jain\"},{\"authorId\":\"2954103\",\"name\":\"B. E. Bejnordi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"24fd7077532323fffec0aab2bea3d1db4159ffc1\",\"title\":\"TimeGate: Conditional Gating of Segments in Long-range Activities\",\"url\":\"https://www.semanticscholar.org/paper/24fd7077532323fffec0aab2bea3d1db4159ffc1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1808.00141\",\"authors\":[{\"authorId\":\"145112187\",\"name\":\"Cristian Rodriguez-Opazo\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"40124570\",\"name\":\"Hongdong Li\"}],\"doi\":\"10.1007/978-3-030-11015-4_10\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5731c4c48aecf2fb15a96a3578016437a4d44cfd\",\"title\":\"Action Anticipation By Predicting Future Dynamic Images\",\"url\":\"https://www.semanticscholar.org/paper/5731c4c48aecf2fb15a96a3578016437a4d44cfd\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46702644\",\"name\":\"H. Zhang\"},{\"authorId\":\"1888678\",\"name\":\"Miao Xin\"},{\"authorId\":\"49185004\",\"name\":\"Shuhang Wang\"},{\"authorId\":\"46285365\",\"name\":\"Yifan Yang\"},{\"authorId\":\"36794849\",\"name\":\"L. Zhang\"},{\"authorId\":\"2512046\",\"name\":\"Helong Wang\"}],\"doi\":\"10.1007/s00138-018-0956-5\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"e8a150b743d487e9dbf6e023b0928f03b2c39aef\",\"title\":\"End-to-end temporal attention extraction and human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/e8a150b743d487e9dbf6e023b0928f03b2c39aef\",\"venue\":\"Machine Vision and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47818720\",\"name\":\"L. Chen\"},{\"authorId\":\"1697700\",\"name\":\"Jiwen Lu\"},{\"authorId\":\"2450987\",\"name\":\"Z. Song\"},{\"authorId\":\"49640256\",\"name\":\"J. Zhou\"}],\"doi\":\"10.1109/ACPR.2017.28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"08acfa0920abbac5c5046edcff01e41b12c98be7\",\"title\":\"Learning Principal Orientations Descriptor for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/08acfa0920abbac5c5046edcff01e41b12c98be7\",\"venue\":\"2017 4th IAPR Asian Conference on Pattern Recognition (ACPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491240780\",\"name\":\"Zhensheng Shi\"},{\"authorId\":\"1491233401\",\"name\":\"Liangjie Cao\"},{\"authorId\":\"153747406\",\"name\":\"Cheng Guan\"},{\"authorId\":\"2336297\",\"name\":\"Haiyong Zheng\"},{\"authorId\":\"29344734\",\"name\":\"Zhaorui Gu\"},{\"authorId\":\"144803009\",\"name\":\"Z. Yu\"},{\"authorId\":\"49721778\",\"name\":\"B. Zheng\"}],\"doi\":\"10.1109/ACCESS.2020.2968024\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c8744061c96cbcf492d5e504d3f6cfc7d0059643\",\"title\":\"Learning Attention-Enhanced Spatiotemporal Representation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c8744061c96cbcf492d5e504d3f6cfc7d0059643\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39691613\",\"name\":\"H. Yang\"},{\"authorId\":\"33913193\",\"name\":\"Xuming He\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"}],\"doi\":\"10.1109/WACV.2018.00175\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"31ec1e5c3b5e020af4a5a3c1be2724c7429a7c78\",\"title\":\"Instance-Aware Detailed Action Labeling in Videos\",\"url\":\"https://www.semanticscholar.org/paper/31ec1e5c3b5e020af4a5a3c1be2724c7429a7c78\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66425285\",\"name\":\"Akash Panchal\"},{\"authorId\":\"48756948\",\"name\":\"H. Trivedi\"},{\"authorId\":\"101106680\",\"name\":\"M. Rajput\"},{\"authorId\":\"144027193\",\"name\":\"D. Trivedi\"}],\"doi\":\"10.1007/978-981-15-3369-3_65\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a3eb1ee19f1312c0a7e4cf8459ff260039968342\",\"title\":\"Activity Recognition Using Temporal Features and Deep Bottleneck 3D-ResNeXt\",\"url\":\"https://www.semanticscholar.org/paper/a3eb1ee19f1312c0a7e4cf8459ff260039968342\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1505.04427\",\"authors\":[{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"1711953\",\"name\":\"Dezhong Yao\"},{\"authorId\":\"144247537\",\"name\":\"Ming Lin\"},{\"authorId\":\"143642520\",\"name\":\"Shoou-I Yu\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1109/CVPRW.2016.152\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e42377ef3aad1b22172079ed70a69a4848c76367\",\"title\":\"The Best of BothWorlds: Combining Data-Independent and Data-Driven Approaches for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e42377ef3aad1b22172079ed70a69a4848c76367\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2016},{\"arxivId\":\"1909.07945\",\"authors\":[{\"authorId\":\"30625178\",\"name\":\"S. K. Dwivedi\"},{\"authorId\":\"49368129\",\"name\":\"V. Gupta\"},{\"authorId\":\"108057223\",\"name\":\"Rudrajit Mitra\"},{\"authorId\":\"83703493\",\"name\":\"S. Ahmed\"},{\"authorId\":\"36399635\",\"name\":\"Arjun Jain\"}],\"doi\":\"10.1109/ICCVW.2019.00166\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"130373cc752e2c51a6cf14c6d1b2e5f7d9006987\",\"title\":\"ProtoGAN: Towards Few Shot Learning for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/130373cc752e2c51a6cf14c6d1b2e5f7d9006987\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1912.01136\",\"authors\":[{\"authorId\":\"49897080\",\"name\":\"Claudia Latella\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e80a37de232e280dfb5d92b0e0d3e4756a5c208a\",\"title\":\"Human Whole-Body Dynamics Estimation for Enhancing Physical Human-Robot Interaction\",\"url\":\"https://www.semanticscholar.org/paper/e80a37de232e280dfb5d92b0e0d3e4756a5c208a\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48882412\",\"name\":\"Tasweer Ahmad\"},{\"authorId\":\"144838978\",\"name\":\"Lianwen Jin\"},{\"authorId\":\"153285152\",\"name\":\"J. Feng\"},{\"authorId\":\"153073573\",\"name\":\"Guozhi Tang\"}],\"doi\":\"10.1109/ACCESS.2019.2937344\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d3fd39dad90b6326b87f0bed5074b4885a013033\",\"title\":\"Human Action Recognition in Unconstrained Trimmed Videos Using Residual Attention Network and Joints Path Signature\",\"url\":\"https://www.semanticscholar.org/paper/d3fd39dad90b6326b87f0bed5074b4885a013033\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"2002.12177\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"2148510\",\"name\":\"A. Angelova\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1109/cvpr42600.2020.00021\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"3cb1b739f32641938485b714a186fb705d0b0215\",\"title\":\"Evolving Losses for Unsupervised Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/3cb1b739f32641938485b714a186fb705d0b0215\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29516300\",\"name\":\"V. O. Silva\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e5b9269c7499be1bf6d50678c2b06db648dbd283\",\"title\":\"Human action recognition in image sequences based on a two-stream convolutional neural network classifier\",\"url\":\"https://www.semanticscholar.org/paper/e5b9269c7499be1bf6d50678c2b06db648dbd283\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1608.07664\",\"authors\":[{\"authorId\":\"46584828\",\"name\":\"J. Wang\"},{\"authorId\":\"143928529\",\"name\":\"Tian Lan\"},{\"authorId\":\"47957556\",\"name\":\"X. Zhang\"},{\"authorId\":\"143827153\",\"name\":\"L. Luo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d3de149c6e99f1e725908be4619bc41491b5164d\",\"title\":\"Spatio-temporal Aware Non-negative Component Representation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d3de149c6e99f1e725908be4619bc41491b5164d\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144459566\",\"name\":\"J. Balicki\"},{\"authorId\":\"65941205\",\"name\":\"Honorata Balicka\"},{\"authorId\":\"3455135\",\"name\":\"Piotr Dryja\"},{\"authorId\":\"3455237\",\"name\":\"M. Tyszka\"}],\"doi\":\"10.1007/978-3-030-47679-3_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7bf2e45f339cef593ec8032de3aa88fce7b8da33\",\"title\":\"Multi-criteria Differential Evolution for Optimization of Virtual Machine Resources in Smart City Cloud\",\"url\":\"https://www.semanticscholar.org/paper/7bf2e45f339cef593ec8032de3aa88fce7b8da33\",\"venue\":\"CISIM\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491240780\",\"name\":\"Z. Shi\"},{\"authorId\":\"1491233401\",\"name\":\"Liangjie Cao\"},{\"authorId\":\"153747406\",\"name\":\"Cheng Guan\"},{\"authorId\":\"1993660232\",\"name\":\"Ju Liang\"},{\"authorId\":\"48934241\",\"name\":\"Qianqian Li\"},{\"authorId\":\"29344734\",\"name\":\"Zhaorui Gu\"},{\"authorId\":\"2336297\",\"name\":\"Haiyong Zheng\"},{\"authorId\":\"49721778\",\"name\":\"Bing Zheng\"}],\"doi\":\"10.1145/3394171.3413646\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"c0d5f622f775d02e90b715b80485dbcab250e7bd\",\"title\":\"Multi-Group Multi-Attention: Towards Discriminative Spatiotemporal Representation\",\"url\":\"https://www.semanticscholar.org/paper/c0d5f622f775d02e90b715b80485dbcab250e7bd\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40576269\",\"name\":\"Emrah Aydemir\"},{\"authorId\":\"50186675\",\"name\":\"T. Tuncer\"},{\"authorId\":\"34689934\",\"name\":\"S. Dogan\"},{\"authorId\":\"2036729861\",\"name\":\"Musa Unsal\"}],\"doi\":\"10.1016/j.apacoust.2020.107701\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"209b62270b6fd5ca10f04d65df7f74e318db1593\",\"title\":\"A novel biometric recognition method based on multi kernelled bijection octal pattern using gait sound\",\"url\":\"https://www.semanticscholar.org/paper/209b62270b6fd5ca10f04d65df7f74e318db1593\",\"venue\":\"\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2059283\",\"name\":\"Ruishan Liu\"},{\"authorId\":\"143730442\",\"name\":\"Yanhua Yang\"},{\"authorId\":\"145102437\",\"name\":\"Cheng Deng\"}],\"doi\":\"10.1007/978-3-319-24075-6_62\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c5d1290c2ed4a0b6e1858d97765bcf3766d07f19\",\"title\":\"Recognizing Human Actions by Sharing Knowledge in Implicit Action Groups\",\"url\":\"https://www.semanticscholar.org/paper/c5d1290c2ed4a0b6e1858d97765bcf3766d07f19\",\"venue\":\"PCM\",\"year\":2015},{\"arxivId\":\"1712.09184\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"2082991\",\"name\":\"Georgia Gkioxari\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"}],\"doi\":\"10.1109/CVPR.2018.00044\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5084ca7e4db3168e674414ae55cb6f4e682214e1\",\"title\":\"Detect-and-Track: Efficient Pose Estimation in Videos\",\"url\":\"https://www.semanticscholar.org/paper/5084ca7e4db3168e674414ae55cb6f4e682214e1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145143348\",\"name\":\"O. V. R. Murthy\"},{\"authorId\":\"1717204\",\"name\":\"R. Goecke\"}],\"doi\":\"10.1016/j.imavis.2015.06.009\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3c8db0d86a6aa51b64ec09c7d25a721adcdfb7a3\",\"title\":\"Ordered trajectories for human action recognition with large number of classes\",\"url\":\"https://www.semanticscholar.org/paper/3c8db0d86a6aa51b64ec09c7d25a721adcdfb7a3\",\"venue\":\"Image Vis. Comput.\",\"year\":2015},{\"arxivId\":\"1912.04538\",\"authors\":[{\"authorId\":\"115023832\",\"name\":\"Zhi-Kai Chen\"},{\"authorId\":\"3041937\",\"name\":\"Lingxi Xie\"},{\"authorId\":\"2852872\",\"name\":\"S. Pang\"},{\"authorId\":\"51004368\",\"name\":\"Y. He\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b9f01b9054517581a675fb919850ad558d4640d7\",\"title\":\"Appending Adversarial Frames for Universal Video Attack\",\"url\":\"https://www.semanticscholar.org/paper/b9f01b9054517581a675fb919850ad558d4640d7\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47056822\",\"name\":\"X. Li\"},{\"authorId\":\"143806694\",\"name\":\"Miao Xie\"},{\"authorId\":\"49890942\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1492114781\",\"name\":\"Jide Li\"}],\"doi\":\"10.1117/1.JEI.29.6.063013\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2ff367b6e92953c0f0e72f5bee2f64f1c1d19f01\",\"title\":\"Multi-scale temporal feature-based dense convolutional network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/2ff367b6e92953c0f0e72f5bee2f64f1c1d19f01\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2518212\",\"name\":\"Hakan Bilen\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1109/CVPR.2016.331\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5aae6f1aedb3e78a05bc430a1d8b86cac33c5184\",\"title\":\"Dynamic Image Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5aae6f1aedb3e78a05bc430a1d8b86cac33c5184\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121866018\",\"name\":\"Guiyu Liu\"},{\"authorId\":\"2795127\",\"name\":\"J. Qian\"},{\"authorId\":\"144356873\",\"name\":\"Fei Wen\"},{\"authorId\":\"40491969\",\"name\":\"Xiaoguang Zhu\"},{\"authorId\":\"66717324\",\"name\":\"R. Ying\"},{\"authorId\":\"47478788\",\"name\":\"P. Liu\"}],\"doi\":\"10.1109/IROS40897.2019.8967570\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"76209561db759fe8595b1f92056968564238e892\",\"title\":\"Action Recognition Based on 3D Skeleton and RGB Frame Fusion\",\"url\":\"https://www.semanticscholar.org/paper/76209561db759fe8595b1f92056968564238e892\",\"venue\":\"2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35984288\",\"name\":\"Guangnan Ye\"}],\"doi\":\"10.7916/D8BG2NGV\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"891711bc69800166bb9da9fec72a9958255b5b9c\",\"title\":\"Large-Scale Video Event Detection\",\"url\":\"https://www.semanticscholar.org/paper/891711bc69800166bb9da9fec72a9958255b5b9c\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3280656\",\"name\":\"Litao Yu\"},{\"authorId\":\"145496509\",\"name\":\"Jie Shao\"},{\"authorId\":\"40620796\",\"name\":\"Xin-Shun Xu\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1007/s11042-014-2010-6\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c3662b1354c38ddbbf564f35833a2cdd9e5f793e\",\"title\":\"Max-margin adaptive model for complex video pattern recognition\",\"url\":\"https://www.semanticscholar.org/paper/c3662b1354c38ddbbf564f35833a2cdd9e5f793e\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"144894849\",\"name\":\"Fei Wu\"},{\"authorId\":\"2248826\",\"name\":\"R. Hong\"}],\"doi\":\"10.1109/TIP.2015.2479917\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fa45daf94e51df07830a68f6c1ed195be8e1747f\",\"title\":\"Compact and Discriminative Descriptor Inference Using Multi-Cues\",\"url\":\"https://www.semanticscholar.org/paper/fa45daf94e51df07830a68f6c1ed195be8e1747f\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"145808756\",\"name\":\"Xuanyi Dong\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2e55a287328b234db16fb538eddbbc185d51582a\",\"title\":\"UTS-CMU-D2DCRC Submission at TRECVID 2016 Video Localization\",\"url\":\"https://www.semanticscholar.org/paper/2e55a287328b234db16fb538eddbbc185d51582a\",\"venue\":\"TRECVID\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144720596\",\"name\":\"Xian Hu\"},{\"authorId\":\"9633703\",\"name\":\"Yongcheng Jing\"}],\"doi\":\"10.1109/ICMLC.2016.7860939\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"02baecdc84ceab31c63adc0a39e6b8220bc56087\",\"title\":\"Confidence-based human action recognition with different-level features\",\"url\":\"https://www.semanticscholar.org/paper/02baecdc84ceab31c63adc0a39e6b8220bc56087\",\"venue\":\"2016 International Conference on Machine Learning and Cybernetics (ICMLC)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47320160\",\"name\":\"Shengchao Li\"},{\"authorId\":\"47058844\",\"name\":\"Lin Zhang\"},{\"authorId\":\"2256493\",\"name\":\"Xiumin Diao\"}],\"doi\":\"10.1109/ROMAN.2018.8525781\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e667250b0407b262e9d15929c86b6da347f9cdc9\",\"title\":\"Improving Human Intention Prediction Using Data Augmentation\",\"url\":\"https://www.semanticscholar.org/paper/e667250b0407b262e9d15929c86b6da347f9cdc9\",\"venue\":\"2018 27th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40930518\",\"name\":\"Nakul Agarwal\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5b345b1d902b2ca940c6e87f8ed41d05b674b32d\",\"title\":\"Exploring Action Recognition without using Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/5b345b1d902b2ca940c6e87f8ed41d05b674b32d\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144701889\",\"name\":\"Shuanglu Dai\"},{\"authorId\":\"144484158\",\"name\":\"Hong Man\"}],\"doi\":\"10.1109/TCSVT.2017.2772026\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"709d7f6b86c01fe90f10ae9216a91f95b1dcd2fb\",\"title\":\"Mixture Statistic Metric Learning for Robust Human Action and Expression Recognition\",\"url\":\"https://www.semanticscholar.org/paper/709d7f6b86c01fe90f10ae9216a91f95b1dcd2fb\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2018},{\"arxivId\":\"1806.11230\",\"authors\":[{\"authorId\":\"145873652\",\"name\":\"Y. Kong\"},{\"authorId\":\"46956675\",\"name\":\"Yun Fu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"025a44bf059aef8b9ee2e6ca598bebefc59a4a61\",\"title\":\"Human Action Recognition and Prediction: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/025a44bf059aef8b9ee2e6ca598bebefc59a4a61\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153614433\",\"name\":\"M. Morris\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a89c1045cf2b86201db80584406e6a9982c04128\",\"title\":\"Visual Attributes in Videos\",\"url\":\"https://www.semanticscholar.org/paper/a89c1045cf2b86201db80584406e6a9982c04128\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121342228\",\"name\":\"Jain\"},{\"authorId\":\"134835107\",\"name\":\"Van Gemert\"},{\"authorId\":\"1722052\",\"name\":\"Thomas Mensink\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4124441c9f41b5e2542cd9c012752a78ae6cc4ac\",\"title\":\"UvA-DARE ( Digital Academic Repository ) Objects 2 action : Classifying and localizing actions without any video example\",\"url\":\"https://www.semanticscholar.org/paper/4124441c9f41b5e2542cd9c012752a78ae6cc4ac\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1812.10071\",\"authors\":[{\"authorId\":\"41191188\",\"name\":\"Lin Sun\"},{\"authorId\":\"2370507\",\"name\":\"Kui Jia\"},{\"authorId\":\"48234805\",\"name\":\"Yuejia Shen\"},{\"authorId\":\"1702137\",\"name\":\"Silvio Savarese\"},{\"authorId\":\"1739816\",\"name\":\"Dit-Yan Yeung\"},{\"authorId\":\"2131088\",\"name\":\"Bertram Emil Shi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"073fabecf18f1421321f1961872b9842d913e4ee\",\"title\":\"Coupled Recurrent Network (CRN)\",\"url\":\"https://www.semanticscholar.org/paper/073fabecf18f1421321f1961872b9842d913e4ee\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"17594102\",\"name\":\"Yingjie Yao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"da770533d9743b297f5022e7fb99b6a7a4ee904c\",\"title\":\"Vision-Based Human Motion Analysis\",\"url\":\"https://www.semanticscholar.org/paper/da770533d9743b297f5022e7fb99b6a7a4ee904c\",\"venue\":\"\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145371957\",\"name\":\"Chang Xu\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"},{\"authorId\":\"31796215\",\"name\":\"Chao Xu\"}],\"doi\":\"10.1109/TPAMI.2013.2296528\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"43996253f97d7023af1b1869a7ec2e6376ca1986\",\"title\":\"Large-Margin Multi-ViewInformation Bottleneck\",\"url\":\"https://www.semanticscholar.org/paper/43996253f97d7023af1b1869a7ec2e6376ca1986\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2014},{\"arxivId\":\"1706.05028\",\"authors\":[{\"authorId\":\"3079079\",\"name\":\"Nelson Nauata\"},{\"authorId\":\"144915895\",\"name\":\"J. Smith\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e2888084b375163f7c956adff102fdbc9fe7fb40\",\"title\":\"Hierarchical Label Inference for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/e2888084b375163f7c956adff102fdbc9fe7fb40\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40241836\",\"name\":\"L. Liu\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"},{\"authorId\":\"144767226\",\"name\":\"P. Rockett\"}],\"doi\":\"10.5244/C.26.18\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a8c3b95ea3eafd52e86479c4d82b544affb43800\",\"title\":\"Genetic Programming-Evolved Spatio-Temporal Descriptor for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a8c3b95ea3eafd52e86479c4d82b544affb43800\",\"venue\":\"BMVC\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10029285\",\"name\":\"Nieves Crasto\"},{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"72492981\",\"name\":\"Alahari Karteek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/CVPR.2019.00807\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6e93bd99350bf03acf870f83bb9c7ab1a7d17147\",\"title\":\"MARS: Motion-Augmented RGB Stream for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6e93bd99350bf03acf870f83bb9c7ab1a7d17147\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49724000\",\"name\":\"H. Zhang\"},{\"authorId\":\"46867310\",\"name\":\"Yi-Xiang Zhang\"},{\"authorId\":\"40296597\",\"name\":\"B. Zhong\"},{\"authorId\":\"2619654\",\"name\":\"Qing Lei\"},{\"authorId\":\"48064117\",\"name\":\"Lijie Yang\"},{\"authorId\":\"3721965\",\"name\":\"Ji-Xiang Du\"},{\"authorId\":\"123204699\",\"name\":\"Duan-Sheng Chen\"}],\"doi\":\"10.3390/s19051005\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"c0e55d740d07b16a50b5eb491117b92965d315c9\",\"title\":\"A Comprehensive Survey of Vision-Based Human Action Recognition Methods\",\"url\":\"https://www.semanticscholar.org/paper/c0e55d740d07b16a50b5eb491117b92965d315c9\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":\"1708.08296\",\"authors\":[{\"authorId\":\"1699054\",\"name\":\"W. Samek\"},{\"authorId\":\"1745395\",\"name\":\"T. Wiegand\"},{\"authorId\":\"145034054\",\"name\":\"K. M\\u00fcller\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"497d645d7b81dd0a6e8db2deccd77097ac94bc4e\",\"title\":\"Explainable Artificial Intelligence: Understanding, Visualizing and Interpreting Deep Learning Models\",\"url\":\"https://www.semanticscholar.org/paper/497d645d7b81dd0a6e8db2deccd77097ac94bc4e\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51931034\",\"name\":\"Khari Jarrett\"},{\"authorId\":\"1411317532\",\"name\":\"Joachim Lohn-Jaramillo\"},{\"authorId\":\"39517986\",\"name\":\"Elijah F. W. Bowen\"},{\"authorId\":\"144089674\",\"name\":\"L. Ray\"},{\"authorId\":\"144297712\",\"name\":\"Richard Granger\"}],\"doi\":\"10.5220/0007313603770387\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e90813779746afae2112eb58f5fe3e4d83fdef6b\",\"title\":\"Feedforward and Feedback Processing of Spatiotemporal Tubes for Efficient Object Localization\",\"url\":\"https://www.semanticscholar.org/paper/e90813779746afae2112eb58f5fe3e4d83fdef6b\",\"venue\":\"ICPRAM\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2089428\",\"name\":\"D. P. Barrett\"},{\"authorId\":\"1737754\",\"name\":\"J. Siskind\"}],\"doi\":\"10.1109/TCSVT.2015.2502839\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"0e90a7b290ec3540f33054517a3f886be27007bd\",\"title\":\"Action Recognition by Time Series of Retinotopic Appearance and Motion Features\",\"url\":\"https://www.semanticscholar.org/paper/0e90a7b290ec3540f33054517a3f886be27007bd\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144899680\",\"name\":\"C. Wolf\"},{\"authorId\":\"2383120\",\"name\":\"E. Lombardi\"},{\"authorId\":\"1723242\",\"name\":\"J. Mille\"},{\"authorId\":\"1717313\",\"name\":\"Oya Celiktutan\"},{\"authorId\":\"2841798\",\"name\":\"Mingyuan Jiu\"},{\"authorId\":\"1490933781\",\"name\":\"Emre Do\\u011fan\"},{\"authorId\":\"34728489\",\"name\":\"Gonen Eren\"},{\"authorId\":\"2341854\",\"name\":\"M. Baccouche\"},{\"authorId\":\"1718878\",\"name\":\"E. Dellandr\\u00e9a\"},{\"authorId\":\"1769096\",\"name\":\"Charles-Edmond Bichot\"},{\"authorId\":\"152408204\",\"name\":\"C. Garc\\u00eda\"},{\"authorId\":\"145940271\",\"name\":\"B. Sankur\"}],\"doi\":\"10.1016/j.cviu.2014.06.014\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0aa74a9b96817e8838c3b76f2ceacfa79c9134e0\",\"title\":\"Evaluation of video activity localizations integrating quality and quantity measurements\",\"url\":\"https://www.semanticscholar.org/paper/0aa74a9b96817e8838c3b76f2ceacfa79c9134e0\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2014},{\"arxivId\":\"1712.04851\",\"authors\":[{\"authorId\":\"1817030\",\"name\":\"Saining Xie\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"1808244\",\"name\":\"J. Huang\"},{\"authorId\":\"144035504\",\"name\":\"Zhuowen Tu\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":\"10.1007/978-3-030-01267-0_19\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"815aa52cfc02961d82415f080384594639a21984\",\"title\":\"Rethinking Spatiotemporal Feature Learning: Speed-Accuracy Trade-offs in Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/815aa52cfc02961d82415f080384594639a21984\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145938577\",\"name\":\"Bo Yu\"}],\"doi\":\"10.1051/ITMCONF/20171201025\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ace300dba513a98d2957207eb1bcb7b7db35a2d6\",\"title\":\"Design and Implementation of Behavior Recognition System Based on Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/ace300dba513a98d2957207eb1bcb7b7db35a2d6\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1910.09616\",\"authors\":[{\"authorId\":\"51290120\",\"name\":\"Siddharth Roheda\"},{\"authorId\":\"145087510\",\"name\":\"H. Krim\"}],\"doi\":\"10.1609/aaai.v34i07.6870\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"4b7273b117d61fe4330ed3c18e14b5ef40054d41\",\"title\":\"Conquering the CNN Over-Parameterization Dilemma: A Volterra Filtering Approach for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4b7273b117d61fe4330ed3c18e14b5ef40054d41\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1710.07455\",\"authors\":[{\"authorId\":\"144119773\",\"name\":\"Kun Liu\"},{\"authorId\":\"1686917\",\"name\":\"Wu Liu\"},{\"authorId\":\"144258295\",\"name\":\"Huadong Ma\"},{\"authorId\":\"123175679\",\"name\":\"W. Huang\"},{\"authorId\":\"27619673\",\"name\":\"Xiongxiong Dong\"}],\"doi\":\"10.1007/s11280-018-0642-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c9f0cad35ad2a974dbf371bb6347d44232b1169f\",\"title\":\"Generalized zero-shot learning for action recognition with web-scale video data\",\"url\":\"https://www.semanticscholar.org/paper/c9f0cad35ad2a974dbf371bb6347d44232b1169f\",\"venue\":\"World Wide Web\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47818720\",\"name\":\"L. Chen\"},{\"authorId\":\"2450987\",\"name\":\"Z. Song\"},{\"authorId\":\"1697700\",\"name\":\"Jiwen Lu\"},{\"authorId\":\"49640256\",\"name\":\"J. Zhou\"}],\"doi\":\"10.1016/j.patcog.2018.08.016\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d2c6f39799392aaacf2fb342518d420e30e24785\",\"title\":\"Learning principal orientations and residual descriptor for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/d2c6f39799392aaacf2fb342518d420e30e24785\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145359186\",\"name\":\"Yang Yi\"},{\"authorId\":\"144858616\",\"name\":\"Yang Cheng\"},{\"authorId\":\"10330369\",\"name\":\"C. Xu\"}],\"doi\":\"10.1016/j.eswa.2017.02.020\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eec88e4ebd35268acf82ad466e69f38fb07395ad\",\"title\":\"Mining human movement evolution for complex action recognition\",\"url\":\"https://www.semanticscholar.org/paper/eec88e4ebd35268acf82ad466e69f38fb07395ad\",\"venue\":\"Expert Syst. Appl.\",\"year\":2017},{\"arxivId\":\"1704.02895\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"145160921\",\"name\":\"Bryan C. Russell\"}],\"doi\":\"10.1109/CVPR.2017.337\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"63213d080a43660ac59ea12e3c35e6953f6d7ce8\",\"title\":\"ActionVLAD: Learning Spatio-Temporal Aggregation for Action Classification\",\"url\":\"https://www.semanticscholar.org/paper/63213d080a43660ac59ea12e3c35e6953f6d7ce8\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"2008.08369\",\"authors\":[{\"authorId\":\"1885326178\",\"name\":\"A. Gorpincenko\"},{\"authorId\":\"50637156\",\"name\":\"Geoffrey French\"},{\"authorId\":\"98341179\",\"name\":\"M. Mackiewicz\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bbffda70337d8f380fff374efac3e3134c95634e\",\"title\":\"Virtual Adversarial Training in Feature Space to Improve Unsupervised Video Domain Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/bbffda70337d8f380fff374efac3e3134c95634e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1811.07503\",\"authors\":[{\"authorId\":\"143749869\",\"name\":\"Y. Pan\"},{\"authorId\":\"1703302\",\"name\":\"J. Xu\"},{\"authorId\":\"50468674\",\"name\":\"M. Wang\"},{\"authorId\":\"7173620\",\"name\":\"Jinmian Ye\"},{\"authorId\":\"39586294\",\"name\":\"Fei Wang\"},{\"authorId\":\"144654778\",\"name\":\"K. Bai\"},{\"authorId\":\"1683510\",\"name\":\"Zenglin Xu\"}],\"doi\":\"10.1609/aaai.v33i01.33014683\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"23b7d6a9fce5732ca5c5e11a3f42e17860ef05ad\",\"title\":\"Compressing Recurrent Neural Networks with Tensor Ring for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/23b7d6a9fce5732ca5c5e11a3f42e17860ef05ad\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1607.02104\",\"authors\":[{\"authorId\":\"47599321\",\"name\":\"Q. Wang\"},{\"authorId\":\"32811782\",\"name\":\"Ke Chen\"}],\"doi\":\"10.1007/s11263-017-1027-5\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"56841310aee1493600a1d20c9dd39c02f89fb563\",\"title\":\"Zero-Shot Visual Recognition via Bidirectional Latent Embedding\",\"url\":\"https://www.semanticscholar.org/paper/56841310aee1493600a1d20c9dd39c02f89fb563\",\"venue\":\"International Journal of Computer Vision\",\"year\":2017},{\"arxivId\":\"1603.09439\",\"authors\":[{\"authorId\":\"1879100\",\"name\":\"P. Nguyen\"},{\"authorId\":\"3321919\",\"name\":\"Gr\\u00e9gory Rogez\"},{\"authorId\":\"143800213\",\"name\":\"Charless C. Fowlkes\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f631f754afc9a82fa7a5e5a70eac37376c7379ef\",\"title\":\"The Open World of Micro-Videos\",\"url\":\"https://www.semanticscholar.org/paper/f631f754afc9a82fa7a5e5a70eac37376c7379ef\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152325076\",\"name\":\"H. Ge\"},{\"authorId\":\"79403975\",\"name\":\"Zehang Yan\"},{\"authorId\":null,\"name\":\"Wenhao Yu\"},{\"authorId\":\"144526347\",\"name\":\"L. Sun\"}],\"doi\":\"10.1007/s11042-019-7404-z\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9804bbb0724c333e9b900d849e492db00b20dbde\",\"title\":\"An attention mechanism based convolutional LSTM network for video action recognition\",\"url\":\"https://www.semanticscholar.org/paper/9804bbb0724c333e9b900d849e492db00b20dbde\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71348295\",\"name\":\"V. F. Mota\"},{\"authorId\":\"6141311\",\"name\":\"J. A. D. Santos\"},{\"authorId\":\"1840904\",\"name\":\"A. Ara\\u00fajo\"}],\"doi\":\"10.5753/sibgrapi.est.2019.8298\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7368ecb5ce7a387fd3729433e8a7e32c0a41ed76\",\"title\":\"FASTensor: A tensor framework for spatiotemporal description\",\"url\":\"https://www.semanticscholar.org/paper/7368ecb5ce7a387fd3729433e8a7e32c0a41ed76\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1557282756\",\"name\":\"Li Yuan\"},{\"authorId\":\"72259333\",\"name\":\"Tao Wang\"},{\"authorId\":\"21458018\",\"name\":\"Xiaopeng Zhang\"},{\"authorId\":\"40983412\",\"name\":\"F. Tay\"},{\"authorId\":\"2750647\",\"name\":\"Zequn Jie\"},{\"authorId\":\"1654091065\",\"name\":\"Wei Liu\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":\"10.1109/cvpr42600.2020.00315\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a43e2dd926b5d3935f4cd3617761634650bbe4dd\",\"title\":\"Central Similarity Quantization for Efficient Image and Video Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/a43e2dd926b5d3935f4cd3617761634650bbe4dd\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48033101\",\"name\":\"Xiao Liu\"},{\"authorId\":\"50030836\",\"name\":\"Xudong Yang\"}],\"doi\":\"10.1007/978-3-030-04167-0_23\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"caae04e73d362180f9586fabb224244200add105\",\"title\":\"Multi-stream with Deep Convolutional Neural Networks for Human Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/caae04e73d362180f9586fabb224244200add105\",\"venue\":\"ICONIP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145095579\",\"name\":\"L. Yao\"},{\"authorId\":\"1730844\",\"name\":\"Atousa Torabi\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"2482072\",\"name\":\"Nicolas Ballas\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"db7228525912e197fe9b9dfffcb4175fbbc1a422\",\"title\":\"Video Description Generation Incorporating Spatio-Temporal Features and a Soft-Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/db7228525912e197fe9b9dfffcb4175fbbc1a422\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1607.01794\",\"authors\":[{\"authorId\":\"3245057\",\"name\":\"Zhenyang Li\"},{\"authorId\":\"32781361\",\"name\":\"Kirill Gavrilyuk\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"143798882\",\"name\":\"Mihir Jain\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1016/j.cviu.2017.10.011\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"86031f555c128b82a1ac0db89ff4faeae16a1802\",\"title\":\"VideoLSTM convolves, attends and flows for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/86031f555c128b82a1ac0db89ff4faeae16a1802\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21643049\",\"name\":\"S. Wilson\"},{\"authorId\":\"70611576\",\"name\":\"C. Krishnamohan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a64d0124f3b154a255c5d3b0c599100500e7b188\",\"title\":\"DESIGN OF COMPACT AND DISCRIMINATIVE DICTIONARIES\",\"url\":\"https://www.semanticscholar.org/paper/a64d0124f3b154a255c5d3b0c599100500e7b188\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2012.03457\",\"authors\":[{\"authorId\":\"2151587\",\"name\":\"Sangdoo Yun\"},{\"authorId\":\"2390510\",\"name\":\"Seong Joon Oh\"},{\"authorId\":\"3086596\",\"name\":\"Byeongho Heo\"},{\"authorId\":\"2086576\",\"name\":\"Dongyoon Han\"},{\"authorId\":\"52289773\",\"name\":\"Jinhyung Kim\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f6830373b3a2758baf5efa50f4ca9ac17b1a377\",\"title\":\"VideoMix: Rethinking Data Augmentation for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/0f6830373b3a2758baf5efa50f4ca9ac17b1a377\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1807.08291\",\"authors\":[{\"authorId\":\"2035597\",\"name\":\"N. Yudistira\"},{\"authorId\":\"50433510\",\"name\":\"Takio Kurita\"}],\"doi\":\"10.1016/j.image.2019.115731\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"08129fdd46ea4dce31c435613ab70b6c35dd60b0\",\"title\":\"Correlation Net: Spatiotemporal multimodal deep learning for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/08129fdd46ea4dce31c435613ab70b6c35dd60b0\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2020},{\"arxivId\":\"2008.11254\",\"authors\":[{\"authorId\":\"49901923\",\"name\":\"Tingting Xie\"},{\"authorId\":\"1694090\",\"name\":\"Christos Tzelepis\"},{\"authorId\":\"50058816\",\"name\":\"I. Patras\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ec7b5f36e8a129521bf46f958cd366aa50a5a46d\",\"title\":\"Temporal Action Localization with Variance-Aware Networks\",\"url\":\"https://www.semanticscholar.org/paper/ec7b5f36e8a129521bf46f958cd366aa50a5a46d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10395796\",\"name\":\"Alex Dillhoff\"},{\"authorId\":\"2949237\",\"name\":\"K. Tsiakas\"},{\"authorId\":\"33166796\",\"name\":\"A. R. Babu\"},{\"authorId\":\"1490678536\",\"name\":\"Mohammad Zakizadehghariehali\"},{\"authorId\":\"11022118\",\"name\":\"B. Buchanan\"},{\"authorId\":\"2065380\",\"name\":\"M. Bell\"},{\"authorId\":\"1720747\",\"name\":\"V. Athitsos\"},{\"authorId\":\"1728274\",\"name\":\"F. Makedon\"}],\"doi\":\"10.1145/3361684.3361693\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b702b7342162d21e22076d18141588e207a54614\",\"title\":\"An automated assessment system for embodied cognition in children: from motion data to executive functioning\",\"url\":\"https://www.semanticscholar.org/paper/b702b7342162d21e22076d18141588e207a54614\",\"venue\":\"iWOAR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49455479\",\"name\":\"Y. Zhou\"},{\"authorId\":\"6485172\",\"name\":\"Xiaoyan Sun\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"}],\"doi\":\"10.1109/CVPR.2018.00054\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b85b79d0535da7e994e419a75f65b2758bf90f21\",\"title\":\"MiCT: Mixed 3D/2D Convolutional Tube for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b85b79d0535da7e994e419a75f65b2758bf90f21\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1808816\",\"name\":\"Jianxin Wu\"},{\"authorId\":\"46867148\",\"name\":\"Y. Zhang\"},{\"authorId\":\"8131625\",\"name\":\"W. Lin\"}],\"doi\":\"10.1109/TCYB.2015.2493538\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8383faea09b4b4bef8117a1da897495ebd68691b\",\"title\":\"Good Practices for Learning to Recognize Actions Using FV and VLAD\",\"url\":\"https://www.semanticscholar.org/paper/8383faea09b4b4bef8117a1da897495ebd68691b\",\"venue\":\"IEEE Transactions on Cybernetics\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40349048\",\"name\":\"Y. Wang\"},{\"authorId\":\"1718829\",\"name\":\"J. Kato\"}],\"doi\":\"10.1587/TRANSINF.2015EDP7333\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c43b5e008331e44270b6548b49223b31dd93a297\",\"title\":\"Efficient Local Feature Encoding for Human Action Recognition with Approximate Sparse Coding\",\"url\":\"https://www.semanticscholar.org/paper/c43b5e008331e44270b6548b49223b31dd93a297\",\"venue\":\"IEICE Trans. Inf. Syst.\",\"year\":2016},{\"arxivId\":\"1812.04172\",\"authors\":[{\"authorId\":\"3313330\",\"name\":\"Gedas Bertasius\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"46865129\",\"name\":\"J. Shi\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e412efc9baecddac274639c0a5140aa28446792c\",\"title\":\"Learning Discriminative Motion Features Through Detection\",\"url\":\"https://www.semanticscholar.org/paper/e412efc9baecddac274639c0a5140aa28446792c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1904.05582\",\"authors\":[{\"authorId\":\"50986865\",\"name\":\"A. Nicolicioiu\"},{\"authorId\":\"51011850\",\"name\":\"Iulia Duta\"},{\"authorId\":\"1749627\",\"name\":\"M. Leordeanu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"56d7309ae0fccc0de5b09c3d426e09287498e4c3\",\"title\":\"Recurrent Space-time Graph Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/56d7309ae0fccc0de5b09c3d426e09287498e4c3\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46651582\",\"name\":\"C. Li\"},{\"authorId\":\"2891860\",\"name\":\"Yue Ming\"},{\"authorId\":\"1916963\",\"name\":\"Y. Shen\"},{\"authorId\":\"89080361\",\"name\":\"Hui Yu\"}],\"doi\":\"10.1109/ICMEW.2019.00034\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c96638d66c1d3423aea1c2f21436e22bc8cd3d7f\",\"title\":\"Deep Key Clips-Video Feature Fusion Framework for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c96638d66c1d3423aea1c2f21436e22bc8cd3d7f\",\"venue\":\"2019 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48434550\",\"name\":\"Y. Bo\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"129c6d8e8695c40806cc696f350f35369c07233b\",\"title\":\"Design and Implementation of Behavior Recognition System Based on Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/129c6d8e8695c40806cc696f350f35369c07233b\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33230676\",\"name\":\"Kiwon Yun\"},{\"authorId\":\"1744068\",\"name\":\"J. Honorio\"},{\"authorId\":\"33623895\",\"name\":\"D. Chattopadhyay\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"145654220\",\"name\":\"D. Samaras\"}],\"doi\":\"10.1109/CVPRW.2012.6239234\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"10d85459ab6a9350931fcb4709bba171cd31bbde\",\"title\":\"Two-person interaction detection using body-pose features and multiple instance learning\",\"url\":\"https://www.semanticscholar.org/paper/10d85459ab6a9350931fcb4709bba171cd31bbde\",\"venue\":\"2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1792719\",\"name\":\"Vincent Delaitre\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d9754deb51c8435f865e53f3788278839b2e9100\",\"title\":\"Modeling and Recognizing Interactions between People, Objects and Scenes. (Mod\\u00e9lisation et Reconnaissance des Interactions entre les Personnes, les Objets et les Sc\\u00e8nes)\",\"url\":\"https://www.semanticscholar.org/paper/d9754deb51c8435f865e53f3788278839b2e9100\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1695223\",\"name\":\"L. Wang\"},{\"authorId\":\"1692389\",\"name\":\"H. Sahbi\"}],\"doi\":\"10.1007/978-3-319-16199-0_4\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"dbaf89ca98dda2c99157c46abd136ace5bdc33b3\",\"title\":\"Nonlinear Cross-View Sample Enrichment for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/dbaf89ca98dda2c99157c46abd136ace5bdc33b3\",\"venue\":\"ECCV Workshops\",\"year\":2014},{\"arxivId\":\"1909.08611\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"51463388\",\"name\":\"G. Kapidis\"},{\"authorId\":\"2358813\",\"name\":\"Grigorios Kalliatakis\"},{\"authorId\":\"49018286\",\"name\":\"C. Chrysoulas\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"},{\"authorId\":\"1739867\",\"name\":\"R. Veltkamp\"}],\"doi\":\"10.1109/ICCVW.2019.00524\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"aaf75022b71fb0346b476ba1b8ad7ec9633d2f58\",\"title\":\"Class Feature Pyramids for Video Explanation\",\"url\":\"https://www.semanticscholar.org/paper/aaf75022b71fb0346b476ba1b8ad7ec9633d2f58\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152506137\",\"name\":\"F. Zhu\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"},{\"authorId\":\"152539938\",\"name\":\"J. Xie\"},{\"authorId\":\"144145644\",\"name\":\"Yi Fang\"}],\"doi\":\"10.1016/j.imavis.2016.06.007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"465bd4e269b455d2607b8bf08538cf098688d82d\",\"title\":\"From handcrafted to learned representations for human action recognition: A survey\",\"url\":\"https://www.semanticscholar.org/paper/465bd4e269b455d2607b8bf08538cf098688d82d\",\"venue\":\"Image Vis. Comput.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144682140\",\"name\":\"R. Venkatesh Babu\"},{\"authorId\":\"40543505\",\"name\":\"Badrinarayanan Rangarajan\"},{\"authorId\":\"1783193\",\"name\":\"S. Suresh\"},{\"authorId\":\"37977601\",\"name\":\"M. Tom\"}],\"doi\":\"10.1016/j.asoc.2015.06.054\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1d8cf725898393cffa685cc767193783ac61d197\",\"title\":\"Human action recognition in H.264/AVC compressed domain using meta-cognitive radial basis function network\",\"url\":\"https://www.semanticscholar.org/paper/1d8cf725898393cffa685cc767193783ac61d197\",\"venue\":\"Appl. Soft Comput.\",\"year\":2015},{\"arxivId\":\"1507.05738\",\"authors\":[{\"authorId\":\"34149749\",\"name\":\"Serena Yeung\"},{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"47243342\",\"name\":\"N. Jin\"},{\"authorId\":\"1906895\",\"name\":\"M. Andriluka\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-017-1013-y\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"aa2d1dac4e27aebfb759d6e0b41b8a8ab1b01406\",\"title\":\"Every Moment Counts: Dense Detailed Labeling of Actions in Complex Videos\",\"url\":\"https://www.semanticscholar.org/paper/aa2d1dac4e27aebfb759d6e0b41b8a8ab1b01406\",\"venue\":\"International Journal of Computer Vision\",\"year\":2017},{\"arxivId\":\"1506.02588\",\"authors\":[{\"authorId\":\"3271933\",\"name\":\"M. Douze\"},{\"authorId\":\"3428663\",\"name\":\"J\\u00e9r\\u00f4me Revaud\"},{\"authorId\":\"1721683\",\"name\":\"J. Verbeek\"},{\"authorId\":\"1681054\",\"name\":\"H. J\\u00e9gou\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1007/s11263-015-0875-0\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"26a6cb38727cd987c872a4dbba2f01708b73dcf3\",\"title\":\"Circulant Temporal Encoding for Video Retrieval and Temporal Alignment\",\"url\":\"https://www.semanticscholar.org/paper/26a6cb38727cd987c872a4dbba2f01708b73dcf3\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1808816\",\"name\":\"Jianxin Wu\"},{\"authorId\":\"46867148\",\"name\":\"Y. Zhang\"},{\"authorId\":\"8131625\",\"name\":\"W. Lin\"}],\"doi\":\"10.1109/CVPR.2014.330\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"48ce52c12e15300be979807ecf49978ad7f2f861\",\"title\":\"Towards Good Practices for Action Video Encoding\",\"url\":\"https://www.semanticscholar.org/paper/48ce52c12e15300be979807ecf49978ad7f2f861\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"2008.03800\",\"authors\":[{\"authorId\":\"47519958\",\"name\":\"Rui Qian\"},{\"authorId\":\"1486442460\",\"name\":\"Tianjian Meng\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"3154495\",\"name\":\"H. Wang\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"1387716705\",\"name\":\"Yin Cui\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1f3a9a431dc5bf813455ac89df5c0a4e747bc553\",\"title\":\"Spatiotemporal Contrastive Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/1f3a9a431dc5bf813455ac89df5c0a4e747bc553\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2007.13278\",\"authors\":[{\"authorId\":\"40482726\",\"name\":\"R. Devon Hjelm\"},{\"authorId\":\"143902541\",\"name\":\"Philip Bachman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"04ea5fe569cd48c588b7fe420965016ed4ddd312\",\"title\":\"Representation Learning with Video Deep InfoMax\",\"url\":\"https://www.semanticscholar.org/paper/04ea5fe569cd48c588b7fe420965016ed4ddd312\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1392587795\",\"name\":\"George Pikramenos\"},{\"authorId\":\"50231158\",\"name\":\"Eirini Mathe\"},{\"authorId\":\"1803397415\",\"name\":\"Eleanna Vali\"},{\"authorId\":\"51031275\",\"name\":\"Ioannis Vernikos\"},{\"authorId\":\"1780666349\",\"name\":\"Antonios Papadakis\"},{\"authorId\":\"144116678\",\"name\":\"E. Spyrou\"},{\"authorId\":\"1557499363\",\"name\":\"Phivos Mylonas\"}],\"doi\":\"10.1007/s00521-020-05162-5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e0140396832ae0e2fc1c1e27e6417b7ce35c592d\",\"title\":\"An adversarial semi-supervised approach for action recognition from pose information\",\"url\":\"https://www.semanticscholar.org/paper/e0140396832ae0e2fc1c1e27e6417b7ce35c592d\",\"venue\":\"Neural Computing and Applications\",\"year\":2020},{\"arxivId\":\"2006.15489\",\"authors\":[{\"authorId\":\"49984891\",\"name\":\"Ceyuan Yang\"},{\"authorId\":\"121983635\",\"name\":\"Yinghao Xu\"},{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"3cb65b26e407e7464223e9568010965fe73ae61f\",\"title\":\"Video Representation Learning with Visual Tempo Consistency\",\"url\":\"https://www.semanticscholar.org/paper/3cb65b26e407e7464223e9568010965fe73ae61f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1907.11272\",\"authors\":[{\"authorId\":\"10385459\",\"name\":\"Noor Al-M\\u00e1adeed\"},{\"authorId\":\"1693388823\",\"name\":\"Omar Elharrouss\"},{\"authorId\":\"1406702495\",\"name\":\"S. Al-M\\u00e1adeed\"},{\"authorId\":\"71753708\",\"name\":\"A. Bouridane\"},{\"authorId\":\"1731553\",\"name\":\"Azeddine Beghdadi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e86020284db7de53d85b11ba7818aea80f9247f0\",\"title\":\"A Novel Approach for Robust Multi Human Action Recognition and Summarization based on 3D Convolutional Neural Networks.\",\"url\":\"https://www.semanticscholar.org/paper/e86020284db7de53d85b11ba7818aea80f9247f0\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2006.13662\",\"authors\":[{\"authorId\":\"47792365\",\"name\":\"Y. Asano\"},{\"authorId\":null,\"name\":\"Mandela Patrick\"},{\"authorId\":\"49359942\",\"name\":\"C. Rupprecht\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"008ba3c574f8e5085dfb1eef0342e8b408565e45\",\"title\":\"Labelling unlabelled videos from scratch with multi-modal self-supervision\",\"url\":\"https://www.semanticscholar.org/paper/008ba3c574f8e5085dfb1eef0342e8b408565e45\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2004.05214\",\"authors\":[{\"authorId\":\"152298373\",\"name\":\"Sergiu Oprea\"},{\"authorId\":\"1410236705\",\"name\":\"P. Martinez-Gonzalez\"},{\"authorId\":\"1397392435\",\"name\":\"Alberto Garcia-Garcia\"},{\"authorId\":\"1410269918\",\"name\":\"John Alejandro Castro-Vargas\"},{\"authorId\":\"1405686926\",\"name\":\"S. Orts-Escolano\"},{\"authorId\":\"1429069120\",\"name\":\"J. Garci\\u0301a-Rodri\\u0301guez\"},{\"authorId\":\"1689415\",\"name\":\"Antonis A. Argyros\"}],\"doi\":\"10.1109/TPAMI.2020.3045007\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ded24959bbd7715073fa700d5898cdbb2b8353f7\",\"title\":\"A Review on Deep Learning Techniques for Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/ded24959bbd7715073fa700d5898cdbb2b8353f7\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"1907.08340\",\"authors\":[{\"authorId\":\"1403581832\",\"name\":\"Laura Sevilla-Lara\"},{\"authorId\":\"2815926\",\"name\":\"Shengxin Zha\"},{\"authorId\":\"3305169\",\"name\":\"Zhicheng Yan\"},{\"authorId\":\"28554843\",\"name\":\"Vedanuj Goswami\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8e79a677855462aa55ea252ffb35c8cac1fed26e\",\"title\":\"Only Time Can Tell: Discovering Temporal Data for Temporal Modeling\",\"url\":\"https://www.semanticscholar.org/paper/8e79a677855462aa55ea252ffb35c8cac1fed26e\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12277476\",\"name\":\"Lifei Song\"},{\"authorId\":\"1779987\",\"name\":\"Liguo Weng\"},{\"authorId\":\"46660013\",\"name\":\"L. Wang\"},{\"authorId\":\"47715056\",\"name\":\"Min Xia\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.1109/ICIP.2018.8451662\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9c23acb6e9b76dd9b4bdacf4974b42e8c45f5260\",\"title\":\"Two-Stream Designed 2D/3D Residual Networks with Lstms for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/9c23acb6e9b76dd9b4bdacf4974b42e8c45f5260\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8962288\",\"name\":\"Zichen zhou\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"498a1e7c6de343dac40f374c4e812e64c6c7826f\",\"title\":\"Attention Before and After Feature Extraction for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/498a1e7c6de343dac40f374c4e812e64c6c7826f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1605.08140\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"2047692\",\"name\":\"Chenyou Fan\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0ee7990e2ae054aab5f1fc08670fe5eddb96fb19\",\"title\":\"Temporal attention filters for human activity recognition in videos\",\"url\":\"https://www.semanticscholar.org/paper/0ee7990e2ae054aab5f1fc08670fe5eddb96fb19\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1401918692\",\"name\":\"M. Sesma-Sara\"},{\"authorId\":\"3359390\",\"name\":\"L. Miguel\"},{\"authorId\":\"144898575\",\"name\":\"M. Pagola\"},{\"authorId\":\"1765261\",\"name\":\"A. Burusco\"},{\"authorId\":\"1763514\",\"name\":\"R. Mesiar\"},{\"authorId\":\"1715030\",\"name\":\"H. Bustince\"}],\"doi\":\"10.1016/J.APM.2018.05.006\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6d19b0f30cbc0776cad35b6b3bf2da8433c9d234\",\"title\":\"New measures for comparing matrices and their application to image processing\",\"url\":\"https://www.semanticscholar.org/paper/6d19b0f30cbc0776cad35b6b3bf2da8433c9d234\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1608.01529\",\"authors\":[{\"authorId\":null,\"name\":\"Suman Saha\"},{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":\"145466505\",\"name\":\"M. Sapienza\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":\"10.5244/C.30.58\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6b0983e11312938381bb9d11ef42612aaf78f5f4\",\"title\":\"Deep Learning for Detecting Multiple Space-Time Action Tubes in Videos\",\"url\":\"https://www.semanticscholar.org/paper/6b0983e11312938381bb9d11ef42612aaf78f5f4\",\"venue\":\"BMVC\",\"year\":2016},{\"arxivId\":\"1604.08826\",\"authors\":[{\"authorId\":\"8197937\",\"name\":\"K. Ohnishi\"},{\"authorId\":\"2859204\",\"name\":\"Masatoshi Hidaka\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.1145/2964284.2967222\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"da48af74960c84750de3cfc1c9c9a5b5252d330c\",\"title\":\"Improved Dense Trajectory with Cross Streams\",\"url\":\"https://www.semanticscholar.org/paper/da48af74960c84750de3cfc1c9c9a5b5252d330c\",\"venue\":\"ACM Multimedia\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"122822134\",\"name\":\"Gregory Casta\\u00f1\\u00f3n\"},{\"authorId\":\"2962929\",\"name\":\"Nathan Shnidman\"},{\"authorId\":\"145901595\",\"name\":\"Tim Anderson\"},{\"authorId\":\"145607579\",\"name\":\"Jeffrey Byrne\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a2b840276017c04e090058e281431379d35de88b\",\"title\":\"Out the Window: A Crowd-Sourced Dataset for Activity Classification in Security Video\",\"url\":\"https://www.semanticscholar.org/paper/a2b840276017c04e090058e281431379d35de88b\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47125215\",\"name\":\"G. Yang\"},{\"authorId\":\"1784263\",\"name\":\"Yafeng Yin\"},{\"authorId\":\"144047501\",\"name\":\"J. Xu\"},{\"authorId\":\"144484158\",\"name\":\"Hong Man\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a9c925d4af85360d9a230223e9f3a8e0d1612549\",\"title\":\"RECOGNIZING INTERACTIONS BETWEEN HUMAN AND OBJECT BASED ON SOCIAL NETWORK ANALYSIS\",\"url\":\"https://www.semanticscholar.org/paper/a9c925d4af85360d9a230223e9f3a8e0d1612549\",\"venue\":\"\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2142272\",\"name\":\"Jong Moo Lee\"},{\"authorId\":\"2059257\",\"name\":\"E. Park\"},{\"authorId\":\"3392973\",\"name\":\"Tae-Du Jung\"}],\"doi\":\"10.3390/s19183873\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"03d3bb3b703df3d7a05422c35daeaa4bb76aac0c\",\"title\":\"Automatic Detection of the Pharyngeal Phase in Raw Videos for the Videofluoroscopic Swallowing Study Using Efficient Data Collection and 3D Convolutional Networks \\u2020\",\"url\":\"https://www.semanticscholar.org/paper/03d3bb3b703df3d7a05422c35daeaa4bb76aac0c\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46213138\",\"name\":\"Minyoung Huh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3fa7405a3ac4487ab44a9098b8f315931159a017\",\"title\":\"Temporal Scene Completion with Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/3fa7405a3ac4487ab44a9098b8f315931159a017\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144997028\",\"name\":\"L. Li\"},{\"authorId\":\"145274329\",\"name\":\"Zhaoxiang Zhang\"},{\"authorId\":\"49867037\",\"name\":\"Y. Huang\"},{\"authorId\":\"49681016\",\"name\":\"L. Wang\"}],\"doi\":\"10.1109/ICPR.2018.8546263\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ecbe158c795b2bdbad9a16ac40a12a09c6bf11f1\",\"title\":\"Deep Temporal Feature Encoding for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ecbe158c795b2bdbad9a16ac40a12a09c6bf11f1\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":\"2003.08042\",\"authors\":[{\"authorId\":\"66562585\",\"name\":\"Xu Li\"},{\"authorId\":\"46584062\",\"name\":\"Junling Wang\"},{\"authorId\":\"152309767\",\"name\":\"L. Ma\"},{\"authorId\":\"3397429\",\"name\":\"K. Zhang\"},{\"authorId\":\"1568961008\",\"name\":\"Fengzong Lian\"},{\"authorId\":\"2705857\",\"name\":\"Zhanhui Kang\"},{\"authorId\":\"71563118\",\"name\":\"Jinjun Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"786a010cb738fe28bb44fcff790966a380c9da56\",\"title\":\"STH: Spatio-Temporal Hybrid Convolution for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/786a010cb738fe28bb44fcff790966a380c9da56\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1611.08663\",\"authors\":[{\"authorId\":\"1735328\",\"name\":\"X. Xu\"},{\"authorId\":\"1697755\",\"name\":\"Timothy M. Hospedales\"},{\"authorId\":\"144784813\",\"name\":\"S. Gong\"}],\"doi\":\"10.1007/978-3-319-46475-6_22\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"ddc6a27f60b42576c0e4ba0a730554ac7e8bd6b0\",\"title\":\"Multi-Task Zero-Shot Action Recognition with Prioritised Data Augmentation\",\"url\":\"https://www.semanticscholar.org/paper/ddc6a27f60b42576c0e4ba0a730554ac7e8bd6b0\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410122921\",\"name\":\"Yuan Yuan\"},{\"authorId\":\"2263014\",\"name\":\"Xiangtao Zheng\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"}],\"doi\":\"10.1016/j.patcog.2016.02.022\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ec6a2093059fd6eada9944212f64a659881abb95\",\"title\":\"A discriminative representation for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/ec6a2093059fd6eada9944212f64a659881abb95\",\"venue\":\"Pattern Recognit.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1745546\",\"name\":\"Meng Chen\"},{\"authorId\":\"3004652\",\"name\":\"Liyu Gong\"},{\"authorId\":\"8269333\",\"name\":\"Tianjiang Wang\"},{\"authorId\":\"145922230\",\"name\":\"Fang Liu\"},{\"authorId\":\"145515370\",\"name\":\"Qi Feng\"}],\"doi\":\"10.1007/s11042-015-3008-4\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c6fc6d3d69612643bb6f376d7d782ee7de4792ee\",\"title\":\"Modeling spatio-temporal layout with Lie Algebrized Gaussians for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/c6fc6d3d69612643bb6f376d7d782ee7de4792ee\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47781687\",\"name\":\"Z. Liu\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"},{\"authorId\":\"49050918\",\"name\":\"J. Zhang\"}],\"doi\":\"10.1007/s11063-018-09972-6\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"33c615be88df63dfd0e8f1b770066f062ee8d157\",\"title\":\"Spatiotemporal Fusion Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/33c615be88df63dfd0e8f1b770066f062ee8d157\",\"venue\":\"Neural Processing Letters\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49050918\",\"name\":\"J. Zhang\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1109/ACCESS.2019.2895472\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"82d4b2272799f0c4acc284bbc6ed3eaeeefdc7c0\",\"title\":\"Deep Spatiotemporal Relation Learning With 3D Multi-Level Dense Fusion for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/82d4b2272799f0c4acc284bbc6ed3eaeeefdc7c0\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38764391\",\"name\":\"Shiwei Zhang\"},{\"authorId\":\"50561740\",\"name\":\"J. Zhang\"},{\"authorId\":\"3261880\",\"name\":\"F. Chen\"},{\"authorId\":\"1707161\",\"name\":\"N. Sang\"}],\"doi\":\"10.1109/TMM.2017.2758524\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6c9bec537353ec3ae7affbc6f5c58ed563852391\",\"title\":\"Discriminative Part Selection for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6c9bec537353ec3ae7affbc6f5c58ed563852391\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145749579\",\"name\":\"R. Hou\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1007/978-3-319-10578-9_47\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bae879849050b9731ba9bb5506cce7d0f7533a3f\",\"title\":\"DaMN - Discriminative and Mutually Nearest: Exploiting Pairwise Category Proximity for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/bae879849050b9731ba9bb5506cce7d0f7533a3f\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2356016\",\"name\":\"Minh Hoai\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/978-3-319-16817-3_15\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ec2930c15d017a34cf78d7bb9b5cd15592481110\",\"title\":\"Thread-Safe: Towards Recognizing Human Actions Across Shot Boundaries\",\"url\":\"https://www.semanticscholar.org/paper/ec2930c15d017a34cf78d7bb9b5cd15592481110\",\"venue\":\"ACCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50726620\",\"name\":\"Konstantinos Raptis\"}],\"doi\":\"10.7912/C2CW7G\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"218eff05ba07f488e2c11c2f6f3a73dbf4b8dab9\",\"title\":\"The clash between two worlds in human action recognition: Supervised feature training vs recurrent ConvNet\",\"url\":\"https://www.semanticscholar.org/paper/218eff05ba07f488e2c11c2f6f3a73dbf4b8dab9\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40241836\",\"name\":\"L. Liu\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"},{\"authorId\":\"34798935\",\"name\":\"Xiantong Zhen\"},{\"authorId\":\"1720243\",\"name\":\"X. Li\"}],\"doi\":\"10.1109/TSMCB.2012.2231959\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"da171d1fae6030bfb0effdf33b28c55395b977e1\",\"title\":\"Learning Discriminative Key Poses for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/da171d1fae6030bfb0effdf33b28c55395b977e1\",\"venue\":\"IEEE Transactions on Cybernetics\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1799820\",\"name\":\"Adrien Gaidon\"},{\"authorId\":\"1753355\",\"name\":\"Z. Harchaoui\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1007/s11263-013-0677-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d83c2948c37421913c425a76c3dcc292fac0471d\",\"title\":\"Activity representation with motion hierarchies\",\"url\":\"https://www.semanticscholar.org/paper/d83c2948c37421913c425a76c3dcc292fac0471d\",\"venue\":\"International Journal of Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145327729\",\"name\":\"Feng Shi\"},{\"authorId\":\"1745632\",\"name\":\"E. Petriu\"},{\"authorId\":\"2035718\",\"name\":\"R. Lagani\\u00e8re\"}],\"doi\":\"10.1109/CVPR.2013.335\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b360fdc731997ad2efe4ab0687057f691f365c62\",\"title\":\"Sampling Strategies for Real-Time Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b360fdc731997ad2efe4ab0687057f691f365c62\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145732825\",\"name\":\"Xiaoqiang Yan\"},{\"authorId\":\"2382085\",\"name\":\"Y. Ye\"},{\"authorId\":\"21862760\",\"name\":\"Xueying Qiu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c9559fa215d6d16bb54f5af9ab9d1ee9673c2e45\",\"title\":\"Unsupervised Human Action Categorization with Consensus Information Bottleneck Method\",\"url\":\"https://www.semanticscholar.org/paper/c9559fa215d6d16bb54f5af9ab9d1ee9673c2e45\",\"venue\":\"IJCAI\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46431991\",\"name\":\"K. Huang\"},{\"authorId\":\"2366069\",\"name\":\"Sarah Jane Delany\"},{\"authorId\":\"143667097\",\"name\":\"Susan McKeever\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"275dc648335bff8c4e73e650b791d29fc1595e14\",\"title\":\"Human Action Recognition in Videos Using Transfer Learning\",\"url\":\"https://www.semanticscholar.org/paper/275dc648335bff8c4e73e650b791d29fc1595e14\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"34066479\",\"name\":\"Vignesh Ramanathan\"},{\"authorId\":\"144542135\",\"name\":\"D. Mahajan\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3afd90a0675936e2f747171a1063d8171d987656\",\"title\":\"l 1 l 2 l 3 l 4 l 5 ( a ) Class-Agnostic Temporal\",\"url\":\"https://www.semanticscholar.org/paper/3afd90a0675936e2f747171a1063d8171d987656\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1885339245\",\"name\":\"Ana-Cosmina Popescu\"},{\"authorId\":\"2595036\",\"name\":\"I. Mocanu\"},{\"authorId\":\"143623623\",\"name\":\"B. Cramariuc\"}],\"doi\":\"10.1109/ACCESS.2020.3013406\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"444cebeebce47adec38e43a0789d6cf2610c1fc9\",\"title\":\"Fusion Mechanisms for Human Activity Recognition Using Automated Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/444cebeebce47adec38e43a0789d6cf2610c1fc9\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1391201846\",\"name\":\"Jianyu Chen\"},{\"authorId\":\"144749222\",\"name\":\"J. Kong\"},{\"authorId\":\"1801474\",\"name\":\"Hui Sun\"},{\"authorId\":\"49507094\",\"name\":\"H. Xu\"},{\"authorId\":\"4058024\",\"name\":\"X. Liu\"},{\"authorId\":\"1774877\",\"name\":\"Ying-hua Lu\"},{\"authorId\":\"5858971\",\"name\":\"Caixia Zheng\"}],\"doi\":\"10.3390/s20113126\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"12afacc80852a3cffa18722ef43c0d82746ff66c\",\"title\":\"Spatiotemporal Interaction Residual Networks with Pseudo3D for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/12afacc80852a3cffa18722ef43c0d82746ff66c\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153188471\",\"name\":\"J. Kim\"},{\"authorId\":\"1706549\",\"name\":\"C. Won\"}],\"doi\":\"10.1109/ACCESS.2020.2983427\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d091af317fa1e58c6e8222d0048fd5de8cfa3065\",\"title\":\"Action Recognition in Videos Using Pre-Trained 2D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/d091af317fa1e58c6e8222d0048fd5de8cfa3065\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2002.09423\",\"authors\":[{\"authorId\":\"31915818\",\"name\":\"D. Torpey\"},{\"authorId\":\"48627696\",\"name\":\"T. \\u00c7elik\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5e7f485a76d95127158683b7bbe386df98394f42\",\"title\":\"Human Action Recognition using Local Two-Stream Convolution Neural Network Features and Support Vector Machines\",\"url\":\"https://www.semanticscholar.org/paper/5e7f485a76d95127158683b7bbe386df98394f42\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48093549\",\"name\":\"Jinpeng Wang\"},{\"authorId\":\"29995014\",\"name\":\"Shiren Li\"},{\"authorId\":\"30646831\",\"name\":\"Zhi-kui Duan\"},{\"authorId\":\"48803999\",\"name\":\"Z. Yuan\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053794\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a021daf17351415827420456377f77f6a146fd56\",\"title\":\"Rethinking Temporal-Related Sample for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a021daf17351415827420456377f77f6a146fd56\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34526205\",\"name\":\"K. Chen\"},{\"authorId\":\"38329336\",\"name\":\"G. Ding\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"}],\"doi\":\"10.1007/s11704-016-6066-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"06b9aa210e42ea808cc454be162fd1da0f6f3ea5\",\"title\":\"Attribute-based supervised deep learning model for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/06b9aa210e42ea808cc454be162fd1da0f6f3ea5\",\"venue\":\"Frontiers of Computer Science\",\"year\":2016},{\"arxivId\":\"2008.01232\",\"authors\":[{\"authorId\":\"1395788009\",\"name\":\"M. E. Kalfaoglu\"},{\"authorId\":\"1699609\",\"name\":\"Sinan Kalkan\"},{\"authorId\":\"1751998\",\"name\":\"Aydin Alatan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dce965db955113b3710c9977dc5f68f3bfd85c4b\",\"title\":\"Late Temporal Modeling in 3D CNN Architectures with BERT for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/dce965db955113b3710c9977dc5f68f3bfd85c4b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145184141\",\"name\":\"Yifan Wang\"},{\"authorId\":\"40403685\",\"name\":\"J. Song\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"2531379\",\"name\":\"Otmar Hilliges\"}],\"doi\":\"10.5244/C.30.108\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b09b693708f412823053508578df289b8403100a\",\"title\":\"Two-Stream SR-CNNs for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/b09b693708f412823053508578df289b8403100a\",\"venue\":\"BMVC\",\"year\":2016},{\"arxivId\":\"2004.01398\",\"authors\":[{\"authorId\":\"48513712\",\"name\":\"Y. Li\"},{\"authorId\":\"102880425\",\"name\":\"Bin Ji\"},{\"authorId\":\"48203223\",\"name\":\"Xintian Shi\"},{\"authorId\":\"98697812\",\"name\":\"J. Zhang\"},{\"authorId\":\"48418655\",\"name\":\"Bin Kang\"},{\"authorId\":\"48170350\",\"name\":\"Limin Wang\"}],\"doi\":\"10.1109/cvpr42600.2020.00099\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1ebeb84e2b8e1182a2b4821c906200ecc49ae187\",\"title\":\"TEA: Temporal Excitation and Aggregation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1ebeb84e2b8e1182a2b4821c906200ecc49ae187\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52622630\",\"name\":\"Kaustubh Sakhalkar\"},{\"authorId\":\"1729410\",\"name\":\"F. Bremond\"}],\"doi\":\"10.1109/IPAS.2018.8708877\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a367717713174d18b3adc4a90d7af7d171dd8ce7\",\"title\":\"Learning to Represent Spatio-Temporal Features for Fine Grained Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a367717713174d18b3adc4a90d7af7d171dd8ce7\",\"venue\":\"2018 IEEE International Conference on Image Processing, Applications and Systems (IPAS)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92422787\",\"name\":\"X. Wang\"},{\"authorId\":\"145175070\",\"name\":\"C. Qi\"}],\"doi\":\"10.1007/s11042-019-08535-8\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0359bf810974ff6bbd61f543f6c33aa1dad25603\",\"title\":\"Detecting action-relevant regions for action recognition using a three-stage saliency detection technique\",\"url\":\"https://www.semanticscholar.org/paper/0359bf810974ff6bbd61f543f6c33aa1dad25603\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34798935\",\"name\":\"Xiantong Zhen\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"}],\"doi\":\"10.1016/j.imavis.2016.02.006\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b7a5fcb9ddaf3232b33aead57141577aaf8e7c2e\",\"title\":\"Action recognition via spatio-temporal local features: A comprehensive study\",\"url\":\"https://www.semanticscholar.org/paper/b7a5fcb9ddaf3232b33aead57141577aaf8e7c2e\",\"venue\":\"Image Vis. Comput.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34798935\",\"name\":\"Xiantong Zhen\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"},{\"authorId\":\"1720243\",\"name\":\"X. Li\"}],\"doi\":\"10.1016/J.INS.2014.05.021\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"290fc6c3b22b3f446caf6b13043e955b13e37ba8\",\"title\":\"Action recognition by spatio-temporal oriented energies\",\"url\":\"https://www.semanticscholar.org/paper/290fc6c3b22b3f446caf6b13043e955b13e37ba8\",\"venue\":\"Inf. Sci.\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1384524187\",\"name\":\"Xuqiang Yin\"},{\"authorId\":\"70258862\",\"name\":\"Dihua Wu\"},{\"authorId\":\"1505801654\",\"name\":\"Yuying Shang\"},{\"authorId\":\"1845918818\",\"name\":\"Bo Jiang\"},{\"authorId\":\"1846177104\",\"name\":\"Huaibo Song\"}],\"doi\":\"10.1016/j.compag.2020.105707\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a598d8c68a2207f4ab921c9912f62eda6c92a1a2\",\"title\":\"Using an EfficientNet-LSTM for the recognition of single Cow's motion behaviours in a complicated environment\",\"url\":\"https://www.semanticscholar.org/paper/a598d8c68a2207f4ab921c9912f62eda6c92a1a2\",\"venue\":\"Comput. Electron. Agric.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"122639155\",\"name\":\"Eyrun-Arna Eyjolfsdottir\"}],\"doi\":\"10.7907/Z9445JJH\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7b43326477795a772c08aee750d3e433f00f20be\",\"title\":\"Computational Methods for Behavior Analysis\",\"url\":\"https://www.semanticscholar.org/paper/7b43326477795a772c08aee750d3e433f00f20be\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1703.10667\",\"authors\":[{\"authorId\":\"7437104\",\"name\":\"Chih-Yao Ma\"},{\"authorId\":\"50133145\",\"name\":\"Min-Hung Chen\"},{\"authorId\":\"145276578\",\"name\":\"Z. Kira\"},{\"authorId\":\"9202076\",\"name\":\"G. Al-Regib\"}],\"doi\":\"10.1016/j.image.2018.09.003\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aac934f2eed758d4a27562dae4e9c5415ff4cdb7\",\"title\":\"TS-LSTM and Temporal-Inception: Exploiting Spatiotemporal Dynamics for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/aac934f2eed758d4a27562dae4e9c5415ff4cdb7\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2019},{\"arxivId\":\"1910.06961\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"2148510\",\"name\":\"A. Angelova\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"7f330ebc8bce345825e3860988aaeb0a7e34ace9\",\"title\":\"Tiny Video Networks\",\"url\":\"https://www.semanticscholar.org/paper/7f330ebc8bce345825e3860988aaeb0a7e34ace9\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1912.04316\",\"authors\":[{\"authorId\":\"34656387\",\"name\":\"Matteo Tomei\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2175529\",\"name\":\"Simone Calderara\"},{\"authorId\":\"102613292\",\"name\":\"Simone Bronzin\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ad16dbe1a5c3b192de961a1f1c3fedeba8bf2783\",\"title\":\"STAGE: Spatio-Temporal Attention on Graph Entities for Video Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/ad16dbe1a5c3b192de961a1f1c3fedeba8bf2783\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1905.11954\",\"authors\":[{\"authorId\":\"2117357\",\"name\":\"Chengxu Zhuang\"},{\"authorId\":\"50112310\",\"name\":\"Alex Andonian\"},{\"authorId\":\"40657572\",\"name\":\"D. Yamins\"}],\"doi\":\"10.1109/CVPR42600.2020.00958\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"02cd7e1a888fedd25337a4598f332c5203091e71\",\"title\":\"Unsupervised Learning From Video With Deep Neural Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/02cd7e1a888fedd25337a4598f332c5203091e71\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1609.06782\",\"authors\":[{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1145/3122865.3122867\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1a4b6ee6cd846ef5e3030a6ae59f026e5f50eda6\",\"title\":\"Deep Learning for Video Classification and Captioning\",\"url\":\"https://www.semanticscholar.org/paper/1a4b6ee6cd846ef5e3030a6ae59f026e5f50eda6\",\"venue\":\"Frontiers of Multimedia Research\",\"year\":2018},{\"arxivId\":\"1604.01753\",\"authors\":[{\"authorId\":\"34280810\",\"name\":\"Gunnar A. Sigurdsson\"},{\"authorId\":\"2668759\",\"name\":\"G. Varol\"},{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1007/978-3-319-46448-0_31\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"21334d1aac5422da88780f8e24e181bfa15ef0e1\",\"title\":\"Hollywood in Homes: Crowdsourcing Data Collection for Activity Understanding\",\"url\":\"https://www.semanticscholar.org/paper/21334d1aac5422da88780f8e24e181bfa15ef0e1\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144289594\",\"name\":\"C. Caetano\"},{\"authorId\":\"6141311\",\"name\":\"J. A. D. Santos\"},{\"authorId\":\"9385043\",\"name\":\"W. Schwartz\"}],\"doi\":\"10.1109/ICPR.2016.7899921\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"cfe678e0c15591c9a85d9023ea2b7e3cf5117339\",\"title\":\"Optical Flow Co-occurrence Matrices: A novel spatiotemporal feature descriptor\",\"url\":\"https://www.semanticscholar.org/paper/cfe678e0c15591c9a85d9023ea2b7e3cf5117339\",\"venue\":\"2016 23rd International Conference on Pattern Recognition (ICPR)\",\"year\":2016},{\"arxivId\":\"1604.07602\",\"authors\":[{\"authorId\":\"40892875\",\"name\":\"Pascal Mettes\"},{\"authorId\":\"1738975\",\"name\":\"J. C. V. Gemert\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1007/978-3-319-46454-1_27\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b1ea1e828256feee129eae3497f41e21bce36a34\",\"title\":\"Spot On: Action Localization from Pointly-Supervised Proposals\",\"url\":\"https://www.semanticscholar.org/paper/b1ea1e828256feee129eae3497f41e21bce36a34\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1511.05788\",\"authors\":[{\"authorId\":\"144713677\",\"name\":\"M. Edwards\"},{\"authorId\":\"6248353\",\"name\":\"Jingjing Deng\"},{\"authorId\":\"2168049\",\"name\":\"X. Xie\"}],\"doi\":\"10.1016/j.cviu.2015.10.010\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0b6bf8700000d52f768ca993b6e5f579cd543a77\",\"title\":\"From pose to activity: Surveying datasets and introducing CONVERSE\",\"url\":\"https://www.semanticscholar.org/paper/0b6bf8700000d52f768ca993b6e5f579cd543a77\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6798639\",\"name\":\"Jinyang Guo\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"1510477221\",\"name\":\"Dong Xu\"}],\"doi\":\"10.1109/cvpr42600.2020.00158\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"ffbcd6379e865f150d2f1d2c7074d5d1e482e547\",\"title\":\"Multi-Dimensional Pruning: A Unified Framework for Model Compression\",\"url\":\"https://www.semanticscholar.org/paper/ffbcd6379e865f150d2f1d2c7074d5d1e482e547\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9272516\",\"name\":\"Suharjito\"},{\"authorId\":\"66416702\",\"name\":\"Herman Gunawan\"},{\"authorId\":\"66467949\",\"name\":\"Narada Thiracitta\"},{\"authorId\":\"1795227\",\"name\":\"A. Nugroho\"}],\"doi\":\"10.1109/INAPR.2018.8627014\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"fe4dbea7d530c21c77137f52fed28c9b0947172b\",\"title\":\"Sign Language Recognition Using Modified Convolutional Neural Network Model\",\"url\":\"https://www.semanticscholar.org/paper/fe4dbea7d530c21c77137f52fed28c9b0947172b\",\"venue\":\"2018 Indonesian Association for Pattern Recognition International Conference (INAPR)\",\"year\":2018},{\"arxivId\":\"1511.06309\",\"authors\":[{\"authorId\":\"1756112\",\"name\":\"Viorica Patraucean\"},{\"authorId\":\"34653454\",\"name\":\"A. Handa\"},{\"authorId\":\"1745672\",\"name\":\"R. Cipolla\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b6e7d0ec83f2a40fadc99bb0f1ced8508f5cfee5\",\"title\":\"Spatio-temporal video autoencoder with differentiable memory\",\"url\":\"https://www.semanticscholar.org/paper/b6e7d0ec83f2a40fadc99bb0f1ced8508f5cfee5\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1705.03146\",\"authors\":[{\"authorId\":\"3491491\",\"name\":\"Shiyang Yan\"},{\"authorId\":\"33830793\",\"name\":\"J. Smith\"},{\"authorId\":\"40178769\",\"name\":\"Wenjin Lu\"},{\"authorId\":\"1782912\",\"name\":\"B. Zhang\"}],\"doi\":\"10.1109/ICIP.2017.8297025\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"463e131ac0d69716d2726bb8ad44ec23628b09d1\",\"title\":\"CHAM: Action recognition using convolutional hierarchical attention model\",\"url\":\"https://www.semanticscholar.org/paper/463e131ac0d69716d2726bb8ad44ec23628b09d1\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":\"1611.06678\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2017.168\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"645de797f936cb19c1b8dba3b862543645510544\",\"title\":\"Deep Temporal Linear Encoding Networks\",\"url\":\"https://www.semanticscholar.org/paper/645de797f936cb19c1b8dba3b862543645510544\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1832019\",\"name\":\"Fuhua Shang\"},{\"authorId\":\"145421603\",\"name\":\"Tao Han\"},{\"authorId\":\"152236895\",\"name\":\"Feng Tian\"},{\"authorId\":\"1884170385\",\"name\":\"Jun Tao\"},{\"authorId\":\"40465774\",\"name\":\"Z. Gao\"}],\"doi\":\"10.1109/ACCESS.2020.3014691\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1c93dfb167a90c2a5a7b802c629327224d4ee806\",\"title\":\"A Multimodal Pairwise Discrimination Network for Cross-Domain Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1c93dfb167a90c2a5a7b802c629327224d4ee806\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46945678\",\"name\":\"T. Singh\"},{\"authorId\":\"47731526\",\"name\":\"D. Vishwakarma\"}],\"doi\":\"10.1007/s10462-018-9651-1\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9018e160b6e73f6816939a37b3e392033d610f09\",\"title\":\"Video benchmarks of human action datasets: a review\",\"url\":\"https://www.semanticscholar.org/paper/9018e160b6e73f6816939a37b3e392033d610f09\",\"venue\":\"Artificial Intelligence Review\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143879230\",\"name\":\"Jianjun Lei\"},{\"authorId\":\"88728572\",\"name\":\"Yalong Jia\"},{\"authorId\":\"144690387\",\"name\":\"B. Peng\"},{\"authorId\":\"1689702\",\"name\":\"Q. Huang\"}],\"doi\":\"10.1109/ICME.2019.00103\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"fe717940e455424c5fa25cc4343e7a42e0d005b6\",\"title\":\"Channel-wise Temporal Attention Network for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fe717940e455424c5fa25cc4343e7a42e0d005b6\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145141847\",\"name\":\"M. Fan\"},{\"authorId\":\"145264515\",\"name\":\"Qi Han\"},{\"authorId\":\"47956995\",\"name\":\"X. Zhang\"},{\"authorId\":\"47910149\",\"name\":\"Yaling Liu\"},{\"authorId\":\"10993830\",\"name\":\"Huan Chen\"},{\"authorId\":\"48484029\",\"name\":\"Y. Hu\"}],\"doi\":\"10.1109/DDCLS.2018.8515970\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"7f3b0452e11e44c9adb16e228defc3966e04334e\",\"title\":\"Human Action Recognition Based on Dense Sampling of Motion Boundary and Histogram of Motion Gradient\",\"url\":\"https://www.semanticscholar.org/paper/7f3b0452e11e44c9adb16e228defc3966e04334e\",\"venue\":\"2018 IEEE 7th Data Driven Control and Learning Systems Conference (DDCLS)\",\"year\":2018},{\"arxivId\":\"1804.04527\",\"authors\":[{\"authorId\":\"22314218\",\"name\":\"Silvio Giancola\"},{\"authorId\":\"41022271\",\"name\":\"Mohieddine Amine\"},{\"authorId\":\"41015552\",\"name\":\"Tarek Dghaily\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1109/CVPRW.2018.00223\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"982f2025925062aeafac07ae015c9ed273e4d3d6\",\"title\":\"SoccerNet: A Scalable Dataset for Action Spotting in Soccer Videos\",\"url\":\"https://www.semanticscholar.org/paper/982f2025925062aeafac07ae015c9ed273e4d3d6\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2018},{\"arxivId\":\"1501.06993\",\"authors\":[{\"authorId\":\"1746008\",\"name\":\"Youjie Zhou\"},{\"authorId\":\"1730682\",\"name\":\"Hongkai Yu\"},{\"authorId\":\"30102584\",\"name\":\"S. Wang\"}],\"doi\":\"10.1109/ICIP.2017.8297027\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"0be0dcbd7284994145d072f7a24db52a210f22ed\",\"title\":\"Feature sampling strategies for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/0be0dcbd7284994145d072f7a24db52a210f22ed\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36475565\",\"name\":\"Yang Cai\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"},{\"authorId\":\"1679880\",\"name\":\"H. Wactlar\"}],\"doi\":\"10.1007/978-3-319-17963-6_14\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a6084786059e21c9521e81cd1326c4859c665b4b\",\"title\":\"Monitoring and Coaching the Use of Home Medical Devices\",\"url\":\"https://www.semanticscholar.org/paper/a6084786059e21c9521e81cd1326c4859c665b4b\",\"venue\":\"Health Monitoring and Personalized Feedback using Multimedia Data\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2022851423\",\"name\":\"Swarnava Sadhukhan\"},{\"authorId\":\"2021176735\",\"name\":\"Siddhartha Mallick\"},{\"authorId\":\"143730686\",\"name\":\"P. Singh\"},{\"authorId\":\"70680168\",\"name\":\"R. Sarkar\"},{\"authorId\":\"89542097\",\"name\":\"D. Bhattacharjee\"}],\"doi\":\"10.1007/978-981-15-4288-6_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cdbfb09e44e83e3e4a5c2d9765fde3522d264121\",\"title\":\"A Comparative Study of Different Feature Descriptors for Video-Based Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cdbfb09e44e83e3e4a5c2d9765fde3522d264121\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1504.04792\",\"authors\":[{\"authorId\":\"1808816\",\"name\":\"Jianxin Wu\"},{\"authorId\":\"2226422\",\"name\":\"Bin-Bin Gao\"},{\"authorId\":\"144349436\",\"name\":\"G. Liu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"260f369827ac7cd76097ff61b3eda6c1d30b8668\",\"title\":\"Visual Recognition Using Directional Distribution Distance\",\"url\":\"https://www.semanticscholar.org/paper/260f369827ac7cd76097ff61b3eda6c1d30b8668\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1312.5785\",\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b1c84ab7cc0c85e8aa8be4c0ec32bad225c9c630\",\"title\":\"EXMOVES: Classifier-based Features for Scalable Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b1c84ab7cc0c85e8aa8be4c0ec32bad225c9c630\",\"venue\":\"ICLR\",\"year\":2014},{\"arxivId\":\"2010.09982\",\"authors\":[{\"authorId\":\"1993669388\",\"name\":\"Yuqian Fu\"},{\"authorId\":\"31267246\",\"name\":\"L. Zhang\"},{\"authorId\":\"1993529318\",\"name\":\"Junke Wang\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1145/3394171.3413502\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8abe9a4d432cc4c43a11f9336cd105d1be30ae92\",\"title\":\"Depth Guided Adaptive Meta-Fusion Network for Few-shot Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8abe9a4d432cc4c43a11f9336cd105d1be30ae92\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40416440\",\"name\":\"W. Ahmed\"},{\"authorId\":\"1697680\",\"name\":\"M. Yousaf\"}],\"doi\":\"10.1109/ICECUBE.2018.8610974\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"81fb2420777d017da2c8b020f1858e31cdcb6812\",\"title\":\"Robust Activity Recognition Model Via Motion Templates\",\"url\":\"https://www.semanticscholar.org/paper/81fb2420777d017da2c8b020f1858e31cdcb6812\",\"venue\":\"2018 International Conference on Computing, Electronic and Electrical Engineering (ICE Cube)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35153466\",\"name\":\"E. M. Pereira\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"5c6a9c4590b260600f9554af5696304fb65925aa\",\"title\":\"Humans in Action at Different Levels: the group, the whole, and the parts\",\"url\":\"https://www.semanticscholar.org/paper/5c6a9c4590b260600f9554af5696304fb65925aa\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2248667\",\"name\":\"J. Rinc\\u00f3n\"},{\"authorId\":\"145895906\",\"name\":\"M. Santofimia\"},{\"authorId\":\"3085605\",\"name\":\"Jean-Christophe Nebel\"}],\"doi\":\"10.1016/j.patrec.2012.10.020\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2b0caf9c0b4befdef29993e7d294344eeca2fd93\",\"title\":\"Common-sense reasoning for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/2b0caf9c0b4befdef29993e7d294344eeca2fd93\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2013},{\"arxivId\":\"1412.0439\",\"authors\":[{\"authorId\":\"1852119\",\"name\":\"C. Lim\"},{\"authorId\":\"1858035\",\"name\":\"Ekta Vats\"},{\"authorId\":\"2863960\",\"name\":\"Chee Seng Chan\"}],\"doi\":\"10.1016/j.patcog.2014.11.016\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ac820d67b313c38b9add05abef8891426edd5afb\",\"title\":\"Fuzzy human motion analysis: A review\",\"url\":\"https://www.semanticscholar.org/paper/ac820d67b313c38b9add05abef8891426edd5afb\",\"venue\":\"Pattern Recognit.\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33692583\",\"name\":\"Raghuraman Gopalan\"},{\"authorId\":\"33458360\",\"name\":\"R. Li\"},{\"authorId\":\"152159833\",\"name\":\"Vishal M. Patel\"},{\"authorId\":\"9215658\",\"name\":\"R. Chellappa\"}],\"doi\":\"10.1561/0600000057\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"564121a1d343cf20840cb4100105aa7facf1ec7c\",\"title\":\"Domain Adaptation for Visual Recognition\",\"url\":\"https://www.semanticscholar.org/paper/564121a1d343cf20840cb4100105aa7facf1ec7c\",\"venue\":\"Found. Trends Comput. Graph. Vis.\",\"year\":2015},{\"arxivId\":\"1503.07274\",\"authors\":[{\"authorId\":\"2711409\",\"name\":\"Elman Mansimov\"},{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fc5bdb98ff97581d7c1e5eb2d24d3f10714aa192\",\"title\":\"Initialization Strategies of Spatio-Temporal Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/fc5bdb98ff97581d7c1e5eb2d24d3f10714aa192\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"2007.09470\",\"authors\":[{\"authorId\":\"1399646334\",\"name\":\"Rui Yan\"},{\"authorId\":\"3041937\",\"name\":\"Lingxi Xie\"},{\"authorId\":\"8053308\",\"name\":\"J. Tang\"},{\"authorId\":\"2287686\",\"name\":\"Xiangbo Shu\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1007/978-3-030-58598-3_13\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"314f0cdcca7cdab68c92821c149786a876c116bb\",\"title\":\"Social Adaptive Module for Weakly-supervised Group Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/314f0cdcca7cdab68c92821c149786a876c116bb\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8602618\",\"name\":\"Shenglan Liu\"},{\"authorId\":\"46522622\",\"name\":\"X. Liu\"},{\"authorId\":\"143983679\",\"name\":\"Gao Huang\"},{\"authorId\":\"1397156292\",\"name\":\"Hong Qiao\"},{\"authorId\":\"1994488088\",\"name\":\"Lianyu Hu\"},{\"authorId\":\"143949784\",\"name\":\"Dong Jiang\"},{\"authorId\":\"49425435\",\"name\":\"Aibin Zhang\"},{\"authorId\":\"40959393\",\"name\":\"Yang Liu\"},{\"authorId\":\"145168166\",\"name\":\"G. Guo\"}],\"doi\":\"10.1016/j.neucom.2020.06.108\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0862ba6326c0667fe909828a5af05a2c809f4b7b\",\"title\":\"FSD-10: A fine-grained classification dataset for figure skating\",\"url\":\"https://www.semanticscholar.org/paper/0862ba6326c0667fe909828a5af05a2c809f4b7b\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2668759\",\"name\":\"G. Varol\"},{\"authorId\":\"1764521\",\"name\":\"A. A. Salah\"}],\"doi\":\"10.1016/j.eswa.2015.06.013\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb657cd8729773cd9a52ed31c68f550be1f86323\",\"title\":\"Efficient large-scale action recognition in videos using extreme learning machines\",\"url\":\"https://www.semanticscholar.org/paper/eb657cd8729773cd9a52ed31c68f550be1f86323\",\"venue\":\"Expert Syst. Appl.\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1799216\",\"name\":\"Jeong-Jik Seo\"},{\"authorId\":\"1780155\",\"name\":\"Jisoo Son\"},{\"authorId\":\"1771358\",\"name\":\"Hyungil Kim\"},{\"authorId\":\"7627712\",\"name\":\"W. D. Neve\"},{\"authorId\":\"7251290\",\"name\":\"Yong Man Ro\"}],\"doi\":\"10.1109/FG.2015.7163123\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"35308a3fd49d4f33bdbd35fefee39e39fe6b30b7\",\"title\":\"Efficient and effective human action recognition in video through motion boundary description with a compact set of trajectories\",\"url\":\"https://www.semanticscholar.org/paper/35308a3fd49d4f33bdbd35fefee39e39fe6b30b7\",\"venue\":\"2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2695601\",\"name\":\"Vadim Kantorov\"},{\"authorId\":\"143991677\",\"name\":\"I. Laptev\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"16785fd468297274409abe011018159e5ff7e851\",\"title\":\"feature extraction, encoding and classication for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/16785fd468297274409abe011018159e5ff7e851\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51033208\",\"name\":\"B. Liu\"},{\"authorId\":\"34149749\",\"name\":\"Serena Yeung\"},{\"authorId\":\"34613203\",\"name\":\"Edward Chou\"},{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1007/978-3-030-01219-9_34\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"73d1b35cd28befe845fcb60a3fed67c9fb7793ad\",\"title\":\"Temporal Modular Networks for Retrieving Complex Compositional Activities in Videos\",\"url\":\"https://www.semanticscholar.org/paper/73d1b35cd28befe845fcb60a3fed67c9fb7793ad\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2229862\",\"name\":\"Baohan Xu\"},{\"authorId\":\"145222820\",\"name\":\"H. Ye\"},{\"authorId\":\"3015119\",\"name\":\"Y. Zheng\"},{\"authorId\":null,\"name\":\"Heng Wang\"},{\"authorId\":\"1840008\",\"name\":\"Tianyu Luwang\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1145/3206025.3206028\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"398e0771e64cab6ca5d21754e32dce63f9e3c223\",\"title\":\"Dense Dilated Network for Few Shot Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/398e0771e64cab6ca5d21754e32dce63f9e3c223\",\"venue\":\"ICMR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2274625\",\"name\":\"Do Hang Nga\"},{\"authorId\":\"1681659\",\"name\":\"K. Yanai\"}],\"doi\":\"10.1109/CVPRW.2012.6239255\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"29b96e41948e35a5bc4a9e7ae978808bc5b0c841\",\"title\":\"Automatic collection of Web video shots corresponding to specific actions using Web images\",\"url\":\"https://www.semanticscholar.org/paper/29b96e41948e35a5bc4a9e7ae978808bc5b0c841\",\"venue\":\"2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49141243\",\"name\":\"Mengmeng Li\"},{\"authorId\":\"11567922\",\"name\":\"E. Koks\"},{\"authorId\":\"30940923\",\"name\":\"H. Taubenb\\u00f6ck\"},{\"authorId\":\"144165265\",\"name\":\"J. Vliet\"}],\"doi\":\"10.1016/j.rse.2020.111859\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7d7f095ade46de965c6a54831e1594844a950bc1\",\"title\":\"Continental-scale mapping and analysis of 3D building structure\",\"url\":\"https://www.semanticscholar.org/paper/7d7f095ade46de965c6a54831e1594844a950bc1\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36794849\",\"name\":\"L. Zhang\"},{\"authorId\":\"34798935\",\"name\":\"Xiantong Zhen\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"}],\"doi\":\"10.1109/ICIP.2012.6466970\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8f96b21222b422913fdd4062a45f84cc1c5a5ff9\",\"title\":\"High order co-occurrence of visualwords for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/8f96b21222b422913fdd4062a45f84cc1c5a5ff9\",\"venue\":\"2012 19th IEEE International Conference on Image Processing\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48475588\",\"name\":\"Y. Gu\"},{\"authorId\":\"47161996\",\"name\":\"Xiaofeng Ye\"},{\"authorId\":\"143891949\",\"name\":\"W. Sheng\"}],\"doi\":\"10.1109/WCICA.2018.8630370\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bc3e1420b468bafc8edd8f2da665a8613fc2912c\",\"title\":\"Depth MHI Based Deep Learning Model for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/bc3e1420b468bafc8edd8f2da665a8613fc2912c\",\"venue\":\"2018 13th World Congress on Intelligent Control and Automation (WCICA)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46381810\",\"name\":\"H. Li\"},{\"authorId\":\"102461379\",\"name\":\"J. Wang\"},{\"authorId\":\"3033573\",\"name\":\"Jian-Jun Han\"},{\"authorId\":\"49049946\",\"name\":\"Jinmin Zhang\"},{\"authorId\":\"2808646\",\"name\":\"Yushan Yang\"},{\"authorId\":\"152621421\",\"name\":\"Yue Zhao\"}],\"doi\":\"10.1177/0020294020902788\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"85810af8b757717d81ab63772d2958445e0818f8\",\"title\":\"A novel multi-stream method for violent interaction detection using deep learning\",\"url\":\"https://www.semanticscholar.org/paper/85810af8b757717d81ab63772d2958445e0818f8\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1708.01741\",\"authors\":[{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"3237649\",\"name\":\"P. Stanitsas\"},{\"authorId\":\"23911916\",\"name\":\"Mehrtash Harandi\"},{\"authorId\":\"1827707\",\"name\":\"V. Morellas\"},{\"authorId\":\"1696163\",\"name\":\"N. Papanikolopoulos\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ce2713945d623dd83356734ba55254cf29a6d458\",\"title\":\"Learning Discriminative Alpha-Beta-divergence for Positive Definite Matrices (Extended Version)\",\"url\":\"https://www.semanticscholar.org/paper/ce2713945d623dd83356734ba55254cf29a6d458\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"2011.08652\",\"authors\":[{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"2025664854\",\"name\":\"Emad Bahrami Rad\"},{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"2199924\",\"name\":\"M. Noroozi\"},{\"authorId\":\"46408185\",\"name\":\"E. Adeli\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"80ddd8e76480aa92aa071d33c624af7195b0b762\",\"title\":\"3D CNNs with Adaptive Temporal Feature Resolutions\",\"url\":\"https://www.semanticscholar.org/paper/80ddd8e76480aa92aa071d33c624af7195b0b762\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1810.12126\",\"authors\":[{\"authorId\":\"8556451\",\"name\":\"F. Angelini\"},{\"authorId\":\"9573943\",\"name\":\"Zeyu Fu\"},{\"authorId\":\"144325904\",\"name\":\"Yang Long\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"},{\"authorId\":\"144403678\",\"name\":\"S. Naqvi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"66837b29270f3e03df64941a081d70c687c7955c\",\"title\":\"ActionXPose: A Novel 2D Multi-view Pose-based Algorithm for Real-time Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/66837b29270f3e03df64941a081d70c687c7955c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51921002\",\"name\":\"N. Sayed\"},{\"authorId\":\"27629992\",\"name\":\"B. Brattoli\"},{\"authorId\":\"1796707\",\"name\":\"B. Ommer\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ed9b230a1629049656c62bf4434d1212faeacc1f\",\"title\":\"C V ] 9 N ov 2 01 8 Cross and Learn : Cross-Modal Self-Supervision\",\"url\":\"https://www.semanticscholar.org/paper/ed9b230a1629049656c62bf4434d1212faeacc1f\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145022791\",\"name\":\"N. Lu\"},{\"authorId\":\"3837645\",\"name\":\"Yidan Wu\"},{\"authorId\":\"47010093\",\"name\":\"L. Feng\"},{\"authorId\":\"2479894\",\"name\":\"Jinbo Song\"}],\"doi\":\"10.1109/JBHI.2018.2808281\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"ce976adda018924f358cc21a76d89c1fb7aacae4\",\"title\":\"Deep Learning for Fall Detection: Three-Dimensional CNN Combined With LSTM on Video Kinematic Data\",\"url\":\"https://www.semanticscholar.org/paper/ce976adda018924f358cc21a76d89c1fb7aacae4\",\"venue\":\"IEEE Journal of Biomedical and Health Informatics\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145839689\",\"name\":\"S. Jones\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8b7f4c9ea272c6b934cd704a6858c6e2fb746b89\",\"title\":\"Unsupervised and semi-supervised methods for human action analysis\",\"url\":\"https://www.semanticscholar.org/paper/8b7f4c9ea272c6b934cd704a6858c6e2fb746b89\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46431991\",\"name\":\"K. Huang\"},{\"authorId\":\"2366069\",\"name\":\"Sarah Jane Delany\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"426384ded7250e64552eb6399eb5382ec202a655\",\"title\":\"Active Vision , Tracking , Motion Analysis IMVIP 2019 : Irish Machine Vision and ImageProcessing 2019 Human Action Recognition in Videos Using Transfer Learning\",\"url\":\"https://www.semanticscholar.org/paper/426384ded7250e64552eb6399eb5382ec202a655\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26986331\",\"name\":\"A. Kling\"},{\"authorId\":\"47707942\",\"name\":\"A. Thomas\"},{\"authorId\":\"145857934\",\"name\":\"M. Martinez\"},{\"authorId\":\"41126694\",\"name\":\"N. Wilkinson\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"66432fc5b010c2a0c5cb81fad39a0409b7a5d6df\",\"title\":\"COS 429 : Class Project Report Examining Motion With a Neural Net\",\"url\":\"https://www.semanticscholar.org/paper/66432fc5b010c2a0c5cb81fad39a0409b7a5d6df\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11485621\",\"name\":\"Cyrille Beaudry\"},{\"authorId\":\"1766371\",\"name\":\"Renaud P\\u00e9teri\"},{\"authorId\":\"3027952\",\"name\":\"L. Mascarilla\"}],\"doi\":\"10.1007/s00138-016-0760-z\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9652f154f4ae7807bdaff32d3222cc0c485a6762\",\"title\":\"An efficient and sparse approach for large scale human action recognition in videos\",\"url\":\"https://www.semanticscholar.org/paper/9652f154f4ae7807bdaff32d3222cc0c485a6762\",\"venue\":\"Machine Vision and Applications\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145745514\",\"name\":\"S. Wang\"},{\"authorId\":\"1991108\",\"name\":\"P. Pan\"},{\"authorId\":\"2062835\",\"name\":\"Guodong Long\"},{\"authorId\":\"1934469\",\"name\":\"Weitong Chen\"},{\"authorId\":\"145950949\",\"name\":\"Xue Li\"},{\"authorId\":\"1713128\",\"name\":\"Quan Z. Sheng\"}],\"doi\":\"10.1007/s11280-015-0354-0\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d4da887fd86af370c8cb45037f29ac1a702d0bb0\",\"title\":\"Compact representation for large-scale unconstrained video analysis\",\"url\":\"https://www.semanticscholar.org/paper/d4da887fd86af370c8cb45037f29ac1a702d0bb0\",\"venue\":\"World Wide Web\",\"year\":2015},{\"arxivId\":\"1611.02155\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5f4d2f6ad967f7c9369c04e75cda08f12cb8afbd\",\"title\":\"Spatiotemporal Residual Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5f4d2f6ad967f7c9369c04e75cda08f12cb8afbd\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1704.01716\",\"authors\":[{\"authorId\":\"48094509\",\"name\":\"Jue Wang\"},{\"authorId\":\"2691929\",\"name\":\"Anoop Cherian\"},{\"authorId\":\"29905643\",\"name\":\"Fatih Murat Porikli\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2f7fc778e3dec2300b4081ba2a1e52f669094fcd\",\"title\":\"Action Representation Using Classifier Decision Boundaries\",\"url\":\"https://www.semanticscholar.org/paper/2f7fc778e3dec2300b4081ba2a1e52f669094fcd\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403633669\",\"name\":\"Jordi Bautista-Ballester\"},{\"authorId\":\"1403633671\",\"name\":\"J. Verg\\u00e9s-Llah\\u00ed\"},{\"authorId\":\"143844336\",\"name\":\"D. Puig\"}],\"doi\":\"10.5220/0005301000780086\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"58a1a8c6ba4b35fa1e2f46f37dc117b6ea408ecd\",\"title\":\"Using Action Objects Contextual Information for a Multichannel SVM in an Action Recognition Approach based on Bag of Visual Words\",\"url\":\"https://www.semanticscholar.org/paper/58a1a8c6ba4b35fa1e2f46f37dc117b6ea408ecd\",\"venue\":\"VISAPP\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29724362\",\"name\":\"Longlong Jing\"},{\"authorId\":\"35484757\",\"name\":\"Yingli Tian\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3eb9f4ca21bd104b1d9963a5a74e0ad48a1a1bdf\",\"title\":\"Self-supervised Spatiotemporal Feature Learning by Video Geometric Transformations\",\"url\":\"https://www.semanticscholar.org/paper/3eb9f4ca21bd104b1d9963a5a74e0ad48a1a1bdf\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"18080084\",\"name\":\"Qingya Huang\"},{\"authorId\":\"145107805\",\"name\":\"Shan Sun\"},{\"authorId\":\"49451223\",\"name\":\"Feng Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"81a142c751bf0b23315fb6717bc467aa4fdfbc92\",\"title\":\"PAIRWISE TRAJECTORY REPRESENTATION FOR ACTION RECOGNITION\",\"url\":\"https://www.semanticscholar.org/paper/81a142c751bf0b23315fb6717bc467aa4fdfbc92\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40430887\",\"name\":\"J. Zhang\"},{\"authorId\":\"50135738\",\"name\":\"Weihai Li\"}],\"doi\":\"10.1117/12.2573117\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"76560c4bb5fe31bf6a9b7fab7f2f2c400f1c40e2\",\"title\":\"Target analysis based anomaly detection in surveillance videos\",\"url\":\"https://www.semanticscholar.org/paper/76560c4bb5fe31bf6a9b7fab7f2f2c400f1c40e2\",\"venue\":\"International Conference on Digital Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699593941\",\"name\":\"Neha Mathur\"},{\"authorId\":\"50486018\",\"name\":\"Shruti Mathur\"},{\"authorId\":\"1699593877\",\"name\":\"Divya Mathur\"},{\"authorId\":\"9194134\",\"name\":\"Pankaj Dadheech\"}],\"doi\":\"10.1109/ICETCE48199.2020.9091747\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dc0beeb87058218101249e7c509d140a299b22c8\",\"title\":\"A Brief Survey of Deep Learning Techniques for Person Re-identification\",\"url\":\"https://www.semanticscholar.org/paper/dc0beeb87058218101249e7c509d140a299b22c8\",\"venue\":\"2020 3rd International Conference on Emerging Technologies in Computer Engineering: Machine Learning and Internet of Things (ICETCE)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2646978\",\"name\":\"Zengmin Xu\"},{\"authorId\":\"37254976\",\"name\":\"RuiMin Hu\"},{\"authorId\":\"47739565\",\"name\":\"J. Chen\"},{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"1708439\",\"name\":\"J. Jiang\"},{\"authorId\":\"81752605\",\"name\":\"Jiao-fen Li\"},{\"authorId\":\"46382329\",\"name\":\"Hongyang Li\"}],\"doi\":\"10.1109/TNNLS.2018.2886008\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f4d4b6c67c05de1d31990076a5142719cd1ff3f6\",\"title\":\"Semisupervised Discriminant Multimanifold Analysis for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f4d4b6c67c05de1d31990076a5142719cd1ff3f6\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3385719\",\"name\":\"Fiza Murtaza\"},{\"authorId\":\"1697680\",\"name\":\"M. Yousaf\"},{\"authorId\":\"1697856\",\"name\":\"S. Velastin\"}],\"doi\":\"10.1109/ICIP.2018.8451255\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"ad58b92ebc45e71e40ce68d4375441267549b054\",\"title\":\"DA-VLAD: Discriminative Action Vector of Locally Aggregated Descriptors for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ad58b92ebc45e71e40ce68d4375441267549b054\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2038786\",\"name\":\"Wentao Fan\"},{\"authorId\":\"2562809\",\"name\":\"Hassen Sallay\"},{\"authorId\":\"1729109\",\"name\":\"N. Bouguila\"},{\"authorId\":\"3721965\",\"name\":\"Ji-Xiang Du\"}],\"doi\":\"10.1109/ICMLA.2015.68\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"199c76c0e5a37433c575d232f14d7bea6676e968\",\"title\":\"Human Action Recognition Using Accelerated Variational Learning of Infinite Dirichlet Mixture Models\",\"url\":\"https://www.semanticscholar.org/paper/199c76c0e5a37433c575d232f14d7bea6676e968\",\"venue\":\"2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51131102\",\"name\":\"P. Rosello\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"770571f5f0932e9eae1eca9d737d3d1f01652ca9\",\"title\":\"Predicting Future Optical Flow from Static Video Frames\",\"url\":\"https://www.semanticscholar.org/paper/770571f5f0932e9eae1eca9d737d3d1f01652ca9\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"144474750\",\"name\":\"Subhabrata Bhattacharya\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1007/s13735-012-0024-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9f9c54f724ac7d6f910bac2da76b9e53e89fb6e8\",\"title\":\"High-level event recognition in unconstrained videos\",\"url\":\"https://www.semanticscholar.org/paper/9f9c54f724ac7d6f910bac2da76b9e53e89fb6e8\",\"venue\":\"International Journal of Multimedia Information Retrieval\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2788104\",\"name\":\"Yuting Su\"},{\"authorId\":\"48513180\",\"name\":\"Y. Li\"},{\"authorId\":\"143602033\",\"name\":\"Anan Liu\"}],\"doi\":\"10.1007/s11042-018-5657-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"87f87c837dfa89637de287fb5e4769114d6dae18\",\"title\":\"Open-view human action recognition based on linear discriminant analysis\",\"url\":\"https://www.semanticscholar.org/paper/87f87c837dfa89637de287fb5e4769114d6dae18\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32052175\",\"name\":\"Ramyad Hadidi\"},{\"authorId\":\"35821903\",\"name\":\"Jiashen Cao\"},{\"authorId\":\"153027140\",\"name\":\"Matthew Woodward\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"},{\"authorId\":\"8187053\",\"name\":\"Hyesoon Kim\"}],\"doi\":\"10.1109/LRA.2018.2856261\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"c227206966eb49b0b16bdd97d1553c0a1dc9a73a\",\"title\":\"Distributed Perception by Collaborative Robots\",\"url\":\"https://www.semanticscholar.org/paper/c227206966eb49b0b16bdd97d1553c0a1dc9a73a\",\"venue\":\"IEEE Robotics and Automation Letters\",\"year\":2018},{\"arxivId\":\"1807.11293\",\"authors\":[{\"authorId\":\"21408156\",\"name\":\"U. B\\u00fcchler\"},{\"authorId\":\"27629992\",\"name\":\"B. Brattoli\"},{\"authorId\":\"1796707\",\"name\":\"B. Ommer\"}],\"doi\":\"10.1007/978-3-030-01267-0_47\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d8b4551d6894ebb48bfe401a814597ea7c491507\",\"title\":\"Improving Spatiotemporal Self-Supervision by Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/d8b4551d6894ebb48bfe401a814597ea7c491507\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2009399\",\"name\":\"Igor L. O. Bastos\"},{\"authorId\":\"143793197\",\"name\":\"V. H. Melo\"},{\"authorId\":\"9385043\",\"name\":\"W. Schwartz\"}],\"doi\":\"10.1109/ICIP40778.2020.9190769\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"35e703f6ad6551cdbe5c58d22010d26662211d02\",\"title\":\"Bubblenet: A Disperse Recurrent Structure To Recognize Activities\",\"url\":\"https://www.semanticscholar.org/paper/35e703f6ad6551cdbe5c58d22010d26662211d02\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"2010.06215\",\"authors\":[{\"authorId\":\"3201156\",\"name\":\"Congqi Cao\"},{\"authorId\":\"48515277\",\"name\":\"Yajuan Li\"},{\"authorId\":\"36602757\",\"name\":\"Qinyi Lv\"},{\"authorId\":\"1490938689\",\"name\":\"Peng Wang\"},{\"authorId\":\"48379046\",\"name\":\"Y. Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"dae1e039833db56735d54a992bb5cfb381bdadd9\",\"title\":\"Few-shot Action Recognition with Implicit Temporal Alignment and Pair Similarity Optimization\",\"url\":\"https://www.semanticscholar.org/paper/dae1e039833db56735d54a992bb5cfb381bdadd9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1910.12016\",\"authors\":[{\"authorId\":\"151474857\",\"name\":\"Hao Kong\"},{\"authorId\":\"144859190\",\"name\":\"Z. Lin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a0d8c562608729d33ee106eedbe78a7eb10fad87\",\"title\":\"Tensor Q-Rank: A New Data Dependent Tensor Rank\",\"url\":\"https://www.semanticscholar.org/paper/a0d8c562608729d33ee106eedbe78a7eb10fad87\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2217653\",\"name\":\"Y. Quan\"},{\"authorId\":\"47557959\",\"name\":\"Y. Chen\"},{\"authorId\":\"47462870\",\"name\":\"Ruotao Xu\"},{\"authorId\":\"153172100\",\"name\":\"Hui Ji\"}],\"doi\":\"10.1016/J.CVIU.2019.102794\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d0d17b7b11994bb3c85e44a3ae1c7ca7eeaeaafc\",\"title\":\"Attention with structure regularization for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/d0d17b7b11994bb3c85e44a3ae1c7ca7eeaeaafc\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2019},{\"arxivId\":\"1912.06430\",\"authors\":[{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"1466466597\",\"name\":\"Lucas Smaira\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/cvpr42600.2020.00990\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fb40df31aa7177c9d009478479db61c39caebd54\",\"title\":\"End-to-End Learning of Visual Representations From Uncurated Instructional Videos\",\"url\":\"https://www.semanticscholar.org/paper/fb40df31aa7177c9d009478479db61c39caebd54\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3275727\",\"name\":\"Linxi (Jim) Fan\"},{\"authorId\":\"8983218\",\"name\":\"S. Buch\"},{\"authorId\":\"96374437\",\"name\":\"Guanzhi Wang\"},{\"authorId\":\"2013547017\",\"name\":\"Ryan Cao\"},{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/978-3-030-58529-7_30\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3ab0c5006bb157b801ec592951a1da2c8af9d158\",\"title\":\"RubiksNet: Learnable 3D-Shift for Efficient Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3ab0c5006bb157b801ec592951a1da2c8af9d158\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1911.12667\",\"authors\":[{\"authorId\":\"19198894\",\"name\":\"Humam Alwassel\"},{\"authorId\":\"144542135\",\"name\":\"D. Mahajan\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1ee9df4e96f5021509c438751b48d3de07ae8b75\",\"title\":\"Self-Supervised Learning by Cross-Modal Audio-Video Clustering\",\"url\":\"https://www.semanticscholar.org/paper/1ee9df4e96f5021509c438751b48d3de07ae8b75\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390412671\",\"name\":\"Yanbo Fan\"},{\"authorId\":\"46223195\",\"name\":\"Shuchen Weng\"},{\"authorId\":\"49889486\",\"name\":\"Y. Zhang\"},{\"authorId\":\"35580784\",\"name\":\"Boxin Shi\"},{\"authorId\":\"80266964\",\"name\":\"Y. Zhang\"}],\"doi\":\"10.1109/ACCESS.2020.2968054\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"72b92168ce61d3d13f37c2f910dd3829bc1a2668\",\"title\":\"Context-Aware Cross-Attention for Skeleton-Based Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/72b92168ce61d3d13f37c2f910dd3829bc1a2668\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1702.00824\",\"authors\":[{\"authorId\":\"2892780\",\"name\":\"E. Real\"},{\"authorId\":\"1789737\",\"name\":\"Jonathon Shlens\"},{\"authorId\":\"49436220\",\"name\":\"S. Mazzocchi\"},{\"authorId\":\"144680010\",\"name\":\"Xin Pan\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"}],\"doi\":\"10.1109/CVPR.2017.789\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"991544f9333296a7d9e5b9751bca932bb68f54e1\",\"title\":\"YouTube-BoundingBoxes: A Large High-Precision Human-Annotated Data Set for Object Detection in Video\",\"url\":\"https://www.semanticscholar.org/paper/991544f9333296a7d9e5b9751bca932bb68f54e1\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1511.02917\",\"authors\":[{\"authorId\":\"34066479\",\"name\":\"Vignesh Ramanathan\"},{\"authorId\":\"4240351\",\"name\":\"Jonathan Huang\"},{\"authorId\":\"1389570466\",\"name\":\"Sami Abu-El-Haija\"},{\"authorId\":\"116230588\",\"name\":\"A. N. Gorban\"},{\"authorId\":\"145601650\",\"name\":\"K. Murphy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2016.332\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"195df1106f4d7aff0e9cb609358abbf80f54a716\",\"title\":\"Detecting Events and Key Actors in Multi-person Videos\",\"url\":\"https://www.semanticscholar.org/paper/195df1106f4d7aff0e9cb609358abbf80f54a716\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1604.04494\",\"authors\":[{\"authorId\":\"2668759\",\"name\":\"G. Varol\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/TPAMI.2017.2712608\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"47e3ef70f2539386bcef604097fa9235246c6d53\",\"title\":\"Long-Term Temporal Convolutions for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/47e3ef70f2539386bcef604097fa9235246c6d53\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":\"1812.11631\",\"authors\":[{\"authorId\":\"32859304\",\"name\":\"Oytun Ulutan\"},{\"authorId\":\"34889835\",\"name\":\"S. Rallapalli\"},{\"authorId\":\"1718467\",\"name\":\"M. Srivatsa\"},{\"authorId\":\"50591689\",\"name\":\"B. S. Manjunath\"}],\"doi\":\"10.1109/WACV45572.2020.9093617\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"057d5e304f1f2f2bd6c35d5c861961ce102fcc48\",\"title\":\"Actor Conditioned Attention Maps for Video Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/057d5e304f1f2f2bd6c35d5c861961ce102fcc48\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2750523\",\"name\":\"Huiwen Guo\"},{\"authorId\":\"1730308\",\"name\":\"X. Wu\"},{\"authorId\":\"46674577\",\"name\":\"W. Feng\"}],\"doi\":\"10.1016/j.sigpro.2017.05.022\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b920626df0c1fd90b6d8a8dfcf1260c6d88196f6\",\"title\":\"Multi-stream deep networks for human action classification with sequential tensor decomposition\",\"url\":\"https://www.semanticscholar.org/paper/b920626df0c1fd90b6d8a8dfcf1260c6d88196f6\",\"venue\":\"Signal Process.\",\"year\":2017},{\"arxivId\":\"1609.03056\",\"authors\":[{\"authorId\":\"38179026\",\"name\":\"Y. Shi\"},{\"authorId\":\"40161651\",\"name\":\"Yonghong Tian\"},{\"authorId\":\"5765799\",\"name\":\"Yaowei Wang\"},{\"authorId\":\"34097174\",\"name\":\"Tiejun Huang\"}],\"doi\":\"10.1109/TMM.2017.2666540\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"776ce1429272028e9c566369cf647177d3522e26\",\"title\":\"Sequential Deep Trajectory Descriptor for Action Recognition With Three-Stream CNN\",\"url\":\"https://www.semanticscholar.org/paper/776ce1429272028e9c566369cf647177d3522e26\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2017},{\"arxivId\":\"1708.03958\",\"authors\":[{\"authorId\":\"41191188\",\"name\":\"Lin Sun\"},{\"authorId\":\"2370507\",\"name\":\"K. Jia\"},{\"authorId\":\"143887468\",\"name\":\"Kevin Chen\"},{\"authorId\":\"1739816\",\"name\":\"D. Yeung\"},{\"authorId\":\"2131088\",\"name\":\"B. Shi\"},{\"authorId\":\"1702137\",\"name\":\"S. Savarese\"}],\"doi\":\"10.1109/ICCV.2017.236\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f22d6d59e413ee255e5e0f2104f1e03be1a6722e\",\"title\":\"Lattice Long Short-Term Memory for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f22d6d59e413ee255e5e0f2104f1e03be1a6722e\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2744109\",\"name\":\"C. Jia\"},{\"authorId\":\"2788685\",\"name\":\"Z. Ding\"},{\"authorId\":\"144790313\",\"name\":\"Y. Kong\"},{\"authorId\":\"152987469\",\"name\":\"Yun Fu\"}],\"doi\":\"10.1109/TCSVT.2019.2910208\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6f4f9740c8e289bfea27a8c57db3510a6623d147\",\"title\":\"Semi-Supervised Cross-Modality Action Recognition by Latent Tensor Transfer Learning\",\"url\":\"https://www.semanticscholar.org/paper/6f4f9740c8e289bfea27a8c57db3510a6623d147\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"1808.01727\",\"authors\":[{\"authorId\":\"49616225\",\"name\":\"Sujoy Paul\"},{\"authorId\":\"2177805\",\"name\":\"S. Roy\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":\"10.1109/ICASSP.2018.8461758\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e624c73e3057a1de75e9d6d7e813771154ff1375\",\"title\":\"Incorporating Scalability in Unsupervised Spatio- Temporal Feature Learning\",\"url\":\"https://www.semanticscholar.org/paper/e624c73e3057a1de75e9d6d7e813771154ff1375\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2461523\",\"name\":\"X. Wang\"},{\"authorId\":\"145175070\",\"name\":\"C. Qi\"}],\"doi\":\"10.1007/s00138-016-0746-x\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1252727e8096f48096ef89483d30c3a74500dd15\",\"title\":\"Action recognition using edge trajectories and motion acceleration descriptor\",\"url\":\"https://www.semanticscholar.org/paper/1252727e8096f48096ef89483d30c3a74500dd15\",\"venue\":\"Machine Vision and Applications\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"97590086\",\"name\":\"Rockson Agyeman\"},{\"authorId\":\"3244945\",\"name\":\"R. Muhammad\"},{\"authorId\":\"32016133\",\"name\":\"G. Choi\"}],\"doi\":\"10.1109/MIPR.2019.00055\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"57ccdab6e02bd905823853c85c525305924c588a\",\"title\":\"Soccer Video Summarization Using Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/57ccdab6e02bd905823853c85c525305924c588a\",\"venue\":\"2019 IEEE Conference on Multimedia Information Processing and Retrieval (MIPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145324038\",\"name\":\"H. Xu\"},{\"authorId\":\"35870173\",\"name\":\"Q. Tian\"},{\"authorId\":\"46365410\",\"name\":\"Jianhui Wu\"}],\"doi\":\"10.1145/2808492.2808554\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"aee99e8164c0ce896562c6c6b6cec9e9d465c789\",\"title\":\"Exploring the influence of motion boundary sampling to improved dense trajectories for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/aee99e8164c0ce896562c6c6b6cec9e9d465c789\",\"venue\":\"ICIMCS '15\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2121584\",\"name\":\"Wangjiang Zhu\"},{\"authorId\":\"2450889\",\"name\":\"B. Wang\"},{\"authorId\":\"145676588\",\"name\":\"Stephen Lin\"}],\"doi\":\"10.1109/AVSS.2015.7301759\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7eb7b32718405940447727c9dee47d213e895540\",\"title\":\"Adaptive pooling over multiple trajectory attributes for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/7eb7b32718405940447727c9dee47d213e895540\",\"venue\":\"2015 12th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)\",\"year\":2015},{\"arxivId\":\"1408.7071\",\"authors\":[{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"2314980\",\"name\":\"X. Li\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7fa4a9ee48f3504b0d2ae4f43d2782a664ba4b1e\",\"title\":\"Temporal Extension of Scale Pyramid and Spatial Pyramid Matching for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7fa4a9ee48f3504b0d2ae4f43d2782a664ba4b1e\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145795309\",\"name\":\"K. Shi\"},{\"authorId\":\"145472490\",\"name\":\"Weiqiang Wang\"},{\"authorId\":\"145194969\",\"name\":\"C. Xu\"}],\"doi\":\"10.1109/ICME.2018.8486530\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"182b627d73de02764498c500aa7fb56cbeb1a424\",\"title\":\"Entity Competition Network for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/182b627d73de02764498c500aa7fb56cbeb1a424\",\"venue\":\"2018 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145196759\",\"name\":\"Chenqiang Gao\"},{\"authorId\":\"2040199\",\"name\":\"Yinhe Du\"},{\"authorId\":\"40035911\",\"name\":\"J. Liu\"},{\"authorId\":\"2858139\",\"name\":\"L. Yang\"},{\"authorId\":\"1803714\",\"name\":\"D. Meng\"}],\"doi\":\"10.1007/978-3-662-48570-5_30\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3dcd70d1e259a561c82736b26314c9d231bc6dec\",\"title\":\"A New Dataset and Evaluation for Infrared Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3dcd70d1e259a561c82736b26314c9d231bc6dec\",\"venue\":\"CCCV\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"108646857\",\"name\":\"Dan Liu\"},{\"authorId\":\"152994876\",\"name\":\"Yunfeng Ji\"},{\"authorId\":\"144560368\",\"name\":\"M. Ye\"},{\"authorId\":\"46636010\",\"name\":\"Y. Gan\"},{\"authorId\":\"1739414\",\"name\":\"Jianwei Zhang\"}],\"doi\":\"10.1109/ACCESS.2020.2983355\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b89aed9287493cc57eb0dcd58eccec4ec0c981b6\",\"title\":\"An Improved Attention-Based Spatiotemporal-Stream Model for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/b89aed9287493cc57eb0dcd58eccec4ec0c981b6\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":\"47903936\",\"name\":\"Yali Wang\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1109/ICASSP.2016.7471878\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"586456925c74c51287476e4395b5c69a831442cc\",\"title\":\"Codebook enhancement of vlad representation for visual recognition\",\"url\":\"https://www.semanticscholar.org/paper/586456925c74c51287476e4395b5c69a831442cc\",\"venue\":\"2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2016},{\"arxivId\":\"2007.07355\",\"authors\":[{\"authorId\":\"2935412\",\"name\":\"U. Demir\"},{\"authorId\":\"2116440\",\"name\":\"Y. Rawat\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f00fcda3127dc697fd2aa30569eafa5e1b0c2f8c\",\"title\":\"TinyVIRAT: Low-resolution Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f00fcda3127dc697fd2aa30569eafa5e1b0c2f8c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.12943\",\"authors\":[{\"authorId\":\"31692099\",\"name\":\"Pedro Morgado\"},{\"authorId\":\"1699559\",\"name\":\"N. Vasconcelos\"},{\"authorId\":\"1806773\",\"name\":\"I. Misra\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"afc91295df19ffc7ab95530dc879ac11126afeee\",\"title\":\"Audio-Visual Instance Discrimination with Cross-Modal Agreement\",\"url\":\"https://www.semanticscholar.org/paper/afc91295df19ffc7ab95530dc879ac11126afeee\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145953753\",\"name\":\"Ting Huang\"},{\"authorId\":\"148127916\",\"name\":\"Sheng-Rong Ru\"},{\"authorId\":\"144187895\",\"name\":\"Zhihong Zeng\"},{\"authorId\":\"144859414\",\"name\":\"Long Zhang\"}],\"doi\":\"10.1007/S00542-019-04462-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ac73832695047ccfeebefbb9be655a5df08d4a59\",\"title\":\"Research on motion recognition algorithm based on bag-of-words model\",\"url\":\"https://www.semanticscholar.org/paper/ac73832695047ccfeebefbb9be655a5df08d4a59\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34798935\",\"name\":\"Xiantong Zhen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2cf7a29324ce22ff39347674d427a32817a434b7\",\"title\":\"Feature extraction and representation for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/2cf7a29324ce22ff39347674d427a32817a434b7\",\"venue\":\"\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"46989533\",\"name\":\"Lei Bao\"},{\"authorId\":\"143642520\",\"name\":\"Shoou-I Yu\"},{\"authorId\":\"40255545\",\"name\":\"W. Liu\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1007/s11042-013-1391-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"29d5c0e598dd678abbdef557beb89704adcac87a\",\"title\":\"Multimedia classification and event detection using double fusion\",\"url\":\"https://www.semanticscholar.org/paper/29d5c0e598dd678abbdef557beb89704adcac87a\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2013},{\"arxivId\":\"1503.01224\",\"authors\":[{\"authorId\":\"48319305\",\"name\":\"P. Wang\"},{\"authorId\":\"2572430\",\"name\":\"Yuanzhouhan Cao\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1109/TCSVT.2016.2576761\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c2a7ad6bb5fee853218b474460eebcef9cad3259\",\"title\":\"Temporal Pyramid Pooling-Based Convolutional Neural Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c2a7ad6bb5fee853218b474460eebcef9cad3259\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145377162\",\"name\":\"Y. Yuan\"},{\"authorId\":\"145940718\",\"name\":\"Yang Zhao\"},{\"authorId\":\"39669401\",\"name\":\"Q. Wang\"}],\"doi\":\"10.1016/j.neucom.2018.06.071\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f3123b1d2dde97b12fdf3a2bf21fb7e190842721\",\"title\":\"Action recognition using spatial-optical data organization and sequential learning framework\",\"url\":\"https://www.semanticscholar.org/paper/f3123b1d2dde97b12fdf3a2bf21fb7e190842721\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":\"1511.02126\",\"authors\":[{\"authorId\":\"49112947\",\"name\":\"Shichao Zhao\"},{\"authorId\":\"1732242\",\"name\":\"Y. Liu\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"48043335\",\"name\":\"R. Hong\"},{\"authorId\":\"153076339\",\"name\":\"Qinghua Hu\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/TCSVT.2017.2682196\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"695426275dee2ec56bc0c0afe1c5b4227a350840\",\"title\":\"Pooling the Convolutional Layers in Deep ConvNets for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/695426275dee2ec56bc0c0afe1c5b4227a350840\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144406781\",\"name\":\"Lijun He\"},{\"authorId\":\"2035803194\",\"name\":\"Shuai Wen\"},{\"authorId\":\"2199437\",\"name\":\"L. Wang\"},{\"authorId\":\"1825677658\",\"name\":\"Fan Li\"}],\"doi\":\"10.1007/s10489-020-01933-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb68cda0fdd2e9fec857ff8016b3a74912ceb57e\",\"title\":\"Vehicle theft recognition from surveillance video based on spatiotemporal attention\",\"url\":\"https://www.semanticscholar.org/paper/eb68cda0fdd2e9fec857ff8016b3a74912ceb57e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48951023\",\"name\":\"F. Husain\"},{\"authorId\":\"1724418\",\"name\":\"B. Dellen\"},{\"authorId\":\"1735976\",\"name\":\"C. Torras\"}],\"doi\":\"10.1109/LRA.2016.2529686\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"14f2ce5bf3a7d33c3ed67ed455022b3849e58393\",\"title\":\"Action Recognition Based on Efficient Deep Feature Learning in the Spatio-Temporal Domain\",\"url\":\"https://www.semanticscholar.org/paper/14f2ce5bf3a7d33c3ed67ed455022b3849e58393\",\"venue\":\"IEEE Robotics and Automation Letters\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1694051\",\"name\":\"Cheston Tan\"},{\"authorId\":\"39538991\",\"name\":\"H. Goh\"},{\"authorId\":\"1802086\",\"name\":\"V. Chandrasekhar\"},{\"authorId\":\"35718875\",\"name\":\"L. Li\"},{\"authorId\":\"6516914\",\"name\":\"J. Lim\"}],\"doi\":\"10.1109/CVPRW.2014.85\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1a30e44d6b70d11f7b270c87eac099b75b2263f1\",\"title\":\"Understanding the Nature of First-Person Videos: Characterization and Classification Using Low-Level Features\",\"url\":\"https://www.semanticscholar.org/paper/1a30e44d6b70d11f7b270c87eac099b75b2263f1\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition Workshops\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145834566\",\"name\":\"Ritam Guha\"},{\"authorId\":\"36841941\",\"name\":\"A. H. Khan\"},{\"authorId\":\"143730686\",\"name\":\"P. Singh\"},{\"authorId\":\"70680168\",\"name\":\"R. Sarkar\"},{\"authorId\":\"89542097\",\"name\":\"D. Bhattacharjee\"}],\"doi\":\"10.1007/s00521-020-05297-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6d8e63de7fe907b355309eab70e74dc8561ebe23\",\"title\":\"CGA: a new feature selection model for visual human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/6d8e63de7fe907b355309eab70e74dc8561ebe23\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1145/2578726.2578775\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"29f0a868644462aa7ebc21f4510d4209932a1b8c\",\"title\":\"Collecting and Annotating Human Activities in Web Videos\",\"url\":\"https://www.semanticscholar.org/paper/29f0a868644462aa7ebc21f4510d4209932a1b8c\",\"venue\":\"ICMR\",\"year\":2014},{\"arxivId\":\"2009.05769\",\"authors\":[{\"authorId\":\"48093158\",\"name\":\"Jinpeng Wang\"},{\"authorId\":\"151470972\",\"name\":\"Yuting Gao\"},{\"authorId\":\"104106360\",\"name\":\"Ke Li\"},{\"authorId\":\"46396519\",\"name\":\"Yiqi Lin\"},{\"authorId\":\"38624848\",\"name\":\"A. J. Ma\"},{\"authorId\":\"143900241\",\"name\":\"Xing Sun\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"01637f04eac8523b6c4887d419bd718f65860982\",\"title\":\"Removing the Background by Adding the Background: Towards Background Robust Self-supervised Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/01637f04eac8523b6c4887d419bd718f65860982\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3422195\",\"name\":\"S. Chaudhary\"},{\"authorId\":\"1827383\",\"name\":\"S. Murala\"}],\"doi\":\"10.1109/SMC.2018.00675\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"634ceba09765a0b5c3f6f3fdd6f5c269c78e94ac\",\"title\":\"TSNet: Deep Network for Human Action Recognition in Hazy Videos\",\"url\":\"https://www.semanticscholar.org/paper/634ceba09765a0b5c3f6f3fdd6f5c269c78e94ac\",\"venue\":\"2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33390229\",\"name\":\"Alina Roitberg\"},{\"authorId\":\"145529194\",\"name\":\"M. Martinez\"},{\"authorId\":\"67310661\",\"name\":\"Monica Haurilet\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"}],\"doi\":\"10.1007/978-3-030-11018-5_8\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1c127e27ec746afbeede792f63316663fb96bf95\",\"title\":\"Towards a Fair Evaluation of Zero-Shot Action Recognition Using External Data\",\"url\":\"https://www.semanticscholar.org/paper/1c127e27ec746afbeede792f63316663fb96bf95\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29901316\",\"name\":\"Prateep Bhattacharjee\"},{\"authorId\":\"144009889\",\"name\":\"Sukhendu Das\"}],\"doi\":\"10.1007/978-3-319-69900-4_70\",\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"bf2eb77e9b795a4a0a38ed4b1c8dd4b2c9a74317\",\"title\":\"Two-Stream Convolutional Network with Multi-level Feature Fusion for Categorization of Human Action from Videos\",\"url\":\"https://www.semanticscholar.org/paper/bf2eb77e9b795a4a0a38ed4b1c8dd4b2c9a74317\",\"venue\":\"PReMI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145706766\",\"name\":\"B. Zhang\"},{\"authorId\":\"2708397\",\"name\":\"C. Xu\"},{\"authorId\":\"27648874\",\"name\":\"Changmao Cheng\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b4d7ca26deb83cec1922a6964c1193e8dd7270e7\",\"title\":\"Learning to score and summarize figure skating sport videos\",\"url\":\"https://www.semanticscholar.org/paper/b4d7ca26deb83cec1922a6964c1193e8dd7270e7\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"K Sivaraman\"},{\"authorId\":null,\"name\":\"Gautam Somappa\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"22f94c43dd8b203f073f782d91e701108909690b\",\"title\":\"MovieScope: Movie trailer classification using Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/22f94c43dd8b203f073f782d91e701108909690b\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1722052\",\"name\":\"Thomas Mensink\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0ab737d110abc8978b8fb82649f5148ba07b98d2\",\"title\":\"UvA-DARE ( Digital Academic Repository ) Objects 2 action : Classifying and localizing actions without any video\",\"url\":\"https://www.semanticscholar.org/paper/0ab737d110abc8978b8fb82649f5148ba07b98d2\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39440469\",\"name\":\"Sudhakar Kumawat\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"68881e3828f18c304189755c5a64979752d4a3eb\",\"title\":\"LP-3 DCNN : Unveiling Local Phase in 3 D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/68881e3828f18c304189755c5a64979752d4a3eb\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1808.01725\",\"authors\":[{\"authorId\":\"27555915\",\"name\":\"Tz-Ying Wu\"},{\"authorId\":\"9618379\",\"name\":\"Juan-Ting Lin\"},{\"authorId\":\"40897201\",\"name\":\"Tsun-Hsuan Wang\"},{\"authorId\":\"27538483\",\"name\":\"Chan-Wei Hu\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":\"10.1007/978-3-030-01252-6_21\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e8b3a257a0a44d2859862cdec91c8841dc69144d\",\"title\":\"Liquid Pouring Monitoring via Rich Sensory Inputs\",\"url\":\"https://www.semanticscholar.org/paper/e8b3a257a0a44d2859862cdec91c8841dc69144d\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1908.10155\",\"authors\":[{\"authorId\":\"151472652\",\"name\":\"Yuqi Huo\"},{\"authorId\":\"101246507\",\"name\":\"Xiaoli Xu\"},{\"authorId\":\"145525059\",\"name\":\"Yao Lu\"},{\"authorId\":\"2520427\",\"name\":\"Yulei Niu\"},{\"authorId\":\"1776220\",\"name\":\"Zhiwu Lu\"},{\"authorId\":\"153693432\",\"name\":\"Jirong Wen\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"16c8f1d316e0235d20a60cae8fb9f5f83e35574c\",\"title\":\"Mobile Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/16c8f1d316e0235d20a60cae8fb9f5f83e35574c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1901.07757\",\"authors\":[{\"authorId\":\"38179026\",\"name\":\"Y. Shi\"},{\"authorId\":null,\"name\":\"Yaowei Wang\"},{\"authorId\":\"51046192\",\"name\":\"Yixiong Zou\"},{\"authorId\":\"3330973\",\"name\":\"Qingsheng Yuan\"},{\"authorId\":\"40161651\",\"name\":\"Yonghong Tian\"},{\"authorId\":\"19960069\",\"name\":\"Yu Shu\"}],\"doi\":\"10.1109/ICME.2018.8486601\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"def65f74de66e37d3c2977d2322813a6f9b163b0\",\"title\":\"ODN: Opening the Deep Network for Open-Set Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/def65f74de66e37d3c2977d2322813a6f9b163b0\",\"venue\":\"2018 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2018},{\"arxivId\":\"1711.09577\",\"authors\":[{\"authorId\":\"2199251\",\"name\":\"K. Hara\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"}],\"doi\":\"10.1109/CVPR.2018.00685\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d716435f0cb0cac56237f74b1ced940aabce6a2b\",\"title\":\"Can Spatiotemporal 3D CNNs Retrace the History of 2D CNNs and ImageNet?\",\"url\":\"https://www.semanticscholar.org/paper/d716435f0cb0cac56237f74b1ced940aabce6a2b\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2068393\",\"name\":\"Xiusheng Lu\"},{\"authorId\":\"1720100\",\"name\":\"H. Yao\"},{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"1761159\",\"name\":\"S. Zhang\"}],\"doi\":\"10.1007/s11042-017-5251-3\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"40d62396bb195d510bef5c0fd2bfa2bae6777754\",\"title\":\"Action recognition with multi-scale trajectory-pooled 3D convolutional descriptors\",\"url\":\"https://www.semanticscholar.org/paper/40d62396bb195d510bef5c0fd2bfa2bae6777754\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145327726\",\"name\":\"F. Shi\"}],\"doi\":\"10.20381/RUOR-3757\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d080cb2f4fb89a63f9e66924fb029cbd07aed477\",\"title\":\"Local Part Model for Action Recognition in Realistic Videos\",\"url\":\"https://www.semanticscholar.org/paper/d080cb2f4fb89a63f9e66924fb029cbd07aed477\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1799820\",\"name\":\"Adrien Gaidon\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"afbf1a957ebd1d93fc2a433284205eabaa411ce6\",\"title\":\"Structured Models for Action Recognition in Real-word Videos\",\"url\":\"https://www.semanticscholar.org/paper/afbf1a957ebd1d93fc2a433284205eabaa411ce6\",\"venue\":\"\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3272087\",\"name\":\"Omar Seddati\"},{\"authorId\":\"40531114\",\"name\":\"Emre Kulah\"},{\"authorId\":\"3221280\",\"name\":\"Gueorgui Pironkov\"},{\"authorId\":\"144436412\",\"name\":\"S. Dupont\"},{\"authorId\":\"144711671\",\"name\":\"S. Mahmoudi\"},{\"authorId\":\"49164810\",\"name\":\"T. Dutoit\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7044d56b1ab16a2a1bea6145bc561f54aa382004\",\"title\":\"UMons at MediaEval 2015 Affective Impact of Movies Task including Violent Scenes Detection\",\"url\":\"https://www.semanticscholar.org/paper/7044d56b1ab16a2a1bea6145bc561f54aa382004\",\"venue\":\"MediaEval\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34678431\",\"name\":\"F. Sener\"},{\"authorId\":\"40313071\",\"name\":\"Nermin Samet\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"94872c6ea198ae25858ea522bc2366cfb183a173\",\"title\":\"Tan\\u0131nmas\\u0131 Recognizing Human Actions From Noisy Videos via Multiple Instance Learning\",\"url\":\"https://www.semanticscholar.org/paper/94872c6ea198ae25858ea522bc2366cfb183a173\",\"venue\":\"\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144552647\",\"name\":\"T. He\"},{\"authorId\":\"1790187\",\"name\":\"H. Mao\"},{\"authorId\":\"144622703\",\"name\":\"Z. Yi\"}],\"doi\":\"10.1007/s00521-016-2277-9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a48b140a283f7d0901e0695cd0ce902853d52c6\",\"title\":\"Moving object recognition using multi-view three-dimensional convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/8a48b140a283f7d0901e0695cd0ce902853d52c6\",\"venue\":\"Neural Computing and Applications\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46584828\",\"name\":\"J. Wang\"},{\"authorId\":\"1685641\",\"name\":\"P. Zhang\"},{\"authorId\":\"3384353\",\"name\":\"Linmin Luo\"}],\"doi\":\"10.1587/TRANSINF.2015EDL8164\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"75b25390dc83a4c63700e1cd261493c26df9a633\",\"title\":\"Nonnegative Component Representation with Hierarchical Dictionary Learning Strategy for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/75b25390dc83a4c63700e1cd261493c26df9a633\",\"venue\":\"IEICE Trans. Inf. Syst.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2620793\",\"name\":\"M. Ramanathan\"}],\"doi\":\"10.32657/10356/70099\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fba2e4667a57f23f6cb1199b5a5b65ba9ef2b3eb\",\"title\":\"Pose-invariant action recognition for automated behaviour analysis\",\"url\":\"https://www.semanticscholar.org/paper/fba2e4667a57f23f6cb1199b5a5b65ba9ef2b3eb\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31746321\",\"name\":\"Shaofan Lai\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"},{\"authorId\":\"67331131\",\"name\":\"Jianfang Hu\"},{\"authorId\":\"144419120\",\"name\":\"J. Zhang\"}],\"doi\":\"10.1109/TIP.2017.2751145\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4289f9f727af39414537a97e5eef90b06115a5db\",\"title\":\"Global-Local Temporal Saliency Action Prediction\",\"url\":\"https://www.semanticscholar.org/paper/4289f9f727af39414537a97e5eef90b06115a5db\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47637491\",\"name\":\"M. Lakhal\"},{\"authorId\":\"7840884\",\"name\":\"A. Clap\\u00e9s\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"},{\"authorId\":\"145440152\",\"name\":\"A. Cavallaro\"}],\"doi\":\"10.1007/978-3-030-11012-3_40\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d1a8e7c833318d30d30e3eeb0cef139f86a02bcc\",\"title\":\"Residual Stacked RNNs for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d1a8e7c833318d30d30e3eeb0cef139f86a02bcc\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144733334\",\"name\":\"A. Zunino\"},{\"authorId\":\"3393678\",\"name\":\"Jacopo Cavazza\"},{\"authorId\":\"34465973\",\"name\":\"A. Koul\"},{\"authorId\":\"37783905\",\"name\":\"Andrea Cavallo\"},{\"authorId\":\"1834966\",\"name\":\"C. Becchio\"},{\"authorId\":\"1727204\",\"name\":\"Vittorio Murino\"}],\"doi\":\"10.1145/3123266.3123298\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"217aa3aa0b3d9f6f394b5d26f03418187d775596\",\"title\":\"Predicting Human Intentions from Motion Cues Only: A 2D+3D Fusion Approach\",\"url\":\"https://www.semanticscholar.org/paper/217aa3aa0b3d9f6f394b5d26f03418187d775596\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145071344\",\"name\":\"Yang Mi\"},{\"authorId\":\"145052333\",\"name\":\"Kang Zheng\"},{\"authorId\":\"30102584\",\"name\":\"S. Wang\"}],\"doi\":\"10.1145/3206025.3206041\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b3ad7bc128b77d9254aa38c5e1ead7fa10b07d29\",\"title\":\"Recognizing Actions in Wearable-Camera Videos by Training Classifiers on Fixed-Camera Videos\",\"url\":\"https://www.semanticscholar.org/paper/b3ad7bc128b77d9254aa38c5e1ead7fa10b07d29\",\"venue\":\"ICMR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32774629\",\"name\":\"A. Richard\"},{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1109/CVPR.2018.00627\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"96ce111119624888be47d998cf87c9df18988c4d\",\"title\":\"Action Sets: Weakly Supervised Action Segmentation Without Ordering Constraints\",\"url\":\"https://www.semanticscholar.org/paper/96ce111119624888be47d998cf87c9df18988c4d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34346779\",\"name\":\"Weixin Li\"},{\"authorId\":\"1699559\",\"name\":\"N. Vasconcelos\"}],\"doi\":\"10.1007/s11263-016-0918-1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c9e1a9c1136a557a2f4a36eba43442c0a731010\",\"title\":\"Complex\\u00a0Activity\\u00a0Recognition Via Attribute\\u00a0Dynamics\",\"url\":\"https://www.semanticscholar.org/paper/6c9e1a9c1136a557a2f4a36eba43442c0a731010\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144434220\",\"name\":\"X. Yang\"},{\"authorId\":\"2824500\",\"name\":\"P. Molchanov\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":\"10.1145/2964284.2964297\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ed1fe0b01c0e97fa840dc4d9f020e8ce1f7ea3c7\",\"title\":\"Multilayer and Multimodal Fusion of Deep Neural Networks for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/ed1fe0b01c0e97fa840dc4d9f020e8ce1f7ea3c7\",\"venue\":\"ACM Multimedia\",\"year\":2016},{\"arxivId\":\"1708.01246\",\"authors\":[{\"authorId\":\"49923155\",\"name\":\"Hsin-Ying Lee\"},{\"authorId\":\"3068086\",\"name\":\"Jia-Bin Huang\"},{\"authorId\":\"144688398\",\"name\":\"Maneesh Kumar Singh\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/ICCV.2017.79\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"de40803a3d17dd406e25922695266d6ed580e371\",\"title\":\"Unsupervised Representation Learning by Sorting Sequences\",\"url\":\"https://www.semanticscholar.org/paper/de40803a3d17dd406e25922695266d6ed580e371\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9452165\",\"name\":\"Mengyang Yu\"},{\"authorId\":\"40241836\",\"name\":\"L. Liu\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"}],\"doi\":\"10.1109/TPAMI.2015.2491925\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9f36db393bb8e6b510c9a04bdbca62e4d7f2a89c\",\"title\":\"Structure-Preserving Binary Representations for RGB-D Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9f36db393bb8e6b510c9a04bdbca62e4d7f2a89c\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51508179\",\"name\":\"Z. Gao\"},{\"authorId\":\"114320931\",\"name\":\"Hai-Zhen Xuan\"},{\"authorId\":\"41189853\",\"name\":\"H. Zhang\"},{\"authorId\":\"31197849\",\"name\":\"Shaohua Wan\"},{\"authorId\":\"2840539\",\"name\":\"Kim-Kwang Raymond Choo\"}],\"doi\":\"10.1109/JIOT.2019.2911669\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"95ab737cc9d496fa2ac544169465c10b962d4cd4\",\"title\":\"Adaptive Fusion and Category-Level Dictionary Learning Model for Multiview Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/95ab737cc9d496fa2ac544169465c10b962d4cd4\",\"venue\":\"IEEE Internet of Things Journal\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49436226\",\"name\":\"Xi Ouyang\"},{\"authorId\":\"23999166\",\"name\":\"Shuangjie Xu\"},{\"authorId\":\"3194878\",\"name\":\"Chaoyun Zhang\"},{\"authorId\":\"33481412\",\"name\":\"Pan Zhou\"},{\"authorId\":\"144757965\",\"name\":\"Y. Yang\"},{\"authorId\":\"145376360\",\"name\":\"G. Liu\"},{\"authorId\":\"1720243\",\"name\":\"X. Li\"}],\"doi\":\"10.1109/ACCESS.2019.2906654\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"48e51c2508e3e3eb6b9c8a331364e5235e7644f3\",\"title\":\"A 3D-CNN and LSTM Based Multi-Task Learning Architecture for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/48e51c2508e3e3eb6b9c8a331364e5235e7644f3\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1604.06397\",\"authors\":[{\"authorId\":\"2295608\",\"name\":\"Y. Wang\"},{\"authorId\":\"2356016\",\"name\":\"Minh Hoai\"}],\"doi\":\"10.1109/CVPR.2016.295\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ae7122103f0868995ea2b53695479af553ab1361\",\"title\":\"Improving Human Action Recognition by Non-action Classification\",\"url\":\"https://www.semanticscholar.org/paper/ae7122103f0868995ea2b53695479af553ab1361\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123878420\",\"name\":\"Junjie Chen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cd179845d5826ddbb5daf47665b37c933e7b3f6a\",\"title\":\"Learning hash codes for multimedia retrieval\",\"url\":\"https://www.semanticscholar.org/paper/cd179845d5826ddbb5daf47665b37c933e7b3f6a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1708.07590\",\"authors\":[{\"authorId\":\"3491491\",\"name\":\"Shiyang Yan\"},{\"authorId\":\"33830793\",\"name\":\"J. Smith\"},{\"authorId\":\"40178769\",\"name\":\"Wenjin Lu\"},{\"authorId\":\"1782912\",\"name\":\"B. Zhang\"}],\"doi\":\"10.1016/j.image.2017.11.005\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1d6cd361b70a30a0ed8bd9c4bc65685e296647da\",\"title\":\"Hierarchical Multi-scale Attention Networks for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/1d6cd361b70a30a0ed8bd9c4bc65685e296647da\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153580352\",\"name\":\"Ionut Cosmin Duta\"},{\"authorId\":\"1823362\",\"name\":\"J. Uijlings\"},{\"authorId\":\"1796198\",\"name\":\"B. Ionescu\"},{\"authorId\":\"1712839\",\"name\":\"K. Aizawa\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":\"10.1007/s11042-017-4795-6\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"98127346920bdce9773aba6a2ffc8590b9558a4a\",\"title\":\"Efficient human action recognition using histograms of motion gradients and VLAD with descriptor shape information\",\"url\":\"https://www.semanticscholar.org/paper/98127346920bdce9773aba6a2ffc8590b9558a4a\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2017},{\"arxivId\":\"1911.08953\",\"authors\":[{\"authorId\":\"144954447\",\"name\":\"Ferran Par\\u00e9s\"},{\"authorId\":\"1389953200\",\"name\":\"Dario Garcia-Gasulla\"},{\"authorId\":\"2003728\",\"name\":\"Harald Servat\"},{\"authorId\":\"1699563\",\"name\":\"J. Labarta\"},{\"authorId\":\"1744495\",\"name\":\"E. Ayguad\\u00e9\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7fd7a640e3e6f2655392f70e45a781ffb25231e6\",\"title\":\"MetH: A family of high-resolution and variable-shape image challenges\",\"url\":\"https://www.semanticscholar.org/paper/7fd7a640e3e6f2655392f70e45a781ffb25231e6\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2894970\",\"name\":\"Yanhu Shan\"},{\"authorId\":\"31828103\",\"name\":\"Z. Zhang\"},{\"authorId\":\"2887871\",\"name\":\"K. Huang\"}],\"doi\":\"10.1007/978-3-319-16199-0_8\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"40c0c421557ce45e09afbcc2468e0fe2e6286f54\",\"title\":\"Learning Skeleton Stream Patterns with Slow Feature Analysis for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/40c0c421557ce45e09afbcc2468e0fe2e6286f54\",\"venue\":\"ECCV Workshops\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8702449\",\"name\":\"Wanneng Wang\"},{\"authorId\":\"47009814\",\"name\":\"Yanan Ma\"},{\"authorId\":\"144947764\",\"name\":\"Ke Gao\"},{\"authorId\":\"152813130\",\"name\":\"J. Cao\"}],\"doi\":\"10.1145/3343031.3350884\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0be689463698d92433b4fd343379a32e763c9f2c\",\"title\":\"Cost-free Transfer Learning Mechanism: Deep Digging Relationships of Action Categories\",\"url\":\"https://www.semanticscholar.org/paper/0be689463698d92433b4fd343379a32e763c9f2c\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1909.02856\",\"authors\":[{\"authorId\":\"48094430\",\"name\":\"J. Wang\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"}],\"doi\":\"10.1109/TPAMI.2019.2937292\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0d3420c51d930983b62c69713c2004bf3a6fb89d\",\"title\":\"Discriminative Video Representation Learning Using Support Vector Classifiers\",\"url\":\"https://www.semanticscholar.org/paper/0d3420c51d930983b62c69713c2004bf3a6fb89d\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1471424585\",\"name\":\"Deepika Roselind Johnson\"},{\"authorId\":\"69493918\",\"name\":\"V. R. Uthariaraj\"}],\"doi\":\"10.1155/2020/8852404\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eded9af5fc3c7462b6e6e355e0a2f1bbe8d66141\",\"title\":\"A Novel Parameter Initialization Technique Using RBM-NN for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eded9af5fc3c7462b6e6e355e0a2f1bbe8d66141\",\"venue\":\"Comput. Intell. Neurosci.\",\"year\":2020},{\"arxivId\":\"2002.03312\",\"authors\":[{\"authorId\":\"27700913\",\"name\":\"Shenlan Liu\"},{\"authorId\":\"117565367\",\"name\":\"Xiang Liu\"},{\"authorId\":\"143983679\",\"name\":\"Gao Huang\"},{\"authorId\":\"48521932\",\"name\":\"L. Feng\"},{\"authorId\":null,\"name\":\"Lianyu Hu\"},{\"authorId\":\"143949784\",\"name\":\"Dong Jiang\"},{\"authorId\":\"49425435\",\"name\":\"Aibin Zhang\"},{\"authorId\":\"40457423\",\"name\":\"Y. Liu\"},{\"authorId\":\"1397156292\",\"name\":\"Hong Qiao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d23441be3a8fc73413afc6d2c67db66b3686b0e3\",\"title\":\"FSD-10: A Dataset for Competitive Sports Content Analysis\",\"url\":\"https://www.semanticscholar.org/paper/d23441be3a8fc73413afc6d2c67db66b3686b0e3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1994889\",\"name\":\"A. S. Santos\"},{\"authorId\":\"1743455\",\"name\":\"H. Pedrini\"}],\"doi\":\"10.5220/0007409401140123\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2521944da3d8cba6b90ee0d069b2518efc8d2e40\",\"title\":\"Spatio-temporal Video Autoencoder for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2521944da3d8cba6b90ee0d069b2518efc8d2e40\",\"venue\":\"VISIGRAPP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2677670\",\"name\":\"H. Kim\"},{\"authorId\":\"2847986\",\"name\":\"Youngjung Uh\"},{\"authorId\":\"14090815\",\"name\":\"Seunghyeon Ko\"},{\"authorId\":\"144036125\",\"name\":\"H. Byun\"}],\"doi\":\"10.1117/1.OE.55.5.053108\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9642adb0999d035d7589012d6ec05d618a223d33\",\"title\":\"Weighing classes and streams: toward better methods for two-stream convolutional networks\",\"url\":\"https://www.semanticscholar.org/paper/9642adb0999d035d7589012d6ec05d618a223d33\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1443786569\",\"name\":\"Pablo Rodrigo Gantier Cadena\"},{\"authorId\":\"2909406\",\"name\":\"Ming Yang\"},{\"authorId\":\"22187872\",\"name\":\"Yeqiang Qian\"},{\"authorId\":\"47073793\",\"name\":\"Chunxiang Wang\"}],\"doi\":\"10.1109/ITSC.2019.8917118\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2fe7ff2390df0f72c64a05181c38cde9a6b29870\",\"title\":\"Pedestrian Graph: Pedestrian Crossing Prediction Based on 2D Pose Estimation and Graph Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/2fe7ff2390df0f72c64a05181c38cde9a6b29870\",\"venue\":\"2019 IEEE Intelligent Transportation Systems Conference (ITSC)\",\"year\":2019},{\"arxivId\":\"1910.02533\",\"authors\":[{\"authorId\":\"1384812397\",\"name\":\"Haoyuan Cao\"},{\"authorId\":\"48932880\",\"name\":\"Shining Yu\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1b18e1431e96f32d152f49127c70a7dbc2a3061f\",\"title\":\"Compressed Video Action Recognition with Refined Motion Vector\",\"url\":\"https://www.semanticscholar.org/paper/1b18e1431e96f32d152f49127c70a7dbc2a3061f\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52207514\",\"name\":\"Amine Ilidrissi\"},{\"authorId\":\"1694472\",\"name\":\"J. Tan\"}],\"doi\":\"10.1007/s10015-018-0518-y\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"308e7f369b4ec7123733ca954845f622d3ababbe\",\"title\":\"A deep unified framework for suspicious action recognition\",\"url\":\"https://www.semanticscholar.org/paper/308e7f369b4ec7123733ca954845f622d3ababbe\",\"venue\":\"Artificial Life and Robotics\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8744711\",\"name\":\"K. Yamada\"},{\"authorId\":\"65954842\",\"name\":\"Seiya Ito\"},{\"authorId\":\"6965816\",\"name\":\"N. Kaneko\"},{\"authorId\":\"145441213\",\"name\":\"K. Sumi\"}],\"doi\":\"10.1007/978-3-030-21074-8_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"88f35f1424c9409f94868bd5a05a9cf291183b20\",\"title\":\"Human Action Recognition via Body Part Region Segmented Dense Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/88f35f1424c9409f94868bd5a05a9cf291183b20\",\"venue\":\"ACCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143709258\",\"name\":\"Yangyang Xu\"},{\"authorId\":\"145131937\",\"name\":\"L. Wang\"},{\"authorId\":\"144703461\",\"name\":\"J. Cheng\"},{\"authorId\":\"39827902\",\"name\":\"H. Xia\"},{\"authorId\":\"1890165\",\"name\":\"J. Yin\"}],\"doi\":\"10.1109/COMPCOMM.2017.8322825\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f7a515d629dccddd413ffa9e395c3100d28f7f26\",\"title\":\"DTA: Double LSTM with temporal-wise attention network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/f7a515d629dccddd413ffa9e395c3100d28f7f26\",\"venue\":\"2017 3rd IEEE International Conference on Computer and Communications (ICCC)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39042074\",\"name\":\"Ian Tu\"},{\"authorId\":\"145901092\",\"name\":\"A. Bhalerao\"},{\"authorId\":\"144482645\",\"name\":\"N. Griffiths\"},{\"authorId\":\"49625872\",\"name\":\"M. Delgado\"},{\"authorId\":\"2059974\",\"name\":\"Alasdair Thomason\"},{\"authorId\":\"2568126\",\"name\":\"T. Popham\"},{\"authorId\":\"2261735\",\"name\":\"A. Mouzakitis\"}],\"doi\":\"10.1109/IVS.2018.8500564\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"27b06d8d09b0190f44597214627f0e8c65031ad9\",\"title\":\"Dual Viewpoint Passenger State Classification Using 3D CNNs\",\"url\":\"https://www.semanticscholar.org/paper/27b06d8d09b0190f44597214627f0e8c65031ad9\",\"venue\":\"2018 IEEE Intelligent Vehicles Symposium (IV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47423370\",\"name\":\"Can Zhang\"},{\"authorId\":\"35325151\",\"name\":\"Yuexian Zou\"},{\"authorId\":\"145082678\",\"name\":\"G. Chen\"}],\"doi\":\"10.1007/978-3-030-05710-7_39\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8feb4af3daf7d1c71d0ee69a3995d17fb21275a2\",\"title\":\"Hierarchical Temporal Pooling for Efficient Online Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8feb4af3daf7d1c71d0ee69a3995d17fb21275a2\",\"venue\":\"MMM\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38872334\",\"name\":\"G. Yang\"},{\"authorId\":\"1784263\",\"name\":\"Yafeng Yin\"},{\"authorId\":\"144484157\",\"name\":\"H. Man\"}],\"doi\":\"10.1109/AIPR.2013.6749320\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a4433e950ffcde79b703c4eac6abe61aff032144\",\"title\":\"Human object interactions recognition based on social network analysis\",\"url\":\"https://www.semanticscholar.org/paper/a4433e950ffcde79b703c4eac6abe61aff032144\",\"venue\":\"2013 IEEE Applied Imagery Pattern Recognition Workshop (AIPR)\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a93700ae268dcda5555f105b691c97500c962068\",\"title\":\"Learning pullback manifolds of generative dynamical models for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/a93700ae268dcda5555f105b691c97500c962068\",\"venue\":\"\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144484157\",\"name\":\"H. Man\"},{\"authorId\":\"145259429\",\"name\":\"Y. Yao\"}],\"doi\":\"10.21236/ada589989\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7710f1fc67f11a91afaa951f1b26e07e280391c5\",\"title\":\"MSEE: Stochastic Cognitive Linguistic Behavior Models for Semantic Sensing\",\"url\":\"https://www.semanticscholar.org/paper/7710f1fc67f11a91afaa951f1b26e07e280391c5\",\"venue\":\"\",\"year\":2013},{\"arxivId\":\"1309.0309\",\"authors\":[{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":\"143740449\",\"name\":\"Q. Peng\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"2723374\",\"name\":\"J. Chen\"},{\"authorId\":\"27305891\",\"name\":\"Mehtab Afzal\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"61aa33cef443cb2c82c3caf1f1fe84c58edb5ec3\",\"title\":\"A Study on Unsupervised Dictionary Learning and Feature Encoding for Action Classification\",\"url\":\"https://www.semanticscholar.org/paper/61aa33cef443cb2c82c3caf1f1fe84c58edb5ec3\",\"venue\":\"ArXiv\",\"year\":2013},{\"arxivId\":\"1510.00562\",\"authors\":[{\"authorId\":\"41191188\",\"name\":\"Lin Sun\"},{\"authorId\":\"2370507\",\"name\":\"K. Jia\"},{\"authorId\":\"1739816\",\"name\":\"D. Yeung\"},{\"authorId\":\"2131088\",\"name\":\"B. Shi\"}],\"doi\":\"10.1109/ICCV.2015.522\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"95561aec9f00cdf5346e627574e1a022eda3e4f5\",\"title\":\"Human Action Recognition Using Factorized Spatio-Temporal Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/95561aec9f00cdf5346e627574e1a022eda3e4f5\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2676982\",\"name\":\"Hueihan Jhuang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"823e57c126124254cf96c723fe1bace505271220\",\"title\":\"Dorsal stream: from algorithm to neuroscience\",\"url\":\"https://www.semanticscholar.org/paper/823e57c126124254cf96c723fe1bace505271220\",\"venue\":\"\",\"year\":2011},{\"arxivId\":\"2010.08055\",\"authors\":[{\"authorId\":\"27478395\",\"name\":\"K. Bhandari\"},{\"authorId\":\"1998945138\",\"name\":\"Mario A. DeLaGarza\"},{\"authorId\":\"153364719\",\"name\":\"Ziliang Zong\"},{\"authorId\":\"3422205\",\"name\":\"Hugo Latapie\"},{\"authorId\":\"49483094\",\"name\":\"Yan Yan\"}],\"doi\":\"10.1109/ICIP40778.2020.9191256\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b30ef8520715d7e5584fbe3bd0f4d0351859154a\",\"title\":\"Egok360: A 360 Egocentric Kinetic Human Activity Video Dataset\",\"url\":\"https://www.semanticscholar.org/paper/b30ef8520715d7e5584fbe3bd0f4d0351859154a\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"2007.09861\",\"authors\":[{\"authorId\":\"9096071\",\"name\":\"Jianchao Wu\"},{\"authorId\":\"1874900\",\"name\":\"Zhanghui Kuang\"},{\"authorId\":\"48170161\",\"name\":\"L. Wang\"},{\"authorId\":\"1726357\",\"name\":\"Wayne Zhang\"},{\"authorId\":\"39914710\",\"name\":\"Gangshan Wu\"}],\"doi\":\"10.1007/978-3-030-58595-2_27\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf0bc1e97049ece897db97ba605594a89df50c34\",\"title\":\"Context-Aware RCNN: A Baseline for Action Detection in Videos\",\"url\":\"https://www.semanticscholar.org/paper/cf0bc1e97049ece897db97ba605594a89df50c34\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d90bcce87174d2e85004036ae3e977c1ef222695\",\"title\":\"Scale-Adaptive Video Understanding.\",\"url\":\"https://www.semanticscholar.org/paper/d90bcce87174d2e85004036ae3e977c1ef222695\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1907.12743\",\"authors\":[{\"authorId\":\"50133145\",\"name\":\"Min-Hung Chen\"},{\"authorId\":\"145276578\",\"name\":\"Z. Kira\"},{\"authorId\":\"9202076\",\"name\":\"G. Al-Regib\"},{\"authorId\":\"66370228\",\"name\":\"J. Yoo\"},{\"authorId\":\"3090152\",\"name\":\"Ruxin Chen\"},{\"authorId\":\"15460136\",\"name\":\"Jianqiu Zheng\"}],\"doi\":\"10.1109/ICCV.2019.00642\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"89917e19175eb4f3bca02e0bace8f99d6910b054\",\"title\":\"Temporal Attentive Alignment for Large-Scale Video Domain Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/89917e19175eb4f3bca02e0bace8f99d6910b054\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66148232\",\"name\":\"Lei Wang\"},{\"authorId\":\"2155775\",\"name\":\"Piotr Koniusz\"},{\"authorId\":\"144199437\",\"name\":\"D. Huynh\"}],\"doi\":\"10.1109/ICCV.2019.00879\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"70660cb3af4e19c74681238c7854e3d341654b2d\",\"title\":\"Hallucinating IDT Descriptors and I3D Optical Flow Features for Action Recognition With CNNs\",\"url\":\"https://www.semanticscholar.org/paper/70660cb3af4e19c74681238c7854e3d341654b2d\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41185832\",\"name\":\"Xiaochun Luo\"},{\"authorId\":\"49404404\",\"name\":\"Heng Li\"},{\"authorId\":\"46690737\",\"name\":\"Dongping Cao\"},{\"authorId\":\"2740879\",\"name\":\"Y. Yu\"},{\"authorId\":\"30963734\",\"name\":\"Xincong Yang\"},{\"authorId\":\"51029695\",\"name\":\"Ting Huang\"}],\"doi\":\"10.1016/J.AUTCON.2018.07.011\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9384eb2b25b939d83b81a618abfc9de686fe5ec5\",\"title\":\"Towards efficient and objective work sampling: Recognizing workers' activities in site surveillance videos with two-stream convolutional networks\",\"url\":\"https://www.semanticscholar.org/paper/9384eb2b25b939d83b81a618abfc9de686fe5ec5\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1807.01026\",\"authors\":[{\"authorId\":\"143894891\",\"name\":\"E. Ong\"},{\"authorId\":\"32673717\",\"name\":\"Sameed Husain\"},{\"authorId\":\"1387990552\",\"name\":\"Mikel Bober-Irizar\"},{\"authorId\":\"144048413\",\"name\":\"M. Bober\"}],\"doi\":\"10.1109/TCSVT.2018.2881842\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"0f2dcefa91c4cf6ed603d489c4cdfe9a4158eb79\",\"title\":\"Deep Architectures and Ensembles for Semantic Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/0f2dcefa91c4cf6ed603d489c4cdfe9a4158eb79\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40241836\",\"name\":\"L. Liu\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"},{\"authorId\":\"1720243\",\"name\":\"X. Li\"},{\"authorId\":\"144106250\",\"name\":\"K. Lu\"}],\"doi\":\"10.1109/TCYB.2015.2399172\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"230ea97b6842c613afeb71723e1e46335dc600a6\",\"title\":\"Learning Spatio-Temporal Representations for Action Recognition: A Genetic Programming Approach\",\"url\":\"https://www.semanticscholar.org/paper/230ea97b6842c613afeb71723e1e46335dc600a6\",\"venue\":\"IEEE Transactions on Cybernetics\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144682140\",\"name\":\"R. Venkatesh Babu\"},{\"authorId\":\"37977601\",\"name\":\"M. Tom\"},{\"authorId\":\"2191475\",\"name\":\"Paras Wadekar\"}],\"doi\":\"10.1007/s11042-014-2345-z\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ed0d8997a4b7b80a7cd3592e98bdbe5c3aab0cee\",\"title\":\"A survey on compressed domain video analysis techniques\",\"url\":\"https://www.semanticscholar.org/paper/ed0d8997a4b7b80a7cd3592e98bdbe5c3aab0cee\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2014},{\"arxivId\":\"2006.00626\",\"authors\":[{\"authorId\":\"47002659\",\"name\":\"Yanchao Li\"},{\"authorId\":\"1720749879\",\"name\":\"Miao Liu\"},{\"authorId\":\"50779871\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a48cde936f7dea115cbda99a08e12dbdf45d13fb\",\"title\":\"In the Eye of the Beholder: Gaze and Actions in First Person Video\",\"url\":\"https://www.semanticscholar.org/paper/a48cde936f7dea115cbda99a08e12dbdf45d13fb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46522476\",\"name\":\"Xiaoli Liu\"},{\"authorId\":\"46947100\",\"name\":\"Zhibin Li\"}],\"doi\":\"10.1016/j.image.2020.115809\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"835963d0f0157841597d6c0d923df6491fa1244e\",\"title\":\"Deeply fusing multi-model quality-aware features for sophisticated human activity understanding\",\"url\":\"https://www.semanticscholar.org/paper/835963d0f0157841597d6c0d923df6491fa1244e\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2020},{\"arxivId\":\"2011.01819\",\"authors\":[{\"authorId\":\"143698653\",\"name\":\"P. Morgado\"},{\"authorId\":\"3184077\",\"name\":\"Y. Li\"},{\"authorId\":\"1699559\",\"name\":\"N. Vasconcelos\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"eeb33ad2ede9944918724978bcbfb08b4c8c50a8\",\"title\":\"Learning Representations from Audio-Visual Spatial Alignment\",\"url\":\"https://www.semanticscholar.org/paper/eeb33ad2ede9944918724978bcbfb08b4c8c50a8\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2009.07420\",\"authors\":[{\"authorId\":\"3671120\",\"name\":\"Yanyi Zhang\"},{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"144555425\",\"name\":\"I. Marsic\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d951f225ab2d64af36e9c44a658ac79c2afde7f3\",\"title\":\"Multi-Label Activity Recognition using Activity-specific Features\",\"url\":\"https://www.semanticscholar.org/paper/d951f225ab2d64af36e9c44a658ac79c2afde7f3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2001.04627\",\"authors\":[{\"authorId\":\"38403207\",\"name\":\"L. Wang\"},{\"authorId\":\"2155775\",\"name\":\"Piotr Koniusz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"8e35dc0f90a721d819f74633c8d0d7e4c5a7973e\",\"title\":\"Hallucinating Statistical Moment and Subspace Descriptors from Object and Saliency Detectors for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8e35dc0f90a721d819f74633c8d0d7e4c5a7973e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.12886\",\"authors\":[{\"authorId\":\"1965933798\",\"name\":\"Alban Main De Boissiere\"},{\"authorId\":\"2479033\",\"name\":\"Rita Noumeir\"}],\"doi\":\"10.1109/ACCESS.2020.3023599\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f67eca7b8511a3253d58fd12b0768c9caa12610d\",\"title\":\"Infrared and 3D Skeleton Feature Fusion for RGB-D Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f67eca7b8511a3253d58fd12b0768c9caa12610d\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1904.07911\",\"authors\":[{\"authorId\":\"47001807\",\"name\":\"Y. Li\"},{\"authorId\":\"1699559\",\"name\":\"N. Vasconcelos\"}],\"doi\":\"10.1109/CVPR.2019.00980\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e91dca6e99f2d392953524986f2125be2008d9fc\",\"title\":\"REPAIR: Removing Representation Bias by Dataset Resampling\",\"url\":\"https://www.semanticscholar.org/paper/e91dca6e99f2d392953524986f2125be2008d9fc\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2044336091\",\"name\":\"Yijun Pan\"},{\"authorId\":\"6485172\",\"name\":\"Xiaoyan Sun\"},{\"authorId\":\"144864335\",\"name\":\"Feng Wu\"}],\"doi\":\"10.1109/VCIP49819.2020.9301827\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2dd36a027fcfc4fd8ec323ac6adcee5168c5e28e\",\"title\":\"Enriching Optical Flow with Appearance Information for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2dd36a027fcfc4fd8ec323ac6adcee5168c5e28e\",\"venue\":\"2020 IEEE International Conference on Visual Communications and Image Processing (VCIP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2044355139\",\"name\":\"Aishrith Rao\"}],\"doi\":\"10.1109/INOCON50539.2020.9298211\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d6f32e3a76094c21ba0afe8e4067c99613f7f8cf\",\"title\":\"Efficient Min-Cost Real Time Action Recognition using Pose Estimates\",\"url\":\"https://www.semanticscholar.org/paper/d6f32e3a76094c21ba0afe8e4067c99613f7f8cf\",\"venue\":\"2020 IEEE International Conference for Innovation in Technology (INOCON)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1395615456\",\"name\":\"Elena Nicora\"},{\"authorId\":\"2442124\",\"name\":\"Gaurvi Goyal\"},{\"authorId\":\"2600472\",\"name\":\"Nicoletta Noceti\"},{\"authorId\":\"2511943\",\"name\":\"A. Vignolo\"},{\"authorId\":\"1961676436\",\"name\":\"Alessandra Sciutti\"},{\"authorId\":\"1712692\",\"name\":\"F. Odone\"}],\"doi\":\"10.1038/s41597-020-00776-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bb9f7b110e4b8e9ab4c9ceb8967f505d80837cca\",\"title\":\"The MoCA dataset, kinematic and multi-view visual streams of fine-grained cooking actions\",\"url\":\"https://www.semanticscholar.org/paper/bb9f7b110e4b8e9ab4c9ceb8967f505d80837cca\",\"venue\":\"Scientific data\",\"year\":2020},{\"arxivId\":\"1604.03196\",\"authors\":[{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"},{\"authorId\":\"1904850\",\"name\":\"B. Rothrock\"},{\"authorId\":\"47517530\",\"name\":\"C. Fleming\"},{\"authorId\":\"3014315\",\"name\":\"H. Yang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f393c5a809fac223461e764495d933c7f18e6ec0\",\"title\":\"Privacy-Preserving Human Activity Recognition from Extreme Low Resolution\",\"url\":\"https://www.semanticscholar.org/paper/f393c5a809fac223461e764495d933c7f18e6ec0\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49616225\",\"name\":\"Sujoy Paul\"},{\"authorId\":\"2177805\",\"name\":\"S. Roy\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"70c58700eb89368e66a8f0d3fc54f32f69d423e1\",\"title\":\"IN UNSUPERVISED SPATIO-TEMPORAL FEATURE LEARNING\",\"url\":\"https://www.semanticscholar.org/paper/70c58700eb89368e66a8f0d3fc54f32f69d423e1\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10029285\",\"name\":\"Nieves Crasto\"},{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"72492981\",\"name\":\"Alahari Karteek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"47e1b171fab52368f14f41955cdc7ca7775ded58\",\"title\":\"RGB TVL 1 Flow RGB + TVL 1 FlowMARS MARS + RGB MERS MERS + RGB Accuracy vs Time on MiniKinetics\",\"url\":\"https://www.semanticscholar.org/paper/47e1b171fab52368f14f41955cdc7ca7775ded58\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1978810071\",\"name\":\"Konstantinos Bacharidis\"},{\"authorId\":\"1689415\",\"name\":\"Antonis A. Argyros\"}],\"doi\":\"10.1109/IJCNN48605.2020.9207397\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"40f490936a81c89d0100c166c86f6ef0ec09fd64\",\"title\":\"Improving Deep Learning Approaches for Human Activity Recognition based on Natural Language Processing of Action Labels\",\"url\":\"https://www.semanticscholar.org/paper/40f490936a81c89d0100c166c86f6ef0ec09fd64\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2610029\",\"name\":\"H. Wu\"},{\"authorId\":\"145453305\",\"name\":\"Xin Ma\"},{\"authorId\":\"47002225\",\"name\":\"Yibin Li\"}],\"doi\":\"10.1177/1729881418825093\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9e4f91715773e6fa3e2e04303e43a77355d1e536\",\"title\":\"Hierarchical dynamic depth projected difference images\\u2013based action recognition in videos with convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/9e4f91715773e6fa3e2e04303e43a77355d1e536\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1819203\",\"name\":\"Zufan Zhang\"},{\"authorId\":\"2000399066\",\"name\":\"Zongming Lv\"},{\"authorId\":\"2901849\",\"name\":\"Chenquan Gan\"},{\"authorId\":\"145649216\",\"name\":\"Qingyi Zhu\"}],\"doi\":\"10.1016/j.neucom.2020.06.032\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"851edff1c8deded530836d0338ea6cbe50f30594\",\"title\":\"Human action recognition using convolutional LSTM and fully-connected LSTM with different attentions\",\"url\":\"https://www.semanticscholar.org/paper/851edff1c8deded530836d0338ea6cbe50f30594\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"108808263\",\"name\":\"Jian He\"},{\"authorId\":\"50445724\",\"name\":\"C. Zhang\"},{\"authorId\":\"98197525\",\"name\":\"Xinlin He\"},{\"authorId\":\"1786267\",\"name\":\"Ruihai Dong\"}],\"doi\":\"10.1016/j.neucom.2019.07.103\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e6fd8edaa5f7da9c9e2d8547a4d8381ea6a7a4e0\",\"title\":\"Visual Recognition of traffic police gestures with convolutional pose machine and handcrafted features\",\"url\":\"https://www.semanticscholar.org/paper/e6fd8edaa5f7da9c9e2d8547a4d8381ea6a7a4e0\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2680865\",\"name\":\"Bo Zhang\"},{\"authorId\":\"39337007\",\"name\":\"Paolo Rota\"},{\"authorId\":\"3058987\",\"name\":\"N. Conci\"},{\"authorId\":\"144211458\",\"name\":\"F. Natale\"}],\"doi\":\"10.1109/ICME.2015.7177480\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0cddac508c44b5e20c619798b0bea9035ceb9fec\",\"title\":\"Human interaction recognition in the wild: Analyzing trajectory clustering from multiple-instance-learning perspective\",\"url\":\"https://www.semanticscholar.org/paper/0cddac508c44b5e20c619798b0bea9035ceb9fec\",\"venue\":\"2015 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2015},{\"arxivId\":\"1810.12819\",\"authors\":[{\"authorId\":\"33390229\",\"name\":\"Alina Roitberg\"},{\"authorId\":\"1390024605\",\"name\":\"Ziad Al-Halah\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"563143c5f4fed0184c1f3e661917da94cfed1d46\",\"title\":\"Informed Democracy: Voting-based Novelty Detection for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/563143c5f4fed0184c1f3e661917da94cfed1d46\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":\"1608.08395\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":null,\"name\":\"Yun He\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"}],\"doi\":\"10.1007/978-3-319-49409-8_3\",\"intent\":[\"result\"],\"isInfluential\":true,\"paperId\":\"31625522950e82ad4dffef7ed0df00fdd2401436\",\"title\":\"Motion Representation with Acceleration Images\",\"url\":\"https://www.semanticscholar.org/paper/31625522950e82ad4dffef7ed0df00fdd2401436\",\"venue\":\"ECCV Workshops\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49050421\",\"name\":\"J. Zhang\"},{\"authorId\":\"145314992\",\"name\":\"Z. Wei\"},{\"authorId\":\"153580352\",\"name\":\"Ionut Cosmin Duta\"},{\"authorId\":\"38083193\",\"name\":\"F. Shen\"},{\"authorId\":\"143813538\",\"name\":\"L. Liu\"},{\"authorId\":\"152506137\",\"name\":\"F. Zhu\"},{\"authorId\":\"1390532590\",\"name\":\"Xing Xu\"},{\"authorId\":\"40799321\",\"name\":\"Ling Shao\"},{\"authorId\":\"152555512\",\"name\":\"Heng Tao Shen\"}],\"doi\":\"10.1145/3343031.3350897\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e2593a896d82b60adf0a982afef27756dcddc6ed\",\"title\":\"Generative Reconstructive Hashing for Incomplete Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/e2593a896d82b60adf0a982afef27756dcddc6ed\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21570451\",\"name\":\"A. Barbu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"09071e54b012fd8b14aa351a73d44190707b1409\",\"title\":\"Reasoning Across Language and Vision in Machines and Humans\",\"url\":\"https://www.semanticscholar.org/paper/09071e54b012fd8b14aa351a73d44190707b1409\",\"venue\":\"\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71272004\",\"name\":\"Mohsin Raza Siyal\"},{\"authorId\":\"50674257\",\"name\":\"M. Ebrahim\"},{\"authorId\":\"31557599\",\"name\":\"S. H. Adil\"},{\"authorId\":\"2095737\",\"name\":\"K. Raza\"}],\"doi\":\"10.1109/ICCI51257.2020.9247670\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b6cfce939e00abefdd4587f476d1171d13914156\",\"title\":\"Human Action Recognition using ConvLSTM with GAN and transfer learning\",\"url\":\"https://www.semanticscholar.org/paper/b6cfce939e00abefdd4587f476d1171d13914156\",\"venue\":\"2020 International Conference on Computational Intelligence (ICCI)\",\"year\":2020},{\"arxivId\":\"2004.02753\",\"authors\":[{\"authorId\":\"1612061859\",\"name\":\"Joshua Knights\"},{\"authorId\":\"1612351216\",\"name\":\"Anthony Vanderkop\"},{\"authorId\":\"143679553\",\"name\":\"D. Ward\"},{\"authorId\":\"1612210724\",\"name\":\"Olivia Mackenzie-Ross\"},{\"authorId\":\"145136889\",\"name\":\"P. Moghadam\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"195a51f9e4be3537f930d87f5200e63a51b9a226\",\"title\":\"Temporally Coherent Embeddings for Self-Supervised Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/195a51f9e4be3537f930d87f5200e63a51b9a226\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1903.05577\",\"authors\":[{\"authorId\":\"50993183\",\"name\":\"Haochen Zhang\"},{\"authorId\":\"48928981\",\"name\":\"Dong Liu\"},{\"authorId\":\"2352456\",\"name\":\"Z. Xiong\"}],\"doi\":\"10.1109/ICCV.2019.00889\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"cb72cbdb5476118a207a51054787f6419d5ec055\",\"title\":\"Two-Stream Action Recognition-Oriented Video Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/cb72cbdb5476118a207a51054787f6419d5ec055\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1910.06540\",\"authors\":[{\"authorId\":\"34831857\",\"name\":\"Jasper S. Wijnands\"},{\"authorId\":\"145040690\",\"name\":\"J. Thompson\"},{\"authorId\":\"52351371\",\"name\":\"Kerry A. Nice\"},{\"authorId\":\"75058211\",\"name\":\"G. Aschwanden\"},{\"authorId\":\"144795096\",\"name\":\"M. Stevenson\"}],\"doi\":\"10.1007/s00521-019-04506-0\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"82a9a9fde3c2c7acb2980506c15d323b338ad85b\",\"title\":\"Real-time monitoring of driver drowsiness on mobile platforms using 3D neural networks\",\"url\":\"https://www.semanticscholar.org/paper/82a9a9fde3c2c7acb2980506c15d323b338ad85b\",\"venue\":\"Neural Computing and Applications\",\"year\":2019},{\"arxivId\":\"2007.09029\",\"authors\":[{\"authorId\":\"1581871399\",\"name\":\"Abdolmaged Alkhulaifi\"},{\"authorId\":\"1387124746\",\"name\":\"F. Alsahli\"},{\"authorId\":\"72137044\",\"name\":\"I. Ahmad\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"1a11c31ccf0238c6d294cdf5f3c0b08f75679877\",\"title\":\"Knowledge Distillation in Deep Learning and its Applications\",\"url\":\"https://www.semanticscholar.org/paper/1a11c31ccf0238c6d294cdf5f3c0b08f75679877\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2037859\",\"name\":\"Saddam Bekhet\"},{\"authorId\":\"143629707\",\"name\":\"Amr Ahmed\"}],\"doi\":\"10.1007/s11554-017-0700-9\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3cc2d6ace4cf0bc3a6c4df5ca8da892275ca201f\",\"title\":\"Video similarity detection using fixed-length Statistical Dominant Colour Profile (SDCP) signatures\",\"url\":\"https://www.semanticscholar.org/paper/3cc2d6ace4cf0bc3a6c4df5ca8da892275ca201f\",\"venue\":\"Journal of Real-Time Image Processing\",\"year\":2017},{\"arxivId\":\"1904.03249\",\"authors\":[{\"authorId\":\"1720749879\",\"name\":\"Miao Liu\"},{\"authorId\":\"40897068\",\"name\":\"Xin Chen\"},{\"authorId\":\"23614019\",\"name\":\"Y. Zhang\"},{\"authorId\":\"47002659\",\"name\":\"Yanchao Li\"},{\"authorId\":\"50779871\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"76db87564c7e6a6f417fca41b9f659a879de5027\",\"title\":\"Attention Distillation for Learning Video Representations\",\"url\":\"https://www.semanticscholar.org/paper/76db87564c7e6a6f417fca41b9f659a879de5027\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144544965\",\"name\":\"Mario Rodr\\u00edguez\"},{\"authorId\":\"31341930\",\"name\":\"C. Orrite\"},{\"authorId\":\"1783769\",\"name\":\"C. Medrano\"},{\"authorId\":\"143920053\",\"name\":\"D. Makris\"}],\"doi\":\"10.1109/TCYB.2016.2558447\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"9aaaafc81ce56acd588135ac85ef553f6bcd0420\",\"title\":\"One-Shot Learning of Human Activity With an MAP Adapted GMM and Simplex-HMM\",\"url\":\"https://www.semanticscholar.org/paper/9aaaafc81ce56acd588135ac85ef553f6bcd0420\",\"venue\":\"IEEE Transactions on Cybernetics\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3174233\",\"name\":\"H. Boyraz\"},{\"authorId\":\"2234898\",\"name\":\"Syed Zain Masood\"},{\"authorId\":\"6312216\",\"name\":\"B. Liu\"},{\"authorId\":\"1802944\",\"name\":\"M. Tappen\"},{\"authorId\":\"1691260\",\"name\":\"H. Foroosh\"}],\"doi\":\"10.5244/C.28.111\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ee80331bc06fc26c319f8e92315f26ce21dcc453\",\"title\":\"Action Recognition by Weakly-Supervised Discriminative Region Localization\",\"url\":\"https://www.semanticscholar.org/paper/ee80331bc06fc26c319f8e92315f26ce21dcc453\",\"venue\":\"BMVC\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144757965\",\"name\":\"Y. Yang\"},{\"authorId\":\"1721819\",\"name\":\"D. Zhan\"},{\"authorId\":\"144788045\",\"name\":\"Ying Fan\"},{\"authorId\":\"2192443\",\"name\":\"Yuan Jiang\"},{\"authorId\":\"145624000\",\"name\":\"Z. Zhou\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"bc8e11b8cdf0cfbedde798a53a0318e8d6f67e17\",\"title\":\"Deep Learning for Fixed Model Reuse\",\"url\":\"https://www.semanticscholar.org/paper/bc8e11b8cdf0cfbedde798a53a0318e8d6f67e17\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31636143\",\"name\":\"P. Maurice\"},{\"authorId\":\"3471188\",\"name\":\"Adrien Malais\\u00e9\"},{\"authorId\":\"1388149790\",\"name\":\"Cl\\u00e9lie Amiot\"},{\"authorId\":\"49017066\",\"name\":\"N. Paris\"},{\"authorId\":\"1379919501\",\"name\":\"Guy-Junior Richard\"},{\"authorId\":\"2921405\",\"name\":\"Olivier Rochel\"},{\"authorId\":\"48128779\",\"name\":\"Serena Ivaldi\"}],\"doi\":\"10.1177/0278364919882089\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f6b7dfb3b5bfe986fad4ca6f202f1589d49cfa20\",\"title\":\"Human movement and ergonomics: An industry-oriented dataset for collaborative robotics\",\"url\":\"https://www.semanticscholar.org/paper/f6b7dfb3b5bfe986fad4ca6f202f1589d49cfa20\",\"venue\":\"Int. J. Robotics Res.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50504401\",\"name\":\"Wei Chen\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1109/ICCV.2015.377\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8336e17542aacd02e644bc029389800bf248d470\",\"title\":\"Action Detection by Implicit Intentional Motion Clustering\",\"url\":\"https://www.semanticscholar.org/paper/8336e17542aacd02e644bc029389800bf248d470\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145143348\",\"name\":\"O. V. R. Murthy\"},{\"authorId\":\"1717204\",\"name\":\"R. Goecke\"}],\"doi\":\"10.1109/ICCVW.2015.105\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"3195461f2068cd0acc3c083fb2cf4876efb623db\",\"title\":\"Injury Mechanism Classification in Soccer Videos\",\"url\":\"https://www.semanticscholar.org/paper/3195461f2068cd0acc3c083fb2cf4876efb623db\",\"venue\":\"2015 IEEE International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47916686\",\"name\":\"K. Matsui\"},{\"authorId\":\"134811419\",\"name\":\"Toru Tamaki\"},{\"authorId\":\"1688940\",\"name\":\"B. Raytchev\"},{\"authorId\":\"1686272\",\"name\":\"K. Kaneda\"}],\"doi\":\"10.1587/TRANSINF.2017EDL8049\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bcf19b964e7d1134d00332cf1acf1ee6184aff00\",\"title\":\"Trajectory-Set Feature for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/bcf19b964e7d1134d00332cf1acf1ee6184aff00\",\"venue\":\"IEICE Trans. Inf. Syst.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49102847\",\"name\":\"Feifei Chen\"},{\"authorId\":\"1707161\",\"name\":\"N. Sang\"},{\"authorId\":\"2445342\",\"name\":\"Xiaoqin Kuang\"},{\"authorId\":\"2257766\",\"name\":\"H. Gan\"},{\"authorId\":\"40115662\",\"name\":\"Changxin Gao\"}],\"doi\":\"10.1364/JOSAA.32.000173\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c2a16ca988e82cd71dbcefdd51a8935805d44646\",\"title\":\"Action recognition through discovering distinctive action parts.\",\"url\":\"https://www.semanticscholar.org/paper/c2a16ca988e82cd71dbcefdd51a8935805d44646\",\"venue\":\"Journal of the Optical Society of America. A, Optics, image science, and vision\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2563887\",\"name\":\"Rohaya Latip\"},{\"authorId\":\"32993846\",\"name\":\"Mien May Chong\"},{\"authorId\":\"49961022\",\"name\":\"Hamidah Ibrahim\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"304297e9b56ef0a0da0a09e64a46919b7ee3b420\",\"title\":\"Framework of fast medical data transmission\",\"url\":\"https://www.semanticscholar.org/paper/304297e9b56ef0a0da0a09e64a46919b7ee3b420\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"48620041\",\"name\":\"Yun Yi\"}],\"doi\":\"10.1109/SMC.2015.530\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"37da889dead905dde002fd2d70a9d6011e7720ca\",\"title\":\"Tracking Salient Keypoints for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/37da889dead905dde002fd2d70a9d6011e7720ca\",\"venue\":\"2015 IEEE International Conference on Systems, Man, and Cybernetics\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46329495\",\"name\":\"Amin Ullah\"},{\"authorId\":\"143636222\",\"name\":\"J. Ahmad\"},{\"authorId\":\"143997136\",\"name\":\"Khan Muhammad\"},{\"authorId\":\"143993371\",\"name\":\"M. Sajjad\"},{\"authorId\":\"1777998\",\"name\":\"S. Baik\"}],\"doi\":\"10.1109/ACCESS.2017.2778011\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b5979489e11edd76607c219a8bdc83ba4a88ab38\",\"title\":\"Action Recognition in Video Sequences using Deep Bi-Directional LSTM With CNN Features\",\"url\":\"https://www.semanticscholar.org/paper/b5979489e11edd76607c219a8bdc83ba4a88ab38\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1751449\",\"name\":\"Dongqi Cai\"},{\"authorId\":\"144310030\",\"name\":\"F. Su\"}],\"doi\":\"10.1109/ICIP.2015.7351140\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3bfa630a6dc6d1ca98e7b43c90dd9e8b98e361d6\",\"title\":\"Deep CCA based super vector for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/3bfa630a6dc6d1ca98e7b43c90dd9e8b98e361d6\",\"venue\":\"2015 IEEE International Conference on Image Processing (ICIP)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2351434\",\"name\":\"Zhongwen Xu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6bd7ff039ff38f4bb41f7a4b9a1f370ef02eed80\",\"title\":\"Large-scale video analysis and understanding\",\"url\":\"https://www.semanticscholar.org/paper/6bd7ff039ff38f4bb41f7a4b9a1f370ef02eed80\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[],\"doi\":\"10.35940/ijeat.a1901.129219\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fd220c9d2a5d2b99dc688c933cac0dd9ee71c30f\",\"title\":\"Hand-Held Object with Action Recognition Based On Convolutional Neural Network in Spatio Temporal Domain\",\"url\":\"https://www.semanticscholar.org/paper/fd220c9d2a5d2b99dc688c933cac0dd9ee71c30f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38179026\",\"name\":\"Y. Shi\"},{\"authorId\":\"40161651\",\"name\":\"Yonghong Tian\"},{\"authorId\":\"5765799\",\"name\":\"Yaowei Wang\"},{\"authorId\":\"34097174\",\"name\":\"Tiejun Huang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"c829be73584966e3162f7ccae72d9284a2ebf358\",\"title\":\"shuttleNet: A biologically-inspired RNN with loop connection and parameter sharing\",\"url\":\"https://www.semanticscholar.org/paper/c829be73584966e3162f7ccae72d9284a2ebf358\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9012538\",\"name\":\"Salah Alghyaline\"},{\"authorId\":\"144717607\",\"name\":\"Jun-Wei Hsieh\"},{\"authorId\":\"3034959\",\"name\":\"Hui-Fen Chiang\"},{\"authorId\":\"9018571\",\"name\":\"Rui-Yu Lin\"}],\"doi\":\"10.1109/SMC.2016.7844559\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"efd286d9ccce0d1d3d9f9d15f6a76655c8b10383\",\"title\":\"Action classification using data mining and Paris of SURF-based trajectories\",\"url\":\"https://www.semanticscholar.org/paper/efd286d9ccce0d1d3d9f9d15f6a76655c8b10383\",\"venue\":\"2016 IEEE International Conference on Systems, Man, and Cybernetics (SMC)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92148538\",\"name\":\"Di Wu\"},{\"authorId\":\"2257498\",\"name\":\"N. Sharma\"},{\"authorId\":\"1801266\",\"name\":\"M. Blumenstein\"}],\"doi\":\"10.1109/IJCNN.2017.7966210\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c3a7262f681fe5c0c4afba73a37b52a7d8b2d8db\",\"title\":\"Recent advances in video-based human action recognition using deep learning: A review\",\"url\":\"https://www.semanticscholar.org/paper/c3a7262f681fe5c0c4afba73a37b52a7d8b2d8db\",\"venue\":\"2017 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145196759\",\"name\":\"Chenqiang Gao\"},{\"authorId\":\"2040199\",\"name\":\"Yinhe Du\"},{\"authorId\":\"40035911\",\"name\":\"J. Liu\"},{\"authorId\":\"145584603\",\"name\":\"J. Lv\"},{\"authorId\":\"2858139\",\"name\":\"L. Yang\"},{\"authorId\":\"1803714\",\"name\":\"D. Meng\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1016/j.neucom.2016.05.094\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2e54c4d86e9801af1663265c0e42938358e8eb13\",\"title\":\"InfAR dataset: Infrared action recognition at different times\",\"url\":\"https://www.semanticscholar.org/paper/2e54c4d86e9801af1663265c0e42938358e8eb13\",\"venue\":\"Neurocomputing\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1808862\",\"name\":\"S. Shankar\"},{\"authorId\":\"1764249\",\"name\":\"Joan Lasenby\"},{\"authorId\":\"32747148\",\"name\":\"A. Kokaram\"}],\"doi\":\"10.1145/2534008.2534017\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3a32aa2a5f54bec6524e95216ce99950102ff106\",\"title\":\"Synchronization of user-generated videos through trajectory correspondence and a refinement procedure\",\"url\":\"https://www.semanticscholar.org/paper/3a32aa2a5f54bec6524e95216ce99950102ff106\",\"venue\":\"CVMP '13\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2274625\",\"name\":\"Do Hang Nga\"},{\"authorId\":\"1681659\",\"name\":\"K. Yanai\"}],\"doi\":\"10.1587/TRANSINF.2014EDP7106\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bdad978bcb8f854fa595eea00960a9bde9866887\",\"title\":\"VisualTextualRank: An Extension of VisualRank to Large-Scale Video Shot Extraction Exploiting Tag Co-occurrence\",\"url\":\"https://www.semanticscholar.org/paper/bdad978bcb8f854fa595eea00960a9bde9866887\",\"venue\":\"IEICE Trans. Inf. Syst.\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145143348\",\"name\":\"O. V. R. Murthy\"},{\"authorId\":\"144380582\",\"name\":\"I. Radwan\"},{\"authorId\":\"1735697\",\"name\":\"Abhinav Dhall\"},{\"authorId\":\"1717204\",\"name\":\"R. Goecke\"}],\"doi\":\"10.1109/DICTA.2013.6691507\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"118c8bcbf52fbe15b38b67ef3f30839aa7faf2f4\",\"title\":\"On the Effect of Human Body Parts in Large Scale Human Behaviour Recognition\",\"url\":\"https://www.semanticscholar.org/paper/118c8bcbf52fbe15b38b67ef3f30839aa7faf2f4\",\"venue\":\"2013 International Conference on Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144756917\",\"name\":\"Shih-Wei Sun\"},{\"authorId\":\"2436996\",\"name\":\"Ting-Chen Mou\"},{\"authorId\":\"65927375\",\"name\":\"Chih-Chieh Fang\"},{\"authorId\":\"145456212\",\"name\":\"P. Chang\"},{\"authorId\":\"145525478\",\"name\":\"K. Hua\"},{\"authorId\":\"1804838\",\"name\":\"H. Shih\"}],\"doi\":\"10.3390/s19061425\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf9eafe88e4e6141ffb229499defd4dde79f7101\",\"title\":\"Baseball Player Behavior Classification System Using Long Short-Term Memory with Multimodal Features\",\"url\":\"https://www.semanticscholar.org/paper/cf9eafe88e4e6141ffb229499defd4dde79f7101\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1754854\",\"name\":\"Venice Erin Liong\"},{\"authorId\":\"1697700\",\"name\":\"Jiwen Lu\"},{\"authorId\":\"1689805\",\"name\":\"Y. Tan\"},{\"authorId\":\"49640256\",\"name\":\"J. Zhou\"}],\"doi\":\"10.1109/TMM.2016.2645404\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9e32c482f2ba4cdfe321aa8eea7ff11679679cdc\",\"title\":\"Deep Video Hashing\",\"url\":\"https://www.semanticscholar.org/paper/9e32c482f2ba4cdfe321aa8eea7ff11679679cdc\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2017},{\"arxivId\":\"1511.05045\",\"authors\":[{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"143642520\",\"name\":\"Shoou-I Yu\"},{\"authorId\":\"144247571\",\"name\":\"Ming Lin\"},{\"authorId\":\"1681921\",\"name\":\"B. Raj\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"839a2155995acc0a053a326e283be12068b35cb8\",\"title\":\"Handcrafted Local Features are Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/839a2155995acc0a053a326e283be12068b35cb8\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2948199\",\"name\":\"Eyrun Eyjolfsdottir\"},{\"authorId\":\"3251767\",\"name\":\"S. Branson\"},{\"authorId\":\"1403267733\",\"name\":\"X. Burgos-Artizzu\"},{\"authorId\":\"2954028\",\"name\":\"Eric D. Hoopfer\"},{\"authorId\":\"50356514\",\"name\":\"J. Schor\"},{\"authorId\":\"97650051\",\"name\":\"D. J. Anderson\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"}],\"doi\":\"10.1007/978-3-319-10605-2_50\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"14070478b8f0d84e5597c3e67c30af91b5c3a917\",\"title\":\"Detecting Social Actions of Fruit Flies\",\"url\":\"https://www.semanticscholar.org/paper/14070478b8f0d84e5597c3e67c30af91b5c3a917\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3095774\",\"name\":\"Dan Oneata\"},{\"authorId\":\"1721683\",\"name\":\"J. Verbeek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2013.228\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"08e61adbfa2178e3fa895a7f85a84597c183aede\",\"title\":\"Action and Event Recognition with Fisher Vectors on a Compact Feature Set\",\"url\":\"https://www.semanticscholar.org/paper/08e61adbfa2178e3fa895a7f85a84597c183aede\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":\"1710.05112\",\"authors\":[{\"authorId\":\"33998511\",\"name\":\"Aaron Chadha\"},{\"authorId\":\"2822935\",\"name\":\"Alhabib Abbas\"},{\"authorId\":\"2747620\",\"name\":\"Y. Andreopoulos\"}],\"doi\":\"10.1109/TCSVT.2017.2786999\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ea9e5fcdac51328a99e88f14b194abb933bd81b3\",\"title\":\"Video Classification With CNNs: Using the Codec as a Spatio-Temporal Activity Sensor\",\"url\":\"https://www.semanticscholar.org/paper/ea9e5fcdac51328a99e88f14b194abb933bd81b3\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":\"2008.07819\",\"authors\":[{\"authorId\":\"72831997\",\"name\":\"T. Ma\"},{\"authorId\":\"101160956\",\"name\":\"L. Zhang\"},{\"authorId\":\"87641774\",\"name\":\"X. Diao\"},{\"authorId\":\"1411075691\",\"name\":\"O. Ma\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1c6a82bcb60db6f0b131e270e4ffb8b84bc01c6e\",\"title\":\"ConvGRU in Fine-grained Pitching Action Recognition for Action Outcome Prediction\",\"url\":\"https://www.semanticscholar.org/paper/1c6a82bcb60db6f0b131e270e4ffb8b84bc01c6e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1510.04565\",\"authors\":[{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"229521d21f0468a9c60a7da2a91a8265a40a53d1\",\"title\":\"Beyond Spatial Pyramid Matching: Space-time Extended Descriptor for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/229521d21f0468a9c60a7da2a91a8265a40a53d1\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1709.03655\",\"authors\":[{\"authorId\":\"1696573\",\"name\":\"Jiagang Zhu\"},{\"authorId\":\"145251501\",\"name\":\"W. Zou\"},{\"authorId\":\"144168342\",\"name\":\"Zheng Zhu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e19ebad4739d59f999d192bac7d596b20b887f78\",\"title\":\"Learning Gating ConvNet for Two-Stream based Methods in Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e19ebad4739d59f999d192bac7d596b20b887f78\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1611.05216\",\"authors\":[{\"authorId\":\"38179026\",\"name\":\"Y. Shi\"},{\"authorId\":\"40161651\",\"name\":\"Yonghong Tian\"},{\"authorId\":\"5765799\",\"name\":\"Yaowei Wang\"},{\"authorId\":\"144424248\",\"name\":\"Wei Zeng\"},{\"authorId\":\"34097174\",\"name\":\"Tiejun Huang\"}],\"doi\":\"10.1109/ICCV.2017.84\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d145edb79ec035d6cf3f50714429f51fb18f0a2f\",\"title\":\"Learning Long-Term Dependencies for Action Recognition with a Biologically-Inspired Deep Network\",\"url\":\"https://www.semanticscholar.org/paper/d145edb79ec035d6cf3f50714429f51fb18f0a2f\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1404304087\",\"name\":\"Salah Al-Obaidi\"},{\"authorId\":\"2034275779\",\"name\":\"Hiba Al-Khafaji\"},{\"authorId\":\"74338570\",\"name\":\"Charith Abhayaratne\"}],\"doi\":\"10.1109/ACCESS.2020.3039740\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"9edf2c2a48a07a077e54f719eb2d0820dbda76ab\",\"title\":\"Modeling Temporal Visual Salience for Human Action Recognition Enabled Visual Anonymity Preservation\",\"url\":\"https://www.semanticscholar.org/paper/9edf2c2a48a07a077e54f719eb2d0820dbda76ab\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2003.02692\",\"authors\":[{\"authorId\":\"12888106\",\"name\":\"H. Cho\"},{\"authorId\":\"40152520\",\"name\":\"Tae-Hoon Kim\"},{\"authorId\":\"145917158\",\"name\":\"H. J. Chang\"},{\"authorId\":\"34600044\",\"name\":\"Wonjun Hwang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"90e185b5011a11fba9dea8db9136e4048b3728ec\",\"title\":\"Self-Supervised Spatio-Temporal Representation Learning Using Variable Playback Speed Prediction\",\"url\":\"https://www.semanticscholar.org/paper/90e185b5011a11fba9dea8db9136e4048b3728ec\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2001.05857\",\"authors\":[{\"authorId\":\"35005950\",\"name\":\"Ethem F. Can\"},{\"authorId\":\"1404629819\",\"name\":\"Aysu Ezen-Can\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6ebc479d685b92b2be9fb045bc7bb4d4eef3b698\",\"title\":\"The Effect of Data Ordering in Image Classification\",\"url\":\"https://www.semanticscholar.org/paper/6ebc479d685b92b2be9fb045bc7bb4d4eef3b698\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11438057\",\"name\":\"H. Bouma\"},{\"authorId\":\"145445122\",\"name\":\"J. Baan\"},{\"authorId\":\"133982738\",\"name\":\"Frank B. ter Haar\"},{\"authorId\":\"1889881\",\"name\":\"P. Eendebak\"},{\"authorId\":\"134632765\",\"name\":\"R. D. den Hollander\"},{\"authorId\":\"1909303\",\"name\":\"G. Burghouts\"},{\"authorId\":\"144502717\",\"name\":\"R. Wijn\"},{\"authorId\":\"134767384\",\"name\":\"Sebastiaan P. van den Broek\"},{\"authorId\":\"134228379\",\"name\":\"Jeroen H. C. van Rest\"}],\"doi\":\"10.1117/12.2194436\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c32a94283945cd467b91cfbbe04b265a974447e8\",\"title\":\"Video content analysis on body-worn cameras for retrospective investigation\",\"url\":\"https://www.semanticscholar.org/paper/c32a94283945cd467b91cfbbe04b265a974447e8\",\"venue\":\"SPIE Security + Defence\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2838450\",\"name\":\"Baixiang Fan\"},{\"authorId\":\"1732242\",\"name\":\"Y. Liu\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"}],\"doi\":\"10.1145/2808492.2808500\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c244c3c797574048d6931b6714ebac64d820dbb3\",\"title\":\"Exploiting the locality information of dense trajectory feature for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/c244c3c797574048d6931b6714ebac64d820dbb3\",\"venue\":\"ICIMCS '15\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"114498698\",\"name\":\"Ankush Manocha\"},{\"authorId\":\"50631862\",\"name\":\"R. Singh\"}],\"doi\":\"10.1007/s11042-019-7700-7\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"ad6493b57050955d9686b3c1fc84a19195852f8c\",\"title\":\"Computer vision based working environment monitoring to analyze Generalized Anxiety Disorder (GAD)\",\"url\":\"https://www.semanticscholar.org/paper/ad6493b57050955d9686b3c1fc84a19195852f8c\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":\"1910.13888\",\"authors\":[{\"authorId\":\"3040310\",\"name\":\"Y. Jiang\"},{\"authorId\":\"1389284356\",\"name\":\"Kaixu Cui\"},{\"authorId\":\"144690387\",\"name\":\"B. Peng\"},{\"authorId\":\"48258796\",\"name\":\"C. Xu\"}],\"doi\":\"10.1109/ICCVW.2019.00195\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"126d93fb45ee6e4d9af314981e8430aa5b2f24c1\",\"title\":\"Comprehensive Video Understanding: Video Summarization with Content-Based Video Recommender Design\",\"url\":\"https://www.semanticscholar.org/paper/126d93fb45ee6e4d9af314981e8430aa5b2f24c1\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"144746444\",\"name\":\"H. Bischof\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"},{\"authorId\":\"40454588\",\"name\":\"J. Frahm\"}],\"doi\":\"10.1007/978-3-030-58539-6\",\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"72eb837c0d113dcdd51e57958e58d48e1759ea0f\",\"title\":\"Computer Vision \\u2013 ECCV 2020: 16th European Conference, Glasgow, UK, August 23\\u201328, 2020, Proceedings, Part VI\",\"url\":\"https://www.semanticscholar.org/paper/72eb837c0d113dcdd51e57958e58d48e1759ea0f\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1732108\",\"name\":\"Weifeng Liu\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"7707388\",\"name\":\"Yanjiang Wang\"},{\"authorId\":\"144106250\",\"name\":\"K. Lu\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/TIE.2016.2552147\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4b15cc203b9e34cfce993edb034f4e0eded32e75\",\"title\":\"$p$-Laplacian Regularized Sparse Coding for Human Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4b15cc203b9e34cfce993edb034f4e0eded32e75\",\"venue\":\"IEEE Transactions on Industrial Electronics\",\"year\":2016},{\"arxivId\":\"1604.07669\",\"authors\":[{\"authorId\":\"3047890\",\"name\":\"Bowen Zhang\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"}],\"doi\":\"10.1109/CVPR.2016.297\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d4cf68fad61cd7dc9061670ba3864a7fdf87d4c\",\"title\":\"Real-Time Action Recognition with Enhanced Motion Vector CNNs\",\"url\":\"https://www.semanticscholar.org/paper/3d4cf68fad61cd7dc9061670ba3864a7fdf87d4c\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145327729\",\"name\":\"Feng Shi\"},{\"authorId\":\"2035718\",\"name\":\"R. Lagani\\u00e8re\"},{\"authorId\":\"1745632\",\"name\":\"E. Petriu\"}],\"doi\":\"10.1016/j.imavis.2015.11.010\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6061b8b96266302af429fcd6a0d227897e65bdff\",\"title\":\"Local part model for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/6061b8b96266302af429fcd6a0d227897e65bdff\",\"venue\":\"Image Vis. Comput.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1727419\",\"name\":\"Zhigang Ma\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1145/2647868.2654907\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d14c1bf8ce40212336c41db66ebbd1ec2d9d6deb\",\"title\":\"Multiple Features But Few Labels?: A Symbiotic Solution Exemplified for Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/d14c1bf8ce40212336c41db66ebbd1ec2d9d6deb\",\"venue\":\"ACM Multimedia\",\"year\":2014},{\"arxivId\":\"1409.4842\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"46641766\",\"name\":\"W. Liu\"},{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"},{\"authorId\":\"48840704\",\"name\":\"Scott Reed\"},{\"authorId\":\"1838674\",\"name\":\"Dragomir Anguelov\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"39863668\",\"name\":\"Andrew Rabinovich\"}],\"doi\":\"10.1109/CVPR.2015.7298594\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"title\":\"Going deeper with convolutions\",\"url\":\"https://www.semanticscholar.org/paper/e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50762746\",\"name\":\"Jun Chen\"},{\"authorId\":\"13849852\",\"name\":\"Yuan-ping Xu\"},{\"authorId\":\"9372837\",\"name\":\"Chao-long Zhang\"},{\"authorId\":\"50070258\",\"name\":\"Zhijie Xu\"},{\"authorId\":\"89978385\",\"name\":\"Xiangxiang Meng\"},{\"authorId\":\"97773646\",\"name\":\"J. Wang\"}],\"doi\":\"10.23919/IConAC.2019.8894962\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"841ae506fbd745273cd3498c923088a5736f42d1\",\"title\":\"An Improved Two-stream 3D Convolutional Neural Network for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/841ae506fbd745273cd3498c923088a5736f42d1\",\"venue\":\"2019 25th International Conference on Automation and Computing (ICAC)\",\"year\":2019},{\"arxivId\":\"1904.11407\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"}],\"doi\":\"10.1109/ICCV.2019.00629\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"296bce85d5a844caa63ab41a96898fd8559e4bb0\",\"title\":\"DynamoNet: Dynamic Action and Motion Network\",\"url\":\"https://www.semanticscholar.org/paper/296bce85d5a844caa63ab41a96898fd8559e4bb0\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3422195\",\"name\":\"S. Chaudhary\"},{\"authorId\":\"1827383\",\"name\":\"S. Murala\"}],\"doi\":\"10.1016/J.NEUCOM.2019.08.031\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"66cdde8d08733b4d9840089f8af07f042749675f\",\"title\":\"Deep network for human action recognition using Weber motion\",\"url\":\"https://www.semanticscholar.org/paper/66cdde8d08733b4d9840089f8af07f042749675f\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"148380935\",\"name\":\"Yousef Alsahafi\"},{\"authorId\":\"41036347\",\"name\":\"Daniel Lemmond\"},{\"authorId\":\"6439443\",\"name\":\"J. Ventura\"},{\"authorId\":\"32163276\",\"name\":\"T. Boult\"}],\"doi\":\"10.1007/978-3-030-14070-0_63\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"549c4bf876da0a568e6492c62015ad46315e4bbc\",\"title\":\"CarVideos: A Novel Dataset for Fine-Grained Car Classification in Videos\",\"url\":\"https://www.semanticscholar.org/paper/549c4bf876da0a568e6492c62015ad46315e4bbc\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2037859\",\"name\":\"Saddam Bekhet\"},{\"authorId\":\"143629707\",\"name\":\"Amr Ahmed\"}],\"doi\":\"10.1145/3190784\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"43c3b6a564b284382fdf8ae33f974f4e7a89600e\",\"title\":\"An Integrated Signature-Based Framework for Efficient Visual Similarity Detection and Measurement in Video Shots\",\"url\":\"https://www.semanticscholar.org/paper/43c3b6a564b284382fdf8ae33f974f4e7a89600e\",\"venue\":\"ACM Trans. Inf. Syst.\",\"year\":2018},{\"arxivId\":\"1807.10037\",\"authors\":[{\"authorId\":\"2647624\",\"name\":\"Myunggi Lee\"},{\"authorId\":\"51151436\",\"name\":\"Seungeui Lee\"},{\"authorId\":\"9044475\",\"name\":\"Sung Joon Son\"},{\"authorId\":\"51136389\",\"name\":\"G. Park\"},{\"authorId\":\"3160425\",\"name\":\"N. Kwak\"}],\"doi\":\"10.1007/978-3-030-01249-6_24\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10a1dcbe52547146fa4735274e8c89ae01e70a55\",\"title\":\"Motion Feature Network: Fixed Motion Filter for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/10a1dcbe52547146fa4735274e8c89ae01e70a55\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39974958\",\"name\":\"T. Yu\"},{\"authorId\":\"1909131\",\"name\":\"Huxiang Gu\"},{\"authorId\":\"46660013\",\"name\":\"L. Wang\"},{\"authorId\":\"1683738\",\"name\":\"S. Xiang\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.1109/ICIP.2017.8296542\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a9756ca629f73dc8f84ee97cfa8b34b8207392dc\",\"title\":\"Cascaded temporal spatial features for video action recognition\",\"url\":\"https://www.semanticscholar.org/paper/a9756ca629f73dc8f84ee97cfa8b34b8207392dc\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":\"1909.05667\",\"authors\":[{\"authorId\":\"151473559\",\"name\":\"Liam Hiley\"},{\"authorId\":\"144978811\",\"name\":\"A. Preece\"},{\"authorId\":\"2256975\",\"name\":\"Y. Hicks\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c138499d43e3e2d4e2cf9e498d984fe2632d7d03\",\"title\":\"Explainable Deep Learning for Video Recognition Tasks: A Framework & Recommendations\",\"url\":\"https://www.semanticscholar.org/paper/c138499d43e3e2d4e2cf9e498d984fe2632d7d03\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2011.07807\",\"authors\":[{\"authorId\":\"1782000465\",\"name\":\"Aftab Alam\"},{\"authorId\":\"51453868\",\"name\":\"Irfan Ullah\"},{\"authorId\":\"2806926\",\"name\":\"Young-Koo Lee\"}],\"doi\":\"10.1109/ACCESS.2020.3017135\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9faf9029981a0b92abdb983a60f2af96eca3aea2\",\"title\":\"Video Big Data Analytics in the Cloud: A Reference Architecture, Survey, Opportunities, and Open Research Issues\",\"url\":\"https://www.semanticscholar.org/paper/9faf9029981a0b92abdb983a60f2af96eca3aea2\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2003.04298\",\"authors\":[{\"authorId\":\"1379929116\",\"name\":\"Mandela Patrick\"},{\"authorId\":\"47792365\",\"name\":\"Y. Asano\"},{\"authorId\":\"145891577\",\"name\":\"Ruth Fong\"},{\"authorId\":\"143848064\",\"name\":\"Jo\\u00e3o F. Henriques\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"8ddbaa34c574124a91fa3bc217e232e17668e84c\",\"title\":\"Multi-modal Self-Supervision from Generalized Data Transformations\",\"url\":\"https://www.semanticscholar.org/paper/8ddbaa34c574124a91fa3bc217e232e17668e84c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.06977\",\"authors\":[{\"authorId\":\"47203405\",\"name\":\"Wenhao Wu\"},{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"6873935\",\"name\":\"T. Lin\"},{\"authorId\":\"1998948807\",\"name\":\"F. Li\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"12081764\",\"name\":\"E. Ding\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"07e0fd1487b8b31d6641c66f67f20e4659e5848e\",\"title\":\"MVFNet: Multi-View Fusion Network for Efficient Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/07e0fd1487b8b31d6641c66f67f20e4659e5848e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7560130\",\"name\":\"L. Zhang\"},{\"authorId\":\"2238957\",\"name\":\"Xuezhi Xiang\"}],\"doi\":\"10.1007/s11042-019-08457-5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c5dc58c7e4158220dbe9157fe1f803e07cf0d40a\",\"title\":\"Video event classification based on two-stage neural network\",\"url\":\"https://www.semanticscholar.org/paper/c5dc58c7e4158220dbe9157fe1f803e07cf0d40a\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"1912.00869\",\"authors\":[{\"authorId\":\"33421444\",\"name\":\"Quanfu Fan\"},{\"authorId\":\"48239920\",\"name\":\"Chun-Fu Chen\"},{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"134455051\",\"name\":\"Marco Pistoia\"},{\"authorId\":\"66305116\",\"name\":\"D. Cox\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9c77ffc223e47388155a6e3bf58ae294f51f9ccb\",\"title\":\"More Is Less: Learning Efficient Video Representations by Big-Little Network and Depthwise Temporal Aggregation\",\"url\":\"https://www.semanticscholar.org/paper/9c77ffc223e47388155a6e3bf58ae294f51f9ccb\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145327729\",\"name\":\"Feng Shi\"},{\"authorId\":\"2035718\",\"name\":\"R. Lagani\\u00e8re\"},{\"authorId\":\"1745632\",\"name\":\"E. Petriu\"},{\"authorId\":null,\"name\":\"Haiyu Zhen\"},{\"authorId\":\"145901386\",\"name\":\"H. Zhong\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a3f684930c5c45fcb56a2b407d26b63879120cbf\",\"title\":\"LPM for Fast Action Recognition with Large Number of Classes\",\"url\":\"https://www.semanticscholar.org/paper/a3f684930c5c45fcb56a2b407d26b63879120cbf\",\"venue\":\"\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403813423\",\"name\":\"Carolina Redondo-Cabrera\"},{\"authorId\":\"1402973336\",\"name\":\"R. L\\u00f3pez-Sastre\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b9f2a755940353549e55690437eb7e13ea226bbf\",\"title\":\"Unsupervised Feature Learning from Videos for Discovering and Recognizing Actions\",\"url\":\"https://www.semanticscholar.org/paper/b9f2a755940353549e55690437eb7e13ea226bbf\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50754085\",\"name\":\"Kunpeng Li\"},{\"authorId\":\"49479171\",\"name\":\"Chen Fang\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"2047181\",\"name\":\"Seokhwan Kim\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"144015161\",\"name\":\"Y. Fu\"}],\"doi\":\"10.1109/cvpr42600.2020.01254\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b1a780c6219996c8481c117056efcf071cbfbd15\",\"title\":\"Screencast Tutorial Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/b1a780c6219996c8481c117056efcf071cbfbd15\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2003.08350\",\"authors\":[{\"authorId\":\"3079231\",\"name\":\"Junye Wen\"},{\"authorId\":\"71797164\",\"name\":\"M. Khan\"},{\"authorId\":\"98335788\",\"name\":\"M. Che\"},{\"authorId\":null,\"name\":\"Yan Yan\"},{\"authorId\":\"47124958\",\"name\":\"Guowei Yang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ee14ade0fac82ef839b30832aa02ee7ca5976d6f\",\"title\":\"Constraint Solving with Deep Learning for Symbolic Execution\",\"url\":\"https://www.semanticscholar.org/paper/ee14ade0fac82ef839b30832aa02ee7ca5976d6f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145839689\",\"name\":\"S. Jones\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"}],\"doi\":\"10.1007/978-3-642-40261-6_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fa29041cda6ab76aacd50c18a25025036045bc2e\",\"title\":\"Rapid Localisation and Retrieval of Human Actions with Relevance Feedback\",\"url\":\"https://www.semanticscholar.org/paper/fa29041cda6ab76aacd50c18a25025036045bc2e\",\"venue\":\"CAIP\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"3237649\",\"name\":\"P. Stanitsas\"},{\"authorId\":\"23911916\",\"name\":\"Mehrtash Harandi\"},{\"authorId\":\"1827707\",\"name\":\"V. Morellas\"},{\"authorId\":\"1696163\",\"name\":\"N. Papanikolopoulos\"}],\"doi\":\"10.1109/ICCV.2017.458\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"820b68614b01794aeb3b4b1254d1e85610b1473c\",\"title\":\"Learning Discriminative \\u03b1\\u03b2-Divergences for Positive Definite Matrices\",\"url\":\"https://www.semanticscholar.org/paper/820b68614b01794aeb3b4b1254d1e85610b1473c\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1605.03324\",\"authors\":[{\"authorId\":\"3114252\",\"name\":\"O. Sener\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"2484982\",\"name\":\"Chenxia Wu\"},{\"authorId\":\"1702137\",\"name\":\"S. Savarese\"},{\"authorId\":\"1681995\",\"name\":\"A. Saxena\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fcbf808bdf140442cddf0710defb2766c2d25c30\",\"title\":\"Unsupervised Semantic Action Discovery from Video Collections\",\"url\":\"https://www.semanticscholar.org/paper/fcbf808bdf140442cddf0710defb2766c2d25c30\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1803.08094\",\"authors\":[{\"authorId\":\"144487556\",\"name\":\"Madan Ravi Ganesh\"},{\"authorId\":\"24337238\",\"name\":\"E. Hofesmann\"},{\"authorId\":\"40893359\",\"name\":\"Byungsu Min\"},{\"authorId\":\"40893002\",\"name\":\"Nadha Gafoor\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7f52b5bbc2678d3bebef7e00e281d5ccdbac9f4b\",\"title\":\"T-RECS: Training for Rate-Invariant Embeddings by Controlling Speed for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7f52b5bbc2678d3bebef7e00e281d5ccdbac9f4b\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3200255\",\"name\":\"Manel Sekma\"},{\"authorId\":\"2769143\",\"name\":\"M. Mejdoub\"},{\"authorId\":\"3410172\",\"name\":\"C. Amar\"}],\"doi\":\"10.1109/ISDA.2015.7489193\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"aace2501e5cb80de84a64d1ce402502034b40777\",\"title\":\"Structured Fisher vector encoding method for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/aace2501e5cb80de84a64d1ce402502034b40777\",\"venue\":\"2015 15th International Conference on Intelligent Systems Design and Applications (ISDA)\",\"year\":2015},{\"arxivId\":\"1801.09086\",\"authors\":[{\"authorId\":\"48303900\",\"name\":\"Ashish Mishra\"},{\"authorId\":\"153610266\",\"name\":\"V. Verma\"},{\"authorId\":\"144109388\",\"name\":\"M. K. Reddy\"},{\"authorId\":\"7598442\",\"name\":\"Arulkumar Subramaniam\"},{\"authorId\":\"145593549\",\"name\":\"P. Rai\"},{\"authorId\":\"50853059\",\"name\":\"Anurag Mittal\"}],\"doi\":\"10.1109/WACV.2018.00047\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"46242b2f1ba03f2625380fbc143cd854b9333e7f\",\"title\":\"A Generative Approach to Zero-Shot and Few-Shot Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/46242b2f1ba03f2625380fbc143cd854b9333e7f\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3200255\",\"name\":\"Manel Sekma\"},{\"authorId\":\"2769143\",\"name\":\"M. Mejdoub\"},{\"authorId\":\"3410172\",\"name\":\"C. Amar\"}],\"doi\":\"10.1016/j.patrec.2015.06.029\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"98212372180ca3826c74ac5d05a600cc20210ec3\",\"title\":\"Human action recognition based on multi-layer Fisher vector encoding method\",\"url\":\"https://www.semanticscholar.org/paper/98212372180ca3826c74ac5d05a600cc20210ec3\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49455479\",\"name\":\"Y. Zhou\"},{\"authorId\":\"6485172\",\"name\":\"Xiaoyan Sun\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cb2917413c9b36c3bb9739bce6c03a1a6eb619b3\",\"title\":\"MiCT : Mixed 3 D / 2 D Convolutional Tube for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cb2917413c9b36c3bb9739bce6c03a1a6eb619b3\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46967595\",\"name\":\"Arshad Jamal\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"},{\"authorId\":\"2064509\",\"name\":\"Dipti Deodhare\"},{\"authorId\":\"50274088\",\"name\":\"K. Venkatesh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c002950de90af087d00b21581d720fc0c79d4ac1\",\"title\":\"Supplementary Material : Deep Domain Adaptation in Action Space\",\"url\":\"https://www.semanticscholar.org/paper/c002950de90af087d00b21581d720fc0c79d4ac1\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1801.03983\",\"authors\":[{\"authorId\":\"143847408\",\"name\":\"Mingze Xu\"},{\"authorId\":\"3377097\",\"name\":\"A. Sharghi\"},{\"authorId\":\"46772058\",\"name\":\"X. Chen\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"}],\"doi\":\"10.1109/WACV.2018.00178\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"58d496268f22d8cd35fbe7fa27919b80d84d9aa9\",\"title\":\"Fully-Coupled Two-Stream Spatiotemporal Networks for Extremely Low Resolution Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/58d496268f22d8cd35fbe7fa27919b80d84d9aa9\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2068393\",\"name\":\"Xiusheng Lu\"},{\"authorId\":\"1720100\",\"name\":\"H. Yao\"},{\"authorId\":\"144783274\",\"name\":\"X. Sun\"},{\"authorId\":\"1793532\",\"name\":\"Y. Zhang\"}],\"doi\":\"10.1007/s11760-017-1161-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ef7a0197e3c08de01fbf33fa6425bee602e60cd5\",\"title\":\"Locally aggregated histogram-based descriptors\",\"url\":\"https://www.semanticscholar.org/paper/ef7a0197e3c08de01fbf33fa6425bee602e60cd5\",\"venue\":\"Signal Image Video Process.\",\"year\":2018},{\"arxivId\":\"1707.01786\",\"authors\":[{\"authorId\":\"3104845\",\"name\":\"Yinchong Yang\"},{\"authorId\":\"2614774\",\"name\":\"Denis Krompass\"},{\"authorId\":\"1700754\",\"name\":\"Volker Tresp\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2db62ac8bc735133f746cc10439f419abf3b3a2c\",\"title\":\"Tensor-Train Recurrent Neural Networks for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/2db62ac8bc735133f746cc10439f419abf3b3a2c\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3347447\",\"name\":\"Sanath Narayan\"},{\"authorId\":\"145986798\",\"name\":\"K. Ramakrishnan\"}],\"doi\":\"10.1109/CVPR.2014.337\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7fcead8c3b491076165f6c5168eaa147dcc550f2\",\"title\":\"A Cause and Effect Analysis of Motion Trajectories for Modeling Actions\",\"url\":\"https://www.semanticscholar.org/paper/7fcead8c3b491076165f6c5168eaa147dcc550f2\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143985656\",\"name\":\"Manuel Martin\"},{\"authorId\":\"33390229\",\"name\":\"Alina Roitberg\"},{\"authorId\":\"67310661\",\"name\":\"Monica Haurilet\"},{\"authorId\":\"37255582\",\"name\":\"M. Horne\"},{\"authorId\":\"1845905584\",\"name\":\"Simon Rei\\u00df\"},{\"authorId\":\"145265390\",\"name\":\"M. Voit\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"}],\"doi\":\"10.1109/ICCV.2019.00289\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"5f6dd9cdbf3419c6bd2ad670f0ff2a3419e384d6\",\"title\":\"Drive&Act: A Multi-Modal Dataset for Fine-Grained Driver Behavior Recognition in Autonomous Vehicles\",\"url\":\"https://www.semanticscholar.org/paper/5f6dd9cdbf3419c6bd2ad670f0ff2a3419e384d6\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"35031371\",\"name\":\"Wenbin Du\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1109/CVPRW.2015.7301330\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5dc7693733fc72b20955d0154c0223955056fd2c\",\"title\":\"Exploring Fisher vector and deep networks for action spotting\",\"url\":\"https://www.semanticscholar.org/paper/5dc7693733fc72b20955d0154c0223955056fd2c\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38932510\",\"name\":\"J. Matas\"},{\"authorId\":\"34788950\",\"name\":\"N. Sebe\"},{\"authorId\":\"144026434\",\"name\":\"M. Welling\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5eef65ed4a246a15fb1dd0a3816fef9c9988ee22\",\"title\":\"Spot On: Action Localization from Pointly-Supervised Proposals\",\"url\":\"https://www.semanticscholar.org/paper/5eef65ed4a246a15fb1dd0a3816fef9c9988ee22\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34798935\",\"name\":\"Xiantong Zhen\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"},{\"authorId\":\"144513293\",\"name\":\"Feng Zheng\"}],\"doi\":\"10.5244/C.28.33\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"adbdacd623befcb89d282e0abd078c3231895e2a\",\"title\":\"Discriminative Embedding via Image-to-Class Distances\",\"url\":\"https://www.semanticscholar.org/paper/adbdacd623befcb89d282e0abd078c3231895e2a\",\"venue\":\"BMVC\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2068393\",\"name\":\"Xiusheng Lu\"},{\"authorId\":\"1720100\",\"name\":\"H. Yao\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"1761159\",\"name\":\"S. Zhang\"},{\"authorId\":\"1793532\",\"name\":\"Y. Zhang\"}],\"doi\":\"10.1007/978-3-319-77380-3_24\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"994b9df5038a6457185e8408075b81e97f1ccafe\",\"title\":\"Trajectory-Pooled 3D Convolutional Descriptors for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/994b9df5038a6457185e8408075b81e97f1ccafe\",\"venue\":\"PCM\",\"year\":2017},{\"arxivId\":\"1803.08460\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"144325904\",\"name\":\"Yang Long\"},{\"authorId\":\"144537809\",\"name\":\"Yu Guan\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"}],\"doi\":\"10.1109/CVPR.2018.00983\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"30ca009c3988d96c4ef7671692f709e8100967f5\",\"title\":\"Towards Universal Representation for Unseen Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/30ca009c3988d96c4ef7671692f709e8100967f5\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410772490\",\"name\":\"R. Ogata\"},{\"authorId\":\"1398077025\",\"name\":\"Edgar Simo-Serra\"},{\"authorId\":\"150298109\",\"name\":\"Satoshi Iizuka\"},{\"authorId\":\"66193516\",\"name\":\"H. Ishikawa\"}],\"doi\":\"10.1109/CVPRW.2019.00309\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"de7cbc5737177ff89913a916e9bd6417836f520e\",\"title\":\"Temporal Distance Matrices for Squat Classification\",\"url\":\"https://www.semanticscholar.org/paper/de7cbc5737177ff89913a916e9bd6417836f520e\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3105254\",\"name\":\"Yuancheng Ye\"},{\"authorId\":\"35484757\",\"name\":\"Yingli Tian\"}],\"doi\":\"10.1109/CVPRW.2016.142\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5f351e99da70625f2011b0dccd131a5e50aa8644\",\"title\":\"Embedding Sequential Information into Spatiotemporal Features for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5f351e99da70625f2011b0dccd131a5e50aa8644\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2016},{\"arxivId\":\"1803.07218\",\"authors\":[{\"authorId\":\"46793780\",\"name\":\"Ximeng Sun\"},{\"authorId\":\"34246012\",\"name\":\"Ryan Szeto\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1007/978-3-030-20893-6_16\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"3819d2b6992be3e224e90371cc83bc5c60345e63\",\"title\":\"A Temporally-Aware Interpolation Network for Video Frame Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/3819d2b6992be3e224e90371cc83bc5c60345e63\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2563751\",\"name\":\"Y. Zhu\"},{\"authorId\":\"145015817\",\"name\":\"Gang Yu\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"},{\"authorId\":\"10212005\",\"name\":\"K. Ma\"}],\"doi\":\"10.1109/ICIP.2018.8451430\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a6badaa9bbd8e222a2f06389261e27c5a599df68\",\"title\":\"Selecting Informative Frames for Action Recognition with Partial Observations\",\"url\":\"https://www.semanticscholar.org/paper/a6badaa9bbd8e222a2f06389261e27c5a599df68\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":\"1908.05877\",\"authors\":[{\"authorId\":\"1735328\",\"name\":\"X. Xu\"},{\"authorId\":\"144784813\",\"name\":\"S. Gong\"},{\"authorId\":\"1697755\",\"name\":\"Timothy M. Hospedales\"}],\"doi\":\"10.1016/B978-0-12-809276-7.00018-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bb3a3e6ef2b0cdcc60d5de18bd3eee147500e9e3\",\"title\":\"Zero-Shot Crowd Behavior Recognition\",\"url\":\"https://www.semanticscholar.org/paper/bb3a3e6ef2b0cdcc60d5de18bd3eee147500e9e3\",\"venue\":\"Group and Crowd Behavior for Computer Vision\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2691929\",\"name\":\"Anoop Cherian\"},{\"authorId\":\"1980683\",\"name\":\"Shuchin Aeron\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b8c001c449cec20221ba3daa76536a124cddc0e5\",\"title\":\"Representation Learning via Adversarially-Contrastive Optimal Transport /Author=Cherian, Anoop; Aeron, Shuchin /CreationDate=July 3, 2020 /Subject=Artificial Intelligence, Computer Vision, Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/b8c001c449cec20221ba3daa76536a124cddc0e5\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3234247\",\"name\":\"Senthil Purushwalkam\"},{\"authorId\":\"145318111\",\"name\":\"Shiva Prakash\"},{\"authorId\":\"1737809\",\"name\":\"Abhinav Gupta\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9f4078773c8ea3f37951bf617dbce1d4b3795839\",\"title\":\"Leveraging Inexpensive Supervision Signals for Visual Learning\",\"url\":\"https://www.semanticscholar.org/paper/9f4078773c8ea3f37951bf617dbce1d4b3795839\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46236858\",\"name\":\"Daan Wynen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6ca9f025567e9a7eaae1449f95608acef6831450\",\"title\":\"Convolutional Kernel Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/6ca9f025567e9a7eaae1449f95608acef6831450\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1904.13072\",\"authors\":[{\"authorId\":\"49370704\",\"name\":\"Dong Wang\"},{\"authorId\":\"145377162\",\"name\":\"Y. Yuan\"},{\"authorId\":\"39669401\",\"name\":\"Q. Wang\"}],\"doi\":\"10.1109/ICASSP.2018.8461792\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ef9a4d76698ebb3cddd705b801a0739a6b06959b\",\"title\":\"Cross-Modal Message Passing for Two-Stream Fusion\",\"url\":\"https://www.semanticscholar.org/paper/ef9a4d76698ebb3cddd705b801a0739a6b06959b\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":\"1812.05770\",\"authors\":[{\"authorId\":\"1696573\",\"name\":\"Jiagang Zhu\"},{\"authorId\":\"145251501\",\"name\":\"W. Zou\"},{\"authorId\":\"47775885\",\"name\":\"Liang Xu\"},{\"authorId\":\"1736595\",\"name\":\"Yiming Hu\"},{\"authorId\":\"144168342\",\"name\":\"Zheng Zhu\"},{\"authorId\":\"143864262\",\"name\":\"Manyu Chang\"},{\"authorId\":null,\"name\":\"Junjie Huang\"},{\"authorId\":\"143986385\",\"name\":\"G. Huang\"},{\"authorId\":\"40359161\",\"name\":\"Dalong Du\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"38d0dd93755b83b2390815fda926866f7ec624ce\",\"title\":\"Action Machine: Rethinking Action Recognition in Trimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/38d0dd93755b83b2390815fda926866f7ec624ce\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145580092\",\"name\":\"Pierre-Etienne Martin\"},{\"authorId\":\"1406426904\",\"name\":\"J. Benois-Pineau\"},{\"authorId\":\"2236496\",\"name\":\"Boris Mansencal\"},{\"authorId\":\"1639895183\",\"name\":\"Renaud P\\u00e9teri\"},{\"authorId\":\"3027952\",\"name\":\"L. Mascarilla\"},{\"authorId\":\"1959267293\",\"name\":\"Jordan Calandre\"},{\"authorId\":\"1639983772\",\"name\":\"Julien Morlier\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0c1a0739b37b2ee0bab8e2281a13d29e60de6332\",\"title\":\"Sports Video Annotation: Detection of Strokes in Table Tennis Task for MediaEval 2019\",\"url\":\"https://www.semanticscholar.org/paper/0c1a0739b37b2ee0bab8e2281a13d29e60de6332\",\"venue\":\"MediaEval\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"},{\"authorId\":\"144119773\",\"name\":\"Kun Liu\"},{\"authorId\":\"144914140\",\"name\":\"H. Su\"},{\"authorId\":\"1744254\",\"name\":\"L. Guibas\"}],\"doi\":\"10.1109/CVPR.2018.00586\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"10befbb6c3f6183fe143830ac1479b7dcf119bae\",\"title\":\"Geometry Guided Convolutional Neural Networks for Self-Supervised Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/10befbb6c3f6183fe143830ac1479b7dcf119bae\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46329495\",\"name\":\"Amin Ullah\"},{\"authorId\":\"143997136\",\"name\":\"Khan Muhammad\"},{\"authorId\":\"29438845\",\"name\":\"I. Haq\"},{\"authorId\":\"1777998\",\"name\":\"S. Baik\"}],\"doi\":\"10.1016/J.FUTURE.2019.01.029\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c40639b5a2be2ac13e2c982348b45e92584ad9c0\",\"title\":\"Action recognition using optimized deep autoencoder and CNN for surveillance data streams of non-stationary environments\",\"url\":\"https://www.semanticscholar.org/paper/c40639b5a2be2ac13e2c982348b45e92584ad9c0\",\"venue\":\"Future Gener. Comput. Syst.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1899754\",\"name\":\"Mohammad Anvaripour\"},{\"authorId\":\"2462355\",\"name\":\"S. Alirezaee\"},{\"authorId\":\"145441739\",\"name\":\"M. Ahmadi\"},{\"authorId\":\"2994941\",\"name\":\"Sima Soltanpour\"}],\"doi\":\"10.1109/CCECE.2015.7129345\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2671c7c7d6193433e929a2e9399657141be38606\",\"title\":\"Moving objects tracking from most probable regions and eliminating camera motion\",\"url\":\"https://www.semanticscholar.org/paper/2671c7c7d6193433e929a2e9399657141be38606\",\"venue\":\"2015 IEEE 28th Canadian Conference on Electrical and Computer Engineering (CCECE)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24735756\",\"name\":\"Zhengkui Weng\"},{\"authorId\":\"40641593\",\"name\":\"Y. Guan\"}],\"doi\":\"10.1117/1.JEI.28.2.021004\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"42ae9506ead8b8b81729ea1ffa72a756ef71118d\",\"title\":\"Trajectory-aware three-stream CNN for video action recognition\",\"url\":\"https://www.semanticscholar.org/paper/42ae9506ead8b8b81729ea1ffa72a756ef71118d\",\"venue\":\"J. Electronic Imaging\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51031275\",\"name\":\"Ioannis Vernikos\"},{\"authorId\":\"50231158\",\"name\":\"Eirini Mathe\"},{\"authorId\":\"144116678\",\"name\":\"E. Spyrou\"},{\"authorId\":\"79441002\",\"name\":\"Alexandros Mitsou\"},{\"authorId\":\"41225110\",\"name\":\"Theodore Giannakopoulos\"},{\"authorId\":\"34050111\",\"name\":\"Ph. Mylonas\"}],\"doi\":\"10.1109/SMAP.2019.8864848\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"31bb2fdf583911a6098d5579d630150ad5876896\",\"title\":\"Fusing Handcrafted and Contextual Features for Human Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/31bb2fdf583911a6098d5579d630150ad5876896\",\"venue\":\"2019 14th International Workshop on Semantic and Social Media Adaptation and Personalization (SMAP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2724075\",\"name\":\"Yiping Tang\"},{\"authorId\":\"51431831\",\"name\":\"Chuang Niu\"},{\"authorId\":\"35182090\",\"name\":\"Minghao Dong\"},{\"authorId\":\"10648494\",\"name\":\"Shenghan Ren\"},{\"authorId\":\"145157018\",\"name\":\"J. Liang\"}],\"doi\":\"10.1007/978-3-030-31723-2_47\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0603f946c7613af4122ebd9cee6d10885f008501\",\"title\":\"Poleward Moving Aurora Recognition with Deep Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/0603f946c7613af4122ebd9cee6d10885f008501\",\"venue\":\"PRCV\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51187369\",\"name\":\"Lingxiao Dong\"},{\"authorId\":\"1764239\",\"name\":\"Dongmei Li\"},{\"authorId\":\"50341413\",\"name\":\"S. Li\"},{\"authorId\":\"27423107\",\"name\":\"Shanzhen Lan\"},{\"authorId\":\"49831019\",\"name\":\"Pengcheng Wang\"}],\"doi\":\"10.1117/12.2538431\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"b61283ec70f31422e1fa195e4e4f6ebf55896d33\",\"title\":\"Tai chi action recognition based on structural LSTM with attention module\",\"url\":\"https://www.semanticscholar.org/paper/b61283ec70f31422e1fa195e4e4f6ebf55896d33\",\"venue\":\"Other Conferences\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3450614\",\"name\":\"Feiwu Yu\"},{\"authorId\":\"2125709\",\"name\":\"Xinxiao Wu\"},{\"authorId\":\"10212142\",\"name\":\"Jialu Chen\"},{\"authorId\":\"2055900\",\"name\":\"Lixin Duan\"}],\"doi\":\"10.1109/TIP.2019.2917867\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"50e94e13947f3f2b7cc93379be88a9cab2b2d320\",\"title\":\"Exploiting Images for Video Recognition: Heterogeneous Feature Augmentation via Symmetric Adversarial Learning\",\"url\":\"https://www.semanticscholar.org/paper/50e94e13947f3f2b7cc93379be88a9cab2b2d320\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50999137\",\"name\":\"M. R. Souza\"},{\"authorId\":\"8125221\",\"name\":\"H. Maia\"},{\"authorId\":\"3052490\",\"name\":\"M. Vieira\"},{\"authorId\":\"1398585275\",\"name\":\"H. Pedrini\"}],\"doi\":\"10.1016/j.neucom.2020.04.035\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"609651891f7605789894397f7d5c6f78b6dba2df\",\"title\":\"Survey on visual rhythms: A spatio-temporal representation for video sequences\",\"url\":\"https://www.semanticscholar.org/paper/609651891f7605789894397f7d5c6f78b6dba2df\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92709220\",\"name\":\"Yao-Sen Chen\"},{\"authorId\":\"1455126232\",\"name\":\"Bing Guo\"},{\"authorId\":\"143736944\",\"name\":\"Yan Shen\"},{\"authorId\":\"115438571\",\"name\":\"W. Wang\"},{\"authorId\":\"1836290988\",\"name\":\"Xinhua Suo\"},{\"authorId\":\"1409738616\",\"name\":\"Zhang Zhen\"}],\"doi\":\"10.1007/s11760-020-01758-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0e47005fae57dfc1e4e3f3abcbd61a8d2cc9aead\",\"title\":\"Using efficient group pseudo-3D network to learn spatio-temporal features\",\"url\":\"https://www.semanticscholar.org/paper/0e47005fae57dfc1e4e3f3abcbd61a8d2cc9aead\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1411.6660\",\"authors\":[{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"144247571\",\"name\":\"Ming Lin\"},{\"authorId\":\"2314980\",\"name\":\"X. Li\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"},{\"authorId\":\"1681921\",\"name\":\"B. Raj\"}],\"doi\":\"10.1109/CVPR.2015.7298616\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"10af69f11301679b6fbb23855bf10f6af1f3d2e6\",\"title\":\"Beyond Gaussian Pyramid: Multi-skip Feature Stacking for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/10af69f11301679b6fbb23855bf10f6af1f3d2e6\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4e28779e52455967a942a28cd35a135b42509ed8\",\"title\":\"Deep Learning Models for Unsupervised and Transfer Learning\",\"url\":\"https://www.semanticscholar.org/paper/4e28779e52455967a942a28cd35a135b42509ed8\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35678872\",\"name\":\"Hongxin Zhi\"},{\"authorId\":\"1792198\",\"name\":\"H. Yu\"},{\"authorId\":\"8086859\",\"name\":\"Shaomei Li\"},{\"authorId\":\"144036350\",\"name\":\"C. Gao\"}],\"doi\":\"10.1109/SSCI.2017.8285296\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"279459cbbc5c6db4802e9c737cc72a612d76f7fc\",\"title\":\"DMMLN: A deep multi-task and metric learning based network for video classification\",\"url\":\"https://www.semanticscholar.org/paper/279459cbbc5c6db4802e9c737cc72a612d76f7fc\",\"venue\":\"2017 IEEE Symposium Series on Computational Intelligence (SSCI)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1931096\",\"name\":\"A. Behera\"},{\"authorId\":\"1967104\",\"name\":\"David C. Hogg\"},{\"authorId\":\"1703235\",\"name\":\"A. Cohn\"}],\"doi\":\"10.1007/978-3-642-37431-9_40\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eccd9b24f6faeee672b28f83cf5b849f6746e7c7\",\"title\":\"Egocentric Activity Monitoring and Recovery\",\"url\":\"https://www.semanticscholar.org/paper/eccd9b24f6faeee672b28f83cf5b849f6746e7c7\",\"venue\":\"ACCV\",\"year\":2012},{\"arxivId\":\"1907.07804\",\"authors\":[{\"authorId\":\"51011359\",\"name\":\"S. Pramanik\"},{\"authorId\":\"7421228\",\"name\":\"Priyanka Agrawal\"},{\"authorId\":\"145374365\",\"name\":\"Aman Hussain\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3fc815cebbd8948dfed0592a254d5d4bf82d3fcf\",\"title\":\"OmniNet: A unified architecture for multi-modal multi-task learning\",\"url\":\"https://www.semanticscholar.org/paper/3fc815cebbd8948dfed0592a254d5d4bf82d3fcf\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34646933\",\"name\":\"T. V. Nguyen\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"},{\"authorId\":\"145198965\",\"name\":\"Khang Nguyen\"}],\"doi\":\"10.1145/3164541.3164611\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c83e26622b275fdf878135e71c23325a31d0e5fc\",\"title\":\"Denser Trajectories of Anchor Points for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c83e26622b275fdf878135e71c23325a31d0e5fc\",\"venue\":\"IMCOM\",\"year\":2018},{\"arxivId\":\"1703.08089\",\"authors\":[{\"authorId\":\"32774629\",\"name\":\"A. Richard\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1016/j.cviu.2016.10.014\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a2af7dfe2769164c14d8ea2f73c5073c2a2f2bbe\",\"title\":\"A bag-of-words equivalent recurrent neural network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/a2af7dfe2769164c14d8ea2f73c5073c2a2f2bbe\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1772198\",\"name\":\"X. Wu\"},{\"authorId\":\"3307319\",\"name\":\"Qing-Ge Ji\"}],\"doi\":\"10.1145/3426826.3426836\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"64469e496132f3e25cdc5bfcfb3b7069c5e15ac4\",\"title\":\"Split and Attentive-Aggregated Learnable Shift Module for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/64469e496132f3e25cdc5bfcfb3b7069c5e15ac4\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29724362\",\"name\":\"Longlong Jing\"},{\"authorId\":\"38101706\",\"name\":\"Xiaodong Yang\"},{\"authorId\":\"35484757\",\"name\":\"Yingli Tian\"}],\"doi\":\"10.1016/j.jvcir.2018.01.016\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1e4b43fd34e14a476ac135bbfd5532a2d0cc50f3\",\"title\":\"Video you only look once: Overall temporal convolutions for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/1e4b43fd34e14a476ac135bbfd5532a2d0cc50f3\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2018},{\"arxivId\":\"1812.08249\",\"authors\":[{\"authorId\":\"143935879\",\"name\":\"Jonathan C. Stroud\"},{\"authorId\":\"144711958\",\"name\":\"D. Ross\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"}],\"doi\":\"10.1109/WACV45572.2020.9093274\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2766379db5d9907766dab034a52867d7394a265e\",\"title\":\"D3D: Distilled 3D Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2766379db5d9907766dab034a52867d7394a265e\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"13741850\",\"name\":\"Yijing Lv\"},{\"authorId\":\"39458374\",\"name\":\"H. Zheng\"},{\"authorId\":null,\"name\":\"Wei Zhang\"}],\"doi\":\"10.1007/978-3-030-03335-4_21\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b33742f8b5852c8d89bb9a0236bb88412c8a807f\",\"title\":\"Multi-level Three-Stream Convolutional Networks for Video-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b33742f8b5852c8d89bb9a0236bb88412c8a807f\",\"venue\":\"PRCV\",\"year\":2018},{\"arxivId\":\"1704.00389\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1007/978-3-030-20893-6_23\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"47195627755d88121af2513646ac41eec8645fb7\",\"title\":\"Hidden Two-Stream Convolutional Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/47195627755d88121af2513646ac41eec8645fb7\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"1612.03052\",\"authors\":[{\"authorId\":\"2340579\",\"name\":\"J. Ng\"},{\"authorId\":\"119675494\",\"name\":\"Jonghyun Choi\"},{\"authorId\":\"144660077\",\"name\":\"Jan Neumann\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/WACV.2018.00179\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a6db73f10084ce6a4186363ea9d7475a9a658a11\",\"title\":\"ActionFlowNet: Learning Motion Representation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a6db73f10084ce6a4186363ea9d7475a9a658a11\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":\"1906.01012\",\"authors\":[{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"3434584\",\"name\":\"Ahsan Iqbal\"},{\"authorId\":\"32774629\",\"name\":\"A. Richard\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b0e31596fe23b8b6c99c1e51fd3d08dcd856d5ac\",\"title\":\"Mining YouTube - A dataset for learning fine-grained action concepts from webly supervised video data\",\"url\":\"https://www.semanticscholar.org/paper/b0e31596fe23b8b6c99c1e51fd3d08dcd856d5ac\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1905.00561\",\"authors\":[{\"authorId\":\"2028234\",\"name\":\"Deepti Ghadiyaram\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"11529694\",\"name\":\"Xueting Yan\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"144542135\",\"name\":\"D. Mahajan\"}],\"doi\":\"10.1109/CVPR.2019.01232\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4cbaea4c21e15312ef2aeb9529a39baa48bbb522\",\"title\":\"Large-Scale Weakly-Supervised Pre-Training for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4cbaea4c21e15312ef2aeb9529a39baa48bbb522\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11964267\",\"name\":\"Tingwei Wang\"},{\"authorId\":\"143792007\",\"name\":\"Peng Duan\"},{\"authorId\":\"2095855\",\"name\":\"B. Ma\"},{\"authorId\":\"144044737\",\"name\":\"P. Wu\"},{\"authorId\":\"2882531\",\"name\":\"Weizhi Lu\"}],\"doi\":\"10.1016/J.JVCIR.2019.04.001\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"735ddb487ed4efdbffd83239019662ba6c584c63\",\"title\":\"Action recognition using dynamic hierarchical trees\",\"url\":\"https://www.semanticscholar.org/paper/735ddb487ed4efdbffd83239019662ba6c584c63\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2720195\",\"name\":\"Y. Li\"},{\"authorId\":\"104269236\",\"name\":\"Q. Li\"},{\"authorId\":\"145298361\",\"name\":\"Q. Huang\"},{\"authorId\":\"31280147\",\"name\":\"Rongjie Xia\"},{\"authorId\":\"40286455\",\"name\":\"Xuelong Li\"}],\"doi\":\"10.1117/1.JEI.28.3.033002\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1cd2f99475097dfc1e4c37e67c1771a9df72b47f\",\"title\":\"Spatiotemporal interest point detector exploiting appearance and motion-variation information\",\"url\":\"https://www.semanticscholar.org/paper/1cd2f99475097dfc1e4c37e67c1771a9df72b47f\",\"venue\":\"J. Electronic Imaging\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"113727681\",\"name\":\"Haotao Wang\"},{\"authorId\":\"145287209\",\"name\":\"Z. Wu\"},{\"authorId\":\"2969311\",\"name\":\"Zhangyang Wang\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ad1480c694a57466a25d9d54671a67207fbd140b\",\"title\":\"Privacy-Preserving Deep Visual Recognition: An Adversarial Learning Framework and A New Dataset\",\"url\":\"https://www.semanticscholar.org/paper/ad1480c694a57466a25d9d54671a67207fbd140b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1720100\",\"name\":\"H. Yao\"},{\"authorId\":\"145440152\",\"name\":\"A. Cavallaro\"},{\"authorId\":\"1934306\",\"name\":\"T. Bouwmans\"},{\"authorId\":\"1809184\",\"name\":\"Z. Zhang\"}],\"doi\":\"10.1109/TCSVT.2017.2669658\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"734406fda0ce66a10e250af02502ce47777f502c\",\"title\":\"Guest Editorial Introduction to the Special Issue on Group and Crowd Behavior Analysis for Intelligent Multicamera Video Surveillance\",\"url\":\"https://www.semanticscholar.org/paper/734406fda0ce66a10e250af02502ce47777f502c\",\"venue\":\"IEEE Trans. Circuits Syst. Video Technol.\",\"year\":2017},{\"arxivId\":\"1711.06330\",\"authors\":[{\"authorId\":\"7437104\",\"name\":\"Chih-Yao Ma\"},{\"authorId\":\"2293919\",\"name\":\"Asim Kadav\"},{\"authorId\":\"50162780\",\"name\":\"I. Melvin\"},{\"authorId\":\"145276578\",\"name\":\"Z. Kira\"},{\"authorId\":\"9202076\",\"name\":\"G. Al-Regib\"},{\"authorId\":\"1775043\",\"name\":\"H. Graf\"}],\"doi\":\"10.1109/CVPR.2018.00710\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"66aebb3af16aaa78579344784212ae10f60ec27e\",\"title\":\"Attend and Interact: Higher-Order Object Interactions for Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/66aebb3af16aaa78579344784212ae10f60ec27e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":\"10.1109/CVPR.2017.786\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8e999d9054c5c84f7839dd050150e28a84e1cdec\",\"title\":\"Temporal Residual Networks for Dynamic Scene Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8e999d9054c5c84f7839dd050150e28a84e1cdec\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1502.06648\",\"authors\":[{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"2485529\",\"name\":\"Michaela Regneri\"},{\"authorId\":\"40404576\",\"name\":\"S. Amin\"},{\"authorId\":\"1906895\",\"name\":\"M. Andriluka\"},{\"authorId\":\"1717560\",\"name\":\"Manfred Pinkal\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1007/s11263-015-0851-8\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"0138ef03aa5cf7bf7d0ce70b3f98876af022ffcd\",\"title\":\"Recognizing Fine-Grained and Composite Activities Using Hand-Centric Features and Script Data\",\"url\":\"https://www.semanticscholar.org/paper/0138ef03aa5cf7bf7d0ce70b3f98876af022ffcd\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40354734\",\"name\":\"Haoze Wu\"},{\"authorId\":\"48210950\",\"name\":\"Jiawei Liu\"},{\"authorId\":\"49898078\",\"name\":\"Xierong Zhu\"},{\"authorId\":\"152808542\",\"name\":\"Meng Wang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"}],\"doi\":\"10.24963/ijcai.2020/105\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f4fb429109591a5d20136fe884b5fd7c7584a62c\",\"title\":\"Multi-Scale Spatial-Temporal Integration Convolutional Tube for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f4fb429109591a5d20136fe884b5fd7c7584a62c\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145193839\",\"name\":\"Aneela Zameer\"},{\"authorId\":\"46410515\",\"name\":\"J. Arshad\"},{\"authorId\":\"2916228\",\"name\":\"A. Khan\"},{\"authorId\":\"38913808\",\"name\":\"M. Raja\"}],\"doi\":\"10.1016/J.ENCONMAN.2016.12.032\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb870abb8e86ed34627162bf7ab28edd9a049e6c\",\"title\":\"Intelligent and robust prediction of short term wind power using genetic programming based ensemble of neural networks\",\"url\":\"https://www.semanticscholar.org/paper/eb870abb8e86ed34627162bf7ab28edd9a049e6c\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"2001.03905\",\"authors\":[{\"authorId\":\"2849892\",\"name\":\"Hongguang Zhang\"},{\"authorId\":\"48571183\",\"name\":\"Liyong Zhang\"},{\"authorId\":\"50844674\",\"name\":\"Xiaojuan Qi\"},{\"authorId\":\"40124570\",\"name\":\"Hongdong Li\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"},{\"authorId\":\"2155775\",\"name\":\"Piotr Koniusz\"}],\"doi\":\"10.1007/978-3-030-58558-7_31\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"161ecde59203eaaa5347cdead5a1090f2a1669a2\",\"title\":\"Few-Shot Action Recognition with Permutation-Invariant Attention\",\"url\":\"https://www.semanticscholar.org/paper/161ecde59203eaaa5347cdead5a1090f2a1669a2\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"143740449\",\"name\":\"Q. Peng\"}],\"doi\":\"10.1007/978-3-319-10578-9_43\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b5716788c78748f2fd77e799bb70f8a2920cc6ec\",\"title\":\"Boosting VLAD with Supervised Dictionary Learning and High-Order Statistics\",\"url\":\"https://www.semanticscholar.org/paper/b5716788c78748f2fd77e799bb70f8a2920cc6ec\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"2010.11595\",\"authors\":[{\"authorId\":\"144240062\",\"name\":\"V\\u00edtor Cerqueira\"},{\"authorId\":\"1490932822\",\"name\":\"Lu\\u00eds Torgo\"},{\"authorId\":\"145726060\",\"name\":\"C. Soares\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5e39d08c3c8587b7ba09c5e3b36b844648f56b11\",\"title\":\"Early Anomaly Detection in Time Series: A Hierarchical Approach for Predicting Critical Health Episodes\",\"url\":\"https://www.semanticscholar.org/paper/5e39d08c3c8587b7ba09c5e3b36b844648f56b11\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2545377\",\"name\":\"Christian Mandery\"},{\"authorId\":\"2501728\",\"name\":\"\\u00d6mer Terlemez\"},{\"authorId\":\"144153518\",\"name\":\"Martin Do\"},{\"authorId\":\"1884591\",\"name\":\"N. Vahrenkamp\"},{\"authorId\":\"1722677\",\"name\":\"T. Asfour\"}],\"doi\":\"10.1109/ICAR.2015.7251476\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"27ed7f342ab5e040fd658db488cf63021ca68999\",\"title\":\"The KIT whole-body human motion database\",\"url\":\"https://www.semanticscholar.org/paper/27ed7f342ab5e040fd658db488cf63021ca68999\",\"venue\":\"2015 International Conference on Advanced Robotics (ICAR)\",\"year\":2015},{\"arxivId\":\"2003.01455\",\"authors\":[{\"authorId\":\"27629992\",\"name\":\"B. Brattoli\"},{\"authorId\":\"40580686\",\"name\":\"Joe Tighe\"},{\"authorId\":\"2096007\",\"name\":\"Fedor Zhdanov\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"3180200\",\"name\":\"Krzysztof Chalupka\"}],\"doi\":\"10.1109/CVPR42600.2020.00467\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c58c4c6ce9ae60dce8b2f6a02c06d086d7c2e545\",\"title\":\"Rethinking Zero-Shot Video Classification: End-to-End Training for Realistic Applications\",\"url\":\"https://www.semanticscholar.org/paper/c58c4c6ce9ae60dce8b2f6a02c06d086d7c2e545\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2003.13042\",\"authors\":[{\"authorId\":\"31463937\",\"name\":\"Haodong Duan\"},{\"authorId\":\"152621421\",\"name\":\"Yue Zhao\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"49663328\",\"name\":\"Wentao Liu\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1007/978-3-030-58555-6_40\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d6f7e18d551743889cd87dc3e0b4a75b8791ea95\",\"title\":\"Omni-sourced Webly-supervised Learning for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d6f7e18d551743889cd87dc3e0b4a75b8791ea95\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2012.08512\",\"authors\":[{\"authorId\":\"2655351\",\"name\":\"Tarun Kalluri\"},{\"authorId\":\"2004879394\",\"name\":\"Deepak Pathak\"},{\"authorId\":\"1491032137\",\"name\":\"M. Chandraker\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5ca230da787b25643150c8b2df474e2d6d8ec7c9\",\"title\":\"FLAVR: Flow-Agnostic Video Representations for Fast Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/5ca230da787b25643150c8b2df474e2d6d8ec7c9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40078088\",\"name\":\"X. Tang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"99a6492fbea30d57ed7e7edf316a96f93008a17a\",\"title\":\"Video Sequence Classification Using Spatio-temporal Features\",\"url\":\"https://www.semanticscholar.org/paper/99a6492fbea30d57ed7e7edf316a96f93008a17a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2482072\",\"name\":\"Nicolas Ballas\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"332003883038e576042fa1f11a0781df1b24e81b\",\"title\":\"Mod\\u00e9lisation de contextes pour l'annotation s\\u00e9mantique de vid\\u00e9os. (Context based modeling for video semantic annotation)\",\"url\":\"https://www.semanticscholar.org/paper/332003883038e576042fa1f11a0781df1b24e81b\",\"venue\":\"\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145412333\",\"name\":\"L. Lu\"},{\"authorId\":\"37942633\",\"name\":\"Yi-Ju Zhan\"},{\"authorId\":\"144157223\",\"name\":\"Q. Jiang\"},{\"authorId\":\"3229935\",\"name\":\"Qing-ling Cai\"}],\"doi\":\"10.1007/s00530-015-0474-5\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"9ab471f5bb6a9d8232afad2918a1ff4180ac02aa\",\"title\":\"Recognizing human actions by two-level Beta process hidden Markov model\",\"url\":\"https://www.semanticscholar.org/paper/9ab471f5bb6a9d8232afad2918a1ff4180ac02aa\",\"venue\":\"Multimedia Systems\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152502426\",\"name\":\"Shaoqing Tan\"},{\"authorId\":\"8092869\",\"name\":\"R. Yang\"}],\"doi\":\"10.1109/IJCNN.2019.8851694\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f1964f5e913bc386707e98e872861dbdf00ed13e\",\"title\":\"Learning Similarity: Feature-Aligning Network for Few-shot Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f1964f5e913bc386707e98e872861dbdf00ed13e\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":\"1306.4746\",\"authors\":[{\"authorId\":\"2089428\",\"name\":\"D. P. Barrett\"},{\"authorId\":\"1737754\",\"name\":\"J. Siskind\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"86f0f71bff42e4bdc60014e4f94ec76d52c8eccf\",\"title\":\"Felzenszwalb-Baum-Welch: Event Detection by Changing Appearance\",\"url\":\"https://www.semanticscholar.org/paper/86f0f71bff42e4bdc60014e4f94ec76d52c8eccf\",\"venue\":\"ArXiv\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1643933241\",\"name\":\"Hayden Hudgins\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"93c972d0d84673f002bfd575fea9bc9e47e2af57\",\"title\":\"Human Path Prediction using Auto Encoder LSTMs and Single Temporal Encoders\",\"url\":\"https://www.semanticscholar.org/paper/93c972d0d84673f002bfd575fea9bc9e47e2af57\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145733600\",\"name\":\"Song Cao\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/ICPR.2016.7899664\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1dabb080e3e968633f4b3774f19192f8378f5b67\",\"title\":\"Exploring deep learning based solutions in fine grained activity recognition in the wild\",\"url\":\"https://www.semanticscholar.org/paper/1dabb080e3e968633f4b3774f19192f8378f5b67\",\"venue\":\"2016 23rd International Conference on Pattern Recognition (ICPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3172766\",\"name\":\"G. Ma\"},{\"authorId\":\"2045700\",\"name\":\"Junyao Gao\"},{\"authorId\":\"1715687\",\"name\":\"Zhangguo Yu\"},{\"authorId\":\"1849860\",\"name\":\"X. Chen\"},{\"authorId\":\"144938785\",\"name\":\"Qiang Huang\"},{\"authorId\":\"40013571\",\"name\":\"Y. Liu\"}],\"doi\":\"10.1007/s12369-015-0330-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0da17de384c4880c5c7e990e8291590ab9ae6313\",\"title\":\"Development of a Socially Interactive System with Whole-Body Movements for BHR-4\",\"url\":\"https://www.semanticscholar.org/paper/0da17de384c4880c5c7e990e8291590ab9ae6313\",\"venue\":\"Int. J. Soc. Robotics\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1416650467\",\"name\":\"Vida Adeli\"},{\"authorId\":\"1707752\",\"name\":\"E. F. Ersi\"},{\"authorId\":\"1734678\",\"name\":\"A. Harati\"}],\"doi\":\"10.1016/j.imavis.2019.08.009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"da6e00eeee9c068e081e24836b230024eaa2eeae\",\"title\":\"A component-based video content representation for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/da6e00eeee9c068e081e24836b230024eaa2eeae\",\"venue\":\"Image Vis. Comput.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144077750\",\"name\":\"Hang Zhao\"},{\"authorId\":null,\"name\":\"Zhicheng Yan\"},{\"authorId\":null,\"name\":\"Heng Wang\"},{\"authorId\":null,\"name\":\"Lorenzo Torresani\"}],\"doi\":\"10.1109/ICCV.2019.00876\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5aeef2c4f3eb125ec1db9c20392f95e64ef62b41\",\"title\":\"HACS: Human Action Clips and Segments Dataset for Recognition and Temporal Localization\",\"url\":\"https://www.semanticscholar.org/paper/5aeef2c4f3eb125ec1db9c20392f95e64ef62b41\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1704.00570\",\"authors\":[{\"authorId\":\"2548303\",\"name\":\"Lijie Fan\"},{\"authorId\":\"22579906\",\"name\":\"Y. Ke\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"616e69647b02e69cffa7eeb83cf3e72b8c532653\",\"title\":\"Spatiotemporal Networks for Video Emotion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/616e69647b02e69cffa7eeb83cf3e72b8c532653\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2893255\",\"name\":\"Jeong-Min Seo\"},{\"authorId\":\"47111186\",\"name\":\"H. Yoo\"},{\"authorId\":\"35323281\",\"name\":\"Kimin Yun\"},{\"authorId\":\"46695861\",\"name\":\"Hyunil Kim\"},{\"authorId\":\"1737997\",\"name\":\"Sang-Il Choi\"}],\"doi\":\"10.1109/AIKE.2018.00040\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ea35d98dd074cee5042942804bd44a636f393d52\",\"title\":\"Behavior Recognition of a Person in a Daily Video Using Joint Position Information\",\"url\":\"https://www.semanticscholar.org/paper/ea35d98dd074cee5042942804bd44a636f393d52\",\"venue\":\"2018 IEEE First International Conference on Artificial Intelligence and Knowledge Engineering (AIKE)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48466004\",\"name\":\"Isaac Sanou\"},{\"authorId\":\"144353664\",\"name\":\"D. Conte\"},{\"authorId\":\"2436386\",\"name\":\"H. Cardot\"}],\"doi\":\"10.5220/0007253301910199\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"68a87599c33c597f1792709c4f0cfd673b5e1b61\",\"title\":\"An Extensible Deep Architecture for Action Recognition Problem\",\"url\":\"https://www.semanticscholar.org/paper/68a87599c33c597f1792709c4f0cfd673b5e1b61\",\"venue\":\"VISIGRAPP\",\"year\":2019},{\"arxivId\":\"1903.02155\",\"authors\":[{\"authorId\":\"144770282\",\"name\":\"D. Xie\"},{\"authorId\":\"145102437\",\"name\":\"Cheng Deng\"},{\"authorId\":\"49528465\",\"name\":\"Hao Wang\"},{\"authorId\":\"66140038\",\"name\":\"Chao Li\"},{\"authorId\":\"1701119\",\"name\":\"Dapeng Tao\"}],\"doi\":\"10.1609/AAAI.V33I01.33019030\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"19458fa0d29181cc3f72f5f1253b64ba0e02e5f3\",\"title\":\"Semantic Adversarial Network with Multi-scale Pyramid Attention for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/19458fa0d29181cc3f72f5f1253b64ba0e02e5f3\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34798935\",\"name\":\"Xiantong Zhen\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"}],\"doi\":\"10.1109/ICPR.2014.769\",\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"1f9395ba9eabb1853d2eac8228e6e10c1727b81a\",\"title\":\"A Performance Evaluation on Action Recognition with Local Features\",\"url\":\"https://www.semanticscholar.org/paper/1f9395ba9eabb1853d2eac8228e6e10c1727b81a\",\"venue\":\"2014 22nd International Conference on Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8556451\",\"name\":\"F. Angelini\"},{\"authorId\":\"9573943\",\"name\":\"Zeyu Fu\"},{\"authorId\":\"144325904\",\"name\":\"Yang Long\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"},{\"authorId\":\"144403678\",\"name\":\"S. Naqvi\"}],\"doi\":\"10.1109/TMM.2019.2944745\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ac558105733cba4e7b03ddcba20e97b1ae4c6793\",\"title\":\"2D Pose-Based Real-Time Human Action Recognition With Occlusion-Handling\",\"url\":\"https://www.semanticscholar.org/paper/ac558105733cba4e7b03ddcba20e97b1ae4c6793\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6076894\",\"name\":\"J. Choi\"},{\"authorId\":\"33311464\",\"name\":\"J. Lee\"}],\"doi\":\"10.1145/3267305.3267522\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"16c2eb10de8b2bf0f2f8304c8a365a5c7f8b7a2b\",\"title\":\"Confidence-based Deep Multimodal Fusion for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/16c2eb10de8b2bf0f2f8304c8a365a5c7f8b7a2b\",\"venue\":\"UbiComp/ISWC Adjunct\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23325763\",\"name\":\"Elit Cenk Alp\"},{\"authorId\":\"2987805\",\"name\":\"Hacer Yalim Keles\"}],\"doi\":\"10.1007/978-3-030-01054-6_76\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aabad1eb6286862328447a9a1e0d82cc64267172\",\"title\":\"A Comparative Study of HMMs and LSTMs on Action Classification with Limited Training Data\",\"url\":\"https://www.semanticscholar.org/paper/aabad1eb6286862328447a9a1e0d82cc64267172\",\"venue\":\"IntelliSys\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40241836\",\"name\":\"L. Liu\"},{\"authorId\":null,\"name\":\"Yi Zhou\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"}],\"doi\":\"10.1109/TIP.2018.2813530\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0329d9be8ab1e3a1d5e4b9e7db5af5bbcc64e36f\",\"title\":\"Deep Action Parsing in Videos With Large-Scale Synthesized Data\",\"url\":\"https://www.semanticscholar.org/paper/0329d9be8ab1e3a1d5e4b9e7db5af5bbcc64e36f\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7466378\",\"name\":\"Jia-xin Cai\"},{\"authorId\":\"34651153\",\"name\":\"J. Hu\"},{\"authorId\":\"1737903652\",\"name\":\"Xin Tang\"},{\"authorId\":\"34985695\",\"name\":\"Tzu-Yi Hung\"},{\"authorId\":\"30915941\",\"name\":\"Y. Tan\"}],\"doi\":\"10.1016/j.neucom.2020.03.111\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"46463edcb809186ca8cd003d02c67567235b3317\",\"title\":\"Deep historical long short-term memory network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/46463edcb809186ca8cd003d02c67567235b3317\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9369513\",\"name\":\"Md. Imtiaz Hossain\"},{\"authorId\":\"50876944\",\"name\":\"Ashraf Siddique\"},{\"authorId\":\"101481224\",\"name\":\"Md. Imtiaz Hossain\"},{\"authorId\":\"81133680\",\"name\":\"Md. Sohorab Hossain\"},{\"authorId\":\"1705900\",\"name\":\"E. Huh\"}],\"doi\":\"10.1109/ACCESS.2020.3037529\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"2b4d7724aecdd21451648b84bff065132fc6e9d9\",\"title\":\"Batch Entropy Supervised Convolutional Neural Networks for Feature Extraction and Harmonizing for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2b4d7724aecdd21451648b84bff065132fc6e9d9\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2357503\",\"name\":\"Ya-Chun Li\"},{\"authorId\":\"97596774\",\"name\":\"Y. Liu\"},{\"authorId\":\"48935472\",\"name\":\"Chi Zhang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9d02a5b52bb47ecf594710ede66c12f1eb660c39\",\"title\":\"What Elements are Essential to Recognize Human Actions?\",\"url\":\"https://www.semanticscholar.org/paper/9d02a5b52bb47ecf594710ede66c12f1eb660c39\",\"venue\":\"CVPR Workshops\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2676982\",\"name\":\"Hueihan Jhuang\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"},{\"authorId\":\"2133988\",\"name\":\"S. Zuffi\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"}],\"doi\":\"10.1109/ICCV.2013.396\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2cee43afc7aad6a8f7c4a6d566b60ebc79d57e7a\",\"title\":\"Towards Understanding Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2cee43afc7aad6a8f7c4a6d566b60ebc79d57e7a\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144692146\",\"name\":\"Ming Tong\"},{\"authorId\":\"47628927\",\"name\":\"Mingyang Li\"},{\"authorId\":null,\"name\":\"He Bai\"},{\"authorId\":\"88502672\",\"name\":\"L. Ma\"},{\"authorId\":\"27746265\",\"name\":\"Mengao Zhao\"}],\"doi\":\"10.1007/s00521-019-04030-1\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"55995e4ac050563d10cbcdc07a79b729ccd1b25b\",\"title\":\"DKD\\u2013DAD: a novel framework with discriminative kinematic descriptor and deep attention-pooled descriptor for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/55995e4ac050563d10cbcdc07a79b729ccd1b25b\",\"venue\":\"Neural Computing and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67055826\",\"name\":\"Renfei Sun\"},{\"authorId\":\"48708295\",\"name\":\"Z. Wang\"},{\"authorId\":\"153321393\",\"name\":\"K. E. Martens\"},{\"authorId\":\"144506986\",\"name\":\"S. Lewis\"}],\"doi\":\"10.1109/DICTA.2018.8615791\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"22bce54fddaaf359f348badfb49b7a168ab53cc6\",\"title\":\"Convolutional 3D Attention Network for Video Based Freezing of Gait Recognition\",\"url\":\"https://www.semanticscholar.org/paper/22bce54fddaaf359f348badfb49b7a168ab53cc6\",\"venue\":\"2018 Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2018},{\"arxivId\":\"2009.01067\",\"authors\":[{\"authorId\":\"47286885\",\"name\":\"Jingyi Hou\"},{\"authorId\":\"7415267\",\"name\":\"Y. Jia\"},{\"authorId\":\"2125709\",\"name\":\"Xinxiao Wu\"},{\"authorId\":\"66547993\",\"name\":\"Yayun Qi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"aa17f11df851372402a0fa1481fdbc6af36ba2b6\",\"title\":\"Video Captioning Using Weak Annotation\",\"url\":\"https://www.semanticscholar.org/paper/aa17f11df851372402a0fa1481fdbc6af36ba2b6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145883076\",\"name\":\"S. Rani\"},{\"authorId\":\"1416537783\",\"name\":\"G. Naidu\"},{\"authorId\":\"145394493\",\"name\":\"V. U. Shree\"}],\"doi\":\"10.35940/ijitee.a4677.119119\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ef016ec90c41e30250e091051e183b80d891bd4e\",\"title\":\"A Fine Grainedresearch Over Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ef016ec90c41e30250e091051e183b80d891bd4e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1611.05215\",\"authors\":[{\"authorId\":\"38179026\",\"name\":\"Y. Shi\"},{\"authorId\":\"40161651\",\"name\":\"Yonghong Tian\"},{\"authorId\":\"5765799\",\"name\":\"Yaowei Wang\"},{\"authorId\":\"34097174\",\"name\":\"Tiejun Huang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b3b532e8ea6304446b1623e83b0b9a96968f926c\",\"title\":\"Joint Network based Attention for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b3b532e8ea6304446b1623e83b0b9a96968f926c\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145546921\",\"name\":\"J. Qin\"},{\"authorId\":\"40241836\",\"name\":\"L. Liu\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"},{\"authorId\":\"144618699\",\"name\":\"F. Shen\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"145905368\",\"name\":\"Jiaxin Chen\"},{\"authorId\":\"40013375\",\"name\":\"Y. Wang\"}],\"doi\":\"10.1109/CVPR.2017.117\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e060e32f8ad98f10277b582393df50ac17f2836c\",\"title\":\"Zero-Shot Action Recognition with Error-Correcting Output Codes\",\"url\":\"https://www.semanticscholar.org/paper/e060e32f8ad98f10277b582393df50ac17f2836c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"46583885\",\"name\":\"J. Wang\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d708ce7103a992634b1b4e87612815f03ba3ab24\",\"title\":\"FCVID : Fudan-Columbia Video Dataset\",\"url\":\"https://www.semanticscholar.org/paper/d708ce7103a992634b1b4e87612815f03ba3ab24\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5964529\",\"name\":\"Xiaochen Lian\"},{\"authorId\":\"50656755\",\"name\":\"Qing Yuan Zhou\"},{\"authorId\":\"50424096\",\"name\":\"Nicolas Christou\"},{\"authorId\":\"145081360\",\"name\":\"Alan Loddon Yuille\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4cc681239c8fda3fb04ba7ac6a1b9d85b68af31d\",\"title\":\"Electronic Theses and Dissertations Title Mining Spatial and Spatio-Temporal ROIs for Action Recognition Permalink\",\"url\":\"https://www.semanticscholar.org/paper/4cc681239c8fda3fb04ba7ac6a1b9d85b68af31d\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19198359\",\"name\":\"Yatao Zhong\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3f87aa098278c5d214a89b00c41734c5f5196eb5\",\"title\":\"Learning Person Trajectory Features for Sports Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/3f87aa098278c5d214a89b00c41734c5f5196eb5\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143994834\",\"name\":\"W. Yan\"},{\"authorId\":\"32874186\",\"name\":\"Jordan Yap\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"}],\"doi\":\"10.5244/C.29.37\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"9cc10842f7701bfb92725b4dda4df391b0b341e3\",\"title\":\"Multi-Task Transfer Methods to Improve One-Shot Learning for Multimedia Event Detection\",\"url\":\"https://www.semanticscholar.org/paper/9cc10842f7701bfb92725b4dda4df391b0b341e3\",\"venue\":\"BMVC\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3414842\",\"name\":\"Hongsong Wang\"},{\"authorId\":null,\"name\":\"Wei Wang\"},{\"authorId\":null,\"name\":\"Liang Wang\"}],\"doi\":\"10.1109/ICIP.2016.7532632\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c2dc29e0db76122dfed075c3b9ee48503b027809\",\"title\":\"How scenes imply actions in realistic videos?\",\"url\":\"https://www.semanticscholar.org/paper/c2dc29e0db76122dfed075c3b9ee48503b027809\",\"venue\":\"2016 IEEE International Conference on Image Processing (ICIP)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145188795\",\"name\":\"Eman M. Nejad\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"7b54f5d3cb2ff5102e2bd9a6ab01d4ef858c1aa2\",\"title\":\"Simple and Complex Human Action Recognition in Constrained and Unconstrained Videos\",\"url\":\"https://www.semanticscholar.org/paper/7b54f5d3cb2ff5102e2bd9a6ab01d4ef858c1aa2\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151392606\",\"name\":\"Malavika Nair\"},{\"authorId\":null,\"name\":\"Mathew Gillroy\"},{\"authorId\":\"4374464\",\"name\":\"Neethu Maria Jose\"},{\"authorId\":\"46426940\",\"name\":\"Jasmy Davies\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c229f5e5fec10547dbeb2e77af6d2db7ab6ceff6\",\"title\":\"i-SURVEILLANCE CRIME MONITORING AND PREVENTION USING NEURAL NETWORKS\",\"url\":\"https://www.semanticscholar.org/paper/c229f5e5fec10547dbeb2e77af6d2db7ab6ceff6\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Joao Carreira\"},{\"authorId\":null,\"name\":\"Karen Simonyan\"},{\"authorId\":\"11809518\",\"name\":\"Brian Zhang\"},{\"authorId\":null,\"name\":\"Chloe Hillier\"},{\"authorId\":null,\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":null,\"name\":\"Fabio Viola\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8a7d3d284b468d689a2f9efa603b385da627a0f5\",\"title\":\"Supplementary Material Dynamic Inference: A New Approach Toward Efficient Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8a7d3d284b468d689a2f9efa603b385da627a0f5\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145466505\",\"name\":\"M. Sapienza\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"74ca629b5216d45bc6ad34f33fb1d1b85c578e61\",\"title\":\"Recognising and localising human actions\",\"url\":\"https://www.semanticscholar.org/paper/74ca629b5216d45bc6ad34f33fb1d1b85c578e61\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4322411\",\"name\":\"L. Li\"},{\"authorId\":\"33126875\",\"name\":\"Shuling Dai\"}],\"doi\":\"10.1007/s11042-016-3889-x\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8d170ba638d5f788bbdbe717a419504d202805d0\",\"title\":\"Erratum to: Action recognition with spatio-temporal augmented descriptor and fusion method\",\"url\":\"https://www.semanticscholar.org/paper/8d170ba638d5f788bbdbe717a419504d202805d0\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2016},{\"arxivId\":\"1902.09928\",\"authors\":[{\"authorId\":\"143781496\",\"name\":\"K. Yang\"},{\"authorId\":\"38373258\",\"name\":\"Jingjing Fu\"},{\"authorId\":\"145762398\",\"name\":\"Xun Guo\"},{\"authorId\":\"144574822\",\"name\":\"Y. Lu\"},{\"authorId\":\"50468629\",\"name\":\"Peng Qiao\"},{\"authorId\":\"144032853\",\"name\":\"Dong-sheng Li\"},{\"authorId\":\"143844357\",\"name\":\"Y. Dou\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"31707c9c377cffb1e6e7435c7b35a46d33976562\",\"title\":\"IF-TTN: Information Fused Temporal Transformation Network for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/31707c9c377cffb1e6e7435c7b35a46d33976562\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2238575\",\"name\":\"Daesik Kim\"},{\"authorId\":\"2647624\",\"name\":\"Myunggi Lee\"},{\"authorId\":\"3160425\",\"name\":\"N. Kwak\"}],\"doi\":\"10.1109/IJCNN.2017.7965886\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ad4d1ecf5c5473c050e11f6876ce148de1c8920a\",\"title\":\"Matching video net: Memory-based embedding for video action recognition\",\"url\":\"https://www.semanticscholar.org/paper/ad4d1ecf5c5473c050e11f6876ce148de1c8920a\",\"venue\":\"2017 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"896b764cff4d71f917c485593ef78d2f1ed7124d\",\"title\":\"Online, Supervised and Unsupervised Action Localization in Videos\",\"url\":\"https://www.semanticscholar.org/paper/896b764cff4d71f917c485593ef78d2f1ed7124d\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"2008.02711\",\"authors\":[{\"authorId\":\"152504322\",\"name\":\"Dezhao Luo\"},{\"authorId\":\"153841261\",\"name\":\"Bo Fang\"},{\"authorId\":\"9113781\",\"name\":\"Yin-qing Zhou\"},{\"authorId\":\"2803189\",\"name\":\"Yucan Zhou\"},{\"authorId\":\"11000953\",\"name\":\"D. Wu\"},{\"authorId\":\"1956868\",\"name\":\"Weiping Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"ec47ea8667ec60f21ead4e4bd9e286ef28e484f3\",\"title\":\"Exploring Relations in Untrimmed Videos for Self-Supervised Learning\",\"url\":\"https://www.semanticscholar.org/paper/ec47ea8667ec60f21ead4e4bd9e286ef28e484f3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1696573\",\"name\":\"Jiagang Zhu\"},{\"authorId\":\"47052503\",\"name\":\"W. Zou\"},{\"authorId\":null,\"name\":\"Liang Xu\"},{\"authorId\":\"1736595\",\"name\":\"Yiming Hu\"},{\"authorId\":\"46637801\",\"name\":\"Zheng Zhu\"},{\"authorId\":\"41170509\",\"name\":\"Manyu Chang\"},{\"authorId\":\"47513708\",\"name\":\"Junjie Huang\"},{\"authorId\":\"143986381\",\"name\":\"Guan Huang\"},{\"authorId\":\"40359161\",\"name\":\"Dalong Du\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"3cd457efa63de3e9810f08cc5f0b57442c670c04\",\"title\":\"Typing Video frames after person detection Pose Tube 2 D Deconv Score fusion RGB action recognition Pose action recognition Pose estimation\",\"url\":\"https://www.semanticscholar.org/paper/3cd457efa63de3e9810f08cc5f0b57442c670c04\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1727419\",\"name\":\"Zhigang Ma\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"},{\"authorId\":\"2351434\",\"name\":\"Zhongwen Xu\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1145/2502081.2502119\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6c510b56b468303adf9ea2fe94bd93d98347f07c\",\"title\":\"We are not equally negative: fine-grained labeling for multimedia event detection\",\"url\":\"https://www.semanticscholar.org/paper/6c510b56b468303adf9ea2fe94bd93d98347f07c\",\"venue\":\"MM '13\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7769579\",\"name\":\"Zhikang Liu\"},{\"authorId\":\"145509096\",\"name\":\"Y. Tian\"},{\"authorId\":\"3238613\",\"name\":\"Zilei Wang\"}],\"doi\":\"10.1109/ICIP.2017.8296405\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"81d232e1f432db7de67baf4f30f240c62d1a9055\",\"title\":\"Improving human action recognitionby temporal attention\",\"url\":\"https://www.semanticscholar.org/paper/81d232e1f432db7de67baf4f30f240c62d1a9055\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144845024\",\"name\":\"Fei Han\"},{\"authorId\":\"38721319\",\"name\":\"C. Reardon\"},{\"authorId\":\"9371012\",\"name\":\"L. Parker\"},{\"authorId\":\"38952862\",\"name\":\"Hao Zhang\"}],\"doi\":\"10.1109/ICRA.2017.7989302\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3c733b84690ecbd98b0f38ce29470089603ebfe9\",\"title\":\"Minimum uncertainty latent variable models for robot recognition of sequential human activities\",\"url\":\"https://www.semanticscholar.org/paper/3c733b84690ecbd98b0f38ce29470089603ebfe9\",\"venue\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145128145\",\"name\":\"Lior Wolf\"},{\"authorId\":\"48967743\",\"name\":\"Yair Hanani\"},{\"authorId\":\"1756099\",\"name\":\"Tal Hassner\"}],\"doi\":\"10.1109/CVPRW.2014.81\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e732fd1760183ac9750a91ed401bda1a80b7ebb2\",\"title\":\"A Piggyback Representation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e732fd1760183ac9750a91ed401bda1a80b7ebb2\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition Workshops\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3411298\",\"name\":\"Ammar Ladjailia\"},{\"authorId\":\"2674025\",\"name\":\"Imed Bouchrika\"},{\"authorId\":\"3410927\",\"name\":\"Nouzha Harrati\"},{\"authorId\":\"9323182\",\"name\":\"Zohra Mahfouf\"}],\"doi\":\"10.4018/978-1-5225-1022-2.CH008\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3cf91a00dd2346e0be1876f126114bf03e0e7714\",\"title\":\"Encoding Human Motion for Automated Activity Recognition in Surveillance Applications\",\"url\":\"https://www.semanticscholar.org/paper/3cf91a00dd2346e0be1876f126114bf03e0e7714\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2092543\",\"name\":\"Gediminas Bertasius\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5dee122d4a5e8726ba280dd3c9a804b1e69e7406\",\"title\":\"Embodied Visual Perception Models For Human Behavior Understanding\",\"url\":\"https://www.semanticscholar.org/paper/5dee122d4a5e8726ba280dd3c9a804b1e69e7406\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3195828\",\"name\":\"L. Rybok\"}],\"doi\":\"10.5445/ir/1000073778\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"1ae22453b5ee4c55fca2c7ce2f56d2ba049d7e1c\",\"title\":\"Unsupervised object candidate discovery for activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/1ae22453b5ee4c55fca2c7ce2f56d2ba049d7e1c\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Wei Zhang\"},{\"authorId\":\"3432527\",\"name\":\"Jiepeng Cen\"},{\"authorId\":\"39458374\",\"name\":\"H. Zheng\"}],\"doi\":\"10.1109/ICPR.2018.8545720\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e39db6a72f533b5adb2ecd9feaadbbab8204e024\",\"title\":\"Temporal Inception Architecture for Action Recognition with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/e39db6a72f533b5adb2ecd9feaadbbab8204e024\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3035146\",\"name\":\"Jinyoung Moon\"},{\"authorId\":\"153439664\",\"name\":\"Y. Kwon\"},{\"authorId\":\"1938407\",\"name\":\"Kyuchang Kang\"},{\"authorId\":\"2800227\",\"name\":\"Jongyoul Park\"}],\"doi\":\"10.1109/SIP.2015.9\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"64c4019f1ea9b54b1848418ac53c4e2584dc62d4\",\"title\":\"ActionNet-VE Dataset: A Dataset for Describing Visual Events by Extending VIRAT Ground 2.0\",\"url\":\"https://www.semanticscholar.org/paper/64c4019f1ea9b54b1848418ac53c4e2584dc62d4\",\"venue\":\"2015 8th International Conference on Signal Processing, Image Processing and Pattern Recognition (SIP)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"1742248\",\"name\":\"P. Moulin\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"}],\"doi\":\"10.1007/s11263-014-0742-4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a5f82fa24eb3e5512e971b4d1cd5cd291b364f91\",\"title\":\"Pose Adaptive Motion Feature Pooling for Human Action Analysis\",\"url\":\"https://www.semanticscholar.org/paper/a5f82fa24eb3e5512e971b4d1cd5cd291b364f91\",\"venue\":\"International Journal of Computer Vision\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145179162\",\"name\":\"Mingxing Zhang\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":\"50006507\",\"name\":\"Yanli Ji\"},{\"authorId\":\"145833207\",\"name\":\"Ning Xie\"},{\"authorId\":\"144618699\",\"name\":\"F. Shen\"}],\"doi\":\"10.1016/j.sigpro.2017.12.008\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2ae9f14872520bb2926cfef2b670a5e9bc3870a5\",\"title\":\"Recurrent attention network using spatial-temporal relations for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/2ae9f14872520bb2926cfef2b670a5e9bc3870a5\",\"venue\":\"Signal Process.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145546921\",\"name\":\"J. Qin\"},{\"authorId\":\"40241836\",\"name\":\"L. Liu\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"144618699\",\"name\":\"F. Shen\"},{\"authorId\":\"40013375\",\"name\":\"Y. Wang\"}],\"doi\":\"10.1109/CVPR.2017.712\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1fa426496ed6bcd0c0b17b8b935a14c84a7ee1c2\",\"title\":\"Binary Coding for Partial Action Analysis with Limited Observation Ratios\",\"url\":\"https://www.semanticscholar.org/paper/1fa426496ed6bcd0c0b17b8b935a14c84a7ee1c2\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145718481\",\"name\":\"Min Sun\"},{\"authorId\":\"32970572\",\"name\":\"Kuo-Hao Zeng\"},{\"authorId\":\"49415774\",\"name\":\"Yen-Chen Lin\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"}],\"doi\":\"10.1109/TIP.2017.2666039\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0696b633404183479bf57bc337de2e2121cf0a5e\",\"title\":\"Semantic Highlight Retrieval and Term Prediction\",\"url\":\"https://www.semanticscholar.org/paper/0696b633404183479bf57bc337de2e2121cf0a5e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40413834\",\"name\":\"J. Imran\"},{\"authorId\":\"1796442\",\"name\":\"B. Raman\"}],\"doi\":\"10.1016/J.INFRARED.2019.103014\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"45b4b470fb2f4af1f4dfbea32edd517161b51ad1\",\"title\":\"Deep residual infrared action recognition by integrating local and global spatio-temporal cues\",\"url\":\"https://www.semanticscholar.org/paper/45b4b470fb2f4af1f4dfbea32edd517161b51ad1\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153234114\",\"name\":\"Yunlei Sun\"},{\"authorId\":\"2679444\",\"name\":\"Dalin Zhang\"}],\"doi\":\"10.17559/tv-20190506101459\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"9478073c3ec0a111e1d3d78508a40f985ecd216d\",\"title\":\"ATSN: Attention-Based Temporal Segment Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9478073c3ec0a111e1d3d78508a40f985ecd216d\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1911.04140\",\"authors\":[{\"authorId\":\"1381281389\",\"name\":\"Prashant Pandey\"},{\"authorId\":\"1411010600\",\"name\":\"P. PrathoshA.\"},{\"authorId\":\"49085157\",\"name\":\"Manu Kohli\"},{\"authorId\":\"49017407\",\"name\":\"J. Pritchard\"}],\"doi\":\"10.1609/aaai.v34i01.5383\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bfefcb0901b173f0da0d4db3948d749ab9734198\",\"title\":\"Guided weak supervision for action recognition with scarce data to assess skills of children with autism\",\"url\":\"https://www.semanticscholar.org/paper/bfefcb0901b173f0da0d4db3948d749ab9734198\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1902.10640\",\"authors\":[{\"authorId\":\"34971636\",\"name\":\"Shweta Bhardwaj\"},{\"authorId\":\"34658653\",\"name\":\"M. Srinivasan\"},{\"authorId\":\"2361078\",\"name\":\"Mitesh M. Khapra\"}],\"doi\":\"10.1109/CVPR.2019.00044\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"58f32f1e294569f88d20892c11b389105da9c615\",\"title\":\"Efficient Video Classification Using Fewer Frames\",\"url\":\"https://www.semanticscholar.org/paper/58f32f1e294569f88d20892c11b389105da9c615\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3112334\",\"name\":\"Behrooz Mahasseni\"},{\"authorId\":\"143856428\",\"name\":\"S. Todorovic\"}],\"doi\":\"10.1109/CVPR.2016.333\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7854a9d1eaaac11047c22177b5ad5aa9ce2bf9e3\",\"title\":\"Regularizing Long Short Term Memory with 3D Human-Skeleton Sequences for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7854a9d1eaaac11047c22177b5ad5aa9ce2bf9e3\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143625300\",\"name\":\"J. Yuan\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"1795291\",\"name\":\"X. Yang\"},{\"authorId\":\"1731233\",\"name\":\"A. Kassim\"}],\"doi\":\"10.1109/CVPR.2016.337\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"374a0df2aa63b26737ee89b6c7df01e59b4d8531\",\"title\":\"Temporal Action Localization with Pyramid of Score Distribution Features\",\"url\":\"https://www.semanticscholar.org/paper/374a0df2aa63b26737ee89b6c7df01e59b4d8531\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39956342\",\"name\":\"Wenbin Li\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":\"10.1109/WACV.2016.7477586\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"65355cbb581a219bd7461d48b3afd115263ea760\",\"title\":\"Recognition of ongoing complex activities by sequence prediction over a hierarchical label space\",\"url\":\"https://www.semanticscholar.org/paper/65355cbb581a219bd7461d48b3afd115263ea760\",\"venue\":\"2016 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3326677\",\"name\":\"Minnan Luo\"},{\"authorId\":\"144962210\",\"name\":\"F. Nie\"},{\"authorId\":\"144950946\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"},{\"authorId\":\"50320297\",\"name\":\"Qinghua Zheng\"}],\"doi\":\"10.1109/TNNLS.2017.2650978\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"766db4e53c7b4a2e4b440751e82ec022290b2e77\",\"title\":\"Adaptive Unsupervised Feature Selection With Structure Regularization\",\"url\":\"https://www.semanticscholar.org/paper/766db4e53c7b4a2e4b440751e82ec022290b2e77\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51508179\",\"name\":\"Z. Gao\"},{\"authorId\":\"152813675\",\"name\":\"Tao-tao Han\"},{\"authorId\":\"39389412\",\"name\":\"H. Zhang\"},{\"authorId\":\"1902532\",\"name\":\"Y. Xue\"},{\"authorId\":\"2615851\",\"name\":\"G. Xu\"}],\"doi\":\"10.1007/s11042-018-5833-8\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ea8bf8924e15607d959ae822f428815a9d435f3b\",\"title\":\"MMA: a multi-view and multi-modality benchmark dataset for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/ea8bf8924e15607d959ae822f428815a9d435f3b\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":\"2007.11118\",\"authors\":[{\"authorId\":\"1825785725\",\"name\":\"Ollie Matthews\"},{\"authorId\":\"1825814505\",\"name\":\"Koki Ryu\"},{\"authorId\":\"121319612\",\"name\":\"Tarun Srivastava\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"725c15261a57eca5a4207f63aa217c97ad75dfda\",\"title\":\"Creating a Large-scale Synthetic Dataset for Human Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/725c15261a57eca5a4207f63aa217c97ad75dfda\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.00095\",\"authors\":[{\"authorId\":\"26902477\",\"name\":\"Amir Rasouli\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9f28b8965e0e1dab3c38ea6c95a6a3ad60d83785\",\"title\":\"Deep Learning for Vision-based Prediction: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/9f28b8965e0e1dab3c38ea6c95a6a3ad60d83785\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1406.2199\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"title\":\"Two-Stream Convolutional Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3367041\",\"name\":\"Himanshu Buckchash\"},{\"authorId\":\"1796442\",\"name\":\"B. Raman\"}],\"doi\":\"10.1109/ICTAI50040.2020.00082\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"44c37249c9d4298d526f56435476311ff74106ff\",\"title\":\"DuTriNet: Dual-Stream Triplet Siamese Network for Self-Supervised Action Recognition by Modeling Temporal Correlations\",\"url\":\"https://www.semanticscholar.org/paper/44c37249c9d4298d526f56435476311ff74106ff\",\"venue\":\"2020 IEEE 32nd International Conference on Tools with Artificial Intelligence (ICTAI)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31474374\",\"name\":\"P. Bilinski\"},{\"authorId\":\"34561667\",\"name\":\"Michal Koperski\"},{\"authorId\":\"40657086\",\"name\":\"Slawomir Bak\"},{\"authorId\":\"144103389\",\"name\":\"F. Br\\u00e9mond\"}],\"doi\":\"10.1109/AVSS.2014.6918649\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"400b3e50a977c49c7486b53a880aaee5ead108ff\",\"title\":\"Representing visual appearance by video Brownian covariance descriptor for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/400b3e50a977c49c7486b53a880aaee5ead108ff\",\"venue\":\"2014 11th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71102154\",\"name\":\"P. Sheeba\"},{\"authorId\":\"30720370\",\"name\":\"S. Murugan\"}],\"doi\":\"10.1080/13682199.2018.1483481\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"028cc0185a25adc5380e9a5bef6fa5e9cf9439fc\",\"title\":\"Hybrid features-enabled dragon deep belief neural network for activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/028cc0185a25adc5380e9a5bef6fa5e9cf9439fc\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144350547\",\"name\":\"Y. Qian\"},{\"authorId\":\"46609038\",\"name\":\"B. Sengupta\"}],\"doi\":\"10.1016/J.ROBOT.2019.04.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"37f188cf5a12c0a842516c87be994eb741473359\",\"title\":\"Pillar Networks: Combining parametric with non-parametric methods for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/37f188cf5a12c0a842516c87be994eb741473359\",\"venue\":\"Robotics Auton. Syst.\",\"year\":2019},{\"arxivId\":\"2003.07833\",\"authors\":[{\"authorId\":\"3347447\",\"name\":\"Sanath Narayan\"},{\"authorId\":\"2702234\",\"name\":\"A. Gupta\"},{\"authorId\":\"2358803\",\"name\":\"F. Khan\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"},{\"authorId\":\"40799321\",\"name\":\"Ling Shao\"}],\"doi\":\"10.1007/978-3-030-58542-6_29\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d9e98cbe813ead99c5f4f57be4ff6949fb51442a\",\"title\":\"Latent Embedding Feedback and Discriminative Features for Zero-Shot Classification\",\"url\":\"https://www.semanticscholar.org/paper/d9e98cbe813ead99c5f4f57be4ff6949fb51442a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46868809\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1720627\",\"name\":\"Lai Man Po\"},{\"authorId\":\"49354358\",\"name\":\"Mengyang Liu\"},{\"authorId\":\"6260845\",\"name\":\"Yasar Abbas Ur Rehman\"},{\"authorId\":\"144981001\",\"name\":\"W. Ou\"},{\"authorId\":\"103425198\",\"name\":\"Yuzhi Zhao\"}],\"doi\":\"10.1016/j.eswa.2020.113203\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"70ee88042c9bd87903b40b535973afecb6c2a49d\",\"title\":\"Data-level information enhancement: Motion-patch-based Siamese Convolutional Neural Networks for human activity recognition in videos\",\"url\":\"https://www.semanticscholar.org/paper/70ee88042c9bd87903b40b535973afecb6c2a49d\",\"venue\":\"Expert Syst. Appl.\",\"year\":2020},{\"arxivId\":\"1909.01939\",\"authors\":[{\"authorId\":\"48754312\",\"name\":\"Pengfei Zhang\"},{\"authorId\":\"3280033\",\"name\":\"J. Xue\"},{\"authorId\":\"40093162\",\"name\":\"Cuiling Lan\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"},{\"authorId\":\"2687716\",\"name\":\"Zhanning Gao\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"}],\"doi\":\"10.1109/TIP.2019.2937724\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1d0b8606483d6d9c1cdb5b8953bf61773bf633db\",\"title\":\"EleAtt-RNN: Adding Attentiveness to Neurons in Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/1d0b8606483d6d9c1cdb5b8953bf61773bf633db\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8092281\",\"name\":\"Hai-Hong Phan\"},{\"authorId\":\"9923528\",\"name\":\"Chi Trung Ha\"},{\"authorId\":\"47523551\",\"name\":\"T. T. Nguyen\"}],\"doi\":\"10.1109/MAPR49794.2020.9237772\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"14b22559f288a9ef8e1bac5f85855b00e3e28df1\",\"title\":\"Improving the efficiency of human action recognition using deep compression\",\"url\":\"https://www.semanticscholar.org/paper/14b22559f288a9ef8e1bac5f85855b00e3e28df1\",\"venue\":\"2020 International Conference on Multimedia Analysis and Pattern Recognition (MAPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35696058\",\"name\":\"Samitha Herath\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"23911916\",\"name\":\"Mehrtash Harandi\"}],\"doi\":\"10.1016/J.PATCOG.2019.106989\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"75e34c4d672344e76ec108aea21f93c04cacc314\",\"title\":\"Using temporal information for recognizing actions from still images\",\"url\":\"https://www.semanticscholar.org/paper/75e34c4d672344e76ec108aea21f93c04cacc314\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":\"1901.03107\",\"authors\":[{\"authorId\":\"7821695\",\"name\":\"Arpan Gupta\"},{\"authorId\":\"3247309\",\"name\":\"Sakthi Balan Muthiah\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cf1a4818504c6d62ac7c030003946dcfa6cd6d33\",\"title\":\"Cricket stroke extraction: Towards creation of a large-scale cricket actions dataset\",\"url\":\"https://www.semanticscholar.org/paper/cf1a4818504c6d62ac7c030003946dcfa6cd6d33\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"119924024\",\"name\":\"Yinan Liu\"},{\"authorId\":\"1702864\",\"name\":\"Q. Wu\"},{\"authorId\":\"2819089\",\"name\":\"L. Tang\"},{\"authorId\":\"3482320\",\"name\":\"Hengcan Shi\"}],\"doi\":\"10.1109/ACCESS.2017.2753830\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c90427085909029afd2af01d1967e80b78e01b88\",\"title\":\"Gaze-Assisted Multi-Stream Deep Neural Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c90427085909029afd2af01d1967e80b78e01b88\",\"venue\":\"IEEE Access\",\"year\":2017},{\"arxivId\":\"2006.15731\",\"authors\":[{\"authorId\":\"2931554\",\"name\":\"P. Tokmakov\"},{\"authorId\":\"33615817\",\"name\":\"M. Hebert\"},{\"authorId\":\"153433844\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"99b33c3b1a38aa4c2569abb98ca21759951849d5\",\"title\":\"Unsupervised Learning of Video Representations via Dense Trajectory Clustering\",\"url\":\"https://www.semanticscholar.org/paper/99b33c3b1a38aa4c2569abb98ca21759951849d5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3443095\",\"name\":\"Bruno Korbar\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c97774191be232678a45d343a25fcc0c96c065e7\",\"title\":\"Co-Training of Audio and Video Representations from Self-Supervised Temporal Synchronization\",\"url\":\"https://www.semanticscholar.org/paper/c97774191be232678a45d343a25fcc0c96c065e7\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66275285\",\"name\":\"Hemerson Tacon\"},{\"authorId\":\"51519347\",\"name\":\"A. Brito\"},{\"authorId\":\"67244903\",\"name\":\"H. Chaves\"},{\"authorId\":\"3052490\",\"name\":\"M. Vieira\"},{\"authorId\":\"3387755\",\"name\":\"S. Villela\"},{\"authorId\":\"8125221\",\"name\":\"H. Maia\"},{\"authorId\":\"66088742\",\"name\":\"Darwin Ttito Concha\"},{\"authorId\":\"1743455\",\"name\":\"H. Pedrini\"}],\"doi\":\"10.1007/978-3-030-24289-3_26\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a2c302047b5c0b66e0be4594200006d93c30c565\",\"title\":\"Human Action Recognition Using Convolutional Neural Networks with Symmetric Time Extension of Visual Rhythms\",\"url\":\"https://www.semanticscholar.org/paper/a2c302047b5c0b66e0be4594200006d93c30c565\",\"venue\":\"ICCSA\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12100407\",\"name\":\"S. Rahman\"},{\"authorId\":\"143937986\",\"name\":\"John See\"},{\"authorId\":\"2864328\",\"name\":\"Chiung Ching Ho\"}],\"doi\":\"10.1186/S13640-017-0221-2\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9919331e3e4da379840d9185827fedc68409cca5\",\"title\":\"Exploiting textures for better action recognition in low-quality videos\",\"url\":\"https://www.semanticscholar.org/paper/9919331e3e4da379840d9185827fedc68409cca5\",\"venue\":\"EURASIP J. Image Video Process.\",\"year\":2017},{\"arxivId\":\"2003.06141\",\"authors\":[{\"authorId\":\"50993183\",\"name\":\"Haochen Zhang\"},{\"authorId\":\"50439333\",\"name\":\"DongSheng Liu\"},{\"authorId\":\"2352456\",\"name\":\"Z. Xiong\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5712e1775e06cdedcb23d5abb624874334b8e22f\",\"title\":\"Is There Tradeoff between Spatial and Temporal in Video Super-Resolution?\",\"url\":\"https://www.semanticscholar.org/paper/5712e1775e06cdedcb23d5abb624874334b8e22f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e6435837116d2d08d4f873e2b556c29a4d20812d\",\"title\":\"Holistic Large Scale Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/e6435837116d2d08d4f873e2b556c29a4d20812d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145895173\",\"name\":\"Asanka G. Perera\"},{\"authorId\":\"1728907\",\"name\":\"Y. W. Law\"},{\"authorId\":\"101386498\",\"name\":\"T. T. Ogunwa\"},{\"authorId\":\"144608860\",\"name\":\"J. Chahl\"}],\"doi\":\"10.1109/THMS.2020.2971958\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3607e34e0d66e7fe4189d0c3e385fd61e4e07aa6\",\"title\":\"A Multiviewpoint Outdoor Dataset for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3607e34e0d66e7fe4189d0c3e385fd61e4e07aa6\",\"venue\":\"IEEE Transactions on Human-Machine Systems\",\"year\":2020},{\"arxivId\":\"2006.03876\",\"authors\":[{\"authorId\":\"9734988\",\"name\":\"Yuecong Xu\"},{\"authorId\":\"2562263\",\"name\":\"Jianfei Yang\"},{\"authorId\":\"153420733\",\"name\":\"Haozhi Cao\"},{\"authorId\":\"120974533\",\"name\":\"Kezhi Mao\"},{\"authorId\":\"2037059\",\"name\":\"Jian-Xiong Yin\"},{\"authorId\":\"144308998\",\"name\":\"S. See\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e30fd64c9659c8cc6b28d37d19395752aae89130\",\"title\":\"ARID: A New Dataset for Recognizing Action in the Dark\",\"url\":\"https://www.semanticscholar.org/paper/e30fd64c9659c8cc6b28d37d19395752aae89130\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145732825\",\"name\":\"Xiaoqiang Yan\"},{\"authorId\":\"2382085\",\"name\":\"Y. Ye\"},{\"authorId\":\"21862760\",\"name\":\"Xueying Qiu\"},{\"authorId\":\"48544078\",\"name\":\"Hui Yu\"}],\"doi\":\"10.1016/j.inffus.2019.10.006\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3e19f3d34bcc14e220a300f27d24f20888cbb04d\",\"title\":\"Synergetic information bottleneck for joint multi-view and ensemble clustering\",\"url\":\"https://www.semanticscholar.org/paper/3e19f3d34bcc14e220a300f27d24f20888cbb04d\",\"venue\":\"Inf. Fusion\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145746387\",\"name\":\"Xin Jin\"},{\"authorId\":\"143912275\",\"name\":\"Zhibo Chen\"},{\"authorId\":\"89187407\",\"name\":\"W. Li\"}],\"doi\":\"10.1016/j.patcog.2019.107143\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cc2c28f85fcc6380e759a92c6d85aab11b693e83\",\"title\":\"AI-GAN: Asynchronous interactive generative adversarial network for single image rain removal\",\"url\":\"https://www.semanticscholar.org/paper/cc2c28f85fcc6380e759a92c6d85aab11b693e83\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":\"2010.06647\",\"authors\":[{\"authorId\":\"153634296\",\"name\":\"Matthew Hutchinson\"},{\"authorId\":\"74882299\",\"name\":\"Vijay Gadepally\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"65955a106905afb90a2a2fa74e48c6d6d597892f\",\"title\":\"Video Action Understanding: A Tutorial\",\"url\":\"https://www.semanticscholar.org/paper/65955a106905afb90a2a2fa74e48c6d6d597892f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40478348\",\"name\":\"Dong Cao\"},{\"authorId\":\"49287317\",\"name\":\"Lisha Xu\"},{\"authorId\":\"144934143\",\"name\":\"Dongdong Zhang\"}],\"doi\":\"10.1145/3371425.3371491\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4273282e911323957c9b885231658ca592612bee\",\"title\":\"Cross-enhancement transform two-stream 3D ConvNets for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/4273282e911323957c9b885231658ca592612bee\",\"venue\":\"AIIPCC '19\",\"year\":2019},{\"arxivId\":\"1902.10024\",\"authors\":[{\"authorId\":\"143884578\",\"name\":\"W. McNally\"},{\"authorId\":\"144821966\",\"name\":\"A. Wong\"},{\"authorId\":\"144304939\",\"name\":\"J. McPhee\"}],\"doi\":\"10.1109/CRV.2019.00015\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"bf3e15a9392621c45da6141a78a60d341ab2e506\",\"title\":\"STAR-Net: Action Recognition using Spatio-Temporal Activation Reprojection\",\"url\":\"https://www.semanticscholar.org/paper/bf3e15a9392621c45da6141a78a60d341ab2e506\",\"venue\":\"2019 16th Conference on Computer and Robot Vision (CRV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8549944\",\"name\":\"J. Li\"},{\"authorId\":\"6820648\",\"name\":\"Xianglong Liu\"},{\"authorId\":\"47473953\",\"name\":\"Mingyuan Zhang\"},{\"authorId\":\"47859105\",\"name\":\"De-qing Wang\"}],\"doi\":\"10.1016/j.patcog.2019.107037\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ec7d8bd083690391c0a40800321554f3a55a2125\",\"title\":\"Spatio-temporal deformable 3D ConvNets with attention for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/ec7d8bd083690391c0a40800321554f3a55a2125\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2695601\",\"name\":\"Vadim Kantorov\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"}],\"doi\":\"10.1109/CVPR.2014.332\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"482f7471c708f371cbd7658aa4a48187dc830e17\",\"title\":\"Efficient Feature Extraction, Encoding, and Classification for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/482f7471c708f371cbd7658aa4a48187dc830e17\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3095774\",\"name\":\"Dan Oneata\"},{\"authorId\":\"1721683\",\"name\":\"J. Verbeek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/CVPR.2014.326\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"19aa7a6f8709f2e7b4341a43c45edfe4e1964ca5\",\"title\":\"Efficient Action Localization with Approximately Normalized Fisher Vectors\",\"url\":\"https://www.semanticscholar.org/paper/19aa7a6f8709f2e7b4341a43c45edfe4e1964ca5\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1807.04445\",\"authors\":[{\"authorId\":\"48754312\",\"name\":\"Pengfei Zhang\"},{\"authorId\":\"3280033\",\"name\":\"J. Xue\"},{\"authorId\":\"40093162\",\"name\":\"Cuiling Lan\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"},{\"authorId\":\"2687716\",\"name\":\"Zhanning Gao\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"}],\"doi\":\"10.1007/978-3-030-01240-3_9\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"04791b727d0b0820d110288546fa5d3fb5528a63\",\"title\":\"Adding Attentiveness to the Neurons in Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/04791b727d0b0820d110288546fa5d3fb5528a63\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40354734\",\"name\":\"Haoze Wu\"},{\"authorId\":\"51260253\",\"name\":\"Z. Zha\"},{\"authorId\":\"145919634\",\"name\":\"X. Wen\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"},{\"authorId\":\"153626293\",\"name\":\"Dong Liu\"},{\"authorId\":\"46772808\",\"name\":\"X. Chen\"}],\"doi\":\"10.1145/3343031.3350891\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b725e11efdc4b4bd367e555dd2a70530b9002c68\",\"title\":\"Cross-Fiber Spatial-Temporal Co-enhanced Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b725e11efdc4b4bd367e555dd2a70530b9002c68\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1379882732\",\"name\":\"L. Tani\"},{\"authorId\":\"2512422\",\"name\":\"Abdelghani Ghomari\"},{\"authorId\":\"2782248\",\"name\":\"M. Y. K. Tani\"}],\"doi\":\"10.5194/isprs-archives-xlii-2-w16-135-2019\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4823216083b8fbab8e246dc0867f2aac4718bc32\",\"title\":\"EVENTS RECOGNITION FOR A SEMI-AUTOMATIC ANNOTATION OF SOCCER VIDEOS: A STUDY BASED DEEP LEARNING\",\"url\":\"https://www.semanticscholar.org/paper/4823216083b8fbab8e246dc0867f2aac4718bc32\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1703.09913\",\"authors\":[{\"authorId\":\"28798386\",\"name\":\"H. Doughty\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"},{\"authorId\":\"1398236231\",\"name\":\"W. Mayol-Cuevas\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"503db524b9a99220d430e741c44cd9c91ce1ddf8\",\"title\":\"Who's Better, Who's Best: Skill Determination in Video using Deep Ranking\",\"url\":\"https://www.semanticscholar.org/paper/503db524b9a99220d430e741c44cd9c91ce1ddf8\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92599875\",\"name\":\"M. Nadeem\"},{\"authorId\":\"1828728\",\"name\":\"V. N. L. Franqueira\"},{\"authorId\":\"1881146\",\"name\":\"X. Zhai\"},{\"authorId\":\"1741168\",\"name\":\"F. Kurugollu\"}],\"doi\":\"10.1109/ACCESS.2019.2924733\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"255485196a869c98aacce60a86074fccf07c01eb\",\"title\":\"A Survey of Deep Learning Solutions for Multimedia Visual Content Analysis\",\"url\":\"https://www.semanticscholar.org/paper/255485196a869c98aacce60a86074fccf07c01eb\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1802.04962\",\"authors\":[{\"authorId\":\"40622539\",\"name\":\"Dong-Jin Kim\"},{\"authorId\":\"49331178\",\"name\":\"Jinsoo Choi\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"2242116\",\"name\":\"Youngjin Yoon\"},{\"authorId\":\"2398271\",\"name\":\"In-So Kweon\"}],\"doi\":\"10.1109/WACV.2018.00189\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a92b5234b8b73e06709dd48ec5f0ec357c1aabed\",\"title\":\"Disjoint Multi-task Learning Between Heterogeneous Human-Centric Tasks\",\"url\":\"https://www.semanticscholar.org/paper/a92b5234b8b73e06709dd48ec5f0ec357c1aabed\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":\"1906.05571\",\"authors\":[{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"143977389\",\"name\":\"C. Ngo\"},{\"authorId\":\"40434674\",\"name\":\"X. Tian\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2019.01233\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e65e8c434895601b27cda0bef9b1bd9ff1475bf3\",\"title\":\"Learning Spatio-Temporal Representation With Local and Global Diffusion\",\"url\":\"https://www.semanticscholar.org/paper/e65e8c434895601b27cda0bef9b1bd9ff1475bf3\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2005.04366\",\"authors\":[{\"authorId\":\"1471722186\",\"name\":\"Miao Yin\"},{\"authorId\":\"145657535\",\"name\":\"Siyu Liao\"},{\"authorId\":\"4029028\",\"name\":\"Xiao-Yang Liu\"},{\"authorId\":\"48632004\",\"name\":\"X. Wang\"},{\"authorId\":\"1471729588\",\"name\":\"Bo Yuan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d2f5c589662c42b0956d2b410f8dcbfaf174bf5b\",\"title\":\"Compressing Recurrent Neural Networks Using Hierarchical Tucker Tensor Decomposition\",\"url\":\"https://www.semanticscholar.org/paper/d2f5c589662c42b0956d2b410f8dcbfaf174bf5b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145607579\",\"name\":\"J. Byrne\"}],\"doi\":\"10.1109/CVPR.2015.7298648\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"bc6d4b6a58ff16ee064da2bc275892a07bbef54e\",\"title\":\"Nested motion descriptors\",\"url\":\"https://www.semanticscholar.org/paper/bc6d4b6a58ff16ee064da2bc275892a07bbef54e\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2518212\",\"name\":\"Hakan Bilen\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"1bbec7190ac3ba34ca91d28f145e356a11418b67\",\"title\":\"Explorer Action Recognition with Dynamic Image Networks\",\"url\":\"https://www.semanticscholar.org/paper/1bbec7190ac3ba34ca91d28f145e356a11418b67\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151507225\",\"name\":\"Qi Yuan\"},{\"authorId\":\"145121526\",\"name\":\"J. Wan\"},{\"authorId\":\"10290688\",\"name\":\"C. Lin\"},{\"authorId\":\"50025139\",\"name\":\"Yunan Li\"},{\"authorId\":\"8254330\",\"name\":\"Qiguang Miao\"},{\"authorId\":\"34679741\",\"name\":\"S. Li\"},{\"authorId\":\"39816921\",\"name\":\"Lihua Wang\"},{\"authorId\":\"47006135\",\"name\":\"Yunxiang Lu\"}],\"doi\":\"10.1007/978-3-030-31456-9_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5ebb7a9439326ec0bbfd7364177ba34a8848aacb\",\"title\":\"Global and Local Spatial-Attention Network for Isolated Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5ebb7a9439326ec0bbfd7364177ba34a8848aacb\",\"venue\":\"CCBR\",\"year\":2019},{\"arxivId\":\"1912.05534\",\"authors\":[{\"authorId\":\"150140884\",\"name\":\"Jin-Woo Choi\"},{\"authorId\":\"49281242\",\"name\":\"C. Gao\"},{\"authorId\":\"79959317\",\"name\":\"Joseph C.E. Messou\"},{\"authorId\":\"3068086\",\"name\":\"Jia-Bin Huang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"439fd498e7b682dea5aa7e910267c10bf2ccb722\",\"title\":\"Why Can't I Dance in the Mall? Learning to Mitigate Scene Bias in Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/439fd498e7b682dea5aa7e910267c10bf2ccb722\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144082568\",\"name\":\"Liangliang Wang\"},{\"authorId\":\"39975036\",\"name\":\"R. Li\"},{\"authorId\":\"40630660\",\"name\":\"Y. Fang\"}],\"doi\":\"10.1117/1.OE.55.4.043109\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3b4955b3ed0bce983843c972f433dfafbd07e534\",\"title\":\"Energy flow: image correspondence approximation for motion analysis\",\"url\":\"https://www.semanticscholar.org/paper/3b4955b3ed0bce983843c972f433dfafbd07e534\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49417387\",\"name\":\"Y. Wang\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"49897466\",\"name\":\"Xiaotian Zhu\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"}],\"doi\":\"10.1109/ICMEW.2018.8551526\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"35cbb64d46dfa3e74aea367a173dcb94cb6125c4\",\"title\":\"Weighted Multi-Region Convolutional Neural Network for Action Recognition With Low-Latency Online Prediction\",\"url\":\"https://www.semanticscholar.org/paper/35cbb64d46dfa3e74aea367a173dcb94cb6125c4\",\"venue\":\"2018 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47987957\",\"name\":\"J. Yang\"},{\"authorId\":\"7947723\",\"name\":\"Zhongke Shi\"},{\"authorId\":\"3311781\",\"name\":\"Z. Wu\"}],\"doi\":\"10.22260/ISARC2015/0007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d0c9abe04cf25e0a15486bce8f92b82b3c0f3813\",\"title\":\"Automatic Recognition of Construction Worker Activities Using Dense Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/d0c9abe04cf25e0a15486bce8f92b82b3c0f3813\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7466378\",\"name\":\"Jia-xin Cai\"},{\"authorId\":\"145653036\",\"name\":\"Xin Tang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0d312a9557b41414d7ee4da47a2e58ef0ed1e9d0\",\"title\":\"RGB Video Based Tennis Action Recognition Using a Deep Weighted Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/0d312a9557b41414d7ee4da47a2e58ef0ed1e9d0\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1901.09403\",\"authors\":[{\"authorId\":\"41049768\",\"name\":\"Amlaan Bhoi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"76c67fb26e0c48efa4062bb9f288a1ceb8b332ee\",\"title\":\"Spatio-temporal Action Recognition: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/76c67fb26e0c48efa4062bb9f288a1ceb8b332ee\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50854337\",\"name\":\"D. Xu\"},{\"authorId\":\"145974111\",\"name\":\"Jun Xiao\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"144899815\",\"name\":\"J. Shao\"},{\"authorId\":\"145982709\",\"name\":\"Di Xie\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1109/CVPR.2019.01058\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"558aeb7aa38cfcf8dd9951bfd24cf77972bd09aa\",\"title\":\"Self-Supervised Spatiotemporal Learning via Video Clip Order Prediction\",\"url\":\"https://www.semanticscholar.org/paper/558aeb7aa38cfcf8dd9951bfd24cf77972bd09aa\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1696573\",\"name\":\"Jiagang Zhu\"},{\"authorId\":\"9276071\",\"name\":\"Wei Zou\"},{\"authorId\":\"49659001\",\"name\":\"Zheng Zhu\"},{\"authorId\":\"97474510\",\"name\":\"L. Xu\"},{\"authorId\":\"153940079\",\"name\":\"Guan Huang\"}],\"doi\":\"10.1109/LSP.2019.2942739\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d45d6e1625af82c656ee9cc6d98fd7f58c923636\",\"title\":\"Action Machine: Toward Person-Centric Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/d45d6e1625af82c656ee9cc6d98fd7f58c923636\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2757212\",\"name\":\"L. Fan\"},{\"authorId\":\"49069534\",\"name\":\"Yixin Chen\"},{\"authorId\":\"145708707\",\"name\":\"P. Wei\"},{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/CVPR.2018.00676\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"037ad2159097dcb7ff29b6c328b859fb64f7078e\",\"title\":\"Inferring Shared Attention in Social Scene Videos\",\"url\":\"https://www.semanticscholar.org/paper/037ad2159097dcb7ff29b6c328b859fb64f7078e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29329124\",\"name\":\"Andreas S. Panayides\"},{\"authorId\":\"1716947\",\"name\":\"C. Pattichis\"},{\"authorId\":\"47293698\",\"name\":\"M. Pattichis\"}],\"doi\":\"10.1109/ACSSC.2016.7869579\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"097d6bbb830e878ebd3d2aab7bb64d20b49132f7\",\"title\":\"The promise of big data technologies and challenges for image and video analytics in healthcare\",\"url\":\"https://www.semanticscholar.org/paper/097d6bbb830e878ebd3d2aab7bb64d20b49132f7\",\"venue\":\"2016 50th Asilomar Conference on Signals, Systems and Computers\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"144154444\",\"name\":\"Marcus Hutter\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1109/CVPR.2016.212\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"641421832f237b280644261a77eca3974ac9c0c1\",\"title\":\"Discriminative Hierarchical Rank Pooling for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/641421832f237b280644261a77eca3974ac9c0c1\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145742542\",\"name\":\"W. Li\"},{\"authorId\":\"144536247\",\"name\":\"Weizhi Nie\"},{\"authorId\":\"2788104\",\"name\":\"Yuting Su\"}],\"doi\":\"10.1109/ACCESS.2018.2863943\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"cd22e6532211f679ba6057d15a801ba448b9915c\",\"title\":\"Human Action Recognition Based on Selected Spatio-Temporal Features via Bidirectional LSTM\",\"url\":\"https://www.semanticscholar.org/paper/cd22e6532211f679ba6057d15a801ba448b9915c\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":\"1906.04226\",\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"1403581832\",\"name\":\"Laura Sevilla-Lara\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"},{\"authorId\":\"143907244\",\"name\":\"Yi Yang\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"8a71b7cf982cf1b54cda4f0746d4ba7c7ea3f4e4\",\"title\":\"FASTER Recurrent Networks for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/8a71b7cf982cf1b54cda4f0746d4ba7c7ea3f4e4\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1806.07754\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"2713759\",\"name\":\"M. M. Arzani\"},{\"authorId\":\"9456273\",\"name\":\"Rahman Yousefzadeh\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-030-01225-0_18\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"85fb0d6cc991cf49ebc4f506b5edd44214979f65\",\"title\":\"Spatio-Temporal Channel Correlation Networks for Action Classification\",\"url\":\"https://www.semanticscholar.org/paper/85fb0d6cc991cf49ebc4f506b5edd44214979f65\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39974958\",\"name\":\"T. Yu\"},{\"authorId\":\"46660013\",\"name\":\"L. Wang\"},{\"authorId\":\"49610443\",\"name\":\"Cheng Da\"},{\"authorId\":\"1909131\",\"name\":\"Huxiang Gu\"},{\"authorId\":\"1683738\",\"name\":\"S. Xiang\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.1109/TMM.2019.2907060\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"53dc8bbc0ccf39b916e0833edeef63fa09eea43c\",\"title\":\"Weakly Semantic Guided Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/53dc8bbc0ccf39b916e0833edeef63fa09eea43c\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144708945\",\"name\":\"Yang Du\"},{\"authorId\":null,\"name\":\"Chunfeng Yuan\"},{\"authorId\":null,\"name\":\"Bing Li\"},{\"authorId\":\"40506509\",\"name\":\"W. Hu\"},{\"authorId\":\"40566477\",\"name\":\"H. Yang\"},{\"authorId\":\"2937291\",\"name\":\"Zhikang Fu\"},{\"authorId\":\"48096213\",\"name\":\"L. Zhao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"290b8a2fb39043d98cad6bb97595f7d79e394ba4\",\"title\":\"Hierarchical Nonlinear Orthogonal Adaptive-Subspace Self-Organizing Map Based Feature Extraction for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/290b8a2fb39043d98cad6bb97595f7d79e394ba4\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2420123\",\"name\":\"D. Dwibedi\"},{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"},{\"authorId\":\"2704494\",\"name\":\"J. Tompson\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2e927d0a2dc4b69fc03124ad876329b22a61f1b0\",\"title\":\"Temporal Reasoning in Videos Using Convolutional Gated Recurrent Units\",\"url\":\"https://www.semanticscholar.org/paper/2e927d0a2dc4b69fc03124ad876329b22a61f1b0\",\"venue\":\"CVPR Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144178916\",\"name\":\"D. Singh\"},{\"authorId\":\"70611576\",\"name\":\"C. Krishnamohan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d9682721c441899752d82bfe66a296cca986669\",\"title\":\"SCALABALE AND DISTRIBUTED METHODS FORLARGE-SCALE VISUAL COMPUTING\",\"url\":\"https://www.semanticscholar.org/paper/4d9682721c441899752d82bfe66a296cca986669\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3114252\",\"name\":\"O. Sener\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"1702137\",\"name\":\"S. Savarese\"},{\"authorId\":\"48473045\",\"name\":\"A. Saxena\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9ae19caad6a1cac362b979992e8fac77221ebf85\",\"title\":\"Unsupervised Activity Learning and Parsing Learned Action 1 : Selected Visual Atoms : Selected Language Atoms\",\"url\":\"https://www.semanticscholar.org/paper/9ae19caad6a1cac362b979992e8fac77221ebf85\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2010.15464\",\"authors\":[{\"authorId\":\"1720851638\",\"name\":\"Li Tao\"},{\"authorId\":\"1524733293\",\"name\":\"Xueting Wang\"},{\"authorId\":\"145572095\",\"name\":\"T. Yamasaki\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"5ada370b12a174a45b27c2e40d01cd47155bb9d4\",\"title\":\"Self-Supervised Video Representation Using Pretext-Contrastive Learning\",\"url\":\"https://www.semanticscholar.org/paper/5ada370b12a174a45b27c2e40d01cd47155bb9d4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1810.08375\",\"authors\":[{\"authorId\":\"46314731\",\"name\":\"W. Wang\"},{\"authorId\":\"47096329\",\"name\":\"Yongjian Wu\"},{\"authorId\":\"8424682\",\"name\":\"H. Liu\"},{\"authorId\":\"2019481\",\"name\":\"S. Wang\"},{\"authorId\":\"144569553\",\"name\":\"Jian Cheng\"}],\"doi\":\"10.1109/ICPR.2018.8545487\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"211b35befe51baf018e971d53d3c35cacbe6ad3e\",\"title\":\"Temporal Action Detection by Joint Identification-Verification\",\"url\":\"https://www.semanticscholar.org/paper/211b35befe51baf018e971d53d3c35cacbe6ad3e\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47909495\",\"name\":\"Y. Liu\"},{\"authorId\":\"1782417\",\"name\":\"Jian-Jiun Ding\"},{\"authorId\":\"144263130\",\"name\":\"Y. Chang\"},{\"authorId\":\"2423297\",\"name\":\"Chien-Yao Wang\"},{\"authorId\":\"3205648\",\"name\":\"J. Wang\"}],\"doi\":\"10.1109/ICCE-CHINA.2017.7991006\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f11e10d1b13ad0c4976835212ff3c8bac2304dba\",\"title\":\"Action recognition using three dimension convolution and long short term memory\",\"url\":\"https://www.semanticscholar.org/paper/f11e10d1b13ad0c4976835212ff3c8bac2304dba\",\"venue\":\"2017 IEEE International Conference on Consumer Electronics - Taiwan (ICCE-TW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"94567368\",\"name\":\"C. Sun\"},{\"authorId\":\"9943923\",\"name\":\"Fabien Baradel\"},{\"authorId\":\"144816684\",\"name\":\"K. Murphy\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"025a0dc4a2a98742f1b410b6318a46de2c854b22\",\"title\":\"Learning Video Representations using Contrastive Bidirectional Transformer\",\"url\":\"https://www.semanticscholar.org/paper/025a0dc4a2a98742f1b410b6318a46de2c854b22\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1807.11195\",\"authors\":[{\"authorId\":\"1713312\",\"name\":\"Y. Chen\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"65737740\",\"name\":\"J. Li\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":\"10.1007/978-3-030-01246-5_22\",\"intent\":[\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"fe82d072a8d13cfefcd575db893f3374251f04a8\",\"title\":\"Multi-Fiber Networks for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fe82d072a8d13cfefcd575db893f3374251f04a8\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1812.02699\",\"authors\":[{\"authorId\":\"47368718\",\"name\":\"R. T. Mullapudi\"},{\"authorId\":\"50357985\",\"name\":\"S. Chen\"},{\"authorId\":\"2040033\",\"name\":\"Keyi Zhang\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"2789576\",\"name\":\"K. Fatahalian\"}],\"doi\":\"10.1109/ICCV.2019.00367\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"669c2655f2d09d5d18b1dd25723f3a3a4cc4937d\",\"title\":\"Online Model Distillation for Efficient Video Inference\",\"url\":\"https://www.semanticscholar.org/paper/669c2655f2d09d5d18b1dd25723f3a3a4cc4937d\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"82957042\",\"name\":\"K. Abe\"},{\"authorId\":\"40984574\",\"name\":\"Chikara Nakamura\"},{\"authorId\":\"3177909\",\"name\":\"Yosuke Otsubo\"},{\"authorId\":\"31432119\",\"name\":\"T. Koike\"},{\"authorId\":\"6611386\",\"name\":\"N. Yokoya\"}],\"doi\":\"10.1145/3347318.3355521\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"74f4225b1303d4c491f76556787a5250d9ed2710\",\"title\":\"Spectator Excitement Detection in Small-scale Sports Events\",\"url\":\"https://www.semanticscholar.org/paper/74f4225b1303d4c491f76556787a5250d9ed2710\",\"venue\":\"MMSports '19\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49897080\",\"name\":\"Claudia Latella\"},{\"authorId\":\"31153432\",\"name\":\"M. Lorenzini\"},{\"authorId\":\"47424488\",\"name\":\"M. Lazzaroni\"},{\"authorId\":\"145549279\",\"name\":\"F. Romano\"},{\"authorId\":\"2255650\",\"name\":\"Silvio Traversaro\"},{\"authorId\":\"41173796\",\"name\":\"M. A. Akhras\"},{\"authorId\":\"2202742\",\"name\":\"Daniele Pucci\"},{\"authorId\":\"1692768\",\"name\":\"F. Nori\"}],\"doi\":\"10.1007/S10514-018-9808-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"80fa97333d239990752c8a663fe13088781b68f5\",\"title\":\"Towards real-time whole-body human dynamics estimation through probabilistic sensor fusion algorithms\",\"url\":\"https://www.semanticscholar.org/paper/80fa97333d239990752c8a663fe13088781b68f5\",\"venue\":\"Auton. Robots\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"13088433\",\"name\":\"Mahshid Majd\"},{\"authorId\":\"1682051\",\"name\":\"R. Safabakhsh\"}],\"doi\":\"10.1007/s10489-018-1395-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c213ea6f39e3c595fc383b43ac9e813ce1c728ae\",\"title\":\"A motion-aware ConvLSTM network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/c213ea6f39e3c595fc383b43ac9e813ce1c728ae\",\"venue\":\"Applied Intelligence\",\"year\":2018},{\"arxivId\":\"1512.09041\",\"authors\":[{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1109/CVPR.2016.336\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1bac3ed8deec94196170ad89931c419ce3ff14b5\",\"title\":\"Actor-Action Semantic Segmentation with Grouping Process Models\",\"url\":\"https://www.semanticscholar.org/paper/1bac3ed8deec94196170ad89931c419ce3ff14b5\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23278631\",\"name\":\"Guangle Yao\"},{\"authorId\":\"144673774\",\"name\":\"T. Lei\"},{\"authorId\":\"23227806\",\"name\":\"Jiandan Zhong\"}],\"doi\":\"10.1016/j.patrec.2018.05.018\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2c12495bfb2f47881191ce0cb672f0372c6a31e2\",\"title\":\"A review of Convolutional-Neural-Network-based action recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c12495bfb2f47881191ce0cb672f0372c6a31e2\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4697712\",\"name\":\"Z. Zhu\"},{\"authorId\":\"1696842\",\"name\":\"Hongbing Ji\"},{\"authorId\":\"1786198\",\"name\":\"W. Zhang\"},{\"authorId\":\"1757932\",\"name\":\"Yiping Xu\"}],\"doi\":\"10.1016/j.neucom.2018.08.018\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d92ff82c1b78cfbf2b9c8f65768ad9e4e3d1f47c\",\"title\":\"Rank pooling dynamic network: Learning end-to-end dynamic characteristic for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/d92ff82c1b78cfbf2b9c8f65768ad9e4e3d1f47c\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1689047\",\"name\":\"V. Argyriou\"},{\"authorId\":\"2248667\",\"name\":\"J. Rinc\\u00f3n\"},{\"authorId\":\"2866802\",\"name\":\"Barbara Villarini\"},{\"authorId\":\"35258531\",\"name\":\"A. Roche\"}],\"doi\":\"10.1002/9781118702451.CH2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"49de9f0b7b7c03a36d8d9267f059e5fd9df3cbdc\",\"title\":\"2. Registration for Video Coding\",\"url\":\"https://www.semanticscholar.org/paper/49de9f0b7b7c03a36d8d9267f059e5fd9df3cbdc\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1810.04511\",\"authors\":[{\"authorId\":\"48153708\",\"name\":\"L. Meng\"},{\"authorId\":\"143946810\",\"name\":\"Bo Zhao\"},{\"authorId\":\"144757437\",\"name\":\"B. Chang\"},{\"authorId\":\"143983679\",\"name\":\"Gao Huang\"},{\"authorId\":\"2123865\",\"name\":\"F. Tung\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b613ea6c4fb5efdf17af090d64e9bdce41e28711\",\"title\":\"Where and When to Look? Spatio-temporal Attention for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/b613ea6c4fb5efdf17af090d64e9bdce41e28711\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Nannan Li\"},{\"authorId\":\"49024484\",\"name\":\"J. Huang\"},{\"authorId\":\"50289966\",\"name\":\"Thomas H. Li\"},{\"authorId\":\"2750523\",\"name\":\"Huiwen Guo\"},{\"authorId\":\"47949235\",\"name\":\"G. Li\"}],\"doi\":\"10.1016/j.neucom.2018.05.033\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"de2cda38655d3f216430969b5b864b96c1b011c1\",\"title\":\"Detecting action tubes via spatial action estimation and temporal path inference\",\"url\":\"https://www.semanticscholar.org/paper/de2cda38655d3f216430969b5b864b96c1b011c1\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":\"1705.03148\",\"authors\":[{\"authorId\":\"144388361\",\"name\":\"C. Li\"},{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"1740430\",\"name\":\"B. Zhang\"},{\"authorId\":\"1694936\",\"name\":\"Q. Ye\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"},{\"authorId\":\"145592290\",\"name\":\"R. Ji\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b191aa2c5b8ece06c221c3a4a0914e8157a16129\",\"title\":\"Deep Spatio-temporal Manifold Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b191aa2c5b8ece06c221c3a4a0914e8157a16129\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145466505\",\"name\":\"M. Sapienza\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"}],\"doi\":\"10.1007/s11263-013-0662-8\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"391fb47efd6bcd2f1c0331f6333951ef167bc24a\",\"title\":\"Learning Discriminative Space\\u2013Time Action Parts from Weakly Labelled Videos\",\"url\":\"https://www.semanticscholar.org/paper/391fb47efd6bcd2f1c0331f6333951ef167bc24a\",\"venue\":\"International Journal of Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49854448\",\"name\":\"A. Fire\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/CVPRW.2017.13\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c15b68986ecfa1e13e3791686ae9024f66983f14\",\"title\":\"Inferring Hidden Statuses and Actions in Video by Causal Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/c15b68986ecfa1e13e3791686ae9024f66983f14\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41155786\",\"name\":\"Silvia Vinyes Mora\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"63a430de2d3c4fd19436d5685afc5abde6a90bba\",\"title\":\"Computer vision and machine learning for in-play tennis analysis: framework, algorithms and implementation\",\"url\":\"https://www.semanticscholar.org/paper/63a430de2d3c4fd19436d5685afc5abde6a90bba\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3633358\",\"name\":\"Sebastian Lapuschkin\"}],\"doi\":\"10.14279/DEPOSITONCE-7942\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c601b185b6080ded463d3c236fa4f9f849f0435b\",\"title\":\"Opening the machine learning black box with Layer-wise Relevance Propagation\",\"url\":\"https://www.semanticscholar.org/paper/c601b185b6080ded463d3c236fa4f9f849f0435b\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40574171\",\"name\":\"S. Bhattacharya\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"566f845c8cca8760fd29e6fe5138bb4f50f0d495\",\"title\":\"Recognition of Complex Events in Open-source Web-scale Videos: Features, Intermediate Representations and Their Temporal Interactions\",\"url\":\"https://www.semanticscholar.org/paper/566f845c8cca8760fd29e6fe5138bb4f50f0d495\",\"venue\":\"\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a87ab836771164adb95d6744027e62e05f47fd96\",\"title\":\"Understanding human-human interactions: a survey\",\"url\":\"https://www.semanticscholar.org/paper/a87ab836771164adb95d6744027e62e05f47fd96\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144783760\",\"name\":\"P. Agust\\u00ed\"},{\"authorId\":\"2247964\",\"name\":\"V. Traver\"},{\"authorId\":\"145381934\",\"name\":\"F. Pla\"}],\"doi\":\"10.1016/j.patrec.2014.07.014\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e0560139ef36521a652c9affc17879c8f1e01a61\",\"title\":\"Bag-of-words with aggregated temporal pair-wise word co-occurrence for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/e0560139ef36521a652c9affc17879c8f1e01a61\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743797\",\"name\":\"I. Guyon\"},{\"authorId\":\"1720747\",\"name\":\"V. Athitsos\"},{\"authorId\":\"1721651\",\"name\":\"Pat Jangyodsuk\"},{\"authorId\":\"1742688\",\"name\":\"H. Escalante\"}],\"doi\":\"10.1007/s00138-014-0596-3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"01b22a3a096df88a2c123e04c43c60e5888ab555\",\"title\":\"The ChaLearn gesture dataset (CGD 2011)\",\"url\":\"https://www.semanticscholar.org/paper/01b22a3a096df88a2c123e04c43c60e5888ab555\",\"venue\":\"Machine Vision and Applications\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21570451\",\"name\":\"A. Barbu\"},{\"authorId\":\"2089428\",\"name\":\"D. P. Barrett\"},{\"authorId\":\"50504401\",\"name\":\"Wei Chen\"},{\"authorId\":\"38052303\",\"name\":\"S. Narayanaswamy\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"},{\"authorId\":\"2663295\",\"name\":\"Christiane D. Fellbaum\"},{\"authorId\":\"145323459\",\"name\":\"Catherine Hanson\"},{\"authorId\":\"1727849\",\"name\":\"S. Hanson\"},{\"authorId\":\"1772825\",\"name\":\"S. H\\u00e9lie\"},{\"authorId\":\"20009336\",\"name\":\"E. Malaia\"},{\"authorId\":\"1700974\",\"name\":\"Barak A. Pearlmutter\"},{\"authorId\":\"1737754\",\"name\":\"J. Siskind\"},{\"authorId\":\"2741035\",\"name\":\"T. Talavage\"},{\"authorId\":\"2465833\",\"name\":\"R. Wilbur\"}],\"doi\":\"10.1007/978-3-319-10602-1_40\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"02b5732a1f448868bf3a3322b6ce57bbdd60acfc\",\"title\":\"Seeing is Worse than Believing: Reading People's Minds Better than Computer-Vision Methods Recognize Actions\",\"url\":\"https://www.semanticscholar.org/paper/02b5732a1f448868bf3a3322b6ce57bbdd60acfc\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1906.11902\",\"authors\":[{\"authorId\":\"150282338\",\"name\":\"Roshan Prakash Rane\"},{\"authorId\":\"1573750032\",\"name\":\"Edit Szugyi\"},{\"authorId\":\"150333998\",\"name\":\"Vageesh Saxena\"},{\"authorId\":\"35280884\",\"name\":\"Andr\\u00e9 Ofner\"},{\"authorId\":\"2983978\",\"name\":\"S. Stober\"}],\"doi\":\"10.1145/3372278.3390694\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"48c39ab475793b349809d7af2d5797bc1e77f48d\",\"title\":\"PredNet and Predictive Coding: A Critical Review\",\"url\":\"https://www.semanticscholar.org/paper/48c39ab475793b349809d7af2d5797bc1e77f48d\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":\"2009.12434\",\"authors\":[{\"authorId\":\"144701907\",\"name\":\"G. Elahi\"},{\"authorId\":\"35964920\",\"name\":\"Yee-Hong Yang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"048de3aa58e86791aa61ae08316e823528ee11f6\",\"title\":\"Online Learnable Keyframe Extraction in Videos and its Application with Semantic Word Vector in Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/048de3aa58e86791aa61ae08316e823528ee11f6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2001.03754\",\"authors\":[{\"authorId\":\"27066021\",\"name\":\"Huanqian Yan\"},{\"authorId\":\"2769710\",\"name\":\"Xingxing Wei\"},{\"authorId\":\"46708584\",\"name\":\"B. Li\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"af1400f1cfbca05fe4b30c972e793bdd36da955b\",\"title\":\"Sparse Black-box Video Attack with Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/af1400f1cfbca05fe4b30c972e793bdd36da955b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48933900\",\"name\":\"Q. Li\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1145/2911996.2912001\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1128a4f57148cec96c0ef4ae3b5a0fbf07efbad9\",\"title\":\"Action Recognition by Learning Deep Multi-Granular Spatio-Temporal Video Representation\",\"url\":\"https://www.semanticscholar.org/paper/1128a4f57148cec96c0ef4ae3b5a0fbf07efbad9\",\"venue\":\"ICMR\",\"year\":2016},{\"arxivId\":\"2012.09434\",\"authors\":[{\"authorId\":\"48031771\",\"name\":\"X. Liu\"},{\"authorId\":\"72285615\",\"name\":\"Yao Hu\"},{\"authorId\":\"98807701\",\"name\":\"Song Bai\"},{\"authorId\":\"1430778662\",\"name\":\"Fei Ding\"},{\"authorId\":\"145905113\",\"name\":\"X. Bai\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"db1b0d0e70f29b0018d1a9462d98dd39559f3e4a\",\"title\":\"Multi-shot Temporal Event Localization: a Benchmark\",\"url\":\"https://www.semanticscholar.org/paper/db1b0d0e70f29b0018d1a9462d98dd39559f3e4a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1608.00486\",\"authors\":[{\"authorId\":\"1808390\",\"name\":\"ZongYuan Ge\"},{\"authorId\":\"49872143\",\"name\":\"C. McCool\"},{\"authorId\":\"144228552\",\"name\":\"C. Sanderson\"},{\"authorId\":\"49830854\",\"name\":\"P. Wang\"},{\"authorId\":\"47968029\",\"name\":\"Lingqiao Liu\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"},{\"authorId\":\"1714296\",\"name\":\"P. Corke\"}],\"doi\":\"10.1109/DICTA.2016.7797039\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1b41d4ffb601d48d7a07dbbae01343f4eb8cc38c\",\"title\":\"Exploiting Temporal Information for DCNN-Based Fine-Grained Object Classification\",\"url\":\"https://www.semanticscholar.org/paper/1b41d4ffb601d48d7a07dbbae01343f4eb8cc38c\",\"venue\":\"2016 International Conference on Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2016},{\"arxivId\":\"1611.08240\",\"authors\":[{\"authorId\":\"24899770\",\"name\":\"Amlan Kar\"},{\"authorId\":\"145193060\",\"name\":\"N. Rai\"},{\"authorId\":\"39707211\",\"name\":\"Karan Sikka\"},{\"authorId\":\"144054467\",\"name\":\"G. Sharma\"}],\"doi\":\"10.1109/CVPR.2017.604\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"574ad7ef015995efb7338829a021776bf9daaa08\",\"title\":\"AdaScan: Adaptive Scan Pooling in Deep Convolutional Neural Networks for Human Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/574ad7ef015995efb7338829a021776bf9daaa08\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4697712\",\"name\":\"Z. Zhu\"},{\"authorId\":\"1696842\",\"name\":\"Hongbing Ji\"},{\"authorId\":\"1786198\",\"name\":\"W. Zhang\"},{\"authorId\":\"47748577\",\"name\":\"C. Ouyang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7b8e9c50f74ce6ca66a8ab61fb18ca31d26cf13f\",\"title\":\"Nonlinear Channels Aggregation Networks for Deep Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7b8e9c50f74ce6ca66a8ab61fb18ca31d26cf13f\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2283107\",\"name\":\"Debaditya Roy\"},{\"authorId\":\"70611576\",\"name\":\"C. Krishnamohan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"62d8bbe48f623f130d243a38674cf77701fbbdb4\",\"title\":\"REPRESENTATION LEARNING FOR ACTION RECOGNITION\",\"url\":\"https://www.semanticscholar.org/paper/62d8bbe48f623f130d243a38674cf77701fbbdb4\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7025059\",\"name\":\"C. Orozco\"},{\"authorId\":\"36507903\",\"name\":\"M. E. Buemi\"},{\"authorId\":\"70169774\",\"name\":\"J. J. Berlles\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"df8beecc6c0d16e9b75675c46b99aee80aaa83d5\",\"title\":\"CNN-LSTM Architecture for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/df8beecc6c0d16e9b75675c46b99aee80aaa83d5\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2606363\",\"name\":\"Ekaterina H. Taralova\"},{\"authorId\":\"143867160\",\"name\":\"F. Torre\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1007/978-3-319-10590-1_47\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"57fd770cce8616ced7edc9a589a706918213d97f\",\"title\":\"Motion Words for Videos\",\"url\":\"https://www.semanticscholar.org/paper/57fd770cce8616ced7edc9a589a706918213d97f\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1907.11628\",\"authors\":[{\"authorId\":\"51496700\",\"name\":\"Shuosen Guan\"},{\"authorId\":\"47892681\",\"name\":\"Haoxin Li\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"}],\"doi\":\"10.1109/ICME.2019.00039\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"309ffd41efdf84f397cf7e8f54c7f98124da3d17\",\"title\":\"Unsupervised Learning for Optical Flow Estimation Using Pyramid Convolution LSTM\",\"url\":\"https://www.semanticscholar.org/paper/309ffd41efdf84f397cf7e8f54c7f98124da3d17\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152674907\",\"name\":\"Lili Meng\"},{\"authorId\":\"47705564\",\"name\":\"B. Zhao\"},{\"authorId\":\"144757437\",\"name\":\"B. Chang\"},{\"authorId\":\"143983679\",\"name\":\"Gao Huang\"},{\"authorId\":\"115284322\",\"name\":\"W. Sun\"},{\"authorId\":\"1402348340\",\"name\":\"Frederich Tung\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":\"10.1109/ICCVW.2019.00189\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2672d3b50dbf4a0e81f506a8d1d6bbb361149c2b\",\"title\":\"Interpretable Spatio-Temporal Attention for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2672d3b50dbf4a0e81f506a8d1d6bbb361149c2b\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144907434\",\"name\":\"T. Kobayashi\"}],\"doi\":\"10.5244/c.31.125\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"55934f5326f7c86f4a00bc2070723d49e250b307\",\"title\":\"Feature Sequence Representation Via Slow Feature Analysis For Action Classification\",\"url\":\"https://www.semanticscholar.org/paper/55934f5326f7c86f4a00bc2070723d49e250b307\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":\"2010.04368\",\"authors\":[{\"authorId\":\"1836642462\",\"name\":\"Sadegh Aliakbarian\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"257bcffeb41bf699840d2ccd392ac6aecc551931\",\"title\":\"Deep Sequence Learning for Video Anticipation: From Discrete and Deterministic to Continuous and Stochastic\",\"url\":\"https://www.semanticscholar.org/paper/257bcffeb41bf699840d2ccd392ac6aecc551931\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1485630780\",\"name\":\"Yanbin Hao\"},{\"authorId\":\"145063759\",\"name\":\"Hao Zhang\"},{\"authorId\":\"143977389\",\"name\":\"C. Ngo\"},{\"authorId\":\"48874063\",\"name\":\"Q. Liu\"},{\"authorId\":\"144635784\",\"name\":\"X. Hu\"}],\"doi\":\"10.1145/3394171.3413595\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1e29826ff34cc39f04d23784ad8ec6649717e1ce\",\"title\":\"Compact Bilinear Augmented Query Structured Attention for Sport Highlights Classification\",\"url\":\"https://www.semanticscholar.org/paper/1e29826ff34cc39f04d23784ad8ec6649717e1ce\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2210460\",\"name\":\"Felipe Andrade Caetano\"},{\"authorId\":\"3052490\",\"name\":\"M. Vieira\"},{\"authorId\":\"34114733\",\"name\":\"R. S. D. Silva\"}],\"doi\":\"10.1142/S0219467816500170\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"79aaab74f4e30c6f3abc649bb7201248c59baa63\",\"title\":\"A Video Descriptor Using Orientation Tensors and Shape-Based Trajectory Clustering\",\"url\":\"https://www.semanticscholar.org/paper/79aaab74f4e30c6f3abc649bb7201248c59baa63\",\"venue\":\"Int. J. Image Graph.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66088742\",\"name\":\"Darwin Ttito Concha\"},{\"authorId\":\"8125221\",\"name\":\"H. Maia\"},{\"authorId\":\"1743455\",\"name\":\"H. Pedrini\"},{\"authorId\":\"66275285\",\"name\":\"Hemerson Tacon\"},{\"authorId\":\"51519347\",\"name\":\"A. Brito\"},{\"authorId\":\"67244903\",\"name\":\"H. Chaves\"},{\"authorId\":\"3052490\",\"name\":\"M. Vieira\"}],\"doi\":\"10.1109/ICMLA.2018.00077\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a294e26e92187a447a74bafc2d6123847c4acd7b\",\"title\":\"Multi-stream Convolutional Neural Networks for Action Recognition in Video Sequences Based on Adaptive Visual Rhythms\",\"url\":\"https://www.semanticscholar.org/paper/a294e26e92187a447a74bafc2d6123847c4acd7b\",\"venue\":\"2018 17th IEEE International Conference on Machine Learning and Applications (ICMLA)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2353872\",\"name\":\"Shahzad Cheema\"},{\"authorId\":\"2914349\",\"name\":\"Abdalrahman Eweiwi\"},{\"authorId\":\"1692283\",\"name\":\"C. Bauckhage\"}],\"doi\":\"10.1007/978-3-319-11752-2_51\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"93e6be8f3fcb13d61d70e088d2a4727605652deb\",\"title\":\"A Stochastic Late Fusion Approach to Human Action Recognition in Unconstrained Images and Videos\",\"url\":\"https://www.semanticscholar.org/paper/93e6be8f3fcb13d61d70e088d2a4727605652deb\",\"venue\":\"GCPR\",\"year\":2014},{\"arxivId\":\"2008.03462\",\"authors\":[{\"authorId\":\"145586191\",\"name\":\"Can Zhang\"},{\"authorId\":\"26981150\",\"name\":\"Yue-Xian Zou\"},{\"authorId\":\"143930563\",\"name\":\"G. Chen\"},{\"authorId\":\"48204311\",\"name\":\"L. Gan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"60840dce8073545641198c297796902fa390c719\",\"title\":\"PAN: Towards Fast Action Recognition via Learning Persistence of Appearance\",\"url\":\"https://www.semanticscholar.org/paper/60840dce8073545641198c297796902fa390c719\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1686715\",\"name\":\"S. Yu\"},{\"authorId\":\"49388033\",\"name\":\"Y. Cheng\"},{\"authorId\":\"145046855\",\"name\":\"L. Xie\"},{\"authorId\":\"40455111\",\"name\":\"Zhiming Luo\"},{\"authorId\":\"145075206\",\"name\":\"M. Huang\"},{\"authorId\":\"8086812\",\"name\":\"Shaozi Li\"}],\"doi\":\"10.1016/j.jvcir.2017.09.007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b844e211ef0c4bfd9d6b810bdedb7b91d0db14f4\",\"title\":\"A novel recurrent hybrid network for feature fusion in action recognition\",\"url\":\"https://www.semanticscholar.org/paper/b844e211ef0c4bfd9d6b810bdedb7b91d0db14f4\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48393804\",\"name\":\"Vikas Tripathi\"},{\"authorId\":\"2979208\",\"name\":\"A. Mittal\"},{\"authorId\":\"50098979\",\"name\":\"D. Gangodkar\"},{\"authorId\":\"143756267\",\"name\":\"V. Kanth\"}],\"doi\":\"10.1007/s11554-016-0573-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9f8b0c91adf5a50de75df2f116595dfedaf09366\",\"title\":\"Real time security framework for detecting abnormal events at ATM installations\",\"url\":\"https://www.semanticscholar.org/paper/9f8b0c91adf5a50de75df2f116595dfedaf09366\",\"venue\":\"Journal of Real-Time Image Processing\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144119773\",\"name\":\"Kun Liu\"},{\"authorId\":\"1686917\",\"name\":\"Wu Liu\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"},{\"authorId\":\"144258295\",\"name\":\"Huadong Ma\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"3d708e4ecabc50d3f3e387a21a73f6ae2b52ddfc\",\"title\":\"T-C3D: Temporal Convolutional 3D Network for Real-Time Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3d708e4ecabc50d3f3e387a21a73f6ae2b52ddfc\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71132307\",\"name\":\"Adithya Reddy Nallabolu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"24e07578dd0c2e224aa209b83fe1c21b635451dd\",\"title\":\"Unsupervised Learning of Spatiotemporal Features by Video Completion\",\"url\":\"https://www.semanticscholar.org/paper/24e07578dd0c2e224aa209b83fe1c21b635451dd\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"2002.04685\",\"authors\":[{\"authorId\":\"16323128\",\"name\":\"Guoxi Huang\"},{\"authorId\":\"1707271\",\"name\":\"Adrian G. Bors\"}],\"doi\":\"10.1109/ICASSP40776.2020.9054200\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ca2b6df138b34d6d3eeb25e65307ba9b6201816f\",\"title\":\"Learning Spatio-Temporal Representations With Temporal Squeeze Pooling\",\"url\":\"https://www.semanticscholar.org/paper/ca2b6df138b34d6d3eeb25e65307ba9b6201816f\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35005950\",\"name\":\"Ethem F. Can\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"238192db5706a1ccd06310564c35598fe88ab983\",\"title\":\"Exploiting Concepts In Videos For Video Event Detection\",\"url\":\"https://www.semanticscholar.org/paper/238192db5706a1ccd06310564c35598fe88ab983\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144733334\",\"name\":\"A. Zunino\"},{\"authorId\":\"3393678\",\"name\":\"Jacopo Cavazza\"},{\"authorId\":\"34465973\",\"name\":\"A. Koul\"},{\"authorId\":\"37783905\",\"name\":\"Andrea Cavallo\"},{\"authorId\":\"1834966\",\"name\":\"C. Becchio\"},{\"authorId\":\"1727204\",\"name\":\"Vittorio Murino\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"db40065a98378b417cf68871a0081944310cb83f\",\"title\":\"Predicting Human Intentions from Motion Only: A 2D+3D Fusion Approach\",\"url\":\"https://www.semanticscholar.org/paper/db40065a98378b417cf68871a0081944310cb83f\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"49416129\",\"name\":\"Y. Wang\"},{\"authorId\":\"1722596\",\"name\":\"Zhulin Li\"},{\"authorId\":\"144035504\",\"name\":\"Zhuowen Tu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"991bb51ac60f2973ed0d7dd131284899a8e598aa\",\"title\":\"Harvesting Motion Patterns in Still Images from the Internet\",\"url\":\"https://www.semanticscholar.org/paper/991bb51ac60f2973ed0d7dd131284899a8e598aa\",\"venue\":\"CogSci\",\"year\":2014},{\"arxivId\":\"1605.09526\",\"authors\":[{\"authorId\":\"144733334\",\"name\":\"A. Zunino\"},{\"authorId\":\"3393678\",\"name\":\"Jacopo Cavazza\"},{\"authorId\":\"34465973\",\"name\":\"A. Koul\"},{\"authorId\":\"37783905\",\"name\":\"Andrea Cavallo\"},{\"authorId\":\"1834966\",\"name\":\"C. Becchio\"},{\"authorId\":\"1727204\",\"name\":\"Vittorio Murino\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ceca53c79ee54db9df526553e5cb045fad10c05e\",\"title\":\"Intention from Motion\",\"url\":\"https://www.semanticscholar.org/paper/ceca53c79ee54db9df526553e5cb045fad10c05e\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34971636\",\"name\":\"Shweta Bhardwaj\"},{\"authorId\":\"34658653\",\"name\":\"Mukundhan Srinivasan\"},{\"authorId\":\"2361078\",\"name\":\"Mitesh M. Khapra\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b5f9d5be7561bb6eacee9012275b17c75696c388\",\"title\":\"A Teacher Student Network For Faster Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/b5f9d5be7561bb6eacee9012275b17c75696c388\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1881509\",\"name\":\"Vicky Kalogeiton\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"40dd2b9aace337467c6e1e269d0cb813442313d7\",\"title\":\"Localizing spatially and temporally objects and actions in videos. (Localiser spatio-temporallement des objets et des actions dans des vid\\u00e9os)\",\"url\":\"https://www.semanticscholar.org/paper/40dd2b9aace337467c6e1e269d0cb813442313d7\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47185625\",\"name\":\"F. Liu\"},{\"authorId\":\"39421976\",\"name\":\"Xiangmin Xu\"},{\"authorId\":\"37178775\",\"name\":\"Chunmei Qing\"}],\"doi\":\"10.1109/ICCE-CHINA.2016.7849737\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"97b50a82c9b1fda9a7d8f32c73803cb7161d392d\",\"title\":\"Temporal order information for complex action recognition\",\"url\":\"https://www.semanticscholar.org/paper/97b50a82c9b1fda9a7d8f32c73803cb7161d392d\",\"venue\":\"2016 IEEE International Conference on Consumer Electronics-China (ICCE-China)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35550884\",\"name\":\"Fan Zhu\"},{\"authorId\":\"47531001\",\"name\":\"Fan Zhu\"},{\"authorId\":\"144082425\",\"name\":\"Ling Shao\"},{\"authorId\":\"40799321\",\"name\":\"Ling Shao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3f84446d87213b88c5102ba975ff9a5f1d485b29\",\"title\":\"ZHU , SHAO AND TANG : BOOSTED CROSS-DOMAIN CATEGORIZATION 1 Boosted Cross-Domain Categorization\",\"url\":\"https://www.semanticscholar.org/paper/3f84446d87213b88c5102ba975ff9a5f1d485b29\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52022007\",\"name\":\"Vasileios Choutas\"},{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"3428663\",\"name\":\"J\\u00e9r\\u00f4me Revaud\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/CVPR.2018.00734\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6009bba115904bc3bf876224db90b232c4f0a48f\",\"title\":\"PoTion: Pose MoTion Representation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6009bba115904bc3bf876224db90b232c4f0a48f\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1839490\",\"name\":\"Chris Whiten\"},{\"authorId\":\"2035718\",\"name\":\"R. Lagani\\u00e8re\"},{\"authorId\":\"1705256\",\"name\":\"Guillaume-Alexandre Bilodeau\"}],\"doi\":\"10.1109/CRV.2013.30\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"a9151f238ad94839cde2f369c38d9bdc5d4186da\",\"title\":\"Efficient Action Recognition with MoFREAK\",\"url\":\"https://www.semanticscholar.org/paper/a9151f238ad94839cde2f369c38d9bdc5d4186da\",\"venue\":\"2013 International Conference on Computer and Robot Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2580693\",\"name\":\"Z. Pei\"},{\"authorId\":\"39150622\",\"name\":\"Y. Wang\"},{\"authorId\":\"29955728\",\"name\":\"John Mkhomoi Afridon\"}],\"doi\":\"10.1109/ITOEC.2017.8122306\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"8b45b98c2f1471eb354b6378f6bec32858e5b722\",\"title\":\"Dictionary pair learning in compressed space for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b45b98c2f1471eb354b6378f6bec32858e5b722\",\"venue\":\"2017 IEEE 3rd Information Technology and Mechatronics Engineering Conference (ITOEC)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40812963\",\"name\":\"Wennan Yu\"},{\"authorId\":\"9177510\",\"name\":\"Y. Sun\"},{\"authorId\":\"3450614\",\"name\":\"Feiwu Yu\"},{\"authorId\":\"2125709\",\"name\":\"Xinxiao Wu\"}],\"doi\":\"10.1007/978-3-319-77380-3_67\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"47cddc8b450fa9e766c6ce5c9696f59e06bfd604\",\"title\":\"Representing Discrimination of Video by a Motion Map\",\"url\":\"https://www.semanticscholar.org/paper/47cddc8b450fa9e766c6ce5c9696f59e06bfd604\",\"venue\":\"PCM\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699240\",\"name\":\"D. Wu\"},{\"authorId\":\"2660640\",\"name\":\"Lionel Pigou\"},{\"authorId\":\"2113697\",\"name\":\"P. Kindermans\"},{\"authorId\":\"2992783\",\"name\":\"N. Le\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"},{\"authorId\":\"2309489\",\"name\":\"J. Dambre\"},{\"authorId\":\"1719610\",\"name\":\"J. Odobez\"}],\"doi\":\"10.1109/TPAMI.2016.2537340\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bf1a72fd086e8051017ee0f8d80b63f98774ae6e\",\"title\":\"Deep Dynamic Neural Networks for Multimodal Gesture Segmentation and Recognition\",\"url\":\"https://www.semanticscholar.org/paper/bf1a72fd086e8051017ee0f8d80b63f98774ae6e\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2016},{\"arxivId\":\"1802.01144\",\"authors\":[{\"authorId\":\"144865353\",\"name\":\"B. Pang\"},{\"authorId\":\"15376265\",\"name\":\"Kaiwen Zha\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"}],\"doi\":\"10.1109/CVPRW.2018.00308\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"35684ac29ea0936635da9d9944659e4cdb7e2d0d\",\"title\":\"Human Action Adverb Recognition: ADHA Dataset and a Three-Stream Hybrid Model\",\"url\":\"https://www.semanticscholar.org/paper/35684ac29ea0936635da9d9944659e4cdb7e2d0d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2641229\",\"name\":\"A. Zlatintsi\"},{\"authorId\":\"2539459\",\"name\":\"Petros Koutras\"},{\"authorId\":\"1710606\",\"name\":\"Georgios Evangelopoulos\"},{\"authorId\":\"2979215\",\"name\":\"Nikos Malandrakis\"},{\"authorId\":\"27687205\",\"name\":\"N. Efthymiou\"},{\"authorId\":\"2861393\",\"name\":\"K. Pastra\"},{\"authorId\":\"1791187\",\"name\":\"A. Potamianos\"},{\"authorId\":\"1750686\",\"name\":\"P. Maragos\"}],\"doi\":\"10.1186/S13640-017-0194-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3dd564602eae3694ccc976b9f5415c6d8d394559\",\"title\":\"COGNIMUSE: a multimodal video database annotated with saliency, events, semantics and emotion with application to summarization\",\"url\":\"https://www.semanticscholar.org/paper/3dd564602eae3694ccc976b9f5415c6d8d394559\",\"venue\":\"EURASIP J. Image Video Process.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50202110\",\"name\":\"Shiwei Zhang\"},{\"authorId\":\"40115662\",\"name\":\"Changxin Gao\"},{\"authorId\":\"3261880\",\"name\":\"F. Chen\"},{\"authorId\":\"48730399\",\"name\":\"Sihui Luo\"},{\"authorId\":\"1707161\",\"name\":\"N. Sang\"}],\"doi\":\"10.1109/TSMC.2016.2625840\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5a24f1e034493ed84a6157636b4733c1a9d793f4\",\"title\":\"Group Sparse-Based Mid-Level Representation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5a24f1e034493ed84a6157636b4733c1a9d793f4\",\"venue\":\"IEEE Transactions on Systems, Man, and Cybernetics: Systems\",\"year\":2017},{\"arxivId\":\"1704.04952\",\"authors\":[{\"authorId\":null,\"name\":\"Suman Saha\"},{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":\"10.1109/ICCV.2017.473\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f91a5b09b50a9118d75ffea672a785a703cd604a\",\"title\":\"AMTnet: Action-Micro-Tube Regression by End-to-end Trainable Deep Architecture\",\"url\":\"https://www.semanticscholar.org/paper/f91a5b09b50a9118d75ffea672a785a703cd604a\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1602.03346\",\"authors\":[{\"authorId\":\"40241836\",\"name\":\"L. Liu\"},{\"authorId\":null,\"name\":\"Yi Zhou\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"}],\"doi\":\"10.1109/ICRA.2017.7989018\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e251595e6ef8396d5b3e423bc03a22ec75ff5038\",\"title\":\"DAP3D-Net: Where, what and how actions occur in videos?\",\"url\":\"https://www.semanticscholar.org/paper/e251595e6ef8396d5b3e423bc03a22ec75ff5038\",\"venue\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2017},{\"arxivId\":\"2008.05789\",\"authors\":[{\"authorId\":\"1443743722\",\"name\":\"Ying Cheng\"},{\"authorId\":\"29068663\",\"name\":\"Ruize Wang\"},{\"authorId\":\"48699340\",\"name\":\"Zhihao Pan\"},{\"authorId\":\"51304315\",\"name\":\"Rui Feng\"},{\"authorId\":\"3067458\",\"name\":\"Yuejie Zhang\"}],\"doi\":\"10.1145/3394171.3413869\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"17b28643a5aaed62fbccd98781d4ebc0f0477afa\",\"title\":\"Look, Listen, and Attend: Co-Attention Network for Self-Supervised Audio-Visual Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/17b28643a5aaed62fbccd98781d4ebc0f0477afa\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1809.04317\",\"authors\":[{\"authorId\":\"33237072\",\"name\":\"Philipp Zech\"},{\"authorId\":\"2898615\",\"name\":\"Erwan Renaudo\"},{\"authorId\":\"36081156\",\"name\":\"Simon Haller\"},{\"authorId\":\"46447747\",\"name\":\"X. Zhang\"},{\"authorId\":\"1772389\",\"name\":\"J. Piater\"}],\"doi\":\"10.1177/0278364919835020\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1ca155a4b65ae19ccb73df48516e4775770a382c\",\"title\":\"Action representations in robotics: A taxonomy and systematic classification\",\"url\":\"https://www.semanticscholar.org/paper/1ca155a4b65ae19ccb73df48516e4775770a382c\",\"venue\":\"Int. J. Robotics Res.\",\"year\":2019},{\"arxivId\":\"1812.01053\",\"authors\":[{\"authorId\":\"3227254\",\"name\":\"Hamid Reza Vaezi Joze\"},{\"authorId\":\"47285696\",\"name\":\"Oscar Koller\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"310a8e2c9f2650fa2e44fdf0d82d11c0cb3e387e\",\"title\":\"MS-ASL: A Large-Scale Data Set and Benchmark for Understanding American Sign Language\",\"url\":\"https://www.semanticscholar.org/paper/310a8e2c9f2650fa2e44fdf0d82d11c0cb3e387e\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145654022\",\"name\":\"V. R. M. Oruganti\"},{\"authorId\":\"2026749552\",\"name\":\"Roland Goecke\"},{\"authorId\":\"2026749552\",\"name\":\"Roland Goecke\"}],\"doi\":\"10.1049/IET-CVI.2015.0091\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bac5f1463de184e7b7b7a9f9b9e1c3f8f7fb785f\",\"title\":\"Dimensionality reduction of Fisher vectors for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/bac5f1463de184e7b7b7a9f9b9e1c3f8f7fb785f\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"2001.07501\",\"authors\":[{\"authorId\":\"2719454\",\"name\":\"W. Wang\"},{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"48265260\",\"name\":\"Jian Cheng\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6b06383710f5dff3028db31d1497914d65888194\",\"title\":\"A Comprehensive Study on Temporal Modeling for Online Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/6b06383710f5dff3028db31d1497914d65888194\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2b42f83a720bd4156113ba5350add2df2673daf0\",\"title\":\"Action Recognition and Detection by Combining Motion and Appearance Features\",\"url\":\"https://www.semanticscholar.org/paper/2b42f83a720bd4156113ba5350add2df2673daf0\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40892875\",\"name\":\"Pascal Mettes\"}],\"doi\":\"10.1145/3264706.3264716\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a5d163605d499b66cbb4d5831caf737f36c3a6c5\",\"title\":\"PhD thesis: objects for spatio-temporal activity recognition in videos\",\"url\":\"https://www.semanticscholar.org/paper/a5d163605d499b66cbb4d5831caf737f36c3a6c5\",\"venue\":\"ACMMR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40241836\",\"name\":\"L. Liu\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"},{\"authorId\":\"144513293\",\"name\":\"Feng Zheng\"},{\"authorId\":\"1720243\",\"name\":\"X. Li\"}],\"doi\":\"10.1016/J.PATCOG.2014.07.006\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a4d92a6559f7f4516552ce0cc2a5df2d5c127da9\",\"title\":\"Realistic action recognition via sparsely-constructed Gaussian processes\",\"url\":\"https://www.semanticscholar.org/paper/a4d92a6559f7f4516552ce0cc2a5df2d5c127da9\",\"venue\":\"Pattern Recognit.\",\"year\":2014},{\"arxivId\":\"1907.11117\",\"authors\":[{\"authorId\":\"145032628\",\"name\":\"Michael Wray\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b73ff5846772da8575262925aa7709b5e64079a0\",\"title\":\"Learning Visual Actions Using Multiple Verb-Only Labels\",\"url\":\"https://www.semanticscholar.org/paper/b73ff5846772da8575262925aa7709b5e64079a0\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"1908.08990\",\"authors\":[{\"authorId\":\"1720818\",\"name\":\"Sebastian Agethen\"},{\"authorId\":\"1716836\",\"name\":\"W. Hsu\"}],\"doi\":\"10.1109/TMM.2019.2932564\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1f4e2bdd9bf848e967b4e68203a914475d306a58\",\"title\":\"Deep Multi-Kernel Convolutional LSTM Networks and an Attention-Based Mechanism for Videos\",\"url\":\"https://www.semanticscholar.org/paper/1f4e2bdd9bf848e967b4e68203a914475d306a58\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2283107\",\"name\":\"Debaditya Roy\"},{\"authorId\":\"34358756\",\"name\":\"C. K. Mohan\"}],\"doi\":\"10.1016/j.patrec.2018.03.004\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fcf2b7907d55dfa2096bf4502a3863c351af651c\",\"title\":\"Snatch theft detection in unconstrained surveillance videos using action attribute modelling\",\"url\":\"https://www.semanticscholar.org/paper/fcf2b7907d55dfa2096bf4502a3863c351af651c\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2894970\",\"name\":\"Yanhu Shan\"},{\"authorId\":\"31828103\",\"name\":\"Z. Zhang\"},{\"authorId\":\"2086001\",\"name\":\"Junge Zhang\"},{\"authorId\":\"2887871\",\"name\":\"K. Huang\"},{\"authorId\":\"145931223\",\"name\":\"N. Wu\"},{\"authorId\":\"3206247\",\"name\":\"Oh Se Hyun\"}],\"doi\":\"10.1109/AVSS.2012.43\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1a97a6dd7a505faf72526fa889f694b243ae4165\",\"title\":\"Interest Point Selection with Spatio-temporal Context for Realistic Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1a97a6dd7a505faf72526fa889f694b243ae4165\",\"venue\":\"2012 IEEE Ninth International Conference on Advanced Video and Signal-Based Surveillance\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6516435\",\"name\":\"Mengxi Lin\"},{\"authorId\":\"1718406\",\"name\":\"N. Inoue\"},{\"authorId\":\"1704408\",\"name\":\"Koichi Shinoda\"}],\"doi\":\"10.1145/3126686.3126755\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4097fef623185557bb1842501cfdc97f812fc66d\",\"title\":\"CTC Network with Statistical Language Modeling for Action Sequence Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/4097fef623185557bb1842501cfdc97f812fc66d\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1510708346\",\"name\":\"Jianbang Qin\"},{\"authorId\":\"1510665624\",\"name\":\"S. Hu\"},{\"authorId\":\"153301546\",\"name\":\"W. Guo\"}],\"doi\":\"10.1117/12.2559286\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"80f0280a05f10f0d95ceb0bc4c435315acfef5bb\",\"title\":\"Global evaluate-and-rescale network: an efficient model for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/80f0280a05f10f0d95ceb0bc4c435315acfef5bb\",\"venue\":\"International Conference on Machine Vision\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2910174\",\"name\":\"Haonan Yu\"},{\"authorId\":\"145809603\",\"name\":\"N. Siddharth\"},{\"authorId\":\"21570451\",\"name\":\"A. Barbu\"},{\"authorId\":\"1737754\",\"name\":\"J. Siskind\"}],\"doi\":\"10.1613/jair.4556\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"083d1055f81dd7c9b41233a92b9768a857d1db58\",\"title\":\"A Compositional Framework for Grounding Language Inference, Generation, and Acquisition in Video\",\"url\":\"https://www.semanticscholar.org/paper/083d1055f81dd7c9b41233a92b9768a857d1db58\",\"venue\":\"J. Artif. Intell. Res.\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145895906\",\"name\":\"M. Santofimia\"},{\"authorId\":\"1405317340\",\"name\":\"J. Mart\\u00ednez-del-Rinc\\u00f3n\"},{\"authorId\":\"3085605\",\"name\":\"Jean-Christophe Nebel\"}],\"doi\":\"10.1155/2014/270171\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"42f0752a4cdd54e4cf986ad45e6d6acc1e19b1c2\",\"title\":\"Episodic Reasoning for Vision-Based Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/42f0752a4cdd54e4cf986ad45e6d6acc1e19b1c2\",\"venue\":\"TheScientificWorldJournal\",\"year\":2014},{\"arxivId\":\"1703.03329\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2017.678\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"61d0125cd9f5aba4aef3e1db911f77be67a4e8c8\",\"title\":\"UntrimmedNets for Weakly Supervised Action Recognition and Detection\",\"url\":\"https://www.semanticscholar.org/paper/61d0125cd9f5aba4aef3e1db911f77be67a4e8c8\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49854448\",\"name\":\"A. Fire\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0653ba0b20bc622763572be89a2b5813b07c8f6e\",\"title\":\"Learning and Inferring Perceptual Causality from Video\",\"url\":\"https://www.semanticscholar.org/paper/0653ba0b20bc622763572be89a2b5813b07c8f6e\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"2010.14810\",\"authors\":[{\"authorId\":\"1557386872\",\"name\":\"Quan Kong\"},{\"authorId\":\"31713260\",\"name\":\"W. Wei\"},{\"authorId\":\"90812043\",\"name\":\"Z. Deng\"},{\"authorId\":\"32710145\",\"name\":\"Tomoaki Yoshinaga\"},{\"authorId\":\"2668511\",\"name\":\"T. Murakami\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"81b6c5b86ff596876078dc7eab4c0f093832056a\",\"title\":\"Cycle-Contrast for Self-Supervised Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/81b6c5b86ff596876078dc7eab4c0f093832056a\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2396114\",\"name\":\"T. Moreira\"},{\"authorId\":\"50534501\",\"name\":\"D. Menotti\"},{\"authorId\":\"1398585275\",\"name\":\"H. Pedrini\"}],\"doi\":\"10.1016/j.jvcir.2020.102771\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"49278c84a9c0204319a62073d1d42556dee3ff4e\",\"title\":\"Video action recognition based on visual rhythm representation\",\"url\":\"https://www.semanticscholar.org/paper/49278c84a9c0204319a62073d1d42556dee3ff4e\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46365948\",\"name\":\"J. Wu\"},{\"authorId\":\"145951569\",\"name\":\"Wu Luo\"},{\"authorId\":\"120639867\",\"name\":\"Weiwei Liu\"},{\"authorId\":\"50445905\",\"name\":\"Chongyang Zhang\"}],\"doi\":\"10.1109/ICASSP40776.2020.9054282\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2f20c25ef69171a64549b5aa9b0dc62e98878ff0\",\"title\":\"Global and Local Discriminative Patches Exploiting for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2f20c25ef69171a64549b5aa9b0dc62e98878ff0\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49902445\",\"name\":\"Y. Tian\"},{\"authorId\":\"145873652\",\"name\":\"Y. Kong\"},{\"authorId\":\"144695333\",\"name\":\"Q. Ruan\"},{\"authorId\":\"2896701\",\"name\":\"G. An\"},{\"authorId\":\"46956675\",\"name\":\"Yun Fu\"}],\"doi\":\"10.1109/TCSVT.2019.2908487\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"c267864e1c267b67a09e2c3b2c7113e47facb1f9\",\"title\":\"Aligned Dynamic-Preserving Embedding for Zero-Shot Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c267864e1c267b67a09e2c3b2c7113e47facb1f9\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1571584056\",\"name\":\"Ersan Zhou\"},{\"authorId\":\"1390919399\",\"name\":\"Heqing Zhang\"}],\"doi\":\"10.1016/j.image.2020.115802\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"054e5023350801c8aac276390d4c6f4fb8ced25f\",\"title\":\"Human action recognition toward massive-scale sport sceneries based on deep multi-model feature fusion\",\"url\":\"https://www.semanticscholar.org/paper/054e5023350801c8aac276390d4c6f4fb8ced25f\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40256896\",\"name\":\"L. Wang\"},{\"authorId\":\"1758267\",\"name\":\"X. Zhao\"},{\"authorId\":\"1701515\",\"name\":\"Y. Liu\"}],\"doi\":\"10.1109/ACCESS.2018.2869751\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7f9b192dad9f85289016c8a089d2a6a65ed1224a\",\"title\":\"Skeleton Feature Fusion Based on Multi-Stream LSTM for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7f9b192dad9f85289016c8a089d2a6a65ed1224a\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":\"2002.03152\",\"authors\":[{\"authorId\":\"47968272\",\"name\":\"Li-Yu Daisy Liu\"},{\"authorId\":\"1491094850\",\"name\":\"Tao Wang\"},{\"authorId\":\"49723003\",\"name\":\"J. Liu\"},{\"authorId\":\"50463545\",\"name\":\"Yang Guan\"},{\"authorId\":\"9963055\",\"name\":\"Qi Bu\"},{\"authorId\":\"49576139\",\"name\":\"Longfei Yang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9f0320cd101ed6426a4330ecb395015c266e976c\",\"title\":\"CTM: Collaborative Temporal Modeling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9f0320cd101ed6426a4330ecb395015c266e976c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31746321\",\"name\":\"Shaofan Lai\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"},{\"authorId\":\"67331131\",\"name\":\"Jianfang Hu\"},{\"authorId\":\"31067082\",\"name\":\"Jian'guo Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5b1679265a4b7764ee9796f6b98c3692f56c7717\",\"title\":\"Recognition Prediction ? ? ? ? ? ? ? ? Gap fi lling\",\"url\":\"https://www.semanticscholar.org/paper/5b1679265a4b7764ee9796f6b98c3692f56c7717\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47150103\",\"name\":\"Xiao Wu\"},{\"authorId\":\"48837492\",\"name\":\"J. Yuan\"}],\"doi\":\"10.1109/WF-IoT48130.2020.9221355\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d69bb85795e1ca9c6354c8537cc96a4361704c87\",\"title\":\"Multipath Event-Based Network for Low-Power Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d69bb85795e1ca9c6354c8537cc96a4361704c87\",\"venue\":\"2020 IEEE 6th World Forum on Internet of Things (WF-IoT)\",\"year\":2020},{\"arxivId\":\"1604.06573\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2016.213\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d9aced120e530484609164c836da64548693484\",\"title\":\"Convolutional Two-Stream Network Fusion for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9d9aced120e530484609164c836da64548693484\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1512.06498\",\"authors\":[{\"authorId\":\"145143348\",\"name\":\"O. V. R. Murthy\"},{\"authorId\":\"1717204\",\"name\":\"R. Goecke\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"69fb98e11df56b5d7ec7d45442af274889e4be52\",\"title\":\"Harnessing the Deep Net Object Models for Enhancing Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/69fb98e11df56b5d7ec7d45442af274889e4be52\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1803.11064\",\"authors\":[{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"3072326\",\"name\":\"S. Sra\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"143750009\",\"name\":\"R. Hartley\"}],\"doi\":\"10.1109/CVPR.2018.00234\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"13d93feb5431eda200ac482b5230f51667c0146a\",\"title\":\"Non-linear Temporal Subspace Representations for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/13d93feb5431eda200ac482b5230f51667c0146a\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4439383\",\"name\":\"Jamie Ray\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"35259685\",\"name\":\"Y. Wang\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1007/978-3-030-01264-9_39\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"71167cf519940a7373adc221401c396198763ab0\",\"title\":\"Scenes-Objects-Actions: A Multi-task, Multi-label Video Dataset\",\"url\":\"https://www.semanticscholar.org/paper/71167cf519940a7373adc221401c396198763ab0\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1398447065\",\"name\":\"Sadjad Asghari-Esfeden\"},{\"authorId\":\"1687866\",\"name\":\"M. Sznaier\"},{\"authorId\":\"143867334\",\"name\":\"O. Camps\"}],\"doi\":\"10.1109/WACV45572.2020.9093500\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"51bcb7de98bedf65215910fcfd08555d5eed682a\",\"title\":\"Dynamic Motion Representation for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/51bcb7de98bedf65215910fcfd08555d5eed682a\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2983562\",\"name\":\"Huafeng Chen\"},{\"authorId\":\"38373223\",\"name\":\"J. Chen\"},{\"authorId\":\"46382329\",\"name\":\"Hongyang Li\"},{\"authorId\":\"2646978\",\"name\":\"Zengmin Xu\"},{\"authorId\":\"144328091\",\"name\":\"R. Hu\"}],\"doi\":\"10.1007/978-3-319-24075-6_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fca32e31a9158545da75a6ccb89cb4df11dc3a50\",\"title\":\"Compressed-Domain Based Camera Motion Estimation for Realtime Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fca32e31a9158545da75a6ccb89cb4df11dc3a50\",\"venue\":\"PCM\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145951562\",\"name\":\"W. Luo\"},{\"authorId\":\"50445655\",\"name\":\"C. Zhang\"},{\"authorId\":\"49663261\",\"name\":\"W. Liu\"},{\"authorId\":\"91945776\",\"name\":\"J. Wu\"},{\"authorId\":\"8131625\",\"name\":\"W. Lin\"}],\"doi\":\"10.1109/BigMM.2019.00-27\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"de265804b8a955308f42fee71d01dfe45fe83f3b\",\"title\":\"Improving Action Recognition with Valued Patches Exploiting\",\"url\":\"https://www.semanticscholar.org/paper/de265804b8a955308f42fee71d01dfe45fe83f3b\",\"venue\":\"2019 IEEE Fifth International Conference on Multimedia Big Data (BigMM)\",\"year\":2019},{\"arxivId\":\"1801.01415\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2018.00818\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"93a7b595757f0e37e59a7b24c6d08508c4177405\",\"title\":\"What have We Learned from Deep Representations for Action Recognition?\",\"url\":\"https://www.semanticscholar.org/paper/93a7b595757f0e37e59a7b24c6d08508c4177405\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jun Yang\"},{\"authorId\":\"7947723\",\"name\":\"Zhongke Shi\"},{\"authorId\":\"3311781\",\"name\":\"Z. Wu\"}],\"doi\":\"10.1016/j.aei.2016.04.009\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"57d60c00baa0152a5f7edb88e3b2220038bf5222\",\"title\":\"Vision-based action recognition of construction workers using dense trajectories\",\"url\":\"https://www.semanticscholar.org/paper/57d60c00baa0152a5f7edb88e3b2220038bf5222\",\"venue\":\"Adv. Eng. Informatics\",\"year\":2016},{\"arxivId\":\"2009.05224\",\"authors\":[{\"authorId\":\"3795834\",\"name\":\"J. Chung\"},{\"authorId\":\"1940024152\",\"name\":\"C. Wuu\"},{\"authorId\":\"1940708423\",\"name\":\"Hsuan-ru Yang\"},{\"authorId\":\"5068280\",\"name\":\"Yu-Wing Tai\"},{\"authorId\":\"2088295\",\"name\":\"C. Tang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d5635ee061af4321d5de2076d4834a4f96012551\",\"title\":\"HAA500: Human-Centric Atomic Action Dataset with Curated Videos\",\"url\":\"https://www.semanticscholar.org/paper/d5635ee061af4321d5de2076d4834a4f96012551\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"88470948\",\"name\":\"Y. Kim\"},{\"authorId\":\"2487892\",\"name\":\"Sungeun Hong\"},{\"authorId\":\"3160154\",\"name\":\"Donghyeon Cho\"},{\"authorId\":\"121416659\",\"name\":\"H. Park\"},{\"authorId\":\"9352814\",\"name\":\"Priyadarshini Panda\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7170952d0d6ded78708be7aca86e630089dcdb88\",\"title\":\"Domain Adaptation without Source Data\",\"url\":\"https://www.semanticscholar.org/paper/7170952d0d6ded78708be7aca86e630089dcdb88\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37977601\",\"name\":\"M. Tom\"},{\"authorId\":\"144682140\",\"name\":\"R. Venkatesh Babu\"},{\"authorId\":\"145799444\",\"name\":\"R Gnana Praveen\"}],\"doi\":\"10.1007/s11042-014-2083-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6343bc0013343b6a5f96154f02d18dcd36a3f74c\",\"title\":\"Compressed domain human action recognition in H.264/AVC video streams\",\"url\":\"https://www.semanticscholar.org/paper/6343bc0013343b6a5f96154f02d18dcd36a3f74c\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2014},{\"arxivId\":\"1901.03460\",\"authors\":[{\"authorId\":\"73423138\",\"name\":\"Zheng Shou\"},{\"authorId\":\"3305169\",\"name\":\"Zhicheng Yan\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"1403581832\",\"name\":\"Laura Sevilla-Lara\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"48030192\",\"name\":\"Xudong Lin\"},{\"authorId\":\"70351911\",\"name\":\"Shih-Fu Chang\"}],\"doi\":\"10.1109/CVPR.2019.00136\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d878aac73038c3bc175ccc2b93acc04675f33bbd\",\"title\":\"DMC-Net: Generating Discriminative Motion Cues for Fast Compressed Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d878aac73038c3bc175ccc2b93acc04675f33bbd\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1756099\",\"name\":\"Tal Hassner\"}],\"doi\":\"10.1109/CVPRW.2013.43\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cd07e9cc9264098159250f78b5f9faceba489800\",\"title\":\"A Critical Review of Action Recognition Benchmarks\",\"url\":\"https://www.semanticscholar.org/paper/cd07e9cc9264098159250f78b5f9faceba489800\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition Workshops\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2708397\",\"name\":\"C. Xu\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"114945277\",\"name\":\"B. Zhang\"},{\"authorId\":\"13556061\",\"name\":\"Z. Chen\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"}],\"doi\":\"10.1109/TCSVT.2019.2927118\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"cfcfe036b2026fbe8761888e43858c61a418331f\",\"title\":\"Learning to Score Figure Skating Sport Videos\",\"url\":\"https://www.semanticscholar.org/paper/cfcfe036b2026fbe8761888e43858c61a418331f\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"2012.14371\",\"authors\":[{\"authorId\":\"2155775\",\"name\":\"Piotr Koniusz\"},{\"authorId\":\"145131935\",\"name\":\"Lei Wang\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"209b706757048dd8606185bb2ca27c31ff991dd3\",\"title\":\"Tensor Representations for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/209b706757048dd8606185bb2ca27c31ff991dd3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1810.12522\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"}],\"doi\":\"10.1007/978-3-030-20893-6_34\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"283181a2173b485726664edc6fe73f0465387629\",\"title\":\"Random Temporal Skipping for Multirate Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/283181a2173b485726664edc6fe73f0465387629\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"1707.06436\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":null,\"name\":\"Yun He\"},{\"authorId\":\"9935341\",\"name\":\"S. Ueta\"},{\"authorId\":\"5014206\",\"name\":\"T. Suzuki\"},{\"authorId\":\"49897653\",\"name\":\"K. Abe\"},{\"authorId\":\"2554424\",\"name\":\"Asako Kanezaki\"},{\"authorId\":\"49133490\",\"name\":\"Shinichiro Morita\"},{\"authorId\":\"22219521\",\"name\":\"Toshiyuki Yabe\"},{\"authorId\":\"50544018\",\"name\":\"Yoshihiro Kanehara\"},{\"authorId\":\"22174281\",\"name\":\"Hiroya Yatsuyanagi\"},{\"authorId\":\"1692565\",\"name\":\"S. Maruyama\"},{\"authorId\":\"10756539\",\"name\":\"Ryousuke Takasawa\"},{\"authorId\":\"3217653\",\"name\":\"Masataka Fuchida\"},{\"authorId\":\"2642022\",\"name\":\"Y. Miyashita\"},{\"authorId\":\"34935749\",\"name\":\"Kazushige Okayasu\"},{\"authorId\":\"20505300\",\"name\":\"Yuta Matsuzaki\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"title\":\"cvpaper.challenge in 2016: Futuristic Computer Vision through 1, 600 Papers Survey\",\"url\":\"https://www.semanticscholar.org/paper/8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71003925\",\"name\":\"Jusong Li\"},{\"authorId\":\"6820648\",\"name\":\"Xianglong Liu\"},{\"authorId\":\"1384523745\",\"name\":\"Jun Xiao\"},{\"authorId\":\"9100047\",\"name\":\"Hainan Li\"},{\"authorId\":\"1390900682\",\"name\":\"S. Wang\"},{\"authorId\":null,\"name\":\"Liang Liu\"}],\"doi\":\"10.1109/ICDMW.2019.00098\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"7fc246181ac6c8b1eb9cb138dd34d35b7dde1a74\",\"title\":\"Dynamic Spatio-Temporal Feature Learning via Graph Convolution in 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/7fc246181ac6c8b1eb9cb138dd34d35b7dde1a74\",\"venue\":\"2019 International Conference on Data Mining Workshops (ICDMW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"2111981\",\"name\":\"Jos\\u00e9 Oramas\"},{\"authorId\":\"3060081\",\"name\":\"A. Ghodrati\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"}],\"doi\":\"10.1109/CVPR.2015.7299176\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5443a1b18fed3173dc426735ff9f486194185172\",\"title\":\"Modeling video evolution for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/5443a1b18fed3173dc426735ff9f486194185172\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46507535\",\"name\":\"T. S. Murray\"},{\"authorId\":\"3306327\",\"name\":\"D. Mendat\"},{\"authorId\":\"3066112\",\"name\":\"P. Pouliquen\"},{\"authorId\":\"2730857\",\"name\":\"A. Andreou\"}],\"doi\":\"10.1117/12.2189349\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fa944a7ffa9e081e7cbd2ccfeea5421adcb6fbe2\",\"title\":\"The Johns Hopkins University multimodal dataset for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/fa944a7ffa9e081e7cbd2ccfeea5421adcb6fbe2\",\"venue\":\"Defense + Security Symposium\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1394018641\",\"name\":\"N. Doa\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0d5f4b6e10cc01f36108a07b2f857b41556b225c\",\"title\":\"VisualTextualRank : An Extension of VisualRank to Large-Scale Video Shot Extraction Exploiting Tag Co-occurrence \\u2217\",\"url\":\"https://www.semanticscholar.org/paper/0d5f4b6e10cc01f36108a07b2f857b41556b225c\",\"venue\":\"\",\"year\":2014},{\"arxivId\":\"1511.05914\",\"authors\":[{\"authorId\":\"2089428\",\"name\":\"D. P. Barrett\"},{\"authorId\":\"144418348\",\"name\":\"R. Xu\"},{\"authorId\":\"2910174\",\"name\":\"Haonan Yu\"},{\"authorId\":\"1737754\",\"name\":\"J. Siskind\"}],\"doi\":\"10.1007/s00138-016-0768-4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6a348493e0a3bd6b35cf02de9e71da675062841d\",\"title\":\"Collecting and annotating the large continuous action dataset\",\"url\":\"https://www.semanticscholar.org/paper/6a348493e0a3bd6b35cf02de9e71da675062841d\",\"venue\":\"Machine Vision and Applications\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48089573\",\"name\":\"Nian Chi Tay\"},{\"authorId\":\"2346406\",\"name\":\"C. Tee\"},{\"authorId\":\"1826101\",\"name\":\"T. S. Ong\"},{\"authorId\":\"3174098\",\"name\":\"P. S. Teh\"}],\"doi\":\"10.1109/ICECIE47765.2019.8974824\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8b08a222ac8c4646c31307ca05ccc0d80b066318\",\"title\":\"Abnormal Behavior Recognition using CNN-LSTM with Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/8b08a222ac8c4646c31307ca05ccc0d80b066318\",\"venue\":\"2019 1st International Conference on Electrical, Control and Instrumentation Engineering (ICECIE)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"144173710\",\"name\":\"X. Martin\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3daafe6389d877fe15d8823cdf5ac15fd919676f\",\"title\":\"Human Action Localization with Sparse Spatial Supervision\",\"url\":\"https://www.semanticscholar.org/paper/3daafe6389d877fe15d8823cdf5ac15fd919676f\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4365900\",\"name\":\"V. Srinivasan\"},{\"authorId\":\"3087384\",\"name\":\"S. Gul\"},{\"authorId\":\"1774736\",\"name\":\"S. Bosse\"},{\"authorId\":\"47451641\",\"name\":\"J. Meyer\"},{\"authorId\":\"1725545\",\"name\":\"T. Schierl\"},{\"authorId\":\"1691172\",\"name\":\"C. Hellge\"},{\"authorId\":\"1699054\",\"name\":\"W. Samek\"}],\"doi\":\"10.1109/EUVIP.2016.7764584\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1ec11e88afe24a9ed14e1244cbaaefb7e8ecb635\",\"title\":\"On the robustness of action recognition methods in compressed and pixel domain\",\"url\":\"https://www.semanticscholar.org/paper/1ec11e88afe24a9ed14e1244cbaaefb7e8ecb635\",\"venue\":\"2016 6th European Workshop on Visual Information Processing (EUVIP)\",\"year\":2016},{\"arxivId\":\"1906.06813\",\"authors\":[{\"authorId\":\"2173531\",\"name\":\"Sangwoo Cho\"},{\"authorId\":\"1691260\",\"name\":\"H. Foroosh\"}],\"doi\":\"10.1109/WACV.2018.00045\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a62f06debc0a5aa0b2652be4f6eedcbf1187d0c2\",\"title\":\"A Temporal Sequence Learning for Action Recognition and Prediction\",\"url\":\"https://www.semanticscholar.org/paper/a62f06debc0a5aa0b2652be4f6eedcbf1187d0c2\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":\"1309.5174\",\"authors\":[{\"authorId\":\"21570451\",\"name\":\"A. Barbu\"},{\"authorId\":\"38052303\",\"name\":\"S. Narayanaswamy\"},{\"authorId\":\"1737754\",\"name\":\"J. Siskind\"}],\"doi\":\"10.1109/TPAMI.2015.2505297\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3ab036b680e8408ec74f78a918f3ffbf6c906d70\",\"title\":\"Saying What You're Looking For: Linguistics Meets Video Search\",\"url\":\"https://www.semanticscholar.org/paper/3ab036b680e8408ec74f78a918f3ffbf6c906d70\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47781687\",\"name\":\"Z. Liu\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1109/ACCESS.2019.2894025\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"9e1dbea5bb15fa88af384ec1baf4a20cffb6e6a8\",\"title\":\"Spatiotemporal Relation Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9e1dbea5bb15fa88af384ec1baf4a20cffb6e6a8\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1784761\",\"name\":\"S. Kruthiventi\"},{\"authorId\":\"144682140\",\"name\":\"R. Venkatesh Babu\"}],\"doi\":\"10.1145/2683483.2683506\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"36ab64210a2fc7e999741aa69912fbc8a100da34\",\"title\":\"3D Action Recognition by Learning Sequences of Poses\",\"url\":\"https://www.semanticscholar.org/paper/36ab64210a2fc7e999741aa69912fbc8a100da34\",\"venue\":\"ICVGIP '14\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49417387\",\"name\":\"Y. Wang\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"}],\"doi\":\"10.1109/VCIP.2018.8698720\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0ecb08611d79b5799a99ea6d4dd32cebc5023d65\",\"title\":\"Convolutional Neural Networks with Generalized Attentional Pooling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/0ecb08611d79b5799a99ea6d4dd32cebc5023d65\",\"venue\":\"2018 IEEE Visual Communications and Image Processing (VCIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3050512\",\"name\":\"Eman Mohammadi\"},{\"authorId\":\"145742710\",\"name\":\"Q. Wu\"},{\"authorId\":\"145278886\",\"name\":\"M. Saif\"},{\"authorId\":\"2864059\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1016/J.NEUCOM.2019.06.097\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9edb61556c353340f53bddae2dea1145f4f11c6d\",\"title\":\"Hierarchical feature representation for unconstrained video analysis\",\"url\":\"https://www.semanticscholar.org/paper/9edb61556c353340f53bddae2dea1145f4f11c6d\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"1706.00893\",\"authors\":[{\"authorId\":\"10386960\",\"name\":\"Nazanin Mehrasa\"},{\"authorId\":\"19198359\",\"name\":\"Yatao Zhong\"},{\"authorId\":\"2123865\",\"name\":\"Frederick Tung\"},{\"authorId\":\"3004771\",\"name\":\"Luke Bornn\"},{\"authorId\":\"10771328\",\"name\":\"Greg Mori\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5141cf2e59fb2ec9bb489b9c1832447d3cd93110\",\"title\":\"Learning Person Trajectory Representations for Team Activity Analysis\",\"url\":\"https://www.semanticscholar.org/paper/5141cf2e59fb2ec9bb489b9c1832447d3cd93110\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40624178\",\"name\":\"Dinesh Singh\"},{\"authorId\":\"51292354\",\"name\":\"Abhijeet Bhure\"},{\"authorId\":\"51305895\",\"name\":\"Sumit Mamtani\"},{\"authorId\":\"34358756\",\"name\":\"C. K. Mohan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1fe1bd6b760e3059fff73d53a57ce3a6079adea1\",\"title\":\"Fast-BoW: Scaling Bag-of-Visual-Words Generation\",\"url\":\"https://www.semanticscholar.org/paper/1fe1bd6b760e3059fff73d53a57ce3a6079adea1\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3047890\",\"name\":\"Bowen Zhang\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"}],\"doi\":\"10.1109/VCIP.2015.7457864\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"046521311141cecffd17769f438d0891b4230e20\",\"title\":\"Encoding scale into fisher vector for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/046521311141cecffd17769f438d0891b4230e20\",\"venue\":\"2015 Visual Communications and Image Processing (VCIP)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47781560\",\"name\":\"Z. Liu\"},{\"authorId\":\"66454724\",\"name\":\"Zeya Li\"},{\"authorId\":\"150238936\",\"name\":\"Ming Zong\"},{\"authorId\":\"29790429\",\"name\":\"Wanting Ji\"},{\"authorId\":\"49908315\",\"name\":\"Ruili Wang\"},{\"authorId\":\"152714157\",\"name\":\"Y. Tian\"}],\"doi\":\"10.1007/978-981-15-3651-9_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9de826c60e7258e2a69b74836213fec465ef2601\",\"title\":\"Spatiotemporal Saliency Based Multi-stream Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9de826c60e7258e2a69b74836213fec465ef2601\",\"venue\":\"ACPR Workshops\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3240115\",\"name\":\"S. Megrhi\"},{\"authorId\":\"2504338\",\"name\":\"Marwa Jmal\"},{\"authorId\":\"1779304\",\"name\":\"W. Souid\\u00e8ne\"},{\"authorId\":\"1731553\",\"name\":\"Azeddine Beghdadi\"}],\"doi\":\"10.1016/j.jvcir.2016.10.016\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0de89455c24c7bc2564f56efa5ba22baa1a3065d\",\"title\":\"Spatio-temporal action localization and detection for human action recognition in big dataset\",\"url\":\"https://www.semanticscholar.org/paper/0de89455c24c7bc2564f56efa5ba22baa1a3065d\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145378980\",\"name\":\"Ye Luo\"},{\"authorId\":\"6835136\",\"name\":\"L. Cheong\"},{\"authorId\":\"144603946\",\"name\":\"A. Tran\"}],\"doi\":\"10.1109/ICCV.2015.371\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a7bd183c013bc62a95216de22387a2c89d13dba0\",\"title\":\"Actionness-Assisted Recognition of Actions\",\"url\":\"https://www.semanticscholar.org/paper/a7bd183c013bc62a95216de22387a2c89d13dba0\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/CVPR.2015.7298698\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0a28efacb92d16e6e0dd4d87b5aca91b28be8853\",\"title\":\"ActivityNet: A large-scale video benchmark for human activity understanding\",\"url\":\"https://www.semanticscholar.org/paper/0a28efacb92d16e6e0dd4d87b5aca91b28be8853\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31474374\",\"name\":\"P. Bilinski\"},{\"authorId\":\"144103389\",\"name\":\"F. Br\\u00e9mond\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bd66e77a6207ca96ae98319a1ea6769d233b672e\",\"title\":\"Video Covariance Matrix Logarithm for Human Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/bd66e77a6207ca96ae98319a1ea6769d233b672e\",\"venue\":\"IJCAI\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48967743\",\"name\":\"Yair Hanani\"},{\"authorId\":\"21494706\",\"name\":\"N. Levy\"},{\"authorId\":\"145128145\",\"name\":\"Lior Wolf\"}],\"doi\":\"10.1109/CVPRW.2013.46\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4cca640761c980c77a696a64ad3c1e95b82109be\",\"title\":\"Evaluating New Variants of Motion Interchange Patterns\",\"url\":\"https://www.semanticscholar.org/paper/4cca640761c980c77a696a64ad3c1e95b82109be\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition Workshops\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145546921\",\"name\":\"J. Qin\"},{\"authorId\":\"40241836\",\"name\":\"L. Liu\"},{\"authorId\":\"145274329\",\"name\":\"Zhaoxiang Zhang\"},{\"authorId\":\"40013375\",\"name\":\"Y. Wang\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"}],\"doi\":\"10.1109/TIP.2015.2508600\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"716521c04295cb7012884488bfd641781e39e2e0\",\"title\":\"Compressive Sequential Learning for Action Similarity Labeling\",\"url\":\"https://www.semanticscholar.org/paper/716521c04295cb7012884488bfd641781e39e2e0\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2016},{\"arxivId\":\"2006.08247\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":\"10.1016/j.patrec.2020.11.012\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"9c9ee02e3394adde596c35d1966566b2d971f426\",\"title\":\"Learn to cycle: Time-consistent feature discovery for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/9c9ee02e3394adde596c35d1966566b2d971f426\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19177140\",\"name\":\"S. Das\"},{\"authorId\":\"145745355\",\"name\":\"Rui Dai\"},{\"authorId\":\"34561667\",\"name\":\"Michal Koperski\"},{\"authorId\":\"10392396\",\"name\":\"Luca Minciullo\"},{\"authorId\":\"2645224\",\"name\":\"Lorenzo Garattoni\"},{\"authorId\":\"69929964\",\"name\":\"F. Br\\u00e9mond\"},{\"authorId\":\"2647267\",\"name\":\"G. Francesca\"}],\"doi\":\"10.1109/ICCV.2019.00092\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c17f395738bc3494974283ba9460c516a948f7ef\",\"title\":\"Toyota Smarthome: Real-World Activities of Daily Living\",\"url\":\"https://www.semanticscholar.org/paper/c17f395738bc3494974283ba9460c516a948f7ef\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23278631\",\"name\":\"Guangle Yao\"},{\"authorId\":\"49543595\",\"name\":\"X. Liu\"},{\"authorId\":\"144673774\",\"name\":\"T. Lei\"}],\"doi\":\"10.1145/3265639.3265672\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"6fdf9b9a80a2fa9c04a3966587c29d1dde978097\",\"title\":\"Action Recognition with 3D ConvNet-GRU Architecture\",\"url\":\"https://www.semanticscholar.org/paper/6fdf9b9a80a2fa9c04a3966587c29d1dde978097\",\"venue\":\"ICRCA '18\",\"year\":2018},{\"arxivId\":\"1803.07179\",\"authors\":[{\"authorId\":\"14800230\",\"name\":\"J. Zang\"},{\"authorId\":\"46659696\",\"name\":\"L. Wang\"},{\"authorId\":\"9071789\",\"name\":\"Z. Liu\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"1786361\",\"name\":\"Zhenxing Niu\"},{\"authorId\":\"144988570\",\"name\":\"Gang Hua\"},{\"authorId\":\"1715389\",\"name\":\"Nanning Zheng\"}],\"doi\":\"10.1007/978-3-319-92007-8_9\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"dd613000f7b2b6161548b1c1044ab46c7327a901\",\"title\":\"Attention-based Temporal Weighted Convolutional Neural Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/dd613000f7b2b6161548b1c1044ab46c7327a901\",\"venue\":\"AIAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2482072\",\"name\":\"Nicolas Ballas\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"},{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"1770571\",\"name\":\"Bertrand Delezoide\"},{\"authorId\":\"1742371\",\"name\":\"F. Pr\\u00eateux\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1109/ICCV.2013.336\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4aedadc4866271c8a41cfd9158e5a70bf628b94f\",\"title\":\"Space-Time Robust Representation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4aedadc4866271c8a41cfd9158e5a70bf628b94f\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1727159\",\"name\":\"Ferda Ofli\"},{\"authorId\":\"36899698\",\"name\":\"Rizwan Ahmed Chaudhry\"},{\"authorId\":\"2862376\",\"name\":\"G. Kurillo\"},{\"authorId\":\"144020730\",\"name\":\"R. Vidal\"},{\"authorId\":\"1784213\",\"name\":\"R. Bajcsy\"}],\"doi\":\"10.1109/WACV.2013.6474999\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8ab709dcffad8abdc73f264993a88f4ca4f5299b\",\"title\":\"Berkeley MHAD: A comprehensive Multimodal Human Action Database\",\"url\":\"https://www.semanticscholar.org/paper/8ab709dcffad8abdc73f264993a88f4ca4f5299b\",\"venue\":\"2013 IEEE Workshop on Applications of Computer Vision (WACV)\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8125221\",\"name\":\"H. Maia\"},{\"authorId\":\"98024338\",\"name\":\"M. Souza\"},{\"authorId\":\"46602675\",\"name\":\"A. Santos\"},{\"authorId\":\"1743455\",\"name\":\"H. Pedrini\"},{\"authorId\":\"66275285\",\"name\":\"Hemerson Tacon\"},{\"authorId\":\"145807601\",\"name\":\"A. Brito\"},{\"authorId\":\"67244903\",\"name\":\"H. Chaves\"},{\"authorId\":\"144042009\",\"name\":\"M. Vieira\"},{\"authorId\":\"3387755\",\"name\":\"S. Villela\"}],\"doi\":\"10.1109/ICMLA.2019.00290\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"45f35057fb1c653c10fd2256f7df454991698971\",\"title\":\"Learnable Visual Rhythms Based on the Stacking of Convolutional Neural Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/45f35057fb1c653c10fd2256f7df454991698971\",\"venue\":\"2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA)\",\"year\":2019},{\"arxivId\":\"1912.10405\",\"authors\":[{\"authorId\":\"52170427\",\"name\":\"Boxiao Pan\"},{\"authorId\":\"3451430\",\"name\":\"Zhangjie Cao\"},{\"authorId\":\"46408185\",\"name\":\"E. Adeli\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1609/AAAI.V34I07.6854\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"94536d1a30f83bd0327b3a7e9f3ed1a66a9a3cdc\",\"title\":\"Adversarial Cross-Domain Action Recognition with Co-Attention\",\"url\":\"https://www.semanticscholar.org/paper/94536d1a30f83bd0327b3a7e9f3ed1a66a9a3cdc\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1845905584\",\"name\":\"Simon Rei\\u00df\"},{\"authorId\":\"33390229\",\"name\":\"Alina Roitberg\"},{\"authorId\":\"67310661\",\"name\":\"Monica Haurilet\"},{\"authorId\":\"49157259\",\"name\":\"R. Stiefelhagen\"}],\"doi\":\"10.1109/CVPRW50498.2020.00459\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6f7886ee688d86a575203c1b308199a8fe6c1f5b\",\"title\":\"Activity-aware Attributes for Zero-Shot Driver Behavior Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6f7886ee688d86a575203c1b308199a8fe6c1f5b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1824096\",\"name\":\"M. Ziaeefard\"},{\"authorId\":\"2145950\",\"name\":\"R. Bergevin\"}],\"doi\":\"10.1109/CRV.2016.35\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb65bea4586db7aff66895d13c1a6b94c5364497\",\"title\":\"Integration of Uncertainty in the Analysis of Dyadic Human Activities\",\"url\":\"https://www.semanticscholar.org/paper/eb65bea4586db7aff66895d13c1a6b94c5364497\",\"venue\":\"2016 13th Conference on Computer and Robot Vision (CRV)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37977601\",\"name\":\"M. Tom\"},{\"authorId\":\"144682140\",\"name\":\"R. Venkatesh Babu\"}],\"doi\":\"10.1109/VCIP.2013.6706430\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dcea30602c4e0b7525a1bf4088620128d4cbb800\",\"title\":\"Rapid human action recognition in H.264/AVC compressed domain for video surveillance\",\"url\":\"https://www.semanticscholar.org/paper/dcea30602c4e0b7525a1bf4088620128d4cbb800\",\"venue\":\"2013 Visual Communications and Image Processing (VCIP)\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49050918\",\"name\":\"J. Zhang\"},{\"authorId\":\"37403439\",\"name\":\"H. Hu\"},{\"authorId\":\"150344317\",\"name\":\"Xinlong Lu\"}],\"doi\":\"10.1145/3321511\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"51738887bb680cc01bdd40fed98442c1b0b226cb\",\"title\":\"Moving Foreground-Aware Visual Attention and Key Volume Mining for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/51738887bb680cc01bdd40fed98442c1b0b226cb\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":\"1608.07138\",\"authors\":[{\"authorId\":\"37868227\",\"name\":\"C. D. Souza\"},{\"authorId\":\"1799820\",\"name\":\"Adrien Gaidon\"},{\"authorId\":\"2286630\",\"name\":\"E. Vig\"},{\"authorId\":\"3940956\",\"name\":\"A. Pe\\u00f1a\"}],\"doi\":\"10.1007/978-3-319-46478-7_43\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"4191d91b6f8c6e48ba6aed3451384b6122ab4a15\",\"title\":\"Sympathy for the Details: Dense Trajectories and Hybrid Classification Architectures for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4191d91b6f8c6e48ba6aed3451384b6122ab4a15\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21643049\",\"name\":\"S. Wilson\"},{\"authorId\":\"34358756\",\"name\":\"C. K. Mohan\"}],\"doi\":\"10.1109/LSP.2017.2690461\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b5a2dc4091665137d754a9ef50b6e9d06857dd18\",\"title\":\"Coherent and Noncoherent Dictionaries for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b5a2dc4091665137d754a9ef50b6e9d06857dd18\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49102268\",\"name\":\"A. Lateef\"},{\"authorId\":\"9353536\",\"name\":\"U. Eranna\"}],\"doi\":\"10.5120/CAE2018652765\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e3c10cb364bdda5b5bf15bb692a043d98b854309\",\"title\":\"Insights on Research-based Approaches in Human Activity Recognition System\",\"url\":\"https://www.semanticscholar.org/paper/e3c10cb364bdda5b5bf15bb692a043d98b854309\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145031814\",\"name\":\"J. Walker\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"66af27ae7c29f5fadf83f29b710a1b9c89987d09\",\"title\":\"Data-Driven Visual Forecasting\",\"url\":\"https://www.semanticscholar.org/paper/66af27ae7c29f5fadf83f29b710a1b9c89987d09\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143954557\",\"name\":\"J. Jones\"},{\"authorId\":\"2542995\",\"name\":\"T. Kim\"},{\"authorId\":\"51207689\",\"name\":\"Michael Peven\"},{\"authorId\":\"144878724\",\"name\":\"J. Bai\"},{\"authorId\":\"9381483\",\"name\":\"Zihao Xiao\"},{\"authorId\":\"145954571\",\"name\":\"Y. Zhang\"},{\"authorId\":\"3256056\",\"name\":\"Weichao Qiu\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"},{\"authorId\":\"1678633\",\"name\":\"Gregory Hager\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d5bb19502f8ae80d9db9e748dcb004bbeb318a17\",\"title\":\"Zero-shot Recognition of Complex Action Sequences\",\"url\":\"https://www.semanticscholar.org/paper/d5bb19502f8ae80d9db9e748dcb004bbeb318a17\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1641886189\",\"name\":\"Vali Ollah Maraghi\"},{\"authorId\":\"1692435\",\"name\":\"K. Faez\"}],\"doi\":\"10.1109/ICSPIS48872.2019.9066160\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f3d1b7d73baf3482275532604607d6756275be73\",\"title\":\"Zero-Shot Learning on Human-Object Interaction Recognition in Video\",\"url\":\"https://www.semanticscholar.org/paper/f3d1b7d73baf3482275532604607d6756275be73\",\"venue\":\"2019 5th Iranian Conference on Signal Processing and Intelligent Systems (ICSPIS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1749627\",\"name\":\"M. Leordeanu\"}],\"doi\":\"10.1007/978-3-030-42128-1_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1431aa3159e932c96265c73f9bf8fbc2fa321926\",\"title\":\"Unsupervised Learning Towards the Future\",\"url\":\"https://www.semanticscholar.org/paper/1431aa3159e932c96265c73f9bf8fbc2fa321926\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1909.08297\",\"authors\":[{\"authorId\":\"46399266\",\"name\":\"Yang Liu\"},{\"authorId\":\"1950475\",\"name\":\"Z. Lu\"},{\"authorId\":\"36190812\",\"name\":\"Jing Li\"},{\"authorId\":\"145670268\",\"name\":\"C. Yao\"},{\"authorId\":\"51055776\",\"name\":\"Yanzi Deng\"}],\"doi\":\"10.1155/2018/5345241\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fd7a3e809bc94a07f2604c1ec97d5e11080a993e\",\"title\":\"Transferable Feature Representation for Visible-to-Infrared Cross-Dataset Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fd7a3e809bc94a07f2604c1ec97d5e11080a993e\",\"venue\":\"Complex.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39974958\",\"name\":\"T. Yu\"},{\"authorId\":\"46660013\",\"name\":\"L. Wang\"},{\"authorId\":\"46181112\",\"name\":\"Chaoxu Guo\"},{\"authorId\":\"1909131\",\"name\":\"Huxiang Gu\"},{\"authorId\":\"1683738\",\"name\":\"S. Xiang\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.1016/j.patcog.2018.07.033\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0bbee095fc18a34e6bce72c51cea8f06cb5f4da0\",\"title\":\"Pseudo low rank video representation\",\"url\":\"https://www.semanticscholar.org/paper/0bbee095fc18a34e6bce72c51cea8f06cb5f4da0\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":\"1912.03442\",\"authors\":[{\"authorId\":\"49530215\",\"name\":\"Behnoosh Parsa\"},{\"authorId\":\"51036510\",\"name\":\"A. Narayanan\"},{\"authorId\":\"2086607\",\"name\":\"B. Dariush\"}],\"doi\":\"10.1109/WACV45572.2020.9093368\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"afafc4077d9ead2260c6ab12293ada21ee889747\",\"title\":\"Spatio-Temporal Pyramid Graph Convolutions for Human Action Recognition and Postural Assessment\",\"url\":\"https://www.semanticscholar.org/paper/afafc4077d9ead2260c6ab12293ada21ee889747\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1737754\",\"name\":\"J. Siskind\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"228eeb5c506030de3cf608b8ee5fb811b09f2b53\",\"title\":\"Conducting Neuroscience to Guide the Development of AI\",\"url\":\"https://www.semanticscholar.org/paper/228eeb5c506030de3cf608b8ee5fb811b09f2b53\",\"venue\":\"AAAI\",\"year\":2015},{\"arxivId\":\"2008.09412\",\"authors\":[{\"authorId\":\"8706479\",\"name\":\"Z. Yu\"},{\"authorId\":\"73819368\",\"name\":\"Benjia Zhou\"},{\"authorId\":\"1785406293\",\"name\":\"Jun Wan\"},{\"authorId\":\"8120382\",\"name\":\"P. Wang\"},{\"authorId\":\"1471684559\",\"name\":\"Haoyu Chen\"},{\"authorId\":null,\"name\":\"Xin Liu\"},{\"authorId\":\"34679741\",\"name\":\"S. Li\"},{\"authorId\":\"83433495\",\"name\":\"G. Zhao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d2fec7fd0d928788491651ef66e795c5d7b73d0b\",\"title\":\"Searching Multi-Rate and Multi-Modal Temporal Enhanced Networks for Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d2fec7fd0d928788491651ef66e795c5d7b73d0b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1503.08909\",\"authors\":[{\"authorId\":\"2340579\",\"name\":\"J. Ng\"},{\"authorId\":\"3308897\",\"name\":\"Matthew J. Hausknecht\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"49519592\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"3089272\",\"name\":\"Rajat Monga\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"}],\"doi\":\"10.1109/CVPR.2015.7299101\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5418b2a482720e013d487a385c26fae0f017c6a6\",\"title\":\"Beyond short snippets: Deep networks for video classification\",\"url\":\"https://www.semanticscholar.org/paper/5418b2a482720e013d487a385c26fae0f017c6a6\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"},{\"authorId\":\"145466505\",\"name\":\"M. Sapienza\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"04cf355db31b03a545003f6a3ee616310f43be2e\",\"title\":\"Learning pullback HMM manifolds\",\"url\":\"https://www.semanticscholar.org/paper/04cf355db31b03a545003f6a3ee616310f43be2e\",\"venue\":\"\",\"year\":2013},{\"arxivId\":\"2007.15829\",\"authors\":[{\"authorId\":\"150350159\",\"name\":\"Yadan Luo\"},{\"authorId\":\"145622169\",\"name\":\"Zi Huang\"},{\"authorId\":\"48708586\",\"name\":\"Zijian Wang\"},{\"authorId\":\"1852415\",\"name\":\"Zheng Zhang\"},{\"authorId\":\"51278862\",\"name\":\"Mahsa Baktashmotlagh\"}],\"doi\":\"10.1145/3394171.3413897\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c312bbdb66bd72643c57213cb167250cadb384a0\",\"title\":\"Adversarial Bipartite Graph Learning for Video Domain Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/c312bbdb66bd72643c57213cb167250cadb384a0\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2008.05721\",\"authors\":[{\"authorId\":\"48271129\",\"name\":\"T. Kim\"},{\"authorId\":\"98080420\",\"name\":\"H. Lee\"},{\"authorId\":\"1387831061\",\"name\":\"MyeongAh Cho\"},{\"authorId\":\"48411936\",\"name\":\"H. Lee\"},{\"authorId\":\"80069330\",\"name\":\"Dong Heon Cho\"},{\"authorId\":\"39847092\",\"name\":\"Sangyoun Lee\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"24b300420bd814e48b59a3419a22d706da6c4191\",\"title\":\"Learning Temporally Invariant and Localizable Features via Data Augmentation for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/24b300420bd814e48b59a3419a22d706da6c4191\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49722633\",\"name\":\"Jixin Liu\"},{\"authorId\":\"49722633\",\"name\":\"Jixin Liu\"},{\"authorId\":\"2000194881\",\"name\":\"R. Zhang\"},{\"authorId\":\"47530538\",\"name\":\"G. Han\"},{\"authorId\":\"144202010\",\"name\":\"Ning Sun\"},{\"authorId\":\"1687386\",\"name\":\"S. Kwong\"}],\"doi\":\"10.1016/J.SYSARC.2020.101882\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5ecda34f73c1512466b6441022f127be279a2288\",\"title\":\"Video action recognition with visual privacy protection based on compressed sensing\",\"url\":\"https://www.semanticscholar.org/paper/5ecda34f73c1512466b6441022f127be279a2288\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3136303\",\"name\":\"G. Cong\"},{\"authorId\":\"2972684\",\"name\":\"G. Domeniconi\"},{\"authorId\":\"49984779\",\"name\":\"Chih-Chieh Yang\"},{\"authorId\":\"47377263\",\"name\":\"Joshua Shapiro\"},{\"authorId\":\"32168186\",\"name\":\"F. Zhou\"},{\"authorId\":\"1795283\",\"name\":\"B. Chen\"}],\"doi\":\"10.1016/j.jpdc.2019.07.009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1d0f0e835a46a7a7938f0eab4e2234a5d2c3bb15\",\"title\":\"Fast neural network training on a cluster of GPUs for action recognition with high accuracy\",\"url\":\"https://www.semanticscholar.org/paper/1d0f0e835a46a7a7938f0eab4e2234a5d2c3bb15\",\"venue\":\"J. Parallel Distributed Comput.\",\"year\":2019},{\"arxivId\":\"1910.02793\",\"authors\":[{\"authorId\":\"144487556\",\"name\":\"Madan Ravi Ganesh\"},{\"authorId\":\"24337238\",\"name\":\"Eric Hofesmann\"},{\"authorId\":\"46184233\",\"name\":\"N. Louis\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"4dfaa337fb4cc3d7f755c258f192edc774f601fc\",\"title\":\"ViP: Video Platform for PyTorch\",\"url\":\"https://www.semanticscholar.org/paper/4dfaa337fb4cc3d7f755c258f192edc774f601fc\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1705.10420\",\"authors\":[{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1007/s11263-017-1030-x\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5615d6045301ecbc5be35e46cab711f676aadf3a\",\"title\":\"Discriminatively Learned Hierarchical Rank Pooling Networks\",\"url\":\"https://www.semanticscholar.org/paper/5615d6045301ecbc5be35e46cab711f676aadf3a\",\"venue\":\"International Journal of Computer Vision\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41052484\",\"name\":\"Girraj Pahariya\"},{\"authorId\":\"144009889\",\"name\":\"Sukhendu Das\"},{\"authorId\":\"48987367\",\"name\":\"Jaikishan Jayakumar\"},{\"authorId\":\"90011069\",\"name\":\"Samik Bannerjee\"},{\"authorId\":\"3976588\",\"name\":\"Venu R. Vangala\"},{\"authorId\":\"2391635\",\"name\":\"K. Ram\"},{\"authorId\":\"48850725\",\"name\":\"P. Mitra\"}],\"doi\":\"10.1101/252247\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"66d76ea4566bfc65b741d1105123a132873d0339\",\"title\":\"High precision automated detection of labeled nuclei in terabyte-scale whole-brain volumetric image data of mouse\",\"url\":\"https://www.semanticscholar.org/paper/66d76ea4566bfc65b741d1105123a132873d0339\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1823362\",\"name\":\"J. Uijlings\"},{\"authorId\":\"153580352\",\"name\":\"Ionut Cosmin Duta\"},{\"authorId\":\"2599281\",\"name\":\"N. Rostamzadeh\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":\"10.1145/2578726.2578744\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"2c9f85d1c6d568af3cbfbca7e62321cfcb952248\",\"title\":\"Realtime Video Classification using Dense HOF/HOG\",\"url\":\"https://www.semanticscholar.org/paper/2c9f85d1c6d568af3cbfbca7e62321cfcb952248\",\"venue\":\"ICMR\",\"year\":2014},{\"arxivId\":\"1803.10628\",\"authors\":[{\"authorId\":\"48094509\",\"name\":\"J. Wang\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1109/CVPR.2018.00126\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"7f36848ec69413253c2e76fa389424e9bf2d7054\",\"title\":\"Video Representation Learning Using Discriminative Pooling\",\"url\":\"https://www.semanticscholar.org/paper/7f36848ec69413253c2e76fa389424e9bf2d7054\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3050512\",\"name\":\"Eman Mohammadi\"},{\"authorId\":\"145742710\",\"name\":\"Q. Wu\"},{\"authorId\":\"145278886\",\"name\":\"M. Saif\"}],\"doi\":\"10.1109/SMC.2017.8122801\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7fa93e140487b4ed1d233d7348411ab254148461\",\"title\":\"Improved rank pooling strategy for complex action recognition\",\"url\":\"https://www.semanticscholar.org/paper/7fa93e140487b4ed1d233d7348411ab254148461\",\"venue\":\"2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC)\",\"year\":2017},{\"arxivId\":\"1611.06646\",\"authors\":[{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2518212\",\"name\":\"Hakan Bilen\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1109/CVPR.2017.607\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7b53a308a41507a2ef2faed78eb48812633e75fb\",\"title\":\"Self-Supervised Video Representation Learning with Odd-One-Out Networks\",\"url\":\"https://www.semanticscholar.org/paper/7b53a308a41507a2ef2faed78eb48812633e75fb\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1704.06925\",\"authors\":[{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1007/s11263-018-1111-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9297a216ee4613d2c86b2ba9aff2b29089d98120\",\"title\":\"Second-order Temporal Pooling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9297a216ee4613d2c86b2ba9aff2b29089d98120\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018},{\"arxivId\":\"1811.09961\",\"authors\":[{\"authorId\":\"144865353\",\"name\":\"B. Pang\"},{\"authorId\":\"15376265\",\"name\":\"Kaiwen Zha\"},{\"authorId\":\"3166067\",\"name\":\"Hanwen Cao\"},{\"authorId\":\"145716219\",\"name\":\"C. Shi\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"}],\"doi\":\"10.1109/CVPR.2019.00051\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"5cd3a3c746c0fdb26630c3ed483294e2daeffa38\",\"title\":\"Deep RNN Framework for Visual Sequential Applications\",\"url\":\"https://www.semanticscholar.org/paper/5cd3a3c746c0fdb26630c3ed483294e2daeffa38\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1807.09380\",\"authors\":[{\"authorId\":\"46585209\",\"name\":\"J. Wang\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2db569d7e7e230ebcbef90ad6bdf9f6ed034c00c\",\"title\":\"Contrastive Video Representation Learning via Adversarial Perturbations\",\"url\":\"https://www.semanticscholar.org/paper/2db569d7e7e230ebcbef90ad6bdf9f6ed034c00c\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1908.00275\",\"authors\":[{\"authorId\":\"31698884\",\"name\":\"M. Hua\"},{\"authorId\":\"11802634\",\"name\":\"Yibing Nan\"},{\"authorId\":\"143763659\",\"name\":\"S. Lian\"}],\"doi\":\"10.1109/ICCVW.2019.00158\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"90b11c6848e2b99674edb7ed6b16e8ba68b64036\",\"title\":\"Falls Prediction Based on Body Keypoints and Seq2Seq Architecture\",\"url\":\"https://www.semanticscholar.org/paper/90b11c6848e2b99674edb7ed6b16e8ba68b64036\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"2011.00362\",\"authors\":[{\"authorId\":\"47589719\",\"name\":\"Ashish Jaiswal\"},{\"authorId\":\"33166796\",\"name\":\"A. R. Babu\"},{\"authorId\":\"1780642035\",\"name\":\"Mohammad Zaki Zadeh\"},{\"authorId\":\"153789025\",\"name\":\"D. Banerjee\"},{\"authorId\":\"1728274\",\"name\":\"F. Makedon\"}],\"doi\":\"10.3390/technologies9010002\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"02f3c052a9cf675a6f033eac56c9dacb0a10ea28\",\"title\":\"A Survey on Contrastive Self-supervised Learning\",\"url\":\"https://www.semanticscholar.org/paper/02f3c052a9cf675a6f033eac56c9dacb0a10ea28\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1502.08029\",\"authors\":[{\"authorId\":\"145095579\",\"name\":\"L. Yao\"},{\"authorId\":\"1730844\",\"name\":\"Atousa Torabi\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"2482072\",\"name\":\"Nicolas Ballas\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":\"10.1109/ICCV.2015.512\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5f425b7abf2ed3172ed060df85bb1885860a297e\",\"title\":\"Describing Videos by Exploiting Temporal Structure\",\"url\":\"https://www.semanticscholar.org/paper/5f425b7abf2ed3172ed060df85bb1885860a297e\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3260425\",\"name\":\"Shijian Huang\"},{\"authorId\":\"2852884\",\"name\":\"Junyong Ye\"},{\"authorId\":\"46958452\",\"name\":\"TongQing Wang\"},{\"authorId\":\"144740190\",\"name\":\"L. Jiang\"},{\"authorId\":\"31735819\",\"name\":\"Y. Li\"},{\"authorId\":\"3728865\",\"name\":\"X. Wu\"}],\"doi\":\"10.1007/S13369-016-2042-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5e1db8bfc85cc2929f7a44c599e740b870aba009\",\"title\":\"Extracting Discriminative Parts with Flexible Number from Low-Rank Features for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5e1db8bfc85cc2929f7a44c599e740b870aba009\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1505.04868\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1109/CVPR.2015.7299059\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"df658828fb4146877f1031ec9d07052f7eb31186\",\"title\":\"Action recognition with trajectory-pooled deep-convolutional descriptors\",\"url\":\"https://www.semanticscholar.org/paper/df658828fb4146877f1031ec9d07052f7eb31186\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1409461476\",\"name\":\"Milad Jafari Barani\"},{\"authorId\":\"3101334\",\"name\":\"P. Ayubi\"},{\"authorId\":\"1409461484\",\"name\":\"Milad Yousefi Valandar\"},{\"authorId\":\"1409461497\",\"name\":\"Behzad Yosefnezhad Irani\"}],\"doi\":\"10.1007/s11042-019-08225-5\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d4e8b022916336c682309fecf09971e8f878e638\",\"title\":\"A blind video watermarking algorithm robust to lossy video compression attacks based on generalized Newton complex map and contourlet transform\",\"url\":\"https://www.semanticscholar.org/paper/d4e8b022916336c682309fecf09971e8f878e638\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":\"2001.05691\",\"authors\":[{\"authorId\":\"122460701\",\"name\":\"Tianhao Li\"},{\"authorId\":\"119770705\",\"name\":\"L. Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2783c13471060300e62a1eed458d9d2888b5b5be\",\"title\":\"Learning Spatiotemporal Features via Video and Text Pair Discrimination\",\"url\":\"https://www.semanticscholar.org/paper/2783c13471060300e62a1eed458d9d2888b5b5be\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.09037\",\"authors\":[{\"authorId\":\"153634296\",\"name\":\"Matthew Hutchinson\"},{\"authorId\":\"2331418\",\"name\":\"S. Samsi\"},{\"authorId\":\"3302251\",\"name\":\"W. Arcand\"},{\"authorId\":\"2159806\",\"name\":\"David Bestor\"},{\"authorId\":\"34001612\",\"name\":\"Bill Bergeron\"},{\"authorId\":\"2098646\",\"name\":\"C. Byun\"},{\"authorId\":\"1850501832\",\"name\":\"Micheal Houle\"},{\"authorId\":\"145238688\",\"name\":\"M. Hubbell\"},{\"authorId\":\"145319478\",\"name\":\"Michael J. Jones\"},{\"authorId\":\"3257323\",\"name\":\"J. Kepner\"},{\"authorId\":\"1983355\",\"name\":\"A. Kirby\"},{\"authorId\":\"1684116\",\"name\":\"P. Michaleas\"},{\"authorId\":\"3385550\",\"name\":\"Lauren Milechin\"},{\"authorId\":\"143913450\",\"name\":\"J. Mullen\"},{\"authorId\":\"2417672\",\"name\":\"A. Prout\"},{\"authorId\":\"144557576\",\"name\":\"A. Rosa\"},{\"authorId\":\"2097629\",\"name\":\"Albert Reuther\"},{\"authorId\":\"145378881\",\"name\":\"C. Yee\"},{\"authorId\":\"74882299\",\"name\":\"Vijay Gadepally\"}],\"doi\":\"10.1109/HPEC43674.2020.9286249\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"48b2b54d27898017b48f158eacabe4952a24a870\",\"title\":\"Accuracy and Performance Comparison of Video Action Recognition Approaches\",\"url\":\"https://www.semanticscholar.org/paper/48b2b54d27898017b48f158eacabe4952a24a870\",\"venue\":\"2020 IEEE High Performance Extreme Computing Conference (HPEC)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Mehreen Hurroo\"},{\"authorId\":null,\"name\":\"Mohammad Elham\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"5ecc9d2073755a1364433d83df2a4007e42b16e1\",\"title\":\"Sign Language Recognition System using Convolutional Neural Network and Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/5ecc9d2073755a1364433d83df2a4007e42b16e1\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2038499155\",\"name\":\"Yuhao Zhang\"},{\"authorId\":\"144184407\",\"name\":\"Jun Liao\"},{\"authorId\":\"52201470\",\"name\":\"Mengyuan Ran\"},{\"authorId\":\"50080172\",\"name\":\"X. Li\"},{\"authorId\":\"118188869\",\"name\":\"S. Wang\"},{\"authorId\":\"120095706\",\"name\":\"Li Liu\"}],\"doi\":\"10.1109/SMC42975.2020.9283407\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e188653c8638298f83cbadf4c92ac4d439407640\",\"title\":\"ST-Xception: A Depthwise Separable Convolution Network for Military Sign Language Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e188653c8638298f83cbadf4c92ac4d439407640\",\"venue\":\"2020 IEEE International Conference on Systems, Man, and Cybernetics (SMC)\",\"year\":2020},{\"arxivId\":\"1905.04757\",\"authors\":[{\"authorId\":\"40940512\",\"name\":\"Jun Liu\"},{\"authorId\":\"3000984\",\"name\":\"Amir Shahroudy\"},{\"authorId\":\"121247048\",\"name\":\"Mauricio Perez\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"},{\"authorId\":\"7667912\",\"name\":\"Ling-yu Duan\"},{\"authorId\":\"1711097\",\"name\":\"A. Kot\"}],\"doi\":\"10.1109/TPAMI.2019.2916873\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1b632712cd0d1f14784ba938f135960f71a52e5c\",\"title\":\"NTU RGB+D 120: A Large-Scale Benchmark for 3D Human Activity Understanding\",\"url\":\"https://www.semanticscholar.org/paper/1b632712cd0d1f14784ba938f135960f71a52e5c\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":\"2006.13017\",\"authors\":[{\"authorId\":\"143657833\",\"name\":\"Li Tao\"},{\"authorId\":\"1524733293\",\"name\":\"Xueting Wang\"},{\"authorId\":\"145572095\",\"name\":\"T. Yamasaki\"}],\"doi\":\"10.1109/ICIP40778.2020.9191133\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3cfee833437b81b89bb272dd4f5a501b61f2c0d1\",\"title\":\"Motion Representation Using Residual Frames with 3D CNN\",\"url\":\"https://www.semanticscholar.org/paper/3cfee833437b81b89bb272dd4f5a501b61f2c0d1\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153122996\",\"name\":\"Josep Maria Carmona\"},{\"authorId\":\"145105992\",\"name\":\"J. Climent\"}],\"doi\":\"10.1016/j.patcog.2018.04.015\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"17334201466dae9a7fa0c74e93472e1bb278fa80\",\"title\":\"Human action recognition by means of subtensor projections and dense trajectories\",\"url\":\"https://www.semanticscholar.org/paper/17334201466dae9a7fa0c74e93472e1bb278fa80\",\"venue\":\"Pattern Recognit.\",\"year\":2018},{\"arxivId\":\"2003.14266\",\"authors\":[{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1109/cvpr42600.2020.00058\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e1e3a36644d71bf1e8a09ad943c7a1bbb65ae73e\",\"title\":\"SCT: Set Constrained Temporal Transformer for Set Supervised Action Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/e1e3a36644d71bf1e8a09ad943c7a1bbb65ae73e\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"1959406969\",\"name\":\"Teppei Suzuki\"},{\"authorId\":\"1484094470\",\"name\":\"Kodai Nakashima\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"},{\"authorId\":\"10664005\",\"name\":\"Y. Aoki\"}],\"doi\":\"10.1109/ICRA40945.2020.9197399\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7422c29fc16151913940b0dad2eb5baec0e2dfa9\",\"title\":\"Joint Pedestrian Detection and Risk-level Prediction with Motion-Representation-by-Detection\",\"url\":\"https://www.semanticscholar.org/paper/7422c29fc16151913940b0dad2eb5baec0e2dfa9\",\"venue\":\"2020 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145377162\",\"name\":\"Y. Yuan\"},{\"authorId\":\"1700621\",\"name\":\"L. Qi\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"}],\"doi\":\"10.1016/j.imavis.2016.04.001\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"247f5089e642a52a141ce34b9a1ed71f30377ed0\",\"title\":\"Action recognition by joint learning\",\"url\":\"https://www.semanticscholar.org/paper/247f5089e642a52a141ce34b9a1ed71f30377ed0\",\"venue\":\"Image Vis. Comput.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12100407\",\"name\":\"S. Rahman\"},{\"authorId\":\"143937986\",\"name\":\"John See\"},{\"authorId\":\"2864328\",\"name\":\"Chiung Ching Ho\"}],\"doi\":\"10.1166/ASL.2017.10283\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"707ba05be4892a89aa8040b369710a17ace29f73\",\"title\":\"Deep CNN object features for improved action recognition in low quality videos\",\"url\":\"https://www.semanticscholar.org/paper/707ba05be4892a89aa8040b369710a17ace29f73\",\"venue\":\"IEEE CSE 2016\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143672034\",\"name\":\"X. Dong\"},{\"authorId\":\"1733691\",\"name\":\"A. Tsoi\"},{\"authorId\":\"1778780\",\"name\":\"S. Lo\"}],\"doi\":\"10.1109/IJCNN.2014.6889575\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f186c0d21173e5727d4557c8990d7d0d0251ade4\",\"title\":\"Superpixel appearance and motion descriptors for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/f186c0d21173e5727d4557c8990d7d0d0251ade4\",\"venue\":\"2014 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2353872\",\"name\":\"Shahzad Cheema\"},{\"authorId\":\"2914349\",\"name\":\"Abdalrahman Eweiwi\"},{\"authorId\":\"1692283\",\"name\":\"C. Bauckhage\"}],\"doi\":\"10.1016/j.dsp.2015.03.019\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"30a87c2fba9dde34775f39e12aa3f4b3eec894dd\",\"title\":\"High dimensional low sample size activity recognition using geometric classifiers\",\"url\":\"https://www.semanticscholar.org/paper/30a87c2fba9dde34775f39e12aa3f4b3eec894dd\",\"venue\":\"Digit. Signal Process.\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2013.441\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d721f4d64b8e722222c876f0a0f226ed49476347\",\"title\":\"Action Recognition with Improved Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/d721f4d64b8e722222c876f0a0f226ed49476347\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3197570\",\"name\":\"Chao-Yeh Chen\"}],\"doi\":\"10.15781/T20G3GZ9Q\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"ccd2152c77ae65e4d3d0988990f6e243133a5efc\",\"title\":\"Learning human activities and poses with interconnected data sources\",\"url\":\"https://www.semanticscholar.org/paper/ccd2152c77ae65e4d3d0988990f6e243133a5efc\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40351549\",\"name\":\"He Zhao\"},{\"authorId\":\"1516251189\",\"name\":\"Rick Wildes\"}],\"doi\":\"10.1109/ICCV.2019.00710\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"93c6f04511240bcdcb6d51d8f457559dd63f4cf2\",\"title\":\"Spatiotemporal Feature Residual Propagation for Action Prediction\",\"url\":\"https://www.semanticscholar.org/paper/93c6f04511240bcdcb6d51d8f457559dd63f4cf2\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2001.07793\",\"authors\":[{\"authorId\":\"145724888\",\"name\":\"Ashraful Islam\"},{\"authorId\":\"1772337\",\"name\":\"R. Radke\"}],\"doi\":\"10.1109/WACV45572.2020.9093620\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"145c15e10967f9eb598b62ab547312571ec3ac3c\",\"title\":\"Weakly Supervised Temporal Action Localization Using Deep Metric Learning\",\"url\":\"https://www.semanticscholar.org/paper/145c15e10967f9eb598b62ab547312571ec3ac3c\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33371794\",\"name\":\"Mouna Selmi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b3d2a2bd7ab10766c2d03371142fdf6433ef4ce5\",\"title\":\"Reconnaissance d'activit\\u00e9s humaines \\u00e0 partir de s\\u00e9quences vid\\u00e9o. (Human activity recognition from video sequences)\",\"url\":\"https://www.semanticscholar.org/paper/b3d2a2bd7ab10766c2d03371142fdf6433ef4ce5\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3429960\",\"name\":\"Youjiang Xu\"},{\"authorId\":\"49112947\",\"name\":\"Shichao Zhao\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"144281199\",\"name\":\"Q. Hu\"},{\"authorId\":\"144894849\",\"name\":\"Fei Wu\"}],\"doi\":\"10.1109/ICME.2017.8019360\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"ba30cc9d8bac724dafc0aea247159cc7e7105784\",\"title\":\"Top attention in line with time: A light-weight strategy\",\"url\":\"https://www.semanticscholar.org/paper/ba30cc9d8bac724dafc0aea247159cc7e7105784\",\"venue\":\"2017 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1414453386\",\"name\":\"Fadwa Al-Azzo\"},{\"authorId\":\"22768683\",\"name\":\"Arwa Mohammed Taqi\"},{\"authorId\":\"1795699\",\"name\":\"Mariofanna G. Milanova\"}],\"doi\":\"10.14569/IJACSA.2017.080403\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a8c8a96b78e7b8e0d4a4a422fcb083e53ad06531\",\"title\":\"3D Human Action Recognition using Hu Moment Invariants and Euclidean Distance Classifier\",\"url\":\"https://www.semanticscholar.org/paper/a8c8a96b78e7b8e0d4a4a422fcb083e53ad06531\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"1742248\",\"name\":\"P. Moulin\"},{\"authorId\":\"1795291\",\"name\":\"X. Yang\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"}],\"doi\":\"10.1109/CVPR.2015.7298993\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f467c60a2b3373018c3615f9f6d77611dff89826\",\"title\":\"Motion Part Regularization: Improving action recognition via trajectory group selection\",\"url\":\"https://www.semanticscholar.org/paper/f467c60a2b3373018c3615f9f6d77611dff89826\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4210401\",\"name\":\"Junqing Yu\"},{\"authorId\":\"51048125\",\"name\":\"Aiping Lei\"},{\"authorId\":\"15429809\",\"name\":\"Yangliu Hu\"}],\"doi\":\"10.1007/978-3-030-05716-9_31\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"168ebf77527329bc2dbd0ce82bddb9905c3aa7ee\",\"title\":\"Soccer Video Event Detection Based on Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/168ebf77527329bc2dbd0ce82bddb9905c3aa7ee\",\"venue\":\"MMM\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3045512\",\"name\":\"R. Granada\"},{\"authorId\":\"10684139\",\"name\":\"J. Aires\"},{\"authorId\":\"40235962\",\"name\":\"J. Monteiro\"},{\"authorId\":\"2920773\",\"name\":\"Felipe Meneguzzi\"},{\"authorId\":\"143914916\",\"name\":\"Rodrigo C. Barros\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9545da8b7194dd2172d2827f59a90d191336a637\",\"title\":\"Improving Action Recognition using Temporal Regions\",\"url\":\"https://www.semanticscholar.org/paper/9545da8b7194dd2172d2827f59a90d191336a637\",\"venue\":\"J. Inf. Data Manag.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50322696\",\"name\":\"Haoliang Tan\"},{\"authorId\":\"48169980\",\"name\":\"L. Wang\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"2687716\",\"name\":\"Zhanning Gao\"},{\"authorId\":\"1715389\",\"name\":\"Nanning Zheng\"},{\"authorId\":\"144988570\",\"name\":\"Gang Hua\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8715474732e8d024078d482b8d0f7cae88a31bcc\",\"title\":\"Object Affordances Graph Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8715474732e8d024078d482b8d0f7cae88a31bcc\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"fd7b6c77b46420c27725757553fcd1fb24ea29a8\",\"title\":\"MEXSVMs : Mid-level Features for Scalable Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fd7b6c77b46420c27725757553fcd1fb24ea29a8\",\"venue\":\"\",\"year\":2013},{\"arxivId\":\"1612.03777\",\"authors\":[{\"authorId\":\"31656404\",\"name\":\"N. Sedaghat\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f42dca4a4426e5873a981712102aa961be34539a\",\"title\":\"Next-Flow: Hybrid Multi-Tasking with Next-Frame Prediction to Boost Optical-Flow Estimation in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/f42dca4a4426e5873a981712102aa961be34539a\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31853287\",\"name\":\"Jun-Seong Choi\"},{\"authorId\":\"4890085\",\"name\":\"J. H. Park\"}],\"doi\":\"10.1145/3175536.3175549\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dbe00c423be0066d450e92d85c9b5efd2e068cfa\",\"title\":\"Uniform Integration and Recognition of Events based on Fine Primitives of Events in Realistic Virtual World\",\"url\":\"https://www.semanticscholar.org/paper/dbe00c423be0066d450e92d85c9b5efd2e068cfa\",\"venue\":\"ICETC 2017\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3471544\",\"name\":\"Feixiang He\"},{\"authorId\":\"2254178\",\"name\":\"Fayao Liu\"},{\"authorId\":\"145786594\",\"name\":\"Rui Yao\"},{\"authorId\":\"2604251\",\"name\":\"Guosheng Lin\"}],\"doi\":\"10.1016/J.IMAVIS.2018.12.002\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"17eaac80a260bc5d665e1035d7291293b056d3b6\",\"title\":\"Local fusion networks with chained residual pooling for video action recognition\",\"url\":\"https://www.semanticscholar.org/paper/17eaac80a260bc5d665e1035d7291293b056d3b6\",\"venue\":\"Image Vis. Comput.\",\"year\":2019},{\"arxivId\":\"1610.03898\",\"authors\":[{\"authorId\":\"1684800\",\"name\":\"J. Chen\"},{\"authorId\":\"33455548\",\"name\":\"Jonathan Wu\"},{\"authorId\":\"144055319\",\"name\":\"J. Konrad\"},{\"authorId\":\"1756038\",\"name\":\"P. Ishwar\"}],\"doi\":\"10.1109/WACV.2017.23\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c6e502fa918beeb033b9e7f6d0de83d55fa59d99\",\"title\":\"Semi-Coupled Two-Stream Fusion ConvNets for Action Recognition at Extremely Low Resolutions\",\"url\":\"https://www.semanticscholar.org/paper/c6e502fa918beeb033b9e7f6d0de83d55fa59d99\",\"venue\":\"2017 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2017},{\"arxivId\":\"1612.00881\",\"authors\":[{\"authorId\":\"37868227\",\"name\":\"C. D. Souza\"},{\"authorId\":\"1799820\",\"name\":\"Adrien Gaidon\"},{\"authorId\":\"3407519\",\"name\":\"Y. Cabon\"},{\"authorId\":\"3940956\",\"name\":\"A. Pe\\u00f1a\"}],\"doi\":\"10.1109/CVPR.2017.278\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8f31de384bee955d8faffa1efe5f7b51cb299381\",\"title\":\"Procedural Generation of Videos to Train Deep Action Recognition Networks\",\"url\":\"https://www.semanticscholar.org/paper/8f31de384bee955d8faffa1efe5f7b51cb299381\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1712.08416\",\"authors\":[{\"authorId\":\"1403581832\",\"name\":\"Laura Sevilla-Lara\"},{\"authorId\":\"2699340\",\"name\":\"Yiyi Liao\"},{\"authorId\":\"3349249\",\"name\":\"Fatma G\\u00fcney\"},{\"authorId\":\"2745026\",\"name\":\"V. Jampani\"},{\"authorId\":\"150013821\",\"name\":\"A. Geiger\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"}],\"doi\":\"10.1007/978-3-030-12939-2_20\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b4990d5eff926fb9dadceef5bb79fa1932904eeb\",\"title\":\"On the Integration of Optical Flow and Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b4990d5eff926fb9dadceef5bb79fa1932904eeb\",\"venue\":\"GCPR\",\"year\":2018},{\"arxivId\":\"1705.08421\",\"authors\":[{\"authorId\":\"39599498\",\"name\":\"C. Gu\"},{\"authorId\":\"94567368\",\"name\":\"C. Sun\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"2997956\",\"name\":\"C. Pantofaru\"},{\"authorId\":\"144711958\",\"name\":\"D. Ross\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"1758054\",\"name\":\"Y. Li\"},{\"authorId\":\"2262946\",\"name\":\"S. Ricco\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"153652146\",\"name\":\"J. Malik\"}],\"doi\":\"10.1109/CVPR.2018.00633\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"54c7c3909c7e1e827befdbe8d2595a3b196ba1b8\",\"title\":\"AVA: A Video Dataset of Spatio-Temporally Localized Atomic Visual Actions\",\"url\":\"https://www.semanticscholar.org/paper/54c7c3909c7e1e827befdbe8d2595a3b196ba1b8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1812.02707\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"2786693\",\"name\":\"C. Doersch\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2019.00033\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"94bbc4ea271c918705876b60d98d227a0ab55a43\",\"title\":\"Video Action Transformer Network\",\"url\":\"https://www.semanticscholar.org/paper/94bbc4ea271c918705876b60d98d227a0ab55a43\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50081925\",\"name\":\"L. Zhang\"},{\"authorId\":\"2032648\",\"name\":\"J. Varadarajan\"},{\"authorId\":\"47332572\",\"name\":\"Yong Pei\"}],\"doi\":\"10.1007/978-3-030-56150-5_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a8b682a04b2e14dedc4de6e889ba641078bd9d64\",\"title\":\"Action Recognition Using Co-trained Deep Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/a8b682a04b2e14dedc4de6e889ba641078bd9d64\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2007311898\",\"name\":\"Yangyang Qiao\"},{\"authorId\":\"2007310586\",\"name\":\"Whenhua Cui\"},{\"authorId\":\"1838022\",\"name\":\"Tianwei Shi\"}],\"doi\":\"10.1109/ACCESS.2020.3032533\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"2a19004227240cd365422eaa00b589469897a3d7\",\"title\":\"LaM-2SRN: A Method Which Can Enhance Local Features and Detect Moving Objects for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2a19004227240cd365422eaa00b589469897a3d7\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738469\",\"name\":\"A. Tapus\"},{\"authorId\":\"32045772\",\"name\":\"A. Bandera\"},{\"authorId\":\"1754151\",\"name\":\"R. Mart\\u00edn\"},{\"authorId\":\"2258049\",\"name\":\"L. Calderita\"}],\"doi\":\"10.1016/j.patrec.2018.03.006\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3d4248b25edbfcfa3889c55e49d3576bed685168\",\"title\":\"Perceiving the person and their interactions with the others for social robotics - A review\",\"url\":\"https://www.semanticscholar.org/paper/3d4248b25edbfcfa3889c55e49d3576bed685168\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2019},{\"arxivId\":\"1406.1881\",\"authors\":[{\"authorId\":\"2299109\",\"name\":\"L. Pishchulin\"},{\"authorId\":\"1906895\",\"name\":\"M. Andriluka\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1007/978-3-319-11752-2_56\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1ed4e6e8eecd26a2a38fe8e8c30a67dbdda88372\",\"title\":\"Fine-Grained Activity Recognition with Holistic and Pose Based Features\",\"url\":\"https://www.semanticscholar.org/paper/1ed4e6e8eecd26a2a38fe8e8c30a67dbdda88372\",\"venue\":\"GCPR\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34798935\",\"name\":\"Xiantong Zhen\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"}],\"doi\":\"10.1109/FG.2013.6553732\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a3366958cb811f0e6c6dc162beabf5cc0ad61faf\",\"title\":\"Spatio-temporal steerable pyramid for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/a3366958cb811f0e6c6dc162beabf5cc0ad61faf\",\"venue\":\"2013 10th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG)\",\"year\":2013},{\"arxivId\":\"1911.00232\",\"authors\":[{\"authorId\":\"95743023\",\"name\":\"Mathew Monfort\"},{\"authorId\":\"40544169\",\"name\":\"K. Ramakrishnan\"},{\"authorId\":\"50112310\",\"name\":\"Alex Andonian\"},{\"authorId\":\"150937390\",\"name\":\"Barry A. McNamara\"},{\"authorId\":\"118728832\",\"name\":\"A. Lascelles\"},{\"authorId\":\"35654996\",\"name\":\"B. Pan\"},{\"authorId\":\"33421444\",\"name\":\"Quanfu Fan\"},{\"authorId\":\"1891570\",\"name\":\"Dan Gutfreund\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"da0822f776025dd73698adf6ed29ac63302d1a32\",\"title\":\"Multi-Moments in Time: Learning and Interpreting Models for Multi-Action Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/da0822f776025dd73698adf6ed29ac63302d1a32\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38796462\",\"name\":\"Imen Jegham\"},{\"authorId\":\"31259963\",\"name\":\"Anouar Ben Khalifa\"},{\"authorId\":\"2880991\",\"name\":\"Ihsen Alouani\"},{\"authorId\":\"1707715\",\"name\":\"M. Mahjoub\"}],\"doi\":\"10.1016/j.image.2020.115960\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8e98a58b26e4a8832a8240d57e3a13a085d06a15\",\"title\":\"A novel public dataset for multimodal multiview and multispectral driver distraction analysis: 3MDAD\",\"url\":\"https://www.semanticscholar.org/paper/8e98a58b26e4a8832a8240d57e3a13a085d06a15\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2020},{\"arxivId\":\"2003.09087\",\"authors\":[{\"authorId\":\"50619476\",\"name\":\"Minjee Kim\"},{\"authorId\":\"7629657\",\"name\":\"Joonmyeong Choi\"},{\"authorId\":\"145979407\",\"name\":\"N. Kim\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b324999ef8d4ff5977ae02f145b7257b1638071a\",\"title\":\"Fully Automated Hand Hygiene Monitoring\\\\\\\\in Operating Room using 3D Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/b324999ef8d4ff5977ae02f145b7257b1638071a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"117491978\",\"name\":\"Mario Rodr\\u00edguez\"},{\"authorId\":\"1398367150\",\"name\":\"C. Orrite-Uru\\u00f1uela\"},{\"authorId\":\"144426554\",\"name\":\"C. Medrano\"},{\"authorId\":\"143920053\",\"name\":\"D. Makris\"}],\"doi\":\"10.1109/CVPRW.2017.166\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"27c66b87e0fbb39f68ddb783d11b5b7e807c76e8\",\"title\":\"Fast Simplex-HMM for One-Shot Learning Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/27c66b87e0fbb39f68ddb783d11b5b7e807c76e8\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2087534\",\"name\":\"Y. Zhu\"},{\"authorId\":\"1990768\",\"name\":\"Guangcan Liu\"}],\"doi\":\"10.1007/s00371-019-01770-y\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"084655e3d230385103d080544d900aa4aa91cf10\",\"title\":\"Fine-grained action recognition using multi-view attentions\",\"url\":\"https://www.semanticscholar.org/paper/084655e3d230385103d080544d900aa4aa91cf10\",\"venue\":\"The Visual Computer\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1557606546\",\"name\":\"Jose M. Rodriguez-Borbon\"},{\"authorId\":\"72445820\",\"name\":\"X. Ma\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"},{\"authorId\":\"1778860\",\"name\":\"W. Najjar\"}],\"doi\":\"10.1109/TCSVT.2019.2895304\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"62be6ce7cab06e635281bb9a8d39062b5737d43c\",\"title\":\"Heterogeneous Acceleration of HAR Applications\",\"url\":\"https://www.semanticscholar.org/paper/62be6ce7cab06e635281bb9a8d39062b5737d43c\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50376990\",\"name\":\"N. Gayathri\"},{\"authorId\":\"145389496\",\"name\":\"K. Mahesh\"}],\"doi\":\"10.1109/ICEECCOT46775.2019.9114831\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1df95f03b7bcfdd000fa79feb5e79985365a732e\",\"title\":\"An Efficient Video Indexing and Retrieval Algorithm using Ensemble Classifier\",\"url\":\"https://www.semanticscholar.org/paper/1df95f03b7bcfdd000fa79feb5e79985365a732e\",\"venue\":\"2019 4th International Conference on Electrical, Electronics, Communication, Computer Technologies and Optimization Techniques (ICEECCOT)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3190645\",\"name\":\"Xiaoqiang Yan\"},{\"authorId\":\"2382085\",\"name\":\"Y. Ye\"},{\"authorId\":\"89208746\",\"name\":\"Yiqiao Mao\"},{\"authorId\":\"46493053\",\"name\":\"Hui Yu\"}],\"doi\":\"10.1109/ACCESS.2019.2904554\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"a08d795b1bf8b29129506c826bec54786843b14b\",\"title\":\"Shared-Private Information Bottleneck Method for Cross-Modal Clustering\",\"url\":\"https://www.semanticscholar.org/paper/a08d795b1bf8b29129506c826bec54786843b14b\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"93250272\",\"name\":\"C. Cheng\"},{\"authorId\":\"47474586\",\"name\":\"Pin Lv\"},{\"authorId\":\"144985898\",\"name\":\"B. Su\"}],\"doi\":\"10.1109/ICIP.2018.8451625\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8de174e1e050e0037d1d51fa35d43b2bfcd7dc2e\",\"title\":\"Spatiotemporal Pyramid Pooling in 3D Convolutional Neural Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8de174e1e050e0037d1d51fa35d43b2bfcd7dc2e\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":\"1907.09021\",\"authors\":[{\"authorId\":\"34792847\",\"name\":\"Mina Bishay\"},{\"authorId\":\"23983998\",\"name\":\"Georgios Zoumpourlis\"},{\"authorId\":\"50058816\",\"name\":\"I. Patras\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"cc78b92306ddfd58665aeb6fb3d02d6c5d526606\",\"title\":\"TARN: Temporal Attentive Relation Network for Few-Shot and Zero-Shot Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cc78b92306ddfd58665aeb6fb3d02d6c5d526606\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145324038\",\"name\":\"H. Xu\"},{\"authorId\":\"35870173\",\"name\":\"Q. Tian\"},{\"authorId\":null,\"name\":\"Zhen Wang\"},{\"authorId\":\"46365410\",\"name\":\"Jianhui Wu\"}],\"doi\":\"10.1016/j.neucom.2016.06.017\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"412ac23dd2b180dda430c8186a9bc0c8d835e676\",\"title\":\"A joint evaluation of different dimensionality reduction techniques, fusion and learning methods for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/412ac23dd2b180dda430c8186a9bc0c8d835e676\",\"venue\":\"Neurocomputing\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47059230\",\"name\":\"L. Zhang\"},{\"authorId\":\"2014277\",\"name\":\"G. Zhu\"},{\"authorId\":\"12166382\",\"name\":\"Peiyi Shen\"},{\"authorId\":\"40403682\",\"name\":\"J. Song\"}],\"doi\":\"10.1109/ICCVW.2017.369\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"863ad2838b9b90d4461995f498a39bcd2fb87c73\",\"title\":\"Learning Spatiotemporal Features Using 3DCNN and Convolutional LSTM for Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/863ad2838b9b90d4461995f498a39bcd2fb87c73\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":\"1901.09107\",\"authors\":[{\"authorId\":\"2809915\",\"name\":\"H. AlAmri\"},{\"authorId\":\"51002409\",\"name\":\"Vincent Cartillier\"},{\"authorId\":\"50317425\",\"name\":\"Abhishek Das\"},{\"authorId\":null,\"name\":\"Jue Wang\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"153149395\",\"name\":\"P. Anderson\"},{\"authorId\":\"21472040\",\"name\":\"Irfan Essa\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"},{\"authorId\":\"1765212\",\"name\":\"C. Hori\"}],\"doi\":\"10.1109/CVPR.2019.00774\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"044c56af7005c2013ce24c7199af716319378d7f\",\"title\":\"Audio Visual Scene-Aware Dialog\",\"url\":\"https://www.semanticscholar.org/paper/044c56af7005c2013ce24c7199af716319378d7f\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.5220/0008345900110013\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"68e12c2f62a1d7a177172148711e0f83ae48d918\",\"title\":\"A Fine-grained Perspective onto Object Interactions from First-person Views\",\"url\":\"https://www.semanticscholar.org/paper/68e12c2f62a1d7a177172148711e0f83ae48d918\",\"venue\":\"VISIGRAPP\",\"year\":2019},{\"arxivId\":\"1902.07370\",\"authors\":[{\"authorId\":\"49470254\",\"name\":\"X. Zhang\"},{\"authorId\":\"3404500\",\"name\":\"Haichao Shi\"},{\"authorId\":\"49673319\",\"name\":\"Changsheng Li\"},{\"authorId\":\"145487535\",\"name\":\"Kai Zheng\"},{\"authorId\":\"1698347\",\"name\":\"Xiaobin Zhu\"},{\"authorId\":\"2055900\",\"name\":\"Lixin Duan\"}],\"doi\":\"10.1609/aaai.v33i01.33019227\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7e273f4763004d9e224e1e91c6f87e63d6d49daf\",\"title\":\"Learning Transferable Self-attentive Representations for Action Recognition in Untrimmed Videos with Weak Supervision\",\"url\":\"https://www.semanticscholar.org/paper/7e273f4763004d9e224e1e91c6f87e63d6d49daf\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23278631\",\"name\":\"Guangle Yao\"},{\"authorId\":\"23227806\",\"name\":\"Jiandan Zhong\"},{\"authorId\":\"144673774\",\"name\":\"T. Lei\"},{\"authorId\":\"49543595\",\"name\":\"X. Liu\"}],\"doi\":\"10.1109/SmartWorld.2018.00123\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"303b832123a0d219e91a3e0bed337d74f68b3fcc\",\"title\":\"Constructing Hierarchical Spatiotemporal Information for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/303b832123a0d219e91a3e0bed337d74f68b3fcc\",\"venue\":\"2018 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)\",\"year\":2018},{\"arxivId\":\"1912.03716\",\"authors\":[{\"authorId\":\"91060830\",\"name\":\"Zhiyu Yao\"},{\"authorId\":null,\"name\":\"Yunbo Wang\"},{\"authorId\":\"93640403\",\"name\":\"Xingqiang Du\"},{\"authorId\":\"35776445\",\"name\":\"Mingsheng Long\"},{\"authorId\":\"46583978\",\"name\":\"J. Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2df80c3db4550da81854e05a24e658bacec564a2\",\"title\":\"Adversarial Pyramid Network for Video Domain Generalization\",\"url\":\"https://www.semanticscholar.org/paper/2df80c3db4550da81854e05a24e658bacec564a2\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41022447\",\"name\":\"Okan K\\u00f6p\\u00fckl\\u00fc\"},{\"authorId\":\"145512909\",\"name\":\"G. Rigoll\"}],\"doi\":\"10.1109/IPAS.2018.8708895\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a8d9b1780989dcac2c6027ab155dbe8939bda56c\",\"title\":\"Analysis on Temporal Dimension of Inputs for 3D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/a8d9b1780989dcac2c6027ab155dbe8939bda56c\",\"venue\":\"2018 IEEE International Conference on Image Processing, Applications and Systems (IPAS)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46882231\",\"name\":\"Vikas Tripathi\"},{\"authorId\":\"50098979\",\"name\":\"D. Gangodkar\"},{\"authorId\":\"46709324\",\"name\":\"M. Pandey\"},{\"authorId\":\"31624058\",\"name\":\"Vishal Sanserwal\"}],\"doi\":\"10.1007/978-981-10-7563-6_42\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6a0049198a4cc4d6c0d347cdcd54ea6788d71568\",\"title\":\"An Efficient Framework Based on Segmented Block Analysis for Human Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6a0049198a4cc4d6c0d347cdcd54ea6788d71568\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2595036\",\"name\":\"I. Mocanu\"},{\"authorId\":\"143623623\",\"name\":\"B. Cramariuc\"},{\"authorId\":\"143850275\",\"name\":\"O. Balan\"},{\"authorId\":\"3088730\",\"name\":\"A. Moldoveanu\"}],\"doi\":\"10.1007/978-3-319-68548-9_66\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"70be8982a220858b0c91b679bf1c2c36255cd861\",\"title\":\"A Framework for Activity Recognition Through Deep Learning and Abnormality Detection in Daily Activities\",\"url\":\"https://www.semanticscholar.org/paper/70be8982a220858b0c91b679bf1c2c36255cd861\",\"venue\":\"ICIAP\",\"year\":2017},{\"arxivId\":\"2006.07203\",\"authors\":[{\"authorId\":\"3443095\",\"name\":\"Bruno Korbar\"},{\"authorId\":\"40052301\",\"name\":\"F. Petroni\"},{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a2bf96de7889360dce11b9fc80f578a56e63dcfc\",\"title\":\"Video Understanding as Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/a2bf96de7889360dce11b9fc80f578a56e63dcfc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.14937\",\"authors\":[{\"authorId\":\"143935879\",\"name\":\"Jonathan C. Stroud\"},{\"authorId\":\"144711958\",\"name\":\"D. Ross\"},{\"authorId\":\"1491624845\",\"name\":\"Chen Sun\"},{\"authorId\":\"145820819\",\"name\":\"Jun Deng\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"153433844\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"a1e68a2ec3a813576e2a2ba7845214862d94815e\",\"title\":\"Learning Video Representations from Textual Web Supervision\",\"url\":\"https://www.semanticscholar.org/paper/a1e68a2ec3a813576e2a2ba7845214862d94815e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47058862\",\"name\":\"L. Zhang\"},{\"authorId\":\"144950946\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"40588062\",\"name\":\"Jun Liu\"},{\"authorId\":\"3326677\",\"name\":\"Minnan Luo\"},{\"authorId\":\"153580417\",\"name\":\"M. Prakash\"},{\"authorId\":\"145788702\",\"name\":\"Alexander G. Hauptmann\"}],\"doi\":\"10.1016/j.patcog.2020.107348\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c164a4da7e69353bc76ed15a08247165c2a6ebf1\",\"title\":\"Few-shot activity recognition with cross-modal memory network\",\"url\":\"https://www.semanticscholar.org/paper/c164a4da7e69353bc76ed15a08247165c2a6ebf1\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36636989\",\"name\":\"Nenghuan Zhang\"},{\"authorId\":\"3256309\",\"name\":\"Yongbin Wang\"},{\"authorId\":\"145483154\",\"name\":\"YU Peng\"}],\"doi\":\"10.1109/ICIS.2018.8466415\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"193474d008cab9fa1c1fa81ce094d415f00b075c\",\"title\":\"A Review of Human Action Recognition in Video\",\"url\":\"https://www.semanticscholar.org/paper/193474d008cab9fa1c1fa81ce094d415f00b075c\",\"venue\":\"2018 IEEE/ACIS 17th International Conference on Computer and Information Science (ICIS)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23124669\",\"name\":\"Jiewan Zheng\"},{\"authorId\":\"40916581\",\"name\":\"Xianbin Cao\"},{\"authorId\":\"1740430\",\"name\":\"B. Zhang\"},{\"authorId\":\"34798935\",\"name\":\"Xiantong Zhen\"},{\"authorId\":\"7883602\",\"name\":\"Xiangbo Su\"}],\"doi\":\"10.1109/TNNLS.2018.2844464\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"dc95fb644c12ee9caa989390af29c969b4c1d646\",\"title\":\"Deep Ensemble Machine for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/dc95fb644c12ee9caa989390af29c969b4c1d646\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2019},{\"arxivId\":\"2008.05861\",\"authors\":[{\"authorId\":\"46584859\",\"name\":\"Jiangliu Wang\"},{\"authorId\":\"2840852\",\"name\":\"Jianbo Jiao\"},{\"authorId\":\"47908910\",\"name\":\"Y. Liu\"}],\"doi\":\"10.1007/978-3-030-58520-4_30\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"78ad3beec8cc6c331dfe491291c213214e798f45\",\"title\":\"Self-supervised Video Representation Learning by Pace Prediction\",\"url\":\"https://www.semanticscholar.org/paper/78ad3beec8cc6c331dfe491291c213214e798f45\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"143740449\",\"name\":\"Q. Peng\"}],\"doi\":\"10.1109/ICPR.2014.450\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6eab69d7b96cea6ece9aada2dccea1dafb11c100\",\"title\":\"A Joint Evaluation of Dictionary Learning and Feature Encoding for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6eab69d7b96cea6ece9aada2dccea1dafb11c100\",\"venue\":\"2014 22nd International Conference on Pattern Recognition\",\"year\":2014},{\"arxivId\":\"2005.10229\",\"authors\":[{\"authorId\":\"27575517\",\"name\":\"Dian Shao\"},{\"authorId\":\"145454812\",\"name\":\"Yue Zhao\"},{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/cvpr42600.2020.00081\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c09af0b1bdbd5d532b0d5d2ba2a2a12b29ba4f19\",\"title\":\"Intra- and Inter-Action Understanding via Temporal Action Parsing\",\"url\":\"https://www.semanticscholar.org/paper/c09af0b1bdbd5d532b0d5d2ba2a2a12b29ba4f19\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2006.01423\",\"authors\":[{\"authorId\":\"73365320\",\"name\":\"Y. Chen\"},{\"authorId\":\"35484757\",\"name\":\"Yingli Tian\"},{\"authorId\":\"3250763\",\"name\":\"Mingyi He\"}],\"doi\":\"10.1016/j.cviu.2019.102897\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"81c2145a73ab64a7bec695616d34486a860d9051\",\"title\":\"Monocular human pose estimation: A survey of deep learning-based methods\",\"url\":\"https://www.semanticscholar.org/paper/81c2145a73ab64a7bec695616d34486a860d9051\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2020},{\"arxivId\":\"2003.13886\",\"authors\":[{\"authorId\":\"51128743\",\"name\":\"Srikanth Malla\"},{\"authorId\":\"2086607\",\"name\":\"B. Dariush\"},{\"authorId\":\"37435569\",\"name\":\"Chiho Choi\"}],\"doi\":\"10.1109/cvpr42600.2020.01120\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"55303cc7773e5e0528b1dc579bcc348c0fc38569\",\"title\":\"TITAN: Future Forecast Using Action Priors\",\"url\":\"https://www.semanticscholar.org/paper/55303cc7773e5e0528b1dc579bcc348c0fc38569\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38796462\",\"name\":\"Imen Jegham\"},{\"authorId\":\"31259963\",\"name\":\"Anouar Ben Khalifa\"},{\"authorId\":\"2880991\",\"name\":\"Ihsen Alouani\"},{\"authorId\":\"1707715\",\"name\":\"M. Mahjoub\"}],\"doi\":\"10.1016/j.fsidi.2019.200901\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"46b3316944b07e1fb77c9edfa0b716a0ea9e2052\",\"title\":\"Vision-based human action recognition: An overview and real world challenges\",\"url\":\"https://www.semanticscholar.org/paper/46b3316944b07e1fb77c9edfa0b716a0ea9e2052\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3436875\",\"name\":\"Omar ElHarrouss\"},{\"authorId\":\"2380070\",\"name\":\"Noor Almaadeed\"},{\"authorId\":\"31330222\",\"name\":\"S. Al-Maadeed\"}],\"doi\":\"10.1007/978-981-15-0637-6_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0dc5686a0a4bd96a1f890cc3a315d23b73ca5f81\",\"title\":\"MHAD: Multi-Human Action Dataset\",\"url\":\"https://www.semanticscholar.org/paper/0dc5686a0a4bd96a1f890cc3a315d23b73ca5f81\",\"venue\":\"ICICT\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145745514\",\"name\":\"S. Wang\"},{\"authorId\":\"2351434\",\"name\":\"Zhongwen Xu\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"},{\"authorId\":\"145950949\",\"name\":\"Xue Li\"},{\"authorId\":\"144954902\",\"name\":\"C. Pang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1145/2505323.2505331\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f1af50b2a4590c05baa4301c226bc995f58113b5\",\"title\":\"Fall detection in multi-camera surveillance videos: experimentations and observations\",\"url\":\"https://www.semanticscholar.org/paper/f1af50b2a4590c05baa4301c226bc995f58113b5\",\"venue\":\"MIIRH '13\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1577678641\",\"name\":\"Ganesh Samarth\"},{\"authorId\":\"1974345797\",\"name\":\"Sheetal Ojha\"},{\"authorId\":\"96566998\",\"name\":\"N. Pareek\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"5624963548a28f00a3aef20dca3bdbfe3d394d9d\",\"title\":\"Knowledge Fusion Transformers for Video Action Classification\",\"url\":\"https://www.semanticscholar.org/paper/5624963548a28f00a3aef20dca3bdbfe3d394d9d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34798935\",\"name\":\"Xiantong Zhen\"},{\"authorId\":\"144513293\",\"name\":\"Feng Zheng\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"},{\"authorId\":\"40916581\",\"name\":\"Xianbin Cao\"},{\"authorId\":\"144742694\",\"name\":\"D. Xu\"}],\"doi\":\"10.1109/TMM.2017.2700204\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"7ad77b6e727795a12fdacd1f328f4f904471233f\",\"title\":\"Supervised Local Descriptor Learning for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7ad77b6e727795a12fdacd1f328f4f904471233f\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"144954807\",\"name\":\"Q. Dai\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"},{\"authorId\":\"143977389\",\"name\":\"C. Ngo\"}],\"doi\":\"10.1109/TIP.2015.2456412\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"89ff7cbcea8e69b7c3cc62a4226cc3c1d00c9766\",\"title\":\"Human Action Recognition in Unconstrained Videos by Explicit Motion Modeling\",\"url\":\"https://www.semanticscholar.org/paper/89ff7cbcea8e69b7c3cc62a4226cc3c1d00c9766\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2015},{\"arxivId\":\"1502.04681\",\"authors\":[{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"2711409\",\"name\":\"Elman Mansimov\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"title\":\"Unsupervised Learning of Video Representations using LSTMs\",\"url\":\"https://www.semanticscholar.org/paper/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21240743\",\"name\":\"Yongqiang Kong\"},{\"authorId\":\"48902208\",\"name\":\"Zhaoqiang Wei\"},{\"authorId\":\"2999650\",\"name\":\"Zhengang Wei\"},{\"authorId\":\"3050837\",\"name\":\"Shengke Wang\"},{\"authorId\":\"143750989\",\"name\":\"F. Gao\"}],\"doi\":\"10.1007/978-3-319-77383-4_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"299e4d4c575fb684f7d234ac1a693f9c75dee9a2\",\"title\":\"Exploiting Sub-region Deep Features for Specific Action Recognition in Combat Sports Video\",\"url\":\"https://www.semanticscholar.org/paper/299e4d4c575fb684f7d234ac1a693f9c75dee9a2\",\"venue\":\"PCM\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145458333\",\"name\":\"Adel Saleh\"},{\"authorId\":\"46717559\",\"name\":\"Mohamed Abdel-Nasser\"},{\"authorId\":\"35257513\",\"name\":\"Miguel \\u00c1ngel Garc\\u00eda\"},{\"authorId\":\"143844336\",\"name\":\"D. Puig\"}],\"doi\":\"10.1016/j.patrec.2017.06.010\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1dfbf2eb54e7307cbd7a4274f9368172e93645e7\",\"title\":\"Aggregating the temporal coherent descriptors in videos using multiple learning kernel for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/1dfbf2eb54e7307cbd7a4274f9368172e93645e7\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153580352\",\"name\":\"Ionut Cosmin Duta\"},{\"authorId\":\"1796198\",\"name\":\"B. Ionescu\"},{\"authorId\":\"1712839\",\"name\":\"K. Aizawa\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":\"10.1145/3078971.3078988\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8aa1591bf8fcb44f2e9f2f10d1029720ccbb8832\",\"title\":\"Simple, Efficient and Effective Encodings of Local Deep Features for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8aa1591bf8fcb44f2e9f2f10d1029720ccbb8832\",\"venue\":\"ICMR\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24337238\",\"name\":\"E. Hofesmann\"},{\"authorId\":\"144487556\",\"name\":\"Madan Ravi Ganesh\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e626c57c874d30965b08bfaa0d559d6fc35610d1\",\"title\":\"M-PACT: Michigan Platform for Activity Classification in Tensorflow\",\"url\":\"https://www.semanticscholar.org/paper/e626c57c874d30965b08bfaa0d559d6fc35610d1\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1508.03755\",\"authors\":[{\"authorId\":\"2319574\",\"name\":\"D. Potapov\"},{\"authorId\":\"3271933\",\"name\":\"M. Douze\"},{\"authorId\":\"3428663\",\"name\":\"J\\u00e9r\\u00f4me Revaud\"},{\"authorId\":\"1753355\",\"name\":\"Z. Harchaoui\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"24ff832171cb774087a614152c21f54589bf7523\",\"title\":\"Beat-Event Detection in Action Movie Franchises\",\"url\":\"https://www.semanticscholar.org/paper/24ff832171cb774087a614152c21f54589bf7523\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"16208838\",\"name\":\"A. Al-Shaikh\"},{\"authorId\":\"3330543\",\"name\":\"M. Sedky\"}],\"doi\":\"10.7753/IJCATR0803.1002\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c01f6cb3ec0b8aa417c6b39d59e4d65bda84b25c\",\"title\":\"Application of Cortical Learning Algorithms to Movement Classification\",\"url\":\"https://www.semanticscholar.org/paper/c01f6cb3ec0b8aa417c6b39d59e4d65bda84b25c\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145589539\",\"name\":\"Y. Peng\"},{\"authorId\":\"145222823\",\"name\":\"H. Ye\"},{\"authorId\":\"11320042\",\"name\":\"Yining Lin\"},{\"authorId\":\"3393850\",\"name\":\"Yixin Bao\"},{\"authorId\":\"50144563\",\"name\":\"Zhijian Zhao\"},{\"authorId\":\"31567595\",\"name\":\"Haonan Qiu\"},{\"authorId\":\"46215480\",\"name\":\"Y. Lu\"},{\"authorId\":\"36547117\",\"name\":\"L. Wang\"},{\"authorId\":\"3015119\",\"name\":\"Y. Zheng\"}],\"doi\":\"10.1145/3134263.3134264\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cec8936d97dea2fcf04f175d3facaaeb65e574bf\",\"title\":\"Large-Scale Video Classification with Elastic Streaming Sequential Data Processing System\",\"url\":\"https://www.semanticscholar.org/paper/cec8936d97dea2fcf04f175d3facaaeb65e574bf\",\"venue\":\"LSVC '17\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2827750\",\"name\":\"Berkan Solmaz\"},{\"authorId\":\"2963501\",\"name\":\"S. M. Assari\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1007/s00138-012-0449-x\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"797f32a0c07c99d2718477c2bdbce71b1ec76e62\",\"title\":\"Classifying web videos using a global video descriptor\",\"url\":\"https://www.semanticscholar.org/paper/797f32a0c07c99d2718477c2bdbce71b1ec76e62\",\"venue\":\"Machine Vision and Applications\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2959229\",\"name\":\"Fran\\u00e7ois Plesse\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"108acfe359acf6875e3ab10fad0be45f6c777ecb\",\"title\":\"Int\\u00e9gration de Connaissances aux Mod\\u00e8les Neuronaux pour la D\\u00e9tection de Relations Visuelles Rares. (Knowledge Integration into Neural Networks for the purposes of Rare Visual Relation Detection)\",\"url\":\"https://www.semanticscholar.org/paper/108acfe359acf6875e3ab10fad0be45f6c777ecb\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2739544\",\"name\":\"Shreyansh Daftry\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"155199d7f10218e29ddaee36ebe611c95cae68c4\",\"title\":\"Towards Scalable Visual Navigation of Micro Aerial Vehicles\",\"url\":\"https://www.semanticscholar.org/paper/155199d7f10218e29ddaee36ebe611c95cae68c4\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"2012.14426\",\"authors\":[{\"authorId\":\"34539976\",\"name\":\"S. Santos\"},{\"authorId\":\"23962586\",\"name\":\"J. Almeida\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1e8708dec2d5177956c2eb3d56162ffad11f85d2\",\"title\":\"Deep Learning Towards Edge Computing: Neural Networks Straight from Compressed Data\",\"url\":\"https://www.semanticscholar.org/paper/1e8708dec2d5177956c2eb3d56162ffad11f85d2\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153673581\",\"name\":\"A. Agarwal\"},{\"authorId\":\"2036985418\",\"name\":\"Bipasha Sen\"}],\"doi\":\"10.1007/978-3-030-64556-4_24\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7d6fbac51d4433646d88236acdc01f06116bd5dd\",\"title\":\"An Approach Towards Action Recognition Using Part Based Hierarchical Fusion\",\"url\":\"https://www.semanticscholar.org/paper/7d6fbac51d4433646d88236acdc01f06116bd5dd\",\"venue\":\"ISVC\",\"year\":2020},{\"arxivId\":\"2007.09835\",\"authors\":[{\"authorId\":\"48643324\",\"name\":\"Wei Niu\"},{\"authorId\":\"8712588\",\"name\":\"Mengshu Sun\"},{\"authorId\":\"48459506\",\"name\":\"Z. Li\"},{\"authorId\":\"84681008\",\"name\":\"J. Chen\"},{\"authorId\":\"1823636176\",\"name\":\"Jiexiong Guan\"},{\"authorId\":\"47435542\",\"name\":\"Xipeng Shen\"},{\"authorId\":null,\"name\":\"Yanzhi Wang\"},{\"authorId\":\"1662772707\",\"name\":\"Xue Lin\"},{\"authorId\":\"153108488\",\"name\":\"Bin Ren\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2ea24183f37578404d455dccc816a7088b0d0f99\",\"title\":\"Achieving Real-Time Execution of 3D Convolutional Neural Networks on Mobile Devices\",\"url\":\"https://www.semanticscholar.org/paper/2ea24183f37578404d455dccc816a7088b0d0f99\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.02265\",\"authors\":[{\"authorId\":\"90724813\",\"name\":\"Y. Cheng\"},{\"authorId\":\"3566342\",\"name\":\"Yuchao Yang\"},{\"authorId\":\"50688512\",\"name\":\"Haibao Chen\"},{\"authorId\":\"1873081\",\"name\":\"N. Wong\"},{\"authorId\":\"37629830\",\"name\":\"H. Yu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"085e32367a143a829fd6c6adc8e28a552afcc191\",\"title\":\"S3-Net: A Fast and Lightweight Video Scene Understanding Network by Single-shot Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/085e32367a143a829fd6c6adc8e28a552afcc191\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92148538\",\"name\":\"Di Wu\"},{\"authorId\":\"2257498\",\"name\":\"N. Sharma\"},{\"authorId\":\"1801266\",\"name\":\"M. Blumenstein\"}],\"doi\":\"10.1109/DICTA.2018.8615804\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"db86679d00baab8e21b436e05c17a661257ad8fd\",\"title\":\"Similar Gesture Recognition using Hierarchical Classification Approach in RGB Videos\",\"url\":\"https://www.semanticscholar.org/paper/db86679d00baab8e21b436e05c17a661257ad8fd\",\"venue\":\"2018 Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49039493\",\"name\":\"W. Zhang\"},{\"authorId\":\"2717876\",\"name\":\"Menglong Zhu\"},{\"authorId\":\"3150825\",\"name\":\"K. Derpanis\"}],\"doi\":\"10.1109/ICCV.2013.280\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f7636582c8abb648c4bb870b228f9ffbc6843c34\",\"title\":\"From Actemes to Action: A Strongly-Supervised Representation for Detailed Action Understanding\",\"url\":\"https://www.semanticscholar.org/paper/f7636582c8abb648c4bb870b228f9ffbc6843c34\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51936306\",\"name\":\"Swati Dewan\"},{\"authorId\":\"50230202\",\"name\":\"Shubham Agarwal\"},{\"authorId\":\"2204983\",\"name\":\"N. Singh\"}],\"doi\":\"10.1117/12.2309445\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"84fdbbe6e85ee5280af2d58f3fe24cf9d4944295\",\"title\":\"A deep learning pipeline for Indian dance style classification\",\"url\":\"https://www.semanticscholar.org/paper/84fdbbe6e85ee5280af2d58f3fe24cf9d4944295\",\"venue\":\"International Conference on Machine Vision\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47185625\",\"name\":\"F. Liu\"},{\"authorId\":\"9303726\",\"name\":\"Xiangmin Xu\"},{\"authorId\":\"37178775\",\"name\":\"Chunmei Qing\"},{\"authorId\":\"3064244\",\"name\":\"Jianxiu Jin\"}],\"doi\":\"10.1007/978-981-10-8530-7_39\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e867bb07b8213c87412e4721ec8a79080887af81\",\"title\":\"Probability Matrix SVM+ Learning for Complex Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e867bb07b8213c87412e4721ec8a79080887af81\",\"venue\":\"ICIMCS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145594181\",\"name\":\"B. Zhu\"}],\"doi\":\"10.1007/978-3-030-03338-5_27\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c9a6de2cc6a4a9f689553e92876cff646eaebae6\",\"title\":\"Feature Aggregation Tree: Capture Temporal Motion Information for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/c9a6de2cc6a4a9f689553e92876cff646eaebae6\",\"venue\":\"PRCV\",\"year\":2018},{\"arxivId\":\"1804.01429\",\"authors\":[{\"authorId\":\"2180291\",\"name\":\"Ruichi Yu\"},{\"authorId\":\"48016412\",\"name\":\"H. Wang\"},{\"authorId\":\"145476833\",\"name\":\"Ang Li\"},{\"authorId\":\"7674316\",\"name\":\"Jingxiao Zheng\"},{\"authorId\":\"2852035\",\"name\":\"V. Morariu\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/ICCV.2019.00135\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9664f41b8e21125fed01fa3858ca40949fb73e01\",\"title\":\"Layout-Induced Video Representation for Recognizing Agent-in-Place Actions\",\"url\":\"https://www.semanticscholar.org/paper/9664f41b8e21125fed01fa3858ca40949fb73e01\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2620793\",\"name\":\"M. Ramanathan\"},{\"authorId\":\"152684187\",\"name\":\"Wei-Yun Yau\"},{\"authorId\":\"1714572\",\"name\":\"E. Teoh\"},{\"authorId\":\"1387241200\",\"name\":\"N. Magnenat-Thalmann\"}],\"doi\":\"10.1109/APSIPA.2017.8282038\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"13876f084198f182f4d031c4927585a3623a181f\",\"title\":\"Pose-invariant kinematic features for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/13876f084198f182f4d031c4927585a3623a181f\",\"venue\":\"2017 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3197570\",\"name\":\"Chao-Yeh Chen\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2013.80\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"db0b7b99bf25fda8673ab169ce8c1d7cb70ff8a6\",\"title\":\"Watching Unlabeled Video Helps Learn New Human Actions from Very Few Labeled Snapshots\",\"url\":\"https://www.semanticscholar.org/paper/db0b7b99bf25fda8673ab169ce8c1d7cb70ff8a6\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3379311\",\"name\":\"Slawomir Wojciechowski\"},{\"authorId\":\"3043492\",\"name\":\"M. Kulbacki\"},{\"authorId\":\"2554241\",\"name\":\"J. Segen\"},{\"authorId\":\"3366961\",\"name\":\"Rafal Wycislok\"},{\"authorId\":\"49829226\",\"name\":\"Artur Bak\"},{\"authorId\":\"2722816\",\"name\":\"Kamil Wereszczynski\"},{\"authorId\":\"1758579\",\"name\":\"K. Wojciechowski\"}],\"doi\":\"10.1007/978-3-662-49390-8_41\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6226918e098fb9570519656ebab83a6d76bda674\",\"title\":\"Selected Space-Time Based Methods for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6226918e098fb9570519656ebab83a6d76bda674\",\"venue\":\"ACIIDS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3387591\",\"name\":\"K. Suganuma\"},{\"authorId\":\"3386099\",\"name\":\"Daiya Aida\"},{\"authorId\":\"31124896\",\"name\":\"R. Okada\"},{\"authorId\":\"3376163\",\"name\":\"Satoshi Hama\"},{\"authorId\":\"34622032\",\"name\":\"Zan Yamashita\"},{\"authorId\":\"145680943\",\"name\":\"T. Ito\"},{\"authorId\":\"48889543\",\"name\":\"Y. Sakai\"},{\"authorId\":\"5635717\",\"name\":\"K. Jo\"}],\"doi\":\"10.1145/2818498.2818509\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"080464da26f01517c782128992a7664c0c284af0\",\"title\":\"\\\"Kotoba Shintai\\\": a workshop to explore the interconnectivity between words and body movements\",\"url\":\"https://www.semanticscholar.org/paper/080464da26f01517c782128992a7664c0c284af0\",\"venue\":\"SIGGRAPH Asia Symposium on Education\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2086001\",\"name\":\"Junge Zhang\"},{\"authorId\":\"2894970\",\"name\":\"Yanhu Shan\"},{\"authorId\":\"2887871\",\"name\":\"K. Huang\"}],\"doi\":\"10.1016/j.neucom.2014.08.002\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"669c82fb3a19e0e064adac6c8efdb1bf6bc9ce5f\",\"title\":\"ISEE Smart Home (ISH): Smart video analysis for home security\",\"url\":\"https://www.semanticscholar.org/paper/669c82fb3a19e0e064adac6c8efdb1bf6bc9ce5f\",\"venue\":\"Neurocomputing\",\"year\":2015},{\"arxivId\":\"1604.06182\",\"authors\":[{\"authorId\":\"1803711\",\"name\":\"H. Idrees\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"40633675\",\"name\":\"Alex Gorban\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1016/j.cviu.2016.10.018\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c57a070724b48962935ff46ab1384d919e1d1089\",\"title\":\"The THUMOS challenge on action recognition for videos \\\"in the wild\\\"\",\"url\":\"https://www.semanticscholar.org/paper/c57a070724b48962935ff46ab1384d919e1d1089\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":\"1611.08563\",\"authors\":[{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":null,\"name\":\"Suman Saha\"},{\"authorId\":\"145466505\",\"name\":\"M. Sapienza\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":\"10.1109/ICCV.2017.393\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"df990d13fbe2e0a982061fc449e9c7e0aa9f357f\",\"title\":\"Online Real-Time Multiple Spatiotemporal Action Localisation and Prediction\",\"url\":\"https://www.semanticscholar.org/paper/df990d13fbe2e0a982061fc449e9c7e0aa9f357f\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9229148\",\"name\":\"Y. Han\"},{\"authorId\":\"48754075\",\"name\":\"P. Zhang\"},{\"authorId\":\"2628886\",\"name\":\"Tao Zhuo\"},{\"authorId\":\"1730584\",\"name\":\"W. Huang\"},{\"authorId\":\"1801395\",\"name\":\"Y. Zhang\"}],\"doi\":\"10.1016/j.patrec.2017.08.015\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"180f0de5d46522cccd34aae83716999c4a69f193\",\"title\":\"Going deeper with two-stream ConvNets for action recognition in video surveillance\",\"url\":\"https://www.semanticscholar.org/paper/180f0de5d46522cccd34aae83716999c4a69f193\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2018},{\"arxivId\":\"1611.05125\",\"authors\":[{\"authorId\":\"3121735\",\"name\":\"Paritosh Parmar\"},{\"authorId\":\"1737830\",\"name\":\"B. Morris\"}],\"doi\":\"10.1109/CVPRW.2017.16\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a53774cb7707b80ae02a0b0cd7435b00d5a1b892\",\"title\":\"Learning to Score Olympic Events\",\"url\":\"https://www.semanticscholar.org/paper/a53774cb7707b80ae02a0b0cd7435b00d5a1b892\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2910174\",\"name\":\"Haonan Yu\"},{\"authorId\":\"1737754\",\"name\":\"J. Siskind\"}],\"doi\":\"10.1007/s11263-017-1018-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"44855e53801d09763c1fb5f90ab73e5c3758a728\",\"title\":\"Sentence Directed Video Object Codiscovery\",\"url\":\"https://www.semanticscholar.org/paper/44855e53801d09763c1fb5f90ab73e5c3758a728\",\"venue\":\"International Journal of Computer Vision\",\"year\":2017},{\"arxivId\":\"2007.03056\",\"authors\":[{\"authorId\":\"19177140\",\"name\":\"S. Das\"},{\"authorId\":\"18139992\",\"name\":\"Saurav Sharma\"},{\"authorId\":\"145745355\",\"name\":\"Rui Dai\"},{\"authorId\":\"69929964\",\"name\":\"F. Br\\u00e9mond\"},{\"authorId\":\"49796048\",\"name\":\"M. Thonnat\"}],\"doi\":\"10.1007/978-3-030-58545-7_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"de51038f9f9e94fa9fdb54c5c3e911f918e87ba9\",\"title\":\"VPN: Learning Video-Pose Embedding for Activities of Daily Living\",\"url\":\"https://www.semanticscholar.org/paper/de51038f9f9e94fa9fdb54c5c3e911f918e87ba9\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2012.09542\",\"authors\":[{\"authorId\":\"2035597\",\"name\":\"N. Yudistira\"},{\"authorId\":\"145263742\",\"name\":\"M. S. Kavitha\"},{\"authorId\":\"152802242\",\"name\":\"T. Kurita\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"64eda1c73af5f24c43e60727fd3aa1e198f27ff7\",\"title\":\"Weakly-Supervised Action Localization and Action Recognition using Global-Local Attention of 3D CNN\",\"url\":\"https://www.semanticscholar.org/paper/64eda1c73af5f24c43e60727fd3aa1e198f27ff7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.14139\",\"authors\":[{\"authorId\":\"1976656211\",\"name\":\"\\u00c7agri G\\u00f6k\\u00e7e\"},{\"authorId\":\"32852728\",\"name\":\"Ogulcan \\u00d6zdemir\"},{\"authorId\":\"1944885\",\"name\":\"A. Kindiroglu\"},{\"authorId\":\"1694599\",\"name\":\"L. Akarun\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"591a11dedfb9190ec66b3cd45c67cee824187a6d\",\"title\":\"Score-level Multi Cue Fusion for Sign Language Recognition\",\"url\":\"https://www.semanticscholar.org/paper/591a11dedfb9190ec66b3cd45c67cee824187a6d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2001.00294\",\"authors\":[{\"authorId\":\"152504322\",\"name\":\"Dezhao Luo\"},{\"authorId\":\"73100429\",\"name\":\"Chang Liu\"},{\"authorId\":\"2187183\",\"name\":\"Y. Zhou\"},{\"authorId\":\"8697322\",\"name\":\"Dongbao Yang\"},{\"authorId\":\"2006302\",\"name\":\"Can Ma\"},{\"authorId\":\"12605536\",\"name\":\"Qixiang Ye\"},{\"authorId\":\"47824616\",\"name\":\"Weiping Wang\"}],\"doi\":\"10.1609/AAAI.V34I07.6840\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"63a8ad8721ae8f15f3ad27b2974aff2f90d10022\",\"title\":\"Video Cloze Procedure for Self-Supervised Spatio-Temporal Learning\",\"url\":\"https://www.semanticscholar.org/paper/63a8ad8721ae8f15f3ad27b2974aff2f90d10022\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144733334\",\"name\":\"A. Zunino\"},{\"authorId\":\"3393678\",\"name\":\"Jacopo Cavazza\"},{\"authorId\":\"134686414\",\"name\":\"Riccardo Volpi\"},{\"authorId\":\"1389596256\",\"name\":\"Pietro Morerio\"},{\"authorId\":\"37783905\",\"name\":\"Andrea Cavallo\"},{\"authorId\":\"1834966\",\"name\":\"C. Becchio\"},{\"authorId\":\"1727204\",\"name\":\"Vittorio Murino\"}],\"doi\":\"10.1007/s11263-019-01234-9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2734eeef756657296857068d386521c58228ef5b\",\"title\":\"Predicting Intentions from Motion: The Subject-Adversarial Adaptation Approach\",\"url\":\"https://www.semanticscholar.org/paper/2734eeef756657296857068d386521c58228ef5b\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49050918\",\"name\":\"J. Zhang\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1007/978-3-319-97909-0_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5549576809e8f9c3871c31285601f71d2d82ce5d\",\"title\":\"Residual Gating Fusion Network for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5549576809e8f9c3871c31285601f71d2d82ce5d\",\"venue\":\"CCBR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145161471\",\"name\":\"Y. Yoon\"},{\"authorId\":\"2199479\",\"name\":\"Jongmin Yu\"},{\"authorId\":\"2184044\",\"name\":\"Moongu Jeon\"}],\"doi\":\"10.1109/AVSS.2019.8909868\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"60d7c89c12351d5b05f221092ed537d0869228b2\",\"title\":\"Spatio-Temporal Feature Extraction and Distance Metric Learning for Unconstrained Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/60d7c89c12351d5b05f221092ed537d0869228b2\",\"venue\":\"2019 16th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46329495\",\"name\":\"Amin Ullah\"},{\"authorId\":\"143997136\",\"name\":\"Khan Muhammad\"},{\"authorId\":\"134151536\",\"name\":\"J. Del Ser\"},{\"authorId\":\"1777998\",\"name\":\"S. Baik\"},{\"authorId\":\"51905607\",\"name\":\"V. H. C. de Albuquerque\"}],\"doi\":\"10.1109/TIE.2018.2881943\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"67683171c2000e5194e50996802d39c72000b5e6\",\"title\":\"Activity Recognition Using Temporal Optical Flow Convolutional Features and Multilayer LSTM\",\"url\":\"https://www.semanticscholar.org/paper/67683171c2000e5194e50996802d39c72000b5e6\",\"venue\":\"IEEE Transactions on Industrial Electronics\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11964267\",\"name\":\"Tingwei Wang\"},{\"authorId\":\"1703445\",\"name\":\"Chuancai Liu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2c808967270cae488d0a6655594a49dda133e214\",\"title\":\"Human Action Recognition Using Supervised pLSA\",\"url\":\"https://www.semanticscholar.org/paper/2c808967270cae488d0a6655594a49dda133e214\",\"venue\":\"\",\"year\":2013},{\"arxivId\":\"1612.00472\",\"authors\":[{\"authorId\":\"2689633\",\"name\":\"Andrew Jaegle\"},{\"authorId\":\"144045396\",\"name\":\"Stephen Phillips\"},{\"authorId\":\"7975935\",\"name\":\"Daphne Ippolito\"},{\"authorId\":\"1751586\",\"name\":\"Kostas Daniilidis\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"da22b399416c39292e316d3596839cc6d5047b53\",\"title\":\"Unsupervised learning of image motion by recomposing sequences\",\"url\":\"https://www.semanticscholar.org/paper/da22b399416c39292e316d3596839cc6d5047b53\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34246012\",\"name\":\"Ryan Szeto\"},{\"authorId\":\"46793780\",\"name\":\"Ximeng Sun\"},{\"authorId\":\"103356373\",\"name\":\"Kunyi Lu\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1109/TPAMI.2019.2951667\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"64dadf96304f65af96fc6b4f82c11bc69589f547\",\"title\":\"A Temporally-Aware Interpolation Network for Video Frame Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/64dadf96304f65af96fc6b4f82c11bc69589f547\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1669712931\",\"name\":\"Arpan Gupta\"},{\"authorId\":\"3247309\",\"name\":\"Sakthi Balan Muthiah\"}],\"doi\":\"10.1145/3293353.3293415\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8889beea3ae4e529f888525e33bd2160559f9153\",\"title\":\"Temporal Cricket Stroke Localization from Untrimmed Highlight Videos\",\"url\":\"https://www.semanticscholar.org/paper/8889beea3ae4e529f888525e33bd2160559f9153\",\"venue\":\"ICVGIP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145458333\",\"name\":\"Adel Saleh\"},{\"authorId\":\"46717559\",\"name\":\"Mohamed Abdel-Nasser\"},{\"authorId\":\"2961376\",\"name\":\"Farhan Akram\"},{\"authorId\":\"35257513\",\"name\":\"Miguel \\u00c1ngel Garc\\u00eda\"},{\"authorId\":\"143844336\",\"name\":\"D. Puig\"}],\"doi\":\"10.1007/978-3-319-41501-7_37\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2497ca3fb457c11dafaaa5687bb3b5d47a747f05\",\"title\":\"Analysis of Temporal Coherence in Videos for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2497ca3fb457c11dafaaa5687bb3b5d47a747f05\",\"venue\":\"ICIAR\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37242835\",\"name\":\"Shiwei Zhang\"},{\"authorId\":\"1707161\",\"name\":\"N. Sang\"},{\"authorId\":\"40115662\",\"name\":\"Changxin Gao\"},{\"authorId\":\"49102847\",\"name\":\"Feifei Chen\"},{\"authorId\":\"50778797\",\"name\":\"Jing Hu\"}],\"doi\":\"10.1109/ACPR.2015.7486577\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f891abaaf67a8feab5e322aeb6732093a14619b9\",\"title\":\"Mid-level parts mined by feature selection for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/f891abaaf67a8feab5e322aeb6732093a14619b9\",\"venue\":\"2015 3rd IAPR Asian Conference on Pattern Recognition (ACPR)\",\"year\":2015},{\"arxivId\":\"1802.02774\",\"authors\":[{\"authorId\":\"2708397\",\"name\":\"C. Xu\"},{\"authorId\":\"144866389\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"40379722\",\"name\":\"B. Zhang\"},{\"authorId\":\"10110775\",\"name\":\"Z. Chen\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"55c68c1237166679d2cb65f266f496d1ecd4bec6\",\"title\":\"Learning to score the figure skating sports videos\",\"url\":\"https://www.semanticscholar.org/paper/55c68c1237166679d2cb65f266f496d1ecd4bec6\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48072671\",\"name\":\"Dongfeng Gu\"}],\"doi\":\"10.20381/RUOR-21013\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"98a81baa53847a397d7948b9ecfcb72f67691518\",\"title\":\"3D Densely Connected Convolutional Network for the Recognition of Human Shopping Actions\",\"url\":\"https://www.semanticscholar.org/paper/98a81baa53847a397d7948b9ecfcb72f67691518\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8897402\",\"name\":\"Feng-Ping An\"}],\"doi\":\"10.1109/ACCESS.2018.2874022\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f1ef5156eccee6c845bb9f0a99a3943218e145a3\",\"title\":\"Human Action Recognition Algorithm Based on Adaptive Initialization of Deep Learning Model Parameters and Support Vector Machine\",\"url\":\"https://www.semanticscholar.org/paper/f1ef5156eccee6c845bb9f0a99a3943218e145a3\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":\"1908.10899\",\"authors\":[{\"authorId\":\"3355010\",\"name\":\"Greg Casta\\u00f1\\u00f3n\"},{\"authorId\":\"2962929\",\"name\":\"Nathan Shnidman\"},{\"authorId\":\"50780334\",\"name\":\"Tim Anderson\"},{\"authorId\":\"145607579\",\"name\":\"Jeffrey Byrne\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8eae86794cb94adfc3022a6929d58c961ad73c1c\",\"title\":\"Out the Window: A Crowd-Sourced Dataset for Activity Classification in Surveillance Video\",\"url\":\"https://www.semanticscholar.org/paper/8eae86794cb94adfc3022a6929d58c961ad73c1c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9355577\",\"name\":\"Shangqian Gao\"},{\"authorId\":\"145809539\",\"name\":\"Cheng Deng\"},{\"authorId\":\"1748032\",\"name\":\"Heng Huang\"}],\"doi\":\"10.1109/CVPR.2019.00918\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d80b8ddc5711a31a4ae82f6ad6d29e528d5e82c3\",\"title\":\"Cross Domain Model Compression by Structurally Weight Sharing\",\"url\":\"https://www.semanticscholar.org/paper/d80b8ddc5711a31a4ae82f6ad6d29e528d5e82c3\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1908.02486\",\"authors\":[{\"authorId\":\"51128181\",\"name\":\"Boyuan Jiang\"},{\"authorId\":\"47446949\",\"name\":\"M. Wang\"},{\"authorId\":\"35893447\",\"name\":\"W. Gan\"},{\"authorId\":\"145717890\",\"name\":\"W. Wu\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\"}],\"doi\":\"10.1109/ICCV.2019.00209\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b812b20192ffac37b03bde0261934a2a8c7fdf47\",\"title\":\"STM: SpatioTemporal and Motion Encoding for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b812b20192ffac37b03bde0261934a2a8c7fdf47\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2001.05060\",\"authors\":[{\"authorId\":\"2180892\",\"name\":\"Yikang Li\"},{\"authorId\":\"144149597\",\"name\":\"Tianshu Yu\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f24594e87dd1b2139197c3b22e88518a6b05892c\",\"title\":\"Recognizing Video Events with Varying Rhythms\",\"url\":\"https://www.semanticscholar.org/paper/f24594e87dd1b2139197c3b22e88518a6b05892c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Roshan Rane\"},{\"authorId\":\"150333998\",\"name\":\"Vageesh Saxena\"},{\"authorId\":\"150096315\",\"name\":\"Edit Sz\\u00fcgyi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"bc7ea2da9346c1e77215f0fe139e9036996ad05d\",\"title\":\"Video Action Classification Using PredNet\",\"url\":\"https://www.semanticscholar.org/paper/bc7ea2da9346c1e77215f0fe139e9036996ad05d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49050918\",\"name\":\"J. Zhang\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1016/J.PATCOG.2019.01.027\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"439668462b3630ba6c43aec8a24a53ea8a316491\",\"title\":\"Domain learning joint with semantic adaptation for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/439668462b3630ba6c43aec8a24a53ea8a316491\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":\"1810.06827\",\"authors\":[{\"authorId\":\"3415077\",\"name\":\"Sameera Ramasinghe\"},{\"authorId\":\"32548363\",\"name\":\"Jathushan Rajasegaran\"},{\"authorId\":\"32446834\",\"name\":\"Vinoj Jayasundara\"},{\"authorId\":\"48430646\",\"name\":\"Kanchana Ranasinghe\"},{\"authorId\":\"144952844\",\"name\":\"R. Rodrigo\"},{\"authorId\":\"144224514\",\"name\":\"A. Pasqual\"}],\"doi\":\"10.1109/TCSVT.2017.2760858\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"065b1e1c48de3aa525f6dc18bef317b90da67e1e\",\"title\":\"Combined Static and Motion Features for Deep-Networks-Based Activity Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/065b1e1c48de3aa525f6dc18bef317b90da67e1e\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1470727828\",\"name\":\"Yongyang Xu\"},{\"authorId\":\"30411581\",\"name\":\"Y. Feng\"},{\"authorId\":\"145980916\",\"name\":\"Zhong Xie\"},{\"authorId\":\"1491410471\",\"name\":\"Mingyu Xie\"},{\"authorId\":\"102577932\",\"name\":\"W. Luo\"}],\"doi\":\"10.1109/ACCESS.2020.3022407\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"b21c6a492e8330111ad19d9a708fb25a0c8eca7f\",\"title\":\"Action Recognition Using High Temporal Resolution 3D Neural Network Based on Dilated Convolution\",\"url\":\"https://www.semanticscholar.org/paper/b21c6a492e8330111ad19d9a708fb25a0c8eca7f\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1927029\",\"name\":\"S. Bandla\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/ICCV.2013.230\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"316b97266fd0be2523c73146d1e902797049825a\",\"title\":\"Active Learning of an Action Detector from Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/316b97266fd0be2523c73146d1e902797049825a\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46882231\",\"name\":\"Vikas Tripathi\"},{\"authorId\":\"50098979\",\"name\":\"D. Gangodkar\"},{\"authorId\":\"2979208\",\"name\":\"A. Mittal\"},{\"authorId\":\"143756267\",\"name\":\"V. Kanth\"}],\"doi\":\"10.1016/J.PROCS.2017.09.094\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"852a0f4d84dbd557c9371d39d77841a1ca5e0b87\",\"title\":\"Robust Action Recognition framework using Segmented Block and Distance Mean Histogram of Gradients Approach\",\"url\":\"https://www.semanticscholar.org/paper/852a0f4d84dbd557c9371d39d77841a1ca5e0b87\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152506137\",\"name\":\"F. Zhu\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"},{\"authorId\":\"144145644\",\"name\":\"Yi Fang\"}],\"doi\":\"10.1109/MIS.2016.30\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ed3e078b94055a77ffefb7822d38ae51c43ff189\",\"title\":\"Boosted Cross-Domain Dictionary Learning for Visual Categorization\",\"url\":\"https://www.semanticscholar.org/paper/ed3e078b94055a77ffefb7822d38ae51c43ff189\",\"venue\":\"IEEE Intelligent Systems\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145466505\",\"name\":\"M. Sapienza\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"}],\"doi\":\"10.5244/C.26.123\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a302a0040a8472aa652b487aa0276fd6e4327e6d\",\"title\":\"Learning discriminative space-time actions from weakly labelled videos\",\"url\":\"https://www.semanticscholar.org/paper/a302a0040a8472aa652b487aa0276fd6e4327e6d\",\"venue\":\"BMVC\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2038786\",\"name\":\"Wentao Fan\"},{\"authorId\":\"1729109\",\"name\":\"N. Bouguila\"},{\"authorId\":\"40246571\",\"name\":\"X. Liu\"}],\"doi\":\"10.1007/s10044-018-00767-y\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e2deda42f50045963080ed22d090a760cd0c8148\",\"title\":\"A nonparametric Bayesian learning model using accelerated variational inference and feature selection\",\"url\":\"https://www.semanticscholar.org/paper/e2deda42f50045963080ed22d090a760cd0c8148\",\"venue\":\"Pattern Analysis and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151493680\",\"name\":\"Jingjun Chen\"},{\"authorId\":\"1682580\",\"name\":\"Y. Song\"},{\"authorId\":\"1591129121\",\"name\":\"Yuanlin Zhang\"}],\"doi\":\"10.1109/ICME.2019.00185\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1bbeaa4279bd31729d718c76d62c0b314fe7b20b\",\"title\":\"Spatial Mask ConvLSTM Network and Intra-Class Joint Training Method for Human Action Recognition in Video\",\"url\":\"https://www.semanticscholar.org/paper/1bbeaa4279bd31729d718c76d62c0b314fe7b20b\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1729341168\",\"name\":\"Andrew M Heroy\"},{\"authorId\":\"69435509\",\"name\":\"Zackary A. Gill\"},{\"authorId\":\"48738630\",\"name\":\"Samantha A. Sprague\"},{\"authorId\":\"6151474\",\"name\":\"D. Stroud\"},{\"authorId\":\"144194404\",\"name\":\"John Santerre\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f5c0453d3e562002a7a211c298c89fb489af2f96\",\"title\":\"Stationary Exercise Classification using IMUs and Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/f5c0453d3e562002a7a211c298c89fb489af2f96\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1812.00722\",\"authors\":[{\"authorId\":\"2539459\",\"name\":\"Petros Koutras\"},{\"authorId\":\"1750686\",\"name\":\"P. Maragos\"}],\"doi\":\"10.1109/CVPRW.2019.00109\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e330af2d061ade245622b9445d5be9717f66b60f\",\"title\":\"SUSiNet: See, Understand and Summarize It\",\"url\":\"https://www.semanticscholar.org/paper/e330af2d061ade245622b9445d5be9717f66b60f\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47286885\",\"name\":\"Jingyi Hou\"},{\"authorId\":\"2125709\",\"name\":\"Xinxiao Wu\"},{\"authorId\":\"9177510\",\"name\":\"Y. Sun\"},{\"authorId\":\"7415267\",\"name\":\"Y. Jia\"}],\"doi\":\"10.1109/TMM.2017.2771462\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3c09fb7fe1886072670e0c4dd632d052102a3733\",\"title\":\"Content-Attention Representation by Factorized Action-Scene Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3c09fb7fe1886072670e0c4dd632d052102a3733\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2545383\",\"name\":\"Mathieu Barnachon\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"96428399e8581c93a4fcc6fb1f6aa73f95ea3366\",\"title\":\"Reconnaissance d'actions en temps r\\u00e9el \\u00e0 partir d'exemples. (Real time actions recognition from examplars)\",\"url\":\"https://www.semanticscholar.org/paper/96428399e8581c93a4fcc6fb1f6aa73f95ea3366\",\"venue\":\"\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145031879\",\"name\":\"T. Poggio\"},{\"authorId\":\"34911188\",\"name\":\"S. Smale\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"efd9cf5ded0aaa9f7a36b589a8e2d0fd1ca4bd79\",\"title\":\"AFRL-OSR-VA-TR-2013-0116 Hierarchical Kernel Machines : The Mathematics of Learning Inspired by Visual CortexTitle , i . e , Synthetic Aperture Ladar for Tactical Imaging\",\"url\":\"https://www.semanticscholar.org/paper/efd9cf5ded0aaa9f7a36b589a8e2d0fd1ca4bd79\",\"venue\":\"\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34936010\",\"name\":\"R. Granada\"},{\"authorId\":\"34096735\",\"name\":\"R. Pereira\"},{\"authorId\":\"40235962\",\"name\":\"J. Monteiro\"},{\"authorId\":\"143914916\",\"name\":\"Rodrigo C. Barros\"},{\"authorId\":\"1868730\",\"name\":\"D. Ruiz\"},{\"authorId\":\"2920773\",\"name\":\"Felipe Meneguzzi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"82e595b287163e6c263d7df3a770ba38b7d71e79\",\"title\":\"Hybrid Activity and Plan Recognition for Video Streams\",\"url\":\"https://www.semanticscholar.org/paper/82e595b287163e6c263d7df3a770ba38b7d71e79\",\"venue\":\"AAAI Workshops\",\"year\":2017},{\"arxivId\":\"2011.10185\",\"authors\":[{\"authorId\":\"2545360\",\"name\":\"Zhouyong Liu\"},{\"authorId\":\"1996150477\",\"name\":\"Shun Luo\"},{\"authorId\":\"3335945\",\"name\":\"Wubin Li\"},{\"authorId\":\"2027604839\",\"name\":\"Jingben Lu\"},{\"authorId\":\"1390683331\",\"name\":\"Yufan Wu\"},{\"authorId\":\"1726286\",\"name\":\"Chunguo Li\"},{\"authorId\":\"97745176\",\"name\":\"L. Yang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"43df53137dfaac590600c4c3dfe1fa0f54148774\",\"title\":\"ConvTransformer: A Convolutional Transformer Network for Video Frame Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/43df53137dfaac590600c4c3dfe1fa0f54148774\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144009889\",\"name\":\"Sukhendu Das\"},{\"authorId\":\"25655386\",\"name\":\"J. Jayakumar\"},{\"authorId\":\"2643208\",\"name\":\"Samik Banerjee\"},{\"authorId\":\"1600703039\",\"name\":\"Janani Ramaswamy\"},{\"authorId\":\"46795035\",\"name\":\"Venu R. Vangala\"},{\"authorId\":\"2391635\",\"name\":\"K. Ram\"},{\"authorId\":\"48850725\",\"name\":\"P. Mitra\"}],\"doi\":\"10.1101/252247\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b15cb536c3cd90314e947721662228e99b5caabc\",\"title\":\"High precision automated detection of labeled nuclei in Gigapixel resolution image data of Mouse Brain\",\"url\":\"https://www.semanticscholar.org/paper/b15cb536c3cd90314e947721662228e99b5caabc\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48447537\",\"name\":\"Haijun Liu\"},{\"authorId\":\"2019481\",\"name\":\"S. Wang\"},{\"authorId\":\"97520398\",\"name\":\"Wen Wang\"},{\"authorId\":\"144569543\",\"name\":\"J. Cheng\"}],\"doi\":\"10.1109/TMM.2019.2929923\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e0ab0522090b2c1e84dd7a4245d3f784ac17f59e\",\"title\":\"Multi-Scale Based Context-Aware Net for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/e0ab0522090b2c1e84dd7a4245d3f784ac17f59e\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46324489\",\"name\":\"Qing Zhang\"},{\"authorId\":\"2849542\",\"name\":\"H. Yan\"},{\"authorId\":\"46660013\",\"name\":\"L. Wang\"}],\"doi\":\"10.1007/978-3-030-31654-9_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e78f395fe206fe3db5efb64bb891bee23b0fa2cf\",\"title\":\"Multi-scale Spatial-Temporal Attention for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e78f395fe206fe3db5efb64bb891bee23b0fa2cf\",\"venue\":\"PRCV\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1703732\",\"name\":\"Shengquan Wang\"},{\"authorId\":\"1644912978\",\"name\":\"Jun Kong\"},{\"authorId\":\"145309461\",\"name\":\"Min Jiang\"},{\"authorId\":\"1878899344\",\"name\":\"Tianshan Liu\"}],\"doi\":\"10.1016/J.JVCIR.2020.102929\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b4ecb7e69e64c9f1a49cc718175e8af7b797cae9\",\"title\":\"Multiple depth-levels features fusion enhanced network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/b4ecb7e69e64c9f1a49cc718175e8af7b797cae9\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2020},{\"arxivId\":\"1903.01038\",\"authors\":[{\"authorId\":\"3530540\",\"name\":\"Yunbo Wang\"},{\"authorId\":\"35776445\",\"name\":\"Mingsheng Long\"},{\"authorId\":\"1751179\",\"name\":\"J. Wang\"},{\"authorId\":\"144019071\",\"name\":\"Philip S. Yu\"}],\"doi\":\"10.1109/CVPR.2017.226\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f1f66207713871da193af24e19a5d8855bfe7f5a\",\"title\":\"Spatiotemporal Pyramid Network for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f1f66207713871da193af24e19a5d8855bfe7f5a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1799820\",\"name\":\"Adrien Gaidon\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"71cbe1b52e2fdb8fa8a8278eb590f8065d3e7fcb\",\"title\":\"Mod\\u00e8les structur\\u00e9s pour la reconnaissance d'actions dans des vid\\u00e9os r\\u00e9alistes\",\"url\":\"https://www.semanticscholar.org/paper/71cbe1b52e2fdb8fa8a8278eb590f8065d3e7fcb\",\"venue\":\"\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1706670\",\"name\":\"X. He\"},{\"authorId\":\"1760393\",\"name\":\"S. Luo\"},{\"authorId\":\"143719919\",\"name\":\"D. Tao\"},{\"authorId\":\"145194969\",\"name\":\"C. Xu\"},{\"authorId\":\"46478312\",\"name\":\"J. Yang\"},{\"authorId\":\"1967144\",\"name\":\"M. A. Hasan\"}],\"doi\":\"10.1007/978-3-319-14442-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b33bbdac96c3540ebb07c3655643e6badc368c59\",\"title\":\"MultiMedia Modeling\",\"url\":\"https://www.semanticscholar.org/paper/b33bbdac96c3540ebb07c3655643e6badc368c59\",\"venue\":\"Lecture Notes in Computer Science\",\"year\":2015},{\"arxivId\":\"1811.09974\",\"authors\":[{\"authorId\":\"3128506\",\"name\":\"Yanghao Li\"},{\"authorId\":\"3384254\",\"name\":\"Sijie Song\"},{\"authorId\":\"50023941\",\"name\":\"Y. Li\"},{\"authorId\":\"41127426\",\"name\":\"Jiaying Liu\"}],\"doi\":\"10.1609/aaai.v33i01.33018674\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6ae72dc774f62b190036fb094be4558d827e53d2\",\"title\":\"Temporal Bilinear Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6ae72dc774f62b190036fb094be4558d827e53d2\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2266110\",\"name\":\"Terrell R. Bennett\"},{\"authorId\":\"38456584\",\"name\":\"Hunter Massey\"},{\"authorId\":\"46177912\",\"name\":\"Jian Wu\"},{\"authorId\":\"31078757\",\"name\":\"Syed Muhammad Ali Hasnain\"},{\"authorId\":\"49564046\",\"name\":\"R. Jafari\"}],\"doi\":\"10.1109/JSEN.2016.2562599\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bcb1de0c1e7d9bc66303265fe680afeed538c90e\",\"title\":\"MotionSynthesis Toolset (MoST): An Open Source Tool and Data Set for Human Motion Data Synthesis and Validation\",\"url\":\"https://www.semanticscholar.org/paper/bcb1de0c1e7d9bc66303265fe680afeed538c90e\",\"venue\":\"IEEE Sensors Journal\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2761710\",\"name\":\"Dengdi Sun\"},{\"authorId\":\"46476972\",\"name\":\"Hanqing Wu\"},{\"authorId\":\"2430623\",\"name\":\"Zhuanlian Ding\"},{\"authorId\":\"144625999\",\"name\":\"B. Luo\"},{\"authorId\":\"37864689\",\"name\":\"Jin Tang\"}],\"doi\":\"10.1007/978-3-030-00776-8_78\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"99cea5d749086408983e54e4ce7e27a5d35e9c9f\",\"title\":\"Spatial-Temporal Attention for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/99cea5d749086408983e54e4ce7e27a5d35e9c9f\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405073588\",\"name\":\"Itsaso Rodr\\u00edguez-Moreno\"},{\"authorId\":\"1401677216\",\"name\":\"J. M. Mart\\u00ednez-Otzeta\"},{\"authorId\":\"144286136\",\"name\":\"B. Sierra\"},{\"authorId\":\"24857630\",\"name\":\"I. Rodriguez\"},{\"authorId\":\"95170363\",\"name\":\"E. Jauregi\"}],\"doi\":\"10.3390/s19143160\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"44f1ae791e8e858a9c7060e42d5db76b170b51e0\",\"title\":\"Video Activity Recognition: State-of-the-Art\",\"url\":\"https://www.semanticscholar.org/paper/44f1ae791e8e858a9c7060e42d5db76b170b51e0\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40554343\",\"name\":\"Abigail H Lee\"},{\"authorId\":\"4292339\",\"name\":\"M. Johnson\"},{\"authorId\":\"1473243160\",\"name\":\"Rochelle Mendonca\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"af5b76a322354c773567cf0a324921c945fd0437\",\"title\":\"Developing and Evaluating Performance of DNN-built Stroke Rehabilitation Robot in Estimating Functional Tasks\",\"url\":\"https://www.semanticscholar.org/paper/af5b76a322354c773567cf0a324921c945fd0437\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31595791\",\"name\":\"J. Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"afff493f38dc2ce94bc469617a83a7c078e0a183\",\"title\":\"Set-Constrained Viterbi for Set-Supervised Action Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/afff493f38dc2ce94bc469617a83a7c078e0a183\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1808816\",\"name\":\"Jianxin Wu\"},{\"authorId\":\"2226422\",\"name\":\"Bin-Bin Gao\"},{\"authorId\":\"144349436\",\"name\":\"G. Liu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8b30259a8ab07394d4dac971f3d3bd633beac811\",\"title\":\"Representing Sets of Instances for Visual Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b30259a8ab07394d4dac971f3d3bd633beac811\",\"venue\":\"AAAI\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1701986\",\"name\":\"S\\u00e9verine Dubuisson\"},{\"authorId\":\"144345068\",\"name\":\"C. Gonzales\"}],\"doi\":\"10.1007/s00138-015-0713-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8da0771e47c32405c4877cedce3ff84ac7390646\",\"title\":\"A survey of datasets for visual tracking\",\"url\":\"https://www.semanticscholar.org/paper/8da0771e47c32405c4877cedce3ff84ac7390646\",\"venue\":\"Machine Vision and Applications\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145607579\",\"name\":\"J. Byrne\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"f782ad069edf3d3d0b619706dac38d40ed01c867\",\"title\":\"Shape representations using nested descriptors\",\"url\":\"https://www.semanticscholar.org/paper/f782ad069edf3d3d0b619706dac38d40ed01c867\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49058762\",\"name\":\"Yongwon Hong\"},{\"authorId\":\"144020384\",\"name\":\"Hoseong Kim\"},{\"authorId\":\"144036125\",\"name\":\"H. Byun\"}],\"doi\":\"10.1145/3265987.3265988\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"2c9f486fcec3c80a41fcecf33b6f4653bac1aaf5\",\"title\":\"Multi-task Joint Learning for Videos in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/2c9f486fcec3c80a41fcecf33b6f4653bac1aaf5\",\"venue\":\"CoVieW@MM\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1742524784\",\"name\":\"Xin Xiong\"},{\"authorId\":\"34924661\",\"name\":\"Weidong Min\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"},{\"authorId\":\"91841568\",\"name\":\"P. Liao\"},{\"authorId\":\"143727903\",\"name\":\"H. Yang\"},{\"authorId\":\"145720715\",\"name\":\"Shuai Wang\"}],\"doi\":\"10.1007/s10489-020-01751-y\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"14be70141c6fc425f280443d671412676b56bb4a\",\"title\":\"S3D-CNN: skeleton-based 3D consecutive-low-pooling neural network for fall detection\",\"url\":\"https://www.semanticscholar.org/paper/14be70141c6fc425f280443d671412676b56bb4a\",\"venue\":\"Applied Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50750258\",\"name\":\"T. Okawara\"},{\"authorId\":\"80809027\",\"name\":\"M. Yoshida\"},{\"authorId\":\"145800886\",\"name\":\"H. Nagahara\"},{\"authorId\":\"1715071\",\"name\":\"Y. Yagi\"}],\"doi\":\"10.1109/ICCP48838.2020.9105176\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"90ccdae5898712d2cb59d52f6aad0aeb64066eb6\",\"title\":\"Action Recognition from a Single Coded Image\",\"url\":\"https://www.semanticscholar.org/paper/90ccdae5898712d2cb59d52f6aad0aeb64066eb6\",\"venue\":\"2020 IEEE International Conference on Computational Photography (ICCP)\",\"year\":2020},{\"arxivId\":\"1907.05640\",\"authors\":[{\"authorId\":\"2014145\",\"name\":\"Mohammad Tavakolian\"},{\"authorId\":\"2884918\",\"name\":\"M. Sabokrou\"},{\"authorId\":\"144979251\",\"name\":\"A. Hadid\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1bd2c92ff77126f7352b32d3b00f998f15bfdf07\",\"title\":\"AVD: Adversarial Video Distillation\",\"url\":\"https://www.semanticscholar.org/paper/1bd2c92ff77126f7352b32d3b00f998f15bfdf07\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1801.07230\",\"authors\":[{\"authorId\":\"2308598\",\"name\":\"U. Ahsan\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"21472040\",\"name\":\"Irfan Essa\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"5f6d6c99fe5011d925d892725ff0c8cbbd7db3ba\",\"title\":\"DiscrimNet: Semi-Supervised Action Recognition from Videos using Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/5f6d6c99fe5011d925d892725ff0c8cbbd7db3ba\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1802.02138\",\"authors\":[{\"authorId\":\"32052175\",\"name\":\"Ramyad Hadidi\"},{\"authorId\":\"35821903\",\"name\":\"Jiashen Cao\"},{\"authorId\":\"153027140\",\"name\":\"Matthew Woodward\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"},{\"authorId\":\"8187053\",\"name\":\"Hyesoon Kim\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"960f04e099afeed7509d66bbdf24b3de0b29adff\",\"title\":\"Musical Chair: Efficient Real-Time Recognition Using Collaborative IoT Devices\",\"url\":\"https://www.semanticscholar.org/paper/960f04e099afeed7509d66bbdf24b3de0b29adff\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27718163\",\"name\":\"Y. Yang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"928e30d78432118af667cf085759b5406484307a\",\"title\":\"Learning Hierarchical Representations For Video Analysis Using Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/928e30d78432118af667cf085759b5406484307a\",\"venue\":\"\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2941187\",\"name\":\"S. M. Safdarnejad\"},{\"authorId\":\"1759169\",\"name\":\"X. Liu\"},{\"authorId\":\"1938832\",\"name\":\"L. Udpa\"},{\"authorId\":\"40467330\",\"name\":\"Brooks Andrus\"},{\"authorId\":\"145342981\",\"name\":\"J. Wood\"},{\"authorId\":\"46969887\",\"name\":\"Dean Craven\"}],\"doi\":\"10.1109/FG.2015.7163105\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"1a40092b493c6b8840257ab7f96051d1a4dbfeb2\",\"title\":\"Sports Videos in the Wild (SVW): A video dataset for sports analysis\",\"url\":\"https://www.semanticscholar.org/paper/1a40092b493c6b8840257ab7f96051d1a4dbfeb2\",\"venue\":\"2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40543505\",\"name\":\"Badrinarayanan Rangarajan\"},{\"authorId\":\"7757884\",\"name\":\"V. Radhakrishnan\"}],\"doi\":\"10.1109/ISSNIP.2014.6827622\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f356702cb8d87d40fcae9bd99643d655af817065\",\"title\":\"Human action recognition in compressed domain using PBL-McRBFN approach\",\"url\":\"https://www.semanticscholar.org/paper/f356702cb8d87d40fcae9bd99643d655af817065\",\"venue\":\"2014 IEEE Ninth International Conference on Intelligent Sensors, Sensor Networks and Information Processing (ISSNIP)\",\"year\":2014},{\"arxivId\":\"1712.09374\",\"authors\":[{\"authorId\":\"49453213\",\"name\":\"Hang Zhao\"},{\"authorId\":\"3305169\",\"name\":\"Zhicheng Yan\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bd9157331104a0708aa4f8ae79b7651a5be797c6\",\"title\":\"SLAC: A Sparsely Labeled Dataset for Action Classification and Localization\",\"url\":\"https://www.semanticscholar.org/paper/bd9157331104a0708aa4f8ae79b7651a5be797c6\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144388361\",\"name\":\"C. Li\"},{\"authorId\":\"1740430\",\"name\":\"B. Zhang\"},{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"1694936\",\"name\":\"Q. Ye\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"},{\"authorId\":\"1822413\",\"name\":\"Guodong Guo\"},{\"authorId\":\"145592288\",\"name\":\"Rongrong Ji\"}],\"doi\":\"10.1109/TIP.2019.2912357\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"cc68848151657035ffbd945d99106e8c52e15c20\",\"title\":\"Deep Manifold Structure Transfer for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cc68848151657035ffbd945d99106e8c52e15c20\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"1801.06349\",\"authors\":[{\"authorId\":\"1681157\",\"name\":\"M. Mancas\"},{\"authorId\":\"1976417\",\"name\":\"Christian Frisson\"},{\"authorId\":\"87114387\",\"name\":\"E. al.\"},{\"authorId\":\"88741566\",\"name\":\"No\\u00e9 Tits\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a7267bc781a4e3e79213bb9c4925dd551ea1f5c4\",\"title\":\"Proceedings of eNTERFACE 2015 Workshop on Intelligent Interfaces\",\"url\":\"https://www.semanticscholar.org/paper/a7267bc781a4e3e79213bb9c4925dd551ea1f5c4\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1953034\",\"name\":\"Manavender R. Malgireddy\"},{\"authorId\":\"1841118\",\"name\":\"Ifeoma Nwogu\"},{\"authorId\":\"1723877\",\"name\":\"V. Govindaraju\"}],\"doi\":\"10.1007/978-3-319-57021-1_5\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"dcad5684c5e269a91c669b242e8df21f1b7b303f\",\"title\":\"Language-motivated approaches to action recognition\",\"url\":\"https://www.semanticscholar.org/paper/dcad5684c5e269a91c669b242e8df21f1b7b303f\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3238416\",\"name\":\"Fransiska Basoeki\"},{\"authorId\":\"1871650\",\"name\":\"F. D. Libera\"},{\"authorId\":\"1687808\",\"name\":\"H. Ishiguro\"}],\"doi\":\"10.1080/01691864.2016.1216724\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2db46f75d5c9e7698e91c2fd2f9d9a7f3d6824f0\",\"title\":\"On the human perception of dissimilarities between postures of humanoids\",\"url\":\"https://www.semanticscholar.org/paper/2db46f75d5c9e7698e91c2fd2f9d9a7f3d6824f0\",\"venue\":\"Adv. Robotics\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98294026\",\"name\":\"S. Liu\"},{\"authorId\":\"145453305\",\"name\":\"Xin Ma\"},{\"authorId\":\"2610029\",\"name\":\"H. Wu\"},{\"authorId\":\"32083314\",\"name\":\"Yi-bin Li\"}],\"doi\":\"10.1109/ACCESS.2020.2979549\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"0b2a5d27304a17f1b613e8816613e3deb3992ab3\",\"title\":\"An End to End Framework With Adaptive Spatio-Temporal Attention Module for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/0b2a5d27304a17f1b613e8816613e3deb3992ab3\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2012.11673\",\"authors\":[{\"authorId\":\"1900466056\",\"name\":\"Sirjan Kafle\"},{\"authorId\":\"1633418058\",\"name\":\"Aman Gupta\"},{\"authorId\":\"1410725735\",\"name\":\"Xue Xia\"},{\"authorId\":\"145630384\",\"name\":\"A. Sankar\"},{\"authorId\":\"46772427\",\"name\":\"X. Chen\"},{\"authorId\":\"144006576\",\"name\":\"D. Wen\"},{\"authorId\":\"2121454\",\"name\":\"Libao Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"18d91abf683d10837f384c1b4c9a3f9f90cf3e87\",\"title\":\"Smoothed Gaussian Mixture Models for Video Classification and Recommendation\",\"url\":\"https://www.semanticscholar.org/paper/18d91abf683d10837f384c1b4c9a3f9f90cf3e87\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37370925\",\"name\":\"Nuha Zamzami\"},{\"authorId\":\"1729109\",\"name\":\"N. Bouguila\"}],\"doi\":\"10.1145/3406242\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c9887eb67cd6355aa47f605479c496750645ddfa\",\"title\":\"Probabilistic Modeling for Frequency Vectors Using a Flexible Shifted-Scaled Dirichlet Distribution Prior\",\"url\":\"https://www.semanticscholar.org/paper/c9887eb67cd6355aa47f605479c496750645ddfa\",\"venue\":\"ACM Trans. Knowl. Discov. Data\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2566189\",\"name\":\"Suguo Zhu\"},{\"authorId\":\"51188296\",\"name\":\"Zhenying Fang\"},{\"authorId\":\"40013369\",\"name\":\"Y. Wang\"},{\"authorId\":\"50812077\",\"name\":\"J. Yu\"},{\"authorId\":\"8491162\",\"name\":\"J. Du\"}],\"doi\":\"10.1016/J.JVCIR.2018.12.026\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"74d70d4dae2c9bac0197cb25fac27ed4d3f626c7\",\"title\":\"Multimodal activity recognition with local block CNN and attention-based spatial weighted CNN\",\"url\":\"https://www.semanticscholar.org/paper/74d70d4dae2c9bac0197cb25fac27ed4d3f626c7\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":\"2006.09675\",\"authors\":[{\"authorId\":\"46578437\",\"name\":\"K. Liu\"},{\"authorId\":\"1686917\",\"name\":\"Wu Liu\"},{\"authorId\":\"144258295\",\"name\":\"Huadong Ma\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"}],\"doi\":\"10.1109/tcsvt.2020.2984569\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"046f98d55c557d574ef84631cae8d65d709585ed\",\"title\":\"A Real-time Action Representation with Temporal Encoding and Deep Compression\",\"url\":\"https://www.semanticscholar.org/paper/046f98d55c557d574ef84631cae8d65d709585ed\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24289349\",\"name\":\"Didik Purwanto\"},{\"authorId\":\"150282005\",\"name\":\"Rizard Renanda Adhi Pramono\"},{\"authorId\":\"49069045\",\"name\":\"Y. Chen\"},{\"authorId\":\"9319953\",\"name\":\"W. Fang\"}],\"doi\":\"10.1109/LSP.2019.2923918\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"6d5ef23c727f979867ca1791d3ea7106a76f7066\",\"title\":\"Three-Stream Network With Bidirectional Self-Attention for Action Recognition in Extreme Low Resolution Videos\",\"url\":\"https://www.semanticscholar.org/paper/6d5ef23c727f979867ca1791d3ea7106a76f7066\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49112947\",\"name\":\"Shichao Zhao\"},{\"authorId\":\"40566345\",\"name\":\"Yanbin Liu\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"120313754\",\"name\":\"Richang Hong\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"515f45e2716626cfd1546a4026f5da1988bbe884\",\"title\":\"Pooling the Convolutional Layers in Deep ConvNets for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/515f45e2716626cfd1546a4026f5da1988bbe884\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48620041\",\"name\":\"Yun Yi\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"3047890\",\"name\":\"Bowen Zhang\"}],\"doi\":\"10.1007/s11042-017-4416-4\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0831794eddcbac1f601dcb9be9d45531a56dbf7e\",\"title\":\"Learning correlations for human action recognition in videos\",\"url\":\"https://www.semanticscholar.org/paper/0831794eddcbac1f601dcb9be9d45531a56dbf7e\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2017},{\"arxivId\":\"2008.02086\",\"authors\":[{\"authorId\":\"48093158\",\"name\":\"Jinpeng Wang\"},{\"authorId\":\"46396519\",\"name\":\"Yiqi Lin\"},{\"authorId\":\"145517136\",\"name\":\"A. Ma\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"6c9ae916c89a804742a382a5eb095030a0db9eb5\",\"title\":\"Self-supervised learning using consistency regularization of spatio-temporal data augmentation for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/6c9ae916c89a804742a382a5eb095030a0db9eb5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40222634\",\"name\":\"Kuldeep Kulkarni\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b5de4315118c224eb4cac2a45690ec083bac176e\",\"title\":\"Computer Vision from Spatial-Multiplexing Cameras at Low Measurement Rates\",\"url\":\"https://www.semanticscholar.org/paper/b5de4315118c224eb4cac2a45690ec083bac176e\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1711.08238\",\"authors\":[{\"authorId\":\"4464686\",\"name\":\"ZhenXing Zheng\"},{\"authorId\":\"2896701\",\"name\":\"Gaoyun An\"},{\"authorId\":\"144695333\",\"name\":\"Qiuqi Ruan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"225fb9181545f8750061c7693661b62d715dc542\",\"title\":\"Multi-Level Recurrent Residual Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/225fb9181545f8750061c7693661b62d715dc542\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153580352\",\"name\":\"Ionut Cosmin Duta\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"558fc9a2bce3d3993a9c1f41b6c7f290cefcf92f\",\"title\":\"Efficient and Effective Solutions for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/558fc9a2bce3d3993a9c1f41b6c7f290cefcf92f\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145580092\",\"name\":\"Pierre-Etienne Martin\"},{\"authorId\":null,\"name\":\"Jenny Benois-Pineau\"},{\"authorId\":\"2236496\",\"name\":\"Boris Mansencal\"},{\"authorId\":\"1639895183\",\"name\":\"Renaud P\\u00e9teri\"},{\"authorId\":\"1639983772\",\"name\":\"Julien Morlier\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d1961c9db224acbc08203677715ade9364d5023a\",\"title\":\"Siamese Spatio-Temporal Convolutional Neural Network for Stroke Classification in Table Tennis Games\",\"url\":\"https://www.semanticscholar.org/paper/d1961c9db224acbc08203677715ade9364d5023a\",\"venue\":\"MediaEval\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2283107\",\"name\":\"Debaditya Roy\"},{\"authorId\":\"144987703\",\"name\":\"M. Srinivas\"},{\"authorId\":\"34358756\",\"name\":\"C. K. Mohan\"}],\"doi\":\"10.1145/2708463.2709047\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d0e0354e1f69013bfa02761c5708e1790bf81db\",\"title\":\"Sparsifying Dense Features for Action Classification\",\"url\":\"https://www.semanticscholar.org/paper/9d0e0354e1f69013bfa02761c5708e1790bf81db\",\"venue\":\"PerMIn '15\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145143348\",\"name\":\"O. V. R. Murthy\"},{\"authorId\":\"1717204\",\"name\":\"R. Goecke\"}],\"doi\":\"10.1109/ICCVW.2013.61\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"060034b59275c13746413ca9c67d6304cba50da6\",\"title\":\"Ordered Trajectories for Large Scale Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/060034b59275c13746413ca9c67d6304cba50da6\",\"venue\":\"2013 IEEE International Conference on Computer Vision Workshops\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10779576\",\"name\":\"Sunder Ali Khowaja\"},{\"authorId\":\"1685677\",\"name\":\"Seok-Lyong Lee\"}],\"doi\":\"10.1007/s00521-019-04578-y\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"5295accd08f555354de16f2b860f2c09e6889b65\",\"title\":\"Hybrid and hierarchical fusion networks: a deep cross-modal learning architecture for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/5295accd08f555354de16f2b860f2c09e6889b65\",\"venue\":\"Neural Computing and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"20812150\",\"name\":\"Andreas M. Lehrmann\"}],\"doi\":\"10.3929/ethz-a-010780141\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1639e5775de7f38f4ce577962ea33c2daf2a1218\",\"title\":\"Non-parametric models for structured data and applications to human bodies and natural scenes\",\"url\":\"https://www.semanticscholar.org/paper/1639e5775de7f38f4ce577962ea33c2daf2a1218\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36054719\",\"name\":\"A. Campilho\"},{\"authorId\":\"122498433\",\"name\":\"F. Karray\"},{\"authorId\":\"1491092225\",\"name\":\"Zhou Wang\"},{\"authorId\":\"1743774\",\"name\":\"E. Bertino\"}],\"doi\":\"10.1007/978-3-030-50347-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6ef4cc8126a312c5e4be1190e28238dc46f50aec\",\"title\":\"Image Analysis and Recognition: 17th International Conference, ICIAR 2020, P\\u00f3voa de Varzim, Portugal, June 24\\u201326, 2020, Proceedings, Part I\",\"url\":\"https://www.semanticscholar.org/paper/6ef4cc8126a312c5e4be1190e28238dc46f50aec\",\"venue\":\"ICIAR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48749954\",\"name\":\"L. Cao\"},{\"authorId\":\"145353089\",\"name\":\"Y. Mu\"},{\"authorId\":\"1820908\",\"name\":\"A. Natsev\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\"},{\"authorId\":\"47088868\",\"name\":\"Joshua R. Smith\"}],\"doi\":\"10.1007/978-3-642-33709-3_49\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8d8de0f299ba20f2301900648bc2a6bd99df79bd\",\"title\":\"Scene Aligned Pooling for Complex Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8d8de0f299ba20f2301900648bc2a6bd99df79bd\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47837986\",\"name\":\"An Yan\"},{\"authorId\":null,\"name\":\"Yali Wang\"},{\"authorId\":\"9247990\",\"name\":\"Zhifeng Li\"},{\"authorId\":\"143970608\",\"name\":\"Y. Qiao\"}],\"doi\":\"10.1109/CVPR.2019.00811\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4ef4bdad7673050b3764e06a26085f9f8ef11e50\",\"title\":\"PA3D: Pose-Action 3D Machine for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4ef4bdad7673050b3764e06a26085f9f8ef11e50\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1411.7883\",\"authors\":[{\"authorId\":\"2059950\",\"name\":\"Luca Del Pero\"},{\"authorId\":\"2262946\",\"name\":\"S. Ricco\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"143865718\",\"name\":\"V. Ferrari\"}],\"doi\":\"10.1109/CVPR.2015.7298827\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"98ae45620ae1980abe685ec4ffa19d98524a8c52\",\"title\":\"Articulated motion discovery using pairs of trajectories\",\"url\":\"https://www.semanticscholar.org/paper/98ae45620ae1980abe685ec4ffa19d98524a8c52\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2496409\",\"name\":\"Z. Shu\"},{\"authorId\":\"33230676\",\"name\":\"Kiwon Yun\"},{\"authorId\":\"145654220\",\"name\":\"D. Samaras\"}],\"doi\":\"10.1007/978-3-319-16178-5_38\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d4dbb54439490d17ae99d394725aada1bbb877a\",\"title\":\"Action Detection with Improved Dense Trajectories and Sliding Window\",\"url\":\"https://www.semanticscholar.org/paper/9d4dbb54439490d17ae99d394725aada1bbb877a\",\"venue\":\"ECCV Workshops\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2941187\",\"name\":\"S. M. Safdarnejad\"},{\"authorId\":\"1759169\",\"name\":\"X. Liu\"},{\"authorId\":\"1938832\",\"name\":\"L. Udpa\"}],\"doi\":\"10.5244/C.29.21\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"0e4490f7616634e06a0b89eedbe37433d7f5392d\",\"title\":\"Robust Global Motion Compensation in Presence of Predominant Foreground\",\"url\":\"https://www.semanticscholar.org/paper/0e4490f7616634e06a0b89eedbe37433d7f5392d\",\"venue\":\"BMVC\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35395217\",\"name\":\"Thomhert S. Siadari\"},{\"authorId\":\"30632612\",\"name\":\"Mikyong Han\"},{\"authorId\":\"40153851\",\"name\":\"H. Yoon\"}],\"doi\":\"10.1109/ICCVW.2017.139\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6d69e5b03389da90fcc89b832a564f62ecbc54ff\",\"title\":\"4D Effect Video Classification with Shot-Aware Frame Selection and Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6d69e5b03389da90fcc89b832a564f62ecbc54ff\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145674667\",\"name\":\"J. Miao\"},{\"authorId\":\"9303726\",\"name\":\"Xiangmin Xu\"},{\"authorId\":\"4980778\",\"name\":\"Xiaoyi Jia\"},{\"authorId\":\"2926087\",\"name\":\"H. Huang\"},{\"authorId\":\"2436482\",\"name\":\"B. Cai\"},{\"authorId\":\"37178775\",\"name\":\"Chunmei Qing\"},{\"authorId\":\"2667341\",\"name\":\"Xiaofen Xing\"}],\"doi\":\"10.1007/978-3-319-48896-7_22\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"57e246612466f7116f3acdbdec83c0e57bb0844d\",\"title\":\"Exploiting Local Feature Fusion for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/57e246612466f7116f3acdbdec83c0e57bb0844d\",\"venue\":\"PCM\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145733600\",\"name\":\"Song Cao\"},{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/WACV.2016.7477584\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"9989eda2f5392cfe1f789bb0f6213a46d92d1302\",\"title\":\"Activity recognition and prediction with pose based discriminative patch model\",\"url\":\"https://www.semanticscholar.org/paper/9989eda2f5392cfe1f789bb0f6213a46d92d1302\",\"venue\":\"2016 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2253198\",\"name\":\"S. Mishra\"},{\"authorId\":\"2091875\",\"name\":\"T. K. Mishra\"},{\"authorId\":\"91464062\",\"name\":\"G. Sanyal\"},{\"authorId\":\"150031446\",\"name\":\"A. Sarkar\"},{\"authorId\":\"68993678\",\"name\":\"S. C. Satapathy\"}],\"doi\":\"10.1016/j.patrec.2020.04.031\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"314df7f1e314252c60fc8f9eb927a36e0abf7d6a\",\"title\":\"Real time human action recognition using triggered frame extraction and a typical CNN heuristic\",\"url\":\"https://www.semanticscholar.org/paper/314df7f1e314252c60fc8f9eb927a36e0abf7d6a\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2020},{\"arxivId\":\"1909.09602\",\"authors\":[{\"authorId\":\"1388016741\",\"name\":\"Chris Careaga\"},{\"authorId\":\"144156036\",\"name\":\"Brian Hutchinson\"},{\"authorId\":\"47312946\",\"name\":\"Nathan Hodas\"},{\"authorId\":\"21785345\",\"name\":\"L. Phillips\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"de3c3e7f2a9d6b48e01f02ec452458e9f37bb6bc\",\"title\":\"Metric-Based Few-Shot Learning for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/de3c3e7f2a9d6b48e01f02ec452458e9f37bb6bc\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1811.01640\",\"authors\":[{\"authorId\":\"8811132\",\"name\":\"Vinaychandran Pondenkandath\"},{\"authorId\":\"38890619\",\"name\":\"M. Alberti\"},{\"authorId\":\"51915899\",\"name\":\"Sammer Puran\"},{\"authorId\":\"1680326\",\"name\":\"R. Ingold\"},{\"authorId\":\"1743758\",\"name\":\"Marcus Liwicki\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"79fc892abaf44a84a758268efd4d1b9e6b64ecf5\",\"title\":\"Leveraging Random Label Memorization for Unsupervised Pre-Training\",\"url\":\"https://www.semanticscholar.org/paper/79fc892abaf44a84a758268efd4d1b9e6b64ecf5\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37038796\",\"name\":\"M. Bhatt\"},{\"authorId\":\"1845677\",\"name\":\"T. Patalia\"}],\"doi\":\"10.1109/CGVIS.2015.7449908\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"04ca4467ff559b6ecbbe45dc1ff5a7155dc8907b\",\"title\":\"Genetic programming evolved spatial descriptor for Indian monuments classification\",\"url\":\"https://www.semanticscholar.org/paper/04ca4467ff559b6ecbbe45dc1ff5a7155dc8907b\",\"venue\":\"2015 IEEE International Conference on Computer Graphics, Vision and Information Security (CGVIS)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1398367150\",\"name\":\"C. Orrite-Uru\\u00f1uela\"},{\"authorId\":\"117491978\",\"name\":\"Mario Rodr\\u00edguez\"},{\"authorId\":\"144426554\",\"name\":\"C. Medrano\"}],\"doi\":\"10.1109/ICPR.2016.7900042\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"8887987f2fc5777e6e5f014a043acccdaadb93dd\",\"title\":\"One-shot learning of temporal sequences using a distance dependent Chinese Restaurant Process\",\"url\":\"https://www.semanticscholar.org/paper/8887987f2fc5777e6e5f014a043acccdaadb93dd\",\"venue\":\"2016 23rd International Conference on Pattern Recognition (ICPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1799216\",\"name\":\"Jeong-Jik Seo\"},{\"authorId\":\"2017906\",\"name\":\"Wissam J. Baddar\"},{\"authorId\":\"2657410\",\"name\":\"D. H. Kim\"},{\"authorId\":\"7251290\",\"name\":\"Yong Man Ro\"}],\"doi\":\"10.1109/ICIP.2015.7350866\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"49ba264102468d0c6d2e4e9ddde006435b257cc2\",\"title\":\"Human action recognition using time-invariant key-trajectories describing spatio-temporal salient motion\",\"url\":\"https://www.semanticscholar.org/paper/49ba264102468d0c6d2e4e9ddde006435b257cc2\",\"venue\":\"2015 IEEE International Conference on Image Processing (ICIP)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49989940\",\"name\":\"A. Jamal\"},{\"authorId\":\"2064509\",\"name\":\"Dipti Deodhare\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"},{\"authorId\":\"145952735\",\"name\":\"K. Venkatesh\"}],\"doi\":\"10.1007/s11042-018-6179-y\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f86df492c45d5dbc28610c6de0fa5edcc06763de\",\"title\":\"Eclectic domain mixing for effective adaptation in action spaces\",\"url\":\"https://www.semanticscholar.org/paper/f86df492c45d5dbc28610c6de0fa5edcc06763de\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2319574\",\"name\":\"D. Potapov\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8eded9b910588d1d2936f527281a98ba3dac7ea4\",\"title\":\"Supervised Learning Approaches for Automatic Structuring of Videos. (M\\u00e9thodes d'apprentissage supervis\\u00e9 pour la structuration automatique de vid\\u00e9os)\",\"url\":\"https://www.semanticscholar.org/paper/8eded9b910588d1d2936f527281a98ba3dac7ea4\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50223012\",\"name\":\"N. Mohammed\"},{\"authorId\":\"2440200\",\"name\":\"Z. Bei-ji\"},{\"authorId\":\"72451763\",\"name\":\"Zhu Cheng-zhang\"},{\"authorId\":\"71428497\",\"name\":\"Zhao Rongchang\"}],\"doi\":\"10.3233/AIS-180476\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"524680578ca3b13367d6aee6856d2257e0e5de33\",\"title\":\"Crime prediction and mapping based on real time video analysis\",\"url\":\"https://www.semanticscholar.org/paper/524680578ca3b13367d6aee6856d2257e0e5de33\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"28014924\",\"name\":\"K. Wang\"},{\"authorId\":\"49306276\",\"name\":\"J. Mi\"},{\"authorId\":\"3431949\",\"name\":\"Chenhan Xu\"},{\"authorId\":\"31772419\",\"name\":\"Qingquan Zhu\"},{\"authorId\":\"1731449\",\"name\":\"L. Shu\"},{\"authorId\":\"145151586\",\"name\":\"Der-Jiunn Deng\"}],\"doi\":\"10.1145/2990473\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d9ff0621d82a216a236424a93fad0eb41c179076\",\"title\":\"Real-Time Load Reduction in Multimedia Big Data for Mobile Internet\",\"url\":\"https://www.semanticscholar.org/paper/d9ff0621d82a216a236424a93fad0eb41c179076\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2461523\",\"name\":\"X. Wang\"},{\"authorId\":\"145175070\",\"name\":\"C. Qi\"}],\"doi\":\"10.1016/j.jvcir.2016.10.015\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e094697064cf77bafd7ed318b774115b7d364e70\",\"title\":\"Saliency-based dense trajectories for action recognition using low-rank matrix decomposition\",\"url\":\"https://www.semanticscholar.org/paper/e094697064cf77bafd7ed318b774115b7d364e70\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2545377\",\"name\":\"Christian Mandery\"},{\"authorId\":\"2501728\",\"name\":\"\\u00d6mer Terlemez\"},{\"authorId\":\"144153518\",\"name\":\"Martin Do\"},{\"authorId\":\"1884591\",\"name\":\"N. Vahrenkamp\"},{\"authorId\":\"1722677\",\"name\":\"T. Asfour\"}],\"doi\":\"10.1109/TRO.2016.2572685\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7934797a9a832fa5bd47dd649d131f0fb29b2342\",\"title\":\"Unifying Representations and Large-Scale Whole-Body Motion Databases for Studying Human Motion\",\"url\":\"https://www.semanticscholar.org/paper/7934797a9a832fa5bd47dd649d131f0fb29b2342\",\"venue\":\"IEEE Transactions on Robotics\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145010348\",\"name\":\"L. Niu\"},{\"authorId\":\"50135099\",\"name\":\"W. Li\"},{\"authorId\":\"38188040\",\"name\":\"Dong Xu\"}],\"doi\":\"10.1007/s11263-015-0862-5\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"6e55a9f44324aeef565b56a4512070d709d9ce31\",\"title\":\"Exploiting Privileged Information from Web Data for Action and Event Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6e55a9f44324aeef565b56a4512070d709d9ce31\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48842639\",\"name\":\"Dotan Kaufman\"},{\"authorId\":\"36813724\",\"name\":\"Gil Levi\"},{\"authorId\":\"1756099\",\"name\":\"Tal Hassner\"},{\"authorId\":\"48519520\",\"name\":\"L. Wolf\"}],\"doi\":\"10.1109/ICCV.2017.20\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"62e6b749ed5825739aa906021c5e613803d5cbe2\",\"title\":\"Temporal Tessellation: A Unified Approach for Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/62e6b749ed5825739aa906021c5e613803d5cbe2\",\"venue\":\"ICCV\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1778986\",\"name\":\"Wanru Xu\"},{\"authorId\":\"145183674\",\"name\":\"Z. Miao\"},{\"authorId\":\"145987219\",\"name\":\"Y. Tian\"}],\"doi\":\"10.1016/j.neucom.2016.08.057\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b04aa6b89670dc078915adf16c524a1187353453\",\"title\":\"A novel mid-level distinctive feature learning for action recognition via diffusion map\",\"url\":\"https://www.semanticscholar.org/paper/b04aa6b89670dc078915adf16c524a1187353453\",\"venue\":\"Neurocomputing\",\"year\":2016},{\"arxivId\":\"1512.01848\",\"authors\":[{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"2111981\",\"name\":\"Jos\\u00e9 Oramas\"},{\"authorId\":\"3060081\",\"name\":\"A. Ghodrati\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"}],\"doi\":\"10.1109/TPAMI.2016.2558148\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fd4defba71c686946351f5e7a090c7aa8136d32f\",\"title\":\"Rank Pooling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fd4defba71c686946351f5e7a090c7aa8136d32f\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40241836\",\"name\":\"L. Liu\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"},{\"authorId\":\"144767226\",\"name\":\"P. Rockett\"}],\"doi\":\"10.1016/j.sigpro.2012.07.017\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"602fc7931cf7aea3c8105505fc7450189b262780\",\"title\":\"Human action recognition based on boosted feature selection and naive Bayes nearest-neighbor classification\",\"url\":\"https://www.semanticscholar.org/paper/602fc7931cf7aea3c8105505fc7450189b262780\",\"venue\":\"Signal Process.\",\"year\":2013},{\"arxivId\":\"1604.07279\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2016.296\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1e667851f67aaa4d3f75d662760a783f45ea4b05\",\"title\":\"Actionness Estimation Using Hybrid Fully Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/1e667851f67aaa4d3f75d662760a783f45ea4b05\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144317565\",\"name\":\"Li Qian\"},{\"authorId\":\"2323048\",\"name\":\"Song Wu\"},{\"authorId\":\"39562998\",\"name\":\"Nan Pu\"},{\"authorId\":\"8182168\",\"name\":\"Shulin Xu\"},{\"authorId\":\"50511561\",\"name\":\"Guoqiang Xiao\"}],\"doi\":\"10.1117/12.2303514\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cfb64084b03d4f8d49584ca48110b79d624876e7\",\"title\":\"Multi-task learning with group information for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/cfb64084b03d4f8d49584ca48110b79d624876e7\",\"venue\":\"International Conference on Graphic and Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48805860\",\"name\":\"Zhimeng Zhang\"},{\"authorId\":\"145453305\",\"name\":\"Xin Ma\"},{\"authorId\":\"145401371\",\"name\":\"R. Song\"},{\"authorId\":\"2924438\",\"name\":\"Xuewen Rong\"},{\"authorId\":\"32004054\",\"name\":\"X. Tian\"},{\"authorId\":\"49209779\",\"name\":\"G. Tian\"},{\"authorId\":\"29275442\",\"name\":\"Yibin Li\"}],\"doi\":\"10.1109/CAC.2017.8243438\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2063222c5ce0dd233fa3056ddc245fca26bd5cf2\",\"title\":\"Deep learning based human action recognition: A survey\",\"url\":\"https://www.semanticscholar.org/paper/2063222c5ce0dd233fa3056ddc245fca26bd5cf2\",\"venue\":\"2017 Chinese Automation Congress (CAC)\",\"year\":2017},{\"arxivId\":\"1510.06939\",\"authors\":[{\"authorId\":\"143798882\",\"name\":\"Mihir Jain\"},{\"authorId\":\"1738975\",\"name\":\"J. C. V. Gemert\"},{\"authorId\":\"1722052\",\"name\":\"Thomas Mensink\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1109/ICCV.2015.521\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"23eed412efdfdd5d798892a8d6ec5f9273a3952d\",\"title\":\"Objects2action: Classifying and Localizing Actions without Any Video Example\",\"url\":\"https://www.semanticscholar.org/paper/23eed412efdfdd5d798892a8d6ec5f9273a3952d\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145479904\",\"name\":\"Tiantian Xu\"},{\"authorId\":\"3314902\",\"name\":\"E. K. Wong\"}],\"doi\":\"10.5244/C.31.160\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c6406d59456c4b468df3d9fa88e93d852c409b8d\",\"title\":\"Learning temporal structures for human activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/c6406d59456c4b468df3d9fa88e93d852c409b8d\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":\"1704.00616\",\"authors\":[{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"144590074\",\"name\":\"Gabriel L. Oliveira\"},{\"authorId\":\"31656404\",\"name\":\"N. Sedaghat\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1109/ICCV.2017.316\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"eac1b644492c10546a50f3e125a1f790ec46365f\",\"title\":\"Chained Multi-stream Networks Exploiting Pose, Motion, and Appearance for Action Classification and Detection\",\"url\":\"https://www.semanticscholar.org/paper/eac1b644492c10546a50f3e125a1f790ec46365f\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2961531\",\"name\":\"M. Hosseini\"},{\"authorId\":\"145226394\",\"name\":\"F. Ghaderi\"}],\"doi\":\"10.5829/ije.2020.33.05b.29\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2ec274b911cf19d45b7cb2e92bcc7e42bd70a156\",\"title\":\"A Hybrid Deep Learning Architecture Using 3D CNNs and GRUs for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2ec274b911cf19d45b7cb2e92bcc7e42bd70a156\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2009.14639\",\"authors\":[{\"authorId\":\"1976000468\",\"name\":\"Okan Kopuklu\"},{\"authorId\":\"114991183\",\"name\":\"Stefan Hormann\"},{\"authorId\":\"32240536\",\"name\":\"Fabian Herzog\"},{\"authorId\":\"2277308\",\"name\":\"Hakan Cevikalp\"},{\"authorId\":\"46343645\",\"name\":\"G. Rigoll\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d197d0ab852c20122ffb1833fb29199ca77ce9bb\",\"title\":\"Dissected 3D CNNs: Temporal Skip Connections for Efficient Online Video Processing\",\"url\":\"https://www.semanticscholar.org/paper/d197d0ab852c20122ffb1833fb29199ca77ce9bb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"14547418\",\"name\":\"Shengwei Zhou\"},{\"authorId\":\"153555891\",\"name\":\"L. Bai\"},{\"authorId\":\"1500530481\",\"name\":\"Haoran Wang\"},{\"authorId\":\"123580511\",\"name\":\"Zhi-Hong Deng\"},{\"authorId\":\"121330693\",\"name\":\"X. Zhu\"},{\"authorId\":\"143724074\",\"name\":\"C. Gong\"}],\"doi\":\"10.12783/dtcse/cisnrc2019/33302\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f1b8e2c68d93617489b838c223d402fa4f425f8e\",\"title\":\"A Spatial-temporal Attention Module for 3D Convolution Network in Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f1b8e2c68d93617489b838c223d402fa4f425f8e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1808.00845\",\"authors\":[{\"authorId\":\"51025358\",\"name\":\"Jiaxin Cai\"},{\"authorId\":\"145653045\",\"name\":\"X. Tang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7857ac165329843f0c215daf935b042f79012ebe\",\"title\":\"RGB Video Based Tennis Action Recognition Using a Deep Historical Long Short-Term Memory.\",\"url\":\"https://www.semanticscholar.org/paper/7857ac165329843f0c215daf935b042f79012ebe\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34678431\",\"name\":\"F. Sener\"},{\"authorId\":\"40313071\",\"name\":\"Nermin Samet\"},{\"authorId\":\"2446509\",\"name\":\"P. D. Sahin\"},{\"authorId\":\"1398643531\",\"name\":\"N. Ikizler-Cinbis\"}],\"doi\":\"10.1109/SIU.2013.6531431\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"331a5f89b9e6f135ee367d341e0338cdc88ac255\",\"title\":\"Recognizing human actions from noisy videos via multiple instance learning\",\"url\":\"https://www.semanticscholar.org/paper/331a5f89b9e6f135ee367d341e0338cdc88ac255\",\"venue\":\"2013 21st Signal Processing and Communications Applications Conference (SIU)\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48571637\",\"name\":\"L. Zhang\"},{\"authorId\":\"34798935\",\"name\":\"Xiantong Zhen\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"}],\"doi\":\"10.1109/TIP.2018.2866688\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"69a41c98f6b71764913145dbc2bb4643c9bc4b0a\",\"title\":\"Learning Match Kernels on Grassmann Manifolds for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/69a41c98f6b71764913145dbc2bb4643c9bc4b0a\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2587442\",\"name\":\"Fredro Harjanto\"},{\"authorId\":\"50857536\",\"name\":\"Z. Wang\"},{\"authorId\":\"39756580\",\"name\":\"S. Lu\"},{\"authorId\":\"1733691\",\"name\":\"A. Tsoi\"},{\"authorId\":\"145855523\",\"name\":\"D. Feng\"}],\"doi\":\"10.1016/j.sigpro.2015.08.006\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bb5d6ca2562a05ceddc1fd315063f4ef68069ced\",\"title\":\"Investigating the impact of frame rate towards robust human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/bb5d6ca2562a05ceddc1fd315063f4ef68069ced\",\"venue\":\"Signal Process.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2501453\",\"name\":\"Min-Kook Choi\"},{\"authorId\":\"50218736\",\"name\":\"Ziyu Wang\"},{\"authorId\":\"3135462\",\"name\":\"H. Lee\"},{\"authorId\":\"1838575\",\"name\":\"Sang-Chul Lee\"}],\"doi\":\"10.1007/s11042-015-2876-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c38e9dce9d5bf9084b2488d6025b78edacd69122\",\"title\":\"A bag-of-regions representation for video classification\",\"url\":\"https://www.semanticscholar.org/paper/c38e9dce9d5bf9084b2488d6025b78edacd69122\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2235260\",\"name\":\"Q. Chen\"},{\"authorId\":\"34853917\",\"name\":\"Y. Zhang\"}],\"doi\":\"10.1016/j.neucom.2015.03.124\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"339075a5cf3c957db1f18f81a35e45f14df56ae9\",\"title\":\"Cluster trees of improved trajectories for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/339075a5cf3c957db1f18f81a35e45f14df56ae9\",\"venue\":\"Neurocomputing\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151492109\",\"name\":\"Wensong Chan\"},{\"authorId\":\"71506962\",\"name\":\"Zhiqiang Tian\"},{\"authorId\":\"51381728\",\"name\":\"S. Liu\"},{\"authorId\":\"145160620\",\"name\":\"J. Ren\"},{\"authorId\":\"2498428\",\"name\":\"X. Lan\"}],\"doi\":\"10.1007/978-3-030-27535-8_41\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d08e6292cf641d5865e2c4fa15624267e225cc9b\",\"title\":\"Select and Focus: Action Recognition with Spatial-Temporal Attention\",\"url\":\"https://www.semanticscholar.org/paper/d08e6292cf641d5865e2c4fa15624267e225cc9b\",\"venue\":\"ICIRA\",\"year\":2019},{\"arxivId\":\"1809.03669\",\"authors\":[{\"authorId\":\"3865974\",\"name\":\"Xiaolin Song\"},{\"authorId\":\"40093162\",\"name\":\"Cuiling Lan\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"},{\"authorId\":\"1757173\",\"name\":\"Junliang Xing\"},{\"authorId\":\"6485172\",\"name\":\"Xiaoyan Sun\"},{\"authorId\":\"40354745\",\"name\":\"J. Yang\"}],\"doi\":\"10.1109/TCSVT.2019.2896029\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"96f0da034d090a3ecadd0fb92333bb681f23ab14\",\"title\":\"Temporal\\u2013Spatial Mapping for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/96f0da034d090a3ecadd0fb92333bb681f23ab14\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"1904.11451\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"145878079\",\"name\":\"Vivek Sharma\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"1576263143\",\"name\":\"Jurgen Gall\"},{\"authorId\":\"49157259\",\"name\":\"R. Stiefelhagen\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-030-58558-7_35\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c2fe9e87e31e6fdb2b7bae5f9cc3c2d2612d13a\",\"title\":\"Large Scale Holistic Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/1c2fe9e87e31e6fdb2b7bae5f9cc3c2d2612d13a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1905.08711\",\"authors\":[{\"authorId\":\"48085995\",\"name\":\"A. Kozlov\"},{\"authorId\":\"117171023\",\"name\":\"V. Andronov\"},{\"authorId\":\"122388064\",\"name\":\"Y. Gritsenko\"}],\"doi\":\"10.1145/3341105.3373906\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d4262413c55cf0319922c42b796c74879a0632a8\",\"title\":\"Lightweight network architecture for real-time action recognition\",\"url\":\"https://www.semanticscholar.org/paper/d4262413c55cf0319922c42b796c74879a0632a8\",\"venue\":\"SAC\",\"year\":2020},{\"arxivId\":\"2010.03497\",\"authors\":[{\"authorId\":\"6917558\",\"name\":\"Daniel Deniz\"},{\"authorId\":\"144484799\",\"name\":\"F. Barranco\"},{\"authorId\":\"103939214\",\"name\":\"J. Isern\"},{\"authorId\":\"32132184\",\"name\":\"E. Ros\"}],\"doi\":\"10.1109/ETFA46521.2020.9211910\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"92594b024a19bc5cb3e38984c864e1653179db8f\",\"title\":\"Reconfigurable Cyber-Physical System for Lifestyle Video-Monitoring via Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/92594b024a19bc5cb3e38984c864e1653179db8f\",\"venue\":\"2020 25th IEEE International Conference on Emerging Technologies and Factory Automation (ETFA)\",\"year\":2020},{\"arxivId\":\"2008.12432\",\"authors\":[{\"authorId\":\"3349165\",\"name\":\"Pallabi Ghosh\"},{\"authorId\":\"19173161\",\"name\":\"Nirat Saini\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"},{\"authorId\":\"51453757\",\"name\":\"Abhinav Shrivastava\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"117595877c1fca610f94c8d07009105092939ecc\",\"title\":\"All About Knowledge Graphs for Actions\",\"url\":\"https://www.semanticscholar.org/paper/117595877c1fca610f94c8d07009105092939ecc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.15560\",\"authors\":[{\"authorId\":\"1391155455\",\"name\":\"Yin-Dong Zheng\"},{\"authorId\":\"46270766\",\"name\":\"Zhaoyang Liu\"},{\"authorId\":\"144720251\",\"name\":\"Tong Lu\"},{\"authorId\":\"29461006\",\"name\":\"L. Wang\"}],\"doi\":\"10.1109/TIP.2020.3007826\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3ee328e73acc9be44d874756dab4c13c65a835c0\",\"title\":\"Dynamic Sampling Networks for Efficient Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/3ee328e73acc9be44d874756dab4c13c65a835c0\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144740100\",\"name\":\"M. Kong\"},{\"authorId\":\"47474586\",\"name\":\"Pin Lv\"}],\"doi\":\"10.1007/978-3-030-32456-8_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ac887b31488b78f9e6e1a98f3a1859454828a3ba\",\"title\":\"Global Features of Fused Frame Relationships Help Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/ac887b31488b78f9e6e1a98f3a1859454828a3ba\",\"venue\":\"ICNC-FSKD\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39956342\",\"name\":\"Wenbin Li\"}],\"doi\":\"10.22028/D291-27156\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"993023a4859f9889f30fa2625790ccfa4dd4b1b3\",\"title\":\"From perception over anticipation to manipulation\",\"url\":\"https://www.semanticscholar.org/paper/993023a4859f9889f30fa2625790ccfa4dd4b1b3\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145071344\",\"name\":\"Yang Mi\"},{\"authorId\":\"50695792\",\"name\":\"S. Wang\"}],\"doi\":\"10.1109/ICME.2019.00182\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fdfcaf729fea332fc0a259143c406cee51303854\",\"title\":\"Recognizing Micro Actions in Videos: Learning Motion Details via Segment-Level Temporal Pyramid\",\"url\":\"https://www.semanticscholar.org/paper/fdfcaf729fea332fc0a259143c406cee51303854\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":\"1512.03958\",\"authors\":[{\"authorId\":\"3004979\",\"name\":\"G. Lev\"},{\"authorId\":\"2251827\",\"name\":\"Gil Sadeh\"},{\"authorId\":\"145969200\",\"name\":\"B. Klein\"},{\"authorId\":\"145128145\",\"name\":\"Lior Wolf\"}],\"doi\":\"10.1007/978-3-319-46466-4_50\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"04b8a1d2498a7c8bd90a5465a02b2e8e178177c5\",\"title\":\"RNN Fisher Vectors for Action Recognition and Image Annotation\",\"url\":\"https://www.semanticscholar.org/paper/04b8a1d2498a7c8bd90a5465a02b2e8e178177c5\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40072752\",\"name\":\"Wenjun Wu\"},{\"authorId\":\"7607552\",\"name\":\"Y. Yang\"},{\"authorId\":\"2059283\",\"name\":\"Ruishan Liu\"},{\"authorId\":\"145102437\",\"name\":\"Cheng Deng\"}],\"doi\":\"10.1145/2808492.2808535\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"01f3d1379049d2b1c5142dcc7ae2a7c8b79daa29\",\"title\":\"Joint-based multi-task sparse learning for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/01f3d1379049d2b1c5142dcc7ae2a7c8b79daa29\",\"venue\":\"ICIMCS '15\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1930831020\",\"name\":\"Lorxayxang Kai\"},{\"authorId\":\"50741340\",\"name\":\"Yang Wu\"},{\"authorId\":\"3017565\",\"name\":\"Xiaodong Dai\"},{\"authorId\":\"81498564\",\"name\":\"M. Ma\"}],\"doi\":\"10.1007/978-3-030-57884-8_71\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7d0b571dcf3897a722309a2dd2974a5475cc70a9\",\"title\":\"Fast Video Classification with CNNs in Compressed Domain\",\"url\":\"https://www.semanticscholar.org/paper/7d0b571dcf3897a722309a2dd2974a5475cc70a9\",\"venue\":\"ICAIS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144985898\",\"name\":\"B. Su\"},{\"authorId\":\"145507765\",\"name\":\"X. Ding\"},{\"authorId\":\"1739067\",\"name\":\"C. Liu\"},{\"authorId\":\"145300185\",\"name\":\"H. Wang\"},{\"authorId\":\"47095827\",\"name\":\"Y. Wu\"}],\"doi\":\"10.1109/TIP.2017.2704438\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"49c512fbaf97bff90994248d93ba5b8cab30359e\",\"title\":\"Discriminative Transformation for Multi-Dimensional Temporal Sequences\",\"url\":\"https://www.semanticscholar.org/paper/49c512fbaf97bff90994248d93ba5b8cab30359e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"1872964\",\"name\":\"Ali K. Thabet\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1007/978-3-319-16817-3_38\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b5b127ff7763ec87bc26c5c18233535db52d650a\",\"title\":\"Camera Motion and Surrounding Scene Appearance as Context for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b5b127ff7763ec87bc26c5c18233535db52d650a\",\"venue\":\"ACCV\",\"year\":2014},{\"arxivId\":\"2004.13918\",\"authors\":[{\"authorId\":\"150140898\",\"name\":\"Junho Choi\"},{\"authorId\":\"1688671\",\"name\":\"J. Lee\"}],\"doi\":\"10.1145/3341162.3344871\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8f9dc46c32f55ab0c0db5d9d3a29152d03bf58f7\",\"title\":\"EmbraceNet for activity: a deep multimodal fusion architecture for activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/8f9dc46c32f55ab0c0db5d9d3a29152d03bf58f7\",\"venue\":\"UbiComp/ISWC Adjunct\",\"year\":2019},{\"arxivId\":\"1712.00636\",\"authors\":[{\"authorId\":\"2978413\",\"name\":\"Chao-Yuan Wu\"},{\"authorId\":\"1771307\",\"name\":\"M. Zaheer\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"1758550\",\"name\":\"R. Manmatha\"},{\"authorId\":\"46234526\",\"name\":\"Alex Smola\"},{\"authorId\":\"2562966\",\"name\":\"Philipp Kr\\u00e4henb\\u00fchl\"}],\"doi\":\"10.1109/CVPR.2018.00631\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9d98a956aadaff727e495b14b7c532d40ea49e16\",\"title\":\"Compressed Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9d98a956aadaff727e495b14b7c532d40ea49e16\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11964267\",\"name\":\"Tingwei Wang\"},{\"authorId\":\"1703445\",\"name\":\"Chuancai Liu\"},{\"authorId\":\"2452789\",\"name\":\"L. Wang\"}],\"doi\":\"10.1016/j.neucom.2017.07.057\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"33fdaa747900d8952c0d371e8903c6531e357f93\",\"title\":\"Action recognition by Latent Duration Model\",\"url\":\"https://www.semanticscholar.org/paper/33fdaa747900d8952c0d371e8903c6531e357f93\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"81188084\",\"name\":\"Saima Nazir\"},{\"authorId\":\"50059673\",\"name\":\"Yu Qian\"},{\"authorId\":\"1697680\",\"name\":\"M. Yousaf\"},{\"authorId\":\"9201993\",\"name\":\"S. A. Velastin\"},{\"authorId\":\"145643264\",\"name\":\"E. Izquierdo\"},{\"authorId\":\"30902466\",\"name\":\"Eduard Vazquez\"}],\"doi\":\"10.5220/0007371104200426\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f7984cc627276d934e8f9ff43ff95ffa3614016c\",\"title\":\"Human Action Recognition using Multi-Kernel Learning for Temporal Residual Network\",\"url\":\"https://www.semanticscholar.org/paper/f7984cc627276d934e8f9ff43ff95ffa3614016c\",\"venue\":\"VISIGRAPP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143829432\",\"name\":\"Ngoc Nguyen\"},{\"authorId\":\"2289674\",\"name\":\"Mera Kartika Delimayanti\"},{\"authorId\":\"34805720\",\"name\":\"Bedy Purnama\"},{\"authorId\":\"89895131\",\"name\":\"Kunti Robiatul Mahmudah\"},{\"authorId\":\"2242591\",\"name\":\"M. Kubo\"},{\"authorId\":\"47753514\",\"name\":\"M. Kakikawa\"},{\"authorId\":\"143663888\",\"name\":\"Y. Yamada\"},{\"authorId\":\"1767800\",\"name\":\"K. Satou\"}],\"doi\":\"10.5220/0007567602700275\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"cc240c52b8f2b53750c1dfb69b0c6cd287ae5ce9\",\"title\":\"Applying Deep Learning Models to Action Recognition of Swimming Mice with the Scarcity of Training Data\",\"url\":\"https://www.semanticscholar.org/paper/cc240c52b8f2b53750c1dfb69b0c6cd287ae5ce9\",\"venue\":\"BIOINFORMATICS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1780024\",\"name\":\"R. Polikar\"}],\"doi\":\"10.1007/978-3-030-12939-2\",\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"b05362caf719e2161f04b035c54b3172d6749cdb\",\"title\":\"Pattern Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b05362caf719e2161f04b035c54b3172d6749cdb\",\"venue\":\"Lecture Notes in Computer Science\",\"year\":2018},{\"arxivId\":\"1511.06040\",\"authors\":[{\"authorId\":\"31515231\",\"name\":\"M. S. Ibrahim\"},{\"authorId\":\"2716937\",\"name\":\"S. Muralidharan\"},{\"authorId\":\"49152600\",\"name\":\"Zhiwei Deng\"},{\"authorId\":\"3214848\",\"name\":\"Arash Vahdat\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"}],\"doi\":\"10.1109/CVPR.2016.217\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7ee9ba11982ec072d4ced752970cb8910e469f28\",\"title\":\"A Hierarchical Deep Temporal Model for Group Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7ee9ba11982ec072d4ced752970cb8910e469f28\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"2012.13726\",\"authors\":[{\"authorId\":\"34539976\",\"name\":\"S. Santos\"},{\"authorId\":\"23962586\",\"name\":\"J. Almeida\"}],\"doi\":\"10.1109/SIBGRAPI51738.2020.00017\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cda76b5d34007c23d67aa2b379ca45bc9c1d8981\",\"title\":\"Faster and Accurate Compressed Video Action Recognition Straight from the Frequency Domain\",\"url\":\"https://www.semanticscholar.org/paper/cda76b5d34007c23d67aa2b379ca45bc9c1d8981\",\"venue\":\"2020 33rd SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)\",\"year\":2020},{\"arxivId\":\"2008.09880\",\"authors\":[{\"authorId\":\"51263546\",\"name\":\"Ujjal Kr Dutta\"},{\"authorId\":\"1686714\",\"name\":\"M. Harandi\"},{\"authorId\":\"1685874\",\"name\":\"C. Sekhar\"}],\"doi\":\"10.1109/TAI.2020.3026982\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"c66a7609909ae6394e6ecd6b926a58e5a2a48e52\",\"title\":\"Unsupervised Deep Metric Learning via Orthogonality Based Probabilistic Loss\",\"url\":\"https://www.semanticscholar.org/paper/c66a7609909ae6394e6ecd6b926a58e5a2a48e52\",\"venue\":\"IEEE Transactions on Artificial Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1423743315\",\"name\":\"Theodoros Georgiou\"},{\"authorId\":\"3546791\",\"name\":\"Y. Liu\"},{\"authorId\":\"47482437\",\"name\":\"W. Chen\"},{\"authorId\":\"1731570\",\"name\":\"M. Lew\"}],\"doi\":\"10.1007/s13735-019-00183-w\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"763495e4ce53c989bf7c2910ae8cb51e4469e195\",\"title\":\"A survey of traditional and deep learning-based feature descriptors for high dimensional data in computer vision\",\"url\":\"https://www.semanticscholar.org/paper/763495e4ce53c989bf7c2910ae8cb51e4469e195\",\"venue\":\"International Journal of Multimedia Information Retrieval\",\"year\":2019},{\"arxivId\":\"2009.10370\",\"authors\":[{\"authorId\":\"2581371\",\"name\":\"B. Seddik\"},{\"authorId\":\"2536574\",\"name\":\"N. B. Amara\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"248d264cc75fc589a2c3dc0f1a5153a57a0b4fe1\",\"title\":\"Visual Methods for Sign Language Recognition: A Modality-Based Review\",\"url\":\"https://www.semanticscholar.org/paper/248d264cc75fc589a2c3dc0f1a5153a57a0b4fe1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1801.03150\",\"authors\":[{\"authorId\":\"95743023\",\"name\":\"Mathew Monfort\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"3298267\",\"name\":\"Sarah Adel Bargal\"},{\"authorId\":\"50112310\",\"name\":\"Alex Andonian\"},{\"authorId\":\"12082007\",\"name\":\"Tom Yan\"},{\"authorId\":\"40544169\",\"name\":\"K. Ramakrishnan\"},{\"authorId\":\"49860655\",\"name\":\"L. Brown\"},{\"authorId\":\"33421444\",\"name\":\"Quanfu Fan\"},{\"authorId\":\"1891570\",\"name\":\"Dan Gutfreund\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"}],\"doi\":\"10.1109/TPAMI.2019.2901464\",\"intent\":[\"result\"],\"isInfluential\":true,\"paperId\":\"07174c2f209f15cacf9ad3422b48652df286be69\",\"title\":\"Moments in Time Dataset: One Million Videos for Event Understanding\",\"url\":\"https://www.semanticscholar.org/paper/07174c2f209f15cacf9ad3422b48652df286be69\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33998511\",\"name\":\"Aaron Chadha\"},{\"authorId\":\"2511001\",\"name\":\"Yin Bi\"},{\"authorId\":\"2822935\",\"name\":\"Alhabib Abbas\"},{\"authorId\":\"2747620\",\"name\":\"Y. Andreopoulos\"}],\"doi\":\"10.1109/ICASSP.2019.8683606\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"750c885ee644cb19d89f52ab31639f56254273a2\",\"title\":\"Neuromorphic Vision Sensing for CNN-based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/750c885ee644cb19d89f52ab31639f56254273a2\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46329495\",\"name\":\"Amin Ullah\"},{\"authorId\":\"147236005\",\"name\":\"Khan Muhammad\"},{\"authorId\":\"116759974\",\"name\":\"T. Hussain\"},{\"authorId\":\"1777998\",\"name\":\"S. Baik\"},{\"authorId\":\"51905607\",\"name\":\"V. H. C. de Albuquerque\"}],\"doi\":\"10.1109/ACCESS.2020.3029834\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"fe503489c378e1dc2d7d1cc743b75585baa814e0\",\"title\":\"Event-Oriented 3D Convolutional Features Selection and Hash Codes Generation Using PCA for Video Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/fe503489c378e1dc2d7d1cc743b75585baa814e0\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32346302\",\"name\":\"F. Wang\"},{\"authorId\":\"1423415979\",\"name\":\"Guorui Wang\"},{\"authorId\":\"100975725\",\"name\":\"Yunwen Huang\"},{\"authorId\":\"49276987\",\"name\":\"Hao Chu\"}],\"doi\":\"10.1109/ACCESS.2019.2953113\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"65d934938c27585e144660ae7c293d297dddf64b\",\"title\":\"SAST: Learning Semantic Action-Aware Spatial-Temporal Features for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/65d934938c27585e144660ae7c293d297dddf64b\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50089367\",\"name\":\"P. Abreu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6d5809d13e9de52ff113575533a029297f737468\",\"title\":\"Augmentation of Two-stream CNN architectures with context and attention for action detection and recognition\",\"url\":\"https://www.semanticscholar.org/paper/6d5809d13e9de52ff113575533a029297f737468\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1911.08206\",\"authors\":[{\"authorId\":\"1382652819\",\"name\":\"Barak Battash\"},{\"authorId\":\"1420126809\",\"name\":\"Haim Barad\"},{\"authorId\":\"39278465\",\"name\":\"Hanlin Tang\"},{\"authorId\":\"3243137\",\"name\":\"Amit Bleiweiss\"}],\"doi\":\"10.1109/CVPRW50498.2020.00350\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"da2934c24a9de690ff399736711b754cc10ae1ec\",\"title\":\"Mimic The Raw Domain: Accelerating Action Recognition in the Compressed Domain\",\"url\":\"https://www.semanticscholar.org/paper/da2934c24a9de690ff399736711b754cc10ae1ec\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48749954\",\"name\":\"L. Cao\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"},{\"authorId\":\"40589056\",\"name\":\"Noel C. F. Codella\"},{\"authorId\":\"2244926\",\"name\":\"Courtenay V. Cotton\"},{\"authorId\":\"37432039\",\"name\":\"D. Ellis\"},{\"authorId\":\"143812191\",\"name\":\"L. Gong\"},{\"authorId\":\"2193254\",\"name\":\"Matthew L. Hill\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\"},{\"authorId\":\"6134973\",\"name\":\"John Kender\"},{\"authorId\":\"2435677\",\"name\":\"Michele Merler\"},{\"authorId\":\"145353089\",\"name\":\"Y. Mu\"},{\"authorId\":\"1820908\",\"name\":\"A. Natsev\"},{\"authorId\":\"47088868\",\"name\":\"Joshua R. Smith\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8340bf61fe6d3160a05d1fa069f063e75e69e23b\",\"title\":\"IBM Research and Columbia University TRECVID-2011 Multimedia Event Detection (MED) System\",\"url\":\"https://www.semanticscholar.org/paper/8340bf61fe6d3160a05d1fa069f063e75e69e23b\",\"venue\":\"TRECVID\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34853867\",\"name\":\"Lelin Zhang\"},{\"authorId\":\"50857536\",\"name\":\"Z. Wang\"},{\"authorId\":\"145188375\",\"name\":\"Tingting Yao\"},{\"authorId\":\"32891034\",\"name\":\"Shin'ichi Staoh\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"145855523\",\"name\":\"D. Feng\"}],\"doi\":\"10.1007/s11042-017-4353-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1221e25763c3be95c1b6626ca9e7feaa3b636d9a\",\"title\":\"Exploiting spatial-temporal context for trajectory based action video retrieval\",\"url\":\"https://www.semanticscholar.org/paper/1221e25763c3be95c1b6626ca9e7feaa3b636d9a\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145987219\",\"name\":\"Y. Tian\"},{\"authorId\":\"145873652\",\"name\":\"Y. Kong\"},{\"authorId\":\"144695333\",\"name\":\"Q. Ruan\"},{\"authorId\":\"2896701\",\"name\":\"G. An\"},{\"authorId\":\"46956675\",\"name\":\"Yun Fu\"}],\"doi\":\"10.1109/TIP.2017.2788196\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d1f77d9418a212c61a3c75c04a5b3884f6441ba\",\"title\":\"Hierarchical and Spatio-Temporal Sparse Representation for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4d1f77d9418a212c61a3c75c04a5b3884f6441ba\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27051463\",\"name\":\"Emil Shirima\"},{\"authorId\":\"2883129\",\"name\":\"Kambiz Ghazinour\"}],\"doi\":\"10.1007/978-3-030-45371-8_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7c94908472a43be1981cb920ab4164d2fc6ba414\",\"title\":\"Towards Privacy-Aware Smart Surveillance\",\"url\":\"https://www.semanticscholar.org/paper/7c94908472a43be1981cb920ab4164d2fc6ba414\",\"venue\":\"FPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1938121\",\"name\":\"Pejman Habashi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c05a10cafbeeffc0c1923fe28f619b2db3c7b101\",\"title\":\"Trajectory-based Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c05a10cafbeeffc0c1923fe28f619b2db3c7b101\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49521346\",\"name\":\"Y. Yuan\"},{\"authorId\":\"49404171\",\"name\":\"Haopeng Li\"},{\"authorId\":\"39669401\",\"name\":\"Q. Wang\"}],\"doi\":\"10.1109/ACCESS.2019.2916989\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"494f3bc2879b4273934e949ee6985f4ecf4b4932\",\"title\":\"Spatiotemporal Modeling for Video Summarization Using Convolutional Recurrent Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/494f3bc2879b4273934e949ee6985f4ecf4b4932\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1905.04511\",\"authors\":[{\"authorId\":\"119040053\",\"name\":\"Ayyappa Kumar Pambala\"},{\"authorId\":\"30895384\",\"name\":\"Titir Dutta\"},{\"authorId\":\"145702363\",\"name\":\"Soma Biswas\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"628b102f4b2b6b35a2516fced98b971379ba0bb4\",\"title\":\"Unified Generator-Classifier for Efficient Zero-Shot Learning\",\"url\":\"https://www.semanticscholar.org/paper/628b102f4b2b6b35a2516fced98b971379ba0bb4\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143602033\",\"name\":\"Anan Liu\"},{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":\"144536249\",\"name\":\"W. Nie\"},{\"authorId\":\"2788104\",\"name\":\"Yuting Su\"},{\"authorId\":\"3026404\",\"name\":\"Yongkang Wong\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":\"10.1109/TCYB.2016.2582918\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1ed617d14dbc53b20287d3405b14c68d8dad3965\",\"title\":\"Benchmarking a Multimodal and Multiview and Interactive Dataset for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1ed617d14dbc53b20287d3405b14c68d8dad3965\",\"venue\":\"IEEE Transactions on Cybernetics\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"47f4f0d6d7251e7b3dfa95b001b8b1420eb8654c\",\"title\":\"Analysis and recognition of human actions with flow features and temporal models\",\"url\":\"https://www.semanticscholar.org/paper/47f4f0d6d7251e7b3dfa95b001b8b1420eb8654c\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9452165\",\"name\":\"Mengyang Yu\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0d2dea23a9b0ff94bbfbdc321ea68f958715a208\",\"title\":\"Feature reduction and representation learning for visual applications\",\"url\":\"https://www.semanticscholar.org/paper/0d2dea23a9b0ff94bbfbdc321ea68f958715a208\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153065698\",\"name\":\"Yinghan Long\"},{\"authorId\":\"153181248\",\"name\":\"G. Srinivasan\"},{\"authorId\":\"9352814\",\"name\":\"Priyadarshini Panda\"},{\"authorId\":\"39703133\",\"name\":\"K. Roy\"}],\"doi\":\"10.1109/JETCAS.2019.2935004\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"212784b86f1bc4ddd43b621e35630579070a1b92\",\"title\":\"Structured Learning for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/212784b86f1bc4ddd43b621e35630579070a1b92\",\"venue\":\"IEEE Journal on Emerging and Selected Topics in Circuits and Systems\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1817030\",\"name\":\"Saining Xie\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"1808244\",\"name\":\"J. Huang\"},{\"authorId\":\"144035504\",\"name\":\"Zhuowen Tu\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4fa0d73b8ba114578744c2ebaf610d2ca9694f45\",\"title\":\"Rethinking Spatiotemporal Feature Learning For Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/4fa0d73b8ba114578744c2ebaf610d2ca9694f45\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144474750\",\"name\":\"Subhabrata Bhattacharya\"}],\"doi\":\"10.1145/2502081.2502210\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a38f5f806a65f87052252946b00be2905ab4fa60\",\"title\":\"Recognition of complex events in open-source web-scale videos: a bottom up approach\",\"url\":\"https://www.semanticscholar.org/paper/a38f5f806a65f87052252946b00be2905ab4fa60\",\"venue\":\"MM '13\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3195774\",\"name\":\"Waqas Sultani\"},{\"authorId\":\"2658133\",\"name\":\"Imran Saleemi\"}],\"doi\":\"10.1109/CVPR.2014.103\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"222d64f63e37ea8f1044176347a49e9c5ef74e2c\",\"title\":\"Human Action Recognition across Datasets by Foreground-Weighted Histogram Decomposition\",\"url\":\"https://www.semanticscholar.org/paper/222d64f63e37ea8f1044176347a49e9c5ef74e2c\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1603.06182\",\"authors\":[{\"authorId\":\"46701988\",\"name\":\"Haimin Zhang\"},{\"authorId\":\"145093159\",\"name\":\"Min Xu\"},{\"authorId\":\"145194969\",\"name\":\"Changsheng Xu\"},{\"authorId\":\"144938740\",\"name\":\"Ramesh C. Jain\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"164b34268c42a1de531d8afb8568889a4b112898\",\"title\":\"Modelling Temporal Information Using Discrete Fourier Transform for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/164b34268c42a1de531d8afb8568889a4b112898\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41230702\",\"name\":\"Nadav Israel\"},{\"authorId\":\"145128145\",\"name\":\"Lior Wolf\"},{\"authorId\":\"34638780\",\"name\":\"Ran Barzilay\"},{\"authorId\":\"5069537\",\"name\":\"Gal Shoval\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d5e310a14ee681fa5c0ddb239f93715625cc9f3f\",\"title\":\"Robust features for facial action recognition\",\"url\":\"https://www.semanticscholar.org/paper/d5e310a14ee681fa5c0ddb239f93715625cc9f3f\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1904.03597\",\"authors\":[{\"authorId\":\"46584859\",\"name\":\"Jiangliu Wang\"},{\"authorId\":\"2840852\",\"name\":\"Jianbo Jiao\"},{\"authorId\":\"2780029\",\"name\":\"Linchao Bao\"},{\"authorId\":\"2548483\",\"name\":\"Shengfeng He\"},{\"authorId\":\"46398631\",\"name\":\"Yunhui Liu\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"}],\"doi\":\"10.1109/CVPR.2019.00413\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb2f5e00049eb5bd36bea402c2818fe4bbfe0a0e\",\"title\":\"Self-Supervised Spatio-Temporal Representation Learning for Videos by Predicting Motion and Appearance Statistics\",\"url\":\"https://www.semanticscholar.org/paper/eb2f5e00049eb5bd36bea402c2818fe4bbfe0a0e\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1904.08703\",\"authors\":[{\"authorId\":\"2398479\",\"name\":\"D. Mandal\"},{\"authorId\":\"3347447\",\"name\":\"Sanath Narayan\"},{\"authorId\":\"102609418\",\"name\":\"Saikumar Dwivedi\"},{\"authorId\":\"144147487\",\"name\":\"V. Gupta\"},{\"authorId\":\"7483338\",\"name\":\"Shuaib Ahmed\"},{\"authorId\":\"2358803\",\"name\":\"F. Khan\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"}],\"doi\":\"10.1109/CVPR.2019.01022\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"510b6717750d711f590e4df0e9a9c82ff332ff46\",\"title\":\"Out-Of-Distribution Detection for Generalized Zero-Shot Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/510b6717750d711f590e4df0e9a9c82ff332ff46\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2274625\",\"name\":\"Do Hang Nga\"},{\"authorId\":\"1681659\",\"name\":\"K. Yanai\"}],\"doi\":\"10.1016/j.cviu.2013.03.009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"83a46116a4b4f5fe7c90ed795c73d7814f63c478\",\"title\":\"Automatic extraction of relevant video shots of specific actions exploiting Web data\",\"url\":\"https://www.semanticscholar.org/paper/83a46116a4b4f5fe7c90ed795c73d7814f63c478\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410106115\",\"name\":\"Tieu Binh Hoang\"},{\"authorId\":\"29543391\",\"name\":\"T. C. Ma\"},{\"authorId\":\"71752568\",\"name\":\"Sugimoto Akihiro\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"c85147d279ba2e3360b2a45a68a5c4f1a1f8f625\",\"title\":\"Selecting active frames for action recognition with 3D convolutional network\",\"url\":\"https://www.semanticscholar.org/paper/c85147d279ba2e3360b2a45a68a5c4f1a1f8f625\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29776066\",\"name\":\"K. Reddy\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"417420030949aa48a468151b3ed8dd156efa149a\",\"title\":\"Action Recognition Using Particle Flow Fields\",\"url\":\"https://www.semanticscholar.org/paper/417420030949aa48a468151b3ed8dd156efa149a\",\"venue\":\"\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37038796\",\"name\":\"M. Bhatt\"},{\"authorId\":\"1845677\",\"name\":\"T. Patalia\"}],\"doi\":\"10.11591/IJECE.V7I4.PP1952-1963\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d9d084aac6c021a6bfc1a9a03c0fa950387df86a\",\"title\":\"Indian Monuments Classification using Support Vector Machine\",\"url\":\"https://www.semanticscholar.org/paper/d9d084aac6c021a6bfc1a9a03c0fa950387df86a\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"40404576\",\"name\":\"S. Amin\"},{\"authorId\":\"1906895\",\"name\":\"M. Andriluka\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1109/CVPR.2012.6247801\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"49435aab7cdf259335725acc96691f755e436f55\",\"title\":\"A database for fine grained activity detection of cooking activities\",\"url\":\"https://www.semanticscholar.org/paper/49435aab7cdf259335725acc96691f755e436f55\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2037859\",\"name\":\"Saddam Bekhet\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"274be0f6a343c0c75e792f4fa9f598bf7d1924c8\",\"title\":\"Signature-based videos' visual similarity detection and measurement\",\"url\":\"https://www.semanticscholar.org/paper/274be0f6a343c0c75e792f4fa9f598bf7d1924c8\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"16208838\",\"name\":\"A. Al-Shaikh\"},{\"authorId\":\"3330543\",\"name\":\"M. Sedky\"}],\"doi\":\"10.7753/IJCATR0612.1007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"09bd994894e7cce4dceb2ee5957e05615a6e54fd\",\"title\":\"A Cortical Learning Movement Classification Algorithm for Video Surveillance\",\"url\":\"https://www.semanticscholar.org/paper/09bd994894e7cce4dceb2ee5957e05615a6e54fd\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2505740\",\"name\":\"Dennis Ludl\"},{\"authorId\":\"7932331\",\"name\":\"T. Gulde\"},{\"authorId\":\"52208429\",\"name\":\"Salma Thalji\"},{\"authorId\":\"8045043\",\"name\":\"C. Curio\"}],\"doi\":\"10.1109/ITSC.2018.8569489\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"39523a5a0225618bdd55212da8c51b04d5db789a\",\"title\":\"Using Simulation to Improve Human Pose Estimation for Corner Cases\",\"url\":\"https://www.semanticscholar.org/paper/39523a5a0225618bdd55212da8c51b04d5db789a\",\"venue\":\"2018 21st International Conference on Intelligent Transportation Systems (ITSC)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"506ea19145838a035e7dba535519fb40a3a0018c\",\"title\":\"Learning Shared Multimodal Embeddings with Unpaired Data\",\"url\":\"https://www.semanticscholar.org/paper/506ea19145838a035e7dba535519fb40a3a0018c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1804.09066\",\"authors\":[{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"145264990\",\"name\":\"K. Singh\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1007/978-3-030-01216-8_43\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aa63893b34f523973d0692dc74ff22512daac322\",\"title\":\"ECO: Efficient Convolutional Network for Online Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/aa63893b34f523973d0692dc74ff22512daac322\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1953034\",\"name\":\"Manavender R. Malgireddy\"},{\"authorId\":\"1841118\",\"name\":\"Ifeoma Nwogu\"},{\"authorId\":\"1723877\",\"name\":\"V. Govindaraju\"}],\"doi\":\"10.1109/CVPRW.2012.6239185\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"22bdc139f95dd4c0fcb165cd95c1ffbb6784c3ea\",\"title\":\"A temporal Bayesian model for classifying, detecting and localizing activities in video sequences\",\"url\":\"https://www.semanticscholar.org/paper/22bdc139f95dd4c0fcb165cd95c1ffbb6784c3ea\",\"venue\":\"2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35031371\",\"name\":\"Wenbin Du\"},{\"authorId\":\"2799162\",\"name\":\"Y. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1109/TIP.2017.2778563\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"57eeaceb14a01a2560d0b90d38205e512dcca691\",\"title\":\"Recurrent Spatial-Temporal Attention Network for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/57eeaceb14a01a2560d0b90d38205e512dcca691\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39527134\",\"name\":\"X. Wang\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1007/978-3-642-37431-9_44\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"536bd55a69a5f536fc4450ac4f482d47333b0270\",\"title\":\"A Comparative Study of Encoding, Pooling and Normalization Methods for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/536bd55a69a5f536fc4450ac4f482d47333b0270\",\"venue\":\"ACCV\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1109/CVPR.2013.345\",\"intent\":[\"result\"],\"isInfluential\":true,\"paperId\":\"2633f6a4bb683aafecd86e9484258c0767196422\",\"title\":\"Motionlets: Mid-level 3D Parts for Human Motion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2633f6a4bb683aafecd86e9484258c0767196422\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153082819\",\"name\":\"Qian Li\"},{\"authorId\":\"1992684694\",\"name\":\"Wenzhu Yang\"},{\"authorId\":\"1992715817\",\"name\":\"Xiangyang Chen\"},{\"authorId\":\"50090639\",\"name\":\"Tongtong Yuan\"},{\"authorId\":null,\"name\":\"Yuxia Wang\"}],\"doi\":\"10.1109/ACCESS.2020.3027386\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"0475918d855bbfcf4c693359935d9a483b7541ce\",\"title\":\"Temporal Segment Connection Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/0475918d855bbfcf4c693359935d9a483b7541ce\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46598954\",\"name\":\"Dan Li\"},{\"authorId\":\"1656176919\",\"name\":\"Kaifeng Zhang\"},{\"authorId\":\"40388829\",\"name\":\"Z. Li\"},{\"authorId\":\"97042247\",\"name\":\"Y. Chen\"}],\"doi\":\"10.3390/s20082381\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a3d3f0d1546018493cfa3a7c502a420e260a791f\",\"title\":\"A Spatiotemporal Convolutional Network for Multi-Behavior Recognition of Pigs\",\"url\":\"https://www.semanticscholar.org/paper/a3d3f0d1546018493cfa3a7c502a420e260a791f\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145254044\",\"name\":\"Jun Zhu\"},{\"authorId\":\"144700854\",\"name\":\"Q. Zhou\"},{\"authorId\":\"2568790\",\"name\":\"Weijia Zou\"},{\"authorId\":\"144142354\",\"name\":\"Rui Zhang\"},{\"authorId\":\"31064779\",\"name\":\"W. Zhang\"}],\"doi\":\"10.3390/s131114398\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3d8efa1175cb0bfdac1e5aac76e752000ba870e2\",\"title\":\"A Generalized Pyramid Matching Kernel for Human Action Recognition in Realistic Videos\",\"url\":\"https://www.semanticscholar.org/paper/3d8efa1175cb0bfdac1e5aac76e752000ba870e2\",\"venue\":\"Sensors\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1941827\",\"name\":\"I. Rodomagoulakis\"},{\"authorId\":\"3493540\",\"name\":\"N. Kardaris\"},{\"authorId\":\"1738119\",\"name\":\"Vassilis Pitsikalis\"},{\"authorId\":\"3493963\",\"name\":\"A. Arvanitakis\"},{\"authorId\":\"1750686\",\"name\":\"P. Maragos\"}],\"doi\":\"10.1109/ICIP.2016.7532923\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"398afc170210dbdd1b4138e180ee2edf09215500\",\"title\":\"A multimedia gesture dataset for human robot communication: Acquisition, tools and recognition results\",\"url\":\"https://www.semanticscholar.org/paper/398afc170210dbdd1b4138e180ee2edf09215500\",\"venue\":\"2016 IEEE International Conference on Image Processing (ICIP)\",\"year\":2016},{\"arxivId\":\"1906.06822\",\"authors\":[{\"authorId\":\"2173531\",\"name\":\"Sangwoo Cho\"},{\"authorId\":\"1691260\",\"name\":\"H. Foroosh\"}],\"doi\":\"10.1007/978-3-030-20887-5_22\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fd4303b2f54a2a87c4ee33b33359b85258d4a726\",\"title\":\"Spatio-Temporal Fusion Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fd4303b2f54a2a87c4ee33b33359b85258d4a726\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"1708.07632\",\"authors\":[{\"authorId\":\"2199251\",\"name\":\"K. Hara\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"}],\"doi\":\"10.1109/ICCVW.2017.373\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"07c83f544d0604e6bab5d741b0bf9a3621d133da\",\"title\":\"Learning Spatio-Temporal Features with 3D Residual Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/07c83f544d0604e6bab5d741b0bf9a3621d133da\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46181112\",\"name\":\"Chaoxu Guo\"},{\"authorId\":\"39974958\",\"name\":\"T. Yu\"},{\"authorId\":\"1909131\",\"name\":\"Huxiang Gu\"},{\"authorId\":\"1683738\",\"name\":\"S. Xiang\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.1109/ICASSP.2018.8462612\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"88493c1952000cde64c3f2294d36fc76fd23bf3f\",\"title\":\"Mgn: Multi-Glimpse Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/88493c1952000cde64c3f2294d36fc76fd23bf3f\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":\"1706.03038\",\"authors\":[{\"authorId\":\"39393520\",\"name\":\"M. Barekatain\"},{\"authorId\":\"144294961\",\"name\":\"M. Mart\\u00ed\"},{\"authorId\":\"19185012\",\"name\":\"Hsueh-Fu Shih\"},{\"authorId\":\"153083684\",\"name\":\"S. Murray\"},{\"authorId\":\"1943224\",\"name\":\"K. Nakayama\"},{\"authorId\":\"49484314\",\"name\":\"Y. Matsuo\"},{\"authorId\":\"2356111\",\"name\":\"H. Prendinger\"}],\"doi\":\"10.1109/CVPRW.2017.267\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bd0e100a91ff179ee5c1d3383c75c85eddc81723\",\"title\":\"Okutama-Action: An Aerial View Video Dataset for Concurrent Human Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/bd0e100a91ff179ee5c1d3383c75c85eddc81723\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":\"1501.04367\",\"authors\":[{\"authorId\":\"40222634\",\"name\":\"K. Kulkarni\"},{\"authorId\":\"143655174\",\"name\":\"P. Turaga\"}],\"doi\":\"10.1109/TPAMI.2015.2469288\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5d082a3d06d5911fbde48b79ccef98df5d04cf59\",\"title\":\"Reconstruction-Free Action Inference from Compressive Imagers\",\"url\":\"https://www.semanticscholar.org/paper/5d082a3d06d5911fbde48b79ccef98df5d04cf59\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2016},{\"arxivId\":\"1909.09422\",\"authors\":[{\"authorId\":\"50065546\",\"name\":\"W. Price\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.1109/ICCVW.2019.00173\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3c0cf56b33fdca7529ec5bc308060e307c9ae1bc\",\"title\":\"Retro-Actions: Learning 'Close' by Time-Reversing 'Open' Videos\",\"url\":\"https://www.semanticscholar.org/paper/3c0cf56b33fdca7529ec5bc308060e307c9ae1bc\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"96140284\",\"name\":\"N. Sedaghat\"},{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e3144f39f473e238374dd4005c8b83e19764ae9e\",\"title\":\"Hybrid Learning of Optical Flow and Next Frame Prediction to Boost Optical Flow in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/e3144f39f473e238374dd4005c8b83e19764ae9e\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1708.06250\",\"authors\":[{\"authorId\":\"39599054\",\"name\":\"B. Sengupta\"},{\"authorId\":\"50059673\",\"name\":\"Yu Qian\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"501bfe67683ddfecf3710f5946c3b77f1ffe9adf\",\"title\":\"Pillar Networks++: Distributed non-parametric deep and wide networks\",\"url\":\"https://www.semanticscholar.org/paper/501bfe67683ddfecf3710f5946c3b77f1ffe9adf\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34608005\",\"name\":\"L. Chen\"},{\"authorId\":\"144207288\",\"name\":\"R. Liu\"},{\"authorId\":\"153450634\",\"name\":\"Dongsheng Zhou\"},{\"authorId\":\"50031413\",\"name\":\"X. Yang\"},{\"authorId\":\"47835286\",\"name\":\"Qing-fang Zhang\"}],\"doi\":\"10.1186/s42492-020-00045-x\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"115880905156feef7d751840b7f59c72987b17a8\",\"title\":\"Fused behavior recognition model based on attention mechanism\",\"url\":\"https://www.semanticscholar.org/paper/115880905156feef7d751840b7f59c72987b17a8\",\"venue\":\"Vis. Comput. Ind. Biomed. Art\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145586191\",\"name\":\"Can Zhang\"},{\"authorId\":\"26981150\",\"name\":\"Yue-Xian Zou\"},{\"authorId\":\"115151196\",\"name\":\"G. Chen\"},{\"authorId\":\"48204311\",\"name\":\"L. Gan\"}],\"doi\":\"10.1145/3343031.3350876\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"ab7f7501d889607d6a9aa3f5ea465a8b1c44f7ff\",\"title\":\"PAN: Persistent Appearance Network with an Efficient Motion Cue for Fast Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ab7f7501d889607d6a9aa3f5ea465a8b1c44f7ff\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"2011.07949\",\"authors\":[{\"authorId\":\"4965440\",\"name\":\"Peihao Chen\"},{\"authorId\":\"145592817\",\"name\":\"D. Huang\"},{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"46550737\",\"name\":\"Xiang Long\"},{\"authorId\":\"147992804\",\"name\":\"Runhao Zeng\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"2336388131b3cb41eb44e927aeac10a1dabbedad\",\"title\":\"RSPNet: Relative Speed Perception for Unsupervised Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/2336388131b3cb41eb44e927aeac10a1dabbedad\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"143740449\",\"name\":\"Q. Peng\"}],\"doi\":\"10.1016/j.imavis.2014.06.011\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"96f6fd5bba796857bd3876fa02ff67d12e58b065\",\"title\":\"Motion boundary based sampling and 3D co-occurrence descriptors for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/96f6fd5bba796857bd3876fa02ff67d12e58b065\",\"venue\":\"Image Vis. Comput.\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491438016\",\"name\":\"Yuanye Fang\"},{\"authorId\":\"80083020\",\"name\":\"Rui Zhang\"},{\"authorId\":\"3040905\",\"name\":\"Q. Wang\"},{\"authorId\":\"5380819\",\"name\":\"K. Huang\"}],\"doi\":\"10.1007/978-3-030-39431-8_23\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d662fa47ebfc8b800d9bbadbe581325cf27a6764\",\"title\":\"Action Recognition in Videos with Temporal Segments Fusions\",\"url\":\"https://www.semanticscholar.org/paper/d662fa47ebfc8b800d9bbadbe581325cf27a6764\",\"venue\":\"BICS\",\"year\":2019},{\"arxivId\":\"1909.13474\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":\"10.1109/ICMLA.2019.00036\",\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"df3b3722df9f1c6a6b586a1c81a109c61ae7f9a9\",\"title\":\"Spatio-Temporal FAST 3D Convolutions for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/df3b3722df9f1c6a6b586a1c81a109c61ae7f9a9\",\"venue\":\"2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA)\",\"year\":2019},{\"arxivId\":\"1804.10073\",\"authors\":[{\"authorId\":\"2439211\",\"name\":\"Chenrui Zhang\"},{\"authorId\":\"143753918\",\"name\":\"Y. Peng\"}],\"doi\":\"10.24963/ijcai.2018/157\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"090873e83594fc7396fb81b64f4ec38a05151304\",\"title\":\"Visual Data Synthesis via GAN for Zero-Shot Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/090873e83594fc7396fb81b64f4ec38a05151304\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145741492\",\"name\":\"Bo Sun\"},{\"authorId\":\"9767548\",\"name\":\"K. Zhao\"},{\"authorId\":\"2308836\",\"name\":\"Yongkang Xiao\"},{\"authorId\":\"1434623735\",\"name\":\"J. He\"},{\"authorId\":\"8834504\",\"name\":\"Lejun Yu\"},{\"authorId\":\"50118329\",\"name\":\"Y. Wu\"},{\"authorId\":\"83162482\",\"name\":\"Huanqing Yan\"}],\"doi\":\"10.1117/12.2539052\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bef084f8096a297cb0a8ab1706adea724348a29f\",\"title\":\"BNU-LCSAD: a video database for classroom student action recognition\",\"url\":\"https://www.semanticscholar.org/paper/bef084f8096a297cb0a8ab1706adea724348a29f\",\"venue\":\"SPIE/COS Photonics Asia\",\"year\":2019},{\"arxivId\":\"1908.05674\",\"authors\":[{\"authorId\":\"40478348\",\"name\":\"Dong Cao\"},{\"authorId\":\"49287317\",\"name\":\"Lisha Xu\"}],\"doi\":\"10.1007/978-981-15-3651-9_2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f99d62a02d91de622dbf5208ef859938980c16d6\",\"title\":\"Bypass Enhancement RGB Stream Model for Pedestrian Action Recognition of Autonomous Vehicles\",\"url\":\"https://www.semanticscholar.org/paper/f99d62a02d91de622dbf5208ef859938980c16d6\",\"venue\":\"ACPR Workshops\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47825539\",\"name\":\"Wei Wang\"},{\"authorId\":\"152299675\",\"name\":\"Siyuan Hao\"},{\"authorId\":\"49020088\",\"name\":\"Yunchao Wei\"},{\"authorId\":\"3124720\",\"name\":\"Shengtao Xiao\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":\"10.1109/ACCESS.2019.2936604\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"74195742093c489401ef8dc3d7f8639fd12c20e8\",\"title\":\"Temporal Spiking Recurrent Neural Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/74195742093c489401ef8dc3d7f8639fd12c20e8\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2896701\",\"name\":\"G. An\"},{\"authorId\":\"4464686\",\"name\":\"ZhenXing Zheng\"},{\"authorId\":\"144953181\",\"name\":\"D. Wu\"},{\"authorId\":\"153168978\",\"name\":\"Wen Zhou\"}],\"doi\":\"10.1016/j.jvcir.2019.102650\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a22e41d8ac3c56072d5fe1136567d1b82d9bb46e\",\"title\":\"Deep spectral feature pyramid in the frequency domain for long-term action recognition\",\"url\":\"https://www.semanticscholar.org/paper/a22e41d8ac3c56072d5fe1136567d1b82d9bb46e\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144732200\",\"name\":\"Bo Lin\"},{\"authorId\":\"143762041\",\"name\":\"B. Fang\"}],\"doi\":\"10.1109/SPAC.2017.8304361\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"5a2589f377fcb37c6c12fc41fc64e091314faae4\",\"title\":\"Spatial-temporal histograms of gradients and HOD-VLAD encoding for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/5a2589f377fcb37c6c12fc41fc64e091314faae4\",\"venue\":\"2017 International Conference on Security, Pattern Analysis, and Cybernetics (SPAC)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1400476720\",\"name\":\"I. G\\u00f3mez-Conde\"},{\"authorId\":\"9443453\",\"name\":\"D. Olivieri\"}],\"doi\":\"10.1016/j.eswa.2015.03.010\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"76aff12778897c6d5471316b028974d64bbb200e\",\"title\":\"A KPCA spatio-temporal differential geometric trajectory cloud classifier for recognizing human actions in a CBVR system\",\"url\":\"https://www.semanticscholar.org/paper/76aff12778897c6d5471316b028974d64bbb200e\",\"venue\":\"Expert Syst. Appl.\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50647202\",\"name\":\"Imran Mumtaz\"},{\"authorId\":\"2053666\",\"name\":\"J. Lv\"},{\"authorId\":\"2059158\",\"name\":\"Jiangshu Wei\"}],\"doi\":\"10.1109/ICIST.2015.7289036\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b956d741740186c99c64bb789c87da000ed3c3a5\",\"title\":\"A novel method for online action segmentation and classification\",\"url\":\"https://www.semanticscholar.org/paper/b956d741740186c99c64bb789c87da000ed3c3a5\",\"venue\":\"2015 5th International Conference on Information Science and Technology (ICIST)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145674667\",\"name\":\"J. Miao\"},{\"authorId\":\"9303726\",\"name\":\"Xiangmin Xu\"},{\"authorId\":\"2704537\",\"name\":\"Shuoyang Qiu\"},{\"authorId\":\"37178775\",\"name\":\"Chunmei Qing\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/TIP.2015.2490551\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"93e1e195f294c463f4832c4686775bf386b3de39\",\"title\":\"Temporal Variance Analysis for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/93e1e195f294c463f4832c4686775bf386b3de39\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145416574\",\"name\":\"H. Shen\"},{\"authorId\":\"47971190\",\"name\":\"Yan Yan\"},{\"authorId\":\"2202745\",\"name\":\"Shicheng Xu\"},{\"authorId\":\"2482072\",\"name\":\"Nicolas Ballas\"},{\"authorId\":\"2530697\",\"name\":\"Wenzhi Chen\"}],\"doi\":\"10.1007/s11042-014-1936-z\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1053843d9c185eba1b113238a811fd96c0ceda9d\",\"title\":\"Evaluation of semi-supervised learning method on action recognition\",\"url\":\"https://www.semanticscholar.org/paper/1053843d9c185eba1b113238a811fd96c0ceda9d\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"97514733\",\"name\":\"Jin-woo Choi\"},{\"authorId\":\"2515597\",\"name\":\"Gaurav Sharma\"},{\"authorId\":\"1790643\",\"name\":\"S. Schulter\"},{\"authorId\":\"50535349\",\"name\":\"J. Huang\"}],\"doi\":\"10.1007/978-3-030-58610-2_40\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"19d574a2238ad11142de1d6f2713315880b2d218\",\"title\":\"Shuffle and Attend: Video Domain Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/19d574a2238ad11142de1d6f2713315880b2d218\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2009.09805\",\"authors\":[{\"authorId\":\"1491401265\",\"name\":\"Shuang Ma\"},{\"authorId\":\"46490565\",\"name\":\"Zhaoyang Zeng\"},{\"authorId\":\"1381192475\",\"name\":\"Daniel McDuff\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7df5dd31f2ce600a4be589dff4d6a758be262324\",\"title\":\"Learning Audio-Visual Representations with Active Contrastive Coding\",\"url\":\"https://www.semanticscholar.org/paper/7df5dd31f2ce600a4be589dff4d6a758be262324\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2894970\",\"name\":\"Yanhu Shan\"},{\"authorId\":\"31828103\",\"name\":\"Z. Zhang\"},{\"authorId\":\"145655470\",\"name\":\"P. Yang\"},{\"authorId\":\"2887871\",\"name\":\"K. Huang\"}],\"doi\":\"10.1109/TCSVT.2014.2376136\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a9506c60ec48056087ee3e10d28ff7774fbbd553\",\"title\":\"Adaptive Slice Representation for Human Action Classification\",\"url\":\"https://www.semanticscholar.org/paper/a9506c60ec48056087ee3e10d28ff7774fbbd553\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49178278\",\"name\":\"Hua-feng Chen\"},{\"authorId\":\"47892402\",\"name\":\"H. Li\"},{\"authorId\":\"2646978\",\"name\":\"Zengmin Xu\"},{\"authorId\":\"46317173\",\"name\":\"Yunhong Zhao\"},{\"authorId\":\"1693960373\",\"name\":\"He Tigang\"}],\"doi\":\"10.1002/cpe.5507\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"354a6b5302e28427c621789d863a7381e9965d4f\",\"title\":\"Real\\u2010time action feature extraction via fast PCA\\u2010Flow\",\"url\":\"https://www.semanticscholar.org/paper/354a6b5302e28427c621789d863a7381e9965d4f\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5546708\",\"name\":\"Ronak Gupta\"},{\"authorId\":\"72177702\",\"name\":\"Prashant Anand\"},{\"authorId\":\"5911068\",\"name\":\"V. Kaushik\"},{\"authorId\":\"144725842\",\"name\":\"S. Chaudhury\"},{\"authorId\":\"143632379\",\"name\":\"Brejesh Lall\"}],\"doi\":\"10.1007/978-3-030-34869-4_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"082855f9000482c9571cda2aadaad05306caaf00\",\"title\":\"Data Driven Sensing for Action Recognition Using Deep Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/082855f9000482c9571cda2aadaad05306caaf00\",\"venue\":\"PReMI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10839487\",\"name\":\"Chunbo Song\"},{\"authorId\":\"46887763\",\"name\":\"C. Rasmussen\"}],\"doi\":\"10.1007/978-3-030-33720-9_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ce9c9eb94b7308728bca5ee6af45dbd7d6f22fb4\",\"title\":\"Multi-camera Temporal Grouping for Play/Break Event Detection in Soccer Games\",\"url\":\"https://www.semanticscholar.org/paper/ce9c9eb94b7308728bca5ee6af45dbd7d6f22fb4\",\"venue\":\"ISVC\",\"year\":2019},{\"arxivId\":\"2007.12887\",\"authors\":[{\"authorId\":\"26415158\",\"name\":\"Xinqi Zhu\"},{\"authorId\":\"153250308\",\"name\":\"C. Xu\"},{\"authorId\":\"102853050\",\"name\":\"L. Hui\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/ICCV.2019.00359\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7303ce1fe8f54f45e4558eb81368bda9dfe2793f\",\"title\":\"Approximated Bilinear Modules for Temporal Modeling\",\"url\":\"https://www.semanticscholar.org/paper/7303ce1fe8f54f45e4558eb81368bda9dfe2793f\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2720733\",\"name\":\"Wangli Hao\"},{\"authorId\":\"145274329\",\"name\":\"Zhaoxiang Zhang\"}],\"doi\":\"10.1016/J.PATCOG.2019.03.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"04d27bbbc875bd8fe52521112841d47b21950e7c\",\"title\":\"Spatiotemporal distilled dense-connectivity network for video action recognition\",\"url\":\"https://www.semanticscholar.org/paper/04d27bbbc875bd8fe52521112841d47b21950e7c\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":\"1910.11667\",\"authors\":[{\"authorId\":\"1952002\",\"name\":\"A. Ranjan\"},{\"authorId\":\"151491781\",\"name\":\"David T. Hoffmann\"},{\"authorId\":\"1940674\",\"name\":\"Dimitrios Tzionas\"},{\"authorId\":\"39578749\",\"name\":\"Siyu Tang\"},{\"authorId\":\"144516670\",\"name\":\"J. Romero\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"}],\"doi\":\"10.1007/s11263-019-01279-w\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6caa038decc7e083fdcac4a3d5797eaf19036016\",\"title\":\"Learning Multi-human Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/6caa038decc7e083fdcac4a3d5797eaf19036016\",\"venue\":\"International Journal of Computer Vision\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8194130\",\"name\":\"Qinyu Li\"},{\"authorId\":\"46307804\",\"name\":\"L. Chen\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"2535030\",\"name\":\"Xianhui Liu\"}],\"doi\":\"10.1007/978-3-030-37731-1_36\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f16256ffdedf1028d44c7cf40a30af1af86b8dde\",\"title\":\"Wonderful Clips of Playing Basketball: A Database for Localizing Wonderful Actions\",\"url\":\"https://www.semanticscholar.org/paper/f16256ffdedf1028d44c7cf40a30af1af86b8dde\",\"venue\":\"MMM\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144732200\",\"name\":\"Bo Lin\"},{\"authorId\":\"143762036\",\"name\":\"B. Fang\"},{\"authorId\":\"2781714\",\"name\":\"Weibin Yang\"},{\"authorId\":\"2543829\",\"name\":\"Jiye Qian\"}],\"doi\":\"10.1016/J.NEUCOM.2018.05.121\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"733c9221c92fcd7b2c339ac1872a8d1331579d9b\",\"title\":\"Human action recognition based on spatio-temporal three-dimensional scattering transform descriptor and an improved VLAD feature encoding algorithm\",\"url\":\"https://www.semanticscholar.org/paper/733c9221c92fcd7b2c339ac1872a8d1331579d9b\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"2006.13256\",\"authors\":[{\"authorId\":\"1677780022\",\"name\":\"Dima Damen\"},{\"authorId\":\"28798386\",\"name\":\"H. Doughty\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"},{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"48842721\",\"name\":\"Evangelos Kazakos\"},{\"authorId\":\"153155867\",\"name\":\"Jian Ma\"},{\"authorId\":\"3420479\",\"name\":\"D. Moltisanti\"},{\"authorId\":\"47077615\",\"name\":\"J. Munro\"},{\"authorId\":\"2682004\",\"name\":\"T. Perrett\"},{\"authorId\":\"50065546\",\"name\":\"W. Price\"},{\"authorId\":\"145032628\",\"name\":\"Michael Wray\"}],\"doi\":\"10.5523/bris.2g1n6qdydwa9u22shpxqzp0t8m\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c1a80daadab9c3bc3fdf183c669070ba7a3fd37\",\"title\":\"Rescaling Egocentric Vision\",\"url\":\"https://www.semanticscholar.org/paper/6c1a80daadab9c3bc3fdf183c669070ba7a3fd37\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1506.01911\",\"authors\":[{\"authorId\":\"2660640\",\"name\":\"Lionel Pigou\"},{\"authorId\":\"3422336\",\"name\":\"A. Oord\"},{\"authorId\":\"48373216\",\"name\":\"S. Dieleman\"},{\"authorId\":\"10182287\",\"name\":\"M. V. Herreweghe\"},{\"authorId\":\"2309489\",\"name\":\"J. Dambre\"}],\"doi\":\"10.1007/s11263-016-0957-7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eae099ca54c9ee12a5763f6347b91f77df2c7bf4\",\"title\":\"Beyond Temporal Pooling: Recurrence and Temporal Convolutions for Gesture Recognition in Video\",\"url\":\"https://www.semanticscholar.org/paper/eae099ca54c9ee12a5763f6347b91f77df2c7bf4\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2243402\",\"name\":\"Jinglian Liang\"},{\"authorId\":\"145194975\",\"name\":\"Chao Xu\"},{\"authorId\":\"145774081\",\"name\":\"Z. Feng\"},{\"authorId\":\"2518530\",\"name\":\"Xirong Ma\"}],\"doi\":\"10.1016/j.cviu.2015.10.008\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"40c77e25129275b91675ea1b3da07ff5b81c32ca\",\"title\":\"Affective interaction recognition using spatio-temporal features and context\",\"url\":\"https://www.semanticscholar.org/paper/40c77e25129275b91675ea1b3da07ff5b81c32ca\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2016},{\"arxivId\":\"1603.08079\",\"authors\":[{\"authorId\":\"1908728\",\"name\":\"Yevgeni Berzak\"},{\"authorId\":\"21570451\",\"name\":\"A. Barbu\"},{\"authorId\":\"38872009\",\"name\":\"Daniel Harari\"},{\"authorId\":\"6104312\",\"name\":\"Boris Katz\"},{\"authorId\":\"1743045\",\"name\":\"S. Ullman\"}],\"doi\":\"10.18653/v1/D15-1172\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3244699e06b145ffa65d0fbddb2ce6e5da889418\",\"title\":\"Do You See What I Mean? Visual Resolution of Linguistic Ambiguities\",\"url\":\"https://www.semanticscholar.org/paper/3244699e06b145ffa65d0fbddb2ce6e5da889418\",\"venue\":\"EMNLP\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"69442223\",\"name\":\"V. Luong\"},{\"authorId\":\"31887773\",\"name\":\"L. Wang\"},{\"authorId\":\"143845735\",\"name\":\"Gaoxi Xiao\"}],\"doi\":\"10.1007/978-3-319-13359-1_42\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f5d077fc03189f0b54fdb1397e8bcf8d026595bc\",\"title\":\"Action Recognition Using Hierarchical Independent Subspace Analysis with Trajectory\",\"url\":\"https://www.semanticscholar.org/paper/f5d077fc03189f0b54fdb1397e8bcf8d026595bc\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1506.08438\",\"authors\":[{\"authorId\":\"3114252\",\"name\":\"O. Sener\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"1702137\",\"name\":\"S. Savarese\"},{\"authorId\":\"1681995\",\"name\":\"A. Saxena\"}],\"doi\":\"10.1109/ICCV.2015.509\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"71d114b58379b99cb96f01fbb9d1667d970ed53c\",\"title\":\"Unsupervised Semantic Parsing of Video Collections\",\"url\":\"https://www.semanticscholar.org/paper/71d114b58379b99cb96f01fbb9d1667d970ed53c\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48397283\",\"name\":\"Ruiqi Wang\"},{\"authorId\":\"2125709\",\"name\":\"Xinxiao Wu\"}],\"doi\":\"10.1007/S11042-018-6509-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c44ce50b8d369b6ee49c540ff1a74992b1358664\",\"title\":\"Combining multiple deep cues for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/c44ce50b8d369b6ee49c540ff1a74992b1358664\",\"venue\":\"Multim. Tools Appl.\",\"year\":2019},{\"arxivId\":\"1906.03349\",\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"}],\"doi\":\"10.1109/cvpr42600.2020.00043\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"45a924794b2c6501b671cf4249c6ac4fa1671597\",\"title\":\"Video Modeling With Correlation Networks\",\"url\":\"https://www.semanticscholar.org/paper/45a924794b2c6501b671cf4249c6ac4fa1671597\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143611428\",\"name\":\"Z. Tu\"},{\"authorId\":\"144561919\",\"name\":\"W. Xie\"},{\"authorId\":\"39952920\",\"name\":\"Q. Qin\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"},{\"authorId\":\"1739867\",\"name\":\"R. Veltkamp\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1016/j.patcog.2018.01.020\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"baa733992a236258adf36a41413b96707c8e9f4c\",\"title\":\"Multi-stream CNN: Learning representations based on human-related regions for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/baa733992a236258adf36a41413b96707c8e9f4c\",\"venue\":\"Pattern Recognit.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3074923\",\"name\":\"Alexandros Iosifidis\"},{\"authorId\":\"1737071\",\"name\":\"A. Tefas\"},{\"authorId\":\"144064571\",\"name\":\"I. Pitas\"},{\"authorId\":\"9219875\",\"name\":\"M. Gabbouj\"}],\"doi\":\"10.1016/j.image.2017.10.004\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e828a00f51116e0ffcb118db0a29122758f1a2ef\",\"title\":\"Big Media Data Analysis\",\"url\":\"https://www.semanticscholar.org/paper/e828a00f51116e0ffcb118db0a29122758f1a2ef\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2017},{\"arxivId\":\"1705.02953\",\"authors\":[{\"authorId\":\"119770705\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"134339866\",\"name\":\"L. V. Van Gool\"}],\"doi\":\"10.1109/TPAMI.2018.2868668\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"37c970a2f27810987e2b47dd5b8e0cc9bb976a38\",\"title\":\"Temporal Segment Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/37c970a2f27810987e2b47dd5b8e0cc9bb976a38\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1145/3122865\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8e87853672791ed5254a1cfc4b7582e7a41a89d6\",\"title\":\"Frontiers of Multimedia Research\",\"url\":\"https://www.semanticscholar.org/paper/8e87853672791ed5254a1cfc4b7582e7a41a89d6\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2822290\",\"name\":\"Suraj Srinivas\"},{\"authorId\":\"1730952\",\"name\":\"Ravi Kiran Sarvadevabhatla\"},{\"authorId\":\"2217000\",\"name\":\"Konda Reddy Mopuri\"},{\"authorId\":\"40390520\",\"name\":\"N. Prabhu\"},{\"authorId\":\"1784761\",\"name\":\"S. Kruthiventi\"},{\"authorId\":\"144682140\",\"name\":\"R. Venkatesh Babu\"}],\"doi\":\"10.1016/B978-0-12-810408-8.00003-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"783cd91797aad234b1558099689e794b48694092\",\"title\":\"An Introduction to Deep Convolutional Neural Nets for Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/783cd91797aad234b1558099689e794b48694092\",\"venue\":\"Deep Learning for Medical Image Analysis\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40566477\",\"name\":\"H. Yang\"},{\"authorId\":null,\"name\":\"Chunfeng Yuan\"},{\"authorId\":\"1757173\",\"name\":\"Junliang Xing\"},{\"authorId\":\"40506509\",\"name\":\"W. Hu\"}],\"doi\":\"10.1109/ICIP.2017.8296802\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"cc6d3ccc9e3dd0a43313a714316c8783cd879572\",\"title\":\"Diversity encouraging ensemble of convolutional networks for high performance action recognition\",\"url\":\"https://www.semanticscholar.org/paper/cc6d3ccc9e3dd0a43313a714316c8783cd879572\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":\"1705.07750\",\"authors\":[{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2017.502\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"title\":\"Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset\",\"url\":\"https://www.semanticscholar.org/paper/b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"2008.01065\",\"authors\":[{\"authorId\":\"22237490\",\"name\":\"Tengda Han\"},{\"authorId\":\"10096695\",\"name\":\"Weidi Xie\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/978-3-030-58580-8_19\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"202c79bbb45ab6524141feacc81caacc4ba00401\",\"title\":\"Memory-augmented Dense Predictive Coding for Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/202c79bbb45ab6524141feacc81caacc4ba00401\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.02632\",\"authors\":[{\"authorId\":\"52025559\",\"name\":\"Mahsa Ehsanpour\"},{\"authorId\":\"3447236\",\"name\":\"A. Abedin\"},{\"authorId\":\"19170799\",\"name\":\"F. Saleh\"},{\"authorId\":\"31635758\",\"name\":\"Javen Shi\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"},{\"authorId\":\"1387977754\",\"name\":\"Hamid Rezatofighi\"}],\"doi\":\"10.1007/978-3-030-58545-7_11\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"81287e31f3e659aaedb5dce0646ba2b86377b282\",\"title\":\"Joint Learning of Social Groups, Individuals Action and Sub-group Activities in Videos\",\"url\":\"https://www.semanticscholar.org/paper/81287e31f3e659aaedb5dce0646ba2b86377b282\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2011.03949\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d7728ed8dd12e0ad64514ae9ec5d0bdf0576dadc\",\"title\":\"Right on Time: Multi-Temporal Convolutions for Human Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/d7728ed8dd12e0ad64514ae9ec5d0bdf0576dadc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152142657\",\"name\":\"Y. Tian\"},{\"authorId\":\"1825799769\",\"name\":\"Guangzhao Zhai\"},{\"authorId\":\"97709070\",\"name\":\"Z. Gao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5768e26731fb55edced4193596f6a470d0029ce6\",\"title\":\"Video-ception Network: Towards Multi-Scale Efficient Asymmetric Spatial-Temporal Interactions\",\"url\":\"https://www.semanticscholar.org/paper/5768e26731fb55edced4193596f6a470d0029ce6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.00197\",\"authors\":[{\"authorId\":\"29724362\",\"name\":\"Longlong Jing\"},{\"authorId\":\"1807477\",\"name\":\"T. Parag\"},{\"authorId\":\"152247556\",\"name\":\"Zhe Wu\"},{\"authorId\":\"8193125\",\"name\":\"Y. Tian\"},{\"authorId\":\"3254319\",\"name\":\"Hongcheng Wang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"637b413488ef5b72a3f04089ea3e3c635caab9ee\",\"title\":\"VideoSSL: Semi-Supervised Learning for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/637b413488ef5b72a3f04089ea3e3c635caab9ee\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1806.09078\",\"authors\":[{\"authorId\":\"8251954\",\"name\":\"Yusuf Tas\"},{\"authorId\":\"2155775\",\"name\":\"Piotr Koniusz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0b1f913c71c9eebffad728a53f8ccac0f226b9f4\",\"title\":\"CNN-based Action Recognition and Supervised Domain Adaptation on 3D Body Skeletons via Kernel Feature Maps\",\"url\":\"https://www.semanticscholar.org/paper/0b1f913c71c9eebffad728a53f8ccac0f226b9f4\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46793780\",\"name\":\"Ximeng Sun\"},{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"99cd8f9920ba94ec9d85517f4975e1c4bee3c60a\",\"title\":\"A Two-Stream Variational Adversarial Network for Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/99cd8f9920ba94ec9d85517f4975e1c4bee3c60a\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144462304\",\"name\":\"George Bebis\"},{\"authorId\":\"67054063\",\"name\":\"Richard Boyle\"},{\"authorId\":\"144946888\",\"name\":\"B. Parvin\"},{\"authorId\":\"1766575\",\"name\":\"Darko Koracin\"},{\"authorId\":\"1811543\",\"name\":\"Daniela Ushizima\"},{\"authorId\":\"144360273\",\"name\":\"Sek Chai\"},{\"authorId\":\"35315389\",\"name\":\"Shinjiro Sueda\"},{\"authorId\":\"145122731\",\"name\":\"Xin Lin\"},{\"authorId\":\"48272564\",\"name\":\"Ai-dong Lu\"},{\"authorId\":\"143725529\",\"name\":\"Daniel Thalmann\"},{\"authorId\":\"40505818\",\"name\":\"Chaoli Wang\"},{\"authorId\":\"49080140\",\"name\":\"Panpan Xu\"}],\"doi\":\"10.1007/978-3-030-33720-9\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b38d49795eb7b421123381b92509527b48941143\",\"title\":\"Advances in Visual Computing: 14th International Symposium on Visual Computing, ISVC 2019, Lake Tahoe, NV, USA, October 7\\u20139, 2019, Proceedings, Part I\",\"url\":\"https://www.semanticscholar.org/paper/b38d49795eb7b421123381b92509527b48941143\",\"venue\":\"ISVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11485621\",\"name\":\"Cyrille Beaudry\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d52edd32144eb9a14b635a5f612cc063d9129a20\",\"title\":\"Analyse et reconnaissance de s\\u00e9quences vid\\u00e9os d'activit\\u00e9s humaines dans l'espace s\\u00e9mantique. (Analysis and recognition of human activities in video sequences in the semantic space)\",\"url\":\"https://www.semanticscholar.org/paper/d52edd32144eb9a14b635a5f612cc063d9129a20\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145929374\",\"name\":\"Xue Bai\"},{\"authorId\":\"3150525\",\"name\":\"Enqing Chen\"},{\"authorId\":\"74806144\",\"name\":\"Haron Chweya Tinega\"}],\"doi\":\"10.1117/12.2540268\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"678b7077b11c3381080b3ecb59c851240ea4cd7c\",\"title\":\"Real-time action recognition based on enhanced motion vector temporal segment network\",\"url\":\"https://www.semanticscholar.org/paper/678b7077b11c3381080b3ecb59c851240ea4cd7c\",\"venue\":\"International Conference on Digital Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"144954807\",\"name\":\"Q. Dai\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"143977389\",\"name\":\"C. Ngo\"}],\"doi\":\"10.1007/978-3-642-33715-4_31\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b071b910f8dc0c64c26730da144cddbedc29ed07\",\"title\":\"Trajectory-Based Modeling of Human Actions with Motion Reference Points\",\"url\":\"https://www.semanticscholar.org/paper/b071b910f8dc0c64c26730da144cddbedc29ed07\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2356016\",\"name\":\"Minh Hoai\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/978-3-319-16814-2_1\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"52e0c03dd661d032865dfedd91ca49542ccfc2a3\",\"title\":\"Improving Human Action Recognition Using Score Distribution and Ranking\",\"url\":\"https://www.semanticscholar.org/paper/52e0c03dd661d032865dfedd91ca49542ccfc2a3\",\"venue\":\"ACCV\",\"year\":2014},{\"arxivId\":\"1410.5861\",\"authors\":[{\"authorId\":\"144418348\",\"name\":\"R. Xu\"},{\"authorId\":\"48390827\",\"name\":\"G. Chen\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"50504401\",\"name\":\"Wei Chen\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"41aa8c1c90d74f2653ef4b3a2e02ac473af61e47\",\"title\":\"Compositional Structure Learning for Action Understanding\",\"url\":\"https://www.semanticscholar.org/paper/41aa8c1c90d74f2653ef4b3a2e02ac473af61e47\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1639344722\",\"name\":\"Junqing Miao\"},{\"authorId\":\"1791880\",\"name\":\"Hailun Xia\"},{\"authorId\":\"7801828\",\"name\":\"Zhimin Zeng\"}],\"doi\":\"10.1109/ICCC47050.2019.9064443\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"3c6f5ee9b64bf6bd7557193665bc38b3e9a0ac1f\",\"title\":\"Exploiting Pose Mask Features For Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3c6f5ee9b64bf6bd7557193665bc38b3e9a0ac1f\",\"venue\":\"2019 IEEE 5th International Conference on Computer and Communications (ICCC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":\"10.1109/CVPR.2016.339\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d9671ec394ec374021702642713aa634b8556312\",\"title\":\"Harnessing Object and Scene Semantics for Large-Scale Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/d9671ec394ec374021702642713aa634b8556312\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2822935\",\"name\":\"Alhabib Abbas\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"38b217f438697476c3fbffd3f1595c17fd05ee89\",\"title\":\"Adapting computer vision models to limitations on input dimensionality and model complexity\",\"url\":\"https://www.semanticscholar.org/paper/38b217f438697476c3fbffd3f1595c17fd05ee89\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2897426\",\"name\":\"Saeid Motiian\"},{\"authorId\":\"1729086\",\"name\":\"Marco Piccirilli\"},{\"authorId\":\"145358382\",\"name\":\"D. Adjeroh\"},{\"authorId\":\"1736352\",\"name\":\"Gianfranco Doretto\"}],\"doi\":\"10.1109/CVPR.2016.166\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3f8b082c10561edd3ffc5d67a3d675cfdff6d94c\",\"title\":\"Information Bottleneck Learning Using Privileged Information for Visual Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3f8b082c10561edd3ffc5d67a3d675cfdff6d94c\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"2004.02205\",\"authors\":[{\"authorId\":\"145878079\",\"name\":\"Vivek Sharma\"},{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"49157259\",\"name\":\"R. Stiefelhagen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e908719ae2a09e3726300df65bcd31dfddea5a86\",\"title\":\"Deep Multimodal Feature Encoding for Video Ordering\",\"url\":\"https://www.semanticscholar.org/paper/e908719ae2a09e3726300df65bcd31dfddea5a86\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144082425\",\"name\":\"L. Shao\"},{\"authorId\":\"40241836\",\"name\":\"L. Liu\"},{\"authorId\":\"9452165\",\"name\":\"Mengyang Yu\"}],\"doi\":\"10.1007/s11263-015-0861-6\",\"intent\":[\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"aa8d1dd2d858c14235bdccd48f21d1ecc5e132df\",\"title\":\"Kernelized Multiview Projection for Robust Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/aa8d1dd2d858c14235bdccd48f21d1ecc5e132df\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3104603\",\"name\":\"J. Wu\"},{\"authorId\":\"46570618\",\"name\":\"D. Hu\"},{\"authorId\":null,\"name\":\"Fanglin Chen\"}],\"doi\":\"10.1007/s00371-013-0899-9\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"96826dfb56dac5ca8a764d22bd181d6f61a73339\",\"title\":\"Action recognition by hidden temporal models\",\"url\":\"https://www.semanticscholar.org/paper/96826dfb56dac5ca8a764d22bd181d6f61a73339\",\"venue\":\"The Visual Computer\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":\"10.1007/s11263-016-0905-6\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b0c8c8f7c84917765c472e14489414d330938c0f\",\"title\":\"EXMOVES: Mid-level Features for Efficient Action Recognition and Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/b0c8c8f7c84917765c472e14489414d330938c0f\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46507535\",\"name\":\"T. S. Murray\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f95557a3ae5c45c1ef282ed8d0711033d86c2172\",\"title\":\"Human Action Recognition from Active Acoustics: Physics Modelling for Representation Learning and Inference Using Generative Probabilistic Graphical Models\",\"url\":\"https://www.semanticscholar.org/paper/f95557a3ae5c45c1ef282ed8d0711033d86c2172\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"69458617\",\"name\":\"Albert Clap\\u00e9s i Sintes\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9a00c447f626be388bb402faeac3653d8555785e\",\"title\":\"Learning to recognize human actions: from hand-crafted to deep-learning based visual representations\",\"url\":\"https://www.semanticscholar.org/paper/9a00c447f626be388bb402faeac3653d8555785e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1906.05743\",\"authors\":[{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"9943923\",\"name\":\"Fabien Baradel\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f259bc7ef31c4ec7dd041c94bfd6b2f93b99b47c\",\"title\":\"Contrastive Bidirectional Transformer for Temporal Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/f259bc7ef31c4ec7dd041c94bfd6b2f93b99b47c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1812.01289\",\"authors\":[{\"authorId\":\"13142264\",\"name\":\"Noureldien Hussein\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"144638781\",\"name\":\"A. Smeulders\"}],\"doi\":\"10.1109/CVPR.2019.00034\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"50fec8e60b63e355241f153d6f5c17d4116b2a9e\",\"title\":\"Timeception for Complex Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/50fec8e60b63e355241f153d6f5c17d4116b2a9e\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152153140\",\"name\":\"Xiuping Bao\"},{\"authorId\":\"49706674\",\"name\":\"J. Yuan\"},{\"authorId\":null,\"name\":\"Bei Chen\"}],\"doi\":\"10.1109/ICTAI.2019.00089\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"60de1895702532f93b93b616d7a47096dfd1dc6c\",\"title\":\"ECPNet: An Efficient Attention-Based Convolution Network with Pseudo-3D Block for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/60de1895702532f93b93b616d7a47096dfd1dc6c\",\"venue\":\"2019 IEEE 31st International Conference on Tools with Artificial Intelligence (ICTAI)\",\"year\":2019},{\"arxivId\":\"1608.04339\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"}],\"doi\":\"10.1007/978-3-319-46604-0_47\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"9abd35b37a49ee1295e8197aac59bde802a934f3\",\"title\":\"Depth2Action: Exploring Embedded Depth for Large-Scale Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9abd35b37a49ee1295e8197aac59bde802a934f3\",\"venue\":\"ECCV Workshops\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4247049\",\"name\":\"Jingyu Liu\"},{\"authorId\":\"145501833\",\"name\":\"Y. Huang\"},{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":null,\"name\":\"Liang Wang\"}],\"doi\":\"10.1109/ICIP.2015.7350908\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"da3b924919f4eaf2c4638b5c7691515978091dda\",\"title\":\"Multi-view descriptor mining via codeword net for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/da3b924919f4eaf2c4638b5c7691515978091dda\",\"venue\":\"2015 IEEE International Conference on Image Processing (ICIP)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9764377\",\"name\":\"Xuanhan Wang\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1109/LSP.2016.2611485\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4d972b4b6d2eae0bc810225dc3fd3b89e861dd56\",\"title\":\"Beyond Frame-level CNN: Saliency-Aware 3-D CNN With LSTM for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4d972b4b6d2eae0bc810225dc3fd3b89e861dd56\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2051165\",\"name\":\"Haocheng Shen\"},{\"authorId\":\"144419120\",\"name\":\"J. Zhang\"},{\"authorId\":\"48213361\",\"name\":\"Hui Bin Zhang\"}],\"doi\":\"10.1007/978-3-319-16181-5_2\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ee1a88a92bc07dde1fc066351f16642a35799ea2\",\"title\":\"Human Action Recognition by Random Features and Hand-Crafted Features: A Comparative Study\",\"url\":\"https://www.semanticscholar.org/paper/ee1a88a92bc07dde1fc066351f16642a35799ea2\",\"venue\":\"ECCV Workshops\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51046192\",\"name\":\"Yixiong Zou\"},{\"authorId\":\"3040136\",\"name\":\"Yemin Shi\"},{\"authorId\":\"1576036690\",\"name\":\"Daochen Shi\"},{\"authorId\":null,\"name\":\"Yaowei Wang\"},{\"authorId\":\"3342777\",\"name\":\"Yongsheng Liang\"},{\"authorId\":\"144051792\",\"name\":\"Yonghong Tian\"}],\"doi\":\"10.1109/TMM.2020.2972128\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"94ebd897b1be9b15b547cff41a3aff2efbca2854\",\"title\":\"Adaptation-Oriented Feature Projection for One-Shot Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/94ebd897b1be9b15b547cff41a3aff2efbca2854\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72208574\",\"name\":\"J. Gao\"},{\"authorId\":\"152602127\",\"name\":\"Tianzhu Zhang\"},{\"authorId\":\"145194969\",\"name\":\"C. Xu\"}],\"doi\":\"10.1609/AAAI.V33I01.33018303\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3cf367c96ea895473a26c580b4f1dfd168bd8c2c\",\"title\":\"I Know the Relationships: Zero-Shot Action Recognition via Two-Stream Graph Convolutional Networks and Knowledge Graphs\",\"url\":\"https://www.semanticscholar.org/paper/3cf367c96ea895473a26c580b4f1dfd168bd8c2c\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1564581635\",\"name\":\"Bassel S. Chawkv\"},{\"authorId\":\"37370786\",\"name\":\"Mohammed Marey\"},{\"authorId\":\"2382767\",\"name\":\"H. A. Shedeed\"}],\"doi\":\"10.1109/ICICIS46948.2019.9014841\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d28a487e0bf59d1f9bf0b27799ff0fbeb699a2e2\",\"title\":\"OA18: A New Office Actions Benchmark\",\"url\":\"https://www.semanticscholar.org/paper/d28a487e0bf59d1f9bf0b27799ff0fbeb699a2e2\",\"venue\":\"2019 Ninth International Conference on Intelligent Computing and Information Systems (ICICIS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145382418\",\"name\":\"P. Narayana\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a2cfa3c1ba5b607b3d1136beda4f5127f82a73a9\",\"title\":\"Improving gesture recognition through spatial focus of attention\",\"url\":\"https://www.semanticscholar.org/paper/a2cfa3c1ba5b607b3d1136beda4f5127f82a73a9\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27648874\",\"name\":\"Changmao Cheng\"},{\"authorId\":\"2832147\",\"name\":\"C. Zhang\"},{\"authorId\":\"1732264\",\"name\":\"Y. Wei\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1145/3343031.3351054\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"9f18e562481538493d71d7b36eb12270f03d6339\",\"title\":\"Sparse Temporal Causal Convolution for Efficient Action Modeling\",\"url\":\"https://www.semanticscholar.org/paper/9f18e562481538493d71d7b36eb12270f03d6339\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1905.04225\",\"authors\":[{\"authorId\":\"41022447\",\"name\":\"Okan K\\u00f6p\\u00fckl\\u00fc\"},{\"authorId\":\"145872624\",\"name\":\"Yao Rong\"},{\"authorId\":\"145512909\",\"name\":\"G. Rigoll\"}],\"doi\":\"10.1109/ICCVW.2019.00345\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3a4787b4123d0928e08ec79412e2626d9e3adbea\",\"title\":\"Talking With Your Hands: Scaling Hand Gestures and Recognition With CNNs\",\"url\":\"https://www.semanticscholar.org/paper/3a4787b4123d0928e08ec79412e2626d9e3adbea\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1909.05165\",\"authors\":[{\"authorId\":\"41022447\",\"name\":\"Okan K\\u00f6p\\u00fckl\\u00fc\"},{\"authorId\":\"32240536\",\"name\":\"Fabian Herzog\"},{\"authorId\":\"145512909\",\"name\":\"G. Rigoll\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"6dbf4b5b49ccfa082a3b3c8a3d42713784d3ef1b\",\"title\":\"Comparative Analysis of CNN-based Spatiotemporal Reasoning in Videos\",\"url\":\"https://www.semanticscholar.org/paper/6dbf4b5b49ccfa082a3b3c8a3d42713784d3ef1b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11964267\",\"name\":\"Tingwei Wang\"},{\"authorId\":\"1703445\",\"name\":\"Chuancai Liu\"},{\"authorId\":\"2452789\",\"name\":\"L. Wang\"},{\"authorId\":\"2095855\",\"name\":\"B. Ma\"},{\"authorId\":\"1859062\",\"name\":\"Xingjian Gu\"}],\"doi\":\"10.1016/j.jvcir.2018.08.014\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6bb7e36612564868a7c880f8bd968250a1f3b40e\",\"title\":\"Evolution modeling with multi-scale smoothing for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/6bb7e36612564868a7c880f8bd968250a1f3b40e\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1695223\",\"name\":\"L. Wang\"},{\"authorId\":\"1692389\",\"name\":\"H. Sahbi\"}],\"doi\":\"10.1109/ICIP.2014.7025310\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bcead1a92744e76c38caaa13159de4abfb81b1d0\",\"title\":\"Bags-of-daglets for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/bcead1a92744e76c38caaa13159de4abfb81b1d0\",\"venue\":\"2014 IEEE International Conference on Image Processing (ICIP)\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1669427929\",\"name\":\"Lichao Yang\"},{\"authorId\":\"48365715\",\"name\":\"Ting-Yu Yang\"},{\"authorId\":null,\"name\":\"Haochen Liu\"},{\"authorId\":\"145409056\",\"name\":\"Xiaocai Shan\"},{\"authorId\":\"13275978\",\"name\":\"J. Brighton\"},{\"authorId\":\"2540001\",\"name\":\"L. Skrypchuk\"},{\"authorId\":\"78767836\",\"name\":\"Alexandros\"},{\"authorId\":\"2006650326\",\"name\":\"Mouzakitis\"},{\"authorId\":\"151469503\",\"name\":\"Yifan Zhao\"}],\"doi\":\"10.1109/jsen.2020.3005810\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b61bf86f7267f547896db1e3e42ba71e4796b919\",\"title\":\"A refined non-driving activity classification using a two-stream convolutional neural network\",\"url\":\"https://www.semanticscholar.org/paper/b61bf86f7267f547896db1e3e42ba71e4796b919\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51432978\",\"name\":\"Zhongke Liao\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"},{\"authorId\":\"1604959773\",\"name\":\"Yichu Liu\"}],\"doi\":\"10.1007/s11063-019-10091-z\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cace91ba53e05f6a5648f63b60bb657ec42764eb\",\"title\":\"Action Recognition with Multiple Relative Descriptors of Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/cace91ba53e05f6a5648f63b60bb657ec42764eb\",\"venue\":\"Neural Processing Letters\",\"year\":2019},{\"arxivId\":\"1905.12462\",\"authors\":[{\"authorId\":\"1756362\",\"name\":\"Swathikiran Sudhakaran\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"adec3b5b4ebccbdacdcd0c805f7c73501852b3cd\",\"title\":\"Hierarchical Feature Aggregation Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/adec3b5b4ebccbdacdcd0c805f7c73501852b3cd\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72557716\",\"name\":\"Song Liu\"},{\"authorId\":\"1709381241\",\"name\":\"Qiaolin He\"},{\"authorId\":\"48708884\",\"name\":\"Z. Wang\"},{\"authorId\":\"153005923\",\"name\":\"Y. Pu\"},{\"authorId\":\"4763857\",\"name\":\"Y. Zhang\"}],\"doi\":\"10.1109/ICCCBDA49378.2020.9095594\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2f1cb50a5ff56f95e43b1fcc3dffe1907e0523d5\",\"title\":\"Irregular Action Recognition in Court with 3D Residual Network\",\"url\":\"https://www.semanticscholar.org/paper/2f1cb50a5ff56f95e43b1fcc3dffe1907e0523d5\",\"venue\":\"2020 IEEE 5th International Conference on Cloud Computing and Big Data Analytics (ICCCBDA)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145839689\",\"name\":\"S. Jones\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"}],\"doi\":\"10.1109/WACV.2014.6836019\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7ec727b0ace1e5344c762e8a57ae7bf2a19f4cc8\",\"title\":\"Linear regression motion analysis for unsupervised temporal segmentation of human actions\",\"url\":\"https://www.semanticscholar.org/paper/7ec727b0ace1e5344c762e8a57ae7bf2a19f4cc8\",\"venue\":\"IEEE Winter Conference on Applications of Computer Vision\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1877834352\",\"name\":\"Sukrit Bhattacharya\"},{\"authorId\":\"1877778893\",\"name\":\"Vaibhav Shaw\"},{\"authorId\":\"143730686\",\"name\":\"P. Singh\"},{\"authorId\":\"70680168\",\"name\":\"R. Sarkar\"},{\"authorId\":\"89542097\",\"name\":\"D. Bhattacharjee\"}],\"doi\":\"10.1007/978-3-030-49345-5_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ae92267620dcebcc38ffb1258344ab8dd21fa635\",\"title\":\"SV-NET: A Deep Learning Approach to Video Based Human Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ae92267620dcebcc38ffb1258344ab8dd21fa635\",\"venue\":\"SoCPaR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152506137\",\"name\":\"F. Zhu\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"},{\"authorId\":\"49763212\",\"name\":\"J. Tang\"}],\"doi\":\"10.5244/C.28.5\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"98abb7cd3f7cc4027a5188784c176fa50d4d41b1\",\"title\":\"Boosted Cross-Domain Categorization\",\"url\":\"https://www.semanticscholar.org/paper/98abb7cd3f7cc4027a5188784c176fa50d4d41b1\",\"venue\":\"BMVC\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2868174\",\"name\":\"Yudong Tao\"},{\"authorId\":\"46958420\",\"name\":\"Tianyi Wang\"},{\"authorId\":\"143926721\",\"name\":\"D. Machado\"},{\"authorId\":\"1697878\",\"name\":\"R. Garc\\u00eda\"},{\"authorId\":\"22994542\",\"name\":\"Yuexuan Tu\"},{\"authorId\":\"39611894\",\"name\":\"Maria E. Presa-Reyes\"},{\"authorId\":\"50580583\",\"name\":\"Yeda Chen\"},{\"authorId\":\"2229900\",\"name\":\"Haiman Tian\"},{\"authorId\":\"144987531\",\"name\":\"M. Shyu\"},{\"authorId\":\"145758552\",\"name\":\"S. Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"84809d1e4f88a82755226f9d278fe8da22fdaa68\",\"title\":\"Florida International University - University of Miami TRECVID 2018\",\"url\":\"https://www.semanticscholar.org/paper/84809d1e4f88a82755226f9d278fe8da22fdaa68\",\"venue\":\"TRECVID\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3493540\",\"name\":\"N. Kardaris\"},{\"authorId\":\"1738119\",\"name\":\"Vassilis Pitsikalis\"},{\"authorId\":\"145702264\",\"name\":\"E. Mavroudi\"},{\"authorId\":\"1750686\",\"name\":\"P. Maragos\"}],\"doi\":\"10.1109/ICIP.2016.7532922\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"242d48dd13979ea65ac0fcad4d02a49db7068d1e\",\"title\":\"Introducing temporal order of dominant visual word sub-sequences for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/242d48dd13979ea65ac0fcad4d02a49db7068d1e\",\"venue\":\"2016 IEEE International Conference on Image Processing (ICIP)\",\"year\":2016},{\"arxivId\":\"1905.05143\",\"authors\":[{\"authorId\":\"13142264\",\"name\":\"Noureldien Hussein\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"144638781\",\"name\":\"A. Smeulders\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d17bc4c3ffcf9e2ecebcae0f5f24f9ee8cc0dcf\",\"title\":\"VideoGraph: Recognizing Minutes-Long Human Activities in Videos\",\"url\":\"https://www.semanticscholar.org/paper/3d17bc4c3ffcf9e2ecebcae0f5f24f9ee8cc0dcf\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1905.00050\",\"authors\":[{\"authorId\":\"2502363\",\"name\":\"Gagan Kanojia\"},{\"authorId\":\"39440469\",\"name\":\"Sudhakar Kumawat\"},{\"authorId\":\"145853779\",\"name\":\"S. Raman\"}],\"doi\":\"10.1109/CVPRW.2019.00302\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ca721f0db5168097048fa19371ab1bdd92ff15ef\",\"title\":\"Attentive Spatio-Temporal Representation Learning for Diving Classification\",\"url\":\"https://www.semanticscholar.org/paper/ca721f0db5168097048fa19371ab1bdd92ff15ef\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"103827464\",\"name\":\"Sharath Chada\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"11e224c2694c5b20d4630a1da493cf3d65af36d8\",\"title\":\"Human Action Recognition in Videos Using Intermediate Matching Kernel\",\"url\":\"https://www.semanticscholar.org/paper/11e224c2694c5b20d4630a1da493cf3d65af36d8\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6544209\",\"name\":\"N. Kumaran\"},{\"authorId\":\"145577551\",\"name\":\"A. Vadivel\"},{\"authorId\":\"8565863\",\"name\":\"S. S. Kumar\"}],\"doi\":\"10.1007/s11042-017-5591-z\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"74377cf5eb4b86284bea4d7acd83c9e8cda455b9\",\"title\":\"Recognition of human actions using CNN-GWO: a novel modeling of CNN for enhancement of classification performance\",\"url\":\"https://www.semanticscholar.org/paper/74377cf5eb4b86284bea4d7acd83c9e8cda455b9\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2017},{\"arxivId\":\"1607.07429\",\"authors\":[{\"authorId\":\"34280810\",\"name\":\"Gunnar A. Sigurdsson\"},{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d0d5aa7f797113c825053f4c4fd3772dc3601139\",\"title\":\"Much Ado About Time: Exhaustive Annotation of Temporal Data\",\"url\":\"https://www.semanticscholar.org/paper/d0d5aa7f797113c825053f4c4fd3772dc3601139\",\"venue\":\"HCOMP\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1923065213\",\"name\":\"Qinghongya Shi\"},{\"authorId\":\"46702837\",\"name\":\"Hongbo Zhang\"},{\"authorId\":\"89616898\",\"name\":\"Haotian Ren\"},{\"authorId\":\"3721965\",\"name\":\"Ji-Xiang Du\"},{\"authorId\":\"48841342\",\"name\":\"Qing Lei\"}],\"doi\":\"10.1186/s13640-020-00519-1\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b76ca4e12247ed63f98b0c1949a4eb9105ec1407\",\"title\":\"Consistent constraint-based video-level learning for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/b76ca4e12247ed63f98b0c1949a4eb9105ec1407\",\"venue\":\"EURASIP J. Image Video Process.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51105591\",\"name\":\"D. Avola\"},{\"authorId\":\"77259716\",\"name\":\"M. Cascio\"},{\"authorId\":\"1729018\",\"name\":\"L. Cinque\"},{\"authorId\":\"144706031\",\"name\":\"G. Foresti\"},{\"authorId\":\"35404907\",\"name\":\"Cristiano Massaroni\"},{\"authorId\":\"51307157\",\"name\":\"E. Rodol\\u00e0\"}],\"doi\":\"10.1109/TMM.2019.2960588\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2e06db13b5d5bbffd2184a3540ed4aa6035ab315\",\"title\":\"2-D Skeleton-Based Action Recognition via Two-Branch Stacked LSTM-RNNs\",\"url\":\"https://www.semanticscholar.org/paper/2e06db13b5d5bbffd2184a3540ed4aa6035ab315\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35684998\",\"name\":\"Marco Wrzalik\"},{\"authorId\":\"1784981\",\"name\":\"D. Krechel\"}],\"doi\":\"10.1109/ICMLA.2017.00-59\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"197efbef17f92e5cb5076961b6cd9f59e88ffd9a\",\"title\":\"Human Action Recognition Using Optical Flow and Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/197efbef17f92e5cb5076961b6cd9f59e88ffd9a\",\"venue\":\"2017 16th IEEE International Conference on Machine Learning and Applications (ICMLA)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4322411\",\"name\":\"L. Li\"},{\"authorId\":\"33126875\",\"name\":\"Shuling Dai\"}],\"doi\":\"10.1007/s11042-016-3789-0\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"eb44e9bb3f0a8059634b5902955f1b8deb315ea9\",\"title\":\"Action recognition with spatio-temporal augmented descriptor and fusion method\",\"url\":\"https://www.semanticscholar.org/paper/eb44e9bb3f0a8059634b5902955f1b8deb315ea9\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390916430\",\"name\":\"Huan Liu\"},{\"authorId\":\"2817677\",\"name\":\"Qinghua Zheng\"},{\"authorId\":\"3326677\",\"name\":\"Minnan Luo\"},{\"authorId\":\"152193942\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"152299623\",\"name\":\"C. Yan\"},{\"authorId\":\"46518251\",\"name\":\"L. Yao\"}],\"doi\":\"10.1016/j.knosys.2020.106432\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6072b5407daf1db4871fa27bdac7f63407019091\",\"title\":\"Memory transformation networks for weakly supervised visual classification\",\"url\":\"https://www.semanticscholar.org/paper/6072b5407daf1db4871fa27bdac7f63407019091\",\"venue\":\"Knowl. Based Syst.\",\"year\":2020},{\"arxivId\":\"2005.03356\",\"authors\":[{\"authorId\":\"117172343\",\"name\":\"Seongho Choi\"},{\"authorId\":\"2943489\",\"name\":\"Kyoung-Woon On\"},{\"authorId\":\"15353659\",\"name\":\"Yu-Jung Heo\"},{\"authorId\":\"1679974562\",\"name\":\"Ahjeong Seo\"},{\"authorId\":\"1680054988\",\"name\":\"Youwon Jang\"},{\"authorId\":\"153311117\",\"name\":\"Seungchan Lee\"},{\"authorId\":\"1491775096\",\"name\":\"Minsu Lee\"},{\"authorId\":\"152705134\",\"name\":\"B. Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4d21241b930b005847cf4350294c61d6c29ccd9f\",\"title\":\"DramaQA: Character-Centered Video Story Understanding with Hierarchical QA\",\"url\":\"https://www.semanticscholar.org/paper/4d21241b930b005847cf4350294c61d6c29ccd9f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1811.08383\",\"authors\":[{\"authorId\":\"46698300\",\"name\":\"Ji Lin\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"143840275\",\"name\":\"Song Han\"}],\"doi\":\"10.1109/ICCV.2019.00718\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4bbfd46721c145852e443ae4aad35148b814bf91\",\"title\":\"TSM: Temporal Shift Module for Efficient Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/4bbfd46721c145852e443ae4aad35148b814bf91\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46382329\",\"name\":\"Hongyang Li\"},{\"authorId\":\"38373223\",\"name\":\"J. Chen\"},{\"authorId\":\"144328091\",\"name\":\"R. Hu\"},{\"authorId\":\"145684947\",\"name\":\"M. Yu\"},{\"authorId\":\"2983562\",\"name\":\"Huafeng Chen\"},{\"authorId\":\"2646978\",\"name\":\"Zengmin Xu\"}],\"doi\":\"10.1007/978-3-030-05716-9_30\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eed979bab2cb22ff105ba59ce674ac5f327f8ddc\",\"title\":\"Action Recognition Using Visual Attention with Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/eed979bab2cb22ff105ba59ce674ac5f327f8ddc\",\"venue\":\"MMM\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145476300\",\"name\":\"P. Zhdanov\"},{\"authorId\":\"143636123\",\"name\":\"A. Khan\"},{\"authorId\":\"2525887\",\"name\":\"A. R. Rivera\"},{\"authorId\":\"1803086\",\"name\":\"A. Khattak\"}],\"doi\":\"10.1109/IJCNN.2018.8489663\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"4c54fe61181045865d6834e2fe4376aeea1f9884\",\"title\":\"Improving Human Action Recognition through Hierarchical Neural Network Classifiers\",\"url\":\"https://www.semanticscholar.org/paper/4c54fe61181045865d6834e2fe4376aeea1f9884\",\"venue\":\"2018 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2018},{\"arxivId\":\"1711.03273\",\"authors\":[{\"authorId\":\"143753918\",\"name\":\"Y. Peng\"},{\"authorId\":\"3361463\",\"name\":\"Yunzhen Zhao\"},{\"authorId\":\"3239379\",\"name\":\"J. Zhang\"}],\"doi\":\"10.1109/TCSVT.2018.2808685\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d9bd1b670b1301b9f4d8c366479173fc7903a331\",\"title\":\"Two-Stream Collaborative Learning With Spatial-Temporal Attention for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/d9bd1b670b1301b9f4d8c366479173fc7903a331\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"70147929\",\"name\":\"H. Yang\"},{\"authorId\":\"18997752\",\"name\":\"Jun Zhang\"},{\"authorId\":\"2721485\",\"name\":\"Shuohao Li\"},{\"authorId\":\"3249639\",\"name\":\"Tingjin Luo\"}],\"doi\":\"10.3233/JIFS-18209\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c6d8c084b395804b68ffbec2724a91b1cf8e269b\",\"title\":\"Bi-direction hierarchical LSTM with spatial-temporal attention for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/c6d8c084b395804b68ffbec2724a91b1cf8e269b\",\"venue\":\"J. Intell. Fuzzy Syst.\",\"year\":2019},{\"arxivId\":\"1811.07059\",\"authors\":[{\"authorId\":\"3766266\",\"name\":\"Zexi Chen\"},{\"authorId\":\"145704184\",\"name\":\"B. Ramachandra\"},{\"authorId\":\"47353858\",\"name\":\"Tianfu Wu\"},{\"authorId\":\"3001600\",\"name\":\"Ranga Raju Vatsavai\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"7b0fe0bc433d894299e249d97ed894671c3748b1\",\"title\":\"Relational Long Short-Term Memory for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7b0fe0bc433d894299e249d97ed894671c3748b1\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1705.08764\",\"authors\":[{\"authorId\":\"144248119\",\"name\":\"Minju Jung\"},{\"authorId\":\"3374519\",\"name\":\"H. Lee\"},{\"authorId\":\"1780524\",\"name\":\"J. Tani\"}],\"doi\":\"10.1016/j.neunet.2018.05.009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"abc78f7d8a0db343cf46622e3196b58a46a4fae2\",\"title\":\"Adaptive Detrending to Accelerate Convolutional Gated Recurrent Unit Training for Contextual Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/abc78f7d8a0db343cf46622e3196b58a46a4fae2\",\"venue\":\"Neural Networks\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1721505\",\"name\":\"Tenika P. Whytock\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"993b61ecdc93a917a86dcceb55d11c50ec7cd6c5\",\"title\":\"Covariate factor mitigation techniques for robust gait recognition\",\"url\":\"https://www.semanticscholar.org/paper/993b61ecdc93a917a86dcceb55d11c50ec7cd6c5\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"2006.04489\",\"authors\":[{\"authorId\":\"1650071598\",\"name\":\"Ahmed Mazari\"},{\"authorId\":\"1692389\",\"name\":\"H. Sahbi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fe7915ca11fda06d678933e2f51ad26e4ce2c661\",\"title\":\"Action Recognition with Deep Multiple Aggregation Networks\",\"url\":\"https://www.semanticscholar.org/paper/fe7915ca11fda06d678933e2f51ad26e4ce2c661\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1909.03580\",\"authors\":[{\"authorId\":\"66438699\",\"name\":\"Yucai Bai\"},{\"authorId\":\"153740190\",\"name\":\"Giang Dai\"},{\"authorId\":null,\"name\":\"Long Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1132b5161dc26ccefeb7187a35251df9f7d0ba3f\",\"title\":\"Extreme Low Resolution Activity Recognition with Spatial-Temporal Attention Transfer\",\"url\":\"https://www.semanticscholar.org/paper/1132b5161dc26ccefeb7187a35251df9f7d0ba3f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145674667\",\"name\":\"J. Miao\"},{\"authorId\":\"9303726\",\"name\":\"Xiangmin Xu\"},{\"authorId\":\"1715790\",\"name\":\"Reji Mathew\"},{\"authorId\":\"2926087\",\"name\":\"H. Huang\"}],\"doi\":\"10.1109/ICIP.2015.7351318\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e546572f8205570de4518bcf8d0345465e51d7a0\",\"title\":\"Residue boundary histograms for action recognition in the compressed domain\",\"url\":\"https://www.semanticscholar.org/paper/e546572f8205570de4518bcf8d0345465e51d7a0\",\"venue\":\"2015 IEEE International Conference on Image Processing (ICIP)\",\"year\":2015},{\"arxivId\":\"1705.00754\",\"authors\":[{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"1382195702\",\"name\":\"Kenji Hata\"},{\"authorId\":\"3260219\",\"name\":\"F. Ren\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/ICCV.2017.83\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"96dd1fc39a368d23291816d57763bc6eb4f7b8d6\",\"title\":\"Dense-Captioning Events in Videos\",\"url\":\"https://www.semanticscholar.org/paper/96dd1fc39a368d23291816d57763bc6eb4f7b8d6\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1711.01467\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"90bb40d96fcd16129eb85ce5dc4ee3b2380d74c8\",\"title\":\"Attentional Pooling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/90bb40d96fcd16129eb85ce5dc4ee3b2380d74c8\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":\"10.1109/CVPR.2017.787\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"265cd694e8886a7f8413dd334662f269c6ac2bfc\",\"title\":\"Spatiotemporal Multiplier Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/265cd694e8886a7f8413dd334662f269c6ac2bfc\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1601.02098\",\"authors\":[{\"authorId\":\"49110624\",\"name\":\"Qingjun Wang\"},{\"authorId\":\"2166468\",\"name\":\"Haiyan Lv\"},{\"authorId\":\"46908419\",\"name\":\"J. Yue\"},{\"authorId\":\"46667426\",\"name\":\"Eugene Mitchell\"}],\"doi\":\"10.1007/s00521-016-2189-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b36a16a849aa73790ec7466bacbec8249b33b267\",\"title\":\"Supervised multiview learning based on simultaneous learning of multiview intact and single view classifier\",\"url\":\"https://www.semanticscholar.org/paper/b36a16a849aa73790ec7466bacbec8249b33b267\",\"venue\":\"Neural Computing and Applications\",\"year\":2016},{\"arxivId\":\"1710.06236\",\"authors\":[{\"authorId\":\"6873935\",\"name\":\"T. Lin\"},{\"authorId\":\"1758267\",\"name\":\"X. Zhao\"},{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"}],\"doi\":\"10.1145/3123266.3123343\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b4fdbe0c627eb374fa9f347157ae94c5a2fcad67\",\"title\":\"Single Shot Temporal Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/b4fdbe0c627eb374fa9f347157ae94c5a2fcad67\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1806773\",\"name\":\"I. Misra\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1007/978-3-319-46448-0_32\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d4e3616d0b27957c4107ae877dc0dd4504b69ab\",\"title\":\"Shuffle and Learn: Unsupervised Learning Using Temporal Order Verification\",\"url\":\"https://www.semanticscholar.org/paper/6d4e3616d0b27957c4107ae877dc0dd4504b69ab\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1607.08584\",\"authors\":[{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1007/978-3-319-46493-0_9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"18994755100686833b92c34af8ec1b35934e23d6\",\"title\":\"Connectionist Temporal Modeling for Weakly Supervised Action Labeling\",\"url\":\"https://www.semanticscholar.org/paper/18994755100686833b92c34af8ec1b35934e23d6\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152506137\",\"name\":\"F. Zhu\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"}],\"doi\":\"10.1007/s11263-014-0703-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"da4048cc2ca2c84fb09e5601d8201c2c2c74f170\",\"title\":\"Weakly-Supervised Cross-Domain Dictionary Learning for Visual Recognition\",\"url\":\"https://www.semanticscholar.org/paper/da4048cc2ca2c84fb09e5601d8201c2c2c74f170\",\"venue\":\"International Journal of Computer Vision\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33075854\",\"name\":\"J. Borges\"},{\"authorId\":\"144218238\",\"name\":\"Sandro F. Queiros\"},{\"authorId\":\"144036590\",\"name\":\"B. Oliveira\"},{\"authorId\":\"39162324\",\"name\":\"H. Torres\"},{\"authorId\":\"144415018\",\"name\":\"N. Rodrigues\"},{\"authorId\":\"144870071\",\"name\":\"V. Coelho\"},{\"authorId\":\"1899292\",\"name\":\"Johannes Pallauf\"},{\"authorId\":\"153874764\",\"name\":\"Jos\\u00e9 Henrique Brito\"},{\"authorId\":\"47755983\",\"name\":\"J. Mendes\"},{\"authorId\":\"152385234\",\"name\":\"Jaime C. Fonseca\"}],\"doi\":\"10.1007/s00138-020-01131-z\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f5c9fe04e6e279b0ab5e3459f8bae33c30867140\",\"title\":\"A system for the generation of in-car human body pose datasets\",\"url\":\"https://www.semanticscholar.org/paper/f5c9fe04e6e279b0ab5e3459f8bae33c30867140\",\"venue\":\"Mach. Vis. Appl.\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"18186434\",\"name\":\"Nudrat Nida\"},{\"authorId\":\"1697680\",\"name\":\"M. Yousaf\"},{\"authorId\":\"2809162\",\"name\":\"Aun Irtaza\"},{\"authorId\":\"1697856\",\"name\":\"S. Velastin\"},{\"authorId\":\"1697856\",\"name\":\"S. Velastin\"}],\"doi\":\"10.1155/2019/2474865\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"6d0b838b40a3fffdc4e796e16a69f2e8b3ed210b\",\"title\":\"Instructor Activity Recognition through Deep Spatiotemporal Features and Feedforward Extreme Learning Machines\",\"url\":\"https://www.semanticscholar.org/paper/6d0b838b40a3fffdc4e796e16a69f2e8b3ed210b\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144095614\",\"name\":\"A. Jalal\"},{\"authorId\":\"2042123418\",\"name\":\"Israr Akhtar\"},{\"authorId\":\"7826090\",\"name\":\"Kyoungmin Kim\"}],\"doi\":\"10.3390/su12239814\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"30d438a0564359d1343c49d826f0d04870ce2847\",\"title\":\"Human Posture Estimation and Sustainable Events Classification via Pseudo-2D Stick Model and K-ary Tree Hashing\",\"url\":\"https://www.semanticscholar.org/paper/30d438a0564359d1343c49d826f0d04870ce2847\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2007.10730\",\"authors\":[{\"authorId\":\"5641221\",\"name\":\"S. Jenni\"},{\"authorId\":\"41016678\",\"name\":\"Givi Meishvili\"},{\"authorId\":\"144707901\",\"name\":\"P. Favaro\"}],\"doi\":\"10.1007/978-3-030-58604-1_26\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"7657ceea5001eb500b4aa2f5e0a440828cde4764\",\"title\":\"Video Representation Learning by Recognizing Temporal Transformations\",\"url\":\"https://www.semanticscholar.org/paper/7657ceea5001eb500b4aa2f5e0a440828cde4764\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2011.00043\",\"authors\":[{\"authorId\":\"21518096\",\"name\":\"Zhengyuan Yang\"},{\"authorId\":\"48984081\",\"name\":\"A. Kay\"},{\"authorId\":\"66508219\",\"name\":\"Y. Li\"},{\"authorId\":\"5687436\",\"name\":\"W. Cross\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":null,\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"41595f75fd06219109f57c084b4c8eae1352b410\",\"title\":\"Pose-based Body Language Recognition for Emotion and Psychiatric Symptom Interpretation\",\"url\":\"https://www.semanticscholar.org/paper/41595f75fd06219109f57c084b4c8eae1352b410\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1845611487\",\"name\":\"L. Chen\"},{\"authorId\":null,\"name\":\"Liu Rui\"},{\"authorId\":null,\"name\":\"Zhou Dongsheng\"},{\"authorId\":null,\"name\":\"Xin Yang\"},{\"authorId\":null,\"name\":\"Qiang Zhang\"},{\"authorId\":null,\"name\":\"Wei Xiaopeng\"}],\"doi\":\"10.1007/978-3-030-63426-1_1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"62295aaed70cb1e3a40b732e7c92748258cb4ec0\",\"title\":\"ESENet: A Human Behavior Recognition Model Based on Extended Squeeze-and-Excitation Network\",\"url\":\"https://www.semanticscholar.org/paper/62295aaed70cb1e3a40b732e7c92748258cb4ec0\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3404403\",\"name\":\"Longteng Kong\"},{\"authorId\":\"145022824\",\"name\":\"D. Huang\"},{\"authorId\":\"145546921\",\"name\":\"J. Qin\"},{\"authorId\":\"40013375\",\"name\":\"Y. Wang\"}],\"doi\":\"10.1109/TCSVT.2019.2893318\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ef022983983d8b948ab27a686da4e76cf92d18b1\",\"title\":\"A Joint Framework for Athlete Tracking and Action Recognition in Sports Videos\",\"url\":\"https://www.semanticscholar.org/paper/ef022983983d8b948ab27a686da4e76cf92d18b1\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3050278\",\"name\":\"Q. Feng\"},{\"authorId\":\"3049217\",\"name\":\"Yicong Zhou\"}],\"doi\":\"10.1109/TCSVT.2016.2615459\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b96e6ea06311ded4c29f7bcfcaa58e68d448bb58\",\"title\":\"Kernel Regularized Data Uncertainty for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b96e6ea06311ded4c29f7bcfcaa58e68d448bb58\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2017},{\"arxivId\":\"2001.05661\",\"authors\":[{\"authorId\":\"143657833\",\"name\":\"Li Tao\"},{\"authorId\":\"1524733293\",\"name\":\"Xueting Wang\"},{\"authorId\":\"145572095\",\"name\":\"T. Yamasaki\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"18726788e8a74aed4420745fc420dddd3950e1c6\",\"title\":\"Rethinking Motion Representation: Residual Frames with 3D ConvNets for Better Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/18726788e8a74aed4420745fc420dddd3950e1c6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121339452\",\"name\":\"Y. Tian\"},{\"authorId\":\"1810382\",\"name\":\"Zhaohui Che\"},{\"authorId\":\"116279011\",\"name\":\"Wenbo Bao\"},{\"authorId\":\"1509899757\",\"name\":\"Guangtao Zhai\"},{\"authorId\":\"97709070\",\"name\":\"Z. Gao\"}],\"doi\":\"10.1007/978-3-030-58568-6_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"27568c821ab008facaa57dc4f99217a294e196c4\",\"title\":\"Self-supervised Motion Representation via Scattering Local Motion Cues\",\"url\":\"https://www.semanticscholar.org/paper/27568c821ab008facaa57dc4f99217a294e196c4\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.00394\",\"authors\":[{\"authorId\":\"1410307807\",\"name\":\"Yizhak Ben-Shabat\"},{\"authorId\":\"1490933487\",\"name\":\"Xin Yu\"},{\"authorId\":\"9120887\",\"name\":\"F. Saleh\"},{\"authorId\":\"145185576\",\"name\":\"Dylan Campbell\"},{\"authorId\":\"145112187\",\"name\":\"Cristian Rodriguez-Opazo\"},{\"authorId\":\"71200893\",\"name\":\"H. Li\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"947b868aa1c38940df280ebeb8077d4e729fb988\",\"title\":\"The IKEA ASM Dataset: Understanding People Assembling Furniture through Actions, Objects and Pose\",\"url\":\"https://www.semanticscholar.org/paper/947b868aa1c38940df280ebeb8077d4e729fb988\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.01524\",\"authors\":[{\"authorId\":\"1992946926\",\"name\":\"Youngeun Kim\"},{\"authorId\":\"3160154\",\"name\":\"Donghyeon Cho\"},{\"authorId\":\"9352814\",\"name\":\"Priyadarshini Panda\"},{\"authorId\":\"2487892\",\"name\":\"Sungeun Hong\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0289f8eebf253c942a2b8ee29a86471d6782159f\",\"title\":\"Progressive Domain Adaptation from a Source Pre-trained Model.\",\"url\":\"https://www.semanticscholar.org/paper/0289f8eebf253c942a2b8ee29a86471d6782159f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":\"145749204\",\"name\":\"Xiao Wu\"},{\"authorId\":\"143740449\",\"name\":\"Q. Peng\"},{\"authorId\":\"2689287\",\"name\":\"X. Qi\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"47909954\",\"name\":\"Yanhua Liu\"}],\"doi\":\"10.1145/2499788.2499795\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b2a90dfc4bb692214ed2ef086beaa86f71cd9b31\",\"title\":\"Exploring dense trajectory feature and encoding methods for human interaction recognition\",\"url\":\"https://www.semanticscholar.org/paper/b2a90dfc4bb692214ed2ef086beaa86f71cd9b31\",\"venue\":\"ICIMCS '13\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2820136\",\"name\":\"Yu-Wei Chao\"},{\"authorId\":\"50218076\",\"name\":\"Z. Wang\"},{\"authorId\":\"3390922\",\"name\":\"Yugeng He\"},{\"authorId\":\"3381089\",\"name\":\"J. Wang\"},{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"}],\"doi\":\"10.1109/ICCV.2015.122\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c0fa318f20ed622a3f28e424b8d98ff5f8ca41b5\",\"title\":\"HICO: A Benchmark for Recognizing Human-Object Interactions in Images\",\"url\":\"https://www.semanticscholar.org/paper/c0fa318f20ed622a3f28e424b8d98ff5f8ca41b5\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"102320235\",\"name\":\"Hao Yang\"},{\"authorId\":null,\"name\":\"Chunfeng Yuan\"},{\"authorId\":\"47059008\",\"name\":\"L. Zhang\"},{\"authorId\":\"2545705\",\"name\":\"Yunda Sun\"},{\"authorId\":\"48594951\",\"name\":\"Weiming Hu\"},{\"authorId\":\"144555237\",\"name\":\"S. Maybank\"}],\"doi\":\"10.1109/TIP.2020.2984904\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c900e452bdb47ed6083ce2651ac32afb211f9fc6\",\"title\":\"STA-CNN: Convolutional Spatial-Temporal Attention Learning for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c900e452bdb47ed6083ce2651ac32afb211f9fc6\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1506.01929\",\"authors\":[{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"1753355\",\"name\":\"Z. Harchaoui\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2015.362\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2f488a8139630e3b2499ea2d3ff192e33387f7de\",\"title\":\"Learning to Track for Spatio-Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/2f488a8139630e3b2499ea2d3ff192e33387f7de\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49763212\",\"name\":\"J. Tang\"},{\"authorId\":\"8769664\",\"name\":\"Haiqun Jin\"},{\"authorId\":\"1907978\",\"name\":\"Shoubiao Tan\"},{\"authorId\":\"145768551\",\"name\":\"D. Liang\"}],\"doi\":\"10.1016/j.imavis.2016.02.003\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ac1a321c7c1b699244c7d8c09fdb68fcee1a9ed3\",\"title\":\"Cross-domain action recognition via collective matrix factorization with graph Laplacian regularization\",\"url\":\"https://www.semanticscholar.org/paper/ac1a321c7c1b699244c7d8c09fdb68fcee1a9ed3\",\"venue\":\"Image Vis. Comput.\",\"year\":2016},{\"arxivId\":\"1603.08561\",\"authors\":[{\"authorId\":\"1806773\",\"name\":\"I. Misra\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e03e86ac61cfac9148b371d75ce81a55e8b332ca\",\"title\":\"Unsupervised Learning using Sequential Verification for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e03e86ac61cfac9148b371d75ce81a55e8b332ca\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1708.02696\",\"authors\":[{\"authorId\":\"34280810\",\"name\":\"Gunnar A. Sigurdsson\"},{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1109/ICCV.2017.235\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"45f858f9e8d7713f60f52618e54089ba68dfcd6d\",\"title\":\"What Actions are Needed for Understanding Human Actions in Videos?\",\"url\":\"https://www.semanticscholar.org/paper/45f858f9e8d7713f60f52618e54089ba68dfcd6d\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1701.03246\",\"authors\":[{\"authorId\":\"48094509\",\"name\":\"J. Wang\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"}],\"doi\":\"10.1109/WACV.2017.26\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2459859dfd2b1860659a87e7f9ad3a84a45f67e1\",\"title\":\"Ordered Pooling of Optical Flow Sequences for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2459859dfd2b1860659a87e7f9ad3a84a45f67e1\",\"venue\":\"2017 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3271933\",\"name\":\"M. Douze\"},{\"authorId\":\"3095774\",\"name\":\"Dan Oneata\"},{\"authorId\":\"2027089\",\"name\":\"Mattis Paulin\"},{\"authorId\":\"122400379\",\"name\":\"Clement Leray\"},{\"authorId\":\"21265854\",\"name\":\"N. Chesneau\"},{\"authorId\":\"2319574\",\"name\":\"D. Potapov\"},{\"authorId\":\"34602236\",\"name\":\"Jakob Verbeek\"},{\"authorId\":\"72492981\",\"name\":\"Alahari Karteek\"},{\"authorId\":\"113130084\",\"name\":\"Zaid Harchaoui\"},{\"authorId\":\"145204681\",\"name\":\"L. Lamel\"},{\"authorId\":\"1685010\",\"name\":\"J. Gauvain\"},{\"authorId\":\"50508239\",\"name\":\"C. Q. Schmidt\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e1b5bd7549a4104710151acd014d19afaa8866cf\",\"title\":\"The INRIA-LIM-VocR and AXES submissions to TrecVid 2014 Multimedia Event Detection\",\"url\":\"https://www.semanticscholar.org/paper/e1b5bd7549a4104710151acd014d19afaa8866cf\",\"venue\":\"TRECVID\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"70550541\",\"name\":\"Christopher J. Whiten\"}],\"doi\":\"10.20381/ruor-2912\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e74749447557ce147cceec228100b8fb685fbbb5\",\"title\":\"Probabilistic Shape Parsing and Action Recognition Through Binary Spatio-Temporal Feature Description\",\"url\":\"https://www.semanticscholar.org/paper/e74749447557ce147cceec228100b8fb685fbbb5\",\"venue\":\"\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2352432\",\"name\":\"H. Zhang\"},{\"authorId\":\"3372558\",\"name\":\"Chenxing Xia\"},{\"authorId\":\"4831929\",\"name\":\"Xiuju Gao\"}],\"doi\":\"10.1007/S11042-018-6622-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"20cc248585941445645d8b7f258fd7df495b3887\",\"title\":\"Action recognition based on multi-stage jointly training convolutional network\",\"url\":\"https://www.semanticscholar.org/paper/20cc248585941445645d8b7f258fd7df495b3887\",\"venue\":\"Multim. Tools Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145803109\",\"name\":\"Chu Luo\"},{\"authorId\":\"134909218\",\"name\":\"Zewen Xu\"},{\"authorId\":\"32609056\",\"name\":\"Ruining Dong\"},{\"authorId\":\"144769817\",\"name\":\"J. Gon\\u00e7alves\"},{\"authorId\":\"2520424\",\"name\":\"Eduardo Velloso\"},{\"authorId\":\"1781697\",\"name\":\"V. Kostakos\"}],\"doi\":\"10.1016/J.PMCJ.2019.04.001\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"93cecc9d40e39488da5c196cefb3f3d2bd11608f\",\"title\":\"CamTest: A laboratory testbed for camera-based mobile sensing applications\",\"url\":\"https://www.semanticscholar.org/paper/93cecc9d40e39488da5c196cefb3f3d2bd11608f\",\"venue\":\"Pervasive Mob. Comput.\",\"year\":2019},{\"arxivId\":\"1904.03498\",\"authors\":[{\"authorId\":\"39440469\",\"name\":\"Sudhakar Kumawat\"},{\"authorId\":\"145853779\",\"name\":\"S. Raman\"}],\"doi\":\"10.1109/CVPR.2019.00504\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"75544f83d38ef1686d70c763deb43305c5dc8a48\",\"title\":\"LP-3DCNN: Unveiling Local Phase in 3D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/75544f83d38ef1686d70c763deb43305c5dc8a48\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2845745\",\"name\":\"Sovan Biswas\"},{\"authorId\":\"144682140\",\"name\":\"R. Venkatesh Babu\"}],\"doi\":\"10.1109/ICASSP.2013.6638012\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5e0bf4cd7b0d22fd8fb8fd761d4a2755aea7b9b2\",\"title\":\"H.264 compressed video classification using Histogram of Oriented Motion Vectors (HOMV)\",\"url\":\"https://www.semanticscholar.org/paper/5e0bf4cd7b0d22fd8fb8fd761d4a2755aea7b9b2\",\"venue\":\"2013 IEEE International Conference on Acoustics, Speech and Signal Processing\",\"year\":2013},{\"arxivId\":\"1606.07373\",\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"1732879\",\"name\":\"Lorenzo Torresani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c69040777e2b0e1d443e22f86e45e527381d79e7\",\"title\":\"ViCom: Benchmark and Methods for Video Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/c69040777e2b0e1d443e22f86e45e527381d79e7\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1506.04714\",\"authors\":[{\"authorId\":\"144348441\",\"name\":\"Dinesh Jayaraman\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2016.418\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"32e6b6106ee2cc90126dcd8996d4a06374afe69b\",\"title\":\"Slow and Steady Feature Analysis: Higher Order Temporal Coherence in Video\",\"url\":\"https://www.semanticscholar.org/paper/32e6b6106ee2cc90126dcd8996d4a06374afe69b\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1704.08723\",\"authors\":[{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cb08f679f2cb29c7aa972d66fe9e9996c8dfae00\",\"title\":\"Action Understanding with Multiple Classes of Actors\",\"url\":\"https://www.semanticscholar.org/paper/cb08f679f2cb29c7aa972d66fe9e9996c8dfae00\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5964529\",\"name\":\"Xiaochen Lian\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a9f652787e5669168c7b8f632c3a343dfbaa6f4b\",\"title\":\"Mining Spatial and Spatio-Temporal ROIs for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a9f652787e5669168c7b8f632c3a343dfbaa6f4b\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5808321\",\"name\":\"Meng-Chieh Wu\"},{\"authorId\":\"145888908\",\"name\":\"Ching-Te Chiu\"},{\"authorId\":\"113011036\",\"name\":\"Kun-Hsuan Wu\"}],\"doi\":\"10.1109/ICASSP.2019.8682450\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"8cb847b8ff42194165bd3cc55368e8df15c992f7\",\"title\":\"Multi-teacher Knowledge Distillation for Compressed Video Action Recognition on Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/8cb847b8ff42194165bd3cc55368e8df15c992f7\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144907434\",\"name\":\"Takumi Kobayashi\"}],\"doi\":\"10.5244/C.30.98\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"66886f5af67b22d14177119520bd9c9f39cdd2e6\",\"title\":\"Learning Additive Kernel For Feature Transformation and Its Application to CNN Features\",\"url\":\"https://www.semanticscholar.org/paper/66886f5af67b22d14177119520bd9c9f39cdd2e6\",\"venue\":\"BMVC\",\"year\":2016},{\"arxivId\":\"2008.00975\",\"authors\":[{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"1591131960\",\"name\":\"Yiheng Zhang\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"1490772804\",\"name\":\"Tao Mei\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"7b4741f8e6667664f1b21c390830b2022eca2da0\",\"title\":\"SeCo: Exploring Sequence Supervision for Unsupervised Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/7b4741f8e6667664f1b21c390830b2022eca2da0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46630500\",\"name\":\"I. Alexiou\"},{\"authorId\":\"145406421\",\"name\":\"T. Xiang\"},{\"authorId\":\"144784813\",\"name\":\"S. Gong\"}],\"doi\":\"10.1109/ICIP.2016.7533149\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5800d5a7d3723e8fa89e8eefea62e627862ba911\",\"title\":\"Exploring synonyms as context in zero-shot action recognition\",\"url\":\"https://www.semanticscholar.org/paper/5800d5a7d3723e8fa89e8eefea62e627862ba911\",\"venue\":\"2016 IEEE International Conference on Image Processing (ICIP)\",\"year\":2016},{\"arxivId\":\"1805.02877\",\"authors\":[{\"authorId\":\"49417387\",\"name\":\"Y. Wang\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"49897466\",\"name\":\"Xiaotian Zhu\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7f511a6a2b38a26f077a5aec4baf5dffc981d881\",\"title\":\"Low-Latency Human Action Recognition with Weighted Multi-Region Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/7f511a6a2b38a26f077a5aec4baf5dffc981d881\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3429960\",\"name\":\"Youjiang Xu\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"2248826\",\"name\":\"R. Hong\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/TIP.2018.2846664\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7fe2ab9f54242ef8609ef9bf988f008c7d42407c\",\"title\":\"Sequential Video VLAD: Training the Aggregation Locally and Temporally\",\"url\":\"https://www.semanticscholar.org/paper/7fe2ab9f54242ef8609ef9bf988f008c7d42407c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144434220\",\"name\":\"X. Yang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4591e7cdca135824f97ebfae3755ab8a64da57e7\",\"title\":\"Feature Representations for Human Activity Recognition in Color and Depth Sequences\",\"url\":\"https://www.semanticscholar.org/paper/4591e7cdca135824f97ebfae3755ab8a64da57e7\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8303994\",\"name\":\"Honggang Xie\"},{\"authorId\":\"144033365\",\"name\":\"Jinsheng Xiao\"},{\"authorId\":\"3389703\",\"name\":\"Junfeng Lei\"},{\"authorId\":\"2268470\",\"name\":\"Wenjuan Xie\"},{\"authorId\":\"1729664\",\"name\":\"Reinhard Klette\"}],\"doi\":\"10.1007/978-981-15-3651-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"42636140273d2a8bdeed36df1cd4d8b56f62270c\",\"title\":\"Pattern Recognition: ACPR 2019 Workshops, Auckland, New Zealand, November 26, 2019, Proceedings\",\"url\":\"https://www.semanticscholar.org/paper/42636140273d2a8bdeed36df1cd4d8b56f62270c\",\"venue\":\"ACPR Workshops\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2871170\",\"name\":\"Huifen Xia\"},{\"authorId\":\"144754529\",\"name\":\"Yongzhao Zhan\"}],\"doi\":\"10.1109/ACCESS.2020.2986861\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6a73ed2d412f2f1a57e400c6f1722f69cf9fcd13\",\"title\":\"A Survey on Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/6a73ed2d412f2f1a57e400c6f1722f69cf9fcd13\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3302494\",\"name\":\"C. Chattopadhyay\"},{\"authorId\":\"144009889\",\"name\":\"Sukhendu Das\"}],\"doi\":\"10.1007/s11760-014-0744-2\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f99359761ece9f42e44e02ad659c170fb52bebe6\",\"title\":\"Use of trajectory and spatiotemporal features for retrieval of videos with a prominent moving foreground object\",\"url\":\"https://www.semanticscholar.org/paper/f99359761ece9f42e44e02ad659c170fb52bebe6\",\"venue\":\"Signal Image Video Process.\",\"year\":2016},{\"arxivId\":\"1910.09920\",\"authors\":[{\"authorId\":\"10007321\",\"name\":\"Farnoosh Heidarivincheh\"},{\"authorId\":\"1728108\",\"name\":\"M. Mirmehdi\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.1109/ICCVW.2019.00150\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"85accdf27ef03155d41f9740fed6044afb5dd5f6\",\"title\":\"Weakly-Supervised Completion Moment Detection using Temporal Attention\",\"url\":\"https://www.semanticscholar.org/paper/85accdf27ef03155d41f9740fed6044afb5dd5f6\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24735756\",\"name\":\"Zhengkui Weng\"},{\"authorId\":\"40641593\",\"name\":\"Y. Guan\"}],\"doi\":\"10.1186/s13640-018-0250-5\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"5923173a50c66e4344c915c1af216546968040d7\",\"title\":\"Action recognition using length-variable edge trajectory and spatio-temporal motion skeleton descriptor\",\"url\":\"https://www.semanticscholar.org/paper/5923173a50c66e4344c915c1af216546968040d7\",\"venue\":\"EURASIP J. Image Video Process.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410131672\",\"name\":\"Yang Mi\"},{\"authorId\":\"2244863\",\"name\":\"X. Zhang\"},{\"authorId\":\"48459086\",\"name\":\"Zhongguo Li\"},{\"authorId\":\"40696794\",\"name\":\"Song Wang\"}],\"doi\":\"10.1109/TIP.2020.2989864\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e099ed2b5389322c71cf693c59decbf08bb4c2d6\",\"title\":\"Dual-Branch Network With a Subtle Motion Detector for Microaction Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/e099ed2b5389322c71cf693c59decbf08bb4c2d6\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39453466\",\"name\":\"T. Zhang\"},{\"authorId\":\"46867148\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"1711097\",\"name\":\"A. Kot\"}],\"doi\":\"10.1109/ICASSP.2016.7472169\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b759936982d6fb25c55c98955f6955582bdaeb27\",\"title\":\"Efficient object feature selection for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/b759936982d6fb25c55c98955f6955582bdaeb27\",\"venue\":\"2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33481412\",\"name\":\"Pan Zhou\"},{\"authorId\":\"48935090\",\"name\":\"Chao Zhang\"},{\"authorId\":\"33383055\",\"name\":\"Zhouchen Lin\"}],\"doi\":\"10.1109/TIP.2016.2623487\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7fc24b91084700ebcb9f25f1307bf2a816d3edd9\",\"title\":\"Bilevel Model-Based Discriminative Dictionary Learning for Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7fc24b91084700ebcb9f25f1307bf2a816d3edd9\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2001082\",\"name\":\"Maryam Koohzadi\"},{\"authorId\":\"1755153\",\"name\":\"N. M. Charkari\"}],\"doi\":\"10.1049/iet-cvi.2016.0355\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c0ba4aa78802bb51daeb2264df2e11bf11ecfbbe\",\"title\":\"Survey on deep learning methods in human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/c0ba4aa78802bb51daeb2264df2e11bf11ecfbbe\",\"venue\":\"IET Comput. Vis.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46382329\",\"name\":\"Hongyang Li\"},{\"authorId\":\"38373223\",\"name\":\"J. Chen\"},{\"authorId\":\"37254976\",\"name\":\"RuiMin Hu\"}],\"doi\":\"10.1007/s11859-017-1219-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"84c4ab901ea11654d09648d79fb2b1d34a529cf8\",\"title\":\"Multiple feature fusion in convolutional neural networks for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/84c4ab901ea11654d09648d79fb2b1d34a529cf8\",\"venue\":\"Wuhan University Journal of Natural Sciences\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144692146\",\"name\":\"Ming Tong\"},{\"authorId\":\"27746265\",\"name\":\"Mengao Zhao\"},{\"authorId\":\"5442167\",\"name\":\"Yiran Chen\"},{\"authorId\":\"49527719\",\"name\":\"Houyi Wang\"}],\"doi\":\"10.1016/j.neucom.2018.09.086\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d98642db8d4fc5330190c7832b86e8bbf85b46ca\",\"title\":\"D3-LND: A two-stream framework with discriminant deep descriptor, linear CMDT and nonlinear KCMDT descriptors for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/d98642db8d4fc5330190c7832b86e8bbf85b46ca\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46651287\",\"name\":\"C. Li\"},{\"authorId\":\"2891860\",\"name\":\"Yue Ming\"}],\"doi\":\"10.1007/978-3-030-12177-8_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d7f93e107e81125397652c5d2ae4535c5344612\",\"title\":\"Three-Stream Convolution Networks After Background Subtraction for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/0d7f93e107e81125397652c5d2ae4535c5344612\",\"venue\":\"FFER/DLPR@ICPR\",\"year\":2018},{\"arxivId\":\"1712.04109\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"144752314\",\"name\":\"Bo Xiong\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2018.00622\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"89498817a49d9c349ec9f67375023ead0411b865\",\"title\":\"Im2Flow: Motion Hallucination from Static Images for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/89498817a49d9c349ec9f67375023ead0411b865\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41189343\",\"name\":\"A. E. Seghrouchni\"},{\"authorId\":\"1707363\",\"name\":\"D. Sarne\"},{\"authorId\":\"145960032\",\"name\":\"R. Goebel\"},{\"authorId\":\"144865865\",\"name\":\"Y. Tanaka\"}],\"doi\":\"10.1007/978-3-030-56150-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ccd6a93d74958ef8993f2b3102ccc4f913e33011\",\"title\":\"Artificial Intelligence. IJCAI 2019 International Workshops: Macao, China, August 10\\u201312, 2019, Revised Selected Best Papers\",\"url\":\"https://www.semanticscholar.org/paper/ccd6a93d74958ef8993f2b3102ccc4f913e33011\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40354734\",\"name\":\"Haoze Wu\"},{\"authorId\":\"48210950\",\"name\":\"Jiawei Liu\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"},{\"authorId\":\"6485172\",\"name\":\"Xiaoyan Sun\"}],\"doi\":\"10.24963/ijcai.2019/136\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"21526c9cb9ba45e4748fb9a967f51c9bd9c0bf16\",\"title\":\"Mutually Reinforced Spatio-Temporal Convolutional Tube for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/21526c9cb9ba45e4748fb9a967f51c9bd9c0bf16\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144015161\",\"name\":\"Y. Fu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"01aecbebc76d494853f6f525f4d285564e697fa7\",\"title\":\"Human Action Recognition and Prediction: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/01aecbebc76d494853f6f525f4d285564e697fa7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144436761\",\"name\":\"T. Hu\"},{\"authorId\":\"3328724\",\"name\":\"X. Zhu\"},{\"authorId\":\"143786201\",\"name\":\"W. Guo\"},{\"authorId\":\"3251134\",\"name\":\"Kehua Su\"}],\"doi\":\"10.1155/2013/795360\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d35c0f2a65fefed481a8fe4468b5572d88772c2e\",\"title\":\"Efficient Interaction Recognition through Positive Action Representation\",\"url\":\"https://www.semanticscholar.org/paper/d35c0f2a65fefed481a8fe4468b5572d88772c2e\",\"venue\":\"\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2700261\",\"name\":\"Y. Lee\"},{\"authorId\":\"73047525\",\"name\":\"J. Fiscus\"},{\"authorId\":\"1781968\",\"name\":\"A. Godil\"},{\"authorId\":\"123306611\",\"name\":\"A. Delgado\"},{\"authorId\":\"71289522\",\"name\":\"Jim Golden\"},{\"authorId\":\"1888300\",\"name\":\"Lukas Diduch\"},{\"authorId\":\"47983546\",\"name\":\"M. Hubert\"}],\"doi\":\"10.1109/WACVW50321.2020.9096926\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"def4f25a27d199981be51b88f28d5745cd9dad90\",\"title\":\"Summary of the 2019 Activity Detection in Extended Videos Prize Challenge\",\"url\":\"https://www.semanticscholar.org/paper/def4f25a27d199981be51b88f28d5745cd9dad90\",\"venue\":\"2020 IEEE Winter Applications of Computer Vision Workshops (WACVW)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"}],\"doi\":\"10.7916/D8-SRKZ-T696\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3ea5b4e02a448174cbc6872eaec27695b04e9b87\",\"title\":\"Deep Learning for Action Understanding in Video\",\"url\":\"https://www.semanticscholar.org/paper/3ea5b4e02a448174cbc6872eaec27695b04e9b87\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66471378\",\"name\":\"Allah Bux\"}],\"doi\":\"10.17635/LANCASTER/THESIS/186\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"12002e37fd9cf69a68c3c216c9ee78fcfac2fab5\",\"title\":\"Vision-based human action recognition using machine learning techniques\",\"url\":\"https://www.semanticscholar.org/paper/12002e37fd9cf69a68c3c216c9ee78fcfac2fab5\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"74437294\",\"name\":\"Sk. Arif Ahmed\"},{\"authorId\":\"3320759\",\"name\":\"D. P. Dogra\"},{\"authorId\":\"46817269\",\"name\":\"Samarjit Kar\"},{\"authorId\":\"40813600\",\"name\":\"P. Roy\"}],\"doi\":\"10.1109/TCSVT.2018.2857489\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7a609736cb7d92a668dbafde515b7ef9be19bf08\",\"title\":\"Trajectory-Based Surveillance Analysis: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/7a609736cb7d92a668dbafde515b7ef9be19bf08\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145143348\",\"name\":\"O. V. R. Murthy\"},{\"authorId\":\"1717204\",\"name\":\"R. Goecke\"}],\"doi\":\"10.1109/DICTA.2014.7008131\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3bd50e33220af76ffc32a7e57688e248843b7f25\",\"title\":\"The Influence of Temporal Information on Human Action Recognition with Large Number of Classes\",\"url\":\"https://www.semanticscholar.org/paper/3bd50e33220af76ffc32a7e57688e248843b7f25\",\"venue\":\"2014 International Conference on Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143937986\",\"name\":\"John See\"},{\"authorId\":\"12100407\",\"name\":\"S. Rahman\"}],\"doi\":\"10.1109/DICTA.2015.7371292\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"29940b5721c9584378a88707818b2114d06d6d41\",\"title\":\"On the Effects of Low Video Quality in Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/29940b5721c9584378a88707818b2114d06d6d41\",\"venue\":\"2015 International Conference on Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49210768\",\"name\":\"Ling Guan\"},{\"authorId\":\"145735014\",\"name\":\"L. Gao\"},{\"authorId\":\"1403961741\",\"name\":\"Nour El-Din El-Madany\"},{\"authorId\":\"3337292\",\"name\":\"Chengwu Liang\"}],\"doi\":\"10.1109/MIPR.2018.00059\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"60462b981fda63c5f9d780528a37c46884fe0b54\",\"title\":\"Statistical Machine Learning vs Deep Learning in Information Fusion: Competition or Collaboration?\",\"url\":\"https://www.semanticscholar.org/paper/60462b981fda63c5f9d780528a37c46884fe0b54\",\"venue\":\"2018 IEEE Conference on Multimedia Information Processing and Retrieval (MIPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12100407\",\"name\":\"S. Rahman\"},{\"authorId\":\"143937986\",\"name\":\"John See\"},{\"authorId\":\"2864328\",\"name\":\"Chiung Ching Ho\"}],\"doi\":\"10.1007/978-981-10-1721-6_26\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"6d0177bb1cd292a2ad4a14e7b9173fcc8b72569c\",\"title\":\"Leveraging textural features for recognizing actions in low quality videos\",\"url\":\"https://www.semanticscholar.org/paper/6d0177bb1cd292a2ad4a14e7b9173fcc8b72569c\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32774629\",\"name\":\"A. Richard\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.5244/C.29.57\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"67fa5ac0aeae6dbcf98c7039a2e11fbe494fe5f4\",\"title\":\"A BoW-equivalent Recurrent Neural Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/67fa5ac0aeae6dbcf98c7039a2e11fbe494fe5f4\",\"venue\":\"BMVC\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143611428\",\"name\":\"Z. Tu\"},{\"authorId\":\"47892850\",\"name\":\"H. Li\"},{\"authorId\":\"2581829\",\"name\":\"Dejun Zhang\"},{\"authorId\":\"1681843\",\"name\":\"J. Dauwels\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1109/TIP.2018.2890749\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"de58df0ceb2741e33e996322a8422aa06442d150\",\"title\":\"Action-Stage Emphasized Spatiotemporal VLAD for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/de58df0ceb2741e33e996322a8422aa06442d150\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41155786\",\"name\":\"Silvia Vinyes Mora\"},{\"authorId\":\"1786779\",\"name\":\"W. Knottenbelt\"}],\"doi\":\"10.1109/CVPRW.2017.27\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"06e872e1de44e5bd4ec546401ff4f06d6826e032\",\"title\":\"Deep Learning for Domain-Specific Action Recognition in Tennis\",\"url\":\"https://www.semanticscholar.org/paper/06e872e1de44e5bd4ec546401ff4f06d6826e032\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":\"2004.04968\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"1628244042\",\"name\":\"Tenga Wakamiya\"},{\"authorId\":\"2199251\",\"name\":\"K. Hara\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"4b1ca549b3378ff8ae52db1528f9f7402544cfd7\",\"title\":\"Would Mega-scale Datasets Further Enhance Spatiotemporal 3D CNNs?\",\"url\":\"https://www.semanticscholar.org/paper/4b1ca549b3378ff8ae52db1528f9f7402544cfd7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2235260\",\"name\":\"Q. Chen\"},{\"authorId\":\"34853917\",\"name\":\"Y. Zhang\"}],\"doi\":\"10.1109/LSP.2017.2689921\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2e5b160892b70a1e846aa9dcdf132b8011937ec6\",\"title\":\"Sequential Segment Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2e5b160892b70a1e846aa9dcdf132b8011937ec6\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48799346\",\"name\":\"W. Chang\"},{\"authorId\":\"2395047\",\"name\":\"C. Ye\"},{\"authorId\":\"1725354018\",\"name\":\"Hui Zhou\"}],\"doi\":\"10.1007/978-3-030-50347-5_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"43c49aaee9a83a41e6950add3dc32371f6ef1462\",\"title\":\"Two-Stream Framework for Activity Recognition with 2D Human Pose Estimation\",\"url\":\"https://www.semanticscholar.org/paper/43c49aaee9a83a41e6950add3dc32371f6ef1462\",\"venue\":\"ICIAR\",\"year\":2020},{\"arxivId\":\"1912.04462\",\"authors\":[{\"authorId\":\"3264239\",\"name\":\"Shi-Yuan Huang\"},{\"authorId\":\"1821514\",\"name\":\"Xu-Dong Lin\"},{\"authorId\":\"35862299\",\"name\":\"S. Karaman\"},{\"authorId\":\"72197815\",\"name\":\"Shih-Fu Chang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"1c801bcaa007c6bf6ce4027bdb45f88f7a861db3\",\"title\":\"Flow-Distilled IP Two-Stream Networks for Compressed Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1c801bcaa007c6bf6ce4027bdb45f88f7a861db3\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39901030\",\"name\":\"Dingwen Zhang\"},{\"authorId\":\"50469612\",\"name\":\"Guangyu Guo\"},{\"authorId\":\"145252513\",\"name\":\"Dong Huang\"},{\"authorId\":\"7181955\",\"name\":\"J. Han\"}],\"doi\":\"10.1109/CVPR.2018.00707\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0f8b1030baee3c1350662903d76510754793db83\",\"title\":\"PoseFlow: A Deep Motion Representation for Understanding Human Behaviors in Videos\",\"url\":\"https://www.semanticscholar.org/paper/0f8b1030baee3c1350662903d76510754793db83\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26923471\",\"name\":\"T. Chalen\"},{\"authorId\":\"3164610\",\"name\":\"B. Vintimilla\"}],\"doi\":\"10.1109/LA-CCI47412.2019.9037051\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2d98987f6ccada446e6dc50b02446e2027c06eec\",\"title\":\"Towards Action Prediction Applying Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/2d98987f6ccada446e6dc50b02446e2027c06eec\",\"venue\":\"2019 IEEE Latin American Conference on Computational Intelligence (LA-CCI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153023158\",\"name\":\"Z. Zhao\"},{\"authorId\":\"49901469\",\"name\":\"G. Chen\"},{\"authorId\":\"49750905\",\"name\":\"Chong Chen\"},{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"51470719\",\"name\":\"Xuanlu Xiang\"},{\"authorId\":\"49339105\",\"name\":\"Yanyun Zhao\"},{\"authorId\":\"152343380\",\"name\":\"Fei Su\"}],\"doi\":\"10.1109/ICCVW.2019.00234\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9a841017d4da8382841d1216ebeed8605bfaafaf\",\"title\":\"Instance-Based Video Search via Multi-Task Retrieval and Re-Ranking\",\"url\":\"https://www.semanticscholar.org/paper/9a841017d4da8382841d1216ebeed8605bfaafaf\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51208565\",\"name\":\"S. Cheng\"},{\"authorId\":\"92194342\",\"name\":\"Guoyi Qin\"},{\"authorId\":\"47320067\",\"name\":\"S. Li\"},{\"authorId\":\"144917416\",\"name\":\"M. Xie\"},{\"authorId\":\"1730232\",\"name\":\"Zheng Ma\"}],\"doi\":\"10.1109/ICCWAMTIP47768.2019.9067588\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"04538c624c44c9735f519a411c95732cc638e469\",\"title\":\"VLAD-SSTA: VLAD with Soft Spatio-Temporal Assignment for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/04538c624c44c9735f519a411c95732cc638e469\",\"venue\":\"2019 16th International Computer Conference on Wavelet Active Media Technology and Information Processing\",\"year\":2019},{\"arxivId\":\"1912.04430\",\"authors\":[{\"authorId\":\"3121735\",\"name\":\"Paritosh Parmar\"},{\"authorId\":\"49059658\",\"name\":\"B. Morris.\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7aef63bbe103760e78f359223e35562cdaed16c1\",\"title\":\"HalluciNet-ing Spatiotemporal Representations Using 2D-CNN\",\"url\":\"https://www.semanticscholar.org/paper/7aef63bbe103760e78f359223e35562cdaed16c1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":\"10.1109/CVPR.2015.7298892\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9754872e151a69c32956497725a4f6f3881f18bb\",\"title\":\"Dynamically encoded actions based on spacetime saliency\",\"url\":\"https://www.semanticscholar.org/paper/9754872e151a69c32956497725a4f6f3881f18bb\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2243964\",\"name\":\"C. Li\"},{\"authorId\":\"51210542\",\"name\":\"Donghao Gu\"},{\"authorId\":\"50088361\",\"name\":\"X. Ma\"},{\"authorId\":\"145164031\",\"name\":\"Kai Yang\"},{\"authorId\":\"1743348\",\"name\":\"S. Liu\"},{\"authorId\":\"144999037\",\"name\":\"Feng Jiang\"}],\"doi\":\"10.1109/DSC.2018.00089\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"26575ad9e75efb440a7dc4ef8e548eed4e19dbd1\",\"title\":\"Video Frame Interpolation Based on Multi-scale Convolutional Network and Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/26575ad9e75efb440a7dc4ef8e548eed4e19dbd1\",\"venue\":\"2018 IEEE Third International Conference on Data Science in Cyberspace (DSC)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2909350\",\"name\":\"Alexander Kl\\u00e4ser\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"1689269\",\"name\":\"C. Liu\"}],\"doi\":\"10.1007/s11263-012-0594-8\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"bbe0819a47a9f3f11dd34bb3ab44a997ef111088\",\"title\":\"Dense Trajectories and Motion Boundary Descriptors for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/bbe0819a47a9f3f11dd34bb3ab44a997ef111088\",\"venue\":\"International Journal of Computer Vision\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1406152923\",\"name\":\"Tingting Han\"},{\"authorId\":\"31255274\",\"name\":\"Hongxun Yao\"},{\"authorId\":\"2648498\",\"name\":\"Wenlong Xie\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":null,\"name\":\"Jun Yu\"}],\"doi\":\"10.1016/j.patcog.2020.107267\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"93dc1e7e7fbcb3110e19d6a8bca55b11b85a4604\",\"title\":\"TVENet: Temporal variance embedding network for fine-grained action representation\",\"url\":\"https://www.semanticscholar.org/paper/93dc1e7e7fbcb3110e19d6a8bca55b11b85a4604\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2005269189\",\"name\":\"Henning Dalsgaard Pohl\"},{\"authorId\":\"2007320625\",\"name\":\"Tor-Salve Dalsgaard\"},{\"authorId\":\"2007546739\",\"name\":\"Vesa Krasniqi\"},{\"authorId\":\"11138274\",\"name\":\"Kasper Hornb\\u00e6k\"}],\"doi\":\"10.1145/3385956.3418946\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"843f65f36f08e1c9d72c3f1799e3c2010290d8a9\",\"title\":\"Body LayARs: A Toolkit for Body-Based Augmented Reality\",\"url\":\"https://www.semanticscholar.org/paper/843f65f36f08e1c9d72c3f1799e3c2010290d8a9\",\"venue\":\"VRST\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2199479\",\"name\":\"Jongmin Yu\"},{\"authorId\":\"145423641\",\"name\":\"D. Y. Kim\"},{\"authorId\":\"8770612\",\"name\":\"Yongsang Yoon\"},{\"authorId\":\"145745152\",\"name\":\"M. Jeon\"}],\"doi\":\"10.1007/s00371-019-01751-1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb7a000f5c196dbb09f939674140ebcd1f20899e\",\"title\":\"Action matching network: open-set action recognition using spatio-temporal representation matching\",\"url\":\"https://www.semanticscholar.org/paper/eb7a000f5c196dbb09f939674140ebcd1f20899e\",\"venue\":\"The Visual Computer\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2882156\",\"name\":\"B. Ayhan\"},{\"authorId\":\"143689616\",\"name\":\"C. Kwan\"},{\"authorId\":\"18098724\",\"name\":\"Bence Budavari\"},{\"authorId\":\"66991683\",\"name\":\"J. Larkin\"},{\"authorId\":\"66931183\",\"name\":\"David Gribben\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"}],\"doi\":\"10.1109/ACCESS.2020.3033190\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4b02c4b808b4b9a13fcb5eaf6140e55a0b1247a2\",\"title\":\"Video Activity Recognition With Varying Rhythms\",\"url\":\"https://www.semanticscholar.org/paper/4b02c4b808b4b9a13fcb5eaf6140e55a0b1247a2\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145359182\",\"name\":\"Yang Yi\"},{\"authorId\":\"144630584\",\"name\":\"A. Li\"},{\"authorId\":\"50177482\",\"name\":\"Xiaofeng Zhou\"}],\"doi\":\"10.1016/j.image.2019.115640\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0cbbed1853bda7dc4cccf5ca07c06b4e7d7959d7\",\"title\":\"Human action recognition based on action relevance weighted encoding\",\"url\":\"https://www.semanticscholar.org/paper/0cbbed1853bda7dc4cccf5ca07c06b4e7d7959d7\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145580092\",\"name\":\"Pierre-Etienne Martin\"},{\"authorId\":\"1381345946\",\"name\":\"J. Benois-Pineau\"},{\"authorId\":\"1639895183\",\"name\":\"Renaud P\\u00e9teri\"},{\"authorId\":\"1639983772\",\"name\":\"Julien Morlier\"}],\"doi\":\"10.1007/s11042-020-08917-3\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"621c1061cc70d9291c03a9d7d0f3a4f9f0127532\",\"title\":\"Fine grained sport action recognition with Twin spatio-temporal convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/621c1061cc70d9291c03a9d7d0f3a4f9f0127532\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"1905.10654\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"20718203ce3b9c7ed5f56f13c08c988bfdf154ca\",\"title\":\"Exploring Temporal Information for Improved Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/20718203ce3b9c7ed5f56f13c08c988bfdf154ca\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51432978\",\"name\":\"Zhongke Liao\"},{\"authorId\":\"46354059\",\"name\":\"Haifeng Hu\"},{\"authorId\":\"49050918\",\"name\":\"J. Zhang\"},{\"authorId\":\"7650248\",\"name\":\"C. Yin\"}],\"doi\":\"10.1016/j.cviu.2019.102821\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fedf56f95e5e80464254573ce2d9648606899ccb\",\"title\":\"Residual attention unit for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/fedf56f95e5e80464254573ce2d9648606899ccb\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"101687783\",\"name\":\"O. Friberg\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ba018189673d883920111184040d307153346267\",\"title\":\"Recognizing Semantics in Human Actions with Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/ba018189673d883920111184040d307153346267\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1811.03879\",\"authors\":[{\"authorId\":\"51921002\",\"name\":\"N. Sayed\"},{\"authorId\":\"27629992\",\"name\":\"B. Brattoli\"},{\"authorId\":\"1796707\",\"name\":\"B. Ommer\"}],\"doi\":\"10.1007/978-3-030-12939-2_17\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"04f2a94a388dbc77d23ef5ec73cdb49ff251c1bd\",\"title\":\"Cross and Learn: Cross-Modal Self-Supervision\",\"url\":\"https://www.semanticscholar.org/paper/04f2a94a388dbc77d23ef5ec73cdb49ff251c1bd\",\"venue\":\"GCPR\",\"year\":2018},{\"arxivId\":\"2009.13087\",\"authors\":[{\"authorId\":\"3173493\",\"name\":\"Y. Li\"},{\"authorId\":\"2050979\",\"name\":\"Zhichao Lu\"},{\"authorId\":\"3182065\",\"name\":\"Xuehan Xiong\"},{\"authorId\":\"4240351\",\"name\":\"Jonathan Huang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"c8bf6f41d6df5c6cdc6249aecfa1aab027f0c8e0\",\"title\":\"PERF-Net: Pose Empowered RGB-Flow Net\",\"url\":\"https://www.semanticscholar.org/paper/c8bf6f41d6df5c6cdc6249aecfa1aab027f0c8e0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1824096\",\"name\":\"M. Ziaeefard\"},{\"authorId\":\"2145950\",\"name\":\"R. Bergevin\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.5244/C.29.167\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ae19008898ea1347cf0f7ecb81b71aa18137085a\",\"title\":\"Time-slice Prediction of Dyadic Human Activities\",\"url\":\"https://www.semanticscholar.org/paper/ae19008898ea1347cf0f7ecb81b71aa18137085a\",\"venue\":\"BMVC\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1859790847\",\"name\":\"Na Feng\"},{\"authorId\":\"1860555990\",\"name\":\"Zikai Song\"},{\"authorId\":\"4210401\",\"name\":\"Junqing Yu\"},{\"authorId\":\"152828944\",\"name\":\"Y. P. Chen\"},{\"authorId\":\"2627212\",\"name\":\"Y. Zhao\"},{\"authorId\":\"49990818\",\"name\":\"Yunfeng He\"},{\"authorId\":\"151470350\",\"name\":\"Tao Guan\"}],\"doi\":\"10.1007/s11042-020-09414-3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3b26c30b70a90b812423e668687db39332addfa0\",\"title\":\"SSET: a dataset for shot segmentation, event detection, player tracking in soccer videos\",\"url\":\"https://www.semanticscholar.org/paper/3b26c30b70a90b812423e668687db39332addfa0\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"1910.06699\",\"authors\":[{\"authorId\":\"37868227\",\"name\":\"C. D. Souza\"},{\"authorId\":\"1799820\",\"name\":\"Adrien Gaidon\"},{\"authorId\":\"3407519\",\"name\":\"Y. Cabon\"},{\"authorId\":\"26734366\",\"name\":\"N. Murray\"},{\"authorId\":\"3940956\",\"name\":\"A. Pe\\u00f1a\"}],\"doi\":\"10.1007/s11263-019-01222-z\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"099bdf9cf1c59c7f5ed201759157fb505f51a762\",\"title\":\"Generating Human Action Videos by Coupling 3D Game Engines and Probabilistic Graphical Models\",\"url\":\"https://www.semanticscholar.org/paper/099bdf9cf1c59c7f5ed201759157fb505f51a762\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2380070\",\"name\":\"Noor Almaadeed\"},{\"authorId\":\"3436875\",\"name\":\"Omar ElHarrouss\"},{\"authorId\":\"1406702495\",\"name\":\"S. Al-M\\u00e1adeed\"},{\"authorId\":\"1690116\",\"name\":\"A. Bouridane\"},{\"authorId\":\"1731553\",\"name\":\"Azeddine Beghdadi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1e088de792b60b1bfeb639a7f810b833b89c29d4\",\"title\":\"A Novel Approach for Robust Multi Human Action Detection and Recognition based on 3-Dimentional Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/1e088de792b60b1bfeb639a7f810b833b89c29d4\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3303577\",\"name\":\"Y. Liu\"},{\"authorId\":\"1702864\",\"name\":\"Q. Wu\"},{\"authorId\":\"1743636\",\"name\":\"L. Xu\"},{\"authorId\":\"48302999\",\"name\":\"B. Wu\"}],\"doi\":\"10.1587/TRANSINF.2016EDL8093\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d0520f1b09cb134229cb3839d352443661975e63\",\"title\":\"Mining Spatial Temporal Saliency Structure for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d0520f1b09cb134229cb3839d352443661975e63\",\"venue\":\"IEICE Trans. Inf. Syst.\",\"year\":2016},{\"arxivId\":\"1708.09522\",\"authors\":[{\"authorId\":\"1730844\",\"name\":\"Atousa Torabi\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2c51069d03974bd28dd821142a852ec24ce7546a\",\"title\":\"Action Classification and Highlighting in Videos\",\"url\":\"https://www.semanticscholar.org/paper/2c51069d03974bd28dd821142a852ec24ce7546a\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34752724\",\"name\":\"A. Gabriel\"},{\"authorId\":\"2148342\",\"name\":\"S. Cosar\"},{\"authorId\":\"1709606\",\"name\":\"N. Bellotto\"},{\"authorId\":\"143997370\",\"name\":\"P. Baxter\"}],\"doi\":\"10.1007/978-3-030-23807-0_30\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b662f49666373648289602e334ec47d34d658800\",\"title\":\"A Dataset for Action Recognition in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/b662f49666373648289602e334ec47d34d658800\",\"venue\":\"TAROS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3056962\",\"name\":\"Shujon Naha\"},{\"authorId\":\"46396571\",\"name\":\"Y. Wang\"}],\"doi\":\"10.1109/ICPR.2016.7899903\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0b2966101fa617b90510e145ed52226e79351072\",\"title\":\"Beyond verbs: Understanding actions in videos with text\",\"url\":\"https://www.semanticscholar.org/paper/0b2966101fa617b90510e145ed52226e79351072\",\"venue\":\"2016 23rd International Conference on Pattern Recognition (ICPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"144418348\",\"name\":\"R. Xu\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1109/CVPR.2015.7299000\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"17ea3c06ac00ad1a909c41a25b6c0f0c4a890d24\",\"title\":\"Human action segmentation with hierarchical supervoxel consistency\",\"url\":\"https://www.semanticscholar.org/paper/17ea3c06ac00ad1a909c41a25b6c0f0c4a890d24\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2983554\",\"name\":\"G. Somasundaram\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"1827707\",\"name\":\"V. Morellas\"},{\"authorId\":\"1696163\",\"name\":\"N. Papanikolopoulos\"}],\"doi\":\"10.1016/j.cviu.2014.01.002\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6c4dab4376d3ae0ddd76a1097820b9f10a8cda26\",\"title\":\"Action recognition using global spatio-temporal features derived from sparse representations\",\"url\":\"https://www.semanticscholar.org/paper/6c4dab4376d3ae0ddd76a1097820b9f10a8cda26\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40465774\",\"name\":\"Z. Gao\"},{\"authorId\":\"9162163\",\"name\":\"T. Han\"},{\"authorId\":\"145081305\",\"name\":\"L. Zhu\"},{\"authorId\":\"38079143\",\"name\":\"H. Zhang\"},{\"authorId\":\"38930487\",\"name\":\"Yinglong Wang\"}],\"doi\":\"10.1109/ACCESS.2018.2878313\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5c45c46b9b35685497d5fcdf2d4d748f3d27449a\",\"title\":\"Exploring the Cross-Domain Action Recognition Problem by Deep Feature Learning and Cross-Domain Learning\",\"url\":\"https://www.semanticscholar.org/paper/5c45c46b9b35685497d5fcdf2d4d748f3d27449a\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1732108\",\"name\":\"Weifeng Liu\"},{\"authorId\":\"47197370\",\"name\":\"Zhen Wang\"},{\"authorId\":\"1701119\",\"name\":\"Dapeng Tao\"},{\"authorId\":\"50812077\",\"name\":\"J. Yu\"}],\"doi\":\"10.1007/978-3-319-14442-9_55\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"e4a6b13e547b2a4bb575611c9d255fac436299c7\",\"title\":\"Hessian Regularized Sparse Coding for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e4a6b13e547b2a4bb575611c9d255fac436299c7\",\"venue\":\"MMM\",\"year\":2015},{\"arxivId\":\"1910.03579\",\"authors\":[{\"authorId\":\"2511001\",\"name\":\"Yin Bi\"},{\"authorId\":\"33998511\",\"name\":\"Aaron Chadha\"},{\"authorId\":\"2822935\",\"name\":\"Alhabib Abbas\"},{\"authorId\":\"2820254\",\"name\":\"Eirina Bourtsoulatze\"},{\"authorId\":\"2747620\",\"name\":\"Y. Andreopoulos\"}],\"doi\":\"10.1109/TIP.2020.3023597\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"5a5cf60486c7bf1937e7725ccccbdd95c4eb1f1b\",\"title\":\"Graph-Based Spatio-Temporal Feature Learning for Neuromorphic Vision Sensing\",\"url\":\"https://www.semanticscholar.org/paper/5a5cf60486c7bf1937e7725ccccbdd95c4eb1f1b\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47652825\",\"name\":\"Ming Zong\"},{\"authorId\":\"47652825\",\"name\":\"Ming Zong\"},{\"authorId\":\"1962363403\",\"name\":\"Ruili Wang\"},{\"authorId\":\"1962363403\",\"name\":\"Ruili Wang\"},{\"authorId\":\"150356113\",\"name\":\"Zhe Chen\"},{\"authorId\":\"2018580\",\"name\":\"M. Wang\"},{\"authorId\":\"1725522\",\"name\":\"X. Wang\"},{\"authorId\":\"1725522\",\"name\":\"X. Wang\"},{\"authorId\":\"144783648\",\"name\":\"J. Potgieter\"}],\"doi\":\"10.1007/s00521-020-05313-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"721fe37281bf9ea474a0c4f1441f02a7d6e4e4ed\",\"title\":\"Multi-cue based 3D residual network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/721fe37281bf9ea474a0c4f1441f02a7d6e4e4ed\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2007.06643\",\"authors\":[{\"authorId\":\"41018180\",\"name\":\"Kyle Min\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1007/978-3-030-58568-6_17\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5e8c230a7241836aeeb7f4c901cc8503ccdd9710\",\"title\":\"Adversarial Background-Aware Loss for Weakly-supervised Temporal Activity Localization\",\"url\":\"https://www.semanticscholar.org/paper/5e8c230a7241836aeeb7f4c901cc8503ccdd9710\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145878079\",\"name\":\"Vivek Sharma\"}],\"doi\":\"10.5445/IR/1000119819\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3605e0e6ea610576fa85fcf8737b9f20ddd87180\",\"title\":\"Self-supervised Face Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/3605e0e6ea610576fa85fcf8737b9f20ddd87180\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2012.08097\",\"authors\":[{\"authorId\":\"51445222\",\"name\":\"Shentong Mo\"},{\"authorId\":\"37874701\",\"name\":\"Xiaoqing Tan\"},{\"authorId\":\"2037452190\",\"name\":\"Jingfei Xia\"},{\"authorId\":\"2037420729\",\"name\":\"Pinxu Ren\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5c10f951f731274f088333a43ba57e416612c8e3\",\"title\":\"Towards Improving Spatiotemporal Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/5c10f951f731274f088333a43ba57e416612c8e3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.06567\",\"authors\":[{\"authorId\":\"1805946041\",\"name\":\"Yi Zhu\"},{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"49046944\",\"name\":\"C. Liu\"},{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"22539483\",\"name\":\"Chongruo Wu\"},{\"authorId\":\"152781163\",\"name\":\"Z. Zhang\"},{\"authorId\":\"2397422\",\"name\":\"Joseph Tighe\"},{\"authorId\":\"1758550\",\"name\":\"R. Manmatha\"},{\"authorId\":\"49140510\",\"name\":\"M. Li\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ee12f02830a5e1f7cadd3623dfed495cf099bc82\",\"title\":\"A Comprehensive Study of Deep Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ee12f02830a5e1f7cadd3623dfed495cf099bc82\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2101.00820\",\"authors\":[{\"authorId\":\"38057121\",\"name\":\"Yang Liu\"},{\"authorId\":\"3170394\",\"name\":\"Keze Wang\"},{\"authorId\":\"95686817\",\"name\":\"Haoyuan Lan\"},{\"authorId\":\"1737218\",\"name\":\"L. Lin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"66bf88cfa5ecd1e46ab67e8afc55dce4e6fd3aca\",\"title\":\"Temporal Contrastive Graph for Self-supervised Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/66bf88cfa5ecd1e46ab67e8afc55dce4e6fd3aca\",\"venue\":\"\",\"year\":2021},{\"arxivId\":\"2101.00545\",\"authors\":[{\"authorId\":\"1471426161\",\"name\":\"Ashraful Islam\"},{\"authorId\":\"48015811\",\"name\":\"Chengjiang Long\"},{\"authorId\":\"1772337\",\"name\":\"R. Radke\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d2b129dcf8d9b0d7d353e608eccb478fc7f9e6e2\",\"title\":\"A Hybrid Attention Mechanism for Weakly-Supervised Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/d2b129dcf8d9b0d7d353e608eccb478fc7f9e6e2\",\"venue\":\"\",\"year\":2021},{\"arxivId\":\"2010.01343\",\"authors\":[{\"authorId\":\"153257128\",\"name\":\"A. Srivastava\"},{\"authorId\":\"83923404\",\"name\":\"O. Dutta\"},{\"authorId\":\"2988091\",\"name\":\"A. Prathosh\"},{\"authorId\":\"47208444\",\"name\":\"Sumeet Agarwal\"},{\"authorId\":\"66286585\",\"name\":\"J. Gupta\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b4a545203ed195f77bb2fa4fcb90199ff7784f74\",\"title\":\"A Variational Information Bottleneck Based Method to Compress Sequential Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b4a545203ed195f77bb2fa4fcb90199ff7784f74\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738282\",\"name\":\"Y. Zheng\"},{\"authorId\":\"1720100\",\"name\":\"H. Yao\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"49835905\",\"name\":\"Xuesong Jiang\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"}],\"doi\":\"10.1007/s11042-017-5038-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf784156547c3be146706e2763c1a52d939d1722\",\"title\":\"Breaking video into pieces for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/cf784156547c3be146706e2763c1a52d939d1722\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2017},{\"arxivId\":\"1705.06950\",\"authors\":[{\"authorId\":\"21028601\",\"name\":\"W. Kay\"},{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"11809518\",\"name\":\"Brian Zhang\"},{\"authorId\":\"38961760\",\"name\":\"Chloe Hillier\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"143740871\",\"name\":\"F. Viola\"},{\"authorId\":\"143897708\",\"name\":\"T. Green\"},{\"authorId\":\"2830305\",\"name\":\"T. Back\"},{\"authorId\":\"1820908\",\"name\":\"A. Natsev\"},{\"authorId\":\"2573615\",\"name\":\"Mustafa Suleyman\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6\",\"title\":\"The Kinetics Human Action Video Dataset\",\"url\":\"https://www.semanticscholar.org/paper/86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"16060509\",\"name\":\"Trang Nguyen\"},{\"authorId\":\"144801511\",\"name\":\"S. Le\"},{\"authorId\":\"3080041\",\"name\":\"Thanh Duc Ngo\"}],\"doi\":\"10.1109/KSE.2015.45\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"287639a656bef401129a951e7649a2fd70653fd2\",\"title\":\"Generalized Max Pooling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/287639a656bef401129a951e7649a2fd70653fd2\",\"venue\":\"2015 Seventh International Conference on Knowledge and Systems Engineering (KSE)\",\"year\":2015},{\"arxivId\":\"2002.11925\",\"authors\":[{\"authorId\":\"47787302\",\"name\":\"J. Li\"},{\"authorId\":\"143856428\",\"name\":\"S. Todorovic\"}],\"doi\":\"10.1109/cvpr42600.2020.01083\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e7cd1bf06d1a248863f58923505e72c1b55e2261\",\"title\":\"Set-Constrained Viterbi for Set-Supervised Action Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/e7cd1bf06d1a248863f58923505e72c1b55e2261\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46276482\",\"name\":\"J. Li\"},{\"authorId\":\"145708711\",\"name\":\"Ping Wei\"},{\"authorId\":\"1978363545\",\"name\":\"Yongchi Zhang\"},{\"authorId\":\"153873673\",\"name\":\"N. Zheng\"}],\"doi\":\"10.1145/3394171.3413641\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"05444a5a49f717dc199957b66e9c472219171f88\",\"title\":\"A Slow-I-Fast-P Architecture for Compressed Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/05444a5a49f717dc199957b66e9c472219171f88\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49741227\",\"name\":\"Haifeng Sang\"},{\"authorId\":\"152254334\",\"name\":\"Z. Zhao\"},{\"authorId\":\"3030181\",\"name\":\"Dakuo He\"}],\"doi\":\"10.1109/ACCESS.2019.2936628\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"267dce4f4c6102e24eeac34d4315de7e7d25b538\",\"title\":\"Two-Level Attention Model Based Video Action Recognition Network\",\"url\":\"https://www.semanticscholar.org/paper/267dce4f4c6102e24eeac34d4315de7e7d25b538\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1708.05038\",\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"4439383\",\"name\":\"Jamie Ray\"},{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a92adfdd8996ab2bd7cdc910ea1d3db03c66d34f\",\"title\":\"ConvNet Architecture Search for Spatiotemporal Feature Learning\",\"url\":\"https://www.semanticscholar.org/paper/a92adfdd8996ab2bd7cdc910ea1d3db03c66d34f\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1888678\",\"name\":\"Miao Xin\"},{\"authorId\":\"46702644\",\"name\":\"H. Zhang\"},{\"authorId\":\"145070659\",\"name\":\"M. Sun\"},{\"authorId\":\"144437722\",\"name\":\"D. Yuan\"}],\"doi\":\"10.1109/IJCNN.2016.7727234\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"8c7136d250f731b0ca8c274a67a07830a69a08fd\",\"title\":\"Recurrent Temporal Sparse Autoencoder for attention-based action recognition\",\"url\":\"https://www.semanticscholar.org/paper/8c7136d250f731b0ca8c274a67a07830a69a08fd\",\"venue\":\"2016 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8297919\",\"name\":\"E. V. Dam\"},{\"authorId\":\"144882446\",\"name\":\"L. Noldus\"},{\"authorId\":\"143799386\",\"name\":\"M. V. Gerven\"}],\"doi\":\"10.1016/j.jneumeth.2019.108536\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5b40697a874e09a123ed7da97323da27662e0028\",\"title\":\"Deep Learning Improves Automated Rodent Behavior Recognition Within a Specific Experimental Setup\",\"url\":\"https://www.semanticscholar.org/paper/5b40697a874e09a123ed7da97323da27662e0028\",\"venue\":\"Journal of Neuroscience Methods\",\"year\":2019},{\"arxivId\":\"1905.10861\",\"authors\":[{\"authorId\":\"50133145\",\"name\":\"Min-Hung Chen\"},{\"authorId\":\"145276578\",\"name\":\"Z. Kira\"},{\"authorId\":\"9202076\",\"name\":\"G. Al-Regib\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d0d7db6fce7c0b8bdb88f8d37b33bb2c1a5256bc\",\"title\":\"Temporal Attentive Alignment for Video Domain Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/d0d7db6fce7c0b8bdb88f8d37b33bb2c1a5256bc\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2006.11476\",\"authors\":[{\"authorId\":\"1390925224\",\"name\":\"Y. Yao\"},{\"authorId\":\"49046944\",\"name\":\"C. Liu\"},{\"authorId\":\"152504322\",\"name\":\"Dezhao Luo\"},{\"authorId\":\"9113781\",\"name\":\"Yin-qing Zhou\"},{\"authorId\":\"12605536\",\"name\":\"Qixiang Ye\"}],\"doi\":\"10.1109/cvpr42600.2020.00658\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"15e8b0a6366e29c7093ecf844eb40d03d8004abb\",\"title\":\"Video Playback Rate Perception for Self-Supervised Spatio-Temporal Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/15e8b0a6366e29c7093ecf844eb40d03d8004abb\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145347149\",\"name\":\"L. Yuan\"},{\"authorId\":\"145527065\",\"name\":\"Tao Wang\"},{\"authorId\":\"21458018\",\"name\":\"Xiaopeng Zhang\"},{\"authorId\":\"2750647\",\"name\":\"Zequn Jie\"},{\"authorId\":\"40983412\",\"name\":\"F. Tay\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"566a9c3c892334fce136a5171beb89d6bdda91ae\",\"title\":\"Central Similarity Hashing via Hadamard matrix\",\"url\":\"https://www.semanticscholar.org/paper/566a9c3c892334fce136a5171beb89d6bdda91ae\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3136303\",\"name\":\"G. Cong\"},{\"authorId\":\"2972684\",\"name\":\"G. Domeniconi\"},{\"authorId\":\"47377263\",\"name\":\"Joshua Shapiro\"},{\"authorId\":\"144315735\",\"name\":\"Fan Zhou\"},{\"authorId\":\"144969569\",\"name\":\"B. Chen\"}],\"doi\":\"10.1109/CAHPC.2018.8645861\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"ac517a5c713824cad0c02789015d96c71ffc10c9\",\"title\":\"Accelerating Deep Neural Network Training for Action Recognition on a Cluster of GPUs\",\"url\":\"https://www.semanticscholar.org/paper/ac517a5c713824cad0c02789015d96c71ffc10c9\",\"venue\":\"2018 30th International Symposium on Computer Architecture and High Performance Computing (SBAC-PAD)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145791568\",\"name\":\"Y. Bo\"},{\"authorId\":\"9527255\",\"name\":\"Yixin Chen\"},{\"authorId\":\"145850224\",\"name\":\"Wenbo He\"},{\"authorId\":\"33276033\",\"name\":\"Jie Xiang\"}],\"doi\":\"10.1109/BigMM.2018.8499251\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"af13aae576f4d9ecc3de73a9ef8ff4396d057b8c\",\"title\":\"DVD: Constructing a Discriminative Video Descriptor by Convolving Frame Features\",\"url\":\"https://www.semanticscholar.org/paper/af13aae576f4d9ecc3de73a9ef8ff4396d057b8c\",\"venue\":\"2018 IEEE Fourth International Conference on Multimedia Big Data (BigMM)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2359832\",\"name\":\"Hongya Wang\"},{\"authorId\":\"1398305251\",\"name\":\"C. Dartigues-Pallez\"},{\"authorId\":\"70023327\",\"name\":\"M. Riveill\"}],\"doi\":\"10.1007/978-3-030-59413-8_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"986712869037687f9f1eb3ce3e1932c3606d5d5d\",\"title\":\"Supervised Learning for Human Action Recognition from Multiple Kinects\",\"url\":\"https://www.semanticscholar.org/paper/986712869037687f9f1eb3ce3e1932c3606d5d5d\",\"venue\":\"DASFAA\",\"year\":2020},{\"arxivId\":\"1711.11200\",\"authors\":[{\"authorId\":\"1729858\",\"name\":\"Hyunwoo Lee\"},{\"authorId\":\"1784186\",\"name\":\"J. Kim\"},{\"authorId\":\"32671800\",\"name\":\"Dojun Yang\"},{\"authorId\":\"49476694\",\"name\":\"Joon-Ho Kim\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"bf77949b099348d8adffb14d5290b1db3fb0d2e0\",\"title\":\"Embedded Real-Time Fall Detection Using Deep Learning For Elderly Care\",\"url\":\"https://www.semanticscholar.org/paper/bf77949b099348d8adffb14d5290b1db3fb0d2e0\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1804.00413\",\"authors\":[{\"authorId\":\"2548303\",\"name\":\"Lijie Fan\"},{\"authorId\":\"2978255\",\"name\":\"Wen-bing Huang\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"2490652\",\"name\":\"S. Ermon\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"},{\"authorId\":\"1768190\",\"name\":\"J. Huang\"}],\"doi\":\"10.1109/CVPR.2018.00630\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"259dcd1afe22e569132ccc41697ac368504c4dd1\",\"title\":\"End-to-End Learning of Motion Representation for Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/259dcd1afe22e569132ccc41697ac368504c4dd1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2155311\",\"name\":\"Eunbyung Park\"},{\"authorId\":\"1682965\",\"name\":\"Xufeng Han\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"}],\"doi\":\"10.1109/WACV.2016.7477589\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ec44bf99ba11f3b6d0bb32dd5bc6ac08dd0c63d6\",\"title\":\"Combining multiple sources of knowledge in deep CNNs for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/ec44bf99ba11f3b6d0bb32dd5bc6ac08dd0c63d6\",\"venue\":\"2016 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2016},{\"arxivId\":\"1910.04744\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"479c6913b92335d77e81af95f559508f0e2753e5\",\"title\":\"CATER: A diagnostic dataset for Compositional Actions and TEmporal Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/479c6913b92335d77e81af95f559508f0e2753e5\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"1905.13607\",\"authors\":[{\"authorId\":\"119413444\",\"name\":\"G. Storey\"},{\"authorId\":\"144725605\",\"name\":\"R. Jiang\"},{\"authorId\":\"32676664\",\"name\":\"Shelagh Keogh\"},{\"authorId\":\"1690116\",\"name\":\"A. Bouridane\"},{\"authorId\":\"1799504\",\"name\":\"Chang-Tsun Li\"}],\"doi\":\"10.1109/ACCESS.2019.2937285\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"860927c6bda80ff6eb8ef4d6fdb8753c255def15\",\"title\":\"3DPalsyNet: A Facial Palsy Grading and Motion Recognition Framework Using Fully 3D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/860927c6bda80ff6eb8ef4d6fdb8753c255def15\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3095774\",\"name\":\"Dan Oneata\"},{\"authorId\":\"3428663\",\"name\":\"J\\u00e9r\\u00f4me Revaud\"},{\"authorId\":\"1721683\",\"name\":\"J. Verbeek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1007/978-3-319-10578-9_48\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5d35db6d5bee363fcaf3ca9397cc063f023e0252\",\"title\":\"Spatio-temporal Object Detection Proposals\",\"url\":\"https://www.semanticscholar.org/paper/5d35db6d5bee363fcaf3ca9397cc063f023e0252\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1708.06637\",\"authors\":[{\"authorId\":\"144289593\",\"name\":\"C. A. Caetano\"},{\"authorId\":\"143793197\",\"name\":\"V. H. Melo\"},{\"authorId\":\"6141311\",\"name\":\"J. A. D. Santos\"},{\"authorId\":\"9385043\",\"name\":\"W. Schwartz\"}],\"doi\":\"10.1109/SIBGRAPI.2017.13\",\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"c6c086748474dcda06d773891848aa1472de3560\",\"title\":\"Activity Recognition Based on a Magnitude-Orientation Stream Network\",\"url\":\"https://www.semanticscholar.org/paper/c6c086748474dcda06d773891848aa1472de3560\",\"venue\":\"2017 30th SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2351434\",\"name\":\"Zhongwen Xu\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"},{\"authorId\":\"1807998\",\"name\":\"I. Tsang\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1109/ICCV.2013.427\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ed593bf166755bd0fe45bc27a48f6dbf4357ef81\",\"title\":\"Feature Weighting via Optimal Thresholding for Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/ed593bf166755bd0fe45bc27a48f6dbf4357ef81\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67267687\",\"name\":\"K. Degiorgio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb4fc543bb24f5793aa797fd36907dcfebd4cfe6\",\"title\":\"Automatic Localization and Annotation of Spatio-Temporal Actions in Weakly Labelled Videos\",\"url\":\"https://www.semanticscholar.org/paper/eb4fc543bb24f5793aa797fd36907dcfebd4cfe6\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"dba69f6d1e5b0ab75a5b317debec898a406a92bb\",\"title\":\"REAL-TIME HUMAN ACTIVITY RECOGNITION BASED ON RADAR A THESIS SUBMITTED TO THE GRADUATE SCHOOL IN PARTIAL FULFILLMENT OF THE REQUIREMENT FOR THE DEGREE MASTER OF SCIENCE BY HANQING GUO\",\"url\":\"https://www.semanticscholar.org/paper/dba69f6d1e5b0ab75a5b317debec898a406a92bb\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1910.11105\",\"authors\":[{\"authorId\":\"1382652819\",\"name\":\"Barak Battash\"},{\"authorId\":\"145128144\",\"name\":\"Lior Wolf\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"f3b1e7592d91717a3cf0e9c42bd27c22ca5d3aab\",\"title\":\"Adaptive and Iteratively Improving Recurrent Lateral Connections\",\"url\":\"https://www.semanticscholar.org/paper/f3b1e7592d91717a3cf0e9c42bd27c22ca5d3aab\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"08d9bea632aa3e32fe6b5436b147edacb69e4660\",\"title\":\"POLITECNICO DI TORINO Master of Science in Mathematical Engineering Deep Learning Algorithms for Video Classification: Application on Real-Time Hand Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/08d9bea632aa3e32fe6b5436b147edacb69e4660\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40370451\",\"name\":\"H. Kim\"},{\"authorId\":\"10263579\",\"name\":\"Seokmok Park\"},{\"authorId\":\"1820264163\",\"name\":\"Hyeokjin Park\"},{\"authorId\":\"9238090\",\"name\":\"J. Paik\"}],\"doi\":\"10.3390/s20143894\",\"intent\":[\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"d76a567188604c227000de1d8e44fe64a176c654\",\"title\":\"Enhanced Action Recognition Using Multiple Stream Deep Learning with Optical Flow and Weighted Sum\",\"url\":\"https://www.semanticscholar.org/paper/d76a567188604c227000de1d8e44fe64a176c654\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2283107\",\"name\":\"Debaditya Roy\"},{\"authorId\":\"144067348\",\"name\":\"K. R. Murty\"},{\"authorId\":\"34358756\",\"name\":\"C. K. Mohan\"}],\"doi\":\"10.1109/TMM.2018.2887021\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"46c7c0d5c54fbd3d26fd719ebc66e2188ea4fc07\",\"title\":\"Unsupervised Universal Attribute Modeling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/46c7c0d5c54fbd3d26fd719ebc66e2188ea4fc07\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143602033\",\"name\":\"Anan Liu\"},{\"authorId\":\"2788104\",\"name\":\"Yuting Su\"},{\"authorId\":\"144536249\",\"name\":\"W. Nie\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":\"10.1109/TPAMI.2016.2537337\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"07dc9f3b34284cc915dea7575f40ef0c04338126\",\"title\":\"Hierarchical Clustering Multi-Task Learning for Joint Human Action Grouping and Recognition\",\"url\":\"https://www.semanticscholar.org/paper/07dc9f3b34284cc915dea7575f40ef0c04338126\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145479904\",\"name\":\"Tiantian Xu\"},{\"authorId\":\"152506137\",\"name\":\"F. Zhu\"},{\"authorId\":\"3314902\",\"name\":\"E. K. Wong\"},{\"authorId\":\"144145644\",\"name\":\"Yi Fang\"}],\"doi\":\"10.1016/j.imavis.2016.01.001\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"defce0398a00162cb79570514f4f1fb390138f5c\",\"title\":\"Dual many-to-one-encoder-based transfer learning for cross-dataset human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/defce0398a00162cb79570514f4f1fb390138f5c\",\"venue\":\"Image Vis. Comput.\",\"year\":2016},{\"arxivId\":\"1909.06423\",\"authors\":[{\"authorId\":\"153494805\",\"name\":\"Valter Lu\\u00eds Estevam Junior\"},{\"authorId\":\"1743455\",\"name\":\"H. Pedrini\"},{\"authorId\":\"50534501\",\"name\":\"D. Menotti\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e93e88c1b38e9d4733f3b5d692b354035fe57fdf\",\"title\":\"Zero-Shot Action Recognition in Videos: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/e93e88c1b38e9d4733f3b5d692b354035fe57fdf\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1404610182\",\"name\":\"Orit Kliper-Gross\"},{\"authorId\":\"2916582\",\"name\":\"Yaron Gurovich\"},{\"authorId\":\"1756099\",\"name\":\"Tal Hassner\"},{\"authorId\":\"145128144\",\"name\":\"L. Wolf\"}],\"doi\":\"10.1007/978-3-642-33783-3_19\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"993a2c02a5a3263b3047202e3d86aa9a0dd6ebfe\",\"title\":\"Motion Interchange Patterns for Action Recognition in Unconstrained Videos\",\"url\":\"https://www.semanticscholar.org/paper/993a2c02a5a3263b3047202e3d86aa9a0dd6ebfe\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1502870508\",\"name\":\"Xiaomeng Li\"},{\"authorId\":\"31620864\",\"name\":\"M. Wang\"},{\"authorId\":\"1687907\",\"name\":\"W. Zeng\"},{\"authorId\":\"48628207\",\"name\":\"Weigang Lu\"}],\"doi\":\"10.1109/ICCSE.2019.8845330\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d39edc81d7879cfae070ec857b8618676c5f73b1\",\"title\":\"A Students\\u2019 Action Recognition Database In Smart Classroom\",\"url\":\"https://www.semanticscholar.org/paper/d39edc81d7879cfae070ec857b8618676c5f73b1\",\"venue\":\"2019 14th International Conference on Computer Science & Education (ICCSE)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"108704164\",\"name\":\"Javier Jorge Cano\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"dcfb53bfbe8b3eb81c424ccc486682147c3293c9\",\"title\":\"Clasificaci\\u00f3n de v\\u00eddeos mediante Redes Neuronales Artificiales\",\"url\":\"https://www.semanticscholar.org/paper/dcfb53bfbe8b3eb81c424ccc486682147c3293c9\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1954884\",\"name\":\"A. Gilbert\"},{\"authorId\":\"145398628\",\"name\":\"R. Bowden\"}],\"doi\":\"10.1007/978-3-319-16814-2_19\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"80571cd21fc64e8293c344bb591ffee49fb72d50\",\"title\":\"Data Mining for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/80571cd21fc64e8293c344bb591ffee49fb72d50\",\"venue\":\"ACCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1999236\",\"name\":\"H. Chang\"},{\"authorId\":\"2373284\",\"name\":\"J. Kim\"},{\"authorId\":\"2803030\",\"name\":\"Jungchan Cho\"},{\"authorId\":\"34184385\",\"name\":\"Songhwai Oh\"},{\"authorId\":\"2906716\",\"name\":\"K. Yi\"},{\"authorId\":\"46174575\",\"name\":\"J. Choi\"}],\"doi\":\"10.5244/C.27.81\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"73a0434a0fad38f174c43b41976e284cf60e1096\",\"title\":\"Action Chart: A Representation for Efficient Recognition of Complex Activity\",\"url\":\"https://www.semanticscholar.org/paper/73a0434a0fad38f174c43b41976e284cf60e1096\",\"venue\":\"BMVC\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3303577\",\"name\":\"Y. Liu\"},{\"authorId\":\"1702864\",\"name\":\"Q. Wu\"},{\"authorId\":\"2819089\",\"name\":\"L. Tang\"}],\"doi\":\"10.1109/ICMEW.2017.8026246\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5f7094ba898a248e1e6b37e3d9fb795e59131cdc\",\"title\":\"Frame-skip Convolutional Neural Networks for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/5f7094ba898a248e1e6b37e3d9fb795e59131cdc\",\"venue\":\"2017 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2017},{\"arxivId\":\"1711.09125\",\"authors\":[{\"authorId\":\"119770705\",\"name\":\"L. Wang\"},{\"authorId\":\"48625175\",\"name\":\"W. Li\"},{\"authorId\":\"145344553\",\"name\":\"W. Li\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2018.00155\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e6b534d8838f92461a478a3e737b73e08db94748\",\"title\":\"Appearance-and-Relation Networks for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/e6b534d8838f92461a478a3e737b73e08db94748\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1686715\",\"name\":\"S. Yu\"},{\"authorId\":\"49388033\",\"name\":\"Y. Cheng\"},{\"authorId\":\"8143876\",\"name\":\"Songzhi Su\"},{\"authorId\":\"1900810\",\"name\":\"Guo-Rong Cai\"},{\"authorId\":\"8086812\",\"name\":\"Shaozi Li\"}],\"doi\":\"10.1007/s11042-016-3768-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d5d5cc27ca519d1300e77e3c1a535a089f52f646\",\"title\":\"Stratified pooling based deep convolutional neural networks for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/d5d5cc27ca519d1300e77e3c1a535a089f52f646\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1711083\",\"name\":\"M. Siddiqi\"},{\"authorId\":\"40545359\",\"name\":\"R. Ali\"},{\"authorId\":\"145468387\",\"name\":\"M. S. Rana\"},{\"authorId\":\"1975289\",\"name\":\"Een-Kee Hong\"},{\"authorId\":\"50078430\",\"name\":\"E. Kim\"},{\"authorId\":\"1700806\",\"name\":\"S. Lee\"}],\"doi\":\"10.3390/s140406370\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a8397f0e413a6ce5457753d7ec7eb940cd241681\",\"title\":\"Video-Based Human Activity Recognition Using Multilevel Wavelet Decomposition and Stepwise Linear Discriminant Analysis\",\"url\":\"https://www.semanticscholar.org/paper/a8397f0e413a6ce5457753d7ec7eb940cd241681\",\"venue\":\"Sensors\",\"year\":2014},{\"arxivId\":\"2004.01225\",\"authors\":[{\"authorId\":\"1944885\",\"name\":\"A. Kindiroglu\"},{\"authorId\":\"32852728\",\"name\":\"Ogulcan \\u00d6zdemir\"},{\"authorId\":\"1694599\",\"name\":\"L. Akarun\"}],\"doi\":\"10.1109/ICCVW.2019.00164\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"13fbc66718d1a4b1c05e0aad78da9642cb61925e\",\"title\":\"Temporal Accumulative Features for Sign Language Recognition\",\"url\":\"https://www.semanticscholar.org/paper/13fbc66718d1a4b1c05e0aad78da9642cb61925e\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47903936\",\"name\":\"Yali Wang\"},{\"authorId\":\"47681623\",\"name\":\"Lin Li\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1109/ICARM.2016.7606913\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b68f55bab12ca50b033d8b5c773ce5fe88c5923d\",\"title\":\"Human action recognition with DeepAction Kernel Gaussian Process\",\"url\":\"https://www.semanticscholar.org/paper/b68f55bab12ca50b033d8b5c773ce5fe88c5923d\",\"venue\":\"2016 International Conference on Advanced Robotics and Mechatronics (ICARM)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2985266\",\"name\":\"Zhuowei Cai\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1109/CVPR.2014.83\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8b5ff695d2bafa45f6bc50927b3142cc93601c59\",\"title\":\"Multi-view Super Vector for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b5ff695d2bafa45f6bc50927b3142cc93601c59\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2983562\",\"name\":\"Huafeng Chen\"},{\"authorId\":\"38373223\",\"name\":\"J. Chen\"},{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"37254976\",\"name\":\"RuiMin Hu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4205cb47ba4d3c0f21840633bcd49349d1dc02c1\",\"title\":\"RECOGNITIONWITH GRADIENT BOUNDARY CONVOLUTIONAL NETWORK\",\"url\":\"https://www.semanticscholar.org/paper/4205cb47ba4d3c0f21840633bcd49349d1dc02c1\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1423699581\",\"name\":\"A. F. D. Marsiano\"},{\"authorId\":\"9149246\",\"name\":\"I. Soesanti\"},{\"authorId\":\"2969172\",\"name\":\"Igi Ardiyanto\"}],\"doi\":\"10.1109/ICAICTA.2019.8904395\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8bbd6a362fd9afe63c8780d9ec199eeb257c5eef\",\"title\":\"Deep learning-based Anomaly Detection on Surveillance Videos: Recent Advances\",\"url\":\"https://www.semanticscholar.org/paper/8bbd6a362fd9afe63c8780d9ec199eeb257c5eef\",\"venue\":\"2019 International Conference of Advanced Informatics: Concepts, Theory and Applications (ICAICTA)\",\"year\":2019},{\"arxivId\":\"1804.10069\",\"authors\":[{\"authorId\":\"2439211\",\"name\":\"Chenrui Zhang\"},{\"authorId\":\"143753918\",\"name\":\"Y. Peng\"}],\"doi\":\"10.24963/ijcai.2018/158\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f00925f8c8acc5450b5482a12753653cfeaeb268\",\"title\":\"Better and Faster: Knowledge Transfer from Multiple Self-supervised Learning Tasks via Graph Distillation for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/f00925f8c8acc5450b5482a12753653cfeaeb268\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1563634707\",\"name\":\"Noorhan Khaled\"},{\"authorId\":\"37370786\",\"name\":\"Mohammed Marey\"},{\"authorId\":\"9160196\",\"name\":\"M. Aref\"}],\"doi\":\"10.1109/ICICIS46948.2019.9014707\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d502ee62d6a46520880ca360a374fdd393f3259b\",\"title\":\"Temporal Action Detection with Fused Two-Stream 3D Residual Neural Networks and Bi-Directional LSTM\",\"url\":\"https://www.semanticscholar.org/paper/d502ee62d6a46520880ca360a374fdd393f3259b\",\"venue\":\"2019 Ninth International Conference on Intelligent Computing and Information Systems (ICICIS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21240743\",\"name\":\"Yongqiang Kong\"},{\"authorId\":\"49025023\",\"name\":\"J. Huang\"},{\"authorId\":\"2898447\",\"name\":\"Shanshan Huang\"},{\"authorId\":\"2999650\",\"name\":\"Zhengang Wei\"},{\"authorId\":\"3050837\",\"name\":\"Shengke Wang\"}],\"doi\":\"10.1109/SmartWorld.2018.00089\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"427be2984bc0ff3831480c6dd6ae9c59c25603e7\",\"title\":\"Dynamic Representation Learning for Video Action Recognition Using Temporal Residual Networks\",\"url\":\"https://www.semanticscholar.org/paper/427be2984bc0ff3831480c6dd6ae9c59c25603e7\",\"venue\":\"2018 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)\",\"year\":2018},{\"arxivId\":\"1904.13080\",\"authors\":[{\"authorId\":\"145377162\",\"name\":\"Y. Yuan\"},{\"authorId\":\"49370704\",\"name\":\"Dong Wang\"},{\"authorId\":\"39669401\",\"name\":\"Q. Wang\"}],\"doi\":\"10.1609/aaai.v33i01.33019167\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e3fc2a67967b1355609094175f19b2412dd4851d\",\"title\":\"Memory-Augmented Temporal Dynamic Learning for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e3fc2a67967b1355609094175f19b2412dd4851d\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144907434\",\"name\":\"T. Kobayashi\"}],\"doi\":\"10.1109/ICCV.2017.600\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"703c9c8f20860a1b1be63e6df1622b2021b003ca\",\"title\":\"Flip-Invariant Motion Representation\",\"url\":\"https://www.semanticscholar.org/paper/703c9c8f20860a1b1be63e6df1622b2021b003ca\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145161471\",\"name\":\"Y. Yoon\"},{\"authorId\":\"2199479\",\"name\":\"Jongmin Yu\"},{\"authorId\":\"2184044\",\"name\":\"Moongu Jeon\"}],\"doi\":\"10.1109/ACCESS.2019.2953455\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"345a2fa96bb50c7986cd39875ac9d55b7f2c7769\",\"title\":\"Spatio-Temporal Representation Matching-Based Open-Set Action Recognition by Joint Learning of Motion and Appearance\",\"url\":\"https://www.semanticscholar.org/paper/345a2fa96bb50c7986cd39875ac9d55b7f2c7769\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1393588876\",\"name\":\"Fei Han\"},{\"authorId\":\"49357069\",\"name\":\"Dejun Zhang\"},{\"authorId\":\"2846159\",\"name\":\"Yiqi Wu\"},{\"authorId\":\"117454237\",\"name\":\"Zirui Qiu\"},{\"authorId\":\"1562396274\",\"name\":\"Longyong Wu\"},{\"authorId\":\"49015700\",\"name\":\"W. Huang\"}],\"doi\":\"10.1007/978-981-15-3651-9_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d4fd6a090c2e098ff21e2b09015328c7c898035b\",\"title\":\"Human Action Recognition Based on Dual Correlation Network\",\"url\":\"https://www.semanticscholar.org/paper/d4fd6a090c2e098ff21e2b09015328c7c898035b\",\"venue\":\"ACPR Workshops\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2089428\",\"name\":\"D. P. Barrett\"},{\"authorId\":\"1737754\",\"name\":\"J. Siskind\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"02fee7a9162387c21d2b52ea5f036be2d860010c\",\"title\":\"Felzenszwalb-Baum-Welch: Event Detection through Changing Appearance\",\"url\":\"https://www.semanticscholar.org/paper/02fee7a9162387c21d2b52ea5f036be2d860010c\",\"venue\":\"\",\"year\":2013},{\"arxivId\":\"2008.13759\",\"authors\":[{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"67968b5b59b08ea1dd8a1266b422ee38e3ca8ad5\",\"title\":\"Online Spatiotemporal Action Detection and Prediction via Causal Representations\",\"url\":\"https://www.semanticscholar.org/paper/67968b5b59b08ea1dd8a1266b422ee38e3ca8ad5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3035146\",\"name\":\"Jinyoung Moon\"},{\"authorId\":\"9637828\",\"name\":\"Junho Jin\"},{\"authorId\":\"144396280\",\"name\":\"Yongjin Kwon\"},{\"authorId\":\"1938407\",\"name\":\"Kyuchang Kang\"},{\"authorId\":\"2800227\",\"name\":\"Jongyoul Park\"},{\"authorId\":\"144341935\",\"name\":\"K. Park\"}],\"doi\":\"10.4218/ETRIJ.17.0116.0054\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e58c692a2ac35d4beab97836c4c95881d52beb61\",\"title\":\"Extensible Hierarchical Method of Detecting Interactive Actions for Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/e58c692a2ac35d4beab97836c4c95881d52beb61\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"2004.06704\",\"authors\":[{\"authorId\":\"27575517\",\"name\":\"Dian Shao\"},{\"authorId\":\"145454812\",\"name\":\"Yue Zhao\"},{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/cvpr42600.2020.00269\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f5c35edc9cf622c7dd7e19ce6fbd5d563557de5b\",\"title\":\"FineGym: A Hierarchical Video Dataset for Fine-Grained Action Understanding\",\"url\":\"https://www.semanticscholar.org/paper/f5c35edc9cf622c7dd7e19ce6fbd5d563557de5b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2658929\",\"name\":\"S. Fothergill\"},{\"authorId\":\"1710393\",\"name\":\"H. Mentis\"},{\"authorId\":\"143967473\",\"name\":\"P. Kohli\"},{\"authorId\":\"2388416\",\"name\":\"Sebastian Nowozin\"}],\"doi\":\"10.1145/2207676.2208303\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dbc7c45f86f11125fc4689e3f019485354f8e505\",\"title\":\"Instructing people for training gestural interactive systems\",\"url\":\"https://www.semanticscholar.org/paper/dbc7c45f86f11125fc4689e3f019485354f8e505\",\"venue\":\"CHI\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1389422664\",\"name\":\"Roshan Singh\"},{\"authorId\":\"1483623375\",\"name\":\"Rajat Khurana\"},{\"authorId\":\"30059439\",\"name\":\"A. Kushwaha\"},{\"authorId\":\"144681901\",\"name\":\"R. Srivastava\"}],\"doi\":\"10.1080/21681163.2020.1805798\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"329ebf6e0edce89f5114f493b6d154c5841be639\",\"title\":\"A Dual Stream Model for Activity Recognition: Exploiting Residual- CNN with Transfer Learning\",\"url\":\"https://www.semanticscholar.org/paper/329ebf6e0edce89f5114f493b6d154c5841be639\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Fang Liu\"},{\"authorId\":\"9303726\",\"name\":\"Xiangmin Xu\"},{\"authorId\":\"50728655\",\"name\":\"Tong Zhang\"},{\"authorId\":\"2698357\",\"name\":\"Kailing Guo\"},{\"authorId\":\"1390771080\",\"name\":\"L. Wang\"}],\"doi\":\"10.1016/j.neucom.2019.11.020\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9df354b00c6450198371172c96be48fea0b78d28\",\"title\":\"Exploring privileged information from simple actions for complex action recognition\",\"url\":\"https://www.semanticscholar.org/paper/9df354b00c6450198371172c96be48fea0b78d28\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5685594\",\"name\":\"G. Lorre\"},{\"authorId\":\"2962220\",\"name\":\"J. Rabarisoa\"},{\"authorId\":\"19258632\",\"name\":\"A. Orcesi\"},{\"authorId\":\"2910432\",\"name\":\"Samia Ainouz\"},{\"authorId\":\"10451773\",\"name\":\"St\\u00e9phane Canu\"}],\"doi\":\"10.1109/WACV45572.2020.9093278\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"90f84c25039d6c69bd25e70c719251aeacc50978\",\"title\":\"Temporal Contrastive Pretraining for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/90f84c25039d6c69bd25e70c719251aeacc50978\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"2011.02543\",\"authors\":[{\"authorId\":\"30621486\",\"name\":\"Stepan Alekseevich Komkov\"},{\"authorId\":\"2007675511\",\"name\":\"Maksim Dzabraev\"},{\"authorId\":\"1380315305\",\"name\":\"Aleksandr Petiushko\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0e0be00a9dac71413ebfca60ea6b40a5d73c5877\",\"title\":\"Mutual Modality Learning for Video Action Classification\",\"url\":\"https://www.semanticscholar.org/paper/0e0be00a9dac71413ebfca60ea6b40a5d73c5877\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32970572\",\"name\":\"Kuo-Hao Zeng\"},{\"authorId\":\"49415774\",\"name\":\"Yen-Chen Lin\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":\"10.1109/ICIP.2016.7532982\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"768eb5df23dbd95e6514ea7ed553de509a115dc0\",\"title\":\"Semantic highlight retrieval\",\"url\":\"https://www.semanticscholar.org/paper/768eb5df23dbd95e6514ea7ed553de509a115dc0\",\"venue\":\"2016 IEEE International Conference on Image Processing (ICIP)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32723478\",\"name\":\"R. O. Garc\\u00eda\"},{\"authorId\":\"34970419\",\"name\":\"E. Morales\"},{\"authorId\":\"144763689\",\"name\":\"L. Sucar\"}],\"doi\":\"10.1007/s10044-020-00924-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2b3d22fad864939a5e630fda197e8584fef793e0\",\"title\":\"Second-order motion descriptors for efficient action recognition\",\"url\":\"https://www.semanticscholar.org/paper/2b3d22fad864939a5e630fda197e8584fef793e0\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1519286161\",\"name\":\"Junjie Wang\"},{\"authorId\":\"51311907\",\"name\":\"Xueyan Wen\"}],\"doi\":\"10.1088/1742-6596/1651/1/012193\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"61a78b9873ca5a0ce47eea5f4c1115dce7658d1e\",\"title\":\"A Spatio-Temporal Attention Convolution Block for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/61a78b9873ca5a0ce47eea5f4c1115dce7658d1e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12808196\",\"name\":\"I. Naeh\"},{\"authorId\":\"1491911042\",\"name\":\"Roi Pony\"},{\"authorId\":\"1712535\",\"name\":\"Shie Mannor\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f26706daac5f920925871c1554da4db6f72702c6\",\"title\":\"Flickering Adversarial Attacks against Video Recognition Networks\",\"url\":\"https://www.semanticscholar.org/paper/f26706daac5f920925871c1554da4db6f72702c6\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1601.06615\",\"authors\":[{\"authorId\":\"2822290\",\"name\":\"Suraj Srinivas\"},{\"authorId\":\"1730952\",\"name\":\"Ravi Kiran Sarvadevabhatla\"},{\"authorId\":\"2217000\",\"name\":\"Konda Reddy Mopuri\"},{\"authorId\":\"40390520\",\"name\":\"N. Prabhu\"},{\"authorId\":\"1784761\",\"name\":\"S. Kruthiventi\"},{\"authorId\":\"144682140\",\"name\":\"R. Venkatesh Babu\"}],\"doi\":\"10.3389/frobt.2015.00036\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"412b3ef02c85087e5f1721176114672c722b17a4\",\"title\":\"A Taxonomy of Deep Convolutional Neural Nets for Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/412b3ef02c85087e5f1721176114672c722b17a4\",\"venue\":\"Front. Robot. AI\",\"year\":2016},{\"arxivId\":\"2001.08740\",\"authors\":[{\"authorId\":\"2299381\",\"name\":\"Fanyi Xiao\"},{\"authorId\":\"144756076\",\"name\":\"Y. Lee\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"153652147\",\"name\":\"J. Malik\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"80685dc522d30b18f3feb97d6c977f71fa746325\",\"title\":\"Audiovisual SlowFast Networks for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/80685dc522d30b18f3feb97d6c977f71fa746325\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1387989010\",\"name\":\"Fida Mohammad Thoker\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b7f3c20652907d4aae0c773f265d5cb833d5d767\",\"title\":\"Feature-Supervised Action Modality Transfer\",\"url\":\"https://www.semanticscholar.org/paper/b7f3c20652907d4aae0c773f265d5cb833d5d767\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3369420\",\"name\":\"D. Dalmazzo\"},{\"authorId\":\"49521806\",\"name\":\"G. Waddell\"},{\"authorId\":\"145921481\",\"name\":\"R. Ram\\u00edrez\"}],\"doi\":\"10.3389/fpsyg.2020.575971\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8d0805de044af93f96d518cd24739dad0652a916\",\"title\":\"Applying Deep Learning Techniques to Estimate Patterns of Musical Gesture\",\"url\":\"https://www.semanticscholar.org/paper/8d0805de044af93f96d518cd24739dad0652a916\",\"venue\":\"Frontiers in Psychology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3095774\",\"name\":\"Dan Oneata\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4e46f6a5fcf304a9e240258eb15e6755226ddff2\",\"title\":\"Robust and efficient models for action recognition and localization\",\"url\":\"https://www.semanticscholar.org/paper/4e46f6a5fcf304a9e240258eb15e6755226ddff2\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1608.02318\",\"authors\":[{\"authorId\":\"39707211\",\"name\":\"Karan Sikka\"},{\"authorId\":\"2515597\",\"name\":\"Gaurav Sharma\"}],\"doi\":\"10.1109/TPAMI.2017.2741482\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4b66d0afa540720bc656aa534c83d685421a077d\",\"title\":\"Discriminatively Trained Latent Ordinal Model for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/4b66d0afa540720bc656aa534c83d685421a077d\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40566477\",\"name\":\"H. Yang\"},{\"authorId\":null,\"name\":\"Chunfeng Yuan\"},{\"authorId\":\"49730034\",\"name\":\"B. Li\"},{\"authorId\":\"144708945\",\"name\":\"Yang Du\"},{\"authorId\":\"1757173\",\"name\":\"Junliang Xing\"},{\"authorId\":\"40506509\",\"name\":\"W. Hu\"},{\"authorId\":\"144555237\",\"name\":\"S. Maybank\"}],\"doi\":\"10.1016/j.patcog.2018.07.028\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"756532d707209f13c44b96e6306ac0c96e6733a5\",\"title\":\"Asymmetric 3D Convolutional Neural Networks for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/756532d707209f13c44b96e6306ac0c96e6733a5\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2461523\",\"name\":\"X. Wang\"},{\"authorId\":\"145175070\",\"name\":\"C. Qi\"},{\"authorId\":\"145684034\",\"name\":\"F. Lin\"}],\"doi\":\"10.1016/j.image.2017.05.007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"83a6d5cbc148d10e6dadcf2066df08f0c58f0161\",\"title\":\"Combined trajectories for action recognition based on saliency detection and motion boundary\",\"url\":\"https://www.semanticscholar.org/paper/83a6d5cbc148d10e6dadcf2066df08f0c58f0161\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2017},{\"arxivId\":\"1610.05613\",\"authors\":[{\"authorId\":\"145310618\",\"name\":\"Aditya Singh\"},{\"authorId\":\"3448416\",\"name\":\"Saurabh Saini\"},{\"authorId\":\"1962817\",\"name\":\"Rajvi Shah\"},{\"authorId\":\"144422343\",\"name\":\"P. J. Narayanan\"}],\"doi\":\"10.1007/978-3-319-45886-1_20\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1dcb4e97c3734e018225995c4faf8ed561550f2a\",\"title\":\"From Traditional to Modern: Domain Adaptation for Action Classification in Short Social Video Clips\",\"url\":\"https://www.semanticscholar.org/paper/1dcb4e97c3734e018225995c4faf8ed561550f2a\",\"venue\":\"GCPR\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1725551\",\"name\":\"C. Mattmann\"},{\"authorId\":\"7250428\",\"name\":\"M. Sharan\"}],\"doi\":\"10.1145/3078971.3079019\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a1fd9c1196eeb5aa446df09bd573146955735f65\",\"title\":\"Scalable Hadoop-Based Pooled Time Series of Big Video Data from the Deep Web\",\"url\":\"https://www.semanticscholar.org/paper/a1fd9c1196eeb5aa446df09bd573146955735f65\",\"venue\":\"ICMR\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48951023\",\"name\":\"F. Husain\"},{\"authorId\":\"1724418\",\"name\":\"B. Dellen\"},{\"authorId\":\"1735976\",\"name\":\"C. Torras\"}],\"doi\":\"10.1016/B978-0-12-811318-9.00020-X\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1350c9f261a5d4e037ea6f6acbdba43abea909b0\",\"title\":\"Scene understanding using deep learning\",\"url\":\"https://www.semanticscholar.org/paper/1350c9f261a5d4e037ea6f6acbdba43abea909b0\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1911.09435\",\"authors\":[{\"authorId\":\"46270766\",\"name\":\"Zhaoyang Liu\"},{\"authorId\":\"9393671\",\"name\":\"Donghao Luo\"},{\"authorId\":null,\"name\":\"Yabiao Wang\"},{\"authorId\":\"29461006\",\"name\":\"L. Wang\"},{\"authorId\":\"144970872\",\"name\":\"Ying Tai\"},{\"authorId\":\"1978245\",\"name\":\"Chengjie Wang\"},{\"authorId\":\"49298244\",\"name\":\"Jilin Li\"},{\"authorId\":\"1835006\",\"name\":\"Feiyue Huang\"},{\"authorId\":\"144720251\",\"name\":\"Tong Lu\"}],\"doi\":\"10.1609/AAAI.V34I07.6836\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fa3473f1f5d4f19ec6d561e2700a4d88dad4ccf8\",\"title\":\"TEINet: Towards an Efficient Architecture for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fa3473f1f5d4f19ec6d561e2700a4d88dad4ccf8\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1910.10056\",\"authors\":[{\"authorId\":\"1750502\",\"name\":\"X. Huang\"},{\"authorId\":\"2846597\",\"name\":\"Hossein Mousavi\"},{\"authorId\":\"144596911\",\"name\":\"Gemma Roig\"}],\"doi\":\"10.1109/ICIP40778.2020.9190781\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cfe3428bc32b957a6ae799e79d31fab88d3ee9f5\",\"title\":\"Predictive Coding Networks Meet Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cfe3428bc32b957a6ae799e79d31fab88d3ee9f5\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"1808.07272\",\"authors\":[{\"authorId\":\"2527741\",\"name\":\"Sibo Song\"},{\"authorId\":\"143770929\",\"name\":\"N. Cheung\"},{\"authorId\":\"1802086\",\"name\":\"V. Chandrasekhar\"},{\"authorId\":\"1709001\",\"name\":\"B. Mandal\"}],\"doi\":\"10.1145/3240508.3240713\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d09d663055b3b6d588bf4de2f386bb144d09aea8\",\"title\":\"Deep Adaptive Temporal Pooling for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d09d663055b3b6d588bf4de2f386bb144d09aea8\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"117454237\",\"name\":\"Zirui Qiu\"},{\"authorId\":\"144359415\",\"name\":\"J. Sun\"},{\"authorId\":\"51163848\",\"name\":\"Mingyue Guo\"},{\"authorId\":\"21836351\",\"name\":\"Mantao Wang\"},{\"authorId\":\"46334637\",\"name\":\"D. Zhang\"}],\"doi\":\"10.1007/978-981-15-0121-0_1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"71e47cea739e472da47756040e78fdae8bd21752\",\"title\":\"Survey on Deep Learning for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/71e47cea739e472da47756040e78fdae8bd21752\",\"venue\":\"ICPCSEE\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"120496321\",\"name\":\"S. Paul\"},{\"authorId\":\"145450908\",\"name\":\"Y. J. Singh\"},{\"authorId\":\"108791663\",\"name\":\"Don Boco\"},{\"authorId\":\"70533518\",\"name\":\"A. Don\"}],\"doi\":\"10.14257/IJSIP.2014.7.3.10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ef48f1d8ec88dabbf7253cb1c8a224cb95f604af\",\"title\":\"Survey on Video Analysis of Human Walking Motion\",\"url\":\"https://www.semanticscholar.org/paper/ef48f1d8ec88dabbf7253cb1c8a224cb95f604af\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2045915\",\"name\":\"Michalis Vrigkas\"},{\"authorId\":\"1727495\",\"name\":\"Christophoros Nikou\"},{\"authorId\":\"1706204\",\"name\":\"I. Kakadiaris\"}],\"doi\":\"10.3389/frobt.2015.00028\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"90a754f597958a2717862fbaa313f67b25083bf9\",\"title\":\"A Review of Human Activity Recognition Methods\",\"url\":\"https://www.semanticscholar.org/paper/90a754f597958a2717862fbaa313f67b25083bf9\",\"venue\":\"Front. Robot. AI\",\"year\":2015},{\"arxivId\":\"2007.11040\",\"authors\":[{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"2521776\",\"name\":\"B. Shuai\"},{\"authorId\":\"2397422\",\"name\":\"Joseph Tighe\"}],\"doi\":\"10.1007/978-3-030-58539-6_17\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c40990d00633b63caf78082f8570a55e2ec5abbb\",\"title\":\"Directional Temporal Modeling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c40990d00633b63caf78082f8570a55e2ec5abbb\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1505.00295\",\"authors\":[{\"authorId\":\"143928130\",\"name\":\"J. Walker\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1109/ICCV.2015.281\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"098fa9b4c3f7fb41c7a178d36f5dbb50a3ffa377\",\"title\":\"Dense Optical Flow Prediction from a Static Image\",\"url\":\"https://www.semanticscholar.org/paper/098fa9b4c3f7fb41c7a178d36f5dbb50a3ffa377\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/CVPR.2015.7298878\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5838af587938e74b5758414c384dcf16dd6e1d1e\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/5838af587938e74b5758414c384dcf16dd6e1d1e\",\"venue\":\"CVPR\",\"year\":2015},{\"arxivId\":\"2008.11378\",\"authors\":[{\"authorId\":\"153420733\",\"name\":\"Haozhi Cao\"},{\"authorId\":\"9734988\",\"name\":\"Yuecong Xu\"},{\"authorId\":\"2562263\",\"name\":\"Jianfei Yang\"},{\"authorId\":\"120974533\",\"name\":\"Kezhi Mao\"},{\"authorId\":\"2037059\",\"name\":\"Jian-Xiong Yin\"},{\"authorId\":\"144308998\",\"name\":\"S. See\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c16a94fe31835a67a8cf5e2d4d1076e0037844a9\",\"title\":\"Effective Action Recognition with Embedded Key Point Shifts\",\"url\":\"https://www.semanticscholar.org/paper/c16a94fe31835a67a8cf5e2d4d1076e0037844a9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2101.00468\",\"authors\":[{\"authorId\":\"33390229\",\"name\":\"Alina Roitberg\"},{\"authorId\":\"67310661\",\"name\":\"Monica Haurilet\"},{\"authorId\":\"1663261712\",\"name\":\"M. Mart\\u00ednez\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"558038947f541eaed14d6e0258a5ad9294070bf8\",\"title\":\"Uncertainty-sensitive Activity Recognition: a Reliability Benchmark and the CARING Models\",\"url\":\"https://www.semanticscholar.org/paper/558038947f541eaed14d6e0258a5ad9294070bf8\",\"venue\":\"\",\"year\":2021},{\"arxivId\":\"2101.00359\",\"authors\":[{\"authorId\":\"151478904\",\"name\":\"Mingjian Zhu\"},{\"authorId\":\"153773171\",\"name\":\"Chenrui Duan\"},{\"authorId\":\"1409820051\",\"name\":\"Changbin Yu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"93eb79ac45d6ff7632a57e782bf306276cf403fa\",\"title\":\"Video Captioning in Compressed Video\",\"url\":\"https://www.semanticscholar.org/paper/93eb79ac45d6ff7632a57e782bf306276cf403fa\",\"venue\":\"\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33998511\",\"name\":\"Aaron Chadha\"},{\"authorId\":\"2822935\",\"name\":\"Alhabib Abbas\"},{\"authorId\":\"2747620\",\"name\":\"Y. Andreopoulos\"}],\"doi\":\"10.1109/ICIP.2017.8296598\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"df2899462e04559c024a773d91f6e06c262e136b\",\"title\":\"Compressed-domain video classification with deep neural networks: \\u201cThere's way too much information to decode the matrix\\u201d\",\"url\":\"https://www.semanticscholar.org/paper/df2899462e04559c024a773d91f6e06c262e136b\",\"venue\":\"2017 IEEE International Conference on Image Processing (ICIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2682004\",\"name\":\"T. Perrett\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.1109/ICCVW.2017.161\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"28a7f604b98938d97f15a9a2d16c5ea177d46447\",\"title\":\"Recurrent Assistance: Cross-Dataset Training of LSTMs on Kitchen Tasks\",\"url\":\"https://www.semanticscholar.org/paper/28a7f604b98938d97f15a9a2d16c5ea177d46447\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":\"1711.08200\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"31493847\",\"name\":\"A. H. Karami\"},{\"authorId\":\"2713759\",\"name\":\"M. M. Arzani\"},{\"authorId\":\"9456273\",\"name\":\"Rahman Yousefzadeh\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f5ce640bbb9d6417fd0853ed88a9e7b93d72910d\",\"title\":\"Temporal 3D ConvNets: New Architecture and Transfer Learning for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/f5ce640bbb9d6417fd0853ed88a9e7b93d72910d\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145143348\",\"name\":\"O. V. R. Murthy\"},{\"authorId\":\"144380582\",\"name\":\"I. Radwan\"},{\"authorId\":\"1717204\",\"name\":\"R. Goecke\"}],\"doi\":\"10.1109/ICIP.2014.7025293\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"251281d9cbd207038efbde0515f4077541967239\",\"title\":\"Dense body part trajectories for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/251281d9cbd207038efbde0515f4077541967239\",\"venue\":\"2014 IEEE International Conference on Image Processing (ICIP)\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145746402\",\"name\":\"X. Jin\"},{\"authorId\":\"31482866\",\"name\":\"Zhibo Chen\"},{\"authorId\":\"2345721\",\"name\":\"S. Liu\"},{\"authorId\":\"1720145\",\"name\":\"Wei Zhou\"}],\"doi\":\"10.1007/978-3-030-03398-9_38\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8244984fb91dca8f24d3d8ded565586faf9ed9d8\",\"title\":\"Augmented Coarse-to-Fine Video Frame Synthesis with Semantic Loss\",\"url\":\"https://www.semanticscholar.org/paper/8244984fb91dca8f24d3d8ded565586faf9ed9d8\",\"venue\":\"PRCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48094509\",\"name\":\"J. Wang\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"f23b737af93469efc4b7438377a3cec2e9c8febb\",\"title\":\"Ju l 2 01 8 Learning Discriminative Video Representations Using Adversarial Perturbations\",\"url\":\"https://www.semanticscholar.org/paper/f23b737af93469efc4b7438377a3cec2e9c8febb\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67135648\",\"name\":\"Meixia Fu\"},{\"authorId\":\"145732482\",\"name\":\"N. Chen\"},{\"authorId\":\"14042415\",\"name\":\"Zhongjie Huang\"},{\"authorId\":\"51940516\",\"name\":\"Kaili Ni\"},{\"authorId\":\"47908920\",\"name\":\"Yuhao Liu\"},{\"authorId\":\"1770819\",\"name\":\"Songlin Sun\"},{\"authorId\":\"35181056\",\"name\":\"X. Ma\"}],\"doi\":\"10.1007/978-981-13-7123-3_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"608efb376175bb8b1c26076fe2fe3fbf7d750720\",\"title\":\"Human Action Recognition: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/608efb376175bb8b1c26076fe2fe3fbf7d750720\",\"venue\":\"ICSINC 2018 Fall\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2229862\",\"name\":\"Baohan Xu\"},{\"authorId\":\"145222823\",\"name\":\"H. Ye\"},{\"authorId\":\"3015119\",\"name\":\"Y. Zheng\"},{\"authorId\":\"50841852\",\"name\":\"Heng Wang\"},{\"authorId\":\"1840008\",\"name\":\"Tianyu Luwang\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1109/TIP.2019.2917283\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"151ebd3d95ca2acb17da3f2274c898a4f43bdf65\",\"title\":\"Dense Dilated Network for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/151ebd3d95ca2acb17da3f2274c898a4f43bdf65\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3104603\",\"name\":\"J. Wu\"},{\"authorId\":\"46570618\",\"name\":\"D. Hu\"}],\"doi\":\"10.1109/TMM.2013.2283846\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"31c4471c4ce56a07ab43e75c063c6e49045dff79\",\"title\":\"Learning Effective Event Models to Recognize a Large Number of Human Actions\",\"url\":\"https://www.semanticscholar.org/paper/31c4471c4ce56a07ab43e75c063c6e49045dff79\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2014},{\"arxivId\":\"2002.03342\",\"authors\":[{\"authorId\":\"47203405\",\"name\":\"Wenhao Wu\"},{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"145681032\",\"name\":\"Xiao Tan\"},{\"authorId\":\"2869725\",\"name\":\"Shifeng Chen\"},{\"authorId\":null,\"name\":\"Yi Yang\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"}],\"doi\":\"10.1109/CVPRW50498.2020.00346\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"de79226c40767073dea787327637c8415b1bc60a\",\"title\":\"Dynamic Inference: A New Approach Toward Efficient Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/de79226c40767073dea787327637c8415b1bc60a\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48933900\",\"name\":\"Q. Li\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1007/s13735-016-0117-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6f5e40d483e0ccbd3087b4da2e2715d774457665\",\"title\":\"Learning hierarchical video representation for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/6f5e40d483e0ccbd3087b4da2e2715d774457665\",\"venue\":\"International Journal of Multimedia Information Retrieval\",\"year\":2016},{\"arxivId\":\"1612.01194\",\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"1803711\",\"name\":\"H. Idrees\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/TPAMI.2018.2797266\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8984641a9566fe8929f4dc1d6ebdbcad610afd95\",\"title\":\"Online Localization and Prediction of Actions and Interactions\",\"url\":\"https://www.semanticscholar.org/paper/8984641a9566fe8929f4dc1d6ebdbcad610afd95\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49913895\",\"name\":\"Romain Belmonte\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6b7fefd13817bb4b5f028b5f98d69a573d308435\",\"title\":\"Facial Landmark Detection with Local and Global Motion Modeling. (D\\u00e9tection des points caract\\u00e9ristiques du visage par mod\\u00e9lisation des mouvements locaux et globaux)\",\"url\":\"https://www.semanticscholar.org/paper/6b7fefd13817bb4b5f028b5f98d69a573d308435\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144757965\",\"name\":\"Y. Yang\"},{\"authorId\":\"2658133\",\"name\":\"Imran Saleemi\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/TPAMI.2012.253\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e5435b147d16bf1d537b33af21378186a8f7ada0\",\"title\":\"Discovering Motion Primitives for Unsupervised Grouping and One-Shot Learning of Human Actions, Gestures, and Expressions\",\"url\":\"https://www.semanticscholar.org/paper/e5435b147d16bf1d537b33af21378186a8f7ada0\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3095774\",\"name\":\"Dan Oneata\"},{\"authorId\":\"1721683\",\"name\":\"Jakob J. Verbeek\"},{\"authorId\":\"2462253\",\"name\":\"Cordelia Schmid\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0e77fdcc952de29d9543044931f6b9d8e9220a15\",\"title\":\"Action Localization with Approximately\",\"url\":\"https://www.semanticscholar.org/paper/0e77fdcc952de29d9543044931f6b9d8e9220a15\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38101706\",\"name\":\"Xiaodong Yang\"},{\"authorId\":\"35484757\",\"name\":\"Yingli Tian\"}],\"doi\":\"10.1007/978-3-319-10605-2_47\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c18cfa44e4da994b23bd4f1657cffc692148e32b\",\"title\":\"Action Recognition Using Super Sparse Coding Vector with Spatio-temporal Awareness\",\"url\":\"https://www.semanticscholar.org/paper/c18cfa44e4da994b23bd4f1657cffc692148e32b\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3258842\",\"name\":\"J. Wang\"},{\"authorId\":\"1788029\",\"name\":\"W. Wang\"},{\"authorId\":\"8082703\",\"name\":\"Xiongtao Chen\"},{\"authorId\":\"1702330\",\"name\":\"R. Wang\"},{\"authorId\":\"48385803\",\"name\":\"W. Gao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b03b4d8b4190361ed2de66fcbb6fda0c9a0a7d89\",\"title\":\"Deep Alternative Neural Network: Exploring Contexts as Early as Possible for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b03b4d8b4190361ed2de66fcbb6fda0c9a0a7d89\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4464686\",\"name\":\"ZhenXing Zheng\"},{\"authorId\":\"2896701\",\"name\":\"Gaoyun An\"},{\"authorId\":\"144695333\",\"name\":\"Qiuqi Ruan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"5dd473a4a9c6337b083edf38b6ddf5a6aece8908\",\"title\":\"Multi-Level ResNets with Stacked SRUs for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5dd473a4a9c6337b083edf38b6ddf5a6aece8908\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1411.6031\",\"authors\":[{\"authorId\":\"2082991\",\"name\":\"Georgia Gkioxari\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/CVPR.2015.7298676\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"295a1c000c5e3fd5959bb250e8376a06efa405b1\",\"title\":\"Finding action tubes\",\"url\":\"https://www.semanticscholar.org/paper/295a1c000c5e3fd5959bb250e8376a06efa405b1\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50081487\",\"name\":\"L. Zhang\"},{\"authorId\":\"145527065\",\"name\":\"Tao Wang\"},{\"authorId\":\"34798935\",\"name\":\"Xiantong Zhen\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"235e73e8c789922cfedd723d0b1a953bbc8326a5\",\"title\":\"Evaluation of Classifiers Based On I2C Distance for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/235e73e8c789922cfedd723d0b1a953bbc8326a5\",\"venue\":\"\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38179026\",\"name\":\"Y. Shi\"},{\"authorId\":\"40161651\",\"name\":\"Yonghong Tian\"},{\"authorId\":\"34097174\",\"name\":\"Tiejun Huang\"},{\"authorId\":\"5765799\",\"name\":\"Yaowei Wang\"}],\"doi\":\"10.1109/ICME.2018.8486452\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a4d4f52f922b3f28251ae03abcca8c0a369694fd\",\"title\":\"Temporal Attentive Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a4d4f52f922b3f28251ae03abcca8c0a369694fd\",\"venue\":\"2018 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145844907\",\"name\":\"Gang Yu\"}],\"doi\":\"10.32657/10356/61739\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c430fcfc135225b1b402f08f8a1a668f9c18e888\",\"title\":\"Detecting and recognizing human action in videos\",\"url\":\"https://www.semanticscholar.org/paper/c430fcfc135225b1b402f08f8a1a668f9c18e888\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145549279\",\"name\":\"F. Romano\"},{\"authorId\":\"40555175\",\"name\":\"G. Nava\"},{\"authorId\":\"2222420\",\"name\":\"M. Azad\"},{\"authorId\":\"5106646\",\"name\":\"Jernej \\u010camernik\"},{\"authorId\":\"8458022\",\"name\":\"Stefano Dafarra\"},{\"authorId\":\"3470995\",\"name\":\"Oriane Dermy\"},{\"authorId\":\"49897080\",\"name\":\"Claudia Latella\"},{\"authorId\":\"47424488\",\"name\":\"M. Lazzaroni\"},{\"authorId\":\"34816416\",\"name\":\"R. Lober\"},{\"authorId\":\"31153432\",\"name\":\"M. Lorenzini\"},{\"authorId\":\"2202742\",\"name\":\"Daniele Pucci\"},{\"authorId\":\"3211142\",\"name\":\"Olivier Sigaud\"},{\"authorId\":\"2255650\",\"name\":\"Silvio Traversaro\"},{\"authorId\":\"1769300\",\"name\":\"J. Babi\\u010d\"},{\"authorId\":\"1763452\",\"name\":\"Serena Ivaldi\"},{\"authorId\":\"51008648\",\"name\":\"Michael Mistry\"},{\"authorId\":\"48192535\",\"name\":\"V. Padois\"},{\"authorId\":\"1692768\",\"name\":\"F. Nori\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"156ab9a85cb07611940c7a189ff1e9ce0d77cc92\",\"title\":\"Explorer The CoDyCo Project achievements and beyond : Towards Human Aware Whole-body Controllers for Physical Human Robot Interaction\",\"url\":\"https://www.semanticscholar.org/paper/156ab9a85cb07611940c7a189ff1e9ce0d77cc92\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23982870\",\"name\":\"Badour Albahar\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b6ef158d95042f39765df04373c01546524c9ccd\",\"title\":\"Im2Vid: Future Video Prediction for Static Image Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b6ef158d95042f39765df04373c01546524c9ccd\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47569464\",\"name\":\"Shiping Yang\"},{\"authorId\":\"1731486\",\"name\":\"Jin-Jang Leou\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0ab8b6ed728cb3811dfe91a3d62f402d889de886\",\"title\":\"Human Action Recognition using Improved Vector of Locally Aggregated Descriptors\",\"url\":\"https://www.semanticscholar.org/paper/0ab8b6ed728cb3811dfe91a3d62f402d889de886\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1901.03728\",\"authors\":[{\"authorId\":\"1695016\",\"name\":\"F. Pirri\"},{\"authorId\":\"65770249\",\"name\":\"L. Mauro\"},{\"authorId\":\"66073991\",\"name\":\"Edoardo Alati\"},{\"authorId\":\"2368860\",\"name\":\"Valsamis Ntouskos\"},{\"authorId\":\"66572445\",\"name\":\"Mahdieh Izadpanahkakhk\"},{\"authorId\":\"66760000\",\"name\":\"E. Omrani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"37fd19e135c065659875e2e824a455ad56689507\",\"title\":\"Anticipation and next action forecasting in video: an end-to-end model with memory\",\"url\":\"https://www.semanticscholar.org/paper/37fd19e135c065659875e2e824a455ad56689507\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1806.11008\",\"authors\":[{\"authorId\":\"1902524\",\"name\":\"Guilhem Ch\\u00e9ron\"},{\"authorId\":\"145319877\",\"name\":\"Anton Osokin\"},{\"authorId\":\"143991676\",\"name\":\"Ivan Laptev\"},{\"authorId\":\"2462253\",\"name\":\"Cordelia Schmid\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"14fee990a372bcc4cb6dc024ab7fc4ecf09dba2b\",\"title\":\"Modeling Spatio-Temporal Human Track Structure for Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/14fee990a372bcc4cb6dc024ab7fc4ecf09dba2b\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145005358\",\"name\":\"Lisa Brown\"},{\"authorId\":\"48749954\",\"name\":\"L. Cao\"},{\"authorId\":\"3076347\",\"name\":\"C. Chang\"},{\"authorId\":\"98742332\",\"name\":\"Y. Cheng\"},{\"authorId\":\"143975796\",\"name\":\"Alok Choudhary\"},{\"authorId\":\"40589056\",\"name\":\"Noel C. F. Codella\"},{\"authorId\":\"2244926\",\"name\":\"Courtenay V. Cotton\"},{\"authorId\":\"1745455\",\"name\":\"D. Ellis\"},{\"authorId\":\"33421444\",\"name\":\"Quanfu Fan\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"143812191\",\"name\":\"L. Gong\"},{\"authorId\":\"2193254\",\"name\":\"Matthew L. Hill\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\"},{\"authorId\":\"6134973\",\"name\":\"John Kender\"},{\"authorId\":\"2435677\",\"name\":\"Michele Merler\"},{\"authorId\":\"145353089\",\"name\":\"Y. Mu\"},{\"authorId\":\"1767897\",\"name\":\"Sharath Pankanti\"},{\"authorId\":\"47088868\",\"name\":\"Joshua R. Smith\"},{\"authorId\":\"1815972\",\"name\":\"F. Yu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bc40057335e589c30e0b6c7b71685ef0433b5af5\",\"title\":\"IBM Research and Columbia University TRECVID-2013 Multimedia Event Detection (MED), Multimedia Event Recounting (MER), Surveillance Event Detection (SED), and Semantic Indexing (SIN) Systems\",\"url\":\"https://www.semanticscholar.org/paper/bc40057335e589c30e0b6c7b71685ef0433b5af5\",\"venue\":\"TRECVID\",\"year\":2013},{\"arxivId\":\"1706.09317\",\"authors\":[{\"authorId\":\"47599321\",\"name\":\"Q. Wang\"},{\"authorId\":\"32811782\",\"name\":\"Ke Chen\"}],\"doi\":\"10.1007/978-3-319-71249-9_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3a6f6c4f477a50c3a513deef4c85392107d26b3b\",\"title\":\"Alternative Semantic Representations for Zero-Shot Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3a6f6c4f477a50c3a513deef4c85392107d26b3b\",\"venue\":\"ECML/PKDD\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46382329\",\"name\":\"Hongyang Li\"},{\"authorId\":\"38373223\",\"name\":\"J. Chen\"},{\"authorId\":\"2646978\",\"name\":\"Zengmin Xu\"},{\"authorId\":\"2983562\",\"name\":\"Huafeng Chen\"},{\"authorId\":\"144328091\",\"name\":\"R. Hu\"}],\"doi\":\"10.1109/ICASSP.2016.7472030\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"537abce20479d86db095efb521bcc9a052f8935a\",\"title\":\"Multiple instance discriminative dictionary learning for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/537abce20479d86db095efb521bcc9a052f8935a\",\"venue\":\"2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2016},{\"arxivId\":\"1509.08439\",\"authors\":[{\"authorId\":\"3347447\",\"name\":\"Sanath Narayan\"},{\"authorId\":\"145986798\",\"name\":\"K. Ramakrishnan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b48a77066fbd74046ec9583df5fa44ec7922dca0\",\"title\":\"Hyper-Fisher Vectors for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b48a77066fbd74046ec9583df5fa44ec7922dca0\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3015575\",\"name\":\"Qingwu Li\"},{\"authorId\":\"2389951\",\"name\":\"Haisu Cheng\"},{\"authorId\":\"1692274\",\"name\":\"Y. Zhou\"},{\"authorId\":\"40109449\",\"name\":\"Guanying Huo\"}],\"doi\":\"10.1155/2016/6750459\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e71a8bba08044fc9deded33700752ee8f4e46b71\",\"title\":\"Human Action Recognition Using Improved Salient Dense Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/e71a8bba08044fc9deded33700752ee8f4e46b71\",\"venue\":\"Comput. Intell. Neurosci.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3012914\",\"name\":\"Simon Ruffieux\"},{\"authorId\":\"1707657\",\"name\":\"D. Lalanne\"},{\"authorId\":\"1802011\",\"name\":\"E. Mugellini\"}],\"doi\":\"10.1145/2522848.2532590\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8c89de940ad0d2b543bb3cd9dfc95d4642e4b4db\",\"title\":\"ChAirGest: a challenge for multimodal mid-air gesture recognition for close HCI\",\"url\":\"https://www.semanticscholar.org/paper/8c89de940ad0d2b543bb3cd9dfc95d4642e4b4db\",\"venue\":\"ICMI '13\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145107805\",\"name\":\"S. Sun\"},{\"authorId\":\"47939010\",\"name\":\"Feng Wang\"},{\"authorId\":\"49478437\",\"name\":\"Qi Liang\"},{\"authorId\":null,\"name\":\"Liang He\"}],\"doi\":\"10.1145/3078971.3079039\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e4d53e7f4c2052940841abc08f9574655f3f7fb4\",\"title\":\"TaiChi: A Fine-Grained Action Recognition Dataset\",\"url\":\"https://www.semanticscholar.org/paper/e4d53e7f4c2052940841abc08f9574655f3f7fb4\",\"venue\":\"ICMR\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33692583\",\"name\":\"Raghuraman Gopalan\"}],\"doi\":\"10.1109/CVPR.2013.353\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"b815ce5a9307ed4077cfdc99f0cfb1a2c62cff18\",\"title\":\"Joint Sparsity-Based Representation and Analysis of Unconstrained Activities\",\"url\":\"https://www.semanticscholar.org/paper/b815ce5a9307ed4077cfdc99f0cfb1a2c62cff18\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":\"2007.05840\",\"authors\":[{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"1980683\",\"name\":\"S. Aeron\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4a2ef52618bc02c12e9edf59088d9fafee829185\",\"title\":\"Representation Learning via Adversarially-Contrastive Optimal Transport\",\"url\":\"https://www.semanticscholar.org/paper/4a2ef52618bc02c12e9edf59088d9fafee829185\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":\"1612.01669\",\"authors\":[{\"authorId\":\"8511875\",\"name\":\"Jonghwan Mun\"},{\"authorId\":\"14454974\",\"name\":\"P. H. Seo\"},{\"authorId\":\"3386346\",\"name\":\"Ilchae Jung\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":\"10.1109/ICCV.2017.312\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"00672bec9dd0e755f9c375f912c0f1c3918a6b74\",\"title\":\"MarioQA: Answering Questions by Watching Gameplay Videos\",\"url\":\"https://www.semanticscholar.org/paper/00672bec9dd0e755f9c375f912c0f1c3918a6b74\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2948848\",\"name\":\"S. Sadanand\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1109/CVPR.2012.6247806\",\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"d90cb88d89408daf4a0fe5ac341a6b9db747a556\",\"title\":\"Action bank: A high-level representation of activity in video\",\"url\":\"https://www.semanticscholar.org/paper/d90cb88d89408daf4a0fe5ac341a6b9db747a556\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2283107\",\"name\":\"Debaditya Roy\"},{\"authorId\":\"34358756\",\"name\":\"C. K. Mohan\"},{\"authorId\":\"144067348\",\"name\":\"K. R. Murty\"}],\"doi\":\"10.1109/ICIP.2018.8451226\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4c6655ab00cf3fbcb412949e85204b608937c881\",\"title\":\"Action Recognition Based on Discriminative Embedding of Actions Using Siamese Networks\",\"url\":\"https://www.semanticscholar.org/paper/4c6655ab00cf3fbcb412949e85204b608937c881\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145324038\",\"name\":\"H. Xu\"},{\"authorId\":\"35870173\",\"name\":\"Q. Tian\"},{\"authorId\":null,\"name\":\"Zhen Wang\"},{\"authorId\":\"46365410\",\"name\":\"Jianhui Wu\"}],\"doi\":\"10.1007/s11042-015-2536-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"abf0aa1d8869d87f4ef62e2da058ccfb4bf46d18\",\"title\":\"A survey on aggregating methods for action recognition with dense trajectories\",\"url\":\"https://www.semanticscholar.org/paper/abf0aa1d8869d87f4ef62e2da058ccfb4bf46d18\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yingwei Li\"},{\"authorId\":\"47001807\",\"name\":\"Y. Li\"},{\"authorId\":\"1699559\",\"name\":\"N. Vasconcelos\"}],\"doi\":\"10.1007/978-3-030-01231-1_32\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"74c19438c78a136677a7cb9004c53684a4ae56ff\",\"title\":\"RESOUND: Towards Action Recognition Without Representation Bias\",\"url\":\"https://www.semanticscholar.org/paper/74c19438c78a136677a7cb9004c53684a4ae56ff\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123175679\",\"name\":\"W. Huang\"},{\"authorId\":\"2548303\",\"name\":\"Lijie Fan\"},{\"authorId\":\"23911916\",\"name\":\"Mehrtash Harandi\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"2641547\",\"name\":\"H. Liu\"},{\"authorId\":\"143775741\",\"name\":\"W. Liu\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"}],\"doi\":\"10.1109/TIP.2018.2877936\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f5b8894cf0606b991a913b84a2a3e8b43e4c32de\",\"title\":\"Toward Efficient Action Recognition: Principal Backpropagation for Training Two-Stream Networks\",\"url\":\"https://www.semanticscholar.org/paper/f5b8894cf0606b991a913b84a2a3e8b43e4c32de\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"1712.08315\",\"authors\":[{\"authorId\":\"40913460\",\"name\":\"X. Liu\"},{\"authorId\":\"48096213\",\"name\":\"L. Zhao\"},{\"authorId\":\"50792340\",\"name\":\"Dajun Ding\"},{\"authorId\":\"31848781\",\"name\":\"Yajiao Dong\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"40ac5047e06f3e80fae6dbac8c7f16354db9b721\",\"title\":\"Deep Hashing with Category Mask for Fast Video Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/40ac5047e06f3e80fae6dbac8c7f16354db9b721\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2145942\",\"name\":\"Allah Bux Sargano\"},{\"authorId\":\"1719855\",\"name\":\"P. Angelov\"},{\"authorId\":\"2708950\",\"name\":\"Z. Habib\"}],\"doi\":\"10.3390/APP7010110\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"a87e37d43d4c47bef8992ace408de0f872739efc\",\"title\":\"A Comprehensive Review on Handcrafted and Learning-Based Action Representation Approaches for Human Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a87e37d43d4c47bef8992ace408de0f872739efc\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2744109\",\"name\":\"C. Jia\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2db974a5bc99778905540f64a3de7d408a7daf08\",\"title\":\"Low-rank tensor learning for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/2db974a5bc99778905540f64a3de7d408a7daf08\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151472652\",\"name\":\"Yuqi Huo\"},{\"authorId\":\"101246507\",\"name\":\"Xiaoli Xu\"},{\"authorId\":\"46215480\",\"name\":\"Yao Lu\"},{\"authorId\":\"2520427\",\"name\":\"Yulei Niu\"},{\"authorId\":\"48876151\",\"name\":\"Mingyu Ding\"},{\"authorId\":\"1776220\",\"name\":\"Zhiwu Lu\"},{\"authorId\":\"145406420\",\"name\":\"Tao Xiang\"},{\"authorId\":\"153693432\",\"name\":\"Jirong Wen\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"89fafbe91b31d43dc3314ffabffa79a5f5ad746f\",\"title\":\"Lightweight Action Recognition in Compressed Videos\",\"url\":\"https://www.semanticscholar.org/paper/89fafbe91b31d43dc3314ffabffa79a5f5ad746f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"1733113\",\"name\":\"T. Kanade\"},{\"authorId\":\"1774867\",\"name\":\"Yaser Sheikh\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8dac02f61e12560607f857cee3c1d5abaf40ecd0\",\"title\":\"Cooperative Learning of Audio and Video Models from Self-Supervised Synchronization\",\"url\":\"https://www.semanticscholar.org/paper/8dac02f61e12560607f857cee3c1d5abaf40ecd0\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1808.00022\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":\"10.1016/j.cviu.2019.102799\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ef7b835c451793a6ea603fa3d5441901832c404e\",\"title\":\"Analyzing human-human interactions: A survey\",\"url\":\"https://www.semanticscholar.org/paper/ef7b835c451793a6ea603fa3d5441901832c404e\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49951778\",\"name\":\"Jianxin Feng\"},{\"authorId\":\"3310042\",\"name\":\"J. Liu\"},{\"authorId\":\"48441832\",\"name\":\"Chengsheng Pan\"}],\"doi\":\"10.1109/MSN.2018.00024\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bbc1d3e8e0a5cfa29e1fca4baed0b63337c38041\",\"title\":\"Complex Behavior Recognition Based on Convolutional Neural Network: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/bbc1d3e8e0a5cfa29e1fca4baed0b63337c38041\",\"venue\":\"2018 14th International Conference on Mobile Ad-Hoc and Sensor Networks (MSN)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66933647\",\"name\":\"Debapriya Hazra\"},{\"authorId\":\"1730636\",\"name\":\"Yungcheol Byun\"}],\"doi\":\"10.3390/electronics9081312\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c03f51a33b2ffe479f2995482143207f889f2c9b\",\"title\":\"Upsampling Real-Time, Low-Resolution CCTV Videos Using Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/c03f51a33b2ffe479f2995482143207f889f2c9b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7496553\",\"name\":\"Dongli Wang\"},{\"authorId\":\"1455510526\",\"name\":\"Hexue Xiao\"},{\"authorId\":\"97713453\",\"name\":\"F. Ou\"},{\"authorId\":\"1692274\",\"name\":\"Y. Zhou\"}],\"doi\":\"10.1109/IECON.2019.8927440\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"ce95957ae9f4e5353a59e4e75da73e7db3e0f3ec\",\"title\":\"Moving Human Focus Inference Model for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ce95957ae9f4e5353a59e4e75da73e7db3e0f3ec\",\"venue\":\"IECON 2019 - 45th Annual Conference of the IEEE Industrial Electronics Society\",\"year\":2019},{\"arxivId\":\"1712.05080\",\"authors\":[{\"authorId\":\"143671632\",\"name\":\"P. Nguyen\"},{\"authorId\":\"40282288\",\"name\":\"Ting Liu\"},{\"authorId\":\"145686558\",\"name\":\"Gautam Prasad\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":\"10.1109/CVPR.2018.00706\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c661d1940518445f350aa5e49ed16f815d90bec2\",\"title\":\"Weakly Supervised Action Localization by Sparse Temporal Pooling Network\",\"url\":\"https://www.semanticscholar.org/paper/c661d1940518445f350aa5e49ed16f815d90bec2\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41185832\",\"name\":\"Xiaochun Luo\"},{\"authorId\":\"49404404\",\"name\":\"Heng Li\"},{\"authorId\":\"39483391\",\"name\":\"H. Wang\"},{\"authorId\":\"13779350\",\"name\":\"Z. Wu\"},{\"authorId\":\"145201645\",\"name\":\"Fei Dai\"},{\"authorId\":\"46690737\",\"name\":\"Dongping Cao\"}],\"doi\":\"10.1016/J.AUTCON.2019.04.001\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0ad0dbd5ac65727c06ff667b26ef77a8e51a84c5\",\"title\":\"Vision-based detection and visualization of dynamic workspaces\",\"url\":\"https://www.semanticscholar.org/paper/0ad0dbd5ac65727c06ff667b26ef77a8e51a84c5\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"34066479\",\"name\":\"Vignesh Ramanathan\"},{\"authorId\":\"144542135\",\"name\":\"D. Mahajan\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/CVPR.2018.00769\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c3e94bffaa786b099a37d58e64e8dc870c7526b9\",\"title\":\"What Makes a Video a Video: Analyzing Temporal Information in Video Understanding Models and Datasets\",\"url\":\"https://www.semanticscholar.org/paper/c3e94bffaa786b099a37d58e64e8dc870c7526b9\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"122572973\",\"name\":\"Md. Moniruzzaman\"},{\"authorId\":\"1993660364\",\"name\":\"Zhaozheng Yin\"},{\"authorId\":\"1700714\",\"name\":\"Z. He\"},{\"authorId\":\"2777406\",\"name\":\"R. Qin\"},{\"authorId\":\"2281499\",\"name\":\"Ming C. Leu\"}],\"doi\":\"10.1145/3394171.3413687\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"393aaa45767018e184499556f078640fb016475b\",\"title\":\"Action Completeness Modeling with Background Aware Networks for Weakly-Supervised Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/393aaa45767018e184499556f078640fb016475b\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"1403581832\",\"name\":\"Laura Sevilla-Lara\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"11445222\",\"name\":\"H. Wang\"}],\"doi\":\"10.1609/AAAI.V34I07.7012\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d718baf9187fa5851a9389e5e250d47ba1210e0e\",\"title\":\"FASTER Recurrent Networks for Efficient Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/d718baf9187fa5851a9389e5e250d47ba1210e0e\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2006.11808\",\"authors\":[{\"authorId\":\"143630472\",\"name\":\"Minseok Seo\"},{\"authorId\":\"120704782\",\"name\":\"Jae-Min Lee\"},{\"authorId\":\"72297759\",\"name\":\"Jongchan Park\"},{\"authorId\":\"2854596\",\"name\":\"Dong-Geol Choi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f6749b9ce96ff36892871c1a60f1f04af7845b2e\",\"title\":\"Sequential Feature Filtering Classifier\",\"url\":\"https://www.semanticscholar.org/paper/f6749b9ce96ff36892871c1a60f1f04af7845b2e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1704.02112\",\"authors\":[{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"23911916\",\"name\":\"Mehrtash Harandi\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1109/CVPR.2017.172\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"faae39b8708de562a78b2b4294694a935442844a\",\"title\":\"Generalized Rank Pooling for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/faae39b8708de562a78b2b4294694a935442844a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"65773211\",\"name\":\"Carlos Ant\\u00f4nio Caetano J\\u00fanior\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"21f42f737204ab5a8a0e9dbf1417b1bb26a07273\",\"title\":\"Motion-based representations for activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/21f42f737204ab5a8a0e9dbf1417b1bb26a07273\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144647868\",\"name\":\"Z. Zhang\"},{\"authorId\":\"1683416\",\"name\":\"Chunheng Wang\"},{\"authorId\":\"2658590\",\"name\":\"B. Xiao\"},{\"authorId\":\"145387913\",\"name\":\"W. Zhou\"},{\"authorId\":null,\"name\":\"Shuang Liu\"}],\"doi\":\"10.1007/s10044-013-0349-3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6e2041a9b5d840b0c3e4195241cd110640b1f5f3\",\"title\":\"Robust relative attributes for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/6e2041a9b5d840b0c3e4195241cd110640b1f5f3\",\"venue\":\"Pattern Analysis and Applications\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7550195\",\"name\":\"Yumeng Zhang\"},{\"authorId\":\"1380048842\",\"name\":\"Gaoguo Jia\"},{\"authorId\":\"1753356\",\"name\":\"Lele Chen\"},{\"authorId\":\"47474011\",\"name\":\"M. Zhang\"},{\"authorId\":\"102662387\",\"name\":\"J. Yong\"}],\"doi\":\"10.1145/3394171.3414003\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"1635be0f2b8d2043c4f17973f8d12cd6c936a821\",\"title\":\"Self-Paced Video Data Augmentation by Generative Adversarial Networks with Insufficient Samples\",\"url\":\"https://www.semanticscholar.org/paper/1635be0f2b8d2043c4f17973f8d12cd6c936a821\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2038787\",\"name\":\"H. Liu\"},{\"authorId\":\"1708696\",\"name\":\"A. Reibman\"},{\"authorId\":\"30949142\",\"name\":\"Aaron C. Ault\"},{\"authorId\":\"1792897\",\"name\":\"J. Krogmeier\"}],\"doi\":\"10.1109/MMSP.2018.8547117\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"698a0a6a39ff89745b8a6c58a4d49357a373b187\",\"title\":\"Video Classification of Farming Activities with Motion-Adaptive Feature Sampling\",\"url\":\"https://www.semanticscholar.org/paper/698a0a6a39ff89745b8a6c58a4d49357a373b187\",\"venue\":\"2018 IEEE 20th International Workshop on Multimedia Signal Processing (MMSP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"83200181\",\"name\":\"X. Gu\"},{\"authorId\":\"32797485\",\"name\":\"X. Xue\"},{\"authorId\":\"50981614\",\"name\":\"F. Wang\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053928\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4f856ebdb3ec93583e1ed99c0dff5deb57e9e9d7\",\"title\":\"Fine-Grained Action Recognition on a Novel Basketball Dataset\",\"url\":\"https://www.semanticscholar.org/paper/4f856ebdb3ec93583e1ed99c0dff5deb57e9e9d7\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"81781019\",\"name\":\"Minho Shim\"},{\"authorId\":\"40832988\",\"name\":\"Y. H. Kim\"},{\"authorId\":\"32850725\",\"name\":\"Kyungmin Kim\"},{\"authorId\":\"1754380\",\"name\":\"S. Kim\"}],\"doi\":\"10.1007/978-3-030-01267-0_25\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"041115cb5509466f7449451709387268a008aba2\",\"title\":\"Teaching Machines to Understand Baseball Games: Large-Scale Baseball Video Database for Multiple Video Understanding Tasks\",\"url\":\"https://www.semanticscholar.org/paper/041115cb5509466f7449451709387268a008aba2\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2008.11149\",\"authors\":[{\"authorId\":\"1390483392\",\"name\":\"Akshat Gupta\"},{\"authorId\":\"66496106\",\"name\":\"Milan Desai\"},{\"authorId\":\"24832454\",\"name\":\"Wusheng Liang\"},{\"authorId\":\"144566321\",\"name\":\"M. Kannan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"18c0b6e5a7ac62788d61eab4f888dddc75a88db2\",\"title\":\"Spatiotemporal Action Recognition in Restaurant Videos\",\"url\":\"https://www.semanticscholar.org/paper/18c0b6e5a7ac62788d61eab4f888dddc75a88db2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1978582908\",\"name\":\"Divina Govender\"},{\"authorId\":\"66491832\",\"name\":\"Jules-Raymond Tapamo\"}],\"doi\":\"10.1007/978-3-030-58799-4_58\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a3c05361e249d6ec8e68f2d9c9d33ed71cfce89\",\"title\":\"Factors Affecting the Cost to Accuracy Balance for Real-Time Video-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8a3c05361e249d6ec8e68f2d9c9d33ed71cfce89\",\"venue\":\"ICCSA\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3033982\",\"name\":\"B. Nair\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fd6c418c3bcbfa115d96d1ca6db6c66e6d3e66ee\",\"title\":\"Learning Latent Temporal Manifolds for Recognition and Prediction of Multiple Actions in Streaming Videos using Deep Networks\",\"url\":\"https://www.semanticscholar.org/paper/fd6c418c3bcbfa115d96d1ca6db6c66e6d3e66ee\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1609.02284\",\"authors\":[{\"authorId\":\"3029956\",\"name\":\"J. Gao\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1007/978-3-319-54184-6_2\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3d8ab52fa7e145b3a37fd90fd90f1105a277deee\",\"title\":\"Learning Action Concept Trees and Semantic Alignment Networks from Image-Description Data\",\"url\":\"https://www.semanticscholar.org/paper/3d8ab52fa7e145b3a37fd90fd90f1105a277deee\",\"venue\":\"ACCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2830865\",\"name\":\"Burcu A. Urgen\"},{\"authorId\":\"39173237\",\"name\":\"S. Pehlivan\"},{\"authorId\":\"2277803\",\"name\":\"A. Saygin\"}],\"doi\":\"10.1016/j.neuropsychologia.2019.02.006\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a0f614f406840e798f893907c24f80ff88bd9a9e\",\"title\":\"Distinct representations in occipito-temporal, parietal, and premotor cortex during action perception revealed by fMRI and computational modeling\",\"url\":\"https://www.semanticscholar.org/paper/a0f614f406840e798f893907c24f80ff88bd9a9e\",\"venue\":\"Neuropsychologia\",\"year\":2019},{\"arxivId\":\"1610.06906\",\"authors\":[{\"authorId\":\"3364308\",\"name\":\"S. Kang\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"473366f025c4a6e0783e6174ca914f9cb328fe70\",\"title\":\"Review of Action Recognition and Detection Methods\",\"url\":\"https://www.semanticscholar.org/paper/473366f025c4a6e0783e6174ca914f9cb328fe70\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1902.06162\",\"authors\":[{\"authorId\":\"29724362\",\"name\":\"Longlong Jing\"},{\"authorId\":\"35484757\",\"name\":\"Yingli Tian\"}],\"doi\":\"10.1109/tpami.2020.2992393\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4c94ee7df6bc2bfcac76703be4f059a79010f7e5\",\"title\":\"Self-supervised Visual Feature Learning with Deep Neural Networks: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/4c94ee7df6bc2bfcac76703be4f059a79010f7e5\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"1901.09244\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":\"10.1109/ICCV.2019.00094\",\"intent\":[\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"8c05c3ec1cf5ca7865cd0e73dd688e94537d5f1a\",\"title\":\"DistInit: Learning Video Representations Without a Single Labeled Video\",\"url\":\"https://www.semanticscholar.org/paper/8c05c3ec1cf5ca7865cd0e73dd688e94537d5f1a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1808.01106\",\"authors\":[{\"authorId\":\"144708945\",\"name\":\"Yang Du\"},{\"authorId\":null,\"name\":\"Chunfeng Yuan\"},{\"authorId\":null,\"name\":\"Bing Li\"},{\"authorId\":\"48096213\",\"name\":\"L. Zhao\"},{\"authorId\":\"2082374\",\"name\":\"Yangxi Li\"},{\"authorId\":\"40506509\",\"name\":\"W. Hu\"}],\"doi\":\"10.1007/978-3-030-01270-0_23\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"7feb72b2d475b0e82444247c0b979cc1112ddaed\",\"title\":\"Interaction-aware Spatio-temporal Pyramid Attention Networks for Action Classification\",\"url\":\"https://www.semanticscholar.org/paper/7feb72b2d475b0e82444247c0b979cc1112ddaed\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1905.01851\",\"authors\":[{\"authorId\":\"143672707\",\"name\":\"Y. Shu\"},{\"authorId\":\"38179026\",\"name\":\"Y. Shi\"},{\"authorId\":\"5765799\",\"name\":\"Yaowei Wang\"},{\"authorId\":\"34097174\",\"name\":\"Tiejun Huang\"},{\"authorId\":\"144051792\",\"name\":\"Yonghong Tian\"}],\"doi\":\"10.1038/s41598-020-63649-6\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a331c08cf6286d7a95a9837c3d9b8586b7f8e9ff\",\"title\":\"P-ODN: Prototype-based Open Deep Network for Open Set Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a331c08cf6286d7a95a9837c3d9b8586b7f8e9ff\",\"venue\":\"Scientific Reports\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9071789\",\"name\":\"Z. Liu\"},{\"authorId\":\"9173291\",\"name\":\"L. Wang\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"}],\"doi\":\"10.1007/978-3-319-92007-8_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d401b48dd13c2a6855c0f2c5f65c7f087f3d5373\",\"title\":\"Content-Aware Attention Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d401b48dd13c2a6855c0f2c5f65c7f087f3d5373\",\"venue\":\"AIAI\",\"year\":2018},{\"arxivId\":\"1508.06073\",\"authors\":[{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"73ed64803d6f2c49f01cffef8e6be8fc9b5273b8\",\"title\":\"Cooking in the kitchen: Recognizing and Segmenting Human Activities in Videos\",\"url\":\"https://www.semanticscholar.org/paper/73ed64803d6f2c49f01cffef8e6be8fc9b5273b8\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"2006.16228\",\"authors\":[{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"39257069\",\"name\":\"A. Recasens\"},{\"authorId\":\"145721402\",\"name\":\"Ros\\u00e1lia G. Schneider\"},{\"authorId\":\"2299479\",\"name\":\"R. Arandjelovi\\u0107\"},{\"authorId\":\"16092809\",\"name\":\"Jason Ramapuram\"},{\"authorId\":\"3364908\",\"name\":\"J. Fauw\"},{\"authorId\":\"1466466597\",\"name\":\"Lucas Smaira\"},{\"authorId\":\"48373216\",\"name\":\"S. Dieleman\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"4174f03c7d8d9add62ae4ecd0ec90efba680b7ae\",\"title\":\"Self-Supervised MultiModal Versatile Networks\",\"url\":\"https://www.semanticscholar.org/paper/4174f03c7d8d9add62ae4ecd0ec90efba680b7ae\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"13088433\",\"name\":\"Mahshid Majd\"},{\"authorId\":\"1682051\",\"name\":\"R. Safabakhsh\"}],\"doi\":\"10.1016/J.NEUCOM.2018.10.095\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9589c0a89cc807ab6269fff8258278af2b0902ba\",\"title\":\"Correlational Convolutional LSTM for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/9589c0a89cc807ab6269fff8258278af2b0902ba\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1711083\",\"name\":\"M. Siddiqi\"},{\"authorId\":\"40545359\",\"name\":\"R. Ali\"},{\"authorId\":\"1397539787\",\"name\":\"Sohel Rana\"},{\"authorId\":\"1975289\",\"name\":\"Een-Kee Hong\"},{\"authorId\":\"50078430\",\"name\":\"E. Kim\"},{\"authorId\":\"1700806\",\"name\":\"S. Lee\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"89eceb0bb258e45484bebef083cae4af86b7ab30\",\"title\":\"Video-Based Human Activity Recognition Using Multilevel\",\"url\":\"https://www.semanticscholar.org/paper/89eceb0bb258e45484bebef083cae4af86b7ab30\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2180291\",\"name\":\"Ruichi Yu\"},{\"authorId\":\"48016412\",\"name\":\"H. Wang\"},{\"authorId\":\"145476833\",\"name\":\"Ang Li\"},{\"authorId\":\"7674316\",\"name\":\"Jingxiao Zheng\"},{\"authorId\":\"2852035\",\"name\":\"V. Morariu\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4cac9eda716a0addb73bd7ffea2a5fb0e6ec2367\",\"title\":\"Representing Videos based on Scene Layouts for Recognizing Agent-in-Place Actions\",\"url\":\"https://www.semanticscholar.org/paper/4cac9eda716a0addb73bd7ffea2a5fb0e6ec2367\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2009.05757\",\"authors\":[{\"authorId\":\"48093158\",\"name\":\"Jinpeng Wang\"},{\"authorId\":\"151470972\",\"name\":\"Yuting Gao\"},{\"authorId\":\"104106360\",\"name\":\"Ke Li\"},{\"authorId\":\"2046022\",\"name\":\"X. Jiang\"},{\"authorId\":\"152978186\",\"name\":\"Xiao-wei Guo\"},{\"authorId\":\"1572139630\",\"name\":\"Rongrong Ji\"},{\"authorId\":\"143900241\",\"name\":\"Xing Sun\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cfff32dd150ee568384d60708622e2a3917fd6cf\",\"title\":\"Enhancing Unsupervised Video Representation Learning by Decoupling the Scene and the Motion\",\"url\":\"https://www.semanticscholar.org/paper/cfff32dd150ee568384d60708622e2a3917fd6cf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2646978\",\"name\":\"Zengmin Xu\"},{\"authorId\":\"144328091\",\"name\":\"R. Hu\"},{\"authorId\":\"38373223\",\"name\":\"J. Chen\"},{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"2983562\",\"name\":\"Huafeng Chen\"},{\"authorId\":\"46382329\",\"name\":\"Hongyang Li\"},{\"authorId\":\"40546560\",\"name\":\"Qingquan Sun\"}],\"doi\":\"10.1016/j.neucom.2016.09.106\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"6e7a80c377e405c1e5ccd4d698f5bde990b2be52\",\"title\":\"Action recognition by saliency-based dense sampling\",\"url\":\"https://www.semanticscholar.org/paper/6e7a80c377e405c1e5ccd4d698f5bde990b2be52\",\"venue\":\"Neurocomputing\",\"year\":2017},{\"arxivId\":\"1504.05524\",\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"3095774\",\"name\":\"Dan Oneata\"},{\"authorId\":\"1721683\",\"name\":\"J. Verbeek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1007/s11263-015-0846-5\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"cb84bb1f298efe45d4f7571e32083f83ae8e5ba9\",\"title\":\"A Robust and Efficient Video Representation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cb84bb1f298efe45d4f7571e32083f83ae8e5ba9\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":\"2008.02531\",\"authors\":[{\"authorId\":\"143657833\",\"name\":\"Li Tao\"},{\"authorId\":\"1524733293\",\"name\":\"Xueting Wang\"},{\"authorId\":\"145572095\",\"name\":\"T. Yamasaki\"}],\"doi\":\"10.1145/3394171.3413694\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"de4e13d7fa8de21e7a09b4ce3f6245ee4e13102c\",\"title\":\"Self-supervised Video Representation Learning Using Inter-intra Contrastive Framework\",\"url\":\"https://www.semanticscholar.org/paper/de4e13d7fa8de21e7a09b4ce3f6245ee4e13102c\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2005.02591\",\"authors\":[{\"authorId\":\"9734988\",\"name\":\"Yuecong Xu\"},{\"authorId\":\"2562263\",\"name\":\"Jianfei Yang\"},{\"authorId\":\"120974533\",\"name\":\"Kezhi Mao\"},{\"authorId\":\"2037059\",\"name\":\"Jian-Xiong Yin\"},{\"authorId\":\"144308998\",\"name\":\"S. See\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fa2d451e839f4108aaa5fdeaa5a5722f3b232d52\",\"title\":\"Exploiting Inter-Frame Regional Correlation for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fa2d451e839f4108aaa5fdeaa5a5722f3b232d52\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3012914\",\"name\":\"Simon Ruffieux\"},{\"authorId\":\"1707657\",\"name\":\"D. Lalanne\"},{\"authorId\":\"1802011\",\"name\":\"E. Mugellini\"},{\"authorId\":\"1799647\",\"name\":\"Omar Abou Khaled\"}],\"doi\":\"10.1007/978-3-319-07230-2_33\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"78aea2027f2593d053c0c4d23241b91c4a707be0\",\"title\":\"A Survey of Datasets for Human Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/78aea2027f2593d053c0c4d23241b91c4a707be0\",\"venue\":\"HCI\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24490927\",\"name\":\"A. R. Choudhury\"},{\"authorId\":\"1510665662\",\"name\":\"Saurabh Goyal\"},{\"authorId\":\"1787471\",\"name\":\"Y. Sabharwal\"},{\"authorId\":\"1845838486\",\"name\":\"Ashish Verma\"}],\"doi\":\"10.1109/CLOUD49709.2020.00065\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"515894a93640252752f542950b59c81d41138117\",\"title\":\"Variable batch size across layers for efficient prediction on CNNs\",\"url\":\"https://www.semanticscholar.org/paper/515894a93640252752f542950b59c81d41138117\",\"venue\":\"2020 IEEE 13th International Conference on Cloud Computing (CLOUD)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35900036\",\"name\":\"T. Wang\"},{\"authorId\":\"49298611\",\"name\":\"J. Li\"},{\"authorId\":\"3075750\",\"name\":\"M. Zhang\"},{\"authorId\":\"2643261\",\"name\":\"A. Zhu\"},{\"authorId\":\"2103629\",\"name\":\"H. Snoussi\"},{\"authorId\":\"145685545\",\"name\":\"Chang Choi\"}],\"doi\":\"10.1002/cpe.5302\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d8bfa4233fc87c7f0b3f1aa0c4960ad13475a04e\",\"title\":\"An enhanced 3DCNN\\u2010ConvLSTM for spatiotemporal multimedia data analysis\",\"url\":\"https://www.semanticscholar.org/paper/d8bfa4233fc87c7f0b3f1aa0c4960ad13475a04e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1399718277\",\"name\":\"Shunki Itadera\"},{\"authorId\":\"2024052975\",\"name\":\"T. Kobayashi\"},{\"authorId\":\"1403471461\",\"name\":\"Jun Nakanishi\"},{\"authorId\":\"1752849\",\"name\":\"T. Aoyama\"},{\"authorId\":\"1500530437\",\"name\":\"Yasuhisa Hasegawa\"}],\"doi\":\"10.1080/01691864.2020.1844797\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8ab7e630bf17ca5f84e96b39f0ac3e667d3d4451\",\"title\":\"Towards physical interaction-based sequential mobility assistance using latent generative model of movement state\",\"url\":\"https://www.semanticscholar.org/paper/8ab7e630bf17ca5f84e96b39f0ac3e667d3d4451\",\"venue\":\"Adv. Robotics\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47033372\",\"name\":\"L. Huang\"},{\"authorId\":\"144404225\",\"name\":\"B. Luo\"}],\"doi\":\"10.1007/s11042-017-4781-z\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8f310ac62e2e3685cf836bec5ad2dd5945f8c018\",\"title\":\"Tag refinement of micro-videos by learning from multiple data sources\",\"url\":\"https://www.semanticscholar.org/paper/8f310ac62e2e3685cf836bec5ad2dd5945f8c018\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2017}],\"corpusId\":206769852,\"doi\":\"10.1109/ICCV.2011.6126543\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":584,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"8b3b8848a311c501e704c45c6d50430ab7068956\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"3502855\",\"name\":\"M. Marszalek\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/cvprw.2009.5206557\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1fd485daa491c0debcd900b3f6bc141c3883812d\",\"title\":\"Actions in context\",\"url\":\"https://www.semanticscholar.org/paper/1fd485daa491c0debcd900b3f6bc141c3883812d\",\"venue\":\"2009 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145431234\",\"name\":\"David Elliott\"}],\"doi\":\"10.1016/s0197-2510(07)72399-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"21612b6929e2c94a501c6a2d155ba42eba79904c\",\"title\":\"In the Wild\",\"url\":\"https://www.semanticscholar.org/paper/21612b6929e2c94a501c6a2d155ba42eba79904c\",\"venue\":\"\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144810819\",\"name\":\"K. Schindler\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2008.4587730\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9b3d378ae82610b17039d4b08d05318743c039c0\",\"title\":\"Action snippets: How many frames does human action recognition require?\",\"url\":\"https://www.semanticscholar.org/paper/9b3d378ae82610b17039d4b08d05318743c039c0\",\"venue\":\"2008 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49049934\",\"name\":\"J. Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0ec48ac86456cea3d6d6172ca81ef68e98b21a61\",\"title\":\"The PASCAL Visual Object Classes Challenge\",\"url\":\"https://www.semanticscholar.org/paper/0ec48ac86456cea3d6d6172ca81ef68e98b21a61\",\"venue\":\"\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"M. Thirkettle\"},{\"authorId\":null,\"name\":\"C. Benton\"},{\"authorId\":null,\"name\":\"N. Scott-Samuel\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Contributions of form\",\"url\":\"\",\"venue\":\"motion and task to biological motion perception. Journal of Vision, 9(3):1\\u201311\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1800425\",\"name\":\"Jingen Liu\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"},{\"authorId\":\"3261071\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/CVPR.2009.5206744\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"11fa6281bd846dba0d303d4a6a5988d8cd1c2100\",\"title\":\"Recognizing realistic actions from videos\",\"url\":\"https://www.semanticscholar.org/paper/11fa6281bd846dba0d303d4a6a5988d8cd1c2100\",\"venue\":\"CVPR\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24492532\",\"name\":\"Jian-xiong Xiao\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1865091\",\"name\":\"Krista A. Ehinger\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/CVPR.2010.5539970\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"908091b4a8757c3b2f7d9cfa2c4f616ee12c5157\",\"title\":\"SUN database: Large-scale scene recognition from abbey to zoo\",\"url\":\"https://www.semanticscholar.org/paper/908091b4a8757c3b2f7d9cfa2c4f616ee12c5157\",\"venue\":\"2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145163052\",\"name\":\"F. Gao\"},{\"authorId\":\"1944486\",\"name\":\"L. Viry\"},{\"authorId\":\"6023137\",\"name\":\"M. Maugey\"},{\"authorId\":\"31430841\",\"name\":\"P. Poulin\"},{\"authorId\":\"10338847\",\"name\":\"N. Mano\"}],\"doi\":\"10.1038/ncomms1000\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b02f96d15de1a0428bab7543351810537c8e3674\",\"title\":\"Engineering hybrid nanotube wires for high-power biofuel cells.\",\"url\":\"https://www.semanticscholar.org/paper/b02f96d15de1a0428bab7543351810537c8e3674\",\"venue\":\"Nature communications\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"14788836\",\"name\":\"G. Jansson\"},{\"authorId\":\"1422441964\",\"name\":\"Sten Sture Bergstr\\u201dm\"},{\"authorId\":\"145978461\",\"name\":\"W. Epstein\"},{\"authorId\":\"152516123\",\"name\":\"S. Bergstrom\"}],\"doi\":\"10.4324/9780203773796\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ad922c0d14819a5d5bc0479c856dcd29c207dcd8\",\"title\":\"Perceiving events and objects\",\"url\":\"https://www.semanticscholar.org/paper/ad922c0d14819a5d5bc0479c856dcd29c207dcd8\",\"venue\":\"\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145160921\",\"name\":\"Bryan C. Russell\"},{\"authorId\":\"143738177\",\"name\":\"J. Yuen\"}],\"doi\":\"10.1109/JPROC.2010.2050290\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"22ec32ab1494698e25aa895092203cb71864b742\",\"title\":\"LabelMe: Online Image Annotation and Applications\",\"url\":\"https://www.semanticscholar.org/paper/22ec32ab1494698e25aa895092203cb71864b742\",\"venue\":\"Proceedings of the IEEE\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123135459\",\"name\":\"Mikel D. Rodriguez\"},{\"authorId\":\"144643948\",\"name\":\"Javed Ahmed\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/CVPR.2008.4587727\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1c2629d53fd73ee42fb9a67b4d656688ef6a005f\",\"title\":\"Action MACH a spatio-temporal Maximum Average Correlation Height filter for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/1c2629d53fd73ee42fb9a67b4d656688ef6a005f\",\"venue\":\"2008 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"}],\"doi\":\"10.1016/j.cviu.2005.09.012\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aedb8df8f953429ec5a6df99fda5c5d71dbee4ff\",\"title\":\"Learning Generative Visual Models from Few Training Examples: An Incremental Bayesian Approach Tested on 101 Object Categories\",\"url\":\"https://www.semanticscholar.org/paper/aedb8df8f953429ec5a6df99fda5c5d71dbee4ff\",\"venue\":\"2004 Conference on Computer Vision and Pattern Recognition Workshop\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3502855\",\"name\":\"M. Marszalek\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/CVPR.2009.5206557\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c26906b6dab02083ffd01fd27d9087597999bc0e\",\"title\":\"Actions in context\",\"url\":\"https://www.semanticscholar.org/paper/c26906b6dab02083ffd01fd27d9087597999bc0e\",\"venue\":\"CVPR\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"3205375\",\"name\":\"T. Lindeberg\"}],\"doi\":\"10.1109/ICCV.2003.1238378\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f90d79809325d2b78e35a79ecb372407f81b3993\",\"title\":\"Space-time interest points\",\"url\":\"https://www.semanticscholar.org/paper/f90d79809325d2b78e35a79ecb372407f81b3993\",\"venue\":\"Proceedings Ninth IEEE International Conference on Computer Vision\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1800425\",\"name\":\"Jingen Liu\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/CVPRW.2009.5206744\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aca29d7bbbf54078f842c8ca1d75d8d8c68191d2\",\"title\":\"Recognizing realistic actions from videos \\u201cin the wild\\u201d\",\"url\":\"https://www.semanticscholar.org/paper/aca29d7bbbf54078f842c8ca1d75d8d8c68191d2\",\"venue\":\"2009 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"120896463\",\"name\":\"Chih-Wei Chen\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/978-3-642-15552-9_29\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"994a7b903b937f8b177c035db86852091fd26aa7\",\"title\":\"Modeling Temporal Structure of Decomposable Motion Segments for Activity Classification\",\"url\":\"https://www.semanticscholar.org/paper/994a7b903b937f8b177c035db86852091fd26aa7\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"}],\"doi\":\"10.1109/CVPR.2004.383\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ed9db7b20e019cdb1c7db8b7921221ee2d9f36e2\",\"title\":\"Learning Generative Visual Models from Few Training Examples: An Incremental Bayesian Approach Tested on 101 Object Categories\",\"url\":\"https://www.semanticscholar.org/paper/ed9db7b20e019cdb1c7db8b7921221ee2d9f36e2\",\"venue\":\"CVPR Workshops\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46786172\",\"name\":\"M. Thirkettle\"},{\"authorId\":\"48909918\",\"name\":\"C. Benton\"},{\"authorId\":\"1403968272\",\"name\":\"N. E. Scott-Samuel\"}],\"doi\":\"10.1167/9.3.28\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8742c47168cfb0809bce5d455fecfb5fc0505336\",\"title\":\"Contributions of form, motion and task to biological motion perception.\",\"url\":\"https://www.semanticscholar.org/paper/8742c47168cfb0809bce5d455fecfb5fc0505336\",\"venue\":\"Journal of vision\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"M. Everingham\"},{\"authorId\":null,\"name\":\"L. Van Gool\"},{\"authorId\":null,\"name\":\"C.K.I. Williams\"},{\"authorId\":null,\"name\":\"J. Winn\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and A\",\"url\":\"\",\"venue\":\"Zisserman. The PASCAL Visual Object Classes Challenge 2010 \",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2119821\",\"name\":\"Daniel Weinland\"},{\"authorId\":\"1719388\",\"name\":\"E. Boyer\"},{\"authorId\":\"2898850\",\"name\":\"R\\u00e9mi Ronfard\"}],\"doi\":\"10.1109/ICCV.2007.4408849\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"deb259adece9095000a79f86aabfb303580be1cd\",\"title\":\"Action Recognition from Arbitrary Views using 3D Exemplars\",\"url\":\"https://www.semanticscholar.org/paper/deb259adece9095000a79f86aabfb303580be1cd\",\"venue\":\"2007 IEEE 11th International Conference on Computer Vision\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1689350\",\"name\":\"Eero P. Simoncelli\"},{\"authorId\":\"2360881\",\"name\":\"D. Heeger\"}],\"doi\":\"10.1016/S0042-6989(97)00183-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4df17f8bbaf8e84f9ebe88c59f88b24babfac9b3\",\"title\":\"A model of neuronal responses in visual area MT\",\"url\":\"https://www.semanticscholar.org/paper/4df17f8bbaf8e84f9ebe88c59f88b24babfac9b3\",\"venue\":\"Vision Research\",\"year\":1998},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"1] http://serre-lab.clps.brown.edu/resources\",\"url\":\"\",\"venue\":\"1] http://serre-lab.clps.brown.edu/resources\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50170517\",\"name\":\"Moshe Blank\"},{\"authorId\":\"3089071\",\"name\":\"Lena Gorelick\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"144611617\",\"name\":\"M. Irani\"},{\"authorId\":\"1760994\",\"name\":\"R. Basri\"}],\"doi\":\"10.1109/ICCV.2005.28\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1a9eb04b9b07d4a58aa78eb9f68a77ade0199fab\",\"title\":\"Actions as space-time shapes\",\"url\":\"https://www.semanticscholar.org/paper/1a9eb04b9b07d4a58aa78eb9f68a77ade0199fab\",\"venue\":\"Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144043541\",\"name\":\"R. Blake\"},{\"authorId\":\"1995854\",\"name\":\"M. Shiffrar\"}],\"doi\":\"10.1146/ANNUREV.PSYCH.57.102904.190152\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ccdddae016dcc15643c9cbc2e26da9585737604b\",\"title\":\"Perception of human motion.\",\"url\":\"https://www.semanticscholar.org/paper/ccdddae016dcc15643c9cbc2e26da9585737604b\",\"venue\":\"Annual review of psychology\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"35033378\",\"name\":\"M. M. Ullah\"},{\"authorId\":\"2909350\",\"name\":\"Alexander Kl\\u00e4ser\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.5244/C.23.124\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a39e6968580762ac5ae3cd064e86e1849f3efb7f\",\"title\":\"Evaluation of Local Spatio-temporal Features for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a39e6968580762ac5ae3cd064e86e1849f3efb7f\",\"venue\":\"BMVC\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1023/A:1011139631724\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"869171b2f56cfeaa9b81b2626cb4956fea590a57\",\"title\":\"Modeling the Shape of the Scene: A Holistic Representation of the Spatial Envelope\",\"url\":\"https://www.semanticscholar.org/paper/869171b2f56cfeaa9b81b2626cb4956fea590a57\",\"venue\":\"International Journal of Computer Vision\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35208858\",\"name\":\"Subhransu Maji\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/CVPR.2011.5995631\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"12fe91ab616b797e22543ae6c2afa7866dbc9a49\",\"title\":\"Action recognition from a distributed representation of pose and appearance\",\"url\":\"https://www.semanticscholar.org/paper/12fe91ab616b797e22543ae6c2afa7866dbc9a49\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"}],\"doi\":\"10.1109/TPAMI.2008.128\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"54d2b5c64a67f65c5dd812b89e07973f97699552\",\"title\":\"80 Million Tiny Images: A Large Data Set for Nonparametric Object and Scene Recognition\",\"url\":\"https://www.semanticscholar.org/paper/54d2b5c64a67f65c5dd812b89e07973f97699552\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2712738\",\"name\":\"C. Sch\\u00fcldt\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"3033284\",\"name\":\"B. Caputo\"}],\"doi\":\"10.1109/icpr.2004.1334462\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b480f6a3750b4cebaf1db205692c8321d45926a2\",\"title\":\"Recognizing human actions: a local SVM approach\",\"url\":\"https://www.semanticscholar.org/paper/b480f6a3750b4cebaf1db205692c8321d45926a2\",\"venue\":\"Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004.\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3056091\",\"name\":\"M. Everingham\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"},{\"authorId\":\"145715698\",\"name\":\"C. K. Williams\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6a2ed19ac684022aa3186887cd4893484ab8f80c\",\"title\":\"The PASCAL visual object classes challenge 2006 (VOC2006) results\",\"url\":\"https://www.semanticscholar.org/paper/6a2ed19ac684022aa3186887cd4893484ab8f80c\",\"venue\":\"\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2676982\",\"name\":\"Hueihan Jhuang\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"},{\"authorId\":\"145128145\",\"name\":\"Lior Wolf\"},{\"authorId\":\"1685292\",\"name\":\"T. Poggio\"}],\"doi\":\"10.1109/ICCV.2007.4408988\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"124d967683544973581f951ee93b3f7c069e3ced\",\"title\":\"A Biologically Inspired System for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/124d967683544973581f951ee93b3f7c069e3ced\",\"venue\":\"2007 IEEE 11th International Conference on Computer Vision\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"3502855\",\"name\":\"M. Marszalek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"3261451\",\"name\":\"Benjamin Rozenfeld\"}],\"doi\":\"10.1109/CVPR.2008.4587756\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0f86767732f76f478d5845f2e59f99ba106e9265\",\"title\":\"Learning realistic human actions from movies\",\"url\":\"https://www.semanticscholar.org/paper/0f86767732f76f478d5845f2e59f99ba106e9265\",\"venue\":\"2008 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38916673\",\"name\":\"B. Yao\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2010.5540234\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"50499aa9af9b4be0f5ef3ffbdd24299f3c402586\",\"title\":\"Grouplet: A structured image representation for recognizing human and object interactions\",\"url\":\"https://www.semanticscholar.org/paper/50499aa9af9b4be0f5ef3ffbdd24299f3c402586\",\"venue\":\"2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"47680287\",\"name\":\"W. Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2009.5206848\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1b47265245e8db53a553049dcb27ed3e495fd625\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/1b47265245e8db53a553049dcb27ed3e495fd625\",\"venue\":\"CVPR 2009\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145160921\",\"name\":\"Bryan C. Russell\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"49312774\",\"name\":\"K. Murphy\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"}],\"doi\":\"10.1007/s11263-007-0090-8\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"092c275005ae49dc1303214f6d02d134457c7053\",\"title\":\"LabelMe: A Database and Web-Based Tool for Image Annotation\",\"url\":\"https://www.semanticscholar.org/paper/092c275005ae49dc1303214f6d02d134457c7053\",\"venue\":\"International Journal of Computer Vision\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2676982\",\"name\":\"Hueihan Jhuang\"},{\"authorId\":\"1930964\",\"name\":\"E. Garrote\"},{\"authorId\":\"2243801\",\"name\":\"J. Mutch\"},{\"authorId\":\"3863128\",\"name\":\"X. Yu\"},{\"authorId\":\"5770339\",\"name\":\"Vinita Khilnani\"},{\"authorId\":\"145031879\",\"name\":\"T. Poggio\"},{\"authorId\":\"145909787\",\"name\":\"A. D. Steele\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"}],\"doi\":\"10.1038/ncomms1064\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ae0d572735f4b65194532e287ebc4b6df8ddb50b\",\"title\":\"Automated home-cage behavioural phenotyping of mice.\",\"url\":\"https://www.semanticscholar.org/paper/ae0d572735f4b65194532e287ebc4b6df8ddb50b\",\"venue\":\"Nature communications\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"},{\"authorId\":\"145128145\",\"name\":\"Lior Wolf\"},{\"authorId\":\"1747918\",\"name\":\"S. Bileschi\"},{\"authorId\":\"1996960\",\"name\":\"M. Riesenhuber\"},{\"authorId\":\"1685292\",\"name\":\"T. Poggio\"}],\"doi\":\"10.1109/TPAMI.2007.56\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"71e3d9fc53ba14c2feeb7390f0dc99076553b05a\",\"title\":\"Robust Object Recognition with Cortex-Like Mechanisms\",\"url\":\"https://www.semanticscholar.org/paper/71e3d9fc53ba14c2feeb7390f0dc99076553b05a\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2119821\",\"name\":\"Daniel Weinland\"},{\"authorId\":\"2898850\",\"name\":\"R\\u00e9mi Ronfard\"},{\"authorId\":\"1719388\",\"name\":\"E. Boyer\"}],\"doi\":\"10.1016/j.cviu.2010.10.002\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"678b758cb1a057fd38d8e6808535f64686bfca71\",\"title\":\"A survey of vision-based methods for action representation, segmentation and recognition\",\"url\":\"https://www.semanticscholar.org/paper/678b758cb1a057fd38d8e6808535f64686bfca71\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2712738\",\"name\":\"C. Sch\\u00fcldt\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"3033284\",\"name\":\"B. Caputo\"}],\"doi\":\"10.1109/ICPR.2004.747\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"046ad9e42bc9ca6c63406836b95cf1bb62271249\",\"title\":\"Recognizing human actions: a local SVM approach\",\"url\":\"https://www.semanticscholar.org/paper/046ad9e42bc9ca6c63406836b95cf1bb62271249\",\"venue\":\"ICPR 2004\",\"year\":2004}],\"title\":\"HMDB: A large video database for human motion recognition\",\"topics\":[{\"topic\":\"Human Metabolome Database\",\"topicId\":\"214982\",\"url\":\"https://www.semanticscholar.org/topic/214982\"},{\"topic\":\"Computer vision\",\"topicId\":\"5332\",\"url\":\"https://www.semanticscholar.org/topic/5332\"},{\"topic\":\"Kinesiology\",\"topicId\":\"113188\",\"url\":\"https://www.semanticscholar.org/topic/113188\"},{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"},{\"topic\":\"Hidden surface determination\",\"topicId\":\"54802\",\"url\":\"https://www.semanticscholar.org/topic/54802\"},{\"topic\":\"Video clip\",\"topicId\":\"30493\",\"url\":\"https://www.semanticscholar.org/topic/30493\"},{\"topic\":\"Scalability\",\"topicId\":\"1360\",\"url\":\"https://www.semanticscholar.org/topic/1360\"}],\"url\":\"https://www.semanticscholar.org/paper/8b3b8848a311c501e704c45c6d50430ab7068956\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011}\n"