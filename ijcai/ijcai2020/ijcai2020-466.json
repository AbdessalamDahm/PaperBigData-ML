"{\"abstract\":\"Generating diverse behaviors for game artificial intelligence (Game AI) has been long recognized as a challenging task in the game industry. Designing a Game AI with a satisfying behavioral characteristic (style) heavily depends on the domain knowledge and is hard to achieve manually. Deep reinforcement learning sheds light on advancing the automatic Game AI design. However, most of them focus on creating a superhuman Game AI, ignoring the importance of behavioral diversity in games. To bridge the gap, we introduce a new framework, named EMOGI, which can automatically generate desirable styles with almost no domain knowledge. More importantly, EMOGI succeeds in creating a range of diverse styles, providing behavior-diverse Game AIs. Evaluations on the Atari and real commercial games indicate that, compared to existing algorithms, EMOGI performs better in generating diverse behaviors and significantly improves the efficiency of Game AI design.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"8510889\",\"name\":\"Ruimin Shen\",\"url\":\"https://www.semanticscholar.org/author/8510889\"},{\"authorId\":\"1752775197\",\"name\":\"Yan Zheng\",\"url\":\"https://www.semanticscholar.org/author/1752775197\"},{\"authorId\":\"40513470\",\"name\":\"Jianye Hao\",\"url\":\"https://www.semanticscholar.org/author/40513470\"},{\"authorId\":\"1889014\",\"name\":\"Zhaopeng Meng\",\"url\":\"https://www.semanticscholar.org/author/1889014\"},{\"authorId\":\"2519427\",\"name\":\"Yingfeng Chen\",\"url\":\"https://www.semanticscholar.org/author/2519427\"},{\"authorId\":\"3120655\",\"name\":\"Changjie Fan\",\"url\":\"https://www.semanticscholar.org/author/3120655\"},{\"authorId\":null,\"name\":\"Yang Liu\",\"url\":null}],\"citationVelocity\":0,\"citations\":[],\"corpusId\":220484635,\"doi\":\"10.24963/ijcai.2020/466\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":false,\"is_publisher_licensed\":false,\"paperId\":\"267cf56e24fc792502613f11f4270dc83c975e7d\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Christoffer Holmg\\u00e5rd\"},{\"authorId\":null,\"name\":\"Antonios Liapis\"},{\"authorId\":null,\"name\":\"Julian Togelius\"},{\"authorId\":null,\"name\":\"Georgios N Yannakakis. Personas versus clones for player de Computing\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"pages 159\\u2013166\",\"url\":\"\",\"venue\":\"Springer,\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1703555\",\"name\":\"A. Agapitos\"},{\"authorId\":\"1810053\",\"name\":\"J. Togelius\"},{\"authorId\":\"145815031\",\"name\":\"S. Lucas\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"},{\"authorId\":\"1746988\",\"name\":\"A. Konstantinidis\"}],\"doi\":\"10.1109/CIG.2008.5035632\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4dad31c570bc437078949863f93e7eb41614a6d0\",\"title\":\"Generating diverse opponents with multiobjective evolution\",\"url\":\"https://www.semanticscholar.org/paper/4dad31c570bc437078949863f93e7eb41614a6d0\",\"venue\":\"2008 IEEE Symposium On Computational Intelligence and Games\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145001045\",\"name\":\"Y. Zheng\"},{\"authorId\":\"1889014\",\"name\":\"Zhaopeng Meng\"},{\"authorId\":\"40513470\",\"name\":\"Jianye Hao\"},{\"authorId\":\"2079174\",\"name\":\"Zongzhang Zhang\"},{\"authorId\":\"3449314\",\"name\":\"Tianpei Yang\"},{\"authorId\":\"3120655\",\"name\":\"Changjie Fan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6b5c4f1f4b4ec90383f43f8bb41ef9758762a53e\",\"title\":\"A Deep Bayesian Policy Reuse Approach Against Non-Stationary Agents\",\"url\":\"https://www.semanticscholar.org/paper/6b5c4f1f4b4ec90383f43f8bb41ef9758762a53e\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Creating Pro-Level AI for a Real-Time Fighting Game Using Deep Reinforcement Learning. arXiv.org\",\"url\":\"\",\"venue\":\"Learning from Demonstration for Shaping through Inverse Reinforcement Learning. AAMAS\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145528658\",\"name\":\"G. Kendall\"}],\"doi\":\"10.1109/TCIAIG.2015.2409514\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9046f46d088eee7be4af8be5ffea602394a937c0\",\"title\":\"Editorial: IEEE Transactions on Computational Intelligence and AI in Games\",\"url\":\"https://www.semanticscholar.org/paper/9046f46d088eee7be4af8be5ffea602394a937c0\",\"venue\":\"IEEE Trans. Comput. Intell. AI Games\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3329979\",\"name\":\"Anders Drachen\"},{\"authorId\":\"1802939\",\"name\":\"Alessandro Canossa\"},{\"authorId\":\"1686193\",\"name\":\"Georgios N. Yannakakis\"}],\"doi\":\"10.1109/CIG.2009.5286500\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a02238f4c5608de0b48bcf8d700479a4a1dec147\",\"title\":\"Player modeling using self-organization in Tomb Raider: Underworld\",\"url\":\"https://www.semanticscholar.org/paper/a02238f4c5608de0b48bcf8d700479a4a1dec147\",\"venue\":\"2009 IEEE Symposium on Computational Intelligence and Games\",\"year\":2009},{\"arxivId\":\"2005.07099\",\"authors\":[{\"authorId\":\"48480213\",\"name\":\"Jianwen Sun\"},{\"authorId\":\"51049314\",\"name\":\"Tianwei Zhang\"},{\"authorId\":\"49419199\",\"name\":\"Xiaofei Xie\"},{\"authorId\":\"143828252\",\"name\":\"L. Ma\"},{\"authorId\":\"1418499676\",\"name\":\"Yan Zheng\"},{\"authorId\":\"5781518\",\"name\":\"Kangjie Chen\"},{\"authorId\":\"40457423\",\"name\":\"Y. Liu\"}],\"doi\":\"10.1609/AAAI.V34I04.6047\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"859c95451018e69ce6bc9d4031b38a4959d495ff\",\"title\":\"Stealthy and Efficient Adversarial Attacks against Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/859c95451018e69ce6bc9d4031b38a4959d495ff\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Damian Isla\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Halo 3-building a better battle\",\"url\":\"\",\"venue\":\"Game Developers Conference, GDC,\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Alexandros Agapitos\"},{\"authorId\":null,\"name\":\"Julian Togelius\"},{\"authorId\":null,\"name\":\"Simon M. Lucas\"},{\"authorId\":null,\"name\":\"J\\u00fcrgen Schmidhuber\"},{\"authorId\":null,\"name\":\"Andreas Konstantinidis. Generating diverse opponents with  evolution\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In IEEE Symposium On Computational Intelligence and Games\",\"url\":\"\",\"venue\":\"IEEE,\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5886094\",\"name\":\"P. Cochat\"},{\"authorId\":\"13267685\",\"name\":\"L. Vaucoret\"},{\"authorId\":\"31455512\",\"name\":\"J. Sarles\"}],\"doi\":\"10.1016/j.arcped.2012.01.013\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"10d85561e4aafc516d10064f30dff05b41f70afe\",\"title\":\"[Et al].\",\"url\":\"https://www.semanticscholar.org/paper/10d85561e4aafc516d10064f30dff05b41f70afe\",\"venue\":\"Archives de pediatrie : organe officiel de la Societe francaise de pediatrie\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1742557\",\"name\":\"I. Szita\"},{\"authorId\":\"32767016\",\"name\":\"M. Ponsen\"},{\"authorId\":\"1746390\",\"name\":\"P. Spronck\"}],\"doi\":\"10.1109/TCIAIG.2009.2018706\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8156bfa6e88f514c3d600ba5e17a438ab090df1e\",\"title\":\"Effective and Diverse Adaptive Game AI\",\"url\":\"https://www.semanticscholar.org/paper/8156bfa6e88f514c3d600ba5e17a438ab090df1e\",\"venue\":\"IEEE Transactions on Computational Intelligence and AI in Games\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Newzoo\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Global games market report\",\"url\":\"\",\"venue\":\"https://newzoo.com/solutions/standard/market-forecasts/ global-games-market-report,\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699645\",\"name\":\"R. Sutton\"},{\"authorId\":\"1730590\",\"name\":\"A. Barto\"}],\"doi\":\"10.1109/TNN.1998.712192\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"97efafdb4a3942ab3efba53ded7413199f79c054\",\"title\":\"Reinforcement Learning: An Introduction\",\"url\":\"https://www.semanticscholar.org/paper/97efafdb4a3942ab3efba53ded7413199f79c054\",\"venue\":\"IEEE Transactions on Neural Networks\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1418499676\",\"name\":\"Yan Zheng\"},{\"authorId\":\"153645633\",\"name\":\"Changjie Fan\"},{\"authorId\":\"145564459\",\"name\":\"X. Xie\"},{\"authorId\":\"144121517\",\"name\":\"Ting Su\"},{\"authorId\":\"143828252\",\"name\":\"L. Ma\"},{\"authorId\":\"40513470\",\"name\":\"Jianye Hao\"},{\"authorId\":\"2528357\",\"name\":\"Zhao-Peng Meng\"},{\"authorId\":null,\"name\":\"Yang Liu\"},{\"authorId\":\"2613907\",\"name\":\"R. Shen\"},{\"authorId\":\"152829349\",\"name\":\"Yingfeng Chen\"}],\"doi\":\"10.1109/ASE.2019.00077\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"70af259ee51166292f485093a1ff0abf3bd6f118\",\"title\":\"Wuji: Automatic Online Combat Game Testing Using Evolutionary Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/70af259ee51166292f485093a1ff0abf3bd6f118\",\"venue\":\"2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)\",\"year\":2019},{\"arxivId\":\"1504.04909\",\"authors\":[{\"authorId\":\"145312416\",\"name\":\"Jean-Baptiste Mouret\"},{\"authorId\":\"2552141\",\"name\":\"J. Clune\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"45373921f06a6efebefa6189d2dd80362ab0836e\",\"title\":\"Illuminating search spaces by mapping elites\",\"url\":\"https://www.semanticscholar.org/paper/45373921f06a6efebefa6189d2dd80362ab0836e\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Inseok Oh\"},{\"authorId\":null,\"name\":\"Seungeun Rho\"},{\"authorId\":null,\"name\":\"Sangbin Moon\"},{\"authorId\":null,\"name\":\"Seongho Son\"},{\"authorId\":null,\"name\":\"Hyoil Lee\"},{\"authorId\":null,\"name\":\"Jinyun Chung\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Creating ProLevel AI for a Real-Time Fighting Game Using Deep Reinforcement Learning\",\"url\":\"\",\"venue\":\"arXiv.org, April\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1757823\",\"name\":\"Christoffer Holmg\\u00e5rd\"},{\"authorId\":\"1713331\",\"name\":\"Antonios Liapis\"},{\"authorId\":\"1810053\",\"name\":\"J. Togelius\"},{\"authorId\":\"1686193\",\"name\":\"Georgios N. Yannakakis\"}],\"doi\":\"10.1007/978-3-662-45212-7_20\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8438874c5c4c6aa15fe707cfefcf3a9ddcc26b90\",\"title\":\"Personas versus Clones for Player Decision Modeling\",\"url\":\"https://www.semanticscholar.org/paper/8438874c5c4c6aa15fe707cfefcf3a9ddcc26b90\",\"venue\":\"ICEC\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3255983\",\"name\":\"V. Mnih\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"},{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"1392331736\",\"name\":\"Andrei A. Rusu\"},{\"authorId\":\"144056327\",\"name\":\"J. Veness\"},{\"authorId\":\"1397980088\",\"name\":\"Marc G. Bellemare\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"3137672\",\"name\":\"Martin A. Riedmiller\"},{\"authorId\":\"1397979864\",\"name\":\"Andreas K. Fidjeland\"},{\"authorId\":\"2273072\",\"name\":\"Georg Ostrovski\"},{\"authorId\":\"145386761\",\"name\":\"S. Petersen\"},{\"authorId\":\"48878752\",\"name\":\"C. Beattie\"},{\"authorId\":\"49813280\",\"name\":\"A. Sadik\"},{\"authorId\":\"2460849\",\"name\":\"Ioannis Antonoglou\"},{\"authorId\":\"153907173\",\"name\":\"H. King\"},{\"authorId\":\"2106164\",\"name\":\"D. Kumaran\"},{\"authorId\":\"1688276\",\"name\":\"Daan Wierstra\"},{\"authorId\":\"34313265\",\"name\":\"S. Legg\"},{\"authorId\":\"48987704\",\"name\":\"Demis Hassabis\"}],\"doi\":\"10.1038/nature14236\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e0e9a94c4a6ba219e768b4e59f72c18f0a22e23d\",\"title\":\"Human-level control through deep reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/e0e9a94c4a6ba219e768b4e59f72c18f0a22e23d\",\"venue\":\"Nature\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39799304\",\"name\":\"Joel Lehman\"},{\"authorId\":\"1846883\",\"name\":\"K. Stanley\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6d459da1ff73ec7225e92842341605e2b90d0da2\",\"title\":\"Evolving a Diversity of Creatures through Novelty Search and Local Competition\",\"url\":\"https://www.semanticscholar.org/paper/6d459da1ff73ec7225e92842341605e2b90d0da2\",\"venue\":\"\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Greg Alt\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"The suffering: A game ai case study\",\"url\":\"\",\"venue\":\"Challenges in Game AI workshop, Nineteenth national conference on Artificial Intelligence, pages 134\\u2013 138,\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145080287\",\"name\":\"K. Deb\"},{\"authorId\":\"32775848\",\"name\":\"Ram Bhushan Agrawal\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b8ee6b68520ae0291075cb1408046a7dff9dd9ad\",\"title\":\"Simulated Binary Crossover for Continuous Search Space\",\"url\":\"https://www.semanticscholar.org/paper/b8ee6b68520ae0291075cb1408046a7dff9dd9ad\",\"venue\":\"Complex Syst.\",\"year\":1995},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145105432\",\"name\":\"J. Ortega\"},{\"authorId\":\"2632121\",\"name\":\"N. Shaker\"},{\"authorId\":\"1810053\",\"name\":\"J. Togelius\"},{\"authorId\":\"1686193\",\"name\":\"Georgios N. Yannakakis\"}],\"doi\":\"10.1016/j.entcom.2012.10.001\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f0d2fd5c3d7cb7cecc02f51c2c5da2efaec3a0a6\",\"title\":\"Imitating human playing styles in Super Mario Bros\",\"url\":\"https://www.semanticscholar.org/paper/f0d2fd5c3d7cb7cecc02f51c2c5da2efaec3a0a6\",\"venue\":\"Entertain. Comput.\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Joel Lehman\"},{\"authorId\":null,\"name\":\"Kenneth O. Stanley. Evolving a diversity of creatures thro search\"},{\"authorId\":null,\"name\":\"local competition. In Genetic\"},{\"authorId\":null,\"name\":\"Evolutionary Computation Conference\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"pages 211\\u2013218\",\"url\":\"\",\"venue\":\"July\",\"year\":2011},{\"arxivId\":\"1902.01894\",\"authors\":[{\"authorId\":\"145476833\",\"name\":\"Ang Li\"},{\"authorId\":\"68976502\",\"name\":\"Ola Spyra\"},{\"authorId\":\"3274881\",\"name\":\"Sagi Perel\"},{\"authorId\":\"2795508\",\"name\":\"Valentin Dalibard\"},{\"authorId\":\"3093886\",\"name\":\"Max Jaderberg\"},{\"authorId\":\"144864103\",\"name\":\"Chenjie Gu\"},{\"authorId\":\"2508525\",\"name\":\"D. Budden\"},{\"authorId\":\"3367786\",\"name\":\"T. Harley\"},{\"authorId\":\"144168034\",\"name\":\"P. Gupta\"}],\"doi\":\"10.1145/3292500.3330649\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"84444b122a37a1c052b2c32e69136d4ec2ca5ff6\",\"title\":\"A Generalized Framework for Population Based Training\",\"url\":\"https://www.semanticscholar.org/paper/84444b122a37a1c052b2c32e69136d4ec2ca5ff6\",\"venue\":\"KDD\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145080287\",\"name\":\"K. Deb\"},{\"authorId\":\"51028933\",\"name\":\"S. Agrawal\"},{\"authorId\":\"143761916\",\"name\":\"Amrit Pratap\"},{\"authorId\":\"2939646\",\"name\":\"T. Meyarivan\"}],\"doi\":\"10.1007/3-540-45356-3_83\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"6b6d6502f89bd2d74c2cec745075e1995f812072\",\"title\":\"A Fast Elitist Non-dominated Sorting Genetic Algorithm for Multi-objective Optimisation: NSGA-II\",\"url\":\"https://www.semanticscholar.org/paper/6b6d6502f89bd2d74c2cec745075e1995f812072\",\"venue\":\"PPSN\",\"year\":2000},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1803071\",\"name\":\"R. Malaka\"}],\"doi\":\"10.1007/s00287-014-0853-x\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9548b05788d638701b98b725609657662bf87b01\",\"title\":\"Entertainment Computing\",\"url\":\"https://www.semanticscholar.org/paper/9548b05788d638701b98b725609657662bf87b01\",\"venue\":\"Informatik-Spektrum\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5036599\",\"name\":\"J. Drife\"}],\"doi\":\"10.1111/TOG.12090\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"686d409df78ed10efb8568f84e6733a1fc083bd6\",\"title\":\"The third edition\",\"url\":\"https://www.semanticscholar.org/paper/686d409df78ed10efb8568f84e6733a1fc083bd6\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1727849\",\"name\":\"S. Hanson\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"69d7086300e7f5322c06f2f242a565b3a182efb5\",\"title\":\"In Advances in Neural Information Processing Systems\",\"url\":\"https://www.semanticscholar.org/paper/69d7086300e7f5322c06f2f242a565b3a182efb5\",\"venue\":\"NIPS 1990\",\"year\":1990},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2908131\",\"name\":\"B. Keepence\"},{\"authorId\":\"145704902\",\"name\":\"M. Mannion\"}],\"doi\":\"10.1109/ECBS.1997.581896\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"64612138bdae0096587a84958c225d9f9f6677aa\",\"title\":\"Complex systems\",\"url\":\"https://www.semanticscholar.org/paper/64612138bdae0096587a84958c225d9f9f6677aa\",\"venue\":\"Proceedings International Conference and Workshop on Engineering of Computer-Based Systems\",\"year\":1997},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2811287\",\"name\":\"Halit Bener Suay\"},{\"authorId\":\"2837869\",\"name\":\"T. Brys\"},{\"authorId\":\"39286677\",\"name\":\"Matthew E. Taylor\"},{\"authorId\":\"144753437\",\"name\":\"S. Chernova\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2896f821c991824fc0bc96949e4baedc37fee06a\",\"title\":\"Learning from Demonstration for Shaping through Inverse Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/2896f821c991824fc0bc96949e4baedc37fee06a\",\"venue\":\"AAMAS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Rockstar Games\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Red dead redemption 2\",\"url\":\"\",\"venue\":\"https://www.rockstargames.com/ reddeadredemption2/,\",\"year\":2018}],\"title\":\"Generating Behavior-Diverse Game AIs with Evolutionary Multi-Objective Deep Reinforcement Learning\",\"topics\":[{\"topic\":\"Reinforcement learning\",\"topicId\":\"2557\",\"url\":\"https://www.semanticscholar.org/topic/2557\"}],\"url\":\"https://www.semanticscholar.org/paper/267cf56e24fc792502613f11f4270dc83c975e7d\",\"venue\":\"IJCAI\",\"year\":2020}\n"