"{\"abstract\":\"Visual Dialogue task requires an agent to be engaged in a conversation with human about an image. The ability of generating detailed and non-repetitive responses is crucial for the agent to achieve human-like conversation. In this paper, we propose a novel generative decoding architecture to generate high-quality responses, which moves away from decoding the whole encoded semantics towards the design that advocates both transparency and flexibility. In this architecture, word generation is decomposed into a series of attention-based information selection steps, performed by the novel recurrent Deliberation, Abandon and Memory (DAM) module. Each DAM module performs an adaptive combination of the response-level semantics captured from the encoder and the word-level semantics specifically selected for generating each word. Therefore, the responses contain more detailed and non-repetitive descriptions while maintaining the semantic accuracy. Furthermore, DAM is flexible to cooperate with existing visual dialogue encoders and adaptive to the encoder structures by constraining the information selection mode in DAM. We apply DAM to three typical encoders and verify the performance on the VisDial v1.0 dataset. Experimental results show that the proposed models achieve new state-of-the-art performance with high-quality responses. The code is available at this https URL.\",\"arxivId\":\"2007.03310\",\"authors\":[{\"authorId\":\"15246869\",\"name\":\"X. Jiang\",\"url\":\"https://www.semanticscholar.org/author/15246869\"},{\"authorId\":\"119883573\",\"name\":\"J. Yu\",\"url\":\"https://www.semanticscholar.org/author/119883573\"},{\"authorId\":\"15087270\",\"name\":\"Yajing Sun\",\"url\":\"https://www.semanticscholar.org/author/15087270\"},{\"authorId\":\"70565757\",\"name\":\"Zengchang Qin\",\"url\":\"https://www.semanticscholar.org/author/70565757\"},{\"authorId\":\"49659134\",\"name\":\"Zihao Zhu\",\"url\":\"https://www.semanticscholar.org/author/49659134\"},{\"authorId\":\"1581498565\",\"name\":\"Yue Hu\",\"url\":\"https://www.semanticscholar.org/author/1581498565\"},{\"authorId\":\"1509240145\",\"name\":\"Qi Wu\",\"url\":\"https://www.semanticscholar.org/author/1509240145\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":\"2008.04858\",\"authors\":[{\"authorId\":\"15246869\",\"name\":\"X. Jiang\"},{\"authorId\":\"1643931890\",\"name\":\"Siyi Du\"},{\"authorId\":\"70565757\",\"name\":\"Zengchang Qin\"},{\"authorId\":\"15087270\",\"name\":\"Yajing Sun\"},{\"authorId\":\"119883573\",\"name\":\"J. Yu\"}],\"doi\":\"10.1145/3394171.3413826\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5c03ca2e4c26e868b7405e6782c72b85b16db8e4\",\"title\":\"KBGN: Knowledge-Bridge Graph Network for Adaptive Vision-Text Reasoning in Visual Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/5c03ca2e4c26e868b7405e6782c72b85b16db8e4\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2012.15015\",\"authors\":[{\"authorId\":\"65844131\",\"name\":\"Yuxian Meng\"},{\"authorId\":\"1845298604\",\"name\":\"Shuhe Wang\"},{\"authorId\":\"5439717\",\"name\":\"Qinghong Han\"},{\"authorId\":\"48304805\",\"name\":\"Xiaofei Sun\"},{\"authorId\":\"93192602\",\"name\":\"Fei Wu\"},{\"authorId\":null,\"name\":\"Rui Yan\"},{\"authorId\":\"5183779\",\"name\":\"J. Li\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3470e15ae52baae8b8560dd59c616da9820cf43a\",\"title\":\"OpenViDial: A Large-Scale, Open-Domain Dialogue Dataset with Visual Contexts\",\"url\":\"https://www.semanticscholar.org/paper/3470e15ae52baae8b8560dd59c616da9820cf43a\",\"venue\":\"\",\"year\":2020}],\"corpusId\":220381384,\"doi\":\"10.24963/ijcai.2020/96\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"acd1e52ec887f899bd59bf3ec36c744887fc43d7\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"33992653\",\"name\":\"Zhiliang Tian\"},{\"authorId\":\"145001706\",\"name\":\"Wei Bi\"},{\"authorId\":\"48568536\",\"name\":\"Xiaopeng Li\"},{\"authorId\":\"46403468\",\"name\":\"N. L. Zhang\"}],\"doi\":\"10.18653/v1/P19-1371\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"80e5d2fecfb51d0d5e03f1ea7c760ada944d1425\",\"title\":\"Learning to Abstract for Memory-augmented Conversational Response Generation\",\"url\":\"https://www.semanticscholar.org/paper/80e5d2fecfb51d0d5e03f1ea7c760ada944d1425\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1911.10496\",\"authors\":[{\"authorId\":\"3167894\",\"name\":\"Jiaxin Qi\"},{\"authorId\":\"2520427\",\"name\":\"Yulei Niu\"},{\"authorId\":\"50560698\",\"name\":\"Jianqiang Huang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"}],\"doi\":\"10.1109/cvpr42600.2020.01087\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ad99fef72abe84e6b5f194d4973ca824812dbb11\",\"title\":\"Two Causal Principles for Improving Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/ad99fef72abe84e6b5f194d4973ca824812dbb11\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1902.09818\",\"authors\":[{\"authorId\":\"49724488\",\"name\":\"H. Zhang\"},{\"authorId\":\"1703558\",\"name\":\"S. Ghosh\"},{\"authorId\":\"46819684\",\"name\":\"Larry Heck\"},{\"authorId\":\"145109280\",\"name\":\"S. Walsh\"},{\"authorId\":\"49051223\",\"name\":\"Junting Zhang\"},{\"authorId\":\"38791445\",\"name\":\"J. Zhang\"},{\"authorId\":\"9363144\",\"name\":\"C.-C. Jay Kuo\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"cb08a5d1ae9985ae3867780094c9a5e7074817d8\",\"title\":\"Generative Visual Dialogue System via Adaptive Reasoning and Weighted Likelihood Estimation\",\"url\":\"https://www.semanticscholar.org/paper/cb08a5d1ae9985ae3867780094c9a5e7074817d8\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66038639\",\"name\":\"H. Secretary\"},{\"authorId\":\"6624658\",\"name\":\"J. B. Wyngaarden\"},{\"authorId\":\"4885596\",\"name\":\"G. Baym\"},{\"authorId\":\"5738308\",\"name\":\"G. Hammes\"},{\"authorId\":\"144907239\",\"name\":\"M. Singer\"},{\"authorId\":\"2969769\",\"name\":\"M. Chamberlin\"},{\"authorId\":\"5177815\",\"name\":\"E. Kandel\"},{\"authorId\":\"2681217\",\"name\":\"H. Varmus\"},{\"authorId\":\"103014532\",\"name\":\"Mary-Dell M Chilton\"},{\"authorId\":\"50311749\",\"name\":\"S. Kornfeld\"},{\"authorId\":\"3566159\",\"name\":\"T. Waldmann\"},{\"authorId\":\"1952119\",\"name\":\"E. David\"},{\"authorId\":\"4752344\",\"name\":\"D. Koshland\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"76eb546f8c7a7796b5b44c56af9409003905b85e\",\"title\":\"Proceedings of the National Academy of Sciences of the United States of America. Annual subject and author indexes.\",\"url\":\"https://www.semanticscholar.org/paper/76eb546f8c7a7796b5b44c56af9409003905b85e\",\"venue\":\"Proceedings of the National Academy of Sciences of the United States of America\",\"year\":1990},{\"arxivId\":\"1611.08669\",\"authors\":[{\"authorId\":\"145497716\",\"name\":\"A. Das\"},{\"authorId\":\"2150275\",\"name\":\"S. Kottur\"},{\"authorId\":\"39855500\",\"name\":\"K. Gupta\"},{\"authorId\":\"1899992\",\"name\":\"Avi Singh\"},{\"authorId\":\"24508084\",\"name\":\"Deshraj Yadav\"},{\"authorId\":\"144915495\",\"name\":\"Jos\\u00e9 M. F. Moura\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1109/CVPR.2017.121\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2231f44be9a8472a46d8e8a628b4e52b9a8f44e0\",\"title\":\"Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/2231f44be9a8472a46d8e8a628b4e52b9a8f44e0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Zilong Zheng\"},{\"authorId\":null,\"name\":\"Wenguan Wang\"},{\"authorId\":null,\"name\":\"Siyuan Qi\"},{\"authorId\":null,\"name\":\"Song-Chun Zhu. Reasoning visual dialogs with structural\"},{\"authorId\":null,\"name\":\"partial observations\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In CVPR\",\"url\":\"\",\"venue\":\"pages 6669\\u2013 6678,\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39165620\",\"name\":\"Wenqiang Lei\"},{\"authorId\":\"51134926\",\"name\":\"Xisen Jin\"},{\"authorId\":\"37596605\",\"name\":\"Min-Yen Kan\"},{\"authorId\":\"2780667\",\"name\":\"Z. Ren\"},{\"authorId\":\"7792071\",\"name\":\"X. He\"},{\"authorId\":\"50559722\",\"name\":\"D. Yin\"}],\"doi\":\"10.18653/v1/P18-1133\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7effa438f586d1d97f9833f3ee8a44284fc614c2\",\"title\":\"Sequicity: Simplifying Task-oriented Dialogue Systems with Single Sequence-to-Sequence Architectures\",\"url\":\"https://www.semanticscholar.org/paper/7effa438f586d1d97f9833f3ee8a44284fc614c2\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":\"1701.03185\",\"authors\":[{\"authorId\":\"2118249\",\"name\":\"Y. Shao\"},{\"authorId\":\"2776283\",\"name\":\"S. Gouws\"},{\"authorId\":\"3908643\",\"name\":\"D. Britz\"},{\"authorId\":\"46684455\",\"name\":\"Anna Goldie\"},{\"authorId\":\"2704071\",\"name\":\"B. Strope\"},{\"authorId\":\"2186634\",\"name\":\"R. Kurzweil\"}],\"doi\":\"10.18653/v1/D17-1235\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2893a347f1cb32b16d4a2cfd0ef01d505ef1c9ec\",\"title\":\"Generating High-Quality and Informative Conversation Responses with Sequence-to-Sequence Models\",\"url\":\"https://www.semanticscholar.org/paper/2893a347f1cb32b16d4a2cfd0ef01d505ef1c9ec\",\"venue\":\"EMNLP\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Zhiliang Tian\"},{\"authorId\":null,\"name\":\"Wei Bi\"},{\"authorId\":null,\"name\":\"Xiaopeng Li\"},{\"authorId\":null,\"name\":\"Nevin L. Zhang. Learning to abstract for memoryaugmented generation\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In ACL\",\"url\":\"\",\"venue\":\"pages 3816\\u20133825,\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ian Goodfellow\"},{\"authorId\":null,\"name\":\"Jean PougetAbadie\"},{\"authorId\":null,\"name\":\"Mehdi Mirza\"},{\"authorId\":null,\"name\":\"Bing Xu\"},{\"authorId\":null,\"name\":\"David Warde-Farley\"},{\"authorId\":null,\"name\":\"Sherjil Ozair\"},{\"authorId\":null,\"name\":\"Aaron Courville\"},{\"authorId\":null,\"name\":\"Yoshua Bengio. Generative adversarial nets\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In NIPS\",\"url\":\"\",\"venue\":\"pages 2672\\u20132680,\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Zhe Gan\"},{\"authorId\":null,\"name\":\"Yu Cheng\"},{\"authorId\":null,\"name\":\"Ahmed Ei Kholy\"},{\"authorId\":null,\"name\":\"Linjie Li\"},{\"authorId\":null,\"name\":\"Jianfeng Gao. Multi-step reasoning via recurrent dual atten dialog\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In ACL\",\"url\":\"\",\"venue\":\"page 6463\\u20136474,\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Louis Shao\"},{\"authorId\":null,\"name\":\"Stephan Gouws\"},{\"authorId\":null,\"name\":\"Denny Britz\"},{\"authorId\":null,\"name\":\"Anna Goldie\"},{\"authorId\":null,\"name\":\"Brian Strope\"},{\"authorId\":null,\"name\":\"Ray Kurzweil. Generating high-quality\"},{\"authorId\":null,\"name\":\"informative conversation responses with sequence-to-sequence models\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In EMNLP\",\"url\":\"\",\"venue\":\"page 2210\\u20132219,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Can Xu\"},{\"authorId\":null,\"name\":\"Wei Wu\"},{\"authorId\":null,\"name\":\"Chongyang Tao\"},{\"authorId\":null,\"name\":\"Huang Hu\"},{\"authorId\":null,\"name\":\"Matt Schuerman\"},{\"authorId\":null,\"name\":\"Ying Wang. Neural response generation with meta-words\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In ACL\",\"url\":\"\",\"venue\":\"pages 5416\\u20135426,\",\"year\":2019},{\"arxivId\":\"1912.08360\",\"authors\":[{\"authorId\":\"49102717\",\"name\":\"Feilong Chen\"},{\"authorId\":\"33427918\",\"name\":\"Fandong Meng\"},{\"authorId\":\"46372563\",\"name\":\"Jiaming Xu\"},{\"authorId\":\"144326610\",\"name\":\"Peng Li\"},{\"authorId\":\"153260119\",\"name\":\"Bo Xu\"},{\"authorId\":\"144535460\",\"name\":\"J. Zhou\"}],\"doi\":\"10.1609/AAAI.V34I05.6248\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7ae9c15c90b7d3e3c90c7f6d83743d4a0e07416b\",\"title\":\"DMRM: A Dual-channel Multi-hop Reasoning Model for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/7ae9c15c90b7d3e3c90c7f6d83743d4a0e07416b\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Zhenqiao Song\"},{\"authorId\":null,\"name\":\"Xiaoqing Zheng\"},{\"authorId\":null,\"name\":\"Lu Liu\"},{\"authorId\":null,\"name\":\"Mu Xu\"},{\"authorId\":null,\"name\":\"Xuanjing Huang. Generating responses with a specific emotio dialog\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In ACL\",\"url\":\"\",\"venue\":\"pages 3685\\u20133695,\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Dejiang Kong\"},{\"authorId\":null,\"name\":\"Fei Wu. Visual dialog with multi-turn attentional memo network\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In PCM\",\"url\":\"\",\"venue\":\"pages 611\\u2013621,\",\"year\":2018},{\"arxivId\":\"1911.07251\",\"authors\":[{\"authorId\":\"15246869\",\"name\":\"X. Jiang\"},{\"authorId\":\"119883573\",\"name\":\"J. Yu\"},{\"authorId\":\"70565757\",\"name\":\"Zengchang Qin\"},{\"authorId\":\"15586721\",\"name\":\"Yingying Zhuang\"},{\"authorId\":\"47958013\",\"name\":\"Xingxing Zhang\"},{\"authorId\":null,\"name\":\"Yue Hu\"},{\"authorId\":\"49018095\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1609/AAAI.V34I07.6769\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0b42cb7889053f5c89380c82604aa33fd6270894\",\"title\":\"DualVD: An Adaptive Dual Encoding Model for Deep Visual Understanding in Visual Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/0b42cb7889053f5c89380c82604aa33fd6270894\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1804.08217\",\"authors\":[{\"authorId\":\"3064807\",\"name\":\"Andrea Madotto\"},{\"authorId\":\"30340989\",\"name\":\"Chien-Sheng Wu\"},{\"authorId\":\"1683412\",\"name\":\"Pascale Fung\"}],\"doi\":\"10.18653/v1/P18-1136\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b129d764c40ae1254354d037903e13a7bb81c5d2\",\"title\":\"Mem2Seq: Effectively Incorporating Knowledge Bases into End-to-End Task-Oriented Dialog Systems\",\"url\":\"https://www.semanticscholar.org/paper/b129d764c40ae1254354d037903e13a7bb81c5d2\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48157611\",\"name\":\"J. Hopfield\"}],\"doi\":\"10.1073/PNAS.79.8.2554\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"98b4d4e24aab57ab4e1124ff8106909050645cfa\",\"title\":\"Neural networks and physical systems with emergent collective computational abilities.\",\"url\":\"https://www.semanticscholar.org/paper/98b4d4e24aab57ab4e1124ff8106909050645cfa\",\"venue\":\"Proceedings of the National Academy of Sciences of the United States of America\",\"year\":1982},{\"arxivId\":\"1706.01554\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"145721096\",\"name\":\"A. Kannan\"},{\"authorId\":\"145743311\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8cdd241b474bf7b0632162403ac2a3c4799252ad\",\"title\":\"Best of Both Worlds: Transferring Knowledge from Discriminative Learning to a Generative Visual Dialog Model\",\"url\":\"https://www.semanticscholar.org/paper/8cdd241b474bf7b0632162403ac2a3c4799252ad\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Abhishek Das\"},{\"authorId\":null,\"name\":\"Satwik Kottur\"},{\"authorId\":null,\"name\":\"Khushi Gupta\"},{\"authorId\":null,\"name\":\"Avi Singh\"},{\"authorId\":null,\"name\":\"Deshraj Yadav\"},{\"authorId\":null,\"name\":\"Jos\\u00e9 M.F. Moura\"},{\"authorId\":null,\"name\":\"Devi Parikh\"},{\"authorId\":null,\"name\":\"Dhruv Batra. Visual dialog\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In CVPR\",\"url\":\"\",\"venue\":\"pages 1080\\u20131089,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Idan Schwartz\"},{\"authorId\":null,\"name\":\"Seunghak Yu\"},{\"authorId\":null,\"name\":\"Tamir Hazan\"},{\"authorId\":null,\"name\":\"Alexander G Schwing. Factor graph attention\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In CVPR\",\"url\":\"\",\"venue\":\"pages 2039\\u20132048,\",\"year\":2019},{\"arxivId\":\"1801.06176\",\"authors\":[{\"authorId\":\"1780690\",\"name\":\"Baolin Peng\"},{\"authorId\":\"40286474\",\"name\":\"Xiujun Li\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"1726477\",\"name\":\"J. Liu\"},{\"authorId\":\"1784988\",\"name\":\"K. Wong\"}],\"doi\":\"10.18653/v1/P18-1203\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"829e45910ca48c9b9d19492d43ef3c035345c380\",\"title\":\"Integrating planning for task-completion dialogue policy learning\",\"url\":\"https://www.semanticscholar.org/paper/829e45910ca48c9b9d19492d43ef3c035345c380\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":\"1902.09326\",\"authors\":[{\"authorId\":\"49876189\",\"name\":\"T. Yang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d83f41d394cb23a87685d7a69bac42a6e86a4641\",\"title\":\"Making History Matter: Gold-Critic Sequence Training for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/d83f41d394cb23a87685d7a69bac42a6e86a4641\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jiaxin Qi\"},{\"authorId\":null,\"name\":\"Yulei Niu\"},{\"authorId\":null,\"name\":\"Jianqiang Huang\"},{\"authorId\":null,\"name\":\"Hanwang Zhang. Two causal principles for improving visual dialog\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In CVPR\",\"url\":\"\",\"venue\":\"pages 10860\\u201310869,\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yulei Niu\"},{\"authorId\":null,\"name\":\"Hanwang Zhang\"},{\"authorId\":null,\"name\":\"Manli Zhang\"},{\"authorId\":null,\"name\":\"Jianhong Zhang\"},{\"authorId\":null,\"name\":\"Zhiwu Lu\"},{\"authorId\":null,\"name\":\"Ji-Rong Wen. Recursive visual attention in visual dialog\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In CVPR\",\"url\":\"\",\"venue\":\"pages 6679\\u2013 6688,\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Satwik Kottur\"},{\"authorId\":null,\"name\":\"Jos\\u00e9 MF Moura\"},{\"authorId\":null,\"name\":\"Devi Parikh\"},{\"authorId\":null,\"name\":\"Dhruv Batra\"},{\"authorId\":null,\"name\":\"Marcus Rohrbach. Visual coreference resolution in visual  networks\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In ECCV\",\"url\":\"\",\"venue\":\"pages 153\\u2013169,\",\"year\":2018},{\"arxivId\":\"1904.05880\",\"authors\":[{\"authorId\":\"38211837\",\"name\":\"Idan Schwartz\"},{\"authorId\":\"1885974\",\"name\":\"Seunghak Yu\"},{\"authorId\":\"1918412\",\"name\":\"T. Hazan\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1109/CVPR.2019.00214\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ecce0a7b0f9b2bfbc6ca2c99805bddd53178ac35\",\"title\":\"Factor Graph Attention\",\"url\":\"https://www.semanticscholar.org/paper/ecce0a7b0f9b2bfbc6ca2c99805bddd53178ac35\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1904.05548\",\"authors\":[{\"authorId\":\"49774254\",\"name\":\"Zilong Zheng\"},{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"3390244\",\"name\":\"Siyuan Qi\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/CVPR.2019.00683\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"edbab8c313fc6d07a2116ab78248ff8af7bd6f4b\",\"title\":\"Reasoning Visual Dialogs With Structural and Partial Observations\",\"url\":\"https://www.semanticscholar.org/paper/edbab8c313fc6d07a2116ab78248ff8af7bd6f4b\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Dalu Guo\"},{\"authorId\":null,\"name\":\"Chang Xu\"},{\"authorId\":null,\"name\":\"Dacheng Tao. Image-question-answer synergistic network for dialog\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In CVPR\",\"url\":\"\",\"venue\":\"pages 10434\\u201310443,\",\"year\":2019},{\"arxivId\":\"1906.06050\",\"authors\":[{\"authorId\":\"46747953\",\"name\":\"Can Xu\"},{\"authorId\":\"145717890\",\"name\":\"W. Wu\"},{\"authorId\":\"8801869\",\"name\":\"Chongyang Tao\"},{\"authorId\":\"46353980\",\"name\":\"Huang Hu\"},{\"authorId\":\"147595772\",\"name\":\"Matt Schuerman\"},{\"authorId\":null,\"name\":\"Ying Wang\"}],\"doi\":\"10.18653/v1/P19-1538\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"dd1e4c7fb44be613cde2ce9766b219c037a952e4\",\"title\":\"Neural Response Generation with Meta-Words\",\"url\":\"https://www.semanticscholar.org/paper/dd1e4c7fb44be613cde2ce9766b219c037a952e4\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1704.04368\",\"authors\":[{\"authorId\":\"13070498\",\"name\":\"A. See\"},{\"authorId\":\"35025299\",\"name\":\"Peter J. Liu\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.18653/v1/P17-1099\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"668db48c6a79826456341680ee1175dfc4cced71\",\"title\":\"Get To The Point: Summarization with Pointer-Generator Networks\",\"url\":\"https://www.semanticscholar.org/paper/668db48c6a79826456341680ee1175dfc4cced71\",\"venue\":\"ACL\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1162/neco.1997.9.8.1735\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"title\":\"Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"venue\":\"Neural Computation\",\"year\":1997},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2516777\",\"name\":\"Hannah Rashkin\"},{\"authorId\":\"51324296\",\"name\":\"Eric Michael Smith\"},{\"authorId\":\"6649233\",\"name\":\"Margaret Li\"},{\"authorId\":\"90841478\",\"name\":\"Y-Lan Boureau\"}],\"doi\":\"10.18653/v1/P19-1534\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a33a06ddc762fb855b6954c08d5aca603080b011\",\"title\":\"Towards Empathetic Open-domain Conversation Models: A New Benchmark and Dataset\",\"url\":\"https://www.semanticscholar.org/paper/a33a06ddc762fb855b6954c08d5aca603080b011\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1711.07613\",\"authors\":[{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2018.00639\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9dde6ed569684356c46217fa53224272b668bae8\",\"title\":\"Are You Talking to Me? Reasoned Visual Dialog Generation Through Adversarial Learning\",\"url\":\"https://www.semanticscholar.org/paper/9dde6ed569684356c46217fa53224272b668bae8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3493849\",\"name\":\"Dejiang Kong\"},{\"authorId\":\"144894849\",\"name\":\"Fei Wu\"}],\"doi\":\"10.1007/978-3-030-00776-8_56\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"89e982f1a1cda786062f4044391a67d6739804cd\",\"title\":\"Visual Dialog with Multi-turn Attentional Memory Network\",\"url\":\"https://www.semanticscholar.org/paper/89e982f1a1cda786062f4044391a67d6739804cd\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98241663\",\"name\":\"M. V. Rossum\"}],\"doi\":\"10.1142/9789814360784_0003\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"2d5af1ab6368f20a4a9bb2afae23663e5b08b9c6\",\"title\":\"Neural Computation\",\"url\":\"https://www.semanticscholar.org/paper/2d5af1ab6368f20a4a9bb2afae23663e5b08b9c6\",\"venue\":\"\",\"year\":1989},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Heming Zhang\"},{\"authorId\":null,\"name\":\"Shalini Ghosh\"},{\"authorId\":null,\"name\":\"Larry Heck\"},{\"authorId\":null,\"name\":\"Stephen Walsh\"},{\"authorId\":null,\"name\":\"Junting Zhang\"},{\"authorId\":null,\"name\":\"Jie Zhang\"},{\"authorId\":null,\"name\":\"CC Jay Kuo. Generative visual dialogue system via ada reasoning\"},{\"authorId\":null,\"name\":\"weighted likelihood estimation\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In IJCAI\",\"url\":\"\",\"venue\":\"pages 1025\\u20131031,\",\"year\":2019},{\"arxivId\":\"1809.01816\",\"authors\":[{\"authorId\":\"2150275\",\"name\":\"S. Kottur\"},{\"authorId\":\"144915495\",\"name\":\"Jos\\u00e9 M. F. Moura\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.1007/978-3-030-01267-0_10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"782bc02684de81f98c92475957501801bf91e023\",\"title\":\"Visual Coreference Resolution in Visual Dialog using Neural Module Networks\",\"url\":\"https://www.semanticscholar.org/paper/782bc02684de81f98c92475957501801bf91e023\",\"venue\":\"ECCV\",\"year\":2018}],\"title\":\"DAM: Deliberation, Abandon and Memory Networks for Generating Detailed and Non-repetitive Responses in Visual Dialogue\",\"topics\":[{\"topic\":\"Encoder\",\"topicId\":\"16744\",\"url\":\"https://www.semanticscholar.org/topic/16744\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"}],\"url\":\"https://www.semanticscholar.org/paper/acd1e52ec887f899bd59bf3ec36c744887fc43d7\",\"venue\":\"IJCAI\",\"year\":2020}\n"