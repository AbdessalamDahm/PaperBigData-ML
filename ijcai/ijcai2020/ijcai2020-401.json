"{\"abstract\":\"Generative adversarial imitation learning (GAIL) has shown promising results by taking advantage of generative adversarial nets, especially in the field of robot learning. However, the requirement of isolated single modal demonstrations limits the scalability of the approach to real world scenarios such as autonomous vehicles' demand for a proper understanding of human drivers' behavior. In this paper, we propose a novel multi-modal GAIL framework, named Triple-GAIL, that is able to learn skill selection and imitation jointly from both expert demonstrations and continuously generated experiences with data augmentation purpose by introducing an auxiliary skill selector. We provide theoretical guarantees on the convergence to optima for both of the generator and the selector respectively. Experiments on real driver trajectories and real-time strategy game datasets demonstrate that Triple-GAIL can better fit multi-modal behaviors close to the demonstrators and outperforms state-of-the-art methods.\",\"arxivId\":\"2005.10622\",\"authors\":[{\"authorId\":\"40432384\",\"name\":\"C. Fei\",\"url\":\"https://www.semanticscholar.org/author/40432384\"},{\"authorId\":\"3027441\",\"name\":\"Bin Wang\",\"url\":\"https://www.semanticscholar.org/author/3027441\"},{\"authorId\":\"8773733\",\"name\":\"Y. Zhuang\",\"url\":\"https://www.semanticscholar.org/author/8773733\"},{\"authorId\":\"2079174\",\"name\":\"Zongzhang Zhang\",\"url\":\"https://www.semanticscholar.org/author/2079174\"},{\"authorId\":\"40513470\",\"name\":\"Jianye Hao\",\"url\":\"https://www.semanticscholar.org/author/40513470\"},{\"authorId\":\"46702837\",\"name\":\"Hongbo Zhang\",\"url\":\"https://www.semanticscholar.org/author/46702837\"},{\"authorId\":\"7807683\",\"name\":\"Xuewu Ji\",\"url\":\"https://www.semanticscholar.org/author/7807683\"},{\"authorId\":\"2032869\",\"name\":\"W. Liu\",\"url\":\"https://www.semanticscholar.org/author/2032869\"}],\"citationVelocity\":0,\"citations\":[],\"corpusId\":218763198,\"doi\":\"10.24963/ijcai.2020/401\",\"fieldsOfStudy\":[\"Computer Science\",\"Mathematics\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"f57b528eec503d40c96befdfbb9b354ae7d4bb8f\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Kuefler\"},{\"authorId\":null,\"name\":\"M. J. Kochenderfer\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Burn-in demonstrations for multimodal imitation learning\",\"url\":\"\",\"venue\":\"Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems, 2018, pp. 1071\\u20131078.\",\"year\":2018},{\"arxivId\":\"1703.02291\",\"authors\":[{\"authorId\":\"2399563\",\"name\":\"Chongxuan Li\"},{\"authorId\":\"1384559245\",\"name\":\"T. Xu\"},{\"authorId\":\"145254043\",\"name\":\"J. Zhu\"},{\"authorId\":\"34997537\",\"name\":\"B. Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3bd6e4f596d99a47e1e70504e0fc51267ab213e9\",\"title\":\"Triple Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/3bd6e4f596d99a47e1e70504e0fc51267ab213e9\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"LI Chongxuan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Taufik Xu\",\"url\":\"\",\"venue\":\"Jun Zhu, and Bo Zhang. Triple generative adversarial nets. In Advances in neural information processing systems, pages 4088\\u20134098\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1713814\",\"name\":\"Bin Fang\"},{\"authorId\":\"11590609\",\"name\":\"S. Jia\"},{\"authorId\":\"66147945\",\"name\":\"Di Guo\"},{\"authorId\":\"1387797308\",\"name\":\"Muhua Xu\"},{\"authorId\":\"1383072346\",\"name\":\"Shuhuan Wen\"},{\"authorId\":\"143823065\",\"name\":\"F. Sun\"}],\"doi\":\"10.1007/s41315-019-00103-5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10befc15a8887b279f2509eba9b6ece0034543fe\",\"title\":\"Survey of imitation learning for robotic manipulation\",\"url\":\"https://www.semanticscholar.org/paper/10befc15a8887b279f2509eba9b6ece0034543fe\",\"venue\":\"International Journal of Intelligent Robotics and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145489534\",\"name\":\"Phillip Taylor\"},{\"authorId\":\"144482645\",\"name\":\"N. Griffiths\"},{\"authorId\":\"33473374\",\"name\":\"L. Barakat\"},{\"authorId\":\"145116379\",\"name\":\"S. Miles\"}],\"doi\":\"10.5555/3237383\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0d075226bf44899d8d86abb8b07a2e83c18fd65d\",\"title\":\"Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems\",\"url\":\"https://www.semanticscholar.org/paper/0d075226bf44899d8d86abb8b07a2e83c18fd65d\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1729374\",\"name\":\"C. Brodley\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b986f5e12d4af7122186f81ce146f3b57a4144e5\",\"title\":\"Proceedings of the twenty-first international conference on Machine learning\",\"url\":\"https://www.semanticscholar.org/paper/b986f5e12d4af7122186f81ce146f3b57a4144e5\",\"venue\":\"ICML 2004\",\"year\":2004},{\"arxivId\":\"1606.03476\",\"authors\":[{\"authorId\":\"2126278\",\"name\":\"Jonathan Ho\"},{\"authorId\":\"2490652\",\"name\":\"S. Ermon\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4ab53de69372ec2cd2d90c126b6a100165dc8ed1\",\"title\":\"Generative Adversarial Imitation Learning\",\"url\":\"https://www.semanticscholar.org/paper/4ab53de69372ec2cd2d90c126b6a100165dc8ed1\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1710.05090\",\"authors\":[{\"authorId\":\"8774938\",\"name\":\"Alex Kuefler\"},{\"authorId\":\"2275756\",\"name\":\"Mykel J. Kochenderfer\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"039182e2c3b5882b97cea358bbfccbb736e7eb4c\",\"title\":\"Burn-In Demonstrations for Multi-Modal Imitation Learning\",\"url\":\"https://www.semanticscholar.org/paper/039182e2c3b5882b97cea358bbfccbb736e7eb4c\",\"venue\":\"AAMAS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J. Halkias\"},{\"authorId\":null,\"name\":\"J. Colyar\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Next generation simulation fact sheet\",\"url\":\"\",\"venue\":\"US Department of Transportation: Federal Highway Administration, 2006.\",\"year\":2006},{\"arxivId\":\"1707.02747\",\"authors\":[{\"authorId\":\"47197117\",\"name\":\"Ziyu Wang\"},{\"authorId\":\"1879232\",\"name\":\"J. Merel\"},{\"authorId\":\"144828948\",\"name\":\"S. Reed\"},{\"authorId\":\"1737568\",\"name\":\"N. D. Freitas\"},{\"authorId\":\"37866714\",\"name\":\"Gregory Wayne\"},{\"authorId\":\"2801204\",\"name\":\"N. Heess\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"cddb1f7f9f004396a2efef285caf29d7780a8e21\",\"title\":\"Robust Imitation of Diverse Behaviors\",\"url\":\"https://www.semanticscholar.org/paper/cddb1f7f9f004396a2efef285caf29d7780a8e21\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3422021\",\"name\":\"Yunzhu Li\"},{\"authorId\":\"51453887\",\"name\":\"Jiaming Song\"},{\"authorId\":\"2490652\",\"name\":\"S. Ermon\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4135004c75a361c91311314fc588d229a7107526\",\"title\":\"InfoGAIL: Interpretable Imitation Learning from Visual Demonstrations\",\"url\":\"https://www.semanticscholar.org/paper/4135004c75a361c91311314fc588d229a7107526\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1707.01067\",\"authors\":[{\"authorId\":\"39402399\",\"name\":\"Yuandong Tian\"},{\"authorId\":\"22194612\",\"name\":\"Qucheng Gong\"},{\"authorId\":\"3163480\",\"name\":\"W. Shang\"},{\"authorId\":\"98264506\",\"name\":\"Yuxin Wu\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"551768e573bb28b3a2fad4993adbc5c028b95489\",\"title\":\"ELF: An Extensive, Lightweight and Flexible Research Platform for Real-time Strategy Games\",\"url\":\"https://www.semanticscholar.org/paper/551768e573bb28b3a2fad4993adbc5c028b95489\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yuandong Tian\"},{\"authorId\":null,\"name\":\"Qucheng Gong\"},{\"authorId\":null,\"name\":\"Wenling Shang\"},{\"authorId\":null,\"name\":\"Yuxin Wu\"},{\"authorId\":null,\"name\":\"C Lawrence Zitnick\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Elf: An extensive\",\"url\":\"\",\"venue\":\"lightweight and flexible research platform for realtime strategy games. In Advances in Neural Information Processing Systems, pages 2659\\u20132669,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Bin Fang\"},{\"authorId\":null,\"name\":\"Shidong Jia\"},{\"authorId\":null,\"name\":\"Di Guo\"},{\"authorId\":null,\"name\":\"Muhua Xu\"},{\"authorId\":null,\"name\":\"Shuhuan Wen\"},{\"authorId\":null,\"name\":\"Fuchun Sun. Survey of imitation learning for robotic manipulation\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"International Journal of Intelligent Robotics and Applications\",\"url\":\"\",\"venue\":\"pages 1\\u20138,\",\"year\":2019},{\"arxivId\":\"1507.04888\",\"authors\":[{\"authorId\":\"3331786\",\"name\":\"Markus Wulfmeier\"},{\"authorId\":\"3214791\",\"name\":\"Peter Ondruska\"},{\"authorId\":\"1834086\",\"name\":\"I. Posner\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9ba266a4a4644e877fc37a64be3beddce8904cf7\",\"title\":\"Maximum Entropy Deep Inverse Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/9ba266a4a4644e877fc37a64be3beddce8904cf7\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1727849\",\"name\":\"S. Hanson\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"69d7086300e7f5322c06f2f242a565b3a182efb5\",\"title\":\"In Advances in Neural Information Processing Systems\",\"url\":\"https://www.semanticscholar.org/paper/69d7086300e7f5322c06f2f242a565b3a182efb5\",\"venue\":\"NIPS 1990\",\"year\":1990},{\"arxivId\":\"1901.02705\",\"authors\":[{\"authorId\":\"39713408\",\"name\":\"Mikael Henaff\"},{\"authorId\":\"2067767\",\"name\":\"A. Canziani\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2eeace98cf3c105a8d37884dc8d33c50ae4b7ddb\",\"title\":\"Model-Predictive Policy Learning with Uncertainty Regularization for Driving in Dense Traffic\",\"url\":\"https://www.semanticscholar.org/paper/2eeace98cf3c105a8d37884dc8d33c50ae4b7ddb\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1905.11108\",\"authors\":[{\"authorId\":\"51024029\",\"name\":\"Siddharth Reddy\"},{\"authorId\":\"2745001\",\"name\":\"Anca D. Dragan\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"08557d510f98e9fdf7d905b618dffbacbc0160b4\",\"title\":\"SQIL: Imitation Learning via Regularized Behavioral Cloning\",\"url\":\"https://www.semanticscholar.org/paper/08557d510f98e9fdf7d905b618dffbacbc0160b4\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51024029\",\"name\":\"Siddharth Reddy\"},{\"authorId\":\"2745001\",\"name\":\"Anca D. Dragan\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b4e69b0172d69c80f83366c296b6222805360445\",\"title\":\"SQIL: Imitation Learning via Reinforcement Learning with Sparse Rewards\",\"url\":\"https://www.semanticscholar.org/paper/b4e69b0172d69c80f83366c296b6222805360445\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2697936\",\"name\":\"Max Pflueger\"},{\"authorId\":\"144851366\",\"name\":\"Ali Agha\"},{\"authorId\":\"1732493\",\"name\":\"G. Sukhatme\"}],\"doi\":\"10.1109/LRA.2019.2895892\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d1368003909b7db992dbd8fa77a5fd4756af18f5\",\"title\":\"Rover-IRL: Inverse Reinforcement Learning With Soft Value Iteration Networks for Planetary Rover Path Planning\",\"url\":\"https://www.semanticscholar.org/paper/d1368003909b7db992dbd8fa77a5fd4756af18f5\",\"venue\":\"IEEE Robotics and Automation Letters\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"John Halkias\"},{\"authorId\":null,\"name\":\"James Colyar\"},{\"authorId\":null,\"name\":\"Henaff\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Next generation simulation fact sheet. US Department of Transportation: Federal Highway Administration\",\"url\":\"\",\"venue\":\"Mikael Henaff, Alfredo Canziani, and Yann LeCun. Model-predictive policy learning with uncertainty regularization for driving in dense traffic\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"John Schulman\"},{\"authorId\":null,\"name\":\"Sergey Levine\"},{\"authorId\":null,\"name\":\"Pieter Abbeel\"},{\"authorId\":null,\"name\":\"Michael Jordan\"},{\"authorId\":null,\"name\":\"Philipp Moritz. Trust region policy optimization\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In International conference on machine learning\",\"url\":\"\",\"venue\":\"pages 1889\\u20131897,\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1403025868\",\"name\":\"Jean Pouget-Abadie\"},{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"144738865\",\"name\":\"Bing Xu\"},{\"authorId\":\"1393680089\",\"name\":\"David Warde-Farley\"},{\"authorId\":\"1955694\",\"name\":\"Sherjil Ozair\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"title\":\"Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"},{\"authorId\":\"34699434\",\"name\":\"A. Ng\"}],\"doi\":\"10.1145/1015330.1015430\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f65020fc3b1692d7989e099d6b6e698be5a50a93\",\"title\":\"Apprenticeship learning via inverse reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/f65020fc3b1692d7989e099d6b6e698be5a50a93\",\"venue\":\"ICML '04\",\"year\":2004},{\"arxivId\":\"1707.02201\",\"authors\":[{\"authorId\":\"1879232\",\"name\":\"J. Merel\"},{\"authorId\":\"2109481\",\"name\":\"Y. Tassa\"},{\"authorId\":\"22216833\",\"name\":\"TB Dhruva\"},{\"authorId\":\"144999731\",\"name\":\"S. Srinivasan\"},{\"authorId\":\"144083287\",\"name\":\"Jay Lemmon\"},{\"authorId\":\"47197117\",\"name\":\"Ziyu Wang\"},{\"authorId\":\"89504302\",\"name\":\"G. Wayne\"},{\"authorId\":\"2801204\",\"name\":\"N. Heess\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e6e01f580c973d91f6445d839389f9f2d5efc78e\",\"title\":\"Learning human behaviors from motion capture by adversarial imitation\",\"url\":\"https://www.semanticscholar.org/paper/e6e01f580c973d91f6445d839389f9f2d5efc78e\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1502.05477\",\"authors\":[{\"authorId\":\"47971768\",\"name\":\"John Schulman\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"},{\"authorId\":\"1694621\",\"name\":\"Michael I. Jordan\"},{\"authorId\":\"29912342\",\"name\":\"P. Moritz\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"66cdc28dc084af6507e979767755e99fe0b46b39\",\"title\":\"Trust Region Policy Optimization\",\"url\":\"https://www.semanticscholar.org/paper/66cdc28dc084af6507e979767755e99fe0b46b39\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46697991\",\"name\":\"Jiahao Lin\"},{\"authorId\":\"2079174\",\"name\":\"Zongzhang Zhang\"}],\"doi\":\"10.1007/978-3-319-97304-3_25\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e676e42d059150734820c472e8f60a23c6aa02a6\",\"title\":\"ACGAIL: Imitation Learning About Multiple Intentions with Auxiliary Classifier GANs\",\"url\":\"https://www.semanticscholar.org/paper/e676e42d059150734820c472e8f60a23c6aa02a6\",\"venue\":\"PRICAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J Halkias\"},{\"authorId\":null,\"name\":\"J Colyar\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"US Department of Transportation: Federal Highway Administration\",\"url\":\"\",\"venue\":\"\",\"year\":2006}],\"title\":\"Triple-GAIL: A Multi-Modal Imitation Learning Framework with Generative Adversarial Nets\",\"topics\":[{\"topic\":\"Modal logic\",\"topicId\":\"61528\",\"url\":\"https://www.semanticscholar.org/topic/61528\"},{\"topic\":\"Robot learning\",\"topicId\":\"214893\",\"url\":\"https://www.semanticscholar.org/topic/214893\"},{\"topic\":\"Convolutional neural network\",\"topicId\":\"29860\",\"url\":\"https://www.semanticscholar.org/topic/29860\"},{\"topic\":\"Scalability\",\"topicId\":\"1360\",\"url\":\"https://www.semanticscholar.org/topic/1360\"},{\"topic\":\"Experience\",\"topicId\":\"4221\",\"url\":\"https://www.semanticscholar.org/topic/4221\"},{\"topic\":\"Autonomous robot\",\"topicId\":\"1175\",\"url\":\"https://www.semanticscholar.org/topic/1175\"},{\"topic\":\"Multimodal interaction\",\"topicId\":\"42592\",\"url\":\"https://www.semanticscholar.org/topic/42592\"},{\"topic\":\"Autonomous car\",\"topicId\":\"642\",\"url\":\"https://www.semanticscholar.org/topic/642\"}],\"url\":\"https://www.semanticscholar.org/paper/f57b528eec503d40c96befdfbb9b354ae7d4bb8f\",\"venue\":\"ArXiv\",\"year\":2020}\n"