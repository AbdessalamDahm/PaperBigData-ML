"{\"abstract\":\"Spatiotemporal super-resolution (SR) aims to upscale both the spatial and temporal dimensions of input videos, and produces videos with higher frame resolutions and rates. It involves two essential sub-tasks: spatial SR and temporal SR. We design a two-stream network for spatiotemporal SR in this work. One stream contains a temporal SR module followed by a spatial SR module, while the other stream has the same two modules in the reverse order. Based on the interchangeability of performing the two sub-tasks, the two network streams are supposed to produce consistent spatiotemporal SR results. Thus, we present a cross-stream consistency to enforce the similarity between the outputs of the two streams. In this way, the training of the two streams is correlated, which allows the two SR modules to share their supervisory signals and improve each other. In addition, the proposed cross-stream consistency does not consume labeled training data and can guide network training in an unsupervised manner. We leverage this property to carry out semi-supervised spatiotemporal SR. It turns out that our method makes the most of training data, and can derive an effective model with few high-resolution and high-framerate videos, achieving the state-of-the-art performance. The source code of this work is available at https://hankweb.github.io/STSRwithCrossTask/.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"93576086\",\"name\":\"H. Lin\",\"url\":\"https://www.semanticscholar.org/author/93576086\"},{\"authorId\":\"1749408\",\"name\":\"P. Hsiu\",\"url\":\"https://www.semanticscholar.org/author/1749408\"},{\"authorId\":\"145348862\",\"name\":\"T. Kuo\",\"url\":\"https://www.semanticscholar.org/author/145348862\"},{\"authorId\":\"47905461\",\"name\":\"Yen-Yu Lin\",\"url\":\"https://www.semanticscholar.org/author/47905461\"}],\"citationVelocity\":0,\"citations\":[],\"corpusId\":220483463,\"doi\":\"10.24963/ijcai.2020/86\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":false,\"paperId\":\"a4876853ba05de357601750ac2708821ae146ad4\",\"references\":[{\"arxivId\":\"1803.02735\",\"authors\":[{\"authorId\":\"145879931\",\"name\":\"M. Haris\"},{\"authorId\":\"2490189\",\"name\":\"Gregory Shakhnarovich\"},{\"authorId\":\"3081689\",\"name\":\"N. Ukita\"}],\"doi\":\"10.1109/CVPR.2018.00179\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3afa826a594d90ee0f4fe062c988289bb213a114\",\"title\":\"Deep Back-Projection Networks for Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/3afa826a594d90ee0f4fe062c988289bb213a114\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1702.02463\",\"authors\":[{\"authorId\":\"3243969\",\"name\":\"Z. Liu\"},{\"authorId\":\"28919105\",\"name\":\"Raymond A. Yeh\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"36966089\",\"name\":\"Y. Liu\"},{\"authorId\":\"1696487\",\"name\":\"A. Agarwala\"}],\"doi\":\"10.1109/ICCV.2017.478\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8970e9caed1fca960ead644e6453a1a7321a7e6d\",\"title\":\"Video Frame Synthesis Using Deep Voxel Flow\",\"url\":\"https://www.semanticscholar.org/paper/8970e9caed1fca960ead644e6453a1a7321a7e6d\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46320230\",\"name\":\"Manoj Sharma\"},{\"authorId\":\"144725842\",\"name\":\"S. Chaudhury\"},{\"authorId\":\"143632379\",\"name\":\"Brejesh Lall\"}],\"doi\":\"10.1007/978-3-319-69900-4_74\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2687bd4f752b24adfa9965e230547a8a80439b9b\",\"title\":\"Space-Time Super-Resolution Using Deep Learning Based Framework\",\"url\":\"https://www.semanticscholar.org/paper/2687bd4f752b24adfa9965e230547a8a80439b9b\",\"venue\":\"PReMI\",\"year\":2017},{\"arxivId\":\"1712.00080\",\"authors\":[{\"authorId\":\"40175280\",\"name\":\"Huaizu Jiang\"},{\"authorId\":\"3232265\",\"name\":\"Deqing Sun\"},{\"authorId\":\"2745026\",\"name\":\"V. Jampani\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"1389846455\",\"name\":\"E. Learned-Miller\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":\"10.1109/CVPR.2018.00938\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"baa1ae74fbf7ed6204f2f6364d51375ff81aabc1\",\"title\":\"Super SloMo: High Quality Estimation of Multiple Intermediate Frames for Video Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/baa1ae74fbf7ed6204f2f6364d51375ff81aabc1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1904.00830\",\"authors\":[{\"authorId\":\"8613898\",\"name\":\"Wenbo Bao\"},{\"authorId\":\"2268189\",\"name\":\"Wei-Sheng Lai\"},{\"authorId\":\"46658056\",\"name\":\"Chao Ma\"},{\"authorId\":\"49469756\",\"name\":\"X. Zhang\"},{\"authorId\":\"145071557\",\"name\":\"Z. Gao\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/CVPR.2019.00382\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6c8a56ae495e5c8871061d1cd0f863d174f5e2ce\",\"title\":\"Depth-Aware Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/6c8a56ae495e5c8871061d1cd0f863d174f5e2ce\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1704.00675\",\"authors\":[{\"authorId\":\"1403171438\",\"name\":\"J. Pont-Tuset\"},{\"authorId\":\"2942259\",\"name\":\"Federico Perazzi\"},{\"authorId\":\"1413064976\",\"name\":\"S. Caelles\"},{\"authorId\":\"1778133\",\"name\":\"Pablo Arbel\\u00e1ez\"},{\"authorId\":\"1388791172\",\"name\":\"Alexander Sorkine-Hornung\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"49e8fec24cce8b73706bc5fcd2c3f681addb9982\",\"title\":\"The 2017 DAVIS Challenge on Video Object Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/49e8fec24cce8b73706bc5fcd2c3f681addb9982\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144970872\",\"name\":\"Ying Tai\"},{\"authorId\":null,\"name\":\"Jian Yang\"},{\"authorId\":\"1759169\",\"name\":\"X. Liu\"}],\"doi\":\"10.1109/CVPR.2017.298\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a55970013b984f344dfbbbba677d89dce0ba5f81\",\"title\":\"Image Super-Resolution via Deep Recursive Residual Network\",\"url\":\"https://www.semanticscholar.org/paper/a55970013b984f344dfbbbba677d89dce0ba5f81\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145347688\",\"name\":\"S. Baker\"},{\"authorId\":\"1709053\",\"name\":\"D. Scharstein\"},{\"authorId\":\"69395700\",\"name\":\"J. Lewis\"},{\"authorId\":\"145920814\",\"name\":\"S. Roth\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"},{\"authorId\":\"1717841\",\"name\":\"R. Szeliski\"}],\"doi\":\"10.1007/s11263-010-0390-2\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"804836b8ad86ef8042e3dcbd45442a52f031ee03\",\"title\":\"A Database and Evaluation Methodology for Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/804836b8ad86ef8042e3dcbd45442a52f031ee03\",\"venue\":\"2007 IEEE 11th International Conference on Computer Vision\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1720957\",\"name\":\"Hsin-Yi Chen\"},{\"authorId\":\"1744044\",\"name\":\"Yen-Yu Lin\"},{\"authorId\":\"1733344\",\"name\":\"B. Chen\"}],\"doi\":\"10.1109/TPAMI.2015.2420556\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6be97af03fa4a6af01a2fbd6ebd4e5edb7a77a1c\",\"title\":\"Co-Segmentation Guided Hough Transform for Robust Feature Matching\",\"url\":\"https://www.semanticscholar.org/paper/6be97af03fa4a6af01a2fbd6ebd4e5edb7a77a1c\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2015},{\"arxivId\":\"1703.07514\",\"authors\":[{\"authorId\":\"39644974\",\"name\":\"Simon Niklaus\"},{\"authorId\":\"2712573\",\"name\":\"Long Mai\"},{\"authorId\":\"40513795\",\"name\":\"Feng Liu\"}],\"doi\":\"10.1109/CVPR.2017.244\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"841832fae29497f20ed795604ce76358ed7e51c3\",\"title\":\"Video Frame Interpolation via Adaptive Convolution\",\"url\":\"https://www.semanticscholar.org/paper/841832fae29497f20ed795604ce76358ed7e51c3\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7377139\",\"name\":\"Y. Chen\"},{\"authorId\":\"1744044\",\"name\":\"Yen-Yu Lin\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"3068086\",\"name\":\"Jia-Bin Huang\"}],\"doi\":\"10.1109/tpami.2020.2985395\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8e0869da381c20c6da2d7d96e9ca03c927b28d4c\",\"title\":\"Show, Match and Segment: Joint Weakly Supervised Learning of Semantic Matching and Object Co-segmentation.\",\"url\":\"https://www.semanticscholar.org/paper/8e0869da381c20c6da2d7d96e9ca03c927b28d4c\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2816067\",\"name\":\"Chung-Chi Tsai\"},{\"authorId\":\"3451859\",\"name\":\"W. Li\"},{\"authorId\":\"2081209\",\"name\":\"Kuang-Jui Hsu\"},{\"authorId\":\"145616431\",\"name\":\"X. Qian\"},{\"authorId\":\"1744044\",\"name\":\"Yen-Yu Lin\"}],\"doi\":\"10.1109/TIP.2018.2861217\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f7b3a4749dc56251d6e5ef33021a2932f4d227e6\",\"title\":\"Image Co-Saliency Detection and Co-Segmentation via Progressive Joint Optimization\",\"url\":\"https://www.semanticscholar.org/paper/f7b3a4749dc56251d6e5ef33021a2932f4d227e6\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"2001.03182\",\"authors\":[{\"authorId\":\"7377139\",\"name\":\"Y. Chen\"},{\"authorId\":\"1744044\",\"name\":\"Yen-Yu Lin\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"3068086\",\"name\":\"Jia-Bin Huang\"}],\"doi\":\"10.1109/CVPR.2019.00189\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9e145fc992e983a8d7c193a8933d08532194ae67\",\"title\":\"CrDoCo: Pixel-Level Domain Transfer With Cross-Domain Consistency\",\"url\":\"https://www.semanticscholar.org/paper/9e145fc992e983a8d7c193a8933d08532194ae67\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39307151\",\"name\":\"R. Keys\"}],\"doi\":\"10.1109/TASSP.1981.1163711\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"de5ca64429d18710232ecc0da54998e1a401fcbe\",\"title\":\"Cubic convolution interpolation for digital image processing\",\"url\":\"https://www.semanticscholar.org/paper/de5ca64429d18710232ecc0da54998e1a401fcbe\",\"venue\":\"\",\"year\":1981},{\"arxivId\":\"1511.04587\",\"authors\":[{\"authorId\":\"3968500\",\"name\":\"Jiwon Kim\"},{\"authorId\":\"3088401\",\"name\":\"J. Lee\"},{\"authorId\":\"2135837\",\"name\":\"Kyoung Mu Lee\"}],\"doi\":\"10.1109/CVPR.2016.182\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b5f3e5d2912bedbcd9458952d664b08db6aed962\",\"title\":\"Accurate Image Super-Resolution Using Very Deep Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/b5f3e5d2912bedbcd9458952d664b08db6aed962\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1609.05158\",\"authors\":[{\"authorId\":\"2700496\",\"name\":\"W. Shi\"},{\"authorId\":\"145372820\",\"name\":\"J. Caballero\"},{\"authorId\":\"3108066\",\"name\":\"Ferenc Husz\\u00e1r\"},{\"authorId\":\"1853456\",\"name\":\"J. Totz\"},{\"authorId\":\"49931957\",\"name\":\"A. Aitken\"},{\"authorId\":\"50784424\",\"name\":\"R. Bishop\"},{\"authorId\":\"1717710\",\"name\":\"D. Rueckert\"},{\"authorId\":\"34627233\",\"name\":\"Zehan Wang\"}],\"doi\":\"10.1109/CVPR.2016.207\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"03a5b2aac53443e6078f0f63b35d4f95d6d54c5d\",\"title\":\"Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/03a5b2aac53443e6078f0f63b35d4f95d6d54c5d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3258961\",\"name\":\"Roman Zeyde\"},{\"authorId\":\"1753908\",\"name\":\"Michael Elad\"},{\"authorId\":\"2941687\",\"name\":\"M. Protter\"}],\"doi\":\"10.1007/978-3-642-27413-8_47\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d1dce9ad419d8c7037980a9ea28506ed0e640bba\",\"title\":\"On Single Image Scale-Up Using Sparse-Representations\",\"url\":\"https://www.semanticscholar.org/paper/d1dce9ad419d8c7037980a9ea28506ed0e640bba\",\"venue\":\"Curves and Surfaces\",\"year\":2010},{\"arxivId\":\"1501.00092\",\"authors\":[{\"authorId\":\"144964868\",\"name\":\"C. Dong\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1109/TPAMI.2015.2439281\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"66e9dc728b5041271bff0cd6ac0d7eadcd88442f\",\"title\":\"Image Super-Resolution Using Deep Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/66e9dc728b5041271bff0cd6ac0d7eadcd88442f\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"References\"},{\"authorId\":null,\"name\":\"Bailer\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Ming-Hsuan Yang, and Jia-Bin Huang. Show, match and segment: Joint weakly supervised learning of semantic matching and object co-segmentation. TPAMI, 2020\",\"url\":\"\",\"venue\":\"Flow fields: Dense correspondence fields for highly accurate large displacement optical flow estimation. TPAMI\",\"year\":1981},{\"arxivId\":\"1808.00449\",\"authors\":[{\"authorId\":\"2268189\",\"name\":\"Wei-Sheng Lai\"},{\"authorId\":\"3068086\",\"name\":\"Jia-Bin Huang\"},{\"authorId\":\"39231399\",\"name\":\"O. Wang\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"8020964\",\"name\":\"Ersin Yumer\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1007/978-3-030-01267-0_11\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"098b68fe34dba7fc4e206035ae2d149944bbca8f\",\"title\":\"Learning Blind Video Temporal Consistency\",\"url\":\"https://www.semanticscholar.org/paper/098b68fe34dba7fc4e206035ae2d149944bbca8f\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10699750\",\"name\":\"X. Gao\"},{\"authorId\":\"1723685\",\"name\":\"K. Zhang\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"},{\"authorId\":\"1720243\",\"name\":\"X. Li\"}],\"doi\":\"10.1109/TIP.2012.2190080\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5359c2aeddcb1ee60239dbdc4b84a3cc3d75ec2a\",\"title\":\"Image Super-Resolution With Sparse Neighbor Embedding\",\"url\":\"https://www.semanticscholar.org/paper/5359c2aeddcb1ee60239dbdc4b84a3cc3d75ec2a\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2012},{\"arxivId\":\"1508.05151\",\"authors\":[{\"authorId\":\"2598904\",\"name\":\"Christian Bailer\"},{\"authorId\":\"2847305\",\"name\":\"Bertram Taetz\"},{\"authorId\":\"143749919\",\"name\":\"D. Stricker\"}],\"doi\":\"10.1109/TPAMI.2018.2859970\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"25ceb810a7373f10b654eb9f736abc00433116d2\",\"title\":\"Flow Fields: Dense Correspondence Fields for Highly Accurate Large Displacement Optical Flow Estimation\",\"url\":\"https://www.semanticscholar.org/paper/25ceb810a7373f10b654eb9f736abc00433116d2\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1809.01649\",\"authors\":[{\"authorId\":\"8299168\",\"name\":\"Y. Zou\"},{\"authorId\":\"3378742\",\"name\":\"Zelun Luo\"},{\"authorId\":\"3068086\",\"name\":\"Jia-Bin Huang\"}],\"doi\":\"10.1007/978-3-030-01228-1_3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c01876292b5d1ce6e746fd2e2053453847905bb2\",\"title\":\"DF-Net: Unsupervised Joint Learning of Depth and Flow using Cross-Task Consistency\",\"url\":\"https://www.semanticscholar.org/paper/c01876292b5d1ce6e746fd2e2053453847905bb2\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19226033\",\"name\":\"Oded Shahar\"},{\"authorId\":\"2859022\",\"name\":\"Alon Faktor\"},{\"authorId\":\"144611617\",\"name\":\"M. Irani\"}],\"doi\":\"10.1109/CVPR.2011.5995360\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d896e9a76a6f8bd873c7e6144c750f71799b37c2\",\"title\":\"Space-time super-resolution from a single video\",\"url\":\"https://www.semanticscholar.org/paper/d896e9a76a6f8bd873c7e6144c750f71799b37c2\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":\"2004.00144\",\"authors\":[{\"authorId\":\"7377139\",\"name\":\"Y. Chen\"},{\"authorId\":\"2660868\",\"name\":\"Po-Hsiang Huang\"},{\"authorId\":\"4129102\",\"name\":\"Li-Yu Yu\"},{\"authorId\":\"3068086\",\"name\":\"Jia-Bin Huang\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"1744044\",\"name\":\"Yen-Yu Lin\"}],\"doi\":\"10.1007/978-3-030-20893-6_22\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c7cbe98349b19de6e09f6e038f7c5a048604ce09\",\"title\":\"Deep Semantic Matching with Foreground Detection and Cycle-Consistency\",\"url\":\"https://www.semanticscholar.org/paper/c7cbe98349b19de6e09f6e038f7c5a048604ce09\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153009621\",\"name\":\"Zhefei Yu\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"},{\"authorId\":\"2969311\",\"name\":\"Zhangyang Wang\"},{\"authorId\":\"1694827\",\"name\":\"Zeng Hu\"},{\"authorId\":\"1735257\",\"name\":\"C. Chen\"}],\"doi\":\"10.1109/TCSVT.2013.2242631\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"2c83b1573163b8794b85e35021a0650945e958da\",\"title\":\"Multi-Level Video Frame Interpolation: Exploiting the Interaction Among Different Levels\",\"url\":\"https://www.semanticscholar.org/paper/2c83b1573163b8794b85e35021a0650945e958da\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46398521\",\"name\":\"Y. Liu\"},{\"authorId\":\"66821424\",\"name\":\"Yi-Tung Liao\"},{\"authorId\":\"1744044\",\"name\":\"Yen-Yu Lin\"},{\"authorId\":\"143708263\",\"name\":\"Yung-Yu Chuang\"}],\"doi\":\"10.1609/AAAI.V33I01.33018794\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"92f3548ff323a65981aed274c0b124053dce2e73\",\"title\":\"Deep Video Frame Interpolation Using Cyclic Frame Generation\",\"url\":\"https://www.semanticscholar.org/paper/92f3548ff323a65981aed274c0b124053dce2e73\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1802.08797\",\"authors\":[{\"authorId\":\"2410227\",\"name\":\"Yulun Zhang\"},{\"authorId\":\"34777509\",\"name\":\"Yapeng Tian\"},{\"authorId\":\"145873652\",\"name\":\"Y. Kong\"},{\"authorId\":\"40296597\",\"name\":\"B. Zhong\"},{\"authorId\":\"46956675\",\"name\":\"Yun Fu\"}],\"doi\":\"10.1109/CVPR.2018.00262\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4ef1476dec02c62227187edbba88615278b3edba\",\"title\":\"Residual Dense Network for Image Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/4ef1476dec02c62227187edbba88615278b3edba\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1681442\",\"name\":\"Ce Liu\"},{\"authorId\":\"3232265\",\"name\":\"Deqing Sun\"}],\"doi\":\"10.1109/CVPR.2011.5995614\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d98140c49bf9a6a7abe4c78054c2d097caf75ff2\",\"title\":\"A Bayesian approach to adaptive video super resolution\",\"url\":\"https://www.semanticscholar.org/paper/d98140c49bf9a6a7abe4c78054c2d097caf75ff2\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":\"1711.09078\",\"authors\":[{\"authorId\":\"3222730\",\"name\":\"Tianfan Xue\"},{\"authorId\":\"5114023\",\"name\":\"B. Chen\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"1766333\",\"name\":\"D. Wei\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"}],\"doi\":\"10.1007/s11263-018-01144-2\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c1045435c208a20f65b79baaa2d79783c2409c09\",\"title\":\"Video Enhancement with Task-Oriented Flow\",\"url\":\"https://www.semanticscholar.org/paper/c1045435c208a20f65b79baaa2d79783c2409c09\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018}],\"title\":\"Spatiotemporal Super-Resolution with Cross-Task Consistency and Its Semi-supervised Extension\",\"topics\":[{\"topic\":\"Super-resolution imaging\",\"topicId\":\"127408\",\"url\":\"https://www.semanticscholar.org/topic/127408\"},{\"topic\":\"Semiconductor industry\",\"topicId\":\"76540\",\"url\":\"https://www.semanticscholar.org/topic/76540\"}],\"url\":\"https://www.semanticscholar.org/paper/a4876853ba05de357601750ac2708821ae146ad4\",\"venue\":\"IJCAI\",\"year\":2020}\n"