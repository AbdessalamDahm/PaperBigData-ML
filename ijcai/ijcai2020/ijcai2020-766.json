"{\"abstract\":\"Audio synthesizers are pervasive in modern music production. These highly complex audio generation functions provide a unique diversity through their large sets of parameters. However, this feature also can make them extremely hard and obfuscated to use, especially for non-expert users with no formal knowledge on signal processing. We recently introduced a novel formalization of the problem of synthesizer control as learning an invertible mapping between an audio latent space, extracted from the audio signal, and a target parameter latent space, extracted from the synthesizer\\u2019s presets, using normalizing flows. In addition to model a continuous representation allowing to ease the intuitive exploration of the synthesizer, it also provides a ground-breaking method for audio-based parameter inference, vocal control and macro-control learning. Here, we discuss the details of integrating these high-level features to develop new interaction schemes between a human user and the generating device: parameters inference from audio, high-level preset visualization and interpolation, that can be used both in off-time and real-time situations. Moreover, we also leverage LeapMotion devices to allow the control of hundreds of parameters simply by moving one hand across space to explore the low-dimensional latent space, creating allowing to both empower and facilitate the user\\u2019s interaction with the synthesizer.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"2952234\",\"name\":\"P. Esling\",\"url\":\"https://www.semanticscholar.org/author/2952234\"},{\"authorId\":\"66751723\",\"name\":\"Naotake Masuda\",\"url\":\"https://www.semanticscholar.org/author/66751723\"},{\"authorId\":\"1403278041\",\"name\":\"Axel Chemla-Romeu-Santos\",\"url\":\"https://www.semanticscholar.org/author/1403278041\"}],\"citationVelocity\":0,\"citations\":[],\"corpusId\":220484250,\"doi\":\"10.24963/ijcai.2020/767\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":false,\"paperId\":\"09afc89653ea3a0f3b4b6c88d1e9f8c650aa9bef\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"145498467\",\"name\":\"R. A. Garcia\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"00d27f50afc68617558426ad033a5d9b8308c8ca\",\"title\":\"Automatic Design of Sound Synthesis Techniques by means of Genetic Programming\",\"url\":\"https://www.semanticscholar.org/paper/00d27f50afc68617558426ad033a5d9b8308c8ca\",\"venue\":\"\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1688313\",\"name\":\"N. Schnell\"},{\"authorId\":\"50362757\",\"name\":\"F. Bevilacqua\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4c34eee0af102935ce2c7f2b0bc3d3f002e8d6f1\",\"title\":\"Proceedings of the 2006 conference on New interfaces for musical expression\",\"url\":\"https://www.semanticscholar.org/paper/4c34eee0af102935ce2c7f2b0bc3d3f002e8d6f1\",\"venue\":\"\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"122604822\",\"name\":\"Doris Weberberger\"}],\"doi\":\"10.7767/omz.2012.67.1.76\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ec72365ccf4c2c7c094249accaec458be09a1d80\",\"title\":\"Organised Sound\",\"url\":\"https://www.semanticscholar.org/paper/ec72365ccf4c2c7c094249accaec458be09a1d80\",\"venue\":\"\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2952234\",\"name\":\"P. Esling\"},{\"authorId\":\"66751723\",\"name\":\"Naotake Masuda\"},{\"authorId\":\"19192985\",\"name\":\"Adrien Bardet\"},{\"authorId\":\"150274337\",\"name\":\"R. Despres\"},{\"authorId\":\"1403278041\",\"name\":\"Axel Chemla-Romeu-Santos\"}],\"doi\":\"10.3390/app10010302\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"47f5b7585a50c7fa99bd646d6e86d562e04f65b9\",\"title\":\"Flow Synthesizer: Universal Audio Synthesizer Control with Normalizing Flows\",\"url\":\"https://www.semanticscholar.org/paper/47f5b7585a50c7fa99bd646d6e86d562e04f65b9\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Matthew John Yee-King\"},{\"authorId\":null,\"name\":\"Leon Fedden\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and Mark d\\u2019Inverno\",\"url\":\"\",\"venue\":\"Automatic programming of vst sound synthesizers using deep networks and other techniques. IEEE Transactions on ETCI, 2(2),\",\"year\":2018},{\"arxivId\":\"1505.05770\",\"authors\":[{\"authorId\":\"1748523\",\"name\":\"Danilo Jimenez Rezende\"},{\"authorId\":\"14594344\",\"name\":\"S. Mohamed\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f899b92b7fb03b609fee887e4b6f3b633eaf30d\",\"title\":\"Variational Inference with Normalizing Flows\",\"url\":\"https://www.semanticscholar.org/paper/0f899b92b7fb03b609fee887e4b6f3b633eaf30d\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1312.6114\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"1678311\",\"name\":\"M. Welling\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5f5dc5b9a2ba710937e2c413b37b053cd673df02\",\"title\":\"Auto-Encoding Variational Bayes\",\"url\":\"https://www.semanticscholar.org/paper/5f5dc5b9a2ba710937e2c413b37b053cd673df02\",\"venue\":\"ICLR\",\"year\":2014}],\"title\":\"FlowSynth: Simplifying Complex Audio Generation Through Explorable Latent Spaces with Normalizing Flows\",\"topics\":[{\"topic\":\"Spaces\",\"topicId\":\"124\",\"url\":\"https://www.semanticscholar.org/topic/124\"}],\"url\":\"https://www.semanticscholar.org/paper/09afc89653ea3a0f3b4b6c88d1e9f8c650aa9bef\",\"venue\":\"IJCAI\",\"year\":2020}\n"