"{\"abstract\":\"Applying multi-scale representations leads to consistent performance improvements on a wide range of image recognition tasks. However, with the addition of the temporal dimension in video domain, directly obtaining layer-wise multi-scale spatialtemporal features will add a lot extra computational cost. In this work, we propose a novel and efficient Multi-Scale Spatial-Temporal Integration Convolutional Tube (MSTI) aiming at achieving accurate recognition of actions with lower computational cost. It firstly extracts multi-scale spatial and temporal features through the multi-scale convolution block. Considering the interaction of differentscales representations and the interaction of spatial appearance and temporal motion, we employ the cross-scale attention weighted blocks to perform feature recalibration by integrating multi-scale spatial and temporal features. An end-to-end deep network, MSTI-Net, is also presented based on the proposed MSTI tube for human action recognition. Extensive experimental results show that our MSTI-Net significantly boosts the performance of existing convolution networks and achieves stateof-the-art accuracy on three challenging benchmarks, i.e., UCF-101, HMDB-51 and Kinetics-400, with much fewer parameters and FLOPs.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"40354734\",\"name\":\"Haoze Wu\",\"url\":\"https://www.semanticscholar.org/author/40354734\"},{\"authorId\":\"48210950\",\"name\":\"Jiawei Liu\",\"url\":\"https://www.semanticscholar.org/author/48210950\"},{\"authorId\":\"49898078\",\"name\":\"Xierong Zhu\",\"url\":\"https://www.semanticscholar.org/author/49898078\"},{\"authorId\":\"152808542\",\"name\":\"Meng Wang\",\"url\":\"https://www.semanticscholar.org/author/152808542\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\",\"url\":\"https://www.semanticscholar.org/author/143962510\"}],\"citationVelocity\":0,\"citations\":[],\"corpusId\":220484644,\"doi\":\"10.24963/ijcai.2020/105\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":false,\"paperId\":\"f4fb429109591a5d20136fe884b5fd7c7584a62c\",\"references\":[{\"arxivId\":\"1712.04851\",\"authors\":[{\"authorId\":\"1817030\",\"name\":\"Saining Xie\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"1808244\",\"name\":\"J. Huang\"},{\"authorId\":\"144035504\",\"name\":\"Zhuowen Tu\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":\"10.1007/978-3-030-01267-0_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"815aa52cfc02961d82415f080384594639a21984\",\"title\":\"Rethinking Spatiotemporal Feature Learning: Speed-Accuracy Trade-offs in Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/815aa52cfc02961d82415f080384594639a21984\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Xiaolong Wang\"},{\"authorId\":null,\"name\":\"Ross Girshick\"},{\"authorId\":null,\"name\":\"Abhinav Gupta\"},{\"authorId\":null,\"name\":\"Kaiming He. Non-local neural networks\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In CVPR\",\"url\":\"\",\"venue\":\"pages 7794\\u20137803,\",\"year\":2018},{\"arxivId\":\"1711.10305\",\"authors\":[{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/ICCV.2017.590\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"024d037d46ae933c7e12fd16af61953c7161773a\",\"title\":\"Learning Spatio-Temporal Representation with Pseudo-3D Residual Networks\",\"url\":\"https://www.semanticscholar.org/paper/024d037d46ae933c7e12fd16af61953c7161773a\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1212.0402\",\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"title\":\"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\",\"url\":\"https://www.semanticscholar.org/paper/da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Vinod Nair\"},{\"authorId\":null,\"name\":\"Geoffrey E Hinton. Rectified linear units improve restricte machines\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In ICML\",\"url\":\"\",\"venue\":\"pages 807\\u2013814,\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Limin Wang\"},{\"authorId\":null,\"name\":\"Wei Li\"},{\"authorId\":null,\"name\":\"Wen Li\"},{\"authorId\":null,\"name\":\"Luc Van Gool. Appearance-\"},{\"authorId\":null,\"name\":\"-relation networks for video classification\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In CVPR\",\"url\":\"\",\"venue\":\"pages 1430\\u20131439,\",\"year\":2018},{\"arxivId\":\"1608.00859\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-319-46484-8_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"title\":\"Temporal Segment Networks: Towards Good Practices for Deep Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Christian Szegedy\"},{\"authorId\":null,\"name\":\"Sergey Ioffe\"},{\"authorId\":null,\"name\":\"Vincent Vanhoucke\"},{\"authorId\":null,\"name\":\"Alexander A Alemi\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Inception-v4\",\"url\":\"\",\"venue\":\"inception-resnet and the impact of residual connections on learning. In AAAI,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Kaiming He\"},{\"authorId\":null,\"name\":\"Xiangyu Zhang\"},{\"authorId\":null,\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun. Deep residual learning for image recognition\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In CVPR\",\"url\":\"\",\"venue\":\"pages 770\\u2013778,\",\"year\":2016},{\"arxivId\":\"1811.01549\",\"authors\":[{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"47230289\",\"name\":\"Zhichao Zhou\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"31442858\",\"name\":\"F. Li\"},{\"authorId\":\"48033101\",\"name\":\"Xiao Liu\"},{\"authorId\":\"47001910\",\"name\":\"Y. Li\"},{\"authorId\":\"48170161\",\"name\":\"L. Wang\"},{\"authorId\":\"35247507\",\"name\":\"Shilei Wen\"}],\"doi\":\"10.1609/aaai.v33i01.33018401\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"94d67304c6c0d23c7dfcf008cbf799b54b8d20b9\",\"title\":\"StNet: Local and Global Spatial-Temporal Modeling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/94d67304c6c0d23c7dfcf008cbf799b54b8d20b9\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/ICCV.2015.510\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"title\":\"Learning Spatiotemporal Features with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Du Tran\"},{\"authorId\":null,\"name\":\"Heng Wang\"},{\"authorId\":null,\"name\":\"Lorenzo Torresani\"},{\"authorId\":null,\"name\":\"Jamie Ray\"},{\"authorId\":null,\"name\":\"Yann LeCun\"},{\"authorId\":null,\"name\":\"Manohar Paluri. A closer look at spatiotemporal convolutio recognition\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In CVPR\",\"url\":\"\",\"venue\":\"pages 6450\\u20136459,\",\"year\":2018},{\"arxivId\":\"1406.2199\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"title\":\"Two-Stream Convolutional Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":null,\"name\":\"Axel Pinz\"},{\"authorId\":null,\"name\":\"Richard Wildes. Spatiotemporal residual networks for video recognition\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In NIPS\",\"url\":\"\",\"venue\":\"pages 3468\\u2013 3476,\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5886094\",\"name\":\"P. Cochat\"},{\"authorId\":\"13267685\",\"name\":\"L. Vaucoret\"},{\"authorId\":\"31455512\",\"name\":\"J. Sarles\"}],\"doi\":\"10.1016/j.arcped.2012.01.013\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"10d85561e4aafc516d10064f30dff05b41f70afe\",\"title\":\"[Et al].\",\"url\":\"https://www.semanticscholar.org/paper/10d85561e4aafc516d10064f30dff05b41f70afe\",\"venue\":\"Archives de pediatrie : organe officiel de la Societe francaise de pediatrie\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Andrej Karpathy\"},{\"authorId\":null,\"name\":\"George Toderici\"},{\"authorId\":null,\"name\":\"Sanketh Shetty\"},{\"authorId\":null,\"name\":\"Thomas Leung\"},{\"authorId\":null,\"name\":\"Rahul Sukthankar\"},{\"authorId\":null,\"name\":\"Li Fei-Fei. Large-scale video classification with con networks\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In CVPR\",\"url\":\"\",\"venue\":\"pages 1725\\u20131732,\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71553048\",\"name\":\"\\u7965\\u5b5d \\u725b\\u4e45\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a3179ed8c9e06e9df6273c74f30a8bb52bfc2687\",\"title\":\"ACM Multimedia \\u53c2\\u52a0\\u5831\\u544a\",\"url\":\"https://www.semanticscholar.org/paper/a3179ed8c9e06e9df6273c74f30a8bb52bfc2687\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1904.01169\",\"authors\":[{\"authorId\":\"3180489\",\"name\":\"Shanghua Gao\"},{\"authorId\":\"37535930\",\"name\":\"Ming-Ming Cheng\"},{\"authorId\":null,\"name\":\"Kai Zhao\"},{\"authorId\":\"50812963\",\"name\":\"Xinyu Zhang\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"}],\"doi\":\"10.1109/TPAMI.2019.2938758\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2a69ddbafb23c63e5e22401664bea229daaeb7d6\",\"title\":\"Res2Net: A New Multi-scale Backbone Architecture\",\"url\":\"https://www.semanticscholar.org/paper/2a69ddbafb23c63e5e22401664bea229daaeb7d6\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40354734\",\"name\":\"Haoze Wu\"},{\"authorId\":\"51260253\",\"name\":\"Z. Zha\"},{\"authorId\":\"145919634\",\"name\":\"X. Wen\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"},{\"authorId\":\"153626293\",\"name\":\"Dong Liu\"},{\"authorId\":\"46772808\",\"name\":\"X. Chen\"}],\"doi\":\"10.1145/3343031.3350891\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b725e11efdc4b4bd367e555dd2a70530b9002c68\",\"title\":\"Cross-Fiber Spatial-Temporal Co-enhanced Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b725e11efdc4b4bd367e555dd2a70530b9002c68\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"119268487\",\"name\":\"Hueihan Jhuang\"},{\"authorId\":\"1930964\",\"name\":\"E. Garrote\"},{\"authorId\":\"145031878\",\"name\":\"T. Poggio\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"}],\"doi\":\"10.1109/ICCV.2011.6126543\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"8b3b8848a311c501e704c45c6d50430ab7068956\",\"title\":\"HMDB: A large video database for human motion recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b3b8848a311c501e704c45c6d50430ab7068956\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":\"1708.05038\",\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"4439383\",\"name\":\"Jamie Ray\"},{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a92adfdd8996ab2bd7cdc910ea1d3db03c66d34f\",\"title\":\"ConvNet Architecture Search for Spatiotemporal Feature Learning\",\"url\":\"https://www.semanticscholar.org/paper/a92adfdd8996ab2bd7cdc910ea1d3db03c66d34f\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49455479\",\"name\":\"Y. Zhou\"},{\"authorId\":\"6485172\",\"name\":\"Xiaoyan Sun\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"}],\"doi\":\"10.1109/CVPR.2018.00054\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b85b79d0535da7e994e419a75f65b2758bf90f21\",\"title\":\"MiCT: Mixed 3D/2D Convolutional Tube for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b85b79d0535da7e994e419a75f65b2758bf90f21\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Limin Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Learning spatio - temporal representation with pseudo - 3 d residual networks Learning spatiotemporal features with 3 d convolutional networks\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jie Hu\"},{\"authorId\":null,\"name\":\"Li Shen\"},{\"authorId\":null,\"name\":\"Gang Sun. Squeezeand-excitation networks\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In CVPR\",\"url\":\"\",\"venue\":\"pages 7132\\u20137141,\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":null,\"name\":\"Haoqi Fan\"},{\"authorId\":null,\"name\":\"Jitendra Malik\"},{\"authorId\":null,\"name\":\"Kaiming He. Slowfast networks for video recognition\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In ICCV\",\"url\":\"\",\"venue\":\"pages 6202\\u20136211,\",\"year\":2019},{\"arxivId\":\"1705.07750\",\"authors\":[{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2017.502\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"title\":\"Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset\",\"url\":\"https://www.semanticscholar.org/paper/b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Haoze Wu\"},{\"authorId\":null,\"name\":\"Jiawei Liu\"},{\"authorId\":null,\"name\":\"Zheng-Jun Zha\"},{\"authorId\":null,\"name\":\"Zhenzhong Chen\"},{\"authorId\":null,\"name\":\"Xiaoyan Sun. Mutually reinforced spatio-temporal convoluti recognition\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In IJCAI\",\"url\":\"\",\"venue\":\"pages 968\\u2013974,\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jeffrey Donahue\"},{\"authorId\":null,\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":null,\"name\":\"Sergio Guadarrama\"},{\"authorId\":null,\"name\":\"Marcus Rohrbach\"},{\"authorId\":null,\"name\":\"Subhashini Venugopalan\"},{\"authorId\":null,\"name\":\"Kate Saenko\"},{\"authorId\":null,\"name\":\"Trevor Darrell. Longterm recurrent convolutional networks recognition\"},{\"authorId\":null,\"name\":\"description\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In CVPR\",\"url\":\"\",\"venue\":\"pages 2625\\u20132634,\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Karen Simonyan\"},{\"authorId\":null,\"name\":\"Andrew Zisserman. Two-stream convolutional networks for a videos\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In NIPS\",\"url\":\"\",\"venue\":\"pages 568\\u2013576,\",\"year\":2014}],\"title\":\"Multi-Scale Spatial-Temporal Integration Convolutional Tube for Human Action Recognition\",\"topics\":[],\"url\":\"https://www.semanticscholar.org/paper/f4fb429109591a5d20136fe884b5fd7c7584a62c\",\"venue\":\"IJCAI\",\"year\":2020}\n"