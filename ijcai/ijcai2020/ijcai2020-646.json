"{\"abstract\":\"In interactive e-learning environments such as Intelligent Tutoring Systems, there are pedagogical decisions to make at two main levels of granularity: whole problems and single steps. In recent years, there is growing interest in applying datadriven techniques for adaptive decision making that can dynamically tailor students\\u2019 learning experiences. Most existing data-driven approaches, however, treat these pedagogical decisions equally, or independently, disregarding the long-term impact that tutor decisions may have across these two levels of granularity. In this paper, we propose and apply an offline Gaussian Processes based Hierarchical Reinforcement Learning (HRL) framework to induce a hierarchical pedagogical policy that makes decisions at both problem and step levels. An empirical classroom study shows that the HRL policy is significantly more effective than a Deep QNetwork (DQN) induced policy and a random yet reasonable baseline policy.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"3349939\",\"name\":\"Guojing Zhou\",\"url\":\"https://www.semanticscholar.org/author/3349939\"},{\"authorId\":\"51216654\",\"name\":\"H. Azizsoltani\",\"url\":\"https://www.semanticscholar.org/author/51216654\"},{\"authorId\":\"51039532\",\"name\":\"Markel Sanz Ausin\",\"url\":\"https://www.semanticscholar.org/author/51039532\"},{\"authorId\":\"152553911\",\"name\":\"T. Barnes\",\"url\":\"https://www.semanticscholar.org/author/152553911\"},{\"authorId\":\"1423680515\",\"name\":\"Min Chi\",\"url\":\"https://www.semanticscholar.org/author/1423680515\"}],\"citationVelocity\":0,\"citations\":[],\"corpusId\":220483422,\"doi\":\"10.24963/ijcai.2020/647\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":false,\"is_publisher_licensed\":false,\"paperId\":\"6a729366768abd5d85a0efd666e6f7ab40ca27d2\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"2681621\",\"name\":\"R. Schwonke\"},{\"authorId\":\"1747907\",\"name\":\"A. Renkl\"},{\"authorId\":\"25708572\",\"name\":\"Carmen Krieg\"},{\"authorId\":\"1838237\",\"name\":\"J. Wittwer\"},{\"authorId\":\"1779915\",\"name\":\"V. Aleven\"},{\"authorId\":\"145433768\",\"name\":\"Ron Salden\"}],\"doi\":\"10.1016/j.chb.2008.12.011\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7564a4ca6b23ed9b62877e442c77dd62bb028718\",\"title\":\"The worked-example effect: Not an artefact of lousy control conditions\",\"url\":\"https://www.semanticscholar.org/paper/7564a4ca6b23ed9b62877e442c77dd62bb028718\",\"venue\":\"Comput. Hum. Behav.\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47710535\",\"name\":\"Devin Schwab\"},{\"authorId\":\"145527877\",\"name\":\"Soumya Ray\"}],\"doi\":\"10.1007/s10994-017-5650-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"486dac5395c1c453d0fe6e1463d5cca06f1f60e7\",\"title\":\"Offline reinforcement learning with task hierarchies\",\"url\":\"https://www.semanticscholar.org/paper/486dac5395c1c453d0fe6e1463d5cca06f1f60e7\",\"venue\":\"Machine Learning\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699645\",\"name\":\"R. Sutton\"},{\"authorId\":\"144368601\",\"name\":\"Doina Precup\"},{\"authorId\":\"1699868\",\"name\":\"Satinder Singh\"}],\"doi\":\"10.1016/S0004-3702(99)00052-1\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0e7638dc16a5e5e9e46c91272bfb9c3dd242ef6d\",\"title\":\"Between MDPs and Semi-MDPs: A Framework for Temporal Abstraction in Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/0e7638dc16a5e5e9e46c91272bfb9c3dd242ef6d\",\"venue\":\"Artif. Intell.\",\"year\":1999},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Xin Wang\"},{\"authorId\":null,\"name\":\"Wenhu Chen\"},{\"authorId\":null,\"name\":\"Jiawei Wu\"},{\"authorId\":null,\"name\":\"Yuan-Fang Wang\"},{\"authorId\":null,\"name\":\"William Yang Wang. Video captioning via hierarchical reinf learning\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In CVPR\",\"url\":\"\",\"venue\":\"pages 4213\\u20134222,\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ana Iglesias\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Paloma Mart\\u0131\\u0301nez\",\"url\":\"\",\"venue\":\"Ricardo Aler, and Fernando Fern\\u00e1ndez. Reinforcement learning of pedagogical policies in adaptive and intelligent educational systems. Knowledge-Based Systems, 22(4):266\\u2013270,\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1446962550\",\"name\":\"Dock Bumpers\"},{\"authorId\":\"1446961266\",\"name\":\"Support Ledgers\"}],\"doi\":\"10.1023/A:1017189329742\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e113be5f2d8458877ad64b8ac0023c332dc16c0e\",\"title\":\"Volume 2\",\"url\":\"https://www.semanticscholar.org/paper/e113be5f2d8458877ad64b8ac0023c332dc16c0e\",\"venue\":\"Proceedings of the Ninth International Conference on Computer Supported Cooperative Work in Design, 2005.\",\"year\":2005},{\"arxivId\":\"1711.11135\",\"authors\":[{\"authorId\":\"48631993\",\"name\":\"Xin Eric Wang\"},{\"authorId\":\"2928777\",\"name\":\"Wenhu Chen\"},{\"authorId\":\"46365930\",\"name\":\"Jiawei Wu\"},{\"authorId\":\"1706938\",\"name\":\"Y. Wang\"},{\"authorId\":\"1682479\",\"name\":\"William Yang Wang\"}],\"doi\":\"10.1109/CVPR.2018.00443\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"74b284a66e75b65f5970d05bac000fe91243ee49\",\"title\":\"Video Captioning via Hierarchical Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/74b284a66e75b65f5970d05bac000fe91243ee49\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Guojing Zhou\"},{\"authorId\":null,\"name\":\"Hamoon Azizsoltani\"},{\"authorId\":null,\"name\":\"Markel Sanz Ausin\"},{\"authorId\":null,\"name\":\"Tiffany Barnes\"},{\"authorId\":null,\"name\":\"Min Chi. Hierarchical reinforcement learning for pedag education\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"pages 544\\u2013556\",\"url\":\"\",\"venue\":\"Springer,\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145437032\",\"name\":\"Shitian Shen\"},{\"authorId\":\"51039532\",\"name\":\"Markel Sanz Ausin\"},{\"authorId\":\"3159445\",\"name\":\"B. Mostafavi\"},{\"authorId\":\"1731937\",\"name\":\"Min Chi\"}],\"doi\":\"10.1145/3209219.3209232\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7e095ed60e0b2e730ea8eb6c472b5d2811983698\",\"title\":\"Improving Learning & Reducing Time: A Constrained Action-Based Reinforcement Learning Approach\",\"url\":\"https://www.semanticscholar.org/paper/7e095ed60e0b2e730ea8eb6c472b5d2811983698\",\"venue\":\"UMAP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48534965\",\"name\":\"J. Anderson\"},{\"authorId\":\"34186174\",\"name\":\"A. Corbett\"},{\"authorId\":\"1718810\",\"name\":\"K. Koedinger\"},{\"authorId\":\"50731181\",\"name\":\"R. Pelletier\"}],\"doi\":\"10.1207/S15327809JLS0402_2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bc797fe1ef4f7b63b7924abd3423200a37f7ba65\",\"title\":\"Cognitive Tutors: Lessons Learned\",\"url\":\"https://www.semanticscholar.org/paper/bc797fe1ef4f7b63b7924abd3423200a37f7ba65\",\"venue\":\"\",\"year\":1995},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144299726\",\"name\":\"Thomas G. Dietterich\"}],\"doi\":\"10.1145/242224.242229\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aab43c9c33af00b718cf2ae374b861d49862a563\",\"title\":\"Machine learning\",\"url\":\"https://www.semanticscholar.org/paper/aab43c9c33af00b718cf2ae374b861d49862a563\",\"venue\":\"CSUR\",\"year\":1996},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51216654\",\"name\":\"H. Azizsoltani\"},{\"authorId\":\"5337973\",\"name\":\"E. Sadeghi\"}],\"doi\":\"10.1016/j.engappai.2018.06.007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e4ef6570d31911a6d0c30cb3b4836f1bec0fd562\",\"title\":\"Adaptive sequential strategy for risk estimation of engineering systems using Gaussian process regression active learning\",\"url\":\"https://www.semanticscholar.org/paper/e4ef6570d31911a6d0c30cb3b4836f1bec0fd562\",\"venue\":\"Eng. Appl. Artif. Intell.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"81476483\",\"name\":\"M. Lepper\"},{\"authorId\":\"118565451\",\"name\":\"Maria Woolverton\"},{\"authorId\":\"4641856\",\"name\":\"D. L. Mumme\"},{\"authorId\":\"49423112\",\"name\":\"J. Gurtner\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f7741af65bad659574280a61e540c4d19093b445\",\"title\":\"Motivational techniques of expert human tutors: Lessons for the design of computer-based tutors.\",\"url\":\"https://www.semanticscholar.org/paper/f7741af65bad659574280a61e540c4d19093b445\",\"venue\":\"\",\"year\":1993},{\"arxivId\":\"1511.05952\",\"authors\":[{\"authorId\":\"1725157\",\"name\":\"T. Schaul\"},{\"authorId\":\"34660073\",\"name\":\"John Quan\"},{\"authorId\":\"2460849\",\"name\":\"Ioannis Antonoglou\"},{\"authorId\":\"145824029\",\"name\":\"D. Silver\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c6170fa90d3b2efede5a2e1660cb23e1c824f2ca\",\"title\":\"Prioritized Experience Replay\",\"url\":\"https://www.semanticscholar.org/paper/c6170fa90d3b2efede5a2e1660cb23e1c824f2ca\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51216654\",\"name\":\"H. Azizsoltani\"},{\"authorId\":\"49170904\",\"name\":\"Yeo-Jin Kim\"},{\"authorId\":\"51039532\",\"name\":\"Markel Sanz Ausin\"},{\"authorId\":\"1734603\",\"name\":\"T. Barnes\"},{\"authorId\":\"1731937\",\"name\":\"Min Chi\"}],\"doi\":\"10.24963/ijcai.2019/273\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"22433eaf7dc3fecb2e7e2e3560bc383288c98041\",\"title\":\"Unobserved Is Not Equal to Non-existent: Using Gaussian Processes to Infer Immediate Rewards Across Contexts\",\"url\":\"https://www.semanticscholar.org/paper/22433eaf7dc3fecb2e7e2e3560bc383288c98041\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1826505\",\"name\":\"Dimitrios Pierrakos\"},{\"authorId\":\"4738873\",\"name\":\"G. Paliouras\"},{\"authorId\":\"3262443\",\"name\":\"C. Papatheodorou\"},{\"authorId\":\"2124138\",\"name\":\"C. Spyropoulos\"},{\"authorId\":\"1755550\",\"name\":\"J. Karat\"},{\"authorId\":\"1789633\",\"name\":\"C. Karat\"},{\"authorId\":\"40565861\",\"name\":\"C. Brodie\"},{\"authorId\":\"1790758\",\"name\":\"J. Vergo\"},{\"authorId\":\"153160404\",\"name\":\"R. Wilson\"}],\"doi\":\"10.1023/A:1026251511156\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f48cbc7a1f9c712c4111b2e2428f00c91a4c2568\",\"title\":\"User Modeling and User-Adapted Interaction\",\"url\":\"https://www.semanticscholar.org/paper/f48cbc7a1f9c712c4111b2e2428f00c91a4c2568\",\"venue\":\"User Modeling and User-Adapted Interaction\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Heriberto Cuay\\u00e1huitl\"},{\"authorId\":null,\"name\":\"Nina Dethlefs\"},{\"authorId\":null,\"name\":\"Lutz Frommberger\"},{\"authorId\":null,\"name\":\"Kai-Florian Richter\"},{\"authorId\":null,\"name\":\"John Bateman. Generating adaptive route instructions us ICSC\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"pages 319\\u2013 334\",\"url\":\"\",\"venue\":\"Springer,\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145433768\",\"name\":\"Ron Salden\"},{\"authorId\":\"1779915\",\"name\":\"V. Aleven\"},{\"authorId\":\"2681621\",\"name\":\"R. Schwonke\"},{\"authorId\":\"1747907\",\"name\":\"A. Renkl\"}],\"doi\":\"10.1007/S11251-009-9107-8\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c4e075e116e1d2b172c1a76c4c1236fbf84c0772\",\"title\":\"The expertise reversal effect and worked examples in tutored problem solving\",\"url\":\"https://www.semanticscholar.org/paper/c4e075e116e1d2b172c1a76c4c1236fbf84c0772\",\"venue\":\"\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144115104\",\"name\":\"A. D. Carvalho\"},{\"authorId\":\"68983551\",\"name\":\"M. G. Romay\"},{\"authorId\":\"1996441\",\"name\":\"K. Guelton\"},{\"authorId\":\"1712282\",\"name\":\"A. Kaklauskas\"},{\"authorId\":\"144833640\",\"name\":\"B. K. Panigrahi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0af5e2266b8bee31096c219bc99d49d0ca51e004\",\"title\":\"ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE\",\"url\":\"https://www.semanticscholar.org/paper/0af5e2266b8bee31096c219bc99d49d0ca51e004\",\"venue\":\"\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31794494\",\"name\":\"J. Beck\"},{\"authorId\":\"3325410\",\"name\":\"B. Woolf\"},{\"authorId\":\"7180590\",\"name\":\"C. Beal\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3910e41b1d76557538d8bf22c914160537e9997e\",\"title\":\"ADVISOR: A Machine Learning Architecture for Intelligent Tutor Construction\",\"url\":\"https://www.semanticscholar.org/paper/3910e41b1d76557538d8bf22c914160537e9997e\",\"venue\":\"AAAI/IAAI\",\"year\":2000},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34035900\",\"name\":\"F. Charbonnier\"},{\"authorId\":\"145803824\",\"name\":\"H. Alla\"},{\"authorId\":\"144383917\",\"name\":\"R. David\"}],\"doi\":\"10.1109/87.748144\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c288f4a98a9751d5cc9352bd6f3e57fc7d36c6f4\",\"title\":\"Discrete-event dynamic systems\",\"url\":\"https://www.semanticscholar.org/paper/c288f4a98a9751d5cc9352bd6f3e57fc7d36c6f4\",\"venue\":\"IEEE Trans. Control. Syst. Technol.\",\"year\":1999},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46660903\",\"name\":\"J. Junker\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2ef2dcc8ffbc5556807eb251d7095d513490dab7\",\"title\":\"One On One Tutoring By Humans And Computers\",\"url\":\"https://www.semanticscholar.org/paper/2ef2dcc8ffbc5556807eb251d7095d513490dab7\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29984691\",\"name\":\"A. Renkl\"},{\"authorId\":\"1737845\",\"name\":\"R. K. Atkinson\"},{\"authorId\":\"30080689\",\"name\":\"U. Maier\"},{\"authorId\":\"40368267\",\"name\":\"R. Staley\"}],\"doi\":\"10.1080/00220970209599510\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bda25348e038bfae46336058940efa7e0b03beb8\",\"title\":\"From Example Study to Problem Solving: Smooth Transitions Help Learning\",\"url\":\"https://www.semanticscholar.org/paper/bda25348e038bfae46336058940efa7e0b03beb8\",\"venue\":\"\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1875900\",\"name\":\"Anna N. Rafferty\"},{\"authorId\":\"2563117\",\"name\":\"Emma Brunskill\"},{\"authorId\":\"1799860\",\"name\":\"T. Griffiths\"},{\"authorId\":\"3210220\",\"name\":\"Patrick Shafto\"}],\"doi\":\"10.1111/cogs.12290\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a8dd4219745c5f3b840bb09ab882a574823161bb\",\"title\":\"Faster Teaching via POMDP Planning\",\"url\":\"https://www.semanticscholar.org/paper/a8dd4219745c5f3b840bb09ab882a574823161bb\",\"venue\":\"Cogn. Sci.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1620865361\",\"name\":\"Seguin Hen\"}],\"doi\":\"10.1515/9783111576855-015\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bdc3d618db015b2f17cd76224a942bfdfc36dc73\",\"title\":\"J\",\"url\":\"https://www.semanticscholar.org/paper/bdc3d618db015b2f17cd76224a942bfdfc36dc73\",\"venue\":\"Edinburgh Medical and Surgical Journal\",\"year\":1824},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144137911\",\"name\":\"T. Mandel\"},{\"authorId\":\"38057113\",\"name\":\"Yun-En Liu\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"},{\"authorId\":\"2563117\",\"name\":\"Emma Brunskill\"},{\"authorId\":\"1986848\",\"name\":\"Z. Popovic\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"471e452dc02edcb9c8c0ec446cc2eb22188dd86b\",\"title\":\"Offline policy evaluation across representations with applications to educational games\",\"url\":\"https://www.semanticscholar.org/paper/471e452dc02edcb9c8c0ec446cc2eb22188dd86b\",\"venue\":\"AAMAS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Glen Berseth Xue Bin Peng\"},{\"authorId\":null,\"name\":\"KangKang Yin\"},{\"authorId\":null,\"name\":\"Michiel Van De Panne\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Deeploco : Dynamic loco - motion skills using hierarchical deep reinforcement learn\",\"url\":\"\",\"venue\":\"ACM Transactions on Graphics\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3349939\",\"name\":\"Guojing Zhou\"},{\"authorId\":\"51216654\",\"name\":\"H. Azizsoltani\"},{\"authorId\":\"51039532\",\"name\":\"Markel Sanz Ausin\"},{\"authorId\":\"1734603\",\"name\":\"T. Barnes\"},{\"authorId\":\"1731937\",\"name\":\"Min Chi\"}],\"doi\":\"10.1007/978-3-030-23204-7_45\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bd7d3becbe36188f22f08609725859c5b72c36df\",\"title\":\"Hierarchical Reinforcement Learning for Pedagogical Policy Induction\",\"url\":\"https://www.semanticscholar.org/paper/bd7d3becbe36188f22f08609725859c5b72c36df\",\"venue\":\"AIED\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Travis Mandel\"},{\"authorId\":null,\"name\":\"Yun-En Liu\"},{\"authorId\":null,\"name\":\"Sergey Levine\"},{\"authorId\":null,\"name\":\"Emma Brunskill\"},{\"authorId\":null,\"name\":\"Zoran Popovic. Offline policy evaluation across represen games\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In AAMAS\",\"url\":\"\",\"venue\":\"pages 1077\\u20131084,\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32200465\",\"name\":\"X. Peng\"},{\"authorId\":\"2994035\",\"name\":\"G. Berseth\"},{\"authorId\":\"153505292\",\"name\":\"KangKang Yin\"},{\"authorId\":\"1745029\",\"name\":\"M. V. D. Panne\"}],\"doi\":\"10.1145/3072959.3073602\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9917363277c783a01bff32af1c27fc9b373ad55d\",\"title\":\"DeepLoco: dynamic locomotion skills using hierarchical deep reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/9917363277c783a01bff32af1c27fc9b373ad55d\",\"venue\":\"ACM Trans. Graph.\",\"year\":2017},{\"arxivId\":\"1604.06057\",\"authors\":[{\"authorId\":\"1954876\",\"name\":\"Tejas D. Kulkarni\"},{\"authorId\":\"144958935\",\"name\":\"Karthik Narasimhan\"},{\"authorId\":\"3231182\",\"name\":\"A. Saeedi\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d37620e6f8fe678a43e12930743281cd8cca6a66\",\"title\":\"Hierarchical Deep Reinforcement Learning: Integrating Temporal Abstraction and Intrinsic Motivation\",\"url\":\"https://www.semanticscholar.org/paper/d37620e6f8fe678a43e12930743281cd8cca6a66\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144703353\",\"name\":\"G. Miller\"}],\"doi\":\"10.1111/(issn)1551-6709\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9d81ed652828fd536d86cc371278efcb502572cd\",\"title\":\"Cognitive science.\",\"url\":\"https://www.semanticscholar.org/paper/9d81ed652828fd536d86cc371278efcb502572cd\",\"venue\":\"Science\",\"year\":1981},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145902687\",\"name\":\"A. Iglesias\"},{\"authorId\":\"144646131\",\"name\":\"Paloma Mart\\u00ednez\"},{\"authorId\":\"3266579\",\"name\":\"R. Aler\"},{\"authorId\":\"143901279\",\"name\":\"F. Fern\\u00e1ndez\"}],\"doi\":\"10.1016/j.knosys.2009.01.007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6d9aba18f1f6187f79a51379a6b018aebac8b274\",\"title\":\"Reinforcement learning of pedagogical policies in adaptive and intelligent educational systems\",\"url\":\"https://www.semanticscholar.org/paper/6d9aba18f1f6187f79a51379a6b018aebac8b274\",\"venue\":\"Knowl. Based Syst.\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ron JCM Salden\"},{\"authorId\":null,\"name\":\"Vincent Aleven\"},{\"authorId\":null,\"name\":\"Rolf Schwonke\"},{\"authorId\":null,\"name\":\"Alexander Renkl. The expertise reversal effect\"},{\"authorId\":null,\"name\":\"worked examples in tutored problem solving\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Instructional Science\",\"url\":\"\",\"venue\":\"38(3):289\\u2013307,\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Carl Edward Rasmussen. Gaussian processes in machine le learning\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"pages 63\\u201371\",\"url\":\"\",\"venue\":\"Springer,\",\"year\":2004}],\"title\":\"Hierarchical Reinforcement Learning for Pedagogical Policy Induction (Extended Abstract)\",\"topics\":[{\"topic\":\"Reinforcement learning\",\"topicId\":\"2557\",\"url\":\"https://www.semanticscholar.org/topic/2557\"}],\"url\":\"https://www.semanticscholar.org/paper/6a729366768abd5d85a0efd666e6f7ab40ca27d2\",\"venue\":\"IJCAI\",\"year\":2020}\n"