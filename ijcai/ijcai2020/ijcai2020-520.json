"{\"abstract\":\"8-bit integer inference, as a promising direction in reducing both the latency and storage of deep neural networks, has made great progress recently. On the other hand, previous systems still rely on 32-bit floating point for certain functions in complex models (e.g., Softmax in Transformer), and make heavy use of quantization and de-quantization. In this work, we show that after a principled modification on the Transformer architecture, dubbed Integer Transformer, an (almost) fully 8-bit integer inference algorithm Scale Propagation could be derived. De-quantization is adopted when necessary, which makes the network more efficient. Our experiments on WMT16 En Ro, WMT14 En De and En->Fr translation tasks as well as the WikiText-103 language modelling task show that the fully 8-bit Transformer system achieves comparable performance with the floating point baseline but requires nearly 4x less memory footprint.\",\"arxivId\":\"2009.08034\",\"authors\":[{\"authorId\":\"49417594\",\"name\":\"Y. Lin\",\"url\":\"https://www.semanticscholar.org/author/49417594\"},{\"authorId\":\"48514532\",\"name\":\"Yanyang Li\",\"url\":\"https://www.semanticscholar.org/author/48514532\"},{\"authorId\":\"1390576286\",\"name\":\"Tengbo Liu\",\"url\":\"https://www.semanticscholar.org/author/1390576286\"},{\"authorId\":\"1739326269\",\"name\":\"Tong Xiao\",\"url\":\"https://www.semanticscholar.org/author/1739326269\"},{\"authorId\":\"26456687\",\"name\":\"T. Liu\",\"url\":\"https://www.semanticscholar.org/author/26456687\"},{\"authorId\":\"1728004\",\"name\":\"Jingbo Zhu\",\"url\":\"https://www.semanticscholar.org/author/1728004\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"114172611\",\"name\":\"Chi Hu\"},{\"authorId\":\"49730090\",\"name\":\"Bei Li\"},{\"authorId\":\"5334267\",\"name\":\"Yinqiao Li\"},{\"authorId\":\"49417594\",\"name\":\"Y. Lin\"},{\"authorId\":\"48514532\",\"name\":\"Yanyang Li\"},{\"authorId\":\"98243944\",\"name\":\"Chenglong Wang\"},{\"authorId\":\"1739326269\",\"name\":\"Tong Xiao\"},{\"authorId\":\"1728004\",\"name\":\"Jingbo Zhu\"}],\"doi\":\"10.18653/v1/2020.ngt-1.24\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"18f86146a095a30d57569197c04f807bb10064e8\",\"title\":\"The NiuTrans System for WNGT 2020 Efficiency Task\",\"url\":\"https://www.semanticscholar.org/paper/18f86146a095a30d57569197c04f807bb10064e8\",\"venue\":\"NGT@ACL\",\"year\":2020},{\"arxivId\":\"2009.09152\",\"authors\":[{\"authorId\":\"49417594\",\"name\":\"Y. Lin\"},{\"authorId\":\"48514532\",\"name\":\"Yanyang Li\"},{\"authorId\":\"152764184\",\"name\":\"Ziyang Wang\"},{\"authorId\":\"49730090\",\"name\":\"Bei Li\"},{\"authorId\":\"94042851\",\"name\":\"Quan Du\"},{\"authorId\":\"1739326269\",\"name\":\"Tong Xiao\"},{\"authorId\":\"1728004\",\"name\":\"Jingbo Zhu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"404526040de867f1e920be80e00017c7558e95e6\",\"title\":\"Weight Distillation: Transferring the Knowledge in Neural Network Parameters\",\"url\":\"https://www.semanticscholar.org/paper/404526040de867f1e920be80e00017c7558e95e6\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":220483468,\"doi\":\"10.24963/ijcai.2020/520\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"89e39742e30c842cc8bf43311d496aa9e92fe8a6\",\"references\":[{\"arxivId\":\"2002.06546\",\"authors\":[{\"authorId\":\"48514532\",\"name\":\"Yanyang Li\"},{\"authorId\":\"145805403\",\"name\":\"Q. Wang\"},{\"authorId\":\"1391183811\",\"name\":\"Tong Xiao\"},{\"authorId\":\"26456687\",\"name\":\"T. Liu\"},{\"authorId\":\"1728004\",\"name\":\"Jingbo Zhu\"}],\"doi\":\"10.1609/AAAI.V34I05.6344\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f24de84e43d411ba6549780b60278dd14653c7e3\",\"title\":\"Neural Machine Translation with Joint Representation\",\"url\":\"https://www.semanticscholar.org/paper/f24de84e43d411ba6549780b60278dd14653c7e3\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1703.09039\",\"authors\":[{\"authorId\":\"1691305\",\"name\":\"V. Sze\"},{\"authorId\":\"49069271\",\"name\":\"Y. Chen\"},{\"authorId\":\"1950815\",\"name\":\"Tien-Ju Yang\"},{\"authorId\":\"1775477\",\"name\":\"J. Emer\"}],\"doi\":\"10.1109/JPROC.2017.2761740\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3f116042f50a499ab794bcc1255915bee507413c\",\"title\":\"Efficient Processing of Deep Neural Networks: A Tutorial and Survey\",\"url\":\"https://www.semanticscholar.org/paper/3f116042f50a499ab794bcc1255915bee507413c\",\"venue\":\"Proceedings of the IEEE\",\"year\":2017},{\"arxivId\":\"1906.11024\",\"authors\":[{\"authorId\":\"1391183811\",\"name\":\"Tong Xiao\"},{\"authorId\":\"5334267\",\"name\":\"Yinqiao Li\"},{\"authorId\":\"1728004\",\"name\":\"Jingbo Zhu\"},{\"authorId\":\"121854326\",\"name\":\"Zhengtao Yu\"},{\"authorId\":\"26456687\",\"name\":\"T. Liu\"}],\"doi\":\"10.24963/ijcai.2019/735\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5b3a37c1bd06bf3b0062e327a04b4a7af13d4e6f\",\"title\":\"Sharing Attention Weights for Fast Transformer\",\"url\":\"https://www.semanticscholar.org/paper/5b3a37c1bd06bf3b0062e327a04b4a7af13d4e6f\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"1706.03762\",\"authors\":[{\"authorId\":\"40348417\",\"name\":\"Ashish Vaswani\"},{\"authorId\":\"1846258\",\"name\":\"Noam Shazeer\"},{\"authorId\":\"3877127\",\"name\":\"Niki Parmar\"},{\"authorId\":\"39328010\",\"name\":\"Jakob Uszkoreit\"},{\"authorId\":\"145024664\",\"name\":\"Llion Jones\"},{\"authorId\":\"19177000\",\"name\":\"Aidan N. Gomez\"},{\"authorId\":\"40527594\",\"name\":\"L. Kaiser\"},{\"authorId\":\"3443442\",\"name\":\"Illia Polosukhin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"204e3073870fae3d05bcbc2f6a8e263d9b72e776\",\"title\":\"Attention is All you Need\",\"url\":\"https://www.semanticscholar.org/paper/204e3073870fae3d05bcbc2f6a8e263d9b72e776\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1709.07809\",\"authors\":[{\"authorId\":\"1755162\",\"name\":\"Philipp Koehn\"}],\"doi\":\"10.1017/9781108608480\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"247328a082d86199ed5a98e1d726aa205c1da9df\",\"title\":\"Neural Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/247328a082d86199ed5a98e1d726aa205c1da9df\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1803.01814\",\"authors\":[{\"authorId\":\"40555034\",\"name\":\"E. Hoffer\"},{\"authorId\":\"2607278\",\"name\":\"R. Banner\"},{\"authorId\":\"40897983\",\"name\":\"Itay Golan\"},{\"authorId\":\"1912398\",\"name\":\"Daniel Soudry\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"48f0b0ab8ccdca861e374f26c3e54e1720cfb22e\",\"title\":\"Norm matters: efficient and accurate normalization schemes in deep networks\",\"url\":\"https://www.semanticscholar.org/paper/48f0b0ab8ccdca861e374f26c3e54e1720cfb22e\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1811.01721\",\"authors\":[{\"authorId\":\"1740242\",\"name\":\"J. Johnson\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6e6f92a1eded19388301983f8d3bdb6cd20b8c48\",\"title\":\"Rethinking floating point for deep learning\",\"url\":\"https://www.semanticscholar.org/paper/6e6f92a1eded19388301983f8d3bdb6cd20b8c48\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1805.08691\",\"authors\":[{\"authorId\":\"37614555\",\"name\":\"J. Gong\"},{\"authorId\":\"1921920\",\"name\":\"Haihao Shen\"},{\"authorId\":\"1815209\",\"name\":\"G. Zhang\"},{\"authorId\":\"46521842\",\"name\":\"X. Liu\"},{\"authorId\":\"31317708\",\"name\":\"Shane Li\"},{\"authorId\":\"152124159\",\"name\":\"Ge Jin\"},{\"authorId\":\"9298900\",\"name\":\"N. Maheshwari\"},{\"authorId\":\"144306358\",\"name\":\"E. Fomenko\"},{\"authorId\":\"46250771\",\"name\":\"Eden Segal\"}],\"doi\":\"10.1145/3229762.3229763\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ed90a9d379f6412a1580e7eda5cb91640000dc42\",\"title\":\"Highly Efficient 8-bit Low Precision Inference of Convolutional Neural Networks with IntelCaffe\",\"url\":\"https://www.semanticscholar.org/paper/ed90a9d379f6412a1580e7eda5cb91640000dc42\",\"venue\":\"ReQuEST@ASPLOS\",\"year\":2018},{\"arxivId\":\"1906.02243\",\"authors\":[{\"authorId\":\"2268272\",\"name\":\"Emma Strubell\"},{\"authorId\":\"47079359\",\"name\":\"Ananya Ganesh\"},{\"authorId\":\"143753639\",\"name\":\"A. McCallum\"}],\"doi\":\"10.18653/v1/P19-1355\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d6a083dad7114f3a39adc65c09bfbb6cf3fee9ea\",\"title\":\"Energy and Policy Considerations for Deep Learning in NLP\",\"url\":\"https://www.semanticscholar.org/paper/d6a083dad7114f3a39adc65c09bfbb6cf3fee9ea\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1906.01787\",\"authors\":[{\"authorId\":\"145805404\",\"name\":\"Qiang Wang\"},{\"authorId\":\"49730090\",\"name\":\"Bei Li\"},{\"authorId\":\"1391183811\",\"name\":\"Tong Xiao\"},{\"authorId\":\"1728004\",\"name\":\"Jingbo Zhu\"},{\"authorId\":\"2348067\",\"name\":\"Changliang Li\"},{\"authorId\":\"1758353\",\"name\":\"Derek F. Wong\"},{\"authorId\":\"1774304\",\"name\":\"Lidia S. Chao\"}],\"doi\":\"10.18653/v1/P19-1176\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a39398f68ae7e042f2ef5009e31b4e6a20fd5736\",\"title\":\"Learning Deep Transformer Models for Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/a39398f68ae7e042f2ef5009e31b4e6a20fd5736\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1502.01852\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/ICCV.2015.123\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d6f2f611da110b5b5061731be3fc4c7f45d8ee23\",\"title\":\"Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification\",\"url\":\"https://www.semanticscholar.org/paper/d6f2f611da110b5b5061731be3fc4c7f45d8ee23\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1710.03740\",\"authors\":[{\"authorId\":\"1802359\",\"name\":\"P. Micikevicius\"},{\"authorId\":\"46617804\",\"name\":\"Sharan Narang\"},{\"authorId\":\"41222446\",\"name\":\"J. Alben\"},{\"authorId\":\"2040049\",\"name\":\"G. Diamos\"},{\"authorId\":\"152585800\",\"name\":\"E. Elsen\"},{\"authorId\":\"144933252\",\"name\":\"D. Garc\\u00eda\"},{\"authorId\":\"31963005\",\"name\":\"B. Ginsburg\"},{\"authorId\":\"122523478\",\"name\":\"Michael Houston\"},{\"authorId\":\"2787022\",\"name\":\"O. Kuchaiev\"},{\"authorId\":\"145595812\",\"name\":\"G. Venkatesh\"},{\"authorId\":\"46477167\",\"name\":\"H. Wu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2e10560579f2bdeae0143141f26bd9f0a195b4b7\",\"title\":\"Mixed Precision Training\",\"url\":\"https://www.semanticscholar.org/paper/2e10560579f2bdeae0143141f26bd9f0a195b4b7\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1809.10853\",\"authors\":[{\"authorId\":\"51428394\",\"name\":\"Alexei Baevski\"},{\"authorId\":\"2325985\",\"name\":\"M. Auli\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d170bd486e4c0fe82601e322b0e9e0dde63ab299\",\"title\":\"Adaptive Input Representations for Neural Language Modeling\",\"url\":\"https://www.semanticscholar.org/paper/d170bd486e4c0fe82601e322b0e9e0dde63ab299\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1910.10485\",\"authors\":[{\"authorId\":\"134028006\",\"name\":\"Gabriele Prato\"},{\"authorId\":\"1380260189\",\"name\":\"Ella Charlaix\"},{\"authorId\":\"1924511\",\"name\":\"M. Rezagholizadeh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e8ed90530663c3f10d0fc777563495dad817ddb6\",\"title\":\"Fully Quantized Transformer for Improved Translation\",\"url\":\"https://www.semanticscholar.org/paper/e8ed90530663c3f10d0fc777563495dad817ddb6\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2001.00926\",\"authors\":[{\"authorId\":\"11591799\",\"name\":\"E. Wu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0e3b9deaab1c70eb70b75abaee51375817c16293\",\"title\":\"Learning Accurate Integer Transformer Machine-Translation Models\",\"url\":\"https://www.semanticscholar.org/paper/0e3b9deaab1c70eb70b75abaee51375817c16293\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1712.05877\",\"authors\":[{\"authorId\":\"11543879\",\"name\":\"B. Jacob\"},{\"authorId\":\"30558915\",\"name\":\"Skirmantas Kligys\"},{\"authorId\":null,\"name\":\"Bo Chen\"},{\"authorId\":\"2717876\",\"name\":\"Menglong Zhu\"},{\"authorId\":\"38796354\",\"name\":\"Matthew Tang\"},{\"authorId\":\"144727050\",\"name\":\"A. Howard\"},{\"authorId\":\"2595180\",\"name\":\"H. Adam\"},{\"authorId\":\"2741985\",\"name\":\"D. Kalenichenko\"}],\"doi\":\"10.1109/CVPR.2018.00286\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"59d0d7ccec2db66cad20cac5721ce54a8a058294\",\"title\":\"Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference\",\"url\":\"https://www.semanticscholar.org/paper/59d0d7ccec2db66cad20cac5721ce54a8a058294\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1804.05038\",\"authors\":[{\"authorId\":\"153531519\",\"name\":\"Jerry Quinn\"},{\"authorId\":\"143668305\",\"name\":\"Miguel Ballesteros\"}],\"doi\":\"10.18653/v1/N18-3014\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a7c37a34dabb036daeed3a94b55f87aa32578bdc\",\"title\":\"Pieces of Eight: 8-bit Neural Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/a7c37a34dabb036daeed3a94b55f87aa32578bdc\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":\"1906.00532\",\"authors\":[{\"authorId\":\"153632986\",\"name\":\"Aishwarya Bhandare\"},{\"authorId\":\"3178304\",\"name\":\"V. Sripathi\"},{\"authorId\":\"51135358\",\"name\":\"Deepthi Karkada\"},{\"authorId\":\"50477715\",\"name\":\"Vivek Menon\"},{\"authorId\":\"2113157\",\"name\":\"Sun Choi\"},{\"authorId\":\"40025857\",\"name\":\"Kushal Datta\"},{\"authorId\":\"2087293\",\"name\":\"V. Saletore\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3366e9eb81880d172752d4397cb8e9e6de02b935\",\"title\":\"Efficient 8-Bit Quantization of Transformer Neural Machine Language Translation Model\",\"url\":\"https://www.semanticscholar.org/paper/3366e9eb81880d172752d4397cb8e9e6de02b935\",\"venue\":\"ArXiv\",\"year\":2019}],\"title\":\"Towards Fully 8-bit Integer Inference for the Transformer Model\",\"topics\":[{\"topic\":\"Transformer\",\"topicId\":\"6977\",\"url\":\"https://www.semanticscholar.org/topic/6977\"},{\"topic\":\"8-bit\",\"topicId\":\"49851\",\"url\":\"https://www.semanticscholar.org/topic/49851\"}],\"url\":\"https://www.semanticscholar.org/paper/89e39742e30c842cc8bf43311d496aa9e92fe8a6\",\"venue\":\"IJCAI\",\"year\":2020}\n"