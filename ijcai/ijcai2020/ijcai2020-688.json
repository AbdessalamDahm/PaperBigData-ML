"{\"abstract\":\"Human gaze reveals a wealth of information about internal cognitive state. Thus, gaze-related research has significantly increased in computer vision, natural language processing, decision learning, and robotics in recent years. We provide a high-level overview of the research efforts in these fields, including collecting human gaze data sets, modeling gaze behaviors, and utilizing gaze information in various applications, with the goal of enhancing communication between these research areas. We discuss future challenges and potential applications that work towards a common goal of human-centered artificial intelligence.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"2657185\",\"name\":\"Ruohan Zhang\",\"url\":\"https://www.semanticscholar.org/author/2657185\"},{\"authorId\":\"10978611\",\"name\":\"Akanksha Saran\",\"url\":\"https://www.semanticscholar.org/author/10978611\"},{\"authorId\":\"73548014\",\"name\":\"Bo Liu\",\"url\":\"https://www.semanticscholar.org/author/73548014\"},{\"authorId\":\"46759203\",\"name\":\"Y. Zhu\",\"url\":\"https://www.semanticscholar.org/author/46759203\"},{\"authorId\":\"1807482896\",\"name\":\"Sihang Guo\",\"url\":\"https://www.semanticscholar.org/author/1807482896\"},{\"authorId\":\"2791038\",\"name\":\"S. Niekum\",\"url\":\"https://www.semanticscholar.org/author/2791038\"},{\"authorId\":\"1691804\",\"name\":\"D. Ballard\",\"url\":\"https://www.semanticscholar.org/author/1691804\"},{\"authorId\":\"2848854\",\"name\":\"M. Hayhoe\",\"url\":\"https://www.semanticscholar.org/author/2848854\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":\"2010.15942\",\"authors\":[{\"authorId\":\"2657185\",\"name\":\"Ruohan Zhang\"},{\"authorId\":\"1720831208\",\"name\":\"Bo Liu\"},{\"authorId\":\"1778450\",\"name\":\"Y. Zhu\"},{\"authorId\":\"1807482896\",\"name\":\"Sihang Guo\"},{\"authorId\":\"2848854\",\"name\":\"M. Hayhoe\"},{\"authorId\":\"1691804\",\"name\":\"D. Ballard\"},{\"authorId\":\"144848112\",\"name\":\"P. Stone\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"0af86c8fe633e71aeb38561165609bc14d699290\",\"title\":\"Human versus Machine Attention in Deep Reinforcement Learning Tasks\",\"url\":\"https://www.semanticscholar.org/paper/0af86c8fe633e71aeb38561165609bc14d699290\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.14804\",\"authors\":[{\"authorId\":\"144190085\",\"name\":\"L. Guan\"},{\"authorId\":\"151500192\",\"name\":\"M. Verma\"},{\"authorId\":\"1740315\",\"name\":\"S. Kambhampati\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6e3273ea2cac5ebbf1479227c254d1d5d5fd0979\",\"title\":\"Explanation Augmented Feedback in Human-in-the-Loop Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/6e3273ea2cac5ebbf1479227c254d1d5d5fd0979\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":220483132,\"doi\":\"10.24963/ijcai.2020/689\",\"fieldsOfStudy\":[\"Computer Science\",\"Medicine\"],\"influentialCitationCount\":0,\"is_open_access\":false,\"is_publisher_licensed\":false,\"paperId\":\"97a06ab02b44a696619c21de32d6ec0dcfc876eb\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Sen He\"},{\"authorId\":null,\"name\":\"Hamed R Tavakoli\"},{\"authorId\":null,\"name\":\"Ali Borji\"},{\"authorId\":null,\"name\":\"Yang Mi\"},{\"authorId\":null,\"name\":\"Nicolas Pugeault. Understanding\"},{\"authorId\":null,\"name\":\"visualizing deep visual saliency models\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In Proceedings of the IEEE conference on computer vision and pattern recognition\",\"url\":\"\",\"venue\":\"pages 10206\\u201310215,\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34646933\",\"name\":\"T. V. Nguyen\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"}],\"doi\":\"10.1007/s11263-017-1042-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"22894791cb1e139177cef3fbb1ebda417a4b549f\",\"title\":\"Attentive Systems: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/22894791cb1e139177cef3fbb1ebda417a4b549f\",\"venue\":\"International Journal of Computer Vision\",\"year\":2017},{\"arxivId\":\"1707.06029\",\"authors\":[{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"1899119\",\"name\":\"Jongwook Choi\"},{\"authorId\":\"4945045\",\"name\":\"Yeonhwa Kim\"},{\"authorId\":\"143912065\",\"name\":\"Kyung Yoo\"},{\"authorId\":\"2135453\",\"name\":\"S. Lee\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1109/CVPR.2017.648\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1a7f16a3b5acaf4aaf9581e2a5a15867e883a95d\",\"title\":\"Supervising Neural Attention Models for Video Captioning by Human Gaze Data\",\"url\":\"https://www.semanticscholar.org/paper/1a7f16a3b5acaf4aaf9581e2a5a15867e883a95d\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1608.05203\",\"authors\":[{\"authorId\":\"1751242\",\"name\":\"Yusuke Sugano\"},{\"authorId\":\"3194727\",\"name\":\"Andreas Bulling\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c70ad19c90491e2de8de686b6a49f9bbe44692c0\",\"title\":\"Seeing with Humans: Gaze-Assisted Neural Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/c70ad19c90491e2de8de686b6a49f9bbe44692c0\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3192572\",\"name\":\"Emiel van Miltenburg\"},{\"authorId\":\"2828538\",\"name\":\"\\u00c1kos K\\u00e1d\\u00e1r\"},{\"authorId\":\"2045556\",\"name\":\"R. Koolen\"},{\"authorId\":\"145210073\",\"name\":\"E. Krahmer\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"14bfde3b760bc09d4c93f81dc029429fca734c48\",\"title\":\"DIDEC: The Dutch Image Description and Eye-tracking Corpus\",\"url\":\"https://www.semanticscholar.org/paper/14bfde3b760bc09d4c93f81dc029429fca734c48\",\"venue\":\"COLING\",\"year\":2018},{\"arxivId\":\"1312.7570\",\"authors\":[{\"authorId\":\"37710702\",\"name\":\"Stefan Mathe\"},{\"authorId\":\"1781120\",\"name\":\"C. Sminchisescu\"}],\"doi\":\"10.1109/TPAMI.2014.2366154\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e254d0e670ce8217e74aaf1421c72e63e62929e3\",\"title\":\"Actions in the Eye: Dynamic Gaze Datasets and Learnt Saliency Models for Visual Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e254d0e670ce8217e74aaf1421c72e63e62929e3\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ruohan Zhang\"},{\"authorId\":null,\"name\":\"Faraz Torabi\"},{\"authorId\":null,\"name\":\"Lin Guan\"},{\"authorId\":null,\"name\":\"Dana H Ballard\"},{\"authorId\":null,\"name\":\"Peter Stone. Leveraging human guidance for deep reinforc tasks\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In Proceedings of the 28th International Joint Conference on Artificial Intelligence\",\"url\":\"\",\"venue\":\"pages 6339\\u20136346. AAAI Press,\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Nour Karessli\"},{\"authorId\":null,\"name\":\"Zeynep Akata\"},{\"authorId\":null,\"name\":\"Bernt Schiele\"},{\"authorId\":null,\"name\":\"Andreas Bulling. Gaze embeddings for zero-shot image classification\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In Proceedings of the IEEE conference on computer vision and pattern recognition\",\"url\":\"\",\"venue\":\"pages 4525\\u20134534,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"6aee8323be7ad5e568d62ba368bc7123f750515f\",\"title\":\"Paying More Attention to Saliency: Image Captioning with Saliency and Context Attention\",\"url\":\"https://www.semanticscholar.org/paper/6aee8323be7ad5e568d62ba368bc7123f750515f\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1682788\",\"name\":\"A. Thomaz\"},{\"authorId\":\"145666784\",\"name\":\"Guy Hoffman\"},{\"authorId\":\"47746753\",\"name\":\"M. \\u00c7akmak\"}],\"doi\":\"10.1561/2300000049\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"83849ca815395268d902e2cd7d7460feccfb121f\",\"title\":\"Computational Human-Robot Interaction\",\"url\":\"https://www.semanticscholar.org/paper/83849ca815395268d902e2cd7d7460feccfb121f\",\"venue\":\"Found. Trends Robotics\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1689610\",\"name\":\"G. Sagerer\"},{\"authorId\":\"1752970\",\"name\":\"M. Imai\"},{\"authorId\":\"2301161\",\"name\":\"Tony Belpaeme\"},{\"authorId\":\"1682788\",\"name\":\"A. Thomaz\"}],\"doi\":\"10.1145/2559636\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d83fdb161563ffabb32e0174c67eb877060fec21\",\"title\":\"Proceedings of the 2014 ACM/IEEE international conference on Human-robot interaction\",\"url\":\"https://www.semanticscholar.org/paper/d83fdb161563ffabb32e0174c67eb877060fec21\",\"venue\":\"HRI 2014\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Russell Webb\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Computational human - robot interaction Attention is all you need\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1735414\",\"name\":\"T. Knasel\"}],\"doi\":\"10.1016/0921-8890(88)90002-4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"edd77f310393f521669b209cbb6828fb45a8485d\",\"title\":\"Robotics and autonomous systems\",\"url\":\"https://www.semanticscholar.org/paper/edd77f310393f521669b209cbb6828fb45a8485d\",\"venue\":\"Robotics Auton. Syst.\",\"year\":1988},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144114624\",\"name\":\"Juan Xu\"},{\"authorId\":\"144889908\",\"name\":\"M. Jiang\"},{\"authorId\":\"40440632\",\"name\":\"Shuo Wang\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"},{\"authorId\":\"51027614\",\"name\":\"Q. Zhao\"}],\"doi\":\"10.1167/14.1.28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"709e8791193cc3fe9fef9ad983afcd2891e6c680\",\"title\":\"Predicting human gaze beyond pixels.\",\"url\":\"https://www.semanticscholar.org/paper/709e8791193cc3fe9fef9ad983afcd2891e6c680\",\"venue\":\"Journal of vision\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47415361\",\"name\":\"Tao Deng\"},{\"authorId\":\"48506762\",\"name\":\"Hongmei Yan\"},{\"authorId\":\"40548435\",\"name\":\"L. Qin\"},{\"authorId\":\"40092548\",\"name\":\"Thuyen Ngo\"},{\"authorId\":\"50591689\",\"name\":\"B. S. Manjunath\"}],\"doi\":\"10.1109/TITS.2019.2915540\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f612076edfc2959d2bab2bfa470654845bf84a5d\",\"title\":\"How Do Drivers Allocate Their Potential Attention? Driving Fixation Prediction via Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/f612076edfc2959d2bab2bfa470654845bf84a5d\",\"venue\":\"IEEE Transactions on Intelligent Transportation Systems\",\"year\":2020},{\"arxivId\":\"1705.03854\",\"authors\":[{\"authorId\":\"38772386\",\"name\":\"A. Palazzi\"},{\"authorId\":\"3309130\",\"name\":\"Davide Abati\"},{\"authorId\":\"2175529\",\"name\":\"Simone Calderara\"},{\"authorId\":\"2059900\",\"name\":\"Francesco Solera\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/TPAMI.2018.2845370\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"914e98db74f29fc608106ff438edde58965037c5\",\"title\":\"Predicting the Driver's Focus of Attention: The DR(eye)VE Project\",\"url\":\"https://www.semanticscholar.org/paper/914e98db74f29fc608106ff438edde58965037c5\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1801905\",\"name\":\"King-Sun Fu\"}],\"doi\":\"10.1002/0471667196.ess1206\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"bb66ae5f36bc84243979c522d8e3f93539cb6a9f\",\"title\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"url\":\"https://www.semanticscholar.org/paper/bb66ae5f36bc84243979c522d8e3f93539cb6a9f\",\"venue\":\"\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7869872\",\"name\":\"Y. Xu\"},{\"authorId\":\"49266038\",\"name\":\"Yanbing Dong\"},{\"authorId\":\"3423101\",\"name\":\"Junru Wu\"},{\"authorId\":\"30581936\",\"name\":\"Zhengzhong Sun\"},{\"authorId\":\"34692825\",\"name\":\"Zhiru Shi\"},{\"authorId\":\"2152356\",\"name\":\"J. Yu\"},{\"authorId\":\"1702868\",\"name\":\"Shenghua Gao\"}],\"doi\":\"10.1109/CVPR.2018.00559\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cc3bd1659d005ee25c26e3f6aab3c7361f6172b7\",\"title\":\"Gaze Prediction in Dynamic 360\\u00b0 Immersive Videos\",\"url\":\"https://www.semanticscholar.org/paper/cc3bd1659d005ee25c26e3f6aab3c7361f6172b7\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50317425\",\"name\":\"Abhishek Das\"},{\"authorId\":\"37825612\",\"name\":\"Harsh Agrawal\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.18653/v1/D16-1092\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"00158a3a5f00bce40d9e0711d78cd9a6b099c21b\",\"title\":\"Human Attention in Visual Question Answering: Do Humans and Deep Networks look at the same regions?\",\"url\":\"https://www.semanticscholar.org/paper/00158a3a5f00bce40d9e0711d78cd9a6b099c21b\",\"venue\":\"EMNLP 2016\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Adria Recasens\"},{\"authorId\":null,\"name\":\"Aditya Khosla\"},{\"authorId\":null,\"name\":\"Carl Vondrick\"},{\"authorId\":null,\"name\":\"Antonio Torralba\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Where are they looking? In Advances in Neural Information Processing Systems\",\"url\":\"\",\"venue\":\"pages 199\\u2013 207,\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ye Xia\"},{\"authorId\":null,\"name\":\"Danqing Zhang\"},{\"authorId\":null,\"name\":\"Jinkyu Kim\"},{\"authorId\":null,\"name\":\"Ken Nakayama\"},{\"authorId\":null,\"name\":\"Karl Zipser\"},{\"authorId\":null,\"name\":\"David Whitney. Predicting driver attention in critical s vision\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"pages 658\\u2013674\",\"url\":\"\",\"venue\":\"Springer,\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Chien-Ming Huang\"},{\"authorId\":null,\"name\":\"Bilge Mutlu. Anticipatory robot control for efficient hu collaboration\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In 2016 11th ACM/IEEE international conference on human-robot interaction\",\"url\":\"\",\"venue\":\"pages 83\\u201390. IEEE,\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143984593\",\"name\":\"Qiong Huang\"},{\"authorId\":\"145280967\",\"name\":\"A. Veeraraghavan\"},{\"authorId\":\"145285930\",\"name\":\"A. Sabharwal\"}],\"doi\":\"10.1007/s00138-017-0852-4\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"4b6ea0c9b4d4d7f86e5c61a84bf855f4b5deed10\",\"title\":\"TabletGaze: dataset and analysis for unconstrained appearance-based gaze estimation in mobile tablets\",\"url\":\"https://www.semanticscholar.org/paper/4b6ea0c9b4d4d7f86e5c61a84bf855f4b5deed10\",\"venue\":\"Machine Vision and Applications\",\"year\":2017},{\"arxivId\":\"1711.09017\",\"authors\":[{\"authorId\":\"2520795\",\"name\":\"Xucong Zhang\"},{\"authorId\":\"1751242\",\"name\":\"Yusuke Sugano\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"},{\"authorId\":\"3194727\",\"name\":\"Andreas Bulling\"}],\"doi\":\"10.1109/TPAMI.2017.2778103\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"01be6c81374acf31bcbabfea7ef7471601fa8987\",\"title\":\"MPIIGaze: Real-World Dataset and Deep Appearance-Based Gaze Estimation\",\"url\":\"https://www.semanticscholar.org/paper/01be6c81374acf31bcbabfea7ef7471601fa8987\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Zheming Zuo\"},{\"authorId\":null,\"name\":\"Longzhi Yang\"},{\"authorId\":null,\"name\":\"Yonghong Peng\"},{\"authorId\":null,\"name\":\"Fei Chao\"},{\"authorId\":null,\"name\":\"Yanpeng Qu. Gaze-informed egocentric action recognition fo systems\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"IEEE Access\",\"url\":\"\",\"venue\":\"6:12894\\u2013 12904,\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31836187\",\"name\":\"J. Adams\"},{\"authorId\":\"1804336\",\"name\":\"W. Smart\"},{\"authorId\":\"145656551\",\"name\":\"B. Mutlu\"},{\"authorId\":\"1753156\",\"name\":\"L. Takayama\"}],\"doi\":\"10.1145/2696454\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"26a0674a3881c6a5870a30afc50d1e8031fa085a\",\"title\":\"Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction\",\"url\":\"https://www.semanticscholar.org/paper/26a0674a3881c6a5870a30afc50d1e8031fa085a\",\"venue\":\"HRI\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"John M Henderson\"},{\"authorId\":null,\"name\":\"Taylor R Hayes\"},{\"authorId\":null,\"name\":\"Gwendolyn Rehrig\"},{\"authorId\":null,\"name\":\"Fernanda Ferreira. Meaning guides attention during real-wor description\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Scientific reports\",\"url\":\"\",\"venue\":\"8(1):1\\u20139,\",\"year\":2018},{\"arxivId\":\"1904.00767\",\"authors\":[{\"authorId\":\"1807405\",\"name\":\"S. Chen\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1007/978-3-030-01252-6_5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5cab3ce511ec8345d16a28c00094a2800b3919ce\",\"title\":\"Boosted Attention: Leveraging Human Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/5cab3ce511ec8345d16a28c00094a2800b3919ce\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[],\"doi\":\"10.1145/3171221\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"82061e0679b64d163b786b6b2c4370dbac68bb01\",\"title\":\"Proceedings of the 2018 ACM/IEEE International Conference on Human-Robot Interaction\",\"url\":\"https://www.semanticscholar.org/paper/82061e0679b64d163b786b6b2c4370dbac68bb01\",\"venue\":\"HRI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2034445\",\"name\":\"Alexandra Papoutsaki\"},{\"authorId\":\"3430745\",\"name\":\"Patsorn Sangkloy\"},{\"authorId\":\"38560689\",\"name\":\"James Laskey\"},{\"authorId\":\"2277777\",\"name\":\"N. Daskalova\"},{\"authorId\":\"145522949\",\"name\":\"Jeff Huang\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"73fc8e9b1faf45855cceee197f094ca3c05afe1c\",\"title\":\"WebGazer: Scalable Webcam Eye Tracking Using User Interactions\",\"url\":\"https://www.semanticscholar.org/paper/73fc8e9b1faf45855cceee197f094ca3c05afe1c\",\"venue\":\"IJCAI\",\"year\":2016},{\"arxivId\":\"1606.03556\",\"authors\":[{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"37825612\",\"name\":\"Harsh Agrawal\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1016/j.cviu.2017.10.001\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"58cb0c24c936b8a14ca7b2d56ba80de733c545b3\",\"title\":\"Human Attention in Visual Question Answering: Do Humans and Deep Networks look at the same regions?\",\"url\":\"https://www.semanticscholar.org/paper/58cb0c24c936b8a14ca7b2d56ba80de733c545b3\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Mary M Hayhoe. Vision\"},{\"authorId\":null,\"name\":\"action\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Annual review of vision science\",\"url\":\"\",\"venue\":\"3:389\\u2013413,\",\"year\":2017},{\"arxivId\":null,\"authors\":[],\"doi\":\"10.1145/3314111\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"794d296f33d47609835f47793efa878c417d1df6\",\"title\":\"Proceedings of the 11th ACM Symposium on Eye Tracking Research & Applications\",\"url\":\"https://www.semanticscholar.org/paper/794d296f33d47609835f47793efa878c417d1df6\",\"venue\":\"ETRA\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2360748\",\"name\":\"Oskar Palinko\"},{\"authorId\":\"143807743\",\"name\":\"F. Rea\"},{\"authorId\":\"1678909\",\"name\":\"G. Sandini\"},{\"authorId\":\"1923910\",\"name\":\"A. Sciutti\"}],\"doi\":\"10.1109/IROS.2016.7759741\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"dc30f43a42c1aa7188dbb042d46f1eb785a8f817\",\"title\":\"Robot reading human gaze: Why eye tracking is better than head tracking for human-robot collaboration\",\"url\":\"https://www.semanticscholar.org/paper/dc30f43a42c1aa7188dbb042d46f1eb785a8f817\",\"venue\":\"2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1643915120\",\"name\":\"AdmoniHenny\"},{\"authorId\":\"1643915322\",\"name\":\"ScassellatiBrian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7b73ab5a6322787bbbe2ee2b5a7f2438bd5e5fd4\",\"title\":\"Social eye gaze in human-robot interaction\",\"url\":\"https://www.semanticscholar.org/paper/7b73ab5a6322787bbbe2ee2b5a7f2438bd5e5fd4\",\"venue\":\"HRI 2017\",\"year\":2017},{\"arxivId\":\"1809.08095\",\"authors\":[{\"authorId\":\"2216790\",\"name\":\"A. Shafti\"},{\"authorId\":\"144321866\",\"name\":\"P. Orlov\"},{\"authorId\":\"144683767\",\"name\":\"A. Faisal\"}],\"doi\":\"10.1109/ICRA.2019.8793804\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8c28de4803bcf4387b78ab166ac908e9d2d9ee67\",\"title\":\"Gaze-based, Context-aware Robotic System for Assisted Reaching and Grasping\",\"url\":\"https://www.semanticscholar.org/paper/8c28de4803bcf4387b78ab166ac908e9d2d9ee67\",\"venue\":\"2019 International Conference on Robotics and Automation (ICRA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Zoya Bylinskii\"},{\"authorId\":null,\"name\":\"Tilke Judd\"},{\"authorId\":null,\"name\":\"Ali Borji\"},{\"authorId\":null,\"name\":\"Laurent Itti\"},{\"authorId\":null,\"name\":\"Fr\\u00e9do Durand\"},{\"authorId\":null,\"name\":\"Aude Oliva\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"and Antonio Torralba\",\"url\":\"\",\"venue\":\"Mit saliency benchmark,\",\"year\":2015},{\"arxivId\":\"1501.02741\",\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"49712326\",\"name\":\"M. Cheng\"},{\"authorId\":\"40175280\",\"name\":\"Huaizu Jiang\"},{\"authorId\":\"97483166\",\"name\":\"J. Li\"}],\"doi\":\"10.1109/TIP.2015.2487833\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a1260c42b86dcbe123ccc038857cd3b14e146032\",\"title\":\"Salient Object Detection: A Benchmark\",\"url\":\"https://www.semanticscholar.org/paper/a1260c42b86dcbe123ccc038857cd3b14e146032\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Adria Recasens\"},{\"authorId\":null,\"name\":\"Carl Vondrick\"},{\"authorId\":null,\"name\":\"Aditya Khosla\"},{\"authorId\":null,\"name\":\"Antonio Torralba. Following gaze in video\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In Proceedings of the IEEE International Conference on Computer Vision\",\"url\":\"\",\"venue\":\"pages 1435\\u20131443,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Erroll Wood\"},{\"authorId\":null,\"name\":\"Tadas Baltrusaitis\"},{\"authorId\":null,\"name\":\"Xucong Zhang\"},{\"authorId\":null,\"name\":\"Yusuke Sugano\"},{\"authorId\":null,\"name\":\"Peter Robinson\"},{\"authorId\":null,\"name\":\"Andreas Bulling. Rendering of eyes for eye-shape registration\"},{\"authorId\":null,\"name\":\"gaze estimation\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In Proceedings of the IEEE International Conference on Computer Vision\",\"url\":\"\",\"venue\":\"pages 3756\\u20133764,\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Brandon Amos\"},{\"authorId\":null,\"name\":\"Bartosz Ludwiczuk\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and Mahadev Satyanarayanan\",\"url\":\"\",\"venue\":\"Openface: A general-purpose face recognition library with mobile applications.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5886094\",\"name\":\"P. Cochat\"},{\"authorId\":\"13267685\",\"name\":\"L. Vaucoret\"},{\"authorId\":\"31455512\",\"name\":\"J. Sarles\"}],\"doi\":\"10.1016/j.arcped.2012.01.013\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10d85561e4aafc516d10064f30dff05b41f70afe\",\"title\":\"[Et al].\",\"url\":\"https://www.semanticscholar.org/paper/10d85561e4aafc516d10064f30dff05b41f70afe\",\"venue\":\"Archives de pediatrie : organe officiel de la Societe francaise de pediatrie\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144645142\",\"name\":\"M. Jiang\"},{\"authorId\":\"1961257\",\"name\":\"Shengsheng Huang\"},{\"authorId\":\"2104164\",\"name\":\"Juanyong Duan\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1109/CVPR.2015.7298710\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c71db5d3546e22227662ee0f0ce586495ef18899\",\"title\":\"SALICON: Saliency in Context\",\"url\":\"https://www.semanticscholar.org/paper/c71db5d3546e22227662ee0f0ce586495ef18899\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144754234\",\"name\":\"N. Emery\"}],\"doi\":\"10.1016/S0149-7634(00)00025-7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6f770bc5788f53f92db99b564209587fb2a7b60b\",\"title\":\"The eyes have it: the neuroethology, function and evolution of social gaze\",\"url\":\"https://www.semanticscholar.org/paper/6f770bc5788f53f92db99b564209587fb2a7b60b\",\"venue\":\"Neuroscience & Biobehavioral Reviews\",\"year\":2000},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Dim P Papadopoulos\"},{\"authorId\":null,\"name\":\"Alasdair DF Clarke\"},{\"authorId\":null,\"name\":\"Frank Keller\"},{\"authorId\":null,\"name\":\"Vittorio Ferrari. Training object class detectors from eye  vision\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"pages 361\\u2013376\",\"url\":\"\",\"venue\":\"Springer,\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38592832\",\"name\":\"Kerstin Ruhland\"},{\"authorId\":\"144687810\",\"name\":\"C. Peters\"},{\"authorId\":\"2211183\",\"name\":\"Sean Andrist\"},{\"authorId\":\"1697165\",\"name\":\"J. Badler\"},{\"authorId\":\"1699200\",\"name\":\"N. Badler\"},{\"authorId\":\"1776507\",\"name\":\"M. Gleicher\"},{\"authorId\":\"145656551\",\"name\":\"B. Mutlu\"},{\"authorId\":\"145795454\",\"name\":\"R. McDonnell\"}],\"doi\":\"10.1111/cgf.12603\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f1ef8b6b5fc64a0387be4514c45a15a7f02bb306\",\"title\":\"A Review of Eye Gaze in Virtual Agents, Social Robotics and HCI: Behaviour Generation, User Interaction and Perception\",\"url\":\"https://www.semanticscholar.org/paper/f1ef8b6b5fc64a0387be4514c45a15a7f02bb306\",\"venue\":\"Comput. Graph. Forum\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38637273\",\"name\":\"Hsiu-Chin Lin\"},{\"authorId\":\"20930108\",\"name\":\"P. Ray\"},{\"authorId\":\"39600588\",\"name\":\"M. Howard\"}],\"doi\":\"10.1109/icra33291.2017\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e0aba478ab135e3b72b38dc9dd3e4608b213ba53\",\"title\":\"The 2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"url\":\"https://www.semanticscholar.org/paper/e0aba478ab135e3b72b38dc9dd3e4608b213ba53\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1709.06308\",\"authors\":[{\"authorId\":\"6002624\",\"name\":\"Tingting Qiao\"},{\"authorId\":\"40240283\",\"name\":\"J. Dong\"},{\"authorId\":\"7471918\",\"name\":\"Duanqing Xu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3fafe70edc7067015ca2d49aef2773c22a71647d\",\"title\":\"Exploring Human-like Attention Supervision in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/3fafe70edc7067015ca2d49aef2773c22a71647d\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ashish Shrivastava\"},{\"authorId\":null,\"name\":\"Tomas Pfister\"},{\"authorId\":null,\"name\":\"Oncel Tuzel\"},{\"authorId\":null,\"name\":\"Joshua Susskind\"},{\"authorId\":null,\"name\":\"Wenda Wang\"},{\"authorId\":null,\"name\":\"Russell Webb. Learning from simulated\"},{\"authorId\":null,\"name\":\"unsupervised images through adversarial training\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In Proceedings of the IEEE conference on computer vision and pattern recognition\",\"url\":\"\",\"venue\":\"pages 2107\\u20132116,\",\"year\":2017},{\"arxivId\":\"1806.03960\",\"authors\":[{\"authorId\":\"2657185\",\"name\":\"Ruohan Zhang\"},{\"authorId\":\"2619658\",\"name\":\"Zhuode Liu\"},{\"authorId\":\"13800723\",\"name\":\"L. Zhang\"},{\"authorId\":\"51002225\",\"name\":\"Jake A. Whritner\"},{\"authorId\":\"47136793\",\"name\":\"K. Muller\"},{\"authorId\":\"2848854\",\"name\":\"M. Hayhoe\"},{\"authorId\":\"1691804\",\"name\":\"D. Ballard\"}],\"doi\":\"10.1007/978-3-030-01252-6_41\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"170643ea1794c4285a491bcea7dede2d35806726\",\"title\":\"AGIL: Learning Attention from Human for Visuomotor Tasks\",\"url\":\"https://www.semanticscholar.org/paper/170643ea1794c4285a491bcea7dede2d35806726\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"},{\"authorId\":\"39257069\",\"name\":\"A. Recasens\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"}],\"doi\":\"10.1007/978-3-319-46454-1_49\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a6d6d0de32939a5d15d2abfb04d131884d2cadc4\",\"title\":\"Where Should Saliency Models Look Next?\",\"url\":\"https://www.semanticscholar.org/paper/a6d6d0de32939a5d15d2abfb04d131884d2cadc4\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1406.6247\",\"authors\":[{\"authorId\":\"3255983\",\"name\":\"V. Mnih\"},{\"authorId\":\"2801204\",\"name\":\"N. Heess\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a756d4d25511d92a45d0f4545fa819de993851d\",\"title\":\"Recurrent Models of Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/8a756d4d25511d92a45d0f4545fa819de993851d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Stephen Hutt\"},{\"authorId\":null,\"name\":\"Caitlin Mills\"},{\"authorId\":null,\"name\":\"Shelby White\"},{\"authorId\":null,\"name\":\"Patrick J Donnelly\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and Sidney K D\\u2019Mello\",\"url\":\"\",\"venue\":\"The eyes have it: Gaze-based detection of mind wandering during learning with an intelligent tutoring system. International Educational Data Mining Society,\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Juan Xu\"},{\"authorId\":null,\"name\":\"Ming Jiang\"},{\"authorId\":null,\"name\":\"Shuo Wang\"},{\"authorId\":null,\"name\":\"Mohan S Kankanhalli\"},{\"authorId\":null,\"name\":\"Qi Zhao. Predicting human gaze beyond pixels\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Journal of vision\",\"url\":\"\",\"venue\":\"14(1):28\\u201328,\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1727849\",\"name\":\"S. Hanson\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"69d7086300e7f5322c06f2f242a565b3a182efb5\",\"title\":\"In Advances in Neural Information Processing Systems\",\"url\":\"https://www.semanticscholar.org/paper/69d7086300e7f5322c06f2f242a565b3a182efb5\",\"venue\":\"NIPS 1990\",\"year\":1990},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145627293\",\"name\":\"W. Cowan\"},{\"authorId\":\"6754005\",\"name\":\"E. Shooter\"},{\"authorId\":\"3352268\",\"name\":\"S. E. Hyman\"},{\"authorId\":\"13024153\",\"name\":\"C. Stevens\"},{\"authorId\":\"144741628\",\"name\":\"H. Zoghbi\"}],\"doi\":\"10.1146/neuro.662\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b118f83709e78c499ecc8c44991dbb3d8964c283\",\"title\":\"Annual Review of Neuroscience\",\"url\":\"https://www.semanticscholar.org/paper/b118f83709e78c499ecc8c44991dbb3d8964c283\",\"venue\":\"\",\"year\":1995},{\"arxivId\":\"1604.03605\",\"authors\":[{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"},{\"authorId\":\"152627906\",\"name\":\"T. Judd\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"}],\"doi\":\"10.1109/TPAMI.2018.2815601\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"bfdf3431ff5182b585b3b0c11fa8cbfc13a6bde4\",\"title\":\"What Do Different Evaluation Metrics Tell Us About Saliency Models?\",\"url\":\"https://www.semanticscholar.org/paper/bfdf3431ff5182b585b3b0c11fa8cbfc13a6bde4\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1167/14.3.29\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"639722c2c23e8c8033b715d039e1f14d79cb970e\",\"title\":\"Defending Yarbus: eye movements reveal observers' task.\",\"url\":\"https://www.semanticscholar.org/paper/639722c2c23e8c8033b715d039e1f14d79cb970e\",\"venue\":\"Journal of vision\",\"year\":2014},{\"arxivId\":\"1907.07202\",\"authors\":[{\"authorId\":\"10978611\",\"name\":\"Akanksha Saran\"},{\"authorId\":\"32775309\",\"name\":\"Elaine Schaertl Short\"},{\"authorId\":\"1682788\",\"name\":\"A. Thomaz\"},{\"authorId\":\"2791038\",\"name\":\"S. Niekum\"}],\"doi\":null,\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"a20a0db43974adcad7db815bc91db3de540b8042\",\"title\":\"Understanding Teacher Gaze Patterns for Robot Learning\",\"url\":\"https://www.semanticscholar.org/paper/a20a0db43974adcad7db815bc91db3de540b8042\",\"venue\":\"CoRL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Sean Andrist\"},{\"authorId\":null,\"name\":\"Xiang Zhi Tan\"},{\"authorId\":null,\"name\":\"Michael Gleicher\"},{\"authorId\":null,\"name\":\"Bilge Mutlu. Conversational gaze aversion for humanlike robots\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In 2014 9th ACM/IEEE International Conference on Human-Robot Interaction (HRI)\",\"url\":\"\",\"venue\":\"pages 25\\u201332. IEEE,\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144136729\",\"name\":\"Chen Yu\"},{\"authorId\":\"2836466\",\"name\":\"L. Smith\"}],\"doi\":\"10.1111/J.1467-7687.2010.00958.X\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"36321bcfe620f4ff84cd2e09e01ae3047634d36c\",\"title\":\"What you learn is what you see: using eye movements to study infant cross-situational word learning.\",\"url\":\"https://www.semanticscholar.org/paper/36321bcfe620f4ff84cd2e09e01ae3047634d36c\",\"venue\":\"Developmental science\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Hamed R Tavakoli\"},{\"authorId\":null,\"name\":\"Rakshith Shetty\"},{\"authorId\":null,\"name\":\"Ali Borji\"},{\"authorId\":null,\"name\":\"Jorma Laaksonen. Paying attention to descriptions genera models\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In Proceedings of the IEEE International Conference on Computer Vision\",\"url\":\"\",\"venue\":\"pages 2487\\u2013 2496,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Akanksha Saran\"},{\"authorId\":null,\"name\":\"Srinjoy Majumdar\"},{\"authorId\":null,\"name\":\"Elaine Schaertl Short\"},{\"authorId\":null,\"name\":\"Andrea Thomaz\"},{\"authorId\":null,\"name\":\"Scott Niekum. Human gaze following for human-robot interaction\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"url\":\"\",\"venue\":\"pages 8615\\u20138621. IEEE,\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Mingxin Yu\"},{\"authorId\":null,\"name\":\"Yingzi Lin\"},{\"authorId\":null,\"name\":\"David Schmidt\"},{\"authorId\":null,\"name\":\"Xiangzhou Wang\"},{\"authorId\":null,\"name\":\"Yu Wang. Human-robot interaction based on gaze gestur teleoperation\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Journal of Eye Movement Research\",\"url\":\"\",\"venue\":\"7(4):1\\u201314,\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Hamed Rezazadegan Tavakoli\"},{\"authorId\":null,\"name\":\"Esa Rahtu\"},{\"authorId\":null,\"name\":\"Juho Kannala\"},{\"authorId\":null,\"name\":\"Ali Borji. Digging deeper into egocentric gaze prediction\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In 2019 IEEE Winter Conference on Applications of Computer Vision\",\"url\":\"\",\"venue\":\"pages 273\\u2013282. IEEE,\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47294217\",\"name\":\"Ziheng Zhang\"},{\"authorId\":\"7869872\",\"name\":\"Y. Xu\"},{\"authorId\":\"2152356\",\"name\":\"J. Yu\"},{\"authorId\":\"1702868\",\"name\":\"Shenghua Gao\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"219bac0d46072291b129748809973618646935e6\",\"title\":\"Saliency Detection in 360\\u00b0 Videos\",\"url\":\"https://www.semanticscholar.org/paper/219bac0d46072291b129748809973618646935e6\",\"venue\":\"ECCV 2018\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35145855\",\"name\":\"S. Fiore\"},{\"authorId\":\"2375973\",\"name\":\"Travis J. Wiltshire\"},{\"authorId\":\"20228152\",\"name\":\"Emilio J. C. Lobato\"},{\"authorId\":\"2191674\",\"name\":\"F. Jentsch\"},{\"authorId\":\"1807280\",\"name\":\"W. Huang\"},{\"authorId\":\"40186019\",\"name\":\"B. Axelrod\"}],\"doi\":\"10.3389/fpsyg.2013.00859\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"18ecefabdacc27f51f1f32440bec84440fc6dbfd\",\"title\":\"Toward understanding social cues and signals in human\\u2013robot interaction: effects of robot gaze and proxemic behavior\",\"url\":\"https://www.semanticscholar.org/paper/18ecefabdacc27f51f1f32440bec84440fc6dbfd\",\"venue\":\"Front. Psychol.\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3380943\",\"name\":\"Mingxin Yu\"},{\"authorId\":\"3253652\",\"name\":\"Y. Lin\"},{\"authorId\":\"69910698\",\"name\":\"D. Schmidt\"},{\"authorId\":\"2257379\",\"name\":\"Xiangzhou Wang\"},{\"authorId\":\"40457242\",\"name\":\"Yu Wang\"}],\"doi\":\"10.16910/JEMR.7.4.4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"269b5aec84d0e8722630dfc81e9bdbd8c8bc6da5\",\"title\":\"Human-Robot Interaction Based on Gaze Gestures for the Drone Teleoperation\",\"url\":\"https://www.semanticscholar.org/paper/269b5aec84d0e8722630dfc81e9bdbd8c8bc6da5\",\"venue\":\"\",\"year\":2014},{\"arxivId\":\"1903.06754\",\"authors\":[{\"authorId\":\"2657185\",\"name\":\"Ruohan Zhang\"},{\"authorId\":\"2619658\",\"name\":\"Zhuode Liu\"},{\"authorId\":\"144190085\",\"name\":\"L. Guan\"},{\"authorId\":\"13800723\",\"name\":\"L. Zhang\"},{\"authorId\":\"2848854\",\"name\":\"M. Hayhoe\"},{\"authorId\":\"1691804\",\"name\":\"D. Ballard\"}],\"doi\":\"10.1609/AAAI.V34I04.6161\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d9dea72f5a7ca7a6e928eb4dca3962c24df6ca50\",\"title\":\"Atari-HEAD: Atari Human Eye-Tracking and Demonstration Dataset\",\"url\":\"https://www.semanticscholar.org/paper/d9dea72f5a7ca7a6e928eb4dca3962c24df6ca50\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37074673\",\"name\":\"AJung Moon\"},{\"authorId\":\"2410348\",\"name\":\"Daniel Troniak\"},{\"authorId\":\"2804335\",\"name\":\"B. Gleeson\"},{\"authorId\":\"2570505\",\"name\":\"Matthew K. X. J. Pan\"},{\"authorId\":\"145537624\",\"name\":\"Minhua Zheng\"},{\"authorId\":\"3024094\",\"name\":\"Benjamin A. Blumer\"},{\"authorId\":\"1796517\",\"name\":\"K. MacLean\"},{\"authorId\":\"1735428\",\"name\":\"E. Croft\"}],\"doi\":\"10.1145/2559636.2559656\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"402172c310409f4bd5dcfebbd198b5ce4ec1c25e\",\"title\":\"Meet Me where I\\u2019m Gazing: How Shared Attention Gaze Affects Human-Robot Handover Timing\",\"url\":\"https://www.semanticscholar.org/paper/402172c310409f4bd5dcfebbd198b5ce4ec1c25e\",\"venue\":\"2014 9th ACM/IEEE International Conference on Human-Robot Interaction (HRI)\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Natasha Jaques\"},{\"authorId\":null,\"name\":\"Cristina Conati\"},{\"authorId\":null,\"name\":\"Jason M Harley\"},{\"authorId\":null,\"name\":\"Roger Azevedo. Predicting affect from gaze data during i Systems\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"pages 29\\u201338\",\"url\":\"\",\"venue\":\"Springer,\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Harish Chaandar Ravichandar\"},{\"authorId\":null,\"name\":\"Avnish Kumar\"},{\"authorId\":null,\"name\":\"Ashwin Dani. Gaze\"},{\"authorId\":null,\"name\":\"motion information fusion for human intention inference\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"International Journal of Intelligent Robotics and Applications\",\"url\":\"\",\"venue\":\"2(2):136\\u2013148,\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40760781\",\"name\":\"Zheming Zuo\"},{\"authorId\":\"1706028\",\"name\":\"L. Yang\"},{\"authorId\":\"2648838\",\"name\":\"Y. Peng\"},{\"authorId\":\"2864709\",\"name\":\"F. Chao\"},{\"authorId\":\"31851271\",\"name\":\"YanPeng Qu\"}],\"doi\":\"10.1109/ACCESS.2018.2808486\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d6aa1b967b69897695b77a66dd36b5833581db49\",\"title\":\"Gaze-Informed Egocentric Action Recognition for Memory Aid Systems\",\"url\":\"https://www.semanticscholar.org/paper/d6aa1b967b69897695b77a66dd36b5833581db49\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":\"1610.01563\",\"authors\":[{\"authorId\":\"2997408\",\"name\":\"Matthias K\\u00fcmmerer\"},{\"authorId\":\"49737748\",\"name\":\"Thomas S. A. Wallis\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d160d375a7c187dfe10c110e9e733f36accb87e6\",\"title\":\"DeepGaze II: Reading fixations from deep features trained on object recognition\",\"url\":\"https://www.semanticscholar.org/paper/d160d375a7c187dfe10c110e9e733f36accb87e6\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1801.07424\",\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"143929120\",\"name\":\"F. Guo\"},{\"authorId\":\"37535930\",\"name\":\"Ming-Ming Cheng\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":\"10.1109/CVPR.2018.00514\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fdf8c9c4c30c6005c2f0e92ce9db3de5ab8b5d29\",\"title\":\"Revisiting Video Saliency: A Large-Scale Benchmark and a New Model\",\"url\":\"https://www.semanticscholar.org/paper/fdf8c9c4c30c6005c2f0e92ce9db3de5ab8b5d29\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Youngjae Yu\"},{\"authorId\":null,\"name\":\"Jongwook Choi\"},{\"authorId\":null,\"name\":\"Yeonhwa Kim\"},{\"authorId\":null,\"name\":\"Kyung Yoo\"},{\"authorId\":null,\"name\":\"Sang-Hun Lee\"},{\"authorId\":null,\"name\":\"Gunhee Kim. Supervising neural attention models for video data\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition\",\"url\":\"\",\"venue\":\"pages 490\\u2013498,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yin Li\"},{\"authorId\":null,\"name\":\"Xiaodi Hou\"},{\"authorId\":null,\"name\":\"Christof Koch\"},{\"authorId\":null,\"name\":\"James M Rehg\"},{\"authorId\":null,\"name\":\"Alan L Yuille. The secrets of salient object segmentation\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition\",\"url\":\"\",\"venue\":\"pages 280\\u2013287,\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Preethi Vaidyanathan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Emily Prud\\u2019hommeaux\",\"url\":\"\",\"venue\":\"Jeff B Pelz, and Cecilia Ovesdotter Alm. Snag: Spoken narratives and gaze dataset. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, pages 132\\u2013137,\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"46331912\",\"name\":\"M. Liu\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1007/978-3-030-01228-1_38\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fa1723b216b1f41b085b62b450b7b0bd9f2fd281\",\"title\":\"In the Eye of Beholder: Joint Learning of Gaze and Actions in First Person Video\",\"url\":\"https://www.semanticscholar.org/paper/fa1723b216b1f41b085b62b450b7b0bd9f2fd281\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33230676\",\"name\":\"Kiwon Yun\"},{\"authorId\":null,\"name\":\"Yifan Peng\"},{\"authorId\":\"145654220\",\"name\":\"D. Samaras\"},{\"authorId\":\"1696991\",\"name\":\"G. Zelinsky\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/CVPR.2013.101\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ad2c0ae801c9e8adece483e74725e12a8544d440\",\"title\":\"Studying Relationships between Human Gaze, Description, and Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/ad2c0ae801c9e8adece483e74725e12a8544d440\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"20492211\",\"name\":\"Viktor Richter\"},{\"authorId\":\"2528049\",\"name\":\"Birte Carlmeyer\"},{\"authorId\":\"3107682\",\"name\":\"Florian Lier\"},{\"authorId\":\"3449340\",\"name\":\"Sebastian Meyer zu Borgsen\"},{\"authorId\":\"1817455\",\"name\":\"David Schlangen\"},{\"authorId\":\"1696799\",\"name\":\"F. Kummert\"},{\"authorId\":\"1724954\",\"name\":\"S. Wachsmuth\"},{\"authorId\":\"1764476\",\"name\":\"B. Wrede\"}],\"doi\":\"10.1145/2974804.2974823\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"434d8f6868ed404d2ebbdcee4926fd6ce1d2fd73\",\"title\":\"Are you talking to me?: Improving the Robustness of Dialogue Systems in a Multi Party HRI Scenario by Incorporating Gaze Direction and Lip Movement of Attendees\",\"url\":\"https://www.semanticscholar.org/paper/434d8f6868ed404d2ebbdcee4926fd6ce1d2fd73\",\"venue\":\"HAI\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145003889\",\"name\":\"R. Fang\"},{\"authorId\":\"21455137\",\"name\":\"Malcolm Doering\"},{\"authorId\":\"1707259\",\"name\":\"J. Y. Chai\"}],\"doi\":\"10.1145/2696454.2696467\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2429e6686ebc2776643bbe92fc9faf29eb8c0ad7\",\"title\":\"Embodied Collaborative Referring Expression Generation in Situated Human-Robot Interaction\",\"url\":\"https://www.semanticscholar.org/paper/2429e6686ebc2776643bbe92fc9faf29eb8c0ad7\",\"venue\":\"2015 10th ACM/IEEE International Conference on Human-Robot Interaction (HRI)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2653652\",\"name\":\"D. Mareschal\"},{\"authorId\":\"145546235\",\"name\":\"M. Johnson\"},{\"authorId\":\"34902749\",\"name\":\"P. Quinn\"}],\"doi\":\"10.1111/j.1467-7687.2011.01063.x\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2fe40cf5705a27c5ca8edfa2aefdf083279b5477\",\"title\":\"Developmental Science.\",\"url\":\"https://www.semanticscholar.org/paper/2fe40cf5705a27c5ca8edfa2aefdf083279b5477\",\"venue\":\"Developmental science\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145295896\",\"name\":\"Y. Shen\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"46948132\",\"name\":\"Zefan Li\"},{\"authorId\":\"2492392\",\"name\":\"N. Zhuang\"}],\"doi\":\"10.1007/978-3-030-01216-8_13\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4bc32b8c34b7d5b08496b9600b15596aa0a0aac1\",\"title\":\"Egocentric Activity Prediction via Event Modulated Attention\",\"url\":\"https://www.semanticscholar.org/paper/4bc32b8c34b7d5b08496b9600b15596aa0a0aac1\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1911.02320\",\"authors\":[{\"authorId\":\"2064588\",\"name\":\"Sandy H. Huang\"},{\"authorId\":\"41206062\",\"name\":\"Isabella Huang\"},{\"authorId\":\"8118986\",\"name\":\"Ravi Pandya\"},{\"authorId\":\"2745001\",\"name\":\"Anca D. Dragan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"0e934d1a31bd2af2df867c684905aaf02fb109a1\",\"title\":\"Nonverbal Robot Feedback for Human Teachers\",\"url\":\"https://www.semanticscholar.org/paper/0e934d1a31bd2af2df867c684905aaf02fb109a1\",\"venue\":\"CoRL\",\"year\":2019},{\"arxivId\":\"1611.09571\",\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/TIP.2018.2851672\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b7e336a7d3cd82ae8cd5e85d3cb62f0b6091a0e5\",\"title\":\"Predicting Human Eye Fixations via an LSTM-Based Saliency Attentive Model\",\"url\":\"https://www.semanticscholar.org/paper/b7e336a7d3cd82ae8cd5e85d3cb62f0b6091a0e5\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2138933\",\"name\":\"H. Ravichandar\"},{\"authorId\":\"50333339\",\"name\":\"A. Kumar\"},{\"authorId\":\"1729843\",\"name\":\"Ashwin P. Dani\"}],\"doi\":\"10.1007/s41315-018-0051-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"39f45615474a44a254743d43b5ff82c47a2187ef\",\"title\":\"Gaze and motion information fusion for human intention inference\",\"url\":\"https://www.semanticscholar.org/paper/39f45615474a44a254743d43b5ff82c47a2187ef\",\"venue\":\"International Journal of Intelligent Robotics and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Arun Balajee Vasudevan\"},{\"authorId\":null,\"name\":\"Dengxin Dai\"},{\"authorId\":null,\"name\":\"Luc Van Gool. Object referring in videos with language\"},{\"authorId\":null,\"name\":\"human gaze\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition\",\"url\":\"\",\"venue\":\"pages 4129\\u20134138,\",\"year\":2018},{\"arxivId\":\"1711.06406\",\"authors\":[{\"authorId\":\"27678837\",\"name\":\"Y. Xia\"},{\"authorId\":\"46334890\",\"name\":\"Danqing Zhang\"},{\"authorId\":\"2569534\",\"name\":\"J. Kim\"},{\"authorId\":\"50605758\",\"name\":\"K. Nakayama\"},{\"authorId\":\"2769532\",\"name\":\"K. Zipser\"},{\"authorId\":\"143659729\",\"name\":\"D. Whitney\"}],\"doi\":\"10.1007/978-3-030-20873-8_42\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"43385e3cb891f34a0bf3b4fb0afde1fd21cf28e9\",\"title\":\"Predicting Driver Attention in Critical Situations\",\"url\":\"https://www.semanticscholar.org/paper/43385e3cb891f34a0bf3b4fb0afde1fd21cf28e9\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"1811.10698\",\"authors\":[{\"authorId\":\"1756362\",\"name\":\"Swathikiran Sudhakaran\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"}],\"doi\":\"10.1109/CVPR.2019.01019\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ed78a2671ef61c031759c01434678c282f23faec\",\"title\":\"LSTA: Long Short-Term Attention for Egocentric Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ed78a2671ef61c031759c01434678c282f23faec\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Margrit Betke. Intelligent interfaces to empower people wi Intelligence\"},{\"authorId\":null,\"name\":\"Smart Environments\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"pages 409\\u2013432\",\"url\":\"\",\"venue\":\"Springer,\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Charles Rich\"},{\"authorId\":null,\"name\":\"Brett Ponsler\"},{\"authorId\":null,\"name\":\"Aaron Holroyd\"},{\"authorId\":null,\"name\":\"Candace L Sidner. Recognizing engagement in human-robot interaction\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In 2010 5th ACM/IEEE International Conference on Human-Robot Interaction (HRI)\",\"url\":\"\",\"venue\":\"pages 375\\u2013382. IEEE,\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1945596530\",\"name\":\"G. Herrera\"}],\"doi\":\"10.1111/j.1528-1157.1949.tb04372.x\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"48af4433abccde13a72153f221901e29167f13fa\",\"title\":\"DESCRIPTION\",\"url\":\"https://www.semanticscholar.org/paper/48af4433abccde13a72153f221901e29167f13fa\",\"venue\":\"\",\"year\":1949},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Marcella Cornia\"},{\"authorId\":null,\"name\":\"Lorenzo Baraldi\"},{\"authorId\":null,\"name\":\"Giuseppe Serra\"},{\"authorId\":null,\"name\":\"Rita Cucchiara. Predicting human eye fixations via an l model\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"IEEE Transactions on Image Processing\",\"url\":\"\",\"venue\":\"27(10):5142\\u20135154,\",\"year\":2018},{\"arxivId\":\"1804.01793\",\"authors\":[{\"authorId\":\"35129473\",\"name\":\"Saumya Jetley\"},{\"authorId\":\"26734366\",\"name\":\"N. Murray\"},{\"authorId\":\"2286630\",\"name\":\"E. Vig\"}],\"doi\":\"10.1109/CVPR.2016.620\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a4d42c041bf30021550e581775c1e04f253edf54\",\"title\":\"End-to-End Saliency Mapping via Probability Distribution Prediction\",\"url\":\"https://www.semanticscholar.org/paper/a4d42c041bf30021550e581775c1e04f253edf54\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2211183\",\"name\":\"Sean Andrist\"},{\"authorId\":\"1776507\",\"name\":\"M. Gleicher\"},{\"authorId\":\"145656551\",\"name\":\"B. Mutlu\"}],\"doi\":\"10.1145/3025453.3026033\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"be9a4798022f2785ba914bd3ed2227618cc761a4\",\"title\":\"Looking Coordinated: Bidirectional Gaze Mechanisms for Collaborative Interaction with Virtual Characters\",\"url\":\"https://www.semanticscholar.org/paper/be9a4798022f2785ba914bd3ed2227618cc761a4\",\"venue\":\"CHI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47287647\",\"name\":\"Sen He\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"3251678\",\"name\":\"N. Pugeault\"}],\"doi\":\"10.1109/ICCV.2019.00862\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e4a91b8c1259e7744784d922f250dd77ea951e9f\",\"title\":\"Human Attention in Image Captioning: Dataset and Analysis\",\"url\":\"https://www.semanticscholar.org/paper/e4a91b8c1259e7744784d922f250dd77ea951e9f\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Saumya Jetley\"},{\"authorId\":null,\"name\":\"Naila Murray\"},{\"authorId\":null,\"name\":\"Eleonora Vig. End-to-end saliency mapping via probability d prediction\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition\",\"url\":\"\",\"venue\":\"pages 5753\\u20135761,\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Kyle Krafka\"},{\"authorId\":null,\"name\":\"Aditya Khosla\"},{\"authorId\":null,\"name\":\"Petr Kellnhofer\"},{\"authorId\":null,\"name\":\"Harini Kannan\"},{\"authorId\":null,\"name\":\"Suchendra Bhandarkar\"},{\"authorId\":null,\"name\":\"Wojciech Matusik\"},{\"authorId\":null,\"name\":\"Antonio Torralba. Eye tracking for everyone\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In Proceedings of the IEEE conference on computer vision and pattern recognition\",\"url\":\"\",\"venue\":\"pages 2176\\u20132184,\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Xucong Zhang\"},{\"authorId\":null,\"name\":\"Yusuke Sugano\"},{\"authorId\":null,\"name\":\"Mario Fritz\"},{\"authorId\":null,\"name\":\"Andreas Bulling. Appearance-based gaze estimation in the wild\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In Proceedings of the IEEE conference on computer vision and pattern recognition\",\"url\":\"\",\"venue\":\"pages 4511\\u20134520,\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47139824\",\"name\":\"A. Fitzgibbon\"},{\"authorId\":\"1742208\",\"name\":\"M. Pollefeys\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"19d6e925ed9643c28981edd233d074b6e3a793c6\",\"title\":\"European conference on computer vision (ECCV)\",\"url\":\"https://www.semanticscholar.org/paper/19d6e925ed9643c28981edd233d074b6e3a793c6\",\"venue\":\"eccv 2006\",\"year\":2006},{\"arxivId\":null,\"authors\":[],\"doi\":\"10.1038/191650a0\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3d676fb023b7f3c25d1fcf86e433dc7eabe27a05\",\"title\":\"Vision Research\",\"url\":\"https://www.semanticscholar.org/paper/3d676fb023b7f3c25d1fcf86e433dc7eabe27a05\",\"venue\":\"Nature\",\"year\":1961},{\"arxivId\":\"1510.02927\",\"authors\":[{\"authorId\":\"1784761\",\"name\":\"S. Kruthiventi\"},{\"authorId\":\"50430041\",\"name\":\"Kumar Ayush\"},{\"authorId\":\"144682140\",\"name\":\"R. Venkatesh Babu\"}],\"doi\":\"10.1109/TIP.2017.2710620\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1295cbaf3b03de2eb8c79530289f5939d7819e5c\",\"title\":\"DeepFix: A Fully Convolutional Neural Network for Predicting Human Eye Fixations\",\"url\":\"https://www.semanticscholar.org/paper/1295cbaf3b03de2eb8c79530289f5939d7819e5c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7326223\",\"name\":\"L. Itti\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"},{\"authorId\":\"3271571\",\"name\":\"E. Niebur\"}],\"doi\":\"10.1109/34.730558\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4816f0b6f0d05da3901441bfa5cc7be044b4da8b\",\"title\":\"A Model of Saliency-Based Visual Attention for Rapid Scene Analysis\",\"url\":\"https://www.semanticscholar.org/paper/4816f0b6f0d05da3901441bfa5cc7be044b4da8b\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2009},{\"arxivId\":\"1505.05916\",\"authors\":[{\"authorId\":\"34399452\",\"name\":\"E. Wood\"},{\"authorId\":\"1756344\",\"name\":\"T. Baltrusaitis\"},{\"authorId\":\"2520795\",\"name\":\"Xucong Zhang\"},{\"authorId\":\"1751242\",\"name\":\"Yusuke Sugano\"},{\"authorId\":\"144681495\",\"name\":\"P. Robinson\"},{\"authorId\":\"3194727\",\"name\":\"Andreas Bulling\"}],\"doi\":\"10.1109/ICCV.2015.428\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5e9f10adb1596259c7e83fce337575b11381e6c7\",\"title\":\"Rendering of Eyes for Eye-Shape Registration and Gaze Estimation\",\"url\":\"https://www.semanticscholar.org/paper/5e9f10adb1596259c7e83fce337575b11381e6c7\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015}],\"title\":\"Human Gaze Assisted Artificial Intelligence: A Review\",\"topics\":[{\"topic\":\"Artificial intelligence\",\"topicId\":\"8286\",\"url\":\"https://www.semanticscholar.org/topic/8286\"}],\"url\":\"https://www.semanticscholar.org/paper/97a06ab02b44a696619c21de32d6ec0dcfc876eb\",\"venue\":\"IJCAI\",\"year\":2020}\n"