"{\"abstract\":\"Image captioning aims to describe an image with a concise, accurate, and interesting sentence. To build such an automatic neural captioner, the traditional models align the generated words with a number of human-annotated sentences to mimic human-like captions. However, the crowd-sourced annotations inevitably come with data quality issues such as grammatical errors, wrong identification of visual objects and sub-optimal sentence focuses. During the model training, existing methods treat all the annotations equally regardless of the data quality. In this work, we explicitly engage human consensus to measure the quality of ground truth captions in advance, and directly encourage the model to learn high quality captions with high priority. Therefore, the proposed consensus-oriented method can accelerate the training process and achieve superior performance with only supervised objective without timeconsuming reinforcement learning. The novel consensus loss can be implemented into most of the existing state-of-the-art methods, boosting the BLEU4 performance by maximum relative 12.47% comparing to the conventional cross-entropy loss. Extensive experiments are conducted on MS-COCO Image Captioning dataset demonstrating the proposed human consensus-oriented training method can significantly improve the training efficiency and model effectiveness.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"48707795\",\"name\":\"Ziwei Wang\",\"url\":\"https://www.semanticscholar.org/author/48707795\"},{\"authorId\":\"145622169\",\"name\":\"Zi Huang\",\"url\":\"https://www.semanticscholar.org/author/145622169\"},{\"authorId\":\"150350159\",\"name\":\"Yadan Luo\",\"url\":\"https://www.semanticscholar.org/author/150350159\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":\"2001.01037\",\"authors\":[{\"authorId\":\"46969089\",\"name\":\"J. Sun\"},{\"authorId\":\"3633358\",\"name\":\"S. Lapuschkin\"},{\"authorId\":\"1699054\",\"name\":\"W. Samek\"},{\"authorId\":\"49345823\",\"name\":\"Alexander Binder\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"82e836be97e706dca7029ce6a0553b4890726593\",\"title\":\"Understanding Image Captioning Models beyond Visualizing Attention\",\"url\":\"https://www.semanticscholar.org/paper/82e836be97e706dca7029ce6a0553b4890726593\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.15829\",\"authors\":[{\"authorId\":\"150350159\",\"name\":\"Yadan Luo\"},{\"authorId\":\"145622169\",\"name\":\"Zi Huang\"},{\"authorId\":\"48708586\",\"name\":\"Zijian Wang\"},{\"authorId\":\"1852415\",\"name\":\"Zheng Zhang\"},{\"authorId\":\"51278862\",\"name\":\"Mahsa Baktashmotlagh\"}],\"doi\":\"10.1145/3394171.3413897\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c312bbdb66bd72643c57213cb167250cadb384a0\",\"title\":\"Adversarial Bipartite Graph Learning for Video Domain Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/c312bbdb66bd72643c57213cb167250cadb384a0\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48708586\",\"name\":\"Zijian Wang\"},{\"authorId\":\"150350159\",\"name\":\"Yadan Luo\"},{\"authorId\":\"144794678\",\"name\":\"Zi Huang\"},{\"authorId\":\"3019028\",\"name\":\"M. Baktash\"}],\"doi\":\"10.1145/3394171.3413662\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8c26ddd60862e5051cf3c4e38aa625d51575c2cb\",\"title\":\"Prototype-Matching Graph Network for Heterogeneous Domain Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/8c26ddd60862e5051cf3c4e38aa625d51575c2cb\",\"venue\":\"ACM Multimedia\",\"year\":2020}],\"corpusId\":220484074,\"doi\":\"10.24963/ijcai.2020/92\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":false,\"paperId\":\"506e7acfb05c851a7b3ccb256f4fed6d5a7dc15c\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yang Yang\"},{\"authorId\":null,\"name\":\"Jie Zhou\"},{\"authorId\":null,\"name\":\"Jiangbo Ai\"},{\"authorId\":null,\"name\":\"Yi Bin\"},{\"authorId\":null,\"name\":\"Alan Hanjalic\"},{\"authorId\":null,\"name\":\"H. T. Shen\"},{\"authorId\":null,\"name\":\"Yanli Ji. Video captioning by adversarial lstm\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"TIP\",\"url\":\"\",\"venue\":\"pages 5600\\u20135611,\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3141511\",\"name\":\"S. Banerjee\"},{\"authorId\":\"1784914\",\"name\":\"A. Lavie\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"0cd18e4400ff75b2f8b58d60ddb9b0bc12f489e7\",\"title\":\"METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments\",\"url\":\"https://www.semanticscholar.org/paper/0cd18e4400ff75b2f8b58d60ddb9b0bc12f489e7\",\"venue\":\"IEEvaluation@ACL\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jonathan Krause\"},{\"authorId\":null,\"name\":\"Justin Johnson\"},{\"authorId\":null,\"name\":\"Ranjay Krishna\"},{\"authorId\":null,\"name\":\"Li Fei-Fei. A hierarchical approach for generating de paragraphs\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In CVPR\",\"url\":\"\",\"venue\":\"pages 3337\\u20133345,\",\"year\":2017},{\"arxivId\":\"1607.06520\",\"authors\":[{\"authorId\":\"2843215\",\"name\":\"Tolga Bolukbasi\"},{\"authorId\":\"2782886\",\"name\":\"Kai-Wei Chang\"},{\"authorId\":\"145085302\",\"name\":\"James Y. Zou\"},{\"authorId\":\"1699322\",\"name\":\"Venkatesh Saligrama\"},{\"authorId\":\"2186481\",\"name\":\"A. Kalai\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ccf6a69a7f33bcf052aa7def176d3b9de495beb7\",\"title\":\"Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/ccf6a69a7f33bcf052aa7def176d3b9de495beb7\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1906.05963\",\"authors\":[{\"authorId\":\"80236158\",\"name\":\"Simao Herdade\"},{\"authorId\":\"40441990\",\"name\":\"Armin Kappeler\"},{\"authorId\":\"145908678\",\"name\":\"K. Boakye\"},{\"authorId\":\"145730823\",\"name\":\"J. Soares\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b499228aa74b59be32711c3926e44de208d6b636\",\"title\":\"Image Captioning: Transforming Objects into Words\",\"url\":\"https://www.semanticscholar.org/paper/b499228aa74b59be32711c3926e44de208d6b636\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40410858\",\"name\":\"R. J. Williams\"}],\"doi\":\"10.1007/BF00992696\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4c915c1eecb217c123a36dc6d3ce52d12c742614\",\"title\":\"Simple statistical gradient-following algorithms for connectionist reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/4c915c1eecb217c123a36dc6d3ce52d12c742614\",\"venue\":\"Machine Learning\",\"year\":2004},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1781574\",\"name\":\"Chin-Yew Lin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"60b05f32c32519a809f21642ef1eb3eaf3848008\",\"title\":\"ROUGE: A Package for Automatic Evaluation of Summaries\",\"url\":\"https://www.semanticscholar.org/paper/60b05f32c32519a809f21642ef1eb3eaf3848008\",\"venue\":\"ACL 2004\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144299726\",\"name\":\"Thomas G. Dietterich\"}],\"doi\":\"10.1145/242224.242229\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aab43c9c33af00b718cf2ae374b861d49862a563\",\"title\":\"Machine learning\",\"url\":\"https://www.semanticscholar.org/paper/aab43c9c33af00b718cf2ae374b861d49862a563\",\"venue\":\"CSUR\",\"year\":1996},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"96558862\",\"name\":\"Priyal Goyal\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"}],\"doi\":\"10.1109/TPAMI.2018.2858826\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"72564a69bf339ff1d16a639c86a764db2321caab\",\"title\":\"Focal Loss for Dense Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/72564a69bf339ff1d16a639c86a764db2321caab\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1906.02365\",\"authors\":[{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"48929163\",\"name\":\"Daqing Liu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"},{\"authorId\":\"144864336\",\"name\":\"F. Wu\"}],\"doi\":\"10.1109/TPAMI.2019.2909864\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d0134f63879cedf3cdfe795bd2fd7c48d9554e4a\",\"title\":\"Context-Aware Visual Policy Network for Fine-Grained Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/d0134f63879cedf3cdfe795bd2fd7c48d9554e4a\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2019},{\"arxivId\":\"1807.00517\",\"authors\":[{\"authorId\":\"40895688\",\"name\":\"Kaylee Burns\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"}],\"doi\":\"10.1007/978-3-030-01219-9_47\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b0c5dc3fa19a2bc97606ccb6f55226b913984395\",\"title\":\"Women also Snowboard: Overcoming Bias in Captioning Models\",\"url\":\"https://www.semanticscholar.org/paper/b0c5dc3fa19a2bc97606ccb6f55226b913984395\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47196880\",\"name\":\"Ziwei Wang\"},{\"authorId\":\"145622169\",\"name\":\"Zi Huang\"},{\"authorId\":\"150350159\",\"name\":\"Yadan Luo\"}],\"doi\":\"10.1007/978-3-030-39469-1_2\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7fb87759fff098cbb487d74404ce8ca1098253a1\",\"title\":\"PAIC: Parallelised Attentive Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7fb87759fff098cbb487d74404ce8ca1098253a1\",\"venue\":\"ADC\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Steven J. Rennie\"},{\"authorId\":null,\"name\":\"Etienne Marcheret\"},{\"authorId\":null,\"name\":\"Youssef Mroueh\"},{\"authorId\":null,\"name\":\"Jarret Ross\"},{\"authorId\":null,\"name\":\"Vaibhava Goel. Selfcritical sequence training for image captioning\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In CVPR\",\"url\":\"\",\"venue\":\"pages 1179\\u20131195,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48707795\",\"name\":\"Ziwei Wang\"},{\"authorId\":\"7988538\",\"name\":\"Yadan Luo\"},{\"authorId\":null,\"name\":\"Yang Li\"},{\"authorId\":\"145622169\",\"name\":\"Zi Huang\"},{\"authorId\":\"2416851\",\"name\":\"Hongzhi Yin\"}],\"doi\":\"10.1145/3240508.3240583\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f9853c76065b72a8a25d984f7aa4f2c65a2df623\",\"title\":\"Look Deeper See Richer: Depth-aware Image Paragraph Captioning\",\"url\":\"https://www.semanticscholar.org/paper/f9853c76065b72a8a25d984f7aa4f2c65a2df623\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Peter Anderson\"},{\"authorId\":null,\"name\":\"Xiaodong He\"},{\"authorId\":null,\"name\":\"Chris Buehler\"},{\"authorId\":null,\"name\":\"Damien Teney\"},{\"authorId\":null,\"name\":\"Mark Johnson\"},{\"authorId\":null,\"name\":\"Stephen Gould\"},{\"authorId\":null,\"name\":\"Lei Zhang. Bottom-up\"},{\"authorId\":null,\"name\":\"top-down attention for image captioning\"},{\"authorId\":null,\"name\":\"visual question answering\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In CVPR\",\"url\":\"\",\"venue\":\"pages 6077\\u20136086,\",\"year\":2018},{\"arxivId\":\"1411.5726\",\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2015.7299087\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"258986132bf17755fe8263e42429fe73218c1534\",\"title\":\"CIDEr: Consensus-based image description evaluation\",\"url\":\"https://www.semanticscholar.org/paper/258986132bf17755fe8263e42429fe73218c1534\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1812.11004\",\"authors\":[{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"1770664\",\"name\":\"X. Li\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1109/TPAMI.2019.2894139\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c0343f9cc5f16166bda83815812c4c71ab3258e3\",\"title\":\"Hierarchical LSTMs with Adaptive Attention for Visual Captioning\",\"url\":\"https://www.semanticscholar.org/paper/c0343f9cc5f16166bda83815812c4c71ab3258e3\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ashish Vaswani\"},{\"authorId\":null,\"name\":\"Noam Shazeer\"},{\"authorId\":null,\"name\":\"Niki Parmar\"},{\"authorId\":null,\"name\":\"Jakob Uszkoreit\"},{\"authorId\":null,\"name\":\"Llion Jones\"},{\"authorId\":null,\"name\":\"Aidan N. Gomez\"},{\"authorId\":null,\"name\":\"Lukasz Kaiser\"},{\"authorId\":null,\"name\":\"Illia Polosukhin. Attention is all you need\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In NeurIPS\",\"url\":\"\",\"venue\":\"pages 6000\\u20136010,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Andrej Karpathy\"},{\"authorId\":null,\"name\":\"Li FeiFei. Deep visual-semantic alignments for genera descriptions\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"TPAMI\",\"url\":\"\",\"venue\":\"pages 664\\u2013676,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yang Li\"},{\"authorId\":null,\"name\":\"Yadan Luo\"},{\"authorId\":null,\"name\":\"Zi Huang. Graphbased relation-aware representation le matching\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In ADC\",\"url\":\"\",\"venue\":\"pages 189\\u2013197,\",\"year\":2020},{\"arxivId\":\"1708.02478\",\"authors\":[{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"8280077\",\"name\":\"Yuyu Guo\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"1720243\",\"name\":\"X. Li\"},{\"authorId\":\"1718099\",\"name\":\"A. Hanjalic\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1109/TNNLS.2018.2851077\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7d78c47093fbf3d85225fd502674aba4a29b3987\",\"title\":\"From Deterministic to Generative: Multimodal Stochastic RNNs for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7d78c47093fbf3d85225fd502674aba4a29b3987\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2019},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1612.01887\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":\"10.1109/CVPR.2017.345\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"9f4d7d622d1f7319cc511bfef661cd973e881a4c\",\"title\":\"Knowing When to Look: Adaptive Attention via a Visual Sentinel for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9f4d7d622d1f7319cc511bfef661cd973e881a4c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3323275\",\"name\":\"Kishore Papineni\"},{\"authorId\":\"1781292\",\"name\":\"S. Roukos\"},{\"authorId\":\"144582029\",\"name\":\"T. Ward\"},{\"authorId\":\"2587983\",\"name\":\"Wei-Jing Zhu\"}],\"doi\":\"10.3115/1073083.1073135\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d7da009f457917aa381619facfa5ffae9329a6e9\",\"title\":\"Bleu: a Method for Automatic Evaluation of Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/d7da009f457917aa381619facfa5ffae9329a6e9\",\"venue\":\"ACL\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ting Yao\"},{\"authorId\":null,\"name\":\"Yingwei Pan\"},{\"authorId\":null,\"name\":\"Yehao Li\"},{\"authorId\":null,\"name\":\"Zhaofan Qiu\"},{\"authorId\":null,\"name\":\"Tao Mei. Boosting image captioning with attributes\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In ICCV\",\"url\":\"\",\"venue\":\"pages 4904\\u20134912,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Quanzeng You\"},{\"authorId\":null,\"name\":\"Hailin Jin\"},{\"authorId\":null,\"name\":\"Zhaowen Wang\"},{\"authorId\":null,\"name\":\"Chen Fang\"},{\"authorId\":null,\"name\":\"Jiebo Luo. Image captioning with semantic attention\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In CVPR\",\"url\":\"\",\"venue\":\"pages 4651\\u20134659,\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yadan Luo\"},{\"authorId\":null,\"name\":\"Zi Huang\"},{\"authorId\":null,\"name\":\"Zheng Zhang\"},{\"authorId\":null,\"name\":\"Ziwei Wang\"},{\"authorId\":null,\"name\":\"Jingjing Li\"},{\"authorId\":null,\"name\":\"Yang Yang. Curiosity-driven reinforcement learning for  generation\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"ACM MM\",\"url\":\"\",\"venue\":\"pages 2341\\u20132350,\",\"year\":2019}],\"title\":\"Human Consensus-Oriented Image Captioning\",\"topics\":[{\"topic\":\"Data quality\",\"topicId\":\"23731\",\"url\":\"https://www.semanticscholar.org/topic/23731\"},{\"topic\":\"Reinforcement learning\",\"topicId\":\"2557\",\"url\":\"https://www.semanticscholar.org/topic/2557\"},{\"topic\":\"Cross entropy\",\"topicId\":\"32634\",\"url\":\"https://www.semanticscholar.org/topic/32634\"},{\"topic\":\"Ground truth\",\"topicId\":\"33313\",\"url\":\"https://www.semanticscholar.org/topic/33313\"},{\"topic\":\"Visual Objects\",\"topicId\":\"242884\",\"url\":\"https://www.semanticscholar.org/topic/242884\"},{\"topic\":\"Crowdsourcing\",\"topicId\":\"85\",\"url\":\"https://www.semanticscholar.org/topic/85\"},{\"topic\":\"Teaching method\",\"topicId\":\"73414\",\"url\":\"https://www.semanticscholar.org/topic/73414\"},{\"topic\":\"Display resolution\",\"topicId\":\"11387\",\"url\":\"https://www.semanticscholar.org/topic/11387\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Align (company)\",\"topicId\":\"439709\",\"url\":\"https://www.semanticscholar.org/topic/439709\"}],\"url\":\"https://www.semanticscholar.org/paper/506e7acfb05c851a7b3ccb256f4fed6d5a7dc15c\",\"venue\":\"IJCAI\",\"year\":2020}\n"