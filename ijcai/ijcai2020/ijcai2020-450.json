"{\"abstract\":\"In this paper, we introduce Transformer to the timedomain methods for single-channel speech separation. Transformer has the potential to boost speech separation performance because of its strong sequence modeling capability. However, its computational complexity, which grows quadratically with the sequence length, has made it largely inapplicable to speech applications. To tackle this issue, we propose a novel variation of Transformer, named multi-scale group Transformer (MSGT). The key ideas are group self-attention, which significantly reduces the complexity, and multi-scale fusion, which retains Transform\\u2019s ability to capture longterm dependency. We implement two versions of MSGT with different complexities, and apply them to a well-known time-domain speech separation method called Conv-TasNet. By simply replacing the original temporal convolutional network (TCN) with MSGT, our approach called MSGTTasNet achieves a large gain over Conv-TasNet on both WSJ0-2mix and WHAM! benchmarks. Without bells and whistles, the performance of MSGTTasNet is already on par with the SOTA methods.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"3381375\",\"name\":\"Y. Zhao\",\"url\":\"https://www.semanticscholar.org/author/3381375\"},{\"authorId\":\"2820418\",\"name\":\"Chong Luo\",\"url\":\"https://www.semanticscholar.org/author/2820418\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\",\"url\":\"https://www.semanticscholar.org/author/143962510\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\",\"url\":\"https://www.semanticscholar.org/author/144864745\"}],\"citationVelocity\":0,\"citations\":[],\"corpusId\":220485088,\"doi\":\"10.24963/ijcai.2020/450\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":false,\"is_publisher_licensed\":false,\"paperId\":\"97cc5d9162f3cc7c20ebaaadc0646f058d488f95\",\"references\":[{\"arxivId\":\"1904.10509\",\"authors\":[{\"authorId\":\"48422824\",\"name\":\"R. Child\"},{\"authorId\":\"145565184\",\"name\":\"Scott Gray\"},{\"authorId\":\"38909097\",\"name\":\"A. Radford\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"21da617a0f79aabf94272107184606cefe90ab75\",\"title\":\"Generating Long Sequences with Sparse Transformers\",\"url\":\"https://www.semanticscholar.org/paper/21da617a0f79aabf94272107184606cefe90ab75\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1811.02508\",\"authors\":[{\"authorId\":\"9332945\",\"name\":\"Jonathan Le Roux\"},{\"authorId\":\"2249568\",\"name\":\"S. Wisdom\"},{\"authorId\":\"143873859\",\"name\":\"Hakan Erdogan\"},{\"authorId\":\"2387467\",\"name\":\"J. Hershey\"}],\"doi\":\"10.1109/ICASSP.2019.8683855\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"54feb392b834c56f45d92e2bdbebf74038126faf\",\"title\":\"SDR \\u2013 Half-baked or Well Done?\",\"url\":\"https://www.semanticscholar.org/paper/54feb392b834c56f45d92e2bdbebf74038126faf\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":\"1810.04805\",\"authors\":[{\"authorId\":\"39172707\",\"name\":\"J. Devlin\"},{\"authorId\":\"1744179\",\"name\":\"Ming-Wei Chang\"},{\"authorId\":\"2544107\",\"name\":\"Kenton Lee\"},{\"authorId\":\"3259253\",\"name\":\"Kristina Toutanova\"}],\"doi\":\"10.18653/v1/N19-1423\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"df2b0e26d0599ce3e70df8a9da02e51594e0e992\",\"title\":\"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\",\"url\":\"https://www.semanticscholar.org/paper/df2b0e26d0599ce3e70df8a9da02e51594e0e992\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":\"1907.01160\",\"authors\":[{\"authorId\":\"1816785\",\"name\":\"G. Wichern\"},{\"authorId\":\"121470632\",\"name\":\"Joe M. Antognini\"},{\"authorId\":\"145900985\",\"name\":\"M. Flynn\"},{\"authorId\":\"28109037\",\"name\":\"L. Zhu\"},{\"authorId\":\"2584132\",\"name\":\"E. McQuinn\"},{\"authorId\":\"150074096\",\"name\":\"Dwight Crow\"},{\"authorId\":\"30450247\",\"name\":\"Ethan Manilow\"},{\"authorId\":\"9332945\",\"name\":\"Jonathan Le Roux\"}],\"doi\":\"10.21437/interspeech.2019-2821\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a6aca3527e123849b740d63e064051a1a46ecec6\",\"title\":\"WHAM!: Extending Speech Separation to Noisy Environments\",\"url\":\"https://www.semanticscholar.org/paper/a6aca3527e123849b740d63e064051a1a46ecec6\",\"venue\":\"INTERSPEECH\",\"year\":2019},{\"arxivId\":\"1902.04891\",\"authors\":[{\"authorId\":\"1891658\",\"name\":\"Ziqiang Shi\"},{\"authorId\":\"9244245\",\"name\":\"Huibin Lin\"},{\"authorId\":\"144117143\",\"name\":\"L. Liu\"},{\"authorId\":\"2113095\",\"name\":\"R. Liu\"},{\"authorId\":\"1718376\",\"name\":\"Jiqing Han\"}],\"doi\":\"10.1007/978-3-030-37731-1_53\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"075ad43cec3aaf6001bae4bfffd12692a2475419\",\"title\":\"FurcaNeXt: End-to-end monaural speech separation with dynamic gated dilated temporal convolutional networks\",\"url\":\"https://www.semanticscholar.org/paper/075ad43cec3aaf6001bae4bfffd12692a2475419\",\"venue\":\"MMM\",\"year\":2020},{\"arxivId\":\"1905.13164\",\"authors\":[{\"authorId\":\"39798499\",\"name\":\"Yang Liu\"},{\"authorId\":\"1747893\",\"name\":\"Mirella Lapata\"}],\"doi\":\"10.18653/v1/P19-1500\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7cc730da554003dda77796d2cb4f06da5dfd5592\",\"title\":\"Hierarchical Transformers for Multi-Document Summarization\",\"url\":\"https://www.semanticscholar.org/paper/7cc730da554003dda77796d2cb4f06da5dfd5592\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1508.04306\",\"authors\":[{\"authorId\":\"2387467\",\"name\":\"J. Hershey\"},{\"authorId\":\"49865106\",\"name\":\"Z. Chen\"},{\"authorId\":\"9332945\",\"name\":\"Jonathan Le Roux\"},{\"authorId\":\"1746678\",\"name\":\"Shinji Watanabe\"}],\"doi\":\"10.1109/ICASSP.2016.7471631\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3332dc72fbe3907e45e8a500c6a1202ad5092c0f\",\"title\":\"Deep clustering: Discriminative embeddings for segmentation and separation\",\"url\":\"https://www.semanticscholar.org/paper/3332dc72fbe3907e45e8a500c6a1202ad5092c0f\",\"venue\":\"2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2016},{\"arxivId\":\"1809.01576\",\"authors\":[{\"authorId\":\"1756193\",\"name\":\"Lesly Miculicich\"},{\"authorId\":\"2559762\",\"name\":\"Dhananjay Ram\"},{\"authorId\":\"143958923\",\"name\":\"Nikolaos Pappas\"},{\"authorId\":\"144915758\",\"name\":\"James Henderson\"}],\"doi\":\"10.18653/v1/D18-1325\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e20ff55e87e2b3ef02ae0529880bb705f5efbcae\",\"title\":\"Document-Level Neural Machine Translation with Hierarchical Attention Networks\",\"url\":\"https://www.semanticscholar.org/paper/e20ff55e87e2b3ef02ae0529880bb705f5efbcae\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145458655\",\"name\":\"J. Shi\"},{\"authorId\":\"46372563\",\"name\":\"Jiaming Xu\"},{\"authorId\":\"1990768\",\"name\":\"Guangcan Liu\"},{\"authorId\":\"49821282\",\"name\":\"Bo Xu\"}],\"doi\":\"10.24963/ijcai.2018/605\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6252b915b64ccfea7dd32b37c2d24b6480d944e7\",\"title\":\"Listen, Think and Listen Again: Capturing Top-down Auditory Attention for Speaker-independent Speech Separation\",\"url\":\"https://www.semanticscholar.org/paper/6252b915b64ccfea7dd32b37c2d24b6480d944e7\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":\"1911.08895\",\"authors\":[{\"authorId\":\"10709286\",\"name\":\"Jens Heitkaemper\"},{\"authorId\":\"1420549202\",\"name\":\"Darius Jakobeit\"},{\"authorId\":\"3364548\",\"name\":\"Christoph B\\u00f6ddeker\"},{\"authorId\":\"3353106\",\"name\":\"Lukas Drude\"},{\"authorId\":\"1390103475\",\"name\":\"R. Haeb-Umbach\"}],\"doi\":\"10.1109/ICASSP40776.2020.9052981\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6acdf6296d40bc849241f67c637df0e19743b1a3\",\"title\":\"Demystifying TasNet: A Dissecting Approach\",\"url\":\"https://www.semanticscholar.org/paper/6acdf6296d40bc849241f67c637df0e19743b1a3\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"1804.10204\",\"authors\":[{\"authorId\":\"12229660\",\"name\":\"Zhong-qiu Wang\"},{\"authorId\":\"9332945\",\"name\":\"Jonathan Le Roux\"},{\"authorId\":\"1733567\",\"name\":\"D. Wang\"},{\"authorId\":\"2387467\",\"name\":\"J. Hershey\"}],\"doi\":\"10.21437/Interspeech.2018-1629\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"080e1bb6bbebeb78f822b3998b7ed898ab6457aa\",\"title\":\"End-to-End Speech Separation with Unfolded Iterative Phase Reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/080e1bb6bbebeb78f822b3998b7ed898ab6457aa\",\"venue\":\"INTERSPEECH\",\"year\":2018},{\"arxivId\":\"1706.03762\",\"authors\":[{\"authorId\":\"40348417\",\"name\":\"Ashish Vaswani\"},{\"authorId\":\"1846258\",\"name\":\"Noam Shazeer\"},{\"authorId\":\"3877127\",\"name\":\"Niki Parmar\"},{\"authorId\":\"39328010\",\"name\":\"Jakob Uszkoreit\"},{\"authorId\":\"145024664\",\"name\":\"Llion Jones\"},{\"authorId\":\"19177000\",\"name\":\"Aidan N. Gomez\"},{\"authorId\":\"40527594\",\"name\":\"L. Kaiser\"},{\"authorId\":\"3443442\",\"name\":\"Illia Polosukhin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"204e3073870fae3d05bcbc2f6a8e263d9b72e776\",\"title\":\"Attention is All you Need\",\"url\":\"https://www.semanticscholar.org/paper/204e3073870fae3d05bcbc2f6a8e263d9b72e776\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1901.02860\",\"authors\":[{\"authorId\":\"3422912\",\"name\":\"Zihang Dai\"},{\"authorId\":\"47087291\",\"name\":\"Z. Yang\"},{\"authorId\":\"35729970\",\"name\":\"Yiming Yang\"},{\"authorId\":\"143712374\",\"name\":\"J. Carbonell\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":\"10.18653/v1/P19-1285\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c4744a7c2bb298e4a52289a1e085c71cc3d37bc6\",\"title\":\"Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context\",\"url\":\"https://www.semanticscholar.org/paper/c4744a7c2bb298e4a52289a1e085c71cc3d37bc6\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1708.07524\",\"authors\":[{\"authorId\":\"46348681\",\"name\":\"D. Wang\"},{\"authorId\":\"49252693\",\"name\":\"J. Chen\"}],\"doi\":\"10.1109/TASLP.2018.2842159\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ae523e2f137fa2a4f5a6cbcc443ba63db2642a96\",\"title\":\"Supervised Speech Separation Based on Deep Learning: An Overview\",\"url\":\"https://www.semanticscholar.org/paper/ae523e2f137fa2a4f5a6cbcc443ba63db2642a96\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26433348\",\"name\":\"Morten Kolbaek\"},{\"authorId\":\"144580027\",\"name\":\"Dong Yu\"},{\"authorId\":\"1709835\",\"name\":\"Z. Tan\"},{\"authorId\":\"145416680\",\"name\":\"J. Jensen\"}],\"doi\":\"10.1109/TASLP.2017.2726762\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9451afc942f1f46a32079cedfd74bb4488e364ad\",\"title\":\"Multitalker Speech Separation With Utterance-Level Permutation Invariant Training of Deep Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/9451afc942f1f46a32079cedfd74bb4488e364ad\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2017},{\"arxivId\":\"1711.00541\",\"authors\":[{\"authorId\":\"145714738\",\"name\":\"Yi Luo\"},{\"authorId\":\"1686269\",\"name\":\"Nima Mesgarani\"}],\"doi\":\"10.1109/ICASSP.2018.8462116\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e5c98541d7ba1cdf92a853d731c4bb1b531aa5d9\",\"title\":\"TaSNet: Time-Domain Audio Separation Network for Real-Time, Single-Channel Speech Separation\",\"url\":\"https://www.semanticscholar.org/paper/e5c98541d7ba1cdf92a853d731c4bb1b531aa5d9\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":\"1904.11148\",\"authors\":[{\"authorId\":\"46398413\",\"name\":\"Yuzhou Liu\"},{\"authorId\":\"1733567\",\"name\":\"D. Wang\"}],\"doi\":\"10.1109/TASLP.2019.2941148\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ed3624957894b6b1745a155f6682f9f0ed415b8a\",\"title\":\"Divide and Conquer: A Deep CASA Approach to Talker-Independent Monaural Speaker Separation\",\"url\":\"https://www.semanticscholar.org/paper/ed3624957894b6b1745a155f6682f9f0ed415b8a\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2019},{\"arxivId\":\"1902.09212\",\"authors\":[{\"authorId\":\"143819049\",\"name\":\"K. Sun\"},{\"authorId\":\"144025674\",\"name\":\"Bin Xiao\"},{\"authorId\":\"1718355\",\"name\":\"Dong Liu\"},{\"authorId\":\"1688516\",\"name\":\"Jingdong Wang\"}],\"doi\":\"10.1109/CVPR.2019.00584\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6303bac53abd725c3b458190a6abe389a4a1e72d\",\"title\":\"Deep High-Resolution Representation Learning for Human Pose Estimation\",\"url\":\"https://www.semanticscholar.org/paper/6303bac53abd725c3b458190a6abe389a4a1e72d\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1803.01271\",\"authors\":[{\"authorId\":\"35836381\",\"name\":\"Shaojie Bai\"},{\"authorId\":\"145116464\",\"name\":\"J. Z. Kolter\"},{\"authorId\":\"145231047\",\"name\":\"V. Koltun\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"921196c32213a229245a9705ee4768bc941e7a26\",\"title\":\"An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling\",\"url\":\"https://www.semanticscholar.org/paper/921196c32213a229245a9705ee4768bc941e7a26\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1505.04597\",\"authors\":[{\"authorId\":\"1737326\",\"name\":\"O. Ronneberger\"},{\"authorId\":\"152702479\",\"name\":\"P. Fischer\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1007/978-3-319-24574-4_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6364fdaa0a0eccd823a779fcdd489173f938e91a\",\"title\":\"U-Net: Convolutional Networks for Biomedical Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/6364fdaa0a0eccd823a779fcdd489173f938e91a\",\"venue\":\"MICCAI\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Bin Xiao\"},{\"authorId\":null,\"name\":\"Llion Jones\"},{\"authorId\":null,\"name\":\"Aidan N Gomez\"},{\"authorId\":null,\"name\":\"R\\u00e9mi Gribonval Emmanuel Vincent\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\", and C\\u00e9dric F\\u00e9votte . Performance measurement in blind audio source separation\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1692147\",\"name\":\"E. Vincent\"},{\"authorId\":\"1731535\",\"name\":\"R. Gribonval\"},{\"authorId\":\"1981204\",\"name\":\"C. F\\u00e9votte\"}],\"doi\":\"10.1109/TSA.2005.858005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"29de8281b8cbc764d605a20d00b818eba6d47da1\",\"title\":\"Performance measurement in blind audio source separation\",\"url\":\"https://www.semanticscholar.org/paper/29de8281b8cbc764d605a20d00b818eba6d47da1\",\"venue\":\"IEEE Transactions on Audio, Speech, and Language Processing\",\"year\":2006},{\"arxivId\":\"1811.09010\",\"authors\":[{\"authorId\":\"48708421\",\"name\":\"Z. Wang\"},{\"authorId\":\"144285709\",\"name\":\"Ke Tan\"},{\"authorId\":\"1733567\",\"name\":\"D. Wang\"}],\"doi\":\"10.1109/ICASSP.2019.8683231\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"62f63c6024031418957209601d8b0b8f79e7de19\",\"title\":\"Deep Learning Based Phase Reconstruction for Speaker Separation: A Trigonometric Perspective\",\"url\":\"https://www.semanticscholar.org/paper/62f63c6024031418957209601d8b0b8f79e7de19\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":\"1806.09055\",\"authors\":[{\"authorId\":\"2391802\",\"name\":\"Hanxiao Liu\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"35729970\",\"name\":\"Yiming Yang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c1f457e31b611da727f9aef76c283a18157dfa83\",\"title\":\"DARTS: Differentiable Architecture Search\",\"url\":\"https://www.semanticscholar.org/paper/c1f457e31b611da727f9aef76c283a18157dfa83\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1607.02173\",\"authors\":[{\"authorId\":\"48427563\",\"name\":\"Yusuf Isik\"},{\"authorId\":\"9332945\",\"name\":\"Jonathan Le Roux\"},{\"authorId\":\"145718850\",\"name\":\"Zhuo Chen\"},{\"authorId\":\"1746678\",\"name\":\"Shinji Watanabe\"},{\"authorId\":\"2387467\",\"name\":\"J. Hershey\"}],\"doi\":\"10.21437/Interspeech.2016-1176\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ab94fae3d49cd7016a47020469dc257d8090f5bb\",\"title\":\"Single-Channel Multi-Speaker Separation Using Deep Clustering\",\"url\":\"https://www.semanticscholar.org/paper/ab94fae3d49cd7016a47020469dc257d8090f5bb\",\"venue\":\"INTERSPEECH\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34857174\",\"name\":\"A. Rix\"},{\"authorId\":\"1836184\",\"name\":\"J. Beerends\"},{\"authorId\":\"3124646\",\"name\":\"M. Hollier\"},{\"authorId\":\"8228168\",\"name\":\"A. P. Hekstra\"}],\"doi\":\"10.1109/ICASSP.2001.941023\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dd5e786fd6ced91db79105ca289f49816fe17c80\",\"title\":\"Perceptual evaluation of speech quality (PESQ)-a new method for speech quality assessment of telephone networks and codecs\",\"url\":\"https://www.semanticscholar.org/paper/dd5e786fd6ced91db79105ca289f49816fe17c80\",\"venue\":\"2001 IEEE International Conference on Acoustics, Speech, and Signal Processing. Proceedings (Cat. No.01CH37221)\",\"year\":2001},{\"arxivId\":\"1809.07454\",\"authors\":[{\"authorId\":\"145714738\",\"name\":\"Yi Luo\"},{\"authorId\":\"1686269\",\"name\":\"Nima Mesgarani\"}],\"doi\":\"10.1109/TASLP.2019.2915167\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d4b28a4a244a569d5a1345464ae2be48595fff0\",\"title\":\"Conv-TasNet: Surpassing Ideal Time\\u2013Frequency Magnitude Masking for Speech Separation\",\"url\":\"https://www.semanticscholar.org/paper/0d4b28a4a244a569d5a1345464ae2be48595fff0\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2019},{\"arxivId\":\"1804.00857\",\"authors\":[{\"authorId\":\"143681703\",\"name\":\"Tao Shen\"},{\"authorId\":\"1805655\",\"name\":\"Tianyi Zhou\"},{\"authorId\":\"2062835\",\"name\":\"Guodong Long\"},{\"authorId\":\"1746594\",\"name\":\"Jing Jiang\"},{\"authorId\":\"32076894\",\"name\":\"C. Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0ef460c47377c3b9482d8177cbcafad1730a91a5\",\"title\":\"Bi-Directional Block Self-Attention for Fast and Memory-Efficient Sequence Modeling\",\"url\":\"https://www.semanticscholar.org/paper/0ef460c47377c3b9482d8177cbcafad1730a91a5\",\"venue\":\"ICLR\",\"year\":2018}],\"title\":\"Multi-Scale Group Transformer for Long Sequence Modeling in Speech Separation\",\"topics\":[{\"topic\":\"Transformer\",\"topicId\":\"6977\",\"url\":\"https://www.semanticscholar.org/topic/6977\"}],\"url\":\"https://www.semanticscholar.org/paper/97cc5d9162f3cc7c20ebaaadc0646f058d488f95\",\"venue\":\"IJCAI\",\"year\":2020}\n"