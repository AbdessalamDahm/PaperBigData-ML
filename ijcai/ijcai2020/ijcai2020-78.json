"{\"abstract\":\"Recognizing sounds is a key aspect of computational audio scene analysis and machine perception. In this paper, we advocate that sound recognition is inherently a multi-modal audiovisual task in that it is easier to differentiate sounds using both the audio and visual modalities as opposed to one or the other. We present an audiovisual fusion model that learns to recognize sounds from weakly labeled video recordings. The proposed fusion model utilizes an attention mechanism to dynamically combine the outputs of the individual audio and visual models. Experiments on the large scale sound events dataset, AudioSet, demonstrate the efficacy of the proposed model, which outperforms the single-modal models, and state-of-the-art fusion and multi-modal models. We achieve a mean Average Precision (mAP) of 46.16 on Audioset, outperforming prior state of the art by approximately +4.35 mAP (relative: 10.4%).\",\"arxivId\":\"2006.01595\",\"authors\":[{\"authorId\":\"1822214\",\"name\":\"Haytham M. Fayek\",\"url\":\"https://www.semanticscholar.org/author/1822214\"},{\"authorId\":\"39862695\",\"name\":\"Anurag Kumar\",\"url\":\"https://www.semanticscholar.org/author/39862695\"}],\"citationVelocity\":0,\"citations\":[],\"corpusId\":219179855,\"doi\":\"10.24963/ijcai.2020/78\",\"fieldsOfStudy\":[\"Computer Science\",\"Engineering\",\"Mathematics\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"5bc24361d1f1ec16451d9c9531cfb45b99ea6a1f\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Stuart Andrews\"},{\"authorId\":null,\"name\":\"Ioannis Tsochantaridis\"},{\"authorId\":null,\"name\":\"Thomas Hofmann. Support vector machines for multiple-inst learning\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In NIPS\",\"url\":\"\",\"venue\":\"pages 577\\u2013584,\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Qiuqiang Kong\"},{\"authorId\":null,\"name\":\"Changsong Yu\"},{\"authorId\":null,\"name\":\"Yong Xu\"},{\"authorId\":null,\"name\":\"Turab Iqbal\"},{\"authorId\":null,\"name\":\"Wenwu Wang\"},{\"authorId\":null,\"name\":\"Mark D Plumbley. Weakly labelled audioset tagging with  networks\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"IEEE/ACM Transactions on Audio\",\"url\":\"\",\"venue\":\"Speech, and Language Processing (TASLP), 27(11):1791\\u20131802,\",\"year\":2019},{\"arxivId\":\"1705.09406\",\"authors\":[{\"authorId\":\"11138090\",\"name\":\"Tadas Baltru\\u0161aitis\"},{\"authorId\":\"118242121\",\"name\":\"Chaitanya Ahuja\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.1109/TPAMI.2018.2798607\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6bc4b1376ec2812b6d752c4f6bc8d8fd0512db91\",\"title\":\"Multimodal Machine Learning: A Survey and Taxonomy\",\"url\":\"https://www.semanticscholar.org/paper/6bc4b1376ec2812b6d752c4f6bc8d8fd0512db91\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Bruno Korbar\"},{\"authorId\":null,\"name\":\"Du Tran\"},{\"authorId\":null,\"name\":\"Lorenzo Torresani. Cooperative learning of audio\"},{\"authorId\":null,\"name\":\"video models from self-supervised synchronization\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In NeurIPS\",\"url\":\"\",\"venue\":\"pages 7763\\u20137774,\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yun Wang\"},{\"authorId\":null,\"name\":\"Juncheng Li\"},{\"authorId\":null,\"name\":\"Florian Metze. A comparison of five multiple instance lear labeling\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In ICASSP\",\"url\":\"\",\"venue\":\"pages 31\\u201335,\",\"year\":2019},{\"arxivId\":\"1912.04487\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":\"10.1109/cvpr42600.2020.01047\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c4128ba8deeb67e731cf52fb98addcfddd487e55\",\"title\":\"Listen to Look: Action Recognition by Previewing Audio\",\"url\":\"https://www.semanticscholar.org/paper/c4128ba8deeb67e731cf52fb98addcfddd487e55\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1811.05250\",\"authors\":[{\"authorId\":\"33481412\",\"name\":\"Pan Zhou\"},{\"authorId\":\"47718595\",\"name\":\"Wenwen Yang\"},{\"authorId\":\"50504401\",\"name\":\"Wei Chen\"},{\"authorId\":\"47905788\",\"name\":\"Y. Wang\"},{\"authorId\":\"144202060\",\"name\":\"Jia Jia\"}],\"doi\":\"10.1109/ICASSP.2019.8683733\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"65591f0aa156b3bb8bbcbaebc635d905f1b6c6d6\",\"title\":\"Modality Attention for End-to-end Audio-visual Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/65591f0aa156b3bb8bbcbaebc635d905f1b6c6d6\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"113798831\",\"name\":\"B. Holden\"}],\"doi\":\"10.7748/ns.9.9.42.s63\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1ff63fbb179b1d6038e0a1c0382fdc0c43308378\",\"title\":\"Listen and learn\",\"url\":\"https://www.semanticscholar.org/paper/1ff63fbb179b1d6038e0a1c0382fdc0c43308378\",\"venue\":\"\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Pan Zhou\"},{\"authorId\":null,\"name\":\"Wenwen Yang\"},{\"authorId\":null,\"name\":\"Wei Chen\"},{\"authorId\":null,\"name\":\"Yanfeng Wang\"},{\"authorId\":null,\"name\":\"Jia Jia. Modality attention for endto-end audio-visual ICASSP\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"pages 6565\\u20136569\",\"url\":\"\",\"venue\":\"IEEE,\",\"year\":2019},{\"arxivId\":\"1810.09050\",\"authors\":[{\"authorId\":\"46393778\",\"name\":\"Y. Wang\"},{\"authorId\":\"3428237\",\"name\":\"Juncheng Billy Li\"},{\"authorId\":\"1740721\",\"name\":\"F. Metze\"}],\"doi\":\"10.1109/ICASSP.2019.8682847\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d961f1ec47bc2894d4b01cce7b918b303029fe48\",\"title\":\"A Comparison of Five Multiple Instance Learning Pooling Functions for Sound Event Detection with Weak Labeling\",\"url\":\"https://www.semanticscholar.org/paper/d961f1ec47bc2894d4b01cce7b918b303029fe48\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"References adavanne\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Arandjelovic and Zisserman, 2017] Relja Arandjelovic and Andrew Zisserman. Look, listen and learn\",\"url\":\"\",\"venue\":\"Tadas Baltru\\u0161aitis, Chaitanya Ahuja, and Louis-Philippe Morency. Multimodal machine learning: A survey and taxonomy. IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3116662\",\"name\":\"J. Gemmeke\"},{\"authorId\":\"1745455\",\"name\":\"D. Ellis\"},{\"authorId\":\"36794621\",\"name\":\"Dylan Freedman\"},{\"authorId\":\"35996413\",\"name\":\"A. Jansen\"},{\"authorId\":\"39965499\",\"name\":\"W. Lawrence\"},{\"authorId\":\"1974225\",\"name\":\"R. C. Moore\"},{\"authorId\":\"2114994\",\"name\":\"M. Plakal\"},{\"authorId\":\"39687627\",\"name\":\"M. Ritter\"}],\"doi\":\"10.1109/ICASSP.2017.7952261\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5ba2218b708ca64ab556e39d5997202e012717d5\",\"title\":\"Audio Set: An ontology and human-labeled dataset for audio events\",\"url\":\"https://www.semanticscholar.org/paper/5ba2218b708ca64ab556e39d5997202e012717d5\",\"venue\":\"2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2017},{\"arxivId\":\"1409.0473\",\"authors\":[{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"title\":\"Neural Machine Translation by Jointly Learning to Align and Translate\",\"url\":\"https://www.semanticscholar.org/paper/fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71296665\",\"name\":\"Logan Ford\"},{\"authorId\":\"40860114\",\"name\":\"Hao Tang\"},{\"authorId\":\"30601738\",\"name\":\"Fran\\u00e7ois Grondin\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"}],\"doi\":\"10.21437/interspeech.2019-2731\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4616ea39c9c4fcaec65b1cf4769898b441511fd0\",\"title\":\"A Deep Residual Network for Large-Scale Acoustic Scene Analysis\",\"url\":\"https://www.semanticscholar.org/paper/4616ea39c9c4fcaec65b1cf4769898b441511fd0\",\"venue\":\"INTERSPEECH\",\"year\":2019},{\"arxivId\":\"1908.08498\",\"authors\":[{\"authorId\":\"48842721\",\"name\":\"Evangelos Kazakos\"},{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.1109/ICCV.2019.00559\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7c9de67cc76aeecddcd07e8898acea3ef4eba738\",\"title\":\"EPIC-Fusion: Audio-Visual Temporal Binding for Egocentric Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7c9de67cc76aeecddcd07e8898acea3ef4eba738\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1911.12667\",\"authors\":[{\"authorId\":\"19198894\",\"name\":\"Humam Alwassel\"},{\"authorId\":\"144542135\",\"name\":\"D. Mahajan\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1ee9df4e96f5021509c438751b48d3de07ae8b75\",\"title\":\"Self-Supervised Learning by Cross-Modal Audio-Video Clustering\",\"url\":\"https://www.semanticscholar.org/paper/1ee9df4e96f5021509c438751b48d3de07ae8b75\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143745107\",\"name\":\"S. Andrews\"},{\"authorId\":\"1765700\",\"name\":\"Ioannis Tsochantaridis\"},{\"authorId\":\"143936663\",\"name\":\"Thomas Hofmann\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"02e68b069d9cf13c082049429ffed18a5ca5f6d0\",\"title\":\"Support Vector Machines for Multiple-Instance Learning\",\"url\":\"https://www.semanticscholar.org/paper/02e68b069d9cf13c082049429ffed18a5ca5f6d0\",\"venue\":\"NIPS\",\"year\":2002},{\"arxivId\":\"1711.09550\",\"authors\":[{\"authorId\":\"144858226\",\"name\":\"Xiang Long\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144608002\",\"name\":\"Gerard de Melo\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"48033101\",\"name\":\"Xiao Liu\"},{\"authorId\":\"35247507\",\"name\":\"Shilei Wen\"}],\"doi\":\"10.1109/CVPR.2018.00817\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5406fd98aa22bc2a0c1a8bc2a58ca3eb7a91155d\",\"title\":\"Attention Clusters: Purely Attention Based Local Feature Integration for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/5406fd98aa22bc2a0c1a8bc2a58ca3eb7a91155d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2126047\",\"name\":\"Xiu-Shen Wei\"},{\"authorId\":\"1808816\",\"name\":\"Jianxin Wu\"},{\"authorId\":\"145624000\",\"name\":\"Z. Zhou\"}],\"doi\":\"10.1109/ICDM.2014.16\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"077ef373d33952ac1a03ce34758c68ebf3ed4abc\",\"title\":\"Scalable Multi-instance Learning\",\"url\":\"https://www.semanticscholar.org/paper/077ef373d33952ac1a03ce34758c68ebf3ed4abc\",\"venue\":\"2014 IEEE International Conference on Data Mining\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1765212\",\"name\":\"C. Hori\"},{\"authorId\":\"145443186\",\"name\":\"T. Hori\"},{\"authorId\":\"1816785\",\"name\":\"G. Wichern\"},{\"authorId\":null,\"name\":\"Jue Wang\"},{\"authorId\":\"1747615\",\"name\":\"Teng-Yok Lee\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8e561b60c6aea937f9d98ee336dde01abd1ff651\",\"title\":\"Multimodal Attention for Fusion of Audio and Spatiotemporal Features for Video Description\",\"url\":\"https://www.semanticscholar.org/paper/8e561b60c6aea937f9d98ee336dde01abd1ff651\",\"venue\":\"CVPR Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[],\"doi\":\"10.1145/3242969\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3cb3e110331e0108c04cbfad1f6e30e2d0fc7a39\",\"title\":\"Proceedings of the 20th ACM International Conference on Multimodal Interaction\",\"url\":\"https://www.semanticscholar.org/paper/3cb3e110331e0108c04cbfad1f6e30e2d0fc7a39\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1705.08421\",\"authors\":[{\"authorId\":\"39599498\",\"name\":\"C. Gu\"},{\"authorId\":\"94567368\",\"name\":\"C. Sun\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"2997956\",\"name\":\"C. Pantofaru\"},{\"authorId\":\"144711958\",\"name\":\"D. Ross\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"1758054\",\"name\":\"Y. Li\"},{\"authorId\":\"2262946\",\"name\":\"S. Ricco\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"153652146\",\"name\":\"J. Malik\"}],\"doi\":\"10.1109/CVPR.2018.00633\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"54c7c3909c7e1e827befdbe8d2595a3b196ba1b8\",\"title\":\"AVA: A Video Dataset of Spatio-Temporally Localized Atomic Visual Actions\",\"url\":\"https://www.semanticscholar.org/paper/54c7c3909c7e1e827befdbe8d2595a3b196ba1b8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1684454\",\"name\":\"T. Virtanen\"},{\"authorId\":\"1804703\",\"name\":\"Mark D. Plumbley\"},{\"authorId\":\"41192047\",\"name\":\"D. Ellis\"}],\"doi\":\"10.1007/978-3-319-63450-0\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5d3aa4d98b7f5c16f474df5199355e4c2ded62ec\",\"title\":\"Computational Analysis of Sound Scenes and Events\",\"url\":\"https://www.semanticscholar.org/paper/5d3aa4d98b7f5c16f474df5199355e4c2ded62ec\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1606.03664\",\"authors\":[{\"authorId\":\"47311290\",\"name\":\"Anurag Kumar\"},{\"authorId\":\"1681921\",\"name\":\"B. Raj\"}],\"doi\":\"10.1109/ICME.2016.7552989\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7df427403a84bf13f634aeb826daf53d59eef961\",\"title\":\"Weakly supervised scalable audio content analysis\",\"url\":\"https://www.semanticscholar.org/paper/7df427403a84bf13f634aeb826daf53d59eef961\",\"venue\":\"2016 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7634810\",\"name\":\"Weiyao Wang\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"}],\"doi\":\"10.1109/CVPR42600.2020.01271\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f6caf91f731fab861ef420f680cf691f12f70134\",\"title\":\"What Makes Training Multi-Modal Classification Networks Hard?\",\"url\":\"https://www.semanticscholar.org/paper/f6caf91f731fab861ef420f680cf691f12f70134\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"47680287\",\"name\":\"W. Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2009.5206848\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1b47265245e8db53a553049dcb27ed3e495fd625\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/1b47265245e8db53a553049dcb27ed3e495fd625\",\"venue\":\"CVPR 2009\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Kaiming He\"},{\"authorId\":null,\"name\":\"Xiangyu Zhang\"},{\"authorId\":null,\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun. Deep residual learning for image recognition\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In CVPR\",\"url\":\"\",\"venue\":\"pages 770\\u2013778,\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Anurag Kumar\"},{\"authorId\":null,\"name\":\"Bhiksha Raj. Weakly supervised scalable audio content analysis\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In 2016 IEEE International Conference on Multimedia and Expo (ICME)\",\"url\":\"\",\"venue\":\"pages 1\\u20136. IEEE,\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Zuxuan Wu\"},{\"authorId\":null,\"name\":\"Yu-Gang Jiang\"},{\"authorId\":null,\"name\":\"Xi Wang\"},{\"authorId\":null,\"name\":\"Hao Ye\"},{\"authorId\":null,\"name\":\"Xiangyang Xue. Multi-stream multi-class fusion of deep netwo Multimedia\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"pages 791\\u2013800\",\"url\":\"\",\"venue\":\"ACM,\",\"year\":2016},{\"arxivId\":\"1910.11789\",\"authors\":[{\"authorId\":\"39862695\",\"name\":\"Anurag Kumar\"},{\"authorId\":\"2736958\",\"name\":\"Vamsi K. Ithapu\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053613\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"20488265dac69a91da26ab7364fd4661cf6a9e38\",\"title\":\"SeCoST:: Sequential Co-Supervision for Large Scale Weakly Labeled Audio Event Detection\",\"url\":\"https://www.semanticscholar.org/paper/20488265dac69a91da26ab7364fd4661cf6a9e38\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"1903.00765\",\"authors\":[{\"authorId\":\"8391640\",\"name\":\"Qiuqiang Kong\"},{\"authorId\":\"144057050\",\"name\":\"Changsong Yu\"},{\"authorId\":\"7869811\",\"name\":\"Yinlong Xu\"},{\"authorId\":\"35965227\",\"name\":\"T. Iqbal\"},{\"authorId\":\"144144027\",\"name\":\"Wenwu Wang\"},{\"authorId\":\"1804703\",\"name\":\"Mark D. Plumbley\"}],\"doi\":\"10.1109/TASLP.2019.2930913\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9dc33dacbb1cee017f4b637895abed3be51a67e6\",\"title\":\"Weakly Labelled AudioSet Tagging With Attention Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/9dc33dacbb1cee017f4b637895abed3be51a67e6\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2830332\",\"name\":\"M. Donn\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"89dc2b3aa1f35444ada8f62a5e964227ca227fad\",\"title\":\"Listen and learn.\",\"url\":\"https://www.semanticscholar.org/paper/89dc2b3aa1f35444ada8f62a5e964227ca227fad\",\"venue\":\"The Health service journal\",\"year\":1990},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"47119743\",\"name\":\"X. Wang\"},{\"authorId\":\"145222820\",\"name\":\"H. Ye\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"}],\"doi\":\"10.1145/2964284.2964328\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"899be93e14d991017b1f8a4afdf907cbc03cf300\",\"title\":\"Multi-Stream Multi-Class Fusion of Deep Networks for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/899be93e14d991017b1f8a4afdf907cbc03cf300\",\"venue\":\"ACM Multimedia\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Andrew Owens\"},{\"authorId\":null,\"name\":\"Alexei A Efros. Audio-visual scene analysis with self-sup features\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In ECCV\",\"url\":\"\",\"venue\":\"pages 631\\u2013648,\",\"year\":2018},{\"arxivId\":\"1610.09001\",\"authors\":[{\"authorId\":\"3152281\",\"name\":\"Y. Aytar\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7ab8d3af6f78f9c9f64a2f2d38471401ad0988a9\",\"title\":\"SoundNet: Learning Sound Representations from Unlabeled Video\",\"url\":\"https://www.semanticscholar.org/paper/7ab8d3af6f78f9c9f64a2f2d38471401ad0988a9\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1902.07473\",\"authors\":[{\"authorId\":\"2564871\",\"name\":\"Yan-Bo Lin\"},{\"authorId\":\"3312576\",\"name\":\"Yu-Jhe Li\"},{\"authorId\":\"2733735\",\"name\":\"Y. Wang\"}],\"doi\":\"10.1109/ICASSP.2019.8683226\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6dad33f2e317cc23abeba8596a4c8a4a13117d54\",\"title\":\"Dual-modality Seq2Seq Network for Audio-visual Event Localization\",\"url\":\"https://www.semanticscholar.org/paper/6dad33f2e317cc23abeba8596a4c8a4a13117d54\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Xiu-Shen Wei\"},{\"authorId\":null,\"name\":\"Jianxin Wu\"},{\"authorId\":null,\"name\":\"Zhi-Hua Zhou. Scalable multi-instance learning. In IEEE In Mining\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"pages 1037\\u20131042\",\"url\":\"\",\"venue\":\"IEEE,\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Zhen-zhong Lan\"},{\"authorId\":null,\"name\":\"Lei Bao\"},{\"authorId\":null,\"name\":\"Shoou-I Yu\"},{\"authorId\":null,\"name\":\"Wei Liu\"},{\"authorId\":null,\"name\":\"Alexander G Hauptmann. Double fusion for multimedia event de Modeling\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"pages 173\\u2013185\",\"url\":\"\",\"venue\":\"Springer,\",\"year\":2012},{\"arxivId\":\"1705.06950\",\"authors\":[{\"authorId\":\"21028601\",\"name\":\"W. Kay\"},{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"11809518\",\"name\":\"Brian Zhang\"},{\"authorId\":\"38961760\",\"name\":\"Chloe Hillier\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"143740871\",\"name\":\"F. Viola\"},{\"authorId\":\"143897708\",\"name\":\"T. Green\"},{\"authorId\":\"2830305\",\"name\":\"T. Back\"},{\"authorId\":\"1820908\",\"name\":\"A. Natsev\"},{\"authorId\":\"2573615\",\"name\":\"Mustafa Suleyman\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6\",\"title\":\"The Kinetics Human Action Video Dataset\",\"url\":\"https://www.semanticscholar.org/paper/86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1808.03766\",\"authors\":[{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"},{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"19198894\",\"name\":\"Humam Alwassel\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"8983218\",\"name\":\"S. Buch\"},{\"authorId\":\"3409955\",\"name\":\"C. D. Dao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5468c96e3846da23c26b59c28c313506bffbf7ce\",\"title\":\"The ActivityNet Large-Scale Activity Recognition Challenge 2018 Summary\",\"url\":\"https://www.semanticscholar.org/paper/5468c96e3846da23c26b59c28c313506bffbf7ce\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144886843\",\"name\":\"Richard Lathe\"}],\"doi\":\"10.1038/332676B0\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6ec27fba80de3b9c52ef6ac4eaa9f59821aefb4b\",\"title\":\"Phd by thesis\",\"url\":\"https://www.semanticscholar.org/paper/6ec27fba80de3b9c52ef6ac4eaa9f59821aefb4b\",\"venue\":\"Nature\",\"year\":1988},{\"arxivId\":\"1804.10070\",\"authors\":[{\"authorId\":\"3215419\",\"name\":\"B. McFee\"},{\"authorId\":\"1786276\",\"name\":\"Justin Salamon\"},{\"authorId\":\"34894065\",\"name\":\"J. Bello\"}],\"doi\":\"10.1109/TASLP.2018.2858559\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3b2f7f5363b3a2199a73752035361311f8ba85a4\",\"title\":\"Adaptive Pooling Operators for Weakly Labeled Sound Event Detection\",\"url\":\"https://www.semanticscholar.org/paper/3b2f7f5363b3a2199a73752035361311f8ba85a4\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5886094\",\"name\":\"P. Cochat\"},{\"authorId\":\"13267685\",\"name\":\"L. Vaucoret\"},{\"authorId\":\"31455512\",\"name\":\"J. Sarles\"}],\"doi\":\"10.1016/j.arcped.2012.01.013\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"10d85561e4aafc516d10064f30dff05b41f70afe\",\"title\":\"[Et al].\",\"url\":\"https://www.semanticscholar.org/paper/10d85561e4aafc516d10064f30dff05b41f70afe\",\"venue\":\"Archives de pediatrie : organe officiel de la Societe francaise de pediatrie\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40217426\",\"name\":\"S. Parekh\"},{\"authorId\":\"1807587\",\"name\":\"S. Essid\"},{\"authorId\":\"2889451\",\"name\":\"A. Ozerov\"},{\"authorId\":\"1756744\",\"name\":\"Ngoc Q. K. Duong\"},{\"authorId\":\"144565372\",\"name\":\"P. P\\u00e9rez\"},{\"authorId\":\"145793390\",\"name\":\"G. Richard\"}],\"doi\":\"10.1109/TASLP.2019.2957889\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"300b6751b7ba68908afdd695f6ca5dfb2ff19d07\",\"title\":\"Weakly Supervised Representation Learning for Audio-Visual Scene Analysis\",\"url\":\"https://www.semanticscholar.org/paper/300b6751b7ba68908afdd695f6ca5dfb2ff19d07\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9918923\",\"name\":\"Sharath Adavanne\"},{\"authorId\":\"1822214\",\"name\":\"Haytham M. Fayek\"},{\"authorId\":\"2597239\",\"name\":\"V. Tourbabin\"}],\"doi\":\"10.33682/fx8n-cm43\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dd1b2f02f017221c18130461a2826a1e013dc414\",\"title\":\"Sound event classification and detection with weakly labeled data\",\"url\":\"https://www.semanticscholar.org/paper/dd1b2f02f017221c18130461a2826a1e013dc414\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1605.02401\",\"authors\":[{\"authorId\":\"47311290\",\"name\":\"Anurag Kumar\"},{\"authorId\":\"1681921\",\"name\":\"B. Raj\"}],\"doi\":\"10.1145/2964284.2964310\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"77e5dd853a01b03c6dd6016f484dfd5f6c662db4\",\"title\":\"Audio Event Detection using Weakly Labeled Data\",\"url\":\"https://www.semanticscholar.org/paper/77e5dd853a01b03c6dd6016f484dfd5f6c662db4\",\"venue\":\"ACM Multimedia\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Anurag Kumar\"},{\"authorId\":null,\"name\":\"Bhiksha Raj. Audio event detection using weakly labeled da Multimedia\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"pages 1038\\u20131047\",\"url\":\"\",\"venue\":\"ACM,\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Weiyao Wang\"},{\"authorId\":null,\"name\":\"Du Tran\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"and Matt Feiszli\",\"url\":\"\",\"venue\":\"What makes training multi-modal networks hard? arXiv preprint arXiv:1905.12681,\",\"year\":2019},{\"arxivId\":\"1807.00230\",\"authors\":[{\"authorId\":\"3443095\",\"name\":\"Bruno Korbar\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2e057a9b195f0ea2d1c5a1e88ff9606f9b67ef8b\",\"title\":\"Cooperative Learning of Audio and Video Models from Self-Supervised Synchronization\",\"url\":\"https://www.semanticscholar.org/paper/2e057a9b195f0ea2d1c5a1e88ff9606f9b67ef8b\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"46989533\",\"name\":\"Lei Bao\"},{\"authorId\":\"143642520\",\"name\":\"Shoou-I Yu\"},{\"authorId\":\"40255545\",\"name\":\"W. Liu\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1007/978-3-642-27355-1_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"146adb105ebcece295a24e8cf3643c9fd0f89bcb\",\"title\":\"Double Fusion for Multimedia Event Detection\",\"url\":\"https://www.semanticscholar.org/paper/146adb105ebcece295a24e8cf3643c9fd0f89bcb\",\"venue\":\"MMM\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"McFee et al\"},{\"authorId\":null,\"name\":\"2018 Brian McFee\"},{\"authorId\":null,\"name\":\"Justin Salamon\"},{\"authorId\":null,\"name\":\"Juan Pablo Bello\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Adaptive pooling operators for weakly\",\"url\":\"\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1809.01728\",\"authors\":[{\"authorId\":\"30606918\",\"name\":\"George Sterpu\"},{\"authorId\":\"1814175\",\"name\":\"Christian Saam\"},{\"authorId\":\"144686633\",\"name\":\"N. Harte\"}],\"doi\":\"10.1145/3242969.3243014\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dfd4b7bb92e43db206f853a5c2222e8bc68a4e5e\",\"title\":\"Attention-based Audio-Visual Fusion for Robust Automatic Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/dfd4b7bb92e43db206f853a5c2222e8bc68a4e5e\",\"venue\":\"ICMI\",\"year\":2018}],\"title\":\"Large Scale Audiovisual Learning of Sounds with Weakly Labeled Data\",\"topics\":[{\"topic\":\"Modal logic\",\"topicId\":\"61528\",\"url\":\"https://www.semanticscholar.org/topic/61528\"},{\"topic\":\"Machine perception\",\"topicId\":\"508558\",\"url\":\"https://www.semanticscholar.org/topic/508558\"},{\"topic\":\"Information retrieval\",\"topicId\":\"2867\",\"url\":\"https://www.semanticscholar.org/topic/2867\"},{\"topic\":\"Mean squared error\",\"topicId\":\"49130\",\"url\":\"https://www.semanticscholar.org/topic/49130\"},{\"topic\":\"Mac OS X 10.4 Tiger\",\"topicId\":\"60932\",\"url\":\"https://www.semanticscholar.org/topic/60932\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"}],\"url\":\"https://www.semanticscholar.org/paper/5bc24361d1f1ec16451d9c9531cfb45b99ea6a1f\",\"venue\":\"IJCAI\",\"year\":2020}\n"