"{\"abstract\":\"We study the problem of fitting task-specific learning rate schedules from the perspective of hyperparameter optimization, aiming at good generalization. We describe the structure of the gradient of a validation error w.r.t. the learning rate schedule - the hypergradient. Based on this, we introduce MARTHE, a novel online algorithm guided by cheap approximations of the hypergradient that uses past information from the optimization trajectory to simulate future behaviour. It interpolates between two recent techniques, RTHO (Franceschi et al., 2017) and HD (Baydin et al., 2017), and is able to produce learning rate schedules that are more stable and lead to models that generalize better.\",\"arxivId\":\"1910.08525\",\"authors\":[{\"authorId\":\"2192704\",\"name\":\"Michele Donini\",\"url\":\"https://www.semanticscholar.org/author/2192704\"},{\"authorId\":\"39883180\",\"name\":\"L. Franceschi\",\"url\":\"https://www.semanticscholar.org/author/39883180\"},{\"authorId\":\"1704699\",\"name\":\"M. Pontil\",\"url\":\"https://www.semanticscholar.org/author/1704699\"},{\"authorId\":\"134549850\",\"name\":\"Orchid Majumder\",\"url\":\"https://www.semanticscholar.org/author/134549850\"},{\"authorId\":\"1688235\",\"name\":\"P. Frasconi\",\"url\":\"https://www.semanticscholar.org/author/1688235\"}],\"citationVelocity\":0,\"citations\":[],\"corpusId\":214802632,\"doi\":\"10.24963/ijcai.2020/289\",\"fieldsOfStudy\":[\"Mathematics\",\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"6752cc8440dd269d1665ca16a778de0ebf12b46d\",\"references\":[{\"arxivId\":\"1502.03167\",\"authors\":[{\"authorId\":\"144147316\",\"name\":\"S. Ioffe\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d376d6978dad0374edfa6709c9556b42d3594d3\",\"title\":\"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\",\"url\":\"https://www.semanticscholar.org/paper/4d376d6978dad0374edfa6709c9556b42d3594d3\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145983059\",\"name\":\"A. Griewank\"},{\"authorId\":\"143775642\",\"name\":\"A. Walther\"}],\"doi\":\"10.1137/1.9780898717761\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"cb11771cbfd45aa09e00f1f3b0fc156a087fa544\",\"title\":\"Evaluating derivatives - principles and techniques of algorithmic differentiation, Second Edition\",\"url\":\"https://www.semanticscholar.org/paper/cb11771cbfd45aa09e00f1f3b0fc156a087fa544\",\"venue\":\"Frontiers in applied mathematics\",\"year\":2000},{\"arxivId\":\"1206.5533\",\"authors\":[{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":\"10.1007/978-3-642-35289-8_26\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"522e90b9fccfd3c1c0603359eb04757d770c1ab5\",\"title\":\"Practical Recommendations for Gradient-Based Training of Deep Architectures\",\"url\":\"https://www.semanticscholar.org/paper/522e90b9fccfd3c1c0603359eb04757d770c1ab5\",\"venue\":\"Neural Networks: Tricks of the Trade\",\"year\":2012},{\"arxivId\":\"1606.04474\",\"authors\":[{\"authorId\":\"2206490\",\"name\":\"Marcin Andrychowicz\"},{\"authorId\":\"1715051\",\"name\":\"Misha Denil\"},{\"authorId\":\"2016840\",\"name\":\"Sergio Gomez Colmenarejo\"},{\"authorId\":\"3243579\",\"name\":\"M. W. Hoffman\"},{\"authorId\":\"144846367\",\"name\":\"D. Pfau\"},{\"authorId\":\"1725157\",\"name\":\"T. Schaul\"},{\"authorId\":\"1737568\",\"name\":\"N. D. Freitas\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"395dd01c0d24777c660cf195c4cfadcdf51fb7e8\",\"title\":\"Learning to learn by gradient descent by gradient descent\",\"url\":\"https://www.semanticscholar.org/paper/395dd01c0d24777c660cf195c4cfadcdf51fb7e8\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1806.04910\",\"authors\":[{\"authorId\":\"39883180\",\"name\":\"L. Franceschi\"},{\"authorId\":\"1688235\",\"name\":\"P. Frasconi\"},{\"authorId\":\"2212342\",\"name\":\"Saverio Salzo\"},{\"authorId\":\"51004518\",\"name\":\"Riccardo Grazzi\"},{\"authorId\":\"1704699\",\"name\":\"M. Pontil\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"15561ab20c298e113b0008b7a029486a422e7ca3\",\"title\":\"Bilevel Programming for Hyperparameter Optimization and Meta-Learning\",\"url\":\"https://www.semanticscholar.org/paper/15561ab20c298e113b0008b7a029486a422e7ca3\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3332636\",\"name\":\"Naman Agarwal\"},{\"authorId\":\"3378789\",\"name\":\"Brian Bullins\"},{\"authorId\":\"34840427\",\"name\":\"Elad Hazan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f3ed7343727361a25e77fdef315850bdaf29d20e\",\"title\":\"Second-Order Stochastic Optimization for Machine Learning in Linear Time\",\"url\":\"https://www.semanticscholar.org/paper/f3ed7343727361a25e77fdef315850bdaf29d20e\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5d90f06bb70a0a3dced62413346235c02b1aa086\",\"title\":\"Learning Multiple Layers of Features from Tiny Images\",\"url\":\"https://www.semanticscholar.org/paper/5d90f06bb70a0a3dced62413346235c02b1aa086\",\"venue\":\"\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144215175\",\"name\":\"R. Jacobs\"}],\"doi\":\"10.1016/0893-6080(88)90003-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a9ef2995e8e1bd57a74343073219364811c2ace0\",\"title\":\"Increased rates of convergence through learning rate adaptation\",\"url\":\"https://www.semanticscholar.org/paper/a9ef2995e8e1bd57a74343073219364811c2ace0\",\"venue\":\"Neural Networks\",\"year\":1988},{\"arxivId\":\"1608.03983\",\"authors\":[{\"authorId\":\"1678656\",\"name\":\"I. Loshchilov\"},{\"authorId\":\"144661829\",\"name\":\"F. Hutter\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b022f2a277a4bf5f42382e86e4380b96340b9e86\",\"title\":\"SGDR: Stochastic Gradient Descent with Warm Restarts\",\"url\":\"https://www.semanticscholar.org/paper/b022f2a277a4bf5f42382e86e4380b96340b9e86\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1623397502\",\"name\":\"Saskia Bonjour\"},{\"authorId\":\"1623405226\",\"name\":\"Doutje Lettinga\"},{\"authorId\":\"1623397535\",\"name\":\"Christian Joppke\"}],\"doi\":\"10.1515/9783111576855-009\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"776f6d45b38cf048ff30cea41f0cd3ceeefed622\",\"title\":\"D\",\"url\":\"https://www.semanticscholar.org/paper/776f6d45b38cf048ff30cea41f0cd3ceeefed622\",\"venue\":\"Edinburgh Medical and Surgical Journal\",\"year\":1824},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"M. Andrychowicz\"},{\"authorId\":null,\"name\":\"M. Denil\"},{\"authorId\":null,\"name\":\"S. Gomez\"},{\"authorId\":null,\"name\":\"M. W. Hoffman\"},{\"authorId\":null,\"name\":\"D. Pfau\"},{\"authorId\":null,\"name\":\"T. Schaul\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and N\",\"url\":\"\",\"venue\":\"de Freitas. Learning to learn by gradient descent by gradient descent. In NeurIPS, pages 3981\\u20133989\",\"year\":2016},{\"arxivId\":\"1206.1106\",\"authors\":[{\"authorId\":\"1725157\",\"name\":\"T. Schaul\"},{\"authorId\":\"33551113\",\"name\":\"Sixin Zhang\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e5a685f40338f9c2f3e68e142efa217aad16dd56\",\"title\":\"No more pesky learning rates\",\"url\":\"https://www.semanticscholar.org/paper/e5a685f40338f9c2f3e68e142efa217aad16dd56\",\"venue\":\"ICML\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"K. He\"},{\"authorId\":null,\"name\":\"X. Zhang\"},{\"authorId\":null,\"name\":\"S. Ren\"},{\"authorId\":null,\"name\":\"J. Sun. Deep residual learning for image recognition\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In CVPR\",\"url\":\"\",\"venue\":\"June\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"},{\"authorId\":\"52184096\",\"name\":\"L. Bottou\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"1721248\",\"name\":\"P. Haffner\"}],\"doi\":\"10.1109/5.726791\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"162d958ff885f1462aeda91cd72582323fd6a1f4\",\"title\":\"Gradient-based learning applied to document recognition\",\"url\":\"https://www.semanticscholar.org/paper/162d958ff885f1462aeda91cd72582323fd6a1f4\",\"venue\":\"\",\"year\":1998},{\"arxivId\":\"1703.01785\",\"authors\":[{\"authorId\":\"39883180\",\"name\":\"L. Franceschi\"},{\"authorId\":\"2192704\",\"name\":\"Michele Donini\"},{\"authorId\":\"1688235\",\"name\":\"P. Frasconi\"},{\"authorId\":\"1704699\",\"name\":\"M. Pontil\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ecc76c03d6a3ae4233097ef8bcc9d04d8b3c9bec\",\"title\":\"Forward and Reverse Gradient-Based Hyperparameter Optimization\",\"url\":\"https://www.semanticscholar.org/paper/ecc76c03d6a3ae4233097ef8bcc9d04d8b3c9bec\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1602.04128\",\"authors\":[{\"authorId\":\"1721068\",\"name\":\"F. Orabona\"},{\"authorId\":\"2153912\",\"name\":\"D. P\\u00e1l\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"06bb9abf54e4234f58ebd54d3fe7b4f55f0c4d76\",\"title\":\"Coin Betting and Parameter-Free Online Learning\",\"url\":\"https://www.semanticscholar.org/paper/06bb9abf54e4234f58ebd54d3fe7b4f55f0c4d76\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1206.2944\",\"authors\":[{\"authorId\":\"144108062\",\"name\":\"Jasper Snoek\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1722180\",\"name\":\"R. Adams\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2e2089ae76fe914706e6fa90081a79c8fe01611e\",\"title\":\"Practical Bayesian Optimization of Machine Learning Algorithms\",\"url\":\"https://www.semanticscholar.org/paper/2e2089ae76fe914706e6fa90081a79c8fe01611e\",\"venue\":\"NIPS\",\"year\":2012},{\"arxivId\":\"1903.03088\",\"authors\":[{\"authorId\":\"144393756\",\"name\":\"Matthew MacKay\"},{\"authorId\":\"2039154\",\"name\":\"Paul Vicol\"},{\"authorId\":\"35839440\",\"name\":\"Jonathan Lorraine\"},{\"authorId\":\"1704657\",\"name\":\"D. Duvenaud\"},{\"authorId\":\"1785346\",\"name\":\"Roger B. Grosse\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6d70291572a0fae4bf02b2e08182cab9db64d399\",\"title\":\"Self-Tuning Networks: Bilevel Optimization of Hyperparameters using Structured Best-Response Functions\",\"url\":\"https://www.semanticscholar.org/paper/6d70291572a0fae4bf02b2e08182cab9db64d399\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1700974\",\"name\":\"Barak A. Pearlmutter\"}],\"doi\":\"10.1162/neco.1994.6.1.147\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c6867b6b564462d6b902f68e0bfa58f4717ca1cc\",\"title\":\"Fast Exact Multiplication by the Hessian\",\"url\":\"https://www.semanticscholar.org/paper/c6867b6b564462d6b902f68e0bfa58f4717ca1cc\",\"venue\":\"Neural Computation\",\"year\":1994},{\"arxivId\":\"1511.06727\",\"authors\":[{\"authorId\":\"1818756\",\"name\":\"Jelena Luketina\"},{\"authorId\":\"2785022\",\"name\":\"T. Raiko\"},{\"authorId\":\"2438071\",\"name\":\"Mathias Berglund\"},{\"authorId\":\"3035541\",\"name\":\"Klaus Greff\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dcad2fd88e432f337018e410c44fd45d52851039\",\"title\":\"Scalable Gradient-Based Tuning of Continuous Regularization Hyperparameters\",\"url\":\"https://www.semanticscholar.org/paper/dcad2fd88e432f337018e410c44fd45d52851039\",\"venue\":\"ICML\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"F. Hutter\"},{\"authorId\":null,\"name\":\"L. Kotthoff\"},{\"authorId\":null,\"name\":\"J. Vanschoren\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Automatic Machine Learning: Methods\",\"url\":\"\",\"venue\":\"Systems, Challenges. Springer\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3119801\",\"name\":\"Xavier Glorot\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b71ac1e9fb49420d13e084ac67254a0bbd40f83f\",\"title\":\"Understanding the difficulty of training deep feedforward neural networks\",\"url\":\"https://www.semanticscholar.org/paper/b71ac1e9fb49420d13e084ac67254a0bbd40f83f\",\"venue\":\"AISTATS\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"2812486\",\"name\":\"P. Simard\"},{\"authorId\":\"1688235\",\"name\":\"P. Frasconi\"}],\"doi\":\"10.1109/72.279181\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d0be39ee052d246ae99c082a565aba25b811be2d\",\"title\":\"Learning long-term dependencies with gradient descent is difficult\",\"url\":\"https://www.semanticscholar.org/paper/d0be39ee052d246ae99c082a565aba25b811be2d\",\"venue\":\"IEEE Trans. Neural Networks\",\"year\":1994},{\"arxivId\":\"1703.04813\",\"authors\":[{\"authorId\":\"52495223\",\"name\":\"Olga Wichrowska\"},{\"authorId\":\"2333223\",\"name\":\"Niru Maheswaranathan\"},{\"authorId\":\"3243579\",\"name\":\"M. W. Hoffman\"},{\"authorId\":\"2016840\",\"name\":\"Sergio Gomez Colmenarejo\"},{\"authorId\":\"1715051\",\"name\":\"Misha Denil\"},{\"authorId\":\"1737568\",\"name\":\"N. D. Freitas\"},{\"authorId\":\"1407546430\",\"name\":\"Jascha Sohl-Dickstein\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b8ff7e02ffa1577d125acd3e998e8ce76a9059dc\",\"title\":\"Learned Optimizers that Scale and Generalize\",\"url\":\"https://www.semanticscholar.org/paper/b8ff7e02ffa1577d125acd3e998e8ce76a9059dc\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144661829\",\"name\":\"F. Hutter\"},{\"authorId\":\"1722782\",\"name\":\"Lars Kotthoff\"},{\"authorId\":\"1717534\",\"name\":\"J. Vanschoren\"}],\"doi\":\"10.1007/978-3-030-05318-5\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"47f2f60995e4393ad689233ee870e1e0707d4d60\",\"title\":\"Automated Machine Learning: Methods, Systems, Challenges\",\"url\":\"https://www.semanticscholar.org/paper/47f2f60995e4393ad689233ee870e1e0707d4d60\",\"venue\":\"The Springer Series on Challenges in Machine Learning\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30320952\",\"name\":\"F. Pineda\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cdbfb3714e19680dafb3711d525b481c08a1566f\",\"title\":\"Generalization of Back propagation to Recurrent and Higher Order Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/cdbfb3714e19680dafb3711d525b481c08a1566f\",\"venue\":\"NIPS\",\"year\":1987},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1739396\",\"name\":\"N. N. Schraudolph\"}],\"doi\":\"10.1049/CP:19991170\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"812b49a877b98941f258f7c2bfc8e890963142bd\",\"title\":\"Local Gain Adaptation in Stochastic Gradient Descent\",\"url\":\"https://www.semanticscholar.org/paper/812b49a877b98941f258f7c2bfc8e890963142bd\",\"venue\":\"\",\"year\":1999},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48889683\",\"name\":\"L. Almeida\"},{\"authorId\":\"1719588\",\"name\":\"T. Langlois\"},{\"authorId\":\"144393547\",\"name\":\"J. Amaral\"},{\"authorId\":\"145229875\",\"name\":\"A. Plakhov\"}],\"doi\":\"10.1017/CBO9780511569920.007\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0581236457270b6c9d0dcc9711dfdb6ef975215d\",\"title\":\"Parameter adaptation in stochastic optimization\",\"url\":\"https://www.semanticscholar.org/paper/0581236457270b6c9d0dcc9711dfdb6ef975215d\",\"venue\":\"\",\"year\":1999},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1602.04062\",\"authors\":[{\"authorId\":\"145591287\",\"name\":\"S. Hansen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"782869235b675af89e73a38a0ce209cfcdd5391b\",\"title\":\"Using Deep Q-Learning to Control Optimization Hyperparameters\",\"url\":\"https://www.semanticscholar.org/paper/782869235b675af89e73a38a0ce209cfcdd5391b\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"N. Mah-eswaranathan O. Wichrowska\"},{\"authorId\":null,\"name\":\"M. W. Hoffman\"},{\"authorId\":null,\"name\":\"S. G. Colmenarejo\"},{\"authorId\":null,\"name\":\"M. Denil\"},{\"authorId\":null,\"name\":\"N. Freitas\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"No more pesky learning rates Local gain adaptation in stochastic gradient descent\",\"url\":\"\",\"venue\":\"\",\"year\":1999},{\"arxivId\":\"1502.03492\",\"authors\":[{\"authorId\":\"1683298\",\"name\":\"D. Maclaurin\"},{\"authorId\":\"1704657\",\"name\":\"D. Duvenaud\"},{\"authorId\":\"1722180\",\"name\":\"R. Adams\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e2820bffe5b42cb7d88b7f65c12171c62ab4aae2\",\"title\":\"Gradient-based Hyperparameter Optimization through Reversible Learning\",\"url\":\"https://www.semanticscholar.org/paper/e2820bffe5b42cb7d88b7f65c12171c62ab4aae2\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1703.04782\",\"authors\":[{\"authorId\":\"1739503\",\"name\":\"Atilim Gunes Baydin\"},{\"authorId\":\"143710901\",\"name\":\"Robert Cornish\"},{\"authorId\":\"121175645\",\"name\":\"David Mart\\u00ednez-Rubio\"},{\"authorId\":\"144713192\",\"name\":\"M. Schmidt\"},{\"authorId\":\"2347189\",\"name\":\"F. Wood\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"512ca06114f5292f7d0b536ce030e319863c781a\",\"title\":\"Online Learning Rate Adaptation with Hypergradient Descent\",\"url\":\"https://www.semanticscholar.org/paper/512ca06114f5292f7d0b536ce030e319863c781a\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1905.07006\",\"authors\":[{\"authorId\":\"1987266\",\"name\":\"A. Beatson\"},{\"authorId\":\"1722180\",\"name\":\"R. Adams\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a58eb3774bba2ccdbd904bc904cdeac801490d94\",\"title\":\"Efficient Optimization of Loops and Limits with Randomized Telescoping Sums\",\"url\":\"https://www.semanticscholar.org/paper/a58eb3774bba2ccdbd904bc904cdeac801490d94\",\"venue\":\"ICML\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5886094\",\"name\":\"P. Cochat\"},{\"authorId\":\"13267685\",\"name\":\"L. Vaucoret\"},{\"authorId\":\"31455512\",\"name\":\"J. Sarles\"}],\"doi\":\"10.1016/j.arcped.2012.01.013\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"10d85561e4aafc516d10064f30dff05b41f70afe\",\"title\":\"[Et al].\",\"url\":\"https://www.semanticscholar.org/paper/10d85561e4aafc516d10064f30dff05b41f70afe\",\"venue\":\"Archives de pediatrie : organe officiel de la Societe francaise de pediatrie\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1722101\",\"name\":\"Justin Domke\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5b0a44014c24f9b584904bf223530a3b9fa9853f\",\"title\":\"Generic Methods for Optimization-Based Modeling\",\"url\":\"https://www.semanticscholar.org/paper/5b0a44014c24f9b584904bf223530a3b9fa9853f\",\"venue\":\"AISTATS\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144661829\",\"name\":\"F. Hutter\"},{\"authorId\":\"30467640\",\"name\":\"J\\u00f6rg L\\u00fccke\"},{\"authorId\":\"1388781075\",\"name\":\"L. Schmidt-Thieme\"}],\"doi\":\"10.1007/s13218-015-0381-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"16d5d586ccc5b9a9f59f55266fb48fcc9436456e\",\"title\":\"Beyond Manual Tuning of Hyperparameters\",\"url\":\"https://www.semanticscholar.org/paper/16d5d586ccc5b9a9f59f55266fb48fcc9436456e\",\"venue\":\"KI - K\\u00fcnstliche Intelligenz\",\"year\":2015},{\"arxivId\":\"1803.02021\",\"authors\":[{\"authorId\":\"3374063\",\"name\":\"Yuhuai Wu\"},{\"authorId\":\"2540599\",\"name\":\"Mengye Ren\"},{\"authorId\":\"2246396\",\"name\":\"Renjie Liao\"},{\"authorId\":\"1785346\",\"name\":\"Roger B. Grosse\"}],\"doi\":null,\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fdb26e0ab0395385bd0511359161607993d42a23\",\"title\":\"Understanding Short-Horizon Bias in Stochastic Meta-Optimization\",\"url\":\"https://www.semanticscholar.org/paper/fdb26e0ab0395385bd0511359161607993d42a23\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1602.02355\",\"authors\":[{\"authorId\":\"2570016\",\"name\":\"Fabian Pedregosa\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"66edb2a8d33db2d133d3a3c8c032a06a95c6cd3b\",\"title\":\"Hyperparameter optimization with approximate gradient\",\"url\":\"https://www.semanticscholar.org/paper/66edb2a8d33db2d133d3a3c8c032a06a95c6cd3b\",\"venue\":\"ICML\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Griewank\"},{\"authorId\":null,\"name\":\"C. Faure\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Reduced functions\",\"url\":\"\",\"venue\":\"gradients and hessians from fixed-point iterations for state equations. Numerical Algorithms, 30(2):113\\u2013139\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47327848\",\"name\":\"T. P. Vogl\"},{\"authorId\":\"5421461\",\"name\":\"J. K. Mangis\"},{\"authorId\":\"40662159\",\"name\":\"A. Rigler\"},{\"authorId\":\"33832398\",\"name\":\"W. T. Zink\"},{\"authorId\":\"3239220\",\"name\":\"D. Alkon\"}],\"doi\":\"10.1007/BF00332914\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f7472c65c41facdc3eb1729706bb0ed97a2ca031\",\"title\":\"Accelerating the convergence of the back-propagation method\",\"url\":\"https://www.semanticscholar.org/paper/f7472c65c41facdc3eb1729706bb0ed97a2ca031\",\"venue\":\"Biological Cybernetics\",\"year\":2004}],\"title\":\"MARTHE: Scheduling the Learning Rate Via Online Hypergradients.\",\"topics\":[],\"url\":\"https://www.semanticscholar.org/paper/6752cc8440dd269d1665ca16a778de0ebf12b46d\",\"venue\":\"\",\"year\":2019}\n"