"{\"abstract\":\"In ad hoc teamwork, multiple agents need to collaborate without having knowledge about their teammates or their plans a priori. A common assumption in this research area is that the agents cannot communicate. However, just as two random people may speak the same language, autonomous teammates may also happen to share a communication protocol. This paper considers how such a shared protocol can be leveraged, introducing a means to reason about Communication in Ad Hoc Teamwork (CAT). The goal of this work is enabling improved ad hoc teamwork by judiciously leveraging the ability of the team to communicate. We situate our study within a novel CAT scenario, involving tasks with multiple steps, where teammates\\u2019 plans are unveiled over time. In this context, the paper proposes methods to reason about the timing and value of communication and introduces an algorithm for an ad hoc agent to leverage these methods. Finally, we introduces a new multiagent domain, the tool fetching domain, and we study how varying this domain\\u2019s properties affects the usefulness of communication. Empirical results show the benefits of explicit reasoning about communication content and timing in ad hoc teamwork.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"3402763\",\"name\":\"Reuth Mirsky\",\"url\":\"https://www.semanticscholar.org/author/3402763\"},{\"authorId\":\"10730649\",\"name\":\"William Macke\",\"url\":\"https://www.semanticscholar.org/author/10730649\"},{\"authorId\":\"145364753\",\"name\":\"A. Wang\",\"url\":\"https://www.semanticscholar.org/author/145364753\"},{\"authorId\":\"2322246\",\"name\":\"Harel Yedidsion\",\"url\":\"https://www.semanticscholar.org/author/2322246\"},{\"authorId\":\"144848112\",\"name\":\"P. Stone\",\"url\":\"https://www.semanticscholar.org/author/144848112\"}],\"citationVelocity\":0,\"citations\":[],\"corpusId\":220483028,\"doi\":\"10.24963/ijcai.2020/36\",\"fieldsOfStudy\":[\"Psychology\",\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":false,\"paperId\":\"da83a77dc3432128534fc6aafcfb8789ebea72b5\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1701132\",\"name\":\"Munindar P. Singh\"}],\"doi\":\"10.1109/2.735849\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"51eced8e97b8463c46f5b6de505e0b33bf4ad348\",\"title\":\"Agent Communication Languages: Rethinking the Principles\",\"url\":\"https://www.semanticscholar.org/paper/51eced8e97b8463c46f5b6de505e0b33bf4ad348\",\"venue\":\"Computer\",\"year\":1998},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34517405\",\"name\":\"M. Roth\"},{\"authorId\":\"144515530\",\"name\":\"R. Simmons\"},{\"authorId\":\"1956361\",\"name\":\"M. Veloso\"}],\"doi\":\"10.1007/4-431-35881-1_18\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ecef06f2f2fd8483b269e98982e095eb8310f1f6\",\"title\":\"What to Communicate? Execution-Time Decision in Multi-agent POMDPs\",\"url\":\"https://www.semanticscholar.org/paper/ecef06f2f2fd8483b269e98982e095eb8310f1f6\",\"venue\":\"DARS\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2212554\",\"name\":\"Ofra Amir\"},{\"authorId\":\"1783184\",\"name\":\"Ece Kamar\"},{\"authorId\":\"6247481\",\"name\":\"A. Kolobov\"},{\"authorId\":\"1692242\",\"name\":\"B. Grosz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bebd4f1259a8db086faeabf05b282cb8912d44f3\",\"title\":\"Interactive Teaching Strategies for Agent Training\",\"url\":\"https://www.semanticscholar.org/paper/bebd4f1259a8db086faeabf05b282cb8912d44f3\",\"venue\":\"IJCAI\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27581584\",\"name\":\"R. Howard\"}],\"doi\":\"10.1109/TSSC.1966.300074\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a7b3c2a88ca459d50010a33db8c2f113f1323e0c\",\"title\":\"Information Value Theory\",\"url\":\"https://www.semanticscholar.org/paper/a7b3c2a88ca459d50010a33db8c2f113f1323e0c\",\"venue\":\"IEEE Trans. Syst. Sci. Cybern.\",\"year\":1966},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ryan Lowe\"},{\"authorId\":null,\"name\":\"Yi Wu\"},{\"authorId\":null,\"name\":\"Aviv Tamar\"},{\"authorId\":null,\"name\":\"Jean Harb\"},{\"authorId\":null,\"name\":\"Pieter Abbeel\"},{\"authorId\":null,\"name\":\"Igor Mordatch. Multi-agent actor-critic for mixed coope environments\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In NeurIPS\",\"url\":\"\",\"venue\":\"pages 6379\\u20136390,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Noa Agmon\"},{\"authorId\":null,\"name\":\"Peter Stone. Leading ad hoc agents in joint action setti teammates\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In AAMAS\",\"url\":\"\",\"venue\":\"pages 341\\u2013348,\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Kaushik Subramanian\"},{\"authorId\":null,\"name\":\"Charles L Isbell\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Learn - ing to communicate with deep multi - agent reinforcement learning\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151196985\",\"name\":\"Rose E. Wang\"},{\"authorId\":\"47403408\",\"name\":\"Sarah A. Wu\"},{\"authorId\":\"144002439\",\"name\":\"James A. Evans\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"},{\"authorId\":\"30907562\",\"name\":\"D. Parkes\"},{\"authorId\":\"1390033240\",\"name\":\"Max Kleiman-Weiner\"}],\"doi\":\"10.5555/3398761.3399065\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"893e14a5db75f7488a949707007caf5c1efc339b\",\"title\":\"Too many cooks: Coordinating multi-agent collaboration through inverse planning\",\"url\":\"https://www.semanticscholar.org/paper/893e14a5db75f7488a949707007caf5c1efc339b\",\"venue\":\"AAMAS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jakob Foerster\"},{\"authorId\":null,\"name\":\"Ioannis Alexandros Assael\"},{\"authorId\":null,\"name\":\"Nando de Freitas\"},{\"authorId\":null,\"name\":\"Shimon Whiteson. Learning to communicate with deep multi- learning\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In NIPS\",\"url\":\"\",\"venue\":\"pages 2137\\u20132145,\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Arkady Epshteyn\"},{\"authorId\":null,\"name\":\"Adam Vogel\"},{\"authorId\":null,\"name\":\"Gerald DeJong. Active reinforcement learning. In Proceedi ICML\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"pages 296\\u2013303\",\"url\":\"\",\"venue\":\"ACM,\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Charles L Isbell\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Learn - ing to communicate with deep multi - agent reinforcement learning\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1400326437\",\"name\":\"Pablo Hernandez-Leal\"},{\"authorId\":\"35224631\",\"name\":\"Bilal Kartal\"},{\"authorId\":\"39286677\",\"name\":\"Matthew E. Taylor\"}],\"doi\":\"10.1007/s10458-019-09421-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"390364c3986d05ad71a40a967b9cc12aa30e4305\",\"title\":\"A survey and critique of multiagent deep reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/390364c3986d05ad71a40a967b9cc12aa30e4305\",\"venue\":\"Autonomous Agents and Multi-Agent Systems\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145841336\",\"name\":\"A. Fern\"},{\"authorId\":\"145986014\",\"name\":\"Sriraam Natarajan\"},{\"authorId\":\"1719050\",\"name\":\"Kshitij Judah\"},{\"authorId\":\"1729906\",\"name\":\"P. Tadepalli\"}],\"doi\":\"10.1613/jair.4213\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c7cc33f1fdcd7fd3d72a3aceca793c3e35dd148b\",\"title\":\"A Decision-Theoretic Model of Assistance\",\"url\":\"https://www.semanticscholar.org/paper/c7cc33f1fdcd7fd3d72a3aceca793c3e35dd148b\",\"venue\":\"IJCAI\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151483280\",\"name\":\"Manish Ravula\"},{\"authorId\":\"1729718\",\"name\":\"Shani Alkoby\"},{\"authorId\":\"144848112\",\"name\":\"P. Stone\"}],\"doi\":\"10.24963/ijcai.2019/78\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"01bd3a7408eb417f16961f3ab5c0165fecc50629\",\"title\":\"Ad Hoc Teamwork With Behavior Switching Agents\",\"url\":\"https://www.semanticscholar.org/paper/01bd3a7408eb417f16961f3ab5c0165fecc50629\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"1706.02275\",\"authors\":[{\"authorId\":\"2054294\",\"name\":\"Ryan Lowe\"},{\"authorId\":\"31613801\",\"name\":\"Yi Wu\"},{\"authorId\":\"3025260\",\"name\":\"A. Tamar\"},{\"authorId\":\"40638357\",\"name\":\"J. Harb\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"},{\"authorId\":\"2080746\",\"name\":\"Igor Mordatch\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7c3ece1ba41c415d7e81cfa5ca33a8de66efd434\",\"title\":\"Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments\",\"url\":\"https://www.semanticscholar.org/paper/7c3ece1ba41c415d7e81cfa5ca33a8de66efd434\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1703.04908\",\"authors\":[{\"authorId\":\"2080746\",\"name\":\"Igor Mordatch\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5d2f5c2dc11c18c0d45203e2b980fe375a56d774\",\"title\":\"Emergence of Grounded Compositional Language in Multi-Agent Populations\",\"url\":\"https://www.semanticscholar.org/paper/5d2f5c2dc11c18c0d45203e2b980fe375a56d774\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Samuel Barrett\"},{\"authorId\":null,\"name\":\"Noa Agmon\"},{\"authorId\":null,\"name\":\"Noam Hazon\"},{\"authorId\":null,\"name\":\"Sarit Kraus\"},{\"authorId\":null,\"name\":\"Peter Stone. Communicating with unknown teammates\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In AAMAS\",\"url\":\"\",\"venue\":\"pages 1433\\u20131434,\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3402763\",\"name\":\"Reuth Mirsky\"},{\"authorId\":\"37300633\",\"name\":\"R. Stern\"},{\"authorId\":\"1721094\",\"name\":\"Y. Gal\"},{\"authorId\":\"1790492\",\"name\":\"Meir Kalech\"}],\"doi\":\"10.1016/j.artint.2018.03.006\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a1270763b10ccd62a1f3c89b82db7565806e8885\",\"title\":\"Sequential plan recognition: An iterative approach to disambiguating between hypotheses\",\"url\":\"https://www.semanticscholar.org/paper/a1270763b10ccd62a1f3c89b82db7565806e8885\",\"venue\":\"Artif. Intell.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Stefano V Albrecht\"},{\"authorId\":null,\"name\":\"Peter Stone. Reasoning about hypothetical agent behaviours\"},{\"authorId\":null,\"name\":\"their parameters\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In AAMAS\",\"url\":\"\",\"venue\":\"pages 547\\u2013555,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Sergey Levine\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Coordinated vs . decentralized exploration in multi - agent multi - armed bandits\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1910.14033\",\"authors\":[{\"authorId\":\"144373380\",\"name\":\"C. Devin\"},{\"authorId\":\"1381359648\",\"name\":\"Daniel Geng\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"56c4712402e94ca770206b6a383b569f3ccf7809\",\"title\":\"Plan Arithmetic: Compositional Plan Vectors for Multi-Task Control\",\"url\":\"https://www.semanticscholar.org/paper/56c4712402e94ca770206b6a383b569f3ccf7809\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8776500\",\"name\":\"Masoumeh Heidari Kapourchali\"},{\"authorId\":\"2558152\",\"name\":\"B. Banerjee\"}],\"doi\":\"10.1109/TETCI.2019.2901540\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"57f216960d94f0d947d42bdb9cfc0950331c6c59\",\"title\":\"State Estimation via Communication for Monitoring\",\"url\":\"https://www.semanticscholar.org/paper/57f216960d94f0d947d42bdb9cfc0950331c6c59\",\"venue\":\"IEEE Transactions on Emerging Topics in Computational Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Pablo Hernandez-Leal\"},{\"authorId\":null,\"name\":\"Bilal Kartal\"},{\"authorId\":null,\"name\":\"Matthew E Taylor. A survey\"},{\"authorId\":null,\"name\":\"critique of multiagent deep reinforcement learning\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"AAMAS\",\"url\":\"\",\"venue\":\"pages 1\\u201348,\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1690271\",\"name\":\"Henry A. Kautz\"},{\"authorId\":\"145844737\",\"name\":\"James F. Allen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"adc713f0787f9fdef701d63615acd4aad61165a6\",\"title\":\"Generalized Plan Recognition\",\"url\":\"https://www.semanticscholar.org/paper/adc713f0787f9fdef701d63615acd4aad61165a6\",\"venue\":\"AAAI\",\"year\":1986},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35096370\",\"name\":\"M. Cakmak\"},{\"authorId\":\"1682788\",\"name\":\"A. Thomaz\"}],\"doi\":\"10.1145/2157689.2157693\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a0ec28b9c8267b7f72eb5da5313139f89ebd92d\",\"title\":\"Designing robot learners that ask good questions\",\"url\":\"https://www.semanticscholar.org/paper/8a0ec28b9c8267b7f72eb5da5313139f89ebd92d\",\"venue\":\"2012 7th ACM/IEEE International Conference on Human-Robot Interaction (HRI)\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3228082\",\"name\":\"Shane Griffith\"},{\"authorId\":\"145362925\",\"name\":\"K. Subramanian\"},{\"authorId\":\"36881095\",\"name\":\"Jonathan Scholz\"},{\"authorId\":\"1787816\",\"name\":\"C. Isbell\"},{\"authorId\":\"1682788\",\"name\":\"A. Thomaz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a7c31b6203949bd8ee6db0ebd4e075b980e9569f\",\"title\":\"Policy Shaping: Integrating Human Feedback with Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/a7c31b6203949bd8ee6db0ebd4e075b980e9569f\",\"venue\":\"NIPS\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2775403\",\"name\":\"F. Bisson\"},{\"authorId\":\"2132916\",\"name\":\"F. Kabanza\"},{\"authorId\":\"3152463\",\"name\":\"A. Benaskeur\"},{\"authorId\":\"2791845\",\"name\":\"H. Irandoust\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"8b7bce2721058e579e014f9aa3b65ae66885966f\",\"title\":\"Provoking Opponents to Facilitate the Recognition of their Intentions\",\"url\":\"https://www.semanticscholar.org/paper/8b7bce2721058e579e014f9aa3b65ae66885966f\",\"venue\":\"AAAI\",\"year\":2011},{\"arxivId\":\"1802.06137\",\"authors\":[{\"authorId\":\"3387360\",\"name\":\"Anagha Kulkarni\"},{\"authorId\":\"145305735\",\"name\":\"Siddharth Srivastava\"},{\"authorId\":\"1740315\",\"name\":\"S. Kambhampati\"}],\"doi\":\"10.1609/aaai.v33i01.33012479\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"172be784036615c4f9b2ed5aca4f8ad79f86a324\",\"title\":\"A Unified Framework for Planning in Adversarial and Cooperative Environments\",\"url\":\"https://www.semanticscholar.org/paper/172be784036615c4f9b2ed5aca4f8ad79f86a324\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Mithun Chakraborty\"},{\"authorId\":null,\"name\":\"Kai Yee Phoebe Chua\"},{\"authorId\":null,\"name\":\"Sanmay Das\"},{\"authorId\":null,\"name\":\"Brendan Juba. Coordinated vs. decentralized exploration in bandits\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In IJCAI\",\"url\":\"\",\"venue\":\"pages 164\\u2013170,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1898340\",\"name\":\"Sarah Keren\"},{\"authorId\":\"70189402\",\"name\":\"A. Gal\"},{\"authorId\":\"1944465\",\"name\":\"Erez Karpas\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e28fbb7e30ea5a2e104cdd6d02ae6e4295628a3a\",\"title\":\"Goal Recognition Design\",\"url\":\"https://www.semanticscholar.org/paper/e28fbb7e30ea5a2e104cdd6d02ae6e4295628a3a\",\"venue\":\"ICAPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1801209\",\"name\":\"Lisa Torrey\"},{\"authorId\":\"39286677\",\"name\":\"Matthew E. Taylor\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"902fccdc900a06246ee0f3f1ee7b58b68ca41916\",\"title\":\"Teaching on a budget: agents advising agents in reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/902fccdc900a06246ee0f3f1ee7b58b68ca41916\",\"venue\":\"AAMAS\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144848112\",\"name\":\"P. Stone\"},{\"authorId\":\"1725049\",\"name\":\"G. Kaminka\"},{\"authorId\":\"144992450\",\"name\":\"S. Kraus\"},{\"authorId\":\"1735970\",\"name\":\"J. S. Rosenschein\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e4996547720f4801eca284a3c3dfa7943cd08ecf\",\"title\":\"Ad Hoc Autonomous Agent Teams: Collaboration without Pre-Coordination\",\"url\":\"https://www.semanticscholar.org/paper/e4996547720f4801eca284a3c3dfa7943cd08ecf\",\"venue\":\"AAAI\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Alan Fern\"},{\"authorId\":null,\"name\":\"Sriraam Natarajan\"},{\"authorId\":null,\"name\":\"Kshitij Judah\"},{\"authorId\":null,\"name\":\"Prasad Tadepalli. A decision-theoretic model of assistance\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In IJCAI\",\"url\":\"\",\"venue\":\"pages 1879\\u20131884,\",\"year\":2007},{\"arxivId\":\"1909.11173\",\"authors\":[{\"authorId\":\"34903901\",\"name\":\"Chris Amato\"},{\"authorId\":\"2276470\",\"name\":\"Andrea Baisero\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8823915dc49713b168b532342b5eefd288bc5510\",\"title\":\"Active Goal Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8823915dc49713b168b532342b5eefd288bc5510\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1709.08071\",\"authors\":[{\"authorId\":\"1961238\",\"name\":\"Stefano V. Albrecht\"},{\"authorId\":\"144848112\",\"name\":\"P. Stone\"}],\"doi\":\"10.1016/j.artint.2018.01.002\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9bf2d6526b480f95fed9b0e0a1125cf07d11e01d\",\"title\":\"Autonomous agents modelling other agents: A comprehensive survey and open problems\",\"url\":\"https://www.semanticscholar.org/paper/9bf2d6526b480f95fed9b0e0a1125cf07d11e01d\",\"venue\":\"Artif. Intell.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144848112\",\"name\":\"P. Stone\"},{\"authorId\":\"1725049\",\"name\":\"G. Kaminka\"},{\"authorId\":\"144992450\",\"name\":\"S. Kraus\"},{\"authorId\":\"1735970\",\"name\":\"J. S. Rosenschein\"},{\"authorId\":\"2442305\",\"name\":\"N. Agmon\"}],\"doi\":\"10.1016/j.artint.2013.07.003\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8b632a11301b5f009b05a24ed6045bf2ff780673\",\"title\":\"Teaching and leading an ad hoc teammate: Collaboration without pre-coordination\",\"url\":\"https://www.semanticscholar.org/paper/8b632a11301b5f009b05a24ed6045bf2ff780673\",\"venue\":\"Artif. Intell.\",\"year\":2013}],\"title\":\"A Penny for Your Thoughts: The Value of Communication in Ad Hoc Teamwork\",\"topics\":[{\"topic\":\"Hoc (programming language)\",\"topicId\":\"3446\",\"url\":\"https://www.semanticscholar.org/topic/3446\"}],\"url\":\"https://www.semanticscholar.org/paper/da83a77dc3432128534fc6aafcfb8789ebea72b5\",\"venue\":\"IJCAI\",\"year\":2020}\n"