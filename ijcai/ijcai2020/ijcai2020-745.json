"{\"abstract\":\"Preliminary experiments in this dissertation show that it is possible to factorize specific types of information from the speech signal in an abstract embedding space using machine learning. This information includes characteristics of the recording environment, speaking style, and speech quality. Based on these findings, a new technique is proposed to factorize multiple types of information from the speech signal simultaneously using a combination of state-of-the-art machine learning methods for speech processing. Successful speech signal factorization will lead to advances across many speech technologies, including improved speaker identification, detection of speech audio deep fakes, and controllable expression in speech synthesis.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"78475838\",\"name\":\"J. Williams\",\"url\":\"https://www.semanticscholar.org/author/78475838\"}],\"citationVelocity\":0,\"citations\":[],\"corpusId\":220483531,\"doi\":\"10.24963/ijcai.2020/746\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":false,\"is_publisher_licensed\":false,\"paperId\":\"d872ed6bf64c77ff396b505bf48ab0a53e51dbc8\",\"references\":[{\"arxivId\":\"1802.08435\",\"authors\":[{\"authorId\":\"2583391\",\"name\":\"Nal Kalchbrenner\"},{\"authorId\":\"152585800\",\"name\":\"E. Elsen\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"30155667\",\"name\":\"Seb Noury\"},{\"authorId\":\"2670752\",\"name\":\"Norman Casagrande\"},{\"authorId\":\"49860549\",\"name\":\"Edward Lockhart\"},{\"authorId\":\"3205302\",\"name\":\"Florian Stimberg\"},{\"authorId\":\"3422336\",\"name\":\"A. Oord\"},{\"authorId\":\"48373216\",\"name\":\"S. Dieleman\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f2c882fd290d616ff96c1c5d6af4578682e26556\",\"title\":\"Efficient Neural Audio Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/f2c882fd290d616ff96c1c5d6af4578682e26556\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4828665\",\"name\":\"X. Wang\"},{\"authorId\":\"2880708\",\"name\":\"Shinji Takaki\"},{\"authorId\":\"1716857\",\"name\":\"J. Yamagishi\"},{\"authorId\":\"70465597\",\"name\":\"S. King\"},{\"authorId\":\"152920407\",\"name\":\"K. Tokuda\"}],\"doi\":\"10.1109/TASLP.2019.2950099\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"968379e8dd6638b15519be82652a2273531ebf2f\",\"title\":\"A Vector Quantized Variational Autoencoder (VQ-VAE) Autoregressive Neural $F_0$ Model for Statistical Parametric Speech Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/968379e8dd6638b15519be82652a2273531ebf2f\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Williams\"},{\"authorId\":null,\"name\":\"Rownicka\"},{\"authorId\":null,\"name\":\"2019 Jennifer Williams\"},{\"authorId\":null,\"name\":\"Joanna\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Rownicka. Speech replay detection with xvector attack embeddings and spectral features\",\"url\":\"\",\"venue\":\"Proc. Interspeech\",\"year\":2019},{\"arxivId\":\"1909.06351\",\"authors\":[{\"authorId\":\"34549139\",\"name\":\"Desh Raj\"},{\"authorId\":\"46974929\",\"name\":\"D. Snyder\"},{\"authorId\":\"47652202\",\"name\":\"D. Povey\"},{\"authorId\":\"2803071\",\"name\":\"S. Khudanpur\"}],\"doi\":\"10.1109/ASRU46091.2019.9003979\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aa09783c7620e42f5d827c55b3f02a4d2cfe3c5e\",\"title\":\"Probing the Information Encoded in X-Vectors\",\"url\":\"https://www.semanticscholar.org/paper/aa09783c7620e42f5d827c55b3f02a4d2cfe3c5e\",\"venue\":\"2019 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"78475838\",\"name\":\"J. Williams\"},{\"authorId\":\"70465597\",\"name\":\"S. King\"}],\"doi\":\"10.21437/interspeech.2019-1769\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"57e41198769e171a6863c737093b010bd912dcd3\",\"title\":\"Disentangling Style Factors from Speaker Representations\",\"url\":\"https://www.semanticscholar.org/paper/57e41198769e171a6863c737093b010bd912dcd3\",\"venue\":\"INTERSPEECH\",\"year\":2019},{\"arxivId\":\"1808.06670\",\"authors\":[{\"authorId\":\"40482726\",\"name\":\"R. Devon Hjelm\"},{\"authorId\":\"26920432\",\"name\":\"A. Fedorov\"},{\"authorId\":\"1412884705\",\"name\":\"Samuel Lavoie-Marchildon\"},{\"authorId\":\"14007973\",\"name\":\"Karan Grewal\"},{\"authorId\":\"3382568\",\"name\":\"Adam Trischler\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"eae7d5b15423a148e6bb32d24bbabedfacd0e2df\",\"title\":\"Learning deep representations by mutual information estimation and maximization\",\"url\":\"https://www.semanticscholar.org/paper/eae7d5b15423a148e6bb32d24bbabedfacd0e2df\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51267247\",\"name\":\"Shaojin Ding\"},{\"authorId\":\"1389225550\",\"name\":\"R. Gutierrez-Osuna\"}],\"doi\":\"10.21437/interspeech.2019-1198\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d2f7e74336baddc6e5e1ac607ad3e33cb24068bd\",\"title\":\"Group Latent Embedding for Vector Quantized Variational Autoencoder in Non-Parallel Voice Conversion\",\"url\":\"https://www.semanticscholar.org/paper/d2f7e74336baddc6e5e1ac607ad3e33cb24068bd\",\"venue\":\"INTERSPEECH\",\"year\":2019},{\"arxivId\":\"1711.00937\",\"authors\":[{\"authorId\":\"3422336\",\"name\":\"A. Oord\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f466157848d1a7772fb6d02cdac9a7a5e7ef982e\",\"title\":\"Neural Discrete Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/f466157848d1a7772fb6d02cdac9a7a5e7ef982e\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"2002.12645\",\"authors\":[{\"authorId\":\"78475838\",\"name\":\"J. Williams\"},{\"authorId\":\"49778844\",\"name\":\"J. Rownicka\"},{\"authorId\":\"32722293\",\"name\":\"Pilar Oplustil\"},{\"authorId\":\"96378082\",\"name\":\"S. King\"}],\"doi\":\"10.21437/odyssey.2020-32\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9544900245d06911a953593500c74f5a2f9df4ba\",\"title\":\"Comparison of Speech Representations for Automatic Quality Estimation in Multi-Speaker Text-to-Speech Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/9544900245d06911a953593500c74f5a2f9df4ba\",\"venue\":\"ArXiv\",\"year\":2020}],\"title\":\"End-to-End Signal Factorization for Speech: Identity, Content, and Style\",\"topics\":[],\"url\":\"https://www.semanticscholar.org/paper/d872ed6bf64c77ff396b505bf48ab0a53e51dbc8\",\"venue\":\"IJCAI\",\"year\":2020}\n"