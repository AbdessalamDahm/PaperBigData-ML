"{\"abstract\":\"Video retrieval is a challenging research topic bridging the vision and language areas and has attracted broad attention in recent years. Previous works have been devoted to representing videos by directly encoding from frame-level features. In fact, videos consist of various and abundant semantic relations to which existing methods pay less attention. To address this issue, we propose a Visual Semantic Enhanced Reasoning Network (ViSERN) to exploit reasoning between frame regions. Specifically, we consider frame regions as vertices and construct a fully-connected semantic correlation graph. Then, we perform reasoning by novel random walk rule-based graph convolutional networks to generate region features involved with semantic relations. With the benefit of reasoning, semantic interactions between regions are considered, while the impact of redundancy is suppressed. Finally, the region features are aggregated to form frame-level features for further encoding to measure video-text similarity. Extensive experiments on two public benchmark datasets validate the effectiveness of our method by achieving state-of-the-art performance due to the powerful semantic reasoning.\",\"arxivId\":\"2006.08889\",\"authors\":[{\"authorId\":\"1751482331\",\"name\":\"Zerun Feng\",\"url\":\"https://www.semanticscholar.org/author/1751482331\"},{\"authorId\":\"7801828\",\"name\":\"Zhimin Zeng\",\"url\":\"https://www.semanticscholar.org/author/7801828\"},{\"authorId\":\"47932273\",\"name\":\"Caili Guo\",\"url\":\"https://www.semanticscholar.org/author/47932273\"},{\"authorId\":\"2123874\",\"name\":\"Z. Li\",\"url\":\"https://www.semanticscholar.org/author/2123874\"}],\"citationVelocity\":0,\"citations\":[],\"corpusId\":219708171,\"doi\":\"10.24963/ijcai.2020/140\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"1ab464a59bbe790ffa33d028d72b3a20cfe89d9f\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jianfeng Dong\"},{\"authorId\":null,\"name\":\"Xirong Li\"},{\"authorId\":null,\"name\":\"Chaoxi Xu\"},{\"authorId\":null,\"name\":\"Shouling Ji\"},{\"authorId\":null,\"name\":\"Yuan He\"},{\"authorId\":null,\"name\":\"Gang Yang\"},{\"authorId\":null,\"name\":\"Xun Wang. Dual encoding for zero-example video retrieval\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In CVPR\",\"url\":\"\",\"venue\":\"pages 9346\\u20139355,\",\"year\":2019},{\"arxivId\":\"1607.00653\",\"authors\":[{\"authorId\":\"1954250\",\"name\":\"Aditya Grover\"},{\"authorId\":\"1702139\",\"name\":\"J. Leskovec\"}],\"doi\":\"10.1145/2939672.2939754\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"36ee2c8bd605afd48035d15fdc6b8c8842363376\",\"title\":\"node2vec: Scalable Feature Learning for Networks\",\"url\":\"https://www.semanticscholar.org/paper/36ee2c8bd605afd48035d15fdc6b8c8842363376\",\"venue\":\"KDD\",\"year\":2016},{\"arxivId\":\"1312.6203\",\"authors\":[{\"authorId\":\"143627859\",\"name\":\"Joan Bruna\"},{\"authorId\":\"2563432\",\"name\":\"W. Zaremba\"},{\"authorId\":\"3149531\",\"name\":\"Arthur Szlam\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5e925a9f1e20df61d1e860a7aa71894b35a1c186\",\"title\":\"Spectral Networks and Locally Connected Networks on Graphs\",\"url\":\"https://www.semanticscholar.org/paper/5e925a9f1e20df61d1e860a7aa71894b35a1c186\",\"venue\":\"ICLR\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2623871\",\"name\":\"Xinchen Liu\"},{\"authorId\":\"144973314\",\"name\":\"Wu Liu\"},{\"authorId\":\"39982497\",\"name\":\"Meng Zhang\"},{\"authorId\":null,\"name\":\"Jingwen Chen\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"3863922\",\"name\":\"C. Yan\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2019.00368\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bdb5450be3a192034c989a0dbeaa24bccc4903ab\",\"title\":\"Social Relation Recognition From Videos via Multi-Scale Spatial-Temporal Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/bdb5450be3a192034c989a0dbeaa24bccc4903ab\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1909.02701\",\"authors\":[{\"authorId\":\"49243413\",\"name\":\"Kunpeng Li\"},{\"authorId\":\"2410227\",\"name\":\"Yulun Zhang\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"47003439\",\"name\":\"Yuanyuan Li\"},{\"authorId\":\"46956675\",\"name\":\"Yun Fu\"}],\"doi\":\"10.1109/ICCV.2019.00475\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"26500af6bb97bf2dab1cc14dfb3b8b08fef67940\",\"title\":\"Visual Semantic Reasoning for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/26500af6bb97bf2dab1cc14dfb3b8b08fef67940\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1727849\",\"name\":\"S. Hanson\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"69d7086300e7f5322c06f2f242a565b3a182efb5\",\"title\":\"In Advances in Neural Information Processing Systems\",\"url\":\"https://www.semanticscholar.org/paper/69d7086300e7f5322c06f2f242a565b3a182efb5\",\"venue\":\"NIPS 1990\",\"year\":1990},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Kunpeng Li\"},{\"authorId\":null,\"name\":\"Yulun Zhang\"},{\"authorId\":null,\"name\":\"Kai Li\"},{\"authorId\":null,\"name\":\"Yuanyuan Li\"},{\"authorId\":null,\"name\":\"Yun Fu. Visual semantic reasoning for image-text matching\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In Proceedings of the IEEE International Conference on Computer Vision\",\"url\":\"\",\"venue\":\"pages 4654\\u20134662,\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Kaiming He\"},{\"authorId\":null,\"name\":\"Xiangyu Zhang\"},{\"authorId\":null,\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun. Deep residual learning for image recognition\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In Proceedings of the IEEE conference on computer vision and pattern recognition\",\"url\":\"\",\"venue\":\"pages 770\\u2013778,\",\"year\":2016},{\"arxivId\":\"1403.6652\",\"authors\":[{\"authorId\":\"2271808\",\"name\":\"Bryan Perozzi\"},{\"authorId\":\"1388360943\",\"name\":\"Rami Al-Rfou\"},{\"authorId\":\"1721948\",\"name\":\"S. Skiena\"}],\"doi\":\"10.1145/2623330.2623732\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fff114cbba4f3ba900f33da574283e3de7f26c83\",\"title\":\"DeepWalk: online learning of social representations\",\"url\":\"https://www.semanticscholar.org/paper/fff114cbba4f3ba900f33da574283e3de7f26c83\",\"venue\":\"KDD\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153642390\",\"name\":\"David L. Chen\"},{\"authorId\":\"83415753\",\"name\":\"W. Dolan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"554a31ce91189cf6022ac677413ef2f8b9b40ca7\",\"title\":\"Collecting Highly Parallel Data for Paraphrase Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/554a31ce91189cf6022ac677413ef2f8b9b40ca7\",\"venue\":\"ACL 2011\",\"year\":2011},{\"arxivId\":\"1707.07998\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"31790073\",\"name\":\"C. Buehler\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":\"10.1109/CVPR.2018.00636\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"title\":\"Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Niluthpol Chowdhury Mithun\"},{\"authorId\":null,\"name\":\"Juncheng Li\"},{\"authorId\":null,\"name\":\"Florian Metze\"},{\"authorId\":null,\"name\":\"Amit K Roy-Chowdhury. Learning joint embedding with mul retrieval\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In ICMR\",\"url\":\"\",\"venue\":\"pages 19\\u201327,\",\"year\":2018},{\"arxivId\":\"1411.2539\",\"authors\":[{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2e36ea91a3c8fbff92be2989325531b4002e2afc\",\"title\":\"Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models\",\"url\":\"https://www.semanticscholar.org/paper/2e36ea91a3c8fbff92be2989325531b4002e2afc\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"N Thomas\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Kipf and Max Welling\",\"url\":\"\",\"venue\":\"Semi-supervised classification with graph convolutional networks.\",\"year\":2017},{\"arxivId\":\"1506.01497\",\"authors\":[{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"144716314\",\"name\":\"J. Sun\"}],\"doi\":\"10.1109/TPAMI.2016.2577031\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"title\":\"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\",\"url\":\"https://www.semanticscholar.org/paper/424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1845331\",\"name\":\"M. Ehler\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9fd41b7f550c9fd1569a26911ad9348b7698b2f7\",\"title\":\"Applied and Computational Harmonic Analysis\",\"url\":\"https://www.semanticscholar.org/paper/9fd41b7f550c9fd1569a26911ad9348b7698b2f7\",\"venue\":\"\",\"year\":2008},{\"arxivId\":\"1602.07332\",\"authors\":[{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"50499889\",\"name\":\"O. Groth\"},{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"1382195702\",\"name\":\"Kenji Hata\"},{\"authorId\":\"40591424\",\"name\":\"J. Kravitz\"},{\"authorId\":\"6000646\",\"name\":\"Stephanie Chen\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"1388344504\",\"name\":\"David A. Shamma\"},{\"authorId\":\"1379506718\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-016-0981-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"title\":\"Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations\",\"url\":\"https://www.semanticscholar.org/paper/afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Fumi Katsuki\"},{\"authorId\":null,\"name\":\"Christos Constantinidis\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Bottom-up and top-down attention: different processes and overlapping neural systems\",\"url\":\"\",\"venue\":\"The Neuroscientist, 20(5):509\\u2013521,\",\"year\":2014},{\"arxivId\":\"1809.06181\",\"authors\":[{\"authorId\":\"40240283\",\"name\":\"J. Dong\"},{\"authorId\":\"9931285\",\"name\":\"Xirong Li\"},{\"authorId\":\"46200183\",\"name\":\"Chaoxi Xu\"},{\"authorId\":\"134724966\",\"name\":\"Shouling Ji\"},{\"authorId\":\"143605211\",\"name\":\"Yuan He\"},{\"authorId\":\"98289428\",\"name\":\"G. Yang\"},{\"authorId\":\"39742349\",\"name\":\"X. Wang\"}],\"doi\":\"10.1109/CVPR.2019.00957\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6a976c123037b138946f6767e1aa0de84b1682d4\",\"title\":\"Dual Encoding for Zero-Example Video Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/6a976c123037b138946f6767e1aa0de84b1682d4\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47931517\",\"name\":\"Mudassar Abbas\"},{\"authorId\":\"6245351\",\"name\":\"J. Kivinen\"},{\"authorId\":\"2785022\",\"name\":\"T. Raiko\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f1aeb751d9cefc9d784d8862562f5a3fe15821ae\",\"title\":\"International Conference on Learning Representations (ICLR)\",\"url\":\"https://www.semanticscholar.org/paper/f1aeb751d9cefc9d784d8862562f5a3fe15821ae\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1761691\",\"name\":\"F. Tasse\"},{\"authorId\":\"2377695\",\"name\":\"J. Kosinka\"},{\"authorId\":\"1743917\",\"name\":\"N. Dodgson\"}],\"doi\":\"10.1109/ICCV.2003.1238306\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"34d7ae9e74ea1531b8409f695f0e22f98fc68db4\",\"title\":\"Proceedings Ninth IEEE International Conference on Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/34d7ae9e74ea1531b8409f695f0e22f98fc68db4\",\"venue\":\"Proceedings Ninth IEEE International Conference on Computer Vision\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jianfeng Dong\"},{\"authorId\":null,\"name\":\"Xirong Li\"},{\"authorId\":null,\"name\":\"Cees GM Snoek. Predicting visual features from text for image\"},{\"authorId\":null,\"name\":\"video caption retrieval\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"TMM\",\"url\":\"\",\"venue\":\"20(12):3377\\u20133388,\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145971173\",\"name\":\"J. Xu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/CVPR.2016.571\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b8e2e9f3ba008e28257195ec69a00e07f260131d\",\"title\":\"MSR-VTT: A Large Video Description Dataset for Bridging Video and Language\",\"url\":\"https://www.semanticscholar.org/paper/b8e2e9f3ba008e28257195ec69a00e07f260131d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2978170\",\"name\":\"Fartash Faghri\"},{\"authorId\":\"1793739\",\"name\":\"David J. Fleet\"},{\"authorId\":\"51131802\",\"name\":\"J. Kiros\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f7ab6c52be9351ac3f6cf8fe6ad5efba1c1595e8\",\"title\":\"VSE++: Improving Visual-Semantic Embeddings with Hard Negatives\",\"url\":\"https://www.semanticscholar.org/paper/f7ab6c52be9351ac3f6cf8fe6ad5efba1c1595e8\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2376144\",\"name\":\"Krzysztof J Geras\"},{\"authorId\":\"37210858\",\"name\":\"Charles Sutton\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cee21e6d84e43f3932f29b54fab65efca8c2610d\",\"title\":\"International Conference on Learning Representations (ICLR) 2015\",\"url\":\"https://www.semanticscholar.org/paper/cee21e6d84e43f3932f29b54fab65efca8c2610d\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47139824\",\"name\":\"A. Fitzgibbon\"},{\"authorId\":\"1742208\",\"name\":\"M. Pollefeys\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"19d6e925ed9643c28981edd233d074b6e3a793c6\",\"title\":\"European conference on computer vision (ECCV)\",\"url\":\"https://www.semanticscholar.org/paper/19d6e925ed9643c28981edd233d074b6e3a793c6\",\"venue\":\"eccv 2006\",\"year\":2006},{\"arxivId\":\"1706.03762\",\"authors\":[{\"authorId\":\"40348417\",\"name\":\"Ashish Vaswani\"},{\"authorId\":\"1846258\",\"name\":\"Noam Shazeer\"},{\"authorId\":\"3877127\",\"name\":\"Niki Parmar\"},{\"authorId\":\"39328010\",\"name\":\"Jakob Uszkoreit\"},{\"authorId\":\"145024664\",\"name\":\"Llion Jones\"},{\"authorId\":\"19177000\",\"name\":\"Aidan N. Gomez\"},{\"authorId\":\"40527594\",\"name\":\"L. Kaiser\"},{\"authorId\":\"3443442\",\"name\":\"Illia Polosukhin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"204e3073870fae3d05bcbc2f6a8e263d9b72e776\",\"title\":\"Attention is All you Need\",\"url\":\"https://www.semanticscholar.org/paper/204e3073870fae3d05bcbc2f6a8e263d9b72e776\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1806.01810\",\"authors\":[{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1007/978-3-030-01228-1_25\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d7cbf2d3ea63d97b699cc04af98fea521459ee75\",\"title\":\"Videos as Space-Time Region Graphs\",\"url\":\"https://www.semanticscholar.org/paper/d7cbf2d3ea63d97b699cc04af98fea521459ee75\",\"venue\":\"ECCV\",\"year\":2018}],\"title\":\"Exploiting Visual Semantic Reasoning for Video-Text Retrieval\",\"topics\":[{\"topic\":\"Interaction\",\"topicId\":\"72\",\"url\":\"https://www.semanticscholar.org/topic/72\"},{\"topic\":\"Logic programming\",\"topicId\":\"6032\",\"url\":\"https://www.semanticscholar.org/topic/6032\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"},{\"topic\":\"Bridging (networking)\",\"topicId\":\"46048\",\"url\":\"https://www.semanticscholar.org/topic/46048\"},{\"topic\":\"Document retrieval\",\"topicId\":\"14824\",\"url\":\"https://www.semanticscholar.org/topic/14824\"}],\"url\":\"https://www.semanticscholar.org/paper/1ab464a59bbe790ffa33d028d72b3a20cfe89d9f\",\"venue\":\"IJCAI\",\"year\":2020}\n"