"{\"abstract\":\"The problem of grounding language in vision is increasingly attracting scholarly efforts. As of now, however, most of the approaches have been limited to word embeddings, which are not capable of handling polysemous words. This is mainly due to the limited coverage of the available semanticallyannotated datasets, hence forcing research to rely on alternative technologies (i.e., image search engines). To address this issue, we introduce EViLBERT, an approach which is able to perform image classification over an open set of concepts, both concrete and non-concrete. Our approach is based on the recently introduced Vision-Language Pretraining (VLP) model, and builds upon a manuallyannotated dataset of concept-image pairs. We use our technique to clean up the image-to-concept mapping that is provided within a multilingual knowledge base, resulting in over 258,000 images associated with 42,500 concepts. We show that our VLP-based model can be used to create multimodal sense embeddings starting from our automaticallycreated dataset. In turn, we also show that these multimodal embeddings improve the performance of a Word Sense Disambiguation architecture over a strong unimodal baseline. We release code, dataset and embeddings at http://babelpic.org.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"1490966079\",\"name\":\"A. Calabrese\",\"url\":\"https://www.semanticscholar.org/author/1490966079\"},{\"authorId\":\"143802044\",\"name\":\"Michele Bevilacqua\",\"url\":\"https://www.semanticscholar.org/author/143802044\"},{\"authorId\":\"1733928\",\"name\":\"R. Navigli\",\"url\":\"https://www.semanticscholar.org/author/1733928\"}],\"citationVelocity\":0,\"citations\":[],\"corpusId\":220484583,\"doi\":\"10.24963/ijcai.2020/67\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":false,\"paperId\":\"366c3f0c35ddce5e10a7e262f09c1f1518b58e27\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jia Deng\"},{\"authorId\":null,\"name\":\"Li-Jia Li\"},{\"authorId\":null,\"name\":\"Kai Li\"},{\"authorId\":null,\"name\":\"Fei-Fei Li\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Bottom - up and top - down attention for image captioning and visual question answering Fatality killed the cat or : BabelPic , a multi - modal dataset for non - concrete concepts\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Peter Anderson\"},{\"authorId\":null,\"name\":\"Xiaodong He\"},{\"authorId\":null,\"name\":\"Chris Buehler\"},{\"authorId\":null,\"name\":\"Damien Teney\"},{\"authorId\":null,\"name\":\"Mark Johnson\"},{\"authorId\":null,\"name\":\"Stephen Gould\"},{\"authorId\":null,\"name\":\"Lei Zhang. Bottom-up\"},{\"authorId\":null,\"name\":\"top-down attention for image captioning\"},{\"authorId\":null,\"name\":\"visual question answering. In Proc\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"of CVPR\",\"url\":\"\",\"venue\":\"pages 6077\\u2013 6086,\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"47680287\",\"name\":\"W. Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2009.5206848\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1b47265245e8db53a553049dcb27ed3e495fd625\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/1b47265245e8db53a553049dcb27ed3e495fd625\",\"venue\":\"CVPR 2009\",\"year\":2009},{\"arxivId\":\"1505.04870\",\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2133220\",\"name\":\"C. Cervantes\"},{\"authorId\":\"145507543\",\"name\":\"Juan C. Caicedo\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1007/s11263-016-0965-7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0612745dbd292fc0a548a16d39cd73e127faedde\",\"title\":\"Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models\",\"url\":\"https://www.semanticscholar.org/paper/0612745dbd292fc0a548a16d39cd73e127faedde\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37515745\",\"name\":\"A. Moro\"},{\"authorId\":\"1733928\",\"name\":\"R. Navigli\"}],\"doi\":\"10.18653/v1/S15-2049\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"de8bff77d6f514bfdedc12a001f6d353a8e0d422\",\"title\":\"SemEval-2015 Task 13: Multilingual All-Words Sense Disambiguation and Entity Linking\",\"url\":\"https://www.semanticscholar.org/paper/de8bff77d6f514bfdedc12a001f6d353a8e0d422\",\"venue\":\"SemEval@NAACL-HLT\",\"year\":2015},{\"arxivId\":\"1908.03557\",\"authors\":[{\"authorId\":\"32562635\",\"name\":\"Liunian Harold Li\"},{\"authorId\":\"2064210\",\"name\":\"Mark Yatskar\"},{\"authorId\":\"144508458\",\"name\":\"Da Yin\"},{\"authorId\":\"1793529\",\"name\":\"C. Hsieh\"},{\"authorId\":\"2782886\",\"name\":\"Kai-Wei Chang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5aec474c31a2f4b74703c6f786c0a8ff85c450da\",\"title\":\"VisualBERT: A Simple and Performant Baseline for Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/5aec474c31a2f4b74703c6f786c0a8ff85c450da\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1733928\",\"name\":\"R. Navigli\"}],\"doi\":\"10.1145/1459352.1459355\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c1e48526eddd68b5bf98739a578ab69a009f570d\",\"title\":\"Word sense disambiguation: A survey\",\"url\":\"https://www.semanticscholar.org/paper/c1e48526eddd68b5bf98739a578ab69a009f570d\",\"venue\":\"CSUR\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743722\",\"name\":\"Douwe Kiela\"},{\"authorId\":\"145783676\",\"name\":\"Felix Hill\"},{\"authorId\":\"145762466\",\"name\":\"A. Korhonen\"},{\"authorId\":\"144523372\",\"name\":\"Stephen Clark\"}],\"doi\":\"10.3115/v1/P14-2135\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0463b1fe889f4924da30a739f5faa61b70e08629\",\"title\":\"Improving Multi-Modal Representations Using Image Dispersion: Why Less is Sometimes More\",\"url\":\"https://www.semanticscholar.org/paper/0463b1fe889f4924da30a739f5faa61b70e08629\",\"venue\":\"ACL\",\"year\":2014},{\"arxivId\":\"1811.00982\",\"authors\":[{\"authorId\":\"33746152\",\"name\":\"A. Kuznetsova\"},{\"authorId\":\"51905008\",\"name\":\"Hassan Rom\"},{\"authorId\":\"3016019\",\"name\":\"Neil Alldrin\"},{\"authorId\":\"1823362\",\"name\":\"J. Uijlings\"},{\"authorId\":\"8804527\",\"name\":\"Ivan Krasin\"},{\"authorId\":\"1403171438\",\"name\":\"J. Pont-Tuset\"},{\"authorId\":\"40645960\",\"name\":\"S. Kamali\"},{\"authorId\":\"31422546\",\"name\":\"S. Popov\"},{\"authorId\":\"1415029863\",\"name\":\"M. Malloci\"},{\"authorId\":\"144629422\",\"name\":\"Alexander Kolesnikov\"},{\"authorId\":\"143642945\",\"name\":\"T. Duerig\"},{\"authorId\":\"143865718\",\"name\":\"V. Ferrari\"}],\"doi\":\"10.1007/s11263-020-01316-z\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5ac18d505ed6d10e8692cbb7d33f6852e6782692\",\"title\":\"The Open Images Dataset V4\",\"url\":\"https://www.semanticscholar.org/paper/5ac18d505ed6d10e8692cbb7d33f6852e6782692\",\"venue\":\"International Journal of Computer Vision\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1733928\",\"name\":\"R. Navigli\"},{\"authorId\":\"1387447871\",\"name\":\"Jos\\u00e9 Camacho-Collados\"},{\"authorId\":\"3106437\",\"name\":\"Alessandro Raganato\"}],\"doi\":\"10.18653/V1/E17-1010\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2df6ae1725ade4249aa961c34da329bdc4761f10\",\"title\":\"Word Sense Disambiguation: A Unified Evaluation Framework and Empirical Comparison\",\"url\":\"https://www.semanticscholar.org/paper/2df6ae1725ade4249aa961c34da329bdc4761f10\",\"venue\":\"EACL\",\"year\":2017},{\"arxivId\":\"1906.10007\",\"authors\":[{\"authorId\":\"144653901\",\"name\":\"Daniel Loureiro\"},{\"authorId\":\"1772839\",\"name\":\"A. Jorge\"}],\"doi\":\"10.18653/v1/P19-1569\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b85ec2b911b7b5e4bc5519d503d265b6c9c9d0c2\",\"title\":\"Language Modelling Makes Sense: Propagating Representations through WordNet for Full-Coverage Word Sense Disambiguation\",\"url\":\"https://www.semanticscholar.org/paper/b85ec2b911b7b5e4bc5519d503d265b6c9c9d0c2\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1733928\",\"name\":\"R. Navigli\"},{\"authorId\":\"1801255\",\"name\":\"Simone Paolo Ponzetto\"}],\"doi\":\"10.1016/j.artint.2012.07.001\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7f90ef42f22d4f9b86d33b0ad7f16261273c8612\",\"title\":\"BabelNet: The automatic construction, evaluation and application of a wide-coverage multilingual semantic network\",\"url\":\"https://www.semanticscholar.org/paper/7f90ef42f22d4f9b86d33b0ad7f16261273c8612\",\"venue\":\"Artif. Intell.\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Carina Silberer\"},{\"authorId\":null,\"name\":\"Mirella Lapata. Learning grounded meaning representations  Proc\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"of ACL\",\"url\":\"\",\"venue\":\"pages 721\\u2013732,\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144096985\",\"name\":\"G. Miller\"}],\"doi\":\"10.1145/219717.219748\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"68c03788224000794d5491ab459be0b2a2c38677\",\"title\":\"WordNet: a lexical database for English\",\"url\":\"https://www.semanticscholar.org/paper/68c03788224000794d5491ab459be0b2a2c38677\",\"venue\":\"CACM\",\"year\":1995},{\"arxivId\":\"1612.00837\",\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"7595427\",\"name\":\"Tejas Khot\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2017.670\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"title\":\"Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51131802\",\"name\":\"J. Kiros\"},{\"authorId\":\"144333684\",\"name\":\"William Chan\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.18653/v1/P18-1085\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"35ebe95db7ab148e25904604d3b06a9412f6b4a4\",\"title\":\"Illustrative Language Understanding: Large-Scale Visual Grounding with Image Search\",\"url\":\"https://www.semanticscholar.org/paper/35ebe95db7ab148e25904604d3b06a9412f6b4a4\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1490966079\",\"name\":\"A. Calabrese\"},{\"authorId\":\"143802044\",\"name\":\"Michele Bevilacqua\"},{\"authorId\":\"1733928\",\"name\":\"R. Navigli\"}],\"doi\":\"10.18653/v1/2020.acl-main.425\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"36d7e8c618bbc5e59ba3d13d7cce7e94d829eea5\",\"title\":\"Fatality Killed the Cat or: BabelPic, a Multimodal Dataset for Non-Concrete Concepts\",\"url\":\"https://www.semanticscholar.org/paper/36d7e8c618bbc5e59ba3d13d7cce7e94d829eea5\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"1908.02265\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"65a9c7b0800c86a196bc14e7621ff895cc6ab287\",\"title\":\"ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/65a9c7b0800c86a196bc14e7621ff895cc6ab287\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1301.3781\",\"authors\":[{\"authorId\":null,\"name\":\"Tomas Mikolov\"},{\"authorId\":\"38644044\",\"name\":\"Kai Chen\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"330da625c15427c6e42ccfa3b747fb29e5835bf0\",\"title\":\"Efficient Estimation of Word Representations in Vector Space\",\"url\":\"https://www.semanticscholar.org/paper/330da625c15427c6e42ccfa3b747fb29e5835bf0\",\"venue\":\"ICLR\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145783676\",\"name\":\"Felix Hill\"},{\"authorId\":\"145762466\",\"name\":\"A. Korhonen\"}],\"doi\":\"10.3115/v1/D14-1032\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb0c26ad12c8bbe2ee02ceaf1033fe6c90f4f7f9\",\"title\":\"Learning Abstract Concept Embeddings from Multi-Modal Data: Since You Probably Can't See What I Mean\",\"url\":\"https://www.semanticscholar.org/paper/eb0c26ad12c8bbe2ee02ceaf1033fe6c90f4f7f9\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":\"1908.07490\",\"authors\":[{\"authorId\":\"3218666\",\"name\":\"Hao Hao Tan\"},{\"authorId\":\"143977266\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/D19-1514\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"79c93274429d6355959f1e4374c2147bb81ea649\",\"title\":\"LXMERT: Learning Cross-Modality Encoder Representations from Transformers\",\"url\":\"https://www.semanticscholar.org/paper/79c93274429d6355959f1e4374c2147bb81ea649\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1602.07332\",\"authors\":[{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"50499889\",\"name\":\"O. Groth\"},{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"1382195702\",\"name\":\"Kenji Hata\"},{\"authorId\":\"40591424\",\"name\":\"J. Kravitz\"},{\"authorId\":\"6000646\",\"name\":\"Stephanie Chen\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"1388344504\",\"name\":\"David A. Shamma\"},{\"authorId\":\"1379506718\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-016-0981-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"title\":\"Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations\",\"url\":\"https://www.semanticscholar.org/paper/afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":\"1810.04805\",\"authors\":[{\"authorId\":\"39172707\",\"name\":\"J. Devlin\"},{\"authorId\":\"1744179\",\"name\":\"Ming-Wei Chang\"},{\"authorId\":\"2544107\",\"name\":\"Kenton Lee\"},{\"authorId\":\"3259253\",\"name\":\"Kristina Toutanova\"}],\"doi\":\"10.18653/v1/N19-1423\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"df2b0e26d0599ce3e70df8a9da02e51594e0e992\",\"title\":\"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\",\"url\":\"https://www.semanticscholar.org/paper/df2b0e26d0599ce3e70df8a9da02e51594e0e992\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Luowei Zhou\"},{\"authorId\":null,\"name\":\"Hamid Palangi\"},{\"authorId\":null,\"name\":\"Lei Zhang\"},{\"authorId\":null,\"name\":\"Houdong Hu\"},{\"authorId\":null,\"name\":\"Jason J. Corso\"},{\"authorId\":null,\"name\":\"VQA Jianfeng Gao. Unified visionlanguage pre-training  captioning\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In Proc\",\"url\":\"\",\"venue\":\"of AAAI,\",\"year\":2020},{\"arxivId\":\"1805.07616\",\"authors\":[{\"authorId\":\"144481186\",\"name\":\"Guillem Collell\"},{\"authorId\":\"145446752\",\"name\":\"Marie-Francine Moens\"}],\"doi\":\"10.18653/v1/P18-2074\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"30893ab43187e55941b8bbff1de903546b1dc459\",\"title\":\"Do Neural Network Cross-Modal Mappings Really Bridge Modalities?\",\"url\":\"https://www.semanticscholar.org/paper/30893ab43187e55941b8bbff1de903546b1dc459\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Tomas Mikolov\"},{\"authorId\":null,\"name\":\"Kai Chen\"},{\"authorId\":null,\"name\":\"Greg Corrado\"},{\"authorId\":null,\"name\":\"Jeffrey Dean. Efficient estimation of word representations space\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In Proc\",\"url\":\"\",\"venue\":\"of ICLR,\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Andrea Frome\"},{\"authorId\":null,\"name\":\"Gregory S. Corrado\"},{\"authorId\":null,\"name\":\"Jonathon Shlens\"},{\"authorId\":null,\"name\":\"Samy Bengio\"},{\"authorId\":null,\"name\":\"Jeffrey Dean\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Marc\\u2019Aurelio Ranzato\",\"url\":\"\",\"venue\":\"and Tomas Mikolov. DeViSE: A deep visual-semantic embedding model. In Proc. of NeurIPS, pages 2121\\u20132129,\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Roberto Navigli\"},{\"authorId\":null,\"name\":\"Simone Paolo Ponzetto\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"BabelNet: The automatic construction\",\"url\":\"\",\"venue\":\"evaluation and application of a wide-coverage multilingual semantic network. Artif. Intell., 193:217\\u2013250,\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143802044\",\"name\":\"Michele Bevilacqua\"},{\"authorId\":\"1733928\",\"name\":\"R. Navigli\"}],\"doi\":\"10.18653/v1/2020.acl-main.255\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"81393a94e6bd33f9a3623814f754f662082a5c11\",\"title\":\"Breaking Through the 80% Glass Ceiling: Raising the State of the Art in Word Sense Disambiguation by Incorporating Knowledge Graph Information\",\"url\":\"https://www.semanticscholar.org/paper/81393a94e6bd33f9a3623814f754f662082a5c11\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"1908.07245\",\"authors\":[{\"authorId\":\"51244526\",\"name\":\"Luyao Huang\"},{\"authorId\":\"46299519\",\"name\":\"C. Sun\"},{\"authorId\":\"1767521\",\"name\":\"Xipeng Qiu\"},{\"authorId\":\"102337801\",\"name\":\"X. Huang\"}],\"doi\":\"10.18653/v1/D19-1355\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b6a587d0aba6f5fb3872c0514fcc3a2623eebf7d\",\"title\":\"GlossBERT: BERT for Word Sense Disambiguation with Gloss Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/b6a587d0aba6f5fb3872c0514fcc3a2623eebf7d\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"1506.01497\",\"authors\":[{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"144716314\",\"name\":\"J. Sun\"}],\"doi\":\"10.1109/TPAMI.2016.2577031\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"title\":\"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\",\"url\":\"https://www.semanticscholar.org/paper/424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Lawrence W Barsalou\"},{\"authorId\":null,\"name\":\"Katja Wiemer-Hastings. Situating abstract concepts\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Grounding Cognition: The Role of Perception and Action in Memory\",\"url\":\"\",\"venue\":\"Language, and Thought, pages 129\\u2013163,\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Dhruv Batra\"},{\"authorId\":null,\"name\":\"Devi Parikh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"guage modelling makes sense : Propagating representations through WordNet for full - coverage Word Sense Disambiguation\",\"url\":\"\",\"venue\":\"\",\"year\":null}],\"title\":\"EViLBERT: Learning Task-Agnostic Multimodal Sense Embeddings\",\"topics\":[{\"topic\":\"Multimodal interaction\",\"topicId\":\"42592\",\"url\":\"https://www.semanticscholar.org/topic/42592\"}],\"url\":\"https://www.semanticscholar.org/paper/366c3f0c35ddce5e10a7e262f09c1f1518b58e27\",\"venue\":\"IJCAI\",\"year\":2020}\n"