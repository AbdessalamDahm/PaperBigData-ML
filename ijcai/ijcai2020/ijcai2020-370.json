"{\"abstract\":\"Stochastic variance-reduced gradient (SVRG) is an optimization method originally designed for tackling machine learning problems with a finite sum structure. SVRG was later shown to work for policy evaluation, a problem in reinforcement learning in which one aims to estimate the value function of a given policy. SVRG makes use of gradient estimates at two scales. At the slower scale, SVRG computes a full gradient over the whole dataset, which could lead to prohibitive computation costs. In this work, we show that two variants of SVRG for policy evaluation could significantly diminish the number of gradient calculations while preserving a linear convergence speed. More importantly, our theoretical result implies that one does not need to use the entire dataset in every epoch of SVRG when it is applied to policy evaluation with linear function approximation. Our experiments demonstrate large computational savings provided by the proposed methods.\",\"arxivId\":\"1906.03704\",\"authors\":[{\"authorId\":\"22187301\",\"name\":\"Zilun Peng\",\"url\":\"https://www.semanticscholar.org/author/22187301\"},{\"authorId\":\"145046554\",\"name\":\"A. Touati\",\"url\":\"https://www.semanticscholar.org/author/145046554\"},{\"authorId\":\"145467703\",\"name\":\"P. Vincent\",\"url\":\"https://www.semanticscholar.org/author/145467703\"},{\"authorId\":\"144368601\",\"name\":\"Doina Precup\",\"url\":\"https://www.semanticscholar.org/author/144368601\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"FERENCE LEARNING\"},{\"authorId\":\"51020953\",\"name\":\"Tengyu Xu\"},{\"authorId\":null,\"name\":\"Zhe Wang\"},{\"authorId\":\"1476825339\",\"name\":\"Y. Zhou\"},{\"authorId\":\"145097686\",\"name\":\"Y. Liang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bc5a582e798344cf464a0908919338824c4aeab8\",\"title\":\"REANALYSIS OF VARIANCE REDUCED TEMPORAL DIF-\",\"url\":\"https://www.semanticscholar.org/paper/bc5a582e798344cf464a0908919338824c4aeab8\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2010.13272\",\"authors\":[{\"authorId\":\"1576266923\",\"name\":\"S. Ma\"},{\"authorId\":\"1476825339\",\"name\":\"Y. Zhou\"},{\"authorId\":\"1805108\",\"name\":\"Shaofeng Zou\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1faa9c6b93d7227a20b3eb0f197f13f7e8f9f9b7\",\"title\":\"Variance-Reduced Off-Policy TDC Learning: Non-Asymptotic Convergence Analysis\",\"url\":\"https://www.semanticscholar.org/paper/1faa9c6b93d7227a20b3eb0f197f13f7e8f9f9b7\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2001.01898\",\"authors\":[{\"authorId\":\"51020953\",\"name\":\"T. Xu\"},{\"authorId\":null,\"name\":\"Zhe Wang\"},{\"authorId\":\"1476825339\",\"name\":\"Y. Zhou\"},{\"authorId\":\"145097686\",\"name\":\"Y. Liang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d72af20c174ed39f45a1538c2fe9444c26686243\",\"title\":\"Reanalysis of Variance Reduced Temporal Difference Learning\",\"url\":\"https://www.semanticscholar.org/paper/d72af20c174ed39f45a1538c2fe9444c26686243\",\"venue\":\"ICLR\",\"year\":2020}],\"corpusId\":182952608,\"doi\":\"10.24963/ijcai.2020/370\",\"fieldsOfStudy\":[\"Computer Science\",\"Mathematics\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"ebb26a0af6c124f8d04c2221e717d88d1f8a2496\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1727849\",\"name\":\"S. Hanson\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"69d7086300e7f5322c06f2f242a565b3a182efb5\",\"title\":\"In Advances in Neural Information Processing Systems\",\"url\":\"https://www.semanticscholar.org/paper/69d7086300e7f5322c06f2f242a565b3a182efb5\",\"venue\":\"NIPS 1990\",\"year\":1990},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Greg Brockman\"},{\"authorId\":null,\"name\":\"Vicki Cheung\"},{\"authorId\":null,\"name\":\"Ludwig Pettersson\"},{\"authorId\":null,\"name\":\"Jonas Schneider\"},{\"authorId\":null,\"name\":\"John Schulman\"},{\"authorId\":null,\"name\":\"Jie Tang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and Wojciech Zaremba\",\"url\":\"\",\"venue\":\"Openai gym,\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Justin Boyan\"},{\"authorId\":null,\"name\":\"Bradtke\"},{\"authorId\":null,\"name\":\"J Barto Steven\"},{\"authorId\":null,\"name\":\"Andrew G Bradtke\"},{\"authorId\":null,\"name\":\"Barto\"},{\"authorId\":null,\"name\":\"Brockman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Zilun Peng, Ahmed Touati, Pascal Vincent, and Doina Precup. Svrg for policy evaluation with fewer gradient evaluations. CoRR, abs/1906.03704\",\"url\":\"\",\"venue\":\"Linear least-squares algorithms for temporal difference learning. Machine Learning\",\"year\":1988},{\"arxivId\":\"1905.12615\",\"authors\":[{\"authorId\":\"47568847\",\"name\":\"Pan Xu\"},{\"authorId\":\"83988382\",\"name\":\"F. Gao\"},{\"authorId\":\"9937103\",\"name\":\"Quanquan Gu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"06fa638770b512703ef74c64642b80a8d2c26fc9\",\"title\":\"An Improved Convergence Analysis of Stochastic Variance-Reduced Policy Gradient\",\"url\":\"https://www.semanticscholar.org/paper/06fa638770b512703ef74c64642b80a8d2c26fc9\",\"venue\":\"UAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Zilun Peng\"},{\"authorId\":null,\"name\":\"Ahmed Touati\"},{\"authorId\":null,\"name\":\"Pascal Vincent\"},{\"authorId\":null,\"name\":\"Doina Precup. Svrg for policy evaluation with fewer grad evaluations\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"CoRR\",\"url\":\"\",\"venue\":\"abs/1906.03704,\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699645\",\"name\":\"R. Sutton\"},{\"authorId\":\"1797222\",\"name\":\"H. Maei\"},{\"authorId\":\"144368601\",\"name\":\"Doina Precup\"},{\"authorId\":\"143683893\",\"name\":\"S. Bhatnagar\"},{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"40868287\",\"name\":\"Csaba Szepesvari\"},{\"authorId\":\"1766844\",\"name\":\"Eric Wiewiora\"}],\"doi\":\"10.1145/1553374.1553501\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a97ba611613d6ee20ec441a15e18cab9d4ebd3e6\",\"title\":\"Fast gradient-descent methods for temporal-difference learning with linear function approximation\",\"url\":\"https://www.semanticscholar.org/paper/a97ba611613d6ee20ec441a15e18cab9d4ebd3e6\",\"venue\":\"ICML '09\",\"year\":2009},{\"arxivId\":\"1702.07944\",\"authors\":[{\"authorId\":\"145697585\",\"name\":\"S. Du\"},{\"authorId\":\"1720246\",\"name\":\"Jianshu Chen\"},{\"authorId\":\"28929337\",\"name\":\"L. Li\"},{\"authorId\":\"145942106\",\"name\":\"Lin Xiao\"},{\"authorId\":\"24982365\",\"name\":\"Dengyong Zhou\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4ce25912f8f0b7bcac53cbc4d8e0ca867f2109bb\",\"title\":\"Stochastic Variance Reduction Methods for Policy Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/4ce25912f8f0b7bcac53cbc4d8e0ca867f2109bb\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Gal Dalal\"},{\"authorId\":null,\"name\":\"Balazs Szorenyi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and Gugan Thoppe\",\"url\":\"\",\"venue\":\"A tale of two-timescale reinforcement learning with the tightest finite-time bound,\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699645\",\"name\":\"R. Sutton\"},{\"authorId\":\"40868287\",\"name\":\"Csaba Szepesvari\"},{\"authorId\":\"1797222\",\"name\":\"H. Maei\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"28c0192e486b5aa26bf9f36a6f563e31225611f6\",\"title\":\"A Convergent O(n) Temporal-difference Algorithm for Off-policy Learning with Linear Function Approximation\",\"url\":\"https://www.semanticscholar.org/paper/28c0192e486b5aa26bf9f36a6f563e31225611f6\",\"venue\":\"NIPS\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1509217815\",\"name\":\"Ina Ruck\"},{\"authorId\":\"1509224719\",\"name\":\"Amerika Nach\"},{\"authorId\":\"1509223858\",\"name\":\"Tagen Unwahrscheinlichkeit\"},{\"authorId\":\"1509221473\",\"name\":\"Torben L\\u00fctjen\"},{\"authorId\":\"1509227399\",\"name\":\"Wie Amerika IN Politische\"},{\"authorId\":\"1509224729\",\"name\":\"Echokammern Zerfiel\"},{\"authorId\":\"1509221527\",\"name\":\"Eva Marlene Hausteiner\"},{\"authorId\":\"13202061\",\"name\":\"M. Berg\"},{\"authorId\":\"1509227509\",\"name\":\"Josef Braml\"},{\"authorId\":\"1509224737\",\"name\":\"Innenansichten Von\"},{\"authorId\":\"1509217488\",\"name\":\"Trumps Aussenpolitik\"},{\"authorId\":\"119118596\",\"name\":\"Andrew B. Denison\"},{\"authorId\":\"116494131\",\"name\":\"G. Seesslen\"}],\"doi\":\"10.1016/S0140-6736(89)91380-9\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2d4e16e5b733b12d7dca311b399c91db2cd89792\",\"title\":\"USA\",\"url\":\"https://www.semanticscholar.org/paper/2d4e16e5b733b12d7dca311b399c91db2cd89792\",\"venue\":\"The Lancet\",\"year\":1989},{\"arxivId\":\"1705.09322\",\"authors\":[{\"authorId\":\"145046554\",\"name\":\"A. Touati\"},{\"authorId\":\"145180695\",\"name\":\"P. Bacon\"},{\"authorId\":\"144368601\",\"name\":\"Doina Precup\"},{\"authorId\":\"145467703\",\"name\":\"P. Vincent\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"46f066d2e1e45228728af614b97edf842d923c4a\",\"title\":\"Convergent Tree-Backup and Retrace with Function Approximation\",\"url\":\"https://www.semanticscholar.org/paper/46f066d2e1e45228728af614b97edf842d923c4a\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":\"1605.06398\",\"authors\":[{\"authorId\":\"2478793\",\"name\":\"B. Palaniappan\"},{\"authorId\":\"144570279\",\"name\":\"Francis R. Bach\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"75b27ad55d57428d0c0590398534569e8f8959ec\",\"title\":\"Stochastic Variance Reduction Methods for Saddle-Point Problems\",\"url\":\"https://www.semanticscholar.org/paper/75b27ad55d57428d0c0590398534569e8f8959ec\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2160071\",\"name\":\"C. Dann\"},{\"authorId\":\"26599977\",\"name\":\"G. Neumann\"},{\"authorId\":\"145197867\",\"name\":\"Jan Peters\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"48863b153276dc5c09f3ff1579b3fa1dc5d444b8\",\"title\":\"Policy evaluation with temporal differences: a survey and comparison\",\"url\":\"https://www.semanticscholar.org/paper/48863b153276dc5c09f3ff1579b3fa1dc5d444b8\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3214276\",\"name\":\"J. Boyan\"}],\"doi\":\"10.1023/A:1017936530646\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d6aa631d44a7f2cbb3ab07f3b993f4e5c5c4150b\",\"title\":\"Technical Update: Least-Squares Temporal Difference Learning\",\"url\":\"https://www.semanticscholar.org/paper/d6aa631d44a7f2cbb3ab07f3b993f4e5c5c4150b\",\"venue\":\"Machine Learning\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Michail G. Lagoudakis\"},{\"authorId\":null,\"name\":\"Ronald Parr. Least-squares policy iteration\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Journal of Machine Learning Research\",\"url\":\"\",\"venue\":\"pages 1107\\u20131149,\",\"year\":2003},{\"arxivId\":\"1407.0202\",\"authors\":[{\"authorId\":\"34597877\",\"name\":\"Aaron Defazio\"},{\"authorId\":\"144570279\",\"name\":\"Francis R. Bach\"},{\"authorId\":\"1388317459\",\"name\":\"S. Lacoste-Julien\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4daec165c1f4aa1206b0d91c0b26f0287d1ef52d\",\"title\":\"SAGA: A Fast Incremental Gradient Method With Support for Non-Strongly Convex Composite Objectives\",\"url\":\"https://www.semanticscholar.org/paper/4daec165c1f4aa1206b0d91c0b26f0287d1ef52d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1309.2388\",\"authors\":[{\"authorId\":\"145610994\",\"name\":\"M. Schmidt\"},{\"authorId\":\"7245737\",\"name\":\"Nicolas Le Roux\"},{\"authorId\":\"144570279\",\"name\":\"Francis R. Bach\"}],\"doi\":\"10.1007/s10107-016-1030-6\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"73068d3d5dacf987848eadd9af5b5fad8f7cf9c6\",\"title\":\"Minimizing finite sums with the stochastic average gradient\",\"url\":\"https://www.semanticscholar.org/paper/73068d3d5dacf987848eadd9af5b5fad8f7cf9c6\",\"venue\":\"Math. Program.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145648751\",\"name\":\"H. Robbins\"}],\"doi\":\"10.1214/AOMS/1177729586\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"34ddd8865569c2c32dec9bf7ffc817ff42faaa01\",\"title\":\"A Stochastic Approximation Method\",\"url\":\"https://www.semanticscholar.org/paper/34ddd8865569c2c32dec9bf7ffc817ff42faaa01\",\"venue\":\"\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ahmed Touati\"},{\"authorId\":null,\"name\":\"Pierre-Luc Bacon\"},{\"authorId\":null,\"name\":\"Doina Precup\"},{\"authorId\":null,\"name\":\"Pascal Vincent. Convergent tree backup\"},{\"authorId\":null,\"name\":\"retrace with function approximation\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In International Conference on Machine Learning\",\"url\":\"\",\"venue\":\"pages 4962\\u20134971,\",\"year\":2018},{\"arxivId\":\"1609.03261\",\"authors\":[{\"authorId\":\"40239086\",\"name\":\"Lihua Lei\"},{\"authorId\":\"1694621\",\"name\":\"Michael I. Jordan\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e2c130b85da00d89ff08a5cae1f8632e078a5c8d\",\"title\":\"Less than a Single Pass: Stochastically Controlled Stochastic Gradient\",\"url\":\"https://www.semanticscholar.org/paper/e2c130b85da00d89ff08a5cae1f8632e078a5c8d\",\"venue\":\"AISTATS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1844179\",\"name\":\"L. Baird\"}],\"doi\":\"10.1016/b978-1-55860-377-6.50013-x\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f518bffb712a298bff18248c67f6fc0181018ae6\",\"title\":\"Residual Algorithms: Reinforcement Learning with Function Approximation\",\"url\":\"https://www.semanticscholar.org/paper/f518bffb712a298bff18248c67f6fc0181018ae6\",\"venue\":\"ICML\",\"year\":1995},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1819261\",\"name\":\"Steven J. Bradtke\"},{\"authorId\":\"1730590\",\"name\":\"A. Barto\"}],\"doi\":\"10.1007/BF00114723\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"41e1b9de83a9e2f53bcb3f27e18d349fd63b40fa\",\"title\":\"Linear Least-Squares algorithms for temporal difference learning\",\"url\":\"https://www.semanticscholar.org/paper/41e1b9de83a9e2f53bcb3f27e18d349fd63b40fa\",\"venue\":\"Machine Learning\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144299726\",\"name\":\"Thomas G. Dietterich\"}],\"doi\":\"10.1145/242224.242229\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aab43c9c33af00b718cf2ae374b861d49862a563\",\"title\":\"Machine learning\",\"url\":\"https://www.semanticscholar.org/paper/aab43c9c33af00b718cf2ae374b861d49862a563\",\"venue\":\"CSUR\",\"year\":1996},{\"arxivId\":\"1511.01942\",\"authors\":[{\"authorId\":\"2207121\",\"name\":\"Reza Babanezhad\"},{\"authorId\":\"50307467\",\"name\":\"M. O. Ahmed\"},{\"authorId\":\"1838543\",\"name\":\"Alim Virani\"},{\"authorId\":\"145610994\",\"name\":\"M. Schmidt\"},{\"authorId\":\"32139366\",\"name\":\"Jakub Konecn\\u00fd\"},{\"authorId\":\"34725700\",\"name\":\"S. Sallinen\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"ee605880a47b72b61406d1b38273c31426108b7d\",\"title\":\"StopWasting My Gradients: Practical SVRG\",\"url\":\"https://www.semanticscholar.org/paper/ee605880a47b72b61406d1b38273c31426108b7d\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2968184\",\"name\":\"R. Johnson\"},{\"authorId\":\"49104973\",\"name\":\"Tong Zhang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"43c05444fbc239321f6676f3cd539cac34fde7b8\",\"title\":\"Accelerating Stochastic Gradient Descent using Predictive Variance Reduction\",\"url\":\"https://www.semanticscholar.org/paper/43c05444fbc239321f6676f3cd539cac34fde7b8\",\"venue\":\"NIPS\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699645\",\"name\":\"R. Sutton\"},{\"authorId\":\"4454080\",\"name\":\"A. Barto\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b1362879e77efef96ab552f5cb1198c2a67204d6\",\"title\":\"Introduction to Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/b1362879e77efef96ab552f5cb1198c2a67204d6\",\"venue\":\"\",\"year\":1998},{\"arxivId\":\"1806.02450\",\"authors\":[{\"authorId\":\"3442097\",\"name\":\"Jalaj Bhandari\"},{\"authorId\":\"145751896\",\"name\":\"D. Russo\"},{\"authorId\":\"46248764\",\"name\":\"Raghav Singal\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"8237b2311d0c41eb4562b3c70eeb1626c64334b6\",\"title\":\"A Finite Time Analysis of Temporal Difference Learning With Linear Function Approximation\",\"url\":\"https://www.semanticscholar.org/paper/8237b2311d0c41eb4562b3c70eeb1626c64334b6\",\"venue\":\"COLT\",\"year\":2018},{\"arxivId\":\"1606.01540\",\"authors\":[{\"authorId\":\"49508975\",\"name\":\"G. Brockman\"},{\"authorId\":\"34415167\",\"name\":\"Vicki Cheung\"},{\"authorId\":\"152877508\",\"name\":\"Ludwig Pettersson\"},{\"authorId\":\"145540310\",\"name\":\"J. Schneider\"},{\"authorId\":\"47971768\",\"name\":\"John Schulman\"},{\"authorId\":\"143805717\",\"name\":\"Jie Tang\"},{\"authorId\":\"2563432\",\"name\":\"W. Zaremba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ff7f3277c6fa759e84e1ab7664efdac1c1cec76b\",\"title\":\"OpenAI Gym\",\"url\":\"https://www.semanticscholar.org/paper/ff7f3277c6fa759e84e1ab7664efdac1c1cec76b\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"2006.14364\",\"authors\":[{\"authorId\":\"49167156\",\"name\":\"B. Liu\"},{\"authorId\":\"37427994\",\"name\":\"J. Liu\"},{\"authorId\":\"1678622\",\"name\":\"M. Ghavamzadeh\"},{\"authorId\":\"1850503\",\"name\":\"S. Mahadevan\"},{\"authorId\":\"145630605\",\"name\":\"M. Petrik\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"fc71c22a316ee4d8cbf27fabf5b4c0c9041c43cc\",\"title\":\"Finite-Sample Analysis of Proximal Gradient TD Algorithms\",\"url\":\"https://www.semanticscholar.org/paper/fc71c22a316ee4d8cbf27fabf5b4c0c9041c43cc\",\"venue\":\"UAI\",\"year\":2015},{\"arxivId\":\"1411.3224\",\"authors\":[{\"authorId\":\"33656309\",\"name\":\"N. Korda\"},{\"authorId\":\"1401932095\",\"name\":\"A. PrashanthL.\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"92d71d44ba0e18c6829356ed12491517029c0850\",\"title\":\"On TD(0) with function approximation: Concentration bounds and a centered variant with exponential convergence\",\"url\":\"https://www.semanticscholar.org/paper/92d71d44ba0e18c6829356ed12491517029c0850\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1806.05618\",\"authors\":[{\"authorId\":\"145388375\",\"name\":\"M. Papini\"},{\"authorId\":\"51035180\",\"name\":\"Damiano Binaghi\"},{\"authorId\":\"51032963\",\"name\":\"Giuseppe Canonaco\"},{\"authorId\":\"6234609\",\"name\":\"M. Pirotta\"},{\"authorId\":\"1792167\",\"name\":\"Marcello Restelli\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"108b2ea6100d71fd25e3f71743c1e5c4674d6d8c\",\"title\":\"Stochastic Variance-Reduced Policy Gradient\",\"url\":\"https://www.semanticscholar.org/paper/108b2ea6100d71fd25e3f71743c1e5c4674d6d8c\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1786249\",\"name\":\"D. Bertsekas\"}],\"doi\":\"10.1109/TAC.2011.2115290\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dcb99eab5ac521b5e4ff3704060c33efa0326cd9\",\"title\":\"Temporal Difference Methods for General Projected Equations\",\"url\":\"https://www.semanticscholar.org/paper/dcb99eab5ac521b5e4ff3704060c33efa0326cd9\",\"venue\":\"IEEE Transactions on Automatic Control\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699645\",\"name\":\"R. Sutton\"}],\"doi\":\"10.1023/A:1022633531479\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a91635f8d0e7fb804efd1c38d9c24ee952ba7076\",\"title\":\"Learning to Predict by the Methods of Temporal Differences\",\"url\":\"https://www.semanticscholar.org/paper/a91635f8d0e7fb804efd1c38d9c24ee952ba7076\",\"venue\":\"Machine Learning\",\"year\":2005},{\"arxivId\":\"2001.01898\",\"authors\":[{\"authorId\":\"51020953\",\"name\":\"T. Xu\"},{\"authorId\":null,\"name\":\"Zhe Wang\"},{\"authorId\":\"1476825339\",\"name\":\"Y. Zhou\"},{\"authorId\":\"145097686\",\"name\":\"Y. Liang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d72af20c174ed39f45a1538c2fe9444c26686243\",\"title\":\"Reanalysis of Variance Reduced Temporal Difference Learning\",\"url\":\"https://www.semanticscholar.org/paper/d72af20c174ed39f45a1538c2fe9444c26686243\",\"venue\":\"ICLR\",\"year\":2020}],\"title\":\"SVRG for Policy Evaluation with Fewer Gradient Evaluations\",\"topics\":[{\"topic\":\"Machine learning\",\"topicId\":\"168\",\"url\":\"https://www.semanticscholar.org/topic/168\"},{\"topic\":\"Rate of convergence\",\"topicId\":\"45663\",\"url\":\"https://www.semanticscholar.org/topic/45663\"},{\"topic\":\"Linear function\",\"topicId\":\"45804\",\"url\":\"https://www.semanticscholar.org/topic/45804\"},{\"topic\":\"Bellman equation\",\"topicId\":\"65628\",\"url\":\"https://www.semanticscholar.org/topic/65628\"},{\"topic\":\"Approximation\",\"topicId\":\"3247\",\"url\":\"https://www.semanticscholar.org/topic/3247\"},{\"topic\":\"Computation\",\"topicId\":\"339\",\"url\":\"https://www.semanticscholar.org/topic/339\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Mathematical optimization\",\"topicId\":\"89\",\"url\":\"https://www.semanticscholar.org/topic/89\"},{\"topic\":\"Estimated\",\"topicId\":\"351\",\"url\":\"https://www.semanticscholar.org/topic/351\"},{\"topic\":\"Sample Variance\",\"topicId\":\"545265\",\"url\":\"https://www.semanticscholar.org/topic/545265\"},{\"topic\":\"Silo (dataset)\",\"topicId\":\"130506\",\"url\":\"https://www.semanticscholar.org/topic/130506\"},{\"topic\":\"Convergence (action)\",\"topicId\":\"26740\",\"url\":\"https://www.semanticscholar.org/topic/26740\"},{\"topic\":\"Evaluation\",\"topicId\":\"46123\",\"url\":\"https://www.semanticscholar.org/topic/46123\"}],\"url\":\"https://www.semanticscholar.org/paper/ebb26a0af6c124f8d04c2221e717d88d1f8a2496\",\"venue\":\"ArXiv\",\"year\":2019}\n"