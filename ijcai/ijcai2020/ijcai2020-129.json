"{\"abstract\":\"Video inpainting aims to synthesize visually pleasant and temporally consistent content in missing regions of video. Due to a variety of motions across different frames, it is highly challenging to utilize effective temporal information to recover videos. Existing deep learning based methods usually estimate optical flow to align frames and thereby exploit useful information between frames. However, these methods tend to generate artifacts once the estimated optical flow is inaccurate. To alleviate above problem, we propose a novel end-to-end Temporal Adaptive Alignment Network(TAAN) for video inpainting. The TAAN aligns reference frames with target frame via implicit motion estimation at a feature level and then reconstruct target frame by taking the aggregated aligned reference frame features as input. In the proposed network, a Temporal Adaptive Alignment (TAA) module based on deformable convolutions is designed to perform temporal alignment in a local, dense and adaptive manner. Both quantitative and qualitative evaluation results show that our method significantly outperforms existing deep learning based methods.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"47246298\",\"name\":\"Ruixin Liu\",\"url\":\"https://www.semanticscholar.org/author/47246298\"},{\"authorId\":\"151270908\",\"name\":\"Zhenyu Weng\",\"url\":\"https://www.semanticscholar.org/author/151270908\"},{\"authorId\":\"46758870\",\"name\":\"Y. Zhu\",\"url\":\"https://www.semanticscholar.org/author/46758870\"},{\"authorId\":\"103717726\",\"name\":\"Bairong Li\",\"url\":\"https://www.semanticscholar.org/author/103717726\"}],\"citationVelocity\":0,\"citations\":[],\"corpusId\":220480969,\"doi\":\"10.24963/ijcai.2020/129\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":false,\"paperId\":\"0db83dbdb6825596860ea08cc2ad090410cd335b\",\"references\":[{\"arxivId\":\"1905.02884\",\"authors\":[{\"authorId\":\"144996246\",\"name\":\"Rui Xu\"},{\"authorId\":\"48569853\",\"name\":\"X. Li\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"}],\"doi\":\"10.1109/CVPR.2019.00384\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f3f1ea39c55e9c85a68fe50450cd7dfa6515e55c\",\"title\":\"Deep Flow-Guided Video Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/f3f1ea39c55e9c85a68fe50450cd7dfa6515e55c\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1502.01852\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/ICCV.2015.123\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d6f2f611da110b5b5061731be3fc4c7f45d8ee23\",\"title\":\"Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification\",\"url\":\"https://www.semanticscholar.org/paper/d6f2f611da110b5b5061731be3fc4c7f45d8ee23\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1811.11168\",\"authors\":[{\"authorId\":\"2578924\",\"name\":\"X. Zhu\"},{\"authorId\":\"1805197\",\"name\":\"H. Hu\"},{\"authorId\":\"145676588\",\"name\":\"Stephen Lin\"},{\"authorId\":\"3304536\",\"name\":\"Jifeng Dai\"}],\"doi\":\"10.1109/CVPR.2019.00953\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"987b2db58fbe0bda771f11a046cd23de1ce92b39\",\"title\":\"Deformable ConvNets V2: More Deformable, Better Results\",\"url\":\"https://www.semanticscholar.org/paper/987b2db58fbe0bda771f11a046cd23de1ce92b39\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"69940262\",\"name\":\"Ieee Xplore\"}],\"doi\":\"10.1109/tc.1978.1675004\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d8ed6678758f9200bd23fcf11dd733c8f4d9d71c\",\"title\":\"IEEE transactions on pattern analysis and machine intelligence\",\"url\":\"https://www.semanticscholar.org/paper/d8ed6678758f9200bd23fcf11dd733c8f4d9d71c\",\"venue\":\"\",\"year\":1979},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Chuan Wang\"},{\"authorId\":null,\"name\":\"Haibin Huang\"},{\"authorId\":null,\"name\":\"Xiaoguang Han\"},{\"authorId\":null,\"name\":\"Jue Wang. Video inpainting by jointly learning tempora structure\"},{\"authorId\":null,\"name\":\"spatial details\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In Proceedings of the AAAI Conference on Artificial Intelligence\",\"url\":\"\",\"venue\":\"pages 5232\\u20135239,\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Xizhou Zhu\"},{\"authorId\":null,\"name\":\"Han Hu\"},{\"authorId\":null,\"name\":\"Stephen Lin\"},{\"authorId\":null,\"name\":\"Jifeng Dai\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Deformable convnets v2: More deformable\",\"url\":\"\",\"venue\":\"better results. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 9308\\u2013 9316,\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Guilin Liu\"},{\"authorId\":null,\"name\":\"Fitsum A Reda\"},{\"authorId\":null,\"name\":\"Kevin J Shih\"},{\"authorId\":null,\"name\":\"Ting-Chun Wang\"},{\"authorId\":null,\"name\":\"Andrew Tao\"},{\"authorId\":null,\"name\":\"Bryan Catanzaro. Image inpainting for irregular holes us convolutions\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In Proceedings of the European Conference on Computer Vision\",\"url\":\"\",\"venue\":\"pages 85\\u2013100,\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Sungho Lee\"},{\"authorId\":null,\"name\":\"Seoung Wug Oh\"},{\"authorId\":null,\"name\":\"DaeYeun Won\"},{\"authorId\":null,\"name\":\"Seon Joo Kim. Copy-\"},{\"authorId\":null,\"name\":\"-paste networks for deep video inpainting\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In Proceedings of the IEEE International Conference on Computer Vision\",\"url\":\"\",\"venue\":\"pages 4413\\u20134421,\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Dahun Kim\"},{\"authorId\":null,\"name\":\"Sanghyun Woo\"},{\"authorId\":null,\"name\":\"Joon-Young Lee\"},{\"authorId\":null,\"name\":\"In So Kweon. Deep video inpainting\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition\",\"url\":\"\",\"venue\":\"pages 5792\\u20135801,\",\"year\":2019},{\"arxivId\":\"1809.03327\",\"authors\":[{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":\"2889075\",\"name\":\"L. Yang\"},{\"authorId\":\"7888497\",\"name\":\"Yuchen Fan\"},{\"authorId\":\"84426766\",\"name\":\"Dingcheng Yue\"},{\"authorId\":\"21160992\",\"name\":\"Yuchen Liang\"},{\"authorId\":\"47988297\",\"name\":\"Jianchao Yang\"},{\"authorId\":\"1739208\",\"name\":\"T. Huang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"cc628fee1e83bfba1d581bfa128c9cb6c28ef8ad\",\"title\":\"YouTube-VOS: A Large-Scale Video Object Segmentation Benchmark\",\"url\":\"https://www.semanticscholar.org/paper/cc628fee1e83bfba1d581bfa128c9cb6c28ef8ad\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Satoshi Iizuka\"},{\"authorId\":null,\"name\":\"Edgar Simo-Serra\"},{\"authorId\":null,\"name\":\"Hiroshi Ishikawa. Globally\"},{\"authorId\":null,\"name\":\"locally consistent image completion\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"ACM Transactions on Graphics (ToG)\",\"url\":\"\",\"venue\":\"36(4):107,\",\"year\":2017},{\"arxivId\":\"1904.10247\",\"authors\":[{\"authorId\":\"48133807\",\"name\":\"Y. Chang\"},{\"authorId\":\"143822897\",\"name\":\"Zhe Yu Liu\"},{\"authorId\":\"3403825\",\"name\":\"Kuan-Ying Lee\"},{\"authorId\":\"31871157\",\"name\":\"Winston Hsu\"}],\"doi\":\"10.1109/ICCV.2019.00916\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e8705ab4b9626c1ab6442483731fe0371f2234b6\",\"title\":\"Free-Form Video Inpainting With 3D Gated Convolution and Temporal PatchGAN\",\"url\":\"https://www.semanticscholar.org/paper/e8705ab4b9626c1ab6442483731fe0371f2234b6\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jiahui Yu\"},{\"authorId\":null,\"name\":\"Zhe Lin\"},{\"authorId\":null,\"name\":\"Jimei Yang\"},{\"authorId\":null,\"name\":\"Xiaohui Shen\"},{\"authorId\":null,\"name\":\"Xin Lu\"},{\"authorId\":null,\"name\":\"Thomas S Huang. Generative image inpainting with contextu attention\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition\",\"url\":\"\",\"venue\":\"pages 5505\\u20135514,\",\"year\":2018},{\"arxivId\":\"1604.07379\",\"authors\":[{\"authorId\":\"38236002\",\"name\":\"Deepak Pathak\"},{\"authorId\":\"2562966\",\"name\":\"Philipp Kr\\u00e4henb\\u00fchl\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1109/CVPR.2016.278\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7d0effebfa4bed19b6ba41f3af5b7e5b6890de87\",\"title\":\"Context Encoders: Feature Learning by Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/7d0effebfa4bed19b6ba41f3af5b7e5b6890de87\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2942259\",\"name\":\"Federico Perazzi\"},{\"authorId\":\"1403171438\",\"name\":\"J. Pont-Tuset\"},{\"authorId\":\"46936952\",\"name\":\"Brian McWilliams\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"144877478\",\"name\":\"M. Gross\"},{\"authorId\":\"1388791172\",\"name\":\"Alexander Sorkine-Hornung\"}],\"doi\":\"10.1109/CVPR.2016.85\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"05e9e85b5137016c93d042170e82f77bb551a108\",\"title\":\"A Benchmark Dataset and Evaluation Methodology for Video Object Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/05e9e85b5137016c93d042170e82f77bb551a108\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743988\",\"name\":\"Yonatan Wexler\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"144611617\",\"name\":\"M. Irani\"}],\"doi\":\"10.1109/TPAMI.2007.60\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3ace907ea90aed1fb4287b78b19a9f65a462d247\",\"title\":\"Space-Time Completion of Video\",\"url\":\"https://www.semanticscholar.org/paper/3ace907ea90aed1fb4287b78b19a9f65a462d247\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jifeng Dai\"},{\"authorId\":null,\"name\":\"Haozhi Qi\"},{\"authorId\":null,\"name\":\"Yuwen Xiong\"},{\"authorId\":null,\"name\":\"Yi Li\"},{\"authorId\":null,\"name\":\"Guodong Zhang\"},{\"authorId\":null,\"name\":\"Han Hu\"},{\"authorId\":null,\"name\":\"Yichen Wei. Deformable convolutional networks\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In Proceedings of the IEEE International Conference on Computer Vision\",\"url\":\"\",\"venue\":\"pages 764\\u2013773,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66441953\",\"name\":\"No Value\"}],\"doi\":\"10.1109/tip.2017.2701118\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"489131da9cc207fe1fb2fe735209b74da5e36533\",\"title\":\"IEEE International Conference on Image Processing\",\"url\":\"https://www.semanticscholar.org/paper/489131da9cc207fe1fb2fe735209b74da5e36533\",\"venue\":\"\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40894045\",\"name\":\"Kamyar Nazeri\"},{\"authorId\":\"144653206\",\"name\":\"Eric Ng\"},{\"authorId\":\"145061556\",\"name\":\"Tony Joseph\"},{\"authorId\":\"1812218\",\"name\":\"Faisal Z. Qureshi\"},{\"authorId\":\"151503008\",\"name\":\"Mehran Ebrahimi\"}],\"doi\":\"10.1109/ICCVW.2019.00408\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1532750abbb9eac71592ff8f81f1a1a3f7ed9a54\",\"title\":\"EdgeConnect: Structure Guided Image Inpainting using Edge Prediction\",\"url\":\"https://www.semanticscholar.org/paper/1532750abbb9eac71592ff8f81f1a1a3f7ed9a54\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Kim\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Luc Van Gool, Markus Gross, and Alexander Sorkine-Hornung. A benchmark dataset and evaluation methodology for video object segmentation\",\"url\":\"\",\"venue\":\"Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jia-Bin Huang\"},{\"authorId\":null,\"name\":\"Sing Bing Kang\"},{\"authorId\":null,\"name\":\"Narendra Ahuja\"},{\"authorId\":null,\"name\":\"Johannes Kopf. Temporally coherent completion of dynamic video\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"ACM Transactions on Graphics (TOG)\",\"url\":\"\",\"venue\":\"35(6):196,\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2496412\",\"name\":\"Connelly Barnes\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"37737599\",\"name\":\"Adam Finkelstein\"},{\"authorId\":\"1976171\",\"name\":\"D. Goldman\"}],\"doi\":\"10.1145/1531326.1531330\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"10aabf4c13ea57d7106cf809c9edbab63819c277\",\"title\":\"PatchMatch: a randomized correspondence algorithm for structural image editing\",\"url\":\"https://www.semanticscholar.org/paper/10aabf4c13ea57d7106cf809c9edbab63819c277\",\"venue\":\"SIGGRAPH 2009\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Kedar A Patwardhan\"},{\"authorId\":null,\"name\":\"Guillermo Sapiro\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and Marcelo Bertalm\\u0131\\u0301o\",\"url\":\"\",\"venue\":\"Video inpainting under constrained camera motion. IEEE Transactions on Image Processing, 16(2):545\\u2013553,\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Seoung Wug Oh\"},{\"authorId\":null,\"name\":\"Sungho Lee\"},{\"authorId\":null,\"name\":\"Joon-Young Lee\"},{\"authorId\":null,\"name\":\"Seon Joo Kim. Onion-peel networks for deep video completion\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In Proceedings of the IEEE International Conference on Computer Vision\",\"url\":\"\",\"venue\":\"pages 4403\\u20134412,\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Miguel Granados\"},{\"authorId\":null,\"name\":\"Kwang In Kim\"},{\"authorId\":null,\"name\":\"James Tompkin\"},{\"authorId\":null,\"name\":\"Jan Kautz\"},{\"authorId\":null,\"name\":\"Christian Theobalt. Background inpainting for videos with dy objects\"},{\"authorId\":null,\"name\":\"a free-moving camera. In European Conference on Comp Vision\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"pages 682\\u2013695\",\"url\":\"\",\"venue\":\"Springer,\",\"year\":2012}],\"title\":\"Temporal Adaptive Alignment Network for Deep Video Inpainting\",\"topics\":[{\"topic\":\"Inpainting\",\"topicId\":\"146260\",\"url\":\"https://www.semanticscholar.org/topic/146260\"}],\"url\":\"https://www.semanticscholar.org/paper/0db83dbdb6825596860ea08cc2ad090410cd335b\",\"venue\":\"IJCAI\",\"year\":2020}\n"