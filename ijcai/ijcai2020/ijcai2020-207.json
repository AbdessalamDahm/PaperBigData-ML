"{\"abstract\":\"This work presents an exploration and imitation-learning-based agent capable of state-of-the-art performance in playing text-based computer games. Text-based computer games describe their world to the player through natural language and expect the player to interact with the game using text. These games are of interest as they can be seen as a testbed for language understanding, problem-solving, and language generation by artificial agents. Moreover, they provide a learning environment in which these skills can be acquired through interactions with an environment rather than using fixed corpora. One aspect that makes these games particularly challenging for learning agents is the combinatorially large action space. Existing methods for solving text-based games are limited to games that are either very simple or have an action space restricted to a predetermined set of admissible actions. In this work, we propose to use the exploration approach of Go-Explore for solving text-based games. More specifically, in an initial exploration phase, we first extract trajectories with high rewards, after which we train a policy to solve the game by imitating these trajectories. Our experiments show that this approach outperforms existing solutions in solving text-based games, and it is more sample efficient in terms of the number of interactions with the environment. Moreover, we show that the learned policy can generalize better than existing solutions to unseen games without using any restriction on the action space.\",\"arxivId\":\"2001.08868\",\"authors\":[{\"authorId\":\"3064807\",\"name\":\"Andrea Madotto\",\"url\":\"https://www.semanticscholar.org/author/3064807\"},{\"authorId\":\"2171886\",\"name\":\"M. Namazifar\",\"url\":\"https://www.semanticscholar.org/author/2171886\"},{\"authorId\":\"39378983\",\"name\":\"J. Huizinga\",\"url\":\"https://www.semanticscholar.org/author/39378983\"},{\"authorId\":\"34890911\",\"name\":\"Piero Molino\",\"url\":\"https://www.semanticscholar.org/author/34890911\"},{\"authorId\":\"66821245\",\"name\":\"Adrien Ecoffet\",\"url\":\"https://www.semanticscholar.org/author/66821245\"},{\"authorId\":\"3172630\",\"name\":\"Huaixiu Zheng\",\"url\":\"https://www.semanticscholar.org/author/3172630\"},{\"authorId\":\"1710287\",\"name\":\"Alexandros Papangelis\",\"url\":\"https://www.semanticscholar.org/author/1710287\"},{\"authorId\":\"150978762\",\"name\":\"Dian Yu\",\"url\":\"https://www.semanticscholar.org/author/150978762\"},{\"authorId\":\"144011343\",\"name\":\"C. Khatri\",\"url\":\"https://www.semanticscholar.org/author/144011343\"},{\"authorId\":\"5108268\",\"name\":\"G. Tur\",\"url\":\"https://www.semanticscholar.org/author/5108268\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":\"2006.07409\",\"authors\":[{\"authorId\":\"19179135\",\"name\":\"Prithviraj Ammanabrolu\"},{\"authorId\":\"1388021064\",\"name\":\"Ethan Tien\"},{\"authorId\":\"3308897\",\"name\":\"Matthew J. Hausknecht\"},{\"authorId\":\"2757194\",\"name\":\"Mark O. Riedl\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3b2ec1d8e56131d2644b1de89733262adc720716\",\"title\":\"How to Avoid Being Eaten by a Grue: Structured Exploration Strategies for Textual Worlds\",\"url\":\"https://www.semanticscholar.org/paper/3b2ec1d8e56131d2644b1de89733262adc720716\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.08795\",\"authors\":[{\"authorId\":\"19179135\",\"name\":\"Prithviraj Ammanabrolu\"},{\"authorId\":\"1388021064\",\"name\":\"Ethan Tien\"},{\"authorId\":\"7013218\",\"name\":\"Z. Luo\"},{\"authorId\":\"2757194\",\"name\":\"Mark O. Riedl\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c5a90bd8693fdf443b9121d50cd06f926d8df427\",\"title\":\"How To Avoid Being Eaten By a Grue: Exploration Strategies for Text-Adventure Agents\",\"url\":\"https://www.semanticscholar.org/paper/c5a90bd8693fdf443b9121d50cd06f926d8df427\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.09127\",\"authors\":[{\"authorId\":\"51941200\",\"name\":\"Ashutosh Adhikari\"},{\"authorId\":\"2854297\",\"name\":\"Xingdi Yuan\"},{\"authorId\":\"40638665\",\"name\":\"Marc-Alexandre C\\u00f4t\\u00e9\"},{\"authorId\":\"1500721635\",\"name\":\"M. Zelinka\"},{\"authorId\":\"3155310\",\"name\":\"M. Rondeau\"},{\"authorId\":\"144100820\",\"name\":\"R. Laroche\"},{\"authorId\":\"1807041\",\"name\":\"P. Poupart\"},{\"authorId\":\"152226504\",\"name\":\"J. Tang\"},{\"authorId\":\"3382568\",\"name\":\"Adam Trischler\"},{\"authorId\":\"49437682\",\"name\":\"William L. Hamilton\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"583c65c56b47f048b22b1235e528b8f4d6bcbf36\",\"title\":\"Learning Dynamic Belief Graphs to Generalize on Text-Based Games\",\"url\":\"https://www.semanticscholar.org/paper/583c65c56b47f048b22b1235e528b8f4d6bcbf36\",\"venue\":\"NeurIPS\",\"year\":2020}],\"corpusId\":210911870,\"doi\":\"10.24963/ijcai.2020/207\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"fce7dfc76d9ddff672cca59d0340bdffcac53bcc\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1080/09540090600768658\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"31b46fdddbe4fc1265615a5c128063858f999d41\",\"title\":\"Developmental robotics, optimal artificial curiosity, creativity, music, and the fine arts\",\"url\":\"https://www.semanticscholar.org/paper/31b46fdddbe4fc1265615a5c128063858f999d41\",\"venue\":\"Connect. Sci.\",\"year\":2006},{\"arxivId\":null,\"authors\":[],\"doi\":\"10.18653/v1/n19-2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d65b6b4b7e26aaa8fd44786921e56305f261c629\",\"title\":\"Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and Short Papers)\",\"url\":\"https://www.semanticscholar.org/paper/d65b6b4b7e26aaa8fd44786921e56305f261c629\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":\"1703.03429\",\"authors\":[{\"authorId\":\"1834105\",\"name\":\"Nancy Fulda\"},{\"authorId\":\"34778050\",\"name\":\"Daniel Ricks\"},{\"authorId\":\"40154683\",\"name\":\"Ben Murdoch\"},{\"authorId\":\"30585164\",\"name\":\"D. Wingate\"}],\"doi\":\"10.24963/ijcai.2017/144\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cfc22be4649a8ec692ddf71688a8b52a416a3da6\",\"title\":\"What Can You Do with a Rock? Affordance Extraction via Word Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/cfc22be4649a8ec692ddf71688a8b52a416a3da6\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Andrew G Barto. Intrinsic motivation\"},{\"authorId\":null,\"name\":\"reinforcement learning. In Intrinsically motivated learning in natural\"},{\"authorId\":null,\"name\":\"artificial systems\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"pages 17\\u201347\",\"url\":\"\",\"venue\":\"Springer,\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143845796\",\"name\":\"Jeffrey Pennington\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.3115/v1/D14-1162\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"title\":\"Glove: Global Vectors for Word Representation\",\"url\":\"https://www.semanticscholar.org/paper/f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Tim Anderson\"},{\"authorId\":null,\"name\":\"Stu Galley\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"The history of zork\",\"url\":\"\",\"venue\":\"The New Zork Times,\",\"year\":1985},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98241663\",\"name\":\"M. V. Rossum\"}],\"doi\":\"10.1142/9789814360784_0003\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2d5af1ab6368f20a4a9bb2afae23663e5b08b9c6\",\"title\":\"Neural Computation\",\"url\":\"https://www.semanticscholar.org/paper/2d5af1ab6368f20a4a9bb2afae23663e5b08b9c6\",\"venue\":\"\",\"year\":1989},{\"arxivId\":\"1506.08941\",\"authors\":[{\"authorId\":\"144958935\",\"name\":\"Karthik Narasimhan\"},{\"authorId\":\"1954876\",\"name\":\"Tejas D. Kulkarni\"},{\"authorId\":\"1741283\",\"name\":\"R. Barzilay\"}],\"doi\":\"10.18653/v1/D15-1001\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d00e7779c39dc7b06d7d43cf6de6d734c8edc4b8\",\"title\":\"Language Understanding for Text-based Games using Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/d00e7779c39dc7b06d7d43cf6de6d734c8edc4b8\",\"venue\":\"EMNLP\",\"year\":2015},{\"arxivId\":\"1507.02221\",\"authors\":[{\"authorId\":\"2041695\",\"name\":\"Alessandro Sordoni\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"2507979\",\"name\":\"H. Vahabi\"},{\"authorId\":\"1784800\",\"name\":\"C. Lioma\"},{\"authorId\":\"1707651\",\"name\":\"J. Simonsen\"},{\"authorId\":\"50204644\",\"name\":\"J. Nie\"}],\"doi\":\"10.1145/2806416.2806493\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"bb0d19804fd8d5be6deaf0059e0b7888e64205c3\",\"title\":\"A Hierarchical Recurrent Encoder-Decoder for Generative Context-Aware Query Suggestion\",\"url\":\"https://www.semanticscholar.org/paper/bb0d19804fd8d5be6deaf0059e0b7888e64205c3\",\"venue\":\"CIKM\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1397596967\",\"name\":\"D. L. Corgan\"}],\"doi\":\"10.1136/bmj.2.340.13-a\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"5a2e406b1734cba02cce5b0c24a02f42ec262a7d\",\"title\":\"King's College\",\"url\":\"https://www.semanticscholar.org/paper/5a2e406b1734cba02cce5b0c24a02f42ec262a7d\",\"venue\":\"British medical journal\",\"year\":1867},{\"arxivId\":\"1806.11532\",\"authors\":[{\"authorId\":\"40638665\",\"name\":\"Marc-Alexandre C\\u00f4t\\u00e9\"},{\"authorId\":\"2828538\",\"name\":\"\\u00c1kos K\\u00e1d\\u00e1r\"},{\"authorId\":\"2854297\",\"name\":\"Xingdi Yuan\"},{\"authorId\":\"145256547\",\"name\":\"Ben Kybartas\"},{\"authorId\":\"48316034\",\"name\":\"Tavian Barnes\"},{\"authorId\":\"31464095\",\"name\":\"Emery Fine\"},{\"authorId\":\"145503062\",\"name\":\"J. Moore\"},{\"authorId\":\"3308897\",\"name\":\"Matthew J. Hausknecht\"},{\"authorId\":\"3349496\",\"name\":\"Layla El Asri\"},{\"authorId\":\"51172009\",\"name\":\"Mahmoud Adada\"},{\"authorId\":\"51166384\",\"name\":\"Wendy Tay\"},{\"authorId\":\"3382568\",\"name\":\"Adam Trischler\"}],\"doi\":\"10.1007/978-3-030-24337-1_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"89daae27e7df4a418b9610d307ce3df0e30fc8a2\",\"title\":\"TextWorld: A Learning Environment for Text-based Games\",\"url\":\"https://www.semanticscholar.org/paper/89daae27e7df4a418b9610d307ce3df0e30fc8a2\",\"venue\":\"CGW@IJCAI\",\"year\":2018},{\"arxivId\":\"1511.04636\",\"authors\":[{\"authorId\":\"49264189\",\"name\":\"Ji He\"},{\"authorId\":\"1720246\",\"name\":\"Jianshu Chen\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"28929337\",\"name\":\"L. Li\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"144339506\",\"name\":\"Mari Ostendorf\"}],\"doi\":\"10.18653/v1/P16-1153\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6118910c4014cc6c061198a2d88c080ab56ea452\",\"title\":\"Deep Reinforcement Learning with a Natural Language Action Space\",\"url\":\"https://www.semanticscholar.org/paper/6118910c4014cc6c061198a2d88c080ab56ea452\",\"venue\":\"ACL\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39799304\",\"name\":\"Joel Lehman\"},{\"authorId\":\"1846883\",\"name\":\"K. Stanley\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fb144a1d31aec3b2bece6a59bd11a876a9fafb34\",\"title\":\"Exploiting Open-Endedness to Solve Problems Through the Search for Novelty\",\"url\":\"https://www.semanticscholar.org/paper/fb144a1d31aec3b2bece6a59bd11a876a9fafb34\",\"venue\":\"ALIFE\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4562073\",\"name\":\"Chris Watkins\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5c8bb027eb65b6d250a22e9b6db22853a552ac81\",\"title\":\"Learning from delayed rewards\",\"url\":\"https://www.semanticscholar.org/paper/5c8bb027eb65b6d250a22e9b6db22853a552ac81\",\"venue\":\"\",\"year\":1989},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Alessandro Sordoni\"},{\"authorId\":null,\"name\":\"Yoshua Bengio\"},{\"authorId\":null,\"name\":\"Hossein Vahabi\"},{\"authorId\":null,\"name\":\"Christina Lioma\"},{\"authorId\":null,\"name\":\"Jakob Grue Simonsen\"},{\"authorId\":null,\"name\":\"Jian-Yun Nie. A hierarchical recurrent encoderdecoder for g CIKM\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"pages 553\\u2013562\",\"url\":\"\",\"venue\":\"ACM,\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3255983\",\"name\":\"V. Mnih\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"},{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"1392331736\",\"name\":\"Andrei A. Rusu\"},{\"authorId\":\"144056327\",\"name\":\"J. Veness\"},{\"authorId\":\"1397980088\",\"name\":\"Marc G. Bellemare\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"3137672\",\"name\":\"Martin A. Riedmiller\"},{\"authorId\":\"1397979864\",\"name\":\"Andreas K. Fidjeland\"},{\"authorId\":\"2273072\",\"name\":\"Georg Ostrovski\"},{\"authorId\":\"145386761\",\"name\":\"S. Petersen\"},{\"authorId\":\"48878752\",\"name\":\"C. Beattie\"},{\"authorId\":\"49813280\",\"name\":\"A. Sadik\"},{\"authorId\":\"2460849\",\"name\":\"Ioannis Antonoglou\"},{\"authorId\":\"153907173\",\"name\":\"H. King\"},{\"authorId\":\"2106164\",\"name\":\"D. Kumaran\"},{\"authorId\":\"1688276\",\"name\":\"Daan Wierstra\"},{\"authorId\":\"34313265\",\"name\":\"S. Legg\"},{\"authorId\":\"48987704\",\"name\":\"Demis Hassabis\"}],\"doi\":\"10.1038/nature14236\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e0e9a94c4a6ba219e768b4e59f72c18f0a22e23d\",\"title\":\"Human-level control through deep reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/e0e9a94c4a6ba219e768b4e59f72c18f0a22e23d\",\"venue\":\"Nature\",\"year\":2015},{\"arxivId\":\"1801.01999\",\"authors\":[{\"authorId\":\"35272608\",\"name\":\"Mikul\\u00e1\\u0161 Zelinka\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"784d36572e460e0fd95535001b158a4300b0bf30\",\"title\":\"Using reinforcement learning to learn how to play text-based games\",\"url\":\"https://www.semanticscholar.org/paper/784d36572e460e0fd95535001b158a4300b0bf30\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1831199\",\"name\":\"S. Gershman\"},{\"authorId\":\"1784997\",\"name\":\"N. Daw\"}],\"doi\":\"10.1146/annurev-psych-122414-033625\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d98ed6612f4d7efc3211131378d592de10bfc636\",\"title\":\"Reinforcement Learning and Episodic Memory in Humans and Animals: An Integrative Framework\",\"url\":\"https://www.semanticscholar.org/paper/d98ed6612f4d7efc3211131378d592de10bfc636\",\"venue\":\"Annual review of psychology\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48974230\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.7551/mitpress/3115.003.0030\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2980dfe5c99658dc3e508d9d6e1d7f26e6fc8934\",\"title\":\"A possibility for implementing curiosity and boredom in model-building neural controllers\",\"url\":\"https://www.semanticscholar.org/paper/2980dfe5c99658dc3e508d9d6e1d7f26e6fc8934\",\"venue\":\"\",\"year\":1991},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J\\u00fcrgen Schmidhuber. Curious modelbuilding control systems\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In IJCNN\",\"url\":\"\",\"venue\":\"pages 1458\\u20131463,\",\"year\":1991},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1720664\",\"name\":\"Pierre-Yves Oudeyer\"},{\"authorId\":\"143791091\",\"name\":\"F. Kaplan\"}],\"doi\":\"10.3389/neuro.12.006.2007\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e8077729ef723d71a0b7492f2f271ae413b5a4d5\",\"title\":\"What is Intrinsic Motivation? A Typology of Computational Approaches\",\"url\":\"https://www.semanticscholar.org/paper/e8077729ef723d71a0b7492f2f271ae413b5a4d5\",\"venue\":\"Frontiers Neurorobotics\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"14199299\",\"name\":\"Ganaele Langlois\"}],\"doi\":\"10.1057/9781137356611_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cd28d64a096476cfb79f028e3ebe7126b9df925b\",\"title\":\"Being in the World\",\"url\":\"https://www.semanticscholar.org/paper/cd28d64a096476cfb79f028e3ebe7126b9df925b\",\"venue\":\"\",\"year\":2014},{\"arxivId\":\"1308.0850\",\"authors\":[{\"authorId\":\"1753223\",\"name\":\"A. Graves\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"89b1f4740ae37fd04f6ac007577bdd34621f0861\",\"title\":\"Generating Sequences With Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/89b1f4740ae37fd04f6ac007577bdd34621f0861\",\"venue\":\"ArXiv\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J\\u00fcrgen Schmidhuber. Developmental robotics\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"optimal artificial curiosity\",\"url\":\"\",\"venue\":\"creativity, music, and the fine arts. Connection Science, 18(2):173\\u2013187,\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ilya Sutskever\"},{\"authorId\":null,\"name\":\"Oriol Vinyals\"},{\"authorId\":null,\"name\":\"Quoc V Le. Sequence to sequence learning with neural networks\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In NeurIPS\",\"url\":\"\",\"venue\":\"pages 3104\\u20133112,\",\"year\":2014},{\"arxivId\":\"1705.05363\",\"authors\":[{\"authorId\":\"38236002\",\"name\":\"Deepak Pathak\"},{\"authorId\":\"33932184\",\"name\":\"Pulkit Agrawal\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/CVPRW.2017.70\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"225ab689f41cef1dc18237ef5dab059a49950abf\",\"title\":\"Curiosity-Driven Exploration by Self-Supervised Prediction\",\"url\":\"https://www.semanticscholar.org/paper/225ab689f41cef1dc18237ef5dab059a49950abf\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":\"1712.06560\",\"authors\":[{\"authorId\":\"32577240\",\"name\":\"Edoardo Conti\"},{\"authorId\":\"8309711\",\"name\":\"V. Madhavan\"},{\"authorId\":\"9927844\",\"name\":\"Felipe Petroski Such\"},{\"authorId\":\"39799304\",\"name\":\"Joel Lehman\"},{\"authorId\":\"1846883\",\"name\":\"K. Stanley\"},{\"authorId\":\"2552141\",\"name\":\"J. Clune\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2064020586d5832b55f80a7dffea1fd90a5d94dd\",\"title\":\"Improving Exploration in Evolution Strategies for Deep Reinforcement Learning via a Population of Novelty-Seeking Agents\",\"url\":\"https://www.semanticscholar.org/paper/2064020586d5832b55f80a7dffea1fd90a5d94dd\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39799304\",\"name\":\"Joel Lehman\"},{\"authorId\":\"1846883\",\"name\":\"K. Stanley\"}],\"doi\":\"10.1162/EVCO_a_00025\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0de77eceda6308618132204b28755ac1e63648c5\",\"title\":\"Abandoning Objectives: Evolution Through the Search for Novelty Alone\",\"url\":\"https://www.semanticscholar.org/paper/0de77eceda6308618132204b28755ac1e63648c5\",\"venue\":\"Evolutionary Computation\",\"year\":2011},{\"arxivId\":\"1905.09700\",\"authors\":[{\"authorId\":\"3393407\",\"name\":\"Chen Tessler\"},{\"authorId\":\"3331540\",\"name\":\"T. Zahavy\"},{\"authorId\":\"6097664\",\"name\":\"D. Cohen\"},{\"authorId\":\"3187297\",\"name\":\"Daniel J. Mankowitz\"},{\"authorId\":\"1712535\",\"name\":\"Shie Mannor\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"cedef40a5ddb55fe061523770659a881fce208c5\",\"title\":\"Action Assembly: Sparse Imitation Learning for Text Based Games with Combinatorial Action Spaces\",\"url\":\"https://www.semanticscholar.org/paper/cedef40a5ddb55fe061523770659a881fce208c5\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1908.06556\",\"authors\":[{\"authorId\":\"19179135\",\"name\":\"Prithviraj Ammanabrolu\"},{\"authorId\":\"2757194\",\"name\":\"Mark O. Riedl\"}],\"doi\":\"10.18653/v1/D19-5301\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"77668573e9180b9fe9ae932a5ce9de53c81b045e\",\"title\":\"Transfer in Deep Reinforcement Learning using Knowledge Graphs\",\"url\":\"https://www.semanticscholar.org/paper/77668573e9180b9fe9ae932a5ce9de53c81b045e\",\"venue\":\"TextGraphs@EMNLP\",\"year\":2019},{\"arxivId\":\"1901.10995\",\"authors\":[{\"authorId\":\"66821245\",\"name\":\"Adrien Ecoffet\"},{\"authorId\":\"39378983\",\"name\":\"J. Huizinga\"},{\"authorId\":\"39799304\",\"name\":\"Joel Lehman\"},{\"authorId\":\"1846883\",\"name\":\"K. Stanley\"},{\"authorId\":\"2552141\",\"name\":\"J. Clune\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c520bf47db3360ae3a52219771390a354ed8a91f\",\"title\":\"Go-Explore: a New Approach for Hard-Exploration Problems\",\"url\":\"https://www.semanticscholar.org/paper/c520bf47db3360ae3a52219771390a354ed8a91f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Tim Anderson\"},{\"authorId\":null,\"name\":\"Stu Galley. The history of zork\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"The New Zork Times\",\"url\":\"\",\"venue\":\"4(1-3),\",\"year\":1985},{\"arxivId\":\"1409.3215\",\"authors\":[{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"cea967b59209c6be22829699f05b8b1ac4dc092d\",\"title\":\"Sequence to Sequence Learning with Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/cea967b59209c6be22829699f05b8b1ac4dc092d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"List of text-based computer games\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1730590\",\"name\":\"A. Barto\"}],\"doi\":\"10.1007/978-3-642-32375-1_2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fae8bbf868681b83d91b2fec6c840d4d2b32005b\",\"title\":\"Intrinsic Motivation and Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/fae8bbf868681b83d91b2fec6c840d4d2b32005b\",\"venue\":\"Intrinsically Motivated Learning in Natural and Artificial Systems\",\"year\":2013},{\"arxivId\":\"1401.5390\",\"authors\":[{\"authorId\":\"1741598\",\"name\":\"S. R. K. Branavan\"},{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"1741283\",\"name\":\"R. Barzilay\"}],\"doi\":\"10.1613/jair.3484\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"99f1921a8ba5ceecb18e5ca7ff19b7f95c4e250d\",\"title\":\"Learning to Win by Reading Manuals in a Monte-Carlo Framework\",\"url\":\"https://www.semanticscholar.org/paper/99f1921a8ba5ceecb18e5ca7ff19b7f95c4e250d\",\"venue\":\"ACL\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1804676\",\"name\":\"B. Kr\\u00f6se\"}],\"doi\":\"10.1016/0921-8890(95)00026-C\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"59b50a775542e87f078db35b868ac10ab43d4c75\",\"title\":\"Learning from delayed rewards\",\"url\":\"https://www.semanticscholar.org/paper/59b50a775542e87f078db35b868ac10ab43d4c75\",\"venue\":\"Robotics Auton. Syst.\",\"year\":1995},{\"arxivId\":\"1810.12894\",\"authors\":[{\"authorId\":\"3080409\",\"name\":\"Yuri Burda\"},{\"authorId\":\"144632352\",\"name\":\"H. Edwards\"},{\"authorId\":\"1728216\",\"name\":\"A. Storkey\"},{\"authorId\":\"144538754\",\"name\":\"O. Klimov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4cb3fd057949624aa4f0bbe7a6dcc8777ff04758\",\"title\":\"Exploration by Random Network Distillation\",\"url\":\"https://www.semanticscholar.org/paper/4cb3fd057949624aa4f0bbe7a6dcc8777ff04758\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40410858\",\"name\":\"R. J. Williams\"},{\"authorId\":\"1895771\",\"name\":\"D. Zipser\"}],\"doi\":\"10.1162/neco.1989.1.2.270\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ce9a21b93ba29d4145a8ef6bf401e77f261848de\",\"title\":\"A Learning Algorithm for Continually Running Fully Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/ce9a21b93ba29d4145a8ef6bf401e77f261848de\",\"venue\":\"Neural Computation\",\"year\":1989},{\"arxivId\":\"1812.01628\",\"authors\":[{\"authorId\":\"19179135\",\"name\":\"Prithviraj Ammanabrolu\"},{\"authorId\":\"2757194\",\"name\":\"Mark O. Riedl\"}],\"doi\":\"10.18653/v1/N19-1358\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f3caa43a7016fbbf309d45112b31b20230eaf8da\",\"title\":\"Playing Text-Adventure Games with Graph-Based Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/f3caa43a7016fbbf309d45112b31b20230eaf8da\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":\"1812.03381\",\"authors\":[{\"authorId\":\"2887364\",\"name\":\"Tim Salimans\"},{\"authorId\":\"49565667\",\"name\":\"R. Chen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5d4ebbaa1ef8feeac885e2869f45c0276c18834f\",\"title\":\"Learning Montezuma's Revenge from a Single Demonstration\",\"url\":\"https://www.semanticscholar.org/paper/5d4ebbaa1ef8feeac885e2869f45c0276c18834f\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1703.01732\",\"authors\":[{\"authorId\":\"3381809\",\"name\":\"Joshua Achiam\"},{\"authorId\":\"144797536\",\"name\":\"S. Sastry\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d6757aedcb53142bc439ec64bfd0b056d99b1881\",\"title\":\"Surprise-Based Intrinsic Motivation for Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/d6757aedcb53142bc439ec64bfd0b056d99b1881\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Marc-Alexandre C\\u00f4t\\u00e9\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"First textworld problems: A reinforcement and language learning challenge\",\"url\":\"\",\"venue\":\"NeurIPS Workshop,\",\"year\":2018},{\"arxivId\":\"1707.06347\",\"authors\":[{\"authorId\":\"47971768\",\"name\":\"John Schulman\"},{\"authorId\":\"143909660\",\"name\":\"F. Wolski\"},{\"authorId\":\"6515819\",\"name\":\"Prafulla Dhariwal\"},{\"authorId\":\"38909097\",\"name\":\"A. Radford\"},{\"authorId\":\"144538754\",\"name\":\"O. Klimov\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dce6f9d4017b1785979e7520fd0834ef8cf02f4b\",\"title\":\"Proximal Policy Optimization Algorithms\",\"url\":\"https://www.semanticscholar.org/paper/dce6f9d4017b1785979e7520fd0834ef8cf02f4b\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1812.00855\",\"authors\":[{\"authorId\":\"117899652\",\"name\":\"Ruo Yu Tao\"},{\"authorId\":\"40638665\",\"name\":\"Marc-Alexandre C\\u00f4t\\u00e9\"},{\"authorId\":\"2854297\",\"name\":\"Xingdi Yuan\"},{\"authorId\":\"3349496\",\"name\":\"Layla El Asri\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cf69d946f05b1ecea27b15768701b4edec5da198\",\"title\":\"Towards Solving Text-based Games by Producing Adaptive Action Spaces\",\"url\":\"https://www.semanticscholar.org/paper/cf69d946f05b1ecea27b15768701b4edec5da198\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Karthik Narasimhan\"},{\"authorId\":null,\"name\":\"Tejas Kulkarni\"},{\"authorId\":null,\"name\":\"Regina Barzilay\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Language understanding for textbased games using deep reinforcement learning\",\"url\":\"\",\"venue\":\"arXiv preprint arXiv:1506.08941,\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144497046\",\"name\":\"N. Nilsson\"}],\"doi\":\"10.7551/mitpress/11723.003.0006\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b886f2c097b635ee9550ca29fff7dcbbb7727ff7\",\"title\":\"Artificial Intelligence\",\"url\":\"https://www.semanticscholar.org/paper/b886f2c097b635ee9550ca29fff7dcbbb7727ff7\",\"venue\":\"IFIP Congress\",\"year\":1974},{\"arxivId\":\"2002.08795\",\"authors\":[{\"authorId\":\"19179135\",\"name\":\"Prithviraj Ammanabrolu\"},{\"authorId\":\"1388021064\",\"name\":\"Ethan Tien\"},{\"authorId\":\"7013218\",\"name\":\"Z. Luo\"},{\"authorId\":\"2757194\",\"name\":\"Mark O. Riedl\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c5a90bd8693fdf443b9121d50cd06f926d8df427\",\"title\":\"How To Avoid Being Eaten By a Grue: Exploration Strategies for Text-Adventure Agents\",\"url\":\"https://www.semanticscholar.org/paper/c5a90bd8693fdf443b9121d50cd06f926d8df427\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1709512\",\"name\":\"L. Kaelbling\"},{\"authorId\":\"144885169\",\"name\":\"M. Littman\"},{\"authorId\":\"2453007\",\"name\":\"A. Cassandra\"}],\"doi\":\"10.1016/S0004-3702(98)00023-X\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"116d7798c1123cf7fad4176e98f58fd49de4f8f1\",\"title\":\"Planning and Acting in Partially Observable Stochastic Domains\",\"url\":\"https://www.semanticscholar.org/paper/116d7798c1123cf7fad4176e98f58fd49de4f8f1\",\"venue\":\"Artif. Intell.\",\"year\":1998},{\"arxivId\":\"1806.11525\",\"authors\":[{\"authorId\":\"2854297\",\"name\":\"Xingdi Yuan\"},{\"authorId\":\"40638665\",\"name\":\"Marc-Alexandre C\\u00f4t\\u00e9\"},{\"authorId\":\"2041695\",\"name\":\"Alessandro Sordoni\"},{\"authorId\":\"144100820\",\"name\":\"R. Laroche\"},{\"authorId\":\"15032777\",\"name\":\"Remi Tachet des Combes\"},{\"authorId\":\"3308897\",\"name\":\"Matthew J. Hausknecht\"},{\"authorId\":\"3382568\",\"name\":\"Adam Trischler\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"c52dddfbb4a3af4cc5e72849fe965c62801539e7\",\"title\":\"Counting to Explore and Generalize in Text-based Games\",\"url\":\"https://www.semanticscholar.org/paper/c52dddfbb4a3af4cc5e72849fe965c62801539e7\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1809.02121\",\"authors\":[{\"authorId\":\"3331540\",\"name\":\"T. Zahavy\"},{\"authorId\":\"81427919\",\"name\":\"Matan Haroush\"},{\"authorId\":\"81589010\",\"name\":\"Nadav Merlis\"},{\"authorId\":\"3187297\",\"name\":\"Daniel J. Mankowitz\"},{\"authorId\":\"1712535\",\"name\":\"Shie Mannor\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3219527aa44d7789c2ed842c90bbc6da0eacd527\",\"title\":\"Learn What Not to Learn: Action Elimination with Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/3219527aa44d7789c2ed842c90bbc6da0eacd527\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1906.03926\",\"authors\":[{\"authorId\":\"1818756\",\"name\":\"Jelena Luketina\"},{\"authorId\":\"39683441\",\"name\":\"Nantas Nardelli\"},{\"authorId\":\"38698094\",\"name\":\"Gregory Farquhar\"},{\"authorId\":\"145356667\",\"name\":\"Jakob N. Foerster\"},{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"1864353\",\"name\":\"Edward Grefenstette\"},{\"authorId\":\"1766767\",\"name\":\"S. Whiteson\"},{\"authorId\":\"2620211\",\"name\":\"Tim Rockt\\u00e4schel\"}],\"doi\":\"10.24963/ijcai.2019/880\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7dc156eb9d84ae8fd521ecac5ccc5b5426a42b50\",\"title\":\"A Survey of Reinforcement Learning Informed by Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/7dc156eb9d84ae8fd521ecac5ccc5b5426a42b50\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144716847\",\"name\":\"G. Baldassarre\"},{\"authorId\":\"1805997\",\"name\":\"M. Mirolli\"}],\"doi\":\"10.1007/978-3-642-32375-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a7c8b076bc68a53019dc445079535bc79b7a098a\",\"title\":\"Intrinsically Motivated Learning in Natural and Artificial Systems\",\"url\":\"https://www.semanticscholar.org/paper/a7c8b076bc68a53019dc445079535bc79b7a098a\",\"venue\":\"\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48974230\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1109/IJCNN.1991.170605\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"94db34f4b68189bfcba22beab33ee3b54f10b876\",\"title\":\"Curious model-building control systems\",\"url\":\"https://www.semanticscholar.org/paper/94db34f4b68189bfcba22beab33ee3b54f10b876\",\"venue\":\"[Proceedings] 1991 IEEE International Joint Conference on Neural Networks\",\"year\":1991}],\"title\":\"Exploration Based Language Learning for Text-Based Games\",\"topics\":[{\"topic\":\"Text-based game\",\"topicId\":\"2137259\",\"url\":\"https://www.semanticscholar.org/topic/2137259\"},{\"topic\":\"Text-based (computing)\",\"topicId\":\"75487\",\"url\":\"https://www.semanticscholar.org/topic/75487\"},{\"topic\":\"Testbed\",\"topicId\":\"1705\",\"url\":\"https://www.semanticscholar.org/topic/1705\"},{\"topic\":\"Text corpus\",\"topicId\":\"14829\",\"url\":\"https://www.semanticscholar.org/topic/14829\"},{\"topic\":\"PC game\",\"topicId\":\"43758\",\"url\":\"https://www.semanticscholar.org/topic/43758\"},{\"topic\":\"Intelligent agent\",\"topicId\":\"18636\",\"url\":\"https://www.semanticscholar.org/topic/18636\"},{\"topic\":\"Interaction\",\"topicId\":\"72\",\"url\":\"https://www.semanticscholar.org/topic/72\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Shortest path problem\",\"topicId\":\"28585\",\"url\":\"https://www.semanticscholar.org/topic/28585\"},{\"topic\":\"Complexity\",\"topicId\":\"167521\",\"url\":\"https://www.semanticscholar.org/topic/167521\"},{\"topic\":\"Inventory\",\"topicId\":\"47567\",\"url\":\"https://www.semanticscholar.org/topic/47567\"},{\"topic\":\"Array slicing\",\"topicId\":\"34129\",\"url\":\"https://www.semanticscholar.org/topic/34129\"},{\"topic\":\"Natural language understanding\",\"topicId\":\"18266\",\"url\":\"https://www.semanticscholar.org/topic/18266\"},{\"topic\":\"Problem solving\",\"topicId\":\"3910\",\"url\":\"https://www.semanticscholar.org/topic/3910\"},{\"topic\":\"Natural language generation\",\"topicId\":\"6196\",\"url\":\"https://www.semanticscholar.org/topic/6196\"},{\"topic\":\"Recurrence plot\",\"topicId\":\"321577\",\"url\":\"https://www.semanticscholar.org/topic/321577\"},{\"topic\":\"Map\",\"topicId\":\"2392\",\"url\":\"https://www.semanticscholar.org/topic/2392\"},{\"topic\":\"Action potential\",\"topicId\":\"343\",\"url\":\"https://www.semanticscholar.org/topic/343\"}],\"url\":\"https://www.semanticscholar.org/paper/fce7dfc76d9ddff672cca59d0340bdffcac53bcc\",\"venue\":\"IJCAI\",\"year\":2020}\n"