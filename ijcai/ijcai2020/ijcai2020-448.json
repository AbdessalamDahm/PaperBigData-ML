"{\"abstract\":\"Adaptive gradient methods, which adopt historical gradient information to automatically adjust the learning rate, have been observed to generalize worse than stochastic gradient descent (SGD) with momentum in training deep neural networks. This leaves how to close the generalization gap of adaptive gradient methods an open problem. In this work, we show that adaptive gradient methods such as Adam, Amsgrad, are sometimes \\\"over adapted\\\". We design a new algorithm, called Partially adaptive momentum estimation method (Padam), which unifies the Adam/Amsgrad with SGD to achieve the best from both worlds. Experiments on standard benchmarks show that Padam can maintain fast convergence rate as Adam/Amsgrad while generalizing as well as SGD in training deep neural networks. These results would suggest practitioners pick up adaptive gradient methods once again for faster training of deep neural networks.\",\"arxivId\":\"1806.06763\",\"authors\":[{\"authorId\":\"7557913\",\"name\":\"J. Chen\",\"url\":\"https://www.semanticscholar.org/author/7557913\"},{\"authorId\":\"9937103\",\"name\":\"Quanquan Gu\",\"url\":\"https://www.semanticscholar.org/author/9937103\"}],\"citationVelocity\":22,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"3069351\",\"name\":\"Qianqian Tong\"},{\"authorId\":\"46400517\",\"name\":\"G. Liang\"},{\"authorId\":\"38370684\",\"name\":\"J. Bi\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"bff7f7265f0f378191b529f0405ab8c531ae7af4\",\"title\":\"Calibrating the Adaptive Learning Rate to Improve Convergence of ADAM\",\"url\":\"https://www.semanticscholar.org/paper/bff7f7265f0f378191b529f0405ab8c531ae7af4\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40381920\",\"name\":\"Tianbao Yang\"}],\"doi\":\"10.1145/3362077.3362085\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"463fb095c1bb789f46c3a78cc90debb9c0e73de7\",\"title\":\"Advancing non-convex and constrained learning: challenges and opportunities\",\"url\":\"https://www.semanticscholar.org/paper/463fb095c1bb789f46c3a78cc90debb9c0e73de7\",\"venue\":\"SIGAI\",\"year\":2019},{\"arxivId\":\"2011.08042\",\"authors\":[{\"authorId\":\"1387994112\",\"name\":\"Nicola Landro\"},{\"authorId\":\"145116184\",\"name\":\"I. Gallo\"},{\"authorId\":\"51475116\",\"name\":\"R. L. Grassa\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"dfb77e0357e3d0bba999be38e9f2f568c0e73a32\",\"title\":\"Mixing ADAM and SGD: a Combined Optimization Method\",\"url\":\"https://www.semanticscholar.org/paper/dfb77e0357e3d0bba999be38e9f2f568c0e73a32\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1808.05671\",\"authors\":[{\"authorId\":\"35972566\",\"name\":\"Dongruo Zhou\"},{\"authorId\":\"8801557\",\"name\":\"Yiqi Tang\"},{\"authorId\":\"34688508\",\"name\":\"Ziyan Yang\"},{\"authorId\":\"145144023\",\"name\":\"Yuan Cao\"},{\"authorId\":\"9937103\",\"name\":\"Quanquan Gu\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"551505614e025831a80c2d67bd854b1441eac03c\",\"title\":\"On the Convergence of Adaptive Gradient Methods for Nonconvex Optimization\",\"url\":\"https://www.semanticscholar.org/paper/551505614e025831a80c2d67bd854b1441eac03c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2006.09091\",\"authors\":[{\"authorId\":\"10746977\",\"name\":\"Diego Granziol\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b3baba078bc2f56c3e4a685ef7f4e6389dcdd930\",\"title\":\"Flatness is a False Friend\",\"url\":\"https://www.semanticscholar.org/paper/b3baba078bc2f56c3e4a685ef7f4e6389dcdd930\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1910.06513\",\"authors\":[{\"authorId\":\"49794558\",\"name\":\"X. Chen\"},{\"authorId\":\"143743061\",\"name\":\"Sijia Liu\"},{\"authorId\":\"46321210\",\"name\":\"Kaidi Xu\"},{\"authorId\":\"92384926\",\"name\":\"Xingguo Li\"},{\"authorId\":\"153201114\",\"name\":\"X. Lin\"},{\"authorId\":\"1793717\",\"name\":\"M. Hong\"},{\"authorId\":\"33894281\",\"name\":\"D. Cox\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"95d87c3eece7e3f48a8377cdbe2a0d357e8a5c8b\",\"title\":\"ZO-AdaMM: Zeroth-Order Adaptive Momentum Method for Black-Box Optimization\",\"url\":\"https://www.semanticscholar.org/paper/95d87c3eece7e3f48a8377cdbe2a0d357e8a5c8b\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"2011.08181\",\"authors\":[{\"authorId\":\"10746977\",\"name\":\"Diego Granziol\"},{\"authorId\":\"7641268\",\"name\":\"Samuel Albanie\"},{\"authorId\":\"1470501980\",\"name\":\"Xingchen Wan\"},{\"authorId\":\"145029236\",\"name\":\"S. Roberts\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7250303cead51f060ab665a3bf19cf4daa6fa136\",\"title\":\"Explaining the Adaptive Generalisation Gap\",\"url\":\"https://www.semanticscholar.org/paper/7250303cead51f060ab665a3bf19cf4daa6fa136\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1908.00700\",\"authors\":[{\"authorId\":\"3069351\",\"name\":\"Qianqian Tong\"},{\"authorId\":\"46400517\",\"name\":\"G. Liang\"},{\"authorId\":\"38370684\",\"name\":\"J. Bi\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"90752cc15cc80cdf7efb38fac52f62bcdda8442c\",\"title\":\"Calibrating the Learning Rate for Adaptive Gradient Methods to Improve Generalization Performance\",\"url\":\"https://www.semanticscholar.org/paper/90752cc15cc80cdf7efb38fac52f62bcdda8442c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1905.09899\",\"authors\":[{\"authorId\":\"40474289\",\"name\":\"Shuai Zheng\"},{\"authorId\":\"145193332\",\"name\":\"James T. Kwok\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"55403aa348bde7e445e3710a64833b2ce9a0a71b\",\"title\":\"Blockwise Adaptivity: Faster Training and Better Generalization in Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/55403aa348bde7e445e3710a64833b2ce9a0a71b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47740605\",\"name\":\"Juza Chen\"},{\"authorId\":\"3393746\",\"name\":\"Anastasios Kyrillidis\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b046630d88e25c5da0adbe08f8353cb8760f9b8f\",\"title\":\"D ECAYING MOMENTUM HELPS NEURAL NETWORK TRAINING\",\"url\":\"https://www.semanticscholar.org/paper/b046630d88e25c5da0adbe08f8353cb8760f9b8f\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"80246865\",\"name\":\"Anas Barakat\"},{\"authorId\":\"48362308\",\"name\":\"P. Bianchi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fd98f44c48a7d7aa636a224561db28343da83573\",\"title\":\"Convergence Rates of a Momentum Algorithm with Bounded Adaptive Step Size for Nonconvex Optimization\",\"url\":\"https://www.semanticscholar.org/paper/fd98f44c48a7d7aa636a224561db28343da83573\",\"venue\":\"ACML\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47740605\",\"name\":\"Juza Chen\"},{\"authorId\":\"3393746\",\"name\":\"Anastasios Kyrillidis\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d24041dfe45489fa055ce5fa4c04970cbce525ae\",\"title\":\"Decaying momentum helps neural network training\",\"url\":\"https://www.semanticscholar.org/paper/d24041dfe45489fa055ce5fa4c04970cbce525ae\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145913712\",\"name\":\"J. Horv\\u00e1th\"},{\"authorId\":\"9522576\",\"name\":\"David Guera\"},{\"authorId\":\"35814486\",\"name\":\"S. K. Yarlagadda\"},{\"authorId\":\"2794131\",\"name\":\"Paolo Bestagini\"},{\"authorId\":\"36061766\",\"name\":\"F. Zhu\"},{\"authorId\":\"1729506\",\"name\":\"S. Tubaro\"},{\"authorId\":\"40434144\",\"name\":\"E. J. Delp\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7ce831a605d62bf50d161cc23d4190c8cd9aba78\",\"title\":\"Anomaly-Based Manipulation Detection in Satellite Images\",\"url\":\"https://www.semanticscholar.org/paper/7ce831a605d62bf50d161cc23d4190c8cd9aba78\",\"venue\":\"CVPR Workshops\",\"year\":2019},{\"arxivId\":\"2006.06958\",\"authors\":[{\"authorId\":\"1471721095\",\"name\":\"Seyed Iman Mirzadeh\"},{\"authorId\":\"1401914937\",\"name\":\"Mehrdad Farajtabar\"},{\"authorId\":\"1996134\",\"name\":\"Razvan Pascanu\"},{\"authorId\":\"144600887\",\"name\":\"H. Ghasemzadeh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"17b8a0ccb2a9450906fa3ea38ed0435b8006397d\",\"title\":\"Understanding the Role of Training Regimes in Continual Learning\",\"url\":\"https://www.semanticscholar.org/paper/17b8a0ccb2a9450906fa3ea38ed0435b8006397d\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"103976698\",\"name\":\"Marija Habijan\"},{\"authorId\":\"31357089\",\"name\":\"Hrvoje Leventic\"},{\"authorId\":\"37945289\",\"name\":\"I. Galic\"},{\"authorId\":\"46784441\",\"name\":\"D. Babin\"}],\"doi\":\"10.1109/IWSSIP.2019.8787253\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ae4e7e2274b0d018867e7715c6747c7296aa0c10\",\"title\":\"Whole Heart Segmentation from CT images Using 3D U-Net architecture\",\"url\":\"https://www.semanticscholar.org/paper/ae4e7e2274b0d018867e7715c6747c7296aa0c10\",\"venue\":\"2019 International Conference on Systems, Signals and Image Processing (IWSSIP)\",\"year\":2019},{\"arxivId\":\"2006.07065\",\"authors\":[{\"authorId\":\"22640218\",\"name\":\"Xunpeng Huang\"},{\"authorId\":\"1748844142\",\"name\":\"Runxin Xu\"},{\"authorId\":null,\"name\":\"Hao Zhou\"},{\"authorId\":\"1521319166\",\"name\":\"Zhe Wang\"},{\"authorId\":\"40004423\",\"name\":\"Zheng-Yang Liu\"},{\"authorId\":null,\"name\":\"Lei Li\"}],\"doi\":null,\"intent\":[\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"efe0af196c18abea1db1e28b7c78dd30c4437585\",\"title\":\"ACMo: Angle-Calibrated Moment Methods for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/efe0af196c18abea1db1e28b7c78dd30c4437585\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1902.04620\",\"authors\":[{\"authorId\":\"49794715\",\"name\":\"Xinyi Chen\"},{\"authorId\":\"3332636\",\"name\":\"Naman Agarwal\"},{\"authorId\":\"34840427\",\"name\":\"Elad Hazan\"},{\"authorId\":\"15943185\",\"name\":\"Cyril Zhang\"},{\"authorId\":\"39939149\",\"name\":\"Y. Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"423c0246d016b092b131132dca8249c3faacd000\",\"title\":\"Extreme Tensoring for Low-Memory Preconditioning\",\"url\":\"https://www.semanticscholar.org/paper/423c0246d016b092b131132dca8249c3faacd000\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"88d27152ce75c67ef9b819174042a55d914d468f\",\"title\":\"ACUTUM: WHEN GENERALIZATION MEETS ADAPT-\",\"url\":\"https://www.semanticscholar.org/paper/88d27152ce75c67ef9b819174042a55d914d468f\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2003.01247\",\"authors\":[{\"authorId\":\"10746977\",\"name\":\"Diego Granziol\"},{\"authorId\":\"1470501980\",\"name\":\"Xingchen Wan\"},{\"authorId\":\"143841496\",\"name\":\"Stephen Roberts\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a0c0a9e3f23b73d8fdb4e295060fe216483659ef\",\"title\":\"Iterate Averaging Helps: An Alternative Perspective in Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/a0c0a9e3f23b73d8fdb4e295060fe216483659ef\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32564459\",\"name\":\"Rachel Ward\"},{\"authorId\":\"39851229\",\"name\":\"X. Wu\"},{\"authorId\":\"52184096\",\"name\":\"L. Bottou\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"33b2e7cb9c3d3cc902a8cd5118862815d406d31a\",\"title\":\"AdaGrad stepsizes: sharp convergence over nonconvex landscapes\",\"url\":\"https://www.semanticscholar.org/paper/33b2e7cb9c3d3cc902a8cd5118862815d406d31a\",\"venue\":\"ICML\",\"year\":2019},{\"arxivId\":\"1811.00576\",\"authors\":[{\"authorId\":\"1398587430\",\"name\":\"J. Thierry-Mieg\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"deb7c539ec40d03ff38712bcea2409c7bccf5b9e\",\"title\":\"How the fundamental concepts of mathematics and physics explain deep learning\",\"url\":\"https://www.semanticscholar.org/paper/deb7c539ec40d03ff38712bcea2409c7bccf5b9e\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1901.09847\",\"authors\":[{\"authorId\":\"40911632\",\"name\":\"Sai Praneeth Karimireddy\"},{\"authorId\":\"66792975\",\"name\":\"Quentin Rebjock\"},{\"authorId\":\"2127057\",\"name\":\"S. Stich\"},{\"authorId\":\"2456863\",\"name\":\"M. Jaggi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7c22a6a07e89461178b794681c675b209332ee15\",\"title\":\"Error Feedback Fixes SignSGD and other Gradient Compression Schemes\",\"url\":\"https://www.semanticscholar.org/paper/7c22a6a07e89461178b794681c675b209332ee15\",\"venue\":\"ICML\",\"year\":2019},{\"arxivId\":\"2003.01247\",\"authors\":[{\"authorId\":\"10746977\",\"name\":\"Diego Granziol\"},{\"authorId\":\"1470501980\",\"name\":\"Xingchen Wan\"},{\"authorId\":\"143841496\",\"name\":\"Stephen Roberts\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f3342dffd279cee7382f2f4034fdd99d099aaf86\",\"title\":\"Gadam: Combining Adaptivity with Iterate Averaging Gives Greater Generalisation\",\"url\":\"https://www.semanticscholar.org/paper/f3342dffd279cee7382f2f4034fdd99d099aaf86\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10785490\",\"name\":\"H. Zhong\"},{\"authorId\":\"2424252\",\"name\":\"Zaiyi Chen\"},{\"authorId\":\"48753416\",\"name\":\"C. Qin\"},{\"authorId\":\"145863758\",\"name\":\"Zai Huang\"},{\"authorId\":\"3113725\",\"name\":\"V. Zheng\"},{\"authorId\":\"41157498\",\"name\":\"T. Xu\"},{\"authorId\":\"144378760\",\"name\":\"E. Chen\"}],\"doi\":\"10.1007/s11704-019-8457-x\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ce7d06bcf254f1b5c28b867cd55165f94db09135\",\"title\":\"Adam revisited: a weighted past gradients perspective\",\"url\":\"https://www.semanticscholar.org/paper/ce7d06bcf254f1b5c28b867cd55165f94db09135\",\"venue\":\"Frontiers of Computer Science\",\"year\":2020},{\"arxivId\":\"2010.06808\",\"authors\":[{\"authorId\":\"91348936\",\"name\":\"Z. Chen\"},{\"authorId\":\"2020608\",\"name\":\"J. Ngiam\"},{\"authorId\":\"35064193\",\"name\":\"Y. Huang\"},{\"authorId\":\"1821711\",\"name\":\"Thang Luong\"},{\"authorId\":\"34699489\",\"name\":\"Henrik Kretzschmar\"},{\"authorId\":\"34858254\",\"name\":\"Y. Chai\"},{\"authorId\":\"1838674\",\"name\":\"Dragomir Anguelov\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"de7c79528c1cdad734b363d92b35ee189f1e3ef5\",\"title\":\"Just Pick a Sign: Optimizing Deep Multitask Models with Gradient Sign Dropout\",\"url\":\"https://www.semanticscholar.org/paper/de7c79528c1cdad734b363d92b35ee189f1e3ef5\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2011.11152\",\"authors\":[{\"authorId\":\"30014947\",\"name\":\"Zeke Xie\"},{\"authorId\":\"3104768\",\"name\":\"I. Sato\"},{\"authorId\":\"153116539\",\"name\":\"M. Sugiyama\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3a784727363aa3f09fb256e4ff9b4e1bae086b87\",\"title\":\"Stable Weight Decay Regularization\",\"url\":\"https://www.semanticscholar.org/paper/3a784727363aa3f09fb256e4ff9b4e1bae086b87\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1904.01367\",\"authors\":[{\"authorId\":\"51209425\",\"name\":\"Fengxiang He\"},{\"authorId\":\"1685106\",\"name\":\"T. Liu\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/TNNLS.2020.2966319\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ebf9cb4e9e59ad1b50781dee168a5fc74cb8dde3\",\"title\":\"Why ResNet Works? Residuals Generalize\",\"url\":\"https://www.semanticscholar.org/paper/ebf9cb4e9e59ad1b50781dee168a5fc74cb8dde3\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2020},{\"arxivId\":\"2006.15815\",\"authors\":[{\"authorId\":\"30014947\",\"name\":\"Zeke Xie\"},{\"authorId\":\"122024096\",\"name\":\"Xinrui Wang\"},{\"authorId\":\"2973831\",\"name\":\"Huishuai Zhang\"},{\"authorId\":\"3104768\",\"name\":\"I. Sato\"},{\"authorId\":\"153116539\",\"name\":\"M. Sugiyama\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3f6a7fffbf3c96c99743f1e01f8dd86d9a9851fa\",\"title\":\"Adai: Separating the Effects of Adaptive Learning Rate and Momentum Inertia\",\"url\":\"https://www.semanticscholar.org/paper/3f6a7fffbf3c96c99743f1e01f8dd86d9a9851fa\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1398587430\",\"name\":\"J. Thierry-Mieg\"}],\"doi\":\"10.31526/lhep.3.2019.110\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4b6366c48a9c4a097542827de0efab7d9c9c6b5a\",\"title\":\"Connections between physics, mathematics and deep learning\",\"url\":\"https://www.semanticscholar.org/paper/4b6366c48a9c4a097542827de0efab7d9c9c6b5a\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2006.16541\",\"authors\":[{\"authorId\":\"3381089\",\"name\":\"J. Wang\"},{\"authorId\":\"38556322\",\"name\":\"J. Wiens\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0344f777445295de3492d830eda0f7db17284c31\",\"title\":\"AdaSGD: Bridging the gap between SGD and Adam\",\"url\":\"https://www.semanticscholar.org/paper/0344f777445295de3492d830eda0f7db17284c31\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1902.07111\",\"authors\":[{\"authorId\":\"39851229\",\"name\":\"X. Wu\"},{\"authorId\":\"145697585\",\"name\":\"S. Du\"},{\"authorId\":\"32564459\",\"name\":\"Rachel Ward\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"73f4922eef752635efa2ba6500a528ba96f0a4fe\",\"title\":\"Global Convergence of Adaptive Gradient Methods for An Over-parameterized Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/73f4922eef752635efa2ba6500a528ba96f0a4fe\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Waymo\"},{\"authorId\":\"65812453\",\"name\":\"Mountain View\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a599a0fadbaf03e31374f0062d78dbbb4a3365f4\",\"title\":\"Just Pick a Sign: Optimizing Deep Multitask Models with Gradient Sign Dropout\",\"url\":\"https://www.semanticscholar.org/paper/a599a0fadbaf03e31374f0062d78dbbb4a3365f4\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2006.11918\",\"authors\":[{\"authorId\":\"1431754650\",\"name\":\"C. Zhu\"},{\"authorId\":\"5524736\",\"name\":\"Y. Cheng\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"40070055\",\"name\":\"F. Huang\"},{\"authorId\":\"46700348\",\"name\":\"Jing-jing Liu\"},{\"authorId\":\"69486855\",\"name\":\"T. Goldstein\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9d3f9ae531ded4c5ac4a36cfb7565446cebe0d53\",\"title\":\"Adaptive Learning Rates with Maximum Variation Averaging\",\"url\":\"https://www.semanticscholar.org/paper/9d3f9ae531ded4c5ac4a36cfb7565446cebe0d53\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1902.09030\",\"authors\":[{\"authorId\":\"46172209\",\"name\":\"Guoqiang Zhang\"},{\"authorId\":\"48341306\",\"name\":\"Kenta Niwa\"},{\"authorId\":\"144015910\",\"name\":\"W. Kleijn\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"aad536aca9a9e9daef829e6c7ee79e6ec08d4b5b\",\"title\":\"Rapidly Adapting Moment Estimation\",\"url\":\"https://www.semanticscholar.org/paper/aad536aca9a9e9daef829e6c7ee79e6ec08d4b5b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2001.06130\",\"authors\":[{\"authorId\":\"65772187\",\"name\":\"Bingxin Zhou\"},{\"authorId\":\"47410668\",\"name\":\"Xuebin Zheng\"},{\"authorId\":\"121495365\",\"name\":\"Junbin Gao\"}],\"doi\":\"10.1109/IJCNN48605.2020.9207166\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"84ddf042c4027aec0221eae1616dd3961829e44b\",\"title\":\"On the Trend-corrected Variant of Adaptive Stochastic Optimization Methods\",\"url\":\"https://www.semanticscholar.org/paper/84ddf042c4027aec0221eae1616dd3961829e44b\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":\"1905.13545\",\"authors\":[{\"authorId\":\"3669925\",\"name\":\"Haohan Wang\"},{\"authorId\":\"144234489\",\"name\":\"Xindi Wu\"},{\"authorId\":\"38253388\",\"name\":\"Pengcheng Yin\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":\"10.1109/cvpr42600.2020.00871\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bceeb52a9d4a4127d6664eea4870e8a60b378eff\",\"title\":\"High-Frequency Component Helps Explain the Generalization of Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/bceeb52a9d4a4127d6664eea4870e8a60b378eff\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1908.03265\",\"authors\":[{\"authorId\":\"46458310\",\"name\":\"Liyuan Liu\"},{\"authorId\":\"5795999\",\"name\":\"Haoming Jiang\"},{\"authorId\":\"50462546\",\"name\":\"Pengcheng He\"},{\"authorId\":\"7307263\",\"name\":\"W. Chen\"},{\"authorId\":\"46522098\",\"name\":\"Xiaodong Liu\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"122203801\",\"name\":\"J. Han\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5759a53418ae3fe74ce96c531617914e7656e45e\",\"title\":\"On the Variance of the Adaptive Learning Rate and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/5759a53418ae3fe74ce96c531617914e7656e45e\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"2002.09095\",\"authors\":[{\"authorId\":\"47104078\",\"name\":\"Yangyang Xu\"},{\"authorId\":\"1500723293\",\"name\":\"Colin Sutcher-Shepard\"},{\"authorId\":\"50126206\",\"name\":\"Yibo Xu\"},{\"authorId\":\"50762898\",\"name\":\"Jie Chen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1f559cb16b729a43f350128b699bc4fd8906cab0\",\"title\":\"Asynchronous parallel adaptive stochastic gradient methods\",\"url\":\"https://www.semanticscholar.org/paper/1f559cb16b729a43f350128b699bc4fd8906cab0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1910.04209\",\"authors\":[{\"authorId\":\"30529616\",\"name\":\"J. Ma\"},{\"authorId\":\"13759615\",\"name\":\"Denis Yarats\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2a48d2b673689e4434fc6b86965ca2a91bb40103\",\"title\":\"On the adequacy of untuned warmup for adaptive optimization\",\"url\":\"https://www.semanticscholar.org/paper/2a48d2b673689e4434fc6b86965ca2a91bb40103\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1904.03590\",\"authors\":[{\"authorId\":\"145847724\",\"name\":\"P. Tran\"},{\"authorId\":\"1694373\",\"name\":\"L. Phong\"}],\"doi\":\"10.1109/ACCESS.2019.2916341\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e2c85b69f5095b43c4f877e8998ac9c52dbee7e0\",\"title\":\"On the Convergence Proof of AMSGrad and a New Version\",\"url\":\"https://www.semanticscholar.org/paper/e2c85b69f5095b43c4f877e8998ac9c52dbee7e0\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1907.04595\",\"authors\":[{\"authorId\":\"2205248\",\"name\":\"Y. Li\"},{\"authorId\":\"3460405\",\"name\":\"Colin Wei\"},{\"authorId\":\"1901958\",\"name\":\"Tengyu Ma\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"36451fe94b7b1f978b8301cf3f7305566bd3b454\",\"title\":\"Towards Explaining the Regularization Effect of Initial Large Learning Rate in Training Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/36451fe94b7b1f978b8301cf3f7305566bd3b454\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1805.07557\",\"authors\":[{\"authorId\":\"11637809\",\"name\":\"H. Huang\"},{\"authorId\":\"144121913\",\"name\":\"C. Wang\"},{\"authorId\":\"39131579\",\"name\":\"Bin Dong\"}],\"doi\":\"10.24963/ijcai.2019/355\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"092e84c89dae16d99cd70648a781479c34006bf4\",\"title\":\"Nostalgic Adam: Weighing more of the past gradients when designing the adaptive learning rate\",\"url\":\"https://www.semanticscholar.org/paper/092e84c89dae16d99cd70648a781479c34006bf4\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"2001.07685\",\"authors\":[{\"authorId\":\"1729571\",\"name\":\"Kihyuk Sohn\"},{\"authorId\":\"39835551\",\"name\":\"David Berthelot\"},{\"authorId\":\"2088535\",\"name\":\"C. Li\"},{\"authorId\":\"2476328\",\"name\":\"Zizhao Zhang\"},{\"authorId\":\"39907737\",\"name\":\"N. Carlini\"},{\"authorId\":\"145071362\",\"name\":\"E. D. Cubuk\"},{\"authorId\":\"146108827\",\"name\":\"Alex Kurakin\"},{\"authorId\":\"120811666\",\"name\":\"Han Zhang\"},{\"authorId\":\"2402716\",\"name\":\"Colin Raffel\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"299847adf3ee558a760475ffa364facac3ebbb16\",\"title\":\"FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence\",\"url\":\"https://www.semanticscholar.org/paper/299847adf3ee558a760475ffa364facac3ebbb16\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"1910.11758\",\"authors\":[{\"authorId\":\"1399665689\",\"name\":\"Prabhu Teja Sivaprasad\"},{\"authorId\":\"38777433\",\"name\":\"Florian Mai\"},{\"authorId\":\"39110714\",\"name\":\"Thijs Vogels\"},{\"authorId\":\"2456863\",\"name\":\"M. Jaggi\"},{\"authorId\":\"1573113868\",\"name\":\"Franccois Fleuret Idiap Research Institute\"},{\"authorId\":\"70658858\",\"name\":\"Epfl\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"12c52f8c8d8b08bee00a004b1c05ad5b7af19e26\",\"title\":\"Optimizer Benchmarking Needs to Account for Hyperparameter Tuning\",\"url\":\"https://www.semanticscholar.org/paper/12c52f8c8d8b08bee00a004b1c05ad5b7af19e26\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":\"2012.04002\",\"authors\":[{\"authorId\":\"80246865\",\"name\":\"A. Barakat\"},{\"authorId\":\"9795551\",\"name\":\"P. Bianchi\"},{\"authorId\":\"1742654\",\"name\":\"W. Hachem\"},{\"authorId\":\"2033389182\",\"name\":\"Sh. Schechtman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bbe1fa3fc1d7151a01c110b98f6c484b19001657\",\"title\":\"Stochastic optimization with momentum: convergence, fluctuations, and traps avoidance\",\"url\":\"https://www.semanticscholar.org/paper/bbe1fa3fc1d7151a01c110b98f6c484b19001657\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1911.06913\",\"authors\":[{\"authorId\":\"9080059\",\"name\":\"K. Yuksel\"},{\"authorId\":\"104580002\",\"name\":\"J. Goschenhofer\"},{\"authorId\":\"1413271829\",\"name\":\"H. V. Varma\"},{\"authorId\":\"3167491\",\"name\":\"U. Fietzek\"},{\"authorId\":\"1412967756\",\"name\":\"Franz M.J. Pfister\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d32cea8912a94242454a5d5376a0b08e166a47d2\",\"title\":\"Granular Motor State Monitoring of Free Living Parkinson's Disease Patients via Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/d32cea8912a94242454a5d5376a0b08e166a47d2\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2004.09740\",\"authors\":[{\"authorId\":\"50135338\",\"name\":\"Wen-Jie Li\"},{\"authorId\":\"38122172\",\"name\":\"Zhaoyang Zhang\"},{\"authorId\":\"48630464\",\"name\":\"Xinjiang Wang\"},{\"authorId\":\"145287455\",\"name\":\"Ping Luo\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c7ab6660706c2010df1f1a45780ae2871ab97149\",\"title\":\"AdaX: Adaptive Gradient Descent with Exponential Long Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/c7ab6660706c2010df1f1a45780ae2871ab97149\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.09729\",\"authors\":[{\"authorId\":\"29879678\",\"name\":\"Ahmet Alacaoglu\"},{\"authorId\":\"41158157\",\"name\":\"Yura Malitsky\"},{\"authorId\":\"1844925\",\"name\":\"P. Mertikopoulos\"},{\"authorId\":\"1678641\",\"name\":\"V. Cevher\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"59600463ca4f6b5d02900022b29b6de278154c6b\",\"title\":\"A new regret analysis for Adam-type algorithms\",\"url\":\"https://www.semanticscholar.org/paper/59600463ca4f6b5d02900022b29b6de278154c6b\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":\"2010.07468\",\"authors\":[{\"authorId\":\"46251934\",\"name\":\"Juntang Zhuang\"},{\"authorId\":\"1895919\",\"name\":\"T. Tang\"},{\"authorId\":\"1571173988\",\"name\":\"Yifan Ding\"},{\"authorId\":\"1688323\",\"name\":\"S. Tatikonda\"},{\"authorId\":\"5507046\",\"name\":\"N. Dvornek\"},{\"authorId\":\"1932911\",\"name\":\"X. Papademetris\"},{\"authorId\":\"145947161\",\"name\":\"J. Duncan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"7dfa2c8025982ab10f8031e6b79c6f9d24d825ee\",\"title\":\"AdaBelief Optimizer: Adapting Stepsizes by the Belief in Observed Gradients\",\"url\":\"https://www.semanticscholar.org/paper/7dfa2c8025982ab10f8031e6b79c6f9d24d825ee\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1399665689\",\"name\":\"Prabhu Teja Sivaprasad\"},{\"authorId\":\"38777433\",\"name\":\"Florian Mai\"},{\"authorId\":\"39110714\",\"name\":\"Thijs Vogels\"},{\"authorId\":\"2456863\",\"name\":\"M. Jaggi\"},{\"authorId\":\"2721983\",\"name\":\"F. Fleuret\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"07891dfdbc6b6f56788a1c7b95362eb82dfed563\",\"title\":\"On the Tunability of Optimizers in Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/07891dfdbc6b6f56788a1c7b95362eb82dfed563\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1906.08676\",\"authors\":[{\"authorId\":\"3401548\",\"name\":\"Adam Byerly\"},{\"authorId\":\"1740183\",\"name\":\"T. Kalganova\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c9bebe9418f7603042a4c7dcc20415004b1cbbd\",\"title\":\"Homogeneous Vector Capsules Enable Adaptive Gradient Descent in Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/1c9bebe9418f7603042a4c7dcc20415004b1cbbd\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1910.10094\",\"authors\":[{\"authorId\":\"153035882\",\"name\":\"P. Melchior\"},{\"authorId\":\"144193124\",\"name\":\"R. Joseph\"},{\"authorId\":\"23973519\",\"name\":\"Fred Moolekamp\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7f6d75f48e651b093ba3e61db9c3ef4d50d4d1b1\",\"title\":\"Proximal Adam: Robust Adaptive Update Scheme for Constrained Optimization\",\"url\":\"https://www.semanticscholar.org/paper/7f6d75f48e651b093ba3e61db9c3ef4d50d4d1b1\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1906.05661\",\"authors\":[{\"authorId\":\"48092709\",\"name\":\"L. Berrada\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"},{\"authorId\":\"3717791\",\"name\":\"M. Kumar\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"865031747807d12f0a10d6db1f7cab40e9549f8e\",\"title\":\"Training Neural Networks for and by Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/865031747807d12f0a10d6db1f7cab40e9549f8e\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":\"1808.02941\",\"authors\":[{\"authorId\":\"2347508\",\"name\":\"Xiangyi Chen\"},{\"authorId\":\"143743061\",\"name\":\"Sijia Liu\"},{\"authorId\":\"39447572\",\"name\":\"Ruoyu Sun\"},{\"authorId\":\"1793717\",\"name\":\"M. Hong\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e60dd237328bc92941e0559ab358e6186cdd41de\",\"title\":\"On the Convergence of A Class of Adam-Type Algorithms for Non-Convex Optimization\",\"url\":\"https://www.semanticscholar.org/paper/e60dd237328bc92941e0559ab358e6186cdd41de\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"2006.06650\",\"authors\":[{\"authorId\":\"29879678\",\"name\":\"Ahmet Alacaoglu\"},{\"authorId\":\"41158157\",\"name\":\"Yura Malitsky\"},{\"authorId\":\"1678641\",\"name\":\"V. Cevher\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb9528b0a5dec97a2a991c33a41b32b63b561629\",\"title\":\"Convergence of adaptive algorithms for weakly convex constrained optimization\",\"url\":\"https://www.semanticscholar.org/paper/eb9528b0a5dec97a2a991c33a41b32b63b561629\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1905.02957\",\"authors\":[{\"authorId\":\"48738375\",\"name\":\"G. Wang\"},{\"authorId\":\"15825779\",\"name\":\"Shiyin Lu\"},{\"authorId\":\"13934136\",\"name\":\"Wei-Wei Tu\"},{\"authorId\":\"48571674\",\"name\":\"L. Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f47f26e500f190b13f989e0dbe56f49f3bc4c260\",\"title\":\"SAdam: A Variant of Adam for Strongly Convex Functions\",\"url\":\"https://www.semanticscholar.org/paper/f47f26e500f190b13f989e0dbe56f49f3bc4c260\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"2002.11803\",\"authors\":[{\"authorId\":\"3332636\",\"name\":\"Naman Agarwal\"},{\"authorId\":\"1508890387\",\"name\":\"R. Anil\"},{\"authorId\":\"34840427\",\"name\":\"Elad Hazan\"},{\"authorId\":\"1711492\",\"name\":\"T. Koren\"},{\"authorId\":\"15943185\",\"name\":\"Cyril Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"08b7e1515b4244ebc96995f9adb8f01c85d26abb\",\"title\":\"Disentangling Adaptive Gradient Methods from Learning Rates\",\"url\":\"https://www.semanticscholar.org/paper/08b7e1515b4244ebc96995f9adb8f01c85d26abb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1910.04952\",\"authors\":[{\"authorId\":\"101777490\",\"name\":\"J. Chen\"},{\"authorId\":\"34210029\",\"name\":\"Cameron R. Wolfe\"},{\"authorId\":\"72239469\",\"name\":\"Z. Li\"},{\"authorId\":\"3393746\",\"name\":\"Anastasios Kyrillidis\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"38eaa92a84543cbd01676295263eaee405a3dc0c\",\"title\":\"Demon: Momentum Decay for Improved Neural Network Training.\",\"url\":\"https://www.semanticscholar.org/paper/38eaa92a84543cbd01676295263eaee405a3dc0c\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2010.11041\",\"authors\":[{\"authorId\":\"1790510695\",\"name\":\"Jie Liu\"},{\"authorId\":\"5739094\",\"name\":\"Chen Lin\"},{\"authorId\":\"114282346\",\"name\":\"Chuming Li\"},{\"authorId\":\"84200540\",\"name\":\"Lu Sheng\"},{\"authorId\":\"152669122\",\"name\":\"Ming Sun\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"bc84178c6b4b19490fb31815c2c15439337a2c89\",\"title\":\"Adaptive Gradient Method with Resilience and Momentum\",\"url\":\"https://www.semanticscholar.org/paper/bc84178c6b4b19490fb31815c2c15439337a2c89\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46256707\",\"name\":\"Qunyong Yuan\"},{\"authorId\":\"2410423\",\"name\":\"N. Xiao\"}],\"doi\":\"10.1002/ima.22434\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cfb3263ba988a40bcbfe55ccb8de08dc334412a5\",\"title\":\"Experimental exploration on loss surface of deep neural network\",\"url\":\"https://www.semanticscholar.org/paper/cfb3263ba988a40bcbfe55ccb8de08dc334412a5\",\"venue\":\"Int. J. Imaging Syst. Technol.\",\"year\":2020},{\"arxivId\":\"2002.04839\",\"authors\":[{\"authorId\":\"12907562\",\"name\":\"Liu Ziyin\"},{\"authorId\":\"1844276615\",\"name\":\"Zhikang T.Wang\"},{\"authorId\":\"2815318\",\"name\":\"Masahito Ueda\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"15ff1ef32bf3711f68a5cdb57638cea779f583d7\",\"title\":\"LaProp: Separating Momentum and Adaptivity in Adam\",\"url\":\"https://www.semanticscholar.org/paper/15ff1ef32bf3711f68a5cdb57638cea779f583d7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1806.01811\",\"authors\":[{\"authorId\":\"32564459\",\"name\":\"Rachel Ward\"},{\"authorId\":\"39851229\",\"name\":\"X. Wu\"},{\"authorId\":\"52184096\",\"name\":\"L. Bottou\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7ce464e2505d1a086612d41a10429393d713fe11\",\"title\":\"AdaGrad stepsizes: Sharp convergence over nonconvex landscapes, from any initialization\",\"url\":\"https://www.semanticscholar.org/paper/7ce464e2505d1a086612d41a10429393d713fe11\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2009.06557\",\"authors\":[{\"authorId\":\"3069351\",\"name\":\"Qianqian Tong\"},{\"authorId\":\"46400517\",\"name\":\"G. Liang\"},{\"authorId\":\"145531104\",\"name\":\"J. Bi\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e5e15e3eed8e0769f198918b9e861e946dfcb132\",\"title\":\"Effective Federated Adaptive Gradient Methods with Non-IID Decentralized Data\",\"url\":\"https://www.semanticscholar.org/paper/e5e15e3eed8e0769f198918b9e861e946dfcb132\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.11985\",\"authors\":[{\"authorId\":\"14697929\",\"name\":\"Mingrui Liu\"},{\"authorId\":\"143715293\",\"name\":\"W. Zhang\"},{\"authorId\":\"1721068\",\"name\":\"F. Orabona\"},{\"authorId\":\"40381920\",\"name\":\"Tianbao Yang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"031960a54caf7059388d4d491a579ac18ebcc2f2\",\"title\":\"Adam+: A Stochastic Method with Adaptive Variance Reduction\",\"url\":\"https://www.semanticscholar.org/paper/031960a54caf7059388d4d491a579ac18ebcc2f2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"65772187\",\"name\":\"Bingxin Zhou\"},{\"authorId\":\"47410668\",\"name\":\"Xuebin Zheng\"},{\"authorId\":\"32278515\",\"name\":\"Junbin Gao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e38f26e160ff1c7e0a5db89bb540247a598b7c9c\",\"title\":\"ADAMT: A Stochastic Optimization with Trend Correction Scheme\",\"url\":\"https://www.semanticscholar.org/paper/e38f26e160ff1c7e0a5db89bb540247a598b7c9c\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":49291046,\"doi\":\"10.24963/ijcai.2020/448\",\"fieldsOfStudy\":[\"Computer Science\",\"Mathematics\"],\"influentialCitationCount\":17,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"3a7f661d157cfb689bb35969e1a0fccccf8ba698\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Geoffrey Hinton\"},{\"authorId\":null,\"name\":\"Nitish Srivastava\"},{\"authorId\":null,\"name\":\"Kevin Swersky\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Neural networks for machine learning lecture 6a overview of mini-batch gradient descent\",\"url\":\"\",\"venue\":\"\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Mitchell Marcus\"},{\"authorId\":null,\"name\":\"Beatrice Santorini\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and Mary Ann Marcinkiewicz\",\"url\":\"\",\"venue\":\"Building a large annotated corpus of english: The penn treebank.\",\"year\":1993},{\"arxivId\":\"1711.05101\",\"authors\":[{\"authorId\":\"1678656\",\"name\":\"I. Loshchilov\"},{\"authorId\":\"144661829\",\"name\":\"F. Hutter\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"45dfef0cc1ed96558c1c650432ce39d6a1050b6a\",\"title\":\"Fixing Weight Decay Regularization in Adam\",\"url\":\"https://www.semanticscholar.org/paper/45dfef0cc1ed96558c1c650432ce39d6a1050b6a\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1608.06993\",\"authors\":[{\"authorId\":\"143983679\",\"name\":\"Gao Huang\"},{\"authorId\":null,\"name\":\"Zhuang Liu\"},{\"authorId\":\"7446832\",\"name\":\"Kilian Q. Weinberger\"}],\"doi\":\"10.1109/CVPR.2017.243\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5694e46284460a648fe29117cbc55f6c9be3fa3c\",\"title\":\"Densely Connected Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/5694e46284460a648fe29117cbc55f6c9be3fa3c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Geoffrey Hinton\"},{\"authorId\":null,\"name\":\"Nitish Srivastava\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"and Kevin Swersky\",\"url\":\"\",\"venue\":\"Neural networks for machine learning lecture 6a overview of mini-batch gradient descent,\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"47680287\",\"name\":\"W. Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2009.5206848\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1b47265245e8db53a553049dcb27ed3e495fd625\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/1b47265245e8db53a553049dcb27ed3e495fd625\",\"venue\":\"CVPR 2009\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5d90f06bb70a0a3dced62413346235c02b1aa086\",\"title\":\"Learning Multiple Layers of Features from Tiny Images\",\"url\":\"https://www.semanticscholar.org/paper/5d90f06bb70a0a3dced62413346235c02b1aa086\",\"venue\":\"\",\"year\":2009},{\"arxivId\":\"1902.09843\",\"authors\":[{\"authorId\":\"51225788\",\"name\":\"Liangchen Luo\"},{\"authorId\":\"144493624\",\"name\":\"Yuanhao Xiong\"},{\"authorId\":\"47909587\",\"name\":\"Y. Liu\"},{\"authorId\":\"2511091\",\"name\":\"X. Sun\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"03af562fb8e69677865dbe94910e464443dd4623\",\"title\":\"Adaptive Gradient Methods with Dynamic Bound of Learning Rate\",\"url\":\"https://www.semanticscholar.org/paper/03af562fb8e69677865dbe94910e464443dd4623\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1808.02941\",\"authors\":[{\"authorId\":\"2347508\",\"name\":\"Xiangyi Chen\"},{\"authorId\":\"143743061\",\"name\":\"Sijia Liu\"},{\"authorId\":\"39447572\",\"name\":\"Ruoyu Sun\"},{\"authorId\":\"1793717\",\"name\":\"M. Hong\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e60dd237328bc92941e0559ab358e6186cdd41de\",\"title\":\"On the Convergence of A Class of Adam-Type Algorithms for Non-Convex Optimization\",\"url\":\"https://www.semanticscholar.org/paper/e60dd237328bc92941e0559ab358e6186cdd41de\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1712.07628\",\"authors\":[{\"authorId\":\"2844898\",\"name\":\"N. Keskar\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8f253d759d99e92888bf9eb595c59cf962fd9069\",\"title\":\"Improving Generalization Performance by Switching from Adam to SGD\",\"url\":\"https://www.semanticscholar.org/paper/8f253d759d99e92888bf9eb595c59cf962fd9069\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1609.02907\",\"authors\":[{\"authorId\":\"41016725\",\"name\":\"Thomas Kipf\"},{\"authorId\":\"1678311\",\"name\":\"M. Welling\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"36eff562f65125511b5dfab68ce7f7a943c27478\",\"title\":\"Semi-Supervised Classification with Graph Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/36eff562f65125511b5dfab68ce7f7a943c27478\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1002.4908\",\"authors\":[{\"authorId\":\"145057514\",\"name\":\"H. McMahan\"},{\"authorId\":\"7977819\",\"name\":\"M. Streeter\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"172a5ffc5a9b5b64c781d85dddc605c8b96b8abd\",\"title\":\"Adaptive Bound Optimization for Online Convex Optimization\",\"url\":\"https://www.semanticscholar.org/paper/172a5ffc5a9b5b64c781d85dddc605c8b96b8abd\",\"venue\":\"COLT\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32564459\",\"name\":\"Rachel Ward\"},{\"authorId\":\"39851229\",\"name\":\"X. Wu\"},{\"authorId\":\"52184096\",\"name\":\"L. Bottou\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"33b2e7cb9c3d3cc902a8cd5118862815d406d31a\",\"title\":\"AdaGrad stepsizes: sharp convergence over nonconvex landscapes\",\"url\":\"https://www.semanticscholar.org/paper/33b2e7cb9c3d3cc902a8cd5118862815d406d31a\",\"venue\":\"ICML\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Sashank J Reddi\"},{\"authorId\":null,\"name\":\"Ahmed Hefny\"},{\"authorId\":null,\"name\":\"Suvrit Sra\"},{\"authorId\":null,\"name\":\"Barnabas Poczos\"},{\"authorId\":null,\"name\":\"Alex Smola. Stochastic variance reduction for nonconvex optimization\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In International conference on machine learning\",\"url\":\"\",\"venue\":\"pages 314\\u2013323,\",\"year\":2016},{\"arxivId\":\"1506.01497\",\"authors\":[{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"144716314\",\"name\":\"J. Sun\"}],\"doi\":\"10.1109/TPAMI.2016.2577031\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"title\":\"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\",\"url\":\"https://www.semanticscholar.org/paper/424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2015},{\"arxivId\":\"1704.04861\",\"authors\":[{\"authorId\":\"144727050\",\"name\":\"A. Howard\"},{\"authorId\":\"2717876\",\"name\":\"Menglong Zhu\"},{\"authorId\":null,\"name\":\"Bo Chen\"},{\"authorId\":\"2741985\",\"name\":\"D. Kalenichenko\"},{\"authorId\":\"47825047\",\"name\":\"W. Wang\"},{\"authorId\":\"47447630\",\"name\":\"Tobias Weyand\"},{\"authorId\":\"2612392\",\"name\":\"M. Andreetto\"},{\"authorId\":\"2595180\",\"name\":\"H. Adam\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3647d6d0f151dc05626449ee09cc7bce55be497e\",\"title\":\"MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications\",\"url\":\"https://www.semanticscholar.org/paper/3647d6d0f151dc05626449ee09cc7bce55be497e\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1912.11940\",\"authors\":[{\"authorId\":\"14697929\",\"name\":\"Mingrui Liu\"},{\"authorId\":\"2211263\",\"name\":\"Youssef Mroueh\"},{\"authorId\":\"39320489\",\"name\":\"J. Ross\"},{\"authorId\":\"145261268\",\"name\":\"W. Zhang\"},{\"authorId\":\"50471144\",\"name\":\"Xiaodong Cui\"},{\"authorId\":\"1730372\",\"name\":\"Payel Das\"},{\"authorId\":\"40381920\",\"name\":\"Tianbao Yang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"16b4c8f533b8ecf9f384684dbf50fed698baa0a6\",\"title\":\"Towards Better Understanding of Adaptive Gradient Algorithms in Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/16b4c8f533b8ecf9f384684dbf50fed698baa0a6\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Charles Audet\"},{\"authorId\":\"1713257\",\"name\":\"Heinz H. Bauschke\"},{\"authorId\":\"2818509\",\"name\":\"L. T. Biegler\"},{\"authorId\":\"1783400\",\"name\":\"P. L. Combettes\"},{\"authorId\":\"1704229\",\"name\":\"W. Cook\"},{\"authorId\":\"1755208\",\"name\":\"F. Cucker\"},{\"authorId\":\"1718311\",\"name\":\"E. D. Klerk\"},{\"authorId\":\"3016531\",\"name\":\"D. Dentcheva\"},{\"authorId\":\"3174496\",\"name\":\"A. Dontchev\"},{\"authorId\":\"1749931\",\"name\":\"F. Eisenbrand\"},{\"authorId\":\"5106399\",\"name\":\"M. Ferris\"},{\"authorId\":\"1684580\",\"name\":\"M. Fukushima\"},{\"authorId\":\"144635205\",\"name\":\"R. Hauser\"},{\"authorId\":\"33842218\",\"name\":\"R. Henrion\"},{\"authorId\":\"1823941\",\"name\":\"D. Klatte\"},{\"authorId\":\"1803569\",\"name\":\"M. Kocvara\"},{\"authorId\":\"4141450\",\"name\":\"J. Lasserre\"},{\"authorId\":\"143961444\",\"name\":\"M. Laurent\"},{\"authorId\":\"1678370\",\"name\":\"S. Leyffer\"},{\"authorId\":\"50769640\",\"name\":\"K. F. Ng\"},{\"authorId\":\"2784955\",\"name\":\"J. Nocedal\"},{\"authorId\":\"104253644\",\"name\":\"Norkin\"},{\"authorId\":\"1709673\",\"name\":\"J. Outrata\"},{\"authorId\":\"1723232\",\"name\":\"M. Overton\"},{\"authorId\":\"1784816\",\"name\":\"J. Pang\"},{\"authorId\":\"145055007\",\"name\":\"J. Pe\\u00f1a\"},{\"authorId\":\"2129662\",\"name\":\"F. Rendl\"},{\"authorId\":\"1996654\",\"name\":\"A. Ruszczynski\"},{\"authorId\":\"2008266\",\"name\":\"A. Sartenaer\"},{\"authorId\":\"2055390\",\"name\":\"S. Scholtes\"},{\"authorId\":\"3118375\",\"name\":\"Hristo S. Sendov\"},{\"authorId\":\"144163407\",\"name\":\"K. Toh\"},{\"authorId\":\"145758858\",\"name\":\"P. Toint\"},{\"authorId\":\"1725666\",\"name\":\"L. Tun\\u00e7el\"},{\"authorId\":\"144624306\",\"name\":\"S. Ulbrich\"},{\"authorId\":\"1685738\",\"name\":\"M. Wright\"},{\"authorId\":\"1790701\",\"name\":\"Y. Yuan\"},{\"authorId\":\"50202049\",\"name\":\"Shuzhong Zhang\"},{\"authorId\":\"144874680\",\"name\":\"N. Gould\"},{\"authorId\":\"48254221\",\"name\":\"L. Vicente\"},{\"authorId\":\"1717322\",\"name\":\"H. Wolkowicz\"}],\"doi\":\"10.1137/siopt\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"359e97ab179d29aae45877dd52db4ec90eae41d6\",\"title\":\"SIAM Journal on Optimization\",\"url\":\"https://www.semanticscholar.org/paper/359e97ab179d29aae45877dd52db4ec90eae41d6\",\"venue\":\"\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Mahesh Chandra Mukkamala\"},{\"authorId\":null,\"name\":\"Matthias Hein. Variants of rmsprop\"},{\"authorId\":null,\"name\":\"adagrad with logarithmic regret bounds\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In International Conference on Machine Learning\",\"url\":\"\",\"venue\":\"pages 2545\\u20132553,\",\"year\":2017},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1212.5701\",\"authors\":[{\"authorId\":\"48799969\",\"name\":\"Matthew D. Zeiler\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8729441d734782c3ed532a7d2d9611b438c0a09a\",\"title\":\"ADADELTA: An Adaptive Learning Rate Method\",\"url\":\"https://www.semanticscholar.org/paper/8729441d734782c3ed532a7d2d9611b438c0a09a\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8195063\",\"name\":\"Martin Zinkevich\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e1f153c6df86d1ca8ecb9561daddfe7a54f901e7\",\"title\":\"Online Convex Programming and Generalized Infinitesimal Gradient Ascent\",\"url\":\"https://www.semanticscholar.org/paper/e1f153c6df86d1ca8ecb9561daddfe7a54f901e7\",\"venue\":\"ICML\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":\"1706.05507\",\"authors\":[{\"authorId\":\"19295410\",\"name\":\"Mahesh Chandra Mukkamala\"},{\"authorId\":\"143610806\",\"name\":\"M. Hein\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"431b37402a5ccf52ee48d2ca2bcaaec54a827b08\",\"title\":\"Variants of RMSProp and Adagrad with Logarithmic Regret Bounds\",\"url\":\"https://www.semanticscholar.org/paper/431b37402a5ccf52ee48d2ca2bcaaec54a827b08\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":\"1904.09237\",\"authors\":[{\"authorId\":\"1981186\",\"name\":\"S. Reddi\"},{\"authorId\":\"144055676\",\"name\":\"S. Kale\"},{\"authorId\":\"2794322\",\"name\":\"S. Kumar\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"43b854bb89f212e2d69a4b64ef0c28ff4d09f666\",\"title\":\"On the Convergence of Adam and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/43b854bb89f212e2d69a4b64ef0c28ff4d09f666\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1309.5549\",\"authors\":[{\"authorId\":\"2291057\",\"name\":\"S. Ghadimi\"},{\"authorId\":\"2070945\",\"name\":\"G. Lan\"}],\"doi\":\"10.1137/120880811\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8424a9e5a4456a2c45a42e392b9c01cd0c5c9467\",\"title\":\"Stochastic First- and Zeroth-Order Methods for Nonconvex Stochastic Programming\",\"url\":\"https://www.semanticscholar.org/paper/8424a9e5a4456a2c45a42e392b9c01cd0c5c9467\",\"venue\":\"SIAM J. Optim.\",\"year\":2013},{\"arxivId\":\"1310.3787\",\"authors\":[{\"authorId\":\"2291057\",\"name\":\"S. Ghadimi\"},{\"authorId\":\"2070945\",\"name\":\"G. Lan\"}],\"doi\":\"10.1007/s10107-015-0871-8\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0dadb9383f3d8b2b1d45f09c6b41d88fd9b7d430\",\"title\":\"Accelerated gradient methods for nonconvex nonlinear and stochastic programming\",\"url\":\"https://www.semanticscholar.org/paper/0dadb9383f3d8b2b1d45f09c6b41d88fd9b7d430\",\"venue\":\"Math. Program.\",\"year\":2016},{\"arxivId\":\"1605.07146\",\"authors\":[{\"authorId\":\"2134433\",\"name\":\"Sergey Zagoruyko\"},{\"authorId\":\"2505902\",\"name\":\"Nikos Komodakis\"}],\"doi\":\"10.5244/C.30.87\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1c4e9156ca07705531e45960b7a919dc473abb51\",\"title\":\"Wide Residual Networks\",\"url\":\"https://www.semanticscholar.org/paper/1c4e9156ca07705531e45960b7a919dc473abb51\",\"venue\":\"BMVC\",\"year\":2016},{\"arxivId\":\"1603.06160\",\"authors\":[{\"authorId\":\"1981186\",\"name\":\"S. Reddi\"},{\"authorId\":\"145253835\",\"name\":\"A. Hefny\"},{\"authorId\":\"3072326\",\"name\":\"S. Sra\"},{\"authorId\":\"1719347\",\"name\":\"B. P\\u00f3czos\"},{\"authorId\":\"46234526\",\"name\":\"Alex Smola\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"acffbcb997ce73bf63e2b5a8d928b287357d4f4f\",\"title\":\"Stochastic Variance Reduction for Nonconvex Optimization\",\"url\":\"https://www.semanticscholar.org/paper/acffbcb997ce73bf63e2b5a8d928b287357d4f4f\",\"venue\":\"ICML\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1734693\",\"name\":\"John C. Duchi\"},{\"authorId\":\"34840427\",\"name\":\"Elad Hazan\"},{\"authorId\":\"1740765\",\"name\":\"Y. Singer\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"413c1142de9d91804d6d11c67ff3fed59c9fc279\",\"title\":\"Adaptive Subgradient Methods for Online Learning and Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/413c1142de9d91804d6d11c67ff3fed59c9fc279\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2464851\",\"name\":\"A. Basu\"},{\"authorId\":\"3252772\",\"name\":\"Soham De\"},{\"authorId\":\"30401836\",\"name\":\"A. Mukherjee\"},{\"authorId\":\"51095694\",\"name\":\"Enayat Ullah\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"72696bce8a55e6d4beb49dcc168be2b3c05ef243\",\"title\":\"Convergence guarantees for RMSProp and ADAM in non-convex optimization and their comparison to Nesterov acceleration on autoencoders\",\"url\":\"https://www.semanticscholar.org/paper/72696bce8a55e6d4beb49dcc168be2b3c05ef243\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1709.04546\",\"authors\":[{\"authorId\":\"3051271\",\"name\":\"Z. Zhang\"},{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"1744839\",\"name\":\"Z. Li\"},{\"authorId\":\"1726963\",\"name\":\"C. Wu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"51ed8996e6bb192c4d56cf16d27ce31c4fdb687e\",\"title\":\"Normalized Direction-preserving Adam\",\"url\":\"https://www.semanticscholar.org/paper/51ed8996e6bb192c4d56cf16d27ce31c4fdb687e\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1403025868\",\"name\":\"Jean Pouget-Abadie\"},{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"144738865\",\"name\":\"Bing Xu\"},{\"authorId\":\"1393680089\",\"name\":\"David Warde-Farley\"},{\"authorId\":\"1955694\",\"name\":\"Sherjil Ozair\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"title\":\"Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"John Duchi\"},{\"authorId\":null,\"name\":\"Elad Hazan\"},{\"authorId\":null,\"name\":\"Yoram Singer. Adaptive subgradient methods for online learning\"},{\"authorId\":null,\"name\":\"stochastic optimization\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Journal of Machine Learning Research\",\"url\":\"\",\"venue\":\"12(Jul):2121\\u20132159,\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"113713833\",\"name\":\"S. J. Crawford\"},{\"authorId\":\"116971860\",\"name\":\"D. F. Kelley\"},{\"authorId\":\"137736247\",\"name\":\"In\\u00e9s Hern\\u00e1ndez \\u00c1vila\"}],\"doi\":\"10.1023/A:1017127612903\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6a8d3d2b99ab48fef1848fb16506a126a2702bde\",\"title\":\"Volume 1\",\"url\":\"https://www.semanticscholar.org/paper/6a8d3d2b99ab48fef1848fb16506a126a2702bde\",\"venue\":\"\",\"year\":1998},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98241663\",\"name\":\"M. V. Rossum\"}],\"doi\":\"10.1142/9789814360784_0003\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2d5af1ab6368f20a4a9bb2afae23663e5b08b9c6\",\"title\":\"Neural Computation\",\"url\":\"https://www.semanticscholar.org/paper/2d5af1ab6368f20a4a9bb2afae23663e5b08b9c6\",\"venue\":\"\",\"year\":1989},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98271909\",\"name\":\"Yi Xu\"},{\"authorId\":\"39436683\",\"name\":\"Qihang Lin\"},{\"authorId\":\"40381920\",\"name\":\"Tianbao Yang\"}],\"doi\":\"10.1142/S0219530519400050\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f0f4cfbe1f73f0b5f443c52c8dfd538b50399570\",\"title\":\"Accelerate Stochastic Subgradient Method by Leveraging Local Growth Condition\",\"url\":\"https://www.semanticscholar.org/paper/f0f4cfbe1f73f0b5f443c52c8dfd538b50399570\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1803.02021\",\"authors\":[{\"authorId\":\"3374063\",\"name\":\"Yuhuai Wu\"},{\"authorId\":\"2540599\",\"name\":\"Mengye Ren\"},{\"authorId\":\"2246396\",\"name\":\"Renjie Liao\"},{\"authorId\":\"1785346\",\"name\":\"Roger B. Grosse\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fdb26e0ab0395385bd0511359161607993d42a23\",\"title\":\"Understanding Short-Horizon Bias in Stochastic Meta-Optimization\",\"url\":\"https://www.semanticscholar.org/paper/fdb26e0ab0395385bd0511359161607993d42a23\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1678656\",\"name\":\"I. Loshchilov\"},{\"authorId\":\"144661829\",\"name\":\"F. Hutter\"}],\"doi\":null,\"intent\":[\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"d07284a6811f1b2745d91bdb06b040b57f226882\",\"title\":\"Decoupled Weight Decay Regularization\",\"url\":\"https://www.semanticscholar.org/paper/d07284a6811f1b2745d91bdb06b040b57f226882\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1705.08292\",\"authors\":[{\"authorId\":\"144102853\",\"name\":\"A. Wilson\"},{\"authorId\":\"40458654\",\"name\":\"Rebecca Roelofs\"},{\"authorId\":\"144872294\",\"name\":\"Mitchell Stern\"},{\"authorId\":\"1706280\",\"name\":\"Nathan Srebro\"},{\"authorId\":\"9229182\",\"name\":\"B. Recht\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1ecc2bd0bc6ffa0a2f466a058589c20593e3e57c\",\"title\":\"The Marginal Value of Adaptive Gradient Methods in Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/1ecc2bd0bc6ffa0a2f466a058589c20593e3e57c\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1904.12838\",\"authors\":[{\"authorId\":\"144804200\",\"name\":\"R. Ge\"},{\"authorId\":\"144695232\",\"name\":\"Sham M. Kakade\"},{\"authorId\":\"1891978\",\"name\":\"R. Kidambi\"},{\"authorId\":\"1751626\",\"name\":\"Praneeth Netrapalli\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a55845aa040374d448e31ad47c4888f28b0f8787\",\"title\":\"The Step Decay Schedule: A Near Optimal, Geometrically Decaying Learning Rate Procedure\",\"url\":\"https://www.semanticscholar.org/paper/a55845aa040374d448e31ad47c4888f28b0f8787\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1734174\",\"name\":\"M. Marcus\"},{\"authorId\":\"2424234\",\"name\":\"Beatrice Santorini\"},{\"authorId\":\"2063206\",\"name\":\"Mary Ann Marcinkiewicz\"}],\"doi\":\"10.21236/ada273556\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0b44fcbeea9415d400c5f5789d6b892b6f98daff\",\"title\":\"Building a Large Annotated Corpus of English: The Penn Treebank\",\"url\":\"https://www.semanticscholar.org/paper/0b44fcbeea9415d400c5f5789d6b892b6f98daff\",\"venue\":\"Comput. Linguistics\",\"year\":1993},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1771307\",\"name\":\"M. Zaheer\"},{\"authorId\":\"1981186\",\"name\":\"S. Reddi\"},{\"authorId\":\"39670454\",\"name\":\"Devendra Singh Sachan\"},{\"authorId\":\"144055676\",\"name\":\"S. Kale\"},{\"authorId\":\"2794322\",\"name\":\"S. Kumar\"}],\"doi\":null,\"intent\":[\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"90e2842c06b8d4a1fa3c146aabf07a63de4bdc2f\",\"title\":\"Adaptive Methods for Nonconvex Optimization\",\"url\":\"https://www.semanticscholar.org/paper/90e2842c06b8d4a1fa3c146aabf07a63de4bdc2f\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1911.07323\",\"authors\":[{\"authorId\":\"1838855\",\"name\":\"Difan Zou\"},{\"authorId\":\"3407296\",\"name\":\"Ziniu Hu\"},{\"authorId\":null,\"name\":\"Yewen Wang\"},{\"authorId\":\"145447441\",\"name\":\"Song Jiang\"},{\"authorId\":\"1792614\",\"name\":\"Y. Sun\"},{\"authorId\":\"9937103\",\"name\":\"Quanquan Gu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9dccd22276aaad5b6ec24e68bb7d29d954226a54\",\"title\":\"Layer-Dependent Importance Sampling for Training Deep and Large Graph Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/9dccd22276aaad5b6ec24e68bb7d29d954226a54\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1907.09547\",\"authors\":[{\"authorId\":\"40047103\",\"name\":\"D. Davis\"},{\"authorId\":\"2670852\",\"name\":\"D. Drusvyatskiy\"},{\"authorId\":\"10727266\",\"name\":\"Vasileios Charisopoulos\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"db75dd78212e6a961bbd512e9aa2720281ff469c\",\"title\":\"Stochastic algorithms with geometric step decay converge linearly on sharp functions\",\"url\":\"https://www.semanticscholar.org/paper/db75dd78212e6a961bbd512e9aa2720281ff469c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1805.08114\",\"authors\":[{\"authorId\":\"1972958\",\"name\":\"Xiaoyu Li\"},{\"authorId\":\"1721068\",\"name\":\"F. Orabona\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e5ac0048c813c7fee1167628c5a505c4669b0518\",\"title\":\"On the Convergence of Stochastic Gradient Descent with Adaptive Stepsizes\",\"url\":\"https://www.semanticscholar.org/paper/e5ac0048c813c7fee1167628c5a505c4669b0518\",\"venue\":\"AISTATS\",\"year\":2019},{\"arxivId\":\"1803.05591\",\"authors\":[{\"authorId\":\"1891978\",\"name\":\"R. Kidambi\"},{\"authorId\":\"1751626\",\"name\":\"Praneeth Netrapalli\"},{\"authorId\":\"48964143\",\"name\":\"P. Jain\"},{\"authorId\":\"144695232\",\"name\":\"Sham M. Kakade\"}],\"doi\":\"10.1109/ITA.2018.8503173\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a99f6f195d6cbc33a6259206c10d4ab0e167f969\",\"title\":\"On the Insufficiency of Existing Momentum Schemes for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a99f6f195d6cbc33a6259206c10d4ab0e167f969\",\"venue\":\"2018 Information Theory and Applications Workshop (ITA)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1162/neco.1997.9.8.1735\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"title\":\"Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"venue\":\"Neural Computation\",\"year\":1997},{\"arxivId\":\"1705.08741\",\"authors\":[{\"authorId\":\"40555034\",\"name\":\"E. Hoffer\"},{\"authorId\":\"2477463\",\"name\":\"Itay Hubara\"},{\"authorId\":\"1912398\",\"name\":\"Daniel Soudry\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8501e330d78391f4e690886a8eb8fac867704ea6\",\"title\":\"Train longer, generalize better: closing the generalization gap in large batch training of neural networks\",\"url\":\"https://www.semanticscholar.org/paper/8501e330d78391f4e690886a8eb8fac867704ea6\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1932759\",\"name\":\"M. J. Todd\"}],\"doi\":\"10.1201/9781420035315.ch46\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"322647135bab6d777cddf77794499bc6372c242f\",\"title\":\"Mathematical programming\",\"url\":\"https://www.semanticscholar.org/paper/322647135bab6d777cddf77794499bc6372c242f\",\"venue\":\"Handbook of Discrete and Computational Geometry, 2nd Ed.\",\"year\":1997},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145089978\",\"name\":\"D. Damen\"},{\"authorId\":\"1967104\",\"name\":\"David C. Hogg\"}],\"doi\":\"10.1109/CVPR.2009.5206636\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"dd116435b6f93e803e8db708ad4d0bce71499982\",\"title\":\"Computer Vision and Pattern Recognition (CVPR)\",\"url\":\"https://www.semanticscholar.org/paper/dd116435b6f93e803e8db708ad4d0bce71499982\",\"venue\":\"\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2018087\",\"name\":\"A. Srivastava\"},{\"authorId\":\"37210858\",\"name\":\"Charles Sutton\"}],\"doi\":null,\"intent\":[\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"2cd8ae29075d7b9b916377ead43b84e485f1399b\",\"title\":\"Proceedings for the 5th International Conference on Learning Representations\",\"url\":\"https://www.semanticscholar.org/paper/2cd8ae29075d7b9b916377ead43b84e485f1399b\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145085265\",\"name\":\"Fangyu Zou\"},{\"authorId\":\"144779869\",\"name\":\"Li Shen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4a9262ed7745764cdbe37cb3be8997565a6fc838\",\"title\":\"On the Convergence of AdaGrad with Momentum for Training Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/4a9262ed7745764cdbe37cb3be8997565a6fc838\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1806.01811\",\"authors\":[{\"authorId\":\"32564459\",\"name\":\"Rachel Ward\"},{\"authorId\":\"39851229\",\"name\":\"X. Wu\"},{\"authorId\":\"52184096\",\"name\":\"L. Bottou\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7ce464e2505d1a086612d41a10429393d713fe11\",\"title\":\"AdaGrad stepsizes: Sharp convergence over nonconvex landscapes, from any initialization\",\"url\":\"https://www.semanticscholar.org/paper/7ce464e2505d1a086612d41a10429393d713fe11\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1727849\",\"name\":\"S. Hanson\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"69d7086300e7f5322c06f2f242a565b3a182efb5\",\"title\":\"In Advances in Neural Information Processing Systems\",\"url\":\"https://www.semanticscholar.org/paper/69d7086300e7f5322c06f2f242a565b3a182efb5\",\"venue\":\"NIPS 1990\",\"year\":1990},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Sergey Zagoruyko\"},{\"authorId\":null,\"name\":\"Nikos Komodakis. Wide residual networks\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In Proceedings of the British Machine Vision Conference (BMVC)\",\"url\":\"\",\"venue\":\"pages 87.1\\u201387.12,\",\"year\":2016},{\"arxivId\":\"1802.08770\",\"authors\":[{\"authorId\":\"143809369\",\"name\":\"Chen Xing\"},{\"authorId\":\"2309967\",\"name\":\"D. Arpit\"},{\"authorId\":\"35766898\",\"name\":\"Christos Tsirigotis\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"78ac8ee86f7e69b91450bffe2bc651a53276b058\",\"title\":\"A Walk with SGD\",\"url\":\"https://www.semanticscholar.org/paper/78ac8ee86f7e69b91450bffe2bc651a53276b058\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2277385\",\"name\":\"Timothy Dozat\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d44efdc542f2cc5e196f04bc76bc783bfd7084af\",\"title\":\"Incorporating Nesterov Momentum into Adam\",\"url\":\"https://www.semanticscholar.org/paper/d44efdc542f2cc5e196f04bc76bc783bfd7084af\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1611.05431\",\"authors\":[{\"authorId\":\"1817030\",\"name\":\"Saining Xie\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"144035504\",\"name\":\"Zhuowen Tu\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"}],\"doi\":\"10.1109/CVPR.2017.634\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f6e0856b4a9199fa968ac00da612a9407b5cb85c\",\"title\":\"Aggregated Residual Transformations for Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/f6e0856b4a9199fa968ac00da612a9407b5cb85c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017}],\"title\":\"Closing the Generalization Gap of Adaptive Gradient Methods in Training Deep Neural Networks\",\"topics\":[{\"topic\":\"Deep learning\",\"topicId\":\"2762\",\"url\":\"https://www.semanticscholar.org/topic/2762\"},{\"topic\":\"Stochastic gradient descent\",\"topicId\":\"202796\",\"url\":\"https://www.semanticscholar.org/topic/202796\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"},{\"topic\":\"Algorithm\",\"topicId\":\"305\",\"url\":\"https://www.semanticscholar.org/topic/305\"},{\"topic\":\"Closing (morphology)\",\"topicId\":\"27538\",\"url\":\"https://www.semanticscholar.org/topic/27538\"},{\"topic\":\"Rate of convergence\",\"topicId\":\"45663\",\"url\":\"https://www.semanticscholar.org/topic/45663\"},{\"topic\":\"Neural network software\",\"topicId\":\"172426\",\"url\":\"https://www.semanticscholar.org/topic/172426\"}],\"url\":\"https://www.semanticscholar.org/paper/3a7f661d157cfb689bb35969e1a0fccccf8ba698\",\"venue\":\"ArXiv\",\"year\":2018}\n"