"{\"abstract\":\"Counterfactual explanations help users to understand the behaviors of machine learning models by changing the inputs for the existing outputs. For an image classification task, an example counterfactual visual explanation explains: \\u201dfor an example that belongs to class A, what changes do we need to make to the input so that the output is more inclined to class B.\\u201d Our research considers changing the attribute description text of class A on the basis of the attributes of class B and generating counterfactual images on the basis of the modified text. We can use the prediction results of the model on counterfactual images to find the attributes that have the greatest effect when the model is predicting classes A and B. We applied our method to a fine-grained image classification dataset and used the generative adversarial network to generate natural counterfactual visual explanations. To evaluate these explanations, we used them to assist crowdsourcing workers in an image classification task. We found that, within a specific range, they improved classification accuracy.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"47748756\",\"name\":\"Wenqi Zhao\",\"url\":\"https://www.semanticscholar.org/author/47748756\"},{\"authorId\":\"153656935\",\"name\":\"S. Oyama\",\"url\":\"https://www.semanticscholar.org/author/153656935\"},{\"authorId\":\"28711707\",\"name\":\"Masahito Kurihara\",\"url\":\"https://www.semanticscholar.org/author/28711707\"}],\"citationVelocity\":0,\"citations\":[],\"corpusId\":220483413,\"doi\":\"10.24963/ijcai.2020/742\",\"fieldsOfStudy\":[\"Economics\",\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":false,\"is_publisher_licensed\":false,\"paperId\":\"6fbe3106d3a969d25c3d9fd0087632f5f4e898a5\",\"references\":[{\"arxivId\":\"1702.08608\",\"authors\":[{\"authorId\":\"1412069139\",\"name\":\"Finale Doshi-Velez\"},{\"authorId\":\"3351164\",\"name\":\"Been Kim\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5c39e37022661f81f79e481240ed9b175dec6513\",\"title\":\"Towards A Rigorous Science of Interpretable Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/5c39e37022661f81f79e481240ed9b175dec6513\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1612.03242\",\"authors\":[{\"authorId\":\"120811666\",\"name\":\"Han Zhang\"},{\"authorId\":\"145017761\",\"name\":\"Tao Xu\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"}],\"doi\":\"10.1109/ICCV.2017.629\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ea67d2d5f2a7d5760ec6b67ea93d11dd5affa921\",\"title\":\"StackGAN: Text to Photo-Realistic Image Synthesis with Stacked Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/ea67d2d5f2a7d5760ec6b67ea93d11dd5affa921\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1904.07451\",\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"3311781\",\"name\":\"Z. Wu\"},{\"authorId\":\"39497207\",\"name\":\"J. Ernst\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"70dbe3e740a5e7927ccce00fd615365b08a6eaae\",\"title\":\"Counterfactual Visual Explanations\",\"url\":\"https://www.semanticscholar.org/paper/70dbe3e740a5e7927ccce00fd615365b08a6eaae\",\"venue\":\"ICML\",\"year\":2019},{\"arxivId\":\"1806.09809\",\"authors\":[{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2893664\",\"name\":\"Zeynep Akata\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"081bc74df7d43ccfc2bd212ce549b54c29f9ea76\",\"title\":\"Generating Counterfactual Explanations with Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/081bc74df7d43ccfc2bd212ce549b54c29f9ea76\",\"venue\":\"ICML 2018\",\"year\":2018},{\"arxivId\":\"1711.10485\",\"authors\":[{\"authorId\":\"39866461\",\"name\":\"T. Xu\"},{\"authorId\":\"9325940\",\"name\":\"Pengchuan Zhang\"},{\"authorId\":\"1788124\",\"name\":\"Qiuyuan Huang\"},{\"authorId\":\"48213346\",\"name\":\"Han Zhang\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"143713756\",\"name\":\"Xiaolei Huang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"}],\"doi\":\"10.1109/CVPR.2018.00143\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8b35c00edfa4edfd7a99d816e671023d2c000d55\",\"title\":\"AttnGAN: Fine-Grained Text to Image Generation with Attentional Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/8b35c00edfa4edfd7a99d816e671023d2c000d55\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018}],\"title\":\"Generating Natural Counterfactual Visual Explanations\",\"topics\":[{\"topic\":\"Counterfactual conditional\",\"topicId\":\"69178\",\"url\":\"https://www.semanticscholar.org/topic/69178\"}],\"url\":\"https://www.semanticscholar.org/paper/6fbe3106d3a969d25c3d9fd0087632f5f4e898a5\",\"venue\":\"IJCAI\",\"year\":2020}\n"