"{\"abstract\":\"Nowadays, algorithms with fast convergence, small memory footprints, and low per-iteration complexity are particularly favorable for artificial intelligence applications. In this paper, we propose a doubly stochastic algorithm with a novel accelerating multi-momentum technique to solve large scale empirical risk minimization problem for learning tasks. While enjoying a provably superior convergence rate, in each iteration, such algorithm only accesses a mini batch of samples and meanwhile updates a small block of variable coordinates, which substantially reduces the amount of memory reference when both the massive sample size and ultra-high dimensionality are involved. Specifically, to obtain an -accurate solution, our algorithm requires only O(log(1/ )/ \\u221a ) overall computation for the general convex case and O((n + \\u221a n\\u03ba) log(1/ )) for the strongly convex case. Empirical studies on huge scale datasets are conducted to illustrate the efficiency of our method in practice.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"3350452\",\"name\":\"Zebang Shen\",\"url\":\"https://www.semanticscholar.org/author/3350452\"},{\"authorId\":\"33441723\",\"name\":\"Hui Qian\",\"url\":\"https://www.semanticscholar.org/author/33441723\"},{\"authorId\":\"3431352\",\"name\":\"Tongzhou Mu\",\"url\":\"https://www.semanticscholar.org/author/3431352\"},{\"authorId\":null,\"name\":\"Chao Zhang\",\"url\":null}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"35076802\",\"name\":\"Vinod Kumar Chauhan\"},{\"authorId\":\"144676401\",\"name\":\"Anuj Sharma\"},{\"authorId\":\"40469693\",\"name\":\"Kalpana Dahiya\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"742c5917880329a8894081f429db531b52e34972\",\"title\":\"SAAGs: Biased Stochastic Variance Reduction Methods\",\"url\":\"https://www.semanticscholar.org/paper/742c5917880329a8894081f429db531b52e34972\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1878723\",\"name\":\"Yangfan Zhou\"},{\"authorId\":\"50495696\",\"name\":\"Mingchuan Zhang\"},{\"authorId\":\"144646645\",\"name\":\"Junlong Zhu\"},{\"authorId\":\"1710272\",\"name\":\"R. Zheng\"},{\"authorId\":\"1701108\",\"name\":\"Q. Wu\"}],\"doi\":\"10.1007/s00521-020-04718-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"44849fb7496e6418fdcfdc6adebd899fce9116e8\",\"title\":\"A Randomized Block-Coordinate Adam online learning optimization algorithm\",\"url\":\"https://www.semanticscholar.org/paper/44849fb7496e6418fdcfdc6adebd899fce9116e8\",\"venue\":\"Neural Computing and Applications\",\"year\":2020},{\"arxivId\":\"1807.08934\",\"authors\":[{\"authorId\":\"35076802\",\"name\":\"Vinod Kumar Chauhan\"},{\"authorId\":\"144676401\",\"name\":\"Anuj Sharma\"},{\"authorId\":\"40469693\",\"name\":\"Kalpana Dahiya\"}],\"doi\":\"10.1007/s10489-019-01450-3\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3c4d7ed606ad65dfa6849c0ddc19d4ebc01bb1fa\",\"title\":\"SAAGs: Biased stochastic variance reduction methods for large-scale learning\",\"url\":\"https://www.semanticscholar.org/paper/3c4d7ed606ad65dfa6849c0ddc19d4ebc01bb1fa\",\"venue\":\"Applied Intelligence\",\"year\":2019}],\"corpusId\":19734489,\"doi\":\"10.24963/ijcai.2017/378\",\"fieldsOfStudy\":[\"Mathematics\",\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":false,\"paperId\":\"357814c6d9a1949965ddf75a808cb825f9037cdd\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"40204991\",\"name\":\"A. Beck\"},{\"authorId\":\"1727609\",\"name\":\"M. Teboulle\"}],\"doi\":\"10.1137/080716542\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3c718363c22221fd16771672da3bfd5f67d2c34c\",\"title\":\"A Fast Iterative Shrinkage-Thresholding Algorithm for Linear Inverse Problems\",\"url\":\"https://www.semanticscholar.org/paper/3c718363c22221fd16771672da3bfd5f67d2c34c\",\"venue\":\"SIAM J. Imaging Sci.\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39435526\",\"name\":\"B. Polyak\"}],\"doi\":\"10.1016/0041-5553(64)90137-5\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4b53e3f719ff983eef867c6d8deac5dbe38aecb4\",\"title\":\"Some methods of speeding up the convergence of iteration methods\",\"url\":\"https://www.semanticscholar.org/paper/4b53e3f719ff983eef867c6d8deac5dbe38aecb4\",\"venue\":\"\",\"year\":1964},{\"arxivId\":\"1409.3257\",\"authors\":[{\"authorId\":null,\"name\":\"Yuchen Zhang\"},{\"authorId\":\"143724437\",\"name\":\"X. Lin\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"75359c49a6abdd5fba642f46ec44812ed8e8a648\",\"title\":\"Stochastic Primal-Dual Coordinate Method for Regularized Empirical Risk Minimization\",\"url\":\"https://www.semanticscholar.org/paper/75359c49a6abdd5fba642f46ec44812ed8e8a648\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1506.07512\",\"authors\":[{\"authorId\":\"34765463\",\"name\":\"Roy Frostig\"},{\"authorId\":\"144804200\",\"name\":\"R. Ge\"},{\"authorId\":\"144695232\",\"name\":\"Sham M. Kakade\"},{\"authorId\":\"2357926\",\"name\":\"Aaron Sidford\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"be681f95d2a3636532068f165d7fbf8fa0a301d5\",\"title\":\"Un-regularizing: approximate proximal point and faster stochastic algorithms for empirical risk minimization\",\"url\":\"https://www.semanticscholar.org/paper/be681f95d2a3636532068f165d7fbf8fa0a301d5\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1309.2388\",\"authors\":[{\"authorId\":\"145610994\",\"name\":\"M. Schmidt\"},{\"authorId\":\"7245737\",\"name\":\"Nicolas Le Roux\"},{\"authorId\":\"144570279\",\"name\":\"Francis R. Bach\"}],\"doi\":\"10.1007/s10107-016-1030-6\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"73068d3d5dacf987848eadd9af5b5fad8f7cf9c6\",\"title\":\"Minimizing finite sums with the stochastic average gradient\",\"url\":\"https://www.semanticscholar.org/paper/73068d3d5dacf987848eadd9af5b5fad8f7cf9c6\",\"venue\":\"Math. Program.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2968184\",\"name\":\"R. Johnson\"},{\"authorId\":\"49104973\",\"name\":\"Tong Zhang\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"43c05444fbc239321f6676f3cd539cac34fde7b8\",\"title\":\"Accelerating Stochastic Gradient Descent using Predictive Variance Reduction\",\"url\":\"https://www.semanticscholar.org/paper/43c05444fbc239321f6676f3cd539cac34fde7b8\",\"venue\":\"NIPS\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2472298\",\"name\":\"Chih-Chung Chang\"},{\"authorId\":\"1711460\",\"name\":\"C. Lin\"}],\"doi\":\"10.1145/1961189.1961199\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"273dfbcb68080251f5e9ff38b4413d7bd84b10a1\",\"title\":\"LIBSVM: A library for support vector machines\",\"url\":\"https://www.semanticscholar.org/paper/273dfbcb68080251f5e9ff38b4413d7bd84b10a1\",\"venue\":\"TIST\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2070945\",\"name\":\"G. Lan\"}],\"doi\":\"10.1007/s10107-010-0434-y\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1621f05894ad5fd6a8fcb8827a8c7aca36c81775\",\"title\":\"An optimal method for stochastic composite optimization\",\"url\":\"https://www.semanticscholar.org/paper/1621f05894ad5fd6a8fcb8827a8c7aca36c81775\",\"venue\":\"Math. Program.\",\"year\":2012},{\"arxivId\":\"1407.0202\",\"authors\":[{\"authorId\":\"34597877\",\"name\":\"Aaron Defazio\"},{\"authorId\":\"144570279\",\"name\":\"Francis R. Bach\"},{\"authorId\":\"1388317459\",\"name\":\"S. Lacoste-Julien\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"4daec165c1f4aa1206b0d91c0b26f0287d1ef52d\",\"title\":\"SAGA: A Fast Incremental Gradient Method With Support for Non-Strongly Convex Composite Objectives\",\"url\":\"https://www.semanticscholar.org/paper/4daec165c1f4aa1206b0d91c0b26f0287d1ef52d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1506.02186\",\"authors\":[{\"authorId\":\"3376305\",\"name\":\"Hongzhou Lin\"},{\"authorId\":\"2599292\",\"name\":\"J. Mairal\"},{\"authorId\":\"1753355\",\"name\":\"Z. Harchaoui\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"de5064b36b1ba71ac7424cdaf280af5bbdf780c1\",\"title\":\"A Universal Catalyst for First-Order Optimization\",\"url\":\"https://www.semanticscholar.org/paper/de5064b36b1ba71ac7424cdaf280af5bbdf780c1\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"13319052\",\"name\":\"Z. Zhu\"}],\"doi\":null,\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"530a75e0ad42adde46744f29732802a2c502ccfc\",\"title\":\"Katyusha: Accelerated Variance Reduction for Faster SGD\",\"url\":\"https://www.semanticscholar.org/paper/530a75e0ad42adde46744f29732802a2c502ccfc\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jerome Friedman\"},{\"authorId\":null,\"name\":\"Trevor Hastie\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and Robert Tibshirani\",\"url\":\"\",\"venue\":\"The elements of statistical learning.\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Olivier Fercoq\"},{\"authorId\":null,\"name\":\"Peter Richt\\u00e1rik. Accelerated\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"parallel\",\"url\":\"\",\"venue\":\"and proximal coordinate descent. SIAM Journal on Optimization,\",\"year\":2015},{\"arxivId\":\"1107.2848\",\"authors\":[{\"authorId\":\"2662221\",\"name\":\"Peter Richt\\u00e1rik\"},{\"authorId\":\"144696183\",\"name\":\"Martin Tak\\u00e1c\"}],\"doi\":\"10.1007/s10107-012-0614-z\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a8048db26cb78e785e82f06645da3f79d729528e\",\"title\":\"Iteration complexity of randomized block-coordinate descent methods for minimizing a composite function\",\"url\":\"https://www.semanticscholar.org/paper/a8048db26cb78e785e82f06645da3f79d729528e\",\"venue\":\"Math. Program.\",\"year\":2014},{\"arxivId\":\"1407.1537\",\"authors\":[{\"authorId\":\"13319052\",\"name\":\"Z. Zhu\"},{\"authorId\":\"1689494\",\"name\":\"L. Orecchia\"}],\"doi\":\"10.4230/LIPIcs.ITCS.2017.3\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bb924d92f0bdab0380d24271b9c1cc5ce3404c20\",\"title\":\"Linear Coupling: An Ultimate Unification of Gradient and Mirror Descent\",\"url\":\"https://www.semanticscholar.org/paper/bb924d92f0bdab0380d24271b9c1cc5ce3404c20\",\"venue\":\"ITCS\",\"year\":2017},{\"arxivId\":\"1312.5799\",\"authors\":[{\"authorId\":\"2442024\",\"name\":\"Olivier Fercoq\"},{\"authorId\":\"2662221\",\"name\":\"Peter Richt\\u00e1rik\"}],\"doi\":\"10.1137/130949993\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8726098f7590cbe1f4b33361050ed1c53632c3c6\",\"title\":\"Accelerated, Parallel, and Proximal Coordinate Descent\",\"url\":\"https://www.semanticscholar.org/paper/8726098f7590cbe1f4b33361050ed1c53632c3c6\",\"venue\":\"SIAM J. Optim.\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1761784\",\"name\":\"R. Tibshirani\"}],\"doi\":\"10.1111/J.2517-6161.1996.TB02080.X\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b365b8e45b7d81f081de44ac8f9eadf9144f3ca5\",\"title\":\"Regression Shrinkage and Selection via the Lasso\",\"url\":\"https://www.semanticscholar.org/paper/b365b8e45b7d81f081de44ac8f9eadf9144f3ca5\",\"venue\":\"\",\"year\":1996},{\"arxivId\":\"1305.1922\",\"authors\":[{\"authorId\":\"3267873\",\"name\":\"Y. Lee\"},{\"authorId\":\"2357926\",\"name\":\"Aaron Sidford\"}],\"doi\":\"10.1109/FOCS.2013.24\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"7d1b95fc9555863d39418962a75a1f8b6e30faf2\",\"title\":\"Efficient Accelerated Coordinate Descent Methods and Faster Algorithms for Solving Linear Systems\",\"url\":\"https://www.semanticscholar.org/paper/7d1b95fc9555863d39418962a75a1f8b6e30faf2\",\"venue\":\"2013 IEEE 54th Annual Symposium on Foundations of Computer Science\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66974892\",\"name\":\"L. H. C. Tippett\"},{\"authorId\":\"88594139\",\"name\":\"W. D. Baten\"}],\"doi\":\"10.1119/1.1933318\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e3cdce4160391fc43965886a3c1d1f9cab730dc1\",\"title\":\"Applied Statistics. A Journal of the Royal Statistical Society\",\"url\":\"https://www.semanticscholar.org/paper/e3cdce4160391fc43965886a3c1d1f9cab730dc1\",\"venue\":\"\",\"year\":1952},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3112035\",\"name\":\"Chonghai Hu\"},{\"authorId\":\"145193332\",\"name\":\"James T. Kwok\"},{\"authorId\":\"144282460\",\"name\":\"Weike Pan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"cb1c9446bf416a4c7c3ddbe3f7581c152860c93a\",\"title\":\"Accelerated Gradient Methods for Stochastic Optimization and Online Learning\",\"url\":\"https://www.semanticscholar.org/paper/cb1c9446bf416a4c7c3ddbe3f7581c152860c93a\",\"venue\":\"NIPS\",\"year\":2009},{\"arxivId\":\"1502.04759\",\"authors\":[{\"authorId\":\"144731788\",\"name\":\"Stephen J. Wright\"}],\"doi\":\"10.1007/s10107-015-0892-3\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"28cf6da1cdcfc1f95b8c31b13d975837257766f2\",\"title\":\"Coordinate descent algorithms\",\"url\":\"https://www.semanticscholar.org/paper/28cf6da1cdcfc1f95b8c31b13d975837257766f2\",\"venue\":\"Math. Program.\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2002509\",\"name\":\"Atsushi Nitanda\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f59023cc50582bd46e07d4579c0c9dbfc7cf6281\",\"title\":\"Stochastic Proximal Gradient Descent with Acceleration Techniques\",\"url\":\"https://www.semanticscholar.org/paper/f59023cc50582bd46e07d4579c0c9dbfc7cf6281\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143676697\",\"name\":\"Y. Nesterov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8d3a318b62d2e970122da35b2a2e70a5d12cc16f\",\"title\":\"A method for solving the convex programming problem with convergence rate O(1/k^2)\",\"url\":\"https://www.semanticscholar.org/paper/8d3a318b62d2e970122da35b2a2e70a5d12cc16f\",\"venue\":\"\",\"year\":1983},{\"arxivId\":\"1309.2375\",\"authors\":[{\"authorId\":\"1389955537\",\"name\":\"S. Shalev-Shwartz\"},{\"authorId\":\"49104973\",\"name\":\"Tong Zhang\"}],\"doi\":\"10.1007/s10107-014-0839-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d9bdff5eac0d0d1ebd8d09960f195b838ce16f4e\",\"title\":\"Accelerated proximal stochastic dual coordinate ascent for regularized loss minimization\",\"url\":\"https://www.semanticscholar.org/paper/d9bdff5eac0d0d1ebd8d09960f195b838ce16f4e\",\"venue\":\"Math. Program.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2799698\",\"name\":\"Noah Simon\"},{\"authorId\":\"3056361\",\"name\":\"J. Friedman\"},{\"authorId\":\"1784682\",\"name\":\"T. Hastie\"},{\"authorId\":\"1761784\",\"name\":\"R. Tibshirani\"}],\"doi\":\"10.1080/10618600.2012.681250\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"829b659f96771f2076ab325b1202b26085b300b4\",\"title\":\"A Sparse-Group Lasso\",\"url\":\"https://www.semanticscholar.org/paper/829b659f96771f2076ab325b1202b26085b300b4\",\"venue\":\"\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1784682\",\"name\":\"T. Hastie\"},{\"authorId\":\"1761784\",\"name\":\"R. Tibshirani\"},{\"authorId\":\"3056361\",\"name\":\"J. Friedman\"}],\"doi\":\"10.1007/b94608\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"44d71e0ec9f68d8eb802b9ab1dde8368efeac42e\",\"title\":\"The Elements of Statistical Learning\",\"url\":\"https://www.semanticscholar.org/paper/44d71e0ec9f68d8eb802b9ab1dde8368efeac42e\",\"venue\":\"\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36345161\",\"name\":\"Tuo Zhao\"},{\"authorId\":\"2482533\",\"name\":\"Mo Yu\"},{\"authorId\":\"21595671\",\"name\":\"Yiming Wang\"},{\"authorId\":\"144365054\",\"name\":\"R. Arora\"},{\"authorId\":\"49957601\",\"name\":\"Han Liu\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"84eac0730d1d6ffc935193f346283e342b5be19c\",\"title\":\"Accelerated Mini-batch Randomized Block Coordinate Descent Method\",\"url\":\"https://www.semanticscholar.org/paper/84eac0730d1d6ffc935193f346283e342b5be19c\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2085709\",\"name\":\"A. Zhang\"},{\"authorId\":\"9937103\",\"name\":\"Quanquan Gu\"}],\"doi\":\"10.1145/2939672.2939819\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3f8f9b918d56041e678d7470523698f9639d9411\",\"title\":\"Accelerated Stochastic Block Coordinate Descent with Optimal Sampling\",\"url\":\"https://www.semanticscholar.org/paper/3f8f9b918d56041e678d7470523698f9639d9411\",\"venue\":\"KDD\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143676697\",\"name\":\"Y. Nesterov\"}],\"doi\":\"10.1137/100802001\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0059cfac9c5b7811866f0729d0917b7478148fc5\",\"title\":\"Efficiency of Coordinate Descent Methods on Huge-Scale Optimization Problems\",\"url\":\"https://www.semanticscholar.org/paper/0059cfac9c5b7811866f0729d0917b7478148fc5\",\"venue\":\"SIAM J. Optim.\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39436683\",\"name\":\"Qihang Lin\"},{\"authorId\":\"6201715\",\"name\":\"Z. Lu\"},{\"authorId\":\"145942106\",\"name\":\"Lin Xiao\"}],\"doi\":\"10.1137/141000270\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8fa74f84e43dc811672a41db4b3724fdf590c3d5\",\"title\":\"An Accelerated Randomized Proximal Coordinate Gradient Method and its Application to Regularized Empirical Risk Minimization\",\"url\":\"https://www.semanticscholar.org/paper/8fa74f84e43dc811672a41db4b3724fdf590c3d5\",\"venue\":\"SIAM J. Optim.\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yu Nesterov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Introductory lectures on convex programming volume\",\"url\":\"\",\"venue\":\"[Nesterov,\",\"year\":1998},{\"arxivId\":\"1605.08003\",\"authors\":[{\"authorId\":\"32373165\",\"name\":\"Blake E. Woodworth\"},{\"authorId\":\"1706280\",\"name\":\"Nathan Srebro\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"03282fc4d206fde34237bcf85f1765442abbd4c9\",\"title\":\"Tight Complexity Bounds for Optimizing Composite Objectives\",\"url\":\"https://www.semanticscholar.org/paper/03282fc4d206fde34237bcf85f1765442abbd4c9\",\"venue\":\"NIPS\",\"year\":2016}],\"title\":\"Accelerated Doubly Stochastic Gradient Algorithm for Large-scale Empirical Risk Minimization\",\"topics\":[{\"topic\":\"Algorithm\",\"topicId\":\"305\",\"url\":\"https://www.semanticscholar.org/topic/305\"},{\"topic\":\"Empirical risk minimization\",\"topicId\":\"70744\",\"url\":\"https://www.semanticscholar.org/topic/70744\"},{\"topic\":\"Doubly stochastic model\",\"topicId\":\"671398\",\"url\":\"https://www.semanticscholar.org/topic/671398\"},{\"topic\":\"Gradient\",\"topicId\":\"3221\",\"url\":\"https://www.semanticscholar.org/topic/3221\"},{\"topic\":\"Iteration\",\"topicId\":\"11823\",\"url\":\"https://www.semanticscholar.org/topic/11823\"},{\"topic\":\"Applications of artificial intelligence\",\"topicId\":\"58827\",\"url\":\"https://www.semanticscholar.org/topic/58827\"},{\"topic\":\"Rate of convergence\",\"topicId\":\"45663\",\"url\":\"https://www.semanticscholar.org/topic/45663\"},{\"topic\":\"Computation\",\"topicId\":\"339\",\"url\":\"https://www.semanticscholar.org/topic/339\"}],\"url\":\"https://www.semanticscholar.org/paper/357814c6d9a1949965ddf75a808cb825f9037cdd\",\"venue\":\"IJCAI\",\"year\":2017}\n"