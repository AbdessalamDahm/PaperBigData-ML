"{\"abstract\":\"We discuss some recent results on Thompson sampling for nonparametric reinforcement learning in countable classes of general stochastic environments. These environments can be non-Markovian, non-ergodic, and partially observable. We show that Thompson sampling learns the environment class in the sense that (1) asymptotically its value converges in mean to the optimal value and (2) given a recoverability assumption regret is sublinear. We conclude with a discussion about optimality in reinforcement learning.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"2990741\",\"name\":\"J. Leike\",\"url\":\"https://www.semanticscholar.org/author/2990741\"},{\"authorId\":\"2989692\",\"name\":\"Tor Lattimore\",\"url\":\"https://www.semanticscholar.org/author/2989692\"},{\"authorId\":\"1749270\",\"name\":\"Laurent Orseau\",\"url\":\"https://www.semanticscholar.org/author/1749270\"},{\"authorId\":\"144154444\",\"name\":\"Marcus Hutter\",\"url\":\"https://www.semanticscholar.org/author/144154444\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":\"1605.03142\",\"authors\":[{\"authorId\":\"1868196\",\"name\":\"Tom Everitt\"},{\"authorId\":\"3393209\",\"name\":\"Daniel Filan\"},{\"authorId\":\"2842216\",\"name\":\"Mayank Daswani\"},{\"authorId\":\"144154444\",\"name\":\"Marcus Hutter\"}],\"doi\":\"10.1007/978-3-319-41649-6_1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d72fd1af6d31ceb7a46b1cd70822549c05a83151\",\"title\":\"Self-Modification of Policy and Utility Function in Rational Agents\",\"url\":\"https://www.semanticscholar.org/paper/d72fd1af6d31ceb7a46b1cd70822549c05a83151\",\"venue\":\"AGI\",\"year\":2016}],\"corpusId\":34651059,\"doi\":\"10.24963/ijcai.2017/688\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":false,\"paperId\":\"4619a0ed05ada81f562c2f1cfbb9116d1913bc98\",\"references\":[{\"arxivId\":\"1611.08944\",\"authors\":[{\"authorId\":\"2990741\",\"name\":\"J. Leike\"}],\"doi\":\"10.25911/5D76346C2E2BE\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7e66171492a39a28cbcefd7309fc8863d3954f0a\",\"title\":\"Nonparametric General Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/7e66171492a39a28cbcefd7309fc8863d3954f0a\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10213745\",\"name\":\"M. Pollack\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"27c593d8b1a3b6d51d33e13a0fc75052dd921775\",\"title\":\"Journal of Artificial Intelligence Research: Preface\",\"url\":\"https://www.semanticscholar.org/paper/27c593d8b1a3b6d51d33e13a0fc75052dd921775\",\"venue\":\"\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jan Leike\"},{\"authorId\":null,\"name\":\"Marcus Hutter. Bad universal priors\"},{\"authorId\":null,\"name\":\"notions of optimality\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In Conference on Learning Theory\",\"url\":\"\",\"venue\":\"pages 1244\\u20131259,\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Tor Lattimore\"},{\"authorId\":null,\"name\":\"Marcus Hutter. Asymptotically optimal agents. In Algorith Theory\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"pages 368\\u2013382\",\"url\":\"\",\"venue\":\"Springer,\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11707333\",\"name\":\"K. Pearson\"}],\"doi\":\"10.1086/278079\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e8b7ec08425250b368c36384b19bb142f47a7d24\",\"title\":\"Biometrika\",\"url\":\"https://www.semanticscholar.org/paper/e8b7ec08425250b368c36384b19bb142f47a7d24\",\"venue\":\"The American Naturalist\",\"year\":1902},{\"arxivId\":\"1712.03779\",\"authors\":[{\"authorId\":\"144923780\",\"name\":\"B. Yu\"},{\"authorId\":\"19225295\",\"name\":\"Karl Kumbier\"}],\"doi\":\"10.1631/FITEE.1700813\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"747f5ea1b986fb15a20b902407f48ef47c80bbcb\",\"title\":\"Artificial intelligence and statistics\",\"url\":\"https://www.semanticscholar.org/paper/747f5ea1b986fb15a20b902407f48ef47c80bbcb\",\"venue\":\"Frontiers of Information Technology & Electronic Engineering\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1730609\",\"name\":\"O. Chapelle\"},{\"authorId\":\"28929337\",\"name\":\"L. Li\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"ab867c140d2947511979c87e7ae580d9d3f0aeab\",\"title\":\"An Empirical Evaluation of Thompson Sampling\",\"url\":\"https://www.semanticscholar.org/paper/ab867c140d2947511979c87e7ae580d9d3f0aeab\",\"venue\":\"NIPS\",\"year\":2011},{\"arxivId\":\"1609.05058\",\"authors\":[{\"authorId\":\"2990741\",\"name\":\"J. Leike\"},{\"authorId\":\"144364160\",\"name\":\"Jessica Taylor\"},{\"authorId\":\"3442559\",\"name\":\"Benya Fallenstein\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cd868884ad4dfaf12b5b8e140d696ff0b31f5dcb\",\"title\":\"A Formal Solution to the Grain of Truth Problem\",\"url\":\"https://www.semanticscholar.org/paper/cd868884ad4dfaf12b5b8e140d696ff0b31f5dcb\",\"venue\":\"UAI\",\"year\":2016},{\"arxivId\":\"1705.10557\",\"authors\":[{\"authorId\":\"9958912\",\"name\":\"J. Aslanides\"},{\"authorId\":\"2990741\",\"name\":\"J. Leike\"},{\"authorId\":\"144154444\",\"name\":\"Marcus Hutter\"}],\"doi\":\"10.24963/ijcai.2017/194\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d1627e5dd7c6656aa8c16d861677ac631c5c4301\",\"title\":\"Universal Reinforcement Learning Algorithms: Survey and Experiments\",\"url\":\"https://www.semanticscholar.org/paper/d1627e5dd7c6656aa8c16d861677ac631c5c4301\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":\"1602.07905\",\"authors\":[{\"authorId\":\"2990741\",\"name\":\"J. Leike\"},{\"authorId\":\"2989692\",\"name\":\"Tor Lattimore\"},{\"authorId\":\"1749270\",\"name\":\"Laurent Orseau\"},{\"authorId\":\"144154444\",\"name\":\"Marcus Hutter\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1a81f1155f847b268ae4bed160540c2ee3acb5a9\",\"title\":\"Thompson Sampling is Asymptotically Optimal in General Environments\",\"url\":\"https://www.semanticscholar.org/paper/1a81f1155f847b268ae4bed160540c2ee3acb5a9\",\"venue\":\"UAI\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Malcolm Strens. A Bayesian framework for reinforcement learning\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In International Conference on Machine Learning\",\"url\":\"\",\"venue\":\"pages 943\\u2013950,\",\"year\":2000},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1740506\",\"name\":\"A. Sayed\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0dfcb3cce7ca12635d02ee0043a8bf2a58d76490\",\"title\":\"Foundations and Trends \\u00ae in Machine Learning > Vol 7 > Issue 4-5 Ordering Info About Us Alerts Contact Help Log in Adaptation , Learning , and Optimization over Networks\",\"url\":\"https://www.semanticscholar.org/paper/0dfcb3cce7ca12635d02ee0043a8bf2a58d76490\",\"venue\":\"\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1749270\",\"name\":\"Laurent Orseau\"}],\"doi\":\"10.1016/j.tcs.2012.10.014\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e6e36ebb02d2ecd6e1a85d584fada153f086779d\",\"title\":\"Asymptotic non-learnability of universal agents with computable horizon functions\",\"url\":\"https://www.semanticscholar.org/paper/e6e36ebb02d2ecd6e1a85d584fada153f086779d\",\"venue\":\"Theor. Comput. Sci.\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145431493\",\"name\":\"P. Nguyen\"},{\"authorId\":\"1794867\",\"name\":\"O. Maillard\"},{\"authorId\":\"1757258\",\"name\":\"D. Ryabko\"},{\"authorId\":\"1786887\",\"name\":\"R. Ortner\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2b5ed13107e55b88893f08f04f4ebeadc33f09e5\",\"title\":\"Competing with an Infinite Set of Models in Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/2b5ed13107e55b88893f08f04f4ebeadc33f09e5\",\"venue\":\"AISTATS\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3113049\",\"name\":\"T. Jaksch\"},{\"authorId\":\"1786887\",\"name\":\"R. Ortner\"},{\"authorId\":\"144543541\",\"name\":\"P. Auer\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0cafe2903b097fc042782c359cb231ea34ef7ed3\",\"title\":\"Near-optimal Regret Bounds for Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/0cafe2903b097fc042782c359cb231ea34ef7ed3\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1814162\",\"name\":\"Peter Sunehag\"},{\"authorId\":\"144154444\",\"name\":\"Marcus Hutter\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f9bed62d59fb77a4b8782fffa0588153189d287f\",\"title\":\"Rationality, optimism and guarantees in general reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/f9bed62d59fb77a4b8782fffa0588153189d287f\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2015},{\"arxivId\":\"1204.5721\",\"authors\":[{\"authorId\":\"1815542\",\"name\":\"S\\u00e9bastien Bubeck\"},{\"authorId\":\"1388387856\",\"name\":\"N. Cesa-Bianchi\"}],\"doi\":\"10.1561/2200000024\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9ae45d013a90c4a562b1e380fe032b20d0779577\",\"title\":\"Regret Analysis of Stochastic and Nonstochastic Multi-armed Bandit Problems\",\"url\":\"https://www.semanticscholar.org/paper/9ae45d013a90c4a562b1e380fe032b20d0779577\",\"venue\":\"Found. Trends Mach. Learn.\",\"year\":2012},{\"arxivId\":\"1609.04994\",\"authors\":[{\"authorId\":\"2990741\",\"name\":\"J. Leike\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c930a04f34ab31ace3d4e2f7683b4ce392329335\",\"title\":\"Exploration Potential\",\"url\":\"https://www.semanticscholar.org/paper/c930a04f34ab31ace3d4e2f7683b4ce392329335\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143817739\",\"name\":\"J. Leeuwen\"},{\"authorId\":\"1714183\",\"name\":\"C. Blundo\"},{\"authorId\":\"1749870\",\"name\":\"C. Laneve\"},{\"authorId\":\"143817739\",\"name\":\"J. Leeuwen\"}],\"doi\":\"10.1007/b13810\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"524f2ec5811aa0e9a6aea053c75488d9b83bb170\",\"title\":\"Theoretical Computer Science\",\"url\":\"https://www.semanticscholar.org/paper/524f2ec5811aa0e9a6aea053c75488d9b83bb170\",\"venue\":\"Lecture Notes in Computer Science\",\"year\":2003},{\"arxivId\":\"1403.5556\",\"authors\":[{\"authorId\":\"145751896\",\"name\":\"D. Russo\"},{\"authorId\":\"1731282\",\"name\":\"Benjamin Van Roy\"}],\"doi\":\"10.1287/opre.2017.1663\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f770614e497f456cfbe310bf7fd5223a4c28edd7\",\"title\":\"Learning to Optimize via Information-Directed Sampling\",\"url\":\"https://www.semanticscholar.org/paper/f770614e497f456cfbe310bf7fd5223a4c28edd7\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Laurent Orseau\"},{\"authorId\":null,\"name\":\"Tor Lattimore\"},{\"authorId\":null,\"name\":\"Marcus Hutter. Universal knowledge-seeking agents for sto Theory\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"pages 158\\u2013172\",\"url\":\"\",\"venue\":\"Springer,\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3101141\",\"name\":\"T. Levitt\"}],\"doi\":\"10.1609/aimag.v9i4.957\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"cb4269a54295aeaab1f86c03afd85fdedde07c55\",\"title\":\"Uncertainty in artificial intelligence\",\"url\":\"https://www.semanticscholar.org/paper/cb4269a54295aeaab1f86c03afd85fdedde07c55\",\"venue\":\"\",\"year\":1988},{\"arxivId\":\"1607.00215\",\"authors\":[{\"authorId\":\"2561924\",\"name\":\"Ian Osband\"},{\"authorId\":\"1731282\",\"name\":\"Benjamin Van Roy\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"88909a57da9a43ceb52aae8424b1f348dba99cab\",\"title\":\"Why is Posterior Sampling Better than Optimism for Reinforcement Learning?\",\"url\":\"https://www.semanticscholar.org/paper/88909a57da9a43ceb52aae8424b1f348dba99cab\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Aditya Gopalan\"},{\"authorId\":null,\"name\":\"Shie Mannor. Thompson sampling for learning parameteriz processes\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In Conference on Learning Theory\",\"url\":\"\",\"venue\":\"pages 861\\u2013898,\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Richard Dearden\"},{\"authorId\":null,\"name\":\"Nir Friedman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Bayesian Qlearning\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1107.5537\",\"authors\":[{\"authorId\":\"2989692\",\"name\":\"Tor Lattimore\"},{\"authorId\":\"144154444\",\"name\":\"Marcus Hutter\"}],\"doi\":\"10.1007/978-3-642-24412-4_29\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"acfe9ca6d6b7599c536390a3df1c25284a45f429\",\"title\":\"Asymptotically Optimal Agents\",\"url\":\"https://www.semanticscholar.org/paper/acfe9ca6d6b7599c536390a3df1c25284a45f429\",\"venue\":\"ALT\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144301306\",\"name\":\"W. Thompson\"}],\"doi\":\"10.1093/BIOMET/25.3-4.285\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ee2cd1d17f833d3c157a1016a778c7c22af555a2\",\"title\":\"ON THE LIKELIHOOD THAT ONE UNKNOWN PROBABILITY EXCEEDS ANOTHER IN VIEW OF THE EVIDENCE OF TWO SAMPLES\",\"url\":\"https://www.semanticscholar.org/paper/ee2cd1d17f833d3c157a1016a778c7c22af555a2\",\"venue\":\"\",\"year\":1933},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"G\\u00e1bor Bart\\u00f3k\"},{\"authorId\":null,\"name\":\"Dean Foster\"},{\"authorId\":null,\"name\":\"D\\u00e1vid P\\u00e1l\"},{\"authorId\":null,\"name\":\"Alexander Rakhlin\"},{\"authorId\":null,\"name\":\"Csaba Szepesv\\u00e1ri\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Partial monitoring\\u2014classification\",\"url\":\"\",\"venue\":\"regret bounds, and algorithms. Mathematics of Operations Research, 39(4):967\\u2013 997,\",\"year\":2014},{\"arxivId\":\"1205.2664\",\"authors\":[{\"authorId\":\"35775902\",\"name\":\"J. Asmuth\"},{\"authorId\":\"28929337\",\"name\":\"L. Li\"},{\"authorId\":\"144885169\",\"name\":\"M. Littman\"},{\"authorId\":\"2758123\",\"name\":\"Ali Nouri\"},{\"authorId\":\"30585164\",\"name\":\"D. Wingate\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"606c3108fe948d9a8a0da8759f88de4df53b5d94\",\"title\":\"A Bayesian Sampling Approach to Exploration in Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/606c3108fe948d9a8a0da8759f88de4df53b5d94\",\"venue\":\"UAI\",\"year\":2009},{\"arxivId\":\"cs/0004001\",\"authors\":[{\"authorId\":\"144154444\",\"name\":\"Marcus Hutter\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"512df75b028a807042a61ca1842b730aa62255d1\",\"title\":\"A Theory of Universal Artificial Intelligence based on Algorithmic Complexity\",\"url\":\"https://www.semanticscholar.org/paper/512df75b028a807042a61ca1842b730aa62255d1\",\"venue\":\"ArXiv\",\"year\":2000},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3255983\",\"name\":\"V. Mnih\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"},{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"1392331736\",\"name\":\"Andrei A. Rusu\"},{\"authorId\":\"144056327\",\"name\":\"J. Veness\"},{\"authorId\":\"1397980088\",\"name\":\"Marc G. Bellemare\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"3137672\",\"name\":\"Martin A. Riedmiller\"},{\"authorId\":\"1397979864\",\"name\":\"Andreas K. Fidjeland\"},{\"authorId\":\"2273072\",\"name\":\"Georg Ostrovski\"},{\"authorId\":\"145386761\",\"name\":\"S. Petersen\"},{\"authorId\":\"48878752\",\"name\":\"C. Beattie\"},{\"authorId\":\"49813280\",\"name\":\"A. Sadik\"},{\"authorId\":\"2460849\",\"name\":\"Ioannis Antonoglou\"},{\"authorId\":\"153907173\",\"name\":\"H. King\"},{\"authorId\":\"2106164\",\"name\":\"D. Kumaran\"},{\"authorId\":\"1688276\",\"name\":\"Daan Wierstra\"},{\"authorId\":\"34313265\",\"name\":\"S. Legg\"},{\"authorId\":\"48987704\",\"name\":\"Demis Hassabis\"}],\"doi\":\"10.1038/nature14236\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e0e9a94c4a6ba219e768b4e59f72c18f0a22e23d\",\"title\":\"Human-level control through deep reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/e0e9a94c4a6ba219e768b4e59f72c18f0a22e23d\",\"venue\":\"Nature\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144886843\",\"name\":\"Richard Lathe\"}],\"doi\":\"10.1038/332676B0\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6ec27fba80de3b9c52ef6ac4eaa9f59821aefb4b\",\"title\":\"Phd by thesis\",\"url\":\"https://www.semanticscholar.org/paper/6ec27fba80de3b9c52ef6ac4eaa9f59821aefb4b\",\"venue\":\"Nature\",\"year\":1988},{\"arxivId\":\"1306.0940\",\"authors\":[{\"authorId\":\"2561924\",\"name\":\"Ian Osband\"},{\"authorId\":\"145751896\",\"name\":\"D. Russo\"},{\"authorId\":\"1731282\",\"name\":\"Benjamin Van Roy\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"789783016fb708abbc061790612ebe91273c05d3\",\"title\":\"(More) Efficient Reinforcement Learning via Posterior Sampling\",\"url\":\"https://www.semanticscholar.org/paper/789783016fb708abbc061790612ebe91273c05d3\",\"venue\":\"NIPS\",\"year\":2013},{\"arxivId\":\"1606.01868\",\"authors\":[{\"authorId\":\"1792298\",\"name\":\"Marc G. Bellemare\"},{\"authorId\":\"144999731\",\"name\":\"S. Srinivasan\"},{\"authorId\":\"2273072\",\"name\":\"Georg Ostrovski\"},{\"authorId\":\"1725157\",\"name\":\"T. Schaul\"},{\"authorId\":\"143810408\",\"name\":\"D. Saxton\"},{\"authorId\":\"1708654\",\"name\":\"R. Munos\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6e90fd78e8a3b98af3954aae5209703aa966603e\",\"title\":\"Unifying Count-Based Exploration and Intrinsic Motivation\",\"url\":\"https://www.semanticscholar.org/paper/6e90fd78e8a3b98af3954aae5209703aa966603e\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2948478\",\"name\":\"M. Strens\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"48cce5ee49facf75eeb12832c387452424b645dd\",\"title\":\"A Bayesian Framework for Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/48cce5ee49facf75eeb12832c387452424b645dd\",\"venue\":\"ICML\",\"year\":2000},{\"arxivId\":\"1205.4217\",\"authors\":[{\"authorId\":\"2578263\",\"name\":\"Emilie Kaufmann\"},{\"authorId\":\"33656309\",\"name\":\"N. Korda\"},{\"authorId\":\"1708654\",\"name\":\"R. Munos\"}],\"doi\":\"10.1007/978-3-642-34106-9_18\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2e96fc720aabb0039f1e9819f4b78259924965ae\",\"title\":\"Thompson Sampling: An Asymptotically Optimal Finite-Time Analysis\",\"url\":\"https://www.semanticscholar.org/paper/2e96fc720aabb0039f1e9819f4b78259924965ae\",\"venue\":\"ALT\",\"year\":2012},{\"arxivId\":\"1610.04491\",\"authors\":[{\"authorId\":\"2989692\",\"name\":\"Tor Lattimore\"},{\"authorId\":\"40868287\",\"name\":\"Csaba Szepesvari\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"72e529ee310ab7fe52cd193217397e2430e5d9e6\",\"title\":\"The End of Optimism? An Asymptotic Analysis of Finite-Armed Linear Bandits\",\"url\":\"https://www.semanticscholar.org/paper/72e529ee310ab7fe52cd193217397e2430e5d9e6\",\"venue\":\"AISTATS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1749270\",\"name\":\"Laurent Orseau\"},{\"authorId\":\"2989692\",\"name\":\"Tor Lattimore\"},{\"authorId\":\"144154444\",\"name\":\"Marcus Hutter\"}],\"doi\":\"10.1007/978-3-642-40935-6_12\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e8dd477ec5d34ba46b8fe654537d509560c91ca3\",\"title\":\"Universal Knowledge-Seeking Agents for Stochastic Environments\",\"url\":\"https://www.semanticscholar.org/paper/e8dd477ec5d34ba46b8fe654537d509560c91ca3\",\"venue\":\"ALT\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145981974\",\"name\":\"Pedro A. Ortega\"},{\"authorId\":\"2354563\",\"name\":\"D. A. Braun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"70a76ed83473afa7f8a491dceb05ca2209234a31\",\"title\":\"Adaptive Coding of Actions and Observations\",\"url\":\"https://www.semanticscholar.org/paper/70a76ed83473afa7f8a491dceb05ca2209234a31\",\"venue\":\"NIPS 2012\",\"year\":2012},{\"arxivId\":\"1510.04931\",\"authors\":[{\"authorId\":\"2990741\",\"name\":\"J. Leike\"},{\"authorId\":\"144154444\",\"name\":\"Marcus Hutter\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"72f2eb13a98229f4b201b12942647853579111da\",\"title\":\"Bad Universal Priors and Notions of Optimality\",\"url\":\"https://www.semanticscholar.org/paper/72f2eb13a98229f4b201b12942647853579111da\",\"venue\":\"COLT\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1406347404\",\"name\":\"Dr. Marcus Hutter\"}],\"doi\":\"10.1007/b138233\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"30a64bdf778b8f561af9ae589e822c2c800920b1\",\"title\":\"Universal Artificial Intelligence\",\"url\":\"https://www.semanticscholar.org/paper/30a64bdf778b8f561af9ae589e822c2c800920b1\",\"venue\":\"Texts in Theoretical Computer Science An EATCS Series\",\"year\":2005},{\"arxivId\":\"1111.1797\",\"authors\":[{\"authorId\":\"1703744\",\"name\":\"S. Agrawal\"},{\"authorId\":\"144260125\",\"name\":\"Navin Goyal\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ea4ffbb3d628cd0739b04b67a1d4c3c7ccf75beb\",\"title\":\"Analysis of Thompson Sampling for the Multi-armed Bandit Problem\",\"url\":\"https://www.semanticscholar.org/paper/ea4ffbb3d628cd0739b04b67a1d4c3c7ccf75beb\",\"venue\":\"COLT\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Richard Dearden\"},{\"authorId\":null,\"name\":\"Nir Friedman\"},{\"authorId\":null,\"name\":\"Stuart Russell. Bayesian Q-learning\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In AAAI\",\"url\":\"\",\"venue\":\"pages 761\\u2013 768,\",\"year\":1998},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Marcus Hutter. Self-optimizing\"},{\"authorId\":null,\"name\":\"Paretooptimal policies in general environments based on Bayesmix Theory\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"pages 364\\u2013 379\",\"url\":\"\",\"venue\":\"Springer,\",\"year\":2002},{\"arxivId\":\"1406.1853\",\"authors\":[{\"authorId\":\"2561924\",\"name\":\"Ian Osband\"},{\"authorId\":\"1731282\",\"name\":\"Benjamin Van Roy\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8783688bfe249bd1cab13146a76ba50fe88128c7\",\"title\":\"Model-based Reinforcement Learning and the Eluder Dimension\",\"url\":\"https://www.semanticscholar.org/paper/8783688bfe249bd1cab13146a76ba50fe88128c7\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2014574318\",\"name\":\"Hang Li\"},{\"authorId\":\"1400659302\",\"name\":\"Dinh Phung\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"b401747b5e93b99585f5fe367d34750a5d7da030\",\"title\":\"Journal of Machine Learning Research: Preface\",\"url\":\"https://www.semanticscholar.org/paper/b401747b5e93b99585f5fe367d34750a5d7da030\",\"venue\":\"\",\"year\":2014},{\"arxivId\":\"0810.3605\",\"authors\":[{\"authorId\":\"145981974\",\"name\":\"Pedro A. Ortega\"},{\"authorId\":\"2354563\",\"name\":\"D. A. Braun\"}],\"doi\":\"10.1613/jair.3062\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ee71b2165a52d5548a8077dc367ddaa922c3e824\",\"title\":\"A Minimum Relative Entropy Principle for Learning and Acting\",\"url\":\"https://www.semanticscholar.org/paper/ee71b2165a52d5548a8077dc367ddaa922c3e824\",\"venue\":\"J. Artif. Intell. Res.\",\"year\":2010},{\"arxivId\":\"1703.01358\",\"authors\":[{\"authorId\":\"40295239\",\"name\":\"Sean Lamont\"},{\"authorId\":\"9958912\",\"name\":\"J. Aslanides\"},{\"authorId\":\"2990741\",\"name\":\"J. Leike\"},{\"authorId\":\"144154444\",\"name\":\"Marcus Hutter\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7209a01579872f17f6e3b4fd634ae39e95bdc31e\",\"title\":\"Generalised Discount Functions applied to a Monte-Carlo AI u Implementation\",\"url\":\"https://www.semanticscholar.org/paper/7209a01579872f17f6e3b4fd634ae39e95bdc31e\",\"venue\":\"AAMAS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145144587\",\"name\":\"G\\u00e1bor Bart\\u00f3k\"},{\"authorId\":\"145346320\",\"name\":\"D. Foster\"},{\"authorId\":\"2153912\",\"name\":\"D. P\\u00e1l\"},{\"authorId\":\"1680046\",\"name\":\"A. Rakhlin\"},{\"authorId\":\"40868287\",\"name\":\"Csaba Szepesvari\"}],\"doi\":\"10.1287/moor.2014.0663\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2e21b210c3cd3ac621b4fac372a48aa8364c7b9a\",\"title\":\"Partial Monitoring - Classification, Regret Bounds, and Algorithms\",\"url\":\"https://www.semanticscholar.org/paper/2e21b210c3cd3ac621b4fac372a48aa8364c7b9a\",\"venue\":\"Math. Oper. Res.\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1727849\",\"name\":\"S. Hanson\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"69d7086300e7f5322c06f2f242a565b3a182efb5\",\"title\":\"In Advances in Neural Information Processing Systems\",\"url\":\"https://www.semanticscholar.org/paper/69d7086300e7f5322c06f2f242a565b3a182efb5\",\"venue\":\"NIPS 1990\",\"year\":1990}],\"title\":\"On Thompson Sampling and Asymptotic Optimality\",\"topics\":[{\"topic\":\"Thompson sampling\",\"topicId\":\"516402\",\"url\":\"https://www.semanticscholar.org/topic/516402\"},{\"topic\":\"Reinforcement learning\",\"topicId\":\"2557\",\"url\":\"https://www.semanticscholar.org/topic/2557\"},{\"topic\":\"Sampling (signal processing)\",\"topicId\":\"7839\",\"url\":\"https://www.semanticscholar.org/topic/7839\"},{\"topic\":\"Ergodicity\",\"topicId\":\"578\",\"url\":\"https://www.semanticscholar.org/topic/578\"},{\"topic\":\"Partially observable system\",\"topicId\":\"473\",\"url\":\"https://www.semanticscholar.org/topic/473\"},{\"topic\":\"Bellman equation\",\"topicId\":\"65628\",\"url\":\"https://www.semanticscholar.org/topic/65628\"},{\"topic\":\"Regret (decision theory)\",\"topicId\":\"528786\",\"url\":\"https://www.semanticscholar.org/topic/528786\"},{\"topic\":\"Serializability\",\"topicId\":\"42587\",\"url\":\"https://www.semanticscholar.org/topic/42587\"},{\"topic\":\"Optimization problem\",\"topicId\":\"12682\",\"url\":\"https://www.semanticscholar.org/topic/12682\"},{\"topic\":\"Asymptotically optimal algorithm\",\"topicId\":\"26547\",\"url\":\"https://www.semanticscholar.org/topic/26547\"}],\"url\":\"https://www.semanticscholar.org/paper/4619a0ed05ada81f562c2f1cfbb9116d1913bc98\",\"venue\":\"IJCAI\",\"year\":2017}\n"