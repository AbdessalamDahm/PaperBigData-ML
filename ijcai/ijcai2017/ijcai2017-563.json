"{\"abstract\":\"In this work we formulate the problem of image captioning as a multimodal translation task. Analogous to machine translation, we present a sequence-to-sequence recurrent neural networks (RNN) model for image caption generation. Different from most existing work where the whole image is represented by convolutional neural network (CNN) feature, we propose to represent the input image as a sequence of detected objects which feeds as the source sequence of the RNN model. In this way, the sequential representation of an image can be naturally translated to a sequence of words, as the target sequence of the RNN model. To represent the image in a sequential way, we extract the objects features in the image and arrange them in a order using convolutional neural networks. To further leverage the visual information from the encoded objects, a sequential attention layer is introduced to selectively attend to the objects that are related to generate corresponding words in the sentences. Extensive experiments are conducted to validate the proposed approach on popular benchmark dataset, i.e., MS COCO, and the proposed model surpasses the state-of-the-art methods in all metrics following the dataset splits of previous work. The proposed approach is also evaluated by the evaluation server of MS COCO captioning challenge, and achieves very competitive results, e.g., a CIDEr of 1.029 (c5) and 1.064 (c40).\",\"arxivId\":\"1702.05658\",\"authors\":[{\"authorId\":null,\"name\":\"Chang Liu\",\"url\":null},{\"authorId\":\"143823065\",\"name\":\"F. Sun\",\"url\":\"https://www.semanticscholar.org/author/143823065\"},{\"authorId\":\"1697065\",\"name\":\"C. Wang\",\"url\":\"https://www.semanticscholar.org/author/1697065\"},{\"authorId\":\"39369840\",\"name\":\"Feng Wang\",\"url\":\"https://www.semanticscholar.org/author/39369840\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\",\"url\":\"https://www.semanticscholar.org/author/145081362\"}],\"citationVelocity\":14,\"citations\":[{\"arxivId\":\"1911.03738\",\"authors\":[{\"authorId\":\"32227979\",\"name\":\"Marc Tanti\"},{\"authorId\":\"145464131\",\"name\":\"Albert Gatt\"},{\"authorId\":\"2370774\",\"name\":\"Kenneth P. Camilleri\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"a55f5de768a455ab01fbe0432962f2f6f1a0a7db\",\"title\":\"On Architectures for Including Visual Information in Neural Language Models for Image Description\",\"url\":\"https://www.semanticscholar.org/paper/a55f5de768a455ab01fbe0432962f2f6f1a0a7db\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39786961\",\"name\":\"Jingqiang Chen\"},{\"authorId\":\"143632630\",\"name\":\"H. Zhuge\"}],\"doi\":\"10.18653/v1/D18-1438\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f8a52cb3d840d7250a87fc9be92be1abaa377d82\",\"title\":\"Abstractive Text-Image Summarization Using Multi-Modal Attentional Hierarchical RNN\",\"url\":\"https://www.semanticscholar.org/paper/f8a52cb3d840d7250a87fc9be92be1abaa377d82\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47672526\",\"name\":\"Shiwei Wang\"},{\"authorId\":\"2410125\",\"name\":\"Long Lan\"},{\"authorId\":\"49470127\",\"name\":\"X. Zhang\"},{\"authorId\":\"1406222945\",\"name\":\"Zhigang Luo\"}],\"doi\":\"10.1007/s11042-019-08567-0\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"49280cc9fa8c9854a655afbfd213c1437c52f1e3\",\"title\":\"GateCap: Gated spatial and semantic attention model for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/49280cc9fa8c9854a655afbfd213c1437c52f1e3\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2788104\",\"name\":\"Yuting Su\"},{\"authorId\":\"50025928\",\"name\":\"Yuqian Li\"},{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":\"49285626\",\"name\":\"An-An Liu\"}],\"doi\":\"10.1007/s11063-019-09997-5\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"65471c0f2a8ee941363ee009e81d450a1b0bbbf9\",\"title\":\"Hierarchical Deep Neural Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/65471c0f2a8ee941363ee009e81d450a1b0bbbf9\",\"venue\":\"Neural Processing Letters\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144081629\",\"name\":\"Mario G\\u00f3mez Mart\\u00ednez\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"faa8314259e9de1af8e841c265b0251531b32e04\",\"title\":\"Deep learning for image captioning: an encoder-decoder architecture with soft attention\",\"url\":\"https://www.semanticscholar.org/paper/faa8314259e9de1af8e841c265b0251531b32e04\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51907635\",\"name\":\"I. Khurram\"},{\"authorId\":\"1756409\",\"name\":\"M. M. Fraz\"},{\"authorId\":\"1380493605\",\"name\":\"M. Shahzad\"},{\"authorId\":\"2229652\",\"name\":\"N. Rajpoot\"}],\"doi\":\"10.1007/s12559-019-09697-1\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e6b2728a7d0677e045a50203b574ea569a20cdf2\",\"title\":\"Dense-CaptionNet: a Sentence Generation Architecture for Fine-grained Description of Image Semantics\",\"url\":\"https://www.semanticscholar.org/paper/e6b2728a7d0677e045a50203b574ea569a20cdf2\",\"venue\":\"Cognitive Computation\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36595248\",\"name\":\"Fang Fang\"},{\"authorId\":\"8194130\",\"name\":\"Qinyu Li\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"8275214\",\"name\":\"P. Tang\"}],\"doi\":\"10.1109/ICME.2018.8486437\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e0f0076476fc81a344b8bdec771802a8584dd10f\",\"title\":\"Refining Attention: A Sequential Attention Model for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/e0f0076476fc81a344b8bdec771802a8584dd10f\",\"venue\":\"2018 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46740305\",\"name\":\"Chunlei Wu\"},{\"authorId\":\"19261873\",\"name\":\"Yiwei Wei\"},{\"authorId\":\"15862607\",\"name\":\"Xiaoliang Chu\"},{\"authorId\":\"152343380\",\"name\":\"Fei Su\"},{\"authorId\":\"2250564\",\"name\":\"Leiquan Wang\"}],\"doi\":\"10.1016/j.image.2018.06.002\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f20d5a6f10c269582bd00fd4733bb0066faee302\",\"title\":\"Modeling visual and word-conditional semantic attention for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/f20d5a6f10c269582bd00fd4733bb0066faee302\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491240404\",\"name\":\"Rishab Lamba\"},{\"authorId\":\"1491236587\",\"name\":\"Sahil Lamba\"}],\"doi\":\"10.1109/ICCCIS48478.2019.8974558\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a35d4f396c4c44484afaf5aae5d5f58fea14c813\",\"title\":\"Image Montage Summarization\",\"url\":\"https://www.semanticscholar.org/paper/a35d4f396c4c44484afaf5aae5d5f58fea14c813\",\"venue\":\"2019 International Conference on Computing, Communication, and Intelligent Systems (ICCCIS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Nannan Li\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"}],\"doi\":\"10.24963/ijcai.2018/110\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"47921216d4758a16cf7b5bfc85cc7b9178bffe6a\",\"title\":\"Image Cationing with Visual-Semantic LSTM\",\"url\":\"https://www.semanticscholar.org/paper/47921216d4758a16cf7b5bfc85cc7b9178bffe6a\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":\"1905.08110\",\"authors\":[{\"authorId\":\"47904580\",\"name\":\"Yiyu Wang\"},{\"authorId\":\"2073589\",\"name\":\"Jungang Xu\"},{\"authorId\":\"46676156\",\"name\":\"Yingfei Sun\"},{\"authorId\":\"40368776\",\"name\":\"Ben He\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8ef4a09eb86e150b08a80d59c2c092d1a56be780\",\"title\":\"Image Captioning based on Deep Learning Methods: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/8ef4a09eb86e150b08a80d59c2c092d1a56be780\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1803.05526\",\"authors\":[{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"},{\"authorId\":\"2708940\",\"name\":\"Shafiq R. Joty\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"}],\"doi\":\"10.1007/978-3-030-01246-5_31\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"05544876b7bc58b59b9ec5a8ee09e3ce9b4791ce\",\"title\":\"Unpaired Image Captioning by Language Pivoting\",\"url\":\"https://www.semanticscholar.org/paper/05544876b7bc58b59b9ec5a8ee09e3ce9b4791ce\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2715920\",\"name\":\"Malihe Alikhani\"},{\"authorId\":\"144884556\",\"name\":\"Matthew Stone\"}],\"doi\":\"10.18653/v1/W19-1806\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5834b21b80c8ec68d508684d25a613a604f06479\",\"title\":\"\\u201cCaption\\u201d as a Coherence Relation: Evidence and Implications\",\"url\":\"https://www.semanticscholar.org/paper/5834b21b80c8ec68d508684d25a613a604f06479\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738647655\",\"name\":\"Emiel van Miltenburg\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"adf57a2bdcffc38238e64d4ae797c12405281173\",\"title\":\"How Do Image Description Systems Describe People? A Targeted Assessment of System Competence in the PEOPLE-domain\",\"url\":\"https://www.semanticscholar.org/paper/adf57a2bdcffc38238e64d4ae797c12405281173\",\"venue\":\"LANTERN\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134680082\",\"name\":\"Raimonda Stani\\u016bt\\u0117\"},{\"authorId\":\"1990294\",\"name\":\"D. Sesok\"}],\"doi\":\"10.3390/APP9102024\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"92ccf5a39c63cb5e1639be518e6db2e357acd58e\",\"title\":\"A Systematic Literature Review on Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/92ccf5a39c63cb5e1639be518e6db2e357acd58e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1909.04402\",\"authors\":[{\"authorId\":\"1387994359\",\"name\":\"Mitja Nikolaus\"},{\"authorId\":\"30671790\",\"name\":\"M. Abdou\"},{\"authorId\":\"48024953\",\"name\":\"Matthew Lamm\"},{\"authorId\":\"19509693\",\"name\":\"Rahul Aralikatte\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"}],\"doi\":\"10.18653/v1/K19-1009\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"11557ee241f6b5dc0a8c62bb8014c0111bbe45ba\",\"title\":\"Compositional Generalization in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/11557ee241f6b5dc0a8c62bb8014c0111bbe45ba\",\"venue\":\"CoNLL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47672526\",\"name\":\"Shiwei Wang\"},{\"authorId\":\"2410125\",\"name\":\"Long Lan\"},{\"authorId\":\"49470127\",\"name\":\"X. Zhang\"},{\"authorId\":\"48593034\",\"name\":\"Guohua Dong\"},{\"authorId\":\"1406222945\",\"name\":\"Zhigang Luo\"}],\"doi\":\"10.1007/s11042-019-08209-5\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"311ee1284e6bdf035f8c3a1a20d00c5841b2e341\",\"title\":\"Object-aware semantics of attention for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/311ee1284e6bdf035f8c3a1a20d00c5841b2e341\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150197175\",\"name\":\"L. Zhou\"},{\"authorId\":\"49890476\",\"name\":\"Yuejie Zhang\"},{\"authorId\":\"49296155\",\"name\":\"Y. Jiang\"},{\"authorId\":\"145326655\",\"name\":\"Tao Zhang\"},{\"authorId\":\"145631869\",\"name\":\"W. Fan\"}],\"doi\":\"10.1109/TIP.2019.2928144\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"95db18799c539c82379585d25af66fd968ff000c\",\"title\":\"Re-Caption: Saliency-Enhanced Image Captioning Through Two-Phase Learning\",\"url\":\"https://www.semanticscholar.org/paper/95db18799c539c82379585d25af66fd968ff000c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1907.08948\",\"authors\":[{\"authorId\":\"8210161\",\"name\":\"Shantipriya Parida\"},{\"authorId\":\"151158933\",\"name\":\"Ondvrej Bojar\"},{\"authorId\":\"32347060\",\"name\":\"S. Dash\"}],\"doi\":\"10.13053/cys-23-4-3294\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5a64c71e8f29a3b7ef77ab24daf2eca3b73f4a75\",\"title\":\"Hindi Visual Genome: A Dataset for Multimodal English-to-Hindi Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/5a64c71e8f29a3b7ef77ab24daf2eca3b73f4a75\",\"venue\":\"Computaci\\u00f3n y Sistemas\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121104319\",\"name\":\"Rehab Alahmadi\"},{\"authorId\":\"1695172\",\"name\":\"C. H. Park\"},{\"authorId\":\"36266636\",\"name\":\"J. Hahn\"}],\"doi\":\"10.1117/12.2523174\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"602cb721618a24a4c48bd53bf47b5a0283e028c9\",\"title\":\"Sequence-to-sequence image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/602cb721618a24a4c48bd53bf47b5a0283e028c9\",\"venue\":\"International Conference on Machine Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152924581\",\"name\":\"Jicheng Wang\"},{\"authorId\":\"51288875\",\"name\":\"Y. Zhou\"},{\"authorId\":\"1438588470\",\"name\":\"Zhenzhen Hu\"},{\"authorId\":\"47957556\",\"name\":\"X. Zhang\"},{\"authorId\":\"31048669\",\"name\":\"M. Wang\"}],\"doi\":\"10.1007/s11042-019-08439-7\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0c48de74a40736498d6443f84ecdddc08275359f\",\"title\":\"Sequential image encoding for vision-to-language problems\",\"url\":\"https://www.semanticscholar.org/paper/0c48de74a40736498d6443f84ecdddc08275359f\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52366010\",\"name\":\"Zhi-bin Guan\"},{\"authorId\":\"49600007\",\"name\":\"Kang Liu\"},{\"authorId\":\"47009350\",\"name\":\"Yan Ma\"},{\"authorId\":\"144222488\",\"name\":\"Xu Qian\"},{\"authorId\":\"35260608\",\"name\":\"Tongkai Ji\"}],\"doi\":\"10.3390/sym10110626\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0d6b701c003c3aecfdbcf1700496cde74ea05642\",\"title\":\"Sequential Dual Attention: Coarse-to-Fine-Grained Hierarchical Generation for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0d6b701c003c3aecfdbcf1700496cde74ea05642\",\"venue\":\"Symmetry\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"153152064\",\"name\":\"A. Liu\"},{\"authorId\":\"153576783\",\"name\":\"Weizhi Nie\"},{\"authorId\":\"2788104\",\"name\":\"Yuting Su\"},{\"authorId\":\"48693981\",\"name\":\"J. Nie\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.1109/TMM.2019.2941820\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aff890f20d28a13b9fb89d192fad35d92381c410\",\"title\":\"Multi-Level Policy and Reward-Based Deep Reinforcement Learning Framework for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/aff890f20d28a13b9fb89d192fad35d92381c410\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"1703.07939\",\"authors\":[{\"authorId\":\"50557601\",\"name\":\"Chenxi Liu\"},{\"authorId\":\"145527707\",\"name\":\"Zhe L. Lin\"},{\"authorId\":\"1720987\",\"name\":\"X. Shen\"},{\"authorId\":\"1768964\",\"name\":\"Jimei Yang\"},{\"authorId\":\"145574672\",\"name\":\"Xin Lu\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.1109/ICCV.2017.143\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d69edb02e935b782b90175cb691f6ab5f4bd64f\",\"title\":\"Recurrent Multimodal Interaction for Referring Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/3d69edb02e935b782b90175cb691f6ab5f4bd64f\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"2001.09545\",\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"66a2eb540af6f47db177599bc793ab0c6a6aa47e\",\"title\":\"aiTPR: Attribute Interaction-Tensor Product Representation for Image Caption\",\"url\":\"https://www.semanticscholar.org/paper/66a2eb540af6f47db177599bc793ab0c6a6aa47e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36595248\",\"name\":\"Fang Fang\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"8275214\",\"name\":\"P. Tang\"}],\"doi\":\"10.1109/ICIP.2018.8451558\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c5f6ed9efc222fe2773135ffb4e5c567d98e64ea\",\"title\":\"Image Captioning with Word Level Attention\",\"url\":\"https://www.semanticscholar.org/paper/c5f6ed9efc222fe2773135ffb4e5c567d98e64ea\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s42979-020-00238-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3f732495721356944027051bb14100436a5dbdf5\",\"title\":\"AACR: Feature Fusion Effects of Algebraic Amalgamation Composed Representation on (De)Compositional Network for Caption Generation for Images\",\"url\":\"https://www.semanticscholar.org/paper/3f732495721356944027051bb14100436a5dbdf5\",\"venue\":\"SN Comput. Sci.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s13735-020-00198-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8c85757cdd7de5f99ab1717a6355a09bb717013c\",\"title\":\"MRECN: mixed representation enhanced (de)compositional network for caption generation from visual features, modeling as pseudo tensor product representation\",\"url\":\"https://www.semanticscholar.org/paper/8c85757cdd7de5f99ab1717a6355a09bb717013c\",\"venue\":\"Int. J. Multim. Inf. Retr.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3192572\",\"name\":\"Emiel van Miltenburg\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"1791713\",\"name\":\"Piek T. J. M. Vossen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fe400b814cfea5538887c92040f1ab0d6fb45bfe\",\"title\":\"Measuring the Diversity of Automatic Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/fe400b814cfea5538887c92040f1ab0d6fb45bfe\",\"venue\":\"COLING\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2250564\",\"name\":\"Leiquan Wang\"},{\"authorId\":\"15862607\",\"name\":\"Xiaoliang Chu\"},{\"authorId\":\"1954076\",\"name\":\"W. Zhang\"},{\"authorId\":\"19261873\",\"name\":\"Yiwei Wei\"},{\"authorId\":\"2037988\",\"name\":\"Weichen Sun\"},{\"authorId\":\"32324177\",\"name\":\"C. Wu\"}],\"doi\":\"10.3390/s18020646\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e4b9c14951cea6259dd9d522586ba2c5bb1fbcce\",\"title\":\"Social Image Captioning: Exploring Visual Attention and User Attention\",\"url\":\"https://www.semanticscholar.org/paper/e4b9c14951cea6259dd9d522586ba2c5bb1fbcce\",\"venue\":\"Sensors\",\"year\":2018},{\"arxivId\":\"2002.06436\",\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4ad005019f7069a3aaff959fbaa657f2ef2143fc\",\"title\":\"MRRC: Multiple Role Representation Crossover Interpretation for Image Captioning With R-CNN Feature Distribution Composition (FDC)\",\"url\":\"https://www.semanticscholar.org/paper/4ad005019f7069a3aaff959fbaa657f2ef2143fc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1909.02489\",\"authors\":[{\"authorId\":\"47748186\",\"name\":\"Wei Wei\"},{\"authorId\":\"144996789\",\"name\":\"L. Cheng\"},{\"authorId\":\"2089102\",\"name\":\"X. Mao\"},{\"authorId\":\"143652253\",\"name\":\"G. Zhou\"},{\"authorId\":\"143663410\",\"name\":\"F. Zhu\"}],\"doi\":\"10.1109/ACCESS.2020.3018752\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b1e8e509a62c424055ffc050dc7cb41329674ea9\",\"title\":\"Stack-VS: Stacked Visual-Semantic Attention for Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/b1e8e509a62c424055ffc050dc7cb41329674ea9\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1904.13148\",\"authors\":[{\"authorId\":\"3110609\",\"name\":\"Zhennan Wang\"},{\"authorId\":\"2568383\",\"name\":\"Wenbin Zou\"},{\"authorId\":\"144282087\",\"name\":\"C. Xu\"}],\"doi\":\"10.1109/ICCV.2019.00611\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b7c074e0fce985164989f0163cef8e7bb59a3612\",\"title\":\"PR Product: A Substitute for Inner Product in Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/b7c074e0fce985164989f0163cef8e7bb59a3612\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1709.03376\",\"authors\":[{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"},{\"authorId\":\"40894914\",\"name\":\"T. Chen\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7f14e73dade94b8b1f276dcd91257aa7de5f19d7\",\"title\":\"Stack-Captioning: Coarse-to-Fine Learning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7f14e73dade94b8b1f276dcd91257aa7de5f19d7\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37670557\",\"name\":\"Xiangyang Li\"},{\"authorId\":\"1696610\",\"name\":\"S. Jiang\"}],\"doi\":\"10.1109/TMM.2018.2811621\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a17310abb249ce8fce8f409709b5395da32e0a6\",\"title\":\"Bundled Object Context for Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/8a17310abb249ce8fce8f409709b5395da32e0a6\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":\"2002.06701\",\"authors\":[{\"authorId\":\"151430668\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"19b00a2bd1624a0931069a539a971e40b65bfb3a\",\"title\":\"Gaussian Smoothen Semantic Features (GSSF) - Exploring the Linguistic Aspects of Visual Captioning in Indian Languages (Bengali) Using MSCOCO Framework\",\"url\":\"https://www.semanticscholar.org/paper/19b00a2bd1624a0931069a539a971e40b65bfb3a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66879907\",\"name\":\"Sigrid Keydana\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2ec26089b31b4c9a53c805c43de4c30c6b1d396f\",\"title\":\"TensorFlow for R: Attention-based Image Captioning with Keras\",\"url\":\"https://www.semanticscholar.org/paper/2ec26089b31b4c9a53c805c43de4c30c6b1d396f\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19261873\",\"name\":\"Yiwei Wei\"},{\"authorId\":\"2250564\",\"name\":\"Leiquan Wang\"},{\"authorId\":\"51172982\",\"name\":\"Haiwen Cao\"},{\"authorId\":\"134473682\",\"name\":\"Mingwen Shao\"},{\"authorId\":\"46740305\",\"name\":\"Chunlei Wu\"}],\"doi\":\"10.1016/j.neucom.2019.12.073\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"50260b547a481a95a2346759da8dba9366e89348\",\"title\":\"Multi-Attention Generative Adversarial Network for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/50260b547a481a95a2346759da8dba9366e89348\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"1811.00228\",\"authors\":[{\"authorId\":\"143827145\",\"name\":\"Daouda Sow\"},{\"authorId\":\"70565757\",\"name\":\"Zengchang Qin\"},{\"authorId\":\"51910760\",\"name\":\"Mouhamed Niasse\"},{\"authorId\":\"46579572\",\"name\":\"T. Wan\"}],\"doi\":\"10.1109/ICASSP.2019.8682505\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f8ffba70ea41640a4f24fa22613f9e94bdc55576\",\"title\":\"A Sequential Guiding Network with Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/f8ffba70ea41640a4f24fa22613f9e94bdc55576\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151430668\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s11042-019-08021-1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1ba03c16bf25d33efc0d977ab51392e1d9b5a0fb\",\"title\":\"Survey of deep learning and architectures for visual captioning\\u2014transitioning between media and natural languages\",\"url\":\"https://www.semanticscholar.org/paper/1ba03c16bf25d33efc0d977ab51392e1d9b5a0fb\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9741677\",\"name\":\"Senmao Ye\"},{\"authorId\":\"7181955\",\"name\":\"J. Han\"},{\"authorId\":\"143905571\",\"name\":\"Nian Liu\"}],\"doi\":\"10.1109/TIP.2018.2855406\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4dea9cce0825c0cdb1a4a28c4ab8416d6e3e047c\",\"title\":\"Attentive Linear Transformation for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/4dea9cce0825c0cdb1a4a28c4ab8416d6e3e047c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":\"1904.09421\",\"authors\":[{\"authorId\":\"1720243\",\"name\":\"X. Li\"},{\"authorId\":\"12122088\",\"name\":\"Aihong Yuan\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"}],\"doi\":\"10.1007/s11042-018-5856-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c03b9770f8cfa7b1420af68cd4d2236c182df967\",\"title\":\"Multi-modal gated recurrent units for image description\",\"url\":\"https://www.semanticscholar.org/paper/c03b9770f8cfa7b1420af68cd4d2236c182df967\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":\"1911.10132\",\"authors\":[{\"authorId\":\"151430668\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s11042-020-09865-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c8f8ea39c64cf08792cd49c6ad04e85e3b90c88f\",\"title\":\"CRUR: Coupled-Recurrent Unit for Unification, Conceptualization and Context Capture for Language Representation - A Generalization of Bi Directional LSTM\",\"url\":\"https://www.semanticscholar.org/paper/c8f8ea39c64cf08792cd49c6ad04e85e3b90c88f\",\"venue\":\"ArXiv\",\"year\":2019}],\"corpusId\":14169709,\"doi\":\"10.24963/ijcai.2017/563\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":4,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"2498124e6466ccde28c95477c923e7cd5843f4c0\",\"references\":[{\"arxivId\":\"1409.3215\",\"authors\":[{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cea967b59209c6be22829699f05b8b1ac4dc092d\",\"title\":\"Sequence to Sequence Learning with Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/cea967b59209c6be22829699f05b8b1ac4dc092d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1603.03925\",\"authors\":[{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2016.503\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"bf55591e09b58ea9ce8d66110d6d3000ee804bdd\",\"title\":\"Image Captioning with Semantic Attention\",\"url\":\"https://www.semanticscholar.org/paper/bf55591e09b58ea9ce8d66110d6d3000ee804bdd\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1605.09553\",\"authors\":[{\"authorId\":\"50557601\",\"name\":\"Chenxi Liu\"},{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ae9850ce1ba187dc5f9e5ab0da381d8a551c1fc0\",\"title\":\"Attention Correctness in Neural Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/ae9850ce1ba187dc5f9e5ab0da381d8a551c1fc0\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3141511\",\"name\":\"S. Banerjee\"},{\"authorId\":\"1784914\",\"name\":\"A. Lavie\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0cd18e4400ff75b2f8b58d60ddb9b0bc12f489e7\",\"title\":\"METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments\",\"url\":\"https://www.semanticscholar.org/paper/0cd18e4400ff75b2f8b58d60ddb9b0bc12f489e7\",\"venue\":\"IEEvaluation@ACL\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jifeng\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Kaiming He, and Jian Sun. R-fcn: Object detection via region-based fully convolutional networks\",\"url\":\"\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1412.7449\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"40527594\",\"name\":\"L. Kaiser\"},{\"authorId\":\"145096103\",\"name\":\"T. Koo\"},{\"authorId\":\"1754497\",\"name\":\"Slav Petrov\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"47570e7f63e296f224a0e7f9a0d08b0de3cbaf40\",\"title\":\"Grammar as a Foreign Language\",\"url\":\"https://www.semanticscholar.org/paper/47570e7f63e296f224a0e7f9a0d08b0de3cbaf40\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1505.01809\",\"authors\":[{\"authorId\":\"39172707\",\"name\":\"J. Devlin\"},{\"authorId\":\"47413820\",\"name\":\"Hao Cheng\"},{\"authorId\":\"145204655\",\"name\":\"Hao Fang\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"}],\"doi\":\"10.3115/v1/P15-2017\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f142c849ffef66f7520aff4e0b40ac964ccb8cc1\",\"title\":\"Language Models for Image Captioning: The Quirks and What Works\",\"url\":\"https://www.semanticscholar.org/paper/f142c849ffef66f7520aff4e0b40ac964ccb8cc1\",\"venue\":\"ACL\",\"year\":2015},{\"arxivId\":\"1605.06409\",\"authors\":[{\"authorId\":\"3304536\",\"name\":\"Jifeng Dai\"},{\"authorId\":\"47001807\",\"name\":\"Y. Li\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b724c3f7ff395235b62537203ddeb710f0eb27bb\",\"title\":\"R-FCN: Object Detection via Region-based Fully Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/b724c3f7ff395235b62537203ddeb710f0eb27bb\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1162/neco.1997.9.8.1735\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"title\":\"Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"venue\":\"Neural Computation\",\"year\":1997},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Subhashini Venugopalan\"},{\"authorId\":null,\"name\":\"Marcus Rohrbach\"},{\"authorId\":null,\"name\":\"Jeffrey Donahue\"},{\"authorId\":null,\"name\":\"Raymond Mooney\"},{\"authorId\":null,\"name\":\"Trevor Darrell\"},{\"authorId\":null,\"name\":\"Kate Saenko. Sequence to sequence - video to text\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In The IEEE International Conference on Computer Vision (ICCV)\",\"url\":\"\",\"venue\":\"December\",\"year\":2015},{\"arxivId\":\"1412.2306\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/TPAMI.2016.2598339\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"title\":\"Deep Visual-Semantic Alignments for Generating Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":\"1411.5726\",\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2015.7299087\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"258986132bf17755fe8263e42429fe73218c1534\",\"title\":\"CIDEr: Consensus-based image description evaluation\",\"url\":\"https://www.semanticscholar.org/paper/258986132bf17755fe8263e42429fe73218c1534\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1607.08822\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1007/978-3-319-46454-1_24\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1c54acd7d9ed8017acdc5674c9b7faac738fd651\",\"title\":\"SPICE: Semantic Propositional Image Caption Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/1c54acd7d9ed8017acdc5674c9b7faac738fd651\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5115386\",\"name\":\"Yunchao Gong\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2170746\",\"name\":\"M. Hodosh\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1007/978-3-319-10593-2_35\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fa0cc5fcd2faa4591dd53504d0c5115783a2d2b6\",\"title\":\"Improving Image-Sentence Embeddings Using Large Weakly Annotated Photo Collections\",\"url\":\"https://www.semanticscholar.org/paper/fa0cc5fcd2faa4591dd53504d0c5115783a2d2b6\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1109/CVPR.2015.7298856\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a72b8bbd039989db39769da836cdb287737deb92\",\"title\":\"Mind's eye: A recurrent visual representation for image caption generation\",\"url\":\"https://www.semanticscholar.org/paper/a72b8bbd039989db39769da836cdb287737deb92\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Minh-Thang Luong\"},{\"authorId\":null,\"name\":\"Hieu Pham\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Manning . Effective approaches to attention - based neural machine translation\",\"url\":\"\",\"venue\":\"Attention correctness in neural image captioning\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"143694777\",\"name\":\"Frank Keller\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3f6a4556769e819242d669d073b895f1e45a706f\",\"title\":\"Image Description using Visual Dependency Representations\",\"url\":\"https://www.semanticscholar.org/paper/3f6a4556769e819242d669d073b895f1e45a706f\",\"venue\":\"EMNLP\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2015.7298932\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"title\":\"Deep visual-semantic alignments for generating image descriptions\",\"url\":\"https://www.semanticscholar.org/paper/ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"venue\":\"CVPR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47087291\",\"name\":\"Z. Yang\"},{\"authorId\":\"30556331\",\"name\":\"Y. Yuan\"},{\"authorId\":\"9287688\",\"name\":\"Yuexin Wu\"},{\"authorId\":\"50056360\",\"name\":\"William W. Cohen\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"61d2dda8d96a10a714636475c7589bd149bda053\",\"title\":\"Review Networks for Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/61d2dda8d96a10a714636475c7589bd149bda053\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Qi Wu\"},{\"authorId\":null,\"name\":\"Chunhua Shen\"},{\"authorId\":null,\"name\":\"Lingqiao Liu\"},{\"authorId\":null,\"name\":\"Anthony Dick\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and Anton van den Hengel\",\"url\":\"\",\"venue\":\"What value do explicit high level concepts have in vision to language problems? In CVPR,\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jacob Devlin\"},{\"authorId\":null,\"name\":\"Hao Cheng\"},{\"authorId\":null,\"name\":\"Hao Fang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and et al\",\"url\":\"\",\"venue\":\"Language models for image captioning: The quirks and what works. In ACL,\",\"year\":2015},{\"arxivId\":\"1409.0473\",\"authors\":[{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"title\":\"Neural Machine Translation by Jointly Learning to Align and Translate\",\"url\":\"https://www.semanticscholar.org/paper/fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Hochreiter\"},{\"authorId\":null,\"name\":\"Schmidhuber\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Sepp Hochreiter and J\\u00fcrgen Schmidhuber. Long short-term memory\",\"url\":\"\",\"venue\":\"Neural computation\",\"year\":1997},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145592791\",\"name\":\"P. Kuznetsova\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":\"10.1162/tacl_a_00188\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"59927ded86ab4f7253fc32efb351e5a13e746ead\",\"title\":\"TreeTalk: Composition and Compression of Trees for Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/59927ded86ab4f7253fc32efb351e5a13e746ead\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1644696911\",\"name\":\"DonahueJeff\"},{\"authorId\":\"1644694750\",\"name\":\"HendricksLisa Anne\"},{\"authorId\":\"1643893071\",\"name\":\"RohrbachMarcus\"},{\"authorId\":\"1644695575\",\"name\":\"VenugopalanSubhashini\"},{\"authorId\":\"1644695790\",\"name\":\"GuadarramaSergio\"},{\"authorId\":\"1644694743\",\"name\":\"SaenkoKate\"},{\"authorId\":\"1644040226\",\"name\":\"DarrellTrevor\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6bb892e8dd4fe4ff6a92470cd991c31c1aebaa99\",\"title\":\"Long-Term Recurrent Convolutional Networks for Visual Recognition and Description\",\"url\":\"https://www.semanticscholar.org/paper/6bb892e8dd4fe4ff6a92470cd991c31c1aebaa99\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Chin-Yew Lin\"},{\"authorId\":null,\"name\":\"Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Ilya Sutskever, Oriol Vinyals, and Quoc VV Le. Sequence to sequence learning with neural networks\",\"url\":\"\",\"venue\":\"Text summarization branches out: Proceedings of the ACL-04 workshop\",\"year\":2002},{\"arxivId\":\"1411.4952\",\"authors\":[{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3346186\",\"name\":\"Forrest N. Iandola\"},{\"authorId\":\"2100612\",\"name\":\"R. Srivastava\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"144189092\",\"name\":\"John C. Platt\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"}],\"doi\":\"10.1109/CVPR.2015.7298754\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"title\":\"From captions to visual concepts and back\",\"url\":\"https://www.semanticscholar.org/paper/15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"34176020\",\"name\":\"Jesse Dodge\"},{\"authorId\":\"46479604\",\"name\":\"Amit Goyal\"},{\"authorId\":\"1721910\",\"name\":\"Kota Yamaguchi\"},{\"authorId\":\"1714215\",\"name\":\"K. Stratos\"},{\"authorId\":\"1682965\",\"name\":\"Xufeng Han\"},{\"authorId\":\"40614240\",\"name\":\"A. Mensch\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1722360\",\"name\":\"Hal Daum\\u00e9\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"355de7460120ddc1150d9ce3756f9848983f7ff4\",\"title\":\"Midge: Generating Image Descriptions From Computer Vision Detections\",\"url\":\"https://www.semanticscholar.org/paper/355de7460120ddc1150d9ce3756f9848983f7ff4\",\"venue\":\"EACL\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49692927\",\"name\":\"Sepp Hochreiter\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"aed054834e2c696807cc8b227ac7a4197196e211\",\"title\":\"Gradient Flow in Recurrent Nets: the Difficulty of Learning Long-Term Dependencies\",\"url\":\"https://www.semanticscholar.org/paper/aed054834e2c696807cc8b227ac7a4197196e211\",\"venue\":\"\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Kelvin Xu\"},{\"authorId\":null,\"name\":\"Jimmy Ba\"},{\"authorId\":null,\"name\":\"Ryan Kiros\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"and et al\",\"url\":\"\",\"venue\":\"Show, attend and tell: Neural image caption generation with visual attention. In ICML,\",\"year\":2015},{\"arxivId\":\"1505.00487\",\"authors\":[{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/ICCV.2015.515\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e58a110fa1e4ddf247d5c614d117d64bfbe135c4\",\"title\":\"Sequence to Sequence -- Video to Text\",\"url\":\"https://www.semanticscholar.org/paper/e58a110fa1e4ddf247d5c614d117d64bfbe135c4\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1506.01144\",\"authors\":[{\"authorId\":\"34902783\",\"name\":\"Qi Wu\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2016.29\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"00fe3d95d0fd5f1433d81405bee772c4fe9af9c6\",\"title\":\"What Value Do Explicit High Level Concepts Have in Vision to Language Problems?\",\"url\":\"https://www.semanticscholar.org/paper/00fe3d95d0fd5f1433d81405bee772c4fe9af9c6\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1781574\",\"name\":\"Chin-Yew Lin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"60b05f32c32519a809f21642ef1eb3eaf3848008\",\"title\":\"ROUGE: A Package for Automatic Evaluation of Summaries\",\"url\":\"https://www.semanticscholar.org/paper/60b05f32c32519a809f21642ef1eb3eaf3848008\",\"venue\":\"ACL 2004\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3323275\",\"name\":\"Kishore Papineni\"},{\"authorId\":\"1781292\",\"name\":\"S. Roukos\"},{\"authorId\":\"144582029\",\"name\":\"T. Ward\"},{\"authorId\":\"2587983\",\"name\":\"Wei-Jing Zhu\"}],\"doi\":\"10.3115/1073083.1073135\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d7da009f457917aa381619facfa5ffae9329a6e9\",\"title\":\"Bleu: a Method for Automatic Evaluation of Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/d7da009f457917aa381619facfa5ffae9329a6e9\",\"venue\":\"ACL\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"You\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Quanzeng You Chen Fang, and Jiebo Luo. Image captioning with semantic attention\",\"url\":\"\",\"venue\":\"CVPR\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Sepp Hochreiter\"},{\"authorId\":null,\"name\":\"Yoshua Bengio\"},{\"authorId\":null,\"name\":\"Paolo Frasconi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and J\\u00fcrgen Schmidhuber\",\"url\":\"\",\"venue\":\"Gradient flow in recurrent nets: the difficulty of learning long-term dependencies,\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Hao Fang\"},{\"authorId\":null,\"name\":\"Saurabh Gupta\"},{\"authorId\":null,\"name\":\"Forrest Iandola\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and et al\",\"url\":\"\",\"venue\":\"From captions to visual concepts and back. In CVPR,\",\"year\":2015},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/CVPR.2015.7298878\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5838af587938e74b5758414c384dcf16dd6e1d1e\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/5838af587938e74b5758414c384dcf16dd6e1d1e\",\"venue\":\"CVPR\",\"year\":2015},{\"arxivId\":\"1508.04025\",\"authors\":[{\"authorId\":\"1821711\",\"name\":\"Thang Luong\"},{\"authorId\":\"143950636\",\"name\":\"Hieu Pham\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.18653/v1/D15-1166\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"93499a7c7f699b6630a86fad964536f9423bb6d0\",\"title\":\"Effective Approaches to Attention-based Neural Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/93499a7c7f699b6630a86fad964536f9423bb6d0\",\"venue\":\"EMNLP\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"1756655\",\"name\":\"C. L. Teo\"},{\"authorId\":\"1722360\",\"name\":\"Hal Daum\\u00e9\"},{\"authorId\":\"1697493\",\"name\":\"Y. Aloimonos\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"76a1dca3a9c2b0229c1b12c95752dcf40dc95a11\",\"title\":\"Corpus-Guided Sentence Generation of Natural Images\",\"url\":\"https://www.semanticscholar.org/paper/76a1dca3a9c2b0229c1b12c95752dcf40dc95a11\",\"venue\":\"EMNLP\",\"year\":2011},{\"arxivId\":\"1504.06692\",\"authors\":[{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"144287022\",\"name\":\"Xu Wei\"},{\"authorId\":\"143907244\",\"name\":\"Yi Yang\"},{\"authorId\":\"152924551\",\"name\":\"J. Wang\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.1109/ICCV.2015.291\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb847564774394c484e701437dbcffbf040ff3cc\",\"title\":\"Learning Like a Child: Fast Novel Visual Concept Learning from Sentence Descriptions of Images\",\"url\":\"https://www.semanticscholar.org/paper/eb847564774394c484e701437dbcffbf040ff3cc\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Minh-Thang Luong\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Effective approaches to attentionbased neural machine translation\",\"url\":\"\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015}],\"title\":\"MAT: A Multimodal Attentive Translator for Image Captioning\",\"topics\":[{\"topic\":\"Convolutional neural network\",\"topicId\":\"29860\",\"url\":\"https://www.semanticscholar.org/topic/29860\"},{\"topic\":\"Multimodal interaction\",\"topicId\":\"42592\",\"url\":\"https://www.semanticscholar.org/topic/42592\"},{\"topic\":\"Machine translation\",\"topicId\":\"34995\",\"url\":\"https://www.semanticscholar.org/topic/34995\"},{\"topic\":\"Recurrent neural network\",\"topicId\":\"16115\",\"url\":\"https://www.semanticscholar.org/topic/16115\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Server (computing)\",\"topicId\":\"6042\",\"url\":\"https://www.semanticscholar.org/topic/6042\"},{\"topic\":\"Random neural network\",\"topicId\":\"136146\",\"url\":\"https://www.semanticscholar.org/topic/136146\"},{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"}],\"url\":\"https://www.semanticscholar.org/paper/2498124e6466ccde28c95477c923e7cd5843f4c0\",\"venue\":\"IJCAI\",\"year\":2017}\n"