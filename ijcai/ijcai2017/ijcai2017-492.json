"{\"abstract\":\"Open-ended video question answering is a challenging problem in visual information retrieval, which automatically generates the natural language answer from the referenced video content according to the question. However, the existing visual question answering works only focus on the static image, which may be ineffectively applied to video question answering due to the lack of modeling the temporal dynamics of video contents. In this paper, we consider the problem of open-ended video question answering from the viewpoint of spatio-temporal attentional encoderdecoder learning framework. We propose the hierarchical spatio-temporal attention network for learning the joint representation of the dynamic video contents according to the given question. We then develop the spatio-temporal attentional encoder-decoder learning method with multi-step reasoning process for open-ended video question answering. We construct a large-scale video question answering dataset. The extensive experiments show the effectiveness of our method.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\",\"url\":\"https://www.semanticscholar.org/author/47122432\"},{\"authorId\":\"9390267\",\"name\":\"Qifan Yang\",\"url\":\"https://www.semanticscholar.org/author/9390267\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\",\"url\":\"https://www.semanticscholar.org/author/1724421\"},{\"authorId\":\"3945955\",\"name\":\"X. He\",\"url\":\"https://www.semanticscholar.org/author/3945955\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\",\"url\":\"https://www.semanticscholar.org/author/143749205\"}],\"citationVelocity\":18,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"50846763\",\"name\":\"W. Zhang\"},{\"authorId\":\"1774936\",\"name\":\"Siliang Tang\"},{\"authorId\":\"48696362\",\"name\":\"Yanpeng Cao\"},{\"authorId\":\"145974114\",\"name\":\"Jun Xiao\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"},{\"authorId\":\"144894845\",\"name\":\"Fei Wu\"},{\"authorId\":\"2125211\",\"name\":\"Yueting Zhuang\"}],\"doi\":\"10.1145/3394171.3413745\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a95d2cad9fd439831d1d0c05d6bf7d1731dcefe8\",\"title\":\"Photo Stream Question Answer\",\"url\":\"https://www.semanticscholar.org/paper/a95d2cad9fd439831d1d0c05d6bf7d1731dcefe8\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1812.00344\",\"authors\":[{\"authorId\":\"1769749\",\"name\":\"S. Wang\"},{\"authorId\":\"29367810\",\"name\":\"Wentian Zhao\"},{\"authorId\":\"16132631\",\"name\":\"Z. Kou\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e7d1c2d4b4ca2bf3109757f181bc2cf15240fcc5\",\"title\":\"How to Make a BLT Sandwich? Learning to Reason towards Understanding Web Instructional Videos\",\"url\":\"https://www.semanticscholar.org/paper/e7d1c2d4b4ca2bf3109757f181bc2cf15240fcc5\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"1764508\",\"name\":\"Z. Zhang\"},{\"authorId\":\"2440041\",\"name\":\"X. Jiang\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"}],\"doi\":\"10.1109/TIP.2019.2902106\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"65bd828c05cac7eabe791e10d4d3c0f2da2b798c\",\"title\":\"Multi-Turn Video Question Answering via Hierarchical Attention Context Reinforced Networks\",\"url\":\"https://www.semanticscholar.org/paper/65bd828c05cac7eabe791e10d4d3c0f2da2b798c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41052836\",\"name\":\"Anya Belz\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"}],\"doi\":\"10.1017/S1351324918000086\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d740802aa22dbc187fe5df39108ba493b34d2839\",\"title\":\"From image to language and back again\",\"url\":\"https://www.semanticscholar.org/paper/d740802aa22dbc187fe5df39108ba493b34d2839\",\"venue\":\"Nat. Lang. Eng.\",\"year\":2018},{\"arxivId\":\"1907.03049\",\"authors\":[{\"authorId\":null,\"name\":\"Yu-Siang Wang\"},{\"authorId\":\"71309591\",\"name\":\"Hung-Ting Su\"},{\"authorId\":\"150053992\",\"name\":\"Chen-Hsi Chang\"},{\"authorId\":\"143822897\",\"name\":\"Zhe Yu Liu\"},{\"authorId\":\"31871157\",\"name\":\"Winston Hsu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"091ad302f5381bd131b41a57e16d802ff4ab9668\",\"title\":\"Video Question Generation via Cross-Modal Self-Attention Networks Learning\",\"url\":\"https://www.semanticscholar.org/paper/091ad302f5381bd131b41a57e16d802ff4ab9668\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2338742\",\"name\":\"Y. Jang\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"32821535\",\"name\":\"C. D. Kim\"},{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"49170458\",\"name\":\"Youngjin Kim\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1007/s11263-019-01189-x\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1e1bd132613866c176a8fc780cb1b9f9aa43feeb\",\"title\":\"Video Question Answering with Spatio-Temporal Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/1e1bd132613866c176a8fc780cb1b9f9aa43feeb\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145488619\",\"name\":\"M. Liu\"},{\"authorId\":null,\"name\":\"Xiang Wang\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":\"7792071\",\"name\":\"X. He\"},{\"authorId\":\"1748939\",\"name\":\"B. Chen\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1145/3209978.3210003\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"519da94369c1d87e09c592f239b55cc9486b5b7c\",\"title\":\"Attentive Moment Retrieval in Videos\",\"url\":\"https://www.semanticscholar.org/paper/519da94369c1d87e09c592f239b55cc9486b5b7c\",\"venue\":\"SIGIR\",\"year\":2018},{\"arxivId\":\"2002.10698\",\"authors\":[{\"authorId\":\"47267313\",\"name\":\"T. Le\"},{\"authorId\":\"144672395\",\"name\":\"Vuong Le\"},{\"authorId\":\"144162181\",\"name\":\"S. Venkatesh\"},{\"authorId\":\"6254479\",\"name\":\"T. Tran\"}],\"doi\":\"10.1109/cvpr42600.2020.00999\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"53de96cf981c9d58a86697d812484808945b47f5\",\"title\":\"Hierarchical Conditional Relation Networks for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/53de96cf981c9d58a86697d812484808945b47f5\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67144160\",\"name\":\"Mao Gu\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"150337817\",\"name\":\"Weike Jin\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"},{\"authorId\":\"144894837\",\"name\":\"F. Wu\"}],\"doi\":\"10.1109/TCSVT.2019.2957309\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1c0acaec480993efb5f882cea44879545dd5687c\",\"title\":\"Video Dialog via Multi-Grained Convolutional Self-Attention Context Multi-Modal Networks\",\"url\":\"https://www.semanticscholar.org/paper/1c0acaec480993efb5f882cea44879545dd5687c\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"1809.10889\",\"authors\":[{\"authorId\":\"143863530\",\"name\":\"Zheyi Pan\"},{\"authorId\":\"3431194\",\"name\":\"Yuxuan Liang\"},{\"authorId\":\"8214994\",\"name\":\"J. Zhang\"},{\"authorId\":\"2098291\",\"name\":\"Xiuwen Yi\"},{\"authorId\":\"1811427\",\"name\":\"Y. Yu\"},{\"authorId\":\"118961885\",\"name\":\"Y. Zheng\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"995b3247589fc80c08a0891bc74ccb1ad6e4d2bd\",\"title\":\"HyperST-Net: Hypernetworks for Spatio-Temporal Forecasting\",\"url\":\"https://www.semanticscholar.org/paper/995b3247589fc80c08a0891bc74ccb1ad6e4d2bd\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48915513\",\"name\":\"P. Johnston\"},{\"authorId\":\"1807106\",\"name\":\"Eyad Elyan\"},{\"authorId\":\"8683625\",\"name\":\"C. Jayne\"}],\"doi\":\"10.1109/IJCNN.2018.8489370\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c08ce05d1d096fb8410859b2134f38b3db308b6f\",\"title\":\"Spatial Effects of Video Compression on Classification in Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/c08ce05d1d096fb8410859b2134f38b3db308b6f\",\"venue\":\"2018 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2125211\",\"name\":\"Yueting Zhuang\"},{\"authorId\":\"50854337\",\"name\":\"D. Xu\"},{\"authorId\":\"1491414917\",\"name\":\"Xin Yan\"},{\"authorId\":\"4004957\",\"name\":\"W. Cheng\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"},{\"authorId\":\"1384523745\",\"name\":\"Jun Xiao\"}],\"doi\":\"10.1145/3366710\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"26997b5e761bfa0f98331e297b6e9518fef3ece1\",\"title\":\"Multichannel Attention Refinement for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/26997b5e761bfa0f98331e297b6e9518fef3ece1\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145940233\",\"name\":\"Xiu Jin\"},{\"authorId\":\"50493987\",\"name\":\"L. Jie\"},{\"authorId\":null,\"name\":\"Shuai Wang\"},{\"authorId\":\"30117473\",\"name\":\"Haijun Qi\"},{\"authorId\":\"48830770\",\"name\":\"S. Li\"}],\"doi\":\"10.3390/rs10030395\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f57fac8810ae67cb0df9b42ff52d34b82799f4dc\",\"title\":\"Classifying Wheat Hyperspectral Pixels of Healthy Heads and Fusarium Head Blight Disease Using a Deep Neural Network in the Wild Field\",\"url\":\"https://www.semanticscholar.org/paper/f57fac8810ae67cb0df9b42ff52d34b82799f4dc\",\"venue\":\"Remote. Sens.\",\"year\":2018},{\"arxivId\":\"1712.01892\",\"authors\":[{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"2520427\",\"name\":\"Yulei Niu\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1109/CVPR.2018.00437\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"69d576ffe624f11fe4e84a03d4063856a5af838f\",\"title\":\"Grounding Referring Expressions in Images by Variational Context\",\"url\":\"https://www.semanticscholar.org/paper/69d576ffe624f11fe4e84a03d4063856a5af838f\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46702644\",\"name\":\"H. Zhang\"},{\"authorId\":\"1888678\",\"name\":\"Miao Xin\"},{\"authorId\":\"49185004\",\"name\":\"Shuhang Wang\"},{\"authorId\":\"46285365\",\"name\":\"Yifan Yang\"},{\"authorId\":\"36794849\",\"name\":\"L. Zhang\"},{\"authorId\":\"2512046\",\"name\":\"Helong Wang\"}],\"doi\":\"10.1007/s00138-018-0956-5\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e8a150b743d487e9dbf6e023b0928f03b2c39aef\",\"title\":\"End-to-end temporal attention extraction and human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/e8a150b743d487e9dbf6e023b0928f03b2c39aef\",\"venue\":\"Machine Vision and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738318751\",\"name\":\"Sinan Tan\"},{\"authorId\":\"3449051\",\"name\":\"Weilai Xiang\"},{\"authorId\":\"2641547\",\"name\":\"H. Liu\"},{\"authorId\":\"1960245583\",\"name\":\"Di Guo\"},{\"authorId\":\"143823065\",\"name\":\"F. Sun\"}],\"doi\":\"10.1007/978-3-030-58601-0_39\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5ed523871586b0f883e4ec890155075b96291a13\",\"title\":\"Multi-agent Embodied Question Answering in Interactive Environments\",\"url\":\"https://www.semanticscholar.org/paper/5ed523871586b0f883e4ec890155075b96291a13\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1811.05021\",\"authors\":[{\"authorId\":\"2389866\",\"name\":\"Yao Wan\"},{\"authorId\":\"143890941\",\"name\":\"Wenqiang Yan\"},{\"authorId\":\"3120119\",\"name\":\"J. Gao\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"49387520\",\"name\":\"J. Wu\"},{\"authorId\":\"144019071\",\"name\":\"Philip S. Yu\"}],\"doi\":\"10.1109/BigData.2018.8622245\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fd54d2e50639e0b237d5ff8db195106d6bb3d42e\",\"title\":\"Improved Dynamic Memory Network for Dialogue Act Classification with Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/fd54d2e50639e0b237d5ff8db195106d6bb3d42e\",\"venue\":\"2018 IEEE International Conference on Big Data (Big Data)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"2440041\",\"name\":\"X. Jiang\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"},{\"authorId\":\"145974112\",\"name\":\"Jun Xiao\"},{\"authorId\":\"3945955\",\"name\":\"X. He\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"}],\"doi\":\"10.24963/ijcai.2018/513\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"396b9b7e7836632eb5e94ddb637c98b0d0cf34a3\",\"title\":\"Multi-Turn Video Question Answering via Multi-Stream Hierarchical Attention Context Network\",\"url\":\"https://www.semanticscholar.org/paper/396b9b7e7836632eb5e94ddb637c98b0d0cf34a3\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51237531\",\"name\":\"Shaoning Xiao\"},{\"authorId\":\"48515305\",\"name\":\"Yimeng Li\"},{\"authorId\":\"22228139\",\"name\":\"Yunan Ye\"},{\"authorId\":null,\"name\":\"Long Chen\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"2549731\",\"name\":\"Jian Shao\"},{\"authorId\":\"145974112\",\"name\":\"Jun Xiao\"}],\"doi\":\"10.1007/s11063-019-10003-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8bf0b37ed005285b6cbef70a78434978ca065120\",\"title\":\"Hierarchical Temporal Fusion of Multi-grained Attention Features for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8bf0b37ed005285b6cbef70a78434978ca065120\",\"venue\":\"Neural Processing Letters\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150337817\",\"name\":\"Weike Jin\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"67144160\",\"name\":\"Mao Gu\"},{\"authorId\":\"9919436\",\"name\":\"J. Yu\"},{\"authorId\":\"145974111\",\"name\":\"Jun Xiao\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1145/3331184.3331240\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f8954b3f74373e953b4449efca71e5ec6be46fb6\",\"title\":\"Video Dialog via Multi-Grained Convolutional Self-Attention Context Networks\",\"url\":\"https://www.semanticscholar.org/paper/f8954b3f74373e953b4449efca71e5ec6be46fb6\",\"venue\":\"SIGIR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1930287\",\"name\":\"L. Zhang\"},{\"authorId\":\"1772337\",\"name\":\"R. Radke\"}],\"doi\":\"10.1145/3382507.3418886\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c43909efc347aab615a8688e0329d5b3d2cc1b62\",\"title\":\"Temporal Attention and Consistency Measuring for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/c43909efc347aab615a8688e0329d5b3d2cc1b62\",\"venue\":\"ICMI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2653622\",\"name\":\"Junfu Pu\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"}],\"doi\":\"10.24963/ijcai.2018/123\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9d8ef2cbaaf8281600135670d44dda3acd82e1aa\",\"title\":\"Dilated Convolutional Network with Iterative Optimization for Continuous Sign Language Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9d8ef2cbaaf8281600135670d44dda3acd82e1aa\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7499906\",\"name\":\"Xiaomeng Song\"},{\"authorId\":\"46571755\",\"name\":\"Yucheng Shi\"},{\"authorId\":\"46772058\",\"name\":\"X. Chen\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"}],\"doi\":\"10.1145/3240508.3240563\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b08c35f8e529f47a3fdc4f0713ffe77d94c57d87\",\"title\":\"Explore Multi-Step Reasoning in Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b08c35f8e529f47a3fdc4f0713ffe77d94c57d87\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152968916\",\"name\":\"Tianhao Yang\"},{\"authorId\":\"51260253\",\"name\":\"Z. Zha\"},{\"authorId\":\"143994657\",\"name\":\"Hongtao Xie\"},{\"authorId\":\"152808542\",\"name\":\"Meng Wang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"}],\"doi\":\"10.1145/3343031.3350969\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2af3819e12239162525259295111d2114d7e3072\",\"title\":\"Question-Aware Tube-Switch Network for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2af3819e12239162525259295111d2114d7e3072\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2712862\",\"name\":\"D. Zhang\"},{\"authorId\":\"145690873\",\"name\":\"R. Cao\"},{\"authorId\":\"1765710\",\"name\":\"Sai Wu\"}],\"doi\":\"10.1016/J.INFFUS.2019.03.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"91118408f8192c2addade2a0401a32c3bbd47818\",\"title\":\"Information fusion in visual question answering: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/91118408f8192c2addade2a0401a32c3bbd47818\",\"venue\":\"Inf. Fusion\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2151048\",\"name\":\"Taiki Miyanishi\"},{\"authorId\":\"34772057\",\"name\":\"Takuya Maekawa\"},{\"authorId\":\"1716788\",\"name\":\"M. Kawanabe\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b3fc587b83d8c6a28b2bc4f9a1f8770f42fb5658\",\"title\":\"Two-Stream Spatiotemporal Compositional Attention Network for VideoQA\",\"url\":\"https://www.semanticscholar.org/paper/b3fc587b83d8c6a28b2bc4f9a1f8770f42fb5658\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9691752\",\"name\":\"Y. Wang\"},{\"authorId\":\"3143685\",\"name\":\"Y. Xu\"},{\"authorId\":\"144346837\",\"name\":\"Min Yang\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"145974111\",\"name\":\"Jun Xiao\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1145/3132847.3133136\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d097d75077ff9c626f74b0413a690011dcb56bee\",\"title\":\"Integrating Side Information for Boosting Machine Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/d097d75077ff9c626f74b0413a690011dcb56bee\",\"venue\":\"CIKM\",\"year\":2017},{\"arxivId\":\"2012.00451\",\"authors\":[{\"authorId\":\"153276988\",\"name\":\"Antoine Yang\"},{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"153433844\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b1b6ff0df21818ac8c4f61d86141da48188f36b3\",\"title\":\"Just Ask: Learning to Answer Questions from Millions of Narrated Videos\",\"url\":\"https://www.semanticscholar.org/paper/b1b6ff0df21818ac8c4f61d86141da48188f36b3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.16010\",\"authors\":[{\"authorId\":\"1390575046\",\"name\":\"Yangyang Guo\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":\"46504200\",\"name\":\"Zhiyong Cheng\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9b9e35875ad771961ad2d35f7b9cd645b96afd04\",\"title\":\"Loss-rescaling VQA: Revisiting Language Prior Problem from a Class-imbalance View\",\"url\":\"https://www.semanticscholar.org/paper/9b9e35875ad771961ad2d35f7b9cd645b96afd04\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49597404\",\"name\":\"Z. Fang\"},{\"authorId\":null,\"name\":\"Jing Liu\"},{\"authorId\":\"49544292\",\"name\":\"Xueliang Liu\"},{\"authorId\":null,\"name\":\"Qu Tang\"},{\"authorId\":\"50025104\",\"name\":\"Yonghong Li\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1145/3282469\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c74311cc5e18a120bebf331b0dd85c72426380d\",\"title\":\"BTDP: Toward Sparse Fusion with Block Term Decomposition Pooling for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2c74311cc5e18a120bebf331b0dd85c72426380d\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51021338\",\"name\":\"Nelson Ruwa\"},{\"authorId\":\"3069077\",\"name\":\"Q. Mao\"},{\"authorId\":\"79927338\",\"name\":\"L. Wang\"},{\"authorId\":\"37233332\",\"name\":\"J. Gou\"}],\"doi\":\"10.1016/J.NEUCOM.2019.06.046\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1b6ce7e65130431eecf98db2e6c162893bbe5127\",\"title\":\"Affective question answering on video\",\"url\":\"https://www.semanticscholar.org/paper/1b6ce7e65130431eecf98db2e6c162893bbe5127\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50854337\",\"name\":\"D. Xu\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"145974111\",\"name\":\"Jun Xiao\"},{\"authorId\":\"144894849\",\"name\":\"Fei Wu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"7792071\",\"name\":\"X. He\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1145/3123266.3123427\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"057b80e235b10799d03876ad25465208a4c64caf\",\"title\":\"Video Question Answering via Gradually Refined Attention over Appearance and Motion\",\"url\":\"https://www.semanticscholar.org/paper/057b80e235b10799d03876ad25465208a4c64caf\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":\"1907.03609\",\"authors\":[{\"authorId\":\"2520427\",\"name\":\"Yulei Niu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1776220\",\"name\":\"Zhiwu Lu\"},{\"authorId\":\"70351911\",\"name\":\"Shih-Fu Chang\"}],\"doi\":\"10.1109/TPAMI.2019.2926266\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"df9c0a59bdbd54be299ca63b60773eed62e2c611\",\"title\":\"Variational Context: Exploiting Visual and Textual Context for Grounding Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/df9c0a59bdbd54be299ca63b60773eed62e2c611\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2389866\",\"name\":\"Yao Wan\"},{\"authorId\":\"143890943\",\"name\":\"Wenqiang Yan\"},{\"authorId\":\"3120119\",\"name\":\"J. Gao\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"39903187\",\"name\":\"J. Wu\"},{\"authorId\":\"144019071\",\"name\":\"Philip S. Yu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bac495af48328fcdf53992057ca95eb7b0dd6ad6\",\"title\":\"General question module Word level ( a ) Hierarchical pyramid utterance encoder bother\",\"url\":\"https://www.semanticscholar.org/paper/bac495af48328fcdf53992057ca95eb7b0dd6ad6\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1865719481\",\"name\":\"Deepak Gupta\"},{\"authorId\":\"27563697\",\"name\":\"Pabitra Lenka\"},{\"authorId\":\"1734904\",\"name\":\"Asif Ekbal\"},{\"authorId\":\"145532184\",\"name\":\"P. Bhattacharyya\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6ba2a128dd8dadc2925b3b9c01fb6db01bd75066\",\"title\":\"A Unified Framework for Multilingual and Code-Mixed Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/6ba2a128dd8dadc2925b3b9c01fb6db01bd75066\",\"venue\":\"AACL/IJCNLP\",\"year\":2020},{\"arxivId\":\"1904.09317\",\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"153677280\",\"name\":\"Robik Shrestha\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.3389/frai.2019.00028\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"78f36f2acb0c88cfe74572933cb52c9cc75a1d50\",\"title\":\"Challenges and Prospects in Vision and Language Research\",\"url\":\"https://www.semanticscholar.org/paper/78f36f2acb0c88cfe74572933cb52c9cc75a1d50\",\"venue\":\"Front. Artif. Intell.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49597404\",\"name\":\"Z. Fang\"},{\"authorId\":\"46700426\",\"name\":\"J. Liu\"},{\"authorId\":\"47003032\",\"name\":\"Y. Li\"},{\"authorId\":\"80526284\",\"name\":\"Yanyuan Qiao\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1016/J.PATCOG.2019.01.038\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aa31126aa9dc7665bf236a51c6de31c4bf6c59ad\",\"title\":\"Improving visual question answering using dropout and enhanced question encoder\",\"url\":\"https://www.semanticscholar.org/paper/aa31126aa9dc7665bf236a51c6de31c4bf6c59ad\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"9515493\",\"name\":\"Liangfu Cao\"},{\"authorId\":\"48669907\",\"name\":\"X. Xu\"},{\"authorId\":\"145496508\",\"name\":\"J. Shao\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"}],\"doi\":\"10.1016/J.NEUCOM.2018.11.102\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"be63949be4151ed73503b3eb218aa9175233661b\",\"title\":\"Question-Led object attention for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/be63949be4151ed73503b3eb218aa9175233661b\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51237531\",\"name\":\"Shaoning Xiao\"},{\"authorId\":\"48515305\",\"name\":\"Yimeng Li\"},{\"authorId\":\"22228139\",\"name\":\"Yunan Ye\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"145974111\",\"name\":\"Jun Xiao\"},{\"authorId\":\"144894849\",\"name\":\"Fei Wu\"},{\"authorId\":\"48566761\",\"name\":\"Jiang Zhu\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1145/3240876.3240885\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e4e599fa3ca042d30321aa5502a135c1de87e688\",\"title\":\"Video question answering via multi-granularity temporal attention network learning\",\"url\":\"https://www.semanticscholar.org/paper/e4e599fa3ca042d30321aa5502a135c1de87e688\",\"venue\":\"ICIMCS '18\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22228139\",\"name\":\"Yunan Ye\"},{\"authorId\":\"101266543\",\"name\":\"Shifeng Zhang\"},{\"authorId\":\"48515305\",\"name\":\"Yimeng Li\"},{\"authorId\":\"152519410\",\"name\":\"Xufeng Qian\"},{\"authorId\":\"1774936\",\"name\":\"Siliang Tang\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"},{\"authorId\":\"153269968\",\"name\":\"Jun Xiao\"}],\"doi\":\"10.1016/j.ipm.2020.102265\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"32589847320c3c783e6eaf512e7723b8d5f5fb0a\",\"title\":\"Video question answering via grounded cross-attention network learning\",\"url\":\"https://www.semanticscholar.org/paper/32589847320c3c783e6eaf512e7723b8d5f5fb0a\",\"venue\":\"Inf. Process. Manag.\",\"year\":2020},{\"arxivId\":\"1904.11574\",\"authors\":[{\"authorId\":\"46665218\",\"name\":\"Jie Lei\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/2020.acl-main.730\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb1b368ca847846774ee41af6da906ab77013313\",\"title\":\"TVQA+: Spatio-Temporal Grounding for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/eb1b368ca847846774ee41af6da906ab77013313\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"48210950\",\"name\":\"Jiawei Liu\"},{\"authorId\":\"49876189\",\"name\":\"T. Yang\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.1145/3320061\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"86ce76f54a7bfc6047f83877408f789449f28df4\",\"title\":\"Spatiotemporal-Textual Co-Attention Network for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/86ce76f54a7bfc6047f83877408f789449f28df4\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"51305348\",\"name\":\"Zhu Zhang\"},{\"authorId\":\"51055350\",\"name\":\"Shuwen Xiao\"},{\"authorId\":\"123034558\",\"name\":\"Z. Xiao\"},{\"authorId\":\"145477645\",\"name\":\"X. Yan\"},{\"authorId\":\"50812077\",\"name\":\"J. Yu\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"},{\"authorId\":\"39918420\",\"name\":\"F. Wu\"}],\"doi\":\"10.1109/TIP.2019.2922062\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"80c67ece4198e3dd1ef88e6ddb81eb71bee5f3fa\",\"title\":\"Long-Form Video Question Answering via Dynamic Hierarchical Reinforced Networks\",\"url\":\"https://www.semanticscholar.org/paper/80c67ece4198e3dd1ef88e6ddb81eb71bee5f3fa\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47056886\",\"name\":\"Xiangpeng Li\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"9764377\",\"name\":\"Xuanhan Wang\"},{\"authorId\":\"51347989\",\"name\":\"W. Liu\"},{\"authorId\":\"1390532590\",\"name\":\"Xing Xu\"},{\"authorId\":\"152555512\",\"name\":\"Heng Tao Shen\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"}],\"doi\":\"10.1145/3343031.3350971\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f133f3daed70c50d1828cc6a46bc2e8dbd7880de\",\"title\":\"Learnable Aggregating Net with Diversity Learning for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f133f3daed70c50d1828cc6a46bc2e8dbd7880de\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1898428\",\"name\":\"Jinyoung Yeo\"},{\"authorId\":\"41130287\",\"name\":\"Gyeongbok Lee\"},{\"authorId\":\"12265111\",\"name\":\"Gengyu Wang\"},{\"authorId\":\"5841595\",\"name\":\"Seungtaek Choi\"},{\"authorId\":\"2505403\",\"name\":\"Hyunsouk Cho\"},{\"authorId\":\"23181472\",\"name\":\"Reinald Kim Amplayo\"},{\"authorId\":\"1716415\",\"name\":\"S. Hwang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb2eb53f46071170fdc9aa70d703b6aea52c932c\",\"title\":\"Visual Choice of Plausible Alternatives: An Evaluation of Image-based Commonsense Causal Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/eb2eb53f46071170fdc9aa70d703b6aea52c932c\",\"venue\":\"LREC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"26900125\",\"name\":\"Jinghao Lin\"},{\"authorId\":\"2440041\",\"name\":\"X. Jiang\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"},{\"authorId\":\"3945955\",\"name\":\"X. He\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1145/3123266.3123364\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2411270f111a160c9289d56132651c896a5738f6\",\"title\":\"Video Question Answering via Hierarchical Dual-Level Attention Network Learning\",\"url\":\"https://www.semanticscholar.org/paper/2411270f111a160c9289d56132651c896a5738f6\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":\"1708.01471\",\"authors\":[{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"},{\"authorId\":\"50812077\",\"name\":\"J. Yu\"},{\"authorId\":\"144147221\",\"name\":\"Jianping Fan\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/ICCV.2017.202\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8e9ad6f8b2bc97f0412fa0cc243ac6975864534a\",\"title\":\"Multi-modal Factorized Bilinear Pooling with Co-attention Learning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8e9ad6f8b2bc97f0412fa0cc243ac6975864534a\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"51055350\",\"name\":\"Shuwen Xiao\"},{\"authorId\":\"1478185914\",\"name\":\"Zehan Song\"},{\"authorId\":\"153228843\",\"name\":\"Chujie Lu\"},{\"authorId\":\"1384523745\",\"name\":\"Jun Xiao\"},{\"authorId\":\"2125211\",\"name\":\"Yueting Zhuang\"}],\"doi\":\"10.1109/TIP.2020.2963950\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5b5de122d508518ecaae7c9e4cc627c36c96f2a9\",\"title\":\"Open-Ended Video Question Answering via Multi-Modal Conditional Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/5b5de122d508518ecaae7c9e4cc627c36c96f2a9\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51021338\",\"name\":\"Nelson Ruwa\"},{\"authorId\":\"3069077\",\"name\":\"Q. Mao\"},{\"authorId\":\"2054737\",\"name\":\"Liangjun Wang\"},{\"authorId\":\"38978232\",\"name\":\"J. Gou\"},{\"authorId\":\"144964053\",\"name\":\"M. Dong\"}],\"doi\":\"10.1016/j.neucom.2018.11.049\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e3e4954e40f33b503f7fe220be90917124a09c43\",\"title\":\"Mood-aware visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/e3e4954e40f33b503f7fe220be90917124a09c43\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144618699\",\"name\":\"F. Shen\"},{\"authorId\":\"143703146\",\"name\":\"X. Gao\"},{\"authorId\":\"40241836\",\"name\":\"L. Liu\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1145/3123266.3123345\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d9f9a4cc9d5a4360a32bc1acf3fd0a5916566a77\",\"title\":\"Deep Asymmetric Pairwise Hashing\",\"url\":\"https://www.semanticscholar.org/paper/d9f9a4cc9d5a4360a32bc1acf3fd0a5916566a77\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"51055559\",\"name\":\"Lingtao Meng\"},{\"authorId\":\"145974111\",\"name\":\"Jun Xiao\"},{\"authorId\":\"144346838\",\"name\":\"Min Yang\"},{\"authorId\":\"144894849\",\"name\":\"Fei Wu\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"},{\"authorId\":\"3945955\",\"name\":\"X. He\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.24963/ijcai.2018/442\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0da9aca2256a4ae82cfbdca8148f6359b1566b40\",\"title\":\"Attentional Image Retweet Modeling via Multi-Faceted Ranking Network Learning\",\"url\":\"https://www.semanticscholar.org/paper/0da9aca2256a4ae82cfbdca8148f6359b1566b40\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":\"1810.10226\",\"authors\":[{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"82054425\",\"name\":\"Hanbing Zhan\"},{\"authorId\":\"51055559\",\"name\":\"Lingtao Meng\"},{\"authorId\":\"145974111\",\"name\":\"Jun Xiao\"},{\"authorId\":\"1720236\",\"name\":\"J. Yu\"},{\"authorId\":\"144069924\",\"name\":\"M. Yang\"},{\"authorId\":\"144894849\",\"name\":\"Fei Wu\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d584951b2b1e5edaec61f72a2dba6c551bb02a8\",\"title\":\"Textually Guided Ranking Network for Attentional Image Retweet Modeling\",\"url\":\"https://www.semanticscholar.org/paper/0d584951b2b1e5edaec61f72a2dba6c551bb02a8\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1907.09358\",\"authors\":[{\"authorId\":\"3219864\",\"name\":\"Aditya Mogadala\"},{\"authorId\":\"151119369\",\"name\":\"M. Kalimuthu\"},{\"authorId\":\"2561225\",\"name\":\"D. Klakow\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f8a48678094adbe421d61d0045361bfc635a2900\",\"title\":\"Trends in Integration of Vision and Language Research: A Survey of Tasks, Datasets, and Methods\",\"url\":\"https://www.semanticscholar.org/paper/f8a48678094adbe421d61d0045361bfc635a2900\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2008.00544\",\"authors\":[{\"authorId\":\"29367810\",\"name\":\"Wentian Zhao\"},{\"authorId\":\"2047181\",\"name\":\"Seokhwan Kim\"},{\"authorId\":null,\"name\":\"Ning Xu\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"}],\"doi\":\"10.24963/ijcai.2020/148\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fda45368ef87c7ac1da12a7303dedab0e779fd20\",\"title\":\"Video Question Answering on Screencast Tutorials\",\"url\":\"https://www.semanticscholar.org/paper/fda45368ef87c7ac1da12a7303dedab0e779fd20\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Kushal Kafle\"},{\"authorId\":\"153677280\",\"name\":\"Robik Shrestha\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e3bb5773205477ae4711524a9d4ae739bee40349\",\"title\":\"Visual semantic role labeling requires recognizing activities and semantic context in images\",\"url\":\"https://www.semanticscholar.org/paper/e3bb5773205477ae4711524a9d4ae739bee40349\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150337817\",\"name\":\"Weike Jin\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"67144160\",\"name\":\"Mao Gu\"},{\"authorId\":\"1384523745\",\"name\":\"Jun Xiao\"},{\"authorId\":\"49807919\",\"name\":\"Furu Wei\"},{\"authorId\":\"2125211\",\"name\":\"Yueting Zhuang\"}],\"doi\":\"10.18653/v1/D19-1217\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"142aa769440eebcd93fd0ff54404ad0bdcb3e854\",\"title\":\"Video Dialog via Progressive Inference and Cross-Transformer\",\"url\":\"https://www.semanticscholar.org/paper/142aa769440eebcd93fd0ff54404ad0bdcb3e854\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993370724\",\"name\":\"Zixuan Su\"},{\"authorId\":\"2444704\",\"name\":\"Xindi Shang\"},{\"authorId\":\"12564022\",\"name\":\"J. Chen\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"50504277\",\"name\":\"Zhiyong Qiu\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1145/3394171.3413764\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"37eb4eca6cf2b1e48bedc74f9b758ebd59e6abf4\",\"title\":\"Video Relation Detection via Multiple Hypothesis Association\",\"url\":\"https://www.semanticscholar.org/paper/37eb4eca6cf2b1e48bedc74f9b758ebd59e6abf4\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51021265\",\"name\":\"T. Yu\"},{\"authorId\":\"97583812\",\"name\":\"J. Yu\"},{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/TIP.2019.2940677\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ef33aedbab68b0771f6dd7ca8ec2492f12d7ea51\",\"title\":\"Compositional Attention Networks With Two-Stream Fusion for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ef33aedbab68b0771f6dd7ca8ec2492f12d7ea51\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"2007.10040\",\"authors\":[{\"authorId\":\"123661590\",\"name\":\"Louis Mahon\"},{\"authorId\":\"31847520\",\"name\":\"Eleonora Giunchiglia\"},{\"authorId\":\"49730060\",\"name\":\"B. Li\"},{\"authorId\":\"1690572\",\"name\":\"Thomas Lukasiewicz\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4384342c18d3ceec7be3c4a65e938e93e34ce4ef\",\"title\":\"Knowledge Graph Extraction from Videos\",\"url\":\"https://www.semanticscholar.org/paper/4384342c18d3ceec7be3c4a65e938e93e34ce4ef\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.10019\",\"authors\":[{\"authorId\":\"47267313\",\"name\":\"T. Le\"},{\"authorId\":\"144672395\",\"name\":\"Vuong Le\"},{\"authorId\":\"144162181\",\"name\":\"S. Venkatesh\"},{\"authorId\":\"6254479\",\"name\":\"T. Tran\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"71e1821c1846f9b13ab97eba05f47bedfc3d76c5\",\"title\":\"Hierarchical Conditional Relation Networks for Multimodal Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/71e1821c1846f9b13ab97eba05f47bedfc3d76c5\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":325460,\"doi\":\"10.24963/ijcai.2017/492\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":4,\"is_open_access\":true,\"is_publisher_licensed\":false,\"paperId\":\"a05e84f77e1dacaa1c59ba0d92919bdcfe4debbb\",\"references\":[{\"arxivId\":\"1506.07285\",\"authors\":[{\"authorId\":\"31910999\",\"name\":\"A. Kumar\"},{\"authorId\":\"2329943\",\"name\":\"Ozan Irsoy\"},{\"authorId\":\"3214791\",\"name\":\"Peter Ondruska\"},{\"authorId\":\"2136562\",\"name\":\"Mohit Iyyer\"},{\"authorId\":\"34963602\",\"name\":\"J. Bradbury\"},{\"authorId\":\"2708454\",\"name\":\"Ishaan Gulrajani\"},{\"authorId\":\"3428769\",\"name\":\"Victor Zhong\"},{\"authorId\":\"2896063\",\"name\":\"Romain Paulus\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"452059171226626718eb677358836328f884298e\",\"title\":\"Ask Me Anything: Dynamic Memory Networks for Natural Language Processing\",\"url\":\"https://www.semanticscholar.org/paper/452059171226626718eb677358836328f884298e\",\"venue\":\"ICML\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98302096\",\"name\":\"Peter Kulchyski\"}],\"doi\":\"10.1080/13688790.2015.1136585\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dfbfcd288ed9b37106564bf6dc95041f6d33b6b2\",\"title\":\"and\",\"url\":\"https://www.semanticscholar.org/paper/dfbfcd288ed9b37106564bf6dc95041f6d33b6b2\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1707726\",\"name\":\"J. Pustejovsky\"}],\"doi\":\"10.3115/981732\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2879e9a829dd65c92f9c30f10cdd643c0d0bc1b1\",\"title\":\"Proceedings of the 32nd annual meeting on Association for Computational Linguistics\",\"url\":\"https://www.semanticscholar.org/paper/2879e9a829dd65c92f9c30f10cdd643c0d0bc1b1\",\"venue\":\"\",\"year\":1994},{\"arxivId\":\"1410.0210\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ac64fb7e6d2ddf236332ec9f371fe85d308c114d\",\"title\":\"A Multi-World Approach to Question Answering about Real-World Scenes based on Uncertain Input\",\"url\":\"https://www.semanticscholar.org/paper/ac64fb7e6d2ddf236332ec9f371fe85d308c114d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Christiane Fellbaum\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"WordNet\",\"url\":\"\",\"venue\":\"Wiley Online Library,\",\"year\":1998},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jiasen Lu\"},{\"authorId\":null,\"name\":\"Jianwei Yang\"},{\"authorId\":null,\"name\":\"Dhruv Batra\"},{\"authorId\":null,\"name\":\"Devi Parikh. Hierarchical question-image co-attention f answering\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In NIPS\",\"url\":\"\",\"venue\":\"pages 289\\u2013297,\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Li Yao\"},{\"authorId\":null,\"name\":\"Atousa Torabi\"},{\"authorId\":null,\"name\":\"Kyunghyun Cho\"},{\"authorId\":null,\"name\":\"Nicolas Ballas\"},{\"authorId\":null,\"name\":\"Christopher Pal\"},{\"authorId\":null,\"name\":\"Hugo Larochelle\"},{\"authorId\":null,\"name\":\"Aaron Courville. Describing videos by exploiting tempora structure\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In ICCV\",\"url\":\"\",\"venue\":\"pages 4507\\u20134515,\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Zhou Zhao\"},{\"authorId\":null,\"name\":\"Qifan Yang\"},{\"authorId\":null,\"name\":\"Deng Cai\"},{\"authorId\":null,\"name\":\"Xiaofei He\"},{\"authorId\":null,\"name\":\"Yueting Zhuang. Expert finding for community-based questio IJCAI\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"pages 3000\\u20133006\",\"url\":\"\",\"venue\":\"AAAI Press,\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Kewei Tu\"},{\"authorId\":null,\"name\":\"Meng Meng\"},{\"authorId\":null,\"name\":\"Mun Wai Lee\"},{\"authorId\":null,\"name\":\"Tae Eun Choe\"},{\"authorId\":null,\"name\":\"Song-Chun Zhu. Joint video\"},{\"authorId\":null,\"name\":\"text parsing for understanding events\"},{\"authorId\":null,\"name\":\"answering queries\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"IEEE MultiMedia\",\"url\":\"\",\"venue\":\"21(2):42\\u201370,\",\"year\":2014},{\"arxivId\":\"1505.00468\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-016-0966-6\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"title\":\"VQA: Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1604.02748\",\"authors\":[{\"authorId\":\"66508219\",\"name\":\"Y. Li\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"48749954\",\"name\":\"L. Cao\"},{\"authorId\":\"1739099\",\"name\":\"J. Tetreault\"},{\"authorId\":\"39420932\",\"name\":\"L. Goldberg\"},{\"authorId\":\"144633617\",\"name\":\"A. Jaimes\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2016.502\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"05f3f8f6f97db00bafa2efd2ac9aac570603c0c6\",\"title\":\"TGIF: A New Dataset and Benchmark on Animated GIF Description\",\"url\":\"https://www.semanticscholar.org/paper/05f3f8f6f97db00bafa2efd2ac9aac570603c0c6\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2618874\",\"name\":\"Michael Heilman\"},{\"authorId\":\"144365875\",\"name\":\"Noah A. Smith\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c8066fa6f7037de866189c70ef2ec995208b011\",\"title\":\"Good Question! Statistical Ranking for Question Generation\",\"url\":\"https://www.semanticscholar.org/paper/1c8066fa6f7037de866189c70ef2ec995208b011\",\"venue\":\"HLT-NAACL\",\"year\":2010},{\"arxivId\":\"1512.02902\",\"authors\":[{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"2214033\",\"name\":\"Y. Zhu\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":\"10.1109/CVPR.2016.501\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1bdd75a37f7c601f01e9d31c2551fa9f2067ffd7\",\"title\":\"MovieQA: Understanding Stories in Movies through Question-Answering\",\"url\":\"https://www.semanticscholar.org/paper/1bdd75a37f7c601f01e9d31c2551fa9f2067ffd7\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Zichao Yang\"},{\"authorId\":null,\"name\":\"Xiaodong He\"},{\"authorId\":null,\"name\":\"Jianfeng Gao\"},{\"authorId\":null,\"name\":\"Li Deng\"},{\"authorId\":null,\"name\":\"Alex Smola. Stacked attention networks for image questi answering\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In CVPR\",\"url\":\"\",\"venue\":\"pages 21\\u2013 29,\",\"year\":2016},{\"arxivId\":\"cmp-lg/9406033\",\"authors\":[{\"authorId\":\"2459057\",\"name\":\"Z. Wu\"},{\"authorId\":\"145755155\",\"name\":\"Martha Palmer\"}],\"doi\":\"10.3115/981732.981751\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0e3e3c3d8ae5cb7c4636870d69967c197484d3bb\",\"title\":\"Verb Semantics and Lexical Selection\",\"url\":\"https://www.semanticscholar.org/paper/0e3e3c3d8ae5cb7c4636870d69967c197484d3bb\",\"venue\":\"ACL\",\"year\":1994},{\"arxivId\":\"1301.3781\",\"authors\":[{\"authorId\":null,\"name\":\"Tomas Mikolov\"},{\"authorId\":\"38644044\",\"name\":\"Kai Chen\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"330da625c15427c6e42ccfa3b747fb29e5835bf0\",\"title\":\"Efficient Estimation of Word Representations in Vector Space\",\"url\":\"https://www.semanticscholar.org/paper/330da625c15427c6e42ccfa3b747fb29e5835bf0\",\"venue\":\"ICLR\",\"year\":2013},{\"arxivId\":\"1511.04670\",\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"2351434\",\"name\":\"Zhongwen Xu\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9ed7d774684a1770445c1c53e276011a8364b9e2\",\"title\":\"Uncovering Temporal Context for Video Question and Answering\",\"url\":\"https://www.semanticscholar.org/paper/9ed7d774684a1770445c1c53e276011a8364b9e2\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2352551\",\"name\":\"Mengxiao Bi\"},{\"authorId\":\"2480051\",\"name\":\"Yanmin Qian\"},{\"authorId\":\"1736727\",\"name\":\"Kai Yu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6d94912bf13daa446fc358db22d4ad27ebfad15d\",\"title\":\"Very deep convolutional neural networks for LVCSR\",\"url\":\"https://www.semanticscholar.org/paper/6d94912bf13daa446fc358db22d4ad27ebfad15d\",\"venue\":\"INTERSPEECH\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"2155311\",\"name\":\"Eunbyung Park\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/ICCV.2015.283\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ced9f7178f8032d3408fcba493c02eb48e8a8636\",\"title\":\"Visual Madlibs: Fill in the Blank Description Generation and Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ced9f7178f8032d3408fcba493c02eb48e8a8636\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1610.04062\",\"authors\":[{\"authorId\":\"144839067\",\"name\":\"Amir Mazaheri\"},{\"authorId\":\"119745921\",\"name\":\"Dong Zhang\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9fb31d0375552500bd494af20ab0c3109c9be3d2\",\"title\":\"Video Fill in the Blank with Merging LSTMs\",\"url\":\"https://www.semanticscholar.org/paper/9fb31d0375552500bd494af20ab0c3109c9be3d2\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1603.01417\",\"authors\":[{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"3375440\",\"name\":\"Stephen Merity\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f96898d15a1bf1fa8925b1280d0e07a7a8e72194\",\"title\":\"Dynamic Memory Networks for Visual and Textual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f96898d15a1bf1fa8925b1280d0e07a7a8e72194\",\"venue\":\"ICML\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Mateusz Malinowski\"},{\"authorId\":null,\"name\":\"Mario Fritz. A multi-world approach to question answerin input\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In NIPS\",\"url\":\"\",\"venue\":\"pages 1682\\u20131690,\",\"year\":2014},{\"arxivId\":\"1502.08029\",\"authors\":[{\"authorId\":\"145095579\",\"name\":\"L. Yao\"},{\"authorId\":\"1730844\",\"name\":\"Atousa Torabi\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"2482072\",\"name\":\"Nicolas Ballas\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":\"10.1109/ICCV.2015.512\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5f425b7abf2ed3172ed060df85bb1885860a297e\",\"title\":\"Describing Videos by Exploiting Temporal Structure\",\"url\":\"https://www.semanticscholar.org/paper/5f425b7abf2ed3172ed060df85bb1885860a297e\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Zhou Zhao\"},{\"authorId\":null,\"name\":\"Lijun Zhang\"},{\"authorId\":null,\"name\":\"Xiaofei He\"},{\"authorId\":null,\"name\":\"Wilfred Ng. Expert finding for question answering via grap completion\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"TKDE\",\"url\":\"\",\"venue\":\"27(4):993\\u2013 1004,\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"60d4cef56efd2f5452362d4d9ac1ae05afa970d1\",\"title\":\"Learning End-to-end Video Classification with Rank-Pooling\",\"url\":\"https://www.semanticscholar.org/paper/60d4cef56efd2f5452362d4d9ac1ae05afa970d1\",\"venue\":\"ICML\",\"year\":2016},{\"arxivId\":\"1511.02274\",\"authors\":[{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"46234526\",\"name\":\"Alex Smola\"}],\"doi\":\"10.1109/CVPR.2016.10\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c1890864c1c2b750f48316dc8b650ba4772adc5\",\"title\":\"Stacked Attention Networks for Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2c1890864c1c2b750f48316dc8b650ba4772adc5\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1511.07394\",\"authors\":[{\"authorId\":\"143953573\",\"name\":\"K. Shih\"},{\"authorId\":\"37415643\",\"name\":\"S. Singh\"},{\"authorId\":\"2433269\",\"name\":\"Derek Hoiem\"}],\"doi\":\"10.1109/CVPR.2016.499\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"175e9bb50cc062c6c1742a5d90c8dfe31d2e4e22\",\"title\":\"Where to Look: Focus Regions for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/175e9bb50cc062c6c1742a5d90c8dfe31d2e4e22\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2265067\",\"name\":\"Sainbayar Sukhbaatar\"},{\"authorId\":\"3149531\",\"name\":\"Arthur Szlam\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4f10b9f47c5bb6b54dd4f5ca8d9fa2c0bbd7ec5e\",\"title\":\"End-To-End Memory Networks\",\"url\":\"https://www.semanticscholar.org/paper/4f10b9f47c5bb6b54dd4f5ca8d9fa2c0bbd7ec5e\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1607.05910\",\"authors\":[{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1016/j.cviu.2017.05.001\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"88c307c51594c6d802080a0780d0d654e2e2891f\",\"title\":\"Visual question answering: A survey of methods and datasets\",\"url\":\"https://www.semanticscholar.org/paper/88c307c51594c6d802080a0780d0d654e2e2891f\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5886094\",\"name\":\"P. Cochat\"},{\"authorId\":\"13267685\",\"name\":\"L. Vaucoret\"},{\"authorId\":\"31455512\",\"name\":\"J. Sarles\"}],\"doi\":\"10.1016/j.arcped.2012.01.013\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"10d85561e4aafc516d10064f30dff05b41f70afe\",\"title\":\"[Et al].\",\"url\":\"https://www.semanticscholar.org/paper/10d85561e4aafc516d10064f30dff05b41f70afe\",\"venue\":\"Archives de pediatrie : organe officiel de la Societe francaise de pediatrie\",\"year\":2012},{\"arxivId\":\"1606.01455\",\"authors\":[{\"authorId\":\"2684967\",\"name\":\"J. Kim\"},{\"authorId\":\"3226948\",\"name\":\"Sang-Woo Lee\"},{\"authorId\":\"3422869\",\"name\":\"Dong-Hyun Kwak\"},{\"authorId\":\"2939188\",\"name\":\"Min-Oh Heo\"},{\"authorId\":\"2947441\",\"name\":\"J. Kim\"},{\"authorId\":\"2577039\",\"name\":\"Jung-Woo Ha\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1afb710a5b35a2352a6495e4bf6eef66808daf1b\",\"title\":\"Multimodal Residual Learning for Visual QA\",\"url\":\"https://www.semanticscholar.org/paper/1afb710a5b35a2352a6495e4bf6eef66808daf1b\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"39738194\",\"name\":\"L. Zhang\"},{\"authorId\":\"3945955\",\"name\":\"X. He\"},{\"authorId\":\"1695492\",\"name\":\"Wilfred Ng\"}],\"doi\":\"10.1109/TKDE.2014.2356461\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2141f99fcce1c5df886816b179adf9adfb3939ca\",\"title\":\"Expert Finding for Question Answering via Graph Regularized Matrix Completion\",\"url\":\"https://www.semanticscholar.org/paper/2141f99fcce1c5df886816b179adf9adfb3939ca\",\"venue\":\"IEEE Transactions on Knowledge and Data Engineering\",\"year\":2015},{\"arxivId\":\"1606.00061\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"145743311\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b\",\"title\":\"Hierarchical Question-Image Co-Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"9390267\",\"name\":\"Qifan Yang\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"},{\"authorId\":\"3945955\",\"name\":\"X. He\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b98ae01668cae9c01592dab5993cf04a23f0c91a\",\"title\":\"Expert Finding for Community-Based Question Answering via Ranking Metric Network Learning\",\"url\":\"https://www.semanticscholar.org/paper/b98ae01668cae9c01592dab5993cf04a23f0c91a\",\"venue\":\"IJCAI\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48881927\",\"name\":\"R. Li\"},{\"authorId\":\"1729056\",\"name\":\"J. Jia\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"269546925f0fd457b31c13c2870343b0aed761dc\",\"title\":\"Visual Question Answering with Question Representation Update (QRU)\",\"url\":\"https://www.semanticscholar.org/paper/269546925f0fd457b31c13c2870343b0aed761dc\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1308.6628\",\"authors\":[{\"authorId\":\"40341553\",\"name\":\"K. Tu\"},{\"authorId\":\"143764552\",\"name\":\"M. Meng\"},{\"authorId\":\"2649483\",\"name\":\"M. Lee\"},{\"authorId\":\"2194804\",\"name\":\"T. E. Choe\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/MMUL.2014.29\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2935d8071583e46c5a895730c65d2bd213757c07\",\"title\":\"Joint Video and Text Parsing for Understanding Events and Answering Queries\",\"url\":\"https://www.semanticscholar.org/paper/2935d8071583e46c5a895730c65d2bd213757c07\",\"venue\":\"IEEE MultiMedia\",\"year\":2014},{\"arxivId\":\"1412.3555\",\"authors\":[{\"authorId\":\"8270717\",\"name\":\"J. Chung\"},{\"authorId\":\"1854385\",\"name\":\"\\u00c7aglar G\\u00fcl\\u00e7ehre\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"adfcf065e15fd3bc9badf6145034c84dfb08f204\",\"title\":\"Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling\",\"url\":\"https://www.semanticscholar.org/paper/adfcf065e15fd3bc9badf6145034c84dfb08f204\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Caiming Xiong\"},{\"authorId\":null,\"name\":\"Stephen Merity\"},{\"authorId\":null,\"name\":\"Richard Socher. Dynamic memory networks for visual\"},{\"authorId\":null,\"name\":\"textual question answering\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"ICML\",\"url\":\"\",\"venue\":\"1603,\",\"year\":2016}],\"title\":\"Video Question Answering via Hierarchical Spatio-Temporal Attention Networks\",\"topics\":[{\"topic\":\"Question answering\",\"topicId\":\"18817\",\"url\":\"https://www.semanticscholar.org/topic/18817\"},{\"topic\":\"Nonlinear gameplay\",\"topicId\":\"62171\",\"url\":\"https://www.semanticscholar.org/topic/62171\"},{\"topic\":\"Natural language\",\"topicId\":\"1911\",\"url\":\"https://www.semanticscholar.org/topic/1911\"},{\"topic\":\"Information retrieval\",\"topicId\":\"2867\",\"url\":\"https://www.semanticscholar.org/topic/2867\"},{\"topic\":\"Digital video\",\"topicId\":\"44670\",\"url\":\"https://www.semanticscholar.org/topic/44670\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Encoder\",\"topicId\":\"16744\",\"url\":\"https://www.semanticscholar.org/topic/16744\"}],\"url\":\"https://www.semanticscholar.org/paper/a05e84f77e1dacaa1c59ba0d92919bdcfe4debbb\",\"venue\":\"IJCAI\",\"year\":2017}\n"