"{\"abstract\":\"Data-driven techniques for interactive narrative generation are the subject of growing interest. Reinforcement learning (RL) offers significant potential for devising data-driven interactive narrative generators that tailor players\\u2019 story experiences by inducing policies from player interaction logs. A key open question in RL-based interactive narrative generation is how to model complex player interaction patterns to learn effective policies. In this paper we present a deep RL-based interactive narrative generation framework that leverages synthetic data produced by a bipartite simulated player model. Specifically, the framework involves training a set of Q-networks to control adaptable narrative event sequences with long short-term memory network-based simulated players. We investigate the deep RL framework\\u2019s performance with an educational interactive narrative, CRYSTAL ISLAND. Results suggest that the deep RL-based narrative generation framework yields effective personalized interactive narratives.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"46808274\",\"name\":\"P. Wang\",\"url\":\"https://www.semanticscholar.org/author/46808274\"},{\"authorId\":\"34971293\",\"name\":\"J. Rowe\",\"url\":\"https://www.semanticscholar.org/author/34971293\"},{\"authorId\":\"1745330\",\"name\":\"W. Min\",\"url\":\"https://www.semanticscholar.org/author/1745330\"},{\"authorId\":\"9808011\",\"name\":\"B. Mott\",\"url\":\"https://www.semanticscholar.org/author/9808011\"},{\"authorId\":\"1717955\",\"name\":\"J. Lester\",\"url\":\"https://www.semanticscholar.org/author/1717955\"}],\"citationVelocity\":6,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"46808274\",\"name\":\"P. Wang\"},{\"authorId\":\"34971293\",\"name\":\"J. Rowe\"},{\"authorId\":\"1745330\",\"name\":\"W. Min\"},{\"authorId\":\"9808011\",\"name\":\"B. Mott\"},{\"authorId\":\"1717955\",\"name\":\"J. Lester\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"7547fea5c9be6655eb045880e09912da1e693de6\",\"title\":\"Simulating Player Behavior for Data-Driven Interactive Narrative Personalization\",\"url\":\"https://www.semanticscholar.org/paper/7547fea5c9be6655eb045880e09912da1e693de6\",\"venue\":\"AIIDE\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3349939\",\"name\":\"Guojing Zhou\"},{\"authorId\":\"51216654\",\"name\":\"H. Azizsoltani\"},{\"authorId\":\"51039532\",\"name\":\"Markel Sanz Ausin\"},{\"authorId\":\"1734603\",\"name\":\"T. Barnes\"},{\"authorId\":\"1731937\",\"name\":\"Min Chi\"}],\"doi\":\"10.1007/978-3-030-23204-7_45\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bd7d3becbe36188f22f08609725859c5b72c36df\",\"title\":\"Hierarchical Reinforcement Learning for Pedagogical Policy Induction\",\"url\":\"https://www.semanticscholar.org/paper/bd7d3becbe36188f22f08609725859c5b72c36df\",\"venue\":\"AIED\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1947401715\",\"name\":\"Jichen Zhu\"},{\"authorId\":\"1722671\",\"name\":\"S. Onta\\u00f1\\u00f3n\"}],\"doi\":\"10.1145/3402942.3402951\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e5446036d375bb7c6a81947b9227a90cf5684b61\",\"title\":\"Player-Centered AI for Automatic Game Personalization: Open Problems\",\"url\":\"https://www.semanticscholar.org/paper/e5446036d375bb7c6a81947b9227a90cf5684b61\",\"venue\":\"FDG\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"103020918\",\"name\":\"S. Ju\"},{\"authorId\":\"1423680515\",\"name\":\"Min Chi\"},{\"authorId\":\"3349939\",\"name\":\"Guojing Zhou\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e7bebcc6398d0b3ac3f004137b1e69a6b3f416c1\",\"title\":\"Pick the Moment: Identifying Critical Pedagogical Decisions Using Long-Short Term Rewards\",\"url\":\"https://www.semanticscholar.org/paper/e7bebcc6398d0b3ac3f004137b1e69a6b3f416c1\",\"venue\":\"EDM\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145437032\",\"name\":\"Shitian Shen\"},{\"authorId\":\"51039532\",\"name\":\"Markel Sanz Ausin\"},{\"authorId\":\"3159445\",\"name\":\"B. Mostafavi\"},{\"authorId\":\"1731937\",\"name\":\"Min Chi\"}],\"doi\":\"10.1145/3209219.3209232\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7e095ed60e0b2e730ea8eb6c472b5d2811983698\",\"title\":\"Improving Learning & Reducing Time: A Constrained Action-Based Reinforcement Learning Approach\",\"url\":\"https://www.semanticscholar.org/paper/7e095ed60e0b2e730ea8eb6c472b5d2811983698\",\"venue\":\"UMAP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1745330\",\"name\":\"W. Min\"},{\"authorId\":\"3367196\",\"name\":\"M. Frankosky\"},{\"authorId\":\"9808011\",\"name\":\"B. Mott\"},{\"authorId\":\"34971293\",\"name\":\"J. Rowe\"},{\"authorId\":\"153087705\",\"name\":\"A. Smith\"},{\"authorId\":\"145182284\",\"name\":\"E. Wiebe\"},{\"authorId\":\"2115476\",\"name\":\"K. Boyer\"},{\"authorId\":\"1717955\",\"name\":\"J. Lester\"}],\"doi\":\"10.1109/TLT.2019.2922356\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5e1a1e9803bfc4b74fea4f59ef6da802900720d0\",\"title\":\"DeepStealth: Game-Based Learning Stealth Assessment With Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/5e1a1e9803bfc4b74fea4f59ef6da802900720d0\",\"venue\":\"IEEE Transactions on Learning Technologies\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152425249\",\"name\":\"J. Cunningham\"},{\"authorId\":\"123962986\",\"name\":\"Christian Lopez\"},{\"authorId\":\"39982761\",\"name\":\"O. Ashour\"},{\"authorId\":\"115814663\",\"name\":\"Conrad S. Tucker\"}],\"doi\":\"10.1115/detc2020-22624\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d6c85800928fdd91ea7c5a27648ac287bb1930f0\",\"title\":\"Multi-Context Generation in Virtual Reality Environments Using Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/d6c85800928fdd91ea7c5a27648ac287bb1930f0\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151439389\",\"name\":\"Floris den Hengst\"},{\"authorId\":\"41078977\",\"name\":\"Eoin Martino Grua\"},{\"authorId\":\"40571759\",\"name\":\"A. E. Hassouni\"},{\"authorId\":\"7579233\",\"name\":\"Mark Hoogendoorn\"}],\"doi\":\"10.3233/ds-200028\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"39c52e98fb6f04d5a938217fd3ea8164a8888268\",\"title\":\"Reinforcement learning for personalization: A systematic literature review\",\"url\":\"https://www.semanticscholar.org/paper/39c52e98fb6f04d5a938217fd3ea8164a8888268\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1907.10827\",\"authors\":[{\"authorId\":\"35224631\",\"name\":\"Bilal Kartal\"},{\"authorId\":\"1400326437\",\"name\":\"Pablo Hernandez-Leal\"},{\"authorId\":\"39286677\",\"name\":\"Matthew E. Taylor\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c5606ab54dcbbc56c8f0ebea9e7324db0b93d468\",\"title\":\"Terminal Prediction as an Auxiliary Task for Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/c5606ab54dcbbc56c8f0ebea9e7324db0b93d468\",\"venue\":\"AIIDE\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145271111\",\"name\":\"N. Henderson\"},{\"authorId\":\"2026675501\",\"name\":\"Vikram Kumara\"},{\"authorId\":\"1745330\",\"name\":\"W. Min\"},{\"authorId\":\"9808011\",\"name\":\"B. Mott\"},{\"authorId\":\"15504706\",\"name\":\"Z. Wu\"},{\"authorId\":\"51499366\",\"name\":\"Danielle Boulden\"},{\"authorId\":\"2604496\",\"name\":\"T. Lord\"},{\"authorId\":\"71133200\",\"name\":\"Frieda Reichsman\"},{\"authorId\":\"15750448\",\"name\":\"Chad Dorsey\"},{\"authorId\":\"145182284\",\"name\":\"E. Wiebe\"},{\"authorId\":\"1717955\",\"name\":\"J. Lester\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ff01d7f18965fa88bfabd52b18603d7eb3e2f9bc\",\"title\":\"Enhancing Student Competency Models for Game-Based Learning with a Hybrid Stealth Assessment Framework\",\"url\":\"https://www.semanticscholar.org/paper/ff01d7f18965fa88bfabd52b18603d7eb3e2f9bc\",\"venue\":\"EDM\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143844811\",\"name\":\"E. Santos\"},{\"authorId\":\"143700717\",\"name\":\"Hien Nguyen\"},{\"authorId\":\"2824763\",\"name\":\"Keum Joo Kim\"},{\"authorId\":\"2619923\",\"name\":\"Russell Jacob\"},{\"authorId\":\"104442991\",\"name\":\"Luke Veenhuis\"},{\"authorId\":\"1380223427\",\"name\":\"Luke De Guelle\"}],\"doi\":\"10.1145/3350546.3352515\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"332d26abc960671959b5aea0411bae487a850637\",\"title\":\"Analysis of Computational Models to Describe Individual Decision-Making Process\",\"url\":\"https://www.semanticscholar.org/paper/332d26abc960671959b5aea0411bae487a850637\",\"venue\":\"2019 IEEE/WIC/ACM International Conference on Web Intelligence (WI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153468821\",\"name\":\"G. Gomes\"},{\"authorId\":\"1872209\",\"name\":\"C. Vidal\"},{\"authorId\":\"1870162\",\"name\":\"J. B. C. Neto\"},{\"authorId\":\"2889936\",\"name\":\"Y. L. B. Nogueira\"}],\"doi\":\"10.1109/SVR.2019.00047\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"25ff416daef2991a1201af46f20f99d7490c037d\",\"title\":\"An Emotional Virtual Character: A Deep Learning Approach with Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/25ff416daef2991a1201af46f20f99d7490c037d\",\"venue\":\"2019 21st Symposium on Virtual and Augmented Reality (SVR)\",\"year\":2019},{\"arxivId\":\"2007.12391\",\"authors\":[{\"authorId\":\"1756108\",\"name\":\"N. Anantrasirichai\"},{\"authorId\":\"2073462\",\"name\":\"D. Bull\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3670d55a696dea9234660149b490e22fb5c2a3a5\",\"title\":\"Artificial Intelligence in the Creative Industries: A Review\",\"url\":\"https://www.semanticscholar.org/paper/3670d55a696dea9234660149b490e22fb5c2a3a5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144650313\",\"name\":\"A. Shirvani\"},{\"authorId\":\"34810994\",\"name\":\"Stephen G. Ware\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"05a2a43edfff98334bdceeff94b26a296be9f681\",\"title\":\"Camelot: A Modular Customizable Sandbox for Visualizing Interactive Narratives\",\"url\":\"https://www.semanticscholar.org/paper/05a2a43edfff98334bdceeff94b26a296be9f681\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"74422322\",\"name\":\"Christian E. Lopez\"},{\"authorId\":\"152425249\",\"name\":\"J. Cunningham\"},{\"authorId\":\"38353693\",\"name\":\"O. Ashour\"},{\"authorId\":\"115814663\",\"name\":\"Conrad S. Tucker\"}],\"doi\":\"10.1115/1.4046293\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"964e43b759860ed7c7bee0500ae10db2785c5125\",\"title\":\"Deep Reinforcement Learning for Procedural Content Generation of 3D Virtual Environments\",\"url\":\"https://www.semanticscholar.org/paper/964e43b759860ed7c7bee0500ae10db2785c5125\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"103020918\",\"name\":\"S. Ju\"},{\"authorId\":\"120206633\",\"name\":\"Shi-tian Shen\"},{\"authorId\":\"51216654\",\"name\":\"H. Azizsoltani\"},{\"authorId\":\"152553911\",\"name\":\"T. Barnes\"},{\"authorId\":\"1423680515\",\"name\":\"Min Chi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"98d7522958e748a5ba57d7524aa6bb8a9e6ff797\",\"title\":\"Importance Sampling to Identify Empirically Valid Policies and their Critical Decisions\",\"url\":\"https://www.semanticscholar.org/paper/98d7522958e748a5ba57d7524aa6bb8a9e6ff797\",\"venue\":\"EDM\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51039532\",\"name\":\"Markel Sanz Ausin\"},{\"authorId\":\"1508776152\",\"name\":\"Mehak Maniktala\"},{\"authorId\":\"152553911\",\"name\":\"T. Barnes\"},{\"authorId\":\"1423680515\",\"name\":\"Min Chi\"}],\"doi\":\"10.1007/978-3-030-52237-7_38\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6f8aa8c2e003086fb3d5acfcb0821927ee526863\",\"title\":\"Exploring the Impact of Simple Explanations and Agency on Batch Deep Reinforcement Learning Induced Pedagogical Policies\",\"url\":\"https://www.semanticscholar.org/paper/6f8aa8c2e003086fb3d5acfcb0821927ee526863\",\"venue\":\"AIED\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"147599844\",\"name\":\"Machi Shimmei\"},{\"authorId\":\"1481115792\",\"name\":\"Noboru Matsuda\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3460e3f953bbafd21b9d02ae388ac92517d86792\",\"title\":\"Learning a Policy Primes Quality Control: Towards Evidence-Based Automation of Learning Engineering\",\"url\":\"https://www.semanticscholar.org/paper/3460e3f953bbafd21b9d02ae388ac92517d86792\",\"venue\":\"EDM\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46808274\",\"name\":\"P. Wang\"},{\"authorId\":\"34971293\",\"name\":\"J. Rowe\"},{\"authorId\":\"1745330\",\"name\":\"W. Min\"},{\"authorId\":\"9808011\",\"name\":\"B. Mott\"},{\"authorId\":\"1717955\",\"name\":\"J. Lester\"}],\"doi\":\"10.24963/ijcai.2018/540\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"8df76587f9fc7bbbd212bd2d93afe0f4797b6554\",\"title\":\"High-Fidelity Simulated Players for Interactive Narrative Planning\",\"url\":\"https://www.semanticscholar.org/paper/8df76587f9fc7bbbd212bd2d93afe0f4797b6554\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145437032\",\"name\":\"Shitian Shen\"},{\"authorId\":\"3159445\",\"name\":\"B. Mostafavi\"},{\"authorId\":\"1734603\",\"name\":\"T. Barnes\"},{\"authorId\":\"1731937\",\"name\":\"Min Chi\"}],\"doi\":\"10.5281/ZENODO.3554713\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"1e489008b0f91064b3622eba8163c6a56a3db7ab\",\"title\":\"Exploring Induced Pedagogical Strategies Through a Markov Decision Process Framework: Lessons Learned\",\"url\":\"https://www.semanticscholar.org/paper/1e489008b0f91064b3622eba8163c6a56a3db7ab\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3396583\",\"name\":\"Shayan Doroudi\"},{\"authorId\":\"1779915\",\"name\":\"V. Aleven\"},{\"authorId\":\"2563117\",\"name\":\"Emma Brunskill\"}],\"doi\":\"10.1007/s40593-019-00187-x\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c5c006725aeff2c749acc9f407cceb97652c33a9\",\"title\":\"Where\\u2019s the Reward?\",\"url\":\"https://www.semanticscholar.org/paper/c5c006725aeff2c749acc9f407cceb97652c33a9\",\"venue\":\"International Journal of Artificial Intelligence in Education\",\"year\":2019}],\"corpusId\":20918043,\"doi\":\"10.24963/ijcai.2017/538\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":false,\"paperId\":\"24b1f433fba56ab7469ecc3835280eff7434bf15\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"145630067\",\"name\":\"D. Roberts\"},{\"authorId\":\"143982337\",\"name\":\"M. J. Nelson\"},{\"authorId\":\"1787816\",\"name\":\"C. Isbell\"},{\"authorId\":\"114402462\",\"name\":\"M. Mateas\"},{\"authorId\":\"144885169\",\"name\":\"M. Littman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"983450f01504e42a88e524d5942d50800edef64f\",\"title\":\"Targeting Specific Distributions of Trajectories in MDPs\",\"url\":\"https://www.semanticscholar.org/paper/983450f01504e42a88e524d5942d50800edef64f\",\"venue\":\"AAAI\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145259603\",\"name\":\"S. Young\"},{\"authorId\":\"1768624\",\"name\":\"Milica Gasic\"},{\"authorId\":\"145462220\",\"name\":\"B. Thomson\"},{\"authorId\":\"47271859\",\"name\":\"J. Williams\"}],\"doi\":\"10.1109/JPROC.2012.2225812\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"84b520a8d6de79f62bb095b565d077e95bfb6f5b\",\"title\":\"POMDP-Based Statistical Spoken Dialog Systems: A Review\",\"url\":\"https://www.semanticscholar.org/paper/84b520a8d6de79f62bb095b565d077e95bfb6f5b\",\"venue\":\"Proceedings of the IEEE\",\"year\":2013},{\"arxivId\":\"1507.06527\",\"authors\":[{\"authorId\":\"3308897\",\"name\":\"Matthew J. Hausknecht\"},{\"authorId\":\"144848112\",\"name\":\"P. Stone\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f5f323e62acb75f785e00b4c90ace16f1690076f\",\"title\":\"Deep Recurrent Q-Learning for Partially Observable MDPs\",\"url\":\"https://www.semanticscholar.org/paper/f5f323e62acb75f785e00b4c90ace16f1690076f\",\"venue\":\"AAAI Fall Symposia\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3255983\",\"name\":\"V. Mnih\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"},{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"1392331736\",\"name\":\"Andrei A. Rusu\"},{\"authorId\":\"144056327\",\"name\":\"J. Veness\"},{\"authorId\":\"1397980088\",\"name\":\"Marc G. Bellemare\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"3137672\",\"name\":\"Martin A. Riedmiller\"},{\"authorId\":\"1397979864\",\"name\":\"Andreas K. Fidjeland\"},{\"authorId\":\"2273072\",\"name\":\"Georg Ostrovski\"},{\"authorId\":\"145386761\",\"name\":\"S. Petersen\"},{\"authorId\":\"48878752\",\"name\":\"C. Beattie\"},{\"authorId\":\"49813280\",\"name\":\"A. Sadik\"},{\"authorId\":\"2460849\",\"name\":\"Ioannis Antonoglou\"},{\"authorId\":\"153907173\",\"name\":\"H. King\"},{\"authorId\":\"2106164\",\"name\":\"D. Kumaran\"},{\"authorId\":\"1688276\",\"name\":\"Daan Wierstra\"},{\"authorId\":\"34313265\",\"name\":\"S. Legg\"},{\"authorId\":\"48987704\",\"name\":\"Demis Hassabis\"}],\"doi\":\"10.1038/nature14236\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e0e9a94c4a6ba219e768b4e59f72c18f0a22e23d\",\"title\":\"Human-level control through deep reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/e0e9a94c4a6ba219e768b4e59f72c18f0a22e23d\",\"venue\":\"Nature\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144915758\",\"name\":\"James Henderson\"},{\"authorId\":\"1782798\",\"name\":\"Oliver Lemon\"},{\"authorId\":\"3194430\",\"name\":\"Kallirroi Georgila\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"93a01cbf7b3214abd3e140d2e95b0393c41b846e\",\"title\":\"Hybrid reinforcement/supervised learning for dialogue policies from COMMUNICATOR data\",\"url\":\"https://www.semanticscholar.org/paper/93a01cbf7b3214abd3e140d2e95b0393c41b846e\",\"venue\":\"\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153832043\",\"name\":\"T. Greenhalgh\"}],\"doi\":\"10.1136/bmj.324.7329.121/a\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f46deb42cfef50a5a75bbd0dcc5a1627906b9627\",\"title\":\"42\",\"url\":\"https://www.semanticscholar.org/paper/f46deb42cfef50a5a75bbd0dcc5a1627906b9627\",\"venue\":\"BMJ : British Medical Journal\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34971293\",\"name\":\"J. Rowe\"},{\"authorId\":\"9808011\",\"name\":\"B. Mott\"},{\"authorId\":\"1717955\",\"name\":\"J. Lester\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9bad1130ab4ee18acfa04077f45e23dea17f755c\",\"title\":\"Optimizing Player Experience in Interactive Narrative Planning: A Modular Reinforcement Learning Approach\",\"url\":\"https://www.semanticscholar.org/paper/9bad1130ab4ee18acfa04077f45e23dea17f755c\",\"venue\":\"AIIDE\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143982337\",\"name\":\"M. J. Nelson\"},{\"authorId\":\"145630067\",\"name\":\"D. Roberts\"},{\"authorId\":\"1787816\",\"name\":\"C. Isbell\"},{\"authorId\":\"114402462\",\"name\":\"M. Mateas\"}],\"doi\":\"10.1145/1160633.1160769\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"50dfcb7aa9ac8ae02ceb0e06392f71dafbdae8e2\",\"title\":\"Reinforcement learning for declarative optimization-based drama management\",\"url\":\"https://www.semanticscholar.org/paper/50dfcb7aa9ac8ae02ceb0e06392f71dafbdae8e2\",\"venue\":\"AAMAS '06\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144224173\",\"name\":\"J. Tsitsiklis\"},{\"authorId\":\"1731282\",\"name\":\"Benjamin Van Roy\"}],\"doi\":\"10.1109/9.580874\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ceee9569717991607b399d9a6890f1dcb9541ac0\",\"title\":\"Analysis of Temporal-Diffference Learning with Function Approximation\",\"url\":\"https://www.semanticscholar.org/paper/ceee9569717991607b399d9a6890f1dcb9541ac0\",\"venue\":\"NIPS\",\"year\":1996},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1162/neco.1997.9.8.1735\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"title\":\"Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"venue\":\"Neural Computation\",\"year\":1997},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2757194\",\"name\":\"Mark O. Riedl\"},{\"authorId\":\"1884952\",\"name\":\"V. Bulitko\"}],\"doi\":\"10.1609/aimag.v34i1.2449\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8cc0b359ac723d819be3343b20df9c6beaaa7bee\",\"title\":\"Interactive Narrative: An Intelligent Systems Approach\",\"url\":\"https://www.semanticscholar.org/paper/8cc0b359ac723d819be3343b20df9c6beaaa7bee\",\"venue\":\"AI Mag.\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1805256\",\"name\":\"J. Schatzmann\"},{\"authorId\":\"1777891\",\"name\":\"K. Weilhammer\"},{\"authorId\":\"2568798\",\"name\":\"Matthew N. Stuttle\"},{\"authorId\":\"145259603\",\"name\":\"S. Young\"}],\"doi\":\"10.1017/S0269888906000944\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e3d8e925ec4f938620a8d76bb50a1b2fc95e7f5e\",\"title\":\"A survey of statistical user simulation techniques for reinforcement-learning of dialogue management strategies\",\"url\":\"https://www.semanticscholar.org/paper/e3d8e925ec4f938620a8d76bb50a1b2fc95e7f5e\",\"venue\":\"Knowl. Eng. Rev.\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143982337\",\"name\":\"M. J. Nelson\"},{\"authorId\":\"114402462\",\"name\":\"M. Mateas\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e13170ee33870179988d69cc1c4369e160f328a4\",\"title\":\"Search-Based Drama Management in the Interactive Fiction Anchorhead\",\"url\":\"https://www.semanticscholar.org/paper/e13170ee33870179988d69cc1c4369e160f328a4\",\"venue\":\"AIIDE\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144312529\",\"name\":\"J. Porteous\"},{\"authorId\":\"5928637\",\"name\":\"A. Lindsay\"},{\"authorId\":\"39784208\",\"name\":\"J. Read\"},{\"authorId\":\"1693495\",\"name\":\"M. Truran\"},{\"authorId\":\"1696638\",\"name\":\"M. Cavazza\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8383926443bfacddc698707629d37047f6c79e99\",\"title\":\"Automated Extension of Narrative Planning Domains with Antonymic Operators\",\"url\":\"https://www.semanticscholar.org/paper/8383926443bfacddc698707629d37047f6c79e99\",\"venue\":\"AAMAS\",\"year\":2015},{\"arxivId\":\"1511.06581\",\"authors\":[{\"authorId\":\"47197117\",\"name\":\"Ziyu Wang\"},{\"authorId\":\"1725157\",\"name\":\"T. Schaul\"},{\"authorId\":\"39357484\",\"name\":\"Matteo Hessel\"},{\"authorId\":\"7634925\",\"name\":\"H. V. Hasselt\"},{\"authorId\":\"1975889\",\"name\":\"Marc Lanctot\"},{\"authorId\":\"1737568\",\"name\":\"N. D. Freitas\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4c05d7caa357148f0bbd61720bdd35f0bc05eb81\",\"title\":\"Dueling Network Architectures for Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/4c05d7caa357148f0bbd61720bdd35f0bc05eb81\",\"venue\":\"ICML\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32904145\",\"name\":\"Hong Yu\"},{\"authorId\":\"2757194\",\"name\":\"Mark O. Riedl\"}],\"doi\":\"10.1109/TCIAIG.2013.2282771\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c5bb7fe69b3b71d8a6f9c89022b687c1053e55ca\",\"title\":\"Personalized Interactive Narratives via Sequential Recommendation of Plot Points\",\"url\":\"https://www.semanticscholar.org/paper/c5bb7fe69b3b71d8a6f9c89022b687c1053e55ca\",\"venue\":\"IEEE Transactions on Computational Intelligence and AI in Games\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36604089\",\"name\":\"J. Robertson\"},{\"authorId\":\"145513579\",\"name\":\"R. Young\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a8181cd321fd9071078080504fbb008b4a5d44f0\",\"title\":\"Automated Gameplay Generation from Declarative World Representations\",\"url\":\"https://www.semanticscholar.org/paper/a8181cd321fd9071078080504fbb008b4a5d44f0\",\"venue\":\"AIIDE\",\"year\":2015},{\"arxivId\":\"1602.01783\",\"authors\":[{\"authorId\":\"3255983\",\"name\":\"V. Mnih\"},{\"authorId\":\"36045539\",\"name\":\"Adri\\u00e0 Puigdom\\u00e8nech Badia\"},{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"2542999\",\"name\":\"T. Lillicrap\"},{\"authorId\":\"3367786\",\"name\":\"T. Harley\"},{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"69e76e16740ed69f4dc55361a3d319ac2f1293dd\",\"title\":\"Asynchronous Methods for Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/69e76e16740ed69f4dc55361a3d319ac2f1293dd\",\"venue\":\"ICML\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1728712\",\"name\":\"Boyang Li\"},{\"authorId\":\"1403853328\",\"name\":\"Stephen Lee-Urban\"},{\"authorId\":\"145725383\",\"name\":\"G. Johnston\"},{\"authorId\":\"2757194\",\"name\":\"Mark O. Riedl\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"89d9ec586758f86d0aabae5f9ecafd5f69c89bf5\",\"title\":\"Story Generation with Crowdsourced Plot Graphs\",\"url\":\"https://www.semanticscholar.org/paper/89d9ec586758f86d0aabae5f9ecafd5f69c89bf5\",\"venue\":\"AAAI\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36797006\",\"name\":\"Seung Y. Lee\"},{\"authorId\":\"34971293\",\"name\":\"J. Rowe\"},{\"authorId\":\"9808011\",\"name\":\"B. Mott\"},{\"authorId\":\"1717955\",\"name\":\"J. Lester\"}],\"doi\":\"10.1109/TCIAIG.2013.2292010\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ae7990ab9f0708773389ab1353d91916ea990e16\",\"title\":\"A Supervised Learning Framework for Modeling Director Agent Strategies in Educational Interactive Narrative\",\"url\":\"https://www.semanticscholar.org/paper/ae7990ab9f0708773389ab1353d91916ea990e16\",\"venue\":\"IEEE Transactions on Computational Intelligence and AI in Games\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49478313\",\"name\":\"L. Lin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"54c4cf3a8168c1b70f91cf78a3dc98b671935492\",\"title\":\"Reinforcement learning for robots using neural networks\",\"url\":\"https://www.semanticscholar.org/paper/54c4cf3a8168c1b70f91cf78a3dc98b671935492\",\"venue\":\"\",\"year\":1992},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46808274\",\"name\":\"P. Wang\"},{\"authorId\":\"34971293\",\"name\":\"J. Rowe\"},{\"authorId\":\"9808011\",\"name\":\"B. Mott\"},{\"authorId\":\"1717955\",\"name\":\"J. Lester\"}],\"doi\":\"10.1007/978-3-319-48279-8_24\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9aa11581d39da0a20c798cf333b4bf2938eaba9b\",\"title\":\"Decomposing Drama Management in Educational Interactive Narrative: A Modular Reinforcement Learning Approach\",\"url\":\"https://www.semanticscholar.org/paper/9aa11581d39da0a20c798cf333b4bf2938eaba9b\",\"venue\":\"ICIDS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J. Rowe S. Lee\"},{\"authorId\":null,\"name\":\"B. Mott\"},{\"authorId\":null,\"name\":\"J. Lester\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Search - based drama management\",\"url\":\"\",\"venue\":\"AAAI Workshop on Challenges in Game Artificial Intelligence\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2690025\",\"name\":\"M. Harmon\"},{\"authorId\":\"1844179\",\"name\":\"L. Baird\"},{\"authorId\":\"2650569\",\"name\":\"A. Klopf\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b37942125dbb83a3bedd418f2797814c604f9e24\",\"title\":\"Advantage Updating Applied to a Differrential Game\",\"url\":\"https://www.semanticscholar.org/paper/b37942125dbb83a3bedd418f2797814c604f9e24\",\"venue\":\"NIPS\",\"year\":1994}],\"title\":\"Interactive Narrative Personalization with Deep Reinforcement Learning\",\"topics\":[{\"topic\":\"Reinforcement learning\",\"topicId\":\"2557\",\"url\":\"https://www.semanticscholar.org/topic/2557\"},{\"topic\":\"Personalization\",\"topicId\":\"2873\",\"url\":\"https://www.semanticscholar.org/topic/2873\"},{\"topic\":\"Long short-term memory\",\"topicId\":\"117199\",\"url\":\"https://www.semanticscholar.org/topic/117199\"},{\"topic\":\"Simulation\",\"topicId\":\"194\",\"url\":\"https://www.semanticscholar.org/topic/194\"},{\"topic\":\"Interactivity\",\"topicId\":\"192\",\"url\":\"https://www.semanticscholar.org/topic/192\"},{\"topic\":\"Synthetic data\",\"topicId\":\"16840\",\"url\":\"https://www.semanticscholar.org/topic/16840\"},{\"topic\":\"Educational entertainment\",\"topicId\":\"196737\",\"url\":\"https://www.semanticscholar.org/topic/196737\"},{\"topic\":\"Interaction\",\"topicId\":\"72\",\"url\":\"https://www.semanticscholar.org/topic/72\"},{\"topic\":\"Nonlinear system\",\"topicId\":\"5329\",\"url\":\"https://www.semanticscholar.org/topic/5329\"},{\"topic\":\"Population\",\"topicId\":\"2902\",\"url\":\"https://www.semanticscholar.org/topic/2902\"},{\"topic\":\"Liquid-crystal display\",\"topicId\":\"40766\",\"url\":\"https://www.semanticscholar.org/topic/40766\"}],\"url\":\"https://www.semanticscholar.org/paper/24b1f433fba56ab7469ecc3835280eff7434bf15\",\"venue\":\"IJCAI\",\"year\":2017}\n"