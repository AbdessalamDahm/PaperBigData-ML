"{\"abstract\":\"Deep Neural Network (DNN) is difficult to train and easy to overfit in training. We address these two issues by introducing EigenNet, an architecture that not only accelerates training but also adjusts number of hidden neurons to reduce over-fitting. They are achieved by whitening the information flows of DNNs and removing those eigenvectors that may capture noises. The former improves conditioning of the Fisher information matrix, whilst the latter increases generalization capability. These appealing properties of EigenNet can benefit many recent DNN structures, such as network in network and inception, by wrapping their hidden layers into the layers of EigenNet. The modeling capacities of the original networks are preserved. Both the training wall-clock time and number of updates are reduced by using EigenNet, compared to stochastic gradient descent on various datasets, including MNIST, CIFAR-10, and CIFAR-100.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"47571885\",\"name\":\"Ping Luo\",\"url\":\"https://www.semanticscholar.org/author/47571885\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":\"1809.00846\",\"authors\":[{\"authorId\":\"47571885\",\"name\":\"Ping Luo\"},{\"authorId\":\"47119674\",\"name\":\"X. Wang\"},{\"authorId\":\"49637157\",\"name\":\"W. Shao\"},{\"authorId\":\"2201921\",\"name\":\"Z. Peng\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9fa42ea422fe1729e04a98fa8072a7b48ce91bc8\",\"title\":\"Towards Understanding Regularization in Batch Normalization\",\"url\":\"https://www.semanticscholar.org/paper/9fa42ea422fe1729e04a98fa8072a7b48ce91bc8\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2749191\",\"name\":\"Guangrun Wang\"},{\"authorId\":\"35739338\",\"name\":\"Jiefeng Peng\"},{\"authorId\":\"47571885\",\"name\":\"Ping Luo\"},{\"authorId\":\"47119674\",\"name\":\"X. Wang\"},{\"authorId\":\"1737218\",\"name\":\"L. Lin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8aa3bf043e7559e6d3a03d061de6f86a31d0cff2\",\"title\":\"Kalman Normalization: Normalizing Internal Representations Across Network Layers\",\"url\":\"https://www.semanticscholar.org/paper/8aa3bf043e7559e6d3a03d061de6f86a31d0cff2\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1811.07727\",\"authors\":[{\"authorId\":\"47571885\",\"name\":\"Ping Luo\"},{\"authorId\":\"2201921\",\"name\":\"Z. Peng\"},{\"authorId\":\"9846740\",\"name\":\"Jiamin Ren\"},{\"authorId\":\"2247393\",\"name\":\"Ruimao Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2d6967a79ed0b093d616badd3e9d23217eef66d0\",\"title\":\"Do Normalization Layers in a Deep ConvNet Really Need to Be Distinct?\",\"url\":\"https://www.semanticscholar.org/paper/2d6967a79ed0b093d616badd3e9d23217eef66d0\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1802.03133\",\"authors\":[{\"authorId\":\"2749191\",\"name\":\"Guangrun Wang\"},{\"authorId\":\"35739338\",\"name\":\"Jiefeng Peng\"},{\"authorId\":\"47571885\",\"name\":\"Ping Luo\"},{\"authorId\":\"47119674\",\"name\":\"X. Wang\"},{\"authorId\":\"1737218\",\"name\":\"L. Lin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"59489eb08a47e6506294ef9130087da8c914948a\",\"title\":\"Batch Kalman Normalization: Towards Training Deep Neural Networks with Micro-Batches\",\"url\":\"https://www.semanticscholar.org/paper/59489eb08a47e6506294ef9130087da8c914948a\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1907.10473\",\"authors\":[{\"authorId\":\"47571885\",\"name\":\"Ping Luo\"},{\"authorId\":\"2247393\",\"name\":\"Ruimao Zhang\"},{\"authorId\":\"9846740\",\"name\":\"Jiamin Ren\"},{\"authorId\":\"2201921\",\"name\":\"Z. Peng\"},{\"authorId\":\"5096712\",\"name\":\"J. Li\"}],\"doi\":\"10.1109/TPAMI.2019.2932062\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2e2534eb1f1af5c043a009391f0ef955aeed2044\",\"title\":\"Switchable Normalization for Learning-to-Normalize Deep Representation\",\"url\":\"https://www.semanticscholar.org/paper/2e2534eb1f1af5c043a009391f0ef955aeed2044\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2019},{\"arxivId\":\"1806.10779\",\"authors\":[{\"authorId\":\"47571885\",\"name\":\"Ping Luo\"},{\"authorId\":\"9846740\",\"name\":\"Jiamin Ren\"},{\"authorId\":\"2201921\",\"name\":\"Z. Peng\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e936def63d29c8e3d4b99788ee7290ff6274911a\",\"title\":\"Differentiable Learning-to-Normalize via Switchable Normalization\",\"url\":\"https://www.semanticscholar.org/paper/e936def63d29c8e3d4b99788ee7290ff6274911a\",\"venue\":\"ICLR\",\"year\":2019}],\"corpusId\":28855125,\"doi\":\"10.24963/ijcai.2017/338\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":false,\"paperId\":\"96f9040fcc4b814690523eb954b53735f8a22df4\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1739396\",\"name\":\"N. N. Schraudolph\"}],\"doi\":\"10.1162/08997660260028683\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ffa94bba647817fa5e8f8d3250fc977435b5ca76\",\"title\":\"Fast Curvature Matrix-Vector Products for Second-Order Gradient Descent\",\"url\":\"https://www.semanticscholar.org/paper/ffa94bba647817fa5e8f8d3250fc977435b5ca76\",\"venue\":\"Neural Computation\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"N Nicol\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Schraudolph . Centering neural network gradient factors\",\"url\":\"\",\"venue\":\"Neural Networks : Tricks of the Trade , 2002\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1739396\",\"name\":\"N. N. Schraudolph\"}],\"doi\":\"10.1007/978-3-642-35289-8_14\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"75a026ddfdd9c219d69fe8af816f085ea1b3877d\",\"title\":\"Centering Neural Network Gradient Factors\",\"url\":\"https://www.semanticscholar.org/paper/75a026ddfdd9c219d69fe8af816f085ea1b3877d\",\"venue\":\"Neural Networks: Tricks of the Trade\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"},{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"34f25a8704614163c4095b3ee2fc969b60de4698\",\"title\":\"Dropout: a simple way to prevent neural networks from overfitting\",\"url\":\"https://www.semanticscholar.org/paper/34f25a8704614163c4095b3ee2fc969b60de4698\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5d90f06bb70a0a3dced62413346235c02b1aa086\",\"title\":\"Learning Multiple Layers of Features from Tiny Images\",\"url\":\"https://www.semanticscholar.org/paper/5d90f06bb70a0a3dced62413346235c02b1aa086\",\"venue\":\"\",\"year\":2009},{\"arxivId\":\"1502.03167\",\"authors\":[{\"authorId\":\"144147316\",\"name\":\"S. Ioffe\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4d376d6978dad0374edfa6709c9556b42d3594d3\",\"title\":\"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\",\"url\":\"https://www.semanticscholar.org/paper/4d376d6978dad0374edfa6709c9556b42d3594d3\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1503.05671\",\"authors\":[{\"authorId\":\"145704247\",\"name\":\"J. Martens\"},{\"authorId\":\"1785346\",\"name\":\"Roger B. Grosse\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cb4dc7277d1c8c3bc76dd7425eb1cc7cbaf99487\",\"title\":\"Optimizing Neural Networks with Kronecker-factored Approximate Curvature\",\"url\":\"https://www.semanticscholar.org/paper/cb4dc7277d1c8c3bc76dd7425eb1cc7cbaf99487\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"32837403\",\"name\":\"J. Bergstra\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":\"10.1145/1273496.1273556\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b8012351bc5ebce4a4b3039bbbba3ce393bc3315\",\"title\":\"An empirical evaluation of deep architectures on problems with many factors of variation\",\"url\":\"https://www.semanticscholar.org/paper/b8012351bc5ebce4a4b3039bbbba3ce393bc3315\",\"venue\":\"ICML '07\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"N Nicol\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Schraudolph . Centering neural network gradient factors\",\"url\":\"\",\"venue\":\"Neural Networks : Tricks of the Trade , 2002\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144362426\",\"name\":\"S. Amari\"},{\"authorId\":\"145930529\",\"name\":\"H. Nagaoka\"}],\"doi\":\"10.1090/mmono/191\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"617111ed3746c4304c87b188ba155b160e9f082e\",\"title\":\"Methods of information geometry\",\"url\":\"https://www.semanticscholar.org/paper/617111ed3746c4304c87b188ba155b160e9f082e\",\"venue\":\"\",\"year\":2000},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2785022\",\"name\":\"T. Raiko\"},{\"authorId\":\"2132516\",\"name\":\"H. Valpola\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b8ef1230a5cc9ea7cd8358f1ae7d1af97813ba14\",\"title\":\"Deep Learning Made Easier by Linear Transformations in Perceptrons\",\"url\":\"https://www.semanticscholar.org/paper/b8ef1230a5cc9ea7cd8358f1ae7d1af97813ba14\",\"venue\":\"AISTATS\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"},{\"authorId\":\"2812486\",\"name\":\"P. Simard\"},{\"authorId\":\"1700974\",\"name\":\"Barak A. Pearlmutter\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"abc8a30694deda46c150d4da277aec291878cfeb\",\"title\":\"Automatic Learning Rate Maximization by On-Line Estimation of the Hessian's Eigenvectors\",\"url\":\"https://www.semanticscholar.org/paper/abc8a30694deda46c150d4da277aec291878cfeb\",\"venue\":\"NIPS 1992\",\"year\":1992},{\"arxivId\":\"1507.00210\",\"authors\":[{\"authorId\":\"2755582\",\"name\":\"G. Desjardins\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1996134\",\"name\":\"Razvan Pascanu\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"941e30afcae061a115301c65a1afe49d8856f14e\",\"title\":\"Natural Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/941e30afcae061a115301c65a1afe49d8856f14e\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ioffe\"},{\"authorId\":null,\"name\":\"Szegedy\"},{\"authorId\":null,\"name\":\"2015 Sergey Ioffe\"},{\"authorId\":null,\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Batch normalization: Accelerating deep network\",\"url\":\"\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Tijmen Tieleman\"},{\"authorId\":null,\"name\":\"Geoffrey Hinton\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Rmsprop: Divide the gradient by a running average of its recent magnitude\",\"url\":\"\",\"venue\":\"Neural Networks for Machine Learning (Lecture 6.5),\",\"year\":2012},{\"arxivId\":\"1312.4400\",\"authors\":[{\"authorId\":\"143953684\",\"name\":\"M. Lin\"},{\"authorId\":\"35370244\",\"name\":\"Q. Chen\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"5e83ab70d0cbc003471e87ec306d27d9c80ecb16\",\"title\":\"Network In Network\",\"url\":\"https://www.semanticscholar.org/paper/5e83ab70d0cbc003471e87ec306d27d9c80ecb16\",\"venue\":\"ICLR\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yann LeCun\"},{\"authorId\":null,\"name\":\"Ido Kanter\"},{\"authorId\":null,\"name\":\"Sara A. Solla\"},{\"authorId\":null,\"name\":\"Sara A. Solla\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0c43153a3627c7d98cc09f909c232f3899597204\",\"title\":\"Second Order Properties of Error Surfaces: Learning Time and Generalization\",\"url\":\"https://www.semanticscholar.org/paper/0c43153a3627c7d98cc09f909c232f3899597204\",\"venue\":\"NIPS 1990\",\"year\":1990}],\"title\":\"EigenNet: Towards Fast and Structural Learning of Deep Neural Networks\",\"topics\":[{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"},{\"topic\":\"Overfitting\",\"topicId\":\"70499\",\"url\":\"https://www.semanticscholar.org/topic/70499\"},{\"topic\":\"Stochastic gradient descent\",\"topicId\":\"202796\",\"url\":\"https://www.semanticscholar.org/topic/202796\"},{\"topic\":\"Fisher information\",\"topicId\":\"36658\",\"url\":\"https://www.semanticscholar.org/topic/36658\"},{\"topic\":\"Deep learning\",\"topicId\":\"2762\",\"url\":\"https://www.semanticscholar.org/topic/2762\"},{\"topic\":\"Generative model\",\"topicId\":\"37177\",\"url\":\"https://www.semanticscholar.org/topic/37177\"},{\"topic\":\"Bayesian information criterion\",\"topicId\":\"303465\",\"url\":\"https://www.semanticscholar.org/topic/303465\"},{\"topic\":\"Academy\",\"topicId\":\"2609\",\"url\":\"https://www.semanticscholar.org/topic/2609\"},{\"topic\":\"Neural network software\",\"topicId\":\"172426\",\"url\":\"https://www.semanticscholar.org/topic/172426\"},{\"topic\":\"Image noise\",\"topicId\":\"18959\",\"url\":\"https://www.semanticscholar.org/topic/18959\"},{\"topic\":\"Network architecture\",\"topicId\":\"58473\",\"url\":\"https://www.semanticscholar.org/topic/58473\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Formation matrix\",\"topicId\":\"36659\",\"url\":\"https://www.semanticscholar.org/topic/36659\"},{\"topic\":\"While\",\"topicId\":\"710504\",\"url\":\"https://www.semanticscholar.org/topic/710504\"},{\"topic\":\"MNIST database\",\"topicId\":\"211771\",\"url\":\"https://www.semanticscholar.org/topic/211771\"},{\"topic\":\"Wrapping (graphics)\",\"topicId\":\"54656\",\"url\":\"https://www.semanticscholar.org/topic/54656\"},{\"topic\":\"Whitening transformation\",\"topicId\":\"619136\",\"url\":\"https://www.semanticscholar.org/topic/619136\"}],\"url\":\"https://www.semanticscholar.org/paper/96f9040fcc4b814690523eb954b53735f8a22df4\",\"venue\":\"IJCAI\",\"year\":2017}\n"