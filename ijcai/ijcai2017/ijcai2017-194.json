"{\"abstract\":\"Many state-of-the-art reinforcement learning (RL) algorithms typically assume that the environment is an ergodic Markov Decision Process (MDP). In contrast, the field of universal reinforcement learning (URL) is concerned with algorithms that make as few assumptions as possible about the environment. The universal Bayesian agent AIXI and a family of related URL algorithms have been developed in this setting. While numerous theoretical optimality results have been proven for these agents, there has been no empirical investigation of their behavior to date. We present a short and accessible survey of these URL algorithms under a unified notation and framework, along with results of some experiments that qualitatively illustrate some properties of the resulting policies, and their relative performance on partially-observable gridworld environments. We also present an open-source reference implementation of the algorithms which we hope will facilitate further understanding of, and experimentation with, these ideas.\",\"arxivId\":\"1705.10557\",\"authors\":[{\"authorId\":\"9958912\",\"name\":\"J. Aslanides\",\"url\":\"https://www.semanticscholar.org/author/9958912\"},{\"authorId\":\"2990741\",\"name\":\"J. Leike\",\"url\":\"https://www.semanticscholar.org/author/2990741\"},{\"authorId\":\"144154444\",\"name\":\"Marcus Hutter\",\"url\":\"https://www.semanticscholar.org/author/144154444\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3403134ad7f0ec47f73404a1026e2e8a60c5bf16\",\"title\":\"Paradigms of Artificial General Intelligence and Their Associated Risks\",\"url\":\"https://www.semanticscholar.org/paper/3403134ad7f0ec47f73404a1026e2e8a60c5bf16\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1903.01021\",\"authors\":[{\"authorId\":\"11983844\",\"name\":\"Michael K. Cohen\"},{\"authorId\":\"22574075\",\"name\":\"Elliot Catt\"},{\"authorId\":\"144154444\",\"name\":\"Marcus Hutter\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"81d4c3f2b513d71a31c0253885a6c4d7f27e30d5\",\"title\":\"Strong Asymptotic Optimality in General Environments\",\"url\":\"https://www.semanticscholar.org/paper/81d4c3f2b513d71a31c0253885a6c4d7f27e30d5\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11983844\",\"name\":\"Michael K. Cohen\"},{\"authorId\":\"22574075\",\"name\":\"Elliot Catt\"},{\"authorId\":\"144154444\",\"name\":\"Marcus Hutter\"}],\"doi\":\"10.24963/ijcai.2019/302\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1430ff8b67a5a221dd719eff6e1c9dee6adbc595\",\"title\":\"A Strongly Asymptotically Optimal Agent in General Environments\",\"url\":\"https://www.semanticscholar.org/paper/1430ff8b67a5a221dd719eff6e1c9dee6adbc595\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10412912\",\"name\":\"T. D. Bruin\"},{\"authorId\":\"145739642\",\"name\":\"J. Kober\"},{\"authorId\":\"2274623\",\"name\":\"K. Tuyls\"},{\"authorId\":\"1705222\",\"name\":\"Robert Babu\\u0161ka\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6a17b2ba75d8fca0b06fa5329b18694ed985959f\",\"title\":\"Experience Selection in Deep Reinforcement Learning for Control\",\"url\":\"https://www.semanticscholar.org/paper/6a17b2ba75d8fca0b06fa5329b18694ed985959f\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2990741\",\"name\":\"J. Leike\"},{\"authorId\":\"2989692\",\"name\":\"Tor Lattimore\"},{\"authorId\":\"1749270\",\"name\":\"Laurent Orseau\"},{\"authorId\":\"144154444\",\"name\":\"Marcus Hutter\"}],\"doi\":\"10.24963/ijcai.2017/688\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4619a0ed05ada81f562c2f1cfbb9116d1913bc98\",\"title\":\"On Thompson Sampling and Asymptotic Optimality\",\"url\":\"https://www.semanticscholar.org/paper/4619a0ed05ada81f562c2f1cfbb9116d1913bc98\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":\"1703.01358\",\"authors\":[{\"authorId\":\"40295239\",\"name\":\"Sean Lamont\"},{\"authorId\":\"9958912\",\"name\":\"J. Aslanides\"},{\"authorId\":\"2990741\",\"name\":\"J. Leike\"},{\"authorId\":\"144154444\",\"name\":\"Marcus Hutter\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7209a01579872f17f6e3b4fd634ae39e95bdc31e\",\"title\":\"Generalised Discount Functions applied to a Monte-Carlo AI u Implementation\",\"url\":\"https://www.semanticscholar.org/paper/7209a01579872f17f6e3b4fd634ae39e95bdc31e\",\"venue\":\"AAMAS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10412912\",\"name\":\"T. D. Bruin\"}],\"doi\":\"10.4233/UUID:F8FAACB0-9A55-453D-97FD-0388A3C848EE\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"af1a3c19914fd6ae759379a0729df12154d0a410\",\"title\":\"Sample effficient deep reinforcement learning for control\",\"url\":\"https://www.semanticscholar.org/paper/af1a3c19914fd6ae759379a0729df12154d0a410\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1806.08083\",\"authors\":[{\"authorId\":\"34612789\",\"name\":\"M. Biehl\"},{\"authorId\":\"3027681\",\"name\":\"C. Guckelsberger\"},{\"authorId\":\"2135139\",\"name\":\"C. Salge\"},{\"authorId\":\"1791180\",\"name\":\"S. Smith\"},{\"authorId\":\"1799704\",\"name\":\"D. Polani\"}],\"doi\":\"10.3389/fnbot.2018.00045\",\"intent\":[\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"71255c5df891501ea99cc02e8699fb0c231658e4\",\"title\":\"Expanding the Active Inference Landscape: More Intrinsic Motivations in the Perception-Action Loop\",\"url\":\"https://www.semanticscholar.org/paper/71255c5df891501ea99cc02e8699fb0c231658e4\",\"venue\":\"Front. Neurorobot.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49935593\",\"name\":\"D. Meedeniya\"},{\"authorId\":\"35492198\",\"name\":\"I. Rubasinghe\"}],\"doi\":\"10.4018/978-1-7998-3069-6.ch016\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b110f28bde057d7d717a2b2d6bb37a49a255c46d\",\"title\":\"A Review of Supportive Computational Approaches for Neurological Disorder Identification\",\"url\":\"https://www.semanticscholar.org/paper/b110f28bde057d7d717a2b2d6bb37a49a255c46d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1868196\",\"name\":\"Tom Everitt\"}],\"doi\":\"10.25911/5D134A2F8A7D3\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8b1e149ae23ea7839c9e3a2bd063c354ff7075d0\",\"title\":\"Towards Safe Artificial General Intelligence\",\"url\":\"https://www.semanticscholar.org/paper/8b1e149ae23ea7839c9e3a2bd063c354ff7075d0\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1705.08417\",\"authors\":[{\"authorId\":\"1868196\",\"name\":\"Tom Everitt\"},{\"authorId\":\"2578985\",\"name\":\"Victoria Krakovna\"},{\"authorId\":\"1749270\",\"name\":\"Laurent Orseau\"},{\"authorId\":\"34313265\",\"name\":\"S. Legg\"}],\"doi\":\"10.24963/ijcai.2017/656\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e5ba74bd3b6c9bb0287d8835621ddd40dd3ebbf4\",\"title\":\"Reinforcement Learning with a Corrupted Reward Channel\",\"url\":\"https://www.semanticscholar.org/paper/e5ba74bd3b6c9bb0287d8835621ddd40dd3ebbf4\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":\"1906.09136\",\"authors\":[{\"authorId\":\"146121921\",\"name\":\"Arushi Majha\"},{\"authorId\":\"48371377\",\"name\":\"S. Sarkar\"},{\"authorId\":\"146567325\",\"name\":\"Davide Zagami\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"ff4108a4621e8fa31d0096a27ee6924e44716007\",\"title\":\"Categorizing Wireheading in Partially Embedded Agents\",\"url\":\"https://www.semanticscholar.org/paper/ff4108a4621e8fa31d0096a27ee6924e44716007\",\"venue\":\"AISafety@IJCAI\",\"year\":2019}],\"corpusId\":11890281,\"doi\":\"10.24963/ijcai.2017/194\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":2,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"d1627e5dd7c6656aa8c16d861677ac631c5c4301\",\"references\":[{\"arxivId\":\"1510.04931\",\"authors\":[{\"authorId\":\"2990741\",\"name\":\"J. Leike\"},{\"authorId\":\"144154444\",\"name\":\"Marcus Hutter\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"72f2eb13a98229f4b201b12942647853579111da\",\"title\":\"Bad Universal Priors and Notions of Optimality\",\"url\":\"https://www.semanticscholar.org/paper/72f2eb13a98229f4b201b12942647853579111da\",\"venue\":\"COLT\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jorma Rissanen. Modeling by shortest data description\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Automatica\",\"url\":\"\",\"venue\":\"14(5):465\\u2013471,\",\"year\":1978},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"D. Pathak\"},{\"authorId\":null,\"name\":\"P. Agrawal\"},{\"authorId\":null,\"name\":\"A. A. Efros\"},{\"authorId\":null,\"name\":\"T. Darrell. Curiosity-driven Exploration by Selfsuper Prediction\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"ArXiv e-prints\",\"url\":\"\",\"venue\":\"May\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"S. Thrun. The role of exploration in learning control\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In Handbook for Intelligent Control: Neural\",\"url\":\"\",\"venue\":\"Fuzzy and Adaptive Approaches.\",\"year\":1992},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"1885349\",\"name\":\"Aja Huang\"},{\"authorId\":\"2772217\",\"name\":\"Chris J. Maddison\"},{\"authorId\":\"35099444\",\"name\":\"A. Guez\"},{\"authorId\":\"2175946\",\"name\":\"L. Sifre\"},{\"authorId\":\"47568983\",\"name\":\"George van den Driessche\"},{\"authorId\":\"4337102\",\"name\":\"Julian Schrittwieser\"},{\"authorId\":\"2460849\",\"name\":\"Ioannis Antonoglou\"},{\"authorId\":\"2749418\",\"name\":\"Vedavyas Panneershelvam\"},{\"authorId\":\"1975889\",\"name\":\"Marc Lanctot\"},{\"authorId\":\"48373216\",\"name\":\"S. Dieleman\"},{\"authorId\":\"2401609\",\"name\":\"Dominik Grewe\"},{\"authorId\":\"4111313\",\"name\":\"John Nham\"},{\"authorId\":\"2583391\",\"name\":\"Nal Kalchbrenner\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"2542999\",\"name\":\"T. Lillicrap\"},{\"authorId\":\"40662181\",\"name\":\"M. Leach\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"},{\"authorId\":\"1686971\",\"name\":\"T. Graepel\"},{\"authorId\":\"48987704\",\"name\":\"Demis Hassabis\"}],\"doi\":\"10.1038/nature16961\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"846aedd869a00c09b40f1f1f35673cb22bc87490\",\"title\":\"Mastering the game of Go with deep neural networks and tree search\",\"url\":\"https://www.semanticscholar.org/paper/846aedd869a00c09b40f1f1f35673cb22bc87490\",\"venue\":\"Nature\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Levente Kocsis\"},{\"authorId\":null,\"name\":\"Csaba Szepesv\\u00e1ri. Bandit based monte-carlo planning\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In European Conference on Machine Learning\",\"url\":\"\",\"venue\":\"pages 282\\u2013293,\",\"year\":2006},{\"arxivId\":\"1602.07905\",\"authors\":[{\"authorId\":\"2990741\",\"name\":\"J. Leike\"},{\"authorId\":\"2989692\",\"name\":\"Tor Lattimore\"},{\"authorId\":\"1749270\",\"name\":\"Laurent Orseau\"},{\"authorId\":\"144154444\",\"name\":\"Marcus Hutter\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1a81f1155f847b268ae4bed160540c2ee3acb5a9\",\"title\":\"Thompson Sampling is Asymptotically Optimal in General Environments\",\"url\":\"https://www.semanticscholar.org/paper/1a81f1155f847b268ae4bed160540c2ee3acb5a9\",\"venue\":\"UAI\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699645\",\"name\":\"R. Sutton\"},{\"authorId\":\"1730590\",\"name\":\"A. Barto\"}],\"doi\":\"10.1109/TNN.1998.712192\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"97efafdb4a3942ab3efba53ded7413199f79c054\",\"title\":\"Reinforcement Learning: An Introduction\",\"url\":\"https://www.semanticscholar.org/paper/97efafdb4a3942ab3efba53ded7413199f79c054\",\"venue\":\"IEEE Transactions on Neural Networks\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1749270\",\"name\":\"Laurent Orseau\"},{\"authorId\":\"2989692\",\"name\":\"Tor Lattimore\"},{\"authorId\":\"144154444\",\"name\":\"Marcus Hutter\"}],\"doi\":\"10.1007/978-3-642-40935-6_12\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e8dd477ec5d34ba46b8fe654537d509560c91ca3\",\"title\":\"Universal Knowledge-Seeking Agents for Stochastic Environments\",\"url\":\"https://www.semanticscholar.org/paper/e8dd477ec5d34ba46b8fe654537d509560c91ca3\",\"venue\":\"ALT\",\"year\":2013},{\"arxivId\":null,\"authors\":[],\"doi\":\"10.1007/3-540-58520-6\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aaf39c55ee8ee9ed83a14f90c68ed93da3aafe09\",\"title\":\"Algorithmic Learning Theory\",\"url\":\"https://www.semanticscholar.org/paper/aaf39c55ee8ee9ed83a14f90c68ed93da3aafe09\",\"venue\":\"Lecture Notes in Computer Science\",\"year\":1994},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153191610\",\"name\":\"G. Christodoulou\"},{\"authorId\":\"1403863711\",\"name\":\"Aris Filos-Ratsikas\"},{\"authorId\":\"5985102\",\"name\":\"S. Frederiksen\"},{\"authorId\":\"33930771\",\"name\":\"P. Goldberg\"},{\"authorId\":\"47538770\",\"name\":\"J. Zhang\"},{\"authorId\":\"40430872\",\"name\":\"J. Zhang\"}],\"doi\":\"10.1007/978-3-319-46882-2\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"0a5542bf6f55be2daaf7757be93a6c3b546a8244\",\"title\":\"Autonomous Agents and Multiagent Systems\",\"url\":\"https://www.semanticscholar.org/paper/0a5542bf6f55be2daaf7757be93a6c3b546a8244\",\"venue\":\"Lecture Notes in Computer Science\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144543541\",\"name\":\"P. Auer\"},{\"authorId\":\"1397171999\",\"name\":\"Nicol\\u00f2 Cesa-Bianchi\"},{\"authorId\":\"152138722\",\"name\":\"P. Fischer\"}],\"doi\":\"10.1023/A:1013689704352\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1e1d35136b1bf3b13ef6b53f6039f39d9ee820e3\",\"title\":\"Finite-time Analysis of the Multiarmed Bandit Problem\",\"url\":\"https://www.semanticscholar.org/paper/1e1d35136b1bf3b13ef6b53f6039f39d9ee820e3\",\"venue\":\"Machine Learning\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2989692\",\"name\":\"Tor Lattimore\"}],\"doi\":\"10.25911/5D5154989FCDA\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bb998491b41f8dcaf20130a8869e7c0a18864c06\",\"title\":\"Theory of general reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/bb998491b41f8dcaf20130a8869e7c0a18864c06\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144867807\",\"name\":\"S. Thrun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7f28557e63e44d60fe01adc442676893d3de3496\",\"title\":\"The role of exploration in learning control\",\"url\":\"https://www.semanticscholar.org/paper/7f28557e63e44d60fe01adc442676893d3de3496\",\"venue\":\"\",\"year\":1992},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Joel Veness\"},{\"authorId\":null,\"name\":\"Kee Siong Ng\"},{\"authorId\":null,\"name\":\"Marcus Hutter\"},{\"authorId\":null,\"name\":\"William Uther\"},{\"authorId\":null,\"name\":\"David Silver. A Monte-Carlo AIXI approximation\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Journal of Artificial Intelligence Research\",\"url\":\"\",\"venue\":\"40(1):95\\u2013142,\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Laurent Orseau. Optimality issues of universal greedy agen Theory\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"pages 345\\u2013359\",\"url\":\"\",\"venue\":\"Springer,\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"144056327\",\"name\":\"J. Veness\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f115acbd94451f58a5bc5062c1d7e6707e5be1f0\",\"title\":\"Monte-Carlo Planning in Large POMDPs\",\"url\":\"https://www.semanticscholar.org/paper/f115acbd94451f58a5bc5062c1d7e6707e5be1f0\",\"venue\":\"NIPS\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3255983\",\"name\":\"V. Mnih\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"},{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"1392331736\",\"name\":\"Andrei A. Rusu\"},{\"authorId\":\"144056327\",\"name\":\"J. Veness\"},{\"authorId\":\"1397980088\",\"name\":\"Marc G. Bellemare\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"3137672\",\"name\":\"Martin A. Riedmiller\"},{\"authorId\":\"1397979864\",\"name\":\"Andreas K. Fidjeland\"},{\"authorId\":\"2273072\",\"name\":\"Georg Ostrovski\"},{\"authorId\":\"145386761\",\"name\":\"S. Petersen\"},{\"authorId\":\"48878752\",\"name\":\"C. Beattie\"},{\"authorId\":\"49813280\",\"name\":\"A. Sadik\"},{\"authorId\":\"2460849\",\"name\":\"Ioannis Antonoglou\"},{\"authorId\":\"153907173\",\"name\":\"H. King\"},{\"authorId\":\"2106164\",\"name\":\"D. Kumaran\"},{\"authorId\":\"1688276\",\"name\":\"Daan Wierstra\"},{\"authorId\":\"34313265\",\"name\":\"S. Legg\"},{\"authorId\":\"48987704\",\"name\":\"Demis Hassabis\"}],\"doi\":\"10.1038/nature14236\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e0e9a94c4a6ba219e768b4e59f72c18f0a22e23d\",\"title\":\"Human-level control through deep reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/e0e9a94c4a6ba219e768b4e59f72c18f0a22e23d\",\"venue\":\"Nature\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144299726\",\"name\":\"Thomas G. Dietterich\"},{\"authorId\":\"153059475\",\"name\":\"S. Becker\"},{\"authorId\":\"1405497839\",\"name\":\"Z. G. Eds\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"89558a43b3b0a24cd0fdb6d5c2283112493af3a0\",\"title\":\"In Advances in Neural Information Processing Systems 15\",\"url\":\"https://www.semanticscholar.org/paper/89558a43b3b0a24cd0fdb6d5c2283112493af3a0\",\"venue\":\"NIPS 1991\",\"year\":1991},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jan Leike\"},{\"authorId\":null,\"name\":\"Tor Lattimore\"},{\"authorId\":null,\"name\":\"Laurent Orseau\"},{\"authorId\":null,\"name\":\"Marcus Hutter\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"On the computability of Solomonoff induction and knowledge - seeking\",\"url\":\"\",\"venue\":\"Algorithmic Learning Theory\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144299726\",\"name\":\"Thomas G. Dietterich\"}],\"doi\":\"10.1145/242224.242229\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aab43c9c33af00b718cf2ae374b861d49862a563\",\"title\":\"Machine learning\",\"url\":\"https://www.semanticscholar.org/paper/aab43c9c33af00b718cf2ae374b861d49862a563\",\"venue\":\"CSUR\",\"year\":1996},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32358325\",\"name\":\"D. Sofge\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a37a7bbd8ba95e134089621e2674a7ac753fa4f5\",\"title\":\"THE ROLE OF EXPLORATION IN LEARNING CONTROL\",\"url\":\"https://www.semanticscholar.org/paper/a37a7bbd8ba95e134089621e2674a7ac753fa4f5\",\"venue\":\"\",\"year\":1992},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11707333\",\"name\":\"K. Pearson\"}],\"doi\":\"10.1086/278079\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e8b7ec08425250b368c36384b19bb142f47a7d24\",\"title\":\"Biometrika\",\"url\":\"https://www.semanticscholar.org/paper/e8b7ec08425250b368c36384b19bb142f47a7d24\",\"venue\":\"The American Naturalist\",\"year\":1902},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144301306\",\"name\":\"W. Thompson\"}],\"doi\":\"10.1093/BIOMET/25.3-4.285\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ee2cd1d17f833d3c157a1016a778c7c22af555a2\",\"title\":\"ON THE LIKELIHOOD THAT ONE UNKNOWN PROBABILITY EXCEEDS ANOTHER IN VIEW OF THE EVIDENCE OF TWO SAMPLES\",\"url\":\"https://www.semanticscholar.org/paper/ee2cd1d17f833d3c157a1016a778c7c22af555a2\",\"venue\":\"\",\"year\":1933},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1749270\",\"name\":\"Laurent Orseau\"}],\"doi\":\"10.1007/978-3-642-24412-4_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c3b25d419f30873420f0bc159e9499edda9c0dbe\",\"title\":\"Universal Knowledge-Seeking Agents\",\"url\":\"https://www.semanticscholar.org/paper/c3b25d419f30873420f0bc159e9499edda9c0dbe\",\"venue\":\"ALT\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Laurent Orseau. Universal knowledgeseeking agents. In Algo Theory\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"pages 353\\u2013367\",\"url\":\"\",\"venue\":\"Springer,\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1749270\",\"name\":\"Laurent Orseau\"}],\"doi\":\"10.1007/978-3-642-16108-7_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"93f469cbbdf9eff9b36079f5989f9a0235880e05\",\"title\":\"Optimality Issues of Universal Greedy Agents with Static Priors\",\"url\":\"https://www.semanticscholar.org/paper/93f469cbbdf9eff9b36079f5989f9a0235880e05\",\"venue\":\"ALT\",\"year\":2010},{\"arxivId\":\"1611.08944\",\"authors\":[{\"authorId\":\"2990741\",\"name\":\"J. Leike\"}],\"doi\":\"10.25911/5D76346C2E2BE\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7e66171492a39a28cbcefd7309fc8863d3954f0a\",\"title\":\"Nonparametric General Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/7e66171492a39a28cbcefd7309fc8863d3954f0a\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"0907.0746\",\"authors\":[{\"authorId\":\"144154444\",\"name\":\"Marcus Hutter\"}],\"doi\":\"10.3390/a2030879\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"601708af94204a9453be9fde5f3f8ceb61e0243c\",\"title\":\"Open Problems in Universal Induction & Intelligence\",\"url\":\"https://www.semanticscholar.org/paper/601708af94204a9453be9fde5f3f8ceb61e0243c\",\"venue\":\"Algorithms\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jan Leike\"},{\"authorId\":null,\"name\":\"Marcus Hutter. Bad universal priors\"},{\"authorId\":null,\"name\":\"notions of optimality\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In Conference on Learning Theory\",\"url\":\"\",\"venue\":\"pages 1244\\u20131259,\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1814162\",\"name\":\"Peter Sunehag\"},{\"authorId\":\"144154444\",\"name\":\"Marcus Hutter\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f9bed62d59fb77a4b8782fffa0588153189d287f\",\"title\":\"Rationality, optimism and guarantees in general reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/f9bed62d59fb77a4b8782fffa0588153189d287f\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Sean Lamont\"},{\"authorId\":null,\"name\":\"John Aslanides\"},{\"authorId\":null,\"name\":\"Jan Leike\"},{\"authorId\":null,\"name\":\"Marcus Hutter\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Levente Kocsis and Csaba Szepesv\\u00e1ri . Bandit based monte - carlo planning\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1703.01358\",\"authors\":[{\"authorId\":\"40295239\",\"name\":\"Sean Lamont\"},{\"authorId\":\"9958912\",\"name\":\"J. Aslanides\"},{\"authorId\":\"2990741\",\"name\":\"J. Leike\"},{\"authorId\":\"144154444\",\"name\":\"Marcus Hutter\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7209a01579872f17f6e3b4fd634ae39e95bdc31e\",\"title\":\"Generalised Discount Functions applied to a Monte-Carlo AI u Implementation\",\"url\":\"https://www.semanticscholar.org/paper/7209a01579872f17f6e3b4fd634ae39e95bdc31e\",\"venue\":\"AAMAS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"103289857\",\"name\":\"J. Rissanen\"}],\"doi\":\"10.1016/0005-1098(78)90005-5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d382b9c11e5c6a8e173fbeb442545e3be8d3e3a5\",\"title\":\"Modeling By Shortest Data Description*\",\"url\":\"https://www.semanticscholar.org/paper/d382b9c11e5c6a8e173fbeb442545e3be8d3e3a5\",\"venue\":\"Autom.\",\"year\":1978},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"3276293\",\"name\":\"G. Lever\"},{\"authorId\":\"2801204\",\"name\":\"N. Heess\"},{\"authorId\":\"1804488\",\"name\":\"T. Degris\"},{\"authorId\":\"1688276\",\"name\":\"Daan Wierstra\"},{\"authorId\":\"3137672\",\"name\":\"Martin A. Riedmiller\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"687d0e59d5c35f022ce4638b3e3a6142068efc94\",\"title\":\"Deterministic Policy Gradient Algorithms\",\"url\":\"https://www.semanticscholar.org/paper/687d0e59d5c35f022ce4638b3e3a6142068efc94\",\"venue\":\"ICML\",\"year\":2014},{\"arxivId\":\"1706.08090\",\"authors\":[{\"authorId\":\"34104547\",\"name\":\"J. Martin\"},{\"authorId\":\"9763678\",\"name\":\"S. N. Sasikumar\"},{\"authorId\":\"1868196\",\"name\":\"Tom Everitt\"},{\"authorId\":\"144154444\",\"name\":\"Marcus Hutter\"}],\"doi\":\"10.24963/ijcai.2017/344\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0f810eb4777fd05317951ebaa7a3f5835ee84cf4\",\"title\":\"Count-Based Exploration in Feature Space for Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/0f810eb4777fd05317951ebaa7a3f5835ee84cf4\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3127100\",\"name\":\"Rein Houthooft\"},{\"authorId\":\"41192764\",\"name\":\"Xi Chen\"},{\"authorId\":\"144581158\",\"name\":\"Yan Duan\"},{\"authorId\":\"47971768\",\"name\":\"John Schulman\"},{\"authorId\":\"1715957\",\"name\":\"F. Turck\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"317cd4522b1f4a6f889743578143bb8823623f8b\",\"title\":\"VIME: Variational Information Maximizing Exploration\",\"url\":\"https://www.semanticscholar.org/paper/317cd4522b1f4a6f889743578143bb8823623f8b\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1606.01868\",\"authors\":[{\"authorId\":\"1792298\",\"name\":\"Marc G. Bellemare\"},{\"authorId\":\"144999731\",\"name\":\"S. Srinivasan\"},{\"authorId\":\"2273072\",\"name\":\"Georg Ostrovski\"},{\"authorId\":\"1725157\",\"name\":\"T. Schaul\"},{\"authorId\":\"143810408\",\"name\":\"D. Saxton\"},{\"authorId\":\"1708654\",\"name\":\"R. Munos\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6e90fd78e8a3b98af3954aae5209703aa966603e\",\"title\":\"Unifying Count-Based Exploration and Intrinsic Motivation\",\"url\":\"https://www.semanticscholar.org/paper/6e90fd78e8a3b98af3954aae5209703aa966603e\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"0909.0801\",\"authors\":[{\"authorId\":\"144056327\",\"name\":\"J. Veness\"},{\"authorId\":\"34746380\",\"name\":\"K. S. Ng\"},{\"authorId\":\"144154444\",\"name\":\"Marcus Hutter\"},{\"authorId\":\"1742809\",\"name\":\"William T. B. Uther\"},{\"authorId\":\"145824029\",\"name\":\"D. Silver\"}],\"doi\":\"10.1613/jair.3125\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"05f3b6736efa61909d871f8fe77bf2cea05e6917\",\"title\":\"A Monte-Carlo AIXI Approximation\",\"url\":\"https://www.semanticscholar.org/paper/05f3b6736efa61909d871f8fe77bf2cea05e6917\",\"venue\":\"J. Artif. Intell. Res.\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1406347404\",\"name\":\"Dr. Marcus Hutter\"}],\"doi\":\"10.1007/b138233\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"30a64bdf778b8f561af9ae589e822c2c800920b1\",\"title\":\"Universal Artificial Intelligence\",\"url\":\"https://www.semanticscholar.org/paper/30a64bdf778b8f561af9ae589e822c2c800920b1\",\"venue\":\"Texts in Theoretical Computer Science An EATCS Series\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5886094\",\"name\":\"P. Cochat\"},{\"authorId\":\"13267685\",\"name\":\"L. Vaucoret\"},{\"authorId\":\"31455512\",\"name\":\"J. Sarles\"}],\"doi\":\"10.1016/j.arcped.2012.01.013\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10d85561e4aafc516d10064f30dff05b41f70afe\",\"title\":\"[Et al].\",\"url\":\"https://www.semanticscholar.org/paper/10d85561e4aafc516d10064f30dff05b41f70afe\",\"venue\":\"Archives de pediatrie : organe officiel de la Societe francaise de pediatrie\",\"year\":2012},{\"arxivId\":\"1312.5602\",\"authors\":[{\"authorId\":\"3255983\",\"name\":\"V. Mnih\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"},{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"2460849\",\"name\":\"Ioannis Antonoglou\"},{\"authorId\":\"1688276\",\"name\":\"Daan Wierstra\"},{\"authorId\":\"3137672\",\"name\":\"Martin A. Riedmiller\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2319a491378867c7049b3da055c5df60e1671158\",\"title\":\"Playing Atari with Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/2319a491378867c7049b3da055c5df60e1671158\",\"venue\":\"ArXiv\",\"year\":2013},{\"arxivId\":\"1507.04124\",\"authors\":[{\"authorId\":\"2990741\",\"name\":\"J. Leike\"},{\"authorId\":\"144154444\",\"name\":\"Marcus Hutter\"}],\"doi\":\"10.1007/978-3-319-24486-0_24\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cb7b7fc7a23d6935ccd7b8f1af50fbfae14fef8b\",\"title\":\"On the Computability of Solomonoff Induction and Knowledge-Seeking\",\"url\":\"https://www.semanticscholar.org/paper/cb7b7fc7a23d6935ccd7b8f1af50fbfae14fef8b\",\"venue\":\"ALT\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1727567\",\"name\":\"R. Solomonoff\"}],\"doi\":\"10.1109/TIT.1978.1055913\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0453028e68581624ec68cfec70214231da8dbce7\",\"title\":\"Complexity-based induction systems: Comparisons and convergence theorems\",\"url\":\"https://www.semanticscholar.org/paper/0453028e68581624ec68cfec70214231da8dbce7\",\"venue\":\"IEEE Trans. Inf. Theory\",\"year\":1978},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jarryd Martin\"},{\"authorId\":null,\"name\":\"S SurajNarayanan\"},{\"authorId\":null,\"name\":\"Tom Everitt\"},{\"authorId\":null,\"name\":\"Marcus Hutter. Count-based exploration in feature space f Intelligence\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"IJCAI\\u201917\",\"url\":\"\",\"venue\":\"AAAI Press,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144886843\",\"name\":\"Richard Lathe\"}],\"doi\":\"10.1038/332676B0\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6ec27fba80de3b9c52ef6ac4eaa9f59821aefb4b\",\"title\":\"Phd by thesis\",\"url\":\"https://www.semanticscholar.org/paper/6ec27fba80de3b9c52ef6ac4eaa9f59821aefb4b\",\"venue\":\"Nature\",\"year\":1988}],\"title\":\"Universal Reinforcement Learning Algorithms: Survey and Experiments\",\"topics\":[{\"topic\":\"Reinforcement learning\",\"topicId\":\"2557\",\"url\":\"https://www.semanticscholar.org/topic/2557\"},{\"topic\":\"Algorithm\",\"topicId\":\"305\",\"url\":\"https://www.semanticscholar.org/topic/305\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Markov decision process\",\"topicId\":\"2556\",\"url\":\"https://www.semanticscholar.org/topic/2556\"},{\"topic\":\"AP Computer Science A\",\"topicId\":\"1293197\",\"url\":\"https://www.semanticscholar.org/topic/1293197\"},{\"topic\":\"Open-source software\",\"topicId\":\"8878\",\"url\":\"https://www.semanticscholar.org/topic/8878\"},{\"topic\":\"Reference implementation\",\"topicId\":\"159764\",\"url\":\"https://www.semanticscholar.org/topic/159764\"},{\"topic\":\"Ergodicity\",\"topicId\":\"578\",\"url\":\"https://www.semanticscholar.org/topic/578\"},{\"topic\":\"AIXI\",\"topicId\":\"956194\",\"url\":\"https://www.semanticscholar.org/topic/956194\"},{\"topic\":\"Approximation\",\"topicId\":\"3247\",\"url\":\"https://www.semanticscholar.org/topic/3247\"},{\"topic\":\"Observable\",\"topicId\":\"479\",\"url\":\"https://www.semanticscholar.org/topic/479\"},{\"topic\":\"Markov chain\",\"topicId\":\"5418\",\"url\":\"https://www.semanticscholar.org/topic/5418\"},{\"topic\":\"Bayesian network\",\"topicId\":\"14005\",\"url\":\"https://www.semanticscholar.org/topic/14005\"}],\"url\":\"https://www.semanticscholar.org/paper/d1627e5dd7c6656aa8c16d861677ac631c5c4301\",\"venue\":\"IJCAI\",\"year\":2017}\n"