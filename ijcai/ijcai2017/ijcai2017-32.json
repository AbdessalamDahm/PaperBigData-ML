"{\"abstract\":\"It is clear that one of the primary tools we can use to mitigate the potential risk from a misbehaving AI system is the ability to turn the system off. As the capabilities of AI systems improve, it is important to ensure that such systems do not adopt subgoals that prevent a human from switching them off. This is a challenge because many formulations of rational agents create strong incentives for self-preservation. This is not caused by a built-in instinct, but because a rational agent will maximize expected utility and cannot achieve whatever objective it has been given if it is dead. Our goal is to study the incentives an agent has to allow itself to be switched off. We analyze a simple game between a human H and a robot R, where H can press R's off switch but R can disable the off switch. A traditional agent takes its reward function for granted: we show that such agents have an incentive to disable the off switch, except in the special case where H is perfectly rational. Our key insight is that for R to want to preserve its off switch, it needs to be uncertain about the utility associated with the outcome, and to treat H's actions as important observations about that utility. (R also has no incentive to switch itself off in this setting.) We conclude that giving machines an appropriate level of uncertainty about their objectives leads to safer designs, and we argue that this setting is a useful generalization of the classical AI paradigm of rational agents.\",\"arxivId\":\"1611.08219\",\"authors\":[{\"authorId\":\"1397904824\",\"name\":\"Dylan Hadfield-Menell\",\"url\":\"https://www.semanticscholar.org/author/1397904824\"},{\"authorId\":\"2745001\",\"name\":\"Anca D. Dragan\",\"url\":\"https://www.semanticscholar.org/author/2745001\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\",\"url\":\"https://www.semanticscholar.org/author/1689992\"},{\"authorId\":\"145107462\",\"name\":\"S. Russell\",\"url\":\"https://www.semanticscholar.org/author/145107462\"}],\"citationVelocity\":13,\"citations\":[{\"arxivId\":\"1705.09990\",\"authors\":[{\"authorId\":\"3458938\",\"name\":\"Smitha Milli\"},{\"authorId\":\"1397904824\",\"name\":\"Dylan Hadfield-Menell\"},{\"authorId\":\"2745001\",\"name\":\"Anca D. Dragan\"},{\"authorId\":\"145107462\",\"name\":\"S. Russell\"}],\"doi\":\"10.24963/ijcai.2017/662\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0f9e4431e844cece73223f521e6d8e4a812b0ef1\",\"title\":\"Should Robots be Obedient?\",\"url\":\"https://www.semanticscholar.org/paper/0f9e4431e844cece73223f521e6d8e4a812b0ef1\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":\"1906.06436\",\"authors\":[{\"authorId\":\"40959392\",\"name\":\"Maayan Shvo\"},{\"authorId\":\"1683896\",\"name\":\"Sheila A. McIlraith\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"56373ceeab7a580853a10d67f84b9aff5abc6a7d\",\"title\":\"Towards Empathetic Planning\",\"url\":\"https://www.semanticscholar.org/paper/56373ceeab7a580853a10d67f84b9aff5abc6a7d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1705.04226\",\"authors\":[{\"authorId\":\"2745001\",\"name\":\"Anca D. Dragan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6884e8a0eaa93acc673e5d3ee09535b62a9b5919\",\"title\":\"Robot Planning with Mathematical Models of Human State and Action\",\"url\":\"https://www.semanticscholar.org/paper/6884e8a0eaa93acc673e5d3ee09535b62a9b5919\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1811.07871\",\"authors\":[{\"authorId\":\"2990741\",\"name\":\"J. Leike\"},{\"authorId\":\"145055042\",\"name\":\"David Krueger\"},{\"authorId\":\"1868196\",\"name\":\"Tom Everitt\"},{\"authorId\":\"26890260\",\"name\":\"Miljan Martic\"},{\"authorId\":\"51965508\",\"name\":\"Vishal Maini\"},{\"authorId\":\"34313265\",\"name\":\"S. Legg\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c6f913e4baa7f2c85363c0625c87003ad3b3a14c\",\"title\":\"Scalable agent alignment via reward modeling: a research direction\",\"url\":\"https://www.semanticscholar.org/paper/c6f913e4baa7f2c85363c0625c87003ad3b3a14c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2757194\",\"name\":\"Mark O. Riedl\"},{\"authorId\":\"35066258\",\"name\":\"B. Harrison\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"789dc83eaf50f5a6c3e52a07e65bd0b3f25d1e48\",\"title\":\"Enter the Matrix: Safely Interruptible Autonomous Systems via Virtualization\",\"url\":\"https://www.semanticscholar.org/paper/789dc83eaf50f5a6c3e52a07e65bd0b3f25d1e48\",\"venue\":\"SafeAI@AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34024409\",\"name\":\"M. Peterson\"}],\"doi\":\"10.1007/s10676-018-9486-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"08e351dde62e327275a2d31dc39547a0db90b2fe\",\"title\":\"The value alignment problem: a geometric approach\",\"url\":\"https://www.semanticscholar.org/paper/08e351dde62e327275a2d31dc39547a0db90b2fe\",\"venue\":\"Ethics and Information Technology\",\"year\":2018},{\"arxivId\":\"1809.01036\",\"authors\":[{\"authorId\":\"3438462\",\"name\":\"L. Hoang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0af287ea1b6c9810246bf505404bb4e0884b6cac\",\"title\":\"A Roadmap for Robust End-to-End Alignment\",\"url\":\"https://www.semanticscholar.org/paper/0af287ea1b6c9810246bf505404bb4e0884b6cac\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1471830089\",\"name\":\"Roel Dobbe\"},{\"authorId\":\"1491245294\",\"name\":\"Patricia Hidalgo-Gonzalez\"},{\"authorId\":\"3450289\",\"name\":\"Stavros Karagiannopoulos\"},{\"authorId\":\"2003510098\",\"name\":\"Rodrigo Henriquez-Auba\"},{\"authorId\":\"2809050\",\"name\":\"G. Hug\"},{\"authorId\":\"1711333\",\"name\":\"D. Callaway\"},{\"authorId\":\"49662423\",\"name\":\"C. Tomlin\"}],\"doi\":\"10.1016/j.epsr.2020.106615\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c70580ee9d59df84b5e19a8ac837b62231c3808\",\"title\":\"Learning to control in power systems: Design and analysis guidelines for concrete safety problems\",\"url\":\"https://www.semanticscholar.org/paper/1c70580ee9d59df84b5e19a8ac837b62231c3808\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40552391\",\"name\":\"Sailik Sengupta\"},{\"authorId\":\"47098951\",\"name\":\"Zahra Zahedi\"},{\"authorId\":\"1740315\",\"name\":\"S. Kambhampati\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"12501ea6c62f14276fd7ce76804e276b09fbf567\",\"title\":\"To Monitor or to Trust: Observing Robot's Behavior based on a Game-Theoretic Model of Trust\",\"url\":\"https://www.semanticscholar.org/paper/12501ea6c62f14276fd7ce76804e276b09fbf567\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1708.03871\",\"authors\":[{\"authorId\":\"22708544\",\"name\":\"Tobias W\\u00e4ngberg\"},{\"authorId\":\"22708729\",\"name\":\"Mikael B\\u00f6\\u00f6rs\"},{\"authorId\":\"22574075\",\"name\":\"Elliot Catt\"},{\"authorId\":\"1868196\",\"name\":\"Tom Everitt\"},{\"authorId\":\"144154444\",\"name\":\"Marcus Hutter\"}],\"doi\":\"10.1007/978-3-319-63703-7_16\",\"intent\":[\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"002050388cdb39d6413ce48230496e8ccc08df04\",\"title\":\"A Game-Theoretic Analysis of the Off-Switch Game\",\"url\":\"https://www.semanticscholar.org/paper/002050388cdb39d6413ce48230496e8ccc08df04\",\"venue\":\"AGI\",\"year\":2017},{\"arxivId\":\"1903.00111\",\"authors\":[{\"authorId\":\"40552391\",\"name\":\"Sailik Sengupta\"},{\"authorId\":\"47098951\",\"name\":\"Zahra Zahedi\"},{\"authorId\":\"1740315\",\"name\":\"Subbarao Kambhampati\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ab2e448d48c79579595482cf1e98283f5792080c\",\"title\":\"To Monitor Or Not: Observing Robot's Behavior based on a Game-Theoretic Model of Trust\",\"url\":\"https://www.semanticscholar.org/paper/ab2e448d48c79579595482cf1e98283f5792080c\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1804.04268\",\"authors\":[{\"authorId\":\"1397904824\",\"name\":\"Dylan Hadfield-Menell\"},{\"authorId\":\"40051700\",\"name\":\"Gillian K. Hadfield\"}],\"doi\":\"10.1145/3306618.3314250\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3be6455d00ff4a69e023b7b5c5d4367decb652c0\",\"title\":\"Incomplete Contracting and AI Alignment\",\"url\":\"https://www.semanticscholar.org/paper/3be6455d00ff4a69e023b7b5c5d4367decb652c0\",\"venue\":\"AIES\",\"year\":2019},{\"arxivId\":\"1711.02827\",\"authors\":[{\"authorId\":\"1397904824\",\"name\":\"Dylan Hadfield-Menell\"},{\"authorId\":\"3458938\",\"name\":\"Smitha Milli\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"},{\"authorId\":\"145107462\",\"name\":\"S. Russell\"},{\"authorId\":\"2745001\",\"name\":\"Anca D. Dragan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"59094d64844ee21e32560fb08db6d53cc3af0c51\",\"title\":\"Inverse Reward Design\",\"url\":\"https://www.semanticscholar.org/paper/59094d64844ee21e32560fb08db6d53cc3af0c51\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1902.09725\",\"authors\":[{\"authorId\":\"49277224\",\"name\":\"A. Turner\"},{\"authorId\":\"1397904824\",\"name\":\"Dylan Hadfield-Menell\"},{\"authorId\":\"1729906\",\"name\":\"P. Tadepalli\"}],\"doi\":\"10.1145/3375627.3375851\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9ed0b6aa983df3d6f458a6cb0ef53cb89157c4eb\",\"title\":\"Conservative Agency via Attainable Utility Preservation\",\"url\":\"https://www.semanticscholar.org/paper/9ed0b6aa983df3d6f458a6cb0ef53cb89157c4eb\",\"venue\":\"AIES\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1397904824\",\"name\":\"Dylan Hadfield-Menell\"},{\"authorId\":\"1741211830\",\"name\":\"Gillian K. Hadfield\"}],\"doi\":\"10.2139/ssrn.3165793\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cda6efd2119f1d2e94d185d735b354d00d6e5041\",\"title\":\"Incomplete Contracting and AI Alignment\",\"url\":\"https://www.semanticscholar.org/paper/cda6efd2119f1d2e94d185d735b354d00d6e5041\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3474598\",\"name\":\"Dagmar Monett\"},{\"authorId\":\"153558545\",\"name\":\"Colin W. P. Lewis\"},{\"authorId\":\"1727838\",\"name\":\"K. Th\\u00f3risson\"},{\"authorId\":\"145606164\",\"name\":\"J. Bach\"},{\"authorId\":\"144716847\",\"name\":\"G. Baldassarre\"},{\"authorId\":\"102847151\",\"name\":\"G. Granato\"},{\"authorId\":\"3346759\",\"name\":\"Istvan S. N. Berkeley\"},{\"authorId\":\"1565641737\",\"name\":\"Fran\\u00e7ois Chollet\"},{\"authorId\":\"143966629\",\"name\":\"M. Crosby\"},{\"authorId\":\"66652934\",\"name\":\"Henry Shevlin\"},{\"authorId\":\"145152293\",\"name\":\"J. Fox\"},{\"authorId\":\"1715438\",\"name\":\"J. Laird\"},{\"authorId\":\"34313265\",\"name\":\"S. Legg\"},{\"authorId\":\"2780534\",\"name\":\"Peter Lindes\"},{\"authorId\":null,\"name\":\"Tom\\u00e1\\u0161 Mikolov\"},{\"authorId\":\"1712022\",\"name\":\"W. J. Rapaport\"},{\"authorId\":\"144870565\",\"name\":\"R. Rojas\"},{\"authorId\":\"144799640\",\"name\":\"Marek Rosa\"},{\"authorId\":\"144848112\",\"name\":\"P. Stone\"},{\"authorId\":\"1699645\",\"name\":\"R. Sutton\"},{\"authorId\":\"1976753\",\"name\":\"Roman V Yampolskiy\"},{\"authorId\":\"143703524\",\"name\":\"P. Wang\"},{\"authorId\":\"2403310\",\"name\":\"R. Schank\"},{\"authorId\":\"145788442\",\"name\":\"A. Sloman\"},{\"authorId\":\"144001613\",\"name\":\"A. Winfield\"}],\"doi\":\"10.2478/jagi-2020-0003\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2d47b43fbd956ca6f15a0fbf1267e9ef74ca63a6\",\"title\":\"Special Issue \\u201cOn Defining Artificial Intelligence\\u201d\\u2014Commentaries and Author\\u2019s Response\",\"url\":\"https://www.semanticscholar.org/paper/2d47b43fbd956ca6f15a0fbf1267e9ef74ca63a6\",\"venue\":\"J. Artif. Gen. Intell.\",\"year\":2020},{\"arxivId\":\"1711.03846\",\"authors\":[{\"authorId\":\"2426676\",\"name\":\"Brett W. Israelsen\"},{\"authorId\":\"143898375\",\"name\":\"N. Ahmed\"}],\"doi\":\"10.1145/3267338\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"12d4522b3f24a8a5c69f8a38f2c632d240cbda10\",\"title\":\"\\u201cDave...I can assure you ...that it\\u2019s going to be all right ...\\u201d A Definition, Case for, and Survey of Algorithmic Assurances in Human-Autonomy Trust Relationships\",\"url\":\"https://www.semanticscholar.org/paper/12d4522b3f24a8a5c69f8a38f2c632d240cbda10\",\"venue\":\"ACM Comput. Surv.\",\"year\":2019},{\"arxivId\":\"1711.04309\",\"authors\":[{\"authorId\":\"40201835\",\"name\":\"J. Gans\"}],\"doi\":\"10.3386/w24352\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b14d69f5241be9ddadf19db92bc8d599fef51a94\",\"title\":\"Self-Regulating Artificial General Intelligence\",\"url\":\"https://www.semanticscholar.org/paper/b14d69f5241be9ddadf19db92bc8d599fef51a94\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144971476\",\"name\":\"M. Walton\"},{\"authorId\":\"3407517\",\"name\":\"Benjamin Migliori\"},{\"authorId\":\"144698199\",\"name\":\"John Reeder\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dfa70ec9bf1c0f2cc0d3d08ac0edb403f7d78147\",\"title\":\"Embodiment Adaptation from Interactive Trajectory Preferences\",\"url\":\"https://www.semanticscholar.org/paper/dfa70ec9bf1c0f2cc0d3d08ac0edb403f7d78147\",\"venue\":\"IAL@PKDD/ECML\",\"year\":2018},{\"arxivId\":\"2011.05373\",\"authors\":[{\"authorId\":\"40566201\",\"name\":\"Bowen Baker\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0b5c6e8c95b52e30bd2789e5d24fd579066904a9\",\"title\":\"Emergent Reciprocity and Team Formation from Randomized Uncertain Social Preferences\",\"url\":\"https://www.semanticscholar.org/paper/0b5c6e8c95b52e30bd2789e5d24fd579066904a9\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2006.13208\",\"authors\":[{\"authorId\":\"3489195\",\"name\":\"Andreea Bobu\"},{\"authorId\":\"1396718714\",\"name\":\"Marius Wiggert\"},{\"authorId\":\"1693894\",\"name\":\"C. Tomlin\"},{\"authorId\":\"2745001\",\"name\":\"Anca D. Dragan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1a87386014b2885b2097cc9b693a0e74b0213a0e\",\"title\":\"Feature Expansive Reward Learning: Rethinking Human Input\",\"url\":\"https://www.semanticscholar.org/paper/1a87386014b2885b2097cc9b693a0e74b0213a0e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.04833\",\"authors\":[{\"authorId\":\"33456733\",\"name\":\"Hong Jun Jeon\"},{\"authorId\":\"3458938\",\"name\":\"Smitha Milli\"},{\"authorId\":\"2745001\",\"name\":\"Anca D. Dragan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5c8ecd1f7082cad5cdd83ed1ec8e377d10d76cc9\",\"title\":\"Reward-rational (implicit) choice: A unifying formalism for reward learning\",\"url\":\"https://www.semanticscholar.org/paper/5c8ecd1f7082cad5cdd83ed1ec8e377d10d76cc9\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"1912.01683\",\"authors\":[{\"authorId\":\"49277224\",\"name\":\"A. Turner\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"09fca334fb5131c622fadd0d1309fc36c10b7c5b\",\"title\":\"Optimal Farsighted Agents Tend to Seek Power\",\"url\":\"https://www.semanticscholar.org/paper/09fca334fb5131c622fadd0d1309fc36c10b7c5b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2010.05418\",\"authors\":[{\"authorId\":\"1693739916\",\"name\":\"Stephen Casper\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3fe4c9c2ad21d76534f429563d855f4cd7490f83\",\"title\":\"The Achilles Heel Hypothesis: Pitfalls for AI Systems via Decision Theoretic Adversaries\",\"url\":\"https://www.semanticscholar.org/paper/3fe4c9c2ad21d76534f429563d855f4cd7490f83\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145305731\",\"name\":\"Siddharth Srivastava\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"967cba5849f93869655af8d3d8fda9b0a3304a1d\",\"title\":\"Unifying Principles and Metrics for Safe and Assistive AI\",\"url\":\"https://www.semanticscholar.org/paper/967cba5849f93869655af8d3d8fda9b0a3304a1d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"147279306\",\"name\":\"Lambade Nilesh Arun\"},{\"authorId\":\"147330440\",\"name\":\"Lavhale Vaishnavi Laxman\"},{\"authorId\":\"148422093\",\"name\":\"Zarkar Amit Anand\"},{\"authorId\":\"147173215\",\"name\":\"Jachak Mayuri Vilas\"},{\"authorId\":\"134779672\",\"name\":\"T. S Bhoye\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0f05859a34a631607b32c41a55dde38ef66df9cc\",\"title\":\"Towards Ubiquitous Computing Technology\",\"url\":\"https://www.semanticscholar.org/paper/0f05859a34a631607b32c41a55dde38ef66df9cc\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1711.09883\",\"authors\":[{\"authorId\":\"2990741\",\"name\":\"J. Leike\"},{\"authorId\":\"26890260\",\"name\":\"Miljan Martic\"},{\"authorId\":\"2578985\",\"name\":\"Victoria Krakovna\"},{\"authorId\":\"145981974\",\"name\":\"Pedro A. Ortega\"},{\"authorId\":\"1868196\",\"name\":\"Tom Everitt\"},{\"authorId\":\"8455031\",\"name\":\"Andrew Lefrancq\"},{\"authorId\":\"1749270\",\"name\":\"Laurent Orseau\"},{\"authorId\":\"34313265\",\"name\":\"S. Legg\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d09bec5af4eef5038e48b26b6c14098f95997114\",\"title\":\"AI Safety Gridworlds\",\"url\":\"https://www.semanticscholar.org/paper/d09bec5af4eef5038e48b26b6c14098f95997114\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33879438\",\"name\":\"M. Peeters\"},{\"authorId\":\"1754414\",\"name\":\"J. Diggelen\"},{\"authorId\":\"1747540\",\"name\":\"K. Bosch\"},{\"authorId\":\"91833364\",\"name\":\"A. Bronkhorst\"},{\"authorId\":\"52519849\",\"name\":\"M. A. Neerincx\"},{\"authorId\":\"70040400\",\"name\":\"J. M. Schraagen\"},{\"authorId\":\"1756368950\",\"name\":\"Stephan Raaijmakers\"}],\"doi\":\"10.1007/s00146-020-01005-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a9f5e549984d0b581e99ef8d34db6438e98db039\",\"title\":\"Hybrid collective intelligence in a human\\u2013AI society\",\"url\":\"https://www.semanticscholar.org/paper/a9f5e549984d0b581e99ef8d34db6438e98db039\",\"venue\":\"AI & SOCIETY\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1381906625\",\"name\":\"Sergey Levine\"},{\"authorId\":\"2745001\",\"name\":\"Anca D. Dragan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"014ec1ecfb9c26549b5398cfd07fbff477e12243\",\"title\":\"An Empirical Exploration of AI Safety\",\"url\":\"https://www.semanticscholar.org/paper/014ec1ecfb9c26549b5398cfd07fbff477e12243\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1399353961\",\"name\":\"G. D'Acquisto\"}],\"doi\":\"10.1007/s00146-019-00927-6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a4bb898025434f402b3930a4fabe625eb22af75d\",\"title\":\"On conflicts between ethical and logical principles in artificial intelligence\",\"url\":\"https://www.semanticscholar.org/paper/a4bb898025434f402b3930a4fabe625eb22af75d\",\"venue\":\"AI & SOCIETY\",\"year\":2020},{\"arxivId\":\"1902.09980\",\"authors\":[{\"authorId\":\"1868196\",\"name\":\"Tom Everitt\"},{\"authorId\":\"145981974\",\"name\":\"Pedro A. Ortega\"},{\"authorId\":\"145638362\",\"name\":\"E. Barnes\"},{\"authorId\":\"34313265\",\"name\":\"S. Legg\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c63ffb172fdacdddf5c8f84d4a1db00fb014bfbb\",\"title\":\"Understanding Agent Incentives using Causal Influence Diagrams. Part I: Single Action Settings\",\"url\":\"https://www.semanticscholar.org/paper/c63ffb172fdacdddf5c8f84d4a1db00fb014bfbb\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2011.08820\",\"authors\":[{\"authorId\":\"38912219\",\"name\":\"R. Kumar\"},{\"authorId\":\"9960452\",\"name\":\"Jonathan Uesato\"},{\"authorId\":\"33613300\",\"name\":\"R. Ngo\"},{\"authorId\":\"1868196\",\"name\":\"Tom Everitt\"},{\"authorId\":\"2578985\",\"name\":\"Victoria Krakovna\"},{\"authorId\":\"34313265\",\"name\":\"S. Legg\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c309158b64f8b05e74c8e208b22f8f160c1501d9\",\"title\":\"REALab: An Embedded Perspective on Tampering\",\"url\":\"https://www.semanticscholar.org/paper/c309158b64f8b05e74c8e208b22f8f160c1501d9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f6bc1db7073d3fa9ab33b83c27867b10a62033c1\",\"title\":\"Robot Action for and around People\",\"url\":\"https://www.semanticscholar.org/paper/f6bc1db7073d3fa9ab33b83c27867b10a62033c1\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1912.01683\",\"authors\":[{\"authorId\":\"49277224\",\"name\":\"A. Turner\"},{\"authorId\":\"145397964\",\"name\":\"L. Smith\"},{\"authorId\":\"40947489\",\"name\":\"Rohin Shah\"},{\"authorId\":\"2651789\",\"name\":\"Andrew Critch\"},{\"authorId\":\"1729906\",\"name\":\"P. Tadepalli\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f98390f3927cfcdfdeef069e92db0292d651e102\",\"title\":\"Optimal Policies Tend to Seek Power.\",\"url\":\"https://www.semanticscholar.org/paper/f98390f3927cfcdfdeef069e92db0292d651e102\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1807.06333\",\"authors\":[{\"authorId\":\"1719219\",\"name\":\"Giuseppe De Giacomo\"},{\"authorId\":\"1712013\",\"name\":\"L. Iocchi\"},{\"authorId\":\"51113841\",\"name\":\"Marco Favorito\"},{\"authorId\":\"1698994\",\"name\":\"F. Patrizi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1b6924a5ba6c6efa88ec432b49f2a931afc92871\",\"title\":\"Foundations for Restraining Bolts: Reinforcement Learning with LTLf/LDLf Restraining Specifications\",\"url\":\"https://www.semanticscholar.org/paper/1b6924a5ba6c6efa88ec432b49f2a931afc92871\",\"venue\":\"ICAPS\",\"year\":2019},{\"arxivId\":\"2006.04948\",\"authors\":[{\"authorId\":\"2651789\",\"name\":\"Andrew Critch\"},{\"authorId\":\"34936272\",\"name\":\"D. Krueger\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"a9c46dfd9a24c754a67386e02424ad68b1f4ab3b\",\"title\":\"AI Research Considerations for Human Existential Safety (ARCHES)\",\"url\":\"https://www.semanticscholar.org/paper/a9c46dfd9a24c754a67386e02424ad68b1f4ab3b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1749906\",\"name\":\"Vincent Conitzer\"}],\"doi\":\"10.1609/aaai.v33i01.33019755\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a548e31b0a4320e2bf52ec624ba95e1f01430f21\",\"title\":\"Designing Preferences, Beliefs, and Identities for Artificial Intelligence\",\"url\":\"https://www.semanticscholar.org/paper/a548e31b0a4320e2bf52ec624ba95e1f01430f21\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1903.06281\",\"authors\":[{\"authorId\":\"3043661\",\"name\":\"S. Croeser\"},{\"authorId\":\"2654106\",\"name\":\"P. Eckersley\"}],\"doi\":\"10.1145/3306618.3314231\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"176402737ba085569bb9e0a168ce20fa9b09b9b4\",\"title\":\"Theories of Parenting and Their Application to Artificial Intelligence\",\"url\":\"https://www.semanticscholar.org/paper/176402737ba085569bb9e0a168ce20fa9b09b9b4\",\"venue\":\"AIES\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3438462\",\"name\":\"L. Hoang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"88f2d3d81c167afb87cd053adbac337604fc26b7\",\"title\":\"Towards Robust End-to-End Alignment\",\"url\":\"https://www.semanticscholar.org/paper/88f2d3d81c167afb87cd053adbac337604fc26b7\",\"venue\":\"SafeAI@AAAI\",\"year\":2019},{\"arxivId\":\"1709.06275\",\"authors\":[{\"authorId\":\"8383113\",\"name\":\"R. Carey\"}],\"doi\":\"10.1145/3278721.3278750\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7ba22bc1cc37336a2a4e769c9798c47c8cad0b11\",\"title\":\"Incorrigibility in the CIRL Framework\",\"url\":\"https://www.semanticscholar.org/paper/7ba22bc1cc37336a2a4e769c9798c47c8cad0b11\",\"venue\":\"AIES\",\"year\":2018},{\"arxivId\":\"2008.04071\",\"authors\":[{\"authorId\":\"1976753\",\"name\":\"Roman V Yampolskiy\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"236c00be7fe8e7452d9ad0ff16cb9a36a6bd783f\",\"title\":\"On Controllability of AI\",\"url\":\"https://www.semanticscholar.org/paper/236c00be7fe8e7452d9ad0ff16cb9a36a6bd783f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1805.11447\",\"authors\":[{\"authorId\":\"15506371\",\"name\":\"H. Aslund\"},{\"authorId\":\"9623412\",\"name\":\"El Mahdi El Mhamdi\"},{\"authorId\":\"1727558\",\"name\":\"R. Guerraoui\"},{\"authorId\":\"143980218\",\"name\":\"Alexandre Maurer\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"15fc8e93535962dfb2ce3d0adf4da83c7268c109\",\"title\":\"Virtuously Safe Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/15fc8e93535962dfb2ce3d0adf4da83c7268c109\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"88240975\",\"name\":\"B. Goertzel\"},{\"authorId\":\"35234816\",\"name\":\"A. Panov\"},{\"authorId\":\"145296409\",\"name\":\"A. Potapov\"},{\"authorId\":\"1976753\",\"name\":\"Roman V Yampolskiy\"},{\"authorId\":\"145960032\",\"name\":\"R. Goebel\"},{\"authorId\":\"144865865\",\"name\":\"Y. Tanaka\"}],\"doi\":\"10.1007/978-3-030-52152-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1de88fd6bdaac4afe6dd3b7ca80923e1dbff40e1\",\"title\":\"Artificial General Intelligence: 13th International Conference, AGI 2020, St. Petersburg, Russia, September 16\\u201319, 2020, Proceedings\",\"url\":\"https://www.semanticscholar.org/paper/1de88fd6bdaac4afe6dd3b7ca80923e1dbff40e1\",\"venue\":\"AGI\",\"year\":2020},{\"arxivId\":\"2007.05411\",\"authors\":[{\"authorId\":\"144775419\",\"name\":\"K. Holtman\"}],\"doi\":\"10.1007/978-3-030-52152-3_21\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2cd52d0843aff066538125770235d9d689ef4006\",\"title\":\"Towards AGI Agent Safety by Iteratively Improving the Utility Function\",\"url\":\"https://www.semanticscholar.org/paper/2cd52d0843aff066538125770235d9d689ef4006\",\"venue\":\"AGI\",\"year\":2020},{\"arxivId\":\"2008.01339\",\"authors\":[{\"authorId\":\"3320417\",\"name\":\"G. Lima\"},{\"authorId\":\"122552797\",\"name\":\"Changyeon Kim\"},{\"authorId\":\"83507666\",\"name\":\"S. Ryu\"},{\"authorId\":\"12263630\",\"name\":\"Chihyung Jeon\"},{\"authorId\":\"1775511\",\"name\":\"Meeyoung Cha\"}],\"doi\":\"10.1145/3415206\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"29b3eb1b8ff57cf1a98eba712c72f0668d395397\",\"title\":\"Collecting the Public Perception of AI and Robot Rights\",\"url\":\"https://www.semanticscholar.org/paper/29b3eb1b8ff57cf1a98eba712c72f0668d395397\",\"venue\":\"Proc. ACM Hum. Comput. Interact.\",\"year\":2020},{\"arxivId\":\"1705.08417\",\"authors\":[{\"authorId\":\"1868196\",\"name\":\"Tom Everitt\"},{\"authorId\":\"2578985\",\"name\":\"Victoria Krakovna\"},{\"authorId\":\"1749270\",\"name\":\"Laurent Orseau\"},{\"authorId\":\"34313265\",\"name\":\"S. Legg\"}],\"doi\":\"10.24963/ijcai.2017/656\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e5ba74bd3b6c9bb0287d8835621ddd40dd3ebbf4\",\"title\":\"Reinforcement Learning with a Corrupted Reward Channel\",\"url\":\"https://www.semanticscholar.org/paper/e5ba74bd3b6c9bb0287d8835621ddd40dd3ebbf4\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Nmative Uertainty\"},{\"authorId\":null,\"name\":\"Bunded Rionality\"},{\"authorId\":null,\"name\":\"Cosistent Dcision\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2b8a2f446c8c2962b9bf399c67272f024e101c5e\",\"title\":\"The Landscape of AI Safety and Beneficence Research: Input for Brainstorming at Beneficial AI 2017\\u2217\",\"url\":\"https://www.semanticscholar.org/paper/2b8a2f446c8c2962b9bf399c67272f024e101c5e\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"2006.04734\",\"authors\":[{\"authorId\":\"66821245\",\"name\":\"Adrien Ecoffet\"},{\"authorId\":\"145776458\",\"name\":\"J. Lehman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"97eb5288580fb16b40e929084cc57121715c759b\",\"title\":\"Reinforcement Learning Under Moral Uncertainty\",\"url\":\"https://www.semanticscholar.org/paper/97eb5288580fb16b40e929084cc57121715c759b\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":3730613,\"doi\":\"10.24963/ijcai.2017/32\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":3,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"808dec0828a74fecab07a497c10cd93e3748a5e2\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"143986522\",\"name\":\"R. Gibbons\"}],\"doi\":\"10.1257/JEP.12.4.115\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"467627fa9fa0291a663a0bd411648085d42c6976\",\"title\":\"Incentives in Organizations\",\"url\":\"https://www.semanticscholar.org/paper/467627fa9fa0291a663a0bd411648085d42c6976\",\"venue\":\"\",\"year\":1998},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144225182\",\"name\":\"D. Dewey\"}],\"doi\":\"10.1007/978-3-642-22887-2_35\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f5ca00ff8650d04f36b2e228226032b0a5c478df\",\"title\":\"Learning What to Value\",\"url\":\"https://www.semanticscholar.org/paper/f5ca00ff8650d04f36b2e228226032b0a5c478df\",\"venue\":\"AGI\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1749270\",\"name\":\"Laurent Orseau\"},{\"authorId\":\"144710847\",\"name\":\"S. Armstrong\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ac70bb2458f01a9e47fc1afe0dd478fb2feb8f50\",\"title\":\"Safely Interruptible Agents\",\"url\":\"https://www.semanticscholar.org/paper/ac70bb2458f01a9e47fc1afe0dd478fb2feb8f50\",\"venue\":\"UAI\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Alan Fern\"},{\"authorId\":null,\"name\":\"Sriraam Natarajan\"},{\"authorId\":null,\"name\":\"Kshitij Judah\"},{\"authorId\":null,\"name\":\"Prasad Tadepalli. A decision-theoretic model of assistance\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Journal of Artificial Intelligence Research\",\"url\":\"\",\"venue\":\"50(1):71\\u2013104,\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3056693\",\"name\":\"Jean Tirole\"}],\"doi\":\"10.1257/AER.99.1.265\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"345b4529793685f62d5261a4ba9226800e09d4ce\",\"title\":\"Cognition and Incomplete Contracts\",\"url\":\"https://www.semanticscholar.org/paper/345b4529793685f62d5261a4ba9226800e09d4ce\",\"venue\":\"\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"S. Russell\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Should we fear supersmart robots? Scientific American 314(June):58\\u201359\",\"url\":\"\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153919677\",\"name\":\"S. Russell\"}],\"doi\":\"10.1038/scientificamerican0616-58\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"64c7ba4096caaf3c577ff438f4313f0bc32a9588\",\"title\":\"Should We Fear Supersmart Robots?\",\"url\":\"https://www.semanticscholar.org/paper/64c7ba4096caaf3c577ff438f4313f0bc32a9588\",\"venue\":\"Scientific American\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145107462\",\"name\":\"S. Russell\"},{\"authorId\":\"2784519\",\"name\":\"Peter Norvig\"}],\"doi\":\"10.5860/choice.33-1577\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3524cdf7cf8344e7eb74886f71fcbb5c6732c337\",\"title\":\"Artificial Intelligence: A Modern Approach\",\"url\":\"https://www.semanticscholar.org/paper/3524cdf7cf8344e7eb74886f71fcbb5c6732c337\",\"venue\":\"\",\"year\":1995},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Guia Marie Del Prado\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Here\\u2019s what Facebook\\u2019s artificial intelligence expert thinks about the future\",\"url\":\"\",\"venue\":\"Tech Insider 9/23/15,\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"N Soares\"},{\"authorId\":null,\"name\":\"B Fallenstein\"},{\"authorId\":null,\"name\":\"S Armstrong\"},{\"authorId\":null,\"name\":\"E Yudkowsky\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Corrigibility. In Workshops at the Twenty-Ninth AAAI Conference on Artificial Intelligence\",\"url\":\"\",\"venue\":\"Corrigibility. In Workshops at the Twenty-Ninth AAAI Conference on Artificial Intelligence\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A M Turing\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Can digital machines think? Lecture broadcast on BBC Third Programme\",\"url\":\"\",\"venue\":\"Can digital machines think? Lecture broadcast on BBC Third Programme\",\"year\":1951},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145531003\",\"name\":\"S. Kerr\"}],\"doi\":\"10.5465/255378\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b3e13a58a1d90eff3156775c67c813e837f8f3cf\",\"title\":\"On the folly of rewarding A, while hoping for B.\",\"url\":\"https://www.semanticscholar.org/paper/b3e13a58a1d90eff3156775c67c813e837f8f3cf\",\"venue\":\"\",\"year\":1975},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Nate Soares\"},{\"authorId\":null,\"name\":\"Benja Fallenstein\"},{\"authorId\":null,\"name\":\"Stuart Armstrong\"},{\"authorId\":null,\"name\":\"Eliezer Yudkowsky\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Corrigibility\",\"url\":\"\",\"venue\":\"Workshops at the Twenty-Ninth AAAI Conference on Artificial Intelligence,\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"D. Hadfield-Menell\"},{\"authorId\":null,\"name\":\"A. D. Dragan\"},{\"authorId\":null,\"name\":\"P. Abbeel\"},{\"authorId\":null,\"name\":\"S. J. Russell\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"The off-switch game\",\"url\":\"\",\"venue\":\"CoRR abs/1611.08219.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. M. Turing\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Can digital machines think? Lecture broadcast on BBC Third Programme; typescript at turingarchive.org\",\"url\":\"\",\"venue\":\"\",\"year\":1951},{\"arxivId\":null,\"authors\":[{\"authorId\":\"81984514\",\"name\":\"F. A. Hayek\"}],\"doi\":\"10.1257/aer.103.3.i\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ed6ab981f8b8e3c51c4e866a6706b3e7aaa26b21\",\"title\":\"The American Economic Review\",\"url\":\"https://www.semanticscholar.org/paper/ed6ab981f8b8e3c51c4e866a6706b3e7aaa26b21\",\"venue\":\"\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"ITIF\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Are super intelligent computers really a threat to humanity? Debate at the Information Technology Innovation Foundation\",\"url\":\"\",\"venue\":\"6/30/15,\",\"year\":2015},{\"arxivId\":\"1606.03137\",\"authors\":[{\"authorId\":\"1397904824\",\"name\":\"Dylan Hadfield-Menell\"},{\"authorId\":\"145107462\",\"name\":\"S. Russell\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"},{\"authorId\":\"2745001\",\"name\":\"Anca D. Dragan\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"1e6abd43fcb157fde4d4ddc3ac8787ae45dbf777\",\"title\":\"Cooperative Inverse Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/1e6abd43fcb157fde4d4ddc3ac8787ae45dbf777\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Steven Kerr. On the folly of rewarding a\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"while hoping for b\",\"url\":\"\",\"venue\":\"Academy of Management Journal, 18(4):769\\u2013783,\",\"year\":1975},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145841336\",\"name\":\"A. Fern\"},{\"authorId\":\"145986014\",\"name\":\"Sriraam Natarajan\"},{\"authorId\":\"1719050\",\"name\":\"Kshitij Judah\"},{\"authorId\":\"1729906\",\"name\":\"P. Tadepalli\"}],\"doi\":\"10.1613/jair.4213\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c7cc33f1fdcd7fd3d72a3aceca793c3e35dd148b\",\"title\":\"A Decision-Theoretic Model of Assistance\",\"url\":\"https://www.semanticscholar.org/paper/c7cc33f1fdcd7fd3d72a3aceca793c3e35dd148b\",\"venue\":\"IJCAI\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"N. Soares\"},{\"authorId\":null,\"name\":\"B. Fallenstein\"},{\"authorId\":null,\"name\":\"S. Armstrong\"},{\"authorId\":null,\"name\":\"E. Yudkowsky\"}],\"doi\":null,\"intent\":[\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Corrigibility . In Workshops at the Twenty - Ninth AAAI Conference on Artificial Intelligence . Tirole , J . 2009 . Cognition and incomplete contracts\",\"url\":\"\",\"venue\":\"Scien - tific American\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Stuart Russell\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Should we fear supersmart robots? Scientific American\",\"url\":\"\",\"venue\":\"314(June):58\\u201359,\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Itif\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Are super intelligent computers really a threat to humanity? Debate at the Information Technology Innovation Foundation\",\"url\":\"\",\"venue\":\"Are super intelligent computers really a threat to humanity? Debate at the Information Technology Innovation Foundation\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"M Alan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Turing\",\"url\":\"\",\"venue\":\"Can digital machines think? Lecture broadcast on BBC Third Programme; typescript at turingarchive.org.,\",\"year\":1951},{\"arxivId\":null,\"authors\":[{\"authorId\":\"116961862\",\"name\":\"G. Baker\"}],\"doi\":\"10.2307/3069615\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f84e575772bc023ea7c8b598da48dcb317bca326\",\"title\":\"Distortion and Risk in Optimal Incentive Contracts\",\"url\":\"https://www.semanticscholar.org/paper/f84e575772bc023ea7c8b598da48dcb317bca326\",\"venue\":\"\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1808760\",\"name\":\"S. Omohundro\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"a6582abc47397d96888108ea308c0168d94a230d\",\"title\":\"The Basic AI Drives\",\"url\":\"https://www.semanticscholar.org/paper/a6582abc47397d96888108ea308c0168d94a230d\",\"venue\":\"AGI\",\"year\":2008}],\"title\":\"The Off-Switch Game\",\"topics\":[{\"topic\":\"Rational agent\",\"topicId\":\"459071\",\"url\":\"https://www.semanticscholar.org/topic/459071\"},{\"topic\":\"Expected utility hypothesis\",\"topicId\":\"18818\",\"url\":\"https://www.semanticscholar.org/topic/18818\"},{\"topic\":\"Reinforcement learning\",\"topicId\":\"2557\",\"url\":\"https://www.semanticscholar.org/topic/2557\"},{\"topic\":\"Programming paradigm\",\"topicId\":\"29522\",\"url\":\"https://www.semanticscholar.org/topic/29522\"},{\"topic\":\"Causality\",\"topicId\":\"1484\",\"url\":\"https://www.semanticscholar.org/topic/1484\"}],\"url\":\"https://www.semanticscholar.org/paper/808dec0828a74fecab07a497c10cd93e3748a5e2\",\"venue\":\"IJCAI\",\"year\":2017}\n"