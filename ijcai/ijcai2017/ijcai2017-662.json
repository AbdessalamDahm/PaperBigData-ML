"{\"abstract\":\"Intuitively, obedience -- following the order that a human gives -- seems like a good property for a robot to have. But, we humans are not perfect and we may give orders that are not best aligned to our preferences. We show that when a human is not perfectly rational then a robot that tries to infer and act according to the human's underlying preferences can always perform better than a robot that simply follows the human's literal order. Thus, there is a tradeoff between the obedience of a robot and the value it can attain for its owner. We investigate how this tradeoff is impacted by the way the robot infers the human's preferences, showing that some methods err more on the side of obedience than others. We then analyze how performance degrades when the robot has a misspecified model of the features that the human cares about or the level of rationality of the human. Finally, we study how robots can start detecting such model misspecification. Overall, our work suggests that there might be a middle ground in which robots intelligently decide when to obey human orders, but err on the side of obedience.\",\"arxivId\":\"1705.09990\",\"authors\":[{\"authorId\":\"3458938\",\"name\":\"Smitha Milli\",\"url\":\"https://www.semanticscholar.org/author/3458938\"},{\"authorId\":\"1397904824\",\"name\":\"Dylan Hadfield-Menell\",\"url\":\"https://www.semanticscholar.org/author/1397904824\"},{\"authorId\":\"2745001\",\"name\":\"Anca D. Dragan\",\"url\":\"https://www.semanticscholar.org/author/2745001\"},{\"authorId\":\"145107462\",\"name\":\"S. Russell\",\"url\":\"https://www.semanticscholar.org/author/145107462\"}],\"citationVelocity\":8,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"2757194\",\"name\":\"Mark O. Riedl\"},{\"authorId\":\"35066258\",\"name\":\"B. Harrison\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"789dc83eaf50f5a6c3e52a07e65bd0b3f25d1e48\",\"title\":\"Enter the Matrix: Safely Interruptible Autonomous Systems via Virtualization\",\"url\":\"https://www.semanticscholar.org/paper/789dc83eaf50f5a6c3e52a07e65bd0b3f25d1e48\",\"venue\":\"SafeAI@AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"147279306\",\"name\":\"Lambade Nilesh Arun\"},{\"authorId\":\"147330440\",\"name\":\"Lavhale Vaishnavi Laxman\"},{\"authorId\":\"148422093\",\"name\":\"Zarkar Amit Anand\"},{\"authorId\":\"147173215\",\"name\":\"Jachak Mayuri Vilas\"},{\"authorId\":\"134779672\",\"name\":\"T. S Bhoye\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0f05859a34a631607b32c41a55dde38ef66df9cc\",\"title\":\"Towards Ubiquitous Computing Technology\",\"url\":\"https://www.semanticscholar.org/paper/0f05859a34a631607b32c41a55dde38ef66df9cc\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2481388\",\"name\":\"S. Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2eedf12b51f713f639a28c2f8dd28dec20417526\",\"title\":\"OnQuerying for Safe Optimality in Factored Markov Decision Processes Extended Abstract\",\"url\":\"https://www.semanticscholar.org/paper/2eedf12b51f713f639a28c2f8dd28dec20417526\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1711.09883\",\"authors\":[{\"authorId\":\"2990741\",\"name\":\"J. Leike\"},{\"authorId\":\"26890260\",\"name\":\"Miljan Martic\"},{\"authorId\":\"2578985\",\"name\":\"Victoria Krakovna\"},{\"authorId\":\"145981974\",\"name\":\"Pedro A. Ortega\"},{\"authorId\":\"1868196\",\"name\":\"Tom Everitt\"},{\"authorId\":\"8455031\",\"name\":\"Andrew Lefrancq\"},{\"authorId\":\"1749270\",\"name\":\"Laurent Orseau\"},{\"authorId\":\"34313265\",\"name\":\"S. Legg\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d09bec5af4eef5038e48b26b6c14098f95997114\",\"title\":\"AI Safety Gridworlds\",\"url\":\"https://www.semanticscholar.org/paper/d09bec5af4eef5038e48b26b6c14098f95997114\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2500065\",\"name\":\"T. Chakraborti\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d0085e8470785e47cfa35085311d7cdd55080129\",\"title\":\"Foundations of Human-Aware Planning - A Tale of Three Models\",\"url\":\"https://www.semanticscholar.org/paper/d0085e8470785e47cfa35085311d7cdd55080129\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144710847\",\"name\":\"S. Armstrong\"},{\"authorId\":\"32777162\",\"name\":\"S. Mindermann\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"11ca969b9c4f02bda7ce42f1bdfa491be4beceb1\",\"title\":\"Impossibility of deducing preferences and rationality from human policy\",\"url\":\"https://www.semanticscholar.org/paper/11ca969b9c4f02bda7ce42f1bdfa491be4beceb1\",\"venue\":\"NIPS 2018\",\"year\":2017},{\"arxivId\":\"1912.01683\",\"authors\":[{\"authorId\":\"49277224\",\"name\":\"A. Turner\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"09fca334fb5131c622fadd0d1309fc36c10b7c5b\",\"title\":\"Optimal Farsighted Agents Tend to Seek Power\",\"url\":\"https://www.semanticscholar.org/paper/09fca334fb5131c622fadd0d1309fc36c10b7c5b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1729718\",\"name\":\"Shani Alkoby\"},{\"authorId\":\"51444860\",\"name\":\"Avilash Rath\"},{\"authorId\":\"144848112\",\"name\":\"P. Stone\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c60b1780877d49ab79e0b005b30655498e64b9b3\",\"title\":\"Ad hoc Teamwork and Moral Feedback as a Framework for Safe Agent Behavior\",\"url\":\"https://www.semanticscholar.org/paper/c60b1780877d49ab79e0b005b30655498e64b9b3\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2481388\",\"name\":\"S. Zhang\"},{\"authorId\":\"1726491\",\"name\":\"E. Durfee\"},{\"authorId\":\"1699868\",\"name\":\"Satinder Singh\"}],\"doi\":\"10.24963/ijcai.2018/676\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"de3c83b4e7b6ab907b050a1feb52e25f44ee41bd\",\"title\":\"Minimax-Regret Querying on Side Effects for Safe Optimality in Factored Markov Decision Processes\",\"url\":\"https://www.semanticscholar.org/paper/de3c83b4e7b6ab907b050a1feb52e25f44ee41bd\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":\"1912.01217\",\"authors\":[{\"authorId\":\"2374892\",\"name\":\"C. Wainwright\"},{\"authorId\":\"2654106\",\"name\":\"P. Eckersley\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"058897b987f563da332a48dfecf4dda0367c3d74\",\"title\":\"SafeLife 1.0: Exploring Side Effects in Complex Environments\",\"url\":\"https://www.semanticscholar.org/paper/058897b987f563da332a48dfecf4dda0367c3d74\",\"venue\":\"SafeAI@AAAI\",\"year\":2020},{\"arxivId\":\"1810.05157\",\"authors\":[{\"authorId\":\"3489195\",\"name\":\"Andreea Bobu\"},{\"authorId\":\"47370841\",\"name\":\"Andrea Bajcsy\"},{\"authorId\":\"1843342\",\"name\":\"Jaime F. Fisac\"},{\"authorId\":\"2745001\",\"name\":\"Anca D. Dragan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d53d39534b496d9a3466b1130ee3357b0d49fa5c\",\"title\":\"Learning under Misspecified Objective Spaces\",\"url\":\"https://www.semanticscholar.org/paper/d53d39534b496d9a3466b1130ee3357b0d49fa5c\",\"venue\":\"CoRL\",\"year\":2018},{\"arxivId\":\"1809.07880\",\"authors\":[{\"authorId\":\"1729718\",\"name\":\"Shani Alkoby\"},{\"authorId\":\"51444860\",\"name\":\"Avilash Rath\"},{\"authorId\":\"143756910\",\"name\":\"P. Stone\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b267b163c7f5ebb2a44be84e7c7b8bddfea09d52\",\"title\":\"Teaching Social Behavior through Human Reinforcement for Ad hoc Teamwork - The STAR Framework: Extended Abstract\",\"url\":\"https://www.semanticscholar.org/paper/b267b163c7f5ebb2a44be84e7c7b8bddfea09d52\",\"venue\":\"AAMAS\",\"year\":2019},{\"arxivId\":\"2002.09089\",\"authors\":[{\"authorId\":\"47627548\",\"name\":\"Daniel S. Brown\"},{\"authorId\":\"152299477\",\"name\":\"R. Coleman\"},{\"authorId\":\"143889798\",\"name\":\"R. Srinivasan\"},{\"authorId\":\"2791038\",\"name\":\"S. Niekum\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"766c17912953a1f1a7696edba3cb42db4fc518ea\",\"title\":\"Safe Imitation Learning via Fast Bayesian Reward Inference from Preferences\",\"url\":\"https://www.semanticscholar.org/paper/766c17912953a1f1a7696edba3cb42db4fc518ea\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34024409\",\"name\":\"M. Peterson\"}],\"doi\":\"10.1007/s10676-018-9486-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"08e351dde62e327275a2d31dc39547a0db90b2fe\",\"title\":\"The value alignment problem: a geometric approach\",\"url\":\"https://www.semanticscholar.org/paper/08e351dde62e327275a2d31dc39547a0db90b2fe\",\"venue\":\"Ethics and Information Technology\",\"year\":2018},{\"arxivId\":\"1805.01109\",\"authors\":[{\"authorId\":\"1868196\",\"name\":\"Tom Everitt\"},{\"authorId\":\"1954561\",\"name\":\"G. Lea\"},{\"authorId\":\"144154444\",\"name\":\"Marcus Hutter\"}],\"doi\":\"10.24963/ijcai.2018/768\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"6b0b1ecca32809b1d5b70b978521a8c27bc98e25\",\"title\":\"AGI Safety Literature Review\",\"url\":\"https://www.semanticscholar.org/paper/6b0b1ecca32809b1d5b70b978521a8c27bc98e25\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":\"1802.07740\",\"authors\":[{\"authorId\":\"3422052\",\"name\":\"Neil C. Rabinowitz\"},{\"authorId\":\"3054009\",\"name\":\"Frank Perbet\"},{\"authorId\":\"143745193\",\"name\":\"H. Song\"},{\"authorId\":\"40313479\",\"name\":\"C. Zhang\"},{\"authorId\":\"143648071\",\"name\":\"S. Eslami\"},{\"authorId\":\"46378362\",\"name\":\"M. Botvinick\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"856d5dcba4772328b8fb784494e3d41d39669b0d\",\"title\":\"Machine Theory of Mind\",\"url\":\"https://www.semanticscholar.org/paper/856d5dcba4772328b8fb784494e3d41d39669b0d\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":\"2006.04948\",\"authors\":[{\"authorId\":\"2651789\",\"name\":\"Andrew Critch\"},{\"authorId\":\"34936272\",\"name\":\"D. Krueger\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a9c46dfd9a24c754a67386e02424ad68b1f4ab3b\",\"title\":\"AI Research Considerations for Human Existential Safety (ARCHES)\",\"url\":\"https://www.semanticscholar.org/paper/a9c46dfd9a24c754a67386e02424ad68b1f4ab3b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1977663\",\"name\":\"Thomas Cederborg\"}],\"doi\":\"10.1515/pjbr-2017-0005\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"aa003788f330e9fafad102493a52ea7a606ba596\",\"title\":\"Artificial learners adopting normative conventions from human teachers\",\"url\":\"https://www.semanticscholar.org/paper/aa003788f330e9fafad102493a52ea7a606ba596\",\"venue\":\"Paladyn J. Behav. Robotics\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"15418993\",\"name\":\"Annika Boos\"},{\"authorId\":\"65929239\",\"name\":\"M. Sax\"},{\"authorId\":\"3672769\",\"name\":\"Jakob Reinhardt\"}],\"doi\":\"10.1007/978-3-030-50726-8_15\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"27bbd91253458ab2fbe0ec46f638ca9c8101584c\",\"title\":\"Investigating Perceived Task Urgency as Justification for Dominant Robot Behaviour\",\"url\":\"https://www.semanticscholar.org/paper/27bbd91253458ab2fbe0ec46f638ca9c8101584c\",\"venue\":\"HCI\",\"year\":2020},{\"arxivId\":\"1705.04226\",\"authors\":[{\"authorId\":\"2745001\",\"name\":\"Anca D. Dragan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6884e8a0eaa93acc673e5d3ee09535b62a9b5919\",\"title\":\"Robot Planning with Mathematical Models of Human State and Action\",\"url\":\"https://www.semanticscholar.org/paper/6884e8a0eaa93acc673e5d3ee09535b62a9b5919\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1868196\",\"name\":\"Tom Everitt\"}],\"doi\":\"10.25911/5D134A2F8A7D3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8b1e149ae23ea7839c9e3a2bd063c354ff7075d0\",\"title\":\"Towards Safe Artificial General Intelligence\",\"url\":\"https://www.semanticscholar.org/paper/8b1e149ae23ea7839c9e3a2bd063c354ff7075d0\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1811.07871\",\"authors\":[{\"authorId\":\"2990741\",\"name\":\"J. Leike\"},{\"authorId\":\"145055042\",\"name\":\"David Krueger\"},{\"authorId\":\"1868196\",\"name\":\"Tom Everitt\"},{\"authorId\":\"26890260\",\"name\":\"Miljan Martic\"},{\"authorId\":\"51965508\",\"name\":\"Vishal Maini\"},{\"authorId\":\"34313265\",\"name\":\"S. Legg\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c6f913e4baa7f2c85363c0625c87003ad3b3a14c\",\"title\":\"Scalable agent alignment via reward modeling: a research direction\",\"url\":\"https://www.semanticscholar.org/paper/c6f913e4baa7f2c85363c0625c87003ad3b3a14c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1912.01683\",\"authors\":[{\"authorId\":\"49277224\",\"name\":\"A. Turner\"},{\"authorId\":\"145397964\",\"name\":\"L. Smith\"},{\"authorId\":\"40947489\",\"name\":\"Rohin Shah\"},{\"authorId\":\"2651789\",\"name\":\"Andrew Critch\"},{\"authorId\":\"1729906\",\"name\":\"P. Tadepalli\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f98390f3927cfcdfdeef069e92db0292d651e102\",\"title\":\"Optimal Policies Tend to Seek Power.\",\"url\":\"https://www.semanticscholar.org/paper/f98390f3927cfcdfdeef069e92db0292d651e102\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1709.06275\",\"authors\":[{\"authorId\":\"8383113\",\"name\":\"R. Carey\"}],\"doi\":\"10.1145/3278721.3278750\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7ba22bc1cc37336a2a4e769c9798c47c8cad0b11\",\"title\":\"Incorrigibility in the CIRL Framework\",\"url\":\"https://www.semanticscholar.org/paper/7ba22bc1cc37336a2a4e769c9798c47c8cad0b11\",\"venue\":\"AIES\",\"year\":2018},{\"arxivId\":\"1910.02822\",\"authors\":[{\"authorId\":\"121135269\",\"name\":\"P. Wang\"},{\"authorId\":\"46583922\",\"name\":\"J. Wang\"},{\"authorId\":\"74861544\",\"name\":\"Pushpi Paranamana\"},{\"authorId\":\"3210220\",\"name\":\"Patrick Shafto\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5373922ad926d3baf58358db2008aefe085febd4\",\"title\":\"A mathematical theory of cooperative communication\",\"url\":\"https://www.semanticscholar.org/paper/5373922ad926d3baf58358db2008aefe085febd4\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4001835\",\"name\":\"S. Armstrong\"},{\"authorId\":null,\"name\":\"Xavier O\\u2019Rourke\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"894d59a88637411ee26cbfe729b592ad7c34a33f\",\"title\":\"J un 2 01 8 \\u2018 Indifference \\u2019 methods for managing agent rewards\",\"url\":\"https://www.semanticscholar.org/paper/894d59a88637411ee26cbfe729b592ad7c34a33f\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1712.06365\",\"authors\":[{\"authorId\":\"144710847\",\"name\":\"S. Armstrong\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0b9d73fb88209699a0a97097c013f4a3aa80f69b\",\"title\":\"'Indifference' methods for managing agent rewards\",\"url\":\"https://www.semanticscholar.org/paper/0b9d73fb88209699a0a97097c013f4a3aa80f69b\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1712.05812\",\"authors\":[{\"authorId\":\"144710847\",\"name\":\"S. Armstrong\"},{\"authorId\":\"32777162\",\"name\":\"S. Mindermann\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cdabff298e9467de9babf0baad04c19789cde44b\",\"title\":\"Occam's razor is insufficient to infer the preferences of irrational agents\",\"url\":\"https://www.semanticscholar.org/paper/cdabff298e9467de9babf0baad04c19789cde44b\",\"venue\":\"NeurIPS\",\"year\":2018}],\"corpusId\":24269996,\"doi\":\"10.24963/ijcai.2017/662\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":2,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"0f9e4431e844cece73223f521e6d8e4a812b0ef1\",\"references\":[{\"arxivId\":\"1611.08219\",\"authors\":[{\"authorId\":\"1397904824\",\"name\":\"Dylan Hadfield-Menell\"},{\"authorId\":\"2745001\",\"name\":\"Anca D. Dragan\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"},{\"authorId\":\"145107462\",\"name\":\"S. Russell\"}],\"doi\":\"10.24963/ijcai.2017/32\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"808dec0828a74fecab07a497c10cd93e3748a5e2\",\"title\":\"The Off-Switch Game\",\"url\":\"https://www.semanticscholar.org/paper/808dec0828a74fecab07a497c10cd93e3748a5e2\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Dylan Hadfield-Menell\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Coopera - tive Inverse Reinforcement Learning\",\"url\":\"\",\"venue\":\"Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1780531\",\"name\":\"Daniel S. Weld\"},{\"authorId\":\"1741101\",\"name\":\"Oren Etzioni\"}],\"doi\":\"10.1007/978-3-642-04879-1_7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4e1a8d5159eb47b959ccedde98eee84a1f3b8275\",\"title\":\"The First Law of Robotics (A Call to Arms)\",\"url\":\"https://www.semanticscholar.org/paper/4e1a8d5159eb47b959ccedde98eee84a1f3b8275\",\"venue\":\"AAAI\",\"year\":1994},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2193691\",\"name\":\"Nick Bostrom\"}],\"doi\":\"10.5860/choice.187536\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7bba95b3d145564025e26b49ca67f13f884f8560\",\"title\":\"Superintelligence: Paths, Dangers, Strategies\",\"url\":\"https://www.semanticscholar.org/paper/7bba95b3d145564025e26b49ca67f13f884f8560\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48719966\",\"name\":\"Persi Diaconis\"},{\"authorId\":\"32854168\",\"name\":\"D. Freedman\"}],\"doi\":\"10.1214/AOS/1176349830\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5c63ab340634a23b84a233f1a7725c4b5ddffe9c\",\"title\":\"On the consistency of Bayes estimates\",\"url\":\"https://www.semanticscholar.org/paper/5c63ab340634a23b84a233f1a7725c4b5ddffe9c\",\"venue\":\"\",\"year\":1986},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98302096\",\"name\":\"Peter Kulchyski\"}],\"doi\":\"10.1080/13688790.2015.1136585\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dfbfcd288ed9b37106564bf6dc95041f6d33b6b2\",\"title\":\"and\",\"url\":\"https://www.semanticscholar.org/paper/dfbfcd288ed9b37106564bf6dc95041f6d33b6b2\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"},{\"authorId\":\"34699434\",\"name\":\"A. Ng\"}],\"doi\":\"10.1145/1015330.1015430\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f65020fc3b1692d7989e099d6b6e698be5a50a93\",\"title\":\"Apprenticeship learning via inverse reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/f65020fc3b1692d7989e099d6b6e698be5a50a93\",\"venue\":\"ICML '04\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2056578\",\"name\":\"Jaedeug Choi\"},{\"authorId\":\"1741330\",\"name\":\"Kee-Eung Kim\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8c802ca0f26177d2dda7664778ab7bb3337edfb7\",\"title\":\"MAP Inference for Bayesian Inverse Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/8c802ca0f26177d2dda7664778ab7bb3337edfb7\",\"venue\":\"NIPS\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Nate Soares\"},{\"authorId\":null,\"name\":\"Benja Fallenstein\"},{\"authorId\":null,\"name\":\"Stuart Armstrong\"},{\"authorId\":null,\"name\":\"Eliezer Yudkowsky\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Corrigibility. In Workshops at the TwentyNinth\",\"url\":\"\",\"venue\":\"AAAI Conference on Artificial Intelligence,\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1753269\",\"name\":\"Brian D. Ziebart\"},{\"authorId\":\"34961461\",\"name\":\"Andrew L. Maas\"},{\"authorId\":\"1756566\",\"name\":\"J. Bagnell\"},{\"authorId\":\"144021446\",\"name\":\"Anind K. Dey\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"11b6bdfe36c48b11367b27187da11d95892f0361\",\"title\":\"Maximum Entropy Inverse Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/11b6bdfe36c48b11367b27187da11d95892f0361\",\"venue\":\"AAAI\",\"year\":2008},{\"arxivId\":\"1602.03506\",\"authors\":[{\"authorId\":\"145107462\",\"name\":\"S. Russell\"},{\"authorId\":\"144225182\",\"name\":\"D. Dewey\"},{\"authorId\":\"2011933\",\"name\":\"Max Tegmark\"}],\"doi\":\"10.1609/aimag.v36i4.2577\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"da08d9d5e0c12da55f3f86ef994759d6dd29f639\",\"title\":\"Research Priorities for Robust and Beneficial Artificial Intelligence\",\"url\":\"https://www.semanticscholar.org/paper/da08d9d5e0c12da55f3f86ef994759d6dd29f639\",\"venue\":\"AI Mag.\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2863625\",\"name\":\"Edward K. Cheng\"},{\"authorId\":null,\"name\":\"Reconceptualizing\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"416c13f81aa4002d15486408460ff46941cfb011\",\"title\":\"THE YALE LAW JOURNAL\",\"url\":\"https://www.semanticscholar.org/paper/416c13f81aa4002d15486408460ff46941cfb011\",\"venue\":\"\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1749270\",\"name\":\"Laurent Orseau\"},{\"authorId\":\"144710847\",\"name\":\"S. Armstrong\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ac70bb2458f01a9e47fc1afe0dd478fb2feb8f50\",\"title\":\"Safely Interruptible Agents\",\"url\":\"https://www.semanticscholar.org/paper/ac70bb2458f01a9e47fc1afe0dd478fb2feb8f50\",\"venue\":\"UAI\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Owain Evans\"},{\"authorId\":null,\"name\":\"Andreas Stuhlm\\u00fcller\"},{\"authorId\":null,\"name\":\"Noah D Goodman. Learning the preferences of ignorant\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"inconsistent agents\",\"url\":\"\",\"venue\":\"Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence, pages 323\\u2013 329. AAAI Press,\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143670744\",\"name\":\"J. Lewis\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"25833081259e30f8afb297be2f012234ff672901\",\"title\":\"The Case for Regulating Fully Autonomous Weapons\",\"url\":\"https://www.semanticscholar.org/paper/25833081259e30f8afb297be2f012234ff672901\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2660697\",\"name\":\"Bernard Michini\"},{\"authorId\":\"1713935\",\"name\":\"J. How\"}],\"doi\":\"10.1109/ICRA.2012.6225241\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"685b41e257acecf76db265540dadf6d0448c132b\",\"title\":\"Improving the efficiency of Bayesian inverse reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/685b41e257acecf76db265540dadf6d0448c132b\",\"venue\":\"2012 IEEE International Conference on Robotics and Automation\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Anca D Dragan\"},{\"authorId\":null,\"name\":\"Siddhartha S Srinivasa. Formalizing assistive teleoperation\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"MIT Press\",\"url\":\"\",\"venue\":\"July,\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Nate Soares\"},{\"authorId\":null,\"name\":\"Benja Fallenstein\"},{\"authorId\":null,\"name\":\"Stuart Armstrong\"},{\"authorId\":null,\"name\":\"Eliezer Yudkowsky\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Corrigibility\",\"url\":\"\",\"venue\":\"Workshops at the Twenty-Ninth AAAI Conference on Artificial Intelligence,\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Peter M Asaro. What Should We Want From a Robot Ethic\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"International Review of Information Ethics\",\"url\":\"\",\"venue\":\"6(12):9\\u201316,\",\"year\":2006},{\"arxivId\":\"1606.03137\",\"authors\":[{\"authorId\":\"1397904824\",\"name\":\"Dylan Hadfield-Menell\"},{\"authorId\":\"145107462\",\"name\":\"S. Russell\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"},{\"authorId\":\"2745001\",\"name\":\"Anca D. Dragan\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"1e6abd43fcb157fde4d4ddc3ac8787ae45dbf777\",\"title\":\"Cooperative Inverse Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/1e6abd43fcb157fde4d4ddc3ac8787ae45dbf777\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Ai Magazine\",\"url\":\"\",\"venue\":\"\",\"year\":1995},{\"arxivId\":null,\"authors\":[{\"authorId\":\"97752732\",\"name\":\"D. Hinkley\"}],\"doi\":\"10.1002/0471667196.ess0046.pub2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c01b5b50d6d082a88bccbf11f539955072a2e2c\",\"title\":\"Annals of Statistics\",\"url\":\"https://www.semanticscholar.org/paper/2c01b5b50d6d082a88bccbf11f539955072a2e2c\",\"venue\":\"\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34968061\",\"name\":\"Deepak Ramachandran\"},{\"authorId\":\"145957401\",\"name\":\"E. Amir\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fd62bc380b66500c31a8f1a8b566bcaea25d1652\",\"title\":\"Bayesian Inverse Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/fd62bc380b66500c31a8f1a8b566bcaea25d1652\",\"venue\":\"IJCAI\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"69475015\",\"name\":\"\\u8107\\u5143 \\u4fee\\u4e00\"}],\"doi\":\"10.1109/icra30979.2015\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"24a0686eec31394a98b233161befdeb41b942cca\",\"title\":\"IEEE International Conference on Robotics and Automation (ICRA) \\u306b\\u304a\\u3051\\u308b\\u30d5\\u30eb\\u30fc\\u30c9\\u30d1\\u30ef\\u30fc\\u6280\\u8853\\u306e\\u7814\\u7a76\\u52d5\\u5411\",\"url\":\"https://www.semanticscholar.org/paper/24a0686eec31394a98b233161befdeb41b942cca\",\"venue\":\"\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1693768\",\"name\":\"C. Gutwin\"},{\"authorId\":\"33968564\",\"name\":\"J. Dyck\"},{\"authorId\":\"48020545\",\"name\":\"J. Burkitt\"}],\"doi\":\"10.1145/958160.958207\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"28da416606db04b96990f233b2b8536c6c7f53b2\",\"title\":\"Using cursor prediction to smooth telepointer jitter\",\"url\":\"https://www.semanticscholar.org/paper/28da416606db04b96990f233b2b8536c6c7f53b2\",\"venue\":\"GROUP '03\",\"year\":2003},{\"arxivId\":\"1503.07619\",\"authors\":[{\"authorId\":\"36031485\",\"name\":\"Shervin Javdani\"},{\"authorId\":\"1752197\",\"name\":\"S. Srinivasa\"},{\"authorId\":\"1756566\",\"name\":\"J. Bagnell\"}],\"doi\":\"10.15607/RSS.2015.XI.032\",\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"2b5bf3e17f655aad45cd705d6b24a2d4e6cb2f5c\",\"title\":\"Shared Autonomy via Hindsight Optimization\",\"url\":\"https://www.semanticscholar.org/paper/2b5bf3e17f655aad45cd705d6b24a2d4e6cb2f5c\",\"venue\":\"Robotics: Science and Systems\",\"year\":2015},{\"arxivId\":\"1512.05832\",\"authors\":[{\"authorId\":\"47107786\",\"name\":\"Owain Evans\"},{\"authorId\":\"2214496\",\"name\":\"Andreas Stuhlm\\u00fcller\"},{\"authorId\":\"144002017\",\"name\":\"Noah D. Goodman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5260a706305c59c0fa2981bcdd86280c3c4a16b1\",\"title\":\"Learning the Preferences of Ignorant, Inconsistent Agents\",\"url\":\"https://www.semanticscholar.org/paper/5260a706305c59c0fa2981bcdd86280c3c4a16b1\",\"venue\":\"AAAI\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1793014\",\"name\":\"Matthias Scheutz\"},{\"authorId\":\"2196860\",\"name\":\"C. Crowell\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3bb0562e7b69bc5143116d3023393640b6dc24a5\",\"title\":\"The Burden of Embodied Autonomy : Some Reflections on the Social and Ethical Implications of Autonomous Robots\",\"url\":\"https://www.semanticscholar.org/paper/3bb0562e7b69bc5143116d3023393640b6dc24a5\",\"venue\":\"\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Andrew Y Ng\"},{\"authorId\":null,\"name\":\"Stuart J Russell\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Algo - rithms for inverse reinforcement learning\",\"url\":\"\",\"venue\":\"International Conference on Machine Learning\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2745001\",\"name\":\"Anca D. Dragan\"},{\"authorId\":\"1752197\",\"name\":\"S. Srinivasa\"}],\"doi\":\"10.15607/RSS.2012.VIII.010\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"21bf7c1bf99c0110cc0310825652a26b3f1b355f\",\"title\":\"Formalizing Assistive Teleoperation\",\"url\":\"https://www.semanticscholar.org/paper/21bf7c1bf99c0110cc0310825652a26b3f1b355f\",\"venue\":\"Robotics: Science and Systems\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34699434\",\"name\":\"A. Ng\"},{\"authorId\":\"145107462\",\"name\":\"S. Russell\"}],\"doi\":\"10.2460/AJVR.67.2.323\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b05b67aca720d0bc39bc9afad02a19f522c7a1bc\",\"title\":\"Algorithms for Inverse Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/b05b67aca720d0bc39bc9afad02a19f522c7a1bc\",\"venue\":\"ICML\",\"year\":2000},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144472017\",\"name\":\"J. Buxton\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c51ed897a5515b7e75a5ba57ce81cf3bd76950d6\",\"title\":\"Software engineering techniques\",\"url\":\"https://www.semanticscholar.org/paper/c51ed897a5515b7e75a5ba57ce81cf3bd76950d6\",\"venue\":\"\",\"year\":1970},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Nick Bostrom\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Superintelligence: Paths\",\"url\":\"\",\"venue\":\"Dangers, Strategies. OUP Oxford,\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3009143\",\"name\":\"W. Teitelman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5fed09060c4b19a30ef4ae2a9aeddaa3011f23f7\",\"title\":\"Toward a Programming Laboratory\",\"url\":\"https://www.semanticscholar.org/paper/5fed09060c4b19a30ef4ae2a9aeddaa3011f23f7\",\"venue\":\"IJCAI\",\"year\":1969},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1492009633\",\"name\":\"Patrick J. Roa\"}],\"doi\":\"10.1023/A:1017153816538\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8e6d789ee714d29c9b5156ba9d61b2170d7a315f\",\"title\":\"Volume 8\",\"url\":\"https://www.semanticscholar.org/paper/8e6d789ee714d29c9b5156ba9d61b2170d7a315f\",\"venue\":\"\",\"year\":1998},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Pieter Abbeel\"},{\"authorId\":null,\"name\":\"Andrew Y Ng. Apprenticeship learning via inverse reinforc learning\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"page 1\",\"url\":\"\",\"venue\":\"ACM,\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5886094\",\"name\":\"P. Cochat\"},{\"authorId\":\"13267685\",\"name\":\"L. Vaucoret\"},{\"authorId\":\"31455512\",\"name\":\"J. Sarles\"}],\"doi\":\"10.1016/j.arcped.2012.01.013\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"10d85561e4aafc516d10064f30dff05b41f70afe\",\"title\":\"[Et al].\",\"url\":\"https://www.semanticscholar.org/paper/10d85561e4aafc516d10064f30dff05b41f70afe\",\"venue\":\"Archives de pediatrie : organe officiel de la Societe francaise de pediatrie\",\"year\":2012},{\"arxivId\":\"cs/9605103\",\"authors\":[{\"authorId\":\"1709512\",\"name\":\"L. Kaelbling\"},{\"authorId\":\"144885169\",\"name\":\"M. Littman\"},{\"authorId\":\"1760402\",\"name\":\"A. Moore\"}],\"doi\":\"10.1613/jair.301\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"12d1d070a53d4084d88a77b8b143bad51c40c38f\",\"title\":\"Reinforcement Learning: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/12d1d070a53d4084d88a77b8b143bad51c40c38f\",\"venue\":\"J. Artif. Intell. Res.\",\"year\":1996},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1727849\",\"name\":\"S. Hanson\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"69d7086300e7f5322c06f2f242a565b3a182efb5\",\"title\":\"In Advances in Neural Information Processing Systems\",\"url\":\"https://www.semanticscholar.org/paper/69d7086300e7f5322c06f2f242a565b3a182efb5\",\"venue\":\"NIPS 1990\",\"year\":1990}],\"title\":\"Should Robots be Obedient?\",\"topics\":[{\"topic\":\"Robot\",\"topicId\":\"6657\",\"url\":\"https://www.semanticscholar.org/topic/6657\"},{\"topic\":\"Obedience (human behavior)\",\"topicId\":\"230849\",\"url\":\"https://www.semanticscholar.org/topic/230849\"},{\"topic\":\"R language\",\"topicId\":\"174635\",\"url\":\"https://www.semanticscholar.org/topic/174635\"},{\"topic\":\"Rationality\",\"topicId\":\"954\",\"url\":\"https://www.semanticscholar.org/topic/954\"},{\"topic\":\"Sensor\",\"topicId\":\"1117\",\"url\":\"https://www.semanticscholar.org/topic/1117\"},{\"topic\":\"Approximation\",\"topicId\":\"3247\",\"url\":\"https://www.semanticscholar.org/topic/3247\"},{\"topic\":\"Converge\",\"topicId\":\"205534\",\"url\":\"https://www.semanticscholar.org/topic/205534\"},{\"topic\":\"Literal (mathematical logic)\",\"topicId\":\"109284\",\"url\":\"https://www.semanticscholar.org/topic/109284\"}],\"url\":\"https://www.semanticscholar.org/paper/0f9e4431e844cece73223f521e6d8e4a812b0ef1\",\"venue\":\"IJCAI\",\"year\":2017}\n"