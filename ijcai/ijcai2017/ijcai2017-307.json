"{\"abstract\":\"Visual information is quite important for the task of video captioning. However, in the video, there are a lot of uncorrelated content, which may cause interference to generate a correct caption. Based on this point, we attempt to exploit the visual features which are most correlated to the caption. In this paper, a Multi-level Attention Model based Recurrent Neural Network (MAM-RNN) is proposed, where MAM is utilized to encode the visual feature and RNN works as the decoder to generate the video caption. During generation, the proposed approach is able to adaptively attend to the salient regions in the frame and the frames correlated to the caption. Practically, the experimental results on two benchmark datasets, i.e., MSVD and Charades, have shown the excellent performance of the proposed approach.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"1720243\",\"name\":\"X. Li\",\"url\":\"https://www.semanticscholar.org/author/1720243\"},{\"authorId\":\"143946808\",\"name\":\"Bin Zhao\",\"url\":\"https://www.semanticscholar.org/author/143946808\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\",\"url\":\"https://www.semanticscholar.org/author/7828998\"}],\"citationVelocity\":12,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"2789566\",\"name\":\"Wei-Hao Chang\"},{\"authorId\":\"35576573\",\"name\":\"J. Li\"},{\"authorId\":\"2467369\",\"name\":\"Chi-Chun Lee\"}],\"doi\":\"10.1109/ICASSP.2019.8682596\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3bfb2bfea1ac1ddc896bd5a3aa3cd0aff729fc8a\",\"title\":\"Learning Semantic-preserving Space Using User Profile and Multimodal Media Content from Political Social Network\",\"url\":\"https://www.semanticscholar.org/paper/3bfb2bfea1ac1ddc896bd5a3aa3cd0aff729fc8a\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144669461\",\"name\":\"Kuncheng Fang\"},{\"authorId\":\"144913277\",\"name\":\"Lian Zhou\"},{\"authorId\":\"145020731\",\"name\":\"Cheng Jin\"},{\"authorId\":\"7550713\",\"name\":\"Yuejie Zhang\"},{\"authorId\":\"35632219\",\"name\":\"Kangnian Weng\"},{\"authorId\":\"1689115\",\"name\":\"Tao Zhang\"},{\"authorId\":\"145631869\",\"name\":\"W. Fan\"}],\"doi\":\"10.1609/AAAI.V33I01.33018271\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"506a3e330dbd2ecc17c6a6d4c239b1cce175b6b0\",\"title\":\"Fully Convolutional Video Captioning with Coarse-to-Fine and Inherited Attention\",\"url\":\"https://www.semanticscholar.org/paper/506a3e330dbd2ecc17c6a6d4c239b1cce175b6b0\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51288954\",\"name\":\"Jiarong Dong\"},{\"authorId\":\"144947766\",\"name\":\"Ke Gao\"},{\"authorId\":\"3162023\",\"name\":\"Xiaokai Chen\"},{\"authorId\":\"144089410\",\"name\":\"J. Cao\"}],\"doi\":\"10.1007/s11063-019-10030-y\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"ed3215857d14557d0afe517b4d28b0e98b384f4b\",\"title\":\"Refocused Attention: Long Short-Term Rewards Guided Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/ed3215857d14557d0afe517b4d28b0e98b384f4b\",\"venue\":\"Neural Processing Letters\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144221742\",\"name\":\"Yifang Yin\"},{\"authorId\":\"123645165\",\"name\":\"Meng-Jiun Chiou\"},{\"authorId\":\"2766201\",\"name\":\"Z. Liu\"},{\"authorId\":\"39861388\",\"name\":\"Harsh Shrivastava\"},{\"authorId\":\"1753278\",\"name\":\"R. Shah\"},{\"authorId\":\"153015119\",\"name\":\"R. Zimmermann\"}],\"doi\":\"10.1145/3343031.3351090\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"612a59fd45a2b11749beb29205b4e03406d5fe0e\",\"title\":\"Multi-Level Fusion based Class-aware Attention Model for Weakly Labeled Audio Tagging\",\"url\":\"https://www.semanticscholar.org/paper/612a59fd45a2b11749beb29205b4e03406d5fe0e\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48352212\",\"name\":\"Aming Wu\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"65747622\",\"name\":\"Yi Yang\"}],\"doi\":\"10.24963/ijcai.2019/135\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c38ae47ae73d9287e181c3f7693c6ca69aa0432e\",\"title\":\"Video Interactive Captioning with Human Prompts\",\"url\":\"https://www.semanticscholar.org/paper/c38ae47ae73d9287e181c3f7693c6ca69aa0432e\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"2002.11886\",\"authors\":[{\"authorId\":\"48352212\",\"name\":\"Aming Wu\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a5dff9ae50c0aadbd99ca59ff70425f63213243e\",\"title\":\"Hierarchical Memory Decoding for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/a5dff9ae50c0aadbd99ca59ff70425f63213243e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1905.12243\",\"authors\":[{\"authorId\":\"50080046\",\"name\":\"Xuelong Li\"},{\"authorId\":\"12122088\",\"name\":\"Aihong Yuan\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"}],\"doi\":\"10.1109/TCYB.2019.2914351\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e5f46d314bcdbe55183cbe7e0852887c148eb807\",\"title\":\"Vision-to-Language Tasks Based on Attributes and Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/e5f46d314bcdbe55183cbe7e0852887c148eb807\",\"venue\":\"IEEE transactions on cybernetics\",\"year\":2019},{\"arxivId\":\"1803.05785\",\"authors\":[{\"authorId\":\"47287647\",\"name\":\"Sen He\"},{\"authorId\":\"2232582\",\"name\":\"D. Kangin\"},{\"authorId\":\"145071344\",\"name\":\"Yang Mi\"},{\"authorId\":\"3251678\",\"name\":\"N. Pugeault\"}],\"doi\":\"10.1109/ICPR.2018.8546051\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3067da31693248e1e966e1fb46658279cc468ccd\",\"title\":\"Aggregated Sparse Attention for Steering Angle Prediction\",\"url\":\"https://www.semanticscholar.org/paper/3067da31693248e1e966e1fb46658279cc468ccd\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":\"1905.01077\",\"authors\":[{\"authorId\":\"50763020\",\"name\":\"Jingwen Chen\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"47636228\",\"name\":\"H. Chao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1609/aaai.v33i01.33018167\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d40892479541c2d173c836534e6fb2acb597de49\",\"title\":\"Temporal Deformable Convolutional Encoder-Decoder Networks for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/d40892479541c2d173c836534e6fb2acb597de49\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48352212\",\"name\":\"Aming Wu\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"}],\"doi\":\"10.24963/ijcai.2018/143\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e2e5cef45c60c52fb0d0415cca6cbf35beab3873\",\"title\":\"Multi-modal Circulant Fusion for Video-to-Language and Backward\",\"url\":\"https://www.semanticscholar.org/paper/e2e5cef45c60c52fb0d0415cca6cbf35beab3873\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153152064\",\"name\":\"A. Liu\"},{\"authorId\":\"52196222\",\"name\":\"Y. Qiu\"},{\"authorId\":\"3026404\",\"name\":\"Yongkang Wong\"},{\"authorId\":\"153011269\",\"name\":\"Yuting Su\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":\"10.1109/ACCESS.2018.2879642\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e6b0247896a9d2eca0f4901032f5cfabd5b09dbe\",\"title\":\"A Fine-Grained Spatial-Temporal Attention Model for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/e6b0247896a9d2eca0f4901032f5cfabd5b09dbe\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7741774\",\"name\":\"Y. Hu\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"},{\"authorId\":\"51260253\",\"name\":\"Z. Zha\"},{\"authorId\":\"51239188\",\"name\":\"Fengcheng Wu\"}],\"doi\":\"10.1145/3343031.3351072\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"db6035229a71a6c93d4f15c4a4280eb644228da4\",\"title\":\"Hierarchical Global-Local Temporal Modeling for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/db6035229a71a6c93d4f15c4a4280eb644228da4\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39650418\",\"name\":\"S. Chen\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1609/AAAI.V33I01.33018191\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"75719b4df1cd244fe5bda0d01b9eb7e0c053857d\",\"title\":\"Motion Guided Spatial Attention for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/75719b4df1cd244fe5bda0d01b9eb7e0c053857d\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1481045559\",\"name\":\"Guannan Liu\"},{\"authorId\":\"153016827\",\"name\":\"J. Guo\"},{\"authorId\":\"1805243\",\"name\":\"Yuan Zuo\"},{\"authorId\":\"119837764\",\"name\":\"Junjie Wu\"},{\"authorId\":\"34850652\",\"name\":\"R. Guo\"}],\"doi\":\"10.1007/s10115-019-01433-3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"54082e7a27a4cbdbcc597ff3b06570601f6c8e7f\",\"title\":\"Fraud detection via behavioral sequence embedding\",\"url\":\"https://www.semanticscholar.org/paper/54082e7a27a4cbdbcc597ff3b06570601f6c8e7f\",\"venue\":\"Knowledge and Information Systems\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48028411\",\"name\":\"T. Jin\"},{\"authorId\":\"2367491\",\"name\":\"Y. Li\"},{\"authorId\":\"9338907\",\"name\":\"Z. Zhang\"}],\"doi\":\"10.1016/j.neucom.2019.08.042\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"00b350e4211dd5ed4791744920e664880cd3fd3a\",\"title\":\"Recurrent convolutional video captioning with global and local attention\",\"url\":\"https://www.semanticscholar.org/paper/00b350e4211dd5ed4791744920e664880cd3fd3a\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143946808\",\"name\":\"Bin Zhao\"},{\"authorId\":\"50080046\",\"name\":\"X. Li\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"}],\"doi\":\"10.1109/TIP.2019.2916757\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"acc2cfe35343195a4f3d0df5d7841d47708208fb\",\"title\":\"CAM-RNN: Co-Attention Model Based RNN for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/acc2cfe35343195a4f3d0df5d7841d47708208fb\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2653622\",\"name\":\"Junfu Pu\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"}],\"doi\":\"10.24963/ijcai.2018/123\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d8ef2cbaaf8281600135670d44dda3acd82e1aa\",\"title\":\"Dilated Convolutional Network with Iterative Optimization for Continuous Sign Language Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9d8ef2cbaaf8281600135670d44dda3acd82e1aa\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50367841\",\"name\":\"Qi Bi\"},{\"authorId\":\"100464675\",\"name\":\"Kun Qin\"},{\"authorId\":\"120811666\",\"name\":\"Han Zhang\"},{\"authorId\":\"46947989\",\"name\":\"Zhili Li\"},{\"authorId\":\"153162713\",\"name\":\"K. Xu\"}],\"doi\":\"10.1016/j.neucom.2019.11.068\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c9d7773300b910fd31bee975980a2d4eb70acf97\",\"title\":\"RADC-Net: A residual attention based convolution network for aerial scene classification\",\"url\":\"https://www.semanticscholar.org/paper/c9d7773300b910fd31bee975980a2d4eb70acf97\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46508937\",\"name\":\"Jing Zhao\"},{\"authorId\":\"3757313\",\"name\":\"J. Xu\"},{\"authorId\":\"46918954\",\"name\":\"Rui Zhou\"},{\"authorId\":\"2927967\",\"name\":\"Pengpeng Zhao\"},{\"authorId\":\"1706734\",\"name\":\"C. Liu\"},{\"authorId\":\"145409952\",\"name\":\"F. Zhu\"}],\"doi\":\"10.1145/3269206.3271708\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2a34e22a0f5fedb21c608b4b68f20109e53d490d\",\"title\":\"On Prediction of User Destination by Sub-Trajectory Understanding: A Deep Learning based Approach\",\"url\":\"https://www.semanticscholar.org/paper/2a34e22a0f5fedb21c608b4b68f20109e53d490d\",\"venue\":\"CIKM\",\"year\":2018},{\"arxivId\":\"1901.00097\",\"authors\":[{\"authorId\":\"51288954\",\"name\":\"Jiarong Dong\"},{\"authorId\":\"144947766\",\"name\":\"Ke Gao\"},{\"authorId\":\"3162023\",\"name\":\"Xiaokai Chen\"},{\"authorId\":\"2031845\",\"name\":\"Junbo Guo\"},{\"authorId\":\"144089410\",\"name\":\"J. Cao\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"3fc5d77e3238a3a9d17698b35fb425cc227263be\",\"title\":\"Not All Words Are Equal: Video-specific Information Loss for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/3fc5d77e3238a3a9d17698b35fb425cc227263be\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92538707\",\"name\":\"Qi Zheng\"},{\"authorId\":\"1409848027\",\"name\":\"Chaoyue Wang\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/CVPR42600.2020.01311\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"59cca2242fb20a6070369b5c1f172e5ee1d71785\",\"title\":\"Syntax-Aware Action Targeting for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/59cca2242fb20a6070369b5c1f172e5ee1d71785\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1994707\",\"name\":\"X. Gao\"},{\"authorId\":\"47279171\",\"name\":\"Tingting Mu\"},{\"authorId\":\"1723263\",\"name\":\"J. Y. Goulermas\"},{\"authorId\":\"2180137\",\"name\":\"Jeyarajan Thiyagalingam\"},{\"authorId\":\"152808542\",\"name\":\"Meng Wang\"}],\"doi\":\"10.1109/TIP.2020.2965275\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9051766694988110440a24152494631e3c98832d\",\"title\":\"An Interpretable Deep Architecture for Similarity Learning Built Upon Hierarchical Concepts\",\"url\":\"https://www.semanticscholar.org/paper/9051766694988110440a24152494631e3c98832d\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"2007.09049\",\"authors\":[{\"authorId\":\"1810689822\",\"name\":\"Ganchao Tan\"},{\"authorId\":\"48929163\",\"name\":\"Daqing Liu\"},{\"authorId\":\"152808542\",\"name\":\"Meng Wang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"}],\"doi\":\"10.24963/ijcai.2020/104\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a7e8aeca681e6409aa73ab0f70ff9e6fb891d071\",\"title\":\"Learning to Discretely Compose Reasoning Module Networks for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/a7e8aeca681e6409aa73ab0f70ff9e6fb891d071\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":\"1906.02500\",\"authors\":[{\"authorId\":\"47936004\",\"name\":\"A. Mott\"},{\"authorId\":\"2944502\",\"name\":\"Daniel Zoran\"},{\"authorId\":\"35977287\",\"name\":\"M. Chrzanowski\"},{\"authorId\":\"1688276\",\"name\":\"Daan Wierstra\"},{\"authorId\":\"1748523\",\"name\":\"Danilo Jimenez Rezende\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a4a2d99d1c237d0818971ec9205e89128c57fb02\",\"title\":\"Towards Interpretable Reinforcement Learning Using Attention Augmented Agents\",\"url\":\"https://www.semanticscholar.org/paper/a4a2d99d1c237d0818971ec9205e89128c57fb02\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1910.02602\",\"authors\":[{\"authorId\":\"1383481973\",\"name\":\"Yan Bin Ng\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"42b7b4bb2f96b21c33541a83606917be5eb6abbb\",\"title\":\"Human Action Sequence Classification\",\"url\":\"https://www.semanticscholar.org/paper/42b7b4bb2f96b21c33541a83606917be5eb6abbb\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143946808\",\"name\":\"Bin Zhao\"},{\"authorId\":\"1720243\",\"name\":\"X. Li\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"}],\"doi\":\"10.24963/ijcai.2018/164\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2f4821a615f08fdad69957a19366c79d939bfd5f\",\"title\":\"Video Captioning with Tube Features\",\"url\":\"https://www.semanticscholar.org/paper/2f4821a615f08fdad69957a19366c79d939bfd5f\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46947567\",\"name\":\"Zhengguang Li\"},{\"authorId\":\"9244357\",\"name\":\"Hongfei Lin\"},{\"authorId\":null,\"name\":\"Wei Zheng\"},{\"authorId\":\"51924718\",\"name\":\"Michael M. Tadesse\"},{\"authorId\":\"51009320\",\"name\":\"Zhihao Yang\"},{\"authorId\":null,\"name\":\"Jian Wang\"}],\"doi\":\"10.1109/ACCESS.2020.2985685\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"818cd69b07b55ace2e089bcfe007ea481b654f14\",\"title\":\"Interactive Self-Attentive Siamese Network for Biomedical Sentence Similarity\",\"url\":\"https://www.semanticscholar.org/paper/818cd69b07b55ace2e089bcfe007ea481b654f14\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48116016\",\"name\":\"J. Ren\"},{\"authorId\":\"50550351\",\"name\":\"W. Zhang\"}],\"doi\":\"10.1007/S11760-019-01449-W\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1581301ddb2b9b76c10b31eef101733ffebc46f8\",\"title\":\"CLOSE: Coupled content\\u2013semantic embedding\",\"url\":\"https://www.semanticscholar.org/paper/1581301ddb2b9b76c10b31eef101733ffebc46f8\",\"venue\":\"Signal Image Video Process.\",\"year\":2019},{\"arxivId\":\"2001.06127\",\"authors\":[{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"46585209\",\"name\":\"J. Wang\"},{\"authorId\":\"1765212\",\"name\":\"C. Hori\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"}],\"doi\":\"10.1109/WACV45572.2020.9093291\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e73fa178f729097428059af13b916275c7e92331\",\"title\":\"Spatio-Temporal Ranked-Attention Networks for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/e73fa178f729097428059af13b916275c7e92331\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40617978\",\"name\":\"X. Wang\"},{\"authorId\":\"49986692\",\"name\":\"Yanan Gu\"},{\"authorId\":\"49779966\",\"name\":\"Xinbo Gao\"},{\"authorId\":\"36893758\",\"name\":\"Zheng Hui\"}],\"doi\":\"10.1016/J.NEUCOM.2019.06.078\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e6ec2b7af6431da2bee5e2397705c863c1ee7bcf\",\"title\":\"Dual residual attention module network for single image super resolution\",\"url\":\"https://www.semanticscholar.org/paper/e6ec2b7af6431da2bee5e2397705c863c1ee7bcf\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"1904.02874\",\"authors\":[{\"authorId\":\"144959773\",\"name\":\"Sneha Chaudhari\"},{\"authorId\":\"2767134\",\"name\":\"Gungor Polatkan\"},{\"authorId\":\"2051517\",\"name\":\"R. Ramanath\"},{\"authorId\":\"1750278\",\"name\":\"Varun Mithal\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a8427ce5aee6d62800c725588e89940ed4910e0d\",\"title\":\"An Attentive Survey of Attention Models\",\"url\":\"https://www.semanticscholar.org/paper/a8427ce5aee6d62800c725588e89940ed4910e0d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1903.00110\",\"authors\":[{\"authorId\":\"46419391\",\"name\":\"M. Elfeki\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":\"10.1109/WACV.2019.00085\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"be447eedf6c50096cc6a85b47ae7afa203c511b6\",\"title\":\"Video Summarization Via Actionness Ranking\",\"url\":\"https://www.semanticscholar.org/paper/be447eedf6c50096cc6a85b47ae7afa203c511b6\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":\"2007.14164\",\"authors\":[{\"authorId\":\"39650418\",\"name\":\"S. Chen\"},{\"authorId\":\"119897463\",\"name\":\"Wenhao Jiang\"},{\"authorId\":\"1654091065\",\"name\":\"Wei Liu\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1007/978-3-030-58548-8_20\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5fb52197928290d3020b2256ccab22d5bf93c366\",\"title\":\"Learning Modality Interaction for Temporal Sentence Localization and Event Captioning in Videos\",\"url\":\"https://www.semanticscholar.org/paper/5fb52197928290d3020b2256ccab22d5bf93c366\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1912.02184\",\"authors\":[{\"authorId\":\"2944502\",\"name\":\"Daniel Zoran\"},{\"authorId\":\"35977287\",\"name\":\"M. Chrzanowski\"},{\"authorId\":\"2421691\",\"name\":\"Po-Sen Huang\"},{\"authorId\":\"2071666\",\"name\":\"Sven Gowal\"},{\"authorId\":\"47936004\",\"name\":\"A. Mott\"},{\"authorId\":\"143967473\",\"name\":\"P. Kohli\"}],\"doi\":\"10.1109/cvpr42600.2020.00950\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f0e287d883755757314fbc628007df2c6709c0bb\",\"title\":\"Towards Robust Image Classification Using Sequential Attention Models\",\"url\":\"https://www.semanticscholar.org/paper/f0e287d883755757314fbc628007df2c6709c0bb\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1904.10709\",\"authors\":[{\"authorId\":\"143946808\",\"name\":\"Bin Zhao\"},{\"authorId\":\"1720243\",\"name\":\"X. Li\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"},{\"authorId\":\"50218032\",\"name\":\"Z. Wang\"}],\"doi\":\"10.1016/j.neucom.2018.09.048\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"834c1a057a90cacad3e36b35387bd4ea9fa80727\",\"title\":\"A CNN-RNN architecture for multi-label weather recognition\",\"url\":\"https://www.semanticscholar.org/paper/834c1a057a90cacad3e36b35387bd4ea9fa80727\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3007274\",\"name\":\"J. Guo\"},{\"authorId\":\"47062215\",\"name\":\"G. Liu\"},{\"authorId\":\"1805243\",\"name\":\"Yuan Zuo\"},{\"authorId\":\"144637541\",\"name\":\"J. Wu\"}],\"doi\":\"10.1109/ICDM.2018.00028\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5e8aefb01f10f757c2a9c0830e760d4682832ee1\",\"title\":\"Learning Sequential Behavior Representations for Fraud Detection\",\"url\":\"https://www.semanticscholar.org/paper/5e8aefb01f10f757c2a9c0830e760d4682832ee1\",\"venue\":\"2018 IEEE International Conference on Data Mining (ICDM)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39650418\",\"name\":\"S. Chen\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.24963/ijcai.2019/877\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eeca19117a8a733aae6fb4a91c51d1c1dc03eb7f\",\"title\":\"Deep Learning for Video Captioning: A Review\",\"url\":\"https://www.semanticscholar.org/paper/eeca19117a8a733aae6fb4a91c51d1c1dc03eb7f\",\"venue\":\"IJCAI\",\"year\":2019}],\"corpusId\":28595880,\"doi\":\"10.24963/ijcai.2017/307\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":4,\"is_open_access\":true,\"is_publisher_licensed\":false,\"paperId\":\"e33bc5c83f2cea403a5521385ee8e2794b311275\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"98241663\",\"name\":\"M. V. Rossum\"}],\"doi\":\"10.1142/9789814360784_0003\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2d5af1ab6368f20a4a9bb2afae23663e5b08b9c6\",\"title\":\"Neural Computation\",\"url\":\"https://www.semanticscholar.org/paper/2d5af1ab6368f20a4a9bb2afae23663e5b08b9c6\",\"venue\":\"\",\"year\":1989},{\"arxivId\":null,\"authors\":[],\"doi\":\"10.1109/iccv19984.2013\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"26940bec2bfa247f2a73909bf2cc40f0dcd7f646\",\"title\":\"2013 Ieee International Conference on Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/26940bec2bfa247f2a73909bf2cc40f0dcd7f646\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yingwei Pan\"},{\"authorId\":null,\"name\":\"Tao Mei\"},{\"authorId\":null,\"name\":\"Ting Yao\"},{\"authorId\":null,\"name\":\"Houqiang Li\"},{\"authorId\":null,\"name\":\"Yong Rui. Jointly modeling embedding\"},{\"authorId\":null,\"name\":\"translation to bridge video\"},{\"authorId\":null,\"name\":\"language\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In 2016 IEEE Conference on Computer Vision and Pattern Recognition\",\"url\":\"\",\"venue\":\"pages 4594\\u20134602,\",\"year\":2016},{\"arxivId\":\"1505.00487\",\"authors\":[{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/ICCV.2015.515\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e58a110fa1e4ddf247d5c614d117d64bfbe135c4\",\"title\":\"Sequence to Sequence -- Video to Text\",\"url\":\"https://www.semanticscholar.org/paper/e58a110fa1e4ddf247d5c614d117d64bfbe135c4\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"E. Scott\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Reed , Dragomir Anguelov , Dumitru Erhan , Vincent Vanhoucke , and Andrew Rabinovich . Going deeper with convolutions\",\"url\":\"\",\"venue\":\"European Conference on Computer Vision\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143845796\",\"name\":\"Jeffrey Pennington\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.3115/v1/D14-1162\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"title\":\"Glove: Global Vectors for Word Representation\",\"url\":\"https://www.semanticscholar.org/paper/f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Karen Simonyan\"},{\"authorId\":null,\"name\":\"Andrew Zisserman. Very deep convolutional networks for la recognition\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"CoRR\",\"url\":\"\",\"venue\":\"abs/1409.1556,\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2665873\",\"name\":\"Jesse Thomason\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"20ab42c9b93b6e41f6e1d7b546f87c5a871db020\",\"title\":\"Integrating Language and Vision to Generate Natural Language Descriptions of Videos in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/20ab42c9b93b6e41f6e1d7b546f87c5a871db020\",\"venue\":\"COLING\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3323275\",\"name\":\"Kishore Papineni\"},{\"authorId\":\"1781292\",\"name\":\"S. Roukos\"},{\"authorId\":\"144582029\",\"name\":\"T. Ward\"},{\"authorId\":\"2587983\",\"name\":\"Wei-Jing Zhu\"}],\"doi\":\"10.3115/1073083.1073135\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d7da009f457917aa381619facfa5ffae9329a6e9\",\"title\":\"Bleu: a Method for Automatic Evaluation of Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/d7da009f457917aa381619facfa5ffae9329a6e9\",\"venue\":\"ACL\",\"year\":2002},{\"arxivId\":\"1505.01861\",\"authors\":[{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/CVPR.2016.497\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"68478207cf3e4fc44bf1602abe82c7ac7f288872\",\"title\":\"Jointly Modeling Embedding and Translation to Bridge Video and Language\",\"url\":\"https://www.semanticscholar.org/paper/68478207cf3e4fc44bf1602abe82c7ac7f288872\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1510.07712\",\"authors\":[{\"authorId\":\"2910174\",\"name\":\"Haonan Yu\"},{\"authorId\":\"40579682\",\"name\":\"J. Wang\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"}],\"doi\":\"10.1109/CVPR.2016.496\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f678a0041f2c6f931168010e7418c500c3f14cdb\",\"title\":\"Video Paragraph Captioning Using Hierarchical Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/f678a0041f2c6f931168010e7418c500c3f14cdb\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1411.5726\",\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2015.7299087\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"258986132bf17755fe8263e42429fe73218c1534\",\"title\":\"CIDEr: Consensus-based image description evaluation\",\"url\":\"https://www.semanticscholar.org/paper/258986132bf17755fe8263e42429fe73218c1534\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52014393\",\"name\":\"Ut Austin\"},{\"authorId\":\"123312980\",\"name\":\"Austin\"},{\"authorId\":\"102704114\",\"name\":\"UMass Lowell\"},{\"authorId\":\"102898595\",\"name\":\"Lowell\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"43795b7bac3d921c4e579964b54187bdbf6c6330\",\"title\":\"Translating Videos to Natural Language Using Deep Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/43795b7bac3d921c4e579964b54187bdbf6c6330\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1412.4729\",\"authors\":[{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.3115/v1/N15-1173\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8cef41606f1e1324b683441e694f0e1c96387abf\",\"title\":\"Translating Videos to Natural Language Using Deep Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/8cef41606f1e1324b683441e694f0e1c96387abf\",\"venue\":\"HLT-NAACL\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Haonan Yu\"},{\"authorId\":null,\"name\":\"Jiang Wang\"},{\"authorId\":null,\"name\":\"Zhiheng Huang\"},{\"authorId\":null,\"name\":\"Yi Yang\"},{\"authorId\":null,\"name\":\"Wei Xu. Video paragraph captioning using hierarchical networks\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In 2016 IEEE Conference on Computer Vision and Pattern Recognition\",\"url\":\"\",\"venue\":\"pages 4584\\u20134593,\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ilya Sutskever\"},{\"authorId\":null,\"name\":\"E Geoffrey\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Hochreiter and Schmidhuber , 1997 ] Sepp Hochreiter and J\\u00fcrgen Schmidhuber . Long short - term memory\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"3006928\",\"name\":\"N. Krishnamoorthy\"},{\"authorId\":\"3163967\",\"name\":\"Girish Malkarnenkar\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/ICCV.2013.337\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d6a7a563640bf53953c4fda0997e4db176488510\",\"title\":\"YouTube2Text: Recognizing and Describing Arbitrary Activities Using Semantic Hierarchies and Zero-Shot Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d6a7a563640bf53953c4fda0997e4db176488510\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1678909\",\"name\":\"G. Sandini\"}],\"doi\":\"10.1016/0262-8856(92)90008-Q\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6a9305a2f0f6a9c60ba5fa483a9c38b30e60a1f6\",\"title\":\"2nd European conference on computer vision\",\"url\":\"https://www.semanticscholar.org/paper/6a9305a2f0f6a9c60ba5fa483a9c38b30e60a1f6\",\"venue\":\"Image Vis. Comput.\",\"year\":1992},{\"arxivId\":\"1608.07068\",\"authors\":[{\"authorId\":\"32970572\",\"name\":\"Kuo-Hao Zeng\"},{\"authorId\":\"3451456\",\"name\":\"Tseng-Hung Chen\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":\"10.1007/978-3-319-46475-6_38\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"65ba5f3927633293112cf1bbdf6641d4d15638cc\",\"title\":\"Title Generation for User Generated Videos\",\"url\":\"https://www.semanticscholar.org/paper/65ba5f3927633293112cf1bbdf6641d4d15638cc\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1781574\",\"name\":\"Chin-Yew Lin\"},{\"authorId\":\"2002316\",\"name\":\"F. Och\"}],\"doi\":\"10.3115/1218955.1219032\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9ca86842aad16797d0fe0323358f3beb1ac6a5c6\",\"title\":\"Automatic Evaluation of Machine Translation Quality Using Longest Common Subsequence and Skip-Bigram Statistics\",\"url\":\"https://www.semanticscholar.org/paper/9ca86842aad16797d0fe0323358f3beb1ac6a5c6\",\"venue\":\"ACL\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"114788213\",\"name\":\"D. Signorini\"},{\"authorId\":\"4137433\",\"name\":\"J. Slattery\"},{\"authorId\":\"12113526\",\"name\":\"S. Dodds\"},{\"authorId\":\"26151757\",\"name\":\"V. Lane\"},{\"authorId\":\"143842868\",\"name\":\"P. Littlejohns\"}],\"doi\":\"10.1016/S0140-6736(95)92525-2\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"20b844e395355b40fa5940c61362ec40e56027aa\",\"title\":\"Neural networks\",\"url\":\"https://www.semanticscholar.org/paper/20b844e395355b40fa5940c61362ec40e56027aa\",\"venue\":\"The Lancet\",\"year\":1995},{\"arxivId\":\"1604.01753\",\"authors\":[{\"authorId\":\"34280810\",\"name\":\"Gunnar A. Sigurdsson\"},{\"authorId\":\"2668759\",\"name\":\"G. Varol\"},{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1007/978-3-319-46448-0_31\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"21334d1aac5422da88780f8e24e181bfa15ef0e1\",\"title\":\"Hollywood in Homes: Crowdsourcing Data Collection for Activity Understanding\",\"url\":\"https://www.semanticscholar.org/paper/21334d1aac5422da88780f8e24e181bfa15ef0e1\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1409.4842\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"46641766\",\"name\":\"W. Liu\"},{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"},{\"authorId\":\"48840704\",\"name\":\"Scott Reed\"},{\"authorId\":\"1838674\",\"name\":\"Dragomir Anguelov\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"39863668\",\"name\":\"Andrew Rabinovich\"}],\"doi\":\"10.1109/CVPR.2015.7298594\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"title\":\"Going deeper with convolutions\",\"url\":\"https://www.semanticscholar.org/paper/e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"2812486\",\"name\":\"P. Simard\"},{\"authorId\":\"1688235\",\"name\":\"P. Frasconi\"}],\"doi\":\"10.1109/72.279181\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d0be39ee052d246ae99c082a565aba25b811be2d\",\"title\":\"Learning long-term dependencies with gradient descent is difficult\",\"url\":\"https://www.semanticscholar.org/paper/d0be39ee052d246ae99c082a565aba25b811be2d\",\"venue\":\"IEEE Trans. Neural Networks\",\"year\":1994},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1162/neco.1997.9.8.1735\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"title\":\"Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"venue\":\"Neural Computation\",\"year\":1997},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1727849\",\"name\":\"S. Hanson\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"69d7086300e7f5322c06f2f242a565b3a182efb5\",\"title\":\"In Advances in Neural Information Processing Systems\",\"url\":\"https://www.semanticscholar.org/paper/69d7086300e7f5322c06f2f242a565b3a182efb5\",\"venue\":\"NIPS 1990\",\"year\":1990},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Rasool Fakoor\"},{\"authorId\":null,\"name\":\"Abdel-rahman Mohamed\"},{\"authorId\":null,\"name\":\"Margaret Mitchell\"},{\"authorId\":null,\"name\":\"Sing Bing Kang\"},{\"authorId\":null,\"name\":\"Pushmeet Kohli. Memory-augmented attention modelling for videos\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"CoRR\",\"url\":\"\",\"venue\":\"abs/1611.02261,\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Rakshith Shetty\"},{\"authorId\":null,\"name\":\"Jorma Laaksonen. Video captioning with recurrent network frame-\"},{\"authorId\":null,\"name\":\"video-level features\"},{\"authorId\":null,\"name\":\"visual content classification\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"CoRR\",\"url\":\"\",\"venue\":\"abs/1512.02949,\",\"year\":2015},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3006928\",\"name\":\"N. Krishnamoorthy\"},{\"authorId\":\"3163967\",\"name\":\"Girish Malkarnenkar\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3b9f8101c61b415f946625b69f69fc9e3d0d6fc4\",\"title\":\"Generating Natural-Language Video Descriptions Using Text-Mined Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/3b9f8101c61b415f946625b69f69fc9e3d0d6fc4\",\"venue\":\"AAAI\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Chin-Yew Lin\"},{\"authorId\":null,\"name\":\"Franz Josef Och\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Hinton . Imagenet classification with deep convolutional neural networks\",\"url\":\"\",\"venue\":\"Advances in Neural Information Processing Systems\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Denkowski\"},{\"authorId\":null,\"name\":\"Lavie\"},{\"authorId\":null,\"name\":\"2014 Michael J. Denkowski\"},{\"authorId\":null,\"name\":\"Alon Lavie\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Meteor universal: Language specific\",\"url\":\"\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145817168\",\"name\":\"D. Scott\"}],\"doi\":\"10.3115/980491\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6a106f83280b66a60ef8637cd1baafd23850ab4d\",\"title\":\"Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics\",\"url\":\"https://www.semanticscholar.org/paper/6a106f83280b66a60ef8637cd1baafd23850ab4d\",\"venue\":\"\",\"year\":2004},{\"arxivId\":\"1502.08029\",\"authors\":[{\"authorId\":\"145095579\",\"name\":\"L. Yao\"},{\"authorId\":\"1730844\",\"name\":\"Atousa Torabi\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"2482072\",\"name\":\"Nicolas Ballas\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":\"10.1109/ICCV.2015.512\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"5f425b7abf2ed3172ed060df85bb1885860a297e\",\"title\":\"Describing Videos by Exploiting Temporal Structure\",\"url\":\"https://www.semanticscholar.org/paper/5f425b7abf2ed3172ed060df85bb1885860a297e\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015}],\"title\":\"MAM-RNN: Multi-level Attention Model Based RNN for Video Captioning\",\"topics\":[{\"topic\":\"Random neural network\",\"topicId\":\"136146\",\"url\":\"https://www.semanticscholar.org/topic/136146\"},{\"topic\":\"Recurrent neural network\",\"topicId\":\"16115\",\"url\":\"https://www.semanticscholar.org/topic/16115\"},{\"topic\":\"Interference (communication)\",\"topicId\":\"572\",\"url\":\"https://www.semanticscholar.org/topic/572\"},{\"topic\":\"Relevance\",\"topicId\":\"503\",\"url\":\"https://www.semanticscholar.org/topic/503\"},{\"topic\":\"ENCODE\",\"topicId\":\"365717\",\"url\":\"https://www.semanticscholar.org/topic/365717\"},{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"}],\"url\":\"https://www.semanticscholar.org/paper/e33bc5c83f2cea403a5521385ee8e2794b311275\",\"venue\":\"IJCAI\",\"year\":2017}\n"