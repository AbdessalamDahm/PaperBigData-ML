"{\"abstract\":\"Effective collaborations among autonomous unmanned aerial vehicles (UAVs) rely on timely information sharing. However, the time-varying flight environment and the intermittent link connectivity pose great challenges to message delivery. In this paper, we leverage the deep reinforcement learning (DRL) technique to address the UAVs\\u2019 optimal links discovery and selection problem in uncertain environments. As the multiagent learning efficiency is constrained by the highdimensional and continuous action spaces, we slice the whole action spaces into a number of tractable fractions to achieve efficient convergences of optimal policies in continuous domains. Moreover, for the nonstationarity issue that particularly challenges the multi-agent DRL with local perceptions, we present a multi-agent mutual sampling method that jointly interacts the intra-agent and inter-agent state-action information to stabilize and expedite the training procedure. We evaluate the proposed algorithm on the UAVs\\u2019 continuous network connection task. Results show that the associated UAVs can quickly select the optimal connected links, which facilitate the UAVs\\u2019 teamwork significantly.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"143787141\",\"name\":\"Bo Yang\",\"url\":\"https://www.semanticscholar.org/author/143787141\"},{\"authorId\":\"46331965\",\"name\":\"M. Liu\",\"url\":\"https://www.semanticscholar.org/author/46331965\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"7313682\",\"name\":\"Duong D. Nguyen\"},{\"authorId\":\"151490069\",\"name\":\"Arvind Rajagopalan\"},{\"authorId\":\"1972968\",\"name\":\"Jijoong Kim\"},{\"authorId\":\"144366790\",\"name\":\"C. Lim\"}],\"doi\":\"10.1109/ACCESS.2019.2930640\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ce58485b6fe79a595c2f7ecb705417735219c452\",\"title\":\"Adaptive Regret Minimization for Learning Complex Team-Based Tactics\",\"url\":\"https://www.semanticscholar.org/paper/ce58485b6fe79a595c2f7ecb705417735219c452\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143787134\",\"name\":\"Bo Yang\"},{\"authorId\":\"65795457\",\"name\":\"M. Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1292279f97be0513c9f88563077b734cecb524ee\",\"title\":\"Attack-Resilient Connectivity Game for UAV Networks using Generative Adversarial Learning\",\"url\":\"https://www.semanticscholar.org/paper/1292279f97be0513c9f88563077b734cecb524ee\",\"venue\":\"AAMAS\",\"year\":2019},{\"arxivId\":\"1911.10635\",\"authors\":[{\"authorId\":\"1776230\",\"name\":\"K. Zhang\"},{\"authorId\":\"150358650\",\"name\":\"Zhuoran Yang\"},{\"authorId\":\"39765157\",\"name\":\"T. Ba\\u015far\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"54d4a221db5a91a2487b1610374843fafff5a23d\",\"title\":\"Multi-Agent Reinforcement Learning: A Selective Overview of Theories and Algorithms\",\"url\":\"https://www.semanticscholar.org/paper/54d4a221db5a91a2487b1610374843fafff5a23d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121441331\",\"name\":\"Wenjuan Sun\"},{\"authorId\":\"14893350\",\"name\":\"P. Bocchini\"},{\"authorId\":\"1800527\",\"name\":\"Brian D. Davison\"}],\"doi\":\"10.1007/s11069-020-04124-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cbc2813c8011edc36b4ed6bf18556f13a202076d\",\"title\":\"Applications of artificial intelligence for disaster management\",\"url\":\"https://www.semanticscholar.org/paper/cbc2813c8011edc36b4ed6bf18556f13a202076d\",\"venue\":\"Natural Hazards\",\"year\":2020},{\"arxivId\":\"2006.00680\",\"authors\":[{\"authorId\":\"47115878\",\"name\":\"S. Roy\"},{\"authorId\":\"9963882\",\"name\":\"Usama Mehmood\"},{\"authorId\":\"1787208\",\"name\":\"R. Grosu\"},{\"authorId\":\"145940172\",\"name\":\"S. Smolka\"},{\"authorId\":\"2173602\",\"name\":\"S. Stoller\"},{\"authorId\":\"48931158\",\"name\":\"A. Tiwari\"}],\"doi\":\"10.1109/ACSOS49614.2020.00033\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8c4507e902acd6d6e348650efddd7871e1008fa8\",\"title\":\"Learning Distributed Controllers for V-Formation\",\"url\":\"https://www.semanticscholar.org/paper/8c4507e902acd6d6e348650efddd7871e1008fa8\",\"venue\":\"2020 IEEE International Conference on Autonomic Computing and Self-Organizing Systems (ACSOS)\",\"year\":2020},{\"arxivId\":\"2011.03615\",\"authors\":[{\"authorId\":\"68974126\",\"name\":\"Amal Feriani\"},{\"authorId\":\"48555688\",\"name\":\"E. Hossain\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6b5e8a917cebbacc4937f6d033b12a7a5de683ca\",\"title\":\"Single and Multi-Agent Deep Reinforcement Learning for AI-Enabled Wireless Networks: A Tutorial\",\"url\":\"https://www.semanticscholar.org/paper/6b5e8a917cebbacc4937f6d033b12a7a5de683ca\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":51605853,\"doi\":\"10.24963/ijcai.2018/78\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":false,\"paperId\":\"031d1194d40f3f075d8eb01faf41d37c2a11cd37\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"145021599\",\"name\":\"Samuel Barrett\"},{\"authorId\":\"40110198\",\"name\":\"Avi Rosenfeld\"},{\"authorId\":\"144992450\",\"name\":\"S. Kraus\"},{\"authorId\":\"144848112\",\"name\":\"P. Stone\"}],\"doi\":\"10.1016/j.artint.2016.10.005\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ddec0eb2a9cc96aabea036ff42a19df5ab518875\",\"title\":\"Making friends on the fly: Cooperating with new teammates\",\"url\":\"https://www.semanticscholar.org/paper/ddec0eb2a9cc96aabea036ff42a19df5ab518875\",\"venue\":\"Artif. Intell.\",\"year\":2017},{\"arxivId\":\"1605.06676\",\"authors\":[{\"authorId\":\"145356667\",\"name\":\"Jakob N. Foerster\"},{\"authorId\":\"3365565\",\"name\":\"Yannis M. Assael\"},{\"authorId\":\"1737568\",\"name\":\"N. D. Freitas\"},{\"authorId\":\"1766767\",\"name\":\"S. Whiteson\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0772905d40b9afa3dc087a88184f09f3b3e1464f\",\"title\":\"Learning to Communicate with Deep Multi-Agent Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/0772905d40b9afa3dc087a88184f09f3b3e1464f\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1702.06054\",\"authors\":[{\"authorId\":\"48703799\",\"name\":\"S. Sharma\"},{\"authorId\":\"2943530\",\"name\":\"Aravind S. Lakshminarayanan\"},{\"authorId\":\"1723632\",\"name\":\"Balaraman Ravindran\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2ad53229b33ddfd3447045ea28c4a0687747b6b0\",\"title\":\"Learning to Repeat: Fine Grained Action Repetition for Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/2ad53229b33ddfd3447045ea28c4a0687747b6b0\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33821409\",\"name\":\"L. Xiao\"},{\"authorId\":\"3417673\",\"name\":\"Caixia Xie\"},{\"authorId\":\"22253036\",\"name\":\"Minghui Min\"},{\"authorId\":\"143887379\",\"name\":\"W. Zhuang\"}],\"doi\":\"10.1109/TVT.2017.2785414\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"24e9d97dbed5fb70913949ecbea77f9dfbd54682\",\"title\":\"User-Centric View of Unmanned Aerial Vehicle Transmission Against Smart Attacks\",\"url\":\"https://www.semanticscholar.org/paper/24e9d97dbed5fb70913949ecbea77f9dfbd54682\",\"venue\":\"IEEE Transactions on Vehicular Technology\",\"year\":2018},{\"arxivId\":\"1801.05757\",\"authors\":[{\"authorId\":\"48559420\",\"name\":\"Zhiyuan Xu\"},{\"authorId\":\"144551170\",\"name\":\"J. Tang\"},{\"authorId\":\"35605323\",\"name\":\"Jingsong Meng\"},{\"authorId\":\"2289238\",\"name\":\"W. Zhang\"},{\"authorId\":\"46395036\",\"name\":\"Yanzhi Wang\"},{\"authorId\":\"14349261\",\"name\":\"C. Liu\"},{\"authorId\":\"2552967\",\"name\":\"D. Yang\"}],\"doi\":\"10.1109/INFOCOM.2018.8485853\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ec1d30b1fba63149f0ac63d3094585172caeb864\",\"title\":\"Experience-driven Networking: A Deep Reinforcement Learning based Approach\",\"url\":\"https://www.semanticscholar.org/paper/ec1d30b1fba63149f0ac63d3094585172caeb864\",\"venue\":\"IEEE INFOCOM 2018 - IEEE Conference on Computer Communications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Zongzhang Zhang\"},{\"authorId\":null,\"name\":\"Zhiyuan Pan\"},{\"authorId\":null,\"name\":\"Mykel J. Kochenderfer. Weighted double Q-learning\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In Proceedings of the 26th International Joint Conference on Artificial Intelligence\",\"url\":\"\",\"venue\":\"Melbourne, Australia,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5886094\",\"name\":\"P. Cochat\"},{\"authorId\":\"13267685\",\"name\":\"L. Vaucoret\"},{\"authorId\":\"31455512\",\"name\":\"J. Sarles\"}],\"doi\":\"10.1016/j.arcped.2012.01.013\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"10d85561e4aafc516d10064f30dff05b41f70afe\",\"title\":\"[Et al].\",\"url\":\"https://www.semanticscholar.org/paper/10d85561e4aafc516d10064f30dff05b41f70afe\",\"venue\":\"Archives de pediatrie : organe officiel de la Societe francaise de pediatrie\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Hado van Hasselt\"},{\"authorId\":null,\"name\":\"Arthur Guez\"},{\"authorId\":null,\"name\":\"David Silver. Deep reinforcement learning with double Q-learning\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In Proceedings of the 30th AAAI Conference on Artificial Intelligence\",\"url\":\"\",\"venue\":\"Phoenix, USA,\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152427364\",\"name\":\"M. Pecht\"}],\"doi\":\"10.1109/mie.2007.357181\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7f9683ed2a42c229f04b0760d4658eda8b27ce84\",\"title\":\"IEEE Transactions on Industrial Informatics CALL FOR PAPERS\",\"url\":\"https://www.semanticscholar.org/paper/7f9683ed2a42c229f04b0760d4658eda8b27ce84\",\"venue\":\"\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3102622\",\"name\":\"Sandeep Chinchali\"},{\"authorId\":\"48956018\",\"name\":\"P. Hu\"},{\"authorId\":\"2688276\",\"name\":\"Tianshu Chu\"},{\"authorId\":\"143989063\",\"name\":\"M. Sharma\"},{\"authorId\":\"3088529\",\"name\":\"M. Bansal\"},{\"authorId\":\"145120655\",\"name\":\"R. Misra\"},{\"authorId\":\"1696085\",\"name\":\"M. Pavone\"},{\"authorId\":\"2546322\",\"name\":\"S. Katti\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"caf8055c3e5fae281aebd3ce234edcc69b83084b\",\"title\":\"Cellular Network Traffic Scheduling With Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/caf8055c3e5fae281aebd3ce234edcc69b83084b\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1611.01929\",\"authors\":[{\"authorId\":\"8412923\",\"name\":\"Oron Anschel\"},{\"authorId\":\"35712547\",\"name\":\"N. Baram\"},{\"authorId\":\"1742179\",\"name\":\"N. Shimkin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6ecb8a743f92db6c6b8691ab8e8aebbb06fb1b48\",\"title\":\"Averaged-DQN: Variance Reduction and Stabilization for Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/6ecb8a743f92db6c6b8691ab8e8aebbb06fb1b48\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":\"1703.06182\",\"authors\":[{\"authorId\":\"3093004\",\"name\":\"Shayegan Omidshafiei\"},{\"authorId\":\"3140253\",\"name\":\"Jason Pazis\"},{\"authorId\":\"34903901\",\"name\":\"Chris Amato\"},{\"authorId\":\"1713935\",\"name\":\"J. How\"},{\"authorId\":\"46956290\",\"name\":\"J. Vian\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b68673a166f9c620e13152f63d358fb8fce7850d\",\"title\":\"Deep Decentralized Multi-task Multi-Agent Reinforcement Learning under Partial Observability\",\"url\":\"https://www.semanticscholar.org/paper/b68673a166f9c620e13152f63d358fb8fce7850d\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145210498\",\"name\":\"J. Wang\"},{\"authorId\":\"1750017\",\"name\":\"C. Jiang\"},{\"authorId\":\"145169163\",\"name\":\"Z. Han\"},{\"authorId\":\"145659296\",\"name\":\"Y. Ren\"},{\"authorId\":\"7290622\",\"name\":\"R. Maunder\"},{\"authorId\":\"1730180\",\"name\":\"L. Hanzo\"}],\"doi\":\"10.1109/MVT.2016.2645481\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5fbba998188ab79476c953ebfe014ae7e7432a20\",\"title\":\"Taking Drones to the Next Level: Cooperative Distributed Unmanned-Aerial-Vehicular Networks for Small and Mini Drones\",\"url\":\"https://www.semanticscholar.org/paper/5fbba998188ab79476c953ebfe014ae7e7432a20\",\"venue\":\"IEEE Vehicular Technology Magazine\",\"year\":2017},{\"arxivId\":\"1702.03037\",\"authors\":[{\"authorId\":\"1700356\",\"name\":\"Joel Z. Leibo\"},{\"authorId\":\"3133079\",\"name\":\"V. Zambaldi\"},{\"authorId\":\"1975889\",\"name\":\"Marc Lanctot\"},{\"authorId\":\"1995313\",\"name\":\"J. Marecki\"},{\"authorId\":\"1686971\",\"name\":\"T. Graepel\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d4e137eeec6ca4883df9f9cf40cc49f62e8388be\",\"title\":\"Multi-agent Reinforcement Learning in Sequential Social Dilemmas\",\"url\":\"https://www.semanticscholar.org/paper/d4e137eeec6ca4883df9f9cf40cc49f62e8388be\",\"venue\":\"AAMAS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"81656417\",\"name\":\"Thekla Stefanou\"},{\"authorId\":\"81656417\",\"name\":\"Thekla Stefanou\"}],\"doi\":\"10.1109/iros.2001.977143\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1d3a42fa7d7e13b455024f6bd480d09fd0a0ed2c\",\"title\":\"Proceedings of the 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems\",\"url\":\"https://www.semanticscholar.org/paper/1d3a42fa7d7e13b455024f6bd480d09fd0a0ed2c\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699645\",\"name\":\"R. Sutton\"},{\"authorId\":\"1730590\",\"name\":\"A. Barto\"}],\"doi\":\"10.1109/TNN.1998.712192\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"97efafdb4a3942ab3efba53ded7413199f79c054\",\"title\":\"Reinforcement Learning: An Introduction\",\"url\":\"https://www.semanticscholar.org/paper/97efafdb4a3942ab3efba53ded7413199f79c054\",\"venue\":\"IEEE Transactions on Neural Networks\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1398777358\",\"name\":\"J. Hern\\u00e1ndez-Orallo\"},{\"authorId\":\"47840704\",\"name\":\"Peter A. Flach\"},{\"authorId\":\"144134367\",\"name\":\"C. Ferri\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"488a3f9092093d4f52b25df4342ec79f0327a325\",\"title\":\"Proceedings of the 28th International Conference on Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/488a3f9092093d4f52b25df4342ec79f0327a325\",\"venue\":\"\",\"year\":2011},{\"arxivId\":\"1511.08779\",\"authors\":[{\"authorId\":\"2543395\",\"name\":\"Ardi Tampuu\"},{\"authorId\":\"3319842\",\"name\":\"Tambet Matiisen\"},{\"authorId\":\"3137677\",\"name\":\"Dorian Kodelja\"},{\"authorId\":\"2830766\",\"name\":\"I. Kuzovkin\"},{\"authorId\":\"1886587\",\"name\":\"Kristjan Korjus\"},{\"authorId\":\"2768016\",\"name\":\"Juhan Aru\"},{\"authorId\":\"2075928\",\"name\":\"J. Aru\"},{\"authorId\":\"144846212\",\"name\":\"Raul Vicente\"}],\"doi\":\"10.1371/journal.pone.0172395\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"83bf91012997019f432179aad798e6d3fbb95c36\",\"title\":\"Multiagent cooperation and competition with deep reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/83bf91012997019f432179aad798e6d3fbb95c36\",\"venue\":\"PloS one\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Koray Kavukcuoglu\"},{\"authorId\":null,\"name\":\"David Silver\"},{\"authorId\":null,\"name\":\"A. Andrei\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Rusu , Joel Veness , Marc G . Bellemare , et al . Human - level control through deep reinforcement learning\",\"url\":\"\",\"venue\":\"IEEE Transactions on Vehicular Technology\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144750841\",\"name\":\"D. Wu\"},{\"authorId\":\"2435702\",\"name\":\"D. I. Arkhipov\"},{\"authorId\":\"2918263\",\"name\":\"Minyoung Kim\"},{\"authorId\":\"1709591\",\"name\":\"C. Talcott\"},{\"authorId\":\"144860036\",\"name\":\"A. Regan\"},{\"authorId\":\"145002459\",\"name\":\"J. McCann\"},{\"authorId\":\"1732742\",\"name\":\"N. Venkatasubramanian\"}],\"doi\":\"10.1109/TC.2016.2584061\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"78766678566fc2e1ea73e5cf6f5dcfa7f654ce51\",\"title\":\"ADDSEN: Adaptive Data Processing and Dissemination for Drone Swarms in Urban Sensing\",\"url\":\"https://www.semanticscholar.org/paper/78766678566fc2e1ea73e5cf6f5dcfa7f654ce51\",\"venue\":\"IEEE Transactions on Computers\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Dayong Ye\"},{\"authorId\":null,\"name\":\"Minjie Zhang\"},{\"authorId\":null,\"name\":\"Athanasios V. Vasilakos. A survey of self-organization mechan Systems\"},{\"authorId\":null,\"name\":\"Man\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and Cybernetics: Systems\",\"url\":\"\",\"venue\":\"47(3): 441\\u2013461,\",\"year\":2017},{\"arxivId\":\"1602.01783\",\"authors\":[{\"authorId\":\"3255983\",\"name\":\"V. Mnih\"},{\"authorId\":\"36045539\",\"name\":\"Adri\\u00e0 Puigdom\\u00e8nech Badia\"},{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"2542999\",\"name\":\"T. Lillicrap\"},{\"authorId\":\"3367786\",\"name\":\"T. Harley\"},{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"69e76e16740ed69f4dc55361a3d319ac2f1293dd\",\"title\":\"Asynchronous Methods for Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/69e76e16740ed69f4dc55361a3d319ac2f1293dd\",\"venue\":\"ICML\",\"year\":2016},{\"arxivId\":\"1604.06057\",\"authors\":[{\"authorId\":\"1954876\",\"name\":\"Tejas D. Kulkarni\"},{\"authorId\":\"144958935\",\"name\":\"Karthik Narasimhan\"},{\"authorId\":\"3231182\",\"name\":\"A. Saeedi\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d37620e6f8fe678a43e12930743281cd8cca6a66\",\"title\":\"Hierarchical Deep Reinforcement Learning: Integrating Temporal Abstraction and Intrinsic Motivation\",\"url\":\"https://www.semanticscholar.org/paper/d37620e6f8fe678a43e12930743281cd8cca6a66\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2617208\",\"name\":\"Dayong Ye\"},{\"authorId\":\"34994053\",\"name\":\"M. Zhang\"},{\"authorId\":\"1747034\",\"name\":\"A. Vasilakos\"}],\"doi\":\"10.1109/TSMC.2015.2504350\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c676ea3d4210bee9eadb9f8d96f7f7d5497b5500\",\"title\":\"A Survey of Self-Organization Mechanisms in Multiagent Systems\",\"url\":\"https://www.semanticscholar.org/paper/c676ea3d4210bee9eadb9f8d96f7f7d5497b5500\",\"venue\":\"IEEE Transactions on Systems, Man, and Cybernetics: Systems\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ardi Tampuu\"},{\"authorId\":null,\"name\":\"Tambet Matiisen\"},{\"authorId\":null,\"name\":\"Dorian Kodelja\"},{\"authorId\":null,\"name\":\"Ilya Kuzovkin\"},{\"authorId\":null,\"name\":\"Kristjan Korjus\"},{\"authorId\":null,\"name\":\"Juhan Aru\"},{\"authorId\":null,\"name\":\"Jaan Aru\"},{\"authorId\":null,\"name\":\"Raul Vicente. Multiagent cooperation\"},{\"authorId\":null,\"name\":\"competition with deep reinforcement learning\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"PLoS ONE\",\"url\":\"\",\"venue\":\"12(4): 1\\u201315,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46193985\",\"name\":\"Weirong Liu\"},{\"authorId\":\"2124627\",\"name\":\"Gaorong Qin\"},{\"authorId\":null,\"name\":\"Yun He\"},{\"authorId\":\"144440580\",\"name\":\"F. Jiang\"}],\"doi\":\"10.1109/TVT.2017.2702388\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"39632be8a9f9885f5d0cd340f0525abb7feb63f1\",\"title\":\"Distributed Cooperative Reinforcement Learning-Based Traffic Signal Control That Integrates V2X Networks\\u2019 Dynamic Clustering\",\"url\":\"https://www.semanticscholar.org/paper/39632be8a9f9885f5d0cd340f0525abb7feb63f1\",\"venue\":\"IEEE Transactions on Vehicular Technology\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1680804\",\"name\":\"H. Meyr\"},{\"authorId\":\"70194407\",\"name\":\"R. Peters\"},{\"authorId\":\"50077389\",\"name\":\"G. Spies\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cde75581222718a64804e34c775c4c25b60b84c4\",\"title\":\"IEEE Transactions on Vehicular Technology Vol. VT-33\",\"url\":\"https://www.semanticscholar.org/paper/cde75581222718a64804e34c775c4c25b60b84c4\",\"venue\":\"\",\"year\":1984}],\"title\":\"Keeping in Touch with Collaborative UAVs: A Deep Reinforcement Learning Approach\",\"topics\":[{\"topic\":\"Unmanned aerial vehicle\",\"topicId\":\"8294\",\"url\":\"https://www.semanticscholar.org/topic/8294\"},{\"topic\":\"Reinforcement learning\",\"topicId\":\"2557\",\"url\":\"https://www.semanticscholar.org/topic/2557\"},{\"topic\":\"Selection algorithm\",\"topicId\":\"65296\",\"url\":\"https://www.semanticscholar.org/topic/65296\"},{\"topic\":\"Multi-agent system\",\"topicId\":\"3830\",\"url\":\"https://www.semanticscholar.org/topic/3830\"},{\"topic\":\"Sampling (signal processing)\",\"topicId\":\"7839\",\"url\":\"https://www.semanticscholar.org/topic/7839\"},{\"topic\":\"Driven right leg circuit\",\"topicId\":\"427743\",\"url\":\"https://www.semanticscholar.org/topic/427743\"},{\"topic\":\"Computational complexity theory\",\"topicId\":\"1133\",\"url\":\"https://www.semanticscholar.org/topic/1133\"},{\"topic\":\"Autonomous robot\",\"topicId\":\"1175\",\"url\":\"https://www.semanticscholar.org/topic/1175\"},{\"topic\":\"Cobham's thesis\",\"topicId\":\"266433\",\"url\":\"https://www.semanticscholar.org/topic/266433\"},{\"topic\":\"Agent-based model\",\"topicId\":\"4774\",\"url\":\"https://www.semanticscholar.org/topic/4774\"},{\"topic\":\"Aerial photography\",\"topicId\":\"11975\",\"url\":\"https://www.semanticscholar.org/topic/11975\"},{\"topic\":\"Action potential\",\"topicId\":\"343\",\"url\":\"https://www.semanticscholar.org/topic/343\"}],\"url\":\"https://www.semanticscholar.org/paper/031d1194d40f3f075d8eb01faf41d37c2a11cd37\",\"venue\":\"IJCAI\",\"year\":2018}\n"