"{\"abstract\":\"While deep reinforcement learning (RL) methods have achieved unprecedented successes in a range of challenging problems, their applicability has been mainly limited to simulation or game domains due to the high sample complexity of the trial-and-error learning process. However, real-world robotic applications often need a data-efficient learning process with safety-critical constraints. In this paper, we consider the challenging problem of learning unmanned aerial vehicle (UAV) control for tracking a moving target. To acquire a strategy that combines perception and control, we represent the policy by a convolutional neural network. We develop a hierarchical approach that combines a model-free policy gradient method with a conventional feedback proportional-integral-derivative (PID) controller to enable stable learning without catastrophic failure. The neural network is trained by a combination of supervised learning from raw images and reinforcement learning from games of self-play. We show that the proposed approach can learn a target following policy in a simulator efficiently and the learned behavior can be successfully transferred to the DJI quadrotor platform for real-world UAV control.\",\"arxivId\":\"1709.08233\",\"authors\":[{\"authorId\":\"50341745\",\"name\":\"S. Li\",\"url\":\"https://www.semanticscholar.org/author/50341745\"},{\"authorId\":\"46999267\",\"name\":\"T. Liu\",\"url\":\"https://www.semanticscholar.org/author/46999267\"},{\"authorId\":\"145657495\",\"name\":\"Chi Zhang\",\"url\":\"https://www.semanticscholar.org/author/145657495\"},{\"authorId\":\"1739816\",\"name\":\"D. Yeung\",\"url\":\"https://www.semanticscholar.org/author/1739816\"},{\"authorId\":\"3225993\",\"name\":\"S. Shen\",\"url\":\"https://www.semanticscholar.org/author/3225993\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"48513191\",\"name\":\"Yilan Li\"},{\"authorId\":\"1391217910\",\"name\":\"Hongjia Li\"},{\"authorId\":\"38315753\",\"name\":\"Z. Li\"},{\"authorId\":\"122851204\",\"name\":\"Haowen Fang\"},{\"authorId\":\"32483826\",\"name\":\"Amit K. Sanyal\"},{\"authorId\":null,\"name\":\"Yanzhi Wang\"},{\"authorId\":\"1862322\",\"name\":\"Q. Qiu\"}],\"doi\":\"10.1109/RTCSA.2019.8864571\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"49d08bd51c4eacbd51a13ac1df44892933cbfba2\",\"title\":\"Fast and Accurate Trajectory Tracking for Unmanned Aerial Vehicles based on Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/49d08bd51c4eacbd51a13ac1df44892933cbfba2\",\"venue\":\"2019 IEEE 25th International Conference on Embedded and Real-Time Computing Systems and Applications (RTCSA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51143204\",\"name\":\"S. Li\"},{\"authorId\":\"2530646\",\"name\":\"J. Zhou\"},{\"authorId\":\"145832720\",\"name\":\"Zhenzhong Jia\"},{\"authorId\":\"66427434\",\"name\":\"Dit-Yan Yeung\"},{\"authorId\":\"1781040\",\"name\":\"M. T. Mason\"}],\"doi\":\"10.1007/978-3-030-33950-0_22\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"93a2054755e69954888d8180d79c35256428fc87\",\"title\":\"Learning Accurate Objectness Instance Segmentation from Photorealistic Rendering for Robotic Manipulation\",\"url\":\"https://www.semanticscholar.org/paper/93a2054755e69954888d8180d79c35256428fc87\",\"venue\":\"ISER\",\"year\":2018},{\"arxivId\":\"2012.15472\",\"authors\":[{\"authorId\":null,\"name\":\"Yoav Alon\"},{\"authorId\":\"46544755\",\"name\":\"Huiyu Zhou\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ef3dcc91a68e2af286183649ebcf7aa8a9465cea\",\"title\":\"Multi-Agent Reinforcement Learning for Unmanned Aerial Vehicle Coordination by Multi-Critic Policy Gradient Optimization\",\"url\":\"https://www.semanticscholar.org/paper/ef3dcc91a68e2af286183649ebcf7aa8a9465cea\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2001.03864\",\"authors\":[{\"authorId\":\"49015886\",\"name\":\"Wen-hui Huang\"},{\"authorId\":\"2978630\",\"name\":\"F. Braghin\"},{\"authorId\":\"101279813\",\"name\":\"Zhuo Wang\"}],\"doi\":\"10.1109/ICTAI.2019.00220\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"10c6ee47327e1179b9ad650095259186c4f0508b\",\"title\":\"Learning to Drive via Apprenticeship Learning and Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/10c6ee47327e1179b9ad650095259186c4f0508b\",\"venue\":\"2019 IEEE 31st International Conference on Tools with Artificial Intelligence (ICTAI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123099304\",\"name\":\"L. Mej\\u00edas\"},{\"authorId\":\"1835659\",\"name\":\"P. Campoy\"}],\"doi\":\"10.1109/ICUAS.2019.8797954\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"30e9b7f7011d6ed18af09178da036d290017a529\",\"title\":\"Visual Controllers for Relative Positioning in Indoor Settings\",\"url\":\"https://www.semanticscholar.org/paper/30e9b7f7011d6ed18af09178da036d290017a529\",\"venue\":\"2019 International Conference on Unmanned Aircraft Systems (ICUAS)\",\"year\":2019},{\"arxivId\":\"2010.02293\",\"authors\":[{\"authorId\":\"1988255495\",\"name\":\"Gabriel Moraes Barros\"},{\"authorId\":\"145385998\",\"name\":\"E. Colombini\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bc4131937f24a13ae1f3098f7a82b2d725ab2e48\",\"title\":\"Using Soft Actor-Critic for Low-Level UAV Control\",\"url\":\"https://www.semanticscholar.org/paper/bc4131937f24a13ae1f3098f7a82b2d725ab2e48\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144370000\",\"name\":\"Q. Cheng\"},{\"authorId\":\"47119840\",\"name\":\"X. Wang\"},{\"authorId\":\"40243319\",\"name\":\"Jian Yang\"},{\"authorId\":\"1781358\",\"name\":\"Lincheng Shen\"}],\"doi\":\"10.3390/APP9040669\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"1107a227de3142f4bd7b5d470c554636035e823d\",\"title\":\"Automated Enemy Avoidance of Unmanned Aerial Vehicles Based on Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/1107a227de3142f4bd7b5d470c554636035e823d\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9445150\",\"name\":\"A. A. Khattab\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8d0f441eea76de1fd8a46d8e8b10b8f1d3d48754\",\"title\":\"Towards an interactive drone : a Bayesian optimization approach\",\"url\":\"https://www.semanticscholar.org/paper/8d0f441eea76de1fd8a46d8e8b10b8f1d3d48754\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2003.08876\",\"authors\":[{\"authorId\":\"1402913772\",\"name\":\"Philip Becker-Ehmck\"},{\"authorId\":\"36543095\",\"name\":\"M. Karl\"},{\"authorId\":\"144719340\",\"name\":\"J. Peters\"},{\"authorId\":\"1715782\",\"name\":\"P. V. D. Smagt\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"48fd6cabd5f9688b7d290e64168e71483c221478\",\"title\":\"Learning to Fly via Deep Model-Based Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/48fd6cabd5f9688b7d290e64168e71483c221478\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35144167\",\"name\":\"C. Sampedro\"},{\"authorId\":\"1403585353\",\"name\":\"Alejandro Rodriguez-Ramos\"},{\"authorId\":\"144288180\",\"name\":\"I. Gil\"},{\"authorId\":\"38332961\",\"name\":\"L. M. Alvarez\"},{\"authorId\":\"1835659\",\"name\":\"P. Campoy\"}],\"doi\":\"10.1109/IROS.2018.8594249\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c9f0ddb22da3294408760c855144cf42f6b8b6f7\",\"title\":\"Image-Based Visual Servoing Controller for Multirotor Aerial Robots Using Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/c9f0ddb22da3294408760c855144cf42f6b8b6f7\",\"venue\":\"2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390644173\",\"name\":\"Shiyu Chen\"},{\"authorId\":\"1627945999\",\"name\":\"Yanjie Li\"}],\"doi\":\"10.1109/ICNSC48988.2020.9238129\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ab5ae03b93b256215717df20bdb42c7692c6ca85\",\"title\":\"An Overview of Robust Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/ab5ae03b93b256215717df20bdb42c7692c6ca85\",\"venue\":\"2020 IEEE International Conference on Networking, Sensing and Control (ICNSC)\",\"year\":2020}],\"corpusId\":20800788,\"doi\":\"10.24963/ijcai.2018/685\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":1,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"546d22231322b68d989278d376497fe97504f36d\",\"references\":[{\"arxivId\":\"1407.7091\",\"authors\":[{\"authorId\":\"49273877\",\"name\":\"Andrew J. Barry\"},{\"authorId\":\"1726802\",\"name\":\"Russ Tedrake\"}],\"doi\":\"10.1109/ICRA.2015.7139617\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"093b3c150b7ca3415685b903389cbc6382126d4c\",\"title\":\"Pushbroom stereo for high-speed navigation in cluttered environments\",\"url\":\"https://www.semanticscholar.org/paper/093b3c150b7ca3415685b903389cbc6382126d4c\",\"venue\":\"2015 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"},{\"authorId\":\"144638694\",\"name\":\"A. Coates\"},{\"authorId\":\"34699434\",\"name\":\"A. Ng\"}],\"doi\":\"10.1177/0278364910371999\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5fc69f93422b11c944b2d53e9d2f93295eca3d19\",\"title\":\"Autonomous Helicopter Aerobatics through Apprenticeship Learning\",\"url\":\"https://www.semanticscholar.org/paper/5fc69f93422b11c944b2d53e9d2f93295eca3d19\",\"venue\":\"Int. J. Robotics Res.\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50341745\",\"name\":\"S. Li\"},{\"authorId\":\"1739816\",\"name\":\"D. Yeung\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6ebc40a061433c24a3ea1f305bb6533b8f3dd5f4\",\"title\":\"Visual Object Tracking for Unmanned Aerial Vehicles: A Benchmark and New Motion Models\",\"url\":\"https://www.semanticscholar.org/paper/6ebc40a061433c24a3ea1f305bb6533b8f3dd5f4\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145197867\",\"name\":\"Jan Peters\"},{\"authorId\":\"1745219\",\"name\":\"S. Schaal\"}],\"doi\":\"10.1109/IROS.2006.282564\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b9dfc5c3ceac9b2b2b74505517a3a3efaa864859\",\"title\":\"Policy Gradient Methods for Robotics\",\"url\":\"https://www.semanticscholar.org/paper/b9dfc5c3ceac9b2b2b74505517a3a3efaa864859\",\"venue\":\"2006 IEEE/RSJ International Conference on Intelligent Robots and Systems\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40499793\",\"name\":\"K. Schmid\"},{\"authorId\":\"34598337\",\"name\":\"Teodor Tomic\"},{\"authorId\":\"32882253\",\"name\":\"F. Ruess\"},{\"authorId\":\"3335378\",\"name\":\"H. Hirschm\\u00fcller\"},{\"authorId\":\"1787158\",\"name\":\"M. Suppa\"}],\"doi\":\"10.1109/IROS.2013.6696922\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"671c4ebfb5e3366f6095cefc6277d2857d0b619b\",\"title\":\"Stereo vision based indoor/outdoor navigation for flying robots\",\"url\":\"https://www.semanticscholar.org/paper/671c4ebfb5e3366f6095cefc6277d2857d0b619b\",\"venue\":\"2013 IEEE/RSJ International Conference on Intelligent Robots and Systems\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145994435\",\"name\":\"Rui Shi\"},{\"authorId\":\"144424251\",\"name\":\"Wei Zeng\"},{\"authorId\":\"3154357\",\"name\":\"Zhengyu Su\"},{\"authorId\":\"145849587\",\"name\":\"Jian Jiang\"},{\"authorId\":\"144027810\",\"name\":\"H. Damasio\"},{\"authorId\":\"30460080\",\"name\":\"Zhonglin Lu\"},{\"authorId\":\"33973920\",\"name\":\"Y. Wang\"},{\"authorId\":\"145617326\",\"name\":\"Shing-Tung Yau\"},{\"authorId\":\"145560807\",\"name\":\"X. Gu\"}],\"doi\":\"10.1109/tpami.2004.1307308\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"208ebe27e70640de8a94f0638fb13bfda71cd943\",\"title\":\"IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE\",\"url\":\"https://www.semanticscholar.org/paper/208ebe27e70640de8a94f0638fb13bfda71cd943\",\"venue\":\"\",\"year\":1998},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2969498\",\"name\":\"Daniel Mellinger\"},{\"authorId\":\"37956314\",\"name\":\"V. Kumar\"}],\"doi\":\"10.1109/ICRA.2011.5980409\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b07938d9a0b6a34fe72c2df1b604c0f07fb2a4ca\",\"title\":\"Minimum snap trajectory generation and control for quadrotors\",\"url\":\"https://www.semanticscholar.org/paper/b07938d9a0b6a34fe72c2df1b604c0f07fb2a4ca\",\"venue\":\"2011 IEEE International Conference on Robotics and Automation\",\"year\":2011},{\"arxivId\":\"1211.1690\",\"authors\":[{\"authorId\":\"1700433\",\"name\":\"S. Ross\"},{\"authorId\":\"1432683555\",\"name\":\"Narek Melik-Barkhudarov\"},{\"authorId\":\"2737958\",\"name\":\"K. Shankar\"},{\"authorId\":\"35246669\",\"name\":\"A. Wendel\"},{\"authorId\":\"1780951\",\"name\":\"Debadeepta Dey\"},{\"authorId\":\"1756566\",\"name\":\"J. Bagnell\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1109/ICRA.2013.6630809\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f0d11429e5aaecbc9fce8445afaa3bad7a74888\",\"title\":\"Learning monocular reactive UAV control in cluttered natural environments\",\"url\":\"https://www.semanticscholar.org/paper/0f0d11429e5aaecbc9fce8445afaa3bad7a74888\",\"venue\":\"2013 IEEE International Conference on Robotics and Automation\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2709197\",\"name\":\"Nima Mohajerin\"},{\"authorId\":\"145292735\",\"name\":\"Steven L. Waslander\"}],\"doi\":\"10.1109/SMC.2014.6974106\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5c6f57ad1d9f834b5cc6ab1593196e6a3035e2f8\",\"title\":\"Modular deep Recurrent Neural Network: Application to quadrotors\",\"url\":\"https://www.semanticscholar.org/paper/5c6f57ad1d9f834b5cc6ab1593196e6a3035e2f8\",\"venue\":\"2014 IEEE International Conference on Systems, Man, and Cybernetics (SMC)\",\"year\":2014},{\"arxivId\":\"1502.05477\",\"authors\":[{\"authorId\":\"47971768\",\"name\":\"John Schulman\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"},{\"authorId\":\"1694621\",\"name\":\"Michael I. Jordan\"},{\"authorId\":\"29912342\",\"name\":\"P. Moritz\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"66cdc28dc084af6507e979767755e99fe0b46b39\",\"title\":\"Trust Region Policy Optimization\",\"url\":\"https://www.semanticscholar.org/paper/66cdc28dc084af6507e979767755e99fe0b46b39\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2967241\",\"name\":\"Fabian L. Mueller\"},{\"authorId\":\"143633801\",\"name\":\"Angela P. Schoellig\"},{\"authorId\":\"1397222121\",\"name\":\"R. D'Andrea\"}],\"doi\":\"10.1109/IROS.2012.6385647\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"39305ee03091b2a782d9e68b0004a906aab5d116\",\"title\":\"Iterative learning of feed-forward corrections for high-performance tracking\",\"url\":\"https://www.semanticscholar.org/paper/39305ee03091b2a782d9e68b0004a906aab5d116\",\"venue\":\"2012 IEEE/RSJ International Conference on Intelligent Robots and Systems\",\"year\":2012},{\"arxivId\":\"1509.06791\",\"authors\":[{\"authorId\":\"1747773\",\"name\":\"T. Zhang\"},{\"authorId\":\"46292812\",\"name\":\"G. Kahn\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"}],\"doi\":\"10.1109/ICRA.2016.7487175\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"10b9283146b71ee5d38238eb3b30732a3d2bdbb2\",\"title\":\"Learning deep control policies for autonomous aerial vehicles with MPC-guided policy search\",\"url\":\"https://www.semanticscholar.org/paper/10b9283146b71ee5d38238eb3b30732a3d2bdbb2\",\"venue\":\"2016 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33354551\",\"name\":\"A. Giusti\"},{\"authorId\":\"2144778\",\"name\":\"J\\u00e9r\\u00f4me Guzzi\"},{\"authorId\":\"1895356\",\"name\":\"Dan C. Ciresan\"},{\"authorId\":\"1946020\",\"name\":\"Fang-Lin He\"},{\"authorId\":\"117005439\",\"name\":\"J. P. Rodriguez\"},{\"authorId\":\"2506029\",\"name\":\"Flavio Fontana\"},{\"authorId\":\"36984610\",\"name\":\"M. Faessler\"},{\"authorId\":\"144789467\",\"name\":\"C. Forster\"},{\"authorId\":\"48974230\",\"name\":\"J. Schmidhuber\"},{\"authorId\":\"1744127\",\"name\":\"G. D. Caro\"},{\"authorId\":\"2075371\",\"name\":\"D. Scaramuzza\"},{\"authorId\":\"6803671\",\"name\":\"L. Gambardella\"}],\"doi\":\"10.1109/LRA.2015.2509024\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5ce030f1650145a103527e883e7a9d9a25c45547\",\"title\":\"A Machine Learning Approach to Visual Perception of Forest Trails for Mobile Robots\",\"url\":\"https://www.semanticscholar.org/paper/5ce030f1650145a103527e883e7a9d9a25c45547\",\"venue\":\"IEEE Robotics and Automation Letters\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"16426519\",\"name\":\"Cooper Bills\"},{\"authorId\":\"143708912\",\"name\":\"Joyce Chen\"},{\"authorId\":\"1681995\",\"name\":\"A. Saxena\"}],\"doi\":\"10.1109/ICRA.2011.5980136\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"003d6ced7ec1923579e84b9facea6583a1227406\",\"title\":\"Autonomous MAV flight in indoor environments using single image perspective cues\",\"url\":\"https://www.semanticscholar.org/paper/003d6ced7ec1923579e84b9facea6583a1227406\",\"venue\":\"2011 IEEE International Conference on Robotics and Automation\",\"year\":2011},{\"arxivId\":\"1010.1725\",\"authors\":[{\"authorId\":\"1757973\",\"name\":\"Taeyoung Lee\"}],\"doi\":\"10.1109/ACC.2011.5990858\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7c369e85b6a781417d7e78a3ef1e91a1efae6187\",\"title\":\"Geometric tracking control of the attitude dynamics of a rigid body on SO(3)\",\"url\":\"https://www.semanticscholar.org/paper/7c369e85b6a781417d7e78a3ef1e91a1efae6187\",\"venue\":\"Proceedings of the 2011 American Control Conference\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"3276293\",\"name\":\"G. Lever\"},{\"authorId\":\"2801204\",\"name\":\"N. Heess\"},{\"authorId\":\"1804488\",\"name\":\"T. Degris\"},{\"authorId\":\"1688276\",\"name\":\"Daan Wierstra\"},{\"authorId\":\"3137672\",\"name\":\"Martin A. Riedmiller\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"687d0e59d5c35f022ce4638b3e3a6142068efc94\",\"title\":\"Deterministic Policy Gradient Algorithms\",\"url\":\"https://www.semanticscholar.org/paper/687d0e59d5c35f022ce4638b3e3a6142068efc94\",\"venue\":\"ICML\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3255983\",\"name\":\"V. Mnih\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"},{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"1392331736\",\"name\":\"Andrei A. Rusu\"},{\"authorId\":\"144056327\",\"name\":\"J. Veness\"},{\"authorId\":\"1397980088\",\"name\":\"Marc G. Bellemare\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"3137672\",\"name\":\"Martin A. Riedmiller\"},{\"authorId\":\"1397979864\",\"name\":\"Andreas K. Fidjeland\"},{\"authorId\":\"2273072\",\"name\":\"Georg Ostrovski\"},{\"authorId\":\"145386761\",\"name\":\"S. Petersen\"},{\"authorId\":\"48878752\",\"name\":\"C. Beattie\"},{\"authorId\":\"49813280\",\"name\":\"A. Sadik\"},{\"authorId\":\"2460849\",\"name\":\"Ioannis Antonoglou\"},{\"authorId\":\"153907173\",\"name\":\"H. King\"},{\"authorId\":\"2106164\",\"name\":\"D. Kumaran\"},{\"authorId\":\"1688276\",\"name\":\"Daan Wierstra\"},{\"authorId\":\"34313265\",\"name\":\"S. Legg\"},{\"authorId\":\"48987704\",\"name\":\"Demis Hassabis\"}],\"doi\":\"10.1038/nature14236\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e0e9a94c4a6ba219e768b4e59f72c18f0a22e23d\",\"title\":\"Human-level control through deep reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/e0e9a94c4a6ba219e768b4e59f72c18f0a22e23d\",\"venue\":\"Nature\",\"year\":2015},{\"arxivId\":\"1609.05143\",\"authors\":[{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"3012475\",\"name\":\"R. Mottaghi\"},{\"authorId\":\"3386570\",\"name\":\"Eric Kolve\"},{\"authorId\":\"35198686\",\"name\":\"Joseph J. Lim\"},{\"authorId\":\"51230553\",\"name\":\"A. Gupta\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"47465174\",\"name\":\"Ali Farhadi\"}],\"doi\":\"10.1109/ICRA.2017.7989381\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7af7f2f539cd3479faae4c66bbef49b0f66202fa\",\"title\":\"Target-driven visual navigation in indoor scenes using deep reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/7af7f2f539cd3479faae4c66bbef49b0f66202fa\",\"venue\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Fabian L Mueller\"},{\"authorId\":null,\"name\":\"Angela P Schoellig\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and Raffaello D\\u2019Andrea\",\"url\":\"\",\"venue\":\"Iterative learning of feed-forward corrections for high-performance tracking. In IROS,\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2355911\",\"name\":\"Ali Punjani\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"}],\"doi\":\"10.1109/ICRA.2015.7139643\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7d5bc454ba9335ce488adeead662d782a8c55f04\",\"title\":\"Deep learning helicopter dynamics models\",\"url\":\"https://www.semanticscholar.org/paper/7d5bc454ba9335ce488adeead662d782a8c55f04\",\"venue\":\"2015 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yuke Zhu\"},{\"authorId\":null,\"name\":\"Roozbeh Mottaghi\"},{\"authorId\":null,\"name\":\"Eric Kolve\"},{\"authorId\":null,\"name\":\"Joseph J Lim\"},{\"authorId\":null,\"name\":\"Abhinav Gupta\"},{\"authorId\":null,\"name\":\"Li Fei-Fei\"},{\"authorId\":null,\"name\":\"Ali Farhadi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Targetdriven visual navigation in indoor scenes using deep reinforcement learning\",\"url\":\"\",\"venue\":\"ICRA,\",\"year\":2017},{\"arxivId\":\"1610.00633\",\"authors\":[{\"authorId\":\"2046135\",\"name\":\"Shixiang Gu\"},{\"authorId\":\"29891985\",\"name\":\"Ethan Holly\"},{\"authorId\":\"2542999\",\"name\":\"T. Lillicrap\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":\"10.1109/ICRA.2017.7989385\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e37b999f0c96d7136db07b0185b837d5decd599a\",\"title\":\"Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates\",\"url\":\"https://www.semanticscholar.org/paper/e37b999f0c96d7136db07b0185b837d5decd599a\",\"venue\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2017},{\"arxivId\":\"1604.06778\",\"authors\":[{\"authorId\":\"144581158\",\"name\":\"Yan Duan\"},{\"authorId\":\"41192764\",\"name\":\"Xi Chen\"},{\"authorId\":\"3127100\",\"name\":\"Rein Houthooft\"},{\"authorId\":\"47971768\",\"name\":\"John Schulman\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1464776f20e2bccb6182f183b5ff2e15b0ae5e56\",\"title\":\"Benchmarking Deep Reinforcement Learning for Continuous Control\",\"url\":\"https://www.semanticscholar.org/paper/1464776f20e2bccb6182f183b5ff2e15b0ae5e56\",\"venue\":\"ICML\",\"year\":2016},{\"arxivId\":\"1504.00702\",\"authors\":[{\"authorId\":\"1736651\",\"name\":\"S. Levine\"},{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b6b8a1b80891c96c28cc6340267b58186157e536\",\"title\":\"End-to-End Training of Deep Visuomotor Policies\",\"url\":\"https://www.semanticscholar.org/paper/b6b8a1b80891c96c28cc6340267b58186157e536\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1999263\",\"name\":\"A. Bachrach\"},{\"authorId\":\"145876248\",\"name\":\"S. Prentice\"},{\"authorId\":\"34250901\",\"name\":\"Ruijie He\"},{\"authorId\":\"1791800\",\"name\":\"P. Henry\"},{\"authorId\":\"29193232\",\"name\":\"Albert S. Huang\"},{\"authorId\":\"2576619\",\"name\":\"Michael Krainin\"},{\"authorId\":\"2043965\",\"name\":\"Daniel Maturana\"},{\"authorId\":\"145197953\",\"name\":\"D. Fox\"},{\"authorId\":\"143724999\",\"name\":\"N. Roy\"}],\"doi\":\"10.1177/0278364912455256\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"99d47183508d7753d34ad1a3e279cb314cade02b\",\"title\":\"Estimation, planning, and mapping for autonomous flight using an RGB-D camera in GPS-denied environments\",\"url\":\"https://www.semanticscholar.org/paper/99d47183508d7753d34ad1a3e279cb314cade02b\",\"venue\":\"Int. J. Robotics Res.\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"},{\"authorId\":\"144638694\",\"name\":\"A. Coates\"},{\"authorId\":\"39100828\",\"name\":\"M. Quigley\"},{\"authorId\":\"34699434\",\"name\":\"A. Ng\"}],\"doi\":\"10.7551/mitpress/7503.003.0006\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0bfbdafdfbcc268860fe54ae4d8f08d487bcc762\",\"title\":\"An Application of Reinforcement Learning to Aerobatic Helicopter Flight\",\"url\":\"https://www.semanticscholar.org/paper/0bfbdafdfbcc268860fe54ae4d8f08d487bcc762\",\"venue\":\"NIPS\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39934673\",\"name\":\"A. Bai\"},{\"authorId\":\"145107462\",\"name\":\"S. Russell\"}],\"doi\":\"10.24963/ijcai.2017/196\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9486d64580fcc72869d46407171285c82d3b005c\",\"title\":\"Efficient Reinforcement Learning with Hierarchies of Machines by Leveraging Internal Transitions\",\"url\":\"https://www.semanticscholar.org/paper/9486d64580fcc72869d46407171285c82d3b005c\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":\"1602.01783\",\"authors\":[{\"authorId\":\"3255983\",\"name\":\"V. Mnih\"},{\"authorId\":\"36045539\",\"name\":\"Adri\\u00e0 Puigdom\\u00e8nech Badia\"},{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"2542999\",\"name\":\"T. Lillicrap\"},{\"authorId\":\"3367786\",\"name\":\"T. Harley\"},{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"69e76e16740ed69f4dc55361a3d319ac2f1293dd\",\"title\":\"Asynchronous Methods for Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/69e76e16740ed69f4dc55361a3d319ac2f1293dd\",\"venue\":\"ICML\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3225993\",\"name\":\"S. Shen\"},{\"authorId\":\"2435597\",\"name\":\"Yash Mulgaonkar\"},{\"authorId\":\"144384764\",\"name\":\"N. Michael\"},{\"authorId\":\"37956314\",\"name\":\"V. Kumar\"}],\"doi\":\"10.15607/RSS.2013.IX.032\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7b9e7b5c372692f6dedad0bfba4771e9e278e2a5\",\"title\":\"Vision-Based State Estimation and Trajectory Control Towards High-Speed Flight with a Quadrotor\",\"url\":\"https://www.semanticscholar.org/paper/7b9e7b5c372692f6dedad0bfba4771e9e278e2a5\",\"venue\":\"Robotics: Science and Systems\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699645\",\"name\":\"R. Sutton\"},{\"authorId\":\"145689002\",\"name\":\"David A. McAllester\"},{\"authorId\":\"1699868\",\"name\":\"Satinder Singh\"},{\"authorId\":\"144830983\",\"name\":\"Y. Mansour\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a20f0ce0616def7cc9a87446c228906cd5da093b\",\"title\":\"Policy Gradient Methods for Reinforcement Learning with Function Approximation\",\"url\":\"https://www.semanticscholar.org/paper/a20f0ce0616def7cc9a87446c228906cd5da093b\",\"venue\":\"NIPS\",\"year\":1999},{\"arxivId\":\"1509.02971\",\"authors\":[{\"authorId\":\"2542999\",\"name\":\"T. Lillicrap\"},{\"authorId\":\"2323922\",\"name\":\"J. Hunt\"},{\"authorId\":\"1863250\",\"name\":\"A. Pritzel\"},{\"authorId\":\"2801204\",\"name\":\"N. Heess\"},{\"authorId\":\"1968210\",\"name\":\"T. Erez\"},{\"authorId\":\"2109481\",\"name\":\"Y. Tassa\"},{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"1688276\",\"name\":\"Daan Wierstra\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"024006d4c2a89f7acacc6e4438d156525b60a98f\",\"title\":\"Continuous control with deep reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/024006d4c2a89f7acacc6e4438d156525b60a98f\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":\"1803.00757\",\"authors\":[{\"authorId\":\"144891954\",\"name\":\"T. Sun\"},{\"authorId\":\"20673748\",\"name\":\"Shengyi Nie\"},{\"authorId\":\"1739816\",\"name\":\"D. Yeung\"},{\"authorId\":\"3225993\",\"name\":\"S. Shen\"}],\"doi\":\"10.1109/ICRA.2017.7989696\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a5e7a37df6123ca2aace19e42ccf60dfe272b108\",\"title\":\"Gesture-based piloting of an aerial robot using monocular vision\",\"url\":\"https://www.semanticscholar.org/paper/a5e7a37df6123ca2aace19e42ccf60dfe272b108\",\"venue\":\"2017 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2017},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1611.04201\",\"authors\":[{\"authorId\":\"3253737\",\"name\":\"F. Sadeghi\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":\"10.15607/RSS.2017.XIII.034\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"f7ac2479e686eb2a7a8afc23f99f213fcd3c5292\",\"title\":\"(CAD)$^2$RL: Real Single-Image Flight without a Single Real Image\",\"url\":\"https://www.semanticscholar.org/paper/f7ac2479e686eb2a7a8afc23f99f213fcd3c5292\",\"venue\":\"Robotics: Science and Systems\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Sergey Levine\"},{\"authorId\":null,\"name\":\"Chelsea Finn\"},{\"authorId\":null,\"name\":\"Trevor Darrell\"},{\"authorId\":null,\"name\":\"Pieter Abbeel. End-to-end training of deep visuomotor policies\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Journal of Machine Learning Research\",\"url\":\"\",\"venue\":\"17(39):1\\u201340,\",\"year\":2016},{\"arxivId\":\"1502.02860\",\"authors\":[{\"authorId\":\"2261881\",\"name\":\"M. Deisenroth\"},{\"authorId\":\"145197953\",\"name\":\"D. Fox\"},{\"authorId\":\"3472959\",\"name\":\"C. Rasmussen\"}],\"doi\":\"10.1109/TPAMI.2013.218\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"718577588f38727ff28cf5321a5772a6fcdc1865\",\"title\":\"Gaussian Processes for Data-Efficient Learning in Robotics and Control\",\"url\":\"https://www.semanticscholar.org/paper/718577588f38727ff28cf5321a5772a6fcdc1865\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2015}],\"title\":\"Learning Unmanned Aerial Vehicle Control for Autonomous Target Following\",\"topics\":[{\"topic\":\"Unmanned aerial vehicle\",\"topicId\":\"8294\",\"url\":\"https://www.semanticscholar.org/topic/8294\"},{\"topic\":\"Reinforcement learning\",\"topicId\":\"2557\",\"url\":\"https://www.semanticscholar.org/topic/2557\"},{\"topic\":\"Convolutional neural network\",\"topicId\":\"29860\",\"url\":\"https://www.semanticscholar.org/topic/29860\"},{\"topic\":\"Supervised learning\",\"topicId\":\"8357\",\"url\":\"https://www.semanticscholar.org/topic/8357\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"},{\"topic\":\"Autonomous robot\",\"topicId\":\"1175\",\"url\":\"https://www.semanticscholar.org/topic/1175\"},{\"topic\":\"Simulation\",\"topicId\":\"194\",\"url\":\"https://www.semanticscholar.org/topic/194\"},{\"topic\":\"Machine learning\",\"topicId\":\"168\",\"url\":\"https://www.semanticscholar.org/topic/168\"},{\"topic\":\"End-to-end principle\",\"topicId\":\"299633\",\"url\":\"https://www.semanticscholar.org/topic/299633\"},{\"topic\":\"High- and low-level\",\"topicId\":\"33507\",\"url\":\"https://www.semanticscholar.org/topic/33507\"},{\"topic\":\"Aerial photography\",\"topicId\":\"11975\",\"url\":\"https://www.semanticscholar.org/topic/11975\"},{\"topic\":\"Sample complexity\",\"topicId\":\"112440\",\"url\":\"https://www.semanticscholar.org/topic/112440\"},{\"topic\":\"Gradient method\",\"topicId\":\"61331\",\"url\":\"https://www.semanticscholar.org/topic/61331\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Instability\",\"topicId\":\"4779\",\"url\":\"https://www.semanticscholar.org/topic/4779\"},{\"topic\":\"Osmo\",\"topicId\":\"3896621\",\"url\":\"https://www.semanticscholar.org/topic/3896621\"},{\"topic\":\"PID\",\"topicId\":\"6659\",\"url\":\"https://www.semanticscholar.org/topic/6659\"}],\"url\":\"https://www.semanticscholar.org/paper/546d22231322b68d989278d376497fe97504f36d\",\"venue\":\"IJCAI\",\"year\":2018}\n"