"{\"abstract\":\"Partially-observable Markov decision processes (POMDPs) with discounted-sum payoff are a standard framework to model a wide range of problems related to decision making under uncertainty. Traditionally, the goal has been to obtain policies that optimize the expectation of the discounted-sum payoff. A key drawback of the expectation measure is that even low probability events with extreme payoff can significantly affect the expectation, and thus the obtained policies are not necessarily risk-averse. An alternate approach is to optimize the probability that the payoff is above a certain threshold, which allows obtaining risk-averse policies, but ignores optimization of the expectation. We consider the expectation optimization with probabilistic guarantee (EOPG) problem, where the goal is to optimize the expectation ensuring that the payoff is above a given threshold with at least a specified probability. We present several results on the EOPG problem, including the first algorithm to solve it.\",\"arxivId\":\"1804.10601\",\"authors\":[{\"authorId\":\"144325663\",\"name\":\"K. Chatterjee\",\"url\":\"https://www.semanticscholar.org/author/144325663\"},{\"authorId\":\"41020332\",\"name\":\"Adri\\u00e1n Elgy\\u00fctt\",\"url\":\"https://www.semanticscholar.org/author/41020332\"},{\"authorId\":\"40136108\",\"name\":\"P. Novotn\\u00fd\",\"url\":\"https://www.semanticscholar.org/author/40136108\"},{\"authorId\":\"41022556\",\"name\":\"Owen Rouill\\u00e9\",\"url\":\"https://www.semanticscholar.org/author/41022556\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1986466\",\"name\":\"Abdullah Al Redwan Newaz\"},{\"authorId\":\"35865989\",\"name\":\"S. Chaudhuri\"},{\"authorId\":\"1780248\",\"name\":\"L. Kavraki\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c8b1e5f20cbd2581b0535ce0d173849650d74717\",\"title\":\"Monte-Carlo Policy Synthesis in POMDPs with Quantitative and Qualitative Objectives\",\"url\":\"https://www.semanticscholar.org/paper/c8b1e5f20cbd2581b0535ce0d173849650d74717\",\"venue\":\"RSS 2019\",\"year\":2019},{\"arxivId\":\"2002.12086\",\"authors\":[{\"authorId\":\"3115896\",\"name\":\"T. Br\\u00e1zdil\"},{\"authorId\":\"41172324\",\"name\":\"K. Chatterjee\"},{\"authorId\":\"40136108\",\"name\":\"P. Novotn\\u00fd\"},{\"authorId\":\"3693436\",\"name\":\"J. V\\u00e1hala\"}],\"doi\":\"10.1609/AAAI.V34I06.6531\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4dadf42b5df67ad65322e7b169b6973ee33f53d3\",\"title\":\"Reinforcement Learning of Risk-Constrained Policies in Markov Decision Processes\",\"url\":\"https://www.semanticscholar.org/paper/4dadf42b5df67ad65322e7b169b6973ee33f53d3\",\"venue\":\"AAAI\",\"year\":2020}],\"corpusId\":13754244,\"doi\":\"10.24963/ijcai.2018/652\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":1,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"aa1cc90d0047e1afb70fbba9547dc25af686cac7\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Krishnendu Chatterjee\"},{\"authorId\":null,\"name\":\"Zuzana Kom\\u00e1rkov\\u00e1\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and Jan Kret\\u0131\\u0301nsk\\u00fd\",\"url\":\"\",\"venue\":\"Unifying two views on multiple mean-payoff objectives in Markov decision processes. In LICS, pages 244\\u2013256. IEEE Computer Society,\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"AI-Toolbox\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"AI-Toolbox [Computer Software\",\"url\":\"\",\"venue\":\"https://github.com/Svalorzen/AI-Toolbox,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144184704\",\"name\":\"Dongho Kim\"},{\"authorId\":\"3017896\",\"name\":\"Jaesong Lee\"},{\"authorId\":\"1741330\",\"name\":\"Kee-Eung Kim\"},{\"authorId\":\"1807041\",\"name\":\"P. Poupart\"}],\"doi\":\"10.5591/978-1-57735-516-8/IJCAI11-329\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"20aebf66e68b517c63fc48045324f7a5342f9c2b\",\"title\":\"Point-Based Value Iteration for Constrained POMDPs\",\"url\":\"https://www.semanticscholar.org/paper/20aebf66e68b517c63fc48045324f7a5342f9c2b\",\"venue\":\"IJCAI\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Pedro Santana\"},{\"authorId\":null,\"name\":\"Sylvie Thi\\u00e9baux\"},{\"authorId\":null,\"name\":\"Brian C. Williams\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"RAO*: An algorithm for chanceconstrained POMDP\\u2019s\",\"url\":\"\",\"venue\":\"AAAI, pages 3308\\u20133314. AAAI Press,\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144325663\",\"name\":\"K. Chatterjee\"},{\"authorId\":\"2551464\",\"name\":\"Zuzana Kom\\u00e1rkov\\u00e1\"},{\"authorId\":\"51110835\",\"name\":\"Jan Kretinsky\"}],\"doi\":\"10.1109/LICS.2015.32\",\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"c1726a487504f8f22252d15e0b3c046b5b74bdb8\",\"title\":\"Unifying Two Views on Multiple Mean-Payoff Objectives in Markov Decision Processes\",\"url\":\"https://www.semanticscholar.org/paper/c1726a487504f8f22252d15e0b3c046b5b74bdb8\",\"venue\":\"LICS 2015\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1387890355\",\"name\":\"H. Kress-Gazit\"},{\"authorId\":\"1682745\",\"name\":\"Georgios Fainekos\"},{\"authorId\":\"143770945\",\"name\":\"George J. Pappas\"}],\"doi\":\"10.1109/TRO.2009.2030225\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"642ef69cae7eb6eff384bae489ddea045e8fee38\",\"title\":\"Temporal-Logic-Based Reactive Mission and Motion Planning\",\"url\":\"https://www.semanticscholar.org/paper/642ef69cae7eb6eff384bae489ddea045e8fee38\",\"venue\":\"IEEE Transactions on Robotics\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"St\\u00e9phane Ross\"},{\"authorId\":null,\"name\":\"Joelle Pineau\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Ap - proximate linear programming for constrained partially observable Markov decision processes\",\"url\":\"\",\"venue\":\"VMCAI , volume 8931 of LNCS\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40639912\",\"name\":\"P. Santana\"},{\"authorId\":\"1685896\",\"name\":\"S. Thi\\u00e9baux\"},{\"authorId\":\"144604297\",\"name\":\"B. Williams\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"cb9876f2c54a50d53ac308f8666d788171a4a17b\",\"title\":\"RAO*: An Algorithm for Chance-Constrained POMDP's\",\"url\":\"https://www.semanticscholar.org/paper/cb9876f2c54a50d53ac308f8666d788171a4a17b\",\"venue\":\"AAAI\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143605196\",\"name\":\"K. Daly\"}],\"doi\":\"10.1023/A:1017101832468\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"de84de57c1f0201eae8f914318723e12a150e15e\",\"title\":\"Volume 7\",\"url\":\"https://www.semanticscholar.org/paper/de84de57c1f0201eae8f914318723e12a150e15e\",\"venue\":\"\",\"year\":1998},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144102674\",\"name\":\"C. Papadimitriou\"},{\"authorId\":\"144224173\",\"name\":\"J. Tsitsiklis\"}],\"doi\":\"10.1287/moor.12.3.441\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d51eb16dfed68bf6e16b8b4516d607370b91189a\",\"title\":\"The Complexity of Markov Decision Processes\",\"url\":\"https://www.semanticscholar.org/paper/d51eb16dfed68bf6e16b8b4516d607370b91189a\",\"venue\":\"Math. Oper. Res.\",\"year\":1987},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2934040\",\"name\":\"Boris Defourny\"},{\"authorId\":\"1751167\",\"name\":\"D. Ernst\"},{\"authorId\":\"1695713\",\"name\":\"L. Wehenkel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4f3d999740d88726ade2baf64e3019bef1c07949\",\"title\":\"Risk-aware decision making and dynamic programming\",\"url\":\"https://www.semanticscholar.org/paper/4f3d999740d88726ade2baf64e3019bef1c07949\",\"venue\":\"\",\"year\":2008},{\"arxivId\":\"cs/9605103\",\"authors\":[{\"authorId\":\"1709512\",\"name\":\"L. Kaelbling\"},{\"authorId\":\"144885169\",\"name\":\"M. Littman\"},{\"authorId\":\"1760402\",\"name\":\"A. Moore\"}],\"doi\":\"10.1613/jair.301\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"12d1d070a53d4084d88a77b8b143bad51c40c38f\",\"title\":\"Reinforcement Learning: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/12d1d070a53d4084d88a77b8b143bad51c40c38f\",\"venue\":\"J. Artif. Intell. Res.\",\"year\":1996},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"David Silver\"},{\"authorId\":null,\"name\":\"Joel Veness. Monte-Carlo planning in large POMDPs\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In NIPS 23\",\"url\":\"\",\"venue\":\"pages 2164\\u20132172. Curran Associates, Inc.,\",\"year\":2010},{\"arxivId\":\"1411.0835\",\"authors\":[{\"authorId\":\"1832722\",\"name\":\"Mickael Randour\"},{\"authorId\":\"1902441\",\"name\":\"Jean-Fran\\u00e7ois Raskin\"},{\"authorId\":\"3002611\",\"name\":\"O. Sankur\"}],\"doi\":\"10.1007/978-3-662-46081-8_1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cfa6113c014cfa32819bddf243ed096edd63317f\",\"title\":\"Variations on the Stochastic Shortest Path Problem\",\"url\":\"https://www.semanticscholar.org/paper/cfa6113c014cfa32819bddf243ed096edd63317f\",\"venue\":\"VMCAI\",\"year\":2015},{\"arxivId\":\"1401.3436\",\"authors\":[{\"authorId\":\"1700433\",\"name\":\"S. Ross\"},{\"authorId\":\"145134886\",\"name\":\"Joelle Pineau\"},{\"authorId\":\"1751565\",\"name\":\"S. Paquet\"},{\"authorId\":\"1399443272\",\"name\":\"B. Chaib-draa\"}],\"doi\":\"10.1613/jair.2567\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0c0107a2f211bdb889cdede2cbf8b6eaf49e6dbb\",\"title\":\"Online Planning Algorithms for POMDPs\",\"url\":\"https://www.semanticscholar.org/paper/0c0107a2f211bdb889cdede2cbf8b6eaf49e6dbb\",\"venue\":\"J. Artif. Intell. Res.\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Dongho Kim\"},{\"authorId\":null,\"name\":\"Jaesong Lee\"},{\"authorId\":null,\"name\":\"Kee-Eung Kim\"},{\"authorId\":null,\"name\":\"Pascal Poupart. Point-based value iteration for constrain POMDPs\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In IJCAI\",\"url\":\"\",\"venue\":\"pages 1968\\u20131974,\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Krishnendu Chatterjee\"},{\"authorId\":null,\"name\":\"Petr Novotn\\u00fd\"},{\"authorId\":null,\"name\":\"Guillermo A. P\\u00e9rez\"},{\"authorId\":null,\"name\":\"Jean-Fran\\u00e7ois Raskin\"},{\"authorId\":null,\"name\":\"Dorde Zikelic. Optimizing expectation with guarantees in AAAI\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"pages 3725\\u20133732\",\"url\":\"\",\"venue\":\"AAAI Press,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Krishnendu Chatterjee\"},{\"authorId\":null,\"name\":\"Adri\\u00e1n Elgy\\u00fctt\"},{\"authorId\":null,\"name\":\"Petr Novotn\\u00fd\"},{\"authorId\":null,\"name\":\"Owen Rouill\\u00e9\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Expectation Optimization with Probabilistic Guarantees in POMDPs with Discounted-sum Objectives\",\"url\":\"\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144885169\",\"name\":\"M. Littman\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b98ddfa5080620f00968ba439eff2e7e235ff5d5\",\"title\":\"Algorithms for Sequential Decision Making\",\"url\":\"https://www.semanticscholar.org/paper/b98ddfa5080620f00968ba439eff2e7e235ff5d5\",\"venue\":\"\",\"year\":1996},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1734775\",\"name\":\"E. Altman\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3cc2608fd77b9b65f5bd378e8797b2ab1b8acde7\",\"title\":\"Constrained Markov Decision Processes\",\"url\":\"https://www.semanticscholar.org/paper/3cc2608fd77b9b65f5bd378e8797b2ab1b8acde7\",\"venue\":\"\",\"year\":1999},{\"arxivId\":\"1207.4166\",\"authors\":[{\"authorId\":\"48658160\",\"name\":\"T. Smith\"},{\"authorId\":\"1719955\",\"name\":\"R. Simmons\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"44569efce398e5f5db22e505c38a7bc5f9c4df2c\",\"title\":\"Heuristic Search Value Iteration for POMDPs\",\"url\":\"https://www.semanticscholar.org/paper/44569efce398e5f5db22e505c38a7bc5f9c4df2c\",\"venue\":\"UAI\",\"year\":2004},{\"arxivId\":\"1411.3880\",\"authors\":[{\"authorId\":\"144325663\",\"name\":\"K. Chatterjee\"},{\"authorId\":\"40261011\",\"name\":\"Martin Chmelik\"},{\"authorId\":\"47495799\",\"name\":\"Raghav Gupta\"},{\"authorId\":\"2661277\",\"name\":\"Ayush Kanodia\"}],\"doi\":\"10.1016/j.artint.2016.01.007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"42b405f685e1ac42a7138a6dcb492917d4ff3954\",\"title\":\"Optimal cost almost-sure reachability in POMDPs\",\"url\":\"https://www.semanticscholar.org/paper/42b405f685e1ac42a7138a6dcb492917d4ff3954\",\"venue\":\"Artif. Intell.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"St\\u00e9phane Ross\"},{\"authorId\":null,\"name\":\"Joelle Pineau\"},{\"authorId\":null,\"name\":\"S\\u00e9bastien Paquet\"},{\"authorId\":null,\"name\":\"Brahim Chaib-draa. Online planning algorithms for POMDPs. Res\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"JAIR)\",\"url\":\"\",\"venue\":\"32:663\\u2013 704,\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"144056327\",\"name\":\"J. Veness\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f115acbd94451f58a5bc5062c1d7e6707e5be1f0\",\"title\":\"Monte-Carlo Planning in Large POMDPs\",\"url\":\"https://www.semanticscholar.org/paper/f115acbd94451f58a5bc5062c1d7e6707e5be1f0\",\"venue\":\"NIPS\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Mickael Randour\"},{\"authorId\":null,\"name\":\"Jean-Fran\\u00e7ois Raskin\"},{\"authorId\":null,\"name\":\"Ocan Sankur. Variations on the stochastic shortest path VMCAI\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"volume 8931 of LNCS\",\"url\":\"\",\"venue\":\"pages 1\\u201318. Springer,\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"69015072\",\"name\":\"R. A. Howard\"}],\"doi\":\"10.2307/2312519\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"95729d4c1596435344cb5a44e5c2680bf6d1c731\",\"title\":\"Dynamic Programming and Markov Processes\",\"url\":\"https://www.semanticscholar.org/paper/95729d4c1596435344cb5a44e5c2680bf6d1c731\",\"venue\":\"\",\"year\":1960},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1692869\",\"name\":\"E. Feinberg\"},{\"authorId\":\"7300196\",\"name\":\"A. Shwartz\"}],\"doi\":\"10.1287/moor.20.2.302\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf418e5ff1623104bd451bcd422937f25236d001\",\"title\":\"Constrained Markov Decision Models with Weighted Discounted Rewards\",\"url\":\"https://www.semanticscholar.org/paper/cf418e5ff1623104bd451bcd422937f25236d001\",\"venue\":\"Math. Oper. Res.\",\"year\":1995},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144325663\",\"name\":\"K. Chatterjee\"},{\"authorId\":\"40136108\",\"name\":\"P. Novotn\\u00fd\"},{\"authorId\":\"145275189\",\"name\":\"G. P\\u00e9rez\"},{\"authorId\":\"1902441\",\"name\":\"Jean-Fran\\u00e7ois Raskin\"},{\"authorId\":\"2069371\",\"name\":\"Dorde Zikelic\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"78a51ad9b488fac5dd192baba8c8cf8d21125e32\",\"title\":\"Optimizing Expectation with Guarantees in POMDPs\",\"url\":\"https://www.semanticscholar.org/paper/78a51ad9b488fac5dd192baba8c8cf8d21125e32\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":\"1309.5439\",\"authors\":[{\"authorId\":\"2611279\",\"name\":\"V. Bruy\\u00e8re\"},{\"authorId\":\"3226100\",\"name\":\"E. Filiot\"},{\"authorId\":\"1832722\",\"name\":\"Mickael Randour\"},{\"authorId\":\"1902441\",\"name\":\"Jean-Fran\\u00e7ois Raskin\"}],\"doi\":\"10.4230/LIPIcs.STACS.2014.199\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e1e37564a4800a16aee9839f6b3e420c84727ccb\",\"title\":\"Meet Your Expectations With Guarantees: Beyond Worst-Case Synthesis in Quantitative Games\",\"url\":\"https://www.semanticscholar.org/paper/e1e37564a4800a16aee9839f6b3e420c84727ccb\",\"venue\":\"STACS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1709512\",\"name\":\"L. Kaelbling\"},{\"authorId\":\"144885169\",\"name\":\"M. Littman\"},{\"authorId\":\"2453007\",\"name\":\"A. Cassandra\"}],\"doi\":\"10.1016/S0004-3702(98)00023-X\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"116d7798c1123cf7fad4176e98f58fd49de4f8f1\",\"title\":\"Planning and Acting in Partially Observable Stochastic Domains\",\"url\":\"https://www.semanticscholar.org/paper/116d7798c1123cf7fad4176e98f58fd49de4f8f1\",\"venue\":\"Artif. Intell.\",\"year\":1998},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35335083\",\"name\":\"R. Thrall\"}],\"doi\":\"10.21236/ada049700\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1b4b9507d9ff065cc5a3d4a30d604eb4ec41bfe2\",\"title\":\"Mathematics of Operations Research.\",\"url\":\"https://www.semanticscholar.org/paper/1b4b9507d9ff065cc5a3d4a30d604eb4ec41bfe2\",\"venue\":\"\",\"year\":1978},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Stuart J. Russell\"},{\"authorId\":null,\"name\":\"Peter Norvig\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Artificial Intelligence - A Modern Approach (3\",\"url\":\"\",\"venue\":\"internat. ed.). Pearson Education,\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2726706\",\"name\":\"N. B\\u00e4uerle\"},{\"authorId\":\"1707387\",\"name\":\"U. Rieder\"}],\"doi\":\"10.1365/S13291-010-0007-2\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b2db5541059288472ca246acdca6ead949326864\",\"title\":\"Markov Decision Processes\",\"url\":\"https://www.semanticscholar.org/paper/b2db5541059288472ca246acdca6ead949326864\",\"venue\":\"\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1709512\",\"name\":\"L. Kaelbling\"},{\"authorId\":\"2453007\",\"name\":\"A. Cassandra\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bd5faed84e43399d465e6133016f374842e8c352\",\"title\":\"Exact and approximate algorithms for partially observable markov decision processes\",\"url\":\"https://www.semanticscholar.org/paper/bd5faed84e43399d465e6133016f374842e8c352\",\"venue\":\"\",\"year\":1998},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34908205\",\"name\":\"L. Kocsis\"},{\"authorId\":\"40868287\",\"name\":\"Csaba Szepesvari\"}],\"doi\":\"10.1007/11871842_29\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e635d81a617d1239232a9c9a11a196c53dab8240\",\"title\":\"Bandit Based Monte-Carlo Planning\",\"url\":\"https://www.semanticscholar.org/paper/e635d81a617d1239232a9c9a11a196c53dab8240\",\"venue\":\"ECML\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144108775\",\"name\":\"P. Hou\"},{\"authorId\":\"1805457\",\"name\":\"William Yeoh\"},{\"authorId\":\"1718824\",\"name\":\"Pradeep Varakantham\"}],\"doi\":null,\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"caa4b95c11b4ac6b2ee1d1de4de67632e81149d8\",\"title\":\"Solving Risk-Sensitive POMDPs With and Without Cost Observations\",\"url\":\"https://www.semanticscholar.org/paper/caa4b95c11b4ac6b2ee1d1de4de67632e81149d8\",\"venue\":\"AAAI\",\"year\":2016},{\"arxivId\":\"1609.03250\",\"authors\":[{\"authorId\":\"3337002\",\"name\":\"A. Somani\"},{\"authorId\":\"50699003\",\"name\":\"Nan Ye\"},{\"authorId\":\"1384318941\",\"name\":\"David Hsu\"},{\"authorId\":\"1740222\",\"name\":\"Wee Sun Lee\"}],\"doi\":\"10.1613/jair.5328\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"270722c0233562d6c423d16d36b2c4adc5ed0829\",\"title\":\"DESPOT: Online POMDP Planning with Regularization\",\"url\":\"https://www.semanticscholar.org/paper/270722c0233562d6c423d16d36b2c4adc5ed0829\",\"venue\":\"NIPS\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3026258\",\"name\":\"A. Undurti\"},{\"authorId\":\"1713935\",\"name\":\"J. How\"}],\"doi\":\"10.1109/ROBOT.2010.5509743\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5ae0df7ab14f05bdcb8ad1de6fa96b74d7c663ca\",\"title\":\"An online algorithm for constrained POMDPs\",\"url\":\"https://www.semanticscholar.org/paper/5ae0df7ab14f05bdcb8ad1de6fa96b74d7c663ca\",\"venue\":\"2010 IEEE International Conference on Robotics and Automation\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1807041\",\"name\":\"P. Poupart\"},{\"authorId\":\"8109317\",\"name\":\"Aarti Malhotra\"},{\"authorId\":\"46905069\",\"name\":\"P. Pei\"},{\"authorId\":\"1741330\",\"name\":\"Kee-Eung Kim\"},{\"authorId\":\"2717154\",\"name\":\"Bongseok Goh\"},{\"authorId\":\"1687780\",\"name\":\"Michael Bowling\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7190d3e96e02e515b2cc5cb67375002a17a0cfa2\",\"title\":\"Approximate Linear Programming for Constrained Partially Observable Markov Decision Processes\",\"url\":\"https://www.semanticscholar.org/paper/7190d3e96e02e515b2cc5cb67375002a17a0cfa2\",\"venue\":\"AAAI\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145107462\",\"name\":\"S. Russell\"},{\"authorId\":\"2784519\",\"name\":\"Peter Norvig\"}],\"doi\":\"10.5860/choice.33-1577\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3524cdf7cf8344e7eb74886f71fcbb5c6732c337\",\"title\":\"Artificial Intelligence: A Modern Approach\",\"url\":\"https://www.semanticscholar.org/paper/3524cdf7cf8344e7eb74886f71fcbb5c6732c337\",\"venue\":\"\",\"year\":1995},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Levente Kocsis\"},{\"authorId\":null,\"name\":\"Csaba Szepesv\\u00e1ri. Bandit Based Monte-Carlo Planning. In ECML\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"volume 4212 of LNCS\",\"url\":\"\",\"venue\":\"pages 282\\u2013293. Springer,\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Pascal Poupart\"},{\"authorId\":null,\"name\":\"Aarti Malhotra\"},{\"authorId\":null,\"name\":\"Pei Pei\"},{\"authorId\":null,\"name\":\"Kee-Eung Kim\"},{\"authorId\":null,\"name\":\"Bongseok Goh\"},{\"authorId\":null,\"name\":\"Michael Bowling. Approximate linear programming for constr AAAI\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"pages 3342\\u20133348\",\"url\":\"\",\"venue\":\"AAAI Press,\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2595627\",\"name\":\"H. Kurniawati\"},{\"authorId\":\"145463096\",\"name\":\"D. Hsu\"},{\"authorId\":\"1740222\",\"name\":\"Wee Sun Lee\"}],\"doi\":\"10.15607/RSS.2008.IV.009\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6c485f3d910d46c88f00cdaa9883cc7c43805fb5\",\"title\":\"SARSOP: Efficient Point-Based POMDP Planning by Approximating Optimally Reachable Belief Spaces\",\"url\":\"https://www.semanticscholar.org/paper/6c485f3d910d46c88f00cdaa9883cc7c43805fb5\",\"venue\":\"Robotics: Science and Systems\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92804988\",\"name\":\"J. Sprauel\"},{\"authorId\":\"6247481\",\"name\":\"A. Kolobov\"},{\"authorId\":\"1403725425\",\"name\":\"F. Teichteil-K\\u00f6nigsbuch\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b2f170819885e3abae8f902695b9dc5c35159e52\",\"title\":\"Saturated Path-Constrained MDP: Planning under Uncertainty and Deterministic Model-Checking Constraints\",\"url\":\"https://www.semanticscholar.org/paper/b2f170819885e3abae8f902695b9dc5c35159e52\",\"venue\":\"AAAI\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ping Hou\"},{\"authorId\":null,\"name\":\"William Yeoh\"},{\"authorId\":null,\"name\":\"Pradeep Varakantham. Solving risk-sensitive POMDPs with\"},{\"authorId\":null,\"name\":\"without cost observations. In AAAI\"}],\"doi\":null,\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"pages 3138\\u20133144\",\"url\":\"\",\"venue\":\"AAAI Press,\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Aditya Undurti\"},{\"authorId\":null,\"name\":\"Jonathan P How. An online algorithm for constrained POMDPs. ICRA\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"pages 3966\\u20133973\",\"url\":\"\",\"venue\":\"IEEE,\",\"year\":2010}],\"title\":\"Expectation Optimization with Probabilistic Guarantees in POMDPs with Discounted-sum Objectives\",\"topics\":[{\"topic\":\"Mathematical optimization\",\"topicId\":\"89\",\"url\":\"https://www.semanticscholar.org/topic/89\"},{\"topic\":\"Risk aversion\",\"topicId\":\"107174\",\"url\":\"https://www.semanticscholar.org/topic/107174\"},{\"topic\":\"Online algorithm\",\"topicId\":\"40041\",\"url\":\"https://www.semanticscholar.org/topic/40041\"},{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"},{\"topic\":\"Decision theory\",\"topicId\":\"31461\",\"url\":\"https://www.semanticscholar.org/topic/31461\"},{\"topic\":\"Markov decision process\",\"topicId\":\"2556\",\"url\":\"https://www.semanticscholar.org/topic/2556\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Observable\",\"topicId\":\"479\",\"url\":\"https://www.semanticscholar.org/topic/479\"},{\"topic\":\"Anytime algorithm\",\"topicId\":\"178783\",\"url\":\"https://www.semanticscholar.org/topic/178783\"},{\"topic\":\"Markov chain\",\"topicId\":\"5418\",\"url\":\"https://www.semanticscholar.org/topic/5418\"}],\"url\":\"https://www.semanticscholar.org/paper/aa1cc90d0047e1afb70fbba9547dc25af686cac7\",\"venue\":\"IJCAI\",\"year\":2018}\n"