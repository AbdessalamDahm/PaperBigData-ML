"{\"abstract\":\"AI systems that learn through reward feedback about the actions they take are increasingly deployed in domains that have significant impact on our daily life. In many cases the rewards should not be the only guiding criteria, as there are additional constraints and/or priorities imposed by regulations, values, preferences, or ethical principles. We detail a novel online system, based on an extension of the contextual bandits framework, that learns a set of behavioral constraints by observation and uses these constraints as a guide when making decisions in an online setting while still being reactive to reward feedback. In addition, our system can highlight features of the context which are more predicted to be more rewarding and/or are in line with the behavioral constraints. We demonstrate the system by building an interactive interface for an online movie recommendation agent and show that our system is able to act within a set of behavior constraints without significantly degrading overall performance. 1 Overview and Related Work In online decision settings an agent must select one out of several possible actions, e.g., recommending a movie to a particular user, or proposing a treatment to a patient in a clinical trial. Each of these actions is associated with a context, e.g., a user profile, and feedback, e.g., the reward or rating, is only observed for the chosen option. In these online decision settings the agent must learn the inherent trade-off between exploration, identifying and understanding the reward from an action, and exploitation, gathering as much reward as possible from an action. These decision problems are traditionally modeled for online settings as a multi-armed bandit (MAB) problem [Mary et al., 2015; Villar et al., 2015] and is used to solve many real-world problems [Sutton and Barto, 2017; Mnih et al., 2013]. In the MAB setting there are K arms, each associated with a fixed but unknown reward probability distribution [Lai and Robbins, 1985; Auer et al., 2002]. At each time step, an agent plays an arm, i.e., recommends an item to a user, and receives a reward that follows the selected arm\\u2019s probability distribution, independent of the previous actions. In the generalized contextual multi-armed bandit (CMAB) problem the agent observes a d-dimensional feature vector, or context before making a decision. Over time, the agent learns the relationship between contexts and rewards; LINUCB [Li et al., 2010; Chu et al., 2011] and Contextual Thompson Sampling [Agrawal and Goyal, 2013] are the most successful algorithms for this domain. We consider cases where the behavior of the online agent may need to be restricted in its choice of arm for a given context by laws, values, preferences, or ethical principles [Sen, 1974]. Constrained or ethical decision making has become popular in CS and AI [Briggs and Scheutz, 2015; Armstrong, 2015] with most of the work focused on teaching a computer system to act within ethical or legal guidelines. We apply a behavioral constraint to the agent that is independent of the reward. For instance, a parent or guardian group may want the agent to not recommend certain types of movies to children, even if this recommendation could lead to a high reward. There is recent work on combining contextual bandits with a budget of arm pulls and/or time constraints [Wu et al., 2015; Agrawal and Goyal, 2016] but none use policy constraints. These exogenous behavioral constraints are guidelines that should be followed by the agent and not updated online. Hence, they should either be explicitly given or learnt from examples, before the online agent begins taking actions. In many settings we may not have access to the constraints as an explicit set of rules or function, we may only have access to examples of constrained behavior from a doctor, or a set of decisions made by a parent, e.g., when setting up a new online account. Contribution. We build an online agent using novel extensions to the CMAB algorithms who is able to learn constraints demonstrated as examples of appropriate actions and apply these constraints in an online recommendation setting while accruing as much reward as possible. For flexibility, we expose a parameter of the algorithm called \\u03c3online that allows the system designer to transition between \\u03c3online = 0.0 where the agent is only following the learned constraints and is insensitive to the online reward to \\u03c3online = 1.0 where the agent is only following the online rewards. We demonstrate an example constrained movie recommendation system using real-world data. Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence (IJCAI-18)\",\"arxivId\":null,\"authors\":[{\"authorId\":\"49858381\",\"name\":\"A. Balakrishnan\",\"url\":\"https://www.semanticscholar.org/author/49858381\"},{\"authorId\":\"1744675\",\"name\":\"Djallel Bouneffouf\",\"url\":\"https://www.semanticscholar.org/author/1744675\"},{\"authorId\":\"143999398\",\"name\":\"Nicholas Mattei\",\"url\":\"https://www.semanticscholar.org/author/143999398\"},{\"authorId\":\"144833426\",\"name\":\"F. Rossi\",\"url\":\"https://www.semanticscholar.org/author/144833426\"}],\"citationVelocity\":10,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"29326342\",\"name\":\"Candice Schumann\"},{\"authorId\":\"50650588\",\"name\":\"Jeffrey S. Foster\"},{\"authorId\":\"1405578188\",\"name\":\"N. Mattei\"},{\"authorId\":\"1718974\",\"name\":\"John P. Dickerson\"}],\"doi\":\"10.5555/3398761.3398960\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1b96b89d5b3ba444126cebefdfc665d3866f14f0\",\"title\":\"We Need Fairness and Explainability in Algorithmic Hiring\",\"url\":\"https://www.semanticscholar.org/paper/1b96b89d5b3ba444126cebefdfc665d3866f14f0\",\"venue\":\"AAMAS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134520439\",\"name\":\"Nobuhito Manome\"},{\"authorId\":\"2856885\",\"name\":\"Shuji Shinohara\"},{\"authorId\":\"2610614\",\"name\":\"Kouta Suzuki\"},{\"authorId\":\"29326748\",\"name\":\"Kosuke Tomonaga\"},{\"authorId\":\"1797927\",\"name\":\"S. Mitsuyoshi\"}],\"doi\":\"10.1007/978-3-030-30487-4_41\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bc37e424e05b35ec31ab072859ec1cc03d38d14b\",\"title\":\"A Multi-armed Bandit Algorithm Available in Stationary or Non-stationary Environments Using Self-organizing Maps\",\"url\":\"https://www.semanticscholar.org/paper/bc37e424e05b35ec31ab072859ec1cc03d38d14b\",\"venue\":\"ICANN\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50187857\",\"name\":\"Muhammad Faisal\"},{\"authorId\":\"86932678\",\"name\":\"A. Hameed\"},{\"authorId\":\"2775580\",\"name\":\"A. Khattak\"}],\"doi\":\"10.1109/ICET48972.2019.8994389\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e8bdc85b2d869880f5cdda81872b7562ae5ad40e\",\"title\":\"Recommending Movies on User's Current Preferences via Deep Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/e8bdc85b2d869880f5cdda81872b7562ae5ad40e\",\"venue\":\"2019 15th International Conference on Emerging Technologies (ICET)\",\"year\":2019},{\"arxivId\":\"2007.11416\",\"authors\":[{\"authorId\":\"1744675\",\"name\":\"Djallel Bouneffouf\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7208cb004ff2539fd7f82ca6995021fa33bb56d9\",\"title\":\"Spectral Clustering using Eigenspectrum Shape Based Nystrom Sampling\",\"url\":\"https://www.semanticscholar.org/paper/7208cb004ff2539fd7f82ca6995021fa33bb56d9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2893945\",\"name\":\"Xiaochuan Lin\"},{\"authorId\":\"145680173\",\"name\":\"Fei Zhang\"},{\"authorId\":\"1476776750\",\"name\":\"Wei-Hui Jiang\"},{\"authorId\":\"1476824514\",\"name\":\"Jiachen Liang\"}],\"doi\":\"10.1109/ICWAPR48189.2019.8946453\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"61e076291fc9a1f9234c6022fbe95c70dcc925f7\",\"title\":\"Improvement of Similarity Coefficients Based on Item Rating and Item Genre\",\"url\":\"https://www.semanticscholar.org/paper/61e076291fc9a1f9234c6022fbe95c70dcc925f7\",\"venue\":\"2019 International Conference on Wavelet Analysis and Pattern Recognition (ICWAPR)\",\"year\":2019},{\"arxivId\":\"1809.08350\",\"authors\":[{\"authorId\":\"2661977\",\"name\":\"Andrea Loreggia\"},{\"authorId\":\"1405578188\",\"name\":\"N. Mattei\"},{\"authorId\":\"144740044\",\"name\":\"F. Rossi\"},{\"authorId\":\"1712010\",\"name\":\"K. Venable\"}],\"doi\":\"10.1007/978-3-030-56150-5_11\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cb90d5ea3a95b4c6ec904f622f51d752f506636e\",\"title\":\"CPMetric: Deep Siamese Networks for Metric Learning on Structured Preferences\",\"url\":\"https://www.semanticscholar.org/paper/cb90d5ea3a95b4c6ec904f622f51d752f506636e\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"1812.03980\",\"authors\":[{\"authorId\":\"144833426\",\"name\":\"F. Rossi\"},{\"authorId\":\"143999398\",\"name\":\"Nicholas Mattei\"}],\"doi\":\"10.1609/aaai.v33i01.33019785\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bd318e959236b0d33a7567b6d3afc8d5e92b8ea3\",\"title\":\"Building Ethically Bounded AI\",\"url\":\"https://www.semanticscholar.org/paper/bd318e959236b0d33a7567b6d3afc8d5e92b8ea3\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"2007.06368\",\"authors\":[{\"authorId\":\"1744675\",\"name\":\"Djallel Bouneffouf\"},{\"authorId\":\"148155763\",\"name\":\"Sohini Upadhyay\"},{\"authorId\":\"2216967\",\"name\":\"Y. Khazaeni\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e71fdea2ebc9a90596a9add3232c511f9bb6ed3f\",\"title\":\"Contextual Bandit with Missing Rewards\",\"url\":\"https://www.semanticscholar.org/paper/e71fdea2ebc9a90596a9add3232c511f9bb6ed3f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3411127\",\"name\":\"Ritesh Noothigattu\"},{\"authorId\":\"1744675\",\"name\":\"Djallel Bouneffouf\"},{\"authorId\":\"143999398\",\"name\":\"Nicholas Mattei\"},{\"authorId\":\"51438016\",\"name\":\"Rachita Chandra\"},{\"authorId\":\"46781068\",\"name\":\"Piyush Madan\"},{\"authorId\":\"1712865\",\"name\":\"Kush R. Varshney\"},{\"authorId\":\"143903370\",\"name\":\"Murray Campbell\"},{\"authorId\":\"36121427\",\"name\":\"M. Singh\"},{\"authorId\":\"118053141\",\"name\":\"F. Rossi\"}],\"doi\":\"10.1147/jrd.2019.2940428\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f5b6819e05e087d2bbae3ddb6d58d2ab4e1d7ca2\",\"title\":\"Teaching AI agents ethical values using reinforcement learning and policy orchestration\",\"url\":\"https://www.semanticscholar.org/paper/f5b6819e05e087d2bbae3ddb6d58d2ab4e1d7ca2\",\"venue\":\"IBM J. Res. Dev.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1832787\",\"name\":\"X. Zhou\"},{\"authorId\":\"143780737\",\"name\":\"D. Qin\"},{\"authorId\":\"3429888\",\"name\":\"Xiaolu Lu\"},{\"authorId\":\"49330176\",\"name\":\"Lei Chen\"},{\"authorId\":\"34853026\",\"name\":\"Y. Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"826ecdce35e8db40e10ddcb58327b4c231caa46d\",\"title\":\"Social Media Recommendation over Streams\",\"url\":\"https://www.semanticscholar.org/paper/826ecdce35e8db40e10ddcb58327b4c231caa46d\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1830413993\",\"name\":\"Raul Gonzalez Fabre\"},{\"authorId\":\"1830413980\",\"name\":\"Javier Camacho Ib\\u00e1\\u00f1ez\"},{\"authorId\":\"1830416607\",\"name\":\"Pedro Tejedor Escobar\"}],\"doi\":\"10.1007/s00146-020-01020-z\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"30c56981cbeca81e86f677e582cdee3d3ed0f80e\",\"title\":\"Moral control and ownership in AI systems\",\"url\":\"https://www.semanticscholar.org/paper/30c56981cbeca81e86f677e582cdee3d3ed0f80e\",\"venue\":\"AI & SOCIETY\",\"year\":2020},{\"arxivId\":\"1809.05720\",\"authors\":[{\"authorId\":\"49858381\",\"name\":\"A. Balakrishnan\"},{\"authorId\":\"1744675\",\"name\":\"Djallel Bouneffouf\"},{\"authorId\":\"143999398\",\"name\":\"Nicholas Mattei\"},{\"authorId\":\"144833426\",\"name\":\"F. Rossi\"}],\"doi\":\"10.1609/aaai.v33i01.33013\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d29d33f3b92b447d6011606be41b64439a1da088\",\"title\":\"Incorporating Behavioral Constraints in Online AI Systems\",\"url\":\"https://www.semanticscholar.org/paper/d29d33f3b92b447d6011606be41b64439a1da088\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144137911\",\"name\":\"T. Mandel\"},{\"authorId\":\"150139461\",\"name\":\"Jahnu Best\"},{\"authorId\":\"150286192\",\"name\":\"Randall H. Tanaka\"},{\"authorId\":\"150128022\",\"name\":\"Hiram Temple\"},{\"authorId\":\"150057513\",\"name\":\"Chansen Haili\"},{\"authorId\":\"1999663139\",\"name\":\"Sebastian J. Carter\"},{\"authorId\":\"1999758913\",\"name\":\"Kayla Schlechtinger\"},{\"authorId\":\"32765063\",\"name\":\"Roy Szeto\"}],\"doi\":\"10.1145/3415168\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5cd03c68c46e1f5f518a5a5455de7ef8f6fa068b\",\"title\":\"Using the Crowd to Prevent Harmful AI Behavior\",\"url\":\"https://www.semanticscholar.org/paper/5cd03c68c46e1f5f518a5a5455de7ef8f6fa068b\",\"venue\":\"Proc. ACM Hum. Comput. Interact.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41189343\",\"name\":\"A. E. Seghrouchni\"},{\"authorId\":\"1707363\",\"name\":\"D. Sarne\"},{\"authorId\":\"145960032\",\"name\":\"R. Goebel\"},{\"authorId\":\"144865865\",\"name\":\"Y. Tanaka\"}],\"doi\":\"10.1007/978-3-030-56150-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ccd6a93d74958ef8993f2b3102ccc4f913e33011\",\"title\":\"Artificial Intelligence. IJCAI 2019 International Workshops: Macao, China, August 10\\u201312, 2019, Revised Selected Best Papers\",\"url\":\"https://www.semanticscholar.org/paper/ccd6a93d74958ef8993f2b3102ccc4f913e33011\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"104724455\",\"name\":\"Ra\\u00fal Gonz\\u00e1lez Fabre\"},{\"authorId\":\"144301051\",\"name\":\"J. C. Ib\\u00e1\\u00f1ez\"},{\"authorId\":\"2006394017\",\"name\":\"Pedro Tejedor Escobar\"}],\"doi\":\"10.1007/S00146-020-01020-Z\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5e2c46e4703b6079215313ad47b06fdbc0fa134b\",\"title\":\"Moral control and ownership in AI systems\",\"url\":\"https://www.semanticscholar.org/paper/5e2c46e4703b6079215313ad47b06fdbc0fa134b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2006.10185\",\"authors\":[{\"authorId\":\"3124110\",\"name\":\"Aldo Pacchiano\"},{\"authorId\":\"103809454\",\"name\":\"Mohammad Ghavamzadeh\"},{\"authorId\":\"48771478\",\"name\":\"P. Bartlett\"},{\"authorId\":\"34710991\",\"name\":\"Heinrich Jiang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d830c7a19d18d864e354427abb4e2a2e07d865e4\",\"title\":\"Stochastic Bandits with Linear Constraints\",\"url\":\"https://www.semanticscholar.org/paper/d830c7a19d18d864e354427abb4e2a2e07d865e4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.06002\",\"authors\":[{\"authorId\":\"1746499\",\"name\":\"G. Booch\"},{\"authorId\":\"50499750\",\"name\":\"F. Fabiano\"},{\"authorId\":\"2522639\",\"name\":\"L. Horesh\"},{\"authorId\":\"2691347\",\"name\":\"K. Kate\"},{\"authorId\":\"1999970095\",\"name\":\"Jon Lenchner\"},{\"authorId\":\"34410599\",\"name\":\"Nick Linck\"},{\"authorId\":\"2661977\",\"name\":\"Andrea Loreggia\"},{\"authorId\":\"3377711\",\"name\":\"K. Murugesan\"},{\"authorId\":\"1405578188\",\"name\":\"N. Mattei\"},{\"authorId\":\"1740894307\",\"name\":\"Francesca Rossi\"},{\"authorId\":\"50784532\",\"name\":\"B. Srivastava\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"554eade16fb6040bbd21a72bacf903245d7458f1\",\"title\":\"Thinking Fast and Slow in AI\",\"url\":\"https://www.semanticscholar.org/paper/554eade16fb6040bbd21a72bacf903245d7458f1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.12574\",\"authors\":[{\"authorId\":\"148155763\",\"name\":\"Sohini Upadhyay\"},{\"authorId\":\"8202372\",\"name\":\"Mikhail Yurochkin\"},{\"authorId\":\"145625765\",\"name\":\"M. Agarwal\"},{\"authorId\":\"2216967\",\"name\":\"Y. Khazaeni\"},{\"authorId\":null,\"name\":\"Djallel Bouneffouf\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"516ed977c5d5e0082c100752b96585545f544317\",\"title\":\"Online Semi-Supervised Learning with Bandit Feedback\",\"url\":\"https://www.semanticscholar.org/paper/516ed977c5d5e0082c100752b96585545f544317\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134520439\",\"name\":\"Nobuhito Manome\"},{\"authorId\":\"2856885\",\"name\":\"Shuji Shinohara\"},{\"authorId\":\"2610614\",\"name\":\"Kouta Suzuki\"},{\"authorId\":\"29326748\",\"name\":\"Kosuke Tomonaga\"},{\"authorId\":\"1797927\",\"name\":\"S. Mitsuyoshi\"}],\"doi\":\"10.1109/IJCNN.2019.8851819\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7410d52b613f49459fb25141b2d21e3531e48ee0\",\"title\":\"SOM-based Algorithm for Multi-armed Bandit Problem\",\"url\":\"https://www.semanticscholar.org/paper/7410d52b613f49459fb25141b2d21e3531e48ee0\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":\"2005.02209\",\"authors\":[{\"authorId\":\"1744675\",\"name\":\"Djallel Bouneffouf\"},{\"authorId\":\"36925271\",\"name\":\"Emmanuelle Claeys\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a753742d003cffb6c6074be8b94e38b263222468\",\"title\":\"Hyper-parameter Tuning for the Contextual Bandit\",\"url\":\"https://www.semanticscholar.org/paper/a753742d003cffb6c6074be8b94e38b263222468\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40963316\",\"name\":\"Nicolas Gutowski\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6423e1300b1e20182cf3fdf4843edb3e400aeca7\",\"title\":\"Recommandation contextuelle de services : Application \\u00e0 la recommandation d'\\u00e9v\\u00e9nements culturels dans la ville intelligente. (Context-aware recommendation systems for cultural events recommendation in Smart Cities)\",\"url\":\"https://www.semanticscholar.org/paper/6423e1300b1e20182cf3fdf4843edb3e400aeca7\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10175775\",\"name\":\"A. Sepliarskaia\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"839c636b9b50bec2d1cbf1c35e26b219b2d0c48f\",\"title\":\"Understanding user goals by analyzing logged interactions and asking the right questions\",\"url\":\"https://www.semanticscholar.org/paper/839c636b9b50bec2d1cbf1c35e26b219b2d0c48f\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1557562242\",\"name\":\"Shan Zhong\"},{\"authorId\":\"120641788\",\"name\":\"Wenhao Ying\"},{\"authorId\":\"48283660\",\"name\":\"Xue-mei Chen\"},{\"authorId\":\"3176996\",\"name\":\"Qiming Fu\"}],\"doi\":\"10.1109/ACCESS.2020.2977463\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"60c6c1528135b4ee477e1e2b58058a6e6cdee2c6\",\"title\":\"An Adaptive Similarity-Measuring-Based CMAB Model for Recommendation System\",\"url\":\"https://www.semanticscholar.org/paper/60c6c1528135b4ee477e1e2b58058a6e6cdee2c6\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2004.01136\",\"authors\":[{\"authorId\":\"145788064\",\"name\":\"M. Yang\"},{\"authorId\":\"153082837\",\"name\":\"Qingyang Li\"},{\"authorId\":\"144559512\",\"name\":\"Zhiwei Qin\"},{\"authorId\":\"2778556\",\"name\":\"Jie-ping Ye\"}],\"doi\":\"10.1145/3366423.3380115\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3ad022f7e746baab201dcf8d1276ee3089fee242\",\"title\":\"Hierarchical Adaptive Contextual Bandits for Resource Constraint based Recommendation\",\"url\":\"https://www.semanticscholar.org/paper/3ad022f7e746baab201dcf8d1276ee3089fee242\",\"venue\":\"WWW\",\"year\":2020},{\"arxivId\":\"2007.11967\",\"authors\":[{\"authorId\":\"1744675\",\"name\":\"Djallel Bouneffouf\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dcca7ba2ae65f807b21a1ae8561d2928a8e2d9cf\",\"title\":\"Computing the Dirichlet-Multinomial Log-Likelihood Function\",\"url\":\"https://www.semanticscholar.org/paper/dcca7ba2ae65f807b21a1ae8561d2928a8e2d9cf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1809.07880\",\"authors\":[{\"authorId\":\"1729718\",\"name\":\"Shani Alkoby\"},{\"authorId\":\"51444860\",\"name\":\"Avilash Rath\"},{\"authorId\":\"143756910\",\"name\":\"P. Stone\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b267b163c7f5ebb2a44be84e7c7b8bddfea09d52\",\"title\":\"Teaching Social Behavior through Human Reinforcement for Ad hoc Teamwork - The STAR Framework: Extended Abstract\",\"url\":\"https://www.semanticscholar.org/paper/b267b163c7f5ebb2a44be84e7c7b8bddfea09d52\",\"venue\":\"AAMAS\",\"year\":2019},{\"arxivId\":\"1901.01003\",\"authors\":[{\"authorId\":\"1832787\",\"name\":\"X. Zhou\"},{\"authorId\":\"143780737\",\"name\":\"D. Qin\"},{\"authorId\":\"40505029\",\"name\":\"Xiaolu Lu\"},{\"authorId\":\"36302865\",\"name\":\"L. Chen\"},{\"authorId\":\"34853026\",\"name\":\"Y. Zhang\"}],\"doi\":\"10.1109/ICDE.2019.00088\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f3aac5c4aef8aa017b40c489d645e387b5838eed\",\"title\":\"Online Social Media Recommendation Over Streams\",\"url\":\"https://www.semanticscholar.org/paper/f3aac5c4aef8aa017b40c489d645e387b5838eed\",\"venue\":\"2019 IEEE 35th International Conference on Data Engineering (ICDE)\",\"year\":2019},{\"arxivId\":\"1809.08343\",\"authors\":[{\"authorId\":\"3411127\",\"name\":\"Ritesh Noothigattu\"},{\"authorId\":\"1744675\",\"name\":\"Djallel Bouneffouf\"},{\"authorId\":\"143999398\",\"name\":\"Nicholas Mattei\"},{\"authorId\":\"51438016\",\"name\":\"Rachita Chandra\"},{\"authorId\":\"46781068\",\"name\":\"Piyush Madan\"},{\"authorId\":\"1712865\",\"name\":\"Kush R. Varshney\"},{\"authorId\":\"143903370\",\"name\":\"Murray Campbell\"},{\"authorId\":\"36121427\",\"name\":\"M. Singh\"},{\"authorId\":\"144833426\",\"name\":\"F. Rossi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d3793ae5b3b31f72605978b749e41811e6dcacd4\",\"title\":\"Interpretable Multi-Objective Reinforcement Learning through Policy Orchestration\",\"url\":\"https://www.semanticscholar.org/paper/d3793ae5b3b31f72605978b749e41811e6dcacd4\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2006.15194\",\"authors\":[{\"authorId\":\"1744675\",\"name\":\"Djallel Bouneffouf\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8cce3d32f6fc411dfffc210584ba0884801a4226\",\"title\":\"Online learning with Corrupted context: Corrupted Contextual Bandits\",\"url\":\"https://www.semanticscholar.org/paper/8cce3d32f6fc411dfffc210584ba0884801a4226\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":51608105,\"doi\":\"10.24963/ijcai.2018/843\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":false,\"paperId\":\"ffe6d7573bb2c4fbfac0cc474804b5b1734a1179\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"2490183\",\"name\":\"O. Vrieze\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"97d8789ca33e550b4c560867f5c2d82ddf5d1ef9\",\"title\":\"Principles and Practice of Marketing\",\"url\":\"https://www.semanticscholar.org/paper/97d8789ca33e550b4c560867f5c2d82ddf5d1ef9\",\"venue\":\"\",\"year\":1988},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Wei Chu\"},{\"authorId\":null,\"name\":\"Lihong Li\"},{\"authorId\":null,\"name\":\"Lev Reyzin\"},{\"authorId\":null,\"name\":\"Robert E. Schapire. Contextual bandits with linear payoff Proc\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"AISTATS\",\"url\":\"\",\"venue\":\"pages 208\\u2013214,\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Stuart Armstrong. Motivated value selection for artificia agents\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In Workshops of the 29th AAAI: AI\",\"url\":\"\",\"venue\":\"Ethics, and Society,\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Shipra Agrawal\"},{\"authorId\":null,\"name\":\"Navin Goyal. Thompson sampling for contextual bandits wi payoffs\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In ICML (3)\",\"url\":\"\",\"venue\":\"pages 127\\u2013135,\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J\\u00e9r\\u00e9mie Mary\"},{\"authorId\":null,\"name\":\"Romaric Gaudel\"},{\"authorId\":null,\"name\":\"Philippe Preux. Bandits\"},{\"authorId\":null,\"name\":\"recommender systems. In Machine Learning\"},{\"authorId\":null,\"name\":\"Optimization\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and Big Data\",\"url\":\"\",\"venue\":\"pages 325\\u2013 336,\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699645\",\"name\":\"R. Sutton\"},{\"authorId\":\"1730590\",\"name\":\"A. Barto\"}],\"doi\":\"10.1109/TNN.1998.712192\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"97efafdb4a3942ab3efba53ded7413199f79c054\",\"title\":\"Reinforcement Learning: An Introduction\",\"url\":\"https://www.semanticscholar.org/paper/97efafdb4a3942ab3efba53ded7413199f79c054\",\"venue\":\"IEEE Transactions on Neural Networks\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Shipra Agrawal\"},{\"authorId\":null,\"name\":\"Navin Goyal. Linear contextual bandits with knapsacks\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In Proceedings of Advances in Neural Information Processing Systems (NIPS 2016)\",\"url\":\"\",\"venue\":\"pages 3450\\u20133458,\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Lihong Li\"},{\"authorId\":null,\"name\":\"Wei Chu\"},{\"authorId\":null,\"name\":\"John Langford\"},{\"authorId\":null,\"name\":\"Robert E. Schapire. A contextual-bandit approach to perso Proc\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"19th WWW\",\"url\":\"\",\"venue\":\"pages 661\\u2013670, USA,\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1752396\",\"name\":\"G. Anastassiou\"},{\"authorId\":\"1711329\",\"name\":\"O. Duman\"}],\"doi\":\"10.1007/978-1-4614-6393-1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1f43f93a42d0d07c13f5872e784f9654566236e2\",\"title\":\"Advances in Applied Mathematics and Approximation Theory\",\"url\":\"https://www.semanticscholar.org/paper/1f43f93a42d0d07c13f5872e784f9654566236e2\",\"venue\":\"\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12363771\",\"name\":\"H. Owton\"}],\"doi\":\"10.1080/08893675.2018.1396736\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"60a222d0ddcb05ea5467c13934bcc382f8b000ed\",\"title\":\"Sorry\",\"url\":\"https://www.semanticscholar.org/paper/60a222d0ddcb05ea5467c13934bcc382f8b000ed\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1507.08025\",\"authors\":[{\"authorId\":\"3194835\",\"name\":\"S. Villar\"},{\"authorId\":\"47929819\",\"name\":\"J. Bowden\"},{\"authorId\":\"1948552\",\"name\":\"J. Wason\"}],\"doi\":\"10.1214/14-STS504\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1240aab236e13e83954c49b4be3c086b4311b4ae\",\"title\":\"Multi-armed Bandit Models for the Optimal Design of Clinical Trials: Benefits and Challenges.\",\"url\":\"https://www.semanticscholar.org/paper/1240aab236e13e83954c49b4be3c086b4311b4ae\",\"venue\":\"Statistical science : a review journal of the Institute of Mathematical Statistics\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145192090\",\"name\":\"F. M. Harper\"},{\"authorId\":\"2478310\",\"name\":\"J. Konstan\"}],\"doi\":\"10.1145/2827872\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"276ebc620a8976026bd2d03582b9ecfa3738d43c\",\"title\":\"The MovieLens Datasets: History and Context\",\"url\":\"https://www.semanticscholar.org/paper/276ebc620a8976026bd2d03582b9ecfa3738d43c\",\"venue\":\"TIIS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144299726\",\"name\":\"Thomas G. Dietterich\"}],\"doi\":\"10.1145/242224.242229\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aab43c9c33af00b718cf2ae374b861d49862a563\",\"title\":\"Machine learning\",\"url\":\"https://www.semanticscholar.org/paper/aab43c9c33af00b718cf2ae374b861d49862a563\",\"venue\":\"CSUR\",\"year\":1996},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Amartya Sen. Choice\"},{\"authorId\":null,\"name\":\"Ordering\"},{\"authorId\":null,\"name\":\"Morality\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Blackwell\",\"url\":\"\",\"venue\":\"Oxford,\",\"year\":1974},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"John Langford\"},{\"authorId\":null,\"name\":\"Tong Zhang. The Epoch-Greedy Algorithm for Contextual M Bandits\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In Proc\",\"url\":\"\",\"venue\":\"21st NIPS,\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143865718\",\"name\":\"V. Ferrari\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7142185fd2e86e922f609562f30820cd7c5af7f4\",\"title\":\"Advances in Neural Information Processing Systems (NIPS)\",\"url\":\"https://www.semanticscholar.org/paper/7142185fd2e86e922f609562f30820cd7c5af7f4\",\"venue\":\"\",\"year\":2007},{\"arxivId\":\"1312.5602\",\"authors\":[{\"authorId\":\"3255983\",\"name\":\"V. Mnih\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"},{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"2460849\",\"name\":\"Ioannis Antonoglou\"},{\"authorId\":\"1688276\",\"name\":\"Daan Wierstra\"},{\"authorId\":\"3137672\",\"name\":\"Martin A. Riedmiller\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"2319a491378867c7049b3da055c5df60e1671158\",\"title\":\"Playing Atari with Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/2319a491378867c7049b3da055c5df60e1671158\",\"venue\":\"ArXiv\",\"year\":2013}],\"title\":\"Using Contextual Bandits with Behavioral Constraints for Constrained Online Movie Recommendation\",\"topics\":[{\"topic\":\"Multi-armed bandit\",\"topicId\":\"85305\",\"url\":\"https://www.semanticscholar.org/topic/85305\"},{\"topic\":\"Algorithm\",\"topicId\":\"305\",\"url\":\"https://www.semanticscholar.org/topic/305\"},{\"topic\":\"Thompson sampling\",\"topicId\":\"516402\",\"url\":\"https://www.semanticscholar.org/topic/516402\"},{\"topic\":\"Feature vector\",\"topicId\":\"4255\",\"url\":\"https://www.semanticscholar.org/topic/4255\"},{\"topic\":\"International Joint Conference on Artificial Intelligence\",\"topicId\":\"453638\",\"url\":\"https://www.semanticscholar.org/topic/453638\"},{\"topic\":\"User profile\",\"topicId\":\"9007\",\"url\":\"https://www.semanticscholar.org/topic/9007\"},{\"topic\":\"User interface\",\"topicId\":\"4509\",\"url\":\"https://www.semanticscholar.org/topic/4509\"},{\"topic\":\"Recommender system\",\"topicId\":\"12428\",\"url\":\"https://www.semanticscholar.org/topic/12428\"},{\"topic\":\"Feedback\",\"topicId\":\"242\",\"url\":\"https://www.semanticscholar.org/topic/242\"},{\"topic\":\"Decision problem\",\"topicId\":\"15220\",\"url\":\"https://www.semanticscholar.org/topic/15220\"},{\"topic\":\"Systems design\",\"topicId\":\"50922\",\"url\":\"https://www.semanticscholar.org/topic/50922\"},{\"topic\":\"oN-Line System\",\"topicId\":\"233809\",\"url\":\"https://www.semanticscholar.org/topic/233809\"},{\"topic\":\"Word lists by frequency\",\"topicId\":\"284043\",\"url\":\"https://www.semanticscholar.org/topic/284043\"},{\"topic\":\"Computer\",\"topicId\":\"1313\",\"url\":\"https://www.semanticscholar.org/topic/1313\"},{\"topic\":\"Coat of arms\",\"topicId\":\"65199\",\"url\":\"https://www.semanticscholar.org/topic/65199\"},{\"topic\":\"Andrew Barto\",\"topicId\":\"1221498\",\"url\":\"https://www.semanticscholar.org/topic/1221498\"},{\"topic\":\"Armstrong's axioms\",\"topicId\":\"997282\",\"url\":\"https://www.semanticscholar.org/topic/997282\"},{\"topic\":\"Gibbs sampling\",\"topicId\":\"43651\",\"url\":\"https://www.semanticscholar.org/topic/43651\"},{\"topic\":\"Robbins v. Lower Merion School District\",\"topicId\":\"4070511\",\"url\":\"https://www.semanticscholar.org/topic/4070511\"}],\"url\":\"https://www.semanticscholar.org/paper/ffe6d7573bb2c4fbfac0cc474804b5b1734a1179\",\"venue\":\"IJCAI\",\"year\":2018}\n"