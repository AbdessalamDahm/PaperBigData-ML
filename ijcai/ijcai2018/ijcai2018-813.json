"{\"abstract\":\"\\u00a9 2018 International Joint Conferences on Artificial Intelligence.All right reserved. Designing \\u201cteams of intelligent agents that successfully coordinate and learn about their complex environments inhabited by other agents (such as humans)\\u201d is one of the major goals of AI, and it is the challenge that I aim to address in my research. In this paper I give an overview of some of the foundations, insights and challenges in this field of Interactive Learning and Decision Making.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"1799949\",\"name\":\"Frans A. Oliehoek\",\"url\":\"https://www.semanticscholar.org/author/1799949\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":\"1810.05587\",\"authors\":[{\"authorId\":\"1400326437\",\"name\":\"Pablo Hernandez-Leal\"},{\"authorId\":\"35224631\",\"name\":\"Bilal Kartal\"},{\"authorId\":\"39286677\",\"name\":\"Matthew E. Taylor\"}],\"doi\":\"10.1007/s10458-019-09421-1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3f43f08611cbcfba62bb9e0c5339c2a8f0cc3e4b\",\"title\":\"Is multiagent deep reinforcement learning the answer or the question? A brief survey\",\"url\":\"https://www.semanticscholar.org/paper/3f43f08611cbcfba62bb9e0c5339c2a8f0cc3e4b\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3441741\",\"name\":\"Minglong Li\"},{\"authorId\":\"47718227\",\"name\":\"W. Yang\"},{\"authorId\":\"3441849\",\"name\":\"Zhongxuan Cai\"},{\"authorId\":\"2245657\",\"name\":\"Shaowu Yang\"},{\"authorId\":\"46583528\",\"name\":\"J. Wang\"}],\"doi\":\"10.24963/ijcai.2019/64\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1eb8a23bec05e64c42b5ad1a97e9fa266b1339c7\",\"title\":\"Integrating Decision Sharing with Prediction in Decentralized Planning for Multi-Agent Coordination under Uncertainty\",\"url\":\"https://www.semanticscholar.org/paper/1eb8a23bec05e64c42b5ad1a97e9fa266b1339c7\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47154938\",\"name\":\"X. Zhou\"},{\"authorId\":\"40007599\",\"name\":\"Weiping Wang\"},{\"authorId\":\"2079257\",\"name\":\"Yifan Zhu\"},{\"authorId\":\"8269527\",\"name\":\"Tao Wang\"},{\"authorId\":\"2680865\",\"name\":\"Bo Zhang\"}],\"doi\":\"10.1109/ACCESS.2019.2913764\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"1e20c562368c134e468d3d584598ef7f6d95a947\",\"title\":\"Centralized Patrolling With Weakly-Coupled Agents Using Monte Carlo Tree Search\",\"url\":\"https://www.semanticscholar.org/paper/1e20c562368c134e468d3d584598ef7f6d95a947\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51181453\",\"name\":\"Alberto Badias\"},{\"authorId\":\"2025920886\",\"name\":\"Sarah Curtit\"},{\"authorId\":\"2025920886\",\"name\":\"Sarah Curtit\"},{\"authorId\":\"47723344\",\"name\":\"David Gonz\\u00e1lez\"},{\"authorId\":\"25038052\",\"name\":\"I. Alfaro\"},{\"authorId\":\"49259170\",\"name\":\"F. Chinesta\"},{\"authorId\":\"153786537\",\"name\":\"E. Cueto\"}],\"doi\":\"10.1002/NME.6127\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"26c94bea87a1715fdcc90835a75cd09d10bef0a7\",\"title\":\"An augmented reality platform for interactive aerodynamic design and analysis\",\"url\":\"https://www.semanticscholar.org/paper/26c94bea87a1715fdcc90835a75cd09d10bef0a7\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1400326437\",\"name\":\"Pablo Hernandez-Leal\"},{\"authorId\":\"35224631\",\"name\":\"Bilal Kartal\"},{\"authorId\":\"39286677\",\"name\":\"Matthew E. Taylor\"}],\"doi\":\"10.1007/s10458-019-09421-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"390364c3986d05ad71a40a967b9cc12aa30e4305\",\"title\":\"A survey and critique of multiagent deep reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/390364c3986d05ad71a40a967b9cc12aa30e4305\",\"venue\":\"Autonomous Agents and Multi-Agent Systems\",\"year\":2019}],\"corpusId\":51609030,\"doi\":\"10.24963/ijcai.2018/813\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":1,\"is_open_access\":true,\"is_publisher_licensed\":false,\"paperId\":\"62a32c6864f0a0a08ae2b503802d44996a3a8d1f\",\"references\":[{\"arxivId\":\"1705.08926\",\"authors\":[{\"authorId\":\"145356667\",\"name\":\"Jakob N. Foerster\"},{\"authorId\":\"38698094\",\"name\":\"Gregory Farquhar\"},{\"authorId\":\"2285516\",\"name\":\"Triantafyllos Afouras\"},{\"authorId\":\"39683441\",\"name\":\"Nantas Nardelli\"},{\"authorId\":\"1766767\",\"name\":\"S. Whiteson\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2b292ff89d808fba10579871591a22f1649cd039\",\"title\":\"Counterfactual Multi-Agent Policy Gradients\",\"url\":\"https://www.semanticscholar.org/paper/2b292ff89d808fba10579871591a22f1649cd039\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Richard Bellman. A Markovian decision process\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Journal of Mathematics and Mechanics\",\"url\":\"\",\"venue\":\"6(5),\",\"year\":1957},{\"arxivId\":\"1712.00679\",\"authors\":[{\"authorId\":\"1799949\",\"name\":\"Frans A. Oliehoek\"},{\"authorId\":\"2377870\",\"name\":\"Rahul Savani\"},{\"authorId\":\"1410596066\",\"name\":\"J. Gallego-Posada\"},{\"authorId\":\"3468383\",\"name\":\"Elise van der Pol\"},{\"authorId\":\"2451711\",\"name\":\"E. D. Jong\"},{\"authorId\":\"6586246\",\"name\":\"R. Gro\\u00df\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"44570d4c17b06326e9d3bf8bfdfdef2527560f75\",\"title\":\"GANGs: Generative Adversarial Network Games\",\"url\":\"https://www.semanticscholar.org/paper/44570d4c17b06326e9d3bf8bfdfdef2527560f75\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1697031\",\"name\":\"E. A. Hansen\"},{\"authorId\":\"35176432\",\"name\":\"D. Bernstein\"},{\"authorId\":\"1707550\",\"name\":\"S. Zilberstein\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b9764ed9cf14b439235987dfe65d35bb6ce406ef\",\"title\":\"Dynamic Programming for Partially Observable Stochastic Games\",\"url\":\"https://www.semanticscholar.org/paper/b9764ed9cf14b439235987dfe65d35bb6ce406ef\",\"venue\":\"AAAI\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Dimitri P. Bertsekas\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Bernstein , Shlomo Zilberstein , and Neil Immerman . The complexity of decentralized control of Markov decision processes\",\"url\":\"\",\"venue\":\"Dynamic Programming and Optimal Control , volume II . Athena Scientific\",\"year\":2000},{\"arxivId\":\"1106.4569\",\"authors\":[{\"authorId\":\"1748597\",\"name\":\"David V. Pynadath\"},{\"authorId\":\"143736701\",\"name\":\"Milind Tambe\"}],\"doi\":\"10.1613/jair.1024\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f307c43c6b05d2635200e636e461d22dc0091e39\",\"title\":\"The Communicative Multiagent Team Decision Problem: Analyzing Teamwork Theories and Models\",\"url\":\"https://www.semanticscholar.org/paper/f307c43c6b05d2635200e636e461d22dc0091e39\",\"venue\":\"J. Artif. Intell. Res.\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Frans A. Oliehoek\"},{\"authorId\":null,\"name\":\"Matthijs T.J. Spaan\"},{\"authorId\":null,\"name\":\"Nikos Vlassis. Optimal\"},{\"authorId\":null,\"name\":\"approximate Q-value functions for decentralized POMDPs\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"JAIR\",\"url\":\"\",\"venue\":\"32,\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2176134\",\"name\":\"Lior Kuyer\"},{\"authorId\":\"1766767\",\"name\":\"S. Whiteson\"},{\"authorId\":\"3011589\",\"name\":\"B. Bakker\"},{\"authorId\":\"31651045\",\"name\":\"N. Vlassis\"}],\"doi\":\"10.1007/978-3-540-87479-9_61\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c5787226587d6612fe702d7f3a2a869a72cf6573\",\"title\":\"Multiagent Reinforcement Learning for Urban Traffic Control Using Coordination Graphs\",\"url\":\"https://www.semanticscholar.org/paper/c5787226587d6612fe702d7f3a2a869a72cf6573\",\"venue\":\"ECML/PKDD\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34903901\",\"name\":\"Chris Amato\"},{\"authorId\":\"1799949\",\"name\":\"Frans A. Oliehoek\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e0fed99620480a506e59668595d3e550679e0903\",\"title\":\"Bayesian Reinforcement Learning for Multiagent Systems with State Uncertainty\",\"url\":\"https://www.semanticscholar.org/paper/e0fed99620480a506e59668595d3e550679e0903\",\"venue\":\"\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47570159\",\"name\":\"P. Antsaklis\"},{\"authorId\":\"6954585\",\"name\":\"E. Kovacs\"},{\"authorId\":\"1744311\",\"name\":\"E. Chong\"},{\"authorId\":\"8564504\",\"name\":\"J. Grizzle\"},{\"authorId\":\"144303180\",\"name\":\"M. Krsti\\u0107\"},{\"authorId\":\"2700298\",\"name\":\"J. Spall\"},{\"authorId\":\"65826872\",\"name\":\"Y. Amamoto\"},{\"authorId\":\"2460665\",\"name\":\"D. Arzelier\"},{\"authorId\":\"144774377\",\"name\":\"A. Astolfi\"},{\"authorId\":\"1765717\",\"name\":\"J. Braslavsky\"},{\"authorId\":\"3166766\",\"name\":\"H. Chang\"},{\"authorId\":\"1708946\",\"name\":\"X. Chen\"},{\"authorId\":\"66578426\",\"name\":\"Shibaura Inst\"},{\"authorId\":\"1689638\",\"name\":\"A. Chiuso\"},{\"authorId\":\"1707671\",\"name\":\"J. Daafouz\"},{\"authorId\":\"2929862\",\"name\":\"F. Dabbene\"},{\"authorId\":\"50345162\",\"name\":\"G. Dullerud\"},{\"authorId\":\"152599370\",\"name\":\"M. Egerstedt\"},{\"authorId\":\"49815118\",\"name\":\"E. Fabre\"},{\"authorId\":\"144101313\",\"name\":\"A. Ferrara\"},{\"authorId\":\"31217167\",\"name\":\"H. Ishii\"},{\"authorId\":\"48082394\",\"name\":\"M. James\"},{\"authorId\":\"145565795\",\"name\":\"A. Loria\"},{\"authorId\":\"1789590\",\"name\":\"M. Malisoff\"},{\"authorId\":\"145581280\",\"name\":\"H. Marchand\"},{\"authorId\":\"65763790\",\"name\":\"Rennes-Bretagne Atlantique\"},{\"authorId\":\"48319064\",\"name\":\"L. Marconi\"},{\"authorId\":\"144939962\",\"name\":\"Kirsten Morris\"},{\"authorId\":\"1752117\",\"name\":\"F. Paganini\"},{\"authorId\":\"2193683\",\"name\":\"M. Prandini\"},{\"authorId\":\"1962798\",\"name\":\"S. Reveliotis\"},{\"authorId\":\"17722135\",\"name\":\"L. Schenato\"},{\"authorId\":\"1775285\",\"name\":\"H. Trentelman\"},{\"authorId\":\"122244178\",\"name\":\"Z. Wang\"},{\"authorId\":\"3064053\",\"name\":\"E. Weyer\"},{\"authorId\":\"2367263\",\"name\":\"J. Winkin\"}],\"doi\":\"10.1109/tac.9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"db0760d59f189a5906e0d2b431eeaec31842ddb5\",\"title\":\"IEEE TRANSACTIONS ON AUTOMATIC CONTROL\",\"url\":\"https://www.semanticscholar.org/paper/db0760d59f189a5906e0d2b431eeaec31842ddb5\",\"venue\":\"\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"E G Foerster\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"\\u2022 Some deep MARL does\",\"url\":\"\",\"venue\":\"Mordatch&Abeel\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687126467\",\"name\":\"DibangoyeJilles Steeve\"},{\"authorId\":\"1644673233\",\"name\":\"AmatoChristopher\"},{\"authorId\":\"1687128189\",\"name\":\"BuffetOlivier\"},{\"authorId\":\"1687122456\",\"name\":\"CharpilletFran\\u00e7ois\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"085a788dc19577b6d0da86e34338231056de6c95\",\"title\":\"Optimally solving Dec-POMDPs as continuous-state MDPs\",\"url\":\"https://www.semanticscholar.org/paper/085a788dc19577b6d0da86e34338231056de6c95\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Carlos Guestrin\"},{\"authorId\":null,\"name\":\"Daphne Koller\"},{\"authorId\":null,\"name\":\"Ronald Parr\"},{\"authorId\":null,\"name\":\"Shobha Venkataraman. Efficient solution algorithms for fa MDPs\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"JAIR\",\"url\":\"\",\"venue\":\"19,\",\"year\":2003},{\"arxivId\":\"cs/9605103\",\"authors\":[{\"authorId\":\"1709512\",\"name\":\"L. Kaelbling\"},{\"authorId\":\"144885169\",\"name\":\"M. Littman\"},{\"authorId\":\"1760402\",\"name\":\"A. Moore\"}],\"doi\":\"10.1613/jair.301\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"12d1d070a53d4084d88a77b8b143bad51c40c38f\",\"title\":\"Reinforcement Learning: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/12d1d070a53d4084d88a77b8b143bad51c40c38f\",\"venue\":\"J. Artif. Intell. Res.\",\"year\":1996},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2691283\",\"name\":\"Ranjit Nair\"},{\"authorId\":\"1718824\",\"name\":\"Pradeep Varakantham\"},{\"authorId\":\"143736701\",\"name\":\"Milind Tambe\"},{\"authorId\":\"144921751\",\"name\":\"M. Yokoo\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"22dacd78c3f9b182509f67ef99cf1e6143618c2a\",\"title\":\"Networked Distributed POMDPs: A Synergy of Distributed Constraint Optimization and POMDPs\",\"url\":\"https://www.semanticscholar.org/paper/22dacd78c3f9b182509f67ef99cf1e6143618c2a\",\"venue\":\"IJCAI\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144885169\",\"name\":\"M. Littman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"da85b2f52c8b1872c963a6a8104bb0906083d28a\",\"title\":\"Probabilistic Propositional Planning: Representations and Complexity\",\"url\":\"https://www.semanticscholar.org/paper/da85b2f52c8b1872c963a6a8104bb0906083d28a\",\"venue\":\"AAAI/IAAI\",\"year\":1997},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1799949\",\"name\":\"Frans A. Oliehoek\"},{\"authorId\":\"1766767\",\"name\":\"S. Whiteson\"},{\"authorId\":\"1723205\",\"name\":\"M. Spaan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"95034d77d2ce03ee62acfa48aa5bae1485001bc3\",\"title\":\"Approximate solutions for factored Dec-POMDPs with many agents\",\"url\":\"https://www.semanticscholar.org/paper/95034d77d2ce03ee62acfa48aa5bae1485001bc3\",\"venue\":\"AAMAS\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"St\\u00e9phane Ross\"},{\"authorId\":null,\"name\":\"Joelle Pineau\"},{\"authorId\":null,\"name\":\"Brahim Chaibdraa\"},{\"authorId\":null,\"name\":\"Pierre Kreitmann. A Bayesian approach for learning\"},{\"authorId\":null,\"name\":\"planning in partially observable Markov decision processes\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"JMLR\",\"url\":\"\",\"venue\":\"12,\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Frans A. Oliehoek\"},{\"authorId\":null,\"name\":\"Christopher Amato. Dec-POMDPs as non-observable MDPs\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"IAS technical report IAS-UVA-14-01\",\"url\":\"\",\"venue\":\"Intelligent Systems Lab, University of Amsterdam,\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1730156\",\"name\":\"Carlos Guestrin\"},{\"authorId\":\"1736370\",\"name\":\"D. Koller\"},{\"authorId\":\"145726861\",\"name\":\"R. Parr\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c0fda2ab14245ca3775fdfc9b0fef1d309dfdb04\",\"title\":\"Multiagent Planning with Factored MDPs\",\"url\":\"https://www.semanticscholar.org/paper/c0fda2ab14245ca3775fdfc9b0fef1d309dfdb04\",\"venue\":\"NIPS\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1736370\",\"name\":\"D. Koller\"},{\"authorId\":\"145726861\",\"name\":\"R. Parr\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2d005ede56be0bd14ef1a8606b105bfcb33d20eb\",\"title\":\"Computing Factored Value Functions for Policies in Structured MDPs\",\"url\":\"https://www.semanticscholar.org/paper/2d005ede56be0bd14ef1a8606b105bfcb33d20eb\",\"venue\":\"IJCAI\",\"year\":1999},{\"arxivId\":\"1511.09080\",\"authors\":[{\"authorId\":\"2473511\",\"name\":\"P. Robbel\"},{\"authorId\":\"1799949\",\"name\":\"Frans A. Oliehoek\"},{\"authorId\":\"2275756\",\"name\":\"Mykel J. Kochenderfer\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bf714e7c2e68e3e4ebdfbb8d41b54382a72d892d\",\"title\":\"Exploiting Anonymity in Approximate Linear Programming: Scaling to Large Multiagent MDPs\",\"url\":\"https://www.semanticscholar.org/paper/bf714e7c2e68e3e4ebdfbb8d41b54382a72d892d\",\"venue\":\"AAAI\",\"year\":2016},{\"arxivId\":\"1803.11485\",\"authors\":[{\"authorId\":\"36054740\",\"name\":\"Tabish Rashid\"},{\"authorId\":\"49089678\",\"name\":\"Mikayel Samvelyan\"},{\"authorId\":\"47542438\",\"name\":\"C. S. Witt\"},{\"authorId\":\"38698094\",\"name\":\"Gregory Farquhar\"},{\"authorId\":\"145356667\",\"name\":\"Jakob N. Foerster\"},{\"authorId\":\"1766767\",\"name\":\"S. Whiteson\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ffc211476f2e40e79466ffc198c919a97da3bb76\",\"title\":\"QMIX: Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/ffc211476f2e40e79466ffc198c919a97da3bb76\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Frans A. Oliehoek\"},{\"authorId\":null,\"name\":\"Christopher Amato. A Concise Introduction to Decentralized POMDPs\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Springer Briefs in Intelligent Systems\",\"url\":\"\",\"venue\":\"Springer,\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1700433\",\"name\":\"S. Ross\"},{\"authorId\":\"145134886\",\"name\":\"Joelle Pineau\"},{\"authorId\":\"1700926\",\"name\":\"B. Chaib-draa\"},{\"authorId\":\"1759904\",\"name\":\"Pierre Kreitmann\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fe1e8ce89501bacfba2cc04dbc781538739c7dcf\",\"title\":\"A Bayesian Approach for Learning and Planning in Partially Observable Markov Decision Processes\",\"url\":\"https://www.semanticscholar.org/paper/fe1e8ce89501bacfba2cc04dbc781538739c7dcf\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2011},{\"arxivId\":\"1312.5602\",\"authors\":[{\"authorId\":\"3255983\",\"name\":\"V. Mnih\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"},{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"2460849\",\"name\":\"Ioannis Antonoglou\"},{\"authorId\":\"1688276\",\"name\":\"Daan Wierstra\"},{\"authorId\":\"3137672\",\"name\":\"Martin A. Riedmiller\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2319a491378867c7049b3da055c5df60e1671158\",\"title\":\"Playing Atari with Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/2319a491378867c7049b3da055c5df60e1671158\",\"venue\":\"ArXiv\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Alessandro Panella\"},{\"authorId\":null,\"name\":\"Piotr Gmytrasiewicz\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Learning policies of agents in partially observable domains using Bayesian nonparametric methods\",\"url\":\"\",\"venue\":\"MultiAgent Sequential Decision Making in Uncertain Domains,\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2945930\",\"name\":\"J. Messias\"},{\"authorId\":\"1723205\",\"name\":\"M. Spaan\"},{\"authorId\":\"1883749\",\"name\":\"P. Lima\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5366623db0711b0ef9346b82f374b289a7765c99\",\"title\":\"Efficient Offline Communication Policies for Factored Multiagent POMDPs\",\"url\":\"https://www.semanticscholar.org/paper/5366623db0711b0ef9346b82f374b289a7765c99\",\"venue\":\"NIPS\",\"year\":2011},{\"arxivId\":\"1703.00573\",\"authors\":[{\"authorId\":\"145563459\",\"name\":\"S. Arora\"},{\"authorId\":\"33018724\",\"name\":\"Rong Ge\"},{\"authorId\":\"40609253\",\"name\":\"Yingyu Liang\"},{\"authorId\":\"1901958\",\"name\":\"Tengyu Ma\"},{\"authorId\":\"48380281\",\"name\":\"Y. Zhang\"}],\"doi\":\"10.1145/3188745.3232194\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"641165c959554d8f03314778bd6dfb581d9a469e\",\"title\":\"Generalization and equilibrium in generative adversarial nets (GANs) (invited talk)\",\"url\":\"https://www.semanticscholar.org/paper/641165c959554d8f03314778bd6dfb581d9a469e\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Factor 2 improvements over baseline\",\"url\":\"\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jo\\u00e3o V. Messias\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Oliehoek and Christopher Amato . Best response Bayesian reinforcement learning for mul - tiagent systems with state uncertainty\",\"url\":\"\",\"venue\":\"Multi - Agent Sequential Decision Making in Uncertain Domains\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144886843\",\"name\":\"Richard Lathe\"}],\"doi\":\"10.1038/332676B0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6ec27fba80de3b9c52ef6ac4eaa9f59821aefb4b\",\"title\":\"Phd by thesis\",\"url\":\"https://www.semanticscholar.org/paper/6ec27fba80de3b9c52ef6ac4eaa9f59821aefb4b\",\"venue\":\"Nature\",\"year\":1988},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Coordinated Deep RL\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Victor Lesser\"},{\"authorId\":null,\"name\":\"V Claudia\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Goldman . Transition - independent decentralized Markov decision processes\",\"url\":\"\",\"venue\":\"\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34157573\",\"name\":\"D. Claes\"},{\"authorId\":\"1799949\",\"name\":\"Frans A. Oliehoek\"},{\"authorId\":\"2502026\",\"name\":\"H. Baier\"},{\"authorId\":\"2274623\",\"name\":\"K. Tuyls\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3bbd9ecd2e8d5496fa5e4ef83bfd2622a2c1a54f\",\"title\":\"Decentralised Online Planning for Multi-Robot Warehouse Commissioning\",\"url\":\"https://www.semanticscholar.org/paper/3bbd9ecd2e8d5496fa5e4ef83bfd2622a2c1a54f\",\"venue\":\"AAMAS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34157573\",\"name\":\"D. Claes\"},{\"authorId\":\"2473511\",\"name\":\"P. Robbel\"},{\"authorId\":\"1799949\",\"name\":\"Frans A. Oliehoek\"},{\"authorId\":\"2274623\",\"name\":\"K. Tuyls\"},{\"authorId\":\"1897926\",\"name\":\"D. Hennes\"},{\"authorId\":\"1706100\",\"name\":\"W. Hoek\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e2882c9bbc2cd3a3d8808969b3cf2bf8347f4638\",\"title\":\"Effective Approximations for Multi-Robot Coordination in Spatially Distributed Tasks\",\"url\":\"https://www.semanticscholar.org/paper/e2882c9bbc2cd3a3d8808969b3cf2bf8347f4638\",\"venue\":\"AAMAS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Crimi\"},{\"authorId\":null,\"name\":\"Verheggen\"},{\"authorId\":\"147641724\",\"name\":\"Malinowski\"},{\"authorId\":\"123468031\",\"name\":\"Robert.\"}],\"doi\":\"10.1017/cbo9781139093927.012\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"92af02c12404afdbe348e89157f4ec2557a0539e\",\"title\":\"Volume II\",\"url\":\"https://www.semanticscholar.org/paper/92af02c12404afdbe348e89157f4ec2557a0539e\",\"venue\":\"\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2964338\",\"name\":\"Liam MacDermed\"},{\"authorId\":\"1787816\",\"name\":\"C. Isbell\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"14d9bb0da5161b5493b19dfb3c58e7e35dda6d6a\",\"title\":\"Point Based Value Iteration with Optimal Belief Compression for Dec-POMDPs\",\"url\":\"https://www.semanticscholar.org/paper/14d9bb0da5161b5493b19dfb3c58e7e35dda6d6a\",\"venue\":\"NIPS\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2414946\",\"name\":\"S. Witwicki\"},{\"authorId\":\"1799949\",\"name\":\"Frans A. Oliehoek\"},{\"authorId\":\"1709512\",\"name\":\"L. Kaelbling\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"20b22094fbf85a26fa94fc4b45ce8058a703699e\",\"title\":\"Heuristic search of multiagent influence space\",\"url\":\"https://www.semanticscholar.org/paper/20b22094fbf85a26fa94fc4b45ce8058a703699e\",\"venue\":\"AAMAS\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21456301\",\"name\":\"R. Bellman\"}],\"doi\":\"10.1512/IUMJ.1957.6.56038\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bff20fb30adad8d1c173963089df5fc9664304f0\",\"title\":\"A Markovian Decision Process\",\"url\":\"https://www.semanticscholar.org/paper/bff20fb30adad8d1c173963089df5fc9664304f0\",\"venue\":\"\",\"year\":1957},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Marl incl\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"deep\\\" MARL)\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2266946\",\"name\":\"X. Shen\"},{\"authorId\":\"144650585\",\"name\":\"G. Tseng\"},{\"authorId\":\"46448079\",\"name\":\"X. Zhang\"},{\"authorId\":\"144932570\",\"name\":\"W. Wong\"}],\"doi\":\"10.1198/016214503000000639\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ab1cfb387e56b6db2f5e8cbc6b253c0231a9af23\",\"title\":\"On \\u03c8-Learning\",\"url\":\"https://www.semanticscholar.org/paper/ab1cfb387e56b6db2f5e8cbc6b253c0231a9af23\",\"venue\":\"\",\"year\":2003},{\"arxivId\":\"1301.3836\",\"authors\":[{\"authorId\":\"35176432\",\"name\":\"D. Bernstein\"},{\"authorId\":\"1707550\",\"name\":\"S. Zilberstein\"},{\"authorId\":\"1808597\",\"name\":\"N. Immerman\"}],\"doi\":\"10.1287/MOOR.27.4.819.297\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"07d88404f24d61a8ea41ee7f688f57ee8f44ac12\",\"title\":\"The Complexity of Decentralized Control of Markov Decision Processes\",\"url\":\"https://www.semanticscholar.org/paper/07d88404f24d61a8ea41ee7f688f57ee8f44ac12\",\"venue\":\"UAI\",\"year\":2000},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145646162\",\"name\":\"Craig Boutilier\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f48318bcb1c2c5540194a846295aa52e7ef3dff9\",\"title\":\"Planning, Learning and Coordination in Multiagent Decision Processes\",\"url\":\"https://www.semanticscholar.org/paper/f48318bcb1c2c5540194a846295aa52e7ef3dff9\",\"venue\":\"TARK\",\"year\":1996},{\"arxivId\":\"1111.0062\",\"authors\":[{\"authorId\":\"1799949\",\"name\":\"Frans A. Oliehoek\"},{\"authorId\":\"1723205\",\"name\":\"M. Spaan\"},{\"authorId\":\"31651045\",\"name\":\"N. Vlassis\"}],\"doi\":\"10.1613/jair.2447\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"19ee8bd6b7ba5ddefa723a018271002705018815\",\"title\":\"Optimal and Approximate Q-value Functions for Decentralized POMDPs\",\"url\":\"https://www.semanticscholar.org/paper/19ee8bd6b7ba5ddefa723a018271002705018815\",\"venue\":\"J. Artif. Intell. Res.\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2414946\",\"name\":\"S. Witwicki\"},{\"authorId\":\"1726491\",\"name\":\"E. Durfee\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5d6bd41dd2ba6e04e0ad6e58587446225eb48072\",\"title\":\"Influence-Based Policy Abstraction for Weakly-Coupled Dec-POMDPs\",\"url\":\"https://www.semanticscholar.org/paper/5d6bd41dd2ba6e04e0ad6e58587446225eb48072\",\"venue\":\"ICAPS\",\"year\":2010},{\"arxivId\":\"cs/0105032\",\"authors\":[{\"authorId\":\"1714319\",\"name\":\"L. Peshkin\"},{\"authorId\":\"1741330\",\"name\":\"Kee-Eung Kim\"},{\"authorId\":\"1735986\",\"name\":\"N. Meuleau\"},{\"authorId\":\"1709512\",\"name\":\"L. Kaelbling\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1d2d6b19f4bec8b2390a0f9b004c1db76255eaa3\",\"title\":\"Learning to Cooperate via Policy Search\",\"url\":\"https://www.semanticscholar.org/paper/1d2d6b19f4bec8b2390a0f9b004c1db76255eaa3\",\"venue\":\"UAI\",\"year\":2000},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1718824\",\"name\":\"Pradeep Varakantham\"},{\"authorId\":\"1995313\",\"name\":\"J. Marecki\"},{\"authorId\":\"33431638\",\"name\":\"Yuichi Yabu\"},{\"authorId\":\"143736701\",\"name\":\"Milind Tambe\"},{\"authorId\":\"144921751\",\"name\":\"M. Yokoo\"}],\"doi\":\"10.1145/1329125.1329388\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f41a04edac78cc72ee87f56aed4e39a9d0906b0c\",\"title\":\"Letting loose a SPIDER on a network of POMDPs: generating quality guaranteed policies\",\"url\":\"https://www.semanticscholar.org/paper/f41a04edac78cc72ee87f56aed4e39a9d0906b0c\",\"venue\":\"AAMAS '07\",\"year\":2007},{\"arxivId\":\"1706.05296\",\"authors\":[{\"authorId\":\"1814162\",\"name\":\"Peter Sunehag\"},{\"authorId\":\"3276293\",\"name\":\"G. Lever\"},{\"authorId\":\"2203658\",\"name\":\"A. Gruslys\"},{\"authorId\":\"144792148\",\"name\":\"W. Czarnecki\"},{\"authorId\":\"3133079\",\"name\":\"V. Zambaldi\"},{\"authorId\":\"3093886\",\"name\":\"Max Jaderberg\"},{\"authorId\":\"1975889\",\"name\":\"Marc Lanctot\"},{\"authorId\":\"2873921\",\"name\":\"Nicolas Sonnerat\"},{\"authorId\":\"1700356\",\"name\":\"Joel Z. Leibo\"},{\"authorId\":\"2274623\",\"name\":\"K. Tuyls\"},{\"authorId\":\"1686971\",\"name\":\"T. Graepel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c4e824a574d396803cf4677b7d0ad4e28ad54804\",\"title\":\"Value-Decomposition Networks For Cooperative Multi-Agent Learning\",\"url\":\"https://www.semanticscholar.org/paper/c4e824a574d396803cf4677b7d0ad4e28ad54804\",\"venue\":\"AAMAS\",\"year\":2018},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"\\u2022 Deep RL has shown ability to scale to impressive domains \\u2022 But... much MARL does not take into account interaction explicitly -Individual Q-learners: may work\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1606.06888\",\"authors\":[{\"authorId\":\"27009713\",\"name\":\"Auke J. Wiggers\"},{\"authorId\":\"1799949\",\"name\":\"Frans A. Oliehoek\"},{\"authorId\":\"1917202\",\"name\":\"Diederik M. Roijers\"}],\"doi\":\"10.3233/978-1-61499-672-9-1628\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"56a8759c5338d044125ce5f3746255d33e5b2129\",\"title\":\"Structure in the Value Function of Two-Player Zero-Sum Games of Incomplete Information\",\"url\":\"https://www.semanticscholar.org/paper/56a8759c5338d044125ce5f3746255d33e5b2129\",\"venue\":\"ECAI\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46724728\",\"name\":\"R. Becker\"},{\"authorId\":\"1707550\",\"name\":\"S. Zilberstein\"},{\"authorId\":\"1725492\",\"name\":\"V. Lesser\"},{\"authorId\":\"5006412\",\"name\":\"C. Goldman\"}],\"doi\":\"10.1145/860575.860583\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ec74abe274d17a0f4790ca570af0e27386df164e\",\"title\":\"Transition-independent decentralized markov decision processes\",\"url\":\"https://www.semanticscholar.org/paper/ec74abe274d17a0f4790ca570af0e27386df164e\",\"venue\":\"AAMAS '03\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1799949\",\"name\":\"Frans A. Oliehoek\"},{\"authorId\":\"1723205\",\"name\":\"M. Spaan\"},{\"authorId\":\"2414946\",\"name\":\"S. Witwicki\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e3431cf4ca0f16f3aec51d155d79b4d1c0b3ca14\",\"title\":\"Factored Upper Bounds for Multiagent Planning Problems under Uncertainty with Non-Factored Value Functions\",\"url\":\"https://www.semanticscholar.org/paper/e3431cf4ca0f16f3aec51d155d79b4d1c0b3ca14\",\"venue\":\"IJCAI\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A Frans\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Oliehoek -Interactive Learning & Decision Making 34\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2726706\",\"name\":\"N. B\\u00e4uerle\"},{\"authorId\":\"1707387\",\"name\":\"U. Rieder\"}],\"doi\":\"10.1365/S13291-010-0007-2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b2db5541059288472ca246acdca6ead949326864\",\"title\":\"Markov Decision Processes\",\"url\":\"https://www.semanticscholar.org/paper/b2db5541059288472ca246acdca6ead949326864\",\"venue\":\"\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1403025868\",\"name\":\"Jean Pouget-Abadie\"},{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"144738865\",\"name\":\"Bing Xu\"},{\"authorId\":\"1393680089\",\"name\":\"David Warde-Farley\"},{\"authorId\":\"1955694\",\"name\":\"Sherjil Ozair\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"title\":\"Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1709512\",\"name\":\"L. Kaelbling\"},{\"authorId\":\"144885169\",\"name\":\"M. Littman\"},{\"authorId\":\"2453007\",\"name\":\"A. Cassandra\"}],\"doi\":\"10.1016/S0004-3702(98)00023-X\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"116d7798c1123cf7fad4176e98f58fd49de4f8f1\",\"title\":\"Planning and Acting in Partially Observable Stochastic Domains\",\"url\":\"https://www.semanticscholar.org/paper/116d7798c1123cf7fad4176e98f58fd49de4f8f1\",\"venue\":\"Artif. Intell.\",\"year\":1998},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1799949\",\"name\":\"Frans A. Oliehoek\"},{\"authorId\":\"1723205\",\"name\":\"M. Spaan\"},{\"authorId\":\"34903901\",\"name\":\"Chris Amato\"},{\"authorId\":\"1766767\",\"name\":\"S. Whiteson\"}],\"doi\":\"10.1613/JAIR.3788\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"106de8ba3b60dc109430dc6efa4590d4d6e4db5a\",\"title\":\"Incremental clustering and expansion for faster optimal planning in decentralized POMDPs\",\"url\":\"https://www.semanticscholar.org/paper/106de8ba3b60dc109430dc6efa4590d4d6e4db5a\",\"venue\":\"\",\"year\":2013},{\"arxivId\":\"1806.05631\",\"authors\":[{\"authorId\":\"3442798\",\"name\":\"S. Katt\"},{\"authorId\":\"1799949\",\"name\":\"Frans A. Oliehoek\"},{\"authorId\":\"34903901\",\"name\":\"Chris Amato\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"614b197a11eba3f25337b0c9b9cb409ae6230238\",\"title\":\"Learning in POMDPs with Monte Carlo Tree Search\",\"url\":\"https://www.semanticscholar.org/paper/614b197a11eba3f25337b0c9b9cb409ae6230238\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34903901\",\"name\":\"Chris Amato\"},{\"authorId\":\"1799949\",\"name\":\"Frans A. Oliehoek\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a925bd0d0af5539650793caa40addae06eca129f\",\"title\":\"Scalable Planning and Learning for Multiagent POMDPs\",\"url\":\"https://www.semanticscholar.org/paper/a925bd0d0af5539650793caa40addae06eca129f\",\"venue\":\"AAAI\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Piotr J. Gmytrasiewicz\"},{\"authorId\":null,\"name\":\"Prashant Doshi. A framework for sequential planning in mult settings\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"JAIR\",\"url\":\"\",\"venue\":\"24,\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35335083\",\"name\":\"R. Thrall\"}],\"doi\":\"10.21236/ada049700\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1b4b9507d9ff065cc5a3d4a30d604eb4ec41bfe2\",\"title\":\"Mathematics of Operations Research.\",\"url\":\"https://www.semanticscholar.org/paper/1b4b9507d9ff065cc5a3d4a30d604eb4ec41bfe2\",\"venue\":\"\",\"year\":1978},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5006412\",\"name\":\"C. Goldman\"},{\"authorId\":\"1707550\",\"name\":\"S. Zilberstein\"}],\"doi\":\"10.1145/860575.860598\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2149ce97854aa16f61c61528dfc49ce9c76bc24b\",\"title\":\"Optimizing information exchange in cooperative multi-agent systems\",\"url\":\"https://www.semanticscholar.org/paper/2149ce97854aa16f61c61528dfc49ce9c76bc24b\",\"venue\":\"AAMAS '03\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2897833\",\"name\":\"Athirai Aravazhi Irissappane\"},{\"authorId\":\"1799949\",\"name\":\"Frans A. Oliehoek\"},{\"authorId\":\"49050482\",\"name\":\"J. Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1da0edabe69325c63eed04c57833387cee4cc6ff\",\"title\":\"A Scalable Framework to Choose Sellers in E-Marketplaces Using POMDPs\",\"url\":\"https://www.semanticscholar.org/paper/1da0edabe69325c63eed04c57833387cee4cc6ff\",\"venue\":\"AAAI\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1730156\",\"name\":\"Carlos Guestrin\"},{\"authorId\":\"1784072\",\"name\":\"M. Lagoudakis\"},{\"authorId\":\"145726861\",\"name\":\"R. Parr\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e0da42f0d1e2fd6fb74fb3402cabf8ccfb8bd2f0\",\"title\":\"Coordinated Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/e0da42f0d1e2fd6fb74fb3402cabf8ccfb8bd2f0\",\"venue\":\"ICML\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1718824\",\"name\":\"Pradeep Varakantham\"},{\"authorId\":\"2070610\",\"name\":\"Yossiri Adulyasak\"},{\"authorId\":\"1805753\",\"name\":\"Patrick Jaillet\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d457578544f00754fddee33e40c0f29264dce96a\",\"title\":\"Decentralized Stochastic Planning with Anonymity in Interactions\",\"url\":\"https://www.semanticscholar.org/paper/d457578544f00754fddee33e40c0f29264dce96a\",\"venue\":\"AAAI\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1799949\",\"name\":\"Frans A. Oliehoek\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0c1558229c9a155eb1c5f8f2e3804a018ef625e9\",\"title\":\"Sufficient Plan-Time Statistics for Decentralized POMDPs\",\"url\":\"https://www.semanticscholar.org/paper/0c1558229c9a155eb1c5f8f2e3804a018ef625e9\",\"venue\":\"IJCAI\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"V David\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Pynadath and Milind Tambe . The communicative multiagent team decision problem : Analyzing teamwork theories and models\",\"url\":\"\",\"venue\":\"JAIR\",\"year\":1994},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Sammie Katt\"},{\"authorId\":null,\"name\":\"A Frans\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Oliehoek , and Christopher Amato . Learning in POMDPs with Monte Carlo tree search\",\"url\":\"\",\"venue\":\"\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Julius Pfrommer\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Graphical partially observable monte - carlo planning\",\"url\":\"\",\"venue\":\"Learning , Inference and Control of Multi - Agent Systems\",\"year\":2000},{\"arxivId\":\"1105.5460\",\"authors\":[{\"authorId\":\"145646162\",\"name\":\"Craig Boutilier\"},{\"authorId\":\"39971338\",\"name\":\"T. Dean\"},{\"authorId\":\"38413017\",\"name\":\"S. Hanks\"}],\"doi\":\"10.1613/jair.575\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"5ae2b62d22b291ce13f07ca20f318a130ad949ab\",\"title\":\"Decision-Theoretic Planning: Structural Assumptions and Computational Leverage\",\"url\":\"https://www.semanticscholar.org/paper/5ae2b62d22b291ce13f07ca20f318a130ad949ab\",\"venue\":\"J. Artif. Intell. Res.\",\"year\":1999},{\"arxivId\":\"1511.09047\",\"authors\":[{\"authorId\":\"2399510\",\"name\":\"Joris Scharpff\"},{\"authorId\":\"1917202\",\"name\":\"Diederik M. Roijers\"},{\"authorId\":\"1799949\",\"name\":\"Frans A. Oliehoek\"},{\"authorId\":\"1723205\",\"name\":\"M. Spaan\"},{\"authorId\":\"1788228\",\"name\":\"M. D. Weerdt\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d33c54fca46036aae5a784d1d5e032dfc7ef2df3\",\"title\":\"Solving Transition-Independent Multi-Agent MDPs with Sparse Interactions\",\"url\":\"https://www.semanticscholar.org/paper/d33c54fca46036aae5a784d1d5e032dfc7ef2df3\",\"venue\":\"AAAI\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1799949\",\"name\":\"Frans A. Oliehoek\"},{\"authorId\":\"1723205\",\"name\":\"M. Spaan\"},{\"authorId\":\"1766767\",\"name\":\"S. Whiteson\"},{\"authorId\":\"31651045\",\"name\":\"N. Vlassis\"}],\"doi\":\"10.1145/1402383.1402457\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f1c592049463e233cdf58d4794f6048b83828ea9\",\"title\":\"Exploiting locality of interaction in factored Dec-POMDPs\",\"url\":\"https://www.semanticscholar.org/paper/f1c592049463e233cdf58d4794f6048b83828ea9\",\"venue\":\"AAMAS\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A Frans\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Oliehoek -Interactive Learning & Decision Making 33\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Frans A. Oliehoek\"},{\"authorId\":null,\"name\":\"Matthijs T.J. Spaan\"},{\"authorId\":null,\"name\":\"Christopher Amato\"},{\"authorId\":null,\"name\":\"Shimon Whiteson. Incremental clustering\"},{\"authorId\":null,\"name\":\"expansion for faster optimal planning in decentralized POMDPs\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"JAIR\",\"url\":\"\",\"venue\":\"46,\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Frans\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Oliehoek and Christopher Amato . Best response Bayesian reinforcement learning for mul - tiagent systems with state uncertainty\",\"url\":\"\",\"venue\":\"Multi - Agent Sequential Decision Making in Uncertain Domains\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Leslie Pack Kaelbling\"},{\"authorId\":null,\"name\":\"Michael L. Littman\"},{\"authorId\":null,\"name\":\"Anthony R. Cassandra. Planning\"},{\"authorId\":null,\"name\":\"acting in partially observable stochastic domains\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"AIJ\",\"url\":\"\",\"venue\":\"101(1-2),\",\"year\":1998},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A Frans\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Oliehoek -Interactive Learning & Decision Making 35\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jelle R. Kok\"},{\"authorId\":null,\"name\":\"Nikos Vlassis. Collaborative multiagent reinforcement le propagation\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"JMLR\",\"url\":\"\",\"venue\":\"7,\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1799949\",\"name\":\"Frans A. Oliehoek\"},{\"authorId\":\"2414946\",\"name\":\"S. Witwicki\"},{\"authorId\":\"1709512\",\"name\":\"L. Kaelbling\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5d71b1f0245af862f16be4cae6a33e05e70ade44\",\"title\":\"Influence-Based Abstraction for Multiagent Systems\",\"url\":\"https://www.semanticscholar.org/paper/5d71b1f0245af862f16be4cae6a33e05e70ade44\",\"venue\":\"AAAI\",\"year\":2012}],\"title\":\"Interactive Learning and Decision Making: Foundations, Insights & Challenges\",\"topics\":[{\"topic\":\"International Joint Conferences on Artificial Intelligence\",\"topicId\":\"1493934\",\"url\":\"https://www.semanticscholar.org/topic/1493934\"},{\"topic\":\"Interactivity\",\"topicId\":\"192\",\"url\":\"https://www.semanticscholar.org/topic/192\"},{\"topic\":\"Intelligent agent\",\"topicId\":\"18636\",\"url\":\"https://www.semanticscholar.org/topic/18636\"}],\"url\":\"https://www.semanticscholar.org/paper/62a32c6864f0a0a08ae2b503802d44996a3a8d1f\",\"venue\":\"IJCAI\",\"year\":2018}\n"