"{\"abstract\":\"We propose a framework based on distributional reinforcement learning and recent attempts to combine Bayesian parameter updates with deep reinforcement learning. We show that our proposed framework conceptually unifies multiple previous methods in exploration. We also derive a practical algorithm that achieves efficient exploration on challenging control tasks.\",\"arxivId\":\"1805.01907\",\"authors\":[{\"authorId\":\"11501567\",\"name\":\"Yunhao Tang\",\"url\":\"https://www.semanticscholar.org/author/11501567\"},{\"authorId\":\"1703744\",\"name\":\"S. Agrawal\",\"url\":\"https://www.semanticscholar.org/author/1703744\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":\"2002.03098\",\"authors\":[{\"authorId\":\"1720480\",\"name\":\"Christos Dimitrakakis\"},{\"authorId\":\"94923427\",\"name\":\"Hannes Eriksson\"},{\"authorId\":\"8335457\",\"name\":\"E. Jorge\"},{\"authorId\":\"4078117\",\"name\":\"Divya Grover\"},{\"authorId\":\"3214072\",\"name\":\"D. Basu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0f062d951b91fdffccdac343bece851d29ebebf6\",\"title\":\"Inferential Induction: Joint Bayesian Estimation of MDPs and Value Functions\",\"url\":\"https://www.semanticscholar.org/paper/0f062d951b91fdffccdac343bece851d29ebebf6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1812.07544\",\"authors\":[{\"authorId\":\"144006199\",\"name\":\"N. Nikolov\"},{\"authorId\":\"9954232\",\"name\":\"Johannes Kirschner\"},{\"authorId\":\"2064772\",\"name\":\"Felix Berkenkamp\"},{\"authorId\":\"145343838\",\"name\":\"Andreas Krause\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a25b645c3d24f91164230a0ac5bb2d4ec88c1538\",\"title\":\"Information-Directed Exploration for Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/a25b645c3d24f91164230a0ac5bb2d4ec88c1538\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1806.04242\",\"authors\":[{\"authorId\":\"13477045\",\"name\":\"T. M. Moerland\"},{\"authorId\":\"1735303\",\"name\":\"J. Broekens\"},{\"authorId\":\"1689001\",\"name\":\"C. Jonker\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2fd959a9750019b10699c9582f6460a0e7776655\",\"title\":\"The Potential of the Return Distribution for Exploration in RL\",\"url\":\"https://www.semanticscholar.org/paper/2fd959a9750019b10699c9582f6460a0e7776655\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"13477045\",\"name\":\"T. M. Moerland\"},{\"authorId\":\"1735303\",\"name\":\"J. Broekens\"},{\"authorId\":\"9376864\",\"name\":\"Catholijn M. Jonker\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"85d593d5ad0f1b864c47e59309ae313ce0434a72\",\"title\":\"The Potential of the Return Distribution for Exploration in Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/85d593d5ad0f1b864c47e59309ae313ce0434a72\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1808.01960\",\"authors\":[{\"authorId\":\"3406056\",\"name\":\"Dror Freirich\"},{\"authorId\":\"95608043\",\"name\":\"R. Meir\"},{\"authorId\":\"3025260\",\"name\":\"A. Tamar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d067828e8dc0b78d9060615a36bda65912c6c2e0\",\"title\":\"Distributional Multivariate Policy Evaluation and Exploration with the Bellman GAN\",\"url\":\"https://www.semanticscholar.org/paper/d067828e8dc0b78d9060615a36bda65912c6c2e0\",\"venue\":\"ICML\",\"year\":2019},{\"arxivId\":\"2011.09083\",\"authors\":[{\"authorId\":\"49339824\",\"name\":\"Yizhou Zhao\"},{\"authorId\":\"12554898\",\"name\":\"S. Zhu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"23a0292dc93a3b60f3af474e62eef6f4377578f1\",\"title\":\"Weighted Entropy Modification for Soft Actor-Critic\",\"url\":\"https://www.semanticscholar.org/paper/23a0292dc93a3b60f3af474e62eef6f4377578f1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.03098\",\"authors\":[{\"authorId\":\"94923427\",\"name\":\"Hannes Eriksson\"},{\"authorId\":\"8335457\",\"name\":\"E. Jorge\"},{\"authorId\":\"1720480\",\"name\":\"Christos Dimitrakakis\"},{\"authorId\":\"3214072\",\"name\":\"D. Basu\"},{\"authorId\":\"4078117\",\"name\":\"Divya Grover\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e74827fab9d1dbdb03cf46c5650271d9f8b1c049\",\"title\":\"Inferential Induction: A Novel Framework for Bayesian Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/e74827fab9d1dbdb03cf46c5650271d9f8b1c049\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1904.03535\",\"authors\":[{\"authorId\":\"2223282\",\"name\":\"Nikolaos Tziortziotis\"},{\"authorId\":\"1720480\",\"name\":\"Christos Dimitrakakis\"},{\"authorId\":\"1690383\",\"name\":\"M. Vazirgiannis\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ae617b76ecd2ba7c4f917ad895fa87c8a0b78e78\",\"title\":\"Randomised Bayesian Least-Squares Policy Iteration\",\"url\":\"https://www.semanticscholar.org/paper/ae617b76ecd2ba7c4f917ad895fa87c8a0b78e78\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1911.02140\",\"authors\":[{\"authorId\":\"153146366\",\"name\":\"Derek C Yang\"},{\"authorId\":\"10999332\",\"name\":\"L. Zhao\"},{\"authorId\":\"41123614\",\"name\":\"Zichuan Lin\"},{\"authorId\":\"82620854\",\"name\":\"Tao Qin\"},{\"authorId\":\"152441498\",\"name\":\"Jiang Bian\"},{\"authorId\":\"152998017\",\"name\":\"T. Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"71ed27bb1facb66ec0a1f9b91e7d0e56e345bbfe\",\"title\":\"Fully Parameterized Quantile Function for Distributional Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/71ed27bb1facb66ec0a1f9b91e7d0e56e345bbfe\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1905.06125\",\"authors\":[{\"authorId\":\"5377654\",\"name\":\"B. Mavrin\"},{\"authorId\":\"2503523\",\"name\":\"S. Zhang\"},{\"authorId\":\"40609469\",\"name\":\"Hengshuai Yao\"},{\"authorId\":\"2515229\",\"name\":\"Linglong Kong\"},{\"authorId\":\"47822523\",\"name\":\"Kaiwen Wu\"},{\"authorId\":\"40508553\",\"name\":\"Y. Yu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f6b218453170edcbb51e49dd44ba2f83af53ef92\",\"title\":\"Distributional Reinforcement Learning for Efficient Exploration\",\"url\":\"https://www.semanticscholar.org/paper/f6b218453170edcbb51e49dd44ba2f83af53ef92\",\"venue\":\"ICML\",\"year\":2019},{\"arxivId\":\"2011.01859\",\"authors\":[{\"authorId\":\"1500722340\",\"name\":\"Gavin McCracken\"},{\"authorId\":\"40477015\",\"name\":\"Colin Daniels\"},{\"authorId\":\"2004617613\",\"name\":\"Rosie Zhao\"},{\"authorId\":\"1443783944\",\"name\":\"Anna M. Brandenberger\"},{\"authorId\":\"1784317\",\"name\":\"P. Panangaden\"},{\"authorId\":\"144368601\",\"name\":\"Doina Precup\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"83c29f2774139ad91f73c9f284a48af927df5299\",\"title\":\"A Study of Policy Gradient on a Class of Exactly Solvable Models\",\"url\":\"https://www.semanticscholar.org/paper/83c29f2774139ad91f73c9f284a48af927df5299\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.14547\",\"authors\":[{\"authorId\":\"32704046\",\"name\":\"Xiaoteng Ma\"},{\"authorId\":\"150271095\",\"name\":\"Qiyuan Zhang\"},{\"authorId\":\"47839538\",\"name\":\"L. Xia\"},{\"authorId\":\"47230320\",\"name\":\"Zhengyuan Zhou\"},{\"authorId\":\"1724199\",\"name\":\"Jun Yang\"},{\"authorId\":\"9397951\",\"name\":\"Q. Zhao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e69833e925a4372ed3529d7491d286ec9e5a5d19\",\"title\":\"Distributional Soft Actor Critic for Risk Sensitive Learning\",\"url\":\"https://www.semanticscholar.org/paper/e69833e925a4372ed3529d7491d286ec9e5a5d19\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"BELLMAN GAN\"},{\"authorId\":null,\"name\":\"Dror Freirich\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d4383062c47013c30312236c63a250d3af342904\",\"title\":\"DISTRIBUTIONAL MULTIVARIATE POLICY EVALUA-\",\"url\":\"https://www.semanticscholar.org/paper/d4383062c47013c30312236c63a250d3af342904\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32704046\",\"name\":\"Xiaoteng Ma\"},{\"authorId\":\"47839538\",\"name\":\"L. Xia\"},{\"authorId\":\"47230320\",\"name\":\"Zhengyuan Zhou\"},{\"authorId\":\"2000933045\",\"name\":\"Jun Yang\"},{\"authorId\":\"9397951\",\"name\":\"Q. Zhao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ce54f25907510d52c659e017ef65c7b8d63f2296\",\"title\":\"DSAC: Distributional Soft Actor Critic for Risk-Sensitive Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/ce54f25907510d52c659e017ef65c7b8d63f2296\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2005.09645\",\"authors\":[{\"authorId\":\"13477045\",\"name\":\"T. M. Moerland\"},{\"authorId\":\"1735303\",\"name\":\"J. Broekens\"},{\"authorId\":\"1500654996\",\"name\":\"Aske Plaat\"},{\"authorId\":\"9376864\",\"name\":\"Catholijn M. Jonker\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cfa555fa2c3ae9f891f52b943dde807e88e6ebd6\",\"title\":\"The Second Type of Uncertainty in Monte Carlo Tree Search\",\"url\":\"https://www.semanticscholar.org/paper/cfa555fa2c3ae9f891f52b943dde807e88e6ebd6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1810.12162\",\"authors\":[{\"authorId\":\"67311962\",\"name\":\"Pranav Shyam\"},{\"authorId\":\"2146303\",\"name\":\"Wojciech Ja\\u015bkowski\"},{\"authorId\":\"144366920\",\"name\":\"Faustino Gomez\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6ab8aca1f727e379632292e1ec4a24ea2739cf89\",\"title\":\"Model-Based Active Exploration\",\"url\":\"https://www.semanticscholar.org/paper/6ab8aca1f727e379632292e1ec4a24ea2739cf89\",\"venue\":\"ICML\",\"year\":2019},{\"arxivId\":\"2011.01706\",\"authors\":[{\"authorId\":\"1419462921\",\"name\":\"Haotian Zhang\"},{\"authorId\":null,\"name\":\"Yuhao Wang\"},{\"authorId\":\"1706546\",\"name\":\"J. Sun\"},{\"authorId\":\"7814629\",\"name\":\"Zongben Xu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9e227c934191011a59fa7c818ee735c90cadf0d3\",\"title\":\"Amortized Variational Deep Q Network\",\"url\":\"https://www.semanticscholar.org/paper/9e227c934191011a59fa7c818ee735c90cadf0d3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1905.09638\",\"authors\":[{\"authorId\":\"37289174\",\"name\":\"W. R. Clements\"},{\"authorId\":\"123250122\",\"name\":\"Benoit-Marie Robaglia\"},{\"authorId\":\"123750697\",\"name\":\"B. V. Delft\"},{\"authorId\":\"121583364\",\"name\":\"Reda Bahi Slaoui\"},{\"authorId\":\"120932039\",\"name\":\"S'ebastien Toth\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d6285ff3dcb15c1da84dcbc98141be10ef0e8dd1\",\"title\":\"Estimating Risk and Uncertainty in Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/d6285ff3dcb15c1da84dcbc98141be10ef0e8dd1\",\"venue\":\"ArXiv\",\"year\":2019}],\"corpusId\":19232369,\"doi\":\"10.24963/ijcai.2018/376\",\"fieldsOfStudy\":[\"Computer Science\",\"Mathematics\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"3995b02fb3d4be47de8cc1a178fe577a445ac5e7\",\"references\":[{\"arxivId\":\"1707.06887\",\"authors\":[{\"authorId\":\"1792298\",\"name\":\"Marc G. Bellemare\"},{\"authorId\":\"2605877\",\"name\":\"W. Dabney\"},{\"authorId\":\"1708654\",\"name\":\"R. Munos\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c1f4ef741242d629d1f56e442a09a7ba29595a0e\",\"title\":\"A Distributional Perspective on Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/c1f4ef741242d629d1f56e442a09a7ba29595a0e\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Fortunato et al\"},{\"authorId\":null,\"name\":\"2017 Meire Fortunato\"},{\"authorId\":null,\"name\":\"Mohammad Gheshlaghi Azar\"},{\"authorId\":null,\"name\":\"Bilal Piot\"},{\"authorId\":null,\"name\":\"Jacob Menick\"},{\"authorId\":null,\"name\":\"Ian Osband\"},{\"authorId\":null,\"name\":\"Alex Graves\"},{\"authorId\":null,\"name\":\"Vlad Mnih\"},{\"authorId\":null,\"name\":\"Remi Munos\"},{\"authorId\":null,\"name\":\"Demis Hassabis\"},{\"authorId\":null,\"name\":\"Ilivier Pietquin\"},{\"authorId\":null,\"name\":\"Charles Blundell\"},{\"authorId\":null,\"name\":\"Shane Legg\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Noisy network for exploration\",\"url\":\"\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144301306\",\"name\":\"W. Thompson\"}],\"doi\":\"10.1093/BIOMET/25.3-4.285\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ee2cd1d17f833d3c157a1016a778c7c22af555a2\",\"title\":\"ON THE LIKELIHOOD THAT ONE UNKNOWN PROBABILITY EXCEEDS ANOTHER IN VIEW OF THE EVIDENCE OF TWO SAMPLES\",\"url\":\"https://www.semanticscholar.org/paper/ee2cd1d17f833d3c157a1016a778c7c22af555a2\",\"venue\":\"\",\"year\":1933},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2273298\",\"name\":\"T. Morimura\"},{\"authorId\":\"67154907\",\"name\":\"Masashi Sugiyama\"},{\"authorId\":\"2785830\",\"name\":\"H. Kashima\"},{\"authorId\":\"40308003\",\"name\":\"H. Hachiya\"},{\"authorId\":\"145876882\",\"name\":\"Toshiyuki TANAKA\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1ec26e05c2577154213e1668ddd374e4da663309\",\"title\":\"Nonparametric Return Distribution Approximation for Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/1ec26e05c2577154213e1668ddd374e4da663309\",\"venue\":\"ICML\",\"year\":2010},{\"arxivId\":\"1601.00670\",\"authors\":[{\"authorId\":\"1796335\",\"name\":\"D. Blei\"},{\"authorId\":\"3081817\",\"name\":\"A. Kucukelbir\"},{\"authorId\":\"2755213\",\"name\":\"J. McAuliffe\"}],\"doi\":\"10.1080/01621459.2017.1285773\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6f24d7a6e1c88828e18d16c6db20f5329f6a6827\",\"title\":\"Variational Inference: A Review for Statisticians\",\"url\":\"https://www.semanticscholar.org/paper/6f24d7a6e1c88828e18d16c6db20f5329f6a6827\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Mnih et al\"},{\"authorId\":null,\"name\":\"2013 Volodymyr Mnih\"},{\"authorId\":null,\"name\":\"Koray Kavukcuoglu\"},{\"authorId\":null,\"name\":\"David Silver\"},{\"authorId\":null,\"name\":\"Alex Graves\"},{\"authorId\":null,\"name\":\"Ioannis Antonoglou\"},{\"authorId\":null,\"name\":\"Daan Wierstra\"},{\"authorId\":null,\"name\":\"Martin Riedmiller\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Playing atari with deep\",\"url\":\"\",\"venue\":\"\",\"year\":2013},{\"arxivId\":\"1401.0118\",\"authors\":[{\"authorId\":\"2615814\",\"name\":\"R. Ranganath\"},{\"authorId\":\"21007048\",\"name\":\"Sean Gerrish\"},{\"authorId\":\"1796335\",\"name\":\"D. Blei\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6a667700100e228cb30a5d884258a0db921603fe\",\"title\":\"Black Box Variational Inference\",\"url\":\"https://www.semanticscholar.org/paper/6a667700100e228cb30a5d884258a0db921603fe\",\"venue\":\"AISTATS\",\"year\":2014},{\"arxivId\":\"1306.0940\",\"authors\":[{\"authorId\":\"2561924\",\"name\":\"Ian Osband\"},{\"authorId\":\"145751896\",\"name\":\"D. Russo\"},{\"authorId\":\"1731282\",\"name\":\"Benjamin Van Roy\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"789783016fb708abbc061790612ebe91273c05d3\",\"title\":\"(More) Efficient Reinforcement Learning via Posterior Sampling\",\"url\":\"https://www.semanticscholar.org/paper/789783016fb708abbc061790612ebe91273c05d3\",\"venue\":\"NIPS\",\"year\":2013},{\"arxivId\":\"1602.04621\",\"authors\":[{\"authorId\":\"2561924\",\"name\":\"Ian Osband\"},{\"authorId\":\"1723876\",\"name\":\"Charles Blundell\"},{\"authorId\":\"1863250\",\"name\":\"A. Pritzel\"},{\"authorId\":\"1731282\",\"name\":\"Benjamin Van Roy\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4b63e34276aa98d5345efa7fe09bb06d8a9d8f52\",\"title\":\"Deep Exploration via Bootstrapped DQN\",\"url\":\"https://www.semanticscholar.org/paper/4b63e34276aa98d5345efa7fe09bb06d8a9d8f52\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1504.00702\",\"authors\":[{\"authorId\":\"1736651\",\"name\":\"S. Levine\"},{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b6b8a1b80891c96c28cc6340267b58186157e536\",\"title\":\"End-to-End Training of Deep Visuomotor Policies\",\"url\":\"https://www.semanticscholar.org/paper/b6b8a1b80891c96c28cc6340267b58186157e536\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2016},{\"arxivId\":\"1312.5602\",\"authors\":[{\"authorId\":\"3255983\",\"name\":\"V. Mnih\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"},{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"2460849\",\"name\":\"Ioannis Antonoglou\"},{\"authorId\":\"1688276\",\"name\":\"Daan Wierstra\"},{\"authorId\":\"3137672\",\"name\":\"Martin A. Riedmiller\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2319a491378867c7049b3da055c5df60e1671158\",\"title\":\"Playing Atari with Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/2319a491378867c7049b3da055c5df60e1671158\",\"venue\":\"ArXiv\",\"year\":2013},{\"arxivId\":\"1706.10295\",\"authors\":[{\"authorId\":\"39067762\",\"name\":\"Meire Fortunato\"},{\"authorId\":\"37666967\",\"name\":\"Mohammad Gheshlaghi Azar\"},{\"authorId\":\"1808897\",\"name\":\"B. Piot\"},{\"authorId\":\"10698483\",\"name\":\"Jacob Menick\"},{\"authorId\":\"2561924\",\"name\":\"Ian Osband\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"123588356\",\"name\":\"Vlad Mnih\"},{\"authorId\":\"118538000\",\"name\":\"R\\u00e9mi Munos\"},{\"authorId\":\"48987704\",\"name\":\"Demis Hassabis\"},{\"authorId\":\"79608109\",\"name\":\"O. Pietquin\"},{\"authorId\":\"1723876\",\"name\":\"Charles Blundell\"},{\"authorId\":\"34313265\",\"name\":\"S. Legg\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4cd76f8353f0c4852cc432fc0e7a5f2b91ae6ce5\",\"title\":\"Noisy Networks for Exploration\",\"url\":\"https://www.semanticscholar.org/paper/4cd76f8353f0c4852cc432fc0e7a5f2b91ae6ce5\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143654598\",\"name\":\"R. Dearden\"},{\"authorId\":\"50785579\",\"name\":\"N. Friedman\"},{\"authorId\":\"145107462\",\"name\":\"S. Russell\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"b90b5b0cf05bc63f768f55322381f5cfbee6ce1c\",\"title\":\"Bayesian Q-Learning\",\"url\":\"https://www.semanticscholar.org/paper/b90b5b0cf05bc63f768f55322381f5cfbee6ce1c\",\"venue\":\"AAAI/IAAI\",\"year\":1998},{\"arxivId\":\"1606.01540\",\"authors\":[{\"authorId\":\"49508975\",\"name\":\"G. Brockman\"},{\"authorId\":\"34415167\",\"name\":\"Vicki Cheung\"},{\"authorId\":\"152877508\",\"name\":\"Ludwig Pettersson\"},{\"authorId\":\"145540310\",\"name\":\"J. Schneider\"},{\"authorId\":\"47971768\",\"name\":\"John Schulman\"},{\"authorId\":\"143805717\",\"name\":\"Jie Tang\"},{\"authorId\":\"2563432\",\"name\":\"W. Zaremba\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ff7f3277c6fa759e84e1ab7664efdac1c1cec76b\",\"title\":\"OpenAI Gym\",\"url\":\"https://www.semanticscholar.org/paper/ff7f3277c6fa759e84e1ab7664efdac1c1cec76b\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"John Schulman\"},{\"authorId\":null,\"name\":\"Philipp Moritz\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Blei . Black box variational inference\",\"url\":\"\",\"venue\":\"Tutorial on thompson sampling . arxiv\",\"year\":2015},{\"arxivId\":\"1703.07608\",\"authors\":[{\"authorId\":\"2561924\",\"name\":\"Ian Osband\"},{\"authorId\":\"145751896\",\"name\":\"D. Russo\"},{\"authorId\":\"39761651\",\"name\":\"Z. Wen\"},{\"authorId\":\"1731282\",\"name\":\"Benjamin Van Roy\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a441728f9fd6af1946368240162a72c2028c8cb1\",\"title\":\"Deep Exploration via Randomized Value Functions\",\"url\":\"https://www.semanticscholar.org/paper/a441728f9fd6af1946368240162a72c2028c8cb1\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2019},{\"arxivId\":\"1509.02971\",\"authors\":[{\"authorId\":\"2542999\",\"name\":\"T. Lillicrap\"},{\"authorId\":\"2323922\",\"name\":\"J. Hunt\"},{\"authorId\":\"1863250\",\"name\":\"A. Pritzel\"},{\"authorId\":\"2801204\",\"name\":\"N. Heess\"},{\"authorId\":\"1968210\",\"name\":\"T. Erez\"},{\"authorId\":\"2109481\",\"name\":\"Y. Tassa\"},{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"1688276\",\"name\":\"Daan Wierstra\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"024006d4c2a89f7acacc6e4438d156525b60a98f\",\"title\":\"Continuous control with deep reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/024006d4c2a89f7acacc6e4438d156525b60a98f\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":\"1507.00300\",\"authors\":[{\"authorId\":\"2561924\",\"name\":\"Ian Osband\"},{\"authorId\":\"1731282\",\"name\":\"Benjamin Van Roy\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"909f736182963dcee2cb2e8c567e2069192b4749\",\"title\":\"Bootstrapped Thompson Sampling and Deep Exploration\",\"url\":\"https://www.semanticscholar.org/paper/909f736182963dcee2cb2e8c567e2069192b4749\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yunhao Tang\"},{\"authorId\":null,\"name\":\"Alp Kucukelbir. Variational deep q network\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"2nd Workshop on Bayesian Deep Learning\",\"url\":\"\",\"venue\":\"NIPS,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Matthias Plappert\"},{\"authorId\":null,\"name\":\"Rein Houthooft\"},{\"authorId\":null,\"name\":\"Prafulla Dhariwal\"},{\"authorId\":null,\"name\":\"Szymon Sidor\"},{\"authorId\":null,\"name\":\"Richard Y. Chen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\", Xi Chen , Tamim Asfour , Pieter Abbeel , and Marcin Andrychowicz . Parameter space noise for exploration\",\"url\":\"\",\"venue\":\"ternational Conference on Learning Representation\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ian Osband\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"daniel Russo\",\"url\":\"\",\"venue\":\"Zheng Wen, and Benjamin Van Roy. Deep exploration via randomized value functions. arXiv: 1703.07608,\",\"year\":2017},{\"arxivId\":\"1608.05081\",\"authors\":[{\"authorId\":\"32219137\",\"name\":\"Zachary Chase Lipton\"},{\"authorId\":\"47058148\",\"name\":\"Xiujun Li\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"47681372\",\"name\":\"Lihong Li\"},{\"authorId\":\"144986722\",\"name\":\"F. Ahmed\"},{\"authorId\":\"144718794\",\"name\":\"Li Deng\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ab193c05bc447f368565c1ff37064b1c517a750f\",\"title\":\"Efficient Dialogue Policy Learning with BBQ-Networks\",\"url\":\"https://www.semanticscholar.org/paper/ab193c05bc447f368565c1ff37064b1c517a750f\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1711.10789\",\"authors\":[{\"authorId\":\"13477045\",\"name\":\"T. M. Moerland\"},{\"authorId\":\"1735303\",\"name\":\"J. Broekens\"},{\"authorId\":\"1689001\",\"name\":\"C. Jonker\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6f40b8d2e73ec0bcc4d12ec2c7c8387d53c7727b\",\"title\":\"Efficient exploration with Double Uncertain Value Networks\",\"url\":\"https://www.semanticscholar.org/paper/6f40b8d2e73ec0bcc4d12ec2c7c8387d53c7727b\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Rejesh Ranganath\"},{\"authorId\":null,\"name\":\"Sean Gerrish\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Blei . Black box variational inference\",\"url\":\"\",\"venue\":\"Tutorial on thompson sampling . arxiv\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Peter Henderson\"},{\"authorId\":null,\"name\":\"Thang Doan\"},{\"authorId\":null,\"name\":\"Riashat Islam\"},{\"authorId\":null,\"name\":\"David Meger. Bayesian policy gradients via alpha diverge inference\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"2nd Workshop on Bayesian Deep Learning\",\"url\":\"\",\"venue\":\"NIPS,\",\"year\":2017},{\"arxivId\":\"1502.05477\",\"authors\":[{\"authorId\":\"47971768\",\"name\":\"John Schulman\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"},{\"authorId\":\"1694621\",\"name\":\"Michael I. Jordan\"},{\"authorId\":\"29912342\",\"name\":\"P. Moritz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"66cdc28dc084af6507e979767755e99fe0b46b39\",\"title\":\"Trust Region Policy Optimization\",\"url\":\"https://www.semanticscholar.org/paper/66cdc28dc084af6507e979767755e99fe0b46b39\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1203.3497\",\"authors\":[{\"authorId\":\"2273298\",\"name\":\"T. Morimura\"},{\"authorId\":\"67154907\",\"name\":\"Masashi Sugiyama\"},{\"authorId\":\"2785830\",\"name\":\"H. Kashima\"},{\"authorId\":\"40308003\",\"name\":\"H. Hachiya\"},{\"authorId\":\"145876882\",\"name\":\"Toshiyuki TANAKA\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8948464fc8dbe49311fcd6610f96bcd75a03bae0\",\"title\":\"Parametric Return Density Estimation for Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/8948464fc8dbe49311fcd6610f96bcd75a03bae0\",\"venue\":\"UAI\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144224173\",\"name\":\"J. Tsitsiklis\"},{\"authorId\":\"1731282\",\"name\":\"Benjamin Van Roy\"}],\"doi\":\"10.1007/BF00114724\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cc9cceefa16164b70a9448ce33e700e2fcc204a3\",\"title\":\"Feature-based methods for large scale dynamic programming\",\"url\":\"https://www.semanticscholar.org/paper/cc9cceefa16164b70a9448ce33e700e2fcc204a3\",\"venue\":\"Machine Learning\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144832491\",\"name\":\"E. Todorov\"},{\"authorId\":\"1968210\",\"name\":\"T. Erez\"},{\"authorId\":\"2109481\",\"name\":\"Y. Tassa\"}],\"doi\":\"10.1109/IROS.2012.6386109\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b354ee518bfc1ac0d8ac447eece9edb69e92eae1\",\"title\":\"MuJoCo: A physics engine for model-based control\",\"url\":\"https://www.semanticscholar.org/paper/b354ee518bfc1ac0d8ac447eece9edb69e92eae1\",\"venue\":\"2012 IEEE/RSJ International Conference on Intelligent Robots and Systems\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Thomas M. Moerland\"},{\"authorId\":null,\"name\":\"Joost Broekens\"},{\"authorId\":null,\"name\":\"Catholijn M. Jonker. Efficient exploration with double uncer networks\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Symposium on Deep Reinforcement Learning\",\"url\":\"\",\"venue\":\"NIPS,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"William R. Thompson. On the likelihood that one unknown pr Biometrika\"},{\"authorId\":null,\"name\":\"Vol\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"25\",\"url\":\"\",\"venue\":\"No. 3/4,\",\"year\":1933},{\"arxivId\":\"1604.06778\",\"authors\":[{\"authorId\":\"144581158\",\"name\":\"Yan Duan\"},{\"authorId\":\"41192764\",\"name\":\"Xi Chen\"},{\"authorId\":\"3127100\",\"name\":\"Rein Houthooft\"},{\"authorId\":\"47971768\",\"name\":\"John Schulman\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1464776f20e2bccb6182f183b5ff2e15b0ae5e56\",\"title\":\"Benchmarking Deep Reinforcement Learning for Continuous Control\",\"url\":\"https://www.semanticscholar.org/paper/1464776f20e2bccb6182f183b5ff2e15b0ae5e56\",\"venue\":\"ICML\",\"year\":2016},{\"arxivId\":\"1707.02038\",\"authors\":[{\"authorId\":\"145751896\",\"name\":\"D. Russo\"},{\"authorId\":\"1731282\",\"name\":\"Benjamin Van Roy\"},{\"authorId\":\"48023738\",\"name\":\"A. Kazerouni\"},{\"authorId\":\"2561924\",\"name\":\"Ian Osband\"}],\"doi\":\"10.1561/2200000070\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"01f6488741f1527201a428c7b05df9649cb9a631\",\"title\":\"A Tutorial on Thompson Sampling\",\"url\":\"https://www.semanticscholar.org/paper/01f6488741f1527201a428c7b05df9649cb9a631\",\"venue\":\"Found. Trends Mach. Learn.\",\"year\":2018},{\"arxivId\":\"1706.01905\",\"authors\":[{\"authorId\":\"3407285\",\"name\":\"Matthias Plappert\"},{\"authorId\":\"3127100\",\"name\":\"Rein Houthooft\"},{\"authorId\":\"6515819\",\"name\":\"Prafulla Dhariwal\"},{\"authorId\":\"2700360\",\"name\":\"S. Sidor\"},{\"authorId\":\"2896187\",\"name\":\"Richard Y. Chen\"},{\"authorId\":\"41192764\",\"name\":\"Xi Chen\"},{\"authorId\":\"1722677\",\"name\":\"T. Asfour\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"},{\"authorId\":\"2206490\",\"name\":\"Marcin Andrychowicz\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"142497432fe179ddb6ffe600c64a837ec6179550\",\"title\":\"Parameter Space Noise for Exploration\",\"url\":\"https://www.semanticscholar.org/paper/142497432fe179ddb6ffe600c64a837ec6179550\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1712.02037\",\"authors\":[{\"authorId\":\"40068904\",\"name\":\"Peter Henderson\"},{\"authorId\":\"33554869\",\"name\":\"Thang Doan\"},{\"authorId\":\"18014232\",\"name\":\"R. Islam\"},{\"authorId\":\"2462512\",\"name\":\"D. Meger\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"684b5100e0328d4257dc6568fafd76cbcd40cdaf\",\"title\":\"Bayesian Policy Gradients via Alpha Divergence Dropout Inference\",\"url\":\"https://www.semanticscholar.org/paper/684b5100e0328d4257dc6568fafd76cbcd40cdaf\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Kamyar Azizzadenesheli\"},{\"authorId\":null,\"name\":\"Emma Brunskill\"},{\"authorId\":null,\"name\":\"Animashree Anandkumar. Efficient exploration through bayesian networks\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Symposium on Deep Reinforcement Learning\",\"url\":\"\",\"venue\":\"NIPS,\",\"year\":2017}],\"title\":\"Exploration by Distributional Reinforcement Learning\",\"topics\":[{\"topic\":\"Reinforcement learning\",\"topicId\":\"2557\",\"url\":\"https://www.semanticscholar.org/topic/2557\"},{\"topic\":\"Algorithm\",\"topicId\":\"305\",\"url\":\"https://www.semanticscholar.org/topic/305\"},{\"topic\":\"RL (complexity)\",\"topicId\":\"3597734\",\"url\":\"https://www.semanticscholar.org/topic/3597734\"},{\"topic\":\"Sampling (signal processing)\",\"topicId\":\"7839\",\"url\":\"https://www.semanticscholar.org/topic/7839\"}],\"url\":\"https://www.semanticscholar.org/paper/3995b02fb3d4be47de8cc1a178fe577a445ac5e7\",\"venue\":\"IJCAI\",\"year\":2018}\n"