"{\"abstract\":\"Existing cross-media retrieval methods usually require that testing categories remain the same with training categories, which cannot support the retrieval of increasing new categories. Inspired by zero-shot learning, this paper proposes zeroshot cross-media retrieval for addressing the above problem, which aims to retrieve data of new categories across different media types. It is challenging that zero-shot cross-media retrieval has to handle not only the inconsistent semantics across new and known categories, but also the heterogeneous distributions across different media types. To address the above challenges, this paper proposes Dual Adversarial Networks for Zero-shot Crossmedia Retrieval (DANZCR), which is the first approach to address zero-shot cross-media retrieval to the best of our knowledge. Our DANZCR approach consists of two GANs in a dual structure for common representation generation and original representation reconstruction respectively, which capture the underlying data structures as well as strengthen relations between input data and semantic space to generalize across seen and unseen categories. Our DANZCR approach exploits word embeddings to learn common representations in semantic space via an adversarial learning method, which preserves the inherent cross-media correlation and enhances the knowledge transfer to new categories. Experiments on three widely-used cross-media retrieval datasets show the effectiveness of our approach.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"36061091\",\"name\":\"Jingze Chi\",\"url\":\"https://www.semanticscholar.org/author/36061091\"},{\"authorId\":\"143753918\",\"name\":\"Y. Peng\",\"url\":\"https://www.semanticscholar.org/author/143753918\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"30895384\",\"name\":\"Titir Dutta\"},{\"authorId\":\"145702360\",\"name\":\"S. Biswas\"}],\"doi\":\"10.1109/TIP.2019.2923287\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ef397474c652fe1cb03508107dcb9f91e3bfcd2b\",\"title\":\"Generalized Zero-Shot Cross-Modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/ef397474c652fe1cb03508107dcb9f91e3bfcd2b\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40055538\",\"name\":\"C. Yang\"},{\"authorId\":\"1519971304\",\"name\":\"Xiaochan Wang\"},{\"authorId\":\"145942580\",\"name\":\"B. Jiang\"}],\"doi\":\"10.1109/ACCESS.2020.2989473\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7efb2bc1d440320de5c38b3c3b1529a93b4dca90\",\"title\":\"Sentiment Enhanced Multi-Modal Hashtag Recommendation for Micro-Videos\",\"url\":\"https://www.semanticscholar.org/paper/7efb2bc1d440320de5c38b3c3b1529a93b4dca90\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1811.02740\",\"authors\":[{\"authorId\":\"144142354\",\"name\":\"Rui Zhang\"},{\"authorId\":\"144044848\",\"name\":\"Sheng Tang\"},{\"authorId\":\"3503889\",\"name\":\"Y. Li\"},{\"authorId\":\"2031845\",\"name\":\"Junbo Guo\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"},{\"authorId\":\"1706774\",\"name\":\"J. Li\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"}],\"doi\":\"10.1145/3240508.3240524\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"13402ca147038e8424a4ac18ecfff968083308d1\",\"title\":\"Style Separation and Synthesis via Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/13402ca147038e8424a4ac18ecfff968083308d1\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30895384\",\"name\":\"Titir Dutta\"},{\"authorId\":\"145702360\",\"name\":\"S. Biswas\"}],\"doi\":\"10.1016/J.PATREC.2019.06.023\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d4c2c47668544b4a890e081ddd4ec428c3eea9ca\",\"title\":\"Cross-modal retrieval in challenging scenarios using attributes\",\"url\":\"https://www.semanticscholar.org/paper/d4c2c47668544b4a890e081ddd4ec428c3eea9ca\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47158869\",\"name\":\"Xing Xu\"},{\"authorId\":\"1830455342\",\"name\":\"K. Lin\"},{\"authorId\":\"143663465\",\"name\":\"Huimin Lu\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1145/3397271.3401149\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8174797fc152649bfa85f60ce99a659fbd9686e9\",\"title\":\"Correlated Features Synthesis and Alignment for Zero-shot Cross-modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/8174797fc152649bfa85f60ce99a659fbd9686e9\",\"venue\":\"SIGIR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47987347\",\"name\":\"Hong-Chang Wu\"},{\"authorId\":\"1749272\",\"name\":\"Ziyu Guan\"},{\"authorId\":\"66883696\",\"name\":\"Tao Zhi\"},{\"authorId\":\"98902616\",\"name\":\"Wei Zhao\"},{\"authorId\":\"144795387\",\"name\":\"C. Xu\"},{\"authorId\":\"144003845\",\"name\":\"Hong Han\"},{\"authorId\":\"1455886221\",\"name\":\"Yaming Yang\"}],\"doi\":\"10.1109/ICBK.2019.00043\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"587c8207b77bf132d99eb1dbdd8ad64fd281ad77\",\"title\":\"Adversarial Graph Attention Network for Multi-modal Cross-Modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/587c8207b77bf132d99eb1dbdd8ad64fd281ad77\",\"venue\":\"2019 IEEE International Conference on Big Knowledge (ICBK)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47158869\",\"name\":\"Xing Xu\"},{\"authorId\":\"143663452\",\"name\":\"Huimin Lu\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"27718163\",\"name\":\"Y. Yang\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"},{\"authorId\":\"40286455\",\"name\":\"Xuelong Li\"}],\"doi\":\"10.1109/TCYB.2019.2928180\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"07daca3acd1025b68b0bef27e451ffb9ea7f607b\",\"title\":\"Ternary Adversarial Networks With Self-Supervision for Zero-Shot Cross-Modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/07daca3acd1025b68b0bef27e451ffb9ea7f607b\",\"venue\":\"IEEE Transactions on Cybernetics\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36061091\",\"name\":\"Jingze Chi\"},{\"authorId\":\"143753918\",\"name\":\"Y. Peng\"}],\"doi\":\"10.1109/TCSVT.2019.2900171\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"226613c3248e26437ec4a93e3513e636b0858f11\",\"title\":\"Zero-Shot Cross-Media Embedding Learning With Dual Adversarial Distribution Network\",\"url\":\"https://www.semanticscholar.org/paper/226613c3248e26437ec4a93e3513e636b0858f11\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1786516\",\"name\":\"Liangli Zhen\"},{\"authorId\":\"143941718\",\"name\":\"P. Hu\"},{\"authorId\":\"144152343\",\"name\":\"Xi Peng\"},{\"authorId\":\"1729436\",\"name\":\"R. Goh\"},{\"authorId\":\"10638646\",\"name\":\"Joey Tianyi Zhou\"}],\"doi\":\"10.1109/TNNLS.2020.3029181\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5971a1320f1285cbc959e6d63756c4a3b869859c\",\"title\":\"Deep Multimodal Transfer Learning for Cross-Modal Retrieval.\",\"url\":\"https://www.semanticscholar.org/paper/5971a1320f1285cbc959e6d63756c4a3b869859c\",\"venue\":\"IEEE transactions on neural networks and learning systems\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47733442\",\"name\":\"Niluthpol Chowdhury Mithun\"},{\"authorId\":null,\"name\":\"Juncheng Li\"},{\"authorId\":\"1740721\",\"name\":\"F. Metze\"},{\"authorId\":\"2968713\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":\"10.1007/s13735-018-00166-3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6305115f393d96df92f9044b8951969e28aa7114\",\"title\":\"Joint embeddings with multimodal cues for video-text retrieval\",\"url\":\"https://www.semanticscholar.org/paper/6305115f393d96df92f9044b8951969e28aa7114\",\"venue\":\"International Journal of Multimedia Information Retrieval\",\"year\":2018},{\"arxivId\":\"1909.06635\",\"authors\":[{\"authorId\":\"32370882\",\"name\":\"Shweta Mahajan\"},{\"authorId\":\"25080314\",\"name\":\"Teresa Botschen\"},{\"authorId\":\"1730400\",\"name\":\"Iryna Gurevych\"},{\"authorId\":\"145920814\",\"name\":\"S. Roth\"}],\"doi\":\"10.1109/ICCVW.2019.00557\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f81c842e37eb0c22528f1bf569514b379cf489ea\",\"title\":\"Joint Wasserstein Autoencoders for Aligning Multimodal Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/f81c842e37eb0c22528f1bf569514b379cf489ea\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"2007.12212\",\"authors\":[{\"authorId\":\"9534640\",\"name\":\"Anurag Roy\"},{\"authorId\":\"39433957\",\"name\":\"V. Verma\"},{\"authorId\":\"153408379\",\"name\":\"Kripabandhu Ghosh\"},{\"authorId\":\"143841814\",\"name\":\"S. Ghosh\"}],\"doi\":\"10.1145/3340531.3411995\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ed834ff7a815406e512c4dddf02807044e71aba8\",\"title\":\"ZSCRGAN: A GAN-based Expectation Maximization Model for Zero-Shot Retrieval of Images from Textual Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/ed834ff7a815406e512c4dddf02807044e71aba8\",\"venue\":\"CIKM\",\"year\":2020}],\"corpusId\":51607084,\"doi\":\"10.24963/ijcai.2018/92\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":3,\"is_open_access\":true,\"is_publisher_licensed\":false,\"paperId\":\"8fa404eae66daeacdfa281b058c423f6216f99a5\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"},{\"authorId\":\"8053308\",\"name\":\"J. Tang\"},{\"authorId\":\"48043335\",\"name\":\"R. Hong\"},{\"authorId\":\"2579920\",\"name\":\"Haojie Li\"},{\"authorId\":\"49386625\",\"name\":\"Zhiping Luo\"},{\"authorId\":\"1688985\",\"name\":\"Y. Zheng\"}],\"doi\":\"10.1145/1646396.1646452\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b80a580a6f2eca77524302acd944fd6edf0a0611\",\"title\":\"NUS-WIDE: a real-world web image database from National University of Singapore\",\"url\":\"https://www.semanticscholar.org/paper/b80a580a6f2eca77524302acd944fd6edf0a0611\",\"venue\":\"CIVR '09\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1712479\",\"name\":\"Mohamed Elhoseiny\"},{\"authorId\":\"3139794\",\"name\":\"B. Saleh\"},{\"authorId\":\"145159523\",\"name\":\"A. Elgammal\"}],\"doi\":\"10.1109/ICCV.2013.321\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f038e8c3656f5c7a4846a7eca731eb567255adcb\",\"title\":\"Write a Classifier: Zero-Shot Learning Using Purely Textual Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/f038e8c3656f5c7a4846a7eca731eb567255adcb\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ali Farhadi\"},{\"authorId\":null,\"name\":\"Ian Endres\"},{\"authorId\":null,\"name\":\"Derek Hoiem\"},{\"authorId\":null,\"name\":\"David Forsyth. Describing objects by their attributes\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In CVPR\",\"url\":\"\",\"venue\":\"pages 1778\\u20131785,\",\"year\":2009},{\"arxivId\":\"1704.02223\",\"authors\":[{\"authorId\":\"143753918\",\"name\":\"Y. Peng\"},{\"authorId\":\"47932618\",\"name\":\"X. Huang\"},{\"authorId\":\"3361463\",\"name\":\"Yunzhen Zhao\"}],\"doi\":\"10.1109/TCSVT.2017.2705068\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"50233ac68c2aa139fabe71e2844c2734adf39a3d\",\"title\":\"An Overview of Cross-Media Retrieval: Concepts, Methodologies, Benchmarks, and Challenges\",\"url\":\"https://www.semanticscholar.org/paper/50233ac68c2aa139fabe71e2844c2734adf39a3d\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Bokun Wang\"},{\"authorId\":null,\"name\":\"Yang Yang\"},{\"authorId\":null,\"name\":\"Xing Xu\"},{\"authorId\":null,\"name\":\"Alan Hanjalic\"},{\"authorId\":null,\"name\":\"Heng Tao Shen. Adversarial crossmodal retrieval\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In ACM MM\",\"url\":\"\",\"venue\":\"pages 154\\u2013162,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Zili Yi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Hao (Richard) Zhang\",\"url\":\"\",\"venue\":\"Ping Tan, and Minglun Gong. Dualgan: Unsupervised dual learning for image-to-image translation. In ICCV, pages 2868\\u20132876,\",\"year\":2017},{\"arxivId\":\"1609.04802\",\"authors\":[{\"authorId\":\"1779917\",\"name\":\"C. Ledig\"},{\"authorId\":\"2073063\",\"name\":\"L. Theis\"},{\"authorId\":\"3108066\",\"name\":\"Ferenc Husz\\u00e1r\"},{\"authorId\":\"79382929\",\"name\":\"J. Caballero\"},{\"authorId\":\"83015038\",\"name\":\"Andrew Aitken\"},{\"authorId\":\"41203992\",\"name\":\"Alykhan Tejani\"},{\"authorId\":\"1853456\",\"name\":\"J. Totz\"},{\"authorId\":\"34627233\",\"name\":\"Zehan Wang\"},{\"authorId\":\"152554375\",\"name\":\"W. Shi\"}],\"doi\":\"10.1109/CVPR.2017.19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"df0c54fe61f0ffb9f0e36a17c2038d9a1964cba3\",\"title\":\"Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network\",\"url\":\"https://www.semanticscholar.org/paper/df0c54fe61f0ffb9f0e36a17c2038d9a1964cba3\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1703.04394\",\"authors\":[{\"authorId\":\"3370667\",\"name\":\"Yongqin Xian\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"2893664\",\"name\":\"Zeynep Akata\"}],\"doi\":\"10.1109/CVPR.2017.328\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"89e88ab5b7ba7557573ad773a0a077484bee3759\",\"title\":\"Zero-Shot Learning \\u2014 The Good, the Bad and the Ugly\",\"url\":\"https://www.semanticscholar.org/paper/89e88ab5b7ba7557573ad773a0a077484bee3759\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2786437\",\"name\":\"Linghui Li\"},{\"authorId\":\"46321465\",\"name\":\"Sheng Tang\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"},{\"authorId\":\"4303531\",\"name\":\"Lixi Deng\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/TMM.2017.2751140\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2e0f1c89c4e099b14c4d77bd406be9f7b78d6f6d\",\"title\":\"GLA: Global\\u2013Local Attention for Image Description\",\"url\":\"https://www.semanticscholar.org/paper/2e0f1c89c4e099b14c4d77bd406be9f7b78d6f6d\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ian Goodfellow\"},{\"authorId\":null,\"name\":\"Jean PougetAbadie\"},{\"authorId\":null,\"name\":\"Mehdi Mirza\"},{\"authorId\":null,\"name\":\"Bing Xu\"},{\"authorId\":null,\"name\":\"David Warde-Farley\"},{\"authorId\":null,\"name\":\"Sherjil Ozair\"},{\"authorId\":null,\"name\":\"Aaron Courville\"},{\"authorId\":null,\"name\":\"Yoshua Bengio. Generative adversarial nets\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In NIPS\",\"url\":\"\",\"venue\":\"pages 2672\\u20132680,\",\"year\":2014},{\"arxivId\":null,\"authors\":[],\"doi\":\"10.1126/science.307.5713.1165j\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"62084c73c544f63b674eb6c9bc8c8d7e06b4eb98\",\"title\":\"The Bad and the Ugly?\",\"url\":\"https://www.semanticscholar.org/paper/62084c73c544f63b674eb6c9bc8c8d7e06b4eb98\",\"venue\":\"Science\",\"year\":2005},{\"arxivId\":\"1704.02510\",\"authors\":[{\"authorId\":\"39737792\",\"name\":\"Zili Yi\"},{\"authorId\":\"39497427\",\"name\":\"Hao Zhang\"},{\"authorId\":\"145604260\",\"name\":\"Ping Tan\"},{\"authorId\":\"34077629\",\"name\":\"Minglun Gong\"}],\"doi\":\"10.1109/ICCV.2017.310\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ef3c1f6c177e37f1d0d2a61702b60c766971700b\",\"title\":\"DualGAN: Unsupervised Dual Learning for Image-to-Image Translation\",\"url\":\"https://www.semanticscholar.org/paper/ef3c1f6c177e37f1d0d2a61702b60c766971700b\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1703.03567\",\"authors\":[{\"authorId\":\"2616738\",\"name\":\"Ruoyu Liu\"},{\"authorId\":\"38161033\",\"name\":\"Y. Zhao\"},{\"authorId\":\"144802394\",\"name\":\"L. Zheng\"},{\"authorId\":\"46730712\",\"name\":\"S. Wei\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9b7c6ef333c6e64f2dfa97a1a3614d0775d81a8a\",\"title\":\"A New Evaluation Protocol and Benchmarking Results for Extendable Cross-media Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/9b7c6ef333c6e64f2dfa97a1a3614d0775d81a8a\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49020088\",\"name\":\"Yunchao Wei\"},{\"authorId\":\"38161033\",\"name\":\"Y. Zhao\"},{\"authorId\":\"33224509\",\"name\":\"Canyi Lu\"},{\"authorId\":\"46730712\",\"name\":\"S. Wei\"},{\"authorId\":\"1776665\",\"name\":\"Luoqi Liu\"},{\"authorId\":\"1749780\",\"name\":\"Zhenfeng Zhu\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"}],\"doi\":\"10.1109/TCYB.2016.2519449\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ce3c5b0691d9e05061adc0a6fed8acb2607b1423\",\"title\":\"Cross-Modal Retrieval With CNN Visual Features: A New Baseline\",\"url\":\"https://www.semanticscholar.org/paper/ce3c5b0691d9e05061adc0a6fed8acb2607b1423\",\"venue\":\"IEEE Transactions on Cybernetics\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3202483\",\"name\":\"Cuicui Kang\"},{\"authorId\":\"1683738\",\"name\":\"S. Xiang\"},{\"authorId\":\"40397682\",\"name\":\"S. Liao\"},{\"authorId\":\"145194969\",\"name\":\"C. Xu\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.1109/TMM.2015.2390499\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e0dd18efe88b30abb91579da66cd2c128b34f5fb\",\"title\":\"Learning Consistent Feature Representation for Cross-Modal Multimedia Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/e0dd18efe88b30abb91579da66cd2c128b34f5fb\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2015},{\"arxivId\":\"1506.00511\",\"authors\":[{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"1754860\",\"name\":\"Kevin Swersky\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":\"10.1109/ICCV.2015.483\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6540cb7971d1a9d72562d465172e010fbb729bc3\",\"title\":\"Predicting Deep Zero-Shot Convolutional Neural Networks Using Textual Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/6540cb7971d1a9d72562d465172e010fbb729bc3\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Shuang Wu\"},{\"authorId\":null,\"name\":\"Sravanthi Bondugula\"},{\"authorId\":null,\"name\":\"Florian Luisier\"},{\"authorId\":null,\"name\":\"Xiaodan Zhuang\"},{\"authorId\":null,\"name\":\"Pradeep Natarajan. Zeroshot event detection using multi-mo concepts\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In CVPR\",\"url\":\"\",\"venue\":\"pages 2665\\u20132672,\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jimmy Lei Ba\"},{\"authorId\":null,\"name\":\"Kevin Swersky\"},{\"authorId\":null,\"name\":\"Sanja Fidler\"},{\"authorId\":null,\"name\":\"Ruslan Salakhutdinov. Predicting deep zero-shot convoluti descriptions\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In ICCV\",\"url\":\"\",\"venue\":\"pages 4247\\u20134255,\",\"year\":2016},{\"arxivId\":\"1411.1784\",\"authors\":[{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"2217144\",\"name\":\"Simon Osindero\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"353ecf7b66b3e9ff5e9f41145a147e899a2eea5c\",\"title\":\"Conditional Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/353ecf7b66b3e9ff5e9f41145a147e899a2eea5c\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Ieee Transactions on Circuits and Systems for Video Technology 1\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jun-Yan Zhu\"},{\"authorId\":null,\"name\":\"Taesung Park\"},{\"authorId\":null,\"name\":\"Phillip Isola\"},{\"authorId\":null,\"name\":\"Alexei A. Efros. Unpaired image-to-image translation usin networks\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In ICCV\",\"url\":\"\",\"venue\":\"pages 2242\\u20132251,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Linghui Li\"},{\"authorId\":null,\"name\":\"Sheng Tang\"},{\"authorId\":null,\"name\":\"Yongdong Zhang\"},{\"authorId\":null,\"name\":\"Lixi Deng\"},{\"authorId\":null,\"name\":\"Qi Tian\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Aitken , Alykhan Tejani , Johannes Totz , Zehan Wang , and Wenzhe Shi . Photo - realistic single image super - resolution using a generative adversarial network\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2743563\",\"name\":\"Xiaohua Zhai\"},{\"authorId\":\"143753918\",\"name\":\"Y. Peng\"},{\"authorId\":\"2888671\",\"name\":\"J. Xiao\"}],\"doi\":\"10.1109/TCSVT.2013.2276704\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"71eb620608a71886dafd77b08523c3cd5b371b1c\",\"title\":\"Learning Cross-Media Joint Representation With Sparse and Semisupervised Regularization\",\"url\":\"https://www.semanticscholar.org/paper/71eb620608a71886dafd77b08523c3cd5b371b1c\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Tat-Seng Chua\"},{\"authorId\":null,\"name\":\"Jinhui Tang\"},{\"authorId\":null,\"name\":\"Richang Hong\"},{\"authorId\":null,\"name\":\"Haojie Li\"},{\"authorId\":null,\"name\":\"Zhiping Luo\"},{\"authorId\":null,\"name\":\"Yantao Zheng\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"NUSWIDE: a real-world web image database from national university of singapore\",\"url\":\"\",\"venue\":\"CIVR, pages 1\\u20139,\",\"year\":2009},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yueting Zhuang\"},{\"authorId\":null,\"name\":\"Yanfei Wang\"},{\"authorId\":null,\"name\":\"Fei Wu\"},{\"authorId\":null,\"name\":\"Yin Zhang\"},{\"authorId\":null,\"name\":\"Weiming Lu. Supervised coupled dictionary learning with gr retrieval\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In AAAI\",\"url\":\"\",\"venue\":\"pages 1070\\u20131076,\",\"year\":2013},{\"arxivId\":\"1511.06434\",\"authors\":[{\"authorId\":\"38909097\",\"name\":\"A. Radford\"},{\"authorId\":\"2096458\",\"name\":\"Luke Metz\"},{\"authorId\":\"2127604\",\"name\":\"Soumith Chintala\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8388f1be26329fa45e5807e968a641ce170ea078\",\"title\":\"Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/8388f1be26329fa45e5807e968a641ce170ea078\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Quoc Le\"},{\"authorId\":null,\"name\":\"Tomas Mikolov. Distributed representations of sentences\"},{\"authorId\":null,\"name\":\"documents\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In ICML\",\"url\":\"\",\"venue\":\"pages 1188\\u20131196,\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Nikhil Rasiwasia\"},{\"authorId\":null,\"name\":\"Jose Costa Pereira\"},{\"authorId\":null,\"name\":\"Emanuele Coviello\"},{\"authorId\":null,\"name\":\"Gabriel Doyle\"},{\"authorId\":null,\"name\":\"Gert RG Lanckriet\"},{\"authorId\":null,\"name\":\"Roger Levy\"},{\"authorId\":null,\"name\":\"Nuno Vasconcelos. A new approach to cross-modal multime retrieval\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In ACM MM\",\"url\":\"\",\"venue\":\"pages 251\\u2013260,\",\"year\":2010},{\"arxivId\":\"1301.3781\",\"authors\":[{\"authorId\":null,\"name\":\"Tomas Mikolov\"},{\"authorId\":\"38644044\",\"name\":\"Kai Chen\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"330da625c15427c6e42ccfa3b747fb29e5835bf0\",\"title\":\"Efficient Estimation of Word Representations in Vector Space\",\"url\":\"https://www.semanticscholar.org/paper/330da625c15427c6e42ccfa3b747fb29e5835bf0\",\"venue\":\"ICLR\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Cuicui Kang\"},{\"authorId\":null,\"name\":\"Shiming Xiang\"},{\"authorId\":null,\"name\":\"Shengcai Liao\"},{\"authorId\":null,\"name\":\"Changsheng Xu\"},{\"authorId\":null,\"name\":\"Chunhong Pan. Learning consistent feature representation fo retrieval\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"IEEE Transactions on Multimedia (TMM)\",\"url\":\"\",\"venue\":\"17(3):370\\u2013381,\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Hugo Larochelle\"},{\"authorId\":null,\"name\":\"Dumitru Erhan\"},{\"authorId\":null,\"name\":\"Yoshua Bengio. Zero-data learning of new tasks\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In AAAI\",\"url\":\"\",\"venue\":\"pages 646\\u2013651,\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21243543\",\"name\":\"Shuang Wu\"},{\"authorId\":\"1828838\",\"name\":\"Sravanthi Bondugula\"},{\"authorId\":\"1689313\",\"name\":\"Florian Luisier\"},{\"authorId\":\"2433508\",\"name\":\"Xiaodan Zhuang\"},{\"authorId\":\"49824581\",\"name\":\"P. Natarajan\"}],\"doi\":\"10.1109/CVPR.2014.341\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"16a4e39dfa15e9ae5906a521464e008a24e628b4\",\"title\":\"Zero-Shot Event Detection Using Multi-modal Fusion of Weakly Supervised Concepts\",\"url\":\"https://www.semanticscholar.org/paper/16a4e39dfa15e9ae5906a521464e008a24e628b4\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1888731\",\"name\":\"M. Hejrati\"},{\"authorId\":\"21160985\",\"name\":\"M. Sadeghi\"},{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"3125805\",\"name\":\"Cyrus Rashtchian\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"144016256\",\"name\":\"D. Forsyth\"}],\"doi\":\"10.1007/978-3-642-15561-1_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eaaed23a2d94feb2f1c3ff22a25777c7a78f3141\",\"title\":\"Every Picture Tells a Story: Generating Sentences from Images\",\"url\":\"https://www.semanticscholar.org/paper/eaaed23a2d94feb2f1c3ff22a25777c7a78f3141\",\"venue\":\"ECCV\",\"year\":2010}],\"title\":\"Dual Adversarial Networks for Zero-shot Cross-media Retrieval\",\"topics\":[{\"topic\":\"Data structure\",\"topicId\":\"3949\",\"url\":\"https://www.semanticscholar.org/topic/3949\"},{\"topic\":\"Teaching method\",\"topicId\":\"73414\",\"url\":\"https://www.semanticscholar.org/topic/73414\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"}],\"url\":\"https://www.semanticscholar.org/paper/8fa404eae66daeacdfa281b058c423f6216f99a5\",\"venue\":\"IJCAI\",\"year\":2018}\n"