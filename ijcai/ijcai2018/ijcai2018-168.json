"{\"abstract\":\"In this paper, we propose a Multi-task Learning Approach for Image Captioning (MLAIC), motivated by the fact that humans have no difficulty performing such task because they have the capabilities of multiple domains. Specifically, MLAIC consists of three key components: (i) A multi-object classification model that learns rich category-aware image representations using a CNN image encoder; (ii) A syntax generation model that learns better syntaxaware LSTM based decoder; (iii) An image captioning model that generates image descriptions in text, sharing its CNN encoder and LSTM decoder with the object classification task and the syntax generation task, respectively. In particular, the image captioning model can benefit from the additional object categorization and syntax knowledge. The experimental results on MS-COCO dataset demonstrate that our model achieves impressive results compared to other strong competitors.1\",\"arxivId\":null,\"authors\":[{\"authorId\":\"47748857\",\"name\":\"Wei Zhao\",\"url\":\"https://www.semanticscholar.org/author/47748857\"},{\"authorId\":\"2894465\",\"name\":\"Benyou Wang\",\"url\":\"https://www.semanticscholar.org/author/2894465\"},{\"authorId\":\"145581826\",\"name\":\"Jianbo Ye\",\"url\":\"https://www.semanticscholar.org/author/145581826\"},{\"authorId\":\"144346838\",\"name\":\"Min Yang\",\"url\":\"https://www.semanticscholar.org/author/144346838\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\",\"url\":\"https://www.semanticscholar.org/author/47122432\"},{\"authorId\":\"3212867\",\"name\":\"R. Luo\",\"url\":\"https://www.semanticscholar.org/author/3212867\"},{\"authorId\":null,\"name\":\"Yu Qiao\",\"url\":null}],\"citationVelocity\":8,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"48195668\",\"name\":\"Jin Yuan\"},{\"authorId\":\"47059067\",\"name\":\"L. Zhang\"},{\"authorId\":\"2836997\",\"name\":\"Songrui Guo\"},{\"authorId\":\"1406190317\",\"name\":\"Y. Xiao\"},{\"authorId\":\"152985786\",\"name\":\"Z. Li\"}],\"doi\":\"10.1145/3394955\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2f977b1d34ad883483727a3c8c52e20b260ac0ad\",\"title\":\"Image Captioning with a Joint Attention Mechanism by Visual Concept Samples\",\"url\":\"https://www.semanticscholar.org/paper/2f977b1d34ad883483727a3c8c52e20b260ac0ad\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1492164677\",\"name\":\"Min Yang\"},{\"authorId\":\"2948588\",\"name\":\"Junhao Liu\"},{\"authorId\":\"143822675\",\"name\":\"Ying Shen\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"40265331\",\"name\":\"X. Chen\"},{\"authorId\":\"31060469\",\"name\":\"Qingyao Wu\"},{\"authorId\":\"48161719\",\"name\":\"C. Li\"}],\"doi\":\"10.1109/TIP.2020.3028651\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f6a09cd467a2752e60a2766160a00c658667043e\",\"title\":\"An Ensemble of Generation- and Retrieval-Based Image Captioning With Dual Generator Generative Adversarial Network\",\"url\":\"https://www.semanticscholar.org/paper/f6a09cd467a2752e60a2766160a00c658667043e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1400258083\",\"name\":\"Chunpu Xu\"},{\"authorId\":\"47748857\",\"name\":\"Wei Zhao\"},{\"authorId\":\"31991405\",\"name\":\"Min Yang\"},{\"authorId\":\"2441161\",\"name\":\"Xiang Ao\"},{\"authorId\":\"1405918472\",\"name\":\"Wangrong Cheng\"},{\"authorId\":\"1936983\",\"name\":\"J. Tian\"}],\"doi\":\"10.1145/3357384.3358105\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e81c97c18cb4f4922e4442664350350536a71a13\",\"title\":\"A Unified Generation-Retrieval Framework for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/e81c97c18cb4f4922e4442664350350536a71a13\",\"venue\":\"CIKM\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1784737\",\"name\":\"K. Lei\"},{\"authorId\":\"1382556324\",\"name\":\"Qiuai Fu\"},{\"authorId\":\"1390524507\",\"name\":\"Yuzhi Liang\"}],\"doi\":\"10.1109/IJCNN.2019.8852189\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"75672f66b71bf6e1ba07055f2df20fd48e6b0b69\",\"title\":\"Multi-Task Learning with Capsule Networks\",\"url\":\"https://www.semanticscholar.org/paper/75672f66b71bf6e1ba07055f2df20fd48e6b0b69\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":\"1906.06620\",\"authors\":[{\"authorId\":\"2251827\",\"name\":\"Gil Sadeh\"},{\"authorId\":\"46397904\",\"name\":\"L. Fritz\"},{\"authorId\":\"36004650\",\"name\":\"Gabi Shalev\"},{\"authorId\":\"40135367\",\"name\":\"E. Oks\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ad4a9a87e2a49d7477c0a3fb371a1a211e597761\",\"title\":\"Joint Visual-Textual Embedding for Multimodal Style Search\",\"url\":\"https://www.semanticscholar.org/paper/ad4a9a87e2a49d7477c0a3fb371a1a211e597761\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2059218\",\"name\":\"Ankit Khare\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"01fe0c5f0d033141a29f4958f15520798022bbe7\",\"title\":\"ULTRA-CONTEXT: MAXIMIZING THE CONTEXT FOR BETTER IMAGE CAPTION GENERATION\",\"url\":\"https://www.semanticscholar.org/paper/01fe0c5f0d033141a29f4958f15520798022bbe7\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2002.06701\",\"authors\":[{\"authorId\":\"151430668\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"19b00a2bd1624a0931069a539a971e40b65bfb3a\",\"title\":\"Gaussian Smoothen Semantic Features (GSSF) - Exploring the Linguistic Aspects of Visual Captioning in Indian Languages (Bengali) Using MSCOCO Framework\",\"url\":\"https://www.semanticscholar.org/paper/19b00a2bd1624a0931069a539a971e40b65bfb3a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1907.09358\",\"authors\":[{\"authorId\":\"3219864\",\"name\":\"Aditya Mogadala\"},{\"authorId\":\"151119369\",\"name\":\"M. Kalimuthu\"},{\"authorId\":\"2561225\",\"name\":\"D. Klakow\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f8a48678094adbe421d61d0045361bfc635a2900\",\"title\":\"Trends in Integration of Vision and Language Research: A Survey of Tasks, Datasets, and Methods\",\"url\":\"https://www.semanticscholar.org/paper/f8a48678094adbe421d61d0045361bfc635a2900\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151430668\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s11042-019-08021-1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1ba03c16bf25d33efc0d977ab51392e1d9b5a0fb\",\"title\":\"Survey of deep learning and architectures for visual captioning\\u2014transitioning between media and natural languages\",\"url\":\"https://www.semanticscholar.org/paper/1ba03c16bf25d33efc0d977ab51392e1d9b5a0fb\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19209527\",\"name\":\"Mingkuan Yuan\"},{\"authorId\":\"92817440\",\"name\":\"Yuxin Peng\"}],\"doi\":\"10.1109/TMM.2019.2951463\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"70de83272caac9af3bb1dd6a159ec3c1b314ff8e\",\"title\":\"CKD: Cross-Task Knowledge Distillation for Text-to-Image Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/70de83272caac9af3bb1dd6a159ec3c1b314ff8e\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50982992\",\"name\":\"Yaqiang Yao\"},{\"authorId\":\"144473268\",\"name\":\"J. Cao\"},{\"authorId\":\"50688910\",\"name\":\"H. Chen\"}],\"doi\":\"10.1145/3292500.3330904\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e52fa7d5e3fe8ebeba5da59cae3874247305fa14\",\"title\":\"Robust Task Grouping with Representative Tasks for Clustered Multi-Task Learning\",\"url\":\"https://www.semanticscholar.org/paper/e52fa7d5e3fe8ebeba5da59cae3874247305fa14\",\"venue\":\"KDD\",\"year\":2019},{\"arxivId\":\"2010.08189\",\"authors\":[{\"authorId\":\"2283009\",\"name\":\"W. Chen\"},{\"authorId\":\"46315247\",\"name\":\"W. Wang\"},{\"authorId\":\"87109212\",\"name\":\"Li Liu\"},{\"authorId\":\"1731570\",\"name\":\"M. Lew\"}],\"doi\":\"10.1016/j.neucom.2020.10.042\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"61ba6969078b7358c61f7eb93b4150ab0e4f329b\",\"title\":\"New Ideas and Trends in Deep Multimodal Content Understanding: A Review\",\"url\":\"https://www.semanticscholar.org/paper/61ba6969078b7358c61f7eb93b4150ab0e4f329b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s13735-020-00198-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8c85757cdd7de5f99ab1717a6355a09bb717013c\",\"title\":\"MRECN: mixed representation enhanced (de)compositional network for caption generation from visual features, modeling as pseudo tensor product representation\",\"url\":\"https://www.semanticscholar.org/paper/8c85757cdd7de5f99ab1717a6355a09bb717013c\",\"venue\":\"Int. J. Multim. Inf. Retr.\",\"year\":2020},{\"arxivId\":\"1905.11569\",\"authors\":[{\"authorId\":\"3764313\",\"name\":\"Jingwen Ye\"},{\"authorId\":\"2714904\",\"name\":\"X. Wang\"},{\"authorId\":\"115560297\",\"name\":\"Yixin Ji\"},{\"authorId\":\"2794841\",\"name\":\"Kairi Ou\"},{\"authorId\":\"144646841\",\"name\":\"M. Song\"}],\"doi\":\"10.24963/IJCAI.2019/573\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"92bd0775aa187a4cb71b71fbe2828ce1cdfd34ef\",\"title\":\"Amalgamating Filtered Knowledge: Learning Task-customized Student from Multi-task Teachers\",\"url\":\"https://www.semanticscholar.org/paper/92bd0775aa187a4cb71b71fbe2828ce1cdfd34ef\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"1907.07804\",\"authors\":[{\"authorId\":\"51011359\",\"name\":\"S. Pramanik\"},{\"authorId\":\"7421228\",\"name\":\"Priyanka Agrawal\"},{\"authorId\":\"145374365\",\"name\":\"Aman Hussain\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3fc815cebbd8948dfed0592a254d5d4bf82d3fcf\",\"title\":\"OmniNet: A unified architecture for multi-modal multi-task learning\",\"url\":\"https://www.semanticscholar.org/paper/3fc815cebbd8948dfed0592a254d5d4bf82d3fcf\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s42979-020-00238-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3f732495721356944027051bb14100436a5dbdf5\",\"title\":\"AACR: Feature Fusion Effects of Algebraic Amalgamation Composed Representation on (De)Compositional Network for Caption Generation for Images\",\"url\":\"https://www.semanticscholar.org/paper/3f732495721356944027051bb14100436a5dbdf5\",\"venue\":\"SN Comput. Sci.\",\"year\":2020},{\"arxivId\":\"2003.09971\",\"authors\":[{\"authorId\":\"3212867\",\"name\":\"R. Luo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b57c9a293934b7434b99807c82d6146634cafa61\",\"title\":\"A Better Variant of Self-Critical Sequence Training\",\"url\":\"https://www.semanticscholar.org/paper/b57c9a293934b7434b99807c82d6146634cafa61\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39710806\",\"name\":\"Nhu-Van Nguyen\"},{\"authorId\":\"153476282\",\"name\":\"Christophe Rigaud\"},{\"authorId\":\"1690398\",\"name\":\"J. Burie\"}],\"doi\":\"10.1007/s10032-019-00330-3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"684726bf4cd22b09110ae62faa899617b8b00e2f\",\"title\":\"Comic MTL: optimized multi-task learning for comic book image analysis\",\"url\":\"https://www.semanticscholar.org/paper/684726bf4cd22b09110ae62faa899617b8b00e2f\",\"venue\":\"International Journal on Document Analysis and Recognition (IJDAR)\",\"year\":2019},{\"arxivId\":\"2002.06436\",\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4ad005019f7069a3aaff959fbaa657f2ef2143fc\",\"title\":\"MRRC: Multiple Role Representation Crossover Interpretation for Image Captioning With R-CNN Feature Distribution Composition (FDC)\",\"url\":\"https://www.semanticscholar.org/paper/4ad005019f7069a3aaff959fbaa657f2ef2143fc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.10132\",\"authors\":[{\"authorId\":\"151430668\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s11042-020-09865-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c8f8ea39c64cf08792cd49c6ad04e85e3b90c88f\",\"title\":\"CRUR: Coupled-Recurrent Unit for Unification, Conceptualization and Context Capture for Language Representation - A Generalization of Bi Directional LSTM\",\"url\":\"https://www.semanticscholar.org/paper/c8f8ea39c64cf08792cd49c6ad04e85e3b90c88f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2001.09545\",\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"66a2eb540af6f47db177599bc793ab0c6a6aa47e\",\"title\":\"aiTPR: Attribute Interaction-Tensor Product Representation for Image Caption\",\"url\":\"https://www.semanticscholar.org/paper/66a2eb540af6f47db177599bc793ab0c6a6aa47e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2894465\",\"name\":\"Benyou Wang\"}],\"doi\":\"10.1145/3331184.3331412\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c42bcc036801731ed5db2edf55480b8750d512b3\",\"title\":\"Dynamic Content Monitoring and Exploration using Vector Spaces\",\"url\":\"https://www.semanticscholar.org/paper/c42bcc036801731ed5db2edf55480b8750d512b3\",\"venue\":\"SIGIR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47860328\",\"name\":\"Shagun Uppal\"},{\"authorId\":\"73368394\",\"name\":\"Sarthak Bhagat\"},{\"authorId\":\"8223433\",\"name\":\"Devamanyu Hazarika\"},{\"authorId\":\"1999177921\",\"name\":\"Navonil Majumdar\"},{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"153015119\",\"name\":\"R. Zimmermann\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0f23b548ff7b3517f028164a30c8bf186f11a1a6\",\"title\":\"Emerging Trends of Multimodal Research in Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/0f23b548ff7b3517f028164a30c8bf186f11a1a6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.09088\",\"authors\":[{\"authorId\":\"3764313\",\"name\":\"Jingwen Ye\"},{\"authorId\":\"115560297\",\"name\":\"Yixin Ji\"},{\"authorId\":\"2714904\",\"name\":\"X. Wang\"},{\"authorId\":\"1470731190\",\"name\":\"Xin Gao\"},{\"authorId\":\"1727111\",\"name\":\"Mingli Song\"}],\"doi\":\"10.1109/cvpr42600.2020.01253\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ae5405fd06e96de5a0a9e8cffde76d9064c249d9\",\"title\":\"Data-Free Knowledge Amalgamation via Group-Stack Dual-GAN\",\"url\":\"https://www.semanticscholar.org/paper/ae5405fd06e96de5a0a9e8cffde76d9064c249d9\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020}],\"corpusId\":51609416,\"doi\":\"10.24963/ijcai.2018/168\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":false,\"paperId\":\"cbe4eac494fa7bc0bcd958d67393f097e0cb17db\",\"references\":[{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145040726\",\"name\":\"R. Bernardi\"},{\"authorId\":\"2588033\",\"name\":\"Ruken Cakici\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"},{\"authorId\":\"1398643531\",\"name\":\"N. Ikizler-Cinbis\"},{\"authorId\":\"1393020635\",\"name\":\"F. Keller\"},{\"authorId\":\"35347012\",\"name\":\"A. Muscat\"},{\"authorId\":\"2022124\",\"name\":\"Barbara Plank\"}],\"doi\":\"10.1613/jair.4900\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c162d791b63682d928c09578bd38c3dd61f78c8c\",\"title\":\"Automatic Description Generation from Images: A Survey of Models, Datasets, and Evaluation Measures\",\"url\":\"https://www.semanticscholar.org/paper/c162d791b63682d928c09578bd38c3dd61f78c8c\",\"venue\":\"J. Artif. Intell. Res.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40410858\",\"name\":\"R. J. Williams\"}],\"doi\":\"10.1007/BF00992696\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4c915c1eecb217c123a36dc6d3ce52d12c742614\",\"title\":\"Simple statistical gradient-following algorithms for connectionist reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/4c915c1eecb217c123a36dc6d3ce52d12c742614\",\"venue\":\"Machine Learning\",\"year\":2004},{\"arxivId\":\"1612.07086\",\"authors\":[{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"40894914\",\"name\":\"T. Chen\"}],\"doi\":\"10.1109/ICCV.2017.138\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d85704f4814e9fa5ff0b68b1e5cad9e6527d0bbf\",\"title\":\"An Empirical Study of Language CNN for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/d85704f4814e9fa5ff0b68b1e5cad9e6527d0bbf\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1704.07489\",\"authors\":[{\"authorId\":\"10721120\",\"name\":\"Ramakanth Pasunuru\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/P17-1117\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9b08d3201af644a638e291755a5e51f6b17a51f3\",\"title\":\"Multi-Task Video Captioning with Video and Entailment Generation\",\"url\":\"https://www.semanticscholar.org/paper/9b08d3201af644a638e291755a5e51f6b17a51f3\",\"venue\":\"ACL\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Kaiming He\"},{\"authorId\":null,\"name\":\"Xiangyu Zhang\"},{\"authorId\":null,\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun. Deep residual learning for image recognition\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In CVPR\",\"url\":\"\",\"venue\":\"pages 770\\u2013778,\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Wei Zhao\"},{\"authorId\":null,\"name\":\"Wei Xu\"},{\"authorId\":null,\"name\":\"Min Yang\"},{\"authorId\":null,\"name\":\"Jianbo Ye\"},{\"authorId\":null,\"name\":\"Zhou Zhao\"},{\"authorId\":null,\"name\":\"Yabing Feng\"},{\"authorId\":null,\"name\":\"Yu Qiao. Dual learning for cross-domain image captioning\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In CIKM\",\"url\":\"\",\"venue\":\"pages 29\\u201338,\",\"year\":2017},{\"arxivId\":\"1604.01729\",\"authors\":[{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.18653/v1/D16-1204\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d1ffd519ff274517ec6fd014ae67af0d0c68a969\",\"title\":\"Improving LSTM-based Video Description with Linguistic Knowledge Mined from Text\",\"url\":\"https://www.semanticscholar.org/paper/d1ffd519ff274517ec6fd014ae67af0d0c68a969\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12094097\",\"name\":\"Pratik P. Rane\"},{\"authorId\":\"118145941\",\"name\":\"A. Sargar\"},{\"authorId\":\"47039181\",\"name\":\"Faiza Shaikh\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f77a604410d88307ec5c6331c8b6133272fbaa10\",\"title\":\"Self-Critical Sequence Training for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/f77a604410d88307ec5c6331c8b6133272fbaa10\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1612.00370\",\"authors\":[{\"authorId\":\"47130333\",\"name\":\"Siqi Liu\"},{\"authorId\":\"39815369\",\"name\":\"Z. Zhu\"},{\"authorId\":\"145361612\",\"name\":\"N. Ye\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":\"10.1109/ICCV.2017.100\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"665a311c538fc021c27acd3953f171924cc5905c\",\"title\":\"Optimization of image description metrics using policy gradient methods\",\"url\":\"https://www.semanticscholar.org/paper/665a311c538fc021c27acd3953f171924cc5905c\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2015.7298932\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"title\":\"Deep visual-semantic alignments for generating image descriptions\",\"url\":\"https://www.semanticscholar.org/paper/ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"venue\":\"CVPR\",\"year\":2015},{\"arxivId\":\"1601.03896\",\"authors\":[{\"authorId\":\"145040726\",\"name\":\"R. Bernardi\"},{\"authorId\":\"2588033\",\"name\":\"Ruken Cakici\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"},{\"authorId\":\"1398643531\",\"name\":\"N. Ikizler-Cinbis\"},{\"authorId\":\"1393020635\",\"name\":\"F. Keller\"},{\"authorId\":\"35347012\",\"name\":\"A. Muscat\"},{\"authorId\":\"2022124\",\"name\":\"Barbara Plank\"}],\"doi\":\"10.24963/ijcai.2017/704\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6e9aebe54f76d85c6df7e80faa761ef0aec3d54c\",\"title\":\"Automatic Description Generation from Images: A Survey of Models, Datasets, and Evaluation Measures (Extended Abstract)\",\"url\":\"https://www.semanticscholar.org/paper/6e9aebe54f76d85c6df7e80faa761ef0aec3d54c\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"},{\"authorId\":\"31790073\",\"name\":\"C. Buehler\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"46878216\",\"name\":\"M. Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a79b694bd4ef51207787da1948ed473903b751ef\",\"title\":\"Bottom-Up and Top-Down Attention for Image Captioning and VQA\",\"url\":\"https://www.semanticscholar.org/paper/a79b694bd4ef51207787da1948ed473903b751ef\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1612.01887\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":\"10.1109/CVPR.2017.345\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9f4d7d622d1f7319cc511bfef661cd973e881a4c\",\"title\":\"Knowing When to Look: Adaptive Attention via a Visual Sentinel for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9f4d7d622d1f7319cc511bfef661cd973e881a4c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1411.5726\",\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2015.7299087\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"258986132bf17755fe8263e42429fe73218c1534\",\"title\":\"CIDEr: Consensus-based image description evaluation\",\"url\":\"https://www.semanticscholar.org/paper/258986132bf17755fe8263e42429fe73218c1534\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5886094\",\"name\":\"P. Cochat\"},{\"authorId\":\"13267685\",\"name\":\"L. Vaucoret\"},{\"authorId\":\"31455512\",\"name\":\"J. Sarles\"}],\"doi\":\"10.1016/j.arcped.2012.01.013\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"10d85561e4aafc516d10064f30dff05b41f70afe\",\"title\":\"[Et al].\",\"url\":\"https://www.semanticscholar.org/paper/10d85561e4aafc516d10064f30dff05b41f70afe\",\"venue\":\"Archives de pediatrie : organe officiel de la Societe francaise de pediatrie\",\"year\":2012},{\"arxivId\":\"1609.08976\",\"authors\":[{\"authorId\":\"2750075\",\"name\":\"Y. Pu\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"145153424\",\"name\":\"Ricardo Henao\"},{\"authorId\":\"50242822\",\"name\":\"X. Yuan\"},{\"authorId\":\"1978606\",\"name\":\"C. Li\"},{\"authorId\":\"9074631\",\"name\":\"A. Stevens\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f4c5d13a8e9e80edcd4f69f0eab0b4434364c6dd\",\"title\":\"Variational Autoencoder for Deep Learning of Images, Labels and Captions\",\"url\":\"https://www.semanticscholar.org/paper/f4c5d13a8e9e80edcd4f69f0eab0b4434364c6dd\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1709.03376\",\"authors\":[{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"},{\"authorId\":\"40894914\",\"name\":\"T. Chen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7f14e73dade94b8b1f276dcd91257aa7de5f19d7\",\"title\":\"Stack-Captioning: Coarse-to-Fine Learning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7f14e73dade94b8b1f276dcd91257aa7de5f19d7\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1704.03135\",\"authors\":[{\"authorId\":\"3092578\",\"name\":\"Y. Li\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2017.199\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9f545b9006970f7626b7b121c5c3c66204f1ba40\",\"title\":\"Improving Pairwise Ranking for Multi-label Image Classification\",\"url\":\"https://www.semanticscholar.org/paper/9f545b9006970f7626b7b121c5c3c66204f1ba40\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1609.06647\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"48818137\",\"name\":\"Samy Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/TPAMI.2016.2587640\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"62f74d3aaf9e86633e4d88b04a6d04ca93e8b81e\",\"title\":\"Show and Tell: Lessons Learned from the 2015 MSCOCO Image Captioning Challenge\",\"url\":\"https://www.semanticscholar.org/paper/62f74d3aaf9e86633e4d88b04a6d04ca93e8b81e\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Andrej Karpathy\"},{\"authorId\":null,\"name\":\"Li FeiFei. Deep visual-semantic alignments for genera descriptions\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In CVPR\",\"url\":\"\",\"venue\":\"pages 3128\\u20133137,\",\"year\":2015},{\"arxivId\":\"1506.01144\",\"authors\":[{\"authorId\":\"34902783\",\"name\":\"Qi Wu\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2016.29\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"00fe3d95d0fd5f1433d81405bee772c4fe9af9c6\",\"title\":\"What Value Do Explicit High Level Concepts Have in Vision to Language Problems?\",\"url\":\"https://www.semanticscholar.org/paper/00fe3d95d0fd5f1433d81405bee772c4fe9af9c6\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1702.01147\",\"authors\":[{\"authorId\":\"3456844\",\"name\":\"Maria Nadejde\"},{\"authorId\":\"145732771\",\"name\":\"Siva Reddy\"},{\"authorId\":\"2082372\",\"name\":\"Rico Sennrich\"},{\"authorId\":\"3407177\",\"name\":\"Tomasz Dwojak\"},{\"authorId\":\"1733933\",\"name\":\"Marcin Junczys-Dowmunt\"},{\"authorId\":\"49604675\",\"name\":\"P. Koehn\"},{\"authorId\":\"2539211\",\"name\":\"Alexandra Birch\"}],\"doi\":\"10.18653/v1/W17-4707\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cf54b66a05bb6eb0ebe93d9ef48da956cb0beea6\",\"title\":\"Predicting Target Language CCG Supertags Improves Neural Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/cf54b66a05bb6eb0ebe93d9ef48da956cb0beea6\",\"venue\":\"WMT\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yunchen Pu\"},{\"authorId\":null,\"name\":\"Zhe Gan\"},{\"authorId\":null,\"name\":\"Ricardo Henao\"},{\"authorId\":null,\"name\":\"Xin Yuan\"},{\"authorId\":null,\"name\":\"Chunyuan Li\"},{\"authorId\":null,\"name\":\"Andrew Stevens\"},{\"authorId\":null,\"name\":\"Lawrence Carin. Variational autoencoder for deep learning o images\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"labels and captions\",\"url\":\"\",\"venue\":\"NIPS, pages 2352\\u20132360,\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Rich Caruana. Multitask learning. In Learning to learn\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"pages 95\\u2013133\",\"url\":\"\",\"venue\":\"Springer,\",\"year\":1998},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144299726\",\"name\":\"Thomas G. Dietterich\"}],\"doi\":\"10.1145/242224.242229\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aab43c9c33af00b718cf2ae374b861d49862a563\",\"title\":\"Machine learning\",\"url\":\"https://www.semanticscholar.org/paper/aab43c9c33af00b718cf2ae374b861d49862a563\",\"venue\":\"CSUR\",\"year\":1996},{\"arxivId\":\"1611.05594\",\"authors\":[{\"authorId\":\"143891667\",\"name\":\"Long Chen\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1406012647\",\"name\":\"Jun Xiao\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":\"104757141\",\"name\":\"Jian Shao\"},{\"authorId\":\"40366581\",\"name\":\"Wei Liu\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1109/CVPR.2017.667\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"88513e738a95840de05a62f0e43d30a67b3c542e\",\"title\":\"SCA-CNN: Spatial and Channel-Wise Attention in Convolutional Networks for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/88513e738a95840de05a62f0e43d30a67b3c542e\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017}],\"title\":\"A Multi-task Learning Approach for Image Captioning\",\"topics\":[{\"topic\":\"Multi-task learning\",\"topicId\":\"76682\",\"url\":\"https://www.semanticscholar.org/topic/76682\"},{\"topic\":\"Long short-term memory\",\"topicId\":\"117199\",\"url\":\"https://www.semanticscholar.org/topic/117199\"},{\"topic\":\"Encoder\",\"topicId\":\"16744\",\"url\":\"https://www.semanticscholar.org/topic/16744\"},{\"topic\":\"Categorization\",\"topicId\":\"8505\",\"url\":\"https://www.semanticscholar.org/topic/8505\"},{\"topic\":\"Computer multitasking\",\"topicId\":\"6968\",\"url\":\"https://www.semanticscholar.org/topic/6968\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"}],\"url\":\"https://www.semanticscholar.org/paper/cbe4eac494fa7bc0bcd958d67393f097e0cb17db\",\"venue\":\"IJCAI\",\"year\":2018}\n"