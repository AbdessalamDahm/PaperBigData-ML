"{\"abstract\":\"Autonomous agents are increasingly required to solve complex tasks; hard-coding behaviors has become infeasible. Hence, agents must learn how to solve tasks via interactions with the environment. In many cases, knowledge reuse will be a core technology to keep training times reasonable, and for that, agents must be able to autonomously and consistently reuse knowledge from multiple sources, including both their own previous internal knowledge and from other agents. In this paper, we provide a literature review of methods for knowledge reuse in Multiagent Reinforcement Learning. We define an important challenge problem for the AI community, survey the existent methods, and discuss how they can all contribute to this challenging problem. Moreover, we highlight gaps in the current literature, motivating \\u201clow-hanging fruit\\u201d for those interested in the area. Our ambition is that this paper will encourage the community to work on this difficult and relevant research challenge.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"145050960\",\"name\":\"F. Silva\",\"url\":\"https://www.semanticscholar.org/author/145050960\"},{\"authorId\":\"39286677\",\"name\":\"Matthew E. Taylor\",\"url\":\"https://www.semanticscholar.org/author/39286677\"},{\"authorId\":\"2209202\",\"name\":\"A. Costa\",\"url\":\"https://www.semanticscholar.org/author/2209202\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"3390081\",\"name\":\"Felipe Leno Da Silva\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"191bc1805d0e290fec9fa6fc1f21cd6b16b087a5\",\"title\":\"Integrating Agent Advice and Previous Task Solutions in Multiagent Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/191bc1805d0e290fec9fa6fc1f21cd6b16b087a5\",\"venue\":\"AAMAS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145050960\",\"name\":\"F. Silva\"},{\"authorId\":\"2209202\",\"name\":\"A. Costa\"},{\"authorId\":\"144848112\",\"name\":\"P. Stone\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"23f53d76d11f83d3a7030540b1089d27ffda08d1\",\"title\":\"Distributional Reinforcement Learning Applied to Robot Soccer Simulation WorkIn-Progress Paper-ALA Workshop at AAMAS-19\",\"url\":\"https://www.semanticscholar.org/paper/23f53d76d11f83d3a7030540b1089d27ffda08d1\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2008.01916\",\"authors\":[{\"authorId\":\"32620196\",\"name\":\"Tianqing Zhu\"},{\"authorId\":\"48214388\",\"name\":\"Dayong Ye\"},{\"authorId\":\"47824688\",\"name\":\"Wei Wang\"},{\"authorId\":\"119796948\",\"name\":\"Wanlei Zhou\"},{\"authorId\":\"144019071\",\"name\":\"Philip S. Yu\"}],\"doi\":\"10.1109/TKDE.2020.3014246\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7d5b94f9d2cee5823757352155d0234454f09a0e\",\"title\":\"More Than Privacy: Applying Differential Privacy in Key Areas of Artificial Intelligence\",\"url\":\"https://www.semanticscholar.org/paper/7d5b94f9d2cee5823757352155d0234454f09a0e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2617208\",\"name\":\"Dayong Ye\"},{\"authorId\":\"32620196\",\"name\":\"Tianqing Zhu\"},{\"authorId\":\"1745566\",\"name\":\"W. Zhou\"},{\"authorId\":\"144019071\",\"name\":\"Philip S. Yu\"}],\"doi\":\"10.1109/TCYB.2019.2906574\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e51167f3f11b015b6b179893b6d03f117be001bb\",\"title\":\"Differentially Private Malicious Agent Avoidance in Multiagent Advising Learning\",\"url\":\"https://www.semanticscholar.org/paper/e51167f3f11b015b6b179893b6d03f117be001bb\",\"venue\":\"IEEE Transactions on Cybernetics\",\"year\":2020},{\"arxivId\":\"2011.03640\",\"authors\":[{\"authorId\":\"2617208\",\"name\":\"Dayong Ye\"},{\"authorId\":\"32620196\",\"name\":\"Tianqing Zhu\"},{\"authorId\":\"48014279\",\"name\":\"Z. Cheng\"},{\"authorId\":\"119796948\",\"name\":\"Wanlei Zhou\"},{\"authorId\":\"144019071\",\"name\":\"Philip S. Yu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f45dd13bfd72b6b15f6d026c5ed715255880d861\",\"title\":\"Differential Advising in Multi-Agent Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/f45dd13bfd72b6b15f6d026c5ed715255880d861\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3390081\",\"name\":\"Felipe Leno Da Silva\"},{\"authorId\":\"1729426820\",\"name\":\"F. C. D. Silva\"},{\"authorId\":\"1938253\",\"name\":\"Garrett Warnell\"},{\"authorId\":\"2209202\",\"name\":\"A. Costa\"},{\"authorId\":\"144848112\",\"name\":\"P. Stone\"}],\"doi\":\"10.26153/TSW/8400\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bc4f6d0a27a60aa7c2c8db2dd3f814b3a5d2f907\",\"title\":\"Agents teaching agents: a survey on inter-agent transfer learning\",\"url\":\"https://www.semanticscholar.org/paper/bc4f6d0a27a60aa7c2c8db2dd3f814b3a5d2f907\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1902.06897\",\"authors\":[{\"authorId\":\"145733816\",\"name\":\"S. Gupta\"},{\"authorId\":\"2440174\",\"name\":\"A. Dukkipati\"}],\"doi\":\"10.5555/3398761.3399007\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8dd7184e2d9c46579ad82fca97e3d74e86c7e24b\",\"title\":\"Winning an Election: On Emergent Strategic Communication in Multi-Agent Networks\",\"url\":\"https://www.semanticscholar.org/paper/8dd7184e2d9c46579ad82fca97e3d74e86c7e24b\",\"venue\":\"AAMAS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9585174\",\"name\":\"Rodrigo Cesar Bonini\"},{\"authorId\":\"145050960\",\"name\":\"F. Silva\"},{\"authorId\":\"8848899\",\"name\":\"R. Glatt\"},{\"authorId\":\"3003299\",\"name\":\"Edison Spina\"},{\"authorId\":\"2209202\",\"name\":\"A. Costa\"}],\"doi\":\"10.1109/BRACIS.2018.00027\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"82c0c95d58ad9c68ff53a8fab3bf71f499772ca4\",\"title\":\"A Framework to Discover and Reuse Object-Oriented Options in Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/82c0c95d58ad9c68ff53a8fab3bf71f499772ca4\",\"venue\":\"2018 7th Brazilian Conference on Intelligent Systems (BRACIS)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145733816\",\"name\":\"S. Gupta\"},{\"authorId\":\"2440174\",\"name\":\"A. Dukkipati\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4cf3992edf80482e14d88b1824354fbc38cae843\",\"title\":\"On Voting Strategies and Emergent Communication\",\"url\":\"https://www.semanticscholar.org/paper/4cf3992edf80482e14d88b1824354fbc38cae843\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2008.04452\",\"authors\":[{\"authorId\":\"26367618\",\"name\":\"Zheqing Zhu\"},{\"authorId\":\"8307674\",\"name\":\"Erdem Biyik\"},{\"authorId\":\"1779671\",\"name\":\"D. Sadigh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cfa4cd6c44dabdd416f2e6eb60689ac45bf1009e\",\"title\":\"Multi-Agent Safe Planning with Gaussian Processes\",\"url\":\"https://www.semanticscholar.org/paper/cfa4cd6c44dabdd416f2e6eb60689ac45bf1009e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1812.11794\",\"authors\":[{\"authorId\":\"153387571\",\"name\":\"T. Nguyen\"},{\"authorId\":\"49694023\",\"name\":\"Ngoc Duy Nguyen\"},{\"authorId\":\"1743136\",\"name\":\"S. Nahavandi\"}],\"doi\":\"10.1109/TCYB.2020.2977374\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"28e66d188efbd0bbb64242b611d96769be910c15\",\"title\":\"Deep Reinforcement Learning for Multiagent Systems: A Review of Challenges, Solutions, and Applications\",\"url\":\"https://www.semanticscholar.org/paper/28e66d188efbd0bbb64242b611d96769be910c15\",\"venue\":\"IEEE Transactions on Cybernetics\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32620196\",\"name\":\"Tianqing Zhu\"},{\"authorId\":\"144019071\",\"name\":\"Philip S. Yu\"}],\"doi\":\"10.1109/ICDCS.2019.00159\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e684a7f8286f4bd9b998c3b8b95cd17e52202133\",\"title\":\"Applying Differential Privacy Mechanism in Artificial Intelligence\",\"url\":\"https://www.semanticscholar.org/paper/e684a7f8286f4bd9b998c3b8b95cd17e52202133\",\"venue\":\"2019 IEEE 39th International Conference on Distributed Computing Systems (ICDCS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145050960\",\"name\":\"F. Silva\"},{\"authorId\":\"2209202\",\"name\":\"A. Costa\"}],\"doi\":\"10.1613/jair.1.11396\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3660f76126fe1343c91f065f452845981041206c\",\"title\":\"A Survey on Transfer Learning for Multiagent Reinforcement Learning Systems\",\"url\":\"https://www.semanticscholar.org/paper/3660f76126fe1343c91f065f452845981041206c\",\"venue\":\"J. Artif. Intell. Res.\",\"year\":2019},{\"arxivId\":\"2006.07169\",\"authors\":[{\"authorId\":\"3448899\",\"name\":\"Filippos Christianos\"},{\"authorId\":\"144824410\",\"name\":\"Lukas Sch\\u00e4fer\"},{\"authorId\":\"1961238\",\"name\":\"Stefano V. Albrecht\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4ae72ead4ac780327217221a632b3f8383542b29\",\"title\":\"Shared Experience Actor-Critic for Multi-Agent Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/4ae72ead4ac780327217221a632b3f8383542b29\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35255277\",\"name\":\"F. Saitoh\"}],\"doi\":\"10.1007/978-3-030-36808-1_40\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"46a408eab7285089c5aee407e3e02372ffbb7523\",\"title\":\"Knowledge Reuse of Learning Agent Based on Factor Information of Behavioral Rules\",\"url\":\"https://www.semanticscholar.org/paper/46a408eab7285089c5aee407e3e02372ffbb7523\",\"venue\":\"ICONIP\",\"year\":2019},{\"arxivId\":\"1902.02311\",\"authors\":[{\"authorId\":\"47771847\",\"name\":\"A. Lin\"},{\"authorId\":\"4749216\",\"name\":\"Mark J. Debord\"},{\"authorId\":\"2976542\",\"name\":\"K. Estabridis\"},{\"authorId\":\"2406695\",\"name\":\"G. Hewer\"},{\"authorId\":\"1782265\",\"name\":\"S. Osher\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f3b4c65f59e212c3d502ef0509cfeb5b862833c6\",\"title\":\"CESMA: Centralized Expert Supervises Multi-Agents\",\"url\":\"https://www.semanticscholar.org/paper/f3b4c65f59e212c3d502ef0509cfeb5b862833c6\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"114603956\",\"name\":\"Felipe Leno Da Silva\"},{\"authorId\":\"1938253\",\"name\":\"Garrett Warnell\"},{\"authorId\":\"2209202\",\"name\":\"A. Costa\"},{\"authorId\":\"144848112\",\"name\":\"P. Stone\"}],\"doi\":\"10.1007/s10458-019-09430-0\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f3a5d43feed53f5e0c92d50be4bb2d5008254d88\",\"title\":\"Agents teaching agents: a survey on inter-agent transfer learning\",\"url\":\"https://www.semanticscholar.org/paper/f3a5d43feed53f5e0c92d50be4bb2d5008254d88\",\"venue\":\"Autonomous Agents and Multi-Agent Systems\",\"year\":2019}],\"corpusId\":51604728,\"doi\":\"10.24963/ijcai.2018/774\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":false,\"paperId\":\"827ce92aa1ed258bca2133443982793d1fda7be5\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Matthew E. Taylor\"},{\"authorId\":null,\"name\":\"Nicholas K. Jong\"},{\"authorId\":null,\"name\":\"Peter Stone. Transferring Instances for ModelBased Reinf Learning\"},{\"authorId\":null,\"name\":\"Knowledge Discovery in Databases\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"volume 5212 of Lecture Notes in Artificial Intelligence\",\"url\":\"\",\"venue\":\"pages 488\\u2013505,\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32999467\",\"name\":\"Reinaldo A. C. Bianchi\"},{\"authorId\":\"2799735\",\"name\":\"Luiz A. Celiberto\"},{\"authorId\":\"145275454\",\"name\":\"Paulo E. Santos\"},{\"authorId\":\"3199458\",\"name\":\"J. P. Matsuura\"},{\"authorId\":\"41070350\",\"name\":\"R. L. D. M\\u00e1ntaras\"}],\"doi\":\"10.1016/j.artint.2015.05.008\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cefc87277665881b0e8de3d4fb172a3f1d44e5f9\",\"title\":\"Transferring knowledge as heuristics in reinforcement learning: A case-based approach\",\"url\":\"https://www.semanticscholar.org/paper/cefc87277665881b0e8de3d4fb172a3f1d44e5f9\",\"venue\":\"Artif. Intell.\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ming Tan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Multi - agent Reinforcement Learning : Independent vs . Cooperative Agents\",\"url\":\"\",\"venue\":\"10 th International Conference on Machine Learning ( ICML )\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3254390\",\"name\":\"A. Lazaric\"}],\"doi\":\"10.1007/978-3-642-27645-3_5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"16c97a8a29b0d63fdb119daefabc47df92ff6c24\",\"title\":\"Transfer in Reinforcement Learning: A Framework and a Survey\",\"url\":\"https://www.semanticscholar.org/paper/16c97a8a29b0d63fdb119daefabc47df92ff6c24\",\"venue\":\"Reinforcement Learning\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699645\",\"name\":\"R. Sutton\"},{\"authorId\":\"1730590\",\"name\":\"A. Barto\"}],\"doi\":\"10.1109/TNN.1998.712192\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"97efafdb4a3942ab3efba53ded7413199f79c054\",\"title\":\"Reinforcement Learning: An Introduction\",\"url\":\"https://www.semanticscholar.org/paper/97efafdb4a3942ab3efba53ded7413199f79c054\",\"venue\":\"IEEE Transactions on Neural Networks\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145050960\",\"name\":\"F. Silva\"},{\"authorId\":\"2209202\",\"name\":\"A. Costa\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e105d71d384fdfbed12b8eee93c38db4269d01a4\",\"title\":\"Object-Oriented Curriculum Generation for Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/e105d71d384fdfbed12b8eee93c38db4269d01a4\",\"venue\":\"AAMAS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39286677\",\"name\":\"Matthew E. Taylor\"},{\"authorId\":\"144848112\",\"name\":\"P. Stone\"}],\"doi\":\"10.1145/1577069.1755839\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"467568f1777bc51a15a5100516cd4fe8de62b9ab\",\"title\":\"Transfer Learning for Reinforcement Learning Domains: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/467568f1777bc51a15a5100516cd4fe8de62b9ab\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1742807\",\"name\":\"H. Kitano\"},{\"authorId\":\"144657032\",\"name\":\"M. Asada\"},{\"authorId\":\"1744602\",\"name\":\"Y. Kuniyoshi\"},{\"authorId\":\"35193947\",\"name\":\"I. Noda\"},{\"authorId\":\"35170332\",\"name\":\"Eiichi Osawa\"},{\"authorId\":\"48084745\",\"name\":\"Hitoshi Matsubara\"}],\"doi\":\"10.1609/aimag.v18i1.1276\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d7853249d888f3e7c4eaebe549db9fe526d02134\",\"title\":\"RoboCup: A Challenge Problem for AI\",\"url\":\"https://www.semanticscholar.org/paper/d7853249d888f3e7c4eaebe549db9fe526d02134\",\"venue\":\"AI Mag.\",\"year\":1997},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Lucian Busoniu\"},{\"authorId\":null,\"name\":\"Robert Babuska\"},{\"authorId\":null,\"name\":\"Bart De Schutter. A Comprehensive Survey of Multiagent Systems\"},{\"authorId\":null,\"name\":\"Man\"},{\"authorId\":null,\"name\":\"Cybernetics\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Part C: Applications and Reviews\",\"url\":\"\",\"venue\":\"38(2):156\\u2013172,\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1400326437\",\"name\":\"Pablo Hernandez-Leal\"},{\"authorId\":\"1689073\",\"name\":\"M. Kaisers\"}],\"doi\":\"10.1007/978-3-319-71682-4_15\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"2ad5aaf0dbb2f4f101ac679b78278be0289f8c95\",\"title\":\"Towards a Fast Detection of Opponents in Repeated Stochastic Games\",\"url\":\"https://www.semanticscholar.org/paper/2ad5aaf0dbb2f4f101ac679b78278be0289f8c95\",\"venue\":\"AAMAS Workshops\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1776850\",\"name\":\"Yujing Hu\"},{\"authorId\":\"145644823\",\"name\":\"Y. Gao\"},{\"authorId\":\"143706345\",\"name\":\"Bo An\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"09f1e3ea9fd7ec33a5d3b9b4f52f44b08a6980f6\",\"title\":\"Learning in Multi-agent Systems with Sparse Interactions by Knowledge Transfer and Game Abstraction\",\"url\":\"https://www.semanticscholar.org/paper/09f1e3ea9fd7ec33a5d3b9b4f52f44b08a6980f6\",\"venue\":\"AAMAS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1956361\",\"name\":\"M. Veloso\"},{\"authorId\":\"1732268\",\"name\":\"A. Aamodt\"}],\"doi\":\"10.1007/3-540-60598-3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"faf0c5b2504de1c5975c7ae261ed85819724f0f7\",\"title\":\"Case-Based Reasoning Research and Development\",\"url\":\"https://www.semanticscholar.org/paper/faf0c5b2504de1c5975c7ae261ed85819724f0f7\",\"venue\":\"Lecture Notes in Computer Science\",\"year\":1995},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34887814\",\"name\":\"Nicholay Topin\"},{\"authorId\":\"2547396\",\"name\":\"Nicholas Haltmeyer\"},{\"authorId\":\"50460087\",\"name\":\"S. Squire\"},{\"authorId\":\"144214684\",\"name\":\"J. Winder\"},{\"authorId\":\"144980202\",\"name\":\"M. desJardins\"},{\"authorId\":\"2700008\",\"name\":\"J. MacGlashan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b8a3c1c0ebe113ffb61b0066aa91ef03701e5550\",\"title\":\"Portable Option Discovery for Automated Learning Transfer in Object-Oriented Markov Decision Processes\",\"url\":\"https://www.semanticscholar.org/paper/b8a3c1c0ebe113ffb61b0066aa91ef03701e5550\",\"venue\":\"IJCAI\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ming Tan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Multi-agent Reinforcement Learning: Independent vs\",\"url\":\"\",\"venue\":\"Cooperative Agents. In 10th International Conference on Machine Learning (ICML), pages 330\\u2013337,\",\"year\":1993},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Matthew E. Taylor\"},{\"authorId\":null,\"name\":\"Nicholas Carboni\"},{\"authorId\":null,\"name\":\"Anestis Fachantidis\"},{\"authorId\":null,\"name\":\"Ioannis P. Vlahavas\"},{\"authorId\":null,\"name\":\"Lisa Torrey. Reinforcement Learning Agents Providing Ad Games\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Connection Science\",\"url\":\"\",\"venue\":\"26(1):45\\u201363,\",\"year\":2014},{\"arxivId\":\"1604.03986\",\"authors\":[{\"authorId\":\"2360436\",\"name\":\"Yusen Zhan\"},{\"authorId\":\"1398842047\",\"name\":\"Haitham Bou-Ammar\"},{\"authorId\":\"39286677\",\"name\":\"Matthew E. Taylor\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"341cd6c1a52dbdd789407f28b31ad387abeaa60f\",\"title\":\"Theoretically-Grounded Policy Advice from Multiple Teachers in Reinforcement Learning Settings with Applications to Negative Transfer\",\"url\":\"https://www.semanticscholar.org/paper/341cd6c1a52dbdd789407f28b31ad387abeaa60f\",\"venue\":\"IJCAI\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2717082\",\"name\":\"G. Boutsioukis\"},{\"authorId\":\"3071383\",\"name\":\"Ioannis Partalas\"},{\"authorId\":\"1697941\",\"name\":\"I. Vlahavas\"}],\"doi\":\"10.1007/978-3-642-29946-9_25\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a0fefc14c3dd10a031c9567fa136a64146eda925\",\"title\":\"Transfer Learning in Multi-Agent Reinforcement Learning Domains\",\"url\":\"https://www.semanticscholar.org/paper/a0fefc14c3dd10a031c9567fa136a64146eda925\",\"venue\":\"EWRL\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2700008\",\"name\":\"J. MacGlashan\"},{\"authorId\":\"144885169\",\"name\":\"M. Littman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d69be75b44153086b51a7ca53b863f151e3e89a1\",\"title\":\"An Empirical Study of Non-Expert Curriculum Design for Machine Learners\",\"url\":\"https://www.semanticscholar.org/paper/d69be75b44153086b51a7ca53b863f151e3e89a1\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"113887627\",\"name\":\"M. Stone\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c260a51d57c4adff52838a39ee474864696d0e40\",\"title\":\"Half Field Offense: An Environment for Multiagent Learning and Ad Hoc Teamwork\",\"url\":\"https://www.semanticscholar.org/paper/c260a51d57c4adff52838a39ee474864696d0e40\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144169878\",\"name\":\"A. Shantia\"},{\"authorId\":\"3040404\",\"name\":\"Eric Begue\"},{\"authorId\":\"32239759\",\"name\":\"M. Wiering\"}],\"doi\":\"10.1109/ijcnn39090.2017\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"092478aa9c2a30eeadcdaa60a0d3b565a9b535a6\",\"title\":\"2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)\",\"url\":\"https://www.semanticscholar.org/paper/092478aa9c2a30eeadcdaa60a0d3b565a9b535a6\",\"venue\":\"IJCNN 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145626007\",\"name\":\"S. Kelly\"},{\"authorId\":\"1796941\",\"name\":\"M. Heywood\"}],\"doi\":\"10.1145/2739480.2754798\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"90df54a582a65eeea30ed437817d3ca061d8e9a6\",\"title\":\"Knowledge Transfer from Keepaway Soccer to Half-field Offense through Program Symbiosis: Building Simple Programs for a Complex Task\",\"url\":\"https://www.semanticscholar.org/paper/90df54a582a65eeea30ed437817d3ca061d8e9a6\",\"venue\":\"GECCO\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1727849\",\"name\":\"S. Hanson\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"69d7086300e7f5322c06f2f242a565b3a182efb5\",\"title\":\"In Advances in Neural Information Processing Systems\",\"url\":\"https://www.semanticscholar.org/paper/69d7086300e7f5322c06f2f242a565b3a182efb5\",\"venue\":\"NIPS 1990\",\"year\":1990},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2327581\",\"name\":\"Eirini Kaldeli\"},{\"authorId\":\"1766996\",\"name\":\"A. Lazovik\"},{\"authorId\":\"1747132\",\"name\":\"Marco Aiello\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"533214fbe2ff4d2532b050a9c2dbffaa9f356eec\",\"title\":\"AAAI Conference on Artificial Intelligence\",\"url\":\"https://www.semanticscholar.org/paper/533214fbe2ff4d2532b050a9c2dbffaa9f356eec\",\"venue\":\"AAAI 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Matthew E. Taylor\"},{\"authorId\":null,\"name\":\"Peter Stone\"},{\"authorId\":null,\"name\":\"Yaxin Liu. Transfer Learning via Inter-Task Mappings for Learning\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Journal of Machine Learning Research\",\"url\":\"\",\"venue\":\"8(1):2125\\u20132167,\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Felipe Leno Da Silva\"},{\"authorId\":null,\"name\":\"Ruben Glatt\"},{\"authorId\":null,\"name\":\"Anna Helena Reali Costa. Simultaneously Learning\"},{\"authorId\":null,\"name\":\"Advising in Multiagent Reinforcement Learning\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In International Conference on Autonomous Agents and Multiagent Systems (AAMAS)\",\"url\":\"\",\"venue\":\"pages 1100\\u20131108,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Alessandro Lazaric\"},{\"authorId\":null,\"name\":\"Marcello Restelli\"},{\"authorId\":null,\"name\":\"Andrea Bonarini. Transfer of Samples in Batch Reinforceme Learning\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In International Conference on Machine Learning (ICML)\",\"url\":\"\",\"venue\":\"pages 544\\u2013551,\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2323268\",\"name\":\"B. Peng\"},{\"authorId\":\"2700008\",\"name\":\"J. MacGlashan\"},{\"authorId\":\"32182645\",\"name\":\"R. Loftin\"},{\"authorId\":\"144885169\",\"name\":\"M. Littman\"},{\"authorId\":\"145630067\",\"name\":\"D. Roberts\"},{\"authorId\":\"39286677\",\"name\":\"Matthew E. Taylor\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"14371054fc71f64d5c93d8e503e8d813b775b09e\",\"title\":\"A Need for Speed: Adapting Agent Action Speed to Improve Task Learning from Non-Expert Humans\",\"url\":\"https://www.semanticscholar.org/paper/14371054fc71f64d5c93d8e503e8d813b775b09e\",\"venue\":\"AAMAS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145217663\",\"name\":\"M. Stewart\"}],\"doi\":\"10.1016/J.WEM.2014.12.006\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"17200cec932975996054db71c83f1d41a9bfa876\",\"title\":\"Ieee Transactions On Cybernetics\",\"url\":\"https://www.semanticscholar.org/paper/17200cec932975996054db71c83f1d41a9bfa876\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144848112\",\"name\":\"P. Stone\"},{\"authorId\":\"1699645\",\"name\":\"R. Sutton\"},{\"authorId\":\"145805766\",\"name\":\"G. Kuhlmann\"}],\"doi\":\"10.1177/105971230501300301\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"39a2cd04d81eeefe8ea8293a29532cf7ad55e34c\",\"title\":\"Reinforcement Learning for RoboCup Soccer Keepaway\",\"url\":\"https://www.semanticscholar.org/paper/39a2cd04d81eeefe8ea8293a29532cf7ad55e34c\",\"venue\":\"Adapt. Behav.\",\"year\":2005},{\"arxivId\":\"1703.05407\",\"authors\":[{\"authorId\":\"2265067\",\"name\":\"Sainbayar Sukhbaatar\"},{\"authorId\":\"2000906\",\"name\":\"Ilya Kostrikov\"},{\"authorId\":\"3149531\",\"name\":\"Arthur Szlam\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8499a250422a3c66357367c8d5fa504de5424c59\",\"title\":\"Intrinsic Motivation and Automatic Curricula via Asymmetric Self-Play\",\"url\":\"https://www.semanticscholar.org/paper/8499a250422a3c66357367c8d5fa504de5424c59\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Sonia Chernova\"},{\"authorId\":null,\"name\":\"Manuela Veloso. Interactive Policy Learning through Confid Autonomy\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Journal of Artificial Intelligence Research (JAIR)\",\"url\":\"\",\"venue\":\"34(1):1,\",\"year\":2009},{\"arxivId\":\"1707.00183\",\"authors\":[{\"authorId\":\"3319842\",\"name\":\"Tambet Matiisen\"},{\"authorId\":\"35679876\",\"name\":\"A. Oliver\"},{\"authorId\":\"2056266\",\"name\":\"T. Cohen\"},{\"authorId\":\"47971768\",\"name\":\"John Schulman\"}],\"doi\":\"10.1109/TNNLS.2019.2934906\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fb9b0a6e88ca6e3cef9fc6ba060b27c5303da258\",\"title\":\"Teacher\\u2013Student Curriculum Learning\",\"url\":\"https://www.semanticscholar.org/paper/fb9b0a6e88ca6e3cef9fc6ba060b27c5303da258\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144299726\",\"name\":\"Thomas G. Dietterich\"}],\"doi\":\"10.1145/242224.242229\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aab43c9c33af00b718cf2ae374b861d49862a563\",\"title\":\"Machine learning\",\"url\":\"https://www.semanticscholar.org/paper/aab43c9c33af00b718cf2ae374b861d49862a563\",\"venue\":\"CSUR\",\"year\":1996},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144848112\",\"name\":\"P. Stone\"},{\"authorId\":\"1725049\",\"name\":\"G. Kaminka\"},{\"authorId\":\"144992450\",\"name\":\"S. Kraus\"},{\"authorId\":\"1735970\",\"name\":\"J. S. Rosenschein\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e4996547720f4801eca284a3c3dfa7943cd08ecf\",\"title\":\"Ad Hoc Autonomous Agent Teams: Collaboration without Pre-Coordination\",\"url\":\"https://www.semanticscholar.org/paper/e4996547720f4801eca284a3c3dfa7943cd08ecf\",\"venue\":\"AAAI\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145050960\",\"name\":\"F. Silva\"},{\"authorId\":\"2209202\",\"name\":\"A. Costa\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e2489161ac8cab8b044fb96966d899a1f1d3ca96\",\"title\":\"Towards Zero-Shot Autonomous Inter-Task Mapping through Object-Oriented Task Description\",\"url\":\"https://www.semanticscholar.org/paper/e2489161ac8cab8b044fb96966d899a1f1d3ca96\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1703826\",\"name\":\"Liviu Panait\"},{\"authorId\":\"1706276\",\"name\":\"S. Luke\"}],\"doi\":\"10.1007/s10458-005-2631-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2a1724427b9c473e73f6abff648e7416269d3a68\",\"title\":\"Cooperative Multi-Agent Learning: The State of the Art\",\"url\":\"https://www.semanticscholar.org/paper/2a1724427b9c473e73f6abff648e7416269d3a68\",\"venue\":\"Autonomous Agents and Multi-Agent Systems\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2670689\",\"name\":\"J. Meyer\"},{\"authorId\":\"2221945\",\"name\":\"A. Guillot\"}],\"doi\":\"10.4135/9781412950565.n6\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3dd614ec69ca6ea73d7d096752d6daf4b4efc896\",\"title\":\"Adaptive Behavior\",\"url\":\"https://www.semanticscholar.org/paper/3dd614ec69ca6ea73d7d096752d6daf4b4efc896\",\"venue\":\"\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2068621\",\"name\":\"Marcelo Li Koga\"},{\"authorId\":\"52146175\",\"name\":\"Valdinei Freire da Silva\"},{\"authorId\":\"2209202\",\"name\":\"A. Costa\"}],\"doi\":\"10.1109/TCYB.2014.2319733\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"09e71db94426311f53e11f4eb4cf3ada86d52198\",\"title\":\"Stochastic Abstract Policies: Generalizing Knowledge to Improve Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/09e71db94426311f53e11f4eb4cf3ada86d52198\",\"venue\":\"IEEE Transactions on Cybernetics\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1735414\",\"name\":\"T. Knasel\"}],\"doi\":\"10.1016/0921-8890(88)90002-4\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"edd77f310393f521669b209cbb6828fb45a8485d\",\"title\":\"Robotics and autonomous systems\",\"url\":\"https://www.semanticscholar.org/paper/edd77f310393f521669b209cbb6828fb45a8485d\",\"venue\":\"Robotics Auton. Syst.\",\"year\":1988},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yujing Hu\"},{\"authorId\":null,\"name\":\"Yang Gao\"},{\"authorId\":null,\"name\":\"Bo An. Learning in Multi-agent Systems with Sparse In Transfer\"},{\"authorId\":null,\"name\":\"Game Abstraction\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In International Conference on Autonomous Agents and Multiagent Systems (AAMAS)\",\"url\":\"\",\"venue\":\"pages 753\\u2013761,\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1682788\",\"name\":\"A. Thomaz\"},{\"authorId\":\"1711777\",\"name\":\"C. Breazeal\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"0fcd047a1a6e391c8a6c140967355ec2a0ad8c9e\",\"title\":\"Reinforcement Learning with Human Teachers: Evidence of Feedback and Guidance with Implications for Learning Performance\",\"url\":\"https://www.semanticscholar.org/paper/0fcd047a1a6e391c8a6c140967355ec2a0ad8c9e\",\"venue\":\"AAAI\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Sanmit Narvekar\"},{\"authorId\":null,\"name\":\"Jivko Sinapov\"},{\"authorId\":null,\"name\":\"Matteo Leonetti\"},{\"authorId\":null,\"name\":\"Peter Stone. Source Task Creation for Curriculum Learning\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In International Conference on Autonomous Agents and Multiagent Systems (AAMAS)\",\"url\":\"\",\"venue\":\"pages 566\\u2013574,\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Bob Price\"},{\"authorId\":null,\"name\":\"Craig Boutilier. Accelerating Reinforcement Learning thr Imitation\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Journal of Artificial Intelligence Research (JAIR)\",\"url\":\"\",\"venue\":\"19:569\\u2013629,\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Silva\"},{\"authorId\":null,\"name\":\"Costa\"},{\"authorId\":null,\"name\":\"2015 Felipe Leno Da Silva\"},{\"authorId\":null,\"name\":\"Anna Helena Reali Costa\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Multi-Objective Reinforcement Learning through Reward Weighting\",\"url\":\"\",\"venue\":\"In Workshop on Synergies Between Multiagent Systems, Machine Learning and Complex Systems (TRI) at IJCAI,\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66921351\",\"name\":\"Natalia Criado Pacheco\"},{\"authorId\":\"144622087\",\"name\":\"J. M. Such\"}],\"doi\":\"10.1016/0004-3702(72)90052-5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0c711a90bf4768599e022511c545f9cfddbf3b35\",\"title\":\"International Joint Conference on Artificial Intelligence (IJCAI)\",\"url\":\"https://www.semanticscholar.org/paper/0c711a90bf4768599e022511c545f9cfddbf3b35\",\"venue\":\"\",\"year\":2016}],\"title\":\"Autonomously Reusing Knowledge in Multiagent Reinforcement Learning\",\"topics\":[{\"topic\":\"Reinforcement learning\",\"topicId\":\"2557\",\"url\":\"https://www.semanticscholar.org/topic/2557\"},{\"topic\":\"Autonomous robot\",\"topicId\":\"1175\",\"url\":\"https://www.semanticscholar.org/topic/1175\"},{\"topic\":\"Hard coding\",\"topicId\":\"592983\",\"url\":\"https://www.semanticscholar.org/topic/592983\"},{\"topic\":\"Interaction\",\"topicId\":\"72\",\"url\":\"https://www.semanticscholar.org/topic/72\"},{\"topic\":\"Autonomous agent\",\"topicId\":\"29926\",\"url\":\"https://www.semanticscholar.org/topic/29926\"},{\"topic\":\"Agent-based model\",\"topicId\":\"4774\",\"url\":\"https://www.semanticscholar.org/topic/4774\"}],\"url\":\"https://www.semanticscholar.org/paper/827ce92aa1ed258bca2133443982793d1fda7be5\",\"venue\":\"IJCAI\",\"year\":2018}\n"