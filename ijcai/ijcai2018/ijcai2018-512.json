"{\"abstract\":\"Open-ended long-form video question answering is challenging problem in visual information retrieval, which automatically generates the natural language answer from the referenced long-form video content according to the question. However, the existing video question answering works mainly focus on the short-form video question answering, due to the lack of modeling the semantic representation of long-form video contents. In this paper, we consider the problem of long-form video question answering from the viewpoint of adaptive hierarchical reinforced encoder-decoder network learning. We propose the adaptive hierarchical encoder network to learn the joint representation of the longform video contents according to the question with adaptive video segmentation. we then develop the reinforced decoder network to generate the natural language answer for open-ended video question answering. We construct a large-scale long-form video question answering dataset. The extensive experiments show the effectiveness of our method.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\",\"url\":\"https://www.semanticscholar.org/author/47122432\"},{\"authorId\":\"1764508\",\"name\":\"Z. Zhang\",\"url\":\"https://www.semanticscholar.org/author/1764508\"},{\"authorId\":\"51055350\",\"name\":\"Shuwen Xiao\",\"url\":\"https://www.semanticscholar.org/author/51055350\"},{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\",\"url\":\"https://www.semanticscholar.org/author/144007938\"},{\"authorId\":\"1720236\",\"name\":\"J. Yu\",\"url\":\"https://www.semanticscholar.org/author/1720236\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\",\"url\":\"https://www.semanticscholar.org/author/1724421\"},{\"authorId\":\"144894849\",\"name\":\"Fei Wu\",\"url\":\"https://www.semanticscholar.org/author/144894849\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\",\"url\":\"https://www.semanticscholar.org/author/143749205\"}],\"citationVelocity\":8,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"},{\"authorId\":\"48481929\",\"name\":\"Yi-jun Song\"},{\"authorId\":\"47891191\",\"name\":\"Jun Yu\"},{\"authorId\":\"48957872\",\"name\":\"Meng Wang\"},{\"authorId\":\"153159021\",\"name\":\"Qingming Huang\"}],\"doi\":\"10.1007/s11063-020-10205-y\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c1d607b58d31c582bee0cc78017909a1eed45c9\",\"title\":\"Intra- and Inter-modal Multilinear Pooling with Multitask Learning for Video Grounding\",\"url\":\"https://www.semanticscholar.org/paper/6c1d607b58d31c582bee0cc78017909a1eed45c9\",\"venue\":\"Neural Processing Letters\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150337817\",\"name\":\"Weike Jin\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"67144160\",\"name\":\"Mao Gu\"},{\"authorId\":\"97583812\",\"name\":\"J. Yu\"},{\"authorId\":\"1384523745\",\"name\":\"Jun Xiao\"},{\"authorId\":\"2125211\",\"name\":\"Yueting Zhuang\"}],\"doi\":\"10.1145/3343031.3351065\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7a162f189c9c553438b83a8a8ec7de4a6fa59069\",\"title\":\"Multi-interaction Network with Object Relation for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7a162f189c9c553438b83a8a8ec7de4a6fa59069\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"1764508\",\"name\":\"Z. Zhang\"},{\"authorId\":\"2440041\",\"name\":\"X. Jiang\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"}],\"doi\":\"10.1109/TIP.2019.2902106\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"65bd828c05cac7eabe791e10d4d3c0f2da2b798c\",\"title\":\"Multi-Turn Video Question Answering via Hierarchical Attention Context Reinforced Networks\",\"url\":\"https://www.semanticscholar.org/paper/65bd828c05cac7eabe791e10d4d3c0f2da2b798c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"1907.13280\",\"authors\":[{\"authorId\":\"2531558\",\"name\":\"G. Chao\"},{\"authorId\":\"2188497\",\"name\":\"Abhinav Rastogi\"},{\"authorId\":\"3014143\",\"name\":\"Semih Yavuz\"},{\"authorId\":\"152325757\",\"name\":\"D. Hakkani-T\\u00fcr\"},{\"authorId\":\"47740493\",\"name\":\"Jindong Chen\"},{\"authorId\":\"5347612\",\"name\":\"I. Lane\"}],\"doi\":\"10.18653/v1/W19-5926\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fb5af7b7d5ebf9e8ff4164233a73b8fe4fe737a3\",\"title\":\"Learning Question-Guided Video Representation for Multi-Turn Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/fb5af7b7d5ebf9e8ff4164233a73b8fe4fe737a3\",\"venue\":\"ViGIL@NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"48210950\",\"name\":\"Jiawei Liu\"},{\"authorId\":\"49876189\",\"name\":\"T. Yang\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.1145/3320061\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"86ce76f54a7bfc6047f83877408f789449f28df4\",\"title\":\"Spatiotemporal-Textual Co-Attention Network for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/86ce76f54a7bfc6047f83877408f789449f28df4\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":\"1906.02497\",\"authors\":[{\"authorId\":\"1764508\",\"name\":\"Z. Zhang\"},{\"authorId\":\"34064720\",\"name\":\"Zhijie Lin\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"123034558\",\"name\":\"Z. Xiao\"}],\"doi\":\"10.1145/3331184.3331235\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fb53803897d3df3e1f43a43a753ee88a64517c47\",\"title\":\"Cross-Modal Interaction Networks for Query-Based Moment Retrieval in Videos\",\"url\":\"https://www.semanticscholar.org/paper/fb53803897d3df3e1f43a43a753ee88a64517c47\",\"venue\":\"SIGIR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49290494\",\"name\":\"Zhijie Lin\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"1742291\",\"name\":\"Zixing Zhang\"},{\"authorId\":\"48805561\",\"name\":\"Zijian Zhang\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"}],\"doi\":\"10.1109/TIP.2020.2965987\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5a68ef4d0c1a814dd0920f6824aaad8e15339f66\",\"title\":\"Moment Retrieval via Cross-Modal Interaction Networks With Query Reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/5a68ef4d0c1a814dd0920f6824aaad8e15339f66\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"2012.00451\",\"authors\":[{\"authorId\":\"153276988\",\"name\":\"Antoine Yang\"},{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"153433844\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b1b6ff0df21818ac8c4f61d86141da48188f36b3\",\"title\":\"Just Ask: Learning to Answer Questions from Millions of Narrated Videos\",\"url\":\"https://www.semanticscholar.org/paper/b1b6ff0df21818ac8c4f61d86141da48188f36b3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2712862\",\"name\":\"D. Zhang\"},{\"authorId\":\"145690873\",\"name\":\"R. Cao\"},{\"authorId\":\"1765710\",\"name\":\"Sai Wu\"}],\"doi\":\"10.1016/J.INFFUS.2019.03.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"91118408f8192c2addade2a0401a32c3bbd47818\",\"title\":\"Information fusion in visual question answering: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/91118408f8192c2addade2a0401a32c3bbd47818\",\"venue\":\"Inf. Fusion\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"BiGRU BiGRU\"},{\"authorId\":null,\"name\":\"BiGRU\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dd8a531ddff2ba788d02555af04632c46f31ecf0\",\"title\":\"Multi-Stage Cross-modal Interaction Module d ) Moment Retrieval Module q \\\" q # q $ q ) Query\",\"url\":\"https://www.semanticscholar.org/paper/dd8a531ddff2ba788d02555af04632c46f31ecf0\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"51305348\",\"name\":\"Zhu Zhang\"},{\"authorId\":\"51055350\",\"name\":\"Shuwen Xiao\"},{\"authorId\":\"123034558\",\"name\":\"Z. Xiao\"},{\"authorId\":\"145477645\",\"name\":\"X. Yan\"},{\"authorId\":\"50812077\",\"name\":\"J. Yu\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"},{\"authorId\":\"39918420\",\"name\":\"F. Wu\"}],\"doi\":\"10.1109/TIP.2019.2922062\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"80c67ece4198e3dd1ef88e6ddb81eb71bee5f3fa\",\"title\":\"Long-Form Video Question Answering via Dynamic Hierarchical Reinforced Networks\",\"url\":\"https://www.semanticscholar.org/paper/80c67ece4198e3dd1ef88e6ddb81eb71bee5f3fa\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49597404\",\"name\":\"Z. Fang\"},{\"authorId\":null,\"name\":\"Jing Liu\"},{\"authorId\":\"49544292\",\"name\":\"Xueliang Liu\"},{\"authorId\":null,\"name\":\"Qu Tang\"},{\"authorId\":\"50025104\",\"name\":\"Yonghong Li\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1145/3282469\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c74311cc5e18a120bebf331b0dd85c72426380d\",\"title\":\"BTDP: Toward Sparse Fusion with Block Term Decomposition Pooling for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2c74311cc5e18a120bebf331b0dd85c72426380d\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1514929766\",\"name\":\"Chongqing Chen\"},{\"authorId\":\"1840771\",\"name\":\"D. Han\"},{\"authorId\":\"71563119\",\"name\":\"Jun Wang\"}],\"doi\":\"10.1109/ACCESS.2020.2975093\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e75fa8852f5a4779cfdf2f22bd87e213f57b2d20\",\"title\":\"Multimodal Encoder-Decoder Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e75fa8852f5a4779cfdf2f22bd87e213f57b2d20\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1735739\",\"name\":\"Weifeng Zhang\"},{\"authorId\":\"119883573\",\"name\":\"J. Yu\"},{\"authorId\":\"47864783\",\"name\":\"H. Hu\"},{\"authorId\":\"144645443\",\"name\":\"H. Hu\"},{\"authorId\":\"70565757\",\"name\":\"Zengchang Qin\"}],\"doi\":\"10.1016/J.INFFUS.2019.08.009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"04afa0417dc2a4555c15243a69e6a54ce44ecf63\",\"title\":\"Multimodal feature fusion by relational reasoning and attention for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/04afa0417dc2a4555c15243a69e6a54ce44ecf63\",\"venue\":\"Inf. Fusion\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24545031\",\"name\":\"Jiayin Cai\"},{\"authorId\":\"144204924\",\"name\":\"C. Yuan\"},{\"authorId\":\"145280977\",\"name\":\"Cheng Shi\"},{\"authorId\":null,\"name\":\"Lei Li\"},{\"authorId\":\"150347046\",\"name\":\"Yangyang Cheng\"},{\"authorId\":\"1387190008\",\"name\":\"Ying Shan\"}],\"doi\":\"10.24963/ijcai.2020/139\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3bcf4c354f68d5e85ffcc6d69c1348e69d241857\",\"title\":\"Feature Augmented Memory with Global Attention Network for VideoQA\",\"url\":\"https://www.semanticscholar.org/paper/3bcf4c354f68d5e85ffcc6d69c1348e69d241857\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":\"1906.10770\",\"authors\":[{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"},{\"authorId\":\"9919436\",\"name\":\"J. Yu\"},{\"authorId\":\"30513139\",\"name\":\"Yuhao Cui\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/CVPR.2019.00644\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a1744da011375d711ed75fc2d160c6fdca2cf89\",\"title\":\"Deep Modular Co-Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8a1744da011375d711ed75fc2d160c6fdca2cf89\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51021265\",\"name\":\"T. Yu\"},{\"authorId\":\"97583812\",\"name\":\"J. Yu\"},{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/TIP.2019.2940677\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ef33aedbab68b0771f6dd7ca8ec2492f12d7ea51\",\"title\":\"Compositional Attention Networks With Two-Stream Fusion for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ef33aedbab68b0771f6dd7ca8ec2492f12d7ea51\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1907.03049\",\"authors\":[{\"authorId\":null,\"name\":\"Yu-Siang Wang\"},{\"authorId\":\"71309591\",\"name\":\"Hung-Ting Su\"},{\"authorId\":\"150053992\",\"name\":\"Chen-Hsi Chang\"},{\"authorId\":\"143822897\",\"name\":\"Zhe Yu Liu\"},{\"authorId\":\"31871157\",\"name\":\"Winston Hsu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"091ad302f5381bd131b41a57e16d802ff4ab9668\",\"title\":\"Video Question Generation via Cross-Modal Self-Attention Networks Learning\",\"url\":\"https://www.semanticscholar.org/paper/091ad302f5381bd131b41a57e16d802ff4ab9668\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150337817\",\"name\":\"Weike Jin\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"48515305\",\"name\":\"Yimeng Li\"},{\"authorId\":\"49298718\",\"name\":\"Jie Li\"},{\"authorId\":\"145974112\",\"name\":\"Jun Xiao\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1145/3321505\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"99b722fc4e168eddea69521f26c77e31e56fc9f4\",\"title\":\"Video Question Answering via Knowledge-based Progressive Spatial-Temporal Attention Network\",\"url\":\"https://www.semanticscholar.org/paper/99b722fc4e168eddea69521f26c77e31e56fc9f4\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":\"1906.12158\",\"authors\":[{\"authorId\":\"47294375\",\"name\":\"Zhu Zhang\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"145510896\",\"name\":\"Z. Lin\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"3945955\",\"name\":\"X. He\"}],\"doi\":\"10.24963/ijcai.2019/609\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1b2ae2e1f9148e6a05128773c16868cae7e99dc2\",\"title\":\"Open-Ended Long-Form Video Question Answering via Hierarchical Convolutional Self-Attention Networks\",\"url\":\"https://www.semanticscholar.org/paper/1b2ae2e1f9148e6a05128773c16868cae7e99dc2\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2151048\",\"name\":\"Taiki Miyanishi\"},{\"authorId\":\"34772057\",\"name\":\"Takuya Maekawa\"},{\"authorId\":\"1716788\",\"name\":\"M. Kawanabe\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b3fc587b83d8c6a28b2bc4f9a1f8770f42fb5658\",\"title\":\"Two-Stream Spatiotemporal Compositional Attention Network for VideoQA\",\"url\":\"https://www.semanticscholar.org/paper/b3fc587b83d8c6a28b2bc4f9a1f8770f42fb5658\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1906.02467\",\"authors\":[{\"authorId\":\"48567197\",\"name\":\"Zhou Yu\"},{\"authorId\":\"50854337\",\"name\":\"D. Xu\"},{\"authorId\":\"1720236\",\"name\":\"J. Yu\"},{\"authorId\":\"144478231\",\"name\":\"T. Yu\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1609/aaai.v33i01.33019127\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4f2c1af57c056102806a184517313804f66e7447\",\"title\":\"ActivityNet-QA: A Dataset for Understanding Complex Web Videos via Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/4f2c1af57c056102806a184517313804f66e7447\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"2006.14264\",\"authors\":[{\"authorId\":\"151430668\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b58adf956dfd71a756b8f98b726fdcd8e2552445\",\"title\":\"Self-Segregating and Coordinated-Segregating Transformer for Focused Deep Multi-Modular Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b58adf956dfd71a756b8f98b726fdcd8e2552445\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49597404\",\"name\":\"Z. Fang\"},{\"authorId\":\"46700426\",\"name\":\"J. Liu\"},{\"authorId\":\"47003032\",\"name\":\"Y. Li\"},{\"authorId\":\"80526284\",\"name\":\"Yanyuan Qiao\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1016/J.PATCOG.2019.01.038\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aa31126aa9dc7665bf236a51c6de31c4bf6c59ad\",\"title\":\"Improving visual question answering using dropout and enhanced question encoder\",\"url\":\"https://www.semanticscholar.org/paper/aa31126aa9dc7665bf236a51c6de31c4bf6c59ad\",\"venue\":\"Pattern Recognit.\",\"year\":2019}],\"corpusId\":51612182,\"doi\":\"10.24963/ijcai.2018/512\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":false,\"paperId\":\"1c6da8fdc68888296730dbeed0fd0624febbc16f\",\"references\":[{\"arxivId\":\"1611.04021\",\"authors\":[{\"authorId\":\"32970572\",\"name\":\"Kuo-Hao Zeng\"},{\"authorId\":\"3451456\",\"name\":\"Tseng-Hung Chen\"},{\"authorId\":\"8551209\",\"name\":\"Ching-Yao Chuang\"},{\"authorId\":\"1826179\",\"name\":\"Yuan-Hong Liao\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1da2431a799f68888b7e035fe49fe47a4735b71b\",\"title\":\"Leveraging Video Descriptions to Learn Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1da2431a799f68888b7e035fe49fe47a4735b71b\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":\"1505.00468\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-016-0966-6\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"title\":\"VQA: Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Christiane Fellbaum\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"WordNet\",\"url\":\"\",\"venue\":\"Wiley Online Library,\",\"year\":1998},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jiasen Lu\"},{\"authorId\":null,\"name\":\"Jianwei Yang\"},{\"authorId\":null,\"name\":\"Dhruv Batra\"},{\"authorId\":null,\"name\":\"Devi Parikh. Hierarchical question-image co-attention f answering\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In NIPS\",\"url\":\"\",\"venue\":\"pages 289\\u2013297,\",\"year\":2016},{\"arxivId\":\"1308.3432\",\"authors\":[{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"144828689\",\"name\":\"N. L\\u00e9onard\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"62c76ca0b2790c34e85ba1cce09d47be317c7235\",\"title\":\"Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation\",\"url\":\"https://www.semanticscholar.org/paper/62c76ca0b2790c34e85ba1cce09d47be317c7235\",\"venue\":\"ArXiv\",\"year\":2013},{\"arxivId\":\"1512.02902\",\"authors\":[{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"2214033\",\"name\":\"Y. Zhu\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":\"10.1109/CVPR.2016.501\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1bdd75a37f7c601f01e9d31c2551fa9f2067ffd7\",\"title\":\"MovieQA: Understanding Stories in Movies through Question-Answering\",\"url\":\"https://www.semanticscholar.org/paper/1bdd75a37f7c601f01e9d31c2551fa9f2067ffd7\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2618874\",\"name\":\"Michael Heilman\"},{\"authorId\":\"144365875\",\"name\":\"Noah A. Smith\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c8066fa6f7037de866189c70ef2ec995208b011\",\"title\":\"Good Question! Statistical Ranking for Question Generation\",\"url\":\"https://www.semanticscholar.org/paper/1c8066fa6f7037de866189c70ef2ec995208b011\",\"venue\":\"HLT-NAACL\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66921351\",\"name\":\"Natalia Criado Pacheco\"},{\"authorId\":\"144622087\",\"name\":\"J. M. Such\"}],\"doi\":\"10.1016/0004-3702(72)90052-5\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0c711a90bf4768599e022511c545f9cfddbf3b35\",\"title\":\"International Joint Conference on Artificial Intelligence (IJCAI)\",\"url\":\"https://www.semanticscholar.org/paper/0c711a90bf4768599e022511c545f9cfddbf3b35\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Zichao Yang\"},{\"authorId\":null,\"name\":\"Xiaodong He\"},{\"authorId\":null,\"name\":\"Jianfeng Gao\"},{\"authorId\":null,\"name\":\"Li Deng\"},{\"authorId\":null,\"name\":\"Alex Smola. Stacked attention networks for image questi answering\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In CVPR\",\"url\":\"\",\"venue\":\"pages 21\\u2013 29,\",\"year\":2016},{\"arxivId\":\"1607.05910\",\"authors\":[{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1016/j.cviu.2017.05.001\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"88c307c51594c6d802080a0780d0d654e2e2891f\",\"title\":\"Visual question answering: A survey of methods and datasets\",\"url\":\"https://www.semanticscholar.org/paper/88c307c51594c6d802080a0780d0d654e2e2891f\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Kuo-Hao Zeng\"},{\"authorId\":null,\"name\":\"Tseng-Hung Chen\"},{\"authorId\":null,\"name\":\"Ching-Yao Chuang\"},{\"authorId\":null,\"name\":\"Yuan-Hong Liao\"},{\"authorId\":null,\"name\":\"Juan Carlos Niebles\"},{\"authorId\":null,\"name\":\"Min Sun. Leveraging video descriptions to learn video answering\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In AAAI\",\"url\":\"\",\"venue\":\"pages 4334\\u20134340,\",\"year\":2017},{\"arxivId\":\"1607.07086\",\"authors\":[{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"2616163\",\"name\":\"Philemon Brakel\"},{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"1996705\",\"name\":\"Anirudh Goyal\"},{\"authorId\":\"2054294\",\"name\":\"Ryan Lowe\"},{\"authorId\":\"145134886\",\"name\":\"Joelle Pineau\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0d24a0695c9fc669e643bad51d4e14f056329dec\",\"title\":\"An Actor-Critic Algorithm for Sequence Prediction\",\"url\":\"https://www.semanticscholar.org/paper/0d24a0695c9fc669e643bad51d4e14f056329dec\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1410.0210\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ac64fb7e6d2ddf236332ec9f371fe85d308c114d\",\"title\":\"A Multi-World Approach to Question Answering about Real-World Scenes based on Uncertain Input\",\"url\":\"https://www.semanticscholar.org/paper/ac64fb7e6d2ddf236332ec9f371fe85d308c114d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/CVPR.2015.7298698\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0a28efacb92d16e6e0dd4d87b5aca91b28be8853\",\"title\":\"ActivityNet: A large-scale video benchmark for human activity understanding\",\"url\":\"https://www.semanticscholar.org/paper/0a28efacb92d16e6e0dd4d87b5aca91b28be8853\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145851269\",\"name\":\"S. S. Krishnan\"},{\"authorId\":\"143987348\",\"name\":\"R. Sitaraman\"}],\"doi\":\"10.1145/2504730.2504748\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fd661fb3ce56685b9ff3169550ed2c11da23b9bf\",\"title\":\"Understanding the effectiveness of video ads: a measurement study\",\"url\":\"https://www.semanticscholar.org/paper/fd661fb3ce56685b9ff3169550ed2c11da23b9bf\",\"venue\":\"Internet Measurement Conference\",\"year\":2013},{\"arxivId\":\"1704.03899\",\"authors\":[{\"authorId\":\"145888238\",\"name\":\"Zhou Ren\"},{\"authorId\":\"145779951\",\"name\":\"X. Wang\"},{\"authorId\":\"145002061\",\"name\":\"N. Zhang\"},{\"authorId\":\"2936952\",\"name\":\"Xutao Lv\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"}],\"doi\":\"10.1109/CVPR.2017.128\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c689f73f8ea65c6e81c628f2b37feae09b29e46b\",\"title\":\"Deep Reinforcement Learning-Based Image Captioning with Embedding Reward\",\"url\":\"https://www.semanticscholar.org/paper/c689f73f8ea65c6e81c628f2b37feae09b29e46b\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1610.04062\",\"authors\":[{\"authorId\":\"144839067\",\"name\":\"Amir Mazaheri\"},{\"authorId\":\"119745921\",\"name\":\"Dong Zhang\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9fb31d0375552500bd494af20ab0c3109c9be3d2\",\"title\":\"Video Fill in the Blank with Merging LSTMs\",\"url\":\"https://www.semanticscholar.org/paper/9fb31d0375552500bd494af20ab0c3109c9be3d2\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48700486\",\"name\":\"J. Lezama\"},{\"authorId\":\"72492981\",\"name\":\"Alahari Karteek\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"}],\"doi\":\"10.1109/CVPR.2011.6044588\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"00d43af56f3d107515f32f070432257bc45eb78a\",\"title\":\"Track to the future: Spatio-temporal video segmentation with long-range motion cues\",\"url\":\"https://www.semanticscholar.org/paper/00d43af56f3d107515f32f070432257bc45eb78a\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Pingbo Pan\"},{\"authorId\":null,\"name\":\"Zhongwen Xu\"},{\"authorId\":null,\"name\":\"Yi Yang\"},{\"authorId\":null,\"name\":\"Fei Wu\"},{\"authorId\":null,\"name\":\"Yueting Zhuang. Hierarchical recurrent neural encoder for captioning\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In CVPR\",\"url\":\"\",\"venue\":\"pages 1029\\u20131038,\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48881927\",\"name\":\"R. Li\"},{\"authorId\":\"1729056\",\"name\":\"J. Jia\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"269546925f0fd457b31c13c2870343b0aed761dc\",\"title\":\"Visual Question Answering with Question Representation Update (QRU)\",\"url\":\"https://www.semanticscholar.org/paper/269546925f0fd457b31c13c2870343b0aed761dc\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1707726\",\"name\":\"J. Pustejovsky\"}],\"doi\":\"10.3115/981732\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2879e9a829dd65c92f9c30f10cdd643c0d0bc1b1\",\"title\":\"Proceedings of the 32nd annual meeting on Association for Computational Linguistics\",\"url\":\"https://www.semanticscholar.org/paper/2879e9a829dd65c92f9c30f10cdd643c0d0bc1b1\",\"venue\":\"\",\"year\":1994},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Li Yao\"},{\"authorId\":null,\"name\":\"Atousa Torabi\"},{\"authorId\":null,\"name\":\"Kyunghyun Cho\"},{\"authorId\":null,\"name\":\"Nicolas Ballas\"},{\"authorId\":null,\"name\":\"Christopher Pal\"},{\"authorId\":null,\"name\":\"Hugo Larochelle\"},{\"authorId\":null,\"name\":\"Aaron Courville. Describing videos by exploiting tempora structure\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In ICCV\",\"url\":\"\",\"venue\":\"pages 4507\\u20134515,\",\"year\":2015},{\"arxivId\":\"1704.04497\",\"authors\":[{\"authorId\":\"2338742\",\"name\":\"Y. Jang\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"49170458\",\"name\":\"Youngjin Kim\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1109/CVPR.2017.149\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b2f521c02c6ed3080c5fe123e938cdf4555e6fd2\",\"title\":\"TGIF-QA: Toward Spatio-Temporal Reasoning in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b2f521c02c6ed3080c5fe123e938cdf4555e6fd2\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1511.02274\",\"authors\":[{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"46234526\",\"name\":\"Alex Smola\"}],\"doi\":\"10.1109/CVPR.2016.10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2c1890864c1c2b750f48316dc8b650ba4772adc5\",\"title\":\"Stacked Attention Networks for Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2c1890864c1c2b750f48316dc8b650ba4772adc5\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1511.04670\",\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"2351434\",\"name\":\"Zhongwen Xu\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9ed7d774684a1770445c1c53e276011a8364b9e2\",\"title\":\"Uncovering Temporal Context for Video Question and Answering\",\"url\":\"https://www.semanticscholar.org/paper/9ed7d774684a1770445c1c53e276011a8364b9e2\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98241663\",\"name\":\"M. V. Rossum\"}],\"doi\":\"10.1142/9789814360784_0003\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2d5af1ab6368f20a4a9bb2afae23663e5b08b9c6\",\"title\":\"Neural Computation\",\"url\":\"https://www.semanticscholar.org/paper/2d5af1ab6368f20a4a9bb2afae23663e5b08b9c6\",\"venue\":\"\",\"year\":1989},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Mateusz Malinowski\"},{\"authorId\":null,\"name\":\"Mario Fritz. A multi-world approach to question answerin input\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In NIPS\",\"url\":\"\",\"venue\":\"pages 1682\\u20131690,\",\"year\":2014},{\"arxivId\":\"1511.07394\",\"authors\":[{\"authorId\":\"143953573\",\"name\":\"K. Shih\"},{\"authorId\":\"37415643\",\"name\":\"S. Singh\"},{\"authorId\":\"2433269\",\"name\":\"Derek Hoiem\"}],\"doi\":\"10.1109/CVPR.2016.499\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"175e9bb50cc062c6c1742a5d90c8dfe31d2e4e22\",\"title\":\"Where to Look: Focus Regions for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/175e9bb50cc062c6c1742a5d90c8dfe31d2e4e22\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1511.03476\",\"authors\":[{\"authorId\":\"1991108\",\"name\":\"P. Pan\"},{\"authorId\":\"2351434\",\"name\":\"Zhongwen Xu\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"},{\"authorId\":\"144894849\",\"name\":\"Fei Wu\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1109/CVPR.2016.117\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e9a66904559011d48245bba01e55f72246927e77\",\"title\":\"Hierarchical Recurrent Neural Encoder for Video Representation with Application to Captioning\",\"url\":\"https://www.semanticscholar.org/paper/e9a66904559011d48245bba01e55f72246927e77\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016}],\"title\":\"Open-Ended Long-form Video Question Answering via Adaptive Hierarchical Reinforced Networks\",\"topics\":[{\"topic\":\"Question answering\",\"topicId\":\"18817\",\"url\":\"https://www.semanticscholar.org/topic/18817\"},{\"topic\":\"Nonlinear gameplay\",\"topicId\":\"62171\",\"url\":\"https://www.semanticscholar.org/topic/62171\"},{\"topic\":\"Encoder\",\"topicId\":\"16744\",\"url\":\"https://www.semanticscholar.org/topic/16744\"},{\"topic\":\"Natural language\",\"topicId\":\"1911\",\"url\":\"https://www.semanticscholar.org/topic/1911\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Information retrieval\",\"topicId\":\"2867\",\"url\":\"https://www.semanticscholar.org/topic/2867\"},{\"topic\":\"Digital video\",\"topicId\":\"44670\",\"url\":\"https://www.semanticscholar.org/topic/44670\"},{\"topic\":\"Unified Video Decoder\",\"topicId\":\"1250042\",\"url\":\"https://www.semanticscholar.org/topic/1250042\"}],\"url\":\"https://www.semanticscholar.org/paper/1c6da8fdc68888296730dbeed0fd0624febbc16f\",\"venue\":\"IJCAI\",\"year\":2018}\n"