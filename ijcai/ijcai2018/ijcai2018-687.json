"{\"abstract\":\"Humans often learn how to perform tasks via imitation: they observe others perform a task, and then very quickly infer the appropriate actions to take based on their observations. While extending this paradigm to autonomous agents is a well-studied problem in general, there are two particular aspects that have largely been overlooked: (1) that the learning is done from observation only (i.e., without explicit action information), and (2) that the learning is typically done very quickly. In this work, we propose a two-phase, autonomous imitation learning technique called behavioral cloning from observation (BCO), that aims to provide improved performance with respect to both of these aspects. First, we allow the agent to acquire experience in a self-supervised fashion. This experience is used to develop a model which is then utilized to learn a particular task by observing an expert perform that task without the knowledge of the specific actions taken. We experimentally compare BCO to imitation learning methods, including the state-of-the-art, generative adversarial imitation learning (GAIL) technique, and we show comparable task performance in several different simulation domains while exhibiting increased learning speed after expert trajectories become available.\",\"arxivId\":\"1805.01954\",\"authors\":[{\"authorId\":\"46221670\",\"name\":\"F. Torabi\",\"url\":\"https://www.semanticscholar.org/author/46221670\"},{\"authorId\":\"1938253\",\"name\":\"Garrett Warnell\",\"url\":\"https://www.semanticscholar.org/author/1938253\"},{\"authorId\":\"144848112\",\"name\":\"P. Stone\",\"url\":\"https://www.semanticscholar.org/author/144848112\"}],\"citationVelocity\":48,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1822288\",\"name\":\"Karan Goel\"},{\"authorId\":\"2563117\",\"name\":\"Emma Brunskill\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1d2060dd9348b9c4b040bb66048f446b7d06e5dc\",\"title\":\"UATING DISCRETE LATENT TEMPORAL STRUCTURE\",\"url\":\"https://www.semanticscholar.org/paper/1d2060dd9348b9c4b040bb66048f446b7d06e5dc\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1905.09335\",\"authors\":[{\"authorId\":\"46221670\",\"name\":\"F. Torabi\"},{\"authorId\":\"1938253\",\"name\":\"Garrett Warnell\"},{\"authorId\":\"144848112\",\"name\":\"P. Stone\"}],\"doi\":\"10.24963/ijcai.2019/497\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1706cc1c2433275fc326967da8318790378da850\",\"title\":\"Imitation Learning from Video by Leveraging Proprioception\",\"url\":\"https://www.semanticscholar.org/paper/1706cc1c2433275fc326967da8318790378da850\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152784304\",\"name\":\"A. Kumar\"},{\"authorId\":\"47924870\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"153652147\",\"name\":\"J. Malik\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"d8886451bd6f3dbc48f98107901220cd845a7ea6\",\"title\":\"Learning Navigation Subroutines from Egocentric Videos\",\"url\":\"https://www.semanticscholar.org/paper/d8886451bd6f3dbc48f98107901220cd845a7ea6\",\"venue\":\"CoRL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49461641\",\"name\":\"G. Li\"},{\"authorId\":\"153013284\",\"name\":\"M. M\\u00fcller\"},{\"authorId\":\"24026083\",\"name\":\"Vincent Casser\"},{\"authorId\":\"152406347\",\"name\":\"N. Smith\"},{\"authorId\":\"1872043\",\"name\":\"D. Michels\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4966198e5d61b9632ebcef77d51afdf57735ac0b\",\"title\":\"Teaching UAVs to Race With Observational Imitation Learning\",\"url\":\"https://www.semanticscholar.org/paper/4966198e5d61b9632ebcef77d51afdf57735ac0b\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1810.01108\",\"authors\":[{\"authorId\":\"34597365\",\"name\":\"Subhajit Chaudhury\"},{\"authorId\":\"40433860\",\"name\":\"Daiki Kimura\"},{\"authorId\":\"2908473\",\"name\":\"T. Pham\"},{\"authorId\":\"1688057\",\"name\":\"A. Munawar\"},{\"authorId\":\"34769239\",\"name\":\"Ryuki Tachibana\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3a0a0c52e5f9d84cd32df90d18f9998d5d61ac3c\",\"title\":\"Video Imitation GAN: Learning control policies by imitating raw videos using generative adversarial reward estimation\",\"url\":\"https://www.semanticscholar.org/paper/3a0a0c52e5f9d84cd32df90d18f9998d5d61ac3c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1904.03438\",\"authors\":[{\"authorId\":\"7912420\",\"name\":\"Konrad Zolna\"},{\"authorId\":\"2599281\",\"name\":\"N. Rostamzadeh\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"3103594\",\"name\":\"Sungjin Ahn\"},{\"authorId\":\"2708655\",\"name\":\"Pedro H. O. Pinheiro\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"226bf05765f706bc71f604679295d4df0970b0a7\",\"title\":\"Reinforced Imitation in Heterogeneous Action Space\",\"url\":\"https://www.semanticscholar.org/paper/226bf05765f706bc71f604679295d4df0970b0a7\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50025199\",\"name\":\"Yanhua Li\"},{\"authorId\":\"73268354\",\"name\":\"W. Huang\"}],\"doi\":\"10.1145/3356471.3365229\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aa2eea9fe8d224e2aaccccf5e020b4597301fa5b\",\"title\":\"Imitation Learning from Human-Generated Spatial-Temporal Data\",\"url\":\"https://www.semanticscholar.org/paper/aa2eea9fe8d224e2aaccccf5e020b4597301fa5b\",\"venue\":\"GeoAI@SIGSPATIAL\",\"year\":2019},{\"arxivId\":\"2006.05779\",\"authors\":[{\"authorId\":\"143625677\",\"name\":\"Xin Xin\"},{\"authorId\":\"1713164\",\"name\":\"Alexandros Karatzoglou\"},{\"authorId\":\"2646401\",\"name\":\"I. Arapakis\"},{\"authorId\":\"50686770\",\"name\":\"J. Jose\"}],\"doi\":\"10.1145/3397271.3401147\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8d26dc21338cbfa5f68944b6ec19f00b2229989c\",\"title\":\"Self-Supervised Reinforcement Learning for Recommender Systems\",\"url\":\"https://www.semanticscholar.org/paper/8d26dc21338cbfa5f68944b6ec19f00b2229989c\",\"venue\":\"SIGIR\",\"year\":2020},{\"arxivId\":\"1906.07374\",\"authors\":[{\"authorId\":\"46221670\",\"name\":\"F. Torabi\"},{\"authorId\":\"153552310\",\"name\":\"S. Geiger\"},{\"authorId\":\"1938253\",\"name\":\"Garrett Warnell\"},{\"authorId\":\"144848112\",\"name\":\"P. Stone\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d308dd89c1efb1e3b604fe79ce8ebefa564a4a9a\",\"title\":\"Sample-efficient Adversarial Imitation Learning from Observation\",\"url\":\"https://www.semanticscholar.org/paper/d308dd89c1efb1e3b604fe79ce8ebefa564a4a9a\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2002.12500\",\"authors\":[{\"authorId\":\"10978611\",\"name\":\"Akanksha Saran\"},{\"authorId\":\"2657185\",\"name\":\"Ruohan Zhang\"},{\"authorId\":\"32775309\",\"name\":\"Elaine Schaertl Short\"},{\"authorId\":\"2791038\",\"name\":\"S. Niekum\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a078029566d58c4efcef2b36523af794922cbf41\",\"title\":\"Efficiently Guiding Imitation Learning Algorithms with Human Gaze\",\"url\":\"https://www.semanticscholar.org/paper/a078029566d58c4efcef2b36523af794922cbf41\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47157162\",\"name\":\"Sili Huang\"},{\"authorId\":\"50699381\",\"name\":\"B. Yang\"},{\"authorId\":\"2721051\",\"name\":\"Hechang Chen\"},{\"authorId\":\"66711267\",\"name\":\"Haiyin Piao\"},{\"authorId\":\"46555018\",\"name\":\"Zhixiao Sun\"},{\"authorId\":\"46623784\",\"name\":\"Y. Chang\"}],\"doi\":\"10.1007/978-3-030-55393-7_1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ccaeae8a36af51057e747e1ec367d5578a1fe95f\",\"title\":\"MA-TREX: Mutli-agent Trajectory-Ranked Reward Extrapolation via Inverse Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/ccaeae8a36af51057e747e1ec367d5578a1fe95f\",\"venue\":\"KSEM\",\"year\":2020},{\"arxivId\":\"2008.05660\",\"authors\":[{\"authorId\":\"1660809827\",\"name\":\"Nathan Gavenski\"},{\"authorId\":\"40235962\",\"name\":\"J. Monteiro\"},{\"authorId\":\"3045512\",\"name\":\"R. Granada\"},{\"authorId\":\"2920773\",\"name\":\"Felipe Meneguzzi\"},{\"authorId\":\"143914916\",\"name\":\"Rodrigo C. Barros\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"adb871f048f5c7de72d2517b741ce998a61cfa2a\",\"title\":\"Imitating Unknown Policies via Exploration\",\"url\":\"https://www.semanticscholar.org/paper/adb871f048f5c7de72d2517b741ce998a61cfa2a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.03619\",\"authors\":[{\"authorId\":\"3439813\",\"name\":\"R. Trivedi\"},{\"authorId\":\"3021550\",\"name\":\"Jiachen Yang\"},{\"authorId\":\"145203884\",\"name\":\"H. Zha\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c82255f7dbe5555f9dc96bed6c6d4b256ccec081\",\"title\":\"GraphOpt: Learning Optimization Models of Graph Formation\",\"url\":\"https://www.semanticscholar.org/paper/c82255f7dbe5555f9dc96bed6c6d4b256ccec081\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":\"2007.05740\",\"authors\":[{\"authorId\":\"1810840208\",\"name\":\"Uppala Sumanth\"},{\"authorId\":\"52186859\",\"name\":\"Narinder Singh Punn\"},{\"authorId\":\"52133313\",\"name\":\"S. K. Sonbhadra\"},{\"authorId\":\"1807691917\",\"name\":\"Sonali Agarwal\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d4a5ddfbd67aa9a7d128445fbb0779a757086a69\",\"title\":\"Enhanced Behavioral Cloning Based self-driving Car Using Transfer Learning\",\"url\":\"https://www.semanticscholar.org/paper/d4a5ddfbd67aa9a7d128445fbb0779a757086a69\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41021998\",\"name\":\"Tianchi Huang\"},{\"authorId\":\"144623098\",\"name\":\"Chao Zhou\"},{\"authorId\":\"48263901\",\"name\":\"Rui-Xiao Zhang\"},{\"authorId\":\"33846296\",\"name\":\"Chenglei Wu\"},{\"authorId\":\"143901532\",\"name\":\"X. Yao\"},{\"authorId\":\"1812254\",\"name\":\"L. Sun\"}],\"doi\":\"10.1109/INFOCOM41043.2020.9155411\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8af583b22b2a27c3aac36ac0a6ae26eda21e5281\",\"title\":\"Stick: A Harmonious Fusion of Buffer-based and Learning-based Approach for Adaptive Streaming\",\"url\":\"https://www.semanticscholar.org/paper/8af583b22b2a27c3aac36ac0a6ae26eda21e5281\",\"venue\":\"IEEE INFOCOM 2020 - IEEE Conference on Computer Communications\",\"year\":2020},{\"arxivId\":\"2006.08051\",\"authors\":[{\"authorId\":\"152241734\",\"name\":\"Yuda Song\"},{\"authorId\":\"38792754\",\"name\":\"Aditi Mavalankar\"},{\"authorId\":\"22578070\",\"name\":\"W. Sun\"},{\"authorId\":\"39219411\",\"name\":\"Sicun Gao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b98f32429eecab610c0c150c111beb95af092d65\",\"title\":\"Provably Efficient Model-based Policy Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/b98f32429eecab610c0c150c111beb95af092d65\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30451228\",\"name\":\"Zhuangdi Zhu\"},{\"authorId\":\"143850177\",\"name\":\"Kaixiang Lin\"},{\"authorId\":\"144445929\",\"name\":\"Bo Dai\"},{\"authorId\":\"1922411503\",\"name\":\"Jiayu Zhou\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e99dd160c931425f485ada0d1bf13ab2d33f9685\",\"title\":\"Off-Policy Imitation Learning from Observations\",\"url\":\"https://www.semanticscholar.org/paper/e99dd160c931425f485ada0d1bf13ab2d33f9685\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2006.01494\",\"authors\":[{\"authorId\":\"88184611\",\"name\":\"Sung-ho Choi\"},{\"authorId\":\"3435623\",\"name\":\"Seungyul Han\"},{\"authorId\":\"7891343\",\"name\":\"Woojun Kim\"},{\"authorId\":\"9238685\",\"name\":\"Youngchul Sung\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"709422784b059294bb8546fe370e1f879bbbcd27\",\"title\":\"Cross-Domain Imitation Learning with a Dual Structure\",\"url\":\"https://www.semanticscholar.org/paper/709422784b059294bb8546fe370e1f879bbbcd27\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3457048\",\"name\":\"Soroush Nasiriany\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6f812978ce061b6c650ffd70ad3cf7dc3eef6003\",\"title\":\"DisCo RL: Distribution-Conditioned Reinforcement Learning for General-Purpose Policies\",\"url\":\"https://www.semanticscholar.org/paper/6f812978ce061b6c650ffd70ad3cf7dc3eef6003\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2008.01205\",\"authors\":[{\"authorId\":\"1854303398\",\"name\":\"Zachary W. Robertson\"},{\"authorId\":\"1733702\",\"name\":\"Matthew R. Walter\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a2960b4e2e455db5f7d661034afdb0da7dbdc20c\",\"title\":\"Concurrent Training Improves the Performance of Behavioral Cloning from Observation\",\"url\":\"https://www.semanticscholar.org/paper/a2960b4e2e455db5f7d661034afdb0da7dbdc20c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1905.12612\",\"authors\":[{\"authorId\":\"47311261\",\"name\":\"A. Kumar\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"8614a91589c4d851574f964ed7a76161591c80c7\",\"title\":\"Learning Navigation Subroutines by Watching Videos\",\"url\":\"https://www.semanticscholar.org/paper/8614a91589c4d851574f964ed7a76161591c80c7\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2008.07284\",\"authors\":[{\"authorId\":\"48026827\",\"name\":\"Eiji Uchibe\"},{\"authorId\":\"1714997\",\"name\":\"K. Doya\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"543ab481de60cb2e3a9b67128996d93c8dfac361\",\"title\":\"Imitation learning based on entropy-regularized forward and inverse reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/543ab481de60cb2e3a9b67128996d93c8dfac361\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19259914\",\"name\":\"Hanan Rosemarin\"},{\"authorId\":\"39890672\",\"name\":\"Ariel Rosenfeld\"}],\"doi\":\"10.1145/3349537.3351904\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"11211b1ebff4044f70a087cdec44e6d69368c3fc\",\"title\":\"Playing Chess at a Human Desired Level and Style\",\"url\":\"https://www.semanticscholar.org/paper/11211b1ebff4044f70a087cdec44e6d69368c3fc\",\"venue\":\"HAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49616225\",\"name\":\"Sujoy Paul\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c558c56245d4e5b3ba1cb3ba650cb6e7f4bd0cbc\",\"title\":\"Learning from Trajectories via Subgoal Discovery /Author=Paul, Sujoy; van Baar, Jeroen; Roy-Chowdhury, Amit K. /CreationDate=October 31, 2019 /Subject=Applied Physics, Computer Vision, Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/c558c56245d4e5b3ba1cb3ba650cb6e7f4bd0cbc\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1911.07224\",\"authors\":[{\"authorId\":\"49616225\",\"name\":\"Sujoy Paul\"},{\"authorId\":\"1751880\",\"name\":\"J. V. Baar\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6fcc8c61041b495c82d339d0cb17147bee2cf0e1\",\"title\":\"Learning from Trajectories via Subgoal Discovery\",\"url\":\"https://www.semanticscholar.org/paper/6fcc8c61041b495c82d339d0cb17147bee2cf0e1\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12646136\",\"name\":\"S. Curi\"},{\"authorId\":\"145413362\",\"name\":\"K. Y. Levy\"},{\"authorId\":\"49737028\",\"name\":\"A. Krause\"}],\"doi\":\"10.1109/CDC40024.2019.9029379\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4fed83001d3b712cec357a9ac5e090c308c4c457\",\"title\":\"Adaptive Input Estimation in Linear Dynamical Systems with Applications to Learning-from-Observations\",\"url\":\"https://www.semanticscholar.org/paper/4fed83001d3b712cec357a9ac5e090c308c4c457\",\"venue\":\"2019 IEEE 58th Conference on Decision and Control (CDC)\",\"year\":2019},{\"arxivId\":\"2011.06507\",\"authors\":[{\"authorId\":\"88726258\",\"name\":\"Karl Schmeckpeper\"},{\"authorId\":\"40900227\",\"name\":\"Oleh Rybkin\"},{\"authorId\":\"1751586\",\"name\":\"Kostas Daniilidis\"},{\"authorId\":\"1381906625\",\"name\":\"Sergey Levine\"},{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a9a83e5050f389606091ca1d38532ccfd832ff13\",\"title\":\"Reinforcement Learning with Videos: Combining Offline Observations with Interaction\",\"url\":\"https://www.semanticscholar.org/paper/a9a83e5050f389606091ca1d38532ccfd832ff13\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yeping Wang\"},{\"authorId\":\"65770075\",\"name\":\"G. Ajaykumar\"},{\"authorId\":\"2805730\",\"name\":\"Chien-Ming Huang\"}],\"doi\":\"10.1145/3319502.3374820\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9707757fd8bfb79def2853eaa4c7df0ac27330dc\",\"title\":\"See What I See: Enabling User-Centric Robotic Assistance Using First-Person Demonstrations\",\"url\":\"https://www.semanticscholar.org/paper/9707757fd8bfb79def2853eaa4c7df0ac27330dc\",\"venue\":\"HRI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3124110\",\"name\":\"Aldo Pacchiano\"},{\"authorId\":\"1410302742\",\"name\":\"Jack Parker-Holder\"},{\"authorId\":\"11501567\",\"name\":\"Yunhao Tang\"},{\"authorId\":\"3216141\",\"name\":\"A. Choromanska\"},{\"authorId\":\"1805203\",\"name\":\"Krzysztof Choromanski\"},{\"authorId\":\"1694621\",\"name\":\"Michael I. Jordan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5ce1303133d3702431eb7f291744dc92f47e22cb\",\"title\":\"Behavior-Guided Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/5ce1303133d3702431eb7f291744dc92f47e22cb\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2006.10034\",\"authors\":[{\"authorId\":\"48746899\",\"name\":\"M. Chang\"},{\"authorId\":\"48668934\",\"name\":\"Arjun Gupta\"},{\"authorId\":\"47924870\",\"name\":\"Saurabh Gupta\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3b0ebc4c21a74210b0abfcfaebb66e27f940b45f\",\"title\":\"Semantic Visual Navigation by Watching YouTube Videos\",\"url\":\"https://www.semanticscholar.org/paper/3b0ebc4c21a74210b0abfcfaebb66e27f940b45f\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2010.00581\",\"authors\":[{\"authorId\":\"1978097132\",\"name\":\"Kamal Ndousse\"},{\"authorId\":\"153329923\",\"name\":\"Douglas Eck\"},{\"authorId\":\"1381906625\",\"name\":\"Sergey Levine\"},{\"authorId\":\"3106683\",\"name\":\"N. Jaques\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e74fd1733c243684d9dc1a143d2a2db722fcfaf7\",\"title\":\"Multi-agent Social Reinforcement Learning Improves Generalization\",\"url\":\"https://www.semanticscholar.org/paper/e74fd1733c243684d9dc1a143d2a2db722fcfaf7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1810.05017\",\"authors\":[{\"authorId\":\"40470211\",\"name\":\"T. Paine\"},{\"authorId\":\"2016840\",\"name\":\"Sergio Gomez Colmenarejo\"},{\"authorId\":\"47197117\",\"name\":\"Ziyu Wang\"},{\"authorId\":\"144828948\",\"name\":\"S. Reed\"},{\"authorId\":\"3152281\",\"name\":\"Y. Aytar\"},{\"authorId\":\"2054956\",\"name\":\"T. Pfaff\"},{\"authorId\":\"3243579\",\"name\":\"M. W. Hoffman\"},{\"authorId\":\"1403998955\",\"name\":\"Gabriel Barth-Maron\"},{\"authorId\":\"12159303\",\"name\":\"Serkan Cabi\"},{\"authorId\":\"2508525\",\"name\":\"D. Budden\"},{\"authorId\":\"1737568\",\"name\":\"N. D. Freitas\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"776f3d2250285ac03b2019ecf18668fcdd72a9ce\",\"title\":\"One-Shot High-Fidelity Imitation: Training Large-Scale Deep Nets with RL\",\"url\":\"https://www.semanticscholar.org/paper/776f3d2250285ac03b2019ecf18668fcdd72a9ce\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2010.12488\",\"authors\":[{\"authorId\":\"2966240\",\"name\":\"Jianren Wang\"},{\"authorId\":\"152244621\",\"name\":\"Y. Lu\"},{\"authorId\":\"47940821\",\"name\":\"Hang Zhao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f0b0466117964e95a28ca695cebcf05f4573c4cd\",\"title\":\"CLOUD: Contrastive Learning of Unsupervised Dynamics\",\"url\":\"https://www.semanticscholar.org/paper/f0b0466117964e95a28ca695cebcf05f4573c4cd\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.11723\",\"authors\":[{\"authorId\":\"46308406\",\"name\":\"Letian Chen\"},{\"authorId\":\"83862731\",\"name\":\"Rohan R. Paleja\"},{\"authorId\":\"145223968\",\"name\":\"M. Gombolay\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6ea51765310c28627ff53d82c85ccb24e336180a\",\"title\":\"Learning from Suboptimal Demonstration via Self-Supervised Reward Regression\",\"url\":\"https://www.semanticscholar.org/paper/6ea51765310c28627ff53d82c85ccb24e336180a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.07078\",\"authors\":[{\"authorId\":\"1395309619\",\"name\":\"Andreas Look\"},{\"authorId\":\"66922581\",\"name\":\"Simona Doneva\"},{\"authorId\":\"11213556\",\"name\":\"M. Kandemir\"},{\"authorId\":\"1777107\",\"name\":\"Rainer Gemulla\"},{\"authorId\":\"145197867\",\"name\":\"Jan Peters\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"889dc098882e6eca9d9510ec09c5ca4e36753952\",\"title\":\"Differentiable Implicit Layers\",\"url\":\"https://www.semanticscholar.org/paper/889dc098882e6eca9d9510ec09c5ca4e36753952\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.07027\",\"authors\":[{\"authorId\":\"31032101\",\"name\":\"T. Xu\"},{\"authorId\":\"25841722\",\"name\":\"Ziniu Li\"},{\"authorId\":\"47111821\",\"name\":\"Yang Yu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"35c9c0f3fde0f398420e95cc709b37042dcddc5d\",\"title\":\"On Value Discrepancy of Imitation Learning\",\"url\":\"https://www.semanticscholar.org/paper/35c9c0f3fde0f398420e95cc709b37042dcddc5d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32161209\",\"name\":\"Thomas R. Hinrichs\"},{\"authorId\":\"1713121\",\"name\":\"Kenneth D. Forbus\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d7bacceb4e1f365ccedd314941281ba423aa072\",\"title\":\"Experimentation in a Model-Based Game\",\"url\":\"https://www.semanticscholar.org/paper/0d7bacceb4e1f365ccedd314941281ba423aa072\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9099731\",\"name\":\"Q. Shao\"},{\"authorId\":\"143802133\",\"name\":\"J. Hu\"},{\"authorId\":\"39899748\",\"name\":\"Weiming Wang\"},{\"authorId\":\"47291418\",\"name\":\"Yi Fang\"},{\"authorId\":\"134404450\",\"name\":\"Mingshuo Han\"},{\"authorId\":\"2432679\",\"name\":\"J. Qi\"},{\"authorId\":\"143974413\",\"name\":\"J. Ma\"}],\"doi\":\"10.2991/ijcis.d.191017.001\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"691bf656a923ab05fcdaa74bbf8c4096968e6895\",\"title\":\"Composable Instructions and Prospection Guided Visuomotor Control for Robotic Manipulation\",\"url\":\"https://www.semanticscholar.org/paper/691bf656a923ab05fcdaa74bbf8c4096968e6895\",\"venue\":\"Int. J. Comput. Intell. Syst.\",\"year\":2019},{\"arxivId\":\"1904.06387\",\"authors\":[{\"authorId\":\"47627548\",\"name\":\"Daniel S. Brown\"},{\"authorId\":\"3461969\",\"name\":\"Wonjoon Goo\"},{\"authorId\":\"40608791\",\"name\":\"P. Nagarajan\"},{\"authorId\":\"2791038\",\"name\":\"S. Niekum\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2fc328f3702d6f8730235b1b3ddf7cc5fc096c0d\",\"title\":\"Extrapolating Beyond Suboptimal Demonstrations via Inverse Reinforcement Learning from Observations\",\"url\":\"https://www.semanticscholar.org/paper/2fc328f3702d6f8730235b1b3ddf7cc5fc096c0d\",\"venue\":\"ICML\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"114603956\",\"name\":\"Felipe Leno Da Silva\"},{\"authorId\":\"1938253\",\"name\":\"Garrett Warnell\"},{\"authorId\":\"2209202\",\"name\":\"A. Costa\"},{\"authorId\":\"144848112\",\"name\":\"P. Stone\"}],\"doi\":\"10.1007/s10458-019-09430-0\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f3a5d43feed53f5e0c92d50be4bb2d5008254d88\",\"title\":\"Agents teaching agents: a survey on inter-agent transfer learning\",\"url\":\"https://www.semanticscholar.org/paper/f3a5d43feed53f5e0c92d50be4bb2d5008254d88\",\"venue\":\"Autonomous Agents and Multi-Agent Systems\",\"year\":2019},{\"arxivId\":\"1806.07377\",\"authors\":[{\"authorId\":\"50986630\",\"name\":\"Shani Gamrian\"},{\"authorId\":\"2089067\",\"name\":\"Y. Goldberg\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0d38284025bd0eabf92399b35df189ae1e034236\",\"title\":\"Transfer Learning for Related Reinforcement Learning Tasks via Image-to-Image Translation\",\"url\":\"https://www.semanticscholar.org/paper/0d38284025bd0eabf92399b35df189ae1e034236\",\"venue\":\"ICML\",\"year\":2019},{\"arxivId\":\"2008.01594\",\"authors\":[{\"authorId\":\"1859450821\",\"name\":\"Siddarth Desai\"},{\"authorId\":\"9571638\",\"name\":\"Ishan Durugkar\"},{\"authorId\":\"27636362\",\"name\":\"Haresh Karnan\"},{\"authorId\":\"1938253\",\"name\":\"Garrett Warnell\"},{\"authorId\":\"34719248\",\"name\":\"Josiah P. Hanna\"},{\"authorId\":\"144848112\",\"name\":\"P. Stone\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ef368de0433a0e4e6bfc9499fbcf655f203d06c7\",\"title\":\"An Imitation from Observation Approach to Transfer Learning with Dynamics Mismatch\",\"url\":\"https://www.semanticscholar.org/paper/ef368de0433a0e4e6bfc9499fbcf655f203d06c7\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2011.05970\",\"authors\":[{\"authorId\":\"36076404\",\"name\":\"Sudeep Dasari\"},{\"authorId\":\"1726095131\",\"name\":\"Abhinav Gupta\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8d0eeb8aee3ce93c9c04f0662ee058e8eefee6bf\",\"title\":\"Transformers for One-Shot Visual Imitation\",\"url\":\"https://www.semanticscholar.org/paper/8d0eeb8aee3ce93c9c04f0662ee058e8eefee6bf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1910.04417\",\"authors\":[{\"authorId\":\"143702931\",\"name\":\"C. Yang\"},{\"authorId\":\"121875989\",\"name\":\"Xiaojian Ma\"},{\"authorId\":\"123175679\",\"name\":\"W. Huang\"},{\"authorId\":\"143823065\",\"name\":\"F. Sun\"},{\"authorId\":\"145433219\",\"name\":\"Huaping Liu\"},{\"authorId\":\"1768190\",\"name\":\"J. Huang\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b6a479e39218a381c9911df24583058c4f283890\",\"title\":\"Imitation Learning from Observations by Minimizing Inverse Dynamics Disagreement\",\"url\":\"https://www.semanticscholar.org/paper/b6a479e39218a381c9911df24583058c4f283890\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1901.07186\",\"authors\":[{\"authorId\":\"2994035\",\"name\":\"G. Berseth\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6690f99cf643550d0568fc251e12628a2f162844\",\"title\":\"Visual Imitation Learning with Recurrent Siamese Networks\",\"url\":\"https://www.semanticscholar.org/paper/6690f99cf643550d0568fc251e12628a2f162844\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1905.10948\",\"authors\":[{\"authorId\":\"144426657\",\"name\":\"Wen Sun\"},{\"authorId\":\"2387189\",\"name\":\"Anirudh Vemula\"},{\"authorId\":\"3288815\",\"name\":\"B. Boots\"},{\"authorId\":\"1756566\",\"name\":\"J. Bagnell\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6e81e3b82c875063dca2aee551aa5d50cc3c69cc\",\"title\":\"Provably Efficient Imitation Learning from Observation Alone\",\"url\":\"https://www.semanticscholar.org/paper/6e81e3b82c875063dca2aee551aa5d50cc3c69cc\",\"venue\":\"ICML\",\"year\":2019},{\"arxivId\":\"1905.12888\",\"authors\":[{\"authorId\":\"3383717\",\"name\":\"Liyiming Ke\"},{\"authorId\":\"38418010\",\"name\":\"M. Barnes\"},{\"authorId\":\"144284282\",\"name\":\"W. Sun\"},{\"authorId\":\"2604352\",\"name\":\"Gilwoo Lee\"},{\"authorId\":\"2487768\",\"name\":\"S. Choudhury\"},{\"authorId\":\"1752197\",\"name\":\"S. Srinivasa\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e9df90537887631964e36beb44b1c341089b8688\",\"title\":\"Imitation Learning as f-Divergence Minimization\",\"url\":\"https://www.semanticscholar.org/paper/e9df90537887631964e36beb44b1c341089b8688\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1806.07200\",\"authors\":[{\"authorId\":\"12646136\",\"name\":\"Sebastian Curi\"},{\"authorId\":\"2886057\",\"name\":\"Kfir Y. Levy\"},{\"authorId\":\"145343838\",\"name\":\"Andreas Krause\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c1a14da6e8b1c8c8ae2db73b94598eaf7c5d59af\",\"title\":\"Unsupervised Imitation Learning\",\"url\":\"https://www.semanticscholar.org/paper/c1a14da6e8b1c8c8ae2db73b94598eaf7c5d59af\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2002.12446\",\"authors\":[{\"authorId\":\"40576688\",\"name\":\"Aaron Zweig\"},{\"authorId\":\"143627859\",\"name\":\"Joan Bruna\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7ce8f4a5ab555afb18e54cfc760de9d1080044e6\",\"title\":\"Provably Efficient Third-Person Imitation from Offline Observation\",\"url\":\"https://www.semanticscholar.org/paper/7ce8f4a5ab555afb18e54cfc760de9d1080044e6\",\"venue\":\"UAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143727953\",\"name\":\"A. Wu\"},{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1007/s11263-019-01238-5\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"879a6970d46e6a22f45875f404e067148dcd326c\",\"title\":\"Model-Based Robot Imitation with Future Image Similarity\",\"url\":\"https://www.semanticscholar.org/paper/879a6970d46e6a22f45875f404e067148dcd326c\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"2006.04678\",\"authors\":[{\"authorId\":\"51914693\",\"name\":\"Robert Dadashi\"},{\"authorId\":\"122562941\",\"name\":\"L'eonard Hussenot\"},{\"authorId\":\"50675536\",\"name\":\"M. Geist\"},{\"authorId\":\"79608109\",\"name\":\"O. Pietquin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"25287b593d2642b1627b96a79c5ff8d3c8ec1f5c\",\"title\":\"Primal Wasserstein Imitation Learning\",\"url\":\"https://www.semanticscholar.org/paper/25287b593d2642b1627b96a79c5ff8d3c8ec1f5c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.08353\",\"authors\":[{\"authorId\":\"6592040\",\"name\":\"Zhihao Cheng\"},{\"authorId\":\"144117135\",\"name\":\"L. Liu\"},{\"authorId\":\"153152072\",\"name\":\"Aishan Liu\"},{\"authorId\":\"144990601\",\"name\":\"Hao Sun\"},{\"authorId\":\"39829184\",\"name\":\"Meng Fang\"},{\"authorId\":\"145047838\",\"name\":\"Dacheng Tao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4aaecb73259a939ea1f2e088f5a937a1a4791349\",\"title\":\"On the Guaranteed Almost Equivalence between Imitation Learning from Observation and Demonstration\",\"url\":\"https://www.semanticscholar.org/paper/4aaecb73259a939ea1f2e088f5a937a1a4791349\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1912.04472\",\"authors\":[{\"authorId\":\"47627548\",\"name\":\"Daniel S. Brown\"},{\"authorId\":\"2791038\",\"name\":\"S. Niekum\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"04f788ea49e7fbd55369fbfa0945c53dd40c9d3b\",\"title\":\"Deep Bayesian Reward Learning from Preferences\",\"url\":\"https://www.semanticscholar.org/paper/04f788ea49e7fbd55369fbfa0945c53dd40c9d3b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47998541\",\"name\":\"Garrett Hall\"},{\"authorId\":\"152781458\",\"name\":\"A. Das\"},{\"authorId\":\"1698407\",\"name\":\"J. Quarles\"},{\"authorId\":\"88123959\",\"name\":\"P. Rad\"}],\"doi\":\"10.1109/ICTAI50040.2020.00077\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f743994c915932d7485343a3b630f1dd10259ca8\",\"title\":\"Studying Adversarial Attacks on Behavioral Cloning Dynamics\",\"url\":\"https://www.semanticscholar.org/paper/f743994c915932d7485343a3b630f1dd10259ca8\",\"venue\":\"2020 IEEE 32nd International Conference on Tools with Artificial Intelligence (ICTAI)\",\"year\":2020},{\"arxivId\":\"1909.02918\",\"authors\":[{\"authorId\":\"10995114\",\"name\":\"Y. Zhao\"},{\"authorId\":\"47473421\",\"name\":\"Ilia Shumailov\"},{\"authorId\":\"49378318\",\"name\":\"Han Cui\"},{\"authorId\":\"2047625\",\"name\":\"Xitong Gao\"},{\"authorId\":\"144883246\",\"name\":\"Robert Mullins\"},{\"authorId\":\"121732142\",\"name\":\"R. Anderson\"}],\"doi\":\"10.1109/DSN-W50199.2020.00013\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"30e5e70738cf3c453e31fcb8db6d43dfdb0d7f73\",\"title\":\"Blackbox Attacks on Reinforcement Learning Agents Using Approximated Temporal Information\",\"url\":\"https://www.semanticscholar.org/paper/30e5e70738cf3c453e31fcb8db6d43dfdb0d7f73\",\"venue\":\"2020 50th Annual IEEE/IFIP International Conference on Dependable Systems and Networks Workshops (DSN-W)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3212040\",\"name\":\"Jinchul Choi\"},{\"authorId\":\"143949303\",\"name\":\"H. Kim\"},{\"authorId\":\"97815851\",\"name\":\"Youngsung Son\"},{\"authorId\":\"30474554\",\"name\":\"Chan-Won Park\"},{\"authorId\":\"50001725\",\"name\":\"J. Park\"}],\"doi\":\"10.1109/ICTC49870.2020.9289148\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6252d3c6f648f3204606b9c5c6e8fb284db176c5\",\"title\":\"Robotic Behavioral Cloning Through Task Building\",\"url\":\"https://www.semanticscholar.org/paper/6252d3c6f648f3204606b9c5c6e8fb284db176c5\",\"venue\":\"2020 International Conference on Information and Communication Technology Convergence (ICTC)\",\"year\":2020},{\"arxivId\":\"1905.07861\",\"authors\":[{\"authorId\":\"48779623\",\"name\":\"A. Edwards\"},{\"authorId\":\"1787816\",\"name\":\"C. Isbell\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7b7762973f445fc3e8c15be2f09a5c2da5197e9f\",\"title\":\"Perceptual Values from Observation\",\"url\":\"https://www.semanticscholar.org/paper/7b7762973f445fc3e8c15be2f09a5c2da5197e9f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46221670\",\"name\":\"F. Torabi\"},{\"authorId\":\"1938253\",\"name\":\"Garrett Warnell\"},{\"authorId\":\"144848112\",\"name\":\"P. Stone\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"92bfa173e091c0340497fb8c1143a1df3c6f1dfd\",\"title\":\"Adversarial Imitation Learning from State-only Demonstrations\",\"url\":\"https://www.semanticscholar.org/paper/92bfa173e091c0340497fb8c1143a1df3c6f1dfd\",\"venue\":\"AAMAS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40087656\",\"name\":\"Chong Huang\"},{\"authorId\":\"3889808\",\"name\":\"Chuan-en Lin\"},{\"authorId\":\"47087303\",\"name\":\"Zhenyu Yang\"},{\"authorId\":\"145131477\",\"name\":\"Y. Kong\"},{\"authorId\":\"144886788\",\"name\":\"Peng Chen\"},{\"authorId\":\"50031413\",\"name\":\"X. Yang\"},{\"authorId\":\"143766349\",\"name\":\"K. Cheng\"}],\"doi\":\"10.1109/CVPR.2019.00437\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6cdb91adf87f404cbbedecb0234eac6a78f5598c\",\"title\":\"Learning to Film From Professional Human Motion Videos\",\"url\":\"https://www.semanticscholar.org/paper/6cdb91adf87f404cbbedecb0234eac6a78f5598c\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1805.07914\",\"authors\":[{\"authorId\":\"48779623\",\"name\":\"A. Edwards\"},{\"authorId\":\"34594615\",\"name\":\"Himanshu Sahni\"},{\"authorId\":\"3403061\",\"name\":\"Yannick Schroecker\"},{\"authorId\":\"1787816\",\"name\":\"C. Isbell\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"395ea8a62d84c8dd85a8dadfc3043cf2228e38c5\",\"title\":\"Imitating Latent Policies from Observation\",\"url\":\"https://www.semanticscholar.org/paper/395ea8a62d84c8dd85a8dadfc3043cf2228e38c5\",\"venue\":\"ICML\",\"year\":2019},{\"arxivId\":\"1904.09162\",\"authors\":[{\"authorId\":\"143688700\",\"name\":\"Tong Mu\"},{\"authorId\":\"1822288\",\"name\":\"Karan Goel\"},{\"authorId\":\"2563117\",\"name\":\"Emma Brunskill\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"3af4bf4c1bc05b029b05d333a4b963594727de4f\",\"title\":\"PLOTS: Procedure Learning from Observations using Subtask Structure\",\"url\":\"https://www.semanticscholar.org/paper/3af4bf4c1bc05b029b05d333a4b963594727de4f\",\"venue\":\"AAMAS\",\"year\":2019},{\"arxivId\":\"2004.04650\",\"authors\":[{\"authorId\":\"30407997\",\"name\":\"Ilija Radosavovic\"},{\"authorId\":\"39635018\",\"name\":\"Xiaolong Wang\"},{\"authorId\":\"34026610\",\"name\":\"Lerrel Pinto\"},{\"authorId\":\"153652147\",\"name\":\"J. Malik\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"df06c6519e5cecece13ce7b1457478bcfdf1ed21\",\"title\":\"State-Only Imitation Learning for Dexterous Manipulation\",\"url\":\"https://www.semanticscholar.org/paper/df06c6519e5cecece13ce7b1457478bcfdf1ed21\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66360707\",\"name\":\"Roy Chowdhury\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a3a8861363fdfbd6a0792fdffb64517e366fea01\",\"title\":\"Learning from Trajectories via Subgoal Discovery /Author=Paul, S.; van Baar, J.; Roy Chowdhury, A.K. /CreationDate=October 31, 2019 /Subject=Applied Physics, Computer Vision, Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/a3a8861363fdfbd6a0792fdffb64517e366fea01\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"148389028\",\"name\":\"Youssef Fenjiro\"},{\"authorId\":\"1795133\",\"name\":\"H. Benbrahim\"}],\"doi\":\"10.18280/ria.330402\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"644d2e89022ca9f67175c0529f6a88fefb97648c\",\"title\":\"Optimal Combination of Imitation and Reinforcement Learning for Self-driving Cars\",\"url\":\"https://www.semanticscholar.org/paper/644d2e89022ca9f67175c0529f6a88fefb97648c\",\"venue\":\"Rev. d'Intelligence Artif.\",\"year\":2019},{\"arxivId\":\"1812.10613\",\"authors\":[{\"authorId\":\"66273798\",\"name\":\"Xinshi Chen\"},{\"authorId\":\"31023698\",\"name\":\"S. Li\"},{\"authorId\":\"47892853\",\"name\":\"H. Li\"},{\"authorId\":\"50559009\",\"name\":\"S. Jiang\"},{\"authorId\":\"40612590\",\"name\":\"Yuan Qi\"},{\"authorId\":\"1779453\",\"name\":\"L. Song\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"16481307a862ddae514045b13b944ca043c36a4b\",\"title\":\"Generative Adversarial User Model for Reinforcement Learning Based Recommendation System\",\"url\":\"https://www.semanticscholar.org/paper/16481307a862ddae514045b13b944ca043c36a4b\",\"venue\":\"ICML\",\"year\":2019},{\"arxivId\":\"1905.12310\",\"authors\":[{\"authorId\":\"9492808\",\"name\":\"M. Sun\"},{\"authorId\":\"3230330\",\"name\":\"Xiaojuan Ma\"}],\"doi\":\"10.24963/ijcai.2019/487\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e402ae3e5db859e45960b32419bd511c56d06152\",\"title\":\"Adversarial Imitation Learning from Incomplete Demonstrations\",\"url\":\"https://www.semanticscholar.org/paper/e402ae3e5db859e45960b32419bd511c56d06152\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"1803.01129\",\"authors\":[{\"authorId\":\"49461641\",\"name\":\"G. Li\"},{\"authorId\":\"153013284\",\"name\":\"M. M\\u00fcller\"},{\"authorId\":\"24026083\",\"name\":\"Vincent Casser\"},{\"authorId\":\"14240165\",\"name\":\"N. Smith\"},{\"authorId\":\"1872043\",\"name\":\"D. Michels\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.15607/RSS.2019.XV.005\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"14129144de50c216551843b76b16a9e9273c0f6e\",\"title\":\"OIL: Observational Imitation Learning\",\"url\":\"https://www.semanticscholar.org/paper/14129144de50c216551843b76b16a9e9273c0f6e\",\"venue\":\"Robotics: Science and Systems\",\"year\":2019},{\"arxivId\":\"2010.11876\",\"authors\":[{\"authorId\":\"145020314\",\"name\":\"T. Xu\"},{\"authorId\":\"25841722\",\"name\":\"Ziniu Li\"},{\"authorId\":\"144705629\",\"name\":\"Yang Yu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"83551ac1e6358182a2c0f2ec223fb3c6f736c8e1\",\"title\":\"Error Bounds of Imitating Policies and Environments\",\"url\":\"https://www.semanticscholar.org/paper/83551ac1e6358182a2c0f2ec223fb3c6f736c8e1\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"1912.05510\",\"authors\":[{\"authorId\":\"2994035\",\"name\":\"G. Berseth\"},{\"authorId\":\"1381359648\",\"name\":\"Daniel Geng\"},{\"authorId\":\"144373380\",\"name\":\"C. Devin\"},{\"authorId\":\"1974383\",\"name\":\"Nicholas Rhinehart\"},{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"},{\"authorId\":\"144348441\",\"name\":\"Dinesh Jayaraman\"},{\"authorId\":\"1381906625\",\"name\":\"Sergey Levine\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3b75418223d5e55a51695a6527c9dd27da095334\",\"title\":\"SMiRL: Surprise Minimizing Reinforcement Learning in Dynamic Environments\",\"url\":\"https://www.semanticscholar.org/paper/3b75418223d5e55a51695a6527c9dd27da095334\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1905.07089\",\"authors\":[{\"authorId\":\"144815077\",\"name\":\"Y. Gong\"},{\"authorId\":\"5141829\",\"name\":\"Y. Zhu\"},{\"authorId\":\"143720825\",\"name\":\"L. Duan\"},{\"authorId\":\"7360511\",\"name\":\"Qingwen Liu\"},{\"authorId\":\"1749272\",\"name\":\"Ziyu Guan\"},{\"authorId\":\"143770118\",\"name\":\"Fei Sun\"},{\"authorId\":\"10336865\",\"name\":\"Wenwu Ou\"},{\"authorId\":\"1796651\",\"name\":\"K. Q. Zhu\"}],\"doi\":\"10.1145/3292500.3330832\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"98f65707cdadaaa2d2dc127d6b3fc6d3b68bf03b\",\"title\":\"Exact-K Recommendation via Maximal Clique Optimization\",\"url\":\"https://www.semanticscholar.org/paper/98f65707cdadaaa2d2dc127d6b3fc6d3b68bf03b\",\"venue\":\"KDD\",\"year\":2019},{\"arxivId\":\"2009.05990\",\"authors\":[{\"authorId\":\"1922080064\",\"name\":\"Nived Rajaraman\"},{\"authorId\":\"40577530\",\"name\":\"Lin F. Yang\"},{\"authorId\":\"2784735\",\"name\":\"J. Jiao\"},{\"authorId\":\"144489804\",\"name\":\"K. Ramachandran\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e5624daed3f2e59be0f90c83e5bf622e69962fef\",\"title\":\"Toward the Fundamental Limits of Imitation Learning\",\"url\":\"https://www.semanticscholar.org/paper/e5624daed3f2e59be0f90c83e5bf622e69962fef\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"1907.05634\",\"authors\":[{\"authorId\":\"3027555\",\"name\":\"Yuping Luo\"},{\"authorId\":\"3286703\",\"name\":\"Huazhe Xu\"},{\"authorId\":\"1901958\",\"name\":\"Tengyu Ma\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bc32aab2970d62a097cee080c8bbd25837a5443b\",\"title\":\"Learning Self-Correctable Policies and Value Functions from Demonstrations with Negative Sampling\",\"url\":\"https://www.semanticscholar.org/paper/bc32aab2970d62a097cee080c8bbd25837a5443b\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"2006.03312\",\"authors\":[{\"authorId\":\"1410212708\",\"name\":\"Raphael Dang-Nhu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"568361dfdf2534bd08edef34c295142fa5c7fd81\",\"title\":\"PLANS: Robust Program Learning from Neurally Inferred Specifications\",\"url\":\"https://www.semanticscholar.org/paper/568361dfdf2534bd08edef34c295142fa5c7fd81\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.09505\",\"authors\":[{\"authorId\":\"48779623\",\"name\":\"A. Edwards\"},{\"authorId\":\"34594615\",\"name\":\"Himanshu Sahni\"},{\"authorId\":\"48757909\",\"name\":\"Rosanne Liu\"},{\"authorId\":\"40220343\",\"name\":\"Jane Hung\"},{\"authorId\":\"49148138\",\"name\":\"Ankit Jain\"},{\"authorId\":\"51262130\",\"name\":\"Rui Wang\"},{\"authorId\":\"66821245\",\"name\":\"Adrien Ecoffet\"},{\"authorId\":\"1934321\",\"name\":\"Thomas Miconi\"},{\"authorId\":\"1787816\",\"name\":\"C. Isbell\"},{\"authorId\":\"2965424\",\"name\":\"J. Yosinski\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6426a3f15b90f4777877f3db49db54db0509c0ba\",\"title\":\"Estimating Q(s, s') with Deep Deterministic Dynamics Gradients\",\"url\":\"https://www.semanticscholar.org/paper/6426a3f15b90f4777877f3db49db54db0509c0ba\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":\"1903.04110\",\"authors\":[{\"authorId\":\"1955964\",\"name\":\"Xiaoxiao Guo\"},{\"authorId\":\"3307026\",\"name\":\"S. Chang\"},{\"authorId\":\"2482533\",\"name\":\"Mo Yu\"},{\"authorId\":\"1699108\",\"name\":\"G. Tesauro\"},{\"authorId\":\"143903370\",\"name\":\"Murray Campbell\"}],\"doi\":\"10.1609/AAAI.V33I01.33013739\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"15704ce8121737e3eb109a210d4b72e2fe1a0ad7\",\"title\":\"Hybrid Reinforcement Learning with Expert State Sequences\",\"url\":\"https://www.semanticscholar.org/paper/15704ce8121737e3eb109a210d4b72e2fe1a0ad7\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1907.03976\",\"authors\":[{\"authorId\":\"50649827\",\"name\":\"D. Brown\"},{\"authorId\":\"3461969\",\"name\":\"Wonjoon Goo\"},{\"authorId\":\"2791038\",\"name\":\"S. Niekum\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9bdd9a40fa31cd44377404b58adb9ac36b396ab8\",\"title\":\"Ranking-Based Reward Extrapolation without Rankings\",\"url\":\"https://www.semanticscholar.org/paper/9bdd9a40fa31cd44377404b58adb9ac36b396ab8\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1912.12773\",\"authors\":[{\"authorId\":\"88726258\",\"name\":\"Karl Schmeckpeper\"},{\"authorId\":\"14484808\",\"name\":\"Annie Xie\"},{\"authorId\":\"40900227\",\"name\":\"Oleh Rybkin\"},{\"authorId\":\"71692259\",\"name\":\"Stephen Tian\"},{\"authorId\":\"1751586\",\"name\":\"Kostas Daniilidis\"},{\"authorId\":\"1381906625\",\"name\":\"Sergey Levine\"},{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"}],\"doi\":\"10.1007/978-3-030-58565-5_42\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"124ec2c95bc0fe417be2bb0d0701f88583d6a16a\",\"title\":\"Learning Predictive Models From Observation and Interaction\",\"url\":\"https://www.semanticscholar.org/paper/124ec2c95bc0fe417be2bb0d0701f88583d6a16a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1910.03157\",\"authors\":[{\"authorId\":\"46840646\",\"name\":\"A. Wu\"},{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b8e35eb21a69178aba00205073d34ec9b2ee499c\",\"title\":\"Model-based Behavioral Cloning with Future Image Similarity Learning\",\"url\":\"https://www.semanticscholar.org/paper/b8e35eb21a69178aba00205073d34ec9b2ee499c\",\"venue\":\"CoRL\",\"year\":2019},{\"arxivId\":\"2011.10274\",\"authors\":[{\"authorId\":\"2028598063\",\"name\":\"Maxime Pietrantoni\"},{\"authorId\":\"1729294\",\"name\":\"Boris Chidlovskii\"},{\"authorId\":\"1759936\",\"name\":\"T. Silander\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d65b67c8716384ae3adbbcf97c6a6d2ef578b3a\",\"title\":\"Learning Synthetic to Real Transfer for Localization and Navigational Tasks\",\"url\":\"https://www.semanticscholar.org/paper/9d65b67c8716384ae3adbbcf97c6a6d2ef578b3a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.00820\",\"authors\":[{\"authorId\":\"3438717\",\"name\":\"S. Azam\"},{\"authorId\":\"2904550\",\"name\":\"F. Munir\"},{\"authorId\":\"51194242\",\"name\":\"Muhammad Aasim Rafique\"},{\"authorId\":\"40590857\",\"name\":\"Ahmad Muqeem Sheri\"},{\"authorId\":\"67196224\",\"name\":\"Muhammad Ishfaq Hussain\"},{\"authorId\":\"2184044\",\"name\":\"Moongu Jeon\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e0a3d0907aad29ad62cb0d798e4b27531dcecfb6\",\"title\":\"N 2 C : Neural Network Controller Design Using Behavioral Cloning\",\"url\":\"https://www.semanticscholar.org/paper/e0a3d0907aad29ad62cb0d798e4b27531dcecfb6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.13529\",\"authors\":[{\"authorId\":\"40235962\",\"name\":\"J. Monteiro\"},{\"authorId\":\"1660809827\",\"name\":\"Nathan Gavenski\"},{\"authorId\":\"3045512\",\"name\":\"R. Granada\"},{\"authorId\":\"2920773\",\"name\":\"Felipe Meneguzzi\"},{\"authorId\":\"1380051745\",\"name\":\"Rodrigo C. Barros\"}],\"doi\":\"10.1109/IJCNN48605.2020.9207672\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1cc12fe047e4d54577c11c6bc8acebffa07a26b5\",\"title\":\"Augmented Behavioral Cloning from Observation\",\"url\":\"https://www.semanticscholar.org/paper/1cc12fe047e4d54577c11c6bc8acebffa07a26b5\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":\"2002.10544\",\"authors\":[{\"authorId\":\"145563459\",\"name\":\"S. Arora\"},{\"authorId\":\"30718820\",\"name\":\"S. S. Du\"},{\"authorId\":\"144695232\",\"name\":\"Sham M. Kakade\"},{\"authorId\":\"1491625903\",\"name\":\"Yuping Luo\"},{\"authorId\":\"10769461\",\"name\":\"Nikunj Saunshi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"14a4bd317880f6763bd2b53de28d93a37eabd10d\",\"title\":\"Provable Representation Learning for Imitation Learning via Bi-level Optimization\",\"url\":\"https://www.semanticscholar.org/paper/14a4bd317880f6763bd2b53de28d93a37eabd10d\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":\"2010.00581\",\"authors\":[{\"authorId\":\"1978097132\",\"name\":\"Kamal Ndousse\"},{\"authorId\":\"153329923\",\"name\":\"Douglas Eck\"},{\"authorId\":\"1381906625\",\"name\":\"Sergey Levine\"},{\"authorId\":\"3106683\",\"name\":\"N. Jaques\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1019d362e9efedd8440a7fd3f58a8f71d2bd476e\",\"title\":\"Learning Social Learning.\",\"url\":\"https://www.semanticscholar.org/paper/1019d362e9efedd8440a7fd3f58a8f71d2bd476e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1910.00738\",\"authors\":[{\"authorId\":\"144941289\",\"name\":\"G. Qiao\"},{\"authorId\":\"3450095\",\"name\":\"H. Zhou\"},{\"authorId\":\"1379758006\",\"name\":\"Mubbasir Kapadia\"},{\"authorId\":\"2244969\",\"name\":\"Sejong Yoon\"},{\"authorId\":\"144658464\",\"name\":\"V. Pavlovic\"}],\"doi\":\"10.1145/3359566.3360087\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b735f40d233cd3607f46b04ac5c353f1b7abb5fc\",\"title\":\"Scenario Generalization of Data-driven Imitation Models in Crowd Simulation\",\"url\":\"https://www.semanticscholar.org/paper/b735f40d233cd3607f46b04ac5c353f1b7abb5fc\",\"venue\":\"MIG\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3390081\",\"name\":\"Felipe Leno Da Silva\"},{\"authorId\":\"1729426820\",\"name\":\"F. C. D. Silva\"},{\"authorId\":\"1938253\",\"name\":\"Garrett Warnell\"},{\"authorId\":\"2209202\",\"name\":\"A. Costa\"},{\"authorId\":\"144848112\",\"name\":\"P. Stone\"}],\"doi\":\"10.26153/TSW/8400\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bc4f6d0a27a60aa7c2c8db2dd3f814b3a5d2f907\",\"title\":\"Agents teaching agents: a survey on inter-agent transfer learning\",\"url\":\"https://www.semanticscholar.org/paper/bc4f6d0a27a60aa7c2c8db2dd3f814b3a5d2f907\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2008.01156\",\"authors\":[{\"authorId\":\"145841847\",\"name\":\"Michael Burke\"},{\"authorId\":\"2740413\",\"name\":\"K. Subr\"},{\"authorId\":\"47172195\",\"name\":\"S. Ramamoorthy\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"164458a07d7f33b5b3c7a7b3c2ce24b89c371911\",\"title\":\"Action sequencing using visual permutations\",\"url\":\"https://www.semanticscholar.org/paper/164458a07d7f33b5b3c7a7b3c2ce24b89c371911\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3194013\",\"name\":\"W. Wei\"},{\"authorId\":\"47775744\",\"name\":\"Liyang Xu\"},{\"authorId\":\"1500379518\",\"name\":\"Minglong Li\"},{\"authorId\":\"38221234\",\"name\":\"Xiaodong Yi\"},{\"authorId\":\"3261878\",\"name\":\"Yuhua Tang\"}],\"doi\":\"10.1109/ISCID.2019.10090\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bfb4970d045a25972629ef9ba428f0b4626e29d7\",\"title\":\"Optimizing High-dimensional Learner with Low-Dimension Action Features\",\"url\":\"https://www.semanticscholar.org/paper/bfb4970d045a25972629ef9ba428f0b4626e29d7\",\"venue\":\"2019 12th International Symposium on Computational Intelligence and Design (ISCID)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47072066\",\"name\":\"W. Ge\"},{\"authorId\":\"46864847\",\"name\":\"Weiwei Shang\"},{\"authorId\":\"6043189\",\"name\":\"Fangjing Song\"},{\"authorId\":\"1910937\",\"name\":\"Hongjian Sui\"},{\"authorId\":\"145250251\",\"name\":\"S. Cong\"}],\"doi\":\"10.1007/978-981-13-7983-3_42\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8081ebb262f9803b6d6be2ffabbb5f7be810839e\",\"title\":\"Robust and High-Precision End-to-End Control Policy for Multi-stage Manipulation Task with Behavioral Cloning\",\"url\":\"https://www.semanticscholar.org/paper/8081ebb262f9803b6d6be2ffabbb5f7be810839e\",\"venue\":\"ICCSIP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2994035\",\"name\":\"G. Berseth\"},{\"authorId\":\"1381359648\",\"name\":\"Daniel Geng\"},{\"authorId\":\"144373380\",\"name\":\"C. Devin\"},{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"},{\"authorId\":\"144348441\",\"name\":\"Dinesh Jayaraman\"},{\"authorId\":\"1381906625\",\"name\":\"Sergey Levine\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ce441c4bb6c13a50182d10ff13ae4bdaf15bf955\",\"title\":\"SMiRL: Surprise Minimizing RL in Dynamic Environments\",\"url\":\"https://www.semanticscholar.org/paper/ce441c4bb6c13a50182d10ff13ae4bdaf15bf955\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2007.11646\",\"authors\":[{\"authorId\":\"1819841658\",\"name\":\"Yifang Liu\"},{\"authorId\":\"2777349\",\"name\":\"Diego Romeres\"},{\"authorId\":\"2743474\",\"name\":\"Devesh K. Jha\"},{\"authorId\":\"2965906\",\"name\":\"D. Nikovski\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6949efeec0a5a34fd1ccf32a0209becf4a806e9a\",\"title\":\"Understanding Multi-Modal Perception Using Behavioral Cloning for Peg-In-a-Hole Insertion Tasks\",\"url\":\"https://www.semanticscholar.org/paper/6949efeec0a5a34fd1ccf32a0209becf4a806e9a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145050960\",\"name\":\"F. Silva\"},{\"authorId\":\"2209202\",\"name\":\"A. Costa\"},{\"authorId\":\"144848112\",\"name\":\"P. Stone\"}],\"doi\":\"10.1109/BRACIS.2019.00090\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"91eabf58179071b24322b40bf68cab7e4a0adb22\",\"title\":\"Building Self-Play Curricula Online by Playing with Expert Agents in Adversarial Games\",\"url\":\"https://www.semanticscholar.org/paper/91eabf58179071b24322b40bf68cab7e4a0adb22\",\"venue\":\"2019 8th Brazilian Conference on Intelligent Systems (BRACIS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33808086\",\"name\":\"J. Wong\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a9f34d64c356e9dcffcb36f36fe7e2f76e22cadb\",\"title\":\"Learning Internal State Memory Representations from Observation\",\"url\":\"https://www.semanticscholar.org/paper/a9f34d64c356e9dcffcb36f36fe7e2f76e22cadb\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50714149\",\"name\":\"G. Hyde\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"aa98c6f51a2bf58ab031c8209364c958c69d7d8e\",\"title\":\"Modeling user behavior to construct counter strategies\",\"url\":\"https://www.semanticscholar.org/paper/aa98c6f51a2bf58ab031c8209364c958c69d7d8e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2010.01748\",\"authors\":[{\"authorId\":\"71563016\",\"name\":\"Jingkang Wang\"},{\"authorId\":\"15836216\",\"name\":\"Hong-Yi Guo\"},{\"authorId\":\"49658780\",\"name\":\"Zhaowei Zhu\"},{\"authorId\":\"1614035413\",\"name\":\"Yang Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fae0366593f579f76ebb89439330a12ea9b9f291\",\"title\":\"Policy Learning Using Weak Supervision\",\"url\":\"https://www.semanticscholar.org/paper/fae0366593f579f76ebb89439330a12ea9b9f291\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1713814\",\"name\":\"Bin Fang\"},{\"authorId\":\"11590609\",\"name\":\"S. Jia\"},{\"authorId\":\"66147945\",\"name\":\"Di Guo\"},{\"authorId\":\"1387797308\",\"name\":\"Muhua Xu\"},{\"authorId\":\"1383072346\",\"name\":\"Shuhuan Wen\"},{\"authorId\":\"143823065\",\"name\":\"F. Sun\"}],\"doi\":\"10.1007/s41315-019-00103-5\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"10befc15a8887b279f2509eba9b6ece0034543fe\",\"title\":\"Survey of imitation learning for robotic manipulation\",\"url\":\"https://www.semanticscholar.org/paper/10befc15a8887b279f2509eba9b6ece0034543fe\",\"venue\":\"International Journal of Intelligent Robotics and Applications\",\"year\":2019},{\"arxivId\":\"1909.09906\",\"authors\":[{\"authorId\":\"2657185\",\"name\":\"Ruohan Zhang\"},{\"authorId\":\"46221670\",\"name\":\"F. Torabi\"},{\"authorId\":\"144190085\",\"name\":\"L. Guan\"},{\"authorId\":\"1691804\",\"name\":\"D. Ballard\"},{\"authorId\":\"144848112\",\"name\":\"P. Stone\"}],\"doi\":\"10.24963/ijcai.2019/884\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9bd453ea1e4655311cb1172f7a188cb9c5ee367d\",\"title\":\"Leveraging Human Guidance for Deep Reinforcement Learning Tasks\",\"url\":\"https://www.semanticscholar.org/paper/9bd453ea1e4655311cb1172f7a188cb9c5ee367d\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"2002.09676\",\"authors\":[{\"authorId\":\"151206404\",\"name\":\"Siddhant Gangapurwala\"},{\"authorId\":\"145652453\",\"name\":\"A. Mitchell\"},{\"authorId\":\"48735502\",\"name\":\"I. Havoutis\"}],\"doi\":\"10.1109/LRA.2020.2979656\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e537143dd60294eb6b38dd7965860e5f7a52cc5f\",\"title\":\"Guided Constrained Policy Optimization for Dynamic Quadrupedal Robot Locomotion\",\"url\":\"https://www.semanticscholar.org/paper/e537143dd60294eb6b38dd7965860e5f7a52cc5f\",\"venue\":\"IEEE Robotics and Automation Letters\",\"year\":2020},{\"arxivId\":\"2011.01046\",\"authors\":[{\"authorId\":\"1572143646\",\"name\":\"Nan Lin\"},{\"authorId\":\"1995232380\",\"name\":\"Yuxuan Li\"},{\"authorId\":\"1470786653\",\"name\":\"Yujun Zhu\"},{\"authorId\":\"121357290\",\"name\":\"Ruolin Wang\"},{\"authorId\":\"93045609\",\"name\":\"Xiayu Zhang\"},{\"authorId\":\"39574278\",\"name\":\"Jianmin Ji\"},{\"authorId\":\"144994529\",\"name\":\"Keke Tang\"},{\"authorId\":\"49697607\",\"name\":\"Xiaoping Chen\"},{\"authorId\":\"1666343721\",\"name\":\"Xinming Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8bae173deaa5f785447686ac59245a929874cb27\",\"title\":\"NEARL: Non-Explicit Action Reinforcement Learning for Robotic Control\",\"url\":\"https://www.semanticscholar.org/paper/8bae173deaa5f785447686ac59245a929874cb27\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1903.01973\",\"authors\":[{\"authorId\":\"32245472\",\"name\":\"Corey Lynch\"},{\"authorId\":\"30559411\",\"name\":\"Mohi Khansari\"},{\"authorId\":\"9961095\",\"name\":\"Ted Xiao\"},{\"authorId\":\"48021747\",\"name\":\"V. Kumar\"},{\"authorId\":\"2704494\",\"name\":\"J. Tompson\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"},{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c5bbfacb581666afadc46b50917b9859d057417e\",\"title\":\"Learning Latent Plans from Play\",\"url\":\"https://www.semanticscholar.org/paper/c5bbfacb581666afadc46b50917b9859d057417e\",\"venue\":\"CoRL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51039185\",\"name\":\"Maximilian Sieb\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"72a49660561810cd9362ab5a3e7eb6e5882ea797\",\"title\":\"Visual Imitation Learning for Robot Manipulation\",\"url\":\"https://www.semanticscholar.org/paper/72a49660561810cd9362ab5a3e7eb6e5882ea797\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152782062\",\"name\":\"Xin-Qiang Cai\"},{\"authorId\":\"22424919\",\"name\":\"Yao-Xiang Ding\"},{\"authorId\":\"2192443\",\"name\":\"Yuan Jiang\"},{\"authorId\":\"145624000\",\"name\":\"Zhi-Hua Zhou\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9fd69b5eeee945c12ff8efde85a6fe8be34d784f\",\"title\":\"Expert-Level Atari Imitation Learning from Demonstrations Only\",\"url\":\"https://www.semanticscholar.org/paper/9fd69b5eeee945c12ff8efde85a6fe8be34d784f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1911.10947\",\"authors\":[{\"authorId\":\"32324034\",\"name\":\"Fangchen Liu\"},{\"authorId\":\"49706114\",\"name\":\"Z. Ling\"},{\"authorId\":\"3431352\",\"name\":\"Tongzhou Mu\"},{\"authorId\":\"71309570\",\"name\":\"H. Su\"}],\"doi\":null,\"intent\":[\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"1c1081922f849ced90745a5bb699ad0a93625be4\",\"title\":\"State Alignment-based Imitation Learning\",\"url\":\"https://www.semanticscholar.org/paper/1c1081922f849ced90745a5bb699ad0a93625be4\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"2012.02458\",\"authors\":[{\"authorId\":\"2511738\",\"name\":\"H. Hashempour\"},{\"authorId\":\"1994524417\",\"name\":\"Kiyanoush Nazari\"},{\"authorId\":\"3385027\",\"name\":\"Fangxun Zhong\"},{\"authorId\":\"1994430721\",\"name\":\"Ghalamzan E. Amir\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c60e64a061ea3da7a3da405d3a00665ed401d47f\",\"title\":\"A data-set of piercing needle through deformable objects for Deep Learning from Demonstrations\",\"url\":\"https://www.semanticscholar.org/paper/c60e64a061ea3da7a3da405d3a00665ed401d47f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47627548\",\"name\":\"Daniel S. Brown\"},{\"authorId\":\"3461969\",\"name\":\"Wonjoon Goo\"},{\"authorId\":\"2791038\",\"name\":\"S. Niekum\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9e13129b14166291892ce0b3a0ee90c02dc7625f\",\"title\":\"Better-than-Demonstrator Imitation Learning via Automatically-Ranked Demonstrations\",\"url\":\"https://www.semanticscholar.org/paper/9e13129b14166291892ce0b3a0ee90c02dc7625f\",\"venue\":\"CoRL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1859450821\",\"name\":\"Siddarth Desai\"},{\"authorId\":\"9571638\",\"name\":\"Ishan Durugkar\"},{\"authorId\":\"27636362\",\"name\":\"Haresh Karnan\"},{\"authorId\":\"1938253\",\"name\":\"Garrett Warnell\"},{\"authorId\":\"35362968\",\"name\":\"Josiah Hanna\"},{\"authorId\":\"144848112\",\"name\":\"P. Stone\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2d38e7f9164efb65d7af52b8642817ed6e8bf530\",\"title\":\"An Imitation from Observation Approach to Sim-to-Real Transfer\",\"url\":\"https://www.semanticscholar.org/paper/2d38e7f9164efb65d7af52b8642817ed6e8bf530\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51489141\",\"name\":\"Omid Mohaddesi\"},{\"authorId\":\"1516447176\",\"name\":\"Tiago Machado\"},{\"authorId\":\"152698947\",\"name\":\"Casper Harteveld\"}],\"doi\":\"10.1145/3334480.3382996\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0529da203d9e05ddccfdd11daa5d18f988ee453f\",\"title\":\"Learning from Gamettes: Imitating Human Behavior in Supply Chain Decisions\",\"url\":\"https://www.semanticscholar.org/paper/0529da203d9e05ddccfdd11daa5d18f988ee453f\",\"venue\":\"CHI Extended Abstracts\",\"year\":2020},{\"arxivId\":\"1912.04443\",\"authors\":[{\"authorId\":\"152447364\",\"name\":\"L. Smith\"},{\"authorId\":\"80009435\",\"name\":\"Nikita Dhawan\"},{\"authorId\":\"2634261\",\"name\":\"Marvin Zhang\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"},{\"authorId\":\"152198491\",\"name\":\"Sergey Levine\"}],\"doi\":\"10.15607/rss.2020.xvi.024\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"465c4fe8e4e4d43cfc89802a76b99bbcaaaa565d\",\"title\":\"AVID: Learning Multi-Stage Tasks via Pixel-Level Translation of Human Videos\",\"url\":\"https://www.semanticscholar.org/paper/465c4fe8e4e4d43cfc89802a76b99bbcaaaa565d\",\"venue\":\"RSS 2020\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"122699890\",\"name\":\"Thuy-Trang Vu\"},{\"authorId\":\"153699253\",\"name\":\"M. Liu\"},{\"authorId\":\"1749657\",\"name\":\"Dinh Q. Phung\"},{\"authorId\":\"2561045\",\"name\":\"Gholamreza Haffari\"}],\"doi\":\"10.18653/v1/P19-1401\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cd618944fa87f52f01d919facd392986a582dbb7\",\"title\":\"Learning How to Active Learn by Dreaming\",\"url\":\"https://www.semanticscholar.org/paper/cd618944fa87f52f01d919facd392986a582dbb7\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1806.01267\",\"authors\":[{\"authorId\":\"40433860\",\"name\":\"Daiki Kimura\"},{\"authorId\":\"34597365\",\"name\":\"Subhajit Chaudhury\"},{\"authorId\":\"34769239\",\"name\":\"Ryuki Tachibana\"},{\"authorId\":\"40206154\",\"name\":\"Sakyasingha Dasgupta\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"470d6f5f5578729d816763f835d6d51c6a536589\",\"title\":\"Internal Model from Observations for Reward Shaping\",\"url\":\"https://www.semanticscholar.org/paper/470d6f5f5578729d816763f835d6d51c6a536589\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46221670\",\"name\":\"Faraz Torabi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ff4a37378515d26b8221e0d6380f984d14e9b7f8\",\"title\":\"Adversarial Imitation Learning from State-only Demonstrations \\u2217 Extended Abstract\",\"url\":\"https://www.semanticscholar.org/paper/ff4a37378515d26b8221e0d6380f984d14e9b7f8\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3124110\",\"name\":\"Aldo Pacchiano\"},{\"authorId\":\"79328311\",\"name\":\"Jack Parker-Holder\"},{\"authorId\":\"11501567\",\"name\":\"Yunhao Tang\"},{\"authorId\":\"3216141\",\"name\":\"Anna Choromanska\"},{\"authorId\":\"1805203\",\"name\":\"Krzysztof Choromanski\"},{\"authorId\":\"1694621\",\"name\":\"Michael I. Jordan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3627d3404cd6c7b0412bb06545aec67bf4c049f7\",\"title\":\"Wasserstein Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/3627d3404cd6c7b0412bb06545aec67bf4c049f7\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2750745\",\"name\":\"Brian Broll\"},{\"authorId\":\"3308897\",\"name\":\"Matthew J. Hausknecht\"},{\"authorId\":\"50438830\",\"name\":\"D. Bignell\"},{\"authorId\":\"40261572\",\"name\":\"A. Swaminathan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ebb1c62c355e40de7be950f2863a613ea3ba7cee\",\"title\":\"Customizing Scripted Bots: Sample Efficient Imitation Learning for Human-like Behavior in Minecraft\",\"url\":\"https://www.semanticscholar.org/paper/ebb1c62c355e40de7be950f2863a613ea3ba7cee\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2002.11879\",\"authors\":[{\"authorId\":\"3366663\",\"name\":\"Tanmay Gangwani\"},{\"authorId\":\"2388660\",\"name\":\"J. Peng\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"34601270eb6274c5331c634be82f701ef394eacf\",\"title\":\"State-only Imitation with Transition Dynamics Mismatch\",\"url\":\"https://www.semanticscholar.org/paper/34601270eb6274c5331c634be82f701ef394eacf\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"2006.10810\",\"authors\":[{\"authorId\":\"34544888\",\"name\":\"Dilip Arumugam\"},{\"authorId\":\"1780951\",\"name\":\"Debadeepta Dey\"},{\"authorId\":\"40333747\",\"name\":\"A. Agarwal\"},{\"authorId\":\"1709797\",\"name\":\"A. \\u00c7elikyilmaz\"},{\"authorId\":\"17013440\",\"name\":\"E. Nouri\"},{\"authorId\":\"83415753\",\"name\":\"W. Dolan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"850490fd3667efeb70e053c565b4a16be9057b97\",\"title\":\"Reparameterized Variational Divergence Minimization for Stable Imitation\",\"url\":\"https://www.semanticscholar.org/paper/850490fd3667efeb70e053c565b4a16be9057b97\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1907.03146\",\"authors\":[{\"authorId\":\"1785853\",\"name\":\"Oliver Kroemer\"},{\"authorId\":\"2791038\",\"name\":\"S. Niekum\"},{\"authorId\":\"1765407\",\"name\":\"G. Konidaris\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f33ae3a6f47ff3897a7ff12c6a0bacec2223d6d6\",\"title\":\"A Review of Robot Learning for Manipulation: Challenges, Representations, and Algorithms\",\"url\":\"https://www.semanticscholar.org/paper/f33ae3a6f47ff3897a7ff12c6a0bacec2223d6d6\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41020222\",\"name\":\"Tsu-Jui Fu\"},{\"authorId\":\"3229899\",\"name\":\"Yuta Tsuboi\"},{\"authorId\":\"144142812\",\"name\":\"Yuta Kikuchi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2ae7bb3b5ded27f58ee04e46305f6d855c16570a\",\"title\":\"Learning from Observation-Only Demonstration for Task-Oriented Language Grounding via Self-Examination\",\"url\":\"https://www.semanticscholar.org/paper/2ae7bb3b5ded27f58ee04e46305f6d855c16570a\",\"venue\":\"ViGIL@NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"David S. Hippocampus\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ce10405e7a1b312447832a60e345076fd53de17c\",\"title\":\"A Simple Imitation Learning Method via Contrastive Regularization\",\"url\":\"https://www.semanticscholar.org/paper/ce10405e7a1b312447832a60e345076fd53de17c\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1905.13566\",\"authors\":[{\"authorId\":\"46221670\",\"name\":\"F. Torabi\"},{\"authorId\":\"1938253\",\"name\":\"Garrett Warnell\"},{\"authorId\":\"144848112\",\"name\":\"P. Stone\"}],\"doi\":\"10.24963/ijcai.2019/882\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cbcbdb44d9d4ad7bb6bf4e9104653aa7623a17c5\",\"title\":\"Recent Advances in Imitation Learning from Observation\",\"url\":\"https://www.semanticscholar.org/paper/cbcbdb44d9d4ad7bb6bf4e9104653aa7623a17c5\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"2008.13193\",\"authors\":[{\"authorId\":null,\"name\":\"Yue Fan\"},{\"authorId\":\"1915870012\",\"name\":\"Shilei Chu\"},{\"authorId\":\"39664510\",\"name\":\"W. Zhang\"},{\"authorId\":\"48968697\",\"name\":\"R. Song\"},{\"authorId\":\"9348561\",\"name\":\"Yibin Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"65dcea0f1ab9e6ba52b30c0847d387858cefd52c\",\"title\":\"Learn by Observation: Imitation Learning for Drone Patrolling from Videos of A Human Navigator\",\"url\":\"https://www.semanticscholar.org/paper/65dcea0f1ab9e6ba52b30c0847d387858cefd52c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.00401\",\"authors\":[{\"authorId\":\"22192824\",\"name\":\"Sam Toyer\"},{\"authorId\":\"40947489\",\"name\":\"Rohin Shah\"},{\"authorId\":\"2651789\",\"name\":\"Andrew Critch\"},{\"authorId\":\"1715793514\",\"name\":\"Stuart Russell\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e0acae87ae6d1d14bb2852aad7d645fceee87eb2\",\"title\":\"The MAGICAL Benchmark for Robust Imitation\",\"url\":\"https://www.semanticscholar.org/paper/e0acae87ae6d1d14bb2852aad7d645fceee87eb2\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2007.04938\",\"authors\":[{\"authorId\":\"3436470\",\"name\":\"Kimin Lee\"},{\"authorId\":\"51093256\",\"name\":\"M. Laskin\"},{\"authorId\":\"41207614\",\"name\":\"A. Srinivas\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e74d7b47f475e81f882fce84e4287261171d0bb0\",\"title\":\"SUNRISE: A Simple Unified Framework for Ensemble Learning in Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/e74d7b47f475e81f882fce84e4287261171d0bb0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1809.02925\",\"authors\":[{\"authorId\":\"2000906\",\"name\":\"Ilya Kostrikov\"},{\"authorId\":\"6565766\",\"name\":\"Kumar Krishna Agrawal\"},{\"authorId\":\"2420123\",\"name\":\"D. Dwibedi\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"},{\"authorId\":\"2704494\",\"name\":\"J. Tompson\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1de1e749668a65cf6b88b8138389581108bb129a\",\"title\":\"Discriminator-Actor-Critic: Addressing Sample Inefficiency and Reward Bias in Adversarial Imitation Learning\",\"url\":\"https://www.semanticscholar.org/paper/1de1e749668a65cf6b88b8138389581108bb129a\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1805.11592\",\"authors\":[{\"authorId\":\"3152281\",\"name\":\"Y. Aytar\"},{\"authorId\":\"2054956\",\"name\":\"T. Pfaff\"},{\"authorId\":\"2508525\",\"name\":\"D. Budden\"},{\"authorId\":\"145757542\",\"name\":\"T. Paine\"},{\"authorId\":\"47197117\",\"name\":\"Ziyu Wang\"},{\"authorId\":\"1737568\",\"name\":\"N. D. Freitas\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"705bbc4dcd475f9230863771da6596e1f677a92d\",\"title\":\"Playing hard exploration games by watching YouTube\",\"url\":\"https://www.semanticscholar.org/paper/705bbc4dcd475f9230863771da6596e1f677a92d\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"101594813\",\"name\":\"J. Zhang\"},{\"authorId\":\"150358813\",\"name\":\"Z. Yu\"},{\"authorId\":\"145536401\",\"name\":\"S. Mao\"},{\"authorId\":\"148114268\",\"name\":\"S. C. Periaswamy\"},{\"authorId\":\"49732601\",\"name\":\"J. Patton\"},{\"authorId\":\"46392801\",\"name\":\"X. Xia\"}],\"doi\":\"10.1109/ACCESS.2020.2997304\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e7ab3bce41c9526ff85b580c18664da486fbd4de\",\"title\":\"IADRL: Imitation Augmented Deep Reinforcement Learning Enabled UGV-UAV Coalition for Tasking in Complex Environments\",\"url\":\"https://www.semanticscholar.org/paper/e7ab3bce41c9526ff85b580c18664da486fbd4de\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1906.07372\",\"authors\":[{\"authorId\":\"137071348\",\"name\":\"Brahma S. Pavse\"},{\"authorId\":\"46221670\",\"name\":\"F. Torabi\"},{\"authorId\":\"34719248\",\"name\":\"Josiah P. Hanna\"},{\"authorId\":\"1938253\",\"name\":\"Garrett Warnell\"},{\"authorId\":\"144848112\",\"name\":\"P. Stone\"}],\"doi\":\"10.1109/LRA.2020.3010750\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fff2bcc0348dffdb7661640d51738d4716a6304c\",\"title\":\"RIDM: Reinforced Inverse Dynamics Modeling for Learning from a Single Observed Demonstration\",\"url\":\"https://www.semanticscholar.org/paper/fff2bcc0348dffdb7661640d51738d4716a6304c\",\"venue\":\"IEEE Robotics and Automation Letters\",\"year\":2020},{\"arxivId\":\"1904.03295\",\"authors\":[{\"authorId\":\"9571638\",\"name\":\"Ishan Durugkar\"},{\"authorId\":\"3308897\",\"name\":\"Matthew J. Hausknecht\"},{\"authorId\":\"40261572\",\"name\":\"A. Swaminathan\"},{\"authorId\":\"3135801\",\"name\":\"Patrick MacAlpine\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3a6705ca23f01d0a115e70cc6b9a36f9b071556c\",\"title\":\"Multi-Preference Actor Critic\",\"url\":\"https://www.semanticscholar.org/paper/3a6705ca23f01d0a115e70cc6b9a36f9b071556c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46221670\",\"name\":\"F. Torabi\"}],\"doi\":\"10.1609/aaai.v33i01.33019900\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"22159c39871129b86118e8c7ec8b9bcc8bee0f5f\",\"title\":\"Imitation Learning from Observation\",\"url\":\"https://www.semanticscholar.org/paper/22159c39871129b86118e8c7ec8b9bcc8bee0f5f\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1912.08444\",\"authors\":[{\"authorId\":\"51430494\",\"name\":\"Lionel Blond\\u00e9\"},{\"authorId\":\"34312504\",\"name\":\"Y. Tang\"},{\"authorId\":\"81337717\",\"name\":\"Jia-yu Zhang\"},{\"authorId\":\"51138986\",\"name\":\"R. Webb\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"553a304f3c46a71f1f43beb60aa573b5deaf803c\",\"title\":\"Relational Mimic for Visual Adversarial Imitation Learning\",\"url\":\"https://www.semanticscholar.org/paper/553a304f3c46a71f1f43beb60aa573b5deaf803c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1905.10985\",\"authors\":[{\"authorId\":\"2552141\",\"name\":\"J. Clune\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8c7bb0db448bf54cf0af6ef38db5e63402ce72bd\",\"title\":\"AI-GAs: AI-generating algorithms, an alternate paradigm for producing general artificial intelligence\",\"url\":\"https://www.semanticscholar.org/paper/8c7bb0db448bf54cf0af6ef38db5e63402ce72bd\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9433338\",\"name\":\"Wanxin Jin\"},{\"authorId\":\"2750574\",\"name\":\"T. Murphey\"},{\"authorId\":\"1768765\",\"name\":\"Dana Kulic\"},{\"authorId\":\"39670581\",\"name\":\"Neta Ezer\"},{\"authorId\":\"1891624\",\"name\":\"S. Mou\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c76f111815c09893d66a586012b07e0f09d61c3d\",\"title\":\"Learning from Sparse Demonstrations\",\"url\":\"https://www.semanticscholar.org/paper/c76f111815c09893d66a586012b07e0f09d61c3d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1807.06158\",\"authors\":[{\"authorId\":\"46221670\",\"name\":\"F. Torabi\"},{\"authorId\":\"1938253\",\"name\":\"Garrett Warnell\"},{\"authorId\":\"144848112\",\"name\":\"P. Stone\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1f1f8330cddf1f4bf7bd73478223e5c02b69a1ff\",\"title\":\"Generative Adversarial Imitation from Observation\",\"url\":\"https://www.semanticscholar.org/paper/1f1f8330cddf1f4bf7bd73478223e5c02b69a1ff\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2009.09467\",\"authors\":[{\"authorId\":\"108199753\",\"name\":\"R. Jena\"},{\"authorId\":\"144612438\",\"name\":\"S. Agrawal\"},{\"authorId\":\"9076478\",\"name\":\"K. Sycara\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a51cebcee14c702e9c1c73e44eae138ef9572c45\",\"title\":\"Addressing reward bias in Adversarial Imitation Learning with neutral reward functions\",\"url\":\"https://www.semanticscholar.org/paper/a51cebcee14c702e9c1c73e44eae138ef9572c45\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66273798\",\"name\":\"Xinshi Chen\"},{\"authorId\":null,\"name\":\"Shuang Li\"},{\"authorId\":null,\"name\":\"Hui Li\"},{\"authorId\":\"47536806\",\"name\":\"Shaohua Jiang\"},{\"authorId\":\"40612590\",\"name\":\"Yuan Qi\"},{\"authorId\":\"1779453\",\"name\":\"L. Song\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e80a21069f3a551cb7832d0cf8262821f5f422ea\",\"title\":\"Neural Model-Based Reinforcement Learning for Recommendation\",\"url\":\"https://www.semanticscholar.org/paper/e80a21069f3a551cb7832d0cf8262821f5f422ea\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yang Gao\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3be26bc9dfa1b83c0484e91c2b8145f1bdb8e22d\",\"title\":\"End to End Learning in Autonomous Driving Systems\",\"url\":\"https://www.semanticscholar.org/paper/3be26bc9dfa1b83c0484e91c2b8145f1bdb8e22d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2001.06940\",\"authors\":[{\"authorId\":\"40223874\",\"name\":\"Philippe Morere\"},{\"authorId\":\"9928241\",\"name\":\"G. Francis\"},{\"authorId\":\"67156778\",\"name\":\"Tom Blau\"},{\"authorId\":\"153279354\",\"name\":\"Fabio Ramos\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2f9d13cbb9bc01b3261f8ff6afbace923eefa341\",\"title\":\"Reinforcement Learning with Probabilistically Complete Exploration\",\"url\":\"https://www.semanticscholar.org/paper/2f9d13cbb9bc01b3261f8ff6afbace923eefa341\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.00524\",\"authors\":[{\"authorId\":\"1850663626\",\"name\":\"Snehal Jauhri\"},{\"authorId\":\"1973021\",\"name\":\"Carlos Celemin\"},{\"authorId\":\"49153781\",\"name\":\"J. Kober\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"41a2906e393d16f301794f05001d457980fc5ba2\",\"title\":\"Interactive Imitation Learning in State-Space\",\"url\":\"https://www.semanticscholar.org/paper/41a2906e393d16f301794f05001d457980fc5ba2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.13205\",\"authors\":[{\"authorId\":\"31719101\",\"name\":\"Karl Pertsch\"},{\"authorId\":\"40900227\",\"name\":\"Oleh Rybkin\"},{\"authorId\":\"27535721\",\"name\":\"Frederik Ebert\"},{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"},{\"authorId\":\"144348441\",\"name\":\"Dinesh Jayaraman\"},{\"authorId\":\"152198491\",\"name\":\"Sergey Levine\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8dd3ec3ca1b7400d998e747356d07763a7ac1fb0\",\"title\":\"Long-Horizon Visual Planning with Goal-Conditioned Hierarchical Predictors\",\"url\":\"https://www.semanticscholar.org/paper/8dd3ec3ca1b7400d998e747356d07763a7ac1fb0\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2011.02671\",\"authors\":[{\"authorId\":\"153318704\",\"name\":\"Shanqi Liu\"},{\"authorId\":\"39767243\",\"name\":\"Junjie Cao\"},{\"authorId\":\"4592594\",\"name\":\"Wenzhou Chen\"},{\"authorId\":\"153109152\",\"name\":\"Licheng Wen\"},{\"authorId\":\"93006732\",\"name\":\"Y. Liu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3f6625a5720d20b211674e6e0046fe86b0aecbaf\",\"title\":\"HILONet: Hierarchical Imitation Learning from Non-Aligned Observations\",\"url\":\"https://www.semanticscholar.org/paper/3f6625a5720d20b211674e6e0046fe86b0aecbaf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.00545\",\"authors\":[{\"authorId\":\"39132551\",\"name\":\"A. Tanwani\"},{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"},{\"authorId\":\"2942754\",\"name\":\"A. Yan\"},{\"authorId\":\"1661031197\",\"name\":\"Raghav Anand\"},{\"authorId\":\"2482400\",\"name\":\"Mariano Phielipp\"},{\"authorId\":\"144344283\",\"name\":\"Ken Goldberg\"}],\"doi\":\"10.1109/ICRA40945.2020.9197324\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"affed45fa3f054c4819fe42f03983f3a83c0bd96\",\"title\":\"Motion2Vec: Semi-Supervised Representation Learning from Surgical Videos\",\"url\":\"https://www.semanticscholar.org/paper/affed45fa3f054c4819fe42f03983f3a83c0bd96\",\"venue\":\"2020 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2020},{\"arxivId\":\"2011.13467\",\"authors\":[{\"authorId\":\"46512864\",\"name\":\"Tianhong Dai\"},{\"authorId\":\"11028732\",\"name\":\"Hengyan Liu\"},{\"authorId\":\"2815535\",\"name\":\"A. Bharath\"}],\"doi\":\"10.3390/electronics9101742\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a15d706d3ceed54466b25fe8c75136249991c4d3\",\"title\":\"Episodic Self-Imitation Learning with Hindsight\",\"url\":\"https://www.semanticscholar.org/paper/a15d706d3ceed54466b25fe8c75136249991c4d3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2431463\",\"name\":\"Changjae Oh\"},{\"authorId\":\"143796134\",\"name\":\"A. Cavallaro\"}],\"doi\":\"10.1109/ICRA.2019.8794401\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e739403b08e22f4846e17fe8b2a1a9eb7b568d62\",\"title\":\"Learning Action Representations for Self-supervised Visual Exploration\",\"url\":\"https://www.semanticscholar.org/paper/e739403b08e22f4846e17fe8b2a1a9eb7b568d62\",\"venue\":\"2019 International Conference on Robotics and Automation (ICRA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145902797\",\"name\":\"B. Banerjee\"},{\"authorId\":\"148120358\",\"name\":\"Sneha Racharla\"}],\"doi\":\"10.1017/S0269888920000387\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7cc2371871eaa5e3a510e588361bf4a4602867ed\",\"title\":\"Human Agent Transfer from Observations\",\"url\":\"https://www.semanticscholar.org/paper/7cc2371871eaa5e3a510e588361bf4a4602867ed\",\"venue\":\"\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151212414\",\"name\":\"Simon Lindst\\u00e5hl\"},{\"authorId\":\"1975153\",\"name\":\"Xiaoyu Lan\"}],\"doi\":\"10.1109/aim43001.2020.9158839\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1504edc2d90ce865271c44acd32e0ea56cbfd0ce\",\"title\":\"Reinforcement Learning with Imitation for Cavity Filter Tuning\",\"url\":\"https://www.semanticscholar.org/paper/1504edc2d90ce865271c44acd32e0ea56cbfd0ce\",\"venue\":\"2020 IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM)\",\"year\":2020},{\"arxivId\":\"2002.09089\",\"authors\":[{\"authorId\":\"47627548\",\"name\":\"Daniel S. Brown\"},{\"authorId\":\"152299477\",\"name\":\"R. Coleman\"},{\"authorId\":\"143889798\",\"name\":\"R. Srinivasan\"},{\"authorId\":\"2791038\",\"name\":\"S. Niekum\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"766c17912953a1f1a7696edba3cb42db4fc518ea\",\"title\":\"Safe Imitation Learning via Fast Bayesian Reward Inference from Preferences\",\"url\":\"https://www.semanticscholar.org/paper/766c17912953a1f1a7696edba3cb42db4fc518ea\",\"venue\":\"ICML\",\"year\":2020}],\"corpusId\":23206414,\"doi\":\"10.24963/ijcai.2018/687\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":22,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"cc2fb12eaa4dae74c5de0799b29624b5c585c43b\",\"references\":[{\"arxivId\":\"1606.03476\",\"authors\":[{\"authorId\":\"2126278\",\"name\":\"Jonathan Ho\"},{\"authorId\":\"2490652\",\"name\":\"S. Ermon\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"4ab53de69372ec2cd2d90c126b6a100165dc8ed1\",\"title\":\"Generative Adversarial Imitation Learning\",\"url\":\"https://www.semanticscholar.org/paper/4ab53de69372ec2cd2d90c126b6a100165dc8ed1\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1604.07316\",\"authors\":[{\"authorId\":\"3146322\",\"name\":\"M. Bojarski\"},{\"authorId\":\"2824480\",\"name\":\"D. Testa\"},{\"authorId\":\"3393305\",\"name\":\"Daniel Dworakowski\"},{\"authorId\":\"2372758\",\"name\":\"Bernhard Firner\"},{\"authorId\":\"2286388\",\"name\":\"Beat Flepp\"},{\"authorId\":\"38774604\",\"name\":\"Prasoon Goyal\"},{\"authorId\":\"2307573\",\"name\":\"L. Jackel\"},{\"authorId\":\"95743023\",\"name\":\"Mathew Monfort\"},{\"authorId\":\"145636949\",\"name\":\"U. Muller\"},{\"authorId\":\"3393542\",\"name\":\"Jiakai Zhang\"},{\"authorId\":\"145863017\",\"name\":\"X. Zhang\"},{\"authorId\":\"79678947\",\"name\":\"Jake Zhao\"},{\"authorId\":\"3262926\",\"name\":\"Karol Zieba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0e3cc46583217ec81e87045a4f9ae3478a008227\",\"title\":\"End to End Learning for Self-Driving Cars\",\"url\":\"https://www.semanticscholar.org/paper/0e3cc46583217ec81e87045a4f9ae3478a008227\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33354551\",\"name\":\"A. Giusti\"},{\"authorId\":\"2144778\",\"name\":\"J\\u00e9r\\u00f4me Guzzi\"},{\"authorId\":\"1895356\",\"name\":\"Dan C. Ciresan\"},{\"authorId\":\"1946020\",\"name\":\"Fang-Lin He\"},{\"authorId\":\"117005439\",\"name\":\"J. P. Rodriguez\"},{\"authorId\":\"2506029\",\"name\":\"Flavio Fontana\"},{\"authorId\":\"36984610\",\"name\":\"M. Faessler\"},{\"authorId\":\"144789467\",\"name\":\"C. Forster\"},{\"authorId\":\"48974230\",\"name\":\"J. Schmidhuber\"},{\"authorId\":\"1744127\",\"name\":\"G. D. Caro\"},{\"authorId\":\"2075371\",\"name\":\"D. Scaramuzza\"},{\"authorId\":\"6803671\",\"name\":\"L. Gambardella\"}],\"doi\":\"10.1109/LRA.2015.2509024\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5ce030f1650145a103527e883e7a9d9a25c45547\",\"title\":\"A Machine Learning Approach to Visual Perception of Forest Trails for Mobile Robots\",\"url\":\"https://www.semanticscholar.org/paper/5ce030f1650145a103527e883e7a9d9a25c45547\",\"venue\":\"IEEE Robotics and Automation Letters\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"70092712\",\"name\":\"J. Shepherdson\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ef6402824bc7a5cfa8b4709f5e766eb39e2132f5\",\"title\":\"Machine Intelligence 15\",\"url\":\"https://www.semanticscholar.org/paper/ef6402824bc7a5cfa8b4709f5e766eb39e2132f5\",\"venue\":\"\",\"year\":1998},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"St\\u00e9phane Ross\"},{\"authorId\":null,\"name\":\"Geoffrey J Gordon\"},{\"authorId\":null,\"name\":\"Drew Bagnell. A reduction of imitation learning\"},{\"authorId\":null,\"name\":\"structured prediction to no-regret online learning\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In International Conference on Artificial Intelligence and Statistics\",\"url\":\"\",\"venue\":\"pages 627\\u2013635,\",\"year\":2011},{\"arxivId\":\"1703.03078\",\"authors\":[{\"authorId\":\"2527420\",\"name\":\"Yevgen Chebotar\"},{\"authorId\":\"1944801\",\"name\":\"Karol Hausman\"},{\"authorId\":\"2634261\",\"name\":\"Marvin Zhang\"},{\"authorId\":\"1732493\",\"name\":\"G. Sukhatme\"},{\"authorId\":\"1745219\",\"name\":\"S. Schaal\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"360cf15dcba643b04f9028bca25396b3beb73f2d\",\"title\":\"Combining Model-Based and Model-Free Updates for Trajectory-Centric Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/360cf15dcba643b04f9028bca25396b3beb73f2d\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144832491\",\"name\":\"E. Todorov\"},{\"authorId\":\"1968210\",\"name\":\"T. Erez\"},{\"authorId\":\"2109481\",\"name\":\"Y. Tassa\"}],\"doi\":\"10.1109/IROS.2012.6386109\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b354ee518bfc1ac0d8ac447eece9edb69e92eae1\",\"title\":\"MuJoCo: A physics engine for model-based control\",\"url\":\"https://www.semanticscholar.org/paper/b354ee518bfc1ac0d8ac447eece9edb69e92eae1\",\"venue\":\"2012 IEEE/RSJ International Conference on Intelligent Robots and Systems\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1765407\",\"name\":\"G. Konidaris\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3661f06555fc77d49e0de0e42fe36650dfe1489f\",\"title\":\"A Framework for Transfer in Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/3661f06555fc77d49e0de0e42fe36650dfe1489f\",\"venue\":\"\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699645\",\"name\":\"R. Sutton\"},{\"authorId\":\"1730590\",\"name\":\"A. Barto\"}],\"doi\":\"10.1109/TNN.1998.712192\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"97efafdb4a3942ab3efba53ded7413199f79c054\",\"title\":\"Reinforcement Learning: An Introduction\",\"url\":\"https://www.semanticscholar.org/paper/97efafdb4a3942ab3efba53ded7413199f79c054\",\"venue\":\"IEEE Transactions on Neural Networks\",\"year\":2005},{\"arxivId\":\"1605.08478\",\"authors\":[{\"authorId\":\"2126278\",\"name\":\"Jonathan Ho\"},{\"authorId\":\"38303675\",\"name\":\"J. Gupta\"},{\"authorId\":\"2490652\",\"name\":\"S. Ermon\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0c4646b611023901d0fda28c52660e40caf7e72c\",\"title\":\"Model-Free Imitation Learning with Policy Optimization\",\"url\":\"https://www.semanticscholar.org/paper/0c4646b611023901d0fda28c52660e40caf7e72c\",\"venue\":\"ICML\",\"year\":2016},{\"arxivId\":\"1603.00448\",\"authors\":[{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"04162cb8cfaa0f7e37586823ff4ad0bff09ed21d\",\"title\":\"Guided Cost Learning: Deep Inverse Optimal Control via Policy Optimization\",\"url\":\"https://www.semanticscholar.org/paper/04162cb8cfaa0f7e37586823ff4ad0bff09ed21d\",\"venue\":\"ICML\",\"year\":2016},{\"arxivId\":\"1707.03374\",\"authors\":[{\"authorId\":\"49421394\",\"name\":\"Yuxuan Liu\"},{\"authorId\":\"144150283\",\"name\":\"A. Gupta\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":\"10.1109/ICRA.2018.8462901\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"77fa0239b9b074e7b62ca3798b8abf6fa3823f80\",\"title\":\"Imitation from Observation: Learning to Imitate Behaviors from Raw Video via Context Translation\",\"url\":\"https://www.semanticscholar.org/paper/77fa0239b9b074e7b62ca3798b8abf6fa3823f80\",\"venue\":\"2018 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5886094\",\"name\":\"P. Cochat\"},{\"authorId\":\"13267685\",\"name\":\"L. Vaucoret\"},{\"authorId\":\"31455512\",\"name\":\"J. Sarles\"}],\"doi\":\"10.1016/j.arcped.2012.01.013\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"10d85561e4aafc516d10064f30dff05b41f70afe\",\"title\":\"[Et al].\",\"url\":\"https://www.semanticscholar.org/paper/10d85561e4aafc516d10064f30dff05b41f70afe\",\"venue\":\"Archives de pediatrie : organe officiel de la Societe francaise de pediatrie\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1836885\",\"name\":\"Brenna Argall\"},{\"authorId\":\"144753437\",\"name\":\"S. Chernova\"},{\"authorId\":\"1956361\",\"name\":\"M. Veloso\"},{\"authorId\":\"1699032\",\"name\":\"B. Browning\"}],\"doi\":\"10.1016/j.robot.2008.10.024\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4e5dfb0b1e54412e799eb0e86d552956cc3a5f54\",\"title\":\"A survey of robot learning from demonstration\",\"url\":\"https://www.semanticscholar.org/paper/4e5dfb0b1e54412e799eb0e86d552956cc3a5f54\",\"venue\":\"Robotics Auton. Syst.\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1727849\",\"name\":\"S. Hanson\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"69d7086300e7f5322c06f2f242a565b3a182efb5\",\"title\":\"In Advances in Neural Information Processing Systems\",\"url\":\"https://www.semanticscholar.org/paper/69d7086300e7f5322c06f2f242a565b3a182efb5\",\"venue\":\"NIPS 1990\",\"year\":1990},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jonathan Ho\"},{\"authorId\":null,\"name\":\"Jayesh Gupta\"},{\"authorId\":null,\"name\":\"Stefano Ermon. Model-free imitation learning with policy optimization\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In International Conference on Machine Learning\",\"url\":\"\",\"venue\":\"pages 2760\\u20132769,\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2791038\",\"name\":\"S. Niekum\"},{\"authorId\":\"1795401\",\"name\":\"Sarah Osentoski\"},{\"authorId\":\"1765407\",\"name\":\"G. Konidaris\"},{\"authorId\":\"1780110\",\"name\":\"S. Chitta\"},{\"authorId\":\"1711416\",\"name\":\"Bhaskara Marthi\"},{\"authorId\":\"1730590\",\"name\":\"A. Barto\"}],\"doi\":\"10.1177/0278364914554471\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9e5bd0e155f7684dc72d8679f260d8031a004952\",\"title\":\"Learning grounded finite-state representations from unstructured demonstrations\",\"url\":\"https://www.semanticscholar.org/paper/9e5bd0e155f7684dc72d8679f260d8031a004952\",\"venue\":\"Int. J. Robotics Res.\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"St\\u00e9phane Ross\"},{\"authorId\":null,\"name\":\"Drew Bagnell. Efficient reductions for imitation learning\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In Proceedings of the thirteenth international conference on artificial intelligence and statistics\",\"url\":\"\",\"venue\":\"pages 661\\u2013668,\",\"year\":2010},{\"arxivId\":\"1608.00627\",\"authors\":[{\"authorId\":\"2739544\",\"name\":\"Shreyansh Daftry\"},{\"authorId\":\"1756566\",\"name\":\"J. Bagnell\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1007/978-3-319-50115-4_1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8e0540ea3c3cc8cd009b2006d96c4b3ac2a84e52\",\"title\":\"Learning Transferable Policies for Monocular Reactive MAV Control\",\"url\":\"https://www.semanticscholar.org/paper/8e0540ea3c3cc8cd009b2006d96c4b3ac2a84e52\",\"venue\":\"ISER\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Shreyansh Daftry\"},{\"authorId\":null,\"name\":\"J Andrew Bagnell\"},{\"authorId\":null,\"name\":\"Martial Hebert. Learning transferable policies for monocul Robotics\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"pages 3\\u201311\",\"url\":\"\",\"venue\":\"Springer,\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1735414\",\"name\":\"T. Knasel\"}],\"doi\":\"10.1016/0921-8890(88)90002-4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"edd77f310393f521669b209cbb6828fb45a8485d\",\"title\":\"Robotics and autonomous systems\",\"url\":\"https://www.semanticscholar.org/paper/edd77f310393f521669b209cbb6828fb45a8485d\",\"venue\":\"Robotics Auton. Syst.\",\"year\":1988},{\"arxivId\":\"1502.05477\",\"authors\":[{\"authorId\":\"47971768\",\"name\":\"John Schulman\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"},{\"authorId\":\"1694621\",\"name\":\"Michael I. Jordan\"},{\"authorId\":\"29912342\",\"name\":\"P. Moritz\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"66cdc28dc084af6507e979767755e99fe0b46b39\",\"title\":\"Trust Region Policy Optimization\",\"url\":\"https://www.semanticscholar.org/paper/66cdc28dc084af6507e979767755e99fe0b46b39\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1011.0686\",\"authors\":[{\"authorId\":\"1700433\",\"name\":\"S. Ross\"},{\"authorId\":\"21889436\",\"name\":\"G. Gordon\"},{\"authorId\":\"1756566\",\"name\":\"J. Bagnell\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"79ab3c49903ec8cb339437ccf5cf998607fc313e\",\"title\":\"A Reduction of Imitation Learning and Structured Prediction to No-Regret Online Learning\",\"url\":\"https://www.semanticscholar.org/paper/79ab3c49903ec8cb339437ccf5cf998607fc313e\",\"venue\":\"AISTATS\",\"year\":2011},{\"arxivId\":\"1606.01540\",\"authors\":[{\"authorId\":\"49508975\",\"name\":\"G. Brockman\"},{\"authorId\":\"34415167\",\"name\":\"Vicki Cheung\"},{\"authorId\":\"152877508\",\"name\":\"Ludwig Pettersson\"},{\"authorId\":\"145540310\",\"name\":\"J. Schneider\"},{\"authorId\":\"47971768\",\"name\":\"John Schulman\"},{\"authorId\":\"143805717\",\"name\":\"Jie Tang\"},{\"authorId\":\"2563432\",\"name\":\"W. Zaremba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ff7f3277c6fa759e84e1ab7664efdac1c1cec76b\",\"title\":\"OpenAI Gym\",\"url\":\"https://www.semanticscholar.org/paper/ff7f3277c6fa759e84e1ab7664efdac1c1cec76b\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"John Schulman\"},{\"authorId\":null,\"name\":\"Sergey Levine\"},{\"authorId\":null,\"name\":\"Pieter Abbeel\"},{\"authorId\":null,\"name\":\"Michael Jordan\"},{\"authorId\":null,\"name\":\"Philipp Moritz. Trust region policy optimization\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In Proceedings of the 32nd International Conference on Machine Learning (ICML-15)\",\"url\":\"\",\"venue\":\"pages 1889\\u20131897,\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Matthew E Taylor\"},{\"authorId\":null,\"name\":\"Nicholas K Jong\"},{\"authorId\":null,\"name\":\"Peter Stone. Transferring instances for modelbased reinf Learning\"},{\"authorId\":null,\"name\":\"Knowledge Discovery in Databases\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"pages 488\\u2013505\",\"url\":\"\",\"venue\":\"Springer,\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1745219\",\"name\":\"S. Schaal\"}],\"doi\":\"10.1007/978-1-4899-7687-1_100247\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a9da09d1e63686706d64782e654d69f13fd292ad\",\"title\":\"Learning by Demonstration\",\"url\":\"https://www.semanticscholar.org/paper/a9da09d1e63686706d64782e654d69f13fd292ad\",\"venue\":\"Encyclopedia of Machine Learning and Data Mining\",\"year\":2017},{\"arxivId\":\"2008.01281\",\"authors\":[{\"authorId\":\"34719248\",\"name\":\"Josiah P. Hanna\"},{\"authorId\":\"144848112\",\"name\":\"P. Stone\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a7b3b89ef299261e172e8f47a263dee05511e7b4\",\"title\":\"Grounded Action Transformation for Robot Learning in Simulation\",\"url\":\"https://www.semanticscholar.org/paper/a7b3b89ef299261e172e8f47a263dee05511e7b4\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":\"1703.02949\",\"authors\":[{\"authorId\":\"144150283\",\"name\":\"A. Gupta\"},{\"authorId\":\"144373380\",\"name\":\"C. Devin\"},{\"authorId\":\"49421394\",\"name\":\"Yuxuan Liu\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b9f8a1a9a5aec3dcdd155c4594f25274f6418e11\",\"title\":\"Learning Invariant Feature Spaces to Transfer Skills with Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/b9f8a1a9a5aec3dcdd155c4594f25274f6418e11\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1700433\",\"name\":\"S. Ross\"},{\"authorId\":\"1756566\",\"name\":\"J. Bagnell\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"70e10a5459c6f1aaf346ee4f2dcc837151fbe75c\",\"title\":\"Efficient Reductions for Imitation Learning\",\"url\":\"https://www.semanticscholar.org/paper/70e10a5459c6f1aaf346ee4f2dcc837151fbe75c\",\"venue\":\"AISTATS\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Josiah P Hanna\"},{\"authorId\":null,\"name\":\"Peter Stone. Grounded action transformation for robot le simulation\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In AAAI\",\"url\":\"\",\"venue\":\"pages 3834\\u20133840,\",\"year\":2017}],\"title\":\"Behavioral Cloning from Observation\",\"topics\":[{\"topic\":\"Autonomous robot\",\"topicId\":\"1175\",\"url\":\"https://www.semanticscholar.org/topic/1175\"},{\"topic\":\"Humans\",\"topicId\":\"732\",\"url\":\"https://www.semanticscholar.org/topic/732\"},{\"topic\":\"Algorithm\",\"topicId\":\"305\",\"url\":\"https://www.semanticscholar.org/topic/305\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Interaction\",\"topicId\":\"72\",\"url\":\"https://www.semanticscholar.org/topic/72\"},{\"topic\":\"Simulation\",\"topicId\":\"194\",\"url\":\"https://www.semanticscholar.org/topic/194\"},{\"topic\":\"Two-phase commit protocol\",\"topicId\":\"180218\",\"url\":\"https://www.semanticscholar.org/topic/180218\"},{\"topic\":\"Programming paradigm\",\"topicId\":\"29522\",\"url\":\"https://www.semanticscholar.org/topic/29522\"}],\"url\":\"https://www.semanticscholar.org/paper/cc2fb12eaa4dae74c5de0799b29624b5c585c43b\",\"venue\":\"IJCAI\",\"year\":2018}\n"