"{\"abstract\":\"Active learning agents typically employ a query selection algorithm which solely considers the agent's learning objectives. However, this may be insufficient in more realistic human domains. This work uses imitation learning to enable an agent in a constrained environment to concurrently reason about both its internal learning goals and environmental constraints externally imposed, all within its objective function. Experiments are conducted on a concept learning task to test generalization of the proposed algorithm to different environmental conditions and analyze how time and resource constraints impact efficacy of solving the learning problem. Our findings show the environmentally-aware learning agent is able to statistically outperform all other active learners explored under most of the constrained conditions. A key implication is adaptation for active learning agents to more realistic human environments, where constraints are often externally imposed on the learner.\",\"arxivId\":\"1907.00921\",\"authors\":[{\"authorId\":\"2302656\",\"name\":\"Kalesha Bullard\",\"url\":\"https://www.semanticscholar.org/author/2302656\"},{\"authorId\":\"3403061\",\"name\":\"Yannick Schroecker\",\"url\":\"https://www.semanticscholar.org/author/3403061\"},{\"authorId\":\"144753437\",\"name\":\"S. Chernova\",\"url\":\"https://www.semanticscholar.org/author/144753437\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"2138933\",\"name\":\"H. Ravichandar\"},{\"authorId\":\"104535400\",\"name\":\"S. Athanasios\"},{\"authorId\":null,\"name\":\"Polydoros\"},{\"authorId\":\"144753437\",\"name\":\"S. Chernova\"},{\"authorId\":\"67168385\",\"name\":\"Aude\"},{\"authorId\":\"117535741\",\"name\":\"Billard\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ce6654a4488dc94eb3a60eba5b2f1f5b3875e76d\",\"title\":\"Robot Learning from Demonstration: A Review of Recent Advances\",\"url\":\"https://www.semanticscholar.org/paper/ce6654a4488dc94eb3a60eba5b2f1f5b3875e76d\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2012.07330\",\"authors\":[{\"authorId\":\"11874816\",\"name\":\"Y. Niu\"},{\"authorId\":\"152241106\",\"name\":\"Yijun Gu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b9e4bccd2e69132af961fceeb51d418ee106e3ff\",\"title\":\"Active Hierarchical Imitation and Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/b9e4bccd2e69132af961fceeb51d418ee106e3ff\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Pallavi Koppol\"},{\"authorId\":\"1882027\",\"name\":\"Henny Admoni\"},{\"authorId\":\"1488658168\",\"name\":\"Reid Simmons\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"08e12ae575234b039e171073d21d4d43e52ca93e\",\"title\":\"Iterative Interactive Reward Learning\",\"url\":\"https://www.semanticscholar.org/paper/08e12ae575234b039e171073d21d4d43e52ca93e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2011.08021\",\"authors\":[{\"authorId\":\"144339038\",\"name\":\"Nisha Pillai\"},{\"authorId\":\"34885007\",\"name\":\"Edward Raff\"},{\"authorId\":\"2034063\",\"name\":\"F. Ferraro\"},{\"authorId\":\"2674440\",\"name\":\"Cynthia Matuszek\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"6f01131e0274729dbf753003da91a2cff8c11837\",\"title\":\"Sampling Approach Matters: Active Learning for Robotic Language Acquisition\",\"url\":\"https://www.semanticscholar.org/paper/6f01131e0274729dbf753003da91a2cff8c11837\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47692450\",\"name\":\"Mattia Racca\"},{\"authorId\":\"2717428\",\"name\":\"V. Kyrki\"},{\"authorId\":\"49258625\",\"name\":\"Maya Cakmak\"}],\"doi\":\"10.1145/3319502.3374784\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0d094bb534cff4dc2754e65aff1205c12fd0d742\",\"title\":\"Interactive Tuning of Robot Program Parameters via Expected Divergence Maximization\",\"url\":\"https://www.semanticscholar.org/paper/0d094bb534cff4dc2754e65aff1205c12fd0d742\",\"venue\":\"HRI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2138933\",\"name\":\"H. Ravichandar\"},{\"authorId\":\"32180850\",\"name\":\"Athanasios S. Polydoros\"},{\"authorId\":\"144753437\",\"name\":\"S. Chernova\"},{\"authorId\":\"143620850\",\"name\":\"Aude Billard\"}],\"doi\":\"10.1146/annurev-control-100819-063206\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f441e637980a8b427474dbdc0141f38dd78bb831\",\"title\":\"Recent Advances in Robot Learning from Demonstration\",\"url\":\"https://www.semanticscholar.org/paper/f441e637980a8b427474dbdc0141f38dd78bb831\",\"venue\":\"\",\"year\":2020}],\"corpusId\":195767341,\"doi\":\"10.24963/ijcai.2019/283\",\"fieldsOfStudy\":[\"Computer Science\",\"Mathematics\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"2bc6a9cafca9064dc04d58c1393d38208406f335\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Burr Settles. Active learning\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Synthesis Lectures on Artificial Intelligence and Machine Learning\",\"url\":\"\",\"venue\":\"6(1):1\\u2013114,\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37755468\",\"name\":\"C. Daniel\"},{\"authorId\":\"2948013\",\"name\":\"M. Viering\"},{\"authorId\":\"153221265\",\"name\":\"Jan Metz\"},{\"authorId\":\"1785853\",\"name\":\"Oliver Kroemer\"},{\"authorId\":\"145197867\",\"name\":\"Jan Peters\"}],\"doi\":\"10.15607/RSS.2014.X.031\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"05355b13af5e67cfb86a782de15e4491d84c98c9\",\"title\":\"Active Reward Learning\",\"url\":\"https://www.semanticscholar.org/paper/05355b13af5e67cfb86a782de15e4491d84c98c9\",\"venue\":\"Robotics: Science and Systems\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5886094\",\"name\":\"P. Cochat\"},{\"authorId\":\"13267685\",\"name\":\"L. Vaucoret\"},{\"authorId\":\"31455512\",\"name\":\"J. Sarles\"}],\"doi\":\"10.1016/j.arcped.2012.01.013\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10d85561e4aafc516d10064f30dff05b41f70afe\",\"title\":\"[Et al].\",\"url\":\"https://www.semanticscholar.org/paper/10d85561e4aafc516d10064f30dff05b41f70afe\",\"venue\":\"Archives de pediatrie : organe officiel de la Societe francaise de pediatrie\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Manuel Lopes\"},{\"authorId\":null,\"name\":\"Francisco Melo\"},{\"authorId\":null,\"name\":\"Luis Montesano. Active learning for reward estimation i Learning\"},{\"authorId\":null,\"name\":\"Knowledge Discovery in Databases\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"pages 31\\u201346\",\"url\":\"\",\"venue\":\"Springer,\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144518313\",\"name\":\"M. Lopes\"},{\"authorId\":\"145125979\",\"name\":\"Francisco S. Melo\"},{\"authorId\":\"2987153\",\"name\":\"L. Montesano\"}],\"doi\":\"10.1007/978-3-642-04174-7_3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a743261fbebc016a3659494886a6e6b7bf8e0ac\",\"title\":\"Active Learning for Reward Estimation in Inverse Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/8a743261fbebc016a3659494886a6e6b7bf8e0ac\",\"venue\":\"ECML/PKDD\",\"year\":2009},{\"arxivId\":\"1401.3439\",\"authors\":[{\"authorId\":\"144753437\",\"name\":\"S. Chernova\"},{\"authorId\":\"1956361\",\"name\":\"M. Veloso\"}],\"doi\":\"10.1613/jair.2584\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e40a0969aac73d50485c05de7f1c0ab081d77028\",\"title\":\"Interactive Policy Learning through Confidence-Based Autonomy\",\"url\":\"https://www.semanticscholar.org/paper/e40a0969aac73d50485c05de7f1c0ab081d77028\",\"venue\":\"J. Artif. Intell. Res.\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Sonia Chernova\"},{\"authorId\":null,\"name\":\"Manuela Veloso. Interactive policy learning through confid autonomy\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Journal of Artificial Intelligence Research\",\"url\":\"\",\"venue\":\"34(1):1,\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145241970\",\"name\":\"S. Rosenthal\"},{\"authorId\":\"1956361\",\"name\":\"M. Veloso\"}],\"doi\":\"10.1109/ROMAN.2011.6005272\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"46417649ef159538778c6d54dfaf5085a4064016\",\"title\":\"Modeling humans as observation providers using POMDPs\",\"url\":\"https://www.semanticscholar.org/paper/46417649ef159538778c6d54dfaf5085a4064016\",\"venue\":\"2011 RO-MAN\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Maya Cakmak\"},{\"authorId\":null,\"name\":\"Crystal Chao\"},{\"authorId\":null,\"name\":\"Andrea L Thomaz. Designing interactions for robot active Development\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"IEEE Transactions on\",\"url\":\"\",\"venue\":\"2(2):108\\u2013118,\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Stevan Harnad. The symbol grounding problem\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Physica D: Nonlinear Phenomena\",\"url\":\"\",\"venue\":\"42(1):335\\u2013346,\",\"year\":1990},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2562288\",\"name\":\"J. Kulick\"},{\"authorId\":\"144918851\",\"name\":\"Marc Toussaint\"},{\"authorId\":\"49046135\",\"name\":\"T. Lang\"},{\"authorId\":\"144518313\",\"name\":\"M. Lopes\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8579d610ad13afd520d68fbedfc1927ead24b45d\",\"title\":\"Active Learning for Teaching a Robot Grounded Relational Symbols\",\"url\":\"https://www.semanticscholar.org/paper/8579d610ad13afd520d68fbedfc1927ead24b45d\",\"venue\":\"IJCAI\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47692450\",\"name\":\"Mattia Racca\"},{\"authorId\":\"2717428\",\"name\":\"V. Kyrki\"}],\"doi\":\"10.1145/3171221.3171241\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c9d3e42c2ed2484c878812cb4fc675e147613455\",\"title\":\"Active Robot Learning for Temporal Task Models\",\"url\":\"https://www.semanticscholar.org/paper/c9d3e42c2ed2484c878812cb4fc675e147613455\",\"venue\":\"HRI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Maya Cakmak\"},{\"authorId\":null,\"name\":\"Andrea L Thomaz. Designing robot learners that ask good questions\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In ACM/IEEE Int Conf on Human-Robot Interaction\",\"url\":\"\",\"venue\":\"pages 17\\u201324,\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Kevin Lai\"},{\"authorId\":null,\"name\":\"Liefeng Bo\"},{\"authorId\":null,\"name\":\"Xiaofeng Ren\"},{\"authorId\":null,\"name\":\"Dieter Fox\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"A large - scale hierarchical multiview rgb - d object dataset Active learning for reward estimation in inverse reinforcement learning\",\"url\":\"\",\"venue\":\"Machine Learning and Knowledge Discovery in Databases\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Johannes Kulick\"},{\"authorId\":null,\"name\":\"Marc Toussaint\"},{\"authorId\":null,\"name\":\"Tobias Lang\"},{\"authorId\":null,\"name\":\"Manuel Lopes. Active learning for teaching a robot ground Intelligence\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"pages 1451\\u20131457\",\"url\":\"\",\"venue\":\"AAAI Press,\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144288136\",\"name\":\"W. B. Knox\"},{\"authorId\":\"144848112\",\"name\":\"P. Stone\"},{\"authorId\":\"1711777\",\"name\":\"C. Breazeal\"}],\"doi\":\"10.1007/978-3-319-02675-6_46\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"17ed4d8c41be0610afcbbf60973a6b138968546b\",\"title\":\"Training a Robot via Human Feedback: A Case Study\",\"url\":\"https://www.semanticscholar.org/paper/17ed4d8c41be0610afcbbf60973a6b138968546b\",\"venue\":\"ICSR\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1753269\",\"name\":\"Brian D. Ziebart\"},{\"authorId\":\"34961461\",\"name\":\"Andrew L. Maas\"},{\"authorId\":\"1756566\",\"name\":\"J. Bagnell\"},{\"authorId\":\"144021446\",\"name\":\"Anind K. Dey\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"11b6bdfe36c48b11367b27187da11d95892f0361\",\"title\":\"Maximum Entropy Inverse Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/11b6bdfe36c48b11367b27187da11d95892f0361\",\"venue\":\"AAAI\",\"year\":2008},{\"arxivId\":null,\"authors\":[],\"doi\":\"10.1145/3171221\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"82061e0679b64d163b786b6b2c4370dbac68bb01\",\"title\":\"Proceedings of the 2018 ACM/IEEE International Conference on Human-Robot Interaction\",\"url\":\"https://www.semanticscholar.org/paper/82061e0679b64d163b786b6b2c4370dbac68bb01\",\"venue\":\"HRI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2302656\",\"name\":\"Kalesha Bullard\"},{\"authorId\":\"144753437\",\"name\":\"S. Chernova\"},{\"authorId\":\"1682788\",\"name\":\"A. Thomaz\"}],\"doi\":\"10.1109/ICRA.2018.8461012\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"271df16c554a014974a442541660fb08ecd1836d\",\"title\":\"Human-Driven Feature Selection for a Robotic Agent Learning Classification Tasks from Demonstration\",\"url\":\"https://www.semanticscholar.org/paper/271df16c554a014974a442541660fb08ecd1836d\",\"venue\":\"2018 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2927155\",\"name\":\"E. Silerova\"},{\"authorId\":\"9528315\",\"name\":\"L. Ku\\u010d\\u00edrkov\\u00e1\"}],\"doi\":\"10.17221/245-AGRICECON\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"35e747d3d0bef4e9e3dabb1f70593b6838d26644\",\"title\":\"Knowledge and information systems\",\"url\":\"https://www.semanticscholar.org/paper/35e747d3d0bef4e9e3dabb1f70593b6838d26644\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1802.01604\",\"authors\":[{\"authorId\":\"7843744\",\"name\":\"Chandrayee Basu\"},{\"authorId\":\"144772132\",\"name\":\"M. Singhal\"},{\"authorId\":\"2745001\",\"name\":\"Anca D. Dragan\"}],\"doi\":\"10.1145/3171221.3171284\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cac053312603a785b23abe9b7998910af7485d6b\",\"title\":\"Learning from Richer Human Guidance: Augmenting Comparison-Based Learning with Feature Queries\",\"url\":\"https://www.semanticscholar.org/paper/cac053312603a785b23abe9b7998910af7485d6b\",\"venue\":\"HRI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jesse Thomason\"},{\"authorId\":null,\"name\":\"Aishwarya Padmakumar\"},{\"authorId\":null,\"name\":\"Jivko Sinapov\"},{\"authorId\":null,\"name\":\"Justin Hart\"},{\"authorId\":null,\"name\":\"Peter Stone\"},{\"authorId\":null,\"name\":\"Raymond J Mooney. Opportunistic active learning for ground descriptions\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In Conference on Robot Learning\",\"url\":\"\",\"venue\":\"pages 67\\u201376,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35096370\",\"name\":\"M. Cakmak\"},{\"authorId\":\"2053404\",\"name\":\"Crystal Chao\"},{\"authorId\":\"1682788\",\"name\":\"A. Thomaz\"}],\"doi\":\"10.1109/TAMD.2010.2051030\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ed504eb31a4046a7c8889c2e821e12d55e6af5bb\",\"title\":\"Designing Interactions for Robot Active Learners\",\"url\":\"https://www.semanticscholar.org/paper/ed504eb31a4046a7c8889c2e821e12d55e6af5bb\",\"venue\":\"IEEE Transactions on Autonomous Mental Development\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"OB Kroemer\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Renaud Detry\",\"url\":\"\",\"venue\":\"Justus Piater, and Jan Peters. Combining active learning and reactive control for robot grasping. Robotics and Autonomous Systems, 58(9):1105\\u20131116\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Stephanie Rosenthal\"},{\"authorId\":null,\"name\":\"Manuela Veloso. Modeling humans as observation providers u RO-MAN\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"2011 IEEE\",\"url\":\"\",\"venue\":\"pages 53\\u201358. IEEE,\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403055469\",\"name\":\"V\\u00edctor Gonz\\u00e1lez-Pacheco\"},{\"authorId\":\"5992147\",\"name\":\"M. Malfaz\"},{\"authorId\":\"2824276\",\"name\":\"\\u00c1. Gonz\\u00e1lez\"},{\"authorId\":\"2439331\",\"name\":\"J. C. Castillo\"},{\"authorId\":\"1401846718\",\"name\":\"F. Alonso-Mart\\u00edn\"},{\"authorId\":\"1853452\",\"name\":\"M. A. Salichs\"}],\"doi\":\"10.1007/s12369-017-0449-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bdb344724e1d34a50f2a8debdd18f78481124b01\",\"title\":\"Analyzing the Impact of Different Feature Queries in Active Learning for Social Robots\",\"url\":\"https://www.semanticscholar.org/paper/bdb344724e1d34a50f2a8debdd18f78481124b01\",\"venue\":\"Int. J. Soc. Robotics\",\"year\":2018},{\"arxivId\":\"cs/9906002\",\"authors\":[{\"authorId\":\"2293327\",\"name\":\"S. Harnad\"}],\"doi\":\"10.4249/scholarpedia.2373\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"026ff33083c647bd3a3734d41904d880a6525d13\",\"title\":\"Symbol grounding problem\",\"url\":\"https://www.semanticscholar.org/paper/026ff33083c647bd3a3734d41904d880a6525d13\",\"venue\":\"Scholarpedia\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2302656\",\"name\":\"Kalesha Bullard\"},{\"authorId\":\"1682788\",\"name\":\"A. Thomaz\"},{\"authorId\":\"144753437\",\"name\":\"S. Chernova\"}],\"doi\":\"10.1109/IROS.2018.8594279\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b45fbb16a77c17a575c15881e5981ef1cd465a11\",\"title\":\"Towards Intelligent Arbitration of Diverse Active Learning Queries\",\"url\":\"https://www.semanticscholar.org/paper/b45fbb16a77c17a575c15881e5981ef1cd465a11\",\"venue\":\"2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Kevin Lai\"},{\"authorId\":null,\"name\":\"Liefeng Bo\"},{\"authorId\":null,\"name\":\"Xiaofeng Ren\"},{\"authorId\":null,\"name\":\"Dieter Fox. A large-scale hierarchical multi-view rgb-d o Conf\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"on Robotics and Automation\",\"url\":\"\",\"venue\":\"pages 1817\\u20131824,\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34699434\",\"name\":\"A. Ng\"},{\"authorId\":\"145107462\",\"name\":\"S. Russell\"}],\"doi\":\"10.2460/AJVR.67.2.323\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b05b67aca720d0bc39bc9afad02a19f522c7a1bc\",\"title\":\"Algorithms for Inverse Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/b05b67aca720d0bc39bc9afad02a19f522c7a1bc\",\"venue\":\"ICML\",\"year\":2000},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1717452\",\"name\":\"B. Settles\"}],\"doi\":\"10.2200/S00429ED1V01Y201207AIM018\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e541c475457a731d7d434c4302867fc45af5876f\",\"title\":\"Active Learning\",\"url\":\"https://www.semanticscholar.org/paper/e541c475457a731d7d434c4302867fc45af5876f\",\"venue\":\"Active Learning\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"},{\"authorId\":\"34699434\",\"name\":\"A. Ng\"}],\"doi\":\"10.1145/1015330.1015430\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f65020fc3b1692d7989e099d6b6e698be5a50a93\",\"title\":\"Apprenticeship learning via inverse reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/f65020fc3b1692d7989e099d6b6e698be5a50a93\",\"venue\":\"ICML '04\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"W Bradley Knox\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Peter Stone\",\"url\":\"\",\"venue\":\"and Cynthia Breazeal. Training a robot via human feedback: A case study. In International Conference on Social Robotics, pages 460\\u2013470. Springer\",\"year\":2013},{\"arxivId\":\"1811.06711\",\"authors\":[{\"authorId\":\"40229316\",\"name\":\"Takayuki Osa\"},{\"authorId\":\"34906504\",\"name\":\"J. Pajarinen\"},{\"authorId\":\"26599977\",\"name\":\"G. Neumann\"},{\"authorId\":\"1756566\",\"name\":\"J. Bagnell\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"},{\"authorId\":\"145197867\",\"name\":\"Jan Peters\"}],\"doi\":\"10.1561/2300000053\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8d6adaa16ed0af9935a1130a305c85e8bdf8780d\",\"title\":\"An Algorithmic Perspective on Imitation Learning\",\"url\":\"https://www.semanticscholar.org/paper/8d6adaa16ed0af9935a1130a305c85e8bdf8780d\",\"venue\":\"Found. Trends Robotics\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Crystal Chao\"},{\"authorId\":null,\"name\":\"Maya Cakmak\"},{\"authorId\":null,\"name\":\"Andrea Lockerd Thomaz. Transparent active learning for robots\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In ACM/IEEE Int\",\"url\":\"\",\"venue\":\"Conf. on Human-Robot Interaction, pages 317\\u2013324,\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1785853\",\"name\":\"Oliver Kroemer\"},{\"authorId\":\"40143841\",\"name\":\"R. Detry\"},{\"authorId\":\"1772389\",\"name\":\"J. Piater\"},{\"authorId\":\"145197867\",\"name\":\"Jan Peters\"}],\"doi\":\"10.1016/j.robot.2010.06.001\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"54ada0ba8661a086077e6c705facf2a9217aedf9\",\"title\":\"Combining active learning and reactive control for robot grasping\",\"url\":\"https://www.semanticscholar.org/paper/54ada0ba8661a086077e6c705facf2a9217aedf9\",\"venue\":\"Robotics Auton. Syst.\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1492009633\",\"name\":\"Patrick J. Roa\"}],\"doi\":\"10.1023/A:1017153816538\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"8e6d789ee714d29c9b5156ba9d61b2170d7a315f\",\"title\":\"Volume 8\",\"url\":\"https://www.semanticscholar.org/paper/8e6d789ee714d29c9b5156ba9d61b2170d7a315f\",\"venue\":\"\",\"year\":1998},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Bradley Hayes\"},{\"authorId\":null,\"name\":\"Brian Scassellati. Discovering task constraints through observation\"},{\"authorId\":null,\"name\":\"active learning\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In 2014 IEEE/RSJ Int\",\"url\":\"\",\"venue\":\"Conf. on Intelligent Robots and Systems, pages 4442\\u20134449,\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Kalesha Bullard\"},{\"authorId\":null,\"name\":\"Andrea L Thomaz\"},{\"authorId\":null,\"name\":\"Sonia Chernova. Towards intelligent arbitration of diver queries\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"url\":\"\",\"venue\":\"pages 6049\\u20136056. IEEE,\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30325272\",\"name\":\"Bradley Hayes\"},{\"authorId\":\"1792053\",\"name\":\"B. Scassellati\"}],\"doi\":\"10.1109/IROS.2014.6943191\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"79fe2a3779040b628b32488fd58d2a6c1db6fe0a\",\"title\":\"Discovering task constraints through observation and active learning\",\"url\":\"https://www.semanticscholar.org/paper/79fe2a3779040b628b32488fd58d2a6c1db6fe0a\",\"venue\":\"2014 IEEE/RSJ International Conference on Intelligent Robots and Systems\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Pieter Abbeel\"},{\"authorId\":null,\"name\":\"Andrew Y Ng. Apprenticeship learning via inverse reinforc learning\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"page 1\",\"url\":\"\",\"venue\":\"ACM,\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145258674\",\"name\":\"K. Lai\"},{\"authorId\":\"144651486\",\"name\":\"L. Bo\"},{\"authorId\":\"46426476\",\"name\":\"X. Ren\"},{\"authorId\":\"145197953\",\"name\":\"D. Fox\"}],\"doi\":\"10.1109/ICRA.2011.5980382\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"055fec9810fe1e98944a229303b0000afbb47b31\",\"title\":\"A large-scale hierarchical multi-view RGB-D object dataset\",\"url\":\"https://www.semanticscholar.org/paper/055fec9810fe1e98944a229303b0000afbb47b31\",\"venue\":\"2011 IEEE International Conference on Robotics and Automation\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2665873\",\"name\":\"Jesse Thomason\"},{\"authorId\":\"2110665\",\"name\":\"A. Padmakumar\"},{\"authorId\":\"1715858\",\"name\":\"J. Sinapov\"},{\"authorId\":\"1802400\",\"name\":\"J. Hart\"},{\"authorId\":\"144848112\",\"name\":\"P. Stone\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"64ec55960fc450b3bcdd31f22d165b2a7d8d153e\",\"title\":\"Opportunistic Active Learning for Grounding Natural Language Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/64ec55960fc450b3bcdd31f22d165b2a7d8d153e\",\"venue\":\"CoRL\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35096370\",\"name\":\"M. Cakmak\"},{\"authorId\":\"1682788\",\"name\":\"A. Thomaz\"}],\"doi\":\"10.1145/2157689.2157693\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a0ec28b9c8267b7f72eb5da5313139f89ebd92d\",\"title\":\"Designing robot learners that ask good questions\",\"url\":\"https://www.semanticscholar.org/paper/8a0ec28b9c8267b7f72eb5da5313139f89ebd92d\",\"venue\":\"2012 7th ACM/IEEE International Conference on Human-Robot Interaction (HRI)\",\"year\":2012}],\"title\":\"Active Learning within Constrained Environments through Imitation of an Expert Questioner\",\"topics\":[{\"topic\":\"Active learning (machine learning)\",\"topicId\":\"9017\",\"url\":\"https://www.semanticscholar.org/topic/9017\"},{\"topic\":\"Concept learning\",\"topicId\":\"140286\",\"url\":\"https://www.semanticscholar.org/topic/140286\"},{\"topic\":\"Selection algorithm\",\"topicId\":\"65296\",\"url\":\"https://www.semanticscholar.org/topic/65296\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Optimization problem\",\"topicId\":\"12682\",\"url\":\"https://www.semanticscholar.org/topic/12682\"},{\"topic\":\"Sampling (signal processing)\",\"topicId\":\"7839\",\"url\":\"https://www.semanticscholar.org/topic/7839\"},{\"topic\":\"Baseline (configuration management)\",\"topicId\":\"3403\",\"url\":\"https://www.semanticscholar.org/topic/3403\"},{\"topic\":\"Computation\",\"topicId\":\"339\",\"url\":\"https://www.semanticscholar.org/topic/339\"},{\"topic\":\"Human\\u2013computer interaction\",\"topicId\":\"463\",\"url\":\"https://www.semanticscholar.org/topic/463\"},{\"topic\":\"Loss function\",\"topicId\":\"3650\",\"url\":\"https://www.semanticscholar.org/topic/3650\"}],\"url\":\"https://www.semanticscholar.org/paper/2bc6a9cafca9064dc04d58c1393d38208406f335\",\"venue\":\"IJCAI\",\"year\":2019}\n"