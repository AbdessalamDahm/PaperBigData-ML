"{\"abstract\":\"AI agents are being developed to support high stakes decision-making processes from driving cars to prescribing drugs, making it increasingly important for human users to understand their behavior. Policy summarization methods aim to convey strengths and weaknesses of such agents by demonstrating their behavior in a subset of informative states. Some policy summarization methods extract a summary that optimizes the ability to reconstruct the agent's policy under the assumption that users will deploy inverse reinforcement learning. In this paper, we explore the use of different models for extracting summaries. We introduce an imitation learning-based approach to policy summarization; we demonstrate through computational simulations that a mismatch between the model used to extract a summary and the model used to reconstruct the policy results in worse reconstruction quality; and we demonstrate through a human-subject study that people use different models to reconstruct policies in different contexts, and that matching the summary extraction model to these can improve performance. Together, our results suggest that it is important to carefully consider user models in policy summarization.\",\"arxivId\":\"1905.13271\",\"authors\":[{\"authorId\":\"46174418\",\"name\":\"Isaac Lage\",\"url\":\"https://www.semanticscholar.org/author/46174418\"},{\"authorId\":\"1419460082\",\"name\":\"Daphna Lifschitz\",\"url\":\"https://www.semanticscholar.org/author/1419460082\"},{\"authorId\":\"1388372395\",\"name\":\"Finale Doshi-Velez\",\"url\":\"https://www.semanticscholar.org/author/1388372395\"},{\"authorId\":\"2212554\",\"name\":\"Ofra Amir\",\"url\":\"https://www.semanticscholar.org/author/2212554\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":\"2002.11697\",\"authors\":[{\"authorId\":\"2500065\",\"name\":\"T. Chakraborti\"},{\"authorId\":\"2400282\",\"name\":\"S. Sreedharan\"},{\"authorId\":\"1740315\",\"name\":\"S. Kambhampati\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"502cce7207a00c4520e130116b9ff8c1a0ea559b\",\"title\":\"The Emerging Landscape of Explainable AI Planning and Decision Making\",\"url\":\"https://www.semanticscholar.org/paper/502cce7207a00c4520e130116b9ff8c1a0ea559b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2212554\",\"name\":\"Ofra Amir\"},{\"authorId\":\"1412069139\",\"name\":\"Finale Doshi-Velez\"},{\"authorId\":\"1707363\",\"name\":\"D. Sarne\"}],\"doi\":\"10.1007/s10458-019-09418-w\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"6062c3dcbef96bafd6c2167686e264955d48f508\",\"title\":\"Summarizing agent strategies\",\"url\":\"https://www.semanticscholar.org/paper/6062c3dcbef96bafd6c2167686e264955d48f508\",\"venue\":\"Autonomous Agents and Multi-Agent Systems\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1505826529\",\"name\":\"Alnour Alharin\"},{\"authorId\":\"32214450\",\"name\":\"Thanh-Nam Doan\"},{\"authorId\":\"46577324\",\"name\":\"Mina Sartipi\"}],\"doi\":\"10.1109/ACCESS.2020.3023394\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"05848f86b121d2534f9b089617bd23b92d23ecec\",\"title\":\"Reinforcement Learning Interpretation Methods: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/05848f86b121d2534f9b089617bd23b92d23ecec\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2500065\",\"name\":\"T. Chakraborti\"},{\"authorId\":\"2400282\",\"name\":\"S. Sreedharan\"},{\"authorId\":\"1740315\",\"name\":\"S. Kambhampati\"}],\"doi\":\"10.24963/ijcai.2020/661\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5a4bde5016f0d5cfeec3dae3b9f1903c359b6fca\",\"title\":\"The Emerging Landscape of Explainable Automated Planning & Decision Making\",\"url\":\"https://www.semanticscholar.org/paper/5a4bde5016f0d5cfeec3dae3b9f1903c359b6fca\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2400282\",\"name\":\"S. Sreedharan\"},{\"authorId\":\"152735970\",\"name\":\"S. Srivastava\"},{\"authorId\":\"1740315\",\"name\":\"S. Kambhampati\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3a143586dfb230297e940919d73d961d42b415d2\",\"title\":\"TLdR: Policy Summarization for Factored SSP Problems Using Temporal Abstractions\",\"url\":\"https://www.semanticscholar.org/paper/3a143586dfb230297e940919d73d961d42b415d2\",\"venue\":\"ICAPS\",\"year\":2020},{\"arxivId\":\"1912.09007\",\"authors\":[{\"authorId\":\"1744526\",\"name\":\"Pedro Sequeira\"},{\"authorId\":\"153749229\",\"name\":\"M. Gervasio\"}],\"doi\":\"10.1016/j.artint.2020.103367\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1eae60e6b6ceb393a896a6c827a08c4d338efcad\",\"title\":\"Interestingness Elements for Explainable Reinforcement Learning: Understanding Agents' Capabilities and Limitations\",\"url\":\"https://www.semanticscholar.org/paper/1eae60e6b6ceb393a896a6c827a08c4d338efcad\",\"venue\":\"Artif. Intell.\",\"year\":2020},{\"arxivId\":\"2005.08874\",\"authors\":[{\"authorId\":\"1492164746\",\"name\":\"T. Huber\"},{\"authorId\":\"3679611\",\"name\":\"Katharina Weitz\"},{\"authorId\":\"145428247\",\"name\":\"E. Andr\\u00e9\"},{\"authorId\":\"2212554\",\"name\":\"Ofra Amir\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"2c9ba5421964b64c2d0bd5a0e3503197c93184e8\",\"title\":\"Local and Global Explanations of Agent Behavior: Integrating Strategy Summaries with Saliency Maps\",\"url\":\"https://www.semanticscholar.org/paper/2c9ba5421964b64c2d0bd5a0e3503197c93184e8\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":173188342,\"doi\":\"10.24963/ijcai.2019/194\",\"fieldsOfStudy\":[\"Computer Science\",\"Mathematics\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"22e43e30bd23d08b549cb05ed2d6e15c5149928c\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"2212554\",\"name\":\"Ofra Amir\"},{\"authorId\":\"1388372395\",\"name\":\"Finale Doshi-Velez\"},{\"authorId\":\"1707363\",\"name\":\"D. Sarne\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"50a808f74f392b77b241c4c9a4b1fb6e6bbea17c\",\"title\":\"Agent Strategy Summarization\",\"url\":\"https://www.semanticscholar.org/paper/50a808f74f392b77b241c4c9a4b1fb6e6bbea17c\",\"venue\":\"AAMAS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Nathaniel D Daw\"},{\"authorId\":null,\"name\":\"Yael Niv\"},{\"authorId\":null,\"name\":\"Peter Dayan. Uncertainty-based competition between prefrontal\"},{\"authorId\":null,\"name\":\"dorsolateral striatal systems for behavioral control. Nature Neuroscience\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"8:1704 EP \",\"url\":\"\",\"venue\":\"11\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2189949\",\"name\":\"William\"},{\"authorId\":null,\"name\":\"E. GuroWSKI\"}],\"doi\":\"10.1126/science.3.71.712-a\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"552cf455a7bfa5a9cfb560c7423b33a0f257b6f0\",\"title\":\"Psychological Review\",\"url\":\"https://www.semanticscholar.org/paper/552cf455a7bfa5a9cfb560c7423b33a0f257b6f0\",\"venue\":\"\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34699434\",\"name\":\"A. Ng\"},{\"authorId\":\"145107462\",\"name\":\"S. Russell\"}],\"doi\":\"10.2460/AJVR.67.2.323\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b05b67aca720d0bc39bc9afad02a19f522c7a1bc\",\"title\":\"Algorithms for Inverse Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/b05b67aca720d0bc39bc9afad02a19f522c7a1bc\",\"venue\":\"ICML\",\"year\":2000},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145666607\",\"name\":\"B. Adams\"},{\"authorId\":\"48554501\",\"name\":\"H. T. Banks\"},{\"authorId\":\"143825649\",\"name\":\"M. Davidian\"},{\"authorId\":\"2014203\",\"name\":\"H. Kwon\"},{\"authorId\":\"145238954\",\"name\":\"H. T. Tran\"},{\"authorId\":\"40593049\",\"name\":\"Shannon N. Wynne\"},{\"authorId\":\"145136605\",\"name\":\"E. Rosenberg\"}],\"doi\":\"10.1016/J.CAM.2005.02.004\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5e4cb9a7ae81c203d5a3beff3a743118f0051ca8\",\"title\":\"HIV dynamics: Modeling, data analysis, and optimal treatment protocols\",\"url\":\"https://www.semanticscholar.org/paper/5e4cb9a7ae81c203d5a3beff3a743118f0051ca8\",\"venue\":\"\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"D Aha\"},{\"authorId\":null,\"name\":\"T Darrell\"},{\"authorId\":null,\"name\":\"M Pazzani\"},{\"authorId\":null,\"name\":\"D Reid\"},{\"authorId\":null,\"name\":\"C Sammut\"},{\"authorId\":null,\"name\":\"P Stone\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Ijcai-17 workshop on explainable ai (xai)\",\"url\":\"\",\"venue\":\"IJCAI-17 Workshop on Explainable AI (XAI)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1832364\",\"name\":\"Xiaojin Zhu\"},{\"authorId\":\"1744700\",\"name\":\"Zoubin Ghahramani\"},{\"authorId\":\"1739581\",\"name\":\"J. Lafferty\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"125842668eab7decac136db8a59d392dc5e4e395\",\"title\":\"Semi-Supervised Learning Using Gaussian Fields and Harmonic Functions\",\"url\":\"https://www.semanticscholar.org/paper/125842668eab7decac136db8a59d392dc5e4e395\",\"venue\":\"ICML\",\"year\":2003},{\"arxivId\":\"1805.07687\",\"authors\":[{\"authorId\":\"47627548\",\"name\":\"Daniel S. Brown\"},{\"authorId\":\"2791038\",\"name\":\"S. Niekum\"}],\"doi\":\"10.1609/aaai.v33i01.33017749\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2417d4271a47c9235b75b1a5239d704be8198c9c\",\"title\":\"Machine Teaching for Inverse Reinforcement Learning: Algorithms and Applications\",\"url\":\"https://www.semanticscholar.org/paper/2417d4271a47c9235b75b1a5239d704be8198c9c\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1391884385\",\"name\":\"Chris L. Baker\"},{\"authorId\":\"2276622\",\"name\":\"R. Saxe\"},{\"authorId\":\"152685200\",\"name\":\"Joshua B. Tenenbaum\"}],\"doi\":\"10.1016/j.cognition.2009.07.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7dd51cef9bd43d495a12d10b7d0846f9bd60d9fa\",\"title\":\"Action understanding as inverse planning\",\"url\":\"https://www.semanticscholar.org/paper/7dd51cef9bd43d495a12d10b7d0846f9bd60d9fa\",\"venue\":\"Cognition\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145489534\",\"name\":\"Phillip Taylor\"},{\"authorId\":\"144482645\",\"name\":\"N. Griffiths\"},{\"authorId\":\"33473374\",\"name\":\"L. Barakat\"},{\"authorId\":\"145116379\",\"name\":\"S. Miles\"}],\"doi\":\"10.5555/3237383\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"0d075226bf44899d8d86abb8b07a2e83c18fd65d\",\"title\":\"Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems\",\"url\":\"https://www.semanticscholar.org/paper/0d075226bf44899d8d86abb8b07a2e83c18fd65d\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21161348\",\"name\":\"Chris L. Baker\"},{\"authorId\":\"2276622\",\"name\":\"R. Saxe\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"58eee36a6e0c59622d800ae4131c29b96f1595c8\",\"title\":\"Bayesian Theory of Mind: Modeling Joint Belief-Desire Attribution\",\"url\":\"https://www.semanticscholar.org/paper/58eee36a6e0c59622d800ae4131c29b96f1595c8\",\"venue\":\"CogSci\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jasper van der Waa\"},{\"authorId\":null,\"name\":\"Jurriaan van Diggelen\"},{\"authorId\":null,\"name\":\"Karel van den Bosch\"},{\"authorId\":null,\"name\":\"Mark A. Neerincx. Contrastive explanations for reinforc consequences\"}],\"doi\":null,\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"CoRR\",\"url\":\"\",\"venue\":\"abs/1807.08706,\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Sandy H. Huang\"},{\"authorId\":null,\"name\":\"David Held\"},{\"authorId\":null,\"name\":\"Pieter Abbeel\"},{\"authorId\":null,\"name\":\"Anca D. Dragan. Enabling robots to communicate their objectives\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"CoRR\",\"url\":\"\",\"venue\":\"abs/1702.03465,\",\"year\":2017},{\"arxivId\":\"1810.08174\",\"authors\":[{\"authorId\":\"2064588\",\"name\":\"Sandy H. Huang\"},{\"authorId\":\"144383716\",\"name\":\"Kush Bhatia\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"},{\"authorId\":\"2745001\",\"name\":\"Anca D. Dragan\"}],\"doi\":\"10.1109/IROS.2018.8593649\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"6001948ea46812c4f1c0a050957377853d4fb44b\",\"title\":\"Establishing Appropriate Trust via Critical States\",\"url\":\"https://www.semanticscholar.org/paper/6001948ea46812c4f1c0a050957377853d4fb44b\",\"venue\":\"2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1751167\",\"name\":\"D. Ernst\"},{\"authorId\":\"144335262\",\"name\":\"G. Stan\"},{\"authorId\":\"144769811\",\"name\":\"J. Gon\\u00e7alves\"},{\"authorId\":\"1695713\",\"name\":\"L. Wehenkel\"}],\"doi\":\"10.1109/CDC.2006.377527\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"353ff4eec5b8b0268a4d3292d102f9f1d601222b\",\"title\":\"Clinical data based optimal STI strategies for HIV: a reinforcement learning approach\",\"url\":\"https://www.semanticscholar.org/paper/353ff4eec5b8b0268a4d3292d102f9f1d601222b\",\"venue\":\"Proceedings of the 45th IEEE Conference on Decision and Control\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064588\",\"name\":\"Sandy H. Huang\"},{\"authorId\":\"145641013\",\"name\":\"David Held\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"},{\"authorId\":\"2745001\",\"name\":\"Anca D. Dragan\"}],\"doi\":\"10.1007/S10514-018-9771-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0f892bea584ad2fbde753639f1a531cfa9f72753\",\"title\":\"Enabling robots to communicate their objectives\",\"url\":\"https://www.semanticscholar.org/paper/0f892bea584ad2fbde753639f1a531cfa9f72753\",\"venue\":\"Auton. Robots\",\"year\":2019},{\"arxivId\":\"1706.07269\",\"authors\":[{\"authorId\":\"144658641\",\"name\":\"T. Miller\"}],\"doi\":\"10.1016/J.ARTINT.2018.07.007\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e89dfa306723e8ef031765e9c44e5f6f94fd8fda\",\"title\":\"Explanation in Artificial Intelligence: Insights from the Social Sciences\",\"url\":\"https://www.semanticscholar.org/paper/e89dfa306723e8ef031765e9c44e5f6f94fd8fda\",\"venue\":\"Artif. Intell.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1689610\",\"name\":\"G. Sagerer\"},{\"authorId\":\"1752970\",\"name\":\"M. Imai\"},{\"authorId\":\"2301161\",\"name\":\"Tony Belpaeme\"},{\"authorId\":\"1682788\",\"name\":\"A. Thomaz\"}],\"doi\":\"10.1145/2559636\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d83fdb161563ffabb32e0174c67eb877060fec21\",\"title\":\"Proceedings of the 2014 ACM/IEEE international conference on Human-robot interaction\",\"url\":\"https://www.semanticscholar.org/paper/d83fdb161563ffabb32e0174c67eb877060fec21\",\"venue\":\"HRI 2014\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1753269\",\"name\":\"Brian D. Ziebart\"},{\"authorId\":\"34961461\",\"name\":\"Andrew L. Maas\"},{\"authorId\":\"1756566\",\"name\":\"J. Bagnell\"},{\"authorId\":\"144021446\",\"name\":\"Anind K. Dey\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"11b6bdfe36c48b11367b27187da11d95892f0361\",\"title\":\"Maximum Entropy Inverse Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/11b6bdfe36c48b11367b27187da11d95892f0361\",\"venue\":\"AAAI\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Sam Greydanus\"},{\"authorId\":null,\"name\":\"Anurag Koul\"},{\"authorId\":null,\"name\":\"Jonathan Dodge\"},{\"authorId\":null,\"name\":\"Alan Fern. Visualizing\"},{\"authorId\":null,\"name\":\"understanding atari agents\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"arXiv\",\"url\":\"\",\"venue\":\"abs/1711.00138,\",\"year\":2017},{\"arxivId\":\"1709.08071\",\"authors\":[{\"authorId\":\"1961238\",\"name\":\"Stefano V. Albrecht\"},{\"authorId\":\"144848112\",\"name\":\"P. Stone\"}],\"doi\":\"10.1016/j.artint.2018.01.002\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9bf2d6526b480f95fed9b0e0a1125cf07d11e01d\",\"title\":\"Autonomous agents modelling other agents: A comprehensive survey and open problems\",\"url\":\"https://www.semanticscholar.org/paper/9bf2d6526b480f95fed9b0e0a1125cf07d11e01d\",\"venue\":\"Artif. Intell.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1492009633\",\"name\":\"Patrick J. Roa\"}],\"doi\":\"10.1023/A:1017153816538\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8e6d789ee714d29c9b5156ba9d61b2170d7a315f\",\"title\":\"Volume 8\",\"url\":\"https://www.semanticscholar.org/paper/8e6d789ee714d29c9b5156ba9d61b2170d7a315f\",\"venue\":\"\",\"year\":1998},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Isaac Lage\"},{\"authorId\":null,\"name\":\"Daphna Lifschitz\"},{\"authorId\":null,\"name\":\"Finale DoshiVelez\"},{\"authorId\":null,\"name\":\"Ofra Amir. Exploring computational user models for agen summarization\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"arXiv\",\"url\":\"\",\"venue\":\"abs/1905.13271,\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144919054\",\"name\":\"M. Brainin\"}],\"doi\":\"10.1016/j.jns.2019.10.016\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"36db3a800f96f160b1a1b1ff9997af0d773f5006\",\"title\":\"Cognition\",\"url\":\"https://www.semanticscholar.org/paper/36db3a800f96f160b1a1b1ff9997af0d773f5006\",\"venue\":\"Journal of the Neurological Sciences\",\"year\":2019},{\"arxivId\":\"1711.00138\",\"authors\":[{\"authorId\":\"14851288\",\"name\":\"S. Greydanus\"},{\"authorId\":\"40135938\",\"name\":\"Anurag Koul\"},{\"authorId\":\"48983294\",\"name\":\"J. Dodge\"},{\"authorId\":\"145841336\",\"name\":\"A. Fern\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b4e669bae43216cb0e77836a411b88dea4bb6034\",\"title\":\"Visualizing and Understanding Atari Agents\",\"url\":\"https://www.semanticscholar.org/paper/b4e669bae43216cb0e77836a411b88dea4bb6034\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Xiaojin Zhu\"},{\"authorId\":null,\"name\":\"John Lafferty\"},{\"authorId\":null,\"name\":\"Zoubin Ghahramani. Combining active learning\"},{\"authorId\":null,\"name\":\"semi-supervised learning using gaussian fields\"},{\"authorId\":null,\"name\":\"harmonic functions\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"ICML 2003 Workshop on The Continuum from Labeled to Unlabeled Data in Machine Learning and Data Mining\",\"url\":\"\",\"venue\":\"pages 58\\u201365,\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"BM Adams\"},{\"authorId\":null,\"name\":\"HT Banks\"},{\"authorId\":null,\"name\":\"M Davidian\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Hee-Dae Kwon\",\"url\":\"\",\"venue\":\"HT Tran, SN Wynne, and ES Rosenberg. Hiv dynamics: modeling, data analysis, and optimal treatment protocols. Journal of Computational and Applied Mathematics, 184(1):10\\u201349\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1832364\",\"name\":\"Xiaojin Zhu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f83ca18f3834d45a70e9b54578e2c33870dde67d\",\"title\":\"Machine Teaching: An Inverse Problem to Machine Learning and an Approach Toward Optimal Education\",\"url\":\"https://www.semanticscholar.org/paper/f83ca18f3834d45a70e9b54578e2c33870dde67d\",\"venue\":\"AAAI\",\"year\":2015},{\"arxivId\":\"1805.08966\",\"authors\":[{\"authorId\":\"3115147\",\"name\":\"Ramya Ramakrishnan\"},{\"authorId\":\"1783184\",\"name\":\"Ece Kamar\"},{\"authorId\":\"1780951\",\"name\":\"Debadeepta Dey\"},{\"authorId\":\"143873972\",\"name\":\"J. Shah\"},{\"authorId\":\"145479841\",\"name\":\"E. Horvitz\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"bac4aaac3d66b783e9116f8a264971059fe0d4ec\",\"title\":\"Discovering Blind Spots in Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/bac4aaac3d66b783e9116f8a264971059fe0d4ec\",\"venue\":\"AAMAS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66381457\",\"name\":\"X. Zhu\"},{\"authorId\":\"1739581\",\"name\":\"J. Lafferty\"},{\"authorId\":\"1744700\",\"name\":\"Zoubin Ghahramani\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8b4a99762d33927e4db312082f9552cce1df9182\",\"title\":\"Combining active learning and semi-supervised learning using Gaussian fields and harmonic functions\",\"url\":\"https://www.semanticscholar.org/paper/8b4a99762d33927e4db312082f9552cce1df9182\",\"venue\":\"ICML 2003\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Sandy H Huang\"},{\"authorId\":null,\"name\":\"Kush Bhatia\"},{\"authorId\":null,\"name\":\"Pieter Abbeel\"},{\"authorId\":null,\"name\":\"Anca D Dragan. Establishing appropriate trust via criti states\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"url\":\"\",\"venue\":\"pages 3929\\u20133936. IEEE,\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jasper van der Waa\"},{\"authorId\":null,\"name\":\"Jurriaan van Diggelen\"},{\"authorId\":null,\"name\":\"Karel van den Bosch\"},{\"authorId\":null,\"name\":\"Mark A. Neerincx. Contrastive explanations for reinforc consequences\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"arXiv\",\"url\":\"\",\"venue\":\"abs/1807.08706,\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Andrew Y Ng\"},{\"authorId\":null,\"name\":\"Stuart J Russell\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and Marguerite M . Shaffer . Context theory of classification learning\",\"url\":\"\",\"venue\":\"\",\"year\":1978},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1735303\",\"name\":\"J. Broekens\"},{\"authorId\":\"33694882\",\"name\":\"M. Harbers\"},{\"authorId\":\"1751831\",\"name\":\"K. Hindriks\"},{\"authorId\":\"1747540\",\"name\":\"K. Bosch\"},{\"authorId\":\"1689001\",\"name\":\"C. Jonker\"},{\"authorId\":\"1691228\",\"name\":\"J. Meyer\"}],\"doi\":\"10.1007/978-3-642-16178-0_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"17de8eda76d3c06d8509fcafa6ca2f729ae1940e\",\"title\":\"Do You Get It? User-Evaluated Explainable BDI Agents\",\"url\":\"https://www.semanticscholar.org/paper/17de8eda76d3c06d8509fcafa6ca2f729ae1940e\",\"venue\":\"MATES\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39307794\",\"name\":\"M. Lomas\"},{\"authorId\":\"144986956\",\"name\":\"R. Chevalier\"},{\"authorId\":\"145085461\",\"name\":\"E. V. Cross\"},{\"authorId\":\"39320661\",\"name\":\"R. C. Garrett\"},{\"authorId\":\"143826110\",\"name\":\"John Hoare\"},{\"authorId\":\"2659502\",\"name\":\"Michael Kopack\"}],\"doi\":\"10.1145/2157689.2157748\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"11f5ce854672bc842cae40156213c02d65286e98\",\"title\":\"Explaining robot actions\",\"url\":\"https://www.semanticscholar.org/paper/11f5ce854672bc842cae40156213c02d65286e98\",\"venue\":\"2012 7th ACM/IEEE International Conference on Human-Robot Interaction (HRI)\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ramya Ramakrishnan\"},{\"authorId\":null,\"name\":\"Ece Kamar\"},{\"authorId\":null,\"name\":\"Debadeepta Dey\"},{\"authorId\":null,\"name\":\"Julie A. Shah\"},{\"authorId\":null,\"name\":\"Eric Horvitz. Discovering blind spots in reinforcement learning\"}],\"doi\":null,\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"CoRR\",\"url\":\"\",\"venue\":\"abs/1805.08966,\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"88122878\",\"name\":\"D. Amir\"},{\"authorId\":\"2212554\",\"name\":\"Ofra Amir\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f611acc0ee253f5903dafe30bbcd65f823374448\",\"title\":\"HIGHLIGHTS: Summarizing Agent Behavior to People\",\"url\":\"https://www.semanticscholar.org/paper/f611acc0ee253f5903dafe30bbcd65f823374448\",\"venue\":\"AAMAS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5886094\",\"name\":\"P. Cochat\"},{\"authorId\":\"13267685\",\"name\":\"L. Vaucoret\"},{\"authorId\":\"31455512\",\"name\":\"J. Sarles\"}],\"doi\":\"10.1016/j.arcped.2012.01.013\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10d85561e4aafc516d10064f30dff05b41f70afe\",\"title\":\"[Et al].\",\"url\":\"https://www.semanticscholar.org/paper/10d85561e4aafc516d10064f30dff05b41f70afe\",\"venue\":\"Archives de pediatrie : organe officiel de la Societe francaise de pediatrie\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145848473\",\"name\":\"T. Dodson\"},{\"authorId\":\"143999398\",\"name\":\"Nicholas Mattei\"},{\"authorId\":\"1715289\",\"name\":\"J. Goldsmith\"}],\"doi\":\"10.1007/978-3-642-24873-3_4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0180c56bfbfb21243f8605e4c6f6aab2779d3ef0\",\"title\":\"A Natural Language Argumentation Interface for Explanation Generation in Markov Decision Processes\",\"url\":\"https://www.semanticscholar.org/paper/0180c56bfbfb21243f8605e4c6f6aab2779d3ef0\",\"venue\":\"ExaCt\",\"year\":2011},{\"arxivId\":\"1807.08706\",\"authors\":[{\"authorId\":\"37066124\",\"name\":\"J. V. D. Waa\"},{\"authorId\":\"1754414\",\"name\":\"J. Diggelen\"},{\"authorId\":\"1747540\",\"name\":\"K. Bosch\"},{\"authorId\":\"1784286\",\"name\":\"M. Neerincx\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"b618b5f212d8b93e8bb866a1e1ce18079946723b\",\"title\":\"Contrastive Explanations for Reinforcement Learning in terms of Expected Consequences\",\"url\":\"https://www.semanticscholar.org/paper/b618b5f212d8b93e8bb866a1e1ce18079946723b\",\"venue\":\"IJCAI 2018\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ramya Ramakrishnan\"},{\"authorId\":null,\"name\":\"Ece Kamar\"},{\"authorId\":null,\"name\":\"Debadeepta Dey\"},{\"authorId\":null,\"name\":\"Julie A. Shah\"},{\"authorId\":null,\"name\":\"Eric Horvitz. Discovering blind spots in reinforcement learning\"}],\"doi\":null,\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"arXiv\",\"url\":\"\",\"venue\":\"abs/1805.08966,\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Thomas Dodson\"},{\"authorId\":null,\"name\":\"Nicholas Mattei\"},{\"authorId\":null,\"name\":\"Judy Goldsmith. A natural language argumentation interf DecisionTheory\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"pages 42\\u201355\",\"url\":\"\",\"venue\":\"Springer,\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2695960\",\"name\":\"O. Khan\"},{\"authorId\":\"1807041\",\"name\":\"P. Poupart\"},{\"authorId\":\"145179737\",\"name\":\"J. Black\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e1925eb6104b94d487e51f5710f697a08eec2778\",\"title\":\"Minimal Sufficient Explanations for Factored Markov Decision Processes\",\"url\":\"https://www.semanticscholar.org/paper/e1925eb6104b94d487e51f5710f697a08eec2778\",\"venue\":\"ICAPS\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34923062\",\"name\":\"M. E. Foster\"},{\"authorId\":\"2695814\",\"name\":\"E. Bard\"},{\"authorId\":\"2988427\",\"name\":\"M. Guhe\"},{\"authorId\":\"3252072\",\"name\":\"R. L. Hill\"},{\"authorId\":\"3263707\",\"name\":\"J. Oberlander\"},{\"authorId\":\"143873832\",\"name\":\"A. Knoll\"}],\"doi\":\"10.1145/1349822.1349861\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4cb1ddc9d85a8d4f9743f7c812d3f6d683a8b0f6\",\"title\":\"The roles of haptic-ostensive referring expressions in cooperative, task-based human-robot dialogue\",\"url\":\"https://www.semanticscholar.org/paper/4cb1ddc9d85a8d4f9743f7c812d3f6d683a8b0f6\",\"venue\":\"2008 3rd ACM/IEEE International Conference on Human-Robot Interaction (HRI)\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Sandy H. Huang\"},{\"authorId\":null,\"name\":\"David Held\"},{\"authorId\":null,\"name\":\"Pieter Abbeel\"},{\"authorId\":null,\"name\":\"Anca D. Dragan. Enabling robots to communicate their objectives\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"arXiv\",\"url\":\"\",\"venue\":\"abs/1702.03465,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Xiaojin Zhu\"},{\"authorId\":null,\"name\":\"Zoubin Ghahramani\"},{\"authorId\":null,\"name\":\"John Lafferty. Semi-supervised learning using gaussian fields\"},{\"authorId\":null,\"name\":\"harmonic functions. In Proceedings of the Twentieth Interna Learning\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"ICML\\u201903\",\"url\":\"\",\"venue\":\"pages 912\\u2013919. AAAI Press,\",\"year\":2003}],\"title\":\"Exploring Computational User Models for Agent Policy Summarization\",\"topics\":[{\"topic\":\"Reinforcement learning\",\"topicId\":\"2557\",\"url\":\"https://www.semanticscholar.org/topic/2557\"},{\"topic\":\"Computation\",\"topicId\":\"339\",\"url\":\"https://www.semanticscholar.org/topic/339\"},{\"topic\":\"Policy-based design\",\"topicId\":\"288890\",\"url\":\"https://www.semanticscholar.org/topic/288890\"},{\"topic\":\"Information\",\"topicId\":\"185548\",\"url\":\"https://www.semanticscholar.org/topic/185548\"},{\"topic\":\"Simulation\",\"topicId\":\"194\",\"url\":\"https://www.semanticscholar.org/topic/194\"},{\"topic\":\"Subgroup\",\"topicId\":\"40740\",\"url\":\"https://www.semanticscholar.org/topic/40740\"},{\"topic\":\"Autonomous car\",\"topicId\":\"642\",\"url\":\"https://www.semanticscholar.org/topic/642\"},{\"topic\":\"Decision Making\",\"topicId\":\"7782\",\"url\":\"https://www.semanticscholar.org/topic/7782\"},{\"topic\":\"Weakness\",\"topicId\":\"873\",\"url\":\"https://www.semanticscholar.org/topic/873\"},{\"topic\":\"Automatic summarization\",\"topicId\":\"36919\",\"url\":\"https://www.semanticscholar.org/topic/36919\"}],\"url\":\"https://www.semanticscholar.org/paper/22e43e30bd23d08b549cb05ed2d6e15c5149928c\",\"venue\":\"IJCAI\",\"year\":2019}\n"