"{\"abstract\":\"In reinforcement learning algorithms, leveraging multiple views of the environment can improve the learning of complicated policies. In multi-view environments, due to the fact that the views may frequently suffer from partial observability, their level of importance are often different. In this paper, we propose a deep reinforcement learning method and an attention mechanism in a multi-view environment. Each view can provide various representative information about the environment. Through our attention mechanism, our method generates a single feature representation of environment given its multiple views. It learns a policy to dynamically attend to each view based on its importance in the decision-making process. Through experiments, we show that our method outperforms its state-of-the-art baselines on TORCS racing car simulator and three other complex 3D environments with obstacles. We also provide experimental results to evaluate the performance of our method on noisy conditions and partial observation settings.\",\"arxivId\":\"1907.09466\",\"authors\":[{\"authorId\":\"50506129\",\"name\":\"E. Barati\",\"url\":\"https://www.semanticscholar.org/author/50506129\"},{\"authorId\":\"35265528\",\"name\":\"Xuewen Chen\",\"url\":\"https://www.semanticscholar.org/author/35265528\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":\"1910.08285\",\"authors\":[{\"authorId\":\"49140611\",\"name\":\"Minne Li\"},{\"authorId\":\"2466694\",\"name\":\"Lisheng Wu\"},{\"authorId\":\"1398842047\",\"name\":\"Haitham Bou-Ammar\"},{\"authorId\":\"49605774\",\"name\":\"Jun Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1e0c224181ca656528163d7d4d73119ca962e06a\",\"title\":\"Multi-View Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/1e0c224181ca656528163d7d4d73119ca962e06a\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50506129\",\"name\":\"E. Barati\"},{\"authorId\":\"2410994\",\"name\":\"Xue-wen Chen\"}],\"doi\":\"10.1145/3343031.3351037\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cf8a3f260fbe4ee104380437cd576a556dccd290\",\"title\":\"Critic-based Attention Network for Event-based Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/cf8a3f260fbe4ee104380437cd576a556dccd290\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1897677374\",\"name\":\"Juan Martinez-Piazuelo\"},{\"authorId\":\"97796305\",\"name\":\"Daniel E. Ochoa\"},{\"authorId\":\"2410760\",\"name\":\"N. Quijano\"},{\"authorId\":\"27224158\",\"name\":\"L. F. Giraldo\"}],\"doi\":\"10.1109/ACCESS.2020.3025194\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7e801b6e7afce2c5d464fbff5cc127f89a3c63df\",\"title\":\"A Multi-Critic Reinforcement Learning Method: An Application to Multi-Tank Water Systems\",\"url\":\"https://www.semanticscholar.org/paper/7e801b6e7afce2c5d464fbff5cc127f89a3c63df\",\"venue\":\"IEEE Access\",\"year\":2020}],\"corpusId\":198179508,\"doi\":\"10.24963/ijcai.2019/277\",\"fieldsOfStudy\":[\"Computer Science\",\"Mathematics\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"ddace5849601f7d8942c52bd6658f23b353df520\",\"references\":[{\"arxivId\":\"1707.02286\",\"authors\":[{\"authorId\":\"2801204\",\"name\":\"N. Heess\"},{\"authorId\":\"22216833\",\"name\":\"TB Dhruva\"},{\"authorId\":\"37118178\",\"name\":\"S. Sriram\"},{\"authorId\":\"144083287\",\"name\":\"Jay Lemmon\"},{\"authorId\":\"1879232\",\"name\":\"J. Merel\"},{\"authorId\":\"89504302\",\"name\":\"G. Wayne\"},{\"authorId\":\"2109481\",\"name\":\"Y. Tassa\"},{\"authorId\":\"1968210\",\"name\":\"T. Erez\"},{\"authorId\":\"47197117\",\"name\":\"Ziyu Wang\"},{\"authorId\":\"143648071\",\"name\":\"S. Eslami\"},{\"authorId\":\"3137672\",\"name\":\"Martin A. Riedmiller\"},{\"authorId\":\"145824029\",\"name\":\"D. Silver\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a762ae907b7dd71a59bd8bd98aba69dfe2de13a2\",\"title\":\"Emergence of Locomotion Behaviours in Rich Environments\",\"url\":\"https://www.semanticscholar.org/paper/a762ae907b7dd71a59bd8bd98aba69dfe2de13a2\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Gregory Palmer\"},{\"authorId\":null,\"name\":\"Karl Tuyls\"},{\"authorId\":null,\"name\":\"Daan Bloembergen\"},{\"authorId\":null,\"name\":\"Rahul Savani. Lenient multi-agent deep reinforcement learning\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In AAMAS\",\"url\":\"\",\"venue\":\"pages 443\\u2013451,\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699645\",\"name\":\"R. Sutton\"},{\"authorId\":\"1730590\",\"name\":\"A. Barto\"}],\"doi\":\"10.1109/TNN.1998.712192\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"97efafdb4a3942ab3efba53ded7413199f79c054\",\"title\":\"Reinforcement Learning: An Introduction\",\"url\":\"https://www.semanticscholar.org/paper/97efafdb4a3942ab3efba53ded7413199f79c054\",\"venue\":\"IEEE Transactions on Neural Networks\",\"year\":2005},{\"arxivId\":\"1409.0473\",\"authors\":[{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"title\":\"Neural Machine Translation by Jointly Learning to Align and Translate\",\"url\":\"https://www.semanticscholar.org/paper/fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Bernhard Wymann\"},{\"authorId\":null,\"name\":\"Eric Espi\\u00e9\"},{\"authorId\":null,\"name\":\"Christophe Guionneau\"},{\"authorId\":null,\"name\":\"Christos Dimitrakakis\"},{\"authorId\":null,\"name\":\"R\\u00e9mi Coulom\"},{\"authorId\":null,\"name\":\"Andrew Sumner. Torcs\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"the open racing car simulator\",\"url\":\"\",\"venue\":\"Software available at http://torcs. sourceforge. net, pages 1\\u20135,\",\"year\":2000},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Nikos Barbalios\"},{\"authorId\":null,\"name\":\"Panagiotis Tzionas. A robust approach for multi-agent natural algorithms\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Applied Soft Computing\",\"url\":\"\",\"venue\":\"18:12\\u201324,\",\"year\":2014},{\"arxivId\":\"1905.03985\",\"authors\":[{\"authorId\":\"50506129\",\"name\":\"E. Barati\"},{\"authorId\":\"35265528\",\"name\":\"Xuewen Chen\"},{\"authorId\":\"34774354\",\"name\":\"Z. Zhong\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a3a7a8c68b837ad4cab0a9e5a1bf2ef69e82f8c8\",\"title\":\"Attention-based Deep Reinforcement Learning for Multi-view Environments\",\"url\":\"https://www.semanticscholar.org/paper/a3a7a8c68b837ad4cab0a9e5a1bf2ef69e82f8c8\",\"venue\":\"AAMAS\",\"year\":2019},{\"arxivId\":\"1703.06182\",\"authors\":[{\"authorId\":\"3093004\",\"name\":\"Shayegan Omidshafiei\"},{\"authorId\":\"3140253\",\"name\":\"Jason Pazis\"},{\"authorId\":\"34903901\",\"name\":\"Chris Amato\"},{\"authorId\":\"1713935\",\"name\":\"J. How\"},{\"authorId\":\"46956290\",\"name\":\"J. Vian\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b68673a166f9c620e13152f63d358fb8fce7850d\",\"title\":\"Deep Decentralized Multi-task Multi-Agent Reinforcement Learning under Partial Observability\",\"url\":\"https://www.semanticscholar.org/paper/b68673a166f9c620e13152f63d358fb8fce7850d\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Marco A Wiering\"},{\"authorId\":null,\"name\":\"Hado Van Hasselt. Ensemble algorithms in reinforcement learning\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"SMC\",\"url\":\"\",\"venue\":\"38(4):930\\u2013936,\",\"year\":2008},{\"arxivId\":\"1801.00690\",\"authors\":[{\"authorId\":\"2109481\",\"name\":\"Y. Tassa\"},{\"authorId\":\"2895238\",\"name\":\"Yotam Doron\"},{\"authorId\":\"50654556\",\"name\":\"Alistair Muldal\"},{\"authorId\":\"1968210\",\"name\":\"T. Erez\"},{\"authorId\":\"3422141\",\"name\":\"Y. Li\"},{\"authorId\":\"40550616\",\"name\":\"D. Casas\"},{\"authorId\":\"2508525\",\"name\":\"D. Budden\"},{\"authorId\":\"2799799\",\"name\":\"Abbas Abdolmaleki\"},{\"authorId\":\"1879232\",\"name\":\"J. Merel\"},{\"authorId\":\"8455031\",\"name\":\"Andrew Lefrancq\"},{\"authorId\":\"2542999\",\"name\":\"T. Lillicrap\"},{\"authorId\":\"3137672\",\"name\":\"Martin A. Riedmiller\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a9a3ed69c94a3e1c08ef1f833d9199f57736238b\",\"title\":\"DeepMind Control Suite\",\"url\":\"https://www.semanticscholar.org/paper/a9a3ed69c94a3e1c08ef1f833d9199f57736238b\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1804.08617\",\"authors\":[{\"authorId\":\"1403998955\",\"name\":\"Gabriel Barth-Maron\"},{\"authorId\":\"3243579\",\"name\":\"M. W. Hoffman\"},{\"authorId\":\"2508525\",\"name\":\"D. Budden\"},{\"authorId\":\"2605877\",\"name\":\"W. Dabney\"},{\"authorId\":\"48257711\",\"name\":\"Dan Horgan\"},{\"authorId\":\"22216833\",\"name\":\"TB Dhruva\"},{\"authorId\":\"50654556\",\"name\":\"Alistair Muldal\"},{\"authorId\":\"2801204\",\"name\":\"N. Heess\"},{\"authorId\":\"2542999\",\"name\":\"T. Lillicrap\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d355e339298fc2ab920688c1709d4ba6476a2bc6\",\"title\":\"Distributed Distributional Deterministic Policy Gradients\",\"url\":\"https://www.semanticscholar.org/paper/d355e339298fc2ab920688c1709d4ba6476a2bc6\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"David Silver\"},{\"authorId\":null,\"name\":\"Guy Lever\"},{\"authorId\":null,\"name\":\"Nicolas Heess\"},{\"authorId\":null,\"name\":\"Thomas Degris\"},{\"authorId\":null,\"name\":\"Daan Wierstra\"},{\"authorId\":null,\"name\":\"Martin Riedmiller. Deterministic policy gradient algorithms\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In ICML\",\"url\":\"\",\"venue\":\"pages 387\\u2013395,\",\"year\":2014},{\"arxivId\":\"1803.00933\",\"authors\":[{\"authorId\":\"48257711\",\"name\":\"Dan Horgan\"},{\"authorId\":\"34660073\",\"name\":\"John Quan\"},{\"authorId\":\"2508525\",\"name\":\"D. Budden\"},{\"authorId\":\"1403998955\",\"name\":\"Gabriel Barth-Maron\"},{\"authorId\":\"39357484\",\"name\":\"Matteo Hessel\"},{\"authorId\":\"7634925\",\"name\":\"H. V. Hasselt\"},{\"authorId\":\"145824029\",\"name\":\"D. Silver\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1f08598381af9146d0fd9a61b30d0e51a7331689\",\"title\":\"Distributed Prioritized Experience Replay\",\"url\":\"https://www.semanticscholar.org/paper/1f08598381af9146d0fd9a61b30d0e51a7331689\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1603.04467\",\"authors\":[{\"authorId\":\"145832079\",\"name\":\"M. Abadi\"},{\"authorId\":\"145984138\",\"name\":\"A. Agarwal\"},{\"authorId\":\"144758007\",\"name\":\"P. Barham\"},{\"authorId\":\"2445241\",\"name\":\"E. Brevdo\"},{\"authorId\":\"2545358\",\"name\":\"Z. Chen\"},{\"authorId\":\"48738717\",\"name\":\"Craig Citro\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"36347083\",\"name\":\"Andy Davis\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"},{\"authorId\":\"145139947\",\"name\":\"M. Devin\"},{\"authorId\":\"1780892\",\"name\":\"Sanjay Ghemawat\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"3384453\",\"name\":\"A. Harp\"},{\"authorId\":\"145659929\",\"name\":\"Geoffrey Irving\"},{\"authorId\":\"2090818\",\"name\":\"M. Isard\"},{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"1944541\",\"name\":\"R. J\\u00f3zefowicz\"},{\"authorId\":\"40527594\",\"name\":\"L. Kaiser\"},{\"authorId\":\"1942300\",\"name\":\"M. Kudlur\"},{\"authorId\":\"3369421\",\"name\":\"Josh Levenberg\"},{\"authorId\":\"143767989\",\"name\":\"Dan Man\\u00e9\"},{\"authorId\":\"3089272\",\"name\":\"Rajat Monga\"},{\"authorId\":\"144375552\",\"name\":\"Sherry Moore\"},{\"authorId\":\"20154699\",\"name\":\"D. Murray\"},{\"authorId\":\"153301219\",\"name\":\"Chris Olah\"},{\"authorId\":\"144927151\",\"name\":\"Mike Schuster\"},{\"authorId\":\"1789737\",\"name\":\"Jonathon Shlens\"},{\"authorId\":\"32163737\",\"name\":\"B. Steiner\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"35210462\",\"name\":\"Kunal Talwar\"},{\"authorId\":\"2080690\",\"name\":\"P. Tucker\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"38062095\",\"name\":\"V. Vasudevan\"},{\"authorId\":\"1765169\",\"name\":\"F. Vi\\u00e9gas\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"47941411\",\"name\":\"Pete Warden\"},{\"authorId\":\"145233583\",\"name\":\"M. Wattenberg\"},{\"authorId\":\"35078078\",\"name\":\"Martin Wicke\"},{\"authorId\":\"47112093\",\"name\":\"Y. Yu\"},{\"authorId\":\"2777763\",\"name\":\"X. Zheng\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9c9d7247f8c51ec5a02b0d911d1d7b9e8160495d\",\"title\":\"TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems\",\"url\":\"https://www.semanticscholar.org/paper/9c9d7247f8c51ec5a02b0d911d1d7b9e8160495d\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1812.11794\",\"authors\":[{\"authorId\":\"153387571\",\"name\":\"T. Nguyen\"},{\"authorId\":\"49694023\",\"name\":\"Ngoc Duy Nguyen\"},{\"authorId\":\"1743136\",\"name\":\"S. Nahavandi\"}],\"doi\":\"10.1109/TCYB.2020.2977374\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"28e66d188efbd0bbb64242b611d96769be910c15\",\"title\":\"Deep Reinforcement Learning for Multiagent Systems: A Review of Challenges, Solutions, and Applications\",\"url\":\"https://www.semanticscholar.org/paper/28e66d188efbd0bbb64242b611d96769be910c15\",\"venue\":\"IEEE Transactions on Cybernetics\",\"year\":2020},{\"arxivId\":\"1703.10069\",\"authors\":[{\"authorId\":\"144189270\",\"name\":\"P. Peng\"},{\"authorId\":\"50531782\",\"name\":\"Ying Wen\"},{\"authorId\":\"49307876\",\"name\":\"Y. Yang\"},{\"authorId\":\"145001852\",\"name\":\"Quan Yuan\"},{\"authorId\":\"50369253\",\"name\":\"Zhenkun Tang\"},{\"authorId\":\"50468018\",\"name\":\"Haitao Long\"},{\"authorId\":\"95115833\",\"name\":\"J. Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"76dfb1ab698963f3776fe894b3743db4a5419a5f\",\"title\":\"Multiagent Bidirectionally-Coordinated Nets: Emergence of Human-level Coordination in Learning to Play StarCraft Combat Games\",\"url\":\"https://www.semanticscholar.org/paper/76dfb1ab698963f3776fe894b3743db4a5419a5f\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1710.03748\",\"authors\":[{\"authorId\":\"1858169\",\"name\":\"Trapit Bansal\"},{\"authorId\":\"2713380\",\"name\":\"Jakub W. Pachocki\"},{\"authorId\":\"2700360\",\"name\":\"S. Sidor\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"2080746\",\"name\":\"Igor Mordatch\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c335ff618991f0a4cdde09271284172a7e5f6b7f\",\"title\":\"Emergent Complexity via Multi-Agent Competition\",\"url\":\"https://www.semanticscholar.org/paper/c335ff618991f0a4cdde09271284172a7e5f6b7f\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1509.02971\",\"authors\":[{\"authorId\":\"2542999\",\"name\":\"T. Lillicrap\"},{\"authorId\":\"2323922\",\"name\":\"J. Hunt\"},{\"authorId\":\"1863250\",\"name\":\"A. Pritzel\"},{\"authorId\":\"2801204\",\"name\":\"N. Heess\"},{\"authorId\":\"1968210\",\"name\":\"T. Erez\"},{\"authorId\":\"2109481\",\"name\":\"Y. Tassa\"},{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"1688276\",\"name\":\"Daan Wierstra\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"024006d4c2a89f7acacc6e4438d156525b60a98f\",\"title\":\"Continuous control with deep reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/024006d4c2a89f7acacc6e4438d156525b60a98f\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144832491\",\"name\":\"E. Todorov\"},{\"authorId\":\"1968210\",\"name\":\"T. Erez\"},{\"authorId\":\"2109481\",\"name\":\"Y. Tassa\"}],\"doi\":\"10.1109/IROS.2012.6386109\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b354ee518bfc1ac0d8ac447eece9edb69e92eae1\",\"title\":\"MuJoCo: A physics engine for model-based control\",\"url\":\"https://www.semanticscholar.org/paper/b354ee518bfc1ac0d8ac447eece9edb69e92eae1\",\"venue\":\"2012 IEEE/RSJ International Conference on Intelligent Robots and Systems\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Elaheh Barati\"},{\"authorId\":null,\"name\":\"Xuewen Chen\"},{\"authorId\":null,\"name\":\"Zichun Zhong. Attention-based deep reinforcement learning environments\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In AAMAS\",\"url\":\"\",\"venue\":\"pages 1805\\u2013 1807,\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5886094\",\"name\":\"P. Cochat\"},{\"authorId\":\"13267685\",\"name\":\"L. Vaucoret\"},{\"authorId\":\"31455512\",\"name\":\"J. Sarles\"}],\"doi\":\"10.1016/j.arcped.2012.01.013\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10d85561e4aafc516d10064f30dff05b41f70afe\",\"title\":\"[Et al].\",\"url\":\"https://www.semanticscholar.org/paper/10d85561e4aafc516d10064f30dff05b41f70afe\",\"venue\":\"Archives de pediatrie : organe officiel de la Societe francaise de pediatrie\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3255983\",\"name\":\"V. Mnih\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"},{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"1392331736\",\"name\":\"Andrei A. Rusu\"},{\"authorId\":\"144056327\",\"name\":\"J. Veness\"},{\"authorId\":\"1397980088\",\"name\":\"Marc G. Bellemare\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"3137672\",\"name\":\"Martin A. Riedmiller\"},{\"authorId\":\"1397979864\",\"name\":\"Andreas K. Fidjeland\"},{\"authorId\":\"2273072\",\"name\":\"Georg Ostrovski\"},{\"authorId\":\"145386761\",\"name\":\"S. Petersen\"},{\"authorId\":\"48878752\",\"name\":\"C. Beattie\"},{\"authorId\":\"49813280\",\"name\":\"A. Sadik\"},{\"authorId\":\"2460849\",\"name\":\"Ioannis Antonoglou\"},{\"authorId\":\"153907173\",\"name\":\"H. King\"},{\"authorId\":\"2106164\",\"name\":\"D. Kumaran\"},{\"authorId\":\"1688276\",\"name\":\"Daan Wierstra\"},{\"authorId\":\"34313265\",\"name\":\"S. Legg\"},{\"authorId\":\"48987704\",\"name\":\"Demis Hassabis\"}],\"doi\":\"10.1038/nature14236\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e0e9a94c4a6ba219e768b4e59f72c18f0a22e23d\",\"title\":\"Human-level control through deep reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/e0e9a94c4a6ba219e768b4e59f72c18f0a22e23d\",\"venue\":\"Nature\",\"year\":2015},{\"arxivId\":\"1312.5602\",\"authors\":[{\"authorId\":\"3255983\",\"name\":\"V. Mnih\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"},{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"2460849\",\"name\":\"Ioannis Antonoglou\"},{\"authorId\":\"1688276\",\"name\":\"Daan Wierstra\"},{\"authorId\":\"3137672\",\"name\":\"Martin A. Riedmiller\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2319a491378867c7049b3da055c5df60e1671158\",\"title\":\"Playing Atari with Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/2319a491378867c7049b3da055c5df60e1671158\",\"venue\":\"ArXiv\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"3276293\",\"name\":\"G. Lever\"},{\"authorId\":\"2801204\",\"name\":\"N. Heess\"},{\"authorId\":\"1804488\",\"name\":\"T. Degris\"},{\"authorId\":\"1688276\",\"name\":\"Daan Wierstra\"},{\"authorId\":\"3137672\",\"name\":\"Martin A. Riedmiller\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"687d0e59d5c35f022ce4638b3e3a6142068efc94\",\"title\":\"Deterministic Policy Gradient Algorithms\",\"url\":\"https://www.semanticscholar.org/paper/687d0e59d5c35f022ce4638b3e3a6142068efc94\",\"venue\":\"ICML\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Shayegan Omidshafiei\"},{\"authorId\":null,\"name\":\"Jason Pazis\"},{\"authorId\":null,\"name\":\"Christopher Amato\"},{\"authorId\":null,\"name\":\"Jonathan P How\"},{\"authorId\":null,\"name\":\"John Vian. Deep decentralized multi-task multi-agent re observability\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In ICML\",\"url\":\"\",\"venue\":\"pages 2681\\u20132690,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Volodymyr Mnih\"},{\"authorId\":null,\"name\":\"Adria Puigdomenech Badia\"},{\"authorId\":null,\"name\":\"Mehdi Mirza\"},{\"authorId\":null,\"name\":\"Alex Graves\"},{\"authorId\":null,\"name\":\"Timothy Lillicrap\"},{\"authorId\":null,\"name\":\"Tim Harley\"},{\"authorId\":null,\"name\":\"David Silver\"},{\"authorId\":null,\"name\":\"Koray Kavukcuoglu. Asynchronous methods for deep reinfor learning\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In ICML\",\"url\":\"\",\"venue\":\"pages 1928\\u20131937,\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ryan Lowe\"},{\"authorId\":null,\"name\":\"Yi Wu\"},{\"authorId\":null,\"name\":\"Aviv Tamar\"},{\"authorId\":null,\"name\":\"Jean Harb\"},{\"authorId\":null,\"name\":\"OpenAI Pieter Abbeel\"},{\"authorId\":null,\"name\":\"Igor Mordatch. Multiagent actor-critic for mixed cooper environments\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In NIPS\",\"url\":\"\",\"venue\":\"pages 6379\\u20136390,\",\"year\":2017},{\"arxivId\":\"1707.06347\",\"authors\":[{\"authorId\":\"47971768\",\"name\":\"John Schulman\"},{\"authorId\":\"143909660\",\"name\":\"F. Wolski\"},{\"authorId\":\"6515819\",\"name\":\"Prafulla Dhariwal\"},{\"authorId\":\"38909097\",\"name\":\"A. Radford\"},{\"authorId\":\"144538754\",\"name\":\"O. Klimov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"dce6f9d4017b1785979e7520fd0834ef8cf02f4b\",\"title\":\"Proximal Policy Optimization Algorithms\",\"url\":\"https://www.semanticscholar.org/paper/dce6f9d4017b1785979e7520fd0834ef8cf02f4b\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Martin Lauer\"},{\"authorId\":null,\"name\":\"Martin Riedmiller. An algorithm for distributed reinforce systems\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In ICML\",\"url\":\"\",\"venue\":\"pages 535\\u2013542,\",\"year\":2000},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145500880\",\"name\":\"M. Lauer\"},{\"authorId\":\"3137672\",\"name\":\"Martin A. Riedmiller\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9d94165d22ae17b7d933dafffabb16ad2b8e147a\",\"title\":\"An Algorithm for Distributed Reinforcement Learning in Cooperative Multi-Agent Systems\",\"url\":\"https://www.semanticscholar.org/paper/9d94165d22ae17b7d933dafffabb16ad2b8e147a\",\"venue\":\"ICML\",\"year\":2000}],\"title\":\"An Actor-Critic-Attention Mechanism for Deep Reinforcement Learning in Multi-view Environments\",\"topics\":[{\"topic\":\"Reinforcement learning\",\"topicId\":\"2557\",\"url\":\"https://www.semanticscholar.org/topic/2557\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"TORCS\",\"topicId\":\"538500\",\"url\":\"https://www.semanticscholar.org/topic/538500\"},{\"topic\":\"Baseline (configuration management)\",\"topicId\":\"3403\",\"url\":\"https://www.semanticscholar.org/topic/3403\"},{\"topic\":\"Machine learning\",\"topicId\":\"168\",\"url\":\"https://www.semanticscholar.org/topic/168\"},{\"topic\":\"Simulation\",\"topicId\":\"194\",\"url\":\"https://www.semanticscholar.org/topic/194\"},{\"topic\":\"Multi-agent system\",\"topicId\":\"3830\",\"url\":\"https://www.semanticscholar.org/topic/3830\"},{\"topic\":\"Algorithm\",\"topicId\":\"305\",\"url\":\"https://www.semanticscholar.org/topic/305\"}],\"url\":\"https://www.semanticscholar.org/paper/ddace5849601f7d8942c52bd6658f23b353df520\",\"venue\":\"IJCAI\",\"year\":2019}\n"