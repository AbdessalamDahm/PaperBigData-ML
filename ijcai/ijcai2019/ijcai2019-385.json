"{\"abstract\":\"Neural networks are vulnerable to adversarial attacks -- small visually imperceptible crafted noise which when added to the input drastically changes the output. The most effective method of defending against these adversarial attacks is to use the methodology of adversarial training. We analyze the adversarially trained robust models to study their vulnerability against adversarial attacks at the level of the latent layers. Our analysis reveals that contrary to the input layer which is robust to adversarial attack, the latent layer of these robust models are highly susceptible to adversarial perturbations of small magnitude. Leveraging this information, we introduce a new technique Latent Adversarial Training (LAT) which comprises of fine-tuning the adversarially trained models to ensure the robustness at the feature layers. We also propose Latent Attack (LA), a novel algorithm for construction of adversarial examples. LAT results in minor improvement in test accuracy and leads to a state-of-the-art adversarial accuracy against the universal first-order adversarial PGD attack which is shown for the MNIST, CIFAR-10, CIFAR-100 datasets.\",\"arxivId\":\"1905.05186\",\"authors\":[{\"authorId\":\"144318274\",\"name\":\"Abhishek Sinha\",\"url\":\"https://www.semanticscholar.org/author/144318274\"},{\"authorId\":\"1400331254\",\"name\":\"Mayank Singh\",\"url\":\"https://www.semanticscholar.org/author/1400331254\"},{\"authorId\":\"46373847\",\"name\":\"Nupur Kumari\",\"url\":\"https://www.semanticscholar.org/author/46373847\"},{\"authorId\":\"145846953\",\"name\":\"Balaji Krishnamurthy\",\"url\":\"https://www.semanticscholar.org/author/145846953\"},{\"authorId\":\"51265012\",\"name\":\"Harshitha Machiraju\",\"url\":\"https://www.semanticscholar.org/author/51265012\"},{\"authorId\":\"1699429\",\"name\":\"V. Balasubramanian\",\"url\":\"https://www.semanticscholar.org/author/1699429\"}],\"citationVelocity\":10,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1400331254\",\"name\":\"Mayank Singh\"},{\"authorId\":\"46373847\",\"name\":\"Nupur Kumari\"},{\"authorId\":\"69453609\",\"name\":\"P. Mangla\"},{\"authorId\":\"144318274\",\"name\":\"Abhishek Sinha\"},{\"authorId\":\"1699429\",\"name\":\"V. Balasubramanian\"},{\"authorId\":\"145846953\",\"name\":\"Balaji Krishnamurthy\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c0241199a4c17dfbcf245f67b6fdae77a3d1f684\",\"title\":\"On the Benefits of Attributional Robustness\",\"url\":\"https://www.semanticscholar.org/paper/c0241199a4c17dfbcf245f67b6fdae77a3d1f684\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151470385\",\"name\":\"Tao Dai\"},{\"authorId\":\"48260254\",\"name\":\"Yan Feng\"},{\"authorId\":\"1492154834\",\"name\":\"Dongxian Wu\"},{\"authorId\":\"14238797\",\"name\":\"B. Chen\"},{\"authorId\":\"145002168\",\"name\":\"J. Lu\"},{\"authorId\":\"101321464\",\"name\":\"Yong Jiang\"},{\"authorId\":\"153813838\",\"name\":\"Shutao Xia\"}],\"doi\":\"10.1145/3394171.3413898\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6ae33d63a1eddf7a99c4493d761b398b77958392\",\"title\":\"DIPDefend: Deep Image Prior Driven Defense against Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/6ae33d63a1eddf7a99c4493d761b398b77958392\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2005.07998\",\"authors\":[{\"authorId\":\"151444358\",\"name\":\"Maungmaung Aprilpyone\"},{\"authorId\":\"12745074\",\"name\":\"Hitoshi Kiya\"}],\"doi\":\"10.1109/ICIP40778.2020.9190904\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"c45132f8a83a85a15eb8c88d00a8e5c941972ef6\",\"title\":\"Encryption Inspired Adversarial Defense For Visual Classification\",\"url\":\"https://www.semanticscholar.org/paper/c45132f8a83a85a15eb8c88d00a8e5c941972ef6\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"2006.07828\",\"authors\":[{\"authorId\":\"69453609\",\"name\":\"P. Mangla\"},{\"authorId\":\"5776920\",\"name\":\"Vedant Singh\"},{\"authorId\":\"1699429\",\"name\":\"V. Balasubramanian\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb842849574ba3dcadaff66c21d4015c23fbc13d\",\"title\":\"On Saliency Maps and Adversarial Robustness\",\"url\":\"https://www.semanticscholar.org/paper/eb842849574ba3dcadaff66c21d4015c23fbc13d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.06566\",\"authors\":[{\"authorId\":\"69453609\",\"name\":\"P. Mangla\"},{\"authorId\":\"5776920\",\"name\":\"Vedant Singh\"},{\"authorId\":\"1565481562\",\"name\":\"Shreyas Jayant Havaldar\"},{\"authorId\":\"1699429\",\"name\":\"V. Balasubramanian\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d0ea48fc5730c405718be0e2313d56e641e78139\",\"title\":\"VarMixup: Exploiting the Latent Space for Robust Training and Inference\",\"url\":\"https://www.semanticscholar.org/paper/d0ea48fc5730c405718be0e2313d56e641e78139\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.06591\",\"authors\":[{\"authorId\":\"78145301\",\"name\":\"Xiao-dan Li\"},{\"authorId\":\"47557806\",\"name\":\"YueFeng Chen\"},{\"authorId\":\"143605211\",\"name\":\"Yuan He\"},{\"authorId\":\"1801206\",\"name\":\"H. Xue\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c36ed04a65e35f3dc00e610a43fa360e4c64abcc\",\"title\":\"AdvKnn: Adversarial Attacks On K-Nearest Neighbor Classifiers With Approximate Gradients\",\"url\":\"https://www.semanticscholar.org/paper/c36ed04a65e35f3dc00e610a43fa360e4c64abcc\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2012.14395\",\"authors\":[{\"authorId\":\"1750611\",\"name\":\"A. Sarkar\"},{\"authorId\":\"1491625166\",\"name\":\"Anirban Sarkar\"},{\"authorId\":\"1699429\",\"name\":\"V. Balasubramanian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"99e6269625fd83090cdcbebf85f9632f8573be40\",\"title\":\"Enhanced Regularizers for Attributional Robustness\",\"url\":\"https://www.semanticscholar.org/paper/99e6269625fd83090cdcbebf85f9632f8573be40\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2006.07258\",\"authors\":[{\"authorId\":\"50536989\",\"name\":\"Qiu-Ling Xu\"},{\"authorId\":\"48927894\",\"name\":\"Guanhong Tao\"},{\"authorId\":\"1664044906\",\"name\":\"Xiangyu Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cfc4b24b34455e984a389cd00027631a3ddcac05\",\"title\":\"D-square-B: Deep Distribution Bound for Natural-looking Adversarial Attack\",\"url\":\"https://www.semanticscholar.org/paper/cfc4b24b34455e984a389cd00027631a3ddcac05\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1908.00706\",\"authors\":[{\"authorId\":\"69453609\",\"name\":\"P. Mangla\"},{\"authorId\":\"151496750\",\"name\":\"Surgan Jandial\"},{\"authorId\":\"81390224\",\"name\":\"S. Varshney\"},{\"authorId\":\"1699429\",\"name\":\"V. Balasubramanian\"}],\"doi\":\"10.1109/ICCVW.2019.00257\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4f0223b5db056b351fd736b4b6a1197cf039e9df\",\"title\":\"AdvGAN++: Harnessing Latent Layers for Adversary Generation\",\"url\":\"https://www.semanticscholar.org/paper/4f0223b5db056b351fd736b4b6a1197cf039e9df\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145831065\",\"name\":\"Feng Yuan\"},{\"authorId\":\"2082966\",\"name\":\"L. Yao\"},{\"authorId\":\"1734279\",\"name\":\"B. Benatallah\"}],\"doi\":\"10.1145/3340531.3411917\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"52830a1749b78a172c76ae8a6057ddafbdc3aa35\",\"title\":\"Exploring Missing Interactions: A Convolutional Generative Adversarial Network for Collaborative Filtering\",\"url\":\"https://www.semanticscholar.org/paper/52830a1749b78a172c76ae8a6057ddafbdc3aa35\",\"venue\":\"CIKM\",\"year\":2020},{\"arxivId\":\"2012.05027\",\"authors\":[{\"authorId\":\"103113328\",\"name\":\"U. Upadhyay\"},{\"authorId\":\"2550012\",\"name\":\"Prerana Mukherjee\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2c6f544ed9a29e7f0fb6b4b7e3587790c2b17e25\",\"title\":\"Generating Out of Distribution Adversarial Attack using Latent Space Poisoning\",\"url\":\"https://www.semanticscholar.org/paper/2c6f544ed9a29e7f0fb6b4b7e3587790c2b17e25\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1753521652\",\"name\":\"Joel Dapello\"},{\"authorId\":\"39035833\",\"name\":\"Tiago Marques\"},{\"authorId\":\"8551292\",\"name\":\"Martin Schrimpf\"},{\"authorId\":\"51929926\",\"name\":\"F. Geiger\"},{\"authorId\":\"2042941\",\"name\":\"D. Cox\"},{\"authorId\":\"34409560\",\"name\":\"James J. DiCarlo\"}],\"doi\":\"10.1101/2020.06.16.154542\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7323ff36df929ecf1b877c8d0daadffae384c3e3\",\"title\":\"Simulating a Primary Visual Cortex at the Front of CNNs Improves Robustness to Image Perturbations\",\"url\":\"https://www.semanticscholar.org/paper/7323ff36df929ecf1b877c8d0daadffae384c3e3\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2006.08403\",\"authors\":[{\"authorId\":\"47535970\",\"name\":\"Chen Liu\"},{\"authorId\":\"2862871\",\"name\":\"M. Salzmann\"},{\"authorId\":\"145724662\",\"name\":\"Tao Lin\"},{\"authorId\":\"2870603\",\"name\":\"Ryota Tomioka\"},{\"authorId\":\"9166214\",\"name\":\"Sabine Susstrunk\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7944223450bf7029f5191805a4f5bb5a28872f38\",\"title\":\"On the Loss Landscape of Adversarial Training: Identifying Challenges and How to Overcome Them\",\"url\":\"https://www.semanticscholar.org/paper/7944223450bf7029f5191805a4f5bb5a28872f38\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"1910.08108\",\"authors\":[{\"authorId\":\"1750611\",\"name\":\"A. Sarkar\"},{\"authorId\":\"150245538\",\"name\":\"N. K. Gupta\"},{\"authorId\":\"52378222\",\"name\":\"R. Iyengar\"}],\"doi\":\"10.1007/978-3-030-61609-0_5\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"009cc279164abcc3299ea1d1c6f6163392052c9e\",\"title\":\"Enforcing Linearity in DNN succours Robustness and Adversarial Image Generation\",\"url\":\"https://www.semanticscholar.org/paper/009cc279164abcc3299ea1d1c6f6163392052c9e\",\"venue\":\"ICANN\",\"year\":2020},{\"arxivId\":\"2011.11164\",\"authors\":[{\"authorId\":\"1474280620\",\"name\":\"Jiequan Cui\"},{\"authorId\":\"122050899\",\"name\":\"Shu Liu\"},{\"authorId\":\"145602574\",\"name\":\"L. Wang\"},{\"authorId\":\"40661332\",\"name\":\"J. Jia\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4c9b767a67475932f096292419d93ed2688b5379\",\"title\":\"Learnable Boundary Guided Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/4c9b767a67475932f096292419d93ed2688b5379\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.13073\",\"authors\":[{\"authorId\":\"1400331254\",\"name\":\"Mayank Singh\"},{\"authorId\":\"46373847\",\"name\":\"Nupur Kumari\"},{\"authorId\":\"69453609\",\"name\":\"P. Mangla\"},{\"authorId\":\"144318274\",\"name\":\"Abhishek Sinha\"},{\"authorId\":\"1699429\",\"name\":\"V. Balasubramanian\"},{\"authorId\":\"1557631185\",\"name\":\"Balaji Krishnamurthy\"}],\"doi\":\"10.1007/978-3-030-58583-9_31\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d4b7319d212fd4f957ad726a217d0a0d3bb2f983\",\"title\":\"Attributional Robustness Training Using Input-Gradient Spatial Alignment\",\"url\":\"https://www.semanticscholar.org/paper/d4b7319d212fd4f957ad726a217d0a0d3bb2f983\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2003.01690\",\"authors\":[{\"authorId\":\"39171784\",\"name\":\"F. Croce\"},{\"authorId\":\"37388290\",\"name\":\"M. Hein\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"18939eadc9c4460c8385e0591cde214a1ead067b\",\"title\":\"Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks\",\"url\":\"https://www.semanticscholar.org/paper/18939eadc9c4460c8385e0591cde214a1ead067b\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":\"2006.11122\",\"authors\":[{\"authorId\":\"3380463\",\"name\":\"Alessandro Tibo\"},{\"authorId\":\"94378548\",\"name\":\"M. Jaeger\"},{\"authorId\":\"50130104\",\"name\":\"Kim G. Larsen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c0b46a3fb8cfb7d4fa2db169dfc4d92a059b83ec\",\"title\":\"A general framework for defining and optimizing robustness\",\"url\":\"https://www.semanticscholar.org/paper/c0b46a3fb8cfb7d4fa2db169dfc4d92a059b83ec\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1909.06271\",\"authors\":[{\"authorId\":\"151389936\",\"name\":\"Zudi Lin\"},{\"authorId\":\"143758231\",\"name\":\"H. Pfister\"},{\"authorId\":\"7969330\",\"name\":\"Ziming Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e3f8fd75a312e84e77ea94d70c85c5ac07972e2f\",\"title\":\"White-Box Adversarial Defense via Self-Supervised Data Estimation\",\"url\":\"https://www.semanticscholar.org/paper/e3f8fd75a312e84e77ea94d70c85c5ac07972e2f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2004.12227\",\"authors\":[{\"authorId\":\"144493624\",\"name\":\"Yuanhao Xiong\"},{\"authorId\":\"3310983\",\"name\":\"C. Hsieh\"}],\"doi\":\"10.1007/978-3-030-58598-3_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"14da16278f385505aec3d0586a19e607f47f5c3c\",\"title\":\"Improved Adversarial Training via Learned Optimizer\",\"url\":\"https://www.semanticscholar.org/paper/14da16278f385505aec3d0586a19e607f47f5c3c\",\"venue\":\"ECCV\",\"year\":2020}],\"corpusId\":153312704,\"doi\":\"10.24963/ijcai.2019/385\",\"fieldsOfStudy\":[\"Computer Science\",\"Mathematics\"],\"influentialCitationCount\":2,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"8d7cff029570cf4dc15fc49693067154823a562e\",\"references\":[{\"arxivId\":\"1805.06605\",\"authors\":[{\"authorId\":\"3383048\",\"name\":\"Pouya Samangouei\"},{\"authorId\":\"2747758\",\"name\":\"Maya Kabkab\"},{\"authorId\":\"9215658\",\"name\":\"R. Chellappa\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f7bb1636ced9036b3d0edafc7d82ad43164d41a3\",\"title\":\"Defense-GAN: Protecting Classifiers Against Adversarial Attacks Using Generative Models\",\"url\":\"https://www.semanticscholar.org/paper/f7bb1636ced9036b3d0edafc7d82ad43164d41a3\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1703.06870\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2082991\",\"name\":\"Georgia Gkioxari\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/ICCV.2017.322\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ea99a5535388196d0d44be5b4d7dd02029a43bb2\",\"title\":\"Mask R-CNN\",\"url\":\"https://www.semanticscholar.org/paper/ea99a5535388196d0d44be5b4d7dd02029a43bb2\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yan Lecun\"},{\"authorId\":null,\"name\":\"B. Boser\"},{\"authorId\":null,\"name\":\"J. S. Denker\"},{\"authorId\":null,\"name\":\"D. Henderson\"},{\"authorId\":null,\"name\":\"R. E. Howard\"},{\"authorId\":null,\"name\":\"W. Hubbard\"},{\"authorId\":null,\"name\":\"L.D\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Jackel\",\"url\":\"\",\"venue\":\"Backpropagation applied to handwritten zip code recognition,\",\"year\":1989},{\"arxivId\":\"1608.04644\",\"authors\":[{\"authorId\":\"2483738\",\"name\":\"Nicholas Carlini\"},{\"authorId\":\"145394689\",\"name\":\"D. Wagner\"}],\"doi\":\"10.1109/SP.2017.49\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"df40ce107a71b770c9d0354b78fdd8989da80d2f\",\"title\":\"Towards Evaluating the Robustness of Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/df40ce107a71b770c9d0354b78fdd8989da80d2f\",\"venue\":\"2017 IEEE Symposium on Security and Privacy (SP)\",\"year\":2017},{\"arxivId\":\"1805.12152\",\"authors\":[{\"authorId\":\"2754804\",\"name\":\"D. Tsipras\"},{\"authorId\":\"2852106\",\"name\":\"Shibani Santurkar\"},{\"authorId\":\"39468283\",\"name\":\"L. Engstrom\"},{\"authorId\":\"152866449\",\"name\":\"A. Turner\"},{\"authorId\":\"143826246\",\"name\":\"A. Madry\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"1b9c6022598085dd892f360122c0fa4c630b3f18\",\"title\":\"Robustness May Be at Odds with Accuracy\",\"url\":\"https://www.semanticscholar.org/paper/1b9c6022598085dd892f360122c0fa4c630b3f18\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1705.07204\",\"authors\":[{\"authorId\":\"2444919\",\"name\":\"Florian Tram\\u00e8r\"},{\"authorId\":\"145714153\",\"name\":\"A. Kurakin\"},{\"authorId\":\"1967156\",\"name\":\"Nicolas Papernot\"},{\"authorId\":\"1752788\",\"name\":\"D. Boneh\"},{\"authorId\":\"144061974\",\"name\":\"P. McDaniel\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"136dee73f203df2f4831994bf4f0c0a4ad2e764e\",\"title\":\"Ensemble Adversarial Training: Attacks and Defenses\",\"url\":\"https://www.semanticscholar.org/paper/136dee73f203df2f4831994bf4f0c0a4ad2e764e\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1803.06373\",\"authors\":[{\"authorId\":\"143862402\",\"name\":\"Harini Kannan\"},{\"authorId\":\"145714153\",\"name\":\"A. Kurakin\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f2c5c3cfe1675dd9239121f1f09069438f047aea\",\"title\":\"Adversarial Logit Pairing\",\"url\":\"https://www.semanticscholar.org/paper/f2c5c3cfe1675dd9239121f1f09069438f047aea\",\"venue\":\"NIPS 2018\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Carlini\"},{\"authorId\":null,\"name\":\"Nicholas Wagner\"},{\"authorId\":null,\"name\":\"David Carlini\"},{\"authorId\":null,\"name\":\"Wagner\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Andrew Ilyas, Logan Engstrom, and Aleksander Madry. Prior convictions: Black-box adversarial attacks with bandits and priors. ICLR\",\"url\":\"\",\"venue\":\"He et al., 2016] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun\",\"year\":1989},{\"arxivId\":\"1705.07263\",\"authors\":[{\"authorId\":\"39907737\",\"name\":\"N. Carlini\"},{\"authorId\":\"40429990\",\"name\":\"D. Wagner\"}],\"doi\":\"10.1145/3128572.3140444\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"99cb08c76c120599abd1d1637e32aaf577f38d39\",\"title\":\"Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods\",\"url\":\"https://www.semanticscholar.org/paper/99cb08c76c120599abd1d1637e32aaf577f38d39\",\"venue\":\"AISec@CCS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"},{\"authorId\":\"2219581\",\"name\":\"B. Boser\"},{\"authorId\":\"49869599\",\"name\":\"J. Denker\"},{\"authorId\":\"37274089\",\"name\":\"D. Henderson\"},{\"authorId\":\"32295804\",\"name\":\"R. Howard\"},{\"authorId\":\"34859193\",\"name\":\"W. Hubbard\"},{\"authorId\":\"2307573\",\"name\":\"L. Jackel\"}],\"doi\":\"10.1162/neco.1989.1.4.541\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a8e8f3c8d4418c8d62e306538c9c1292635e9d27\",\"title\":\"Backpropagation Applied to Handwritten Zip Code Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a8e8f3c8d4418c8d62e306538c9c1292635e9d27\",\"venue\":\"Neural Computation\",\"year\":1989},{\"arxivId\":\"1705.07819\",\"authors\":[{\"authorId\":\"2716670\",\"name\":\"S. Sankaranarayanan\"},{\"authorId\":\"35561551\",\"name\":\"Arpit Jain\"},{\"authorId\":\"9215658\",\"name\":\"R. Chellappa\"},{\"authorId\":\"38760573\",\"name\":\"Ser-Nam Lim\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"68409946aa855b9a14de341bd321c38762817122\",\"title\":\"Regularizing deep networks using efficient layerwise adversarial training\",\"url\":\"https://www.semanticscholar.org/paper/68409946aa855b9a14de341bd321c38762817122\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2483738\",\"name\":\"Nicholas Carlini\"},{\"authorId\":\"40348902\",\"name\":\"G. Katz\"},{\"authorId\":\"144672018\",\"name\":\"C. Barrett\"},{\"authorId\":\"1699040\",\"name\":\"D. Dill\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"59ea59d73eea51f80b60ba6ea47dac0197029336\",\"title\":\"Provably Minimally-Distorted Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/59ea59d73eea51f80b60ba6ea47dac0197029336\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1511.05122\",\"authors\":[{\"authorId\":\"143752292\",\"name\":\"Sara Sabour\"},{\"authorId\":\"2902068\",\"name\":\"Yanshuai Cao\"},{\"authorId\":\"2978170\",\"name\":\"Fartash Faghri\"},{\"authorId\":\"1793739\",\"name\":\"David J. Fleet\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"da900e5f02e23716af164f45333cd182f7e756ca\",\"title\":\"Adversarial Manipulation of Deep Representations\",\"url\":\"https://www.semanticscholar.org/paper/da900e5f02e23716af164f45333cd182f7e756ca\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":\"1711.00851\",\"authors\":[{\"authorId\":\"145116464\",\"name\":\"J. Z. Kolter\"},{\"authorId\":\"51026953\",\"name\":\"E. Wong\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4b23012689e0f17912fb38d4984775e567cff8d6\",\"title\":\"Provable defenses against adversarial examples via the convex outer adversarial polytope\",\"url\":\"https://www.semanticscholar.org/paper/4b23012689e0f17912fb38d4984775e567cff8d6\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":\"1412.6572\",\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1789737\",\"name\":\"Jonathon Shlens\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"bee044c8e8903fb67523c1f8c105ab4718600cdb\",\"title\":\"Explaining and Harnessing Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/bee044c8e8903fb67523c1f8c105ab4718600cdb\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1802.04034\",\"authors\":[{\"authorId\":\"37708360\",\"name\":\"Yusuke Tsuzuku\"},{\"authorId\":\"73355331\",\"name\":\"I. Sato\"},{\"authorId\":\"67154907\",\"name\":\"Masashi Sugiyama\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"0bd8c29a206c46dccca63c010a95734018c98d2e\",\"title\":\"Lipschitz-Margin Training: Scalable Certification of Perturbation Invariance for Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/0bd8c29a206c46dccca63c010a95734018c98d2e\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Alex Krizhevsky\"},{\"authorId\":null,\"name\":\"Vinod Nair\"},{\"authorId\":null,\"name\":\"Geoffrey Hinton\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Cifar-10\",\"url\":\"\",\"venue\":\"URL http://www.cs.toronto. edu/kriz/cifar.html,\",\"year\":2010},{\"arxivId\":\"1704.08847\",\"authors\":[{\"authorId\":\"5723508\",\"name\":\"M. Ciss\\u00e9\"},{\"authorId\":\"2329288\",\"name\":\"P. Bojanowski\"},{\"authorId\":\"3024698\",\"name\":\"E. Grave\"},{\"authorId\":\"2921469\",\"name\":\"Yann Dauphin\"},{\"authorId\":\"1746841\",\"name\":\"Nicolas Usunier\"}],\"doi\":null,\"intent\":[\"methodology\",\"result\"],\"isInfluential\":false,\"paperId\":\"013efe3ff541e518c51f08d1b62a62e0c57c0b14\",\"title\":\"Parseval Networks: Improving Robustness to Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/013efe3ff541e518c51f08d1b62a62e0c57c0b14\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":\"1610.08401\",\"authors\":[{\"authorId\":\"1403182206\",\"name\":\"Seyed-Mohsen Moosavi-Dezfooli\"},{\"authorId\":\"33054064\",\"name\":\"Alhussein Fawzi\"},{\"authorId\":\"145602557\",\"name\":\"Omar Fawzi\"},{\"authorId\":\"48036489\",\"name\":\"P. Frossard\"}],\"doi\":\"10.1109/CVPR.2017.17\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"16aa01ca0834a924c25faad5d8bfef3fd1acfcfe\",\"title\":\"Universal Adversarial Perturbations\",\"url\":\"https://www.semanticscholar.org/paper/16aa01ca0834a924c25faad5d8bfef3fd1acfcfe\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1801.02612\",\"authors\":[{\"authorId\":\"2723309\",\"name\":\"Chaowei Xiao\"},{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"143771567\",\"name\":\"Bo Li\"},{\"authorId\":\"145551594\",\"name\":\"Warren He\"},{\"authorId\":\"39037167\",\"name\":\"M. Liu\"},{\"authorId\":\"143711382\",\"name\":\"D. Song\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d3c071dbbb4520ed5875f7e064a9da87240534db\",\"title\":\"Spatially Transformed Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/d3c071dbbb4520ed5875f7e064a9da87240534db\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1806.08049\",\"authors\":[{\"authorId\":\"2535083\",\"name\":\"David Alvarez-Melis\"},{\"authorId\":\"35132120\",\"name\":\"T. Jaakkola\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b7fcbb19c75ad65be522b64d5f4b23dbcb3b883b\",\"title\":\"On the Robustness of Interpretability Methods\",\"url\":\"https://www.semanticscholar.org/paper/b7fcbb19c75ad65be522b64d5f4b23dbcb3b883b\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1706.06083\",\"authors\":[{\"authorId\":\"143826246\",\"name\":\"A. Madry\"},{\"authorId\":\"17775913\",\"name\":\"Aleksandar Makelov\"},{\"authorId\":\"33404869\",\"name\":\"L. Schmidt\"},{\"authorId\":\"2754804\",\"name\":\"D. Tsipras\"},{\"authorId\":\"2869958\",\"name\":\"Adrian Vladu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7aa38b85fa8cba64d6a4010543f6695dbf5f1386\",\"title\":\"Towards Deep Learning Models Resistant to Adversarial Attacks\",\"url\":\"https://www.semanticscholar.org/paper/7aa38b85fa8cba64d6a4010543f6695dbf5f1386\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":\"1801.00553\",\"authors\":[{\"authorId\":\"47398812\",\"name\":\"N. Akhtar\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"}],\"doi\":\"10.1109/ACCESS.2018.2807385\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b514949ad8344071c0f342f182390d2d88bcc26d\",\"title\":\"Threat of Adversarial Attacks on Deep Learning in Computer Vision: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/b514949ad8344071c0f342f182390d2d88bcc26d\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":\"1801.09344\",\"authors\":[{\"authorId\":\"2655157\",\"name\":\"Aditi Raghunathan\"},{\"authorId\":\"5164568\",\"name\":\"J. Steinhardt\"},{\"authorId\":\"145419642\",\"name\":\"Percy Liang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"966e3c7a65ec75a6359b55c0cecaf3896d318432\",\"title\":\"Certified Defenses against Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/966e3c7a65ec75a6359b55c0cecaf3896d318432\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1802.00420\",\"authors\":[{\"authorId\":\"38939786\",\"name\":\"Anish Athalye\"},{\"authorId\":\"2483738\",\"name\":\"Nicholas Carlini\"},{\"authorId\":\"145394689\",\"name\":\"D. Wagner\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"651adaa058f821a890f2c5d1053d69eb481a8352\",\"title\":\"Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/651adaa058f821a890f2c5d1053d69eb481a8352\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":\"1807.10272\",\"authors\":[{\"authorId\":\"39468283\",\"name\":\"L. Engstrom\"},{\"authorId\":\"34562927\",\"name\":\"Andrew Ilyas\"},{\"authorId\":\"38939786\",\"name\":\"Anish Athalye\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6effa092456e30e7e54954fd28b755e0a75b52b8\",\"title\":\"Evaluating and Understanding the Robustness of Adversarial Logit Pairing\",\"url\":\"https://www.semanticscholar.org/paper/6effa092456e30e7e54954fd28b755e0a75b52b8\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1807.07978\",\"authors\":[{\"authorId\":\"34562927\",\"name\":\"Andrew Ilyas\"},{\"authorId\":\"39468283\",\"name\":\"L. Engstrom\"},{\"authorId\":\"143826246\",\"name\":\"A. Madry\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"10ab21b120e305b6d3cbf81c5a906d36521152f1\",\"title\":\"Prior Convictions: Black-Box Adversarial Attacks with Bandits and Priors\",\"url\":\"https://www.semanticscholar.org/paper/10ab21b120e305b6d3cbf81c5a906d36521152f1\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1712.07107\",\"authors\":[{\"authorId\":\"152162529\",\"name\":\"Xiaoyong Yuan\"},{\"authorId\":\"50462511\",\"name\":\"Pan He\"},{\"authorId\":\"22317545\",\"name\":\"Qile Zhu\"},{\"authorId\":\"47058258\",\"name\":\"X. Li\"}],\"doi\":\"10.1109/TNNLS.2018.2886017\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"03a507a0876c7e1a26608358b1a9dd39f1eb08e0\",\"title\":\"Adversarial Examples: Attacks and Defenses for Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/03a507a0876c7e1a26608358b1a9dd39f1eb08e0\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2019},{\"arxivId\":\"1812.03411\",\"authors\":[{\"authorId\":\"3011497\",\"name\":\"Cihang Xie\"},{\"authorId\":\"98264506\",\"name\":\"Yuxin Wu\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"}],\"doi\":\"10.1109/CVPR.2019.00059\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"41071dbbbcbb27af3fec70de045f19c28535f5b7\",\"title\":\"Feature Denoising for Improving Adversarial Robustness\",\"url\":\"https://www.semanticscholar.org/paper/41071dbbbcbb27af3fec70de045f19c28535f5b7\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34180232\",\"name\":\"Yuval Netzer\"},{\"authorId\":\"17929104\",\"name\":\"T. Wang\"},{\"authorId\":\"144638694\",\"name\":\"A. Coates\"},{\"authorId\":\"1726358\",\"name\":\"A. Bissacco\"},{\"authorId\":\"144397975\",\"name\":\"B. Wu\"},{\"authorId\":\"34699434\",\"name\":\"A. Ng\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"02227c94dd41fe0b439e050d377b0beb5d427cda\",\"title\":\"Reading Digits in Natural Images with Unsupervised Feature Learning\",\"url\":\"https://www.semanticscholar.org/paper/02227c94dd41fe0b439e050d377b0beb5d427cda\",\"venue\":\"\",\"year\":2011},{\"arxivId\":\"1409.0575\",\"authors\":[{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"71309570\",\"name\":\"H. Su\"},{\"authorId\":\"2285165\",\"name\":\"J. Krause\"},{\"authorId\":\"145031342\",\"name\":\"S. Satheesh\"},{\"authorId\":\"145423516\",\"name\":\"S. Ma\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-015-0816-y\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"title\":\"ImageNet Large Scale Visual Recognition Challenge\",\"url\":\"https://www.semanticscholar.org/paper/e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":\"1802.05666\",\"authors\":[{\"authorId\":\"9960452\",\"name\":\"Jonathan Uesato\"},{\"authorId\":\"1389654226\",\"name\":\"Brendan O'Donoghue\"},{\"authorId\":\"3422336\",\"name\":\"A. Oord\"},{\"authorId\":\"143967473\",\"name\":\"P. Kohli\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f4b434c3ab979ecdd71bbed894b34de77590c6dd\",\"title\":\"Adversarial Risk and the Dangers of Evaluating Against Weak Attacks\",\"url\":\"https://www.semanticscholar.org/paper/f4b434c3ab979ecdd71bbed894b34de77590c6dd\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5886094\",\"name\":\"P. Cochat\"},{\"authorId\":\"13267685\",\"name\":\"L. Vaucoret\"},{\"authorId\":\"31455512\",\"name\":\"J. Sarles\"}],\"doi\":\"10.1016/j.arcped.2012.01.013\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10d85561e4aafc516d10064f30dff05b41f70afe\",\"title\":\"[Et al].\",\"url\":\"https://www.semanticscholar.org/paper/10d85561e4aafc516d10064f30dff05b41f70afe\",\"venue\":\"Archives de pediatrie : organe officiel de la Societe francaise de pediatrie\",\"year\":2012},{\"arxivId\":\"1804.09699\",\"authors\":[{\"authorId\":\"27836724\",\"name\":\"Tsui-Wei Weng\"},{\"authorId\":\"49723481\",\"name\":\"Huan Zhang\"},{\"authorId\":\"47666284\",\"name\":\"H. Chen\"},{\"authorId\":\"145328196\",\"name\":\"Zhao Song\"},{\"authorId\":\"1793529\",\"name\":\"C. Hsieh\"},{\"authorId\":\"2766041\",\"name\":\"D. Boning\"},{\"authorId\":\"1783667\",\"name\":\"I. Dhillon\"},{\"authorId\":\"144599985\",\"name\":\"L. Daniel\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"9db631435f7f79646a4e0a1841fbeb3340e44261\",\"title\":\"Towards Fast Computation of Certified Robustness for ReLU Networks\",\"url\":\"https://www.semanticscholar.org/paper/9db631435f7f79646a4e0a1841fbeb3340e44261\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":\"1312.6199\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"2563432\",\"name\":\"W. Zaremba\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"143627859\",\"name\":\"Joan Bruna\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d891dc72cbd40ffaeefdc79f2e7afe1e530a23ad\",\"title\":\"Intriguing properties of neural networks\",\"url\":\"https://www.semanticscholar.org/paper/d891dc72cbd40ffaeefdc79f2e7afe1e530a23ad\",\"venue\":\"ICLR\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jonathan Uesato\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Brendan O\\u2019Donoghue\",\"url\":\"\",\"venue\":\"Aaron van den Oord, and Pushmeet Kohli. Adversarial risk and the dangers of evaluating against weak attacks. ICML,\",\"year\":2018},{\"arxivId\":\"1605.01775\",\"authors\":[{\"authorId\":\"2974221\",\"name\":\"Andras Rozsa\"},{\"authorId\":\"39886114\",\"name\":\"Ethan M. Rudd\"},{\"authorId\":\"32163276\",\"name\":\"T. Boult\"}],\"doi\":\"10.1109/CVPRW.2016.58\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"27d7f1b8bb23390817b7af64b75367714775e7fb\",\"title\":\"Adversarial Diversity and Hard Positive Generation\",\"url\":\"https://www.semanticscholar.org/paper/27d7f1b8bb23390817b7af64b75367714775e7fb\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2016},{\"arxivId\":\"1709.10207\",\"authors\":[{\"authorId\":\"2483738\",\"name\":\"Nicholas Carlini\"},{\"authorId\":\"40348902\",\"name\":\"G. Katz\"},{\"authorId\":\"1680661\",\"name\":\"C. Barrett\"},{\"authorId\":\"1699040\",\"name\":\"D. Dill\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c486cec6473c6f97cc2037d475c99c00d6ff9b23\",\"title\":\"Ground-Truth Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/c486cec6473c6f97cc2037d475c99c00d6ff9b23\",\"venue\":\"ArXiv\",\"year\":2017}],\"title\":\"Harnessing the Vulnerability of Latent Layers in Adversarially Trained Models\",\"topics\":[{\"topic\":\"Adversary (cryptography)\",\"topicId\":\"5369\",\"url\":\"https://www.semanticscholar.org/topic/5369\"},{\"topic\":\"Algorithm\",\"topicId\":\"305\",\"url\":\"https://www.semanticscholar.org/topic/305\"},{\"topic\":\"Adversarial machine learning\",\"topicId\":\"301178\",\"url\":\"https://www.semanticscholar.org/topic/301178\"},{\"topic\":\"Deep learning\",\"topicId\":\"2762\",\"url\":\"https://www.semanticscholar.org/topic/2762\"},{\"topic\":\"Effective method\",\"topicId\":\"17681\",\"url\":\"https://www.semanticscholar.org/topic/17681\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Gene regulatory network\",\"topicId\":\"22947\",\"url\":\"https://www.semanticscholar.org/topic/22947\"},{\"topic\":\"MNIST database\",\"topicId\":\"211771\",\"url\":\"https://www.semanticscholar.org/topic/211771\"},{\"topic\":\"Neural Networks\",\"topicId\":\"99954\",\"url\":\"https://www.semanticscholar.org/topic/99954\"},{\"topic\":\"First-order reduction\",\"topicId\":\"1954345\",\"url\":\"https://www.semanticscholar.org/topic/1954345\"}],\"url\":\"https://www.semanticscholar.org/paper/8d7cff029570cf4dc15fc49693067154823a562e\",\"venue\":\"IJCAI\",\"year\":2019}\n"