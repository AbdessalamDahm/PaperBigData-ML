"{\"abstract\":\"World-class human players have been outperformed in a number of complex two person games (Go, Chess, Checkers) by Deep Reinforcement Learning systems. However, owing to tractability considerations minimax regret of a learning system cannot be evaluated in such games. In this paper we consider simple games (Noughts-and-Crosses and Hexapawn) in which minimax regret can be efficiently evaluated. We use these games to compare Cumulative Minimax Regret for variants of both standard and deep reinforcement learning against two variants of a new Meta-Interpretive Learning system called MIGO. In our experiments all tested variants of both normal and deep reinforcement learning have worse performance (higher cumulative minimax regret) than both variants of MIGO on Noughts-and-Crosses and Hexapawn. Additionally, MIGO's learned rules are relatively easy to comprehend, and are demonstrated to achieve significant transfer learning in both directions between Noughts-and-Crosses and Hexapawn.\",\"arxivId\":\"1902.09835\",\"authors\":[{\"authorId\":\"51209414\",\"name\":\"C\\u00e9line Hocquette\",\"url\":\"https://www.semanticscholar.org/author/51209414\"},{\"authorId\":\"145147565\",\"name\":\"S. Muggleton\",\"url\":\"https://www.semanticscholar.org/author/145147565\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"69459381\",\"name\":\"E. Pettersson\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"175c8460de8ef96e4ca80fd40ab664765de54f16\",\"title\":\"Meta-Interpretive Learning Versus Inductive Metalogic Programming : A Comparative Analysis in Inductive Logic Programming\",\"url\":\"https://www.semanticscholar.org/paper/175c8460de8ef96e4ca80fd40ab664765de54f16\",\"venue\":\"\",\"year\":2019}],\"corpusId\":67855940,\"doi\":\"10.24963/ijcai.2019/909\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"a0b486978a613c2c99f7c9d5b247d212701c7322\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"48926589\",\"name\":\"Dianhuan Lin\"},{\"authorId\":\"2667012\",\"name\":\"Eyal Dechter\"},{\"authorId\":\"145594432\",\"name\":\"K. Ellis\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"},{\"authorId\":\"145147566\",\"name\":\"S. Muggleton\"}],\"doi\":\"10.3233/978-1-61499-419-0-525\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a9b8f5dde834b9a8b4c4db5c889e16fcc325be78\",\"title\":\"Bias reformulation for one-shot function induction\",\"url\":\"https://www.semanticscholar.org/paper/a9b8f5dde834b9a8b4c4db5c889e16fcc325be78\",\"venue\":\"ECAI\",\"year\":2014},{\"arxivId\":\"1609.05518\",\"authors\":[{\"authorId\":\"3468254\",\"name\":\"Marta Garnelo\"},{\"authorId\":\"68972911\",\"name\":\"Kai Arulkumaran\"},{\"authorId\":\"1757629\",\"name\":\"M. Shanahan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"376f23cce537235122fdce5524d084e3a869c403\",\"title\":\"Towards Deep Symbolic Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/376f23cce537235122fdce5524d084e3a869c403\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"1885349\",\"name\":\"Aja Huang\"},{\"authorId\":\"2772217\",\"name\":\"Chris J. Maddison\"},{\"authorId\":\"35099444\",\"name\":\"A. Guez\"},{\"authorId\":\"2175946\",\"name\":\"L. Sifre\"},{\"authorId\":\"47568983\",\"name\":\"George van den Driessche\"},{\"authorId\":\"4337102\",\"name\":\"Julian Schrittwieser\"},{\"authorId\":\"2460849\",\"name\":\"Ioannis Antonoglou\"},{\"authorId\":\"2749418\",\"name\":\"Vedavyas Panneershelvam\"},{\"authorId\":\"1975889\",\"name\":\"Marc Lanctot\"},{\"authorId\":\"48373216\",\"name\":\"S. Dieleman\"},{\"authorId\":\"2401609\",\"name\":\"Dominik Grewe\"},{\"authorId\":\"4111313\",\"name\":\"John Nham\"},{\"authorId\":\"2583391\",\"name\":\"Nal Kalchbrenner\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"2542999\",\"name\":\"T. Lillicrap\"},{\"authorId\":\"40662181\",\"name\":\"M. Leach\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"},{\"authorId\":\"1686971\",\"name\":\"T. Graepel\"},{\"authorId\":\"48987704\",\"name\":\"Demis Hassabis\"}],\"doi\":\"10.1038/nature16961\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"846aedd869a00c09b40f1f1f35673cb22bc87490\",\"title\":\"Mastering the game of Go with deep neural networks and tree search\",\"url\":\"https://www.semanticscholar.org/paper/846aedd869a00c09b40f1f1f35673cb22bc87490\",\"venue\":\"Nature\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145878706\",\"name\":\"D. Michie\"}],\"doi\":\"10.1093/COMJNL/6.3.232\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"69d7108c6c9daace884e3d2d533ee7dfcedad375\",\"title\":\"Experiments on the Mechanization of Game-Learning Part I. Characterization of the Model and its parameters\",\"url\":\"https://www.semanticscholar.org/paper/69d7108c6c9daace884e3d2d533ee7dfcedad375\",\"venue\":\"Comput. J.\",\"year\":1963},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145147566\",\"name\":\"S. Muggleton\"},{\"authorId\":\"1727734\",\"name\":\"U. Schmid\"},{\"authorId\":\"26755201\",\"name\":\"Christina Zeller\"},{\"authorId\":\"1403549560\",\"name\":\"Alireza Tamaddoni-Nezhad\"},{\"authorId\":\"143862012\",\"name\":\"Tarek R. Besold\"}],\"doi\":\"10.1007/s10994-018-5707-3\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4603c2513605d18d8f7318c455aae32f20e0ecfc\",\"title\":\"Ultra-Strong Machine Learning: comprehensibility of programs learned with ILP\",\"url\":\"https://www.semanticscholar.org/paper/4603c2513605d18d8f7318c455aae32f20e0ecfc\",\"venue\":\"Machine Learning\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1784820\",\"name\":\"A. Taylor\"}],\"doi\":\"10.1145/1518701.1519022\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"20efcd00528a0b7d3bf28c2da0950c8a0c7bebe6\",\"title\":\"Machine intelligence\",\"url\":\"https://www.semanticscholar.org/paper/20efcd00528a0b7d3bf28c2da0950c8a0c7bebe6\",\"venue\":\"CHI\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"V. Mnih\"},{\"authorId\":null,\"name\":\"K. Kavukcuoglu\"},{\"authorId\":null,\"name\":\"D. Silver et al. Human-level control through deep rei Nature\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"518:529\\u2013533\",\"url\":\"\",\"venue\":\"02\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1986234\",\"name\":\"A. Cropper\"},{\"authorId\":\"145147566\",\"name\":\"S. Muggleton\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"544a43340f38891b536621fe1e26fa653d13e70a\",\"title\":\"Learning Higher-Order Logic Programs through Abstraction and Invention\",\"url\":\"https://www.semanticscholar.org/paper/544a43340f38891b536621fe1e26fa653d13e70a\",\"venue\":\"IJCAI\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"M. Bain\"},{\"authorId\":null,\"name\":\"S. H. Muggleton\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Machine intelligence 13\",\"url\":\"\",\"venue\":\"pages 291\\u2013309\",\"year\":1995},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"C. Watkins\"},{\"authorId\":null,\"name\":\"P. Dayan. Qlearning. Machine Learning\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"8(3):279\\u2013292\",\"url\":\"\",\"venue\":\"May\",\"year\":1992},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Dianhuan Lin\"},{\"authorId\":null,\"name\":\"Eyal Dechter\"},{\"authorId\":null,\"name\":\"Kevin M. et al Ellis. Bias reformulation for one-shot fu induction\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In In Proceedings of the 23rd European Conference on Artificial Intelligence (ECAI 2014)\",\"url\":\"\",\"venue\":\"pages 525\\u2013 530,. IOS Press,\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4562073\",\"name\":\"Chris Watkins\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"5c8bb027eb65b6d250a22e9b6db22853a552ac81\",\"title\":\"Learning from delayed rewards\",\"url\":\"https://www.semanticscholar.org/paper/5c8bb027eb65b6d250a22e9b6db22853a552ac81\",\"venue\":\"\",\"year\":1989},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47510673\",\"name\":\"P. R. Libby\"}],\"doi\":\"10.1038/1811767e0\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"99e09fe511a313e3fe6b0b74a616d809059ad8ca\",\"title\":\"The Scientific American\",\"url\":\"https://www.semanticscholar.org/paper/99e09fe511a313e3fe6b0b74a616d809059ad8ca\",\"venue\":\"Nature\",\"year\":1958},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3255983\",\"name\":\"V. Mnih\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"},{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"1392331736\",\"name\":\"Andrei A. Rusu\"},{\"authorId\":\"144056327\",\"name\":\"J. Veness\"},{\"authorId\":\"1397980088\",\"name\":\"Marc G. Bellemare\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"3137672\",\"name\":\"Martin A. Riedmiller\"},{\"authorId\":\"1397979864\",\"name\":\"Andreas K. Fidjeland\"},{\"authorId\":\"2273072\",\"name\":\"Georg Ostrovski\"},{\"authorId\":\"145386761\",\"name\":\"S. Petersen\"},{\"authorId\":\"48878752\",\"name\":\"C. Beattie\"},{\"authorId\":\"49813280\",\"name\":\"A. Sadik\"},{\"authorId\":\"2460849\",\"name\":\"Ioannis Antonoglou\"},{\"authorId\":\"153907173\",\"name\":\"H. King\"},{\"authorId\":\"2106164\",\"name\":\"D. Kumaran\"},{\"authorId\":\"1688276\",\"name\":\"Daan Wierstra\"},{\"authorId\":\"34313265\",\"name\":\"S. Legg\"},{\"authorId\":\"48987704\",\"name\":\"Demis Hassabis\"}],\"doi\":\"10.1038/nature14236\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e0e9a94c4a6ba219e768b4e59f72c18f0a22e23d\",\"title\":\"Human-level control through deep reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/e0e9a94c4a6ba219e768b4e59f72c18f0a22e23d\",\"venue\":\"Nature\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410609862\",\"name\":\"Alice M. Obenchain-Leeson\"},{\"authorId\":\"70155357\",\"name\":\"Carole Ann Creque\"},{\"authorId\":\"92909371\",\"name\":\"Brian Satterlee\"},{\"authorId\":\"1414249534\",\"name\":\"Kendrick W. Brunson\"}],\"doi\":\"10.1023/A:1017149715629\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"543d0c69ed424891fb0f3f601e72cb78a54a678a\",\"title\":\"Volume 6\",\"url\":\"https://www.semanticscholar.org/paper/543d0c69ed424891fb0f3f601e72cb78a54a678a\",\"venue\":\"\",\"year\":1998},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145341779\",\"name\":\"J. Quinlan\"}],\"doi\":\"10.1007/978-3-662-12405-5_15\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c606d130b2a6c653f2e84047d79201a820b7ab56\",\"title\":\"Learning Efficient Classification Procedures and Their Application to Chess End Games\",\"url\":\"https://www.semanticscholar.org/paper/c606d130b2a6c653f2e84047d79201a820b7ab56\",\"venue\":\"\",\"year\":1983},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144299726\",\"name\":\"Thomas G. Dietterich\"}],\"doi\":\"10.1145/242224.242229\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aab43c9c33af00b718cf2ae374b861d49862a563\",\"title\":\"Machine learning\",\"url\":\"https://www.semanticscholar.org/paper/aab43c9c33af00b718cf2ae374b861d49862a563\",\"venue\":\"CSUR\",\"year\":1996},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31474779\",\"name\":\"A. Shapiro\"},{\"authorId\":\"2353436\",\"name\":\"T. Niblett\"}],\"doi\":\"10.1016/B978-0-08-026898-9.50010-3\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"715916de986050eb2f6c1f963750dd8a72d033cf\",\"title\":\"AUTOMATIC INDUCTION OF CLASSIFICATION RULES FOR A CHESS ENDGAME\",\"url\":\"https://www.semanticscholar.org/paper/715916de986050eb2f6c1f963750dd8a72d033cf\",\"venue\":\"\",\"year\":1982},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"R. Brooks\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"FoR & AI: Machine learning explained\",\"url\":\"\",\"venue\":\"August\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Volodymyr Mnih\"},{\"authorId\":null,\"name\":\"Koray Kavukcuoglu\"},{\"authorId\":null,\"name\":\"David Silver\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"and et al\",\"url\":\"\",\"venue\":\"Human-level control through deep reinforcement learning. Nature, 518:529\\u2013533, 02\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145147566\",\"name\":\"S. Muggleton\"}],\"doi\":\"10.1007/3-540-63494-0_65\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eae43471750180d3fab67c8e5b954a91c54bed41\",\"title\":\"Learning from Positive Data\",\"url\":\"https://www.semanticscholar.org/paper/eae43471750180d3fab67c8e5b954a91c54bed41\",\"venue\":\"Inductive Logic Programming Workshop\",\"year\":1996},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145147566\",\"name\":\"S. Muggleton\"},{\"authorId\":\"48926589\",\"name\":\"Dianhuan Lin\"}],\"doi\":\"10.1007/s10994-014-5471-y\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d3f74da92bf3f9dae3329c6d962e908a38878ea1\",\"title\":\"Meta-interpretive learning of higher-order dyadic datalog: predicate invention revisited\",\"url\":\"https://www.semanticscholar.org/paper/d3f74da92bf3f9dae3329c6d962e908a38878ea1\",\"venue\":\"Machine Learning\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"S. D\\u017eeroski\"},{\"authorId\":null,\"name\":\"L. De Raedt\"},{\"authorId\":null,\"name\":\"K. Driessens. Relational reinforcement learning. Mach Learning\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"43(1):7\\u201352\",\"url\":\"\",\"venue\":\"Apr\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"M. Shanahan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"K . Driessens . Relational reinforcement learning\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145147566\",\"name\":\"S. Muggleton\"},{\"authorId\":\"48926589\",\"name\":\"Dianhuan Lin\"},{\"authorId\":\"2338174\",\"name\":\"Niels Pahlavi\"},{\"authorId\":\"1403549560\",\"name\":\"Alireza Tamaddoni-Nezhad\"}],\"doi\":\"10.1007/s10994-013-5358-3\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1801aa99bfe09a3ac2f74a2208047334cc8aef59\",\"title\":\"Meta-interpretive learning: application to grammatical inference\",\"url\":\"https://www.semanticscholar.org/paper/1801aa99bfe09a3ac2f74a2208047334cc8aef59\",\"venue\":\"Machine Learning\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1693549\",\"name\":\"S. Dzeroski\"},{\"authorId\":\"1740042\",\"name\":\"L. D. Raedt\"},{\"authorId\":\"1695114\",\"name\":\"K. Driessens\"}],\"doi\":\"10.1023/A:1007694015589\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bb09f2cd352865f8ee082d39c1e5583a5d208445\",\"title\":\"Relational Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/bb09f2cd352865f8ee082d39c1e5583a5d208445\",\"venue\":\"Machine Learning\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144753183\",\"name\":\"M. Carlson\"}],\"doi\":\"10.1080/10486801.2015.992227\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"73929283dad265b96be175510e359e67f2330a08\",\"title\":\"Editor\",\"url\":\"https://www.semanticscholar.org/paper/73929283dad265b96be175510e359e67f2330a08\",\"venue\":\"\",\"year\":2015}],\"title\":\"Can Meta-Interpretive Learning outperform Deep Reinforcement Learning of Evaluable Game strategies?\",\"topics\":[{\"topic\":\"Reinforcement learning\",\"topicId\":\"2557\",\"url\":\"https://www.semanticscholar.org/topic/2557\"},{\"topic\":\"Minimax\",\"topicId\":\"41706\",\"url\":\"https://www.semanticscholar.org/topic/41706\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"}],\"url\":\"https://www.semanticscholar.org/paper/a0b486978a613c2c99f7c9d5b247d212701c7322\",\"venue\":\"IJCAI\",\"year\":2019}\n"