"{\"abstract\":\"We propose an approach to general subgoal-based temporal abstraction in MCTS. Our approach approximates a set of available macro-actions locally for each state only requiring a generative model and a subgoal predicate. For that, we modify the expansion step of MCTS to automatically discover and optimize macro-actions that lead to subgoals. We empirically evaluate the effectiveness, computational efficiency and robustness of our approach w.r.t. different parameter settings in two benchmark domains and compare the results to standard MCTS without temporal abstraction.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"144309686\",\"name\":\"T. Gabor\",\"url\":\"https://www.semanticscholar.org/author/144309686\"},{\"authorId\":\"143917064\",\"name\":\"J. Peter\",\"url\":\"https://www.semanticscholar.org/author/143917064\"},{\"authorId\":\"41021158\",\"name\":\"Thomy Phan\",\"url\":\"https://www.semanticscholar.org/author/41021158\"},{\"authorId\":\"1416982170\",\"name\":\"C. Meyer\",\"url\":\"https://www.semanticscholar.org/author/1416982170\"},{\"authorId\":\"1402371578\",\"name\":\"C. Linnhoff-Popien\",\"url\":\"https://www.semanticscholar.org/author/1402371578\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":\"2009.08922\",\"authors\":[{\"authorId\":\"144839843\",\"name\":\"J. Goodman\"},{\"authorId\":\"1491612677\",\"name\":\"S. Risi\"},{\"authorId\":\"144288708\",\"name\":\"Simon Lucas\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"331acc8cc481f90a43fc96553ca0e479cf75ff15\",\"title\":\"AI and Wargaming\",\"url\":\"https://www.semanticscholar.org/paper/331acc8cc481f90a43fc96553ca0e479cf75ff15\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.11410\",\"authors\":[{\"authorId\":\"50213542\",\"name\":\"Giambattista Parascandolo\"},{\"authorId\":\"1981334\",\"name\":\"Lars Buesing\"},{\"authorId\":\"1599377224\",\"name\":\"Josh Merel\"},{\"authorId\":\"40401956\",\"name\":\"Leonard Hasenclever\"},{\"authorId\":\"9958912\",\"name\":\"J. Aslanides\"},{\"authorId\":\"2158860\",\"name\":\"Jessica B. Hamrick\"},{\"authorId\":\"1599360864\",\"name\":\"Nicolas Heess\"},{\"authorId\":\"40390373\",\"name\":\"Alexander Neitz\"},{\"authorId\":\"144588860\",\"name\":\"T. Weber\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4ad257a38360f03b905102af120a2726669334e7\",\"title\":\"Divide-and-Conquer Monte Carlo Tree Search For Goal-Directed Planning\",\"url\":\"https://www.semanticscholar.org/paper/4ad257a38360f03b905102af120a2726669334e7\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":199466238,\"doi\":\"10.24963/ijcai.2019/772\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":false,\"paperId\":\"99c4a4fc463ef56bb14feadbbfb3c79f54bb9d66\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Alec Solway\"},{\"authorId\":null,\"name\":\"Carlos Diuk\"},{\"authorId\":null,\"name\":\"Natalia C\\u00f3rdova\"},{\"authorId\":null,\"name\":\"Debbie Yee\"},{\"authorId\":null,\"name\":\"Andrew G. Barto\"},{\"authorId\":null,\"name\":\"Yael Niv\"},{\"authorId\":null,\"name\":\"Matthew M. Botvinick. Optimal behavioral hierarchy. PLOS C Biology\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"10(8)\",\"url\":\"\",\"venue\":\"August\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153449533\",\"name\":\"M. Botvinick\"},{\"authorId\":\"9796712\",\"name\":\"Y. Niv\"},{\"authorId\":\"119554887\",\"name\":\"Andrew C. Barto\"}],\"doi\":\"10.1016/j.cognition.2008.08.011\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3402002efd65b8002d03d1d455b196087abe7fc8\",\"title\":\"Hierarchically organized behavior and its neural foundations: A reinforcement learning perspective\",\"url\":\"https://www.semanticscholar.org/paper/3402002efd65b8002d03d1d455b196087abe7fc8\",\"venue\":\"Cognition\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Aijun Bai\"},{\"authorId\":null,\"name\":\"Feng Wu\"},{\"authorId\":null,\"name\":\"Xiaoping Chen. Online planning for large MDPs with MAXQ decomposition\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In AAMAS\",\"url\":\"\",\"venue\":\"IFAAMAS,\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144299726\",\"name\":\"Thomas G. Dietterich\"}],\"doi\":\"10.1145/242224.242229\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"aab43c9c33af00b718cf2ae374b861d49862a563\",\"title\":\"Machine learning\",\"url\":\"https://www.semanticscholar.org/paper/aab43c9c33af00b718cf2ae374b861d49862a563\",\"venue\":\"CSUR\",\"year\":1996},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1689774\",\"name\":\"B. Scherrer\"},{\"authorId\":\"1678622\",\"name\":\"M. Ghavamzadeh\"},{\"authorId\":\"3038127\",\"name\":\"Victor Gabillon\"},{\"authorId\":\"2961471\",\"name\":\"Boris Lesner\"},{\"authorId\":\"1737555\",\"name\":\"M. Geist\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a6ee4ae5344033fee613898841e2b9894bbfe4b7\",\"title\":\"Approximate modified policy iteration and its application to the game of Tetris\",\"url\":\"https://www.semanticscholar.org/paper/a6ee4ae5344033fee613898841e2b9894bbfe4b7\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29727884\",\"name\":\"A. Weinstein\"},{\"authorId\":\"144885169\",\"name\":\"M. Littman\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"14d2f4b8bb7c2ecb14c0072d9e25ba4c9ee59b68\",\"title\":\"Open-Loop Planning in Large-Scale Stochastic Domains\",\"url\":\"https://www.semanticscholar.org/paper/14d2f4b8bb7c2ecb14c0072d9e25ba4c9ee59b68\",\"venue\":\"AAAI\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699645\",\"name\":\"R. Sutton\"},{\"authorId\":\"144368601\",\"name\":\"Doina Precup\"},{\"authorId\":\"1699868\",\"name\":\"Satinder Singh\"}],\"doi\":\"10.1016/S0004-3702(99)00052-1\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0e7638dc16a5e5e9e46c91272bfb9c3dd242ef6d\",\"title\":\"Between MDPs and Semi-MDPs: A Framework for Temporal Abstraction in Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/0e7638dc16a5e5e9e46c91272bfb9c3dd242ef6d\",\"venue\":\"Artif. Intell.\",\"year\":1999},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"4337102\",\"name\":\"Julian Schrittwieser\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"2460849\",\"name\":\"Ioannis Antonoglou\"},{\"authorId\":\"1885349\",\"name\":\"Aja Huang\"},{\"authorId\":\"35099444\",\"name\":\"A. Guez\"},{\"authorId\":\"2449382\",\"name\":\"T. Hubert\"},{\"authorId\":\"144522726\",\"name\":\"L. Baker\"},{\"authorId\":\"40227832\",\"name\":\"Matthew Lai\"},{\"authorId\":\"34848283\",\"name\":\"A. Bolton\"},{\"authorId\":\"1519062204\",\"name\":\"Yutian Chen\"},{\"authorId\":\"2542999\",\"name\":\"T. Lillicrap\"},{\"authorId\":\"88791868\",\"name\":\"F. Hui\"},{\"authorId\":\"2175946\",\"name\":\"L. Sifre\"},{\"authorId\":\"47568983\",\"name\":\"George van den Driessche\"},{\"authorId\":\"1686971\",\"name\":\"T. Graepel\"},{\"authorId\":\"48987704\",\"name\":\"Demis Hassabis\"}],\"doi\":\"10.1038/nature24270\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c27db32efa8137cbf654902f8f728f338e55cd1c\",\"title\":\"Mastering the game of Go without human knowledge\",\"url\":\"https://www.semanticscholar.org/paper/c27db32efa8137cbf654902f8f728f338e55cd1c\",\"venue\":\"Nature\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143817739\",\"name\":\"J. Leeuwen\"},{\"authorId\":\"1685622\",\"name\":\"H. J. V. Herik\"},{\"authorId\":\"2937925\",\"name\":\"H. Iida\"},{\"authorId\":\"143817739\",\"name\":\"J. Leeuwen\"}],\"doi\":\"10.1007/3-540-48957-6\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8d01fdb6c503bc8b2d08172eb3f1f348f7bbdc33\",\"title\":\"Computers and Games\",\"url\":\"https://www.semanticscholar.org/paper/8d01fdb6c503bc8b2d08172eb3f1f348f7bbdc33\",\"venue\":\"Lecture Notes in Computer Science\",\"year\":1999},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37814588\",\"name\":\"M. Puterman\"}],\"doi\":\"10.1002/9780470316887\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8090121ad488b4af27bc59bf91b62e9c6a6f49c6\",\"title\":\"Markov Decision Processes: Discrete Stochastic Dynamic Programming\",\"url\":\"https://www.semanticscholar.org/paper/8090121ad488b4af27bc59bf91b62e9c6a6f49c6\",\"venue\":\"Wiley Series in Probability and Statistics\",\"year\":1994},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34250901\",\"name\":\"Ruijie He\"},{\"authorId\":\"2563117\",\"name\":\"Emma Brunskill\"},{\"authorId\":\"143724999\",\"name\":\"N. Roy\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2dc382065cc0230d6446d66936a49addac337f36\",\"title\":\"PUMA: Planning Under Uncertainty with Macro-Actions\",\"url\":\"https://www.semanticscholar.org/paper/2dc382065cc0230d6446d66936a49addac337f36\",\"venue\":\"AAAI\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Cai Zhongjie\"},{\"authorId\":null,\"name\":\"Dapeng Zhang\"},{\"authorId\":null,\"name\":\"Bernhard Nebel. Playing Tetris Using Bandit-Based Monte-Car Planning\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In AISB 2011: AI and Games\",\"url\":\"\",\"venue\":\"January\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144543541\",\"name\":\"P. Auer\"},{\"authorId\":\"1397171999\",\"name\":\"Nicol\\u00f2 Cesa-Bianchi\"},{\"authorId\":\"152138722\",\"name\":\"P. Fischer\"}],\"doi\":\"10.1023/A:1013689704352\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1e1d35136b1bf3b13ef6b53f6039f39d9ee820e3\",\"title\":\"Finite-time Analysis of the Multiarmed Bandit Problem\",\"url\":\"https://www.semanticscholar.org/paper/1e1d35136b1bf3b13ef6b53f6039f39d9ee820e3\",\"venue\":\"Machine Learning\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ronald Parr\"},{\"authorId\":null,\"name\":\"Stuart Russell. Reinforcement learning with hierarchies o machines\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In 1997 Conf\",\"url\":\"\",\"venue\":\"on Advances in Neural Information Processing Systems, NIPS \\u201997. MIT Press,\",\"year\":1998},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Thomas G. Dietterich. Hierarchical Reinforcement Learning Decomposition\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Journal of Artificial Intelligence Research\",\"url\":\"\",\"venue\":\"13,\",\"year\":2000},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Richard Bellman. Dynamic Programming. Princeton University Press\"},{\"authorId\":null,\"name\":\"Princeton\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"NJ\",\"url\":\"\",\"venue\":\"USA,\",\"year\":1957},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39934673\",\"name\":\"A. Bai\"},{\"authorId\":\"144864333\",\"name\":\"Feng Wu\"},{\"authorId\":\"27054809\",\"name\":\"X. Chen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"baa86bd53e7658378f1e61b0319cfa0bde8401a5\",\"title\":\"Online planning for large MDPs with MAXQ decomposition\",\"url\":\"https://www.semanticscholar.org/paper/baa86bd53e7658378f1e61b0319cfa0bde8401a5\",\"venue\":\"AAMAS\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1709512\",\"name\":\"L. Kaelbling\"}],\"doi\":\"10.1016/b978-1-55860-307-3.50028-9\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f4c6240b68e97d6f3b9bc67a701f10e49a1b1dab\",\"title\":\"Hierarchical Learning in Stochastic Domains: Preliminary Results\",\"url\":\"https://www.semanticscholar.org/paper/f4c6240b68e97d6f3b9bc67a701f10e49a1b1dab\",\"venue\":\"ICML\",\"year\":1993},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Aijun Bai\"},{\"authorId\":null,\"name\":\"Siddharth Srivastava\"},{\"authorId\":null,\"name\":\"Stuart J. Russell. Markovian State\"},{\"authorId\":null,\"name\":\"Action Abstractions for MDPs via Hierarchical MCTS\"}],\"doi\":null,\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In IJCAI\",\"url\":\"\",\"venue\":\"IJCAI/AAAI,\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145557817\",\"name\":\"Jonathan Rubin\"},{\"authorId\":\"1809241\",\"name\":\"I. Watson\"}],\"doi\":\"10.1016/j.artint.2010.12.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"43f8e76de51b81396faacbd61c91a5ac03fab9f3\",\"title\":\"Computer poker: A review\",\"url\":\"https://www.semanticscholar.org/paper/43f8e76de51b81396faacbd61c91a5ac03fab9f3\",\"venue\":\"Artif. Intell.\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1919203\",\"name\":\"Zhongjie Cai\"},{\"authorId\":\"47845024\",\"name\":\"Dapeng Zhang\"},{\"authorId\":\"145304209\",\"name\":\"B. Nebel\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8ba0126d89eed94da23f2142b17947a6c7d902e2\",\"title\":\"Playing Tetris Using Bandit-Based Monte-Carlo Planning\",\"url\":\"https://www.semanticscholar.org/paper/8ba0126d89eed94da23f2142b17947a6c7d902e2\",\"venue\":\"\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Christophe Thiery\"},{\"authorId\":null,\"name\":\"Bruno Scherrer. Building Controllers for Tetris\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"ICGA Journal\",\"url\":\"\",\"venue\":\"32(1),\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2146303\",\"name\":\"Wojciech Ja\\u015bkowski\"},{\"authorId\":\"8897266\",\"name\":\"Marcin Grzegorz Szubert\"},{\"authorId\":\"3176468\",\"name\":\"Pawel Liskowski\"},{\"authorId\":\"2076499\",\"name\":\"K. Krawiec\"}],\"doi\":\"10.1145/2739480.2754783\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5a5e702ac3f9daeb608a4f2f4ea82e8a5cbf2c12\",\"title\":\"High-Dimensional Function Approximation for Knowledge-Free Reinforcement Learning: a Case Study in SZ-Tetris\",\"url\":\"https://www.semanticscholar.org/paper/5a5e702ac3f9daeb608a4f2f4ea82e8a5cbf2c12\",\"venue\":\"GECCO\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52017307\",\"name\":\"\\u702c\\u5ddd \\u76f4\\u6a39\"},{\"authorId\":\"52031237\",\"name\":\"\\u6771 \\u6cbb\\u4eba\"},{\"authorId\":\"66095883\",\"name\":\"\\u4e2d\\u897f \\u5409\\u5f66\"},{\"authorId\":\"67047146\",\"name\":\"\\u5e73\\u6c60 \\u8c4a\"},{\"authorId\":\"66263994\",\"name\":\"\\u91d1\\u539f \\u88d5\\u5247\"},{\"authorId\":\"51961229\",\"name\":\"\\u52dd\\u5ca1 \\u6d0b\\u6cbb\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3388feae34ed63511fbca9b6450212ab51c03a64\",\"title\":\"\\u75c7\\u4f8b \\u814e\\u7d30\\u80de\\u764c\\u8853\\u5f8c13\\u5e74\\u76ee\\u306b\\u767a\\u898b\\u3055\\u308c\\u305f\\u81b5\\u30fb\\u5341\\u4e8c\\u6307\\u8178\\u8ee2\\u79fb\\u306e1\\u4f8b\",\"url\":\"https://www.semanticscholar.org/paper/3388feae34ed63511fbca9b6450212ab51c03a64\",\"venue\":\"\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3042377\",\"name\":\"Christophe Thiery\"},{\"authorId\":\"1689774\",\"name\":\"B. Scherrer\"}],\"doi\":\"10.3233/ICG-2009-32102\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f0e0060504adcfa8e980108054723aa045e0b20b\",\"title\":\"Building Controllers for Tetris\",\"url\":\"https://www.semanticscholar.org/paper/f0e0060504adcfa8e980108054723aa045e0b20b\",\"venue\":\"J. Int. Comput. Games Assoc.\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Mausam\"},{\"authorId\":null,\"name\":\"Andrey Kolobov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Planning with Markov Decision Processes: An AI Perspective\",\"url\":\"\",\"venue\":\"Synthesis Lect. on AI and Machine Learning. Morgan & Claypool Publishers,\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ngo Anh Vien\"},{\"authorId\":null,\"name\":\"Marc Toussaint. Hierarchical Monte-carlo Planning. In P Intelligence\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"AAAI\\u201915\",\"url\":\"\",\"venue\":\"AAAI Press,\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145107462\",\"name\":\"S. Russell\"},{\"authorId\":\"2784519\",\"name\":\"Peter Norvig\"}],\"doi\":\"10.5860/choice.33-1577\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3524cdf7cf8344e7eb74886f71fcbb5c6732c337\",\"title\":\"Artificial Intelligence: A Modern Approach\",\"url\":\"https://www.semanticscholar.org/paper/3524cdf7cf8344e7eb74886f71fcbb5c6732c337\",\"venue\":\"\",\"year\":1995},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699645\",\"name\":\"R. Sutton\"},{\"authorId\":\"1730590\",\"name\":\"A. Barto\"}],\"doi\":\"10.1109/TNN.1998.712192\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"97efafdb4a3942ab3efba53ded7413199f79c054\",\"title\":\"Reinforcement Learning: An Introduction\",\"url\":\"https://www.semanticscholar.org/paper/97efafdb4a3942ab3efba53ded7413199f79c054\",\"venue\":\"IEEE Transactions on Neural Networks\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"G Andrew\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Barto and Sridhar Mahadevan . Recent advances in hierarchical reinforcement learning\",\"url\":\"\",\"venue\":\"Discrete Event Dynamic Systems , 13 ( 1 ) , Jan 2003 . [ Bellman , 1957 ] Richard Bellman . Dynamic Programming\",\"year\":1957},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Bruno Scherrer\"},{\"authorId\":null,\"name\":\"Mohammad Ghavamzadeh\"},{\"authorId\":null,\"name\":\"Victor Gabillon\"},{\"authorId\":null,\"name\":\"Boris Lesner\"},{\"authorId\":null,\"name\":\"Matthieu Geist. Approximate modified policy iteration\"},{\"authorId\":null,\"name\":\"its application to the game of Tetris\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Journal of Machine Learning Research\",\"url\":\"\",\"venue\":\"16,\",\"year\":2015}],\"title\":\"Subgoal-Based Temporal Abstraction in Monte-Carlo Tree Search\",\"topics\":[{\"topic\":\"Monte Carlo tree search\",\"topicId\":\"18928\",\"url\":\"https://www.semanticscholar.org/topic/18928\"}],\"url\":\"https://www.semanticscholar.org/paper/99c4a4fc463ef56bb14feadbbfb3c79f54bb9d66\",\"venue\":\"IJCAI\",\"year\":2019}\n"